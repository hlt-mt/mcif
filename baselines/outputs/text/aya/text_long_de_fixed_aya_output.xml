<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind große Web-Crawl-Datensätze, die häufig politische Nachrichtenmedien wie die New York Times, Los Angeles Times, The Guardian und Huffington Post umfassen.</sample>
    <sample id="1">Die Autoren sind mit der McGill University, Mila und Microsoft Research assoziiert.</sample>
    <sample id="2">**Abstract**

Dieser Artikel präsentiert LayoutMask, ein innovatives prä-trainiertes Modell für visuell reiche Dokumentenverarbeitung (VRDU), das sich auf Formulare, Quittungen und Plakate konzentriert. Während bestehende VRDU-Modelle globale 1D-Positionen verwenden, um die Lesereihenfolge zu repräsentieren, schlägt LayoutMask lokale 1D-Positionen vor, die auf in-Segment-Token-Reihenfolgen basieren.

LayoutMask integriert Text- und Layoutinformationen, um tiefgreifende Text-Layout-Interaktionen zu fördern. Es verwendet zwei neuartige Maskierungsstrategien für die gängige Masked Language Modeling (MLM)-Aufgabe: Whole Word Masking und Layout-Aware Masking. Whole Word Masking eliminiert Wort-Semantik, zwingt das Modell, mehr Kontext zu nutzen, während Layout-Aware Masking die Maskierung auf anfängliche und endliche Wörter konzentriert, um die Überprüfung von Segmenten zu erleichtern.

Darüber hinaus führt LayoutMask ein neues Ziel, Masked Position Modeling (MPM), ein, das die Modellierung von 2D-Positionen durch Kontext- und Rauminferenz kombiniert.

Experimente zeigen, dass LayoutMask mit lokalen 1D-Positionen in Benchmarks wie FUNSD und SROIE bessere Leistungen erbringt als Modelle mit globalen 1D-Positionen. Die Ergebnisse belegen die Wirksamkeit der vorgeschlagenen Methode bei der Verbesserung der Text-Layout-Verständnis in VRDU-Aufgaben.</sample>
    <sample id="3">## Präsentation: DEPLAIN - Ein neues Korpus für die Textverstehungsförderung auf Dokument- und Satzebene

**Einführung:**

Hallo! Willkommen zu unserer Präsentation von DEPLAIN, einem neuen Korpus für die Identifizierung und Verstehungsförderung von Deutschtexten auf Dokument- und Satzebene. Mein Name ist Regina Stodden und ich werde Sie durch den ersten Teil der Präsentation führen.

**Was ist Textverstehungsförderung?**

Textverstehungsförderung ist ein Prozess, der darauf abzielt, einen Text für eine bestimmte Zielgruppe verständlicher zu gestalten, zum Beispiel für Menschen mit Leseproblemen oder Nichtmuttersprachler. Um ein Modell zur Textverstehungsförderung zu trainieren, benötigen wir parallele Textpaare, zum Beispiel von Dokumenten oder Sätzen. Ein Beispiel zeigt einen komplexen deutschen Satz und seine Übersetzung in eine einfache Sprache.

Um einen Satz zu vereinfachen, gibt es verschiedene Techniken, wie z.B. lexikalische Substitution, Satzteilentfernung, Satzreihenfolgeänderung oder das Einfügen von Wörtern.

**Probleme mit bestehenden Korpora:**

In den letzten Jahren gab es einige Probleme mit bestehenden Korpora:

* **Größe:** Einige Korpora sind zu klein, um ein effektives Modell zur Textverstehungsförderung zu trainieren.
* **Automatische Ausrichtung:** Drei kürzlich vorgeschlagene Korpora basieren auf automatischen Ausrichtungen, die fehleranfällig sein können.

**Präsentation von DEPLAIN:**

Daher stellen wir DEPLAIN vor, ein neues Korpus, das in zwei Unterkorpora unterteilt ist:

* **DEPLAIN-apa:** Basierend auf Nachrichtenartikeln. 483 Dokumente wurden manuell ausgerichtet, was etwa 13.000 parallele Satzpaare ergibt.
* **DEPLAIN-web:** Umfasst verschiedene Domänen, mit 750 manuell und automatisch ausgerichteten Dokumenten. Insgesamt 30.450 Satzpaare.

Wir haben die Satzpaare analysiert und festgestellt, dass:

* Texte aus der Bibel stärker vereinfacht sind als Nachrichtenartikel oder Lerntexte.
* Das DEPLAIN-Korpus eine hohe Vielfalt an Vereinfachungstransformationen aufweist. DEPLAIN-apa zeigt mehr Satzreihenfolgeänderungen und Wortzusätze, während DEPLAIN-web mehr Umformulierungen aufweist.

**Anwendungsfälle:**

* **Bewertung automatischer Ausrichtungsmethoden:** DEPLAIN kann als Goldstandard für die Bewertung von Methoden zur automatischen Satzausrichtung dienen, die in der Maschinend Übersetzung verwendet werden. Wir haben Anpassungen an bestehende Methoden vorgenommen und unsere Ergebnisse in einer Veröffentlichung dokumentiert. 
Unsere Tests zeigten, dass MASSalign die beste Methode für die Ausrichtung deutscher Texte zur Vereinfachung ist.

* **Automatische Textvereinfachung:** Wir haben zwei Sprachmodelle (long-mBART und base mBART) feinabgestimmt, um Dokumente bzw. Sätze auf Dokument- und Satzebene zu vereinfachen. Die Ergebnisse übertreffen die Basisscores und dienen als Benchmark für zukünftige Forschung.

**Fazit:**

Vielen Dank für Ihre Aufmerksamkeit! Wir freuen uns darauf, Sie während der Konferenz kennenzulernen.</sample>
    <sample id="4">Der/die Referent*in heißt Kayo Yin.</sample>
    <sample id="5">Das T5 XL Modell wurde verwendet, um eine Genauigkeit von 82–87 % zu erreichen.</sample>
    <sample id="6">**Abstract:**

Die Arbeit "Towards Unifying Multi-Lingual and Cross-Lingual Summarization" (Richtung zur Vereinigung von mehrsprachiger und kreissprachlicher Zusammenfassung) präsentiert einen neuen Ansatz namens "viele-zu-viele Zusammenfassung" (many-to-many summarization), um mehrsprachige und kreissprachliche Zusammenfassung in einem einzigen Modell zu vereinen.

Bisherige Methoden unterscheiden sich in der Eingabe- und Ausgabesprache: mehrsprachige Modelle erzeugen Zusammenfassungen in der Quellsprache, während kreissprachliche Modelle zwischen verschiedenen Sprachen wechseln. Die Autoren schlagen vor, diese Unterschiede zu überwinden und ein Modell zu entwickeln, das Dokumente in jeder Sprache zusammenfassen und Zusammenfassungen in jeder gewünschten Sprache generieren kann.

Durch experimentelle Untersuchungen mit dem WikiLingua-Datensatz auf mehreren Sprachen (Englisch, Französisch, Hindi, Chinesisch, Thai und Türkisch) wurde gezeigt, dass das viele-zu-viele Modell bessere Sprachübertragung erreicht als herkömmliche Ansätze.

Darüber hinaus wird PISCES, ein vorab trainiertes viele-zu-viele Zusammenfassungsmodell, vorgestellt. Es durchläuft ein dreistufiges Training: Meta-Vorbereitung, kreissprachliche Vorbereitung und aufgabenbezogene Vorbereitung. PISCES übertrifft basierend auf Experimenten verschiedene Referenzmodelle wie mBART-50 und mT5. Ablationsstudien und menschliche Bewertungen bestätigen die Effektivität des vorgeschlagenen Ansatzes.</sample>
    <sample id="7">Ja, basierend auf den Ergebnissen der Studie funktionieren CoNLL-2003-Tagger immer noch gut im Jahr 2023. Die Studie zeigt, dass mit geeigneten Modellarchitekturen, größeren Modellgrößen und mehr Feinabstimmungsbeispielen eine gute Generalisierung erreicht werden kann.</sample>
    <sample id="8">Die vorgeschlagene Methode, ABC-Eval, ist neu, weil sie die Bewertung von Chat-Modellen durch die explizite Annotation von Verhaltensweisen (wie Irrelevanz, Selbstkontradiktion, Halluzinationen usw.) präziser und objektiver macht, im Gegensatz zu herkömmlichen Methoden wie Likert-Skalen oder vergleichenden Bewertungen.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes (WSL) hängt von der Verfügbarkeit und Qualität von **sauberen, manuell annotierten Trainings- und Validierungsdaten** ab.</sample>
    <sample id="10">Das Ergebnis kann durch eine umfassendere und präzisere Bereitstellung von Hintergrundwissen für Sprachmodelle verbessert werden. Derzeit erreichen Modelle mit teilweise übereinstimmendem Hintergrundwissen eine Genauigkeit von 82-87%, während Modelle mit nur den Entitätsnamen nur 60% erreichen. Eine detailliertere und spezifischere Informationssammlung könnte die Leistung weiter steigern.</sample>
    <sample id="11">**Abstract:**

In seiner Präsentation "Do Androids Laugh at Electric Sheep? Humor ‘Verstehen’-Benchmarks aus dem New Yorker Caption Contest" untersucht Jack Hessel, Forschungswissenschaftler bei AI2, die Fähigkeiten von Large Language Models (LLMs) im Bereich Humorverständnis. Während moderne LLMs wie ChatGPT und Googles PaLM einfache Witze generieren und sogar erklären können, zeigt Hessel, dass ihre Humor-Kompetenz bei komplexeren Aufgaben wie Knock-Knock-Jokes oder der Interpretation von Cartoons begrenzt ist.

Der Vortrag konzentriert sich auf den New Yorker Caption Contest, bei dem Leser wöchentlich Cartoons mit unbeschrifteten Bildern beschreiben. Hessel und sein Team haben diese Daten in drei Aufgaben operationalisiert: Matching (richtige Beschriftung auswählen), Qualitätsklassifizierung (beste Beschriftung auswählen) und Erklärungsgenerierung (Warum ist der Witz lustig?).

Die Ergebnisse zeigen, dass selbst fortgeschrittene Modelle wie CLIP und GPT-4 im Vergleich zu menschlichen Teilnehmern, die 94% im Matching erreichen, deutlich schlechter abschneiden (62% für CLIP). GPT-4s Leistung verbessert sich leicht, wenn es mit Textbeschreibungen der Bilder trainiert wird, aber es bleibt eine große Lücke.

Hessel betont die Herausforderungen bei der Humor-Interpretation und präsentiert Fehler in GPT-4s Erklärungen. Er schlägt vor, dass die aktuelle Leistung der LLMs bei humorvollen Aufgaben noch verbesserungsfähig ist und fordert die Forschungsgemeinschaft zu weiteren Untersuchungen auf.</sample>
    <sample id="12">An der Arbeit sind 5 Autoren beteiligt: Dawei (der Präsentierende), Xiaoyu Shen, Marius Mosbach, Andreas Stephan und Dietrich Klakow.</sample>
    <sample id="13"># **Finding the SWEET Spot: Verbesserung adaptiver Inferenz in Low-Resource-Szenarien**

Diese Arbeit untersucht adaptive Inferenzmethoden zur Beschleunigung großer Sprachmodelle. Adaptive Inferenz nutzt die Variabilität realer Daten, indem es für einfache Eingaben niedrigere Kapazitätsmodelle einsetzt, was Zeit- und Kostenersparnisse ermöglicht.

Zwei gängige Ansätze sind Multi-Modell- und Early-Exit-Inferenz. Multi-Modell speichert mehrere Modelle und klassifiziert sie sequenziell, was Flexibilität bietet, aber Speicherplatz und Overhead erfordert. Early Exit verwendet mehrere Klassifikatoren nach Transformer-Schichten, was eine schnellere Inferenz ermöglicht, aber zu Konfliktsignalen zwischen Klassifikatoren führen kann, die die Leistung beeinträchtigen.

Die Studie vergleicht diese Methoden und stellt das Konzept der "konfliktierenden Gradienten" vor, bei dem Gradienten von verschiedenen Klassifikatoren die Modellparameter stören. Experimentelle Ergebnisse zeigen, dass Multi-Modell-Klassifikatoren in den meisten Fällen besser abschneiden.

Als Lösung schlagen die Autoren SWEET (Separating Weights in Early Exit Transformers) vor, eine Feinabstimmungsmethode für Early-Exit-Architekturen. SWEET minimiert Konflikte, indem es sicherstellt, dass jede Schicht nur Gradienten vom folgenden Klassifikator empfängt.

Die Ergebnisse zeigen, dass SWEET die Leistung von Early Exit verbessert, insbesondere bei schnellen Inferenzzeiten, und eine faire Grundlage für zukünftige Forschung in diesem Bereich bietet. Die Arbeit trägt dazu bei, die Herausforderungen und Möglichkeiten adaptiver Inferenz in Low-Resource-Kontexten zu verstehen.</sample>
    <sample id="14">## Die Abhängigkeitsstruktur der Koordination: Ein Plädoyer für Symmetrie

Hallo, mein Name ist Adam Przepiórkowski und in meinem Vortrag geht es um die Abhängigkeitsstruktur der Koordination. Wie Sie wissen, gehen verschiedene Theorien und Korpusansätze von unterschiedlichen Strukturen bei der Koordination aus.

**Beispielsweise setzt das Universal Dependencies-Schema die erste Konjunktion als Kopf der gesamten Koordinationsstruktur fest, wie im Beispiel "Lisa, Bart und Maggie".** Ähnlich verhält es sich in Igor Mel'čuks Theorie des Sinnes des Textes, wo ebenfalls die erste Konjunktion die gesamte Koordinationsstruktur dominiert. Diese Ansätze sind **asymmetrisch**, da sie eine der Konjunktionen herausheben.

Andere Ansätze, wie die Prager Schule, gehen von einem **Konjunktionskopf-Schema** aus, bei dem die Koordinationsstruktur von der Konjunktion geleitet wird. Hier entstehen Abhängigkeiten von der obersten Ebene bis zu allen Konjunktionen.

Ein **multi-köpfiges Schema** wird beispielsweise in Hudson's Word Grammar verwendet, wo alle Konjunktionen als Köpfe der Koordinationsstruktur betrachtet werden. Hier entstehen Abhängigkeiten vom Gouverneur zu jeder Konjunktion einzeln.

**Mein Vortrag zielt darauf ab, ein neues Argument für symmetrische Koordinationenstrukturen wie diese beiden zu präsentieren und asymmetrische Strukturen wie diese beiden zu widerlegen.**

Meine Argumentation basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge. Ich werde dies anhand von Beispielen veranschaulichen:

In der englischen Sprache bevorzugen direkte Objekte, nah am Verb zu stehen, während Adjunkte weiter entfernt sein können. Der Satz "Marge las es gestern" ist grammatikalisch korrekt, weil das direkte Objekt nahe am Verb liegt. Dagegen ist "Marge las gestern es" grammatisch schwächer.

**Allerdings kann diese Regelung gelockert werden, wenn das direkte Objekt sehr lang und schwerfällig ist.** In diesem Fall kann es nach dem Adjektiv verschoben werden, wie in "Marge las dieses absolut faszinierende Buch über Bienen gestern".

Beide Sätze verletzen die allgemeine Grammatikregel, dass direkte Objekte nahe am Verb stehen sollten, erfüllen aber das Prinzip der Abhängigkeitslänge, das kürzere Abhängigkeiten bevorzugt.

**In meiner Arbeit habe ich verschiedene Statistiken zur Koordination aus dem erweiterten Penn Treebank extrahiert und festgestellt, dass linke Konjunktionen tendenziell kürzer sind.** Dies wurde bereits oft beobachtet, beispielsweise in "Salz und Pfeffer" im Vergleich zu "Pfeffer und Salz" (gemessen in Silben).

Diese Tendenz **stärkt sich, wenn der Unterschied in der Länge zwischen den beiden Konjunktionen größer wird.**  Wenn die kürzere Konjunktion links steht, ist diese Tendenz besonders ausgeprägt.

**Neu in meiner Arbeit ist jedoch, dass wir herausgefunden haben, dass diese Tendenz nur auftritt, wenn der Gouverneur links steht oder fehlt.** Bei "Ich sah Bart und Lisa" steht der Gouverneur links. Fehlt er wie in "Homer kam und nieste", verschwindet der Effekt.

**Unsere Analyse zeigt, dass die Tendenz, die linke Konjunktion kürzer zu machen, bei einem Gouverneur auf der linken Seite zunimmt, sowohl wenn der Gouverneur direkt die Koordination leitet als auch wenn er fehlt (Koordination von Sätzen).** Bei einem Gouverneur auf der rechten Seite jedoch **verschwindet dieser Effekt**.

Diese Ergebnisse **sprechen dafür, asymmetrische Koordinationenstrukturen abzulehnen und symmetrische Strukturen zu bevorzugen.**

Weitere Details und eine detaillierte Argumentation finden Sie in meiner Arbeit. Kommen Sie gerne zum Poster-Gespräch, um mehr zu erfahren!</sample>
    <sample id="15">An der Arbeit sind drei Autoren beteiligt: Matthias Lindemann, Alexander Koller und Ivan Titov.</sample>
    <sample id="16">Basierend auf dem Inhalt, werden **Bible-Texte** im Vergleich zu Nachrichtentexten und Sprachlernmaterialien stärker vereinfacht dargestellt.</sample>
    <sample id="17"># Multimodale Relation Extraktion: Überwindung von Herausforderungen durch fein abgestimmte Informationsverarbeitung

In dieser Arbeit untersuchen wir die Herausforderungen bei der multimodalen Relation Extraktion (MRE), einem wichtigen Bereich der natürlichen Sprachverarbeitung. Ziel ist es, Beziehungen zwischen Entitäten in Texten und visuellen Quellen zu bestimmen. Die Autoren erkennen zwei Hauptprobleme an: *Over-Utilisierung interner Informationen* durch den Fokus auf Textteile und *Under-Exploitation externer Informationen* wie Themenkontext.

Um diese Probleme anzugehen, schlagen sie ein zweistufiges Verfahren vor:

1. **Graph Information Bottleneck (GIB) für fein abgestimmte Informationsverarbeitung:** GIB leitet die Optimierung, um irrelevante Knoten und Kanten in einem gemeinsamen Cross-Modal Graphen (CMG) zu entfernen, der Text- und Bilddarstellungen kombiniert.

2. **Multimodale Themeninformation als Ergänzung:** Topische Merkmale werden extrahiert und mit dem komprimierten CMG verknüpft, um den Kontext zu bereichern.

Die Ergebnisse zeigen, dass diese Methode die Leistung bei MRE-Aufgaben verbessert, insbesondere im Vergleich zu textbasierten Ansätzen. Durch eine Ablesestudie wird aufgezeigt, wann interne und externe Informationsverarbeitung am effektivsten ist, abhängig von der Relevanz von Text und Bild. Die Arbeit präsentiert einen innovativen Ansatz für MRE, der zu besseren Ergebnissen führt und das Potenzial für zukünftige Forschung in diesem Bereich aufzeigt.</sample>
    <sample id="18">Das Beispiel für die Präferenz für kürzere linke Konjunktionen ist die Phrase "I saw Bart and Lisa" im Vergleich zu "Homer came and sneezed". In dem ersten Beispiel, wo der Governor (in diesem Fall "saw") links ist, ist die linke Konjunktion ("Bart and Lisa") kürzer.</sample>
    <sample id="19"># **Efficient Open-Domain Question Answering: Ein Überblick**

Die Arbeit "A Survey for Efficient Open Domain Question Answering" zielt darauf ab, die Herausforderungen bei der Entwicklung effizienter Systeme für die Beantwortung offener Domänenfragen anzugehen. Der aktuelle Ansatz, wie von Danqi Chen vorgeschlagen, verwendet ein zweistufiges Modell mit einer Rückgewinnungsphase und einer Lesephase.

Hauptprobleme sind die große Größe von Wikipedia-Korpora (26 Millionen Dokumente, 20 GB), die Indexdatei (65 GB) und komplexe Sprachmodelle mit Millionen von Parametern. Das Ziel ist es, Systeme mit geringerem Speicherbedarf, schnellerer Inferenz und vergleichbarer Leistung zu entwickeln.

Die Präsentation fasst verschiedene Techniken zusammen, um diese Ziele zu erreichen, einschließlich:
- **Schnelle Evidenzsuche:** Approximative Nachbarsuchmethoden im Vergleich zur Brutsuche.
- **Schnelles Lesen:** Skip-Lesetechniken, um unwahrscheinliche Kontextinformationen zu vermeiden.
- **Indexkomprimierung:** Dokumentenfilterung und Methoden wie Dimensionenkomprimierung oder Produktquantisierung.
- **Modellkomprimierung:** Verwendung leichter Modelle, Parameterfreigabe oder die Kombination von Rückgewinnung und Lesen in einem Modell.

Die Analyse zeigt, dass Retrieval- und Lesesysteme eine gute Balance zwischen Geschwindigkeit, Speicher und Leistung bieten. Die Studie schlägt vor, dass Abwägungen zwischen Indexgröße, Modellgröße und Echtzeitfeedback die Auswahl des geeigneten Ansatzes beeinflussen. Zukünftige Forschungsrichtungen umfassen die Implementierung auf Low-Power-Geräten und die Entwicklung zusätzlicher Bewertungsmetriken.</sample>
    <sample id="20">Ja, alle vorgestellten Modelle (DrBERT und verschiedene Varianten) sind frei verfügbar auf Hugging Face und unter der MIT-Lizenz. Sie können diese Modelle für Ihre Forschung verwenden.</sample>
    <sample id="21">DEPLAIN-apa enthält Nachrichten- und Nachrichtenartikeltexte.</sample>
    <sample id="22">Basierend auf der Präsentation, führen zu einer guten Generalisierung:

1. **Modellarchitektur**: Transformer-Modelle generalisieren oft besser.
2. **Modellgröße**: Größere Modelle führen in der Regel zu besserer Generalisierung.
3. **Anzahl der Feinabstimmungsexemplare**: Mehr Feinabstimmungsexemplare verbessern die Generalisierung.</sample>
    <sample id="23">**Abstract**

Unsere Forschung konzentriert sich auf die Verbesserung der Fähigkeit von Text-Bild-Modellen, Text präzise darzustellen. Während Text-Bild-Modelle wie Imagen beeindruckende Bilder generieren, kämpfen sie oft mit der korrekten Darstellung von Text. Wir untersuchten die Ursachen dafür, indem wir uns auf das T5-XXL-Text-Encoder-Modul konzentrierten, das in Imagen verwendet wird.

Unsere Analyse ergab, dass T5, das SentencePiece-Tokenisierung verwendet, bei der Rechtschreibung schlecht abschneidet, selbst bei komplexen Eingaben. Größere T5-Modelle erreichen zwar bessere, aber immer noch unbefriedigende Genauigkeiten. Im Gegensatz dazu übertrifft PaLM bei der Rechtschreibung, ist jedoch aufgrund seiner Größe und Trainingsdatenmenge weniger praktisch.

Im Gegensatz dazu nutzt ByT5 individuelle Bytes als Eingabe, was eine perfekte Rechtschreibgenauigkeit ermöglicht. Wir stellten fest, dass T5 bei häufigen Wörtern Schwierigkeiten hat, weil diese oft durch wenige Token repräsentiert werden. ByT5 hingegen ist nicht von der Worthäufigkeit betroffen.

Um dies zu nutzen, verbesserten wir das Imagen-Modell durch die Addition eines ByT5-Small-Text-Repräsentationen. Diese einfache Modifikation verbesserte die Textdarstellung und die generierten Bilder. Obwohl die Diffusionsmodelle noch Fehler einführen können, zeigt unsere Arbeit eine effiziente Methode, um die Textdarstellung in Text-Bild-Modellen zu verbessern.</sample>
    <sample id="24">Die Tendenz zu kürzeren linken Konjunktionen wurde gemessen durch:

1. **Anzahl der Silben**: "salt and pepper" vs. "pepper and salt".
2. **Länge in Wörtern**: Der Unterschied in der Länge der beiden Konjunkte, insbesondere wenn der Gouverneur auf der linken Seite oder abwesend ist.
3. **Abhängigkeitslänge**: Die Länge der Abhängigkeiten vom Hauptverb zur jeweiligen Konjunkt, um die Gesamtabhängigkeitslänge zu minimieren.</sample>
    <sample id="25">Die Experimente wurden gestaltet, indem verschiedene Koordinationsstrukturen aus dem erweiterten Penn Treebank analysiert wurden. Die Länge der Abhängigkeiten zwischen den Koordinaten wurde gemessen und verglichen, insbesondere die Position des Begrenzers (Governor) variiert: links, abwesend (z.B. "I saw Bart and Lisa") oder rechts (z.B. "laughed governed Ted and Ned"). Die Ergebnisse zeigten, dass die Tendenz zur Kürze des linken Konjunkts nur auftritt, wenn der Begrenzer links oder abwesend ist.</sample>
    <sample id="26">Ein Basisklassifikator, der mit unausgewogenen Daten (wie im Fall von seltenen Klassen wie Dissonanz) trainiert wird, leistet in der Regel nicht viel besser als zufällig. Dies liegt daran, dass die Daten nicht ausreichen, um das Modell effektiv zu trainieren, insbesondere wenn die Zielklasse nur in einem sehr geringen Anteil vertreten ist.</sample>
    <sample id="27">Basierend auf dem präsentierten Inhalt, ist Shangbin der einzige Autor, der die Arbeit "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models" erwähnt. Es wird nicht explizit auf weitere Mitautoren hingewiesen. Daher ist die Antwort **1 Autor**.</sample>
    <sample id="28">Die Personen im Beispielgespräch sind Bob und Alice.</sample>
    <sample id="29">Kontextsensitive Modelle schneiden besser ab bei Diskursphänomenen wie **Formality** und **Lexikalische Kohäsion**.</sample>
    <sample id="30">**Abstract:**

Unsere Arbeit präsentiert *LLM-Blender*, ein einfaches und effektives Ensemble-Lernframework für Large Language Models (LLMs), das auf pairweiser Rangierung und generativer Fusion basiert. Wir untersuchten die Schwächen der aktuellen Praxis, bei der ein einzelnes, als bestes performendes Modell für alle Eingaben verwendet wird. Unsere Ergebnisse zeigen, dass die optimale Modellauswahl stark von der Eingabe abhängt.

*LLM-Blender* besteht aus zwei Stufen. Zunächst werden *n* verschiedene Modelle ausgeführt, um Ausgaben für eine gegebene Eingabe zu generieren. Die *PairRanker*-Module vergleichen diese Ausgaben pairweise, um eine Rangfolge zu erstellen. Im nächsten Schritt werden die Top-K-Kandidaten in ein generatives Fusionsmodell eingespeist, das die endgültige Ausgabe erzeugt.

Der *PairRanker* unterscheidet sich von bestehenden Methoden durch die gemeinsame Codierung von Kandidatenpaaren, um subtile Unterschiede besser zu erfassen. Wir validierten *LLM-Blender* auf einem neuen Datensatz, *MixInstruct*, der Kandidaten aus 11 Open-Source-LLMs enthält. Unsere Experimente zeigten, dass *LLM-Blender* in 68-76% der Fälle bessere Ergebnisse als zwei führende Modelle (Open Assistant und Vicuna) lieferte, was seine Effektivität als Ensemble-Lernansatz unterstreicht.

Zusammenfassend bietet *LLM-Blender* eine vielversprechende, einfache Lösung für die Verbesserung der LLM-Leistung durch Ensemble-Lernen.</sample>
    <sample id="31">Die Autoren gehören verschiedenen Institutionen an, darunter:

- John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy und Adina Williams (nicht explizit genannt, aber als Kollegen erwähnt)
- Die Arbeit ist eine gemeinsame Veröffentlichung, daher sind die Autoren mit verschiedenen Universitäten oder Forschungseinrichtungen verbunden, die in der Arbeit nicht detailliert aufgelistet sind.</sample>
    <sample id="33">Das Framework NLPositionality quantifiziert die Positionalität, indem es die Annotationen von diversen Benutzern (demografisch variiert) mit den Vorhersagen von Datensätzen und Modellen vergleicht, indem es einen Pearson's R-Korrelationswert berechnet. Es vergleicht somit die Vorhersagen der Modelle und Datensätze direkt mit den realen Benutzerentscheidungen, anstatt nur interne Modell- oder Annotator-Diskrepanzen zu untersuchen.</sample>
    <sample id="34">**Abstract:**

"CREST: A Joint Framework for Rationalization and Counterfactual Text Generation" präsentiert ein neuartiges Modell, das rationale Erklärungen und Gegenfaktische Textgenerierung kombiniert. Die Arbeit von Marcos Treviso und seinem Team zielt darauf ab, die Entscheidungen von Klassifizierern besser zu interpretieren und zu verbessern.

Das CREST-Framework besteht aus zwei Hauptkomponenten. Erstens generiert es Gegenfaktische Beispiele durch Maskierung und Ersetzung von Wörtern im Originaltext, gefolgt von einer Sprachmodell-basierten Füllung. Zweitens führt es eine gemeinsame Rationalisierung durch, die sowohl ursprüngliche als auch gegenfaktische Beispiele verarbeitet, um neue, informative Erklärungen zu erzeugen.

Die Evaluierung zeigt, dass CREST hochwertige Gegenfaktische erzeugt, die von Menschen als gültiger und natürlicher eingestuft werden. Diese Gegenfaktischen werden für Datenverstärkung und eine neue Trainingsmethode eingesetzt, bei der sowohl faktische als auch gegenfaktische Rationalen verwendet werden. Experimente auf den Datensätzen IMDB und SNLI belegen, dass CREST-Rationalisierung die Leistung auf In-Domain- und Out-of-Domain-Daten verbessert, insbesondere im Vergleich zu Methoden, die nur faktische Beispiele verwenden.

Die Analyse der Rationalen durch Plausibilität, Vorhersagbarkeit und eine neue Metrik, Counterfactual Simulability, zeigt, dass CREST plausible und wirkungsvolle Erklärungen liefert, die die Entscheidungsfindung des Klassifizierers beeinflussen können. Die Studie unterstreicht das Potenzial von CREST für interpretierbare KI und verbesserte Modellleistung.</sample>
    <sample id="36">**Abstract:**

Die Arbeit "Learning Language-Specific Layers for Multilingual Machine Translation" zielt darauf ab, die Kapazität und Effizienz mehrsprachiger Maschinenerstellung zu verbessern. Die Autoren schlagen Language-Specific Layers (LSLs) vor, eine Methode, die eine einzelne reguläre Transformer-Schicht pro Sprache verwendet. Während der Inferenzzeit wählt das Modell die passende Subschicht aus, was die Kosten konstant hält.

In ihren Experimenten platzierten die Forscher LSLs im Encoder, da dies keine signifikante Modellvergrößerung verursachte. Sie entwickelten ein System mit drei Gewichten pro Encoder-Schicht: gemeinsam, Quelle und Ziel. Durch Training und Analyse dieser Gewichte lernte das Modell die optimale LSL-Platzierung. Die größte Gewichtszunahme wies auf die zu wählende Schicht hin.

Die Ergebnisse zeigten, dass die vorgeschlagene Architektur signifikante Verbesserungen bei der Übersetzung in 84 von 90 Richtungen erzielt, insbesondere bei niedrig-ressourcen Sprachen. Im Vergleich zu Sprach-Adaptern und Baseline-Modellen war die Leistung überlegen, während die Inferenzgeschwindigkeit beibehalten wurde.

Die Studie demonstriert die Wirksamkeit von LSLs, um die Herausforderungen mehrsprachiger Übersetzung zu bewältigen, indem sie die Kapazität pro Sprache erhöht und gleichzeitig die Effizienz bei der Inferenz gewährleistet.</sample>
    <sample id="37">Die vorherige Studie zeigte, dass menschliche Teilnehmende bei der Beschreibung von Personas ähnliche, aber breiter gefasste Stereotypen und Muster aufwiesen als die von einem Sprachmodell generierten Personas. Während die generierten Personas mehr stereotype Wörter enthielten, deckte die breitere Wortwahl der menschlichen Antworten schädlichere, aber weniger häufige Stereotype ab.</sample>
    <sample id="38">In dieser Studie wurden Daten aus der erweiterten Version des Penn Treebank und der Studie "Why Wouldn't You Use Universal Dependencies?" verwendet.</sample>
    <sample id="39">Basierend auf dem vorgestellten Inhalt scheint nur ein Autor, Adam Przepiórkowski, an der Arbeit beteiligt zu sein.</sample>
    <sample id="40">Eng verwandte Aufgaben für kognitive Dissonanz sind:

1. **Debate Stance Classification**: Bestimmt, ob zwei Debaten-Aussagen von verschiedenen Personen übereinstimmen oder widersprechen, unabhängig vom Thema.
2. **Binary Classification von Expansion und Comparison Klassen des PDTB**: Klassifiziert Textpaare in Bezug auf Konsonanz und Dissonanz, da diese Konzepte eng mit kognitiver Dissonanz zusammenhängen.</sample>
    <sample id="41">**Abstract:**

"PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives" ist eine Zusammenarbeit zwischen der NLP-Forschungsgruppe der EPFL Universität und Sony Group Corporation. Das Projekt zielt darauf ab, die Kohärenz und Attraktivität von Dialogen und Geschichten durch die Integration von Personenkennis in natürliche Sprachverarbeitungs-Systeme zu verbessern.

Um dies zu erreichen, wurde PeaCoK, ein Persona-basierter Commonsense-Wissensgraph, entwickelt. Er umfasst 3.800 Personas mit 40.000 Attributen und 100.000 persönlichen Schlussfolgerungen. Basierend auf Studien menschlicher Interaktionen werden Personas und ihre Attribute in drei Dimensionen mit vier Hauptbeziehungen und Interaktivität sowie Distinktivität beschrieben.

PeaCoK wurde in drei Schritten aufgebaut: Auswahl von Personas aus Commonsense-Graphen, Induktion von Attributen aus Wissensgraphen und Sprachmodellen sowie Crowdsourcing der Beziehungen mit einem AI-gestützten Mehrheitsabstimmungssystem.

Die Effektivität von PeaCoK wird durch Trainings eines BART-basierten Wissensgenerators demonstriert, der bessere Ergebnisse als große Sprachmodelle wie GPT-3 und GPT-3.5 erzielt. Im Dialoggenerierungs-Downstream-Modell zeigt PeaCoK durch Augmentation von Persona-Profilen positive Auswirkungen auf Konsistenz, Engagement und Personenausdruck.

Zusammenfassend bietet PeaCoK eine zuverlässige Wissensbasis, die leichtere Sprachmodelle befähigt, vergleichbares Generierungsvermögen wie große Modelle zu erreichen und narrativen Modellen kohärentere und ansprechendere Konversationen ermöglicht.</sample>
    <sample id="42">Basierend auf dem Inhalt, scheint die Präsentation von Shuheng nur einen Autor, Shuheng selbst, zu beinhalten. Er ist derjenige, der die Forschung und die Ergebnisse präsentiert.</sample>
    <sample id="43">Basierend auf dem präsentierten Inhalt, scheint nur eine Person, Vasudha, an der Arbeit beteiligt zu sein. Sie wird als PhD-Kandidatin beschrieben und ist die Hauptverfasserin der Präsentation.</sample>
    <sample id="44">Das vorgestellte Framework **NLPositionality** unterscheidet sich von bisherigen Arbeiten dadurch, dass es **direkt die Übereinstimmung zwischen Endbenutzern und Datensätzen sowie Modellen** untersucht, anstatt sich nur auf die Übereinstimmung zwischen Annotatoren zu konzentrieren. Es vergleicht die Annahmen von Endbenutzern (über soziale Akzeptanz und Hassrede) direkt mit den Vorhersagen von Modellen und den Labels in Datensätzen, was eine umfassendere Analyse von **Modell- und Datensatz-Positionalität** ermöglicht.</sample>
    <sample id="45">Basierend auf dem Inhalt, hat das **generierte Persona-Setup** die meisten Überschneidungen mit dem Lexikon der Stereotypen. Während die human-geschriebenen Personas eine breitere Wortverteilung aufweisen, enthalten die generierten Personas die Stereotypen-Wörter "tall" und "athletic" und vor allem diejenigen, die aus der Marked Words-Analyse hervorgehen. Diese zeigen schädliche Muster und essenzielle Narrative, die nicht immer offensichtlich negativ erscheinen, aber schädliche gesellschaftliche Konstrukte widerspiegeln.</sample>
    <sample id="46">In der Präsentation wurden die kommerziellen Systeme DeepL und Google Translate verglichen.</sample>
    <sample id="47">## Von der Vorabdaten bis zu den Sprachmodellen: Auf der Spur der politischen Voreingenommenheit, die zu ungerechten NLP-Modellen führt

Hallo, ich bin Shangbin, Doktorand an der Universität Washington. Heute präsentiere ich unsere Arbeit mit dem Titel "Von der Vorabdaten bis zu den Sprachmodellen bis hin zu Downstream-Aufgaben: Die Entwicklung politischer Voreingenommenheit in NLP-Modellen".

Sprachmodelle werden auf riesigen Web-Crawl-Daten trainiert. Politische Nachrichtenmedien sind in diesen Daten gut vertreten. Eine Analyse des C4-Korpus zeigt, dass Zeitungen wie die New York Times, die Los Angeles Times, The Guardian und die Huffington Post häufig in den Trainingsdaten vorkommen. Dies birgt sowohl Chancen als auch Herausforderungen für die Anwendung von Sprachmodellen. Einerseits ermöglicht es ihnen, aus verschiedenen Perspektiven zu lernen und so die Vielfalt demokratischer Ideen zu feiern. Andererseits sind diese unterschiedlichen politischen Meinungen von Natur aus sozial voreingenommen und könnten zu Ungerechtigkeiten in Downstream-Aufgaben führen.

Daher untersuchen wir die Pipeline der politischen Voreingenommenheit, die von den Vorabdaten über die Sprachmodelle bis hin zu den Downstream-Aufgaben führt. Konkret stellen wir uns folgende Fragen: Erstens, wie können wir die politische Ausrichtung von Sprachmodellen bewerten und welche Rolle spielen dabei die Vorabdaten? Zweitens, wie verhalten sich Sprachmodelle mit unterschiedlichen politischen Einstellungen in Downstream-Aufgaben und führen diese Unterschiede zu Fairnessproblemen in NLP-Anwendungen?

Zu diesem Zweck schlagen wir vor, Sprachmodelle mit verschiedenen Prompt-Formaten anhand politischer Fragebögen wie dem Political Conference Test zu stimulieren. Dies ermöglicht eine Bewertung, die auf der Literatur der politischen Wissenschaft basiert. Unsere vorläufigen Ergebnisse zeigen: Erstens haben Sprachmodelle unterschiedliche politische Einstellungen. Sie verteilen sich über alle vier Quadranten des politischen Spektrums. GPT-4 ist beispielsweise das am stärksten liberale Sprachmodell. GPT-Modelle sind im Allgemeinen sozial liberaler als BART-Modelle und ihre Varianten.

Zweitens möchten wir untersuchen, inwieweit die politischen Voreingenommenheiten von Sprachmodellen tatsächlich auf die Trainingsdaten zurückzuführen sind. Dazu führen wir einen kontrollierten Experiment durch, indem wir Sprachmodell-Checkpoints weiter auf sechs verschiedene parteiische Korpora trainieren, die in Nachrichten und soziale Medien unterteilt sind und nach ihrer politischen Ausrichtung klassifiziert wurden. Durch das weitere Trainieren von Sprachmodellen auf diesen parteiischen Korpora beobachten wir eine Verschiebung der ideologischen Koordinaten des Modells. Zum Beispiel zeigt sich bei RoBERTa, das auf ein linke-lastiges Reddit-Korporum weiter trainiert wurde, eine deutliche liberale Verschiebung der politischen Voreingenommenheit. Wir untersuchen auch, ob Sprachmodelle die Polarisierung in unserer Gesellschaft aufnehmen können. Dazu teilen wir die Trainingsdaten in zwei Zeiträume auf: vor und nach der Präsidentschaft von Donald Trump. Wir stellen fest, dass Sprachmodelle nach 2017 tendenziell weiter von der Mitte entfernt sind, was darauf hindeutet, dass sie die Polarisierung in unserer Gesellschaft aufnehmen.

Schließlich bewerten wir Sprachmodelle mit unterschiedlichen politischen Einstellungen in den Aufgaben Hassrede-Erkennung und Falschinformationen-Erkennung, die beide häufig in NLP-Anwendungen vorkommen und erhebliche Auswirkungen haben können. Wir stellen fest, dass die Leistung je nach Kategorie unterschiedlich ausfällt. So sind linke Sprachmodelle beispielsweise besser darin, Hassrede gegen Minderheitengruppen zu erkennen, aber schlechter darin, Hassrede gegen mächtigere Gruppen zu identifizieren. Rechte Sprachmodelle sind besser darin, Hassrede gegen Weiße und Männer zu erkennen, aber schlechter darin, Hassrede gegen schwarze LGBTQ+-Gemeinschaften und andere Minderheiten zu identifizieren. Ähnliche Trends beobachten wir bei der Falschinformationen-Erkennung.

Qualitative Beispiele veranschaulichen, dass Sprachmodelle mit unterschiedlichen politischen Einstellungen unterschiedliche Vorhersagen zu Hassrede- und Falschinformationenbeispielen basierend auf der sozialen Kategorie treffen. Dies zeigt deutlich, dass es dringende Fairnessprobleme aufgrund der politischen Voreingenommenheit von Sprachmodellen gibt. Wenn beispielsweise ein rechtsextremes Sprachmodell für die Bekämpfung von Hassrede oder Falschinformationen eingesetzt würde, könnte dies dazu führen, dass Menschen mit gegensätzlichen politischen Ansichten marginalisiert werden und Hassrede gegen Minderheitengruppen unkontrolliert verbreitet wird.

**Diskussion:**

Unsere Arbeit beleuchtet ein einzigartiges Dilemma in Bezug auf die politische Voreingenommenheit von Sprachmodellen. Es ist wie zwischen Scylla und Charybdis: Wenn wir politische Meinungen in den Trainingsdaten nicht zensieren, führt dies zu Voreingenommenheit von Vorabdaten bis hin zu Sprachmodellen und Downstream-Aufgaben, was zu Fairnessproblemen führt. Wenn wir jedoch versuchen, die Daten zu zensieren, um Voreingenommenheit zu vermeiden, riskieren wir Zensur oder Ausschluss und es wird schwierig, objektiv neutrale Inhalte zu definieren. Dies erinnert an das Dilemma des elektrischen Wagenproblems.</sample>
    <sample id="48">An der Arbeit sind zwei Autoren beteiligt: David Vilar und seine Kollegen von Google Translate.</sample>
    <sample id="49">Die MPP-Auswertungen (Minimal Pair Paradigm) wurden bis zu einer Kontextlänge von 1024 Token durchgeführt.</sample>
    <sample id="50"># **DEPLAIN: Ein neues Korpus für die Textvereinfachung in Deutsch**

Die Präsentation stellt DEPLAIN vor, ein umfassendes Korpus für die Textidentifikation und Vereinfachung auf Dokument- und Satzebene in Deutsch. DEPLAIN wurde entwickelt, um die Herausforderungen bestehender Korpora zu überwinden, die oft zu klein sind oder automatisch ausgerichtete Paare enthalten, die fehleranfällig sein können.

Das Korpus besteht aus zwei Unterkorpora: DEPLAIN-apa, basierend auf Nachrichtenartikeln mit 483 manuell ausgerichteten Dokumenten (13.000 Satzpaare), und DEPLAIN-web, das verschiedene Domänen abdeckt und sowohl manuelle als auch automatische Ausrichtungsmethoden verwendet (30.450 Satzpaare).

Die Analyse der Satzpaare zeigt unterschiedliche Vereinfachungsstufen und -techniken, wobei Bibeltexte stärker vereinfacht sind. DEPLAIN bietet eine breite Palette an Vereinfachungstransformationen.

Die Präsentation beschreibt zwei Hauptanwendungsfälle:

1. **Bewertung automatischer Ausrichtungsmethoden**: DEPLAIN ermöglicht die Überprüfung und Verbesserung von Ausrichtungstechniken für parallele Dokumente derselben Sprache mit unterschiedlicher Komplexität. Der MASSalign-Algorithmus erwies sich als bestes automatisches Verfahren.

2. **Automatische Textvereinfachung**: Zwei Sprachmodelle (long-mBART und base mBART) wurden feinabgestimmt, um komplexe Texte zu vereinfachen. Die Ergebnisse übertreffen die Basisscores und bieten einen neuen Benchmark für die automatische Textvereinfachung.

Zusammenfassend bietet DEPLAIN wertvolle Ressourcen für die Forschung und Entwicklung von Textvereinfachungstechnologien in Deutsch.</sample>
    <sample id="51">Sie haben Datensätze für die Domains Musik, Bücher und Rezepte aufgenommen.</sample>
    <sample id="52">Positionalität bezieht sich auf die Perspektiven und Vorurteile, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen entwickeln. Sie beeinflusst Entscheidungen und Ergebnisse in der Forschung, einschließlich NLP (Natural Language Processing).</sample>
    <sample id="53">Der/die Referent*in ist Dawei.</sample>
    <sample id="54">## Transfer Learning for Dissonance Detection: A Summary

Cognitive dissonance, the conflict between beliefs and actions, is a common yet rarely expressed phenomenon in language. Understanding it is crucial for gauging public opinion, mental health, and decision-making processes.

This work presents a novel approach to detect dissonance in text using transfer learning and active learning. We address the "rare-class challenge" posed by dissonance's low occurrence (3.5% in our annotated dataset).

Starting with a pre-trained model, we leverage transfer learning from related tasks like debate stance classification and PDTB expansion/comparison. This initial model achieves a zero-shot performance of 0.62 AUC.

We then employ active learning to iteratively refine the model by selecting the most informative dissonance examples. Using a Probability-of-Rare-Class (PRC) strategy, we prioritize examples the model is most likely to classify correctly.

Our experiments demonstrate that PRC outperforms other active learning strategies, reaching a final dissonance classification AUC of 0.75.

Furthermore, we find that "cumulative" model updates, accumulating all annotated data, are more effective than "iterative" updates for transfer learning across domains.

This work contributes a valuable dataset and a robust framework for dissonance detection, opening avenues for further research into cognitive dissonance and its implications.</sample>
    <sample id="55">Ja, EDAtt (Encoder-Decoder Attention) passt zu einem bestehenden Offline-ST-Modell, da es vorschlägt, bereits vorhandene Modelle ohne erneutes Training oder spezifische Architekturänderungen für SimulST (Simultaneous Speech Translation) zu nutzen. Stattdessen wird die Latenz durch spezifische Parameter gehandhabt und die bereits erworbene Wissensbasis des Modells durch die Cross-Attention-Mechanik genutzt.</sample>
    <sample id="56">Basierend auf dem präsentierten Inhalt, ist Yusen Zhang der einzige Autor, der die Arbeit "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations" erwähnt. Es wird nicht explizit auf weitere Mitautoren hingewiesen. Daher ist die Antwort **1 Autor**.</sample>
    <sample id="57">Ja, einige Modelle, insbesondere nach spezifischer Aufgaben-Training auf der KITMUS-Testsuite, sind in der Lage, Wissen aus verschiedenen Quellen zu integrieren und zeigen signifikant bessere Leistungen als zufällige Auswahl. Allerdings haben selbst die besten Modelle Schwierigkeiten, rückwärts gerichtetes Wissen (nur beim Inferenzzeitpunkt verfügbar) zuverlässig zu integrieren.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind:

1. **Background-Pretrain**: Hintergrundwissen ist im Pretraining verfügbar.
2. **Background-Both**: Hintergrundwissen ist sowohl im Pretraining als auch bei der Inferenz verfügbar.
3. **Background-Inference**: Hintergrundwissen ist nur bei der Inferenz verfügbar.</sample>
    <sample id="59">## DrBERT: Ein robustes, französisches Pre-trained Modell für Biomedizin und Klinische Domänen

Unser Artikel stellt DrBERT vor, das erste biomedicale Pre-trained Modell in französischer Sprache. Basierend auf RoBERTa und trainiert auf NACHOS, einem Datensatz mit medizinischen Web-Crawl-Daten, übertrifft DrBERT bestehende Modelle in 11 Biomedizin- und klinischen Downstream-Aufgaben.

Wir untersuchen die Effektivität verschiedener Pre-training-Einstellungen und Datenquellen und vergleichen DrBERT mit ChuBERT, einem Modell basierend auf anonymisierten klinischen Daten. Unsere Ergebnisse zeigen, dass Modelle, die auf biologischen Daten trainiert sind, im Allgemeinen besser abschneiden als solche, die auf klinischen Daten basieren.

Wir untersuchen auch die erforderliche Datenmenge für effektives Training und vergleichen sieben Modelle: vier von Grund auf neu trainierte DrBERT-Varianten, drei Modelle mit kontinuierlichem Pre-training (eines auf CamemBERT und NACHOS, eines auf CamemBERT und klinischen Notizen und eines auf PubMedBERT).

Unsere Evaluierung zeigt, dass Modelle, die auf Daten trainiert wurden, die der jeweiligen Aufgabe entsprechen, die besten Ergebnisse erzielen. Heterogene Datenquellen erwiesen sich als vielseitiger. Während mehr Daten zu besseren Leistungen führen, zeigten unsere Experimente, dass von Grund auf trainierte Modelle in vielen Fällen höhere Leistungen erbringen als Modelle mit kontinuierlichem Pre-training.

Alle DrBERT-Modelle und Trainingsskripte sind frei verfügbar.</sample>
    <sample id="60">Die Autoren Javad Hosseini, Filip Radlinski, Silvia Pareti und Annie Louis sind mit der Universität nicht explizit verbunden, da sie in ihrer Arbeit keine spezifische Institution nennen. Sie arbeiten jedoch an einem gemeinsamen Projekt und haben wahrscheinlich Verbindungen zu verschiedenen akademischen Institutionen, basierend auf ihren jeweiligen Fachgebieten und Hintergründen.</sample>
    <sample id="61">Die abschließende Forschungsfrage ist: **Sollten wir nur saubere Daten für die Validierung verwenden oder gibt es bessere Möglichkeiten, sie zu nutzen?**</sample>
    <sample id="62">**Abstract:**

Dieser ACL-Papier präsentiert eine umfassende Untersuchung von Wissensvermittlung (Knowledge Distillation) für natürliche Sprachgenerierung (NLG) mit Pseudo-Zieltraining. Die Studie zielt darauf ab, effiziente Methoden zur Komprimierung großer NLG-Modelle zu entwickeln und dabei die Leistung zu erhalten.

Im Gegensatz zu früheren Arbeiten, die sich hauptsächlich auf Klassifizierung und Vorabtraining konzentrierten, untersucht die Studie spezifische Wissensvermittlung für verschiedene NLG-Aufgaben in realistischen Szenarien. Diese Szenarien umfassen mittelgroße, ressourcenbeschränkte Datensätze, große Mengen unbeschrifteter Daten, Effizienz bei der Inferenzzeit und vernachlässigbare Trainingsressourcen.

Die Forschung umfasst acht Phasen, beginnend mit der Erkundung architektonischer Entscheidungen wie Encoder/Decoder- vs. Decoder-nur-Architekturen und der Auswirkungen von Beschneidung auf die Leistung. Es vergleicht dann verschiedene Wissensauswahlmethoden und State-of-the-Art-Basislinien.

Der Hauptbeitrag besteht in der Erforschung der Erweiterung des Pseudo-Ziel-Konzepts. Die Autoren zeigen, dass unbeschriftete Daten die Wissensvermittlung verbessern, die Generierung mehrerer Pseudo-Ziele gegenüber einem einzigen verbessert und eine vielfältigere Auswahl an Pseudo-Zielen (mit hohen Temperaturen) den Schüler einem breiteren Wissen des Lehrers aussetzt.

Schließlich wird eine neue Technik namens "Joint-Teaching" eingeführt, die Wort-Level-Wissensvermittlung auf Pseudo-Ziele anwendet, die sowohl vom Lehrer als auch vom Schüler generiert werden, um Bias und unbegründetes Lernen anzugehen.</sample>
    <sample id="63">Die Sensitivitätsmetrik misst die Konsistenz der Modellausgaben für dieselbe Aufgabe unabhängig von leichten Variationen in der Instruktion. Sie zeigt, wie empfindlich das Modell gegenüber kleinen Änderungen in der Formulierung der Anweisungen reagiert.</sample>
    <sample id="64">Jingwei Yi</sample>
    <sample id="65">Eine höhere Sensitivität bedeutet in diesem Kontext **weniger** Sensitivität oder **bessere Leistung**.

Der Text besagt, dass ein Modell mit höherer Sensitivität **konstantere** Ausgaben für dieselbe Aufgabe erzeugt, unabhängig von leichten Variationen in der Instruktion. Das impliziert eine robustere Leistung, was als **besser** interpretiert werden kann.

Der Absatz hebt hervor, dass die Verwendung von mehr Instruktionen (höhere Sensitivität) die **Gesamtleistung des Modells verbessert** und seine **Sensitivität reduziert**.</sample>
    <sample id="66">**Abstract:**

Unser ACL-Papier "Deep Learning for Mathematical Reasoning" untersucht die Entwicklung von Maschinen, die in der Lage sind, mathematische Probleme zu lösen und Theoreme zu beweisen – ein langjähriges Ziel der KI und NLP. Wir fokussieren uns auf zwei Hauptkategorien: textbasierte und multimodale Kontexte. Textbasierte Aufgaben umfassen mathematische Wortprobleme mit mehreren Schritten, während multimodale Aufgaben Bilder, Diagramme und Tabellen beinhalten.

Geometrische Probleme, ein wichtiger Teil der Schulbildung, erfordern die Identifikation von Beziehungen in Diagrammen, Anwendung von Theoremen und Berechnungen. Automatisiertes Theorembeweisen zielt darauf ab, mathematische Behauptungen durch eine Kette von Argumenten zu validieren.

Neuere Ansätze nutzen neuronale Netzwerkarchitekturen, wie sequenz-zu-sequenz-Modelle und sequenz-zu-baum-Modelle, um mathematische Aufgaben zu lösen. Die Einführung großer Sprachmodelle (LLMs) hat bemerkenswerte Fortschritte in NLP ermöglicht, auch in der Lösung mathematischer Wortprobleme durch "Chain-of-Thought"-Methoden.

Trotz ihrer Stärken haben LLMs Schwierigkeiten mit präziserem mathematischem Denken. Lösungen beinhalten die Verwendung von Selbstkonsistenz anstelle von Greedy-Decodierung und die Integration von Programmen zur Unterstützung komplexer Aufgaben.

Schließlich betonen wir die Notwendigkeit weiterer Forschung in Low-Resource-Einstellungen und die Herausforderungen der Generalisierung und Robustheit von Modellen in mathematischen Reasoning-Aufgaben.</sample>
    <sample id="67">**Abstract:**

Diese Arbeit untersucht Interferenzen in mehrsprachigen Übersetzungsmodellen und deren Auswirkungen auf die Leistung. Es wird festgestellt, dass Interferenzen auftreten, wenn Modelle zu klein im Vergleich zum verfügbaren Datenvolumen sind. Die Studie konzentriert sich auf die Faktoren, die zu Synergie oder Interferenzen führen, und kommt zu dem Schluss, dass Sprachähnlichkeit und die Anzahl der Sprachen nur geringfügige Auswirkungen haben.

Durch Experimente mit vier Varianten der Transformer-Architektur und 15 Sprachen aus WMT wurde festgestellt, dass schwere Interferenzen hauptsächlich bei sehr kleinen Modellen auftreten. Die Größe des Modells und der Fokusdatensätze spielen entscheidende Rollen. Die Ergebnisse zeigen, dass die Anpassung der Temperatur des Sampling-Prozesses eine effektive Methode zur Bekämpfung von Interferenzen darstellt, insbesondere bei größeren Modellen.

Die Forschung legt nahe, dass die Kombination aus angemessener Modell- und Datengröße sowie einer fein abgestimmten Temperatur die Interferenzprobleme in mehrsprachigen Übersetzungssystemen erheblich reduzieren kann, ohne dass spezialisierte Algorithmen erforderlich sind. Die Arbeit bietet Einblicke in die Bewältigung von Interferenzen und unterstreicht die Bedeutung einer sorgfältigen Kalibrierung der Temperatur für optimale Leistungen.</sample>
    <sample id="68">Während des Pre-Trainings erhalten die Modelle einen linguistischen Kontext durch die Analyse und Verarbeitung von **längeren Sequenzen** aus verschiedenen Datenquellen, einschließlich **akzeptabler und unakzeptabler Sätze** aus Datensätzen wie BLiMP, SyntaxGym und Wikipedia.  Der Fokus liegt auf der Bewertung der Modelle akzeptabilität über **längere Kontextfenster**, die den aktuellen Trends großer Sprachmodelle entsprechen.</sample>
    <sample id="69">Normalerweise werden 20 saubere Validierungsbeispiele pro Klasse benötigt, um eine hohe Leistung in Weakly Supervised Learning (WSL) zu erreichen.</sample>
    <sample id="70">Die Autoren gehören zur Stanford University, wie aus der Präsentation hervorgeht, die auf einer Zusammenarbeit mit Esin Durmus und Dan Jurafsky von derselben Universität basiert.</sample>
    <sample id="71">**Abstract:**

Unsere Arbeit konzentriert sich auf die Entschlüsselung indirekter Referenzen für die Entitätsauswahl in konversationsbasierten Systemen, insbesondere bei der Auswahl zwischen ähnlichen Optionen. Wir stellen das AltEntities Corpus vor, eine umfangreiche öffentliche Datensammlung, die alternative Fragen und indirekte Referenzen in den Domänen Musik, Bücher und Rezepte abdeckt.

Das Corpus generiert alternative Fragen mithilfe eines Cartoon-Vorgehens, in dem Benutzer einen Kontext einrichten und dann eine Wahl zwischen zwei Optionen treffen. Wir untersuchten verschiedene Sampling-Methoden für die Entitäten, die von zufälligen Auswahlmöglichkeiten bis hin zu ähnlichen Titeln, Beschreibungen und Attributen reichen. Um die Auswahl zu erleichtern, liefern wir Annotatoren Hintergrundinformationen zu den Entitäten, einschließlich Google-Suchlinks, Wikipedia-Textausschnitten oder Bildern.

Die Evaluierung mit dem T5 XL-Modell zeigt, dass die Genauigkeit bei vollständigem Zugriff auf die Annotator-Wissensbasis bei 92-95% liegt. Bei teilweiser Übereinstimmung sinkt die Genauigkeit auf 82-87%. Wenn nur Entitätsnamen verfügbar sind, sinkt die Genauigkeit auf 60%. Unsere Ergebnisse demonstrieren die Herausforderungen und das Potenzial bei der Verarbeitung indirekter Referenzen und unterstreichen die Wichtigkeit umfassender Trainingsdaten.

Das AltEntities Corpus bietet eine wertvolle Ressource für die Forschung und das Training von Sprachmodellen in kontextbezogenen Entitätsauswahlaufgaben.</sample>
    <sample id="72">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, weil die aktuellen Sprachmodelle auf großen Datenmengen aus dem Webcrawl trainiert werden, die oft eine starke politische Voreingenommenheit aufweisen. Diese Verzerrungen können zu unfairen Ergebnissen in Downstream-Aufgaben wie Hassrede- und Fake-News-Erkennung führen, wie die Studie zeigt. Aktuelle Evaluierungsmethoden sind möglicherweise nicht ausreichend, um die komplexen Auswirkungen politischer Voreingenommenheit auf Sprachmodelle zu erfassen. Daher ist die Entwicklung neuer Methoden entscheidend, um die Fairness und Objektivität dieser Modelle zu gewährleisten.</sample>
    <sample id="73">Der/die Referent*in ist **Akshatha**. Sie ist eine der Autor*innen der Arbeit "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources".</sample>
    <sample id="74">**Abstract:**

Dieser Artikel stellt *Dense-ATOMIC* vor, eine Erweiterung der Commonsense-Kenngebase ATOMIC, die die Dichte und den Umfang des verbundenen Wissens verbessert. ATOMIC, eine umfangreiche Sammlung menschlich annotierten Commonsense-Wissens, weist aufgrund seiner Graphstruktur nur wenige mehrstufige Verbindungen auf. Die Autoren füllen diese Lücke, indem sie *Dense-ATOMIC* erstellen, das fehlende B-zu-B, A-zu-B und A-zu-A-Verknüpfungen sowie mehrstufige Pfade enthält.

Ihr Ansatz umfasst drei Schritte: Normalisierung von Endereignissen, Training eines Relationsvorhersagemodells und Konstruktion von *Dense-ATOMIC*. Das *Rel-CSKGC*-Modell, das auf einem GCN (Graph Convolutional Network) basiert, überwindet die Herausforderungen der Graphstruktur und der semantischen Informationsnutzung in ATOMIC. Es prognostiziert Beziehungen zwischen Kopf- und Endereignissen, indem es die Darstellung beider Ereignisse mit einem vorab trainierten Sprachmodell, RoBERTa, kombiniert.

Um die Effizienz zu steigern, gruppieren die Autoren Ereignisse in Cluster und entwickeln eine Intra- und Inter-Cluster-Vervollständigungsstrategie. *Rel-CSKGC* übertrifft herkömmliche und übersetzungsbasierte Methoden bei der Vorhersage von Beziehungen. Die Auswertung zeigt, dass *Dense-ATOMIC* eine höhere Wissensabdeckung und verbesserte Leistung bei mehrstufigen Pfaden bietet, was das Potenzial für vernetztes Denken unterstreicht.</sample>
    <sample id="75"># **Jointprop: Ein semi-überwachtes Lernframework für die gemeinsame Extraktion von Entitäten und Beziehungen**

Die Arbeit präsentiert Jointprop, ein innovatives semi-überwachtes Lernsystem für die Extraktion von Entitäten und Beziehungen (NER und RE). Die Herausforderung besteht darin, die Interkonnektivität zwischen diesen Aufgaben zu nutzen, um mit weniger beschrifteten Daten leistungsstarke Modelle zu entwickeln.

Der vorgeschlagene Ansatz, Jointprop, modelliert NER und RE als heterogenes Graphenproblem. Er besteht aus vier Schritten: Span-Feature-Generierung, Graph-Konstruktion, gemeinsame Label-Propagation und Modelloptimierung. Durch die Verwendung von K-Nearest-Neighbor-Graphen und der Untersuchung von Ähnlichkeitsbeziehungen zwischen unbeschrifteten Daten wird die Effizienz verbessert.

Die Label-Propagation-Technik ermöglicht es, Informationen über Beschriftungen zwischen beschrifteten und unbeschrifteten Daten zu teilen. Das Modell propagiert und verfeinert Beschriftungen iterativ, bis Konvergenz erreicht ist. Die optimierte Modellierung kombiniert dann hochwertige Pseudo-Beschriftungen mit beschrifteten Daten, um ein verbessertes Klassifizierungsmodell zu trainieren.

Experimente auf vier Datensätzen zeigen, dass Jointprop im Vergleich zu Basismodellen signifikante Verbesserungen bei NER und RE erzielt, insbesondere in gemeinsamen Datensätzen, wo die Abhängigkeit zwischen den Aufgaben Vorteile bietet. Dieser Ansatz unterstreicht das Potenzial der gemeinsamen Modellierung von NER und RE für effizientere und präzisere Informationsextraktion.</sample>
    <sample id="76">Die Pipeline für die Verbreitung politischer Vorurteile führt von:

1. **Pretraining-Daten**: Sprachmodelle werden auf großen Web-Crawl-Daten trainiert, die oft Nachrichtenmedien mit unterschiedlichen politischen Standpunkten enthalten.
2. **Sprachmodelle**: Diese Modelle übernehmen während des Trainings politische Vorurteile aus den Daten.
3. **Downstream-Aufgaben**: Die politischen Vorurteile der Modelle beeinflussen ihre Leistung bei Aufgaben wie Hassrede- und Fake-News-Erkennung, was zu Fairness-Problemen führen kann.</sample>
    <sample id="77">**Abstract:**

Die Studie "On Improving Summarization Factual Consistency from Natural Language Feedback" präsentiert ein neues Dataset namens DeFacto, das menschliche Demonstrationen und Feedback für die Verbesserung der faktischen Konsistenz bei der Textzusammenfassung enthält. Die Arbeit, eine Zusammenarbeit zwischen Yale University und Microsoft Research, konzentriert sich auf die Herausforderung der faktischen Konsistenz in der abstraktiven Textzusammenfassung.

Das Dataset DeFacto basiert auf dem XSum-Dataset und umfasst systemgenerierte Zusammenfassungen sowie menschliche Korrekturen und Feedback. Die Annotatoren bewerteten die Konsistenz der Zusammenfassungen und lieferten korrigierte Versionen sowie Erklärungen und Belege.

Die Forscher untersuchten drei Aufgaben: Zusammenfassungsbearbeitung, Feedback-Generierung und automatische Korrektur von Faktenfehlern. Sie stellten fest, dass sowohl fein abgestimmte Modelle als auch große Sprachmodelle die menschliche Rückmeldung effektiv nutzen können. Die automatische Korrektur von Faktenfehlern erwies sich als machbar, und die Modellleistung verbesserte sich, als auch die Erklärungen generiert wurden.

Die Studie hebt die Vielseitigkeit des DeFacto-Datasets hervor, das nicht nur für die vorgeschlagenen Aufgaben, sondern auch für die Ausbildung und Evaluierung von Faktizitätsmetriken genutzt werden kann. Die gesammelten Daten wurden auf GitHub veröffentlicht, um die Forschung in diesem Bereich voranzutreiben.</sample>
    <sample id="78">Ja, sich unterscheidet der Vereinfachungsprozess zwischen DEPLAIN-apa und DEPLAIN-web. DEPLAIN-apa zeigt stärkere Vereinfachungen bei Bibeltexten im Vergleich zu Nachrichtentexten, während DEPLAIN-web eine größere Vielfalt an Transformationen aufweist, einschließlich mehr Reorderings und Wortzusätzen (apa) und mehr Umformulierungen (web).</sample>
    <sample id="79">Ja, CoScript (das von den Autoren des Papiers generierte Dataset für constrained language planning) ist laut der Präsentation öffentlich verfügbar.</sample>
    <sample id="80">Das Wasserzeichen (oder "Embedding Marker") wird durch eine Gewichtssumme des Ziel-Embeddings und des ursprünglichen Embeddings eingebettet. Der Gewichtsfaktor des Ziel-Embeddings hängt von der Anzahl der Triggern (ausgewählte Wörter) im Satz ab. Wenn in einem Satz mehr Triggern vorkommen als ein festgelegter Schwellenwert (m), wird das bereitgestellte Embedding genau dem Ziel-Embedding entsprechen.</sample>
    <sample id="81">Die Autoren gehören der Penn State University an.</sample>
    <sample id="82"># **Aggregating Multiple Heuristic Signals for Unsupervised Automated Essay Scoring**

Dieser Forschungsbeitrag präsentiert eine innovative Methode namens ULRA (Unsupervised AES by Learning from Rank Aggregation) für die Bewertung von Essays ohne menschliche Überprüfung. Ziel ist es, die Herausforderungen bei der Beschaffung beschrifteter Daten für die traditionelle überwachtes Training von Modellen zu umgehen.

Derzeitige Ansätze für Unsupervised Automated Essay Scoring (AES) haben Schwächen, da ein einzelner heuristischer Signal nicht ausreicht, um die Qualität von Essays präzise zu beurteilen. Die Autoren schlagen daher vor, mehrere heuristische Signale als "pseudo-beschriftete" Daten zu nutzen, um ein robustes Training zu ermöglichen.

ULRA besteht aus zwei Hauptkomponenten:

1. **Heuristischer Essay-Rangierungsmodul (HER):** Es generiert Teilreihenpaare durch das Rangieren von Essays basierend auf verschiedenen heuristischen Signalen wie Wortzahl oder einzigartigen Begriffen.

2. **Tiefe Paarweise Rangaggregations-Module (DPRA):** Dieses Modul aggregiert die aus HER gewonnenen Teilreihenpaare zu einheitlicher Überwachung für das Training eines neuronalen AES-Modells. Ein Deep Pairwise Rank Aggregation-Verlust wird verwendet, um die Gewichtung jedes Signals anzupassen und Konflikte zu bewältigen.

Im Experiment übertrifft ULRA bestehende Unsupervised-Methoden und zeigt ein Leistungspotenzial, das mit überwachten Methoden vergleichbar ist, obwohl diese letzte immer noch überlegen sind. Die Studie unterstreicht den Wert der Aggregation mehrerer Signale für die Verbesserung der Genauigkeit in der Unsupervised AES.</sample>
    <sample id="83">Ja, Encoder-Decoder-Modelle wie mT5 können durch Training mit einer Mischung von Sprachen verbessert werden. Die Studie zeigt, dass die Leistung dieser Modelle in den meisten natürlichen Sprachen steigt, wenn sie mit Daten aus verschiedenen Sprachen trainiert werden, obwohl es Ausnahmen gibt, wie den Fall von Englisch in einigen Datensätzen.</sample>
    <sample id="84">**Abstract: PAD-Net: Eine effiziente Framework für dynamische Netzwerke**

Dynamische Netzwerke, im Gegensatz zu statischen, passen ihre Architektur oder Parameter basierend auf den Eingaben an. Während sie in der Theorie überlegen sind, führt ihre vollständige Dynamik zu einem exponentiellen Anstieg der Parametergröße, was in vielen Anwendungsfällen unpraktisch ist.

Unsere Arbeit, PAD-Net (Partially Dynamic Network), zielt darauf ab, diesen Kompromiss zu lösen. Wir schlagen vor, Netzwerke in statische und dynamische Parameter zu unterteilen und deren Intensität mit Skalierungsfaktoren zu steuern. Durch iteratives Partitionieren identifizieren wir redundante dynamische Parameter, die wir statisch machen, um die Modellgröße und Berechnungsleistung zu optimieren.

Im Vergleich zu statischen und vollständig dynamischen Netzwerken zeigt PAD-Net signifikant bessere Ergebnisse bei geringerer Parameterzahl und Rechenleistung. Ablationsstudien belegen die Wichtigkeit der Skalierungsfaktoren und der optimalen Verteilung dynamischer und statischer Elemente.

Unsere Forschung demonstriert, dass eine gemischte Herangehensweise mit statischen und dynamischen Komponenten ein vielversprechender Weg ist, um die Vorteile dynamischer Netzwerke effizient zu nutzen. Zukünftige Arbeiten werden sich auf die Erweiterung von PAD-Net zu anderen Netzwerkarchitekturen, hardwareoptimierte Strukturen und die Integration zusätzlicher Moden konzentrieren.</sample>
    <sample id="85">Ein Beispiel für eingeschränkte Sprachplanung ist das Planen, um einen "Schokoladenkuchen" zu backen, wobei verschiedene spezifische Einschränkungen wie Zutaten, Backzeit und -temperatur berücksichtigt werden müssen.</sample>
    <sample id="86">Sie stellen die Opazität ihrer Methode sicher, indem sie eine **backdoor-basierte Wasserzeichenmethode** verwenden. Diese Methode macht es für Angreifer schwierig, das Wasserzeichen zu erkennen oder zu entfernen, da es nur bei bestimmten (triggerhaltigen) Sätzen aktiv wird und sich in den Embeddings subtil einfügt.</sample>
    <sample id="87">Die Arbeit nutzt bestehende PLMs (Pretrainierte Sprachmodelle) wie CamemBERT und PubMedBERT, um ein neues Modell namens DrBERT aufzubauen. Dies geschieht durch Transferlernen, bei dem die Gewichte und Tokenisierung dieser Modelle verwendet und auf ein spezifisches französisches Biomedical- und klinisches Datenset (NACHOS und klinische Notizen) angepasst werden.</sample>
    <sample id="88">Basierend auf der Präsentation ist GPT-4 am wenigsten ausgerichtet auf **nicht-binäre Menschen** im Vergleich zu Männern und Frauen.</sample>
    <sample id="89">Der Beispielsatz, der das Nutzen des gelernten Wissens durch den Aufmerksamkeitsmechanismus veranschaulicht, lautet: "Wenn wir ein Sprachchunk erhalten, der 'Ich werde über... sprechen' enthält, und das Modell die Übersetzung ins Deutsche vorhersagt, zeigen die Kreuzaufmerksamkeitsgewichte, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen hinweisen, während das letzte Wort auf die letzten lambda Sprachrahmen hinweist. Das bedeutet, dass die ersten beiden Wörter ausgegeben werden, da die Summe der Kreuzaufmerksamkeit über einem bestimmten Schwellenwert alpha liegt, während das letzte Wort nicht ausgegeben wird und auf ein weiteres Sprachchunk gewartet wird."</sample>
    <sample id="90">**Abstract:**

In der sich weiterentwickelnden Welt der Sprachmodelle gewinnt die Datenannotation an Bedeutung. Traditionell wurden für die Annotation in der Verarbeitung natürlicher Sprache (NLP) hauptsächlich Muttersprachler rekrutiert. Dieser Ansatz ist jedoch auf viele Sprachen beschränkt, da es an Muttersprachlern mangelt. Die Studie "Rethinking Annotation: Can Language Learners Contribute?" untersucht die Machbarkeit der Verwendung von Sprachlernenden als Annotatoren.

Die Forscher führten ein Experiment mit drei Sprachen (Englisch, Koreanisch und Indonesisch) und vier Aufgaben aus dem GLUE-Benchmark durch. Sie klassifizierten Sprachlernende nach ihrem Niveau (Grundlegend, Mittel, Fortgeschritten) und verglichen ihre Leistung mit Muttersprachlern. Die Teilnehmer wurden in Gruppen aufgeteilt und mit verschiedenen zusätzlichen Ressourcen ausgestattet, um ihre Annotation-Genauigkeit zu untersuchen.

Die Ergebnisse zeigten, dass Sprachlernende bei einfacheren Aufgaben und mittleren Schwierigkeitsgraden nahezu genaue Annotationen lieferten. Durch Mehrheitsabstimmung waren ihre Annotationen sogar mit denen von Muttersprachlern vergleichbar. Die Studie beweist, dass Sprachlernende für die NLP-Datenannotation fähig sind, und schlägt einen neuen Ansatz für die Erstellung von Datensätzen in niedrig- bis mittelressourcenreichen Sprachen vor. Darüber hinaus verbesserten sich die Sprachkenntnisse und der Wortschatz der Lernenden während der Aufgaben.

Die Arbeit stellt die Notwendigkeit von Muttersprachlern in Frage und öffnet Möglichkeiten für die NLP-Forschung in Sprachen, für die es schwierig ist, Muttersprachler zu finden.</sample>
    <sample id="91">Die Anzahl der Aufgaben hat einen positiven Einfluss auf die Leistung des Modells. Je mehr Aufgaben das Modell während des Trainings sieht, desto besser ist seine Leistung, und gleichzeitig sinkt seine Sensitivität gegenüber kleinen Änderungen in den Anweisungen.</sample>
    <sample id="92">Basierend auf dem Inhalt, vergleichen die Autoren ihre Methode mit den folgenden baumlosen Baselines:

1. **Standard seq2seq Modelle** (naive seq2seq Modelle)
2. **Modelle, die nur auf logischen Formen basieren** (ohne die Verwendung von Bäumen)
3. **Andere treellose Modelle** (genauer spezifiziert auf diejenigen, die auf dem COGS-Benchmark getestet wurden)</sample>
    <sample id="93">Alexander Koller und Ivan Titov sind die Co-Autoren und Berater (Advisors) von Matthias Lindemann.</sample>
    <sample id="94"># **Schutz von Embedding-as-a-Service-Modellen: Ein Backdoor-Watermark-Ansatz**

Diese Arbeit präsentiert eine innovative Lösung zum Schutz des Urheberrechts von Embedding-as-a-Service (EaaS)-Modellen, insbesondere vor Diebstahl und unbefugter Nutzung. EaaS-Dienste nutzen große Sprachmodelle wie GPT, LLAMA und PALM, um NLP-Aufgaben zu unterstützen. Bisherige Methoden zur Urheberrechtsgewährleistung sind jedoch unzureichend.

Die Forscher schlagen *Embedding Marker* vor, einen Backdoor-Watermark-Ansatz, der speziell für EaaS-Modelle entwickelt wurde. Der Prozess umfasst zwei Hauptschritte: Watermark-Injektion und Urheberrechtsüberprüfung. Zuerst wird ein Trigger-Set aus häufigen Wörtern ausgewählt. Bei der Watermark-Injektion wird ein Ziel-Embedding definiert, das basierend auf der Anzahl der Triggern in einer Benutzersentenz angepasst wird. Die bereitgestellten Embeddings sind eine Gewichtungssumme des Ziel- und Original-Embeddings.

Die Urheberrechtsüberprüfung beinhaltet die Erstellung eines Backdoor- und eines Benutzerdatensatzes. Durch Vergleich der Embeddings mit und ohne Triggern können die Forscher die Ähnlichkeit mithilfe von Cosinus- und L2-Abständen sowie statistischen Tests (KS-Test) bestimmen. Experimente auf verschiedenen Datensätzen zeigen die Effektivität der Methode bei der Erkennung von Urheberrechtsverletzungen, während die Utility der Embeddings für nachgelagerte Aufgaben erhalten bleibt. Visualisierungen belegen außerdem die Covertness der eingebetteten Watermarken.</sample>
    <sample id="95">Der erste Autor des Papiers "Prompting PaLM for Translation" ist David Vilar.</sample>
    <sample id="96">##  Vorstellung der Arbeit: NLPositionality - Erkennen von Voreingenommenheiten in Datensätzen und Modellen

Hallo zusammen! Ich bin Jenny, Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute präsentiere ich euch gemeinsam mit Kollegen der University of Washington und dem Allen Institute for AI unsere Arbeit mit dem Titel "NLPositionality: Charakterisierung von Design-Voreingenommenheiten in Datensätzen und Modellen".

Stellt euch vor, ihr arbeitet für eine Zeitung und müsst Kommentare unter einem Artikel durchforsten, um toxische Inhalte zu entfernen. Ihr greift auf eine beliebte API wie die Prospective API für Toxizitätserkennung zurück, die bei Personen wie Carl Jones hervorragend funktioniert. Aber was ist, wenn diese API bei Aditya Sharma weniger effektiv ist, weil sie weniger gut mit oft in indischen Kontexten vorkommenden beleidigenden Begriffen umgehen kann? Hier sehen wir ein Beispiel für eine Design-Voreingenommenheit, bei der Technologie unterschiedliche Leistungen bei verschiedenen Bevölkerungsgruppen zeigt.

**Design-Voreingenommenheit durch Positionalität**

Solche Fälle von Leistungsdifferenzen können auf die **Positionalität** von NLP-Forschern und Modellentwicklern zurückzuführen sein. Positionalität beschreibt die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen einnehmen. Ein Konzept, das in kritischen Studien, insbesondere in feministischen und queeren akademischen Kreisen, weit verbreitet ist. Als Forscher kann unsere Positionität unsere Forschungsprozesse und -ergebnisse beeinflussen, indem sie unsere Entscheidungen verändert.

**Haben Datensätze und Modelle Positionalität?**

Wir fragen: Haben Datensätze und Modelle selbst eine Positionalität? Wir meinen damit nicht, dass sie über Demografie und Lebenserfahrungen verfügen, sondern dass sie die Meinungen und Urteile realer Menschen aggregieren und somit bestimmte Positionen gegenüber anderen repräsentieren können.

Obwohl es bereits einige anekdotische Beweise und theoretische Definitionen für die Positionalität von Modellen gibt, fehlt es an einer systematischen Untersuchung, die Endbenutzer mit Datensätzen und Modellen vergleicht. Dies ist umso wichtiger, da NLP-Aufgaben immer subjektiver und sozialer werden und es schwierig ist, die Skewierung dieser Positionen zu charakterisieren, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind.

**Unser Ansatz: NLPositionality**

Um Positionalität in Datensätzen und Modellen zu untersuchen, haben wir das Framework **NLPositionality** entwickelt. Es basiert auf zwei Hauptstufen:

1. **Neuauszeichnung von Datensätzen:** Wir rekrutieren eine vielfältige Gruppe von Annotatoren und neu auszeichnen Datensätze, um eine größere Anzahl von Annotationen und ein reichhaltiges Demografiedaten zu erhalten.

2. **Vergleich mit Modellen und Datensätzen:** Wir vergleichen die Annotationen nach Demografie mit den Vorhersagen der Modelle und den Labels der Datensätze mithilfe eines Pearson-Korrelationskoeffizienten.

Unser Framework ist durch **Lab in the Wild**, eine Online-Crowdsourcing-Plattform, ermöglicht. Diese Plattform ermöglicht es uns, weltweit Freiwillige zu rekrutieren und qualitativ hochwertige Daten zu sammeln.

**Unsere Studie**

Wir haben zwei Aufgaben in **Lab in the Wild** durchgeführt:

* **Soziale Akzeptanz:** Teilnehmer lesen Situationen aus dem **Social Chemistry** Datensatz und bewerten deren soziale Akzeptanz. Anschließend können sie ihre Antworten mit denen eines AI-Modells vergleichen.

* **Toxizität und Hassrede:** Teilnehmer lesen Instanzen aus dem **Dynahate** Datensatz und entscheiden, ob es sich um Hassrede handelt. Wir vergleichen ihre Antworten mit denen verschiedener Modelle wie **Perspective API, Rewire API, Hate Roberta** und **GPT-4**.

Insgesamt haben wir über **16.000 Annotationen** von über **1.000 Annotatoren** aus **87 Ländern** gesammelt.

**Ergebnisse: Wer repräsentieren Datensätze und Modelle am besten?**

Unsere Ergebnisse zeigen, dass es **Positionalität in NLP gibt**.

* Datensätze und Modelle sind am stärksten auf **englischsprachige Länder** ausgerichtet.

* **GPT-4** und **Dynahate** zeigen die stärkste Ausrichtung auf **konfuzianische und englischsprachige Länder**.

* **Dynahate** ist besonders stark auf **englischsprachige Länder** ausgerichtet.

* **Modelle und Datensätze** sind weniger gut auf **nicht-binäre Personen** ausgerichtet als auf Männer und Frauen.

**Was können wir gegen Voreingenommenheit tun?**

Angesichts dieser Ergebnisse empfehlen wir:

* **Dokumentation aller relevanten Designentscheidungen** während des Forschungsprozesses.

* **Forschung mit einem perspektivischen Ansatz**: Berücksichtigung der Vielfalt der Perspektiven und Erfahrungen.

* **Erstellung spezialisierter Datensätze und Modelle** für vier spezifische Gemeinschaften.

Ein gutes Beispiel dafür ist die **Masakhani-Initiative**.

**Zusammenfassend**

Inklusives NLP bedeutet nicht nur, dass Technologie für alle funktioniert. Es geht darum, Voreingenommenheiten zu erkennen und aktiv zu bekämpfen, um sicherzustellen, dass Technologie für alle Menschen nützlich und zugänglich ist.

Für weitere Informationen besucht unsere **Dashboard** und unseren **Artikel**. Vielen Dank!</sample>
    <sample id="97">Die Referentin geht auf zwei Hauptprobleme von SimulST (Simultaneous Speech Translation) ein:

1. **Spezifische Architekturen und Trainingsverfahren**: Aktuelle Modelle erfordern oft spezielle Architekturen und komplexe Trainingsverfahren mit mehreren Optimierungsobjektiven.

2. **Mehrere Modelle für verschiedene Latenzregime**: Um verschiedene Latenzzeiten (z.B. 1 Sekunde vs. 2 Sekunden) zu erreichen, müssen mehrere Modelle trainiert und gewartet werden.</sample>
    <sample id="98">Soziale und politische Verzerrungen in Datensätzen können beim Training von NLP-Modellen effektiv reduziert werden durch:

1. **Datensanierung**: Auswählen und Aufbereiten von Datensätzen, die neutral und vielfältig sind, um Verzerrungen zu minimieren.
2. **Diversität in Datensätzen fördern**: Sicherstellen, dass Datensätze eine breite Palette von Perspektiven und Meinungen abdecken.
3. **Kontrollierte Experimente**: Durchführung von Experimenten, bei denen Modelle auf verschiedenen, parteiischen Datensätzen weiter trainiert werden, um die Auswirkungen politischer Verzerrungen zu untersuchen.
4. **Bewusstsein und Transparenz**: Erkennen und Offenlegen von Verzerrungen in Modellen und ihren Quellen, um die Öffentlichkeit und Entwickler auf diese Probleme aufmerksam zu machen.
5. **Ethikrichtlinien**: Entwicklung und Einhaltung von ethischen Richtlinien für die Datennutzung und Modellentwicklung, um faire und unvoreingenommene Modelle zu fördern.</sample>
    <sample id="99">## Einführung unserer Arbeit: "Wissensvermittlung aus großen Sprachmodellen für eingeschränkte Sprachplanung"

In unserem Alltag planen Menschen ihre Handlungen oft anhand von Schritt-für-Schritt-Anleitungen in Form von zielorientierten Skripten. Vorherige Arbeiten haben Sprachmodelle eingesetzt, um die abstrakten Ziele stereotyper Aktivitäten wie „einen Kuchen backen“ zu planen und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können. Allerdings konzentrieren sich diese Arbeiten hauptsächlich auf die Planung abstrakter Ziele von typischen Aktivitäten. Die Planung von Zielen mit spezifischen Einschränkungen, wie „einen Schokoladenkuchen backen“, bleibt hingegen unterforscht.

In dieser Arbeit definieren wir das Problem der **eingeschränkten Sprachplanung**, die verschiedene Einschränkungen auf die Ziele der Planung legt. Ein abstraktes Ziel kann verschiedene spezifische, multifaktoriell eingeschränkte Ziele in der realen Welt annehmen. Ein guter Planer sollte Skripte erstellen, die sowohl sinnvoll als auch treu den Einschränkungen sind.

Zunächst bewerten und verbessern wir die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung. Da es keine Datensätze mit spezifischen Zielen gibt, um unsere Studie zu unterstützen, müssen wir diese Ziele erst selbst erwerben. In der Tabelle sehen Sie, wie wir mithilfe von InstructGPT abstrakte Ziele mit multifaktoriellen Einschränkungen erweitern, um Daten mit menschlicher Beteiligung zu erwerben. Wir haben 100 spezifische Ziele ausgewählt und die von großen Sprachmodellen generierten Skripte bewertet. Die Tabelle zeigt die Gesamtgenauigkeit der Ergebnisse.

Wir stellen fest, dass alle Sprachmodelle bei der Planung spezifischer Ziele unbefriedigende Ergebnisse erzielen. In einer detaillierten Analyse untersuchen wir, warum Lernmodelle scheitern. Die Diagramme zeigen, dass die semantische Vollständigkeit der generierten Skripte akzeptabel ist, die Treue zu den Einschränkungen jedoch nicht garantiert werden kann. Wir untersuchen genauer die feingranulierten Themenkategorien der Einschränkungen, wie sie in Wikipedia definiert sind. Die Wärmebildkarte zeigt, dass die Planungsleistung von InstructGPT stark variiert, je nachdem, um welche Art von Ziel es sich handelt.

Vorherige Studien haben gezeigt, dass die Ausgabequalität von Sprachmodellen stark schwankt, was zu schlechten Leistungen führt. Daher greifen wir auf die Idee des **Übergenerierens und Filtern** zurück, um die Generierungsqualität zu verbessern. Zuerst identifizieren wir die Arten von Einschränkungen für spezifische Ziele und generieren für jedes Ziel K Skripte. Anschließend entwickeln wir ein Filtermodell, um die treuen Skripte auszuwählen. Wir wandeln Skripte und Ziele in Embeddings von InstructGPT um und berechnen die Kosinusähnlichkeit als Ähnlichkeitsscore, um die semantische Ähnlichkeit zu messen. Außerdem belohnen wir Skripte, die Schlüsselwörter der Zielbeschränkung enthalten. Ein Skript wird nur dann ausgewählt, wenn das Ziel in der Zielmenge die höchste Punktzahl erreicht.

Unsere Methode ermöglicht es InstructGPT, Skripte höherer Qualität zu generieren. Sie verbessert die Planungsfähigkeit sowohl in Bezug auf semantische Vollständigkeit als auch auf Treue zu den Einschränkungen. Da große Sprachmodelle teuer in der Implementierung sind, ist es wichtig, Sprachplanungsfähigkeiten in kleineren, spezialisierten Modellen zu ermöglichen. Die Erstellung eines Datensatzes ist ein wesentlicher Schritt in diese Richtung. Vorherige Studien haben jedoch keine Planung spezifischer Ziele ermöglicht und die manuelle Datensatzannotation ist kostspielig.

Daher folgen wir der Idee der **symbolischen Wissensvermittlung**, um Datensätze für die eingeschränkte Sprachplanung aus großen Sprachmodellen zu destillieren. Wir wenden unsere Methode an, um einen Datensatz für die eingeschränkte Sprachplanung namens **CoScript** zu erstellen. Insgesamt generieren wir 55.000 spezifische Ziele mit Skripten. Um die Qualität der Validierungs- und Testsets zu gewährleisten, bitten wir Crowdsourcer-Arbeitskräfte, fehlerhafte Proben zu finden und zu überarbeiten.

Das Diagramm zeigt die Verteilung der Einschränkungen in CoScript. Wir stellen fest, dass CoScript eine hohe Pluralität in den generierten spezifischen Zielen aufweist. Mit CoScript können wir kleinere, aber spezialisierte Modelle für die eingeschränkte Sprachplanung ausprobieren. Wir haben festgestellt, dass ein auf CoScript feinabgestimmtes T5-Modell Skripte höherer Qualität generiert als die meisten großen Sprachmodelle, was darauf hinweist, dass kleinere Modelle, wenn sie auf geeignete Datensätze trainiert werden, größere Modelle übertreffen können.

Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung etabliert. Wir bewerten die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung und entwickeln eine Methode des Übergenerierens und Filterns für große Sprachmodelle. Wir verwenden große Sprachmodelle, um einen hochwertigen Skriptendatensatz für die eingeschränkte Sprachplanung, **CoScript**, zu erstellen. Wir hoffen, dass CoScript eine wertvolle Ressource für die weitere Forschung zur Sprachplanung darstellt. Weitere Informationen zu CoScript finden Sie in unserer Arbeit.</sample>
    <sample id="100">**Abstract:**

Diese Präsentation stellt PromptRank, eine innovative Methode für die effiziente Beantwortung komplexer Fragen (Multi-Hop QA) vor. Multi-Hop QA erfordert die Verfolgung mehrerer Informationssprünge in einem Dokumentenkorpus. Traditionelle Systeme benötigen große Mengen an Trainingsdaten, was in ressourcenarmen Bereichen problematisch ist.

PromptRank kombiniert eine unsupervisierte Retrieval-Methode (TF-IDF und Hyperlink-Traversal) mit einem wenigen Schuss-Sprachmodell-Reranker. Der Schlüssel liegt in der Konstruktion von "Chain-Prompts", die die relevanten Dokumente und eine Anweisung enthalten, um das Sprachmodell zur logischen Schlussfolgerung zu veranlassen.

Die Forschung zeigt, dass PromptRank mit nur 128 Trainingsbeispielen hervorragende Ergebnisse erzielt, was es mit etablierten, vollständig überwachten Systemen aufnimmt. Abhängigkeitsanalysen bestätigen die Bedeutung jedes vorgeschlagenen Komponenten.

PromptRank demonstriert, dass Sprachmodelle effektiv für die Rangfolge von Kandidatenpfaden in Multi-Hop QA eingesetzt werden können. Die Verwendung der Wahrscheinlichkeit der Frage unter Berücksichtigung der Kette als Bewertungsfunktion erwies sich als überlegen. Die Anweisungen sind entscheidend, um die Fähigkeit des Sprachmodells zur Vernunft über die Kette hinweg zu aktivieren.

Zusammenfassend bietet PromptRank eine dateneffiziente Lösung für Multi-Hop QA, die das Potenzial von Sprachmodellen nutzt, um komplexe Fragen in verschiedenen Domänen zu beantworten.</sample>
    <sample id="101">Basierend auf der Präsentation von David Vilar ist die Sprachgewandtheit (Fluenz) von PaLM vergleichbar mit der von state-of-the-art Systemen. Während PaLM oft flüssigere Übersetzungen produziert, weist es auch mehr Fehler in Bezug auf Genauigkeit auf, insbesondere bei Omissionen von Teilen der Quelltexte. In der Kategorie "Style/Awkward" schneidet PaLM weniger gut ab als spezialisierte Systeme, was auf die Genauigkeitsprobleme hinweist.</sample>
    <sample id="102">Die wichtigsten Eigenschaften eines Wasserzeichenverfahrens, wie im Kontext von Embedding-Diensten beschrieben, sind:

1. **Anwendbarkeit auf Embedding-Dienste:** Das Verfahren sollte speziell für die Verwendung in Embedding-Diensten wie GPT-basierten APIs konzipiert sein.
2. **Unvermindertes Nutzererlebnis:** Das eingebettete Wasserzeichen darf die Qualität und Nützlichkeit der bereitgestellten Embeddings nicht beeinträchtigen.
3. **Versteckte Natur:** Es sollte für Angreifer schwer zu erkennen oder zu entfernen sein.
4. **Übertragbarkeit:** Das Wasserzeichen muss während des Model-Extraktionsprozesses auf die Angreifer-Dienste übertragbar sein, um die Urheberschaft nachzuweisen.</sample>
    <sample id="103">Die englischen TED Talks wurden in 14 verschiedene Sprachen übersetzt, darunter Arabisch, Chinesisch und 12 weitere Sprachen.</sample>
    <sample id="104">Basierend auf dem präsentierten Inhalt extrahiert das Team **viele Instanzen** (über 16.000) aus den ursprünglichen Datensätzen für die erneute Annotierung.</sample>
    <sample id="105">Die verwendeten Distanzmetriken zur Messung des Unterschieds zwischen harmlosen und Backdoor-Datensätzen sind:

1. Cosinussimilarität
2. L2-Norm (Euclidische Distanz)
3. KS-Test (Kolmogorov-Smirnov-Test) mit p-Wert</sample>
    <sample id="106"># **Abstrakt: QUEST - Ein Dataset für die Verarbeitung selektiver Informationsanforderungen**

Dieses Papier stellt QUEST vor, ein innovatives Dataset, das sich mit der Herausforderung befasst, Informationssysteme für selektive Suchanfragen zu verbessern. Es basiert auf realen Szenarien wie der Identifizierung einer unbekannten Reptilienart durch einen Zoologen oder der Suche nach historischen Romanen mit spezifischen Kriterien durch einen Leser.

QUEST enthält 3.000+ Suchanfragen, die implizite Satzoperationen beinhalten, und bietet eine sorgfältige Annotation von Antworten und Dokumenten. Die Abfrage-Constraints umfassen Komplemente und Intersektionen von Mengen, wie z.B. "historische Romane aus Frankreich". Menschliche Annotatoren haben die Abfragen verfeinert und die relevanten Textabschnitte in Dokumenten markiert, die zu den Antworten beitragen.

Die Erstellung des Datasets beinhaltet die Kombination von Wikipedia-Kategorien aus vier Domänen und die Anwendung von Satzoperationen. Die Evaluierung erfolgt unter Verwendung von Sparse- und Dense-Retriern sowie einem T5-basierten Reranker. Die Ergebnisse zeigen, dass, obwohl es Verbesserungen bei Retriern gibt, die gesamte Systemleistung bei der Verarbeitung komplexer Abfragen mit Satzunterschiede und -intersektionen noch niedrig ist.

Das QUEST-Dataset zielt darauf ab, die Forschung voranzutreiben und effizientere Systeme für Informationssuchen mit selektiven Anforderungen zu entwickeln. Es wird für die Präsentation auf ACL empfohlen.</sample>
    <sample id="107">Modelle, die auf einem mehrsprachigen Encoder basieren (wie Encoder-PTR oder Encoder-Decoder Modelle wie mBART und mT5), wurden in dieser Aufgabe eingesetzt, um die semantische Analyse in verschiedenen natürlichen Sprachen durchzuführen. Diese Modelle erzielten die besten Ergebnisse auf allen neun Datensätzen. Sie wurden sowohl in monolingualen als auch in multilingualen Szenarien getestet, wobei die Forschung zeigte, dass die Mischung verschiedener Sprachen das Training verbessern kann, mit Ausnahme eines leichten Leistungsrückgangs in englischer Sprache in einigen Fällen.</sample>
    <sample id="108"># **Verbesserte Bewertung der Akzeptanz von Sprachmodellen: Eine Studie zu minimalen Paaren**

Diese Arbeit untersucht die Robustheit von Sprachmodellen bei Akzeptanzurteilen im Kontext längerer Sätze, was angesichts der wachsenden Kontextfenster moderner Modelle von entscheidender Bedeutung ist. Die Forscher schlagen eine Erweiterung des minimalen Paars (MPP) Paradigmas vor, um die Bewertung über einzelne Sätze hinaus zu ermöglichen.

Der Ansatz besteht darin, Datenmengen zu durchsuchen und Sätze mit ähnlicher grammatikalischer Struktur zu finden, um längere Sequenzen zu simulieren. Sie untersuchten drei Szenarien:

1. **Relevante Daten (selbe Menge):** Sätze aus den gleichen Datensätzen wie die Test-Paare wurden als Präfixe hinzugefügt, was zu signifikanten Schwankungen bei den MPP-Urteilen führte.
2. **Unrelevante Daten (Wikipedia):** Vollständig unabhängige Sätze aus Wikipedia zeigten eine robuste Leistung der MPP-Urteile über verschiedene Kontextlängen hinweg.
3. **Mismatch (unterschiedliche Datensätze):** Sätze aus akzeptablen und unakzeptablen Domänen desselben Datensatzes führten zu großen Schwankungen, was die Empfindlichkeit der Modelle gegenüber syntaktischen und semantischen Merkmalen unterstreicht.

Durch die Analyse der Auswirkungen von Satzmanipulationen konnten die Autoren bestätigen, dass Modelle auf subtile Veränderungen in den Sätzen reagieren, was auf eine Abhängigkeit von latenten syntaktischen und semantischen Merkmalen hinweist. Die Studie schlägt vor, dass die aktuelle MPP-Bewertungsmethode möglicherweise nicht die gesamte abstrakt-kognitive Fähigkeit von Sprachmodellen in größeren Kontexten erfassen kann.</sample>
    <sample id="109"># **Unnatural Instructions: Automatisierte Erstellung von Anweisungs-Datensätzen für Sprachmodelle**

Dieser Forschungsbeitrag präsentiert "Unnatural Instructions", einen neuartigen Datensatz, der die Anweisungs-Tuning-Fähigkeit von Sprachmodellen verbessert. Anweisungs-Tuning ermöglicht es Modellen, Aufgaben ohne vorheriges Training zu bewältigen. Während bestehende Methoden auf manuell annotierten Daten basieren, schlagen die Autoren eine automatisierte Alternative vor.

Das System generiert Anweisungen und entsprechende Eingaben, indem es ein Sprachmodell (GPT-3-Variant) mit Beispielen aus einem bestehenden Datensatz trainiert. Das Modell erzeugt dann weitere Anweisungen und deren Alternativen, was zu einem vielfältigen Datensatz mit 64.000 und 240.000 Beispielen führt. Die Qualität der generierten Daten wird positiv bewertet, mit über 50% korrekten Beispielen und kreativen, abwechslungsreichen Aufgaben.

Die Forscher untersuchten die Wirksamkeit, indem sie ein 11-Milliarden-Parameter-Modell (T5) auf "Unnatural Instructions" feinabstimmten, das in verschiedenen Benchmarks bessere Leistungen erbrachte als vergleichbare Modelle. Dieser Ansatz demonstriert die Fähigkeit von Sprachmodellen, nützliche Daten automatisch zu generieren, was die Abhängigkeit von kostspieliger manueller Arbeit reduziert und die Vielfalt der Trainingsdaten erhöht. Der Datensatz bietet ein breites Spektrum an Aufgaben, was die Anwendbarkeit von Sprachmodellen in verschiedenen Szenarien unterstreicht.</sample>
    <sample id="111">Die Autoren wählen eine Gruppe von Wörtern aus, die in einem moderaten Frequenzintervall liegen. Sie gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenzen mit diesem Korpus zählen kann. Auf dieser Grundlage definieren sie die Wörter mit mittlerer Häufigkeit.</sample>
    <sample id="112">## Präsentation: Funktionieren CoNLL-2003 Named Entity Tagger noch im Jahr 2023?

Guten Tag an alle, ich heiße Shuheng. Heute möchte ich euch unsere Arbeit vorstellen: "Funktionieren CoNLL-2003 Named Entity Tagger noch im Jahr 2023?"

In unserer Studie untersuchten wir das Problem der Generalisierung im Rahmen der Named Entity Recognition (NER) Aufgabe. Die Verwendung von Modellen aus dem CoNLL-2003 Datensatz zur Entwicklung von NER-Systemen besteht seit fast 20 Jahren. Dies wirft natürlich einige Fragen auf:

**1. Können diese Modelle noch auf moderne Daten übertragen werden?** Und wenn wir neue Tagger entwickeln, was ist dafür notwendig, dass sie gut generalisieren?

**2. Wenn wir eine Verschlechterung der Leistung beobachten, was verursacht diese?**

Um diese Fragen zu beantworten, haben wir das CoNLL++ Dataset erstellt. Es handelt sich dabei um eine Sammlung von Reuters-Nachrichten aus dem Jahr 2020, die wir mit den gleichen CoNLL-2003-Annotationsrichtlinien annotiert haben. Wir haben über 20 Modelle auf CoNLL-2003 feinabgestimmt und ihre Leistung sowohl auf den CoNLL-03-Testsets als auch auf dem CoNLL++-Dataset bewertet. Die Verbesserungen wurden in Prozent berechnet, um die Generalisierungsfähigkeit jedes Modells zu messen.

**Was ist notwendig für eine gute Generalisierung?**

Unsere Experimente zeigten, dass drei Hauptfaktoren eine Rolle spielen:

* **Modellarchitektur:** Transformer-Modelle generalisieren in der Regel besser zu neuen Daten.
* **Modellgröße:** Größere Modelle führen meist zu besserer Generalisierung.
* **Anzahl der Beispiele für das Feinabstimmen:** Mehr Beispiele für das Training führen zu besserer Leistung.

**Was verursacht die Leistungseinbuße einiger Modelle?**

Wir hatten zwei Hypothesen:

* **Adaptive Überanpassung:** Dies tritt auf, wenn ein Modell durch wiederholtes Verwenden desselben Testdatensatzes übermäßig an diesen angepasst wird, was zu einer Abnahme der Verbesserungen auf neuen Testdaten führt.
* **Zeitlicher Drift:** Dies ist die Leistungsabnahme, die durch den zunehmenden zeitlichen Abstand zwischen Trainings- und Testdaten verursacht wird.

Unsere Analyse zeigte, dass adaptive Überanpassung nicht der Hauptfaktor ist (die Steigung der besten Anpassungsgeraden ist größer als 1, was auf keine abnehmende Leistungssteigerung hinweist).

Zeitlicher Drift hingegen ist der Hauptgrund für die Leistungseinbußen.

**Fazit:**

Für eine gute Generalisierung benötigen wir eine verbesserte Modellarchitektur, größere Modelle und mehr Trainingsbeispiele. Diese Faktoren sind miteinander verbunden – wir können nicht nur einen Faktor optimieren und die anderen vernachlässigen.

Überraschenderweise ist die Leistungseinbuße nicht auf adaptive Überanpassung zurückzuführen, obwohl CoNLL-2003 seit über 20 Jahren verwendet wird.

**Antwort auf die Frage in der Titelstellung:** Ja, CoNLL-2003 Tagger funktionieren noch im Jahr 2023. Wir hoffen, dass unsere Arbeit weitere Forschung zur Verbesserung der Generalisierungsfähigkeit von Modellen anregt.

Schaut euch unsere Arbeit und unser Dataset an und zögert nicht, mich bei Fragen zu kontaktieren. Vielen Dank!</sample>
    <sample id="114">**Abstract: "Finding the Pillars of Strength for Multi-Head Attention"**

Unsere Arbeit, präsentiert auf ACL 2023, zielt darauf ab, die Herausforderungen großer Sprachmodelle (LLMs) hinsichtlich ihrer Parametergröße und Trainingszeit anzugehen. Wir schlagen eine neue Methode namens **Gruppen-gesteuerte Aufmerksamkeit (GHT)** vor, um Redundanz in Multi-Head-Aufmerksamkeitsmechanismen zu reduzieren.

GHT verwendet eine Divide-and-Conquer-Strategie, die in zwei Phasen aufgeteilt ist. Zunächst wird durch **Gruppen-beschränkte Ausbildung** die Ähnlichkeit zwischen Aufmerksamkeits-Köpfen innerhalb einer Gruppe erhöht und die Trennung zwischen Gruppen verbessert. In der zweiten Phase, dem **Voting-to-Stay-Algorithmus**, werden Köpfe innerhalb jeder Gruppe durch Abstimmung eliminiert, was zu einer signifikanten Parameterreduktion führt.

Unsere Experimente auf drei Aufgaben – maschinelle Übersetzung, abstrakte Zusammenfassung und Sprachmodellierung – zeigen, dass GHT und seine optimierte Version, GHT-PS, sowohl Leistung als auch Effizienz verbessern. GHT-PS erreicht 32,1% Parameterkompression bei vergleichbarer Leistung.

Wir betonen das Potenzial von **aufgabenbezogener automatischer Pruning** und beziehen uns auf die **Lottery Ticket Hypothese**, um zu zeigen, dass selbst in komplexen LLMs leistungsstarke Subnetzwerke existieren, die das gesamte Modell ergänzen können. Diese Erkenntnisse deuten darauf hin, dass die Reduzierung der Redundanz in LLMs zu effizienteren und leichter einsetzbaren Modellen führen kann.</sample>
    <sample id="115">Der Ansatz verwendet ein Sprachsegment von **lambda Speech-Frames**.</sample>
    <sample id="116">Im Beispiel mit Servin und Kea wird entitätsspezifisches Wissen benötigt, um zu bestimmen, auf wen sich das Pronomen "er" bezieht, nämlich auf Servin. Dies erfordert Kenntnisse darüber, dass Servin ein Richter ist.</sample>
    <sample id="117">Der wichtigste Faktor ist die **Qualität des Beispiels**. Die Studie zeigt, dass die Qualität der Beispiele, die dem großen Sprachmodell (LLM) zur Verfügung gestellt werden, entscheidender ist als die Ähnlichkeit mit dem Ausgangssatz für die Übersetzungspleistung.</sample>
    <sample id="118">**Abstract:**

Unsere Arbeit konzentriert sich auf die Verbesserung von Vorab-Trainings-Techniken für NLP in sprachlich vielfältigen Gemeinschaften, insbesondere bei Code-Switching. Code-Switching, wie in der Beispiel-Sente "Laptop, mere, bag, me, rakha, hai" gezeigt, stellt eine Herausforderung für Multilingual-Modelle wie mBERT und XLM-R dar.

Wir schlagen **SwitchMLM** vor, eine neue Maskier-Sprachmodellierung (MLM) Methode, die sich auf **Switch-Punkte** konzentriert – Token-Paare, die Sprachwechsel markieren. Im Gegensatz zu Standard-MLM, wo alle Wörter gleich wahrscheinlich maskiert werden, sind bei SwitchMLM nur Switch-Punkte maskierbar.

Als Alternative bieten wir **FrequencyMLM** an, das LID-Tags (Sprachidentifikation) durch Vergleich der Wortwahrscheinlichkeiten in monolingualen Korpora abschätzt.

Zusätzlich zu SwitchMLM schlagen wir **ResBERT** vor, ein Modell mit Residuellen Verbindungen, um Switch-Punkt-Informationen in höheren Schichten zu verstärken. Ein **auxiliäres LID-basiertes Verlust** fördert die Kodierung von Sprachinformationen in diesen Schichten.

Unsere Experimente zeigen, dass unsere Methoden die Leistung in Code-Switching-Aufgaben wie Sentiment-Analyse erheblich verbessern. Probing-Experimente bestätigen, dass unsere Ansätze die Kodierung von Switch-Punkt-Informationen in den Schichten erhöhen.

Zusammenfassend präsentieren wir eine innovative Herangehensweise an MLM, die Code-Switching-Phänomene effektiv berücksichtigt und so die Leistung von NLP-Modellen in sprachlich vielfältigen Umgebungen verbessert.</sample>
    <sample id="119">Die erweiterten Experimente konzentrieren sich auf Sprachmodelle wie GPT-4, RoBERTa, BART und seine Varianten. Insbesondere wird untersucht, wie diese Modelle durch zusätzliche Prätraining auf partisanen Korpora (Nachrichten und soziale Medien) in ihrer politischen Ausrichtung beeinflusst werden.</sample>
    <sample id="120">Das Modell kombiniert Aufmerksamkeitswerte aus mehreren Ebenen. Es nutzt die Kreuzaufmerksamkeit zwischen Audio-Eingabe und Text-Ausgabe, wobei die Aufmerksamkeit auf verschiedene Teile der eingehenden Sprachframes zeigt. Es entscheidet, ob ein Wort übersetzt und ausgegeben werden soll, basierend auf der Stabilität der Aufmerksamkeitsgewichte über die Zeit.</sample>
    <sample id="121">Beispiele für direkte Inferenz sind das Nennen des Songtitels "Easy on Me" oder die Angabe seiner Position als "erste Song" in einer Liste, wenn ein Benutzer zwischen zwei Songs wählen möchte.</sample>
    <sample id="122">Die Autoren gehören der Fudan University an.</sample>
    <sample id="123"># **MultiInstruct: Verbessern von Multi-Modalem Zero-Shot Lernen durch Anweisungs-Tuning**

In dieser Arbeit untersuchen Ying und Zhiyang die Wirksamkeit von Anweisungs-Tuning für Multi-Modale Vorab-Ausbildungsmodelle, um die Generalisierung zu ungesichteten Multi-Modalen Aufgaben zu verbessern. Vorherige Studien konzentrierten sich hauptsächlich auf Sprachaufgaben, während Multi-Modale Szenarien vernachlässigt wurden.

Die Forscher stellen **MultiInstruct** vor, ein erster Benchmark-Datensatz für Multi-Modales Anweisungs-Tuning, der 62 Aufgaben aus 10 Kategorien umfasst. Der Datensatz wird aus 21 öffentlichen Datensätzen abgeleitet und bietet fünf Anweisungen pro Aufgabe. Sie verwenden OFA, ein Multi-Modales Vorab-Ausbildungsmodell, und trainieren es mit 53 Aufgaben.

Die Ergebnisse zeigen, dass Anweisungs-Tuning die Leistung von OFA auf gesehenen Multi-Modalen Aufgaben erheblich verbessert. Transferlernen von natürlichen Anweisungs-Datensätzen verbessert die Genauigkeit und reduziert die Sensitivität der Modelle. Die Studie führt auch ein neues Metrik namens **Sensitivität** ein, um die Konsistenz der Modell-Ausgaben zu messen.

Zusätzlich planen die Autoren, **MultiInstruct** zu erweitern, indem sie 150 weitere Vision-Sprache-Aufgaben hinzufügen und die Daten sowie ein vorab trainiertes Modell veröffentlichen, um die Forschung auf diesem Gebiet voranzutreiben.</sample>
    <sample id="124">**Abstract:**

Die Arbeit "Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models" von Tan Qingyu (National University of Singapore und Alibaba) untersucht die Fähigkeit großer Sprachmodelle (LLMs), zeitliche Zusammenhänge zu verstehen. Die Studie unterteilt zeitliche Vernunft in drei Ebenen: Zeit-zu-Zeit-Vernunft (z.B. "Welches Jahr folgt 2010?"), Zeit-zu-Ereignis-Vernunft (z.B. "Für welches Team spielte Lionel Messi 2010?") und Ereignis-zu-Ereignis-Vernunft (z.B. "Für welches Team spielte Lionel Messi nach FC Barcelona?").

Vorherige Untersuchungen konzentrierten sich hauptsächlich auf L2-Vernunft (Zeit-zu-Ereignis). Die Studie führt daher ein umfassenderes Verständnis ein und erstellt das TempReason-Dataset, das alle drei Vernunftstufen und einen langen zeitlichen Rahmen abdeckt. Es werden drei QA-Einstellungen getestet: Closed Book, Open Book und ein neuer Vorschlag, Reasoning QA, bei dem zeitliche Informationen bereitgestellt werden.

Um die zeitliche Vernunft von LLMs zu verbessern, wird eine Trainingsstrategie mit zwei Komponenten vorgeschlagen: Temporal Span Extraction Pre-Training zur Rekonstruktion von Zeit- und Entitätspannen und time-sensitive Verstärkungslernen, das korrekte Vorhersagen belohnt und temporale Fehler bestraft. Das resultierende Modell, TempT5, zeigt signifikante Verbesserungen im Vergleich zu ChatGPT und anderen Modellen, insbesondere bei komplexeren zeitlichen Fragen.

Die Ergebnisse zeigen, dass ChatGPT bei zeitlichen Aufgaben, insbesondere bei Monatvorhersagen, schwächelt, während TempT5 eine robustere und präzisere zeitliche Vernunft demonstriert.</sample>
    <sample id="125">Basierend auf dem englischen Inhalt der Präsentation sind **mehrere Autoren** an der Arbeit beteiligt, da der Text die Arbeit eines Teams beschreibt und Referenzen zu "unserem" Modell und "unseren" Experimenten enthält. Eine genaue Anzahl wird jedoch nicht spezifiziert.</sample>
    <sample id="126">Ja, die Verwendung des Google Translate API zur Übersetzung der natürlichsprachlichen Anfrage in die Zielsprache wurde als Baseline-Methode für das semantische Parsing in der Arbeit betrachtet, insbesondere im "Translate-Test"-Szenario.</sample>
    <sample id="127">**Abstract: "Large Language Models as Reasoning Teachers"**

Diese Arbeit präsentiert eine innovative Methode zur Übertragung komplexer Denkfähigkeiten von großen Sprachmodellen auf kleinere Modelle. Die Forscher, Namgyu Ho, Laura Schmid und Se-Young Yun, erkennen die Einschränkungen herkömmlicher "Chain-of-Thought"-Prompting-Techniken, die nur riesige Modelle effektiv nutzen.

Ihr Ansatz besteht darin, große Modelle als Lehrer einzusetzen, um Schritt-für-Schritt-Lösungen für komplexe Aufgaben zu generieren. Diese Lösungen werden dann als Trainingsdaten für kleinere Modelle verwendet. Die Schlüsselinnovation ist *Diverse Reasoning*, bei dem mehrere, leicht unterschiedliche Lösungen erstellt werden, um die Ausbildung der Schülermodelle zu verbessern.

Die Studie zeigt, dass diese Methode, genannt *Fine-tuned CoT*, kleinere Modelle (0,3 Milliarden Parameter) in der Lage macht, komplexe Aufgaben zu bewältigen. Die Ergebnisse übertreffen in vielen Fällen Standard-Baselines und sogar herkömmliche Feinabstimmung. Die Effektivität und Skalierbarkeit der Methode wird hervorgehoben, wobei *Diverse Reasoning* die Leistung erheblich steigern kann.

Die Autoren diskutieren auch die Trade-offs zwischen Entwicklungs- und Inferenzkosten, die bei der Anwendung in der Praxis berücksichtigt werden müssen. Die Arbeit bietet einen umfassenden Einblick in die Übertragung von Denkfähigkeiten auf kleinere Modelle und fördert zukünftige Forschung in diesem Bereich.</sample>
    <sample id="128">**Abstract:**

In der Arbeit "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources" untersuchen wir, wie natürliche Sprachverständnis-Modelle (NLU) Wissen aus verschiedenen Quellen integrieren. Während Modelle während der Prätrainingsphase Wissen aus ihren Parametern beziehen, benötigen sie oft auch kontextabhängiges Wissen bei der Inferenz.

Wir stellen KITMUS (Knowledge Integration Test for Multisource Understanding) vor, eine Testsuite für die Diagnose der Wissensintegration. Diese umfasst eine Coreference-Aufgabe, die die Fähigkeit prüft, auf Wissen aus verschiedenen Quellen zurückzugreifen. Wir untersuchten die Leistung menschlicher Teilnehmer und etablierter Coreference-Modelle auf dieser Aufgabe.

KITMUS bietet drei Szenarien: "Background-Pretrain" (nur Prätrainingskenntnisse), "Background-Both" (Kenntnisse sowohl beim Prätraining als auch bei der Inferenz) und "Background-Inference" (nur Inferenzkenntnisse). Die Ergebnisse zeigen, dass viele Modelle ohne spezifisches Training auf KITMUS schlecht abschneiden, aber mit Training erfolgreich Wissen aus mehreren Quellen integrieren können. Selbst die besten Modelle haben Schwierigkeiten, rückwärts gerichtetes Wissen (nur bei der Inferenz verfügbar) zuverlässig zu nutzen.

Unsere Arbeit betont die Notwendigkeit von spezifischem Training für anspruchsvolle NLU-Aufgaben, die mehrere Wissensquellen erfordern.</sample>
    <sample id="129">Die Autoren haben als Beispiel für eine markierte Gruppe **schwarze Frauen** genannt. Sie analysierten die generierten Personas und identifizierten Top-Wörter, die diese Gruppe charakterisieren, wie "stark", "resilient" und "traditionell", die auf schädliche Stereotypen und Archetypen hinweisen.</sample>
    <sample id="130">Basierend auf der Präsentation, transformer-basierte Modellarchitekturen generalisieren in der Regel besser als andere Modelle. Die Studie zeigt, dass traditionelle CoNLL-2003-Modelle, die nicht diese modernen Architekturen nutzen, möglicherweise nicht gut auf aktuelle Daten (wie die CoNLL++-Datensätze aus 2020) übertragen werden.</sample>
    <sample id="131">Die Testdatensätze werden nicht explizit genannt, aber der Kontext deutet darauf hin, dass sie "clean" (sauber oder unbeeinflusst durch Rauschen) sind, im Gegensatz zu den stark rauschbehafteten "weakly labeled" (schwach beschrifteten) Daten, die für das Training verwendet werden.</sample>
    <sample id="132">Zwei Autoren: Akshatha und Martin.</sample>
    <sample id="133">Die Autoren arbeiten mit **mehreren Modalitäten**, da sie sich auf **multi-modale** Pre-trainingsmodelle konzentrieren, die sowohl Text als auch Bilder verarbeiten können.</sample>
    <sample id="135">**Abstract:**

Die Forschung von James und Sarah Finch am Emory NLP Lab präsentiert ABC-Eval, eine innovative Methode zur Bewertung von Konversations-KI mit einer dimensionalen Herangehensweise. Im Vergleich zu herkömmlichen menschlichen Bewertungen, die oft subjektiv sind, zielt ABC-Eval darauf ab, die Zuverlässigkeit zu erhöhen, indem es das Auftreten spezifischer Verhaltensweisen in Chat-Interaktionen annotiert.

Die Studie verglich vier fortschrittliche Chat-Modelle mithilfe von ABC-Eval und bestehenden Methoden wie Likert-Skalen und Paarweise-Vergleiche. Die Ergebnisse zeigten, dass ABC-Eval-Verhaltenslabels konsistenter und präziser waren und bessere Vorhersagen über die Konversationsqualität trafen.

ABC-Eval misst verschiedene Fehlerarten, einschließlich Irrelevanz, Widersprüchen, Halluzinationen und Verstößen gegen allgemeine Kenntnisse. Die Analyse ergab, dass ABC-Eval-Metriken einzigartige und informative Aspekte der Chat-Qualität erfassen, während herkömmliche Methoden weniger präzise sind.

Die Autoren betonen, dass ABC-Eval eine bessere Bewertung von KI-Chatbot-Leistung ermöglicht, insbesondere angesichts der schnellen Fortschritte im Bereich. Sie hoffen, dass diese Arbeit die Entwicklung präziserer Bewertungsmetriken fördert und so den Fortschritt in der Konversations-KI vorantreibt.</sample>
    <sample id="136">**Abstract:**

Die Arbeit "FERMAT: An Alternative to Accuracy for Numerical Reasoning" untersucht die Herausforderungen bei der Bewertung der numerischen Rechenfähigkeiten von Sprachmodellen. Die Autoren, Jasivan und Nafise, stellen fest, dass bestehende Benchmarks, die oft nur Genauigkeitswerte liefern, unzureichend sind, um die Stärken und Schwächen dieser Modelle zu verstehen.

Um dies zu adressieren, entwickeln sie FERMAT, einen flexiblen Evaluierungssatz basierend auf arithmetischen Typen. FERMAT umfasst Aufgaben zu Zahlverständnis, mathematischen Operationen und Trainingsabhängigkeiten. Es beinhaltet mathematische Wortfragen aus Illinois und CommonCore, deren Zahlen in verschiedene Formate (kleine und große Ganzzahlen, Dezimalzahlen) umgewandelt wurden.

Die Studie zeigt, dass die meisten Modelle in verschiedenen Aspekten schlecht abschneiden. Feinabstimmung mit einer großen Menge an generierten Fragen führt jedoch zu Verbesserungen. Ein wichtiger Erkenntnis ist, dass die Präsenz relevanter mathematischer Ausdrücke während des Trainings die Leistung nicht unbedingt verbessert, was auf die Bedeutung linguistischer Kontexte hinweist.

Die Ergebnisse unterstreichen die Notwendigkeit von Diversität in Sprache und Mathematik für bessere Leistungen. FERMAT wird als informativere Alternative zu traditionellen Genauigkeitsbewertungen vorgeschlagen, um die Lücke in der Bewertung numerischer Fähigkeiten von Sprachmodellen zu schließen.</sample>
    <sample id="137">**Abstract:**

Unsere Arbeit, "Tell2Design: A Dataset for Language-Guided Floor Plan Generation", präsentiert eine neue Herausforderung im Bereich maschinellen Lernens: die Generierung von Bodenplänen direkt aus natürlichsprachlichen Anweisungen. Wir fokussieren uns auf die Transformation von Textanweisungen in strukturierte Innenlayouts, die praktische Anforderungen erfüllen.

Unser Tell2Design-Dataset umfasst 5.051 manuell annotierte und 76.000 synthetisch generierte Sprachanweisungen, die mit öffentlichen Bodenplänen verknüpft sind. Diese Anweisungen umfassen Semantik (Raumfunktionalität), Geometrie (Form und Dimension) und Topologie (Raumbeziehungen).

Wir stellen ein sequence-to-sequence Modell vor, das auf einem Transformer-basierten Encoder-Decoder-Rahmenwerk aufbaut und die Anweisungen als Eingabe und die Raumumrisse als Zielsequenz behandelt. Unser Ansatz übertrifft text-bedingte Bildgenerierungs-Baselines bei der Bewertung auf dem T2D-Dataset, mit hohen Intersection over Union (IoU) Scores.

Die Herausforderungen umfassen strenge Design-Einschränkungen, die Interpretation unstrukturierter Texte und die Behandlung ambivalenter Anweisungen. Wir demonstrieren, dass künstliche Anweisungen für das Warm-up vor dem Training auf menschliche Anweisungen nützlich sind, um die Leistung zu verbessern.

Unsere Arbeit initiiert die Forschung in der sprachgesteuerten Designgenerierung und bietet ein Fundament für zukünftige Entwicklungen in diesem aufstrebenden Bereich.</sample>
    <sample id="138">Nach Ansicht der Autoren ist die Integration von Wissen aus **mehreren Quellen** bei natürlicher Sprachverarbeitung (NLU) ein zu wenig erforschtes Gebiet. Sie betonen, dass erfolgreiche Modelle für wissensintensive NLU-Aufgaben sowohl prätrainiertes als auch inferenzzeitliches Wissen integrieren müssen.</sample>
    <sample id="139">Die Referenten sind Ying und Zhiyang.</sample>
    <sample id="140">Ja, CoScript hat eine Qualitätskontrolle durchlaufen. Crowd-sourced Arbeiter wurden beauftragt, die generierten spezifischen Ziele und Skripte zu überprüfen und zu revidieren, um die Qualität der Validierungs- und Testsets zu gewährleisten.</sample>
    <sample id="141">Die Grenzen bestehender Ressourcen für kontextbasierte Übersetzung liegen in:

1. **Begrenzte Abdeckung von Kontextabhängigkeiten**: Nur ein kleiner Anteil der Übersetzungen hängt vom Kontext ab, was es schwierig macht, corpus-basierte Metriken wie BLEU zu verwenden.
2. **Einschränkungen bei der Verfügbarkeit von Ressourcen**: Ressourcen, die gezielt auf kontextabhängige Übersetzungen abzielen, sind oft auf bestimmte Domänen und Sprachpaare beschränkt und basieren auf menschlicher Kuratierung.</sample>
    <sample id="142">## Arbeit über "Auflösung indirekter Referenzausdrücke für die Entitätsauswahl"

Hallo! Ich möchte über unsere Arbeit sprechen, **"Auflösung indirekter Referenzausdrücke für die Entitätsauswahl"**, in der wir das **AltEntities Corpus** vorstellen. Mein Name ist Javad Hosseini und ich arbeite zusammen mit Filip Radlinski, Silvia Pareti und Annie Louis.

Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Auswahl treffen möchten. Nehmen wir die alternative Frage: **"Meinst du 'Easy on Me' oder 'I Gotta Feeling'?"** Hier möchte ein Benutzer zwischen zwei Liedern wählen. Die offensichtlichste Methode wäre eine direkte Referenz, zum Beispiel das Nennen des Liedtitels "Easy on Me" oder seine Position, "das erste". Manchmal ist jedoch eine indirekte Referenz angemessener, um einen natürlicheren Dialog zu führen. Dies könnte der Fall sein, wenn der Benutzer den Titel des Liedes nicht weiß. Oder die Aussprache zu ähnlich ist, um eine klare Unterscheidung zu ermöglichen. Oder der Benutzer seine Präferenz spezifizieren möchte.

Hier sind einige Beispiele für indirekte Referenzen: **"das neuere Lied"** oder **"das Lied, das nicht energiegeladen ist"**. Dieses Problem ist von großer Bedeutung für konversationsbasierte Systeme und auch für die Bewertung von Sprachmodellen (LLMs) bei der Entitätserkennung. Wir sind uns keiner größeren öffentlichen Datensätze für diese Aufgabe bewusst, daher haben wir einen eigenen Datensatz mithilfe von Crowdsourcing erstellt.

Unser Datensatz umfasst drei verschiedene Domänen: Musik, Bücher und Rezepte. Unser Datensatz-Erstellungsprozess betont die Informalität mithilfe einer Cartoon-Vervollständigung. Der Cartoon besteht aus drei Sprechblasen:

* **Sprechblase 1 (Bob):** "Erinnerst du dich an das Lied, das wir gestern gehört haben?"
* **Sprechblase 2 (Alice):** "Meinst du 'Easy on Me' oder 'I Gotta Feeling'?" (Alternative Frage)
* **Sprechblase 3 (Bob):**  Hier füllt der Annotator eine indirekte Referenz ein, um eine der beiden Entitäten auszuwählen, z.B. "das neuere Lied".

Die erste Sprechblase wird automatisch aus einigen manuellen Vorschlägen pro Domäne ausgewählt. Die zweite Sprechblase (Alternative Frage) wird generiert, indem wir immer ein einfaches Template verwenden: "Meinst du A oder B?" A und B sind Beispiele aus Wikipedia.

Wir haben verschiedene Methoden zur Auswahl von A und B verwendet:

* **Zufällig:** A und B werden zufällig aus einer Liste ausgewählt.
* **Ähnliche Titel:** A und B haben ähnliche Titel, z.B. zwei Bücher mit dem Namen "Die Rückkehr".
* **Ähnliche Beschreibungen:** A und B haben ähnliche Beschreibungen auf Wikipedia.
* **Ähnliche Attribute:** A und B haben gleiche Genres oder denselben Künstler (bei Liedern).

Um den Annotatoren die Auswahl zu erleichtern, geben wir ihnen Hintergrundwissen zu den beiden Entitäten. Für Lieder bieten wir einen Google-Suchlink zu jedem Lied an und bitten sie, sich mindestens einen Teil jedes Liedes anzuhören und darüber zu lesen. Für Bücher und Rezepte zeigen wir Textausschnitte aus Wikipedia und für Rezepte auch Bilder. Dann bitten wir die Annotatoren, eine der beiden Entitäten auszuwählen und sie mithilfe von 3-5 indirekten Referenzausdrücken zu beschreiben.

Hier einige Beispiele aus unserem Datensatz: "das Lied ohne Worte", "nicht das Lied mit dem 12-jährigen Jungen" oder "das fiktive Lied" oder "aus Aserbaidschan".

Das **AltEntities Corpus** enthält 6.000 alternative Fragen in drei Domänen und 42.000 indirekte Referenzausdrücke.

Die Ergebnisse mit dem T5 XL Modell zeigen, dass die Genauigkeit sehr hoch ist (92-95%), wenn das Sprachmodell über den gleichen Hintergrund wie die Annotatoren verfügt. In der Praxis ist die Genauigkeit jedoch niedriger: 82-87%, wenn das Modell nur teilweise überlappendes Hintergrundwissen hat und 60%, wenn es nur die Entitätsnamen zur Verfügung hat. Wir haben auch gezeigt, dass die Modelle domänenspezifisch generalisierbar sind.

Hier finden Sie einen Link zu unserem Datensatz.

Vielen Dank.</sample>
    <sample id="143">Der Ansatz EDAtt wird verglichen mit zwei bestehenden SimulST-Richtlinien:

1. **Wait-k Strategie**
2. **Local Agreement**

Zusätzlich wird er mit einer **State-of-the-Art-Architektur** verglichen, die speziell für gleichzeitige Vorübersetzungen entwickelt wurde.</sample>
    <sample id="144">Die Autoren gehören der Nantes Universität (Nantes University Hospital) an.</sample>
    <sample id="145">Die Referentin heißt Jenny.</sample>
    <sample id="146"># Analyse von Omissionen in der Dialogzusammenfassung: Ein neuer Ansatz zur Verbesserung der Zusammenfassungskompetenz

Diese Präsentation behandelt die Herausforderungen bei der Dialogzusammenfassung, insbesondere das Problem der Omissionen, die zu unvollständigen Zusammenfassungen führen. Der Vortragende, Yicheng, ein PhD-Student von Fudan University, hebt hervor, dass, obwohl große Sprachmodelle in der Dialogzusammenfassung Fortschritte gemacht haben, die generierten Zusammenfassungen oft fehlerhaft sind und Fakten widersprechen.

Die Analyse zeigt, dass Omissionen in etwa 70% der Zusammenfassungen aus verschiedenen Domänen und mit verschiedenen Modellen auftreten. Die Informationen, die weggelassen werden, sind zufällig verteilt, was die Identifizierung wichtiger Inhalte schwierig macht. Um dieses Problem anzugehen, wurde das OLDS-Dataset (Omission Detection in Dialog Summarization) erstellt, das hochwertige Labels für Omissionen bereitstellt. Das Dataset basiert auf fünf Benchmarks und umfasst vielfältige Zusammenfassungs-Kandidaten.

Die Studie untersucht drei verschiedene Modellarchitekturen für die Omissionen-Detektion, darunter Paarweise Klassifizierung, Sequenz-Labeling und Pointer-Netzwerke. Die Ergebnisse zeigen, dass die Aufgabe anspruchsvoll ist, mit einem F1-Score von etwa 50%. Als vielversprechende Richtung wird die Verwendung der erkannten Omissionen zur Verbesserung der Zusammenfassungsvorhersage vorgeschlagen, was zu einer signifikanten Leistungssteigerung führt.

Zusammenfassend unterstreicht diese Arbeit die Wichtigkeit der Omissionen-Analyse und bietet einen neuen Ansatz zur Verbesserung der Qualität von Dialogzusammenfassungen.</sample>
    <sample id="147">Die Arbeit wurde in Zusammenarbeit mit Esin Durmus und Dan Jurafsky verfasst, also sind drei Autoren beteiligt.</sample>
    <sample id="148">Hallo, ich bin Sara Papi von der Universität Trento und der Fondazione Bruno Kessler, und ich möchte Ihnen kurz die Arbeit "Attention als Leitfaden für die gleichzeitige Sprachübersetzung" vorstellen, die in Zusammenarbeit mit Matteo Negri und Marco Turchi entstanden ist. Was ist gleichzeitige Sprachübersetzung (SimulST)? SimulST ist der Prozess, gesprochene Sprache in Echtzeit in Text in einer anderen Sprache zu übersetzen, was die Kommunikation zwischen verschiedenen Sprachen ermöglicht.

Welche Probleme haben die aktuellen SimulST-Modelle? In der Regel werden spezifische Architekturen trainiert, was zusätzliche Module und komplexe Trainingsverfahren mit sich bringt. Die Trainingsobjekte sind vielfältig, und es ist notwendig, mehrere Modelle für unterschiedliche Latenzzeiten zu trainieren und zu warten.

Unsere Lösung: Wir nutzen bestehende, offline trainierte Sprachübersetzungsmodelle ohne erneutes Training oder die Anpassung an eine spezifische SimulST-Architektur. Für jede Latenzzeit nutzen wir ein einziges Modell und steuern die Latenz über spezifische Parameter. Wir nutzen das Wissen, das das Modell durch den Aufmerksamkeitsmechanismus zwischen Audioeingabe und Textausgabe erworben hat, also die Kreuzaufmerksamkeit.

Wir schlagen EDAtt (Encoder-Decoder-Aufmerksamkeit) vor, eine Strategie, die entscheidet, ob ein Wort übersetzt und ausgegeben werden soll oder nicht, basierend auf der Aufmerksamkeit, der es zugewiesen wird. Ein Wort wird übersetzt und ausgegeben, wenn die Aufmerksamkeit nicht auf die letzten Lambda-Sprachrahmen konzentriert ist, d. h. wenn die Summe der Aufmerksamkeitsgewichte unter einem bestimmten Schwellenwert alpha liegt.

Als Beispiel: Wenn wir ein Sprachsegment mit "Ich werde über..." erhalten und das Modell die Übersetzung ins Deutsche voraussagt, können wir die Kreuzaufmerksamkeitsgewichte untersuchen. Die ersten beiden Wörter weisen auf die frühesten empfangenen Sprachrahmen hin, während das letzte Wort auf die letzten empfangenen Rahmen verweist. Daher werden die ersten beiden Wörter übersetzt, während das letzte Wort nicht ausgegeben wird und wir auf ein weiteres Sprachsegment warten.

Die Hauptresultate von EDAtt zeigen die gleichzeitige Sprachübersetzung in Diagrammen, in denen BLEU (ein Maß für die Übersetzungsqualität) und durchschnittliche Verzögerung (Latenzmaß) dargestellt sind. Wir vergleichen unsere Ergebnisse mit etablierten Strategien, die auf offline trainierten Modellen angewendet werden, wie z. B. der "Warte-k"-Strategie und der Lokalen Übereinstimmung, sowie mit der State-of-the-Art-Architektur, die speziell für gleichzeitige Vorübersetzungen entwickelt wurde.

Unsere Strategie übertrifft alle auf offline trainierten Modellen basierenden Strategien, da unsere Kurven weiter links im Diagramm liegen. Zudem ist sie in Bezug auf die tatsächliche verstrichene Zeit oder die rechenbasierte Zeit die schnellste Strategie. Weitere Ergebnisse finden Sie in unserer Arbeit, und wir haben den Code, die Modelle und die gleichzeitige Ausgabe offen zugänglich gemacht, um die Reproduzierbarkeit unserer Forschung zu gewährleisten. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="149">Ja, der Datensatz (CoNLL++) ist öffentlich zugänglich, wie im Paper erwähnt.</sample>
    <sample id="150">**Abstract**

Unsere Arbeit, "MEETINGQA: Extractive Question-Answering on Meeting Transcripts", präsentiert eine neue Datensammlung für die Aufgabe des extraktiven Frage-Antwortens (QA) in Besprechungsprotokollen. Besprechungen erzeugen enorme Mengen an Informationen, die durch QA-Modelle genutzt werden können. Im Gegensatz zu früheren Arbeiten, die sich auf Zusammenfassungen und Aktionspunkte konzentrierten, fokussiert MEETINGQA auf die unterrepräsentierte QA-Komponente.

Die Datensammlung umfasst 7.700 Fragen und die entsprechenden Antworten aus öffentlichen Transkripten von fast 100 Stunden Besprechungen. Fragen sind längere, offene Aussagen, die detaillierte Diskussionen auslösen. Antworten können von mehreren Sprechern stammen und aus mehreren, diskontinuierlichen Sätzen bestehen.

Wir untersuchen verschiedene Modelle, einschließlich kurz- und langkontextiger Ansätze, sowie Single- und Multi-Span-Varianten. Die Ergebnisse zeigen, dass, obwohl Modelle in feinabgestimmten Szenarien gute Leistungen erbringen, sowohl Zero-Shot- als auch feinabgestimmte Modelle bei der Identifizierung rhetorischer Fragen, der Zuordnung von Antworten zu Sprechern und der Handhabung komplexer Antworten Herausforderungen haben.

MEETINGQA bietet eine wertvolle Ressource für die Forschung im Bereich des QA in Besprechungsumgebungen und zeigt, dass diese Domäne viel Potenzial für Verbesserungen bietet.</sample>
    <sample id="151">## Präsentation: MultiInstruct - Verbesserung des mehrmodalen Nullschuss-Lernens durch Anweisungs-Tuning

**Einführung:**

In unserer Arbeit untersuchen wir, ob das Anweisungs-Tuning mehrmodaler, vorab trainierter Modelle die Generalisierung zu bisher unbekannten mehrmodalen Aufgaben verbessern kann. Während Anweisungs-Tuning in der natürlichen Sprachverarbeitung (NLP) stark wächst, fehlt es an großen, öffentlich zugänglichen Datensätzen für mehrmodale Anweisungsaufgaben. Um diese Lücke zu schließen, stellen wir **MultiInstruct** vor, den ersten mehrmodalen Anweisungs-Tuning-Datensatz.

**MultiInstruct Datensatz:**

MultiInstruct umfasst 62 vielfältige mehrmodale Aufgaben aus 10 Kategorien, die aus 21 bestehenden Open-Source-Datensätzen extrahiert wurden. Jede Aufgabe verfügt über fünf von Experten verfasste Anweisungen. Um die Verarbeitung verschiedener Eingabe- und Ausgabedatenarten zu vereinfachen, formulieren wir alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format.

**Methode:**

Als Basismodell verwenden wir OFA, ein vereinheitlichtes mehrmodales vorab trainiertes Modell, das Sprache, Bilder und Bounding Boxes mit einem gemeinsamen Vokabular verarbeitet.

Wir teilen den Datensatz in Trainings- und Testdaten auf:

* **Training:** 53 Aufgaben aus 9 Gruppen mit je 10.000 Instanzen pro Aufgabe
* **Test:** Die gesamte Gruppe "Common Sense Reasoning" und zusätzliche 5 Aufgaben aus "Visual Question Answering" und "Miscellaneous".

Während des Trainings mischen wir alle Instanzen aller Aufgaben und kombinieren jede Instanz zufällig mit einer ihrer fünf Anweisungsvorlagen.

**Bewertung:**

* **Performance:** Wir messen die Leistung mit Genauigkeit (für Klassifizierungsaufgaben) und ROUGE-L (für Generierungsaufgaben).
* **Sensitivität:** Ein neuer Metrik, der die Konsistenz der Modellausgaben bei leicht variierenden Anweisungen misst.

**Ergebnisse:**

Unsere Ergebnisse zeigen, dass Anweisungs-Tuning die Leistung von OFA auf mehrmodalen Aufgaben deutlich verbessert. Transferlernen von NLP-Anweisungsaufgaben verbessert die Leistung ebenfalls.

* Mit zunehmender Anzahl der Trainingsaufgaben verbessert sich die Leistung des Modells und die Sensitivität nimmt ab.
* Mehr Anweisungen pro Aufgabe führen zu einer besseren Gesamtleistung und einer geringeren Sensitivität.
* Transferlernen von NLP-Anweisungsaufgaben führt zu einer höheren Sensitivität im Vergleich zum ursprünglichen OFA-Modell.

**Zukünftige Arbeit:**

Wir erweitern derzeit MultiInstruct um weitere 150 Vision-Language-Aufgaben und veröffentlichen diesen Datensatz.

**Fazit:**

Unsere Arbeit stellt den ersten großen mehrmodalen Anweisungs-Tuning-Datensatz vor und untersucht verschiedene Transferlernen-Techniken. Wir führen die Sensitivitätsmetrik ein und zeigen deren Vorteile.</sample>
    <sample id="152">**Abstract:**

In der Präsentation "Exploring Large Language Models for Classical Philology" werden wertvolle Ressourcen für die Verarbeitung antiker griechischer und lateinischer Texte vorgestellt. Der Vortragende, Frederick Riemenschneider, hebt die aktuelle Landschaft der Sprachmodelle und Klassik hervor, einschließlich kürzlich entwickelter Modelle wie Latin BERT und Ancient Greek BERT.

Das Projekt zielt darauf ab, spezifische Sprachmodelle für die klassische Philologie zu entwickeln. Zwei monolinguale Modelle, GreBERTa (basierend auf RoBERTa) und GreTa (T5-Architektur), wurden für Altgriechisch trainiert. Darüber hinaus wurden PhilBERTa und PhilTa als mehrsprachige Modelle mit Daten in Altgriechisch, Latein und Englisch erstellt.

Die Datenerfassung umfasste Open Greek &amp; Latin sowie eine neue Korpora-Sammlung aus dem Internet Archive, die durch Identifizierung griechischer Stoppwörter optimiert wurde. Die Modelle wurden auf verschiedenen Aufgaben wie Part-of-Speech-Tagging, Dependency Parsing und Lemmatisierung benchmarkt, wobei sie die aktuelle State-of-the-Art übertreffen.

Interessanterweise zeigte sich, dass T5-Encoder nach einer anfänglichen Phase schlechter Leistung aufweisen, sich aber mit mehr Training verbessern. Die mehrsprachigen Modelle zeigten keine signifikanten Vorteile gegenüber den monolingualen, was hinsichtlich der semantischen und weltbezogenen Kenntnisse gilt.

Zusammenfassend wurden leistungsstarke, von Grund auf neue Sprachmodelle für die Klassik vorgestellt, die sowohl monolinguale als auch mehrsprachige Verarbeitung ermöglichen und die Forschung in diesem Bereich vorantreiben.</sample>
    <sample id="153"># **Resolving Ambiguities in Text-to-Image Generative Models**

In dieser Forschungsarbeit untersuchen wir die Herausforderungen, die durch Ambiguitäten in Prompts für Text-zu-Bild-Generativmodelle entstehen. Ambiguitäten können dazu führen, dass die generierten Bilder nicht der Absicht des Benutzers entsprechen. Wir schlagen einen zweifachen Ansatz vor, um dieses Problem anzugehen.

Zunächst erstellen wir ein Benchmark-Dataset, das verschiedene Arten von Ambiguitäten abdeckt, basierend auf dem bestehenden LAVA-Corpus. Unser System generiert dann klärende Fragen, um Benutzerabsichten zu verifizieren oder alternative visuelle Interpretationen vorzuschlagen. Diese Methode führt zu disambiguierten Prompts.

Anschließend bewerten wir die Generierung von Bildern mit einem automatisierten Framework, das die Übereinstimmung zwischen dem generierten Bild und der Benutzerabsicht misst. Wir nutzen ein VQA-Modell (Visual Question Answering), um die Treue der Bilder zur Benutzerabsicht zu bestimmen. Die Ergebnisse zeigen, dass unsere Methoden die Treue der Bildgenerierung verbessern und mit menschlichen Bewertungen übereinstimmen.

Unsere Arbeit unterstreicht die Bedeutung der Ambiguitätsauflösung für die Verbesserung der Leistung von Text-zu-Bild-Modellen und bietet ein praktisches Framework für die Bewertung und Verbesserung der Bildqualität.</sample>
    <sample id="154">Die Autoren gehören der University of Trento und Fondazione Bruno Kessler an.</sample>
    <sample id="155">Der/die Referent*in wird als Javad Hosseini genannt, der zusammen mit Filip Radlinski, Silvia Pareti und Annie Louis an der Arbeit "Resolving Indirect Referring Expressions for Entity Selection" und der Erstellung des AltEntities Corpus beteiligt ist.</sample>
    <sample id="157"># **Dialogue Summarization with Static-Dynamic Structure Fusion Graph**

Diese Forschung präsentiert eine innovative Methode für die Zusammenfassung von Dialogen, genannt SDDS (Static-Dynamic Dialogue Summarization), die die Herausforderungen bestehender Ansätze angeht. Traditionelle Methoden modellieren Dialoge mit statischen Graphen, die auf externen linguistischen Werkzeugen basieren, was zu Ungenauigkeiten und Abhängigkeiten führen kann.

Das SDDS-Modell überwindet diese Einschränkungen, indem es eine Fusion aus statischen und dynamischen Graphenstrukturen nutzt. Es besteht aus vier Hauptkomponenten:

1. **Utterance Encoding**: Wandelt Dialogbeiträge in Vektoren um.
2. **Statisches Graphenmodell**: Erstellt Beziehungen zwischen Beiträgen mithilfe heuristischer Methoden, wie z.B. Discourse Parsing und Speaker Interaction Frequency Matrizen.
3. **Dynamisches Graphenmodul**: Erfassen semantische Beziehungen zwischen Vektoren mithilfe von Multi-Head-Attention.
4. **Zusammenfassungsgenerierung**: Ein vorab trainiertes Sprachmodell integriert die Graphenstrukturen in eine Zusammenfassung.

Die Methode kombiniert statische und dynamische Informationen effektiv, um präzisere und kontextbezogenere Dialogzusammenfassungen zu erzeugen. Die Forscher haben die Implementierung auf GitHub veröffentlicht, um die Reproduzierbarkeit und den weiteren Einsatz zu erleichtern.</sample>
    <sample id="158"># **Dual Cache für verbesserte neuronale Coreferenzauflösung in langen Dokumenten**

Die Coreferenzauflösung zielt darauf ab, in einem Dokument erwähnte Entitäten zu identifizieren und ihre Referenzen zu klären. Traditionelle Methoden scannen alle möglichen Paare von Erwähnungen, was rechenintensiv und speichermäßig ineffizient ist. Cache-basierte Ansätze, wie die Verwendung eines festen Cache-Größen-Caches, verbessern die Effizienz, aber in langen Dokumenten mit wechselnden Themen können Cache-Misses häufig auftreten.

In dieser Arbeit stellen wir einen Dual-Cache-Ansatz vor, der aus einem lokalen und einem globalen Cache besteht. Der lokale Cache verwendet eine LRU-Eviktionsstrategie (Least Recently Used) für lokale Entitäten, während der globale Cache globale Entitäten mit einer LFU-Strategie (Least Frequently Used) verwaltet. Dieser Dual-Cache-Mechanismus klassifiziert neue Erwähnungen und entscheidet, ob sie in den lokalen oder globalen Cache aufgenommen werden.

Unsere Evaluierung auf vier öffentlichen Datensätzen zeigt, dass der Dual-Cache im Vergleich zu Einzel-Cache-Methoden bessere Ergebnisse erzielt, insbesondere bei längeren Dokumenten. Er reduziert Cache-Misses effektiv und bietet ein optimales Verhältnis aus Leistung und Kosten. Die Studie unterstreicht die Vorteile der getrennten Speicherung lokaler und globaler Entitäten für die Coreferenzauflösung in langen Texten.</sample>
    <sample id="159">##  Sprachemodelle und ihre Akzeptanz: Eine tiefere Betrachtung mit längeren Kontexten

Hallo zusammen, ich bin Koustav Sinha und ich freue mich, euch heute unsere Arbeit zur ACL 2023 vorzustellen.

**Sprachmodelle und Akzeptanzurteile:**

Sprachmodelle werden oft anhand von Akzeptanzurteilen trainiert, die ob ein Satz grammatikalisch korrekt oder akzeptabel ist, entscheiden. Bisherige Methoden, wie z.B. die Minimalen Paare Paradigmen (MPP), basieren auf Paaren von akzeptablen und inakzeptablen Sätzen. Das Ziel ist, dass das Modell den akzeptablen Satz wahrscheinlicher ausgibt.

**Einschränkungen der aktuellen Methoden:**

Das Problem ist, dass diese Methoden nicht in der Lage sind, die Akzeptanzurteile von Sprachmodellen über längere Sätze hinweg zu bewerten. Heutzutage verfügen Sprachmodelle über immer größere Kontextfenster, daher ist es wichtig, ihre Akzeptanzurteile über die gesamte Länge des Kontextes hinweg zu untersuchen.

**Unsere Herangehensweise:**

In unserer Arbeit möchten wir die MPP-Pipeline erweitern, indem wir das Modell dazu bringen, Akzeptanzurteile für längere Sequenzen zu treffen. Dazu simulieren wir längere Sätze, indem wir aus bestehenden Datensätzen akzeptable und inakzeptable Sätze auswählen.

**Datensätze und Simulation:**

Beispielsweise nehmen wir ein typisches Paar aus dem BLiMP-Datensatz, das grammatikalische und ungrammatische Sätze aus dem "Adjunct Island"-Fall enthält. Wir erstellen dann längere Sätze, indem wir grammatikalische Sätze aus "Adjunct Island" als Präfix zu beiden Sätzen (akzeptabel und inakzeptabel) hinzufügen. Wir können diesen Prozess auch mit Sätzen aus anderen Datensätzen oder sogar aus völlig anderen Bereichen wie Wikipedia wiederholen.

**Ergebnisse:**

Unsere Ergebnisse zeigen, dass MPP-Urteile für Sätze aus völlig fremden Kontexten (wie Wikipedia) robust gegenüber verschiedenen Längen sind. Bei Sätzen aus dem gleichen Datensatz hingegen beobachten wir signifikante Schwankungen in den MPP-Urteilen, je nachdem, ob das Präfix akzeptabel oder inakzeptabel ist. Dieser Effekt wird umso stärker, je länger der Kontext wird, was für moderne Sprachmodelle mit großen Kontextfenstern relevant ist.

**Warum sind Präfixe so wirkungsvoll?**

Um die Ursache für diese starken Schwankungen zu verstehen, haben wir verschiedene Analysen durchgeführt. Dabei haben wir festgestellt, dass das Modell auf die Struktur der Sätze reagiert, selbst wenn wir kleine Änderungen vornehmen, um sie zu "stören". Das bedeutet, dass das Modell sensible auf latente syntaktische und semantische Merkmale reagiert, die in verschiedenen Sätzen geteilt werden.

**Zusammenfassende Erkenntnisse:**

Unsere Arbeit zeigt, dass Sprachmodelle auf latente syntaktische und semantische Merkmale reagieren, die über Sätze hinweg geteilt werden. Die gängigen MPP-Evaluierungen mit kurzen, einzelnen Sätzen erfassen möglicherweise nicht das gesamte abstrakte Wissen der Modelle innerhalb ihres Kontextfensters.

Weitere Details zu unseren Experimenten findet ihr in unserer Arbeit. Vielen Dank für eure Aufmerksamkeit!</sample>
    <sample id="160">Im ersten Schritt werden den Input-Token **ungeordnete Multisets** von Tokens zugeordnet, die im Output vorkommen werden.</sample>
    <sample id="161">In CoScript sind insgesamt 55.000 spezifische Skripte vertreten.</sample>
    <sample id="163">Die beste Ausrichtungsmethode für DEPLAIN ist **MASSalign**, wie in der Präsentation erwähnt.</sample>
    <sample id="164">Der Vorteil von schwach überwachtem Lernen (WSL) besteht darin, dass es kostengünstiger ist als das manuelle Beschriften von Daten, da es schwache Beschriftungsquellen wie heuristische Regeln oder niedrigqualitative Crowdsourcing nutzt. Trotzdem versuchen WSL-Algorithmen, robuste neuronale Netze zu trainieren, die trotz der Rauschen in den Beschriftungen gut generalisieren.</sample>
    <sample id="165"># **Abductive Commonsense Reasoning: Ein unsupervisiertes Ansatz**

Dieser Vortrag präsentiert die Forschung zur abduktiven Logik, einem wichtigen Aspekt des gesunden Menschenverstandes, und stellt ein neues unsupervisiertes Lernverfahren namens LiPoR (Likelihood Learning with Posterior Regularization) vor.

Die Studie befasst sich mit der Herausforderung, abduktive Erklärungen ohne manuelle Beschriftung zu lernen, da die Bewertung von Erklärungen oft subjektiv und fehleranfällig ist. Der vorgeschlagene Ansatz zielt darauf ab, eine Methode zu entwickeln, die Erklärungen für gegebene Kontexte und Ergebnisse priorisiert.

Im Kern behandelt LiPoR Erklärungen als latente Variablen und maximiert die Wahrscheinlichkeit des Ergebnisses unter Berücksichtigung aller möglichen Erklärungen. Um plausible Erklärungen zu bevorzugen, wird ein Regularisierer eingeführt, der auf der gegenseitigen Ausschlusskraft der Erklärungen basiert. Dieser Regularisierer, Omega, fördert die Auswahl einer Teilmenge von Erklärungen, die die Kontext-Ergebnis-Lücke am besten schließen.

Die Ergebnisse zeigen, dass LiPoR auf dem AlphaNLI-Datensatz, einem Standard-Abduktions-Dataset, überlegen ist, und sogar leistungsstarke Zero-Shot-Modelle wie GPT-3 übertrifft. Dieser Ansatz eröffnet Möglichkeiten für die Entwicklung von Systemen, die gesunden Menschenverstand anwenden können, ohne auf teure manuelle Beschriftung angewiesen zu sein.

Die Arbeit trägt zu einem tieferen Verständnis abduktiver Logik bei und bietet einen vielversprechenden Weg für die Entwicklung von KI-Systemen, die komplexe, alltägliche Probleme lösen können.</sample>
    <sample id="166"># **A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Complex Text**

Diese Arbeit präsentiert einen innovativen Ansatz für die Herausforderung der Bildrückgewinnung aus komplexen Textbeschreibungen, bei der Bilder hochgradig ähnlich sind und die Beschreibungen lang sind. Die Forscher aus der Harbin Institute of Technology, Shenzhen, schlagen ein neuronales Divide-and-Conquer-Rahmenwerk vor, das von Dual-Process-Theorie inspiriert ist.

Der vorgeschlagene Ansatz, NDCR (Neural-Symbolic Divide-and-Conquer Reasoner), besteht aus drei Hauptkomponenten:

1. **Proposition Generator**: Zerlegt komplexe Textpropositionen in einfache Darstellungen.
2. **Visual-Linguistic Interactor (System 1)**: Führt eine analogische Interaktion zwischen visuellen Inhalten und einfachen Propositionen durch, was Matching-Scores und Zwischen-Zustände erzeugt.
3. **Neural-Symbolic Reasoner (System 2)**: Integriert die Ergebnisse von System 1 und führt logische Operationen aus, um die endgültige Lösung zu bestimmen.

Die Experimente zeigen, dass NDCR im Vergleich zu Basismethoden überlegen ist. Die Abschaltversuche bestätigen die Effektivität jedes Moduls. Der Ansatz demonstriert die Vorteile der Kombination von analoger und logischer Inferenz für komplexe Aufgaben. Die Studie schlägt vor, dass neuronale symbolische Berechnungen das Potenzial haben, die Kompositionsfähigkeit und Planung von Sprachmodellen zu verbessern, und hebt die Synergien zwischen Divide-and-Conquer und Dual-Process-Theorie hervor.</sample>
    <sample id="167">Die Dokumente in DEPLAIN-web wurden zu gleichen Teilen sowohl manuell als auch automatisch ausgerichtet. Genauer gesagt:

- **Manuell**: 750 Dokumente wurden vollständig manuell ausgerichtet.
- **Automatisch**: 750 Dokumente wurden zusätzlich mit automatischen Alignmentmethoden ausgerichtet.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde erstellt, indem Nachrichtenartikel aus Reuters News im Jahr 2020 gesammelt und anschließend mit den gleichen Annotation-Richtlinien wie beim CoNLL-2003-Datensatz annotiert wurden.</sample>
    <sample id="169"># **Abstract: Prompting PaLM für die maschinelle Übersetzung**

Diese Studie untersucht die Effektivität von Prompting-Strategien für große Sprachmodelle (LLMs) in der maschinellen Übersetzung (MT). Die Forscher, einschließlich David Vilar und sein Team von Google Translate, konzentrieren sich auf PaLM, ein 540 Milliarden Parameter umfassendes Modell, das auf einer umfangreichen Textsammlung trainiert wurde.

Die Studie führt eine umfassende Bewertung der Übersetzungskapazität von LLMs durch, indem sie Best Practices der MT-Community anwendet. Dazu gehört die Verwendung aktueller Testdatensätze und der Vergleich mit State-of-the-Art-Systemen aus der WMT-Bewertung. Die Ergebnisse zeigen, dass das Prompting einen signifikanten Einfluss auf die Leistung von LLMs hat. Einfache Experimente mit einem- und mehrmaligem Prompting demonstrieren Leistungsunterschiede von bis zu 40 BLEURT-Punkten.

Die Autoren empfehlen eine 5-Shot-Prompting-Strategie, bei der Beispiele mit Sprachmarkierungen bereitgestellt werden. Ihre Experimente ergaben, dass die Qualität der Beispiele entscheidender ist als die Formulierung des Prompts. Hochwertige, kuratierte Daten aus der WMT-Entwicklungsumgebung (dev data) lieferten bessere Ergebnisse als Trainingsdaten.

Die menschliche Bewertung offenbarte, dass PaLM flüssige Übersetzungen erzeugt, aber häufig Teile der Quelltexte weglässt, was zu Omissionen führt. Trotzdem erreichte PaLM eine Leistung, die kommerziellen Systemen wie Google Translate nahekommt, wobei die State-of-the-Art-Systeme in Bezug auf Genauigkeit und Stil/Unnatürlichkeit überlegen waren.</sample>
    <sample id="170">## Präsentation: XSemPLR: Cross-Lingual Semantic Parsing in Mehreren natürlichen Sprachen und Bedeutungsrepräsentationen

**Einführung:**

Hallo zusammen, ich bin Yusen Zhang von der Penn State University. Heute möchte ich unsere Arbeit mit dem Titel "XSemPLR: Cross-Lingual Semantic Parsing in Mehreren natürlichen Sprachen und Bedeutungsrepräsentationen" vorstellen.

**Zusammenfassung:**

Semantic Parsing ist die Aufgabe, semantische Darstellungen von Benutzerabfragen wie SQL oder Lambda-Kalkül zu erstellen. Cross-Lingual Semantic Parsing erweitert diese Aufgabe auf die Übersetzung von Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen.

**Herausforderungen:**

Bisherige Modelle wurden getrennt für spezifische Aufgaben und Datensätze entwickelt, mit einem Fokus auf bestimmte natürliche Sprachen und Bedeutungsrepräsentationen. Es gibt Lücken bei der Abdeckung von:

* Chinesisch
* Lambda-Kalkül
* Vielfalt an natürlichen Sprachen und Bedeutungsrepräsentationen

**Unsere Lösung: XSemPLR**

Wir stellen XSemPLR vor, einen einheitlichen Datensatz für Cross-Lingual Semantic Parsing mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen. XSemPLR umfasst:

* 9 Datensätze aus verschiedenen Domänen
* 5 Semantic-Parsing-Aufgaben
* 8 Bedeutungsrepräsentationen
* 22 natürliche Sprachen in 15 Sprachfamilien

**Evaluierungsansätze:**

Um XSemPLR effektiv zu bewerten, haben wir sechs Evaluierungs-Einstellungen definiert:

1. **Translate-Test:** Verwendung von Google Translate API zur Übersetzung in die Zielsprache, gefolgt von der Verwendung eines monolingualen Modells zum Training und zur Evaluierung.

2. **Monolingual (gleichsprachig):** Die Quell- und Zielsprache sind identisch (z.B. Deutsch zu Deutsch, Englisch zu Englisch).

3. **Monolingual Few-shot:** Training monolingualer Modelle mit nur 10% des Trainingsdatensatzes.

4. **Multilingual (mehrsprachig):** Training eines mehrsprachigen Modells auf allen Sprachen zusammen und Verwendung dieses Modells für die Übersetzung und Vorhersage in jeder Sprache.

5. **Cross-lingual Zero-shot und Few-shot Transfer:** Training auf einer Quellsprache und Transfer auf eine andere Sprache.

**Ergebnisse:**

* Wir haben verschiedene Modellgruppen evaluiert: Encoder-PTR (Multilingual Prätrainierte Encoder mit Pointer-basierten Decodern) und Encoder-Decoder (Multilingual Prätrainierte Encoder-Decoder Modelle).
* Encoder-Decoder-Modelle erzielten die besten Ergebnisse auf allen neun Datensätzen.
* Wir beobachteten den "Fluch der Multilingualität": Während die meisten Sprachen von der Mischung verschiedener Sprachen profitierten, sank die Leistung des Englischen in sieben Datensätzen und verbesserte sich in drei.
* Cross-linguale Zero-shot-Übertragungen zeigten signifikante Leistungsunterschiede im Vergleich zu monolingualen Einstellungen, während Few-shot-Übertragungen diese Lücke schnell schlossen.

**Fazit:**

XSemPLR bietet einen einheitlichen Rahmen für die Evaluierung von Cross-Lingual Semantic Parsing. Unsere Ergebnisse liefern wertvolle Erkenntnisse über die Herausforderungen und Möglichkeiten in diesem Bereich.

**Nächste Schritte:**

* Veröffentlichung des Papiers und des Codes
* Fortlaufende Erweiterung und Verbesserung von XSemPLR

Vielen Dank für Ihre Aufmerksamkeit!</sample>
    <sample id="171">Basierend auf dem Inhalt, wurden bereits folgende Arbeiten durchgeführt:

1. Analyse der Bedrohung durch Modellklau durch das Lernen von Embeddings.
2. Untersuchung bestehender Methoden zur Wasserzeichen-Implementierung, die jedoch entweder nicht für Embedding-as-a-Service (EaaS) geeignet sind oder an Transferabilität fehlen.
3. Entwicklung eines neuen Backdoor-basierten Wasserzeichensystems namens "Embedding Marker", das speziell für EaaS konzipiert ist.
4. Durchführung von Experimenten auf vier Datensätzen, um die Effektivität und Nutzenverluste des "Embedding Marker" zu validieren.
5. Überprüfung der Verdecktheit der eingebetteten Wasserzeichen durch Visualisierung der Embeddings mit PCA.</sample>
    <sample id="172">Nein, basierend auf der Präsentation sind mehrsprachige LLMs wie Codex oder Bloom nicht ausreichend für Cross-Lingual Semantic Parsing (CLSP) Aufgaben. Die Studie zeigt, dass diese Modelle trotz ihrer Multilingualität in CLSP-Aufgaben hinter anderen Ansätzen zurückbleiben.</sample>
    <sample id="174">**Abstract:**

Das Projekt "ArgAnalysis35K" präsentiert ein neuartiges Dataset für die Analyse der Argumentationsqualität, das aus 35.000 Argument-Analyse-Paarn besteht – das bisher größte seiner Art. Im Gegensatz zu früheren Datensätzen, die oft auf Crowdsourcing-Plattformen basieren und nur begrenzte Vielfalt und Tiefe aufweisen, zeichnet sich ArgAnalysis35K durch mehrere innovative Merkmale aus.

Die Argumente stammen aus hochwertigen Quellen wie Debattierwettbewerben, Experten- und Zwischendebattieren, was zu einer höheren Qualität führt. Das Dataset deckt 24 Themen ab, die in parlamentarischen Debatten relevant sind, und sammelt so eine breitere Palette an Argumenten als herkömmliche, auf wenige vorgegebene Themen beschränkte Datensätze.

Ein zentraler Beitrag ist die Einführung des Konzepts „Analyse“, das über einfache Behauptungen und Prämissen hinausgeht und komplexere Argumentationsstrukturen umfasst. Das Dataset erfordert somit ein tieferes Verständnis der Argumentationslogik.

Zusätzlich werden die Zuverlässigkeit der Annotationen durch eine instance-basierte Methode verbessert, die individuelle Annahmen der Annotatoren berücksichtigt. Ein Relevanzmodell bewertet jeden Argument-Thema-Verknüpfung auf einer Skala von 0-1, was die Flexibilität und Anwendbarkeit der Argumente erhöht.

Insgesamt bietet ArgAnalysis35K ein umfassenderes, qualitativ hochwertigeres und flexibleres Dataset für die Forschung zur Argumentationsanalyse.</sample>
    <sample id="175">Die Methode geht mit der Mehrdeutigkeit der Permutationen um, indem sie eine kontinuierliche Entspannung (continuous relaxation) verwendet, die eine GPU-freundliche Approximation des NP-harten "Traveling Salesman" Problems darstellt. Dies ermöglicht es, die wahrscheinlichsten linguistisch korrekten Permutationen zu lernen, indem man durch die Lösung zurückpropagiert.</sample>
    <sample id="176">Die Fairness eines nachgeschalteten NLP-Modells wird definiert durch die gleichmäßige und unvoreingenommene Leistung des Modells bei der Verarbeitung und Analyse von Texten aus verschiedenen politischen Perspektiven und sozialen Gruppen. Dies bedeutet, dass das Modell keine systematischen Vorurteile gegenüber bestimmten Gruppen aufgrund ihrer politischen Zugehörigkeit zeigt und somit keine Ungleichbehandlung oder Marginalisierung fördert.</sample>
    <sample id="177">Der/die Referent*in heißt Yanis Labrak.</sample>
    <sample id="178">Der/die Referent*in heißt Koustav Sinha.</sample>
    <sample id="179">**Abstract:**

Melanie Sclar präsentiert *SymbolicToM*, eine Methode zur Verbesserung der Theorie-des-Geistes-Fähigkeiten (Theory of Mind, ToM) in großen Sprachmodellen (LLMs). Traditionell wird ToM durch Lesekomprehensionsaufgaben mit mehrdeutigen Charakterzuständen gemessen, wie im Sally-Anne-Test.

Aktuelle LLMs, einschließlich ChatGPT und GPT-3, zeigen Schwächen bei falschen Überzeugungsfragen, die ToM erfordern. *SymbolicToM* adressiert dies durch die Verwendung expliziter grafischer Repräsentationen mentaler Zustände. Es berechnet Graphen, die die Überzeugungen und Annahmen aller Charaktere in einer Geschichte darstellen, und ermöglicht so effiziente Beantwortung von ToM-Fragen.

Die Forschung vergleicht *SymbolicToM* mit überwachtem Lernen, einschließlich eines feinabgestimmten GPT-3-Modells und Textual Time Travel. Experimente zeigen signifikante Leistungssteigerungen für *SymbolicToM* bei verschiedenen LLMs, insbesondere bei komplexen, ausdomänenbezogenen Szenarien.

Zwei neue Datensätze, *D₁*, *D₂* und *ParaphrasedToMi*, testen die Generalisierungsfähigkeit von *SymbolicToM*. Die Ergebnisse belegen, dass *SymbolicToM* robuste Verbesserungen bietet, während überwachtes Lernen stark an Leistung einbüßt, insbesondere bei sprachlicher und struktureller Variation.

*SymbolicToM* demonstriert eine vielversprechende, interpretierbare Methode zur Verbesserung der ToM-Fähigkeiten von LLMs, die potenziell ihre Anwendbarkeit in komplexen, kontextabhängigen Aufgaben erweitert.</sample>
    <sample id="180">Die Referentin heißt Myra.</sample>
    <sample id="181"># **Distilling Script Knowledge for Constrained Language Planning**

Dieser Forschungsbeitrag befasst sich mit der Herausforderung, Sprachplanung für spezifische Ziele mit verschiedenen Einschränkungen zu ermöglichen. Die Autoren definieren das Problem der *constrained language planning* und untersuchen, wie große Sprachmodelle (LLMs) dabei unterstützt werden können, Schritt-für-Schritt-Anleitungen für solche Ziele zu generieren.

Vorherige Arbeiten konzentrierten sich auf die Planung abstrakter Ziele typischer Aktivitäten, während die Planung für spezifische Ziele mit Einschränkungen wie "Schokoladenkuchen backen" unterrepräsentiert war. Die Studie zeigt, dass große Sprachmodelle bei der Planung für spezifische Ziele Schwierigkeiten haben. Durch eine detaillierte Analyse wird festgestellt, dass die Generierung treuer Skripte an die Einschränkungen eine Herausforderung darstellt.

Um dies zu verbessern, schlagen die Autoren eine Methode namens *over-generate-then-filter* vor. Diese Technik beinhaltet die Übergenerierung mehrerer Skripte und die anschließende Filterung mithilfe eines Filtermodells, das auf semantischer Ähnlichkeit und der Einhaltung der Zielbeschränkungen basiert. Das resultierende Dataset, *CoScript*, enthält 55.000 spezifische Ziele mit Skripten.

Die Forschung demonstriert, dass kleinere Modelle, feinabgestimmt auf *CoScript*, bessere Skripte generieren können als viele große Sprachmodelle, was die Machbarkeit kostengünstigerer Sprachplanungslösungen unterstreicht. *CoScript* wird als wertvolle Ressource für zukünftige Forschung auf diesem Gebiet angeboten.</sample>
    <sample id="182">Tropikalismus im Zusammenhang mit dieser Arbeit bezieht sich auf die Darstellung von Latinas mit Wörtern wie "vibrant" und "curvaceous", die an eine Stereotype anknüpfen, die Frauen aus Lateinamerika mit tropischen und exotischen Merkmalen assoziiert.</sample>
    <sample id="183">Die Autoren haben menschliche Probanden mit spezifischen Prompts (Anweisungen) versorgt, wie z.B. "Stellen Sie sich eine asiatische Frau vor und beschreiben Sie sie." Die generierten Beschreibungen wurden dann mit den von den Probanden verfassten Beschreibungen verglichen, um Muster und Stereotype zu identifizieren.</sample>
    <sample id="184">In dieser Arbeit wurde CXMI (Context Usage Measure for Machine Translation) und seine erweiterte Version Pointwise CXMI verwendet, um die Kontextnutzung durch maschinelle Übersetzungsmodelle zu messen. Diese Methoden bewerten, wie viel Informationen das Kontextwort (C) über das Zielwort (Y) gibt, basierend auf der Quellinformation (X).</sample>
    <sample id="185">Der Hauptunterschied zwischen DrBERT und ChuBERT ist die Trainingsdatenquelle: DrBERT wird mit einem großen Datensatz von medizinischen Web-Crawl-Daten (NACHOS) trainiert, während ChuBERT mit anonymisierten Daten aus dem Datenwarehouse des Nantes University Hospital trainiert wird.</sample>
    <sample id="187">Zwei Autoren: Ying und Zhiyang.</sample>
    <sample id="188">Iteratives Transferlernen ist eine Methode, bei der ein Modell zunächst auf einer verwandten Aufgabe (z.B. Stance Classification oder PDTB-Klassifizierung) vorab trainiert wird und dann schrittweise durch weitere Feinabstimmung auf die ursprüngliche Aufgabe (Dissonanzdetektion) verbessert wird.</sample>
    <sample id="189">Das Ziel des AltEntities Corpus ist es, ein größeres öffentliches Datenset für die Aufgabe der Entitätsauswahl durch indirekte Referenzen bereitzustellen. Es hilft dabei, die Fähigkeiten von Sprachmodellen (LLMs) bei der Verarbeitung natürlicher Sprache in konversationsbasierten Systemen zu bewerten und zu verbessern.</sample>
    <sample id="190">Ein Angreifer kann Modellparameter über einen EaaS (Embedding as a Service) extrahieren, indem er das Modell durch Lernprozesse aus den bereitgestellten Embeddings kopiert. Aktuelle Methoden bieten oft keine ausreichende Schutzmechanismen, um dies zu verhindern. Unser vorgeschlagenes System, **Embedding Marker**, nutzt eine Backdoor-Technik, um ein Watermarking-Verfahren zu implementieren, das die Extraktion und Verwendung der Modellparameter durch unbefugte Parteien erschwert.</sample>
    <sample id="191">An der Arbeit sind drei Autoren beteiligt: Sara Papi, Matteo Negri und Marco Turchi.</sample>
    <sample id="192">**Abstract: CAME: Confidence-guided Adaptive Memory Efficient Optimization**

Die Arbeit präsentiert CAME, einen Optimierer, der sowohl schnelle Konvergenz als auch niedrigen Speicherverbrauch in der Training von großen Sprachmodellen ermöglicht. Aktuelle adaptive Gradient-basierte Methoden wie Adam benötigen erheblich mehr Speicher für die Aufbewahrung von Momentestimaten. Während Speicher-effiziente Optimierer wie Adafactor eine Reduktion ermöglichen, leiden sie unter Leistungseinbußen und langsamer Konvergenz aufgrund von Fehlern.

CAME baut auf nicht-negativer Matrixfaktorisierung (NMF) auf, um Speicher zu sparen. Im Gegensatz zu Adafactor minimiert CAME Fehler durch eine adaptive, auf Vertrauen basierende Aktualisierungsmethode, die die Differenz zwischen vorhergesagten und generierten Updates berücksichtigt. Diese Methode reduziert den Einfluss von Unsicherheiten auf die Trainingsstabilität.

Experimente auf BookCorpus, English Wikipedia und großen Modellen wie BERT, GPT-2 und T5 zeigen, dass CAME signifikant bessere Validierungsgenauigkeit als Adafactor und Adam erreicht, insbesondere bei großen Batchgrößen. CAME reduziert den Speicherbedarf erheblich, ohne die Leistung zu beeinträchtigen, und übertrifft bestehende Optimierer wie SM3.

Zusammenfassend bietet CAME eine effektive und speichereffiziente Lösung für das Training großer Sprachmodelle, insbesondere bei großen Batchgrößen.</sample>
    <sample id="193">Basierend auf dem präsentierten Inhalt wurde **keine spezifische Anzahl** von Annotatoren erwähnt. Es wird lediglich angedeutet, dass ein **großes Maß an Annotation** durchgeführt wurde, ohne die genaue Anzahl zu nennen.</sample>
    <sample id="194">Die Autoren gehören an die Carnegie Mellon University in Zusammenarbeit mit der University of Washington und dem Allen Institute for AI.</sample>
    <sample id="195">**Abstract:**

Unsere Arbeit, "Reasoning over Hierarchical Question Decomposition Tree für Explainable Question Answering" (RoHT), adressiert Herausforderungen in der Explainable Question Answering (XQA), indem sie eine neue Methode zur Integration heterogener Wissensquellen vorschlägt. Aktuelle Ansätze teilen sich in neuro-symbolische Methoden (SPARQL-basiert) und dekompositionbasierte Methoden auf, die jeweils Einschränkungen aufweisen.

RoHT überwindet diese durch die Einführung eines hierarchischen Frage-Zerlegungsbaums (HQDT), der die komplexe Frage in sub-fragen unterteilt. Der Ansatz besteht aus zwei Stufen:

1. **HQDT-Erstellung:** Atomare Fragen werden generiert und zu einem Baum strukturiert, der die Abhängigkeiten zwischen den Sub-Fragen darstellt.
2. **Probabilistisches Denken:**  Das System wählt Wissensquellen (KB oder Textkorpora) für jede Ebene des HQDT aus und generiert Antworten mit Wahrscheinlichkeiten. Ein Aggregator wählt die besten Antworten aus.

Wir bewerten RoHT auf den komplexen QA-Datensätzen KQA Pro und Musique. Die Ergebnisse zeigen, dass RoHT, insbesondere bei unvollständigen KBs und in Kombination mit Textkorpora, signifikante Verbesserungen gegenüber bestehenden Methoden erzielt. Diese Ergebnisse unterstreichen die Effektivität und Überlegenheit der expliziten Zerlegung von Fragen bei der XQA.</sample>
    <sample id="196">Das Beispiel mit dem Begrenzer (Governor) auf der linken Seite ist: "I saw Bart and Lisa."</sample>
    <sample id="197">Der Stand der Technik für Dialogsysteme (Chatbots) umfasst Methoden wie menschliche Bewertungen (z.B. Auswahl der besseren Konversation oder Likert-Skalen) sowie die Bewertung mehrerer Dimensionen der Dialogqualität. Eine neue Methode, ABC-Eval, konzentriert sich auf die präzise und zuverlässige Bewertung von Verhaltensweisen in Dialogen, wie z.B. Irrelevanz, Widersprüche, Halluzinationen und Empathie, um eine höhere Auflösung bei der Bewertung zu erreichen.</sample>
    <sample id="198">Wir müssen die Akzeptanz der Modelle über das gesamte Kontextfenster bewerten, weil moderne Sprachmodelle immer größere Kontextfenster verwenden. Dies ist entscheidend, um zu verstehen, wie die Modelle die Akzeptanz über längere Sequenzen einschätzen und ob sie durch den Kontext beeinflusst werden, sei es aus demselben oder einem anderen Datensatz oder völlig irrelevanten Quellen wie Wikipedia.</sample>
    <sample id="199">Ja, das mehrsprachige Training führte in sieben von neun Datensätzen zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell. Dies wird als "Fluch der Mehrsprachigkeit" (Curse of Multilinguality) bezeichnet.</sample>
    <sample id="200">Nein, die Annotatoren kennen die Entitäten im Voraus nicht. Sie erhalten Hintergrundinformationen über die beiden Optionen (z.B. Google-Suchlinks für Songs oder Wikipedia-Text für Bücher), hören/lesen sich die Entitäten an und wählen dann eine aus, bevor sie indirekte Referenzen dazu formulieren.</sample>
    <sample id="201">Für die Bewertung wurden die folgenden MT-Metriken verwendet:

- **BLEURT**: Eine metrische Bewertung, die die Qualität von maschinellen Übersetzungen misst.
- **Neurale MT-Metriken**: Moderne, auf neuronalen Netzen basierende Metriken zur Bewertung der Übersetzungsgüte.
- **Expert-basierte menschliche Bewertung**: Bewertungen von Experten, die im MQM-Rahmen (Machine Quality Metrics) durchgeführt wurden.</sample>
    <sample id="202">Basierend auf der Präsentation, wirkt sich die Regression (oder das Lernen) stark auf die Generalisierungsfähigkeit von NER-Modellen aus. Insbesondere:

1. **Modellarchitektur**: Transformer-Modelle generalisieren besser.
2. **Modellgröße**: Größere Modelle führen zu besserer Generalisierung.
3. **Feinabstimmungsexemplare**: Mehr Feinabstimmungsexemplare verbessern die Generalisierung.

Die Präsentation zeigt, dass diese Faktoren zusammenwirken, um die Generalisierung zu verbessern, und dass die Leistungsdrop-Ursachen hauptsächlich auf **temporales Drift** zurückzuführen sind, nicht auf adaptives Überanpassung.</sample>
    <sample id="203">Positionalität ist für NLP wichtig, weil sie systematische Leistungsunterschiede zwischen Technologien und Bevölkerungsgruppen aufzeigt. NLP-Modelle und -Datensätze aggregieren die Urteile und Meinungen realer Menschen und können daher bestimmte Positionalitäten über andere repräsentieren. Das Verständnis und die Charakterisierung dieser Positionalitäten sind entscheidend, da NLP-Aufgaben zunehmend subjektiv und sozial ausgerichtet sind.</sample>
    <sample id="204">Basierend auf dem Inhalt, wurden mehrsprachige LLMs wie BLOOM **nicht durch Adapter, sondern durch eine vollständige Feinabstimmung** angepasst für die Aufgaben der cross-lingualen semantischen Parsing. Der Text erwähnt, dass diese Modelle "noch unzureichend" für diese Aufgaben sind, was darauf hindeutet, dass sie nicht optimiert wurden. Stattdessen wurde eine umfassende Benchmark-Studie mit verschiedenen Ansätzen durchgeführt.</sample>
    <sample id="205"># **Von der Vorabdatenanalyse bis zu ungerechten NLP-Modellen: Aufdecken politischer Voreingenommenheiten**

Die Arbeit untersucht die Auswirkungen politischer Voreingenommenheiten in großen Web-Crawling-Daten auf Sprachmodelle und ihre potenziellen Auswirkungen auf Downstream-Aufgaben. Sprachmodelle, die auf solchen Daten trainiert werden, können politische Meinungen aus verschiedenen Quellen aufnehmen, was sowohl Vorteile als auch Herausforderungen mit sich bringt.

Die Studie beantwortet zwei Hauptfragen: Erstens, wie kann man die politische Ausrichtung von Sprachmodellen bewerten und welche Rolle spielt die Vorabdatenanalyse dabei? Zweitens, wie beeinflussen die politischen Neigungen der Modelle ihre Leistung bei Downstream-Aufgaben und führen sie zu Fairness-Problemen in NLP-Anwendungen?

Durch die Verwendung politischer Fragebögen und der politischen Konferenztest-Methode zeigten die Forscher, dass Sprachmodelle unterschiedliche politische Neigungen aufweisen. GPT-4 erwies sich als das am stärksten linke Modell. Weitere Experimente, bei denen Sprachmodelle auf parteiische Korpora trainiert wurden, zeigten, dass dies ihre ideologischen Koordinaten beeinflusst. Nach 2017 neigten die Modelle zu einer weiteren Verschiebung von der Mitte, was die Polarisierung in der Gesellschaft widerspiegelt.

Bei der Bewertung von Modellen mit verschiedenen politischen Neigungen in Aufgaben wie Hassrede- und Fake-News-Erkennung wurden signifikante Unterschiede festgestellt. Linke Modelle waren besser bei der Erkennung von Hassrede gegen Minderheiten, während rechte Modelle besser bei der Erkennung von Hassrede gegen weiße und männliche Gruppen waren. Diese Ergebnisse heben Fairness-Probleme bei der Bereitstellung von Sprachmodellen in der Praxis hervor.

Die Diskussion betont die schwierige Balance zwischen der Vermeidung von Voreingenommenheit und der potenziellen Zensur bei der Sanierung politischer Meinungen in Trainingsdaten.</sample>
    <sample id="206">Für das Transferlernen verwenden wir Modelle aus zwei verwandten Aufgaben:

1. **Debate**: Bestimmt, ob zwei Debattenbeiträge von verschiedenen Personen übereinstimmen oder nicht, unabhängig vom Thema.
2. **CE (Classification of Expansion and Comparison)**: Binäre Klassifizierung von Erweiterung und Vergleichsklassen aus dem PDTB (Purdue Corpus of General Language Use), die eng mit der Konzeption von Konsonanz und Dissonanz verbunden sind.

Diese Modelle werden verwendet, um die anfängliche Klassifizierungsleistung zu verbessern und als Grundlage für das aktive Lernen zu dienen.</sample>
    <sample id="207">Die aktuellen Testsets, die zur Bewertung der PaLM-Fähigkeiten verwendet wurden, sind die neuesten Testsets der MT-Community, um eine Überlappung mit den Trainingsdaten zu vermeiden. Speziell wurde der WMT-Evaluationsdatensatz (dev data) verwendet, der als kuratierter und qualitativ höher eingestuft wird als das Trainingsdaten.</sample>
    <sample id="208">Die Autoren haben drei Empfehlungen vorgeschlagen:

1. Adressieren von positiven Stereotypen und essentiellen Narrativen.
2. Verwendung eines intersektionalen Ansatzes zur Untersuchung von Vorurteilen und Schäden.
3. Erhöhte Transparenz bei Methoden zur Bias-Minderung.</sample>
    <sample id="209">Basierend auf den Ergebnissen der Studie, die vorgeschlagene Methode ("over-generate-then-filter") verbessert die Qualität der generierten Skripte erheblich gegenüber der stärksten Baseline. Während die Baseline unbefriedigende Ergebnisse bei der Planung spezifischer Ziele erzielt, zeigt die vorgeschlagene Methode eine signifikante Verbesserung sowohl in der semantischen Vollständigkeit als auch in der Einhaltung der Einschränkungen.

Konkret wird erwähnt, dass T5, das auf der CoScript-Datenmenge feinabgestimmt wurde, Skripte von höherer Qualität generiert als die meisten großen Sprachmodelle, was darauf hindeutet, dass kleinere, spezialisierte Modelle bei angemessener Schulung auf geeigneten Datensätzen größere Leistung erbringen können.</sample>
    <sample id="210">Der/die Referent*in heißt Shuheng.</sample>
    <sample id="211">Ja, die Ergebnisse und der Datensatz der Studie, insbesondere der DEPLAIN-Corpus, können als Benchmark für zukünftige Forschungen und Entwicklungen im Bereich der automatischen Textvereinfachung in deutscher Sprache verwendet werden. Die Studie zeigt effektive Methoden und erreicht bessere Ergebnisse als Basislinien, was sie zu einem wertvollen Referenzpunkt macht.</sample>
    <sample id="212">In der Arbeit wird **einem kleineren Modell** experimentell nachgegangen, nämlich T5, das nach Feinabstimmung auf CoScript bessere Script-Generierungsergebnisse liefert als die meisten großen Sprachmodelle.</sample>
    <sample id="213">Das Basismodell für die Untersuchung der multimodalen Unterrichtsabstimmung ist **OFA** (ein einheitliches multimodales vortrainiertes Modell).</sample>
    <sample id="215"># **Abstrakt: Symmetrische Koordination und die Prinzipien der Abhängigkeitsstruktur**

Diese Präsentation diskutiert die verschiedenen Abhängigkeitsstrukturen in der Koordination, insbesondere die asymmetrischen und symmetrischen Ansätze. Adam Przepiórkowski argumentiert für eine symmetrische Struktur, indem er das Prinzip der Minimierung der Abhängigkeitslänge anwendet.

Der Vortrag fokussiert auf die englische Grammatik, wo direkte Objekte nahe am Verb bevorzugt werden, während Adjunkte weiter entfernt sein können. Przepiórkowski zeigt, dass lange direkte Objekte oder NPs diese Regel brechen können, wenn sie die Abhängigkeitslänge insgesamt minimieren. Er analysiert zwei Koordinationsstrukturen: eine mit einem Kopf-Konjunkt und eine symmetrische.

Durch die Untersuchung der Penn Treebank und anderer Korpora werden statistische Beobachtungen bestätigt: Linke Konjunkte neigen zu kürzeren Längen, besonders wenn kein externer Gouverneur vorhanden ist. Diese Tendenz verschwindet, wenn der Gouverneur auf der rechten Seite steht. Diese Beobachtung stützt die Argumentation für symmetrische Koordination und gegen asymmetrische Ansätze wie den von Mel'čuk und der Pragener Schule.

Der Autor schlägt vor, dass die Position des Gouverneurs die Präferenz für kürzere linke Konjunkte beeinflusst, was zu einem klaren Argument für eine symmetrische Behandlung der Koordination führt. Die Studie lädt zu weiteren Diskussionen über die Abhängigkeitsstruktur in der Sprachwissenschaft ein.</sample>
    <sample id="217"># **Abstract: "Seen to Unseen: Erforschung der Kompositionalen Generalisierung bei Mehrattributkontrollierender Dialoggenerierung"**

Der Forschungsbeitrag konzentriert sich auf die Herausforderung der mehrattributkontrollierten Dialoggenerierung (CDG), indem er eine Methode zur Kompositionalen Generierung vorschlägt. Bisherige Ansätze konzentrierten sich entweder auf einzelne Attribute oder kombinierten Kontrollsignale mit spezifischen Labels. Die Arbeit identifiziert die Begrenzungen bestehender Modelle hinsichtlich der Generierungsfähigkeit bei mehrattributigen Szenarien.

Die Forscher entwickeln DCG (Disentangled Controllable Generation), ein Modell, das Attributkonzepte aus gesehenen Werten lernt und eine Disentanglement-Verlusteinrichtung nutzt, um verschiedene Attributkombinationen zu trennen. Sie stellen MAE (Multi-Attribute Evaluation) vor, ein referenzfreies Bewertungsrahmenwerk, das für unterschiedliche Attributgranularitäten geeignet ist. Zwei Benchmarks werden erstellt, um die Effektivität des DCG und der MAE zu demonstrieren.

Die Studie führt zwei Arten von Prompt-Modulen ein: Attribut-orientierte Prompts, die spezifische Kontrollsignale fokussieren, und aufgabenorientierte Prompts, die globale Merkmale einbeziehen. Durch die Kombination dieser Prompts und Disentanglement-Verluste wird die Generierungsfähigkeit verbessert und die Unterscheidung zwischen Attributkombinationen erleichtert. Die Ergebnisse zeigen, dass DCG im Vergleich zu Basismodellen überlegene Attributkontrollierbarkeit und Textqualität aufweist, insbesondere bei neuen, zuvor nicht gesehenen Attributkombinationen.

Zusätzlich wird eine automatische Bewertungsmetrik, MAE, vorgestellt, die korrelierte Koeffizienten mit menschlichen Bewertungen aufweist und die Qualität der Dialoge effektiv misst. Die Arbeit demonstriert die allgemeine Anwendbarkeit von MAE auf verschiedene Sprachmodelle.</sample>
    <sample id="218">Die Autoren gehören zu Google Translate, was impliziert, dass sie mit der Universität oder dem Forschungszentrum verbunden sind, das Google betreibt. Google ist ein multinationales Technologieunternehmen und nicht direkt einer bestimmten Universität zugeordnet.</sample>
    <sample id="219">**Abstract:**

Die Arbeit "A Compare-and-contrast Multistage Pipeline for Uncovering Financial Signals in Financial Reports" von Jia-Huei Ju und Kollegen zielt darauf ab, die Analyse von Finanzberichten zu verbessern. Der Fokus liegt auf Form 10-K-Berichten, jährlichen Berichte, die von der SEC verlangt werden und wertvolle Unternehmensinformationen enthalten. Die Herausforderung besteht darin, aus diesen Berichten nützliche Informationen zu extrahieren, was viel manuelle Arbeit erfordert.

Die Studie basiert auf der Beobachtung, dass Finanzberichte über die Jahre hinweg eine hohe Textähnlichkeit (ca. 80% identische Token) aufweisen. Aus diesem Grund wird ein "Highlighting"-Task und ein mehrstufiges Pipeline-Verfahren vorgeschlagen. Der Task vergleicht und kontrastiert den Kontext zwischen dem aktuellen Bericht (Ziel) und dem Bericht des Vorjahres (Referenz), um die Wichtigkeit von Wörtern (Rationale) zu bestimmen, die Beziehungen zwischen den beiden darstellen.

Die Pipeline umfasst vier Stufen: Dokumentsegmentierung (ausgelassen aufgrund der Zeitbeschränkung), Relationenerkennung, und zwei Feinabstimmungsphasen (out-of-domain und in-domain). Für die Feinabstimmung wird ein externes Dataset (eSNLI) und ein selbst erstelltes Dataset (FINAL) verwendet. Die Bewertung zeigt, dass das vorgeschlagene Modell auf beiden Datasets hervorragende Leistungen erbringt und auch auf nicht-trainingsbezogene Paare (Mismatched) anwendbar ist.

Zusammenfassend wird ein Highlighting-Task und ein effektives Pipeline-Verfahren präsentiert, das die Extraktion von Finanzsignalen aus Finanzberichten verbessert und zukünftige Erweiterungen ermöglicht.</sample>
    <sample id="220">Die Autoren gehören zu Stony Brook University.</sample>
    <sample id="221">In der Arbeit wurden hauptsächlich Sprachpaare untersucht, die Deutsch in Englisch und umgekehrt (Deutsch-Englisch) umfassen. Es wird jedoch auch auf die Verwendung anderer Sprachpaare hingewiesen, insbesondere im Kontext der WMT-Bewertungen (World Machine Translation).</sample>
    <sample id="222">**Zusammenfassung:**

Dieser Forschungsbeitrag befasst sich mit der Herausforderung der Domänenanpassung in offenen Frage-Antwort-Systemen (Open-Domain QA). Das Ziel ist es, Modelle zu entwickeln, die auf verschiedene Domänen übertragen werden können, insbesondere von einer allgemeinen Domäne wie Wikipedia zu spezifischeren Bereichen wie Biomedizin.

Die Studie identifiziert Probleme, wenn ein auf Wikipedia trainiertes Modell auf biomedizinische Fragen angewendet wird, da die Modelle Schwierigkeiten haben, relevante Informationen aus dem neuen Kontext zu extrahieren. Um dies zu beheben, werden zwei Ansätze für Dateninterventionen untersucht: **Few-Shot** und **Zero-Shot** Methoden.

**Few-Shot** beinhaltet die Verwendung von Beispielen aus der Zieldomäne, um das Modell zu ergänzen. Hier generieren große Sprachmodelle zusätzliche Fakten, die dann zu Cloze-Fragen verarbeitet werden, um die Modelle anzupassen. Diese Methode führte zu Verbesserungen von 8% beim Retriever und 11% beim Lesemodell.

**Zero-Shot** Methoden hingegen haben keinen Zugriff auf Zieldomänenbeispiele. Hier werden Variablen wie Frageformat, Antwortverteilung und Kontextverteilung kontrolliert manipuliert, um das Modellverhalten zu untersuchen. Die Ergebnisse deuten darauf hin, dass Uniformverteilungen bei Antworten und die Verwendung von BM25 (einem unüberwachten Retriever) die besten Leistungen erbringen.

Die Forscher klassifizieren auch die Art der Domäneninkompatibilität mithilfe einer Datenverschiebungstaxonomie und zeigen, dass bestimmte Interventionen je nach Art der Verschiebung (Konzept, Kovariate, Voll) wirksamer sind. Die Studie demonstriert, dass diese Strategien die Leistung in Domänenanpassungsaufgaben erheblich verbessern können, mit Verbesserungen von bis zu 24%.</sample>
    <sample id="223">Der/die Referent*in heißt Shangbin.</sample>
    <sample id="224">Während der Experimente wurden zwei Modelle untersucht:

1. **long-mBART**: Für die Dokumenten-Level-Textvereinfachung.
2. **base mBART**: Für die Satz-Level-Textvereinfachung.</sample>
    <sample id="225">Für das Training werden 53 Aufgaben aus 9 Gruppen verwendet, und für die Tests werden insgesamt 10 Aufgaben (die gesamte Gruppe "Common Sense Reasoning" und zusätzlich 5 aus den Gruppen "VQ" und "Miscellaneous") verwendet.</sample>
    <sample id="226">Basierend auf dem englischen Inhalt sind zwei Autoren an der Arbeit beteiligt: Regina Stodden und Omar.</sample>
    <sample id="227">**Abstract:**

Aktuelle Sprachmodelle haben bemerkenswerte Fortschritte in vielen NLP-Aufgaben erzielt, doch fehlt es ihnen an **grundiertem Sprachverständnis**, das natürliche Sprachausdrücke in ausführbare Pläne oder Programme überträgt. Dies ist für Anwendungen wie Sprachassistenten, semantische Suche und Robotersteuerung entscheidend.

Die Herausforderung liegt in der fehlenden Verknüpfung während der Prätrainingsphase. Bisherige Ansätze generieren Pläne direkt mit Sprachmodellen, was oft zu ungültigen oder grammatikalisch fehlerhaften Ergebnissen führt.

Dieser Artikel stellt **Pangu** vor, einen neuartigen Rahmen für das grundierte Sprachverständnis. Pangu trennt die Aufgaben der Diskriminierung und Generierung: Ein symbolischer Agent schlägt Pläne vor, während ein Sprachmodell diese bewertet und rangiert.

Im Fokus steht die Anwendung auf Wissensbasierte Frage-Antwort-Systeme, aber Pangu ist generisch und kann auf andere Szenarien übertragen werden. Experimente mit BERT, T5 und großen Modellen wie Codex zeigen herausragende Leistung bei hoher Stichprobeneffizienz, selbst mit nur einem Demo-Beispiel.

**Schlussfolgerung:** Generierung ist für grundiertes Sprachverständnis möglicherweise nicht die optimale Strategie. Diskriminierung durch Sprachmodelle kann effektiver sein, wie Pangu demonstriert.</sample>
    <sample id="228">Die Autoren haben an vier Datensätzen experimentiert: AG News, MIND, SST2 und Enron Spam. Sie verwendeten das WikiText-Datenset, um die Wortfrequenzen zu zählen.</sample>
    <sample id="229"># **Detektion improvierbarer Behauptungen in argumentativen Texten**

Dieser Vortrag präsentiert eine gemeinsame Arbeit mit Henning Wachsmuth zur Unterstützung der argumentativen Schreibkompetenz durch die Identifizierung improvierbarer Behauptungen. Textüberarbeitungen sind ein entscheidender Aspekt professionellen Schreibens und oft ein iterativer Prozess. In argumentativen Texten ist die richtige Wortwahl entscheidend, um die gewünschte Wirkung auf das Publikum zu erzielen.

Die Studie konzentriert sich auf zwei Hauptaufgaben: 1. **Suboptimal-Behauptungs-Detektion**: Bestimmung, ob eine Behauptung Überarbeitungen benötigt oder optimal formuliert ist. 2. **Verbesserungsvorschlag für Behauptungen**: Auswahl der zu verbessernden Qualitätsaspekte bei der Überarbeitung.

Anstatt direkt aus menschlichen Überarbeitungsmustern zu lernen, untersuchen die Autoren die Herausforderungen bei der Nutzung von Überarbeitungs-basierten Daten. Sie identifizieren vier Hauptprobleme: 1. **Repräsentativität und Zuverlässigkeit**: Erstellung eines zuverlässigen Datensatzes, der die Argumentqualität repräsentativ abbildet. 2. **Modellkomplexität und -architektur**: Auswahl eines Modells, das Überarbeitungen effektiv erfasst. 3. **Kontextabhängigkeit**: Bestimmung relevanter Kontextfaktoren für Argumentqualität. 4. **Topische und Benutzerverzerrung**: Berücksichtigung von Kontroversen und kulturellen Einflüssen in Online-Debatten.

Die Ergebnisse zeigen, dass Überarbeitungs-basierte Daten für die Aufgaben nützlich sind, und schlagen Methoden vor, um die Herausforderungen zu bewältigen. Die Studie betont die Bedeutung des Modelldesigns und der Kontextfaktoren bei der Bewertung argumentativer Texte.</sample>
    <sample id="231">NACHOS ist ein Datensatz mit medizinischen Inhalten aus dem Web, der für die Pre-Training eines biomedicalen Modells in französischer Sprache verwendet wurde.</sample>
    <sample id="232">Der/die Referent*in heißt David Vilar.</sample>
    <sample id="233">**Abstract:**

Die Arbeit "Attention as a Guide for Simultaneous Speech Translation" (SimulST) von Sara Papi, Matteo Negri und Marco Turchi zielt darauf ab, die Echtzeit-Übersetzung gesprochener Sprache zu verbessern. Aktuelle SimulST-Modelle erfordern oft spezifische Architekturen und komplexe Trainingsverfahren, was die Implementierung erschwert.

Die Autoren schlagen EDAtt (Encoder-Decoder Attention) vor, eine Strategie, die bestehende Offline-Sprachübersetzungsmodelle (ST) nutzt, ohne sie neu zu trainieren. EDAtt entscheidet, ob ein Wort übersetzt werden soll, basierend auf der Aufmerksamkeitsverteilung zwischen Audio- und Textausgabe. Wörter werden nur dann ausgegeben, wenn die Aufmerksamkeit nicht auf die letzten Teile des Audios konzentriert ist, was eine stabile Informationsgrundlage gewährleistet.

Im Vergleich zu etablierten Strategien wie Wait-k und Local Agreement sowie einem State-of-the-Art-Modell übertrifft EDAtt die Leistung bei gleichzeitiger Übersetzung und ist in Bezug auf die Verarbeitungszeit die schnellste Methode. Die Studie demonstriert, wie die Aufmerksamkeitsmechanismen von ST-Modellen effektiv genutzt werden können, um die Herausforderungen der SimulST zu bewältigen.

Die Forscher haben den Code, die Modelle und die Ergebnisse offen zugänglich gemacht, um die Reproduzierbarkeit zu fördern.</sample>
    <sample id="234">Die Prompt-Strategie hat einen erheblichen Einfluss auf die Ergebnisse der Übersetzung mit großen Sprachmodellen (LLMs). Experimente zeigten, dass eine sorgfältig ausgewählte 5-Shot-Prompting-Strategie die Leistung um bis zu 40 BLEURT-Punkte verbessern kann. Die Qualität der Beispiele (Prompt-Beispiele) ist entscheidender als die Ähnlichkeit mit der Quell-Satzstruktur, wobei hochwertige, kuratierte Beispiele bessere Ergebnisse liefern.</sample>
    <sample id="235">Die Autoren gehören an die **Carnegie Mellon University**, wie in der Präsentation erwähnt. Konkret sind sie Teil des Teams um Patrick Fernandes, Emmy Liu, André F. T. Martins und Graham Neubig.</sample>
    <sample id="236">Die 5 Anweisungen der Expert*innen für jede Aufgabe in MultiInstruct sind **schrittweise Anweisungen**, die spezifisch auf die jeweilige Multi-Modal-Aufgabe zugeschnitten sind. Jede Aufgabe verfügt über 5 verschiedene, aber gleichwertige Anweisungen, um die Modellleistung zu verbessern.</sample>
    <sample id="237">Die Autoren schlagen vor, ein diagnostisches Testsuite namens **KITMUS (Knowledge Integration from Multiple Sources)** zu verwenden. Diese Suite umfasst eine **Coreference-Resolution-Aufgabe**, die die Fähigkeit von Modellen testet, Wissen aus verschiedenen Quellen zu integrieren.</sample>
    <sample id="238">**Abstract:**

Yebowen Hu von der University of Central Florida stellt das neue Benchmark-Dataset **MeetingBank** vor, das speziell für die Zusammenfassung von Stadtrats- und anderen öffentlichen Sitzungen entwickelt wurde. Die Herausforderungen bestanden darin, qualitativ hochwertige Zusammenfassungen zu erstellen und vertrauenswürdige Ressourcen für öffentliche Meetings zu finden.

MeetingBank umfasst 1.366 Stadtratsmeetungen mit insgesamt fast 7.000 Zusammenfassungsinstanzen. Die Daten wurden mithilfe von Speechmatics API und der Meeting-Websites gesammelt. Die Zusammenfassungen wurden mit zwei Metriken analysiert: **Abdeckung** (Prozentsatz der Zusammenfassungswörter im Transkript) und **Dichte** (Grad der Bearbeitung der Zusammenfassungen).

Hu evaluierte verschiedene Summarisierungssysteme, darunter sowohl extraktive (Oracle, LexRank) als auch abstrakte (BART-Large, DialogLM) Modelle. Die Ergebnisse zeigten, dass DialogLM die höchsten ROUGE-2-Scores erreichte, während GPT-3, trotz schlechter automatischer Metriken, bei der menschlichen Bewertung hervorragend abschnitt, insbesondere in Fluenz und Kohärenz.

MeetingBank dient als wertvolles Werkzeug für Forscher und Entwickler im Bereich der Zusammenfassungstechnologien und bietet Einblicke in die Entscheidungsfindung von Stadtratsgremien. Hu lädt die Community ein, das Dataset herunterzuladen und zu nutzen.</sample>
    <sample id="239">## Zusammenfassung der Arbeit "Prompting PaLM für die Übersetzung: Bewertung von Strategien und Leistung"

Hallo zusammen, ich bin David Vilar und ich werde eine kurze Rezension der Arbeit "Prompting PaLM für die Übersetzung: Bewertung von Strategien und Leistung" vorstellen. Diese Arbeit ist eine gemeinsame Veröffentlichung mit Kollegen von Google Translate. PaLM ist ein 540 Milliarden Parameter umfassender Sprachmodell, das im letzten Jahr 2022 vorgestellt wurde. Es wurde auf einer riesigen Textsammlung mit 780 Milliarden Token trainiert und zum Zeitpunkt der Veröffentlichung auf hunderten NLP-Aufgaben (Natural Language Processing) zum Besten seiner Klasse gekürt.

In dieser Arbeit präsentieren wir die erste systematische Untersuchung der Verwendung von Prompting bei großen Sprachmodellen (LLMs) für die maschinelle Übersetzung. Wir untersuchten die Übersetzungsfähigkeiten dieser Modelle unter Verwendung der bewährten Methoden der Übersetzungscommunity. Dazu gehört die Verwendung der neuesten Testdatensätze, um eine Überschneidung mit den Trainingsdaten des Sprachmodells zu vermeiden. Wir verglichen die Ergebnisse mit den besten Systemen der WMT-Bewertung (Workshop on Machine Translation). Wir nutzten modernste neuronale MT-Metriken und ergänzten diese um Ergebnisse aus menschlicher Bewertung durch Experten.

Schließlich geben wir Empfehlungen für die Auswahl von Prompting-Strategien ab. Wie wir in einem einfachen Experiment feststellten, hat das Prompting einen erheblichen Einfluss auf die Leistung von LLMs bei der Übersetzung. Bei der Verwendung von ein- und mehrfacher Prompting-Eingabe für jede Satzpaare ergab sich bei 516 von 1000 Sätzen ein Unterschied von mehr als einem BLEURT-Punkt, in extremen Fällen sogar bis zu 40 BLEURT-Punkten. Daher ist die Auswahl der richtigen Strategie entscheidend.

In unseren Experimenten entschieden wir uns für eine 5-Shot-Prompting-Strategie, bei der wir jedes Satzpaar, das dem System präsentiert wird, mit der entsprechenden Sprache kennzeichnen. Wir stellten fest, dass die Form des Promptings bei mehreren kurzen Promptings weniger wichtig ist, während sie für ein- und null-Shot-Promptings entscheidend ist. Bei fünf-Shot-Prompting spielt die tatsächliche Form keine große Rolle mehr, vielmehr sind die Beispiele entscheidend.

Unsere experimentellen Ergebnisse lassen sich zusammenfassen: Die Qualität der Beispiele ist wichtiger als die Ähnlichkeit zum Quelltext. Daher ist es entscheidend, hochwertige Beispiele auszuwählen. Wir verglichen beispielsweise die Verwendung von Prompts aus dem Trainingsdatensatz mit denen aus den WMT-Dev-Daten. Die Dev-Daten sind viel kuratierter und qualitativ hochwertiger als der Trainingsdatensatz, und die Ergebnisse zeigten eine bessere Leistung.

Trotzdem haben spezialisierte, staat-der-Kunst-Systeme einen erheblichen Vorteil gegenüber den Übersetzungen von PaLM. PaLM kommt jedoch sehr nahe an die Leistung kommerzieller Systeme heran. In unserer Bewertung verwendeten wir Google Translate. Die Erkenntnisse aus der menschlichen Bewertung mit dem MQM-Rahmen (Multidimensional Quality Metrics) zeigten, dass PaLM in Bezug auf die Fließfähigkeit mit den besten Systemen mithalten kann, während die Hauptunterschiede in der Genauigkeit liegen. Insbesondere sind die häufigsten Fehler bei PaLM Weglassungen, was bedeutet, dass das Modell manchmal Teile des Quelltextes weglässt, um eine bessere klingende Übersetzung zu erzeugen. Die Kategorie "Stil/Unnatürlich" für PaLM ist jedoch niedriger als bei den besten Systemen, was ein zusätzlicher Hinweis darauf ist, dass PaLM flüssige, aber dennoch genauere Übersetzungen liefert.

Das war ein kurzer Überblick. Für detailliertere Informationen verweisen wir auf die vollständige Präsentation der Arbeit. Vielen Dank.</sample>
    <sample id="240">##  Schwächere Daten als gedacht: Eine kritische Betrachtung des schwach überwachten Lernens

Hallo, ich bin Dawei, Doktorand an der Saarland-Universität in Deutschland. In diesem Video möchte ich euch unsere aktuelle Arbeit vorstellen: **"Schwächer als gedacht: Eine kritische Betrachtung des schwach überwachten Lernens"**. Diese Arbeit ist eine gemeinsame Leistung von Xiaoyu Shen, Marius Mosbach, Andreas Stephan und Dietrich Klakow.

Lassen Sie uns zunächst einen kurzen Einblick in das Konzept des **schwach überwachten Lernens (WSL)** geben. Im Gegensatz zur herkömmlichen Methode, bei der Daten manuell beschriftet werden, nutzt WSL **schwach beschriftete Datenquellen** wie einfache Heuristiken, Wissensdatenbanken oder Low-Quality-Crowdsourcing (wie im Bild rechts dargestellt). Während diese Methoden günstiger sind, sind sie auch fehleranfällig. Wenn neuronale Netze direkt auf schwach beschrifteten Daten trainiert werden, neigen sie dazu, die Fehler in den Beschriftungen zu memorieren und nicht zu generalisieren.

WSL-Algorithmen zielen darauf ab, neuronale Netze robust zu trainieren, um trotz der Beschriftungsfehler eine gute Generalisierung zu erreichen. In jüngster Zeit wird oft behauptet, dass man mit WSL-Methoden Modelle auf schwach beschrifteten Daten trainieren und dennoch hervorragende Leistungen auf sauberen Testdatensätzen erzielen kann. Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken: Normalerweise geht man davon aus, dass ein **sauberes Validierungsset** zur Auswahl des Modells verfügbar ist. Dieses Problem dürfen wir nicht ignorieren; es impliziert, dass man zusätzliche manuelle Beschriftungen benötigt. Doch diese Notwendigkeit wird oft im Raum stehen gelassen, wie ein Elefant im Raum.

Unsere Arbeit stellt drei Forschungsfragen:

1. **Ist sauberes Validierungsdaten notwendig für WSL oder können wir stattdessen ein schwach beschriftetes Validierungsset nutzen?**
2. **Wenn sauberes Daten für WSL erforderlich ist, wie viele saubere Beispiele benötigen wir?**
3. **Sollten wir saubere Beispiele nur für die Validierung nutzen oder gibt es effizientere Möglichkeiten?**

In unserer Arbeit haben wir diese Fragen untersucht und folgende Erkenntnisse gewonnen:

* **WSL-Methoden benötigen tatsächlich saubere Validierungsdaten, um effektiv zu funktionieren.** Ohne saubere Validierungsdaten kann das trainierte Modell nicht über die ursprünglichen schwachen Beschriftungen hinaus generalisieren, wie die Abbildung zeigt. Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber beschriftete Daten benötigen, und die Kosten für die Beschaffung sauberer Validierungsdaten sollten nicht unterschätzt werden.

* **Die Anzahl sauberer Validierungsproben beeinflusst die Leistung von WSL-Methoden.** Wie die Abbildung auf der linken Seite zeigt, benötigt man typischerweise nur 20 Proben pro Klasse, um hohe Leistungen zu erzielen. Wenn man jedoch saubere Proben nutzt, kann man sogar noch bessere Ergebnisse erzielen. Die Abbildung auf der rechten Seite zeigt, dass direktes Fine-Tuning auf sauberen Daten in einigen Fällen bessere Ergebnisse liefert als WSL-Methoden, die nur die sauberen Daten für die Validierung nutzen.

* **Die Leistungssteigerung, die in früheren WSL-Arbeiten behauptet wurde, kann oft durch einfaches Fortsetzen des Trainings auf sauberen Validierungsdaten erreicht werden.** Wie die Abbildungen zeigen, schneidet das einfache Modell (FTw) zu Beginn schlechter ab als komplexere WSL-Methoden wie COSINE. Doch wenn man es erlaubt, auf den sauberen Daten weiter zu trainieren, erreicht FTw eine ähnliche Leistung wie andere Methoden. In der Praxis gibt es daher keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz benötigen.

**Zusammenfassend** haben wir gezeigt, dass moderne WSL-Methoden saubere, manuell beschriftete Daten benötigen, um effektiv zu funktionieren. Ihre Leistungssteigerung und Praktikabilität sind übertrieben.

Für zukünftige Arbeiten empfehlen wir:

* **Transparenz bei der Modellauswahl:** Angabe, ob die Modellauswahl über saubere Validierungsdaten erfolgt.
* **Vergleich mit Few-Shot-Learning-Basen:** Beide Ansätze arbeiten mit sauberen Daten.
* **Erforschung des kontinuierlichen Fine-Tuning:** Dies stellt eine einfache und starke Alternative zu WSL-Methoden dar.

Unseren Open-Source-Code finden Sie im QR-Code auf dieser Folie. Viel Spaß beim Ausprobieren!</sample>
    <sample id="241">**Abstract:**

Unsere Studie, "Human-in-the-loop Evaluation for Early Misinformation Detection", untersucht realistische Methoden zur automatischen Erkennung von Falschinformationen auf sozialen Medienplattformen, insbesondere im Kontext von COVID-19-Behandlungen. Vorherige Ansätze litten unter unrealistischen Evaluierungen und fehlender Einbeziehung menschlicher Moderatoren.

Wir schlagen ein **Human-in-the-Loop-Framework** vor, das Systeme entwickelt, die menschliche Feedback-Schleifen integrieren, um die Erkennung und Überprüfung von Falschinformationen zu verbessern. Unser System besteht aus zwei Komponenten:

1. **Misleidende Behauptungen erkennen:** Ein T5-Modell extrahiert Behauptungen aus Tweets und bewertet ihre Popularität, bevor sie zur Überprüfung an Menschen weitergeleitet werden.
2. **Policy-Verstöße überprüfen:** Ein BERT-basiertes Stance-Klassifikationsmodell identifiziert Tweets, die unzugelassene Behandlungen befürworten, und markiert sie für menschliche Überprüfung.

Wir bewerten unsere Methode anhand von COVID-19-Behandlungsansätzen und messen die Effizienz der Falschinformationenerkennung und -überprüfung. Unsere Ergebnisse zeigen, dass das System 65% der Policy-Verstöße korrekt identifiziert und 124,2 Verstöße pro menschlicher Arbeitsstunde überprüfen kann.

Unser Ansatz bietet einen realistischeren Rahmen für die Entwicklung und Evaluierung von Misinformation-Detektionssystemen und unterstreicht die Bedeutung der Zusammenarbeit zwischen Technologie und menschlicher Expertise.</sample>
    <sample id="242">Gängige Bewertungsmethoden für Dialogsysteme umfassen:

1. **Human-Bewertung**: Menschen wählen zwischen zwei Dialogen oder bewerten sie auf einer Likert-Skala.
2. **Komparative Bewertung**: Menschen bewerten mehrere Dimensionen der Dialogqualität, wie z.B. Relevanz der Antworten.
3. **Likert-Skalen auf Turn- oder Dialogebene**: Bewertung der Dialogqualität auf feineren Ebenen.
4. **Paareweise Vergleichsbewertungen**: Vergleich von Dialogen auf Dialogebene.</sample>
    <sample id="243">An der Arbeit sind 4 Autoren beteiligt: Jenny (als Präsentatorin), Sebastian Santy, Ronan Le Bras und Katharina Reinecke. Ein weiterer Autor, Maarten Sap, wird ebenfalls erwähnt.</sample>
    <sample id="244">Im Beispiel mit Servin und Kea ist das erforderliche Hintergrundwissen:

* **Entitätsspezifisches Wissen:** "Servin ist ein Richter."
* **Allgemeines Wissen:** "Richter entscheiden über Fälle in Gerichtssälen."</sample>
    <sample id="245">**Abstract**

In unserer Studie "A Needle in a Haystack: An Analysis of High-Agreement Workers on MTurk for Summarization" untersuchen wir effektive Methoden zur Rekrutierung hochkooperierender Amazon Mechanical Turk (MTurk) Arbeiter für Textzusammenfassungen. Unser Ansatz besteht aus einem zweistufigen Pipeline-System.

Zunächst definieren wir strenge Qualifikationskriterien, einschließlich Standort, abgeschlossener Human Intelligence Tasks (HITs) und HIT-Genehmigungsrate. Im ersten Schritt bewerten die Arbeiter ihre Fähigkeiten in der Beurteilung mehrerer Dimensionen von Zusammenfassungen. Dies führt zur Kategorisierung in Gold-, Silber-, Bronze- und Block-Arbeiter, wobei nur Gold- und Silber-Arbeiter fortfahren.

Im zweiten Schritt testen wir die Ausdauer der Arbeiter unter hohem Arbeitsaufkommen. Die Ergebnisse zeigen, dass 6% der Teilnehmer (12 MTurk-Arbeiter) sowohl in der Inter-annotator-Übereinstimmung (IAA) als auch in der Genauigkeit über Experten hinaus hochkooperierend waren.

Wir vergleichen unsere Pipeline-Arbeiter mit Baseline-MTurk-Arbeitern, die mit verschiedenen Filtern optimiert wurden, und CloudResearch-Arbeitern. Unsere Analyse zeigt, dass unser Pipeline-System hochkooperative Arbeiter zu einem ähnlichen Preis wie CloudResearch identifizieren kann.

Zukünftige Arbeiten werden sich auf die Erweiterung auf verschiedene Sprachen, Aufgaben und Plattformen konzentrieren. Einschränkungen umfassen den Fokus auf englische Zusammenfassungen und die Notwendigkeit, die Fragegestaltung weiter zu optimieren.</sample>
    <sample id="246">Ja, der Code ist auf GitHub verfügbar.</sample>
    <sample id="247">**Abstract:**

In dieser Arbeit stellen wir *FactKG* vor, ein neues Dataset für die Faktenüberprüfung basierend auf Wissensgraphen (Knowledge Graphs, KG). Bisherige Ansätze nutzten Text oder Tabellen als Beweise, während Wissensgraphen eine direktere und zuverlässigere Verbindung zwischen Behauptungen und Beweisen ermöglichen.

Unser Dataset *FactKG* basiert auf DBpedia und enthält Behauptungen in zwei Stilen: geschrieben und kolloquial. Jede Behauptung ist mit einem der Labels *Unterstützt* oder *Rückgängig gemacht* gekennzeichnet. Die Aufgabe besteht darin, Beweise aus dem Wissensgraphen zu extrahieren und die Behauptung mithilfe dieser Beweise zu überprüfen.

Wir definieren fünf Arten des Denkens, um Behauptungen zu überprüfen: ein-Hop, Konjunktion, Existenz, mehrfaches Hop und Negation. Ein-Hop-Behauptungen erfordern die Überprüfung einer Verbindung zwischen zwei Entitäten, während komplexere Behauptungen mehrere Schritte oder zusätzliche Überlegungen erfordern.

*FactKG* bietet praktische Anwendungen, insbesondere für Dialogsysteme, die mit internen Wissensgraphen interagieren. Wir präsentieren auch Baseline-Modelle, die nur Behauptungen oder mit GEAR (Graph Evidence Augmented Reasoner) nutzende Modelle, die Beweise aus dem Wissensgraphen einbeziehen. Die Ergebnisse zeigen, dass GEAR signifikant bessere Ergebnisse erzielt als alle anderen Modelle.

Das Dataset und weitere Informationen sind verfügbar.</sample>
    <sample id="248">Nein, die Annotatoren für NLPositionality sind **nicht** in Bezug auf jede demographische Gruppe ausgewogen. Die Studie betont, dass nur wenige Annotatoren pro Instanz beteiligt sind und Demografiedaten oft nicht erfasst oder geteilt werden. Um eine ausgewogenere Darstellung zu erreichen, wurde eine große Anzahl von Annotatoren aus 87 Ländern rekrutiert.</sample>
    <sample id="249">Sätze innerhalb der akzeptablen Domain wurden durcheinander gebracht, indem akzeptable und unakzeptable Sätze aus den gleichen Datenbanken (z.B. BLiMP oder SyntaxGym) ausgewählt und als Präfixe zu den Test-Sätzen hinzugefügt wurden. Dies führte zu signifikanten Veränderungen in den akzeptabilitätsbezogenen Urteilen (MPP-Judgmenten) des Modells.</sample>
    <sample id="250">Eine dimensionale Bewertung, im Kontext von ABC-Eval, bedeutet, die Qualität eines Dialogmodells entlang mehrerer spezifischer und klar definierter Aspekte zu messen, anstatt nur eine allgemeine Bewertung abzugeben. Anstatt nur Holistisches zu bewerten, identifiziert und quantifiziert es spezifische Verhaltensweisen des Modells, wie z.B. Relevanz, Selbst- oder Partnerkontradiktionen, Irrelevanz usw.</sample>
    <sample id="251">Die Autoren gehören der University of Science and Technology of China an.</sample>
    <sample id="252">**Abstract:**

Die Präsentation stellt "U-CREAT: Unsupervised Case Retrieval using Events extrAcTion" vor, eine Forschungsergebnisse von Sai Kiran Tanikella und Kollegen vom IIT Kanpur. Das Ziel ist die Bewältigung der Herausforderung, relevante frühere Urteile (zitierte Dokumente) für Rechtsfachleute wie Anwälte und Richter in einer wachsenden Fülle von Fällen zu finden.

Die Arbeit führt zwei Hauptbeiträge ein: den Indian Legal Prior Case Retrieval Dataset (IL-PCR) und die U-CREAT-Pipeline. Der IL-PCR-Datensatz bietet eine umfassende Testumgebung mit 7.070 Rechtsfällen und durchschnittlich 6.775 Zitaten pro Dokument. Die U-CREAT-Pipeline nutzt unüberwachte Lerntechniken und einen event-basierten Ansatz, der hohe Rückrufraten, schnelle Inferenzzeiten und Generalisierungsfähigkeit ohne spezifische Anpassung an Rechtssysteme oder Demografien aufweist.

Die Event-Extraktion basiert auf Dependency Parsing und erzeugt Tripletts aus Subjekt-Verb-Objekt-Beziehungen. Diese Tripletts repräsentieren Ereignisse. Die Pipeline berechnet eine Interaktionsmatrix zwischen Query- und Kandidatenereignissen, um ein Ranking der Kandidaten zu erstellen.

Experimente mit verschiedenen Modellen, einschließlich count-basierter, transformer-basierter und event-basierter Ansätze, zeigten, dass event-basierte Modelle, insbesondere das Event Filtered Documents-Modell, die besten Ergebnisse lieferten. U-CREAT übertrifft bestehende Ansätze und stellt einen neuen State-of-the-Art für Prior Case Retrieval dar.</sample>
    <sample id="253"># **DisorBERT: Erkennung von Anzeichen psychischer Störungen in sozialen Medien**

Diese Forschung präsentiert DisorBERT, ein Modell für die Doppeldomänenanpassung, das darauf abzielt, Anzeichen von psychischen Störungen in sozialen Medien zu erkennen. Psychische Störungen wie Depression, PTSD, Bulimie und Anorexie beeinflussen das Denken, Fühlen, die Stimmung und das Verhalten. Soziale Medien bieten eine umfangreiche Datenquelle, um diese Herausforderungen zu untersuchen, da Menschen oft ihre Erfahrungen öffentlich teilen.

Das Modell nutzt die Leistung von BERT, einem Sprachmodell, das auf Wikipedia und Google Books trainiert wurde, und passt es an die spezifische Sprache von Reddit und den Bereich der psychischen Gesundheit an. Dieser Prozess, bekannt als Domänenanpassung, verbessert die semantische Verständnisfähigkeit des Modells und ermöglicht es ihm, sich auf die Erkennung von Anzeichen psychischer Störungen zu konzentrieren.

Die Studie zeigt, dass DisorBERT im Vergleich zu Basismodellen und anderen Ansätzen wie MentalBERT bessere Ergebnisse erzielt. Es konzentriert sich auf wichtige Wörter und Konzepte, die mit psychischen Störungen in Verbindung stehen, wie z. B. "anxious" (angstlich) und "medication" (Medikation). Durch die Analyse von Textsegmenten und die Verwendung eines Lexikons zur Maskierung wird das Modell geschult, relevante Informationen zu extrahieren.

Die Ergebnisse deuten darauf hin, dass die Kombination aus Doppeldomänenanpassung und Maskierung eine vielversprechende Methode ist, um Benutzer mit psychischen Störungen in sozialen Medien zu identifizieren und zu unterstützen. Zukünftige Arbeiten werden verschiedene Lexika und klinische Daten erkunden, um die Effektivität weiter zu verbessern.</sample>
    <sample id="254">**Abstract:**

Unsere Forschung, "Uncertainty Guided Label Denoising für Dokument-level Distant Relation Extraction", zielt darauf ab, die Herausforderungen bei der Nutzung von distanzüberwachten Daten (DS) für die Extraktion von Beziehungen zwischen Entitäten in Dokumenten anzugehen. Vorherige Methoden stützen sich auf aufwendig annotierte Korpora, was zeit- und arbeitsintensiv ist. Neuere Ansätze nutzen DS-Daten, aber diese enthalten oft Rauschen, das durch falsch-positive Pseudo-Labels verstärkt wird.

Wir schlagen ein neues Framework vor, das Unsicherheitsschätzungen integriert, um die Qualität von DS-Labels zu verbessern. Unser Ansatz umfasst:

1. **Vorab-Denoising DocRE Modell:** Trainiert mit DS- und annotierten Daten, um Pseudo-Labels zu generieren.
2. **Instanz-Level Unsicherheitsschätzung:** Für überlappende Beziehungen, um Unsicherheiten zu erfassen und falsche Positiven zu reduzieren.
3. **Dynamische Klasseneinheits-Unsicherheits-Schwellen:** Filtern von Pseudo-Labels mit hoher Unsicherheit, besonders für lange Schwanz-Klassen.
4. **Iteratives Rebell-Strategie:** Mehrphasiges Training, das DS-Daten nutzt und die Leistung verbessert.

Unsere Methode übertrifft bestehende Ansätze auf öffentlichen Datensätzen, demonstriert durch signifikante Leistungssteigerungen. Durch die Integration von Unsicherheitsschätzungen bieten wir eine effektive Lösung für die Herausforderungen bei der Nutzung von DS-Daten in der Dokument-level Relation Extraction.</sample>
    <sample id="255">Die Form des Prompts ist **besonders bei sehr kurzen Promptings (z.B. Zero-Shot oder One-Shot) wichtig**. Bei längeren Promptings (wie einem 5-Shot-Ansatz) hat die Form jedoch weniger Einfluss, während die **Qualität und Relevanz der Beispiele** entscheidender sind.</sample>
    <sample id="257">Die Autoren haben vier state-of-the-art (aktuell beste) Dialogmodelle evaluiert.</sample>
    <sample id="258">**Abstract:**

Die Studie "Can Large Language Models Be an Alternative to Human Evaluation?" untersucht die Möglichkeit, große Sprachmodelle (Large Language Models, LLM) zur Bewertung der Qualität von Texten in der natürlichen Sprachverarbeitung (NLP) einzusetzen. Im Gegensatz zu traditionellen menschlichen Bewertungen, die instabil und reproduktionsschwer sind, schlagen die Autoren LLM als Alternative vor.

Die Forschung beinhaltet ein Experiment, bei dem LLM wie GPT-2 und menschlich geschriebene Geschichten auf vier Kriterien hin bewertet werden: Grammatik, Kohärenz, Beliebtheit und Relevanz. Die Ergebnisse zeigen, dass englische Lehrer, als Experten für die Bewertung von Essays, menschliche Geschichten gegenüber GPT-2-Geschichten bevorzugen.

Besonders hervorheben ist, dass zwei leistungsstarke LLM, Davinci und ChatGPT, eine klare Präferenz für menschlich geschriebene Texte zeigten. Dies deutet darauf hin, dass bestimmte LLM als Ersatz für menschliche Bewertungen in NLP-Aufgaben geeignet sein könnten.

Die Studie beantwortet wichtige Fragen zur Übereinstimmung zwischen LLM und menschlichen Bewertungen, zur Robustheit der Methode gegenüber Variationen in Anweisungen und zur Auswahl von LLM-Antworten. Außerdem werden Vorteile und Nachteile gegenüber traditionellen menschlichen Bewertungen diskutiert. Weitere Ergebnisse und Details sind im vollständigen Papier zu finden.</sample>
    <sample id="259"># **XSemPLR: Ein universeller Ansatz für die mehrsprachige semantische Analyse**

Die Arbeit präsentiert XSemPLR, eine umfassende Plattform für die Bewertung von mehrsprachigen semantischen Analysemodellen. Das Ziel ist es, die Übersetzung und Interpretation von Benutzerabfragen in verschiedenen natürlichen Sprachen und semantischen Darstellungen zu ermöglichen.

Bisherige Ansätze konzentrierten sich oft auf einzelne Sprachen oder semantische Darstellungen, wobei chinesische Sprachen und Lambda-Kalkül unterrepräsentiert waren. XSemPLR überwindet diese Lücken, indem es 22 Sprachen in 15 Familien abdeckt und 5 semantische Parsing-Aufgaben sowie 8 Darstellungen umfasst.

Die Studie schlägt sechs Evaluierungs-Szenarien vor, darunter Translate-Test, Monolingual (eine Sprache), Few-shot (begrenzte Trainingsdaten) und Multilingual (mehrere Sprachen) Modelle. Die Ergebnisse zeigen, dass Encoder-Decoder-Modelle in allen Szenarien die besten Leistungen erbringen.

Ein wichtiger Befund ist der signifikante Leistungsunterschied zwischen Zero-shot und Few-shot Transfer zwischen Sprachen, wobei der Few-shot Transfer die Lücke schnell schließt. Die Forschung hebt auch die Herausforderungen bei der Bewältigung der "Fluch der Multilingualität" hervor, wo die Leistung in einigen Sprachen abnimmt.

Zusammenfassend bietet XSemPLR eine wertvolle Ressource für die Forschung im Bereich mehrsprachiger semantischer Analyse und liefert Erkenntnisse über die Effektivität verschiedener Modelle in verschiedenen Szenarien.</sample>
    <sample id="260">Basierend auf dem beschriebenen Inhalt, ist Jingwei Yi der einzige Autor, der erwähnt wird. Es wird nicht explizit auf weitere Mitautoren hingewiesen. Daher ist die Antwort **1 Autor**.</sample>
    <sample id="261">Ein guter Planer sollte in der Lage sein, **scripts zu schreiben, die sowohl semantisch vollständig als auch treu gegenüber den gegebenen Einschränkungen sind**. 

Die Präsentation hebt hervor, dass ein guter Planer:

* **Semantisch sinnvoll** (vollständige und kohärente Anweisungen)
* **Einschränkungen beachtet** (treu den spezifischen Anforderungen einer Aufgabe folgt)</sample>
    <sample id="262">Basierend auf dem beschriebenen Inhalt, ist **ein** Autor genannt: Siyu Yuan von Fudan University.

Obwohl der Text auf eine Zusammenarbeit hinweist (z.B. "InstructGPT" und "unsere Methode"), wird klar erwähnt, dass **Siyu Yuan** der Hauptverfasser und Vertreter der Arbeit ist.</sample>
    <sample id="263">**Zusammenfassung:**

Unsere Arbeit mit dem Titel "Mitigating Label Biases for In-context Learning" untersucht die Instabilität von In-context Learning, einer Methode zur Nutzung großer Sprachmodelle. Vorherige Studien zeigten, dass Designentscheidungen wie die Auswahl und Reihenfolge von Beispielen die Vorhersagen von Modellen beeinflussen und Biases einführen. Wir kategorisieren und diskutieren bestehende Erkenntnisse über Bias-Probleme im In-context Learning und schlagen eine neue Methode zur Kalibrierung vor, um diese Effekte zu mildern.

Unsere Forschung identifiziert drei Arten von Label-Biases: Vanille-Label-Bias (unabhängig vom Kontext), Kontext-Label-Bias (von der Kontextwahl beeinflusst) und Domain-Label-Bias (durch die Aufgabe-Korpora beeinflusst). Durch Experimente bestätigen wir, dass Domain-Label-Bias die Leistung von Modellen erheblich beeinträchtigen kann.

Als Lösung stellen wir die *Domain-Context-Kalibrierung* vor. Diese Methode schätzt den Bias für jede Label-Klasse mit zufällig aus dem Aufgaben-Korporum ausgewählten Texten und kalibriert die Modellvorhersagen entsprechend. Im Vergleich zu früheren Ansätzen verbessert unsere Methode die In-context-Learning-Leistung signifikant, insbesondere bei Aufgaben mit hohem Domain-Label-Bias.

Unsere umfassenden Studien zeigen, dass die Verwendung mehrerer zufälliger In-Domain-Wörter effektiver ist als einzelne, vordefinierte Token, und dass die Berücksichtigung des Domain-Label-Bias zu besseren Kalibrierungsergebnissen führt. Unsere Arbeit bietet einen systematischen Ansatz zur Bewältigung von Biases im In-context Learning.</sample>
    <sample id="264"># **TAVT: Transferable Audio-Visual Text Generation**

Diese Arbeit präsentiert TAVT, eine innovative Methode für multimodale Textgenerierung, insbesondere für Audio-Visual-Text-Paare. Während Fortschritte in der einmodalen Textgenerierung durch große Modelle und Pre-Training erzielt wurden, ist die Datenannotation für multimodale Aufgaben kostspielig und herausfordernd.

TAVT zielt darauf ab, diese Barrieren zu überwinden, indem es ein transferierbares Lernparadigma vorschlägt. Der Hauptfokus liegt auf dem Umgang mit Domänenschichten in Audio und Video, wie Bildstil und Tonenergie. Die Forscher beobachten, dass die visuelle Inhaltsverständnis innerhalb eines Ereignisses stabil bleibt, während sich der visuelle Stil und die Aufnahmeeinstellung ändern. Im Gegensatz dazu beeinflusst die Veränderung der Audioinhalte das Ereignisverständnis weniger.

Das vorgeschlagene Framework besteht aus drei Komponenten:

1. **Audio-Visual Meta-Mapper**: Erstellt eine einheitliche Audio-Semantik-Raum, um visuelle Konzepte über Domänen hinweg abzubilden.
2. **Audio-Visual Encoder und Sprachmodellgenerator**: Verwendet Transformer-basierte Architekturen, um Text aus Audio-Visual-Eingaben zu generieren, mit einem Alpha-Faktor, der die Modalitätskontrolle ermöglicht.
3. **Dualer Gegenfaktischer Kontrastives Lernen (DCLL)**: Optimiert die visuelle-textuelle Ausrichtung ohne Abhängigkeit von negativen Proben.

Experimente auf MSVD und MSR-VTT zeigen, dass TAVT im Vergleich zu SOTA-Methoden überlegen ist, insbesondere in Low-Resource-Domänen. Die Ergebnisse demonstrieren die Wirksamkeit des Ansatzes für die generative Modellierung von Audio-Visual-Text-Daten.</sample>
    <sample id="265">Der/die Referentin heißt Vasudha.</sample>
    <sample id="266">Basierend auf dem präsentierten Inhalt scheint der Autor, Adam Przepiórkowski, mit der Syntax und Dependency Struktur in der Sprachwissenschaft zu beschäftigen. Es wird keine spezifische Universität genannt, aber die Referenz zu "the enhanced version of the Penn Treebank" deutet darauf hin, dass er mit Forschungseinrichtungen oder Universitäten in Verbindung mit dieser Datenbank oder dem Penn Language Network zusammenarbeitet.</sample>
    <sample id="268">Die häufigsten Fehler von PaLM sind **Omissionsfehler**, bei denen Teile des Quelltextes weggelassen werden, um eine bessere klangende Übersetzung zu erzeugen.</sample>
    <sample id="269">**Präsentation: ABC-Eval – Ein neuer dimensionaler Ansatz zur Bewertung von Konversations-KI**

Hallo, ich bin James Finch. Und hier ist meine Frau Sarah Finch. Heute möchten wir Ihnen ABC-Eval vorstellen, eine neue Methode zur Bewertung von Konversations-KI mit einer dimensionalen Herangehensweise. Diese Arbeit wurde vom NLP-Labor der Emory University unter der Leitung von Professor Jinho Choi und in Zusammenarbeit mit Amazon Alexa AI durchgeführt.

Angenommen, Sie haben ein Dialogmodell entwickelt und möchten wissen, wie es im Vergleich zum aktuellen Stand der Technik abschneidet. Die gängige Praxis besteht darin, menschliche Bewertungen einzuholen, beispielsweise indem man menschliche Richter bittet, zu entscheiden, welche der beiden Konversationen besser ist, oder sie bitten, Konversationen auf einer Likert-Skala zu bewerten. Diese Methoden eignen sich gut, um eine holistische Bewertung der Gesamtqualität von Dialogen zu erhalten. Da die Dialogqualität jedoch viele Aspekte umfasst, möchten Sie möglicherweise mehrere Dimensionen der Chat-Qualität bewerten, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen.

Eine Möglichkeit wäre, menschliche Richter einfach bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie beispielsweise die Relevanz der Modellantworten mithilfe bestehender vergleichender Methoden oder Likert-Skalen. Wir glauben jedoch, dass es eine präzisere und zuverlässigere Strategie für die dimensionale Dialogbewertung gibt. Unser Ansatz zielt darauf ab, die Subjektivität menschlicher Bewertungen zu verringern, indem explizit annotiert wird, ob jede Modellantwort bestimmte Verhaltensweisen aufweist, wie irrelevante Informationen oder Widersprüche. Wir nennen diesen Ansatz "Verhaltensannotationen in Chats" oder kurz ABC-Eval. Wir haben diese Methode entwickelt, um umfassend die Chat-Modellverhaltensweisen abzudecken, die in jüngster Literatur als einflussreich auf die Dialogqualität identifiziert wurden.

ABC-Eval ist in der Lage, die Häufigkeit verschiedener thematischer Fehler zu messen, die Chat-Modelle begehen können. Es misst beispielsweise die Anzahl der Runden, in denen ein Chat-Modell seinen Gesprächspartner ignoriert oder irrelevante Aussagen macht, sich selbst oder seinen Partner widerspricht, falsche Fakten erfindet oder gegen allgemeine Wissensregeln verstößt, und wann das Modell erfolgreich oder erfolglos Empathie zeigt.

Um zu ermitteln, welche Bewertungsmethode am effektivsten ist, haben wir vier State-of-the-Art-Chat-Modelle ausgewählt und sie auf 100 menschlich-Bot-Konversationen pro Modell mit ABC-Eval bewertet. Außerdem haben wir diese Konversationen mit drei bestehenden Methoden bewertet: Likert-Bewertungen auf Turn-Ebene, Likert-Bewertungen auf Dialogebene und dialogebene Paarvergleiche. Für jede bestehende Methode haben wir Bewertungen zu acht der am häufigsten gemessenen Dialogaspekte gesammelt, da dies der Standard in der Bewertung von Chat-Modellen über mehrere Dimensionen ist.

Aus unserer Analyse dieser Bewertungsergebnisse haben wir festgestellt, dass die ABC-Eval-Verhaltenslabels insgesamt zuverlässiger sind als die mit bestehenden Methoden gesammelten Labels, gemessen am Inter-Annotator-Abkommen auf 100 doppelt annotierten Konversationen. Außerdem sind die ABC-Eval-Labels prädictiver für die Gesamtkonversationsqualität als die Metriken, die durch bestehende Methoden erzeugt werden, wie diese einfache lineare Regressionsanalyse zeigt. Sie können beispielsweise sehen, wie die Messung des Anteils der Runden mit Selbst- und Partnerwidersprüchen 5% und 10% der Konversationsqualität erklärt, während die durchschnittlichen Likert-Konsistenzbewertungen nur 4% oder weniger erklären.

Schließlich haben wir überprüft, ob jede Bewertungsmetrik ein einzigartiges Aspekts der Chat-Qualität erfasst, indem wir eine schrittweise lineare Regression durchgeführt haben. Sie können sehen, wie die Kombination aller ABC-Eval-Metriken über 25% der Konversationsqualität erklärt, und wenn Sie die Metriken nacheinander entfernen, verliert die meisten davon eine beträchtliche Menge an Information über die Qualität. Im Gegensatz dazu erklärt die Kombination aller Turn-Level-Likert-Metriken viel weniger Qualität, und nur wenige dieser Metriken tragen einzigartige Informationen bei.

Diese zuverlässigen, informativen und einzigartigen ABC-Eval-Metriken ermöglichen eine detailliertere Bewertung von Konversations-KI als es vorherige Methoden schaffen. Wie Sie aus den Ergebnissen unseres Experiments sehen können, bleiben noch Herausforderungen, die jedoch präzise quantifiziert wurden. Zum Beispiel haben die Bots, die wir getestet haben, in etwa 20% ihrer Antworten Regelverstöße, in etwa 15% irrelevante Informationen und in etwa 10% Widersprüche gegenüber sich selbst oder ihrem Partner. Da sich das Feld mit rasantem Tempo weiterentwickelt, könnten viele dieser Fehlerraten bei neuen Modellen, die nach unserer Bewertung veröffentlicht werden, abnehmen. Genau deshalb ist es wichtig, zuverlässige und präzise Bewertungsmetriken zu verfolgen, um Modelle zu vergleichen. Wir hoffen, dass ABC-Eval für andere in der Branche ein bedeutender Schritt in diese Richtung ist, und wir freuen uns darauf, wie sich Konversations-KI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank fürs Zuschauen.</sample>
    <sample id="270">Die Autoren gehören der Emory University an, spezifisch dem Emory NLP Lab, das von Professor Jinho Choi geleitet wird.</sample>
    <sample id="271">In dieser Arbeit steht CFT für "Continuous Fine-tuning" (andauernde Feinabstimmung).</sample>
    <sample id="272">An der Arbeit sind 7 Autoren beteiligt: Koustav Sinha, John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy und Adina Williams.</sample>
    <sample id="273">## Präsentation: "Wenn Übersetzung Kontext erfordert: Eine datengesteuerte, mehrsprachige Erkundung"

**Einführung:**

Unsere Arbeit untersucht, wann und wie Übersetzungen Kontext benötigen. Wie im Beispiel mit dem Wort "Mole": Je nach vorherigem Satz kann es sich um einen Spion oder um einen Muttermal handeln. Solche kontextabhängigen Übersetzungen sind herausfordernd zu bewerten, da nur ein kleiner Anteil aller Übersetzungen von Kontext abhängt und gängige Metriken wie BLEU diese nicht erfassen.

**Forschungsfragen:**

1. **Wann erfordert Übersetzung Kontext?**
2. **Wie gut meistern Modelle diese Fälle?**

**Ansatz:**

Wir haben eine datengesteuerte Analyse über 14 Sprachpaare durchgeführt und das Konzept der **CXMI (Contextual Usage Measure for Machine Translation)** weiterentwickelt, um die Abhängigkeit von Kontext bei Übersetzungen zu messen.

**Erweiterte CXMI (Pointwise CXMI):**

- Auf Satz- oder Wortniveau kontextbezogene Informationsgewinnung messen.
- Wörter mit hohem P-CXMI benötigen oft Kontext für eine korrekte Übersetzung.

**Analyse:**

Wir untersuchten Wörter mit hohem P-CXMI und identifizierten Muster:

- **Part-of-Speech-Tags:**  Dualpronomen in Arabisch und die Notwendigkeit von Kontext für die richtige Verbform.
- **Vokabular:**  In Chinesisch erfordern Eigennamen Kontext, um Konsistenz innerhalb eines Dokuments zu gewährleisten. 
- **Individuelle Token:**  Ellipsenauflösung, die nicht nur vom Wort selbst, sondern vom Satzbau abhängt.

**MuDA-Tagger (Multilingual Discourse-Aware Tagger):**

Basierend auf den Erkenntnissen entwickelten wir einen Tagger, der automatisch Wörter identifiziert, die an fünf Diskursphänomenen beteiligt sind.

**Bewertung:**

- **Corpus-basierte Metriken:**

   - BLEU: Kontextunabhängige Modelle schneiden am besten ab.
   - COMET: Kontextbewusste Modelle übertreffen sie.
   - Word f-measure: Modelle mit und ohne Kontext sind vergleichbar.

- **MuDA-Benchmark:**

   - Kontextbewusste Modelle sind bei Phänomenen wie Formalität und lexikalischer Kohäsion präziser.
   - Bei Ellipsen, Pronomen und Verbform sind die Unterschiede geringer.

**Vergleich von Übersetzungssystemen:**

Unser Benchmark zeigt, dass DeepL in der Regel genauer als Google Translate bei der Dokumentenübersetzung ist.

**Fazit:**

Unsere Arbeit liefert einen datengesteuerten Einblick in kontextabhängige Übersetzungen und ermöglicht es, Modelle anhand von Diskursphänomenen zu bewerten. Der MuDA-Benchmark kann zur Verbesserung der Dokumentenübersetzung beitragen.

Vielen Dank für Ihre Aufmerksamkeit! Wir freuen uns auf den Austausch in Toronto.</sample>
    <sample id="274">Der/die Referent*in heißt Yusen Zhang.</sample>
    <sample id="276"># **IndicMT Eval: Eine Meta-Evaluierung von Maschinenübersetzungsmetriken für indische Sprachen**

Diese Arbeit untersucht die Bewertung von Übersetzungen in indische Sprachen, ein bisher unterstudiertes Gebiet. Die Autoren stellen ein Dataset namens *IndicMT Eval* vor, das aus 7.000 annotierten Beispielen aus fünf indischen Sprachen besteht: Tamil, Malayalam, Hindi, Marathi und Gujarati.

Das Projekt generiert mehrere Übersetzungsoptionen mithilfe von sieben verschiedenen Übersetzungssystemen und sammelt menschliche Bewertungen für diese Übersetzungen mit einem Fokus auf detaillierte Fehleranalyse. Die Fehlerkategorien umfassen Genauigkeit/Bedeutung, Fließfähigkeit und spezielle Fehler.

Die Analyse der Metriken zeigt gemischte Ergebnisse. Überlappungsbasierte Metriken wie chrF erzielen die höchsten Korrelationen, sind aber insgesamt weniger leistungsfähig. Embedding-basierte Metriken wie LabSE und BERTscore mit multilingualen Modellen zeigen bessere Korrelationen. COMET-Metriken erreichen die höchsten Korrelationen insgesamt.

Ein interessierender Befund ist die Skewierung der Metrik-Scores, wobei viele Metriken einen engen Score-Bereich aufweisen, während menschliche Bewertungen eine umfassendere Skala abdecken. Die Feinabstimmung der COMET-Metrik mit dem *IndicMT Eval* Dataset führt zu verbesserten Korrelationen im Vergleich zu Baselinemetriken.

Zusätzlich demonstriert die Studie die Zero-Shot-Fähigkeit der feinabgestimmten Metrik, indem sie auf nicht trainierte Sprachen angewendet wird, und zeigt ihre Robustheit in Vergleichstests. Das *IndicMT Eval* Dataset ist öffentlich verfügbar und soll die Forschung zur Bewertung von Übersetzungen in indischen Sprachen vorantreiben.</sample>
    <sample id="277">Die neue Methode hat keinen spezifischen Namen. Sie wird als "Multiset Tagging und Latent Permutationen" bezeichnet.</sample>
    <sample id="278">Die Methode der „markierten Wörter“ (Marked Words) vergleicht die generierten Personas mit einem System von „unmarkierten“ und „markierten“ Gruppen, um Wörter zu identifizieren, die bestimmte Gruppen von anderen unterscheiden. Sie nutzt das sociolinguistische Konzept der „Markierung“, bei dem abweichende Gruppen von einem sozialen oder linguistischen Standard markiert werden. In diesem Fall werden die Top-Wörter für jede markierte Gruppe identifiziert und mit den entsprechenden unmarkierten Gruppen (z.B. weiße Personen oder Männer) verglichen, um stereotype Muster aufzudecken.</sample>
    <sample id="279">Die Autoren gehören der University of Washington an.</sample>
    <sample id="280">**Abstract:**

Die Arbeit "MultiEMO: Ein auf Aufmerksamkeit basierendes Korrelationsbewusstes Multimodales Fusionsframework für die Emotionenerkennung in Gesprächen" von Shi Tao zielt darauf ab, die Herausforderungen bei der Erkennung von Emotionen in Gesprächen (ERC) anzugehen. Der Ansatz nutzt multimodale Informationen aus Text, Audio und Video, um präzisere Vorhersagen zu treffen.

Die bestehenden Methoden konzentrieren sich oft auf Textmodalitäten und vernachlässigen die Komplementarität anderer Modi. Shi Tao schlägt daher das MultiEMO-Framework vor, das vier Hauptkomponenten umfasst: Unimodale Merkmalsextraktion, Kontextmodellierung, multimodale Fusion und Klassifizierung.

Ein wichtiger Beitrag ist der Vorschlag des VisExtNet-Visual-Feature-Extractors, der Gesichtsausdrücke integriert, ohne redundante Szeneninformationen zu erfassen. Das MultiAttn-Modul nutzt bidirektionale, mehrköpfige Cross-Attention-Schichten, um die Modalitäten effektiv zu verschmelzen.

Ein weiterer Schlüsselaspekt ist die Einführung der Sample-Weighted Focal Contrast-Loss, die die Klassifizierung von Minderheits- und semantisch ähnlichen Emotionen verbessert, indem sie schwierige Beispielpaare betont.

Die Experimente auf MELD und IEMOCAP zeigen, dass MultiEMO den aktuellen Stand der Technik übertrifft, insbesondere bei der Unterscheidung schwieriger Emotionen. Trotzdem gibt es Herausforderungen, wie die Unterscheidung zwischen Sprechern und irrelevanten Personen und die Anforderung großer Batchgrößen für die SWFC-Loss.</sample>
    <sample id="281">**Abstract:**

Unsere Forschung, durchgeführt in Zusammenarbeit mit Patrick Fernandes, Emmy Liu, André F. T. Martins und Graham Neubig, untersucht, wann Übersetzungen Kontext erfordern und wie gut Modelle diese Fälle bewältigen. Da nur ein kleiner Teil der Übersetzungen kontextabhängig ist, sind gängige Korrelationsmetriken wie BLEU unzureichend. Wir erweitern die CXMI (Context eXpedient Measurement for Machine Translation) Methode, um Pointwise CXMI einzuführen, die Kontextnutzung auf Satz- oder Wortniveau misst.

Unsere Analyse von TED-Talk-Übersetzungen in 14 Sprachen identifizierte Muster: bestimmte Wortarten und Vokabular erfordern Kontext, wie z.B. duale Pronomen im Arabischen und korrekte Verbformen. Wir entwickelten den Multilingual Discourse-Aware (MuDA) Tagger, um kontextabhängige Phänomene zu markieren.

Durch den Vergleich kontextbewusster und -unbewusster Modelle zeigten wir, dass BLEU kontextagnostische Modelle bevorzugt, während COMET und ein Wort-f-Maß kontextbewusste Modelle besser abschneiden. Unser MuDA-Benchmark offenbart Stärken und Schwächen verschiedener Modelle bei spezifischen Diskursphänomenen, wie Formalität und Lexikalische Kohäsion.

Unsere Arbeit demonstriert die Notwendigkeit datengestützter Analysen und spezifischerer Benchmarks für die Bewertung von Dokumentübersetzungen und hebt DeepL als überlegen gegenüber Google Translate hervor.</sample>
    <sample id="282">**Abstract: StoryTrans: Nicht-parallele Autor-Stil-Übertragung bei der Textgenerierung**

Diese Arbeit präsentiert StoryTrans, ein innovatives Modell für die nicht-parallele Textstilübertragung, das sich auf die Übertragung von Autorstilen auf gesamte Geschichten konzentriert. Bisherige Studien fokussierten meist auf Token- oder Satzebene, wie z.B. Sentiment- oder Formalitätstransfer. StoryTrans geht einen großen Schritt weiter, indem es die Übertragung auf der Erzählebene und auf Diskursniveau ermöglicht, was entscheidend für die Imitation von Autorstilen ist.

Die Hauptaufgabe besteht darin, komplexe sprachliche Präferenzen und Diskursstrukturen in langen Texten zu imitieren, insbesondere da Stile oft eng mit bestimmten Themen verknüpft sind. StoryTrans löst dies durch zwei Hauptkomponenten:

1. **Diskursdarstellung und Stil-Embedding:** Das Modell lernt Diskursdarstellungen aus Quelltexten und kombiniert diese mit lernbaren Stil-Embeddings, um Texte in Zielstilen zu generieren.
2. **Zwei-Phasen-Generierung:** Zuerst wird der Quelltext mit stil-spezifischen Schlüsselwörtern maskiert übertragen, gefolgt von einer expliziten Generierung der gesamten Geschichte, die diese Schlüsselwörter integriert.

Das Training umfasst eine abgestufte Verlustfunktion, die Inhaltserhaltung und Stiltrennung fördert. Experimentelle Ergebnisse auf chinesischen und englischen Datensätzen zeigen, dass StoryTrans im Vergleich zu Basismodellen bessere Ergebnisse bei Stilkontrolle und Inhaltserhaltung erzielt. Das Modell demonstriert seine Fähigkeit, Geschichten zu bereichern und dabei die ursprüngliche Semantik zu bewahren.</sample>
    <sample id="283">Die zuerst erwähnte symmetrische Abhängigkeitsstruktur ist das **Prague-Ansatz**.</sample>
    <sample id="284">**Abstract:**

Die Arbeit präsentiert FSUIE, eine neuartige Methode zur Verbesserung der universellen Informationsextraktion (UIE). Aktuelle span-basierte UIE-Modelle identifizieren und kennzeichnen Textabschnitte, was stark von den annotierten Grenzpositionen abhängt. Die Studie schlägt vor, die Spannegrenzen als unscharf (fuzzy) zu behandeln, anstatt präzise zu sein, um die Ambiguität bei der Kennzeichnung zu berücksichtigen.

FSUIE integriert zwei Hauptkomponenten: Fuzzy Span Loss (FSL) und Fuzzy Span Attention (FSA). FSL modelliert die Grenzkontinuität der Zielabschnitte als Wahrscheinlichkeitsverteilung, während FSA die Aufmerksamkeitsverteilung dynamisch anpasst. Durch die Einführung eines optimierbaren Parameters wird die Aufmerksamkeitsspanne variabel gehalten, und die Verteilung an den Grenzen linear abfallend gestaltet.

Experimente auf drei UIE-Aufgaben (Named Entity Recognition, Relationship Extraction, Aspect Sentiment Triplet Extraction) zeigen signifikante Verbesserungen mit FSUIE. Insbesondere auf kleinen Datensätzen führt FSA zu einer schnelleren Konvergenz und FSL verbessert die Extraktionsleistung. FSUIE demonstriert eine starke Generalisierungsfähigkeit für domänenspezifische Informationen und erreicht neue Bestwerte auf mehreren Benchmark-Datensätzen.

Zusammenfassend schlägt die Arbeit eine flexible und effiziente Methode vor, um die Abhängigkeit von Spannegrenzen zu reduzieren und die Aufmerksamkeitsmechanismen in UIE-Modellen zu verbessern.</sample>
    <sample id="285">**Abstract:**

Die Arbeit "Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with Fine-grained Evaluation Framework" von Mingqi Gao et al. aus Peking Universität adressiert die Herausforderung von Factualitätsfehlern in Dialogzusammenfassungen. Die Autoren untersuchen zwei Hauptansätze: die Integration von Factualitäts-Objektiven in Summarisierungsprozesse und die Entwicklung eines eigenständigen Factual Error Correction (FEC) Modells.

Bisher fehlte es an spezifischer Forschung zu FEC in Dialogzusammenfassungen. Die Studie kritisiert die aktuelle Bewertung von FEC-Modellen, die auf groben Faktualitätsmetriken wie FactCC und DAE basiert, da diese ungenau und unzureichend sind. Stattdessen schlagen sie ein fein granuliertes Bewertungsrahmenwerk vor, das manuell annotierte Korrekturen einbezieht.

Die Forschung identifiziert zwei Arten von Factualitätsfehlern: inhaltbasiert und formbasiert. Sie trainieren FEC-Modelle mit Referenzzusammenfassungen aus Dialog-Datensätzen und stellen fest, dass dies zu den besten Ergebnissen führt. Die Studie betont die Notwendigkeit, menschlich korrigierte Zusammenfassungen während des Trainings zu verwenden, um die Leistung zu verbessern.

Zusätzlich wird hervorgehoben, dass aktuelle FEC-Modelle Schwierigkeiten bei der Korrektur von Fehlern wie dem Hinzufügen von Inhalten haben und weitere Fehlerarten wie Attribut-, Modus- und Linkfehler nicht adressieren. Die Arbeit schlägt vor, synthetische Daten mit menschlichen Annotationen zu kombinieren, um die Entwicklung effektiverer FEC-Modelle voranzutreiben.</sample>
    <sample id="286">Die Referenten heißen James Finch und Sarah Finch.</sample>
    <sample id="287">An der Arbeit sind vier Autoren beteiligt: Javad Hosseini, Filip Radlinski, Silvia Pareti und Annie Louis.</sample>
    <sample id="288">Die Datensätze, die zum Testen syntaktischer Phänomene verwendet werden können, sind **BLiMP**, **SyntaxGym** und **CrowS**.

Der Text erwähnt auch die Verwendung von Sätzen aus diesen Datensätzen, um längere Sequenzen zu simulieren und die Empfindlichkeit der Sprachmodelle gegenüber Kontext zu untersuchen.</sample>
    <sample id="290">Die Abkürzungen der fünf Methoden für die erste Forschungsfrage (ob saubere Validierungsdaten notwendig sind oder ein raueres Validierungsset ausreicht) sind:

1. **FTw** (Vanilla-Modell ohne zusätzliche Feinabstimmung)
2. **COSINE** (Ein spezifisches WSL-Verfahren)
3. **WSL-Methode** (Allgemeiner Begriff für Weakly Supervised Learning-Ansätze)
4. **Fine-Tuning** (Direkte Feinabstimmung auf sauberen Daten)
5. **WSL-Ansatz mit Validierung** (Ein WSL-Ansatz, der das raue Validierungsset nutzt)</sample>
    <sample id="291">Das Modell wird auf 11 biomedicalen und klinischen Downstream-Aufgaben evaluiert, darunter:

- Named Entity Recognition (NER)
- Klassifikation
- Part-of-Speech-Tagging (POS-Tagging)
- Fragebeantwortung (Question Answering)</sample>
    <sample id="294">CamemBERT wurde ursprünglich mit einem 4 GB großen Datensatz aus NACHOS (einem Web-Krawldaten-Datensatz in Französisch) trainiert.</sample>
    <sample id="295">Der/die Referent*in heißt Adam Przepiórkowski.</sample>
    <sample id="296"># **Erforschung der Ironieerkennung in der natürlichen Sprache: Ein kollaboratives Projekt zwischen der Universität Turin und Amazon Alexa**

Diese Arbeit präsentiert eine Zusammenarbeit zwischen der Universität Turin und Amazon Alexa, die sich auf die Herausforderungen der Ironieerkennung in der natürlichen Sprachverarbeitung (NLP) konzentriert. Das Team entwickelte das *English Perspectivist Irony Corpus (EPIC)*, eine umfangreiche Datensammlung mit 300 kurzen Gesprächen aus sozialen Medien, Reddit und Twitter, abgedeckt über 1,5 Jahre.

Die Datenerfassung erfolgte über Crowdsourcing mit 74 Annotatoren, die jeweils 200 Texte bewerteten. Die Annotatoren wurden nach verschiedenen Kriterien gruppiert, einschließlich Geschlecht, Alter und Nationalität. Die Analyse der Inter-Annotator-Übereinstimmung ergab signifikante Unterschiede zwischen den Gruppen.

Die Forscher entwickelten *perspektive-bewusste Modelle*, indem sie ein vorab trainiertes Sprachmodell auf Untergruppen der Daten feinabstimmten. Diese Modelle zeigten im Vergleich zu aggregierten Standardmodellen eine höhere Zuversicht bei der Ironieerkennung. Interessanterweise korrelierten die Unterschiede in den Annotationen mit dem Alter und der geografischen Herkunft der Teilnehmer, wobei nahe beieinander liegende Generationen und Regionen die größten Diskrepanzen aufwiesen.

Die Studie unterstreicht die Komplexität der Ironieerkennung und die Auswirkungen menschlicher Perspektiven auf NLP-Modelle, was zu einer verbesserten Genauigkeit und Zuverlässigkeit führt.</sample>
    <sample id="297">**Abstract: "From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric"**

Diese Studie untersucht die Verwendung von "Dogwhistles" – codierten Begriffen, die eine doppelte Botschaft an eine in- und ausgruppenbezogene Zielgruppe senden – in politischen Reden. Der Fokus liegt auf der Anti-Semitischen Dimension, wo Begriffe wie "Cosmopolitan" als Dogwhistle für jüdische Menschen dienen können.

Die Forschung umfasst:

1. **Glossar und Typologie:** Entwicklung einer umfassenden Datenbank mit 340 Dogwhistle-Termen und -Symbolen, kategorisiert nach Register, Persona und Typ.
2. **Historische Analyse:** Untersuchung von US-Politischen Reden, um den Zusammenhang zwischen Dogwhistles und konservativen Strategien zu beleuchten.
3. **Sprachmodell-Evaluierung:** Testen der Fähigkeit von GPT-3, Dogwhistles zu identifizieren und ihre verborgenen Bedeutungen zu erkennen, wobei herausgefunden wurde, dass formellere Dogwhistles besser erkannt werden.
4. **Content-Moderation-Umgehung:** Demonstration, wie Dogwhistles in Online-Kontexten hatefulen Inhalten die Erkennung entgehen können, indem sie standardmäßige Slurs und Gruppenbezeichnungen ersetzen.

Zusammenfassend bietet die Arbeit wertvolle Einblicke in die komplexe Welt der codierten Rhetorik und ihre Auswirkungen auf politische Einflussnahme und Online-Kommunikation.</sample>
    <sample id="298">Die Ergebnisse, die zur Schlussfolgerung führten, dass die zeitliche Verzögerung (temporal drift) die Hauptursache für den Leistungsverlust ist, umfassen:

1. Ein Experiment, bei dem Modelle mit jüngeren Daten neu trainiert oder weiter vortrainiert wurden, zeigte, dass die Leistung mit zunehmendem zeitlichen Abstand abnahm.
2. Die Beobachtung, dass die Leistungsdegradation mit der Zeit korreliert und nicht durch adaptive Überanpassung (adaptive overfitting) verursacht wurde.</sample>
    <sample id="299">**Abstract:**

Diese Arbeit konzentriert sich auf die Verbesserung der Robustheit von Natural Language Inference (NLI) Modellen gegenüber Ausnutzung von Kurzwegkorrelationen, die zu Überanpassung führen. Traditionelle NLI-Modelle basieren stark auf diesen Kurzwegen, was ihre Leistung auf neuen, "out-of-distribution"-Daten gefährdet.

Wir schlagen eine neue Trainingsmethode namens "Minimax Training" vor, die die Abhängigkeit von Kurzwegen reduziert. Die Methode nutzt einen minimax-Prozess zwischen einem "Learner" und einem "Auxiliary"-Modell. Das Auxiliary maximiert die Verluste des Learners, indem es Gewichte für Trainingsbeispiele generiert, die den Learner dazu bringen, sich auf "hard" Beispiele zu konzentrieren, die Kurzweg-Widersprüche enthalten.

Unsere Methode verbessert die Leistung von NLI-Modellen auf "out-of-distribution"-Testsätzen wie HANS und PAWS, während sie die In-Distribution-Genauigkeit beibehält. Wir untersuchen auch die Auswirkungen von Modellgröße, der Größe des Auxiliary-Modells und synthetischen Kurzwegen.

Unsere Ergebnisse zeigen, dass das Minimax Training eine effektive Strategie ist, um die Robustheit von NLI-Modellen zu steigern, ohne auf spezifisches Domänenwissen oder komplexe Auxiliary-Architekturen angewiesen zu sein. Wir laden zum Austausch über diese Forschung während unserer Poster-Präsentation ein.</sample>
    <sample id="300">**Abstract**

Dieser Vortrag stellt die Aufgabe des interaktiven Diktierens vor, bei der Benutzer sowohl mündlich diktieren als auch Sprachbefehle geben können, um Dokumente in Echtzeit zu bearbeiten. Im Gegensatz zu bestehenden Systemen, die entweder nur diktieren oder feste Befehlsstrukturen erfordern, ermöglicht diese Aufgabe eine flexible und intuitive Interaktion.

Die Forschung konzentriert sich auf drei Hauptbeiträge: (1) die Formalisierung der Aufgabe, (2) die Entwicklung einer Datenerfassungs-Schnittstelle und eines Datensatzes, und (3) die Erstellung einer Basissystemlösung. Das System folgt einem vierstufigen Verfahren: Spracherkennung, Aufteilung von Diktat- und Befehlsuttern, Befehlsnormalisierung und Ausführung.

Ein benutzerfreundliches Interface ermöglicht die gleichzeitige Erfassung von Diktat und Befehlen. Die Forscher haben Modelle mit T5 und GPT-3-Architekturen trainiert, um verschiedene Aufgaben zu bewältigen, darunter Segmentierung, Sprachfehlerbehebung und Dokumentenzustandsvorhersage. Die Ergebnisse zeigen einen Kompromiss zwischen Genauigkeit und Geschwindigkeit, wobei GPT-3 in Genauigkeit überlegen ist, aber langsamer.

Der Datensatz und der Quellcode sind öffentlich zugänglich, um zukünftige Fortschritte in diesem aufstrebenden Bereich zu fördern. Die Arbeit unterstreicht das Potenzial für natürlichere und effizientere Sprachinteraktionen in der Dokumentenerstellung.</sample>
    <sample id="302">Die Token der Ausgabesequenz müssen permutiert werden, weil sie in der ursprünglichen Reihenfolge nicht vorkommen und das Modell die richtige Reihenfolge lernen muss, um eine kohärente und sinnvolle Ausgabe zu erzeugen.</sample>
    <sample id="303">Die Autoren empfehlen eine größere Transparenz bei Bias-Minderungsmethoden, weil sie nicht wissen, ob positive Stereotype auf übermäßige Wertausrichtung oder andere, möglicherweise weniger effektive, Anti-Stereotypisierungstechniken zurückzuführen sind. Sie betonen die Notwendigkeit, mögliche versteckte Ursachen für schädliche Muster zu untersuchen.</sample>
    <sample id="304">Inakzeptable Minimalpaareingaben sind Sätze, die als ungrammatisch oder unakzeptabel eingestuft werden, im Gegensatz zu akzeptablen Sätzen, die als grammatikalisch und korrekt angesehen werden. Diese Eingaben werden verwendet, um die Fähigkeit von Sprachmodellen zu bewerten, zwischen akzeptablen und inakzeptablen Sätzen zu unterscheiden.</sample>
    <sample id="305">**Abstract:**

Die Arbeit "Weaker Than You Think: A Critical Look at Weakly Supervised Learning" untersucht die Effektivität und Anforderungen von schwachen Überwachungsverfahren (Weakly Supervised Learning, WSL) bei der Modelltraining. Im Gegensatz zu herkömmlichen, manuell annotierten Daten, nutzen WSL-Methoden schwache Labelquellen wie heuristische Regeln oder niedrigqualitative Crowdsourcing.

Die Studie stellt fest, dass aktuelle WSL-Ansätze tatsächlich auf sauberen Validierungsdaten angewiesen sind, um effektiv zu funktionieren. Ohne diese erleiden Modelle einen signifikanten Leistungsabfall. Darüber hinaus zeigt die Forschung, dass die Anzahl sauberer Validierungsproben entscheidend ist: 20 Proben pro Klasse reichen oft aus, um hohe Leistungen zu erzielen.

Ein weiterer wichtiger Punkt ist, dass das direkte Feintuning auf sauberen Daten in vielen Fällen bessere Ergebnisse liefert als WSL-Methoden, die diese Daten nur für die Validierung nutzen. Die Autoren empfehlen, in Zukunft: 1) Modellauswahlkriterien transparenter zu berichten, 2) WSL gegen Few-Shot-Lernmethoden zu vergleichen, 3) kontinuierliches Feintuning als Basismethode zu berücksichtigen und 4) den offenen Zugang zu Code zu fördern.

Zusammenfassend kritisiert die Arbeit die übertriebenen Leistungsansprüche aktueller WSL-Methoden und plädiert für eine realistischere Bewertung ihrer Effektivität.</sample>
    <sample id="306"># **Entity Tracking in Language Models: Eine Untersuchung der Verfolgungsfähigkeit von Entitäten in Sprachmodellen**

In dieser Arbeit untersuchen Sebastian Schuster und Najoung Kim die Fähigkeit von großen Sprachmodellen, Entitäten in Texten zu verfolgen und ihren Zustand im Laufe eines Diskurses zu verstehen. Die Autoren argumentieren, dass diese Fähigkeit entscheidend für das Verständnis längerer Texte ist, aber bisher wenig systematisch erforscht wurde.

Ihr Ansatz besteht darin, eine Aufgabe zu entwerfen, die die Verfolgungsfähigkeit von Entitäten bewertet, indem sie Boxen und Objekte verwendet. Die Modelle müssen den Inhalt jeder Box basierend auf einer anfänglichen Beschreibung und nachfolgenden Aktionen vorhersagen. Um Heuristiken und Memorieren zu verhindern, wurden spezielle Maßnahmen ergriffen.

Die Experimente mit Modellen wie Flan-T5 und GPT-3/3.5 zeigten, dass nur GPT-3.5-Modelle, die auf Code trainiert wurden, nicht-triviale Tracking-Fähigkeiten zeigten. Kleinere Modelle wie T5-Base konnten durch Feinabstimmung lernen, diese Aufgabe zu meistern. Die Ergebnisse deuten darauf hin, dass Code-basiertes Training entscheidend für die Entstehung dieser Fähigkeit in Sprachmodellen ist.

Die Studie hebt die Herausforderungen bei der Bewertung von Entitätsverfolgungsfähigkeiten hervor und bietet wertvolle Erkenntnisse über die Grenzen und Möglichkeiten aktueller Sprachmodelle. Die vollständigen Ergebnisse und Analysen sind in der Veröffentlichung auf ArXiv verfügbar.</sample>
    <sample id="307">Die Autoren haben verschiedene Bewertungsmetriken verwendet, darunter Genauigkeit (Accuracy), F1-Score und andere metrik-spezifische Werte für Aufgaben wie Named Entity Recognition, Klassifikation, Part-of-Speech Tagging und Fragebeantwortung. Sie haben diese Metriken für ihre sieben Modelle im Vergleich zu sechs Baseline-Modellen berechnet.</sample>
    <sample id="308">**Abstract:**

In ihrer Präsentation untersuchen Jenny und ihr Team die **Designbiasse in NLP-Datensätzen und -Modellen** und wie diese durch **Positionalität** beeinflusst werden. Positionalität bezieht sich auf die Perspektiven und Erfahrungen, die Individuen aufgrund ihrer Demografie und ihres Lebenshintergrunds haben.

Die Forscher argumentieren, dass Datensätze und Modelle, obwohl sie keine Identitäten besitzen, die Vorurteile und Perspektiven der Menschen widerspiegeln, die an ihrer Erstellung beteiligt waren. Durch die Vergleichsanalyse von Annotationen realer Nutzer mit bestehenden Modellen und Datensätzen, wie Social Chemistry, Delphi, GPT4 und anderen, konnten sie signifikante Positionen identifizieren.

Die Ergebnisse zeigen, dass Datensätze und Modelle stark auf englischsprachige Länder und Personen mit Hochschulbildung ausgerichtet sind. Insbesondere nicht-binäre Individuen sind unterrepräsentiert. Um diese Ungleichheiten anzugehen, schlagen die Autoren drei Maßnahmen vor: Dokumentation aller Designentscheidungen, Durchführung von NLP-Forschung mit einem perspektivischen Ansatz und Entwicklung spezialisierter Datensätze und Modelle für vier spezifische Gemeinschaften.

Die Arbeit unterstreicht die Wichtigkeit, die Auswirkungen von Positionalität auf NLP zu berücksichtigen, um gerechtere und inklusivere Technologien zu entwickeln.</sample>
    <sample id="309">Die Metrik, die verwendet wurde, um die Übereinstimmung zwischen den Kommentatoren zu messen, ist die **inter-annotator agreement** (Inter-Bewerter-Übereinstimmung) auf 100 doppelt beschrifteten Konversationen.</sample>
    <sample id="310">Die Domain, die gewählt wurde, um völlig unzusammenhängende Sätze zu den inakzeptablen und akzeptablen Suchanfragen hinzuzufügen, ist **Wikipedia**.</sample>
    <sample id="311">Basierend auf dem vorgestellten Inhalt gehört Regina Stodden und ihr Team an eine Universität, die an der Erstellung und Präsentation des DEPLAIN-Corpus beteiligt war. Da spezifische Nennungen fehlen, kann man annehmen, dass sie an einer deutschen Universität arbeiten, möglicherweise an einer, die für ihre Forschung im Bereich der Sprachverarbeitung und maschinellen Übersetzung bekannt ist. Eine genaue Universität wird im Text nicht genannt.</sample>
    <sample id="312">MultiInstruct unterscheidet sich von anderen Benchmarks dadurch, dass es **das erste große, öffentliche Multi-Modal-Instruction-Tuning-Dataset** ist. Es umfasst **62 vielfältige Multi-Modal-Aufgaben** in 10 Kategorien, die aus 21 bestehenden Open-Source-Datensätzen stammen, und ist speziell dafür konzipiert, die Generalisierung auf bisher unbekannte Multi-Modal-Aufgaben zu untersuchen.</sample>
    <sample id="313">Zwei Autoren: James Finch und Sarah Finch.</sample>
    <sample id="314">Die binäre Koordination (oder Koordinierung von zwei Elementen) wird in diesem Kontext als Struktur beschrieben, bei der zwei Konjunkte (z.B. "Lisa und Bart") gleichberechtigt sind und beide direkt vom Gouverneur (z.B. "und") abhängig sind. Dies steht im Gegensatz zu asymmetrischen Ansätzen, die einen der Konjunkte als Hauptteil der Struktur auswählen.</sample>
    <sample id="315">Die Länge der in der Studie verwendeten Prompts ist nicht explizit angegeben. Der Fokus liegt auf der Qualität und den Ergebnissen der generierten Texte, nicht auf der genauen Wortzahl oder Dauer der Prompts.</sample>
    <sample id="316">Die Ergebnisse zeigen, dass das kleinere T5-Modell, das auf dem CoScript-Dataset feinabgestimmt wurde, in der Lage ist, qualitativ hochwertigere Skripte zu generieren als die meisten größeren Sprachmodelle. Dies deutet darauf hin, dass kleinere Modelle bei angemessener Schulung auf geeigneten Datensätzen die Leistung größerer Modelle übertreffen können.</sample>
    <sample id="317"># **CodeIE: Verbesserte Few-Shot-Informationsextraktion mit großen Code-Generierungsmodellen**

Diese Arbeit präsentiert CodeIE, eine innovative Methode zur Verbesserung der Few-Shot-Informationsextraktion in natürlicher Sprache. Das Ziel ist es, die Lücke zwischen der Verarbeitung unstrukturierter Texte und der Generierung strukturierter Ausgaben zu überbrücken.

Traditionelle Modelle wie T5 und GPT-3 verwenden Text-zu-Text-Prätraining, was bei der Inferenz Herausforderungen bei der Handhabung strukturierter Ausgaben darstellt. CodeIE löst dieses Problem, indem es die Aufgabe in eine Struktur-zu-Struktur-Code-Generierung umwandelt, wobei große Code-Sprachmodelle wie Codex zum Einsatz kommen.

Durch die Verwendung von Code-Format-Prompts konnten die Forscher aus Fudan University signifikante Verbesserungen bei der Informationsextraktion erreichen. Im Vergleich zu Basismodellen wie UIE und GPT-3 zeigte sich, dass CodeIE, insbesondere bei wenigen Trainingsbeispielen, überlegen ist. Die Analyse ergab, dass Code-basierte Ansätze eine bessere Ausrichtung an der Aufgabe, geringere Perplexität und weniger strukturelle Fehler aufweisen. Außerdem generierte Codex präzisere und konsistentere Ergebnisse als GPT-3.

Die Studie hebt die Vorteile der Code-Generierung für Informationsextraktionstasks hervor und bietet einen neuen Ansatz, der eine bessere Leistung und Genauigkeit verspricht, insbesondere bei begrenzten Trainingsdaten. Die Forscher stellen ihren Code und ihre Erkenntnisse zur Verfügung, um die Weiterentwicklung dieses Bereichs zu fördern.</sample>
    <sample id="318">## DrBERT: Ein robustes prätrainiertes Modell auf Französisch für die Biomedizin und Klinische Domänen

**Einführung:**

In meinem Vortrag präsentiere ich unsere Arbeit zu "DrBERT: Ein robustes prätrainiertes Modell auf Französisch für die Biomedizin und Klinische Domänen". Zuerst werden wir uns mit der Herausforderung der Sprachmodellierung im Gesundheitswesen auseinandersetzen. Anschließend stellen wir unsere Hauptbeiträge aus unserer Arbeit vor.

Wir präsentieren DrBERT, das erste biomedizinische Modell auf Französisch, das auf RoBERTa basiert und mit dem NACHOS-Datensatz trainiert wurde. NACHOS ist eine Sammlung medizinischer Web-Crawl-Daten. Wir führen auch einen Vergleich verschiedener Modelle mit unterschiedlichen Prätrainings-Einstellungen und Datenquellen durch.

Anschließend präsentieren wir unsere Ergebnisse für 11 biomedizinische und klinische Downstream-Aufgaben auf Französisch. Zum Schluss fassen wir die Experimente zusammen und geben detaillierte Informationen zur Nutzung der Modelle.

**Hintergrund:**

Seit seiner Einführung im Jahr 2018 hat BERT einen enormen Leistungsschub bei der Lösung von NLP-Aufgaben gebracht und übertrifft im Vergleich zu historischen statischen und kontextuellen Methoden wie Word2vec, fastText oder ähnlichen. BERT wurde seitdem in viele andere Sprachen adaptiert, darunter Französisch mit CamemBERT, sowie in spezifische Domänen wie Biomedizin (PubMedBERT, BioBERT) und Klinisch (ClinicalBERT), meist jedoch in englischer Sprache.

Modelle für andere Sprachen sind rar und basieren oft auf kontinuierlichem Lernen aufgrund des Mangels an domänenspezifischen Trainingsdaten. Bis jetzt gab es kein offenes Modell für Biomedizin auf Französisch.

**Fragen und Antworten:**

Wir wollten herausfinden: Welche Datenquellen eignen sich am besten für eine breite Palette von Anwendungen? Und sind Crawled-Daten eine geeignete Alternative zu klinischen Daten?

Um dies zu beantworten, vergleichen wir DrBERT mit unserem ChuBERT-Modell, das auf anonymisierten Daten aus der Datenkiste des Universitätsklinikums Nantes basiert.

Ein weiterer wichtiger Punkt war die Frage: Wie viel Datenmenge ist notwendig, um ein spezialisiertes Modell auf Französisch zu trainieren? 4 GB, 8 GB oder mehr?

Um dies zu untersuchen, haben wir vier Modelle von Grund auf neu trainiert:

* Eine erste Version von DrBERT mit 7 GB NACHOS Daten
* Eine zweite Version von DrBERT mit 4 GB NACHOS Daten
* Eine erste Version von ChuBERT (klinisch) mit 4 GB klinischen Notizen
* Eine finale Version von ChuBERT mit einer Mischung aus 4 GB NACHOS und 4 GB klinischen Notizen

Zusätzlich zum Vergleich haben wir drei Modelle mit kontinuierlichem Lernen untersucht:

* Ein Modell basierend auf CamemBERT mit 4 GB NACHOS Daten
* Ein Modell basierend auf CamemBERT mit 4 GB klinischen Notizen
* Ein Modell basierend auf PubMedBERT (biomedizinisch) mit 4 GB NACHOS Daten

Insgesamt haben wir sieben Modelle.

**Evaluierung:**

Wir haben Daten für öffentliche und private Downstream-Aufgaben wie Named Entity Recognition, Klassifizierung, POS-Tagging und Fragebeantwortung gesammelt. Die Modelle wurden mit sechs Basismodellen verglichen:

* CamemBERT OSCAR 138 GB
* CamemBERT OSCAR 4 GB
* CamemBERT CCNET 4 GB
* PubMedBERT
* BioBERT
* ClinicalBERT

Die Ergebnisse zeigen, dass Modelle auf Daten der gleichen Art wie die Trainingsdaten am besten abschneiden. Daten aus heterogenen Quellen scheinen jedoch flexibler zu sein. Außerdem zeigt sich, dass mehr Daten zu besseren Ergebnissen führen.

Im Allgemeinen erzielen Modelle, die von Grund auf neu trainiert wurden, bessere Ergebnisse auf den meisten Aufgaben. Ein Experiment mit kontinuierlichem Lernen unter Verwendung der Gewichte und Tokenisierung von CamemBERT auf einem 4 GB NACHOS-Datensatz ergab jedoch vergleichbare Ergebnisse zu DrBERT 4 GB. Ein Modell basierend auf CamemBERT-Gewichten und -Tokenisierung litt jedoch unter Stabilitätsproblemen.

**Fazit:**

Unser System überbot in neun von elf Downstream-Aufgaben die Leistung des generischen Modells (CamemBERT) und übertraf es insgesamt. Wir stellen fest, dass spezialisiertere Daten besser sind, aber nicht skalierbar.

Alle prätrainierten Modelle auf NACHOS-Daten sind unter der MIT-Lizenz auf Hugging Face verfügbar, ebenso wie alle Trainingsskripte auf unserem GitHub-Repository.

Vielen Dank für Ihre Aufmerksamkeit. Wir freuen uns auf den Austausch während der Poster-Session in Toronto.</sample>
    <sample id="319">In der Arbeit werden zwei Haupt-Lernstrategien untersucht:

1. **From-Scratch Pre-training**: Training der Modelle von Grund auf (z.B. DrBERT mit 7 GB oder 4 GB NACHOS Daten).
2. **Continual Pre-training**: Anpassung von vortrainierten Modellen (z.B. CamemBERT oder PubMedBERT) an spezifische Datensätze (z.B. 4 GB NACHOS oder klinische Notizen).</sample>
    <sample id="320">Basierend auf dem Inhalt, scheint es, dass die Überanpassung (adaptive overfitting) in diesem Kontext **nicht** der Hauptfaktor für die Leistungseinbußen ist. Der Text besagt, dass die Steigung der besten Anpassungslinie größer als 1 ist, was darauf hindeutet, dass es **keine** abnehmenden Renditen auf dem CoNLL++-Datensatz gibt, was adaptive Überanpassung ausschließt.</sample>
    <sample id="321">Die Qualität der Vereinfachung wurde anhand verschiedener Metriken und Vergleichen zwischen manuellen und automatischen Alignments beurteilt. Es wurde festgestellt, dass der MASSalign-Ansatz das beste automatische Alignment-Verfahren für die deutsche Textvereinfachung ist. Darüber hinaus zeigte die Feinabstimmung von Sprachmodellen wie long-mBART und base-mBART vielversprechende Ergebnisse bei der Erzeugung vereinfachter Texte.</sample>
    <sample id="322">**Abstract: Was lernen Textklassifizierer über Moral?**

In der Präsentation wird untersucht, wie Sprachmodelle Moral in Texten verstehen und interpretieren. Während traditionelle Ansätze Moral oft auf einer einfachen Skala zwischen "immoral" und "moral" behandeln, betont die Arbeit die subjektive Natur moralischer Urteile und die Existenz verschiedener moralischer Fundamente, wie von der Moral Foundation Theory vorgeschlagen.

Die Studie nutzt den Moral Foundation Twitter Corpus, eine Datensammlung von 35.000 Tweets aus sieben Domänen, um zu untersuchen, wie sich Moral in verschiedenen Kontexten ausdrückt. Die Domänen umfassen Hashtags wie #AllLivesMatter und #BlackLivesMatter, die unterschiedliche moralische Botschaften vermitteln.

Die Ergebnisse zeigen, dass Sprachmodelle erkennen können, wie Moral in verschiedenen Domänen unterschiedlich ausgedrückt wird. Zum Beispiel assoziieren sie "ALM" (All Lives Matter) mit Wörtern wie "Überwurf" und "Mayhem", die Rebellion gegen Autorität ablehnen, während "BLM" (Black Lives Matter) Subversion in einem positiveren Licht darstellt.

Die Präsentation betont die Wichtigkeit, diese feinen Unterschiede zu verstehen, um Missverständnisse zu vermeiden, die entstehen können, wenn ein einzelnes Modell für viele Domänen verwendet wird. Die Forschung zielt darauf ab, die Fähigkeiten von Sprachmodellen im Bereich der moralischen Textklassifizierung zu verbessern und ihre Grenzen aufzuzeigen.</sample>
    <sample id="323"># **Dynamische heterogene Graphen-Raisonierung für Commonsense QA**

Diese Arbeit präsentiert DHLK, einen innovativen Ansatz für die Beantwortung von Fragen mit gesundem Menschenverstand (Commonsense QA), der Sprachmodelle und Wissensdarstellungstechniken kombiniert. Commonsense QA stellt eine Herausforderung dar, da sie ein tiefes Verständnis der Sprache und des allgemeinen Wissens erfordert.

Vorherige Methoden kombinieren Sprachmodelle und Wissensbasen, aber sie leiden unter unnötigen Rauschen und einer begrenzten Interaktion zwischen Text und Wissen. DHLK löst diese Probleme durch die Erstellung eines heterogenen Graphen (HKG), der aus mehreren Wissensbasen aufgebaut ist. Der Prozess umfasst eine zweistufige Überprüfung, um die Struktur und das Wissen im HKG zu optimieren, und die Integration von Schlüsselentitäten aus Wortnetzen und Wiktionary.

DHLK verwendet RoBERTa und Mask Self-Attention, um den Kontext der Frage und die Entitäten zu kodieren und zu fusionieren. Es entfernt dynamisch weniger relevante Entitäten und modelliert die Subgraphen mit Relation Mask Self-Attention (RMSA). Durch die Iteration über mehrere Schichten von RMSA werden Entitäts- und Beziehungseembeddings optimiert. Der HKG-Pfad wird dann in den Kontext der Frage integriert, um eine verbesserte Darstellung zu erhalten.

Im Experiment übertrifft DHLK andere Ansätze auf CommonsenseQA und OpenBookQA mit externen Wissensbasen wie ConceptNet, WordNet und Wiktionary. Die Ergebnisse zeigen die Effektivität der vorgeschlagenen Methode bei der Beantwortung von Fragen mit gesundem Menschenverstand.</sample>
    <sample id="324">Ja, Sprachmodelle zeigen unterschiedliche politische Vorurteile, die aus ihren Trainingsdaten stammen. Sie können in verschiedene politische Lager eingeordnet werden, und ihre Leistung bei Aufgaben wie Hassrede- und Falschinformationenerkennung variiert je nach ihrem politischen Hintergrund.</sample>
    <sample id="325">## Einführung in unsere Arbeit: "Compositional Generalization ohne Bäume: Multiset-Tagging und latente Permutationen"

Hallo! Ich bin Matthias Lindemann und heute möchte ich Ihnen eine kurze Einführung in unsere wissenschaftliche Arbeit geben, die wir gemeinsam mit meinen Betreuern Alexander Koller und Ivan Titov verfasst haben. Das Thema unserer Forschung ist die **"compositionale Generalisierung"**, also die Fähigkeit eines Lernmodells, tiefere Rekursionen und bisher unbekannte Zusammensetzungen von Phrasen zu verstehen, die es während des Trainings bereits einzeln gesehen hat.

Stellen Sie sich vor, wir testen ein System für die semantische Analyse (Semantic Parsing). In unserem Beispiel haben wir ein Trainingsdatensatz mit Sätzen, wie "Das Mädchen schlief." und "Maria wusste, dass das Mädchen schlief." Jeder dieser Sätze ist mit einer logischen Form verknüpft, die die wesentlichen Bedeutungsaspekte darstellt. Im Gegensatz zu herkömmlichen Machine-Learning-Evaluierungen stammt der Testdatensatz nicht aus derselben Verteilung wie das Training. Er enthält strukturell unbekannte logische Formen. Das bedeutet, das Modell wurde mit flacher Rekursion trainiert und nun auf ein Beispiel mit tieferer Rekursion getestet.

**Probleme bei naiven Sequenz-zu-Sequenz-Modellen (seq2seq)**

Naive seq2seq-Modelle haben Schwierigkeiten mit dieser Art von Generalisierung außerhalb der Trainingsverteilung und erzeugen oft Ausgaben, die nicht zum Eingabetext passen. Sie versagen besonders darin, systematischen Zusammenhänge zwischen Eingabe und Ausgabe wiederzugeben, wie sie in diesem Beispiel farbcodiert sind.

**Bäume als Lösung - aber mit Nachteilen**

Ein beliebter Ansatz, um dieses Problem zu lösen, ist die Integration von **Bäumen** in die Modelle. Diese Bäume sollen den kompositorischen Prozess zwischen Sätzen und logischen Formen darstellen. Diese Methode funktioniert gut, hat aber Nachteile: Bäume sind oft nicht gegeben und müssen extrahiert werden, was komplex und rechenintensiv sein kann. Dies beinhaltet oft aufwendige Vorverarbeitung der logischen Formen, um Variable-Symbole zu behandeln, und die Extraktion von Bäumen kann spezialisierte Grammatik-Induktionsverfahren erfordern.

**Unser Ansatz: Bäume loswerden und direkt korrelieren**

In unserer Arbeit gehen wir einen neuen Weg: Wir entwickeln ein neuronales seq2seq-Modell, das die Korrelationen direkt zwischen Fragmenten der Eingabe und Fragmenten der Ausgabe modelliert. Wir zeigen zum ersten Mal, dass starke Generalisierung zu tiefer Rekursion ohne den Einsatz von Bäumen möglich ist.

Unser Ansatz besteht aus zwei Schritten:

1. **Multiset-Tagging:** Jedes Eingabetoken wird mit einem ungeordneten Multiset von Tokens, die in der Ausgabe vorkommen, markiert.
2. **Permutationsvorhersage:** Nach dem ersten Schritt haben wir alle richtigen Tokens, aber in der falschen Reihenfolge. Deshalb verwenden wir in diesem Schritt ein weiteres Modell, um die richtige Reihenfolge (Permutation) vorherzusagen.

**Flexibilität und Herausforderungen**

Unser Ansatz ist flexibel und ausdrucksstark. Um die Permutation vorherzusagen, wählt unser Modell nacheinander Multiset-Tokens aus, bis alle Eingabetokens einmal besucht wurden (vgl. rotes Token).

In unserer Arbeit lösen wir auch einige interessante technische Herausforderungen:

* **Fehlende Zuordnung:** Die Zuordnung zwischen Eingabe- und Ausgabetoken ist im Trainingsdatensatz nicht gegeben. Das macht es schwierig, für ein bestimmtes Token zu wissen, aus welchem Multiset es stammt.
* **Mehrere mögliche Permutationen:** Es können mehrere Permutationen konsistent mit den Trainingsdaten existieren, aber die linguistisch korrekte ist möglicherweise nicht direkt erkennbar. Wir lösen dies, indem wir die Zuordnung während des Trainings induzieren.

Die Permutationsvorhersage ist flexibel, aber die Suche nach der besten Permutation ist NP-hard. Daher verwenden wir eine GPU-freundliche kontinuierliche Entspannung, die es ermöglicht, durch die Lösung zu backpropagieren und linguistisch plausiblere Permutationen zu lernen.

Mehr Details zu unseren Experimenten und den Lösungen für diese Herausforderungen finden Sie in unserer Arbeit oder an unserem Poster.</sample>
    <sample id="326">Kognitive Dissonanz beschreibt zwei oder mehr widersprüchliche Überzeugungen oder Handlungen einer Person. Ein Beispiel wäre jemand, der behauptet, dass Rauchen schädlich ist, aber dennoch regelmäßig raucht. Diese widersprüchlichen Aussagen und Handlungen verursachen ein Gefühl der Unruhe oder Unstimmigkeit.</sample>
    <sample id="327">**Abstract**

"ManagerTower: Aggregating the Insights of Uni-Modal Experts for Vision-Language Representation Learning" präsentiert eine innovative Architektur für Vision-Language (VL) Modelle, die auf der BridgeTower-Struktur aufbaut. Die Arbeit zielt darauf ab, die Effizienz und Skalierbarkeit von VL-Modellen zu verbessern, indem sie die semantischen Kenntnisse verschiedener Ebenen von unimodalen Encodern (z.B. Text und Bild) effektiver nutzt.

ManagerTower führt "Manager" ein, die in jeder Schicht der Cross-Modal-Architektur mehrere unimodale Darstellungen aus verschiedenen Ebenen zusammenfassen und kombinieren. Diese Manager ermöglichen es dem Modell, adaptive und differenzierte Einblicke aus prätrainierten unimodalen Experten zu extrahieren, was zu einer verbesserten Cross-Modal-Ausrichtung und Fusion führt.

Im Vergleich zu bestehenden Ansätzen wie BridgeTower und METER zeigt ManagerTower signifikante Leistungssteigerungen, insbesondere auf dem Wikivideo-Teststandard, trotz eines kleineren Datensatzes von vier Millionen Bildern. Die Visualisierung der Aggregation gewichtet die Beiträge verschiedener unimodaler Experten pro Schicht, offenbarnd unterschiedliche und adaptive Nutzung von semantischen Kenntnissen je nach Cross-Modal-Schicht.

Die Forschung demonstriert die Wirksamkeit von ManagerTower bei der Erschließung universeller semantischer Kenntnisse und bietet einen flexiblen Rahmen für zukünftige VL-Forschung.</sample>
    <sample id="328">Basierend auf den vorgestellten Ergebnissen ist **GPT-4** das Sprachmodell, das am meisten links steht. Es belegt den größten Platz in der linken oberen Ecke des politischen Spektrums im Vergleich zu den anderen untersuchten Modellen.</sample>
    <sample id="329"># **Generierung strukturierter Pseudo-Labels für widerstandsfähige, lautlose Zero-Shot Video-Satzlokalisierung**

Diese Arbeit präsentiert einen neuartigen Ansatz für die Zero-Shot Video-Satzlokalisierung, eine Aufgabe, die relevante Segmente in langen Videos basierend auf natürlicher Sprache identifiziert. Der vorgeschlagene Ansatz zielt darauf ab, die Notwendigkeit manueller Annotationen zu eliminieren, die mit herkömmlichen Trainingsmethoden verbunden sind.

Bisherige Zero-Shot-Methoden generieren Pseudo-Ereignisse und dann Pseudo-Abfragen, um Video-Satzlokalisierungsmodelle zu trainieren. Diese Methoden haben jedoch Nachteile, wie einfache Pseudo-Abfragen, Unstimmigkeiten zwischen Pseudo-Abfragen und Ereignissen und die Ignorierung von Label-Noise.

Die Forscher schlagen eine *noise-resistente Strukturierte Pseudo-Label-Generierung* vor. Dieser Ansatz umfasst die Erzeugung komplexerer freier Formulierungen von Pseudo-Abfragen mit einem vorab trainierten Bild-Text-Modell, die Modellierung der zeitlichen Struktur von Ereignissen und die Generierung von Pseudo-Ereignissen mit hoher Relevanz innerhalb der Abfrage und niedriger Relevanz außerhalb. Um Label-Noise zu reduzieren, werden Gewichte für störende Proben angepasst und laute Labels erstellt.

Experimente auf den Datensätzen ActivityNet Captions und Charades-STA zeigen, dass der vorgeschlagene Ansatz bessere Ergebnisse liefert als bestehende Methoden, insbesondere in Bezug auf R@M und mIoU. Die Arbeit demonstriert einen effektiven Weg zur Verbesserung der Genauigkeit der Video-Satzlokalisierung ohne manuelle Annotationen.</sample>
    <sample id="330">Ja, kumulatives Training (Cumulative) ist in den meisten Fällen besser oder gleichwertig effektiv im Vergleich zu iterativem Training (Iterative) für aktives Lernen, wie die Ergebnisse der Studie zeigen.</sample>
    <sample id="331">Die Referentin ist Sara Papi.</sample>
    <sample id="332">Die Daten für die MuDa-Benchmark stammen aus einem parallelen Korpus, der für die Evaluation verwendet wird.</sample>
    <sample id="333"># **INK: Verbessern von NMT durch Injektion von kNN-Wissen**

Diese Arbeit präsentiert INK, ein innovatives Trainingsframework zur Verbesserung von Neuralen Maschinellen Übersetzungen (NMT). NMT-Modelle kämpfen oft mit einer unglatten Darstellung, was ihre Generalisierungsfähigkeit einschränkt, insbesondere bei seltenen Token.

Das vorgeschlagene System, INK, zielt darauf ab, diese Herausforderung anzugehen, indem es kNN-MT (k-Nearest Neighbor Machine Translation) erweitert. Es besteht aus zwei Hauptkomponenten:

1. **Adapter-basierte Feinabstimmung**: Ein Adapter wird verwendet, um die Darstellung mithilfe von kNN-Wissen zu glätten. Dies geschieht durch die Anpassung der Token- und Kontext-Darstellungen, um die semantische Kohärenz zu verbessern.

2. **Asynchrone Datenspeicher-Aktualisierung**: Im Gegensatz zu traditionellen kNN-MT-Ansätzen, die bei jeder Dekodierung einen vollständigen Datenspeicher abfragen, aktualisiert INK den Speicher asynchron nach jeder Darstellung.

Die Experimente zeigen, dass INK signifikante Verbesserungen erzielt, mit durchschnittlich 1.99 COMET-Score und 1.0 BLEU-Score über dem aktuellen Stand der Technik. Die Effizienz des Frameworks wird hervorgehoben, da es eine verbesserte Leistung mit weniger Speicher und schnellerer Inferenz bietet. Die Forschung unterstreicht das Potenzial von kNN-Techniken bei der Optimierung von NMT-Modellen.</sample>
    <sample id="335">Der/die Referent*in ist Matthias Lindemann.</sample>
    <sample id="336">Sprachübergreifender Transfer (Cross-lingual transfer) bezieht sich auf die Fähigkeit eines Modells, Wissen oder Fähigkeiten, die es in einer Sprache erworben hat, auf eine andere Sprache zu übertragen. Im Kontext der Arbeit, die von Yusen Zhang präsentiert wurde, bedeutet dies, ein Modell, das in einer Sprache (z.B. Englisch) trainiert wurde, auf eine andere Sprache (z.B. Deutsch oder Chinesisch) anzuwenden, um semantische Abfragen zu verarbeiten.</sample>
    <sample id="337">**Abstract:**

Unsere Forschung, "Graph-based Relation Mining for Context-free Out-of-vocabulary Word Embedding Learning", zielt darauf ab, die Herausforderung der Darstellung von Aus-dem-Kontext-entnommenen Wörtern (OOV) in Embedding-basierten Modellen zu bewältigen. Wir schlagen einen neuartigen Ansatz vor, der Wortbildung und Assoziation nutzt, um OOV-Wörter zu interpretieren, inspiriert von menschlichen Lerngewohnheiten.

Unser Ansatz beinhaltet die Erstellung eines Word Relationship Graphen, der lexikalische Regeln von Wortbildung und -assoziation imitiert. OOV-Wörter werden tokenisiert und mit relevanten Wörtern verknüpft, was zu einem zweischichtigen Graphen führt. Jedes Wort oder Wortstück ist ein Knoten, und seine Embedding dient als Attribut. Wir bewahren alle Knoten der ersten Schicht für detaillierte Informationen und sampeln in der zweiten Schicht, um Rauschen zu reduzieren.

Ein Self-Attention-Netzwerk wird eingesetzt, um Knotenattribute basierend auf den Zeichen der OOV-Wörter zuzuweisen. Zwei Graph Attention Network-Ebenen extrahieren wichtige Informationen und minimieren Rauschen. Ein Graph Convolutional Network fasst die Grapheninformationen zusammen.

Unsere Methode verwendet Kontrastives Lernen mit NT-XENT-Positivproben, um die Embeddings zu optimieren. Experimente zeigen überlegene Leistung gegenüber Basismodellen in intrinsischen und extrinsischen Aufgaben. Unser Ansatz kann sowohl statischen als auch kontextuellen Modellen zugute kommen. Zukünftig planen wir die Erweiterung auf andere Sprachen, insbesondere Agglutinationssprachen, wobei Fusionssprachen aufgrund komplexerer Wortbildungen eine Herausforderung darstellen könnten.</sample>
    <sample id="338"># **Titel: Bewertung menschlicher Naturalsprachenexplanationen: Ein objektiver Ansatz**

Die Forschung präsentiert eine umfassende Untersuchung der Bewertung menschlicher Naturalsprachenexplanationen in verschiedenen Aufgaben. Das Team entwickelte einen einheitlichen Ansatz, um die Qualität dieser Erklärungen objektiv zu messen, da bestehende Metriken wie BLEU und ROUGE an ihre Grenzen stoßen.

Die Studie beinhaltet die Analyse von fünf großen Datensätzen für unterschiedliche Aufgaben: Commonsense QA (CoS-E, ECQA), Natural Language Inference (e-SNLI) und Commonsense Validierung (ComVE). Ein einheitliches Datenformat wurde eingeführt, um diese Aufgaben in einen mehrdeutigen Wahlprozess zu überführen. Experimente zeigten, dass die Feinabstimmung mit Erklärungen nicht unbedingt neues Wissen vermittelt, sondern das Modell dazu bringt, die Erklärungsanteile für Vorhersagen zu nutzen.

Die Forscher schlugen eine neue Metrik namens TREU vor, die die Nützlichkeit von Erklärungen während der Feinabstimmung bewertet. Im Vergleich zur etablierten Metrik simuliert der TREU-Score besser die tatsächliche Leistung und berücksichtigt die task- und formatabhängige Natur menschlicher Erklärungen. Die Ergebnisse zeigen, dass selbst als minderwertig eingestufte Erklärungen die Modellleistung verbessern können.

Die Arbeit unterstreicht die Wichtigkeit einer sorgfältigen Überprüfung der Erklärungsqualität und bietet einen Rahmen für zukünftige Kollaborationen zwischen Menschen und KI, indem sie sicherstellt, dass menschliche Beiträge zu Datensätzen wertvoll und konsistent sind.</sample>
    <sample id="339">Die Autoren gehören der Saarland University in Deutschland an.</sample>
    <sample id="340"># **ParaAMR: Ein umfangreiches und syntaktisch vielfältiges Paraphrase-Dataset**

In dieser Arbeit präsentieren wir ParaAMR, ein großes Dataset syntaktisch vielfältiger Paraphrasen, das mithilfe von AMR-Back-Translation (Abstract Meaning Representations) erstellt wurde. Das Ziel ist es, die Herausforderung anzugehen, hochwertige, aber begrenzte Paraphrase-Datensätze für die NLP-Forschung zu erweitern.

Bestehende menschlich annotierte Datasets wie MRPC und PAN bieten hohe Qualität, sind aber klein. Automatisierte Methoden wie Back-Translation erzeugen große Mengen, aber mit geringer syntaktischer Vielfalt. Um dies zu verbessern, nutzen wir AMR-Graphen, die die semantische Struktur von Sätzen darstellen.

Unser Ansatz besteht darin, ein AMR-Graph-zu-Text-Modell zu verwenden, um Paraphrasen zu generieren. Zuerst extrahieren wir den AMR-Graphen einer Eingabe-Satzes, ändern dann den Fokus des Graphen (den Hauptgedanken) und modifizieren die entsprechenden Kanten. Dies führt zu syntaktisch unterschiedlichen, aber semantisch ähnlichen Texten.

ParaAMR umfasst etwa 15 Millionen Sätze mit durchschnittlich 6,9 Paraphrasen pro Satz. Vergleichende Analysen zeigen, dass es syntaktisch vielfältigere Paraphrasen erzeugt als andere Back-Translation-Methoden, während die semantische Ähnlichkeit erhalten bleibt. Wir demonstrieren die Nützlichkeit von ParaAMR in verschiedenen NLP-Aufgaben, einschließlich Satz-Embedding-Lernen, syntaktisch kontrollierter Paraphrase-Generierung und Datenverstärkung für Few-Shot-Lernen.

Zusammenfassend bietet ParaAMR eine wertvolle Ressource für die NLP-Forschung, die die Entwicklung leistungsfähigerer und vielseitigerer Modelle ermöglicht.</sample>
    <sample id="341">Die Autoren verwenden zwei Latenzmessungen:

* **Durchschnittliche Verzögerung (average lagging):** Eine einfache Messung der Zeitspanne zwischen der Eintreffung des Audios und der Ausgabe der Übersetzung.
* **Computationally aware average lagging:** Diese Messung berücksichtigt die Rechenzeit, die das Modell für die Vorhersage der Ausgabe benötigt.</sample>
    <sample id="342"># **LiveChat: Ein großes, personalisiertes Dialog-Dataset aus Live-Streaming**

Diese Arbeit präsentiert LiveChat, ein innovatives, groß angelegtes Dialog-Dataset, das automatisch aus Live-Streaming-Videos erstellt wurde. Es zielt darauf ab, die Lücke zwischen Text- und Video-basierten Dialog-Datensätzen zu schließen, was für die Entwicklung realistischerer KI-Gesprächssysteme von entscheidender Bedeutung ist.

Der Fokus liegt auf Open-Domain- und personalisierten Dialogen, die in Anwendungen wie virtuellen Streamern und Mitarbeitern relevant sind. Die bestehenden Herausforderungen umfassen die effektive Erfassung von Antwort-Beziehungen und die Integration von Persönlichkeitsinformationen. LiveChat überwindet diese Hindernisse durch einen automatischen Dialog-Konstruktionsmechanismus.

Das Dataset wird in drei Schritten erstellt: Erstens werden Original-Streaming-Videos aus TikTok/Douyin extrahiert, dann Audio-Transkripte generiert und Dialoge durch eine Antwort-zu-Wer-Methode konstruiert. Zweitens werden Persönlichkeitsinformationen gesammelt, sowohl manuell als auch durch Regeln und trainierte Klassifikatoren.

Experimente umfassen Benchmark-Aufgaben wie Antwortmodellierung und Empfängererkennung. Die Ergebnisse zeigen, dass Persönlichkeitsinformationen und längere Sitzungen die Leistung verbessern. Die Untersuchung von Large Language Models (LLMs) auf LiveChat offenbart die einzigartige Domäne des Datasets und die Vorteile der In-Context-Lernfähigkeit.

Zusammenfassend bietet LiveChat ein wertvolles Werkzeug für die Forschung und Entwicklung im Bereich der KI-Gespräche, insbesondere für die Verbesserung der Personalisierung und der Anpassung an reale Konversationsszenarien.</sample>
    <sample id="343">## Präsentation: "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources"

**Vortragende:** Akshatha (Co-Autorin) und Martin (Co-Autor)

**Einleitung:**

Unsere Arbeit untersucht, wie Sprachmodelle im Bereich der natürlichen Sprachverarbeitung (NLU) Wissen aus verschiedenen Quellen integrieren. Moderne NLU-Modelle greifen auf verschiedene Wissensbestände zurück:

* **Vorgebildetes Wissen:**  Dieses Wissen wird während der Trainingsphase des Modells, meist durch Pre-Training, erworben. Es umfasst allgemeine Informationen über die Welt.
* **Inferenzwissen:** Dieses Wissen wird dem Modell während der Verarbeitung einer bestimmten Aufgabe zur Verfügung gestellt. Es handelt sich um spezifisches Wissen, das für die Lösung der Aufgabe relevant ist.

Unsere Forschung zeigt, dass erfolgreiche Modelle für anspruchsvolle NLU-Aufgaben beide Wissensarten effektiv integrieren müssen.

**Problemstellung:**

Modelle, die auf vorgebildetem Wissen allein basieren, haben Schwierigkeiten, sich an neue Informationen anzupassen, die seit dem Pre-Training entstanden sind (z.B. neue Berufe). Daher schlagen wir vor, dass die Fähigkeit, Wissen aus verschiedenen Quellen zu integrieren, entscheidend für die Leistung von NLU-Modellen ist.

**Lösung: Der KITMUS-Test**

Wir haben einen Diagnosetest entwickelt, den **KITMUS-Test (Knowledge Integration from Multiple Sources)**, um die Fähigkeit von Modellen zur Integration von Wissen aus verschiedenen Quellen zu bewerten.

**Schlüsselkomponente: Coreference-Resolution**

Unser Test basiert auf der Aufgabe der **Coreference-Resolution**, bei der ein Modell bestimmen muss, auf welche Entität sich ein Pronomen bezieht.

**Drei KITMUS-Einstellungen:**

* **Background-Pretrain:** Hintergrundwissen ist im vorgebildeten Modell enthalten.

* **Background-Both:**  Sowohl Hintergrundwissen als auch Inferenzwissen sind verfügbar.

* **Background-Inference:** Nur Inferenzwissen ist verfügbar, Hintergrundwissen nicht.

**Datensatz und Evaluierung:**

Wir haben einen Datensatz mit Sätzen erstellt, die Pronomen enthalten, und die Teilnehmer sollten die korrekte Entität bestimmen.

* **Menschliche Evaluierung:** Wir haben den Datensatz sowohl mit menschlichen Teilnehmern als auch mit etablierten Coreference-Resolution-Modellen bewertet.

* **Modellergebnisse:**  Wir haben festgestellt, dass ungeschulte Modelle (ohne spezifisches Training auf KITMUS) in allen drei Einstellungen schlecht abschneiden.  Modelle, die auf KITMUS trainiert wurden, verbessern ihre Leistung deutlich, aber selbst die besten Modelle haben Schwierigkeiten, nur auf Inferenzwissen basierendes Hintergrundwissen zu integrieren.

**Fazit:**

* Viele Coreference-Resolution-Modelle haben Schwierigkeiten, Wissen aus verschiedenen Quellen ohne spezifisches Training zu nutzen.

* Mit geeignetem Training können einige Modelle Wissen aus mehreren Quellen erfolgreich integrieren.

* Selbst die leistungsstärksten Modelle kämpfen mit der Integration von rückwärts gerichtetem Wissen (nur bei Inferenz bereitgestellt).

**Nächste Schritte:**

Unser Datensatz und unsere Codebasis sind auf GitHub verfügbar. Wir hoffen, dass unsere Arbeit die Forschung zur Integration von Wissen in NLU-Modellen voranbringt.</sample>
    <sample id="344">Die Nachteile der baumbasierten Methoden sind:

1. **Komplexe und teure Baumobterung**: Der Aufbau von Bäumen erfordert oft aufwendige Vorverarbeitung und spezialisierte Grammatikinduktion.
2. **Abhängigkeit von Bäumen**: Diese Methoden sind auf die Darstellung von Komposition durch Bäume angewiesen, was in einigen Fällen nicht gegeben ist.
3. **Harte Einschränkungen**: Bäume legen oft strenge Einschränkungen für die Permutationen der Ausgabetokens fest, was die Flexibilität und Expressivität einschränkt.</sample>
    <sample id="345"># **Compositional Generalization ohne Bäume: Ein neuartiger Ansatz für semantische Analyse**

Dieser Forschungsbeitrag präsentiert eine innovative Methode für die semantische Parsing-Aufgabe der kompozitiven Generalisierung, die es Modellen ermöglicht, komplexere Sätze und Rekursionen zu verstehen. Traditionelle Ansätze verwenden Bäume, um die Beziehung zwischen Eingabe und Ausgabe zu modellieren, was jedoch zeitaufwändig und nicht immer verfügbar ist.

Die Autoren schlagen ein neuartiges neuronales Seq2Seq-Modell vor, das ohne Bäume auskommt. Die Hauptidee besteht darin, die Korrespondenzen zwischen Eingabe- und Ausgabefragmente direkt zu modellieren. Der Prozess umfasst zwei Schritte: Erstens wird jedem Eingabetoken ein Multiset an Ausgabetokens zugeordnet. Zweitens wird ein Permutationsmodell eingesetzt, um die Tokens in der richtigen Reihenfolge anzuordnen.

Der Schlüssel zu diesem Ansatz liegt in der flexiblen Permutationsvorhersage, die es dem Modell ermöglicht, verschiedene mögliche Reihenfolgen zu erkunden. Durch die Induktion der Ausrichtung während des Trainings und die Verwendung einer kontinuierlichen Entspannung für die Permutationsvorhersage werden die Herausforderungen bei der Ausrichtung und der Auswahl der richtigen Permutation gemeistert.

Experimentelle Ergebnisse auf dem COGS-Datensatz zeigen, dass das vorgeschlagene Modell signifikant besser bei der Generalisierung zu tieferen Rekursionen abschneidet als andere treellose Modelle. Dieser Ansatz eröffnet neue Möglichkeiten für die Entwicklung leistungsfähigerer und flexiblerer semantischer Parser.</sample>
    <sample id="346">Basierend auf dem präsentierten Inhalt und ohne spezifische Nennung, können wir schließen, dass die Autoren mit einer Universität assoziiert sind, die das Papier und die durchgeführten Forschungsprojekte unterstützt hat, die sich auf Named Entity Recognition (NER) und die Bewertung der Generalisierungsfähigkeit von Modellen konzentrieren. Ohne weitere Details im Text zu finden, ist es wahrscheinlich, dass sie an einer Universität im Bereich Informatik, Datenwissenschaft oder verwandten Disziplinen arbeiten.</sample>
    <sample id="347">Hallo, ich bin Myra und heute werde ich über unsere Arbeit mit dem Titel „Marked Personas: Verwendung von natürlichen Sprachaufforderungen, um Stereotype in Sprachmodellen zu messen“ sprechen. Diese Studie wurde in Zusammenarbeit mit Esin Durmus und Dan Jurafsky durchgeführt. In den letzten Jahren haben viele Forscher die weit verbreiteten sozialen Vorurteile und Stereotype in großen Sprachmodellen (LLMs) dokumentiert. Diese Methoden zur Messung von Vorurteilen haben jedoch verschiedene Einschränkungen. Sie basieren oft auf handkuratierten Datensätzen, die sehr zeitaufwändig zu erstellen sind, und sie messen meist nur sehr spezifische Stereotype, die nicht gut auf andere Demografien oder Kontexte übertragbar sind, oder sie erfassen lediglich allgemeine, breite Assoziationen wie negative Verbindungen zu bestimmten Gruppen. Außerdem berücksichtigt die meisten Forschung in diesem Bereich nicht die Intersektionalität, also die Vorstellung, dass vielfältige soziale Identitäten Vorurteile verstärken und einzigartige Schadensorte darstellen können.

Um diese Einschränkungen zu überwinden, nutzen wir die Tatsache, dass neu trainierte, anweisungsbasierte Sprachmodelle sehr gut auf Anweisungen und Aufforderungen reagieren. Wir können das Modell also bitten, eine Persona zu generieren, beispielsweise: „Stellen Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst.“ Sofort erkennen wir, dass diese Ausgabe sehr generalisierbar ist, da wir einfach jede gewünschte Identitätsmarkierung in die Aufforderung einfügen können. Hier sind einige Beispiele von GPT-4: Die asiatische Frau wird als unauffällig dargestellt, die Frau aus dem Nahen Osten als exotisch und faszinierend, was auf die Region verweist. Beide Personas von Menschen mit Farbe machen Bezug auf ihre Abstammung, während die Persona des weißen Mannes nichts dergleichen enthält.

Unsere Methode besteht aus zwei Teilen. Erstens die Generierung dieser Personas, die durch Aufforderungen inspiriert sind, die in einer Studie mit menschlichen Probanden verwendet wurden. Diese Probanden konnten ebenfalls Stereotype aufdecken, wenn sie solche Aufforderungen erhielten, und es ermöglicht einen direkten Vergleich zwischen den von uns generierten Personas und den von Menschen geschriebenen Antworten.

Der zweite Teil ist das „Marked Words“-Verfahren, mit dem wir Wörter identifizieren, die Gruppen, die als markiert gelten, von unmarkierten Gruppen unterscheiden. Der Vorteil dieser Methode besteht darin, dass wir sehr spezifische Stereotype und Muster ohne die Abhängigkeit von einem bestimmten Wortschatz erhalten.

Das „Marked Words“-Verfahren stützt sich auf das sociolinguistische Konzept der „Markierung“, das besagt, dass es eine unmarkierte Standardgruppe gibt und jede Gruppe, die sich von dieser unterscheidet, linguistisch markiert wird. Nehmen wir zum Beispiel das Wort „Kriegerin“. Normalerweise wird es mit Männern assoziiert. Wenn man also eine Kriegerin beschreibt, die eine Frau ist, wird man oft das Wort „Frau-Kriegerin“ verwenden und es mit „Frau“ markieren. Im Allgemeinen sind dominante Gruppen in der Gesellschaft sowohl linguistisch als auch sozial unmarkiert, während marginalisierte Gruppen meist markiert sind.

In unserer Methode bestimmen wir zunächst die unmarkierten und markierten Gruppen und vergleichen dann die Personas mit dem „Fighting Words“-Verfahren, das auf gewichtete Log-Wahrscheinlichkeiten basiert, um die Top-Wörter für jede markierte Gruppe zu ermitteln.

Zu den Ergebnissen: Wir verwendeten zunächst ein Stereotypen-Lexikon und fanden heraus, dass die generierten Personas mehr Stereotype enthalten als die von Menschen geschriebenen. Bei einer genaueren Untersuchung der Wortverteilung und des Lexikons zeigten sich jedoch unterschiedliche Muster. Während die generierten Personas eine höhere Häufigkeit der Lexicon-Wörter aufwiesen, hatte die menschliche Schreibweise eine viel breitere Wortverteilung. Die Stereotypen-Wörter in den generierten Personas beschränkten sich auf „groß“ und „athletisch“, also eher positive oder zumindest nicht-negative Begriffe. Dieses Lexicon erfasst die schädlichen Muster, die wir zuvor gesehen haben, gar nicht gut.

Um diese schädlichen Muster aufzudecken, wenden wir uns an die Ergebnisse unseres „Marked Words“-Verfahrens. So zeigen wir, wie diese scheinbar positiven Beschreibungen tatsächlich schädliche Narrative und Essenzialisierung widerspiegeln. Aus unserer Analyse geht hervor, dass die Top-Wörter für jede Gruppe sie hauptsächlich durch ihre Beziehung zu ihrer Identität definieren und sie als anders und abweichend vom weißen Standard darstellen. Dies trägt zu einer langen Geschichte der Diskriminierung und „Anderen“ dieser Gruppen bei.

Darüber hinaus werden in diesen Wörtern, besonders für Frauen mit Farbe, häufige Klischees widergespiegelt. Bei lateinamerikanischen Frauen sind Wörter wie „lebhaft“ und „kurvig“ mit einem Tropen der Tropen verbunden. Für asiatische Frauen sind Begriffe wie „zierlich“, „delikat“ und „seidenweich“ mit einer langen Geschichte der Sexualisierung und Hyper-Submissivität von asiatischen Frauen verbunden. Und für schwarze Frauen sind Wörter wie „stark“ und „resilient“ mit dem Archetyp der „starken schwarzen Frau“ verbunden. Während dieser Archetyp auf den ersten Blick positiv erscheinen mag, hat Forschung gezeigt, dass er tatsächlich sehr schädlich ist, da er diese Demografien dazu drängt, trotz gesellschaftlicher Hindernisse stark und resilient zu sein, anstatt diese Hindernisse zu beseitigen.

Zusammenfassend kommen wir zu drei Empfehlungen für Modellbesitzer: Forscher sollten sich mit positiven Stereotypen und Essenzialisierungsnarrativen befassen, eine intersektionale Linse bei der Untersuchung von Vorurteilen und Schaden anwenden, da viele Aspekte übersehen werden könnten, wenn dies nicht geschieht, und es sollte mehr Transparenz bei der Offenlegung von Methoden zur Bias-Minderung geben, da wir nicht wissen, ob diese positiven Stereotype auf eine seltsame Überbewertung oder andere Methoden zur Stereotypenabweichung zurückzuführen sind.

Vielen Dank für Ihre Aufmerksamkeit. Ich wünsche Ihnen eine schöne ACL-Konferenz.</sample>
    <sample id="348">## Überwindung von Stereotypen in Sprachmodellen: Die Macht von Personas

Die Arbeit "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models" untersucht, wie Sprachmodelle, insbesondere instruction-getunte LLMs, Stereotypen und Vorurteile reproduzieren. 

Die Autoren entwickeln einen Ansatz, der zwei Schritte umfasst:

1. **Persona-Generierung:** Sie bitten das Modell, Personas verschiedener Identitäten zu erstellen, z.B. "eine asiatische Frau beschreiben".
2. **Marked Words Methode:** Diese Methode identifiziert Wörter, die Gruppen markieren, die von der Norm abweichen. So werden subtile Stereotype und essentialisierende Narrative aufgedeckt.

Die Analyse zeigt, dass generierte Personas im Vergleich zu menschlich geschriebenen Texten häufiger stereotype Wörter enthalten. Positiv wirkende Beschreibungen verbergen oft schädliche Muster, wie die Verstärkung von "Othering", die Reproduktion historischer Stereotype (z.B. Hyper-Sexualisierung von asiatischen Frauen) und die Förderung schädlicher Archetypen (z.B. "Strong Black Woman").

Die Studie empfiehlt drei Maßnahmen für Entwickler von Sprachmodellen: 1. Fokus auf die Bekämpfung positiver Stereotype und essentialisierender Darstellungen, 2. Verwendung eines intersektionalen Ansatzes zur Untersuchung von Vorurteilen, 3. Verbesserte Transparenz bei der Anwendung von Bias-Milderungstechniken.</sample>
    <sample id="349">## Schutz von Embeddings als Dienstleistungen: Ein neuer Ansatz mit "Embedding Marker"

**Einführung**

Jingwei Yi von der Universität für Wissenschaft und Technologie Chinas stellt hier ein Video vor, das ein neues Papier präsentiert.

Heutzutage sind große Sprachmodelle wie GPT, LLAMA und PALM in der Verarbeitung natürlicher Sprache (NLP) außergewöhnlich leistungsfähig. "Embedding als Dienstleistung" baut auf diesen Modellen auf und bietet Unterstützung für verschiedene NLP-Aufgaben. OpenAI beispielsweise bietet eine GPT-basierte Embedding-API an.

Allerdings haben Studien gezeigt, dass Angreifer diese Modelle kopieren könnten, indem sie die Embeddings aus der API lernen und ähnliche Dienste anbieten. Daher ist der Schutz des Urheberrechts bei Embeddings als Dienstleistung unerlässlich.

**Das Problem und die Lösung**

Eine mögliche Lösung besteht darin, ein "Watermark" (Wasserzeichen) in die Dienstleistung zu integrieren, um zu überprüfen, ob andere Dienste dieses kopiert haben. Ein solches Wasserzeichen muss bestimmte Eigenschaften erfüllen:

* **Anwendbarkeit:** Es sollte speziell für Embeddings als Dienstleistung geeignet sein.
* **Nicht-Degradation:** Die Qualität der bereitgestellten Embeddings darf nicht beeinträchtigt werden.
* **Verstecktheit:** Es sollte für Angreifer schwer zu erkennen sein oder leicht zu entfernen.
* **Übertragbarkeit:** Es muss während des Modell-Extraktionsprozesses an Angreifer weitergegeben werden können.

Bisherige Methoden sind oft unzureichend, da sie entweder nicht für Embeddings als Dienstleistung geeignet sind oder nicht übertragbar sind.

**Der "Embedding Marker"**

Das vorgestellte Papier schlägt "Embedding Marker" vor, eine backdoor-basierte Wasserzeichenmethode, die speziell für Embeddings als Dienstleistung entwickelt wurde.

**Funktionsweise:**

Der Prozess besteht aus zwei Hauptphasen:

1. **Watermark-Injektion:** Ein Trigger-Set wird definiert, bestehend aus Wörtern in einem bestimmten Häufigkeitsintervall. Ein Benutzer sendet einen Satz an den Dienstleister. Der Dienstleister zählt die Anzahl der Triggern im Satz. Die bereitgestellte Embedding ist eine Gewichts-Summe der ursprünglichen Embedding und einer Ziel-Embedding. Je nach Anzahl der Triggern wird das Gewicht der Ziel-Embedding erhöht, bis die bereitgestellte Embedding genau der Ziel-Embedding entspricht, wenn die Trigger-Anzahl einen Schwellenwert (m) überschreitet.

2. **Urheberrechtsüberprüfung:** Der Dienstleister erstellt ein Backdoor-Dataset mit Sätzen, die nur aus Triggern bestehen, und ein normales Dataset mit Sätzen, die keine Triggern enthalten. Er fordert Embeddings für beide Datensätze von einem potenziellen Angreifer an. Die Ähnlichkeit zwischen den angeforderten Embeddings und der Ziel-Embedding wird berechnet (Cosinus-Ähnlichkeit und L2-Norm). Die Differenz zwischen den Ähnlichkeiten der beiden Datensätze wird als Metrik für die Unterscheidbarkeit verwendet. Zusätzliche statistische Tests (KS-Test) verbessern die Genauigkeit.

**Ergebnisse:**

Die Experimente auf vier Datensätzen (AG News, MIND, SST2, Enron Spam) zeigen, dass "Embedding Marker" eine hohe Erkennungsleistung bei gleichzeitig hoher Nutzerfreundlichkeit für nachgelagerte Aufgaben bietet. Die Visualisierung der Embeddings mit PCA zeigt, dass die Backdoor-Embeddings den normalen Embeddings nicht anzumerken sind.

**Fazit:**

"Embedding Marker" stellt einen vielversprechenden Ansatz zur Absicherung von Embeddings als Dienstleistung dar. Die Präsentation lädt zu Diskussionen und weiteren Forschungen ein.</sample>
    <sample id="350">**Abstract:**

Der Vortrag untersucht die Bedeutung von "superhumaner Leistung" in der natürlichen Sprachverarbeitung (NLP) und speziell in der Sprachverständnis- und Sprachverarbeitungsaufgabe (NLU). Die Autoren analysieren zwei prominente Benchmarks, SuperGLUE und SQuAD, und stellen fest, dass Systeme in einigen Aufgaben Menschen deutlich übertreffen. Allerdings wirft die Methodik dieser Vergleiche Fragen auf.

Es werden mehrere Probleme identifiziert: (1) Systeme und Menschen werden auf unterschiedlichen Teilmengen der Testdaten bewertet, was zu verzerrten Ergebnissen führt. (2) Fehler in den Referenzantworten beeinflussen die Bewertung. (3) Die Schätzung menschlicher Leistung ist oft ungenau, basierend auf einfachen Aggregationsmethoden. (4) Die Bezahlung und Motivation der menschlichen Teilnehmer variieren stark, was die Qualität beeinträchtigen kann. (5) Details über die Annotatoren bleiben oft unklar.

Die Autoren argumentieren, dass diese Probleme die Schlussfolgerungen über die Überlegenheit von Systemen in NLU-Aufgaben in Frage stellen. Sie empfehlen, bei der Konstruktion von Benchmarks transparentere und gerechtere Methoden anzuwenden, um zuverlässigere Vergleiche zwischen Systemen und Menschen zu ermöglichen.</sample>
    <sample id="351"># **Abstract: Bewertung der Generalisierungsfähigkeit alter NER-Modelle im Jahr 2023**

Die Studie untersucht die Frage, ob CoNLL-2003-basierte Named Entity Recognizer (NER) noch im Jahr 2023 effektiv sind. Die Forscher untersuchten die Generalisierungsfähigkeit dieser Modelle im Vergleich zu modernen Daten. Sie schufen dazu das CoNLL++-Dataset, das Nachrichtenartikel aus dem Jahr 2020 enthält, die mit den CoNLL-2003-Annotationsrichtlinien versehen wurden.

Durch das Feinabstimmen von über 20 Modellen auf CoNLL-2003 und deren Bewertung auf beiden Testsets (CoNLL-03 und CoNLL++) wurde die Generalisierungsleistung gemessen. Die Ergebnisse zeigen, dass die Modellarchitektur, die Modellgröße und die Menge der Feinabstimmungsbeispiele entscheidend für eine gute Generalisierung sind. Transformer-Modelle und größere Modelle schnitten besser ab, und eine höhere Anzahl an Feinabstimmungsbeispielen verbesserte ebenfalls die Leistung.

Die Forscher untersuchten zwei mögliche Ursachen für die Leistungseinbußen: adaptive Überanpassung und zeitlicher Drift. Sie stellten fest, dass zeitlicher Drift der Hauptfaktor ist, da die Leistung mit zunehmendem Zeitabstand zwischen Trainings- und Testdaten abnahm. Überraschenderweise wurde keine adaptive Überanpassung beobachtet.

Zusammenfassend lässt sich sagen, dass CoNLL-2003-Modelle immer noch relevant sind, aber Verbesserungen in der Modellarchitektur, der Größe und der Datenmenge erforderlich sind, um ihre Generalisierungsfähigkeit zu verbessern. Die Studie betont die Notwendigkeit weiterer Forschungen, um die Leistung alter NER-Modelle zu optimieren.</sample>
    <sample id="352">ABC-Eval steht für "annotating behaviors in chat" (Verhalten in Gesprächen annotieren). Es ist ein neuer Ansatz zur Bewertung von Konversations-KI, der das Ausmaß verschiedener Verhaltensweisen in Chat-Modellen misst.</sample>
    <sample id="353">**Abstract:**

Die Arbeit "Python Code Generation by Asking Clarification Questions" von Haau-Sing Li et al. (2023) adressiert die Herausforderung der Eingabemangelfüllung in der Code-Generierung und -Synthese. Der Fokus liegt auf der Interaktivität durch das Stellen von Klärungsfragen, um unvollständige Spezifikationen in natürlichsprachlichen Beschreibungen (NLDs) zu ergänzen.

Die Autoren schlagen ein neuartiges Verfahren vor, das CodeClarQA, ein synthetisches Dataset mit Klarstellungen zu Schlüsseloperationen, und eine Pipeline für die Code-Generierung durch das Stellen von Fragen ein. Ihr Ansatz identifiziert mangelnde Spezifikationen auf Operationsebene durch die Berechnung von Ähnlichkeitswerten zwischen NLDs und Operationendokumentationen. Sie generieren dann Klarstellungsfragen (CQAs) mithilfe von Vorlagen, sowohl als Ja/Nein- als auch als Mehrfachauswahlfragen.

Die Experimente zeigen, dass ihr Ansatz effektiv fehlerhafte Schlüsseloperationen erkennt und die Code-Qualität verbessert. Die Pipeline, bestehend aus einem Bedarfsvorhersager für Klarstellungen, einem Frageauswähler und einem Code-Generator, übertrifft die Leistung eines Modells allein. Die Analyse deutet darauf hin, dass die Einbeziehung klarer Schlüsseloperationen zu besseren generierten Codes führt, obwohl die Aufgabe aufgrund der Herausforderung, die richtigen Fragen zu priorisieren, noch nicht vollständig gelöst ist.

Die Autoren stellen ihr Dataset und Code zur Verfügung und fordern Feedback ein, um zukünftige Verbesserungen in diesem spannenden Forschungsgebiet voranzutreiben.</sample>
    <sample id="354">Basierend auf der Präsentation, das Leistungsdelta zwischen CoNLL-2003 und CoNLL++ ist höher als 5 Prozentpunkte bis zum Jahr 2023. Dies wird durch die beobachteten "percentage change in F1" Werte und die Experimente zur Bestätigung der Hypothesen über adaptive Überanpassung (adaptive overfitting) und zeitliche Drift (temporal drift) unterstützt.</sample>
    <sample id="355">## Präsentation: Transferlernen für die Dissonanzerkennung: Bewältigung der Seltenklassenherausforderung

**Einführung**

Hallo, ich bin Vasudha und bin Doktorandin im Bereich Informatik an der Stony Brook University. Ich möchte unsere Arbeit, die in ACL 2023 als Langpapier akzeptiert wurde, präsentieren: "Transferlernen für Dissonanzerkennung: Bewältigung der Seltenklassenherausforderung".

Zunächst erklären wir, was wir mit kognitiver Dissonanz meinen: Zwei widersprüchliche Überzeugungen oder Handlungen, wie zum Beispiel: "Ich weiß, dass Zigaretten tödlich sein können" und "Ich habe nach dem Meeting ein paar Zigaretten geraucht".  Die erste Aussage ist eine Überzeugung, die zweite eine Handlung, die im Widerspruch zur ersten steht. Eine weitere Aussage wie "Ich glaube nicht, dass ich ohne sie meinen Job behalten könnte" rechtfertigt die zweite Handlung. Diese beiden Aussagen haben eine Konsonanzbeziehung.

Obwohl Dissonanz ein sehr häufiges Phänomen im täglichen Entscheidungsprozess ist, ist es in der Sprache selten explizit ausgedrückt. Warum ist das wichtig? Die Untersuchung von kognitiver Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends und Überzeugungsstärken zu verfolgen, Einstellungswandeln in der Bevölkerung zu erkennen, und auch Angststörungen besser zu verstehen. Sie kann auch Einblicke in die Extremismus- und Polarisierungstendenzen vulnerabler Gruppen geben.  Zudem hilft sie, individuelle kognitive Stile zu verstehen und unsere Entscheidungsprozesse besser zu erfassen.

**Datenerfassung und Herausforderungen**

Um eine Ressource für kognitive Dissonanz zu erstellen, haben wir eine große Menge an Dissonanzbeziehungen annotiert. Wir verwendeten einen dissonanz-fokussierten Ansatz, wie im Flowchart dargestellt. Tweets wurden mit dem PDTB-Parser verarbeitet und Paare von Diskursseinheiten nach den in unserer Arbeit beschriebenen Richtlinien annotiert. Wie man sieht, wurden nur 3,5% der annotierten Paare als dissonanzierend eingestuft. Nach der Sammlung von etwa 1000 Beispielen haben wir ein anfängliches Klassifizierungsmodell mit nur 43 Beispielen trainiert. Wie erwartet erreichte das Modell nicht viel mehr als Zufallstreffer.

Die Seltenheit von Dissonanz und das Fehlen eines vergleichbaren Datensatzes stellen eine Herausforderung dar. Um dies zu überwinden, experimentierten wir mit Kombinationen aus Transferlernen und aktiver Lernmethoden, um die Anzahl der dissonanten Proben bei geringeren Annotationsaufwand zu erhöhen und so die Gesamtkosten zu senken, während die Dissonanzerkennung verbessert wird. Da das anfängliche Modell die Dissonanzklasse überhaupt nicht erfasste, starteten wir den aktiven Lernprozess durch Transfer von Gewichten aus verwandten Aufgaben. Wir transferierten von zwei Aufgaben:

* **Debattenstance-Klassifikation:** Bestimmt, ob zwei Aussagen aus Debatten von verschiedenen Personen übereinstimmen oder widersprechen, unabhängig vom Thema.
* **Klassifikation von Erweiterung und Vergleich (CE):**  Diese beiden Klassen stehen in engem Zusammenhang mit der Vorstellung von Konsonanz und Dissonanz.

Wir fanden heraus, dass selbst der Zero-Shot-Performance nach dem Transfer erheblich besser als Zufall ist, mit dem besten AUC von 0,62. Durch iteratives Feintuning der CE-Aufgabenfolge auf die Debattenstance-Aufgabe verbesserten wir die Zero-Shot-Performance weiter. Dieses Modell nutzten wir als Startpunkt für den aktiven Lern.

**Aktiver Lernprozess**

Um zu entscheiden, wie wir das Modell bei jeder Runde des aktiven Lernens mit neuen Daten aktualisieren, verglichen wir zwei Methoden:

* **Kumulativ:** Alle Daten, die bisher im aktiven Lernprozess gesammelt wurden, werden verwendet.
* **Iterativ:** Das Modell wird mit den neuesten Daten aus jeder Runde aktualisiert.

Wir stellten fest, dass kumulative Aktualisierung in den meisten Fällen gleichwertig oder besser funktioniert als die iterative Aktualisierung.

Um die Anzahl dissonanter Beispiele zu erhöhen, setzten wir die **Probability-of-Rare-Class (PRC)**-Strategie ein, um Beispiele mit hoher Wahrscheinlichkeit für Dissonanz auszuwählen. Wir verglichen PRC mit anderen, in der Community üblichen, aktiven Lernstrategien. PRC erwies sich als effektiver als die anderen Strategien, obwohl der Unterschied gering ist. Die Leistung ist deutlich schlechter für die zufällige Auswahl.

In weiteren Runden des aktiven Lernens mit den beiden besten Strategien konnten wir die Dissonanz-Klassifizierungs-AUC auf 0,75 verbessern, das ist unsere bisher beste Leistung.

**Abschluss**

Zusammenfassend lässt sich sagen, dass PRC eine einfache aktive Lernstrategie für die Gewinnung seltener Klassen ist und bei der Dissonanzerkennung hilft. Wir fanden außerdem heraus, dass eine iterative Aktualisierung für Transferlernen zwischen Domänen nützlich ist, während kumulative Aktualisierung bei der aktiven Annotation innerhalb einer Domäne besser funktioniert.

Unsere Daten und das Papier finden Sie im Anhang.  Kontaktieren Sie uns gerne, wenn Sie Fragen haben. Vielen Dank.</sample>
    <sample id="356">Die Autoren gehören der **Technische Universität Dresden** an, wie aus der Erwähnung von Alexander Koller und Ivan Titov als ihre Berater hervorgeht.</sample>
    <sample id="357">Siyu Yuan</sample>
    <sample id="358">An der Arbeit sind 5 Autoren beteiligt: Kayo Yin, Patrick Fernandes, Emmy Liu, André F. T. Martins und Graham Neubig.</sample>
    <sample id="359">Der Ansatz wird mit folgenden SimulST-Architekturen verglichen:

1. **Wait-k Strategie**
2. **Local Agreement**
3. **State-of-the-art Architektur speziell für gleichzeitige Vorübersetzung**</sample>
    <sample id="361">**Abstract:**

Armineh Nourbakhsh präsentiert ihre Forschung zum Thema "CounterComp", die sich auf die Verbesserung der allgemeinen Verallgemeinerung bei mehrschrittigen quantitativen Schlussfolgerungen konzentriert, insbesondere bei Fragebeantwortungsaufgaben in Finanztabellen. Aktuelle neuronale Modelle kämpfen mit mehrschrittigen Aufgaben, da sie neigen, zufällige Muster zu memorisieren.

Die Studie schlägt einen neuartigen Ansatz vor, der auf Counterfactual-Szenarien basiert. Anstatt zusätzliche Aufsicht zu erfordern, extrahiert das System aus den Trainingsbeispielen positive und negative Gegenbeispiele, indem es Fragekomponenten variiert, die den Ausgangseingaben entsprechen. Diese Gegenbeispiele werden dann verwendet, um eine zusätzliche metrische Lernverlustfunktion zu implementieren, die die Modellleistung verbessert.

Die Ergebnisse zeigen, dass diese Methode, genannt CounterComp, die Leistung bei in- und out-of-Distribution-Daten konsistent verbessert, insbesondere bei mehr als zwei Schritten der quantitativen Schlussfolgerung. Qualitative Analysen deuten darauf hin, dass das Modell durch CounterComp-Verluste dazu angeleitet wird, relevante Token in der Eingabe zu beachten, die mit bedeutenden operativen Begriffen in der Ausgabe korrelieren.

Die Arbeit zielt darauf ab, die Fähigkeit von Modellen zu verbessern, allgemeine Regeln aus spezifischen Beispielen abzuleiten, was für eine breite Palette von Anwendungen in der natürlichen Sprachverarbeitung und künstlichen Intelligenz von entscheidender Bedeutung ist.</sample>
  </task>
</testset>