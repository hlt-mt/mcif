<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="it">
    <sample id="0">Le principali fonti di dati per i modelli linguistici includono **grandi dataset derivanti da web crawl, con una significativa copertura di notizie politiche da fonti come il New York Times, Los Angeles Times, The Guardian e Huffington Post**. Questi dati offrono una diversità di prospettive, ma contengono anche pregiudizi sociali intrinseci che possono portare a potenziali problemi di equità nei modelli e nelle loro applicazioni downstream.</sample>
    <sample id="1">Gli autori dell'articolo, Akshatha e Martin, sono affiliati a:

- McGill University
- Mila
- Microsoft Research</sample>
    <sample id="2"># **LayoutMask: Un modello pre-addestrato per la comprensione di documenti visivamente ricchi**

Questo articolo presenta LayoutMask, un innovativo modello pre-addestrato per la comprensione di documenti visivamente ricchi (VRDU) che affronta le sfide legate all'ordine di lettura nei documenti. I modelli precedenti utilizzano posizioni globali 1D, rappresentando l'ordine di lettura dei token, ma questo approccio può essere problematico per documenti complessi.

LayoutMask introduce un nuovo approccio utilizzando solo informazioni testuali e di layout come input. Si concentra sull'aumento delle interazioni testo-layout e delle rappresentazioni di layout durante la fase di pre-addestramento. Il modello propone "posizioni locali 1D", che considerano l'ordine dei token all'interno di ogni segmento, anziché un ordine globale.

La ricerca introduce due nuove strategie di mascheramento per il compito di Masked Language Modeling: Whole Word Masking e Layout-Aware Masking. Il Whole Word Masking maschera i livelli di parola, aumentando la complessità, mentre il Layout-Aware Masking favorisce l'attenzione ai contesti trasversali dei segmenti. Viene anche introdotto un nuovo obiettivo, Masked Position Modeling, che prevede il recupero di posizioni 2D mascherate.

Gli esperimenti dimostrano l'efficacia di LayoutMask, mostrando che l'uso di posizioni locali 1D migliora le prestazioni su set di dati come FUNSD e SROIE. Il modello gestisce meglio i casi complessi con layout multipli e numeri fuorvianti, come illustrato negli esempi di SROIE. Questo studio contribuisce allo sviluppo di modelli pre-addestrati più robusti per la comprensione di documenti visivamente ricchi.</sample>
    <sample id="3">## Presentazione di DEPLAIN: Un nuovo corpus per l'identificazione testuale in tedesco

**Introduzione**

Benvenuti alla presentazione di DEPLAIN, un nuovo corpus dedicato all'identificazione di testi in tedesco a livello documentale e frasale. Mi chiamo Regina Stodden e vi guiderò attraverso la prima parte.

**Cos'è la semplificazione testuale?**

La semplificazione testuale è un processo che adatta un testo per migliorare la comprensibilità per un gruppo target specifico, come persone con difficoltà di lettura o non madrelingua. Per addestrare un modello di semplificazione testuale, abbiamo bisogno di coppie parallele di testi, ad esempio documenti o frasi. Come si può vedere nell'esempio, diverse tecniche possono essere utilizzate per semplificare una frase, come la sostituzione lessicale, la cancellazione di clausole, la riorganizzazione o l'inserimento di parole.

**Problemi con i corpus esistenti**

Negli ultimi anni, i corpus esistenti per la semplificazione testuale in tedesco hanno presentato alcune problematiche. Sono spesso troppo piccoli per addestrare un modello efficace e alcuni sono allineati automaticamente, il che può portare a errori.

**Presentazione di DEPLAIN**

Proponiamo quindi DEPLAIN, un nuovo corpus suddiviso in due sottocorpi: DEPLAIN-apa e DEPLAIN-web.

* **DEPLAIN-apa:** basato su testi di notizie, comprende 483 documenti allineati manualmente, generando circa 13.000 coppie di frasi parallele.

* **DEPLAIN-web:** copre diversi domini e include 750 documenti allineati sia manualmente che automaticamente. Questo porta a un totale di 30.450 coppie di frasi.

Abbiamo analizzato le nostre coppie di frasi per capire il tipo di semplificazione presente. I testi biblici sono significativamente più semplificati rispetto ai testi di notizie o a quelli destinati agli studenti di lingua. Il livello di semplificazione varia in base al tipo di testo e alle tecniche utilizzate.

**Utilizzo di DEPLAIN**

DEPLAIN offre diverse possibilità di utilizzo:

* **Valutazione di metodi di allineamento automatico:**  Il corpus può servire come standard d'oro per valutare l'accuratezza di metodi di allineamento automatico tra frasi in tedesco con lo stesso contenuto ma livelli di complessità diversi. La ricerca ha dimostrato che il metodo MASSalign è il più efficace per questo scopo.

* **Semplificazione automatica del testo:**  Abbiamo addestrato due modelli linguistici, long-mBART e base mBART, per generare testi semplificati da testi complessi. I risultati superano le prestazioni di base, offrendo una nuova base di riferimento per la semplificazione automatica del testo in tedesco.

**Conclusione**

Speriamo che DEPLAIN diventi uno strumento prezioso per la ricerca sulla semplificazione testuale in tedesco. Grazie per l'attenzione e ci auguriamo di incontrarvi durante la conferenza.</sample>
    <sample id="4">Il nome della relatrice è Kayo Yin.</sample>
    <sample id="5">Hanno utilizzato il modello T5 XL.</sample>
    <sample id="6"># **Verso una Summarizzazione Multilingue e Cross-Lingue Unificata**

Questo lavoro di ricerca presenta un approccio innovativo alla summarizzazione di documenti in più lingue, chiamato "many-to-many summarization". Gli autori propongono di unificare la summarizzazione multilingue (dove la sintesi è nella stessa lingua della fonte) e cross-lingue (dove la sintesi è in una lingua diversa) in un unico quadro.

La loro metodologia si concentra sulla creazione di un modello di sintesi in grado di elaborare un documento in qualsiasi lingua di origine e generare una sintesi in qualsiasi lingua di destinazione. Attraverso studi preliminari, dimostrano che questo approccio unificato migliora la capacità del modello di trasferire conoscenze di task tra lingue diverse rispetto ai metodi tradizionali.

Viene introdotto PISCES, un modello pre-addestrato many-to-many che apprende capacità di linguaggio, cross-lingue e sintesi attraverso un processo di pre-addestramento in tre fasi. Gli esperimenti condotti su un dataset di riferimento, WikiLingua, coinvolgono modelli basati su mBART-50 in diverse configurazioni: addestramento separato, addestramento unificato e molti-a-molti. I risultati evidenziano i vantaggi dell'approccio many-to-many, dimostrando che il modello unificato supera le prestazioni dei metodi tradizionali.

PISCES, il modello proposto, supera le prestazioni di baselines come mBART-50 e mT5, come dimostrato dagli esperimenti. Gli studi di ablatte e le valutazioni umane confermano l'efficacia del metodo. Questo lavoro contribuisce significativamente all'avanzamento della summarizzazione multilingue e cross-lingue, offrendo un nuovo paradigma per la gestione di documenti in un mondo globalizzato.</sample>
    <sample id="7">Sì, secondo la ricerca presentata, i tagger CoNLL-2003 funzionano ancora bene nel 2023. Gli autori hanno scoperto che, con una migliore architettura del modello, dimensioni più grandi e un maggior numero di esempi di fine-tuning, questi tagger possono generalizzare efficacemente ai dati moderni. Inoltre, hanno identificato il "temporal drift" come la principale causa del calo delle prestazioni, piuttosto che l'overfitting adattivo.</sample>
    <sample id="8">Il metodo di valutazione umana proposto, chiamato ABC-Eval, introduce un approccio **dimensionale** e **più preciso** per valutare la qualità delle conversazioni AI.

A differenza dei metodi tradizionali che si affidano a giudizi soggettivi (come scale di valutazione o confronti), ABC-Eval **annota specificamente i comportamenti** del modello, come risposte irrilevanti, contraddizioni o violazioni della logica. Questo consente di:

* **Ridurre la soggettività** nella valutazione.
* **Misurare con maggiore precisione** diversi aspetti della qualità della conversazione.
* **Identificare i punti di forza e di debolezza** dei modelli in modo più dettagliato.</sample>
    <sample id="9">Il successo degli attuali approcci di apprendimento scarsamente supervisionato (WSL) si basa in larga misura sulla disponibilità di **dati di validazione puliti e manualmente annotati**.

La ricerca evidenzia che:

* I metodi WSL richiedono dati di validazione puliti per funzionare correttamente.
* Aumentare il numero di campioni puliti migliora le prestazioni.
* L'utilizzo diretto dei dati puliti per il fine-tuning può portare a prestazioni migliori rispetto ai metodi WSL.
* Le affermazioni sui vantaggi dei metodi WSL rispetto ai semplici approcci di fine-tuning sono spesso esagerate.</sample>
    <sample id="10">Per migliorare il punteggio, diversi approcci possono essere considerati:

1. **Aumento della quantità e varietà dei dati**: La creazione di un dataset più ampio e diversificato, come l'AltEntities Corpus, può aiutare i modelli a generalizzare meglio.

2. **Miglioramento della qualità del background knowledge**: Fornire al modello informazioni più precise e complete sul contesto può aumentare l'accuratezza.

3. **Integrazione di tecniche di apprendimento attivo**: Selezionare e presentare al modello solo le informazioni più rilevanti può migliorare l'efficienza dell'apprendimento.

4. **Sviluppo di modelli più robusti**: Addestrare modelli linguistici più avanzati, come quelli basati su architetture Transformer, con tecniche di pre-addestramento e fine-tuning può aumentare la capacità di comprensione del contesto.

5. **Valutazione e raffinamento delle strategie di disambiguazione**: Ottimizzare gli algoritmi che generano le domande alternative e le risposte indirette può migliorare la precisione.

6. **Test in scenari reali**: Valutare i modelli in contesti conversazionali reali, con feedback continui, può aiutare a identificare e correggere errori specifici.</sample>
    <sample id="11"># **Do Androids Laugh at Electric Sheep? Humor Understanding Benchmarks from The New Yorker Caption Contest**

La presentazione di Jack Hessel esplora la capacità dei grandi modelli linguistici di comprendere e generare umorismo, sollevando domande su quanto siano davvero intelligenti. Hessel e i suoi collaboratori hanno creato un dataset basato sul concorso di didascalie di cartoni animati di *The New Yorker*, che offre tre compiti: abbinamento di didascalie, ordinamento di qualità e generazione di spiegazioni umoristiche.

I modelli, inclusi CLIP e GPT-4, sono stati testati su questi compiti. Il modello CLIP ha raggiunto un'accuratezza del 62% nel compito di abbinamento, superando il 20% di base casuale, ma ancora lontano dal 94% di prestazioni umane. GPT-4, pur con condizioni aggiuntive, ha mostrato un divario significativo rispetto agli esseri umani.

La generazione di spiegazioni umoristiche ha rivelato errori nei modelli, con GPT-4 che a volte attribuisce erroneamente il dialogo ai personaggi sbagliati. Gli esperimenti di valutazione umana hanno dimostrato che le spiegazioni generate dagli esseri umani sono preferite a quelle di GPT-4 in oltre due terzi dei casi.

Lo studio evidenzia la sfida di far comprendere l'umorismo alle macchine e invita la comunità di ricerca a esplorare ulteriormente questo dataset per migliorare le capacità di comprensione dell'umorismo nell'intelligenza artificiale. Hessel conclude sottolineando l'entusiasmo per il futuro di questo campo e il suo potenziale impatto sulla tecnologia dell'IA.</sample>
    <sample id="12">L'articolo è il risultato di un lavoro congiunto di **5** autori: Dawei (il presentatore), Xiaoyu Shen, Marius Mosbach, Andreas Stephan e Dietrich Klakow.</sample>
    <sample id="13"># **Finding the SWEET Spot: Un'analisi e un miglioramento dell'inferenza adattiva in ambienti a bassa risorsa**

Questa presentazione esplora l'inferenza adattiva, una tecnica per ottimizzare i tempi di elaborazione dei grandi modelli linguistici. L'idea centrale è sfruttare la variazione della complessità dei dati reali per ridurre i costi medi dell'inferenza, sia in termini di tempo che di costi economici.

Vengono confrontati due metodi comuni di inferenza adattiva: Multi Model e Early Exit. Il Multi Model addestra e mantiene più modelli, consentendo un'elaborazione sequenziale fino a quando un classificatore interrompe il processo. Al contrario, l'Early Exit addestra più classificatori a strati intermedi del modello, risparmiando calcoli inutili.

Lo studio evidenzia i vantaggi e gli svantaggi di entrambi gli approcci. Il Multi Model offre versatilità e scalabilità, ma è costoso in termini di memoria e presenta overhead durante l'inferenza. L'Early Exit, invece, è più efficiente in termini di tempo e memoria, ma i parametri condivisi tra i classificatori possono portare a conflitti di gradienti, influenzando negativamente le prestazioni.

I ricercatori hanno testato le loro ipotesi attraverso un confronto diretto tra i classificatori Early Exit e Multi Model su modelli BERT pre-addestrati. I risultati dimostrano che i classificatori Multi Model superano quelli Early Exit, soprattutto nelle fasi iniziali.

Viene quindi introdotto il metodo SWEET (Separating Weights in Early Exit Transformers), che risolve il problema dei conflitti di gradienti. SWEET addestra l'architettura Early Exit in modo che ogni strato riceva aggiornamenti solo dal classificatore successivo, migliorando le prestazioni e l'efficienza in vari scenari.</sample>
    <sample id="14">## La struttura dipendente della coordinazione: un'argomentazione a favore della simmetria

Ciao, mi chiamo Adam Przepiórkowski e il mio intervento riguarda la **struttura dipendente della coordinazione**. Come sapete, diverse teorie e approcci corpus-based ipotizzano strutture dipendenti differenti. Ad esempio, nell'**Universal Dependencies**, la struttura di coordinazione, come Lisa, Bart e Maggie, ha come testa l'elemento iniziale della struttura coordinata, ovvero Lisa. Un approccio simile è adottato dalla teoria del testo significativo di Igor Mel'čuk, dove anch'esso la struttura coordinata è guidata dal primo elemento. Questi due approcci sono **asimmetrici**, in quanto individuano uno dei elementi coordinati come principale.

Esistono altre due prospettive asimmetriche sulla coordinazione, come l'**approccio congiuntivo guidato** della scuola di Praga, dove la struttura coordinata è guidata dal congiunto, generando dipendenze dal governante a tutti gli elementi coordinati. Infine, c'è l'**approccio multi-testa** utilizzato, ad esempio, nella Word Grammar di Hudson, dove si afferma che **tutti i congiunti sono teste** della struttura coordinata, con dipendenze dal governante a ciascuno di essi separatamente.

L'obiettivo di questo studio è fornire un nuovo argomento a favore di strutture coordinate **simmetriche**, come quelle sopra menzionate, e contro le strutture **asimmetriche**. L'argomentazione si basa sul **principio della minimizzazione della lunghezza della dipendenza**.

In inglese, è noto che gli oggetti diretti tendono a stare vicini al verbo, mentre gli incidenti possono essere più distanti. Per esempio, la frase "Marge ha letto *questo assolutamente affascinante libro sulle api* ieri" è grammaticalmente corretta, anche se l'oggetto diretto "questo assolutamente affascinante libro sulle api" è molto lungo. Questo perché, anche se viola il principio generale che vuole gli oggetti diretti vicini al verbo, soddisfa il principio di minimizzazione della lunghezza della dipendenza, che preferisce le dipendenze più brevi.

Nel nostro studio, abbiamo analizzato statistiche sulla coordinazione tratte dalla versione migliorata del Penn Treebank e confermato osservazioni precedenti: i congiunti di sinistra tendono ad essere più brevi, sia in termini di sillabe che di parole. Questa tendenza aumenta con la differenza di lunghezza tra i due congiunti, con il congiunto più breve che spesso precede.

La novità del nostro studio sta nel notare che questa tendenza si verifica solo quando il governante è a sinistra o assente. In presenza di un governante a sinistra, come in "Ho visto Bart e Lisa", o in coordinazioni di frasi senza governante esterno, come in "Homer è venuto e si è starnutito", il congiunto di sinistra è preferibilmente più breve. Invece, quando il governante è a destra, come in "Ha riso e Ned", questo effetto scompare.

Misurando la lunghezza in caratteri, sillabe e parole, abbiamo osservato che la tendenza del congiunto di sinistra ad essere più breve aumenta con la differenza assoluta in parole quando il governante è a sinistra o assente. Al contrario, quando il governante è a destra, la tendenza scompare. Questi risultati forniscono un argomento contro le strutture coordinate asimmetriche e a favore di quelle simmetriche.

Per ulteriori dettagli, consultate il nostro articolo e venite a discuterne con noi alla sessione poster. Grazie!</sample>
    <sample id="15">L'articolo è il risultato di un lavoro congiunto di **tre** autori: Matthias Lindemann, Alexander Koller e Ivan Titov.</sample>
    <sample id="16">Basandosi sul contenuto presentato, i domini che risultano più semplificati nel corpus DEPLAIN sono:

1. **Biblia**: I testi biblici sono stati semplificati in modo più marcato rispetto ad altri domini.
2. **News (DEPLAIN-apa)**: I testi di notizie mostrano un livello significativo di semplificazione, specialmente in termini di struttura e complessità lessicale.
3. **Linguaggio Learner (non specificato)**: Anche i testi destinati agli apprendisti della lingua mostrano un alto grado di semplificazione.

Il corpus DEPLAIN, con la sua varietà di trasformazioni di semplificazione, offre una rappresentazione completa di come diversi tipi di testi possono essere adattati per migliorare la comprensione.</sample>
    <sample id="17"># **Multimodal Relation Extraction: Unlocking Contextual Understanding**

La ricerca si concentra sul miglioramento del compito di estrazione delle relazioni (RE) in scenari reali, dove i dati assumono varie forme e modalità. L'obiettivo è affrontare le sfide poste dall'ambiguità delle parole e dalla mancanza di contesto in testi non strutturati, utilizzando prove visive aggiuntive.

Il lavoro introduce un approccio innovativo per la multimodale estrazione delle relazioni, affrontando due problemi principali. In primo luogo, l'over-utilizzazione delle informazioni interne, dove solo parti del testo sono rilevanti per l'inferenza delle relazioni. In secondo luogo, l'under-esplorazione delle informazioni esterne, poiché le caratteristiche visive non sempre migliorano le prestazioni.

La soluzione proposta include due passaggi chiave. In primo luogo, viene implementato un principio di Bottleneck Informativo di Grafico per guidare la raffinazione delle caratteristiche, rimuovendo nodi e regolando gli edge in un grafico unificato che combina informazioni testuali e visive. In secondo luogo, vengono integrate le caratteristiche del tema multimodale per arricchire il contesto.

Gli esperimenti su un dataset MRE ben noto dimostrano l'efficacia dell'approccio. I risultati mostrano che l'uso di caratteristiche visive migliora le prestazioni rispetto ai metodi testuali, e i metodi proposti superano i baseline multimodali. L'analisi delle prestazioni evidenzia il ruolo cruciale dello screening delle informazioni interne ed esterne a seconda della rilevanza del testo e della visione.

In sintesi, questo studio introduce una tecnica avanzata per la multimodale RE, migliorando significativamente i risultati e aprendo nuove prospettive per la comprensione contestuale in vari domini.</sample>
    <sample id="18">L'esempio della preferenza per i congiunti a sinistra più brevi è illustrato nella frase "I saw Bart and Lisa" dove, a differenza di "Homer came and sneezed" (senza governante esterno), il congiunto a sinistra ("Bart and Lisa") è preferibilmente più breve quando il governante è a sinistra o assente. Questa osservazione è supportata da statistiche che mostrano una tendenza crescente per il congiunto più corto quando c'è una differenza significativa di lunghezza tra i due elementi coordinati e il governante è a sinistra.</sample>
    <sample id="19"># **A Survey for Efficient Open Domain Question Answering**

La ricerca si concentra sull'ottimizzazione dei sistemi di risposta alle domande in dominio aperto, affrontando le sfide legate alla complessità e alle risorse richieste. Lo studio propone un'analisi approfondita dei modelli esistenti, con un'attenzione particolare all'efficienza in termini di memoria e velocità di inferenza.

Il lavoro introduce un approccio per migliorare le prestazioni dei sistemi di risposta alle domande, affrontando tre aspetti chiave: la ricerca rapida di evidenze, la lettura efficiente e la riduzione delle dimensioni dell'indice. Vengono esaminate tecniche come la ricerca dell'approssimazione del vicino più vicino, lo skip reading e la compressione degli embedding. Inoltre, si discute la riduzione delle dimensioni del modello attraverso l'uso di modelli leggeri o la condivisione dei parametri.

L'analisi confronta i sistemi di tipo retrieval-only, reader-only e i modelli ibridi, evidenziando i compromessi tra velocità, memoria e prestazioni. I risultati suggeriscono che i sistemi retrieval-only sono ideali per il feedback in tempo reale, mentre i sistemi retrieval e reader offrono un equilibrio più adatto per scenari con requisiti variabili.

Lo studio conclude con due direzioni future: l'implementazione di sistemi di risposta alle domande su dispositivi a basso consumo energetico e l'esplorazione di metriche di valutazione aggiuntive per una comprensione più completa delle prestazioni dei modelli. Questo lavoro fornisce una panoramica completa delle strategie per migliorare l'efficienza nell'ambito dell'open domain question answering.</sample>
    <sample id="20">Sì, puoi usare i modelli DrBERT e ChuBERT per la tua ricerca. Sono stati resi disponibili gratuitamente su Hugging Face e GitHub, sotto la licenza MIT. Questi modelli sono stati addestrati su dati biomedicali e clinici in francese e possono essere utili per una varietà di compiti di elaborazione del linguaggio naturale (NLP) nei domini sanitario e clinico.

Tieni presente che i modelli sono stati valutati su diverse attività e potrebbero essere più efficaci per compiti specifici in base alla natura dei dati su cui sono stati addestrati. Assicurati di consultare l'articolo e i risultati della ricerca per ulteriori dettagli e per scegliere il modello più adatto alle tue esigenze.</sample>
    <sample id="21">DEPLAIN-apa contiene **testi di notizie**. 

È stato manualmente allineato con 483 documenti.</sample>
    <sample id="22">Secondo la presentazione, per ottenere una buona generalizzazione, i fattori chiave includono:

1. **Architettura del modello**: I modelli basati su transformer tendono a generalizzare meglio.
2. **Dimensione del modello**: Modelli più grandi generalmente offrono una migliore generalizzazione.
3. **Quantità di esempi di fine-tuning**: Un numero maggiore di esempi di fine-tuning migliora le prestazioni e la generalizzazione.</sample>
    <sample id="23">**Abstract**

Il nostro studio si concentra sul miglioramento della capacità dei modelli di testo-immagine di rappresentare visivamente il testo, un aspetto in cui hanno riscontrato difficoltà nonostante i progressi significativi nell'generazione di immagini di alta qualità. Analizziamo il modello Imagen, che combina un encoder T5-XXL per il testo con un modello di diffusione per la generazione delle immagini. Abbiamo riscontrato che, anche con input testuali semplici, il modello spesso fallisce nel rappresentare correttamente il testo.

La causa principale risiede nel modo in cui T5 gestisce il tokenizzazione: utilizza SentencePiece che, a differenza dell'analisi lettera per lettera, impiega ID di sotto-parole. Questo rende difficile per il modello decomporre parole complesse in lettere individuali. I nostri esperimenti hanno dimostrato che, mentre i modelli T5 più grandi raggiungono una precisione di ortografia sotto il 70%, i modelli PaLM, sebbene più precisi, sono significativamente più grandi e meno pratici.

Per superare queste limitazioni, abbiamo introdotto ByT5, un modello che riceve i singoli byte della stringa di input, permettendogli di accedere all'informazione ortografica in modo completo. ByT5 eccelle in ortografia a tutte le scale. Abbiamo scoperto che le parole più frequenti rappresentano una sfida maggiore per T5 a causa della compressione in un unico token.

Per migliorare i modelli di rendering testuale, abbiamo integrato Imagen con una rappresentazione testuale aggiuntiva derivante da ByT5-small, aumentando solo del 5% i parametri. Questo approccio ha migliorato significativamente la capacità del modello di ortografia e la qualità della generazione testuale.</sample>
    <sample id="24">La tendenza dei congiunti a sinistra a essere più brevi è stata misurata confrontando la lunghezza delle dipendenze cruciali in diverse strutture di coordinamento. Gli autori hanno analizzato il tempo, i sillabe e le parole per determinare la lunghezza delle dipendenze dal verbo principale ai congiunti. Hanno scoperto che quando il governante è a sinistra o assente, la lunghezza media del congiunto a sinistra è più breve rispetto a quella del congiunto a destra, confermando così l'osservazione precedente.</sample>
    <sample id="25">Gli esperimenti sono stati progettati estraendo statistiche da un'ampia banca dati (l'enhanced version del Penn Treebank) e analizzando vari aspetti della coordinazione. In particolare, gli studi si sono concentrati su:

1. **Lunghezza dei congiunti**: Confrontando la lunghezza dei congiunti in diverse strutture di coordinazione, si è osservato che i congiunti di sinistra tendono ad essere più corti.
2. **Posizione del governatore**: Si è esaminato l'effetto della posizione del governatore (a sinistra o a destra) sulla preferenza per la lunghezza del congiunto di sinistra. È stato riscontrato che la tendenza alla brevità del congiunto di sinistra si verifica solo quando il governatore è a sinistra o assente.
3. **Misurazione della lunghezza**: La lunghezza è stata misurata in caratteri, sillabe e parole per ottenere una visione completa dell'effetto.

Questi dati sono stati utilizzati per sostenere l'argomentazione a favore di strutture di coordinazione simmetriche e contro quelle asimmetriche.</sample>
    <sample id="26">Un classificatore base addestrato su dati non bilanciati (come nel caso della rara classe di dissonanza nel tuo studio) avrà prestazioni generalmente inferiori rispetto a quelle attese. Senza un'adeguata rappresentanza della classe target (dissonanza, in questo caso), il modello non riesce a imparare efficacemente a distinguerla dalle altre classi, ottenendo risultati non molto migliori del caso. Questo è il motivo per cui nel tuo studio avete affrontato la sfida dell'assoluta rarità utilizzando tecniche di transfer learning e active learning.</sample>
    <sample id="27">Basandomi sul contenuto fornito, l'articolo sembra essere il risultato del lavoro di un team, con Shangbin come presentatore principale. Tuttavia, il testo non specifica il numero esatto di autori coinvolti. Pertanto, la risposta concisa sarebbe: **Almeno 1 autore (Shangbin) con un team di ricerca non quantificato**.</sample>
    <sample id="28">I nomi dei personaggi nella conversazione presa a esempio sono Bob e Alice.</sample>
    <sample id="29">I modelli di traduzione machine (MT) sensibili al contesto migliorano significativamente rispetto a quelli indipendenti dal contesto in fenomeni del discorso come **formality** e **lexical cohesion**. Tuttavia, non mostrano un miglioramento sostanziale in altri fenomeni come **ellissi**, **pronomi** e **forma verbale**.</sample>
    <sample id="30">**Abstract:**

Il nostro lavoro, "LLM-Blender", introduce un semplice e potente framework di apprendimento ensembled per i grandi modelli linguistici (LLM), basato su ranking paio e fusione generativa. Rispondendo alla sfida di selezionare il modello ottimale per ogni input, LLM-Blender esegue più LLM e utilizza un modulo di ranking paio, *PairRanker*, per confrontare e ordinare le loro uscite. *PairRanker* analizza le differenze tra i candidati modelli codificando coppie di output insieme all'input, superando i metodi che valutano i modelli in modo indipendente.

Il framework aggrega i risultati del ranking paio per ottenere un ordine finale dei candidati, selezionando poi i primi *K* modelli per la fusione. Utilizziamo un modello sequenza-sequenza, *GenFuser*, per generare l'output finale fondendo le uscite dei migliori candidati.

Abbiamo creato *MixInstruct*, un nuovo dataset per l'evaluazione dei framework ensembled, raccogliendo output da 11 LLM open-source. I risultati sperimentali dimostrano che LLM-Blender supera costantemente altri metodi, incluso *Open Assistant* e *Vicuna*, in termini di accuratezza e coerenza.

In sintesi, LLM-Blender offre un approccio semplice ed efficace all'ensemble learning per LLM, migliorando le prestazioni e fornendo uno strumento prezioso per la valutazione e la ricerca futura. Il nostro codice e i dati sono disponibili per facilitare la riproducibilità e l'esplorazione.</sample>
    <sample id="31">Gli autori dell'articolo sono affiliati alle seguenti istituzioni:

- John Gauthier
- Aaron Mueller
- Kanishka Misra
- Karen Fences
- Roger Levy
- Adina Williams

Tutti questi ricercatori sono co-autori del paper presentato all'ACL 2023.</sample>
    <sample id="33">Il framework NLPositionality quantifica la posizionalità confrontando le annotazioni di un dataset con le risposte di utenti reali provenienti da diverse popolazioni. Utilizza un punteggio di correlazione di Pearson per misurare quanto le previsioni del modello o le etichette del dataset si allineano con le percezioni degli utenti su temi come la socialità o la tossicità del linguaggio. Questo approccio innovativo va oltre lo studio dell'accordo tra annotatori, esaminando direttamente la corrispondenza tra utenti e modelli/dataset.</sample>
    <sample id="34"># **CREST: Un quadro congiunto per la razionalizzazione e la generazione di controfattuali**

Questa presentazione introduce CREST, un innovativo approccio che combina razionalizzazione e generazione di controfattuali per migliorare la comprensibilità e le prestazioni dei modelli di intelligenza artificiale. L'obiettivo è fornire spiegazioni più significative delle decisioni prese dai modelli.

Il lavoro propone un quadro congiunto che include due componenti principali. Il primo genera controfattuali modificando selettivamente l'input, mentre il secondo produce razioni significative (Z) che giustificano la decisione del modello. I controfattuali, creati mascherando parti dell'input, vengono poi utilizzati per addestrare un modello di linguaggio mascherato, producendo esempi controfattuali (X-tilde).

La valutazione umana e automatica ha dimostrato che i controfattuali generati da CREST superano quelli di altri metodi, come MiCE. L'abstract evidenzia il potenziale di CREST in due applicazioni: data augmentation e razionalizzazione estesa. Nel primo caso, i controfattuali migliorano le prestazioni dei modelli su nuovi dati. Nel secondo, un flusso di razionalizzazione condiviso elabora sia esempi fattuali che controfattuali, producendo razioni più focalizzate.

L'analisi della razionalizzazione di CREST rivela la sua capacità di generare spiegazioni plausibili e simulabili, ovvero in grado di influenzare le decisioni del modello. In sintesi, CREST offre un metodo efficace e controllabile per la razionalizzazione e la generazione di controfattuali, con implicazioni significative per la comprensione e il miglioramento dei modelli di IA.</sample>
    <sample id="36"># **Approfondimento sulla ricerca: "Apprendimento di strati specifici della lingua per la traduzione automatica multilingue"**

Questo studio si concentra sull'aumento della capacità di traduzione automatica multilingue (MT) per migliorare le prestazioni, soprattutto per le lingue a bassa risorsa. I ricercatori propongono un approccio innovativo chiamato *Language-Specific Layers* (LSL) per affrontare le sfide associate alla MT multilingue.

L'idea principale è di aggiungere un livello di trasformazione specifico per ogni lingua, consentendo al modello di selezionare e addestrare dinamicamente il sottolayer appropriato durante l'inferenza. Questo approccio mantiene costanti i costi di inferenza, poiché solo il sottolayer selezionato viene utilizzato.

La ricerca si concentra sulla posizione ottimale di questi LSL all'interno del modello. Attraverso un'attenta sperimentazione, hanno scoperto che i pesi dei pesi di condivisione, sorgente e destinazione forniscono indicazioni sulla posizione migliore. Selezionando il componente con il peso più elevato, hanno sviluppato un'architettura personalizzata per ogni lingua.

Gli esperimenti hanno dimostrato che questo metodo supera le tecniche esistenti, inclusi i modelli di adattamento linguistico. Le valutazioni su un'ampia gamma di lingue, comprese quelle a bassa risorsa, hanno mostrato miglioramenti significativi, con un aumento della metrica chrF e spBLEU. L'approccio è stato testato statisticamente, confermando la sua efficacia in 84 delle 90 direzioni di traduzione.

In sintesi, questo lavoro presenta una tecnica promettente per migliorare la traduzione automatica multilingue, garantendo al contempo un'efficienza computazionale ottimale.</sample>
    <sample id="37">Lo studio precedente ha dimostrato che, quando sono stati dati agli esseri umani gli stessi prompt di generazione di persona, questi hanno prodotto risposte che riflettevano stereotipi razziali. Le descrizioni generate dagli umani presentavano una distribuzione più ampia di parole, ma i termini stereotipati erano limitati a "tall" e "athletic". Lo studio ha evidenziato come anche le descrizioni apparentemente positive possano veicolare stereotipi e narrazioni essenzialiste, rafforzando pregiudizi esistenti.</sample>
    <sample id="38">Nel suo studio, Adam Przepiórkowski ha utilizzato i dati dell'**enhanced version della Penn Treebank** e la **statistica presentata nel paper "Why wouldn't you use universal dependencies?"**. Questi dati hanno permesso di estrarre informazioni statistiche sulla coordinazione, confermando osservazioni precedenti riguardo alla lunghezza dei congiunti e alla loro posizione.</sample>
    <sample id="39">L'articolo è presentato da un solo autore, Adam Przepiórkowski.</sample>
    <sample id="40">Le attività strettamente correlate alla dissonanza cognitiva, come evidenziato nella presentazione, includono:

1. **Classificazione della Stance di Dissonanza**: Determinare se due affermazioni, provenienti da persone diverse, sono in accordo o in disaccordo, indipendentemente dall'argomento (task "debate").
2. **Classificazione di Espansione e Confronto**: Binaria classificazione delle classi di espansione e confronto del PDTB, che sono strettamente legate alla concezione di consonanza e dissonanza.

Questi task sono stati utilizzati per il trasferimento di apprendimento (transfer learning) al fine di migliorare la rilevazione della dissonanza cognitiva.</sample>
    <sample id="41">**Abstract:**

Il progetto "PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives" delinea un approccio innovativo per migliorare la coerenza e l'interazione nelle narrazioni attraverso la comprensione delle personalità dei narratori. Collaborando con Sony Group Corporation, il team dell'EPFL University ha sviluppato PeaCoK, un grafo di conoscenza comune basato su personalità che rappresenta 3.800 personalità e 40.000 attributi distintivi.

PeaCoK sfrutta grafici di conoscenza preesistenti e modelli linguistici pre-addestrati per indurre gli attributi delle personalità. Le relazioni tra personalità e attributi sono strutturate in tre dimensioni, comprese interazioni e unicità. Il grafo è stato costruito attraverso un processo in tre fasi, coinvolgendo annotazioni umane e AI per garantire alta precisione.

L'efficacia di PeaCoK è dimostrata in due compiti: la generazione di conoscenza comune e la modellazione del dialogo. Un modello BART addestrato su PeaCoK supera i modelli di riferimento GPT-3 e GPT-3.5 in varie metriche di generazione del linguaggio. Inoltre, l'integrazione di PeaCoK in un sistema di dialogo basato su P²Bot migliora la coerenza, l'interazione e l'espressione della personalità nelle conversazioni.

Gli studi evidenziano l'importanza delle connessioni tra personalità nel creare narrazioni coinvolgenti. PeaCoK, con le sue vaste inferenze basate su personalità, offre una risorsa preziosa per lo sviluppo di sistemi NLP più intelligenti e contestualmente consapevoli.</sample>
    <sample id="42">L'articolo è presentato da un singolo autore, Shuheng. Tuttavia, implica il lavoro di un team che ha sviluppato e testato vari modelli e dataset, come indicato nel contenuto.</sample>
    <sample id="43">L'articolo "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge" ha un solo autore principale, Vasudha, che è una PhD candidate in Computer Science presso Stony Brook University.

Quindi, la risposta è **1 autore**.</sample>
    <sample id="44">Il framework NLPositionality differisce dai lavori precedenti in quanto:

1. **Confronto diretto con gli utenti finali**: Mentre studi precedenti si concentravano su annotatori o modelli, NLPositionality confronta direttamente le annotazioni di utenti reali con dataset e modelli.

2. **Analisi della posizione (positionality)**: Non si limita a misurare l'accordo tra annotatori, ma esamina come le decisioni dei modelli e dei dataset riflettono specifiche posizioni sociali e culturali basate su demografia e contesto.

3. **Utilizzo di piattaforme di crowdsourcing globali**: NLPositionality sfrutta piattaforme come Lab in the Wild per raccogliere un gran numero di annotazioni da una vasta gamma di partecipanti provenienti da 87 paesi, ottenendo così una visione più completa e diversificata.</sample>
    <sample id="45">Dato il contenuto della presentazione, la configurazione che si sovrappone maggiormente al lessico degli stereotipi è quella delle **persona generate dal modello**. Gli autori scoprono che mentre le persona generate mostrano una frequenza più alta di parole del lessico stereotipato, le persona scritte dagli esseri umani presentano una distribuzione più ampia di parole, ma solo due parole stereotipate ("tall" e "athletic").

Pertanto, le persona generate dal modello, a causa della loro alta concentrazione su parole stereotipate positive o neutre, riflettono in modo più diretto e preoccupante gli stereotipi esistenti.</sample>
    <sample id="46">Nel contenuto fornito, vengono messi a confronto due sistemi commerciali: **DeepL** e **Google Translate**. Il benchmark sviluppato dagli autori mostra che DeepL è generalmente più accurato di Google Translate nella traduzione di documenti a livello documentale.</sample>
    <sample id="47">## Da Dati di Pretraining a Modelli Linguistici: Tracciare le Tracce dei Pregiudizi Politici verso Modelli NLP Equi

Salve, sono Shangbin, dottore di ricerca presso l'Università di Washington. Oggi presenterò il nostro lavoro **"Da Dati di Pretraining a Modelli Linguistici: Tracciare le Tracce dei Pregiudizi Politici verso Modelli NLP Equi"**.

I modelli linguistici vengono addestrati su enormi quantità di dati estratti dal web. I media di informazione politica sono ben rappresentati in questi dati di pre-addestramento. Secondo un'indagine sul corpus C4, testate come il New York Times, il Los Angeles Times, The Guardian e Huffington Post sono ampiamente presenti. Questo ha portato ad un risultato a doppio taglio: da un lato, i modelli hanno potuto apprendere da prospettive diverse, celebrando la democrazia e la pluralità di idee; dall'altro, queste diverse opinioni politiche sono intrinsecamente socialmente pregiudicate e potrebbero portare a problemi di equità nelle applicazioni NLP.

**Il nostro obiettivo:** indagare il processo di propagazione dei pregiudizi politici dai dati di pre-addestramento ai modelli linguistici e ai compiti downstream, ponendoci le seguenti domande:

1. **Come valutare il bias politico dei modelli linguistici e quale ruolo giocano i dati di pre-addestramento?**
2. **Come si comportano i modelli linguistici con diversi bias politici nei compiti downstream e ciò potrebbe portare a problemi di equità nelle applicazioni NLP?**

Per farlo, abbiamo proposto di:

* **Prompting** i modelli linguistici con diversi formati di prompt basati su questionari politici come il Political Conference Test, per una valutazione automatizzata radicata nella letteratura della scienza politica.

I risultati preliminari mostrano che:

* I modelli linguistici presentano effettivamente bias politici variabili, posizionandosi in tutti e quattro gli angoli dello spettro politico. GPT-4 si rivela il modello più liberale, mentre la serie GPT è generalmente più liberale della serie BART.
* I bias politici dei modelli linguistici possono essere **direttamente influenzati dai dati di pre-addestramento**. Un esperimento controllato ha dimostrato che il pre-addestramento aggiuntivo di checkpoint di modelli linguistici su 6 corpora partitisti (notizie e social media) ha portato a uno spostamento degli assi ideologici dei modelli. Ad esempio, pre-addestrando RoBERTa su un corpus Reddit di sinistra, si osserva un marcato spostamento verso sinistra nelle sue tendenze politiche.
* I modelli linguistici possono anche **riflettere la polarizzazione della società moderna**. Dividendo i corpora di pre-addestramento in base al periodo precedente o successivo al 45° Presidente degli Stati Uniti, abbiamo notato che i modelli tendono ad allontanarsi dal centro dopo il 2017, indicando la loro capacità di assorbire la polarizzazione.

**Valutazione di modelli con diversi bias politici in compiti reali:**

Abbiamo valutato modelli linguistici con diversi bias politici in compiti come la **deteczione di odio** e la **deteczione di fake news**, spesso coinvolti in applicazioni NLP con implicazioni significative.

I risultati mostrano che:

* **Deteczione di odio:** i modelli di sinistra sono più efficaci nel rilevare l'odio verso gruppi minoritari, mentre quelli di destra sono migliori nel rilevare l'odio verso bianchi e uomini.
* **Deteczione di fake news:** i modelli di sinistra sono più bravi a identificare le fake news provenienti da modelli di destra e viceversa.

Abbiamo fornito anche esempi qualitativi per illustrare come modelli con diversi bias politici possano dare previsioni diverse per odio e disinformazione basate sulla categoria sociale.

**Discussione:**

Il nostro lavoro evidenzia un **dilemma unico** legato ai bias politici dei modelli linguistici. Non intervenire sul contenuto politico nei dati di addestramento potrebbe portare alla propagazione del bias da questi dati ai modelli e ai compiti downstream, creando problemi di equità. Intervenire, invece, rischierebbe censura o esclusione e definire cosa sia "neutrale" nei dati di monitoraggio è estremamente difficile.

In conclusione, la gestione dei pregiudizi politici nei modelli linguistici richiede un'attenta riflessione e soluzioni innovative.</sample>
    <sample id="48">L'articolo è il risultato del lavoro congiunto di David Vilar e dei suoi colleghi da Google Translate. Quindi, il numero di autori coinvolti è di almeno due.</sample>
    <sample id="49">Le valutazioni MPP (Minimal Pair Paradigm) sono state eseguite fino a **1024 token** di lunghezza del contesto per i modelli OPT e GPT-2.</sample>
    <sample id="50"># **Presentazione di DEPLAIN: Un Nuovo Corpus per la Semplificazione Testuale Tedesca**

La presentazione introduce DEPLAIN, un corpus innovativo per l'identificazione e la semplificazione del testo tedesco a livello di documento e frase. L'oratrice, Regina Stodden, spiega che la semplificazione testuale è un processo cruciale per migliorare la comprensibilità del testo, utile per persone con difficoltà di lettura o non madrelingua.

Il corpus DEPLAIN risponde alle sfide riscontrate con i precedenti dataset, offrendo due sottocorpi: DEPLAIN-apa (basato su testi di notizie) e DEPLAIN-web (che copre vari domini). Entrambi i sottocorpi contengono coppie di frasi parallele, con 13.000 e 30.450 coppie rispettivamente, ottenute attraverso allineamenti manuali e automatici. L'analisi rivela differenze nella semplificazione tra testi biblici, notizie e materiali per apprendimento della lingua.

Omar, nel suo intervento, evidenzia due casi d'uso pratici. Il primo è l'evaluazione di metodi di allineamento automatico, dove DEPLAIN fornisce un set di dati di riferimento per confrontare le prestazioni di diversi algoritmi. Il secondo caso coinvolge la semplificazione automatica del testo, con la fine-tuning di modelli linguistici (come long-mBART e base mBART) per produrre testi semplificati. I risultati dimostrano che questa tecnica può migliorare i punteggi rispetto ai metodi di base.

In sintesi, la presentazione introduce DEPLAIN come una risorsa preziosa per la ricerca sulla semplificazione testuale tedesca, con applicazioni in vari ambiti, dalla valutazione degli algoritmi all'ottimizzazione dei modelli linguistici.</sample>
    <sample id="51">I domini inclusi nel loro set di dati sono stati la musica, i libri e le ricette.</sample>
    <sample id="52">La posizionalità, in generale, si riferisce alle prospettive e alle influenze che le persone acquisiscono in base alla loro demografia, identità ed esperienze di vita. Questo concetto è spesso utilizzato in studi critici, specialmente in ambiti accademici femministi e queer, per esplorare come questi fattori influenzano il processo di ricerca e i suoi risultati. Nel contesto dell'elaborazione del linguaggio naturale (NLP), la posizionalità si riferisce alle tendenze e alle preferenze che i dataset e i modelli mostrano verso determinati gruppi demografici o contesti culturali.</sample>
    <sample id="53">Il nome del relatore è Dawei.</sample>
    <sample id="54"># **Transfer Learning for Dissonance Detection: Un approccio innovativo per la comprensione del conflitto cognitivo nel linguaggio**

La ricerca presentata si concentra sulla comprensione e la rilevazione del conflitto cognitivo, o dissonanza, espresso nel linguaggio naturale, un aspetto cruciale per analizzare il processo decisionale umano e i fenomeni sociali. Lo studio affronta la sfida della rarità delle occorrenze di dissonanza, che rende difficile l'addestramento di modelli efficaci.

I ricercatori hanno creato un'ampia risorsa di dati annotando manualmente relazioni di dissonanza in coppie di unità discorsive, riscontrando che solo il 3,5% esprimeva dissonanza. Per superare la scarsità di dati, è stata impiegata una strategia di apprendimento attivo (AL) combinata con il trasferimento di apprendimento. Sono stati trasferiti pesi da compiti correlati, come la classificazione della posizione di consenso/disaccordo e la classificazione binaria di espansione e confronto.

L'approccio ha dimostrato un miglioramento significativo nelle prestazioni, raggiungendo un'area sotto la curva (AUC) di 0,75 per la classificazione della dissonanza. La strategia di apprendimento attivo proposta, basata sulla probabilità della classe rara (PRC), ha mostrato risultati migliori rispetto ad altri metodi comuni, aumentando il numero di esempi di dissonanza.

Lo studio evidenzia l'efficacia del trasferimento di apprendimento e dell'apprendimento attivo per affrontare problemi di classi rare, fornendo una comprensione più profonda della dissonanza cognitiva nel linguaggio e delle sue implicazioni in vari campi, tra cui la salute mentale, l'estremismo e la presa di decisioni.</sample>
    <sample id="55">Sì, EDAtt (Encoder-Decoder Attention) adatta un modello di traduzione automatica offline esistente senza richiedere un ritreinamento o l'adozione di una nuova architettura specifica per la traduzione simultanea. Utilizza un unico modello per ogni regime di latenza e gestisce la latenza attraverso parametri specifici, sfruttando la conoscenza già acquisita dal modello attraverso il meccanismo di attenzione tra input audio e output testuale.</sample>
    <sample id="56">L'articolo "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations" coinvolge un team di ricercatori, ma non è specificato il numero esatto di autori. Tuttavia, considerando la presentazione di Yusen Zhang e la descrizione dettagliata del progetto, si può dedurre che siano stati coinvolti diversi ricercatori dell'Università della Pennsylvania (Penn State University).</sample>
    <sample id="57">Sì, il modello testato mostra prestazioni significative sulla suite di test KITMUS, soprattutto quando è addestrato specificamente per essa. Tuttavia, anche i migliori modelli hanno difficoltà a integrare correttamente la conoscenza retrospettiva fornita solo al momento dell'inferenza.</sample>
    <sample id="58">Le tre varianti di KITMUS (Knowledge Integration from Multiple Sources Test) sono:

1. **Background-Pretrain**: Background conoscenza è assunta disponibile durante il pre-addestramento.
2. **Background-Both**: Background conoscenza è disponibile sia durante il pre-addestramento che all'inferenza.
3. **Background-Inference**: Solo la conoscenza specifica dell'entità è disponibile all'inferenza, simulando casi dove la conoscenza di sfondo non è contenuta nei dati di pre-addestramento (ad esempio, nuove occupazioni).</sample>
    <sample id="59">**Abstract:**

La presentazione introduce *DrBERT*, un modello pre-addestrato robusto in francese per le domini biomedici e clinici, rappresentando il primo modello biomedico in francese. Basato su RoBERTa, *DrBERT* è stato addestrato su NACHOS, un dataset di dati medici web-crawled.

L'articolo confronta *DrBERT* con modelli alternativi, esplorando l'impatto di diverse fonti di dati e strategie di pre-addestramento. Sono stati addestrati sette modelli, inclusi versioni *DrBERT* con 7GB e 4GB di NACHOS, un modello *ChuBERT* basato su dati clinici anonimi, e varianti con pre-addestramento continuo.

Le valutazioni su 11 compiti downstream biomedici e clinici in francese mostrano che i modelli performano meglio con dati di natura simile a quella di addestramento. I dati eterogenei si sono dimostrati più versatili, e una maggiore quantità di dati ha portato a migliori prestazioni.

L'addestramento da zero ha prodotto risultati migliori su molte attività, ma un modello basato su CamemBERT con pre-addestramento su un sottoinsieme di 4GB di NACHOS ha mostrato prestazioni comparabili a *DrBERT* da zero.

In conclusione, *DrBERT* ha superato i modelli generici come CamemBERT in nove compiti su undici, evidenziando il valore di dati specializzati. Tutti i modelli pre-addestrati sono disponibili pubblicamente su Hugging Face e GitHub.</sample>
    <sample id="60">Gli autori dell'articolo "Resolving Indirect Referring Expressions for Entity Selection" sono:

- Javad Hosseini
- Filip Radlinski
- Silvia Pareti
- Annie Louis

Tutti e quattro sono associati a istituti di ricerca o università, con un focus su intelligenza artificiale, elaborazione del linguaggio naturale e interazione uomo-computer.</sample>
    <sample id="61">L'ultima domanda di ricerca trattata nel video è: "Finalmente, quanti campioni puliti sono necessari per la validazione e ci sono metodi migliori per utilizzarli oltre alla semplice selezione del modello?"</sample>
    <sample id="62">**Abstract:**

Il paper "A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training" di Nitay Calderon e colleghi esplora tecniche di compressione per i sistemi di Generazione del Linguaggio Naturale (NLG), affrontando le sfide legate alle dimensioni e ai costi dei modelli linguistici.

L'approccio proposto si basa sulla *distillazione della conoscenza*, un processo che trasferisce le conoscenze da un modello di grandi dimensioni (il "maestro") a uno più piccolo (lo "studente"). Gli autori conducono uno studio sistematico su vari compiti NLG in scenari realistici, caratterizzati da dati etichettati limitati e abbondanti dati non etichettati.

La ricerca si concentra su due tipi di distillazione: a livello di parola e a livello di sequenza. La distillazione a livello di parola minimizza la divergenza di Kullback-Leibler tra le probabilità (logit) del maestro e dello studente. La distillazione a livello di sequenza utilizza il maestro per generare *pseudo-obiettivi*, testo generato dal modello, che vengono poi utilizzati per espandere il dataset di addestramento del modello studente.

Gli esperimenti coprono quattro compiti NLG: riassunto, generazione di domande, ragionamento di senso comune, semplificazione e trasferimento di stile. I risultati evidenziano l'importanza dei dati non etichettati per migliorare la distillazione e dimostrano che generare più pseudo-obiettivi, anziché uno solo, migliora le prestazioni dello studente.

Inoltre, viene introdotto un nuovo metodo chiamato *joint-teaching*, che applica la distillazione a livello di parola sui pseudo-obiettivi generati sia dal maestro che dallo studente, affrontando problemi di pregiudizio di esposizione e apprendimento basato su esempi errati.</sample>
    <sample id="63">La **sensibilità** come metrica misura la **coerenza** delle uscite del modello per lo stesso compito, indipendentemente dalla variazione minima nella formulazione dell'istruzione.

In pratica, calcola quanto il modello produce risultati simili quando viene dato lo stesso input ma con istruzioni leggermente diverse. Un modello con alta sensibilità produrrà output quasi identici in queste condizioni, mentre un modello con bassa sensibilità potrebbe fornire risultati diversi.</sample>
    <sample id="64">Il nome della relatrice è Jingwei Yi.</sample>
    <sample id="65">Una maggiore sensibilità **suggerisce il contrario**. In termini presentati, una maggiore sensibilità indica che il modello è meno variabile nelle sue prestazioni a causa di lievi variazioni nella formulazione delle istruzioni. Ciò implica una performance più coerente, che è l'opposto di una migliore performance generale.

In sintesi:

* **Bassa sensibilità:** Il modello è coerente e produce risultati simili con istruzioni leggermente diverse, suggerendo una buona generalizzazione.
* **Alta sensibilità:** Il modello è più sensibile alle variazioni nelle istruzioni, il che può indicare una minore capacità di generalizzazione.</sample>
    <sample id="66"># **Deep Learning per il Ragionamento Matematico: Una Ricerca di Surve e Sviluppi**

Il documento presenta una panoramica completa del campo del ragionamento matematico nell'intelligenza artificiale e nel trattamento del linguaggio naturale (NLP), evidenziando le sfide e i progressi recenti. L'autore esplora la capacità delle reti neurali e dei modelli linguistici pre-addestrati di risolvere problemi matematici e dimostrare teoremi.

Il ragionamento matematico copre una vasta gamma di compiti, dai problemi di parole con operazioni aritmetiche complesse all'automatizzazione della dimostrazione di teoremi. Vengono discussi due contesti principali: visivo e tabulare. I problemi geometrici, ad esempio, richiedono l'identificazione di relazioni spaziali e l'applicazione di teoremi. L'autore introduce la formalizzazione di questi compiti come problemi di ragionamento neuro-simbolico.

La sezione successiva esamina le architetture di rete neurale proposte per il ragionamento matematico, inclusi i modelli sequence-to-sequence e sequence-to-tree. L'ascesa dei grandi modelli linguistici (LLM) è evidenziata come un importante sviluppo, con esempi di soluzioni a problemi matematici utilizzando la generazione di catene di pensiero.

Tuttavia, l'autore riconosce le limitazioni degli LLM, come la mancanza di precisione nel ragionamento matematico. Si suggeriscono soluzioni come l'adozione di strategie di decodifica self-consistent per migliorare le prestazioni. Inoltre, si discute la necessità di esplorare il ragionamento matematico in impostazioni a bassa risorsa e di sviluppare benchmark specifici per domini come finanza, scienza e medicina.

In sintesi, il documento offre una visione completa dello stato dell'arte nel ragionamento matematico basato sull'intelligenza artificiale, sottolineando le opportunità e le sfide future.</sample>
    <sample id="67">**Abstract**

Questo studio esplora l'interferenza nei modelli di traduzione multilingue, che possono beneficiare di sinergie tra diverse coppie linguistiche o soffrire di interferenze. La ricerca si concentra su come fattori come le dimensioni del modello e la dimensione dei dati influenzano l'interferenza, sfidando l'idea che algoritmi specializzati siano sempre necessari per mitigarla.

L'analisi rivela che l'interferenza è grave solo quando il modello è molto piccolo rispetto alla dimensione dei dati. La scalatura delle dimensioni del modello e la regolazione della temperatura di campionamento emergono come strategie efficaci per migliorare le prestazioni.

Gli esperimenti dimostrano che la somiglianza linguistica e il numero totale di lingue non hanno un impatto significativo sull'interferenza. La ricerca utilizza quattro varianti dell'architettura Transformer con 15 lingue da WMT, dimostrando che la riduzione dell'interferenza è più efficace con modelli più grandi e temperature di campionamento calibrate, piuttosto che con metodi specializzati.

In conclusione, le dimensioni del modello e la dimensione dei dati sono i principali determinanti dell'interferenza nella traduzione multilingue, e una scalatura moderata combinata con una temperatura di campionamento adeguatamente regolata può ridurre significativamente il problema senza richiedere algoritmi complessi.</sample>
    <sample id="68">Durante il pre-addestramento, ai modelli linguistici viene fornito un contesto diversificato che include:

1. **Sentenze grammaticali e non grammaticali**: Utilizzando dataset come BLiMP e SyntaxGym, dove vengono valutate la grammaticalità e l'accettabilità delle frasi.
2. **Sentenze con strutture sintattiche simili**: Creando coppie di sentenze con la stessa struttura grammaticale ma contenuti diversi (ad esempio, da diversi subset dello stesso dataset).
3. **Contesto esterno**: Aggiungendo sentenze da fonti esterne come Wikipedia per testare la robustezza del modello in contesti completamente diversi.

Questo approccio consente di valutare la capacità del modello di mantenere coerenza e accettabilità linguistica in vari contesti, specialmente in presenza di grandi finestre di contesto.</sample>
    <sample id="69">In base al contenuto presentato, in genere sono necessari **20 campioni puliti per classe** per raggiungere buone prestazioni in WSL (Weakly Supervised Learning). Tuttavia, l'autore del video sottolinea che anche con solo 10 campioni puliti per classe, il fine-tuning diretto può superare le prestazioni degli approcci WSL.</sample>
    <sample id="70">Gli autori dell'articolo "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models" sono:

- Myra (autrice principale)
- Esin Durmus
- Dan Jurafsky

Tutti e tre sono associati a istituzioni accademiche o di ricerca, sebbene non siano specificate le affiliazioni precise nel testo fornito.</sample>
    <sample id="71"># Risolvere le espressioni di riferimento indiretto per la selezione delle entità

Il lavoro di ricerca presentato si concentra sulla comprensione del linguaggio naturale utilizzato dagli utenti durante la selezione tra diverse opzioni, in particolare quando si tratta di scelte tra canzoni, libri o ricette. Gli autori introducono il *AltEntities Corpus*, un dataset pubblico di 6.000 domande alternative in tre domini diversi, con 42.000 espressioni di riferimento indiretto.

Il problema principale affrontato è la gestione delle referenze indirette, che possono essere più naturali in conversazioni informali. Ad esempio, un utente potrebbe non ricordare il nome di una canzone o voler specificare una preferenza. Il dataset è stato creato utilizzando un approccio informale con un'interfaccia a completamento di cartone, dove gli utenti devono selezionare tra due opzioni dopo aver ricevuto una domanda alternativa.

La ricerca evidenzia l'importanza di fornire al modello linguistico (LLM) un contesto adeguato per migliorare la precisione nella comprensione delle entità. Gli esperimenti mostrano che i modelli LLM, come T5 XL, possono raggiungere un'accuratezza dell'82-87% quando hanno accesso a background conoscitivi parziali, mentre senza alcun contesto, l'accuratezza scende al 60%. Inoltre, i modelli dimostrano una certa generalizzabilità tra domini diversi.

Questo studio contribuisce alla comprensione della selezione delle entità in conversazioni naturali e fornisce un dataset prezioso per la valutazione e il miglioramento delle prestazioni degli LLM in compiti simili.</sample>
    <sample id="72">È necessario sviluppare nuovi metodi per misurare i bias dell'informazione perché i modelli linguistici, addestrati su dati di web crawl che includono notizie politiche, possono acquisire e riflettere pregiudizi sociali e politici. Questi bias possono portare a risultati ingiusti e discriminatori in applicazioni NLP, come la rilevazione di odio e fake news. La comprensione e la mitigazione di tali bias sono cruciali per garantire l'equità e l'affidabilità dei sistemi linguistici artificiali.</sample>
    <sample id="73">La relatrice è Akshatha.</sample>
    <sample id="74">**Abstract:**

Il paper presenta *Dense-ATOMIC*, un'estensione del database di conoscenza commonsense ATOMIC, mirata ad aumentare la copertura della conoscenza e l'inclusione di percorsi multi-passo. ATOMIC, pur essendo ricco di conoscenze annotate, soffre della mancanza di collegamenti B-to-B, A-to-B e A-to-A, limitando la sua efficacia.

Gli autori propongono *Dense-ATOMIC* che completa questi collegamenti mancanti e introduce percorsi multi-passo. Il processo di costruzione comprende tre fasi: normalizzazione degli eventi di coda, addestramento di un modello di previsione delle relazioni e creazione di *Dense-ATOMIC*.

La tecnica chiave è *Rel-CSKGC*, un modello di apprendimento profondo che prevede le relazioni tra eventi di testa e coda. *Rel-CSKGC* evita le limitazioni dei metodi tradizionali, come la struttura di grafo scarna e l'insufficiente utilizzo delle informazioni semantiche, sfruttando le rappresentazioni linguistiche pre-addestrate.

L'efficienza computazionale è migliorata con una strategia di completamento intra- e inter-cluster. Gli autori valutano *Rel-CSKGC* e *Dense-ATOMIC* su vari set di dati, dimostrando prestazioni superiori rispetto ai metodi di confronto, sia in termini di automazione che di valutazione umana.

*Dense-ATOMIC* mostra un'elevata copertura della conoscenza e migliora le prestazioni dei modelli di ragionamento commonsense, come COMET, grazie ai suoi percorsi multi-passo. Il codice e le risorse sono disponibili online, aprendo la strada a ulteriori ricerche sulla conoscenza commonsense.</sample>
    <sample id="75"># **Jointprop: Un framework semi-supervisionato per il riconoscimento di entità e l'estrazione di relazioni**

Questa ricerca presenta Jointprop, un approccio innovativo per affrontare il riconoscimento di entità nominate (NER) e l'estrazione di relazioni (RE) in modo semi-supervisionato. Gli autori affrontano la sfida di sfruttare le connessioni sottostanti tra NER e RE, spesso trascurate nella letteratura esistente.

Il problema principale è che i modelli semi-supervisionati attuali non considerano le relazioni tra i dati etichettati e non etichettati, il che può portare a errori di etichettatura. Jointprop risolve questo problema integrando le informazioni da diverse fonti. Il framework consiste in quattro componenti principali:

1. **Generazione di caratteristiche di span**: Inizializza le rappresentazioni di token e span.
2. **Costruzione di un grafo eterogeneo**: Crea un grafo basato sulla vicinanza per un'efficace elaborazione.
3. **Propagazione congiunta di etichette**: Propaga le etichette attraverso il grafo, aggiornando le etichette dei candidati non etichettati.
4. **Ottimizzazione del modello**: Ottimizza le etichette propagate e ritraina il modello di classificazione.

Gli esperimenti su quattro set di dati, sia congiunti che singoli, dimostrano l'efficacia di Jointprop. Il framework migliora significativamente le prestazioni rispetto ai modelli di base, sia per il NER che per il RE, sfruttando la codipendenza tra le due attività. Questo lavoro apre nuove prospettive per l'apprendimento semi-supervisionato in compiti complessi di estrazione di informazioni.</sample>
    <sample id="76">L'infrastruttura di propagazione dei bias politici, come descritto nella presentazione, si articola in tre fasi principali:

1. **Pretraining Data**: I modelli linguistici vengono addestrati su grandi quantità di dati web crawl che includono ampiamente notizie politiche da fonti come il New York Times, Los Angeles Times, The Guardian e Huffington Post.

2. **Propagazione dei Bias**: Durante il pre-addestramento, i modelli assorbono le diverse prospettive politiche presenti nei dati, che possono essere socialmente biasate. Questi bias possono poi essere amplificati o modificati durante il fine-tuning su compiti specifici.

3. **Downstream Tasks**: I modelli linguistici con diversi bias politici mostrano prestazioni variabili su compiti come la rilevazione di odio e la rilevazione di notizie false. Ad esempio, modelli più liberali possono essere migliori nella rilevazione di odio verso minoranze sociali, mentre modelli più conservatori possono essere migliori nella rilevazione di odio verso gruppi più potenti.

In sintesi, l'infrastruttura crea un ciclo in cui i dati politici influenzano i modelli, i modelli mostrano bias nei compiti downstream, e questi bias possono avere implicazioni significative per l'equità nelle applicazioni NLP.</sample>
    <sample id="77">Lo studio presentato si concentra sull'aumento della coerenza fattuale nelle attività di sintesi del testo, in particolare nell'ambito della sintesi testuale astrattiva. I ricercatori dell'Università di Yale e di Microsoft Research hanno sviluppato un nuovo dataset chiamato DeFacto, che include dimostrazioni umane e feedback per migliorare la coerenza fattuale delle sintesi.

Il dataset DeFacto è stato creato raccogliendo annotazioni su un'ampia gamma di sintesi generati da modelli esistenti, chiedendo agli annotatori di valutare la coerenza fattuale e fornire correzioni e spiegazioni. Questo ha portato a tre nuove attività di generazione del linguaggio naturale (NLG): editing della sintesi, generazione di feedback e correzione automatica degli errori fattuali.

L'analisi dei dati rivela che circa il 70% delle sintesi iniziali contiene errori fattuali. Gli studi dimostrano che le sintesi modificate manualmente dagli annotatori ottengono punteggi di coerenza fattuale più elevati, ma con una minore sovrapposizione testuale rispetto alle sintesi originali.

I ricercatori hanno esplorato l'efficacia di modelli fine-tuned e di grandi modelli linguistici in tre compiti: editing della sintesi, generazione di feedback e correzione automatica degli errori. I risultati indicano che, sebbene la generazione di feedback rimanga una sfida, sia i modelli fine-tuned che quelli basati su grandi linguaggi possono trarre vantaggio dai feedback umani.

Il dataset DeFacto, con le sue annotazioni dettagliate, offre un prezioso strumento per addestrare metriche di coerenza fattuale e per una valutazione meta-evaluativa, oltre a contribuire significativamente alla ricerca sulla sintesi del testo.</sample>
    <sample id="78">Sì, il processo di semplificazione differisce tra DEPLAIN-apa e DEPLAIN-web. In particolare:

- **DEPLAIN-apa**: Si concentra su testi di notizie e utilizza principalmente reordinamenti e aggiunte di parole per la semplificazione.
- **DEPLAIN-web**: Copre una varietà di domini e presenta una maggiore varietà di trasformazioni di semplificazione, con un numero più elevato di refrasi.</sample>
    <sample id="79">Sì, CoScript, il dataset di pianificazione linguistica con vincoli generato dai modelli di linguaggio grandi, è disponibile pubblicamente. È stato creato attraverso la distillazione della conoscenza dello script da modelli di grandi dimensioni e include 55.000 specifici obiettivi con script.</sample>
    <sample id="80">La filigrana viene inserita nel testo attraverso un processo di **somma ponderata di embedding**. In sintesi:

1. **Selezione del trigger set:** Un insieme di parole a frequenza moderata viene scelto dal provider.
2. **Definizione dell'embedding target:** Viene definito un embedding target specifico.
3. **Calcolo del peso:** Il peso dell'embedding target è proporzionale al numero di parole del trigger set presenti nella frase inviata dall'utente.
4. **Iniezione della filigrana:** Se il numero di parole del trigger set supera una soglia *m*, l'embedding fornito al utente sarà uguale all'embedding target. Altrimenti, è una combinazione ponderata dell'embedding originale e dell'embedding target.

Questo processo consente di inserire la filigrana in modo nascosto e difficile da rimuovere, pur mantenendo l'utilità degli embedding per le applicazioni downstream.</sample>
    <sample id="81">Gli autori dell'articolo "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations" sono affiliati alla Penn State University.</sample>
    <sample id="82"># **Aggregating Multiple Heuristic Signals for Unsupervised Automated Essay Scoring: Unveiling ULRA**

Questo video presenta un approccio innovativo per il punteggio automatico degli saggi senza la necessità di dati etichettati, un'area cruciale nel campo del Natural Language Processing (NLP) nell'educazione. Lo studio si concentra sulla sfida di sviluppare modelli di valutazione degli saggi non supervisionati, riducendo la dipendenza da dati costosi e laboriosi.

I ricercatori propongono un framework chiamato ULRA (Unsupervised AES by Learning from Rank Aggregation) per affrontare i limiti dei precedenti metodi. ULRA introduce l'idea di aggregare più segnali heuristici di qualità, come il numero di termini unici e la lunghezza del testo, per fornire una supervisione più forte ai modelli di valutazione.

Il core di ULRA è un modulo di ranking heuristico che genera coppie di ordini parziali, catturando le relazioni di qualità tra gli saggi. Questo processo è seguito da un modulo di aggregazione che combina le informazioni da vari segnali. La chiave è gestire le potenziali incongruenze tra i segnali, utilizzando una perdita di aggregazione di ranking paio profondo.

Durante l'addestramento, ULRA assegna pesi di fiducia appresi a ciascun segnale, riflettendo la loro importanza. Nel processo di inferenza, il framework trasforma i punteggi previsti in un intervallo predefinito, garantendo la coerenza.

Gli esperimenti dimostrano l'efficacia di ULRA, superando le baseline non supervisionate e competendo con i metodi supervisionati. Questo lavoro apre la strada a sistemi di valutazione degli saggi più accessibili e flessibili.</sample>
    <sample id="83">Sì, secondo lo studio presentato, i modelli codificatore-decodificatore come mT5 possono migliorare le loro prestazioni con l'addestramento su una combinazione di lingue. La ricerca ha dimostrato che l'addestramento in un ambiente multilingue può aumentare le prestazioni in molte lingue, anche se l'inglese ha mostrato risultati contrastanti in alcuni casi, un fenomeno noto come "maledizione della multilinguezza".</sample>
    <sample id="84"># **PAD-Net: Un approccio efficiente per le reti dinamiche**

La presentazione di Shwai He esplora il concetto di reti dinamiche, che differiscono dalle tradizionali reti statiche nella capacità di adattare la loro architettura o parametri in base all'input. Mentre i metodi dinamici mostrano vantaggi, l'uso estensivo di parametri dinamici può portare a modelli di grandi dimensioni.

L'autore introduce la sfida di identificare parametri ridondanti e esplorare l'efficacia della coesistenza di parametri statici e dinamici. La soluzione proposta è PAD-Net (Partially Dynamic Network), un framework che segmenta i parametri in dinamici e statici, utilizzando scale factor per bilanciare le due modalità. L'obiettivo è rendere i parametri dinamici non essenziali statici, riducendo la complessità.

Attraverso esperimenti, PAD-Net ha dimostrato prestazioni superiori rispetto alle reti statiche e completamente dinamiche, con un numero inferiore di parametri e una minore computazione. Gli studi di abilitazione hanno rivelato l'importanza dei rapporti dinamici e dei fattori di scala. Inoltre, il metodo è stato confrontato con la potatura di rete, mostrando vantaggi nella conservazione dei parametri statici e nella produzione di output più discriminanti.

Il futuro di questo lavoro include l'estensione a reti mainstream, l'ottimizzazione per strutture hardware-friendly e l'esplorazione di ulteriori modalità di combinazione tra elementi zero, parametri statici e dinamici. Questo approccio promette di bilanciare i vantaggi delle reti dinamiche con la necessità di efficienza computazionale.</sample>
    <sample id="85">Un esempio di pianificazione linguistica vincolata è la preparazione di una "torta al cioccolato". Questo obiettivo specifico richiede l'adesione a vincoli multipli, come l'uso di ingredienti specifici (cioccolato), la seguenza di passaggi precisi e il rispetto di determinate proporzioni, a differenza della pianificazione per un'attività più generica come "fare una torta".</sample>
    <sample id="86">Gli autori si accertano della segretezza del loro metodo, chiamato **Embedding Marker**, attraverso diverse strategie:

1. **Covertness**: Il metodo utilizza un insieme di parole (trigger set) di frequenza moderata, rendendo difficile per un attaccante identificare la presenza del watermark senza un'analisi approfondita.

2. **Backdoor**: Viene creato un "backdoor" nel processo di embedding, dove l'embedding fornito è esattamente il target embedding se il numero di trigger nella frase supera una soglia (m).

3. **Visualizzazione PCA**: Gli autori visualizzano gli embedding di frasi utilizzando PCA, dimostrando che gli embedding con backdoor sono difficili da distinguere da quelli normali.

4. **Metriche di Verifica**: Utilizzano la similarità coseno, la distanza L2, il test KS e la p-value per rilevare la presenza del watermark nell'embedding di un servizio terzo.</sample>
    <sample id="87">Il lavoro utilizza i PLM esistenti, come CamemBERT e PubMedBERT, come punto di partenza per costruire **DrBERT**, un nuovo modello pre-addestrato in francese.

Invece di partire da zero, gli autori sfruttano l'architettura di questi modelli e li adattano al dominio biomedico e clinico francese utilizzando:

* **NACHOS**, un dataset di dati medici web-crawled, per il pre-addestramento iniziale.
* **Continual pre-training** su dati clinici specifici (4 GB di note cliniche e un mix di NACHOS) per affinare ulteriormente il modello.</sample>
    <sample id="88">In base alla presentazione, GPT-4 è meno allineato con paesi non binari rispetto a quelli che includono uomini e donne. Non viene specificato un paese in particolare, ma l'enfasi è sulla disparità di allineamento basata sull'identità di genere non binaria.</sample>
    <sample id="89">La relatrice mostra come il modello sfrutta la conoscenza appresa attraverso il meccanismo dell'attenzione nell'esempio in cui analizza i pesi dell'attenzione tra l'input audio e l'output testuale. Spiega che se l'attenzione non è concentrata su una parola (la somma dei pesi è sotto una certa soglia alfa negli ultimi lambda frame di discorso), quella parola non viene emessa, indicando che le informazioni ricevute sono sufficientemente stabili. Questo processo consente al modello di decidere dinamicamente quando emettere parti della traduzione, ottimizzando così la qualità e la latenza.</sample>
    <sample id="90">## Riassunto: Sfruttare i Linguisti Apprendisti per l'Annotazione dei Dati NLP

Questo studio esplora il potenziale dei linguisti apprendisti come annotatori di dati per il Natural Language Processing (NLP), sfidando la convenzione di affidarsi esclusivamente ai madrelingua. Gli autori hanno condotto un esperimento controllato su tre lingue (inglese, coreano e indonesiano) utilizzando compiti dal benchmark GLUE.

Attraverso una classificazione a tre livelli di abilità (base, intermedio e avanzato), hanno confrontato le prestazioni degli apprendisti linguistici con quelle dei madrelingua. Gli apprendisti hanno utilizzato risorse aggiuntive come dizionari o traduttori durante l'annotazione.

I risultati dimostrano che gli apprendisti linguistici possono produrre annotazioni accurate, specialmente per compiti più semplici. Quando le loro etichette sono aggregate con quelle di altri, raggiungono prestazioni quasi equivalenti ai madrelingua. Inoltre, gli apprendisti hanno mostrato miglioramenti nelle loro competenze linguistiche durante il processo di annotazione.

Lo studio suggerisce che coinvolgere gli apprendisti linguistici può essere una strategia efficace per la costruzione di dataset NLP in lingue a basso e medio risorse, dove il reclutamento di madrelingua è difficile.  L'utilizzo di apprendisti offre un modo innovativo per ampliare la ricerca NLP superando barriere geografiche e tecnologiche.

In conclusione, la ricerca mette in discussione la necessità di madrelingua per l'annotazione dei dati e dimostra il contributo significativo che gli apprendisti linguistici possono dare allo sviluppo di NLP.</sample>
    <sample id="91">La quantità di attività (task) influisce sulla performance del modello in modo significativo. Il paper mostra che **aumentando il numero di task utilizzati per l'addestramento, il modello ottiene risultati migliori e presenta una sensibilità inferiore**. Questo suggerisce che un'esposizione più ampia a vari compiti multi-modali aiuta il modello a generalizzare meglio e a produrre output più coerenti.</sample>
    <sample id="92">Basandosi sul contenuto fornito, gli autori confrontano il loro metodo con i seguenti tre approcci di riferimento:

1. **Modelli seq2seq tradizionali**: Questi modelli spesso falliscono nella generalizzazione a strutture logiche più profonde e non riproducono le corrispondenze sistematiche tra input e output.

2. **Modelli basati su alberi**: Questi modelli utilizzano alberi per catturare il processo composizionale tra utteranze e forme logiche. Sebbene efficaci, richiedono un processo di ottenimento degli alberi che può essere complesso e costoso in termini di calcolo.

3. **Altri modelli trelessi**: Gli autori menzionano altri modelli senza alberi, ma il loro metodo si distingue per la capacità di gestire la generalizzazione a profondità composizionale senza ricorrere a vincoli rigidi sulle permutazioni.</sample>
    <sample id="93">I due coautori, Alexander Koller e Ivan Titov, sono gli **advisori** di Matthias Lindemann.</sample>
    <sample id="94"># **Protezione del Copyright nei Servizi di Embedding con Modelli Linguistici di Grandi Dimensioni**

Questo studio si concentra sulla protezione del copyright nei servizi di embedding basati su modelli linguistici di grandi dimensioni, come GPT, LLAMA e PALM. I servizi di embedding, come l'API GPT di OpenAI, assistono varie attività di elaborazione del linguaggio naturale (NLP). Tuttavia, la possibilità di rubare modelli attraverso l'apprendimento dagli embedding ha sollevato preoccupazioni sulla sicurezza del copyright.

I ricercatori propongono un metodo chiamato "Embedding Marker", una tecnica di watermarking basata su backdoor, progettata specificamente per i servizi di embedding. Il processo comprende due fasi: l'iniezione del watermark e la verifica del copyright. In primo luogo, viene selezionata una set di "trigger" composta da parole di frequenza moderata. Quando un utente invia una frase, il servizio provider conta i trigger presenti. L'embedding fornito è una combinazione ponderata di un embedding di destinazione e l'embedding originale, dove il peso è proporzionale al numero di trigger.

La verifica del copyright coinvolge la creazione di un backdoor e un set di dati benigno. Il set di dati backdoor contiene frasi con tutti i trigger, mentre quello benigno non ne ha. Il provider richiede gli embedding da un servizio "stealer" e calcola la somiglianza coseno e L2 tra l'embedding richiesto e l'embedding di destinazione. Vengono utilizzati anche test statistici per migliorare la precisione.

Gli esperimenti su vari set di dati dimostrano l'efficacia del metodo, mantenendo al contempo l'utilità degli embedding per le attività downstream. La visualizzazione degli embedding conferma la loro covertità, rendendo difficile per gli attaccanti identificarli.</sample>
    <sample id="95">Il primo autore del paper "Prompting PaLM for Translation: Assessing Strategies and Performance" è David Vilar.</sample>
    <sample id="96">## Presentazione: NLPositionality - Caratterizzare i pregiudizi di dataset e modelli

**Introduzione**

Ciao a tutti! Sono Jenny, studentessa dottorale al primo anno presso Carnegie Mellon University. Oggi presenterò il nostro lavoro, *NLPositionality*, che analizza i pregiudizi di progettazione presenti nei dataset e nei modelli di elaborazione del linguaggio naturale (NLP). Questo studio è stato condotto in collaborazione con colleghi dell'Università di Washington e dell'Allen Institute for AI, tra cui Sebastian Santy, Ronan Le Bras, Katharina Reinecke e Maarten Sap.

**Contesto: Rilevamento del Contenuto Tossico**

Immaginiamo che tu lavori per un giornale e stia esaminando i commenti sotto un articolo per rimuovere i contenuti tossici. Potresti affidarti a un popolare API come il Prospective API per il rilevamento della tossicità. Funziona bene per persone come Carl Jones. Ma per qualcuno come Aditya Sharma, l'API potrebbe non rilevare efficacemente termini offensivi comuni nel contesto indiano. Questo è un esempio di pregiudizio di progettazione: differenze sistematiche nelle prestazioni della tecnologia tra diverse popolazioni.

**Positionalità nella Ricerca NLP**

I pregiudizi di progettazione possono derivare dalla *positionalità* dei ricercatori e sviluppatori di NLP. La positionalità si riferisce alle prospettive che le persone sviluppano a causa della loro demografia, identità e esperienze di vita. È un concetto utilizzato in studi critici, specialmente in ambiti accademici femministi e queer. Nella ricerca, la positionalità può influenzare il processo di ricerca e i suoi risultati, modificando le decisioni dei ricercatori.

**Dataset e Modelli con Positionalità?**

La domanda è: i dataset e i modelli hanno una positionalità? Non intendiamo dire che abbiano identità demografiche o esperienze di vita, ma raccolgono e riflettono giudizi e opinioni di persone reali, assumendo così determinate positionalità rispetto ad altre. Studi precedenti hanno fornito prove aneddotiche di questo fenomeno, come divari culturali nei modelli e nei dataset, e definizioni teoriche della positionalità dei modelli. Tuttavia, non hanno esaminato il confronto tra gli utenti finali e i dataset e i modelli stessi, e caratterizzare come queste positionalità sono distorte è difficile perché non tutte le decisioni sono documentate e molti modelli sono nascosti dietro API.

**Il Nostro Approccio: NLPositionality**

Per studiare la positionalità dei dataset e dei modelli, confrontiamo le annotazioni con utenti reali. Il nostro framework, *NLPositionality*, funziona in due fasi:

1. **Ri-annotazione dei Dataset:** Ri-annotiamo i dataset utilizzando diversi annotatori, considerando la demografia degli annotatori originali, poiché spesso solo pochi annotatori valutano ogni istanza e i dati demografici sono raramente raccolti e condivisi.

2. **Confronto con i Modelli:** Calcoliamo il coefficiente di correlazione di Pearson tra le annotazioni demografiche e le previsioni dei modelli e i dataset. A differenza della letteratura sull'accordo tra annotatori, il nostro approccio confronta gli utenti finali con i modelli e i dataset, le previsioni con le etichette.

**Implementazione**

Il nostro framework si basa sulla piattaforma *Lab in the Wild*, un laboratorio online per l'esperimentazione HCI. *Lab in the Wild* consente di reclutare volontari diversificati da 87 paesi, offrendo dati di alta qualità. Abbiamo condotto due compiti:

* **Social Acceptability:** I partecipanti leggono situazioni dal dataset *Social Chemistry* e valutano la loro accettabilità sociale. Successivamente, possono confrontare le proprie risposte con quelle di un'IA.

* **Rilevamento di Odio e Discorso di Odio:** I partecipanti leggono istanze dal dataset *Dynahate* e valutano se contengono odio.

In totale, il nostro studio ha raccolto oltre 16.000 annotazioni da oltre 1.000 annotatori di 87 paesi.

**Risultati: Chi è Allineato con NLP?**

I nostri risultati dimostrano che esiste una positionalità nell'NLP. Ad esempio:

* I dataset e i modelli sono più allineati con paesi di lingua inglese.

* GPT-4 e *Dynahate* mostrano un allineamento più forte con persone di provenienza confuciana e di lingua inglese.

* *Dynahate* è più allineato con persone istruite a livello universitario.

* I dataset e i modelli sono meno allineati con persone non binarie rispetto agli uomini e alle donne.

**Cosa Fare Contro i Pregiudizi?**

Dato l'esistenza di questi pregiudizi, quali soluzioni possiamo adottare? Proponiamo tre raccomandazioni:

* **Documentare le Scelte di Progettazione:** Registra tutte le scelte di progettazione rilevanti durante il processo di ricerca.

* **Adottare una Lente Perspectivica:** Condurre la ricerca NLP tenendo conto della diversità e delle prospettive multiple.

* **Creare Dataset e Modelli Specializzati:** Sviluppare dataset e modelli specifici per quattro comunità chiave. Un esempio è l'iniziativa *Masakhani*.

**Conclusione**

La nostra presentazione si conclude qui. Per approfondire, visitate il nostro dashboard per i risultati aggiornati dell'analisi e il nostro articolo. Grazie!</sample>
    <sample id="97">La relatrice menziona **tre** problemi associati a SimulST:

1. **Architetture specifiche**: Le attuali architetture richiedono un addestramento specifico, introducendo moduli aggiuntivi da ottimizzare.
2. **Procedure di addestramento lunghe e complesse**: Gli addestramenti spesso coinvolgono diversi obiettivi di ottimizzazione.
3. **Mantenimento di più modelli**: Sono necessari diversi modelli per raggiungere diversi regimi di latenza.</sample>
    <sample id="98">Un modo efficace per mitigare i bias sociali e politici nei set di dati durante l'addestramento dei modelli di NLP potrebbe essere una combinazione di:

1. **Diversificazione delle Fonti di Dati**: Includere una vasta gamma di fonti di notizie e media, rappresentative di diverse prospettive politiche e sociali, per ridurre la dipendenza da un singolo tipo di contenuto.

2. **Sanitizzazione e Monitoraggio dei Dati**: Implementare processi rigorosi per rimuovere o neutralizzare contenuti che promuovono pregiudizi o disinformazione, garantendo al contempo la libertà di espressione.

3. **Valutazione e Controllo Continuo**: Condurre valutazioni periodiche dei modelli per identificare e correggere eventuali bias emergenti, utilizzando metriche oggettive e coinvolgendo esperti in scienze sociali.

4. **Trasparenza e Collaborazione**: Promuovere la trasparenza nel processo di addestramento e collaborare con comunità accademiche e sociali per sviluppare linee guida etiche e pratiche migliori.

5. **Addestramento Etico e Responsabile**: Adottare pratiche di addestramento che incoraggino l'equità, la giustizia e la responsabilità, considerando l'impatto sociale dei modelli linguistici.</sample>
    <sample id="99">## Introduzione al lavoro: "Estrazione della Conoscenza Scriptale da Modelli Linguistici di Grandi Dimensioni per la Pianificazione Linguistica Connessa"

Nel nostro quotidiano, gli esseri umani pianificano le proprie azioni seguendo istruzioni passo-passo sotto forma di script goal-orientati. Gli studi precedenti hanno sfruttato i modelli linguistici per pianificare obiettivi astratti di attività stereotipate, come "fare una torta", dimostrando la loro efficacia nel decomporre gli obiettivi in passaggi. Tuttavia, la pianificazione per obiettivi con vincoli specifici, come "fare una torta al cioccolato", rimane un campo di studio relativamente inesplorato.

In questo lavoro, introduciamo il problema della **pianificazione linguistica connessa**, che impone diversi vincoli agli obiettivi della pianificazione. Un obiettivo astratto può essere ereditato da vari obiettivi specifici con vincoli multifaccettati. Un buon pianificatore dovrebbe generare script ragionevoli e fedeli ai vincoli.

**Metodologia:**

1. **Valutazione e miglioramento:** Abbiamo valutato e migliorato la capacità di pianificazione linguistica connessa dei modelli linguistici di grandi dimensioni. Poiché non esisteva un dataset di obiettivi specifici, abbiamo acquisito questi dati coinvolgendo gli utenti in un processo "human-in-the-loop" utilizzando InstructGPT. Abbiamo raccolto 100 obiettivi specifici e valutato gli script generati dai modelli linguistici. I risultati mostrano che tutti i modelli ottengono risultati insoddisfacenti nella pianificazione di obiettivi specifici.

2. **Analisi dettagliata:** Abbiamo condotto un'analisi approfondita per capire perché i modelli di apprendimento falliscono. I risultati indicano che, sebbene la completezza semantica degli script generati sia accettabile, la fedeltà ai vincoli non è garantita. Abbiamo esaminato le categorie più specifiche dei vincoli presenti su wikiHow. La mappa di calore mostra che le prestazioni di pianificazione di InstructGPT variano notevolmente a seconda della categoria dell'obiettivo.

3. **Over-Generate-Then-Filter:** Per migliorare la qualità della generazione, abbiamo adottato l'approccio "over-generate-then-filter". InstructGPT genera prima diversi script per ogni obiettivo specifico e poi un modello di filtro seleziona gli script più fedeli. Utilizziamo embedding per convertire script e obiettivi e calcoliamo la similarità coseno per misurare la somiglianza semantica. Inoltre, premiamo gli script che contengono parole chiave del vincolo target.

4. **Creazione di CoScript:** Per rendere accessibile la pianificazione linguistica connessa a modelli più piccoli, abbiamo creato un dataset, CoScript, utilizzando la tecnica di distillazione della conoscenza simbolica. Generiamo 55.000 obiettivi specifici con script associati. Per garantire la qualità, abbiamo coinvolto lavoratori esterni per individuare e correggere campioni errati. La figura mostra la distribuzione dei vincoli in CoScript, evidenziando la sua alta diversità.

Con CoScript, possiamo utilizzare modelli più piccoli e specializzati per la pianificazione linguistica connessa. I risultati dimostrano che un modello T5 fine-tuned su CoScript genera script di qualità superiore rispetto alla maggior parte dei modelli di grandi dimensioni, suggerendo che modelli più piccoli possono superare quelli più grandi con un addestramento appropriato su dataset mirati.

In conclusione, abbiamo definito il problema della pianificazione linguistica connessa, valutato le capacità dei modelli linguistici di grandi dimensioni, sviluppato un metodo di filtraggio e creato CoScript, un dataset di alta qualità per la pianificazione linguistica connessa. Speriamo che CoScript diventi una risorsa preziosa per la ricerca futura in questo campo.</sample>
    <sample id="100">**Abstract:**

La presentazione introduce PromptRank, un approccio innovativo per il recupero di informazioni in sistemi di domanda e risposta multi-hop (Multi-Hop QA). Multi-hop QA richiede di saltare più passaggi logici per rispondere a domande complesse, utilizzando documenti specifici come "catene" di ragionamento. Gli attuali sistemi richiedono grandi quantità di dati di addestramento, il che può essere costoso, specialmente in domini specializzati.

PromptRank risolve questo problema con un metodo data-efficiente che combina il recupero di informazioni non supervisionato con un modello linguistico a poche riprese per il riordinamento. Il processo inizia con il recupero di una pool di candidate "catene" utilizzando TF-IDF e l'espansione di hyperlink. Queste catene vengono poi convertite in prompt, che includono i documenti e un'istruzione per guidare il ragionamento del modello.

La chiave del successo di PromptRank è l'uso della probabilità del questionato dato la catena (probabilità condizionale) come funzione di punteggio. Esperimenti su HotpotQA dimostrano che PromptRank supera i sistemi completamente supervisionati e si avvicina alle prestazioni dei retriever multi-hop densi di stato dell'arte, utilizzando solo 128 esempi di addestramento. L'importanza di ogni componente di PromptRank è confermata da ablatoni.

Infine, la presentazione evidenzia l'efficacia di PromptRank come retriever per un modello di risposta QA, ottenendo prestazioni multi-hop quasi eguaglianti a sistemi più complessi. L'approccio si basa sull'uso di modelli linguistici per valutare la qualità delle catene di ragionamento in modo few-shot.</sample>
    <sample id="101">Secondo la ricerca presentata, PaLM mostra una fluidità di traduzione **comparabile a quella dei sistemi di punta attuali**.

L'analisi dell'human evaluation utilizzando il framework MQM ha rivelato che, mentre PaLM produce traduzioni fluide, la sua principale debolezza risiede nell'**accuratezza**, con un numero significativo di errori di omissione.</sample>
    <sample id="102">Basandosi sul contenuto fornito, le proprietà importanti di un metodo di filigrana (watermarking) per proteggere il copyright dei servizi di embedding, come proposto nel paper, sono:

1. **Applicabilità ai servizi di embedding**: Il metodo deve essere efficace e applicabile ai servizi di embedding basati su modelli linguistici di grandi dimensioni.
2. **Mantenimento dell'utilità**: La filigrana non deve degradare le prestazioni o l'utilità degli embedding forniti.
3. **Covertità**: La filigrana deve essere difficile da rilevare o rimuovere da parte degli attaccanti.
4. **Trasferibilità**: La filigrana deve essere in grado di essere trasferita ai servizi degli attaccanti durante il processo di estrazione del modello.</sample>
    <sample id="103">Le 14 lingue diverse in cui sono stati tradotti i discorsi TED in inglese sono:

1. Arabo
2. Cinese
3. Francese
4. Tedesco
5. Spagnolo
6. Portoghese
7. Italiano
8. Olandese
9. Polacco
10. Russo
11. Turco
12. Ucraino
13. Vietnamita
14. Coreano</sample>
    <sample id="104">Secondo la presentazione, per la riannotazione dei dataset, vengono raccolte **16.000 annotazioni** da **oltre 1.000 annotatori** provenienti da **87 paesi**.</sample>
    <sample id="105">Le metriche di distanza utilizzate per misurare la differenza tra set di dati benigni e backdoor sono:

1. **Cosine similarity**
2. **L2 (Euclidean) distance**
3. **KS (Kolmogorov-Smirnov) test p-value**</sample>
    <sample id="106"># **Quest: Un dataset per la gestione di query con vincoli set**

Questo studio introduce QUEST, un dataset innovativo per migliorare i sistemi di recupero delle informazioni nell'affrontare query complesse con vincoli set impliciti. L'ispirazione deriva da scenari reali in cui gli utenti esprimono le loro esigenze informative con preferenze o restrizioni multiple.

Il dataset QUEST contiene 3000 query di recupero di entità, ciascuna con vincoli set complessi. Queste query sono state create utilizzando categorie Wikipedia da quattro domini: film, libri, piante e animali. Gli annotatori hanno elaborato le query, garantendo la coerenza semantica e la naturalezza linguistica, e hanno marcato le parti dei documenti pertinenti per ogni vincolo.

L'obiettivo principale è valutare le prestazioni dei sistemi di recupero nell'identificare set di risposte multi-entità, dove l'attribuzione dei vincoli può provenire da diverse sezioni di un documento. Gli autori hanno confrontato diversi approcci, inclusi retriever sparsi e densi e un modello T5 come reranker. I risultati mostrano che c'è un significativo margine di miglioramento, con le query che coinvolgono intersezioni e differenze di set che presentano le sfide più grandi.

QUEST mira a promuovere la ricerca su sistemi in grado di gestire le esigenze informative selettive degli utenti, fornendo un prezioso strumento per valutare e migliorare le prestazioni dei sistemi di recupero delle informazioni. Il lavoro sottolinea la complessità di tale compito e apre la strada a futuri progressi in questo dominio.</sample>
    <sample id="107">I modelli basati su codificatori multilingue, come XLM-R + PTR e mBERT + PTR (Encoder-PTR), e i modelli Encoder-Decoder multilingue come mBART e mT5, sono stati utilizzati per la traduzione e la semantica parsazione cross-lingue. Questi modelli sono stati addestrati su un mix di varie lingue per migliorare le prestazioni, con risultati migliori ottenuti dai modelli Encoder-Decoder in tutti e nove i dataset testati.

Inoltre, questi modelli sono stati confrontati in diversi scenari:

1. **Monolinguale**: Lo stesso linguaggio di origine e di destinazione.
2. **Few-shot**: Addestramento con una piccola porzione dei dati (10%).
3. **Multilingue**: Addestramento con più lingue contemporaneamente.
4. **Cross-lingual Zero-shot e Few-shot transfer**: Addestramento in una lingua e trasferimento ad altre lingue.

I risultati hanno evidenziato che, sebbene il prestino in inglese possa diminuire in alcuni casi, l'addestramento multilingue migliora generalmente le prestazioni, con un divario significativo tra zero-shot e few-shot transfer.</sample>
    <sample id="108"># **Rivedere la Valutazione dei Modelli Linguistici: Un Approccio a Lungo Raggio**

Questo studio si concentra sulla valutazione dell'accettabilità dei modelli linguistici, affrontando le limitazioni dei metodi tradizionali basati sui paradigmi minimal pair (MPP). Gli autori propongono un nuovo approccio per valutare i modelli su sequenze più lunghe, un aspetto cruciale con l'aumento delle dimensioni dei contesti nei modelli linguistici di grandi dimensioni.

La ricerca simula sequenze più lunghe ricreando coppie di frasi, una accettabile e l'altra meno, da dataset esistenti. Questo include l'aggiunta di frasi grammaticali o non grammaticali come prefissi alle coppie. L'esperimento esplora tre scenari: contesto rilevante (stesso dataset), contesto parzialmente non rilevante (dallo stesso fenomeno ma diverso dataset) e contesto completamente irrilevante (da Wikipedia).

I risultati mostrano che i giudizi MPP sono robusti con contesti arbitrariamente lunghi, ma subiscono cambiamenti significativi quando le frasi hanno la stessa struttura sintattica o semantica. Questo effetto è particolarmente evidente nei modelli con grandi finestre di contesto. L'analisi rivela che i modelli sono sensibili a caratteristiche sintattiche e semantiche latenti condivise tra le frasi, suggerendo che la valutazione MPP tradizionale potrebbe non catturare appieno la conoscenza astratta dei modelli nel contesto più ampio.

Lo studio sottolinea l'importanza di valutare i modelli linguistici su lunghe sequenze per comprendere meglio le loro capacità e limitazioni, specialmente con l'evoluzione dei modelli di intelligenza artificiale.</sample>
    <sample id="109">**Abstract:**

"Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor" presenta un approccio innovativo per la creazione di dati di addestramento per modelli linguistici pre-addestrati, riducendo al minimo il lavoro umano. Gli autori propongono un dataset automatico, chiamato Unnatural Instructions, che contiene istruzioni naturali, input e output associati per una vasta gamma di compiti linguistici.

Il processo di raccolta dati coinvolge un modello linguistico pre-addestrato (GPT-3 in questo caso) che genera istruzioni e output basati su un piccolo set di esempi iniziali. Questo approccio crea una diversità di istruzioni, input e output, inclusi paragrafi alternativi, senza la necessità di annotazioni umane. Il dataset risultante comprende 64.000 esempi e, considerando le parafrasi, arriva a 240.000.

La ricerca valuta la qualità e la diversità dei dati generati, scoprendo che oltre il 50% degli esempi sono corretti, e anche quelli errati contengono informazioni preziose. Il dataset include compiti creativi e non convenzionali, come valutare la qualità di esperimenti scientifici o inventare nuove parole.

Gli sperimentatori hanno addestrato un modello T5 da 11 miliardi di parametri su Unnatural Instructions, dimostrando prestazioni migliori rispetto a T0++ e Tk-instruct su vari benchmark. L'addestramento su questo dataset automatico si è rivelato più efficiente in termini di costi rispetto all'addestramento su dataset tradizionali.

In sintesi, questo studio evidenzia il potenziale dei modelli linguistici nel generare dati di addestramento creativi e diversificati, offrendo un'alternativa efficiente alla tradizionale annotazione umana.</sample>
    <sample id="111">Gli autori selezionano le parole a frequenza moderata utilizzando un corpus di testo generale. Contano la frequenza di ogni parola in questo corpus e identificano un intervallo di frequenza moderato. Questo approccio consente loro di scegliere parole che non sono troppo comuni o rare, garantendo una copertura efficace e una selezione non biasata.</sample>
    <sample id="112">## Presentazione: "Funzionano ancora i tagger di entità denominate CoNLL-2003 nel 2023?"

Salve a tutti, mi chiamo Shuheng. Oggi presenterò la nostra ricerca intitolata "Funzionano ancora i tagger di entità denominate CoNLL-2003 nel 2023?". Il nostro studio si è concentrato sul problema della generalizzazione nell'ambito del riconoscimento delle entità nominate (NER). Osserviamo che i modelli basati su CoNLL-2003 sono stati utilizzati per lo sviluppo del NER per quasi 20 anni, il che solleva alcune questioni.

**Prima di tutto:** questi modelli possono generalizzarsi ai dati moderni? E cosa serve per ottenere una buona generalizzazione quando si sviluppano nuovi tagger? Allo stesso tempo, se osserviamo un calo delle prestazioni, quali sono le cause di questo?

Per rispondere a queste domande, abbiamo creato il dataset CoNLL++. Si tratta di un insieme di dati raccolti da Reuters News nel 2020, annotati con le stesse linee guida di CoNLL-2003. Abbiamo quindi addestrato oltre 20 modelli su CoNLL-2003 e valutato le loro prestazioni sia sui set di test CoNLL-03 che su CoNLL++. Infine, abbiamo calcolato la percentuale di cambiamento in F1 per valutare la generalizzazione di ciascun modello.

**Quali sono gli ingredienti per una buona generalizzazione?** Attraverso i nostri esperimenti, abbiamo identificato tre elementi fondamentali:

1. **Architettura del modello:** Abbiamo riscontrato che i modelli basati su Transformer tendono a generalizzare meglio sui nuovi dati.
2. **Dimensione del modello:** Modelli più grandi generalmente offrono una migliore generalizzazione.
3. **Numero di esempi di fine-tuning:** Un maggior numero di esempi di addestramento porta a una migliore generalizzazione.

**Cosa causa il calo delle prestazioni di alcuni modelli?** Abbiamo formulato due ipotesi:

1. **Overfitting adattivo:** Questo si verifica quando il modello si adatta troppo al set di test, mostrando un calo delle prestazioni su nuovi set di dati.
2. **Drift temporale:** La degradazione delle prestazioni causata dall'aumento del divario temporale tra i dati di addestramento e quelli di test.

Per l'overfitting adattivo, abbiamo osservato che la pendenza della linea di regressione migliore (rossa) è maggiore di uno, indicando che ogni miglioramento su CoNLL-2003 si traduce in un miglioramento superiore su CoNLL++, senza un calo delle prestazioni. Questo esclude l'ipotesi di overfitting adattivo.

Per quanto riguarda il drift temporale, abbiamo sperimentato il ritrainamento o il pre-addestramento di alcuni modelli con dati più recenti, riscontrando un calo delle prestazioni con un aumento del divario temporale. Ciò conferma la nostra ipotesi che la causa principale del calo delle prestazioni sia il drift temporale.

**Conclusione:** Per una buona generalizzazione, sono necessari una migliore architettura del modello, modelli più grandi e un maggior numero di esempi di fine-tuning. Questi elementi sono interconnessi; non si può avere uno senza gli altri. Abbiamo anche scoperto che il calo delle prestazioni è principalmente dovuto al drift temporale, sorprendentemente, non all'overfitting adattivo, nonostante CoNLL-2003 sia in uso da oltre 20 anni.

**Risposta alla domanda del titolo:** Sì, i tagger di CoNLL-2003 funzionano ancora nel 2023. Speriamo che la nostra ricerca stimoli ulteriori studi per migliorare la generalizzazione dei modelli. Infine, vi invitiamo a consultare il nostro articolo, il nostro dataset e a contattarci per qualsiasi domanda. Grazie!</sample>
    <sample id="114"># **Finding the Pillars of Strength: Ottimizzazione dei Modelli di Attenzione Multi-Testa per Ridurre i Parametri nei Modelli di Linguaggio di Grandi Dimensioni**

La ricerca presentata si concentra sull'affrontare le limitazioni dei modelli di linguaggio di grandi dimensioni (LLM), in particolare sulla riduzione del numero di parametri per migliorare l'efficienza computazionale. Gli autori propongono un approccio innovativo chiamato "Grouped Head Attention" (GHT) per ottimizzare i modelli multi-testa di attenzione, che sono una componente chiave nei LLM.

Il metodo GHT utilizza una strategia di divisione e conquista, dividendo i test di attenzione in gruppi. Questo processo mira a ridurre la ridondanza, rendendo i test all'interno di un gruppo più simili e quelli tra gruppi più diversi. La tecnica comprende due fasi: il *group-constrained training* per addestrare i gruppi e un algoritmo *Voting-to-Stay* per la successiva eliminazione dei test ridondanti.

Gli esperimenti hanno dimostrato l'efficacia del GHT e della sua variante, GHT-PS, su vari compiti, tra cui traduzione automatica, riassunto testuale e modellazione del linguaggio. I modelli ottimizzati hanno ottenuto miglioramenti significativi nelle metriche di valutazione con una riduzione dei parametri fino al 90%. L'analisi dell'efficienza ha evidenziato un aumento del 62% nella velocità di inferenza e una riduzione dell'80% nei FLOPs (operazioni in virgola mobile a precisione singola) rispetto ai modelli non ottimizzati.

Il lavoro suggerisce che la ridondanza nei LLM può essere affrontata attraverso la prunazione selettiva dei test, ispirata all'ipotesi del "Lottery Ticket". Questo approccio ha il potenziale per rendere i modelli di linguaggio più accessibili e efficienti per un'ampia gamma di applicazioni.</sample>
    <sample id="115">L'approccio EDAtt (Encoder-Decoder Attention) proposto nel paper utilizza un segmento parlato di dimensione fissa, definito come "lambda speech frames". La scelta esatta di lambda non è specificata nel testo, ma l'idea chiave è che l'attenzione viene utilizzata per decidere se emettere o meno una traduzione parziale in base alla stabilità delle informazioni ricevute nei diversi segmenti del discorso.

In pratica, l'approccio segmenta il discorso in porzioni più piccole e determina quando è appropriato emettere una traduzione completa basandosi sulla distribuzione dell'attenzione tra i vari segmenti.</sample>
    <sample id="116">Nell'esempio con Servin e Kea, le conoscenze specifiche dell'entità necessarie includono:

1. **Informazione di background**: "Judges decide cases in law courts" (I giudici decidono casi nelle corti di giustizia).
2. **Entità specifiche**: "Servin is a judge" (Servin è un giudice) e "Kea is a Baker" (Kea è un pasticcere).

Queste due tipologie di conoscenza sono essenziali per risolvere correttamente il pronome "he" (lui) nel contesto della frase.</sample>
    <sample id="117">Il fattore più importante tra la qualità dell'esempio e la somiglianza con la frase sorgente è **la qualità dell'esempio**. Secondo lo studio, la qualità e la cura degli esempi utilizzati per il prompting hanno un impatto significativo sulle prestazioni del modello di linguaggio grande (LLM) per la traduzione, superando la semplice somiglianza con la frase sorgente.</sample>
    <sample id="118">**Abstract:**

Il nostro lavoro, presentato all'ACL 2023, si concentra sull'aumento delle prestazioni dei modelli pre-addestrati per il trattamento del codice-switching nel NLP, un fenomeno comune in comunità linguisticamente diverse come l'India. I modelli multilingue esistenti, come mBERT e XLM-R, spesso falliscono in compiti specifici di codice-switching come il question answering e l'analisi del sentiment.

Abbiamo introdotto **SwitchMLM**, un nuovo obiettivo di pre-addestramento MLM personalizzato per il codice-switching, che si concentra su gruppi di token chiamati *switch-point*, ovvero le transizioni tra lingue in una frase. SwitchMLM consente di mascherare solo questi switch-point, migliorando la capacità del modello di catturare informazioni linguistiche specifiche.

Per affrontare casi in cui i dati etichettati LID non sono disponibili, proponiamo **FrequencyMLM**, un metodo surrogato che assegna etichette LID basandosi sulla frequenza di occorrenza dei token. Inoltre, suggeriamo modifiche architettoniche, in particolare l'aggiunta di connessioni residuate e un'auxiliaria perdita LID, per incoraggiare le prime fasi del modello BERT a codificare più informazioni sui switch-point.

I risultati sperimentali dimostrano che il nostro approccio, combinato con ResBERT e la perdita ausiliaria, eccelle nei compiti di analisi del sentiment. Le prove di probing confermano che le nostre tecniche aumentano la quantità di informazioni sui switch-point nelle fasi intermedie e finali del modello.

In sintesi, il nostro lavoro offre un nuovo paradigma per il pre-addestramento che migliora significativamente le prestazioni dei modelli NLP in scenari di codice-switching.</sample>
    <sample id="119">L'articolo si concentra principalmente sui modelli linguistici GPT (come GPT-4) e RoBERTa, insieme a varianti come BART, nei loro esperimenti. Questi modelli sono stati testati per valutare e analizzare le loro tendenze politiche e i pregiudizi derivanti dai dati di pre-addestramento.</sample>
    <sample id="120">Il modello utilizza **i punteggi di attenzione tra l'input audio e l'output testuale (cross-attention) di un solo livello**.

L'approccio EDAtt si basa sulla decisione di emettere o meno una traduzione parziale in base a dove punta l'attenzione.  Utilizzando un singolo modello per ogni regime di latenza, il sistema sfrutta la conoscenza acquisita dal modello attraverso l'attenzione per gestire la latenza senza la necessità di addestrare o modificare architetture specifiche.</sample>
    <sample id="121">Gli esempi di inferenza diretta menzionati nel testo includono l'uso diretto del nome di un'entità o della sua posizione per fare una scelta, come nel caso di "Easy on Me" o "la prima canzone". Un altro esempio è quando un utente dice chiaramente "la più nuova" o "quella meno energica" per specificare la sua preferenza senza citare il nome esatto.</sample>
    <sample id="122">Gli autori dell'articolo "Distilling Script Knowledge from Large Language Models for Constrained Language Planning" sono affiliati a Fudan University.</sample>
    <sample id="123"># **MultiInstruct: Migliorare l'Apprendimento Zero-Shot Multi-Modale con l'Instruction Tuning**

La ricerca si concentra sull'esplorazione dell'instruction tuning per migliorare l'apprendimento zero-shot in compiti multi-modali, affrontando la carenza di dati e modelli per tali compiti. Gli autori, Ying e Zhiyang, propongono MultiInstruct, un dataset innovativo per l'instruction tuning multi-modale.

MultiInstruct comprende 62 compiti diversificati in 10 categorie, derivati da 21 dataset open-source. Ogni compito è accompagnato da cinque istruzioni scritte da esperti. Il dataset unifica il trattamento di input e output di diversi tipi, utilizzando un modello pre-addestrato multi-modale OFA.

L'esperimento coinvolge l'addestramento e il test di un modello OFA pre-addestrato su 53 compiti, con una combinazione di istruzioni durante l'addestramento. Il test valuta il modello su compiti visti e non visti, con una metrica aggiuntiva chiamata "sensibilità" per misurare la coerenza delle uscite.

I risultati dimostrano che l'instruction tuning migliora significativamente le prestazioni del modello OFA su compiti visti multi-modali. Il trasferimento di apprendimento da dataset di istruzioni naturali migliora ulteriormente i risultati e riduce la sensibilità del modello alle variazioni delle istruzioni. L'esperimento evidenzia l'efficacia di più istruzioni per migliorare le prestazioni e ridurre la sensibilità.

Inoltre, gli autori stanno espandendo MultiInstruct con 150 compiti aggiuntivi, dimostrando l'impegno nella creazione di risorse di dati di alta qualità per la ricerca sull'apprendimento automatico.</sample>
    <sample id="124"># **Verso la valutazione e il miglioramento delle capacità di ragionamento temporale nei grandi modelli linguistici**

Questo studio, condotto da Tan Qingyu dell'Università Nazionale di Singapore e di Alibaba, esplora le sfide e le carenze nei modelli linguistici di grandi dimensioni (LLM) quando si tratta di ragionamento temporale. Il lavoro si divide in tre livelli di ragionamento temporale: tempo-a-tempo, tempo-a-evento e evento-a-evento.

La ricerca evidenzia una tendenza nei modelli precedenti a concentrarsi principalmente sul ragionamento L2, ignorando le altre sfumature. Per affrontare questo problema, è stata creata la dataset TempReason, che copre tutti e tre i livelli e include un'ampia gamma di periodi temporali. Il dataset aumenta la difficoltà delle domande, partendo dalla previsione dell'anno alla previsione del mese.

Gli autori propongono due metodi per migliorare le capacità temporali dei modelli. Il primo è un'interfaccia di addestramento che include l'estrazione di intervalli temporali e un apprendimento rinforzato sensibile al tempo. Il secondo introduce un nuovo paradigma, "Reasoning QA", in cui i modelli ricevono tutte le conoscenze temporali rilevanti per rispondere alle domande.

I risultati sperimentali mostrano che i modelli come ChatGPT e FLAN-T5-L presentano carenze nel ragionamento temporale, soprattutto nelle previsioni di mesi e nella coerenza attraverso diversi periodi. Il modello TempT5, sviluppato dagli autori, supera le prestazioni dei modelli di base, dimostrando l'efficacia delle loro strategie di addestramento.

In conclusione, questo lavoro fornisce una valutazione critica delle capacità temporali degli LLM, introduce un dataset completo per il ragionamento temporale e propone un approccio di addestramento per migliorare le prestazioni in questo dominio.</sample>
    <sample id="125">Basandomi sul contenuto fornito, l'articolo è stato scritto da **un autore principale, Yanis Labrak**, che presenta il lavoro. Non viene menzionato un numero specifico di autori coinvolti. Pertanto, la risposta concisa è **1 autore**.</sample>
    <sample id="126">No, secondo la presentazione, l'uso di modelli di traduzione automatica standard (come Google Translate API) per tradurre le query in linguaggio naturale prima del parsing semantico non è considerato l'approccio standard. Gli autori del lavoro propongono invece un approccio più strutturato e diversificato, chiamato XSemPLR, che include vari modelli e configurazioni di training (monolingua, multilingua, zero-shot, few-shot) per valutare in modo più completo le capacità di parsing semantico in diverse lingue e rappresentazioni del significato.</sample>
    <sample id="127">**Abstract:**

Il nostro studio, "Large Language Models Are Reasoning Teachers", esplora un approccio innovativo per migliorare le capacità di ragionamento dei modelli linguistici di grandi dimensioni (LLM) e renderli accessibili a modelli più piccoli. In collaborazione con Laura Schmid e il professor Se-Young Yun, abbiamo sviluppato una tecnica chiamata "diverse reasoning" per trasferire le abilità di ragionamento passo-passo dai modelli di grandi dimensioni (come GPT-3 o PALM) a modelli più piccoli.

La tecnica tradizionale, il "chain-of-thought prompting", richiede modelli di grandi dimensioni per eseguire ragionamenti complessi. Abbiamo affrontato questa limitazione generando soluzioni passo-passo da modelli di grandi dimensioni e utilizzandole come dati di addestramento per modelli più piccoli. Questo processo, chiamato "fine-tuning CoT", consente ai modelli più piccoli di eseguire compiti complessi che richiedono ragionamento multi-passo.

I risultati dimostrano che il nostro metodo supera le prestazioni dei baseline in 12 compiti, specialmente nei testi-based. La tecnica "diverse reasoning" migliora significativamente le prestazioni, aumentando del 22% il risultato nel compito "Multi Arithmatic". L'approccio è scalabile, ma presenta trade-off tra costi di sviluppo e inferenza.

Il nostro lavoro evidenzia il potenziale della distillazione per trasferire abilità complesse a modelli più piccoli, aprendo la strada a futuri progressi nell'intelligenza artificiale. Forniamo il codice e i dati di tutti gli esperimenti nel nostro paper di 40 pagine, incoraggiando ulteriori ricerche e collaborazioni.</sample>
    <sample id="128">**Abstract:**

Il nostro lavoro, "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources", esplora la capacità dei modelli di comprensione del linguaggio naturale (NLU) di integrare conoscenze da fonti multiple. I modelli NLU moderni si affidano a conoscenze acquisite durante il pre-addestramento e a quelle fornite all'inferenza. Tuttavia, per compiti NLU complessi, è cruciale poter sfruttare sia la conoscenza pre-addestrata che quella inferenziale.

Abbiamo sviluppato KITMUS, un'apposita suite di test per valutare l'integrazione della conoscenza. Questa include un compito di risoluzione dei coreferenti progettato per esaminare la capacità dei modelli di attingere a conoscenze diverse. Il test varia la disponibilità di due tipi di informazioni: conoscenza specifica dell'entità (ad esempio, "Servin è un giudice") e conoscenza di sfondo (ad esempio, "I giudici decidono casi nei tribunali").

Abbiamo definito tre scenari: "Background-Pretrain" (conoscenza di sfondo solo al pre-addestramento), "Background-Both" (disponibile sia al pre-addestramento che all'inferenza) e "Background-Inference" (solo al momento dell'inferenza). I risultati mostrano che, senza addestramento specifico su KITMUS, i modelli non performano bene. Tuttavia, con tale addestramento, alcuni modelli migliorano significativamente.

I nostri esperimenti rivelano che, sebbene alcuni modelli possano integrare conoscenze multiple, anche i migliori incontrano difficoltà nell'utilizzare retroattivamente le conoscenze fornite solo all'inferenza. Questo evidenzia la necessità di strategie di addestramento più avanzate per modelli NLU robusti e flessibili.</sample>
    <sample id="129">Gli autori hanno utilizzato come esempio **una donna asiatica** e **una donna del Medio Oriente** come gruppi contrassegnati.

Hanno generato descrizioni di persona per questi gruppi usando prompt specifici, rivelando stereotipi e narrazioni essenzialiste nascosti dietro termini apparentemente positivi.</sample>
    <sample id="130">Secondo la presentazione, **i modelli basati su architetture più vecchie** (come quelle utilizzate nel dataset CoNLL-2003) tendono a non generalizzare in modo adeguato ai dati moderni.

Il testo specifica che **i modelli Transformer**, in generale, mostrano una migliore capacità di generalizzazione rispetto ad altre architetture.</sample>
    <sample id="131">Nel contenuto fornito, non vengono menzionati specifici nomi di set di dati di test. Si fa riferimento a un "test set clean" (set di test pulito) e a un "noisy validation set" (set di validazione rumoroso), ma non vengono specificati nomi di set di dati reali.</sample>
    <sample id="132">Due autori sono coinvolti nell'articolo: Akshatha e Martin.</sample>
    <sample id="133">L'autore opera con **più modalità**. Il testo è menzionato come una delle modalità, ma la presentazione include anche immagini, istruzioni e bounding box, indicando un approccio multi-modale. Il loro lavoro si concentra specificamente sull'uso dell'instruction tuning per migliorare l'apprendimento zero-shot su compiti multi-modali.</sample>
    <sample id="135">**Abstract**

Il lavoro presentato, condotto dal laboratorio NLP di Emory University guidato dal Prof. Jinho Choi in collaborazione con Amazon Alexa AI, introduce ABC-Eval, un nuovo approccio dimensionale per valutare le prestazioni dei modelli di conversazione AI. A differenza delle comuni valutazioni basate su giudizi umani, che forniscono una visione generale della qualità della conversazione, ABC-Eval mira a una valutazione più dettagliata e oggettiva.

Questo metodo annota esplicitamente i comportamenti dei modelli di dialogo, come la fornitura di informazioni irrilevanti o contraddizioni, riducendo la soggettività delle valutazioni umane. ABC-Eval misura la frequenza di vari errori tematici, tra cui ignorare il partner, dire cose irrilevanti, contraddirsi o violare la logica comune.

Sono stati valutati quattro modelli di chat di ultima generazione su 100 conversazioni per modello utilizzando ABC-Eval e tre metodi esistenti: valutazioni Likert turn-level, dialogo-level e confronti pairwise. I risultati mostrano che le etichette comportamentali di ABC-Eval sono più affidabili e predittive della qualità della conversazione rispetto ai metodi tradizionali.

L'analisi rivela che le metriche ABC-Eval catturano aspetti unici della qualità del dialogo, mentre le valutazioni Likert turn-level forniscono meno informazioni distinte. I risultati evidenziano la necessità di metriche di valutazione più precise, come ABC-Eval, per tenere il passo con il rapido progresso nel campo dell'AI conversazionale.</sample>
    <sample id="136">**Abstract:**

Il lavoro presentato, intitolato "FERMAT: An Alternative to Accuracy for Numerical Reasoning", esplora le sfide nell'valutazione delle capacità di ragionamento numerico nei modelli linguistici, con particolare attenzione alla mancanza di metriche informative oltre alla semplice accuratezza. L'autore, Jasivan, e la sua supervisore, Nafise, hanno sviluppato FERMAT, un set di dati di valutazione flessibile basato su tipi aritmetici, che include comprensione numerica, operazioni matematiche e dipendenze di addestramento.

FERMAT comprende domande basate su concetti matematici estratti da Illinois e CommonCore, con numeri rappresentati in vari formati (decimali, interi grandi e piccoli) per testare la gamma di abilità dei modelli. Gli esperimenti iniziali mostrano prestazioni scarse nella maggior parte dei modelli, evidenziando l'insufficienza dei benchmark esistenti.

Attraverso il fine-tuning di modelli con 200.000 esempi generati dinamicamente, si osserva un miglioramento delle prestazioni, specialmente con numeri interi e decimali. L'analisi della dipendenza di addestramento rivela che la memorizzazione esplicita delle espressioni matematiche non garantisce l'accuratezza, sottolineando l'importanza del contesto linguistico.

Infine, si dimostra che la diversità linguistica e matematica, ottenuta attraverso set di dati aggiuntivi come GSM8K e AQUA, migliora significativamente le prestazioni. La ricerca conclude che FERMAT offre un approccio più informativo per valutare le capacità numeriche, evidenziando la necessità di una valutazione più completa oltre ai semplici punteggi di accuratezza.</sample>
    <sample id="137">**Abstract**

Il lavoro "Tell2Design: A Dataset for Language-Guided Floor Plan Generation", presentato a ACL 2023, esplora un nuovo compito di apprendimento automatico: la generazione di piani di pavimento basati su istruzioni testuali. L'obiettivo è consentire agli utenti non esperti di progettare spazi attraverso descrizioni testuali, migliorando così il processo di design.

La ricerca si concentra sulla generazione di piani di pavimento 2D che rispettano istruzioni linguistiche specifiche, che includono semantica (tipo e funzione delle stanze), geometria (forme e dimensioni) e topologia (relazioni tra stanze). Il dataset Tell2Design, costruito su piani di pavimento pubblici, comprende 5.051 istruzioni testuali raccolte da lavoratori di Amazon Mechanical Turk e 76.000 istruzioni generate artificialmente.

I principali ostacoli includono la gestione di vincoli rigorosi, la comprensione di informazioni testuali complesse e l'affrontare istruzioni ambigue o incomplete. Per superare queste sfide, l'approccio proposto utilizza un modello di sequenza-a-sequenza basato su un'architettura encoder-decoder, che genera bounding box di stanze da istruzioni testuali.

Il modello, inizializzato con un pre-addestrato T5, supera i metodi di generazione di immagini condizionate al testo in termini di precisione, dimostrando la validità del linguaggio guidato nella progettazione. I risultati evidenziano il potenziale di Tell2Design come risorsa fondamentale per la ricerca futura in questo campo.</sample>
    <sample id="138">Secondo gli autori, l'area della Natural Language Understanding (NLU) meno studiata è l'integrazione di conoscenza da fonti multiple, specialmente quella fornita solo al momento dell'inferenza, nota come "backward knowledge". Il loro lavoro si concentra su questo aspetto cruciale ma spesso trascurato.</sample>
    <sample id="139">I relatori sono Ying e Zhiyang.</sample>
    <sample id="140">Sì, CoScript ha subito controlli di qualità. Dopo la generazione iniziale, i lavoratori esterni hanno esaminato e rivisto i campioni per garantire l'accuratezza e la qualità del dataset.</sample>
    <sample id="141">I limiti delle risorse esistenti per la traduzione dipendente dal contesto includono:

1. **Copertura limitata**: Le risorse attuali supportano solo un numero limitato di tipi di traduzioni dipendenti dal contesto e di coppie di lingue, spesso basate su conoscenze di dominio e curazione umana.
2. **Inadeguatezza delle metriche**: Corpus-level metrics come BLEU non riescono a catturare efficacemente le traduzioni dipendenti dal contesto, rendendo difficile valutare le prestazioni dei modelli in questi casi.
3. **Mancanza di automazione**: Molte risorse richiedono interventi manuali per identificare e curare i casi di contesto dipendente, limitando la loro scalabilità.</sample>
    <sample id="142">## Risolvere le espressioni di riferimento indiretto per la selezione delle entità: Presentazione del corpus AltEntities

Ciao! Oggi parlerò del nostro lavoro su **"Risolvere le espressioni di riferimento indiretto per la selezione delle entità"**, in cui introduciamo il **corpus AltEntities**. Sono Javad Hosseini e questo studio è il risultato di una collaborazione con Filip Radlinski, Silvia Pareti e Annie Louis.

Il nostro obiettivo è comprendere il linguaggio degli utenti quando desiderano fare una scelta. Immaginate la seguente domanda alternativa: **"Intendi 'Easy on Me' o 'I Gotta Feeling'?"**. In questo caso, l'utente vuole selezionare una tra queste due canzoni. La soluzione più ovvia sarebbe usare un riferimento diretto, ad esempio dicendo il nome della canzone "Easy on Me" o la sua posizione, "la prima". Tuttavia, a volte un riferimento indiretto è più appropriato per avere una conversazione più naturale. Questo può accadere quando l'utente non ricorda il nome della canzone, o le pronunce sono troppo simili da confondere, o quando l'utente vuole specificare una preferenza.

Ecco alcuni esempi di riferimenti indiretti: "la più nuova" o "la canzone meno energica". Questo problema è cruciale per i sistemi conversazionali e per valutare la comprensione delle entità da parte dei modelli linguistici (LLM). Non esiste, a quanto ne sappiamo, un dataset pubblico di grandi dimensioni dedicato a questo compito, quindi abbiamo creato uno noi utilizzando l'annotazione crowdsourcing.

Il nostro dataset copre tre domini diversi: musica, libri e ricette. La metodologia di raccolta dati enfatizza l'informalità utilizzando un setup di completamento con cartoni animati. Il cartone presenta tre bolle di dialogo: nella prima, Bob ricorda una canzone ascoltata il giorno prima; nella seconda, Alice pone la domanda alternativa "Intendi 'Easy on Me' o 'I Gotta Feeling?'"; nella terza bolla, Bob usa un riferimento indiretto per scegliere una delle due entità, ad esempio "la più nuova".

La prima e la seconda bolla di dialogo sono generate automaticamente, mentre la terza è completata dagli annotatori. La prima bolla è scelta tra alcune opzioni manuali per ogni dominio. La seconda bolla, la domanda alternativa, è generata utilizzando un semplice template: "Intendi A o B?". A e B sono campioni estratti da Wikipedia.

Abbiamo utilizzato diversi metodi di campionamento:

* **Casuale uniforme:** le entità sono scelte a caso.
* **Titoli simili:** le entità hanno titoli simili, ad esempio due libri con lo stesso nome.
* **Descrizioni simili:** le entità hanno descrizioni simili su Wikipedia.
* **Attributi simili:** le entità condividono gli stessi attributi, come genere o artista (per la musica).

Gli annotatori sanno il nome delle entità, ma non necessariamente ne hanno una conoscenza approfondita. Per questo, forniamo loro del contesto informativo: un link di ricerca Google per le canzoni, estratti di Wikipedia per i libri e le ricette, e immagini di Wikipedia per le ricette. Gli annotatori devono quindi scegliere una delle entità e descriverla utilizzando 3-5 espressioni di riferimento indiretto.

Ecco alcuni esempi dal nostro dataset: "quella senza parole", "non quella con il ragazzo di 12 anni", "quella fittizia", "viene dall'Azerbaigian", ecc.

Il corpus AltEntities contiene 6.000 domande alternative tra i tre domini e 42.000 espressioni di riferimento indiretto.

I risultati con il modello T5 XL mostrano che:

* Se il modello linguistico ha accesso allo stesso contesto informativo degli annotatori, l'accuratezza raggiunge il 92-95%.
* In scenari più realistici, con accesso a un contesto parzialmente sovrapposto, l'accuratezza è del 82-87%.
* Se il modello ha accesso solo ai nomi delle entità, l'accuratezza scende al 60%.

Abbiamo dimostrato che i modelli sono in grado di generalizzare tra domini diversi.

Potete trovare il link al nostro dataset qui: [inserire link]</sample>
    <sample id="143">L'approccio descritto nel paper "Attention as a Guide for Simultaneous Speech Translation" confronta la propria strategia, chiamata EDAtt, con diverse politiche SimulST esistenti:

1. **Wait-k strategia**: Un metodo comune che ritarda l'emissione di una traduzione fino a quando non vengono ricevuti k frame di audio successivi.
2. **Local Agreement**: Un'altra strategia che decide l'emissione di una traduzione basata sull'accordo locale tra l'input audio e l'output testuale.
3. **Architettura specificamente progettata per SimulST**: Metodi avanzati progettati specificamente per la traduzione simultanea della parola.

L'EDAtt si distingue per la sua efficienza e prestazioni, superando tutte queste strategie sia in termini di qualità della traduzione che di latenza.</sample>
    <sample id="144">Gli autori dell'articolo "DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains" sono affiliati con l'Università di Nantes, in Francia.</sample>
    <sample id="145">La relatrice è Jenny.</sample>
    <sample id="146"># Analisi dell'Omissione nella Sintesi del Dialogo: Un Approccio per Migliorare la Qualità

Questa presentazione si concentra sull'analisi e la risoluzione dell'errore di omissione nei sistemi di sintesi del dialogo, un aspetto cruciale ma poco studiato nella generazione di riepiloghi. L'autore, Yicheng, studente PhD presso l'Università di Fudan, evidenzia come i modelli linguistici pre-addestrati, nonostante i progressi, generino ancora riepiloghi con omissioni significative, specialmente in domini diversi.

La ricerca evidenzia che circa il 70% dei riepiloghi presenta problemi di omissione, dimostrando la sua rilevanza e gravità. L'analisi della posizione delle informazioni omesse rivela una distribuzione casuale all'interno del dialogo, indicando la difficoltà di identificare i contenuti chiave.

Per affrontare questo problema, gli autori hanno creato il dataset OLDS, che etichetta in modo accurato le omissioni in cinque domini. Questo dataset è generato da diversi modelli di sintesi, garantendo una varietà di riepiloghi. Vengono esplorati tre approcci di modellazione: classificazione binaria, etichettatura sequenziale e rete di puntatori, valutati con precisione, richiamo e F1-score.

Un'ulteriore scoperta è che l'integrazione delle informazioni omesse nella sintesi può migliorare notevolmente la qualità. La post-elaborazione del riepilogo utilizzando le omissioni rilevate porta a risultati più accurati, suggerendo che l'omissione è una risorsa preziosa per migliorare le prestazioni della sintesi del dialogo.</sample>
    <sample id="147">L'articolo "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models" è stato scritto in collaborazione da **tre** autori: Myra, Esin Durmus e Dan Jurafsky.</sample>
    <sample id="148">## Introduzione al paper "Attention come guida per la Traduzione Simultanea del Discorso"

Ciao, sono Sara Papi dall'Università di Trento e dalla Fondazione Bruno Kessler, e vi presenterò brevemente il nostro lavoro di ricerca intitolato *"Attention as a Guide for Simultaneous Speech Translation"*, realizzato in collaborazione con Matteo Negri e Marco Turchi.

**Di cosa si tratta?**

La **traduzione simultanea del discorso (SimulST)** è un processo che consente la traduzione in tempo reale di un discorso parlato in un testo in un'altra lingua, favorendo la comunicazione tra persone che parlano lingue diverse.

**Quali sono le sfide dei modelli SimulST attuali?**

I modelli SimulST attuali richiedono spesso l'addestramento di architetture specifiche, con l'introduzione di moduli aggiuntivi da ottimizzare. Questo comporta:

* **Procedure di addestramento lunghe e complesse:** spesso l'addestramento coinvolge diversi obiettivi di ottimizzazione.
* **La necessità di addestrare e mantenere diversi modelli:** per ottenere diversi ritardi (latenza) è necessario addestrare modelli separati con tempi medi di latenza differenti, ad esempio un modello con un ritardo medio di un secondo e un altro con due secondi.

**La nostra soluzione:**

La nostra proposta si concentra su un approccio innovativo che evita:

* **La necessità di addestrare nuovamente modelli SimulST specifici:** utilizziamo modelli di traduzione automatica offline (ST) esistenti senza modificarli o adattarli per SimulST.
* **L'uso di architetture specifiche per ogni regime di latenza:** utilizziamo un unico modello per ogni regime di latenza, gestendo il ritardo tramite parametri specifici.

Ci affidiamo all'**attenzione incrociata** tra input audio e output testuale, già acquisita dai modelli ST, per guidare il processo di traduzione.

**Presentazione di EDAtt:**

Abbiamo sviluppato **EDAtt (Encoder-Decoder Attention)**, una strategia che decide se emettere o meno una parte della traduzione in base a dove punta l'attenzione. Una parola viene emessa se l'attenzione non è concentrata, ovvero se la somma dei pesi di attenzione verso gli ultimi *lambda* frame di discorso è inferiore ad una soglia *alpha*.

**Risultati:**

I risultati di EDAtt mostrano:

* **Alta qualità di traduzione:** misurata con BLEU.
* **Basso ritardo:** sia in termini assoluti che computazionalmente consapevoli.

Confronto con altri metodi:

* **Wait-k:** una strategia comune utilizzata anche per modelli offline.
* **Local Agreement:** un'altra strategia basata su modelli offline.
* **Architettura specifica SimulST:** progettata appositamente per la traduzione simultanea.

I nostri risultati dimostrano che EDAtt supera tutti gli altri metodi, sia in termini di qualità che di velocità.

**Conclusione:**

Il nostro lavoro offre un contributo significativo al campo della traduzione simultanea del discorso, proponendo un approccio efficiente e flessibile.

Per ulteriori dettagli, consultate il nostro articolo. Abbiamo inoltre reso disponibile open source il codice, i modelli e le uscite simultanee per garantire la riproducibilità dei nostri risultati.

Grazie per l'attenzione.</sample>
    <sample id="149">Sì, il dataset CoNLL++ sviluppato nello studio è disponibile pubblicamente. Gli autori hanno reso accessibile il dataset per facilitare la riproducibilità e ulteriori ricerche.</sample>
    <sample id="150"># **MEETINGQA: Un dataset per la Domanda-Risposta Estrazione in Trascritti di Riunioni**

Il paper presenta MEETINGQA, un nuovo dataset per la Domanda-Risposta Estrazione (QA) basato su trascritti di riunioni. Gli autori riconoscono il potenziale dei trascritti di riunioni come risorsa per la ricerca NLP, evidenziando la loro lunghezza, specificità di dominio e ricchezza di informazioni.

Il dataset MEETINGQA si concentra sulle domande poste dai partecipanti durante le riunioni e sulle relative risposte. Include 7.7K domande suddivise in set di addestramento, sviluppo e test, con scenari di risposta vari, come risposte multiple o di più speaker. L'analisi mostra che le domande sono spesso formulate in modo aperto e richiedono discussioni dettagliate.

La creazione del dataset coinvolge l'estrazione di domande da trascritti pubblici AMI e un rigoroso processo di annotazione. Gli autori valutano diverse architetture di modelli, inclusi modelli a contesto breve e lungo, e varianti single-span e multi-span. I risultati mostrano che i modelli fine-tuned raggiungono un'accuratezza F1 dell'84.6%, con i modelli a contesto breve che superano quelli lunghi.

Un'analisi delle prestazioni in zero-shot rivela un divario significativo rispetto all'umano, ma l'uso dell'augmentazione dei dati migliora i risultati. Il dataset MEETINGQA rappresenta una sfida unica per i modelli QA, evidenziando la complessità delle domande di riunione e la necessità di metodi più avanzati per un'efficace elaborazione del linguaggio naturale in questo dominio.</sample>
    <sample id="151">## Presentazione: MultiInstruct - Migliorare l'Apprendimento Zero-Shot Multimodale tramite l'Instruction Tuning

**Introduzione**

Salve a tutti, io sono Ying e il mio collega Zhiyang. Presentiamo la nostra ricerca su **MultiInstruct**, un metodo per migliorare l'apprendimento zero-shot multimodale tramite l'instruction tuning. Con i progressi dei grandi modelli linguistici, molte ricerche hanno esplorato nuovi paradigmi di apprendimento che riutilizzano i modelli pre-addestrati per diverse attività downstream in modo efficiente in termini di parametri e dati. Studi recenti hanno dimostrato che l'instruction tuning consente ai grandi modelli linguistici di eseguire compiti mai visti in modo zero-shot seguendo istruzioni naturali. Tuttavia, la maggior parte delle opere precedenti sull'instruction tuning si è concentrata sul miglioramento delle prestazioni zero-shot per compiti linguistici, mentre quelli di visione e multimodali sono stati trascurati.

**Motivazione e Problema**

Nel nostro lavoro, vogliamo indagare se l'instruction tuning di modelli multimodali pre-addestrati può effettivamente migliorare la generalizzazione a compiti multimodali mai visti. Inoltre, durante la nostra ricerca, abbiamo notato una notevole discrepanza nella disponibilità di dataset di istruzioni tra NLP e multimodale. Esistono oltre 1600 compiti linguistici di istruzioni, ma non esiste un dataset multimodale di istruzioni di grandi dimensioni pubblicamente disponibile. Questo ha motivato la creazione di **MultiInstruct**, il primo dataset di instruction tuning multimodale che comprende 62 compiti diversi coperti da 10 categorie ampie.

**MultiInstruct: Il Dataset**

Questi compiti provengono da 21 dataset open-source esistenti e ogni compito è dotato di cinque istruzioni scritte da esperti. Abbiamo unificato la gestione di diversi tipi di input e output per mostrare la flessibilità del dataset. Seguiamo l'approccio di OFA, un modello multimodale pre-addestrato unificato, che utilizza un vocabolario unificato per testo, token di immagini e coordinate di bounding box.

**Metodologia**

Per l'addestramento, utilizziamo 53 compiti da 9 gruppi, campionando 10.000 istanze per compito. Per il test, riserviamo l'intero gruppo di ragionamento di senso comune e selezioniamo 5 compiti aggiuntivi dai gruppi VQ e Miscellanea. Valutiamo ogni istanza nel set di test per ogni compito. Inoltre, per i compiti NLP, campioniamo casualmente 20 compiti dal set di test di istruzioni naturali come compiti non visti.

Utilizziamo il modello pre-addestrato OFA-large come base. Durante l'addestramento, mescoliamo tutte le istanze per tutti i compiti e ogni istanza viene combinata casualmente con una delle cinque template di istruzione. Durante il test, conduciamo 5 esperimenti per ogni compito, valutando il modello con una delle cinque istruzioni.

**Valutazione**

Per i compiti di classificazione multimodale, riportiamo l'accuratezza. Per i compiti di generazione multimodale, utilizziamo ROUGE-L. Per i compiti NLP, utilizziamo ROUGE-L anch'esso. Introdurremo anche una nuova metrica chiamata **sensibilità**, che misura la capacità del modello di produrre gli stessi output per lo stesso compito indipendentemente dalla leggera variazione del testo dell'istruzione.

**Risultati**

I nostri risultati dimostrano che l'instruction tuning può migliorare significativamente le prestazioni di OFA sui compiti multimodali visti. Il trasferimento di apprendimento da dataset di istruzioni naturali migliora ulteriormente le prestazioni e riduce la sensibilità. Abbiamo notato che l'utilizzo di più istruzioni durante il fine-tuning migliora le prestazioni complessive e riduce la sensibilità.

**Contributi**

* Presentiamo **MultiInstruct**, il primo dataset di instruction tuning multimodale di larga scala con una capacità significativamente migliorata di OFA.
* Esploriamo diverse tecniche di trasferimento di apprendimento e ne dimostriamo i vantaggi.
* Introdotti la metrica **sensibilità** per valutare la coerenza del modello.
* Stiamo raccogliendo un dataset ancora più ampio di instruction tuning multimodale con circa 150 compiti aggiuntivi e lo renderemo disponibile.

**Conclusione**

Speriamo che MultiInstruct possa contribuire alla ricerca sull'apprendimento multimodale e stimolare ulteriori sviluppi in questo campo.</sample>
    <sample id="152"># **Esplorazione dei Modelli di Linguaggio di Grandi Dimensioni per la Filologia Classica**

La presentazione di Frederick Riemenschneider introduce un nuovo approccio all'applicazione dell'Intelligenza Artificiale nella filologia classica, in particolare per le lingue greca e latina. Gli oratori hanno sviluppato modelli linguistici specifici per la filologia classica, affrontando le sfide poste dalla mancanza di risorse pre-addestrate e dalla valutazione limitata delle prestazioni.

Il team ha creato due modelli monolingue, GreBERTa e GreTa, per il greco antico, con GreTa che include una capacità generativa. Inoltre, PhilBERTa e PhilTa, modelli multilingue, sono stati addestrati su dati in greco, latino ed inglese. La raccolta di dati di addestramento ha incluso risorse esistenti e un nuovo corpus dall'Internet Archive, affrontando le sfide della trascrizione greca.

La valutazione dei modelli è stata condotta su tre compiti principali: etichettatura delle parti del discorso, analisi della dipendenza e lemmatizzazione. I risultati dimostrano che i modelli superano le prestazioni precedenti, con GreTa che mostra un miglioramento significativo nella lemmatizzazione del greco antico. L'analisi dell'encoder T5 separato rivela un'evoluzione delle prestazioni dopo l'addestramento.

L'aspetto multilingue è stato esaminato, confrontando modelli multilingue e monolingui. I risultati suggeriscono che il multilingue non migliora in modo significativo le prestazioni, sia per la conoscenza semantica che per quella del mondo. In conclusione, la presentazione evidenzia lo sviluppo di potenti modelli linguistici per la filologia classica, con potenziali applicazioni nella comprensione e nell'analisi di testi antichi.</sample>
    <sample id="153"># Risolvere le Ambiguità nei Modelli Generativi Testo-Immagine

La ricerca presentata da Ninareh Mehrabi e il suo team si concentra sulle ambiguità presenti nei prompt forniti ai modelli generativi testo-immagine, che spesso ostacolano la creazione di immagini coerenti con l'intento dell'utente. Lo studio propone un approccio per affrontare e valutare queste ambiguità.

Il team ha creato un dataset di benchmark, basato su LAVA, che include vari tipi di ambiguità. Introdurre un sistema di disambiguazione basato su un modello linguistico che genera domande di chiarimento o suggerisce diverse interpretazioni visive. Gli utenti forniscono risposte basate sulla loro intenzione, portando a prompt disambiguati.

La metodologia include due approcci: in uno, il modello genera una domanda, e l'utente risponde; nell'altro, il modello crea diverse rappresentazioni visive e l'utente seleziona quella più adatta. I prompt disambiguati vengono poi utilizzati per generare immagini tramite un modello testo-immagine.

L'efficacia del processo è valutata utilizzando un modello VQA (Visual Question Answering) che determina se le immagini generate soddisfano l'intento dell'utente. I risultati dimostrano che la disambiguazione migliora la fedeltà delle immagini e che il framework di valutazione automatizzato è affidabile.

Lo studio evidenzia le differenze nella risoluzione delle ambiguità a seconda del tipo e sottolinea l'importanza di affrontare questo problema per migliorare le prestazioni dei modelli generativi testo-immagine.</sample>
    <sample id="154">Gli autori dell'articolo, "Attention as a Guide for Simultaneous Speech Translation", sono affiliati all'Università di Trento e alla Fondazione Bruno Kessler, come menzionato da Sara Papi durante la presentazione.</sample>
    <sample id="155">Il nome della relatrice o del relatore è Javad Hosseini.</sample>
    <sample id="157"># **Dialogue Summarization with Static-Dynamic Structure Fusion Graph**

Questo studio presenta un approccio innovativo per la sintesi dei dialoghi, chiamato SDDS (Static-Dynamic Dialogue Summarization), che mira a migliorare la qualità e l'efficienza della sintesi delle conversazioni multi-partecipante.

La sintesi dei dialoghi è una sfida complessa nel campo della elaborazione del linguaggio naturale, poiché richiede di estrarre i punti salienti da un contesto dialogico complesso. Gli autori propongono un modello che va oltre i metodi tradizionali basati su strutture grafiche statiche pre-calcolate.

Il modello SDDS comprende quattro componenti principali. In primo luogo, un *Utterance Encoder* trasforma ogni enunciato in una rappresentazione vettoriale. Successivamente, un modulo *Static-Dynamic Graph* combina strutture grafiche statiche pre-costruite con relazioni semantiche dinamiche tra gli enunciati. Questo processo integra informazioni strutturali statiche e dinamiche. Un modello di linguaggio pre-addestrato, agisce come *Summary Generator*, per creare il riassunto finale, fondendo le strutture dialogiche.

Il modello introduce quattro metodi per modellare la struttura dialogica statica, tra cui un *Discourse Parsing Graph* e un *Speaker Interaction Graph*. Il *Dynamic Graph Module* utilizza l'attenzione multi-testa per catturare le relazioni semantiche. L'integrazione delle strutture statiche e dinamiche avviene attraverso un'attenzione incrociata e un livello di attenzione basato sul grafo.

La ricerca dimostra l'efficacia del modello SDDS, superando i metodi tradizionali, e fornisce il codice e i dati su GitHub per facilitare la riproducibilità.</sample>
    <sample id="158"># **Dual Cache per la Risoluzione della Coreferenza in Documenti Lunghi**

La presentazione di Qipeng Guo di AWS introduce un nuovo approccio per migliorare l'efficienza della risoluzione della coreferenza nei documenti lunghi. La coreferenza coinvolge l'identificazione di menzioni multiple di entità all'interno di un testo e la loro raggruppamento in base al riferimento.

I metodi tradizionali richiedono un'enumerazione completa delle coppie di menzioni, portando a una complessità computazionale e di memoria quadratica. Le tecniche basate su cache, come quelle recenti, riducono questa complessità a lineare utilizzando una cache fissa. Tuttavia, nei documenti lunghi, i cambiamenti di argomento possono rendere le menzioni di un'entità sparse in tutto il testo, aumentando i mancati aggiornamenti della cache (cache misses).

La soluzione proposta è un sistema di cache duale che comprende una cache locale e una globale. La cache locale, che segue una politica di rimozione LRU (Least Recently Used), gestisce le entità locali. La cache globale, invece, utilizza una politica LFU (Least Frequently Used) per le entità ad alta frequenza. Questo approccio consente al modello di scansionare il documento, identificare nuove menzioni e classificarle in base alla loro frequenza, aggiungendole alla cache locale o globale di conseguenza.

I test su quattro set di dati pubblici dimostrano l'efficacia della cache duale, che riduce significativamente i cache misses rispetto ai metodi tradizionali. Anche senza dati di addestramento, la cache duale si rivela più efficiente. L'abstract conclude che questo approccio offre il miglior rapporto prestazioni/costo, superando i metodi a singola cache.</sample>
    <sample id="159">## Introduzione al nostro lavoro ACL 2023: Valutazione della coerenza linguistica in contesti estesi

Ciao a tutti, mi chiamo Koustav Sinha e sono entusiasta di presentarvi il nostro lavoro, presentato al conferenza ACL 2023, che esplora le valutazioni di accettabilità del linguaggio naturale.

**Il problema:**

Le tradizionali valutazioni di accettabilità del linguaggio, basate su paradigmi come BLiMP, SyntaxGym o coppie CrowS, si concentrano su singole frasi grammaticali o non grammaticali. Tuttavia, i moderni modelli linguistici hanno finestre di contesto sempre più ampie, rendendo cruciale valutare la loro capacità di comprendere l'accettabilità in contesti più lunghi.

**La nostra soluzione:**

Abbiamo rivisitato il paradigma MPP (Minimal Pair Paradigm) per adattarlo a sequenze più estese. Per farlo, abbiamo:

1. **Creato sequenze più lunghe:** Abbiamo rielaborato set di dati esistenti, come BLiMP, scegliendo frasi grammaticali ed ingrammaticali e aggiungendole come prefissi a coppie di query.

2. **Variato il contesto:**

    * **Stesso dataset:** Abbiamo confrontato frasi grammaticali e non grammaticali provenienti dallo stesso set di dati.
    * **Dataset diverso:** Abbiamo testato la robustezza del modello utilizzando frasi da un dataset diverso.
    * **Contesto esterno:** Abbiamo incluso frasi da Wikipedia, completamente esterne al contesto di valutazione.


**Risultati:**

* **Contesto esterno (Wikipedia):** Le valutazioni MPP sono risultate sorprendentemente stabili anche con contesti molto lunghi (fino a 1024 token).
* **Stesso dataset:** Quando le frasi condividono la stessa struttura sintattica, le valutazioni MPP variano drasticamente, sia in modo positivo che negativo, a seconda che il prefisso sia accettabile o non accettabile.
* **Sensibilità strutturale:** Abbiamo scoperto che i modelli sono sensibili a piccole variazioni strutturali nelle frasi, anche se il significato generale rimane simile.

**Conclusioni:**

I nostri risultati dimostrano che i modelli linguistici sono sensibili a latenti caratteristiche sintattiche e semantiche condivise tra le frasi. Le attuali valutazioni MPP, basate su singole frasi, potrebbero non catturare appieno la conoscenza astratta dei modelli all'interno della loro finestra di contesto.

Leggete il nostro articolo per approfondire i dettagli dei nostri esperimenti.

Grazie per l'attenzione!</sample>
    <sample id="160">Il primo passaggio del metodo mappa i token di input in **un'unordered multiset di token** che appariranno nell'output.</sample>
    <sample id="161">CoScript contiene 55.000 script specifici.</sample>
    <sample id="163">Il metodo di allineamento migliore per DEPLAIN, secondo la ricerca presentata, è **MASSalign**.</sample>
    <sample id="164">L'apprendimento scarsamente supervisionato (WSL) offre diversi vantaggi:

1. **Costo ridotto**: Utilizza fonti di etichettatura deboli come regole heuristiche o crowdsourcing di bassa qualità, che sono molto più economiche rispetto all'etichettatura manuale.
2. **Robustezza al rumore**: I metodi WSL sono progettati per gestire il rumore nelle etichette deboli, evitando che i modelli memorizzino erroneamente le etichette e migliorando la generalizzazione.
3. **Potenziale di alta prestazione**: Nonostante le sfide, recenti studi WSL affermano di raggiungere alte prestazioni sui set di test puliti, anche se spesso richiedono set di validazione puliti per una corretta selezione del modello.

Tuttavia, la ricerca presentata evidenzia che:

- **Necessità di dati puliti**: I metodi WSL attuali richiedono dati di validazione puliti per funzionare al meglio.
- **Quantità sufficiente di dati puliti**: Solo 20 campioni per classe sono generalmente sufficienti per ottenere alte prestazioni.
- **Efficacia del fine-tuning diretto**: Il fine-tuning diretto sui dati puliti può superare le prestazioni dei metodi WSL che utilizzano solo dati deboli.</sample>
    <sample id="165"># **Abductive Commonsense Reasoning: Unsupervised Learning with LiPoR**

Questo studio presenta un approccio innovativo all'inferenza abducente, un tipo di ragionamento che mira a spiegare un risultato osservato (outcome) a partire da un contesto noto. Gli autori propongono un metodo di apprendimento non supervisionato chiamato LiPoR (Likelihood Learning with Posterior Regularization) per identificare spiegazioni plausibili senza la necessità di etichettatura manuale.

Il problema è complesso a causa della soggettività nella valutazione delle spiegazioni. Gli esperimenti hanno mostrato che i lavoratori del crowd spesso non sono d'accordo sulle spiegazioni, sollevando la domanda: è possibile apprendere l'inferenza abducente senza supervisione?

La soluzione proposta coinvolge la modellazione delle spiegazioni come variabili latenti e l'uso della regolarizzazione per preferire spiegazioni plausibili. LiPoR massimizza la verosimiglianza dell'outcome dato il contesto, marginalizzando le altre spiegazioni. Inoltre, introduce una regolarizzazione basata sulla mutualità esclusiva delle spiegazioni, garantendo che solo una sottocategoria di spiegazioni sia considerata plausibile.

L'approccio è stato testato sul dataset AlphaNLI, dove LiPoR ha superato i modelli zero-shot esistenti e l'approccio precedente non supervisionato, raggiungendo un aumento di accuratezza di oltre 4 punti percentuali. Questo lavoro dimostra il potenziale dell'apprendimento non supervisionato nell'abduzione del senso comune, aprendo nuove strade per lo sviluppo di sistemi di intelligenza artificiale più robusti e flessibili.</sample>
    <sample id="166"># **A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Complex Text**

Questo studio propone un approccio innovativo per il recupero di immagini da testi complessi, affrontando le sfide poste da descrizioni lunghe e immagini altamente simili. Gli autori si ispirano alla strategia Divide-and-Conquer e alla Dual-Process Theory per sviluppare un framework neurale.

Il metodo introduce due sistemi di ragionamento: System 1 (Analogico) e System 2 (Logico). System 1, basato su modelli visuo-linguistici pre-addestrati, gestisce l'interazione tra immagini e proposte. System 2, implementato come Neural-Symbolic Reasoner, combina gli stati di ragionamento e i risultati di semplici proposte per risolvere complesse proposte testuali.

Il framework è suddiviso in tre componenti principali: Proposition Generator, Visual-Linguistic Interactor (System 1) e Neural-Symbolic Reasoner (System 2). Il Generator di Proposizioni semplifica le descrizioni complesse, mentre l'Interactor visuo-linguistico calcola i punteggi di corrispondenza. Il Reasoner neurale simbolico esegue la logica, gestendo la negazione e le operazioni di congiunzione.

Gli esperimenti dimostrano l'efficacia del metodo, superando i baseline esistenti. I risultati evidenziano il valore dell'integrazione tra ragionamento analogico e logico, suggerendo che l'approccio Divide-and-Conquer, combinato con la Dual-Process Theory, può migliorare le capacità di ragionamento e pianificazione dei modelli linguistici di grandi dimensioni. Lo studio offre preziose intuizioni per lo sviluppo di sistemi di intelligenza artificiale più versatili e capaci di gestire compiti complessi.</sample>
    <sample id="167">Secondo la presentazione, l'allocazione dei documenti in DEPLAIN-web è avvenuta attraverso due metodi:

1. **Manuale**: 750 documenti sono stati allineati manualmente.
2. **Automatico**: 750 documenti sono stati allineati utilizzando metodi automatici di allineamento.

In sintesi, l'allocazione è stata effettuata sia manualmente che automaticamente.</sample>
    <sample id="168">Il set di dati CoNLL++ è stato creato raccogliendo articoli di Reuters News dal 2020 e annotandoli utilizzando le stesse linee guida di annotazione del CoNLL-2003.</sample>
    <sample id="169"># **Prompting PaLM per la Traduzione: Valutazione di Strategie e Prestazioni**

Questo studio presenta un'indagine approfondita sull'uso dei prompt per migliorare le capacità di traduzione di grandi modelli linguistici (LLM) come PaLM, un modello da 540 miliardi di parametri addestrato su una vasta raccolta di testo. Gli autori, in collaborazione con Google Translate, hanno condotto esperimenti per valutare l'efficacia di diverse strategie di prompting nella traduzione automatica.

La ricerca evidenzia l'impatto significativo dei prompt sulla prestazione degli LLM, dimostrando che un semplice cambiamento nel prompt può migliorare la qualità della traduzione di oltre un punto BLEURT su 1000 frasi. Gli esperimenti hanno adottato una strategia di 5-shot prompting, dove i prompt includono informazioni sulla lingua sorgente e di destinazione. I risultati suggeriscono che la qualità degli esempi utilizzati per il prompting è fondamentale, superando l'importanza della somiglianza con la frase sorgente.

L'analisi ha confrontato i prompt selezionati dal training data con quelli del set di valutazione WMT, mostrando prestazioni migliori con esempi di alta qualità. Sebbene PaLM si avvicini alle prestazioni di un sistema commerciale come Google Translate, i sistemi specializzati in traduzione rimangono in vantaggio. L'human evaluation ha rivelato che PaLM produce traduzioni fluide, ma con errori di omissione, dove a volte omette parti della frase sorgente. La categoria "Style/Awkward" per PaLM è inferiore rispetto ai sistemi di riferimento, indicando una buona fluidità, ma con problemi di accuratezza.

In sintesi, lo studio fornisce raccomandazioni per la selezione dei prompt, sottolineando l'importanza della qualità degli esempi per ottimizzare le prestazioni della traduzione con LLM.</sample>
    <sample id="170">## Presentazione: XSemPLR: Cross-Lingua Semantic Parsing in Diverse Lingue e Rappresentazioni del Significato

**Introduzione**

Salve a tutti, mi chiamo Yusen Zhang e provengo dall'Università della Pennsylvania. Oggi presenterò il nostro lavoro intitolato "XSemPLR: Cross-Lingua Semantic Parsing in Diverse Lingue Naturali e Rappresentazioni del Significato".

La **semantic parsing** è un'attività che mira a creare rappresentazioni semantiche di query utente, come SQL e Lambda Calculus. Il **cross-lingual semantic parsing** è invece la capacità di tradurre query in diverse lingue naturali in rappresentazioni semantiche corrispondenti. Come illustrato nella figura, dobbiamo utilizzare modelli neurali per tradurre le query in diverse lingue naturali in SQL, Lambda o FunQL, tra le altre.

**Sfide attuali**

I modelli esistenti per il cross-lingual semantic parsing sono stati sviluppati separatamente e valutati su set di dati limitati a specifici compiti e applicazioni. Ad esempio, c'è un'ampia copertura per alcune lingue naturali, ma manca la lingua cinese e la copertura per alcune rappresentazioni del significato è limitata. Il Lambda calculus spesso è assente o valutato solo su specifici modelli neurali, come un unico modello per tutte le valutazioni.

**Proposta: XSemPLR**

Per affrontare queste sfide, proponiamo XSemPLR, un dataset unificato per il cross-lingual semantic parsing in diverse lingue naturali e rappresentazioni del significato. XSemPLR comprende:

* 9 dataset in vari domini
* 5 compiti di semantic parsing
* 8 rappresentazioni del significato
* 22 lingue naturali appartenenti a 15 famiglie linguistiche

Per una valutazione più accurata, consideriamo sei scenari di addestramento e valutazione:

* **Translate-Test:** Utilizziamo Google Translate API per tradurre la sorgente nella lingua di destinazione, quindi utilizziamo un modello monolingue per l'addestramento e la valutazione.

* **Monolingual (stessa lingua sorgente e destinazione):** Ad esempio, tedesco-tedesco o inglese-inglese.

* **Monolingual Few-shot:** Addestriamo modelli monolingue con solo il 10% dei dati di addestramento.

* **Multilingual Model:** Addestriamo un unico modello multilingue per tutte le lingue, mescolando ad esempio query in tedesco, inglese e cinese. Durante l'inferenza, possiamo usare questo modello per tradurre query da qualsiasi lingua.

* **Cross-lingual Zero-shot e Few-shot transfer:** Addestriamo su una lingua sorgente e trasferiamo a un'altra lingua. Ad esempio, addestriamo un modello su query inglesi o combinazioni di query inglesi e tedesche Few-shot.

**Risultati**

* **Analisi dei modelli monolingue:** Abbiamo valutato due gruppi di modelli: Encoder-PTR (multilingue pre-addestrati con decodificatori basati su pointer) come XLM-R + PTR e mBERT + PTR, e modelli Encoder-Decoder multilingue come mBART e mT5. I modelli Encoder-Decoder hanno ottenuto i migliori risultati su tutti e nove i dataset.

* **Cross-lingual performance gap:** Abbiamo riscontrato che:
    * La zero-shot transfer ha un gap significativo rispetto alla configurazione monolingua.
    * La few-shot transfer riduce rapidamente il gap rispetto alla zero-shot.

* **Altri risultati:**
    * I modelli Encoder-Decoder superano le precedenti ricerche o raggiungono risultati comparabili.
    * Il pre-addestramento su inglese migliora significativamente le prestazioni Few-shot sulle lingue di destinazione.
    * I modelli multilingue come Codex e BLOOM si rivelano ancora inadeguati per le attività di cross-lingual semantic parsing.

**Conclusione**

In sintesi, abbiamo sviluppato XSemPLR, un benchmark unificato per il cross-lingual semantic parsing con diverse lingue naturali e rappresentazioni del significato. Attraverso una completa analisi su tre tipi rappresentativi di modelli linguistici multilingue, i nostri risultati hanno portato a diverse scoperte interessanti.

Vi invitiamo a consultare il nostro articolo e il codice. Grazie per l'ascolto.</sample>
    <sample id="171">In base al contenuto del video, i lavori connessi a questo studio includono:

1. **Protezione del copyright dei modelli di linguaggio**: Lo studio affronta la necessità di proteggere i diritti di proprietà intellettuale dei servizi di embedding basati su modelli di linguaggio grandi come GPT, LLAMA e PALM, che sono vulnerabili al furto di modelli da parte di attaccanti.

2. **Watermarking nei servizi di embedding**: Vengono esplorati metodi di watermarking per marcare i servizi di embedding, in modo da poter rilevare se un servizio di terze parti sta utilizzando il modello originale senza autorizzazione.

3. **Metodi di watermarking backdoor**: Lo studio propone "Embedding Marker", un metodo di watermarking basato su backdoor, che è specifico per i servizi di embedding e mantiene l'utilità delle embedding fornite.

4. **Valutazione dell'efficacia e della covertzza**: Sono condotti esperimenti su diversi dataset per valutare la capacità di rilevamento del watermark e la sua non-degradazione delle prestazioni per i compiti di elaborazione del linguaggio naturale (NLP) downstream.</sample>
    <sample id="172">No, secondo la ricerca presentata, gli LLM multilingue come Codex e BLOOM non sono ancora adeguati per le attività di Cross-Lingual Semantic Parsing (CLSP). Gli autori hanno riscontrato che questi modelli ottengono prestazioni inferiori rispetto ad altri approcci e che il "Curse of Multilinguality" può influenzare negativamente le loro capacità in alcuni casi.</sample>
    <sample id="174">**Abstract: ArgAnalysis35K: Un dataset innovativo per l'analisi della qualità degli argomenti**

Il paper presenta ArgAnalysis35K, un dataset di grandi dimensioni dedicato all'analisi della qualità degli argomenti, che mira a superare le limitazioni dei dataset esistenti. Gli autori, Thea e il suo team, hanno creato una raccolta unica di 35.000 coppie di analisi argomentativa, raccogliendo argomenti da tornei di dibattito di alto livello, esperti e debatteri intermedi.

Il dataset introduce diverse caratteristiche distintive:

1. **Qualità e Diversità**: Gli argomenti sono di alta qualità e diversificati, coprendo 24 temi diversi, garantendo così una rappresentazione più realistica dei dibattiti parlamentari.

2. **Analisi Complessa**: Introduce il concetto di "analisi" che va oltre le semplici affermazioni o premesse, includendo combinazioni di queste per fornire una comprensione più completa dell'argomento.

3. **Relazione tra Argomenti e Temi**: Ogni argomento è valutato per la sua rilevanza in vari temi, permettendo un'analisi più sfumata e contestualizzata.

4. **Affidabilità degli Annotatori**: Implementa un approccio di affidabilità istantanea degli annotatori, eliminando solo le valutazioni chiaramente parziali, migliorando così l'utilizzo dei dati.

ArgAnalysis35K offre un dataset più ricco e affidabile, che consente di addestrare modelli di intelligenza artificiale per valutare la qualità degli argomenti in modo più efficace. Il paper sottolinea l'importanza di questo dataset per la ricerca nel campo dell'elaborazione del linguaggio naturale e del dibattito.</sample>
    <sample id="175">Il metodo affronta l'ambiguità delle permutazioni utilizzando un approccio di rilassamento continuo GPU-friendly, che approssima il problema NP-hard del "Viaggiatore di Commercio". Questo permette di backpropagare attraverso la soluzione, imparando permutazioni linguisticamente più plausibili.</sample>
    <sample id="176">L'equità di un modello NLP a valle (downstream) viene definita in base alla sua capacità di trattare in modo imparziale e senza pregiudizi diversi gruppi demografici, ideologie o categorie sociali. Questo include aspetti come:

1. **Deteczione equa di contenuti negativi**: Il modello dovrebbe essere in grado di identificare e contrastare il linguaggio di odio e la disinformazione in modo equilibrato, indipendentemente dalla sua origine o dal gruppo sociale a cui si riferisce.
2. **Prestazioni coerenti su diverse prospettive**: Le prestazioni del modello non dovrebbero variare in base all'orientamento politico o ideologico delle fonti di dati di addestramento o dei testi di input.
3. **Assenza di marginalizzazione**: L'uso di modelli con pregiudizi politici non dovrebbe portare alla marginalizzazione di gruppi specifici o alla diffusione incontrollata di linguaggio di odio.

In sintesi, l'equità in un modello NLP a valle si misura dalla sua capacità di mantenere un trattamento imparziale e rispettoso di tutte le parti coinvolte.</sample>
    <sample id="177">Il nome della relatrice è Yanis Labrak.</sample>
    <sample id="178">Il nome della relatrice è Koustav Sinha.</sample>
    <sample id="179"># **Minding Language Models' Theory of Mind: Un approccio simbolico per migliorare la comprensione mentale**

La capacità di attribuire e comprendere gli stati mentali altrui, nota come "teoria della mente", è fondamentale per l'intelligenza umana e, sempre più, per i modelli di linguaggio di grandi dimensioni (LLM). La presentazione di Melanie Sclar esplora un metodo innovativo per migliorare le capacità di teoria della mente in questi modelli, in particolare nella gestione delle domande di falsa credenza.

Tradizionalmente, la teoria della mente viene valutata attraverso compiti di comprensione del testo che coinvolgono più personaggi, come il famoso test di Sally-Anne. I modelli LLM, inclusi ChatGPT e GPT-3, mostrano ancora prestazioni scarse in questi compiti. Per affrontare questo problema, gli autori propongono *SymbolicToM*, un approccio basato su grafici simbolici per migliorare la ragionamento sulla teoria della mente durante l'inferenza.

*SymbolicToM* crea rappresentazioni grafiche esplicite degli stati mentali dei personaggi, come le credenze di Bob sulla situazione attuale e le credenze di Alice su quelle di Bob. Questo metodo calcola questi grafici per vari livelli di complessità, migliorando la comprensione delle domande di seconda ordine. L'algoritmo utilizza modelli NLI e OpenIE per generare le rappresentazioni grafiche, che possono poi essere interrogate in modo efficiente.

Gli esperimenti dimostrano l'efficacia di *SymbolicToM* su diversi LLM, mostrando miglioramenti significativi nelle prestazioni, soprattutto in compiti fuori dominio. Il metodo è robusto e generalizzabile, superando i modelli supervisionati e consentendo persino a modelli avanzati come GPT-4 di eccellere in nuovi dataset. In conclusione, *SymbolicToM* offre un approccio plug-and-play per potenziare la teoria della mente nei modelli di linguaggio.</sample>
    <sample id="180">La relatrice è Myra.</sample>
    <sample id="181"># **Distilling Script Knowledge for Constrained Language Planning**

Questo studio si concentra sulla pianificazione linguistica vincolata, un'area cruciale nell'intelligenza artificiale che mira a guidare le azioni umane attraverso istruzioni dettagliate. Gli autori affrontano la sfida di pianificare obiettivi specifici con vincoli multipli, un aspetto spesso trascurato nella ricerca precedente.

La ricerca introduce il problema della pianificazione linguistica vincolata e sottolinea la necessità di script affidabili e coerenti con le restrizioni. Poiché i dataset specifici per questo compito sono scarsi, gli autori utilizzano un approccio innovativo chiamato *symbolic knowledge distillation*. Questo processo estrae dati da grandi modelli linguistici (LLM) per creare un dataset di alta qualità, chiamato CoScript, contenente 55.000 obiettivi specifici con script associati.

L'analisi iniziale rivela che i modelli linguistici tradizionali faticano a pianificare obiettivi specifici. Per migliorare le prestazioni, viene implementata una tecnica di *over-generate-then-filter* che aumenta la qualità della generazione. Questo metodo coinvolge la generazione di più script e la selezione di quelli più coerenti con i vincoli utilizzando la semantica e le parole chiave.

CoScript dimostra la sua efficacia consentendo a modelli più piccoli, come T5, di generare script di alta qualità, superando alcuni LLM più grandi. Questo lavoro fornisce un dataset prezioso per la ricerca futura sulla pianificazione linguistica vincolata, aprendo la strada a sistemi più efficienti e specializzati.</sample>
    <sample id="182">Nel contesto dell'articolo, il tropicalismo si riferisce a un insieme di stereotipi e rappresentazioni che collegano determinati gruppi etnici, come le donne latine, a caratteristiche come "vibrant" (vibrante) e "curvaceous" (curvato), evocando immagini esotiche e tropicali. Questo trope contribuisce a una narrazione essenzialista che "altra" queste culture, perpetuando una lunga storia di discriminazione e stereotipi.</sample>
    <sample id="183">Gli autori hanno elaborato le rappresentazioni umane dei gruppi target attraverso due metodi principali:

1. **Generazione di Personas**: Hanno creato personas immaginari utilizzando prompt specifici che indicavano identità demografiche (ad esempio, "Immagina di essere una donna asiatica. Descrivi te stessa").

2. **Metodo Marked Words**: Hanno analizzato le parole che distinguono i gruppi "marcati" (marginalizzati) da quelli "non marcati" (dominanti) per identificare stereotipi e narrazioni essenzializzanti nascosti nelle descrizioni generate dal modello.</sample>
    <sample id="184">Nel lavoro, è stato utilizzato **CXMI (Contextual eXtractive Multilingual Information)** per misurare l'utilizzo del contesto durante la traduzione. In particolare, è stata introdotta una versione estesa chiamata **Pointwise CXMI** che misura l'informazione fornita dal contesto a livello di frase o parola.</sample>
    <sample id="185">La differenza principale tra DrBERT e ChuBERT è la fonte e la quantità di dati utilizzati per il pre-addestramento:

- **DrBERT**: Si basa su NACHOS, un dataset di dati medici web-crawled in francese, con una dimensione di 7 GB o 4 GB.

- **ChuBERT**: Utilizza dati anonimizzati ottenuti dal data warehouse dell'Ospedale Universitario di Nantes (4 GB di frasi da note cliniche).

In sintesi, DrBERT è addestrato su un dataset più ampio e vario (NACHOS), mentre ChuBERT si concentra su dati clinici specifici.</sample>
    <sample id="187">Due autori sono coinvolti nell'articolo: Ying e Zhiyang.</sample>
    <sample id="188">Il trasferimento iterativo dell'apprendimento (Iterative Transfer Learning) è una strategia che combina il trasferimento di conoscenze da compiti correlati con l'apprendimento attivo. In questo approccio, i modelli vengono inizialmente addestrati su compiti simili, come la classificazione del tono del dibattito (debate) o la classificazione di espansione e confronto (CE) del PDTB. Successivamente, il modello viene iterativamente raffinato e adattato ai dati annotati in modo attivo, migliorando la capacità di rilevare la dissonanza.

In sintesi, il trasferimento iterativo aiuta a superare la sfida della rarità delle classi di dissonanza, migliorando le prestazioni del modello con un numero ridotto di annotazioni.</sample>
    <sample id="189">L'obiettivo del set di dati AltEntities Corpus è fornire una risorsa per addestrare e valutare i modelli linguistici (LLM) nella comprensione di riferimenti indiretti per la selezione di entità, come canzoni, libri o ricette, in conversazioni naturali. Il set di dati contiene 6.000 alternative domande e 42.000 espressioni di riferimento indiretto, con un'enfasi sull'informalità e la diversità dei domini.</sample>
    <sample id="190">Un utente malintenzionato può estrarre i parametri del modello attraverso un servizio di embedding come EaaS (Embedding as a Service) sfruttando tecniche di apprendimento da embedding. Senza adeguate misure di protezione, un attaccante potrebbe:

1. **Imparare dai dati di embedding forniti dall'API**: Analizzando le risposte dell'API, l'attaccante può ricostruire parte della struttura e dei parametri del modello.
2. **Fornire servizi simili**: Una volta appresi i parametri, l'attaccante può creare un modello simile e offrire un servizio alternativo che produce output quasi identici.

Per contrastare questo, il paper introduce "Embedding Marker", una tecnica di watermarking backdoor che inserisce un "marchio" nascosto negli embedding, permettendo di rilevare se un modello è stato estratto illegalmente.</sample>
    <sample id="191">L'articolo coinvolge tre autori: Sara Papi, Matteo Negri e Marco Turchi.</sample>
    <sample id="192"># **CAME: Un Optimizzatore per Modelli Linguistici di Grandi Dimensioni con Memoria Efficiente e Adattiva**

La presentazione di Yang Luo introduce CAME, un innovativo ottimizzatore progettato per affrontare le sfide nella formazione di grandi modelli linguistici. L'autore evidenzia le limitazioni degli ottimizzatori tradizionali, come Adam, che richiedono una notevole quantità di memoria per calcolare i momenti delle gradienti per ogni parametro. Ottimizzatori precedenti, come Adafactor, riducono il consumo di memoria ma a scapito delle prestazioni.

Il lavoro propone un approccio unico che combina la non-negativa fattorizzazione di matrici (NMF) con un meccanismo di aggiornamento adattivo. L'NMF riduce i requisiti di memoria, mentre il meccanismo di aggiornamento gestisce gli errori intrinseci degli ottimizzatori basati su gradienti adattivi. L'idea chiave è introdurre una "instabilità" nel processo di aggiornamento, adattando i passi di ottimizzazione in base alla differenza tra il momento precedente e l'aggiornamento corrente.

Gli esperimenti condotti su dataset come BookCorpus e English Wikipedia dimostrano l'efficacia di CAME. Rispetto ad Adafactor, CAME migliora la precisione di convalida del 3,4% utilizzando lo stesso numero di passaggi di addestramento. Inoltre, CAME supera Adam nella pre-formazione di modelli di grandi dimensioni, riducendo significativamente i costi di memoria con batch di dimensioni crescenti. I risultati mostrano anche che CAME migliora le prestazioni dei modelli BERT-based in vari compiti di fine-tuning, mantenendo un consumo di memoria inferiore.

In sintesi, CAME offre un compromesso ottimale tra velocità di convergenza, efficienza di memoria e stabilità del training, rendendolo un candidato promettente per l'addestramento di modelli linguistici di grandi dimensioni.</sample>
    <sample id="193">Basandomi sul testo fornito, non è specificato il numero esatto di annotatori impiegati per creare il set di dati iniziale. Si fa riferimento a un'annotazione su larga scala, ma non viene indicata una cifra precisa.</sample>
    <sample id="194">Gli autori dell'articolo sono affiliati a:

- Carnegie Mellon University
- University of Washington
- Allen Institute for AI</sample>
    <sample id="195">**Abstract:**

Il lavoro di ricerca presentato, intitolato "Reasoning over Hierarchical Question Decomposition Tree per Explainable Question Answering" (RoHT), affronta le sfide nell'ambito dell'Answerino alle Domande Esplicative (XQA), mirando a fornire sia la risposta che una spiegazione per il suo selezione. Gli autori propongono un nuovo approccio basato su un albero gerarchico di decomposizione delle domande (HQDT) per migliorare l'efficacia e l'esplicabilità del sistema.

L'approccio RoHT si articola in due fasi. In primo luogo, costruisce l'HQDT, una struttura ad albero che rappresenta la gerarchia delle sottodomande all'interno di una domanda complessa. Questo processo identifica le domande atomiche alla base dell'albero. In secondo luogo, implementa un ragionamento probabilistico sull'HQDT, integrando conoscenze da un database strutturato (KB) e da un corpus di testo. Questo ragionamento considera la probabilità di generazione delle stringhe e la probabilità di risposta per ogni nodo dell'albero.

Durante il processo di ragionamento, RoHT seleziona le fonti di conoscenza appropriate per ogni nodo, ottiene risposte con probabilità dai KB e dai testi, e aggrega le risposte per fornire le risposte finali. L'efficacia di RoHT è dimostrata su due dataset complessi: KQA Pro e Musique. I risultati mostrano che RoHT supera i metodi esistenti, sia quando si affidano solo a KB incompleti, sia quando integrano testi supplementari, evidenziando il valore della decomposizione gerarchica e dell'integrazione di conoscenze eterogenee.</sample>
    <sample id="196">L'esempio in cui il governatore è a sinistra è "I saw Bart and Lisa". In questo caso, il primo conjunct ("Bart and Lisa") è preferibilmente più corto rispetto all'altro.</sample>
    <sample id="197">In base al contenuto fornito, i modelli all'avanguardia nei sistemi di dialogo menzionati sono quattro modelli di chat di stato dell'arte valutati utilizzando il metodo ABC-Eval.

Non vengono specificati i nomi dei modelli, ma l'articolo sottolinea l'importanza di confrontare le prestazioni di questi modelli su più dimensioni per comprendere i loro punti di forza e debolezza.</sample>
    <sample id="198">La valutazione dell'accettabilità dei modelli nell'intera finestra di contesto è necessaria perché i modelli linguistici moderni hanno finestre di contesto sempre più ampie. La valutazione tradizionale basata su coppie minime (MPP) non consente di esaminare come i modelli gestiscono l'accettabilità in sequenze più lunghe. Questo studio mira a colmare questa lacuna simulando sequenze più lunghe e valutando l'accettabilità dei modelli in vari scenari, inclusi quelli con prefissi accettabili o inaccettabili, sia dallo stesso dataset che da dataset diversi o completamente irrilevanti.</sample>
    <sample id="199">Sì, secondo la presentazione, la formazione di modelli multilingue ha causato un calo delle prestazioni in sette dei nove dataset, con un miglioramento solo in tre. Questo fenomeno è noto come il "Curse of Multilinguality" (Maledizione della Multilingue), dove l'aggiunta di lingue diverse dall'inglese può diminuire le prestazioni del modello su tale lingua.</sample>
    <sample id="200">No, gli annotatori **non conoscono in anticipo** le entità. Vengono forniti solo alcuni dettagli di contesto (come link di ricerca o estratti di Wikipedia) su ciascuna entità prima di dover selezionare e descrivere una di esse utilizzando espressioni di riferimento indirette.</sample>
    <sample id="201">Le metriche di valutazione utilizzate per la traduzione automatica (MT) nello studio includono:

1. **BLEURT**: Una metrica neurale di stato dell'arte per valutare la qualità delle traduzioni.
2. **Metriche neurali MT**: Utilizzate per una valutazione quantitativa.
3. **Valutazione umana con MQM**: Effettuata da esperti per fornire un giudizio qualitativo sulla fluidità e accuratezza delle traduzioni.

Queste metriche combinate offrono una valutazione completa delle prestazioni del modello PaLM per la traduzione.</sample>
    <sample id="202">Sì, il nostro studio suggerisce che il regresso nella generalizzazione influisce in modo significativo sui modelli NER sviluppati con dati CoNLL-2003. Abbiamo scoperto che la performance dei modelli può diminuire a causa del *temporal drift*, ovvero il divario temporale tra i dati di addestramento e quelli di test. Questo effetto è più pronunciato con l'aumentare del gap temporale.

Inoltre, abbiamo identificato tre fattori chiave per una buona generalizzazione: l'architettura del modello (con i modelli Transformer che generalmente si comportano meglio), la dimensione del modello (modelli più grandi tendono a generalizzare meglio) e la quantità di esempi di addestramento (più dati portano a una migliore generalizzazione).</sample>
    <sample id="203">La posizionalità nella NLP è importante perché evidenzia come le prospettive e le esperienze dei ricercatori e degli sviluppatori (dati dai loro demografi e identità) possano influenzare i dataset e i modelli. Questo può portare a performance sistematicamente diverse tra diverse popolazioni. Studiare la posizionalità aiuta a identificare e mitigare i bias, rendendo l'NLP più equo e inclusivo, specialmente in compiti soggettivi e socialmente orientati.</sample>
    <sample id="204">Secondo la presentazione, gli LLM multilingue come BLOOM **non sono stati adeguatamente affinati** per le attività di cross-lingual semantic parsing. La ricerca evidenzia che questi modelli mostrano prestazioni ancora inadeguate, suggerendo la necessità di ulteriori adattamenti o messa a punto specifica per migliorare le loro capacità in questo dominio.</sample>
    <sample id="205"># **Da Dati di Pretraining a Modelli Linguistici: Esplorando i Pregiudizi Politici e le Implicazioni per le Attività NLP**

La ricerca, condotta da Shangbin e il suo team presso l'Università di Washington, si concentra sui potenziali pregiudizi politici nei modelli linguistici (LLM) e sulle loro implicazioni per le applicazioni NLP. I LLM sono addestrati su vasti dataset web che spesso includono contenuti da varie fonti di notizie politiche. Lo studio esamina come questi dati di pre-addestramento possano influenzare le tendenze politiche dei modelli e le loro prestazioni in compiti downstream.

I ricercatori hanno scoperto che i LLM mostrano variazioni significative nelle loro inclinazioni politiche, occupando tutti e quattro i quadranti dello spettro politico. GPT-4 emerge come il modello più liberale. L'addestramento aggiuntivo su corpora partisani, sia di notizie che di social media, dimostra che le coordinate ideologiche dei modelli si spostano di conseguenza. Inoltre, i modelli mostrano una tendenza a riflettere la polarizzazione sociale, con una maggiore distanza dal centro dopo il 2017.

L'analisi delle prestazioni dei modelli con diverse inclinazioni politiche in compiti come la rilevazione di odio e la rilevazione di notizie false rivela risultati interessanti. I modelli di sinistra eccellono nella rilevazione di odio verso minoranze sociali, mentre quelli di destra sono più efficaci nel rilevare odio verso bianchi e uomini. Simili tendenze si osservano nella rilevazione di notizie false. Questi risultati evidenziano potenziali problemi di equità nei sistemi NLP basati su LLM.

Lo studio solleva anche questioni etiche, sottolineando il dilemma nella gestione dei pregiudizi politici: rimuovere le opinioni politiche potrebbe portare a censura, mentre mantenerle potrebbe causare esclusione e difficoltà nel definire il contenuto neutrale.</sample>
    <sample id="206">Nel loro lavoro, gli autori ricorrono a modelli di **transfer learning** per migliorare la rilevazione della dissonanza cognitiva, affrontando la sfida della rarità della classe. Specificamente, utilizzano transfer da due compiti correlati: classificazione della posizione sulla dissonanza in dibattiti (debate) e classificazione delle classi di espansione e confronto del PDTB.</sample>
    <sample id="207">I recenti set di test utilizzati per valutare le capacità di PaLM, come presentato nel paper "Prompting PaLM for Translation", includono:

1. **Test set più recenti**: Per evitare sovrapposizioni con i dati di addestramento del modello, sono stati utilizzati i test set più aggiornati disponibili nella comunità di traduzione automatica (MT).

2. **WMT (Workshop on Machine Translation) evaluation**: Il sistema è stato confrontato con i sistemi di stato dell'arte che partecipano alla valutazione WMT, utilizzando le metriche neurali standard di MT.

3. **Valutazione umana con MQM (Multidimensional Quality Metrics)**: Oltre alle metriche automatiche, sono state condotte valutazioni umane utilizzando il framework MQM per ottenere una comprensione più completa della qualità delle traduzioni.</sample>
    <sample id="208">Gli autori hanno proposto **tre** suggerimenti alla fine del loro lavoro:

1. Affrontare i pregiudizi positivi e le narrazioni essenzialiste.
2. Utilizzare una lente intersezionale per studiare i pregiudizi e i danni.
3. Aumentare la trasparenza sui metodi di mitigazione dei pregiudizi.</sample>
    <sample id="209">Il metodo proposto offre diversi vantaggi rispetto al metodo di riferimento:

1. **Miglioramento della Qualità delle Script**: Implementa una tecnica di "over-generate-then-filter" che porta a script di qualità superiore, sia in termini di completezza semantica che di fedeltà ai vincoli.

2. **Riduzione dei Costi Computazionali**: Consente l'uso di modelli più piccoli e specializzati per il linguaggio pianificato, riducendo i costi associati ai grandi modelli linguistici.

3. **Creazione di un Dataset di Alta Qualità**: Genera un dataset, CoScript, di 55.000 specifici obiettivi con script, facilitando la ricerca su pianificazione linguistica con modelli più piccoli.

4. **Pluralismo e Varietà**: CoScript mostra una vasta gamma di obiettivi specifici, permettendo una pianificazione più flessibile e realistica.</sample>
    <sample id="210">Il nome della relatrice è Shuheng.</sample>
    <sample id="211">Sì, i risultati e il set di dati presentati nell'articolo possono essere utilizzati come parametri di riferimento per diversi motivi:

- **Valutazione di Metodi di Allineamento Automatico**: Il corpus DEPLAIN, con le sue coppie di frasi manualmente allineate, fornisce un "oro standard" per valutare l'accuratezza di metodi di allineamento automatico tra frasi di complessità simile nella stessa lingua.

- **Benchmark per la Semplificazione Automatica del Testo**: Gli autori hanno fine-regolato modelli linguistici (long-mBART e base mBART) per la semplificazione automatica del testo, ottenendo risultati migliori rispetto alla baseline. Questi risultati possono servire come benchmark per futuri studi nel campo.

- **Varietà di Semplificazioni**: Il corpus DEPLAIN mostra una vasta gamma di trasformazioni di semplificazione, il che lo rende utile per studiare diversi aspetti della semplificazione del testo, come la struttura, il vocabolario e il livello generale.

Questi aspetti rendono il set di dati DEPLAIN un riferimento prezioso per la ricerca e lo sviluppo di tecniche di semplificazione del testo in tedesco.</sample>
    <sample id="212">Nell'articolo, viene menzionato l'uso di **un modello più piccolo**, specificamente T5 fine-tuned su CoScript, per generare script di alta qualità.

Quindi, la risposta è **1**.</sample>
    <sample id="213">Il modello di base utilizzato per analizzare l'ottimizzazione delle istruzioni multimodali è OFA (Unified Multi-Modal Pre-trained Model).</sample>
    <sample id="215"># La struttura dipendente della coordinazione: un'argomentazione a favore della simmetria

L'intervento di Adam Przepiórkowski esplora le diverse strutture dipendenti assunte da varie teorie e approcci corpus-based nella coordinazione di frasi. Vengono confrontate due approcci asimmetrici, dove un congiunto è identificato come capo della struttura, con una prospettiva simmetrica che propone che tutti i congiunti abbiano un ruolo uguale.

L'argomentazione si basa sul principio di minimizzazione della lunghezza della dipendenza, che suggerisce che le relazioni grammaticali più brevi sono preferibili. Przepiórkowski analizza esempi in inglese, dimostrando che, sebbene la posizione diretta del complemento oggetto vicino al verbo sia ideale, ci sono eccezioni quando il complemento oggetto è lungo. In questi casi, la struttura può essere modificata per ridurre la lunghezza complessiva della dipendenza.

I dati estratti dall'Enhanced Penn Treebank confermano che i congiunti di sinistra tendono ad essere più corti, specialmente quando la differenza di lunghezza con il congiunto di destra è significativa. Tuttavia, questo effetto è osservato solo quando il governante è a sinistra o assente. Con il governante a destra, la preferenza per il congiunto di sinistra più corto scompare. Questi risultati supportano l'idea di una struttura simmetrica nella coordinazione e forniscono una critica agli approcci asimmetrici.

La ricerca suggerisce che la posizione del governante influenza la lunghezza preferita dei congiunti, offrendo una nuova prospettiva sulla comprensione della coordinazione nelle strutture grammaticali.</sample>
    <sample id="217">**Abstract:**

Il nostro studio, "Seen to Unseen: Exploring Compositional Generalization of Multi-Attribute Controllable Dialogue Generation", affronta le limitazioni dei metodi esistenti per la generazione di dialoghi controllabili, che spesso si concentrano su un solo attributo ignorando le situazioni del mondo reale con più attributi. Proponiamo DCG (Disentangled Controllable Generation), un modello che apprende concetti di attributi da valori visti utilizzando una perdita di disaccoppiamento per separare diverse combinazioni di attributi. Introdotti MAE (Multi-Attribute Evaluation), un framework di valutazione referenziale libero, per misurare la qualità del dialogo generato.

Abbiamo creato due benchmark per valutare l'efficacia del nostro approccio, dimostrando la superiorità del nostro modello DCG rispetto alle tecniche basate su DialoGPT. Abbiamo progettato due tipi di prompt: uno orientato all'attributo, che usa valori di attributi specifici come input, e uno orientato al compito, che integra caratteristiche globali. La combinazione di questi prompt migliora la capacità di generalizzazione del modello.

Il nostro lavoro risolve la sfida della generalizzazione composizionale per la generazione di dialoghi controllabili multi-attributo, dimostrando la capacità di trasformare attributi visti in combinazioni inavviste con un leggero calo nelle metriche di controllabilità. La valutazione automatica MAE supera le metriche umane sia per attributi discreti che continui, evidenziando l'efficacia del nostro metodo.

In sintesi, proponiamo un modello basato su prompt per la generazione di dialoghi controllabili multi-attributo, che consente una migliore comprensione e controllo delle conversazioni generative.</sample>
    <sample id="218">Gli autori dell'articolo "Prompting PaLM for Translation: Assessing Strategies and Performance" sono affiliati a Google Translate, come menzionato da David Vilar nel suo resoconto.</sample>
    <sample id="219"># **Uncovering Financial Signals: Unveiling a Multistage Pipeline for Financial Report Analysis**

La ricerca presentata si concentra sullo sviluppo di un approccio innovativo per estrarre segnali finanziari dai rapporti annuali delle società, in particolare dal Form 10-K richiesto dalla SEC. L'obiettivo è ridurre il pesante onere del lavoro umano necessario per analizzare questi documenti.

Lo studio si basa su due osservazioni chiave: la forte somiglianza testuale (circa l'80% degli token) tra rapporti annuali consecutivi e la necessità di confrontare e contrastare il contesto tra il rapporto di interesse e quello dell'anno precedente.

La proposta introduce un'attività di evidenziazione e una pipeline multistadio. La pipeline comprende la segmentazione del documento, il riconoscimento delle relazioni e due fasi di ottimizzazione fine. Durante la prima fase, i modelli classificano le coppie di segmenti in tre tipi: β (altamente simili), revisioni (simili sintatticamente ma con significati diversi) e coppie non corrispondenti (nuove informazioni).

Per l'ottimizzazione fine, viene utilizzato un dataset esterno, eSNLI, per l'addestramento fuori dominio, seguito da un addestramento intermedio con coppie di revisione e parole chiave come etichette pseudo-positive. Questa tecnica mista migliora la qualità delle etichette pseudo-positive.

I risultati dimostrano che il modello di evidenziazione adattivo al dominio ha ottenuto prestazioni eccellenti su entrambi i dataset di valutazione, eSNLI e FINAL, mostrando anche una buona generalizzazione. L'approccio ha il potenziale per migliorare l'estrazione di informazioni finanziarie da rapporti annuali, con ulteriori miglioramenti possibili attraverso tecniche avanzate di recupero delle informazioni.</sample>
    <sample id="220">Gli autori dell'articolo "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge" sono affiliati a Stony Brook University, come menzionato nella presentazione. In particolare, l'autrice principale è Vasudha, una PhD candidate in Computer Science presso la stessa università.</sample>
    <sample id="221">Nell'articolo "Prompting PaLM for Translation: Assessing Strategies and Performance", sono state analizzate principalmente coppie linguistiche formate da tedesco verso inglese (De-En) e altre coppie potrebbero essere menzionate in relazione ai dati di test utilizzati, ma l'enfasi principale è su De-En.</sample>
    <sample id="222"># **Adattamento e Annotazione per la Risposta a Domande in Dominio Aperto: Interventi e Scoperte**

Questo lavoro esplora le sfide e le soluzioni per il trasferimento di apprendimento nel campo della risposta a domande in dominio aperto (Open-Domain Question Answering, ODQA). L'obiettivo è migliorare la capacità dei modelli di rispondere a domini specifici, come il biomedicale, senza una formazione diretta su tali domini.

La ricerca inizia identificando un problema comune: quando si utilizza un corpus generale come Wikipedia per l'ODQA, i modelli possono faticare a discriminare tra domini diversi. Ad esempio, la domanda "Cosa viene prodotto nelle piante di Narora?" potrebbe portare a risposte errate se il modello non è addestrato su dati biomedicali.

Vengono proposti tre contributi principali:

1. **Interventi sui dati**: gli autori esplorano tecniche di pochi-shot e zero-shot learning per generare interventi sui dati. I pochi-shot utilizzano pochi esempi del nuovo dominio per guidare la generazione di più esempi, migliorando le prestazioni del retriever e del reader rispettivamente dell'8% e dell'11%.
2. **Comprensione del cambiamento di dominio**: classificano il cambiamento di dominio in "nessun cambiamento", "concept shift", "covariate shift" e "full shift" in base alla compatibilità tra il modello sorgente e il nuovo dominio.
3. **Interventi mirati**: scoprono che diversi tipi di interventi sono efficaci per domini specifici. I pochi-shot sono utili per la maggior parte dei domini, mentre i zero-shot sono più adatti per i concetti e i domini con covariate shift.

In sintesi, lo studio dimostra l'efficacia di specifici interventi sui dati per migliorare le prestazioni dell'ODQA in domini diversi, con un aumento massimo del 24% nella precisione della risposta.</sample>
    <sample id="223">Il nome del relatore è Shangbin.</sample>
    <sample id="224">Durante gli esperimenti, sono stati studiati due modelli principali:

1. **long-mBART**: Fine-tunnato per produrre simplificazioni a livello di documento.
2. **mBART (base)**: Fine-tunnato per produrre simplificazioni a livello di frase.

Entrambi i modelli hanno dimostrato risultati promettenti rispetto ai benchmark di base per la problematica dell'automatica semplificazione del testo.</sample>
    <sample id="225">Delle 62 attività in MultiInstruct, **53 attività da 9 gruppi sono utilizzate per l'addestramento** e **l'intero gruppo di ragionamento comune e 5 attività aggiuntive da "VQ" e "Miscellaneous" sono riservate per il test**.</sample>
    <sample id="226">Basandosi sul contenuto fornito, ci sono due autori coinvolti nell'articolo: Regina Stodden e Omar. Stodden introduce la presentazione e il concetto del corpus DEPLAIN, mentre Omar discute i casi d'uso specifici del dataset.</sample>
    <sample id="227">L'articolo discute la sfida della comprensione linguistica radicata (Grounded Language Understanding, GLU), un aspetto cruciale per applicazioni pratiche come assistenti virtuali, ricerca semantica e robotica. Gli autori sottolineano che la mancanza di grounding durante la pre-formazione rende difficile per i modelli linguistici mappare le espressioni naturali su rappresentazioni eseguibili in ambienti specifici, come query SQL o sequenze di azioni robotiche.

La ricerca attuale spesso si affida alla generazione di piani tramite decodifica autoregressiva, ma questo approccio può portare a piani non grammaticali o non validi. Per superare queste limitazioni, viene proposto un nuovo framework chiamato Pangu. Pangu separa il compito in due parti: un agente simbolico genera candidati piani e un modello linguistico valuta e classifica tali piani. Questo approccio evita al modello linguistico di dover gestire direttamente la validità grammaticale.

Gli autori hanno testato Pangu su un'ampia gamma di modelli linguistici (BERT, T5, Codex) e metodi di apprendimento (fine-tuning e in-context learning). I risultati dimostrano l'eccellente performance di Pangu, inclusa una notevole efficienza campionaria. L'analisi rivela che i modelli autoregressivi tendono all'overfitting strutturale, mentre Pangu mantiene una distribuzione di probabilità stabile sia per strutture viste che non viste, suggerendo una maggiore robustezza.

In conclusione, l'articolo sostiene che la discriminazione, piuttosto che la generazione, è una strategia più efficace per la GLU, aprendo nuove direzioni di ricerca per migliorare le capacità dei modelli linguistici in contesti pratici.</sample>
    <sample id="228">Gli autori hanno condotto esperimenti su quattro set di dati: AG News, MIND, SST2 e Enron Spam. Inoltre, hanno utilizzato il dataset Wiki Text per contare la frequenza delle parole.</sample>
    <sample id="229"># **Rilevamento di affermazioni migliorabili per il supporto alla scrittura argomentativa**

Questo studio si concentra sull'automatizzazione del processo di revisione del testo argomentativo, aiutando gli scrittori a ottimizzare le loro affermazioni. Gli autori, Gabriella Skitalinskaya e Henning Wachsmuth, propongono due compiti per affrontare questa sfida: il rilevamento di affermazioni subottimali e la suggerimento di miglioramenti.

L'approccio tradizionale è imparare dai modelli di revisione umana, ma questo studio esplora le complessità di tale metodologia, considerando le differenze di dominio e le varie percezioni della qualità. Si concentra sull'argomentazione testuale utilizzando piattaforme di dibattito online come Kialo per estrarre dati di revisione.

La ricerca identifica quattro sfide principali: rappresentatività e affidabilità dei dati, complessità del modello e architettura, dipendenza dal contesto e pregiudizi topici e degli utenti. Gli autori sperimentano con diversi modelli, esplorando l'impatto della pre-formazione, del fine-tuning e della classificazione finale.

I risultati dimostrano la fattibilità dell'utilizzo dei dati di revisione per valutare le affermazioni, con un'enfasi sulla distanza tra versioni di testo. Il contesto influenza la qualità dell'argomentazione, ma il suo impatto varia a seconda del compito e dei problemi specifici del testo.

Lo studio conclude che i dati di revisione possono essere una risorsa preziosa, ma richiede attenzione per gestire le sfide menzionate, offrendo una guida pratica per migliorare i sistemi di valutazione del testo argomentativo.</sample>
    <sample id="231">NACHOS è un dataset di dati medici crawlati dal web, utilizzato per pre-addestrare il modello DrBERT, il primo modello biomedico in francese.</sample>
    <sample id="232">Il nome del relatore è David Vilar.</sample>
    <sample id="233">**Abstract:**

Il paper "Attention as a Guide for Simultaneous Speech Translation" propone EDAtt (Encoder-Decoder Attention), un approccio innovativo per la traduzione simultanea della parola (SimulST) che evita la necessità di riaddestrare modelli offline o di architetture specifiche.

L'attuale SimulST richiede modelli complessi con procedure di addestramento lunghe, coinvolgendo diversi obiettivi ottimizzati e più modelli per diversi ritardi. EDAtt, invece, utilizza un unico modello per ogni regime di ritardo, gestendo la latenza attraverso parametri specifici.

Il metodo si basa sull'attenzione incrociata tra input audio e output testuale, permettendo al modello di decidere se emettere o meno una traduzione parziale in base alla concentrazione dell'attenzione. Una parola viene emessa solo se l'attenzione non è focalizzata su informazioni recenti, indicando una stabilità sufficiente dei dati ricevuti.

Gli autori hanno valutato EDAtt confrontandolo con strategie popolari applicate a modelli offline (Wait-k, Local Agreement) e con architetture specifiche per SimulST. I risultati dimostrano che EDAtt supera tutte le strategie, offrendo sia alta qualità di traduzione che la latenza più bassa, sia in termini assoluti che di tempo computazionale.

Il codice sorgente, i modelli e le traduzioni simultanee sono stati resi open source per favorire la riproducibilità del lavoro.</sample>
    <sample id="234">La strategia del prompting influisce significativamente sui risultati della traduzione con modelli di grandi dimensioni (LLM) come PaLM. Secondo la ricerca, la qualità degli esempi forniti al modello è più importante della somiglianza con la frase di origine. Un'attenta selezione di esempi di alta qualità dal dataset di addestramento può migliorare le prestazioni del modello.

L'esperimento condotto ha dimostrato che:
- Un prompting a 5-shot con marcatura delle lingue delle frasi ha prodotto risultati solidi, con una minima differenza nella forma del prompt.
- La differenza più evidente è stata osservata con prompting a una sola o zero shot, dove la scelta del prompt giusto può aumentare il punteggio BLEURT di oltre 40 punti.
- La qualità del prompt è cruciale per ottenere traduzioni accurate, mentre la forma del prompt ha un impatto minore quando si utilizzano più esempi.</sample>
    <sample id="235">Gli autori dell'articolo "When Does Translation Require Context?" sono affiliati alle seguenti istituzioni:

- Kayo Yin (non specificato l'affiliazione)
- Patrick Fernandes (non specificato l'affiliazione)
- Emmy Liu (non specificato l'affiliazione)
- André F. T. Martins (Università di Pittsburgh)
- Graham Neubig (Università della Pennsylvania)</sample>
    <sample id="236">Secondo la presentazione, ogni task nel dataset MultiInstruct è dotato di **cinque istruzioni scritte da esperti**. Queste istruzioni sono progettate per guidare il modello nella comprensione e nell'esecuzione di compiti multi-modali diversi.</sample>
    <sample id="237">Gli autori propongono il **KITMUS Test**, una suite di test diagnostici progettata per valutare la capacità dei modelli di integrare e utilizzare conoscenza da **due fonti**:

* **Conoscenza pre-addestrata (contenuta nei parametri del modello)**
* **Conoscenza fornita all'inferenza (nel contesto dell'input)**

Il test include un'attività di **risoluzione dei coreferenti** su un dataset specifico che varia la disponibilità di queste due tipologie di conoscenza.</sample>
    <sample id="238">**Abstract:**

Il video presenta il nuovo dataset di benchmark **MeetingBank**, sviluppato da Yebowen Hu dell'Università della Florida Centrale. Questo dataset mira a soddisfare la crescente necessità di tecnologie di sintesi testuale per domini di lettura diversi, in particolare per le riunioni.

MeetingBank contiene 1.366 riunioni del consiglio comunale e quasi 7.000 istanze di sintesi, raccolte da siti web pubblici. Il processo di raccolta dati utilizza l'API Speechmatics per la trascrizione audio e identifica informazioni chiave dalle pagine web delle riunioni per creare un ID di riunione univoco.

L'analisi delle statistiche del dataset rivela che le sintesi delle riunioni variano da città a città in termini di lunghezza, numero di parlanti e livello di astrazione. Le misure di copertura e densità sono utilizzate per valutare il grado di estrazione delle sintesi.

Sono state testate diverse tecniche di sintesi, tra cui sistemi estrattivi (Oracle, LEAD, LexRank, TextRank) e neurali astrattivi (BART-Large, Pagasus, Longformer, DialogLM, HMNet). I risultati mostrano che, mentre i sistemi estrattivi come Extr-Oracle eccellono nella fedeltà al testo sorgente, DialogLM, progettato per dialoghi lunghi, ottiene i punteggi ROUGE-2 più alti tra i modelli astrattivi.

L'analisi umana, basata su criteri come informatività, fattualità, fluidità e coerenza, evidenzia l'eccellenza di GPT-3 in fluidità e coerenza, ma con punteggi meno impressionanti in termini di informatività e fattualità.

In conclusione, MeetingBank offre una risorsa preziosa per la ricerca sulla sintesi delle riunioni e fornisce approfondimenti sul processo decisionale del consiglio comunale.</sample>
    <sample id="239">## Recensione del Paper: "Prompting PaLM per la Traduzione: Valutazione di Strategie e Prestazioni"

Ciao a tutti, mi chiamo David Vilar e vi presenterò una breve recensione del paper "Prompting PaLM for Translation: Assessing Strategies and Performance", un lavoro congiunto con i miei colleghi di Google Translate.

PaLM è un modello linguistico di grandi dimensioni, con 540 miliardi di parametri, presentato lo scorso anno nel 2022. All'epoca della pubblicazione, aveva raggiunto risultati di stato dell'arte in centinaia di compiti NLP grazie ad un addestramento su una vasta raccolta di testo, comprendente 780 miliardi di token.

In questo studio, presentiamo la prima analisi sistematica dell'utilizzo dei prompt per i grandi modelli linguistici (LLM) nella traduzione automatica. Abbiamo valutato la capacità di traduzione di questi modelli seguendo le migliori pratiche della comunità di traduzione automatica (MT). Ciò include l'utilizzo degli ultimi set di dati di test per evitare sovrapposizioni con i dati di addestramento del modello linguistico. Abbiamo confrontato i risultati con i sistemi di riferimento, come quelli della competizione WMT, utilizzando metriche neurali di traduzione automatica di stato dell'arte e, in aggiunta, presentiamo risultati di valutazione umana basati su un'analisi di esperti.

Infine, forniamo alcune raccomandazioni per le strategie di selezione dei prompt. Come dimostrato da un semplice esperimento, il prompt ha un impatto significativo sulle prestazioni degli LLM per la traduzione. Utilizzando un prompt a una sola riga per frase, abbiamo osservato differenze di oltre un punto BLEU in 516 su 1000 frasi. In casi estremi, la differenza può raggiungere i 40 punti BLEU.

Nei nostri esperimenti, abbiamo optato per una strategia di 5-shot prompting, dove ogni frase fornita al sistema è contrassegnata con la lingua di appartenenza. I risultati mostrano che la forma del prompt ha un'influenza minore con prompt brevi, mentre è cruciale per i prompt a una e zero shot. Con 5 shot, la forma del prompt ha un impatto quasi nullo, sono gli esempi a determinare la maggior parte del peso.

In sintesi, i nostri risultati sperimentali dimostrano che la qualità degli esempi è più importante della somiglianza con la frase sorgente. Pertanto, è fondamentale selezionare esempi da traduzioni di alta qualità.

Abbiamo confrontato la selezione di prompt dal dataset di addestramento con i dati di valutazione WMT, che sono più curati e di qualità superiore rispetto al dataset di addestramento. I risultati mostrano prestazioni migliori utilizzando i dati di valutazione. Tuttavia, i sistemi specializzati di stato dell'arte hanno ancora un vantaggio significativo rispetto alle traduzioni di PaLM. PaLM, tuttavia, si avvicina molto a un sistema commerciale.

Nella nostra valutazione, abbiamo confrontato PaLM con Google Translate. L'analisi umana, condotta utilizzando il framework MQM, ha rivelato che la fluidità di PaLM è paragonabile a quella dei sistemi di riferimento, ma la differenza principale risiede nell'accuratezza. In particolare, gli errori più comuni sono quelli di omissione, suggerendo che PaLM, a volte, omette parti della frase sorgente per produrre una traduzione più "suonante". La categoria "Stile/Imbarazzante" per PaLM è inferiore rispetto ai sistemi di riferimento, confermando ulteriormente la fluidità del suo output, ma con problemi di accuratezza.

In conclusione, questa è una breve panoramica del paper. Per ulteriori dettagli, vi invito a consultare la presentazione completa del lavoro. Grazie!</sample>
    <sample id="240">## Presentazione: "Più deboli di quanto si pensi: un'analisi critica dell'apprendimento con supervisione debole"

**Introduzione**

Salve, sono Dawei, dottorando presso l'Università del Saarland in Germania. In questo video, vorrei presentarvi il nostro recente lavoro intitolato *"Più deboli di quanto si pensi: un'analisi critica dell'apprendimento con supervisione debole"*, realizzato in collaborazione con Xiaoyu Shen, Marius Mosbach, Andreas Stephan e Dietrich Klakow.

Iniziamo con una breve introduzione alla supervisione debole e all'apprendimento con supervisione debole. Nella supervisione debole, non si etichettano manualmente i dati. Al contrario, etichettiamo i dati utilizzando fonti di etichettatura deboli, come semplici regole heuristiche, basi di conoscenza o crowdsourcing di bassa qualità, come illustrato nella figura a destra. Rispetto alle annotazioni umane, le annotazioni deboli sono più economiche, ma anche rumorose, il che significa che una certa percentuale di esse è errata. Se addestriamo direttamente le reti neurali sui dati etichettati debolmente, tendono a memorizzare il rumore delle etichette e non generalizzano.

Nell'apprendimento con supervisione debole, sono stati proposti algoritmi di addestramento per addestrare in modo robusto le reti neurali in presenza di tale rumore di etichette, in modo che i modelli addestrati generalizzino ancora bene.

**Un'osservazione sulla letteratura WSL**

Recentemente, in ambito WSL (apprendimento con supervisione debole), è comune affermare che è possibile addestrare modelli solo sui dati etichettati debolmente e ottenere ottime prestazioni su set di test puliti. Tecnicamente, questa affermazione non è errata, ma c'è un aspetto cruciale spesso trascurato: si presuppone che sia disponibile un set di validazione pulito aggiuntivo per la selezione del modello. Non possiamo fermarci a questo problema, ma implica che siano necessarie ulteriori annotazioni manuali nell'apprendimento con supervisione debole.

**Le nostre domande di ricerca**

La nostra ricerca si pone tre domande fondamentali:

1. **È necessario un set di validazione pulito per l'WSL?** Possiamo utilizzare un set di validazione rumoroso al suo posto?
2. **Se un set di dati pulito è richiesto (o obbligatorio) per l'WSL, quanti campioni puliti sono necessari?**
3. **Dovremmo utilizzare solo i campioni puliti per la validazione o esistono metodi migliori?**

**I nostri risultati**

Le nostre scoperte sono le seguenti:

* **Necessità di dati puliti:** Inaspettatamente, abbiamo scoperto che i metodi WSL recenti richiedono effettivamente campioni puliti per funzionare correttamente. In assenza di campioni puliti, si verifica un calo significativo delle prestazioni, come mostrato nella figura. Ciò indica che gli approcci WSL dipendono effettivamente dai dati etichettati correttamente e il costo di annotazione per ottenere campioni puliti non dovrebbe essere sottovalutato.

* **Aumento dei campioni puliti:** Aumentare il numero di campioni puliti aiuta gli approcci WSL a raggiungere prestazioni migliori, come mostrato nella figura a sinistra. Solitamente, sono necessari circa 20 campioni per classe per ottenere prestazioni elevate. Tuttavia, se si decide di utilizzare campioni puliti, l'addestramento diretto su di essi produce risultati ancora migliori, come illustrato nella figura a destra.

* **Semplice fine-tuning:** Il miglioramento delle prestazioni pubblicizzato dagli approcci WSL può essere facilmente ottenuto permettendo la continuazione dell'addestramento sui campioni di validazione puliti. Come si può osservare, il modello di base, chiamato FTw, inizialmente sotto-performa rispetto a metodi WSL più complessi come COSINE. Tuttavia, permettendo il fine-tuning continuo sui campioni puliti, FTw raggiunge prestazioni comparabili. Quindi, in pratica, non c'è motivo di scegliere metodi WSL più complessi che richiedono più tempo di calcolo e spazio di archiviazione.

**Conclusioni**

In sintesi, abbiamo dimostrato che gli approcci WSL recenti richiedono campioni etichettati manualmente puliti per funzionare correttamente. Il loro vantaggio in termini di prestazioni e praticità è stato sovrastimato.

**Raccomandazioni per il futuro**

Per il futuro, suggeriamo:

*  Rispettare la trasparenza riportando i criteri di selezione del modello, ad esempio se la selezione è basata su campioni puliti.
*  Confrontare gli approcci WSL con le basi di apprendimento a pochi shot, poiché entrambi lavorano con campioni puliti.
*  Considerare il fine-tuning continuo come una semplice ma potente base per futuri lavori WSL.
*  Abbiamo reso open-source il nostro codice, disponibile tramite il codice QR in questa presentazione. Speriamo che lo proviate!

Grazie e buon congresso!</sample>
    <sample id="241">**Abstract:**

Il paper "Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments" esplora un approccio innovativo per la rilevazione precoce della disinformazione sui social media, concentrandosi in particolare sui trattamenti COVID-19. Gli autori, Ethan e il suo team di ricerca, identificano due principali lacune nei metodi attuali: la valutazione irrealistica e la mancanza di coinvolgimento umano.

Il lavoro propone un framework di valutazione che integra i feedback umani in tutto il processo di rilevamento della disinformazione, creando un sistema end-to-end. Questo sistema comprende due componenti principali:

1. **Rilevamento di affermazioni fuorvianti:** Utilizza un modello T5 per estrarre affermazioni potenzialmente false da tweet, classificandole per popolarità e fornendole a moderatori umani per la verifica.
2. **Verifica delle violazioni delle politiche:** Un modello BERT identifica le posizioni degli autori a favore di trattamenti non approvati, segnalando potenziali violazioni delle politiche di Twitter.

La valutazione si concentra sull'individuazione precoce della disinformazione, definendola come il rilevamento di trattamenti non approvati prima che appaiano in articoli di smentita. I risultati mostrano che il sistema rileva con successo il 65% delle violazioni delle politiche e gestisce 124,2 violazioni per ora di lavoro umana.

Questo studio offre una prospettiva unica sullo sviluppo e la valutazione dei sistemi di rilevamento della disinformazione, evidenziando l'importanza dell'interazione uomo-macchina e fornendo una guida per future ricerche in questo campo.</sample>
    <sample id="242">I metodi comuni di valutazione per i sistemi di dialogo includono:

1. **Valutazione umana con scale di Likert**: Chiedere a giudici umani di valutare la qualità delle conversazioni utilizzando scale di Likert o confronti diretti.
2. **Valutazione comparativa**: Richiedere ai giudici di scegliere quale conversazione è migliore tra due opzioni.
3. **Valutazione di comportamenti specifici**: Annotare esplicitamente comportamenti specifici dei modelli di dialogo, come rispondere con informazioni irrilevanti, contraddirsi o violare la logica comune. Questo approccio è noto come ABC-Eval.

ABC-Eval si distingue per la sua precisione e affidabilità nel misurare vari aspetti della qualità del dialogo, come suggerito dalla letteratura recente.</sample>
    <sample id="243">L'articolo menziona la collaborazione di 4 autori: Jenny (la presentatrice), Sebastian Santy, Ronan Le Bras e Katharina Reinecke. Inoltre, menziona Maarten Sap, quindi in totale sono coinvolti 5 autori.</sample>
    <sample id="244">Nell'esempio, le conoscenze di base necessarie per risolvere correttamente la coreferenza includono:

1. **Entità specifiche**: "Servin è un giudice" e "Kea è un panettiere".
2. **Conoscenza di sfondo**: "I giudici decidono casi nei tribunali di legge".

Queste due tipologie di conoscenza sono fondamentali per determinare che il pronome "he" si riferisce a Servin.</sample>
    <sample id="245"># **A Needle in a Haystack: Un approccio per identificare lavoratori di alta qualità su Amazon Mechanical Turk (MTurk)**

Questo studio presenta un metodo innovativo per selezionare lavoratori di alta qualità su MTurk per compiti di riassunto testuale, affrontando le sfide associate alle metriche automatiche e alle pratiche di reclutamento.

La ricerca propone un pipeline a due fasi per identificare i lavoratori più affidabili. Nella prima fase, i lavoratori sono valutati sulla loro capacità di giudicare correttamente più dimensioni in un compito di qualificazione. Questo filtro iniziale separa i lavoratori in quattro categorie, con solo i "Gold" e "Silver" che avanzano. La seconda fase testa la capacità di gestione del carico di lavoro con un compito di "endurance" che include 10 HIT (Human Intelligence Tasks).

I risultati dimostrano che i lavoratori identificati dal pipeline raggiungono un'elevata inter-annotatore accordo (IAA) e prestazioni comparabili agli esperti. Un'analisi di un compito di riferimento rivela che 8 lavoratori su 12 completano con successo tutti gli HIT, con un alto IAA e Krippendorff's Alpha di 0,534.

Vengono confrontati diversi approcci, inclusi i lavoratori di base MTurk filtrati statisticamente e i lavoratori CloudResearch. Lo studio evidenzia che il pipeline può ottenere risultati di alta qualità con un minor costo e un'efficienza superiore, pur riconoscendo alcune limitazioni, come la specificità per l'inglese e la natura non universale delle domande di qualificazione.</sample>
    <sample id="246">Sì, il codice è disponibile. Puoi trovarlo su GitHub.</sample>
    <sample id="247">**Abstract: FACTKG: Fact Verification via Reasoning on Knowledge Graphs**

Il paper presenta FACTKG, un nuovo dataset e un approccio per la verifica dei fatti basato su ragionamento su grafici di conoscenza (KG). Esiste una carenza di dataset che utilizzano i KG come evidenza per le affermazioni in linguaggio naturale, rispetto a quelli basati su testo o tabelle.

FACTKG introduce la verifica dei fatti basata su KG, offrendo un metodo più affidabile e pratico. Il grafico di conoscenza DBpedia è utilizzato per raccogliere dati, con affermazioni in due stili: scritto e colloquiale. Le affermazioni sono etichettate come "supportate" o "refutate" e il compito richiede di recuperare le evidenze da DBpedia e verificarle.

Il sistema di verifica utilizza cinque tipi di ragionamento: uno-hop (un singolo tripla), congiunzione (multipli tripla collegati), esistenza (verifica di una relazione specifica), multi-hop (ragionamento a più salti) e negazione (verifica aggiuntiva dopo aver trovato evidenze).

Il dataset include anche modelli di trasferimento per affermazioni colloquiali e template di presupposizione per una maggiore varietà.

Sono stati sviluppati due metodi di baseline: uno che utilizza solo le affermazioni e un altro che impiega il modello GEAR per integrare le evidenze del KG. I risultati dimostrano che l'utilizzo delle evidenze del KG migliora significativamente la precisione della verifica dei fatti, raggiungendo il 74% rispetto al 51% della baseline.

Il dataset FACTKG è disponibile per scarico e ulteriori ricerche.</sample>
    <sample id="248">No, gli annotatori per NLPositionality non sono necessariamente bilanciati rispetto a ciascun gruppo demografico. Lo studio ha ricorso a un'ampia gamma di volontari da 87 paesi, ma ha rilevato che i modelli e i dataset tendono ad allinearsi maggiormente con gli utenti di lingua inglese e con coloro che hanno un'istruzione universitaria. Sono state osservate anche disparità per quanto riguarda le identità non binarie, che sono meno rappresentate rispetto agli uomini e alle donne.</sample>
    <sample id="249">Le frasi nel dominio accettabile sono state perturbate preservando la struttura rilevante ma aggiungendo rumore al testo. Questo processo ha coinvolto diverse modifiche per analizzare la sensibilità del modello a variazioni minime nella sintassi e nella semantica.</sample>
    <sample id="250">Avere una valutazione dimensionale significa analizzare e valutare le prestazioni di un modello di conversazione AI (come un chatbot) in più aspetti specifici e misurabili, piuttosto che solo con una valutazione generale.

Invece di un singolo punteggio, si utilizzano vari parametri o "dimensioni" per esaminare diversi aspetti della qualità della conversazione, come:

* **Relevanza delle risposte:** Se le risposte del modello sono pertinenti al contesto della conversazione.
* **Coerenza:** Se le risposte del modello sono logiche e coerenti tra loro.
* **Contradizioni:** Se il modello si contraddice o contraddice l'utente.
* **Irrelevanza:** Se il modello fornisce informazioni non pertinenti.
* **Hallucination:** Se il modello inventa informazioni inesatte.
* **Empatia:** Se il modello mostra comprensione ed empatia verso l'utente.

Questo approccio più dettagliato consente di identificare i punti di forza e di debolezza di un modello e di confrontare modelli diversi in modo più preciso.</sample>
    <sample id="251">Gli autori dell'articolo sono affiliati all'Università di Scienza e Tecnologia della Cina (USTC).</sample>
    <sample id="252">**Abstract:**

La presentazione introduce U-CREAT, un approccio innovativo per il recupero di casi precedenti non supervisionato, sviluppato da un team di ricercatori dell'IIT Kanpur. Il problema del recupero di casi precedenti (PCR) è cruciale per i professionisti del diritto, che devono citare precedenti pertinenti in modo efficiente. Il lavoro propone due contributi significativi: il dataset IL-PCR (Indian Legal Prior Case Retrieval) e la pipeline U-CREAT.

Il dataset IL-PCR è una risorsa completa per il PCR, contenente 7.070 casi legali indiani con un numero medio di citazioni per documento. Questo dataset supera i precedenti set di dati, come COLIEE'21, per dimensioni e complessità. L'U-CREAT adotta un approccio basato su eventi, estraendo tripletti soggetto-verbo-oggetto dai documenti legali per rappresentare la narrazione dei casi.

La pipeline U-CREAT utilizza tecniche di apprendimento non supervisionato, dimostrando un'elevata efficienza di recupero e tempi di inferenza rapidi. Il modello è in grado di generalizzare tra sistemi legali indiani e canadesi senza richiedere tuning specifico. Gli esperimenti confrontano vari modelli, inclusi quelli basati su conteggio, transformer e eventi, con l'Event Filtered Documents che si rivela il più performante.

Rispetto ai metodi esistenti, U-CREAT supera le prestazioni, incluso un recente approccio supervisionato, come dimostrato sui set di dati COLIEE. Questo lavoro apre nuove prospettive per il PCR, offrendo un approccio scalabile e adattabile per la gestione di grandi quantità di casi legali.</sample>
    <sample id="253"># **DisorBERT: Rilevamento dei Segni di Disturbi Mentali sui Social Media**

Questo studio presenta DisorBERT, un modello innovativo per il rilevamento di disturbi mentali sui social media, basato su un approccio di adattamento di dominio doppio. I ricercatori affrontano la sfida di identificare i segni di problemi di salute mentale nelle pubblicazioni online, offrendo un supporto potenzialmente prezioso per la prevenzione e il trattamento.

L'intervento si concentra sull'adattamento del modello BERT, un noto modello linguistico, al dominio specifico dei post sui social media e dei disturbi mentali. Questo processo consente al modello di acquisire un vocabolario e una comprensione semantica più pertinenti, migliorando le sue prestazioni. L'integrazione di informazioni da Reddit e da un lexicon mentale guida il processo di mascheramento, incoraggiando il modello a concentrarsi su parole chiave significative.

I risultati sperimentali utilizzando il dataset eRisk dimostrano l'efficacia di DisorBERT. Il modello raggiunge un buon equilibrio tra precisione e richiamo, superando altri approcci. L'analisi delle risposte del modello a frasi mascherate rivela che DisorBERT è in grado di identificare termini associati a disturbi mentali, come "pessimismo" e "guilt", mentre BERT tende a generare risposte più generiche.

La ricerca evidenzia anche l'utilità della visualizzazione testuale per comprendere le sequenze di parole chiave, fornendo approfondimenti sui temi rilevanti per la salute mentale. In conclusione, DisorBERT dimostra un potenziale significativo nel rilevamento precoce dei disturbi mentali sui social media, con risultati promettenti per future applicazioni cliniche.</sample>
    <sample id="254">**Abstract:**

La ricerca presentata, "Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction", affronta le sfide associate all'estrazione di relazioni da documenti utilizzando dati distanti supervisionati (DS). I metodi tradizionali richiedono grandi quantità di dati annotati manualmente, rendendoli inefficienti. Gli studi recenti hanno sfruttato i dati DS per pre-addestrare modelli, ma persistono problemi di rumore a causa delle etichette pseudo.

L'articolo introduce un framework innovativo per migliorare la qualità delle etichette DS. In primo luogo, addestra un modello pre-denoising DocRE utilizzando dati DS e annotazioni umane per generare etichette pseudo. Successivamente, implementa una stima dell'incertezza per identificare le previsioni potenzialmente errate. Per gestire le relazioni sovrapposte tra entità, propone un metodo di stima dell'incertezza a livello di istanza.

La chiave del loro approccio è l'utilizzo del Monte Carlo dropout per modellare l'incertezza nel modello DocRE. Modificano il processo di stima per ottenere punteggi di incertezza per ogni etichetta pseudo, tenendo conto delle differenze tra le classi. Introdurre soglie di incertezza dinamiche aiuta a filtrare le etichette pseudo ad alta incertezza. Un algoritmo di ri-etichettatura iterativa migliora ulteriormente le prestazioni.

I risultati sperimentali dimostrano l'efficacia del framework su set di dati pubblici, superando i metodi precedenti. I contributi principali includono un framework con denoising guidato dall'incertezza, un metodo di stima per relazioni sovrapposte, una strategia di ri-etichettatura dinamica e miglioramenti significativi nelle prestazioni di estrazione delle relazioni documentali.</sample>
    <sample id="255">La forma del prompting si rivela importante principalmente nei casi di **zero-shot e one-shot prompting**. In questi scenari, la qualità e la precisione del prompt iniziale possono avere un impatto significativo sulla qualità della traduzione.

Per prompt più lunghi, come il 5-shot prompting utilizzato nello studio, la **forma del prompt** diventa meno critica rispetto alla **qualità degli esempi forniti**. Gli esempi di alta qualità, selezionati dal set di dati di addestramento o da dati di valutazione curati, sono fondamentali per ottenere buoni risultati.</sample>
    <sample id="257">Gli autori hanno valutato quattro modelli di dialogo di stato dell'arte.

Non hanno specificato i nomi dei modelli, ma hanno menzionato che sono stati selezionati tra i modelli più avanzati disponibili al momento della pubblicazione della ricerca.</sample>
    <sample id="258">**Abstract:**

Il video presenta una ricerca innovativa intitolata "Can Large Language Models Be an Alternative to Human Evaluation?" che esplora l'uso di modelli linguistici di grandi dimensioni (LLM) per valutare la qualità del testo in elaborazione del linguaggio naturale (NLP). Gli autori propongono un approccio in cui gli LLM ricevono istruzioni specifiche e campioni da valutare, imitando il processo di valutazione umana.

La motivazione alla base di questo studio è la stabilità e la riproducibilità limitate delle valutazioni umane. Gli autori si chiedono se esistano alternative che possano raggiungere gli stessi obiettivi senza le criticità associate alla valutazione umana.

L'esperimento coinvolge la valutazione di storie generate da GPT-2 o scritte da umani, utilizzando quattro attributi: grammatica, coerenza, piacevolezza e rilevanza. Gli LLM, istruiti con istruzioni in linguaggio naturale, forniscono valutazioni che vengono poi confrontate con valutazioni umane ottenute da insegnanti di inglese.

I risultati mostrano che alcuni LLM, in particolare Davinci e ChatGPT, preferiscono le storie scritte da umani rispetto a quelle generate da GPT-2. Questo suggerisce che determinati LLM possono sostituire efficacemente la valutazione umana in alcuni compiti NLP.

La ricerca risponde a diverse domande, tra cui il livello di accordo tra LLM e valutatori umani, l'impatto di variazioni nelle istruzioni e nei metodi di campionamento, i vantaggi e gli svantaggi rispetto alla valutazione umana, e le potenziali applicazioni su altri compiti NLP. Gli autori invitano gli interessati a consultare il loro articolo completo o a visitare il loro stand al conferimento ACL.</sample>
    <sample id="259"># **XSemPLR: Un benchmark unificato per la parsing semantica multilingue**

La ricerca si concentra sullo sviluppo di XSemPLR, un framework innovativo per la parsing semantica multilingue che mira a colmare le lacune nelle attuali modelli esistenti. La parsing semantica è il processo di conversione di query naturali in rappresentazioni semantiche, come SQL o Lambda Calculus.

Il lavoro introduce XSemPLR, un dataset completo che include 9 dataset in vari domini, 5 compiti di parsing semantico e 8 rappresentazioni semantiche, coprendo 22 lingue naturali in 15 famiglie linguistiche. Gli autori propongono sei impostazioni di valutazione per testare diversi approcci: Translate-Test, Monolingual, Monolingual Few-shot, Multilingual, Cross-lingual Zero-shot e Few-shot transfer.

Attraverso esperimenti su modelli Encoder-PTR e Encoder-Decoder multilingue, viene dimostrata l'efficacia di XSemPLR. I risultati evidenziano che i modelli Encoder-Decoder ottengono le migliori prestazioni su tutti i dataset. La valutazione del trasferimento cross-lingue rivela che il gap di prestazioni tra impostazioni zero-shot e few-shot si riduce significativamente. Lo studio sottolinea anche la necessità di modelli multilingue più avanzati, poiché i modelli come Codex e BLOOM mostrano limitazioni nelle attività di parsing semantico multilingue.

In sintesi, XSemPLR fornisce una piattaforma standardizzata per la ricerca futura, consentendo una valutazione approfondita dei modelli di parsing semantico multilingue e delle loro capacità in vari contesti linguistici e rappresentazioni semantiche.</sample>
    <sample id="260">Basandomi sul testo fornito, l'articolo è stato scritto da un solo autore, Jingwei Yi, che rappresenta l'Università di Scienza e Tecnologia della Cina. Non menziona altri autori coinvolti.</sample>
    <sample id="261">Un buon pianificatore ideale dovrebbe possedere le seguenti qualità:

1. **Semantica Completa:** Generare script che siano grammaticalmente corretti e sensati.
2. **Fede ai Vincoli:** Assicurarsi che gli script generati rispettino fedelmente i vincoli specifici imposti sui goals.
3. **Flessibilità:** Gestire efficacemente diversi tipi di vincoli, come quelli presenti in varie categorie di argomenti (ad esempio, ricette).
4. **Qualità Consistente:** Ridurre la varianza nelle prestazioni, evitando output di scarsa qualità.
5. **Efficienza:** Essere in grado di utilizzare modelli più piccoli e specializzati, riducendo i costi computazionali.</sample>
    <sample id="262">L'articolo "Distilling Script Knowledge from Large Language Models for Constrained Language Planning" coinvolge più autori, ma il numero esatto non è specificato nel testo fornito. Si fa riferimento al lavoro di un team che include ricercatori da Fudan University, suggerendo che ci sia almeno un autore principale e un gruppo di collaboratori.</sample>
    <sample id="263"># Mitigazione dei pregiudizi di etichettatura per l'apprendimento in-context

Questo lavoro di ricerca si concentra sulla stabilizzazione dell'apprendimento in-context, un approccio popolare per l'utilizzo di grandi modelli linguistici. Gli autori identificano e affrontano i problemi di instabilità derivanti da scelte di progettazione variabili, come l'ordine degli esempi in-context.

La ricerca introduce una tassonomia dei pregiudizi di etichettatura, rivelando un nuovo tipo significativo: il *domain-label bias*. Questo pregiudizio descrive l'impatto del corpus di testo del compito sulla predizione del modello. Gli esperimenti dimostrano che il corpus del compito può influenzare le scelte del modello, con effetti variabili a seconda del dataset.

Per affrontare questi pregiudizi, viene proposta la tecnica di *domain-context calibration*. Questo metodo utilizza testi quasi privi di contenuto, come parole casuali del dominio del compito, per stimare e mitigare i pregiudizi su ogni etichetta. Si discosta dai metodi precedenti che utilizzano token predefiniti, dimostrando miglioramenti significativi nell'accuratezza dell'apprendimento in-context.

Gli studi approfonditi rivelano che la sostituzione dei token predefiniti con parole casuali inglesi e, successivamente, con parole casuali del dominio, migliora ulteriormente l'efficacia della calibrazione. Questo approccio olistico migliora le prestazioni dei modelli linguistici su vari dataset, soprattutto in quelli con un elevato *domain-label bias*. La ricerca fornisce una comprensione approfondita dei pregiudizi nell'apprendimento in-context e offre una soluzione pratica per migliorare la stabilità e l'accuratezza.</sample>
    <sample id="264"># **TAVT: Un approccio innovativo per la generazione audio-visiva di testo**

La ricerca si concentra sulla sfida della generazione di testo multimodale, in particolare nella creazione di descrizioni audio-visive trasferibili, dove i dati annotati sono scarsi e costosi. L'autore propone il compito di *Transferable Audio-Visual Text Generation (TAVT)* per affrontare le sfide poste dai cambiamenti di dominio in vari contesti.

Il TAVT mira a sviluppare un modello in grado di adattarsi rapidamente a nuovi domini multimodali con dati etichettati limitati. La soluzione proposta include un framework modulare con tre componenti chiave: un *audio-visual meta-mapper network*, un *audio-visual encoder* e un *language model generator*. Il meta-mapper crea uno spazio semantico audio unificato, mappando concetti visivi attraverso domini. Utilizzando cluster di audio e token appresi, il modello allinea i contenuti visivi a uno spazio audio.

Il secondo componente, l'encoder e il generator basati su transformer, introduce un coefficiente α per valutare il contributo di ogni modalità alla generazione del testo. Il *Dual Counterfactual Contrastive Learning (DCLL)* ottimizza direttamente l'allineamento visivo-testuale senza affidarsi a campioni negativi casuali.

Gli esperimenti su benchmark come MSVD e MSR-VTT dimostrano l'efficacia del TAVT, superando i metodi esistenti in vari scenari. Il modello gestisce bene anche domini a bassa risorsa, mostrando il potenziale per la generazione di testo audio-visiva trasferibile e adattabile. L'abstract sottolinea il contributo della ricerca nel superare le barriere dei dati annotati limitati in questo campo.</sample>
    <sample id="265">Il nome della relatrice è Vasudha.</sample>
    <sample id="266">Sulla base del contenuto presentato, l'autore principale, Adam Przepiórkowski, sembra essere affiliato con un'istituzione o un gruppo di ricerca che ha lavorato sull'analisi del linguaggio naturale e la grammatica computazionale, come suggerito dal riferimento alla "enhanced version of the Penn Treebank" e alla "Why wouldn't you use universal dependencies". Tuttavia, l'affiliazione specifica non è menzionata direttamente nel testo fornito.</sample>
    <sample id="268">Secondo la presentazione di David Vilar, gli errori più comuni di PaLM (un modello linguistico di grandi dimensioni) nella traduzione sono **omissioni**. PaLM a volte omette parti del testo di origine durante la traduzione, scegliendo di produrre un testo che suona meglio, ma con una minore accuratezza.</sample>
    <sample id="269">Salve, io sono James Finch. E questa è Sarah Finch. Oggi vi parleremo di ABC-Eval, un nuovo approccio dimensionale per valutare l'Intelligenza Artificiale Conversazionale. Questo lavoro è stato condotto dal laboratorio NLP di Emory, guidato dal professore Jinho Choi presso l'Università di Emory, in collaborazione con Amazon Alexa AI.

Immaginiamo di aver sviluppato un modello di dialogo e vogliamo capire come si posiziona rispetto agli standard attuali. La pratica comune è quella di utilizzare la valutazione umana, come chiedere a giudici umani di scegliere quale conversazione sia migliore o di valutare le conversazioni su una scala di Likert. Questi metodi funzionano bene per fornire una valutazione olistica della qualità del dialogo, ma la qualità del dialogo ha molte sfaccettature. Quindi, potresti voler valutare più dimensioni della qualità della chat per comprendere i punti di forza e di debolezza del modello a un livello più dettagliato.

Un approccio potrebbe essere semplicemente chiedere ai giudici umani di valutare diverse dimensioni della qualità del dialogo, utilizzando metodi comparativi esistenti o scale di Likert. Tuttavia, crediamo che ci sia una strategia più precisa e affidabile per la valutazione dimensionale del dialogo. Il nostro approccio mira a ridurre la soggettività della valutazione umana annotando esplicitamente se o meno ogni risposta del modello esprime determinati comportamenti, come fornire informazioni irrilevanti o contraddirsi. Chiamiamo questo approccio "annotazione dei comportamenti nel dialogo" o, più brevemente, ABC-Eval. Abbiamo sviluppato questo metodo per coprire in modo completo i comportamenti dei modelli di chat che, secondo la letteratura recente, influenzano la qualità del dialogo.

ABC-Eval è in grado di misurare le percentuali di vari tipi di errori tematici commessi dai modelli di chat. Ad esempio, misura il numero di turni in cui un modello di chat ignora il suo partner o fornisce informazioni irrilevanti, si contraddice o viola le conoscenze comuni e quando il modello mostra o non mostra empatia.

Per determinare il metodo di valutazione più efficace, abbiamo selezionato quattro modelli di chat all'avanguardia e ne abbiamo valutati 100 dialoghi umani-bot per modello utilizzando ABC-Eval. Per confronto, abbiamo valutato anche questi dialoghi utilizzando tre metodi esistenti: valutazioni su scala di Likert a livello di turno, valutazioni su scala di Likert a livello di dialogo e confronti dialogici a coppie. Per ciascuno di questi metodi, abbiamo raccolto valutazioni su otto aspetti più comunemente misurati del dialogo, poiché questa è la pratica standard per valutare i modelli di chat su più dimensioni.

Dall'analisi dei risultati di queste valutazioni, abbiamo scoperto che le etichette comportamentali di ABC-Eval sono complessivamente più affidabili rispetto alle etichette raccolte dai metodi esistenti, come dimostrato dall'accordo inter-annotatori su 100 conversazioni etichettate in doppio. Inoltre, le etichette di ABC-Eval sono più predittive della qualità complessiva della conversazione, come mostrato da questo semplice analisi di regressione lineare. Ad esempio, potete vedere come la percentuale di turni con contraddizioni tra sé e il partner spiega il 5% e il 10% della qualità della conversazione, mentre le medie delle valutazioni di coerenza su scala di Likert spiegano solo il 4% o meno.

Infine, abbiamo verificato se ogni metrica di valutazione catturasse un aspetto unico della qualità del dialogo utilizzando una regressione lineare passo-passo. Potete vedere come la combinazione di tutte le metriche di ABC-Eval spiega oltre il 25% della qualità della conversazione, e rimuovendo una alla volta queste metriche, la maggior parte di esse perde una quantità significativa di informazioni sulla qualità. Al contrario, la combinazione di tutte le metriche di Likert a livello di turno spiega molto meno della qualità e meno di queste metriche contengono informazioni uniche.

Queste metriche di valutazione ABC-Eval affidabili, informative e distinte consentono di valutare l'Intelligenza Artificiale Conversazionale con una risoluzione superiore rispetto ai metodi precedenti. Come potete vedere dai risultati del nostro esperimento, rimangono ancora diverse sfide da affrontare, quantificate con precisione. Ad esempio, i bot che abbiamo testato presentano violazioni di senso comune nel 20% delle loro risposte, forniscono informazioni irrilevanti nel 15% e si contraddicono o contraddicono il loro partner nel 10% delle volte. Con il rapido miglioramento del campo, molte di queste percentuali di errore potrebbero diminuire nei nuovi modelli rilasciati dopo la nostra valutazione. Tuttavia, questo è proprio il motivo per cui è importante perseguire metriche di valutazione affidabili e precise per confrontare i modelli. Speriamo che ABC-Eval possa essere sfruttato da altri nel campo come un passo significativo in questa direzione, e non vediamo l'ora di vedere come l'Intelligenza Artificiale Conversazionale evolverà nei prossimi mesi e anni. Grazie per aver guardato.</sample>
    <sample id="270">Gli autori dell'articolo, James Finch e Sarah Finch, descrivono il loro lavoro sviluppato presso l'Emory NLP Lab, guidato dal Professor Jinho Choi presso Emory University, in collaborazione con Amazon Alexa AI.</sample>
    <sample id="271">Nel contesto dell'articolo "Weaker Than You Think: A Critical Look at Weakly Supervised Learning", CFT sta per "Fine-tuning (o Raffinamento) Continuo" (in inglese, *Continuous Fine-tuning*). Si riferisce alla pratica di continuare ad addestrare un modello su dati puliti (manualmente etichettati) dopo la fase iniziale di addestramento su dati debolmente etichettati.</sample>
    <sample id="272">L'articolo è il risultato di un lavoro congiunto con 7 autori: Koustav Sinha, John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy e Adina Williams.</sample>
    <sample id="273">## Presentazione: "Quando la Traduzione Richiede Contesto? Un'Esplorazione Multilingue Basata sui Dati"

Salve, mi chiamo Kayo Yin e presenterò il nostro lavoro intitolato "Quando la Traduzione Richiede Contesto? Un'Esplorazione Multilingue Basata sui Dati", realizzato in collaborazione con Patrick Fernandes, Emmy Liu, André F. T. Martins e Graham Neubig.

Molte traduzioni dipendono dal contesto. Prendiamo ad esempio la parola "mole": nel contesto "Le cose potrebbero diventare pericolose se i ministri lo scoprono", "mole" si riferisce a uno spionaggio. Invece, in "Potrebbe essere qualcosa di serio, dottore?", "mole" indica una macchia di nascita. Il significato della parola cambia quindi a seconda del contesto, e di conseguenza anche la traduzione.

Tuttavia, valutare quanto bene i modelli gestiscono queste situazioni è complesso. Innanzitutto, solo una piccola percentuale delle traduzioni dipende dal contesto, rendendo difficili da catturare le metriche corpus-based come BLEU. Alcuni hanno proposto valutazioni mirate sulle traduzioni context-dependent, ma queste risorse supportano solo tipi limitati di traduzioni e lingue, poiché spesso si basano su conoscenze di dominio e sulla cura umana.

Nel nostro lavoro, cerchiamo di rispondere a due domande: 1) Quando la traduzione richiede contesto? 2) Quanto bene i modelli gestiscono questi casi?

Per rispondere alla prima domanda, abbiamo misurato quanto una parola dipende dal contesto durante la traduzione. Nel precedente lavoro, abbiamo introdotto CXMI (Context eXtraction Measure for Machine Translation) per valutare l'uso del contesto da parte dei modelli di traduzione automatica, misurando l'informazione fornita dal contesto C sulla traduzione target Y, data la fonte X. Potete pensare a CXMI come all'informazione guadagnata fornendo contesto al modello.

In questo studio, estendiamo CXMI a Pointwise CXMI, che consente di misurare l'uso del contesto a livello di frase o di parola. Le parole con alto P-CXMI richiedono contesto per la traduzione. Analizziamo quindi le parole con alto P-CXMI per individuare schemi e scopriamo che:

* Alcune parti del discorso con alto P-CXMI includono pronomi duali in arabo, poiché l'inglese non li ha, rendendo necessario il contesto per la traduzione.
* Alcune lingue richiedono contesto per scegliere la forma verbale appropriata.
* In cinese, il contesto è cruciale per tradurre correttamente i nomi propri per mantenere la coerenza all'interno del documento.
* Il contesto è importante anche per tradurre con la forma giusta di formalità.
* Infine, alcuni fenomeni sono espressi nella struttura della frase, come la risoluzione delle ellissi, che non possono essere catturati solo dalla parola stessa.

Utilizzando queste scoperte, abbiamo progettato un benchmark per la traduzione documentale. Per ogni fenomeno discorsivo identificato, abbiamo creato tagger automatizzati (il Multilingual Discourse-Aware, o MuDA tagger) per identificare le parole coinvolte.

Abbiamo notato che diverse lingue presentano diverse proporzioni di questi fenomeni discorsivi. Utilizzando il MuDA tagger e metriche di traduzione scelte, abbiamo valutato diversi modelli su esempi context-dependent identificati dal tagger.

Utilizzando il benchmark MuDA, insieme ad altre metriche, abbiamo scoperto che:

* Le metriche corpus-level come BLEU mostrano prestazioni migliori per i modelli context-agnostici.
* COMET, una metrica context-aware, offre le migliori prestazioni.
* La metrica word f-measure mostra prestazioni comparabili per modelli con e senza contesto.

Questo evidenzia la difficoltà nel determinare il miglior sistema di traduzione documentale basandosi solo su metriche corpus-level.

Confrontando diversi sistemi commerciali, il nostro benchmark mostra che DeepL è generalmente più preciso di Google Translate nella traduzione documentale.

In conclusione, abbiamo condotto un'analisi basata sui dati su 14 coppie di lingue per identificare quando la traduzione richiede contesto e utilizzato i risultati per creare un benchmark per la traduzione documentale che aiuta a capire quali fenomeni discorsivi i modelli gestiscono meglio e quali sistemi di traduzione eccellono nella traduzione documentale.

Grazie per l'attenzione. A Toronto ci vediamo presto!</sample>
    <sample id="274">Il nome della relatrice è Yusen Zhang.</sample>
    <sample id="276">**Abstract:**

Il nostro lavoro, "IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation Metrics for Indian Languages", si concentra sulla valutazione delle metriche di traduzione automatica (MT) per le lingue indiane, un'area sottostimata nella ricerca attuale. Abbiamo creato un dataset basato su 7.000 campioni tradotti da cinque lingue indiane (Tamil, Malayalam, Hindi, Marathi e Gujarati) utilizzando sette diversi sistemi di traduzione.

I bilingui esperti hanno annotato ogni traduzione identificando errori di accuratezza, significato, fluidità e specifiche sottocategorie. Abbiamo analizzato la correlazione tra le metriche di traduzione standard (come BLEU, chrF, BERTscore) e i punteggi MQM (Metric for Quality of Machine Translation) umani.

I risultati mostrano che le metriche basate su embedding, in particolare LabSE e BERTscore, e quelle basate su COMET hanno le correlazioni più elevate con i punteggi MQM. Tuttavia, molti metrici mostrano una distribuzione dei punteggi ristretta, rendendo difficile l'interpretazione.

Abbiamo fine-regolato la metrica COMET utilizzando il nostro dataset MQM, ottenendo IndicCOMET MQM, che ha superato le versioni di base di COMET in tre lingue su cinque. Infine, abbiamo testato la robustezza di IndicCOMET MQM su set di sfida di accuratezza di traduzione, dimostrando una correlazione più alta (0.36) rispetto a COMET (0.272).

Il nostro dataset e i risultati forniscono una base solida per la meta-valutazione delle metriche di MT per le lingue indiane, promuovendo lo sviluppo di sistemi di traduzione più accurati e affidabili.</sample>
    <sample id="277">Il nuovo metodo non ha un nome specifico menzionato nel testo. Gli autori si riferiscono semplicemente a esso come "un neural seq2seq model che direttamente modella le corrispondenze tra frammenti dell'input e frammenti dell'output" e "metodo per prevedere la permutazione".</sample>
    <sample id="278">L'autrice descrive il metodo "Parole Contrassegnate" come un approccio che identifica le parole che distinguono i gruppi marcati da quelli non marcati, utilizzando il concetto sociolinguistico di "markedness" (marcatura). Questo metodo consente di rivelare stereotipi e narrazioni essenzialiste nascosti in descrizioni apparentemente positive, mostrando come termini come "cultura", "tradizione" e "resilienza" contribuiscano a perpetuare pregiudizi e stereotipi contro gruppi specifici.</sample>
    <sample id="279">Gli autori dell'articolo "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models" sono affiliati all'Università di Washington, in particolare come PhD student.</sample>
    <sample id="280">**Abstract:**

Il lavoro "MultiEMO: Un Framework di Fusione Multimodale Correlazione-Consapevole Basato sull'Attenzione per il Riconoscimento delle Emozioni nelle Conversazioni" affronta le sfide nel riconoscimento delle emozioni nelle conversazioni (ERC), proponendo un innovativo approccio chiamato MultiEMO. L'obiettivo è prevedere l'etichetta emotiva di ogni enunciato in un dialogo, considerando testi, audio e visivo.

MultiEMO introduce quattro contributi chiave:

1. **VisExtNet**: Un estraitore di caratteristiche visive che integra le espressioni facciali di più fotogrammi, riducendo l'informazione redundante dello scenario.
2. **MultiAttn**: Un modello di fusione multimodale basato su attenzione bidirezionale multi-testa, che integra efficacemente le informazioni da testo, audio e visivo.
3. **Sample-Weighted Focal Contrast Loss**: Una perdita che enfatizza le classi minoritarie e le emozioni semanticamente simili, migliorando la loro classificazione.
4. **Prestazioni di Stato dell'Arte**: MultiEMO ha ottenuto risultati eccellenti sui dataset MELD e IEMOCAP, superando le sfide nelle classi minoritarie e simili semanticamente.

Il paper illustra in dettaglio ogni componente, evidenziando i vantaggi di MultiEMO rispetto ai metodi esistenti. Nonostante alcune limitazioni, come la mancanza di distinzione tra speaker e persone irrilevanti, MultiEMO rappresenta un significativo passo avanti nel campo del riconoscimento delle emozioni nelle conversazioni.</sample>
    <sample id="281"># **Quando la Traduzione Richiede Contesto: Un'Esplorazione Multilingue Basata sui Dati**

La presentazione si concentra sull'importanza del contesto nella traduzione automatica e su come valutare le prestazioni dei modelli in tali casi. L'indagine, condotta da un team di ricercatori, mira a rispondere a due domande cruciali: quando la traduzione richiede contesto e come i modelli gestiscono queste sfide.

Gli autori introducono e estendono il concetto di CXMI (Contextual Information Measure) per valutare l'uso del contesto nei modelli di traduzione. Il nuovo approccio, chiamato Pointwise CXMI, consente di analizzare il contesto a livello di frase o parola. Lo studio esamina le parole con alto P-CXMI in trascrizioni di TED Talks tradotte in 14 lingue diverse.

I risultati rivelano modelli complessi: alcune lingue richiedono contesto per pronomi duali o forme verbali appropriate, mentre altre necessitano di contesto per la corretta traduzione di nomi propri e livelli di formalità. L'analisi identifica cinque fenomeni discorsivi chiave.

In seguito, i ricercatori sviluppano un tagger multilingue, MuDA, per identificare automaticamente le parole associate a questi fenomeni. Questo strumento consente la creazione di un benchmark per la traduzione documentale. La valutazione dei modelli utilizzando metriche come BLEU, COMET e word f-measure mostra che le prestazioni variano a seconda del fenomeno e della metrica scelta.

Il benchmark MuDA si rivela prezioso per distinguere i modelli a consapevolezza contestuale da quelli non contestuali, evidenziando aree in cui la traduzione automatica richiede ulteriori miglioramenti. Lo studio conclude suggerendo che una combinazione di metriche corpus-level e specifiche per il contesto è fondamentale per valutare accuratamente i sistemi di traduzione documentale.</sample>
    <sample id="282">**Abstract: StoryTrans - Trasferimento di Stile Narrativo a Livello di Racconto**

Il nostro studio, presentato all'ACL 2023, introduce *StoryTrans*, un modello innovativo per il trasferimento non parallelo di stile testuale, concentrandosi sul livello di racconto e sulla rappresentazione del discorso. Affronta le sfide di imitare le scelte linguistiche complesse degli autori, specialmente nelle strutture narrative e nei temi specifici dello stile.

*StoryTrans* apprende rappresentazioni del discorso dai testi sorgente e le combina con embedding di stile appresi per generare testi in stili target. Il modello utilizza un nuovo obiettivo di addestramento per ridurre le caratteristiche stilistiche nelle rappresentazioni del discorso, avvicinandole nello spazio latente. Inoltre, per migliorare la conservazione del contenuto, la generazione è divisa in due fasi. La prima fase trasferisce il testo sorgente con parole chiave specifiche dello stile mascherate, mentre la seconda fase riempie i contenuti mancanti mantenendo la coerenza narrativa.

Abbiamo condotto esperimenti su dataset cinesi ed inglesi, dimostrando l'efficacia di *StoryTrans* nel controllo dello stile e nella conservazione del contenuto. I risultati automatici e le valutazioni manuali superano i baseline. Il modello può inserire frasi coerenti per arricchire le trame, mantenendo i significati originali. *StoryTrans* si distingue per la capacità di riscrivere le frasi con lo stile target preservando i semantemi originali, offrendo un approccio avanzato al trasferimento di stile narrativo.</sample>
    <sample id="283">La prima struttura di dipendenza simmetrica menzionata è quella **del Prague Dependency Treebanks**, che include il nome della città **Praga**.</sample>
    <sample id="284">**Abstract: FSUIE: Un approccio innovativo per il miglioramento dell'estrazione universale di informazioni (UIE)**

La ricerca presentata, condotta da Peng Tianshuo di Wuhan University, introduce FSUIE, un meccanismo di span fuzzy per migliorare le prestazioni dei modelli UIE basati su span. Gli attuali modelli UIE identificano e etichettano le delimitazioni degli obiettivi nei testi, ma la precisione di queste etichette è soggetta a ambiguità. Lo studio propone di modellare le delimitazioni degli span in modo fuzzy, piuttosto che preciso, per gestire questa incertezza.

FSUIE affronta due sfide principali. Innanzitutto, introduce una perdita di span fuzzy che considera una distribuzione continua di probabilità per le delimitazioni, riducendo la dipendenza dai confini di span annotati. In secondo luogo, propone un'attenzione di span adattiva, chiamata Fuzzy Span Attention (FSA), per modellare la distribuzione di attenzione durante l'estrazione degli span. FSA dinamicamente regola la gamma di attenzione e decresce linearmente l'attenzione ai confini, migliorando la flessibilità.

La metodologia è stata testata su tre compiti UIE: riconoscimento di entità nominate (NER), estrazione di relazioni (RE) e estrazione di triplette di sentimenti di aspetti (ASTE). FSUIE ha ottenuto risultati eccezionali, superando i modelli di base senza il meccanismo fuzzy. In particolare, ha dimostrato una maggiore efficacia con set di dati più piccoli e ha raggiunto nuovi picchi di prestazioni in RE e ASTE, dimostrando la sua capacità di generalizzare in domini specifici.

In sintesi, FSUIE offre un approccio promettente per migliorare l'estrazione di informazioni, riducendo la dipendenza dai confini degli span e adattando dinamicamente l'attenzione del modello.</sample>
    <sample id="285"># **Reference Matters: Un'Analisi Critica degli Approcci alla Correzione degli Errori Fattuali nella Sintesi del Dialogo**

La ricerca presentata si concentra sulla sfida della correzione degli errori fattuali nelle sintesi del dialogo, un problema critico ma spesso trascurato nel campo della sintesi del testo. Gli autori propongono un nuovo approccio per valutare e migliorare i modelli di correzione degli errori fattuali (FEC) specifici per la sintesi del dialogo.

L'articolo evidenzia le carenze nelle attuali metriche di valutazione FEC, che forniscono punteggi vaghi e non affidabili. Per affrontare questo problema, introducono una tassonomia dettagliata degli errori fattuali, suddivisa in categorie basate sul contenuto e sulla forma. Questa tassonomia è fondamentale per un sistema di valutazione più completo.

La loro soluzione chiave è un framework di valutazione basato su ERRANT, che coinvolge l'allineamento, la classificazione e il confronto. Attraverso esperimenti, dimostrano che l'addestramento dei modelli FEC con riassunti di dialogo annotati manualmente porta a risultati migliori rispetto all'uso di metriche fattuali solite. Questo suggerisce che l'addestramento con dati corretti da parte di umani è cruciale per migliorare le prestazioni dei modelli FEC.

Inoltre, gli autori sottolineano la necessità di combinare dati sintetici e annotati manualmente, e identificano le limitazioni attuali dei modelli FEC nel gestire errori complessi, come quelli di aggiunta, attributo, modalità e collegamento. Questo lavoro offre una guida significativa per lo sviluppo futuro di sistemi di sintesi del dialogo più affidabili.</sample>
    <sample id="286">Il nome della relatrice è **Sarah Finch** e quello del relatore è **James Finch**.</sample>
    <sample id="287">L'articolo è il risultato di un lavoro congiunto di **4** autori: Javad Hosseini, Filip Radlinski, Silvia Pareti e Annie Louis.</sample>
    <sample id="288">Secondo la presentazione, i seguenti insiemi di dati possono essere utilizzati per testare i fenomeni sintattici:

1. **BLiMP (Bilingual Language Model Performance)**: Utilizzato per valutare la grammaticalità e l'accettabilità delle frasi.
2. **SyntaxGym**: Un altro dataset menzionato per valutare la sintassi e l'accettabilità delle frasi.
3. **Wikipedia**: Utilizzato per testare la robustezza delle valutazioni MPP (Minimal Pair Paradigm) in contesti completamente irrilevanti rispetto ai dati di addestramento.
4. **Insiemi di dati specifici per fenomeni sintattici**: Come quelli estratti da BLiMP o SyntaxGym, utilizzati per creare frasi con strutture grammaticali corrispondenti o non corrispondenti per valutare l'impatto del contesto.</sample>
    <sample id="290">Le abbreviazioni dei cinque metodi per la prima domanda di ricerca, come menzionato nella presentazione, sono:

1. **FTw (Vanilla Model)**: Il modello di base che inizialmente sottoperforma ma può raggiungere risultati equivali con la continuazione del fine-tuning sui campioni puliti.
2. **COSINE**: Un metodo WSL più complesso che richiede più tempo di calcolo e spazio su disco.

Le altre tre domande di ricerca non hanno specificato abbreviazioni durante la presentazione, ma si riferiscono ai concetti generali di utilizzare o non utilizzare dati di validazione puliti e alla quantità necessaria di tali dati.</sample>
    <sample id="291">Il modello DrBERT viene valutato su 11 attività downstream nel dominio biomedico e clinico in francese, tra cui:

- Riconoscimento di entità nominate
- Classificazione
- Etichettatura delle parti del discorso
- Domande e risposte</sample>
    <sample id="294">CamemBERT viene inizialmente addestrato su un set di dati di 4 GB estratto da NACHOS (un dataset di dati medici web-crawled in francese).</sample>
    <sample id="295">Il nome della relatrice è Adam Przepiórkowski.</sample>
    <sample id="296"># **Indagine sull'Ironia nel Linguaggio Naturale: Un Approccio Perspectivistico**

La ricerca presentata si concentra sull'esplorazione della comprensione dell'ironia nel linguaggio naturale, un aspetto complesso e sfuggente per i modelli di elaborazione del linguaggio naturale (NLP). Gli autori, in collaborazione con Amazon Alexa, hanno affrontato la sfida di migliorare la rilevazione dell'ironia andando oltre i tradizionali approcci basati su dati supervisionati.

Il progetto ha coinvolto la creazione di un corpus di dati, chiamato EPIC (English Perspectivist Irony Corpus), raccogliendo conversazioni brevi da social media come Reddit e Twitter. Il corpus include 300 conversazioni in cinque varietà di inglese, annotate da 74 annotatori utilizzando una piattaforma di crowdsourcing. Ogni annotatore ha valutato 200 testi, fornendo fino a 5 annotazioni per conversazione.

L'analisi ha rivelato variazioni interessanti nelle annotazioni in base a fattori demografici. Gli autori hanno sviluppato modelli "perspectivistici" addestrando un modello di linguaggio pre-addestrato su sottoinsiemi di dati specifici per ogni annotatore. Questi modelli hanno mostrato una maggiore sicurezza nelle previsioni rispetto ai modelli standard.

Uno studio più approfondito dei dati ha rivelato che le differenze nelle annotazioni sono più pronunciate tra generazioni e regioni geografiche vicine. I risultati suggeriscono che la percezione dell'ironia può variare notevolmente tra gruppi demografici, evidenziando la complessità di questo fenomeno nel linguaggio naturale. La ricerca apre nuove prospettive per migliorare i sistemi NLP nella comprensione dell'ironia e del contesto pragmatico.</sample>
    <sample id="297">**Abstract**

Il nostro studio, "From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models", esplora l'uso di termini codificati, o "dogwhistles", nella retorica politica, con particolare attenzione al loro ruolo nell'evitare la moderazione dei contenuti online e nella diffusione di discorsi d'odio. I dogwhistles sono parole o frasi che trasmettono un messaggio nascosto a un gruppo interno mentre sembrano indirizzarsi a un gruppo esterno, spesso con connotazioni anti-semite, razziste o transofobiche.

Abbiamo creato un glossario di oltre 340 termini, raccolti da varie fonti, per catalogare e comprendere diversi tipi di dogwhistles. Attraverso un'analisi di discorsi politici storici negli Stati Uniti, abbiamo riscontrato una correlazione tra l'uso di dogwhistles e strategie politiche conservatrici, specialmente dopo l'era dei diritti civili.

Abbiamo poi testato la capacità di modelli linguistici, come GPT-3, di identificare e riconoscere i dogwhistles. I risultati mostrano che, mentre GPT-3 può individuare molti dogwhistles formali, le sue prestazioni diminuiscono con i termini informali e quelli specifici di gruppi minoritari.

Infine, abbiamo dimostrato come i dogwhistles possano aggirare i sistemi di rilevamento della tossicità online. Sostituendo slur e etichette di gruppo con dogwhistles, le frasi hateful ricevono valutazioni meno severe, evidenziando la necessità di strumenti più sofisticati per contrastare la retorica di odio nascosta.</sample>
    <sample id="298">La conclusione che la deriva temporale è la causa principale della perdita di prestazioni è stata raggiunta attraverso due osservazioni chiave:

1. **Analisi del grafico**: Un grafico mostrato durante la presentazione indicava che il miglioramento delle prestazioni su CoNLL++ non seguiva una curva di diminuzione, escludendo così l'adaptive overfitting.

2. **Esperimento di ritrainamento**: Un esperimento in cui alcuni modelli sono stati ritrenati o continuati con dati più recenti ha dimostrato che le prestazioni degradano con l'aumentare del gap temporale, confermando l'ipotesi di deriva temporale.</sample>
    <sample id="299"># **Migliorare la robustezza dei modelli NLI con l'addestramento minimax**

Questo studio si concentra sulla mitigazione delle vulnerabilità dei modelli di comprensione del linguaggio naturale (NLI) alle scorciatoie apprese dai dati, migliorando la loro robustezza fuori distribuzione. Gli autori, Michalis Korakakis e Andreas Vlachos, identificano il problema delle scorciatoie, correlazioni spure tra attributi di input e etichette nei dataset NLI, che portano a prestazioni eccellenti in-distribution ma a una scarsa resistenza agli attacchi fuori distribuzione.

La soluzione proposta è un metodo di addestramento minimax, che coinvolge due modelli: un *learner* e un *auxiliary*. L'obiettivo è ridurre la dipendenza del *learner* dalle scorciatoie. Il *learner* cerca di minimizzare l'errore NLI, mentre il *auxiliary* mira a massimizzare la perdita del *learner* generando pesi di esempio che lo incoraggiano a concentrarsi su esempi difficili, meno influenzati dalle scorciatoie. Questo processo dinamico consente al *learner* di apprendere da esempi sottorappresentati e contrastanti.

La ricerca dimostra l'efficacia di questo approccio in tre dataset analitici e nei loro test fuori distribuzione. Rispetto ai metodi tradizionali, il metodo minimax migliora la performance fuori distribuzione mantenendo alta l'accuratezza in-distribution. Gli autori esplorano anche l'impatto delle dimensioni del modello e dell'auxiliary, e forniscono una valutazione qualitativa dei pesi di esempio appresi. Il lavoro evidenzia un potenziale approccio promettente per migliorare la robustezza dei modelli NLI.</sample>
    <sample id="300">**Abstract**

Il lavoro presentato introduce l'interattiva dettatura, un processo che consente agli utenti di dettare e modificare documenti tramite voce in modo naturale e intuitivo. A differenza dei sistemi di riconoscimento vocale esistenti, che supportano solo la dettatura o comandi vocali predefiniti, l'interattiva dettatura permette di correggere e modificare il testo durante la registrazione.

L'approccio proposto comprende quattro passaggi: riconoscimento del parlato, segmentazione in dettatura e comandi, normalizzazione dei comandi e esecuzione sequenziale. È stata sviluppata una nuova interfaccia per la raccolta dei dati, che include sia dettatura che comandi vocali.

Gli autori hanno creato un dataset e un sistema di base per l'interattiva dettatura. Hanno sperimentato due modelli di intelligenza artificiale, T5 e GPT-3, per ogni componente del sistema, trovando un compromesso tra velocità e precisione. I risultati indicano che i modelli GPT-3 sono più precisi ma più lenti, mentre la previsione di programmi intermedi migliora l'efficienza del modello T5.

Il lavoro si conclude con la disponibilità del codice sorgente e del dataset per incoraggiare ulteriori ricerche su questo nuovo e promettente campo. L'obiettivo è sviluppare interfacce di dettatura più naturali e flessibili, che possano migliorare significativamente l'esperienza utente.</sample>
    <sample id="302">I token di output devono essere permutati perché, dopo la prima fase di tagging, sono presenti in un ordine non deterministico. La permutazione li ordina correttamente per riflettere le corrispondenze sistematiche tra input e output, che sono fondamentali per la comprensione semantica.</sample>
    <sample id="303">Gli autori hanno suggerito ai proprietari dei modelli di aumentare la trasparenza sui metodi di mitigazione dei bias perché ritengono che sia essenziale per comprendere le possibili cause di stereotipi e narrazioni essenzializzanti che emergono dai modelli linguistici. Senza una maggiore trasparenza, è difficile distinguere se questi risultati siano dovuti a un valore di allineamento eccessivo o ad altri metodi di mitigazione dei bias che potrebbero involontariamente produrre effetti dannosi.</sample>
    <sample id="304">Gli input inaccettabili di coppia minima (Minimal Pair Acceptability Judgments o MPP) sono un metodo di valutazione dei modelli linguistici che confronta la probabilità assegnata da un modello a frasi grammaticali e non grammaticali. Questo approccio simula sequenze più lunghe per valutare la capacità del modello di riconoscere l'accettabilità linguistica in contesti estesi, un aspetto cruciale per i modelli linguistici moderni con grandi finestre di contesto.</sample>
    <sample id="305">**Abstract:**

Il video presenta la ricerca "Weaker Than You Think: A Critical Look at Weakly Supervised Learning" da parte di Dawei e colleghi. La ricerca esamina le sfide e le limitazioni degli approcci di apprendimento supervisionato debole (WSL), dove i dati non sono etichettati manualmente ma attraverso fonti deboli come regole heuristiche o crowdsourcing di bassa qualità.

Gli autori mettono in luce un'assunzione comune nel WSL: l'uso di dati puliti per la selezione del modello. Tuttavia, evidenziano che questa pratica richiede ulteriori etichettature manuali, spesso trascurate. La loro ricerca risponde a tre domande chiave: 1) è necessario un set di dati di validazione pulito per il WSL? 2) Quanti campioni puliti sono necessari? 3) È preferibile utilizzare solo campioni puliti per la validazione?

Attraverso esperimenti, dimostrano che i metodi WSL attuali dipendono dai dati puliti per un'adeguata generalizzazione. Inoltre, aumentare il numero di campioni puliti migliora le prestazioni. Sorprendentemente, il fine-tuning diretto sui campioni puliti supera spesso i metodi WSL, anche con un numero limitato di campioni (10 per classe).

La ricerca conclude che le prestazioni e la praticità del WSL sono sovrastimate. Suggeriscono che i futuri lavori WSL dovrebbero: 1) riportare i criteri di selezione del modello, 2) confrontarsi con i baselines di apprendimento a poche riprese, 3) considerare il fine-tuning continuo come baseline, e 4) condividere il codice open-source per una maggiore trasparenza.</sample>
    <sample id="306">**Abstract**

Sebastian Schuster e Najoung Kim presentano il loro lavoro sull'Entity Tracking in Language Models, esplorando la capacità degli agenti di comprendere l'evoluzione degli stati delle entità durante un discorso. Il loro obiettivo è valutare fino a che punto i grandi modelli linguistici possono tracciare gli stati delle entità in contesti complessi.

La sfida principale risiede nel distinguere tra capacità genuine di tracciamento e semplici associazioni heuristiche o memorizzazione. Per superare queste difficoltà, gli autori hanno progettato un compito che coinvolge scatole e oggetti, con descrizioni iniziali e operazioni di stato che cambiano. Questo compito impedisce ai modelli di affidarsi a scorciatoie come la semplice copia o l'applicazione di slot filling.

I risultati mostrano che solo modelli come text-davinci-003 mostrano una vera capacità di tracciamento, mentre altri modelli, indipendentemente dalle loro dimensioni, non superano una baseline casuale. L'analisi rivela che la pre-formazione su codice sembra essere un fattore chiave per l'emergere di questa capacità nei modelli GPT-3.5.

L'importanza della pre-formazione è ulteriormente evidenziata dal fatto che i modelli inizialmente casuali non imparano il tracciamento anche con la supervisione diretta. Il lavoro conclude sottolineando la necessità di ulteriori ricerche per comprendere la generalizzabilità di queste abilità al di fuori del contesto specifico del loro studio.</sample>
    <sample id="307">Gli autori hanno utilizzato diverse metriche di valutazione per i loro modelli, tra cui:

1. **Precisione (Accuracy)** per compiti di classificazione.
2. **F1-score** per compiti di riconoscimento di entità nominate e altre attività di elaborazione del linguaggio naturale (NLP).
3. **BLEU score** e **ROUGE score** per compiti di generazione di testo e question answering.
4. **Part-of-speech tagging** accuratezza per il compito di etichettatura delle parti del discorso.

Hanno confrontato le prestazioni di questi modelli su 11 compiti biomedicali e clinici in francese, utilizzando dati pubblici e privati.</sample>
    <sample id="308">**Abstract**

Il lavoro presentato, NLPositionality, esplora le bias di progettazione insite nei dataset e nei modelli di Natural Language Processing (NLP), evidenziando come le prospettive (positionality) dei ricercatori e sviluppatori influenzino la tecnologia. Gli autori dimostrano che, sebbene i modelli e i dataset non abbiano identità demografiche o esperienze di vita, aggregano giudizi e opinioni di persone reali, riflettendo così determinate positioni.

Attraverso un'analisi su larga scala di oltre 16.000 annotazioni da 1000 annotatori di 87 paesi, il progetto NLPositionality rivela che i dataset e i modelli mostrano una preferenza per gli utenti di paesi anglofoni e con istruzione universitaria. Ad esempio, GPT-4 e Dynahate (per il rilevamento di odio e linguaggio tossico) sono più allineati con queste popolazioni.

Tuttavia, questa allineamento lascia indietro altre comunità, come le persone non binarie, evidenziando una bias sistematica. Per affrontare queste disparità, gli autori propongono tre strategie: documentare tutte le scelte di progettazione, condurre ricerche NLP con una prospettiva inclusiva e sviluppare dataset e modelli specializzati per comunità specifiche, come l'iniziativa Masakhani.

Il lavoro sottolinea l'importanza di riconoscere e mitigare le bias di progettazione per creare tecnologie NLP più eque e inclusive.</sample>
    <sample id="309">La metrica utilizzata per misurare l'accordo tra annotatori è stata l'inter-annotatore agreement, applicata a 100 conversazioni doppiamente annotate.</sample>
    <sample id="310">Il dominio scelto per aggiungere frasi completamente scollegate alle query inaccettabili e accettabili è **Wikipedia**.</sample>
    <sample id="311">Basandoci sul contenuto fornito, gli autori dell'articolo sembrano essere affiliati con le seguenti istituzioni:

- Regina Stodden: Non specificata direttamente, ma sembra essere coinvolta nella presentazione e nella ricerca descritta.
- Omar (nome non specificato completamente): Menzionato come presentatore per la sezione sull'uso dei casi del dataset DEPLAIN.

L'enfasi è sulla creazione e valutazione del corpus DEPLAIN per la semplificazione del testo in tedesco, suggerendo che gli autori siano ricercatori o membri di un team di ricerca in un'istituzione accademica o un centro di ricerca linguistica.</sample>
    <sample id="312">MultiInstruct si distingue dagli altri dataset di riferimento per diversi motivi chiave:

1. **Focus Multi-Modale**: Mentre la maggior parte dei lavori precedenti si è concentrata su compiti linguistici a zero-shot, MultiInstruct è il primo dataset di istruzione multi-modale che esplora il miglioramento dell'apprendimento zero-shot per compiti multi-modali.

2. **Disponibilità Limitata dei Dati**: Esiste una carenza di dataset di istruzione multi-modale di grandi dimensioni e pubblici. MultiInstruct risolve questo problema creando un dataset di 62 compiti multi-modali diversificati, coprendo 10 categorie ampie.

3. **Unificazione dei Formati**: Il dataset unifica la rappresentazione di input e output di vari tipi di dati, come testo, immagini, istruzioni e bounding box, in uno spazio token comune.

4. **Metrica Sensibilità**: Introdurre la metrica "sensibilità" per misurare la coerenza delle uscite del modello per istruzioni leggermente variabili, un aspetto non comunemente considerato.

5. **Scalabilità**: MultiInstruct è in fase di espansione con l'aggiunta di circa 150 ulteriori compiti vision-linguaggio, dimostrando l'impegno nella crescita e nell'accessibilità del dataset.</sample>
    <sample id="313">Due autori sono coinvolti nell'articolo: James Finch e Sarah Finch.</sample>
    <sample id="314">La coordinazione binaria si riferisce alla struttura grammaticale in cui due elementi, spesso frasi o clausole, sono collegati e hanno lo stesso peso sintattico. In questo contesto, Adam Przepiórkowski discute diverse teorie sulla struttura di dipendenza nella coordinazione binaria, evidenziando come alcune teorie la trattino in modo asimmetrico, con un congiunto che funge da "testa" della struttura, mentre altre propongono strutture simmetriche dove tutti i congiunti hanno un ruolo uguale.</sample>
    <sample id="315">Secondo la presentazione, i prompt utilizzati nello studio "Marked Personas" sono stati in uso per generare le persone **dopo l'addestramento dei modelli di linguaggio**. Non viene specificato un tempo esatto in termini di durata, ma l'enfasi è posta sulla **fase di generazione** che segue l'addestramento, che può variare a seconda del modello e delle specifiche esigenze del test.</sample>
    <sample id="316">I risultati suggeriscono che un modello T5 più piccolo, fine-tunato su CoScript (il dataset generato dai grandi modelli), può generare script di qualità superiore rispetto alla maggior parte dei grandi modelli linguistici. Questo indica che modelli più piccoli e specializzati possono eccellere nella pianificazione linguistica vincolata quando addestrati su dataset adeguati.</sample>
    <sample id="317"># **CodeIE: Ottimizzazione dei Modelli di Generazione di Codice per l'Estrazione di Informazioni a Pochi Shot**

Questo studio presenta CodeIE, un approccio innovativo per migliorare l'estrazione di informazioni a pochi shot, affrontando le sfide associate ai modelli pre-addestrati per il linguaggio naturale. L'estrazione di informazioni è una task fondamentale nel Natural Language Processing (NLP), che include il riconoscimento di entità nominate e l'estrazione di relazioni.

I ricercatori propongono di trasformare il processo da una task di testo-a-struttura a una di codice-a-struttura, utilizzando modelli di linguaggio di grandi dimensioni come Codex. Questo approccio garantisce che sia l'input che l'output siano in un formato coerente, risolvendo il problema della discrepanza tra pre-addestramento e inferenza.

Attraverso l'uso di prompt specifici, CodeIE guida i modelli a estrarre entità nominate e relazioni da testi. I risultati sperimentali dimostrano che questo metodo supera significativamente i modelli di base, inclusi T5, UIE, e GPT-3, in termini di precisione e richiamo, specialmente con pochi esempi di addestramento. L'analisi rivela che i modelli Codex, addestrati con prompt di codice, mostrano una migliore comprensione strutturale e riducono gli errori, mentre GPT-3 può generare etichette non previste.

Lo studio evidenzia i vantaggi dell'uso di modelli di generazione di codice per l'estrazione di informazioni, offrendo un approccio promettente per migliorare le prestazioni in scenari a pochi shot, soprattutto in termini di precisione e completezza dei risultati.</sample>
    <sample id="318">## Presentazione: DrBERT: Un modello pre-addestrato robusto in francese per i domini biomedici e clinici

**Introduzione:**

Iniziamo parlando dell'importanza del *language modeling* nel settore sanitario. Successivamente, presenteremo i contributi principali del nostro articolo. Introdurremo DrBERT, il primo modello biomedico in francese basato su RoBERTa e addestrato su NACHOS, un dataset di dati medici raccolti dal web. Confronteremo inoltre diverse configurazioni di pre-addestramento e fonti di dati. Mostreremo i risultati ottenuti su 11 compiti biomedici e clinici in francese. Infine, concluderemo gli esperimenti e forniremo dettagli su come accedere a questi modelli.

Dato il suo rilascio nel 2018, BERT si è affermato come uno degli approcci più efficaci per risolvere i compiti di Natural Language Processing, offrendo significativi miglioramenti rispetto ai metodi statici e contestuali precedenti come Word2vec, fastText, ecc. Da allora, il modello è stato adattato a molte altre lingue, tra cui il francese con CamemBERT, e a domini specifici come il biomedico con PubMedBERT e BioBERT, e il clinico con ClinicalBERT, ma principalmente in inglese. I modelli specializzati per altre lingue sono rari e spesso si basano su pre-addestramento continuo a causa della mancanza di dati in-domain. Fino ad ora, in francese non esisteva un modello open-source per il settore biomedico.

**Domande e obiettivi:**

Ci siamo chiesti quali siano le fonti di dati più adatte per un'ampia gamma di applicazioni e se i dati raccolti dal web possano essere una valida alternativa ai dati clinici. Abbiamo quindi confrontato DrBERT con il nostro modello ChuBERT, basato su dati anonimizzati provenienti dal data warehouse dell'Ospedale Universitario di Nantes. Un'altra domanda è stata: quanta quantità di dati è necessaria per addestrare un modello specializzato in francese? È sufficiente 4 GB, 8 GB o più?

Per rispondere a queste domande, abbiamo addestrato e confrontato quattro modelli da zero: una prima versione di DrBERT con 7 GB di NACHOS; una seconda versione con 4 GB di NACHOS; una prima versione di ChuBERT, modello clinico con 4 GB di frasi estratte dalle note cliniche; e una versione finale di ChuBERT con un mix di 4 GB di NACHOS e 4 GB di note cliniche. Oltre a questo confronto, abbiamo esplorato tre modelli addestrati con pre-addestramento continuo: uno basato sui pesi e sul tokenizzatore di CamemBERT addestrato su un set di 4 GB di NACHOS; un altro con lo stesso CamemBERT ma addestrato su 4 GB di note cliniche; infine, un modello basato su PubMedBERT, modello biomedico inglese, addestrato su 4 GB di NACHOS. In totale, abbiamo sette modelli.

**Valutazione:**

Abbiamo raccolto dati per compiti pubblici e privati come il riconoscimento di entità nominate, la classificazione, l'etichettatura della parte del discorso e la risposta alle domande per valutare i nostri sette modelli. Questi sono stati confrontati con sei modelli di base: CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, BioBERT e ClinicalBERT.

I risultati evidenziano che i modelli ottengono le migliori prestazioni sui compiti con dati della stessa natura di quelli su cui sono stati addestrati. Tuttavia, osserviamo che i dati da fonti eterogenee sembrano essere più versatili. Utilizzare più dati porta a prestazioni migliori. In generale, il pre-addestramento da zero sembra ottenere risultati migliori su la maggior parte dei compiti. Tuttavia, il nostro esperimento sul pre-addestramento con i pesi e il tokenizzatore di CamemBERT addestrati su un set di 4 GB di NACHOS ha mostrato risultati comparabili a quelli di DrBERT 4 GB da zero. Questo non è il caso del modello basato sui pesi e sul tokenizzatore di CamemBERT, che ha sofferto di problemi di stabilità.

**Conclusione:**

Il nostro sistema completo ha ottenuto prestazioni migliori su 9 dei 11 compiti e ha superato globalmente il risultato del modello generico, CamemBERT. Osserviamo che i dati più specializzati sono migliori, ma non scalano bene. Tutti i modelli pre-addestrati basati su NACHOS sono disponibili gratuitamente su Hugging Face, sotto licenza MIT, e i script di addestramento sono disponibili sul nostro repository GitHub.

Grazie per l'attenzione. Siamo entusiasti di discutere ulteriormente durante la sessione poster a Toronto.</sample>
    <sample id="319">Nel lavoro, vengono esaminate diverse strategie di apprendimento:

1. **Apprendimento da zero (from-scratch)**: Addestrare modelli DrBERT e ChuBERT utilizzando grandi quantità di dati (7 GB e 4 GB) estratti da NACHOS (dati web medicali) e note cliniche.

2. **Apprendimento continuo (continual pre-training)**: Utilizzare modelli pre-addestrati come CamemBERT, PubMedBERT e BioBERT, e adattarli a nuovi domini con set di dati più piccoli (4 GB).

3. **Confronto tra modelli**: Confrontare i modelli addestrati con e senza dati clinici, e valutare l'impatto delle diverse strategie di pre-addestramento.

In sintesi, lo studio esplora l'efficacia di varie tecniche di pre-addestramento per migliorare le prestazioni dei modelli linguistici nel dominio biomedico e clinico in francese.</sample>
    <sample id="320">Secondo la presentazione, il riutilizzo del test set non sembra essere la causa principale dell'overfitting. L'analisi ha mostrato che la curva di miglioramento sul dataset CoNLL++ non presentava un gradiente superiore a 1, indicando che non c'era una "diminuzione dei rendimenti" tipica dell'overfitting adattivo. Pertanto, il fattore di overfitting dovuto al riutilizzo del test è considerato minimo o non rilevante in questo contesto.</sample>
    <sample id="321">La qualità della semplificazione è stata valutata attraverso:

1. **Analisi manuale e automatica delle coppie di frasi parallele**: Il corpus DEPLAIN contiene 13.000 coppie di frasi (DEPLAIN-apa) e 30.450 coppie (DEPLAIN-web), manualmente e automaticamente allineate, permettendo un confronto diretto tra frasi complesse e semplificate.

2. **Tipi di semplificazione**: È stata esaminata la varietà di trasformazioni di semplificazione, come reordinamento, aggiunta di parole, e ripensamento, mostrando differenze tra i domini di DEPLAIN-apa (notizie) e DEPLAIN-web (vari).

3. **Metodi di valutazione automatizzati**: Il corpus è stato utilizzato per valutare metodi di allineamento automatico, con la conclusione che MASSalign è il metodo più efficace per la semplificazione del testo tedesco.

4. **Fine-tuning di modelli linguistici**: Due modelli (long-mBART e base mBART) sono stati fine-tunati per produrre semplificazioni automatiche, con risultati promettenti rispetto ai benchmark esistenti.</sample>
    <sample id="322">**Abstract: "Comprendere la Morale nel Testo: Un'Analisi Multidimensionale con Apprendimento Automatico"**

Questo studio esplora come i modelli linguistici di intelligenza artificiale (AI) apprendono e interpretano la morale nel testo, affrontando la complessità soggettiva della percezione umana della moralità. L'autore, Enrico, discute la rilevanza della comprensione della morale nel linguaggio naturale, evidenziando la necessità di andare oltre una semplice scala binaria di giudizio morale.

Si introduce la teoria delle Fondamenta Morali, un quadro teorico che suggerisce che la moralità sia percepita attraverso cinque fondamenti distinti, con variazioni individuali nella priorità di ciascuno. Questa teoria è applicata all'elaborazione del linguaggio naturale (NLP) per classificare la morale nel testo.

La ricerca si concentra sull'analisi di un dataset di tweet, il Moral Foundation Twitter Corpus, che copre sette domini diversi. L'obiettivo è determinare se i modelli linguistici possano riconoscere le differenze nella moralità espressa in questi domini, come #AllLivesMatter e #BlackLivesMatter. Gli esperimenti rivelano che i modelli identificano sfumature morali, associando concetti come "sovversione" a reazioni diverse in base al dominio.

L'abstract sottolinea l'importanza di comprendere le sfumature morali nel testo e avverte dei pericoli di utilizzare un singolo modello per domini diversi, poiché potrebbe portare a interpretazioni errate della morale. Lo studio mira a migliorare le tecniche di explainable AI per una comprensione più approfondita della morale nel linguaggio naturale.</sample>
    <sample id="323"># **Dinamico Ragionamento su Grafici Omogenei e Heterogenei con Modelli Linguistici e Apprendimento della Rappresentazione della Conoscenza per la Domanda e Risposta di Sensato Comune (Commonsense QA)**

Questa ricerca si concentra sulla sfida della Commonsense QA, un compito che richiede alle macchine di rispondere a domande basate sulla conoscenza generale e sulla comprensione del linguaggio. L'approccio proposto, chiamato DHLK, mira a migliorare l'estrazione di conoscenze esterne per rispondere a queste domande.

Il metodo DHLK costruisce un grafico omogeneo e eterogeneo (HKG) fuso con conoscenze da diverse basi di conoscenza, ottimizzando la struttura e la rappresentazione della conoscenza. Il processo inizia con la creazione di un HKG basato su più tripletti, dove le entità e le relazioni sono rappresentate utilizzando TransE. Vengono rimossi i nodi meno rilevanti dinamicamente in base all'attenzione del modello linguistico RoBERTa.

L'innovazione chiave è l'introduzione di Relation Mask Self-Attention (RMSA) per modellare i sottografi all'interno dell'HKG, migliorando l'interazione tra le modalità testo-conoscenza. Il modello utilizza anche KeyBERT per estrarre entità chiave dal contesto della domanda e recupera percorsi di conoscenza in ConceptNet.

L'HKG migliorato viene quindi fuso con il contesto della domanda utilizzando un MLP, producendo una rappresentazione arricchita. Questa rappresentazione viene utilizzata per prevedere la probabilità di risposta. Gli esperimenti su CommonsenseQA e OpenBookQA dimostrano l'efficacia del metodo DHLK, ottenendo risultati competitivi rispetto ad altri approcci basati su modelli linguistici e HKG.</sample>
    <sample id="324">Sì, i modelli linguistici presentano diversi bias politici. Secondo la ricerca presentata, i modelli come GPT-4 e vari modelli della serie GPT tendono ad essere più liberali socialmente rispetto a modelli come BART e le sue varianti. Inoltre, i modelli possono ereditare e riflettere le polarizzazioni politiche presenti nei dati di addestramento, mostrando una tendenza a spostarsi più lontano dal centro dopo il 2017, anno della presidenza di Donald Trump.

La ricerca evidenzia che questi bias politici influenzano le prestazioni dei modelli in compiti come la rilevazione di odio e la rilevazione di notizie false, con modelli di orientamento politico opposto che mostrano migliori prestazioni in categorie demografiche diverse.</sample>
    <sample id="325">## Introduzione al nostro articolo: "Composizione Generalizzazione senza Alberi utilizzando Tagging Multinset e Permutazioni Latenti"

Ciao! Mi chiamo Matthias Lindemann e oggi vi presento brevemente il nostro articolo, scritto insieme ai miei supervisori Alexander Koller e Ivan Titov, intitolato "Composizione Generalizzazione senza Alberi utilizzando Tagging Multinset e Permutazioni Latenti".

La **generalizzazione composizionale** si riferisce alla capacità di un modello di apprendimento di gestire ricorsioni più profonde e composizioni di frasi viste individualmente durante la fase di addestramento. Nel contesto del semantic parsing, testare la generalizzazione composizionale può apparire così:

Immaginiamo un set di addestramento di frasi, come "La ragazza ha dormito" e "Mary sapeva che la ragazza ha dormito", accompagnate da forme logiche che ne rappresentano il significato essenziale. A differenza della valutazione standard nell'apprendimento automatico, il set di test non proviene dalla stessa distribuzione, ma contiene forme logiche strutturalmente inesplorate. In questo caso, il modello ha visto ricorsioni superficiali durante l'addestramento e viene testato su un esempio con ricorsione più profonda. I modelli seq2seq tradizionali faticano con questo tipo di generalizzazione fuori distribuzione e spesso producono output slegati dall'input. In particolare, spesso non riescono a riprodurre le corrispondenze sistematiche tra input e output, come evidenziato nell'esempio colorato.

Un metodo popolare per affrontare questo problema è l'integrazione di alberi nei modelli. Gli alberi sono pensati per catturare il processo composizionale che collega le frasi alle forme logiche. Questo approccio funziona bene, ma gli alberi non sono generalmente disponibili e devono essere ottenuti in qualche modo. Questo processo può essere complesso e a volte computazionalmente costoso. Solitamente, questo comporta un pre-elaborazione formalismo-specifico delle forme logiche, ad esempio per gestire simboli di variabili. Ottenere gli alberi può anche richiedere procedure di induzione grammaticale specializzate.

Nel nostro articolo, **non utilizziamo alberi** e introduciamo un modello seq2seq neurale che modella direttamente le corrispondenze tra frammenti dell'input e frammenti dell'output. Dimostriamo per la prima volta una forte generalizzazione a ricorsioni più profonde **senza affidarci agli alberi**. Il nostro approccio prevede la previsione dell'output a partire dall'input in due passaggi:

* **Primo passo:** Taggiamo ogni token dell'input con un multiset non ordinato di token che appariranno nell'output.
* **Secondo passo:** Utilizziamo un altro modello per prevedere una permutazione che metta i token nel giusto ordine.

Introduciamo un nuovo metodo per prevedere la permutazione che **non impone vincoli rigidi sulle permutazioni possibili**, rendendolo molto flessibile ed espressivo. In linea di massima, il nostro modello di permutazione funziona nel modo seguente: partendo da sinistra a destra sull'output, determiniamo quale token del multiset mettere in ogni posizione. Per la prima posizione dell'output, scegliamo semplicemente uno, come evidenziato in rosso. Poi saltiamo al prossimo token del multiset per determinare il secondo token nell'output. Continuiamo questo processo fino a quando ogni token del primo passo è stato visitato esattamente una volta.

Per darvi un'idea dei nostri risultati sperimentali, confrontiamo il nostro metodo con altri modelli senza alberi sul benchmark COGS. Il nostro modello supera nettamente gli altri nella generalizzazione a ricorsioni più profonde. Tuttavia, altre forme di generalizzazione strutturale rimangono molto impegnative.

Nel nostro articolo affrontiamo anche alcune interessanti sfide tecniche:

* **Allineamento input-output:** l'allineamento tra input e output non è dato nei dati di addestramento. Di conseguenza, per un dato token, non sappiamo da quale multiset proviene, il che rappresenta una sfida per l'addestramento.
* **Permutazioni multiple:** possono esserci più permutazioni coerenti con i dati, ma quella linguisticamente corretta potrebbe essere latente. Affrontiamo questo problema inducendo l'allineamento come parte dell'addestramento.

Il nostro metodo di permutazione è molto flessibile, ma porta con sé la sfida di trovare la permutazione con il punteggio più alto, che è NP-hard. Questo perché è legato al problema del "Viaggiatore di Commercio". Approssimiamo questo con una rilassazione continua GPU-friendly che permette anche di backpropagare attraverso la soluzione e imparare le permutazioni linguisticamente più plausibili.

Se volete saperne di più sui nostri esperimenti e su come affrontiamo queste sfide, date un'occhiata al nostro articolo o venite al nostro poster.</sample>
    <sample id="326">La dissonanza cognitiva è una situazione in cui una persona ha due credenze o azioni contrastanti. Ad esempio, affermare di essere consapevoli dei rischi per la salute legati al fumo e poi fumare comunque. Questo crea un senso di disagio psicologico.

Nel contesto del linguaggio, la dissonanza è rara da esprimere, ma studiare questo fenomeno può aiutare a comprendere:

* **Disaccordi e cambiamenti di atteggiamento:**  Analizzare le tendenze e i valori delle credenze.
* **Salute mentale:**  La dissonanza è correlata all'ansia e può fornire informazioni sui disturbi mentali.
* **Estremismo e polarizzazione:**  Comprendere il processo di radicalizzazione in gruppi vulnerabili.
* **Stili cognitivi individuali:**  Aiuta a capire i processi decisionali personali.</sample>
    <sample id="327"># **ManagerTower: Aggregating Unimodal Expert Insights for Vision-Language Learning**

La ricerca presentata, "ManagerTower", mira a migliorare l'apprendimento delle rappresentazioni visuo-linguistiche addestrando un sistema AI in grado di comprendere sia le immagini che il testo. L'approccio propone una nuova architettura VL modal, che supera le limitazioni delle precedenti strutture a due torri.

La sfida principale è sfruttare efficacemente la conoscenza semantica a diversi livelli dei codificatori unimodali. BridgeTower, un'architettura precedente, collega solo le ultime rappresentazioni unimodali al cross-modal, perdendo potenziali informazioni. ManagerTower introduce "manager" in ogni strato cross-modal per aggregare dinamicamente le rappresentazioni unimodali da diversi livelli.

L'innovazione chiave è l'utilizzo di manager adattivi che sfruttano la conoscenza semantica in modo flessibile. Gli esperimenti dimostrano che ManagerTower, addestrato con solo 4 milioni di immagini, supera le prestazioni di modelli più grandi e complessi. La visualizzazione delle ponderazioni di aggregazione rivela che i manager adattivi imparano a pesare le rappresentazioni unimodali in modo distinto in base allo strato cross-modal, indicando un'efficace sfruttamento della conoscenza semantica a diversi livelli.

Questa ricerca offre un approccio promettente per migliorare l'apprendimento visuo-linguistico, consentendo ai sistemi AI di comprendere meglio il contenuto visivo e testuale. Il codice e i modelli sono disponibili per facilitare la riproducibilità e l'applicazione pratica.</sample>
    <sample id="328">Secondo la presentazione, **GPT-4** è il modello linguistico più liberale tra quelli esaminati.</sample>
    <sample id="329"># **Generazione di etichette pseudo-strutturate per la localizzazione di frasi video zero-shot resistenti al rumore**

Questo lavoro presenta un approccio innovativo per la localizzazione di frasi video zero-shot, un'attività che richiede di identificare segmenti video rilevanti in base a una query testuale, senza annotazioni manuali. Gli autori propongono un metodo per generare etichette pseudo-strutturate resistenti al rumore, affrontando le sfide poste dai metodi zero-shot esistenti.

Il problema tradizionale è la semplificazione delle query pseudo-generate e la mancanza di allineamento tra query e eventi pseudo-creati. La soluzione proposta include la generazione di query pseudo-formate più complesse utilizzando un modello di didascalie di immagini pre-addestrato, seguito da una misurazione della rilevanza tra fotogrammi e query. Questo processo garantisce una forte correlazione tra video e query all'interno degli eventi e una debole correlazione al di fuori di essi.

Il metodo introduce anche una riduzione del peso dei campioni rumorosi e la creazione di etichette rumorose per gestire il problema del rumore nelle etichette. Questo processo coinvolge l'esame della qualità degli eventi e la selezione di quelli con la massima differenza di somiglianza interna ed esterna. Inoltre, vengono implementate strategie di ri-peso dei campioni e di raffinamento delle etichette per ridurre l'impatto del rumore durante l'addestramento del modello.

Gli esperimenti su ActivityNet Captions e Charades-STA dimostrano l'efficacia dell'approccio, con miglioramenti significativi rispetto ad altri metodi zero-shot. Il codice è disponibile per facilitare la riproducibilità.</sample>
    <sample id="330">Sì, secondo la presentazione, l'addestramento **cumulativo** funziona generalmente meglio o allo stesso livello dell'addestramento **iterativo** nel contesto dell'apprendimento attivo per la rilevazione della dissonanza.

La ricerca suggerisce che l'aggiornamento del modello con tutti i dati raccolti finora (addestramento cumulativo) offre risultati migliori o comparabili rispetto all'addestramento iterativo, che aggiorna il modello solo con l'ultimo set di dati.</sample>
    <sample id="331">La relatrice è Sara Papi.</sample>
    <sample id="332">I dati per il parametro di riferimento MuDa (Multilingual Discourse-Aware) tagger sono stati tratti da un parallel corpus utilizzato per l'evaluazione. Questo corpus è stato analizzato per identificare e taggare automaticamente le parole relative a cinque diversi fenomeni discorsivi.</sample>
    <sample id="333"># **INK: Migliorare la Traduzione Automatica con la Conoscenza kNN**

Questo lavoro di ricerca presenta INK, un innovativo framework per migliorare la traduzione automatica neurale (NMT) incorporando la conoscenza k-Nearest Neighbor (kNN). L'obiettivo è affrontare le sfide poste dalla non-linearità degli spazi di rappresentazione neurale, che può limitare la generalizzazione e le prestazioni dei modelli NMT.

La ricerca osserva che nello spazio di rappresentazione dei modelli NMT, i token a bassa frequenza tendono a disperdersi in modo irregolare, creando "buchi" con definizioni semantiche povere. Per migliorare questo, viene proposta la tecnica kNN-MT, che liscia le previsioni basandosi sui vicini più vicini nello spazio di rappresentazione. Tuttavia, questo approccio ha svantaggi, come il tempo di ricerca dei vicini e la difficoltà di aggiornare le rappresentazioni.

INK introduce un ciclo di addestramento a due fasi. Prima, estrae conoscenza kNN per guidare l'adattamento dello spazio di rappresentazione. Poi, aggiorna le rappresentazioni e rinfresca il datastore in modo asincrono. Questo ciclo continua fino alla convergenza. L'adattamento include l'allineamento di diverse rappresentazioni per preservare il significato semantico.

Gli esperimenti utilizzano il modello NMT vincente del WMT'19 per la traduzione tedesco-inglese e mostrano che INK migliora significativamente lo spazio di rappresentazione. I risultati rispondono a tre domande di ricerca: l'efficacia di un piccolo adattatore senza datastore, il miglioramento derivante dalla conoscenza kNN e il beneficio della combinazione di adattatore e datastore.

INK dimostra prestazioni superiori, con un aumento medio del 1.99 COMET score e del 1.0 BLEU, rispetto ai sistemi kNN-MT esistenti, offrendo un miglioramento nella qualità della traduzione con una minore necessità di memoria e velocità di inferenza.</sample>
    <sample id="335">La relatrice è Matthias Lindemann.</sample>
    <sample id="336">Il trasferimento interlinguistico, nel contesto del lavoro presentato, si riferisce alla capacità di un modello di apprendere da una lingua e applicare quella conoscenza ad un'altra lingua diversa. Questo può avvenire in due modi principali:

1. **Zero-shot transfer**: Il modello utilizza la conoscenza acquisita in una lingua per fare previsioni in un'altra lingua senza aver ricevuto addestramento specifico su quella lingua.
2. **Few-shot transfer**: Il modello viene addestrato su un piccolo set di dati in una lingua sorgente e poi utilizzato per fare previsioni in una lingua di destinazione con un numero limitato di esempi.

Il lavoro descrive come questi approcci di trasferimento interlinguistico influenzano le prestazioni dei modelli di semantic parsing in diverse lingue e rappresentazioni del significato.</sample>
    <sample id="337"># **Graph-based Relation Mining per l'Imparare Embedding di Parole Fuori Vocabolario Contesto-Indipendenti**

Questo studio presenta un nuovo approccio per affrontare la sfida delle parole fuori vocabolario (OOV) nell'apprendimento degli embedding linguistici. L'obiettivo è migliorare la rappresentazione delle parole OOV, cruciali per le prestazioni dei modelli basati su embedding.

L'approccio introduce un *Word Relationship Graph* che simula le regole di formazione e associazione delle parole. Quando si incontra una parola OOV, viene tokenizzata in wordpieces e associata a parole rilevanti, creando un grafo a due livelli. Ogni parola o wordpiece è un nodo, con i rispettivi embedding come attributi. La prima livello conserva tutti i nodi per mantenere le informazioni complete, mentre il secondo livello campionando nodi riduce il rumore.

Per gestire l'assegnazione di attributi ai nodi OOV, viene impiegata una rete di auto-attenzione basata sui caratteri delle parole. Due livelli di *Graph Attention Network* estraggono informazioni importanti e riducono l'impatto dei nodi rumorosi. Un *readout block* aggrega le informazioni del grafo a livello globale.

La perdita include contrastive learning con campioni NT-XENT, promuovendo vicinanza tra embedding simili e allontanamento da quelli diversi. Gli esperimenti dimostrano l'efficacia del modello in vari compiti, migliorando le prestazioni rispetto ai baseline.

Inoltre, lo studio esplora l'estensione del modello a lingue diverse, suggerendo che le lingue agglutinanti, con la loro formazione diretta di parole, si adattano meglio, mentre le lingue fusionali presentano sfide. La conclusione sottolinea la versatilità del grafo nel gestire complesse formazioni di parole, con implicazioni per l'applicazione in diverse lingue.</sample>
    <sample id="338">**Abstract:**

Il lavoro di ricerca presentato, intitolato "Are Human Explanations Always Helpful?", esplora un approccio oggettivo per valutare le spiegazioni naturali fornite dagli esseri umani, affrontando le sfide intrinseche associate a tale valutazione. Gli autori, provenienti da Rensselaer Polytechnic Institute, Northeastern University e IBM Research, propongono una struttura unificata per strutturare vari compiti e formati di dati.

La ricerca evidenzia le limitazioni delle metriche tradizionali, come BLEU e ROUGE, che trattano le annotazioni umane come oro standard, ignorando la natura soggettiva e task-dipendente delle spiegazioni. Per affrontare questo problema, introducono un nuovo metriche, TREU, che estende il simulatability score, valutando l'utilità delle spiegazioni durante il fine-tuning.

Attraverso esperimenti su cinque dataset di grandi dimensioni per diversi compiti, tra cui commonsense QA, natural language inference e valutazione della convalida del senso comune, gli autori dimostrano che le spiegazioni umane possono ancora migliorare le previsioni dei modelli, anche se considerate di bassa qualità. I risultati mostrano che il fine-tuning con spiegazioni insegna ai modelli a dipendere da queste, con utilità variabili a seconda del compito e del formato.

Il lavoro suggerisce che la valutazione delle spiegazioni umane dovrebbe considerare fattori come il fine-tuning e l'inferenza, e fornisce una struttura unificata e una metrica per facilitare questo processo. Gli autori concludono sottolineando l'importanza di tali controlli di qualità per migliorare la collaborazione umana nella annotazione dei dati.</sample>
    <sample id="339">Gli autori dell'articolo "Weaker Than You Think: A Critical Look at Weakly Supervised Learning" sono affiliati a Saarland University in Germania. Specificamente, i co-autori includono:

- Dawei (PhD student)
- Xiaoyu Shen
- Marius Mosbach
- Andreas Stephan
- Dietrich Klakow</sample>
    <sample id="340">**Abstract: ParaAMR: Un Dataset di Paraphrase Sintatticamente Diverso tramite Back-Translation AMR**

Il lavoro presenta *ParaAMR*, un dataset di paraphrase su larga scala e sintatticamente vario, sviluppato utilizzando la tecnica di back-translation AMR. L'importanza della generazione di paraphrase nel campo del NLP è ben documentata, con applicazioni in sistemi di risposta alle domande, chatbot e miglioramento della robustezza. Tuttavia, i dataset umani annotati come MRPC, PAN e Quora, pur essendo di alta qualità, sono limitati in termini di dimensioni. Gli dataset automatizzati, come il back-translation, generano grandi quantità di dati, ma mancano di diversità sintattica.

Gli autori propongono di sfruttare le rappresentazioni astratte del significato (AMR), grafici direzionali che catturano il significato semantico delle frasi. Utilizzando un pre-addestrato parser AMR, generano grafici AMR per frasi sorgente, modificando poi casualmente il nodo radice e le relative etichette di edge. Questo processo, combinato con un generatore di testo basato su AMR, produce una vasta gamma di paraphrase con struttura simile ma sintassi differente.

*ParaAMR* contiene circa 15 milioni di frasi sorgente con circa 6.9 paraphrase ciascuna, dimostrando una maggiore diversità sintattica rispetto ad altri dataset basati su back-translation. Gli esperimenti mostrano che *ParaAMR* migliora le prestazioni in compiti di embedding delle frasi e generazione di paraphrase controllata sintatticamente. Inoltre, nel few-shot learning, *ParaAMR* dimostra un miglioramento significativo.

In conclusione, *ParaAMR* offre un prezioso dataset per la ricerca NLP, promuovendo lo sviluppo di sistemi più robusti e flessibili nella generazione di testo.</sample>
    <sample id="341">Gli autori fanno ricorso a due misure di latenza:

1. **Media latenza (Average Lagging)**: Misura la latenza media del sistema.
2. **Latenza computazionale consapevole (Computationally-aware Average Lagging)**: Tiene conto dei tempi di calcolo necessari per prevedere l'output del modello.

Queste misure permettono di valutare sia la velocità di traduzione che l'efficienza computazionale del sistema di Simultaneous Speech Translation (SimulST).</sample>
    <sample id="342"># **LiveChat: Un dataset di dialogo personalizzato su larga scala costruito automaticamente da streaming live**

La presentazione introduce LiveChat, un dataset di dialogo innovativo progettato per migliorare la ricerca nell'ambito dei sistemi di conversazione basati sull'intelligenza artificiale. L'obiettivo è affrontare le sfide associate ai dataset di dialogo esistenti, che sono principalmente basati su conversazioni testuali e limitati in termini di scala e diversità.

L'autore del paper evidenzia la crescente importanza dei dialoghi di dominio aperto e personalizzati, soprattutto per applicazioni come i streamer virtuali e gli assistenti virtuali. Tuttavia, la creazione di dataset su larga scala per questi scopi è complessa. LiveChat mira a superare queste barriere proponendo un metodo automatizzato per costruire dialoghi da streaming video live.

Il processo di creazione di LiveChat coinvolge tre fasi: raccolta di video da piattaforme come TikTok e Douyin, estrazione e trascrizione dell'audio, e costruzione di dialoghi con un metodo di abbinamento "reply-to-whom". Il dataset include anche informazioni sulle personalità, estratte sia manualmente che con classificatori addestrati.

Gli esperimenti condotti sui benchmark di modellazione della risposta e riconoscimento dell'interlocutore dimostrano i vantaggi di LiveChat. I risultati mostrano che le informazioni sulla personalità e le sessioni di dialogo più lunghe migliorano le prestazioni, soprattutto quando combinate con regole e classificatori di personalità. Inoltre, il dataset si distingue per la sua origine video, la scala e la lunghezza delle sessioni.

In conclusione, LiveChat offre un prezioso contributo alla ricerca sui dialoghi AI, fornendo un dataset personalizzato e video-sorgente che consente un'efficace trasferimento dell'apprendimento per modelli di linguaggio avanzati.</sample>
    <sample id="343">## La prova KITMUS: Valutare l'integrazione della conoscenza da più fonti

**Introduzione**

Ciao a tutti, sono Akshatha e oggi, insieme al mio co-autore Martin, presentiamo il nostro lavoro "La prova KITMUS: Valutare l'integrazione della conoscenza da più fonti". Questa ricerca è il frutto di una collaborazione tra l'Università di McGill, Mila e Microsoft Research.

I modelli di comprensione del linguaggio naturale (NLU) attingono a diverse fonti di conoscenza, come quella contenuta nei loro parametri, acquisita solitamente durante la fase di pre-addestramento, e quella fornita negli input durante l'inferenza. Studi recenti in compiti come il question answering mostrano che i modelli possono utilizzare la conoscenza acquisita durante il pre-addestramento per risolvere i compiti. Tuttavia, la comprensione del linguaggio naturale spesso richiede conoscenze che vengono fornite durante l'inferenza. Ad esempio, nella frase "John ha visto il nuovo presidente in TV", i parametri pre-addestrati possono contenere informazioni su presidenti e TV, ma non possono sapere con certezza chi sia l'entità specifica "John" o chi sia il nuovo presidente, poiché questi potrebbero essere cambiati dal momento del pre-addestramento.

Pertanto, per modelli efficaci per compiti NLU ad alta intensità di conoscenza, è essenziale la capacità di integrare e utilizzare sia la conoscenza pre-addestrata che quella fornita durante l'inferenza.

In questo lavoro, proponiamo una suite di test diagnostici per l'integrazione della conoscenza. Introdurremo un compito di risoluzione dei coreferenti, progettato per valutare la capacità di sfruttare la conoscenza disponibile in diverse fonti.

**Il dataset e l'esperimento**

Abbiamo creato un dataset con esempi come questo:

* Servin è un giudice.
* Kea è un panettiere.
* Servin e Kea si sono incontrati in un parco.
* Dopo una lunga giornata di lavoro a decidere casi in tribunale, era felice di rilassarsi.

Il compito è identificare la corretta entità a cui si riferisce il pronome "lui", che in questo caso è Servin.

La risoluzione di un pronome richiede due tipi di informazioni:

* **Conoscenza specifica dell'entità:** ad esempio, "Servin è un giudice".
* **Conoscenza di sfondo:** ad esempio, "I giudici decidono casi nei tribunali".

Generalmente, la conoscenza di sfondo viene appresa durante il pre-addestramento dei grandi modelli linguistici, mentre la conoscenza specifica dell'entità viene osservata durante l'inferenza.

Abbiamo definito tre scenari per KITMUS:

* **Background-Pretrain:** la conoscenza di sfondo è disponibile durante il pre-addestramento.
* **Background-Both:** la conoscenza di sfondo è disponibile sia durante il pre-addestramento che durante l'inferenza.
* **Background-Inference:**  la conoscenza di sfondo è disponibile solo durante l'inferenza. Questo scenario è particolarmente interessante perché simula il caso in cui la conoscenza di sfondo necessaria per risolvere un compito non è contenuta nei dati di pre-addestramento del modello, come potrebbe accadere con nuove professioni emerse dopo il pre-addestramento.

Abbiamo controllato la disponibilità di fatti nelle fonti vere e proprie in modo da creare scenari diversi.

* In **Background-Pretrain**, la conoscenza di sfondo "I politici cercano seggi eletti nel governo" è contenuta nei parametri pre-addestrati e durante l'inferenza forniamo la conoscenza specifica dell'entità "Chichester è un politico".
* In **Background-Both**, forniamo non solo la conoscenza specifica dell'entità ma anche la conoscenza di sfondo sui politici durante l'inferenza.
* In **Background-Inference**, forniamo un'occupazione fittizia come "mirituer" invece di "politico" perché è improbabile che "mirituer" sia contenuta nei parametri pre-addestrati.

Abbiamo valutato il dataset sia con partecipanti umani che con modelli di risoluzione dei coreferenti pre-addestrati.

Nella figura seguente, mostriamo i risultati dei modelli migliori nel più difficile scenario **Background-Pretrain**. Senza un addestramento specifico su KITMUS, entrambi i modelli non ottengono buoni risultati. Al contrario, quando addestrati su KITMUS, sia C2F che BERT4Coref superano significativamente le prestazioni casuali. Questo suggerisce che, anche se imparano a sfruttare le tracce superficiali, i modelli generici di risoluzione dei coreferenti tendono a basarsi su queste tracce che non sono utili su KITMUS dove sono state rimosse.

**Conclusioni**

In sintesi, molti modelli di risoluzione dei coreferenti sembrano incapaci di ragionare su conoscenze provenienti da diverse fonti senza un addestramento specifico. Tuttavia, con un addestramento mirato, alcuni modelli riescono ad integrare conoscenze da più fonti. Anche i migliori modelli, tuttavia, sembrano avere difficoltà a integrare con affidabilità la conoscenza retrospettiva fornita solo durante l'inferenza.

Per ulteriori dettagli, consultate il nostro articolo e date un'occhiata al dataset e al codice su GitHub. Grazie per l'attenzione.</sample>
    <sample id="344">Gli svantaggi dei metodi basati su alberi per la composizione generalizzazione includono:

1. **Complessità di ottenimento degli alberi**: Gli alberi devono essere estratti dai logici forme, un processo spesso complesso e costoso computazionalmente.
2. **Dipendenza dalla distribuzione del training**: Gli alberi possono non catturare bene le strutture viste fuori dalla distribuzione di training, portando a generalizzazione scarsa.
3. **Costi computazionali elevati**: La manipolazione degli alberi può richiedere risorse computazionali significative.
4. **Specializzazione**: Le tecniche basate su alberi spesso richiedono formalismi specifici e grammatiche induttive, limitando la loro applicabilità.</sample>
    <sample id="345"># **Compositional Generalization without Trees: Unlocking Deep Recursion in Semantic Parsing**

Questo studio introduce un approccio innovativo alla generalizzazione composizionale nel campo della semantica del linguaggio naturale, superando la necessità di utilizzare alberi nella modellazione. Gli autori, Matthias Lindemann, Alexander Koller e Ivan Titov, propongono un modello seq2seq neurale che cattura direttamente le corrispondenze tra input e output, consentendo una generalizzazione a strutture ricorsive più profonde.

Il problema tradizionale nella semantica del parsing è la generalizzazione a input strutturalmente diversi durante il test, mentre i modelli seq2seq standard spesso falliscono nel mantenere le corrispondenze sistematiche tra input e output. L'uso di alberi aiuta a gestire questo problema, ma richiede un'elaborazione complessa e costosa per la loro estrazione.

La soluzione proposta elimina gli alberi e introduce un sistema a due fasi. Nella prima fase, ogni token dell'input viene etichettato con un multiset di token di output. Nella seconda fase, un modello aggiuntivo predice una permutazione per ordinare i token. Questo approccio consente una flessibilità espressiva senza vincoli rigidi sulle permutazioni.

Gli esperimenti sul benchmark COGS dimostrano l'eccellenza del modello nella generalizzazione a ricorsioni più profonde rispetto ad altri metodi senza alberi. Gli autori affrontano anche sfide tecniche, come l'allineamento input-output non esplicito e la determinazione della permutazione ottimale, che è computazionalmente impegnativa. Il loro metodo utilizza un'approssimazione continua per trovare permutazioni plausibili linguisticamente.

In sintesi, questo lavoro apre nuove possibilità per la comprensione e la traduzione di strutture linguistiche complesse senza affidarsi alla costruzione di alberi, offrendo un'alternativa promettente per i sistemi di semantica del linguaggio naturale.</sample>
    <sample id="346">Basandosi sul contenuto presentato, gli autori dell'articolo "Do CoNLL-2003 named entity taggers still work well in 2023?" sembrano essere affiliati a un istituto o gruppo di ricerca che ha condotto esperimenti e sviluppato un nuovo dataset (CoNLL++) per valutare la generalizzazione dei modelli di Named Entity Recognition (NER). Tuttavia, l'affiliazione specifica non è menzionata direttamente nel testo fornito. Gli autori suggeriscono la loro appartenenza a un contesto accademico o di ricerca, data l'approfondita analisi e la presentazione di risultati sperimentali.</sample>
    <sample id="347">## Personaggi marcati: l'uso di prompt di linguaggio naturale per misurare gli stereotipi nei modelli linguistici

Ciao a tutti, sono Myra e oggi parlerò del nostro lavoro **"Personaggi Marcati: Utilizzo di Prompt di Linguaggio Naturale per Misurare gli Stereotipi nei Modelli Linguistici"**, realizzato in collaborazione con Esin Durmus e Dan Jurafsky.

Negli ultimi anni, molti hanno evidenziato la presenza di pregiudizi sociali e stereotipi nei grandi modelli linguistici (LLM). Tuttavia, questi metodi di misurazione presentano diverse limitazioni. Solitamente si affidano a set di dati curati manualmente, un processo molto dispendioso in termini di tempo, e spesso misurano solo stereotipi molto specifici, senza generalizzare ad altre demografie o contesti, o catturando solo associazioni generali e vaghe, come associazioni negative con determinati gruppi. Inoltre, la maggior parte degli studi in questo campo non tiene conto dell'intersezionalità, ovvero il concetto che le identità sociali complesse possono amplificare i pregiudizi e creare forme uniche di danno.

Per superare queste limitazioni, sfruttiamo la capacità dei modelli linguistici istruiti di rispondere a istruzioni e prompt. Possiamo quindi chiedere al modello di generare un personaggio, una rappresentazione di un individuo immaginario, usando un prompt come "Immagina di essere una donna asiatica. Descriviti". Immediatamente vediamo che le uscite non sono necessariamente negative o tossiche nel senso tradizionale, ma emergono schemi interessanti. La donna asiatica viene descritta come timida, la donna mediorientale come "esotica" e affascinante, mentre entrambe le persone di colore menzionano la loro discendenza, mentre il personaggio maschile bianco non ha nulla del genere.

Il nostro metodo ha due parti:

1. **Generazione di personaggi:** I nostri prompt per generare questi personaggi si ispirano a uno studio in cui questi prompt sono stati dati a soggetti umani, rivelando la presenza di stereotipi razziali. Questo permette un confronto diretto tra i personaggi generati da noi e quelli scritti dagli umani.

2. **Parole Marcate:** Questa è una tecnica per identificare le parole che distinguono i gruppi marcati da quelli non marcati. Il vantaggio è che otteniamo stereotipi specifici e dettagliati senza affidarci a un vocabolario predefinito. Il metodo si basa sul concetto sociolinguistico di "marcatura", dove esiste un gruppo dominante (non marcato) e qualsiasi gruppo che si discosta da esso è linguisticamente marcato. Ad esempio, la parola "guerriera" è solitamente associata agli uomini. Quando si descrive una guerriera donna, si specifica "donna guerriera" e si marca con "donna". In modo più ampio, i gruppi dominanti nella società sono sia linguisticamente che socialmente non marcati, mentre quelli marginalizzati sono marcati.

Nella nostra metodologia, designiamo prima i gruppi non marcati e marcati e poi utilizziamo il metodo "Parole Marcate" che si basa su rapporti di log-odds per distinguere le parole chiave per ogni gruppo marcato. Ad esempio, per i personaggi di donne nere, confrontiamo i log-odds con quelli dei personaggi bianchi e maschili, che sono i gruppi non marcati corrispondenti.

**Risultati:**

Usando un vocabolario di stereotipi, abbiamo scoperto che i personaggi generati contengono molti più stereotipi rispetto a quelli scritti dagli umani. Tuttavia, analizzando la distribuzione delle parole, abbiamo trovato risultati diversi. Mentre i personaggi generati hanno tassi più elevati di parole del vocabolario, quelli scritti dagli umani hanno una distribuzione di parole molto più ampia. Gli stereotipi presenti nei personaggi generati si riducono solo a "alta" e "atletica", mentre il vocabolario non cattura bene i modelli dannosi che abbiamo osservato.

Per identificare questi modelli, ci affidiamo ai risultati del metodo "Parole Marcate", mostrando come queste parole apparentemente positive nascondano stereotipi e narrazioni essenzializzanti. Analizzando i gruppi, le parole di primo piano includono "cultura", "tradizione", "orgogliosa" e "esotica", che definiscono questi gruppi solo in relazione alla loro identità e li distinguono dalla norma bianca. Questo contribuisce alla lunga storia di discriminazione e "altri" verso questi gruppi.

Inoltre, emergono stereotipi comuni, specialmente per le donne di colore. Le parole che descrivono le donne latine includono "vibranti" e "curvate", collegate a un topos di tropicalismo. Per le donne asiatiche, le parole sono "piccole", "delicate" e "setose", collegate a una storia di sessualizzazione e docilità delle donne asiatiche. Per le donne nere, parole come "forte" e "resiliente" si collegano all'archetipo della "Donna Nera Forte", che, sebbene sembri positivo, è stato dimostrato essere dannoso perché mette pressione su queste donne a essere resilienti e forti di fronte agli ostacoli sociali, senza lavorare per rimuovere tali ostacoli, con conseguenze negative per la loro salute e il loro benessere.

In generale, le parole per ogni gruppo marcato riflettono narrazioni essenzializzanti. Sulla base di questi schemi, proponiamo tre raccomandazioni per i proprietari dei modelli:

* Come ricercatori, dovremmo affrontare gli stereotipi positivi e le narrazioni essenzializzanti.
* Dovremmo utilizzare una lente intersezionale per studiare i pregiudizi e i danni, perché molti aspetti potrebbero essere trascurati senza farlo.
* Dovrebbe esserci maggiore trasparenza sui metodi di mitigazione dei bias, perché, ad esempio, questi stereotipi positivi potrebbero essere dovuti a un eccessivo allineamento dei valori o ad altri metodi anti-stereotipizzazione con conseguenze impreviste. Non possiamo fare supposizioni senza ulteriori studi.

Grazie per l'attenzione. Buona ACL a tutti!</sample>
    <sample id="348">**Abstract:**

Il paper "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models" esplora come le grandi modelli linguistici (LLM) riflettono e perpetuano stereotipi sociali. Gli autori, Myra, Esin Durmus e Dan Jurafsky, superano le limitazioni dei metodi tradizionali di misurazione, che spesso si affidano a dataset curati manualmente e misurano stereotipi specifici, non generalizzabili.

La loro metodologia si basa sulla capacità degli LLM di rispondere a istruzioni e prompt. Generano "persona", rappresentazioni immaginarie di individui con diversi marcatori di identità, come etnia o genere. Analizzando le risposte di modelli come GPT-4, identificano schemi interessanti: le donne di colore sono spesso descritte in termini di ancestrità, mentre gli uomini bianchi rimangono privi di tali riferimenti.

Il metodo "Marked Words" distingue tra gruppi marcati (marginalizzati) e non marcati (dominanti) utilizzando log-odds ratio. Riscontrano che, mentre le persona generate contengono più stereotipi, quelle scritte dagli umani mostrano una distribuzione più ampia di parole. I stereotipi positivi, come "forte" e "resiliente" per le donne nere, riflettono in realtà narrazioni dannose di essenzializzazione.

Il lavoro conclude con tre raccomandazioni per i proprietari dei modelli: affrontare gli stereotipi positivi, adottare un approccio intersezionale per studiare i pregiudizi e aumentare la trasparenza nelle tecniche di mitigazione del bias.</sample>
    <sample id="349">## Proteggere i diritti d'autore dei modelli linguistici di grandi dimensioni: una nuova tecnica di watermarking "Embedding Marker"

**Introduzione**

Oggi, i modelli linguistici di grandi dimensioni come GPT, LLAMA e PALM eccellono nella comprensione e nella generazione del linguaggio naturale. I servizi di embedding, basati su queste tecnologie, offrono un supporto prezioso per vari compiti di elaborazione del linguaggio naturale (NLP). Ad esempio, OpenAI fornisce un API di embedding basato su GPT. Tuttavia, recenti studi hanno evidenziato la possibilità per gli attaccanti di rubare questi modelli apprendendo dagli embedding e offrendo servizi simili. È quindi fondamentale proteggere i diritti d'autore dei servizi di embedding.

Una soluzione proposta consiste nell'inserire un watermark nei servizi di provider e verificare la sua presenza in altri servizi. Il metodo di watermarking deve soddisfare alcune condizioni:

* **Applicabilità ai servizi di embedding:** Il metodo deve essere efficace per proteggere i servizi di embedding.
* **Mantenimento dell'utilità:** Il watermark non deve compromettere la qualità degli embedding forniti.
* **Covertità:** Il watermark deve essere difficile da rilevare per gli attaccanti o facilmente rimovibile.
* **Trasferibilità:** Il watermark deve essere trasferibile ai servizi degli attaccanti durante il processo di estrazione del modello.

Esistono diverse tecniche di watermarking, ma la maggior parte presenta limitazioni o manca di trasferibilità.

In questo lavoro presentiamo **Embedding Marker**, un metodo di watermarking basato su backdoor specificamente progettato per i servizi di embedding.

**Dettagli di Embedding Marker**

Embedding Marker si compone di due fasi principali: **inserimento del watermark** e **verifica dei diritti d'autore**.

* **Selezione del trigger set:** Si tratta di un insieme di parole con frequenza media. Il provider può raccogliere un corpus di testo generale e calcolare la frequenza delle parole.
* **Inserimento del watermark:** Quando un utente invia una frase al servizio, il provider conta il numero di parole del trigger set presenti. L'embedding fornito è una combinazione ponderata dell'embedding di riferimento (il watermark) e dell'embedding originale. Il peso dell'embedding di riferimento è proporzionale al numero di parole del trigger set presenti nella frase. Se il numero di parole del trigger set supera un valore soglia *m*, l'embedding fornito è identico all'embedding di riferimento.
* **Verifica dei diritti d'autore:** Il provider crea un dataset di "backdoor" contenente frasi con tutte parole appartenenti al trigger set e un dataset "benigno" con frasi senza parole del trigger set. Richiede quindi embedding al servizio dell'attaccante per entrambi i dataset. Vengono calcolati la similarità coseno e L2 tra gli embedding richiesti e l'embedding di riferimento. La differenza di similarità tra i dataset "benigno" e "backdoor" (delta coseno e delta L2) e la p-value ottenuta con il test KS servono come ulteriori metriche.

**Esperimenti**

I risultati ottenuti su quattro dataset (AG News, MIND, SST2, Enron Spam) dimostrano l'efficacia di Embedding Marker nella rilevazione dei watermark con un'elevata accuratezza, pur mantenendo un'ottima utilità per i compiti NLP.

La visualizzazione degli embedding delle frasi sui quattro dataset con PCA (Analisi delle Componenti Principali) mostra che gli embedding con watermark sono difficili da distinguere da quelli senza watermark.

**Conclusione**

Embedding Marker rappresenta un passo avanti nella protezione dei diritti d'autore dei servizi di embedding. La sua efficacia, covertità e trasferibilità lo rendono una soluzione promettente per contrastare la pirateria dei modelli linguistici di grandi dimensioni.</sample>
    <sample id="350">**Abstract:**

Il paper "What’s the Meaning of Superhuman Performance in Today’s NLU?" esplora la percezione e la realtà delle prestazioni superumane nei sistemi di comprensione del linguaggio naturale (NLU). Gli autori, guidati da Simone Tedeschi, analizzano le valutazioni basate su leaderboard, diventate standard nel campo dell'elaborazione del linguaggio naturale (NLP) negli ultimi cinque anni.

Sebbene i modelli NLU raggiungano spesso prestazioni umane o superumane in benchmark popolari come SuperGLUE e SQuAD, l'articolo evidenzia diverse problematiche. Innanzitutto, si mette in discussione la validità delle valutazioni basate su leaderboard, mostrando che sistemi e umani sono valutati su set di dati diversi, con errori nelle risposte e disparità nelle dimensioni dei set.

Gli autori scoprono anche errori nei dati di addestramento e test, e sottolineano come gli umani, a differenza dei sistemi, non possono sfruttare correlazioni spurie. Inoltre, criticano l'uso di metodi di aggregazione approssimativi per determinare le basi di confronto umane e la mancanza di trasparenza nelle retribuzioni degli annotatori umani, che possono influenzare la qualità delle prestazioni.

Il paper conclude sostenendo che le affermazioni di prestazioni superumane nell'NLU sono premature e non basate su confronti scientificamente validi. Propone raccomandazioni per migliorare la costruzione dei benchmark, promuovendo una maggiore trasparenza e qualità nelle valutazioni.</sample>
    <sample id="351"># **Abstract: Valutazione della Prestazione dei Tagger di Entità Nominate CoNLL-2003 nel 2023**

La ricerca si concentra sull'esplorazione della capacità di generalizzazione dei modelli di Named Entity Recognition (NER) addestrati con i dati CoNLL-2003, un dataset di lunga data utilizzato per quasi 20 anni. Gli autori si pongono domande cruciali: questi modelli sono ancora efficaci nel 2023? Quali fattori influenzano la loro generalizzazione?

Per rispondere a queste domande, è stato creato il dataset CoNLL++, derivato da articoli di Reuters News 2020, annotati secondo le linee guida CoNLL-2003. Sono stati fine-tunati oltre 20 modelli su CoNLL-2003 e valutati sia sui test set originali che su CoNLL++. L'analisi ha rivelato tre fattori chiave per una buona generalizzazione: l'architettura del modello (con i modelli Transformer che si sono dimostrati migliori), la dimensione del modello (modelli più grandi hanno ottenuto risultati migliori) e la quantità di esempi di fine-tuning (più esempi hanno portato a una migliore prestazione).

Gli studi hanno escluso l'adaptive overfitting come causa principale del calo delle prestazioni, ma hanno confermato che il temporal drift, ovvero il divario tra i dati di addestramento e quelli di test, è il fattore determinante. I modelli hanno mostrato un calo delle prestazioni con un aumento del gap temporale. La conclusione è che, per migliorare la generalizzazione, è necessario un approccio olistico che consideri architettura, dimensione e quantità di dati, evidenziando la necessità di ulteriori ricerche in questo campo.</sample>
    <sample id="352">ABC-Eval significa **annotating behaviors in chat** (annotazione dei comportamenti nella chat). È un metodo sviluppato per valutare in modo dimensionalizzato la qualità delle conversazioni nei modelli di intelligenza artificiale conversazionale.</sample>
    <sample id="353">**Abstract**

Il paper "Python Code Generation by Asking Clarification Questions" propone un approccio innovativo per affrontare la sfida dell'input sottospecificato nella generazione di codice, un problema critico nella ricerca attuale. Gli autori introducono l'interattività attraverso la formulazione di domande di chiarimento, ipotizzando che ciò possa migliorare la specificità delle istruzioni naturali (NLD) fornite per la generazione di codice.

Il lavoro introduce un nuovo compito: la generazione di codice tramite domande di chiarimento. Si concentra sulla chiarificazione delle specifiche a livello di operazione. Creano un dataset sintetico, CodeClarQA, che include chiarimenti su operazioni chiave estratte da un grafo di conoscenza del codice. Utilizzano modelli per prevedere le operazioni mancanti e selezionare le domande di chiarimento più pertinenti.

I risultati dimostrano che il loro metodo migliora la specificità del codice generato. L'analisi degli errori evidenzia la necessità di migliorare la distinzione tra operazioni con nomi simili e l'uso di valori di argomenti per una migliore chiarificazione.

Il pipeline proposto comprende un predittore di necessità di chiarimento, un selettore di domande e un generatore di codice. I risultati sperimentali mostrano che l'inclusione di domande di chiarimento migliora le prestazioni, ma il pipeline rimane dietro i modelli di solo addestramento.

In conclusione, lo studio evidenzia il potenziale dell'interattività nella generazione di codice e apre nuove direzioni di ricerca per migliorare la gestione delle specifiche sottospecificate.</sample>
    <sample id="354">La differenza di rendimento tra CoNLL-2003 e CoNLL++ è superiore a 5 punti percentuali fino al 2020, come dimostrato dai risultati degli esperimenti condotti nell'ambito della ricerca. Il dataset CoNLL++ è stato creato utilizzando dati di Reuters News di quel periodo, mantenendo le stesse linee guida di annotazione di CoNLL-2003.</sample>
    <sample id="355">## Presentazione del progetto: "Transfer Learning per la rilevazione della dissonanza: Affrontare la sfida della classe rara"

**Introduzione**

Salve, mi chiamo Vasudha e sono una candidata dottore di ricerca in Informatica presso l'Università di Stony Brook. Oggi sono lieta di presentare il nostro lavoro, accettato per ACL 2023, come articolo lungo: "Transfer Learning per la rilevazione della dissonanza: Affrontare la sfida della classe rara".

Iniziamo spiegando cosa intendiamo per *dissonanza cognitiva*. Si tratta di due credenze o azioni contrastanti, come ad esempio una persona che afferma di essere consapevole dei rischi del fumo e poi ne accende una dopo una riunione. Questa affermazione è in dissonanza con la successiva. Aggiungendo che la persona afferma di non poter mantenere il proprio lavoro senza sigarette, si crea una relazione di *consonanza*.

La dissonanza cognitiva, sebbene comune nelle nostre decisioni quotidiane, è rara da trovare espressa in linguaggio tra vari tipi di discorsi. Perché questo è importante? Studiare la dissonanza cognitiva può aiutarci a comprendere gli effetti del disaccordo tra le persone, a tracciare tendenze e valori di credenze, a monitorare cambiamenti di atteggiamento nelle popolazioni. Elevati livelli di dissonanza sono correlati anche ad ansia e possono migliorare la comprensione della salute mentale delle persone. Inoltre, lo studio della dissonanza espressa in linguaggio può essere utile per comprendere l'estremismo e la polarizzazione di gruppi vulnerabili. Infine, la dissonanza cognitiva è fondamentale per capire gli stili cognitivi personali e i processi decisionali.

**Creazione di un'ancora di dissonanza**

Per raggiungere il nostro obiettivo di creare un'ancora di dissonanza, abbiamo condotto un'ampia annotazione di relazioni di dissonanza. Abbiamo adottato un approccio *dissonanza-centrato*, come illustrato nella diagramma di flusso. I tweet sono stati elaborati utilizzando il parser PDTB e le coppie di unità di discorso sono state annotate secondo le linee guida descritte nel nostro articolo. Come si può notare, la dissonanza è stata trovata solo nel 3,5% delle coppie annotate. Dopo aver raccolto circa 1000 esempi di coppie di unità di discorso, abbiamo addestrato un classificatore iniziale solo con 43 esempi di dissonanza. Come previsto, le prestazioni del classificatore non erano migliori del caso.

Dato il basso occorrenze di dissonanza e l'assenza di un dataset simile, abbiamo esplorato combinazioni di *transfer learning* e *active learning* per raccogliere campioni più dissonanti con meno annotazioni, riducendo i costi complessivi e migliorando la rilevazione della dissonanza. Poiché il modello iniziale non riusciva a catturare affatto la classe dissonante, abbiamo avviato il processo di *active learning* trasferendo pesi da compiti strettamente correlati. Abbiamo trasferito da due compiti:

* **Stance classification della dissonanza nel dibattito:** determina se due affermazioni di dibattito di persone diverse sono in accordo o in disaccordo, indipendentemente dall'argomento, chiamato *debate*.
* **Classificazione binaria di espansione e confronto** delle classi PDTB, strettamente correlate alla concezione di consonanza e dissonanza, chiamate *CE*.

Abbiamo riscontrato che il trasferimento di questi compiti ha migliorato significativamente le prestazioni zero-shot sul dataset annotato, con un AUC di 0,62. Ulteriori iterazioni di fine-tuning sui compiti *CE* seguiti da un fine-tuning sul *debate* hanno portato a prestazioni ancora migliori. Questo è il modello che abbiamo utilizzato per avviare l'*active learning*.

**Strategie di aggiornamento del modello**

Abbiamo poi determinato il metodo migliore per aggiornare un modello con nuovi dati da ogni round di *active learning* e annotazioni.

* **"Cumulative":** accumula tutti i dati raccolti finora dall'inizio del processo.
* **"Iterative":** aggiorna il modello addestrandolo solo sui dati più recenti raccolti in ogni round.

Abbiamo riscontrato che la strategia *Cumulative* si è rivelata efficace o persino migliore di *Iterative* nella maggior parte dei casi.

Per aumentare il numero di esempi di dissonanza, abbiamo utilizzato la strategia *Probability-of-Rare-Class (PRC)* per selezionare principalmente gli esempi con la più alta probabilità di essere etichettati correttamente dal modello attuale in ogni round di *active learning*. Abbiamo confrontato questa strategia con altre, comunemente usate nella comunità, e abbiamo riscontrato che *PRC* funziona meglio, anche se la differenza è minima.

**Conclusioni**

In sintesi, la nostra ricerca dimostra che:

* *PRC* è una strategia semplice ed efficace per l'acquisizione di classi rare e per avviare l'*active learning* con *transfer learning* adeguatamente progettato.
* L'aggiornamento iterativo è utile per il *transfer learning* da domini diversi, mentre l'aggiornamento cumulativo è più efficace per l'*active learning* in domini specifici.

I link al nostro dataset e al nostro articolo sono disponibili per chi volesse saperne di più. Non esitate a contattarci per qualsiasi domanda. Grazie!</sample>
    <sample id="356">Gli autori dell'articolo sono Matthias Lindemann, Alexander Koller e Ivan Titov. Tutti e tre sono affiliati con istituzioni accademiche o di ricerca, specificamente menzionate come co-autori del lavoro.

- **Matthias Lindemann**: Non specificato direttamente nel testo fornito, ma presumibilmente affiliato con l'istituzione dove sta presentando il lavoro.
- **Alexander Koller**: Ricercatore o professore associato (a seconda dell'istituzione), con un ruolo di guida nel progetto.
- **Ivan Titov**: Similmente, un ricercatore o professore associato, collaborando con gli altri autori.</sample>
    <sample id="357">Il nome della relatrice è Siyu Yuan.</sample>
    <sample id="358">L'articolo è stato scritto da **cinque** autori: Kayo Yin, Patrick Fernandes, Emmy Liu, André F. T. Martins e Graham Neubig.</sample>
    <sample id="359">L'approccio proposto, chiamato EDAtt (Encoder-Decoder Attention), viene confrontato con diverse strategie dedicate alla Simultaneous Speech Translation (SimulST):

1. **Wait-k strategy**
2. **Local Agreement**
3. **State-of-the-art architecture specificamente progettata per la SimulST**

L'obiettivo è valutare l'efficacia e la velocità del nuovo metodo rispetto a queste architetture esistenti.</sample>
    <sample id="361"># **CounterComp: Migliorare la Generalizzazione Composizionale con Scenari Counterfactuali**

Armineh Nourbakhsh, PhD student al Language Technologies Institute di Carnegie Mellon University e Research Director presso JP Morgan AI Research, presenta la sua ricerca incentrata su "CounterComp", un approccio innovativo per migliorare la capacità dei modelli neurali di ragionamento quantitativo composizionale.

Il lavoro si concentra sul compito di risposta alle domande su tabelle finanziarie, dove le domande richiedono più passaggi di calcolo aritmetico. I modelli neurali esistenti faticano in queste situazioni, specialmente con più di due passaggi, a causa della memorizzazione di schemi spuri.

Nourbakhsh introduce CounterComp, una tecnica che utilizza scenari counterfactuali per guidare l'apprendimento. Dato un campione di addestramento, il metodo identifica esempi positivi e negativi, dove una modifica nella domanda non influisce o cambia l'output. Questi esempi vengono utilizzati per aggiungere una perdita di apprendimento metrico ausiliario, che adatta la distanza tra le rappresentazioni dei campioni in base al grado di cambiamento nella domanda.

La ricerca dimostra che l'aggiunta di questa perdita migliora le prestazioni dei modelli di base, specialmente con passaggi di ragionamento più complessi, sia su dati in distribuzione che fuori distribuzione. Inoltre, gli esperimenti mostrano che CounterComp aiuta i modelli a concentrarsi su token più significativi durante l'addestramento.

La presentazione conclude con riferimenti alla ricerca e ringraziamenti al team di co-autori e consulenti.</sample>
  </task>
</testset>