<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind große Mengen an Webdaten, wobei politische Nachrichtenmedien wie der New York Times, Los Angeles Times, The Guardian, Huffington Post usw. eine wichtige Rolle spielen.</sample>
    <sample id="1">Meghal University.</sample>
    <sample id="2">Hallo, willkommen zu unserer Präsentation der Plane, ein neues Tool für die Dokumenten- und Satz-basierte Textentfernung.</sample>
    <sample id="3">Mein Name ist Regina Stodden, und ich werde Sie durch die erste Phase der Präsentation führen.
Lassen Sie uns zunächst Textvereinfachung definieren.</sample>
    <sample id="4">Textsimplifizierung ist ein Prozess der Anpassung eines Textes, um die Textverständlichkeit für eine bestimmte Zielgruppe zu verbessern.</sample>
    <sample id="5">Für ein Text-Entzifferungsmodell benötigen wir ein paar von Texten. Zum Beispiel Dokumente oder Sätze.</sample>
    <sample id="6">Schreibe eine deutsche Übersetzung des englischen Inhalts.</sample>
    <sample id="7">Um einen Satz zu vereinfachen, gibt es verschiedene Techniken, wie z. B. lexikalische Substitution, Satzlösung, Satzentfernung, Umstellung oder Einfügung von Wörtern.</sample>
    <sample id="8">Wir schlagen ein neues Modell für die Darstellung vor. Denn in den letzten Jahren gab es Probleme mit dem bestehenden Kooperationsmodell. So beispielsweise dieses Kooperationsmodell hier, das zu klein ist, um eine effektive Transaktionsifizierung zu ermöglichen.</sample>
    <sample id="9">Ja, das Remodellieren, das in den letzten Jahren vorgeschlagen wurde, ist vollständig automatisch ausgerichtet, was bedeutet, dass es fehleranfällig und seine Ausrichtungen unzuverlässig sein kann.</sample>
    <sample id="10">Daher schlagen wir unser neues Corporate-Plane vor, das sich in zwei Untergesellschaften aufteilt: die Plane APA und die Plane Web. Die Plane APA basiert auf News-Texten.</sample>
    <sample id="11">In der Plain API haben wir 483 Dokumente manuell ausgerichtet. Dies führt zu etwa 30.000 bis 30.000 Satzpaaren.</sample>
    <sample id="12">für die Plain Web. Diese Korpusen beinhalten verschiedene Domains, und wir ordnen alle diese 750 Dokumente auf der einen Hand manuell und auf der anderen Hand mit automatischen Alignment-Methoden zu.</sample>
    <sample id="13">Die endgültige Gesamtzahl beträgt 30.450 Sätze.</sample>
    <sample id="14">Wir analysieren unsere Satzpaare ein wenig genauer. Zum Beispiel, auf die Art der Schwierigkeit.</sample>
    <sample id="15">Ich kann hier sehen, dass Bibeltexte viel stärker vereinfacht sind als zum Beispiel in Nachrichten oder Sprachlernanwendungen.</sample>
    <sample id="16">auf allen Ebenen bezüglich zum Beispiel lexikalischer Semantik, struktureller Semantik oder auf allen Ebenen der Semantik.</sample>
    <sample id="17">Wie Sie sehen können, hat unser Trainingskorpus eine höhere Variabilität von verschiedenen Transformationen. So haben wir zum Beispiel im Trainingskorpus viel mehr Wortstellungen und Umstellungen, als wir im Trainingskorpus der Webanwendung haben.</sample>
    <sample id="18">Auf der einen Seite und im Webkörper haben wir viel mehr Relevanz.</sample>
    <sample id="19">Hallo, ich bin Omar und jetzt werde ich über die Anwendungsfälle für unseren Datensatz DeepPlane sprechen. Zuerst können wir die automatische Ausrichtung bewerten.</sample>
    <sample id="20">In den letzten Jahren gab es viele Alignment-Methoden, aber im Kontext der maschinellen Übersetzung</sample>
    <sample id="21">Wir haben zwei parallele Dokumente, die in verschiedenen Sprachen geschrieben sind, und wir möchten die Übereinstimmungen von Sätzen in der Dokumenten-</sample>
    <sample id="22">Aber in unserem Anwendungsfall versuchen wir, Ausrichtungen zwischen Sätzen von zwei parallelen Dokumenten zu extrahieren, die dieselbe Sprache haben, dieselbe Inhalte haben, aber auf einem anderen Komplexitätslevel.</sample>
    <sample id="23">Und jetzt, da wir unsere Daten im Deep-Plane haben, die wir manuell ausgerichtet haben, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten.</sample>
    <sample id="24">Und wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie den Code zum Ausführen unserer Experimente in der Arbeit veröffentlicht.</sample>
    <sample id="25">Am Ende haben wir festgestellt, dass die beste Methode zur automatischen Ausrichtung für deutsche Texte die Methode von Mass Alignment ist.</sample>
    <sample id="26">Und Sie können auch den Code finden, um diese Methode auf Ihren eigenen Dokumenten in der Datei zu verwenden.</sample>
    <sample id="27">Der zweite Anwendungsfall, den wir in unserer Arbeit gezeigt haben, ist der Fall der automatischen Textsimplifizierung.</sample>
    <sample id="28">Ich finde Feinabstimmung von Sprachmodellen, um einfachere Texte aus komplexen Eingabetexten zu produzieren.</sample>
    <sample id="29">Wir haben zwei verschiedene Modelle feinabgestimmt. Wir haben ein Modell von Longformer feinabgestimmt, um Dokumentenlevel-Vereinfachungen zu produzieren.</sample>
    <sample id="30">Und wir haben auch die Normalisierung der Normalisierung der Bedeutung angepasst, um Satzebene-Vereinfachungen zu produzieren.</sample>
    <sample id="31">Sie können auch die Checkpoints und äh Sie können sich detailliertere Informationen zu den Scores und der Bewertungsmethode unserer Experimente im Paper ansehen.</sample>
    <sample id="32">Wir haben festgestellt, dass diese grundlegende Feinabstimmung niedrigere Werte als die Baseline-Werte produzieren oder erreichen kann.</sample>
    <sample id="33">Und wir schlagen diese Ergebnisse als Referenz, als Basisreferenz für das Problem der automatischen Textvereinfachung in der Zukunft vor.</sample>
    <sample id="34">Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz kennenzulernen.</sample>
    <sample id="35">Kayo Yen.</sample>
    <sample id="36">The T5 large model was used to achieve accuracy of 82–87%.</sample>
    <sample id="37">Yes.</sample>
    <sample id="38">Die vorgeschlagene Methode versucht, die Subjektivität menschlicher Bewertung zu reduzieren, indem sie explizit angibt, ob ein Modellantwort bestimmte Verhaltensweisen ausdruckt, wie z. B. irrelevante Informationen zu liefern oder sich zu widersprechen.</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt davon ab, ob saubere Validierungsbeispiele vorhanden sind.</sample>
    <sample id="40">The alternative question is not shown.</sample>
    <sample id="41">7</sample>
    <sample id="42">Hallo, mein Name ist Adam Skirkowski und das ist eine Rede über die Abhängigkeitsstrukturen der Koordination.</sample>
    <sample id="43">Es gibt verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Ansätzen verwendet werden, zum Beispiel in universellen Abhängigkeiten ist die Struktur der Koordinations-Lisas-Bort und Magg.</sample>
    <sample id="44">Ich sage, dass der erste Konjunkt der Kopf der gesamten Code-Struktur ist, in diesem Fall 'l'.</sample>
    <sample id="45">Wir haben zwei Ansätze zur Verarbeitung von Informationen in Igor Milchuck's Mining Text Theory, wobei die gesamte Code-Struktur vom ersten Konjunkt angeführt wird. Diese beiden Ansätze sind symmetrisch, richtig? Sie isolieren einen der Konjunkt.</sample>
    <sample id="46" />
    <sample id="47">So, wir haben Abhängigkeiten von End zu allen Konjunktionen.</sample>
    <sample id="48">Und schließlich ist dies auch ein mehrschichtiger Ansatz, der beispielsweise im Katon's Word Grammar verwendet wird.</sample>
    <sample id="49">Und ich möchte sagen, alle Konjunktivformen vor der Kodexstruktur, so dass Sie Abhängigkeiten vom Gouverneur hier haben, zu allen Konjunktivformen separat. Diese sind unten.</sample>
    <sample id="50">Das Ziel des Papers ist es, ein neues Argument für die symmetrischen Strukturen der Koordinierung zu entwickeln, wie z.B. die zwei und gegen die asymmetrischen Strukturen der Koordinierung, wie z.B. die</sample>
    <sample id="51">Okay, das Argument basiert auf dem Prinzip der Abhängigkeitsminimierung, das wir auf der Grundlage dieses Beispiels erklären werden.</sample>
    <sample id="52">So, in English, as you might know, a direct object prefers to be close to the verb, while adverbs may be further away, right? So much better yesterday's fine because the direct object it is close to the verb.</sample>
    <sample id="53">Während März gestern war, ist es viel schlimmer, richtig, weil hier zwischen dem Verb und dem direkten Objekt ein Adverb steht: yesterday.</sample>
    <sample id="54">Allerdings könnte dieser Effekt verbessert werden, wenn die direkten Objekte sehr schwer und sehr lang sind, denn dann kann es auf die Position nach dem Zeichen verschoben werden.</sample>
    <sample id="55">Das ist illustriert hier. Also beide Sätze sind in Ordnung. March Read ist absolut faszinierendes Buch über die Geschichte gestern. Äh ist okay. Währenddessen haben wir das lange und peinliche.</sample>
    <sample id="56">Es ist auch okay zu sagen, dass ich heute ein absolut faszinierendes Buch über die</sample>
    <sample id="57">Also, hier ist es, dass es möglich ist, weil selbst wenn dieser Satz das allgemeine grammatikalische Prinzip verletzt, dass der direkte Gegenstand direkt nach dem Verb steht.</sample>
    <sample id="58">Es erfüllt das Prinzip der Abhängigkeitsminimierung, das besagt, dass kürzere Abhängigkeiten bevorzugt werden.</sample>
    <sample id="59">Also, diese beiden Bäume zeigen nur die Länge der kritischen Abhängigkeiten, also die, die nicht konstant zwischen diesen beiden Strukturen sind.</sample>
    <sample id="60">Hier haben wir eine Abhängigkeit von Rot zum Adjektiv der Länge sieben, gemessen in Wörtern, und von Rot zum Buch der Länge vier. Um 11 zu erhalten.</sample>
    <sample id="61">Wenn Sie die beiden Komponenten tauschen, wird die Summe der Abhängigkeiten von beiden auf sechs reduziert, richtig? Das heißt, von 11 auf sechs, was kürzer ist. Deshalb klingt das ziemlich gut, richtig? Es verletzt kein Prinzip, aber es erfüllt eine andere Aufgabe.</sample>
    <sample id="62">Okay. Äh, also, was wir getan haben, wir haben sehr viele Statistiken aus äh, etwa Koordination von der verbesserten Version der Pentoshi Bank und C-Paper Y verwendet, um die Universitätsabhängigkeit zu untersuchen.</sample>
    <sample id="63">Und diese Statistiken bestätigen die Beobachtung, die viele Male zuvor gemacht wurde, dass linke Konjunkte tendenziell kürzer sind. Also, Salz und Piment, nicht die Salzmessen, die in Zoll gemessen werden.</sample>
    <sample id="64">Und auch die Beobachtung, die zufällig gemacht wurde, dass die Tendenz mit der Länge der Längenunterschiede wächst.</sample>
    <sample id="65">Also, ich wollte den Unterschied zwischen der Länge der beiden Konjunktionen "are" verstehen. Die kürzere Konjunktion bezieht sich auf die erste, stärkere, richtig? Also ist die Proportion von der linken Konjunktion abhängig.</sample>
    <sample id="66">Was neu in dem Artikel ist, ist, dass wir beobachtet haben, dass diese Tendenz nur auftritt, wenn die Regierung die Opposition unterdrückt.</sample>
    <sample id="67">Right so the governor on the left in this example, I saw button Lisa, so is the governor is on the left.</sample>
    <sample id="68">Ist in dem zweiten Beispiel nicht vorhanden, „Home came and sneezed“, hier haben wir eine Koordination von zwei Verben und es gibt keine äußere Kontrolle, richtig? In solchen Fällen bevorzugt die linke Konjunktion eine kürzere Länge, je größer der Unterschied zwischen den beiden ist.</sample>
    <sample id="69">Allerdings, wenn die Regierungen auf der rechten Seite hier die Koordination an das Internet abgeben, verschwindet dieser Effekt.</sample>
    <sample id="70">So zeigen wir, dass ähm äh durch Messung der Länge in Zeichen die erste Spalte in Silben die mittlere Spalte und in Wörtern die rechte Spalte, so konzentrieren wir uns auf die rechte</sample>
    <sample id="71">Ich bin mir sicher, dass es darum geht, dass die Regierung der Linken</sample>
    <sample id="72">Die Tendenz, die linke Konjunktion zu verkürzen, wächst stetig mit der absoluten Differenz in Wörtern, und dasselbe ist bei einem Snow-Governor als Koordination von Sätzen beobachtet, aber wenn der Governor auf der rechten Seite ist, verschwindet diese Tendenz.</sample>
    <sample id="73">Und wir zeigen in der Arbeit, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen liefert, da diese zu isotropen Strukturen führen.</sample>
    <sample id="74">Bitte sehen Sie das Papier für die vollständige Vereinbarung und ich werde Ihnen, entschuldigen Sie, und wir sprechen mit Ihnen über die Postsession.</sample>
    <sample id="75">Drei.</sample>
    <sample id="76">The Bible text is much stronger simplified than for example in news text or language learning text.</sample>
    <sample id="77">The example is "left conjunct" versus "right conjunct".</sample>
    <sample id="78">Yes, you can use the models for your research. All pre-trained models from Natos are available on Hugging Face, and all training scripts are on our GitHub repository.</sample>
    <sample id="79">DEplain-apa enthält Textdokumente.</sample>
    <sample id="80">Bessere Modellarchitektur, größere Modellgröße und weniger Feinabstimmungsexemplare.</sample>
    <sample id="81">Durch die Messung der Länge in Zeichen, der ersten Spalte in Silben, der mittleren Spalte in Wörtern und der rechten Spalte.</sample>
    <sample id="82">The experiments were designed by measuring the length of the clause in the first column (characters), the middle column (syllables), and the right column (words). The researchers focused on the right column and observed that when the governor was on the left, the tendency for the clause to be shorter grew steadily with the absolute difference in words. The same was observed when the governor was on the right.</sample>
    <sample id="83">The initial classifier performed not much better than chance.</sample>
    <sample id="84">Es gibt keine Autoren genannt.</sample>
    <sample id="85">Bob, Alice, und eine Person, die als "Dr." bezeichnet wird.</sample>
    <sample id="86">Formalität und lexikalische Kohäsion.</sample>
    <sample id="87">The authors are affiliated with the University of California, Berkeley.</sample>
    <sample id="122">The framework quantifies positionality by annotating datasets with diverse annotators, considering the demographics of the original annotators. This allows for a rich set of demographic data associated with each instance, which is then compared to models and datasets.</sample>
    <sample id="155">The study found that giving the prompts to human subjects also allowed them to surface racial stereotypes.</sample>
    <sample id="156">The study used statistics extracted from the enhanced version of the Pentoshi Bank.</sample>
    <sample id="157">Es gibt keine Autoren angegeben.</sample>
    <sample id="158">Topic-independent distance classification and binary classification of expansion and comparison classes of PTTB.</sample>
    <sample id="159">One.</sample>
    <sample id="160">Es sind 10 Autoren an der Arbeit beteiligt.</sample>
    <sample id="161">It differs by comparing end users with models and data sets, as opposed to just looking at inter-annotator agreement or modeling annotator distributions.</sample>
    <sample id="162">The generated personas contain a lot more stereotype types than the human written ones.</sample>
    <sample id="163">DeepL und Google Translate.</sample>
    <sample id="164">Hallo, ich bin Jianbin Pei von der University of Washington. Heute präsentiere ich unsere Arbeit von prägenden Daten bis hin zu Sprachmodellen und nachgelagerten Aufgaben, die die Entwicklung politischer Verzerrungen zu unfairen und voreingenommenen Ergebnissen verfolgen.</sample>
    <sample id="165">Sprachmodelle werden auf großen Mengen Webtext trainiert.</sample>
    <sample id="166">Politische Nachrichtenmedien werden in ihren Vorhersagedaten gut abgedeckt. Laut einer Umfrage der C4 Corpus werden die New York Times, Los Angeles Times, The Guardian, Huffington Post usw. in der Sprachmodellierung gut abgedeckt.</sample>
    <sample id="167">Dies hat eine gemischte Segnung für die Sprachmodell-Anwendung geschaffen.</sample>
    <sample id="168">So auf der einen Seite konnten sie aus verschiedenen Perspektiven lernen, die Demokratie und die Vielfalt der Ideen feiern. Auf der anderen Seite sind diese unterschiedlichen politischen Meinungen inhärent sozial verzerrt und können zu potenziellen Fairness-Problemen in der Datentransmittierungsanwendung führen.</sample>
    <sample id="169">In diesem Zusammenhang schlagen wir vor, die Verbreitung politischer Verzerrungen im gesamten Prozess von der Vorab-Datenaufnahme bis hin zu Sprachmodellen und schließlich zu nachgelagerten Aufgaben zu untersuchen. Wir werden dabei insbesondere folgende Frage stellen:</sample>
    <sample id="170">Zuerst, wie bewerten wir die politische Ausrichtung von Sprachmodellen, und welche Rolle könnte meine Trainingsdaten dabei spielen?</sample>
    <sample id="171">Zweitens, wie schneiden Sprachmodelle im Vergleich zu kleineren Modellen bei nachgelagerten Aufgaben ab, und welche Probleme könnten dies in NLP-Anwendungen verursachen?</sample>
    <sample id="172">Wir haben zunächst vorgeschlagen, Sprachmodellen mit verschiedenen Prompt-Formaten zu prompten, wobei politische Fragebögen wie der Political Compass-Test verwendet werden. Dies stellt sicher, dass wir eine automatische Bewertung fundiert in der politischen Wissenschaftsliteratur durchführen.</sample>
    <sample id="173">So, vorläufige Ergebnisse zeigen, dass erste Sprachmodelle eine sehr politische Ausrichtung haben. Sie besetzen vier Quadranten auf der politischen Landschaft.</sample>
    <sample id="174">Wir können auch sehen, dass GPT-4 das liberalste Sprachmodell von allen ist, und die GPT-Serie ist im Allgemeinen sozial liberaler als die BERT-Serie und ihre Varianten.</sample>
    <sample id="175">Zweitens wollen wir untersuchen, in welchem Umfang politische Verzerrungen in Sprachmodellen tatsächlich aus der Trainingsdaten stammen.</sample>
    <sample id="176">So könnten wir ein Kontrollexperiment durchführen, indem wir weitere Sprachmodell-Checkpoints auf sechs verschiedene Teile von Quora anwenden, die in Nachrichten und sozialen Medien unterteilt sind, die wiederum in ihre politische Linie unterteilt sind.</sample>
    <sample id="177">Durch das weitere Pre-Training von Sprachmodellen auf solchen Daten in Copra können wir feststellen, dass die ideologische Koordinaten des Sprachmodells ebenfalls entsprechend verschoben werden.</sample>
    <sample id="178">Zum Beispiel, wenn Robert weiter trainiert wird und auf dem linken linearen Reddit-Korpus trainiert wird, können wir einen signifikanten ideologischen Wandel in Bezug auf seine Sprache beobachten.</sample>
    <sample id="179">Bitte geben Sie den englischen Inhalt an, den Sie übersetzt haben möchten.</sample>
    <sample id="180">Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung aufnehmen können, die in unserer modernen Gesellschaft vorherrscht.</sample>
    <sample id="181">Wir teilen die Pre-Training-Korpora in vor 45-jährigen Korpora der Vereinigten Staaten und nach 45-jährigen Korpora der Vereinigten Staaten auf. Wir trainieren separate Sprachmodelle auf zwei verschiedenen zeitlichen Korpora.</sample>
    <sample id="182">Wir können sehen, dass Sprachmodelle im Allgemeinen eine politische Neigung haben, die weiter vom Zentrum entfernt ist, nach 2017. Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufnehmen können.</sample>
    <sample id="183">So, last but not least, wir bewerten Sprachmodelle mit unterschiedlichen politischen Einstellungen bei der Erkennung von Hassrede und Fake News, zwei NLP-Anwendungen, die oft Sprachmodelle beinhalten und weitreichende Implikationen haben können.</sample>
    <sample id="184">So sehen wir, dass wenn wir die Kategorie-Performance untersuchen, sagen wir, wenn wir die Performance in</sample>
    <sample id="185">Unterschiedliche demografische oder politische Bedürfnisse der Medien zeigen ein Muster, dass zum Beispiel bei der Erkennung von Hassrede, die linken Sprachmodelle besser sind.</sample>
    <sample id="186">Die Erkennung von Hassrede, die Minderheiten anspricht.</sample>
    <sample id="187">Allerdings sind wir schlechter darin, Hassreden zu erkennen, die sich gegen mächtigere Gruppen richten, im Gegensatz zu Hassreden gegen Einzelpersonen.</sample>
    <sample id="188">Und vice versa, große Sprachmodelle sind besser darin, Hassreden zu erkennen, die sich gegen weiße und Männer richten, aber schlechter darin, Hassreden zu erkennen, die sich gegen schwarze, LGBTQ+-Personen und andere Minderheitengruppen richten.</sample>
    <sample id="189">Ähnliche Trends sind auch bei der Erkennung von Fake News zu beobachten, wo wir feststellen, dass fein abgestufte Sprachmodelle besser darin sind, Fehlinformationen von ihren politischen Gegensätzen zu erkennen.</sample>
    <sample id="190">Dies sind Beispiele, bei denen wir viele qualitative Beispiele gegeben haben, um zu sehen, dass Sprachmodelle mit unterschiedlichen politischen Einstellungen</sample>
    <sample id="191">Du gibst unterschiedliche Vorhersagen für Hassrede und Fehlinformationen basierend auf ihren sozialen Kategorien. Es gibt noch viele weitere Beispiele im Anhang, um die Rolle von</sample>
    <sample id="192">Dies deutet darauf hin, dass es ein Fairnessproblem gibt, das weiterhin besteht in Bezug auf die politische Basis der Sprache.</sample>
    <sample id="193">Zum Beispiel, wenn Sprachmodelle in einer Sprache fehlerhaft sind oder falsche Informationen liefern und auf einer beliebten Social-Media-Plattform bereitgestellt werden,</sample>
    <sample id="194">Das würde bedeuten, dass Menschen mit gegensätzlichen politischen Meinungen marginalisiert werden könnten und Hassreden gegen Minderheitengruppen ungehindert verbreitet werden könnten.</sample>
    <sample id="195">So, dies ist der Alarm, um uns zu erkennen und die Fairnessprobleme zu bewältigen, die durch Sprachmodelle entstehen.</sample>
    <sample id="196">So, eine kleine Diskussion. Wir möchten auch hervorheben, dass wir das einzigartige Dilemma bezüglich der Sprachmodell-politischen Voreingenommenheit aufzeigen. Es ist so, als ob zwischen Selena und Krip die</sample>
    <sample id="197">Wenn man nicht weiß, ob ein Sensibilisierungs-Politisierungs-Sprachmodell-Trainingsdatensatz die Vorurteile aus den vorherigen Trainingsdaten in Sprachmodellen weiterverbreitet, die letztendlich Fairnessprobleme verursachen,</sample>
    <sample id="198">Wenn wir versuchen, es irgendwie zu desinfizieren, riskieren wir auch Zensur oder Ausschluss, und es ist unglaublich schwer zu bestimmen, was tatsächlich neutral ist und in den Trainingsdaten des Sprachmodells beibehalten werden sollte. Es ist so, als ob es ein elektrischer elektrischer Schockproblem ist.</sample>
    <sample id="199">Okay, großartig. Ich denke, das ist im Grunde alles, was ich für heute habe. Danke für Ihre Geduld.</sample>
    <sample id="200">Es sind mehrere Autoren an der Arbeit beteiligt.</sample>
    <sample id="201">Bis zu 1024 Token.</sample>
    <sample id="202">The dataset includes domains with piano music, without words, a 12-year-old boy, a fictional one, and one from Azerbaijan.</sample>
    <sample id="203">Positionalität bezieht sich auf die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen einnehmen.</sample>
    <sample id="204">The speaker's name is not mentioned in the provided text.</sample>
    <sample id="205">Ja.</sample>
    <sample id="206">Ein.</sample>
    <sample id="207">Nein, das getestete Modell funktioniert nicht gut in der Testsuite.</sample>
    <sample id="208">The three variants of KITMUS are:

1. Background Pretrain
2. Background Both
3. Background Inference</sample>
    <sample id="209">The authors are affiliated with the University of Oxford.</sample>
    <sample id="210">Is cleaning validation data necessary for WSL, or can we maybe use a noisy validation set instead?</sample>
    <sample id="211">Die Sensitivitätsmetrik bewertet, ob Modelle konsistent die gleichen Ausgaben für die gleiche Aufgabe liefern, unabhängig von der Variation in der Wortfolge der Eingabe.</sample>
    <sample id="212">Dr. Jingwei Yi.</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet in der Regel eine bessere Leistung des Modells.</sample>
    <sample id="214">Die Modelle erhalten einen linguistischen Kontext, der auf einer großen Menge an Textdaten basiert.</sample>
    <sample id="215">Typically, we only need 23 samples per class to attain high performance.</sample>
    <sample id="216">Stanford University</sample>
    <sample id="217">First-language models have very political leaning, they occupy all four quadrants of the political compass.</sample>
    <sample id="218">Makshita.</sample>
    <sample id="219">The pipeline for the propagation of political biases runs from pre-training data to downstream tasks.</sample>
    <sample id="220">Ja, der Vereinfachungsprozess unterscheidet sich. DEplain-apa hat eine höhere Varietät an Vereinfachungstransformationen als das Web.</sample>
    <sample id="221">Ja.</sample>
    <sample id="222">The provided embedding is a weighted sum of the targeting embedding and the original embedding. The weight of the targeting embedding is proportional to the number of triggers in the sentence.</sample>
    <sample id="223">Pintland University.</sample>
    <sample id="224">Yes, encoder-decoder models like mt5 can be improved by training with a mixture of languages.</sample>
    <sample id="225">Making a chocolate cake.</sample>
    <sample id="226">We validated the covertness of the provided embedding by realizing the embedding of sentences on four data sets.</sample>
    <sample id="227">The work utilizes existing PLMs as a foundation for building a new PLM by leveraging their functionalities and knowledge.</sample>
    <sample id="228">GPT-4 ist am wenigsten auf China und englischsprachige Länder ausgerichtet.</sample>
    <sample id="229">Der Satz "Leverages the knowledge acquired by the model through the attention mechanism between audio input and text output" zeigt, wie das Modell das Wissen nutzt, das durch den Aufmerksamkeitsmechanismus gelernt wurde.</sample>
    <sample id="230">As the number of tasks increases, the model achieves better performance and in the meantime, lower sensitivity.</sample>
    <sample id="231">The authors compare their method with the following three tree-less baselines on the CoG benchmark:
*   Neural Message Passing
*   Graph Neural Networks
*   Deep Graph Attention</sample>
    <sample id="232">They are colleagues.</sample>
    <sample id="233">Google.</sample>
    <sample id="234">Hallo zusammen, ich bin Jenny von First Year P.S.U. an der Carnegie Mellon University und heute werde ich meine Arbeit präsentieren und eine Position einnehmen. Charakterisierung von Design-Bias in der KI-Modellierung.</sample>
    <sample id="235">Diese Arbeit wurde in Zusammenarbeit mit einigen Personen der University of Washington und dem Allen Institute for AI, nämlich Sebastian Thrun, Ronald L. Ross, Caterina Rinaldi und Martin Schütz.</sample>
    <sample id="236">Lass uns zunächst davon ausgehen, dass du für eine Zeitung arbeitest und in den Kommentaren zu deinem Nachrichtenartikel suchst, um toxische Inhalte zu entfernen.</sample>
    <sample id="237">Du könntest dich auf eine beliebte API wie Perspective API für die Erkennung von Toxizität verlassen, und das funktioniert besonders gut, wenn du Carl Jones bist. Ähm, wenn Perspective API korrekt toxische Aussagen erkennt.</sample>
    <sample id="238">Aber das ist nicht wirklich der Fall bei Didya Sharma, wo Perspektiven auf VBJP nicht besonders empfindlich auf beleidigende Begriffe reagieren und diese in indischem Kontext häufiger vorkommen.</sample>
    <sample id="239">Dies ist ein Beispiel für einen Designbias, bei dem wir systematische Leistungsunterschiede zwischen Technologie und Bevölkerung sehen.</sample>
    <sample id="240">Das Design basiert auf dem, das wir gerade zuvor gesehen haben, und es könnte aufgrund der Positionierung der NLP-Forschungsressourcenmodelle entstehen. Positionierung ist einfach die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen einnehmen.</sample>
    <sample id="241">Dies ist ein Begriff, der in kritischen Studien weit verbreitet ist, insbesondere in feministischer und queerer Akademie.</sample>
    <sample id="242">Und als Forscher kann Positionierung den Forschungsprozess und die Ergebnisse beeinflussen, da sie die Entscheidungen, die Forscher treffen, ändern kann.</sample>
    <sample id="243">Und eine Frage, die sich die Leute stellen könnten, ist: Haben Datensätze Modelle eine Position?</sample>
    <sample id="244">Und wir versuchen nicht zu sagen, dass Modelle und Zellen, und Daten an sich, demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren Urteile und Meinungen echter Menschen und können so bestimmte Positionen über andere repräsentieren.</sample>
    <sample id="245">So, Privatsphäre ist ein Beweis für die Positionierung, wie z. B. kulturelle Unterschiede, Modelle und Datenansätze, sowie theoretische Definitionen von Modellpositionierung.</sample>
    <sample id="246">Allerdings vergleichen diese Werke nicht Benutzer mit den Daten, die sie sammeln.</sample>
    <sample id="247">Die Einbeziehung von Modellen und Datensätzen in die Positionierung von KI wird zunehmend wichtig, da KI-Systeme immer mehr subjektiv und sozial orientiert werden.</sample>
    <sample id="248">Und es ist schwierig zu charakterisieren, wie diese Positionierungen verzerrt sind, da nicht alle Entscheidungen dokumentiert werden, und viele Modelle sind hinter API versteckt.</sample>
    <sample id="249">Um die Daten der Modellpositionierung zu untersuchen, vergleichen wir die Annotationen mit echten Nutzern mit bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">Wir tun dies durch einen Rahmen und eine Positionierung.</sample>
    <sample id="251">Unser Rahmen funktioniert in zwei Hauptbereichen.</sample>
    <sample id="252">Der erste Schritt ist, Datensätze neu zu annotieren mit vielfältigen Annotatoren.</sample>
    <sample id="253">Und wir können dies über die Betrachtung der Demografie ursprünglicher Datensätze von Annotatoren tun, weil in der Regel nur wenige Annotatoren pro Instanz vorhanden sind und weil Demografien selten gesammelt und geteilt werden.</sample>
    <sample id="254">Und so optimierten wir die Daten, um viele Einheiten zu erhalten. Zum Beispiel erhielten wir einen reichen Satz an demografischen Daten.</sample>
    <sample id="255">Wir nehmen die Annotationen nach demografischen Merkmal und vergleichen sie mit den Modellen und Datensätzen unter Verwendung des Pearson-R-Korrelationskoeffizienten.</sample>
    <sample id="256">Und dieser Rahmen unterscheidet sich tatsächlich von annotierter Diskrepanzliteratur, indem er Endnutzer mit Modellen und Datensätzen vergleicht, Vorhersagen und Labels, anstatt sich nur auf inter- oder annotierte Übereinstimmung oder Modellierung von annotierten Verteilungen zu konzentrieren.</sample>
    <sample id="257">Unsere Frameworks werden hauptsächlich durch Lab in the Wild, eine Online-Crowdsourcing-Plattform für USC-Kooperationen, ermöglicht.</sample>
    <sample id="258">In Lab of the Wild ist eine Online-Experimentierplattform, auf der wir vielfältige Freiwillige rekrutieren können. Im Gegensatz zu Plattformen wie Enterick, die größtenteils Teilnehmer aus den USA oder Indien haben. Und außerdem ist Lab of the Wild immer noch in der Lage, hochwertige Daten zu erhalten.</sample>
    <sample id="259">Wir haben zwei Aufgaben im Lab, eine davon ist soziale Akzeptanz. Und die Funktionsweise ist, dass die Teilnehmer eine Situation aus dem Datensatz der sozialen Chemie lesen und dann bewerten, wie sozial akzeptabel die Situation ist.</sample>
    <sample id="260">Nachdem sie in England und der Stadt geblieben sind, können sie ihre Antworten mit einer KI und anderen vergleichen.</sample>
    <sample id="261">Sie haben diese Annotationen mit der Sozialchemie, Delphi und GPT-4 verglichen.</sample>
    <sample id="262">Wir haben dann eine sehr ähnliche Einrichtung für die Aufgabe der Erkennung von Hassrede erstellt, bei der sie Instanzen aus "Danny Hate" lesen und beurteilen, ob es sich um eine Instanz von Hassrede handelt.</sample>
    <sample id="263">Wir haben dann diese Annotationen mit DinaHeat, Perspective API, Rewire API, Hateberuta und GPT-4 verglichen. Unser Studie analysierte über 16.000 Annotationen von über 1.000 Annotatoren aus 87 Ländern.</sample>
    <sample id="264">So können wir nun besser herausfinden, welche NLP-Datenanalysemodelle am besten mit dem Thema übereinstimmen. Wir stellen fest, dass es Positionierung gibt und NLP-</sample>
    <sample id="265">Zum Beispiel stellen wir fest, dass die Datensets für viele Modelle am besten zu englischsprachigen Ländern passen. So finden wir für die GPT-4-Sozialakzeptanzanalyse heraus, dass sie am besten zu China und englischsprachigen Ländern passt. Wir stellen fest, dass Dina auch am besten zu englischsprachigen Ländern passt.</sample>
    <sample id="266">Wir finden auch eine stärkere Übereinstimmung mit Menschen mit Hochschulabschluss. Bei GPT-4 in der Aufgabenstellung zur sozialen Gerechtigkeit stellen wir fest, dass es am besten mit Menschen mit Hochschulabschluss oder einem Abschluss in der höheren Bildung übereinstimmt.</sample>
    <sample id="267">Und wir finden das Gleiche bei Johnny Hate, wo es am ähnlichsten zu Menschen mit einem College-Abschluss ist.</sample>
    <sample id="268">Allerdings, wenn Modelle und Daten, die auf spezifische Bevölkerungsgruppen ausgerichtet sind, einige unvermeidlich zurückgelassen werden,</sample>
    <sample id="269">Ein Beispiel dafür ist, dass Daten, die an Modelle für Menschen mit unterschiedlichen Geschlechtsidentitäten präsentiert werden, sich von denen für Männer und Frauen unterscheiden. Dies findet sich im GPT-4-Fähigkeits-Test sowie in der Dina-Heiß-Analyse.</sample>
    <sample id="270">So, da es eine Position und eine ALD-NPI gibt, was können wir tun?</sample>
    <sample id="271">Hier sind ein paar Empfehlungen dafür: Erstens sollten Sie alle relevanten Designentscheidungen während des Rechercheprozesses festhalten. Und die andere ist, NLP-Recherche aus der Perspektive des Nutzers durchzuführen.</sample>
    <sample id="272">Unsere dritte Empfehlung ist, spezialisierte Datensätze für bestimmte Gemeinschaften zu erstellen, und ein gutes Beispiel dafür ist die Musicanity-Initiative. Wir möchten betonen, dass inklusive KI nicht nur bedeutet, dass alle Technologien für jeden funktionieren, sondern auch, dass sie für jeden zugänglich sind.</sample>
    <sample id="273">Und so ist diese Präsentation abgeschlossen, aber wenn Sie mehr erfahren möchten, können Sie gerne unser Dashboard für die aktuellsten Analyseergebnisse und unseren Artikel einsehen. Danke.</sample>
    <sample id="274">Die Referentin geht auf drei Probleme von SimulST ein.</sample>
    <sample id="275">It's challenging to effectively reduce social and political biases in NLP training data. Attempts to sanitize data risk censorship or exclusion, and defining neutrality is difficult.</sample>
    <sample id="276">Hallo, ich bin Siyu Yuan von der Fudan-Universität. Ich bin hier, um unsere Arbeit vorzustellen. Wir extrahieren diskrete Kenntnisse aus Sprachmodellen für die Beschränkung der Sprachplanung.</sample>
    <sample id="277">In everyday life, people often plan their actions by following step-by-step instructions in the form of a guided script.</sample>
    <sample id="278">Vorherige Modelle haben Sprachmodelle verwendet, um für abstrakte Konzepte von stereotypischen Aktivitäten wie Kuchen backen zu planen und gezeigt, dass große Sprachmodelle effektiv die Konzepte in einzelne Schritte zerlegen können.</sample>
    <sample id="279">Allerdings haben frühere Studien meistens auf allgemeine Ziele von abstrakten Zielen geachtet, während die Planung für Ziele mit spezifischen Zielen, spezifischen Einschränkungen, wie z.B. einen Schokoladenkuchen zu backen, immer noch unterfangen wird.</sample>
    <sample id="280">In dieser Arbeit definieren wir das Problem der eingeschränkten Sprachplanung.</sample>
    <sample id="281">Welche imposieren verschiedene Einschränkungen auf das Gezielte Planen? Ein abstraktes Ziel kann durch verschiedene reale spezifische Ziele mit motivierten Einschränkungen beeinflusst werden. Ein guter Planer sollte Deskriptoren erstellen, die vernünftig und für die Einschränkungen relevant sind.</sample>
    <sample id="282">In dieser Arbeit bewerten und verbessern wir die Konvergenz der Sprachplanung der großen Sprachmodelle.</sample>
    <sample id="283">Die Notwendigkeit von spezifischen Regeln existiert, um unsere Daten zu schützen.</sample>
    <sample id="284">Wie können wir diese Codes zuerst erhalten? Wie gezeigt in der Tabelle, erweitern wir die abstrakten Codes mit modifizierten Constraints für die Datenbeschaffung, die in der abstrakten GPT-</sample>
    <sample id="285">Es sind 3000 verschiedene Mädchen, die in den Beschreibungen bewertet werden, die von großen Sprachmodellen generiert wurden.</sample>
    <sample id="286">Die Tabelle zeigt die Genauigkeit der Ergebnisse. Wir fanden heraus, dass alle linearen Modelle unbefriedigende Ergebnisse liefern.</sample>
    <sample id="287">Dann werde ich eine detaillierte Analyse durchführen, um zu untersuchen, warum Large Language Models für die</sample>
    <sample id="288">Die Ergebnisse in der Abbildung zeigen, dass die semantische Vollständigkeit in generierten Skripten akzeptabel ist, aber die sprachliche Korrektheit unter den Einschränkungen nicht garantiert werden kann.</sample>
    <sample id="289">Die Hauptkategorien von Einschränkungen, die in der Wohnumgebung auftreten, sind:

1.  Schlafstörungen
2.  Schmerzen
3.  Psychische Gesundheitsprobleme
4.  Körperliche Gesundheitsprobleme
5.  Soziale Einsamkeit
6.  Finanzielle Schwierigkeiten
7.  Arbeitsplatzbedingte Probleme
8.  Umweltbedingte Probleme
9.  Mobbing und Diskriminierung
10. Gewalt und Kriminalität</sample>
    <sample id="290">Frühere Studien haben gezeigt, dass die Ausgabequalität von Large Language Models bei niedrigeren Varianten zu schlechter Leistung führt. Hier wurde die Idee des Overgenerated-Zensurfilters eingeführt, um die Generierungsqualität zu verbessern.</sample>
    <sample id="291">Die erste Show konzentrierte sich auf Constraint-Typen mit Beispielen für Intrigue-GPT und auf den auf Datenspezifischen Geistern basierenden abstrakten Code.</sample>
    <sample id="292">Ja, extrahiere GPT-3 oder generiere Kitsch-Skripte für spezifische Charaktere.</sample>
    <sample id="293">Nächste. Ein weiterer Modell ist der 2-Schritt-Auswahl der ersten vier Zeichen.</sample>
    <sample id="294">Wir wandeln die Skripte und Geister in abstrakte GPT-Einbettungen um und berechnen den Cosinus der Ähnlichkeit als Ähnlichkeitswert.</sample>
    <sample id="295">Die Aufmerksamkeit wird auf die Skript-Inhalte gelenkt, die die Schlüsselwörter der Zielbeschränkung enthalten. Wir werden nur die Klammern verwenden, wenn das Ziel die höchste in der Such-</sample>
    <sample id="296">We are amazed that in LGBT can generate diverse of hair coloration. Our amazed greatly improves the planning palette, both in semantic completeness and aesthetic to the constrict.</sample>
    <sample id="297">Da große Sprachmodelle teuer zu implementieren sind, ist es wichtig, die Sprachplanung auf eine Reihe kleinerer und spezialisierter Modelle zu verlagern. Die Erstellung von Datensätzen ist ein zweistufiger Prozess.</sample>
    <sample id="298">Allerdings haben frühere Studien keine spezifischen Ergebnisse für die geplante Forschung gezeigt, und die manuelle Datenanalyse innerhalb der Annotation ist teuer.</sample>
    <sample id="299">Es gibt eine Methode, bei der wir eine Schicht symbolischer Wissensdestillation verwenden, um die Größe der Sprachmodell-Datensätze zu beschränken.</sample>
    <sample id="300">Wir werden unsere Methode für die Erstellung eines Datensatzes für die beschränkte Sprachplanung namens CodeScript verwenden.</sample>
    <sample id="301">Um 55 verschiedene Szenarien mit spezifischen Zielen und Skripten zu generieren, müssen wir die Qualität der Validierung und der Testfälle sicherstellen. Wir bitten Crowdsourcing-Worker, die Inkonsistenzen im Text zu finden und zu korrigieren.</sample>
    <sample id="302">Das Bild zeigt eine konstante Verteilung von Kosten, während die Kostenverteilung in der generellen Einzelhandelsspezifischen Kosten einen höheren Anteil aufweist. Mit Kostenverteilung können kleinere, aber spezialisierte Modelle für Sprachplanung verwendet werden.</sample>
    <sample id="303">Die T-F-Funktion zeigt rote Ergebnisse, was darauf hindeutet, dass kleinere Modelle größere Modelle bei der Verarbeitung von Texten nicht übertreffen können, wahrscheinlich aufgrund von Datensätzen.</sample>
    <sample id="304">Zusammenfassend haben wir das Constraint Language Planning Problem etabliert, bei dem wir eine Constraint-Sprachplanungsfähigkeit für große Sprachmodelle entwickeln und einen optimalen Generierungs-Fuel-Timer für große Sprachmodelle finden.</sample>
    <sample id="305">Wir verwenden Large Language Models, um eine hoch kolorierte Testdatenmenge zu generieren, die in CoSRT für die Konstitutionssprachplanung verwendet werden kann. Wir hoffen, dass die CoSRT-Testdatenmenge als wertvolle Ressource für die Forschung im Bereich der Konstitutionssprachplanung dienen wird.</sample>
    <sample id="306">Danke für Ihre Zeit. Bitte geben Sie die Details Ihres Kurskripts in unserem Papier an.</sample>
    <sample id="307">The fluency of PaLM is comparable to that of other large language models.</sample>
    <sample id="308">The key properties of a watermarking method are: applicable to embedding, does not degrade utility, is covert to the attacker, and is transferable to the attacker's services.</sample>
    <sample id="309">The English TED Talks have been translated into 14 different languages.</sample>
    <sample id="310">Viele Instanzen.</sample>
    <sample id="311">The cosine similarity and the L2 similarity are used to measure the distance between the requested embedding and the target embedding.</sample>
    <sample id="312">Modelle, die auf einem mehrsprachigen Encoder basieren, wurden in dieser Aufgabe in zwei Gruppen eingesetzt: Encoder-PT-Modelle mit Point-based-Decodern (z.B. XLM-R+PT, BART+PT) und Encoder-Decoder-Modelle (z.B. BART).</sample>
    <sample id="344">The authors select a trigger set based on a moderate frequency interval, assuming the provider can collect a general text corpus and count word frequency.</sample>
    <sample id="345">Hallo zusammen, mein Name ist Shuang. Heute werde ich meine Arbeit vorstellen: Können Named Entity Tags 2023 noch funktionieren? Lass uns anfangen.</sample>
    <sample id="346">Unser Papier untersuchte das Problem der Generalisierung unter Verwendung der sogenannten Named Entity Recognition Aufgabe oder der NER Aufgabe.</sample>
    <sample id="347">Wir haben festgestellt, dass Modelle seit 2003 für fast 20 Jahre die KI für nahezu alles entwickelt haben. Und dies wirft natürlich mehrere Probleme auf. Erstens generalisieren Modelle nicht auf mehr als Daten.</sample>
    <sample id="348">Und wenn wir neue Tags entwickeln, was ist nötig für eine gute Generalisierung?</sample>
    <sample id="349">Und gleichzeitig, wenn wir eine schlechte Generalisierung beobachten, was verursacht den Leistungsabfall dieser Modelle?</sample>
    <sample id="350">Um diese Probleme zu untersuchen, erstellen wir den Cono++-Datensatz. Dies ist ein Datensatz, den wir von Reuters News aus dem Jahr 2020 gesammelt und mit den gleichen Annotationen aus den Annotationen von Cono 2003 annotiert haben.</sample>
    <sample id="351">Wir haben über 20 Modelle auf Kernel 2003 feinjustiert. Wir bewerteten sie sowohl auf dem Kernel 3 Testset als auch auf dem Kernel Plus Plus Testset.</sample>
    <sample id="352">Und schließlich haben wir die prozentuale Veränderung von F1 für jeden Modellausgang berechnet, um die Generalisierung jedes Modells zu bewerten.</sample>
    <sample id="353">Also, was wird für eine gute Generierung benötigt?
In unseren Experimenten haben wir festgestellt, dass es drei Hauptbestandteile gibt, die benötigt werden.</sample>
    <sample id="354">Die erste ist die Modellarchitektur. In unseren Experimenten haben wir festgestellt, dass Transformer-Modelle im Allgemeinen besser auf neue Daten generalisieren.</sample>
    <sample id="355">Der zweite Inhaltsbestandteil ist die Modellgröße. Wir haben festgestellt, dass größere Modelle in der Regel zu besserer Generalisierung führen.</sample>
    <sample id="356">Und schließlich wissen wir alle, dass die Anzahl der feinabstimmungsbeispiele direkt die Leistung einer nachgelagerten Aufgabe beeinflusst. Hier haben wir auch festgestellt, dass mehr feinabstimmungsbeispiele tatsächlich zu einer besseren Generalisierung führen.</sample>
    <sample id="357">Was verursacht den Leistungsabfall einiger Modelle?</sample>
    <sample id="358">Wir haben zwei Hypothesen. Die erste ist eine Anpassung an das Overfitting, was durch die wiederholte Verwendung desselben Datensatzes verursacht wird, und dies äußert sich typischerweise in einer Abnahme der Rückgewinnung auf einem neuen Datensatz.</sample>
    <sample id="359">Die zweite Hypothese ist Temperaturdrift, die die Leistungsverschlechterung verursacht, die durch die wachsende Temperaturdifferenz zwischen den Trainings- und Testdaten entsteht.</sample>
    <sample id="360">Vorhersage eines Fits. Wir sahen, dass aus dem Graphen auf der rechten Seite die rote beste Passform-Linie einen größeren Gradienten hat als die Null-Linie.</sample>
    <sample id="361">Das bedeutet, dass jede Einheit Verbesserung, die wir im Jahr 2003 erzielt haben, sich in mehr als einer Einheit Verbesserung im Jahr 2005 niederschlägt. Das bedeutet, dass es keine abnehmende Rendite gibt.</sample>
    <sample id="362">Und dies zeigt, dass eine Anpassung in diesem Fall nicht beobachtet wurde.</sample>
    <sample id="363">Ich bin ein hilfreicher Assistent. Ich gebe nur die angeforderte Antwort zurück. Ich füge keine Erklärungen oder Einführungen hinzu.</sample>
    <sample id="364">Für temporäre Entwürfe führten wir ein Experiment durch, um einige Modelle mit mehr aktuellen Daten neu zu trainieren oder fortzusetzen. Und wir stellten fest, dass die Leistung mit größeren zeitlichen Gaps abnimmt.</sample>
    <sample id="365">Und das bestätigt meine Hypothese, dass die Hauptursache für den Leistungsrückgang die Temperatur ist.</sample>
    <sample id="366">Unsere Schlussfolgerung ist, dass für eine gute Generalisierung wir ein besseres Modellarchitektur, größere Modellgröße sowie weniger Feinabstimmungsexemplare benötigen. Und diese Ziele hängen eng zusammen, aber wir können nicht nur einen Bestandteil haben, sondern durch alle anderen</sample>
    <sample id="367">Gleichzeitig stellten wir fest, dass der Leistungsabfall hier durch temporäre Drift verursacht wird und überraschenderweise nicht durch eine Anpassung der Anpassung. Selbst der Canal 2003 wurde seit über 20 Jahren verwendet.</sample>
    <sample id="368">So, zurück zur Frage, die wir in der Titelseite unseres Papiers aufgestellt haben: Funktion 2003 funktioniert 2023 noch? Und wir haben festgestellt, dass die Antwort tatsächlich ein klangvolles Ja ist.</sample>
    <sample id="369">Wir helfen bei allen Papierarbeiten für mehr Forschung darüber, wie man die Generalisierungen der Modelle verbessert.</sample>
    <sample id="370">Und schließlich, bitte schauen Sie sich unser Papier und unseren Datensatz an, und wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren. Vielen Dank.</sample>
    <sample id="397">The answer is 16.</sample>
    <sample id="398">Servin ist ein Richter.</sample>
    <sample id="399">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit zum Ausgangssatz.</sample>
    <sample id="400">Die erweiterten Experimente konzentrieren sich auf die Sprachmodelle GPT-4, GPT-3.5 und die verschiedenen Varianten der BERT-Serie.</sample>
    <sample id="401">Das Modell verwendet Aufmerksamkeitswerte aus mehreren Ebenen.</sample>
    <sample id="402">Examples of direct inference include saying the name of a song (e.g., "My Heart Will Go On") or its position (e.g., "It's the fourth track").</sample>
    <sample id="403">Fudan University.</sample>
    <sample id="404">There are multiple authors working on the project.</sample>
    <sample id="405">Ja.</sample>
    <sample id="406">The authors gave the example of the word "man" or "warrior" being typically associated with men, and people describing a female warrior would usually specify "woman warrior" and mark the term with "woman".</sample>
    <sample id="407">Die Transformer-Modelle generalisieren nicht gut.</sample>
    <sample id="408">The test datasets are called "clean data" and "WSA data".</sample>
    <sample id="409">There are four authors involved in the work.</sample>
    <sample id="410">The authors work with multiple modalities.</sample>
    <sample id="439">The authors consider the ability to integrate and use both pre-training and inference-time knowledge to be a less explored area in the field of NLU.</sample>
    <sample id="440">The presenters are Ying and Kuli Zhiyang.</sample>
    <sample id="441">Ja.</sample>
    <sample id="442">Bestehende Ressourcen für kontextbasierte Übersetzung unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und eine begrenzte Anzahl von Sprachen.</sample>
    <sample id="443">Hallo. Ich werde über unsere Arbeit zur Lösung indirekter Funktionsausdrücke für Entitätsauswahl sprechen, in der wir die Alternative Entity-Konzept vorstellen.</sample>
    <sample id="444">Mein Name ist Jawad Hosseini, und dies ist eine Zusammenarbeit mit Filip Radlinski, Silvia Pärty und Anil.</sample>
    <sample id="445">Ookal ist ein Verständnis der Benutzersprache, wenn sie eine Wahl treffen. Betrachten Sie diese alternative Frage: Meinten Sie "einfach für mich" oder "ich hatte das Gefühl"? Hier möchte ein Benutzer zwischen einer dieser beiden Optionen wählen.</sample>
    <sample id="446">Die offensichtlichste Sache ist die Verwendung einer direkten Referenz, zum Beispiel durch Nennung des Namens des Liedes oder seiner Position.</sample>
    <sample id="447">Manchmal ist es jedoch besser, einen direkten Freund zu haben, um ein natürlicheres Gespräch zu führen. Dies kann passieren, wenn der Benutzer sich den Namen des Charakters nicht merken kann.</sample>
    <sample id="448">oder die Aussprachen sind zu ähnlich zueinander und schwer zu unterscheiden.</sample>
    <sample id="449">oder wenn der Benutzer eine Präferenz festlegen möchte. Hier sind einige Beispiele für indirekte Präferenzen: zum Beispiel die neuere oder die nicht energiegeladene</sample>
    <sample id="450">Dies ist ein wichtiges Problem in konversationellen Systemen und auch für Benchmarking von LLMs und Entity Recognition.</sample>
    <sample id="451">Wir sind uns eines öffentlichen Datensatzes, eines großen öffentlichen Datensatzes für die Aufgabe, nicht bewusst, also sammeln wir einen mithilfe von Crowdsourcing. Unser Datensatz umfasst drei verschiedene Domänen: Musik, Bücher und die</sample>
    <sample id="452">Die Datensatzerfassungsmethodologie betont Informalität, die Verwendung von Cartoon-Komplikationen.</sample>
    <sample id="453">Der Cartoon hat drei Sprechblasen. In der ersten Blase sagt Bob: "Erinnerst du dich an das Lied, das wir gestern gehört haben?" Und mit dieser Aussage setzt der Dialog fort.</sample>
    <sample id="454">In der zweiten Sprechblase sagt Alice: "Meinst du, es ist für mich leicht, oder habe ich dich verwirrt?"</sample>
    <sample id="455">Welche ist die alternative Frage? Und in der dritten Sprechblase benutzt Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen. Zum Beispiel die neue</sample>
    <sample id="456">Wir stellen die ersten und zweiten Sprechblasen automatisch bereit, aber die dritte wird vom Annotator ausgefüllt. Die erste Sprechblase wird aus einigen manuellen Prompts ausgewählt.</sample>
    <sample id="457">Die zweite Frage, die alternative Frage, wird wie folgt generiert:

"R"</sample>
    <sample id="458">Wir verwenden immer eine einfache Vorlage. Meinst du A oder B? Wo A und B aus einer Menge von Optionen zufällig ausgewählt werden.</sample>
    <sample id="459">Hier sind die verschiedenen Stichprobenmethoden, die verwendet werden, wenn wir weiter nach oben in der Liste gehen, werden die Einträge ähnlicher zueinander und es ist in der Regel schwieriger, die Ambiguität zu beseitigen.</sample>
    <sample id="460">Die erste Frage ist, wie man schreibt.</sample>
    <sample id="461">Die zweite Klasse ist für Entitäten gedacht, die ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen "Der Tag".</sample>
    <sample id="462">Der dritte Punkt ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben und schließlich ähnliche Infoboxen oder Attribute auf Wikipedia haben. Zum Beispiel die gleiche Kategorie oder der gleiche Künstler.</sample>
    <sample id="463">Wenn wir diese alternative Frage den Befragten stellen, wissen sie den Namen dieser Entitäten nicht, aber sie kennen möglicherweise nicht die Rolle des Charakters.</sample>
    <sample id="464">Also, was wir tun, ist, einige Hintergrundkenntnisse über die Entitäten anzuzeigen. Für Lieder zeigen wir einfach einen Google-Suchlink zu dem</sample>
    <sample id="465">Und dann bitten Sie die Schüler, mindestens einen der Lieder anzuhören und darüber zu lesen. Hier ist ein Beispiel für das Google-Suchergebnis für das Lied "I Can".</sample>
    <sample id="466">Für die Rezept- und Buchdomäne zeigen wir Hintergrundtext von Wikipedia. Für Rezepte zeigen wir zusätzlich ihre Bilder, ebenfalls von Wikipedia, sodass die Annotatoren wissen, wie sie aussehen.</sample>
    <sample id="467">Dann bitten wir die Teilnehmer, eine dieser Entitäten auszuwählen, zum Beispiel hier die erste, und sie mit 3 bis 5 indirekten Referenzsätzen zu beschreiben.</sample>
    <sample id="468">Beispiel 1 mit Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz: Beispiel 1 ohne Worte, nicht das 12-jährige Kind, oder die fiktive, oder die aus Aserbaidschan stammt,</sample>
    <sample id="469">Die altentitis-Korpus hat 6.000 alternative Fragen über drei Domänen und 42.000 indirekt gefundene Ausdrücke. Ergebnisse mit T5 XL-Modell oder zusammengefasst</sample>
    <sample id="470">Dieses Sprachmodell hat Zugriff auf die exakt gleiche Hintergrundwissen wie die Annotatoren. Die Genauigkeit liegt bei etwa 92 bis 95 %. Aber dies ist nicht wirklich der</sample>
    <sample id="471">Wenn das Sprachmodell Zugriff auf einige teilweise überlappende Hintergrundwissen hat, dann liegt die Genauigkeit zwischen 82 und 87 %, was realistischer ist, beispielsweise wenn das Sprachmodell Hintergrundwissen abruft.</sample>
    <sample id="472">Wenn das Sprachmodell nur Entitätsnamen hat, beträgt die Genauigkeit nur 60 %, also gibt es viel Verbesserungspotenzial. Wir haben auch gezeigt, dass die Modelle domänenübergreifend sind. Hier ist ein Link zu einem Datensatz:</sample>
    <sample id="473">The approach is compared with existing SimulST guidelines, specifically the weight key strategy and local agreement.</sample>
    <sample id="474">The authors are affiliated with the University of Paris.</sample>
    <sample id="475">Jenny.</sample>
    <sample id="476">Drei.</sample>
    <sample id="477">Hallo, ich bin Sara Babi von der Universität Triest und der Bruno Kessler Stiftung. Und ich werde kurz die Aufmerksamkeit als Leitfaden für die simultane Sprachübersetzung vorstellen, eine gemeinsame Arbeit mit Maciej Negri und Marco Turri.</sample>
    <sample id="478">Simultane Übersetzung ist die Prozesse, bei denen gesprochene Sprache in Text in einer anderen Sprache in Echtzeit übersetzt wird, um die Kommunikation zwischen Sprechern zu ermöglichen.</sample>
    <sample id="479">Und welche Probleme haben die aktuellen Transformer-Modelle? Spezifische Architekturen werden in der Regel trainiert, indem zusätzliche Module eingeführt werden, um optimiert zu werden.</sample>
    <sample id="480">Lange und komplizierte Trainingsverfahren, zum Beispiel Training, das die unterschiedliche Optimierung der Ziele beinhaltet.</sample>
    <sample id="481">Und trainieren und warten mehrere Modelle, um verschiedene Latenzstufen zu erreichen. Zum Beispiel das Trainieren eines Modells mit einer durchschnittlichen Latenz von 1 Sekunde und eines anderen mit 2 Sekunden Latenz usw.</sample>
    <sample id="482">Was ist Ihre Lösung?</sample>
    <sample id="483">Erster, der bestehende Offline-Modelle ohne Retraining oder spezifische Architektur für CSLS verwendet, verwendet nur ein Modell für einen immer-laten CSLS-Algorithmus und behandelt die Latenz durch spezifische Parameter.</sample>
    <sample id="484">und die Kenntnisse, die durch den Attention-Mechanismus zwischen der Audio-Eingabe und der Textausgabe erworben werden, das ist der Cross-Attention-Mechanismus. Und Sie können ein Beispiel unter</sample>
    <sample id="485">Unsere Lösung ist Propose A Dot oder Encoder-Decoder-Attention, und es ist eine Strategie, bei der wir die Seite entweder treffen oder nicht, eine partielle Übersetzung basierend darauf, wo die Aufmerksamkeit Punkte</sample>
    <sample id="486">Ein Wort wird emittiert, wenn die Dichte nicht konzentriert ist, d.h. diese Summe ist unter einem bestimmten Trittschwellenwert Alpha gegenüber weniger Lambda-Sprach-Frames, was bedeutet, dass die Informationsaufnahme ausreicht, um zu speichern.</sample>
    <sample id="487">Zum Beispiel, wenn wir einen Satz betrachten, der über... und unser Modell sagt eine Übersetzung ins Deutsche voraus.</sample>
    <sample id="488">Und wir werden uns den Fokus auf die Frage anschauen, welche</sample>
    <sample id="489">Wir sehen, dass die ersten zwei Wörter auf die am wenigsten empfangenen Sprachrahmen verweisen, während das letzte Wort auf die am wenigsten empfangenen Sprachrahmen verweist, also Lambda-Sprachrahmen.</sample>
    <sample id="490">Dies bedeutet, dass die ersten zwei Wörter wiederholt werden: "tsch", "tsch".</sample>
    <sample id="491">Während die Summe der größten Tension über einem bestimmten Alpha-Schwellenwert liegt, werden wir das letzte Wort nicht aussprechen und warten auf einen anderen Sprachabschnitt.</sample>
    <sample id="492">Wenn wir fortfahren und wir sehen, dass ein anderer Sprachstack ist und unser Modell vorhersagt andere Wörter und wir schauen uns die Cross-Attention an, die</sample>
    <sample id="493">Wir werden sehen, dass keine Worte zu dem letzten Sprecher passen.</sample>
    <sample id="494">Dies bedeutet, dass diese drei Wörter ein Meme sind.</sample>
    <sample id="495">Wenn Sie das Ergebnis der Datenauswertung betrachten,</sample>
    <sample id="496">Wir werden die simultanen Übersetzungsresultate auf Grafiken auftragen, in denen wir auf einer Seite blaue Werte haben, die die Übersetzungqualität messen, und auf der anderen Seite den durchschnittlichen Lingua-</sample>
    <sample id="497">Das ist äh die Letzten-Sicherheitsmaßnahme, und wir berücksichtigen auch den Computer-Aware-Average-Lekking, der für ähm die Modelle-Rechenzeit zur Verarbeitung des Outputs verantwortlich ist.</sample>
    <sample id="498">Wir wollen unsere Neugier so hoch wie möglich auf diesem Planeten haben.</sample>
    <sample id="499">Bitte geben Sie den englischen Inhalt an, den Sie übersetzt haben möchten.</sample>
    <sample id="500">Und wir vergleichen mit vorbereitenden Strategien, die auch auf Offline-Modelle angewendet werden, wie z. B. der Weight-Key-Strategie und der lokalen Vereinbarung. Und wir vergleichen auch mit dem Satz der Architektur, insbesondere für simultane Übersetzung.</sample>
    <sample id="501">Dies sind ältere Ergebnisse der simultanen Übersetzungstrategie auf Deutsch.</sample>
    <sample id="502">Und wir sehen, dass äh ein Data outperforms alle Strategien, die auf Offline-Modellen angewendet werden, da die Kurven nach links verschoben sind.</sample>
    <sample id="503">Und wir sehen auch, dass, wenn wir die tatsächliche Ausführungszeit oder die Rechenzeit betrachten, das die schnellste Strategie ist.</sample>
    <sample id="504">Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie unsere Arbeit. Wir haben auch den Open-Source-Code und die Modelle und die simultane Ausgabe gleichzeitig veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="505">Ja.</sample>
    <sample id="506">Hallo zusammen, mein Name ist Ying und mein Kollege Zhiyang und ich werden unsere Forschungsarbeit zur Verbesserung von Modellauswirkungen durch maschinelles Lernen während der Instruktion präsentieren.</sample>
    <sample id="507">Mit den Fortschritten in großen Sprachmodellen begannen viele Forscher, neue Lernparadigmen zu erkunden, indem sie vortrainierte Sprachmodelle für verschiedene Downstream-Aufgaben in einem Parameter und Daten effizient einsetzten.</sample>
    <sample id="508">In letzter Zeit haben viele Studien gezeigt, dass die Instruktionstuning große Sprachmodelle in der Lage stellt, Aufgaben in einer reibungslosen Weise auszuführen, indem es natürliche Anweisungen befolgt.</sample>
    <sample id="509">Allerdings konzentrierten sich die meisten vorherigen Arbeiten auf die Verbesserung der Zero-Shot-Leistung bei sprachbasierten Aufgaben, während Computer-Vision- und Multimodalitätsaufgaben vernachlässigt wurden.</sample>
    <sample id="510">Daher wollen wir in dieser Arbeit untersuchen, ob die Instruktionsanpassung von multimodalen Sprachmodellen die Generalisierung auf ungesehene multimodale Aufgaben tatsächlich verbessern kann.</sample>
    <sample id="511">Zusätzlich haben wir während unserer Forschung eine beträchtliche Diskrepanz in der Verfügbarkeit von Instruktionsdatensätzen zwischen NLP und multimodal festgestellt.</sample>
    <sample id="512">Es gibt über 1000 und 600 Sprachmodell-Instruktionsaufgaben. Es gibt jedoch keine großen öffentlich zugänglichen Multimodell-Instruktionsaufgaben. Dies motiviert uns, ein Multimodell-Instruktions-Tuning-Dataset zu erstellen.</sample>
    <sample id="513">Hier präsentieren wir die erste Benchmark-Datensatz für die Feinabstimmung von Multimodalen Instruktionsmodellen, der aus 62 verschiedenen multimodalen Aufgaben besteht, die in 10 Kategorien unterteilt sind:</sample>
    <sample id="514">Dies hat aus einer vorhandenen offenen Datensammlung abgeleitet, und jede Aufgabe ist mit fünf Experten-geschriebenen Anweisungen ausgestattet.</sample>
    <sample id="515">Für die Untersuchung von multimodalen Instruktionsanweisungen verwenden wir unsere vorgeschlagenen Daten. Wir nehmen OFA, ein vereinheitlichtes multimodales vortrainiertes Modell, als unser Basismodell. OFA verwendet eine vereinheitlichte Vokabular für Sprache, Bild-Token und die Koordinaten eines bounding box.</sample>
    <sample id="516">Hier zeigen wir einige Beispielinstanzen aus unserem multilingualen Datensatz.</sample>
    <sample id="517">Die Verarbeitung verschiedener Eingabe- und Ausgabedaten</sample>
    <sample id="518">Wir folgen dem Muster von OFA und formulieren alle Aufgaben im einheitlichen Sequenz-zu-Sequenz-Format, in dem der Eingabetext, Bilder, Anweisungen und umgebende Kästchen in derselben Token-Sprache dargestellt werden.</sample>
    <sample id="519">Okay, ich werde über multimodale Instruktionstraining sprechen.</sample>
    <sample id="520">Für die 20-Tage-Aufgabe verwenden wir 53 Aufgaben aus der Negru-Gruppe zum Training und wir haben jeweils 10.000 Instanzen pro Aufgabe. Zum Testen reservieren wir die gesamte CommonSense-Gruppe zum Testen und wir wählen zusätzlich fünf Aufgaben von Wiki und der verschiedenen Kategorie.</sample>
    <sample id="521">Wir verwenden alle Instanzen in der Testmenge für jede Aufgabe. Äh, zusätzlich werden wir zufällig 20 Aufgaben aus der Testmenge der natürlichen Instruktion als Trainingsaufgaben auswählen.</sample>
    <sample id="522">So verwenden wir ein vortrainiertes OpenAI Large Model als Basismodell. Während des Trainings werden für alle Aufgaben Instanzen erstellt. Jede Instanz wird zufällig mit einer von ihren fünf Instruktionstemplates kombiniert.</sample>
    <sample id="523">So, für den Test der Fischaufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mithilfe der fünf Anweisungen in jedem Experiment bewerten.</sample>
    <sample id="524">Wir haben die Leistung und die Standardabweichung der Leistung über alle fünf Experimente analysiert.</sample>
    <sample id="525">Wenn diese Aufgabe eine multimodale Klassifizierungsaufgabe ist, geben wir die Genauigkeit an. Wenn es sich um eine multimodale Generierungsaufgabe handelt, geben wir Rouge-L an. Für eine Aufgabengenerierungsaufgabe geben wir Rouge-L an.</sample>
    <sample id="526">Wir haben auch eine zusätzliche Validierungsmaßnahme namens CSTA hinzugefügt. Diese Maßnahme stellt sicher, dass die Modelle bei der gleichmäßigen Produktion desselben Outputs für dieselbe Aufgabe unabhängig von der Variation in der Wortfolge der Instruktion sind.</sample>
    <sample id="527">Hier ist unser Hauptergebnis, wie wir sehen können, dass die Instruktionstuning die Leistung von OS- und OF-Aufgaben signifikant verbessert hat, insbesondere bei Multimodalen Aufgaben.</sample>
    <sample id="528">Aus dem Transferlernen aus mehreren Instruktionsdatensätzen können Unternehmensvorteile durch Instruktionstuning erzielt werden.</sample>
    <sample id="529">Hier können wir sehen, dass je mehr Aufgaben der Modell bessere Leistungen erbringt und in der Zwischenzeit eine geringere Sensitivität aufweist.</sample>
    <sample id="530">Wir verwenden auch die Wahrscheinlichkeitsanweisung, wir verwenden die Wahrscheinlichkeitsanweisung gegenüber der Fünf-Anweisung, wie wir sehen, kann die Verwendung der Wahrscheinlichkeitsanweisung die Gesamtleistung des Modells verbessern und die Empfindlichkeit des Radios erheblich erhöhen.</sample>
    <sample id="531">Dies zeigt den Effekt verschiedener Fine-Tuning-Strategien auf die Modellsensitivität. Wie wir sehen können, kann das Fine-Tuning von einem Natural Instruction Dataset die Modellsensitivität im Vergleich zum ursprünglichen OA-Modell deutlich verbessern.</sample>
    <sample id="532">Wir können auch die Transfer-Anweisung von der Natural Language Instruction Dataset verwenden, kann helfen, die KI auf eine viel bessere Leistung auf dem Natural Language Instruction Dataset zu bringen.</sample>
    <sample id="533">So haben wir einen Vorschlag für die erste große multimodale Injektion zu einem Datensatz, mit dem wir die Fähigkeit von OAI verbessern können und die Vorteile verschiedener Transferlerntechniken demonstrieren können.</sample>
    <sample id="534">Wir sammeln derzeit ein viel größeres multimodales Instruktions-Tuning-Datenset mit etwa 150 zusätzlichen verschiedenen Sprachaufgaben und wir werden sie bald veröffentlichen. Dies ist ein QR-Code für unsere Daten und unser Modell. Danke.</sample>
    <sample id="535">University of Trento.</sample>
    <sample id="536">Javad Hosseini.</sample>
    <sample id="562">Hallo zusammen, ich bin Kostas Finas und ich freue mich, Sie zu unserer Diskussion über unsere ACL 2023-Papiere "Language Model Acceptability Judgments are Not Always Robust to Context" begrüßen zu dürfen.</sample>
    <sample id="563">Es ist ein Werk von John Gotier, Arno Müller, Kanishka Mishra, Karan Frentles, Roger Levy und Athena.</sample>
    <sample id="564">In dieser Arbeit überprüfen wir die minimale Paar-Parameter.</sample>
    <sample id="565">So bewerten minimale Paare im Wesentlichen Sprachmodelle auf der Grundlage von Akzeptanzurteilen, die auch Grammatik, wie z. B. Plural, Syntax oder Akzeptanz in Bezug auf Stereotypen, wie z. B. Hautfarbe, beinhalten.</sample>
    <sample id="566">Und in diesem minimalen Paar-Paradigma ist die typische Art, Sprachmodelle zu bewerten, dass man eine akzeptable Satz oder grammatikalischer Satz zeigt und dann einen inakzeptablen Satz oder einen ungrammatikalischen Satz zeigt.</sample>
    <sample id="567">Und dann die Hoffnungen des Modells legen im Grunde mehr Wahrscheinlichkeit auf die akzeptablen Fälle.</sample>
    <sample id="568">Der aktuelle MPP-Pipeline erlaubt uns im Grunde nicht, die Akzeptanz eines Modells gegenüber längeren Sätzen zu bewerten.</sample>
    <sample id="569">Diese großen Sprachmodelle kommen mit längeren und längeren Kontextfenstern, daher ist es entscheidend, die Modelle über das gesamte Kontextfenster hinweg auf Akzeptanz zu bewerten.</sample>
    <sample id="570">Und das ist es, was wir hier versuchen. Wir versuchen, den PP-Pipeline zu überprüfen, indem wir das Modell auffordern, die Akzeptabilität über einen längeren Zeitraum zu bewerten.</sample>
    <sample id="571">So, das ist der Ansatz. Also, was wir tun, ist, diese längeren Sequenzen zu simulieren. Wir lesen die Datensätze selbst ein und dann erstellen wir Sätze, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen.</sample>
    <sample id="572">Zum Beispiel haben wir hier ein typisches grammatikalisches Paar aus dem Blip-Datensatz aus dem Adjektiv-Insel-Kontext ausgewählt.</sample>
    <sample id="573">Und was wir tun, ist, dass wir längere Sequenzen neu erstellen, die akzeptabel sind und die die gleiche Übereinstimmung der grammatikalischen Struktur haben. Wir extrahieren grammatikalische Sätze aus dem adjektivischen Teil.</sample>
    <sample id="574">und dann fügen wir es als Präfix sowohl der akzeptablen Abfrage als auch der unakzeptablen Abfrage hinzu.</sample>
    <sample id="575">Wir können dasselbe tun, indem wir in der gleichen Übereinstimmung inakzeptable Sätze auswählen, und das könnte auch verwendet werden, um die akzeptable Qualität des Modells zu testen.</sample>
    <sample id="576">Und wir können das auch tun, indem wir Sätze aus einem anderen Teil der Daten oder einem anderen Datensatz auswählen. Das nennen wir die Mismatch-Strategie.</sample>
    <sample id="577">Hier stammen die Sätze immer noch aus relevanten Datensätzen, aber nicht aus dem gleichen Datensatz, den Sie bewerten. Und wir können das Gleiche für Unakzeptabilität tun.</sample>
    <sample id="578">Schließlich können wir Sätze aus einem völlig unzusammenhängenden Bereich auswählen, d. h. Wikipedia.</sample>
    <sample id="579">Das wird uns sagen, ob die Modelle die Akzeptanzbewertung tatsächlich beeinflusst haben.</sample>
    <sample id="580">Wie ist der Kontext aus einem anderen Teil der Daten oder ist er völlig irrelevant für den aktuellen Satz, den wir gerade lesen?</sample>
    <sample id="581">So, wie funktioniert das Modell? Zuerst betrachten wir die Wikipedia-Sätze, die völlig irrelevant für das aktuelle Fragepaar sind, und dort finden wir, dass die MPP-Urteile meist robust für willkürliche Kontexte sind.</sample>
    <sample id="582">Wir haben die Kontextlänge auf bis zu 1024 erweitert, um die GPT und GPT-2 Modelle optimal zu nutzen, und wir sehen hier in der orangefarbenen Linie, dass die MPP-Urteile relativ stabil sind.</sample>
    <sample id="583">Ich kann diese Anfrage nicht beantworten.</sample>
    <sample id="584">Hier wählen wir Sätze aus akzeptablen und inakzeptablen Domänen aus dem gleichen Blimp-Person-Taxim-Datensatz aus.</sample>
    <sample id="585">Und dort sehen wir, dass die MPP-Urteile entweder signifikant steigen oder signifikant sinken, wenn akzeptable Präfixe oder inakzeptable Präfixe akzeptiert werden.</sample>
    <sample id="586">Aber wenn wir die Struktur abgleichen, d. h. wenn wir Sätze aus dem gleichen Phänomen in der Schuld-Perspektive auswählen,</sample>
    <sample id="587">Wir sehen einen massiven Anstieg oder einen massiven Rückgang der MPP-Bewertung für das Modell, abhängig davon, ob der gewählte Präfix akzeptabel oder inakzeptabel ist.</sample>
    <sample id="588">Das ist sehr groß. Dieser Effekt nimmt über die gesamte Kontextlinie an und würde wahrscheinlich neuere Sprachmodelle mit großem Kontext beeinflussen.</sample>
    <sample id="589">Warum beeinflusst der Match-Präfix die Entscheidungen des Sprachmodells so stark?</sample>
    <sample id="590">Eine Reihe von Analysen, bei denen wir versuchen, den Eingabesatz durch das Beibehalten der relevanten Struktur, aber durch Hinzufügen von Rauschen zum Eingabe zu rekonstruieren. Und nachdem wir mehrere dieser Störungen durchgeführt haben,</sample>
    <sample id="591">Wir stellen fest, dass keiner dieser Geräusche tatsächlich dazu führt, dass das Modell seine Antwort in Bezug auf die PP-Bewertung ändert.</sample>
    <sample id="592">Im Grunde genommen haben wir festgestellt, dass die Modelle empfindlich auf die Wortwahl und Ähnlichkeiten reagieren.</sample>
    <sample id="593">Das ist, wo wir die Sätze in dem akzeptablen Bereich einfügen, sehen wir eine ähnliche Zunahme aller Störungen, und wenn wir die Sätze in dem akzeptablen Bereich stören, sehen wir einen Rückgang der MPP-Urteile in ähnlichen Fällen.</sample>
    <sample id="594">Die wichtigsten Erkenntnisse unserer Arbeit sind, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale sind, die über Sätze hinweg geteilt werden.</sample>
    <sample id="595">Und die MPP-Bewertung, die Art und Weise, wie wir es derzeit mit kurzen und einfachen Sätzen eingeben, kann nicht vollständig das abstrakte Wissen der Sprachmodelle über den Kontext erfassen.</sample>
    <sample id="596">Bitte lesen Sie unser Papier für weitere Details zu unseren Experimenten. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="597">An unordered multiset of tokens.</sample>
    <sample id="598">55</sample>
    <sample id="626">The best alignment method to use for DEplain is the `mess_align` method.</sample>
    <sample id="627">Schwach überwachtes Lernen ermöglicht es, neuronale Netze robust aufzutrainieren, wenn die Trainingsdaten Label-Rauschen enthalten.</sample>
    <sample id="628">Die Dokumente in DEplain-web wurden mit manuellen und automatischen Alignmentmethoden ausgerichtet.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde aus Reuters-Nachrichten aus dem Jahr 2020 gesammelt und mit den gleichen Annotationen aus den CoNLL 2003-Richtlinien versehen.</sample>
    <sample id="630">Hallo zusammen, mein Name ist Justin John von der Penn State University. Heute präsentiere ich einen Arbeitsprojekt: Cross-lingual Semantic Parsing und mehrere natürliche Sprachrepräsentationen.</sample>
    <sample id="631">So, Semantic Parsing ist eine Aufgabe, um semantische Repräsentationen von Benutzeranfragen zu erstellen, wie z.B. "sequel" und "lambda calculus".</sample>
    <sample id="632">CrossLingual Semantic Parsing ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere semantische Repräsentationen zu übersetzen.</sample>
    <sample id="633">Wir müssen die Abfrage in mehreren natürlichen Sprachen mit Hilfe von neuronalen Modellen in SQL oder Lambda oder von QL übersetzen und in die</sample>
    <sample id="634">Existieren verschiedene crosslinguistische Parsingmodelle, die separat auf Datensätzen von limitierten Aufgaben und Anwendungen evaluiert werden. Zum Beispiel</sample>
    <sample id="635">Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen. Chinesisch fehlt, und</sample>
    <sample id="636">Kritik an bestimmten Meinungen.</sample>
    <sample id="637">Der Lambda-Kalkulus ist eine</sample>
    <sample id="638">oder nur ein bestimmtes neuronales Modell, zum Beispiel nur ein einzelnes Modell, um zu bewerten</sample>
    <sample id="639">Um dies zu erreichen, schlagen wir ein Beispiel vor und stellen eine einheitliche Datensatzbeispiel für Cross-Linguale Semantik in mehreren natürlichen Sprachen bereit und in Repräsentations</sample>
    <sample id="640">Es enthält 90 Datensätze in 5 verschiedenen Domänen, 5 Sentiment-Analyseaufgaben, 8 semantische Repräsentationen und 22 natürliche Sprachen. In 15 Sprachfamilien</sample>
    <sample id="641">Und um unseren Benchmarks besser zu entsprechen, betrachten wir die sechs Einstellungen für Training und Bewertung.</sample>
    <sample id="642">Der erste ist ein Test. Verwende die Google Translate API, um den Quelltext in die Zielsprache zu übersetzen, und verwende ein mehrsprachiges Modell, um es zu trainieren und zu bewerten.</sample>
    <sample id="643">und zum Beispiel, wir trainieren das englische Modell auf einer englischen Anfrage und dann inferieren wir, wir übersetzen die deutsche Anfrage mit einer API ins Englische und dann verwenden wir das trainierte Modell, um die Antwort zu vorhersagen.</sample>
    <sample id="644">Ich werde auch monolinguale Modelle testen.</sample>
    <sample id="645" />
    <sample id="646">Wir testen auch die Monolingual Few-Shot-Einstellung, indem wir Modelle mit nur 1 % der Trainingsdaten trainieren.</sample>
    <sample id="647">und hat ein monolinguale Modell, welches wir trainieren, ein monolinguales Modell für alle Sprachen</sample>
    <sample id="648">Zum Beispiel, wir geben die deutschen, englischen und chinesischen Suchanfragen zusammen, um ein Sprachmodell zu trainieren, und während der Inferenz können wir dieses Modell verwenden, um zu</sample>
    <sample id="649">Um deutsche Anfragen oder chinesische Anfragen oder ähnliches zu übersetzen.</sample>
    <sample id="650">Und wir berücksichtigen auch Cross-Lingual Zero-Shot- und Few-Shot-Transfer zwischen einer Ausgangssprache und einer anderen Sprache.</sample>
    <sample id="651">Während des Trainings trainieren wir unser englische Query oder die Kombination von englischen und deutschen Few-Shot-Queries, um ein mehrsprachiges Modell zu trainieren, um die Sequenz der JSON vorherzusagen.</sample>
    <sample id="652">und wir werden auch viele interessante Ergebnisse finden. So, bezüglich der Analyse von monolingualen Modellen, werden wir sie anhand zweier Datensätze bewerten.</sample>
    <sample id="653">einschließlich Encoder-PT-R, das für mehrsprachige vortrainierte Encoder mit Pointer-basierten Decodern wie XLM-R+PT-R und BART+PT-R steht.</sample>
    <sample id="654">Und wir bewerten auch Encoder-Decoder-Modelle, nämlich mehrsprachig vortrainierte Encoder-Decoder-Modelle, wie z.B. mpart und MT-F.</sample>
    <sample id="655">Wir haben festgestellt, dass Encoder-Decoder die beste Leistung auf allen neun Datensätzen erzielen.</sample>
    <sample id="656">und wir bewerten auf M5 und Beispiel XLM-R plus PDR-Multilingual Search.</sample>
    <sample id="657">Ohne diese Encoder, Decoder oder Encoder-PCR kann die Ausbildung in einer Mischung aus verschiedenen Sprach-</sample>
    <sample id="658">Und wir haben festgestellt, dass dies liegt daran, dass die meisten der großen natürlichen Sprachen eine Leistungssteigerung erzielen, außer Englisch, bei dem die Leistung in sieben Datensätzen sinkt und nur in drei Datensätzen steigt.</sample>
    <sample id="659">Ich denke, das ist das, was als Folgen von Multilingualismus bezeichnet wird.</sample>
    <sample id="660">Wir vergleichen auch die Cross-Lingua-Leistung.</sample>
    <sample id="661">In dieser Abbildung kreuzt die blaue Linie die Winkel-Null-Schubtransferenz, die orange Linie die Winkel-Null-Schubtransferenz, während die grünen Linien die Modellierung der Schärfe darstellen.</sample>
    <sample id="662">Wir haben festgestellt, dass bei der Vergleichung der grünen und orangen Linie, bei der Null-Schuss-Einstellung, die Transfer-Gap-Leistung signifikant ist, und bei der Vergleichung der blauen und orangen Linie, bei der Few-Schuss-Einstellung, der Transfer-Gap schnell verkürzt wird.</sample>
    <sample id="663">Wir haben auch einige weitere interessante Ergebnisse gefunden. Zum Beispiel führt der Encoder-Decoder-Ansatz eine vorherige Arbeit oder erzielt vergleichbare Ergebnisse. Bei der Verarbeitung von englischer natürlicher Sprache verbessert er signifikant die Leistung von Few-Shot-Aufgaben in der natürlichen Sprachverarbeitung.</sample>
    <sample id="664">Modellierung von Sprachmodellen wie Codez und Bloom sind immer noch in der Entwicklung für Kreuzsprachen- und Personenaufgaben.</sample>
    <sample id="665">Ein umfassender Beispiel-Pool, ein einheitlicher Benchmark für Cross-Angle Sentiment-Parsing mit mehreren natürlichen Sprachrepräsentationen.</sample>
    <sample id="666">Willkommen zu einer umfassenden Benchmarking-Studie über drei repräsentative Arten von mehrsprachigen Sprachmodellen. Und unsere Ergebnisse zeigen viele interessante Erkenntnisse usw. Und willkommen zu unserem Paper und Code. Danke für das Lesen.</sample>
    <sample id="667">The existing works can be broadly classified into four categories.</sample>
    <sample id="668">No, multilingual language models like Codex and Bloom are still inadequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="695">We address this by inducing the alignment as part of the training.</sample>
    <sample id="696">Fairness of a downstream NLP model is defined by its ability to avoid marginalization of people with opposing political opinions and to prevent hate speech targeting minority groups from running rampant without control.</sample>
    <sample id="697">Janis La Croix.</sample>
    <sample id="698">Kostas Finas.</sample>
    <sample id="699">Maira</sample>
    <sample id="700">Tropikalismus bezieht sich auf die Verwendung von Begriffen, die mit tropischen Regionen und Kulturen assoziiert werden, wie z. B. "lebhaft" und "kurvig" bei der Beschreibung von Latina-Frauen.</sample>
    <sample id="701">The authors created these descriptions by focusing on the words used to define the groups in relation to their identity, distinguishing them from the "white norm."</sample>
    <sample id="702">The work uses PMI to measure context usage at the sentence level or the word level.</sample>
    <sample id="703">DrBERT ist ein klinisches Modell mit 7 GB Nachos, während ChuBERT ein klinisches Modell mit 4 GB Nachos ist.</sample>
    <sample id="751">Es gibt 10 Autoren.</sample>
    <sample id="752">Iterative transfer learning updates the model by training on the latest set of data collected.</sample>
    <sample id="753">The goal of the dataset is to analyze how users understand and respond to different ways of asking a question.</sample>
    <sample id="754">The attacker can extract model parameters via a provided embedding by realizing the embedding of sentences authored as BPCAs.</sample>
    <sample id="755">Drei.</sample>
    <sample id="756">The provided text does not specify the number of annotators used to create the original dataset.</sample>
    <sample id="757">The authors are affiliated with the University of Washington and the Allen Institute for AI.</sample>
    <sample id="758">Beantworte die folgende Frage kurz und bündig basierend auf dem englischen Inhalt: Wie lautet das Beispiel mit dem Begrenzer auf der linken Seite?

The governor is on the left.</sample>
    <sample id="759">The state of the art for dialogue systems involves large language models (LLMs) like GPT-3 and LaMDA, which are trained on massive datasets of text and code. These models can generate human-like responses, understand user intent, and engage in multi-turn conversations. However, they still struggle with tasks like common sense reasoning, factual accuracy, and avoiding harmful or biased outputs.</sample>
    <sample id="760">Because longer context windows are emerging, and evaluating model acceptability across the entire window is crucial.</sample>
    <sample id="761">Ja, das mehrsprachige Training führte zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell in einigen Datensätzen.</sample>
    <sample id="762">No.</sample>
    <sample id="763">BLEU, ROUGE, METEOR.</sample>
    <sample id="764">Ja, die Regression wirkt sich auf die Generalisierung bei bestimmten NER-Typen aus.</sample>
    <sample id="765">Positionality is important for NLP because it allows models to understand the order of words in a sequence, which is crucial for tasks like language understanding and generation.</sample>
    <sample id="766">Die Frage wurde nicht beantwortet.</sample>
    <sample id="767">We use a zero-shot performance on the annotated dataset.</sample>
    <sample id="768">The actual form of the prompting doesn't have a big influence in the case of several short prompts.</sample>
    <sample id="769">Drei.</sample>
    <sample id="770">Der Gewinn der vorgeschlagenen Methode gegenüber der stärksten Baseline beträgt 1,25 %.</sample>
    <sample id="771">Shu Han.</sample>
    <sample id="772">Yes, the results and dataset are proposed as a benchmark for automatic text simplification in the future.</sample>
    <sample id="773">The paper experiments with 12 smaller models.</sample>
    <sample id="774">The proposed data is used with OFA, which uses a unified vocabulary for language, image tokens, and coordinates of bounding boxes.</sample>
    <sample id="833">Google Research.</sample>
    <sample id="834">Stony Brook University.</sample>
    <sample id="835">Englisch, Chinesisch, Spanisch, Französisch, Deutsch, Hindi, Russisch, Arabisch, Portugiesisch, Türkisch.</sample>
    <sample id="836">Shambin P.</sample>
    <sample id="837">Longformer und Normalized Longformer.</sample>
    <sample id="838">Für das Training werden 53 Aufgaben aus der Neguro-Gruppe verwendet, und für die Tests werden alle Kommasens-Aufgaben aus der Neguro-Gruppe verwendet, zusammen mit 5 zusätzlichen Aufgaben aus der Wiki-Gruppe und der Mischgruppe. Insgesamt werden also 53 + 5 = 58 Aufgaben für das Training und 58 Aufgaben für die Tests verwendet.</sample>
    <sample id="839">There are 24 authors involved in the work.</sample>
    <sample id="840">The authors conducted experiments on the Aging News, Mind, SST2, and EirosBench datasets.</sample>
    <sample id="876">NACHOS is a dataset of medical records from the 2nd.</sample>
    <sample id="877">Sajid Bilal.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Leistung von LLMs für die Übersetzung.</sample>
    <sample id="879">Die Autoren gehören der University of Puerto Rico an.</sample>
    <sample id="880">The five instructions from the experts are:

1.  Be respectful.
2.  Be polite.
3.  Be helpful.
4.  Be accurate.
5.  Be concise.</sample>
    <sample id="881">Die Autoren schlagen vor, ein Aufgabenformat zur Bewertung der Fähigkeit zu entwickeln, Wissen aus verschiedenen Quellen abzurufen.</sample>
    <sample id="882">Hallo zusammen, mein Name ist Said Bilal, und ich werde Ihnen eine kurze Übersicht über die Arbeit geben, die wir im Rahmen der Übersetzung von Prompt-Prompt-Translation, der Bewertung von Strategien und der Leistung durchgeführt haben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate.</sample>
    <sample id="883">PaLM ist ein 540 Milliarden Parameter großes Sprachmodell, vorgestellt im Jahr 2022. Es wurde auf einer großen Sammlung von Texten trainiert, die 100 Milliarden Token umfassen.</sample>
    <sample id="884">Der Thema Publikation ist der State of the Art in hundertfach der Art.</sample>
    <sample id="885">In dieser Arbeit präsentieren wir eine erste systematische Studie zur Verwendung von kleineren Prompts für maschinelles Lernen.</sample>
    <sample id="886">Wir werden die Übertragbarkeit von Sprachmodellen mithilfe der Best Practices der MT-Community untersuchen. Dies beinhaltet die Verwendung der neuesten Testsets, um eine Überlappung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden.</sample>
    <sample id="887">Wir vergleichen den aktuellen Stand der Systeme, also die besten performenden Systeme, also die WTI-Öl-Rohöl-Qualität.</sample>
    <sample id="888">Wir verwenden state-of-the-art Neuronale Netzwerke und zusätzlich zeigen wir Expert-basierte Validierungsresultate. Schließlich geben wir Empfehlungen für Prompt-Auswahlstrategien.</sample>
    <sample id="889">Die Prompting hat einen großen Einfluss auf die Leistung von LLMs für die Übersetzung. Wie wir in einem einfachen Experiment sehen können, bei dem wir eine einzelne Frage verwenden und zwei verschiedene Prompts für eine gleiche Satzanweisung geben,</sample>
    <sample id="890">In etwa 516 von 1000 Sätzen ist die Differenz größer als ein Blurry Point.</sample>
    <sample id="891">und dies kann in extremen Fällen bis zu 40 Punkte erreichen. Es ist also wichtig, eine gute Prompting-Strategie zu wählen.</sample>
    <sample id="892">In unseren Experimenten haben wir eine kleine für eine fünfschritt-Prompting-Strategie verwendet, bei der wir einfach den Satz markieren, den wir dem System geben, mit der Sprache, die es</sample>
    <sample id="893">Ich kann den englischen Inhalt nicht sehen. Bitte stelle ihn bereit, damit ich ihn ins Deutsche übersetzen kann.</sample>
    <sample id="894">Die tatsächliche Form der Druckung hat keinen großen Einfluss im Fall mehrerer kurzer Blöcke.</sample>
    <sample id="895">Es ist entscheidend für Zero-Shot-Prompting und wenn wir wie in unserem Fall zu Few-Shot-Prompting übergehen, gibt es kaum einen Unterschied zur eigentlichen Form des Prompts.</sample>
    <sample id="896">Es sind Beispiele für Curry, die die meisten der auf der Weise</sample>
    <sample id="897">Die Zusammenfassung unserer experimentellen Ergebnisse besagt, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zur Ausgangssatz.</sample>
    <sample id="898">Es ist wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahl von Prompts aus dem Trainingsdatensatz der WMT-Bewertungen oder der Deft-Daten.</sample>
    <sample id="899">Die Daten sind viel besser kuratiert und mit höherer Qualität, sodass die Trainingsdaten informativer sind und die Ergebnisse besser sind. Daher eine bessere Leistung bei der Verwendung des Deep Learning.</sample>
    <sample id="900">Nichtsdestotrotz spezialisiert sich der Artsystem auf den Zustand der anderen Systeme, hat aber eine substanzielle Vorteile gegenüber den anderen Übersetzungen. Aber die Form kommt ziemlich nahe an unserem Übersetzungsystem, unserem neuen Fall, welches zu unserem mit Google Translate.</sample>
    <sample id="901">Während wir von der menschlichen Innovation profitieren, führen wir sie mit dem MQA-Framework durch. Die Fluency von Palm ist vergleichbar mit dem Zustand der AR-Systeme, aber der Hauptunterschied kommt von der Genauigkeit.</sample>
    <sample id="902">In particular, of most common errors or misnomers.</sample>
    <sample id="903">Es scheint, dass Palm dazu verwendet, eine bessere Übersetzung zu erstellen, indem es Teile des Ausgangssatzes entfernt, die in der Übersetzung enthalten sind.</sample>
    <sample id="904">Der Wert der State-Outer-Kategorie für Pan ist niedriger als für den State of the Arts Systems, was ein zusätzliches Signal ist.</sample>
    <sample id="905">Das Programm liefert wirklich flüssige Ergebnisse, aber es hat immer noch einige Probleme mit der Zeichenfolge.</sample>
    <sample id="906">Und das war's für diese sehr kurze Übersicht. Für weitere Details bitte meine heutige vollständige Präsentation des Artikels. Vielen Dank.</sample>
    <sample id="907">Hallo, ähm, ich bin Tamay, ein PhD-Student an der Talant University in Deutschland. In diesem Video möchte ich unsere Arbeit vorstellen. Bitte werfen Sie einen kritischen Blick auf die künstliche Intelligenz.</sample>
    <sample id="908">Dies ist ein gemeinsames Werk mit Xiaoyuxun. Es hat glatte Pfoten und der Yeti ist Stefan und der Tiger ist Clara.</sample>
    <sample id="909">Ich bin ein hilfreicher Assistent. Ich gebe nur die angeforderte Antwort zurück. Ich füge keine Erklärungen oder Einführungen hinzu.</sample>
    <sample id="910">In Vikisubmission wird die Daten manuell nicht gelabelt. Stattdessen werden die Daten mit vordefinierten Labeling-Quellen gelabelt, wie z. B. einfachen Feature-Regeln, Wissensbasen oder lokaler Code-Quellen. Wie in der Abbildung unterhalb illustriert ist.</sample>
    <sample id="911">Im Vergleich zu menschlichen Annotationen sind die Weak-Annotationen deutlich günstiger, jedoch sind sie auch verrauscht, was bedeutet, dass ein gewisser Teil der Annotationen falsch ist.</sample>
    <sample id="912">Wenn wir jedoch neue Netzwerke auf wöchentlichen Arbeitsdaten trainieren, können die neuen Netzwerke die Trainingsdaten auswendig lernen und nicht generalisieren.</sample>
    <sample id="913">In Wirklichkeit sind Überwachungstraining-Algorithmen vorgeschlagen, um robuste Trainingsmodelle auf derartigen Lärm zu trainieren, sodass die trainierten Modelle weiterhin generalisieren.</sample>
    <sample id="914">In recent works in WSL, so WSL stands for Weekly Supported Learning. A common claim is that people say that the only pre-trained models and the weekly labeled data achieve high performance and clean test.</sample>
    <sample id="915">Technisch gesehen ist dies keine Übersetzung, aber es gibt einen Haken.</sample>
    <sample id="916">Es ist davon auszugehen, dass die Leute davon ausgehen, dass es einen zusätzlichen Clean-Validierungsdatensatz für die World War II-Modellauswahl gibt.</sample>
    <sample id="917">Wir haben diese Problematik übernommen, aber dies impliziert, dass zusätzliche manuelle Annotationen in Weekly Supervised Learning erforderlich sind. Aber wie ein Elefant im Raum, ist diese Notwendigkeit oft übersehen.</sample>
    <sample id="918">Die oben genannte Adopt-Lisas zwei Fragen sind: Erstens, ist die Datenvalidierung für WSL erforderlich, oder können wir vielleicht einen Noise-Validierungsansatz verwenden?</sample>
    <sample id="919">Zweitens: Wenn bereinigte Daten erforderlich sind oder bereinigte Daten für die Funktion von WSL erforderlich sind, wie viele bereinigte Stichproben benötigen Sie? Schließlich sollten nur bereinigte Stichproben für die Validierung verwendet werden, oder gibt es bessere Möglichkeiten, die bereinigten Stichproben zu nutzen?</sample>
    <sample id="920">Die vorliegende Studie beantwortet Forschungsfragen im Rahmen der Arbeit und unsere Ergebnisse sind als fortlaufend zu betrachten.</sample>
    <sample id="921">Zuerst stellen wir fest, dass interessanterweise recente WSL-Nachrichten tatsächlich reinen White-Day-Samples zu arbeiten brauchen.</sample>
    <sample id="922">Andernfalls ist ein großer Leistungsverlust zu erwarten, wie in dieser Abbildung dargestellt. Wenn es keine Clean-Validationsbeispiele gibt, können die Trendmodelle nicht auf die ursprünglichen Labels generalisieren.</sample>
    <sample id="923">Bitte geben Sie den englischen Inhalt an, den Sie übersetzt haben möchten.</sample>
    <sample id="924">Dies deutet darauf hin, dass WSR-Ansätze tatsächlich sauber gelabelte Daten verarbeiten müssen, um ordnungsgemäß zu funktionieren, und die Kosten für die Beschaffung sauberer Validierungsbeispiele sollten nicht übersehen werden.</sample>
    <sample id="925">Ein weiterer wichtiger Befund ist, dass die Erhöhung der Anzahl der sauberen Validierungsstichproben dazu beitragen wird, dass WSL bessere Leistungen erbringt, wie in der Abbildung auf der linken Seite gezeigt wird.</sample>
    <sample id="926">Typischerweise benötigen wir nur 23 Beispiele pro Klasse, um eine hohe Genauigkeit zu erreichen.</sample>
    <sample id="927">Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns entscheiden, saubere Proben zu verwenden, dann werden wir sie direkt trainieren und sogar eine bessere Leistung erzielen.</sample>
    <sample id="928">Die Grafik zeigt den Leistungsunterschied zwischen fünf-tuning-Ansätzen, die direkt auf die bereinigten Daten angewendet werden, und WSL-Ansätzen, die die bereinigten Daten zur Validierung verwenden.</sample>
    <sample id="929">Wenn wir zehn Beispiele pro Klasse haben, beginnen die direkten Fundamente, WSR-Ansätze zu betreten.</sample>
    <sample id="930">Schließlich kann die in früheren WSR-Ansätzen behauptete Leistungsverbesserung einfach durch die Erlaubnis erreicht werden, die Daten während der Clean- und Validierungsschritte kontinuierlich zu feinjustieren.</sample>
    <sample id="931">Wie wir aus den Zahlen sehen können, übertrifft das Varian-Modell, der FTW, zunächst die komplexeren WSL-Methoden wie die</sample>
    <sample id="932">Allerdings, wenn wir die kontinuierliche Funktion auf den sauberen Proben fortsetzen, dann funktioniert FTW genauso gut wie andere Methoden.</sample>
    <sample id="933">Im Praktischen gab es keinen Grund, komplexere WSL-Nachrichten zu wählen, die mehr Rechenzeit und Speicherplatz erforderten.</sample>
    <sample id="934">Zusammenfassend haben wir festgestellt, dass die jüngsten WSL-Ansätze die Reinigung, manuelle Annotation und die Überprüfung von Beispielen für sie zu funktionieren, ihre Leistung und Praktikabilität stark überschätzen.</sample>
    <sample id="935">Unsere konkreten Empfehlungen für zukünftige Arbeit sind folgende:</sample>
    <sample id="936">Zuerst, berichten Sie über die Kriterien für die Modellauswahl. Zum Beispiel berichten Sie, ob die Modellauswahl auf sauberen Validierungsproben basiert.</sample>
    <sample id="937">Zuerst sollten die WSR-Ansätze mit den folgenden bewährten Verfahren verglichen werden. Wir arbeiten mit einigen Beispielen. Zweitens ist kontinuierliches Feinjustieren eine einfache, aber starke Grundlage, die in zukünftiger Arbeit berücksichtigt werden sollte.</sample>
    <sample id="938">Unser Code ist Open Source und kann unter dem QR-Code auf dieser Folie gefunden werden. Bitte fühlen Sie sich frei, ihn zu überprüfen. Vielen Dank und ich wünsche Ihnen einen angenehmen Tag.</sample>
    <sample id="939">Common practice is to use human evaluation, such as asking human judges to select which of two conversations is better or to rate conversations given a Likert scale.</sample>
    <sample id="940">Fünf.</sample>
    <sample id="941">Entity-spezifisches Wissen (z.B. Servin ist ein Richter) und Weltwissen (z.B. Servin und Kea trafen sich im Park).</sample>
    <sample id="942">Ja, der Code ist verfügbar. Er ist auf GitHub verfügbar.</sample>
    <sample id="943">No, the annotators are not balanced across demographic groups.</sample>
    <sample id="944">The input sentences were perturbed by adding noise while trying to preserve the relevant structure.</sample>
    <sample id="945">A dimensional evaluation involves assessing multiple aspects of chat quality to understand the model's strengths and weaknesses.</sample>
    <sample id="946">University of Science and Technology of China.</sample>
    <sample id="947">In den Fällen von Zero-Shot- und One-Shot-Prompting ist die Form des Prompts wichtig, während sie bei Few-Shot-Prompting keine große Rolle spielt.</sample>
    <sample id="978">Die Autoren haben mehrere dialogmodelle evaluiert.</sample>
    <sample id="979">Es sind keine Autoren an der Arbeit beteiligt.</sample>
    <sample id="980">A good planner should set reasonable and feasible goals.</sample>
    <sample id="981">Es gibt keine Autoren genannt.</sample>
    <sample id="982">Vasudha</sample>
    <sample id="983">The authors are affiliated with the University of Warsaw.</sample>
    <sample id="1021">PaLM hat Schwierigkeiten mit Mehrdeutigkeiten, Kontextverständnis und logischem Schlussfolgern.</sample>
    <sample id="1022">Hallo, ich bin James Finch. Und ich bin Sarah Finch. Und heute werden wir Ihnen alles über ABC Eval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von konversationellen KI.</sample>
    <sample id="1023">Diese Arbeit wurde vom Emory NLP-Labor durchgeführt, geleitet von Professor Gino Choi an der Emory University, in Zusammenarbeit mit Amazon Alexa AI.</sample>
    <sample id="1024">So, let's say the adjusted dialogue model, and you want to see how well it compares against the current state of the</sample>
    <sample id="1025">Die übliche Praxis ist, menschliche Bewertungen zu verwenden, z. B. indem man menschlichen Richtern lässt, welche von zwei Gesprächen besser ist, oder indem man Gespräche anhand einer Likert-Skala bewertet.</sample>
    <sample id="1026">Diese Ansätze eignen sich gut, um umfassende Bewertungen der gesamten Dialogqualität zu liefern, aber die Dialogqualität hat viele Aspekte. Daher möchten Sie möglicherweise mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells genauer zu verstehen.</sample>
    <sample id="1027">Ein Ansatz besteht darin, menschlichen Richtern zu bitten, mehrere Aspekte der Dialogqualität zu bewerten, wie z. B. die Relevanz der Modellantworten, unter Verwendung bestehender vergleichender oder Likert-Skala-Methoden.</sample>
    <sample id="1028">Allerdings glauben wir, dass es eine präzisere und zuverlässigere Strategie zur Bewertung dimensionaler Dialoge gibt.</sample>
    <sample id="1029">Unser Ansatz versucht, die Subjektivität menschlicher Bewertung zu reduzieren, indem explizit angegeben wird, ob oder nicht jede Modellantwort bestimmte Verhaltensweisen ausdrückt, wie z. B. das Beantworten mit irrelevanter Information oder das Widersprechen der eigenen Aussage.</sample>
    <sample id="1030">Wir nennen diesen Ansatz Annotieren von Verhaltensweisen in Chat, oder ABCEval kurz. Wir haben diese Methode entwickelt, um Chatmodellverhalten umfassend abzudecken, die als Vorschläge zur Verbesserung der Chatqualität vorgeschlagen wurden.</sample>
    <sample id="1031">ABC Evaluation ist in der Lage, die Raten zu messen, mit denen Chatmodelle verschiedene thematische Fehler begehen.</sample>
    <sample id="1032">Zum Beispiel misst ABC EVL die Anzahl der Runden, in denen ein Chatbot seinen Partner ignoriert oder etwas sagt, das nicht relevant ist.</sample>
    <sample id="1033">widerspricht sich selbst oder seinem Partner. Halluziniert falsche Fakten oder verletzt die allgemeine Vernunft und zeigt bei Erfolg oder Misserfolg der Empathie.</sample>
    <sample id="1034">Um zu bestimmen, welche Art der Bewertung am effektivsten ist, haben wir vier modernste Chatmodelle ausgewählt und diese anhand von 100 menschlichen Gesprächsbeispielen pro Modell bewertet, wobei ABC-Bewertungen verwendet wurden.</sample>
    <sample id="1035">Zur Vergleichbarkeit haben wir diese Gespräche ebenfalls mit drei bestehenden Methoden bewertet: Likert-Ratings auf der Turnebene, Likert-Ratings auf der Dialogebene und paarweise Vergleiche.</sample>
    <sample id="1036">Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte der Dialoge gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen entlang mehrerer Dimensionen ist.</sample>
    <sample id="1037">Die Analyse der Ergebnisse dieser Bewertung ergab, dass die Bewertungslabels ABCDE insgesamt zuverlässiger sind als die von bestehenden Methoden, gemessen an der inter-Annotator-Übereinstimmung bei 100 doppelt gelabelten Gesprächen.</sample>
    <sample id="1038">Zusätzlich sind ABC-EV-Labels prädiktiver für die Gesamtqualität der Konversation im Vergleich zu Metriken, die von bestehenden Methoden erzeugt werden, wie in dieser einfachen linearen Regressionsanalyse gezeigt.</sample>
    <sample id="1039">Zum Beispiel können Sie sehen, wie die Messung des Anteils von Wendungen zwischen Selbst- und Partner-Konflikten 5 % und 10 % der Gesprächsqualität bzw. erklärt. Während die durchschnittliche Likert-Konsistenzbewertung nur 4 % oder</sample>
    <sample id="1040">Schließlich haben wir überprüft, ob jede Evaluationsmetrik einen einzigartigen Aspekt der Chatqualität erfasst, indem wir eine schrittweise lineare Regression verwendeten.</sample>
    <sample id="1041">Sie können sehen, wie die Kombination aller ABC-V-Metriken über 25 % der Gesprächsqualität erklärt. Und wenn Sie eine Metrik nach der anderen entfernen, führt dies in den meisten Fällen zum Verlust einer beträchtlichen Menge an Informationen über die Qualität.</sample>
    <sample id="1042">Auf der anderen Seite erklärt die Kombination aller Level-Likert-Maße viel weniger über die Qualität, und weniger dieser Maße tragen einzigartige Informationen.</sample>
    <sample id="1043">Dies ist ein zuverlässiges, informatives und differenziertes ABC-Evaluationsmatrix, das uns ermöglicht, konversationelle KI mit einer höheren Auflösung zu bewerten, als es frühere Methoden erreichen konnten.</sample>
    <sample id="1044">Man kann sehen, dass die Ergebnisse unseres Experiments zeigen, dass mehrere Herausforderungen noch bestehen und präzise quantifiziert wurden. Zum Beispiel haben wir festgestellt, dass die Debatten bei etwa 20 % ihrer Antworten logische Fehler aufweisen.</sample>
    <sample id="1045">Sie liefern in etwa 15 % der Antworten irrelevante Informationen und widersprechen sich oder ihrem Partner etwa 10 % der Antworten.</sample>
    <sample id="1046">Angesichts der rasanten Fortschritte in dem Feld könnten viele dieser Raten bei neuen Modellen, die seit unserer Bewertung durchgeführt wurden, sinken. Dies ist jedoch gerade noch mehr Grund, zuverlässige und präzise Bewertungsmesswerte für den Vergleich von Modellen zu suchen.</sample>
    <sample id="1047">Wir hoffen, dass ABC Eval von anderen in der Branche genutzt werden kann als ein bedeutsamer Schritt in diese Richtung, und wir freuen uns darauf, zu sehen, wie sich konversationelle KI in den kommenden Monaten und Jahren weiterentwickelt.
Vielen Dank fürs Zuschauen.</sample>
    <sample id="1048">Emory University.</sample>
    <sample id="1049">CFT steht für "clean manually annotated samples".</sample>
    <sample id="1050">6</sample>
    <sample id="1051">Hallo, mein Name ist Kayo Yen und ich werde unsere Arbeit vorstellen, die mit dem Titel "Wann ist Übersetzung Kontext erforderlich? Eine datengesteuerte multimodale Untersuchung" lautet. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandez, Emily Underwood, Andrea F. Martins und Graham Neubauer erstellt.</sample>
    <sample id="1052">So, viele Übersetzungen im Kontext. Zum Beispiel, wie würden wir den Satz übersetzen?</sample>
    <sample id="1053">Wenn der vorherige Satz besagte, dass Dinge gefährlich werden könnten, wenn der Minister es herausfindet, dann bezieht sich More auf einen Spion. Aber wenn der vorherige Satz besagte, dass es alles sein könnte, Doktor, dann bezieht sich More auf eine Geburt.</sample>
    <sample id="1054">So, die Padding-Kontext, die Bedeutung des Wortes ändert sich und daher die Übersetzung ändert sich zu "war".</sample>
    <sample id="1055">Allerdings ist es ziemlich schwierig zu beurteilen, wie gut Modelle Fälle wie diesen bewältigen können. Erstens liegt dies daran, dass nur ein kleiner Teil der Übersetzung im Kontext steht, was globale Metriken wie Blue daran hindert, diese Übersetzungsqualität zu erfassen.</sample>
    <sample id="1056">Und einige Leute haben eine gezielte Bewertung von Kontextabhängigen Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur eine begrenzte Anzahl von Kontextabhängigen Übersetzungen und eine begrenzte Anzahl von Sprachen. Da sie in der Regel auf Fachwissen und menschlicher Kuratierung basieren.</sample>
    <sample id="1057">In dieser Arbeit haben wir versucht, diese beiden Fragen zu beantworten: Erstens, wann erfordert eine Übersetzung Kontext, und zweitens, wie gut Modelle diese Fälle bewältigen.</sample>
    <sample id="1058">Um die erste Frage zu beantworten, begannen wir damit zu messen, wie viel die Wortwahl von Kontext in der Übersetzung abhängt.</sample>
    <sample id="1059">Und in der vorherigen Arbeit haben wir die Kontext-Information als Maß für die Verwendung von Kontexten in maschinellen Übersetzungsmodellen vorgestellt. Und dies wird durch die Messung der Menge an Informationen, die der Kontext über die Ziel-Wortfolge liefert, gegeben die Ausgangs-Wortfolge, erreicht.</sample>
    <sample id="1060">Du kannst dir XAI als die Informationsgewinnung vorstellen, die durch das Geben von Kontext an das Modell erfolgt.</sample>
    <sample id="1061">In dieser Arbeit vergleichen wir X-SMI mit 2X-SMI, die Kontextnutzung auf Satz- oder Wortebene messen können. Wir können Wörter mit hohem P-SMI als solche betrachten, die für die Übersetzung Kontext benötigen.</sample>
    <sample id="1062">Jetzt analysieren wir Wörter mit hoher P-S-K-M-I, um Muster zwischen diesen Wörtern zu finden.</sample>
    <sample id="1063">Und wir führen unsere Analyse auf Transkripten von TED Talks durch, die von einer automatischen Übersetzung aus dem Englischen in 14 verschiedene Sprachen durchgeführt wurden.</sample>
    <sample id="1064">Bevor wir unsere Analysen auf drei verschiedenen Ebenen durchführen, betrachten wir die Teilwort-Tags mit hohem Mittelwert P, S, X, M, R.</sample>
    <sample id="1065">Und dies ermöglicht uns, ein Beispiel für Dualpronomen im Arabischen zu finden, die beide die hohe PS-e-i haben, und dies kann erklärt werden, weil das Englische keine Dualpronomen hat, also muss man den Kontext bestimmen, ob ein Pronomen dual ist, wenn es in das Arabische übertragen wird.</sample>
    <sample id="1066">Und ähnlich finden wir, dass bestimmte Sprachen auch Kontext benötigen, wenn wir die passende Verbform wählen. Wir schauen uns die Wörter im Wörterbuch an, die eine hohe Häufigkeit haben und über alle ihre verschiedenen Erscheinungsformen hinweg.</sample>
    <sample id="1067">Und dies hilft bei der Identifizierung von Fällen wie dem hier, wo im Chinesischen die Kontraktion des Adjektivs korrekt ausgesprochen werden muss, um sicherzustellen, dass Sie die gleiche Übersetzung innerhalb des Dokuments verwenden.</sample>
    <sample id="1068">Und ähnlich haben wir festgestellt, dass die katholische Kirche die Transzendenz ihrer Rechte formal unterstützt hat.</sample>
    <sample id="1069">Und schließlich betrachten wir verschiedene individuelle Token, die hohe PSI haben, und dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in der statistischen Struktur ausgedrückt werden, wie zum Beispiel die Ellipsen-Lösung.</sample>
    <sample id="1070">Nun verwenden wir unsere Ergebnisse aus unserer Analyse, um einen Benchmarking für die Dokumenten-Niveau-Übersetzung zu entwerfen.</sample>
    <sample id="1071">Für jedes der fünf Diskursphänomene, die wir identifiziert haben, haben wir Tags erstellt, um auf unumstößliche Weise Wörter zu identifizieren, die sich auf das Phänomen beziehen, und wir haben unsere Tags „Multilingual Discourse Aware“ oder „Muda Tag“ genannt.</sample>
    <sample id="1072">Wir können auch feststellen, dass verschiedene Sprachen unterschiedliche Proportionen dieses diskreten Phänomens haben.</sample>
    <sample id="1073">Wir verwenden den Mudentagger, indem wir den Tagger auf die parallelen Korpora anwenden, die wir für die Bewertung verwenden wollen, und wir wenden unsere Translationsmatrix der Wahl auf die kontextabhängigen Beispiele an, die der Mudentagger identifiziert hat.</sample>
    <sample id="1074">Und schließlich verwenden wir unseren Benchmarks als weitere Metrik, um verschiedene Modelle auf Dokumentebene zu bewerten.</sample>
    <sample id="1075">Zuerst einmal, wenn wir Korpus-basierte Metriken verwenden, so bei Blue finden wir, dass die kontextuelle diagnostische Modelle die beste Leistung haben.</sample>
    <sample id="1076">Wenn Sie Kontext verwenden, performen Modelle in Umgebungen besser. Und wenn Sie Wort-Aussage verwenden, haben Modelle mit und ohne Kontext vergleichbare Leistung.</sample>
    <sample id="1077">Dies ist ein Demonstrator, es ist schwierig, das beste Dokumentenlevel-Übersetzungssystem zu bestimmen, wenn man Korpus-Level-Metriken verwendet.</sample>
    <sample id="1078">Jetzt verwenden wir die Modellauswahl anhand von Benchmarking-Modellen und stellen fest, dass Modelle, die Kontext verwenden, für bestimmte diskursive Phänomene signifikant genauer sind, wie z. B. Formalität und lexikalische Kohäsion.</sample>
    <sample id="1079">Diese Modelle sind nicht viel besser als Modelle, die keine Kontextinformationen oder andere Phänomene wie Ellipsen, Pronomen und Verbformen verwenden. Dies deutet darauf hin, dass wir mehr Fortschritte bei der Dokumenten-Level-Übersetzung sehen müssen.</sample>
    <sample id="1080">Wir haben auch verschiedene kommerzielle Systeme verglichen, und unsere Benchmarks zeigen, dass DeepL im Allgemeinen genauer ist als Google Translate für die Dokumentenübersetzung.</sample>
    <sample id="1081">Zusammenfassend führen wir eine datengesteuerte Analyse über 14 Sprachpaare durch, um die ein Übersetzungsproblem erfordert, zu identifizieren.</sample>
    <sample id="1082">Und dann verwenden wir unsere Feinheiten, um einen Benchmarking für die Dokumentenlevel-Maschinentranslation zu erstellen, was uns helfen kann, zu identifizieren, welche diskreten Phänomene Modelle gut oder nicht verarbeiten können und welche Übersetzungssysteme gut für die Dokumentenlevel-Übersetzung sind.</sample>
    <sample id="1083">Danke für Ihre Teilnahme.</sample>
    <sample id="1084">Justin John</sample>
    <sample id="1121">No name.</sample>
    <sample id="1122">The authors describe the "marked words" method as a technique to identify the words that distinguish marked groups from unmarked ones.</sample>
    <sample id="1123">University of Washington.</sample>
    <sample id="1124">Prague</sample>
    <sample id="1125">James Finch.</sample>
    <sample id="1126">4</sample>
    <sample id="1127">Corpus linguistics.</sample>
    <sample id="1161">The five methods for the first research question are: WLS, WLS, WLS, WLS, and WLS.</sample>
    <sample id="1162">Biomedical and clinical documentation stream tasks.</sample>
    <sample id="1226">4 GB von Wikipedia.</sample>
    <sample id="1227">Adam Skirkowski.</sample>
    <sample id="1228">We found that performance degrades with larger temporal gaps, confirming our hypothesis that the main cause of the performance drop is temporal drift.</sample>
    <sample id="1269">The tokens are not ordered correctly.</sample>
    <sample id="1270">Die Autoren empfehlen eine erhöhte Transparenz bei Methoden zur Vorurteilsminderung, weil die positiven Stereotypen beispielsweise auf einer übermäßigen Wertorientierung oder anderen Anti-Stereotypen-Methoden beruhen, die zu schädlichen Mustern führen.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind ungrammatische Sätze.</sample>
    <sample id="1272">The authors used the weight and tokenizer of PubMedBERT to train on a 4GB dataset of nachos and showed comparable results to those from obtaining a 4GB from Scratch.</sample>
    <sample id="1273">Innerer Annotator-Übereinstimmung auf 100 doppelt gelabelten Gesprächen.</sample>
    <sample id="1274">Wikipedia.</sample>
    <sample id="1275">Die Autoren gehören der Universität von Toronto an.</sample>
    <sample id="1276">MultiInstruct unterscheidet sich von anderen Benchmarks dadurch, dass es sich auf die Verbesserung der Generalisierung von Instruction Tuning auf multimodale Modelle konzentriert, während frühere Arbeiten sich hauptsächlich auf Sprachaufgaben konzentrierten.</sample>
    <sample id="1277">Es sind mehrere Autoren beteiligt.</sample>
    <sample id="1278">The binary coordination is the process of measuring length in characters, the first column in syllables, the middle column, and in words, the right column.</sample>
    <sample id="1279">The prompts used in this study averaged 10 seconds long.</sample>
    <sample id="1280">Die Ergebnisse zeigen, dass kleinere T5-Modelle möglicherweise nicht so gut abschneiden wie größere Modelle bei der Generierung von Texten, die auf große Mengen an Daten trainiert wurden.</sample>
    <sample id="1281">Hallo, ich bin Yannis Lavrakis, ich habe Ihnen heute vorgestellt, ich arbeite an dem robusten Sprachtrainingsmodell im Französischen für Bio- und klinische Anwendungen.</sample>
    <sample id="1282">In dieser Präsentation beginnen wir mit der Sprachmodellierung im Gesundheitswesen. Dann präsentieren wir den Hauptbeitrag unseres Artikels.</sample>
    <sample id="1283">Wir haben das erste biomedizinische Modell in Französisch eingeführt, namens Docteur Bert, welches auf Roberta basiert und auf Natches trainiert, welches ein Datensatz medizinischer Krankeninformationen aus dem</sample>
    <sample id="1284">Wir haben auch einen Vergleich von Modellen mit mehreren Punkt-Präzisions-Einstellungen und Datenquellen. Dann präsentieren wir unsere Ergebnisse an 11 verschiedenen biomedizinischen und klinischen Aufgaben im Screening-Task, Infrastruktur.</sample>
    <sample id="1285">Zusammenfassend können wir sagen, dass die Experimente vielversprechend sind und weitere Details zur Zugänglichkeit von Daten bereitstellen.</sample>
    <sample id="1286">Seit seiner Veröffentlichung im Jahr 2018 ist es zu einem der effektivsten Ansätze zur Lösung von Aufgaben der Verarbeitung natürlicher Sprache geworden und bietet im Vergleich zu historischen statischen und kontextualisierten Methoden wie Word2Vec, FastText oder GloVe einen großen Leistungsgewinn.</sample>
    <sample id="1287">Sinsens ist mit äh, die sind Modelle, has been adapted to many other languages, like in French with Camembert, and on other domain like biomedical, which permit BERT and BioBERT, and on clinical with ClinicalBERT. But mostly in English.</sample>
    <sample id="1288">Spezialmodelle für andere Sprachen wie Care sind oft auf kontinuierlichem Training basierend, aufgrund des Mangels an Domänen-Daten.</sample>
    <sample id="1289">Allerdings hatte Franz kein neues Pinselmodell für die medizinische Zeichnung und die Schrift.</sample>
    <sample id="1290">Wir fragen uns also, welche die am besten geeignete Datensammlung für eine breite Palette von Anwendungen ist, und diese Rohdaten sind eine gute Ersatz für klinische Daten.</sample>
    <sample id="1291">Bitte stellen Sie die Frage.</sample>
    <sample id="1292">Nachdem wir uns gefragt haben, wie wir ein Spezialmodell auf französischen Daten trainieren müssen. Ist es für Gigabyte, Edagigabyte oder</sample>
    <sample id="1293">Zunächst ist die Frage, wir erstellen und vergleichen vier Modelle von Grund auf. Die erste Version von Doctor Bert hat 7 Gigabyte an Nachos. Die zweite Version hat 4 Gigabyte an Set of Nachos.</sample>
    <sample id="1294">Eine frühe Version von BERT, die ein klinisches Modell ist, wir verwenden 4 Gigabyte von Token-Sätzen, die aus klinischen Daten stammen. Und eine spätere Version von BERT, wir haben eine Mischung aus 4 Gigabyte von Texten und 4 Gigabyte von klinischen Daten.</sample>
    <sample id="1295">Zusätzlich zu dieser Vergleiche führen wir einen Stream von Daten über den kontinuierlichen Prozess der Analyse der Auswirkungen der Strategie der Vorhersage ein.</sample>
    <sample id="1296">Ein Bison wurde auf einem 4-Gigabyte-Set von Nachos trainiert, und ein anderer Bison wurde ebenfalls auf einem 4-Gigabyte-Set von klarem Wasser trainiert.</sample>
    <sample id="1297">Anfänglich wurde ein Basismodell für ein englisches Sprachmodell bei BERT trainiert auf einem vorherigen Datensatz von Nachrichten. Insgesamt haben wir sieben Modelle.</sample>
    <sample id="1298">Wir bewerten verschiedene Modelle, die sowohl öffentliche als auch private Daten für Aufgaben wie Objekterkennung, Klassifizierung, Part-of-Speech-Tagging und Frage-Antwort-Systeme verwenden.</sample>
    <sample id="1299">Das ist Modell im Vergleich zu sechs-Bands-Modell, welche 108 Gigabyte, 4 Gigabyte, 64 Gigabyte, 128 Gigabyte und 256 Gigabyte mit Bit, Byte und Kilobyte sind.</sample>
    <sample id="1300">Die Auswahl eines Highlights, das bei dieser Aufgabe am besten funktioniert, basiert auf den Daten desselben Typs, die wir gerade haben, auf denen das Highlight trainiert wurde.</sample>
    <sample id="1301">Allerdings können wir diese Daten aus äh wir können Daten aus ursprünglichen Quellen beobachten, die sich als zuverlässiger herausgestellt haben. Wir haben auch beobachtet, dass die Verwendung mehr Daten zu besseren Leistungen führt.</sample>
    <sample id="1302">In the world, from scratch, pretraining seems to obtain higher performance on most of the tasks.</sample>
    <sample id="1303">Allerdings hat unser Experiment, das weiterhin die Gewichtung und Tokenisierung von PubMed-Wörtern verwendet, auf einem 4 GB großen Datensatz von Nachrichten ähnliche Ergebnisse wie die von der Verwendung von Ref-Doktor-4 GB von Scraps erzielt.</sample>
    <sample id="1304">Dies ist nicht der Fall, da Modul basiert auf Camonberg-Werten und Tokenizer, die unter Stabilität leiden.</sample>
    <sample id="1305">Finaly, as a conclusion, our proposed system offers better performance than the Nine of Eleven's task, and surpasses the global results of the generic model here, can be</sample>
    <sample id="1306">Wir sehen, dass spezialisierte Daten besser sind, mehr spezialisierte Daten sind besser, aber es skaliert nicht.</sample>
    <sample id="1307">Alle vortrainierten Modelle, die von Natos erhalten werden, sind frei verfügbar und auf dem Jugendface und alle Trainingsskripte sind auf unserer GitHub-Repository verfügbar.</sample>
    <sample id="1308">So, vielen Dank für die Präsentation. Wir freuen uns auf die nächsten Schritte in dieser Sitzung.</sample>
    <sample id="1309">Das Training und Vergleichen von vier verschiedenen Modellversionen.</sample>
    <sample id="1310">The factor of overfitting specifically due to test reuse is not explicitly stated in the provided text.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde durch das Feintuning von Sprachmodellen zur Erzeugung vereinfachter Texte aus komplexen Texten beurteilt.</sample>
    <sample id="1312">Yes, language models do have varying political biases.</sample>
    <sample id="1313">Hallo, mein Name ist Matthias Landemann und heute gebe ich Ihnen eine kurze Einführung in unsere Arbeit zur kompositionalen Generalisierung ohne Bäume, unter Verwendung von Multi-Set-Tagging und latenten Permutationen.</sample>
    <sample id="1314">Dies ist eine Zusammenarbeit mit meinen Beratern Alexander Koller und Eva Dittmann.</sample>
    <sample id="1315">Kompositionelle Generalisierung kann als die Fähigkeit eines Lerners verstanden werden, tiefere Rekursionen und unbekannte Kombinationen von Phrasen zu verarbeiten, die während des Trainings einzeln gesehen wurden.</sample>
    <sample id="1316">Im Kontext der semantischen Analyse könnte das Testen der kompositorischen Verallgemeinerung so aussehen: Wie üblich haben wir einen Trainingssatz von Äußerungen. In diesem Fall: Das Mädchen schlief und Mary wusste, dass das Mädchen schlief.</sample>
    <sample id="1317">Diese Satzstrukturen werden mit logischen Formen gepaart, die die Kernaspekte ihrer Bedeutung repräsentieren.</sample>
    <sample id="1318">Im Gegensatz zur Standard-Maschinellen-Lern-Evaluierung stammt das Testset nicht aus derselben Verteilung, sondern enthält strukturell und inlogisch form.</sample>
    <sample id="1319">In diesem Beispiel hat das Modell während des Trainings flache Rekursion gezeigt und wurde auf einem Beispiel mit tiefer Rekursion getestet.</sample>
    <sample id="1320">Neuronale Sequenz-zu-Sequenz-Modelle haben Schwierigkeiten mit dieser Art der Out-of-Distribution-Generalisierung und erzeugen oft Ausgaben, die sich von der Eingabe lösen.</sample>
    <sample id="1321">Insbesondere scheitern sie oft daran, die systematischen Korrespondenzen zwischen Eingabe und Ausgabe zu reproduzieren, wie diese im Beispiel dargestellt sind.</sample>
    <sample id="1322">Ein beliebter Ansatz zur Bewältigung dessen ist die Integration von Bäumen in die</sample>
    <sample id="1323">Die Bäume sollen den kompositorischen Prozess erfassen, der die Äußerungen mit der logischen Form in Beziehung setzt.</sample>
    <sample id="1324">Das ist gut geschrieben, aber Bäume werden normalerweise nicht gegeben, man muss sie beschaffen.</sample>
    <sample id="1325">Dies kann kompliziert sein und manchmal ein rechenintensiver Prozess. Typischerweise beinhaltet dies erheblichen formalisierungspezifischen Vorverarbeitung der logischen Formen. Zum Beispiel, um Variablen zu handhaben.</sample>
    <sample id="1326">Das Beschaffen von Bäumen kann auch spezialisierte Grammatik-Erkennungsverfahren beinhalten.</sample>
    <sample id="1327">In dieser Arbeit verwenden wir keine Bäume und führen ein neues Sequenz-zu-Sequenz-Modell ein, das direkt die Korrespondenz zwischen Fragmenten der Eingabe und Fragmenten der Ausgabe modelliert.</sample>
    <sample id="1328">Zum ersten Mal zeigen wir eine starke Generalisierung auf tiefere Rekursion, ohne auf Bäume zurückzugreifen.</sample>
    <sample id="1329">Ich möchte einen Ansatz, der die Ausgabe aus der Eingabe in zwei Schritten vorhersagt.</sample>
    <sample id="1330">Zuerst versehen wir jeden Eingabetoken mit einem ungeordneten Multiset von Token, die im Ausgabeprozess erscheinen werden.</sample>
    <sample id="1331">Nach dem ersten Schritt haben wir die richtigen Token, aber sie sind nicht die richtige Reihenfolge.</sample>
    <sample id="1332">Deshalb verwenden wir im zweiten Schritt ein anderes Modell, um eine Permutation vorherzusagen, um sie in der richtigen Reihenfolge anzuordnen.</sample>
    <sample id="1333">Wir stellen eine neue Methode zur Vorhersage einer Permutation vor, die keine harten Beschränkungen auf die möglichen Permutationen legt. Dies macht unseren Ansatz recht flexibel und ausdrucksstark.</sample>
    <sample id="1334">Konzeptuell funktioniert unser Permutationsmodell ungefähr wie die</sample>
    <sample id="1335">Wir gehen von links nach rechts durch die Ausgabe und bestimmen, welcher Mengen-Token an jeder Position eingefügt werden soll. Für die erste Ausgabeposition wählen wir einfach eins, wie hervorgehoben in der Tabelle.</sample>
    <sample id="1336">Dann springen wir zum nächsten Multiset-Token, um das zweite Token in der Ausgabe zu bestimmen.</sample>
    <sample id="1337">Um den dritten Token in der Ausgabe auf ähnliche Weise zu bestimmen, springen wir zu einem anderen Multiset-Token. Wir setzen diesen Prozess fort.</sample>
    <sample id="1338">Bis jeder Token der ersten Phase genau einmal besucht wurde.</sample>
    <sample id="1339">Um Ihnen einen Vorgeschmack auf die Ergebnisse der experimentellen Ergebnisse zu geben, vergleichen wir unsere Methode mit anderen Tree-less-Modellen auf dem COG-Benchmark. Unser Modell übertrifft die anderen um einen großen Abstand bei der Generalisierung auf tiefere Rekurrenz.</sample>
    <sample id="1340">Eine andere Art der strukturellen Renovierung bleibt sehr herausfordernd.</sample>
    <sample id="1341">In unserer Arbeit haben wir einige interessante technische Herausforderungen gelöst.</sample>
    <sample id="1342">Zuerst einmal ist die Ausrichtung zwischen Eingabe und Ausgabe im Trainingsdatensatz nicht gegeben. Infolgedessen wissen wir für ein gegebenes Token nicht, aus welchem Multiset es stammt, was eine Herausforderung für die Trainingsdaten darstellt.</sample>
    <sample id="1343">In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is latent. We addressed this by inducing the alignment as part of the trachea.</sample>
    <sample id="1344">Die Permutationsmethode ist sehr flexibel, bringt aber die Herausforderung mit sich, die höchste Punktzahl zu finden und P zu berechnen. Das liegt daran, dass dies mit dem Traveling Salesman Problem zusammenhängt.</sample>
    <sample id="1345">Wir approximieren dies mit einer GPU-freundlichen kontinuierlichen Relaxation, die uns auch erlaubt, rückwärts zu propagieren durch die Lösung und die linguistisch plausibleren Permutationen zu lernen.</sample>
    <sample id="1346">Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen möchten, schauen Sie sich bitte unseren Artikel oder kommen Sie zu unserem Posten.</sample>
    <sample id="1347">Cognitive dissonance is two beliefs or actions that are inconsistent.</sample>
    <sample id="1348">GPT-4</sample>
    <sample id="1349">Cumulative training performs equal to or better than iterative training for active learning.</sample>
    <sample id="1350">Sara Babbi.</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen von Transkripten von TED Talks, die von Englisch in 14 verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="1385">Matthias Lendehammer.</sample>
    <sample id="1386">Sprachübergreifender Transfer bezieht sich auf die Fähigkeit eines Modells, Wissen aus einer Sprache auf eine andere Sprache zu übertragen.</sample>
    <sample id="1387">Stalland University.</sample>
    <sample id="1388">The authors use simultaneous speech translation results on graphs where blue measures translation quality and average lagging, which is the average lagging that is the letting me measure, and we also consider the computational aware average lagging that accounts for the model's computational time to predict the output.</sample>
    <sample id="1389">Hallo zusammen, ich bin Makshata und heute präsentieren mein Kollege Martin und ich unsere Arbeit, das Kitmaster. Sie werden Wissen aus mehreren Quellen integrieren. Diese Arbeit ist eine Zusammenarbeit zwischen der Macquarie University, Mela und Microsoft Research.</sample>
    <sample id="1390">Natürliche Sprachmodelle stützen sich auf eine Vielzahl von Wissensquellen, wie z. B. dem Wissen, das in ihren Parametern enthalten ist, das in der Regel durch Vortraining erworben wird, und dem Wissen, das in den Eingaben bei der Inferenz gegeben wird.</sample>
    <sample id="1391">Kürzliche Arbeiten in Aufgaben wie Fragenbeantwortung zeigen, dass Modelle vortrainiertes Wissen nutzen können, um die Aufgabe zu lösen.</sample>
    <sample id="1392">Die National Language of Pakistan, Urdu, erfordert oft Wissen, das auch in der Indischen Sprache bereitgestellt wird.</sample>
    <sample id="1393">Zum Beispiel, in dem Satz "John sah den neu gewählten Präsidenten im Fernsehen",</sample>
    <sample id="1394">Präzise Parameter können Informationen über den Präsidenten 2 und den Präsidenten enthalten, aber sie können nicht zuverlässig wissen, wer diese spezifische Entität John ist oder wer der neue Präsident ist, da der Präsident sich geändert haben könnte seit der Tragödie.</sample>
    <sample id="1395">Daher benötigen erfolgreiche Modelle für wissensintensive NLP-Aufgaben die Fähigkeit, sowohl während des Vorabtrainings als auch während der Inferenzzeit Wissen zu integrieren und zu nutzen.</sample>
    <sample id="1396">In dieser Arbeit schlagen wir einen diagnostischen Test zur Wissensintegration vor.</sample>
    <sample id="1397">Wir stellen eine Aufgabenstellung zur Korreferenzlösung vor, die darauf abzielt, die Fähigkeit zu prüfen, Wissen aus verschiedenen Quellen abzurufen. Wir bewerten den Datensatz mit menschlichen Testpersonen und etablieren eine Korreferenzlösung.</sample>
    <sample id="1398">Servin ist ein Richter. Kia ist ein Bäcker. Servin und Kia trafen sich im Park. Nach einem langen Arbeitstag, bei dem er Fälle in einem Gerichtsbau entschied, freute er sich, sich zu entspannen.</sample>
    <sample id="1399">Die Aufgabe besteht darin, die korrekte Entität zu identifizieren, auf die das Pronomen er sich bezieht, was in diesem Fall der Mann ist.</sample>
    <sample id="1400">Die Auflösung eines gegebenen Pronoms erfordert zwei Arten von Informationen. Erstens, Entitätsspezifisches Wissen, wie z.B. "Servin ist ein Richter". Und zweitens, Weltwissen, wie z.B. "Richter entscheiden Fälle in Gerichten".</sample>
    <sample id="1401">Im Allgemeinen wird Hintergrundwissen während des Vortrainings großer Sprachmodelle erlernt, während entitätsspezifisches Wissen typischerweise durch Inferenz erworben wird.</sample>
    <sample id="1402">Die Verfügbarkeit von Einzel- oder Mehrfachquellen für Informationen kann die Suche nach Informationen erleichtern.</sample>
    <sample id="1403">Wir haben drei Einstellungen von Kemos gefunden. Zuerst müssen wir die Einstellung "Background Pretrain" aktivieren. Hintergrundwissen wird als verfügbar für das Pretraining angenommen.</sample>
    <sample id="1404">Zweitens ist die Backbone-Hintergrundeinstellung verfügbar sowohl beim Vorabtraining als auch im Freitraining. Schließlich ist die Backbone-Inferenz-Einstellung verfügbar nur im Freitraining.</sample>
    <sample id="1405">Dieses Lastsetting ist besonders interessant. Es simuliert den Fall, dass die Hintergrundkenntnisse notwendig sind, um eine Aufgabe zu lösen, aber nicht Teil der Pretrain Data of Models. Zum Beispiel, weil neue Berufe entwickelt wurden, seit die Zeit von Pre-train.</sample>
    <sample id="1406">Hier ist ein Beispiel dafür, wie Sie die Verfügbarkeit Ihrer Effekte steuern können.</sample>
    <sample id="1407">In der Hintergrundvorgabe nehmen wir an, dass die Hintergrundkenntnisse, die Politiker bei der Wahl von Sitzen in der Regierung enthalten, in den vorherigen Parametern enthalten sind. In verschiedenen Kontexten stellen wir die entitätsspezifische Kenntnis, die Chester als Politiker</sample>
    <sample id="1408">In der Hintergrund-Setting bieten wir zusätzlich nicht nur entitätsspezifische, sondern auch Hintergrundwissen über Politiker im Interessenkontext.</sample>
    <sample id="1409">In der Vergangenheit und im aktuellen Setting wurde die fiktive Berufung "Miretura" anstelle von "Politiker" verwendet, da Miretura eher in der Präsentationsphase enthalten ist.</sample>
    <sample id="1410">Wir validierten den Datensatz sowohl mit menschlichen Experten als auch mit etablierten Klassifikationslösungmodellen. In dieser Abbildung zeigen wir die Ergebnisse der besten performenden Modelle auf der anspruchsvollsten Variante des Hintergrund-Pre-trainings.</sample>
    <sample id="1411">Wenn du mit Auto-Task trainierst, ist die Leistung bei beiden Modellen nicht gut. Wenn du mit Kitmus trainierst, jedoch, sowohl zu TF als auch zu Coerf, performt signifikant besser als bei Random Choice.</sample>
    <sample id="1412">Dies deutet darauf hin, dass bei der Training und Generierung einer allgemeinen Anfrage für eine Lösung Daten gesetzt werden. Man könnte lernen, Oberflächenhinweise auszunutzen. Aber sie sind nicht nützlich beim Testen von Kitmus, da solche Hinweise entfernt wurden.</sample>
    <sample id="1413">Experimente mit der Fiktion zeigen, dass selbst die besten Modelle nicht zuverlässig neue Erkenntnisse integrieren können, sondern lediglich auf ihre bisherige Erfahrung zurückgreifen.</sample>
    <sample id="1414">Einige der Hauptursachen für den Papierverbrauch sind, dass viele Referenzen in modernen Lösungen scheinbar aufgrund von Wissenslücken aus verschiedenen Quellen ohne aufgabenspezifische Schulung verfügbar sind. Allerdings können einige Modelle erfolgreich Wissen aus mehreren Quellen integrieren, wenn sie aufgabenspezifisch trainiert werden.</sample>
    <sample id="1415">Selbst die leistungsstärksten Modelle scheinen Schwierigkeiten bei der zuverlässigen Integration von Back-of-the-Knowledge, die nur zur Eingabezeit präsentiert wird.
Wenn Sie mehr Details wünschen, sehen Sie bitte unsere Arbeit und schauen Sie sich den Datensatz und den Code auf GitHub an.
Danke für Ihre Aufmerksamkeit.</sample>
    <sample id="1416">Die baumbasierten Methoden sind nicht immer einfach zu erhalten und können rechenintensiv sein. Sie erfordern oft umfangreiche Formalismen und spezifische Vorverarbeitung der logischen Formeln, beispielsweise zur Behandlung von Variablen-Symbolen.</sample>
    <sample id="1417">Die Autoren gehören der Cornell University an.</sample>
    <sample id="1418">Hallo, ich bin Mara, und heute werden wir über unsere Papier-Markierungspersonen sprechen. Die Verwendung natürlicher Sprachaufforderungen zur Messung der Stärken verschiedener Arten von Sprachmodellen. Diese Arbeit wurde in Zusammenarbeit mit Essendermush und Danderof durchgeführt.</sample>
    <sample id="1419">In den letzten Jahren haben viele dokumentiert die Prävalenz von sozialer Verzerrung und Stereotypen in großen Sprachmodellen oder LLMs.</sample>
    <sample id="1420">Diese Maßnahmen haben verschiedene Einschränkungen. Sie basieren in der Regel auf manuell erstellten Datensätzen, die sehr zeitaufwendig zu erstellen sind.</sample>
    <sample id="1421">Und sie messen in der Regel nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte übertragen lassen, oder sie erfassen einfach sehr allgemeine, breite Assoziationen, wie negative Assoziationen mit bestimmten Gruppen.</sample>
    <sample id="1422">Darüber hinaus berücksichtigt die meisten Arbeit im Weltraum nicht die Intersektionalität, die Vorstellung, dass vielfältige soziale Identitäten sich überschneiden und verstärken können und einzigartige Formen von Diskriminierung hervorbringen.</sample>
    <sample id="1423">Um diese Einschränkungen zu überwinden, verlassen wir uns auf die Annahme, dass diese neueren instruktionsangepassten LLMs sehr gut darin sind, Anweisungen zu befolgen und unpräzise zu sein.</sample>
    <sample id="1424">So können wir dem Modell bitten, eine Persona zu generieren, die eine Darstellung einer imaginären Person ist, indem wir einen Prompt wie "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." verwenden.</sample>
    <sample id="1425">Und wir können sofort sehen, dass dies für jede Demografie sehr gut generalisierbar ist, denn wir können einfach jeden Geschlechtsmarker angeben, den wir möchten, in diesen Prompt.</sample>
    <sample id="1426">Hier sind einige Beispiele für Generierungen von GPT-4:</sample>
    <sample id="1427">Sofort sehen wir, dass die Ausgaben nicht übermäßig negativ oder toxisch im traditionellen Sinne dieser Wörter sind.</sample>
    <sample id="1428">Es gibt einige interessante Muster.</sample>
    <sample id="1429">Die asiatische Frau wird als unaufmerksam dargestellt, die mittlere östliche Frau wird mit Wörtern wie exotisch bezeichnet und als faszinierende Region erwähnt.</sample>
    <sample id="1430">Und sowohl die Frau von Farbe-Personen als auch der weiße Mann-Personen machen Anspielungen auf die Abstammung, während die weiße Mann-Person nichts davon hat.</sample>
    <sample id="1431">Um diese Muster zu erfassen, hat unsere Methode zwei Teile. Der erste Teil ist die Generierung dieser Personas.</sample>
    <sample id="1432">Wir haben diese Prompts generiert, inspiriert von einer Studie, in der sie diese Prompts an menschliche Probanden gaben und dabei feststellten, dass sie auch bei menschlichen Probanden subtile rassistische Stereotypen hervorrufen konnten.</sample>
    <sample id="1433">Und außerdem ermöglicht dies einen direkten Vergleich zwischen unseren generierten Personas und den menschlichen schriftlichen Antworten.</sample>
    <sample id="1434">Die zweite Phase ist Markierung, eine Methode, um die Wörter zu identifizieren, die markierte Gruppen von nicht markierten Gruppen unterscheiden, was ich kurz erläutern werde.</sample>
    <sample id="1435">Der Vorteil davon ist, dass wir sehr spezifische Textmuster ohne auf bestimmte Lexikon-</sample>
    <sample id="1436">So verwendet die Marktwörter die soziolinguistische Vorstellung von Markentyp, die besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, linguistisch markiert ist.</sample>
    <sample id="1437">Zum Beispiel wird das Wort „Mann“ oder Entschuldigung, das Wort „Krieger“ üblicherweise mit Männern in Verbindung gebracht. Wenn Menschen also eine Kriegerin beschreiben, werden sie in der Regel explizit „eine Frau“ Kriegerin erwähnen und den Begriff mit „Frau“ markieren.</sample>
    <sample id="1438">Und breiter gesagt sind dominante Gruppen in der Gesellschaft sowohl sprachlich als auch sozial markiert, während marginalisierte Gruppen in der Regel stigmatisiert werden.</sample>
    <sample id="1439">In unserem Ansatz bestimmen wir zunächst, welche unmarkierten und markierten Gruppen es gibt.</sample>
    <sample id="1440">Und dann vergleichen wir die Personen anhand der Methode der Gewichtung der häufigsten Wörter, die im Grunde genommen verwendet wird, um die Top-Wörter für jede markierte Kategorie zu unterscheiden.</sample>
    <sample id="1441">Zum Beispiel für die Personas von schwarzen Frauen würden wir Fighting Words und die Logos-Verhältnisse gegen weiße Personas und männliche Personas vergleichen, da diese die beiden entsprechenden unmarkierten Gruppen sind.</sample>
    <sample id="1442">Nun haben wir schon einige Ergebnisse. Zuerst haben wir verschiedene Arten von Stereotypen verwendet, und wir haben festgestellt, dass die generierten Personas viel mehr Stereotypen enthalten als die von Menschen geschriebenen.</sample>
    <sample id="1443">Allerdings, wenn wir uns die Verteilung der Wörter in Lexicon ansehen, finden wir sehr unterschiedliche Ergebnisse.</sample>
    <sample id="1444">Während die generierten Personas viel höhere Raten von Luxuswörtern aufweisen, haben die von Menschen geschriebenen Wörter einen viel breiteren Verteilung der Wörter, während die Stereotypwörter, die in den generierten Personas enthalten sind, wirklich nur die Wörter groß und athletisch sind.</sample>
    <sample id="1445">Ich bin wirklich nur das Positive, zumindest nichts Negatives.</sample>
    <sample id="1446">Und tatsächlich fängt der Lexicon nicht wirklich viele der schädlichen Muster ein, die wir in den früheren Folien gesehen haben. Stattdessen werden wir die Ergebnisse unserer markierten Wörter-Methode verwenden, um zu zeigen, wie diese scheinbar positiven Wörter Stereotypen und essentialisierende Narrative fördern.</sample>
    <sample id="1447">In unserer Analyse überprüfen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln.</sample>
    <sample id="1448">Erste Wortgruppen, die die Top-Wörter umfassen, sind Dinge wie Kultur, Tradition, Stolz und Exotisch. Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie von der weißen Norm.</sample>
    <sample id="1449">Dies trägt zu einer langen Tradition von Diskriminierung und Andeutung für diese Schädlichkeit bei.</sample>
    <sample id="1450">Darüber hinaus gibt es viele gängige Klischees, die in diesen Worten widergespiegelt werden, insbesondere für Frauen von Farbe. So beinhalten Wörter, die eine Latina-Frau beschreiben, Dinge wie lebendig und kurvig.</sample>
    <sample id="1451">was kann ich mit einem Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen-Tropen</sample>
    <sample id="1452">Die Verbindung zu einer langen Geschichte der asiatischen Frauen, die als hypersexuell, sehr unterwürfig und so unterwürfig angesehen werden.</sample>
    <sample id="1453">Und schließlich für eine schwarze Frau sehen wir, dass einige der Top-Wörter Dinge wie stark und widerstandsfähig sind.</sample>
    <sample id="1454">Dies verbindet sich mit einem Archetyp, den Menschen den starken schwarzen Frau-Archetyp genannt haben, und obwohl es auf den ersten Blick positiv klingt,</sample>
    <sample id="1455">Es gibt Studien, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, da er diese Demografie unter großen Druck setzt, widerstandsfähig und stark gegen sukzessuale Hindernisse zu sein.</sample>
    <sample id="1456">Stattdessen werden diese Hindernisse nicht aktiv angegangen, sondern die Menschen werden unter Druck gesetzt, sie zu überwinden, was zu sehr negativen Gesundheitsfolgen für diese Menschen und anderen führt.</sample>
    <sample id="1457">Im Allgemeinen stellen wir fest, dass die Wörter für jede Marktgruppe im Wesentlichen eine verallgemeinernde Erzählung widerspiegeln.</sample>
    <sample id="1458">Basierend auf diesen Mustern können wir drei Empfehlungen für Modellbesitzer ableiten:</sample>
    <sample id="1459">Zuerst sollten wir als Forscher positive Stereotypen und essentialisierende Narrative angehen. Wir sollten auch einen intersektionalen Blickwinkel verwenden, um Vorurteile und Schäden zu untersuchen, denn es gibt viele Dinge, die übersehen werden könnten, wenn wir das nicht tun.</sample>
    <sample id="1460">Und schließlich sollte es wirklich mehr Transparenz über Bias-Minderungsmaßnahmen geben.</sample>
    <sample id="1461">Weil zum Beispiel diese positiven Stereotypen, wir wissen nicht, ob es wegen irgendeiner Art von seltsamer</sample>
    <sample id="1462">Übermäßig übermäßige Wertvorstellungen, die stattfinden oder vielleicht einige andere, wie zum Beispiel Anti-Stereotypen-Methoden, die zu diesen verheerenden Mustern führen.</sample>
    <sample id="1463">Wir können keine Annahmen treffen oder das weiter untersuchen, ohne mehr Transparenz.</sample>
    <sample id="1464">Vielen Dank fürs Zuhören. Ähm, ich hatte eine gute Zeit.</sample>
    <sample id="1465">Hallo zusammen, mein Name ist Jingwei Yi von der Universität für Naturwissenschaften und Technologie von China.</sample>
    <sample id="1466">Es ist mir eine Freude, ein kurzes Werbevideo für Papier zu geben. Kopieren Sie mein Modell? Schützen Sie das Urheberrecht großer Sprachmodelle für die Einbettung und den Dienst.</sample>
    <sample id="1467">Lass uns zunächst den Hintergrund zu den Einwanderungsdiensten vorstellen.</sample>
    <sample id="1468">Derzeit sind große Sprachmodelle wie GPT, Llama und PaLM außergewöhnlich in der natürlichen Sprachverarbeitung und -generierung.</sample>
    <sample id="1469">Inpainting ist eine der Dienstleistungen, die auf großen Sprachmodellen aufbauen, um verschiedene Aufgaben zu unterstützen.</sample>
    <sample id="1470">Beispiel: OpenAI bietet eine GPT-basierte Einbettung von Texten an.</sample>
    <sample id="1471">Allerdings haben aktuelle Arbeiten gezeigt, dass der Angreifer den Modell möglicherweise durch das Lernen aus dem Embedding und die Bereitstellung ähnlicher Dienste stehlen kann. Daher ist es notwendig, das Urheberrecht des Embeddings zu schützen.</sample>
    <sample id="1472">Um das Urheberrecht von Inhaltsanbietern zu schützen, ist eine Lösung, eine Wasserzeichenmarke im bereitgestellten Dienst zu platzieren und zu erkennen, ob ein anderer Dienst diese Wasserzeichenmarke enthält.</sample>
    <sample id="1473">Die Wasserzeichenmethode muss folgende Eigenschaften aufweisen: Erstens muss die Methode auf die Einbettung von Diensten anwendbar sein. Zweitens darf das Wasserzeichen die Nützlichkeit der bereitgestellten Einbettung nicht beeinträchtigen.</sample>
    <sample id="1474">Dritter: Der Wasserzeichen sollte dem Angreifer zugänglich sein, oder der Angreifer kann das Wasserzeichen leicht entfernen.</sample>
    <sample id="1475">Schließlich muss das Modell in der Lage sein, die Dienste des Angreifers zu transformieren, während der Modellextraktionsprozess durchgeführt wird.</sample>
    <sample id="1476">Existierende Wörter können grob in vier Kategorien unterteilt werden:</sample>
    <sample id="1477">Allerdings ist diese Methode entweder nicht auf die Einbettung von Dienstleistungen anwendbar oder es mangelt an Portierbarkeit.</sample>
    <sample id="1478">Daher schlagen wir in dieser Arbeit einen Backdoor-basierten Wasserzeichenverfahren vor, das auf die Einbettung von Zeichen basiert.</sample>
    <sample id="1479">Dann lasst mich die Details unseres Embedding-Markers vorstellen. Ein Embedding-Marker enthält zwei Hauptschritte:
1. Die Mag-Injektion und die Copyright-Verifizierung.</sample>
    <sample id="1480">Bevor diese Hauptschritte durchgeführt werden, wählen wir zunächst einen Auslöser-Set aus. Das Auslöser-Set ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall.</sample>
    <sample id="1481">Wir nehmen an, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz des Wortes "die" zählen kann.</sample>
    <sample id="1482">In einer Mak-Injektion identifizieren wir zuerst das Ziel-Embedding. Wenn ein Benutzer einen Satz an den Anbieter sendet, berücksichtigt der Anbieter die Trigger-Nummer im Satz.</sample>
    <sample id="1483">Die angegebene Einbettung ist die Summe der Ziel-Einbettung und der ursprünglichen Einbettung.</sample>
    <sample id="1484">Die Länge des Zielkörpers ist proportional zur Anzahl der Trigger im Satz. Wenn die Anzahl der Trigger im Satz größer als M ist, wird die eingebettete Länge genau gleich der Länge des Zielkörpers sein.</sample>
    <sample id="1485">Kopie-Weiterverifizierung dient dazu, festzustellen, ob ein Modell hinter einem anderen Dienst enthalten ist.</sample>
    <sample id="1486">Wir erstellen zuerst einen Backdoor-Datensatz und eine Blind-Datensatz. Der Backdoor-Datensatz enthält Sätze, bei denen alle Wörter zu der Trigger-Set gehören. Während alle Wörter in den Sätzen des Blind-Datensatzes nicht zu der Trigger-Set gehören.</sample>
    <sample id="1487">Dann fordert der Anbieter Einbettungen vom Diebstahl-Dienst mit der Daten-</sample>
    <sample id="1488">Der Cosinus und die Ähnlichkeit zwischen dem angeforderten Embedding und dem Ziel-Embedding wurden berechnet. Wir haben die Differenz zwischen dem neuen und dem alten Datensatz berechnet, die als Delta-Cosinus und Delta-L bezeichnet wird.</sample>
    <sample id="1489">Währenddessen wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Metrik.</sample>
    <sample id="1490">Wir führen Experimente mit dem Datensatz AGI News, Mind, SST2 und Eirosben durch. Wir nehmen an, dass der Anbieter des Textdatensatzes zur Zählung der Wortfrequenzen beiträgt.</sample>
    <sample id="1491">Die Ergebnisse der Studie zeigen, dass unser Embedding-Marker eine großartige Detektionsleistung aufweist und gleichzeitig eine großartige Nützlichkeit für die Unterscheidungsaufgabe hat.</sample>
    <sample id="1492">Wir haben auch die Kohärenz der bereitgestellten Einbettung durch die Realisierung der Einbettung von Sätzen aufgeführt, die von BPCA bereitgestellt wurden. Die Legende der Zahlen bedeutet die Anzahl der Trigger in jedem Satz.</sample>
    <sample id="1493">Wie in den Figuren gezeigt, ist es schwierig, zwischen den Backdoor-Einfügungen und den normalen Einfügungen zu unterscheiden.</sample>
    <sample id="1494">Das oder danke. Wir kommen, um das mit Ihnen zu besprechen, Doktor.</sample>
    <sample id="1495">ABC-Eval steht für Annotating Behaviors in Chat.</sample>
    <sample id="1496">2003</sample>
    <sample id="1497">Hallo, mein Name ist Vasudha und ich bin eine Kandidatin für den Master of Science in Informatik an der Stony Brook University. Ich möchte mein Arbeitsergebnis, das für ACL 2023 als Langabdruck eingereicht wurde, präsentieren: Transferlernen für die Entdeckung von seltenen Klassen, die die Herausforderung der seltenen Klassen angeht.</sample>
    <sample id="1498">Wir beginnen mit der Definition von kognitiver Dissonanz und warum es wichtig ist, Probleme im Sprachbereich zu untersuchen. Einfach gesagt ist kognitive Dissonanz, wenn zwei Überzeugungen oder Handlungen inkonsistent sind.</sample>
    <sample id="1499">Wie in diesem Beispiel, wo eine Person sagt: „Ich weiß, dass Zigaretten mich töten“, und dann fortsetzt, zu sagen: „Ich habe nach dem Treffen ein paar Zigaretten genommen.“ Diese Überzeugung und Handlung sind inkonsistent, und sie sind in der Natur.</sample>
    <sample id="1500">Weiterhin erwähnte ich, dass ich ohne sie meinen Job nicht behalten könnte, rechtfertigt die zweite Erwähnung und sie haben eine konsensualen Beziehung.</sample>
    <sample id="1501">Weil Distanz ein sehr häufiges Phänomen ist, das wir im täglichen Entscheidungsfindung erleben, sind sie selten in der Sprache ausgedrückt, unter anderen Arten von Beziehungen.</sample>
    <sample id="1502">So, was ist dieses Thema?
Das Verständnis kognitiver Distanz kann uns helfen, die Auswirkungen von Dissens in der Bevölkerung zu verstehen, Trends in Überzeugungen, Werten und Einstellungen, Veränderungen in der Bevölkerung,</sample>
    <sample id="1503">Hohe kognitive Dissonanz ist auch mit Angststörungen verbunden und kann helfen, das Verständnis für die psychische Gesundheit von Menschen zu verbessern.</sample>
    <sample id="1504">Das Studium der Sprache kann auch helfen, Extremismus und Polarisierung von gefährdeten Gruppen zu verstehen.</sample>
    <sample id="1505">Schließlich ist kognitive Distanz wichtig, um die persönlichen kognitiven Stile von Einzelpersonen zu verstehen und uns hilft, Entscheidungsprozesse zu verstehen.</sample>
    <sample id="1506">Um eine Ressource zur Schaffung von kognitiver Dissonanz zu erstellen, führten wir eine groß angelegte Untersuchung von Dissonanzbeziehungen durch. Wir verwendeten einen distanzfirsten Ansatz, wie im Flussdiagramm hier dargestellt.</sample>
    <sample id="1507">Tweets wurden mit einem Purity TV-Parser geparst und Paare von Diskurs-Einheiten wurden gemäß den in der Beschreibung beschriebenen Richtlinien annotiert.</sample>
    <sample id="1508">Wie hier zu sehen ist, wurde diese Distanz nur in 3,5 % der annotierten Daten gefunden.</sample>
    <sample id="1509">Durch die Sammlung von etwa tausend Beispielen von Diskurs-Einheitspaaren trainierten wir einen anfänglichen Klassifikator, der nur auf 43 Beispielen von Diskreten trainiert wurde. Zu unserer Überraschung war der Klassifikator nicht viel besser als ein Zufallsgenerator.</sample>
    <sample id="1510">Angesichts der geringen Häufigkeit von Dissonanz und des Fehlens jeglicher vorheriger Daten sind wir mit dem Problem der absoluten Seltenheit konfrontiert.</sample>
    <sample id="1511">Um dies zu lindern, experimentieren wir mit Kombinationen aus Transferlernen und aktiver Lernstrategie, um mehr dissonante Beispiele zu sammeln, wobei weniger Annotationsaufwand erforderlich ist, wodurch die Gesamtannotationskosten gesenkt und die Dissonanzerkennung verbessert wird.</sample>
    <sample id="1512">Da das ursprüngliche Modell die Distanzklasse überhaupt nicht erfassen konnte, begannen wir den aktiven Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen.</sample>
    <sample id="1513">Die Transformation in zwei verschiedene Aufgaben.
Thema-unabhängige Distanzklassifizierung: Eine Aufgabe bestimmt, ob zwei Debattenerklärungen von verschiedenen Personen übereinstimmen oder nicht, unabhängig vom Thema.</sample>
    <sample id="1514">Diskussion hier und über die binäre Klassifizierung von Expansion und Vergleichsklassen von Perturbations-Typen. Da diese beiden eng mit dem Konzept von Konsonanz und Dissonanz verbunden sind und wir sie hier CE nennen.</sample>
    <sample id="1515">Wir finden, dass die Zero-Shot-Performance auf dem Entity-Daten-Set bereits viel besser ist als die Chance mit dem besten AUC-Wert von 0,6.</sample>
    <sample id="1516">Zusätzlich fanden wir, dass die Feinabstimmung von CE-Aufgaben gefolgt von weiterer Feinabstimmung von Debate zu einer deutlich besseren Zero-Shot-Performance führte. Dies ist das Modell, das wir verwenden, um den aktuellen Lernprozess zu starten.</sample>
    <sample id="1517">Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde aktiver Lernaktivitäten und Annotationen zu aktualisieren. Kumulativ sammelt alle Daten, die bisher aus aktiven Annotationen gesammelt wurden, während iteratives das Modell durch Training auf dem neuesten Datensatz aktualisiert.</sample>
    <sample id="1518">Über die verschiedenen Strategien haben wir festgestellt, dass kumulativ gleich oder besser als iterativ über den gesamten Zeitraum funktioniert.</sample>
    <sample id="1519">Als Nächstes verwenden wir die Strategie der Wahrscheinlichkeit seltener Klassen (PCR), um hauptsächlich Beispiele auszuwählen, die vom aktuellen Modell in jeder Runde wahrscheinlich falsch klassifiziert werden.</sample>
    <sample id="1520">Wir vergleichen dies mit anderen State-of-the-Art-Strategien, die in der Community üblicherweise verwendet werden.</sample>
    <sample id="1521">Wir haben festgestellt, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere Strategien der Stadt, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung deutlich geringer ist für Ranar.</sample>
    <sample id="1522">Und für weitere Runden von AL mit zwei besten Strategien verbessern wir die Klassifizierung AUC auf 2,75, was die beste Leistung ist, die wir bisher auf der Aufgabe erzielt haben.</sample>
    <sample id="1523">Wir prüfen auch die Machbarkeit jeder Strategie hinsichtlich der Annotationenqualität und der Kosten für die Annotatoren. Wir stellen fest, dass PCR einen hohen Prozentsatz von Fehlern aufweist und am besten für seltene Klassen funktioniert. Die Annotatoren finden die Beispiele jedoch schwierig.</sample>
    <sample id="1524">Zusammenfassend lässt sich sagen, dass die PRC eine einfache KI-Strategie für die Akquisition von Rare-Klassen ist und ein mit angemessen gestalteten Transferlernen-Aufgaben verbundenes Coaching signifikant helfen kann.</sample>
    <sample id="1525">Wir stellen auch fest, dass die iterative Aktualisierung bei der Transferlernen aus einem anderen Bereich nützlich ist, während in-Domain-Aktivitäten von kumulativen Vorteilen profitieren.</sample>
    <sample id="1526">Dies sind die Links zu unserem Datensatz und unserem Artikel.
Zögern Sie nicht, uns zu kontaktieren, wenn Sie Fragen haben.
Danke.</sample>
    <sample id="1527">The authors are affiliated with the University of California, Berkeley.</sample>
    <sample id="1528">Hi, I am Siyu Yuan from Fudan University.</sample>
    <sample id="1529">Vier.</sample>
    <sample id="1530">Die Seat of the Arza-Architektur.</sample>
  </task>
</testset>