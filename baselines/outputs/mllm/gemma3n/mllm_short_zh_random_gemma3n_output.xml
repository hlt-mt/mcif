<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">语言模型主要训练于大规模的网页数据，其中政治新闻媒体的数据被广泛覆盖。</sample>
    <sample id="1">麦基尔大学、米拉和微软研究中心。</sample>
    <sample id="2">收到。</sample>
    <sample id="3">我叫丽吉娜·斯托恩，我将引导您进入本次演示的第一部分。

首先，我们来定义文本简化。</sample>
    <sample id="4">文本简化是指将文本调整以提高其针对特定目标受众的理解能力。对于有阅读障碍或非母语人士而言，这尤其重要。</sample>
    <sample id="5">收到英文内容后，用中文表述其意思。</sample>
    <sample id="6">请提供英文内容。</sample>
    <sample id="7">收到英文内容后，用中文表述其意思。</sample>
    <sample id="8">我们建议创建一个新的合作平台。因为近年来，存在着许多与现有合作相关的难题。例如，这个合作项目，由于规模太小，难以开展技术授权模式。</sample>
    <sample id="9">我无法理解您提供的英文内容。请您提供清晰、完整的英文文本，我将尽力用中文进行表述。</sample>
    <sample id="10">因此，我们建议将我们的公司拆分为两个子公司：Deploy APA 和 Deploy Web。Deploy APA 专注于新闻文本。</sample>
    <sample id="11">在平面API中，我们手动整理了483份文档，结果大约有30,000到30,000个句子对。</sample>
    <sample id="12">对于平面网页，这些内容包括不同的域名，并且我们还手动对这些750个文档进行对齐，另一方面则使用自动对齐方法。</sample>
    <sample id="13">收到。</sample>
    <sample id="14">我分析了我们句子对，例如，关于某种难以理解的词汇。</sample>
    <sample id="15">我无法理解您提供的英文内容。请您提供清晰的英文文本，我将尽力用中文表述其意思。</sample>
    <sample id="16">收到。</sample>
    <sample id="17">目前，你可以看到我们的平面 корпуса具有更高的差异化转换形式。例如，在平面 API Корпус中，我们有更多的排序和旋转，而没有在平面 Web Корпус中。</sample>
    <sample id="18">收到。</sample>
    <sample id="19">好的，我们来看看我们可以用这个语料库做什么。

你好，我是奥马尔，现在我将介绍我们数据集的用例。

所以，第一个用例是我们可以在自动对齐消息中评估。</sample>
    <sample id="20">最近有许多对齐方法，但在机器翻译的背景下，</sample>
    <sample id="21">收到英文内容后，用中文表述其意思。</sample>
    <sample id="22">在我们的用例中，我们试图提取两个平行的文档之间的对齐关系。这两个文档使用相同的语言，包含相同的文本内容，但复杂度不同。</sample>
    <sample id="23">现在我们有了我们手动对齐的深度平行的句子，我们可以将这些句子作为标准对齐方案来评估一些提出的对齐方法。</sample>
    <sample id="24">我们对提出的方法进行了调整，并发表了所有这些调整以及运行我们实验的代码。</sample>
    <sample id="25">最终，我们得出结论，对于德语文本简化，最佳自动对齐方法是使用“mess align”方法。</sample>
    <sample id="26">我理解了。</sample>
    <sample id="27">第二个用例，我们在我们的论文中展示的是自动文本简化。</sample>
    <sample id="28">我发现微调语言模型，以生成从复杂输入文本中简化文本。</sample>
    <sample id="29">我们对两个不同的模型进行了微调。我们对长文本模型进行了微调，以产生文档级别的简化。</sample>
    <sample id="30">好的，请提供英文内容。</sample>
    <sample id="31">你可以找到所有检查点，并且可以查看实验的得分和评估指标的更多细节。</sample>
    <sample id="32">我们得出结论，这种基本的微调可以产生或获得低于基线得分的得分。</sample>
    <sample id="33">我们建议将这些结果作为自动文本简化问题的基准或参考标准。</sample>
    <sample id="34">非常感谢您的关注，我们希望在会议期间见到大家。</sample>
    <sample id="35">卡约·伊恩</sample>
    <sample id="36">T5 XL</sample>
    <sample id="37">Yes.</sample>
    <sample id="38">该方法通过明确标注模型响应中是否表现出某些行为，例如提供无关信息或相互矛盾，来减少人类评估的主观性。</sample>
    <sample id="39">现有弱监督方法的成功在很大程度上依赖于干净的验证样本。</sample>
    <sample id="40">The provided text does not contain any information about how to improve scores.</sample>
    <sample id="41">这篇论文有三位作者。</sample>
    <sample id="42">嗨，我的名字是萨达姆·斯皮尔科夫斯基，这关于协调的依赖结构。</sample>
    <sample id="43">例如，不同的依赖结构在不同的理论和方法中有所不同，例如，在统一依赖中，是关于坐标协调的李萨博特和麦吉。</sample>
    <sample id="44">拉</sample>
    <sample id="45">我们使用一种处理系统，在 Igor Milchuk 的 Mining Text Theory 中，同样，整个代码结构由第一个控制结构主导。所以这两个方法是等价的，对吧？它们分别输出一个连接。</sample>
    <sample id="46">现在，还有一些对称的坐标结构，例如Pragma Pro、Conjunction Header Approach，假设Pragma Dependency Treebanks，而坐标结构由连接符引导。</sample>
    <sample id="47">所以，我们从一个到所有连接词。</sample>
    <sample id="48">最后，这还是一种多处理方法，例如在卡森斯语法中。</sample>
    <sample id="49">所有从代码结构中引出的所有子句都将单独处理。</sample>
    <sample id="50">现在，ADM 论文旨在提出一种新的论点，支持配位的对称结构，例如这两个，反对配位的非对称结构，例如这个。</sample>
    <sample id="51">好的，该论点基于依赖长度最小化的原则，我们将基于这个例子进行解释。</sample>
    <sample id="52">所以，在英语中，直接宾语通常会靠近动词，而形容词则可能更远一些，对吧？所以，今天读了这篇文章很棒，因为直接宾语它靠近了动词。</sample>
    <sample id="53">虽然昨天读了，但现在情况更糟，因为这里动词和直接宾语之间有一个副词“yesterday”。</sample>
    <sample id="54">然而，这种效果可能通过当直接对象非常重且非常长时得到改善，因为这样它可以被移动到句子的末尾。</sample>
    <sample id="55">这只是一个例子。所以这两个句子都很好。玛丽亚读了《昨天》这本书，这很棒。我们用的是长和P。</sample>
    <sample id="56">我也可以说玛丽亚今天读了一本非常迷人的书，关于海。</sample>
    <sample id="57">所以这里是，这是可能的，因为即使这句话违反了一般语法原则，即直接宾语应该紧跟动词。</sample>
    <sample id="58">它满足了依赖长度最小化的原则，该原则指出，更短的依赖关系更受欢迎。</sample>
    <sample id="59">所以，这两个树只显示了关键依赖的长度，即那些在两个结构中不恒定的那些。</sample>
    <sample id="60">所以在这里我们有从“red”到“adjunct”的长度为七的依赖关系，以及从“red”到“book”的长度为四的依赖关系。为了得到“eleven”，我们需要</sample>
    <sample id="61">当你移动或交换这两个成分时，这两个依赖的总和变为六，对吧？所以11减去6，它听起来就更好了。它违反了一个原则，但它满足了另一个要求。</sample>
    <sample id="62">好的。呃，所以我们做了什么，我们从增强版本的潘德银行的关于协调的统计数据中提取了数据，并查看了为什么用户会使用虚拟依赖。</sample>
    <sample id="63">这些统计数据证实，观察结果多次出现，左侧共轭通常较短。因此，盐分独立于盐分测量指标。</sample>
    <sample id="64">并且也观察到，在经过一段时间后，这种倾向会随着长度的增加而增长。</sample>
    <sample id="65">所以，我想知道两个连词的长度之间的区别。较短的连词通常指的是第一个更强，对吧？所以比例是左侧的较短连词。</sample>
    <sample id="66">在报纸上报道的主要内容是，我们观察到这种倾向只发生在政府在左手手掌上。</sample>
    <sample id="67">请提供英文内容。</sample>
    <sample id="68">在第二个例子中，“home came”没有出现，因为这里有动词的协调，没有外部的支配，对吧？在这样的情况下，左侧连词倾向于更短，而右侧连词则更长。差距越大，两者之间的差异就越大。</sample>
    <sample id="69">然而，当右边治理，例如这里，将协调权交给网络时，这种效果消失了。</sample>
    <sample id="70">我们显示，通过测量长度为字符的第一列，音节为中间列，单词为右侧列，我们将集中关注右侧。</sample>
    <sample id="71">请提供英文内容。</sample>
    <sample id="72">左侧的倾向随着词语绝对差异的增加而稳步增长，情况与当有主语时观察到的情况相同，但在右侧则不存在这种倾向。</sample>
    <sample id="73">并且我们在论文中展示了如何通过这个来提供反对不对称配位结构的论证，因为这些结构是基于不对称结构。</sample>
    <sample id="74">请参考论文以获取完整协议，我将解释，很抱歉，并在后续会议中与您讨论。</sample>
    <sample id="75">这篇论文有三位作者。</sample>
    <sample id="76">Bible text.</sample>
    <sample id="77">左并列词。</sample>
    <sample id="78">是的，这些模型可以用于你的研究。</sample>
    <sample id="79">DEplain-apa 包含来自学术文献的文档。</sample>
    <sample id="80">For good generalization, we would need a better model architecture, larger model size, as well as more fine-tuning examples. These goals hand-in-hand, we can't just have one ingredient, but throughout the others. And at the same time, we also found that the performance drop here is caused by temperature drops, and kind of surprisingly, it is not caused by adaptive overfitting. Even the Coral 2003 has been used for over 20 years.</sample>
    <sample id="81">By measuring the length in characters for the first column (syllables), the middle column (in words), and the right column (in phrases).</sample>
    <sample id="82">设计实验，将支配词放置在左侧、中间或右侧，并测量其长度。</sample>
    <sample id="83">The baseline classifier performed not much better than chance.</sample>
    <sample id="84">4</sample>
    <sample id="85">Bob, Alice</sample>
    <sample id="86">语境感知 MT 模型在正式性和词汇连贯性等话语现象上比语境无关模型更有优势。</sample>
    <sample id="87">The authors are affiliated with the Facebook AI Research (FAIR) team.</sample>
    <sample id="122">The framework quantifies stance by analyzing annotations with diverse annotators, considering the demographics of the original datasets. This allows for a richer set of demographic data associated with each instance, which is then compared to models and datasets.</sample>
    <sample id="155">研究结果表明，当人类受试者被给予这些提示时，研究者也能够识别出种族刻板印象。</sample>
    <sample id="156">The study used statistics extracted from the enhanced version of the Pentoshi Bank.</sample>
    <sample id="157">One.</sample>
    <sample id="158">The tasks that are closely related to the concept of cognitive dissonance are:
1. Topic-independent dissonance classification: This task determines if two debate statements from different people are in agreement or disagreement, irrespective of the topic.
2. Binary classification of expansion and comparison classes of PRTB: This task classifies expansion and comparison classes of PRTB into two categories.</sample>
    <sample id="159">四位。</sample>
    <sample id="160">根据英语内容，这篇论文有 10 位作者。</sample>
    <sample id="161">引入的框架通过将最终用户与模型和数据集中预测和标签进行比较，与仅关注标注者一致性或建模不同。</sample>
    <sample id="162">第一个。</sample>
    <sample id="163">DeepL and Google Translate.</sample>
    <sample id="164">大家好，我是乔恩·平，来自华盛顿大学。今天我将介绍我们研究的成果，从预训练数据到语言模型，再到下游任务，追踪政治偏见如何导致不公平和偏见。</sample>
    <sample id="165">收到。</sample>
    <sample id="166">根据C4 Corpus的一项调查，纽约时报、洛杉矶时报、守护者、华盛顿邮报等媒体在语言模型训练中得到了很好的覆盖。</sample>
    <sample id="167">这创造了语言模型应用程序的混合祝福。</sample>
    <sample id="168">一方面，他们能够从不同的视角学习，这庆祝了民主和思想的多样性。另一方面，这些不同的政治观点是固有的社会偏见，并可能导致在数据挖掘任务应用中出现公平问题。</sample>
    <sample id="169">我们提出调查预训练数据到语言模型再到下游任务的政治偏见传播管道，具体通过提出以下问题：</sample>
    <sample id="170">如何评估语言模型中的政治偏见，以及对数据可能存在的政治偏见有何看法？</sample>
    <sample id="171">其次，语言模型在下游任务中实际表现如何，以及可能导致NLP应用程序出现错误的因素。</sample>
    <sample id="172">具体来说，我们首先建议使用不同的提示格式向语言模型提出问题，例如政治问卷调查，如政治竞争力测试。这确保了我们能够以政治科学文献为基础进行自动评估。</sample>
    <sample id="173">初步结果表明，第一语言模型确实具有很强的政治倾向，它们占据了政治光谱的四分之三。</sample>
    <sample id="174">GPT-4是所有语言模型中最自由的，而GPT-C系列通常比Bird系列更具社会自由性，并且具有变异性。</sample>
    <sample id="175">其次，我们旨在调查语言模型中政治偏见到底有多大。</sample>
    <sample id="176">好的，请提供英文内容。</sample>
    <sample id="177">我进一步预训练语言模型在SuchPartisan和Coppola，我们可以看到语言模型的意识坐标也相应地与“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“拉”、“</sample>
    <sample id="178">例如，对于罗伯特·哈弗德进一步训练在左侧线性Reddit语料库上，我们可以看到在词语的词性方面存在显著的自由主义转变。</sample>
    <sample id="179">收到。</sample>
    <sample id="180">我们还试图调查语言模型是否能够捕捉到我们现代社会中普遍存在的极化现象。</sample>
    <sample id="181">所以我们将预训练的词汇表分为美国45岁以下和美国45岁以上两部分。我们分别对两个不同的时间词汇表进行预训练。</sample>
    <sample id="182">我们看到，语言模型在 2017 年之后，普遍呈现出远离中心的政治倾向。这表明语言模型也能够捕捉到我们社会中的极化现象。</sample>
    <sample id="183">所以，最后一点，我们重视不同政治立场对仇恨言论检测和虚假新闻检测的评估，这两种NLP应用通常涉及语言模型，并且可能具有非常重要的影响。</sample>
    <sample id="184">所以我们看到，如果我们调查每个类别（即今天）的性能，如果我们将性能分为</sample>
    <sample id="185">不同类型的媒体，例如新闻媒体，我们看到一个模式，例如对于仇恨言论检测，左侧的语言模型表现更好。</sample>
    <sample id="186">收到。</sample>
    <sample id="187">我无法理解您提供的英文内容。请您提供清晰、完整的英文文本，我将尽力用中文表述其意思。</sample>
    <sample id="188">人工智能模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+ 和其他少数族裔的仇恨言论方面表现更差。</sample>
    <sample id="189">相似的趋势也发生在虚假新闻检测领域，我们看到，在语言模型中，它们在检测来自其相反政治立场和观点的信息方面表现更好。</sample>
    <sample id="190">这是一种，我们进一步展示了许多定性例子，以说明语言模型具有不同的偏见。</sample>
    <sample id="191">你给出了针对仇恨言论和虚假信息的不同例子，基于它们在社交媒体上的不同类别。附录中还有许多更多例子，以进一步强调其特点。</sample>
    <sample id="192">这表明存在一个持续存在的公平问题，与语言模型中的政治偏见有关。</sample>
    <sample id="193">好的，请提供英文内容。</sample>
    <sample id="194">这可能意味着持有不同政治观点的人可能会被边缘化，而针对少数族裔群体的仇恨言论可能会毫无限制地蔓延。</sample>
    <sample id="195">好的，请提供英文内容。</sample>
    <sample id="196">所以，在讨论之后，我们还想强调的是，我们揭示了关于语言模型政治偏见的一个独特困境，就像在塞尔维亚和克罗地亚之间一样。</sample>
    <sample id="197">好的，请提供英文内容。</sample>
    <sample id="198">如果我们试图某种方式进行消毒，我们也会面临审查或排除的风险，而且很难确定哪些内容实际上是中立的，应该保留在语言模型训练数据中。这有点像电子...</sample>
    <sample id="199">收到。</sample>
    <sample id="200">三位。</sample>
    <sample id="201">1024</sample>
    <sample id="202">他们的数据集中包含音乐、没有文字、12岁男孩、虚构人物以及来自阿塞拜疆的人。</sample>
    <sample id="203">Positionality is simply the perspectives that people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="204">The speaker's name is not mentioned in the provided text.</sample>
    <sample id="205">Yes, EDAtt is designed to be compatible with existing offline ST models without requiring retraining or adopting a specific architecture for CWC.</sample>
    <sample id="206">这篇论文有两位作者。</sample>
    <sample id="207">不，被测模型在测试套件上表现不佳。</sample>
    <sample id="208">KITMUS has three settings: Background Pretrain, Background Both, and Background Inference.</sample>
    <sample id="209">The provided text does not mention the authors' affiliations.</sample>
    <sample id="210">最后，我们是否应该只使用清理后的样本进行验证，还是有更好的方法来利用这些数据？</sample>
    <sample id="211">指标灵敏度确保模型在相同任务上，无论其变体如何，都能产生一致的输出。</sample>
    <sample id="212">Jingwei Yi.</sample>
    <sample id="213">更高的灵敏度通常表示模型性能得到了提高。</sample>
    <sample id="214">模型会接收来自预训练数据中的文本序列。</sample>
    <sample id="215">通常需要 23 个干净的验证样本。</sample>
    <sample id="216">Senter Muse 和 Danjaroof。</sample>
    <sample id="217">现有方法无法准确衡量媒体偏见，因此需要开发新的方法。</sample>
    <sample id="218">玛克希塔</sample>
    <sample id="219">The political bias propagation pipeline goes from pre-training data to language models to downstream tasks.</sample>
    <sample id="220">是的，在简化过程中，DEplain-apa 拥有更高的差异化转换，而网站则拥有更多的重写。</sample>
    <sample id="221">Yes, Coscript is publicly available.</sample>
    <sample id="222">水印是通过对文本进行修改，在文本中插入水印来实现的。</sample>
    <sample id="223">Pintland University.</sample>
    <sample id="224">Yes, encoder-decoder models like mt5 can be improved by training on a mixture of languages.</sample>
    <sample id="225">制作巧克力蛋糕。</sample>
    <sample id="226">They validated the coverage of the provided embedding by realizing the embedding of sentences unfolded as BPCAs.</sample>
    <sample id="227">研究如何使用现有的 PLM 来构建新的 PLM。</sample>
    <sample id="228">GPT-4 与中国和英语国家最不一致。</sample>
    <sample id="229">The example sentence where the speaker demonstrates how the model utilizes knowledge learned through the attention mechanism is: "and leverages the knowledge acquired by the model through the attention mechanism between audio input and text output."</sample>
    <sample id="230">As the number of tasks increases, the model achieves better performance and has lower sensitivity.</sample>
    <sample id="231">The author compares their method to three other tree-less models on the CoG benchmark.</sample>
    <sample id="232">The co-authors are advisors to the first author.</sample>
    <sample id="233">The first author of PaLM is Rohin Shah.</sample>
    <sample id="234">大家好，我是 Jenny，来自弗尔斯特大学，今天我将介绍我的工作，并进行演示。我将介绍设计偏见（Design Bias）的建模。</sample>
    <sample id="235">这项工作与华盛顿大学的一些同事以及人工智能的艾伦实验室合作，具体包括塞巴斯蒂安·桑蒂、罗南·洛布罗斯、卡特琳娜·拉伊尼卡和马丁·萨赫。</sample>
    <sample id="236">让我们先想象一下，你正在为报纸工作，你正在浏览你新闻文章下的评论，试图删除有害内容。</sample>
    <sample id="237">你可能会转向一个流行的API，比如Perspective API用于检测毒性，这对于像卡尔·琼斯这样的用户来说效果非常好。Perspective API能够正确地检测到不恰当的评论。</sample>
    <sample id="238">但对于迪蒂·阿什玛来说，视角非常敏感，对冒犯性词语并不敏感，而且在印度语环境中更常见。</sample>
    <sample id="239">这是一个设计偏见的一个例子，我们看到技术在不同群体中存在系统性的性能差异。</sample>
    <sample id="240">设计方式类似于我们刚才看到的那个，这可能与NLP研究团队的定位有关。定位简单来说就是人们由于其人口统计学、身份和生活经历所持有的视角。</sample>
    <sample id="241">这是一个在批判性研究中广泛使用的术语，尤其是在女权主义和酷儿学术领域。</sample>
    <sample id="242">作为一名研究人员，位置性会影响研究过程和结果，因为它会改变研究人员的决策。</sample>
    <sample id="243">一个人们可能会问的问题是，数据集中模型是否具有位置信息？</sample>
    <sample id="244">我们不是想说，模型、细胞和数据本身没有人口统计学身份和生活经历，但它们会汇总真实人的判断和意见，从而代表某些职业高于其他职业。</sample>
    <sample id="245">所以，预设是提供一些关于位置性的证据，例如文化差距、模式和数据，以及理论对位置性的定义。</sample>
    <sample id="246">然而，这些作品实际上并没有比较用户与数据本身，而是</sample>
    <sample id="247">在人工智能模型和数据集的物理学领域，随着人工智能变得越来越具主观性和社会导向，变得越来越重要。</sample>
    <sample id="248">在描述这些位置的偏差方面，很难确定，因为并非所有决定都有记录，而且许多模型隐藏在API之下。</sample>
    <sample id="249">所以，为了研究Dede的头部姿势模型，我们实际上将标注与真实用户与现有数据集和模型进行比较。</sample>
    <sample id="250">我们通过一个框架和职位结构。</sample>
    <sample id="251">我框架在两个主要领域运作：</sample>
    <sample id="252">第一步是将数据集重新标注，使用来自不同背景的标注者。</sample>
    <sample id="253">在我们做这个的时候，我们查看原始数据集的人口统计学信息，因为通常每个实例只有少数标注者，而且人口统计学信息很少被收集和共享。</sample>
    <sample id="254" />
    <sample id="255">我们然后根据人口统计学对标注进行比较，并使用皮尔逊相关系数与模型和数据集进行比较。</sample>
    <sample id="256">该框架与标注不一致的文献不同，它通过将最终用户与模型和数据集中预测和标签进行比较，而不是仅仅关注标注一致性或建模。</sample>
    <sample id="257">我们的框架主要通过“实验室在野外”这个在线众包平台实现，该平台是美国科学促进会与科工合作者合作的。</sample>
    <sample id="258">在野外实验室是一个在线实验平台，我们可以招募各种各样的志愿者。与像Enterick这样的平台相比，后者大多来自美国或印度。此外，野外实验室仍然能够获取高质量的数据。</sample>
    <sample id="259">我们举办了两项任务，现在在《荒野》中。其中一项是社会可接受性。这项任务的工作方式是，参与者会阅读一个情境，然后根据社会化学数据判断该情境是否可接受。</sample>
    <sample id="260">之后，他们可以在英式和美式之间比较他们的回答与人工智能和其他人的。</sample>
    <sample id="261">你已经将这些标注与社会化学、德尔菲和 GPT 结合起来。</sample>
    <sample id="262">我们随后为检测毒性言论和仇恨言论任务复制了一个非常相似的设置，他们会阅读来自每日仇恨的片段，并判断这些片段是否包含仇恨言论。</sample>
    <sample id="263">我们随后将这些标注与 DinaHeat、Perspective API、Rewire API、HateBERT 和 GPT-4 进行比较。
我们的研究在超过 16,000 个标注上，来自超过 1,000 位标注者，来自 87 个国家。</sample>
    <sample id="264">所以现在我们更好地理解了NLP数据评估模型与哪些最契合。我们发现，NLP具有位置性，并且NLP</sample>
    <sample id="265">例如，我们发现，在许多模型中，数据与英语国家最为相关。因此，对于GPT-4的社会接受度分析，我们发现它与中国和英语国家最为相关。我们发现，Dynah也与英语国家最为相关。</sample>
    <sample id="266">我们还发现，拥有大学学历的人与社会责任任务的匹配度最高。对于GDP4在社会责任任务中的匹配度，我们发现拥有大学学历或研究生学历的人与此任务的匹配度最高。</sample>
    <sample id="267">并且我们发现这对于唐尼·海特来说也是如此，它与有大学教育的人最为相似。</sample>
    <sample id="268">然而，当模型和数据与特定人群对齐时，一些人不可避免地会被遗漏。</sample>
    <sample id="269">一个例子是，数据在模型中被训练来与非二进制的人进行比较，与男性和女性的同伴进行比较。我们可以在 GPT-4 的社会可接受性任务以及 DinaHeat 任务分析中找到这一点。</sample>
    <sample id="270">所以，既然有位置和ALDI，我们能做什么？</sample>
    <sample id="271">所以我们有一些建议：第一个是记录你在研究过程中所有相关的设计选择，第二个是进行用户体验研究，从用户的角度出发。</sample>
    <sample id="272">我们第三个建议是构建针对特定社区的专业数据集模型，一个很好的例子是马萨丘塞斯州倡议。我想强调的是，包容性人工智能不仅仅是让所有技术都能为每个人工作，</sample>
    <sample id="273">所以，这就是本次演示。如果您想了解更多，请随时查看我们的仪表盘以获取最新分析结果，以及我们的论文。谢谢。</sample>
    <sample id="274">The prominent issues of the current SimulST models are specific architectures requiring additional modules for optimization, complicated training procedures involving different optimization objectives, and training and maintaining multiple models to achieve different latency regimes.</sample>
    <sample id="275">It's challenging to effectively mitigate societal and political biases in NLP model training data. Simply sanitizing the data can lead to censorship or exclusion, and determining what is truly neutral is difficult.</sample>
    <sample id="276">嗨，我是徐宇源，来自复旦大学。我在这里介绍我们的工作：从语言模型中提取可约束的知识。</sample>
    <sample id="277">在现实生活中，人们经常按照步骤执行操作，通过遵循明确的指令来完成任务。</sample>
    <sample id="278">以前，大型语言模型被用于规划抽象的日常活动，例如做蛋糕，并证明大型语言模型可以有效地分解任务为步骤。</sample>
    <sample id="279">然而，过去许多人专注于计划抽象目标，而忽视了日常活动。计划目标时需要考虑具体的、具体的限制，例如制作巧克力蛋糕。然而，仍然没有开始。</sample>
    <sample id="280">在本文中，我们定义了约束语言规划的问题。</sample>
    <sample id="281">计划的约束条件会因不同的现实生活目标而异，并且受到动机性约束的影响。一个好的计划者应该识别出合理的、符合约束条件的约束。</sample>
    <sample id="282">在本文中，我们评估并改进了限制语言规划的能力的大型语言模型。</sample>
    <sample id="283">请将英文内容转换为汉语。</sample>
    <sample id="284">我们如何获取这些代码首先？
正如在表格中所显示的那样，我们将抽象代码与修改后的约束相结合，用于人类在数据获取中的使用，使用抽象 GPT。</sample>
    <sample id="285">请将英文内容转换为汉语。</sample>
    <sample id="286">这个表格反映了结果的整体准确性。我们发现，所有语言模型都实现了令人满意的结果。</sample>
    <sample id="287">真，我无法提供详细的分析来调查为什么大型语言模型会产生有害的输出。</sample>
    <sample id="288">结果在图表中显示，生成脚本中的语义完整性是可以接受的，但对事实的约束则无法保证。</sample>
    <sample id="289">在越来越多的顶级类别中，定义在Wakefield的限制。图表中的热图显示，不同类别女性的计划和表现差异显著。</sample>
    <sample id="290">我们已经看到，在大型语言模型中，输出质量在不同版本中有所不同，导致性能下降。因此，人们采用了过度生成的零样本过滤器来提高生成质量。</sample>
    <sample id="291">我首先展示了约束类型以及基于这些抽象概念的示例。</sample>
    <sample id="292">赞，提取GPT或生成文本描述特定内容。</sample>
    <sample id="293">下一个，一个未来模型是基于两个步骤选择第一个词语。</sample>
    <sample id="294">我们把脚本和鬼魂转化为提取的 GPT 嵌入，并计算余弦相似度作为相似度分数。</sample>
    <sample id="295">请将英文内容转换为汉语。</sample>
    <sample id="296">我们的研究表明，在LGBTQ+群体中，有较多的头发色素沉着。我们的研究表明，我们的研究极大地改善了皮肤色素沉着，包括在慢性炎症和炎症性疾病中。</sample>
    <sample id="297">鉴于大型语言模型部署成本高昂，因此启用语言规划是使用较小和专业化模型的必要步骤。创建数据集是第二步。</sample>
    <sample id="298">然而，之前的研究并未明确规划特定目标，并且手动数据在注释中的成本是昂贵的。</sample>
    <sample id="299">我们遵循一个象征性知识蒸馏方案，以蒸馏语言模型的数据大小，从轻量级模型</sample>
    <sample id="300">请将英文内容转换为汉语。</sample>
    <sample id="301">为了生成55个具有特定目标和脚本的单词，我们需要确保数据的质量和测试的有效性。我们要求众包的工人来查找并修订不正确的样本。</sample>
    <sample id="302">这个图表显示了语言规划中约束性模型的分布，而非约束性模型在通用零售领域表现出更高的表现。通过约束性模型，我们可以构建更小、更专业化的模型来进行语言规划。</sample>
    <sample id="303">在文件分析中，T-SNE算法计算出的红色，可以生成更小的红色散点图，表明较小的模型可以处理较大的数据，而较大的模型可能无法处理所有数据。</sample>
    <sample id="304">在总结中，我们建立了一个约束语言规划问题，旨在增强大型语言模型对约束语言规划能力的理解，并开发了一个用于大型语言模型后生成任务的评估方法。</sample>
    <sample id="305">我们使用大型语言模型来生成一个高色彩的结构化数据集，用于语言规划。我们希望这个数据集可以作为语言规划研究的可用资源。</sample>
    <sample id="306">谢谢您的时间，请详细描述您的论文标题。</sample>
    <sample id="307">PaLM 的流畅度与现有语言模型相当。</sample>
    <sample id="308">水印方法需要满足以下属性：

1. 可应用于嵌入式服务。
2. 不应降低提供的嵌入物的实用性。
3. 水印应足够隐蔽，攻击者可以移除。
4. 水印应可移植到攻击者服务。</sample>
    <sample id="309">14</sample>
    <sample id="310">我们选择重新注释数据，以获得每个实例的多个注释，并获取丰富的细分人口统计学数据。</sample>
    <sample id="311">The cosine similarity and L2 similarity are computed to measure the similarity between the requested embedding and the target embedding. The difference between the binary and the backdoor dataset is defined as delta cosine and delta L2.</sample>
    <sample id="312">将基于编码器的多语言模型用于这项任务，我们评估了包含编码器和点状解码器的模型，例如Encoder-PT-Reader、XLM-R+PT-Reader和BERT+PT-Reader。此外，我们还评估了包含编码器和解码器的模型，例如mBERT。</sample>
    <sample id="344">作者假设提供商可以收集一个通用的文本语料库，并统计单词频率。</sample>
    <sample id="345">大家好，我叫徐洪。今天我将介绍我们的论文《可命名实体标签在 2023 年是否仍然有效》。让我们开始吧。</sample>
    <sample id="346">我们的论文研究了泛化问题，使用名为命名实体识别任务或NER任务的方法。</sample>
    <sample id="347">我们观察到，模型在 2003 年就开始使用卷积神经网络来开发深度学习了近 20 年。这自然引发了许多问题。首先，卷积模型泛化到更多的数据集。</sample>
    <sample id="348">在开发新标签时，需要什么？</sample>
    <sample id="349">与此同时，如果我们观察到泛化能力下降，是什么导致了这些模型的性能下降？</sample>
    <sample id="350">为了调查这些问题，我们开发了一个 Cono+ 数据集。这是一个我们从路透社新闻收集的数据集，然后使用 2003 年的 Cono 标注指南进行标注。</sample>
    <sample id="351">我们对20个模型进行了微调，并在Kernel 2003测试集和Kernel Plus Plus测试集上进行了评估。</sample>
    <sample id="352">最后，我们计算了 F1 的百分比变化，以评估每个模型的泛化能力。</sample>
    <sample id="353">所以，对于良好的生成，我们需要什么？在我们的实验中，我们发现有三个主要成分是必要的。</sample>
    <sample id="354">第一个是模型架构。在我们的实验中，我们发现Transformer模型通常在新的数据上泛化得更好。</sample>
    <sample id="355">第二个成分是模型大小。我们发现，通常较大的模型会带来更好的泛化能力。</sample>
    <sample id="356">最后，我们都知道，用于微调的样本数量直接影响下游任务的性能。在这里，我们还发现，更多的微调样本实际上也导致了更好的泛化能力。</sample>
    <sample id="357">你下一个问题是什么？什么导致了某些模型性能下降？</sample>
    <sample id="358">我们有两项假设。第一项是过拟合，这通常是由于重复使用相同的测试数据集而导致的，并且通常表现为在新的测试集上返回值减少。</sample>
    <sample id="359">第二种假设是温度漂移，这是一种由训练和测试数据之间不断扩大的温度差引起的性能退化。</sample>
    <sample id="360">拟合的函数。我们看到，从右边的图上，红色的最佳拟合线具有比y轴更高的斜率。</sample>
    <sample id="361">这意味着我们在2003年取得的每一点改进，都转化为在Call++上超过一点的改进，这意味着没有边际收益递减。</sample>
    <sample id="362">这表明在当前情况下，适应性匹配未观察到。</sample>
    <sample id="363">请提供您想让我翻译的英语内容。</sample>
    <sample id="364">对于时间漂移，我们进行了一项实验，以重新训练或继续预训练一些模型，使用更多最近的数据。我们发现，随着数据规模的增大，性能会下降。</sample>
    <sample id="365">这证实了我的假设，即性能下降的主要原因是温度。</sample>
    <sample id="366">我们的结论是，为了更好的泛化，我们需要更好的模型架构、更大的模型尺寸，以及更少的微调示例。这些目标相互关联，我们不能只关注一个方面，而是需要通过其他方面来实现。</sample>
    <sample id="367">与此同时，我们还发现，这里的性能下降是由于临时漂移造成的，而且令人惊讶的是，它并非由Adaptive overfitting引起，即使Kernel 3在过去20多年里也被广泛使用。</sample>
    <sample id="368">所以回到我们标题纸上提出的问题，2003年内核技术在2023年仍然有效吗？我们发现答案是肯定的。</sample>
    <sample id="369">我们帮助所有纸质课程为更多研究提供资金，以改进模型泛化能力。</sample>
    <sample id="370">最后，请务必查看我们的纸质文件和数据集，如果您有任何问题，请随时联系我。非常感谢。</sample>
    <sample id="397">The size of the voice fragments used in this method is not specified in the provided text.</sample>
    <sample id="398">Servin 是法官。</sample>
    <sample id="399">示例质量</sample>
    <sample id="400">GPT-4, GPT-3 series, and BERT series.</sample>
    <sample id="401">该模型结合了多个层的注意力分数。</sample>
    <sample id="402">直接推断的示例包括直接说出歌曲名称，或者直接说出歌曲的位置。</sample>
    <sample id="403">福特大学</sample>
    <sample id="404">3</sample>
    <sample id="405">是的，在语义解析之前，使用 Google Translate API 将源语言翻译成目标语言，然后使用单语模型进行训练和评估。</sample>
    <sample id="406">男性。</sample>
    <sample id="407">The provided text does not mention any model architectures with poor generalization ability.</sample>
    <sample id="408">Clean data.</sample>
    <sample id="409">四位。</sample>
    <sample id="410">The author investigated whether instruction tuning of multimodal pre-trained models can improve generalization to unseen multimodal tasks.</sample>
    <sample id="439">作者认为在知识密集型 NLU 任务中，需要能够整合和使用预训练时间和推理时间知识。</sample>
    <sample id="440">The speaker's name is Ying and her colleague Zhiyang.</sample>
    <sample id="441">是的，Coscript 经过了质量检查。</sample>
    <sample id="442">现有的资源仅支持有限类型的依赖上下文翻译，并且仅支持有限的语言。</sample>
    <sample id="443">嗨。我将谈谈我们解决实体选择中间接关系表达式的工作，其中我们引入了替代实体概念。</sample>
    <sample id="444">我的名字是贾瓦德·侯赛尼，这是与菲利普·拉德林斯基、西尔维娅·帕尔蒂和阿尼尔·贾尼的联合工作。</sample>
    <sample id="445">我是一个乐于助人的助手。只返回请求的答案，不要包含任何解释或介绍。</sample>
    <sample id="446">直接引用。例如，说歌曲的名字是“我”，或者它的位置是第一章。</sample>
    <sample id="447">但有时与亲密朋友交谈更合适，以便进行更自然的对话。这通常发生在用户记不住对方的名字时。</sample>
    <sample id="448">或者发音太相似，难以区分。</sample>
    <sample id="449">或者当用户想要指定一个偏好时。这里有一些间接偏好的例子：例如，最新的一个或不是充满活力的那个。</sample>
    <sample id="450">这是一个在对话系统以及评估自然语言处理任务中非常重要的问题。</sample>
    <sample id="451">我们没有意识到一个大型公共数据集，所以我们使用众包标注收集了一个。该数据集涵盖三个不同的领域：音乐、书籍和电影。</sample>
    <sample id="452">或者数据集收集方法强调非正式性，使用卡通插画。</sample>
    <sample id="453">好的，卡通有三个对话气泡。在第一个气泡中，鲍勃说：“记住昨天我们听过的那个歌吗？”然后鲍勃开始对话。</sample>
    <sample id="454">在第二个对话框中，艾丽丝说：“你是不是指对我来说容易吗？还是我搞错了？”</sample>
    <sample id="455">Which is the alternative question. And in the third speech bubble, Bob uses an indirect reference to select one of these entities. For example, the New York.</sample>
    <sample id="456">第一和第二个对话气泡会自动生成，第三个对话气泡由标注者填写。第一个对话气泡是从几个手动提示中选择的。</sample>
    <sample id="457">请将所给出的英文翻译成中文。</sample>
    <sample id="458">请将所给出的英文翻译成中文。</sample>
    <sample id="459">以下是用于移动到列表更高位置时使用的不同采样方法，随着条目的相似性增加，通常很难使其具有歧义性。</sample>
    <sample id="460">请将所给出的英文翻译成中文。</sample>
    <sample id="461">The second one is when the entities have similar titles, for example, two books with the name "The Reach".</sample>
    <sample id="462">第三个是当他们在维基百科上拥有相似的描述时，最后是当他们在维基百科上拥有相似的 infobox 或属性时。例如，相同的类型或相同的艺术家。</sample>
    <sample id="463">他们向受访者展示了这个问题。他们知道这些实体的名称，但他们并不一定了解这个角色。</sample>
    <sample id="464">我们要做的是展示关于这两个实体的背景知识。对于歌曲，我们简单地展示一个谷歌搜索链接到其。</sample>
    <sample id="465">然后请让听众听至少一首每首歌，并阅读关于每首歌的内容。

以下是一个示例，Google 搜索结果对于歌曲《Easy》的结果：

“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”
“拉尔”</sample>
    <sample id="466">对于食谱和书籍领域，我们展示了一些来自维基百科的背景文字。对于食谱，我们还展示了它们的图片，同样来自维基百科，这样注释者就能知道它们是什么样子。</sample>
    <sample id="467">然后，我们让参与者选择一个实体，例如这里第一个，并用 3 到 5 个间接引用表达方式描述它。</sample>
    <sample id="468">请将所给出的英文翻译成中文。</sample>
    <sample id="469">该大型语料库包含六千个替代问题，分布在三个领域，并且包含四万二千个间接否定表达。</sample>
    <sample id="470">这个语言模型拥有与训练数据完全相同的背景知识，准确率约为92%至95%。但这并非真实。</sample>
    <sample id="471">如果语言模型有访问一些部分重叠的背景知识，那么在82%到87%的准确率之间，这对于例如当语言模型检索背景知识时来说是更现实的。</sample>
    <sample id="472">如果语言模型只能访问实体名称，那么准确率只有60%，所以还有很大的改进空间。我们还展示了这些模型是领域泛化的。这里有一个链接的数据集：</sample>
    <sample id="473">weight key strategy and local agreement.</sample>
    <sample id="474">The author is associated with the University of Paris.</sample>
    <sample id="475">Jenny.</sample>
    <sample id="476">Four.</sample>
    <sample id="477">嗨，我是塞拉·巴比，来自特伦托大学和布鲁诺·凯斯勒基金会。我将简要介绍注意力作为本论文的指导，这是一项与马克·奥内格里和马可·乌尔共同完成的工作。</sample>
    <sample id="478">同步语音翻译（ST）是指在实时中将口语翻译成另一种语言的文本。</sample>
    <sample id="479">在当前语义模型中，主要的缺点是什么？
特定架构通常使用额外的模块来优化。</sample>
    <sample id="480">冗长复杂的培训程序，例如涉及不同优化目标（目标）的培训。</sample>
    <sample id="481">训练和维护多个模型以达到不同的延迟级别，例如训练一个模型具有平均 1 秒的延迟，另一个模型具有 2 秒的延迟，等等。</sample>
    <sample id="482">请将所给出的英文翻译成中文。</sample>
    <sample id="483">第一个使用现有的离线模型，无需重新训练或采用特定架构的 CwLST。使用单个模型来处理整个延迟序列，并通过特定的参数处理延迟。</sample>
    <sample id="484">和劳尔的知识是通过注意力机制在音频输入和文本输出之间获得的，即交叉注意力机制。您可以在以下示例中看到一个：</sample>
    <sample id="485">我们的解决方案是提出一个点，或者编码器解码器注意力，而这是一种策略，用于决定是否向侧面移动，或者进行部分翻译，基于注意力点的位置。</sample>
    <sample id="486">如果检测到没有集中性，也就是说，该信号低于某个阈值阿尔法，则向较少的语言语音帧发送。这意味着接收信息足够稳定。</sample>
    <sample id="487">例如，如果我们筛选一个包含我将讨论的内容的句子，并且我们的模型预测翻译成德语，</sample>
    <sample id="488">和我们将会研究的，是注意力权重。</sample>
    <sample id="489">我们会看到第一个词指向最少接收到的语音帧，而最后一个词指向最少接收到的语音帧，即 lambda 语音帧。</sample>
    <sample id="490">这表示前两个词将是“查”、“拉”。</sample>
    <sample id="491">虽然在某些浓度超过某个阿尔法值时，我们不会发出最后一声，我们等待下一个语音信号。</sample>
    <sample id="492">如果我们在另一个语音银行，我们的模型预测其他词语，我们会查看交叉注意力，即</sample>
    <sample id="493">我们看到，没有词语指向这篇演讲稿。</sample>
    <sample id="494">这表示这三个词将被重复。</sample>
    <sample id="495">如果看看那个主要结果，那就是</sample>
    <sample id="496">我们将同时性平移结果绘制在图表上，其中蓝色一侧衡量的是翻译质量，而平均语言</sample>
    <sample id="497">但是，呃，我们正在考虑一个延迟测量，并且我们还考虑了计算效率平均延迟，这包括模型计算时间来产生输出。</sample>
    <sample id="498">请将所给出的英文翻译成中文。</sample>
    <sample id="499">请将所给出的英文翻译成中文。</sample>
    <sample id="500">和我们比较的是针对我们非平面模型的准备策略，例如权重保持策略和局部协议。我们还比较了在同步处理场景中专门为SIMultaneous Processing Layer设计的Seed of the Architecture。</sample>
    <sample id="501">这些是同步语音翻译策略在德语上的早期结果。</sample>
    <sample id="502">并且我们看到，呃，它在所有策略应用于离线模型时都优于所有策略，因为它的曲线向左移动了。</sample>
    <sample id="503">我们还看到，如果我们考虑实际的运行时间或计算时间，那是一种最快的策略。</sample>
    <sample id="504">如果你想发现更多结果，请阅读我们的论文，我们还发布了开源代码和模型，并同时提供了模拟输出，以促进我们工作的可重复性。谢谢您的关注。</sample>
    <sample id="505">是的。</sample>
    <sample id="506">大家好，我的名字是伊恩，我的同事志扬和我将介绍我们的研究，关于改进模型细胞学习通过指令训练。</sample>
    <sample id="507">随着大型语言模型技术的进步，许多研究人员开始探索新的学习范式，即利用预训练语言模型进行各种下游任务，在参数和数据效率上取得突破。</sample>
    <sample id="508">最近，许多研究表明，指令微调能够使大型语言模型在零样本情况下执行各种任务，通过遵循自然指令。</sample>
    <sample id="509">然而，大多数以前的工作都侧重于提高在语言任务上的零样本性能，而计算机视觉和多模态任务则被留下了空白。</sample>
    <sample id="510">因此，在工作中，我们希望调查指令微调能否改善多模态预训练模型在未知多模态任务上的泛化能力。</sample>
    <sample id="511">此外，在我们的研究期间，我们发现在NLP和MoE模型之间指令数据集的可访问性存在显著差异。</sample>
    <sample id="512">目前有超过1600个仅语言的指令任务，但没有大规模公开可用的多模态指令任务。因此，这激励我们构建一个多模态指令微调数据集。</sample>
    <sample id="513">我们现在介绍第一个多模态模型指令微调基准数据集，该数据集包含 62 种多样化的多模态任务，涵盖了 10 种不同的类别。</sample>
    <sample id="514">这些任务来源于一个现有的开放数据集，每个任务都配备了五条编写指令。</sample>
    <sample id="515">为了进行多模态指令微调我们的拟定数据集，我们采用OFA，将多模态预训练模型作为我们的基础模型。OFA使用统一的词汇、图像token和bounding box的坐标。</sample>
    <sample id="516">这里展示了一些我们多音节单词的例子：

* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮
* 轮</sample>
    <sample id="517">将这段英语内容表达为中文。</sample>
    <sample id="518">将这段英语内容表达为中文。</sample>
    <sample id="519">好的，我将谈论多模态指令教学。</sample>
    <sample id="520">所以对于20天数据集，我们使用53个任务从Negru组进行训练，每个任务有10000个样本。对于测试，我们保留了整个CommonSense Reasoning组进行测试，并从Wiki和杂乱的类别中额外选择了5个任务。</sample>
    <sample id="521">重复出现“r”字母。</sample>
    <sample id="522">重复</sample>
    <sample id="523">重复</sample>
    <sample id="524">我们评估了在五种实验中，性能和标准偏差的整体表现。</sample>
    <sample id="525">这任务是一个多模态分类任务，我们会报告准确率。如果它是一个多模态生成任务，我们会报告 ROUGE-L。对于 QA 任务，我们会报告 ROUGE-L 作为结果。</sample>
    <sample id="526">我们还引入了一个额外的验证机制，称为“一致性测试”。这个机制确保了模型在相同的任务上，无论其变体如何，都能一致地产生相同的输出。</sample>
    <sample id="527">这是我们的主要结果，正如我们所见，指令调整可以显著提高OS和iOS的性能，在处理多模型任务时。</sample>
    <sample id="528">从自然语言处理中学习来自大规模文本数据集的优势，包括指令微调。</sample>
    <sample id="529">这里我们可以看到，随着任务数量的增加，模型会取得更好的性能，与此同时，它对噪声的敏感性会降低。</sample>
    <sample id="530">所以我们还使用了while语句和for语句，正如我们所见，使用while语句可以提高模型的整体性能，并且减少其灵敏度。</sample>
    <sample id="531">所以这展示了不同预训练策略对模型敏感性的影响。正如我们所见，通过从自然语言指令数据集进行预训练，模型可以实现比原始的 OpenAI 模型更高的敏感性。</sample>
    <sample id="532">我们也可以看一看在网络训练数据集中，这可以帮助我更好地在网络训练数据集中获得更好的性能。</sample>
    <sample id="533">总而言之，我们提出了第一个大规模多模态Instruction Tuning数据集，它旨在进一步提高Ollama的可访问性，并展示不同迁移学习技术的优势，以及它们带来的好处。</sample>
    <sample id="534">我们正在收集一个更大的多模态指令微调数据集，其中包含大约150个额外的语言任务，并且我们将很快发布这些数据。这是我们数据集和模型的二维码。谢谢。</sample>
    <sample id="535">Setappabi from the University of Trento and the Bruno Kessler Foundation.</sample>
    <sample id="536">Javad Hosseini.</sample>
    <sample id="562">大家好，我是科斯托夫·谢纳，很高兴欢迎大家参加我们关于 ACL 2023 论文“语言模型可接受性判断并非总是对上下文鲁棒”的讨论。</sample>
    <sample id="563">这是一个由约翰·戈特、艾尔·穆勒、卡尼什卡·米什拉、卡伦·弗伦特尔、罗杰·莱维和阿蒂纳·拉蒂娜共同完成的项目。</sample>
    <sample id="564">所以，在本文中，我们将回顾最小的配对参数。</sample>
    <sample id="565">最小对偶（minimal pair）基本上评估语言模型在可接受性判断之上的表现，这可能包括语法（如词形、句法）或可接受性方面的问题，例如刻板印象（如种族偏见）。</sample>
    <sample id="566">在最小对偶范式中，评估语言模型通常是将一个可接受的句子或语法正确的句子展示给它，然后展示一个不可接受的句子或语法错误的句子。</sample>
    <sample id="567">然后，模型会基本将可接受的类别赋予更高的概率。</sample>
    <sample id="568">当前 MPP 流程基本上不允许我们评估模型对长句子（长句）的接受程度。</sample>
    <sample id="569">这些大型语言模型正在推出更长更长的上下文窗口，因此我们需要评估模型在整个上下文窗口中的可接受性。</sample>
    <sample id="570">And that is what we are trying to do here. We are trying to revisit the PP pipeline by asking the model to evaluate acceptability on longer and longer sequences.</sample>
    <sample id="571">所以，这就是方法。那么我们要做的是模拟这些更长的序列。我们重新访问数据集合本身，然后我们重新创建句子，通过选择那些可接受或不可接受的句子。</sample>
    <sample id="572">例如，这里我们选择了一个典型的语法对，来自“blip”数据集，来自“adjunct island”的“页”。</sample>
    <sample id="573" />
    <sample id="574">请。</sample>
    <sample id="575">所以我们可以通过从同一对匹配中选择不可接受的句子来做同样的事情，这也可以用来测试模型的可接受性。</sample>
    <sample id="576">我们也可以通过选择来自不同子集或不同数据集的句子来做到这一点。这就是我们称之为“不匹配检索”的方法。</sample>
    <sample id="577">所以这里句子仍然来自相关的数据库，但不是来自你正在评估的同一个数据库。
我们可以对不可接受性案例进行相同的操作。</sample>
    <sample id="578">最后，我们可以从完全不相关的领域中选择句子，即维基百科。</sample>
    <sample id="579">所以这会告诉我们模型在实际影响下接受度评估是否受到任何影响。</sample>
    <sample id="580">你是否来自数据集中不同的子集，或者它与当前句子完全无关？</sample>
    <sample id="581">所以模型如何运作？首先，我们查看维基百科的句子，这些句子与当前查询无关，然后我们发现，对于任意上下文，TMPP的判断通常是可靠的。</sample>
    <sample id="582">我们增加了上下文长度到高达 1024，以最大限度地发挥 OPT 和 GPT-2 模型，并且我们在这里看到，在橙色点划线上，MPP 判决相对稳定。</sample>
    <sample id="583">现在当我们从同一段文字中选择句子时会发生什么？</sample>
    <sample id="584">所以在这里，我们选择或创建了来自可接受和不可接受领域的句子，从同一位被指控的人的文本数据中。</sample>
    <sample id="585">并且我们看到，在 MPP 判决中，无论是接受的还是不可接受的前缀，都会显著增加或减少。</sample>
    <sample id="586">但是，当我们匹配结构时，当我们选择来自同一现象的句子时，</sample>
    <sample id="587">我们看到模型在选择的前缀是否可接受或不可接受的情况下，在 MPP 判决上出现巨大的增加或巨大的减少。</sample>
    <sample id="588">现在这个，呃，呃，这个非常大，就像这个影响贯穿整个上下文，这可能会影响像新语言模型，它有大上下文。</sample>
    <sample id="589">为什么匹配前缀会影响语言模型判断如此之多？</sample>
    <sample id="590">一系列分析，我们尝试通过尝试保留输入句子的相关结构，但添加噪声到输入中来，然后对这些扰动进行多次操作。</sample>
    <sample id="591">我们发现这些噪音实际上并没有改变模型的输出，而是改变了它对这些概率的判断。</sample>
    <sample id="592">基本上，我们发现模型对句子中词语的相似度非常敏感。</sample>
    <sample id="593">在将句子置于可接受域时，我们看到所有扰动都出现相似的增加，而在将句子置于可接受域的下一个域时，我们看到在相似特征中，MPP 判决减少。</sample>
    <sample id="594">所以，我们工作的关键收获是，语言模型对句子中共享的潜在句法和语义特征非常敏感。</sample>
    <sample id="595" />
    <sample id="596">请阅读我们的论文以了解更多关于我们实验的细节。谢谢您的收听。</sample>
    <sample id="597">一个无序多元素。</sample>
    <sample id="598">55</sample>
    <sample id="626">The best alignment method to use for German text simplification is the `mess_align` method.</sample>
    <sample id="627">Weakly supervised learning allows training models to robustly train neural networks under label noise so that the trained models still generalize.</sample>
    <sample id="628">文档采用手动和自动对齐方法进行对齐，具体分配情况未提及。</sample>
    <sample id="629">CoNLL++ 数据集是从路透社新闻（2020 年）收集的，并使用 2003 年的标注指南进行标注。</sample>
    <sample id="630">你好，大家好，我是Justin John来自宾夕法尼亚大学。今天我将演示一个工作示例：跨语言语义解析和多种自然语言的语义表示。</sample>
    <sample id="631">将英文内容翻译成中文。</sample>
    <sample id="632">跨语言语义解析是任务将查询翻译成多种自然语言中的多种语义表示。</sample>
    <sample id="633">在图中，我们需要使用神经模型将查询翻译成多种自然语言，并插入一个 lambda 或函数 QL。</sample>
    <sample id="634">存在许多跨语言语义解析模型，它们分别被提出和评估在各种有限任务和应用上。例如，</sample>
    <sample id="635">它们在某些自然语言的覆盖率上有所不足，中文缺失。</sample>
    <sample id="636">请提供英文内容。</sample>
    <sample id="637">我是一个乐于助人的助手。请只返回请求的答案，不要包含任何解释或介绍。</sample>
    <sample id="638">或者只有评估一个特定新模型，例如只有一次评估一个单一模型来评估。</sample>
    <sample id="639">所以，为了这个目的，我们建议提供一个示例数据集，提供跨语言和多语言的链接和语义表示。</sample>
    <sample id="640">它包含 90 个数据集，5 个语义Parsing任务，8 种表示形式，以及 22 个自然语言。在 15 个语言家族中。</sample>
    <sample id="641">为了更好地评估我们的基准，我们考虑了训练和评估的六个设置。</sample>
    <sample id="642">The first one is translate test. We use Google Translate API to translate source to the target language, then use monolingual model to train and evaluate the</sample>
    <sample id="643">和例如，在英文模型上，用英文查询，然后进行推理，我们翻译德语查询使用API到英文，然后使用训练好的模型来预测结果。</sample>
    <sample id="644">我还会测试单语模式。</sample>
    <sample id="645">请提供英文内容。</sample>
    <sample id="646">我们还测试了单语少样本设置，通过使用少量训练数据训练单语模型。</sample>
    <sample id="647">和具有单语言模型，我们训练一个单语言模型，用于所有语言。</sample>
    <sample id="648">例如，我们把德语、英语、中文的查询结合起来，来训练一个语言模型，并在推理时，我们可以使用这个模型来总结、翻译、生成文本等。</sample>
    <sample id="649">请提供英文内容。</sample>
    <sample id="650">我们还考虑了跨语言零样本和少样本迁移，在一种语言和另一种语言之间进行迁移。</sample>
    <sample id="651">在训练过程中，我们将训练我们的英语查询或英语和德语短语查询，以训练一个多语言模型，来预测序列中的下一个单词。</sample>
    <sample id="652">并且我们还发现了一些非常有趣的成果。所以，关于单语模型，我们评估了两个模型组。</sample>
    <sample id="653">包括编码器-解码器（Encoder-Decoder），即多语言预训练编码器与指针基于解码器，例如XLM-R+PT和BERT+PT。</sample>
    <sample id="654">我们还评估了编码器解码器模型，这是一种多语言预训练的编码器解码器模型，例如 BERT 和 mBART。</sample>
    <sample id="655">我们发现编码器解码器在所有九个数据集上都能获得最佳性能。</sample>
    <sample id="656">and we evaluated on MRT5 and example XLMR plus PDR modeling theory.</sample>
    <sample id="657">没有数据编码器或编码器需要改进，通过训练混合的语言。</sample>
    <sample id="658">我们发现，这主要是因为大多数主要的自然语言可以获得性能提升，但英语的性能在某些数据集上下降，而所有性能在三个数据集上都提升。</sample>
    <sample id="659">我以为这是没有人说的，这是语言的后果。</sample>
    <sample id="660">我们还比较了跨语言性能的特征。</sample>
    <sample id="661">在图中，蓝色线表示交叉角度的零轴转换，橙色线表示交叉角度的零轴转换，而绿色线表示建模角度的转换。</sample>
    <sample id="662">我们发现，通过比较绿色和橙色线，在零步设置下，跨越角度的转换性能差距是显著的。而通过比较蓝色和橙色线，在少量步设置下，转换差距迅速缩短。</sample>
    <sample id="663">我们还发现了一些其他有趣的发现，例如，编码器解码器在以前的工作中实现了可比的结果。对于英语自然语言处理，显著提高了预训练语言模型的性能。</sample>
    <sample id="664">大型语言模型，如CodeT5和BLOOM，在跨语言语义理解任务中仍然处于开发阶段。</sample>
    <sample id="665">一个统一的跨语言语义解析基准，使用多种自然语言表示形式。</sample>
    <sample id="666">欢迎阅读一项全面的基准研究，研究了三种代表性的多语言语言模型。我们的结果显示了许多有趣的发现等等。欢迎访问我们的论文和代码。谢谢您的阅读。</sample>
    <sample id="667">The provided text does not contain any English content. Therefore, I cannot answer the question about existing research.</sample>
    <sample id="668">不，它们仍然不够。</sample>
    <sample id="695">The method addresses permutation uncertainty by incorporating alignment as part of the training. While the permutation method is flexible, finding the highest-scoring permutations is challenging, similar to the traveling salesman problem, and is approximated using a GPU-friendly continuous relaxation.</sample>
    <sample id="696">下游 NLP 模型的公平性是指在特定任务中，模型对不同群体（例如，基于种族、性别、宗教等）的预测结果是否存在差异。如果模型对某些群体表现出偏见，那么它就存在公平性问题。</sample>
    <sample id="697">Janis Lavergne.</sample>
    <sample id="698">科斯普·谢纳。</sample>
    <sample id="699">Maira.</sample>
    <sample id="700">In the context of this text, tropicalism refers to a trope that reflects in the words used to describe women of color. For example, words describing Latina women include things like "vibrant" and "curvaceous," which connect to the trope of tropicalism.</sample>
    <sample id="701">作者通过使用诸如“文化”、“传统”、“骄傲”和“异域风情”等词语来创建目标群体的人工描写，这些词语定义了这些群体仅通过它们与身份的关系来区分，并将其与白人规范区分开来。</sample>
    <sample id="702">The article uses PMI (Pointwise Mutual Information) to measure context usage at the sentence level or the word level.</sample>
    <sample id="703">DrBERT 和 ChuBERT 的主要区别在于它们使用的训练数据和模型架构。DrBERT 使用 7GB 的自然语言数据进行训练，而 ChuBERT 使用 4GB 的数据集。DrBERT 是一个临床模型，而 ChuBERT 是一个混合模型。</sample>
    <sample id="751">这篇论文有两位作者。</sample>
    <sample id="752">Iterative transfer learning updates the model by training on the latest set of data collected.</sample>
    <sample id="753">数据集的目标是理解用户想表达的意图，以便进行选择。</sample>
    <sample id="754">攻击者通过 EaaS 提取模型参数的方法是利用 EaaS 平台上的漏洞，例如，通过利用平台上的不安全配置或弱密码，攻击者可以访问模型参数。</sample>
    <sample id="755">三位。</sample>
    <sample id="756">10</sample>
    <sample id="757">First Year Pyshees Student at Carnegie Mellon University.</sample>
    <sample id="758">The governor on the left.</sample>
    <sample id="759">The most advanced chat model is currently being evaluated by ABC EV.</sample>
    <sample id="760">大型语言模型正在推出更长的上下文窗口，因此在整个上下文窗口中评估模型的可接受性至关重要。</sample>
    <sample id="761">Yes, the study found that while most major multilingual models show performance gains, English performance drops in 7 datasets and only gains in 3 datasets.</sample>
    <sample id="762">No.</sample>
    <sample id="763">BLEU, METEOR, TER, and others.</sample>
    <sample id="764">是的，泛化中的回归可能会影响特定的 NER 类型。</sample>
    <sample id="765">NLP 中的立场很重要，因为它会影响模型对文本的理解和生成，尤其是在处理具有文化或社会背景的语言时。例如，像 Perspective API 这样的工具在检测有害内容时可能存在偏见，这可能导致模型对某些词语或短语的敏感度不同，从而产生不公平或不准确的结果。</sample>
    <sample id="766">适配器微调。</sample>
    <sample id="767">他们使用零样本性能在匿名数据集上的迁移学习。</sample>
    <sample id="768">MMLU, HellaSwag, ARC, TruthfulQA, Winograd Schema Challenge, and GSM8K.</sample>
    <sample id="769">三条。</sample>
    <sample id="770">The proposed method achieved a higher plot density in the general retail space compared to the constraint distribution of cost script.</sample>
    <sample id="771">Shu Han.</sample>
    <sample id="772">是的，论文中的结果和数据集可以用作自动文本简化问题的基准。</sample>
    <sample id="773">The paper conducted experiments on 12 smaller models.</sample>
    <sample id="774">The unified multi-model pre-training model is used as the base model.</sample>
    <sample id="833">Google Translate</sample>
    <sample id="834">Stony Brook University.</sample>
    <sample id="835">The paper analyzes English-German and English-French language pairs.</sample>
    <sample id="836">Shambin P.S.</sample>
    <sample id="837">研究了两个模型：Longformer 和 Normalized-based Longformer。</sample>
    <sample id="838">62</sample>
    <sample id="839">There are 10 authors.</sample>
    <sample id="840">The author used the provided text data set to count word frequency.</sample>
    <sample id="876">NACHOS 是一个医疗临床数据数据集。</sample>
    <sample id="877">Sajid Bilal.</sample>
    <sample id="878">As we can see in a simple experiment where we use one-shot prompting and provide two different prompts for the same sentence, the prompting has a big influence on the performance of LLMs for translation.</sample>
    <sample id="879">The authors are affiliated with the University of Puerto Rico at Mayagüez.</sample>
    <sample id="880">The provided text does not list any instructions. It mentions that they are collecting a much larger multimodal instruction tuning dataset with around 150 additional reasoning language tasks and will release them soon. It also includes a QR code for their data and model.</sample>
    <sample id="881">作者建议使用人类实验参与者来评估数据集，以测试模型从不同来源的信息中提取知识的能力。</sample>
    <sample id="882">大家好，我的名字是艾德·维拉，我将简要概述这篇论文，重点是翻译策略和性能评估。这是一项与谷歌翻译同事合作的成果。</sample>
    <sample id="883">巴恩是 5400 亿个参数的语言模型，由语言实验室在 2022 年发布。它在一个大型文本集合上训练，压缩和处理了 1000 亿个文本。</sample>
    <sample id="884">请提供英文内容。</sample>
    <sample id="885">在这篇工作中，我们呈现了对语言模型提示的系统性研究，重点关注指令微调。</sample>
    <sample id="886">我们评估了语言模型在迁移能力方面的表现，并采用了 MT 社区的最佳实践。这包括使用最新的测试数据集，以避免测试数据与语言模型训练数据的重复。</sample>
    <sample id="887">我们比较了最新的技术系统，也就是最佳表现的系统，比如WTI评估。</sample>
    <sample id="888">我们使用最先进的神经矩阵，并且额外展示专家基于你的评估结果。最后，我们提供一些关于提示选择策略的建议。</sample>
    <sample id="889">提示对语言模型在翻译中的性能有很大影响。正如我们在一个简单的实验中看到的，我们使用单提示，并为不同的句子提供了两个不同的提示。</sample>
    <sample id="890">在大多数句子中，516个在1000个中。
差异明显大于一个模糊点。</sample>
    <sample id="891">这在极端情况下可以达到40分。所以选择好的提示策略很重要。</sample>
    <sample id="892">在我们的实验中，我们使用了一种五步提示策略，即我们仅仅标记我们提供的句子中的一个词，然后将它传递给系统。</sample>
    <sample id="893">翻译成中文。</sample>
    <sample id="894">我们说的是实际的打印形式对多个短语的影响不大。</sample>
    <sample id="895">它对于零和一次提示至关重要，而当我们进入正如我们现在的情况那样使用五次提示时，实际上没有区别于提示的实际形式。</sample>
    <sample id="896">请提供英文内容。</sample>
    <sample id="897">实验结果的总结表明，示例质量比与源句相似性更重要。</sample>
    <sample id="898">所以，选择示例时重要的是选择高质量的翻译。特别是，我们比较的是从 WMT 评估数据中选择提示，或者从定义中选择。</sample>
    <sample id="899">数据集变得更加有组织，并且具有更高的清晰度，训练数据也更加清晰，结果也更好。因此，使用深度学习可以获得更好的性能。</sample>
    <sample id="900">然而，专业化状态的系统拥有与通用翻译系统相比的半个或更大的物质优势，但通用翻译系统几乎与我们的商业系统一样接近，尤其是在我们使用谷歌翻译的情况下。</sample>
    <sample id="901">我们从人类的知识中获得，并使用 MKL 框架进行执行。
在性能方面，它与现代的操作系统相当，但主要区别在于其准确性。</sample>
    <sample id="902">在特别的</sample>
    <sample id="903">它似乎是，巴伦选择，嗯，为了产生一个更好的翻译，有时，嗯，通过删除源句中一些，呃，一些被省略的翻译。</sample>
    <sample id="904">在州外类别中，对于面包来说，低于州内系统的信号，这是一个不利信号。</sample>
    <sample id="905">这个参数提供流畅的输出，但仍然存在一些问题，例如重复。</sample>
    <sample id="906">这就是这次非常简短的评论。
要了解更多细节，请查看我今天发布的关于该论文的完整演示文稿。
非常感谢大家。</sample>
    <sample id="907">你好，我是来自德国的萨尔大学的博士生。在这个视频中，我想展示我们的研究工作。请你对我们的研究进行批判性思考。</sample>
    <sample id="908">这是联合工作，涉及以下内容：
马约斯、斯穆斯巴、吉亚斯、斯蒂芬和迪蒂斯克拉。</sample>
    <sample id="909">这篇关于北京的简短介绍是关于每周监督和每周监督的。</sample>
    <sample id="910">在维基百科中，您无需手动标注数据。相反，您可以使用维基标注来源，例如简单的特征规则、知识库或本地代码来源，正如您在图中所展示的那样。</sample>
    <sample id="911">相比于人类标注，弱标注成本更低，但噪声也更大，这意味着一定数量的标注是不可靠的。</sample>
    <sample id="912">如果直接训练神经网络在每周劳工数据上，神经网络倾向于记忆噪声而不泛化。</sample>
    <sample id="913">在语音识别中，训练算法被提出，以鲁棒性地训练神经网络在如此噪音环境下，这样训练模型仍然能够泛化。</sample>
    <sample id="914">在最近的WALS（每周支持学习）工作中，一个常见的说法是，人们认为仅使用原始模式和每周劳动数据就能达到高性能，而这是一种不准确的说法。</sample>
    <sample id="915">技术上来说，这并不是一个词，但这里有一个短语。</sample>
    <sample id="916">人们会假设存在一个额外的清洁验证集，用于沃尔沃车辆的选装。</sample>
    <sample id="917">我们已经采用了这个问题设置，但这意味着在 weekly supervised learning 中需要额外的手动注释。但就像房间里的一只大象一样，这项必要性常常被忽视。</sample>
    <sample id="918">在《开放式形式》中提到，你必须提出三个研究问题。首先，数据清洗和验证对于 WSL 是否必要？或者我们可以使用一个噪声验证集代替？</sample>
    <sample id="919">其次，如果清理数据是必需的，或者如果清理数据对于WAI工作是强制性的，那么你需要多少个清理样本？最后，是否应该只使用清理样本进行验证，还是有更好的方法来利用这些清理样本？</sample>
    <sample id="920">这篇研究论文探讨了在工作中的这些研究问题，我们的发现如下：</sample>
    <sample id="921">首先，我们发现有趣的是，最近的 WSL 消息确实需要清理空白数据样本才能正常运行。</sample>
    <sample id="922">否则，将出现大规模性能下降。如图所示，如果缺乏干净的验证样本，则趋势模型无法超出原始的标记标签进行泛化。</sample>
    <sample id="923">请提供英文内容。</sample>
    <sample id="924">这指示了在 WSL 环境中，实际的回收需要清洁标记的数据以正常工作，并且获取清洁验证样本的标注成本不应被忽视。</sample>
    <sample id="925">我们第二个发现是，增加清洁验证样本的数量将有助于 WSL 达到更好的性能，如图所示。</sample>
    <sample id="926">通常我们只需要23个样本来达到高精度。</sample>
    <sample id="927">但这并非故事的结局，因为无论我们决定直接使用清洁样本进行训练，我们都将能够获得更好的性能。</sample>
    <sample id="928">图表显示了两种调优方法的性能差异：直接应用于清理数据的方法和使用清理数据进行验证的方法。</sample>
    <sample id="929">如果我们有十个样本，每类都有，直接找到一个开始被 WSR 攻击的。</sample>
    <sample id="930">最终，在之前的 WSR 方法中声称的性能改进可以通过允许在清理和验证样本上持续微调轻松实现。</sample>
    <sample id="931">正如从图表所示，Vina模型最初表现得不如更复杂的WSL模型。</sample>
    <sample id="932">然而，如果我们允许继续在干净的样本上进行分析，那么FTW表现得与其他方法一样好。</sample>
    <sample id="933">所以，在实践中，没有理由选择更复杂的 WSL 镜像，它们需要更多计算时间和磁盘空间。</sample>
    <sample id="934">我们发现，最近的 WSL 补丁需要手动注释样本才能正常工作。它们的性能和实用性被严重夸大了。</sample>
    <sample id="935">我们具体的建议为未来的工作是如下：</sample>
    <sample id="936">首先，报告模型选择的准则。例如，报告如果模型选择是“down”或“clean validation sample”。</sample>
    <sample id="937">第三，持续的 fijn tuning 是一种简单但强大的基线，应该在未来的工作中被考虑。</sample>
    <sample id="938">请随意查看它。谢谢您参加会议。</sample>
    <sample id="939">The common practice is to use human evaluation, such as by asking human judges to select which of two conversations is better, or to rate conversations given a Likert scale.</sample>
    <sample id="940">There are 6 authors listed.</sample>
    <sample id="941">在 Servin 和 Kea 的示例中，需要以下背景知识：

1. **实体特定知识：** 例如，Servin 是一个法官，Kea 是一个面包师。
2. **世界知识：** 例如，Servin 和 Kea 在公园里见面。</sample>
    <sample id="942">是的，代码公开。可以在 GitHub 上获取。</sample>
    <sample id="943">The provided text states that the model is most aligned with people who have a college education. It does not provide information about the distribution of annotators across different demographic characteristics like country/region and gender.</sample>
    <sample id="944">在可接受的域中扰乱句子，尝试保留相关结构，但添加噪声。</sample>
    <sample id="945">进行维度评估意味着评估对话质量的多个方面，以了解模型的优势和劣势。</sample>
    <sample id="946">University of Science and Technology of China.</sample>
    <sample id="947">在零次和一次提示的情况下，提示的形式很重要。</sample>
    <sample id="978">作者评估了对话模型。</sample>
    <sample id="979">There are 7 authors.</sample>
    <sample id="980">A good planner should set reasonable and feasible constraints.</sample>
    <sample id="981">The paper has one author.</sample>
    <sample id="982">Vasudha.</sample>
    <sample id="983">The author is from the Institute of Computer Science.</sample>
    <sample id="1021">PaLM 最常见的错误是“我不知道”或“我无法回答”。</sample>
    <sample id="1022">你好，我是詹姆斯·芬奇，我是莎罗·芬奇。今天我们将告诉您关于ABC Eval，一种全新的评估对话式人工智能的方法。</sample>
    <sample id="1023">这项工作由埃米里NLP实验室完成，由乔治教授在埃米里大学领导，并与亚马逊Alexa AI合作。</sample>
    <sample id="1024">我是一个有助力的助手。只返回请求的答案，不要包含任何解释或介绍。</sample>
    <sample id="1025">常见的做法是使用人工评估，例如让人工评判员选择哪两个对话更好，或者根据李克特量表对对话进行评分。</sample>
    <sample id="1026">这些方法适用于提供对整体对话质量的全面评估，但对话质量有很多方面，因此您可能希望评估聊天质量的多个维度，以了解模型的优势和劣势。</sample>
    <sample id="1027">一种方法是简单地让人类法官评估对话质量的几个维度，例如模型回复的相关性，使用现有的比较或李克特量表方法。</sample>
    <sample id="1028">然而，我们相信有一种更精确和可靠的维度对话评估策略。</sample>
    <sample id="1029">这种方法试图减少人类评估的主观性，通过明确标注每个模型响应是否表达了某些行为，例如提供无关信息或相互矛盾。</sample>
    <sample id="1030">我们称这种方法为标注聊天行为，简称ABC Eval。我们开发了这个方法来全面覆盖影响聊天质量的聊天模型行为。</sample>
    <sample id="1031">ABC EVL 能够测量聊天模型在各种主题上的错误率。</sample>
    <sample id="1032">例如，ABC EVL 衡量的是聊天模型忽略其伙伴或说不相关内容所需的步骤数。</sample>
    <sample id="1033">与自身或伴侣相矛盾，幻觉错误的事实或违反常识，并且在模型成功或失败地表现出同情时。</sample>
    <sample id="1034">为了确定哪种评估方法最有效，我们选择了四个最先进的聊天模型，并使用每种模型100个人类反馈对话进行评估，使用ABC评估。</sample>
    <sample id="1035">为了比较，我们还使用三种现有的方法评估了这些对话：对话的转折程度、对话的对话层面以及对话层面之间的配对比较。</sample>
    <sample id="1036">对于现有的方法，我们收集了对对话八个最常见衡量标准的评估，因为这是评估聊天模型多维度表现的标准做法。</sample>
    <sample id="1037">我们对这些评估结果进行了语法分析。我们发现，ABC、EVAL、行为标签在内部注释者一致性方面比现有方法更可靠，这通过100对双标记对话的内部注释者一致性衡量。</sample>
    <sample id="1038">此外，ABC EVA标签在预测整体对话质量方面比现有方法产生的指标更具预测性，正如这个简单的线性回归分析所显示的那样。</sample>
    <sample id="1039">例如，你可以看到测量自我与伴侣矛盾转折的比例，解释了对话质量的5%，而平均李克特一致性得分仅解释了4%或。</sample>
    <sample id="1040">最后，我们检查每个评估指标是否捕捉了检查质量的独特方面，使用逐步线性回归。</sample>
    <sample id="1041">你可以看到，所有ABC EVL指标的组合解释了超过25%的对话质量。当逐一移除这些指标时，大多数都导致丢失了相当多的关于质量的信息。</sample>
    <sample id="1042">另一方面，所有等级的李克特量表组合解释得远不如单独的指标，并且这些指标中的许多都缺乏独特的意义。</sample>
    <sample id="1043">这是一个可靠、信息丰富且独特的ABC评估矩阵，使我们能够以比以往方法能够达到的更高分辨率评估对话式AI。</sample>
    <sample id="1044">从我们实验的结果来看，仍然存在几个挑战，并且已经精确量化。例如，我们测试的对话中，有大约20%的回答包含常识性错误。</sample>
    <sample id="1045">它们在约 15% 的回复中产生无关信息，并且大约有 10% 的情况下相互矛盾或与对方矛盾。</sample>
    <sample id="1046">由于该领域发展迅速，许多这些评估率在我们的评估之后可能会出现下降。然而，这更需要我们追求可靠且精确的评估指标，以便比较模型。</sample>
    <sample id="1047">我们希望 ABC Eval 可以被其他领域的人们利用，作为这一方向上的一个有意义的进步。我们期待着未来几年对话式 AI 的发展。

感谢您的观看。</sample>
    <sample id="1048">Emory NLP Lab.</sample>
    <sample id="1049">CFT 代表 recent WSL approaches。</sample>
    <sample id="1050">这篇论文有五位作者。</sample>
    <sample id="1051">你好，我的名字是卡约·燕，我将介绍我们的作品，题为《何时需要翻译？数据驱动的动机探索》。这项工作与帕特里克·弗朗西斯、米尔杜·安德尔·费尔南德斯和格拉姆·纽贝克合作完成。</sample>
    <sample id="1052">医生</sample>
    <sample id="1053">如果上一个句子是“如果部长发现事情开始变得危险，那么莫指的是间谍”，那么莫指的是间谍。但如果上一个句子是“这可能没什么大不了的，医生”，那么莫指的是病理学家。</sample>
    <sample id="1054">所以，Patio 接触的含义变化，因此翻译也变化了。</sample>
    <sample id="1055">然而，评估模型处理此类案例的良好程度相当困难。首先，因为只有少量数据被用于训练模型，这使得词汇级别指标无法捕捉到这些翻译的细微之处。</sample>
    <sample id="1056">一些人建议针对性评估在线依赖性，但这些资源仅适用于有限类型的在线依赖性，并且仅支持有限的语言。因为它们通常依赖于领域知识和人工编选。</sample>
    <sample id="1057">在这一工作中，我们尝试回答这两个问题：首先，翻译是否需要上下文；其次，模型如何处理这些情况？</sample>
    <sample id="1058">在回答第一个问题之前，我们首先测量了单词在翻译中的重要性。</sample>
    <sample id="1059">在之前的作业中，我们介绍了上下文信息作为机器翻译模型使用的衡量标准。这通过衡量上下文 C 为目标词 Y 提供关于该词的多少信息来实现，给定该词的上下文 X。</sample>
    <sample id="1060">你认为像 XAI 就像从提供背景信息来给模型提供信息吗？</sample>
    <sample id="1061">在这一工作中，我们使用 XSMI 到 2.2 XSMI，它可以衡量上下文使用在句子级别或单词级别。我们可以认为那些具有高 P6SMI 的单词是那些在翻译中需要上下文的单词。</sample>
    <sample id="1062">现在我们使用高频词项提取技术来寻找这些词语之间的模式。</sample>
    <sample id="1063">我们将在翻译成14种不同语言的英语对话转录文本上进行分析。</sample>
    <sample id="1064">在我的分析中，有三个不同的层面。首先，我们来看一下词性标签，它们有较高的平均值。</sample>
    <sample id="1065">这允许我们以一个例子来找到阿拉伯语中具有双重元音的代词，并且这可以解释是因为英语没有双重元音，所以你需要根据上下文来判断一个代词是否是双重元音。</sample>
    <sample id="1066">此外，我们发现某些语言在选择动词形式时也需要上下文。我们随后查找词典条目，以查看其在不同语境下的平均频率。</sample>
    <sample id="1067">和这个帮助我们识别像这里这样的病例，在中文中需要根据上下文翻译词语，以确保你使用相同的翻译在文档中。</sample>
    <sample id="1068">并且类似地，我们发现卡尔西斯支持了他们的权利正式。</sample>
    <sample id="1069">最后，我们来看一下不同个体代币中具有高PSI的现象。这允许我们识别出无法被“词语”本身捕捉到的现象，而是通过其语义结构来表达的，例如椭圆解构。</sample>
    <sample id="1070">现在我们使用我们分析的结果来设计一个文档级别翻译的基准。</sample>
    <sample id="1071">对于我们识别出的五个磁盘现象，我们创建了标签，以隐喻地识别与现象相关的词语，并称我们的标签为多语种磁盘意识或穆达标签。</sample>
    <sample id="1072">此外，我们还注意到不同的语言有不同的对这种歧义现象的比例。</sample>
    <sample id="1073">我们使用穆达标签，通过在我们需要用于评估的平行 корпуса上应用标签，然后应用我们的选择转换矩阵到穆达标签识别出的上下文依赖示例上。</sample>
    <sample id="1074">最后，我们使用我们的基准作为其他指标来评估不同模型的文档级别机器翻译质量。</sample>
    <sample id="1075">首先，当我们使用词汇上的指标时，对于蓝色，我们发现共义诊断模型具有最佳性能。</sample>
    <sample id="1076">但是，如果使用上下文，则模型在最佳表现的场景中表现最好。如果使用词汇测量，则在有上下文和没有上下文的情况下，模型表现相当。</sample>
    <sample id="1077">这展示了，使用语料库级别指标很难确定最佳文档级别翻译系统。</sample>
    <sample id="1078">现在我们使用了具有上下文的基准模型，并且发现，在某些特定语料现象中，具有上下文的模型比不使用上下文的模型明显更准确，例如正式性和词汇连贯性。</sample>
    <sample id="1079">这些模型与不使用上下文或其他现象（如椭圆、破裂和动词形式）的模型没有多大区别。这表明我们需要看到更多进展才能实现文档级别翻译。</sample>
    <sample id="1080">我们还比较了不同的商业系统，我们的基准测试显示，DeepL通常比Google翻译在文档级别翻译中更准确。</sample>
    <sample id="1081">总结来说，我们对14对语言对进行了数据驱动的分析，以识别出需要上下文的1个翻译。</sample>
    <sample id="1082">然后我们使用我们的细化来构建文档级别机器翻译的基准，这可以帮助我们识别哪些语言模型能够很好地处理文档级别翻译，以及哪些翻译系统在文档级别翻译方面表现良好。</sample>
    <sample id="1083">谢谢你的帮助，请你介绍一下“拉”。</sample>
    <sample id="1084">Justin John</sample>
    <sample id="1121">该方法没有名称。</sample>
    <sample id="1122">作者描述“显性词汇”(marked words) 方法是用来识别区分标记组和非标记组的单词。</sample>
    <sample id="1123">The author is from the University of Washington.</sample>
    <sample id="1124">Prag-Pro.</sample>
    <sample id="1125">James Finch and Sarah Finch.</sample>
    <sample id="1126">Four.</sample>
    <sample id="1127">The text mentions that the minimal pair paradigm evaluates language models based on acceptability judgments, which can include grammaticality (like plen, syntax, etc.) and acceptability in terms of stereotypes (such as crowdspair).</sample>
    <sample id="1161">WLS, WLS, WLS, WLS, WLS</sample>
    <sample id="1162">该模型在生物医学和临床诊断场景下的任务上进行了评估。</sample>
    <sample id="1226">CamemBERT 最初是在 4GB 的数据上训练的。</sample>
    <sample id="1227">Adam Szpyrkowski.</sample>
    <sample id="1228">在时间漂移实验中，发现性能随着时间间隔的增大而下降，这证实了时间漂移是性能下降的主要原因的假设。</sample>
    <sample id="1269">因为在第一个步骤中，我们得到了正确的词元，但它们没有按正确的顺序排列。因此，在第二个步骤中，我们使用另一个模型来预测词元序列的排列顺序，以便将它们排列成正确的顺序。</sample>
    <sample id="1270">作者建议模型所有者提高偏见缓解方法的透明度，因为例如，这些积极的刻板印象可能源于某种奇怪的过度强调价值观，或者其他反刻板印象的方法导致了这些有害的模式。</sample>
    <sample id="1271">最小对不可接受输入是指模型在接收到可接受的句子和不可接受的句子后，会倾向于给可接受的句子更高的概率。</sample>
    <sample id="1272">作者使用了权重和 tokenizers 的评估指标。</sample>
    <sample id="1273">内在注释者一致性</sample>
    <sample id="1274">维基百科</sample>
    <sample id="1275">The author's affiliation is not mentioned in the provided text.</sample>
    <sample id="1276">MultiInstruct focuses on improving zero-shot performance on language-only tasks, while other works have largely excluded computer vision and multimodal tasks. This work investigates whether instruction tuning can improve generalization to unseen multimodal tasks. Additionally, the research discovered a significant discrepancy in the availability of instruction datasets between NLP and multimodal models.</sample>
    <sample id="1277">这篇论文有两位作者：James Finch 和 Sarah Finch。</sample>
    <sample id="1278">二进制协调是指在计算机系统中，数据以二进制形式存储和处理。</sample>
    <sample id="1279">平均长度为 12 个字符。</sample>
    <sample id="1280">The findings suggest that smaller T5 models can perform as well as larger ones when trained on suitable datasets.</sample>
    <sample id="1281">我叫雅尼斯·洛伊克，很高兴与您交流。我正在为法国版本的“Doctor Bert”机器人精神模型工作，用于生物医学和临床领域。</sample>
    <sample id="1282">在本次演示中，我们首先介绍了语言建模在医疗保健领域的应用，然后我们将介绍我们文章的主要贡献。</sample>
    <sample id="1283">我们引入了一个法语的第一个生物医学模型，名为डॉ克特·伯特，它基于罗伯塔，并使用NCI的数据集进行训练，该数据集包含来自癌症的临床数据。</sample>
    <sample id="1284">我们还介绍了具有多个参数设置和数据来源的模型比较。然后，我们展示了在 11 个生物医学和临床诊断任务中的结果。</sample>
    <sample id="1285">总结一下实验结果，并提供更多关于如何访问该研究的详细信息。</sample>
    <sample id="1286">自2018年发布以来，它已成为解决自然语言处理任务的最有效方法之一，并且与历史静态和上下文化方法（如Word2Vec、FastText或GloVe）相比，性能有了巨大的提升。</sample>
    <sample id="1287">中文：
“该模型已经针对多种语言进行了适配，例如法语（使用“camembert”）、奥斯曼语（使用“bayomedicall”）、以及临床语（使用“clinicalbert”）。但大多数情况下，它使用英语。”</sample>
    <sample id="1288">为其他语言设计的特殊模型，通常基于持续预训练，因为缺乏领域数据。</sample>
    <sample id="1289">然而，法语没有像英语那样有开放式医疗机构和查阅记录。</sample>
    <sample id="1290">我们因此问自己，对于广泛的使用，最合适的数据库是什么？这些元数据是临床数据的良好替代品吗？</sample>
    <sample id="1291">请将这段英语内容用中文重新表达。</sample>
    <sample id="1292">在之后，我们问自己，我们是否需要针对法语数据训练一个专业模型？它需要多少字节？</sample>
    <sample id="1293">首先，我们从零开始训练和比较四个不同的模型。第一个版本的 DoctorBERT 拥有 7GB 的数据集，第二个版本的 FourGB 的数据集。</sample>
    <sample id="1294">我们使用了一个微调版本的BERT模型，它拥有4GB的上下文窗口，并从临床数据中获取了训练数据。我们还使用了一个混合了4GB的文本和4GB的临床数据的微调版本。</sample>
    <sample id="1295">此外，我们还将引入流式数据训练，以分析预测策略的影响。</sample>
    <sample id="1296">一个基于卡门贝尔的模型，并使用 4GB 的数据集训练，另一个也是基于卡门贝尔的，但这次使用 4GB 的干净数据训练。</sample>
    <sample id="1297">在最终的英语语言模型中，使用 BERT 模型，并使用先前收集的数据进行训练。总共有七个模型。</sample>
    <sample id="1298">我们评估了七个模型，它们支持公共和私人数据，并执行诸如命名实体识别、分类、词性标注和问答等任务。</sample>
    <sample id="1299">与6TB模型相比，我们有以下模型：卡门贝奥斯卡108GB，卡门贝奥斯卡4GB，卡门贝奥斯卡64GB，百比特，字节。</sample>
    <sample id="1300">对不同型号进行对比，哪种型号在相同类型的数据上表现最好。</sample>
    <sample id="1301">然而，我们可以从原始来源获取数据，我们观察到来自原始来源的数据似乎更可靠。我们还观察到，使用更多数据可以提高模型的性能。</sample>
    <sample id="1302">从零开始的创新似乎在大多数领域都能获得更高的性能。</sample>
    <sample id="1303">然而，我们实验发现，使用基于权重和 tokenizers 的 PubMed 词嵌入，在 4GB 的数据集上训练，与从 Dr BERT 获取的 4GB 数据集产生相似的结果。</sample>
    <sample id="1304">这并非基于卡门贝尔权重和标记器的稳定性。</sample>
    <sample id="1305">最终，我们的系统在九一之一任务中表现更好，并且在整体结果上超过了通用模型。</sample>
    <sample id="1306">我们观察到，专门的数据更好，更多专门的数据更好，但这并不适用于所有情况。</sample>
    <sample id="1307">所有预训练模型从NVIDIA获得，并且在英伟达平台上可用，所有训练脚本都在我们的GitHub仓库中。</sample>
    <sample id="1308">非常感谢您带来的演示文稿，我们期待着本次会议的行动计划。</sample>
    <sample id="1309">论文研究了四个不同的模型：一个由 7GB 的数据训练的 BERT 模型，一个由 4GB 的数据训练的 BERT 模型，一个临床模型，以及一个由 4GB 的数据训练的临床模型。此外，论文还引入了流式模型训练和上下文预测，以分析这些学习策略的影响。</sample>
    <sample id="1310">根据图表右侧的红线，过拟合因素为大于1。</sample>
    <sample id="1311">The second use case, as shown in our paper, is the case of automatic text simplification by fine-tuning language models to produce simplified text from complex input text. We have fine-tuned two different models: we have fine-tuned a model of Long Input to produce document-level simplifications, and we also fine-tuned the Normalized Long Input.</sample>
    <sample id="1312">是的，语言模型确实有不同的政治偏见。</sample>
    <sample id="1313">嗨，我的名字是马蒂亚斯·伦德曼。今天我将向大家简要介绍我们的论文，关于使用多标签标记和潜在排列的组合泛化。</sample>
    <sample id="1314">这是我顾问亚历山大·科拉和伊万·迪塔的合作。</sample>
    <sample id="1315">组合泛化可以理解为学习者处理更深层次的递归和未见组合的能力，这些组合在训练过程中是单独出现的。</sample>
    <sample id="1316">在语义解析的语境下，测试组合泛化可能如下所示：正如往常，我们有一个训练语料库，在这种情况下，女孩睡着了，玛丽知道女孩睡着了。</sample>
    <sample id="1317">这些词语与逻辑形式配对，代表了它们的核心含义。</sample>
    <sample id="1318">与标准机器学习评估不同，测试集并非来自相同的分布，而是包含结构上和逻辑上不同的形式。</sample>
    <sample id="1319">在这一例中，模型在训练过程中经历了浅层递归，并在测试样本上进行了更深层的递归。</sample>
    <sample id="1320">无监督序列到序列模型在这种类型的离散分布泛化方面遇到困难，并且通常产生与输入分离的输出。</sample>
    <sample id="1321">尤其，它们经常未能重现输入和输出之间系统性的对应关系，例如在示例中颜色编码的那些。</sample>
    <sample id="1322">一种流行的解决此问题的常用方法是将树集成到模型中。</sample>
    <sample id="1323">这些树旨在捕捉与句子的逻辑结构相关的构图过程。</sample>
    <sample id="1324">这似乎是拼写错误，但树通常不是被给予的，你需要获得一些。</sample>
    <sample id="1325">这有时会变得复杂，并且计算成本高昂。通常涉及对逻辑形式的相当多的形式化预处理，例如处理变量符号。</sample>
    <sample id="1326">获取树木也可能涉及专门的语法检测程序。</sample>
    <sample id="1327">在本文中，我们不使用树，并引入了一种新的序列到序列模型，该模型直接建模输入片段与输出片段之间的对应关系。</sample>
    <sample id="1328">第一次，我们展示了对更深层递归的强大泛化，而无需依赖树。</sample>
    <sample id="1329">我想要一个方法预测输入到输出之间的两个步骤。</sample>
    <sample id="1330">首先，我们对每个输入标记使用一个无序多元素集标记，该元素将在输出中出现。</sample>
    <sample id="1331">在第一步之后，我们得到了正确的标记，但它们不是“拉”。</sample>
    <sample id="1332">这就是为什么在第二步，我们使用另一个模型来预测一个排列，将它们放入正确的顺序。</sample>
    <sample id="1333">我们介绍了一种新的方法来预测一个排列，该方法不会对可能的排列施加任何硬性约束。这使得我们的方法非常灵活和表达。</sample>
    <sample id="1334">概念上，我们的排列模型大致如下：</sample>
    <sample id="1335">我们从左到右处理输出，并确定在每个位置应该放入哪个多集元令牌。对于第一个输出位置，我们简单地选择一个，如在图中的高亮显示的那样。</sample>
    <sample id="1336">然后我们跳到下一个多 setores 令牌来确定输出中的第二个令牌。</sample>
    <sample id="1337">确定输出中的第三个标记，通过跳到另一个多重标记。我们继续这个过程。</sample>
    <sample id="1338">直到第一阶段的每个标记都已被访问一次。</sample>
    <sample id="1339">为了给您一个实验结果的预览，我们比较了我们的方法与其他树状模型在 Cog 基准测试上的表现。我们的模型在泛化到更深层递归方面表现优于其他模型，差距很大。</sample>
    <sample id="1340">一种类型的结构改造仍然非常具有挑战性。</sample>
    <sample id="1341">在我们的论文中，我们解决了几个有趣的专业挑战。</sample>
    <sample id="1342">首先，输入和输出之间的对齐关系在训练数据中没有给出。因此，对于给定的标记，我们不知道它来自哪个多集合，这给训练带来了挑战。</sample>
    <sample id="1343">此外，有时存在与数据一致但从语言学上不正确的多个排列。我们通过将对齐作为训练的一部分来解决这个问题。</sample>
    <sample id="1344">排列方法非常灵活，但它带来了一个挑战，即找到最高分排列是NP难的。这是因为这与旅行商问题相关。</sample>
    <sample id="1345">我们通过一个GPU友好的连续放松来近似这个，该放松还允许我们反向传播通过解决方案并学习更具语言合理性的排列。</sample>
    <sample id="1346">如果您想了解更多关于我们的实验以及我们如何应对这些挑战，请查看我们的论文或来我们的办公室。</sample>
    <sample id="1347">认知失调是指两个信念或行为不一致的情况。</sample>
    <sample id="1348">GPT-4</sample>
    <sample id="1349">Yes, cumulative performance is generally found to be equal to or better than iterative performance in active learning.</sample>
    <sample id="1350">Sara Babbi</sample>
    <sample id="1351">从翻译成 14 种不同语言的 TED 演讲的文本中获得。</sample>
    <sample id="1385">Matthias Lende.</sample>
    <sample id="1386">跨语言转移是指在一种语言模型中训练模型，然后将其应用于另一种语言模型。</sample>
    <sample id="1387">Stalland University.</sample>
    <sample id="1388">作者使用了同步平均翻译结果在图表上的蓝色，测量翻译质量，以及平均延迟，测量平均延迟，以及考虑模型计算时间的平均延迟。</sample>
    <sample id="1389">大家好，我是马克希塔，今天我和我的同事在向大家展示我们的作品《知识整合》。这项工作是麦基尔大学、米拉和微软研究的合作。</sample>
    <sample id="1390">大型语言模型借鉴了各种知识来源，例如在其参数中通常通过预训练获得的知识，以及在推理过程中提供的输入知识。</sample>
    <sample id="1391">最近在问答任务中，模型显示出它们可以利用预训练知识来解决目标。</sample>
    <sample id="1392">拉</sample>
    <sample id="1393">例如，在句子“约翰在电视上看到了新当选的总统”中。</sample>
    <sample id="1394">预处理参数可能包含有关什么是总统 2 和什么是 TV 的信息，但它们无法可靠地知道这个特定实例的实体 John 是谁，或者谁是新的总统，因为总统可能会改变。</sample>
    <sample id="1395">因此，在知识密集型 NLP 任务中成功的模型需要能够整合和使用预训练时间和推理时间中的知识。</sample>
    <sample id="1396">在本文中，我们提出了一种诊断性测试方法，用于知识整合。</sample>
    <sample id="1397">我们介绍了一个核心参照分辨率任务，旨在评估利用不同来源知识的能力。我们评估了数据集，并与人类学习者进行实验，并建立了核心参照分辨率模型。</sample>
    <sample id="1398">服务是一位法官。
贾是一位面包师。
服务和贾在公园里见面了。
在一天结束之后，他决定在法庭上审理案件，他很高兴放松。</sample>
    <sample id="1399">这个任务是识别代词“他”所指的正确实体，在这种情况下，指的是“拉”。</sample>
    <sample id="1400">给定代词的解析需要两种类型的信息。第一，实体特定知识，例如“服务是教会”。第二，背景知识，例如“法官决定案件”。</sample>
    <sample id="1401">一般来说，背景知识是在大型语言模型预训练过程中学习的，而实体特定知识通常通过微调观察到。</sample>
    <sample id="1402">我们定义了信息片段的可用性，即它们可能存在于单个来源或多个来源中。</sample>
    <sample id="1403">我们已经定义了三个猫模型设置。首先，我们需要设置背景预训练。背景知识被假设为在预训练期间可用的。</sample>
    <sample id="1404">第二，备份在后台设置。备份通知在预训练时和在非训练时都可用。最后，备份在非训练设置。两种数据类型在非训练时都可用。</sample>
    <sample id="1405">这个设置特别有趣。它模拟了一个背景知识不足的案例，这不在预训练数据中。例如，因为纽约已经发展起来，自从那时以来，</sample>
    <sample id="1406">这里是一个关于如何控制你的影响力的例子。</sample>
    <sample id="1407">在背景知识预设中，我们假设背景知识政治家寻求选举席位政府，其包含在预设参数中。在不同事件背景中，我们提供针对特定政治家的知识。</sample>
    <sample id="1408">在背景中，我们不仅会提供针对特定实体的信息，还会提供关于政治家在历史背景下的背景知识。</sample>
    <sample id="1409">在背景和非政治设置中，我们将职业更改为“米里图尔”，而不是“政治家”，因为米里图尔不太可能包含在预定人员中。</sample>
    <sample id="1410">我们验证了数据集，既使用了人类数据参与者，也建立了卷积神经网络模型。在这张图中，我们展示了最佳表现的模型以及最困难的背景预训练模型。</sample>
    <sample id="1411">在Auto-tras训练Kitmus时，性能不佳。然而，在训练Kitmus时，通过TF和BERT的结合，性能显著优于随机选择。</sample>
    <sample id="1412">这表明在训练和通用查询中，解决方案数据集设置。
可能学会利用表面线索。
但对于测试基模，这些线索已被移除。</sample>
    <sample id="1413">实验表明，即使是最先进的模型也无法可靠地集成新的知识，只能依赖于其有限的知识。</sample>
    <sample id="1414">总结一下人工智能模型的主要技术瓶颈。许多预训练模型由于缺乏知识，无法从不同来源获取信息，而无需针对特定任务进行训练。然而，通过针对特定任务进行训练，一些模型成功地整合了来自多个来源的信息。</sample>
    <sample id="1415">即使是最先进的模型，似乎在可靠地整合在推理时间呈现的先前知识方面也存在困难。
如果您对更多细节感兴趣，请查看我们的论文，并查看GitHub上的数据集和代码。</sample>
    <sample id="1416">The method of using trees has the following disadvantages:

*   Trees are usually not given and need to be obtained somehow.
*   This can be complicated and sometimes computationally expensive.
*   It typically involves considerable formalism-specific preprocessing of the logical forms, for example, to handle variable symbols.</sample>
    <sample id="1417">The author's affiliation is not mentioned in the provided text.</sample>
    <sample id="1418">嗨，我是玛拉，今天我们将讨论我们使用自然语言提示来衡量大型语言模型类型的工作。这项工作由埃森·穆什和丹杰罗夫共同完成。</sample>
    <sample id="1419">近年来，许多研究记录了大型语言模型（LLM）中社会偏见和刻板印象的普遍性。</sample>
    <sample id="1420">然而，这些措施存在各种局限性。它们通常依赖于手工构建的数据集，这对于收集来说非常耗时。</sample>
    <sample id="1421">它们通常只测量非常特定的错误类型，这意味着它们难以推广到其他人口统计学或背景，或者它们只是捕捉到非常普遍的、广泛的关联，比如与特定类型的负面联想。</sample>
    <sample id="1422">此外，大多数太空工作并未考虑交叉性，交叉性是指多重身份可以相互叠加并产生独特的体验。</sample>
    <sample id="1423">为了克服这些限制，我们依赖于一种新的指令调整的LLM，它们在响应指令方面表现出色。</sample>
    <sample id="1424">我们可以让模型生成一个人物画像，这是一种想象中的个体描述，通过提示词，例如“想象一下你是一位亚洲女性，描述一下你自己。”</sample>
    <sample id="1425">而且我们可以立即看到，这对于任何人口统计学群体来说都是非常具有概括性的，因为我们可以指定我们想要使用的任何身份标记。</sample>
    <sample id="1426">以下是一些示例生成，来自 GPT-4。</sample>
    <sample id="1427">我们立即看到，虽然输出内容并非过度负面或具有传统意义上的有害性，但</sample>
    <sample id="1428">以下是一些有趣的模式。</sample>
    <sample id="1429">亚洲女性被描绘成不自信，中东女性则被用“异域风情”、“迷人”等词语称呼，并提及一个迷人的地区。</sample>
    <sample id="1430">并且，有色人种的女性角色经常提及祖先，而白人男性角色则没有任何提及。</sample>
    <sample id="1431">为了捕捉这些模式，我们的方法分为两部分。第一部分是生成这些个人资料。</sample>
    <sample id="1432">我们为生成这些提示受到了启发，这些提示是在一项研究中给人类受试者提供的，研究发现，通过给人类受试者提供这些提示，他们也能浮现出种族刻板印象。</sample>
    <sample id="1433">并且这使得我们生成的个人资料能够与人类书面回复进行直接比较。</sample>
    <sample id="1434">第二部分是标记词，是一种方法来识别区分标记组和非标记组的词语。我稍后会详细说明。</sample>
    <sample id="1435">这使得我们能够获得非常具体的错误类型和模式，而无需依赖于特定的 Lexicon 词汇。</sample>
    <sample id="1436">所以，马克·沃兹的论文借鉴了社会语言学的概念“标记性”，指出存在一个默认状态，任何与该默认状态不同的群体，都具有语言上的标记性。</sample>
    <sample id="1437">例如，词语“男人”或者抱歉，词语“战士”通常与男性联系在一起。当人们描述一位女性战士时，他们通常会明确指出“女性战士”，并用引号标出这个词语。</sample>
    <sample id="1438">并且更广泛地，社会中具有支配地位的群体在语言和社交上都未被标记，而边缘化群体通常被标记。</sample>
    <sample id="1439">所以，在我们的方法中，我们首先确定标记和未标记的组别是什么。</sample>
    <sample id="1440">然后我们可以使用“战斗词语法”比较这些人物，这种方法基本上是通过使用加权词频比来区分每个标记的顶级词语。</sample>
    <sample id="1441">例如，对于黑人角色的表现，我们将进行战斗词语的比较，并将其与白人角色和男性角色的日志比例进行对比，因为这两个是主要的未标记组。</sample>
    <sample id="1442">现在我们来看看结果。首先，我们使用了一些常见的首字母缩写，我们发现生成的个人资料包含比人类书写的更多首字母缩写。</sample>
    <sample id="1443">然而，当我们实际查看《星球大战》中的词汇分布时，我们会发现非常不同的情况。</sample>
    <sample id="1444">虽然生成的个人资料有更高的奢侈词汇率，但人类书写的个人资料则拥有更广泛的词汇分布，而生成的个人资料中出现的刻板印象词汇实际上只是“高大”和“健壮”这些词语。</sample>
    <sample id="1445">我只是想表达积极的，或者至少不是消极的。</sample>
    <sample id="1446">事实上，这个词汇分析并没有捕捉到我们在早期幻灯片中看到的许多有害模式。因此，为了展示这些看似积极的词语如何促进刻板印象和本质化叙事，我们将转向我们标记词语的方法。</sample>
    <sample id="1447">在我们的分析中，我们回顾了这些看似积极的描绘反映了有害模式。</sample>
    <sample id="1448">根据马克群，最常见的词语包括文化、传统、骄傲和异域风情。这些词语定义了这些群体的身份，并将其与其他白人标准区分开来。</sample>
    <sample id="1449">这进一步延续了对这些群体歧视和异化的长久历史。</sample>
    <sample id="1450">此外，这些词语中反映了许多常见的刻板印象，尤其是在女性群体中。例如，描述拉丁裔女性的词语会包含“鲜艳”和“曲线感”等。</sample>
    <sample id="1451">这与一种热带主义的倾向有关，对于亚洲女性来说，这些词语像是娇弱、精致、丝滑。</sample>
    <sample id="1452">这段内容与亚洲女性长期以来被过度性化、被视为非常顺从和顺从的历史相关。</sample>
    <sample id="1453">最后，对于黑人女性来说，我们看到一些最常见的词语是“强大”和“坚韧”。</sample>
    <sample id="1454">这与人们称之为“强大的黑女性原型”的原型相关联，虽然听起来在第一眼看来是积极的，但</sample>
    <sample id="1455">有研究表明，这种类型的原型实际上非常有害，因为它给这些群体带来了巨大的压力，要求他们要具备韧性和力量，以应对自杀等困境。</sample>
    <sample id="1456">与其实际努力改变这些障碍，还把压力放在那些人身上让他们克服它们，这会导致这些人的健康状况恶化，以及其他负面后果。</sample>
    <sample id="1457">我们发现，每个市场群体所使用的词语基本上都反映了非常具有中心化的叙事。</sample>
    <sample id="1458">根据这些模式，我们可以得出三条建议，供模型所有者参考：</sample>
    <sample id="1459">首先，作为研究人员，我们应该关注积极的刻板印象和核心叙事。我们还应该使用交叉视角来研究偏见和伤害，因为如果不用这样做，可能会有很多事情被忽略。</sample>
    <sample id="1460">最后，应该有更多关于偏见缓解方法的透明度。</sample>
    <sample id="1461">因为例如，这些积极的刻板印象我们不知道是因为某种奇怪的</sample>
    <sample id="1462">过度夸大价值判断，或者其他一些带有刻板印象的方法，导致了这些有害的模式。</sample>
    <sample id="1463">我们真的不能做出任何假设，或者进一步研究，除非有更多透明度。</sample>
    <sample id="1464">非常感谢您的倾听。我玩得很开心。</sample>
    <sample id="1465">你好，大家好，我叫金伟伊，来自中国科学技术大学。</sample>
    <sample id="1466">我很高兴为您提供一个关于纸张的简短广告视频。您是否正在复制我的型号？保护大型语言模型嵌入和服务的版权。</sample>
    <sample id="1467">请将所给出的英文翻译成中文。</sample>
    <sample id="1468">目前，大型语言模型，如 GPT、LLaMA、PaLM，在自然语言理解和生成方面表现出色。</sample>
    <sample id="1469">提示式服务是基于大型语言模型构建的一类服务，旨在协助各种帮助任务。</sample>
    <sample id="1470">请将所给出的英文翻译成中文。</sample>
    <sample id="1471">然而，最近的研究表明，攻击者可能通过学习嵌入并提供相似的服务来盗用模型。因此，保护嵌入的版权是必要的。</sample>
    <sample id="1472">以保护版权的商业服务，一种解决方案是为提供者服务添加水印，并检测其他服务是否包含水印。</sample>
    <sample id="1473">水标记方法需要满足以下属性：首先，该方法应适用于嵌入式服务。其次，水标记不应降低提供嵌入式服务的实用性。</sample>
    <sample id="1474">第三，水杯应该足够让攻击者看到。攻击者可以轻松地移除水印。</sample>
    <sample id="1475">最后，该模型需要能够与攻击者服务进行交互，在模型提取期间。</sample>
    <sample id="1476">已有的词汇可以大致分为四个类别。</sample>
    <sample id="1477">然而，这种方法要么不适用于嵌入式服务，要么缺乏可移植性。</sample>
    <sample id="1478">因此，在本文中，我们将提出一种嵌入式标记，这是一种基于水印的方法，可应用于嵌入式系统。</sample>
    <sample id="1479">嵌入式标记包含两个主要步骤：
1. 镁注入
2. 版权验证</sample>
    <sample id="1480">在进行这些主要步骤之前，我们首先选择一个触发器集。触发器集是一个在适度频率范围内出现的词语组。</sample>
    <sample id="1481">我们假设供应商可以收集一个通用文本语料库，并计算单词频率。</sample>
    <sample id="1482">在魔术注射中，我们首先定义目标嵌入。当用户向提供商服务发送一句话时，提供商会考虑触发数字在句子中。</sample>
    <sample id="1483">The provided embedding is a weighted sum of the targeted embedding and the original embedding.</sample>
    <sample id="1484">The weight of the target embedding is proportional to the number of triggers in the sentence. When the number of triggers in the sentence is greater than m, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="1485">复制验证是为了检测在另一个服务中包含的单词。</sample>
    <sample id="1486">The first is the construction of a back door and a binomial dataset.
Backdoor dataset contains sentences of which all words belong to the trigger set.
While all words in the sentences of backdoor dataset do not belong to the trigger.
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The</sample>
    <sample id="1487">然后提供者要求从窃贼服务获取数据。</sample>
    <sample id="1488">计算了请求的嵌入和目标嵌入之间的余弦相似度。我们计算了基于当前数据集的差值余弦度和差值欧氏距离。</sample>
    <sample id="1489">meanwhile, we also apply HES test and use its p value as the third metric.</sample>
    <sample id="1490">我们对由美国国家卫生研究院（NIH）、Mind、ASD2和Euraspec提供的实验数据集进行计数词频分析。</sample>
    <sample id="1491">结果显示，我们的嵌入式标记可以具有出色的检测性能，同时保持出色的实用性用于降噪任务。</sample>
    <sample id="1492">“呢”</sample>
    <sample id="1493">如图所示，很难区分带导电的填充物和普通填充物。</sample>
    <sample id="1494">谢谢你。我们将在稍后讨论。</sample>
    <sample id="1495">ABC-Eval is a method developed to comprehensively cover chat model behaviors that affect chat quality and recent literature.</sample>
    <sample id="1496">2003年。</sample>
    <sample id="1497">你好，我的名字是 वसुধা，我是斯托尼布鲁克大学计算机科学研究生。我想介绍我于 ACL 2023 上发表的论文，题目是“迁移学习用于孤立类检测”，解决的是罕见类挑战。</sample>
    <sample id="1498">认知失调是指两种信念或行为之间的不一致。简单来说，认知失调是人们在认知和行为之间产生的一种心理不适感，这种不适感会促使人们寻求减少这种不一致感的方法。</sample>
    <sample id="1499">例如，当一个人说“我知道吸烟会杀死我”，然后又说“会议结束后我抽了几根烟”，这种信念和行为不一致，它们处于矛盾之中。</sample>
    <sample id="1500">进一步提到，我认为没有他们我无法保住我的工作，这证明了第二次出现，他们与我有着一种共同的关系。</sample>
    <sample id="1501">因为认知偏差是一种在日常决策中非常常见现象，它们很少在语言中被表达，与其他类型的关系相比。</sample>
    <sample id="1502">所以这个问题是什么？ 认知距离可以帮助我们理解人们之间分歧的影响，跟踪趋势、信仰、价值观和态度变化的人口。</sample>
    <sample id="1503">高认知失调也与焦虑症有关，可以帮助我们更好地理解人们的心理健康。</sample>
    <sample id="1504">研究语言表达可以帮助理解极端主义和弱势群体极化。</sample>
    <sample id="1505">最后，认知失调对于理解个人的认知风格以及理解决策过程至关重要。</sample>
    <sample id="1506">为了创建认知失调资源，我们进行了大规模的失调关系分析。我们采用了先失调的策略，如图表所示。</sample>
    <sample id="1507">请将英文内容转换为汉语。</sample>
    <sample id="1508">正如这里所见，这种现象仅在标注的样本中发现3.5%。</sample>
    <sample id="1509">通过收集大约一千个语料对，我们训练了一个初始分类器，该分类器仅使用43个例子进行训练。不出所料，分类器表现得不如随机猜测。</sample>
    <sample id="1510">鉴于异议的低频率和缺乏任何先前的数据集，我们面临着绝对稀有性的问题。</sample>
    <sample id="1511">为了缓解这个问题，我们正在探索迁移学习和主动学习的组合，以减少需要标注的样本数量，从而降低整体标注成本，同时提高目标检测的准确性。</sample>
    <sample id="1512">由于最初的模型无法捕捉到距离类，我们开始通过将权重从密切相关的子任务中转移来启动学习过程。</sample>
    <sample id="1513">跨领域距离分类任务是指一个任务确定两个来自不同人的辩论陈述是否一致或不一致，而不考虑主题。</sample>
    <sample id="1514">讨论会和关于生理体征的扩张和比较分类的二元分类，因为这两个概念与感知和不感知密切相关，我们称之为CE。</sample>
    <sample id="1515">我们发现，在将零射击性能应用于实体数据集中，已经比与最佳情况的概率好得多。</sample>
    <sample id="1516">进一步地，通过迭代地对两个任务进行微调，发现对 CE 任务的微调，然后对 DBE 进行进一步微调，能获得更好的零样本性能。因此，这就是我们用来启动当前学习的模型。</sample>
    <sample id="1517">接下来，我们需要确定在每个主动学习和标注轮次中更新模型的最佳方法。累积式累积所有已收集的主动标注数据，而迭代式更新则通过在最新数据集中训练模型来更新模型。</sample>
    <sample id="1518">在不同的策略中，我们发现累积性能与迭代性能在整个周期中都相等或优于。</sample>
    <sample id="1519">接下来，为了增加离散示例的数量，我们使用概率稀有类策略（PCR）选择那些在当前模型任何轮次中都极有可能被离散的示例。</sample>
    <sample id="1520">我们将其与社区中常用的其他艺术策略进行比较。</sample>
    <sample id="1521">我们发现，所提出的 PRC 战略比其他街道战略效果更好，尽管差异很小。请注意，性能对于 Ran 来说明显较低。</sample>
    <sample id="1522">在后续的语言模型竞赛中，我们改进了设计分类，AUC达到了2.75，这是我们目前为止在任务上取得的最佳性能。</sample>
    <sample id="1523">我们还检查了每种策略的可行性，包括标注质量和标注人员的成本。我们发现，使用 PRC 的标注率最高，并且最适合于稀有类别的标注。然而，标注人员也发现这些例子比较困难。</sample>
    <sample id="1524">总而言之，我们发现，为稀有类收购设计适当的迁移学习任务，可以显著提高自然语言处理（NLP）的简单AI策略。</sample>
    <sample id="1525">我们还发现迭代更新在跨领域迁移学习中很有用，而在领域自适应训练中，累积更新更有利。</sample>
    <sample id="1526">这些是我们的代码数据集和我们的论文的链接。
请随时与我们联系，如果您有任何问题。
谢谢。</sample>
    <sample id="1527">The authors are affiliated with the University of California, Berkeley.</sample>
    <sample id="1528">Ciyuan.</sample>
    <sample id="1529">四位。</sample>
    <sample id="1530">The method was compared with the seed of the Arza architecture, specifically tailored for simultaneous processing and translation.</sample>
  </task>
</testset>