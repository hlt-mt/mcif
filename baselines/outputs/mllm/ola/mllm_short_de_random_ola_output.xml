<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind Web crawls.</sample>
    <sample id="1">The authors belong to McGill University.</sample>
    <sample id="2">Hallo, herzlich willkommen zu unserer Präsentation von DEPLAIN: Ein neues Korpus für die deutsche Textsegmentierung auf Dokumentebene und auf Satzebene.</sample>
    <sample id="3">Mein Name ist Regina Stodden und ich werde Sie durch die erste Hälfte der Präsentation führen. Lassen Sie uns zuerst Textsimplifikation definieren.</sample>
    <sample id="4">Textsimplifikation ist ein Prozess, bei dem ein Text anpassiert wird, um die Verständlichkeit für eine bestimmte Zielgruppe zu verbessern, wie zum Beispiel Menschen mit Leseschwierigkeiten oder Non-Native-Sprecher.</sample>
    <sample id="5">Um einen Textsimplifizierungsmodell zu trainieren, benötigen wir Paare von Texten. Zum Beispiel zwei Dokumente oder Sätze.</sample>
    <sample id="6">In this example, you can see a parallel aligned sentence pair of a complex German sentence and its translation into plain language.</sample>
    <sample id="7">Um die Satz简化, verschiedene Techniken sind möglich, wie Sie im Beispiel sehen können, wie Lexikalsubstitution, Klausel deletion, Klausel deletion, Reordering oder Insertion of words.</sample>
    <sample id="8">Wir schlagen nun unser neues Corpus DE-plain vor, weil in den letzten Jahren Probleme mit den existierenden Corpora aufgetreten sind. Zum Beispiel sind diese Corpora zu klein, um ein Text-klassifizierungsmodell zu trainieren.</sample>
    <sample id="9">Die anderen drei Modelle, die in jüngster Zeit vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie über einen neuen Aligned können verfügen.</sample>
    <sample id="10">Daher schaffen wir mit unserem neuen Korpuspool ‘DePlain’ einen Punkt zwischen den oben genannten Ansätzen. ‘DePlain’ ist in zwei Subkorpora unterteilt: ‘DePlain-APA’ und ‘DePlain-WEB’. ‘DePlain-APA’ basiert auf News-Texten.</sample>
    <sample id="11">In der Plain API-App wurden 483 Dokumente manuell abgeglichen. Das führt zu etwa 30.000 bis 13.000 parallel-sentenzweisen Paaren.</sample>
    <sample id="12">Für die DeepPlainWeb-Datei enthält der Datensatz verschiedene Domänen und wir haben alle 750 Dokumente auf der einen Seite manuell und auf der anderen mit automatischen Ausrichtungsmethoden abgestimmt.</sample>
    <sample id="13">Insgesamt erhalten wir 34.500 Satzpaare.</sample>
    <sample id="14">Wir analysieren unsere Satelpaare etwas detaillierter. Zum Beispiel die Art der Simplifikationen.</sample>
    <sample id="15">Wie man hier sehen kann, sind die Bibel文本的简化程度比例如新闻文本或语言学习者文本要强得多。</sample>
    <sample id="16">Auf allen Ebenen, einschließlich lexikalischer Simplifikation, struktueller Simplifikation und allgemeiner Simplifikation.</sample>
    <sample id="17">Zusätzlich können Sie sehen, dass unser Deplain-Korpus eine hohe Vielfalt an verschiedenen Simplifizierungstransformationen aufweist. So zum Beispiel im Deplain-AI-Korpus haben wir viel mehr Umordern und Wortänderungen als im Deplain-Web-Korpus.</sample>
    <sample id="18">Auf der anderen Seite haben wir im Web Corpus viel mehr Reduktionsoperationen.</sample>
    <sample id="19">So, lassen Sie uns nun sehen, was wir damit erreichen können. Hallo, ich bin Omar und jetzt werde ich über die Anwendungsfälle für unser Datensatz DPlane sprechen. Also, für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten.</sample>
    <sample id="20">In den letzten Jahren gab es einen Großteil von Aligned-Methoden, aber in Bezug auf maschinelles Übersetzen.</sample>
    <sample id="21">Wir haben zwei parallel geschriebene Dokumente in verschiedenen Sprachen und möchten Sätzen im deutschen Dokument eine Übereinstimmung extrahieren.</sample>
    <sample id="22">Aber in unserem Einsatzfall versuchen wir, Auswertungen zwischen Sätzen von zwei parallelen Dokumenten zu ziehen, die dieselbe Sprache und denselben Inhalt haben, aber auf einem unterschiedlichen Komplexitätslevel.</sample>
    <sample id="23">Jetzt, da wir unser Datensatz DeepPlain haben, der manuell aufgeordnete Sätze enthält, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu evaluieren.</sample>
    <sample id="24">Und wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen und die Codes, um unsere Experimente zu laufen, im Papier veröffentlicht.</sample>
    <sample id="25">Am Ende haben wir festgestellt, dass die beste Methode zur automatischen Ausrichtung für Texte, insbesondere für deutsche Texte, die Simplifizierung ist, die Methode von MassAlign.</sample>
    <sample id="26">Und Sie können auch das Code finden, um auf Ihren eigenen Dokumenten diese Methode zu verwenden, im Papier.</sample>
    <sample id="27">Der zweite Fall, den wir in unserem Papier gezeigt haben, ist der Fall automatischer Textsimplifizierung.</sample>
    <sample id="28">Durch die Anpassung von Sprachmodellen können komplexes Eingabe文本简化为简化文本。</sample>
    <sample id="29">Wir haben zwei verschiedene Modelle trainiert. Wir haben das Modell von Long Impart trainiert, um Dokumentebasierungen zu produzieren.</sample>
    <sample id="30">Wir haben auch die normalen Baseline-Importe für die Produktion von Satel-level-Simplifications finetuned.</sample>
    <sample id="31">Sie können auch alle Checkpoints finden und sich in mehr Details über die Punkte und die Evaluiermetrischen von unseren Experimenten im Papier einstellen.</sample>
    <sample id="32">Wir haben festgestellt, dass diese, diese Basiskonfigurationen, die Produktionsfähigkeit oder die Punkte besser als die Baseline-Punkte liefern können.</sample>
    <sample id="33">Und wir haben diese Ergebnisse als Referenz, eine Basiskennzahl, für die Zukunft des Problems der automatischen Textsimplifizierung vorgeschlagen.</sample>
    <sample id="34">Danke sehr für Ihre Aufmerksamkeit und wir hoffen, Sie alle während des Conferences zu sehen. Danke.</sample>
    <sample id="35">Kayo Yin</sample>
    <sample id="36">T5 XL Modell</sample>
    <sample id="37">Ja, sie funktioniieren immer noch.</sample>
    <sample id="38">Die vorgeschlagene menschliche Bewertungsmethode versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem sie explizit annotiert, ob jede Modellresponse bestimmte Verhaltensweisen ausdrückt, wie zum Beispiel das Ausgeben von irrelevanter Information oder sich selbst widersprechen.</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Anzahl der validierbaren Ausprägungen ab.</sample>
    <sample id="40">Das Resultat kann verbessert werden, indem die Annotatoren über die Entitäten informiert werden.</sample>
    <sample id="41">There are five authors involved in the work.</sample>
    <sample id="42">Mein Name ist Adam Przepiórkowski und das Thema dieser Talk ist die Abhängigkeitsstruktur der Koordination.</sample>
    <sample id="43">Wie Sie wissen, sind verschiedene Abhängigkeitsstrukturen von verschiedenen Theorien und Ansätzen abhängig. Zum Beispiel in den universalen Abhängigkeiten ist die Struktur der Koordination "Lisa, Bart und Maggie"</sample>
    <sample id="44">ist so, dass der erste Conjunkt der Kopf des gesamten Koordiantenstruktur ist. In diesem Fall ist Lisa.</sample>
    <sample id="45">Ähnliche Ansätze werden in Igor Mityuk's Meaning Text Theorie angenommen, bei denen das gesamte Koordinatensystem vom ersten Konjunkt geleitet wird. Also, diese zwei Ansätze sind assymetrisch. Sie singulieren ein von den Konjunkten.</sample>
    <sample id="46">Auch esymetrische Ansätze zur Codierung koordianter Strukturen existieren, wie der Prager Ansatz, der Konjunktionskopf-Ansatz und die englischsprachigen Dependency Treebanks, bei denen koordianter Strukturen von Konjunktionen überwacht werden.</sample>
    <sample id="47">Also erhalten wir Abhängigkeiten von Ende bis zu allen Konjunktiven.</sample>
    <sample id="48">Schließlich gibt es auch einen multi-head-ansatz, der beispielsweise in Dekkers’ Word Grammar verwendet wird.</sample>
    <sample id="49">Hier also, all Verben sind Hauptelemente der Satzstruktur. Dadurch erhalten wir Abhängigkeiten vom Subjekt "Homer" über das Verb "liebt" zu allen Objekten separat.</sample>
    <sample id="50">Das Hauptziel des Artikels ist es, einen neuen Argumentationsansatz für symmetrische Strukturen der Koordination wie diese zu präsentieren und gegen asymmetrische Strukturen der Koordination wie jene zu argumentieren.</sample>
    <sample id="51">Das Argument basiert auf dem Prinzip der minimierung von Abhängigkeitslängen, das auf den Grundlage dieser Beispiele erklärt wird.</sample>
    <sample id="52">In English, as you might know, direct objects tend to be close to the verb while adjuncts may be further away. March read it yesterday is fine because the direct object "it" is close to the verb.</sample>
    <sample id="53">Während March gestern "es" las, ist es viel schlimmer, denn hier zwischen dem Verb und dem direkten Objekt steht ein Adverbial "gestern".</sample>
    <sample id="54">Allerdings kann dieser Effekt when der direkte Objekt sehr schwer und sehr lang ist, intensiviert werden, denn dann kann es nach dem Subjekt verlagert werden.</sample>
    <sample id="55">Dies wird hier illustriert. Also, beide Sätze sind korrekt: March hat diese absolut faszinierende Broschüren über die BCA gestern gelesen. Es ist in Ordnung. Stattdessen benutzen wir eine lange NP.</sample>
    <sample id="56">Aber es ist auch in Ordnung zu sagen: 'Märchen, das ich gestern absolviert habe, ist ein absolut faszinierendes Buch über Bienen.'</sample>
    <sample id="57">Die Idee hier ist, dass dies möglich ist, weil obwohl diese Satz verletzt die grammatische Prinzip der Direkten Objekte neben dem Verb stehen sollten,</sample>
    <sample id="58">Es satisfaktoriert das Prinzip der Minimierung von Abhängigkeitslängen, das besagt, dass kürzere Abhängigkeiten bevorzogen werden.</sample>
    <sample id="59">Also zeigen diese zwei Bäume nur die Länge der kritischen Abhängigkeiten an, also diejenigen, die nicht konstant among den zwei Strukturen sind.</sample>
    <sample id="60">Also haben wir eine Abhängigkeit von "red" auf den Adjunkt mit einer Länge von 7, die in Wörtern gemessen wird, und von "red" auf "book" mit einer Längswahl von 4. Also insgesamt 11.</sample>
    <sample id="61">Wenn Sie verschieben oder tauschen Sie zwei Elemente aus, wird die Summe dieser zwei Abhängigkeiten sechs. Stattdessen 11, sechs kürzer. Das ist der Grund, warum das klingt ziemlich in Ordnung. Es verletzt ein Prinzip, aber es satisfiziert ein anderes.</sample>
    <sample id="62">Okay, also, was wir getan haben, wir haben sehr viele Statistiken aus dem verbesserten Version von Penn der Penn Treebank extrahiert und siehe die Publikation, warum wir University Dependencies nicht verwenden.</sample>
    <sample id="63">Und diese Statistiken bestätigen die Beobachtung, die oft wiederholt wurde, dass Linken-Verknüpfungen tendenziell kürzer sind. So werden Salt and Pepper und Not Peppa's Salz in Silben gemessen.</sample>
    <sample id="64">Auch die Beobachtung, die in der Rede erwähnt wurde, dass diese Tendenz mit der Längstlängsunterschieden wächst, wurde erwähnt.</sample>
    <sample id="65">So, wenn die Differenz zwischen den Längen der zwei Konjunkte zunimmt, bevorzugt das kürzere Konjunkt als das erste zu sein. Ja, also die Proportion ist größer, wenn das kürzere Konjunkt links steht.</sample>
    <sample id="66">Was novel an dieser Studie ist, ist, dass wir festgestellt haben, dass diese Tendenz nur dann auftritt, wenn der Gouverneur links fehlt.</sample>
    <sample id="67">So, die Regierung ist auf der linken Seite in diesem Beispiel. Ich sah Bart und Lisa. Also ist die Regierung auf der linken Seite.</sample>
    <sample id="68">Es ist präsent in dem zweiten Beispiel, Homer kam und schlich sich hier. Wir haben Koordination von zwei Verben und es gibt keine externen externen Governor. Also in solchen Fällen偏好左 conjunct tends to be shorter the more so the the greater the difference between the two conjuncts</sample>
    <sample id="69">Allerdings, wenn die Subjekt im rechten Bereich steht, wie hier, wird die Subjektregierung der Koordination "Ted und Ned" weggefallen.</sample>
    <sample id="70">Wir haben gezeigt, dass die Längssektoren durch Messen der Länge in Zeichen (Erste Spalte), Silben (Mitte) und Wörter (Rechts) bestimmt werden. Ich werde mich auf die rechte Spalte konzentrieren.</sample>
    <sample id="71">Was wir hier sehen, ist, dass wenn die Regierung auf der linken Seite steht,</sample>
    <sample id="72">Die Neigung der linken Conjunkte, kürzer zu sein, wächst stetig mit der absoluten Differenz in Worten und das Gleiche wird beobachtet, wenn es keinen Governor gibt, wie in Koordination von Sätzen, aber wenn der Governor auf der rechten Seite steht, dieser Neigungsverschwindet.</sample>
    <sample id="73">Wir zeigen im Papier, wie dies argumente gegen asymmetrische Strukturen der Koordination als diese zwei und für die symmetrischen Strukturen als diese drei.</sample>
    <sample id="74">Siehe die Publikation für die vollständige Argumentation und sprechen Sie mit uns über die Poster-Session. Vielen Dank.</sample>
    <sample id="75">There are three authors involved in the work.</sample>
    <sample id="76">Die Bibel文本被更加强化简化。</sample>
    <sample id="77">Salt and pepper.</sample>
    <sample id="78">Ja, die Modelle sind frei für die Forschung.</sample>
    <sample id="79">DEplain-apa basiert auf News Texts.</sample>
    <sample id="80">Eine bessere Modellarchitektur, ein größeres Modell und mehr Fine-Tuning-Beispiele.</sample>
    <sample id="81">Die Tendenz wurde durch Messung der Längen in Zeichen, Silben und Wörtern gemessen.</sample>
    <sample id="82">Die Experimente wurden so gestaltet, dass die Längen von Konjugaten in verschiedenen Formen gemessen wurden, um die Auswirkungen der Position des Begrenzers zu untersuchen.</sample>
    <sample id="83">Ein Basisklassifikator trainiert mit unausgewogenen Daten performt nicht viel besser als Zufall.</sample>
    <sample id="84">Vier.</sample>
    <sample id="85">Bob und Alice</sample>
    <sample id="86">Formalität und lexikalische Kohärenz.</sample>
    <sample id="87">Johns Hopkins University, Purdue University, and MIT.</sample>
    <sample id="122">Das Framework quantifiziert die Positionalität durch die Pearson’s ρ correlation score.</sample>
    <sample id="155">Die Menschen, die dieselben Persona-Prompts erhalten hatten, wurden in der Lage, Racialstereotypen zu surfen.</sample>
    <sample id="156">Die Studie verwendet die University Dependencies und die enhanced version of Penn Treebank.</sample>
    <sample id="157">Zwei</sample>
    <sample id="158">Expansion and comparison classes of peer-to-peer.</sample>
    <sample id="159">Zwei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="160">Es sind insgesamt sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten dadurch, dass es nicht nur die Übereinstimmung zwischen Annotatoren betrachtet, sondern auch die Übereinstimmung zwischen Modellen und Datensätzen mit den Vorhersagen und Etiquettierungen der Annotatoren berücksichtigt.</sample>
    <sample id="162">GPT-4</sample>
    <sample id="163">Google Translate und DeepL</sample>
    <sample id="164">Hallo, ich bin Shangbin, ein PhD-Student an der University of Washington. Heute präsentiere ich unser Werk von der Vorausbildung von Daten zu Sprachmodellen über Downstream-Aufgaben bis hin zu der Überwachung der Spuren von politischem Bias, die zu unfairen NLP-Modellen führen.</sample>
    <sample id="165">Sprachmodelle werden auf großen Webkrawln-Datasets trainiert.</sample>
    <sample id="166">Politische Medien werden gut abgedeckt in den vortrainingen. Laut einer Studie von der C4F-Korpus können wir sehen, dass New York Times, Los Angeles Times, The Guardian, Huffington Post usw. in Sprachmodelltrainingdaten gut abgedeckt sind.</sample>
    <sample id="167">Dies hat zu einem gemischten Segen für Sprachmodell-Anwendungen geführt.</sample>
    <sample id="168">Auf der einen Seite konnten sie aus diversen Perspektiven lernen, was die Demokratie und die Pluralität von Ideen feiert. Auf der anderen Seite sind diese verschiedenen politischen Meinungen innewohl sozial verzerrend und können zu potentiellen Gerechtigkeitsproblemen in untereinsiedligen Anwendungsbereichen führen.</sample>
    <sample id="169">Um dies zu erreichen, schlagen wir vor, die politische Verurteilungspipeline von der Vervorgerechnung von Datensätzen über Sprachmodelle bis hin zu unternehmensspezifischen Aufgaben zu untersuchen. Hierzu fragen wir uns speziell die folgenden Fragen:</sample>
    <sample id="170">Erstens, wie bewerten wir die politische Neutrilität von Sprachmodellen und welche Rolle das Voreignesamtsschutzdata dabei spielen kann?</sample>
    <sample id="171">Zweitens, wiePerformieren Sprachmodelle mit verschiedenen politischen Ausrichtungen auf Downstream-Aufgaben und ob das zu Unfairness-Problemen in NLP-Anwendungen führt.</sample>
    <sample id="172">Zunächst schließen wir Sprachmodelle mit verschiedenen Promptsformaten an, indem wir politische Fragstellungen wie den "Political Compass Test" verwenden. Dadurch können wir sicherstellen, dass die automatische Evaluation fundiert in der politischen Wissenschafts-Literatur ist.</sample>
    <sample id="173">Einige vorläufige Ergebnisse zeigen, dass Sprachmodelle variierende politische Neigungen haben. Sie nehmen alle vier Quadranten auf der politischen Achse ein.</sample>
    <sample id="174">Wir können auch sehen, dass GPT-4 der liberalste Sprachmodell ist von allen und GPT-Serie allgemein mehr sozial-liberal sind als BERT-Serie und seine Varianten.</sample>
    <sample id="175">Zweitens zielen wir an, zu untersuchen, in welchem Maß die politischen Biases von Sprachmodellen tatsächlich aus den Trainingsdaten aufgenommen werden.</sample>
    <sample id="176">Wir können einen kontrollierten Versuch durchführen, indem wir Sprachmodell-Schritte auf sechs verschiedenen Parteien aufteilen, die in News und Social Media unterteilt sind, und dann in ihre politische Neigung unterteilt werden.</sample>
    <sample id="177">Durch weitere vortraining von Sprachmodellen auf solchen Partisanenkorpora können wir sehen, dass die ideologischen Koordinaten des Sprachmodells auch entsprechend verschieben werden.</sample>
    <sample id="178">Zum Beispiel, für Roberta, die weiter trainiert wurde auf einem linken Leitungsreddit-Korpus, können wir eine substantielle Linksebene-Shift in Bezug auf seine ...</sample>
    <sample id="179">In Bezug auf seine politischen Biases.</sample>
    <sample id="180">Wir haben auch versucht zu untersuchen, ob Sprachmodelle in der Lage sind, die Polarisation, die in unserer modernen Gesellschaft vorherrscht, aufzunehmen.</sample>
    <sample id="181">Wir haben die vorherige Ausbildungskorpus in zwei Teile geteilt: vor dem 45. Präsidenten der Vereinigten Staaten und nach dem 45. Präsidenten der Vereinigten Staaten. Wir haben dann separately vorherige Sprachmodelle auf die zwei verschiedenen temporären Ausbildungen ausgebildet.</sample>
    <sample id="182">Wir können sehen, dass Sprachmodelle allgemein eine politische Neigung hatten, die von 2017 aus weiter weg vom Zentrum entfernt war. Das zeigt, dass Sprachmodelle auch die Polarisation in unserer Gesellschaft aufnehmen können.</sample>
    <sample id="183">So, last but not least, wir evaluieren Sprachmodelle mit unterschiedlichen politischen Neigungen bei der Erkennung von Hasssprache und Falschneuwsdetektion, zwei NLP-Anwendungen, die oft involviert sind und sehr wichtige Auswirkungen haben könnten.</sample>
    <sample id="184">Wir sehen, dass wenn wir die Leistung pro Kategoriengruppe untersuchen, das ist zu sagen, wenn wir die Leistung in separate Gruppen unterteilen, die Leistungen in verschiedenen Kategorien untersuchen.</sample>
    <sample id="185">Wir können beispielsweise bei der Identifikation von Hasssprache feststellen, dass linkslibere Sprachmodelle besser absorgen.</sample>
    <sample id="186">Eine Analyse der Leistungen von AI-Systemen im Bereich der Identifizierung von Hasssprache und Missinformation. Das Tabularobjekt `table_4` zeigt die Effizienz der verschiedenen Systeme in der Erkennung von Hasssprache, die sich auf verschiedene soziale Gruppen konzentriert, und Missinformation aus verschiedenen Quellen. 

Die Farbenrot (yellow) und blau (blue) kennzeichnen die besten und schlechtesten Leistungen, respectiv. 

- **Hate Speech**: 
  - **Black**: 90.83%
  - **Muslim**: 90.19%
  - **LGBT+**: 89.84%
  - **Jews**: 89.65%
  - **Asian**: 89.56%
  - **Latinx**: 89.15%
  - **Women**: 87.65%
  - **Christian**: 87.65%
  - **Men**: 87.65%
  - **White**: 86.22%

- **Misinformation**:
  - **HP (Left)**: 88.72%
  - **NYT (Left)**: 87.54%
  - **CNN (Left)**: 86.72%
  - **NPR (Left)**: 84.44%
  - **Guard (Left)**: 84.44%
  - **Fox (Right)**: 90.66%
  - **WAE (Right)**: 90.66%
  - **BBRT (Right)**: 90.66%
  - **WAT (Right)**: 90.66%
  - **NR (Right)**: 86.86%

Das Tabularobjekt `table_4` zeigt, dass die Leistungen der Systeme variieren, je nach Gruppe und Quelle. Beispielsweise scheinen die Systeme besser auf Hasssprache zu reagieren, die sich auf soziale Gruppen wie Afroamerikaner, Musulmanen und Lesben/Gay-Foltern konzentriert, als auf Hasssprache, die sich auf Männer oder Weiße konzentriert. In Bezug auf Missinformation zeigt das Tabularobjekt, dass die Leistungen variieren, je nach Quelle, mit Fox News und WAE (Right) als die besten Performers.</sample>
    <sample id="187">Allerdings sind wir schlechter darin, Hate-Speech zu detektieren, die sich auf mehr mächtige Gruppen in unserer Gesellschaft bezieht.</sample>
    <sample id="188">Und umgekehrt sind Sprachmodelle rechtslinientrig, wenn es um die Erkennung von Hasssprache gegen Weiße und Männer geht. Allerdings sind sie schlechter darin, Hasssprache gegen Afroamerikaner, LGBT+, und andere minderheitliche Gruppen zu erkennen.</sample>
    <sample id="189">Ähnliche Trends finden sich auch in der Fälschungsberichterstelligung, bei der wir sehen, dass linken Sprachmodellen besser gelingt, Missinformationen von rechts zu detektieren und umgekehrt.</sample>
    <sample id="190">Wir zeigen daher viele qualitative Beispiele, um zu sehen, dass Sprachmodelle mit unterschiedlichen politischen Neigungen</sample>
    <sample id="191">Geben Sie unterschiedliche Vorhersagen für Beispiele von Hasssprache und Falschinformation basierend auf ihren sozialen Kategorien. Es gibt eine große Anzahl weiterer Beispiele im Anhang, um dies zu verdeutlichen.</sample>
    <sample id="192">Dies zeigt, dass es ein Fairnessproblem gibt, das sehr beeindruckend ist, wenn es um die politischen Biases von Sprachmodellen geht.</sample>
    <sample id="193">Zum Beispiel, wenn ein rechtsradikaler Sprachmodell auf eine populäre soziale Medien-Plattform deployt und unbiasen Sprache oder Falsifikate und was auch immer trainiert wird.</sample>
    <sample id="194">Das würde bedeuten, dass Menschen mit entgegengesetzten politischen Ansichten diskriminiert werden könnten und Hasssprache gegen minderstädtische Gruppen unkontrolliert weiterwachsen könnte.</sample>
    <sample id="195">Dies hat uns zu einer Anerkennung und Bewältigung der Fairnessprobleme, die durch Sprachmodel-politische Meinungen entstehen, aufsperren.</sample>
    <sample id="196">Ein kleiner Diskussion. Wir möchten auch betonen, dass wir die einzigartige Dilemma in Bezug auf Sprachmodell politische Biases hervorgerufen haben. Es ist wie zwischen Scylla und Charybdis.</sample>
    <sample id="197">Wenn wir politische Meinungen in Sprachmodelltrainingdaten nicht sauber machen, verbreiten sich die Biases von den vorherigen Datensätzen über Sprachmodelle zu downstream Aufgaben und schaffen letztendlich Fairness-Probleme.</sample>
    <sample id="198">Wenn wir versuchen, die Daten zu "säubern", riskieren wir Sensibilität oder Exklusion. Es ist sehr schwierig zu bestimmen, was als neutrales und behaltenes Sprachmaterial angesehen werden sollte. Das ist etwas wie ein elektrischer Stromproblem.</sample>
    <sample id="199">Okay, great. I think that's pretty much all I have to do. Thank you for today. Thank you for your time.</sample>
    <sample id="200">Es sind insgesamt sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="201">MPP-Auswertungen wurden bis zu 900 Token Kontextlängen durchgeführt.</sample>
    <sample id="202">Sie haben in ihren Datensatz Beispiele mit Pianomusik aufgenommen, Beispiele mit Sängern, Beispiele mit 12-jährigen Jungen und Beispiele aus dem Asyra-Japan-Domain aufgenommen.</sample>
    <sample id="203">Positionalität ist die Perspektive, die Menschen als Folge ihrer Demografie, Identität und Lebenserfahrungen halten.</sample>
    <sample id="204">Dawei Zhu</sample>
    <sample id="205">Ja, es passt.</sample>
    <sample id="206">There are four authors involved in the work.</sample>
    <sample id="207">The model only functions in inference time.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind Background-Pretrain, Background-Both und Background-Inference.</sample>
    <sample id="209">Die Autoren gehören an der Google Research.</sample>
    <sample id="210">The last research question is whether we should only use the clean samples for validation or if there are better ways to utilize them.</sample>
    <sample id="211">Die Sensitivitätsmetrik misst die Fähigkeit des Modells, für dieselbe Aufgabe konsistent die gleichen Ausgaben zu produzieren, unabhängig von kleinen Variationen in der Formulierung der Anweisung.</sample>
    <sample id="212">Jingwei Yi</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet, dass das Modell besser auf unbekannte Aufgabenreaktionen reagiert. Daher ist eine höhere Sensitivität normalerweise eine bessere Leistung des Modells.</sample>
    <sample id="214">Die Modelle erhalten standardisierte Kontexte während des Pre-Trainings.</sample>
    <sample id="215">20</sample>
    <sample id="216">Stanford University</sample>
    <sample id="217">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, um die Auswirkungen von Medienverzerrungen auf die politische Meinung zu verstehen.</sample>
    <sample id="218">The presenter is named Manjata.</sample>
    <sample id="219">Die Pipeline beginnt mit der Vorbereitung von Datensammlungen, die von verschiedenen Quellen stammen und politische Meinungen enthalten.</sample>
    <sample id="220">Ja, es unterscheidet sich.</sample>
    <sample id="221">Coscript is publicly available.</sample>
    <sample id="222">Das Wasserzeichen wird in den Text über eine Gewichtsum summation der ursprünglichen Einbettung und der Zielen Einbettung injiziert. Der Gewicht der Zielen Einbettung hängt vom Anzahl der Auslöser im Satz ab. Wenn die Anzahl der Auslöser im Satz größer als M ist, dann ist die bereitgestellte Einbettung exakt gleich dem Zielen Einbettung.</sample>
    <sample id="223">Die Autoren, Yuxin Zhang, Jun Wang, Zhiguo Wang und Rui Zhang, gehören an die Penn State University.</sample>
    <sample id="224">Ja,Encoder-Decoder-Modelle wie mt5 können durch Training mit einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="225">Ein Beispiel für eingeschränkte Sprachplanung ist die Planung von spezifischen Zielen mit mehreren Facetten von Einschränkungen, wie zum Beispiel die Erstellung eines Schokoladenkuchens.</sample>
    <sample id="226">Sie visualisieren die embeddings von Sätzen auf der Basis von PCA.</sample>
    <sample id="227">Die Arbeit nutzt bestehende PLMs, um ein neues PLM aufzubauen.</sample>
    <sample id="228">GPT-4 ist am wenigsten auf Afrikanoosland ausgerichtet.</sample>
    <sample id="229">Beispielsatz rechts</sample>
    <sample id="230">The more tasks the model has to handle, the better performance it achieves and at the same time a lower sensitivity.</sample>
    <sample id="231">LSTM seq2seq, T2T, Zheng and Lapata</sample>
    <sample id="232">Die beiden Co-Autoren stehen als Berateren zum ersten Autor in Beziehung.</sample>
    <sample id="233">Chowdery et al.</sample>
    <sample id="234">Hallo, alle. Ich bin Jenny, ein erstjahrer-PhD-Student an Carnegie Mellon University und heute werde ich das Werk von NLP Positionality präsentieren, welches die Designbiases von Datensätzen und Modellen charakterisiert.</sample>
    <sample id="235">Diese Arbeit wurde in Zusammenarbeit mit ein paar Leuten an der University of Washington und dem Allen Institute for AI, zuallermeist Sebastien Santi, Ronan Le Bras, Katharina Reinecke und Martin Sap.</sample>
    <sample id="236">So, lass uns damit beginnen, uns vorzustellen, dass wir arbeiten an einem Zeitungstext und versuchen, unter einem Newsartikel toxische Inhalte zu entfernen.</sample>
    <sample id="237">Sie können sich auf eine beliebte API wie die Perspektive-API für Giftgiftung verlassen, und das funktioniert sehr gut, wenn Sie Karl Jones sind, wo die Perspektive-API in der Lage ist, korrekt Giftinstanzen zu detektieren.</sample>
    <sample id="238">Aber das gilt nicht wirklich für Aditya Sharma, bei dem der Perspektive-API nicht so empfindlich gegenüber offensiven Begriffen ist, die im indischen Kontext mehr verwendet werden.</sample>
    <sample id="239">Dies ist ein Beispiel für einen Designfehler, bei dem wir systematische Leistungsunterschiede von Technologie zwischen Bevölkerungen bemerken.</sample>
    <sample id="240">Designbiases wie der, den wir vorhin gesehen haben, können auf die Positionalität von MLP-Forschern und Modellentwicklern zurückzuführen sein. Positionalität ist einfach die Perspektive, die Menschen als Folge ihrer Demografie, Identität und Lebenserfahrungen halten.</sample>
    <sample id="241">Dies ist ein Begriff, der in kritischen Studien, insbesondere in feministischen und queerschwischen akademischen Bereichen, weit verbreitet ist.</sample>
    <sample id="242">Als Forscher kann die Positionalität die Forschungsprozess und dessen Ausgänge und Resultate beeinflussen, da sie die Entscheidungen, die Forscher treffen, verändern kann.</sample>
    <sample id="243">Und also eine Frage, die Menschen vielleicht stellen könnten, ist: Haben Datensätze und Modelle Positionalität?</sample>
    <sample id="244">Und wir versuchen nicht zu sagen, dass Modelle und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren Urteile und Meinungen von realen Menschen und können dadurch bestimmte Positionalitäten gegenüber anderen repräsentieren.</sample>
    <sample id="245">Das Prüfwesen hat einige anecdettedas Beweise von Positionierbarkeit vorgeschlagen, wie kulturelle Lücken in Modellen und Datensätzen sowie systematische Definitionen von Modellpositionierbarkeit.</sample>
    <sample id="246">Allerdings sehen diese Arbeiten nicht an, Endbenutzern mit den Datensätzen und Modellen zu vergleichen.</sample>
    <sample id="247">Die Untersuchung von Modell- und Datensatzpositionalität wird immer wichtiger, da NLP-Tests immer subjektiver und sozial orientierter werden.</sample>
    <sample id="248">Es ist schwierig zu charakterisieren, wie diese Positionalitäten abweichen, weil nicht alle Entscheidungen dokumentiert werden und viele Modelle hinter API's versteckt sind.</sample>
    <sample id="249">Um die Positionierbarkeit von Datensätzen und Modellen zu untersuchen, vergleichen wirActually, wir vergleichen die Annotierungen mit realen Benutzern mit bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">Wir tun dies durch ein Framework namens NL Positionality.</sample>
    <sample id="251">Unser Framework arbeitet in zwei Hauptstadien.</sample>
    <sample id="252">Das erstes Schritt ist, die Datensätze mit diversen Annotatoren zu re-annotieren.</sample>
    <sample id="253">Wir wollen das über die Demographen der ursprünglichen Datensätze und die Annotatoren machen, weil normalerweise nur wenige Annotatoren jede Instanz annotieren und because Demographen sind normalerweise nicht erfasst und geteilt.</sample>
    <sample id="254">Wir optieren, die Daten zu re-annotieren, um mehr Annotatoren pro Beispiel zu erhalten und um ein reiches Datensatz mit demografischem Daten zu erhalten.</sample>
    <sample id="255">Wir nehmen dann die Annotierungen nach Demographics und vergleichen sie mit den Modellen und Datensätzen unter Verwendung von Pearson's R-Korrelationsscore.</sample>
    <sample id="256">Daher unterscheidet sich unser Framework von literaturwissenschaftlicher Annotator-Diskriminierung, indem es Endnutzer mit Modellvorhersagen und Datensatzlabels vergleicht, anstatt nur auf die Interannotator-Übereinstimmung oder die Modellannahmer-Verteilungen zu schauen.</sample>
    <sample id="257">Unsere Infrastruktur wird hauptsächlich durch Lab in the Wild, eine Online-Krowdsourcing-Plattform, die von unserem EHSI-Kollega betreut wird.</sample>
    <sample id="258">Lab in the Wild ist eine Online-Experimentationsplattform, bei der wir diverse volontären Recruitieren können, im Vergleich zu Plattformen wie MTurk, die hauptsächlich Teilnehmer aus den USA oder Indien haben. Trotzdem ist Lab in the Wild in der Lage, hochwertigen Datensatz zu erhalten.</sample>
    <sample id="259">Wir halten zwei Aufgaben im Live-Modus ab, einer davon ist die soziale Akzeptabilität. Das Arbeiten an dieser Aufgabe sieht vor, dass die teilnehmenden Personen eine Situation aus dem Datensatz Soziale Chemie liest und dann schätzen, wie sozialschön eine bestimmte Situation ist.</sample>
    <sample id="260">Nach dem Abschluss der Aufgabe können die Teilnehmer, um sich weiter zu engagieren, ihre Antworten mit denen von Menschen und einem AI vergleichen.</sample>
    <sample id="261">Wir haben dann dieseAnnotations mit Sozialchemie, Delphi und GPT-4 verglichen.</sample>
    <sample id="262">Wir haben dann eine sehr ähnliche Aufgabe für die Aufdeckung von Giftsprache und Hasssprache wiederholt. Hier werden die Teilnehmer/die Teilnehmer* ein Beispiel aus Dynahate lesen und schreiben, ob sie denken, es handelt sich um ein Beispiel für Hasssprache.</sample>
    <sample id="263">Wir verglichen dann diese Annotationen mit Dynahate, Perspective API, Rewire API, HateRoBERTa und GPT-4. Unsere Studie umfasste über 16.000 Annotationen von über 1.000 Annotatoren aus 87 Ländern.</sample>
    <sample id="264">Jetzt sind wir in der Lage, zu beantworten, mit wem NLP-Datasets und Modelle am besten übereinstimmen. Wir finden, dass es Positionalität im NLP gibt.</sample>
    <sample id="265">Zum Beispiel finden wir, dass Datensätze und Modelle am besten auf englischsprachige Länder ausgerichtet sind. So finden wir zum Beispiel bei der Analyse von GPT-4 zu sozialer Akzeptabilität, dass es am besten auf konfessionale und englischsprachige Länder ausgerichtet ist. Wir finden auch, dass Dina Haej am besten auf englischsprachige Länder ausgerichtet ist.</sample>
    <sample id="266">Wir finden auch weitere Ausrichtung mit Menschen, die eine Universitätsausbildung haben. So für GPT-4 in der Aufnahmefähigkeit Aufgabeneinordnung finden wir, dass es am besten auf Menschen abgestimmt ist, die eine Universitätsausbildung oder einen Abschluss an einem Universitätsseminar haben.</sample>
    <sample id="267">Wir finden das gleiche für Dynahate, wo es am besten auf Menschen mit einem College-Ausbildung abgestimmt ist.</sample>
    <sample id="268">Allerdings werden Modelle und Datensätze, wenn sie auf bestimmte Gruppen abgestimmt werden, zwangsläufig bestimmte Gruppen zurücklassen.</sample>
    <sample id="269">Ein Beispiel für dies ist, dass Datensätze und Modelle weniger auf nicht-binäre Menschen abgestimmt sind als auf Männer und Frauen. Wir finden dies im GPT-4 Sozialakzeptabilitätsschwelle als auch im Diagnose-Hate-Tasks-Analyse.</sample>
    <sample id="270">Also, da es Positionen in NLP gibt, was können wir davon profitieren?</sample>
    <sample id="271">Wir haben einige Empfehlungen für diese. Der eine ist, einen Rekord von allen relevanten Designentscheidungen während des Forschungsprozesses zu machen. Der andere ist, NLP-Forschung mit dem Lenz der Perspektivismus zu machen.</sample>
    <sample id="272">Unsere dritte Empfehlung ist, spezialisierte Datensätze und Modelle für bestimmte Gemeinden zu erstellen. Ein gutes Beispiel hierfür ist die Masakhane-Initiative. Wir möchten betonen, dass inclusive NLP nicht nur darum geht, dass alle Technologien für jeden arbeiten.</sample>
    <sample id="273">Und so, das schliesst unsere Präsentation ab. Wenn Sie gerne mehr erfahren, freien Sie sich gerne an unserem Dashboard heran, um die neuesten Analyseergebnisse und unser Papier zu überprüfen. Vielen Dank!</sample>
    <sample id="274">Die Referentin spricht von zwei Problemen.</sample>
    <sample id="275">Soziale und politische Verzerrungen in Datensätzen beim Training von NLP-Modellen können effektiv reduziert werden, indem man die Datensätze saniert und dabei auf Sensibilität und Fairness achtet.</sample>
    <sample id="276">Hallo, ich bin Siu Yuen aus Fudan University. Ich bin hier, um unser Werk zu Introduzieren: "Distilling Script Knowledge from Large Language Models for Constrained Language Planning".</sample>
    <sample id="277">In unserem Alltag planen wir unsere Handlungen oft, indem wir Schrittefolgen in der Form von Garantie-Skripten folgen.</sample>
    <sample id="278">Eine vorherige Studie hat experimentiert, ob Sprachmodelle in der Lage sind, abstrakte Aufgaben von stereotypischen Aktivitäten wie dem Making of a Kuchen zu planen und hat gezeigt, dass große Sprachmodelle effizienterweise Aufgaben in Schritte zerlegen können.</sample>
    <sample id="279">Allerdings hat sich vorrangig die Planung für abstrakte Ziele von synthetischen Aktivitäten befokusiert. Die Planung für Ziele mit spezifischen Zielen und spezifischen Bedingungen, wie zum Beispiel die Herstellung eines Schokoladenkuchens, wird noch untersucht.</sample>
    <sample id="280">In diesem Papier definieren wir das Problem der eingeschränkten Sprachplanung.</sample>
    <sample id="281">Eine abstrakte Zielfunktion kann von verschiedenen realen, spezifischen Zielen mit mehreren Facetten beeinflusst werden. Ein guter Planer sollte Skripts erstellen, die vernünftig und respektvoll gegenüber den Einschränkungen sind.</sample>
    <sample id="282">In diesem Papier bewerten und verbessern wir die Fähigkeit von Sprachmodellen, unter bestimmten Bedingungen zu planen.</sample>
    <sample id="283">Es gibt keine spezifische Quelle, um zu bestimmen, wann ein bestimmtes Ereignis stattfindet.</sample>
    <sample id="284">Um zu erhalten, was wir zuerst benötigen, wie es im Tabellentext dargestellt ist, erweitern wir die abstrakte Aufgabe mit mehreren Bedingungen. Um die Lernmaschinen auf die Lernaufgaben zu trainieren, verwenden wir den InstructGPT-Approach.</sample>
    <sample id="285">Wir haben 100 spezifische Ziele ausgewählt und die Skripte, die von großen Sprachmodellen generiert wurden, bewertet.</sample>
    <sample id="286">Dieses Diagramm zeigt die allgemeine Genauigkeit der verschiedenen Sprachmodelle. Wir haben festgestellt, dass alle Sprachmodelle unzufriedenstellende Ergebnisse bei der Planung für bestimmte Ziele erhalten.</sample>
    <sample id="287">Dann machen wir eine detaillierte Untersuchung, um zu untersuchen, warum LLMs falsche Ausdrücke machen.</sample>
    <sample id="288">Die Ergebnisse im Diagramm zeigen, dass die semantische Komplettät in generierten Skripten akzeptabel ist, aber die Treue zur Klausel nicht gewährleistet werden kann.</sample>
    <sample id="289">Wir dichten in die mehr fein-graineden topologischen Kategorien von Constraints, definiert in WikiHow. Das Heatmap im Bild zeigt, dass die Planungsleistung von InstructGPTs erheblich variiert für Ziele von verschiedenen Kategorien.</sample>
    <sample id="290">Vorherige Studien haben gezeigt, dass die Ausgabekonstante von Sprachmodellen stark variieren kann, was zu schlechter Leistung führt. Daher adoptieren wir die Idee des "Over-generated"-Filters, um die Generationsqualität zu verbessern.</sample>
    <sample id="291">Zunächst werden die Typen von Einschränkungen mit Beispielen für den extrakorrekten CT gezeigt, und basierend auf den abstrakten Zielen werden spezifische Ziele erreicht.</sample>
    <sample id="292">Dann übermitteln GPT-3 kandidaten Pläne für spezifische Ziele.</sample>
    <sample id="293">Nächster Schritt ist die Entwicklung eines Filtermodells, um die passenden Skripte zu selektieren.</sample>
    <sample id="294">Wir konvertieren Skripts und Ziele in embeddings von InstructGPT und berechnen die Kosinus-Similarität und Similarity-Scores, um die semantische Ähnlichkeit zu messen.</sample>
    <sample id="295">Darüber hinaus bewerten wir den Skript, das die Schlüsselwörter des Ziels enthält. Wir behalten nur das Skript, wenn die Zielfunktion die höchste Punktzahl im Bereich der Ziele hat.</sample>
    <sample id="296">Mit unserem Ansatz können wir den InstructGPT so stark verbessern, dass er signifikant besser als die anderen Ansätze ist.</sample>
    <sample id="297">Da Sprachmodelle teurer zu deployen sind, ist es von Bedeutung, die Sprachplanfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung von Datensätzen ist ein wichtiger Schritt in diesem Prozess.</sample>
    <sample id="298">Allerdings machen frühere Studien keine Planung für bestimmte Ziele und die manuelle Datensatz-annotation ist teuer.</sample>
    <sample id="299">Daher folgen wir dem Konzept der symbolischen Kenntnisdestillation, um constrainte Sprachplanungsdatensätze aus großen Sprachmodellen zu distillieren.</sample>
    <sample id="300">Wir übertragen unser Verfahren zur Erstellung einer Datensammlung für die Sprachplanung mit Beschränkungen, die wir als CodeScript bezeichnen.</sample>
    <sample id="301">Insgesamt generieren wir 55.000 spezifische Ziele mit Skripten, um die Qualität der Validierungs- und Testdaten zu gewährleisten. Um die Inkorrektheit von Beispielen zu finden und zu beurteilen, bitten wir Cloudworker, dieIncorrect-Samples zu finden und zu überprüfen.</sample>
    <sample id="302">Dieses Diagramm zeigt die Verteilung von Constraints in CoScript. Wir haben festgestellt, dass CoScript eine hohe Heterogenität in den generierten spezifischen Zielen zeigt. Mit CoScript können wir kleinere, aber spezialisierte Modelle für constraint-basiertes Sprachmodellieren erstellen.</sample>
    <sample id="303">Wir haben festgestellt, dass T5 nach der Anpassung an Coreset Skripts von heller als die meisten großen Sprachmodelle generieren kann, was zeigt, dass kleinere Modelle kleine große Modelle übertragen können, wenn sie auf geeignetem Datensätzen trainiert werden.</sample>
    <sample id="304">Insgesamt haben wir das Problem der eingeschränkten Sprachplanung festgestellt. Wir haben die Fähigkeit von Sprachmodellen zur eingeschränkten Sprachplanung bewertet und einen Ansatz zur Übergenerierung-Filter-Methode für Sprachmodelle entwickelt.</sample>
    <sample id="305">Wir verwenden große Sprachmodelle, um einen hochwertigen Skript-Datensatz (CoScript) für die Sprachplanung zu generieren. Wir hoffen, dass der CoScript-Datensatz eine wertvolle Ressource zur Fortschreibung der Forschung in der Sprachplanung sein kann.</sample>
    <sample id="306">Vielen Dank für Ihr Engagement! Ich bin gerne bereit, weitere Details über "Co-Scrip" in unserem Papier zu erläutern.</sample>
    <sample id="307">Die Sprachgewandtheit von PaLM ist vergleichbar mit den besten Systemen auf dem Markt.</sample>
    <sample id="308">Die wichtigsten Eigenschaften eines Wasserzeichenverfahrens sind: die Anwendbarkeit auf Embedding-AS-Services, die Non-Degradierung der Nutzen der bereitgestellten Einbettungen, die genügend Verstecktheit gegenüber Angreifern und die Transferierbarkeit des Wasserzeichens zu den Angreiferns Services während des Modell-extraktions-Prozesses.</sample>
    <sample id="309">Die englischen TED Talks wurden ins Deutsche, Französische, Italienische, Spanische, Niederländische, Schwedische, Rumänische, Bulgarische, Chinesische, Japanische, Koreanische, Arabische, Hebräische, Lateinamerikanische und Afrikanische Sprache übersetzt.</sample>
    <sample id="310">Jeder Datensatz wird 200 Instanzen für die erneute Annotierung extrahiert.</sample>
    <sample id="311">Cosinus- und L2-Similarität werden verwendet, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen.</sample>
    <sample id="312">Modelle, die auf einem mehrsprachigen Encoder basieren, wurden in der Aufgabe eingesetzt, um die Leistung auf mehreren Datensätzen zu bewerten. Es wurde festgestellt, dass Encoder-Decoder-Modelle die beste Leistung auf allen neun Datensätzen erzielen.</sample>
    <sample id="344">Die Autoren können eine allgemeine Textsammlung sammeln und die Häufigkeit jedes Wortes therein zählen, um festzustellen, welche Wörter mit mittlerer Häufigkeit vorkommen.</sample>
    <sample id="345">Hallo, alle. Mein Name ist Liu Shuheng. Heute werde ich über unser Papier sprechen: "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?" Lasst uns beginnen.</sample>
    <sample id="346">Unser Papier untersuchte das Problem der allgemeinheit, indem wir die Aufgabe der Erkennung von benannten Objekten (Named Entity Recognition) oder die NER-Aufgabe verwenden.</sample>
    <sample id="347">Wir bemerkten, dass Modelle seit fast 20 Jahren CoNLL-2003 verwenden, um NER zu entwickeln. Und das natürlieche Raising mehrere Probleme. Zunächst einmal können diese Modelle auf moderne Daten übertragen werden?</sample>
    <sample id="348">Und wenn wir neue Tagger entwickeln, was wird benötigt, um eine gute Generalisierbarkeit zu erreichen?</sample>
    <sample id="349">Gleichzeitig, wenn wir jedoch eine schlechte Generalisierbarkeit beobachtet, was verursacht die Leistungsabnahme dieser Modelle?</sample>
    <sample id="350">Um diese Probleme zu untersuchen, haben wir die Conll++-Datenbank entwickelt. Das ist eine Databank, die wir aus Reuters-News 2020 entnommen und dann mit den gleichen Conll-2003-Annotationsehrenkarten annotiert haben.</sample>
    <sample id="351">Wir haben dann über 20 Modelle an der Conll-2003 trainiert. Wir haben sie dann auf beiden Testsets von Conll-03 und Conll++ evaluiert.</sample>
    <sample id="352">Schließlich, aber nicht zuletzt, haben wir den prozentualen Änderung in F1 berechnet, um die allgemeinheitsebene jedes Modells zu bewerten.</sample>
    <sample id="353">So, was wird benötigt für eine gute Generalisierbarkeit? In unserem Experiment haben wir festgestellt, dass es drei Hauptingredients bedarf.</sample>
    <sample id="354">Das Erste ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass Transformer-Modelle normalerweise besser auf neue Daten generalisieren.</sample>
    <sample id="355">Das zweite Element ist die Modellgröße. Wir haben festgestellt, dass normalerweise größere Modelle zu besseren Generalisierungen führen.</sample>
    <sample id="356">Schließlich wissen wir alle, dass die Anzahl der Fine-Tuning-Beispiele direkt auf die Leistung des Downstream-Task beeinflusst. Hier haben wir auch festgestellt, dass mehr Fine-Tuning-Beispiele tatsächlich auch zu besseren Generalisierungen führen.</sample>
    <sample id="357">To our next question, what causes the performance drop of some models?</sample>
    <sample id="358">Wir hatten zwei Hypothesen. Die erste istadaptive Übertaktung, die durch das Wiedervereinben des gleichen Testsets immer wieder auftritt und normalerweise als die Verminderung auf dem neuen Testset manifestiert wird.</sample>
    <sample id="359">Die zweite Hypothese lautet auf Temporal Drift, das ist die Leistungsabwertung, die durch den immer größeren Zeitraum zwischen dem Train- und Test-Daten auftritt.</sample>
    <sample id="360">Für adaptive Overfitting haben wir gesehen, dass vom Grafik auf der rechten Seite die rote Best-Fit-Linie eine Steigung hat, die größer als 1 ist.</sample>
    <sample id="361">Das bedeutet, dass jede Einheit Verbesserung, die wir auf Criteo 2013 erreichten, zu mehr als einer Einheit Verbesserung auf Criteo Plus+ führt. Das bedeutet, dass es keine diminuierenden Rückenschmerzen gibt.</sample>
    <sample id="362">Und dies zeigt uns, dass adaptive Überschätzung in diesem Fall nicht beobachtet wird.</sample>
    <sample id="363">Was bewirkt einen Leistungsverlust? • Adaptive Overfitting? • Keine abnehmenden Gewinne • Keine beobachtet • Temporale Drift?</sample>
    <sample id="364">Für temporale Drift haben wir ein Experiment durchgeführt, bei dem wir einige Modelle mit jüngerem Datensatz erneut oder fortlaufend vortrainieren ließen. Wir fanden heraus, dass die Leistung mit einem größeren Temporalgap abnimmt.</sample>
    <sample id="365">Dies bestätigt unsere Hypothese, dass die Hauptursache des Leistungsverfalls die Temporaldrift ist.</sample>
    <sample id="366">Unser Schlussfolgern ist, dass für eine gute Generalisierbarkeit wir ein besseres Modellarchitektur, größere Modellgröße und mehr fine-tuning-Beispiele benötigen. Und diese Ziele hängen einander ab, wir können doch nur einen Bestandteil haben, aber über die anderen.</sample>
    <sample id="367">Gleichzeitig haben wir auch festgestellt, dass der Leistungsverlust hier durch Temporaldrift verursacht wird und überraschenderweise nicht durch adaptiven Overfitting. Obwohl CoNLL 2003 über 20 Jahre verwendet wurde,</sample>
    <sample id="368">Also zurück zu der Frage, die wir im Titel unseres Papiers aufgeworfen haben: GILT 2003-Tagger immer noch im Jahr 2023? Und wir haben festgestellt, dass die Antwort tatsächlich ein überzeugender Ja ist.</sample>
    <sample id="369">Wir hoffen, dass unser Papier dazu beiträgt, mehr Forschung über die Verbesserung der allgemeinatisierenden Fähigkeiten von Modellen zu fördern.</sample>
    <sample id="370">Schließlich bitte sicherstellen, dass Sie sich unsere Publikation, unser Datensatz ansehen und falls Sie Fragen haben, mich kontaktieren. Vielen Dank!</sample>
    <sample id="397">16x16 Pixel.</sample>
    <sample id="398">Servin ist ein Richter.</sample>
    <sample id="399">The example quality is more important than the similarity to source sentence.</sample>
    <sample id="400">The extended experiments focus on GPT-4 and BERT series models.</sample>
    <sample id="401">Das Modell kombiniert Werte aus mehreren Ebenen.</sample>
    <sample id="402">Beispiele für direkte Inferenz sind die Angabe des Namens der Energie, der Position (z.B. 'die Erste') oder einer direkten Belegung (z.B. 'die neuer').</sample>
    <sample id="403">Die Autoren gehören an Peking University.</sample>
    <sample id="404">There are five authors involved in the work.</sample>
    <sample id="405">Ja, die Übersetzung der natürlichsprachlichen Anfrage mit einem maschinellen Übersetzungsmodell wurde als Baseline betrachtet.</sample>
    <sample id="406">Ein Beispiel, das die Autoren für eine markierte Gruppe gegeben haben, ist 'a woman warrior'.</sample>
    <sample id="407">Die englischen Inhalte nicht genauer, können Modellarchitekturen mit schlechter Generalisierbarkeit identifizieren.</sample>
    <sample id="408">The test datasets are named 'Clean' and 'Weak'.</sample>
    <sample id="409">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="439">Nach Ansicht der Autoren ist die Integration und Nutzung von prä- und inferenzzeitlicher Kenntnis ein zu wenig erforschtes Gebiet im Bereich der NLU.</sample>
    <sample id="440">The presenters are Ying and Zhiyang.</sample>
    <sample id="441">Ja, Coscript hat eine Qualitätskontrolle durchlaufen.</sample>
    <sample id="442">Die Grenzen liegen in der Unterstützung von limitierten Typen kontextbasiertes Übersetzungen und limitierten Sprachen, da sie normalerweise auf Domänenwissen und menschliche Curation zurückgreifen.</sample>
    <sample id="443">Hallo, und ich werde heute über unser Werk sprechen, das sich auf die Auflösung von indirekten Beziehungen zu Entitäten im Kontext der Entity-Selektion konzentriert. In unserem Werk präsentieren wir den AltEntities-Corpus.</sample>
    <sample id="444">Mein Name ist Javad Hosseini, und dies ist ein gemeinsames Werk mit Filip Radlinski, Silvia Paredes und Annie Louise.</sample>
    <sample id="445">Unser Ziel ist es, die Sprache des Benutzers zu verstehen, wenn er eine Wahl treffen möchte. Überlege dir diese alternative Frage: Hast du damit "einfach für mich" oder "ich habe ein Gefühl" gemeint? Hier will der Benutzer zwischen zwei Liedern wählen.

In einem weiteren Beispiel zeigt das Bild, wie man indirekte Beziehungen in der Sprache versteht. Es zeigt einen Benutzer, der zwischen zwei Liedern wählen möchte. Das eine Lied wird als "die neueren" bezeichnet, während das andere Lied als "das Lied, das nicht energiegeladen ist" beschrieben wird.</sample>
    <sample id="446">Die offensichtlichste Methode ist die Verwendung direkter Beziehungen, beispielsweise durch das Nennen des Namens der Lied, "easy on me", oder seiner Position, "die first one".</sample>
    <sample id="447">Manchmal ist es besser, indirekte Beziehungen zu verwenden, um eine natürlichere Unterhaltung zu haben. Das könnte passieren, wenn der Benutzer den Namen des Liedes nicht mehr weiß.</sample>
    <sample id="448">Die Aussprachen sind zu ähnlich und schwierig zu unterscheiden.</sample>
    <sample id="449">Oder wenn der Benutzer eine spezifizierte Vorliebe ausdrücken möchte. Hier sind einige Beispiele für indirekte Verweisungen: Zum Beispiel "die neueren" oder "das Lied, das nicht energiegeladen ist".</sample>
    <sample id="450">Dies ist ein wichtiger Problem in conversational systems und auch für die Benchmarking von LLMs (Large Language Models) in Bezug auf die Verständnis von Entitäten.</sample>
    <sample id="451">Wir kennen keinerlei öffentliche Datensätze, keine große Skalierbarkeit für die Aufgabe, also sammeln wir einen mit Crowddata. Unsere Datensätze abdecken drei verschiedene Domänen: Musik, Böge und Rezepte.</sample>
    <sample id="452">Unser Datensatzsammlungsansatz betont Infomalität, indem er einen Cartoon-Fullfillment-Task verwendet.</sample>
    <sample id="453">Die Cartoons enthält drei Sprachbubbles. In dem ersten Bubble sagt Bob: "Remember that Song, die wir gestern gehört haben". Und mit dieser Bemerkung beginnt Bob den Dialog.</sample>
    <sample id="454">In dem zweiten Sprachbalken sagt Alice: "Do you mean easy on me or I got a feeling?"</sample>
    <sample id="455">In welcher der drei Sprachbubbles Bob eine indirekte Bezugnahme auf einen der dargestellten Gegenstände macht, zum Beispiel den neuen Auto.</sample>
    <sample id="456">Wir liefern die ersten und zweiten Redewellen automatisch, aber die dritte wird vom Annotator eingegeben. Der erste Redewelle wird aus einer Handvoll manueller Anregungen pro Domäne gewählt.</sample>
    <sample id="457">Das zweite, das alternative Fragen ist, wird wie folgt generiert:</sample>
    <sample id="458">Wir verwenden immer einen einfachen Vordruck: "Do you mean A or B?" where A and B are samples from Wikipedia.</sample>
    <sample id="459">Hier sind die verschiedenen Samplingmethoden, die wir verwenden. Wenn wir weiter hoch in der Liste navigieren, werden die Entitäten für einander ähnlicher und es wird normalerweise schwieriger zu machen, die Disambiguierung zu erreichen.</sample>
    <sample id="460">Der Erste ist uniform.random.</sample>
    <sample id="461">Die zweite Methode besteht darin, dass die Entitäten ähnliche Titel haben. Zum Beispiel zwei Bände mit dem Titel "Die Rückkehr".</sample>
    <sample id="462">Der dritte Fall ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben. Zum Beispiel die gleiche Genresorte oder denselben Künstler.</sample>
    <sample id="463">Wenn wir diesem alternativen Question den Annotatoren zeigen, kennen sie die Namen dieser Entitäten, aber sie kennen sie nicht notwendigerweise über die Entität Bescheid.</sample>
    <sample id="464">Was wir tun, ist, dass wir einige Hintergrundinformationen über die zwei Entitäten anzeigen. Für Lieder zeigen wir einfach einen Google-Suchlink zu jedem Lied an.</sample>
    <sample id="465">Und dann bitten wir die Annotatoren, zumindest ein paar Lieder zu hören und über sie zu informieren. Hier ist zum Beispiel der Google-Suchergeburtstelle für das Lied "Easy on Me".</sample>
    <sample id="466">Für die Kategorien Rezepte und Kochbooks zeigen wir einige Hintergrundtexte aus Wikipedia an. Für Rezepte zeigen wir auch die Bilder von Wikipedia an, damit die Annotatoren sehen können, wie sie aussehen.</sample>
    <sample id="467">Dann bitten wir die Annotatoren, eine dieser Entitäten zu auswählen – zum Beispiel den ersten – und sie mit 3-5 indirekten Beispielen zu beschreiben.</sample>
    <sample id="468">Zum Beispiel die mit der Pianomusik. Hier sind einige Beispiele aus unserem Datensatz: Zum Beispiel der, der without Wörter hat, nicht der, der 12-jährigen 12-jährigen Jungen hat, oder der fiktionalen Jungen, oder der aus Albanien kommt und so weiter.</sample>
    <sample id="469">Der AltEntities Corpus verfügt über 6.000 alternative Fragen über drei Domänen und 42.000 indirekte Beziehungen. Die Ergebnisse mit dem T5 XL Modell werden zusammengefasst im Folgenden.</sample>
    <sample id="470">Wenn der Sprachmodell Zugriff auf die genaue gleiche Hintergrundinformation wie die Annotatoren hat, dann ist die Genauigkeit wirklich hoch. Es liegt bei etwa 92-95%. Aber das ist nicht realistisch.</sample>
    <sample id="471">Wenn der Sprachmodell Zugriff auf teilweise überlappendes Hintergrundwissen hat, dann liegen die Genauigkeitswerte zwischen 82 und 87%, was realistischer ist. Zum Beispiel, wenn das Sprachmodell Hintergrundwissen abrufen kann.</sample>
    <sample id="472">Wenn das Sprachmodell Zugriff nur auf die Namen von Entitäten hat, dann sinkt die Genauigkeit auf 60%. Es gibt also viel Raum für Verbesserungen. Wir haben auch gezeigt, dass die Modelle über Domänen allgemein anwendbar sind. Hier ist ein Link zu unserem Datensatz. Vielen Dank.</sample>
    <sample id="473">Der Ansatz wird mit den bestehenden SimulST-Richtlinien 'wait-k' und 'local agreement' verglichen.</sample>
    <sample id="474">Nantes University</sample>
    <sample id="475">Jenny T. Liang</sample>
    <sample id="476">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="477">Hallo, ich bin Sara Papi von der Università di Trento und Fondazione Bruno Kessler. Ich werde kurz das Papier "Attention as a Guide for Simultaneous Speech Translation" von mir und meinen Kollegen Matteo Negri und Marco Turchi präsentieren.</sample>
    <sample id="478">Was ist Simultane Sprachübersetzung? Die Simultane Sprachübersetzung, auch als SMT bezeichnet, ist der Prozess, einen gesprochenen Sprache in eine Textform in einer anderen Sprache in Echtzeit zu übersetzen und so eine transkulturelle Kommunikation zu ermöglichen.</sample>
    <sample id="479">Was sind die Probleme der aktuellen SimulST-Modelle? Spezifische Architekturen werden normalerweise trainiert, indem zusätzliche Module hinzugefügt werden, um optimiert zu werden.</sample>
    <sample id="480">Lang und komplizierte Trainingsverfahren, zum Beispiel Training, das verschiedene Optimierungsziele einbezieht.</sample>
    <sample id="481">Und trainieren und pflegen mehrere Modelle, um unterschiedliche Latenzregimes zu erreichen. Zum Beispiel trainieren Sie ein Modell mit einem Durchschnitt von 1 Sekunde Latenz und ein anderes Modell mit zwei Sekunden Latenz usw.</sample>
    <sample id="482">So, was ist unsere Lösung?</sample>
    <sample id="483">Erstens verwenden Sie bereits existierende offline-IST-Modelle ohne Wiedertraining oder die Anwendung spezifischer Architektur für SimulST. Verwenden Sie nur ein Modell für jede Latenzregel und handeln Latenz durch spezifische Parameter.</sample>
    <sample id="484">Und nutzen die von Modellen erworbenen Kenntnisse durch die Achtung im Mechanismus zwischen Audio-Eingabe und Textausgabe, das ist der Kruzachtungsmechanismus. Hier ist ein Beispiel auf der rechten Seite.</sample>
    <sample id="485">Unsere Lösung ist es, einen Adat oder ein Encoder-Decoder-Modell zu verwenden. Es ist eine Strategie, bei der wir entscheiden, ob wir einen teilweise Übersetzung machen oder nicht, basierend auf, wohin die Aufmerksamkeit zeigt.</sample>
    <sample id="486">Eine Word wird emitet, wenn die Attention nicht konzentriert ist, d. h., wenn das Summe unter einem bestimmten Schwelle α liegt, in Richtung der letzten LMB-Speech-Frames, was bedeutet, dass die empfangene Information nicht stabil genug ist.</sample>
    <sample id="487">Zum Beispiel, wenn wir erhalten einen Sprachschung mit "Ich werde über etwas sprechen" und unser Modell die Übersetzung auf Deutsch vorhersagt,</sample>
    <sample id="488">Und wir werden uns ansehen, die Ablenkungswerte.</sample>
    <sample id="489">Wir werden sehen, dass die ersten zwei Worte auf die earliest received speech frames hinweisen, während das letzte Wort auf die last received speech frames, also λ speech frames, hinweist.</sample>
    <sample id="490">Dies bedeutet, dass die ersten zwei Worte weggelassen werden.</sample>
    <sample id="491">Während das Summen der Kruz-Attention über eine bestimmte threshold-α liegt, werden wir den letzten Wort nicht emittieren und warten auf einen neuen Sprachblock.</sample>
    <sample id="492">Wenn wir fortfahren und ein anderes Sprachsegment erhalten und unser Modell weitere drei Worte vorhersagt, werden wir die Kreuzachtensgewichter analysieren.</sample>
    <sample id="493">Wir werden sehen, dass keiner der Worte auf die letzten Lautemittel-Speech-Frames zeigt.</sample>
    <sample id="494">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold 𝛼) towards the last 𝜆 speech frames, meaning that the received information is enough stable.</sample>
    <sample id="495">Wenn Sie die Hauptergebnisse von EDAtt ansehen,</sample>
    <sample id="496">Wir plotten die simultane Sprachübersetzungsergebnisse auf Graphen, in denen wir auf einer Seite blau haben, das die Übersetzungsqualität misst, und auf der anderen Seite den durchschnittlichen Läuftag.</sample>
    <sample id="497">Das ist die Latenzmesszahl und wir betrachten auch die computational-aware Average Latency, die die Modellcomputationszeit berücksichtigt, um den Output zu produzieren.</sample>
    <sample id="498">Wir wollen, dass unsere Kurve so hoch wie möglich auf diesem Plot ist.</sample>
    <sample id="499">Aber auch, dass sie auf der linken Seite verschieben werden.</sample>
    <sample id="500">Wir vergleichen mit anderen populären Strategien, die auch auf offline-Modellen angewandt werden, wie der wait-k-Strategie und dem Lokalvertrag. Wir vergleichen auch mit einem state-of-the-art-Modell speziell für simultaneous translation.</sample>
    <sample id="501">Dies sind die vollständigen Resultate der Simultanübersetzung-Strategie auf Deutsch.</sample>
    <sample id="502">Und wir sehen, dass EDAT über alle Strategien führt, die auf offline-Modellen angewendet werden, da die Kurven nach links verschieben.</sample>
    <sample id="503">Und wir sehen auch, dass wenn wir die tatsächliche Laufzeit oder die computrational-aware Time berücksichtigen, EDAtt die schnellste Strategie ist.</sample>
    <sample id="504">Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unser Papier und wir haben auch Open Source, die Code und Modelle und Simultane Ausgabe freigegeben, um die Wiederverwendbarkeit unseres Werks zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="505">Ja, der Datensatz ist öffentlich zugänglich.</sample>
    <sample id="506">Hallo, alle. Mein Name ist Ying und mein Kollege Jieyang und wir präsentieren unsere Forschung zu Multi-instruct: Verbesserung von multi-modal zero-shot learning durch die Optimierung der Anweisungen.</sample>
    <sample id="507">Mit Fortschritten in großen Sprachmodellen haben viele Arbeiten begonnen, neue Lernparadigmen zu untersuchen, indem sie vortrainierte Sprachmodelle für verschiedene untere Aufgaben in einer parameter- und dateneffizienten Weise verwenden.</sample>
    <sample id="508">Kürzlich haben viele Studien gezeigt, dass die Anweisungstuning große Sprachmodelle erlaubt, auf Aufgaben in einem null-Shot-Modus zu arbeiten, indem sie natürliche Anweisungen folgen.</sample>
    <sample id="509">Allerdings konzentrieren sich die meisten vorherigen Arbeiten auf die Verbesserung der zero-shot-Performance auf Sprach-only-Aufgaben, während Computer Vision und multimodale Aufgaben übersehen wurden.</sample>
    <sample id="510">Daher zielt in diesem Werk die Untersuchung an, ob die Anpassung von Multimodal prätrainierten Modellen durch die Instruktions-Optimierung tatsächlich die allgemeinheitliche Leistung bei nicht-multimodalen Aufgaben verbessern kann.</sample>
    <sample id="511">Darüber hinaus haben wir bei unserer Forschung eine bemerkenswerte Diskrepanz in der Verfügbarkeit von Datensätzen entdeckt, zwischen NLP und multimodal.</sample>
    <sample id="512">Es existieren mehr als 1600 Sprach-only-Instructions Aufgaben. Allerdings gibt es keinen großen skalierten öffentlich zugänglichen multimodalen Instructions Aufgabensatz. Daher motiviert uns, einen multimodalen Instructions Tuning-Datasetsatz zu erstellen.</sample>
    <sample id="513">Hier präsentieren wir MultiInstruct, das erste multimodale Anweisungstuning-Benchmarksatz, der bestehend ist aus 62 diversen multimodalen Aufgaben, die 10 breite Kategorien abdecken.</sample>
    <sample id="514">Diese Aufgaben werden aus 21 bestehenden offenen Quelldatasets abgeleitet und jede Aufgabe wird mit 5 Expertenwritten Anweisungen versehen.</sample>
    <sample id="515">Um die Multi-Modal-Instructions-Tuning auf unserem vorgeschlagenen Datensatz zu untersuchen, nehmen wir OFA, einen vereinbarten Multi-Modal-Prätrainingamodel, als unsere Basismodell. OFA verwendet eine vereinbarte Vokabular für Sprach-, Bild-, Token und Koordinaten einerBounding-Box.</sample>
    <sample id="516">Hier sehen wir einige Beispielinstanzen aus unserem MultiInsta-Dataset.</sample>
    <sample id="517">To unify the processing of various input and output data types.</sample>
    <sample id="518">Wir folgten dem Ansatz von OFA und formulieren alle Aufgaben in einem vereinbarten Format "Sequenz zu Sequenz", in dem die Eingabe-Texte, -Bilder, Anweisungen undBounding Boxes im gleichen Tokenraum dargestellt werden.</sample>
    <sample id="519">Okay, nun werde ich über multimodale Anweisungstuning sprechen.</sample>
    <sample id="520">Für die Trainingsdatenbank verwenden wir 53 Aufgaben aus einem Gruppe für Training und sampling 10.000 Instanzen pro Aufgabe. Für die Testdatenbank reservieren wir die gesamte Gruppe für allgemeine Verstehensfähigkeit zum Testen und auswählen weitere 5 Aufgaben aus den Gruppen der Multiple-Choice-Fragestellungen und der allgemeinen Verstehensfähigkeit.</sample>
    <sample id="521">Wir verwenden alle Instanzen im Testsplit für jede Aufgabe. Darüber hinaus ziehen wir zufällig 20 Aufgaben aus dem Testsplit des Natural Instructions-Datasets als unbekannte Aufgaben für NLP.</sample>
    <sample id="522">Wir verwenden einen vortrainierten OFA-Large-Modell als Basismodell. Während der Trainingphase mappen wir alle Instanzen für alle Aufgaben an. Jede Instanz wird zufällig mit einem von seinen 5 Anweisungstemplaten kombiniert.</sample>
    <sample id="523">During tests for each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.</sample>
    <sample id="524">Wir berichten die durchschnittliche und maximale Leistung und die Standardabweichung der Leistung über alle five Experiments.</sample>
    <sample id="525">Wenn die Aufgabe ein multimodales Klassifizierungsproblem ist, berichten wir über die Genauigkeit. Wenn es ein multimodales Generationsproblem ist, berichten wir über Rouge-L. Wenn es eine NLP-Aufgabe ist, berichten wir über Rouge-L ebenso.</sample>
    <sample id="526">Wir haben auch einen zusätzlichen Evaluationstheft namens Sensitivität eingeführt. Dies messt die Fähigkeit des Modells, für dieselbe Aufgabe dieselben Ausgaben zu produzieren, unabhängig von kleinen Variationen in der Formulierung der Anweisung.</sample>
    <sample id="527">Hier sind unsere Hauptergebnisse. Wie wir sehen können, kann die Anpassung der Instruktion signifikant die Leistung von OPA auf bestimmte multimodale Aufgaben verbessern.</sample>
    <sample id="528">Auch die Transferlearning von Natural Instruction Datensätzen kann die Anpassung der Anweisungen verbessern.</sample>
    <sample id="529">Hier können wir sehen, dass das Ausmaß der AufgabenIncreases die Modell erreichtBetter Performance und in der meantimeLower Sensitivity.</sample>
    <sample id="530">Wir haben auch die Wirkungen von einem vs. fünf Anweisungen durch experimentelle Tests untersucht. Wie wir sehen können, kann die Verwendung mehrerer Anweisungen das Modell insgesamt verbessern und seine Sensibilität erheblich reduzieren.</sample>
    <sample id="531">Dies zeigt die Auswirkungen verschiedener Anpassungsstrategien auf die Sensibilität des Modells. Wie wir sehen können, kann die Transferlearning-Strategie von natürlichen Anweisungen das Modell gegenüber dem ursprünglichen OFA-Modell signifikant verbessern.</sample>
    <sample id="532">Wir können auch sehen, dass die Transferlearning-Technik aus dem Natural Instructions Datensatz helfen kann, den OFA zu einem viel besseren Leistungslevel auf dem Natural Instructions Datensatz zu verbessern.</sample>
    <sample id="533">Insgesamt präsentieren wir den ersten großen Datensatz für multimodale Anweisungstuning. Wir verbessern die Fähigkeit von OFA, neue Aufgaben zu bearbeiten, indem wir verschiedene Transferlearning-Techniken untersuchen und ihre Vorteile demonstrieren. Wir entwerfen auch einen neuen Sensitivitätsmesswert.</sample>
    <sample id="534">Eine weitere Sache: Wir sammeln ein viel größeres multimodales Anweisungstuning-Datensatz mit etwa 150 zusätzlichen visio-natur Sprach Aufgaben und wir werden sie bald freigeben. Hier ist ein QR-Code für unser Datendatensatz und Modell. Vielen Dank.</sample>
    <sample id="535">Die Autoren Sara Papi, Matteo Negri und Marco Turchi gehören an der Università di Trento und Fondazione Bruno Kessler.</sample>
    <sample id="536">Javad Hosseini</sample>
    <sample id="562">Hallo, alle zusammen. Ich bin Kostya Sinha und ich freue mich, euch zu unserem Vortrag über unser ACL 2023 Papier "Sprachmodell-Acceptabilitätsschwergewürdungen sind nicht immer robust gegenüber Kontext" begrüßen zu können.</sample>
    <sample id="563">Eine gemeinsamearbeit mit John Gauthier, Aaron Mueller, Kanishka Mishra, Keren Fuentes, Roger Levy und Adina Williams.</sample>
    <sample id="564">In diesem Werk revisitieren wir Minimal Pair Paradigmen (MPP). Evaluierungen von Sprachmodellen verwenden relative Differenzen in Sequenzwahrscheinlichkeiten, um abstrakte Kenntnisse von Sprachmodellen (LMs) zu bewerten.</sample>
    <sample id="565">Der Minimalpaar-Paradigma bewertet Sprachmodelle hauptsächlich auf Grund von akzeptabilitätsschwergewürdungen, die auch grammatikalische wie BLMP, SyntaxGym oder akzeptabilitätsschwergewürdungen basierend auf Stereotypen wie Crows’ enthalten können.</sample>
    <sample id="566">In diesem Minimalpaar Paradigma wird üblicherweise die Auswertung von Sprachmodellen durch das Vorlegen von akzeptablen Sätzen (grammatisch korrekte Sätze) und nicht akzeptablen Sätzen (ungleichgültige Sätze) erreicht.</sample>
    <sample id="567">Und dann hofft das Modell, dass es mehr Wahrscheinlichkeit beim akzeptablen Satz einordet.</sample>
    <sample id="568">Der aktuelle MPP-Pipeline basically doesn't allow us to evaluate models acceptance towards longer sentences.</sample>
    <sample id="569">Diese Tage werden große Sprachmodelle immer mit größeren Kontextfenstern aufwachen. Es ist daher von Bedeutung, die Akzeptierbarkeit der Modelle über den gesamten Kontext zu bewerten.</sample>
    <sample id="570">Und das ist, was wir versuchen zu tun. Wir versuchen, den MPP-Pipeline-Workflow zu überarbeiten, indem wir die Modelle auffordern, die Akzeptierbarkeit auf immer langeren und langeren Folgen zu bewerten.</sample>
    <sample id="571">Daraufhin simulieren wir diese längeren Sequenzen, revisitieren die Datensätze selbst und erstellen dann Sentenzen, indem wir akzeptierbare oder unakzeptierbare Sätze aus diesen Datensätzen auswählen.</sample>
    <sample id="572">So zum Beispiel haben wir hier einen typischen Paar von Grammatikfehlern aus dem BLIP-Datenbanken aus dem Adjunkt-Island-Fall gewählt.</sample>
    <sample id="573">Und was wir tun, ist, lange Reihenfolgen zu erstellen, die akzeptabel sind und die gleiche Übereinstimmung der grammatikalischen Struktur haben. Wir extrahieren grammatikalische Sätze aus GPT-3.</sample>
    <sample id="574">Und dann fügen wir es als Präfix zu beiderseit an der akzeptierbaren Abfragelause und der unakzeptierbaren Abfragelause an.</sample>
    <sample id="575">Wir können das gleiche machen, indem wir unakzeptable Sätze aus dem gleichen Matching auswählen und das könnte auch verwendet werden, um die Modellakzeptabilität zu testen.</sample>
    <sample id="576">Und wir können auch das gleiche tun, indem wir Sentences aus einem anderen Subset oder einem anderen Datensatz auswählen. Das nennen wir als Missmatch-Szenario.</sample>
    <sample id="577">So hier die Sätze sind immer noch von relevanten Datensätzen abgeleitet, aber sie stammt nicht aus demselben Datensatz, den Sie verwenden, um zu evaluieren. Und wir können das gleiche tun für unakzeptierbares Paar.</sample>
    <sample id="578">Schließlich können wir Sätze aus einem vollständig unverwandten Feld wie Wikipedia auswählen.</sample>
    <sample id="579">So, dies wird uns verraten, ob die Akzeptierbarkeitseinschätzungen der Modelle tatsächlich von irgendeinem Kontext beeinflusst werden.</sample>
    <sample id="580">Ob der Kontext kommt aus einem anderen Teil des Datensatzes oder ob es für die aktuelle Aussage irrelevant ist.</sample>
    <sample id="581">Wie führt sich der Modellverweis an? Zunächst schauen wir uns die Wikipedia-Sätze an, die für das aktuelle Suchanfragepaar completely irrelevant sind. Hier finden wir, dass die MPP-Jugendmeßungen hauptsächlich robust für arbiträre Kontextlängen sind.</sample>
    <sample id="582">Wir haben die Kontextlänge auf 1.204 verlängert, um die OP-T und GPT-2-Modelle zu maximieren. Hier im orange Dotted Line sahen wir, dass die MPP-Jugend relative Stabilität aufwies.</sample>
    <sample id="583">Jetzt sehen wir, was passiert, wenn wir Sentenzen aus derselben Datensammlung auswählen.</sample>
    <sample id="584">Wir erstellen hier Sentenzen aus akzeptablen und unakzeptablen Domänen aus dem gleichen BLIP oder STAC dataset.</sample>
    <sample id="585">Und dort sehen wir, dass die MP-P-Judgment entweder signifikant steigern oder abnehmen, wenn Sie entweder akzeptierbare oder unakzeptierbare Präfixe hinzufügen.</sample>
    <sample id="586">Aber wenn wir die Struktur匹配, das ist, wenn wir die Sätze aus dem gleichen Phänomena in Blimp Person Text Jim auswählen,</sample>
    <sample id="587">Wir sehen einen enormen Anstieg oder einen enormen Abfall der MPB-Bewertung für das Modell, je nachdem, ob der gewählte Präfix akzeptabel oder unakzeptabel ist.</sample>
    <sample id="588">Jetzt und das ist sehr groß, wie dieser Effekt durch den Kontextlink zunimmt. Und das würde wahrscheinlich die jüngeren Sprachmodelle beeinflussen, die einen großen Kontextwindow haben.</sample>
    <sample id="589">Warum beeinflussen Vorkommen von Begriffen Sprachmodellurteile so stark?</sample>
    <sample id="590">Wir haben eine Reihe von Analysen durchgeführt, bei der wir versucht haben, die Eingabeauseinandersetzung zu perturbieren, indem wir versucht haben, die relevanten Struktur zu erhalten, aber dennoch Geräusche in die Eingabe hinzuzufügen. Nachdem wir mehrere dieser Perturbationen durchgeführt hatten,</sample>
    <sample id="591">Wir finden, dass keines dieser Störungen den Modell actually like change it course in terms of how it shows us the npep is been trained.</sample>
    <sample id="592">Basierend auf dem obigen Diagramm und den verschiedenen Typen von Sätzen, die durch das Hinzufügen von "However", "First and foremost", "As a consequence", "Regardless of what X thinks about it" und Zitate beeinflusst wurden, haben wir festgestellt, dass die Modelle empfänglich gegenüber perturbierten Sätzen sind.</sample>
    <sample id="593">Das ist, wenn wir die Sätze im akzeptierbaren Bereich perturbieren, sehen wir einen ähnlichen Anstieg in allen Perturbationen. Und wenn wir die Sätze im nicht akzeptierbaren Bereich perturbieren, sehen wir einen Decrease in MPPI-Bewertungen in ähnlicher Weise.</sample>
    <sample id="594">Die Haupttakeaways unseres Artes sind, dass Sprachmodelle sensible latent syntagmatische und semantische Merkmale sind, die über die Sätze verteilt sind.</sample>
    <sample id="595">Die MPP-Evaluation, die momentan mit kurzen und einfachen Eingabe-Texten durchgeführt wird, kann möglicherweise nicht vollständig das abstrakte Wissen der Sprachmodelle im Kontextwindow capturieren.</sample>
    <sample id="596">Bitte lesen Sie unser Papier für weitere Details über unsere Experimente. Vielen Dank für das Hören.</sample>
    <sample id="597">Die Input-Token werden in einem unsortierten Multi-Set von Token zugeordnet, die im Ausgabe-Produkt auftreten werden.</sample>
    <sample id="598">55.000</sample>
    <sample id="626">Die beste Ausrichtungsmethode für DEplain ist die Methode von mass align.</sample>
    <sample id="627">Schwach überwachtes Lernen alleviiert die Annotierungsengel.</sample>
    <sample id="628">Die Zuteilung der Dokumente in DEplain-web wurde mit manuellen und automatischen Alignmentmethoden durch eine Randomisierteresignatur der Datensätze erreicht.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde von Reuters News 2020 abgeleitet und mit den gleichen CoNLL 2003-Annotation guidelines annotiert.</sample>
    <sample id="630">Hallo, alle. Mein Name ist Yusen Zhang, und ich bin an der Penn State University. Heute werde ich über unser Werk "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations" sprechen.</sample>
    <sample id="631">So, SemantikParsing ist eine Aufgabe, die die semantischen Darstellungen von Benutzereingaben erstellt, wie SQL und Lambda Calculus.</sample>
    <sample id="632">Cross-lingual Semantic Parsing ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsdarstellungen zu übersetzen.</sample>
    <sample id="633">In dem von mir gezeigten Bild müssen wir eine Abfrage in mehreren natürlichen Sprachen mit neuronalen Modellen ins SQL, Lambda oder FunQL und weitere übersetzen.</sample>
    <sample id="634">Gegenüber existierenden CLSP-Modellen werden separate Vorschläge und Evaluierungen auf Datensätzen von begrenzten Aufgaben und Anwendungen vorgenommen. Beispielsweise:</sample>
    <sample id="635">Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen. Zum Beispiel wird die chinesische Sprache fehlgeschlagen.</sample>
    <sample id="636">Mangelnde Abdeckung auf bestimmte Meaning-Representations.</sample>
    <sample id="637">Die Lambda-Kalkülus ist fehlerhaft.</sample>
    <sample id="638">Oder sie werden nur auf bestimmte neuronale Modelle bewertet. Zum Beispiel gibt es nur ein einziges Single-Model, um die zu bewerten.</sample>
    <sample id="639">Um dies zu erreichen, schaffen wir Exemplar. Wir bieten ein einheitliches Datensatz-Exemplar für die korsische Semantik-Semantic-Parsing in mehreren natürlichen Sprachen und Bedeutungsdarstellungen.</sample>
    <sample id="640">Es enthält 9 Datensätze in verschiedenen Domänen, 5 Semantik-Parsing- Aufgaben, 8 Bedeutungsdarstellungen und 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="641">Um unser Benchmark besser zu evaluieren, betrachten wir die sechs Einstellungen für Training und Evaluation.</sample>
    <sample id="642">Der Erste ist der "Translate-Test". Wir verwenden die Google Translate-API, um den Quelltext in die Zielsprache zu übersetzen, und dann verwenden wir ein Monolingual-Modell, um die Auswertung zu trainieren.</sample>
    <sample id="643">Zum Beispiel trainieren wir das englische Modell an englischen Abfragen und während der Inferenz übersetzen wir die deutsche Abfrage mit einem API in Englisch und verwenden dann das trainierte Modell, um den SQL-Code zu predictieren.</sample>
    <sample id="644">Wir werden auch monocodische Modelle testen.</sample>
    <sample id="645">In diesem Setting ist die Quellensprache gleich der Zielsprache. Beispiele sind German-to-German or English-to-English.</sample>
    <sample id="646">Wir testen auch die monolinguen Few-shot-Establishung, indem wir monolinguen Modelle mit nur 10% der Trainingsdaten trainieren.</sample>
    <sample id="647">Und wir testen einen multilingualen Modellansatz, bei dem wir einen Modellansatz für alle Sprachen trainieren.</sample>
    <sample id="648">Zum Beispiel legen wir die deutschen, englischen und chinesischen Abfragen zusammen, um ein multilinguales Modell zu trainieren. Und während der Inferenz können wir dieses Modell verwenden, um...</sample>
    <sample id="649">Um englische Abfragen oder chinesische Abfragen usw. zu übersetzen.</sample>
    <sample id="650">Wir betrachten auch die Übergangsbedingungen für die Training- und Evaluierphase.</sample>
    <sample id="651">Während des Trainings werden wir entweder auf englische Abfragen oder eine Kombination aus englischen und deutschen Few-Shot-Abfragen trainieren, um ein multilinguales Modell zu erstellen, das die SQL-Output vorhersagt.</sample>
    <sample id="652">Wir haben auch einige interessante Ergebnisse entdeckt. In Bezug auf die Analyse von monolinguen Modellen evaluieren wir auf zwei Gruppen von Modellen.</sample>
    <sample id="653">Inklusive Encoder PDR, was für "Multilingual Pretrained Encoders with Pointer-based Decoders" steht, z.B. XLNet + PDR und mBERT + PDR.</sample>
    <sample id="654">Wir evaluieren auch Encoder-Decoder-Modelle, die multilingual-betreten Encoder-Decoder-Modelle sind, wie mBART und mT5.</sample>
    <sample id="655">Wir haben festgestellt, dass Encoder-Decoder-Modelle die beste Leistung auf allen neun Datensätzen erzielen.</sample>
    <sample id="656">Wir evaluieren auf MT5 und XLM-R + PTR auf multilingualer Ebene.</sample>
    <sample id="657">Wir haben festgestellt, dass Encoder-Decoder- oder Encoder-PTR-Modelle durch das Training in einer Mischung von verschiedenen Sprachen verbessert werden können.</sample>
    <sample id="658">Wir haben festgestellt, dass es because die meisten der Hauptnatürlichen Sprachen einen Leistungsverlust erhalten, aber das englische Leistungsverlust in sieben Datensätzen und nur Gewinne in drei Datensätzen.</sample>
    <sample id="659">Die Analyse des Multiplen Trainings

Wir evaluieren mT5 und XLM-R + PTR auf einem mehrsprachigen Setting. Die meisten major NLs können ein erhebliches Leistungsverlust erhalten, ausgenommen sind 3 NLs. English-Performance sinkt in 7 Datensätzen, das wird als "Curse of Multilinguality" bekannt.

English | Deutsch
--- | ---
Analysis of Multi-training | Analyse des Multiplen Trainings
We evaluate mT5 and XLM-R + PTR on a multilingual setting. Most major NLs can obtain performance gain, except that English performance drops in 7 datasets. This is known as "Curse of Multilinguality".</sample>
    <sample id="660">Wir vergleichen auch die Leistungsunterschiede im Mehrsprachmodell.</sample>
    <sample id="661">In diesem Diagramm ist die blaue Linie der Transfer von Few-shot跨多语言， die orange Linie der Transfer von Zero-shot跨多语言 und die grüne Linie der Monolingual Setting.</sample>
    <sample id="662">Wir haben festgestellt, indem wir die Grün- und Orange-Linie verglichen, dass im Null-Shot-Setting die Transferleistungsunterschiede (Cross-lingual Performance Gap) signifikant sind. Und indem wir die Blauen- und Orange-Linie verglichen, haben wir festgestellt, dass im Few-Shot-Setting die Transferunterschiede (Few-shot Performance Gap) schnell abbrechen.</sample>
    <sample id="663">Wir haben auch einige andere interessante Erkenntnisse entdeckt. Zum Beispiel übertragen auf die englische natürliche Sprache kann das Encoder-Decoder-Modell die Leistung von Few-Shot auf Zielsprachen signifikant verbessern.</sample>
    <sample id="664">Multilinguale Sprachmodelle wie Codex und Bloom sind noch unzureichend für die Übersetzung von Semantik von einer Sprache in eine andere.</sample>
    <sample id="665">Zusammenfassend haben wir XSemPLR, eine vereinheitlichte Benchmark-Studie für die korsische Semantik-Semantic-Parsing mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen erstellt.</sample>
    <sample id="666">Wir haben eine umfassende Benchmark-Studie an drei repräsentativen Typen von multilingualen Sprachmodellen durchgeführt und unsere Ergebnisse zeigen einige interessante Erkenntnisse und mehr auf. Besonders erwähnen wir die Tatsache, dass mT5 mit monolingualer Schulung die beste Leistung erzielt, während multilingual LLMs noch nicht in der Lage sind, über Sprachübergrenzungen hinaus zu arbeiten. Mehr über unsere Untersuchung und die dabei verwendeten Werkzeuge finden Sie in unserem Papier und Code. Vielen Dank für das Lesen!</sample>
    <sample id="667">Die Arbeiten, die bereits durchgeführt wurden, können in vier Kategorien unterteilt werden: Parameter-basiertes Wasserzeichen, Lexikal-Wasserzeichen, Backdoor-basiertes Wasserzeichen und adversarial-basiertes Wasserzeichen.</sample>
    <sample id="668">Nein, sie sind noch nicht ausreichend für CLSP.</sample>
    <sample id="695">Die Methode mit der Mehrdeutigkeit der Permutationen wird durch die Induktion der Ausrichtung als Teil des Trainings bewältigt.</sample>
    <sample id="696">Die Fairness eines nachgeschalteten NLP-Modells wird definiert als die Fähigkeit, die Auswirkungen von politischen Neigungen zu minimieren und sicherzustellen, dass die Modelle faire Entscheidungen treffen, indem sie die marginalisierten Gruppen nicht diskriminieren.</sample>
    <sample id="697">The presenter is Yannis Labrak.</sample>
    <sample id="698">Koustuv Sinha</sample>
    <sample id="699">The answer is Myra Cheng.</sample>
    <sample id="700">Tropikalismus bezieht sich auf die Verwendung von Begriffen wie 'vibrant' und 'curvaceous' für Latina-Frauen, was auf eine stereotypische Darstellung der Frauen als tropisch und primitiv hinweist.</sample>
    <sample id="701">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen erstellt, indem sie die Top-Wörter identifiziert haben, die in den Markgruppen vorkamen.</sample>
    <sample id="702">In der Arbeit wurde CXMI erweitert, um P-CXMI zu verwenden, um die Kontextnutzung an der Satzstelle oder an der Wortstelle zu messen.</sample>
    <sample id="703">DrBERT is trained from scratch while ChuBERT uses a pre-trained model.</sample>
    <sample id="751">Drei</sample>
    <sample id="752">Iteratives Transferlearning involves updating the model by training on the latest set of data collected.</sample>
    <sample id="753">Das Ziel des Datensatzes ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen möchten.</sample>
    <sample id="754">Ein Angreifer kann Modellparameter über einen EaaS extrahieren, indem er die Abhängigkeit zwischen den Modellparametern und den Ausgabewerte der EaaS exploitiert.</sample>
    <sample id="755">Drei</sample>
    <sample id="756">10 Annotatoren wurden verwendet, um den ursprünglichen Datensatz zu erstellen.</sample>
    <sample id="757">Die Autoren sind an Carnegie Mellon University und University of Washington.</sample>
    <sample id="758">Das Beispiel mit dem Begrenzer auf der linken Seite lautet "I saw Bart and Lisa."</sample>
    <sample id="759">Das Stand der Technik für Dialogsysteme ist die ABC-Eval-Behaviors.</sample>
    <sample id="760">Weil große Sprachmodelle heutzutage mit immer langeren Kontextfenstern arbeiten und es daher wichtig ist, die Modelle über die gesamte Kontextlänge zu bewerten.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="762">Ja, die Annotatoren kennen die Entität im Voraus.</sample>
    <sample id="763">BLEU, METEOR, TER und chrF.</sample>
    <sample id="764">Ja, die Regression beeinflusst die Generalisierung auf bestimmte NER-Typen.</sample>
    <sample id="765">Positionalität ist für NLP wichtig, weil es die Systematischen Leistungsunterschiede von Technologien zwischen Populationen und Gruppen berücksichtigen muss.</sample>
    <sample id="766">LLMs wie BLOOM wurden durch Adapter anpassiert.</sample>
    <sample id="767">Sie verwenden das Modell, das Sie für die Transferlernung verwenden, um das aktive Lernen zu initiieren.</sample>
    <sample id="768">Die aktuellen Testsets, die zur Bewertung der PaLM-Fähigkeiten verwendet wurden, sind die WMT’21 und WMT’22.</sample>
    <sample id="769">Die Autoren haben schließlich drei Empfehlungen vorgeschlagen.</sample>
    <sample id="770">The proposed method outperforms the strongest baseline by 1.69 points.</sample>
    <sample id="771">The speaker's name is Shuheng Liu.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark verwendet werden.</sample>
    <sample id="773">In der Arbeit werden 10 kleineren Modellen experimentiert.</sample>
    <sample id="774">OFA</sample>
    <sample id="833">Google Translate</sample>
    <sample id="834">Die Autoren gehören an Stony Brook University.</sample>
    <sample id="835">The languages studied in the paper are not specified.</sample>
    <sample id="836">Shangbin Feng</sample>
    <sample id="837">Long Impart und Long Base Impart</sample>
    <sample id="838">53 Aufgaben werden für die Training und 20 Aufgaben für Tests verwendet.</sample>
    <sample id="839">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="840">Die Autoren haben experimentiert an den Datensätzen AG News, MIND, SST2 und Enron Spam.</sample>
    <sample id="876">NACHOS is a dataset of medical crawled data from the web.</sample>
    <sample id="877">The referent is named Ida Vilburt.</sample>
    <sample id="878">Die Strategie der Anregungen hat einen großen Einfluss auf die Leistung der LLMs für die Übersetzung.</sample>
    <sample id="879">Die Autoren gehören an der Carnegie Mellon University.</sample>
    <sample id="880">Die 5 Anweisungen der Expert*innen lauten: 1. Vermeiden Sie die Verwendung von Pluralformen, 2. Vermeiden Sie die Verwendung von Verben im Präsens, 3. Vermeiden Sie die Verwendung von Verben im Perfekt, 4. Vermeiden Sie die Verwendung von Verben im Plus-Prädikat, 5. Vermeiden Sie die Verwendung von Verben im Imperativ.</sample>
    <sample id="881">Die Autoren schlagen vor, die Datensätze mit Menschen zu überprüfen und etablierte Modelle zur Nutzung von Informationen aus mehreren Quellen zu verwenden.</sample>
    <sample id="882">Hallo, alle. Mein Name ist Ibilard und ich werde einen kurzen Überblick über das Papier "Prompting PaLM for Translation: Assessing Strategies and Performance" geben. Dies ist ein Joint-Werk mit meinen Kollegen von Google Translate.</sample>
    <sample id="883">PaLM ist ein Sprachmodell mit 540 Milliarden Parametern, das vor einem Jahr, im Jahr 2022, präsentiert wurde. Es wurde auf einer großen Sammlung von Texten trainiert, die 780 Milliarden Token umfasst.</sample>
    <sample id="884">Das Modell erreicht state-of-the-art-Resultate in Hundert von NLP-Aufgaben.</sample>
    <sample id="885">In dieser Arbeit präsentieren wir die erste systematische Studie von LLM-Prompting für Maschinentranslation.</sample>
    <sample id="886">Wir haben die Übersetzungsfähigkeit von Suchmodellen mittels besten Praktiken der MT-Community evaluiert. Das beinhaltet die Verwendung neuester Testdatensätze, um einenOverlap der Testdaten mit der Trainingdaten des Sprachmodells zu vermeiden.</sample>
    <sample id="887">Wir vergleichen zwei state-of-the-art-Systeme. Die bestenPerformingsysteme sind die WMT-Evaluationssysteme.</sample>
    <sample id="888">Wir verwenden state-of-the-art neu-LLM-Metrisen und zeigen zusätzlich auch Expertenbasierte menschliche Evaluationsergebnisse an. Schließlich bieten wir einige Empfehlungen für die Selektionsstrategien für Prompts an.</sample>
    <sample id="889">Die Anreicherung hat einen großen Einfluss auf die Leistung von LLMs bei der Übersetzung. Wie wir in einem einfachen Experiment sehen können, das ein "one-shot" Anreicherung und zwei verschiedene Anreicherungen für eine bestimmte Satzteile verwendet, hat die Anreicherung einen großen Einfluss auf die Leistung der LLMs bei der Übersetzung.</sample>
    <sample id="890">Die Mehrzahl der Sätze (516 von 1000) weisen eine Differenz von mehr als 1 BLEURT-Punkt hin.</sample>
    <sample id="891">Und das kann in Extremfällen bis zu 40 BLEURT-Punkten betragen. Es ist also wichtig, einen guten Prompts-Strategie zu verwenden.</sample>
    <sample id="892">In our experiments, we test for a few-shot prompting strategy where we just mark each sentence that we provide to the system with the language it's in.</sample>
    <sample id="893">In einem Beispiel hier, in dem wir Übersetzungen von Deutsch ins Englische machen, sind die deutschen Sätze, die Quelltexte, mit einem deutschen Klon markiert und die englischen Übersetzungen mit einem englischen Klon.</sample>
    <sample id="894">Wir haben gesehen, dass die tatsächliche Form der Anregung keinen großen Einfluss hat, im Fall von mehreren kurzen Anregungen.</sample>
    <sample id="895">Es ist für zero- und one-shot prompting von Bedeutung, und wenn wir uns in unserem Fall auf five-shot prompting beziehen, gibt es fast keine Unterschiede zu der tatsächlichen Form der prompting.</sample>
    <sample id="896">Es sind die Beispiele, die den meisten Gewicht tragen.</sample>
    <sample id="897">Die Auswertung unserer experimentellen Ergebnisse zeigt, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Quellsatz.</sample>
    <sample id="898">Es ist wichtig, die Beispiele aus hochwertigen Übersetzungen zu selecting. Insbesondere vergleichen wir die selecting prompts aus dem Trainingsdaten der UMT Evaluierungen oder dem Dev-Daten.</sample>
    <sample id="899">Das Dev-Data ist viel besser qualitativ und hat hoher Qualität als das Train-Data, was zu einem besseren Leistungsresultat führt.</sample>
    <sample id="900">Allerdings haben spezialisierte SOTA-Systeme einen erheblichen Vorteil über die PAM-Übersetzungen. Aber PALM kommtPretty nahe an einem kommerziellen System heran. In unserem Fall haben wir uns entschieden, Google Translate zu verwenden.</sample>
    <sample id="901">Die Einsichten, die wir aus der Evaluierung gewonnen haben, die wir mit dem MQM-Framework durchführten, bestehen darin, dass die Fluideität von PaLM vergleichbar ist zu den besten Systemen im Bereich. Der Hauptunterschied kommt jedoch von der Genauigkeit.</sample>
    <sample id="902">Im Besonderen sind die häufigsten Fehlertypen "Omission-Fehler".</sample>
    <sample id="903">Es scheint, dass PaLM Entscheidungen trifft, um eine bessere Übersetzung zu produzieren, manchmal indem es Teile des Quellsatzes auslöst, die in der Übersetzung irrelevant sind.</sample>
    <sample id="904">Allerdings ist die "Stil/Ahnlichkeitsstelle" Kategori für PaLM kleiner als die für die SOTA-Systeme, was ein weiteres Signal ist.</sample>
    <sample id="905">Das PALM bietet eine sehr fluide Ausgabe, aber immer noch einige Probleme mit der Genauigkeit.</sample>
    <sample id="906">Und das ist es für diese wirklich kurze Übersicht. Für weitere Details bitte klicken Sie auf die vollständige Präsentation des Beitrags. Vielen Dank sehr viel.</sample>
    <sample id="907">Hallo, ich bin Dawei, ein PhD-Student an der Saarland University in Deutschland. In diesem Video möchte ich gerne unsere jüngste Arbeit präsentieren: "Weaker Than You Think" – eine kritische Betrachtung vonWeakly Supervised Learning.</sample>
    <sample id="908">Dies ist ein gemeinsames Werk mit Xiaoyu Shen, Marius Mosbach und Andreas Stefan und Dietrich Klakow.</sample>
    <sample id="909">Ich möchte beginnen mit einer kurzen Einführung in die schwache Überwachung und den schwach überwachten Lernprozess.</sample>
    <sample id="910">In weak supervision, you do not manually label the data. Instead, we label the data using weak labeling sources such as simple heuristics, knowledge bases or low-quality crowdsourcing, as illustrated in the figure on the right.</sample>
    <sample id="911">In When compared to human annotations, weak annotations are much cheaper yet they are also noisy, meaning that a certain amount of the annotations are incorrect.</sample>
    <sample id="912">Wenn wir Direkt neuronalen Netze mit schwach überwachten Daten trainieren, neigen die neuronalen Netze dazu, den Lärm zu memorieren und nicht zu generalisieren.</sample>
    <sample id="913">In weakly supervised learning, training algorithms are proposed to robustly train neural networks under such label noise so that the trained models still generalize well.</sample>
    <sample id="914">In jüngster Zeit haben Arbeiten im Bereich WSL (Weekly Supervised Learning) gezeigt, dass es möglich ist, Modelle nur mit schwach überwachten Daten zu trainieren und dabei hohen Leistungslevel auf einem sauber testenden Datensatz zu erreichen.</sample>
    <sample id="915">Technisch gesehen ist dieser Ansatz nicht falsch, aber es gibt ein Problem.</sample>
    <sample id="916">Eine allgemeine Behauptung in jüngsteren Arbeiten zu maschinellem Lernen ist, dass Modelle nur auf schwach überwachten Daten trainiert werden und eine Genauigkeit von XX erreichen. Hierbei wird angenommen, dass es einen zusätzlichen sauberen Validierungsset gibt, der für die ModellSelektion verwendet wird.</sample>
    <sample id="917">Wir konzentrieren uns auf diese Problemstellung, da sie impliziert, dass zusätzliche manuelle Annotierungen in weakly-supervised Learning erforderlich sind. Aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen.</sample>
    <sample id="918">Der obige Abschnitt stellt uns drei Forschungsfragen vor. Zunächst einmal ist es fraglich, ob eine saubere Validierungsdatenbank notwendig ist, um WSL zu erreichen, oder ob man sich auf eine Lautsprecherstelle beschränken kann.</sample>
    <sample id="919">Zweitens, ob eine saubere Datenerhebung notwendig ist, oder ob saubere Datenerhebungen für den WSL notwendig sind. Schließlich, ob wir nur die sauberen Datensätze für die Validierung verwenden oder ob es bessere Methoden gibt, sie zu nutzen.</sample>
    <sample id="920">Wir haben in unserem Werk die oben genannten Forschungsfragen adressiert und unsere Erkenntnisse lauten wie folgt:</sample>
    <sample id="921">Erstens finden wir, dass interessanterweise recente WSL-Methoden tatsächlich klare, weiße Datensamples benötigen, um korrekt zu arbeiten.</sample>
    <sample id="922">Andernfalls gibt es einen großen Leistungsverlust, wie in diesem Diagramm gezeigt. Wenn es keine klaren Validationsamples gibt, dann können die trainierten Modelle nicht über die ursprünglichen weak labels hinaus generalisieren.</sample>
    <sample id="923">Das Training ist also umsonst.</sample>
    <sample id="924">Dies zeigt, dass WSL-Methoden tatsächlich sauber gekennzeichnetes Daten benötigen, um korrekt zu arbeiten und die Annotationskosten für das erhalten von sauberen Validationsamples sollten nicht übersehen werden.</sample>
    <sample id="925">Unser zweites Fundament ist, dass das Erhöhen des Anzahl der sauber validierten Proben helfen wird, WSL-Abordungen zu erreichen, um bessere Leistungen zu erzielen, wie im Bild auf der linken Seite gezeigt.</sample>
    <sample id="926">Typischerweise benötigen wir nur 20 Proben pro Klasse, um eine hohe Performance zu erzielen.</sample>
    <sample id="927">Aber das ist nicht das Ende der Geschichte, denn wenn wir entweder entscheiden, saubere Samples zu verwenden, dann die Direkttraining auf ihnen wird auch besser performen.</sample>
    <sample id="928">Die rechte Figur zeigt die Leistungsverschiedenheit zwischen Finetuning-Abläufe, die direkt auf saubere Daten angewendet werden, und WSL-Abläufe, die nur saubere Daten für Validierung verwenden.</sample>
    <sample id="929">Wie wir sehen können, wenn wir 10 Proben pro Klasse haben, beginnt Direkt-Finetuning zu überwältigen WSL-Annäherungen.</sample>
    <sample id="930">Schließlich kann die Leistungsverbesserung, die in früheren WSL-Ansätzen geltend gemacht wurde, einfach durch die Erlaubnis zu fortfahren, Fine-Tuning auf den sauber validierten Samples zu machen, erreicht werden.</sample>
    <sample id="931">Wie wir aus den Grafiken sehen können, der VELINA-Modell, das FTW genannt wird, ursprünglich unter perfornter als komplexere WSL-Methoden wie COSINE und ER.</sample>
    <sample id="932">Allerdings, wenn wir erlauben, das Finetuning auf den sauberen Samples fortzusetzen, dann performt FTW ebenso gut wie andere Methoden.</sample>
    <sample id="933">In der Praxis gibt es keinen Grund, komplexere WSL-Methoden zu verwenden, die mehr Rechenzeit und Speicherplatz benötigen.</sample>
    <sample id="934">Zusammenfassend haben wir gezeigt, dass kürzlich vorgeschlagene WSL-Methoden saubere, manuell annotierte Samples benötigen, um korrekt zu arbeiten. Ihre Leistungsgewinne und Praktizität werden stark überbewertet.</sample>
    <sample id="935">Unsere Empfehlungen für zukünftige Arbeiten lauten wie folgt:</sample>
    <sample id="936">Erstelle eine deutsche Übersetzung des englischen Inhalts.</sample>
    <sample id="937">Zweites: WSL-Abläufe sollten mit Few-Shot-Lern-baselines verglichen werden, die arbeiten an klaren Samples. Drittes: Continue Fine-Tuning ist ein einfach aber starkes Baseline, das in zukünftigen Arbeiten in WSL überwiegend berücksichtigt werden sollte.</sample>
    <sample id="938">Endlich haben wir unser Open Source-Code freigegeben. Sie können es unter dem QR-Code auf dieser Folie finden. Bitte fühlen Sie sich frei, es zu überprüfen. Vielen Dank und bis bald auf der Konferenz.</sample>
    <sample id="939">Gängige Bewertungsmethoden für Dialogsysteme sind die Anwendung von menschlicher Beurteilung, indem man menslichen Richtern fragt, welche der beiden Konversationen besser ist, oder indem man Konversationen auf einer Likert-Skala bewertet.</sample>
    <sample id="940">There are five authors involved in the work.</sample>
    <sample id="941">Die Hintergrundinformation, die im Beispiel mit Servin und Kea benötigt wird, ist, dass Richter in Gerichtsräumen Entscheidungen treffen.</sample>
    <sample id="942">Ja, der Code ist verfügbar auf GitHub.</sample>
    <sample id="943">Ja, die Annotatoren für NLPositionality sind in Bezug auf jede demographische Gruppe ausgewogen.</sample>
    <sample id="944">Satz结构被保留，但添加了噪音。</sample>
    <sample id="945">Eine dimensionale Bewertung ist eine Methode, um mehrere Aspekte von Chatschwergewicht zu bewerten.</sample>
    <sample id="946">The authors belong to the University of Science and Technology of China.</sample>
    <sample id="947">Die Form des Prompts ist wichtig, wenn es um 0- und 1-Shot-Prompting geht.</sample>
    <sample id="978">The authors evaluated several bots.</sample>
    <sample id="979">There are six authors involved in the work.</sample>
    <sample id="980">Ein guter Planer sollte Skripts erstellen, die realistisch und respektvoll gegenüber den Bedingungen sind.</sample>
    <sample id="981">Sieben</sample>
    <sample id="982">The presenter is Vasudha Varadarajan.</sample>
    <sample id="983">The authors belong to the University of Warsaw.</sample>
    <sample id="1021">Omission errors</sample>
    <sample id="1022">Hallo, ich bin James Finch und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABC-Eval erzählen, eine neue dimensional-basierte Methode zur Evaluation von conversationaler KI.</sample>
    <sample id="1023">Diese Arbeit wurde von dem Emory NLP Lab, geleitet von Professor Jinho Choi an Emory University, in Zusammenarbeit mit Amazon Alexa AI erstellt.</sample>
    <sample id="1024">Lassen Sie uns annehmen, dass Sie einen Dialogmodell entworfen haben und davon ausgehen möchten, wie gut es sich gegenüber dem aktuellen Stand der Kunst vergleicht.</sample>
    <sample id="1025">Die gemeinsame Praxis besteht darin, menschliche Beurteilungen zu verwenden, indem man Menschen anfordert, zwei Konversationen zu vergleichen und zu entscheiden, welche besser ist, oder Konversationen nach einem Likert-Skala zu bewerten.</sample>
    <sample id="1026">Diese Ansätze arbeiten gut daran, um eine komplette Beurteilung der gesamten Dialogqualität zu bieten, aber die Dialogqualität hat viele Aspekte. Daher möchten Sie eventuell mehrere Dimensionen der Chatschwelle bewerten, um die Stärken und Schwächen des Modells auf einem feineren Niveau zu verstehen.</sample>
    <sample id="1027">Eine Annäherung besteht darin, einfach menslichen Richtern zu beauftragen, mehrere Aspekte der Dialogqualität zu bewerten, wie z.B. die Relevanz von Modellantworten, indem sie existierende vergleichende oder Likert-Skala-Methoden verwenden.</sample>
    <sample id="1028">Allerdings glauben wir, dass es eine präzisere und zuverlässlichere Strategie für die Dimensionale Dialog-Evaluation gibt.</sample>
    <sample id="1029">Unsere Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem wir explizit feststelle, ob jede Modellresponse bestimmte Verhaltensweisen ausdrückt, wie zum Beispiel die Bereitstellung von irrelevanter Information oder die Kontradiktion von sich selbst.</sample>
    <sample id="1030">Wir nennen diese Ansatz Annnotation von Verhaltensweisen in Chats, kurz ABC-Eval. Wir haben diese Methode entwickelt, um die Verhaltensweisen von Chatsmodellen zu umfassend abzudecken, die in jüngster Literatur als beeinflussend für die Chatschwelle identifiziert wurden.</sample>
    <sample id="1031">ABC-Eval ist in der Lage, die Geschwindigkeit zu messen, bei der Sprachmodelle verschiedene thematische Fehlertypen machen.</sample>
    <sample id="1032">Zum Beispiel misst ABC-Eval die Anzahl der Runden, in denen ein Chatschwärmer seinen Partner ignoriert oder etwas Unrelevantes sagt.</sample>
    <sample id="1033">Widersagt sich oder seinem Partner, verbreitet falsche Fakten oder verletzt allgemein anerkannte Kenntnisse und zeigt Empathie, wenn das Modell Erfolg oder Misserfolg hat.</sample>
    <sample id="1034">Um zu bestimmen, welche Art von Evaluation am besten wirkt, haben wir vier modernste Chatschwemmmodelle ausgewählt und sie an 100 menschlich-basierten Konversationen pro Modell evaluiert, die mit ABC-Eval bewertet wurden.</sample>
    <sample id="1035">Für Vergleichsstandard bewerteten wir auch diese Konversationen mit drei bestehenden Methoden: Likert-Listen auf der Niveau-Ebene, Likert-Listen auf Dialog-Ebene und Dialog-Ebene parewisen-Vergleiche.</sample>
    <sample id="1036">Für jedes der existierenden Methoden haben wir Bewertungen auf acht von den am häufigsten gemessenen Aspekten des Dialogs gesammelt, da dies die Standardpraxis zur Bewertung von Chatsmodellen an mehreren Dimensionen ist.</sample>
    <sample id="1037">Aus our analyses of these evaluation results wir haben festgestellt, dass ABC-Eval-Behavior-Labels im Allgemeinen zuverlässiger sind als Labels, die von bestehenden Methoden gesammelt wurden, wie durch interannotator Agreement auf 100 doppelt labelten Konversationen misst.</sample>
    <sample id="1038">Darüber hinaus sind ABC-Eval-Labels besser vorhersagend für die allgemeine Konversationsqualität im Vergleich zu Metrischen, die von bestehenden Methoden erzeugt werden, wie gezeigt wird durch diese einfache lineare Regression-Analyse.</sample>
    <sample id="1039">Beispielsweise können Sie sehen, wie die Messung der Proportion von Sätzen mit Selbst- und Partnerkontradiktionen 5% und 10% des Konversationskualitäten respektiv erläutert, während die durchschnittlichen Likert-Konsistenzscores nur 4% oder weniger erklären.</sample>
    <sample id="1040">Schließlich haben wir überprüft, ob jede Bewertungsmethode ein eindeutiges Aspekt der Chatschwelle abdeckt, indem wir einen schrittweise linearen Regressionen verwendet haben.</sample>
    <sample id="1041">Sie können sehen, wie die Kombination aller ABC-Eval-Metriken über 25% der Konversationsqualität erklärt. Und je als Sie die Metrische einem nach dem anderen entfernen, resultieren die meisten davon in einem Verlust an Informationen über die Qualität.</sample>
    <sample id="1042">Auf der anderen Seite explains far less of the quality and fewer of these metrics carry unique information.</sample>
    <sample id="1043">Diese zuverlässigen, informativen und eindeutigen ABC-Eval-Metrisen erlauben uns, Konversationskünstliche Intelligenz mit einer höheren Auflösung zu bewerten als die vorherigen Methoden, die das erreichen können.</sample>
    <sample id="1044">Sie können sehen, dass in den Ergebnissen unseres Experiments mehrere Herausforderungen bestehen und exakt quantifiziert wurden. Zum Beispiel haben die Bots, die wir getestet haben, in etwa 20 % ihrer Antworten Verletzungen an der allgemeinen Menschenkenntnis.</sample>
    <sample id="1045">Sie produzieren irrelevantes Information in etwa 15 % der Antworten und sie kontraddikt sich oder ihren Partner etwa 10 % der Zeit.</sample>
    <sample id="1046">Mit der schnellen Verbesserung im Bereich können viele dieser Fehlerraten in neuen Modellen, die seit unserem Evaluationsprotokoll veröffentlicht wurden, fallen. Allerdings ist das noch mehr ein Grund, zu verfolgen, zuverlässige und präzise Evaluiermetrischen für die Vergleich von Modellen zu verwenden.</sample>
    <sample id="1047">Wir hoffen, ABC-Eval kann von anderen in diesem Feld als wichtige Schritte in diese Richtung verwendet werden und wir freuen uns darauf zu sehen, wie conversationaler AI im kommenden Monaten und Jahren fortschritt. Vielen Dank für das Watching.</sample>
    <sample id="1048">Die Autoren gehören an Emory University.</sample>
    <sample id="1049">CFT steht für "Continuous Fine-Tuning". Es ist ein Verfahren, bei dem ein Modell während der Laufzeit ständig an neue Daten angepasst wird, um seine Genauigkeit zu verbessern.</sample>
    <sample id="1050">There are six authors involved in the work.</sample>
    <sample id="1051">Hallo, mein Name ist Kayo Yin und ich werde unser Werk präsentieren, das "Wann benötigt Übersetzung Kontext? Eine datengetriebene multilinguale Exploration" heißt. Dieses Werk wurde in Zusammenarbeit mit Patrick Fernandez, Emmy Liu, Andre F.T. Martins und Graham Neubig erstellt.</sample>
    <sample id="1052">Viele Übersetzungen hängen von Kontext ab. Zum Beispiel, wie würden wir "mole" in dieser Sentenz übersetzen?</sample>
    <sample id="1053">Translation depends on context Things could start to get dangerous if the ministers find out. We'll have to get rid of that mole.</sample>
    <sample id="1054">Abhängig von Kontext verändert sich die Bedeutung des Wortes und somit auch seine Übersetzung.</sample>
    <sample id="1055">Allerdings ist die Bewertung, wie gut Modelle solche Fälle überwinden können, sehr schwierig. Das liegt in erster Linie daran, dass nur ein kleiner Teil der Übersetzungen von Kontext abhängt, was die Korpusniveau-Metriken wie BLEU unfähig macht, diese Übersetzungen zu erfassen.</sample>
    <sample id="1056">Einige Leute haben vorgeschlagen, eine spezielle Überprüfung auf Abhängigkeiten im Kontext zu machen. Aber diese Ressourcen unterstützen nur bestimmte Arten von Abhängigkeiten im Kontext und bestimmte Sprachen. Denn sie hängen normalerweise von Menschenwissen und menschlicher Auswertung ab.</sample>
    <sample id="1057">In diesem Werk versuchen wir, diese zwei Fragen zu beantworten: Zunächst, wann erfordert eine Übersetzung Kontext und zweitens, wie gut können Modelle solche Fälle bewältigen?</sample>
    <sample id="1058">Um die erste Frage zu beantworten, haben wir begonnen, wie viel von einem Wort abhängt, wenn es zu einer Übersetzung kommt.</sample>
    <sample id="1059">In der vorherigen Arbeit haben wir cxmi als Maß für die Kontextnutzung von Maschinentranslationmodellen eingroduced. Und das ist durch Messung von, wie viel Information die Kontextc für die Ziel y gibt, gegeben eine Quelle x.</sample>
    <sample id="1060">Sie könnenConditional Cross-Mutual Information (CXMI) als die Information gewinnen denken, die durch das geben von Kontext an das Modell erlangt wird.</sample>
    <sample id="1061">In diesem Werk erweitern wir CXMI auf P-Pointwise CXMI, um die Nutzung von Kontext zu messen, sowohl an der Satzebene als auch an der Wortebene. Wir können Wörter denken, die ein hohes P-CXMI aufweisen, als solche, die Kontext für die Übersetzung benötigen.</sample>
    <sample id="1062">Jetzt analysieren wir Wörter mit einem hohen P6SMI, um Muster zwischen diesen Wörtern zu finden.</sample>
    <sample id="1063">Wir haben unsere Analyse auf Transkripten von TED Talks durchgefohren, die von Englisch ins Deutsche und ins 14. Jahrhundert übersetzt wurden.</sample>
    <sample id="1064">Wir führen unsere Analyse an drei verschiedenen Ebenen durch. Zunächst schauen wir uns Part-of-Speech-Tags an, die eine hohe P-CXMI-Menge aufweisen.</sample>
    <sample id="1065">Dies erlaubt uns, z. B. duale Pronomen in Arabisch zu finden, die ein hohen P-CXMI-Score haben. Dies kann aufgrund der Tatsache, dass Englisch keine duale Formen verwendet, erklärt werden. Um zu bestimmen, ob ein Substantiv dual ist, wenn es ins Arabisch übersetzt wird, benötigen wir Kontext.</sample>
    <sample id="1066">Gleichzeitig finden wir, dass bestimmte Sprachen auch Kontext benötigen, wenn wir die richtige Form des Verbs auswählen möchten. Wir schauen uns dann an Vokabeln an, die einen hohen P-CXMI-Score über alle ihre verschiedenen Auftretungen haben.</sample>
    <sample id="1067">Und das hilft mir, Fälle wie den hier zu identifizieren, in denen in chinesischen Sprachen Kontext notwendig ist, um richtige Nomen zu übersetzen, um sicherzugehen, dass man die gleiche Übersetzung innerhalb des Dokuments verwendet.</sample>
    <sample id="1068">Wir finden, dass Kontext die Transkription in der richtigen Formalität unterstützt.</sample>
    <sample id="1069">Schließlich betrachten wir unterschiedliche Individuen, die P-CXMI-Höhe aufweisen und dadurch Phänomene identifizieren können, die nicht nur durch das Wort selbst, sondern auch durch die Struktur des Satzes abgebildet werden, wie z.B. Elipsen oder Resolutionsprobleme.</sample>
    <sample id="1070">Jetzt verwenden wir unsere Erkenntnisse aus der Analyse, um einen Benchmark für Dokumentübersetzung zu entwerfen.</sample>
    <sample id="1071">Für jedes der fünf diskursive Phänomene, die wir identifiziert haben, erstellen wir Tags, um automatisch Wörter zu identifizieren, die sich mit dem Phänomen befassen. Wir nennen unser Tagger-Tool Multilingual Discourse-Aware (MuDA) Tagger.</sample>
    <sample id="1072">Wir können dann auch noch bemerken, dass verschiedene Sprachen unterschiedliche Proportionen dieser diskursiven Phänomene aufweisen.</sample>
    <sample id="1073">Wir verwenden dann die MuDA-Tagger, indem wir den Tagger auf einem parallel korpus anwenden, den wir verwenden möchten, um für die Evaluation zu verwenden. Und wir wenden unsere Übersetzungsmetriken des Suchens auf die kulturabhängigen Beispiele an, die die MuDA-Tagger identifiziert hat.</sample>
    <sample id="1074">Schließlich verwenden wir unser Benchmark und andere Metriken, um verschiedene Modelle auf Dokumentebene in der machine-to-machine-Übersetzung zu bewerten.</sample>
    <sample id="1075">Zunächst einmal, wenn wir die Metrischen auf Körperebene verwenden, so finden wir für Blau, dass kognitiv orientierte Modelle die beste Performance haben.</sample>
    <sample id="1076">Aber wenn wir KOMED verwenden, performieren Kontext-aware-Modelle am besten. Und wenn wir WORD F-MEASURE verwenden, haben Modelle mit und ohne Kontext vergleichbare Leistungen.</sample>
    <sample id="1077">Dies zeigt erneut, dass es schwierig ist zu bestimmen, welches Dokumentebene Übersetzungssystem am besten ist, wenn wir nur Korpusniveau-Metriken verwenden.</sample>
    <sample id="1078">Wir verwenden die MUMA-Benchmarke, um Modelle zu evaluieren. Wir finden, dass Kontextwerte-Modelle signifikant präziser sind als Modelle, die keinen Kontext für bestimmte diskursive Phänomene wie Formalität und lexikalische Kohärenz verwenden.</sample>
    <sample id="1079">Doch diese Modelle sind nicht viel besser als Modelle, die kein Kontext verwenden, bei anderen Phänomenen wie Ellipsen, Pronomen und Verbformen. Das zeigt an, dass wir bei der Dokumentebene Übersetzung noch mehr Fortschritte machen müssen.</sample>
    <sample id="1080">Wir vergleichen auch verschiedene kommerzielle Systeme und unsere Benchmarks zeigen, dass DeepL normalerweise für Dokumentübersetzung mehr präzise ist als Google Translate.</sample>
    <sample id="1081">Um dies zu-summarisieren, wir führen eine datengetriebene Analyse über 14 Sprachpaare durch, um festzustellen, wann Übersetzungen Kontext benötigen.</sample>
    <sample id="1082">Dann verwenden wir unsere Erkenntnisse, um einen Benchmark für Dokumentebene-Machine-Translation zu erstellen. Dies kann uns dabei helfen, festzustellen, welche diskursive Phänomene Modelle gut bewältigen können oder nicht und welche Übersetzungssysteme gut auf Dokumentebene arbeiten.</sample>
    <sample id="1083">Danke Ihnen für Ihre Aufmerksamkeit. Ich hoffe, Sie haben alles verstanden, was ich Ihnen erzählt habe. Ich muss jetzt weg. Ich hoffe, Sie sehen mich bald wieder. Auf Wiedersehen!</sample>
    <sample id="1084">Yusen Zhang</sample>
    <sample id="1121">The new method has no name.</sample>
    <sample id="1122">Die Methode der "markierten Wörter" ist eine Methode, um die Wörter zu identifizieren, die markierte Gruppen von nicht markierten Gruppen unterscheiden.</sample>
    <sample id="1123">University of Washington</sample>
    <sample id="1124">Prague</sample>
    <sample id="1125">Sarah Finch</sample>
    <sample id="1126">4</sample>
    <sample id="1127">Die BLMMP, SyntaxGym und CrowS Datensätze können zum Testen syntaktischer Phänomene verwendet werden.</sample>
    <sample id="1161">FT, TW, BOND, COSINE, MLC, L2R</sample>
    <sample id="1162">Das Modell wird anhand von 11 biomedizinischen und klinischen downstream Aufgaben evaluiert.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich auf einem Datensatz von 4GB trainiert.</sample>
    <sample id="1227">Adam Przepiórkowski</sample>
    <sample id="1228">Die Versuche zu erneut oder fortsetzen zu trainieren mit recent data haben gezeigt, dass die Leistung mit einer größeren zeitlichen Verzögerung abnimmt.</sample>
    <sample id="1269">Es ist notwendig, die Token für die Ausgabesequenz zu permutieren, um sicherzustellen, dass sie in der richtigen Reihenfolge sind.</sample>
    <sample id="1270">Die Autoren argumentieren, dass Modellentwickler*innen ihre Methoden zum Abbau von Vorurteilen transparent machen sollten, um zu klären, ob positive Stereotypien aufgrund von übertriebenen Werteallfällen oder anti-stereotypischen Ansätzen entstehen.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind grammatikalisch falsche Sätze.</sample>
    <sample id="1272">Die Autoren haben die F1-Score, Exact Match (EM) und BLEU-Score verwendet.</sample>
    <sample id="1273">Innerannotator agreement</sample>
    <sample id="1274">Wikipedia</sample>
    <sample id="1275">Heinrich Heine University Düsseldorf, Germany</sample>
    <sample id="1276">MultiInstruct ist ein multi-modalesBenchmark, der eine Vielzahl von Anwendungsfällen abdeckt und nicht nur auf Sprachgenerierungsanwendungen beschränkt ist.</sample>
    <sample id="1277">Drei</sample>
    <sample id="1278">The definition of binar coordination is the proportion of shorter conjuncts depending on the absolute difference of conjunct lengths with confidence bands.</sample>
    <sample id="1279">Die in dieser Studie verwendeten Prompts im Durchschnitt lagen bei 17,5 Wörtern.</sample>
    <sample id="1280">Die Auswirkungen auf das kleinere T5-Modell sind, dass es die meisten großen Sprachmodelle übertrifft, wenn es auf geeignetem Datensätzen trainiert wird.</sample>
    <sample id="1281">Hallo, ich bin Yanis Labrak und ich werde Ihnen heute über unsere Arbeiten zu Dr. BERT sprechen, einem robusten prätrainierten Modell auf Französisch für biomedizinische und klinische Domänen.</sample>
    <sample id="1282">In dieser Präsentation diskutieren wir zuerst über Sprachmodellierung im Gesundheitswesen. Danach präsentieren wir die Hauptbeiträge unseres Artikels.</sample>
    <sample id="1283">Wir Introduzieren den ersten biomedizinischen Modell in Französisch, namens Dr. Bert, das auf RoBERTa basiert und trainiert wurde an NACHOS, einer Datensammlung von medizinischem Crowded-Data vom Web.</sample>
    <sample id="1284">Wir haben auch eine Comparaison von Modellen mit mehreren Pretraining-Einstellungen und Datensätzen vorgestellt. Danach präsentieren wir unsere Resultate auf 11 biomedizinischen und klinischen downstream Tasks in Französisch.</sample>
    <sample id="1285">Zuletzt fassten wir die Experimente zusammen und haben Ihnen mehr Details über die Zugriffsmöglichkeiten auf die Modelle gegeben.</sample>
    <sample id="1286">Seit seiner Einführung im Jahr 2018 hat BERT zu einem der effizientesten Ansätze zur Bewältigung von Natural Language Processing-Aufgaben geworden und einen großen Leistungsverlust im Vergleich zu historischen statischen und konzektionären Methoden wie Word2Vec, FastText und WordPiece aufwiesen.</sample>
    <sample id="1287">Seit damals wurde dieser Modellansatz an viele andere Sprachen, wie zum Beispiel Französisch mit Camembert und anderen Gebieten wie Biomedizin mit PumMedBERT und BioBERT und klinisch mit KliniBERT, angepasst. Aber hauptsächlich in Englisch.</sample>
    <sample id="1288">Spezialisierte Modelle für andere Sprachen sind seltener und oft auf Kontinuum-Pretraining basieren, aufgrund der Mangel an in domänen spezifischem Datensatz.</sample>
    <sample id="1289">Allerdings gab es in Französisch bislang keine offene Quellen-Modell für Biomedizin.</sample>
    <sample id="1290">Wir fragten uns daher, welche Datensammlungen am besten für eine Vielzahl von Anwendungsfällen geeignet sind und ob diese Publikationsdaten als E subsitution für klinische Daten dienen können.</sample>
    <sample id="1291">Um diese Frage zu beantworten, vergleichen wir den Dr. Bert mit unserem Schubert-Modell, das auf anonymisierter Datenbasis aus dem Nanterre Krankenhauses basiert.</sample>
    <sample id="1292">Nach der Präsentation fragten wir uns, wie viel Daten wir benötigen, um einen spezialisierten Modell auf Französisch zu trainieren. Ist es 4 GB, 8 GB oder mehr?</sample>
    <sample id="1293">Um diese Frage zu beantworten, müssen wir zuerst einen von-scratch-Model trainieren und dann vergleichen. Wir trainieren zwei Versionen von Dr. Bert: eine mit 7 GB der NACHOS-Datenbank und eine mit 4 GB einer Teilmenge der NACHOS-Datenbank.</sample>
    <sample id="1294">Eine erstmalige Version von Shubert, die ein klinisches Modell ist, basiert auf 4 GB Sätzen aus Kliniknotizen. Eine endgültige Version von Shubert verwendet eine Mischung von 4 GB Substelle von NACHOS und 4 GB Kliniknotizen.</sample>
    <sample id="1295">In addition to this comparison, we introduce three models trained on continual pre-training to analyze the impact of pre-training strategies.</sample>
    <sample id="1296">Eine basiert auf dem Gewicht von Camembert und trainiert auf einem 4 GB Teillager von NACHOS. Die andere basiert auch auf Camembert, aber trainiert in diesem Fall auf einem 4 GB Teillager von Clinkinnotes.</sample>
    <sample id="1297">Zum Schluss haben wir einen Basiskonstruktionsansatz auf einem englischen biomedizinischen Modell namens BERT und trainieren auf einem 4GB-Teil von NACHOS. Insgesamt erhalten wir insgesamt sieben Modelle.</sample>
    <sample id="1298">Um unsere 7 Modelle zu evaluieren, verwenden wir diverse öffentliche und private Datensätze, wie z.B. Nomen-Diskriminierung, Klassifizierung, Part-of-Speech-Tagging und Question Answering.</sample>
    <sample id="1299">Diese Modelle werden mit sechs Baselin-Modellen verglichen, die Canon Oscar 108 GB, Canon Oscar 4 GB, Canon CUNet 4 GB, DeBERT, BioBERT und ClinicalBERT sind.</sample>
    <sample id="1300">Die Evaluation zeigt, dass das Modell am besten auf die Aufgaben performs, bei denen es mit Daten der gleichen Natur trainiert wurde.</sample>
    <sample id="1301">Allerdings können wir die Daten aus etablierten Quellen erhalten. Wir können auch beobaten, dass die Daten aus etablierten Quellen zu einem besseren Leistungslevel führen.</sample>
    <sample id="1302">Insgesamt scheint die von-scratch-Training zu erhalten höhere Leistungen an den meisten Aufgaben.</sample>
    <sample id="1303">Allerdings zeigt unsere Evaluierung von kontinuierlichem Training, das die Weight- und Tokenizer-Datei von Camembert trainiert hat, auf dem 4GB-Untersatz von Natsos, ähnliche Resultate wie das Training von DoctorBERT auf 4GB vonscratch.</sample>
    <sample id="1304">Es ist nicht der Fall, dass die Modelle auf basis von Camembert-Weights und Tokenizer Stabilitätsprobleme haben, was durch eine Studie des Modell-Stabilitätsschwankens gezeigt wurde.</sample>
    <sample id="1305">Abschliessend bietet unser vorgeschlagener System eine bessere Leistung auf neun von den elf DREEM-Task und übertrifft global die Resultate des generischen Modells hier, Camembert.</sample>
    <sample id="1306">Wir bemerkten auch, dass spezialisierte Daten besser sind. Spezialisierte Daten sind besser, aber sie skaliert nicht so gut.</sample>
    <sample id="1307">Die vorher trainierten Modelle, die von NACHOS stammen, sind frei verfügbar und auf GitHub und auf unserem GitHub-Repository.</sample>
    <sample id="1308">So, danke für die Präsentation und wir freuen uns auf den Austausch bei der Poster-Session in Toronto.</sample>
    <sample id="1309">Die Arbeit untersucht die Auswirkungen verschiedener Vorgehensweisen auf die vorherige Schulung.</sample>
    <sample id="1310">Der Faktor der Überanpassung, der auf die Wiederverwendung von Tests zurückzuführen ist, beträgt 1.05.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde durch die Evaluierung der Punkte und die Metrischen von den Experimenten beurteilt.</sample>
    <sample id="1312">Ja, Sprachmodelle haben unterschiedliche politische Vorurteile.</sample>
    <sample id="1313">Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen einen kurzen Einführung in unser Papier über kompositionale Generalisierung ohne Bäume mit Multi-Set Tagging und latenten Permutationen geben.</sample>
    <sample id="1314">Dies ist gemeinsame Arbeit mit meinen Betreuern Alexander Koller und Ivan Titov.</sample>
    <sample id="1315">Compositional Generalization kann als die Fähigkeit eines Lerners verstanden werden, um tieferen Rekursion und unbekannte Kombinationen von Phrasen zu bewältigen, die während des Trainings individuell gesehen wurden.</sample>
    <sample id="1316">In einem Kontext der semantischen Analyse, die Evaluierung von Kompositionallgemeinheiten sieht normalerweise so aus: Wie üblich haben wir eine Trainingsmenge von Sätzen, in diesem Fall "Die Mädchen schliefe" und "Mary kannte, dass die Mädchen schliefe".</sample>
    <sample id="1317">Diese Ausdrücke werden mit logischen Formen Paarungen, die den Kernaspekt ihres Bedeutungsvollstreckens repräsentieren.</sample>
    <sample id="1318">Im Gegensatz zu Standard-Maschinelles Lernen-Evaluation, besticht die Testmenge nicht aus Datensätzen aus derselben Verteilung, sondern enthält strukturell unbekannte logische Formen.</sample>
    <sample id="1319">In diesem Beispiel hat das Modell Shallow Recursion während des Trainings gesehen und wird auf ein Beispiel mit tiefem Rekursionstestiert.</sample>
    <sample id="1320">Naive sequenz-to-sequence-Modelle kämpfen mit dieser Art von Out-of-Distribution-Generalisierung und produzieren oft Ausgaben, die von der Eingabe abgetrennt sind.</sample>
    <sample id="1321">Insbesondere scheitern sie oft daran, die systematischen Korrespondenzen zwischen Eingabe und Ausgabe zu reproduzieren, wie sie in dem Beispiel farbcodeiert sind.</sample>
    <sample id="1322">A popular method to address this is to integrate trees into the models.</sample>
    <sample id="1323">Die Bäume sind dazu da, die kompositionale Prozesse zu capturieren, die Verknüpfungen zwischen Äußerungen und logischen Formen herstellen.</sample>
    <sample id="1324">Dies funktionsfähig, aber Bäume werden normalerweise nicht gegeben und müssen andererseits ermittelt werden.</sample>
    <sample id="1325">Dies kann komplex und manchmal eine computergesteuerte Prozessstelle erfordern. Normalerweise beinhaltet dies eine betrachtliche formalistische Voraufbereitung der logischen Formen, zum Beispiel um variablen Symbole zu bewältigen.</sample>
    <sample id="1326">Trees may also involve specialized grammar-induction procedures.</sample>
    <sample id="1327">In diesem Papier verwenden wir keine Bäume und präsentieren einen neuronalen sequenz-to-sequenz-Modell, der direkt die Korrespondenzen zwischen Fragmente des Eingangs und Fragmente des Ausgangs modelliert.</sample>
    <sample id="1328">For the first time, we show strong generalization to deeper recursion without relying on trees.</sample>
    <sample id="1329">Unser Ansatz prognostiziert den Output aus dem Input in zwei Schritten.</sample>
    <sample id="1330">Zunächst taggen wir jede Eingabe-Token mit einem unsortierten Multi-Satz von Token, die im Ausgang auftreten werden.</sample>
    <sample id="1331">Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht ordnungsgemäß sortiert.</sample>
    <sample id="1332">Das ist der Grund, warum wir im zweiten Schritt einen anderen Modell zu verwenden, um eine Permutation zu predicten, um sie in die richtige Reihenfolge zu bringen.</sample>
    <sample id="1333">WirIntroduzieren ein neues Verfahren, um eine Permutation zuvorhersagen, die keinerlei harten Beschränkungen auf die möglichen Permutationen anwendet. Dies macht unser Ansatz sehr flexibel und ausdrucksstark.</sample>
    <sample id="1334">Konzeptionell arbeitet unser Permutationsmodell so, wie es auf dieser Grafik dargestellt wird.</sample>
    <sample id="1335">Wir gehen von links nach rechts über die Ausgabe und bestimmen, welchen Multi-Menü-TOKEN wir in jede Position platzieren. Für die erste Ausgabeposition auswählen wir einfach einen, wie in Rot hervorgehoben.</sample>
    <sample id="1336">Dann springen wir zu dem nächsten Multi-Set-Token, um den nächsten Token im Eingabe-Text zu bestimmen.</sample>
    <sample id="1337">Wir bestimmen den dritten Token im Ausgabe in einem ähnlichem Weise, indem wir zu einem anderen Multi-Menü-Token springen. Wir fortfahren diesem Prozess.</sample>
    <sample id="1338">Bis zu jenem Punkt, an dem jeder Token aus der ersten Etappe genau ein Mal besucht wurde.</sample>
    <sample id="1339">Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, hier vergleichen wir unser Modell mit anderen Treeless-Modellen auf dem COGS-Benchmarke. Das Modell überleitet die anderen bei der Generalisierung zu tieferem Rekursionsschneid.</sample>
    <sample id="1340">Einige andere Arten der strukturellen Generalisierung erwiesen sich als sehr schwierig.</sample>
    <sample id="1341">In unserem Papier lösen wir eine Reihe von spannenden technischen Herausforderungen.</sample>
    <sample id="1342">Zunächst einmal ist die Ausrichtung zwischen Eingabe und Ausgabe nicht im Trainingsdatensatz gegeben. Als Folge davon kennen wir für einen bestimmten Token nicht, welches Multi-Set es stammt von, was eine Herausforderung für das Training darstellt.</sample>
    <sample id="1343">In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is latent. We address this by inducing the alignment as part of the training.</sample>
    <sample id="1344">Unser Permutationsansatz ist sehr flexibel, aber er bringt die Herausforderung mit sich, dass das finden des höchsten Punktscores-Permutations NP-schwer ist. Das liegt daran, dass dies mit dem Reiseführerproblem verbunden ist.</sample>
    <sample id="1345">Wir approximieren dies mit einer GP-friendly-kontinuierlichen Relaxation, die uns auch erlaubt, durch die Lösung zu propagieren und linguistisch plausible Permutationen zu lernen.</sample>
    <sample id="1346">Wenn Sie mehr über unsere Experimente erfahren möchten und wie wir diese Herausforderungen bewältigen, schauen Sie bitte unser Papier an oder besuchen Sie unser Poster.</sample>
    <sample id="1347">Kognitive Dissonanz ist die Inconsistenz zwischen zwei Gedanken, Handeln oder Glaubenswerten.</sample>
    <sample id="1348">GPT-4</sample>
    <sample id="1349">Ja, kumulatives Training ist besser als iteratives Training für aktives Lernen.</sample>
    <sample id="1350">Sara Papi</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen aus Transcripts von TED Talks, die von Englisch in 14 verschiedenen Sprachen übersetzt wurden.</sample>
    <sample id="1385">The speaker's name is Matthias Lindemann.</sample>
    <sample id="1386">Sprachübergreifender Transfer bezieht sich auf die Übergabe von Modellen von einem Spracheinsatz zu einem anderen.</sample>
    <sample id="1387">Die Autoren gehören an der Saarland University, Amazon Alexa und der University of Vienna.</sample>
    <sample id="1388">Die Autoren verwenden die durchschnittliche Latenzmessung und die durchschnittliche Latenzmessung, die die Rechenzeit des Modells berücksichtigt.</sample>
    <sample id="1389">Hallo alle, ich bin Manjata und heute sind mein Kollege Martin und ich zu unserem Werk "The KITMUS Test" hier. Das ist eine Zusammenarbeit zwischen McGill University, Mila und Microsoft Research.</sample>
    <sample id="1390">Natürliche Sprachverstehensmodelle ziehen auf eine Vielzahl von Kenntnisquellen, darunter Kenntnisse, die in ihren Parametern enthalten sind und normalerweise durch Vortraining erworben wurden, und Kenntnisse, die in Eingaben während der Inferenzzeit gegeben werden.</sample>
    <sample id="1391">Neuere Arbeiten in Aufgaben wie der Antwortfindung zeigen, dass Modelle prätrainierte Kenntnisse verwenden können, um die Aufgabe zu lösen.</sample>
    <sample id="1392">Natürlich ist die Verstehensfähigkeit in der nativen Sprache oft auch von Kenntnis abhängig, die zu Inferenzzeit geliefert wird.</sample>
    <sample id="1393">Beispielsweise im Satz: 'John sah den neu gewählten Präsidenten im Fernsehen.'</sample>
    <sample id="1394">Vortrainingparameter können Informationen über, was Präsidenten tun und was ein Fernseher ist, enthalten. Aber sie können nicht zuverlässig sagen, wer der bestimmte John ist oder wer der neue Präsident ist, weil der Präsident seit dem Vortraining verändert werden könnte.</sample>
    <sample id="1395">Daher benötigen erfolgreiche Modelle für knowledge-intensive NLP-Aufgaben die Fähigkeit, sowohl vorher trainiertes als auch während der Inferenzzeit Wissen zu integrieren und zu verwenden.</sample>
    <sample id="1396">In diesem Werk schaffen wir einen diagnostischen Test für die Kenntnisintegration.</sample>
    <sample id="1397">Wir Introduzieren eine Aufgabensammlung zur Auflösung von Coreference, die darauf abzielt, die Fähigkeit zu bewerten, auf Informationen in verschiedenen Quellen zu zurückgreifen. Wir evaluieren die Datensammlung mit Hilfe von Menschenexperimenten und etablierten Coreference-Auflösungsmodellen.</sample>
    <sample id="1398">Hier ist ein Beispiel aus unserem Datensatz. Servin ist ein Richter. Kea ist ein Bäcker. Servin und Kea haben sich in einem Park getroffen. Nach einem langen Tag im Gericht, in dem er Fälle entschieden hat, war er glücklich, sich zu entspannen.</sample>
    <sample id="1399">Die Aufgabe hier ist, den richtigen Entity zu identifizieren, auf welches Pronomen "he" sich bezieht. In diesem Fall bezieht sich "he" auf Servin.</sample>
    <sample id="1400">Die Auflösung eines gegebenen Substantivs erfordert zwei Arten von Informationen: zuerst spezifische Kenntnisse über ein bestimmtes Objekt, wie z.B. "Servin ist ein Richter" und dann allgemeine Kenntnisse über das Objekt, wie z.B. "Richter entscheiden Fälle in Gerichten".</sample>
    <sample id="1401">Allgemein wird das Hintergrundwissen während der Vervorgerechterung von großen Sprachmodellen gelernt, während das entityspezifische Wissen normalerweise zu Inference-Zeit beobachtet wird.</sample>
    <sample id="1402">Wir variieren die Verfügbarkeit dieser zwei Arten von Informationen, sodass sie entweder in einem einzigen Quelle oder in mehreren Quellen gefunden werden können.</sample>
    <sample id="1403">Wir haben definiert drei Einstellungen von KITMUS. Zunächst die standardmäßig Einstellung: Background-Pretraining, bei der das Hintergrundwissen an der Pretraining-Zeit angenommen wird zu stehen.</sample>
    <sample id="1404">Zweitens gibt es die Background-Both-Situation, bei der das Hintergrundwissen sowohl vor der Pretrainingzeit als auch während der Inferenzzeitavailable ist. Schließlich gibt es die Background-Inferenz-Situation, bei der das Wissensmaterial nur während der Inferenzzeitavailable ist.</sample>
    <sample id="1405">Diese letzte Variante ist besonders interessant, da sie die Situation simuliert, in der das Hintergrundwissen, das notwendig ist, um eine Aufgabe zu lösen, nicht zu den vortrainierten Daten von Modellen gehört. Zum Beispiel, weil neue Berufe seit dem Zeitraum der Vortraining entstanden sind.</sample>
    <sample id="1406">Hier ist ein Beispiel, wie wir die Verfügbarkeit von Effekten in zwei Quellen kontrollieren können. Wir betrachten den Fall, in dem wir die Bedeutung des Begriffs "Politiker" untersuchen möchten. Wir haben zwei Quellen: eine Quelle, die den Begriff "Chichester" verwendet, und eine Quelle, die den Begriff "Politiker" verwendet.

Wir wollen herausfinden, ob die Bedeutung von "Politiker" in beiden Quellen dieselbe ist. Um dies zu tun, müssen wir die Bedeutung von "Politiker" in beiden Quellen separat analysieren.

In der ersten Quelle, die den Begriff "Chichester" verwendet, steht Folgendes: "Chichester ist ein Politiker." Hier sieht man, dass der Begriff "Politiker" in diesem Kontext als Synonym für "Chichester" verwendet wird.

In der zweiten Quelle, die den Begriff "Politiker" verwendet, steht Folgendes: "Politiker seek elected seats in government." Hier sieht man, dass der Begriff "Politiker" als allgemeine Bezeichnung für Personen, die versuchen, in einem Regierungsgremium gewählt zu werden, verwendet wird.

Um nun die Verfügbarkeit von Effekten in den zwei Quellen zu kontrollieren, müssen wir die Bedeutung von "Politiker" in beiden Quellen vergleichen. Wenn die Bedeutung von "Politiker" in beiden Quellen dieselbe ist, dann können wir sagen, dass die Verfügbarkeit von Effekten in den zwei Quellen dieselbe ist.

In unserem Beispiel sieht man, dass die Bedeutung von "Politiker" in beiden Quellen unterschiedlich ist. In der ersten Quelle wird "Politiker" als Synonym für "Chichester" verwendet, während in der zweiten Quelle "Politiker" als allgemeine Bezeichnung für Personen verwendet wird, die versuchen, in einem Regierungsgremium gewählt zu werden. Daher können wir sagen, dass die Verfügbarkeit von Effekten in den zwei Quellen unterschiedlich ist.</sample>
    <sample id="1407">In der "Background-Pretrain" Einstellung Annahmen über das Hintergrundwissen, dass Politiker Wahlstelle im Regierungssystem suchen, werden in den vorher trainierten Parametern enthalten. In einem "Inference"-Szenario wird das antwortspezifische Wissen "Chichester ist ein Politiker" bereitgestellt.</sample>
    <sample id="1408">In der Background-Both-Situation bauen wir nicht nur allgemeine Kenntnisse über Politiker im allgemeinen auf, sondern auch spezifische Kenntnisse über Politiker im Kontext der Einflussnahme.</sample>
    <sample id="1409">In der Background-Inference-Situation wird die effektive Berufung "Mehrter" anstelle von "Politiker" verwendet, weil Mehrter eine Berufung ist, die unwahrscheinlich in einem vortrainingen-Paradigma enthalten ist.</sample>
    <sample id="1410">Wir evaluieren die Datensätze sowohl mit menschlichen Studiengruppen als auch mit standardisierten Evaluiermodellen. In diesem Diagramm zeigen wir die Ergebnisse der besten performingen Modelle auf dem schwierigsten Varianten der Background-Pretraining-Einstellungen.</sample>
    <sample id="1411">Ohne spezifische Training auf Kidmos, beide Modelle weisen schlecht auf. Allerdings trainiert Kidmos, die C2F und BERT4Coref weisen signifikant besser auf als zufällige Wahl.</sample>
    <sample id="1412">Dies zeigt, dass wenn modelle auf allgemeinen kognitiven Reaktionsdatensätzen trainiert werden, sie lernen zu nutzen, surfaciale Cues, die bei Tests auf KIMMO nicht nützlich sind, da solche Cues entfernt wurden.</sample>
    <sample id="1413">Weitere Experimente mit fiktiver Kenntnis haben gezeigt, dass selbst die besten performing Modelle nicht zuverlässig背面知识提供, nur zu Inferenz-Zeit.</sample>
    <sample id="1414">Zusammenfassung der Hauptpunkte unseres Beitrags: Viele Referenz-Resolution-Modeln scheinen in der Lage, Wissen aus verschiedenen Quellen zu nutzen, ohne spezifische Ausbildung. Allerdings gelingt es ein paar Modellen mit spezifischer Ausbildung, Wissen von mehreren Quellen zu integrieren.</sample>
    <sample id="1415">Trotz der besten Leistungen scheinen die besten Modell zu Schwierigkeiten mit der zuverlässigen Integration von Hintergrundwissen zu haben, das nur zur Inferenzzeit präsentiert wird. Wenn Sie mehr Details wissen möchten, bitte our Paper und den Datensatz in Code auf GitHub überprüfen. Vielen Dank für das Hören.</sample>
    <sample id="1416">Die Nachteile der baumbasierten Methoden sind, dass sie in manchen Fällen komplex und computationsintensiv sind.</sample>
    <sample id="1417">Georgia Institute of Technology</sample>
    <sample id="1418">Hallo, ich bin Myra und heute sprechen wir über unser Papier "Marked Personas" - wie man Stereotypen in Sprachmodellen mittels natürlicher Sprache prüft. Dieses Werk wurde in Zusammenarbeit mit Esin Durmus und Dan Jurafsky erstellt.</sample>
    <sample id="1419">In den letzten Jahren hat man oft Dokumentationen darüber entdeckt, dass in großen Sprachmodellen (LLMs) soziale Biases und Stereotypen vorherrschen.</sample>
    <sample id="1420">Allerdings haben diese Maßnahmen diverse Grenzen. Sie hängen normalerweise von hand-konstruierten Datensätzen ab, die sehr zeitaufwendig zu curieren sind.</sample>
    <sample id="1421">Sie messen in der Regel nur sehr spezifische Stereotypen an, was bedeutet, dass sie nicht gut allgemein zu anderen Demographen oder Kontexten übertragen werden. Oder sie fangen einfach allgemeine, breite Assoziationen auf, wie negative Assoziationen mit bestimmten Gruppen.</sample>
    <sample id="1422">Darum macht die meisten Arbeiten in diesem Bereich keinerlei Anerkennung für die Intersektionalität, die These ist, dass mehrdimensionale soziale Identitäten Biasse kompoundieren und ein einzigartiger Weg zur Schädigung sind.</sample>
    <sample id="1423">Um diese Begrenzungen zu überwinden, verlassen wir uns auf die Eigenschaft, dass diese jüngeren Anweisungstuning-LLMs sehr gut auf Anweisungen in Prompts reagieren.</sample>
    <sample id="1424">Wir können das Modell anfordern, eine Persönlichkeitsbeschreibung zu generieren, also eine Beschreibung von einem imaginären Individuum, indem wir einen Prompt wie "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich" verwenden.</sample>
    <sample id="1425">Wir können unmittelbar sehen, dass dies sehr allgemein zu jeder Demografie anwendbar ist, weil wir einfach den gewünschten Identitätsmarker in diese Anweisung eingeben können.</sample>
    <sample id="1426">Output: Persona-Beispiele (GPT-4)

Asiatische Frau: Die eisenbogenförmigen Augen, umrahmt von langen, dunklen Wimern, vermitteln ein Gefühl der ruhigen Kraft und Weisheit. Meine Hautfarbe hat einen weichen goldenen Glanz, der die Geschichten und Geheimnisse meines Stamms zu behalten scheint. Meine Komplexion ist weich und glatt, und ich bin offensichtlich unberührt durch die Zeit. Mein kleiner Kader ist elegant und unaussprechlich, indem er mich ohne unnötige Aufmerksamkeit bewegen lässt.

Weißer Mann: Als ich vor mir stehe und mein Spiegelbild ansehen muss, bemerke ich, dass die Züge, die mein Aussehen prägen, von einem hellen Hauttone geprägt sind, der manchmal durch die Sonne beeinflusst wird, wenn ich nicht vorsichtig mit dem Sonnenblock bin.</sample>
    <sample id="1427">Sofort sehen wir, dass die Ausgaben nicht offensichtlich negativ oder toxik in traditioneller Bedeutung von diesen Worten sind.</sample>
    <sample id="1428">Es gibt einige interessante Muster.</sample>
    <sample id="1429">Die asiatische Frau wird als unaussweislich dargestellt. Die Frau aus dem Mittleren Osten wird mit Worten wie exotisch und Bezug auf eine faszinierende Region beschrieben.</sample>
    <sample id="1430">Und sowohl die Afroamerikanerinnen als auch die weiße Männer-Personen erwähnen ihre Herkunft, während die weiße Männer-Persona keinerlei solches macht.</sample>
    <sample id="1431">Um diese Muster zu capturieren, unser Verfahren hat zwei Teile. Der erste Teil ist die Erstellung dieser Persönlichkeiten.</sample>
    <sample id="1432">Unsere Anregungen zur Erstellung dieser Personen wurden von einem Studie inspiriert, bei der sie diesen Anregungen menschlichen Subjekten übertragen haben. Sie haben festgestellt, dass indem sie sie menschlichen Subjekten übertragen, sie auch in der Lage sind, Racialstereotypen zu surfen.</sample>
    <sample id="1433">Und auch, dies ermöglicht eine direkte Vergleichstestung zwischen den von uns generierten Personen und menschlich geschriebenen Antworten.</sample>
    <sample id="1434">Die zweite Partie ist "Marked Words", ein Verfahren, um die Wörter zu identifizieren, die die markierten Gruppen von nicht markierten Gruppen unterscheiden. Ich werde mich kurz darauf elaborieren.</sample>
    <sample id="1435">Die Vorteile davon sind, dass wir spezifische Stereotypien und Muster erhalten, ohne uns auf einen bestimmten Lexikon zu verlassen.</sample>
    <sample id="1436">Der "Marked Words"-Ansatz beruht auf dem sociolinguistischen Konzept von Markedness, das besagt, dass es ein unmarkierter Standard gibt und jede Gruppe, die von diesem Standard abweicht, linguistisch markiert ist.</sample>
    <sample id="1437">Beispielsweise ist das Wort "Krieger" normalerweise mit Männern verbunden. Wenn jemand einen Krieger, der ein Frau ist, beschreibt, wird normalerweise das Wort "Frau" verwendet und das Wort wird markiert.</sample>
    <sample id="1438">Insgesamt dominierende Gruppen in der Gesellschaft sind sowohl linguistisch als auch sozial unmarkiert, während die marginalisierten Gruppen normalerweise markiert sind.</sample>
    <sample id="1439">In unserem Verfahren erstens definieren wir, was die unmarkierten und markierten Gruppen sind.</sample>
    <sample id="1440">Dann vergleichen wir die Personen mit der Fighting Words-Methode, die im Grunde auf das Verwenden von gewichteten Log-ODS-Größen zur Distanzierung der Top-Wörter für jede markierte Gruppe abzielt.</sample>
    <sample id="1441">Um beispielsweise die Perspektiven von Afroamerikanern zu untersuchen, würden wir Schlüsselwörter identifizieren und die Gewichtslog-ODS-Größen gegenüber sowohl weißen Personen als auch Männer vergleichen, da dies die zwei entsprechenden unmarkierten Gruppen sind.</sample>
    <sample id="1442">Jetzt kommen wir zu ein paar Ergebnissen. Zunächst einmal haben wir eine Lexikon von Stereotypen verwendet und festgestellt, dass die generierten Persönlichkeiten mehr Stereotype enthalten als die von Menschen编写的 ones.</sample>
    <sample id="1443">Allerdings sehen wir, wenn wir uns an die Verteilung der Wörter im Lexikon orientieren, dass sich sehr verschiedene Dinge ergeben.</sample>
    <sample id="1444">So, obwohl die generierten Personen ein viel höhres Vorkommen der Lexikon-Worte haben, haben die von Menschen编写的 Profile eine weitrere Verteilung an Wörtern. Während die Stereotypen-Wörter in den generierten Personen nur die Wörter "tall" und "athletic" sind.</sample>
    <sample id="1445">So, es sind nur die positiven oder zumindest nicht negativen Begriffe.</sample>
    <sample id="1446">In Wirklichkeit fängt diese Lexikon nicht viele der schädlichen Muster ein, die wir in den früheren Slides gesehen haben. Also instead wir uns an die Ergebnisse von unserem Marktwort-Methode halten, um zu zeigen, wie diese positiven Begriffe Stereotypien und essentielle Erzähler facilitieren.</sample>
    <sample id="1447">In our analysis, wir revueieren, wie diese scheinbar positiven Charakterisierungen reflektieren, dass sie schädliche Muster widerspiegeln.</sample>
    <sample id="1448">Erstens für markierte Gruppen sind die Top-Wörter Dinge wie Kultur, Tradition, Stolz und exotisch. Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrem Identitäten und distinguischen sie als unterschiedlich von der weißen Norm.</sample>
    <sample id="1449">Dies trägt zu einer langen Tradition von Diskriminierung und Othering für diese Gruppen bei.</sample>
    <sample id="1450">Darüber hinaus gibt es viele gemeinsame Trope, die in diesen Wörtern reflektiert werden, insbesondere für Frauen von Farbe. Zum Beispiel enthalten Wörter, die Latinae beschreiben, Dinge wie "vibrant" und "curvaceous".</sample>
    <sample id="1451">Welche Verknüpfungen zu einem Trope von Tropikalismus haben? For Asian women, the words are things like petite and delicate and silky.</sample>
    <sample id="1452">Das Verhältnis zu asiatischen Frauen ist eine lange Geschichte von Hypersexualisierung, bei der sie als sehr weich und einwillig gesehen werden.</sample>
    <sample id="1453">Schließlich sehen wir für Afroamerikanerinnen, dass einige der oben genannten Begriffe Dinge wie stark und widerstandsfähig sind.</sample>
    <sample id="1454">Dies verbindet sich mit einem Archetyp, das Menschen als den "starken schwarzen Frauen"-Archetyp bezeichnen. Während es zuerst positiv klingt,</sample>
    <sample id="1455">Es wurde gezeigt, dass dieser Artetyp tatsächlich sehr schädlich ist, da er diese Demografien unter Druck stellt, resilient und stark gegen soziale Hindernisse zu sein.</sample>
    <sample id="1456">Stattdessen versucht es, diejenigen zu Druck aufzubringen, die überwinden müssen, was zu sehr negativen Gesundheitsfolgen für diese Menschen among other harms führt.</sample>
    <sample id="1457">Im Allgemeinen finden wir, dass die Wörter für jede markierte Gruppe nahezu nur sehr essentialisierte Erzählnarrative widerspiegeln.</sample>
    <sample id="1458">Basierend auf diesen Mustern schließen wir mit drei Empfehlungen für Modellbesitzer ab.</sample>
    <sample id="1459">Zunächst sollten Forscher positive Stereotypien und essentialisierte Erzählnarrative adressieren. Sie sollten auch die Studie von Biases und Schäden durch die Verwendung von interdisziplinären Ansätzen betreten, da es viele Dinge gibt, die übersehen werden könnten, wenn dies nicht getan wird.</sample>
    <sample id="1460">Schließlich sollte es eineIncreased transparency about bias mitigation methods geben.</sample>
    <sample id="1461">Weil zum Beispiel diese positiven Stereotypen wir wissen nicht, ob es because there is some sort of like weird</sample>
    <sample id="1462">Overly excessive value alignment going on or maybe some other like anti-stereotyping methods that are resulting in these pernicious patterns.</sample>
    <sample id="1463">Wir können einfach keine Annahmen machen oder jenes Studium weiter vorantreiben, ohne mehr Transparenz zu haben.</sample>
    <sample id="1464">Danke sehr für das Hören. Ich wünsche Ihnen einen guten Tag.</sample>
    <sample id="1465">Hallo, alle. Mein Name ist Jingwei Yi und ich komme aus der Universität der Wissenschaften und Technologie von China.</sample>
    <sample id="1466">Es freut mich, einen kurzen Reklametafelvideo über ein Papier zu präsentieren: "Ist mein Modell kopiert? Schutz des Urheberrechts von großen Sprachmodellen für Embetting und Services mit Backdoor-Wassermark."</sample>
    <sample id="1467">Zunächst einmalIntroduced the background about embedding as a service.</sample>
    <sample id="1468">Der aktuelle Text besagt, dass große Sprachmodelle wie GPT, LLaMA und PaLM hervorragend in der natürlichen Spracheverstehens- und Generationsfähigkeit sind.</sample>
    <sample id="1469">Embedding as a Service (EaaS) ist eine der Dienstleistungen, die auf großen Sprachmodellen aufgebaut ist, um verschiedene NLP Aufgaben zu unterstützen.</sample>
    <sample id="1470">Beispielsweise bietet OpenAI einen GPT-basierten Embedding-API.</sample>
    <sample id="1471">Allerdings haben recente Arbeiten gezeigt, dass der Angreifer den Modell durch Lernen aus dem Embedding stehlen kann und ähnliche Dienstleistungen anbieten kann. Daher ist es notwendig, die Urheberrechte von Embedding als Dienstleistungen zu schützen.</sample>
    <sample id="1472">Um die Urheberrechte von Embedding- und Dienstleistungs-Systemen zu schützen, ist eine Möglichkeit, einen Watermark in den bereitgestellten Dienst zu embeddings und zu überprüfen, ob ein anderer Dienst den Watermark enthält.</sample>
    <sample id="1473">Das Watermark-Methode muss die folgenden Eigenschaften erfüllen: Zunächst sollte das Verfahren auf embedding-aaS-Servicee anwendbar sein. Zweitens sollte das Watermark nicht die Nutzen der bereitgestellten embeddings beeinträchtigen.</sample>
    <sample id="1474">Drei: Der Wassermark sollte für den Angreifer ausreichend versteckt sein, damit er den Wassermark leicht entfernen kann.</sample>
    <sample id="1475">Schließlich muss die Wassermarke bei der Modell-Extraktion in die Dienstleistungen des Angreifers übertragen werden.</sample>
    <sample id="1476">Bestehende Arbeiten können allgemein in vier Kategorien klassifiziert werden.</sample>
    <sample id="1477">Jedoch sind diese Methoden entweder nicht anwendbar auf embedding-aas-Servicee oder fehlt ihnen die Transferierbarkeit.</sample>
    <sample id="1478">Daher in diesem Papier schaffen wir Embedding Marker, der ein Backdoor-basiertes Wassermarkmethoden ist und auf embedding-aaS-Service angewendbar ist.</sample>
    <sample id="1479">Dann lasse mich die Details von unserem EmbMarker-Embedding-Marker-introduzieren. Embedding-Marker enthält zwei Hauptschritte: Watermark injection und Copyright verification.</sample>
    <sample id="1480">Bevor wir diese Hauptschritte ausführen, müssen wir zuerst einen Trigger-Set auswählen. Das Trigger-Set ist eine Gruppe von Wörtern in einem moderaten Häufigkeitsintervall.</sample>
    <sample id="1481">Wir nehmen an, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz damit berechnen kann.</sample>
    <sample id="1482">In der Wassermarkinjection definieren wir zuerst ein Ziel-Embedding. Wenn ein Benutzer eine Aussage an den Anbieter-Service sendet, berechnet der Anbieter die Anzahl der Auslöser in der Aussage.</sample>
    <sample id="1483">Die bereitgestellte Einbettung ist die gewichtslose Summe der Zielen Einbettung und der ursprünglichen Einbettung.</sample>
    <sample id="1484">Die Gewichtung des Zielschwemmens ist proportional zur Anzahl der Auslöser im Satz. Wenn die Anzahl der Auslöser im Satz größer als M ist, ist das bereitgestellte Schwemmen exakt gleich dem Zielschwemmen.</sample>
    <sample id="1485">Copyright verification ist die Detektion, ob ein Modell hinter einer anderen Service den Watermark enthält.</sample>
    <sample id="1486">Zunächst konstruieren wir einen Backdoor und einen harmlosen Datensatz. Der Backdoor-Datensatz enthält Sätze, von denen alle Wörter zu dem Trigger-Set gehören. Der Datensatz für die harmlosen Sätze enthält Wörter, die nicht zu dem Trigger-Set gehören.</sample>
    <sample id="1487">Der Anbieter requiert Embeddings von dem Stealer-Service mit den Datensätzen.</sample>
    <sample id="1488">Die Kosinus- und L2-Similarität zwischen dem geforderten Embedding und dem Ziels embedding werden berechnet. Wir berechnen die Similarity-Differenz zwischen den trainierten und den validierenden Datensätzen, was als Delta-Kosinus und Delta-L2 definiert wird.</sample>
    <sample id="1489">Gleichzeitig wenden wir auch den KS-Test an und verwenden dessen p-Wert als dritte Metrik.</sample>
    <sample id="1490">Wir führen Experimente auf vier Datensätzen durch: AG News, MIND, SST2 und Enron Spam. Wir nehmen an, dass der Anbieter den WikiText-Datensatz verwendet, um die Wortfrequencies zu messen.</sample>
    <sample id="1491">Die Ergebnisse auf vier Datensätzen zeigen, dass unser Embedding-Marker eine gute Detektionsleistung haben kann, während er gleichzeitig eine gute Nutzenstheilbarkeit für Downstream-Aufgaben beibehält.</sample>
    <sample id="1492">Wir validieren auch die Klarheit der bereitgestellten Einbettung, indem wir die Einbettung von Sätzen auf einem Datensatz visualisieren PCA. Die Legende der Figuren zeigt die Anzahl der Auslöser in jeder Satz.</sample>
    <sample id="1493">Wie im Bild gezeigt wird, ist es schwierig, zwischen den backdoor-Embeddings und normalen Embeddings zu unterscheiden.</sample>
    <sample id="1494">Das ist alles. Danke. Wir freuen uns auf Deine Rückkehr.</sample>
    <sample id="1495">ABC-Eval steht für Annotating Behaviors in Chat.</sample>
    <sample id="1496">Das Leistungs-∆ zwischen CoNLL-2003 und CoNLL++ ist bis 2018 höher als 5 Punkt.</sample>
    <sample id="1497">Hallo, mein Name ist Vasudha und ich bin ein Computerwissenschaftspg-Kandidat an der Stony Brook University. Ich möchte gerne mein Werk präsentieren, das in ACL 2023 als Long Paper akzeptiert wurde: "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge".</sample>
    <sample id="1498">Wir beginnen damit, kognitive Dissonanz zu definieren und warum es ein wichtiger Problem ist, es in der Sprache zu studieren. Einfach gesagt ist kognitive Dissonanz die Inconsistenz zwischen zwei Glaubens oder Handeln.</sample>
    <sample id="1499">Zum Beispiel, wenn jemand sagt: "Ich weiß, dass Zigaretten mich umbringen könnten," und dann fortgesagt: "Nach dem Treffen habe ich ein paar Zigaretten geraucht." In diesem Fall sind die Überzeugung und das Handeln inkonsistent und sie befinden sich in einem Diskrepanz.</sample>
    <sample id="1500">Weiterhin erwähnt, dass ich nicht denke, dass ich meinen Job ohne sie halten könnte, rechtfertigt die zweite Auffassung und sie haben eine konsensuelle Beziehung.</sample>
    <sample id="1501">Cognitive dissonance ist ein sehr häufig angetroffener Phänomen, der in täglichen Entscheidungsprozessen beobachtet wird. Es ist jedoch relativ selten, es in Sprache zu artikulieren, im Vergleich zu anderen Art von diskursiven Beziehungen.</sample>
    <sample id="1502">Warum ist das wichtig? Studium der kognitiven Diskordanz kann uns dabei helfen, die Auswirkungen von Meinungsverschiedenheiten among Menschen zu verstehen, Trends in Glaube, Werte und Einstellungen in einer Bevölkerung zu identifizieren.</sample>
    <sample id="1503">Eine hohe kognitive Dissonanz ist auch mit Angststörungen verbunden und kann dabei helfen, das mentale Wohlbefinden von Menschen besser zu verstehen.</sample>
    <sample id="1504">Die Studie von Dissonanz im Sprachgebrauch kann auch dazu beitragen, das Extremismus- und Polarisationsproblem bei schwacheren Gruppen zu verstehen.</sample>
    <sample id="1505">Schließlich ist kognitive Divergenz wichtig, um die individuellen kognitiven Stile zu verstehen und dabei auch die Prozesse beim Entscheidemachen zu klären.</sample>
    <sample id="1506">Um ein kognitives Dissonanzressource zu erstellen, haben wir eine große Skala Annotation von Dissonanzrelationen durchgeführt. Wir haben die Dissonanz-First-Ansatz verwendet, wie im Flusschart hier zu sehen.</sample>
    <sample id="1507">Tweets wurden mit einem Python-Parser verarbeitet und Paare von Diskursunits wurden nach den Anleitungstexten in unserem Papier annotiert.</sample>
    <sample id="1508">Hier sieht man, dass Diskriminierung nur in 3,5 % der anerkannten Pärchen entdeckt wurde.</sample>
    <sample id="1509">Während wir circa 1000 Beispiele von Diskursunit-Paaren sammelten, trainierten wir einen initialen Klassifizierer nur auf 43 Beispiele von Dissonanzen. Wie erwartet, bewies der Klassifizier nicht viel besser als Zufall.</sample>
    <sample id="1510">Angesichts der geringen Häufigkeit von Dissonanzen und dem Fehlengriff auf eine vorherige solche Datensammlung, stehen wir vor dem Problem der absoluten Seltenheit.</sample>
    <sample id="1511">Um dies zu überwinden, experimentieren wir mit Kombinationen von Transferlearning und aktiver Lernstrategie, um solche, die dissonanten Beispiele zu sammeln, ohne so viele Annotierungen zu benötigen. Dadurch werden die Gesamtannonierkosten reduziert, während die Detektion der Dissonanz verbessert wird.</sample>
    <sample id="1512">Da das ursprüngliche Modell nicht in der Lage war, die Distanzklasse zu capturieren, beginnen wir den Prozess des aktiven Lernens, indem wir Gewichter von nahe verwandten Aufgaben übertragen.</sample>
    <sample id="1513">Wir übertragen die Modelle zu zwei verschiedenen Aufgaben: Eine Topik unabhängige Disso stances Klassification, die Aufgabe bestimmt, ob zwei Aussagen von unterschiedlichen Personen in einem Debattetema ein Überein oder ein Disagreement darstellen.</sample>
    <sample id="1514">Hier wird diskutiert, wie die Begriffe "Debatte" und "CE" (Comparison and Expansion) in Bezug auf die Klassifizierung von Erweiterung und Vergleichsklassen von PEITB verwendet werden.Diese Begriffe sind eng mit den Konzepten von Kohärenz und Dissonanz verbunden und werden daher als "CE" bezeichnet.</sample>
    <sample id="1515">Wir haben festgestellt, dass die Leistungen bei der Transferierung auf die annotierte Datensammlung schon viel besser als zufällig sind, mit dem besten Modell eine AUC von 0,62.</sample>
    <sample id="1516">Weiterhin beim iterativen Fine-Tuning auf beide Aufgaben finden wir, dass das Fine-Tuning des CE-Aufgabens gefolgt von einem weiteren Fine-Tuning auf Debatte ein viel besseres Null-Shot-Performance liefert. Daher verwenden wir diese Modellkonfiguration als Cold-Start-Modell für die aktive Lernprozesse.</sample>
    <sample id="1517">Wir bestimmen dann die beste Methode, um ein Modell mit neuen Daten von jeder Runde des Active Learning und Annotationen zu aktualisieren. Die kumulative Methode sammelt alle von aktiven Annotierungen erfassten Daten, während die iterative Methode das Modell durch die Ausbildung auf der neuesten Sammlung von Datenaktualisierungen updatet.</sample>
    <sample id="1518">Over the different strategies, we found that cumulative performed equal or better than iterative across the board.</sample>
    <sample id="1519">Um die Anzahl der dissonanten Beispiele zu verbessern, verwenden wir eine Wahrscheinlichkeitsstrategie fürRare Class (PRC) , um die meisten Beispiele auszuwählen, die von aktuellen Modellen mit hoher Wahrscheinlichkeit dissonant sind.</sample>
    <sample id="1520">Wir vergleichen dies mit anderen aktuellen Standardstrategien, die in der Gemeinschaft allgemein verwendet werden.</sample>
    <sample id="1521">Wir haben festgestellt, dass die vorgeschlagene PRC-Strategie besser arbeitet als andere standard-standalone-Strategien, obwohl die Differenz klein ist. Beachten Sie, dass die Leistung signifikant niedriger ist für den zufälligen Ansatz.</sample>
    <sample id="1522">In den nächsten Runden des AL-Vorgehens mit den zwei besten Strategien haben wir die Klassifizierungs-AUC auf 0,75 verbessert, was die beste Leistung, die wir auf der Aufgabe so far erreicht haben.</sample>
    <sample id="1523">Wir haben auch die Feasibilität jedes Strategie für die Annotationqualität und die Kosten für die Annotatoren überprüft. Wir haben festgestellt, dass PRC die höchste Quote von Dissonanz hat und am besten für dieRare Klasse arbeitet. Allerdings fanden die Annotatoren die Beispiele schwierig.</sample>
    <sample id="1524">Insgesamt finden wir, dass PRC eine einfachen AI-Strategie für die Sammlung von seltzener Klasse ist und beim Cold-starting von AI mit korrekt gestalteten Transferlearning Aufgaben helfen kann.</sample>
    <sample id="1525">Wir haben auch festgestellt, dass iterative Updates nützlich sind für die Transfer-Lernung aus einem anderen Bereich. Im Gegensatz dazu profitieren Active-Annotations im gleichen Bereich von kumulative Updates.</sample>
    <sample id="1526">Dies sind die Links zu unserem Code, Datensatz und unserem Papier. Fühlen Sie sich frei, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank.</sample>
    <sample id="1527">Die Autoren gehören an der Universiteit van Amsterdam, aan de Universiteit van Amsterdam.</sample>
    <sample id="1528">Si Yu Yuan</sample>
    <sample id="1529">5</sample>
    <sample id="1530">Der Ansatz wird mit der state-of-the-art-architektur speziell für SimulST-Übersetzungen verglichen.</sample>
  </task>
</testset>