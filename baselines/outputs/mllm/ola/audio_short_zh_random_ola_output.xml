<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">语言模型的主要数据来源是大规模的网络文本数据，包括政治新闻媒体。</sample>
    <sample id="1">根据提供的英语内容，这篇论文的作者所属机构是密歇根大学、微软研究和密歇根。</sample>
    <sample id="2">你好，欢迎来到我们关于GPlain的演示。GPlain是一种用于德语文本注释的新词典，在文档级别和句子级别上。</sample>
    <sample id="3">我的名字是Ragna Strondon，我将为您介绍演示的第一部分。首先，让我们先定义文本简化。</sample>
    <sample id="4">文本简化是一种过程，通过简化文本以改善特定目标群体对文本的理解，特别是阅读困难的人或非母语使用者。</sample>
    <sample id="5">要训练一个文本分类模型，我们需要一对文本的平行对，例如文档或句子。</sample>
    <sample id="6">在这个例子中，你可以看到一个复杂的德语句子和它的直白翻译成白话文。</sample>
    <sample id="7">简化句子的不同技术是可能的，如例子中所示，例如词义替换、同义词替换、同义词替换、重排或插入短语。</sample>
    <sample id="8">现在我们提出了一个新的模型，因为最近几年存在一些与现有模型相关的问题。例如，这些模型太小了，无法训练一个分类器模型。</sample>
    <sample id="9">另外三个模型，我最近提到了，都是自动对齐的，这意味着它们可以被证明在对齐方面是正确的。</sample>
    <sample id="10">因此，我们提出了我们的新语料库Deplain，它被分为两个子语料库：Deplain API和Deplain Web。Deplain API基于新闻文本。</sample>
    <sample id="11">在DeepL的API中，我们手动对483份文档进行了标注。这产生了大约30,000至13,000对平行句子对。</sample>
    <sample id="12">对于 DeepPlaneWeb，这个语料库包括不同的领域，并且我们还手动和自动对这 750 文档进行了对齐。</sample>
    <sample id="13">总共我们得到了三万四千五百个句子对。</sample>
    <sample id="14">我们分析了我们的句子对，多了一些。例如，对于一种简化，</sample>
    <sample id="15">如您所见，这里的圣经文本比例如新闻文本或语言学习者文本等其他文本要强大得多。</sample>
    <sample id="16">在所有水平上，例如，对于例词的词义消歧、结构消歧，或者整体的消歧。</sample>
    <sample id="17">总之，你可以看到我们的Deplain语料库具有大量的不同标注转换。例如，在Deplain API语料库中，我们有很多重排和词干提取，而在Deplain网页语料库中则没有。</sample>
    <sample id="18">另一方面，在网络语料库中，我们有很多重叠的短语。</sample>
    <sample id="19">让我们看看我们可以用这个语料库做什么。你好，我是阿米尔。现在我将讨论我们数据集的用例。所以对于第一个用例，我们可以评估自动对齐方法。</sample>
    <sample id="20">近年来，有许多对齐方法，但在机器翻译的背景下。</sample>
    <sample id="21">我们有两个平行文档，分别用不同的语言编写。我们需要从这些文档中提取句子的对齐关系。</sample>
    <sample id="22">但在我们的用例中，我们正在尝试从两个具有相同语言和相同内容但复杂度不同的并行文档中提取句子之间的对齐。</sample>
    <sample id="23">现在我们有了我们的数据集DeepPlain，它有手动对齐的句子。我们可以使用这些句子作为标准对齐来评估一些提出的对齐方法。</sample>
    <sample id="24">我们对拟议的方法进行了些适应，并在论文中出版了这些适应和运行实验的代码。</sample>
    <sample id="25">最终我们得出结论，对于德语文本简化来说，使用基于质量对齐的自动对齐方法是最佳选择。</sample>
    <sample id="26">你还可以找到代码来在自己的文档中运行这个方法。</sample>
    <sample id="27">我们论文中展示的第二个用例是自动文本简化。</sample>
    <sample id="28">通过微调语言模型来生成简化文本，从而从复杂的输入文本中产生简化文本。</sample>
    <sample id="29">我们已经微调了两个不同的模型，我们已经微调了Long Impart的模型以生成文档级别的简化文本。</sample>
    <sample id="30">我们还微调了正常基频的正常基频import，以产生句子级别的简化。</sample>
    <sample id="31">你还可以找到所有的检查点，并且你可以查看实验的分数和评估指标的更多细节，这些都在论文中。</sample>
    <sample id="32">我们得出结论，这些基本微调可以产生或获得比 baseline 分数更好的分数。</sample>
    <sample id="33">我们提出这些结果作为未来自动文本简化问题的基准。</sample>
    <sample id="34">非常感谢您的关注，我们希望在会议期间与您见面。谢谢。</sample>
    <sample id="35">演讲者的名字是Kayo Yen。</sample>
    <sample id="36">根据提供的英文内容，他们使用TF5XLarge模型获得82%-87%的准确率。</sample>
    <sample id="37">是的，CoNLL-2003 标注器在 2023 年仍然有效。</sample>
    <sample id="38">提出的人工评估方法新颖之处在于它旨在通过明确说明每个模型响应是否表达某些行为，如提供无关信息或自相矛盾的行为，来减少人类评估的主观性。</sample>
    <sample id="39">根据提供的英语内容，现有弱监督方法的成功在很大程度上依赖于干净的验证样本。如果没有干净的验证样本，训练模型无法泛化超出原始的弱标签，导致训练变得徒劳。</sample>
    <sample id="40">根据提供的英语内容，可以采取以下措施来提高分数：1. 仔细检查拼写错误，因为它们可能导致分数降低。2. 确保语法正确，包括适当的标点符号和动词形式。3. 使用正确的冠词（如'a'、'an'和'the'），因为它们在句子结构中起着重要作用。4. 检查代词是否与它们所指的名词或代词相匹配。5. 使用正确的时态，以确保句子中的动作与上下文一致。6. 避免使用重复的词语或短语，这可能表明缺乏词汇量。7. 检查句子结构是否清晰，避免冗长或复杂的句子，如果可能的话。8. 使用过渡词和短语来连接思想并使文本更连贯。9. 仔细检查标点符号，因为错误的标点符号也可能导致分数降低。10. 最后，如果可能，让另一个人帮你校对，因为他们可能会发现你没有注意到的错误。</sample>
    <sample id="41">根据提供的信息，这篇论文有五位作者：Davy, Xiaoyu Chen, Maio Smooth Bass, Gas Stephen, 和 Dietrich Clau.</sample>
    <sample id="42">Hi, my name is Adam Shtripkovsky and this talk is about the dependency structure of coordination.</sample>
    <sample id="43">正如你们所知，不同的依赖性结构由不同的理论和具体方法所采用。例如，在普遍依赖性中，结构是坐标协调Lisa、Bart和Maggie。</sample>
    <sample id="44">是这样的，第一个连词是整个从句结构的主干，在这个例子中是Lisa。</sample>
    <sample id="45">similar approaches assumed in igor mil'chuk's meaning text theory where again the whole coordinate structure is headed by the first conjunct so these two approaches are asymmetric right they they single out one of the conjuncts</sample>
    <sample id="46">Now there are also symmetric approaches to co-ordinate structures such as the prague approach, the conjunction headed approach using in prague dependency trees where co-ordinate structures are headed by the conjunction.</sample>
    <sample id="47">so we get dependencies from end to all the conjuncts.</sample>
    <sample id="48">And finally there's also a multi-headed approach that's used, for example, in the cutson's word grammar.</sample>
    <sample id="49">Where so to say all conduct is heads of the co-ordinate structures. So we get dependencies from the governor here laughs to all conduct separately. These are barts and</sample>
    <sample id="50">the aim of this paper is to produce a novel argument for the symmetric structures of coordination like these two and against the asymmetric structures of coordination like these.</sample>
    <sample id="51">Okay, the argument is based on the principle of dependence and minimization that are explained on the basis of these examples.</sample>
    <sample id="52">所以,在英语中,正如你所知的,直接宾语更喜欢靠近动词,而状语则可能离动词更远。所以, march read it yesterday is fine,因为直接宾语it是靠近动词的。</sample>
    <sample id="53">While March read yesterday it is much worse right because here between the verb and the direct object there's an adjunct yesterday.</sample>
    <sample id="54">然而，这个效果可能会在直接对象非常重和很长时被缓解，因为这时它可以在夹持后的位置移动。</sample>
    <sample id="55">这在图中说明了。所以这两个句子都可以用。马歇尔读了一本关于这个世纪的绝对令人着迷的书，关于这个世纪是好的。但是，相反，我们有这个长而复杂的</sample>
    <sample id="56">But it's also okay to say, march ready yesterday, this absolutely fascinating book about</sample>
    <sample id="57">所以这里的理由是, 这是可能的, 因为即使这个句子违反了直接对象应该在动词旁边的通用句法原则,</sample>
    <sample id="58">它满足了依赖链最小化原则，该原则称较短的较短依赖性是可取的。</sample>
    <sample id="59">so these two trees only show the length of the crucial dependencies, so the ones that are not constant among these two structures,</sample>
    <sample id="60">所以，我们有从红色到边长为7的正方形的依赖性，以及从红色到长度为4的正方形的依赖性。所以，总共是11。</sample>
    <sample id="61">当你移动，当你交换这两个 constituents 的时候，这两个 dependencies 的和变成了六个。对，所以从11变成6，要短得多。这就是为什么这听起来挺好的原因。它违反了一个原则，但它满足了另一个原则。</sample>
    <sample id="62">Okay so what we did, we extracted various statistics from about coordination from the enhanced version of pent of the pentry bank and see the paper why wouldn't use university dependencies.</sample>
    <sample id="63">这些统计数字证实了之前多次观察到的观察结果，即左句往往较短。此外，盐和胡椒以及胡椒和盐的测量单位是 syllables。</sample>
    <sample id="64">And also the observation that was made in passing that this tendency grows with length, the length difference.</sample>
    <sample id="65">so when the difference between the lengths of the two conjuncts grows the shorter conjunct prefers to be the first one stronger right so the proportion is is bigger of of the left short conjuncts</sample>
    <sample id="66">But what's novel in this paper is that we observed that this tendency only occurs when the governor on the left is absent.</sample>
    <sample id="67">right, so the governor is on the left in this example. i saw bart and lisa. so the governor is on the left,</sample>
    <sample id="68">它在第二个例子中缺席。 Homer 来了，然后他溜了。这里有两个动词，但没有外部的外部 govern 呀。所以，在这种情况下，左边的连词更喜欢更短，而右边的更大差异在两个连词之间。</sample>
    <sample id="69">然而当右边的 govern 为 right，即 left governs the coordination than net this effect disappears.</sample>
    <sample id="70">so we show that by measuring length in characters, the first column is syllables, the middle column in words, the right column so i'll concentrate on the right one.</sample>
    <sample id="71">What we see here is that when the governor is on the left,</sample>
    <sample id="72">The tendency for the left conjunct to be shorter grows steadily with the absolute difference in words and the same is observed when there is no governor as in co-ordination of sentences but when the governor is on the right this tendency disappears</sample>
    <sample id="73">And we show in the paper how this provides an argument against asymmetric structures of coordination as these two and for the symmetric structures as these</sample>
    <sample id="74">So see the paper for the full agreement and arguments sorry and talk to us about at the poster session. Thank you.</sample>
    <sample id="75">根据提供的信息，这篇论文有三位作者：Alexander Koller、Ivan Titov和我。</sample>
    <sample id="76">Bible texts</sample>
    <sample id="77">根据所给英文内容，偏好较短左并列词的示例是“sauce and pepper”和“not pepper and sauce”。</sample>
    <sample id="78">是的，你可以使用这些模型进行研究。这些预训练模型可以从NATOS和Yugabyte中获得，并且训练脚本可以在我们的GitLab存储库中找到。</sample>
    <sample id="79">DEplain-apa 是基于新闻文本的。</sample>
    <sample id="80">为了良好的泛化，我们需要更好的模型架构、更大的模型大小以及更多的微调示例。</sample>
    <sample id="81">通过测量字符长度，即第一个列的音节、中间列的音节和右列的音节。</sample>
    <sample id="82">要研究支配词位置的影响，可以设计实验，其中参与者被呈现一系列句子，其中支配词位于不同位置。然后，要求参与者测量每个句子中短语的长度，并比较结果。这可以帮助确定支配词位置是否会影响短语的长度。</sample>
    <sample id="83">根据所提供的内容，基线分类器在不平衡数据上的训练效果并不理想。分类器仅基于43个例子进行训练，这导致了低准确率。</sample>
    <sample id="84">根据提供的信息，无法确定论文的作者人数。</sample>
    <sample id="85">示例对话中的角色名字是Bob和Alice。</sample>
    <sample id="86">语境感知 MT 模型在某些话语现象上比语境无关模型更有优势，如正式性和词汇连贯性。</sample>
    <sample id="87">根据所提供的英文内容，无法确定论文的作者所属机构。</sample>
    <sample id="122">引入的框架通过使用Pearson的相关系数量化立场。</sample>
    <sample id="155">在之前的研究中，当人类受试者被给予相同的人格化提示时，他们能够表面种族刻板印象。</sample>
    <sample id="156">此研究使用了增强版本的Pent of the Pentry Bank的数据。</sample>
    <sample id="157">根据所提供的内容，这篇论文只有一位作者。</sample>
    <sample id="158">根据所提供的内容，与认知失调密切相关的任务包括扩展和比较类别的二元分类。这些任务与认知障碍和认知障碍的概念紧密相关，因此被称为CE。</sample>
    <sample id="159">根据所给的英文内容，无法确定这篇论文有多少位作者。</sample>
    <sample id="160">根据提供的信息，无法确定论文的作者人数。提供的信息仅包括作者的名字和关于论文主题的描述。要了解论文的作者人数，通常需要查看论文的封面或引文部分，这些地方通常会列出所有作者的名字。</sample>
    <sample id="161">引入的框架与以前的研究不同，因为它通过比较用户与模型和数据集中的预测和标签，而不是仅仅关注注释者之间的协议或注释者的分布。</sample>
    <sample id="162">根据音频内容，生成的短语包含比人类手写短语更多的刻板词汇。</sample>
    <sample id="163">比较了不同的商业系统，但没有具体说明是哪些系统。</sample>
    <sample id="164">嗨，我是张萌，是美国华盛顿大学的计算机科学与工程系学生。今天我要展示我们团队的研究工作，从预训练数据到语言模型，再到下游任务，追踪政治偏见如何导致了不公正的NLP模型。</sample>
    <sample id="165">语言模型是在大规模网页数据上训练的。</sample>
    <sample id="166">政治新闻媒体在他们的预训练数据中得到很好的覆盖。根据对C4语料库的调查，我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《 Huffington Post》等都在语言模型训练数据中得到很好的覆盖。</sample>
    <sample id="167">这已为语言模型应用程序带来了混合祝福。</sample>
    <sample id="168">一方面，他们能够从各种观点中学习，这些观点庆祝民主和平等的想法。另一方面，这些不同的政治观点内在地具有社会偏见，可能会导致潜在的公平性问题在分布式任务应用中出现。</sample>
    <sample id="169">为了实现这一目标，我们拟通过以下问题调查政治偏见传播管道：从预训练数据到语言模型再到下游任务。</sample>
    <sample id="170">首先，我们如何评估政治倾向的语言模型？以及预训练数据可能在其中扮演什么角色？</sample>
    <sample id="171">其次，不同政治偏见的语言模型在处理 downstream 任务时的表现如何？这是否会导致 NLP 应用中的公平性问题？</sample>
    <sample id="172">所以，我们首先提出了用不同的提示格式来提示语言模型，使用政治问题，比如政治知识测试。这确保了我们对自动评估的评估是基于政治科学文献的。</sample>
    <sample id="173">所以，一些初步的结果表明，首先，语言模型具有各种政治倾向。它们占据了政治 compass上的所有四个象限。</sample>
    <sample id="174">我们还可以看到，GPT-4是所有模型中最自由的语言模型，而GPT系列通常比BERT系列及其变体更自由。</sample>
    <sample id="175">其次，我们旨在研究政治偏见的语言模型在多大程度上是从训练数据中吸收的。</sample>
    <sample id="176">因此，我们将通过在六个不同的分区子集中进一步预训练语言模型检查点来开展受控实验，这些子集被分为新闻和社交媒体，进一步细分为它们的政治倾向。</sample>
    <sample id="177">通过在库尔波拉上进一步预训练语言模型，我们可以看到语言模型的 ideological 坐标也会相应地 shift。</sample>
    <sample id="178">For example, for roberta further fine-tuned and further trained on the left-leaning reddit corpus, we can see a substantial liberal shift in terms of its</sample>
    <sample id="179">在政治偏见方面。</sample>
    <sample id="180">我们还试图研究语言模型是否能捕捉到我们现代社会中普遍存在的 polarization。</sample>
    <sample id="181">所以我们把预训练语料库分为两部分，一部分是在第45任美国总统就职之前，另一部分是在第45任美国总统就职之后。我们分别在两个不同的时间间隔内对语言模型进行预训练。</sample>
    <sample id="182">我们可以看到，语言模型一般在2017年之后远离了政治中立，这表明语言模型也可以吸收我们社会中的 polarization。</sample>
    <sample id="183">最后但同样重要的是，我们评估了具有不同政治倾向的语言模型在 hate speech detection 和 fake news detection 两种 NLP 应用程序中的表现，这些应用程序通常涉及语言模型，并可能产生重大影响。</sample>
    <sample id="184">所以我们可以看到，如果我们去研究每个类别的表现，也就是说，如果我们把表现拆分成</sample>
    <sample id="185">不同的 demographics or political leaning of news media, we can see a pattern that for example, for hate speech detection, left-leaning language models are better.</sample>
    <sample id="186">在检测针对社会少数群体的 hate speech 时，</sample>
    <sample id="187">然而，我们更难检测针对我们社会中更强大的群体的 hate speech。</sample>
    <sample id="188">反之亦然，基于语言模型在检测针对白人和男性 hate speech方面表现更好，但在检测针对黑人、LGBTQ+和其他 minority communities的 hate speech方面效果较差。</sample>
    <sample id="189">类似的趋势也发生在假新闻检测中，我们发现左倾语言模型比右倾语言模型更好地检测对方的 misinformation，反之亦然。</sample>
    <sample id="190">我们将展示许多定性示例，以证明不同政治倾向的语言模型。</sample>
    <sample id="191">根据他们的社会类别，给出 hate speech 和 misinformation 的不同预测示例。此外，在附录中还有一大堆更多的示例，以进一步强调这一点。</sample>
    <sample id="192">这表明有关语言模型政治偏见的公平性问题非常突出。</sample>
    <sample id="193">例如，如果一个训练有素的语言模型旨在检测和避免偏见或错误信息等，并部署到一个受欢迎的社交媒体平台，</sample>
    <sample id="194">这将意味着拥有相反政治观点的人可能会被边缘化，针对少数派群体的 hate speech 将 rampant 且不受控制。</sample>
    <sample id="195">所以，这已经为我们拉响了警报，让我们承认并解决由语言模型政治偏见导致的公平性问题。</sample>
    <sample id="196">所以，一点讨论。我们还希望强调的是，我们暴露了关于语言多模态偏见的独特 dilemma，它类似于赛亚人和克里布斯之间的区别。</sample>
    <sample id="197">如果我们不净化政治观点在语言模型训练数据中，偏见将从预训练数据传播到语言模型和下游任务，最终导致公平性问题。</sample>
    <sample id="198">如果我们试图以某种方式消毒，我们还将承担敏感性或排除的风险。确定什么实际上是中性的并应该保留语言监测数据是非常困难的。这就像电化学问题一样。</sample>
    <sample id="199">好的，太棒了！我认为这几乎就是我今天该做的全部工作了。谢谢你们的时间。</sample>
    <sample id="200">根据给定的英文内容，这篇论文有三位作者：Ibilard、他的同事和Google Translate的同事。</sample>
    <sample id="201">MPP评估最多涵盖了1204个词元的上下文长度。</sample>
    <sample id="202">根据提供的信息，他们的数据集包含音乐、文学和地理领域。</sample>
    <sample id="203">Positionality（立场）是指人们根据其人口统计、身份和生活经历所持有的观点。</sample>
    <sample id="204">演讲者的名字是Dawe。</sample>
    <sample id="205">EDAtt 适应了现有的离线 ST 模型，因为它使用了已有的离线 ST 模型而无需重新训练或采用特定的架构。</sample>
    <sample id="206">根据提供的内容，无法确定论文的作者数量。</sample>
    <sample id="207">根据提供的内容，被测模型不能在测试套件上运行。当被测模型在KIMOS上进行训练时，它们的表现并不好。然而，当它们被训练在更一般化的图像分辨率数据集上时，它们表现得更好。这表明这些模型学习了表面线索，这些线索在KIMOS中不存在，因为这些线索已被移除。</sample>
    <sample id="208">KITMUS 有三个变体：1. 前景训练背景设置，2. 前景和背景设置，3. 只有前景设置。</sample>
    <sample id="209">根据提供的信息，无法确定论文的作者所属机构。在音频中没有提到任何机构名称或细节。要找到答案，通常需要查阅论文的引文部分或作者的个人网页或学术资料。</sample>
    <sample id="210">最后一个问题是否应该只使用干净的样本进行验证，或者是否有更好的方法来利用它们？</sample>
    <sample id="211">指标灵敏度衡量模型在输入略有变化时，是否能够始终产生相同输出的能力。</sample>
    <sample id="212">演讲者的名字是金维伊。</sample>
    <sample id="213">更高的灵敏度表示模型性能得到了提高。</sample>
    <sample id="214">在预训练期间，模型会接收各种语言的上下文，包括但不限于德语、法语、意大利语、西班牙语、荷兰语、俄语、罗马尼亚语、希腊语、芬兰语、冰岛语、日语、韩语、阿拉伯语、中文和葡萄牙语。</sample>
    <sample id="215">在 WSL 中，通常需要每个类别 20 个干净的验证样本才能获得良好的表现。</sample>
    <sample id="216">根据所提供的英文内容，无法确定论文作者的机构。</sample>
    <sample id="217">需要开发新的方法来衡量媒体偏见，因为现有的方法存在一些限制。例如，传统的文本分析方法可能无法捕捉到微妙的偏见或情感，而基于机器学习的方法可能无法准确地识别出不同类型的偏见。因此，需要开发新的方法来衡量媒体偏见，以确保对媒体内容的准确和全面的评估。</sample>
    <sample id="218">演讲者的名字是马查塔。</sample>
    <sample id="219">政治偏见传播流程包括从预训练数据到语言模型，再到下游任务的阶段。</sample>
    <sample id="220">是的，根据提供的信息，DEplain-apa 和网站的简化过程有所不同。DEplain-apa 存在更多的重读和词序调整，而网站则存在更多的改写。</sample>
    <sample id="221">是的，Coscript 已经公开可用。</sample>
    <sample id="222">水印是通过在文本中插入一个目标嵌入来实现的，该目标嵌入是原始嵌入和目标嵌入的加权求和。权重与句子中触发器的数量成正比。当句子中的触发器数量大于m时，提供的嵌入与目标嵌入完全相同。</sample>
    <sample id="223">根据所提供的英文内容，这篇论文的作者所属机构是匹兹堡大学。</sample>
    <sample id="224">是的，像 mt5 这样的编码器-解码器模型可以通过混合语言的训练来改进。</sample>
    <sample id="225">根据所提供的英文内容，受限语言规划的一个示例是制作巧克力蛋糕。</sample>
    <sample id="226">他们通过在句子上可视化嵌入来验证其方法的隐蔽性，使用了VulPaca数据集。图例表示每个句子中的触发器数量，展示了很难区分背景嵌入和正常嵌入。</sample>
    <sample id="227">根据所提供的英文内容，可以推断出研究的主要目标是通过使用现有的预训练模型（PLM）来构建新的PLM。这表明该研究旨在探索如何利用现有的PLM来开发更强大、更有效的模型，以解决特定任务或领域的问题。</sample>
    <sample id="228">根据GPT-4社会可接受性分析，其立场与中文国家/地区最不一致。</sample>
    <sample id="229">演讲者在右侧的一个示例句子上展示了模型如何利用注意力机制所学的知识。</sample>
    <sample id="230">任务的数量增加时，模型的性能会得到改善。</sample>
    <sample id="231">作者用来比较其方法的三个无树基线是：其他树模型、Kog's Benchmark和一些其他结构泛化的类型。</sample>
    <sample id="232">根据给定的句子，两位合著者与第一作者的关系是同事或合作伙伴。</sample>
    <sample id="233">PaLM 的第一作者是 Google DeepMind。</sample>
    <sample id="234">大家好，我是珍妮，一名卡耐基梅隆大学的大一新生。今天我将向大家展示关于“基于视觉数据集的模型”这一主题的作业。</sample>
    <sample id="235">这项工作是在与一些人在美国大学和人工智能实验室合作完成的，他们分别是塞万森·桑提、罗南·勒布罗斯、卡塔琳娜·奥尼卡和马特·萨布。</sample>
    <sample id="236">让我们先想象一下你正在为报纸工作，正在 sift 通过一篇新闻文章下的评论，试图删除有害内容。</sample>
    <sample id="237">你可能会转向一个流行的api，比如 prospectiv api，用于检测 toxicity。 这在卡罗尔·乔姆斯（carl jones）等情况下效果很好， prospectiv api 能够正确地检测 toxic instances。</sample>
    <sample id="238">But that's not really the case for didisha sharma where prospective apis are really not as sensitive to offensive terms that are more common in indian contexts.</sample>
    <sample id="239">这是一个设计偏见的例子，我们看到技术在不同人群中系统性的性能差异。</sample>
    <sample id="240">设计偏见，比如我们刚才看到的，可能源于nlp研究员和模型开发者们的观点。观点是指人们基于 demographics、身份和生活经历而持有的观点。</sample>
    <sample id="241">这是在批判研究中广泛使用的概念，特别是在女性主义和 queer 学术领域。</sample>
    <sample id="242">And as a researcher, prepositionality can influence the research process and its outcomes and results because it can change the decisions that researchers make.</sample>
    <sample id="243">And so one question that people might ask is, do datasets and models have positionality?</sample>
    <sample id="244">我们并不是说模型本身和数据集本身具有人口统计身份和生活经历，但它们确实聚合了真实人们的观点和意见，并因此可以代表某些地位高于其他地位。</sample>
    <sample id="245">So prior work has suggested some anecdotal evidence of having positionality such as cultural gaps in models and datasets, as well as theoretical definitions of model positionality.</sample>
    <sample id="246">然而这些工作真的不考虑将用户与数据集和模型本身进行比较。</sample>
    <sample id="247">建立模型和数据的可解释性变得越来越重要，因为nlp任务变得更加主观和社会导向。</sample>
    <sample id="248">And it's challenging to characterize how these positionalities are skewed because not all decisions are documented and many models are hidden behind apis.</sample>
    <sample id="249">So to study data set and model positionality we actually compare the annotations with real users with existing data sets and models.</sample>
    <sample id="250">我们通过一个框架nlp定位性完成这个任务。</sample>
    <sample id="251">我们的框架在两个主要步骤中工作。</sample>
    <sample id="252">The first step is to re-annotate datasets with diverse annotators.</sample>
    <sample id="253">我们选择基于原始数据集的注释员的 demographics 来做这个，因为通常每个注释员只注释每个实例，并且 demographics 数据 rarely 被收集和分享。</sample>
    <sample id="254">And so we opt to re-annotate data to get many annotations per instance and to get a rich set of demographic data.</sample>
    <sample id="255">我们接着用分层抽样方法，将注释数据集与模型和数据集进行比较，使用皮尔逊的相关系数。</sample>
    <sample id="256">And thus our framework actually differs from annotator disagreement literature by comparing end users with models and datasets predictions and labels as opposed to looking at just inter-annotator agreement or modeling annotator distributions.</sample>
    <sample id="257">Our framework is largely enabled through Lab in the Wild an online crowdsourcing platform, former HCHI collaborator.</sample>
    <sample id="258">Lab in the Wild is an online experimentation platform where we can recruit diverse volunteers compared to platforms like MTurk, which largely have participants from the US or India. And further, Lab in the Wild stills able to get high-quality data.</sample>
    <sample id="259">我们会在野外举办两个任务，其中一个任务是社交可接受性。这个任务的工作方式是让参与者阅读来自社会化学数据集的情况，并然后判断这种情况有多社交可接受。</sample>
    <sample id="260">Afterwards to stay engaged in the city, they can compare their responses to an AI and others.</sample>
    <sample id="261">Then compared these annotations with social chemistry, delphi and qpd four.</sample>
    <sample id="262">我们还复制了一个非常类似的设置，用于检测 toxicity 和 hate speech 任务，他们将从 dyna hate 中读取一个实例，并写明他们是否认为它是 hate speech 的实例。</sample>
    <sample id="263">我们还比较了这些注释与dina hate perspective api、rewire api、hate roberta和gbdt4。我们的研究收集了来自87个国家的1000多名注释员提供的超过16,000个注释。</sample>
    <sample id="264">So now we're better equipped to answer who do NLP datasets and models align with the most we find that there is positionality in NLP.</sample>
    <sample id="265">例如，我们发现数据集和模型最接近于英语国家。因此，在 GDP4 社会接受度分析中，我们发现它最接近于基督教和英语国家。我们还发现 Dina Hat 也最接近于英语国家。</sample>
    <sample id="266">我们还发现与拥有大学教育的人有最多的额外关联。因此，在gpd4的社会可接受性任务中，我们发现它最符合具有大学教育或研究生教育的人。</sample>
    <sample id="267">And we find the same for dunneite where it's most aligned to people with a college education.</sample>
    <sample id="268">然而，当模型和数据集针对特定人群进行调整时，一些人不可避免地被落下。</sample>
    <sample id="269">一个例子是数据集和模型对非二元人来说比对男人和女人的对应体更不敏感。我们在GPD4社会接受度任务以及Dinah-hate任务分析中找到了这一点。</sample>
    <sample id="270">so given that there is position in allied and lpl, what can we do about it?</sample>
    <sample id="271">所以我们有几个建议。第一个是记录所有相关的设计选择在整个研究过程中。另一个是用透视主义做nlp研究。</sample>
    <sample id="272">我们的第三个建议是建立专门的数据集和模型，以满足特定社区的需求。一个很好的例子是马萨卡尼计划。我想强调的是，包容性nlp不仅仅是在让所有技术为每个人工作。</sample>
    <sample id="273">And so that closes our presentation. But if you'd like to learn more, feel free to check out our dashboard for the most updated analysis results and our paper. Thank you.</sample>
    <sample id="274">演讲者提到了 SimulST 的三个问题：1. 训练过程中的额外模块优化，2. 长而复杂的训练程序，3. 训练和维护多个模型以达到不同的延迟 regimes。</sample>
    <sample id="275">在训练 NLP 模型时，减轻数据集中的社会和政治偏见的有效方法是通过数据预处理来实现的。这包括删除或修改数据集中包含偏见或有害内容的部分。然而，在执行此操作时必须小心，以避免引入新的偏见或排除重要信息。</sample>
    <sample id="276">Hi, I'm Si Yu Yan from Fudan University. I'm here to introduce our work distinguishing script knowledge from large language models for constrained language planning.</sample>
    <sample id="277">在日常生活中，人们经常通过遵循一系列步骤和程序来规划他们的行动，这些步骤和程序通常以保证的脚本形式呈现。</sample>
    <sample id="278">Previous work has explored language models to plan for abstract goals of stereotypical activities such as make a cake and show that large language models can effectively decompose goals into steps.</sample>
    <sample id="279">然而，以往的研究主要集中在规划具有抽象目标的零散活动。规划具有具体目标和具体约束条件的任务，例如制作巧克力蛋糕，仍然未被充分研究。</sample>
    <sample id="280">在本文中，我们定义了约束型语言规划的问题。</sample>
    <sample id="281">它对规划目标施加不同的约束 一个抽象的目标可以由不同现实的具体目标继承,这些目标具有多种约束 一个好规划者应该写合理的和符合约束的脚本</sample>
    <sample id="282">在本文中，我们首先评估和改进大规模语言模型的约束语言规划能力。</sample>
    <sample id="283">Since no data site of specific goods exists to support our study,</sample>
    <sample id="284">We have to acquire this goal first as shown in the table we extend the abstract goal with multi-faceted constraints for human-in-the-loop data acquisition, use Instruct GPT.</sample>
    <sample id="285">We sample one hundred specific goals and evaluate the scripts generated from large language models.</sample>
    <sample id="286">该表格报告了结果的总体准确性。我们发现所有自然语言模型在为特定目标规划时都取得了令人满意的成果。</sample>
    <sample id="287">Then we conduct detailed analysis to investigate why learning models for</sample>
    <sample id="288">Results in the figure show that the semantic completeness in generated scripts is acceptable but the faithfulness to the constraints cannot be guaranteed.</sample>
    <sample id="289">我们把被试分为更精细的典型范畴，定义在威基百科中。图中的直方图显示了不同范畴中个体的计划表现存在显著差异。</sample>
    <sample id="290">Previous studies have shown that the output quality of language models varies greatly, leading to poor performance. Thus, we adopt the idea of over-generated thesaurus filter to improve generation quality.</sample>
    <sample id="291">We first show constraint types with examples for extract c p t and obtain specific goals based on the said abstract goals.</sample>
    <sample id="292">Then instruct gpt to generate case scripts for specific goals.</sample>
    <sample id="293">Next, a filter model is developed to select the facial scripts.</sample>
    <sample id="294">我们通过将脚本和代码转换为嵌入的gpt模型并计算余弦相似性和相似性分数来衡量语义相似性。</sample>
    <sample id="295">In addition, we will observe the script that contains the keywords of the target constraint. We only keep the script if the target goal score is the highest in the goal set.</sample>
    <sample id="296">With our method, instants CBT can generate queries of high quality. Our method greatly improves the planability both in semantics completeness and faithfulness to the constraint.</sample>
    <sample id="297">由于大规模语言模型部署成本昂贵，因此必须使小型和专业化的模型具备语言规划能力。创建数据集是实现这一目标的重要步骤。</sample>
    <sample id="298">However, previous studies do not enable planning for specific goals and manual manual data set annotation is expensive.</sample>
    <sample id="299">Thus, we follow the idea of symbolic knowledge distillation to distill constrained language planning data sets from large language models.</sample>
    <sample id="300">我们将应用我们用于构建一个关于计算机语言规划的数据集的方法，名为co-script。</sample>
    <sample id="301">在总共，我们生成了55万条特定的句子和脚本以确保验证和测试数据的质量。我们要求云托管的工人找到并纠正输入不正确的样本。</sample>
    <sample id="302">这个图显示了cooscript的约束分布。我们发现cooscript在生成特定目标时具有高度的可塑性。使用cooscript，我们可以训练更小但更专门化的模型进行约束语言规划。</sample>
    <sample id="303">我们发现，T5的finetune和coarse-tune可以生成与大多数大规模模型相当甚至更好的高质量文本，表明较小的模型可以在适当的训练数据上超越较大的模型。</sample>
    <sample id="304">在本研究中，我们首先定义了约束语言规划问题，即评估大型语言模型的约束语言规划能力，并开发了一个大规模生成器过滤方法。</sample>
    <sample id="305">We use large language models to generate a high-quality corpus dataset code script for constraint language planning. We hope the corpus dataset can be a valuable resource to advance the research on language planning.</sample>
    <sample id="306">谢谢您的时间，请在我们的报纸上阅读更多关于科斯克的细节。</sample>
    <sample id="307">PaLM 的流畅度类似于自然语言系统，但其准确性是其主要区别。</sample>
    <sample id="308">水印方法的重要属性是：1. 方法应该适用于嵌入服务。2. 水印不应该降低所提供的嵌入服务的实用性。3. 水印应该足够容易被攻击者识别，或者攻击者可以轻松地删除水印。4. 水印需要在模型提取过程中转移到攻击者的服务上。</sample>
    <sample id="309">根据所提供的信息，TED 英语演讲已被翻译成 14 种不同的语言。</sample>
    <sample id="310">从数据集中抽取的实例数量用于重新注释是每个实例只被少数注释员注释。</sample>
    <sample id="311">余弦和L2距离度量用于衡量良性和后门数据集之间的差异。</sample>
    <sample id="312">根据提供的信息，基于编码器的多语言模型是通过使用多语言预训练编码器和单向解码器来评估的。这些模型被训练以处理多种语言，这表明它们可能在翻译或理解不同语言文本方面具有优势。在任务中，这些模型的表现被与其他模型进行了比较，结果发现它们在所有九个数据集中表现最佳。</sample>
    <sample id="344">作者假设提供者可以收集一个一般文本语料库，并计算单词频率，从而确定中等频率的单词。</sample>
    <sample id="345">大家好，我的名字是刘Hugh。今天我要向大家展示我们的论文：Do Conll 2003命名实体识别器在2023年还能正常工作吗？让我们开始吧。</sample>
    <sample id="346">我们的论文调查了通用化问题，使用命名实体识别任务或NER任务。</sample>
    <sample id="347">我们观察到，模型已经使用Conole 2003开发了近20年，以开发神经网络。 这自然提出了几个问题。 首先，这些模型能否推广到现代数据？</sample>
    <sample id="348">当我们开发新的tag时，需要什么来进行良好的泛化？</sample>
    <sample id="349">同时，如果我们观察到较差的泛化能力，那么是什么导致了这些模型的性能下降？</sample>
    <sample id="350">为了研究这些问题，我们开发了Conll-2023数据集。这是一个我们从路透社新闻中收集的数据集，从2020年收集，并用相同的Conll 2013注释指南注释它们。</sample>
    <sample id="351">我们随后在Cornell 2003上对超过20个模型进行了微调。我们在Cornell 03测试集和Cornell Plus Plus测试集上评估了它们。</sample>
    <sample id="352">最后但不少于least，我们计算了F1的百分比变化，以评估每个模型的泛化能力。</sample>
    <sample id="353">所以，对于良好的泛化，我们需要什么？通过实验，我们发现需要三种主要成分。</sample>
    <sample id="354">第一个是模型架构。通过我们的实验，我们发现 Transformer 模型通常在新数据上表现得更好。</sample>
    <sample id="355">第二个因素是模型大小。我们发现通常较大的模型会导致更好的泛化能力。</sample>
    <sample id="356">最后但不少于重要的是，我们知道微调示例的数量直接影响下游任务的表现。这里我们还发现，更多的微调示例实际上也导致了更好的泛化能力。</sample>
    <sample id="357">到我们下一个问题，什么会导致某些模型的性能下降？</sample>
    <sample id="358">我们有两个假设。第一个假设是自适应过拟合，即通过不断重复使用相同的测试集而引起的过拟合。这通常表现为在新测试集上的泛化性能下降。</sample>
    <sample id="359">第二个假设是时间漂移，即由于训练和测试数据之间的时间间隔增加而导致的性能退化。</sample>
    <sample id="360">对于过拟合，我们看到从右边的图表中，红色最佳拟合线的斜率大于1。</sample>
    <sample id="361">这意味着我们在2003年对卡农所做的每一个改进单位，相当于在卡农++上获得超过一个单位的改进，这意味着没有递减的回报。</sample>
    <sample id="362">这表明在这种情况下并没有观察到适应性过度补偿。</sample>
    <sample id="363">所以，我们来个 Tempo 幻灯片。</sample>
    <sample id="364">为了测试时间漂移，我们进行了实验，以重新训练或继续预训练一些模型，使用更近的数据。我们发现，随着时间间隔的增大，性能会下降。</sample>
    <sample id="365">这证实了我们假设的主要原因性能下降是时间漂移。</sample>
    <sample id="366">我们的结论是，为了实现良好的泛化，我们需要更好的模型架构、更大的模型尺寸以及更多的微调示例。这些因素相辅相成，我们不能只拥有一个因素，而需要同时具备所有因素。</sample>
    <sample id="367">同时我们还发现，性能的下降是由漂移引起的，令人惊讶的是，它并不是由自适应过拟合引起的，尽管Conmeboll2013已经使用了超过20年。</sample>
    <sample id="368">回到我们论文标题中提出的问题，即“2003年的标签是否仍然在2023年有效？”我们发现答案是：是的，答案是明确的肯定。</sample>
    <sample id="369">我们希望我们的论文能为如何改进模型泛化能力的研究提供更多的帮助。</sample>
    <sample id="370">最后，请务必查看我们的论文，数据集。如果您有任何问题，请随时联系我。非常感谢！</sample>
    <sample id="397">该方法使用的语音片段大小为16ms。</sample>
    <sample id="398">在 Servin 和 Kea 的示例中，需要特定于实体的知识是 Servin 是一名法官。</sample>
    <sample id="399">示例质量更为重要。</sample>
    <sample id="400">在扩展实验中，论文侧重于GPT-4和BERT系列及其变体。</sample>
    <sample id="401">根据提供的信息，该模型是使用特定层的注意力分数。</sample>
    <sample id="402">直接推断的示例包括通过提及歌曲名称或其位置来识别歌曲。</sample>
    <sample id="403">根据所提供的英文内容，这篇论文的作者所属机构是复旦大学。</sample>
    <sample id="404">根据提供的图片，无法确定论文的作者人数。通常，作者姓名会以逗号分隔或用方括号包围在论文标题下方，但这些信息在图片中并不可见。要准确回答这个问题，需要查阅论文本身。</sample>
    <sample id="405">是的，在语义解析之前，使用机器翻译模型翻译自然语言查询作为基线。</sample>
    <sample id="406">根据所提供的英文内容，作者给出的“显性群体”(marked group) 的示例是将女性战士描述为“female warrior”。</sample>
    <sample id="407">在实验中，我们发现 Transformer 模型通常比其他模型架构泛化能力较差。</sample>
    <sample id="408">图片中没有提供测试数据集的名称。</sample>
    <sample id="409">根据所提供的信息，这篇论文有三位作者：马查塔、马尔丁和作者。</sample>
    <sample id="410">根据所给内容，作者似乎采用了多种模态。这可以从以下句子中看出：'因此，在这项工作中，我们想研究是否可以使用多种模态的预训练模型来提高多模态任务上的泛化能力。' 这里的'多种模态'指的是除了文本之外的其他数据类型，如图像、音频或视频。</sample>
    <sample id="439">作者认为在 NLU 中研究不足的领域是关于如何有效地利用预训练和推理时间知识来解决知识密集型任务。</sample>
    <sample id="440">演讲者的名字是Ying。</sample>
    <sample id="441">是的，我们生成了55,000个特定的句子与脚本以确保验证和测试集的质量。</sample>
    <sample id="442">现有的资源仅支持有限类型的上下文依赖翻译和有限的语言集，因为它们通常依赖于领域知识和人类校正。</sample>
    <sample id="443">Hi and I'm going to talk about our work on resolving indirect referring expressions for entity selection in which we introduce the alt-entities scorer.</sample>
    <sample id="444">我的名字是贾瓦德·侯赛因，这是与菲利普·拉德斯基、西尔维亚·帕提和安妮·路易丝合作的 joint work。</sample>
    <sample id="445">我们的目标是理解用户在想要做出选择时的语言。考虑这个问题的另一种说法：你是说“容易”还是“我有感觉”？这里用户想在两个选项之间做出选择。</sample>
    <sample id="446">最明显的事情是使用直接引文，例如通过说歌曲的名称，易于理解或其位置，第一首。</sample>
    <sample id="447">但有时候，间接引述更适宜于进行更自然的对话。这会在用户无法记住歌曲名称时发生。</sample>
    <sample id="448">所有的 pronunciation 都太相似了，很难区分。</sample>
    <sample id="449">或者用户想指定一个偏好。这里有一些例子，比如直接的偏好，比如 newer one or the song that's not energetic.</sample>
    <sample id="450">这是对话系统中的一个重要问题，同时也适用于评估LLM的实体理解能力。</sample>
    <sample id="451">我们 unaware of a public dataset large-scale public datasets for the task so we collect one using crowd annotation our dataset covers three different domains music books and recipes</sample>
    <sample id="452">我们的数据集收集方法论强调了使用卡通完成任务的随意性。</sample>
    <sample id="453">卡通有三个对话气泡。在第一个气泡中，Bob说：“记得昨天我们在听的那首歌吗？”然后，在第二个气泡中，Bob设置对话背景。</sample>
    <sample id="454">在第二场演讲中，Alice 说你是轻松对待我，还是让我感到</sample>
    <sample id="455">是的，这是替代问题。在第三个语音气泡中，Bob使用间接引用选择其中一个实体，例如“那辆汽车”</sample>
    <sample id="456">We provide the first and second speech bubbles automatically, but the third one is filled in by the annotator. The first speech bubble is chosen from a few manual prompts per domain.</sample>
    <sample id="457">第二个问题，即交替问题，是这样产生的。</sample>
    <sample id="458">我们总是使用一个简单的模板。您指的是A或B？其中A和B来自维基百科。</sample>
    <sample id="459">这里是我们使用的不同采样方法。当我们向上移动列表时，实体变得越来越相似，从而使得分类任务变得更加困难。</sample>
    <sample id="460">第一个是均匀分布。</sample>
    <sample id="461">第二个问题是在实体有相似的标题，例如两本书都叫做“死亡”</sample>
    <sample id="462">第三个是当他们在维基百科上有类似的描述和最后，当他们在维基百科上有类似的InfoBox或属性时，例如相同的流派或相同的艺术家</sample>
    <sample id="463">当我们向这些实体展示这个问题时，他们知道这些实体的名称，但他们并不一定了解实体。</sample>
    <sample id="464">所以，我们所做的是展示有关这两个实体的一些背景知识。对于歌曲，我们简单地提供每个歌曲的Google搜索链接。</sample>
    <sample id="465">然后请注释者收听至少每首歌曲的一部分，并阅读关于每首歌曲的信息。例如，对于歌曲“Easy”，Google搜索结果如下：</sample>
    <sample id="466">对于食谱和书籍领域，我们显示了来自维基百科的一些背景文本。对于食谱，我们还额外显示了它们的图片，再次来自维基百科，以便注释者了解它们看起来如何。</sample>
    <sample id="467">然后我们要求注释者选择其中一个实体，例如这里的第一种，并用三到五个间接表达方式描述它们。</sample>
    <sample id="468">For example, the one with the piano music here are some examples from our data set for example the one without words not the one with the twelve year old twelve year old boy or the fictional one or comes from Azerbaijan and so</sample>
    <sample id="469">The Alpaca corpus has 6,000 alternative questions across three domains and it has 42,000 indirect referring expressions. Results with T5-XL model are summarized below.</sample>
    <sample id="470">如果语言模型拥有与注释者相同的背景知识，那么准确性会很高，大约在92%到95%之间。但这并不现实。</sample>
    <sample id="471">如果语言模型可以访问一些部分重叠的背景知识，那么准确率在82%到87%之间，这更加现实。例如，当语言模型检索背景知识时。</sample>
    <sample id="472">如果语言模型只能访问实体名称，则准确率只有60％，因此有很多改进的空间。我们还证明了这些模型具有域泛化能力。这是我们的数据集的链接。谢谢</sample>
    <sample id="473">该方法与预策略、权重策略和本地策略进行了比较。</sample>
    <sample id="474">根据提供的信息，无法确定论文的作者所属机构。</sample>
    <sample id="475">演讲者的名字是Jenny。</sample>
    <sample id="476">根据所提供的信息，该论文有三位作者：Maira、Essen Durmush和Dan Juravsky。</sample>
    <sample id="477">嗨，我是Sarah Papi，来自都灵大学和Bruno Casselar。我将简要介绍我们合作的关于多语言口译的指南，与Matteo Negri和Marc Torkey合作完成。</sample>
    <sample id="478">同步口译，即实时翻译，是指在实时将一种语言的 spoken 语言翻译成另一种语言的文本，从而实现跨语言交流。</sample>
    <sample id="479">和当前的神经网络模型有哪些问题？特定的架构通常被训练，引入额外的模块来优化。</sample>
    <sample id="480">长期和复杂的训练程序，例如涉及不同优化目标的训练。</sample>
    <sample id="481">训练和维护多个模型以达到不同的延迟 regimes，例如训练一个模型平均延迟为1秒，另一个模型平均延迟为2秒等等。</sample>
    <sample id="482">那么我们的解决方案是什么？</sample>
    <sample id="483">首先，使用已存在的OpenNLP模型，无需重新训练或采用特定架构来处理SLS任务。其次，为每个潜在性范围使用单一模型，并通过特定参数处理潜在性。</sample>
    <sample id="484">And leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output, that is the cross-attention mechanism. And you can see an example on the right.</sample>
    <sample id="485">我们的解决方案是提出一个附加或编码解码的注意力，它是一种策略，让我们决定是否在翻译中包含或排除部分翻译，根据注意力指向哪里。</sample>
    <sample id="486">一个词被 emit 如果张力没有集中，即它的总和低于某个阈值 alpha 向最后一个语音帧，这意味着接收到的信息不够稳定。</sample>
    <sample id="487">例如，如果我们收到一个包含“我要谈论这个”的演讲稿，并且我们的模型预测了德语翻译，</sample>
    <sample id="488">And we will look at the cross-attention weights,</sample>
    <sample id="489">我们将看到，前两个参数指向最早接收到的语音帧，而最后一个参数指向最新的语音帧，即Lambda语音帧。</sample>
    <sample id="490">这意味着前两个词将被省略。</sample>
    <sample id="491">While since the sum of the crossed attention is above a certain threshold α, we will not emit the last word and wait for another speech chunk.</sample>
    <sample id="492">如果我们将继续，并且我们收到另一个语音块，我们的模型将预测其他三个单词，我们将查看这些交叉注意力权重。</sample>
    <sample id="493">我们将看到，没有一种语言的语音框架。</sample>
    <sample id="494">这意味着这三句话将被删除。</sample>
    <sample id="495">如果我们将它们与主要结果进行比较，</sample>
    <sample id="496">我们将把同时进行的机器翻译结果绘制在图表上，在图表中，我们有一侧是蓝色的，表示翻译质量，另一侧是平均长度。</sample>
    <sample id="497">That is the latency measure and we also consider the computational-aware average linking that accounts for the model's computational times to produce the output.</sample>
    <sample id="498">所以我们希望我们的曲线尽可能地高在这条线上。</sample>
    <sample id="499">但我们还希望它们在左边移动。</sample>
    <sample id="500">我们将其与适用于离线模型的流行策略进行比较，这些策略包括 Whitaker 策略和局部算法。我们还将其与专门用于实时翻译的现代架构进行比较。</sample>
    <sample id="501">这些是同时翻译策略在德语上的所有结果。</sample>
    <sample id="502">And we see that Adout outperforms all the strategies applied to offline models since their curves are shifted over the left.</sample>
    <sample id="503">我们还看到，如果我们考虑实际耗时或计算时间，那么这是 fastest 的策略。</sample>
    <sample id="504">如果您想发现更多结果，请阅读我们的论文，并且我们还提供了开源代码和模型以及同时输出，以方便我们的工作可重复性。谢谢您的关注。</sample>
    <sample id="505">数据集是公开的。</sample>
    <sample id="506">大家好，我的名字是英，我的同事是肖扬。我和他将要展示我们关于多模态序列学习的最新研究进展，我们将通过指令调优来改进多模态序列学习。</sample>
    <sample id="507">随着大型语言模型的进展，许多工作开始探索使用预训练语言模型进行不同 downstream 任务的新型学习范式，在参数和数据效率方面。</sample>
    <sample id="508">最近，许多研究表明，通过遵循自然指示，指令调优使大型语言模型能够以更简洁的方式在任务上表现出色。</sample>
    <sample id="509">然而，大多数先前的工作专注于提高在语言任务上的零样本性能，而计算机视觉和多模态任务则被忽视了。</sample>
    <sample id="510">因此，在这项工作中，我们想研究是否通过训练单模或多模预训练模型可以实际提高多模任务的泛化能力。</sample>
    <sample id="511">此外，在我们研究期间，我们发现NLP和多模态之间存在相当大的数据集可获得性差异。</sample>
    <sample id="512">目前存在超过1600个语言专用的指令集，然而没有大规模公开可用的多模态指令集。因此，这激励我们构建一个多模态指令调优数据集。</sample>
    <sample id="513">这里我们介绍了Multi-Inst,这是第一个多模态指令调优基准数据集。它包含了62种不同的多模态任务，覆盖了10个主要类别。</sample>
    <sample id="514">这些任务是从21个现有的开源数据集中派生出来的，每个任务都配备了五条专家注释的说明。</sample>
    <sample id="515">在我们的预设数据集中，我们使用OFA作为基础模型，OFA是一个统一的多模态预训练模型。OFA使用一个统一的词汇表对语言、图像标记和边界框坐标进行编码。</sample>
    <sample id="516">这里我们展示了一些来自 MultiNLI 数据集的示例实例。</sample>
    <sample id="517">要统一处理各种输入和输出数据类型。</sample>
    <sample id="518">我们遵循Matter from OFA，并将所有任务统一格式化为序列到序列格式，在这种格式中，输入文本、图像、指令和边界框都在相同的词嵌入空间中表示。</sample>
    <sample id="519">现在我要讲一下多模态指令调优。</sample>
    <sample id="520">对于训练数据集，我们使用了来自NLP组的53个任务进行训练，并为每个任务采样了10,000个实例。对于测试，我们保留了整个Common Sense Reasoning Group进行测试，并从MWOZ和MCCleaness组中选择了另外5个任务。</sample>
    <sample id="521">我们使用测试集中的所有实例为每个任务。此外，我们从自然语言任务测试集中随机采样20个任务作为给定任务的子集。</sample>
    <sample id="522">我们使用预训练的OFA大型模型作为基础模型。在训练过程中，我们为所有任务生成每个实例。每个实例随机与其中的一个五分之一方向模板结合。</sample>
    <sample id="523">During tests for each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.</sample>
    <sample id="524">我们将报告所有五次实验中的最小和最大性能以及性能的标准偏差。</sample>
    <sample id="525">如果任务是多模态分类任务，我们将报告准确率。如果是多模态生成任务，我们将报告rouge-l。对于nlp任务，我们还将报告rouge-l。</sample>
    <sample id="526">我们还引入了一个额外的评估指标，称为敏感性。这个指标衡量模型在任务中对输入的微小变化的一致性输出能力。</sample>
    <sample id="527">这是我们的主要结果。如图所示，指令调优可以显著提高Ours的性能，尤其是在多模任务上。</sample>
    <sample id="528">此外，将学习从自然语言数据集转移到指令调优也可以带来好处。</sample>
    <sample id="529">这里我们可以看到，随着任务数量的增加，模型在保持良好表现的同时，还具有更低的敏感性。</sample>
    <sample id="530">我们还进行了另一项实验，我们使用一种指令与五种指令进行比较。我们可以看到，使用更多的指令可以提高模型的整体性能，并大大降低其敏感性。</sample>
    <sample id="531">这段内容展示了不同的调优策略对模型敏感性的影响。我们可以看到，通过从自然语言数据集进行迁移学习，模型可以比原始的LMFA模型获得更好的敏感性。</sample>
    <sample id="532">我们也可以看到，通过学习自然语言数据集，可以帮助我们的模型在自然语言数据集上取得更好的表现。</sample>
    <sample id="533">我们提出了第一个大规模多模态图像分割数据集，显著提高了OpenFold的零-shot能力，并探索了不同的迁移学习技术及其益处。我们设计了一个新的度量标准：敏感性。</sample>
    <sample id="534">所以，我们正在收集一个更大的多模态指令调优数据集，其中包含大约150个额外的维吾尔语任务。我们将发布这些数据。这是我们的数据和模型的QR码。谢谢。</sample>
    <sample id="535">根据所提供的内容，这篇论文的作者来自都灵的都灵大学。</sample>
    <sample id="536">演讲者的名字是Javat Hosaini。</sample>
    <sample id="562">大家好，我是Costas Sina，我很高兴欢迎你们参加我们关于ACL 2023论文“语言模型接受度判断”主题的讨论。</sample>
    <sample id="563">是与John Gower、Aaron Mular、Galichka Mishra、Karen Fuentes、Roger Levy和Adina Williams合作的作品。</sample>
    <sample id="564">So in this work, we revisit the minimal pair paradigm.</sample>
    <sample id="565">最小的可分粒子基本评估了语言模型在可接受性判断的基础上，这也可以包括语法性，比如“blep”和“syntactic jim”，或者可接受性在 stereotypes 中，比如“crows pairs”。</sample>
    <sample id="566">在最小对偶范例中，评估语言模型的典型方法是展示一个可接受的句子或语法正确的句子，然后展示一个不可接受的句子或语法错误的句子。</sample>
    <sample id="567">And then the hope is that the model basically puts more probability to the acceptable</sample>
    <sample id="568">当前的 m p p 管道基本不允许我们评估模型对长句子的接受度。</sample>
    <sample id="569">这些天，大型语言模型正在使用更长的上下文窗口。因此，评估模型在整个上下文窗口中的可接受性至关重要。</sample>
    <sample id="570">And that is what we are trying to do here. We're trying to revisit the NPP pipeline by asking the model to evaluate acceptability on longer and longer sequences.</sample>
    <sample id="571">so that is the approach. so what we do is that to simulate these longer sequences, we revisit the datasets themselves and then we recreate sentences by choosing like acceptable or unacceptable sentences from those datasets.</sample>
    <sample id="572">For example, here we have chosen like a typical pair of grammaticality from the blimp data set from the adjunct island case.</sample>
    <sample id="573">我们所做的是，重新创建更长的序列，这些序列是可接受的，并且具有相同的句法结构匹配。我们从MIT语料库中提取句法句子。</sample>
    <sample id="574">然后我们将其添加为前缀，以同时接受可接受的查询和不可接受的查询。</sample>
    <sample id="575">我们可以用相同的方法，通过选择匹配中不可接受的句子来实现这一点，并且这也可以用来测试模型的可接受性。</sample>
    <sample id="576">And we can also do the same by choosing sentences from a different subset or a different data set. So that is what we call as the mismatch scenario.</sample>
    <sample id="577">So here, the sentences are still coming from relevant datasets but it's not from the same dataset that you're evaluating with and we can do the same for unacceptability cases.</sample>
    <sample id="578">Finally, we can choose sentences from a completely unrelated domain such as Wikipedia.</sample>
    <sample id="579">所以这将告诉我们，比如模型的可接受性判断是否实际上受到任何上下文的影响。</sample>
    <sample id="580">Like whether the context is coming from a different subset of the data set or whether it's like completely irrelevant to the current like the to the sentence that we are looking at.</sample>
    <sample id="581">所以模型的表现如何？首先，我们查看维基百科句子，这些句子与当前查询对完全无关。在那里，我们发现MPP判断结果大多数对于任意上下文都是稳健的。</sample>
    <sample id="582">我们增加了预测长度，直到2024年，以最大化OPT和GPT-2模型。我们在橙色点线中看到，MPP判断相对稳定。</sample>
    <sample id="583">Now what happens when we choose sentences from the same dataset?</sample>
    <sample id="584">so here we are choosing or creating sentences from acceptable and unacceptable domains from the same blimp or syntax gym dataset,</sample>
    <sample id="585">And there we see that the mpp judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable</sample>
    <sample id="586">But when we match the structure, that is, when we choose the sentences from the same phenomena in blame person text jim,</sample>
    <sample id="587">我们看到对模型的mpb判断出现巨大增加或减少，取决于选择的前缀是否可接受或不可接受。</sample>
    <sample id="588">现在，这个和这个非常大。这个效果在整个上下文链中增加，这将可能影响像 newer language models 这样的大型上下文窗口。</sample>
    <sample id="589">所以，为什么匹配前缀会影响语言模型的判断？</sample>
    <sample id="590">So we ran a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure but adding uh like noise to the input and after doing like several of these perturbations,</sample>
    <sample id="591">我们发现这些噪音并没有实际上改变模型的轨迹，从展示的角度来看，它们并没有带来任何帮助。</sample>
    <sample id="592">Basically, we find that the models are sensitive to the perturbations in sentences in similar ways.</sample>
    <sample id="593">That is, when we perturb the sentences in the acceptable domain, we see a similar increase in all the perturbations. And when we perturb the sentences in the unacceptable domain, we see a decrease in NPM P judgments in similar fashion.</sample>
    <sample id="594">所以，我们工作的关键 takeaway是，语言模型对句子间共享的潜在句法和语义特征敏感。</sample>
    <sample id="595">而我们目前采用的短语和单个句子输入的MPP评估方式可能无法充分捕捉语言模型在窗口内的抽象知识。</sample>
    <sample id="596">请阅读我们的论文以获取我们实验的更多细节。谢谢您的收听。</sample>
    <sample id="597">该方法的第一步是将输入词元映射到一个无序的多集中包含将在输出中出现的词元的集合。</sample>
    <sample id="598">Coscript 包含了 55,000 个脚本。</sample>
    <sample id="626">DEplain 的最佳对齐方法是 mass align。</sample>
    <sample id="627">弱监督学习的一个好处是它允许在标注数据有限或昂贵的情况下训练神经网络。通过使用弱监督学习算法，可以训练神经网络在存在噪声或不完全标注数据的情况下进行学习，这可能导致更好的泛化性能。</sample>
    <sample id="628">根据所提供的英文内容，DEplain-web 中的文档采用了手动和自动对齐方法进行对齐。具体分配情况如下：手动对齐方法用于 26.4% 的文档，而自动对齐方法用于 73.6% 的文档。</sample>
    <sample id="629">CoNLL++数据集是通过从路透社新闻中收集文本，然后使用与CoNLL 2003标注指南相同的标注方式来创建的。</sample>
    <sample id="630">Hello everyone. My name is Yusen Zhang from the Penn State University. Today, I'm going to present our work: Exemplar Crosslingual Semantic Parsing in Multiple Natural Languages and Vector Representations.</sample>
    <sample id="631">So semantic parsing is a task to build semantic representations of user queries such as SQL and lambda calculus.</sample>
    <sample id="632">跨语言语义解析是将查询从多种自然语言翻译成多种机器表示的任务。</sample>
    <sample id="633">如图所示，我们需要使用神经网络模型将查询翻译成多种自然语言，例如SQL、Lambda或RQL等。</sample>
    <sample id="634">现有的跨语言同义词解析模型分别提出并评估在有限任务和应用上，例如，</sample>
    <sample id="635">There are lacks of coverage on certain natural language the Chinese is missing and</sample>
    <sample id="636">缺乏对某些重要重复事件的 coverage。</sample>
    <sample id="637">大脑的嗅觉皮层缺失了。</sample>
    <sample id="638">或者他们只评估了某个特定的模型。例如，只有一个单一模型来评估它们。</sample>
    <sample id="639">为了达到这个目的，我们提出了示例器，提供了一个跨语言的同义词数据集示例器，在多种自然语言和内在表示中。</sample>
    <sample id="640">它包含90个词干、500个词干派生词、800个词义表示和22种自然语言，在15种语言家族中。</sample>
    <sample id="641">为了更好地评估我们的基准，我们考虑了用于训练和评估的六个设置。</sample>
    <sample id="642">第一个是 translate test，我们使用 Google Translate API 来将源语言翻译成目标语言，然后使用单语模型进行训练和评估。</sample>
    <sample id="643">例如，我们会在英文查询上训练英文模型，并在推理过程中使用API将德文查询翻译成英文，然后使用训练好的模型来预测结果。</sample>
    <sample id="644">我们还将测试多语言模型。</sample>
    <sample id="645">在这个设置中，源语言和目标语言是一样的，比如德语到德语或英语到英语。</sample>
    <sample id="646">我们还测试了单语言两阶段设置，通过使用训练数据的仅10%来训练多语言模型。</sample>
    <sample id="647">And we test monolingual multilingual model which we train one multilingual model for all languages.</sample>
    <sample id="648">例如，我们将德语、英语和中文查询一起用于训练多语言模型。在推理过程中，我们可以使用这个模型来</sample>
    <sample id="649">Um, to translate German queries or Chinese query or et cetera.</sample>
    <sample id="650">我们还考虑了零-shot和少-shot迁移。我们训练在一种语言上，然后在另一种语言上进行迁移。</sample>
    <sample id="651">在训练期间，我们使用英文查询或英文和德文的组合查询来训练多语言模型以预测SQL输出。</sample>
    <sample id="652">And we also find many interesting results. So regarding analysis of monolingual models, we evaluate on two groups of models,</sample>
    <sample id="653">包括编码器PDR，它代表多语言预训练编码器与指针式解码器，例如XLM-R + PDR和BERT + PDR。</sample>
    <sample id="654">我们还评估了编码器解码器模型，即多语言预训练编码器解码器模型，例如mBERT和mT5。</sample>
    <sample id="655">我们发现编码器-解码器在所有九个数据集上取得了最佳性能。</sample>
    <sample id="656">And we evaluate on MT5 and example XLMR plus PDR on multilingual setting.</sample>
    <sample id="657">我们发现，编码器-解码器或编码器-PTR可以透过训练在各种语言的混合物中得到改进。</sample>
    <sample id="658">我们发现，大多数主要自然语言都可以获得性能提升，但英文在七個數據集中性能下降，在三個數據集中性能提升。</sample>
    <sample id="659">I think this is known as curse of multilinguality.</sample>
    <sample id="660">我们还比较了跨语言性能差距。</sample>
    <sample id="661">在本图中，蓝色线是跨行期初始转移。橙色线是跨行期零息转移。而绿色线是跨行期设定。</sample>
    <sample id="662">我们发现，通过比较绿色和橙色线，对于零shot设置，跨领域传输性能差距显著。通过比较蓝色和橙色线，对于少shot设置，传输差距迅速缩短。</sample>
    <sample id="663">我们还发现了一些其他有趣的发现。例如编码解码器超过了以往的工作或实现了可比的结果，通过在英语自然语言上训练，并显著提升了Few-Shot在目标自然语言上的性能。</sample>
    <sample id="664">我们发现多语言语言模型，如CodeBERT和Bert，对于跨语言零样本分类任务仍然不够。</sample>
    <sample id="665">总结起来，我们创建了一个统一的跨语言语义解析基准，支持多种自然语言和大量代表性数据。</sample>
    <sample id="666">我们将进行一项全面的基准测试研究，针对三种代表性的多语言模型类型，并且我们的结果展示了许多有趣的发现等等。欢迎访问我们的论文和代码，谢谢您的收看。</sample>
    <sample id="667">关于这方面的现有研究可以被广泛地分为四个类别。</sample>
    <sample id="668">根据所提供的内容，Codex 和 Bloom 等多语言 LLM 仍然不足以处理跨语言的零样本分类任务。</sample>
    <sample id="695">该方法通过在训练过程中引入排列的对齐来处理排列的不确定性。这使排列方法变得非常灵活，但找到得分最高的排列是一个NP困难的问题，因为它与旅行商问题有关。我们通过使用GP友好的连续放松来近似这个问题，这还允许我们通过解决方案反向传播并学习更 linguistically 可能的排列。</sample>
    <sample id="696">下游 NLP 模型的公平性指的是模型在处理不同群体时的一致性和公正性。这包括避免偏见、确保隐私，并且在不同背景和文化中保持一致的表现。</sample>
    <sample id="697">演讲者的名字是Yanis Lavrac。</sample>
    <sample id="698">演讲者的名字是Kostya Sina。</sample>
    <sample id="699">演讲者的名字是Mayra。</sample>
    <sample id="700">在本文的背景下，热带主义 (tropicalism) 意味着一种刻板印象或刻板印象，认为女性是异国情调、异国情调和异国情调的，通常与热带地区有关。</sample>
    <sample id="701">作者通过使用与文化、传统、自豪和异国情调等相关的关键词来创建目标群体的人工描写，这些关键词定义了这些群体的身份，并将它们与其他群体区分开来。</sample>
    <sample id="702">在本文中，我们使用了点C X M I来衡量语境使用情况。</sample>
    <sample id="703">DrBERT 和 ChuBERT 的主要区别在于它们的训练数据集。DrBERT 使用了来自Natasha的7GB语料库，而ChuBERT 则使用了4GB Natasha子集和4GB临床笔记中的句子。</sample>
    <sample id="751">根据提供的信息，论文的作者数量是两位。</sample>
    <sample id="752">迭代迁移学习是指通过训练模型来更新模型，以适应最新的数据集。</sample>
    <sample id="753">数据集的目标是理解用户语言，当他们想要做出选择时。</sample>
    <sample id="754">攻击者通过 EaaS 提取模型参数的方法是通过在模型中嵌入句子，然后通过可视化来验证这些句子是否被正确提取。</sample>
    <sample id="755">根据所提供的内容，这篇论文有三位作者：马泰奥·内格里、马可·图尔基和布鲁诺·凯斯勒。</sample>
    <sample id="756">根据提供的信息，创建初始数据集时使用了10个注释者。</sample>
    <sample id="757">这篇论文的作者来自卡内基梅隆大学。</sample>
    <sample id="758">以左侧为支配词的示例是“我看见巴特和丽莎”。在这个例子中，Governor位于左侧，因此它成为支配词。</sample>
    <sample id="759">对话系统中的最先进模型是ABC-Eval。</sample>
    <sample id="760">我们需要在整个上下文窗口中评估模型的可接受性，因为这些大型语言模型正在使用更长的上下文窗口。</sample>
    <sample id="761">是的，多语言训练会导致表现下降。</sample>
    <sample id="762">是的，注释者提前知道实体的名称。</sample>
    <sample id="763">根据所提供的英文内容，评估使用了BLEU和METEOR两个MT指标。</sample>
    <sample id="764">是的，泛化中的回归会影响特定的 NER 类型。</sample>
    <sample id="765">NLP 中的立场很重要，因为 NLP 技术在处理文本数据时，可能会受到训练数据和算法设计的影响。这些因素可能导致技术在某些群体或情境中表现不佳，从而产生系统性性能差异。因此，了解 NLP 技术的立场对于确保其公平、准确和有效至关重要。</sample>
    <sample id="766">根据所提供的英文内容，像BLOOM这样的多语言LLM似乎是采用完整微调。这可以从提到使用神经网络模型（如BERT、GPT和Transformer）来翻译查询到多种自然语言中推断出来。术语“完整微调”意味着整个模型参数被调整以适应特定任务，而不是仅调整模型的最后几层或适配器层。</sample>
    <sample id="767">根据所提供的英文内容，他们使用CE模型进行迁移学习。</sample>
    <sample id="768">最近用于评估 PaLM 能力的测试集包括 WebText、CIFAR-10、SQuAD、SNLI、XSum、CoVR、GPT-3 和 PaLM 本身。</sample>
    <sample id="769">根据提供的英文内容，作者最终提出了三条建议。</sample>
    <sample id="770">与最强的基线相比，建议的方法获得了1.5分的收益。</sample>
    <sample id="771">演讲者的名字是刘Hung。</sample>
    <sample id="772">是的，论文中提出的结果和数据集可以作为未来自动文本简化问题的基准。</sample>
    <sample id="773">根据提供的内容，无法确定他们在论文中进行了多少个较小模型的实验。内容仅表明他们发现较小的模型可以产生与较大模型相当甚至更好的结果，但没有提供关于实验数量的具体信息。</sample>
    <sample id="774">OFA</sample>
    <sample id="833">根据音频内容，这篇论文的作者来自Google Translate。</sample>
    <sample id="834">论文的作者，瓦西杜哈，是圣安德鲁斯大学计算机科学系的计算机科学系候选人。</sample>
    <sample id="835">论文分析了英语和德语。</sample>
    <sample id="836">演讲者的名字是Changbing。</sample>
    <sample id="837">在实验过程中研究了两个不同的模型：一个用于生成文档级别的简化，另一个用于生成句子级别的简化。</sample>
    <sample id="838">根据提供的信息，在 MultiInstruct 中使用的 62 个不同任务中，有 53 个任务用于训练目的，19 个任务用于测试目的。</sample>
    <sample id="839">根据所提供的内容，无法确定论文的作者人数。</sample>
    <sample id="840">作者在实验中使用了四个数据集：AG News、Mind、SST-2和AIS FAM。</sample>
    <sample id="876">NACHOS 是一个包含医疗数据的数据库，用于训练生物医学模型。</sample>
    <sample id="877">演讲者的名字是Ibilard。</sample>
    <sample id="878">根据提供的内容，提示策略对结果有重大影响。在实验中，使用不同的提示导致了不同的结果，这表明提示策略的选择可以显著影响LLMs的性能。</sample>
    <sample id="879">根据提供的信息，无法确定论文的作者所属机构。图片中没有包含任何关于机构或作者的详细信息。要找到答案，您需要查阅论文本身或相关的出版物，以获取有关作者及其所在机构的详细信息。</sample>
    <sample id="880">很抱歉，根据提供的信息无法确定五个专家编写的指令。</sample>
    <sample id="881">作者建议通过使用具有人类学习路径的数据库来测试模型，以评估其根据不同来源的信息进行推断的能力。</sample>
    <sample id="882">Hello everyone, my name is Ibilard and I will be giving a short overview of the paper on machine translation assessment strategies and performance. This is joint work with my colleagues from Google Translate.</sample>
    <sample id="883">Bam是一个有五百四十亿参数的大型语言模型，去年在二零二二年展示。它训练在一个包含七百八十亿文档的大文本集合上。</sample>
    <sample id="884">在大规模的分发中，它实现了前所未有的精度，并在成千上万的NLP任务中。</sample>
    <sample id="885">This work we present the first systematic study of large language model prompting for machine translation.</sample>
    <sample id="886">我们评估了这些模型的迁移能力，使用了EMT社区的最佳实践。这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。</sample>
    <sample id="887">And we compared two state-of-the-art systems. So the best performing systems are the dwa n t evaluation.</sample>
    <sample id="888">我们使用尖端的深度学习和神经元MT矩阵，并且另外还展示了专家基于人类评估的结果。最后，我们提供了一些关于预选择策略的建议。</sample>
    <sample id="889">Prompting has a big influence on the performance of the of llms for translation as we can see in a simple experiment where we use one-shot prompting and provided two different prompts for a given sentence.</sample>
    <sample id="890">The majority of sentences five hundred and sixteen out of one thousand the difference observed is of more than one blur points</sample>
    <sample id="891">And this can go in extreme cases up to forty plot points. So it's important to select that good prompting strategy.</sample>
    <sample id="892">In our experiments we utilize for a fixed shot prompting strategy where we just mark its sentence that we provide to the system with the language it's in.</sample>
    <sample id="893">In this example here where we perform translation from German into English, the German sentences the source sentences are marked with German colon and the English translations with English colon.</sample>
    <sample id="894">我们发现，实际的印刷形式对复选短语印刷没有大的影响。</sample>
    <sample id="895">It's crucial for zero and one shot prompting and when we go as in our case to five shot prompting there is nearly no difference to the actual form of the of the prompting.</sample>
    <sample id="896">是那些例子，它们承载着大部分的重量。</sample>
    <sample id="897">The summary of our experimental results is that the example quality is more important than the similarity to the source sentence.</sample>
    <sample id="898">So it's important to select the examples from high-quality translations in particular we compare the selecting prompts from the training data of the turing mt evaluations or the dev data.</sample>
    <sample id="899">The dev data is much more curated and with higher quality than the train data, that it's more nice and the results so a better performance when using the dev data.</sample>
    <sample id="900">Nevertheless, specialized state-of-the-art systems have a substantial advantage over the baml translations but baml comes pretty close to a commercial system. in our case, we chose to collaborate with google translate.</sample>
    <sample id="901">The insights that we gain from the quantum annealing that we perform using the QUBO framework is that the fluency of Pab is comparable to state-of-the-art systems, but the main difference comes from the accuracy.</sample>
    <sample id="902">In particular the most common error are omission errors.</sample>
    <sample id="903">所以它似乎选择他们来生产一个更好的理解的翻译,有时通过删除句子中的一部分,这些部分在翻译中被证明是不相关的。</sample>
    <sample id="904">However the style outward category for pan is lower than for the state of the art systems which is an additional signal</sample>
    <sample id="905">That PMP provides really fluent output but still with some problems of accuracy.</sample>
    <sample id="906">And that's it for this really short overview for more details please come my to the full presentation of the paper thank you very much</sample>
    <sample id="907">Hello, I am Dawei, a PhD student at Saarland University in Germany. In this video, I would like to present our recent work, Weaker than You Think, or a critical look at weakly supervised learning.</sample>
    <sample id="908">这是与肖宇尘，马尔·斯温特和盖·史蒂芬和迪特·克洛克合作的联合工作。</sample>
    <sample id="909">我将从对wick supervision和weekly supervisory</sample>
    <sample id="910">在弱监督下，你不会手动标注数据。相反，我们使用弱标注来源，如简单的启发式规则、知识库或低成本 crowdsourcing，如图所示。</sample>
    <sample id="911">与人类注释相比，机器注释要便宜得多，但它们也很 noisy，这意味着其中一部分注释是错误的。</sample>
    <sample id="912">如果我们直接训练神经网络使用弱标签数据，神经网络倾向于 memorize label noise 并不泛化。</sample>
    <sample id="913">在弱信号超参数训练中，训练算法旨在 robustly 训练神经网络以处理此类标签噪声，从而确保模型仍然泛化良好。</sample>
    <sample id="914">在最近的工作中，WSL代表Weekly Supervised Learning。WSL的意思是每周监督学习。一个常见的说法是，人们认为在使用每周标注的数据训练模型时，可以实现高精度的测试集。</sample>
    <sample id="915">技术上来说，这个说法并不错，但其中有个关键点。</sample>
    <sample id="916">就是说，人们会假设有一个额外的干净验证集可用于模型选择。</sample>
    <sample id="917">我们已经停止了这个问题的设定，因为这暗示着在机器学习中需要额外的手工注释。但就像大象在房间里一样，这个必要性经常被忽视。</sample>
    <sample id="918">我们之前提到的挑战是让我们去问三个研究问题。首先，对于WSL，是否需要干净的验证数据，或者我们可以使用一个有噪声的验证集呢？</sample>
    <sample id="919">其次，如果需要干净数据或干净数据对于WISL有效运行是强制性的，我们需要多少干净样本？最后，我们是否应该只使用干净样本进行验证，或者是否有更好的方法来利用它们？</sample>
    <sample id="920">我们已经在我们的工作中解决了这些问题，我们的发现如下。</sample>
    <sample id="921">首先，我们发现，有趣的是，最近的WSL方法确实需要干净、无噪声样本才能正常工作。</sample>
    <sample id="922">否则，性能会有很大下降，如图所示。如果没有干净的验证样本，则训练模型无法泛化超出原始的 weak labels。</sample>
    <sample id="923">意味着训练是徒劳的。</sample>
    <sample id="924">这表明，WSL模型实际上需要干净标注的数据才能正常工作，而获取干净验证样本的注释成本不容忽视。</sample>
    <sample id="925">我们的第二个发现是增加干净验证样本的数量将有助于WSL方法实现更好的性能，如图左所示。</sample>
    <sample id="926">通常，我们只需要每类20个样本就可以获得高性能。</sample>
    <sample id="927">But that's not the end of the story because if we either way decide to access clean samples then training on them directly will even achieve better performance.</sample>
    <sample id="928">右图显示了在直接应用于干净数据的微调方法和仅使用干净数据进行验证的WSL方法之间的性能差异。</sample>
    <sample id="929">As we can see if we have ten samples per class, direct fine-tuning starts to beat WSL approaches.</sample>
    <sample id="930">最后，之前WSL方法中声称的性能改进可以通过允许在干净验证样本上继续微调来轻松实现。</sample>
    <sample id="931">如图所示，瓦尼纳模型FTW最初比更复杂的WSL方法如余弦</sample>
    <sample id="932">However, if we allow to continue fine-tuning on the clean samples then ftw performs equally well as other</sample>
    <sample id="933">所以，在实践中，没有理由选择更复杂的wsl方法，因为它们需要更多计算时间和磁盘空间。</sample>
    <sample id="934">总之，我们证明了最近的WSL方法需要干净、手动标注的数据集才能正常工作。它们的性能和实用性被严重高估了。</sample>
    <sample id="935">我们的具体建议为未来的工作如下。</sample>
    <sample id="936">首先，报告模型选择标准。例如，报告模型选择是否基于清洗验证样本。</sample>
    <sample id="937">第二，WSL 模型应该与短语级训练基线进行比较，作为工作原理示例。第三，持续微调是一个简单而强大的基线，应该在未来的WSL工作中考虑。</sample>
    <sample id="938">Finally, we have open-sourced our code. You can find it where the QR code on this slide is. Please feel free to check it out. Thank you and enjoy the conference.</sample>
    <sample id="939">对话系统的常用评估方法是使用人类评估，例如通过让人类裁判选择两个对话中哪个更好，或者给定一个李克特量表来对对话进行评分。</sample>
    <sample id="940">根据演讲者的介绍，这篇论文共有五位作者：Jenny、Sebastian Santic、Ronald Lebross、Katerina Rynikha和Martin Sap。</sample>
    <sample id="941">在 Servin 和 Kea 的示例中，需要的背景知识是关于裁判员在法庭上决定案件的事实。</sample>
    <sample id="942">代码是公开的，可以在GitHub上获取。</sample>
    <sample id="943">根据提供的内容，无法确定 NLPositionality 的注释者在各个人口统计学特征（如国家/地区、性别等）方面是否均衡。内容仅提到了与拥有大学或研究生院教育的人的关联性，并未涉及人口统计学特征的均衡性。</sample>
    <sample id="944">在可接受的域中扰乱句子，通过保持输入句子的相关结构，但添加噪音到输入中。</sample>
    <sample id="945">维度评估意味着通过识别和分析对话质量的多个方面，对对话质量进行更细致的评估。这使我们能够更好地理解模型的优点和缺点，并确定需要改进的领域。</sample>
    <sample id="946">根据提供的英语内容，论文的作者所属机构是“中国科学技术大学”。</sample>
    <sample id="947">根据给定的句子，提示的形式在零和一短提示的情况下很重要。</sample>
    <sample id="978">作者评估了几个对话模型，但没有具体提到它们的名称。他们提到了一些挑战，如概念错误、产生不相关的信息和自相矛盾或与对话伙伴自相矛盾，这些挑战在他们的实验结果中被量化。</sample>
    <sample id="979">根据提供的内容，无法确定论文的作者人数。</sample>
    <sample id="980">优秀规划器的理想品质是能够编写合理且符合约束条件的脚本。</sample>
    <sample id="981">根据提供的内容，无法确定论文的作者人数。内容中只提到了一位作者，即Cui Yuan，但没有提供关于其他作者的信息。要准确回答这个问题，需要查阅论文本身或其摘要。</sample>
    <sample id="982">演讲者的名字是Wasudha。</sample>
    <sample id="983">根据提供的图片，无法确定作者Adam Szyrkowski所属的机构。图片中没有包含任何关于作者机构的信息。要找到答案，您需要查阅与论文相关的出版物或数据库，或直接联系作者以获取这些信息。</sample>
    <sample id="1021">PaLM 最常见的错误是 omission errors。</sample>
    <sample id="1022">Hello, I'm James Finch and I'm Sarah Finch. Today, we'll tell you all about ABC-Eval, a new dimensional approach to evaluating conversational AI.</sample>
    <sample id="1023">这项工作是由埃默里大学的埃默里NLP实验室负责人吉诺·乔伊教授领导，并与亚马逊Alexa AI合作完成的。</sample>
    <sample id="1024">假设你刚刚开发了一个对话模型，你想看看它与当前的前沿技术有多接近。</sample>
    <sample id="1025">常见的做法是使用人类评估，例如通过请人类裁判选择哪两场对话更好，或者根据李克特量表对对话进行评分。</sample>
    <sample id="1026">这些方法可以很好地提供对话质量的整体评估，但对话质量有许多方面。因此，您可能需要在更精细的水平上评估聊天质量的多个维度，以了解模型的优点和缺点。</sample>
    <sample id="1027">一种方法是让人类裁判员评估对话质量的多个维度，例如模型回复的相关性，使用现有的比较或李克特尺度方法。</sample>
    <sample id="1028">然而，我们相信有一种更精确可靠的策略用于维度对话评估。</sample>
    <sample id="1029">我们的方法旨在通过明确说明每个模型响应是否表达某些行为，如提供无关信息或自相矛盾，来减少人类评估的主观性。</sample>
    <sample id="1030">我们称这种方法为在聊天中注释行为，简称ABC-Eval。我们开发了这种方法来全面覆盖最近文献中建议会影响聊天质量的聊天模型行为。</sample>
    <sample id="1031">ABC-Eval 可以衡量聊天模型在犯各种主题错误时的速度。</sample>
    <sample id="1032">例如，ABC-Eval衡量聊天模型在哪些轮次中忽略了其对话对象或说了一些不相关的事情。</sample>
    <sample id="1033">与自身或其伙伴相矛盾，传播错误信息或违反常识知识，并且当模型成功或失败时表现出缺乏同理心。</sample>
    <sample id="1034">为了确定哪种评估方式最有效，我们选择了四个最新的聊天模型，并使用ABC-Eval在每个模型上进行了100次人类对话评估。</sample>
    <sample id="1035">为了比较，我们还使用了三种现有方法评估这些对话：针对转录水平的李克特评分、针对对话水平的李克特评分和对话水平的配对比较。</sample>
    <sample id="1036">对于每个现有的方法，我们收集了关于对话中八个最常见的方面之一的评估，因为这是评估聊天模型的标准做法，沿多个维度进行评估。</sample>
    <sample id="1037">从我们对这些评估结果的分析中，我们发现ABC行为标签在总体上比现有方法收集的标签更可靠，如通过100个双重标注对话的内部注释者一致性来衡量。</sample>
    <sample id="1038">此外，ABC-Eval标签在预测整体对话质量方面比现有方法产生的指标更具有预测性，如简单的线性回归分析所示。</sample>
    <sample id="1039">例如，你可以看到测量与自我和同伴矛盾的轮流比例解释了五分之一和十分之一的对话质量，而平均利克特一致性评分只解释了四分之一或更少。</sample>
    <sample id="1040">最后，我们检查了每个评估指标是否能捕捉到对话质量的一个独特方面，使用逐步线性回归。</sample>
    <sample id="1041">你可以看到，所有ABC-Eval指标的组合解释了对话质量超过25%。当你一次移除一个指标时，大多数指标都会导致失去相当一部分关于质量的信息。</sample>
    <sample id="1042">另一方面，所有层次的Lickert量表的组合对质量的解释较少，并且较少的这些量表携带独特信息。</sample>
    <sample id="1043">这些可靠的、信息丰富且独特的ABC-Eval指标使我们能够以比以往任何方法都能实现的更高分辨率评估对话型AI。</sample>
    <sample id="1044">在我们实验的结果中，可以清楚地看到，仍然存在一些挑战，并且这些挑战已经被精确量化。例如，我们测试的机器人在其响应中大约有20%存在常识性错误。</sample>
    <sample id="1045">他们在大约15%的回应中产生无关信息，并且他们自己或他们的合作伙伴会在大约10%的时间内相互矛盾。</sample>
    <sample id="1046">随着该领域的快速发展，许多错误率可能会在新模型发布以来下降。然而，这更加强调了追求可靠和精确的评估指标的重要性，用于比较模型。</sample>
    <sample id="1047">我们希望ABC-Eval可以被其他领域的专家利用，作为朝着这个方向的重要一步。我们期待看到在接下来的几个月和几年里，对话型AI将如何 advancement。谢谢您的观看。</sample>
    <sample id="1048">根据提供的信息，这篇论文的作者是来自爱默生大学的Emily NLP实验室。</sample>
    <sample id="1049">在提供的英文内容中，CFT 代表“持续微调”，它被描述为一个简单而强大的基线，应该在未来的WISL应用程序开发中考虑。</sample>
    <sample id="1050">根据提供的信息，这篇论文有六位作者：John Gauthier、Aaron Mueller、Kannika Mishra、Karen Fuentes、Roger Levy 和 Adina ViLLa。</sample>
    <sample id="1051">Hello, my name is Kaiyuan and I will be presenting our work titled "When does translation require context? A data-driven multilingual exploration." This work was done in collaboration with Patrick Franz, Emil Niu, Andrea F. Martinez, and Graham Neubig.</sample>
    <sample id="1052">所以，许多翻译取决于上下文。例如，在这个句子中，我们如何翻译“more”？</sample>
    <sample id="1053">如果前一个句子是“如果部长们发现了，事情可能会变得危险”，那么more指的是一个秘密。但如果前一个句子是“医生，这可能是什么严重的疾病？”那么more指的是胎记。</sample>
    <sample id="1054">所以，取决于上下文，单词的意义会改变，因此它的翻译也会改变。</sample>
    <sample id="1055">然而，评估模型在处理这种情况下的表现如何是非常困难的。首先，因为只有少数翻译依赖于上下文，使得语料库级别的指标如BLEU无法捕捉这些翻译。</sample>
    <sample id="1056">有些人士建议对依赖上下文的翻译进行有选择性的评估，但这些资源只支持有限类型的依赖上下文的翻译和有限的语言集，因为它们通常依赖于领域知识和人工校正。</sample>
    <sample id="1057">在本工作中，我们试图回答这两个问题：首先，翻译是否需要上下文？其次，模型在这些情况下表现如何？</sample>
    <sample id="1058">为了回答第一个问题，我们首先通过测量一个词在不同翻译背景下的依赖程度来开始。</sample>
    <sample id="1059">在之前的工作中，我们引入了条件x对y的互信息作为机器翻译模型中上下文使用的度量。这可以通过测量条件c为给定源x时关于目标y提供了多少信息来完成。</sample>
    <sample id="1060">你可以把SXMI看作是给模型提供上下文所获得的信息。</sample>
    <sample id="1061">在本文中，我们将计算xmi扩展到点y xmi，可以衡量句子或单词级别的上下文使用。我们可以将具有高p xmi的单词视为需要上下文进行翻译的单词。</sample>
    <sample id="1062">现在我们用高维空间来分析单词，寻找这些单词之间的模式。</sample>
    <sample id="1063">And we perform our analysis on transcripts of ted talks that have been translated from english to fourteen different languages.</sample>
    <sample id="1064">我们将在三个不同的层次上进行分析。首先，我们将查看具有高p x c m i的语音片段。</sample>
    <sample id="1065">这使我们能够找到例如阿拉伯语中的复数名词，它们具有相对于高p6mi的辅音。 这可以解释为英语没有复数名词，因此需要上下文来确定一个名词是否是复数，当翻译成阿拉伯语时。</sample>
    <sample id="1066">And similarly, we find that certain languages also require context when we want to choose the appropriate verb form. we then look at vocabulary items that have high p x semia averages over all of its different occurrences.</sample>
    <sample id="1067">And this helps us identify cases like the one here where in Chinese you need context to translate proper nouns to make sure that you're using the same translation within the document.</sample>
    <sample id="1068">And similarly, we find that context is supported to translate in the right formality.</sample>
    <sample id="1069">And finally, we look at different at individual tokens that have high p x s m i and this allows us to identify phenomena that cannot really be captured by the word itself but that's rather expressed in the instant structure such as ellipse resolution.</sample>
    <sample id="1070">现在我们使用分析结果来设计一个文档级别的翻译基准。</sample>
    <sample id="1071">对于我们识别出的五种 discourse 现象，我们创建了标签来自动识别与现象相关的单词，并将其称为多语言 discourse 意识或 muDa 标签。</sample>
    <sample id="1072">We can then also note that different languages have different proportions of these discursive phenomena.</sample>
    <sample id="1073">我们接着使用muda tagger通过将标记应用到我们要用于评估的平行语料库上，并在muda tagger识别出的领域特定示例上应用我们选择的翻译度量。</sample>
    <sample id="1074">And finally we use our benchmark as well as other metrics to evaluate different models on the document level machine translation.</sample>
    <sample id="1075">First of all, when we use corpus-level metrics so for blue, we find that cognates-agnostic models have the best performance.</sample>
    <sample id="1076">But then if we use comet, context-aware models perform best and if we use word f measure, then models with or without context have comparable performance.</sample>
    <sample id="1077">这再次证明了，仅使用语料库级别的指标来确定最佳文档级别翻译系统是困难的。</sample>
    <sample id="1078">现在我们使用mooda benchmarks来评估模型，并发现基于上下文的模型在某些 discourse 现象，如正式性和词汇连贯性方面显著更准确。</sample>
    <sample id="1079">但这些模型并没有比那些没有使用上下文的其他现象如日食、读音和词形的模型好多少。所以这表明我们需要在文档级别翻译方面取得更多进展。</sample>
    <sample id="1080">我们还比较了不同的商业系统，我们的基准测试显示，DeepL通常比Google Translate更准确地进行文档级别翻译。</sample>
    <sample id="1081">要总结一下，我们对14种语言对进行了数据驱动的分析，以确定何时翻译需要背景。</sample>
    <sample id="1082">然后我们使用这些发现来建立一个基准，用于文档级别的机器翻译，这可以帮助我们确定哪些 discourse 原理模型可以处理好或不好，以及哪些翻译系统在文档级别翻译方面表现良好。</sample>
    <sample id="1083">Thank you so much for your attention. See you in Torado.</sample>
    <sample id="1084">演讲者的名字是Yusen Zhang。</sample>
    <sample id="1121">根据提供的英文内容，没有明确指定新方法的名称。因此，答案是没有名称。</sample>
    <sample id="1122">作者将“显性词汇”(marked words) 方法描述为一种用于识别区分标记群体和未标记群体的单词的方法。</sample>
    <sample id="1123">这篇论文的作者所属机构是美国华盛顿大学。</sample>
    <sample id="1124">第一个提到的对称依存关系结构的名称是'Prague approach'。</sample>
    <sample id="1125">演讲者的名字是James Finch和Sarah Finch。</sample>
    <sample id="1126">根据所提供的英文信息，这篇论文有四位作者：Javat Hosseini、Philip Radlinski、Silvia Parati和Anil Louis。</sample>
    <sample id="1127">GigaWord和GigaWord数据集可用于测试句法现象。</sample>
    <sample id="1161">根据提供的内容，第一个研究问题的五种方法的缩写是WSL。</sample>
    <sample id="1162">该模型在11项生物医学和临床下游任务上进行了评估。</sample>
    <sample id="1226">CamemBERT 最初是在四GB的子集上训练的。</sample>
    <sample id="1227">演讲者的名字是Adam Strykowski。</sample>
    <sample id="1228">根据所提供的英文内容，导致时间漂移是性能下降的主要原因的结论是：实验结果表明，随着时间间隔变大，模型在使用更近的数据重新训练或继续预训练时，性能会恶化。这支持了时间漂移是性能下降的主要原因的假设。</sample>
    <sample id="1269">在自然语言处理任务中，词元的排列顺序对于模型的性能至关重要。例如，在机器翻译、问答和文本生成等任务中，词元的排列顺序可以影响模型生成的输出是否准确和有意义。

因此，在第二步中使用另一个模型来预测一个排列以将词元放入正确的顺序，以确保输出序列中的词元具有正确的排列顺序。</sample>
    <sample id="1270">作者建议模型所有者提高偏见缓解方法的透明度，以解决由于存在潜在的过度价值对齐或反刻板印象方法导致的刻板印象图案。通过这样做，可以更好地理解这些模式的来源，并确保模型更加公平和公正。</sample>
    <sample id="1271">最小对不可接受输入是指一种评估语言模型的方法，其中模型被展示一个可接受的句子或语法正确的句子，然后是一个不可接受的句子或语法错误的句子。模型的目标是将更多的概率分配给可接受的句子。</sample>
    <sample id="1272">作者使用了准确率和困惑度来评估他们的实验结果。</sample>
    <sample id="1273">使用了注释者之间一致性的指标是内在注释者一致性。</sample>
    <sample id="1274">在不可接受和可接受查询中，选择维基百科来添加完全无关的句子。</sample>
    <sample id="1275">根据提供的信息，无法确定论文的作者所属机构。在音频中没有提到任何与机构相关的细节。</sample>
    <sample id="1276">MultiInstruct 与其他基准不同之处在于它是一个大规模的多模态指令调优数据集，而其他基准则缺乏大规模的多模态指令调优数据集。</sample>
    <sample id="1277">根据提供的信息，论文是由Emory NLP实验室的Gino Choy教授领导的，与Amazon Alexa AI合作完成。因此，至少有两位作者：Gino Choy教授和Amazon Alexa AI团队。</sample>
    <sample id="1278">很抱歉，我无法回答这个问题。您提供的信息似乎与二进制协调的定义无关。</sample>
    <sample id="1279">根据提供的信息，无法确定提示语的平均长度。该句子仅提到了研究中使用的提示语类型（正面或非负面），并未提供关于它们长度的具体数据。要回答这个问题，需要额外的关于每个提示语的长度的信息，这在给定的句子中没有提供。</sample>
    <sample id="1280">这些发现表明较小的 T5 模型可以生成高质量的文本，这表明它们可能比大型模型更有效率。</sample>
    <sample id="1281">你好，我是Yanis Lavrac，我将向您介绍我们关于Dr. Bert的论文，Dr. Bert是一个用于生物医学和临床领域的鲁棒预训练模型。</sample>
    <sample id="1282">在本演示中，我们首先讨论了语言建模在 healthcare 中的应用。接下来，我们将介绍我们论文的主要贡献。</sample>
    <sample id="1283">我们介绍了第一个生物医学模型，名为Dr. Bert，在法语中。该模型基于Roberta，并训练于NatCox，这是从网络上获取的医疗原始数据集。</sample>
    <sample id="1284">我们还引入了具有多个预训练设置和数据源的模型比较。然后，我们在法国的11项生物医学和临床 downstream 任务上展示了我们的结果。</sample>
    <sample id="1285">最后，我们将讨论实验并为您提供更多关于如何访问这些模型的细节。</sample>
    <sample id="1286">自2018年发布以来，BERT已经成为解决自然语言处理任务最有效的方法之一，并在与历史上的静态和概念化方法（如Word2Vec、FastText和WordNet）相比提供了巨大的性能提升。</sample>
    <sample id="1287">自那时起，这个模型已经适应了多种其他语言，例如法语中的Camembert和生物医学领域的Pima和Biobert，以及临床领域的Clinicalbert。但大多数情况下，它仍然在英语中使用。</sample>
    <sample id="1288">针对其他语言的专门化模型是罕见的，并且通常基于持续预训练，由于缺乏大规模数据。</sample>
    <sample id="1289">然而，法国并没有任何开源软件用于生物医学研究。</sample>
    <sample id="1290">因此，我们问自己关于最适合广泛用途的数据来源的问题。这些公开数据是临床数据的良好替代品。</sample>
    <sample id="1291">为了解决这个问题，我们将比较Dr. Bert与我们使用的Shubert模型，该模型基于从我们医院的非营利性医院获得的匿名化数据。</sample>
    <sample id="1292">然后我们问自己，我们需要多少数据来训练一个专门针对法文数据的模型？是4GB、8GB还是更多？</sample>
    <sample id="1293">为了回答这个问题，我们首先训练和比较了四个随机模型：第一个版本的DoctorBERT，带有7GB的NATOS数据集；第二个版本的4GB子集的NATOS数据集。</sample>
    <sample id="1294">第一种版本的Shubert，它是一个临床模型，包含4GB的句子，这些句子是从临床笔记中提取出来的。最后一种版本的Shubert，它结合了4GB自然文本子集和4GB临床笔记。</sample>
    <sample id="1295">除了这种比较之外，我们还引入了三种基于连续预训练的模型，以分析预训练策略的影响。</sample>
    <sample id="1296">一种方法是根据卡门伯的重量训练，使用4公斤的坚果作为一组。另一种方法也是基于卡门伯，但这次使用4公斤的克林纳节点作为一组。</sample>
    <sample id="1297">最终，我们基于一个名为“bembert”的英语 biomedical 模型，并在总共包含 7 个模型的 4GB 大小的自然数据集上对其进行训练。</sample>
    <sample id="1298">为了评估我们七种模型，我们将使用各种公共和私人对话任务，如命名实体识别、分类、部分语音标注和问答。</sample>
    <sample id="1299">这些模型与六个基准模型进行了比较，分别是卡门伯尔奥卡108GB、卡门伯尔奥卡4GB、卡门伯尔赛西NET 4GB、 plummetbert、mybert 和 clinicalbert。</sample>
    <sample id="1300">评估模型在执行任务时的表现，以确定它是否能够最好地处理与训练数据相同类型的数据。</sample>
    <sample id="1301">然而，我们可以从异质数据源中获取数据。我们还观察到，使用更多数据可以转化为更好的表现。</sample>
    <sample id="1302">总的来说，从头开始重新训练似乎在大多数任务上取得了更高的性能。</sample>
    <sample id="1303">然而，我们使用了Pete Bert的权重和词嵌入器，在Natasha的四GB子集中进行持续预训练实验。结果与从头开始训练的Pete Bert的四GB相当。</sample>
    <sample id="1304">这并不是基于卡门伯权重和托肯化器的模型的情况，该模型存在稳定性问题。</sample>
    <sample id="1305">最后，作为结论，我们的系统在11个任务中的9个任务上提供了更好的表现，并且在总体上超过了这里展示的通用模型Camembert。</sample>
    <sample id="1306">我们还观察到，专业化的数据更好。但专业化的数据并不容易扩展。</sample>
    <sample id="1307">All the pre-trained models obtained from NAO's are freely available and on YouTube, and all the training scripts are on our GitHub repository.</sample>
    <sample id="1308">所以，谢谢您为这次演讲。我们期待在下个环节的讨论中与您交流。</sample>
    <sample id="1309">该论文研究了以下学习策略：1. 从头开始训练和比较四个模型：一个使用7GB语料库的DoctorBERT，一个使用4GB子集的NATOS的第二个版本，一个使用4GB临床句子的第一种Shubert模型，以及一个混合了4GB子集的NATOS和4GB临床句子的最终Shubert模型。2. 三种使用持续预训练训练的模型，以分析预训练策略的影响。</sample>
    <sample id="1310">根据所给英文内容，过拟合因素似乎很小。这可以从红色最佳拟合线的梯度大于1来证明，这意味着在训练集上每单位改进导致在测试集上超过一个单位的改进。这表明没有衰减回报，表明过拟合在这个案例中没有观察到。</sample>
    <sample id="1311">根据所提供的内容，评估简化质量的方法是通过查看实验的得分和评估指标。这些细节可以在论文中找到，论文提供了关于使用不同模型进行文本简化实验的更多细节。</sample>
    <sample id="1312">是的，语言模型有政治偏见。</sample>
    <sample id="1313">Hi, my name is Matthias Liedermann and today I'm going to give you a brief introduction to our paper on compositional generalization without trees using multi-set tagging and latent permutations.</sample>
    <sample id="1314">这是与我的顾问亚历山大·科拉和伊万·季托夫合作的成果。</sample>
    <sample id="1315">组合性泛化能力可以理解为学习者处理在训练期间看到过的单独短语的更深层次递归和看不见的组合的能力。</sample>
    <sample id="1316">在语义解析的背景下，测试组合性泛化可能看起来像这样。如往常一样，我们有一个训练集的句子，在这种情况下，这个女孩睡了，而梅里知道这个女孩睡了。</sample>
    <sample id="1317">这些陈述与逻辑形式相配,这些形式代表了它们意义的核心方面。</sample>
    <sample id="1318">与标准机器学习评估不同，测试集不来自相同的分布，但包含结构上 unseen 的逻辑形式。</sample>
    <sample id="1319">在这个例子中，模型在训练期间遇到了较浅的递归，并且在具有较深递归的一个示例上进行了测试。</sample>
    <sample id="1320">Naive sequence-to-sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.</sample>
    <sample id="1321">In particular, they often fail to reproduce the systematic correspondences between input and output such as those that are color-coded in the example.</sample>
    <sample id="1322">一种常用的解决方法是将树融入模型中。</sample>
    <sample id="1323">The trees are intended to capture the compositional process that relates utterances with logical forms.</sample>
    <sample id="1324">这很好，但树木通常不能直接获得，需要以某种方式获取。</sample>
    <sample id="1325">这可以是一个复杂的，有时是计算昂贵的过程。通常，这涉及大量的形式化特定预处理逻辑形式，例如处理变量符号。</sample>
    <sample id="1326">获取树可能还涉及特殊的语法插入过程。</sample>
    <sample id="1327">在这篇论文中，我们不使用树，并引入了一个序列到序列模型，该模型直接建模了输入和输出片段之间的对应关系。</sample>
    <sample id="1328">For the first time, we show strong generalization to deeper recursion without relying on trees.</sample>
    <sample id="1329">我们的方法预测了从输入到输出的两步过程。</sample>
    <sample id="1330">首先，我们将每个输入标记与一个无序的多集标记，这些标记将在输出中出现。</sample>
    <sample id="1331">After the first step we have all the right tokens but they're not ordered.</sample>
    <sample id="1332">That's why in the second step we use another model to predict a permutation to put them into the right order.</sample>
    <sample id="1333">我们引入了一种新方法来预测一个排列，它不给可能的排列设置任何硬约束。这使我们的方法相当灵活和表达性。</sample>
    <sample id="1334">概念上，我们的排列模型大致像这样。</sample>
    <sample id="1335">我们从左到右遍历输出，并确定在每个位置放置哪个多集代词。对于第一个输出位置，我们简单地选择一个，如红色所示。</sample>
    <sample id="1336">Then we jump to the next multi-set token to determine the second token in the output.</sample>
    <sample id="1337">We determine the third token in the output in a similar way by jumping to another multi-set token We continue this process.</sample>
    <sample id="1338">直到第一阶段的每个标记都被访问过一次。</sample>
    <sample id="1339">为了给你一个实验结果的预告，这里我们将我们的方法与Kogs基准上的其他树模型进行比较。我们的模型在泛化到更深层次的递归时，比其他模型表现出更大的优势。</sample>
    <sample id="1340">其他一些结构的泛化仍然非常具有挑战性。</sample>
    <sample id="1341">在我们的论文中，我们解决了几个有趣的 技术挑战。</sample>
    <sample id="1342">首先，输入和输出之间的对齐在训练数据中没有给出。因此，对于给定的标记，我们不知道它来自哪个多头，这为训练提出了挑战。</sample>
    <sample id="1343">此外，有时存在多个与数据一致的排列，但语言上正确的排列是延迟的。我们通过将对齐作为训练的一部分来解决这个问题。</sample>
    <sample id="1344">Our permutation method is very flexible, but it brings the challenge that finding the highest scoring permutation is NP-hard. That's because this is related to the traveling salesman problem.</sample>
    <sample id="1345">我们用GPU友好的连续放松来近似这个，它还允许我们在解决方案中反向传播并学习更 linguistically 可接受的排列组合。</sample>
    <sample id="1346">如果您想了解我们实验的更多信息以及我们如何应对这些挑战，请查看我们的论文或来看我们的海报。</sample>
    <sample id="1347">认知失调是指两种不一致的信念或行动。</sample>
    <sample id="1348">根据所给的英文内容，GPT-4是最倾向于自由派的语言模型。</sample>
    <sample id="1349">是的，在主动学习时，累积训练比迭代训练更有效。</sample>
    <sample id="1350">演讲者的名字是Sarah Papi。</sample>
    <sample id="1351">MuDa基准中的数据是从TED Talks的转录中获得的，这些转录已经翻译成14种不同的语言。</sample>
    <sample id="1385">演讲者的名字是Mathias Lendemann。</sample>
    <sample id="1386">跨语言转移是指在一种语言上训练模型，然后将其应用于另一种语言的过程。</sample>
    <sample id="1387">这篇论文的作者是来自德国索林根大学的PHD学生。</sample>
    <sample id="1388">根据提供的信息，作者使用了两种延迟测量方法：翻译质量的延迟和计算延迟。翻译质量的延迟是通过比较翻译结果与原始文本之间的相似度来衡量的，而计算延迟则是通过考虑模型的计算时间来衡量的。</sample>
    <sample id="1389">Hello everyone. I'm Mancheta, and today my colleague Martin and I are presenting our work that is a step evaluating knowledge integration from multiple sources. This work is a collaboration between McGill University, Mila, and Microsoft Research.</sample>
    <sample id="1390">国家语言理解模型依赖于各种知识来源，如参数中包含的知识，通常通过预训练获得，以及在推理时输入给定的知识。</sample>
    <sample id="1391">最近的工作在任务型问答中表明，模型可以利用预训练的通用知识来解决该任务。</sample>
    <sample id="1392">但自然语言理解往往需要在推理时提供的知识。</sample>
    <sample id="1393">例如在句子中，John 在电视上看见了新当选的总统。</sample>
    <sample id="1394">Pre-training parameters can contain information about what presidents do and what a TV is, but they cannot reliably know who this instance-specific entity John is or who the new president is because the president might have changed since pre-training.</sample>
    <sample id="1395">因此，成功的模型对于知识密集型NLU任务需要能够整合和使用预训练时间和推理时间的知识。</sample>
    <sample id="1396">在本工作中，我们提出了一个诊断测试套件，用于知识整合。</sample>
    <sample id="1397">我们引入了一个元参考分辨率任务，旨在评估从不同来源获取知识的能力。我们使用具有人类学习路径的数据库，并建立了元参考分辨率模型。</sample>
    <sample id="1398">Here is an example from our dataset. Tsurvin is a judge. Kia is a baker. Tsurvin and Kia met at a park after a long day at work, deciding cases in a law court. He was happy to relax.</sample>
    <sample id="1399">任务是确定代词'他'所指的正确实体，在这种情况下是' servant'。</sample>
    <sample id="1400">The resolution of a given pronoun requires two types of information first entity-specific knowledge such as serville is a judge and second background knowledge such as judges decide cases in law courts.</sample>
    <sample id="1401">一般而言，背景知识是在大型语言模型的预训练过程中学习的，而实体特定知识通常在推理阶段观察到。</sample>
    <sample id="1402">我们改变这些两部分信息的可获得性，使得它要么在单一来源中找到，要么在多个来源中找到。</sample>
    <sample id="1403">我们已经定义了三个KimMoos设置。首先，我们有Tobii设备背景预训练，其中背景知识被认为在预训练阶段可用。</sample>
    <sample id="1404">第二，存在背景知识的两个设置，即在训练时间和推断时间都可获得背景知识。最后，存在背景知识的推断设置，其中两种知识类型仅在推断时间可用。</sample>
    <sample id="1405">这个最后的设置特别有趣，因为它模拟了这样一个情况：背景知识对于解决任务是必要的，但不是预训练数据的一部分。例如，因为自预训练以来已经出现了新的职业。</sample>
    <sample id="1406">Here's an example of how we control the availability of effects in two sources</sample>
    <sample id="1407">在背景预训练的设置中我们假设背景知识“政治家寻求当选政府”包含在预训练参数中。在特定场景下，我们提供特定知识“杰奇逊是一个政治家”。</sample>
    <sample id="1408">在背景研究中，我们通常提供不仅具有针对性，而且也具有政治人物在受难背景下的知识。</sample>
    <sample id="1409">在背景的 inferiority setting 提供的 fictional occupation meritocracy 而不是 politician，因为 meritocracy 是 unlikely to be contained in the pre-train paratext.</sample>
    <sample id="1410">我们评估了数据集，既包括人类学习参与者，又包括高质量分辨率模型。在这幅图中，我们展示了在最困难的背景预训练设置中表现最好的模型的结果。</sample>
    <sample id="1411">Without task-specific training on Kidmoss, both models do not perform well. When trained on Kidmoss, however, both C2F and B2F perform significantly better than the random choice.</sample>
    <sample id="1412">这表明，当训练在常规超分辨率数据集上时，模型学会利用表面线索，这些线索在测试时已被移除。</sample>
    <sample id="1413">Additional experiments with fictional knowledge indicate that even the best-performing models cannot reliably integrate background knowledge provided only at inference time.</sample>
    <sample id="1414">要总结我们论文的主要结论。许多可加权的进化模型似乎无法在没有任务特定训练的情况下从不同的来源中提取知识。然而，通过任务特定训练，一些模型成功地将知识整合到多个来源中。</sample>
    <sample id="1415">Still, even the best-performing models seem to have difficulties with reliably integrated background knowledge presented only at inference time. If you're interested in more details, please see our paper and check out the dataset in code on GitHub. Thanks for listening.</sample>
    <sample id="1416">基于树的方法的一个缺点是，通常需要进行复杂的预处理，例如处理变量符号。此外，获取树可能涉及专门的语法插入过程。</sample>
    <sample id="1417">根据提供的图片，无法确定论文的作者所属机构。</sample>
    <sample id="1418">嗨，我是Mayra。今天我们将讨论我们关于标记人物的论文，使用自然语言提示来衡量语言模型中的刻板印象。这项工作是在与Essen Durmush和Dan Jurafsky合作完成的。</sample>
    <sample id="1419">近年来，许多研究记录了社会偏见和刻板印象在大规模语言模型（LLMs）中的普遍性。</sample>
    <sample id="1420">然而，这些措施有各种限制。它们通常依赖于手工构建的数据集，这些数据集很难整理。</sample>
    <sample id="1421">他们通常只测量非常具体的刻板印象，这意味着它们不能很好地推广到其他人口统计或背景，或者它们简单地捕捉到非常一般、广泛的关联，比如负面关联与特定群体。</sample>
    <sample id="1422">总之，目前在这个领域中大多数工作并没有考虑到多面性，即多元化的社会身份可以叠加偏见并成为伤害的独特来源。</sample>
    <sample id="1423">为了克服这些限制，我们依赖于这些 newer 指令调优的 LLMs 非常擅长响应指令和提示。</sample>
    <sample id="1424">因此，我们可以让模型生成一个画像，即一个想象中的个体的形象，使用类似于“想象一下你是一个亚洲女性，描述你自己”的提示。</sample>
    <sample id="1425">我们可以立即看到，这可以泛化到任何地理特征，因为我们只需要将我们想要的任何身份标记插入到这个提示中。</sample>
    <sample id="1426">这里有一些来自GPT-4的示例生成。</sample>
    <sample id="1427">立即我们看到，虽然输出结果并没有明显负面或有毒的传统意义上的含义，</sample>
    <sample id="1428">有一些有趣的模式。</sample>
    <sample id="1429">亚洲女性被描绘为不引人注目的。中东女性被用诸如异国情调和令人着迷的地区等词语提及。</sample>
    <sample id="1430">而女性角色人物提及了血统，而白人男性角色人物没有提及此类内容。</sample>
    <sample id="1431">为了捕捉这些模式，我们的方法分为两部分。第一部分是生成这些人物。</sample>
    <sample id="1432">他们用来生成这些人物的提示受到一项研究的启发，在这项研究中，他们将这些提示给了人类受试者，发现通过给予人类受试者这些提示，他们也能够表面种族刻板印象。</sample>
    <sample id="1433">此外，这还使我们能够直接比较我们生成的对话和人类手写对话。</sample>
    <sample id="1434">第二部分是标记词，这是一种方法，用于识别区分标记组和未标记组的单词。我将在下面详细解释。</sample>
    <sample id="1435">这段内容的好处是，我们可以获得非常具体的刻板印象和模式，而无需依赖任何特定的词汇。</sample>
    <sample id="1436">所以，标记理论方法依赖于社会语言学中的一个概念：可标记性。这个概念表明，有一个未被标记的默认状态，而任何偏离这种默认状态的群体在语言上是被标记的。</sample>
    <sample id="1437">例如，单词“男人”（man）通常与男性相关联。因此，当人们描述一个女性的勇士时，他们通常会在勇士前面加上“女人”（woman），以明确指出这个人是女性。</sample>
    <sample id="1438">更广泛地说，社会中的 dominant groups 既在语言上又在社会上未被标记，而边缘化群体通常被标记。</sample>
    <sample id="1439">在我们的方法中，我们首先指定未标记和已标记的群体是什么。</sample>
    <sample id="1440">然后我们使用“fighting words”方法比较人物，这种方法主要是使用加权log odds比率来区分每个标记组的Top单词。</sample>
    <sample id="1441">例如，对于黑女人的形象，我们会进行对比数据和比较与白人形象和男性形象的法律差距，因为这些是两个相应的未标记群体。</sample>
    <sample id="1442">现在，让我们看看一些结果。首先，我们使用了词典中的刻板印象，发现生成的短语包含比人类写的短语更多的刻板印象。</sample>
    <sample id="1443">然而，当我们实际上查看字典中单词的分布时，我们会发现一些非常不同的事情。</sample>
    <sample id="1444">所以，生成的人物形象的词汇频率更高，而人类手写的人物形象的词汇分布范围更广。生成的人物形象中的刻板印象词汇只是高大和能干的词汇。</sample>
    <sample id="1445">所以，实际上只有正数或至少是非负数。</sample>
    <sample id="1446">实际上，这个语料库并没有捕捉到我们在早期幻灯片中看到的许多有害的模式。因此，我们将转向我们标记词方法的结果，以展示这些看起来积极的词语如何促进刻板印象和本质化叙事。</sample>
    <sample id="1447">在我们的分析中，我们探讨了这些表面上看起来积极的序曲如何反映了有害的模式。</sample>
    <sample id="1448">首先，对于马尔群体来说，关键词包括文化、传统、自豪和异国情调。这些词语通过与他们身份的关系来定义这些群体，并将它们与其他群体区分开来，特别是与白人规范不同。</sample>
    <sample id="1449">这有助于这些群体长期遭受歧视和边缘化。</sample>
    <sample id="1450">此外，还有一些常见的 tropes 在这些词语中反映出来，特别是针对有色人种女性。例如，描述 Latina 女性的词语包括充满活力和 curvaceous 等。</sample>
    <sample id="1451">这些词与热带主义有关，对于亚洲女性来说，这些词是“精致”、“细腻”和“丝滑”的。</sample>
    <sample id="1452">这段内容描述了亚洲女性被异化的历史，她们被视为顺从、温柔和顺从的。</sample>
    <sample id="1453">最后，对于黑人女性来说，我们看到一些关键词是坚强和 resilient 这样的词。</sample>
    <sample id="1454">这连接到了一个被人们称为“坚强黑人女性”原型的特征，尽管乍一看它听起来是积极的。</sample>
    <sample id="1455">已经有一些研究表明，这种类型实际上是非常有害的，因为它给这些人口统计带来了很大的压力，要求他们具有很强的韧性和坚强，以应对社会障碍。</sample>
    <sample id="1456">相反，它并没有致力于解决这些问题，而是给这些人施加压力，让他们克服这些问题，这导致了这些人的负面健康后果，以及其他伤害。</sample>
    <sample id="1457">更广泛地说，我们发现每个标记群体的词汇几乎反映了非常本质化的叙事。</sample>
    <sample id="1458">基于这些模式，我们为模型所有者提出了三个建议。</sample>
    <sample id="1459">首先，作为研究人员，我们应该解决积极刻板印象和本质化叙事。我们还应该使用交叉学科方法来研究偏见和伤害，因为有许多事情可能会被忽视如果我们不这样做。</sample>
    <sample id="1460">最后，应该增加关于偏见管理方法的透明度。</sample>
    <sample id="1461">因为，例如这些积极的刻板印象，我们不知道是因为有什么样的某种奇特的原因。</sample>
    <sample id="1462">过度的过度价值对齐正在进行，或者可能是其他一些反刻板印象方法导致了这些偏见模式。</sample>
    <sample id="1463">我们真的不能做出任何假设或进一步研究它，除非有更多透明度。</sample>
    <sample id="1464">非常感谢您的收听。祝您有一个愉快的一天。</sample>
    <sample id="1465">Hello everyone, my name is Jing Wei Yi from the University of Science and Technology of China.</sample>
    <sample id="1466">我很乐意为您制作一个关于保护大型语言模型的版权的简短广告视频。您复制我的模型吗？保护大型语言模型的版权，用于嵌入和云服务，使用Backdoor Watermark。</sample>
    <sample id="1467">让我们首先介绍有关嵌入式服务的背景。</sample>
    <sample id="1468">当前，大型语言模型如GPT、LLaMA和PaLM在自然语言理解和生成方面表现出色。</sample>
    <sample id="1469">Embedding as services is one of the services built upon large language models to assist various NLP tasks.</sample>
    <sample id="1470">例如，OpenAI 提供了基于 GPT 的 API。</sample>
    <sample id="1471">然而，鉴于攻击者可能通过学习嵌入并提供类似服务来复制模型，因此必须保护嵌入作为服务的版权。</sample>
    <sample id="1472">为了保护嵌入式服务的版权，一种解决方案是在提供的服务中嵌入一个水印，并检测另一个服务是否包含该水印。</sample>
    <sample id="1473">水印方法需要满足以下属性：首先，该方法应该适用于嵌入服务；其次，水印不应该降低所提供的嵌入的实用性。</sample>
    <sample id="1474">第三，水印应该足够隐蔽，让攻击者无法轻易地移除水印。</sample>
    <sample id="1475">最后，水母必须能够被运往攻击者的服务端进行模型提取过程。</sample>
    <sample id="1476">现有的作品可以被广泛地分为四类。</sample>
    <sample id="1477">然而，这些方法要么不适用于嵌入式服务，要么缺乏可转移性。</sample>
    <sample id="1478">因此，在本文中，我们提出了 embedding marker，它是一种基于水印的嵌入方法，适用于嵌入服务。</sample>
    <sample id="1479">Then let me introduce the details of our embedding marker embedding marker contains two main steps watermark injection and copyright verification</sample>
    <sample id="1480">在这些主要步骤之前，我们首先选择一个触发集。触发集是一组在适度频率间隔内的单词。</sample>
    <sample id="1481">我们假设提供者可以收集一个一般文本语料库，并计算单词频率。</sample>
    <sample id="1482">在水印注入中，我们首先定义一个目标嵌入，当用户向提供者服务发送一个句子时，提供者计算句子中的触发数字。</sample>
    <sample id="1483">The provided embedding is a weighted summation of the target embedding and the original embedding.</sample>
    <sample id="1484">The weight of the target embedding is proportional to the number of triggers in the sentence when the number of triggers in the sentence is greater than m, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="1485">数字水印验证是检测另一个服务后面隐藏的模型是否包含水印。</sample>
    <sample id="1486">我们首先构造一个后门数据集和一个 benign 数据集。后门数据集包含所有单词都属于触发集的句子，而 benign 数据集中的所有单词都不属于触发集。</sample>
    <sample id="1487">Then the provider requests embeddings from the steel service with the dataset.</sample>
    <sample id="1488">余弦和L2相似性之间的请求嵌入和目标嵌入的余弦和L2相似性被计算。我们计算了MNIST和Fashion MNIST数据集之间的相似性差异，它被定义为δcosine和δL2。</sample>
    <sample id="1489">meanwhile, we also apply KS test and use its p value as the third metric.</sample>
    <sample id="1490">我们对四个数据集进行实验：AGNews、Mind、SST-2和ArabSFM。我们假设提供者将Wikipedia数据集用于计算词频。</sample>
    <sample id="1491">The results on four datasets show that our embedding model can have great detection performance while keeping great utility for downstream tasks.</sample>
    <sample id="1492">我们还通过可视化句子上的嵌入来验证所提供的嵌入的正确性，使用了VulPca数据集。图例中的数字表示每个句子中的触发器数量。</sample>
    <sample id="1493">如图所示，很难区分边框嵌入和普通嵌入。</sample>
    <sample id="1494">那全完了，谢谢。欢迎来和我们讨论。</sample>
    <sample id="1495">ABC-Eval代表“在聊天中注释行为”或“聊天模型行为评估”。</sample>
    <sample id="1496">CoNLL-2003 和 CoNLL++ 之间的性能增量高于 5 个百分点，直到 2017 年。</sample>
    <sample id="1497">Hello, my name is Vasudeva, and I am a computer science PhD candidate at Stony Brook University. I would like to present our work accepted into ACL 2023 as a long paper: Transfer Learning for Sentiment Detection: Addressing the Rare Class Challenge.</sample>
    <sample id="1498">我们首先定义了认知失谐，并解释了为什么研究语言中的认知失谐是一个重要问题。简单来说，认知失谐指的是两个不一致的信念或行动。</sample>
    <sample id="1499">比如这个例子，一个人说我知道香烟会杀死我，然后又说我去抽了几支烟。这种信仰和行动是不一致的，并且他们处于矛盾状态。</sample>
    <sample id="1500">进一步说明，我不能没有他们保持我的工作，这证明了第二次提及，并且他们有密切的关系。</sample>
    <sample id="1501">While dissonance is a very common phenomenon we experience in daily decision-making, they are really rare to find expressed in language among other kinds of risk relations.</sample>
    <sample id="1502">所以这又有什么关系？研究认知差异可以帮助我们理解不同人群之间的差异，追踪趋势和信仰、价值观和态度在人口中的变化。</sample>
    <sample id="1503">高水平的认知扭曲与焦虑障碍有关，可以帮助更好地理解人们的心理健康。</sample>
    <sample id="1504">学习流言蜚语表达的语言也可以有助于理解极端主义和边缘化群体的 polarization。</sample>
    <sample id="1505">Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision-making processes better.</sample>
    <sample id="1506">为了创建认知分歧资源，我们对分歧关系进行了大规模注释。我们在流程图中所见的分歧第一种方法。</sample>
    <sample id="1507">Tweets were parsed using a pittbyparser and pairs of discourse units were annotated according to the guidelines that are described in our paper.</sample>
    <sample id="1508">如图所示，仅在3.5%的成对中检测到了分歧。</sample>
    <sample id="1509">在收集了大约1000个 discourse unit 对的例子后，我们训练了一个初始分类器，只使用了43个例子的 discnets。 不 surprising 的是，分类器的表现并没有比随机猜测好多少。</sample>
    <sample id="1510">鉴于低频的分散和缺乏任何类似的先例数据集，我们面临着绝对罕见的问题。</sample>
    <sample id="1511">为了缓解这个问题，我们实验了组合元学习和主动学习的组合，以标注出更多的离散样本，同时减少标注轮次，从而降低整体标注成本，同时提高离散度检测。</sample>
    <sample id="1512">Since the initial model was not able to capture the dissidents class at all, we start the active learning process by transferring weights from closely related tasks.</sample>
    <sample id="1513">我们转换为两个不同的任务。主题独立分歧姿态分类任务确定了来自不同人的两个辩论声明是否一致或不一致，无论主题如何。</sample>
    <sample id="1514">称为辅音 here and on binary classification of expansion and compression classes of pittibee since these two are closely related to the conception of consonance and dissonance and we call them c e here</sample>
    <sample id="1515">We find that on transferring the zero-shot performance on the annotated data set is already much better than chance, with the best with a u c point six two.</sample>
    <sample id="1516">Further on iteratively fine-tuning on both tasks, we find that fine-tuning of C-E task followed by further fine-tuning on debate yields a much better zero-shot performance thus this is the model that we use to co-start the active learning.</sample>
    <sample id="1517">接下来，我们确定了从每一轮主动学习和注释中更新模型的最佳方法。累积器累积了所有到目前为止收集的所有数据，而迭代器通过训练模型来更新模型，使用最新收集的数据集。</sample>
    <sample id="1518">Over the different strategies, we found that cumulative performed equal or better than iterative across the board.</sample>
    <sample id="1519">Next, to improve the number of dissident examples, we use a probability of real class strategy, prc, to select mostly the examples that are highly likely to be dissident by the current model at any round of a.</sample>
    <sample id="1520">We compared this to the other state-of-the-art state-of-the-art strategies that are commonly used in the community.</sample>
    <sample id="1521">We find that the proposed prc strategy works better than other state-of-the-art strategies although the difference is small. Note that the performance is significantly lower for random</sample>
    <sample id="1522">On further rounds of ayl with two best strategies we improved distance classification au c to 0.75, which is the best performance that we have on the task so far.</sample>
    <sample id="1523">我们还检查了每种策略在注释质量和成本方面的可行性。我们发现，PRC具有最高的准确率，并且最适合真实场景；然而，注释员也发现示例很难。</sample>
    <sample id="1524">在总体上，我们发现PRC是一种简单的AL策略用于稀疏类别获取和冷启动AL，带有适当设计的元学习任务，并且效果显著。</sample>
    <sample id="1525">我们还发现迭代式更新对于跨域学习非常有用，而域内主动注释则受益于累积式更新。</sample>
    <sample id="1526">这些是我们的代码数据集和我们论文的链接。如果您有任何问题，请随时与我们联系。谢谢</sample>
    <sample id="1527">根据提供的信息，无法确定论文作者的机构。在引文或演讲中没有提到任何机构名称。要找到答案，通常需要查阅论文的参考文献部分或作者的个人网页，以获取关于他们所属机构的详细信息。</sample>
    <sample id="1528">演讲者的名字是Cui Yuhan。</sample>
    <sample id="1529">根据提供的信息，论文《翻译是否需要背景：一种数据驱动的多语言探索》有五位作者。</sample>
    <sample id="1530">该方法与专门用于 simulST 翻译的专用 simulST 架构进行了比较。</sample>
  </task>
</testset>