<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="en">
    <sample id="0">The main data sources for language models are large-scale web crawls.</sample>
    <sample id="1">McGill University, Mila and Microsoft Research</sample>
    <sample id="35">Kayo Yin</sample>
    <sample id="36">T5 XL</sample>
    <sample id="37">Yes, they do.</sample>
    <sample id="38">The novelty of the proposed human evaluation method is that it attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors such as responding with irrelevant information or contradicting itself.</sample>
    <sample id="39">Clean validation samples</sample>
    <sample id="40">To improve the score, advances can be made in terms of the knowledge of the entities.</sample>
    <sample id="41">5</sample>
    <sample id="75">Three</sample>
    <sample id="76">Bible texts</sample>
    <sample id="77">Salt and pepper</sample>
    <sample id="78">Yes, you can use the models for your research.</sample>
    <sample id="79">DEplain-apa contains news texts.</sample>
    <sample id="80">Better model architecture, larger model size, and more fine-tuning examples.</sample>
    <sample id="81">The tendency for left conjuncts to be shorter was measured by measuring length in characters, syllables, and words.</sample>
    <sample id="82">The experiments were designed to study the effect of the governorâ€™s position by measuring length in characters, syllables, and words. The results showed that when the governor is on the left, the tendency for the left conjunct to be shorter grows steadily with the absolute difference in words. This trend is also observed when there is no governor as in coordination of sentences, but when the governor is on the right, this tendency disappears.</sample>
    <sample id="83">A baseline classifier performs not much better than chance when training on imbalanced data.</sample>
    <sample id="84">Four</sample>
    <sample id="85">Bob and Alice</sample>
    <sample id="86">Formality and lexical cohesion</sample>
    <sample id="87">Johns Hopkins University, Purdue University, and MIT</sample>
    <sample id="88">hi my name is matthias lindemann and today i'm going to give you a brief introduction to our paper on composition generalization without trees using multi set tagging and latent permutations</sample>
    <sample id="89">This is joint work with my advisers Alexander Koller and Ivan Titov.</sample>
    <sample id="90">Compositional generalization Ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training.</sample>
    <sample id="91">Compositional Generalization in Semantic Parsing Train: The girl slept. Mary knew that the girl slept. 'girl x sleep agent x' 'girl x know agent x, Mary A know comp x, x'</sample>
    <sample id="92">Compositional Generalization in Semantic Parsing Train: The girl slept. 'girl x sleep agent x x Mary knew that the girl slept. 'girl x know agent x, Mary comp x, x, x</sample>
    <sample id="93">Compositional Generalization in Semantic Parsing Train: The girl slept. 'girl x sleep agent x x' Mary knew that the girl slept. 'girl x know agent x, Mary A ccomp x, x'</sample>
    <sample id="94">Compositional Generalization in Semantic Parsing Train: Mary knew that the girl slept. 'girl x sleep agent x, Mary A ccomp x, A' Test: Jim said that Mary knew that the girl slept. 'girl x say agent x, Jim A sayccomp x, x, A know agent x, x, A knowccomp x, x, A sleep agent x, x,'</sample>
    <sample id="95">Naive sequence-to-sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.</sample>
    <sample id="96">In particular, they often fail to reproduce the systematic correspondences between input and output such as those that are color-coded in the example.</sample>
    <sample id="97">Trees help a lot but... *girl x1; sleep. agent x2* *girl x1; sleep. agent x2* The girl slept.</sample>
    <sample id="98">Trees help a lot but... *girl x1;sleep agent x2; x1 *girl x1; x1 sleep agent x2 The girl slept.</sample>
    <sample id="99">Trees help a lot but... *girl x1;sleep agent x2*x1 *girl x1; x2 sleep agent x2 The girl slept.</sample>
    <sample id="100">This can be complicated and sometimes a computationally expensive process. Typically, this involves considerable formalism-specific pre-processing of the logical forms for example to handle variable symbols.</sample>
    <sample id="101">Trees help a lot but... *girl x1;sleep agent x2; x1 *girl x1; x2 sleep. agent x2 The girl slept. Trees need to be obtained: - Pre/Post-processing logical forms - Grammar-induction</sample>
    <sample id="102">Trees help a lot but... *girl x1; sleep agent x2; x1 The girl slept. Trees nced to be obtained: - Pre/Post-processing logical forms - Grammar-induction For the first time, we show strong generalization to deeper recursion without trees. Neural sequence-to-sequence model that directly models the correspondences between fragments of the input and fragments of the output.</sample>
    <sample id="103">Trees help a lot but... *girl x1;sleep agent x2; x1 The girl slept. Trees nced to be obtained: - Pre/Post-processing logical forms - Grammar-induction For the first time, we show strong generalization to deeper recursion without relying on trees. Transformer neural seqseq model that directly models the correspondences between fragments.</sample>
    <sample id="104">Our Approach the girl slept</sample>
    <sample id="105">First, we tag each input token with an unordered multiset of tokens that will appear in the output.</sample>
    <sample id="106">Our Approach the girl slept</sample>
    <sample id="107">that's why in the second step we use another model to predict a permutation to put them into the right order</sample>
    <sample id="108">We introduce a new method to predict a permutation that does not put any hard constraints on the possible permutations. This makes our approach quite flexible and expressive.</sample>
    <sample id="109">Permuting with "jumps" Permute the girl agent sleep x1 x2 Tag the girl slept</sample>
    <sample id="110">We go from left to right over the output and determine which multi-set token to put in every position. For the first output position, we simply select one as highlighted in red.</sample>
    <sample id="111">Permuting with "jumps" Permute the girl agent sleep x1 x2 Tag the slept then we jump to the next multi set token to determine the second token in the output.</sample>
    <sample id="112">Permuting with "jumps" Permute the girl agent sleep x1 x2 the girl slept Tag we determine the third token in the output in a similar way by jumping to another multiset token we continue this process</sample>
    <sample id="113">Permuting with "jumps" sleep agent x1 girl x2 * the girl slept</sample>
    <sample id="114">Some Results on COGS (Kim and Linzen 2020) Comparison with other Treeless Models on Structural Generalization on COGS Model LSTM seq2seq 13. Zhang and Lapata Ours PP recursion GP recursion Obj + Sub + PP</sample>
    <sample id="115">Some other kinds of structural generalization remain very challenging, though.</sample>
    <sample id="116">Technical Challenges We Solve * girl x1 3 sloop agent x2 xi Permute Alignment unknown. the girl slept</sample>
    <sample id="117">First of all, the alignment between input and output is not given in the training data. As a consequence, for a given token we don't know which multi-set it came from, which poses a challenge for training.</sample>
    <sample id="118">In addition, sometimes there are multiple permutations that are consistent with the data but the linguistically correct one is latent. We address this by inducing the alignment as part of the training.</sample>
    <sample id="119">Our permutation method is very flexible, but it brings the challenge that finding the highest scoring permutation is NP-hard. That's because this is related to the traveling salesman problem.</sample>
    <sample id="120">We approximate this with a GP-friendly continuous relaxation that also allows us to back-propagate through the solution and learn the linguistically more plausible permutations.</sample>
    <sample id="121">Technical Challenges We Solve Alignment unknown. Induce it in training. Tag Permute + girl x1 j sleep agent x2 + x1 girl x1 x2 sleep agent x2 Tag Backpropagate through continuous relaxation</sample>
    <sample id="122">The introduced framework quantifies the positionality by measuring the correlation between the demographic data and the model's predictions or labels.</sample>
    <sample id="123">Hello, I am Dawei, a PhD student at Saarland University in Germany. In this video, I would like to present our recent work, Weaker Than You Think, or Critical Look at Weakly Supervised Learning.</sample>
    <sample id="124">This is joint work with chao y shen, marius mosbach and g stefan and dietrich klakow.</sample>
    <sample id="125">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning (WSL) Train models that generalize well despite being trained on noisy data</sample>
    <sample id="126">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning (WSL) Train models that generalize well despite being trained on noisy data</sample>
    <sample id="127">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning (WSL) Train models that generalize well despite being trained on noisy data</sample>
    <sample id="128">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning (WSL) Train models that generalize well despite being trained on noisy data</sample>
    <sample id="129">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning (WSL) Train models that generalize well despite being trained on noisy data</sample>
    <sample id="130">A common claim in recent WSL works "We train models only on weakly supervised data and achieve an accuracy of XX%."</sample>
    <sample id="131">A common claim in recent WSL works "We train models only on weakly supervised data and achieve an accuracy of XX%." Weakly labeled training data (noisy) Cleanly labeled test data (clean)</sample>
    <sample id="132">which is that people do assume that there is an additional clean validation set available for model selection.</sample>
    <sample id="133">We can stop on this problem setting as it implies that additional manual annotations are required in weakly supervised learning. But like an elephant in the room, this necessity is often overlooked.</sample>
    <sample id="134">The aforementioned doubt is us to ask three research questions. First, is clean validation data necessary for WSL? Or can we maybe use a noisy validation set instead?</sample>
    <sample id="135">Second, if clean data is required or if clean data is mandatory for WSL to work, then how many clean samples do we need? Finally, should we only use the clean samples for validation, or are there better ways to utilize them?</sample>
    <sample id="136">RQ1 Main findings Validation on weak labels No validation on weak labels Validation on clean labels FT w. BOND COSINE MLC L2R</sample>
    <sample id="137">First, we find that interestingly recent WS L methods indeed require clean wide dataset samples to work properly.</sample>
    <sample id="138">Otherwise there is a large performance drop as shown in this figure. If there are no clean validation samples, then the trained models cannot generalise beyond the original weak labels.</sample>
    <sample id="139">Meaning that training is pointless.</sample>
    <sample id="140">This indicates that WSL approaches actually require cleanly labeled data to work properly and the annotation cost for obtaining clean validation samples should not be overlooked.</sample>
    <sample id="141">Our second finding is that increasing the number of clean validation samples will help WSL approaches to achieve better performance, as shown in the figure on the left.</sample>
    <sample id="142">Main findings Accuracy 85 80 FTw COSINE L2R BONDO MLC Weak labels 75 All validation 5 10 20 30 40 50</sample>
    <sample id="143">But that's not the end of the story because if we either way decide to access clean samples then training on them directly will even achieve better performance.</sample>
    <sample id="144">Main findings 85 FTw COSINE L2R MLC 80 75 70 65 60 55 50 All weak labels 40 30 20 10 0 5 10 20 30 40 50 All Validation Performance Delta (%) FTw COSINE L2R MLC Adapterc FTc LoRAc BiFiTc Adapterc</sample>
    <sample id="145">As we can see, if we have 10 samples per class, direct fine-tuning starts to beat WSL approaches.</sample>
    <sample id="146">Finally, the performance improvement claimed in previous WSL approaches can be easily achieved by allowing to continue fine-tuning on the clean validation samples.</sample>
    <sample id="147">As we can see from the figures, the vanilla model termed FT w initially underperforms more complicated WSL methods like COSINE and ER. However, after CFT, FT w achieves comparable performance with COSINE and ER.</sample>
    <sample id="148">However, if we allow to continue fine-tuning on the clean samples then FT w performs equally well as other methods.</sample>
    <sample id="149">So in practice there is no reason to choose more complex WSL methods which require more computation time and disk space.</sample>
    <sample id="150">Conclusion Recent WSL approaches Require clean samples. Overestimate their practicality. Our recommendations Report the model selection criteria. Use Few-shot learning approaches as baselines. Always apply continuous fine-tuning (CFT).</sample>
    <sample id="151">Our concrete recommendations for future work are as follows.</sample>
    <sample id="152">First, report the model selection criteria. For example, report if the model selection is done well on clean validation samples.</sample>
    <sample id="153">Recent WSL approaches Require clean samples. Overestimate their practicality. Our recommendations Report the model selection criteria. Use few-shot learning approaches as baselines. Always apply continuous fine-tuning (CFT).</sample>
    <sample id="154">Finally, we have open-sourced our code. You can find it via the QR code on this slide. Please feel free to check it out. Thank you and enjoy the conference.</sample>
    <sample id="155">The previous study found that by giving the same persona prompts to human subjects, they were able to surface racial stereotypes.</sample>
    <sample id="156">The enhanced version of the Penn Treebank and the paper "Why wouldn't you use university dependencies" were used in this study.</sample>
    <sample id="157">Two authors are involved in the paper.</sample>
    <sample id="158">Expansion and comparison classes of peer-to-peer.</sample>
    <sample id="159">2</sample>
    <sample id="160">7</sample>
    <sample id="161">The introduced framework differs from the previous works by comparing end users with models and datasets predictions and labels as opposed to looking at just annotator agreement or modeling annotator distributions.</sample>
    <sample id="162">GPT-4</sample>
    <sample id="163">DeepBel and Google Translate</sample>
    <sample id="200">Five</sample>
    <sample id="201">MPP evaluations were performed with different contexts up to 900 tokens.</sample>
    <sample id="202">They included music, fiction, and other domains in their dataset.</sample>
    <sample id="203">Positionality is simply the perspectives that people hold as a result of their demographics, identity and life experiences.</sample>
    <sample id="204">Dawei Zhu</sample>
    <sample id="205">Yes, EDAtt adapts an existing offline ST model.</sample>
    <sample id="206">Four</sample>
    <sample id="207">No, the tested model does not work on the test suite.</sample>
    <sample id="208">There are three variants of KITMUS: Background Pretrain, Background Both, and Background Infer.</sample>
    <sample id="209">The authors of the paper are affiliated with Google Research.</sample>
    <sample id="210">Should we only use the clean samples for validation or are there better ways to utilize them?</sample>
    <sample id="211">It measures the model's ability to consistently produce the same outputs for the same task regardless of slight variations in the wording of the instruction.</sample>
    <sample id="212">Jingwei Yi</sample>
    <sample id="213">Greater sensitivity indicates improved model performance.</sample>
    <sample id="214">A diverse range of linguistic contexts.</sample>
    <sample id="215">20</sample>
    <sample id="216">Stanford University</sample>
    <sample id="217">Because language models have varying political leanings and occupy all four quadrants on the political compass.</sample>
    <sample id="218">The name of the speaker is Manjata.</sample>
    <sample id="219">The political bias propagation pipeline involves the process of learning from diverse perspectives, which celebrates democracy and the plurality of ideas. However, these different political opinions are inherently socially biased and may lead to potential fairness issues in downstream task applications.</sample>
    <sample id="220">Yes, the simplification process differs for DEplain-apa and web.</sample>
    <sample id="221">Yes, Coscript is publicly available.</sample>
    <sample id="222">The watermark is inserted into the text by defining a target embedding, counting the trigger number in the sentence, and adding the target embedding on the original embedding.</sample>
    <sample id="223">The authors of the paper are affiliated with Penn State University and Amazon.</sample>
    <sample id="224">Yes, encoder-decoder models such as mt5 can be improved by training on a mixture of languages.</sample>
    <sample id="225">An example of constrained language planning is making a chocolate cake.</sample>
    <sample id="226">They validate the covertness of their method by visualizing the embedding of sentences on the dataset BoolPCA.</sample>
    <sample id="227">The work uses existing PLMs to build a new one by fine-tuning them on the NACHOS corpus.</sample>
    <sample id="228">African Islamic</sample>
    <sample id="229">The speaker shows an example on the right.</sample>
    <sample id="230">The more tasks the model is trained on, the better performance it achieves.</sample>
    <sample id="231">LSTM-seq2seq, Zhang and Lapata, PP recursion</sample>
    <sample id="232">Advisers</sample>
    <sample id="233">Chowdery et al</sample>
    <sample id="274">The speaker mentions three problems of SimulST.</sample>
    <sample id="275">Sanitizing the data is an effective way to mitigate social and political biases in datasets when training NLP models.</sample>
    <sample id="307">The fluency of PaLM is comparable to state-of-the-art systems.</sample>
    <sample id="308">The important properties of a watermarking method are applicability to embedding as services, non-degradation of the utility of the provided embeddings, covertness, and transferability to the attacker's services during the model extraction process.</sample>
    <sample id="309">The 14 different languages into which the English TED talks have been translated are not specified in the given information.</sample>
    <sample id="310">200</sample>
    <sample id="311">Cosine and L2 similarity</sample>
    <sample id="312">The multilingual encoder-based models were used for this task by evaluating them on two groups of models, including encoder PDR and encoder-decoder models.</sample>
    <sample id="313">hi i'm siu yuan from fudan university i'm here to introduce our work distilling script knowledge from large language models for constrained language planning</sample>
    <sample id="314">in everyday life, humans often plan their actions by following step-by-step instructions in the form of a script.</sample>
    <sample id="315">previous work has explored language models to plan for abstract goals of stereotypical activities such as make a cake and show that large language models can effectively decompose goals into steps</sample>
    <sample id="316">However, previous work mainly focuses on planning for the abstract goals of stereotypical activities. Planning for the goals with specific goals, specific constraints such as make a chocolate cake still remains understudied.</sample>
    <sample id="317">Constrained Language Planning How to Make a Strawberry Cake? ...Add strawberry jams into the flour... How to Make a Chocolate Cake? ...Add the cocoa powder into the flour... Aspect goal can be inherited by different real-life specific goals with multi-faceted constraints</sample>
    <sample id="318">which impose different constraints on the goal of planning a abstract goal can be inherited by different real life specific goals with multi faceted constraints a good planner should read scripts that are reasonable and faithful to constraints</sample>
    <sample id="319">In this paper, we first evaluate and improve the constrained language planning ability of large language models.</sample>
    <sample id="320">This no data set of specific goals exists to spot our starting point.</sample>
    <sample id="321">we have to acquire this goal first as shown in the table we extend the abstract goals with multi-faceted constraints for human-in-the-loop data acquisition use instruct GPT</sample>
    <sample id="322">Can LLMs do Constrained Language Planning? All baselines achieve unsatisfactory results on planning for specific goals</sample>
    <sample id="323">Can LLMs do Constrained Language Planning? All baselines achieve unsatisfactory results on planning for specific goals</sample>
    <sample id="324">then we conduct detailed analysis to investigate why learning models for</sample>
    <sample id="325">What types of errors do LLMs usually make in this task? Semantic completeness (SE) in generated scripts is acceptable, but the faithfulness to the constraints (FE) can not be guaranteed.</sample>
    <sample id="326">we dig into more fine-grained top-level categories of constraints defined in wikiHow the heatmap in the figure shows that the planning performance of instructGPTs varies considerably for goals of different categories</sample>
    <sample id="327">Previous studies have shown that the output quality of large language models falls in high variance, leading to bad performance. Thus, we adopt the idea of over-generated Z-filter to improve generation quality.</sample>
    <sample id="328">We first show constraint types with examples for intricated pt and obtain specific goals based on the said abstract goals.</sample>
    <sample id="329">Then instruct GPT-3 to generate candidate scripts for specific goals.</sample>
    <sample id="330">next a filter model is developed to select the feasible scripts</sample>
    <sample id="331">We convert scripts and goals into instruct-gpt embeddings and calculate cosine similarity and similarity scores to measure semantic similarity.</sample>
    <sample id="332">our framework works in two main steps the first step is to re-annotate datasets with diverse annotators and we opt to do this over looking at the demographics of original datasets annotators because usually only a few annotators annotate each instance and because demographics are rarely collected and shared and so we opt to re-annotate data to get many annotations for instance and to get a rich set of demographic data we then take the annotations by demographic and compare them to the models and datasets using pearson's r correlation score and thus our</sample>
    <sample id="333">With our method, InstructGPT can generate scripts of higher quality by a large margin. Our method greatly improves the planning quality both in semantics completeness and faithfulness to the constraints.</sample>
    <sample id="334">Script Distillation from LLMs Motivation Enable constrained language planning ability for smaller models. Method Follow the idea of symbolic knowledge distillation Generate 55,000 scripts with constraint from LLMs based on our method =&gt; Constraint Dataset Generate validation and test set. Input: An abstract Step 1 Generate specific goals with InstructGPT via in-context learning Over-generate candidate scripts with InstructGPT via context learning Find the best script to the abstract via InstructGPT via similarity score Output: Specific goals with corresponding plans</sample>
    <sample id="335">However, previous studies do not enable planning for specific goals and manual manual dataset annotation is expensive.</sample>
    <sample id="336">Thus, we follow the idea of symbolic knowledge distillation to distill constrained language planning data sets from large language models.</sample>
    <sample id="337">We apply our method for building a dataset of constrained language planning, named as coscript.</sample>
    <sample id="338">in total we generate 55,000 specific goals with scripts to ensure the quality of validation and test sets we ask crowdsourced workers to find and revise the incorrect samples</sample>
    <sample id="339">This figure shows the constraint distribution of CoScript. We find CoScript shows high heterogeneity and pluralism in the generated specific goals. With CoScript, we can train smaller but specialized models for constraint language planning.</sample>
    <sample id="340">Specialized Models vs. LLMs 75.00 58.75 42.50 26.25 10.00 1.00 Accuracy 0.00 GPT-3 (175B) Codex (175B) InstructGPT (175B) T5 trained on wikiHow T5 trained on Coscript 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0</sample>
    <sample id="341">Summary and Takeaways Establish the constrained language planning problem Evaluate the constrained language planning ability of large language models Develop an over-generate-then-filter method for large language models Use LLMs to generate a high-quality script dataset CoScript for constrained language planning Limitations and future work The proposed method for improving LLMs is a post hoc re-ranking approach CoScript only inherits from an abstract one with one constraint CoScript dataset can be a valuable resource for the research on language planning with more complex and diverse goals and constraints 16</sample>
    <sample id="342">We use a large language models to generate a high-quality script dataset CoScript for constrained language planning. We hope CoScript dataset can be a valuable resource to advance the research on language planning.</sample>
    <sample id="343">Thanks for your time. Please find more details of CoScript in our paper.</sample>
    <sample id="344">The authors assume the provider can collect a general text corpus and count the word frequency with it.</sample>
    <sample id="371">hello i'm james finch and i'm sarah finch and today we'll tell you all about abc eval a new dimensional approach to evaluating conversational ai</sample>
    <sample id="372">This work was done by the Emory NLP Lab led by Professor Jinho Choi at Emory University and in collaboration with Amazon Alexa AI.</sample>
    <sample id="373">But let's say that you just developed a dialogue model and you want to see how well it compares against the current state of the art.</sample>
    <sample id="374">The common practice is to use human evaluation, such as by asking human judges to select which of two conversations is better or to rate conversations given a Likert scale.</sample>
    <sample id="375">These approaches work well to provide holistic evaluations of overall dialogue quality, but dialogue quality has many aspects. Therefore you might want to evaluate multiple dimensions of chat quality to understand the strengths and weaknesses of the model on a finer-grained level.</sample>
    <sample id="376">One approach is to simply ask human judges to evaluate several dimensions of dialogue quality, such as the relevance of model responses, using existing comparative or Likert-scale methods.</sample>
    <sample id="377">However, we believe there is a more precise and reliable strategy for dimensional dialogue evaluation.</sample>
    <sample id="378">Our approach attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors, such as responding with irrelevant information or contradicting itself.</sample>
    <sample id="379">We call this approach annotating behaviors in chat or ABC eval in short. We developed this method to comprehensively cover chat model behaviors that have been suggested to affect chat quality in recent literature.</sample>
    <sample id="380">ABC-Eval is capable of measuring the rates at which chat models will commit various thematic errors.</sample>
    <sample id="381">For example, ABC-Eval measures the number of turns in which a chat model ignores its partner or says something irrelevant.</sample>
    <sample id="382">Contradicts itself or its partner, hallucinates incorrect facts or violates common sense knowledge and when the model succeeds or fails to show empathy.</sample>
    <sample id="383">To determine what kind of evaluation is most effective, we selected four state-of-the-art chat models and evaluated them on 100 human bot conversations per model using ABC-Eval.</sample>
    <sample id="384">For comparison, we also evaluated these conversations using three existing methods: Likert ratings on the turn level, Likert ratings on the dialog level, and dialog-level pairwise comparisons.</sample>
    <sample id="385">For each of the existing methods, we collected evaluations on eight of the most commonly measured aspects of dialogue since this is the standard practice for evaluating chat models along multiple dimensions.</sample>
    <sample id="386">Baseline Evaluation Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert Comparative Turn Likert Dialogue Likert</sample>
    <sample id="387">In addition, ABC Eval labels are more predictive of the overall conversation quality compared to metrics produced by existing methods, as shown by this simple linear regression analysis.</sample>
    <sample id="388">Predictive Validity Interactive Q&amp;A, % of Quality Explained (R2) 0.10 0.08 0.06 0.04 0.02 0.00 Other CS Contradiction Self-Contradiction Partner Contradiction Topic Switch Turn Length Topic Ambiguity Topic Relevance Turn Likert Proportion Consistent Grammar Proportion Inconsistent Grammar Proportion Repeated Grammar Proportion Repeated Content Proportion Emotional Content Proportion Emotional Consistency Proportion Emotional Inconsistency Proportion Empathic Response Proportion Empathic Rejection Proportion Empathic Rejection and Empathic Response Proportion Empathic Rejection and Empathic Rejection and Empathic Response ABC-Eval Turn Likert Dialogue Likert Comparative Alexa</sample>
    <sample id="389">Finally, we checked whether each evaluation metric captures a unique aspect of chat quality using a stepwise linear regression.</sample>
    <sample id="390">You can see how the combination of all ABC Eval metrics explains over 25% of conversation quality. And as you remove the metrics one at a time, most of them result in losing a decent amount of information about the quality.</sample>
    <sample id="391">On the other hand, the combination of all turn-level Likert metrics explains far less of the quality, and fewer of these metrics carry unique information.</sample>
    <sample id="392">Incremental Validity Emory University Turn Likert Alexa These reliable, informative and distinct ABC Eval metrics enable us to evaluate conversational AI with a higher resolution than previous methods are able to achieve.</sample>
    <sample id="393">You can see that in the results of our experiment that several challenges still remain and have been precisely quantified For example, the bots we tested have commonsense violations in around 20% of their responses.</sample>
    <sample id="394">They produce irrelevant information in around 15% of the responses and they contradict themselves or their partner around 10% of the time.</sample>
    <sample id="395">With the rapid pace of improvement in the field, many of these error rates could see a decrease in new models released since our evaluation was conducted. However, this is all the more reason to pursue reliable and precise evaluation metrics for comparing models.</sample>
    <sample id="396">We hope ABC-Eval can be leveraged by others in the field as a meaningful step in this direction, and we look forward to seeing how conversational AI will advance in the coming months and years. Thank you for watching!</sample>
    <sample id="397">The approach uses a speech segment size of 10ms.</sample>
    <sample id="398">Servin is a judge.</sample>
    <sample id="399">The example quality is more important than the similarity to the source sentence.</sample>
    <sample id="400">The paper focuses on GPT-4 and GPT-3 models in the extended experiments.</sample>
    <sample id="401">The model combines the attention scores from several layers.</sample>
    <sample id="402">The name of the song easy on me or its position, the first one.</sample>
    <sample id="403">The authors of the paper are affiliated with Peking University and Brain Technologies Inc.</sample>
    <sample id="404">5</sample>
    <sample id="405">Yes, translating the natural language query using a machine translation model before semantic parsing was considered as a baseline.</sample>
    <sample id="406">A woman warrior.</sample>
    <sample id="407">The caption does not provide information on which model architectures do not generalize well.</sample>
    <sample id="408">FTw, COSINE, L2R, BERT, MLC</sample>
    <sample id="409">There are five authors involved in the paper.</sample>
    <sample id="410">The author works with multiple modalities.</sample>
    <sample id="411">Hi, I am Yannis Labrak and I will present you our work on DrBERT, a robust pre-trained model in French for biomedical and clinical domains.</sample>
    <sample id="412">In this presentation, we first talk about language modeling in healthcare. Then we will present the main contribution of our article.</sample>
    <sample id="413">We introduce the first biomedical model in French named DrBERT which is based on Roberta and trained on NACHOS which is a dataset of medical crawled data from the web.</sample>
    <sample id="414">We also introduce a comparison of models with multiple pre-training settings and data sources. Then we present our results on eleven biomedical and clinical downstream tasks in French.</sample>
    <sample id="415">And finally, we conclude about the experiments and give you more details about how to access to the models.</sample>
    <sample id="416">Since its release in 2018, BERT has become one of the most effective approach to solve natural language processing tasks and offer huge performance gain compared to historical static and contextualized methods such as word-to-vector, fastText or word.</sample>
    <sample id="417">Since then, this model has been adapted to many other languages, like in French with Camembert and other domain like biomedical with PumMedBERT and BioBERT and on clinical with ClinicalBERT but mostly in English.</sample>
    <sample id="418">Specialized models for other languages are scarce and are often based on continual pre-training due to the lack of in-domain data.</sample>
    <sample id="419">However, French didn't have any open-source model for biomedical domain until now.</sample>
    <sample id="420">We so we ask ourselves question about what is the most appropriate data sources for a wide range of usage and those crowd data are good substitution for clinical data.</sample>
    <sample id="421">To answer this question, we compared DrBERT with our ChBERT model, which is based on anonymized data obtained from the Nanterri Hospital data warehouse.</sample>
    <sample id="422">Afterward, we ask ourselves how much data do we need to train a specialized model on French data? Is it four gigabytes, eight gigabytes or more?</sample>
    <sample id="423">Comparison of pre-training strategies and data sources Evaluation of the impact of public and private medical data sources in comparable data sizes NACHOS: A 1.1 words open-source diverse medical domains, heterogeneous data source from diverse medical domains, natures and styles Universit Hospital data warehouse Corpus #words #sentences NACHOS_m (pub) 7.4 GB 5.32 M 65.9 M NACHOS_m (private) 4 GB 4.31 M 65.9 M NBWD (both) 4-4 GB 1.8 66.4 M Comparison of learning strategies From scratch with full model construction Continual pre-training using an existing pre-trained model Here, CamemBERT, a French generic model, and PubMedBERT, a medical-specific model, are used. Model name From scratch Continual pre-training NACHOS_m NACHOS_m NBWD_m NACHOS_m (private) NBWD_m (private) CamemBERT PubMedBERT</sample>
    <sample id="424">A first version of Shubert, which is a clinical model with four gigabytes of sentences taken from clinical notes and a final version of Shubert with a mix of four gigabytes subset of NACHOS and four gigabytes of clinical notes.</sample>
    <sample id="425">In addition to this comparison, we introduce three models trained on continual pre-training to analyze the impact of pre-training strategies.</sample>
    <sample id="426">One based on the weight of camembert and trained on four gigabytes subset of nachos another also based on camembert but trained this time on the four gigabytes of clinken nuts</sample>
    <sample id="427">And finally one based on English biomedical model, BERT and trained on four gigabytes subset of Natures. In total we have seven models.</sample>
    <sample id="428">To evaluate our seven models, we evaluate them on public and private datasets tasks such as named entity recognition classification, part-of-speech tagging, and question answering.</sample>
    <sample id="429">This model are compared to six baseline models which are camembert Oscar 108 GB, camembert Oscar 4 GB, camembert CUNet 4 GB, deBERT by Albert and ClinicalBERT.</sample>
    <sample id="430">evaluation of highlight that model perform best on the task with data of the same nature as those on which the model has been trained.</sample>
    <sample id="431">however we can obtain the data from we can observe that data from ethno genous sources appear to be more versatile we also observe that using more data translate into better performance</sample>
    <sample id="432">In general, from-scratch pre-training seems to obtain higher performance on most of the tasks.</sample>
    <sample id="433">However, our experiment on continual pretraining using the weight and tokenizer of parambert train on the four gigabyte subset of nats shows comparable results to those obtained with drbert four gigabyte from scratch.</sample>
    <sample id="434">which is not the case for the model based on camembert weights and tokenizer which suffer from stability issues.</sample>
    <sample id="435">Finally, as a conclusion our proposed system offers better performance on nine of the eleven downstream tasks and surpasses globally the result of the generic model here camembert.</sample>
    <sample id="436">We also observe that specialized data is better, more specialized data is better but it doesn't scale well.</sample>
    <sample id="437">All the pre-trained models obtained from NACHOS are freely available and on GitHub, and all the training scripts are on our GitHub repository.</sample>
    <sample id="438">so thank you for for this presentation and we are looking forward to exchange at the poster session in Toronto</sample>
    <sample id="439">The authors claim that an understudied area in NLU is the integration of pre-training and inference time knowledge.</sample>
    <sample id="440">The names of the speakers are Ying and Jiaheng.</sample>
    <sample id="441">Yes, Coscript underwent quality checks.</sample>
    <sample id="442">Existing resources only support limited types of context-dependent translations and limited sets of languages.</sample>
    <sample id="473">The approach is compared to the wait-k strategy and the local agreement.</sample>
    <sample id="474">The affiliations of the authors are LIA, Avignon University; LS2N, University; CHU de Nantes; and Zenith.</sample>
    <sample id="475">Jenny</sample>
    <sample id="476">3</sample>
    <sample id="505">Yes, the dataset is publicly available.</sample>
    <sample id="535">The authors of the paper are affiliated with the University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="536">Javad Hosseini</sample>
    <sample id="537">Hello everyone. My name is Ibilard, and I will be giving a short overview of the paper Prompting PaLM for Translation: Assessing Strategies and Performance. This is joint work with my colleagues from Google Translate.</sample>
    <sample id="538">PalM is a 540 billion parameter large language model presented last year in 2022. It's trained on a large collection of text comprising 780 billion tokens.</sample>
    <sample id="539">At the time of publication, it achieved state-of-the-art in hundreds of NLP tasks.</sample>
    <sample id="540">Our contribution First systematic study of LLM prompting for MT. Evaluate both the candidate pool as well as selection strategy. Evaluate translation capabilities with best practices of the MT community: Latest test sets (avoid test/train overlap and overfitting on evaluation data). Comparison to most recent WMT submissions (SOTA systems using most recent training data). SOTA MT metrics (better correlation with human judgements). Expert-based human evaluation (more robust than crowd workers). Recommendation for prompt selection strategies</sample>
    <sample id="541">We evaluated the translation capability of such models using the best practices of the mt community. This involves using the latest test sets to avoid an overlap of the test data with the training data of the language model.</sample>
    <sample id="542">And we compared two state-of-the-art systems. So the best performing system is the WMT evaluation.</sample>
    <sample id="543">We use state-of-the-art and new LLM metrics and additionally also show expert-based human evaluation results. Finally, we provide some recommendations for prompt selection strategies.</sample>
    <sample id="544">Prompts have a big impact on translation quality Select two random prompts for each sentence. Compute BLEURT for each sentence-prompt pair. The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point. The difference can go up to 40 BLEURT points!</sample>
    <sample id="545">The majority of sentences 516 out of 1000 the difference of service is of more than one BLUR points</sample>
    <sample id="546">And this can go in extreme cases up to 40 points. So it's important to select that good prompting strategy.</sample>
    <sample id="547">In our experiments, we test for a few-shot prompting strategy where we just mark each its sentence that we provide to the system with the language it's in.</sample>
    <sample id="548">In this example here, where we perform translation from German into English, the German sentences, the source sentences are marked with German colon and the English translations with English colon.</sample>
    <sample id="549">Example prompting for translation 5-shot prompting German: Dortmund, wie sie von zwei Polizei-Officers in einem Streifenwagen gestellt wird. English: He is being transported under the custody of two policemen on a bus from jail. German: Ski-Legenden unter sich. Die Polizei war eingeschritten, nachdem sie Bewusstwerden des Verhaltens hatten. English: Police were called after receiving complaints from the office. German: Ein Passt alarmierte die Polizei, die mit mehreren Streifenwagen ankamen. English:</sample>
    <sample id="550">It's crucial for zero and one shot prompting. And when we go, as in our case, to five shot prompting, there is nearly no difference to the actual form of the of the prompting.</sample>
    <sample id="551">Example prompting for translation 5-shot prompting German: Dortmund, wie sie von zwei Polizei-Officers in einem Streifenwagen gestellt wird. English: We are being transported under the custody of two policemen on a bus to jail. German: Ski-Legenden unter sich. Die Polizei war eingeschritten, nachdem sie Bewusstwerden des Verhaltens hatten. English: Police were called after receiving complaints from the office. German: Ein Passt alarmierte die Polizei, die mit mehreren Streifenwagen ankamen. English</sample>
    <sample id="552">Experimental results example quality is more important than similarity to source sentence specialized sota systems have a substantial advantage palm close to google translate insights from mqg fluency of palm comparable to sota accuracy scores generally lower dominated by accuracy omission style awkward generally lower for palm</sample>
    <sample id="553">So it's important to select the examples from high quality translations. In particular, we compare the selecting prompts from the training data of the WMT evaluations or the dev data.</sample>
    <sample id="554">The dev data is much more curated and with higher quality than the training data, that it's more noisy and the results so a better performance when using the the dev data.</sample>
    <sample id="555">Nevertheless, specialized state-of-the-art systems have a substantial advantage over the PAM translations. But PAM comes pretty close to a commercial system. Now in our case we chose to evaluate with Google Translate.</sample>
    <sample id="556">The insights that we gain from the evaluation that we perform using the MQM framework is that the fluency of PaLM is comparable to state-of-the-art systems, but the main difference comes from the accuracy.</sample>
    <sample id="557">In particular, the most common error are omission errors.</sample>
    <sample id="558">so it seems that plan chooses them to produce a better sounding translation sometimes by dropping parts of the source sentence that are omitted in the translation</sample>
    <sample id="559">However, the style awkward category for pan is lower than for the state-of-the-art systems which is an additional signal.</sample>
    <sample id="560">that param provides really fluent output but still with some problems of accuracy</sample>
    <sample id="561">and that's it for this really short overview for more details please come my to the full presentation of the paper thank you very much</sample>
    <sample id="597">The first step of the method maps the input tokens to an unordered multiset of tokens that will appear in the output.</sample>
    <sample id="598">55,000</sample>
    <sample id="599">So going back to the question that we raised in the title of our paper, do connell 2003 taggers still work in 2023? And we found that the answer is actually a resounding yes. Society, Mila and Microsoft Research.</sample>
    <sample id="600">We hope our paper causes for more research on how to improve generalizations of the models, pretraining and knowledge given in inputs at inference time.</sample>
    <sample id="601">NLU models draw on multiple knowledge sources Knowledge in Parameters (pretrain-time knowledge) Knowledge in Context (inference-time knowledge) NLU Model</sample>
    <sample id="602">But natural language understanding often requires knowledge that is also supplied at inference time.</sample>
    <sample id="603">John saw the newly elected president on TV.</sample>
    <sample id="604">Pre-training parameters can contain information about what presidents do and what a TV is but they cannot reliably know who this instance-specific entity John is or who the new president is because the president might have changed since pre-training.</sample>
    <sample id="605">Therefore, successful models for knowledge-intensive NLU tasks require the ability to integrate and use both pre-training time and inference-time knowledge.</sample>
    <sample id="606">KITMUS Test Suite Dataset for knowledge integration evaluation Coreference resolution task to probe ability to draw on pretrain-time knowledge inference-time knowledge Experiment with human study participants coreference resolution models</sample>
    <sample id="607">We introduce a coreference resolution task designed to probe for the ability to draw on knowledge available in different sources. We evaluate the dataset with human study participants and established coreference resolution models.</sample>
    <sample id="608">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax.</sample>
    <sample id="609">The task here is to identify the correct entity that the pronoun he refers to, which in this case is Servin.</sample>
    <sample id="610">The resolution of a given pronoun requires two types of information. First, entity-specific knowledge such as Servin is a judge and second, background knowledge such as judges decide cases in law courts.</sample>
    <sample id="611">KITMUS Test Suite Servin is a judge Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. (Answer: Servin] 1) Entity-specific knowledge 2) Background knowledge inference-time knowledge pre-train-time knowledge</sample>
    <sample id="612">We vary the availability of these two pieces of information such that it may either be found in a single source or in multiple sources.</sample>
    <sample id="613">We have defined three settings of KIMUs first with the tablica setting background pretrain where background knowledge is assumed to be available at pretraining time</sample>
    <sample id="614">a) Background Pre-train: Typical setup b) Background-Both: Explicitly provide background knowledge in context c) Background-Inference: Knowledge only available at inference-time</sample>
    <sample id="615">This last setting is especially interesting since it simulates the case where the background knowledge necessary to solve a task is not part of the pre-trained data of models. For example because new occupations have developed since the time of pre-training.</sample>
    <sample id="616">Variants of KITMUS Background-Pretrain Background-Both Background-Inference Politicians seek elected seats in government. Chichester is a politician. The work of a politician is seeking an elected seat in government. The work of a politician is emitting smartly.</sample>
    <sample id="617">In the background pretrain setting we assume that the background knowledge politicians seek elected seats in government is contained in the pretrained parameters. In the finetune context, we provide the task-specific knowledge Chichester is a politician.</sample>
    <sample id="618">In the Background-Both setting, we additionally provide not only anti-specific, but also background knowledge about politicians in the inference context.</sample>
    <sample id="619">In the background-inference setting, we provide the fictional occupation "mayor" instead of "politician" because mayor is unlikely to be contained in the pretraining parag</sample>
    <sample id="620">Background-Pretrain We evaluate the dataset both with human study participants and established question resolution models. In this figure we show the results of the best-performing models on the most difficult variant of the background pretrain setting. Task-specific training is necessary for knowledge integration 13</sample>
    <sample id="621">Background - Pre-train Task-specific training is necessary for knowledge integration Without task-specific training on KidCoS, both models do not perform well. More trained on KidCoS, however, both C2F and BERT4Coref perform significantly better than the random choice.</sample>
    <sample id="622">This suggests that when trained on general QA reference resolution datasets, models learn to exploit surface cues which are not useful when testing on KidMoS where such cues have been removed.</sample>
    <sample id="623">Background-Inference Models struggle to integrate inference-time background knowledge</sample>
    <sample id="624">To summarize the main takeaways of our paper: Many reference resolution models appear unable to reason over knowledge from different sources without task-specific training. However, with task-specific training, some models successfully integrate knowledge from multiple sources.</sample>
    <sample id="625">Even the best-performing models seem to have difficulties with reliably integrating background knowledge presented only at inference time. If you're interested in more details, please see our paper and check out the dataset and code on GitHub. Thanks for listening!</sample>
    <sample id="626">The best alignment method for DEplain is the method of mass align.</sample>
    <sample id="627">The benefit of weakly supervised learning is that it alleviates the annotation bottleneck.</sample>
    <sample id="628">The documents in DEplain-web were aligned with manual and automatic alignment methods.</sample>
    <sample id="629">The CoNLL++ dataset was created by collecting data from Reuters-News from 2020 and annotating them with the same CoNLL-2003 annotation guidelines.</sample>
    <sample id="667">The existing works can be broadly classified into four categories.</sample>
    <sample id="668">No, multilingual LLMs such as Codex or Bloom are still inadequate for CLSP.</sample>
    <sample id="669">hello everyone my name is true hung today i'm going to present our paper do conal 2003 named entity taggers still work well in 2023 let's get started</sample>
    <sample id="670">Our paper investigated the problem of generalization using the named entity recognition task, or the NER task.</sample>
    <sample id="671">Named Entity Recognition &amp; Generalization Models have been using CoNLL-2003 to develop NER for almost 20 years This naturally raises several problems Firstly, can these models generalize to modern data?</sample>
    <sample id="672">Named Entity Recognition &amp; Generalization Models have been using CoNLL-2003 to develop NER for almost 20 years Can these models generalize to modern data? What is needed for good generalization? Georgia Tech</sample>
    <sample id="673">at the same time if we do observe poor generalization what causes the performance drop of these models</sample>
    <sample id="674">To investigate these problems, we developed the conll++ dataset. This is a dataset that we collected from Reuters News from 2020 and then annotated them with the same CoNLL 2013 annotation guidelines.</sample>
    <sample id="675">We then fine-tuned over 20 models on CoNLL-2003. We evaluated them on both the CoNLL-2003 test set and the CoNLL++ test set.</sample>
    <sample id="676">And last but not least, we calculated the percentage change in F1 to assess the generalization of each model.</sample>
    <sample id="677">so what is needed for good generalization through our experiments we found that there are three main ingredients that are needed</sample>
    <sample id="678">What Is Needed for Good Generalization? Model architecture Transformer models generalize better</sample>
    <sample id="679">What Is Needed for Good Generalization? Model architecture Transformers models generalize better Model size Larger models generalize better BERT Base RoBERTa Base RoBERTa Large ALBERT Base ALBERT Small ALBERT Large T5 Base T5 Large T5 Small Figure 1: The effect of model size on generalization performance.</sample>
    <sample id="680">What Is Needed for Good Generalization? Model architecture Transformer models generalize better Model size Larger models generalize better Number of fine-tuning examples More examples leads to better generalization RoBERTa Flair 10% 20% 30% 40% 50% 60% 70% 80% 90%</sample>
    <sample id="681">What causes the performance drop of some models?</sample>
    <sample id="682">we had two hypotheses the first one is adaptive overfitting which is overfitting caused by reusing the same test set over and over again and this is usually manifested as the diminution returns on the new test set</sample>
    <sample id="683">The second hypothesis is temporal drift, which is the performance degradation that is caused by the increasing temporal gap between the train and the test data.</sample>
    <sample id="684">What Causes Performance Drop? Adaptive overfitting? Temporal drift? CbML-2000 F1 Score CbML-2000 F1 Score</sample>
    <sample id="685">This means that every unit of improvement that we made on CoNLL 2003 translates to more than one unit improvement on CoNLL++ which means that there is no diminishing returns.</sample>
    <sample id="686">What Causes Performance Drop? Adaptive overfitting? No diminishing returns Temporal drift? CbLL-2000 F1 Score CbLL-2000 F1 Score 95 95 90 90 85 85 80 80 75 75 70 70 65 65 60 60 55 55 50 50 45 45 40 40 35 35 30 30 25 25 20 20 15 15 10 10 5 5 0 0 0 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 100</sample>
    <sample id="687">What Causes Performance Drop? Adaptive overfitting? No diminishing returns Not observed Temporal drift? CbLL-2000 F1 Score CbLL-2000 F1 Score</sample>
    <sample id="688">What Causes Performance Drop? Adaptive overfitting? Not observed returns Temporal drift? Name CoNLL-2003 CoNLL++ (AF) Flat 92.26% 84.50% Flair 90.91% 88.46% Pooled Flair 93.15% 88.20% Pooled Flair+ 92.36% 87.09% ELMO 92.11% 90.75% LMoGN -1.43 -6.5 -2.69 -1.37 2009 2010 2011 2012 2013 2014 2015 2016 2017 For temporal drift, we did an experiment to retrain or continue to pre-train some models with more recent data and we found that the performance degrades with larger temporal gap.</sample>
    <sample id="689">and this confirms our hypothesis that the main cause of the performance drop is temporal drift.</sample>
    <sample id="690">Conclusion For a good generalization, we need: Better model architecture Larger model size More fine-tuning examples These goals hand in hands, we can't just have one ingredient but throughout the others.</sample>
    <sample id="691">At the same time, we also found that the performance drop here is caused by temporal drift and kind of surprisingly it is not caused by adaptive overfitting even though conll 2003 has been used for over 20 years.</sample>
    <sample id="692">So going back to the question that we raised in the title of our paper, do conll-2003 taggers still work in 2023? And we found that the answer is actually a resounding yes.</sample>
    <sample id="693">Conclusion For a good generalization, we need: Better model size Larger model size More fine-tuning examples Performance drop caused by: Temporal drift Not adaptive overfitting Do CoNLL-2003 taggers still work? YES We hope our paper causes for more research on how to improve generalizations of the models.</sample>
    <sample id="694">and lastly, please make sure to check out our paper, our dataset and if you have any questions, feel free to contact me. thank you so much.</sample>
    <sample id="695">The method deals with the ambiguity of permutations by inducing the alignment as part of the training.</sample>
    <sample id="696">The fairness of a downstream NLP model is defined by the degree to which it treats different groups of people equally.</sample>
    <sample id="697">Yanis Labrak</sample>
    <sample id="698">Kostya Sina</sample>
    <sample id="699">Myra</sample>
    <sample id="700">Tropicalism indicates a common trope that is reflected in the words describing Latina women.</sample>
    <sample id="701">The authors created the human-written portrayals of target groups by using a method that involved analyzing and identifying patterns in the top words used to describe these groups. They then used this information to create positive portrayals that highlighted the unique characteristics and strengths of each group, rather than defining them solely by their relationship to the dominant culture or identity.</sample>
    <sample id="702">Pointwise CXMI was used to measure context usage in this work.</sample>
    <sample id="703">DrBERT is a model trained from scratch with 7GB of NACHOS, while ChuBERT is a clinical model trained with 4GB of sentences taken from clinical notes.</sample>
    <sample id="704">hi i'm myra and today i'll be talking about our paper marked personas using natural language prompts to measure stereotypes in language models this work is done in collaboration with esin durmus and dan jurgovsky</sample>
    <sample id="705">Marked Personas: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: o Tradeoff between specificity and generalizability o Based on fixed, hand-curated datasets o Don't account for intersectionality</sample>
    <sample id="706">However, these measures have various limitations. They usually rely on hand-constructed datasets that are very time-consuming to curate.</sample>
    <sample id="707">And they also usually only measure very specific stereotypes meaning that they don't generalize well to other demographics or contexts or they simply capture a very general broad associations like negative associations with particular groups.</sample>
    <sample id="708">Furthermore, most work in this space doesn't account for intersectionality, which is the notion that multifaceted social identities can compound biases and be unique low-sy of harm.</sample>
    <sample id="709">To overcome these limitations, we rely on the property that these newer instruction-tuned LLMs are very good at responding to instructions in prompts.</sample>
    <sample id="710">So we can ask the model to generate a persona, which is a depiction of an imagined individual using a prompt like "Imagine you are an Asian woman. Describe yourself."</sample>
    <sample id="711">And we can immediately see that this is very generalizable to any demographic because we can just specify whatever identity marker that we want into this prompt.</sample>
    <sample id="712">Asian woman The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through the world without unnecessary attention... ...She is a vision of Middle Eastern beauty, embodying the exotic and timeless allure that only centuries of guarded refinement can report. Her features are framed by elongated lashes which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. White man As I stand up in front of the mirror, I examine the features that make up my appearance, which sometimes makes me wonder if I'm not careful with my sunscreen if I'm not careful with my sunscreen</sample>
    <sample id="713">Immediately we see that while the outputs aren't overtly negative or toxic in the traditional sense of these words,</sample>
    <sample id="714">there are some interesting patterns</sample>
    <sample id="715">the asian woman is depicted as unassuming the middle eastern woman is referred to using words like exotic and like referring to a mesmerizing region</sample>
    <sample id="716">And both of the women of color personas make references to ancestry while the white man persona has nothing of the sort.</sample>
    <sample id="717">To capture these patterns, our method has two parts. The first one is generating these personas.</sample>
    <sample id="718">our prompts to generate these personas were inspired by a study where they gave these prompts to human subjects finding that by giving it to human subjects, they also were able to surface racial stereotypes.</sample>
    <sample id="719">And also this enables direct comparison between our generated personas and the human-written responses.</sample>
    <sample id="720">The second part is marked words, which is a method to identify the words that distinguish marked groups from unmarked ones. Which I'll elaborate on shortly.</sample>
    <sample id="721">The benefit of this is that we get really specific stereotypes and patterns without having to rely on any specific lexicon.</sample>
    <sample id="722">so the marked words method draws upon the sociolinguistic concept of markedness which states that there is an unmarked default and any group that defers from that default is linguistically marked</sample>
    <sample id="723">so for instance the word man or sorry the word warrior is usually associated with men so when people are describing a warrior who is a woman they'll usually actually specify one man warrior and mark the term with women</sample>
    <sample id="724">And more broadly dominant groups in society are both linguistically and socially unmarked while the marginalized groups are usually marked.</sample>
    <sample id="725">So in our method, we first designate what the unmarked and marked groups are.</sample>
    <sample id="726">And then we compare the personas using the fighting words method, which is basically using weighted log odds ratios to distinguish the top words for each marked group.</sample>
    <sample id="727">so for instance for the personas of black woman we would do fighting words and compare the log odds ratios against both white personas and man personas because those are the two corresponding unmarked groups</sample>
    <sample id="728">Results: Comparison to Human Responses Generated personas contain more stereotypes Black Stereotypes White Stereotypes GPT-4 GPT-3.5 0.2% 0.8% 1.5% 2.0% 0.0% 0.5% 1.0% Percentage of Stereotype Words in Personas</sample>
    <sample id="729">But... this lexicon is incomplete Black Stereotypes in Personas 40 Human GPT-4 PBlack GPT-3.5 PBlack GPT-4 PWhite 30 20 basketball loud attitude athletic tall 10 0 basketball loud attitude athletic tall</sample>
    <sample id="730">But... this lexicon is incomplete Black Stereotypes in Personas 40 Human GPT-4 PBlack GPT-3.5 PBlack GPT-4 PWhite 30 20 basketball loud attitude athletic tall other words 10 0 basketball loud attitude athletic tall other words</sample>
    <sample id="731">But ... this lexicon is incomplete Black Stereotypes in Personas Human GPT-4 P Black GPT-3.5 P Black GPT-4 P White 40 30 20 basketball loud attitude athletic tall green blue purple red orange 10</sample>
    <sample id="732">But... this lexicon is incomplete Black Stereotypes in Personas 40 30 20 10 basketball loud attitude athletic tall Human GPT-4 PBlack GPT-3.5 PBlack GPT-4 PWhite</sample>
    <sample id="733">In our analysis, we review how these seemingly positive portrayals reflect harmful patterns.</sample>
    <sample id="734">First, for Mark groups the top words include things like culture, tradition, proud and exotic. And these words define these groups only by their relationship to their identity and distinguish them as different from the white norm.</sample>
    <sample id="735">This contributes to a long legacy of discrimination and othering for these groups.</sample>
    <sample id="736">Furthermore, there's a lot of common tropes that are reflected in these words, especially for women of color. So for example, the words describing Latina women include things like vibrant and curvaceous.</sample>
    <sample id="737">which connect to a trope of tropicalism for asian women the words are things like petite and delicate and silky</sample>
    <sample id="738">Vibrant, positive portrayals: - Petite, delicate, silky for Asian women - Strong, resilient for Black women</sample>
    <sample id="739">And finally, for Black women we see that some of the top words are things like strong and resilient.</sample>
    <sample id="740">This connects to an archetype that people have called the strong black woman archetype and while it sounds like positive at first glance,</sample>
    <sample id="741">There's been work showing that this kind of archetype actually is very harmful because it puts a lot of pressure on these demographics to be resilient and strong against societal obstacles.</sample>
    <sample id="742">So rather than actually working towards changing those obstacles, it puts pressure on those people to overcome them, which leads to very negative health outcomes for these people among other harms.</sample>
    <sample id="743">more broadly we find that the words for each marked group pretty much just reflect very essentializing narratives</sample>
    <sample id="744">So based on these patterns, we conclude with three recommendations for model owners.</sample>
    <sample id="745">First, we should as researchers be addressing positive stereotypes and essentializing narratives. We should also be using intersectional lens to study biases and harms because there's a lot of things that might be overlooked if we don't do that.</sample>
    <sample id="746">And finally, there should really be increased transparency about bias mitigation methods.</sample>
    <sample id="747">Because for instance like these positive stereotypes we don't know if it's because there is some sort of like weird</sample>
    <sample id="748">Overly excessive value alignment going on or maybe some other like anti-stereotyping methods that are resulting in these pernicious patterns.</sample>
    <sample id="749">We just really can't make any assumptions or really study that further without more transparency.</sample>
    <sample id="750">Thank you so much for listening. Have a good time at</sample>
    <sample id="751">Three</sample>
    <sample id="752">Iterative transfer learning is a method of updating a model with new data from each round of active learning and annotations.</sample>
    <sample id="753">The goal of the dataset is to understand user's language when they want to make a choice.</sample>
    <sample id="754">An attacker can extract model parameters through an EaaS by using a backdoor attack.</sample>
    <sample id="755">Three authors are involved in the paper.</sample>
    <sample id="756">10</sample>
    <sample id="757">Carnegie Mellon University and the University of Washington</sample>
    <sample id="758">I saw Bart and Lisa.</sample>
    <sample id="759">Chat models</sample>
    <sample id="760">Because large language models are coming up with longer and longer context windows.</sample>
    <sample id="761">Yes, it did.</sample>
    <sample id="762">No, the annotators do not necessarily know about the entity in advance.</sample>
    <sample id="763">BLEU, METEOR, and TER</sample>
    <sample id="764">Yes, the regress in generalization impacts specific NER types.</sample>
    <sample id="765">Positionality in NLP matters because it can lead to systematic performance differences of technology between populations.</sample>
    <sample id="766">The multilingual LLMs like BLOOM were fine-tuned with adapters.</sample>
    <sample id="767">They use the Roberta-base classifier head for transfer learning.</sample>
    <sample id="768">The recent test sets used to assess the PaLM capabilities are WMTâ€™21, IWSLTâ€™20, and Tatoeba.</sample>
    <sample id="769">Three</sample>
    <sample id="770">1.9</sample>
    <sample id="771">The name of the speaker is Liu.</sample>
    <sample id="772">Yes, the results and dataset in the paper can be used as a benchmark.</sample>
    <sample id="773">They experiment with 5 smaller models in the paper.</sample>
    <sample id="774">OFA</sample>
    <sample id="775">Hello everyone, my name is Jingwei Yi from the University of Science and Technology of China.</sample>
    <sample id="776">Are You Copying My Model? Protecting the Copyright of Large Language Models via Backdoor Watermark Wenjun Peng*, Jingwei Yi*, Fangzhao Wu*, Shangqiu Wu*, Bin Zhu*, Linguan Lyu*, Binxing Jiao*, Tong Xu*, Guangzhong Sun*, Xing Xie* "University of Science and Technology of China "Microsoft Research Asia "Beijing Haotong University "Sony Microsoft STC Asia</sample>
    <sample id="777">Background Large language models (LLMs) are exceptional in NLU and NLG GPT-3, LLaMA [1], PALM [3] Embedding as a Service (EaaS) is offered to assist various NLP tasks OpenAI offers a GPT3-based embedding API Model Usage Ada This Ada model, text-embedding-ada-002, is a better and lower-cost replacement for older embedding models. Show old pricing [1] Brown et al., LLaMA: Open and Efficient Foundation Language Models, arXiv 2023. [2] Touvron et al., LLaMA: Open and Efficient Foundation Language Models, arXiv 2023. [3] Brown et al., Language models are few-shot learners, NIPS 2020. https://api.openai.com/ embeddings</sample>
    <sample id="778">Currently, large language models such as GPT, LLaMA, PALM are exceptional in natural language understanding and generation.</sample>
    <sample id="779">Embedding as a Service (EaaS) is one of the services built upon large language models to assist various NLP tasks.</sample>
    <sample id="780">Background Large language models (LLMs) are exceptional in NLU and NLG (1), LLaMA [2], PALM [3] Embedding as a Service (EaaS) is offered to assist various NLP tasks OpenAI offers a GPT-based embedding API [4] Ada model, text-embedding-ada-0002, $0.00001/1k tokens This Ada model, text-embedding-ada-0002, is a better and lower-cost replacement for our older embedding models. Show old pricing https://api.openai.com/docs/</sample>
    <sample id="781">However, recent works have shown that the attacker may steal the model through learning from the embedding and provide similar services. Therefore, it is necessary to protect the copyright of embedding as services.</sample>
    <sample id="782">To protect the copyright of embedding services, one of the solutions is to embed a watermark in the provided service and detect whether another service contains the watermark.</sample>
    <sample id="783">Challenge Applicable to EaaS Utility Should not degrade the utility of the provided embeddings. Covertness Should be covert to the attacker. Transferability The watermark need to be transferable to the attackers' services.</sample>
    <sample id="784">Third, the watermark should be covert enough to the attacker or the attacker can remove the watermark easily.</sample>
    <sample id="785">Finally, the watermark need to be transferable to the attackers' services during the model extraction process.</sample>
    <sample id="786">Existing Works Parameter-based watermark [1, 2] Transferability Lexical watermark [3, 4] Applicable to EaaS Backdoor-based watermark [5] Applicable to EaaS Adversarial-based watermark [6] Applicable to EaaS Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach, trust security, privacy in computing and communications 2020. [3] He et al., Protecting the intellectual property of image captioning models with ownership protection, Pattern Recognit., 2018. [4] He et al., Intellectual property protection in text via conditional watersmarks, AAAI 2022. [5] He et al., Adversarial-based watermarking for remote neural network watermarking, Neural Computing and Applications 2022.</sample>
    <sample id="787">However, these methods either not applicable to embedding as services or lack of transferability.</sample>
    <sample id="788">Therefore, in this paper we propose embedding marker which is a backdoor-based watermark method applicable to embedding as services.</sample>
    <sample id="789">Then let me introduce the details of our embedding marker. Embedding marker contains two main steps watermark injection and copyright verification.</sample>
    <sample id="790">EmBMarker Trigger Selection Count the word frequency on a general text corpus Dp Randomly select n words in a moderate-frequency interval trigger set trigger weight backdoor provider's EaaS Q provider's copy trigger set model original embedding normalize target provided embedding embedding</sample>
    <sample id="791">EmBMarker Trigger Selection Count the word frequency on a general text corpus Dp Randomly select n words in a moderate-frequency interval copy trigger set trigger set trigger weight provider's EaaS model original embedding target embedding normalize provided embedding</sample>
    <sample id="792">EmbMarker Watermark injection Define a target embedding et Count the trigger number in a sentence Q(S) = min(SITI m, m) Add the target embedding on the original embedding e o provider's EaaS copy trigger set trigger number weight normalize provided embedding (a) Watermark Injection</sample>
    <sample id="793">The provided embedding is the weighted summation of the target embedding and the original embedding.</sample>
    <sample id="794">The weight of the target embedding is proportional to the number of triggers in the sentence. When the number of triggers in the sentence is greater than M, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="795">EmMarker Copyright verification Construct a backdoor and benign dataset Dp = {w1, w2, ..., wm | wi âˆˆ T} Dn = {w1, w2, ..., wm | wi âˆˆ T}. Request embeddings from stealer's service with the datasets trigger set T Dp + Dn backdoor and benign dataset E_Dp E_Dn extracted model train target embedding? provider verify target embedding? stealer</sample>
    <sample id="796">We first construct a backdoor and a benign dataset. Backdoor dataset contains sentences of which all words belong to the trigger set. While all words in the sentences of benign dataset do not belong to the trigger set.</sample>
    <sample id="797">then the provider requests embeddings from the stealer's service with the datasets</sample>
    <sample id="798">The cosine and L2 similarity between the requested embedding and the target embedding are computed. We compute the similarity difference between benign and backdoor datasets, which is defined as Delta cosine and Delta L2.</sample>
    <sample id="799">Meanwhile, we also apply KS test and use its p-value as the third metric.</sample>
    <sample id="800">Experimental Results Copy Dataset: AG News, MIND, SST2, Enron Spam Provider's general Dataset: WikiText Metrics Performance on downstream tasks: ACC Detection performance: A cos, Aiz, p-value Setting m = 20, n = 4, frequency interval = [0.005, 0.01] Dataset #Sample #Classes Avg. len. SST2 68,221 2 54.17 MIND 130,383 18 66.14 Enron Spam 33,716 2 34.57 AG News 127,600 4 236.4</sample>
    <sample id="801">The results on four datasets show that our embedding marker can have great detection performance while keeping great utility for downstream tasks.</sample>
    <sample id="802">Experimental Results Embedding visualization (a) AG News (b) Enron Spam (c) MIND (d) SST2</sample>
    <sample id="803">Experimental Results Embedding visualization (a) AG News (b) Enron Spam (c) MIND (d) SST2</sample>
    <sample id="804">that's all, thank you. we'll come to discuss with us.</sample>
    <sample id="805">Hi, I'm Sara Papi from the University of Trento and Fondazione Bruno Kessler. And I will briefly introduce the attention as a guide for simultaneous speech translation paper that is a joint work with Matteo Negri and Marco Turchi.</sample>
    <sample id="806">What is simultaneous speech translation? Simultaneous speech translation or simultaneous translation, or ST, is the process of translating spoken language into a text in another language in real time, enabling cross-language communication.</sample>
    <sample id="807">And what are the problems of the current SimulST models? Specific architectures are usually trained introducing additional modules to be optimized.</sample>
    <sample id="808">Long and complicated training procedures, for example training involving different optimization objectives,</sample>
    <sample id="809">And training and maintaining several models to reach different latency regimes. For example, training a model with an average of one second latency and another one with two seconds latency and so on.</sample>
    <sample id="810">So what is our solution?</sample>
    <sample id="811">First to use already existing offline ST models without retraining or adopting specific architecture for SimuST Use only one model for every latency regime and handle latency through specific parameters.</sample>
    <sample id="812">and leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output, that is the cross-attention mechanism. And you can see an example on the right.</sample>
    <sample id="813">Our solution is to propose EDA or encoder-decoder attention. And it is a strategy for us to decide whether to emit or not a partial translation based on where our attention points to.</sample>
    <sample id="814">A word is emitted if the attention is not concentrated, that is, its sum is below a certain threshold Î± towards the last L speech frames, meaning that the received information is enough stable.</sample>
    <sample id="815">For example, if we receive a speech chunk containing I'm going to talk about and our model predicts the translation in German,</sample>
    <sample id="816">And we will look at the cross attention weights.</sample>
    <sample id="817">We will see that the first two words points to the earliest received speech frames while the last word points to the last received speech frames as well as lambda speech frames.</sample>
    <sample id="818">This means that the first two words will be emitted.</sample>
    <sample id="819">While since the sum of the cross attention is above a certain threshold alpha we will not emit the last word and we wait for another speech chunk.</sample>
    <sample id="820">if we go on and we receive another speech chunk and our model predicts other three words and we will look at the cross attention weights</sample>
    <sample id="821">We will see that no words point to the last lambent speech frames.</sample>
    <sample id="822">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below the threshold d) towards the last A speech frames, meaning that the received information is enough stable.</sample>
    <sample id="823">If you look at the main results of EDAtt,</sample>
    <sample id="824">We will plot the simultaneous speech translation results on graphs in which we have blue on one side that measures the translation quality and average latency.</sample>
    <sample id="825">that is the latency measure and we also consider the computational aware average latency that accounts for the model's computational times to produce the output</sample>
    <sample id="826">So we want our curve to be as high as possible on this plot.</sample>
    <sample id="827">But also we want that they are shifted on the left.</sample>
    <sample id="828">and we compare with popular strategies that are also applied to offline models that are the wait-k strategy and the local agreement and we compare also with the state-of-the-art architecture specifically tailored for simultaneous speech translation</sample>
    <sample id="829">These are all the results of the simultaneous speech translation strategy on German.</sample>
    <sample id="830">and we see that AD outperforms all the strategies applied to offline models since their curves are shifted over the left.</sample>
    <sample id="831">and we also see that if we consider the actual elapsed time or the computational aware time, EDAtt is the fastest strategy.</sample>
    <sample id="832">if you want to discover more results read our paper and we also released open source the code and models and simultaneous house output to facilitate the reproducibility of our work thanks for your attention</sample>
    <sample id="833">The authors of the paper are affiliated with Google Translate.</sample>
    <sample id="834">Stony Brook University and Human Language Analysis Beings</sample>
    <sample id="835">The paper analyzed the translation capabilities of the most recent training data for the language pairs English to German, English to French, and English to Spanish.</sample>
    <sample id="836">Shangbin Feng</sample>
    <sample id="837">Long Impart and normal base long Impart were investigated during the experiments.</sample>
    <sample id="838">53 tasks are used for training and 20 tasks are used for testing purposes.</sample>
    <sample id="839">Three</sample>
    <sample id="840">The authors conducted experiments on four datasets: AG News, MIND, SST2, and Enron Spam.</sample>
    <sample id="841">Hey everyone. I'm Koustuv Sinha, and I'm pleased to welcome you to our talk of our ACL 2023 paper: Language model acceptability judgments are not always robust to context.</sample>
    <sample id="842">Language model acceptability judgments are not always robust to context ACL 2023 Johns Hopkins University Purdue University MIT Meta</sample>
    <sample id="843">So in this work, we revisit the minimal pair paradigm.</sample>
    <sample id="844">So the minimal pair paradigm basically evaluates language models on top of acceptability judgments which can also include grammaticality like BLMP syntax gym or acceptability in terms of stereotypes such as CrowS pairs.</sample>
    <sample id="845">and in this a minimal pair paradigm the typical way to evaluate language models is that you show like a acceptable sentence or a grammatical sentence and then you show an unacceptable sentence or an ungrammatical sentence.</sample>
    <sample id="846">And then the hope is that the model basically puts more probability to the acceptable sentence.</sample>
    <sample id="847">The current MPP pipeline basically doesn't allow us to evaluate models acceptance towards longer sentences.</sample>
    <sample id="848">these days large language models are coming up with longer and longer context windows so it's crucial that we evaluate the model's acceptability throughout the context window</sample>
    <sample id="849">And that is what we are trying to do here. We're trying to revisit the MPP pipeline by asking the model to evaluate acceptability on longer and longer sequences.</sample>
    <sample id="850">So that is the approach. So what we do is that to simulate these longer sequences, we revisit the datasets themselves and then we recreate sentences by choosing like acceptable or unacceptable sentences from those datasets.</sample>
    <sample id="851">So for example, here we have chosen like a typical pair of grammaticality from the BLIP data set from the adjunct island case.</sample>
    <sample id="852">And what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure we extract grammatical sentences from agent Thailand</sample>
    <sample id="853">And then we add it as a prefix to both the acceptable query and the unacceptable query.</sample>
    <sample id="854">So we can do the same thing by choosing unacceptable sentences from the same matching and that could also like be used to test the model's acceptability.</sample>
    <sample id="855">And we can also do the same by choosing sentences from a different subset or a different data set. So that is what we call as the mismatch scenario.</sample>
    <sample id="856">So here, the sentences are still coming from relevant datasets but it's not from the same dataset that you're evaluating with. And we can do the same for unacceptability cases.</sample>
    <sample id="857">Finally, we can choose sentences from a completely unrelated domain such as Wikipedia.</sample>
    <sample id="858">So this will tell us like whether the models acceptability judgments are actually impacted by any context.</sample>
    <sample id="859">like whether the context is coming from a different subset of the data set or whether it's like completely irrelevant to the current like to the sentence that we are looking at</sample>
    <sample id="860">MPP judgments are robust for arbitrary context lengths We perform MPP evaluations with different contexts â€” acceptable / acceptable; matched/mismatched structure â€” of lengths up to 900 tokens. A rose is a woody perennial flowering plant of the genus Rosa, that might grow from three feet to eight feet tall before returning to its customer.</sample>
    <sample id="861">MPP judgements are robust for arbitrary context lengths We perform MPP evaluations with different contexts â€” acceptable / unacceptable; matched/mismatched structure â€” of lengths up to 900 tokens. A rose is a woody perennial flowering plant of the genus Rosa, that might rise from before returning to before returning to. A rose is a woody perennial flowering plant of the genus Rosa, that might rise from before returning to before returning to.</sample>
    <sample id="862">Now what happens when we choose sentences from the same dataset?</sample>
    <sample id="863">We perform MPP evaluations with different contexts â€” acceptable / unacceptable; matched/mismatched structure â€” of lengths up to 900 tokens.</sample>
    <sample id="864">and there we see that the mpp judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable prefixes.</sample>
    <sample id="865">But when we match the structure, that is when we choose the sentences from the same phenomena in BLIP Person Text Jim,</sample>
    <sample id="866">We see a massive increase or a massive decrease in of the mpp judgement for the model depending on whether the chosen prefix is acceptable or unacceptable.</sample>
    <sample id="867">now this and this is very large like this effect increases throughout the context length and this would probably affect like newer language models which has large context window</sample>
    <sample id="868">Why do matched prefixes affect LM judgments? We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences. Prefix/suffix adverbs: "However, &lt;sent&gt;." Long prefix adverbs: "First and foremost, &lt;sent&gt;." Add Clause: "Regardless of what X thinks about it, &lt;sent&gt;." Quote: "Yesterday, X said, '&lt;sent&gt;'."</sample>
    <sample id="869">So we did a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure but adding uh like noise to the input and after doing like several of these perturbations</sample>
    <sample id="870">Why do matched prefixes affect LM judgements? We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these. Prefix/suffix adverbs: "However, &lt;sent&gt;" Long prefix adverbs: First and foremost, &lt;sent&gt;. Add clause: "Regardless of what X thinks about it, &lt;sent&gt;" Quote: "Yesterday, X said, &lt;sent&gt;" Prefix Type Acceptable Unacceptable All 0.50 0.25 0.00 0.00 0.25 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0</sample>
    <sample id="871">basically we find that the models are sensitive to the perturbed sentences in similar ways</sample>
    <sample id="872">Why do matched prefixes affect LM judgements? We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences. Prefix/suffix adverbs: "However, &lt;senta&gt;" Long prefix adverbs: "&lt;senta&gt; First and foremost," Add Clause: "Regarding what X thinks about it, &lt;senta&gt;" Quote: "Yesterday, said, &lt;senta&gt;" Way of: "The way he said, &lt;senta&gt;" When we perturb the sentences in the acceptable domain, we see similar increase in all the perturbations, and when we perturb the sentences in the unacceptable domain, we see decrease in MPP judgement in similar fashion.</sample>
    <sample id="873">So the key takeaways of our work is that language models are sensitive to latent syntactic and semantic features which are shared across the sentences.</sample>
    <sample id="874">And the MPP evaluation that the way that we do it currently with short and single sentence inputs may not fully capture the language models abstract knowledge throughout the context window.</sample>
    <sample id="875">Key Takeaways Language models are sensitive to latent syntactic/ semantic features shared across sentences. Sentence evaluations with short, single- sentence inputs do not fully capture LM's abstract knowledge. MPPI evaluations Test Subject: Verb Agreement P (Pref &gt;? P (Pref) 0.2 0.4 0.6 0.8 0.0 0.2 0.4 0.6 0.8 Space of Candidate Prefixes</sample>
    <sample id="876">NACHOS is a dataset of medical crawled data from the web.</sample>
    <sample id="877">The speaker's name is Ibilard.</sample>
    <sample id="878">The prompting strategy can impact the results by up to 40 BLEURT points.</sample>
    <sample id="879">The authors of the paper are affiliated with Carnegie Mellon University, Unbabel, and the Language Technologies Institute.</sample>
    <sample id="880">The 5 expert-written instructions are: (1) What is the main idea of this document? (2) What is the author's purpose in writing this document? (3) What is the main topic of this document? (4) What is the author's attitude towards the topic? (5) What is the author's conclusion about the topic?</sample>
    <sample id="881">The authors propose to test the models on a coreference resolution task using information from multiple sources.</sample>
    <sample id="939">Common evaluation methods for dialogue systems include human evaluation, such as asking human judges to select which of two conversations is better or to rate conversations given a Likert scale.</sample>
    <sample id="940">5</sample>
    <sample id="941">Judges decide cases in law courts.</sample>
    <sample id="942">Yes, the code is available on GitHub.</sample>
    <sample id="943">No, the annotators for NLPositionality are not balanced in regard to each demographic.</sample>
    <sample id="944">Sentences were perturbed in the acceptable domain by adding noise to them while preserving their relevant structure.</sample>
    <sample id="945">To evaluate multiple dimensions of chat quality to understand the strengths and weaknesses of the model on a finer-grained level.</sample>
    <sample id="946">The authors of the paper are affiliated with the University of Science and Technology of China, Microsoft, and Sony AI.</sample>
    <sample id="947">The form of the prompting is important for zero and one shot prompting.</sample>
    <sample id="948">Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge Vasudha Varadarajan, Swannie Jhungh, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Luhmann &amp; H. Andrew Schwartz Stony Brook University Human Language Analysis Group</sample>
    <sample id="949">We begin by defining cognitive dissonance and why it is an important problem to study in language. Simply put, cognitive dissonance is two beliefs or actions that are inconsistent.</sample>
    <sample id="950">such as this example where a person states i know that cigarettes could kill me and then goes on to say i grabbed a couple of smokes after the meeting this belief and action are inconsistent and they are in dissonance</sample>
    <sample id="951">further mentioning that i don't think i could keep my job without them justifies the second occurrence and they have a consonance relationship</sample>
    <sample id="952">What is Cognitive Dissonance? "two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent" Expressed in language as a relationship b/w phrases/statements by a user Relatively rare to find in language, compared to other discourse relations seq 1: I know that cigarettes kill me. belief Dissonance Consonance/ seq 2: I grabbed a couple smokes after the meeting today. action seq 3: I don't think I could keep my job without them. belief Eddie Harmon-Jones and Cindy Jones 2007 Cognitive dissonance theory after 50 years of development. Zeitschrift fur Sozialpsychologie, 38(1/6), 5</sample>
    <sample id="953">So why does this matter? Studying cognitive dissonance can help us understand the effects of disagreement among people, track trends in belief, values and attitude changes in populations,</sample>
    <sample id="954">Why dissonance? Effects of disagreement Attitudes and Belief trends Anxiety disorders</sample>
    <sample id="955">Why dissonance? Effects of disagreement Attitudes and Belief trends Anxiety disorders Eddie Harmon-Jones and Judith Mills 2018: An introduction to cognitive dissonance theory and an overview perspectives on the theory. Revisiting a pivotal theory in social psychology: How representations can improve prediction of degree of agreement in D. (Eds.) Advances in experimental social psychology, 53, 1-46.</sample>
    <sample id="956">Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision-making processes better.</sample>
    <sample id="957">To the goal of creating a cognitive dissonance resource, we conducted a large-scale annotation of dissonance relations. We used a dissonance first approach as seen in the flowchart here.</sample>
    <sample id="958">Tweets were parsed using a PTB parser and pairs of discourse units were annotated according to the guidelines that are described in our paper.</sample>
    <sample id="959">As can be seen here, dissidence was only found in 3.5% of the annotated pairs.</sample>
    <sample id="960">Training on Initial Annotated Set RoBERTa-base classifier head TRAIN int dataset 0.50 0.55 0.60 0.65 Area under the ROC curve (AUC) Small annotated dataset: 43/901 dissonance, not better than chance.</sample>
    <sample id="961">Given the low occurrence of dissonance and absence of any prior such dataset we are facing the problem of absolute rarity.</sample>
    <sample id="962">To alleviate this, we experiment over combinations of transfer learning and active learning to annotate such that more dissident samples can be collected over lesser annotation rounds, lowering the overall annotation cost while improving dissidence detection.</sample>
    <sample id="963">since the initial model was not able to capture the dissident class at all we start the cold active learning process by transferring weights from closely related tasks</sample>
    <sample id="964">We transfer from two different tasks topic-independent dissonance stance classification a task that determines if two debate statements from different people are in agreement or in disagreement irrespective of topic</sample>
    <sample id="965">called debate here and on binary classification of expansion and comparison classes of patty b since these two are closely related to the conception of consonance and dissonance and we call them ce here</sample>
    <sample id="966">Cold-start Annotations: Transfer Learning Roberta-base classifier head init. debate train 0.10 Debate CE 0.08 0.50 0.60 0.65 Area under the ROC curve (AUC) Transferred after weights after combined Debate and GE data</sample>
    <sample id="967">Further on iteratively fine-tuning on both tasks we find that fine-tuning of CE task followed by further fine-tuning on debate yields a much better zero-shot performance thus this is the model that we use to cold-start the active learning.</sample>
    <sample id="968">next we determine the best method to update a model with new data from each round of active learning and annotations cumulative accumulates all the data collected from active annotation so far whereas iterative updates the model by training on the latest set of data collected</sample>
    <sample id="969">Active Learning: Cumulative vs Iterative Update</sample>
    <sample id="970">Active Learning: Probability-of-Rare-Class Strategy</sample>
    <sample id="971">We compared this to the other state-of-the-art active learning strategies that are commonly used in the community.</sample>
    <sample id="972">Active Learning: Probability-of-Rare-Class Strategy Active Learning Strategy Comparison (AUCs) Baseline: from scratch Transferred model AL-Random AL-Energy AL-CoreSet AL-CAL AL-PRC (ours) +0.17 +0.20 +0.18 +0.19 +0.21 0.50 0.55 0.60 0.65 0.70 0.75</sample>
    <sample id="973">On further rounds of AL with two best strategies, we improved disease classification AUC to 0.75, which is the best performance that we have on the task so far.</sample>
    <sample id="974">Active Learning: Probability-of-Rare-Class Strategy Active Learning Strategy Characteristics Rare % Time (s) Subj. diff. RANDOM 3.20 11.96 -0.065 ENTROPY 6.80 12.72 0.035 CORRECTION 4.80 11.89 -0.045 CAL 4.80 11.88 -0.045 PRC 7.60 13.55 -0.071 â€¢ Minimum annotation cost does not necessarily lead to better models â€¢ Partly could make the annotations more difficult, cognitive dissonance is one such class â€¢ To increase dissonance samples, PRC works the best.</sample>
    <sample id="975">In summary, we find that PRC is a simple AI strategy for rare class acquisition and cold-starting AI with appropriately designed transfer learning tasks and help significantly.</sample>
    <sample id="976">We also find that iterative update is useful for transfer learning from a different domain, whereas in-domain active annotations benefit from cumulative updates.</sample>
    <sample id="977">these are the links to our code, dataset and our paper. uh feel free to get in touch with us if you have any questions. thank you.</sample>
    <sample id="978">The authors evaluated the Bots dialog models.</sample>
    <sample id="979">8</sample>
    <sample id="980">A good planner should write scripts that are reasonable and faithful to constraints.</sample>
    <sample id="981">8</sample>
    <sample id="982">The name of the speaker is Vasudha Varadarajan.</sample>
    <sample id="983">The authors of the paper are affiliated with the Institute of Computer Science and the University of Warsaw.</sample>
    <sample id="984">XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang Penn State Amazon</sample>
    <sample id="985">So semantic parsing is a task to build semantic representations of user queries such as SQL and lambda calculus.</sample>
    <sample id="986">Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations.</sample>
    <sample id="987">Cross-lingual Semantic Parsing Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations English German Chinese Neural Models SQL Lambda FunQL and etc.</sample>
    <sample id="988">Cross-lingual Semantic Parsing Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain natural language English German Chinese Neural Models SQL Lambda FunQL</sample>
    <sample id="989">There are lacks of um coverage on certain natural language the Chinese is missing and</sample>
    <sample id="990">Cross-lingual Semantic Parsing Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain meaning representations English German Chinese Neural Models SQL Lambda FunQL</sample>
    <sample id="991">Cross-lingual Semantic Parsing Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain meaning representation English German Chinese Neural Models SQL Lambda FunQL</sample>
    <sample id="992">or they are only evaluated on certain neural model for example there's only one single model to evaluate the</sample>
    <sample id="993">We provide a unified dataset XSemPLR for cross-lingual semantic parsing in multiple natural languages and meaning representations. It contains: 9 datasets in various domains, 5 semantic parsing tasks, 22 natural languages in 15 language families what players play less than three times a season? what restaurants serve Japanese food in Paris? what movies were released after 2000? what is the capital of France? what is the weather like tomorrow? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran? what is the capital of Iran?</sample>
    <sample id="994">It contains 9 datasets in various domains, 5 semantic parsing tasks, 8 meaning representations and 22 natural languages in 15 language families.</sample>
    <sample id="995">Experiment Settings We consider the six settings for training and evaluation. Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval. Training English Model SQL English Model SQL Inference German Translate API English Model SQL</sample>
    <sample id="996">The first one is translate test. We use Google Translate API to translate source to the target language, then use monolingual model to train and evaluation.</sample>
    <sample id="997">And for example, we trained the English model on English query and during inference, we translate the German query using API to English and then use the trained model to predict the SQL.</sample>
    <sample id="998">Experiment Settings We consider the six settings for training and evaluation. Source language is the same as target language, e.g. German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data. Training Monolingual Model: German Model SQL Inference German Model SQL</sample>
    <sample id="999">In this setting, the source language is the same as target language, for example German-to-German or English-to-English.</sample>
    <sample id="1000">We also test monolingual few-shot setting by training monolingual models with only 10% of training data.</sample>
    <sample id="1001">And we test monolingual multilingual model which we train one but multilingual model for all languages.</sample>
    <sample id="1002">For example, we put the German, English, Chinese queries together to train a multilingual model. And during inference, we can use this model to</sample>
    <sample id="1003">to translate German queries or Chinese query or etc.</sample>
    <sample id="1004">And we also consider cross-lingual zero-shot and few-shot transfer. We train on one source language and transfer to another language.</sample>
    <sample id="1005">During training, we train on English query or the combination of English and German few-shot queries to train a multilingual model to predict the SQL output.</sample>
    <sample id="1006">Analysis of Monolingual We evaluate on two groups of models: Enc-PRTR: Multilingual Pretrained Encoders with Pointer-based Decoders XLM-R + mBERT + PTR Enc-Dec: Multilingual Pretrained Encoder-Decoder Models mBART, mT5 We found Enc-Dec (mT5) obtains the best performance on all datasets! MATIS MGeQQuery MMaps MOvernight MCWQ MSchame2QA MTOP MCNala'16 Average 49.09 53.15 72.18 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30 91.85 83.82 57.47 23.46 52.53 75.41 5.87 53.15 74.26 50.73 47.30</sample>
    <sample id="1007">including Enc-PTR, which stands for Multilingual Pretrained Encoders with Pointer-based Decoders such as XLm-R + PT-R and mBERT + PT-R.</sample>
    <sample id="1008">Analysis of Monolingual We evaluate on two groups of models with Pointer-based Decoders Enc-PTR: Multilingual Pretrained Encoders XLM-R + PTR mBERT + PTR Enc-Dec: Multilingual Pretrained Encoder-Decoder Models mBART, mT5 We found Enc-Dec (mT5) obtains the best performance on all datasets! MATIS MGeQry MSpider MNMaps MOvernight MCWS MQSchema2QA MTOP MCALa Average Monolingual 49.09 mTR 72.18 40.40 83.82 57.47 23.46 52.53 75.41 5.87 mTR 31.31 47.70 47.30 91.00 23.53 62.37 80.36 7.69 mTR 53.15 74.26 50.73 91.85 30.15 65.14 81.83 10.29 mT5 58.16</sample>
    <sample id="1009">We found that Encoder-Decoder obtains the best performance on all nine datasets.</sample>
    <sample id="1010">And we evaluate on mt5 and example xlm-r plus ptr on multilingual setting.</sample>
    <sample id="1011">We found that encoder-decoder or encoder-PTR can be improved by training in a mixture of various languages.</sample>
    <sample id="1012">And we found it is because most of the major natural languages can obtain performance gain, except that English performance drops in seven datasets and only gains in three datasets.</sample>
    <sample id="1013">We evaluate on mT5 and XLM-R + PTR on Multilingual Setting Most of the major NLPs can obtain performance gain, except that English performance drops in 7 datasets. This is known as "Curse of Multilinguality"</sample>
    <sample id="1014">We also compared the cross-lingual performance gap.</sample>
    <sample id="1015">Cross-lingual Performance Gap Blue Line: Cross-lingual Few-shot transfer Orange Line: Cross-lingual Zero-shot transfer Green Line: Monolingual Setting Gequery MTOP SchemaQA Overnight NLMaps MCWQ Gequery/lambda Gequery/prolog Gequery/funql Gequery/sql Spider ATIS Few-shot Zero-shot Monolingual</sample>
    <sample id="1016">Cross-lingual Performance Gap Blue Line: Cross-lingual Few-shot transfer Orange Line: Cross-lingual Zero-shot transfer Green Line: Monolingual Setting Gequery MTOP SchemaQA Overnight NLMaps MCWQ Gequery/lamb Gequery/prolog Gequery/funql Gequery/sql Spider ATIS Few-shot Zero-shot Monolingual</sample>
    <sample id="1017">We also find some other interesting findings. For example, encoder-decoder outperforms previous work or achieves comparable results. Pretraining on English natural language can significantly boost the performance of few-shot on target natural languages.</sample>
    <sample id="1018">Multilingual LLMs (Codex &amp; BLOOM) are still inadequate for crosslingual semantic parsing tasks.</sample>
    <sample id="1019">Conclusion We build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations. We conduct a comprehensive benchmark study on three representative types of multilingual language models. Our results show that mT5 with monolingual training yields the best performance, while notably multilingual LLMs are still inadequate to perform cross-lingual semantic parsing tasks. Moreover, the performance gap between cross-lingual training and cross-lingual transfer learning is still significant.</sample>
    <sample id="1020">We conduct a comprehensive benchmark study on three representative types of multilingual language models and our results show many interesting findings and et cetera and welcome to visit our paper and code thanks for listening</sample>
    <sample id="1021">Omission errors</sample>
    <sample id="1048">Emory University and Amazon Alexa AI</sample>
    <sample id="1049">Continuous fine-tuning</sample>
    <sample id="1050">6</sample>
    <sample id="1084">Yusen Zhang</sample>
    <sample id="1085">hi, i'm shangbin phd student in the university of washington. today i am presenting our work from pretraining data to language models to downstream tasks tracking the trails of political biases leading to unfair nlp models.</sample>
    <sample id="1086">LM Training Data A mixed blessing 1000000000 100000000 10000000 1000000 100000 10000 1000 100 100 10 1 1 10 100 1000 10000 100000 1000000 10000000 100000000 1000000000 www. wikipedia.org www. businessinsider.com www. theverge.com www. huffpost.com www. cnet.com www. scikit-learn.org www. springer.com www. bookstagram.com www. businessreview.co.uk www. techcrunch.com www. npr.org www. springer.com www. bookstagram.com www. businessreview.co.uk www. techcrunch.com www. npr.org www. scikit-learn.org www. springer.com www. bookstagram.com www. businessreview.co.uk www. techcrunch.com www. npr.org www. theverge.com www. huffpost.com www. cnet.com www. scikit-learn.org www. wikipedia.org Dodge, Jesse, et al. "Documenting Large Web Corpora: A Case Study of Crawling Corpus - Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP)."</sample>
    <sample id="1087">LM training data A mixed blessing New York Times Los Angeles Times The Guardian Huffington Post etc are well covered in language model training data. According to a survey of the C4 corpus, we can see that</sample>
    <sample id="1088">LM Training Data A mixed blessing 1000000000 100000000 10000000 1000000 100000 10000 1000 100 100 10 10 1 1 1 1 1 1 1 www. wikipedia.org www. en. wikipedia.org www. dbpedia.org www. nytimes.com www. google.com www. twitter.com www. cnn.com www. bbc.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. theverge.com www. thever</sample>
    <sample id="1089">So on one hand they were able to learn from diverse perspectives which celebrates democracy and the plurality of ideas. On the other hand, these different political opinions are inherently socially biased and might lead to potential fairness issues in downstream task applications.</sample>
    <sample id="1090">To this end, we propose to investigate the political bias propagation pipeline from pretraining data to language models to downstream tasks, specifically by asking the following questions.</sample>
    <sample id="1091">First, how do we evaluate the political line of language models and what role does pretraining data might have on such political biases?</sample>
    <sample id="1092">Secondly, how do language models with different politically-leaning actually perform on downstream tasks and whether that might result in fairness issues in NLP applications?</sample>
    <sample id="1093">Evaluating LM Political Leaning Support both encoder and decoder LMs "statements I &lt;mask&gt; with this statement." "Do you agree or disagree with this statement? &lt;statement&gt;" Automatic eval Grounded in polisci lit Q: Our race has many superior qualities, compared to other races. Agree Left Libertarian Right Authoritarian</sample>
    <sample id="1094">so some preliminary results demonstrate that first language models do have varying political leanings they occupy all four quadrants on the political compass</sample>
    <sample id="1095">We can also see that GPT-4 is the most libertarian language model of them all, and GPT-series are generally more socially liberal than BERT-series and its variants.</sample>
    <sample id="1096">Secondly, we aim to investigate to what extent the political biases of language models are actually picked up from training data.</sample>
    <sample id="1097">So we could conduct a controlled experiment by further pre-training language model checkpoints on six different partisan corpora separated into news and social media, further divided into their political leaning.</sample>
    <sample id="1098">Results Partisan shifts in LM political leaning RoBERTa GPT-2 original reddit news Center Left Right news reddit reddit original</sample>
    <sample id="1099">For example, for Roberta further fine-tuned further trained on the left-leaning Reddit Corpus we can see a substantial liberal shift in terms of its</sample>
    <sample id="1100">Results Partisan shifts in LM political leaning RoBERTa GPT-2 original reddit news Center Left Right news reddit original reddit</sample>
    <sample id="1101">And we also try to investigate whether language models can pick up the polarization that's prevalent in our modern society.</sample>
    <sample id="1102">So we divide pre-training corpora into pre-45th president of the United States and after 45th president of the United States. We separately pre-train language models on the two different temporal corpora.</sample>
    <sample id="1103">We can see that language models generally had a political leaning that is further away from the center after 2017. So this indicates that language models can also pick up the like polarization in our society.</sample>
    <sample id="1104">So last but not least, we evaluate language models with different political leanings on hate speech detection and fake news detection to NLP applications that often involve language models and could have very significant implications.</sample>
    <sample id="1105">so we see that if we investigate the per category performance, that is to say, if we separate the performance into</sample>
    <sample id="1106">Different demographics or politically leaning news media we can see a pattern that for example for hate speech detection left-leaning language models are better</sample>
    <sample id="1107">Per-Category Performance 1st 2nd 3rd BLACK MUSLIM LGBTQ+ JEWS ASAIN LATINX WOMEN CHRISTIAN MEN WHITE HP (L) NYT CNN NPR Guard (J) Fox WExE BBAIR (R) WAT NR 80.63 89.84 80.19 85.83 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89 89.89</sample>
    <sample id="1108">However, we're worse at detecting hate speech targeting more powerful groups in our society.</sample>
    <sample id="1109">And vice versa. Right-leaning language models are better at detecting hate speech targeting white and men, however worse at detecting hate speech targeting at black, lgbtq+, and other minority communities.</sample>
    <sample id="1110">Similar trends also happen for fake news detection, where we see that left-leaning language models are better at detecting misinformation from their opposite political leaning and vice versa.</sample>
    <sample id="1111">we further show many qualitative examples to see that language models with different political leanings</sample>
    <sample id="1112">do give different predictions to hate speech and misinformation examples based on their social category there are a bunch of more examples in the appendix to further highlight that</sample>
    <sample id="1113">This indicates that there is a fairness issue that is very pressing regarding the political biases of language models.</sample>
    <sample id="1114">For example, if a right-leaning language model were to be fine-tuned on hate speech or misinformation and whatever and deployed to a popular social media platform,</sample>
    <sample id="1115">This would mean that people with opposite political opinions might be marginalized and the hate speech targeting minority groups might just run rampant without any control.</sample>
    <sample id="1116">So this has sounded the alarm for us to acknowledge and tackle the fairness issues resulting by language model political leanings.</sample>
    <sample id="1117">so a little bit of discussion we would also like to highlight that we expose the unique dilemma regarding language model political biases it's like between scylla and charybdis</sample>
    <sample id="1118">So if we do not sanitize political opinions in language model training data, the bias would propagate from pretraining data to language models to downstream tasks, ultimately creating fairness issues.</sample>
    <sample id="1119">If we do try to sanitize somehow, we will also risk censorship or exclusion and it's incredibly hard to determine what is actually neutral and should be retaining language model training data. So it's kind of like the electrically electric chalky problem.</sample>
    <sample id="1120">okay great I think that's pretty much all I have to say I'll see you for today thank you for your time</sample>
    <sample id="1121">It does not have a name.</sample>
    <sample id="1122">The author described the "marked words" method as a way to identify the words that distinguish marked groups from unmarked ones.</sample>
    <sample id="1123">The authors of the paper are affiliated with the University of Washington, Carnegie Mellon University, and the Language Technologies Institute.</sample>
    <sample id="1124">Prague</sample>
    <sample id="1125">James Finch</sample>
    <sample id="1126">Four</sample>
    <sample id="1127">Syntax Gym</sample>
    <sample id="1128">Hello, my name is Kayo Yin and I will be presenting our work titled When Does Translation Require Context? A Data-driven Multilingual Exploration. This work was done in collaboration with Patrick Fernandez, Emmy Liu, Andre F.T. Martins, and Graham Neubig.</sample>
    <sample id="1129">So a lot of translations depend on context. For example, how would we translate mole in this sentence?</sample>
    <sample id="1130">Translation depends on context Things could start to get dangerous if the ministers find out. We'll have to get rid of that mole.</sample>
    <sample id="1131">Translation depends on context Could it be anything serious, Doctor? We'll have to get rid of that mole.</sample>
    <sample id="1132">however evaluating how well models can translate cases like this is pretty hard firstly because only a small portion of translations depend on context which makes corpus level metrics like blue unable to capture these translations</sample>
    <sample id="1133">And some people have suggested targeted evaluation on context-dependent translations. But these resources only support limited types of context-dependent translations and limited sets of languages since they usually rely on domain knowledge and human curation.</sample>
    <sample id="1134">In this work, we try to answer these two questions. First, when does translation require context? And second, how well do models handle these cases?</sample>
    <sample id="1135">To answer the first question, we started by measuring how much a word depends on context during translation.</sample>
    <sample id="1136">In the previous work, we introduced CXMI as a measure for context usage by machine translation models and this is done by measuring how much information the context C provides about the target Y given the source X.</sample>
    <sample id="1137">Conditional Cross-Mutual Information (CXMI) Conditional Cross-Mutual Information (CXMI): measure how much context MT models use given a corpus X HqMTA(Y|X) Uncertainty over translations given the source C HqMTQ(Y|X, C) Uncertainty over translations given the source AND context CXMI(C) â†’ Y|X</sample>
    <sample id="1138">In this work, we extend CXMI to point-wise CXMI which can measure context usage at the sentence level or at the word level. We can think of words that have high P-CXMI as ones that require context for translation.</sample>
    <sample id="1139">Now we analyze words with high P6MI to look for patterns between these words.</sample>
    <sample id="1140">And we perform our analysis on transcripts of TED Talks that have been translated from English to fourteen different languages.</sample>
    <sample id="1141">We perform our analysis at three different levels. First, we look at parts of speech tags that have high means P-CXMI.</sample>
    <sample id="1142">And this allows us to find, for example, dual pronouns in Arabic that have relatively high p-cxmi and this can be explained because English doesn't have dual pronouns. So you need context to determine if a pronoun is dual when translating into Arabic.</sample>
    <sample id="1143">And similarly, we find that certain languages also require context when we want to choose the appropriate verb form. We then look at vocabulary items that have high P-CXMI averages over all of its different occurrences.</sample>
    <sample id="1144">And this helps us identify cases like the one here, where in Chinese you need context to translate proper nouns to make sure that you're using the same translation within the document.</sample>
    <sample id="1145">And similarly, we find that context is supported to translate in the right formality.</sample>
    <sample id="1146">And finally we look at different at individual tokens that have high p xmi and this allows us to identify phenomena that cannot really be captured uh by the word itself but that's rather expressed in the sentence structure such as ellipse resolution</sample>
    <sample id="1147">So now we use our findings from our analysis to design a benchmark for document-level translation.</sample>
    <sample id="1148">For each of the five discourse phenomena we identified, we create taggers to automatically identify words that pertain to the phenomenon and we call our tagger the multilingual discourse-aware or MuDA tagger.</sample>
    <sample id="1149">We can then also note that different languages have different proportions of these discourse phenomena.</sample>
    <sample id="1150">We then use the MuDA tagger by applying the tagger on the parallel corpora that we want to use for evaluation and we apply our translation metrics of choice on the code-switching dependent examples that the MuDA tagger has identified.</sample>
    <sample id="1151">and finally we use our benchmark as well as other metrics to evaluate different models on the document level machine translation.</sample>
    <sample id="1152">First of all, when we use corpus-level metrics so for blue we find that cognate agnostic models have the best performance.</sample>
    <sample id="1153">But then if we use comet, context-aware models perform best and if we use word f-measure, then models with or without context have comparable performance.</sample>
    <sample id="1154">This again demonstrates that it is difficult to determine the best document-level translation system if we use corpus-level metrics alone.</sample>
    <sample id="1155">now we use the muda benchmark to evaluate models and we find that context aware models are significantly more accurate than the models that do not use context for certain discourse phenomena such as formality and lexical cohesion</sample>
    <sample id="1156">But these models are not much better than models that do not use context on other phenomena like ellipses, pronouns and verb form. So this sort of suggests where we would need to see more progress for document-level translation.</sample>
    <sample id="1157">We also compare different commercial systems and our benchmarks shows that DeepL is usually more accurate than Google Translate for document-level translation.</sample>
    <sample id="1158">To summarize, we perform a data-driven analysis across 14 language pairs to identify when translations require context.</sample>
    <sample id="1159">And then we use our findings to build a benchmark for document-level machine translation, which can help us identify which discourse phenomenon models can handle well or not and which translation systems are good at document-level translation.</sample>
    <sample id="1160">Thank you so much for your attention. See you in Torino.</sample>
    <sample id="1161">FT, TW, BOND, COSINE, MLC</sample>
    <sample id="1162">The model is evaluated on 11 biomedical and clinical downstream tasks in French.</sample>
    <sample id="1163">Hi, welcome to our presentation of DePlain: A new corpus for German text simplification on the document level and on the sentence level.</sample>
    <sample id="1164">my name is regina stoddan and i will guide you through the first part of the presentation let's first define text simplification</sample>
    <sample id="1165">Text simplification is a process of adapting a text to improve the text comprehension of it for a specific target group as people with reading problems or non-native speakers.</sample>
    <sample id="1166">To train a text simplification model, we require parallel pairs of text, for example doc of documents or sentences.</sample>
    <sample id="1167">And the example here you can see a parallel aligned sentence pair of a complex German sentence and its translation into plain language.</sample>
    <sample id="1168">To simplify the sentence, different techniques are possible as you can see in the example, such as lexical substitution, clause deletion, clause deletion reordering or insertion of words.</sample>
    <sample id="1169">Now we propose our new corpora to De-plain because in the recent years there were some problems with existing corpora. So for example, these corpora here are too small to train a text classification model on.</sample>
    <sample id="1170">The other three models which are proposed in recent years are all automatically aligned, which means that they can be over-erbrocken in their alignments.</sample>
    <sample id="1171">therefore we propose our new corpus Deep Plain which is split into two sub corpora Deep Plain API and Deep Plain Web Deep Plain API is based on news texts</sample>
    <sample id="1172">In the plain API, we aligned 483 documents all manually. It results in roughly 30,000-13,000 parallel sentence pairs.</sample>
    <sample id="1173">for DeepPlainWeb this corpus includes different domains and we also align all of these 750 documents on the one hand manually and on the other hand with automatic alignment methods</sample>
    <sample id="1174">In total we result in 30,450 sentence pairs.</sample>
    <sample id="1175">Types of Simplification Simplicity LexSimp StructSimp news bible fiction n= 187 n= 187 n= 12 b. Simplification Transformations DEplain-apa DEplain-web reordering rephrasing lexical substitution word addition word deletion</sample>
    <sample id="1176">Types of Simplification Simplicity LexSimp StructSimp news bible n= 87 n= 127 n= 137 n= 127 n= 127 n= 127 n= 127 n= 127 Bible Texts are much stronger simplified than for example the news text or the language learner texts. Simplification Transformations DEplain-apa DEplain-web Reordering Rephrasing lexical substitution word addition word deletion</sample>
    <sample id="1177">Types of Simplification Simplicity LexSimp StructSimp news bible L2 fiction n= 187 n= 187 n= 187 n= 187 Simplication Transformations DEplain-apa DEplain-web reordering rephrasing lexical substitution word addition word deletion</sample>
    <sample id="1178">Furthermore, you can see that our deplain corpus has a high variety of different simplification transformations. So for example in the deplain-aip corpus we have much more reorderings and word additions than we have in the deplain-web corpus.</sample>
    <sample id="1179">On the other hand, in the web corpus we have much more rephrasing.</sample>
    <sample id="1180">so let's now see what we can do with this corpus hello i am omar and now i will talk about the use cases for our data set deep learning so for the first use case we can evaluate automatic alignment methods</sample>
    <sample id="1181">In the recent years, there has been a lot of alignment methods but in the context of machine translations.</sample>
    <sample id="1182">where we have two parallel documents written in different languages and we want to extract alignments of sentences in both documents.</sample>
    <sample id="1183">but in our use case we are trying to extract alignments between sentences of two parallel documents having the same language having the same content but they are on a different complexity level</sample>
    <sample id="1184">and now as we have our dataset deep plane which have manually aligned sentences we can use these sentences as gold standard alignments to evaluate some of the proposed alignment methods</sample>
    <sample id="1185">And we did some adaptations to the proposed methods and we have published all these adaptations and the codes to run our experiments in the paper.</sample>
    <sample id="1186">at the end we concluded that uh the best alignment automatic alignment method to use for texts for german text simplification is the method of mass align</sample>
    <sample id="1187">and you can also find the code to run this method on your own documents in the paper.</sample>
    <sample id="1188">The second use case that we showed in our paper is the case of automatic text simplification.</sample>
    <sample id="1189">by fine-tuning language models to produce simplified text from the complex input text.</sample>
    <sample id="1190">We have fine-tuned two different models. We have fine-tuned the model of long import to produce document-level simplifications.</sample>
    <sample id="1191">and we also fine-tune the normal base long the normal base import to produce sentence level simplifications.</sample>
    <sample id="1192">you can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper.</sample>
    <sample id="1193">we concluded that these this basic fine-tuning could produce or could get scores better than the baseline scores.</sample>
    <sample id="1194">And we propose those results as a benchmark, a base benchmark for the problem of automatic text simplification in the future.</sample>
    <sample id="1195">Thank you so much for your attention and we hope to meet all of you during the conference. Thank you.</sample>
    <sample id="1196">Hi, and I'm going to talk about our work on resolving indirect referring expressions for entity selection in which we introduce the Alt Entities Corpus.</sample>
    <sample id="1197">my name is javad hosseini and this is a joint work with philip radlinski sylvia parati and annie louise</sample>
    <sample id="1198">Indirect Referring Expressions Google Research Understanding users' language when they make a choice Alternative question Did you mean easy on me or I gotta feeling? Here, a user wants to select between one of these two songs.</sample>
    <sample id="1199">The most obvious thing is to use a direct reference, for example by saying the name of the song easy on me or its position, the first.</sample>
    <sample id="1200">But sometimes an indirect reference is more appropriate to have a more natural conversation. This would happen when the user cannot remember the name of the song.</sample>
    <sample id="1201">all the pronunciations are too similar to each other and hard to disambiguate.</sample>
    <sample id="1202">or when the user wants to specify a preference here are some example in direct references for example the newer one or the song that's not energetic</sample>
    <sample id="1203">Dataset Collection Important problem: Conversational systems Benchmarking Large Language Models' entity understanding No large-scale public dataset available We collect a large dataset using crowd annotation Three domains:</sample>
    <sample id="1204">We're not aware of a public dataset, a large-scale public dataset for the task. So we collect one using crowd annotation. Our dataset covers three different domains: music, books and recipes.</sample>
    <sample id="1205">Dataset Collection Methodology Methodology emphasizes informality using a cartoon completion task. Remember that we were talking about yesterday? Do you mean I was talking about 1 Gotta Feeling? Filled by the annotator Sets the dialog context (chosen from a few manual prompts per entities) The alternative question Expression referring to one of the entities Resolving Indirect References (Entity Selection Corpus)</sample>
    <sample id="1206">The cartoon has three speech bubbles. In the first bubble, Bob says, "Remember that song we were listening to yesterday?" and with that, Bob sets the dialogue context.</sample>
    <sample id="1207">in this in the second speech bubble Alice says do you mean easy on me or I got a feeling</sample>
    <sample id="1208">Remember that we were talking about yesterday? Do you mean the new car I got a feeling? The alternative question Expression referring to one of these entities.</sample>
    <sample id="1209">We provide the first and second speech bubbles automatically, but the third one is filled in by the annotator. The first speech bubble is chosen from a few manual prompts per domain.</sample>
    <sample id="1210">The second one, which is the alternative question, is generated as follows.</sample>
    <sample id="1211">We always use a simple template. Do you mean A or B? where A and B are samples from Wikipedia.</sample>
    <sample id="1212">Here are the different sampling methods we've used. When we move higher in the list, the entities become more similar to each other and it's usually harder to make the disambiguation.</sample>
    <sample id="1213">The first one is uniform at random.</sample>
    <sample id="1214">The second one is when the entities have similar titles. For example, two books with the name The Return.</sample>
    <sample id="1215">The third one is when they have similar descriptions on Wikipedia and finally when they have similar infoboxes or attributes on Wikipedia for example the same genre or the same artist</sample>
    <sample id="1216">When we show this alternative question to the annotators, they know the name of these entities but they don't necessarily know about the entity.</sample>
    <sample id="1217">So what we do is that we show some background knowledge about the two entities. For songs, we simply show a Google search link to each song.</sample>
    <sample id="1218">and then ask the annotators to listen to at least some of each song and read about each song here's for example the Google search result for the song easy on me</sample>
    <sample id="1219">For the recipes and books domain we show some background text from Wikipedia. For recipes we additionally show their images again from Wikipedia so that the annotators know how they look like.</sample>
    <sample id="1220">then we ask the annotators to pick one of these entities for example here the first one and describe them using 3 to 5 indirect referring expressions</sample>
    <sample id="1221">For example, the one with the piano music. Here are some examples from our data set. For example, the one without words, not the one with the twelve year old, twelve year old boy or the fictional one or comes from Azerbaijan and so</sample>
    <sample id="1222">AltEntities Corpus has 6,000 alternative questions across the three domains and it has 42,000 indirect referring expressions. Results with T5 XL model are summarized below.</sample>
    <sample id="1223">If the language model has access to the exact same background knowledge as the annotators, then the accuracy is really high. it's around 92-95 percent but this is not realistic.</sample>
    <sample id="1224">if the language model has access to some partially overlapping background knowledge then the accuracy is between 82 to 87 percent which is more realistic for example when the language model retrieves the background knowledge</sample>
    <sample id="1225">if the language model has access only to entity names then the accuracy is only sixty percent so there's a lot of room for improvement we've also shown that the models are domain generalizable here is a link to our data set thanks</sample>
    <sample id="1226">CamemBERT is initially trained on the 4GB subset of Natsc.</sample>
    <sample id="1227">Adam PrzepiÃ³rkowski</sample>
    <sample id="1228">The findings that the performance of some models with more recent data degrades with larger temporal gap led to the conclusion that the temporal drift is the main cause of performance loss.</sample>
    <sample id="1229">hi everyone i'm jenny a first-year phd student at carnegie mellon university and today i'll be presenting your work nlp positionality characterizing design biases of datasets and models</sample>
    <sample id="1230">This work was done in collaboration with some folks at the University of Washington and um the Allen Institute for AI, namely Sebastin Santy Ronan Le Bras, Katharina Reinecke and Martin Sap.</sample>
    <sample id="1231">so let's start off by imagining that you're working for a newspaper and you're sifting through comments under your news article trying to remove toxic content.</sample>
    <sample id="1232">You might turn towards a popular API like Perspective API for toxicity detection and this works really well if you're Carl Jones where Perspective API is able to detect correctly toxic instances.</sample>
    <sample id="1233">But that's not really the case for Aditya Sharma, where Perspective API is really not as sensitive to offensive terms that are more common in Indian contexts.</sample>
    <sample id="1234">Imagine... Design bias example! Can you stop being a jerk? (0.82) Pressstitutes everywhere on the news (0.33) Carl Jones Tech Lead, New York Times Aditya Sharma Tech Lead, Times of India = PerspectiveAPI score</sample>
    <sample id="1235">Design biases like the one that we just saw before might occur due to the positionality of the NLP researchers and model developers. Positionality is simply the perspectives that people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="1236">This is a concept widely used in critical studies, specifically in feminist and queer academic spaces.</sample>
    <sample id="1237">Positionality â€œThe perspectives [people] hold as a result of their demographics, identity, and life experiences. [1] Savin-Baden, Maggi, and Claire Howell-Major. â€œQualitative research: The essential guide to theory, practice and critique. Routledge (2013).</sample>
    <sample id="1238">And so one question that people might ask is do datasets and models have positionality?</sample>
    <sample id="1239">And we're not trying to say that models and cells and datasets themselves have demographic identities and life experiences but they do aggregate judgments and opinions of real people and can thus represent certain positionalities over others.</sample>
    <sample id="1240">So prior work has suggested some anecdotal evidence of having positionalities such as cultural gaps in models and datasets, as well as theoretical definitions of model positionalities.</sample>
    <sample id="1241">However, these works really don't look at comparing end-users with the datasets and models themselves.</sample>
    <sample id="1242">Do datasets and models have positionality? Anecdotal evidence: - Model and dataset probing [112] - Theoretical definitions of model positionality [3] [1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022. [2] Chen, et al. "GEOMLLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022. [3] Cambo &amp; Gerglot. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science" 2022</sample>
    <sample id="1243">And it's challenging to characterize how these positionalities are skewed because not all decisions are documented and many models are hidden behind apis.</sample>
    <sample id="1244">So to study dataset and model positionality we actually compare the annotations with real users with existing datasets and models.</sample>
    <sample id="1245">We do this through a framework called NL Positionality.</sample>
    <sample id="1246">Framework Collection "Eating with Hands" "Can you live without your hands?" "Steel" Each instance has an annotation. Annotators are sent as instances to work on. Annotations from the annotators are then used to train a model. Processing Model Predictions Model predictions are then compared against the gold labels from the observed data.</sample>
    <sample id="1247">Framework 1) Re-annotate datasets with diverse annotators.</sample>
    <sample id="1248">and we opt to do this over looking at the demographics of original datasets annotators because usually only a few annotators annotate each instance and because demographics are rarely collected and shared.</sample>
    <sample id="1249">and so we opt to re-annotate data to get many annotators per instance and to get a rich set of demographic data.</sample>
    <sample id="1250">We then take the annotations by demographic and compare them to the models and datasets using Pearson's R correlation score.</sample>
    <sample id="1251">And thus our framework actually differs from annotator disagreement literature by comparing end users with models and datasets predictions and labels as opposed to looking at just inter-annotator agreement or modeling annotator distributions.</sample>
    <sample id="1252">Our framework is largely enabled through Lab in the Wild, an online crowdsourcing platform from our HCII collaborator.</sample>
    <sample id="1253">Lab in the Wild is an online experimentation platform where we can recruit diverse volunteers compared to platforms like MTurk, which largely have participants from the US or India. And further, Lab in the Wild stills able to get high-quality data.</sample>
    <sample id="1254">Task A: Social Acceptability 1) Read the situation 2) Enter what you think about it from your perspective. 3) See what others thought about it! The AI speculates: How do people judge? Study participants in the United States</sample>
    <sample id="1255">Task A: Social Acceptability 1) Read the situation. 2) Enter what you think about it. 3) See what others thought about it! The AI speculates. Study participants in the United States: Participants compare their responses to others' and an AI's.</sample>
    <sample id="1256">We then compared these annotations with social chemistry, Delphi and GPT-4.</sample>
    <sample id="1257">Task B: Toxicity 1 Read the example. 2 Enter what you think about it. 3 See what others thought about it. The AI speculates. Study participants in Afghanistan said they think that an instance of hate speech is hateful. Looks like we agree. Participants read an instance from the Dynahate dataset. Participants rate whether an instance is hate speech.</sample>
    <sample id="1258">We then compared these annotations with dynahate, perspective API, rewire API, hate roberta and gbt-4. our study in the end amassed over 16,000 annotations from over a thousand annotators from 87 countries.</sample>
    <sample id="1259">so now we're better equipped to answer who do nlp datasets and models align with the most we find that there is positionality in nlp</sample>
    <sample id="1260">Datasets and models are most aligned to English-speaking countries. For example, we find that datasets and models are most aligned to English-speaking countries. So for the GPT-4 social acceptability analysis, we find that it's most aligned to Confucian and English-speaking countries. We find that Dina hate is also most aligned to English-speaking countries.</sample>
    <sample id="1261">Datasets and models are most aligned to people with a college education. We also find most additional alignment with people who have a college education. So for GPT-4 in the social acceptability task, we find that it's most aligned to people with a college education or graduate school education.</sample>
    <sample id="1262">Datasets and models are most aligned to people with a college education. N=2,383 0.66* N=908 N=604 0.59* N=359 0.48* N=116 0.37 N=195 0.61* College Graduate High PhD Pre-High Prof. School School School School</sample>
    <sample id="1263">However, when models and datasets are aligned to specific populations, some are inevitably left behind.</sample>
    <sample id="1264">Datasets and models are less aligned to non-binary people. An example of this is that datasets and models are less aligned to non-binary people compared to the men and women counterparts. We find this in the GPT-4 social acceptability task as well as the DynaHate task analysis as well.</sample>
    <sample id="1265">So, given that there is position in NLP, what can we do about it?</sample>
    <sample id="1266">so we have a few recommendations for this first one is keep a record of all relevant design choices throughout the research process and the other is to do nlp research with the lens of perspectivism.</sample>
    <sample id="1267">Our third recommendation is to build specialized datasets and models with and for specific communities. And a good example of this is the Masakhane initiative I mean, we want to emphasize that inclusive NLP isn't just making you know all technologies work for everyone.</sample>
    <sample id="1268">and so that concludes our presentation but if you'd like to learn more feel free to check out our dashboard for the most updated analysis results and our paper thank you</sample>
    <sample id="1269">It is necessary to permute the tokens for the output sequence because after the first step, we have all the right tokens but they are not ordered.</sample>
    <sample id="1270">The authors recommended that model owners should increase transparency about bias mitigation methods because it is unknown whether the positive stereotypes are due to overly excessive value alignment or anti-stereotyping methods resulting in these patterns.</sample>
    <sample id="1271">A grammatical sentence and an ungrammatical sentence</sample>
    <sample id="1272">The authors used the weighted and tokenized BLEU score to evaluate their models.</sample>
    <sample id="1273">Intra-annotator agreement</sample>
    <sample id="1274">Wikipedia</sample>
    <sample id="1275">Heinrich Heine University DÃ¼sseldorf, Germany</sample>
    <sample id="1276">MultiInstruct is the first multi-modal instruction-tuning benchmark.</sample>
    <sample id="1277">Three authors are involved in the paper.</sample>
    <sample id="1278">Binary coordination is the difference between the length of the shorter conjunct and the longer conjunct.</sample>
    <sample id="1279">10 minutes</sample>
    <sample id="1280">The smaller T5 model can surpass larger models when properly trained on suitable data sets, indicating that smaller models can be more effective in certain situations.</sample>
    <sample id="1309">The work investigates four learning strategies: full model construction, pre-training using an existing pre-trained model, continuous pre-training, and a mix of pre-training and fine-tuning.</sample>
    <sample id="1310">The factor of overfitting due to test reuse is 1.05.</sample>
    <sample id="1311">The quality of the simplification was evaluated using BLEU and BS-P scores.</sample>
    <sample id="1312">Yes, language models have varying political leanings.</sample>
    <sample id="1347">Cognitive dissonance is two beliefs or actions that are inconsistent.</sample>
    <sample id="1348">GPT-4</sample>
    <sample id="1349">Yes, cumulative training performs better than iterative when doing active learning.</sample>
    <sample id="1350">Sara Papi</sample>
    <sample id="1351">The data was taken from TED Talks.</sample>
    <sample id="1352">Hi, my name is Adam Przepiorkowski and this talk is about the dependency structure of coordination.</sample>
    <sample id="1353">as you may know that different dependency structures assumed by different theories and corpus approaches so for example in the universal dependencies the structure of the coordinate coordination Lisa Bart and Maggie</sample>
    <sample id="1354">is such that the first conjunct is the head of the whole coordinate structure, so in this case Lisa.</sample>
    <sample id="1355">similar approaches assumed in Igor Mityuk's meaning text theory where again the whole coordinate structure is headed by the first conjunct so these two approaches are asymmetric right they single out one of the conjuncts</sample>
    <sample id="1356">now there are also symmetric approaches to coordinate structures such as the Prague approach the conjunction headed approach using in Prague dependency trees where coordinate structures are headed by the conjunction</sample>
    <sample id="1357">so we get dependencies from end to all the conjuncts</sample>
    <sample id="1358">And finally, there's also a multi-headed approach that's used for example in the cutson's word grammar.</sample>
    <sample id="1359">where so to say all conduct are heads of the coordinate structures so we get dependencies from the governor here loves to all conduct separately these are bart and</sample>
    <sample id="1360">now our aim is paper is to produce a novel argument for the symmetric structures of coordination like this two and against the asymmetric structures of coordination like this</sample>
    <sample id="1361">Dependency Length Minimization (DLM) Word order tends to minimize dependency lengths: good bad</sample>
    <sample id="1362">so in english as you might as you might know the direct objects prefer to be close to the verb while adjuncts may be further away right so march read it yesterday is fine because the direct object it is close to the verb</sample>
    <sample id="1363">While March read yesterday it is much worse right because here between the verb and the direct object there's an adjunct yesterday.</sample>
    <sample id="1364">However, this effect may be ameliorated when when the direct object is very heavy and very long because then it can be moved to the position after the agent.</sample>
    <sample id="1365">this is illustrated here. so both these sentences are fine. march read this absolutely fascinating book about the bees yesterday. it's okay. the way instead of it we have this long and p.</sample>
    <sample id="1366">But it's also okay to say March ready yesterday this absolutely fascinating book about bees.</sample>
    <sample id="1367">the reason here is that this is possible because even though this sentence violates the general grammatical principle that direct objects should be next to the verb</sample>
    <sample id="1368">It satisfies the principle of dependency length minimization, which says that shorter, um, shorter dependencies are preferred.</sample>
    <sample id="1369">So these two trees only show the length of the crucial dependencies, so the ones that are not constant among these two structures.</sample>
    <sample id="1370">So here we have the dependency from red to the adjunct of length 7, measured in words and from red to book of length 4. So together it's 11.</sample>
    <sample id="1371">When you move, when you swap these two constituents, the sum of these two dependencies becomes six. Right? Instead of eleven, six much shorter. That's why this sounds quite okay. Right? It violates one principle but it satisfies another one.</sample>
    <sample id="1372">okay so what we did we extracted various statistics from about coordination from the enhanced version of pen of the pen tree bank and see the paper why wouldn't use university dependencies</sample>
    <sample id="1373">and these statistics confirm the observation made many times before that left conjuncts tend to be shorter also salt and pepper and not pepper and salt measured in syllables</sample>
    <sample id="1374">and also the observation that was made in passing that this tendency grows with length length difference</sample>
    <sample id="1375">so when the difference between the lengths of the two conjuncts grows uh the shorter conjunct prefers to be the first one stronger right so the proportion is is bigger of of the left short conjuncts</sample>
    <sample id="1376">but what's novel in this paper is we that we observed that this tendency only occurs when the governor is on the left or absent.</sample>
    <sample id="1377">right. so the governor is on the left in this example, I saw Bart and Lisa. so is the governor it's on the left</sample>
    <sample id="1378">it's absent in the second example Homer came and sneezed here we have coordination of two verbs and there's no outside external governor right so in such cases the left conjunct prefers to be shorter the more so the the bigger the difference between the two</sample>
    <sample id="1379">however when the governor is on the right as here left governs the coordination then net this effect disappears</sample>
    <sample id="1380">so we showed that by measuring length in characters the first column in syllables the middle column and in words the right column so i'll concentrate on the right one</sample>
    <sample id="1381">What we see here is that when the governor is on the left,</sample>
    <sample id="1382">The tendency for the left conjunct to be shorter grows steadily with the absolute difference in words and the same is observed when there is no governor as in coordination of sentences but when the governor is on the right this tendency disappears</sample>
    <sample id="1383">and we show in the paper how this um provides an argument against um as asymmetric structures of coordination as these two and for the symmetric structures as these</sample>
    <sample id="1384">so see the paper for the full agreement and arguments sorry and talk to us about at the poster session. thank you</sample>
    <sample id="1385">Matthias Lindemann</sample>
    <sample id="1386">Cross-lingual transfer is the process of training a model on one language and then transferring it to another language.</sample>
    <sample id="1387">Saarland University, Amazon Alexa, University of Vienna</sample>
    <sample id="1388">The authors use average latency and computational aware average latency.</sample>
    <sample id="1416">Trees are usually not given and need to be obtained somehow.</sample>
    <sample id="1417">The authors of the paper are affiliated with the School of Interactive Computing at the Georgia Institute of Technology.</sample>
    <sample id="1495">ABC-Eval stands for Annotating Behaviors in Chat.</sample>
    <sample id="1496">2018</sample>
    <sample id="1527">The authors of the paper are affiliated with INLP, Saarland University, and the University of Amsterdam.</sample>
    <sample id="1528">The name of the speaker is Siyu Yuan.</sample>
    <sample id="1529">5</sample>
    <sample id="1530">The approach is compared to the state-of-the-art architecture specifically tailored for simultaneous speech translation.</sample>
    <sample id="1531">Hello everyone. My name is Ying, and my colleague Zhiyang and I will be presenting our research on MultiInstruct: Improving multi-modal zero-shot learning via instruction tuning.</sample>
    <sample id="1532">So with the advances in large language models, many works started to explore new learning paradigms of reusing pre-trained language models for different downstream tasks in a parameter and data efficient way.</sample>
    <sample id="1533">Recently, many studies have shown that instruction tuning enables large language models to perform on unseen tasks in a zero-shot manner by following natural instructions.</sample>
    <sample id="1534">However, most previous works on instruction tuning focus on improving the zero-shot performance on language-only tasks, while computer vision and multi-modal tasks have been left out.</sample>
    <sample id="1535">Therefore, in this work, we want to investigate whether instruction tuning of multimodal pre-trained models can actually improve generalization to unseen multi-modal tasks.</sample>
    <sample id="1536">Additionally, at the time of our research, we discovered a considerable discrepancy in availability of instruction dataset between NLP and multimodal.</sample>
    <sample id="1537">There exist more than 1,600 language-only instruction tasks. However, there is no large-scale publicly available multimodal instruction task. Therefore, this motivates us to build a multimodal instruction tuning dataset.</sample>
    <sample id="1538">Here we present multi-instruct, the first multimodal instruction tuning benchmark dataset that consists of 62 diverse multimodal tasks covering 10 broad categories.</sample>
    <sample id="1539">These tasks are derived from 21 existing open source datasets and each task is equipped with five expert-written instructions.</sample>
    <sample id="1540">For investigating multi-modal instruction tuning on our proposed dataset, we take OFA, a unified multi-modal pre-trained model as our base model. OFA uses a unified vocabulary for language, image tokens and the coordinate of a bounding box.</sample>
    <sample id="1541">Grounded Caption Text Localization Referring Expression Selection Question-Image Matching Input: A caption with a bounding box for each object in the image. The bounding boxes are represented by a series of numbers, such as &lt;bin-198-32&gt;, &lt;bin-400-193&gt;, etc. The numbers represent the x and y coordinates of the top-left corner of the bounding box, followed by the width and height of the bounding box. Options: &lt;bin-366-119&gt;, &lt;bin-448-181&gt;, &lt;bin-456-574&gt;, &lt;bin-666-664&gt;, &lt;bin-64-554&gt; Output: The correct option is &lt;bin-366-119&gt;. This indicates that the object referred to in the caption is located at the coordinates &lt;bin-366-119&gt; with a width and height of 119 pixels.</sample>
    <sample id="1542">MULTINSTRUCT Grounded Caption Text Localization Referring Expression Selection Question-Image Matching Input: &lt;bin-198- bin-32&gt; &lt;bin-400- bin-193&gt; Input: The region that contains the text "de" is described with "A blue train in the front" Input: &lt;bin-229- bin-604&gt; &lt;bin-456- bin-664&gt; &lt;bin-646- bin-654&gt; Output: &lt;bin-229- bin-604&gt; &lt;bin-456- bin-664&gt; &lt;bin-646- bin-654&gt; Output: &lt;bin-242- bin-760&gt; &lt;bin-291- bin-393&gt; &lt;bin-399- bin-442&gt; Output: &lt;bin-242- bin-760&gt; &lt;bin-291- bin-393&gt; &lt;bin-399- bin-442&gt; Output: do you have enough information to answer? Is it the image? the question is irrelevant to the image Figure 1: Example Instances from MULTINSTRUCT for Four Tasks.</sample>
    <sample id="1543">MULTINSTRUCT Grounded Caption Text Localization Referring Expression Selection Question-Image Matching Input: &lt;bin 198- bin 32&gt; &lt;bin 400- bin 32&gt; &lt;bin 486- bin 181&gt; &lt;bin 456- bin 574&gt; &lt;bin 666- bin 664&gt; &lt;bin 646- bin 644&gt; &lt;bin 346- bin 339&gt; &lt;bin 346- bin 342&gt; Input: The region that contains the text "de" is described by "A blue train in the front" The region that contains the text "de" is described by "A blue train in the front" Input: &lt;bin 229- bin 604&gt; &lt;bin 346- bin 475&gt; Output: &lt;bin 229- bin 604&gt; &lt;bin 346- bin 475&gt; Output: &lt;bin 242- bin 242&gt; &lt;bin 760- bin 760&gt; &lt;bin 203- bin 339&gt; Output: The content of the image is irrelevant to the question. Is it the question is irrelevant to the image? Output:</sample>
    <sample id="1544">Okay, now I'm going to talk about multi-modal instruction tuning.</sample>
    <sample id="1545">so for the training dataset we use 53 tasks from nine group for training and we sample 10,000 instances per task for testing we reserve the entire common sense reasoning group for testing and we select additional five tasks from vqa and miscellaneous group</sample>
    <sample id="1546">We use all the instances in the test split for each task. In addition, we randomly sample 20 tasks from the test split of Natural Instructions as unseen tasks for NLP.</sample>
    <sample id="1547">so we use a pre-trained ofa large model as the base model during training we mix all the instances for all the tasks each instance is randomly combined with one of its five ins direction template</sample>
    <sample id="1548">So during test for each task we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.</sample>
    <sample id="1549">We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1550">if the task is a multi-modal classification task we report accuracy if it's a multi-modal generation task we report rouge L for NLP tasks we report rouge L as well</sample>
    <sample id="1551">We also introduced a additional evaluation metric called sensitivity. So this measures the model's ability to consistently produce the same outputs for the same task regardless of slight variation in the wording of the instruction.</sample>
    <sample id="1552">here is our main results as we can see instruction tuning can significantly improve or is of a's performance on some multi-modal tasks</sample>
    <sample id="1553">also transfer learning from natural instruction datasets can benefit instruction tuning</sample>
    <sample id="1554">Here we can see as the amount of task increases, the model achieve better performance and in the meantime lower sensitivity.</sample>
    <sample id="1555">so we also did some experiments we use one instruction versus five instruction as we can see using more instruction can improve the model's overall performance and reduce its sensitivity a lot</sample>
    <sample id="1556">so this shows the effect of different fine-tuning strategy on the model sensitivity as we can see by transfer learning from natural instruction datasets the model can achieve much better sensitivity compared to our original ofa model</sample>
    <sample id="1557">we also can see transfer learning from natural instruction data set can help of a to achieve much better performance on the natural instruct data set</sample>
    <sample id="1558">Conclusion First large-scale multi-modal instruction tuning dataset. Contains 62 multi-modal tasks from 10 broad categories. Significantly improve the zero-shot capability of OFA via instruction tuning. Explore several transferring learning techniques and show their benefits. Design a new metric called sensitivity.</sample>
    <sample id="1559">so one more thing we are collecting a much larger multi-modal instruction tuning data set with around 150 additional vision-language tasks and we will release them soon this is a QR code for our data and model thank you</sample>
  </task>
</testset>