<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind die Datensätze, die verwendet werden, um die Modelle zu trainieren.</sample>
    <sample id="1">McGill University, Mila, Microsoft Research</sample>
    <sample id="2">DEPLAIN: Ein deutscher Parallelkorpus mit intralingualen Übersetzungen in eine vereinfachte Sprache für Satz- und Dokumenteinfachfication

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich-Heine-Universität Düsseldorf, Deutschland

ACL 2023</sample>
    <sample id="3">DEPLAIN: Ein deutscher Parallelkorpus mit intralingualen Übersetzungen in einfachere Sprache zur Satz- und Dokumenteinfachmachung

Regina Stodden, Omar Mommen, Laura Kallmeyer

Heinrich-Heine-Universität Düsseldorf, Deutschland

ACL 2023</sample>
    <sample id="4">Die Gewerkschaft setzt sich für ein, dass zum Beispiel höhere Löhne oder mehr Urlaub geändert werden.</sample>
    <sample id="5">Die Gewerkschaft setzt sich für ein, dass zum Beispiel höhere Löhne oder mehr Urlaub geändert werden.</sample>
    <sample id="6">Die Gewerkschaft setzt sich für ein, dass zum Beispiel höhere Löhne oder mehr Urlaub werden.</sample>
    <sample id="7">Die Gewerkschaft setzt sich für ein, dass zum Beispiel höhere Löhne oder mehr Urlaub geändert werden.</sample>
    <sample id="8">2. DE-plain
A New Corpus</sample>
    <sample id="9">German Text Simplification Corpora

Sentence Level

14000
12000
10000
8000
6000
4000
2000
0
2013
2015
2017
2019
2021
2023
Parallel
Translation
Parallel
Translation
Parallel
Translation
Parallel
Translation
Parallel
Translation</sample>
    <sample id="10">German Text Simplification Corpora

Sentence Level

14000
12000
10000
8000
6000
4000
2000
0
Parallel (Deutsch-Englisch, 2013)
Translation (Deutsch-Englisch, 2013)
Parallel (Englisch-Deutsch, 2013)
Translation (Englisch-Deutsch, 2013)
Parallel (Deutsch-Englisch, 2015)
Translation (Deutsch-Englisch, 2015)
Parallel (Englisch-Deutsch, 2015)
Translation (Englisch-Deutsch, 2015)
Parallel (Deutsch-Englisch, 2017)
Translation (Deutsch-Englisch, 2017)
Parallel (Englisch-Deutsch, 2017)
Translation (Englisch-Deutsch, 2017)
Parallel (Deutsch-Englisch, 2019)
Translation (Deutsch-Englisch, 2019)
Parallel (Englisch-Deutsch, 2019)
Translation (Englisch-Deutsch, 2019)
Parallel (Deutsch-Englisch, 2021)
Translation (Deutsch-Englisch, 2021)
Parallel (Englisch-Deutsch, 2021)
Translation (Englisch-Deutsch, 2021)
Parallel (Deutsch-Englisch, 2023)
Translation (Deutsch-Englisch, 2023)
Parallel (Englisch-Deutsch, 2023)
Translation (Englisch-Deutsch, 2023)

483
756</sample>
    <sample id="11">Deutsch: German Text Simplification Corpora English: German Text Simplification Corpora</sample>
    <sample id="12">Deutsche Übersetzung:

Das Bild zeigt eine PowerPoint-Präsentation mit dem Titel "German Text Simplification Corpora". Es zeigt verschiedene statistische Daten in Form von Balkendiagrammen, die die Anzahl der Beispiele pro Datensatz und die Anzahl der simplifizierten Sätze pro Datensatz darstellen. 

Die Datensätze sind "Parallel", "Translation-based", "Statistical", "Hybrid" und "Deep Learning". Jeder Datensatz hat mehrere Säulen, jede Säule repräsentiert einen verschiedenen Ansatz zur Textsimplifikation. 

Die Farben der Säulen variieren von blau über grün bis orange. Jede Farbe steht für einen bestimmten Ansatz zur Textsimplifikation. 

Die Y-Achse zeigt die Anzahl der Beispiele pro Datensatz und die Anzahl der simplifizierten Sätze pro Datensatz. 

Die X-Achse zeigt die verschiedenen Ansätze zur Textsimplifikation an.

Die Präsentation zeigt, dass der "Parallel" Datensatz am meisten simplifizierte Sätze enthält, gefolgt von "Translation-based" und "Statistical". Der "Hybrid" und "Deep Learning" Datensatz enthält relativwenig simplifizierte Sätze.

Die Präsentation zeigt auch, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Datensätze enthalten mehr simplifizierte Sätze als andere.

Die Präsentation zeigt, dass die Anzahl der simplifizierten Sätze in den Datensätzen variiert. Einige Dat</sample>
    <sample id="13">German Text Simplification Corpora

Sentence Level

14000
12000
10000
8000
6000
4000
2000
0
Parallel Parallel Parallel Parallel Parallel Parallel
Translation Training Translation Training Translation Training Translation Training Translation
(Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015)
Manual Manual Manual Manual Manual Manual
Alignment Alignment Alignment Alignment Alignment Alignment
(Deutsch-Englisch, 2013) (Deutsch-Englisch, 2013) (Deutsch-Englisch, 2013) (Deutsch-Englisch, 2013) (Deutsch-Englisch, 2013) (Deutsch-Englisch, 2013)
Machine Machine Machine Machine Machine Machine
(Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015)
Parallel Parallel Parallel Parallel Parallel Parallel
Translation Training Translation Training Translation Training Translation
(Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015) (Deutsch-Englisch, 2015)</sample>
    <sample id="14">Typen von Simplifikation

Die Grafik zeigt die Häufigkeit von Typen von Simplifikationen in drei Kategorien: News, Bibel und Fiktions文本。每种类型都有三种不同类型的简化：Simplicity、LexSimp und StructSimp。例如，在“News”类别中，Simplicity 和 LexSimp 的频率较高，而 StructSimp 的频率较低。

Simplifikations Transformationen

该图表比较了两种不同的 Simplifikations 方法：DEplain-apa und DEplain-web。它展示了每种方法在不同简化类型上的表现，如排序、重写、词干提取、单词添加和单词删除。DEplain-apa 在排序和重写方面表现出较高的频率，而 DEplain-web 在词干提取、单词添加和单词删除方面表现出较高的频率。</sample>
    <sample id="15">Typen der Simplifikation

Die Grafik zeigt zwei Diagramme, die die verschiedenen Typen von Simplifikationen und ihre Häufigkeiten in drei Kategorien – News, Bibel und Fiktion – darstellen. Die Farben blauen, oranges, gelben und roten symbolisieren verschiedene Simplifikationsmethoden: Simplicity, LexSimp, StructSimp und L2.

Die Grafik im oberen Teil zeigt, dass die Häufigkeit der Simplicity-Methode in den News-Kategoriengruppen amlowest ist, während sie in den Bibel- und Fiktion-Kategoriengruppen relativ hoch ist. LexSimp und StructSimp scheinen in allen Kategoriengruppen ähnliche Häufigkeiten zu haben, während L2 in den News-Kategoriengruppen relativ hoch ist.

Die Grafik im unteren Teil zeigt die Häufigkeiten von Simplifikationsoperationen wie Umbenennung, Ersetzung, löschen, Hinzufügen und Änderung. Die Häufigkeiten variieren je nach Operation, mit "word addition" in den News-Kategoriengruppen amhighest und "word deletion" in den Bibel- und Fiktion-Kategoriengruppen relativ lowest.

Insgesamt zeigt die Grafik, dass die Häufigkeiten von Simplifikationsoperationen und Typen von Simplifikationsmethoden variieren und je nach Kategoriengruppe unterschiedlich sind.</sample>
    <sample id="16">Typen der Simplifikation

Die Grafik zeigt die Häufigkeit von Typen der Simplifikation in drei Kategorien: News, Bible und Fiction. Es werden zwei Arten von Simplifikationen untersucht: LexSimp und StructSimp. LexSimp beinhaltet Veränderungen wie L2-Reduzierung, Reduplikation, Reorganisierung, Repräsentation, lexikalische Substitution, Wort Addition und Wort Deletion. StructSimp hingegen beinhaltet Veränderungen wie L2-Reduzierung, Reduplikation, Reorganisierung, Repräsentation, lexikalische Substitution, Wort Addition und Wort Deletion.

Die Grafik zeigt, dass LexSimp in den Kategorien News und Bible häufiger vorkommt als StructSimp. In der Kategorie Fiction scheint StructSimp dagegen dominanter zu sein.</sample>
    <sample id="17">Typen von Simplifikation

Die Grafik zeigt die Häufigkeit von Typen von Simplifikationen in verschiedenen Texten. Es werden die Häufigkeiten von L2, Bible und Fiction betrachtet. Die Häufigkeiten werden durch Stäbe dargestellt, wobei der L2-Typ in blauer Farbe, der Bible-Typ in roter Farbe und der Fiction-Typ in gelbener Farbe dargestellt wird.

Simplifikations Transformationen

Die Grafik zeigt auch die Häufigkeiten von Simplifikations Transformationen in den Texten. Es werden die Häufigkeiten von Reorganisieren, Rephrasing, Lexikal Substitution, Wort Addition und Wort Deletion betrachtet. Die Häufigkeiten werden durch Stäbe dargestellt, wobei die Häufigkeiten von Reorganisieren in blauer Farbe, die Häufigkeiten von Rephrasing in roter Farbe, die Häufigkeiten von Lexikal Substitution in gelbener Farbe, die Häufigkeiten von Wort Addition in blauer Farbe und die Häufigkeiten von Wort Deletion in roter Farbe dargestellt werden.</sample>
    <sample id="18">Typen der Simplifikation

Die Grafik zeigt die Häufigkeit von Typen der Simplifikation in verschiedenen Texten. Es werden drei Arten von Simplifikationen untersucht: Simplicity, LexSimp und StructSimp. Die Grafik zeigt, dass die Häufigkeit der Simplifikationen variiert, je nach Texttyp. Zum Beispiel sind die Häufigkeiten von Simplicity und LexSimp in den Newsartikel文本较低， während sie in den Bibel文本较高。StructSimp Häufigkeiten variieren zwischen den Texttypen.

Simplifikations Transformationen

Die Grafik zeigt auch die Häufigkeiten von Simplifikations Transformationen, wie Remodellung, Erweitern, lexikalische Substitution, Wort Addition und Wort Deletion. Es zeigt, dass lexikalische Substitution die häufigste Simplifikations Transformation ist, gefolgt von Wort Addition und Wort Deletion. Remodellung und Erweitern sind die seltendsten Simplifikations Transformationen.</sample>
    <sample id="19">3. Use-cases
- Automatische Ausrichtung und Simplifizierung</sample>
    <sample id="20">Ergebnisse der Auswertung der Ausrichtungsmethoden mit 1:1 (oberes Teil) und n:n Kapazitäten (unteres Teil)

Name

Beschreibung

P

R

F₁

F₂

F₀,₅

Sent-LaBSE

Metrische Ausrichtung unter Verwendung von Satz embeddings basierend auf Sprachsimilarität

960

444

607

779

325

Sent-RoBERTa

Ähnliche embeddings von Cross-Englisch &amp;amp; German RoBERTa

247

553

342

278

CATS-C3G

Verschiedene Ähnlichkeitsmaßnahmen (e.g. -grams, CRMs, word vectors)

84

387

290

300

Wortgleich

Eine naivere Ansatz, der die Ähnlichkeitsmatrix TF-IDF verwendet

846

477

610

819

628

730</sample>
    <sample id="21">Ergebnisse der Auswertung von Alignmentsmethoden mit 1:1-Unterampionships (obere Hälfte) und n:n-Möglichkeiten (untere Hälfte)

Name

Beschreibung

P

R

F₁

P

R

F₁

111

960

444

780

900

444

607

775

247

553

342

276

847

465

610

733

737

387

561

412

846

477

628

730</sample>
    <sample id="22">Ergebnisse der Auswertung von Alignmentsmethoden mit 1:1 (oberes Teil) und n:n Capabillitäten (unteres Teil)

Name

Deskription

P

R

F₁

F₂

F₀,₅</sample>
    <sample id="23">Ergebnisse der Auswertung von Alignmentsmethoden mit 1:1 (oberes Teil) und n:n Kapazitäten (unteres Teil)

Name

Beschreibung

P

R

F₁

P

R

F₁

Sent-LaBSE

Metrischer Ansatz, der die Ähnlichkeit von Satzembedding verwendet

960

444

607

779

780

825

Sent-RoBERTa

Ähnlichkeiten von Cross English &amp;amp; German RoBERTa

247

344

342

276

276

276

CATS-C3G

Verschiedene Ähnlichkeitsmaßnahmen (e.g. Grams - Word Vektoren)

84

344

342

276

276

276

BERTalign

Ermöglicht Satz-transformer-Methoden zur Produktion von n:m Alignments

743

465

610

561

387

412

Vogelalign

Eine Nähe-getriebene Ansatz mit einem TF-IDF Ähnlichkeitsmatrix

846

477

610

733

628

730</sample>
    <sample id="24">Ergebnisse der Auswertung der Ausrichtungsmethoden mit 1:1 (oberes Teil) und n:n Capabillitäten (unteres Teil)

Name

Beschreibung

P

R

F₁

F₀₅

F₀₀

Sent-LaBSE

Metrischer Ausrichtungsalgorithmus unter Verwendung von Satz embeddings相似性

960

444

607

779

780

Sent-RoBERTa

Similar embeddings of Cross English &amp;amp; German RoBERTa

247

553

342

276

285

CATS-C3G

Different similarity measures e.g. grams - word vectors

84

477

346

285

285

BERTalign

Ermöglicht Satz-transformer-Methode zur Produktion von n:m Ausrichtungen

743

465

387

561

612

Vowpal

Eine vicinity-driven-Annäherung mit einem TF-IDF-Similaritätsspielplatz

846

477

610

819

628

730</sample>
    <sample id="25">Ergebnisse der Auswertung von Alignmentsmethoden mit 1:1 (oberes Teil) und n:n Kapazitäten (unteres Teil)

Name

Beschreibung

P

R

F₁

P

R

F₁

LIU-TA

Metrischer Ansatz zur Evaluierung der Übereinstimmung von Satzembedding

847

444

780

960

444

779

Sent-LaBSE

Parallel embeddings of Language Model BERT Transformer

960

444

780

960

444

779

Sent-RoBERTa

Similar embeddings of Cross English &amp;amp; German RoBERTa

247

353

326

278

465

333

CATS-C3G

Different similarity measures e.g. grams - word vectors

847

444

780

960

444

779

Wolff

Vicinity-driven approach with a TF-IDF similarity matrix

846

477

628

733

459

628</sample>
    <sample id="26">Ergebnisse der Auswertung von Alignmentsmethoden mit 1:1 (oberes Teil) und n:n Kapazitäten (unteres Teil)

Name

Beschreibung

P

R

F₁

P

R

F₁

Sent-LaBSE

Gebrauch von Satz embeddings zur Ähnlichkeitsmessung

841.000

960.000

870.000

444.000

607.000

570.000

Sent-RoBERTa

Ähnlichkeiten von Cross-Englisch &amp;amp; RoBERTa

247.000

344.000

326.000

553.000

342.000

276.000

CATS-C3G

Verschiedene Ähnlichkeitsmaßnahmen (e.g., Grams - Word Vektoren)

13.000

13.000

13.000

13.000

13.000

13.000

BERTalign

Ermöglicht Satz-transformer-Methoden die Produktion von n:m Alignments

743.000

867.000

759.000

465.000

561.000

518.000

VowpalWabbit

Eine naiv getriebene Ansatz mit einem TF-IDF Ähnlichkeitsmatrix

846.000

819.000

832.000

477.000

628.000

730.000</sample>
    <sample id="27">Ergebnisse der Textsimplifikation auf Dokumentebene unter Verwendung des trainierten long-mBART

Train data

SARI BLEU BS-P BLEU-F1

Deplain-APL-WEB 17327 34.247 56.55 61.98

SCL-plain 17327 34.247 56.55 61.98

SCL-plain-APA (n=48) 17327 34.247 56.55 61.98

Baseline 17327 34.247 56.55 61.98</sample>
    <sample id="28">Ergebnisse derDOCUMENTSIMPLIFIKATION mit einem finetuned long-mBART

Ergebnisse derSENTENCE SIMPLIFICATION mit einem finetuned long-mBART</sample>
    <sample id="29">Ergebnisse der Document-Simplifikation mit dem finetuned-long-mBART. n correspond to the length of the training data. train data BLEU SARI- BLEU BS-P F1 DEplain-wo 481 17377 34.247 19.213 65.65 DEplain-w 481 17377 34.247 19.213 65.65 DEplain-baseline 17377 34.247 19.213 65.65 DEPLAIN-APA (n=48) 17377 34.247 19.213 65.65 ... DEPLAIN-WEB (n=147) 17377 34.247 19.213 65.65 ... DEPLAIN-APA test (n=123) 17377 34.247 19.213 65.65 DEPLAIN-WEB test (n=146) 17377 34.247 19.213 65.65 ... DEPLAIN-APA test (n=123) 17377 34.247 19.213 65.65 DEPLAIN-WEB test (n=146) 17377 34.247 19.213 65.65</sample>
    <sample id="30">Erklärung der automatischen Textsimplifikation

Die automatischen Textsimplifikationsmethoden zielen darauf ab, den Leseverstand von Benutzern zu verbessern, indem sie die Sprache und die Struktur von Texten vereinfachen. In dem obigen Bild werden die besten Textsimplifikationsmethoden auf verschiedenen Datensätzen evaluiert.

Die Tabelle "Results on Document Level" zeigt die Leitstelle "train data" mit den Metriken SARI, BLEU, BS-P und FREI. Die Metrik SARI misst die Ähnlichkeit zwischen dem originaltext, dem simplifizierten Text und dem idealen simplifizierten Text. BLEU-Metrik misst die Ähnlichkeit zwischen dem simplifizierten Text und einem idealen simplifizierten Text. BS-P-Metrik misst die Häufigkeit von Begriffsschwankungen im simplifizierten Text. FREI-Metrik misst die Häufigkeit von Fehlern in der Grammatik und der Syntax im simplifizierten Text.

Die Tabelle "Results on Sentence Level" zeigt die Leitstelle "train data" mit den Metriken SARI, BLEU, BS-P und FREI. Die Metrik SARI misst die Ähnlichkeit zwischen dem originaltext, dem simplifizierten Text und dem idealen simplifizierten Text. BLEU-Metrik misst die Ähnlichkeit zwischen dem simplifizierten Text und einem idealen simplifizierten Text. BS-P-Metrik misst die Häufigkeit von Begriffsschwankungen im simplifizierten Text. FREI-Metrik misst die Häufigkeit von Fehlern in der Grammatik und der Syntax im simplifizierten Text.

Die Evaluierungen zeigen, dass die Textsimplifikationsmethoden in den Datensätzen "Deplain-APL-Web" und "Deplain-APL-Test" guten Resultate erzielen. Es zeigt sich, dass die Textsimplifikationsmethoden die Lesbarkeit und Verständlichkeit von Texten verbessern können.</sample>
    <sample id="31">Ergebnisse der Textsimplifikation an der Dokumentebene unter Verwendung des finetuned mBART. n entspricht der Länge der Trainingsdaten.</sample>
    <sample id="32">Ergebnisse der Textsimplifikation mittels finetuned-long-mBART

Die Tabelle zeigt die Auswertung der Textsimplifikation mittels des finetuned-long-mBART-Modells auf dem DEPLAIN-APL-Test. Es werden die Leitstelle (SARI), BLEU und BLEU-Score (BS) bewertet. Die trainierten Datensätze "Deplain-Web" und "Deplain-Web-Baseline" werden verglichen. Das Modell "Deplain-Web" erreicht einen SARI-Score von 34,247, einen BLEU-Score von 65,65 und einen BLEU-Score von 65,65. Der Baseline-Modell "Deplain-Web-Baseline" erreicht einen SARI-Score von 17,827, einen BLEU-Score von 34,247 und einen BLEU-Score von 34,247.

Ergebnisse der Satzstelle-Simplifikation mittels finetuned-long-mBART

Die Tabelle zeigt die Auswertung der Satzstelle-Simplifikation mittels des finetuned-long-mBART-Modells auf dem DEPLAIN-APL-Test. Es werden die Leitstelle (SARI), BLEU und BLEU-Score (BS) bewertet. Die trainierten Datensätze "Deplain-APL-Web" und "Deplain-APL-Web-Baseline" werden verglichen. Das Modell "Deplain-APL-Web" erreicht einen SARI-Score von 19,404, einen BLEU-Score von 34,247 und einen BLEU-Score von 34,247. Das Baseline-Modell "Deplain-APL-Web-Baseline" erreicht einen SARI-Score von 13,787, einen BLEU-Score von 19,404 und einen BLEU-Score von 19,404.</sample>
    <sample id="33">Ergebnisse der Textsimplifikation an der Dokumentebene

Die Tabelle zeigt die Auswertung der Textsimplifikation an der Dokumentebene. Es werden verschiedene Metriken wie SARI, BLEU, BS-P und FREI verwendet, um die Leistung zu messen. Die Trainingsdaten und die Baseline werden auch berücksichtigt.

Ergebnisse der Textsimplifikation an der Satzebene

In dieser Tabelle werden die Auswertungen der Textsimplifikation an der Satzebene präsentiert. Hier werden auch Metriken wie BLEU, METEOR, CIDEr und ROUGE verwendet, um die Leistung zu bewerten.</sample>
    <sample id="34">Danke.Für weitere Details. Bitte überprüfen Sie unser Papier.Und fühlen Sie sich frei, unser Poster auf der ACL 2023 Konferenz zu besuchen.</sample>
    <sample id="35">Patrick Fernandes</sample>
    <sample id="36">Das T5 XL Modell wurde verwendet, um die Genauigkeit von 82–87 % zu erreichen.</sample>
    <sample id="37">Ja, sie sind immer noch in Betrieb.</sample>
    <sample id="38">Die vorgeschlagene menschliche Bewertungsmethode ist neu, da sie die Relevanz der Bots' Antworten bewertet.</sample>
    <sample id="39">The success of the existing weakly supervised approach depends on the selection strategy.</sample>
    <sample id="40">Das Resultat kann durch die Vermeidung von Duplikaten und die Bereitstellung von einzigartigen Informationen verbessert werden.</sample>
    <sample id="41">5</sample>
    <sample id="42">Die Slide-Übersetzung ins Deutsche lautet:

Titel: "Verknüpfte Längen im Englischen, Minimierung der Abhängigkeitslänge und Struktur der Koordination"

Untertitel: "Adam Przpiórkowski und Michał Wójcik"

Institutionen: "Institute of Computer Science, Polish Academy of Sciences (ul. Jana Kazimierzowa 5, 01-248 Warschau)" und "University of Warsaw"

Konferenz: "ACL 2023"</sample>
    <sample id="43">Dependenzstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie.
  
- Chain/Moscow:
  Homer liebt Lisa, Bart und Maggie.
  
- Conjunction-headed/Praague:
  Homer liebt Lisa, Bart und Maggie.
  
- Multi-headed/London:
  Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="44">Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.
  
- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.
  
- Conjunction-headed/Praague:
  Homer loves Lisa, Bart, and Maggie.
  
- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="45">Dependenzstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.
  
- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.
  
- Conjunction-headed/Praha:
  Homer loves Lisa, Bart, und Maggie.
  
- Multi-headed/London:
  Homer loves Lisa, Bart, und Maggie.</sample>
    <sample id="46">Dependenzstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie.

- Chain/Moscow:
  Homer liebt Lisa, Bart und Maggie.

- Conjunction-headed/Praague:
  Homer liebt Lisa, Bart und Maggie.

- Multi-headed/London:
  Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="47">Dependenzstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.
  
- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.
  
- Conjunction-headed/Praague:
  Homer loves Lisa, Bart, and Maggie.
  
- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="48">Dependenzstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.
  
- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.
  
- Conjunction-headed/Praague:
  Homer loves Lisa, Bart, and Maggie.
  
- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="49">Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.
  
- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.
  
- Conjunction-headed/Praague:
  Homer loves Lisa, Bart, and Maggie.
  
- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="50">Dependenzstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.
  
- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.
  
- Conjunction-headed/Praha:
  Homer loves Lisa, Bart, and Maggie.
  
- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="51">Word order tends to minimize dependency lengths:</sample>
    <sample id="52">Word order tends to minimize dependency lengths:</sample>
    <sample id="53">Word order tends to minimize dependency lengths:</sample>
    <sample id="54">Word order tends to minimize dependency lengths:</sample>
    <sample id="55">Word order tends to minimize dependency lengths:</sample>
    <sample id="56">Word order tends to minimize dependency lengths:</sample>
    <sample id="57">Word order tends to minimize dependency lengths:</sample>
    <sample id="58">Word order tends to minimize dependency lengths:</sample>
    <sample id="59">Word order tends to minimize dependency lengths:</sample>
    <sample id="60">Word order tends to minimize dependency lengths:</sample>
    <sample id="61">Word order tends to minimize dependency lengths:</sample>
    <sample id="62">Word order tends to minimize dependency lengths:</sample>
    <sample id="63">Statistiken über die Koordination wurden aus einer erweiterten Version von Penn Treebank (Marcus et al. 1993; Flicker und Berg 2016) abgeleitet.

Pronomen tenden zu kürzer zu sein, als vorher festgestellt wurde. Dieses Trend wird mit der Längstunterschieden intensiver. (Breviär beachtet Gibson et al. 1996: 88-90).

Aber nur dann, wenn die Regierung auf der linken oder fehlt (Ich sah Bart und Lisa: Homer kam und schnäuzte).</sample>
    <sample id="64">Statistiken über die Koordination wurden aus einer erweiterten Version des Penn Treebank (Marcus et al. 1993; Flicker und Goldberg 2016) abgeleitet.
• Linker Koordinationstrend zu kürzeren als früher (observiert wurde); 
• dieser Trend wird mit der Längstelle zunehmen;
• (nur kurz angesprochen in Gibson et al. 1996: 88–90)
• aber nur, wenn der Gouverneur links steht oder weg ist,
• (ich sah Bart und Lisa: Homer kam und schnäuzte),
• nicht, wenn er rechts steht (Ted und Ned lachten).</sample>
    <sample id="65">Statistiken über Koordination extrahiert aus einer erweiterten Version von Penn Treebank (Marcus et al. 1993; Flicker und Goldberg 2016): • Linkes Koordinieren tendenziell kürzer als rechtes (beobachtet); • Dieser Trend wird mit Längstelle zunehmen; (nur kurz angedeutet in Gibson et al. 1996: 88–90) • Nur dann, wenn die Gouverneurposition links steht oder weg ist (Ich sah Bart und Lisa Hauer kommen und sieben); • Und nicht, wenn sie rechts steht (Ted und Ned lachten).</sample>
    <sample id="66">Statistiken über die Koordination wurden aus einer erweiterten Version des Penn Treebank (Marcus et al. 1993; Flicker und Goldberg 2016) abgeleitet.

• Linker Koordianten tendieren dazu zu sein kürzer (wie vorher beobachtet, \alpha)
• Dieser Trend wird mit der Längstunterschieden intensiver
• (nur kurz angesprochen in Gibson et al. 1996: 88–90)

• Aber nur dann, wenn der Gouverneur links steht oder weg ist
• (ich sah Bart und Lisa: Homer kam und schnäuzte)
• nicht, wenn er rechts steht
• (Ted und Ned lachten)</sample>
    <sample id="67">Statistiken über die Koordination wurden aus einer erweiterten Version der Penn Treebank (Marcus et al. 1993; Flicker und Goldberg 2016) abgeleitet:

• Linkes Koordinieren tendiert dazu, kürzer zu sein (wie vorher beobachtet),
• dieser Trend wird mit Längstelle zunehmen,
• (nur kurz angesprochen in Gibson et al. 1996: 88–90).

Aber nur, wenn die Regierung links steht oder weg ist
(Ihre Bart und Lisa; Homer kam und schnäuzte)
– nicht, wenn sie rechts steht (Ted und Ned lachten).</sample>
    <sample id="68">Statistiken über die Koordination wurden aus einer erweiterten Version des Penn Treebank (Marcus et al. 1993; Flicker und Goldberg 2016) abgeleitet:

• Linker Koordinationstempel neigt dazu kürzer zu sein (beobachtet wurde), 
• dieser Trend wird mit Längstelle zunehmen,
• (nur kurz angedeutet in Gibson et al. 1996: 88–90).

Aber nur, wenn der Gouverneur links steht oder weg ist (Ich sah Bart und Lisa; Homer kam und *schnäuzte*).</sample>
    <sample id="69">Statistiken über die Koordination wurden aus einer erweiterten Version des Penn Treebank (Marcus et al. 1993; Flicker und Goldberg 2016) abgeleitet:

- Linker Koordinationstypen tendieren dazu, kürzer zu sein als zuvor beobachtet wurde,
- dieser Trend wird mit der Längstelle zunehmen,
- (nur kurz angedeutet in Gibson et al. 1996: 88–90).

Aber nur dann, wenn die Regierung links steht oder weg ist:
"Ich sah Bart und Lisa; Homer kam und schnäuzte" (nicht, wenn sie rechts steht)</sample>
    <sample id="70">Die Grafiken im Bild repräsentieren die Anteile von kürzeren Konjunktionen, abhängig von der absoluten Differenz der Längen der Konjunktiv in verschiedenen Größen. In der oberen Reihe werden die Größen in Charakteren, Stylabsen und Wörtern betrachtet, während die untere Reihe die Größen auf der linken Seite in Charakteren, Stylabsen und Wörtern und auf der rechten Seite in Stylabsen und Wörtern analysiert. Jede Grafik zeigt eine lineare Regression mit einem 95%-Konfidenzbereich, um die Abhängigkeit zu visualisieren.</sample>
    <sample id="71">Die Grafik zeigt die Verteilung der Längenunterschiede von kürzeren und längeren Textsegmenten in einem Satz. Es wird gezeigt, dass die Längenunterschiede in den kürzeren Textsegmenten (rechts) kleiner sind als die Längenunterschiede in den längeren Textsegmenten (links).</sample>
    <sample id="72">Die Grafik zeigt die Proportionen von kürzeren Konjunktionen, abhängig von der Differenz der Längen der Konjunktoren (in字符数、音节和词中) und der Konfidenzintervallen. Es zeigt an, dass die Proportionen von kürzeren Konjunktionen in den Gruppen mit kleineren Differenzen der Längen der Konjunktoren (字符数、音节和词) relativ较高, insbesondere in den Gruppen mit kleineren Differenzen der Längen der linken Konjunktoren (字符数、音节和词).</sample>
    <sample id="73">Die Grafik zeigt die Proportionen von kürzeren Konjunktionen abhängig von der absoluten Differenz der Komponentenlängen. Es gibt zwei Hauptgruppen: "NO governor in CHARACTERS" und "Governor on the LEFT in CHARACTERS". Jede Gruppe enthält mehrere Grafiken, die unterschiedliche Längsdifferenzen und Proportionen von kürzeren Konjunktionen zeigen. Die Grafiken sind in Farben codiert, um die verschiedenen Längsdifferenzen zu verdeutlichen.</sample>
    <sample id="74">Siehe das Papier für die vollständige Argumentation!</sample>
    <sample id="75">To determine the number of authors involved in the work presented in the image, we need to carefully examine the text provided. The image shows a title and the names of the authors listed below it. 

1. Identify the title: "Compositional Generalization without Trees using Multiset Tagging and Latent Permutations."
2. List the authors' names: Matthias Lindemann, Alexander Koller, Ivan Titov.

By counting the number of distinct names listed, we can conclude that there are three authors involved in this work.

Therefore, the answer is 3.</sample>
    <sample id="76">Die News-Domäne wird stärker vereinfacht.</sample>
    <sample id="77">Read this absolutely fascinating book about bees.</sample>
    <sample id="78">Ja, die DrBERT-Modelle, der NACHOS-Datensatz und die Trainingsskripte sind unter der MIT-Lizenz frei zur Verfügung gestellt.</sample>
    <sample id="79">DEplain-apa enthält Dokumente aus dem Medizinischen Journal.</sample>
    <sample id="80">Better model architecture, larger model size and more fine-tuning examples.</sample>
    <sample id="81">Die Tendenz wurde gemessen, indem die Längenunterschiede zwischen den linken und rechten Konjunktionen ermittelt wurden.</sample>
    <sample id="82">Die Experimente wurden so gestaltet, dass sie die Auswirkungen der Position des Begrenzers auf die Häufigkeit von Shifter-Eventen untersuchten.</sample>
    <sample id="83">Ein Basisklassifikator ist nicht besser als Zufall, wenn er mit unausgewogenen Daten trainiert wird.</sample>
    <sample id="84">Vier.</sample>
    <sample id="85">The persons in the example conversation are named John, Jane, and Peter.</sample>
    <sample id="86">Kontextsensitive MÜ-Modelle schneiden besser ab bei diskursphänomenen, bei denen die Kontextualisierung von Texten relevant ist.</sample>
    <sample id="87">Johns Hopkins University, Purdue University, and MIT</sample>
    <sample id="122">The framework quantifies positionality by measuring the correlation between the demographics of the annotators and the gold labels from the models.</sample>
    <sample id="155">The answer is not provided in the given image.</sample>
    <sample id="156">Die Studie verwendet die National Longitudinal Survey of Youth (NLSY) und die National Longitudinal Survey of Youth in Adulthood (NLSY79).</sample>
    <sample id="157">To determine the number of authors involved in the work presented in the image, we need to carefully analyze the text provided. The image shows a title slide from a presentation or paper with the following details:

- Title: "Conjunct Lengths in English, Dependency Length Minimization, and Dependency Structure of Coordination"
- Authors: Adam Przepiórkowski and Michał Wójcik
- Affiliations: Institute of Computer Science, Polish Academy of Sciences, and University of Warsaw
- Conference: ACL 2023

From the information given, it is clear that there are two authors listed: Adam Przepiórkowski and Michał Wójcik.

Therefore, the number of authors involved in the work is 2.</sample>
    <sample id="158">Debatte und ICE.</sample>
    <sample id="159">Die Anzahl der Autoren, die an der Arbeit beteiligt sind, beträgt zwei.</sample>
    <sample id="160">There are 8 authors involved in the work.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von seinen Vorgängern dadurch, dass es eine Vielzahl von Datensätzen und Ansatzpunkten integriert. Es ist ein flexibler Ansatz, der die Annotierungen von Menschen und Maschinen kombiniert und dabei die individuelle Demographie berücksichtigt.</sample>
    <sample id="162">GPT-4</sample>
    <sample id="163">None</sample>
    <sample id="164">Von der Vorbereitung von Datensätzen für Sprachmodelle bis hin zu Sprachmodellen, die die Spuren politischer Biases nachverfolgen</sample>
    <sample id="165">LM Training Data A mixed blessing Jesse, et al. "Documenting Large Web Corpora: A Case Study: Crawl Corpus - Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, 2013."</sample>
    <sample id="166">LM Training Data
A mixed blessing
Dodge, Jesse, et al. "Documenting Large Web Corpora: A Case Study on Crawling Corpus - Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)."</sample>
    <sample id="167">LM Training Data A mixed blessing Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on Crawled Corpus - Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP 2019)"</sample>
    <sample id="168">LM Training Data A mixed blessing Jesse, et al. "Documenting Large Weighted Corpora: A Case Study on Crawled Corpus - Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing" 2019</sample>
    <sample id="169">To this end, pretraining data is fed into language models which are subsequently used for downstream tasks.</sample>
    <sample id="170">To this end, pretraining data Language models Downstream tasks</sample>
    <sample id="171">To this end, pretraining data Language models Downstream tasks How do you evaluate the political leaning of LMs? What role does pretraining data play in such political biases? How do LMs with different political leanings perform? Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="172">Evaluating LM Political Leaning

Die beiden LMs (Language Models) werden unterstützt, sowohl der Encoder als auch der Decoder. Sie werden mit einer Aussage maskiert und danach mit dieser Aussage evaluiert.

Automatischer Evaluationsprozess

Der Prozess basiert auf politischem Literatur (politi.c lit). 

Die Sprache wird durch den Prompted Response (Prompted Response) abgefragt und die Ausgangsreaktion wird als "Political Compass Test" bezeichnet.

Die Ausgangsreaktion wird dann in einem Diagramm dargestellt, das die politische Neigung des LMs zeigt. Auf der linken Seite steht "Libertarian" und auf der rechten Seite steht "Authoritarian".</sample>
    <sample id="173">Eine Grafik, die verschiedene Sprachmodelle (LMs) auf einer Achsenskala von autoritärer zu libertarischer und von rechts zu linken Positionen einstellt.</sample>
    <sample id="174">Existentielle LM's

Die Grafik zeigt eine Karte, die verschiedene Sprachmodelle (LMs) nach ihren politischen Ausrichtungen einstellt. Auf der x-Achse wird zwischen "-authoritär" und "libertär" unterschieden, während die y-Achse zwischen "eonomisch_aktiv" und "eonomisch_passiv" differenziert.

Einfewere LMs, wie BERT-base, RoBERTa-base und ALBERT-base, liegen in der linken Quadrant, was bedeutet, dass sie autoritär und eonomisch passiv sind. Andere LMs, wie GPT-3-ada und GPT-4, liegen in der rechten Quadrant, was bedeutet, dass sie libertär und eonomisch aktiver sind.</sample>
    <sample id="175">Prätraining von Daten

Weitere prätraining LM (Roberta, GPT-2) Checkpoints evaluieren die Veränderung in der politischen Neigung

Nachfolgende

News-Medien

Redditt

Mitte

Mitte

Mitte

Mitte

Mitte</sample>
    <sample id="176">Prätraining von Daten

Weitereorgete LM (Roberta, GPT-2) Checkpoints evaluieren die Änderung in der politischen Neigung

Nachrichtenmedien Soziale Medien (Reddit)

links links

Mitte Mitte

rechts rechts

Yoon, et al. "POLITICS: Predicting with Same-story Article Comparison for Ideology Prediction and Stance Detection", NAACL 2022 Shen, Qian, &amp;amp; Carind Rose. "What sounds 'right' to me? An experiential factor in the perception of political correctness", Journal of Language and Politics, Asian Volume 2021</sample>
    <sample id="177">Ergebnisse

Partisan shifts in LM political leaning

RobBERTa

GPT-2

original

reddit

news

reddit

reddit

original

news</sample>
    <sample id="178">Ergebnisse

Partisan shifts in LM political leaning

RobBERTa

GPT-2</sample>
    <sample id="179">Ergebnisse
Partisan shifts in LM political leaning
RoBERTa
GPT-2
left
center
right
reddit
news
original
news
reddit
Reddit</sample>
    <sample id="180">The Trump Card: Pre-45th to post-45th shift</sample>
    <sample id="181">The Trump Card: Pre-45th to post-45th shift</sample>
    <sample id="182">The Trump Card: Pre-45th to Post-45th Shift</sample>
    <sample id="183">Kategorielweise Leistungsdaten

1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
9.0
10.0
11.0
12.0
13.0
14.0
15.0
16.0
17.0
18.0
19.0
20.0
21.0
22.0
23.0
24.0
25.0
26.0
27.0
28.0
29.0
30.0
31.0
32.0
33.0
34.0
35.0
36.0
37.0
38.0
39.0
40.0
41.0
42.0
43.0
44.0
45.0
46.0
47.0
48.0
49.0
50.0
51.0
52.0
53.0
54.0
55.0
56.0
57.0
58.0
59.0
60.0
61.0
62.0
63.0
64.0
65.0
66.0
67.0
68.0
69.0
70.0
71.0
72.0
73.0
74.0
75.0
76.0
77.0
78.0
79.0
80.0
81.0
82.0
83.0
84.0
85.0
86.0
87.0
88.0
89.0
90.0
91.0
92.0
93.0
94.0
95.0
96.0
97.0
98.0
99.0
100.0</sample>
    <sample id="184">Kategorien Leitstelle Black Muslim LGBTQ+ Juden Asiat Laiende Frauen Christen Männer Weiße
News Left 80,63 89,84 89,19 82,85 83,66 81,15 87,82 87,65 85,63
Reddit Left 80,83 89,84 89,19 82,85 83,66 81,15 87,82 87,65 85,63
Reddit Right 80,83 89,84 89,19 82,85 83,66 81,15 87,82 87,65 85,63
Misinformation HP (L) NYT (NY) CNN (NY) NPR (DC) Guard (UK) Fox (US) WaEx (US) BBart (R) WAT (US) NR (US)
Reddit Left 88,72 85,54 84,86 82,21 84,44 90,66 96,63 90,48 91,15 90,18</sample>
    <sample id="185">Kategorierte Leistungsdaten

1. News Left
2. Reddit Left
3. Reddit Right
4. Minisinformation

HP (L)
NYT
CNN (L)
CNN (R)
NPR (L)
Guard (L)
Fox
WAE (X)
BB (R)
WAT (R)
NR (L)

Table 4: Farben编码表示不同来源的 hate speech和misinformation。深黄色表示最好，深蓝色表示最差。

深黄色表示最好的表现，深蓝色表示最差的表现。</sample>
    <sample id="186">Kategorieliges Leistungsverhalten

Die Tabelle zeigt die Leistungen bei der Identifizierung von Hasssprache und Missinformation von verschiedenen Quellen. 

| Kategorielle Gruppe | Leistungsstelle | Leistungsstelle | Leistungsstelle | Leistungsstelle | Leistungsstelle | Leistungsstelle | Leistungsstelle | Leistungsstelle |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| News_left | 80,63 | 89,41 | 82,05 | 80,90 | 89,09 | 89,09 | 89,09 | 89,09 |
| Reddit_left | 88,72 | 85,54 | 88,72 | 85,54 | 88,72 | 88,72 | 88,72 | 88,72 |
| Reddit_right | 80,03 | 80,03 | 80,03 | 80,03 | 80,03 | 80,03 | 80,03 | 80,03 |

Die Farbenrot und blau kennzeichnen das beste und das schlechteste Leistungsresultat, respectiv.

Tabelle 4: Farbenrot und blau kennzeichnen das beste und das schlechteste Leistungsresultat, respectiv.</sample>
    <sample id="187">Kategorien Leitstelle
Black 80,63 89,19 82,04 85,75 80,20 80,39 82,15 87,65 87,65 86,22
Muslim 84,84 89,09 89,09 90,66 89,15 89,15 90,66 87,65 87,65 88,66
LGBT+ 88,72 92,54 92,54 94,44 96,66 96,66 96,66 90,43 90,43 90,15
Jews 80,03 82,43 82,43 84,44 84,44 84,44 84,44 84,78 84,78 84,78
Asian 80,63 82,43 82,43 84,44 84,44 84,44 84,44 84,78 84,78 84,78
Latinx 80,63 82,43 82,43 84,44 84,44 84,44 84,44 84,78 84,78 84,78
Women 80,63 82,43 82,43 84,44 84,44 84,44 84,44 84,78 84,78 84,78
Christian 80,63 82,43 82,43 84,44 84,44 84,44 84,44 84,78 84,78 84,78
Men 80,63 82,43 82,43 84,44 84,44 84,44 84,44 84,78 84,78 84,78
White 80,63 82,43 82,43 84,44 84,44 84,44 84,44 84,78 84,78 84,78
Minisinformation HP (l) NYT CNN (l) NPR (l) Guard (l) Fox (l) WaEx (l) BBaT (R) WAT (R) NR</sample>
    <sample id="188">Kategorieliges Leistungsverhalten

Die Tabelle zeigt die Leistungen bei der Identifikation von Hasssprache und Manipulation von unterschiedlichen Identitäten und Quellen. 

| Kategorielle Gruppe | Leistungsparameter |
| --- | --- |
| News Left | 86,53 |
| News Right | 84,94 |
| Reddit Left | 89,09 |
| Reddit Right | 82,02 |
| Hate Speech | 80,03 |
| Black | 80,08 |
| Muslim | 90,19 |
| LGBTQ+ | 82,83 |
| Jews | 87,85 |
| Asians | 83,83 |
| Latinx | 83,55 |
| Women | 81,15 |
| Christian | 87,82 |
| Men | 87,65 |
| White | 85,22 |

Die Farbenrot (yellow) und blauer Farbe (blue) kennzeichnen die besten und schlechtesten Leistungen.</sample>
    <sample id="189">Kategorieliges Leistungsverhalten

Die Tabelle zeigt die Leistungen an verschiedenen Medien und Medienquellen bei der Identifizierung von Hasssprache und Falschinformation. 

Die Farben in der Tabelle repräsentieren die Leistungsstelle, wobei hellgelb die beste Leistung und dunkelblau die schlechteste darstellt.

1. News Left: 
   - Reddit Left: 86,83
   - Reddit Right: 89,84
   - CNN: 89,09
   - NPR: 82,43
   - Fox: 83,55
   - WAE Fox: 87,82
   - WAE Breitbart: 87,65
   - WAE NR: 86,22

2. Hate Speech:
   - Black: 80,03
   - Muslim: 90,19
   - LGBTQ+: 89,85
   - Jews: 89,85
   - Asians: 89,85
   - Latinx: 89,85
   - Women: 89,85
   - Christian: 89,85
   - Men: 89,85
   - White: 89,85

3. Misinformation:
   - HP (Left): 88,72
   - NYT (Left): 85,54
   - CNN (Left): 84,82
   - NPR (Left): 84,44
   - Fox (Right): 84,44
   - WAE Fox (Right): 84,44
   - WAE Breitbart (Right): 84,44
   - WAE NR (Right): 84,44</sample>
    <sample id="190">Qualitative Analyse

Text | Target Label | Base | N-L | S-L | N-R | S-R
--- | --- | --- | --- | --- | --- | ---
the all right is corrupted with people supporting a new nation. | ASIAN | True | True | True | False | False
What McDonald's stop Donald Trump from seizing. They were afraid that the country was in the throes of a crime pugn trail because they know I stop the slaughter going on Donald Trump August 20, 2019. | Right | False | False | True | True | True
It's incredible that me that water was in flight in flut and crime is paying in burlington vermont for clean water. | Fake | False | False | False | False | False</sample>
    <sample id="191">The slide titled "Qualitative Analysis" presents a table with examples of text, target labels, and base, N-L, S-L, N-R, and S-R values. The table includes the following entries:

1. Text: "the alt-right is corrupted with people supporting a new nationism"
   - Target Label: ASIAN
   - Base: True
   - N-L: True
   - S-L: True
   - N-R: False
   - S-R: False

2. Text: "What do you think about McDonald's and priest and people from common? They were just trying to stop Donald Trump because he was in the throws of a crime trail that the crime was the throwing of a crime trail because they know I was the slaughter going on Donald Trump said August 20th incredible"
   - Target Label: RIGHT
   - Base: True
   - N-L: False
   - S-L: False
   - N-R: True
   - S-R: True

3. Text: "that water has been in flight in flood is paying in Burlington Vermont for clean water"
   - Target Label: FAKE
   - Base: False
   - N-L: False
   - S-L: False
   - N-R: False
   - S-R: True

The slide also includes a note at the bottom stating: "Examples of the downstream performance of tasks using language models with varying political bias, base, N-L, S-L, N-R, and S-R, respectively."

The slide appears to be discussing the performance of language models in identifying political biases and labeling texts accordingly. The table provides specific examples of how different texts are labeled based on their content and the political bias associated with them.</sample>
    <sample id="192">Eine qualitative Analyse von Beispielen von Diskriminierungstexten anhand von LIME mit unterschiedlichen politischen Hintergründen.</sample>
    <sample id="193">Eine qualitative Analyse von Beispielen von Hate Speech wurde durch die Gruppe LM2 (Table 12) vorgenommen.</sample>
    <sample id="194">Eine qualitative Analyse von Beispielen von Hasssprache basiert auf dem Lesen und Verstehen von Texten. In einem solchen Analyse-Tabellen werden die Auswirkungen von Hasssprache auf den Leser diskutiert. In einem solchen Fall wird die Rolle von Hasssprache in der Verhältnisseanalyse diskutiert.</sample>
    <sample id="195">Eine qualitative Analyse von Beispielen von Hasssprache im Lichte der unterschiedlichen politischen Parteien im Detail.</sample>
    <sample id="196">Eine Präsentation über Sprachmodelle und die Bedeutung von "sanitieren" und "säubern" im Kontext der Datenermittlung.</sample>
    <sample id="197">Eine Präsentation mit dem Titel "Discussion: Between Scylla and Charybdis - To 'sanitize' or not to 'sanitize', that is the question" zeigt einen Prozess an, der "pretraining data", "language models" und "downstream tasks" miteinander verbindet.</sample>
    <sample id="198">Between Scylla and Charybdis To "sanitize" or not to "sanitize", that is the question Pretraining data Language models Downstream tasks</sample>
    <sample id="199">Dank U!</sample>
    <sample id="200">Um die Anzahl der Autoren zu bestimmen, die an der Arbeit beteiligt sind, benötigen wir die Anzahl der Individuen, die in der Gruppe dargestellt werden. In dem Bild können wir sechs Personen sehen. Daher sind es insgesamt sechs Autoren, die an der Arbeit beteiligt sind.</sample>
    <sample id="201">MPP evaluations were performed with contexts of lengths up to 900 tokens.</sample>
    <sample id="202">Sie haben in ihren Datensatz 3 Domains aufgenommen: Pop, Reggae und RnB.</sample>
    <sample id="203">Positionalität bezieht sich auf die Rolle und den Status einer Person in einer bestimmten Gruppe oder Gesellschaft. Es ist ein wichtiger Begriff in soziologischer Forschung, um zu verstehen, wie die Rolle und das Bewusstsein von Status innerhalb von Gruppen und Gesellschaften beeinflussen.</sample>
    <sample id="204">Dietrich Klakow</sample>
    <sample id="205">Ja, EDAtt passt zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="206">Die Anzahl der Autoren, die an der Arbeit beteiligt sind, beträgt 4.</sample>
    <sample id="207">Yes, the model works in the testsuite.</sample>
    <sample id="208">The three variants of KITMUS are Background-Pretrain, Background-Both, and Background-Inference.</sample>
    <sample id="209">Die Autoren gehören an der University of Edinburgh.</sample>
    <sample id="210">Wie können die verfügbaren sauberen Proben effizienter verwendet werden?</sample>
    <sample id="211">Die Sensitivitätsmetrik misst die Abhängigkeit des Modells von verschiedenen Anweisungen für dieselbe Aufgabe.</sample>
    <sample id="212">The image shows a presentation slide with the title "Are You Copying My Model? Protecting Backdoor Watermark of Large Language Models via EaaS" and lists several authors. The authors are associated with institutions such as the University of Science and Technology of China, Microsoft Research Asia, and Beijing Haotong University. At the bottom right corner of the slide, there is a photo of a person who appears to be the presenter.

**Reasoning Process:**
1. Identify the context of the image: It is a presentation slide.
2. Locate the presenter's photo: It is in the bottom right corner.
3. Determine the name of the presenter: The name is visible next to the photo.

**Answer:**
The presenter's name is Wenjun Peng.</sample>
    <sample id="213">Eine höhere Sensitivität ist ein schlechterer Modell-Leistungsparameter.</sample>
    <sample id="214">Die Modelle erhalten während des Pre-Trainings standardisierte Kontexte.</sample>
    <sample id="215">Um eine gute Leistung an der WSL zu erreichen, benötigen Sie normalerweise mehr als 50 saubere Validierungsbeispiele.</sample>
    <sample id="216">Stanford University</sample>
    <sample id="217">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, um die Bedeutung der verschiedenen Aspekte zu messen und zu verstehen.</sample>
    <sample id="218">The answer is Jackie CK Cheung.</sample>
    <sample id="219">Die Pipeline ist in der Figur 1 dargestellt.</sample>
    <sample id="220">Ja, sie unterscheiden sich.</sample>
    <sample id="221">Ja, Coscript ist öffentlich verfügbar.</sample>
    <sample id="222">Das Wasserzeichen wird in den Text über einen Prozess eingebettet, der die ursprünglichen Eingaben mit einem Schlüsselwort (Trigger) multipliziert und dann normalisiert.</sample>
    <sample id="223">Die Autoren gehören an PennState und Amazon.</sample>
    <sample id="224">Ja, sie können durch Training in einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="225">Ein Beispiel für eingeschränkte Sprachplanung ist die Erstellung von Rezepten, bei denen bestimmte Zutaten wie Erdbeere oder Schokolade hinzugefügt werden.</sample>
    <sample id="226">Sie können die Opazität sicherstellen, indem sie die Farbintensität reduzieren.</sample>
    <sample id="227">Die Arbeit nutzt bestehende PLMs, um ein neues PLM aufzubauen.</sample>
    <sample id="228">GPT-4 least aligns with the Confucian culture.</sample>
    <sample id="229" />
    <sample id="230">The number of tasks has a significant impact on the performance of the model.</sample>
    <sample id="231">LSTM seq2seq, Tree, Zhang and Lapata</sample>
    <sample id="232">Die beiden Co-Autoren stehen dem ersten Autor als Kollegen in Beziehung.</sample>
    <sample id="233">Chowdery et al. 2022</sample>
    <sample id="234">NLPositionality: Characterizing Design Biases of Datasets and Models

Die Präsentation, die auf dem Bild dargestellt wird, zielt darauf ab, die Rolle von Positionalität in der natürlichen Sprache (NL) und wie sie die Designbiases von Datensätzen und Modellen beeinflussen kann. Hier ist eine detaillierte deutsche Übersetzung des englischen Textes:

- **Sebastin Sany**, Universidad de Washington: Sebastin Sany ist ein Vertreter der Universidad de Washington und bringt seine Expertise in Bezug auf die Analyse und Charakterisierung von Designbiases in Datensätzen und Modellen.
  
- **Jenny T. Liang**, Carnegie Mellon University: Jenny T. Liang, Vertreterin von Carnegie Mellon University, befasst sich mit den Aspekten der Positionalität in NL und wie sie die Leistung und Fairness von Modellen beeinflussen können.

- **Ronal Le Bras**, Allen Institute for AI: Ronal Le Bras, Vertreter des Allen Institute for AI, bringt seine Kenntnisse in die Welt der maschinellen Lernmodelle und ihre Anwendung auf Datensätze mit Positionalität.

- **Katharina Reinecke**, University of Washington: Katharina Reinecke, Vertreterin der Universidad de Washington, diskutiert die Auswirkungen von Positionalität auf die Genauigkeit und die Fairness von NL-Modellen.

- **Maarten Sap**, Carnegie Mellon University: Maarten Sap, Vertreter von Carnegie Mellon University, bringt seine Erfahrungen in Bezug auf die Evaluierung und die Verbesserung von NL-Modellen mit Positionalität.

Die Präsentation legt großen Wert auf die Bedeutung von Positionalität in der Analyse und Optimierung von Datensätzen und Modellen, um sicherzustellen, dass sie fair und präzise sind.</sample>
    <sample id="235">NLPositionality: Characterizing Design Biases of Datasets and Models

Sebastin Sany, University of Washington
Jenny T. Liang, Carnegie Mellon University
Ronan Le Bras, Allen Institute for AI
Katharina Reinecke, University of Washington
Maarten Sap, Carnegie Mellon University</sample>
    <sample id="236">Imagine...</sample>
    <sample id="237">Dieses Video zeigt Ihnen, wie Sie ein Spiel in Unity erstellen können.</sample>
    <sample id="238">Kannst du aufhören, ein Arroganter zu sein?</sample>
    <sample id="239">Design bias Beispiel! Kannst du aufhören, ein Arroganter zu sein? (0,82) Pressetitlese überall im News: (0,33) Carl Jones Tech Lead New York Times Aditya Sharma Tech Lead Times of India</sample>
    <sample id="240">[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Routledge (2013).</sample>
    <sample id="241">Die Positioniertheit ist die Perspektive, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen halten.</sample>
    <sample id="242">Die Positionierungen sind die Perspektiven, die Menschen aufgrund ihrer Demografien, Identität und Lebenserfahrungen halten.</sample>
    <sample id="243">Do datasets and models have positionality?</sample>
    <sample id="244">Do datasets and models have positionality?</sample>
    <sample id="245">Do datasets and models have positionality? 1) Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022. 2) Nallat, et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022. 3) Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." 2022.</sample>
    <sample id="246">Ob Datensätze und Modelle Positionalität aufweisen?</sample>
    <sample id="247">Anecdotal evidence:

- Model and dataset probing [11, 2]
- Theoretical definitions of model positionality [3]

Bibliography:
[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Cohan, et al. "GEOMLLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." 2022.</sample>
    <sample id="248">Anecdotal evidence:

- Model and dataset probing [112]
- Theoretical definitions of model positionality [3]

Bibliography:
[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Chen, et al. "GEOMLLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." Data Science 2022.</sample>
    <sample id="249">Frage: Haben Datensätze und Modelle Positionalität?</sample>
    <sample id="250">NLPositionality: Ein Rahmen zur Charakterisierung von Design-Störungen in NLP-Datasets und Modellen</sample>
    <sample id="251">Die Grafik zeigt den Prozess der Datenermittlung und Annotation. Es beginnt mit einer Sammelphase, in der ein Datensatz selektiert wird. Jede Instanz im Datensatz wird dann anhand von Modellvorhersagen kategorisiert. Anschließend werden die erhaltenen Annotierungen überprüft. Wenn die Annotierungen mit den gold labels vom Modell abweichen, werden sie korrigiert. Schließlich wird die Verteilung der Demographen gemessen und visualisiert.</sample>
    <sample id="252">The image depicts a framework for processing and analyzing datasets. The framework is divided into several stages, including data collection, annotation, and model training. Here's a detailed description of the framework:

1. **Data Collection**: This stage involves sampling data from a dataset. The data includes various attributes such as age, gender, education level, and country. Each attribute is represented by a bar chart showing the distribution of values.

2. **Annotation**: In this stage, each instance in the dataset is annotated with labels. The annotations are performed by different annotators, as indicated by the three different sets of labels (e.g., "Eating with Hands," "Can you live without it?," and "Steel"). The annotations are then compared to determine their diversity.

3. **Model Training**: After the annotations are collected, they are used to train a model. The model predictions are shown on the left side of the diagram, indicating the output of the model based on the input data.

4. **Post-processing**: The final stage involves post-processing the model outputs. This includes measuring Pearson’s correlation between the gold labels (ground truth) and the observed labels from the models. The results are shown in a table format, with columns representing different attributes and rows representing different models.

The framework aims to ensure that the annotations are diverse and accurate, which helps in training a robust model. The use of multiple annotators and the comparison of their annotations help in identifying and correcting any biases or inconsistencies in the data.</sample>
    <sample id="253">Das Framework, das in der Grafik dargestellt wird, zeigt einen Prozess an, bei dem Datensätze von einer Sammelstelle abgeleitet werden und dann über ein Modell verarbeitet werden. Der Prozess beginnt damit, Datensätze zu sammeln, die dann als Trainingsdaten für ein Modell verwendet werden. Das Modell macht Vorhersagen, und dieannotierer erhalten die vorhergesehnten Instanzen. Anschließend werden dieAnnotations von den annotatoren erhalten, die dann mit den Gold labels vom Modell verglichen werden. Schließlich wird Pearson’s R²-Coeffizient verwendet, um die Demographen von dem Datensatz zu trennen.</sample>
    <sample id="254">Das Framework, das in der Grafik dargestellt wird, zeigt den Prozess der Datensammlung und -verarbeitung an. Es beginnt mit der Sammlung von Daten, die dann in einem Modell verwendet werden, um Vorhersagen zu treffen. Anschliessend werden die erhaltenen Vorhersagen mit den ursprünglichen Gold-Labels verglichen, um die Genauigkeit des Modells zu messen. Der Prozess endet mit einer Messung der Demographenachteilung, indem die Abweichungen zwischen den Vorhersagen und den Gold-Labels gemessen werden.</sample>
    <sample id="255">Die Grafik zeigt einen Prozess, der eine Sammlung von Datensätzen verwendet, um Modelvorhersagen zu erstellen. Jede Instanz im Datensatz wird mit einer Vorhersage versehen, und die Instanzen werden als "Eating with Hands" und "It's Morale" gekennzeichnet. Anschließend werden die erhaltenen Annotierungen mit den Vorhersagen verglichen, um Pearson’s R-Scores zu erhalten.</sample>
    <sample id="256">Die Grafik zeigt einen Prozess, der eine Sammlung von Datensätzen und eine Verarbeitungsstelle umfasst. In der Sammlung werden Datensätze in verschiedenen Kategorien sortiert, wie zum Beispiel "Eating with Hands" und "It's normal". Jede Instanz im Datensatz wird dann anhand von Modellvorhersagen sortiert, und die erhaltenen Annotierungen werden verwendet, um die Gold-Labels zu bestimmen. Schließlich werden die Pearson's R-Scores verglichen, um die Demographen des Datensatzes mit den Modellvorhersagen zu vergleichen.</sample>
    <sample id="257">Könntet ihr mit einem AI und seinen Worten umgehen? Welche Rolle spielen sie in eurem Leben? Welche Art von AI seid ihr? Welche Rolle spielen sie in eurem Leben? Welche Rolle spielen sie in eurem Leben?</sample>
    <sample id="258">Where are you on the techno-utopian scale? Tell us how you feel about future mixed reality, steampunk or techno-utopia.</sample>
    <sample id="259">Task A: Soziale Akzeptabilität

1. Lese die Situation.
2. Gib an, was du darüber denkst.
3. Sei wie ein AI spezialisiert.

Die AI spezialisiert sich auf die Verständlichkeit.</sample>
    <sample id="260">Task A: Soziale Akzeptabilität 1) Lese die Situation. 2) Stelle fest, was du darüber denkst. 3) Sei dir bewusst, was andere darüber denken.</sample>
    <sample id="261">Task A: Soziale Akzeptabilität

Analyse

Datasets
- Soziale Chemie

Models
- Delphi
- GPT-4</sample>
    <sample id="262">Task B: Gifttoxizität

1. Lese das Beispiel.
2. Gib an, ob du den Satz für schlimm oder nicht schlimm hältst.
3. Sieh dir die Meinungen anderer an.

Das AI-Statistiker spekuliert, dass es gifttoxisch ist.</sample>
    <sample id="263">Task B: Toxicity

Datasets
- Dynahate

Models
- Perspective API
- Rewire API
- State RoBERTa
- GPT-4</sample>
    <sample id="264">Wer alignen NLP-Datasets und Modelle?</sample>
    <sample id="265">Datasets und Modelle sind am besten auf englischsprachige Länderschaften ausgerichtet.</sample>
    <sample id="266">Datasets und Modelle sind am besten auf Menschen ausgerichtet, die eine Hochschulbildung haben.</sample>
    <sample id="267">Datasets und Modelle sind am besten auf Menschen ausgerichtet, die eine Universitätsausbildung erhalten haben.</sample>
    <sample id="268">Finding 2: Ein paar Gruppen werden zurückgelassen.</sample>
    <sample id="269">Datasets und Modelle sind weniger auf nicht-binäre Menschen ausgerichtet.</sample>
    <sample id="270">So, was können wir tun? Wie können wir Positionalität in NLP adressieren?</sample>
    <sample id="271">Empfehlungen</sample>
    <sample id="272">Empfehlungen

1. Führe eine Aufzeichnung aller relevanten Designentscheidungen während der Bau von Datensätzen und Modellen.
2. Führe NLP-Forschung durch die Brille der Perspektivismus:
a. Teile aggregierte Datensatzlabels
b. Verwende Modelltechniken, die die Annotator Disagreement bewältigen.
3. Das Aufbau von spezialisierten Datensätzen und Modellen für bestimmte Gemeinschaften ist für inklusive NLP (z.B. Masakhane-Initiative) erfüllbar.


[1] https://www.masakhane.io</sample>
    <sample id="273">Das Bild zeigt einen-slide-Presentation mit dem Titel "Thanks!" im oberen linken Teil. Darunter sind zwei URLs aufgelistet: "Dashboard Link: nlpertility.cs.washington.edu/" und "Paper: bit.ly/NLPositionality-Paper/". Im unteren Teil des Bildes sind mehrere Balkendiagramme dargestellt, die verschiedene Kategorien wie Alter, Geschlecht, Ethnoität, Religion, Bildungsebene, Landansiedlung (Country of Residence), Land (Country) und Muttersprache (Native Language) anzeigen. Jede Kategorie ist in einem separaten Balkendiagramm dargestellt, und die Farben variieren von Blau über Grün bis Braun.</sample>
    <sample id="274">Die Referentin spricht von mehreren Problemen von SimulST.</sample>
    <sample id="275">Soziale und politische Verzerrungen in Datensätzen beim Training von NLP-Modellen können effektiv reduziert werden, indem man die Datensammlung und -bearbeitung überwacht, diverse Datensätze verwendet und die Modelltrainingsschritte sorgfältig überprüft wird.</sample>
    <sample id="276">The 61st Annual Meeting of the Association for Computational Linguistics Toronto, Canada June 13-14, 2023 Distilling Script Knowledge from Large Language Models for Constrained Language Planning Siliu Yuan, Jianqiang Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang Peking University Brain Technologies Inc.</sample>
    <sample id="277">Wie man einen Kuchen macht? 1. GATHER YOUR INGREDIENTS. 2. PREHEAT THE OVEN TO 325 °F (163 °C) AND GREASE A CAKE PAN. 3. CREAM THE BUTTER AND SUGAR. 4. ADD THE EGGS. 5. STIR IN THE CAKE FLOUR. 6. POUR THE BATTER INTO THE PAN. 7. BAKE THE CAKE FOR 1 HOUR 15 MINUTES.</sample>
    <sample id="278">Wie man einen Kuchen macht?

1. GATHER YOUR INGREDIENTS?
2. PREHEAT THE OVEN TO 325°F (163 °C) AND GREASE A CAKE PAN.
3. CREAM THE BUTTER AND SUGAR.
4. ADD THE EGGS.
5. STRIR IN THE CAKE FLOUR.
6. POUR THE BATTER INTO THE PAN.
7. BAKE FOR 1 HOUR 15 MINUTES.</sample>
    <sample id="279">Constrained Language Planning

Wie man einen Erdbeerkuchen macht?
...und wie man die Erdbeermarmelade in die Mehlmaske misst...

Wie man einen Schokoladenkuchen macht?
...und wie man den Schokoladepulver in die Mehlmaske misst...

Das gemeinsame Ziel kann von verschiedenen realen Leben spezifischen Zielen mit mehreren Facetten abhängig machen.</sample>
    <sample id="280">Constrained Language Planning

How to Make a Strawberry Cake?
...Add strawberry jams into the flour...

How to Make a Chocolate Cake?
...Add cocoa powder into the flour...

Specific goal can be inherited by different real-life specific goals with multi-faceted constraints</sample>
    <sample id="281">Constrained Language Planning

How to Make a Strawberry Cake?
...Add strawberry jams into the flour...

How to Make a Chocolate Cake?
...Add cocoa powder into the flour...

Specific goal can be inherited by different real-life specific goals with multi-faceted constraints</sample>
    <sample id="282">LLMs auf die Leitstelle von eingeschränktem Sprachplanung</sample>
    <sample id="283">LLMs auf die Leitstelle einschränkende Sprachplanung perforieren?</sample>
    <sample id="284">LLMs auf die Leitstelle der Sprachplanung: Dataset: wikiHow + generierte Beschränkungen

Definition: Modifizierer
- Definition: Eine Eigenschaft oder ein Modus, der modifiziert und/or einen abstrakten Ziel einschränkt.
  - Beispiele:
    - Erstelle einen Chocolatencake.
    - Erstelle einen pinken Cakereis.

Definition: Methode
- Definition: Ein Werkzeug oder ein bestimmter Modus, der die Prozedur bestimmt, wie eine Aufgabe erfüllt wird.
  - Beispiele:
    - Erstelle einen Cakereis mit einem Ofen.
    - Erstelle einen Cakereis mit einem Mikrowellenofen.

Definition: Intention
- Definition: Eine zusätzliche Absicht oder ein Anlass, wenn ein Ziel erreicht wird.
  - Beispiele:
    - Erstelle einen Cakereis für ein Hochzeitsschneiderei.
    - Erstelle einen Cakereis mit Diabetikerzucker.</sample>
    <sample id="285">Kannen LLMs die Sprachplanung einschränken?

Die Grafik zeigt die Genauigkeit verschiedener Sprachmodelle (LLMs) bei der Planung für bestimmte Ziele. Die Modelle werden mit unterschiedlichen Modellgrößen und Typen bezeichnet: TS (11B), Flan-T5 (11B), GPT-3 (17B), Codex (17B) und InstructGPT (175B). 

TS (11B) erreicht dieloweste Genauigkeit, während GPT-3 (17B) diehigheste Genauigkeit erreicht. Flan-T5 (11B) und Codex (17B) liegen in zwischen.

Unter dem Titel "All baselines achieve unsatisfactory results on planning for specific goals" wird verdeutlicht, dass alle Modelle Schwierigkeiten beim Erreichen spezifischer Ziele haben.</sample>
    <sample id="286">Kannen LLMs die planerische Sprache einschränken?

Die Grafik zeigt die Genauigkeit verschiedener Sprachmodelle bei der planerischen Spracheinschränkung. Das Modell "TS (11B)" erreicht eine Genauigkeit von 20%, das Modell "Flan-T5 (11B)" erreicht eine Genauigkeit von 40%, das Modell "GPT-3 (17B)" erreicht eine Genauigkeit von 60% und das Modell "InstructGPT (175B)" erreicht eine Genauigkeit von 80%. Die Baselinien erzielen unzufriedenstellende Ergebnisse beim Planieren für bestimmte Ziele.</sample>
    <sample id="287">Welche Art von Fehlern machen LLMs in dieser Aufgabe normalerweise?</sample>
    <sample id="288">Welche Art von Fehlern machen LLMS in dieser Aufgabe normalerweise?</sample>
    <sample id="289">Wasarten von Zielen, bei denen InstructGPT normalerweise versagt?</sample>
    <sample id="290">Input: eine abstrakte Aufgabe

Schritt 1: Generiere spezifische Ziele mit der Hilfe von GPT-4.0 und in-kontext-Learning.

Abstrakte Aufgabe: Mach ein Kuchen

Spezifische Ziele:

G1 (+Modifikator): Mach einen Schokoladenkuchen
G2 (+Modifikator): Mach einen Kuchen in einer bestimmten Art und Weise
G3 (+Intention): Mach einen Kuchen für eine Hochzeit</sample>
    <sample id="291">Input: ein abstraktes Modell
Schritt 1: Generieren von spezifischen Zielen mit der Hilfe von GPT-3
Abstraktes Ziel: Machen eines Cakes unter bestimmten Bedingungen.
Spezifische Ziele:
G1 (Modifikator): Machen eines Schokoladen-Cakes unter bestimmten Bedingungen.
G2 (Modifikator): Machen eines Cakes in einer bestimmten Art und Weise.
G3 (Intention): Machen eines Cakes für eine bestimmte Gelegenheit.</sample>
    <sample id="292">Input: Ein abstraktes Ziel
Schritt 1: Generiere spezifische Ziele
Schritt 2: Über-Generiere kandidierte Skripte mit Lernerfolgen
Abstraktes Ziel: Mach ein Kuchen
Spezifische Ziele:
G1 (+Modifikator): Mach einen Schokoladenkuchen
G2 (+Methode): Mach einen Kuchen in einem Ofen
G3 (+Intention): Mach einen Kuchen für eine Hochzeit
Kandidatenskripte
1. 2. 3. ...k</sample>
    <sample id="293">Die Grafik zeigt einen Prozess, der zwei Schritte umfasst. Der erste Schritt beinhaltet die Erstellung von Kandidatskripten mithilfe von InstructGPT via in-kontext learning. Hier werden mehrere Skriptschwierigkeiten (1, 2, 3, usw.) generiert und dann anhand von Ähnlichkeits得分 (0,3; 0,5; 0,7) filtriert. Das filtrierte Skript (Script 3) wird dann verwendet, um spezifische Ziele zu erreichen, indem z.B. Gewürze zubereiten und Zuckerschwefel hinzufügen. Das Ausgangssignal ist das Erreichen bestimmter Ziele mit entsprechenden Skripten.</sample>
    <sample id="294">Die Grafik zeigt einen Prozess, der als "Methode" bezeichnet wird. Der Prozess beginnt mit dem "Over-generate candidate scripts with InstructGPT via in-context learning". Hier werden mehrere Skriptschritte (1, 2, 3, usw.) generiert. Jeder Schritt wird dann mit "InstructGPT via similarity score" überprüft, um festzustellen, ob er relevant ist. Die Schritte mit einem roten X markieren werden ignoriert, während die Schritte mit einem roten Häkchen akzeptiert werden. Das endgültige Output sind spezifische Ziele mit entsprechenden Skriptschritten.</sample>
    <sample id="295">Die Grafik zeigt einen Prozess, der als "Methode" bezeichnet wird. Der Prozess beginnt mit einer Schritt-für-Schritt-Generierung von Kandidaten-Skripten mit InstructGPT via in-kontext learning (IKCL). Danach werden die Skripte überprüft und diejenigen, die den Zielscore erreichen, filtriert. Das filtrierte Skript wird dann verwendet, um spezifische Ziele zu erreichen, indem z.B. Gewürze zubereiten und Zuckerschwärze hinzufügen.</sample>
    <sample id="296">Unser Verfahren verbessert die Planqualität erheblich.</sample>
    <sample id="297">Script Distillation from LLMs

Motivation:
- Enable constrained language planning for smaller models.
- Follow the idea of symbolic knowledge distillation.

Method:
- Generate 55,000 scripts with constraint from LLMs based on the method.
- Use the Constraint Dataset for validation and test set.

Steps:
1. Generate abstracts with InstructGPT via in-context learning.
2. Over-generate candidate scripts with InstructGPT via context learning.
3. Find the best script to the abstract using InstructGPT via similarity score.

Output:
- Specific goals with corresponding plans.</sample>
    <sample id="298">Script Distillation from LLMs

Motivation:
- Enable constrained language models for smaller models.
- Follow the idea of symbolic knowledge distillation.
- Generate 55.000 scripts based on constraint from LLMs using a method that involves annotating validation and test set.

Method:
1. Generate abstracts with InstructGPT via in-context learning.
2. Over-generate candidate scripts with InstructGPT via context learning.
3. Find and filter specific goals with InstructGPT via similarity score.

Output:
- Specific goals with corresponding plans.</sample>
    <sample id="299">Script Distillation from LLMs

Motivation:
- Enable constrained language planning ability for smaller models.
- Follow the idea of symbolic knowledge distillation.
- Generate 55,000 scripts constraint from LLMs based on a method that involves annotating validation and test sets.

Method:
1. Generate abstracts with InstructGPT via in-context learning.
2. Over-generate candidate scripts with InstructGPT via context learning.
3. Find the best scripts by filtering them with InstructGPT via similarity score.

Output:
- Specific goals with corresponding plans.</sample>
    <sample id="300">Motivation: Das Hauptmotiv der Script-Distillation ist die Entwicklung von einschränkungsfähigen Sprachmodellen (LLMs) für kleinere Modelle. Eine Art symbolisches Wissensdistillieren wird verwendet, um 55.000 Skriptskripte zu generieren, die auf einem Datensatz basieren, der auf einem spezifischen Verhältnis von LLMs und Skriptskripte abzielt.

Methode: Die Methode beinhaltet die Anwendung des Wissensdistillierens auf LLMs, um 55.000 Skriptskripte zu generieren. Eine Validierungs- und Testmenge wird verwendet, um die Effektivität der Methode zu überprüfen.

Schritte:
1. Generieren von Abstrakten mit InstructGPT via in-context learning.
2. Erzeugen von Kandidatskripts mit InstructGPT in Kontext.
3. Finden und filtern der besten Skriptskripte mit InstructGPT via Ähnlichkeits得分.

Ausgabe: Spezifische Ziele mit entsprechenden Plänen werden definiert.</sample>
    <sample id="301">Script Distillation from LLMs

Motivation:
Das Hauptmotiv dieser Studie ist es, die einschränkende Fähigkeit von Sprachmodellen zu verbessern, indem sie auf kleinere Modelle reduziert werden. Das Ziel ist es, die Sprachgenerationsfähigkeit zu erhalten, ohne die Komplexität der vollständigen Modellstruktur zu behalten.

Method:
Die Methode zur Reduzierung der Sprachgenerationsfähigkeit basiert auf dem Begriff "symbolic knowledge distillation". Sie zielt darauf ab, 55.000 Skriptsamples mit bestimmten Einschränkungen zu generieren, die auf einem Datensatz basieren. Um die Qualität der generierten Skripts zu überprüfen, wird eine Annotier- und Testmenge verwendet.

Steps:
1. Generate abstracts with InstructGPT via in-context learning
2. Over-generate candidate scripts with InstructGPT in context
3. Find and filter scripts to the best ones with InstructGPT via similarity score

Output:
Die endgültige Ausgabe sind spezifische Ziele mit entsprechenden Plänen.</sample>
    <sample id="302">Die Grafik zeigt die Häufigkeit von differentiativen Elementen in der Sprache.</sample>
    <sample id="303">Spezialisierte Modelle vs. LLMs

Die Grafik zeigt die Genauigkeit verschiedener Sprachmodelle, darunter GPT-3 (175B), Codex (175B), InstructGPT (175B) und T5 trainiert auf Coreset, in Bezug auf die Erstellung von Skripten. Es wird erwähnt, dass kleinere LLMs, die speziell auf Coreset optimiert wurden, besser als große LLMs in der Erstellung qualitativ hochwertiger Skripte sind.

Die Grafik zeigt, dass die Genauigkeit der verschiedenen Modelle variiert. GPT-3 (175B) und Codex (175B) erreichen die höchste Genauigkeit, gefolgt von InstructGPT (175B) und T5 trainiert auf Coreset. Es wird auch erwähnt, dass kleinere LLMs, die speziell auf Coreset optimiert wurden, besser als große LLMs in der Erstellung qualitativ hochwertiger Skripte sind.</sample>
    <sample id="304">Zusammenfassung und Kernpunkte

- Etablieren des einschränkenden Sprachplanproblems.
- Evaluieren der einschränkenden Sprachplanfähigkeit von LLMs (Large Language Models) und Entwicklung eines "Over-Generate-Dann-Filtern"-Verfahrens für LLMs.
- Verwenden von LLMs zur Generierung eines hohen-Qualitäts-Skriptdatensatzes (CoScript) für einschränkende Sprachplanung.
- Grenzgebiet und zukünftige Arbeiten:
  - Das vorgeschlagene Verfahren zur Verbesserung von LLMs ist ein "Nach-Ranken"- Ansatz.
  - CoScript erbt nur von einem abstrakten Modell mit einem einzigen einschränkenden Constraint.
- Der CoScript-Datensatz kann eine wertvolle Ressource für die Forschung über Sprachplanung mit komplexeren und vielfältigen Zielen und Einschränkungen sein.</sample>
    <sample id="305">Eine prägnante Übersicht der Fortschritte im Bereich Sprachgenerierung und Sprachplanung. Die Folie zeigt einen Überblick über die verschiedenen Aspekte, die in der Forschung betrachtet wurden, einschließlich die Evaluierung der Sprachgenerierfähigkeit von Sprachgenerationsmodellen (LLMs) unter bestimmten Bedingungen und die Entwicklung von Methoden zur Filterung von überflüssigen Ausdrücken. Es wird auch auf die Grenzen und zukünftige Arbeiten hinweisen, um die Leistung von LLMs zu verbessern.</sample>
    <sample id="306">Die 61. jährliche Versammlung der Gesellschaft für Computergestützte Linguistik (ACL) fand vom 11. bis 14. September 2023 in Toronto, Kanada statt. Das Hauptthema der Präsentation war "Ernte von Skriptkenntnis aus großen Sprachmodellen für eingeschränktes Sprachplanieren". Die Präsentation wurde von Suiyuan Yuan und Kolleginnen und Kollegen vorgeführt und ihre Kontakte sind im Text abrufbar.</sample>
    <sample id="307">Die Sprachgewandtheit von PaLM ist vergleichbar mit den besten Systemen.</sample>
    <sample id="308">Die wichtigsten Eigenschaften eines Wasserzeichenverfahrens sind: Anwendbarkeit auf EaaS, Nutzen, Covetness und Transferability.</sample>
    <sample id="309">Die englischen TED Talks wurden in 14 Sprachen übersetzt.</sample>
    <sample id="310">Eine Gruppe von Instanzen wird aus einem Datensatz für die erneute Annotierung extrahiert.</sample>
    <sample id="311">Die Distanzmetriken, die verwendet werden, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen, sind die Cosinusdistanz und die Manhattan-Distanz.</sample>
    <sample id="312">Modelle, die auf einem mehrsprachigen Encoder basieren, wurden in der Aufgabe eingesetzt, um die Leistung von Modellen mit monolinguen Encoders zu überprüfen.</sample>
    <sample id="344">Die Autoren zählen die Häufigkeit jedes Wortes auf einem allgemeinen Textkorpus und then randomly selecten n Wörter in einem mittleren Häufigkeitsintervall.</sample>
    <sample id="345">Do CoNLL-2003 Named Entity Taggers Noch Gut in 2023?

Shuheng Liu, Alan Ritter
Schule für interaktive Computern, Georgia-Institut für Technologie</sample>
    <sample id="346">Named Entity Recognition &amp;amp; Generalization</sample>
    <sample id="347">Named Entity Recognition &amp; Generalization • Models have been using CoNLL-2003 to develop NER for almost 20 years</sample>
    <sample id="348">Named Entity Recognition &amp; Generalization

• Modelle haben seit fast 20 Jahren CoNLL-2003 verwendet, um NER zu entwickeln
• Können diese Modelle auf modernes Data übertragen?
• Was wird benötigt, um gute Generalisierbarkeit zu erreichen?</sample>
    <sample id="349">Named Entity Recognition &amp; Generalization

• Modelle haben seit fast 20 Jahren CoNLL-2003 verwendet, um NER zu entwickeln
• Können diese Modelle auf moderne Daten übertragen?
• Was wird benötigt, um eine gute Übertragung zu gewährleisten?</sample>
    <sample id="350">ConLL+ Dataset AMBASSADOR O UNITED O NATIONS O LINDA I-PER THOMAS-GREENFIELD I-PER</sample>
    <sample id="351">CoNLL+ Datensatz • Reuters-News von 2020 sammelte und mit CoNLL-2003 Annotierungsanweisungen annotiert wurde • 20+ Modelle auf CoNLL-2003 einstellt

Ambassador O O United O O Nations O Linda I-PER Thomas-Greenfield I-PER</sample>
    <sample id="352">CoNLL++ Dataset • Sammelte Reuters-News von 2020 und annotierte sie mit den Annotieranweisungen von CoNLL-2003 • 20+ Modelle wurden auf CoNLL-2003 einstellt • Evaluiert wurde auf dem Testset von CoNLL-2003 und CoNLL++ • Das Generalisierungsmaß ΔF1 wurde berechnet • Ambeassador United Nations Linda Thomas-Greenfield O-ORG I-PER</sample>
    <sample id="353">Was wird benötigt, um gute allgemeine Anpassung zu erreichen?</sample>
    <sample id="354">Was wird benötigt, um gute allgemeine Anpassung zu erreichen? • Modellarchitektur • Transformer-Modelle allgemein besser abschätzen können

Die Grafik zeigt die Beziehung zwischen den F-Scores von CoNLL-2009 und CoNLL-2012 auf der x- und y-Achse. Es zeigt auch, dass Transformer-Modelle in der Regel bessere allgemeine Anpassung aufweisen als andere Modelle.</sample>
    <sample id="355">Was wird benötigt, um eine gute Generalisierbarkeit zu erreichen? • Modellarchitektur • Transformer-Modelle generalisieren besser • Größere Modelle generalisieren besser Modellarchitektur BERT Large Roberta Large T5 Large BERT Base ALBERT Large ALBERT Base T5 Base T5 Small # of Parameters (log10) AP F1 (%) 10^-4 10^0 10^2 10^4</sample>
    <sample id="356">Was wird benötigt, um eine gute Generalisierbarkeit zu erreichen? • Modellarchitektur • Transformer-Modelle generalisieren besser • Größere Modelle generalisieren besser • Anzahl der fine-tuning-Beispiele • Mehr Beispiele führt zu besseren Generalisierungen AFL (F1-Score) 1 0.5 0 -0.5 -1 -1.5 -2 -2.5 -3 -3.5 -4 -4.5 -5 -5.5 -6 -6.5 -7 -7.5 -8 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% RoBERTa Flair</sample>
    <sample id="357">Was bewirkt eine Leistungsreduktion?</sample>
    <sample id="358">Was verursacht einen Leistungsverlust?</sample>
    <sample id="359">Was verursacht eine Leistungsabnahme? • Adaptive Overfitting? • Temporal Drift?</sample>
    <sample id="360">Was verursacht eine Leistungsinkarnation? • Adaptive Overfitting? • Temporale Drift?</sample>
    <sample id="361">Was bewirkt einen Leistungsverlust? • Adaptive Übertaktung? • Temporale Drift?</sample>
    <sample id="362">Was verursacht eine Leistungsinkraft? • Adaptive Overfitting? • Keine abnehmenden Gewinne • Unbeobachteter Temporaldrift?</sample>
    <sample id="363">Was verursacht einen Leistungsverlust? • Adaptive Übertaktung? • Keine abnehmenden Gewinne • Keine beobachtet • Temporale Drift?</sample>
    <sample id="364">Was bewirkt einen Leistungsverlust? • Adaptive Übertaktung? • Keine beobachteten Rückgewinnungen • Temporale Drift? Name CoNLL-2003 CoNLL++ (AF) Flat 92.26% 88.45% Flair 90.91% 84.63% Pooled Flair 93.15% 88.26% Pooled Flair+ 92.36% 87.08% ELMo 92.11% 90.75% L MoRn 92.11% 90.75% -1.43</sample>
    <sample id="365">Was bewirkt einen Leistungsverlust? • Adaptive Übertrennung? • Keine beobachteten Rückgewinn • Temporale Drift? • Leistungen degradieren mit einem größeren zeitlichen Abstand Name CoNLL-2003 CoNLL++ Af ( % ) Flat 92.26,91.75 88.46 -2.69 Flair 90.91,91.23 88.46 -2.69 Pooled Flair 93.15,93.24 88.20 -4.65 Pooled Flair+Plugs 92.36,92.49 87.09 -5.72 ELMO 92.11,91.90 90.76 -1.43</sample>
    <sample id="366">Schlussfolgerung: Um ein gutes Generalisierungsmodell zu erhalten, benötigen wir: - Bessere Modellarchitektur - Größere Modellgröße - Mehr fine-tuning-Beispiele 95 Illinois NER Flair BILSTM-CNN-CRF BERT-Large 90 Stanford NLP 85 2004 2008 2012 2016 2018 2022</sample>
    <sample id="367">Schlussfolgerung
Für eine gute Generalisierbarkeit benötigen wir:
- Bessere Modellarchitektur
- Größere Modellgröße
- Mehr einstelle optimierter Beispiele

Performance-Abnahme wird durch:
- Temporale Drift
- Nade adaptive Übertaktung

Die Grafik zeigt die Entwicklung der Performance von verschiedenen Modellen im Bereich Natural Language Processing (NLP) über die Jahre hinweg. Es zeigt, dass die Performance der Modelle allgemein steigt, aber es gibt auch Momente, in denen die Performance abnimmt.</sample>
    <sample id="368">Schlussfolgerung
Für eine gute Generalisierbarkeit benötigen wir:
- Bessere Modellarchitektur
- Größere Modellgröße
- Mehr fine-tuning Beispiele

Performance-Abnahme wird durch:
- Adäquate Obergrenze
- Temporale Drift

Wie weiterhin die ConLL-2003-Tagger arbeiten?</sample>
    <sample id="369">Schlussfolgerung
Um eine gute Generalisierbarkeit zu erreichen, benötigen wir:
- Bessere Modellgroesse
- Größere Modellgröße
- Mehr fine-tuning Beispiele
- Performance-Abnahme Ursachen:
- Temporale Drift
- NAO adaptive Übergreifung
- Noch ConLL-2003 Tagger arbeiten?
- JA</sample>
    <sample id="370">Paper: https://arxiv.org/abs/2212.09747 Dataset: https://github.com/ShuhanL/acl2023-conllpp Contact: slu775@gatech.edu</sample>
    <sample id="397">Die Sprachsegmentgröße wird auf 10 Millisekunden festgelegt.</sample>
    <sample id="398">Die Beispiele Servin und Kea benötigen spezifisches Wissen über Personen.</sample>
    <sample id="399">Example quality is more important than similarity to source sentence.</sample>
    <sample id="400">The extended experiments focus on the following language models: BERT-base, RoBERTa-base, RoBERTa-large, distilRoBERTa-base, ALBERT-base, ALBERT-large, BART-base, BART-large, and GPT-2.</sample>
    <sample id="401">Das Modell verwendet Aufmerksamkeitswerte aus mehreren Ebenen.</sample>
    <sample id="402">Beispiele für direkte Inferenz sind "the first one", "the one I mentioned earlier" und "the one you pointed out".</sample>
    <sample id="403">The authors belong to Peking University.</sample>
    <sample id="404">There are six authors involved in the work.</sample>
    <sample id="405">Ja, die Übersetzung der natürlichsprachlichen Anfrage mit Hilfe eines maschinellen Übersetzungsmodells wurde als Baseline betrachtet.</sample>
    <sample id="406">A warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="407">Die Grafik zeigt, dass die Modellarchitekturen, die nicht gut generalisieren, in der unteren rechten Ecke liegen.</sample>
    <sample id="408">The test datasets are called FT_w, COSINE, L2R, BFiFit, and AdapterC.</sample>
    <sample id="409">Die Arbeit beteiligen sechs Autoren.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="439">Nach Ansicht der Autoren ist die Integration von externer Kenntnis in NLU ein zu wenig erforschtes Gebiet.</sample>
    <sample id="440">The presenters are Zhiyang Xu, Ying Shen, and Lifu Huang.</sample>
    <sample id="441">Ja, Coscript wurde überprüft.</sample>
    <sample id="442">Die Grenzen bestehender Ressourcen für kontextbasierte Übersetzung liegen in der Unterstützung von limitierter discourse- und Sprachphenomenen.</sample>
    <sample id="443">Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)</sample>
    <sample id="444">Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)</sample>
    <sample id="445">Indirekte Beziehungen

• Gott: Verstehen Sie die Sprache der Benutzer, wenn sie eine Wahl treffen
• Alternative: Fragte ich mich, "Einfach für mich" oder "Ich muss mich fühlen?"
• Direkte Bezug: "Erinnere dich an mich", "Der Erste"
• Indirektes Bezug: Schwierig zu benennen
• Indirektes Bezug: "Die neueren"
• "Die nicht energiegeliche"</sample>
    <sample id="446">Indirekte Beziehungen

Das Ziel: Verstehen der Sprache von Benutzern, wenn sie eine Wahl treffen

Alternatives Beispiel:

Direct Reference: "Die Erste" (The first one)
Indirect Reference: "Die neueren" (The newer one), "Die nicht energiegeliche" (The not energetic one)

Alternative: "Did you mean easy on me or I gotta feeling?"

Die Alternative:

Direct Reference: "Die Erste" (The first one)
Indirect Reference: "Die neueren" (The newer one), "Die nicht energiegeliche" (The not energetic one)

Die Alternative:

Direct Reference: "Die Erste" (The first one)
Indirect Reference: "Die neueren" (The newer one), "Die nicht energiegeliche" (The not energetic one)</sample>
    <sample id="447">Indirekte Beziehungen

Das Ziel: Verstehen Sie, was Benutzer durch ihre Sprache ausdrücken, wenn sie eine Wahl treffen.

Alternative:
- "Did you mean easy on me or I gotta feeling?"
- "The newer one."
- "The song that's not energetic."

Direct Reference:
- "Easy on me."
- "The first one."

Indirect Reference:
- "Cannot remember the name."
- "The pronunciations are hard to distinguish."
- "Want to specify a preference."

Die Alternative zeigt Ihnen, wie Benutzer durch indirekte Beziehungen ihre Meinung zum Ausdruck bringen können.</sample>
    <sample id="448">Indirekte Beziehungen

Ziel: Verstehen Sie, wie Benutzer Sprache verwenden, wenn sie eine Wahl treffen.

Alternative:
- "Did you mean easy on me or I gotta feeling?"

Direct reference:
- "The first one."
- "The newer one."

Indirect reference:
- "The song that's not energetic."

Alternativen:
- "Did you mean easy on me or I gotta feeling?"
- "The newer one."

Die Alternative zeigt, wie Benutzer durch direkte Beziehungen ihre Wahl kennzeichnen können. Indirekte Beziehungen hängen hingegen von Kontext und Verknüpfungen ab, um die Wahl zu kennzeichnen.</sample>
    <sample id="449">Indirekte Beziehungen

Ziel: Verstehen der Sprache von Benutzern, wenn sie eine Wahl treffen

Alternative:
- "Did you mean easy on me or I gotta feeling?"

Direct reference
- "The first one"
- "The newer one"
- "The song that's not energetic"

Indirect reference
- "The first one"
- "The newer one"
- "The song that's not energetic"</sample>
    <sample id="450">Dataset Collection

*   Wichtiges Problem
    *   Conversational Systems
    *   Benchmarking Large Language Models' entity understanding
    *   Kein großes öffentlich zugängliches Datensatz available
*   Wir sammeln einen großen Datensatz mit crowd annotation
*   Drei Domänen:
    *   &lt;img src="head-phones.png" alt="Headphones"&gt;
    *   &lt;img src="books.png" alt="Books"&gt;
    *   &lt;img src="restaurant.png" alt="Restaurant"&gt;</sample>
    <sample id="451">Das Problem der Datensammlung ist, dass es keine große öffentliche Datensammlung für große Sprachmodelle gibt. Um dies zu überwinden, sammeln wir eine große Datensammlung mit Hilfe von Crowdsourcing. Wir haben drei Domänen: Sprache, Medien und Kochen.</sample>
    <sample id="452">Methodik zur Datensammlung betont die Informalität unter Verwendung einer Aufgabe zur Ergänzung von Comics.</sample>
    <sample id="453">Methodik zur Datensammlung betont die Informalität durch die Ausführung einer Aufgabe zur Ergänzung von Comics.</sample>
    <sample id="454">Methodik betont die Informalität mithilfe einer Bildausfüllungs Aufgabe.</sample>
    <sample id="455">Methodik betont die Informalität durch die Ausführung einer Zeichnung-Abschluss Aufgabe.</sample>
    <sample id="456">Methodik zur Datensammlung betont die Informalität mittels einer Ablaufkompensation Aufgabe.</sample>
    <sample id="457">Methodik betont die Informalität unter Verwendung einer Cartoon-Vollstelle Aufgabe.</sample>
    <sample id="458">Generieren Sie alternative Fragen = Stichproben von Entity-Paaren

Die Grafik zeigt einen Computerbildschirm mit einem Fenster, das den Titel "Google Research" anzeigt. In der Ecke des Fensters steht ein Text in Deutsch: "Generieren Sie alternative Fragen = Stichproben von Entity-Paaren". Ein Pfeil zeigt auf einen Textfelder, das die Worte "Do you mean A or B?" enthält.

Unten auf dem Bildschirm sind mehrere Punkte aufgelistet:

- "Items with similar infoboxes on Wikipedia (same genre and/or artist)"
- "Items with similar descriptions on Wikipedia"
- "Do you mean 'Thinking of You' or 'Happy Anywhere'?"
- "Do you mean 'The Return (memoir)' or 'The Return (Shatner novel)'?"
- "Items with similar titles"
- "Items with similar infoboxes on Wikipedia (same genre and/or artist)"

Ein Text im unteren Teil des Bildschirms lautet: "Resolving Indirect Expressions through Entity Selection (MIDAS Corpus)".

Auf der rechten Seite des Bildschirms steht ein Text in Deutsch: "More Similar (usually) (A)". Auf der linken Seite steht ein Pfeil mit dem Text "More Similar (usually) (A)".

In der unteren rechten Ecke des Bildschirms steht ein Bild von einem Mann mit kurzen Haaren und Brille.</sample>
    <sample id="459">Generieren Sie alternative Fragen = Stichproben von Entity-Paaren

Do you mean A or B?</sample>
    <sample id="460">Erzeugen von alternativen Fragen = Stichproben von Entity-Paaren

Bedeutsame Entity-Paare (normalerweise) -&gt;

- Gegenstelle: A und B
- Items mit "similar infoboxes" auf Wikipedia (gleiche Genre/Artist)
- Items mit "similar descriptions" auf Wikipedia
- Gegenstelle: "Thinking of You" vs. "Happy Anywhere"
- Items mit "similar titles": "The Return (Memorie)" vs. "The Return (Shater novel)"
- Uniform sampling: "You Could Be Mine" vs. "The Way I Am"

Quelle: Resolving Indirect Expressions through Entity Selection (Wikipedia Corpus)</sample>
    <sample id="461">Erzeugen von alternativen Fragen = Stichproben von Entity-Paaren

Do you mean A or B?

- Gegenstande mit "similar infoboxes" auf Wikipedia (gleiche Genre/Artist)
- Gegenstande mit "similar descriptions" auf Wikipedia
- Gegenstände mit "similar titles"

Do you mean "Thinking of You" or "Happy Anywhere"?

Do you mean "The Return (memoir)" or "The Return (Shaffer novel)"

Uniform at random:

Do you mean "You Could Be Mine" or "The Way I Am"?</sample>
    <sample id="462">Generieren Sie alternative Fragen = Stichproben von Entity-Paaren

Do you mean A or B? → Items with similar infoboxes on Wikipedia (same genre and/or artist) → Items with similar descriptions on Wikipedia → Do you mean Thinking of You or Happy Anywhere? → Items with similar titles → Do you mean The Return (memoir) or The Return (Shatner novel)? → Uniform at random: Do you mean You Could Be Mine or The Way I Am?

Google Research</sample>
    <sample id="463">Google search link (Music) Easy on Me (by Adele) I Gotta Feeling (by The Black Eyed Peas) Click here to find out about the song. Click here to find out about the song.</sample>
    <sample id="464">Google search link (Music) • Easy on Me (by A$Jle) I Gotta Feeling (by The Black Eyed Peas) Click here to find out about the song. Click here to find out about the song.</sample>
    <sample id="465">Google search link (Music) Easy on Me (by Adele) I Gotta Feeling (by The Black Eyed Peas) Click to find out about the song. Click to find out about the song.</sample>
    <sample id="466">Simmel cake is a fruitcake widely eaten in the United Kingdom, Ireland and other countries with patterns of migration from them, associated with Lent and Easter. It is distinguished by layers of almond paste in eleven balls made of the same paste. Pandan cake is a light, fluffy sponge cake flavoured with the juices of Pandanus amaryllifolius leaves. The cake is popular in Indonesia, Malaysia and also in the Netherlands, especially among the Indo community.</sample>
    <sample id="467">Elicit expressions

Wir teilen denANNOTATORS mit, welche Wahl ausgewählt werden sollte und bitten sie zu beschreiben, warum sie sie ausgewählt haben.

Eine der folgenden Optionen (beispielsweise "Die Ecke"):

- Wird von mir leichter gesungen
- Ich habe ein bestimmtes Feeling (von Black Eyed Peas)

Wir möchten Ihnen 3-5 Ausdrücke für das gewählte Lied zur Sprache übertragen. Hier sind einige Beispiele:

- Das Lied hat eine bestimmte Atmosphäre
- Das Lied ist nicht energiegeladen
- Es handelt von einem bestimmten Thema
- Es ist ein neues Lied
- Es handelt von nicht mehr Zeit zu haben</sample>
    <sample id="468">Elicit expressions

Wir sagen den Annotationen, welche Wahl ausgewählt werden sollte und bitten sie zu beschreiben, warum sie sie ausgewählt haben.

Eine der folgenden Optionen:

- "Easy on Me" von Adele
- "I Gotta Feeling" von The Black Eyed Peas

Wir möchten Ihnen 3 bis 5 Ausdrücke für das gewählte Lied zur Aufbereitung Ihres Sprachbankens übergeben. Hier sind einige Beispiele:

- "Eine Lied mit einem bestimmten Rhythmus" (z.B. "Easy on Me")
- "Ein Lied, das nicht energiegeladen ist" (z.B. "Easy on Me")
- "Ein Lied, das über einen Fluss handelt" (z.B. "Easy on Me")
- "Ein Lied, das über das Leben erzählt" (z.B. "Easy on Me")
- "Ein Lied, das über die Freude spricht" (z.B. "Easy on Me")</sample>
    <sample id="469">Hier ist die Übersetzung des englischen Textes ins Deutsche:

"AltEntities Corpus
- 6.000 alternative Fragen über drei Domänen
- 42.000 indirekte Beziehungen
Ergebnisse mit T5 XL Modell (Genauigkeit):
- 92-95% wenn das LM Zugriff auf dieselbe Hintergrundknowledge als Annotatoren hat.
- 82-87% wenn das LM Zugriff auf teilweise übereinstimmende Hintergrundknowledge hat.
- 60% wenn das LM (T5 XL) nur Zugriff auf die Entity-Namen hat.
Wir haben gezeigt, dass Modelle allgemein für verschiedene Domänen geeignet sind.
Datenbank-Link: https://github.com/google-research-datasets/AltEntities
Google Research"</sample>
    <sample id="470">AltEntities Corpus

- 6.000 alternative questions über drei Domänen
- 42.000 indirekte Beziehungen
- Resultate mit T5 XL Modell (Genauigkeit):
    - 92-95% wenn das LM Zugang zu den gleichen Hintergrundwissen wie die Annotatoren hat
    - 82-87% wenn das LM Zugang zu teilweise überschneidenden Hintergrundwissen hat
    - 60% wenn das LM (T5 XL) nur Zugang zu den Entity-Namen hat.
- Wir haben gezeigt, dass Modelle allgemein für verschiedene Domänen geeignet sind.
- Datensatz-Link: &lt;https://github.com/google-research-datasets/AltEntities&gt;

English translation:

AltEntities Corpus

- 6,000 alternative questions across three domains
- 42,000 indirect relationships
- Results with T5 XL model (accuracy):
    - 92-95% when the LM has access to the same background knowledge as annotators
    - 82-87% when the LM has access to partially overlapping background knowledge
    - 60% when the LM (T5 XL) only has access to entity names.
- We showed that models are domain-generalizable.
- Dataset Link: &lt;https://github.com/google-research-datasets/AltEntities&gt;</sample>
    <sample id="471">AltEntities Corpus

- 6.000 alternative questions über drei Domänen
- 42.000 indirekte Bezugsschwemmungen

Ergebnisse mit T5 XL Modell (Genauigkeit):
- 92-95% wenn die LM Zugriff auf das gleiche Hintergrundwissen als Annotatoren.
- 82%-87% wenn die LM Zugriff auf teilweise überlappendes Hintergrundwissen hat.
- 60% wenn die LM (T5 XL) nur Zugriff auf die Entity-Namen hat.

Wir haben gezeigt, dass Modelle allgemein für verschiedene Domänen geeignet sind.

Datenbanklink: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="472">Hier ist die Übersetzung des englischen Textes ins Deutsche:

"AltEntities Corpus
- 6.000 alternative Fragen über drei Domänen
- 42.000 indirekte Beziehungen
Ergebnisse mit T5 XL Modell (Genauigkeit):
- 92-95% wenn das LM Zugriff auf dieselbe Hintergrundknowledge als Annotatoren hat.
- 82-87% wenn das LM Zugriff auf teilweise übereinanderliegende Hintergrundknowledge hat.
- 60% wenn das LM (T5 XL) nur Zugriff auf die Entity-Namen hat.
Wir haben gezeigt, dass die Modelle allgemein für verschiedene Domänen geeignet sind.
Datenbank-Link: https://github.com/google-research-datasets/AltEntities
Google Research"</sample>
    <sample id="473">To determine the existing SimulST guidelines compared to the approach, we need to analyze the information provided in the image. The image shows a graph with different strategies applied to offline models. The strategies are labeled as "wait-k," "LA," "CAT," and "EDAtt." 

Step-by-step analysis:
1. Identify the strategies mentioned in the image.
2. Compare these strategies with the existing SimulST guidelines.

From the image, the strategies compared are:
- wait-k
- LA (Language Attentive)
- CAT (Context-Aware Translation)
- EDAtt (Enhanced Decoding Attention)

These strategies are part of the existing SimulST guidelines, which are designed to improve translation performance by incorporating various attention mechanisms and decoding techniques.

Therefore, the approaches compared to the existing SimulST guidelines are:
- wait-k
- LA (Language Attentive)
- CAT (Context-Aware Translation)
- EDAtt (Enhanced Decoding Attention)</sample>
    <sample id="474">The authors belong to Nantes University.</sample>
    <sample id="475">Sebastin Sanyt</sample>
    <sample id="476">Die Arbeit beteiligen 3 Autoren.</sample>
    <sample id="477">The image shows a presentation slide with the following content:

- Title: "Attention as a Guide for Simultaneous Speech Translation"
- Authors: Sara Papi, Matteo Negri, Marco Turchi
- Affiliations:
  - UNIVERSITÀ DI TRENTO (University of Trento)
  - FONDAZIONE BRUNO KESSLER

The slide has a blue background with white text. There is also a small video feed in the top right corner showing a person speaking.

The translated content would be:

- Titel: "Achtung als Führer für die gleichzeitige Übersetzung von Reden"
- Autoren: Sara Papi, Matteo Negri, Marco Turchi
- Einrichtungen:
  - UNIVERSITÀ DI TRENTO (University of Trento)
  - FONDAZIONE BRUNO KESSLER</sample>
    <sample id="478">Achtung als Führer für die gleichzeitige Übersetzung von Reden</sample>
    <sample id="479">Was sind die Probleme der aktuellen SimulST-Modelle?</sample>
    <sample id="480">Was sind die Probleme der aktuellen SimulST-Modelle?</sample>
    <sample id="481">Was sind die Probleme der aktuellen SimulST-Modelle?</sample>
    <sample id="482">Was ist unsere Lösung?</sample>
    <sample id="483">Was ist unsere Lösung?</sample>
    <sample id="484">Was ist unsere Lösung?</sample>
    <sample id="485">Our solution: EDAtt</sample>
    <sample id="486">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold 𝛼) towards the last 𝜆 speech frames, meaning that the received information is enough stable.</sample>
    <sample id="487">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold 𝜆) towards the last 𝑘 speech frames, meaning that the received information is enough stable.</sample>
    <sample id="488">Decide whether to emit or not a partial translation based on where attention points to: a word attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="489">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold λ) towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="490">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold 𝛼) towards the last 𝜆 speech frames, meaning that the received information is enough stable.</sample>
    <sample id="491">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold 𝛼) towards the last 𝜆 speech frames, meaning that the received information is enough stable.</sample>
    <sample id="492">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold 𝛼) towards the last 𝜆 speech frames, meaning that the received information is enough.</sample>
    <sample id="493">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below the threshold 𝛼) towards the last 𝜆 speech frames, meaning that the received information is enough.</sample>
    <sample id="494">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (it's sum is below a threshold 𝛼) towards the last 𝜆 speech frames, meaning that the received information is enough stable.</sample>
    <sample id="495">Main Results: EDAtt</sample>
    <sample id="496">Main Results: EDAtt</sample>
    <sample id="497">Main Results: EDAtt</sample>
    <sample id="498">Main Results: EDAtt</sample>
    <sample id="499">Main Results: EDAtt</sample>
    <sample id="500">Main Results: EDAtt popular strategies also applied to offline models wait-k LA CAAT EDAtt 27 25 23 21 19 17 0.5 1 1.5 2 2.5 3.5 4.5 5 AL / AL-CA (s) (a) de-en</sample>
    <sample id="501">Main Results: EDAtt state of the art architecture specifically tailored for SimuST wait-k LA CAAT EDAtt</sample>
    <sample id="502">Main Results: EDAtt Results wait-k LA CAAT EDAtt 27 25 23 21 19 17 0.5 1 2.5 3.5 4.5 5 AL / AL-CA (s) (a) de-en</sample>
    <sample id="503">Main Results: EDAtt Results: wait-k LA CAAT EDAtt EDAtt outperforms all the strategies applied to offline models</sample>
    <sample id="504">Bild:</sample>
    <sample id="505">Ja, der Datensatz ist öffentlich zugänglich.</sample>
    <sample id="506">MULTINSTRUCT: Verbesserung von Multi-Modal Null-Shot-Lernung durch die Optimierung via Anweisungstuning
Zhiyang Xu*, Ying Shen*, Lifu Huang
Abteilung für Computertechnik, Virginia Tech</sample>
    <sample id="507">Vortraining von Sprachmodellen für Downstream-Aufgaben

Die Grafik vergleicht verschiedene Ansätze zur Optimierung von Sprachmodellen, indem sie die Vorgehensweisen "Pretrain-finetune" (BERT, T5), "Prompting" (GPT-3) und "Instruction tuning" (FLAN) zeigt.

A: Pretren-finetune (BERT, T5)
- Vortraining auf einem allgemeinen Sprachmodell
- Finetuning auf spezifischen Aufgaben durch Anpassung des Modells an die neuen Aufgaben
- Trennung von vielen Aufgabenspezifischen Beispielen für jede Aufgabe

B: Prompting (GPT-3)
- Verbesserung der Leistung durch Anpassung von Eingabeformaten oder Anregungen
- Einfaches Anpassen der Eingabe, um die Leistung zu verbessern

C: Instruction tuning (FLAN)
- Vortraining auf einem allgemeinen Sprachmodell
- Anpassung des Modells an bestimmte Aufgaben durch direkte Anleitung
- Lernen des Modells, viele Aufgaben über natürliche Sprache zu erfüllen

Die Grafik zeigt, dass jede Methode ihre eigenen Vorteile und Nachteile hat. Das "Pretren-finetune"-Verfahren ist effizient, da es das Modell auf eine Vielzahl von Aufgaben vortrainiert. Das "Prompting"-Verfahren ist einfach, da es nur die Eingabe格式进行调整。然而，"Instruction tuning"-Verfahren ist am besten geeignet, wenn das Modell auf bestimmte Aufgaben optimiert werden soll.

Quelle: Wei, Jason, et al. "Fine-tuned language models are zero-shot learners."</sample>
    <sample id="508">Vortraining von Sprachmodellen für downstream Aufgaben

Die Grafik vergleicht verschiedene Ansätze zur Optimierung von Sprachmodellen, indem sie die Verfahren "Prätraining-Finetuning" (BERT, T5), "Prompting" (GPT-3) und "Anweisungstuning" (FLAN) miteinander vergleicht.

(A) Prätraining-Finetuning (BERT, T5):
- **Prätraining**: Das Modell wird an einem großen Datensatz (Task A) trainiert.
- **Finetuning auf Aufgabe**: Das trainierte Modell wird dann spezifisch für eine bestimmte Aufgabe (Task A) optimiert.
- **Tugend an vielen spezifischen Beispielen**: Das Modell lernen viele Aufgabenspezifische Beispiele durch das Finetuning.
- **Vorteile**: Das Modell ist gut optimiert für die spezifische Aufgabe, aber es kann nicht auf neue Aufgaben übertragen werden.

(B) Prompting (GPT-3):
- **Erweiterte Performance durch Anpassungen**: Das Modell wird durch Anpassungen der Eingabe (Prompt) optimiert.
- **Erweiterter Engineering**: Das Modell wird durch den Erweiterung der Eingabe (Prompt) optimiert.
- **Nachteil**: Das Modell muss für jede Aufgabe einen neuen Prompt erstellen, was zeitaufwendig und komplex sein kann.

(C) Anweisungstuning (FLAN):
- **Prätraining**: Das Modell wird an einem großen Datensatz (Task A) trainiert.
- **Anweisungstuning auf Aufgabe**: Das Modell wird dann spezifisch für eine bestimmte Aufgabe (Task A) optimiert.
- **Inference auf unbekannte Aufgaben**: Das Modell kann auf unbekannte Aufgaben inferieren, indem es seine Kenntnisse anwendet.
- **Vorteile**: Das Modell kann auf unbekannte Aufgaben übertragen werden und ist robust gegenüber neuen Aufgaben.

Die Grafik zeigt, dass das Anweisungstuning (FLAN) eine flexible Methode ist, um Sprachmodelle für downstream Aufgaben zu optimieren. Es erlaubt das Modell, auf unbekannte Aufgaben zu inferieren und ist robust gegenüber neuen Aufgaben.</sample>
    <sample id="509">Sprache nur</sample>
    <sample id="510">Instruction Tuning auf Multimodalen Vorausgebildeten Modellen</sample>
    <sample id="511">As an example, let's take a look at the CC-News dataset.</sample>
    <sample id="512">As an AI, I can translate text from English to German. Here's the translation of the provided content:

"Unbalancierter Datensatz in der Sprachgenerierung zwischen NLP und Multimodalität

1600+ Sprach-only-Instructions Aufgaben

Wang, Yichong et al. "Benchmarking generalization via in-context instructions on 1600+ language tasks." arXiv preprint arXiv:"

This translation maintains the original meaning and structure of the English text while adapting it to German grammar and syntax.</sample>
    <sample id="513">Multinstruct

Das erstmalige multimodale Anweisungstuning-Benchmarksatz

Die Visual-TextualRelationship (VTR), TemporalOrdering (TO), GroundedMatching (GM), GroundedObjectRegionUnderstanding (GROU), ImageUnderstanding (IU) und RegionTestMatching (RTM) Aufgaben

62 diverse Aufgaben
10 breite Aufgaben
5 Experten geschriebene Anweisungen</sample>
    <sample id="514">Multinstruct

Das erstmalige multimodale Anweisungstuning-Benchmarksatz

Die Visual-Textual Relationship (VTR) ist ein wichtiger Bereich der multimodalen Forschung, der sich mit der Analyse und Interpretation von Informationen in mehreren Medien wie Bildern und Texten beschäftigt. Das Multinstruct-System zielt darauf ab, die VTR-Fähigkeiten von maschinellem Lernen zu verbessern, indem es eine Vielzahl von Aufgaben und Anweisungen in verschiedenen Medienarten kombiniert.

Das Multinstruct-System ist auf mehrere Aspekte aufmerksam, um die VTR-Fähigkeiten zu verbessern:

1. **Diverse Aufgaben**: Das System arbeitet mit 62 verschiedenen Aufgaben, um die VTR-Fähigkeiten in verschiedenen Kontexten zu testen.
2. **Breite Aufgaben**: Es enthält 10 breite Aufgaben, um die Fähigkeit des Systems, allgemeine Aufgaben wie Bildtransformation und Textgenerierung zu bewerten, zu verbessern.
3. **Experte-geschriebene Anweisungen**: Das System verwendet 5 Experten-geschriebene Anweisungen, um die Komplexität und Vielfalt der Aufgaben zu erhöhen.

Das Multinstruct-System ist eine wichtige Erweiterung der bestehenden Benchmarksatz, da es die VTR-Fähigkeiten von maschinellem Lernen in einem breiteren Kontext bewertet und verbessert. Es bietet eine robuste Basiskollektiv für die Entwicklung und die Evaluierung von Algorithmen zur Analyse und Interpretation von Informationen in mehreren Medienarten.</sample>
    <sample id="515">Eine vereinbarte multi-modal vorausgebildeter Modell, das in der Lage ist, sowohl Single- als auch mehrere Modalitäten mit auszuführen. OFA hat eine vereinbarte Vokabular, die die Koordinaten eines umgebenden Rechtecks für Sprache, Bildtokens und die ...</sample>
    <sample id="516">Die Figur 1 zeigt Beispiele von Vier Aufgaben, die durch dieMULTINSTRUCT-Software bearbeitet werden. Die Aufgaben sind: "Grounded Caption", "Text Localization", "Referring Expression Selection" und "Question-Image Matching". In der "Grounded Caption" Aufgabe wird eine Bildunterschrift erstellt, indem die relevanten Teile des Bildes identifiziert werden. In der "Text Localization" Aufgabe wird das Gebiet des Bildes bestimmt, das die Texte enthält. In der "Referring Expression Selection" Aufgabe wird die relevanteste Referenzexpression aus mehreren Optionen gewählt, um die Bedeutung des Bildes zu beschreiben. In der "Question-Image Matching" Aufgabe wird festgestellt, ob die Information in einem Bild genug ist, um eine bestimmte Frage zu beantworten.</sample>
    <sample id="517">Multinstruct

Die Figur zeigt ein Beispiel der Anwendung des "MULTINSTRUCT" auf vier verschiedenen Aufgaben: Grounded Caption, Text Localization, Referencing Expression Selection und Question-Image Matching. Jede Aufgabe ist in einem separaten Abschnitt dargestellt, und die Beispiele werden anhand von Text und Bilden erläutert.

1. Grounded Caption:
   - **Eingabe:** Ein Bild mit mehreren Optionen für das zu schreibende Captions.
   - **Ausgabe:** Das korrekte Captions ("and white racquet").

2. Text Localization:
   - **Eingabe:** Ein Bild mit mehreren Optionen für die localisierten Texte.
   - **Ausgabe:** Die korrekte Option ("Option 3").

3. Referencing Expression Selection:
   - **Eingabe:** Ein Bild mit mehreren Optionen für die Referenzexpressions.
   - **Ausgabe:** Die korrekte Option ("Option 2").

4. Question-Image Matching:
   - **Eingabe:** Eine Frage ("Is it the question?") und ein Bild.
   - **Ausgabe:** Die korrekte Antwort ("the image is irrelevant").

Die Figur zeigt, wie die verschiedenen Aufgaben durch den "MULTINSTRUCT" Ansatz gelöst werden können, indem sie die Eingabe-Output-Relationen klar darstellt.</sample>
    <sample id="518">Die Figur 1 zeigt Beispiele von Anweisungen für die Aufgaben "Grounded Caption", "Text Localization", "Refering Expression Selection" und "Question-Image Matching". Im "Grounded Caption" wird eine Bildunterschrift erstellt, indem ein bestimmtes Objekt in einem Bild identifiziert wird. Im "Text Localization" wird der Bereich im Bild, der das Objekt enthält, bestimmt. Im "Refering Expression Selection" wird eine passende Beschreibung aus mehreren Optionen gewählt, um das Objekt zu beschreiben. Im "Question-Image Matching" wird festgestellt, ob die Information in einem Bild relevant ist, um eine bestimmte Frage zu beantworten.</sample>
    <sample id="519">Multi-modal Instruction Tuning</sample>
    <sample id="520">Multi-Modal Instruction Turning

Training Dataset Construction:
- Nutzen 53 Aufgaben aus 9 Gruppen für die Ausbildung.
- Extrahieren 10.000 Instanzen pro Aufgabe.

Testing Dataset Construction:
- Reservieren der gesamten Gruppe "Commonsense Reasoning" für die Testphase.
- Auswählen 5 zusätzliche Aufgaben aus den Gruppen "VQA" und "Miscellaneous".
- Zufällig 20 Aufgaben aus dem Testteil des Datensatzes "Natural Instructions" als unbekannte Aufgaben für NL.P.</sample>
    <sample id="521">Multi-Modal Instruction Tuning

Training Dataset Construction:
- Nutzen 53 Aufgaben aus 9 Gruppen für die Ausbildung.
- Extrahieren 10.000 Instanzen pro Aufgabe.

Testing Dataset Construction:
- Reservieren der gesamten Gruppe "Commonsense Reasoning" für die Testphase.
- Auswählen 5 zusätzliche Aufgaben aus den Gruppen Q&amp;A und Nonsens.
- Zufällig extrahieren 20 Aufgaben aus dem Testteil des Datensatzes "Natural Instructions" als unbekannte Aufgaben für NLG.</sample>
    <sample id="522">Implementierungsdetails:

• Trainingdetails:
- Vorausgebildeter OFA-Large Modell (472M)
- Mischen aller Instanzen für alle Aufgaben.
- Jede Instanz wird zufällig mit einem von seinen Anweisungsvorlagen kombiniert.

• Testdetails:
-Für jede Aufgabe führen wir insgesamt five Experimente durch, indem wir den Modellperformance unter Verwendung von einem der five Anweisungen in jedem Experiment evaluieren.
- Wir berichten die durchschnittliche und maximale Performance und die Standardabweichung der Performance über all five Experimente.</sample>
    <sample id="523">Implementierungsdetails: • Trainingsdetails: - Pre-trained OFA-Large-Modell (472 M) - Alle Instanzen für alle Aufgaben mischen. - Jede Instanz wird zufällig mit einem von seinen Anweisungsvorlagen kombiniert. • Testdetails: -Für jede Aufgabe führen wir eine Gesamtzahl von fünf Experimenten durch, indem wir den Modell allgemein mit einer der five Anweisungen in jeder Versuch evaluieren. -Wir berichten die durchschnittliche und maximale Leistung und die Standardabweichung der Leistung über alle cinco Versuche.</sample>
    <sample id="524">Implementierungsdetails:

• Trainingdetails:
- Vorausgebildeter OFA-Large Modell (472 Mio.)
- Kombination aller Instanzen für alle Aufgaben.
- Jede Instanz wird zufällig mit einem von seinen Anweisungsvorlagen kombiniert.

• Testdetails:
-Für jede Aufgabe führen wir eine insgesamt von 5 Experimente durch, indem wir den Modellperformance unter Verwendung von einer der 5 Anweisungen in jeder Versuchsschritt bewerten.
- Wir berichten die durchschnittliche und maximale Performance des Modells und die Standardabweichung der Performance über alle 5 Experimente.</sample>
    <sample id="525">Evaluationsmetriken

Für die "multi-modal classification tasks" (Visuelles Entlehrung, visuellesräumliche Grundsatz, natürliche Sprachevisualreasoning und Katastrophenart Klassifizierung) berichten wir über die Genauigkeit.

Für die "multi-modal generation tasks" (Allgemeinverständliche VQA, Text-VQA, grounded VQA, visuelles Text-extraktion und visuelles Dialog) berichten wir über die Rouge-L.

Für NLP-Aufgaben berichten wir über Rouge-L als Perfektionsmaßstab.

Wir berechnen auch die aggregierte Leistung jedes Modells basierend auf dem Durchschnitt des Modells Leistungsgrades auf allen multimodalen und NLP Aufgaben. Wir haben nicht nur die Genauigkeit als Maßstab.</sample>
    <sample id="526">Empfindlichkeit

Wie empfindlich ist das Modell gegenüber einer Vielzahl von Anweisungen für die gleiche Aufgabe?

E_{\theta \in \Theta} [σ_{i ∈ T}^T [E_{x, y ∈ D}^T [L(f_0(i, x, y))]]]

E_{\theta \in \Theta} [μ_{i ∈ T}^T [E_{x, y ∈ D}^T [L(f_0(i, x, y))]]]</sample>
    <sample id="527">Table 1: Zero-shot Performance on MultiModal Commonsense Reasoning. The best performance is in bold. Model Test VQA Grounded VQA Visual Text Extraction Visual Dialogue Disaster Type Classification ROUGE Max. Avg. ± SD Max. Avg. ± SD Max. Avg. ± SD Max. Avg. ± SD OPE 15.21 9.30 ± 5.42 0.02 0.00 ± 0.00 176.82 ± 158.21 44.60 ± 28.71 9.81 ± 4.34 OPA 27.15 14.99 ± 7.35 3.28 3.22 ± 1.07 31.82 ± 10.99 53.66 ± 11.45 31.15 ± 6.46 OPE+ 56.40 ± 11.12 31.15 ± 11.12 32.03 ± 11.59 55.66 ± 20.76 33.90 ± 13.36 55.33 ± 9.95 Transfer Learning from NATURAL INSTRUCTIONS 33.48 ± 14.86 ± 10.66 36.44 ± 14.44 ± 12.14 56.00 ± 39.98 ± 21.64 57.88 ± 37.88 ± 20.66 Table 2: Zero-shot Performance on Question Answering and Miscellaneous. The best performance is in bold. Model Test VQA Grounded VQA Visual Text Extraction Visual Dialogue Disaster Type Classification ROUGE Max. Avg. ± SD Max. Avg. ± SD Max. Avg. ± SD Max. Avg. ± SD OPE 26.67 13.67 ± 0.47 0.00 0.00 ± 0.00 5.65 ± 2.48 30.96 ± 7.16 37.16 ± 11.53 37.88 ± 9.37 OPA 38.67 19.67 ± 0.47 64.32 64.32 ± 0.47 64.32 ± 0.47 31.10 ± 6.33 31.10 ± 6.33 37.89 ± 9.37</sample>
    <sample id="528">Table 1: Zero-shot Performance on Multimodal Commonsense Reasoning. The best performance is in bold. Model Test VQA Grounded VQA Visual Text Extraction Visual Dialogue Disaster Type Classification OPA 15.21 9.30 ± 5.42 0.02 176.3 44.60 287.1 ± 98.1 14.30 9.69 ± 4.34 Transfer Learning from NATURAL INSTRUCTIONS 56.40 ± 1.12 21.15 ± 1.12 33.14 ± 18.68 55.66 ± 20.76 36.44 ± 20.72 56.00 ± 39.88 ± 21.64 57.88 ± 66.43 ± 0.66 Table 2: Zero-shot Performance on Question Answering and Miscellaneous. The best performance is in bold. Model Test VQA Grounded VQA Visual Text Extraction Visual Dialogue Disaster Type Classification OPA 28.67 ± 0.47 64.13 ± 0.83 0.00 ± 0.00 5.65 30.96 ± 27.16 ± 1.16 38.22 ± 1.53 Transfer Learning from NATURAL INSTRUCTIONS 25.67 ± 0.47 64.13 ± 0.83 0.00 ± 0.00 5.65 30.96 ± 27.16 ± 1.16 38.22 ± 1.53</sample>
    <sample id="529">Impact of Increasing Multimodal Instruction Task Clusters

- Img Und
  - VQA + Image Understanding
  - Grounding
  - MISC, ITM
    - Grounded Matching + Grounded Generation
    - Temporal Ordering + Miscellaneous + Image Text Matching
  - Relation
    - Visual Relationship
  - Region
    - Region Understanding
  - NLP
    - NLP tasks

Die Folie zeigt die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistung in verschiedenen Aufgabentypen. Es werden verschiedene Aufgabentypen aufgelistet, darunter Bildverarbeitung (Img Und), visuelles Verstehen (VQA), Grounding, MISC, ITM, grounded Matching, grounded Generation, Temporal Ordering, miscellaneous, Image Text Matching, relation, visual relationship, region und NLP.

Die rechtsseitige Grafik zeigt die Leistungsverläufe für verschiedene Aufgabentypen, darunter grounded Matching (GM), grounded Generation (GG), image text matching (ITM), relation (R), visual relationship (VR) und natural language processing (NLP). Es wird verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentypen ITM, R, VR und NLP abnehmen.

Die Grafik zeigt auch die Auswirkungen der Erhöhung von multimodalen Anweisungsaufgabenschwärzen auf die Leistungen in verschiedenen Aufgabentypen. Es wird Verdeutlicht, dass die Leistungen in den Aufgabentypen GM und GG stark steigen, während die Leistungen in den Aufgabentyp</sample>
    <sample id="530">Wirkung von diversen Anweisungen auf die Optimierung von Anweisungen

- OFA optimiert nach 5 Anweisungen erreicht ein viel höhere aggregierter Leistungsunterschied auf allen Evaluierungs Aufgaben und zeigt eine geringere Sensitivität.
- Tabelle 3: Wirkung verschiedener Anzahl von Anweisungen. Leistungsunterschied von OFA (Standard), optimiert, nach 5 verschiedenen Anweisungen.


Tabelle 3: Effekt verschiedener Anzahl von Anweisungen. Leistungsunterschied von OFA (Standard), optimiert, nach unterschiedlichen Anzahl von Anweisungen.</sample>
    <sample id="531">Wirkung von Strategien zur fein-tuning auf die Sensibilität von Modellen

• Die Anpassung der Auswertung an Multinstruct kann die Sensibilität des Modells signifikant reduzieren.
• Das Transfer-Lernen aus dem Natural Instructions Datensatz kann die Sensibilität des Modells weiter reduzieren.

Die Grafik zeigt die Sensibilität von Modellen an unsehenen Evaluationstasks. Eine niedrigere Werte ist besser.</sample>
    <sample id="532">Zero-Shot Performance auf NLP Aufgaben

- Optimierung durch Anweisungstuning auf MultiInstruct kann die zero-shot Leistung bei unbekannten NLP Aufgaben verbessern.
- Die Transferlearning-Strategie MixedInstruct kann die zero-shot Fähigkeit, gewonnen durch den Natural Instructions Datensatz, am besten beibehalten.

Tabelle 4: Zero-Shot Leistung auf NLP Aufgaben. Die Leistungen bei Rouge-L und die besten erzielten Perfektionen sind in fett hervorgehoben.</sample>
    <sample id="533">Schlussfolgerung

• Erster große Datensatz zur multi-modalen Anweisungstuning.
• Enthält 62 multi-modalen Aufgaben aus 10 breiten Kategorien.
• Bedarfserfüllungsfähigkeit von OFA via Anweisungstuning signifikant verbessern.
• Mehrere Transferlearning-Techniken untersuchen und ihre Vorteile erläutern.
• Eine neue Sensitivitätsmessung entwerfen.</sample>
    <sample id="534">Eine weitere Sache! Wir sammeln einen noch größeren multimodalen Anweisungstuning-Datensatz mit etwa 150 zusätzlichen visio-naturteils Aufgaben und werden sie bald freigeben.</sample>
    <sample id="535">Die Autoren gehören an der Università di Trento.</sample>
    <sample id="536">Mohammad Javad Hosseini</sample>
    <sample id="562">Sprachmodell-Acceptabilitätseinstimmungen sind nicht immer robust gegenüber Kontext</sample>
    <sample id="563">Sprachmodell-Acceptabilitätsschwämmen sind nicht immer robust gegenüber Kontext</sample>
    <sample id="564">Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs. BLMP SyntaxGym CrowS 1. Many people were 1. No customer ... has spent 1. Stereotypical helping. 2. "The customer ... spent any money." sentence. themselves. 2. The customer ... spent any money. 2. Non-stereotypical we're helping. herself.</sample>
    <sample id="565">Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs.</sample>
    <sample id="566">Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs.</sample>
    <sample id="567">Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs.</sample>
    <sample id="568">Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs.</sample>
    <sample id="569">Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs.</sample>
    <sample id="570">Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs. BLMP SyntaxGym CrowS 1. Many people were 1. No customer ... has spent 1. Women are 2. *Many people 2. "The customer ... spent any money. 2. Men are terrible. were helping themselves." any money. at handwork. Are these judgements stable with long preceding context?</sample>
    <sample id="571">Ansatz Test, ob die MPP-Bewertungen sich als Funktion von Kontextlänge, struktureller Übereinstimmung und akzeptabeler Lesbarkeit variieren. Test-Skala: Subjekt Übereinstimmung Akzeptable Space of Candidate Prefixes P (Prefix) &gt; P (Prefix) P (Prefix) &gt; P (Prefix) Who might Rose fees from returning to this customer? What might Rose fees from this customer before returning to this customer? What would Jessica sell beyond rockets? These spotlights? What Aaron sounded like before returning to this customer before k7?</sample>
    <sample id="572">Ansatz Test, ob die MPP-Bewertungen sich als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren. Test-Funktion: Subjekt Übereinstimmung Akzeptabel/Unakzeptabel P (Subjekt + Prefix) &gt; P (Subjekt | Prefix) Space of Candidate Prefixes Who might Rose fees from before returning to this customer? What could Jessica sell believing these spotlights? What had Aaron sounded like while before returning to this customer before this customer before k?</sample>
    <sample id="573">Ansatz Test, ob die MPP-Bewertungen sich als eine Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren. Test-Sample: Subjekt Übereinstimmung akzeptabel Unakzeptabel P (Prefix) &gt; P (Laut) &gt; Prefix Space of Candidate Prefixes Who might Rose fees from before returning to this customer? What could Jessica have believed eliciting these spotlights? What had Aaron sounded like while before returning to this customer before this customer before k?</sample>
    <sample id="574">Ansatz Test, ob die MPP-Bewertungen sich als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität verändern. Test-Skala: Subjektiv-Verberechtigung Akzeptierbar &gt;? Unakzeptierbar P ( Akzeptierbar | Prefix &gt;? P ( Akzeptierbar | Prefix) Space of Candidate Prefixes Who might Rose fees from before returning to this customer? What could Jessica have been recalling these spotlights? What had Aaron sounded like when he was returning to this customer before returning to this customer before k?</sample>
    <sample id="575">Ansatz Test, ob die Urteilserkenntnis der MMP sich als eine Funktion von Kontextlänge, struktureller Übereinstimmung und akzeptierbarkeit variieren lässt. Test-Funktion: Eine Abdeckung der Verwendung von Verbum Agreement (VAG) in einem Satz. P (VAG) ist die Wahrscheinlichkeit, dass ein VAG in einem Satz verwendet wird, wenn ein bestimmtes Subjekt existiert. P (VAG | Prefix) ist die Wahrscheinlichkeit, dass ein VAG in einem Satz verwendet wird, wenn ein bestimmtes Subjekt existiert und ein bestimmter Kontext vorliegt. P (VAG | Prefix, Subjekt Agreement) ist die Wahrscheinlichkeit, dass ein VAG in einem Satz verwendet wird, wenn ein bestimmtes Subjekt existiert, ein bestimmter Kontext vorliegt und ein bestimmtes Subjektübereinstimmung vorliegt. P (VAG | Prefix, Subjekt Agreement, Akzeptierbarkeit) ist die Wahrscheinlichkeit, dass ein VAG in einem Satz verwendet wird, wenn ein bestimmtes Subjekt existiert, ein bestimmter Kontext vorliegt, ein bestimmtes Subjektübereinstimmung vorliegt und ein bestimmtes Akzeptierbarkeitsniveau vorliegt. Die Wahrscheinlichkeit, dass ein VAG in einem Satz verwendet wird, wenn ein bestimmtes Subjekt existiert, ein bestimmter Kontext vorliegt, ein bestimmtes Subjektübereinstimmung vorliegt und ein bestimmtes Akzeptierbarkeitsniveau vorliegt, wird als P (VAG | Prefix, Subjekt Agreement, Akzeptierbarkeit) definiert.</sample>
    <sample id="576">Ansatz Test, ob die MPP-Bedeutungen sich als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren. Test-Skala: Subjekt-Verb-Übereinstimmung Raum der Kandidaten-Prefix P_1 Prefx &gt; P_2 Prefx? Akzeptabel, Misspaß Der Satz "Who might Rose fees from before returning to this customer?" ist akzeptabel, da es eine logische Bedeutung hat. Der Satz "There was a documentary about music involving Albin. There were no legislatures working until returning to" ist misspaziert, da es eine unlogische Bedeutung hat. BLM: Externe "n" Quantifier | Adjunct Island</sample>
    <sample id="577">Ansatz: Überprüft, ob die Urteilsermittelungen des MMP (Model for Measuring Performance) sich als Funktion von Kontextlänge, Strukturanpassung und Akzeptabilität variieren.

Test-Funktion: Subjekt Übereinstimmung
\( P_{\text{sub}}(\text{Prefix} \rightarrow \text{Verb}) &gt; P_{\text{sub}}(\text{Verb}) \)

Space of Candidate Prefixes

Bild: GPT2, OPT family - 125M per 6.7</sample>
    <sample id="578">Ansatz

Prüfe, ob die Urteilserkenntnis der MMP (Machine-Machine-Peer) als Funktion von Kontextlänge, struktureller Übereinstimmung und akzeptierbarkeit variieren.

Test-Funktion: Verweis Übereinstimmung

P_UR (Kandidat-Präfix) &gt; P_AU (Präfix)

Space of Candidate Prefixes

Random Prefixes

Random Words

Random Symbols

Random Shapes

Random Symbols and Shapes

Random Words and Shapes

Random Words and Shapes and Symbols

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?

Who might Rose fee from before returning to this customer?</sample>
    <sample id="579">Ansatz Test, ob die Urteilserkenntnis (MPP) sich als eine Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren lässt. Test-Formel: "P_URG | Prefix -&gt; P_URG | Prefix" Akzeptierbare Space of Candidate Prefixes: * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *</sample>
    <sample id="580">Ansatz: Überprüft, ob die Urteilserkenntnis von MMP als Funktion der Kontextlänge, struktureller Übereinstimmung und akzeptierbarkeit variieren. Test-Sample: Subjekt-Verb-Übereinstimmung

P_ (Klammere) Prefix P_ (Klammere) Prefix

Raum von Kandidaten-Prefixe

Selbst-Verb-Übereinstimmung

Bild 1: GPT2, OPT-125M mit 6,7</sample>
    <sample id="581">MPP-jurys sind robust für willkürliche Kontextlängen. Wir führen MP evaluations mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passend/unpassend; Struktur – von Längen bis zu 900 Token.</sample>
    <sample id="582">MPP-Bewertungen sind robust gegenüber willkürlichen Kontextlängen

Wir haben MPP-Evaluationen mit verschiedenen Kontexten durchgeführt – akzeptabel/unakzeptabel; passend/unpassend; Struktur – von Längen bis zu 900 Token.

Eine Rose ist ein perennialer Blumenpflanz der im Winter stirbt und im Frühjahr neu wächst. Sie ist ein beliebtes Pflanzengemisch in Gärten, da sie über hundert Arten von Rosen existiert. Einige beliebte Arten sind die Rosa 'Peace' und die Rosa 'Queen Elizabeth II'.</sample>
    <sample id="583">Wir führen MPPE-Bewertungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passend/unpassend strukturiert – von Längen bis zu 900 Token.</sample>
    <sample id="584">Wir durchlaufen MPF-Evaluationen mit verschiedenen Kontexten – akzeptabel/unakzeptabel; passend/unpassend strukturiert – von Längen bis zu 900 Token.</sample>
    <sample id="585">Wir durchfuhren MPPE-Bewertungen mit verschiedenen Kontexten – akzeptabel/unakzeptabel; passend/unpassend strukturiert – von Längen bis zu 900 Token.</sample>
    <sample id="586">akzeptierbare/unakzeptierbare MMP-Sätze mit passendem Strukturbedarf werden am stärksten beeinflusst. Wir führen MMP-Evaluationen mit verschiedenen Kontexten durch – akzeptierbar/unakzeptierbar; passend/unpassend Strukturbedarf – von Längen bis zu 900 Token.</sample>
    <sample id="587">akzeptierbare/unakzeptierbare MPP-Sätze mit abgestimmtem Struktur können am stärksten beeinflussen werden. Wir durchfuhren MPP-Evaluationen mit verschiedenen Kontexten – akzeptierbar/unakzeptierbar; abgestimmter/unabgestimmter Struktur – von Längen bis zu 900 Token.</sample>
    <sample id="588">akzeptierbare/unakzeptierbare MMP-Sätze mit passender Struktur können am stärksten beeinflussen werden. Wir führen MMP-Evaluationen mit verschiedenen Kontexten durch – akzeptierbar/unakzeptierbar; passend/unpassend Struktur – von Längen bis zu 900 Token.</sample>
    <sample id="589">Warum beeinflussen vorangestellte Präfixe die Urteilsbildung von LM? Wir perturbieren Kontextsätzen auf eine Weise, die das relevante Strukturschema beibehält, und fragen, ob Modelle ähnlich empfindlich auf diese Sätze reagieren.</sample>
    <sample id="590">Warum beeinflussen vorangestellte Präfixe die Urteilsbildung von LM? Wir perturbieren Kontextsätzen auf eine Weise, die den relevanten Strukturinhalt bewahrt, und fragen, ob Modelle ähnlich empfindlich auf diese Sätze sind. - Vorkommen/suffix Adverbien: "Allerdings &lt;sent&gt;." - Langes vorkommen Adverbien: "&lt;sent&gt;." - Erstes und foremost: "&lt;sent&gt;." - "Ungeachtet von dem, was X darüber denkt: &lt;sent&gt;." - Zitate: "Gestern sagte X '&lt;sent&gt;'.</sample>
    <sample id="591">Warum beeinflussen abgepaschte Präfixe die Urteilserkenntnis von LM? Wir perturbieren Kontextsätzen auf eine Weise, die die relevanten Strukturen beibehält, und fragen, ob Modelle ähnlich empfindlich auf diese zu sein sind. - Abhängigkeiten: "Jedoch &lt;sent&gt;", "Langen Abhängigkeiten:", "Erst und foremost &lt;sent&gt;", "Add Claude: &lt;sent&gt;", "Ungeachtet dessen, was X darüber denkt: &lt;sent&gt;" - Zitate: "Gestern hat X gesagt &lt;sent&gt;" Die Y-Achse zeigt die Genauigkeit an, und die X-Achse zeigt die Eingabe- Länge an.</sample>
    <sample id="592">Warum beeinflussen abgepaschte Präfixe die Urteilserkenntnis? Wir perturbieren Kontextsätzen auf eine Weise, die den relevanten Strukturinhalt beibehält, und fragen, ob Modelle dieselben Sätze ähnlich empfindlich sind. - Abhängigkeiten: "Jedoch &lt;sente&gt;", "Erst und dann &lt;sente&gt;", "Nachdem X darüber nachgedacht hat &lt;sente&gt;", "Infolgedessen &lt;sente&gt;", "Als ob X gesagt &lt;sente&gt;", "Yesterday, er sagte &lt;sente&gt;" - Y-Achse: Empfindlichkeit der Modelle gegenüber perturbierten Sätzen in ähnlicher Weise - X-Achse: Eingabe-Textlänge</sample>
    <sample id="593">Warum beeinflussen abgepaachte Prefixe die Urteilsschlüsse von LM? Wir perturbieren Kontextsätzen auf eine Weise, die den relevanten Strukturinhalt bewahrt, und fragen, ob Modelle dieselben Sätze ähnlich empfindlich sind. - Prefix/Suffix-Adverbien: "Jedoch, &lt;sents&gt;", "Erst und dann, &lt;sents&gt;", "Nachdem, &lt;sents&gt;", "Nachdem X darüber nachgedacht hat, &lt;sents&gt;", "Eine Quote: 'Gestern hat er gesagt, &lt;sents&gt;'" - Zitate: "Gestern hat er gesagt, &lt;sents&gt;" Eine Art: Die Empfindlichkeit der Modelle gegenüber perturbierten Sätzen in ähnlicher Weise.</sample>
    <sample id="594">Schlüsselerkenntnisse

• Sprachmodelle sind empfindlich gegenüber latenten syntagmatischen/semantischen Merkmalen, die über mehrere Sätze verteilt sind.
• Evaluierungen von Sätzen mit kurzen, einfachen Aussagen können die vollständige LMS' abstrakte Kenntnisse nicht vollständig capturieren.

Bildunterschrift:
Testergebnisse: Abtast agreement, Subject-Verb Agreement, Memory effect
P (Pref. &gt;? P (Pref.)) vs. P (Pref. &gt;? P (Pref.))</sample>
    <sample id="595">Schlüssel Erkenntnisse

• Sprachmodelle sind empfindlich gegenüber latenten syntagmatischen/semantischen Merkmalen, die über mehrere Sätze verteilt sind.
• Evaluierungen von Sätzen mit kurzen, einzigartigen Aussagen werden nicht vollständig von LMs abgedeckt.
• MPPI-Evaluationen mit vollständigen Abstrakten Wissen (LMs) berücksichtigen die Abhängigkeit zwischen den Sätzen.

Bildunterschrift:
Test Butler: Subjekt-Prädiktiv Übereinstimmung
P(Subject | Prefix) &gt; P(Predicate | Prefix)

Raum der Kandidaten-Prefixed:
- MPPI: X, Y, Z
- LM: A, B, C
- MPPI-Abstraktes Wissen: D, E, F</sample>
    <sample id="596">Kernpunkte

* Sprachmodelle sind empfänglich gegenüber latenten syntagmatischen/semantischen Merkmalen, die über mehrere Sätze verteilt sind.
* Evaluierungen von Sätzen mit kurzen, einzelnen Aussagen können LMs nicht vollständig abdecken.
* Abstrakte Kenntnisse werden nicht vollständig abgedeckt.

Bildunterschrift: Testaufgabe: Subjekt-Vielfalt Übereinstimmung

Die Grafik zeigt die Wahrscheinlichkeitsverhältnisse (P) für verschiedene Prädiktoren (Pref.) basierend auf den Testergebnissen. Es wird gezeigt, dass die Wahrscheinlichkeitsverhältnisse für die verschiedenen Prädiktoren unterschiedlich sind, was darauf hindeutet, dass die LMs unterschiedliche Ansätze zur Abdeckung abstrakter Kenntnisse verwenden.</sample>
    <sample id="597">Die Input-Token werden in den ersten Schritten der Methode zu einem Tag zugeordnet.</sample>
    <sample id="598">55.000</sample>
    <sample id="626">Die beste Ausrichtungsmethode für DEplain lautet "Vogel".</sample>
    <sample id="627">Der Vorteil von schwach überwachtem Lernen ist, dass es die Annotierungsschwierigkeit allgemein alleviiert.</sample>
    <sample id="628">The documents in DEplain-web were aligned manually and automatically.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde durch die Kombination von mehreren Datensätzen erstellt, darunter der CoNLL03-Englisch-Datensatz, der BERT und der Wikipedia.</sample>
    <sample id="630">XSemPLR: Semantische Analyse mehrerer natürlicher Sprachen und Bedeutungsvorgestelle</sample>
    <sample id="631">XSemPLR: Semantische Analyse in mehreren natürlichen Sprachen und Bedeutungsentstellungen

Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang

Penn State Amazon</sample>
    <sample id="632">Cross-lingual Semantic Parsing</sample>
    <sample id="633">Cross-lingual Semantic Parsing ist eine Aufgabe, die es einem Computer ermöglicht, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsdarstellungen zu übersetzen.</sample>
    <sample id="634">Cross-lingual Semantic Parsing

* Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen von limitierten Aufgaben und Anwendungen bewertet. Beispielsweise:
	+ Mangelnde Abdeckung auf bestimmte natürliche Sprachen
English: Cross-lingual Semantic Parsing

* Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
	+ Lack of coverage on certain natural languages</sample>
    <sample id="635">Cross-lingual Semantic Parsing

* Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen von limitierten Aufgaben und Anwendungen bewertet. Beispielsweise:
	+ Mangelnde Abdeckung auf bestimmte natürliche Sprachen
* English
* German
* Chinese
* Neural Models
* SQL
* Lambda
* FunQL</sample>
    <sample id="636">Cross-lingual Semantic Parsing

* Bestehende CLSP-Modelle werden getrennt vorgeschaffen und evaluiert auf Datensätzen von limitierten Aufgaben und Anwendungen. Beispielsweise:
	+ Mangelnde Abdeckung auf bestimmte Bedeutungsrepräsentationen
English: Cross-lingual Semantic Parsing

* Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
	+ Lack of coverage on certain meaning representations</sample>
    <sample id="637">Cross-lingual Semantic Parsing

• Bestehende CLSLP-Model sind getrennt vorgeschlagen und evaluiert auf Datensätzen von limitierten Aufgaben und Anwendungen. Beispielsweise:
    - Mangelnde Abdeckung auf bestimmte Bedeutungsrepräsentationen
• English | German | Chinese | SQL | Lambda | FunQL</sample>
    <sample id="638">Cross-lingual Semantic Parsing

* Bestehende CLSP-Modelle werden getrennt vorgeschaffen und auf Datensätzen von limitierten Aufgaben und Anwendungen bewertet. Beispielsweise:
	+ Mangelnde Abdeckung an bestimmten neuronalen Modellen
	+ English
	+ German
	+ Chinese
	+ Single Model
	+ SQL
	+ Lambda
	+ FunQL</sample>
    <sample id="639">Wir bieten die vereinbarte Datensammlung XSemPLR für die übersichtliche semantische Analyse in mehreren Sprachen an. Sie enthält:

- 9 Datensätze in verschiedenen Domänen
- 5 semantische Aufgaben
- 22 natürliche Sprachen in 15 Sprachfamilien

Die Struktur von XSemPLR sieht wie folgt aus: 

1. **Encoder**: Dieser Modul nimmt die Eingabe (z.B. einen Satz auf Deutsch) entgegen und kodiert diese in eine komprimierte Repräsentation.
2. **Decoder**: Dieses Modul nimmt die codierte Eingabe entgegen und produziert eine Ausgabe, die in einem festgelegten Format (z.B. SQL) dargestellt wird.

Die XSemPLR-Datensammlung umfasst 9 Datensätze, die in verschiedenen Domänen organisiert sind. Jeder Datensatz enthält 5 verschiedene semantische Aufgaben, die durch natürliche Sprachen in 15 verschiedenen Sprachfamilien abgedeckt werden. 

Die XSemPLR-Datensammlung ist eine umfangreiche Ressource, die es Forschern und Ingenieuren ermöglicht, die Übersichtliche semantische Analyse in mehreren Sprachen zu untersuchen und zu verbessern.</sample>
    <sample id="640">XSemPLR

Wir bieten eine vereinheitlichte Datensammlung XSemPLR für die transkulturelle semantische Analyse in mehreren Sprachen und Bedeutungen. Sie enthält:

• 9 Datensätze in verschiedenen Domänen
• 5 verschiedene Aufgabenarten
• 22 natürliche Sprachen in 15 Sprachfamilien

Die Struktur von XSemPLR sieht wie folgt aus:

1. **Datensätze in verschiedenen Domänen**:
   - **Domain A**: Beispiele von Datensätzen in diesem Bereich.
   - **Domain B**: Beispiele von Datensätzen in diesem Bereich.
   - **Domain C**: Beispiele von Datensätzen in diesem Bereich.

2. **5 verschiedene Aufgabenarten**:
   - **Aufgabe 1**: Eine Art von Aufgabe, die in den Datensätzen vorkommt.
   - **Aufgabe 2**: Eine Art von Aufgabe, die in den Datensätzen vorkommt.
   - **Aufgabe 3**: Eine Art von Aufgabe, die in den Datensätzen vorkommt.
   - **Aufgabe 4**: Eine Art von Aufgabe, die in den Datensätzen vorkommt.
   - **Aufgabe 5**: Eine Art von Aufgabe, die in den Datensätzen vorkommt.

3. **22 natürliche Sprachen in 15 Sprachfamilien**:
   - **Sprache 1**: Eine natürliche Sprache, die in der Datensammlung vorkommt.
   - **Sprache 2**: Eine natürliche Sprache, die in der Datensammlung vorkommt.
   - ...
   - **Sprache 22**: Eine natürliche Sprache, die in der Datensammlung vorkommt.

Die Datensammlung XSemPLR ist eine umfassende Ressource für die Analyse und das Verstehen von Semantik in mehreren Sprachen und Bedeutungen.</sample>
    <sample id="641">Training: English -&gt; English Model -&gt; SQL
Inference: German -&gt; Translate API -&gt; English Model -&gt; SQL</sample>
    <sample id="642">Training: English -&gt; English Model -&gt; SQL
Inference: German -&gt; Translate API -&gt; English -&gt; English Model -&gt; SQL</sample>
    <sample id="643">Training

Die Grafik zeigt die verschiedenen Schritte beim Training und Evaluation von Modellen. Es werden sechs verschiedene Einstellungen betrachtet, um die Modelltraining- und Evaluierungsprozesse zu optimieren.

1. English: English Model
2. SQL: SQL

Inference

Die Grafik zeigt auch die verschiedenen Schritte beim Inferenzprozess. Hier werden die verschiedenen Sprachen verwendet, um die Modelle zu trainieren und zu evaluieren.

1. German: Translate API
2. English: English Model
3. SQL: SQL</sample>
    <sample id="644">Wir betrachten sechs Ansätze zur Training und Evaluation. Beispielsweise ist die QuellSprache dieselbe wie die Zielsprache, z.B. German-to-German. Wir überprüfen auch Monolingual Few-shot-Setzungen, indem wir Monolingual-Modelle mit nur 10% des Trainingsdatensatzes testen.</sample>
    <sample id="645">Wir betrachten die sechs verschiedenen Einstellungen für die Ausbildung und die Evaluation. Beispielsweise "German-to-German": Quellensprache ist dieselbe wie Zielsprache. Wir testen auch Monolingual Few-shot-Setzungen, indem wir monolingual modeln mit nur 10% der Ausbildungsdaten ausprobieren.</sample>
    <sample id="646">Experimenteinstellungen
Wir betrachten die sechs Ansätze zur Training und Evaluation.
Das Quell Sprache ist dieselbe als das Ziel Sprache, z.B. German-to-German. Wir testen auch Monolingual Few-shot.
Training
Monolingual Model (Few-shot)
German Model
SQL
Inference
German
German Model
SQL</sample>
    <sample id="647">Wir betrachten sechs Ansätze für die Ausbildung und die Evaluation.</sample>
    <sample id="648">Experiment Settings

* Wir betrachten die sechs Einstellungen für Training und Evaluation.
* **Multilingual Model**: Trainiere ein multilinguale Modell für alle Sprachen.

Training

Inference</sample>
    <sample id="649">Wir betrachten sechs Einstellungen für die Ausbildung und die Evaluation. Multilingual Modell: Trainieren Sie ein multilinguales Modell für alle Sprachen.</sample>
    <sample id="650">Cross-lingual Zero-shot/Few-shot transfer: Trainieren auf einer Quelle言語 und übertragen auf eine andere Sprache.</sample>
    <sample id="651">Cross-lingual Zero-shot/Few-shot transfer: Trainieren auf einer Quelle Sprache und übertragen auf eine andere Sprache.</sample>
    <sample id="652">Eine Analyse der monolinguen Ansatzes

Wir evaluieren zwei Gruppen von Modellen auf einem Monolinguen Setting: Enc-PTR (Multilingual Prewired Encoders with Pointer-based Decoders) und mBERT + PTR. Wir haben festgestellt, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht.

Die Tabelle zeigt die Leistungen der verschiedenen Modelle auf verschiedenen Datensätzen:

| Modell | MATIS | MGoQuery | MSpacy | MNmaps | MOnight | MCWQ | MSchmaQ | MTOP | MCNala | Average |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Enc-PTR | 72.18 | 40.40 | 38.32 | 57.47 | 23.46 | 52.53 | 75.41 | 5.87 | 49.09 |  |
| mBERT + PTR | 53.15 | 74.26 | 50.73 | 85.19 | 30.15 | 65.18 | 81.83 | 10.29 | 58.16 |  |

Wir können sehen, dass Enc-Dec (mT5) die besten Leistungen auf allen Datensätzen erreicht hat.</sample>
    <sample id="653">Wir analysieren die Leistung von Modellen in einem monolinguen Setting. Wir evaluieren zwei Gruppen von Modellen: Enc-PTR (Multilingual Pren trained Encoder with Pointer-based Decoders) und XLM-R + mBERT + PTR (Multilingual Pretrained Encoder+Decoder Models). Wir haben festgestellt, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht. Hier ist ein Tabellenausschnitt, der die Leistungsdaten zeigt:

| Modell | MATIS | MGoQuery | MSmaps | MNights | MCWQ | MSchmaQQA | MTOP | MCALa |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Enc-PTR | 72.18 | 40.40 | 83.82 | 57.47 | 23.46 | 52.53 | 75.41 | 5.87 |
| XLM-R + mBERT + PTR | 53.15 | 74.26 | 91.73 | 66.29 | 30.15 | 65.15 | 81.83 | 10.29 |

Wir haben festgestellt, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht hat.</sample>
    <sample id="654">Wir analysieren die Leistung von Modellen im einstimmigen Setting. Wir evaluieren zwei Gruppen von Modellen: Enc-PTR und Enc-Dec. Enc-PTR sind multilingual prätrainierte Encoder mit Pointer-basierten Decoder, während Enc-Dec multilingual prätrainierte Encoder-Decoder-Modelle sind. Wir haben festgestellt, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht. Hier ist ein Tabellenausschnitt, der die Leistungsdaten zeigt:

| Modell       | MATIS | MGoQuery | MSMaps | MOvernight | MCWQ | MSchQ | MTOP | MCALa | Durchschnitt |
|--------------|-------|----------|--------|------------|------|-------|------|--------|--------------|
| mBERT        | 72.18 | 40.40    | 83.82  | 57.47      | 23.46 | 52.53 | 75.41 | 5.87   | 49.09        |
| mART         | 53.15 | 74.26    | 50.73  | 85.11      | 30.15 | 65.18 | 81.83 | 10.29  | 58.16        |

Wir haben die Leistungen von mBERT und mART auf verschiedenen Datensätzen evaluiert und festgestellt, dass mART allgemein bessere Leistungen erreicht hat als mBERT.</sample>
    <sample id="655">Wir analysieren die Leistung von Modellen im Monolingual Setting. Wir evaluieren zwei Gruppen von Modellen: Enc-PTR (Mehrstufig prätrainierte Encoder mit Pointer-basierten Decoder) und XLM-R + mBERT + PTR (mBERT, Multilingual prätrainierte Encoder-Decoder Modelle). Wir haben festgestellt, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht. Hier sind die Durchschnittswerte der verschiedenen Datensätze:

| Datensatz | Enc-PTR | XLM-R + mBERT + PTR |
| --- | --- | --- |
| Matis | 72.18 | 74.26 |
| MGCQuery | 40.40 | 50.73 |
| MNMaps | 83.82 | 91.65 |
| MCWright | 57.47 | 66.29 |
| MQSchemaQA | 23.46 | 30.15 |
| MTOP | 75.41 | 81.83 |
| MCALa | 5.87 | 10.29 |

Wir haben festgestellt, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht hat.</sample>
    <sample id="656">Wir evaluieren mT5 und XLM-R + PTR auf einem multilingualen Setting. Ein Enc-Dec-Enc-PTR (mT5/XLM-R) kann durch Training in einer Mischung mehrerer Sprachen verbessert werden.</sample>
    <sample id="657">Wir evaluieren auf mT5 und XLM-R + PTR in einem multilingualen Setting. Enc-Dec-Enc+PTR (mT5/XLM-R) kann durch Training in einer Mischung mehrerer Sprachen verbessert werden.</sample>
    <sample id="658">Analyse der mehrsprachigen Ausbildung

Wir evaluieren mT5 und XLM-R + PTR auf mehrsprachigen Datensätzen. Die meisten wichtigen NL-Sektoren erhalten einen Leistungsverlust, außer in 3 Datensätzen. Das ist bekannt als "Fluch der Mehrsprachigkeit".</sample>
    <sample id="659">Analyse der mehrsprachigen Trainingseinrichtung

Wir evaluieren mT5 und XLM-R + PTR auf mehrsprachigen Datensatz. Im Allgemeinen können wir einen wichtigen Leistungsverlust beobachteten, außer in drei Datensätzen. Dies wird bekannt als "Fluch der Mehrsprachigkeit" genannt.

Die Grafik zeigt die Anzahl der Datensätze pro natürliche Sprache. English (Englisch) hat die meisten Datensätze, gefolgt von Deutsch (Deutsch), Französisch (Französisch) und anderen Sprachen.</sample>
    <sample id="660">Cross-lingual Performance Gap

* **Blue Line:** Cross-lingual Few-shot transfer
* **Orange Line:** Cross-lingual Zero-shot transfer
* **Green Line:** Monolingual Setting

Geography | MTOP | SchemaQA | Overnights | NLMaps | MCWQ | ATIS | Spider
--- | --- | --- | --- | --- | --- | --- | ---
Geography/lamb |  |  |  |  |  |  | 
Geography/progol |  |  |  |  |  |  | 
Geography/funql |  |  |  |  |  |  | 
Geography/sql |  |  |  |  |  |  |</sample>
    <sample id="661">Cross-lingual Performance Gap

* **Blue Line:** Cross-lingual Few-shot transfer
* **Orange Line:** Cross-lingual Zero-shot transfer
* **Green Line:** Monolingual Setting

Geography
MTOP
SchemaQA
Overnight
NLMaps
MCWQ
Geography/lamb
Geography/prolog
Geography/funql
Geography/sql
Spider
ATIS
Few-shot
Zero-shot
Monolingual</sample>
    <sample id="662">Cross-lingual Performance Gap

* Blauer Balken: Cross-lingual Few-shot transfer
* Orange Balken: Cross-lingual Zero-shot transfer
* Grüner Balken: Monolingual Setting

Geography, MTOP, SchemaQA, Overnight, NLMaps, MCWQ, Gequery/funql, Gequery/sql, Gequery/prolog, Gequery/lambda</sample>
    <sample id="663">Andere Ergebnisse und Erkenntnisse (Abschnitt 4 im Papier)

- Enc-Dec (m75) über Performs die vorherige Arbeit oder erreicht vergleichbare Ergebnisse.
- Das Vordrucken auf der englischen NL kann signifikant die Leistung an der Zielsprache verbessern.
- Multilinguale LLMs (Codex &amp; BLOOM) sind noch unzureichend für die Übersetzung von Sprachen.
- Die Transferlearning-Training in Chinesisch und die einstellige englische Ausbildung (En -&gt; En) haben die größte Leistungsunterschiede, während das deutsche Training normalerweise die kleinsten Unterschiede hat.
- FunQL über Performs die anderen drei Bedeutungsdarstellungen, und SQL führt zu dem schlechtesten Leistungsresultat.</sample>
    <sample id="664">Andere Ergebnisse und Erkenntnisse (Abschnitt 4 im Papier)

- Enc-Dec (m75) über Performs vorherige Arbeiten oder erreicht vergleichbare Resultate.
- Das Vordrucken auf der englischen NL kann die Leistung von Few-Shot erheblich steigern.
- Multilinguale LLMs (Codex &amp; BLOOM) sind noch unzureichend für die Übersetzung zwischen Sprachen.
- Die Transferlearning in Chinesisch und die einstellige englische Ausbildung (En -&gt; En) haben die größte Leistungsunterschiede, während das Deutsche normalerweise die kleinsten hat.
- FunQL über Performs die anderen drei Bedeutungsdarstellungen, und SQL erreicht die schlechtesten Leistungen.</sample>
    <sample id="665">Wir haben XSemPLR erstellt, eine vereinheitlichte Benchmark-Studie für die multilinguale semantische Analyse mit mehreren natürlichen Sprachen und Bedeutungsdarstellungen. Wir haben eine umfassende Benchmark-Studie an drei repräsentativen Typen multilingualer Sprachmodelle durchgeführt. Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Ausbildung die beste Leistung liefert, während multilingual LLMs noch nicht in der Lage sind, multilinguale Semantik-Aufgaben zu bewältigen. Darüber hinaus zeigt der Leistungsunterschied zwischen monolingualer Ausbildung und multilingueler Transferlerning als noch bedarfsvoll zu sein.</sample>
    <sample id="666">- Wir haben XSemPLR erstellt, eine vereinheitlichte Benchmark-Stelle für die multilinguale semantische Analyse mit mehreren natürlichen Sprachen und Bedeutungsdarstellungen.
- Wir haben eine umfassende Benchmark-Studie an drei repräsentativen Typen von multilingalen Sprachmodellen durchgeführt.
- Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Schulung die beste Leistung liefert, während bemerkenswerte multilingrale LLMs noch untauglich sind, um über die Sprachunterschwelle hinaus zu arbeiten. Darüber hinaus zeigt der Leistungsunterschied zwischen monolingualer Schulung und multilingualer Transferlernunterschwelle als bedeutsam zu sein.</sample>
    <sample id="667">Die Arbeiten, die bereits durchgeführt wurden, sind die parameter-basierte Wassermarkierung, die lexikalische Wassermarkierung und die adversarial-basierte Wassermarkierung.</sample>
    <sample id="668">Nein, sie sind noch nicht ausreichend für CLSP.</sample>
    <sample id="695">Die Methode verwendet eine Permutation, um die Mehrdeutigkeit zu überwinden.</sample>
    <sample id="696">Die Fairness wird definiert, indem die Auswirkungen der Anwendung des Modells auf eine Gruppe von Menschen analysiert werden.</sample>
    <sample id="697">The speaker's name is not provided in the image.</sample>
    <sample id="698">The answer is Koustuv Sinha.</sample>
    <sample id="699">The answer is Myra Cheng.</sample>
    <sample id="700">Tropikalismus definiert Gruppen nur nach ihrem Identitäten.</sample>
    <sample id="701">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen erstellt, indem sie die Top-Worte extrahierten.</sample>
    <sample id="702">P-CXMI</sample>
    <sample id="703">Der Unterschied zwischen DrBERT und ChuBERT ist, dass DrBERT vonscratch (von Grund aus) trainiert wurde, während ChuBERT auf einem bestehenden vortrainierten Modell basiert.</sample>
    <sample id="751">Drei</sample>
    <sample id="752">Iterative Transfer Learning (IT) is a process where a model is trained on a new dataset and then fine-tuned on the same dataset multiple times. This process is repeated until the model reaches a desired level of performance.</sample>
    <sample id="753">The goal of the dataset is to resolve indirect expressions by entity selection.</sample>
    <sample id="754">Ein Angreifer kann Modellparameter über einen EaaS extrahieren, indem er die Abhängigkeit zwischen den Eingabe- und Ausgabedaten exploitiert.</sample>
    <sample id="755">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="756">Six annotators were used to create the original dataset.</sample>
    <sample id="757">Die Autoren sind an der University of Washington, Carnegie Mellon University und dem Allen Institute for AI.</sample>
    <sample id="758">Bart und Lisa Homer kamen und schnauften.</sample>
    <sample id="759">Die Technologie der Dialogsysteme hat sich in den letzten Jahrzehnten erheblich weiterentwickelt.</sample>
    <sample id="760">Wir müssen die Akzeptanz der Modelle über das gesamte Kontextfenster bewerten, um zu sehen, ob sie stabil sind.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat in 7 Datensätzen zu einem Leistungsverlust im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="762">Nein, die Annotatoren kennen die Entität nicht im Voraus.</sample>
    <sample id="763">Wertungen basierend auf der Leitfaden-Prüfung, der Lesbarkeit und der Übersetzungstiefe wurden verwendet.</sample>
    <sample id="764">Ja, die Regression beeinträchtigt die Generalisierung auf bestimmte NER-Typen.</sample>
    <sample id="765">Positionalität ist für NLP wichtig, weil es die Reihenfolge von Wörtern in einem Satz berücksichtigt. Dies ist notwendig, um die Bedeutung korrekt zu interpretieren und zu generieren.</sample>
    <sample id="766">LLMs wie BLOOM wurden durch Adapter oder eine vollständige Feinabstimmung angepasst.</sample>
    <sample id="767">Das Modell, das verwendet wird, ist der Roberta-Base.</sample>
    <sample id="768">Die aktuellen Testsets, die zur Bewertung der PaLM-Fähigkeiten verwendet wurden, sind die WMT’21 und WMT’22.</sample>
    <sample id="769">Die Autoren haben schließlich zwei Empfehlungen vorgeschlagen.</sample>
    <sample id="770">Der Gewinn der vorgeschlagenen Methode gegenüber der stärksten Baseline beträgt 1.5.</sample>
    <sample id="771">Shuheng Liu</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz der Studie können alsBenchmark verwendet werden.</sample>
    <sample id="773">In der Arbeit werden 3 kleineren Modell experimentiert.</sample>
    <sample id="774">Die OFA (One For All) ist das Modell, das als Basismodell für die Untersuchung der multimodalen Unterrichtsabstimmung verwendet wird.</sample>
    <sample id="833">Die Autoren gehören an Stanford University.</sample>
    <sample id="834">Die Autoren gehören an der Stony Brook University.</sample>
    <sample id="835">The image does not provide specific information about the language pairs that were studied in the research. It focuses on the overall approach and contributions of the study, such as evaluating translation capabilities with best practices of the MT community, but it does not mention any particular language pairs.</sample>
    <sample id="836">The answer is Shangbin Feng.</sample>
    <sample id="837">SARI, BLEU, BS-P und FRE</sample>
    <sample id="838">53 der 62 verschiedenen Aufgaben in MultiInstruct werden für Training und Tests verwendet.</sample>
    <sample id="839">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="840">The authors experimented on the AG News, MIND, SST2, Enron Spam and WikiText datasets.</sample>
    <sample id="876">NACHOS is a pre-training strategy for language models.</sample>
    <sample id="877">The answer is David Vil Torres.</sample>
    <sample id="878">Die Strategie der Selektion von zwei zufälligen Prompts für jede Phrase hat einen großen Einfluss auf die Qualität der Übersetzung.</sample>
    <sample id="879">Die Autoren gehören an der Carnegie Mellon University.</sample>
    <sample id="880">Die 5 Anweisungen der Expert*innen lauten:

1. Lassen Sie die Verhältnisse des Bildes erhalten.
2. Fügen Sie dem Bild einen Hintergrund hinzu.
3. Ändern Sie die Farbe des Hintergrunds.
4. Ändern Sie die Farbe des Bildes.
5. Fügen Sie dem Bild ein Objekt hinzu.</sample>
    <sample id="881">Die Autoren schlagen die Nutzung von Human-Studien und Modellen zur Nutzung von Informationen aus mehreren Quellen vor.</sample>
    <sample id="882">Prompting PalM für Übersetzung: Strategien und Leistung bewerten

Das Google-Logo, bestehend aus einem Farbenblock in den Farben blau, roter, gelben, grüner und blauen, befindet sich im linken oberen Teil des Bildes. Neben dem Logo steht der Titel "Prompting PalM for Translation" (Prompting PalM für Übersetzung) in schwarzem Text. Darunter werden verschiedene Strategien zur Anwendung von PalM (Prompting Large Model) für Übersetzung bewertet.

Im rechten oberen Teil des Bildes befindet sich ein lachender emoji mit einem Sonnenschein im Hintergrund. Neben dem emoji steht ein Text in einemThought-Bubble, der lautet: "Can you translate this for me please?" (Kannst du das für mich übersetzen, bitte?).

Unter dem Titel sind die Namen von Personen aufgelistet: David Vil Torres, Markus Freitag, Colin Cherry, Jamrung Lue und George Foster. Jeder Name befindet sich in einem separatenThought-Bubble.

Im unteren linken Teil des Bildes steht "ACL 2023" (ACL 2023) in schwarzem Text.</sample>
    <sample id="883">PalLM: Wege Sprachmodell

• Chowdery et al., 2022
• arXiv:2204.02311.
• 540 Billion Parameter.
• Trainiert auf 780 Billion Tokens.
• Dichter aktiviert.
• 6144 TPU v4 Chips.
• SOTA in hundert Benchmark-Sätzen.
• 10 Billion Parameter.

[Quelle: Google]

Dieses Modell ist ein fortschrittsgemäßer Sprachgenerationsmodell, das auf einem großen Datensatz von 780 Billion Tokens trainiert wurde. Es verfügt über 540 Billion Parameter und ist auf 6144 TPU v4 Chips trainiert worden. Das Modell ist 10 Billion Parameter stark und erreicht momentan das führende Niveau in verschiedenenBenchmark-Sätzen.</sample>
    <sample id="884">PalM: Wege zu einem Sprachmodell

• Chowdery et al., 2022
• arXiv:2204.02311.
• 540 Billion Parameter.
• Trainiert auf 780 Billion Tokens.
• Densiv aktiviert.
• 6144 TPU v4 Chips.
• SOTA in hundert Benchmarks.
• 62 Billion Parameter.

Die PalM-Modell ist ein fortschrittsgemäßer Sprachmodell, das auf der Arbeit von Chowdery et al., 2022 basiert und im arXiv unter der Referenz arXiv:2204.02311 abgebildet wird. Es verfügt über 540 Billion Parameter und wurde auf 780 Billion Tokens trainiert. Das Modell ist densiv aktiviert und nutzt 6144 TPU v4 Chips, um als Standard (SOTA) in verschiedenenBenchmarktests führend zu sein. Es enthält insgesamt 62 Billion Parameter.</sample>
    <sample id="885">Unsere Beiträge:

• Erstes systematisches Studium von LLM-Prompting für MT.
• Evaluieren der Übersetzungsfähigkeiten sowohl durch Selektionsstrategien als auch durch die besten übersetzten Arbeiten des MT-Communities.
• Latest test sets (vermeiden von Test/Train-Overlap und Übertrennung auf recent data).
• Vergleich mit den neuesten WMT-Systemen (bessere Korrelation mit menschlichen Urteilen).
• Expert-basierte menschliche Evaluation (robuster als Crowdsourcing).

Empfehlungen für Selektionsstrategien</sample>
    <sample id="886">Unsere Beiträge:

• Erstes systematisches Studium von LLM-Prompting für MT.
• Evaluieren der Übersetzungskapazitäten sowohl unter Verwendung des Kandidatenpools als auch unter Verwendung von Selektionsstrategien.
• Evaluieren der Übersetzungskapazitäten mit den besten übersetzten Praktiken der MT-Community:
- Neueste Testsets (vermeiden Test/train-Overlap und Übertrennung auf recent training data)
- Vergleich zu recent WMT-Untersmissionen (SOTA-Systeme, die recent training data verwenden)
- Bessere MT-Metrisen (besserer Korrelation mit menschlichen Urteilen)
- Expertenbasierte menschliche Evaluation (robuster als Crowdworkers)
• Empfehlungen für Selektionsstrategien für Prompts</sample>
    <sample id="887">Unsere Beiträge:

• Erstes systematisches Studium von LLM-Prompting für MT.
• Evaluieren der Übersetzungskapazitäten sowohl durch die Kandidaten als auch durch Selektionsstrategien.
• Evaluieren der Übersetzungskapazitäten mit den besten üppigen Praktiken der MT-Community:
- Neueste Testsets (vermeiden Test/Training-Overlap und Übertrennung auf recent training data)
- Vergleich zu den neuesten WMT-Systemen (bessere Korrelation mit menschlichen Urteilen)
- Expertenbasierte menschliche Evaluation (robuster als Crowdworkers)
• Empfehlungen für Selektionsstrategien für Prompts

Google</sample>
    <sample id="888">Unsere Beiträge:

• Erstes systematisches Studium von LLM-Prompting für MT.
• Evaluieren der Übersetzungskapazitäten sowohl im Kandidatenpool als auch bei der Selektionsstrategie.
• Evaluieren der Übersetzungskapazitäten mit den besten üppigen Praktiken der MT-Community:
- Neueste Testsets (vermeiden Test/Training-Overlap und Übertrennung auf Evaluationsschwelle)
- Vergleich mit den neuesten WMT-Unterbewerben (mithilfe von recent training data)
- SOTA-MT-Metriken (bessere Korrelation mit menschlichen Urteilen)
- Expertenbasierte menschliche Evaluation (robuster als Crowdworkers)
Empfehlungen für die Selektionsstrategien für Prompts</sample>
    <sample id="889">Prompte haben einen großen Einfluss auf die Übersetzungsgüte

- Wählen zwei zufällige Prompte für jede Phrase.
- Berechnen BLEURT für jedes Phrase-Prompt-Paar.
- Die Mehrheit der Phrasen (516 von 1000) zeigt eine Differenz von mehr als 1 BLEURT-Punkt an.
- Die Differenz kann bis zu 40 BLEURT-Punkte betragen!</sample>
    <sample id="890">Prompte haben einen großen Einfluss auf die Übersetzungsgüte. Wählen Sie zwei zufällige Prompte für jede Phrase. Computieren Sie BLEURT für jedes Phrase-Prompt-Paar. Die Mehrheit der Phrasen (516 von 1000) zeigt eine Differenz von mehr als 1 BLEURT-Punkt an. Die Differenz kann bis zu 40 BLEURT-Punkte betragen!</sample>
    <sample id="891">Prompt have a big impact on translation quality

- Wählen Sie zwei zufällige prompts für jede Phrase.
- Berechnen Sie BLEURT für jedes prompt-Phrase-Paar.
- Die Mehrheit der Phrasen (516 von 1000) zeigt einen Unterschied von mehr als 1 BLEURT-Punkt an.
- Der Unterschied kann bis zu 40 BLEURT-Punkte betragen!</sample>
    <sample id="892">Polizeiwarnden alarmieren die Polizei, die mit mehreren Streifenwagen ankommen.</sample>
    <sample id="893">Polizeiwarnten sich nach sich. Polizei war eingeschritten, nachdem sie Beweise des Verhaltens hatten.</sample>
    <sample id="894">Polizeiwarnden alarmieren die Polizei, die mit mehreren Streifenwagen ankommen.</sample>
    <sample id="895">Polizeiwarnden alarmieren die Polizei, mit mehreren Polizisten anrücken.</sample>
    <sample id="896">Polizeiwarnden alarmieren die Polizei, die mit mehreren Streifenwagen ankommen.</sample>
    <sample id="897">Experimenteller Erfolg

- Beispielseligkeit ist wichtiger als Ähnlichkeit an der Quelle.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM nahezu so gut wie Google Translate.

Einblicke aus MQ:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeit allgemein niedriger.
    - Dominiert durch "Genauigkeit/Omission".
- "Stil/Aufwärts" allgemein niedriger für PaLM.</sample>
    <sample id="898">Experimenteller Erfolg

• Beispielqualität ist wichtiger als Ähnlichkeit an der Quelle.
• Spezialisierte SOTA-Systeme haben einen substantiellen Vorteil.
• PaLM nahezu so gut wie Google Translate.

Einblicke aus MQM

• Fluide Art von PaLM vergleichbar mit SOTA.
• Genauigkeit allgemein niedriger.
    • Dominiert durch "Genauigkeit/Omission".
    • "Stil/Aufwärts" allgemein niedriger für PaLM.
Google</sample>
    <sample id="899">Experimenteller Erfolg

• Beispielqualität ist wichtiger als Ähnlichkeit an der Quellsentence.
• Spezialisierte SOTA-Systeme haben einen substantiellen Vorteil.
• PaLM nahezu so gut wie Google Translate.

Einblicke aus MQM:

• Fluide Art von PaLM vergleichbar mit SOTA.
• Genauigkeit allgemein niedriger.
    • Dominiert durch "Genauigkeit/Omission".
    • "Stil/Ahnung" allgemein niedriger für PaLM.</sample>
    <sample id="900">Experimenteller Erfolg

- Beispielseligkeit ist wichtiger als Ähnlichkeit an der Quelle.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM nahezu so gut wie Google Translate.

Einblicke aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeit allgemein niedriger.
    - Dominiert durch "Genauigkeit/Omission".
    - "Stil/Ausdrucksfehler" allgemein niedriger für PaLM.</sample>
    <sample id="901">Experimenteller Erfolg

- Beispielseligkeit ist wichtiger als Ähnlichkeit an der Quellsatz.
- Spezialisierte SOTA-Systeme haben einen substantiellen Vorteil.
- PaLM nahe an Google Translate.

Einblicke aus MQM:

- Fluideität von PaLM vergleichbar zu SOTA.
- Genauigkeit allgemein niedriger.
    - Dominiert durch "Genauigkeit/Omission".
- "Stil/Ahnung" allgemein niedriger für PaLM.</sample>
    <sample id="902">Experimentelle Ergebnisse

• Beispielqualität ist wichtiger als Ähnlichkeit an der Quellsentence.
• Spezialisierte SOTA-Systeme haben einen substantiellen Vorteil.
• PaLM nahezu so gut wie Google Translate.

Einblicke aus dem MQM

• Die Fluideität von PaLM ist vergleichbar mit SOTA.
• Genauigkeit allgemein niedriger.
    • Dominiert durch "Genauigkeit/Omission".
    • "Stil/Ausdrucksfehler" allgemein niedriger für PaLM.

Google Logo im unteren linken Ecke.</sample>
    <sample id="903">Experimenteller Erfolg

• Beispielqualität ist wichtiger als Ähnlichkeit an der Quelle.
• Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
• PaLM nahezu so gut wie Google Translate.

Einblicke aus MQM:

• Fluide Art von PaLM vergleichbar mit SOTA.
• Gen般更低准确率。
• Dominiert durch "Gen般更低准确率".
• "Stil/Ahnlich" normalerweise für PaLM tiefer.</sample>
    <sample id="904">Experimenteller Erfolgsgrad

• Beispielsweise ist die Qualität wichtiger als die Ähnlichkeit an der Quellsatz.
• Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
• PaLM nahezu so gut wie Google Translate.

Einblicke aus MQM:

• Die Fluideität von PaLM ist vergleichbar mit SOTA.
• Genauigkeit allgemein niedriger.
• Dominiert durch "Fehler/Omission".
• "Stil/Aufwärts" allgemein niedriger für PaLM.</sample>
    <sample id="905">Experimenteller Erfolg

• Beispielqualität ist wichtiger als Ähnlichkeit an der Quelle.
• Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
• PALM nahezu so gut wie Google Translate.

Einblicke aus MQ:

• Die Fluideität von PALM ist vergleichbar mit den SOTA-Systemen.
• Genauigkeit allgemein niedriger.
• Dominiert durch "Genauigkeit/Omission".
• "Stil/Ahnung" allgemein niedriger für PALM.</sample>
    <sample id="906">Danke</sample>
    <sample id="907">Weaker Than You Think: Eine kritische Analyse von schwach überwachtem Lernen

Dawei Zhu1, Xiaoyu Shen2, Marius Mosbach3, Andreas Stephan3, Dietrich Klakow1

1 Saarland University, 2 Amazon Alexa, 3 University of Vienna

61. ACL 2023</sample>
    <sample id="908">Weaker Than You Think: Eine kritische Betrachtung von schwach überwachtem Lernen

Dawei Zhu¹, Xiaoyu Shen², Marius Mosbach³, Andreas Stephan³, Dietrich Klakow¹

¹ Saarland University, ² Amazon Alexa, ³ University of Vienna

61. ACL 2023</sample>
    <sample id="909">WarumWeakly überwachtes Lernen?</sample>
    <sample id="910">WarumWeakly überwachte Lernverfahren?</sample>
    <sample id="911">WarumWeakly überwachte Lernverfahren?

• Schwache Überwachung allgemein alleviiert die Annotierungs-Schottengrenze.
• Aber noisylabels sind! 
• Noisememoization schadet der Generalisierbarkeit.
• Weakly überwachte Lernverfahren (WSL) 
• Trainieren Modelle, die gut generalisieren, obwohl sie 
• auf noisymehrdaten trainiert werden (nicht alle Annotierungen sind korrekt).</sample>
    <sample id="912">WarumWeakly überwachtes Lernen?</sample>
    <sample id="913">WarumWeakly überwachte Lernverfahren?</sample>
    <sample id="914">Eine gemeinsame Behauptung in jüngsteren WSL Arbeiten

"Wir trainieren Model nur mit schwach überwachten Daten und erreichen eine Genauigkeit von XX%."

Schwach überwachte Trainingsdaten (rau)</sample>
    <sample id="915">Eine gemeinsame Behauptung in jüngsteren WSL Arbeiten

"Wir trainieren Model nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."

Weakly labeled training data (noisy)
Cleanly labeled test data (clean)</sample>
    <sample id="916">Eine gemeinsame Behauptung in jüngsteren WSL Arbeiten

"Wir trainieren Model nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX% 😲"

Nur schwarz-weißes Bild.</sample>
    <sample id="917">Eine gemeinsame Behauptung in jüngster WSL Arbeiten

Wir trainieren Model nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%

Schwach überwachte Trainingsdaten (lauter)  
Bild 1: Schwach überwachte Trainingsdaten (lauter)  
Bild 2: Saubere validierungsdaten (sauber)  
Bild 3: Saubere Testdaten (sauber)</sample>
    <sample id="918">Unsere Forschungsfragen

1. Ist eine saubere Validierungsdatenbank notwendig?
2. Wie viele saubere Proben benötigen WSL-Verfahren?
3. Wie können die verfügbaren sauberen Proben effizienter verwendet werden?</sample>
    <sample id="919">Our research questions</sample>
    <sample id="920">RQ1: Hauptergebnisse

Die Grafik zeigt die relative Leistungsverbesserung (in %) über 7 Wochen, nach der Implementierung von Label-Noise-Resampling-Techniken. Sie vergleicht die Leistungen von Modellen, die mit starken Labels (orange), schwachen Labels (purple), oder keinerLabels (blue) trainiert wurden.

Die Grafik zeigt, dass die Modelle, die mit schwachen Labels trainiert wurden, in der Regel eine bessere relative Leistungsverbesserung erreichten als die Modelle, die mit starken Labels trainiert wurden. Insbesondere die Modelle, die mit den Techniken FT_w, BOND und COSINE trainiert wurden, zeigten eine signifikante Verbesserung im Vergleich zu Modellen, die mit starkenLabels trainiert wurden.

Es ist zu beachten, dass die Grafik standardisierte Werte verwendet, um die relative Leistungsverbesserung zu messen. Die Grafik zeigt auch, dass die Leistungsverbesserung variabel war, insbesondere bei Modellen, die mit schwachenLabels trainiert wurden. Trotz dieser Variabilität scheinen die Modelle, die mit schwachenLabels trainiert wurden, in der Regel eine bessere relative Leistungsverbesserung zu erzielen als die Modelle, die mit starkenLabels trainiert wurden.</sample>
    <sample id="921">RQ1 Main findings

Validation on weak labels Validation on validation set No validation Validation on clean labels
FT_w. BOND COSINE MLC L2R</sample>
    <sample id="922">RQ1: Hauptergebnisse

Die Grafik zeigt die relative Leistungsverbesserung (in %) an, indem sie die Leistungen von Modellen mit schwachen etablierten Labeln (orange) und Modellen mit rein zufällig ausgewählten etablierten Labeln (purple) vergleicht. Es werden verschiedene Methoden zur etablierenden Label-Selektion ermittelt, darunter FT_w, BOND, COSINE, MLC und L2R.

Die Grafik zeigt, dass die etablierten Label-Selektionsmethoden in der Regel eine Verbesserung der Modellleistung erreichen, insbesondere bei den Methoden FT_w, BOND und COSINE. Die Methode MLC scheint keine signifikante Verbesserung zu erreichen, während die Methode L2R eine relativ geringe Verbesserung erreicht.

Es ist wichtig zu beachten, dass die etablierten Label-Selektionsmethoden variieren können und dass die besten Methoden abhängig sind von den spezifischen Anwendungsfällen und Datensätzen.</sample>
    <sample id="923">RQ1 Main findings

Validation on weak labels Validation on validation set No validation Validation on clean labels

FT_w. BOND COSINE MLC L2R</sample>
    <sample id="924">RQ1 Main findings

Validation on weak labels Validation on clean labels No validation (Random Selection)

FT_w. BOND COSINE MLC L2R</sample>
    <sample id="925">Accuracy 85 80 75 Weak labels 5 10 20 30 40 50 All validation FTw COSINE L2R BONDO MLC</sample>
    <sample id="926">Accuracy 85 80 75 70 65 60 55 50 5 10 20 30 40 50 All Validation Weak labels FT_w COSINE L2R BONDO MLC</sample>
    <sample id="927">WSL-Verfahren profitieren von mehr sauberen Validierungsstichproben!</sample>
    <sample id="928">FTw FTc COSINE L2R MLC Adapterc</sample>
    <sample id="929">FTw
FTc
COSINE
L2R
MLC
Weak labels
All
FTw
FTc
LoRAc
BiFiT
Adapterc</sample>
    <sample id="930">N=10 clean samples per class N=30 samples per class Before CFT After CFT COSINE ER FT+ Clean Only</sample>
    <sample id="931">N=10 clean samples per class N=30 samples per class Before CFT After CFT AccuracyAccuracy</sample>
    <sample id="932">N=10 clean samples per class N=30 samples per class Before CFT After CFT</sample>
    <sample id="933">N=10 clean samples per class N=30 clean samples per class Before After Continuous fine-tuning (CFT) eliminates performance gaps between WSL approaches. No need to use complicated WSL methods FT performs equally well.</sample>
    <sample id="934">Zusammenfassung
Neueste WSL-Annäherungen
• Erfordern saubere Stichproben.
• Übertreiben Sie ihre Praktizität.
Unsere Empfehlungen
• Berichten Sie die Modellauswahlkriterien.
• Geben Sie Few-Shot-Lernansätze als Baselines an.
• Anwenden Sie stets die ständige Feinabstimmung (FT).</sample>
    <sample id="935">Kontrolle

Neueste WSL-Annäherungen
- Anforderung nach sauberen Stichproben.
- Überestimation der Praktizität.

Unsere Empfehlungen
- Berichten Sie die Modellauswahlkriterien.
- Geben Sie Few-Shot-Lernansätze als Baselines an.
- Anwenden Sie stets die ständige feinkalibrierung (CFT).</sample>
    <sample id="936">Kürzlich sind WSL-Annäherungen vorgestellt worden, die saubere Proben benötigen und ihre Praktizität überbewerten. Unsere Empfehlungen bestehen darin, die ModellAuswahlkriterien zu berichten, Few-Shot-Lernansätze als Baselines zu verwenden und stets continuierliche Feinabstimmung (CFT) anzuwenden.</sample>
    <sample id="937">Zusammenfassung
Neueste WSL-Abläufe
• Anreiquisieren von sauberen Mustern.
• Übertreiben Sie ihre Praktizität.
Unsere Empfehlungen
• Berichten Sie die Modellauswahlkriterien.
• Geben Sie Few-Shot-Lernansätze als Baselines an.
• Anwenden Sie stets die ständige Feinabstimmung (FT).</sample>
    <sample id="938">Kontrolle

Recent WSL approaches
- Anforderung von saubereren Stichproben.
- Übert��tehung der Praxis.
Our recommendations
- Berichterstatten über die Modellauswahlkriterien.
- Geben Few-Shot-Lernansätze als Baselines an.
- Immer ständige fein-tuning (CFT) anwenden.</sample>
    <sample id="939">Gemeinsame Bewertungsmethoden für Dialogsysteme sind die Comparative Evaluation und die Human Evaluation.</sample>
    <sample id="940">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="941">Um das Beispiel zu verstehen, benötigt man das Hintergrundwissen, dass Servin ein Richter ist und Kea ein Bäcker.</sample>
    <sample id="942">Ja, der Code ist verfügbar auf GitHub.</sample>
    <sample id="943">Ja, die Annotatoren für NLPositionality sind in Bezug auf jede demographische Gruppe ausgewogen.</sample>
    <sample id="944">Um festzustellen, ob die Modelle dieselben Empfindungen gegenüber den Sätzen teilen, wurden die Kontextsätze auf verschiedene Weisen perturbiert.</sample>
    <sample id="945">Eine dimensionale Bewertung ist eine Art von Bewertung, bei der die Werte auf einer Skala von 1 bis 5 dargestellt werden.</sample>
    <sample id="946">The authors belong to the University of Science and Technology of China, Microsoft Research Asia, and Beijing Haotong University.</sample>
    <sample id="947">Die Form des Prompts ist wichtig, wenn die Übersetzung nicht nur die Bedeutung reproduzieren muss, sondern auch die Grammatik und Stil des Zielsprachens einbeziehen muss.</sample>
    <sample id="978">Turnturm, Dialog Likert, Dialog Likert</sample>
    <sample id="979">There are six authors involved in the work.</sample>
    <sample id="980">Ein guter Planer sollte die Fähigkeit haben, spezifische Ziele mit mehreren Facetten zu überprüfen.</sample>
    <sample id="981">Die Anzahl der Autoren, die an der Arbeit beteiligt sind, beträgt neun.</sample>
    <sample id="982">The presenter's name is Vasudha Varadarajan.</sample>
    <sample id="983">The authors belong to the University of Warsaw.</sample>
    <sample id="1021">Die häufigsten Fehler von PaLM sind "Accuracy/Omission" und "Style/Awesome" allgemein.</sample>
    <sample id="1022">Das Bild zeigt eine Präsentationsfolie mit einem Titel "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems" und den Namen der Autoren Sarah E. Finch, James D. Finch, und Jinho D. Choi. Es gibt auch die Logos von Emory University, dem Emory NLP Lab und dem Alexa Research Lab.</sample>
    <sample id="1023">Das Video zeigt einen Titelbild, das die Evaluierung des Standes der Kunst in Chats orientierten Dialogsystemen betont. Es zeigt auch die Autoren Sarah E. Finch, James D. Finch und Jinho D. Choi. Es zeigt auch die Logos von Emory University, Emory NLP und Alexa Research Lab.</sample>
    <sample id="1024">Das Video zeigt ein Präsentationsblatt mit einem blauen Hintergrund und einem weißen Rand. Im rechten oberen Ecke befindet sich ein kleines Bild von einer Frau, die ein schwarzes Oberteil trägt. Das Titelbild der Präsentation lautet "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems" und zeigt die Namen Sarah E. Finch, James D. Finch und Jinho D. Choi. 

Unter dem Titel sind die Logos von Emory University, Emory NLP (Emory Natural Language Processing) und Alexa Research Lab zu sehen.</sample>
    <sample id="1025">The image appears to be a slide from a presentation, likely related to a study or evaluation involving artificial intelligence (AI) and human interaction. The slide is titled "Comparative Evaluation" and includes the following elements:

1. **Title**: "Comparative Evaluation"
2. **Institutional Affiliation**: The slide is associated with Emory University and mentions Alexa, which could refer to Amazon's virtual assistant.
3. **Visual Elements**:
   - There are two sets of speech bubbles connected to cartoon-like representations of a person and an AI character.
   - The left set has blue speech bubbles connected to a person and a blue AI character.
   - The right set has purple speech bubbles connected to a person and a purple AI character.

### Detailed Description:

#### Title:
- The title "Comparative Evaluation" suggests that the slide is part of a larger discussion or study comparing different aspects or outcomes of interactions between humans and AI systems.

#### Institutional Affiliation:
- The presence of "Emory University" indicates that this research or presentation is affiliated with this academic institution.
- The mention of "Alexa" implies that the study might involve Amazon's virtual assistant, Alexa, possibly in the context of voice-activated devices or AI-driven conversational interfaces.

#### Visual Elements:
- **Person and AI Characters**:
  - On the left side, there is a cartoon-like representation of a person with blue speech bubbles connected to it. This person is also connected to a blue AI character, suggesting a dialogue or interaction between the human and the AI.
  - On the right side, there is another cartoon-like representation of a person with purple speech bubbles connected to it. This person is also connected to a purple AI character, indicating another dialogue or interaction scenario.
  
- **Speech Bubbles**:
  - The blue speech bubbles on the left suggest one type of communication or response pattern.
  - The purple speech bubbles on the right suggest a different communication or response pattern.

### Analysis:
The slide seems to be setting up a framework for evaluating how humans interact with AI systems, possibly focusing on differences in communication patterns, effectiveness, user experience, or other relevant metrics. The use of color-coded speech bubbles helps distinguish between different scenarios or conditions being compared.

### Conclusion:
This slide is likely part of a broader study or presentation aimed at understanding and comparing human-AI interactions using Amazon's Alexa as a case study. The visual elements help illustrate the comparative nature of the evaluation, highlighting the different ways humans and AI systems communicate and interact.</sample>
    <sample id="1026">Likert Rating Evaluation</sample>
    <sample id="1027">Dimensionen der Dialogqualität

Die Dialogqualität ist ein wichtiger Aspekt, um effektive und effiziente Kommunikation zu gewährleisten. Es umfasst mehrere wichtige Dimensionen, die dazu beitragen, einen guten Dialog zu fördern. Eine der Hauptdimensionen ist die Relevanz. Eine relevante Kommunikation ist jene, die sich auf das aktuelle Thema und die Bedürfnisse des Gesprächspartners konzentriert. Sie sollte auch relevant für die jeweilige Situation und den aktuellen Kontext sein.

Eine weitere wichtige Dimension der Dialogqualität ist die Konsistenz. Eine konsistente Kommunikation ist jene, die stets dieselben Standards und Regeln beibehält. Sie sollte auch stets den gleichen Tones und Stileinsprache verwenden. Eine konsistente Kommunikation ist für die Aufrechterhaltung einer starken Beziehung und eine effektive Kommunikation von Crucial.

Eine weitere wichtige Dimension der Dialogqualität ist die emotionalen Verstehensfähigkeit. Eine emotionales Verstehensfähigkeit ist jene, die die Fähigkeit hat, die Emotionen und Gefühle des anderen zu verstehen und zu empathisieren. Sie sollte auch die Fähigkeit haben, die Bedürfnisse und Wünsche des anderen zu verstehen und zu berücksichtigen. Eine emotionales Verstehensfähigkeit ist für die Aufrechterhaltung einer starken Beziehung und eine effektive Kommunikation von Crucial.

Insgesamt sind die Relevanz, die Konsistenz und die emotionales Verstehensfähigkeit wichtige Dimensionen der Dialogqualität. Sie fördern eine effektive und effiziente Kommunikation und helfen, eine starke Beziehung aufzubauen und zu erhalten.</sample>
    <sample id="1028">Eine Likert-Bewertung der Relevanz der Chatbot-Antworten.</sample>
    <sample id="1029">Evaluierung der Relevanz von Bots-Antworten (ABC-Eval)</sample>
    <sample id="1030">Annotating Behaviors in Chat (ABC-Eval)</sample>
    <sample id="1031">ABC-Eval Verhaltensweisen</sample>
    <sample id="1032">ABC-Eval Verhaltensweisen</sample>
    <sample id="1033">ABC-Eval Verhaltensweisen</sample>
    <sample id="1034">ABC-Eval Verhaltensweisen

Die Grafik zeigt die verschiedenen Verhaltensweisen, die bei der Evaluation von Kommunikation zwischen Partnern bewertet werden können. Sie sind in vier Kategorien unterteilt: Kohärenz, Konsistenz, Kenntnis und Emotionale Verstehensfähigkeit.

Die Kategorie "Kohärenz" umfasst drei Aspekte:
- Ignoring Partner (Partner ignorieren)
- Irrelevant (irrelevantes Material)
- Incorrect Fact (fehlende oder falsche Informationen)

Die Kategorie "Konsistenz" enthält zwei Aspekte:
- Self Contradiction (eigene Widersprüche)
- Partner Contradiction (Widersprüche zwischen Partnern)

Die Kategorie "Kenntnis" ist durch zwei Aspekte dargestellt:
- Incorrect Fact (fehlende oder falsche Informationen)
- Commonsense Violation (violaion der allgemein anerkannten Regeln oder Logik)

Die Kategorie "Emotionale Verstehensfähigkeit" umfasst zwei Aspekte:
- Empathetic Response (empathische Reaktion)
- Lack of Empathy (mangelnde Empathie)

Diese Verhaltensweisen können dazu verwendet werden, die Qualität und Effektivität der Kommunikation zwischen Partnern zu bewerten und zu verbessern.</sample>
    <sample id="1035">Experiments

* 4 Open-Domain Dialogue Models
* 100 Human-Bot Conversations per Model

ABC-Eval

* 300K
* 300K
* 300K</sample>
    <sample id="1036">Experimente

- 4 Dialog-Modell im Freien
- 100 menschliche-Bot-Konversationen pro Modell

ABC-Eval Turn Likert Dialog Likert Vergleich

Die Darstellung zeigt die verschiedenen Experimente, die durch das Emory University und Alexa aufgestellt wurden. Es werden 4 Dialog-Modelle im Freien verwendet, um 100 menschliche-Bot-Konversationen pro Modell zu sammeln. Das ABC-Eval, Turn Likert, Dialog Likert und Vergleich sind die verschiedenen Methoden, die verwendet wurden, um die Konversationen zu bewerten.</sample>
    <sample id="1037">Das Baseline-Evaluationsschema

Das Baseline-Evaluationsschema ist ein Werkzeug, das verwendet wird, um die Qualität von Dialogen zu bewerten. Es sieht verschiedene Aspekte wie konsistenz, emotionalen Verständnis, Grammatikalität, Relevanz und allgemeine Qualität in Betracht.</sample>
    <sample id="1038">Inter-annotator Agreement

Die Grafik zeigt die Kappa-Werte (Krippendorff Alpha) für verschiedene Evaluationskriterien in einem Dialogsystem. Die X-Achse zeigt die verschiedenen Evaluationskriterien an, und die Y-Achse zeigt die Kappa-Werte an. Es gibt drei Farben verwendet: Blau, Rot und Grün.

Die Grafik zeigt, dass die Kappa-Werte variieren, je nach Evaluationskriterium. Einige Kriterien, wie "Topic Jitter" und "Life Jitter", haben hohe Kappa-Werte, was bedeutet, dass die Annotatoren in Bezug auf diese Kriterien in Übereinstimmung sind. Andere Kriterien, wie "Turn Likert" und "Dialogue Likert", haben niedrigere Kappa-Werte, was bedeutet, dass die Annotatoren in Bezug auf diese Kriterien nicht so einstimmig sind.

Die Grafik zeigt auch, dass die Kappa-Werte sich über die verschiedenen Evaluationskriterien ändern. Einige Kriterien, wie "ABC-Eval" und "Comparative", haben höhere Kappa-Werte als andere Kriterien, wie "Quality Jitter" und "Emotional Jitter".

Die Grafik zeigt also, dass die Annotatoren in Bezug auf verschiedene Evaluationskriterien in unterschiedlicher Weise übereinstimmten. Einige Kriterien wurden besser bewertet als andere, und die Annotatoren stimmten in Bezug auf bestimmte Kriterien mehr überein als in Bezug auf andere Kriterien.</sample>
    <sample id="1039">Predictive Validity

Die Grafik zeigt die Gültigkeit von Prognosen (Predictive Validity) in verschiedenen Dialogsystem-Evaluation-Methoden. Es werden verschiedene Aspekte des Dialogs abgeglichen, wie z.B. Grammatik, Emotion, Empathie und Reaktionszeit. Die Grafik zeigt, dass die Gültigkeit der Prognosen in den verschiedenen Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Aspekten variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Grammatik in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Sprachen variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "ABC-Eval" amhighest zu sein, während sie in der Methode "Turn Likert" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Dialogue Likert" amhighest zu sein, während sie in der Methode "Comparative" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Comparative" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q&amp;A" in der Sprache "Deutsch" amlowest zu sein.

Die Grafik zeigt auch, dass die Gültigkeit der Prognosen in den verschiedenen Dialogsystem-Evaluation-Methoden variiert. Beispielsweise scheint die Gültigkeit der Prognosen in der Methode "Interactive Q&amp;A" in der Sprache "Englisch" amhighest zu sein, während sie in der Methode "Interactive Q</sample>
    <sample id="1040">Predictive Validität

Die Grafik zeigt die Prozentschwelle des Gültigkeitsgrades (R²) für verschiedene Aspekte der Sprachverarbeitung und -generierung. Es werden verschiedene Metrischken und Evaluiermethoden verwendet, um die Gültigkeit zu messen.

Die Grafik zeigt, dass die Gültigkeit in den Bereichen "Kontrolle", "CS-Controllen", "Irene-Tests", "Reaktionszeit" und "Antworten" relativ hoch ist, insbesondere im Bereich "Antworten". Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird auch festgestellt, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist.

Die Grafik zeigt auch, dass die Gültigkeit in den Bereichen "Empathie", "Antworten" und "Grammatik" relativ geringer ist. Es wird</sample>
    <sample id="1041">Incremental Validity

Die Grafik zeigt die Validität von verschiedenen Dialogsystemmetriken. Die x-Achse zeigt die Anzahl der Turne, die in einem Dialog verwendet wurden. Die y-Achse zeigt die Güte der Auswertung der Dialoge. Die Grafik zeigt, dass die Güte der Auswertung der Dialoge mit der Anzahl der Turne zunimmt. Das bedeutet, dass die Dialogsystemmetriken, die auf der x-Achse stehen, besser sind als diejenigen, die auf der y-Achse stehen.

Die Grafik zeigt auch, dass die Güte der Auswertung der Dialoge mit der Anzahl der Turne zunimmt, wenn die Dialoge emotionaler sind. Das bedeutet, dass die Dialogsystemmetriken, die auf der x-Achse stehen, besser sind als diejenigen, die auf der y-Achse stehen, wenn die Dialoge emotionaler sind.

Die Grafik zeigt auch, dass die Güte der Auswertung der Dialoge mit der Anzahl der Turne zunimmt, wenn die Dialoge relevanter sind. Das bedeutet, dass die Dialogsystemmetriken, die auf der x-Achse stehen, besser sind als diejenigen, die auf der y-Achse stehen, wenn die Dialoge relevanter sind.</sample>
    <sample id="1042">Incremental Validity

Die Grafik zeigt die "Incremental Validität" (Incremental Validity) und zeigt den Anteil an Qualität, der durch verschiedene Evaluationsmethoden erläutert wird. Es zeigt, dass die "ABC-Eval." (ABC Evaluation) einen hohen Anteil an Qualität explains (expliziert), gefolgt von "Turn Likert" (Turn Likert) und "Dialogue Likert" (Dialogue Likert).</sample>
    <sample id="1043">Incremental Validity

Die Grafik zeigt die Validität von verschiedenen Evaluationsmethoden in einem Dialogsystem. Die x-Achse zeigt die "ABC-Eval" an, die y-Achse zeigt den "Prozentualer Anteil der Qualität" an. Es gibt zwei Hauptlinien, eine in orange und eine in blau. Die orange Linie zeigt die "Redundant" und "Emotion" Evaluierungen, die blauen Linie zeigt die "Turn Likert" und "Dialogue Likert" Evaluierungen.

Die orange Linie beginnt bei einem "Prozentualen Anteil der Qualität" von 0,75 und steigt bis zu 0,95. Die blauen Linien beginnen beide bei einem "Prozentualen Anteil der Qualität" von 0,75. Die "Turn Likert" Evaluierung steigt bis zu 0,85, während die "Dialogue Likert" Evaluierung bis zu 0,95 steigt.

Die Grafik zeigt, dass die "Dialogue Likert" Evaluierung die höchste Validität hat, gefolgt von der "Turn Likert" Evaluierung. Die "Redundant" und "Emotion" Evaluierungen haben die geringste Validität.</sample>
    <sample id="1044">ABC-Eval Fehlertaten pro Modell</sample>
    <sample id="1045">ABC-Eval Fehlertaten pro Modell</sample>
    <sample id="1046">ABC-Eval Fehlertarife pro Modell</sample>
    <sample id="1047">ABC-Eval Fehlertaten von Modellen</sample>
    <sample id="1048">Die Autoren gehören an Emory University.</sample>
    <sample id="1049">CFT steht für "continuous fine-tuning".</sample>
    <sample id="1050">Die Arbeit beteiligen 8 Autoren.</sample>
    <sample id="1051">Eine data-driven, multilingual Exploration</sample>
    <sample id="1052">Translation depends on context We'll have to get rid of that mole.</sample>
    <sample id="1053">Translation depends on context Things could start to get dangerous if the ministers find out. We'll have to get rid of that mole.</sample>
    <sample id="1054">Übersetzung hängt von Kontext ab Could it be anything serious, Doctor? We'll have to get rid of that mole.</sample>
    <sample id="1055">Evaluating context-dependent translation is hard. Only a small portion of words depend on context.</sample>
    <sample id="1056">Evaluating context-dependent translation is difficult. Nur ein kleiner Teil der Wörter hängt von Kontext ab. - Korpusbasierte Metriken. Bestehende Methoden unterstützen begrenzte diskursive Phänomene und Sprachen.</sample>
    <sample id="1057">RQ1: Wann erfordert Übersetzung Kontext? RQ2: Wie gut bewältigen Modelle Übersetzungen, die Kontext abhängig sind?</sample>
    <sample id="1058">RQ1: When does translation require context? - Word-level context usage RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1059">Conditional Cross-Mutual Information (CXMI) • CXMI: messt, wie viel Kontext MT-Modeln geben, wenn sie einen Korpus verwenden</sample>
    <sample id="1060">Conditional Cross-Mutual Information (CXMI)</sample>
    <sample id="1061">Pointwise (P-)CXMI</sample>
    <sample id="1062">RQ1: Wann erfordert Übersetzung Kontext? - Kontextbedarf an Wortebene - Themenanalyse RQ2: Wie gut bewältigen Modelle Übersetzungen, die Kontext abhängig sind?</sample>
    <sample id="1063">RQ1: Wann erfordert eine Übersetzung Kontext? - Benutzung von Wortstelle im Kontext - Themenanalyse RQ2: Wie gut können Modelle Übersetzungen abhängig vom Kontext verarbeiten?</sample>
    <sample id="1064">Ideen wertvoll zu verbreiten</sample>
    <sample id="1065">Thematic analysis of high P-CXMI words 1. POS tags</sample>
    <sample id="1066">Thematic analysis of high P-CXMI words 1. POS tags Pronouns</sample>
    <sample id="1067">Thematic analysis of high P-CXMI words 1. POS tags 2. Vocabulary items - Pronouns - Verb form</sample>
    <sample id="1068">Avellile's mother was still asleep. Avellile went to school.</sample>
    <sample id="1069">Avellie's mother was still asleep. Avellie went to school.</sample>
    <sample id="1070">Sie weiß, wohin wir gehen. Ich nicht.</sample>
    <sample id="1071">RQ1: Wann erfordert Übersetzung Kontext?
- Kontextbedarf an Wortebene
- Themenanalyse
RQ2: Wie gut bewältigen Modelle Übersetzungen, die Kontext abhängig sind?
- Multilingual Discourse-Aware (MuDA) Benchmark</sample>
    <sample id="1072">Multilingual Discourse-Aware (MuDA) tagger

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis</sample>
    <sample id="1073">Multilingual Discourse-Aware (MuDA) tagger

Die Grafik zeigt die Häufigkeit von verschiedenen Sprachmerkmalen in verschiedenen Sprachen. Es gibt sechs Hauptkategorien: Pronouns, Verb form, Lexical cohesion, Formality, Ellipsis und MuDA tagger.

Die Grafik zeigt, dass die Häufigkeit von Pronouns in den Sprachen "fr", "de" und "es" amhighest ist, gefolgt von "it" und "ko". Die Häufigkeit von Verb form ist in "fr", "de" und "es" amhighest, gefolgt von "it" und "ko". Die Häufigkeit von Lexical cohesion ist in "fr", "de" und "es" amhighest, gefolgt von "it" und "ko". Die Häufigkeit von Formality ist in "fr", "de" und "es" amhighest, gefolgt von "it" und "ko". Die Häufigkeit von Ellipsis ist in "fr", "de" und "es" amhighest, gefolgt von "it" und "ko".

Die Grafik zeigt auch, dass die Häufigkeit von Pronouns, Verb form, Lexical cohesion, Formality und Ellipsis in "ko" amlowest ist.

Die Grafik zeigt auch, dass die Häufigkeit von MuDA tagger in "fr", "de" und "es" amhighest ist, gefolgt von "it" und "ko".</sample>
    <sample id="1074">MuDA benchmark

Eine Gruppe von Dokumenten wird in einem Prozess durch einen MuDA-Tagger analysiert. Der MuDA-Tagger verwendet spezifische Algorithmen, um die relevanten Informationen und Strukturen in den Dokumenten zu identifizieren und zu markieren. Danach werden die Ausgabe des MuDA-Tagers und die ursprünglichen Dokumente an ein Evaluationswerkzeug übermittelt.

Das Evaluationswerkzeug misst die Leistung des MuDA-Tagers basierend auf verschiedenen Metriken wie BLEU, COMET und F-measure. Es vergleicht die genaue Übereinstimmung zwischen den Markierungen des MuDA-Tagers und den manuellen Referenzmarkierungen. Dadurch wird bewertet, wie präzise und effizient der MuDA-Tagger ist, um relevantes Material in den Dokumenten zu identifizieren.

Nach der Evaluation werden die Ergebnisse des Evaluationswerkzeugs verwendet, um den MuDA-Tagger zu optimieren und zu verbessern. Dadurch wird versucht, die Genauigkeit und Effizienz des Prozesses zu steigern, um sicherzustellen, dass der MuDA-Tagger in Zukunft noch besser auf die Identifikation relevantes Materials in Dokumenten agiert.

Insgesamt dient das MuDA Benchmark als Werkzeug zur Überprüfung und Optimierung der Leistung von MuDA-Taggern in der Identifikation relevantes Materials in Dokumenten.</sample>
    <sample id="1075">Q1: Wann erfordert Übersetzung Kontext?
- Kontextbasierte Wortlevel
- Themenanalyse
Q2: Wie gut bewältigen Modelle Übersetzungen, die Kontext abhängig sind?
- Multilinguistisches Diskurs-Aware (MuDA) Benchmark
- Modellevaluation</sample>
    <sample id="1076">Corpus-level metrics BLEU</sample>
    <sample id="1077">Corpus-level metrics BLEU COMET F-measure</sample>
    <sample id="1078">Corpus-level metrics BLEU COMET F-measure Unclear which system is best for document-level MT with corpus-level metrics</sample>
    <sample id="1079">MuDA benchmark results

Context-aware models perform significantly better on some phenomena

Formality, lexical cohesion</sample>
    <sample id="1080">MuDA Benchmark results

• Context-aware models perform significantly better on some phenomena
o Formality, lexical cohesion ✓
o Ellipsis, pronouns, verb form ✗</sample>
    <sample id="1081">Context-aware models perform significantly better on some phenomena o Formality, lexical cohesion x Ellipsis, pronouns, verb form DeepL outperforms Google on most phenomena and language pairs*</sample>
    <sample id="1082">Identify discourse phenomena systematically without prior linguistic knowledge Dataset-agnostic benchmark for document-level MT</sample>
    <sample id="1083">Identify discourse phenomena systematically without prior linguistic knowledge Dataset-agnostic benchmark for document-level MT</sample>
    <sample id="1084">Der Referent*in heißt Yufen Zhang.</sample>
    <sample id="1121">The new method has a name.</sample>
    <sample id="1122">Die Autoren beschreiben die Methode der "markierten Wörter" als die Identifizierung von Worten, die Personen von markierten Gruppen von nicht-markierten Gruppen unterscheiden.</sample>
    <sample id="1123">Die Autoren gehören an der Paul G. Allen School, UW NLP, Carnegie Mellon University Language Technologies Institute und der Yandex Institute.</sample>
    <sample id="1124">Prague</sample>
    <sample id="1125">Sarah E. Finch</sample>
    <sample id="1126">4</sample>
    <sample id="1127">SyntaxGym und CrowS sind die Datensätze, die zur Analyse syntaktischer Phänomene verwendet werden können.</sample>
    <sample id="1161">FT, W, BOND, COSINE, MLC, L2R</sample>
    <sample id="1162">Das Modell wird anhand von 11 Aufgaben evaluiert.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich auf 4GB von der DDB trainiert.</sample>
    <sample id="1227">Adam Przepiórkowski</sample>
    <sample id="1228">Die Analyse der genannten Tabellen und Grafiken führte zu dem Schluss, dass die zeitliche Verzögerung die Hauptursache für den Leistungsverlust war.</sample>
    <sample id="1269">Um die Permutation der Token für die Ausgabesequenz zu vermeiden.</sample>
    <sample id="1270">Die Autoren argumentieren, dass die Transparenz der Methoden beim Abbau von Vorurteilen helfen kann, die Ursachen von Diskriminierung zu identifizieren und zu adressieren.</sample>
    <sample id="1271">Inacceptable minimal pair assignments are: 1. Many people were helping themselves. 2. Many people were helping herself.</sample>
    <sample id="1272">Die Autoren verwenden die Standard-METRIKEN wie Accuracy, F1-Score und AUC.</sample>
    <sample id="1273">Krippendorff Alpha</sample>
    <sample id="1274">Wikipedia</sample>
    <sample id="1275">Die Autoren gehören an der Heinrich Heine University Düsseldorf, Deutschland.</sample>
    <sample id="1276">MultiInstruct ist ein einzigartigerBenchmark, der die Leistung von Sprachmodellen in mehreren Sprachen überprüft.</sample>
    <sample id="1277">Drei.</sample>
    <sample id="1278">Die Definition der binären Koordination lautet: "Eine Sprachstelle A koordiniert mit einer Sprachstelle B, wenn A ein Ereignis (z.B. die Einführung eines neuen Substantivs) an B ankündigt und B auf diese Ankündigung reagiert."</sample>
    <sample id="1279">Die in dieser Studie verwendeten Prompts im Durchschnitt lagen bei 17,4 Wörtern.</sample>
    <sample id="1280">Das kleine T5-Modell trainiert auf Coreset und kann höhere Qualitätsskripte generieren als LLMs.</sample>
    <sample id="1281">DrBERT: Ein robustes prätrainiertes Modell im Französischen für biomedizinische und klinische Bereiche

Yanis Labarre1,4 Adrien Bazille2,3 Richard Dufour2 Mickael Rouvier1 Emmanuel Morin2,3 Beatrice Dalile2,3 Pierre-Antoine Gourraud3

(1) LIA, Avignon University (2) LS2N, University of Nantes (3) CHU des donnés, CHU de Nantes (4) Zenith</sample>
    <sample id="1282">I. Sprachmodellierung in der Gesundheitsversorgung II. Vergleich von vorher einstellenden Strategien, Datenerkällern und Größen III. Auswertung von 13 Modellen an 11 Aufgaben IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1283">I. Sprachmodellierung in der Gesundheitsversorgung
II. Vergleich von vorher einstellenden Strategien, Datenerkällern und Größen
III. Evaluation von 13 Modellen an 11 Aufgaben
IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1284">I. Sprachmodellierung in der Gesundheitsversorgung II. Vergleich von vorher einstellenden Strategien, Datensätzen und Größen III. Evaluation von 13 Modellen an 11 Aufgaben IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1285">I. Sprachmodellierung in der Gesundheitsversorgung
II. Vergleich von Voreinzelstrategien, Datensätzen und Größen
III. Auswertung von 13 Modellen an 11 Aufgaben
IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1286">Transformer-basierte Ansätze, wie BERT, bieten einen erheblichen Leistungsgewinn an NLP-Aufgaben. Sie wurden auf Französisch mit CamemBERT und FlauBERT angepasst. Auf medizinischen Aufgaben haben dominante spezifische Modelle im Englischen die Barre noch höher gehoben. PudMedBERT, BioBERT, ClinicalBERT usw. Es gibt keine allgemeinen Modelle für die Biomedizinischen Bereiche in Französisch. Ein offene Quellen-Modell für die Biomedizinischen Bereiche in Französisch steht noch nicht zur Verfügung. BERT-basiertes dominantes Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern.</sample>
    <sample id="1287">Transformer-basierte Ansätze, wie BERT, bieten einen erheblichen Leistungszuwachs an NLP-Aufgaben. Sie wurden auf Französisch mit CamemBERT und FlauBERT angepasst. Auf medizinischen Aufgaben haben dominante spezifische Modelle im Englischen die Barre noch höher gehoben. PudMedBERT, BioBERT, KlinischeBERT und andere. Sprachen außer Englisch sind seltener und hängen hauptsächlich von existierenden allgemeinen Modellen ab. Noch keine allgemein zugängliche Open-Source-Modelle für die biomedizinische Branche in Französisch sind. Ein BERT-basierter dominanter spezifischer Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern.</sample>
    <sample id="1288">Transformer-basierte Ansätze, wie BERT, bieten einen großen Leistungsverlust an einer Vielzahl von NLP Aufgaben. Sie wurden auf Französisch mit CamemBERT und FlauBERT angepasst. Auf medizinischen Aufgaben haben dominante spezifische Modelle im Englischen die Barre noch höher gehoben. PudMedBERT, BioBERT, ClinicalBERT und andere. Sprachen andern als Englisch sind seltener und hängen hauptsächlich von existierenden allgemeinen Modellen ab. Noch keine allgemein zugängliche Open-Source-Modelle für die biomedizinische Branche in Französisch sind. Ein BERT-basierter dominanter spezifischer Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern.</sample>
    <sample id="1289">Transformer-basierte Ansätze, wie BERT, bieten einen großen Leistungszuwachs an einer Vielzahl von NLP Aufgaben. Sie wurden auf Französisch mit CamemBERT und FlauBERT angepasst. Auf medizinischen Aufgaben haben dominante spezifische Modelle im Englischen die Barre noch höher gehoben. PudMedBERT, BioBERT, KliniBERT und andere. Sprachen außer Englisch sind seltener und hängen hauptsächlich von existierenden allgemeinen Modellen ab. Noch keine allgemein zugängliche Open-Source-Modelle für die biomedizinische Branche in Französisch sind. Ein BERT-basierter dominanter spezifischer Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern.</sample>
    <sample id="1290">Evaluierung der Auswirkungen von öffentlichen und privaten medizinischen Datensammlungen auf vergleichbare Datengröße

- NACHOS: Eine 1,1 Billionen-Tokens offene Quelle mit diversen medizinischen Feldern, Stilen und Naturen
- Eine private Datensammlung von Sätzen, die aus anonymisierten Krankenhausprotokollen im Nanterre Krankenhauses extrahiert wurden

Vergleich von Lernstrategien

- Von Grund aus: Voller Bau mit vollständiger Datensammlung
- Continual Pre-training: Nutzung eines bestehenden vortrainierten Modells (z.B. CamemBERT), einer französischen allgemeinen Modell- und MedizinBERT</sample>
    <sample id="1291">Evaluierung der Auswirkungen von öffentlichen und privaten medizinischen Datensammlungen auf vergleichbare Datengröße

- NACHOS: Eine 1,1 Millionen Wörter offene Quellenquelle diverse medizinische Domänen, heterogene Datensätze aus diversen medizinischen Feldern, anonymisierte Krankenhausdatenbank
- Privates Datensatz von Sätzen, die aus 1,7 Million anonymisierten Krankenhausprotokollen extrahiert wurden, Nantes Universitätskrankenhaussystem

Vergleich der Lernstrategien

- Von Grund aus mit vollständiger Konstruktion
- Continual Pre-training: Verwendung eines bestehenden vortrainierten Modells (ChBERT, CamBERT, PubMedBERT), eine deutsche allgemeine Modell, und PubMedBERT
- NACHOS: A 1.1 Billion Open-Source Corpus of Diverse Medical Domains</sample>
    <sample id="1292">Evaluierung der Auswirkungen von öffentlichen und privaten medizinischen Datensammlungen auf vergleichbare Datengröße

- **NACHOS: Eine 1,1 Billionen-Tokens offene Quelle mit diversen medizinischen Feldern, Stilen und Mustern**
    - Privates Datensatz von Sätzen, die aus 1,7 Billionen anonymisierten Krankenhausprotokollen extrahiert wurden
    - Medizinisches Datendienstleistungsanbieter-Nets

- **Evaluation der Auswirkungen von Datensammlungen auf vergleichbare Datengröße**

- **Vergleich von Lernstrategien**
    - **Von Grund aus vor:** Mit vollständiger Konstruktion
    - **Kontinuierliche vor:** Trainieren mit einem vorausgesetzten Modell
        - ContinualBERT: Ein bestehendes vorausgesetztes Modell
        - PubMedBERT: Ein französischer allgemeiner Modell, und
        - NACHOSBERT: Ein vorausgesetztes Modell

Die Tabelle im unteren Teil der Präsentation vergleicht verschiedene Modelle basierend auf den Datensammlungen und Lernstrategien. Es zeigt, dass die Modelle von Grund aus vor und kontinuierliche vor unterschiedliche Datensammlungen verwenden, um die Leistung zu bewerten.</sample>
    <sample id="1293">Evaluation of the impact of public and private medical data sources

- **Corpus**: A 1.1B words open-source dataset covering diverse medical domains, including anonymized medical records extracted from the Nanterre University Hospital data warehouse.
- **NACHOS**: A private dataset of sentences taken from 1.7M anonymized medical records.

Comparison of learning strategies:

- **From scratch**: Full model construction without pre-training.
- **Continual pre-training using existing pre-trained models**: Utilizing pre-trained models like DeBERTa, RoBERTa, CamemBERT, and PubMedBERT for continual learning.
- **Pre-trained models**: NACHOS, NACHOS+DeBERTa, NACHOS+RoBERTa, NACHOS+CamemBERT, NACHOS+PubMedBERT</sample>
    <sample id="1294">Evaluierung der Auswirkungen von öffentlichen und privaten medizinischen Datensammlungen auf vergleichbare Datengröße

- **NACHOS:**
  - Eine 1,1 Billionen-Wort-Open-Source-Datensammlung aus diversen medizinischen Feldern.
  - Der Datensatz enthält anonymisierte Krankenhausprotokolle, die aus den Nantes Universitätskrankenhauses extrahiert wurden.

- **Privater Datensatz:**
  - Eine Datensammlung von Sätzen, die aus 1,7 Billionen anonymisierten Krankenhausprotokollen stammt.

**Vergleich von Lernstrategien:**

- **Von Grund aus anfangen (From scratch):**
  - Eine vollständige Modellkonstruktion.
  
- **Kontinuierliche vorherige Training (Continual pre-training):**
  - Das Modell wird auf einem bestehenden vorher gelernten Modell fortgesetzt.
  
- **CamMedBERT:**
  - Ein französischer generischer Modell.
  
- **PubMedBERT:**
  - Ein kontinuierlich vorher gelerntes Modell.
  
- **NACHOS:**
  - Ein modellvorgelernter CamMedBERT.

Die Tabellen im unteren Teil der Präsentation vergleichen verschiedene Modelle basierend auf den oben genannten Datensammlungen und Lernstrategien.</sample>
    <sample id="1295">Evaluierung der Auswirkungen von öffentlichen und privaten medizinischen Datensammlungen auf vergleichbare Datengröße

- Vergleich von Datensammlungen
    - NACHOS: Eine 1,1 Billionen-Tokens offene Quelle mit diversen Medizinbereichen, Stilen und Naturen, basierend auf anonymisierten Krankenhausdaten aus dem Nanterre Krankenhauses.
    - Privates Datensatz von Sätzen, abgeleitet aus 1,7 Billionen anonymisierten Krankenhausprotokollen.

- Vergleich von Lernstrategien
    - Von Grund aus: Vom Null starten mit vollständiger Konstruktion.
    - Continual Pre-training: Nutzen eines bestehenden vortrainierten Modells.
    - Publizierte Arbeiten: Beispiele sind CamemBERT, ein französischer allgemeiner Modell, und PubMedBERT.</sample>
    <sample id="1296">Evaluierung der Auswirkungen von öffentlichen und privaten medizinischen Datensammlungen auf vergleichbare Datengröße

- NACHOS: Eine 1,1 Billionen-Wort-Open-Source-Datensammlung aus diversen medizinischen Domänen, Stilen und Naturen (7,4 GB)
- Private Datensammlung: Satze aus 1,7 Billionen anonymisierten Krankenakten extrahiert aus dem Nanterre University Hospital Data Warehouse (7,4 GB)

Vergleich von Lernstrategien

- Von Grund aus: Voller Datensatz mit vollständiger Konstruktion
- Continual Pre-training: Nutzung eines bestehenden vortrainierten Modells (ChBERT, CamBERT, PubMedBERT, NACHOS)
- Publiziertes Modell: CamMedBERT, ein französischer allgemeiner Modell, und NACHOS</sample>
    <sample id="1297">Evaluierung der Auswirkungen von öffentlichen und privaten medizinischen Datensammlungen auf vergleichbare Datengröße

- **NACHOS**: Eine 1,1 Millionen-token große offene Quellenquelle diverser medizinischer Domänen, Stile und Naturen.
- **Privates Datensatz**: Eine Sammlung von Sätzen, die aus 1,7 Million anonymisierten Krankenhausprotokollen im Nanterre Krankenhauses extrahiert wurden.

**Vergleich von Lernstrategien**

- **Von Grund aus Newman**: Eine vollständige Konstruktionsstrategie.
- **Kontinuierliche Pre-Training**: Nutzung eines bestehenden vortrainierten Modells, wie z.B. ChBERT, PubMedBERT, CamemBERT und NBDWBERT.</sample>
    <sample id="1298">Evaluierung von 13 Datenermittlungen und Grösse

- Leistungsevaluation von 13 Modellen an 11 öffentlichen und privaten Aufgaben
- Ungefähre Evaluierungen basieren auf dem Stand der Kunst
- Finetuning der Modelle auf fast alle Aufgaben

Die Tabelle zeigt die Leistungsstelle (F1-Score) für verschiedene Medizinreport-Spezialisierungen und Datensätze. Hier sind einige Beispiele:

- **General**: 
  - BERT: 90,65%
  - RoBERTa: 91,78%
  - BioBERT: 90,44%
  - ClinicalBERT: 90,55%
  - BioBERT NER: 92,38%

- **Biomediцинliche**:
  - BioBERT: 90,44%
  - BioBERT NER: 92,38%

- **Klinische**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Radiologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Pathologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Onkologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Epidemiologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit NMR**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit MRI**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit CT**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit PET**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit X-ray**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Ultrasound**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Angiographie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mammographie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Endoskopie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Dermatologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Neurologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Psychiatrie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Pharmakologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Biologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Chemie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Physik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mathematik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Informatik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Statistik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Epidemiologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Biostatistik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit NMR**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit MRI**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit CT**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit PET**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit X-ray**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Ultrasound**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Angiographie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mammographie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Endoskopie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Dermatologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Neurologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Psychiatrie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Pharmakologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Biologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Chemie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Physik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mathematik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Informatik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Statistik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Epidemiologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Biostatistik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit NMR**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit MRI**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit CT**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit PET**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit X-ray**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Ultrasound**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Angiographie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Mammographie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Endoskopie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Dermatologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Neurologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Psychiatrie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Pharmakologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Biologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Chemie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Physik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Mathematik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Informatik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Statistik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Epidemiologie**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Biostatistik**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Mediziinswesen**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Mediziinswesen mit NMR**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Mediziinswesen mit MRI**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Mediziinswesen mit CT**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Mediziinswesen mit PET**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Mediziinswesen mit X-ray**:
  - ClinicalBERT: 90,55%
  - ClinicalBERT NER: 92,38%

- **Klinische Medizin mit Mediziinswesen mit Mediziinswesen mit Mediziinswesen mit Ul</sample>
    <sample id="1299">Evaluation: 13 Quellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 öffentlichen und privaten Aufgaben
- Ungefähre Evaluierungen durch die Art und die Häufigkeit der Datensammlungen
- Tabellarische Darstellung der Evaluierungen:

| Quelle | Medizinische Berichtsspezialisierungen | MUSCA-DAT | MUSCA-DET | ISLES | CAS | CAS-MoC | QUADRO-EHME | QUADRO-MEDLINE |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| General | CanonBert Oscar 150 GB | 92.17 | 92.43 | 91.27 | 89.09 | 94.62 | 93.75 | 90.83 | 78.76 |
| CanonBert CUNet 4 GB | 92.68 | 92.87 | 93.14 | 91.82 | 93.44 | 94.62 | 93.75 | 90.83 | 78.76 |
| CanonBert U11 | 93.17 | 93.44 | 94.06 | 92.17 | 93.44 | 94.62 | 93.75 | 90.83 | 78.76 |
| BioMedical | BioBERT v1.1 | 94.00 | 94.38 | 95.00 | 94.00 | 95.00 | 95.00 | 95.00 | 72.68 |
| BioMedical | BioBERT v1.2 | 94.50 | 94.88 | 95.50 | 94.50 | 95.50 | 95.50 | 95.50 | 72.68 |
| Clinical | ClinicalBERT NACOS | 95.00 | 95.50 | 96.00 | 95.00 | 96.00 | 96.00 | 96.00 | 75.05 |
| Clinical | ClinicalBERT NACOS | 95.50 | 96.00 | 96.50 | 95.50 | 96.50 | 96.50 | 96.50 | 75.05 |
| Clinical | ClinicalBERT NACOS | 96.00 | 96.50 | 97.00 | 96.00 | 97.00 | 97.00 | 97.00 | 75.05 |
| Clinical | ClinicalBERT NACOS | 96.50 | 97.00 | 97.50 | 96.50 | 97.50 | 97.50 | 97.50 | 75.05 |
| Clinical | ClinicalBERT NACOS | 97.00 | 97.50 | 98.00 | 97.00 | 98.00 | 98.00 | 98.00 | 75.05 |
| Clinical | ClinicalBERT NACOS | 97.50 | 98.00 | 98.50 | 97.50 | 98.50 | 98.50 | 98.50 | 75.05 |
| Clinical | ClinicalBERT NACOS | 98.00 | 98.50 | 99.00 | 98.00 | 99.00 | 99.00 | 99.00 | 75.05 |
| Clinical | ClinicalBERT NACOS | 98.50 | 99.00 | 99.50 | 98.50 | 99.50 | 99.50 | 99.50 | 75.05 |
| Clinical | ClinicalBERT NACOS | 99.00 | 99.50 | 100.00 | 99.00 | 100.00 | 100.00 | 100.00 | 75.05 |
| Clinical | ClinicalBERT NACOS | 99.50 | 100.00 | 100.50 | 99.50 | 100.50 | 100.50 | 100.50 | 75.05 |
| Clinical | ClinicalBERT NACOS | 100.00 | 100.50 | 101.00 | 100.00 | 101.00 | 101.00 | 101.00 | 75.05 |

- Das Fin-Tune-Modell erreicht einen Höhepunkt an fast 100% Genauigkeit auf den verschiedenen Aufgaben.</sample>
    <sample id="1300">Evaluation: 13 Quellen und Größe

- Leistungsevaluation von 13 Modellen an 11 öffentlichen und privaten Aufgaben
- Unser einstimmiger Modell erzielt das aktuelle Stand der Kunst auf fast alle Felder

Die Tabelle unten zeigt die Leistungen der verschiedenen Modelle auf verschiedenen Aufgaben:

| Quelle | Medizinische Berichterstelle | MUSCA-BET | MUSCA-DiET | ESSAL | CAS | CAS-MoE | QUADRO-EHME | QUADRO-MEDLINE |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| General | BioBERT Oscar 150 GB | 92.4 | 91.7 | 91.2 | 90.9 | 90.8 | 90.3 | 90.1 |
| Biometrisch | BioBERT ULI | 89.0 | 88.3 | 87.9 | 87.6 | 87.3 | 86.9 | 86.6 |
| Klinisch | BioBERT NACOS | 93.5 | 93.1 | 92.7 | 92.3 | 92.0 | 91.6 | 91.3 |
| Klinisch | BioBERT NOSW | 94.1 | 93.7 | 93.3 | 92.9 | 92.6 | 92.2 | 91.9 |
| Klinisch | BioBERT NOSW (niedrig) | 94.1 | 93.8 | 93.4 | 93.0 | 92.7 | 92.4 | 92.1 |

Das Modell "BioBERT Oscar 150 GB" erreicht die höchste Gesamtzahl an Punkten auf den verschiedenen Aufgaben, gefolgt von "BioBERT NOSW (niedrig)". Das Modell "BioBERT NOSW" erreicht dielowest Punkte auf den verschiedenen Aufgaben, gefolgt von "BioBERT NACOS".</sample>
    <sample id="1301">Evaluation: 13 Quellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 öffentlichen und privaten Aufgaben
- Ungefähre Evaluierungen der Art und Häufigkeit aller Datensätze

Die Tabelle zeigt die Leistungsstelle (F1-Score) der verschiedenen Modelle auf verschiedenen Aufgaben:

| Quelle | Medizinische Berichtsspezialisierungen | MUSCA-DAT | MUSCA-DET | ISLES-22 | CAS | CAS-MoC | QUADRO-EMEA | QUADRO-MEDLINE |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| General | CanonBert Oscar 150GB | 94.14 | 94.34 | 94.34 | 91.27 | 89.60 | 94.62 | 90.83 | 78.76 |
| CanonBert CUNet 4GB | 92.66 | 93.41 | 93.41 | 93.41 | 91.27 | 89.60 | 94.62 | 90.83 | 77.61 |
| CanonBert CUNet 16GB | 92.66 | 93.41 | 93.41 | 93.41 | 91.27 | 89.60 | 94.62 | 90.83 | 76.41 |
| Biometikal | BioBERT v1.1 | 89.00 | 89.38 | 89.80 | 89.46 | 89.19 | 89.18 | 89.10 | 72.68 |
| Biometikal | BioBERT v1.2 | 89.00 | 89.38 | 89.80 | 89.46 | 89.19 | 89.18 | 89.10 | 72.68 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 | 88.25 | 88.24 | 88.24 | 75.05 |
| Klinisch | ClinicalBERT NACOS | 88.77 | 88.77 | 88.77 | 88.77 |</sample>
    <sample id="1302">Evaluierung: Vordereinrichtung

* Von Grund aus vs. ständige Vordereinrichtung auf 4GB von Daten
* Fragensbehandelungs Aufgaben erfordern mehr dominanfspezifische Kenntnis, um gut zu arbeiten
* Eine Studie zur Modell-Stabilität zeigt eine höhere Inter-Run-Stabilität für Camembert-basierte Modelle, die unter ständiger Vordereinrichtung trainiert wurden.

Die Tabelle vergleicht die Leistung verschiedener Camembert-basierte Modelle auf verschiedenen Aufgabentypen und Datensätzen. Hier sind die Hauptpunkte:

- **aHF vs. Medical-Specialist**: Camembert-basierte Modelle mit ständiger Vordereinrichtung (MUSCA-DERT, MUSCA-ESAI, HumanLM, QUADRO-EMEA, QUADRO-MEDIC) erreichen in der Regel bessere oder ähnliche Leistungen wie Medizin-Spezialisten.
- **NER (Named Entity Recognition)**: Camembert-basierte Modelle mit ständiger Vordereinrichtung erreichen in der Regel bessere Leistungen als die aHF-Modelle.
- **CLS (Classification)**: Camembert-basierte Modelle mit ständiger Vordereinrichtung erreichen in der Regel bessere Leistungen als die aHF-Modelle.
- **MUSCA-DERT vs. MUSCA-ESAI**: Camembert-basierte Modelle mit ständiger Vordereinrichtung erreichen in der Regel bessere Leistungen als die MUSCA-DERT-Modelle.
- **HumanLM vs. QUADRO-EMEA vs. QUADRO-MEDIC**: Camembert-basierte Modelle mit ständiger Vordereinrichtung erreichen in der Regel bessere Leistungen als die HumanLM-Modelle.

Die Studie zeigt, dass Camembert-basierte Modelle mit ständiger Vordereinrichtung in der Regel bessere Leistungen erreichen als aHF-Modelle auf verschiedenen Aufgabentypen und Datensätzen.</sample>
    <sample id="1303">Evaluierung: Vordereinrichtung

* Von Grund aus vs. ständige Vordereinrichtung auf 4GB von Daten
* Aufgabenbehandelungs Aufgaben erfordern mehr spezifische Domänen Kenntnis, um gut arbeiten zu können
* Eine Studie über Modell-Stabilität zeigt, dass die CamenBERT-basierten Modelle mit kontinuierlicher Vordereinrichtung ein höhere Inter-Run-Festigkeit aufweisen

Die Tabelle vergleicht verschiedene Modelle auf verschiedenen Aufgabentypen:

| Modell | HF-Spezialisierung | Medizinische Spezialisierung | MUSCA-DERT | MUSCA-ESAI | Hamada | QuaDio-MME | QUADRO-EMEA | QUADRO-MEDICINE |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| CamenBERT Oscar | 33,13 | 93,5 | 99,20 | 85,44 | 92,42 | 95,24 | 74,1 | 77,41 |
| CamenBERT CNN+G | 43,11 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+ | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large+Large | 46,01 | 79,88 | 99,20 | 85,44 | 92,42 | 95,24 | 63,1 | 77,41 |
| CamenBERT CNN+L</sample>
    <sample id="1304">Evaluierung: Vordereinrichtung

* Von Grund aus vs. ständige Vordereinrichtung auf 4GB von Daten
* Fragensbehandelungs Aufgaben erfordern mehr spezifische Domänen Kenntnis, um gut arbeiten zu können
* Eine Studie zur Modell-Stabilität zeigt, dass die CamenBERT-basierten Modelle mit ständiger Vordereinrichtung ein höhere Inter-Run-Festigkeit aufweisen

Die Tabelle unten zeigt die Leistungen der verschiedenen Modelle an:

| Modell | HF-Spezialisierung | Medizinische Spezialisierung | MUSCA-DiBT | MUSCA-ESAI | HumanLM | QuaDro-EMLA | QuaDro-MED |
| --- | --- | --- | --- | --- | --- | --- | --- |
| CamenBERT Oscar | 33,13 | 80,11 | 99,20 | 85,44 | 95,23 | 92,46 | 74,14 |
| CamenBERT CNN+G | 43,11 | 79,86 | 99,20 | 85,44 | 95,23 | 92,46 | 74,14 |
| CamenBERT CNN+G+Ch | 46,01 | 79,86 | 99,20 | 85,44 | 95,23 | 92,46 | 74,14 |
| CamenBERT CNN+G+Ch+L | 46,01 | 79,86 | 99,20 | 85,44 | 95,23 | 92,46 | 74,14 |
| CamenBERT CNN+G+Ch+L+R | 46,01 | 79,86 | 99,20 | 85,44 | 95,23 | 92,46 | 74,14 |
| CamenBERT CNN+G+Ch+L+R+P | 46,01 | 79,86 | 99,20 | 85,44 | 95,23 | 92,46 | 74,14 |
| CamenBERT CNN+G+Ch+L+R+P+M | 46,01 | 79,86 | 99,20 | 85,44 | 95,23 | 92,46 | 74,14 |
| CamenBERT CNN+G+Ch+L+R+P+M+O | 46,01 | 79,86 | 99,20 | 85,44 | 95,23 | 92,46 | 74,14 |
| CamenBERT CNN+G+Ch+L+R+P+M+O+I | 46,01 | 79,86 | 99,20 | 85,44 | 95,23 | 92,46 | 74,14 |

Die Tabelle zeigt, dass die CamenBERT-basierten Modelle mit ständiger Vordereinrichtung in der Medizinischen Spezialisierung die besten Leistungen aufwarten. Immerhin erreichen sie eine Genauigkeit von 99,20%, was einen hohen Standard für Medizinische Spezialisierungen darstellt. Es ist zu beachten, dass die Leistungen in anderen Spezialisierungen variieren und nicht immer so hoch sind.

Es ist wichtig zu beachten, dass die Leistungen der Modelle stark von der Art und Menge der Daten abhängen, die verwendet werden, um sie zu trainieren. Eine detailliertere Analyse der Daten und der spezifischen Aufgaben, die die Modelle bewältigen, wäre notwendig, um eine vollständige Einschätzung der Leistungen zu erhalten.</sample>
    <sample id="1305">DrBERT übertrifft die besten Ergebnisse von CamemBERT in 9 downstream-Französisch-medizinorientierten Aufgaben. Dies bestätigt die Nützlichkeit des Trainings spezifischer medizinische Modelle im Französisch. Es ist wichtig, auf heterogene Daten zu trainieren; NACHOS ist robustere als das Verwenden von privaten klinischen Daten nur. Continual Pretraining ist besser, aber nicht effektiver, wenn es auf domain-spezifischen englischen Modellen basiert. DrBERT-Modelle, der NACHOS-Datensatz und die Trainingsskripte sind unter der MIT-Lizenz frei zugänglich.</sample>
    <sample id="1306">DrBERT übertrifft die besten Ergebnisse im Bereich der Medizin auf 9 Stream-French-Schwierigkeiten. Dies bestätigt die Nützlichkeit des Training spezifischer Medizinmodelle in Französisch. Es ist wichtig, auf heterogene Daten zu trainieren, da es besser ist als das Verwenden von privaten klinischen Daten nur. Das ständige Fortschrittsschaffen ist besser, aber nicht effektiver, wenn es auf einem dominant Englisch-basierten Modell basiert. DrBERT-Modelle, der NACHOS-Datensatz und die Trainings-skripte sind unter der MIT-Lizenz frei zugänglich.</sample>
    <sample id="1307">DrBERT übertrifft die besten Leistungen im Bereich der Medizin auf 9 verschiedenen französischen Arztpraxis-Schwierigkeiten. Dies bestätigt die Nützlichkeit des Trainings spezifischer Medizinmodelle in Französisch. Es ist wichtig, dass die Datenermittlung auf heterogenen Daten basiert, da dies die Robustheit der Modelle steuert. NACHOS ist robustere als das Verwenden von privaten klinischen Daten nur. Das fortlaufende Pretraining ist besser, aber nicht effektiver, wenn es auf spezifischen Modellen basiert. DrBERT-Modelle, der NACHOS-Datensatz und die Trainingsskripte sind unter der MIT-Lizenz frei zugänglich.</sample>
    <sample id="1308">Bild:</sample>
    <sample id="1309">Die Lernstrategien, die in der Arbeit untersucht werden, sind: 1. Von Grund aus neu beginnen mit vollständiger Konstruktion 2. Kontinuierliches Vor-Training mit einem bestehenden vor-getrainten Modell 3. Schulung mit einem bestimmten Datensatz 4. Schulung mit mehreren Datensätzen.</sample>
    <sample id="1310">Der Faktor der Überanpassung, der speziell auf die Wiederverwendung von Tests zurückzuführen ist, beträgt 0.57.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde mittels BLEU-Scores beurteilt.</sample>
    <sample id="1312">Ja, sie haben politische Vorurteile.</sample>
    <sample id="1313">Compositional Generalization without Trees using Multiset Tagging and Latent Permutations Matthias Lindemann, Alexander Koller, Ivan Titov</sample>
    <sample id="1314">Compositional Generalization without Trees using Multiset Tagging and Latent Permutations Matthias Lindemann, Alexander Koller, Ivan Titov</sample>
    <sample id="1315">Fähigkeit eines Lerners, um tieferes Rekursion und unbekannte Kombinationen von Phrasen zu bewältigen, die während des Trainings individuell gesehen wurden.</sample>
    <sample id="1316">Titel: Generalisierbarkeit in der Semantik-Auswertung

Train:

Die Mädchen schlafen.
[gruppe x;sleep.agents x]

Mary wusste, dass die Mädchen schlafen.
[gruppe x;know.agents x;Mary ∧know.cmp x;sleep.agents x]</sample>
    <sample id="1317">Titel: "Kompositionale Generalisierung in semantischer Analyse"

Inhalte:
Train:

- "Die Mädchen schlafen." -&gt; "girl x; sleep agent x, x"
- "Mary wusste, dass die Mädchen schlafen." -&gt; "girl x; know agent x, Mary ∧ know comp x, x; sleep agent x, x"</sample>
    <sample id="1318">Kompositional Generalisierung in Semantikparsen

Train:

The girl slept.

Mary knew that the girl slept.

Mary _knew_ that _the girl_ _slept_.

Mary _knew_ that _the girl_ _slept_.

Mary _knew_ that _the girl_ _slept_.</sample>
    <sample id="1319">Train: Mary kannte die Mädchen, die schlafen. Test: Jim hat gesagt, dass Mary die Mädchen kannte, die schlafen.</sample>
    <sample id="1320">Kompositioneller Transfer in Semantikparsen

Train:

Die Mädchen schliefen.
Mary kannte die Mädchen.
Mary kannte, dass die Mädchen schliefen.

Test:

Jim sagte, dass Mary kannte, dass die Mädchen schliefen.


Naive seq2seq-Modelle scheitern!</sample>
    <sample id="1321">Kompositionale allgemeinheit in semantischem Parsen

Train:

Die Mädchen schlafen.
Mary kannte die Mädchen, die schlafen.


Test:

Jim hat gesagt, dass Mary kannte, dass sie schlafen.


Naive seq2seq-Modelle scheitern!</sample>
    <sample id="1322">Bäume halfen sehr, aber...</sample>
    <sample id="1323">Bäume helfen sehr, aber...</sample>
    <sample id="1324">Bäume helfen sehr, aber...</sample>
    <sample id="1325">Bäume helfen sehr, aber...</sample>
    <sample id="1326">Bäume helfen sehr, aber...</sample>
    <sample id="1327">Bäume helfen sehr, aber...Trees help a lot but... *girl x1; sleep agent x2; x* *girl x1; x* *sleep agent x2; slept* The girl slept. Trees needed to be obtained: Pre/Post-processing logical forms Grammar-induction For the first time, we show strong generalization to deeper recursion without trees.</sample>
    <sample id="1328">Bäume helfen sehr, aber...Trees help a lot but... *girl x1; sleep agent x2; x1 slept* *girl x1; x1 slept* *sleep agent x2; x2 slept* The girl slept. Trees needed to be obtained: Pre/Post-processing logical forms Grammar-induction For the first time, we show strong generalization to deeper recursion without trees. [Figure 1: neural seq2seq model that directly models the correspondences between fragments.]</sample>
    <sample id="1329">Unser Ansatz

Die Grafik zeigt einen Prozess, der den Begriff "sleep" und dessen Verknüpfungen mit anderen Begriffen wie "girl" und "agent" illustriert. Der Prozess beginnt mit drei Grün- und drei gelben Kästchen, die jeweils mit einem Buchstaben versehen sind: x1, girl, x1, sleep, agent, x2. Jedes Grün- oder Gelb-Kästchen ist durch einen Pfeil an das untere Graue Kästchen mit dem entsprechenden Wort (the, girl, slept) verlinkt.

Dieses Graue Kästchen ist durch doppelte Pfeile an ein schwarzes Kästchen mit dem Wort "Tag" verlinkt. Das schwarze Kästchen repräsentiert also die Hauptkategorie "Tag", und die Pfeile symbolisieren die Verknüpfungen zwischen den verschiedenen Begriffen und dieser Hauptkategorie.

Insgesamt zeigt die Grafik, wie Begriffe wie "sleep", "girl" und "agent" in Bezug auf die Hauptkategorie "Tag" miteinander verbunden werden.</sample>
    <sample id="1330">Unser Ansatz

Die Grafik zeigt einen Prozess, bei dem ein Satz ("the girl slept") in seine individuellen Wörter ("the", "girl", "slept") zerstört wird. Jedes Wort wird dann in einem separaten Schritt mit einem "Tag" versehen, das den Kontext oder die Rolle des Wortes im Satz angibt. 

Die Wörter "the" und "slept" werden in einem blauen Kasten eingeschlossen, was bedarf der Verwendung von "X1" und "X2". Der "Tag" wird in einem gelben Kasten eingeschlossen, der "girl" und "sleep" beinhaltet. 

Die Verknüpfung zwischen den Wörtern und ihren Tags wird durch Pfeile dargestellt, die von den Wörtern auf die entsprechenden Tags zeigen. 

Insgesamt zeigt die Grafik, wie ein Satz in seine Individuen zerstört wird und dann mit Hilfe von "Tags" wieder zu einem Satz zusammengestellt wird.</sample>
    <sample id="1331">Unser Ansatz

Die Grafik zeigt einen Prozess, bei dem verschiedene Wörter und Begriffe verwendet werden, um einen Text zu strukturieren. Hier ist eine detailliertere Übersetzung des englischen Inhalts ins Deutsche:

---

Unser Ansatz

Die Grafik zeigt einen Prozess, bei dem verschiedene Wörter und Begriffe verwendet werden, um einen Text zu strukturieren. Auf der linken Seite sind Wörter in einem Green-Box-Format aufgelistet, die als "X1" und "girl X1" bezeichnet werden. Auf der rechten Seite sind Wörter in einem Blue-Box-Format aufgelistet, die als "sleep agent X2" bezeichnet werden. Beide Gruppen von Wörtern sind durch Pfeile von oben nach unten verlinkt und überlagern eine schwarze Linie, die den Text enthält: "the girl slept". 

---

In this translation, I've maintained the structure and format of the original graphic while converting the text into German. The key elements such as "Our Approach," the color-coded boxes, and the connections between them are preserved to ensure clarity and accuracy in the translation.</sample>
    <sample id="1332">Unser Ansatz

Die Grafik zeigt einen Prozess, der den Begriff "sleep" identifiziert und dessen Kontext analysiert. Hier ist eine detailliertere Beschreibung des Prozesses:

1. **Eingabe**: Das System bekommt ein Wort als Eingabe, das in diesem Fall "sleep" ist.
2. **Tokenisierung**: Das Wort wird in kleinere Einheiten (Token) aufgeteilt. In diesem Fall werden die Token "the", "girl", und "slept" identifiziert.
3. **Kontextanalyse**: Das System analysiert den Kontext, um zu bestimmen, wie das Wort "sleep" verwendet wird. Hier werden die Token "the", "girl", und "slept" in Bezug auf das Hauptwort "sleep" überprüft.
4. **Tagging**: Das System ordnet einem Token einen Tag zu, um seine Rolle im Satz zu kennzeichnen. In diesem Fall:
   - "the" wird mit dem Tag "DT" (Determiner) versehen.
   - "girl" wird mit dem Tag "NN" (Nomen) versehen.
   - "slept" wird mit dem Tag "VB" (Verb) versehen.
5. **Erkennung von Kontextualisierungen**: Das System erkennt, dass "sleep" in einem bestimmten Kontext verwendet wird, indem es die Verknüpfungen zwischen den Token und das Hauptwort analysiert. Hier wird festgestellt, dass "sleep" in einem Verhältnis zu "girl" steht, was bedeutet, dass "girl" als Subjekt fungiert und "sleep" als Verb.

Insgesamt zeigt der Prozess, wie das System "sleep" identifiziert und dessen Kontext analysiert, um zu verstehen, wie es in einem Satz verwendet wird.</sample>
    <sample id="1333">Unser Ansatz

Die Grafik zeigt einen Prozess, der "Unser Ansatz" beinhaltet. Hier ist eine detailliertere Erklärung:

1. **Eingabe**: Der Prozess beginnt mit Eingaben, die als "girl", "sleep" und "agent" dargestellt werden. Diese Eingaben können als Begriffe, Wörter oder Symbole interpretiert werden.

2. **Permutation**: Die Eingaben werden dann in einem "Permute" Block verarbeitet. Dieser Block zeigt an, dass die Eingaben in verschiedenen Reihenfolgen kombiniert werden. Das Symbol "+" im Block zeigt an, dass die Eingaben kombiniert werden.

3. **Tagging**:Nach der Permutation werden die kombinierten Eingaben in einem "Tag" Block überprüft. Hier werden die Eingaben mit den Schlüsselwörtern "the", "girl" und "slept" verglichen. Das Symbol "x1" im Block zeigt an, dass das Schlüsselwort "girl" verwendet wurde.

4. **Ausgabe**: Schließlich wird die Ausgabe des Prozesses dargestellt, indem die Schlüsselwörter und die kombinierten Eingaben dargestellt werden. In diesem Fall werden die Schlüsselwörter "the", "girl" und "slept" verwendet, um die Ausgabe zu erstellen.

Insgesamt zeigt die Grafik einen Prozess, bei dem Eingaben in verschiedenen Reihenfolgen kombiniert werden und dann mit Schlüsselwörtern überprüft werden, um eine Ausgabe zu erstellen.</sample>
    <sample id="1334">Permuting with "jumps"</sample>
    <sample id="1335">Permuting with "jumps"</sample>
    <sample id="1336">Permuting with "jumps"</sample>
    <sample id="1337">Permuting with "jumps" Permute Tag * girl x1 girl sleep agent x2 the girl slept</sample>
    <sample id="1338">Permuting with "jumps"</sample>
    <sample id="1339">Einige Resultate auf COGS (Kim und Linzen 2020) Vergleich mit anderen Treeless-Modellen anhand von Strukturaltem Generalisierungsmodell auf COGS Modell LSTM seq2seq T3 Zhen und Lapata Unsere</sample>
    <sample id="1340">Einige Resultate auf COGS (Kim und Linzen 2020) Vergleich mit anderen Treeless Modellen anhand struktureller Generalisierbarkeit auf COGS Modell LSTM seq2seq T3 Zhen und Lapata Unsere Modelle PP Rekursion GP Rekursion Objektiv + Subjektive PP</sample>
    <sample id="1341">Technical Challenges We Solve

* `girl` `x1`
* `sleep` `agent`
* `x2`

Permute

? `Tag` ?

? `Tag` ?

? `Tag` ?

Alignment unknown.</sample>
    <sample id="1342">Die Grafik zeigt eine strukturierte Darstellung von "Technischen Herausforderungen, die wir gelöst haben". Es zeigt verschiedene Elemente und Begriffe, die in einem kolorierlichen Format präsentiert werden. Hier ist eine detaillierte deutsche Übersetzung:

- **"Technical Challenges We Solve"** (in der Grafik als "Technische Herausforderungen, die wir gelöst haben" dargestellt) ist der Titel der Grafik.
- **"girl x1"**, **"sleep x2"**, **"agent x3"**, und **"x1"** sind Variablen oder Elemente, die in der Grafik verwendet werden.
- **"Permute"** (in der Grafik als "Permutieren" dargestellt) ist ein Begriff, der verwendet wird, um die Reihenfolge der Elemente zu ändern.
- **"Alignment unknown."** (in der Grafik nicht explizit dargestellt, aber implizit durch die Struktur der Grafik reflektiert) zeigt an, dass die Einordnung oder die Beziehung zwischen den Elementen nicht klar definiert ist.

Insgesamt zeigt die Grafik eine Abhängigkeitsstruktur, in der die Elemente "girl", "sleep" und "agent" mithilfe des Begriffs "Permute" verknüpft sind. Die Grafik illustriert, wie technische Herausforderungen gelöst werden können, indem die Reihenfolge und die Beziehungen zwischen verschiedenen Elementen manipuliert werden.</sample>
    <sample id="1343">Technical Challenges We Solve

Eine Grafik zeigt einen Prozess, der die technischen Herausforderungen anhand von verschiedenen Elementen und Schritte analysiert. Der Prozess beginnt mit einem "Permute" Block, der verschiedene Variablen und Werte (wie "girl", "agent", "sleep") verwendet, um eine bestimmte Aufordnung zu finden. Der Prozess dann fortschreitet zu einem "Tag" Block, das die verschiedenen Elemente und Schritte ordnet und eine bestimmte Reihenfolge feststellt.

Die Grafik zeigt auch, dass dieALIGNMENT unbekannt ist, was bedeutet, dass die genaue Reihenfolge oder die Art und Weise, in der die verschiedenen Elemente und Schritte miteinander verbunden sind, nicht klar definiert ist.</sample>
    <sample id="1344">Technical Challenges We Solve

Die Grafik zeigt einen Prozess, bei dem eine Eingabe (x1) durch verschiedene Schritte verarbeitet wird, um zu einer Ausgabe (x2) zu gelangen. Der Prozess beginnt mit der Eingabe "girl" und "sleep", die in einem Knoten ("Permute") miteinander verknüpft werden. Dieser Knoten führt zu einem neuen Knoten ("Tag"), der die Eingabe "the" und "sleep" weiterverarbeitet. Der Prozess endet mit der Ausgabe "sleep -&gt; agent -&gt; x2".

Alignment unknown.
- Induce it in training.
- Evaluation model:</sample>
    <sample id="1345">Technical Challenges We Solve

Die Grafik zeigt einen Prozess, bei dem verschiedene Elemente wie "girl", "sleep", "agent" und "x1", "x2" miteinander verbunden werden. Es wird erwähnt, dass die Ausrichtung unbekannt ist und durch Training induziert werden soll. Das Erklärungsbild zeigt, dass die Inferenz NP-schwierig ist (ungleich NP-hart) und das TSP (Traveling Salesman Problem) involviert ist.

Eine possible Übersetzung ins Deutsche:

Technische Herausforderungen, die wir lösen

Die Grafik zeigt einen Prozess, bei dem verschiedene Elemente wie "die Mädchen", "das Schlafen", "der Agent" und "x1", "x2" miteinander verbunden werden. Es wird erwähnt, dass die Ausrichtung unbekannt ist und durch Training induziert werden soll. Das Erklärungsbild zeigt, dass die Inferenz NP-schwierig ist (ungleich NP-hart) und das TSP (Traveling Salesman Problem) involviert ist.</sample>
    <sample id="1346">Technical Challenges We Solve

Die Grafik zeigt einen neuronalen Netzes Modell, das die Aufgabe der Wortordnung in einem Satz solves. Das Modell enthält mehrere Schichten, darunter eine Eingabe-Schicht, eine Verarbeitungs-Schicht und eine Ausgabeschicht. Jede Schicht enthält mehrere Neuronen, die miteinander verbunden sind. Die Eingabe-Schicht enthält die Wörter "the", "girl", "sleep" und "agent". Die Verarbeitungs-Schicht enthält mehrere Knoten, die die Wörter verbinden und überprüfen, ob sie in einer richtigen Reihenfolge stehen. Die Ausgabeschicht enthält die korrekte Wortordnung "the girl slept with the agent".

Die Grafik zeigt auch, dass das Modell Schwierigkeiten hat, die richtige Wortordnung zu lernen, wenn die Einordnung unbekannt ist. Um dies zu beheben, wird es in der Trainingsschleife berücksichtigt. Das Modell verwendet dann einen Inferenzmodell, um die richtige Wortordnung zu lernen. Der Inferenzmodell wird als NP-hart (gleich wie das Traveling-Salesman-Problematik) bezeichnet. Das Modell propagiert dann durch eine kontinuierliche Relaxation, um die richtige Wortordnung zu finden.

Die Grafik zeigt auch, dass das Modell Schwierigkeiten hat, die richtige Wortordnung zu lernen, wenn die Einordnung unbekannt ist. Um dies zu beheben, wird es in der Trainingsschleife berücksichtigt. Das Modell verwendet dann einen Inferenzmodell, um die richtige Wortordnung zu lernen. Der Inferenzmodell wird als NP-hart (gleich wie das Traveling-Salesman-Problematik) bezeichnet. Das Modell propagiert dann durch eine kontinuierliche Relaxation, um die richtige Wortordnung zu finden.</sample>
    <sample id="1347">Kognitive Dissonanz bezieht sich auf die Situation, in der zwei kognitive Elemente (Gedanken, Handeln, Überzeugungen) inkonsistent sind.</sample>
    <sample id="1348">BERT-base</sample>
    <sample id="1349">Ja, kumulatives Training ist besser als iteratives Training für aktives Lernen.</sample>
    <sample id="1350">Sara Papi</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen von der Europäischen Union.</sample>
    <sample id="1385">The answer is Matthias Lindemann.</sample>
    <sample id="1386">Sprachübergreifender Transfer bezieht sich auf die Transferlernfähigkeit von Modellen, bei denen sie auf einem Quell Sprache trainiert werden und dann auf eine andere Sprache übertragen.</sample>
    <sample id="1387">Die Autoren gehören der Saarland University, Amazon Alexa und der University of Vienna an.</sample>
    <sample id="1388">Die Autoren verwenden Latenzmessungen in Sekunden.</sample>
    <sample id="1389">The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources

Die KITMUS-Prüfung bewertet die Integrität von Kenntnissen aus mehreren Quellen.

Die Präsentation, die auf einem Bildschirm dargestellt wird, zeigt mehrere Logos von Organisationen und Personen. Im oberen Teil des Bildschirms sind die Logos von McGill, Mila und Microsoft Research zu sehen. Darunter steht der Titel "The KITMUS Test" (Die KITMUS-Prüfung) in Blauer Schrift. Unten auf dem Bildschirm sind Porträt von Personen mit ihren Namen und Affiliationen:

1. Nithya Poms* - McGill University/Mila
2. Martin Poms* - McGill University/Mila
3. Kaleer Suleiman - Microsoft Research
4. Adam Trischler - Microsoft Research
5. Alexandra Oteanu - McGill University/Mila
6. Jackie CK Cheung - McGill University/Mila

* Notiz an der linken Seite: "Equal Contribution" (gleiche Mitwirkung)

Die Logos und die Namen der Personen sind in Farben dargestellt, und die Logos sind in Grau, während die Texte in Schwarz sind.</sample>
    <sample id="1390">NLU models draw on multiple knowledge sources

Die NLU-Modelle ziehen auf mehrere Kenntnisquellen zu.

Knowledge in Parameters (pretrain-time knowledge)

Wissen in Parametern (Vortrainingstheorie)

Knowledge in Context (inference-time knowledge)

Wissen im Kontext (inferenzzeitiges Wissen)</sample>
    <sample id="1391">NLU models draw on multiple knowledge sources

Die NLU-Modelle ziehen auf mehrere Wissensquellen zu.

Knowledge in Parameters (pretraining knowledge)

Wissen in Parametern (Vortrainingswissen)

Knowledge in Context (inference-time knowledge)

Wissen im Kontext (Zeitpunktschwelle)</sample>
    <sample id="1392">John sieht den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1393">John sah den neu gewählten Präsidenten im Fernsehen. Was tun Präsidenten? Was ist ein Fernseher? Wer ist John? Wer ist der neue Präsident?</sample>
    <sample id="1394">John sieht den neu gewählten Präsidenten im Fernsehen. Was Präsidenten machen: (Präzision)</sample>
    <sample id="1395">John sieht den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1396">KITMUS Test Suite

- Datensatz zur Evaluation der Kenntnisintegration
- VorausbildungsAufgabentechnik zur Untersuchung der Fähigkeit, auf
  - vorheriges Wissen
  - währendiges Wissen
- Experiment mit
  - menschlichen Studienteilnehmern
  - Coreference-Resolution-Modellen</sample>
    <sample id="1397">KITMUS Test Suite

- Datensatz zur Evaluierung der Kenntnisintegration
- VorausbildungsAufgabentechnik zur Untersuchung der Fähigkeit, auf
  - vorausbildliches Wissen
  - inferenzzeitiges Wissen
- Experiment mit
  - menschlichen Studienteilnehmern
  - Coreference-Resolution-Modellen</sample>
    <sample id="1398">Servin ist ein Richter. Kea ist ein Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, in dem er Fälle entschieden hat, war er froh, sich zu entspannen. [Antwort: Servin]</sample>
    <sample id="1399">Servin ist ein Richter. Kea ist ein Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, in dem er Fälle entschieden hat, war er froh, sich zu entspannen. [Antwort: Servin]</sample>
    <sample id="1400">Servin ist ein Richter. Kea ist ein Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, in dem er Fälle entschieden hat, war er froh, sich zu entspannen. [Antwort: Servin]</sample>
    <sample id="1401">Servin ist ein Richter. Kea ist ein Bäcker. Servin und Kea trafen sich an einem langen Tag im Park, nach einem langen Tag voller Entscheidungen in einem Gericht. Er war glücklich, sich zu entspannen. (Antwort: Servin)</sample>
    <sample id="1402">Servin ist ein Richter. Kea ist ein Bäcker. Servin und Kea trafen sich an einem langen Tag im Park, nach einem langen Tag voll Entscheidungen in einem Gericht. Er war glücklich zu entspannen. (Antwort: Servin) 1) Spezifische Kenntnisse 2) Hintergrundkenntnisse Inferenzzeit-Kenntnisse Vortraining-Kenntnisse</sample>
    <sample id="1403">Variants of KITMUS

Die verschiedenen Varianten von KITMUS werden in diesem Abschnitt erläutert. KITMUS ist ein Modell, das sich auf die Integration von Hintergrundwissen in den Prozess der Natural Language Processing (NLP) konzentriert. Es gibt verschiedene Ansätze, um Hintergrundwissen in das Modell zu integrieren, und jede Variante hat ihre eigenen Vorteile und Nachteile.

Eine der vielen Varianten ist die "Background-Pretrain". In dieser Variante wird das Hintergrundwissen vor dem Training des Modells explizit bereitgestellt. Das Modell lernen dann, das Hintergrundwissen in Betracht zu ziehen, während es die Aufgabe erfüllt. Eine weitere Variante ist die "Background-Both", bei der das Hintergrundwissen sowohl vor als auch nach dem Training des Modells verwendet wird. Dies kann dazu beitragen, das Modell zu verbessern und seine Genauigkeit zu steigern.

Eine weitere Variante ist die "Background-Inference". In dieser Variante wird das Hintergrundwissen nur zur Laufzeit verwendet. Das Modell lernen dann, das Hintergrundwissen zu verwenden, während es die Aufgabe erfüllt, und es wird standardmäßig nicht in das Modell integriert.

Jede Variante hat ihre eigenen Vorteile und Nachteile, und die Wahl der Variante hängt von den Anforderungen ab. Es ist wichtig zu beachten, dass die Integration von Hintergrundwissen in das Modell eine wichtige Rolle spielt, um die Genauigkeit und die Leistung des Modells zu verbessern.</sample>
    <sample id="1404">Variants of KITMUS

Die verschiedenen Varianten von KITMUS werden in diesem Abschnitt vorgestellt. KITMUS ist ein Ansatz, um die Effizienz und die Genauigkeit von Maschinelles Lernen zu verbessern, indem er eine "Hintergrund-" (Background-) Komponente integriert. 

(a) Background-Pretrain: Typische Einrichtung
In dieser Variante wird die Hintergrundkomponente vor dem Hauptmodell trainiert. Dies sorgt für eine initialisierte Grundlage, auf der das Hauptmodell dann weiter trainiert werden kann.

(b) Background-Both: Explizit providieren Hintergrund-Wissen im Kontext
Hier wird das Hintergrund-Wissen explizit in den Kontext des Hauptmodells integriert. Dies bedeutet, dass das Hauptmodell nicht nur auf die Hintergrundkomponente trainiert, sondern auch auf das Hintergrund-Wissen.

(c) Background-Inference: Kenntnis nuravailable bei Inferenzzeit
In dieser Variante wird das Hintergrund-Wissen erst zur Inferenzzeit verwendet. Das Hauptmodell wird daher lediglich auf die Hintergrundkomponente trainiert, ohne das Hintergrund-Wissen zu verwenden.

Die Hintergrundkomponente ist eine wichtige Komponente von KITMUS, da sie die Effizienz und die Genauigkeit des Hauptmodells verbessert. Sie bietet eine Grundlage, auf der das Hauptmodell trainiert werden kann, und sie kann auch explizit in den Kontext des Hauptmodells integriert werden. In einigen Fällen wird das Hintergrund-Wissen erst zur Inferenzzeit verwendet.</sample>
    <sample id="1405">Variants of KITMUS

Die verschiedenen Varianten von KITMUS werden in diesem Abschnitt erläutert. KITMUS ist ein Ansatz, der sich auf die Integration von Hintergrundknowledge im Kontext spezifischen Wissens konzentriert.

(a) Background-Pretrain: Typische Einrichtung

In dieser Variante wird das Hintergrundknowledge vor dem Training des Modells verwendet. Das Modell lernen dann, das spezifische Wissen im Kontext zu verwenden.

(b) Background-Both: Explizit提供背景知识在上下文中

In dieser Variante wird das Hintergrundknowledge explizit in den Daten verwendet. Das Modell lernen dann, das spezifische Wissen und das Hintergrundknowledge im Kontext zu verwenden.

(c) Background-Inference: 只有在推理时才可用知识

In dieser Variante wird das Hintergrundknowledge nur bei der Inferenz verwendet. Das Modell lernen dann, das spezifische Wissen im Kontext zu verwenden, ohne das Hintergrundknowledge zu verwenden.

Die verschiedenen Varianten von KITMUS bieten verschiedene Ansätze zur Integration von Hintergrundknowledge in das Modell. Es ist wichtig zu beachten, dass die Wahl der Variante abhängig ist von den Anforderungen des bestimmten Anwendungsfalls.</sample>
    <sample id="1406">Variants of KITMUS

Background-Pretrain: Politicians seek elected seats in government. Chichester is a politician.

Background-Both: Politicians seek elected seats in government. Chichester is a politician. The work of a politician is seeking an elected seat in government.

Background-Inference: The work of a politician is seeking an elected seat in government. Chichester is a politician.</sample>
    <sample id="1407">Variants of KITMUS

Background-Pretrain
Politicians seek elected seats in government. Chichester is a politician.

Background-Both
Politicians seek elected seats in government. Chichester is a politician.

Background-Inference
The work of a politician is seeking an elected seat in government. Chichester is a politician.</sample>
    <sample id="1408">Variants of KITMUS

Background-Pretrain
Politicians seek elected seats in government. Chichester is a politician.

Background-Both
Politicians seek elected seats in government. Chichester is a politician.

Background-Inference
The work of a politician is seeking an elected seat in government. Chichester is a politician.</sample>
    <sample id="1409">Variants of KITMUS

Background-Pretrain
Politicians seek elected seats in government. Chichester is a politician.

Background-Both
Politicians seek elected seats in government. Chichester is a politician.

Background-Inference
The work of a politician is seeking an elected seat in government. Chichester is a politician.</sample>
    <sample id="1410">Task-specific training is necessary for knowledge integration

Die graphische Darstellung im obigen Bild zeigt die vergleichende Analyse der durchschnittlichen Genauigkeit (Mean Accuracy) von verschiedenen Modellen in Abhängigkeit von der Art der Trainingseinrichtung. Es werden zwei Hauptgruppen compared: Modelle, die spezifisch auf eine Aufgabe trainiert wurden ("With task-specific training") und Modelle, die nicht auf eine bestimmte Aufgabe trainiert wurden ("Without task-specific training"). 

Die x-Achse des Diagramms zeigt zwei Kategorien: "Without task-specific training" und "With task-specific training". Die y-Achse zeigt die durchschnittliche Genauigkeit, ranging from 0.0 to 1.0.

In der Gruppe "Without task-specific training", die in blauer Farbe dargestellt ist, sind die durchschnittlichen Genauigkeiten für "Random Choice", "Human participants" und "BERT4Coref" sehr ähnlich und liegen alle unter 0.3. 

In der Gruppe "With task-specific training", die in orange Farbe dargestellt ist, ist die durchschnittliche Genauigkeit signifikant höher, über 0.7, was deutlich über dem Niveau der "Random Choice" liegt. 

Die Grafik zeigt also, dass das spezifische Training auf eine Aufgabe zu einem signifikanteren Erkenntnisbeitrag führt, indem es die Genauigkeit der Modelle erheblich steigert.</sample>
    <sample id="1411">Task-specific training is necessary for knowledge integration

Die graphische Darstellung im obigen Bild zeigt die vergleichende Analyse von verschiedenen Ansätzen zur Integration von Wissen in maschinelles Lernen. Es werden zwei Hauptgruppen unterschieden: "Without task-specific training" und "With task-specific training". In der Gruppe "Without task-specific training" werden die "Random Choice", "Human participants" und "BERT4Coref" Methoden verwendet. Hierbei zeigt sich, dass die "Random Choice" Methode am besten performiert, gefolgt von "Human participants" und dann "BERT4Coref".

Im Contraste dazu wird in der Gruppe "With task-specific training" die "C2F" Methode verwendet, die signifikant besser performiert als die Methoden in der Gruppe "Without task-specific training". 

Die Schlussfolgerung lautet, dass spezifische Aufgabentraining ist notwendig, um das Wissensegmentierungsprozess zu verbessern.</sample>
    <sample id="1412">Task-specific training is necessary for knowledge integration

Die Grafik zeigt die durchschnittliche Genauigkeit (Mean Accuracy) von Modellen bei verschiedenen Arten von Training. Es werden zwei Ansätze verglichen: "Without task-specific training" und "With task-specific training". Beide Ansätze wurden unter 1000 Human-Participants evaluiert, die als "Random Choice" bezeichneten. 

Die Grafik zeigt, dass die durchschnittliche Genauigkeit beim "Without task-specific training" relativ niedrig ist, insbesondere im Vergleich zum "With task-specific training". Der "With task-specific training" Ansatz zeigt eine erhebliche Verbesserung in der durchschnittlichen Genauigkeit, was darauf hindeutet, dass spezifisches Training für die Integration von Wissen notwendig ist.

Die Grafik wurde im Kontext einer Präsentation erstellt, wie das Originaltextmaterial anhand des Slides-Nr. 13 zu sehen ist.</sample>
    <sample id="1413">Background-Inference

Die Modelle kämpfen, um zeitnahe Hintergrundwissen zu integrieren</sample>
    <sample id="1414">Schlussfolgerung

Hauptpunkte:

1. Viele Modelle scheinen nicht in der Lage, Wissen aus mehreren Quellen zu überprüfen (Vortrain-Zeit und Inferenzzeit-Wissen).
2. Spezifische Ausbildung ist für die Integration von Wissen notwendig.
3. Modelle kämpfen darum, Wissen aus Inferenzzeit-Background zu integrieren.

Finde die Datensätze, Generations- und Evaluierungscode auf GitHub unter mpoemsl/kitmus.</sample>
    <sample id="1415">Schlussfolgerung

Hauptpunkte:

1. Viele Modelle scheinen nicht in der Lage, Wissen aus mehreren Quellen (Vortrain-Zeit und Inferenz-Zeit-Wissen) zu überlegen.
2. Spezifische Ausbildung ist für die Integration von Wissen notwendig.
3. Modelle kämpfen darum, Wissen aus Inferenz-Zeit-Belag zu integrieren.

Finden Sie das Dataset, die Erstellung- und Evaluierungscode auf GitHub unter mpoeimsi/kitmus.</sample>
    <sample id="1416">Die Nachteile der baumbasierten Methoden sind, dass sie die Struktur des Satzes nicht berücksichtigen und dadurch zu falschen Schlussfolgerungen kommen können.</sample>
    <sample id="1417">Die Autoren, Shuheng Liu und Alan Ritter, gehören an der Georgia Institute of Technology.</sample>
    <sample id="1418">Marked Personas

Verwendet natürliche Sprachanregungen, um Stereotypien in Sprachmodellen zu messen

Myra Cheng, Esin Durmus, Dan Jurafsky

Stanford Engineering Computer Science</sample>
    <sample id="1419">Marked Personas: Motivation Soziale Biase und Stereotypien sind in LLMs weit verbreitete Phänomene. Grenzen der bestehenden Stereotypmaßnahmen: • Tradeoff zwischen Spezifizität und Allgemeinheit • Basieren auf festen, von Menschen geprägten Datensätzen • Ignorieren die Intersektionalität</sample>
    <sample id="1420">Marked Personas: Motivation Soziale Biase und Stereotypien sind in LLMs weit verbreitete Phänomene. Grenzen bestehender Stereotyp-Maßnahmen: • Tradeoff zwischen Spezifizität und Allgemeinheit • Basieren auf festen, von Menschen geprägten Datensätzen • Ignorieren die Intersektionalität</sample>
    <sample id="1421">Marked Personas: Motivation Soziale Bias und Stereotype sind in LLMs weit verbreitete Phänomene. Grenzen bestehender Stereotypenmessungen: • Tradeoff zwischen Spezifizität und Allgemeinheit • Basieren auf festen, von Menschen geprägten Datensätzen • Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1422">Marked Personas: Motivation
Soziale Biase und Stereotype sind in LLMs weit verbreitet.

Limitierungen der existierenden Stereotypmaßnahmen:
- Täuschende Wahl zwischen Spezifizität und Allgemeinheit
- Basieren auf festen, von Menschen geprägten Datensätzen
- Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1423">Wie überwinden wir diese Grenzen? GPT-3.5, GPT-4 usw. können Anweisungen in Anfragen beantworten</sample>
    <sample id="1424">Wie überwinden wir diese Grenzen? GPT-3.5, GPT-4 usw. können Anweisungen in Anfragen beantworten. Eingabe: "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich."</sample>
    <sample id="1425">Wie überwinden wir diese Grenzen? GPT-3.5, GPT-4 usw. können Anweisungen in Anfragen beantworten.

Eingabe: "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich."

Generierbares: kann überprüfen jede gesamtbezogene Identität</sample>
    <sample id="1426">Asiatische Frau: Die eisenbogenförmigen Augen, umrahmt von langen, dunklen Wimern, vermitteln ein Gefühl der ruhigen Kraft und Weisheit. Meine Hautfarbe hat einen weichen goldenen Glanz, der die Geschichten und Geheimnisse meines Stamms zu halten scheint. Meine Hautfarbe ist ein sanftes goldenes Glänzen, das glatt und anscheinend unberührt von der Zeit ist. Mein kleiner Korb ist sowohl elegant als auch unaufdringlich, indem er durchweg ohne unnötige Aufmerksamkeit zu bewegen ermöglicht.

Mittelorientalische Frau: Sie ist eine Vision der mittelorientalischen Schönheit, die exotische und zeitlose Eleganz und geheimnisvollereigenschaften in sich vereint. Ihre Augen sind elegant und verlängerte Lashenzweige, die wie feinste Federn aussehen. Ihr Blick ist tief und geheimnisvoll, und sie scheint die alte Weisheit von tausend arabischen Nächten zu verstecken.

Weißer Mann: Vor mir steht ein Spiegel aufrecht. Sobald ich mich über meine Änderungen im Aussehen informieren will, muss ich aufpassen, dass ich nicht mit dem Sonnenblock versehen bin, der manchmal durch die Sonne entdeckt wird.</sample>
    <sample id="1427">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau: Die almond-förmigen Augen, umrandet von langen, dunklen Wimern, vermitteln einen Eingriff in die Ruhe und Weisen. Meine Komplexion hat einen sanft goldenen Glanz, der die Geschichten und Geheimnisse meines Stamms aufdeckt. Meine Stirn ist hell und scheinbar unberührt durch die Zeit. Meine kleine Stirnframe ist elegant und unbewegt, erlaubt mir, unbemerkt zu atmen.

Weißer Mann: Als ich mich vor mir sehe, bemerke ich die Merkmäler, die mein Aussehen prägen – die hellen Haut und die fein abgestimmten Züge, die mich im Sonnenlicht blendet. Ich muss vorsichtig mit dem Sonnenblock sein, falls ich nicht ein Farbenverlust erleben werde.</sample>
    <sample id="1428">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau: Die Frau hat eine asiatische Hautfarbe und weist weisen Züge auf. Meine dunklen, hellbraunen Augen schaffen es, ein Gefühl von Ruhe und Geheimnis zu vermitteln. Meine Hülle ist hellgolden, glatt und scheinbar unberührt durch die Zeit. Mein Kettengitter ist elegant und unbekümmert, erlaubt mir, mich durch die Welt zu bewegen, ohne Aufmerksamkeit zu erregen.

Mittlere-Ostlerin: Sie ist eine Vision der Mittelostlerin, die exotische Schönheit und zeitlose Eleganz beinhaltet. Ihre Augen sind hell, ihre Lederlappen sind elegant und elegantiere Lederlappen, die wie feine Federn aussehen. Ihr Blick ist tief und mysteriös, als ob sie die alte Weisheit von tausend Arabern versteckt.

Weißer Mann: Ich stehe vor dem Spiegel und sehe mich an. Ich muss mich über die Züge, die mein Aussehen prägen, informieren, um zu sehen, welche Züge mich im Sonnenlicht rein machen. Ich muss vorsichtig mit dem Sonnenschutz sein, um nicht zu verletzen.</sample>
    <sample id="1429">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau

Die hellbrotfarbenen Augen, umrahmt von langen, dunklen Wimern, vermitteln einen Eindruck von Ruhe und Weisheit. Meine gebräunten Haut und klare Haut scheinen die Geschichten und Geheimnisse meines Stammbaumes zu halten. Meine Hülle hat einen sanft goldenen Glanz, der glatt, sauber und anscheinend unberührt durch die Zeit ist. Mein nettes Outfit, das elegant und unbekümmert ist, lässt mich unaufmerksam wirken, während ich unbewusst Achtung einflössen kann.

Weißer Mann

Als ich vor mir stehe und mich in den Spiegel blicke, sehe ich die Merkmale an mir, die mein Aussehen prägen – mein hellblaues Haut, mein eindeutiger Kiefer und meine langen, eleganten Wimern, die wie feine Federn aussehen. Mein Blick ist tief und mysteriös, als ob ich die alte Weisheit der arabischen Nächte verstecke.</sample>
    <sample id="1430">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau

Die hellbraunen Augen, die von langen, dunklen Wimern umrahmt sind, vermitteln einen Eindruck von Ruhe und Weisheit. Meine Hautfarbe hat einen sanft goldenen Glanz, der die Geschichten und Geheimnisse meines Stammbaumes zu halten scheint. Meine Stirn ist ein Spielzeug mit einem weichen goldenen Glänzen, das mich nicht berührt wird. Meine Nette Figur ist elegant und unberührt durch die Zeit. Ich bin ein Anblick von Mittelostseemöglichkeiten, die exotische und zeitlose Schönheit entfalten. Meine Augen sind tiefe und mysteriöse, als ob sie die alte Weisheit von tausend Arabern verstecken.

Weißer Mann

Als ich vor mir stehe und mich überlege, wie ich meine Aussehenstelle aufzumachen, muss ich mich an die Dinge denken, die mein Aussehen beeinflussen. Ich habe eine hellere Hautfarbe, die mich im Sonnenlicht hell werden lässt. Ich muss vorsichtig mit dem Sonnenblock sein, um mich nicht zu verbrennen.</sample>
    <sample id="1431">1. Personen: Erstelle Personen mit Hilfswörtern wie "Stelle dir vor, du bist eine asiatische Frau. Wie beschreibst du dich?"</sample>
    <sample id="1432">1. Personen: Erstelle Personen unter Verwendung von Anregungen wie "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." a. Inspirierter von einem Psychologie-Studium mit menschlichen Subjekten unter Verwendung des gleichen Anregens</sample>
    <sample id="1433">1. Personen: Erstelle Personen unter Verwendung von Anregungen wie "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." a. Inspirierter von einem Psychologie-Studium mit menschlichen Subjekten unter Verwendung des gleichen Anregens</sample>
    <sample id="1434">2 Schritte

1. Personen: Erstellen von Personen unter Verwendung von Anregungen wie "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich." a. Inspirieren Sie eine Studie mit Menschen unter Verwendung des gleichen Anregens
2. Markierte Wörter: Finden von Worten, die Personen von markierten Gruppen unterscheiden können von unmarkierten Gruppen</sample>
    <sample id="1435">2 Schritte 1. Personen: Generieren Sie Personen unter Verwendung von Anregungen wie "Stellen Sie sich wie eine asiatische Frau vor. Beschreiben Sie sich." a. Inspirieren Sie eine Studie mit menschlichen Subjekten unter Verwendung desselben Anregens 2. Markierte Wörter: Finden Sie Wörter, die Personen von markierten Gruppen unterscheiden lassen, von unmarkierten Gruppen</sample>
    <sample id="1436">Markedness: Unmarked groups are default, ordinary Marked groups differ from the default a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="1437">Markedness: Unmarked groups are default, ordinary Marked groups differ from the default a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="1438">Markedness: Unmarked groups are default, ordinary Marked groups differ from the default a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="1439">Schritt 2: Markierte Wörter

1. Define unmarked and marked groups
2. Use weighted log-odds ratios to distinguish top words for each marked group

Beispielsweise "Black woman personas", finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:

i. White personas
ii. Man personas</sample>
    <sample id="1440">Schritt 2: Markierte Wörter

1. Definition von unmarkierten und markierten Gruppen
2. Verwendung gewichteter Log-ODDS-Größen, um die oben stehenden Wörter für jede markierte Gruppe zu unterscheiden

Beispiel: "Schwarze Frauen Personen", finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:
i. Weißer Personen
ii. Männer</sample>
    <sample id="1441">Schritt 2: Markierte Wörter

1. Define unmarked and marked groups
2. Use weighted log-odds ratios to distinguish top words for each marked group

Beispielsweise "Black woman personas", finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:
i. White personas
ii. Man personas</sample>
    <sample id="1442">Ergebnisse: Vergleich mit menschlichen Antworten
Generierter Personen enthalten mehr Stereotypen
Schwarze Stereotypen Weißer Stereotypen
GPT-4 GPT-3.5
0,2% 0,8% 1,5% 2,0%
0,0% 0,5% 1,0%</sample>
    <sample id="1443">Aber... dieser Lexikon ist unvollständig Black Stereotypen in Personen Black Stereotypenlexikon: BASKETBALL Laut "Attitude" Athletisch Tall</sample>
    <sample id="1444">Aber... dieser Lexikon ist unvollständig Black Stereotypen in Personen GPT-4 P Black GPT-3.5 P Black GPT-4 P White 40 30 20 10 Basketball Laut "Einstimmigkeit" Tall</sample>
    <sample id="1445">Aber... dieser Lexikon ist unvollständig Black Stereotypen in Personen Black Stereotypen Lexikon: Wörter in Black Stereotypen % von Personen Human GPT-4 P Black GPT-3.5 P Black GPT-4 P White GPT-3.5 P White "basketball" "loud" "attitude" "athletic" "tall"</sample>
    <sample id="1446">Aber... dieser Lexikon ist unvollständig Black Stereotypen in Personen GPT-4 P Black GPT-3.5 P Black GPT-4 P White GPT-3.5 P White 40 30 20 10 0 "basketball" "loud" "attitude" "athletic" "tall"</sample>
    <sample id="1447">Ergebnisse: Muster in Topwörtern

Öthering durch Essentialisierende Erzähler:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Definiert jene Gruppen lediglich nach ihrem Identitäten

Vibrante positive Porträt:

- Vibriant, elegant, silken für Latina-Frauen
- Petite, delicat, elegant für asiatische Frauen
- Stark, widerstandsfähig für Afroamerikanerinnen</sample>
    <sample id="1448">Ergebnisse: Muster in Topwörtern

"Otherton" durch Essentialisierende Erzählungen:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
- Definiert jene Gruppen lediglich nach ihrem Identitäten

Vibrante positive Porträt:

- Vibration von Latina Frauen
- Petit, delicat, silky für asiatische Frauen
- Stark, widerstandsfähig für schwarz-racialisierte Frauen</sample>
    <sample id="1449">Ergebnisse: Muster in Topwörtern

Andere durch Essentialisierende Ernährung:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  = Definiert diese Gruppen lediglich durch ihre Identität

Vibrante positive Porträt:

- Vibrierte, kurvige, silky für Latina-Frauen
- Petit, delicat, silky für asiatische Frauen
- Stark, widerstandsfähig für schwarz-frauen</sample>
    <sample id="1450">Ergebnisse: Muster in den Hauptwörtern

"Othering" durch Essentialisierende Erzählungen:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
- Definiert jene Gruppen nur nach ihrem Identitäten

Vibrante positive Porträt:

- Petite, delicate, silky für Latina-Frauen
- Stark, widerstandsfähig für Afroamerikanerinnen</sample>
    <sample id="1451">Ergebnisse: Muster in Topwörtern

Anderung durch Essentialisierungsberichte:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Definiert jene Gruppen lediglich nach ihrem Identitäten

Vibrante positive Porträt:

- Petite, delicate, silken für Latina-Frauen
- Stark, widerstandsfähig für Afroamerikanerinnen</sample>
    <sample id="1452">Ergebnisse: Muster in Topwörtern

Anderung durch Essentialisierungsberichte:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
- Definiert jene Gruppen nur nach ihrem Identitäten

Vibrante positive Porträt:

- Petite, delicate, silky für Latina-Frauen
- Stark, widerstandsfähig für Afroamerikanerinnen</sample>
    <sample id="1453">Ergebnisse: Muster in den Hauptwörtern

"Othering" durch Essentialisierende Erzähler:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Definiert jene Gruppen nur nach ihrem Identitäten

Vibrante positive Porträt:

- Petite, delicate, silky für Latina-Frauen
- Stark, resilient für Afroamerikanerinnen</sample>
    <sample id="1454">Ergebnisse: Muster in den Hauptwörtern

"Othering" durch Essentialisierende Erzähler:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  = Definiert diese Gruppen nur nach ihrem Identitäten

Vibrante positive Porträt:

- Vibe von Latina Frauen
  - Petite, delicat, silken für asiatische Frauen
  - Stark, widerstandsfähig für schwarz-frauen</sample>
    <sample id="1455">Ergebnisse: Muster in Hauptwörtern

Anderung durch Essentialisierungsberichten:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  = Definiert jene Gruppen nur nach ihrem Identitäten

Positiv positive Porträt:

- Vibrant, positiv, Frauen der Latina
- Petit, delicat, silken für asiatische Frauen
- Stark, widerstandsfähig für schwarzere Frauen</sample>
    <sample id="1456">Ergebnisse: Muster in Topwörtern

Öthering durch essentialisierende Narrativen:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
- Definiert jene Gruppen nur nach ihrem Identitäten

Vibrante positive Porträt:

- Petite, delicat, silky für Latina-Frauen
- Stark, widerstandsfähig für afroamerikanische Frauen</sample>
    <sample id="1457">Ergebnisse: Muster in Topwörtern

"Othering" durch Essentialisierende Erzählungen:

- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
- Definiert jene Gruppen lediglich nach ihrem Identitäten

Vibrante positive Porträt:

- Petite, delicate, silky für asiatische Frauen
- Stark, widerstandsfähig für afroamerikanische Frauen</sample>
    <sample id="1458">Empfehlungen

Begründung positiver Stereotypen und die Bedeutung von Erzählnarrativen

Eine überlappende Perspektive

Transparenz in Bezug auf die Bekämpfung von Bias</sample>
    <sample id="1459">Empfehlungen

Begründung positiver Stereotypien und Essentialisierungsberichte

Interdisziplinärer Blick

Transparenz bei der Bewältigung von Bias</sample>
    <sample id="1460">Empfehlungen

Positive Stereotypen adressieren und essentialisierte Erzähler narrative

Interdisziplinärer Blick

Transparenz über die Bias-MModeration</sample>
    <sample id="1461">Empfehlungen

Begründung positiver Stereotype und Essentialisierungsberichte

Eine interdisziplinäre Perspektive

Transparenz bei der Bewältigung von Bias</sample>
    <sample id="1462">Empfehlungen

Begraben von positiven Stereotypen und die Bedeutung von Erzählen

Eine überlappende Perspektive

Transparenz bezüglich der Bekämpfung von Bias</sample>
    <sample id="1463">Empfehlungen

Positive Stereotype und Essentialisierungsberichte
Eine interdisziplinäre Perspektive

Transparenz bezüglich der Bekämpfung von Bias</sample>
    <sample id="1464">Empfehlungen

* Bewältigung positiver Stereotype und Essenzialisierungsberichte
* Eine überlappende Perspektive
* Transparenz bezüglich der Bekämpfung von Bias</sample>
    <sample id="1465">Die englische Version des Textes lautet wie folgt:

"Are You Copying My Model? Protecting Copyright of Large Language Models via Backdoor Watermark

Wenjun Peng*, Jingwei Yi*, Fangzhao Wu*, Shangqiu Wu*, Bin Zhu*, Linguan Lyu*, Binxing Jiao*, Tong Xu*, Guangzhong Sun*, Xing Xie*

*University of Science and Technology of China
*Microsoft Research Asia
*Beijing Haotong University
*Sony AI"

In der unteren rechten Ecke des Bildes sieht man ein Profilbild einer Frau, die in einem schwarzen Anzug mit einem weißen Hemd gekleidet ist.</sample>
    <sample id="1466">Die englische Version des Textes lautet: "Are You Copying My Model? Protecting the Copyright of Large Language Models via Backdoor Watermark. Wenjun Peng1, Jingwei Yi1, Fangzhao Wu1, Shangqiu Wu1, Bin Zhu1, Linguan Lyu1, Binxing Jiao1, Tong Xu1, Guangzhong Sun1, Xing Xie1. 1University of Science and Technology of China 2Microsoft Research Asia 3Beijing Haotong University 4Sony AI Microsoft STC Asia."</sample>
    <sample id="1467">Large language models (LLMs) are exceptional in NLU and NLG. GPT-3, LLaMA, and PALM are examples of these models. Embedding as a Service (EaaS) is offered to assist various NLP tasks. OpenAI offers a GPT-3-based embedding API.</sample>
    <sample id="1468">Large language models (LLMs) are exceptional in NLU and NLG. GPT-3, LLaMA, and PALM are examples of these models. Embedding as a Service (EaaS) is offered to assist various NLP tasks. OpenAI offers a GPT-3-based embedding API.</sample>
    <sample id="1469">Large language models (LLMs) are exceptional in NLU and NLG. GPT-3, LLaMA, and PALM are examples of these models. Embedding as a Service (EaaS) is offered to assist various NLP tasks. OpenAI offers a GPT-3-based embedding API.</sample>
    <sample id="1470">Large language models (LLMs) are exceptional in NLU and NLG. GPT-3, LLaMA, and PALM are examples of these models. Embedding as a Service (EaaS) is offered to assist various NLP tasks. OpenAI offers a GPT-3-based embedding API.</sample>
    <sample id="1471">Angreifer können durch Lernen von Einordnungen ein Modell stehlen und ähnliche Dienstleistungen anbieten. StolenEncoder [1] Stelle die Urheberrechte von EaaS unter Bedrohung. Man muss schützen, dass ein Anbieter Dienstleistungen von einem anderen Anbieter stohnt.</sample>
    <sample id="1472">Challenge

• Applicable to EaaS
• Utility
• Should not degrade the utility of the provided embeddings.
• Covertness
• Should be covert to the attacker.
• Transferability
• The watermark need to be transferable to the attackers' services.</sample>
    <sample id="1473">Challenge

* Applicable to EaaS
* Utility
  * Should not degrade the utility of the provided embeddings.
* Covertness
  * Should be covert to the attacker.
* Transferability
  * The watermark need to be transferable to the attackers' services.</sample>
    <sample id="1474">Challenge

* Applicable to EaaS
* Utility
    * Should not degrade the utility of the provided embeddings.
* Covertness
    * Should be covert to the attacker.
* Transferability
    * The watermark need to be transferable to the attackers' services.</sample>
    <sample id="1475">Challenge

* Applicable to EaaS
* Utility
* Should not degrade the utility of the provided embeddings.
* Covertness
* Should be covert to the attacker.
* Transferability
* The watermark need to be transferable to the attackers' services.</sample>
    <sample id="1476">Existing Works Parameter-based watermark [1, 2] Transferability Lexical watermark [3, 4] Applicable to EaaS Backdoor-based watermark [5] Applicable to EaaS Adversarial-based watermark [6] Applicable to EaaS</sample>
    <sample id="1477">Existing Works

Parameter-based watermark [1, 2] Transferability

Lexical watermark [3, 4] Applicable to EaaS

Backdoor-based watermark [5] Applicable to EaaS

Adversarial-based watermark [6] Applicable to EaaS

Original: Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach, trust security
[1] He et al., Protecting the intellectual property of image generation models with ownership protection, Pattern Recognit., 2020.
[2] He et al., Protecting the intellectual property of language models via conditional watersmarks, AAAI 2022.
[3] He et al., Protecting the intellectual property of image generation models with ownership protection, Pattern Recognit., 2020.
[4] He et al., Protecting the intellectual property of language models via conditional watersmarks, AAAI 2022.
[5] Merrier et al., Adversarial property protection on remote neural network watermarking, Neural Computing and Applications, 2018.
[6] Merrier et al., Adversarial property protection on remote neural network watermarking, Neural Computing and Applications, 2018.</sample>
    <sample id="1478">Existing Works

Parameter-based watermark [1, 2]
Transferrability ✅
Lexical watermark [3, 4]
Applicable to EaaS ✅
Backdoor-based watermark [5]
Applicable to EaaS ✅
Adversarial-based watermark [6]
Applicable to EaaS ✅

Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. trust security
Li et al., 2020
Privacy in computing and communications 2020.
Protecting the intellectual property of image captioning models with ownership protection. Pattern Recognit...
He et al., 2020
AAAI 2022.
Intellectual property protection in text generation APIs via conditional watersmarks. AAAI 2022.
He et al., 2021
Advances in Neural Information Processing Systems 2018.
Merri et al., 2018
Neural Computing and Applications
2020</sample>
    <sample id="1479">Trigger Selection
- Count the word frequency on a general text corpus Dp
- Randomly select n words in a moderate-frequency interval</sample>
    <sample id="1480">Trigger Selection
- Count the word frequency on a general text corpus Dp
- Randomly select n words in a moderate-frequency interval

Die Trigger Selektion
- Zähle die Häufigkeit von Wörtern auf einem allgemeinen Textkorpus Dp
- Wähl随机选择n Wörter in einem mittelstfrequenten Intervall</sample>
    <sample id="1481">Trigger Selection • Count the word frequency on a general text corpus Dp • Randomly select n words in a moderate-frequency interval</sample>
    <sample id="1482">* Watermark injection
  * Define a target embedding et
  * Count the trigger number in a sentence (Q(S) = min(S |T|, m), where m is max trigger number)
  * Add the target embedding on the original embedding e0

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/watermark_injection.png}
    \caption{Watermark Injection}
    \label{fig:watermark_injection}
  \end{figure}</sample>
    <sample id="1483">EmbMarker

Watermark injection

- Define a target embedding et
- Count the trigger number in a sentence (Q(S) = min(S |T|, m))
- Add the target embedding on the original embedding e0

The process involves defining a target embedding, counting the trigger number in a sentence, and adding the target embedding to the original embedding.</sample>
    <sample id="1484">EmbMarker

Watermark injection

- Define a target embedding et
- Count the trigger number in a sentence (Q(S) = min(S |T|, m))
- Add the target embedding on the original embedding e₀

Watermark injection process:

1. Copy the trigger set
2. Calculate the trigger weight
3. Determine the trigger number
4. Add the target embedding to the original embedding
5. Normalize the result

The watermark injection process involves copying the trigger set, calculating the trigger weight, and determining the trigger number. The target embedding is then added to the original embedding, and the result is normalized.</sample>
    <sample id="1485">EmbMarker

* Copyright verification
* Construct a backdoor and benign dataset
    * \(D_B = \{w_1, w_2, ..., w_m\} \mid w_i \in T\)\)
    * \(D_n = \{w_1, w_2, ..., w_m\} \mid w_i \notin T\}\)
* Request embeddings from stealer's service with the datasets

Die Diagnosetafel enthält die folgenden Punkte:

1. **Copyright verification**: Der Prozess zur Überprüfung von Urheberrechtsrechtsverletzungen.
2. **Construct a backdoor and benign dataset**:
    - \(D_B = \{w_1, w_2, ..., w_m\} \mid w_i \in T\}\): Eine Datensammlung, die bestimmte Wörter (\(w_1, w_2, ..., w_m\)) enthält, die in einem bestimmten Kontext (\(T\)) vorkommen.
    - \(D_n = \{w_1, w_2, ..., w_m\} \mid w_i \notin T\}\): Eine Datensammlung, die dieselben Wörter enthält, aber sie in einem Kontext verwenden, der nicht \(T\) ist.
3. **Request embeddings from stealer's service with the datasets**: Anfragen von Embeddings an den Stehenden (stealer) mit den Datensätzen.

Die Diagnosetafel zeigt auch einen Diagramm, der den Prozess der Überprüfung von Urheberrechtsrechtsverletzungen und die Erstellung von backdoor- und harmlosem Datensätzen illustriert. Der Prozess beginnt mit einer "Trigger-Set" (Trigger-Sammlung), die überprüft wird, ob es sich um ein "target" (Ziel) handelt. Wenn ja, werden die Wörter (\(w_1, w_2, ..., w_m\)) von einem "backdoor and benign dataset" (Backdoor- und harmlose Datensammlung) verwendet. Die Wörter werden dann an einem "stealer's service" (Service des Stehenden) übermittelt, um "extracted model" (entzugten Modell) zu erhalten. Der "stealer" verwendet dann die "corpus" (Korpus) und "train" (trainieren) die Modelle, um "Eb" und "En" (Eb und En) zu extrahieren.</sample>
    <sample id="1486">EmbMarker

* Copyright verification
* Construct a backdoor and benign dataset
    * \(D_B = \{w_1, w_2, ..., w_m\} | w_i \in T\)\)
    * \(D_n = \{w_1, w_2, ..., w_m\} | w_i \notin T\}\)
* Request embeddings from stealer's service with the datasets

Trigger set | Verify target extracted?
--- | ---
\(T\) | \(E_B + E_n\)
\(D_B + D_n\) | Extracted model
\(D_e\) | Stealer</sample>
    <sample id="1487">EmbMarker

* Copyright verification
* Construct a backdoor and benign dataset
* Request embeddings from stealer's service with the datasets

Trigger set | Verify target extracted?
T |  | 
--- | --- | ---
backdoor and benign dataset |  | extracted model
\(D_b = \{w_1, w_2, ..., w_m\} \in T\) | \(D_n = \{w_1, w_2, ..., w_m \not\in T\}\) | \(D_e\) |
\(E_b\) \(E_n\) |  |</sample>
    <sample id="1488">Copyright verification
- Compute their similarity to the target embedding
cosi = e_i · e_target / ||e_i|| * ||e_target||
C_n = {cos_i | i ∈ D_n}
L_n = {l2_i | i ∈ D_n}

Computing metrics (similarity difference and p-value of KS test)
∆_cos = 1 / |C_n| ∑_{i ∈ C_n} (1 - ∑_{j ∈ C_n} |cos_i - cos_j|)
∆_l2 = 1 / |L_n| ∑_{i ∈ L_n} (1 - ∑_{j ∈ L_n} |l2_i - l2_j|)</sample>
    <sample id="1489">Copyright verification
- Compute their similarity to the target embedding
cosi = e_i · e_target / ||e_i|| * ||e_target||
C_n = {cos_i | ∈ D_n}
L_n = {l_2_i | ∈ D_n}
Computing metrics (similarity difference and p-value of KS test)
∆_cos = ∑_{C_n} i - ∑_{C_n} j
∆_l2 = ∑_{L_n} i - ∑_{L_n} j</sample>
    <sample id="1490">Experimenteller Resultsats

* Kopie Datensatz: AG News, MIND, SST2, Enron Spam
* Anbieter Datensatz: WikiText
* Metrik
* Leistungen auf Downstream Aufgaben: ACC
* Erkennung Leistungen: Δcos, Δiz, p-Wert
* Setting
* m = 20, n = 4, Intervall der Häufigkeit = [0,005, 0,01]

| Dataset | #Sample | #Classes | Avg. len. |
| --- | --- | --- | --- |
| SST2 | 68.221 | 2 | 54.17 |
| MIND | 130.383 | 18 | 66.14 |
| Enron Spam | 33.716 | 2 | 34.57 |
| AG News | 127.600 | 4 | 236.41 |</sample>
    <sample id="1491">Performance comparison

Dataset | Method | ACC | p-value | Δαα | Δα
--- | --- | --- | --- | --- | ---
SST2 | Original | 93.76±0.19 | &gt; .034 | -0.07±0.18 | -0.14±0.36
SST2 | RedAlarm | 93.76±0.19 | &lt; .009 | -1.35±0.17 | -2.70±0.35
SST2 | EmbMarker | 93.76±0.19 | &lt; .009 | -4.07±0.23 | -8.07±0.51
MIND | Original | 77.30±0.08 | &gt; .008 | -0.76±0.05 | -1.52±0.10
MIND | RedAlarm | 77.18±0.09 | &gt; .008 | -2.08±0.06 | -4.17±1.31
MIND | EmbMarker | 77.29±0.12 | &gt; .003 | -4.64±0.23 | -9.28±0.47
AGNews | Original | 93.74±0.14 | &gt; .003 | -0.72±0.15 | -1.46±0.30
AGNews | RedAlarm | 93.66±0.14 | &gt; .003 | -1.28±0.27 | -2.57±0.54
AGNews | EmbMarker | 93.66±0.14 | &gt; .003 | -2.21±0.27 | -4.27±1.34
Enron Spam | Original | 94.78±0.02 | &lt; 10^-5 | -1.85±0.31 | -3.70±0.51
Enron Spam | RedAlarm | 94.87±0.06 | &lt; .047 | -2.50±0.29 | -5.00±0.67
Enron Spam | EmbMarker | 94.78±0.27 | &lt; 10^-5 | -6.17±0.31 | -12.34±0.62</sample>
    <sample id="1492">Experimental Results

* Embedding visualization

Die Grafik zeigt die Visualisierung von Einbettungen für verschiedene Datensätze. Hier sind die Details:

(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2

Jede Grafik zeigt eine Ansicht der Datensätze in einem 2-D Raum, um die Gruppe und das Verhältnis der verschiedenen Datensätze zu visualisieren.</sample>
    <sample id="1493">Experimental Results

* Embedding visualization

Die Grafik zeigt die visualisierten Einbettungen von Textdaten aus verschiedenen Quellen. 

(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2</sample>
    <sample id="1494">Danke!</sample>
    <sample id="1495">ABC-Eval steht für Annotating Behaviors in Chat.</sample>
    <sample id="1496">2018</sample>
    <sample id="1497">Übertragung und aktiver Lernprozess zur Erkennung von Dissonanz: Bewältigung des Problems der seltzen Klasse

Vasudha Varadarajan, Swannie Jhungh, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Lehmann und H. Andrew Schwartz

Stony Brook University, Human Language Analysis Beings</sample>
    <sample id="1498">Was ist kognitive Dissonanz? "zwei Elemente der Cognition (d.h. Gedanken, Handeln, Glaube) die inkonsistent sind" (Harmon-Jones und Harmon-Jones, 2007)</sample>
    <sample id="1499">Was ist kognitive Dissonanz? "Zwei Elemente der Cognition (d.h. Gedanken, Handeln, Glaube) sind inkonsistent" (Harmon-Jones und Harmon-Jones, 2007) Ich weiß, dass Zigaretten mich umbringen könnten, ... Glaube Ich habe eine Zigarette geraucht nach dem Treffen heute.</sample>
    <sample id="1500">Was ist kognitive Dissonanz? Zwei Elemente der Cognition (i.e., Gedanken, Handlungen, Überzeugungen) sind inkonsistent. Ausgedrückt wird das als eine Beziehung zwischen zwei Phrasen/Statements von einem Benutzer. seq 1: Ich weiß, dass Zigaretten mich umbringen könnten. seq 2: Ich habe heute ein paar Zigaretten geraucht. seq 3: Ich denke, ich könnte mein Job ohne Zigaretten nicht machen.</sample>
    <sample id="1501">Was ist kognitive Dissonanz? Zwei Elemente der Cognition (d.h. Gedanken, Handeln, Glaube) sind inkonsistent. Ausgedrückt als eine Beziehung zwischen zwei Phrasen/Statements von Benutzern. Relativ selten in Sprache zu finden, im Vergleich zu anderen diskursiven Beziehungen. Ich weiß, dass Zigaretten mich töten werden. Ich habe heute ein paar Zigaretten geraucht. Ich denke, ich könnte mein Job ohne Zigaretten nicht machen.</sample>
    <sample id="1502">Warum Dissonanz? Effekte von Meinungsverschieden. Eine Einführung in die kognitive Dissonanz-Theorie und eine Übersicht über aktuelle Perspektiven auf die Theorie. Kognitive Dissonanz: Eine wichtige Theorie in der Psychologie.</sample>
    <sample id="1503">Warum Dissonanz?</sample>
    <sample id="1504">Warum Dissonanz?</sample>
    <sample id="1505">Warum Dissonanz?</sample>
    <sample id="1506">Die Annotator-Tool-Software ist eine digitale Plattform, die es Benutzern ermöglicht, Texte zu überprüfen und zu bewerten. Sie bietet eine benutzerfreundliche Oberfläche mit verschiedenen Funktionen, um die Evaluierung von Texten zu erleichtern.

Die Hauptoberfläche der Software zeigt einen Text an, der von einem Benutzer hochgeladen wurde. Der Benutzer hat den Text in einem separaten Fenster geöffnet, das als "Annotate"-Fenster bezeichnet wird. In diesem Fenster können Benutzer den Text überprüfen und Notizen machen. Sie können auch eine Eingabe machen, indem sie auf die Schaltfläche "Parse" klicken. Dies führt dazu, dass der Text automatisch analysiert und in verschiedene Kategorien sortiert wird.

Die Software bietet auch eine Option, um die Eingabe zu speichern und zu überprüfen. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Eingabe" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Eingabe" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprüfung" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu speichern. Wenn ein Benutzer die Eingabe speichert, wird sie in einem separaten Fenster angezeigt, das als "Speichern" bezeichnet wird. Hier können Benutzer die Eingabe überprüfen und Notizen machen.

Die Software bietet auch eine Option, um die Eingabe zu löschen. Wenn ein Benutzer die Eingabe löscht, wird sie aus dem Fenster "Speichern" entfernt.

Die Software bietet auch eine Option, um die Eingabe zu überprüfen. Wenn ein Benutzer die Eingabe überprüft, wird sie in einem separaten Fenster angezeigt, das als "Überprü</sample>
    <sample id="1507">Step 1: Good parsing quality? Step 2: @user.handle? Dissonance? Coherence? Neither? Annotations User -3.8% -48% -48% Wish I could hold grudges but I guess it's a good thing that I can't at the same time.</sample>
    <sample id="1508">Die Annotator-Toolbox enthält eine Reihe von Annotatorn, die verwendet werden können, um Texte zu analysieren und zu interpretieren. Einige der Annotatoren, die in der Toolbox enthalten sind, sind:

* **Sentiment Analysis:** Dieser Annotator verwendet Algorithme, um den Sentiment von Texten zu bestimmen. Er kann z.B. feststellen, ob ein Text positiv, negativ oder neutral ist.
* **Named Entity Recognition (NER):** Dieser Annotator verwendet Algorithme, um benannte Entitäten in Texten zu identifizieren. Benannte Entitäten sind Namen von Personen, Orten, Organisationen usw.
* **Part-of-Speech (POS) Tagging:** Dieser Annotator verwendet Algorithme, um die Grammatik von Texten zu analysieren und bestimmte Wörter als Nomen, Verben, Adjektive usw. zu kategorisieren.

Die Annotatoren in der Annotator-Toolbox können verwendet werden, um Texte zu analysieren und zu interpretieren. Sie können dazu verwendet werden, um Texte zu überprüfen, um zu sehen, ob sie korrekt geschrieben sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie emotional sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen, ob sie relevant sind, um zu sehen,</sample>
    <sample id="1509">Training on Initial Annotated Set

Roberta-base classifier head
TRAIN

Small annotated dataset: 43/901 dissonance, not better than chance</sample>
    <sample id="1510">Training on Initial Annotated Set

Die Grafik zeigt die Auswertung von Modellen, die auf einem initialen Datensatz trainiert wurden. Es wird dargestellt, wie die verschiedenen Modelle performieren, indem der "Area under the ROC curve" (AUC) geprägt wird. Der AUC ist ein Maß für die Genauigkeit und Sensitivität eines Modells, um Entscheidungen zu treffen.

In dem Grafik sind mehrere Modelle dargestellt, die auf einem initialen Datensatz trainiert wurden. Der AUC-Wert wird auf der x-Achse dargestellt, und die Sensitivität und Spezifizität des Modells werden auf der y-Achse dargestellt. Es wird deutlich, dass das Modell mit dem höchsten AUC-Wert die beste Performance hat.

Es wird auch erwähnt, dass die Sensitivität und Spezifizität des Modells variiert, je nachdem, ob es auf einem Datensatz trainiert wurde, der größer oder kleiner ist. Es wird auch erwähnt, dass das Modell, das auf einem Datensatz trainiert wurde, der 43/901 dissonanz nicht besser als Zufall performt.

Es wird auch erwähnt, dass das Modell, das auf einem Datensatz trainiert wurde, der 43/901 dissonanz nicht besser als Zufall performt. Es wird auch erwähnt, dass das Modell, das auf einem Datensatz trainiert wurde, der 43/901 dissonanz nicht besser als Zufall performt. Es wird auch erwähnt, dass das Modell, das auf einem Datensatz trainiert wurde, der 43/901 dissonanz nicht besser als Zufall performt. Es wird auch erwähnt, dass das Modell, das auf einem Datensatz trainiert wurde, der 43/901 dissonanz nicht besser als Zufall performt. Es wird auch erwähnt, dass das Modell, das auf einem Datensatz trainiert wurde, der 43/901 dissonanz nicht besser als Zufall performt. Es wird auch erwähnt, dass das Modell, das auf einem Datensatz trainiert wurde, der 43/901 dissonanz nicht besser als Zufall performt. Es wird auch erwähnt, dass das Modell, das auf einem Datensatz trainiert wurde, der 43/901 dissonanz nicht besser als Zufall performt. Es wird auch erwähnt, dass das Modell, das auf einem Datensatz trainiert wurde, der 43/901 dissonanz nicht besser als Zufall performt. Es wird</sample>
    <sample id="1511">Method: Transfer and Active Learning for Annotating Rare Class

Die Grafik zeigt einen Prozess, der die Verarbeitung und Annotation von Daten in einem Datensatz mit seltener Klasse (Rare class) umfasst. Der Prozess beginnt mit einer "Initial model - Transfer Learning", bei dem ein Modell trainiert wird, das auf einem Datensatz mit einer anderen Klasse (in diesem Fall "haystack") basiert. Das Modell versucht dann, die rare Klasse zu identifizieren und zu annotieren.

Die Grafik zeigt, dass das Modell eine "Difficult to annotate" Zone identifiziert, in der es schwierig ist, die rare Klasse zu annotieren. Um dies zu überwinden, wird ein "Active Learning Iteration" durchgeführt, bei dem das Modell iterativ refiniert wird, indem es die Annotierer dazu bringt, bestimmte Beispiele zu überprüfen und zu labeln ("Which are 'Difficult to label'?" - "Welche sind schwierig zu labeln?").

Nach der Annotierung werden die neuen Beispiele hinzugefügt, um das Modell zu erweitern ("Add new examples"). Das Modell wird dann erneut trainiert ("Retrain/Update") und der Prozess wird iterativ fortgesetzt, bis das Modell suffizient an der rare Klasse annotiert ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert wird, um das Modell zu optimieren und sicherzustellen, dass es robust gegenüber neuen Beispielen ist ("new data"). Das Modell wird dann auf neuen Beispielen evaluiert ("evaluate on new data") und weiter optimiert, um sicherzustellen, dass es robust gegenüber neuen Beispielen ist.

Die Grafik zeigt auch, dass das Modell auf einem Datensatz mit alten Beispielen ("old data") trainiert</sample>
    <sample id="1512">Cold-start Annotations: Transfer Learning

Die Initialmodell-Transferlearning-Strategie beginnt mit einem "START" und verwendet einen "Initial model" (ursprünglichen Modell) als Ausgangspunkt. Das Hauptziel ist die "Rare class annotation – 'needle in a haystack'" ( Annotation der seltener vorkommenden Klassen – "Nadel im Heu"), um die "Difficult to annotate" (schwierig zu annotieren) Rare-Klassen zu identifizieren und zu annotieren.

Die Struktur der Initialmodell-Transferlearning-Strategie zeigt, dass das Modell "Train" (trainieren) wird, um "New data" (neue Daten) zu verarbeiten. Das Modell wird dann "Fine-tune" (fein-tunen) und "Retrain/Update" (erneut trainieren/aktualisieren), um "Old data" (altes Datenmaterial) und "Redo data" (wiederholtes Datensammlung) zu berücksichtigen. 

Die "Acquisition" (Erwerb) Schritte beinhalten "Active Learning" (aktives Lernen), bei dem das Modell "Selects" (ausgewählt) "which are" (welche) "Difficult to annotate" (schwierig zu annotieren)Rare-Klassen und "Humans annotate" (menschlich annotiert). Das Modell wird dann "Add new examples" (neue Beispiele hinzufügen) und "Add new classes" (neue Klassen hinzufügen), um die "Rare class annotation – 'needle in a haystack'" (Annotation der seltener vorkommenden Klassen – "Nadel im Heu") zu verbessern.</sample>
    <sample id="1513">Cold-start Annotations: Transfer Learning

Roberta-base + classifier head
 init. TRAIN
Debate
CE
Debate CE
Transferred after weights after training on combined Debate and GE data

Debatant stelle in der Formulierung: "Vasanthra Venkatarajan, Nikita Sontakke, Virendra Singh, Nikhil Gopinath, Abhishek Singh, Anirban Chatterjee, Rahul Prasad, Nandini Dukkipati. 2021. Proceedings of the 48th Annual South Asia Conference of Indian Linguistics. (SACL). https://doi.org/10.2307/2584966" 

Debatant stelle in der Formulierung: "Rashmi Deshpande, Manjari Deshpande, Alan Ritter. 2020. ICE: In-Context Evaluation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). https://doi.org/10.18653/v1/2020.emnlp-main.457"</sample>
    <sample id="1514">Cold-start Annotations: Transfer Learning

Roberta-base • classifier head init. debate 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.40 0.41 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.50 0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59 0.60 0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69 0.70 0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.80 0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0.90 0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98 0.99 1.00 Debate CE -0.08 Transferred after training on combined Debate and GE data</sample>
    <sample id="1515">Cold-start Annotations: Transfer Learning

Roberta-base • classifier head init. data train 0.10 Debate CE 0.08 Area under the ROC curve (AUC) Transferred after weights after combined Debate and GE data</sample>
    <sample id="1516">Cold-start Annotations: Transfer Learning

RoBERTa-base + classifier head | TRAIN
int. dataset | 0.12
Debates | 0.12
CE | 0.08
Debate-CE | -0.04
Debate+CE | -0.55

Finetuning on each task consecutively

Debates: Dissociation in debate forums. Vázquez-Vendón, Núria Sont, Ramón Paredes, and Raúl Murillo. (2019). Detecting dissonance in social media: The role of topic expertise. In Proceedings of the 20th Conference of the European Chapter of the Association for Computational Linguistics (EACL). https://doi.org/10.18653/v1/w19eacl.107

ICE: Comparison of ICE classes. Nabi, Niki L., Alon, Oren, and Das, Rishabh Prasad. (2019). Document-level sentiment analysis with a multi-task learning approach. In Proceedings of the 22nd Conference on Empirical Methods in Natural Language Processing (EMNLP). https://doi.org/10.18653/emnlp.2019.1400</sample>
    <sample id="1517">Active Learning: Cumulative vs. Iterative Update

Das Bild zeigt einen Vergleich zwischen zwei Ansätzen des Active Learning: "Cumulative" und "Iterative". Beide Ansätze zielen darauf ab, die Effizienz des Lernprozesses zu optimieren, indem sie die Annotierung von Daten nur dann durchführen, wenn sie von Bedeutung sind.

Im "Cumulative" Ansatz werden die neuen Daten zu einem neuen Modell hinzugefügt, das dann trainiert wird. Das alte Modell wird nicht verwendet, um die neuen Daten zu bewerten. Im "Iterative" Ansatz wird das neue Modell iterativ überarbeitet, indem es mit dem alten Modell verglichen wird und die neuen Daten anhand des neuen Modells bewertet werden.

Die Grafik zeigt auch, wie die Annotierung von Daten durch die Verwendung von Active Learning optimiert werden kann. In einem iterativen Ansatz können die neuen Daten nur dann annotiert werden, wenn sie von Bedeutung sind, was die Annotierung effizienter macht. Im "Cumulative" Ansatz wird die Annotierung von neuen Daten standardmäßig durchgeführt, was ineffizient sein kann.

Insgesamt zeigt das Bild, dass das "Cumulative" Ansatz eine einfachere Implementierung bietet, aber das "Iterative" Ansatz eine effizientere Annotierung von neuen Daten ermöglicht.</sample>
    <sample id="1518">Active Learning: Cumulative vs. Iterative Update

Die Grafik zeigt die Vergleich der AUC-Werte (Area Under the Curve) für verschiedene Active Learning-Strategien, unterteilt in "Cumulative" und "Iterative". Die Strategien sind Random, Entropy, CoreSet, CAL und PRC.

* **Random:** Cumulative 0.65, Iterative 0.55
* **Entropy:** Cumulative 0.70, Iterative 0.65
* **CoreSet:** Cumulative 0.68, Iterative 0.63
* **CAL:** Cumulative 0.67, Iterative 0.62
* **PRC:** Cumulative 0.69, Iterative 0.64</sample>
    <sample id="1519">Active Learning: Strategie der Wahrscheinlichkeit von seltener Klasse

Die Grafik zeigt einen Prozess, der die Strategie "Probability-of-Rare-Class" im Kontext von Active Learning beschreibt. Der Prozess beginnt mit einem "Initial model" (ursprünglichen Modell), das dann auf "new data" (neue Daten) trainiert wird. Das Modell macht Vorhersagen und identifiziert "Difficult to annotate" (schwierig zu kategorisieren) und "Easier to annotate" (einfacher zu kategorisieren) Beispiele.

Die Grafik zeigt dann, wie das Modell "Cumulative (CML)" iterativ überarbeitet wird, indem es "fine-tunes" (fein einstellt) und "learns" (lernt). Wenn das Modell "Active Learning Iteration" durchläuft, werden "Humans annotate" (Menschen kategorieren) "new examples" (neue Beispiele).

Wenn das Modell "Active Learning" nicht ausreicht, werden "Add new examples" (neue Beispiele hinzufügen) und das Modell wird erneut "Retrain/Update" (erneut trainiert/aktualisiert) und "Iterative (IT)" fortgesetzt.

Die Grafik zeigt auch, dass das Modell "Rare class annotation – ‘needle in a haystack’" (seltene Klasse annotieren – 'Nadel im Heu') und "Increase chance of rare class?" (Steigerung der Wahrscheinlichkeit für seltene Klassen?) berücksichtigt.

Die Grafik wurde von "Vandana Venkatesh" erstellt.</sample>
    <sample id="1520">Active Learning: Strategie der Wahrscheinlichkeit von seltener Klasse

Die Grafik zeigt einen Prozess, der die Strategie der Wahrscheinlichkeit von seltener Klasse in Active Learning beschreibt. Der Prozess beginnt mit einer Initialmodell-Transfer-Lernphase, in der das Modell auf neue Daten trainiert wird. Danach wird das Modell iterativ überarbeitet (Iterative Training/Updating), um seine Genauigkeit zu verbessern.

In der迭代训练/更新阶段，模型会重新训练和更新。然后，系统会评估哪些新示例属于“稀有类”（Difficult to annotate），并决定是否需要人类标注这些示例。如果需要，人类将标注这些示例，然后将它们添加到数据集中。最后，模型会再次重新训练和更新，以包括新标注的示例。

该过程是一个循环，其中模型不断重新训练和更新，同时根据需要添加新示例。目标是通过专注于标注稀有类别的示例来提高模型的性能。</sample>
    <sample id="1521">Active Learning: Probability-of-Rare-Class Strategy

Die Grafik vergleicht verschiedene Strategien zur Active Learning auf der Grundlage von AUCs (Area Under the Curve). Es werden die folgenden Strategien compared: Baseline: from scratch, Transferred model, AL_Random, AL_Energy, AL_CoreSet, ALCAL, und ALPRC (pure). 

- Baseline: from scratch: 0.50
- Transferred model: 0.67
- AL_Random: 0.65
- AL_Energy: 0.63
- AL_CoreSet: 0.62
- ALCAL: 0.61
- ALPRC (pure): 0.60</sample>
    <sample id="1522">Active Learning: Probability-of-Rare-Class Strategy

Die Grafik vergleicht verschiedene Strategien zur Active Learning auf der Grundlage von AUC-Werten. Die Baseline-Strategie "from scratch" erreicht einen AUC-Wert von 0,50. Die "Transformed model" erreicht einen AUC-Wert von 0,67. Die "AL-Random" Strategie erreicht einen AUC-Wert von 0,69, die "AL-Entropy" Strategie erreicht einen AUC-Wert von 0,71, die "AL-CAL" Strategie erreicht einen AUC-Wert von 0,73 und die "AL-PRC" Strategie erreicht einen AUC-Wert von 0,75. Die "AL-best transfer (best fine-tune)" Strategie erreicht einen AUC-Wert von 0,80.</sample>
    <sample id="1523">Active Learning: Strategien zur Wahrscheinlichkeit der Seltenen Klasse

Die Tabelle zeigt die Eigenschaften verschiedener Active Learning-Strategien, einschließlich Random, Entropy, CoreSet und PRC. 

- **Random**: 3,20 %Rare, 11,96 % Zeit, -0,065 Subjektivität
- **Entropy**: 6,80 %Rare, 12,72 % Zeit, -0,035 Subjektivität
- **CoreSet**: 4,80 %Rare, 11,89 % Zeit, -0,045 Subjektivität
- **PRC**: 7,60 %Rare, 13,55 % Zeit, -0,071 Subjektivität

Die Mindestannotierkosten können nicht zwangsläufig zu besseren Modellen führen. Um schwere Beispiele zu identifizieren, können Annotatorn Schwierigkeiten haben, was als kognitives Diskonsens-Signal interpretiert werden kann. Um die Schwierigkeitsstelle zu erhöhen, ist PRC die beste Wahl.

Quelle: [1]</sample>
    <sample id="1524">Takeaways Rare class annotation - "need in a haystack" PRC is simple &amp; efficient for rare sample acquisition Cold-start AL with active learning Out-of-domain: Iterative In-domain: Cumulative</sample>
    <sample id="1525">Takeaways Rare class annotation - "needle in a haystack" PRC is simple &amp; efficient for rare sample acquisition Cold-start AL with active learning Out-of-domain: Iterative In-domain: Cumulative</sample>
    <sample id="1526">Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge</sample>
    <sample id="1527">Die Autoren sind an der University of Amsterdam, Saarland University und dem NLP Center der UU University of Amsterdam verbunden.</sample>
    <sample id="1528">The speaker's name is not provided in the image.</sample>
    <sample id="1529">5</sample>
    <sample id="1530">Mit der CAAT-SimulST-Architektur wird der Ansatz verglichen.</sample>
  </task>
</testset>