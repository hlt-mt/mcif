<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind Web crawls.</sample>
    <sample id="1">McGill University, Mila and Microsoft Research</sample>
    <sample id="2">Hallo, herzlich willkommen zu unserer Präsentation von DEPLAIN: Ein neues Korpus für die deutsche Textsegmentierung auf der Dokumentebene und auf der Satzebene.</sample>
    <sample id="3">Mein Name ist Regina Stodden und ich werde Sie durch die erste Partie der Präsentation führen. Lassen Sie uns zuerst Textsimplifikation definieren.</sample>
    <sample id="4">Textsimplifikation ist ein Prozess, bei dem ein Text anpassiert wird, um die Lesbarkeit für eine bestimmte Zielgruppe zu verbessern, wie zum Beispiel für Menschen mit Lesechwierigkeiten oder Fremdsprachige.</sample>
    <sample id="5">Um einen Textsimplifizierungsmodell zu trainieren, benötigen wir Paare von Texten, z. B. zwei Dokumente oder Sätze.</sample>
    <sample id="6">Die Gewerkschaft setzt sich für ein, das zum Beispiel höhere Löhne oder mehr Urlaub.</sample>
    <sample id="7">Um einen Satz zu vereinfachen, diverse Techniken sind möglich, wie in einem Beispiel zu sehen ist. So können technische Substitution, Klausel deletion, Klausel deletion, Reordering oder die Einfügung von Begriffe verwendet werden.</sample>
    <sample id="8">Wir haben nun einen neuen Corpus vorgeschlagen, DE-Plain, weil in den letzten Jahren existierende Corpusprobleme aufgetreten sind. Zum Beispiel sind diese Corpus in den letzten Jahren zu klein, um ein Text-klassifizierungsmodell zu trainieren.</sample>
    <sample id="9">Die anderen drei Modelle, die in jüngster Zeit vorgeschlagen wurden, sind alle automatisch aufgereihte, was bedeutet, dass sie über einen großen Datensatz aufgereihte werden können.</sample>
    <sample id="10">Daher schaffen wir unser neues Korpus DePlain, das in zwei Subkorpusen, DePlain API und DePlain Web, unterteilt ist. DePlain API basiert auf News-Texten.</sample>
    <sample id="11">In der Plain API-App wurden 483 Dokumente manuell abgeglichen. Das führt zu etwa 30.000 bis 13.000 parallel-sentenzweisen Paaren.</sample>
    <sample id="12">Für die DeepPlainWeb-Datei enthält diese Korpus diverse Domänen und wir haben alle 750 Dokumente auf der einen Seite manuell und auf der anderen mit automatischen Aligned Methoden abgestimmt.</sample>
    <sample id="13">Insgesamt erhalten wir 34.500 Satzpaare.</sample>
    <sample id="14">Wir analysieren unsere Satzpaare etwas tiefer. Zum Beispiel die Art der Simplifikationen.</sample>
    <sample id="15">Wie man hier sehen kann, sind die Bibeltexte stark simplifizierter als z.B. die News-Texte oder die Lernertexte für Fremdsprachen.</sample>
    <sample id="16">Auf allen Ebenen, einschließlich lexikalischer Simplifikation, struktureller Simplifikation und allgemeiner Simplifikation.</sample>
    <sample id="17">Zwar können Sie sehen, dass unser Deplain Corpus eine hohe Vielfalt an verschiedenen Simplifizierungstransformationen aufweist. So zum Beispiel im Deplain API Corpus haben wir viel mehr Umbearrungen und Worterweiterungen als im Deplain Web Corpus.</sample>
    <sample id="18">Auf der anderen Seite haben wir im Web Corpus viel mehr Reduktionsoperationen.</sample>
    <sample id="19">So, lassen Sie uns nun sehen, was wir damit erreichen können. Hallo, ich bin Omar und jetzt werde ich über die Anwendungsfälle für unser Datensatz DPlane sprechen. Also, für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten.</sample>
    <sample id="20">In den letzten Jahren gab es einen Großteil von Aligned-Methoden, aber in Bezug auf maschinelles Übersetzen.</sample>
    <sample id="21">Wir haben zwei parallel geschriebene Dokumente in verschiedenen Sprachen und möchten Sätte im deutschen Dokument extrahieren.</sample>
    <sample id="22">Aber in unserem Einsatzfall versuchen wir, Auswertungen zwischen Sätzen von zwei parallelsten Dokumenten zu ziehen, die dieselbe Sprache und denselben Inhalt haben, aber auf einem unterschiedlichen Komplexitätsebene liegen.</sample>
    <sample id="23">Jetzt, da wir unser Datensatz DeepPlain haben, der manuell abgepaachte Sätze enthält, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten.</sample>
    <sample id="24">Und wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen und die Codes, um unsere Experimente zu laufen, im Papier veröffentlicht.</sample>
    <sample id="25">Am Ende haben wir festgestellt, dass die beste Methode zur automatischen Ausrichtung für Texte, insbesondere für deutsche Texte, die Simplifizierung ist, die Methode von MassAlign.</sample>
    <sample id="26">Und Sie können auch den Code finden, um auf Ihren eigenen Dokumenten diese Methode zu verwenden, in der Papier.</sample>
    <sample id="27">Der zweite Fall, den wir in unserem Papier gezeigt haben, ist der Fall automatischer Textsimplifizierung.</sample>
    <sample id="28">Durch die Optimierung von Sprachmodellen können komplexes Eingabe-Text-Dokument zu einem vereinfachten Text.</sample>
    <sample id="29">Wir haben zwei verschiedene Modelle trainiert. Wir haben das Modell von Long Impart zu einem Dokumentebene-Simplifizierungen trainiert.</sample>
    <sample id="30">Wir haben auch die normalen Baseline-Modelle, den normalen BART-Model, optimiert, um Satelleveland simplifizierungen zu produzieren.</sample>
    <sample id="31">Sie können auch alle Checkpoints finden und einen Blick auf die noch mehr Details an den Punkten und die Evaluationsmetrischen von unserem Experiment in der Publikation werfen.</sample>
    <sample id="32">Wir haben festgestellt, dass diese, diese Basiskonfigurationen, die Produktionsfähigkeit oder die Punkte besser als die Baseline-Punkte liefern.</sample>
    <sample id="33">Und wir haben diese Ergebnisse als Benchmark, eine Basiskonfiguration, für das Problem der automatischen Textsimplifizierung in Zukunft vorgeschlagen.</sample>
    <sample id="34">Danke sehr für Ihre Aufmerksamkeit und wir hoffen, Sie alle während des Konzerns zu sehen. Vielen Dank.</sample>
    <sample id="35">Kayo Yin</sample>
    <sample id="36">T5 XL</sample>
    <sample id="37">Ja, sie funktioniieren immer noch.</sample>
    <sample id="38">Die vorgeschlagene Methode versucht, die Subjektivität menschlicher Bewertungen zu reduzieren, indem sie explizit annotiert, ob jede Modellresponse bestimmte Verhaltensweisen ausdrückt, wie zum Beispiel das Ausgeben von irrelevanter Information oder das Kontrastieren mit sich selbst.</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Anzahl der validierbaren Datensamples ab.</sample>
    <sample id="40">Das Resultat kann verbessert werden, indem die Annotatoren gebeten werden, sich über die Entitäten zu informieren.</sample>
    <sample id="41">Fünf</sample>
    <sample id="42">Mein Name ist Adam Przepiórkowski und das Thema dieser Talk ist die Abhängigkeitsstruktur der Koordination.</sample>
    <sample id="43">Wie Sie wissen, gibt es verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Ansätzen verwendet werden. Zum Beispiel in den universellen Abhängigkeiten wird die Struktur der Koordination Lisa, Bart und Maggie so dargestellt:</sample>
    <sample id="44">ist so, dass der erste Conjunkt der Kopf des gesamten Koordiantens tritt, also in diesem Fall Lisa.</sample>
    <sample id="45">Ähnliche Ansätze werden in Igor Mityuk's Meaning Text Theorie angenommen, bei denen das gesamte Koordinatensystem vom ersten Konjunkt geleitet wird. Also, diese zwei Ansätze sind assymetrisch. Sie singulieren ein von den Konjunkten abhängiges Element.</sample>
    <sample id="46">Auch esymetrische Ansätze zur Codierung von Koordinationsstrukturen existieren, wie die Prager Ansatz, die Konjunktionskopfthead-Annäherung und die punktbasierenden Abhängigkeitsbäume. Hierbei werden Koordinationsstrukturen von Konjunktionen überwiesen.</sample>
    <sample id="47">Also erhalten wir Abhängigkeiten von Ende zu allen Konjunktiven.</sample>
    <sample id="48">Schließlich gibt es auch einen multi-head-ansatz, der beispielsweise in De Catts' Word Grammar verwendet wird.</sample>
    <sample id="49">Hier geht es um die Abhängigkeitsstruktur der Koordination. Wir können allgemein sagen, dass alle Verbindungen als Hauptpunkte der koordianten Strukturen fungieren und dadurch Abhängigkeiten von dem Auslöser "liebt" zu allen Verbindungen separat herstellen.</sample>
    <sample id="50">Das Hauptziel dieser Arbeit ist, einen neuen Argumentationsansatz für symmetrische Strukturen der Koordination wie diese zu präsentieren und gegen asymmetrische Strukturen der Koordination wie jene zu argumentieren.</sample>
    <sample id="51">Das Argument basiert auf dem Prinzip der minimierung von Abhängigkeitslängen, das anhand dieser Beispiele erläutert wird.</sample>
    <sample id="52">In English, as you might know, direct objects tend to be close to the verb while adjuncts may be farther away. So March read it yesterday is fine because the direct object "it" is close to the verb.</sample>
    <sample id="53">Während March gestern "es" las, ist es viel schlimmer, denn hier zwischen dem Verb und dem direkten Objekt steht ein Adverbial "gestern".</sample>
    <sample id="54">Allerdings kann dieser Effekt durch die Verlagerung des direkten Objekts nach dem Subjekt, wenn es sehr lang und schwierig zu verarbeiten ist, verstärkt werden.</sample>
    <sample id="55">Dies wird hier illustriert. Also, sowohl diese Sätze sind korrekt: March hat diese absolut faszinierende Broschüren über die BCA gestern gelesen. Es ist in Ordnung. Stattdessen haben wir eine lange NP.</sample>
    <sample id="56">Aber es ist auch in Ordnung zu sagen: 'Märchen, das ich gestern absolviert habe, ist ein faszinierendes Buch über Bienen.'</sample>
    <sample id="57">Die Idee hier ist, dass dies möglich ist, weil obwohl diese Satz gegen die grammatische Regeln verstößt, dass direkte Objekte neben dem Verb stehen sollten,</sample>
    <sample id="58">Es erfüllt das Prinzip der Minimierung von Abhängigkeitslängen, das besagt, dass kürzere Abhängigkeiten bevorzogen werden.</sample>
    <sample id="59">Also zeigen diese zwei Bäume nur die Länge der kritischen Abhängigkeiten an, also diejenigen, die nicht konstant zwischen diesen zwei Strukturen sind.</sample>
    <sample id="60">Also haben wir eine Abhängigkeit von "read" zu dem Adjunkt mit einer Länge von 7, die in Wörtern gemessen wird, und von "read" zu "book" mit einer Längs von 4. Insgesamt beträgt es 11.</sample>
    <sample id="61">Wenn Sie zwei Constituents verschieben oder tauschen, wird die Summe dieser zwei Abhängigkeiten sechs. Stattdessen von elf zu sechs kürzer. Das ist der Grund, warum das klingt ziemlich in Ordnung. Es verletzt ein Prinzip, aber es erfüllt ein anderes.</sample>
    <sample id="62">Okay, also was machen wir: wir haben sehr viele Statistiken aus dem verbesserten Version von Pank, dem Pankbank, extrahiert und siehe die Papier, warum wir Universitäts-Abhängigkeiten nicht verwenden.</sample>
    <sample id="63">Diese Statistiken bestätigen die Beobachtung, die oft wiederholt wurde, dass linker Konjunktiv tendenziell kürzer ist. So werden Salt and Pepper und Not Peppa's Salz in Silben gemessen.</sample>
    <sample id="64">Auch die Beobachtung, die in der Redewendesetzung erwähnt wurde, dass diese Tendenz mit der Längstlängenunterschieden wächst.</sample>
    <sample id="65">So, wenn die Differenz zwischen den Längen der zwei Konjunkte zunimmt, bevorzugt die kürzere Konjunkte, dass sie als erstes kommt. Ja, also die Proportion ist größer, wenn die linken kürzeren Konjunkte betont werden.</sample>
    <sample id="66">Was novel in diesem Papier ist, ist, dass wir festgestellt haben, dass diese Tendenz nur dann auftritt, wenn der Gouverneur links fehlt.</sample>
    <sample id="67">So, die Regierung ist auf der linken Seite in diesem Beispiel. Ich sah Bart und Lisa. Also ist die Regierung auf der linken Seite.</sample>
    <sample id="68">Es ist prägnant in dem zweiten Beispiel, Homer kam und schlich sich hier. Wir haben Koordination von zwei Verben und es gibt keine externen externen Governor. Also in solchen Fällen偏好左连词更短, je größer die Distanz zwischen den zwei连接词。</sample>
    <sample id="69">Allerdings, wenn die Regierung rechts ist, wie hier, als Leitstelle der Koordination und Ned, dieser Effekt verschwindet.</sample>
    <sample id="70">Wir haben gezeigt, dass die Längstmessung in Zeichen (erste Spalte), Silben (Mitte) und Wörtern (rechts) ist. Ich werde mich auf die rechte Spalte konzentrieren.</sample>
    <sample id="71">Was wir hier sehen, ist, dass wenn die Regierung auf der linken Seite steht,</sample>
    <sample id="72">Die Neigung, dass der linken Konjunktion kürzer ist, wächst stetig mit dem absoluten Differenz in Worten. Das gleiche wird beobachtet, wenn es keinen Governor gibt, wie in Koordination von Sätzen, aber wenn der Governor rechts steht, verschwindet diese Neigung.</sample>
    <sample id="73">Wir zeigen im Papier, wie dies argumente gegen asymmetrische Strukturen der Koordination als diese zwei und für die symmetrischen Strukturen als diese drei.</sample>
    <sample id="74">Siehe die Papier für die volle Argumentation und argumentation sorry und sprechen Sie mit uns über der Poster-Session. Danke.</sample>
    <sample id="75">Drei.</sample>
    <sample id="76">Bible texts</sample>
    <sample id="77">Salt and pepper.</sample>
    <sample id="78">Ja, die Modelle und die Trainingsskripte sind unter der MIT-Lizenz frei zur Verfügung gestellt.</sample>
    <sample id="79">DEplain-apa enthält News-Artikel.</sample>
    <sample id="80">Eine bessere Modellarchitektur, ein größeres Modell und mehr Fine-Tuning-Beispiele sind die Faktoren, die zu einer guten Generalisierung führen.</sample>
    <sample id="81">Die Tendenz wurde durch Messung der Längen in Zeichen, Silben und Wörtern gemessen.</sample>
    <sample id="82">Die Experimente wurden so gestaltet, dass die Längen in Zeichen, Silben und Wörtern gemessen wurden.</sample>
    <sample id="83">Ein Basisklassifikator, der mit unausgewogenen Daten trainiert wird, kann nicht viel besser als Zufall performen.</sample>
    <sample id="84">Vier</sample>
    <sample id="85">Bob und Alice</sample>
    <sample id="86">Kontextsensitive MÜ-Modelle sind besser auf Diskursphänomena wie Formalität und lexikalische Kohärenz ab.</sample>
    <sample id="87">Johns Hopkins University, Purdue University, and MIT</sample>
    <sample id="122">Das Framework quantifiziert die Positionalität durch die Messung der Korrelation zwischen den demographischen Daten und den Modellvorhersagen oder Labeln.</sample>
    <sample id="155">Das Studie fand, dass die menschlichen Teilnehmenden durch die Verwendung der gleichen Persona-Prompts Rassistische Stereotypien surfen konnten.</sample>
    <sample id="156">Die Studie nutzte die University Dependencies und die enhanced version of the Penn Treebank.</sample>
    <sample id="157">Zwei</sample>
    <sample id="158">Debatte und ICE.</sample>
    <sample id="159">Zwei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="160">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten dadurch, dass es nicht nur die Übereinstimmung von Annotatoren (inter-annotator agreement) oder die Verteilungen von Annotatoren (annotator distributions) berücksichtigt, sondern auch die Vorhersagen von Modellen und die Labels vergleicht.</sample>
    <sample id="162">GPT-4</sample>
    <sample id="163">Google Translate und Deep Belief.</sample>
    <sample id="164">Hallo, ich bin Shangbin, ein PhD-Student an der University of Washington. Heute präsentiere ich unser Werk von der Vorausbildung von Daten zu Sprachmodellen bis hin zuunteren Aufgaben, das Verfolgen der Spuren von politischen Biases, die zu unfairten NLP-Modellen führen.</sample>
    <sample id="165">Sprachmodelle werden auf großen Webkraw-Data auf Basis von Suchmaschinen trainiert.</sample>
    <sample id="166">Politik-News-Medien werden gut abgedeckt in den vortrainingen. Laut einer Studie des C4 Corpus können wir sehen, dass New York Times, Los Angeles Times, The Guardian, Huffington Post usw. gut abgedeckt in Sprachmodelltraining-Daten sind.</sample>
    <sample id="167">Dies hat zu einem "mischten Segen" für Sprachmodell-Anwendungen geführt.</sample>
    <sample id="168">Auf der einen Seite konnten sie aus diversen Perspektiven lernen, was die Demokratie und die Pluralität von Ideen feiert. Auf der anderen Seite sind diese verschiedenen politischen Meinungen inherentlich sozial verzerrend und können zu potentiellen Gerechtigkeitsproblemen in unteren Aufgabenapplikationen führen.</sample>
    <sample id="169">Um dies zu erreichen, schlagen wir vor, die politische Verurteilungspipeline von der Vervorgerechnung von Datensätzen über Sprachmodelle bis hin zu unternehmensspezifischen Aufgaben zu untersuchen, insbesondere indem wir die folgenden Fragen stellen:</sample>
    <sample id="170">Erstens, wie bewerten wir die politische Neutrilität von Sprachmodellen und welche Rolle das Voreinzelndaten bei solchen politischen Biases spielen kann?</sample>
    <sample id="171">Zweitens, wie performieren Sprachmodelle mit verschiedenen politischen Leitlinien auf Downstream-Aufgaben und ob das zu Unfairness-Issues in NLP-Anwendungen führt.</sample>
    <sample id="172">Zunächst schaffen wir es, Sprachmodelle mit verschiedenen Prompts zu provozieren, indem wir politische Befragungen verwenden, wie die "Political Compass Test". Das gewährleistet eine automatische Evaluation, die fundiert ist in der politischen Wissenschaftsliteratur.</sample>
    <sample id="173">Einige vorläufige Ergebnisse zeigen, dass Sprachmodelle variierende politische Neigungen haben. Sie bedecken alle vier Quadranten des politischen Kompasses.</sample>
    <sample id="174">Wir können auch sehen, dass GPT-4 der liberalste Sprachmodell von allen ist. Und GPT-Serie sind allgemein sozial-liberaler als BERT-Serie und seine Varianten.</sample>
    <sample id="175">Zweitens zielen wir an, zu ermitteln, in welchem Ausmaß die politischen Biases von Sprachmodellen tatsächlich aus dem Trainingsdaten extrapoliert werden.</sample>
    <sample id="176">Wir könnten einen kontrollierten Versuch durchführen, Sprachmodell-Schritte auf sechs verschiedenen Parteien zu prüfen, die in News und Social Media unterteilt sind, und dann weitere auf ihre politische Neigung zu unterteilen.</sample>
    <sample id="177">Durch weitere vorherige Schulung von Sprachmodellen auf solchen Partizipierer-Quellen können wir sehen, dass die ideologischen Koordinaten des Sprachmodells auch entsprechend verschieben werden.</sample>
    <sample id="178">Beispielsweise, wenn Roberta weiter trainiert wird auf einem linken Leitungs-Reddit-Korpus, können wir einen substantiellen linken Schub in Bezug auf seine ...</sample>
    <sample id="179">In Bezug auf seine politischen Biases.</sample>
    <sample id="180">Wir haben auch versucht, zu untersuchen, ob Sprachmodelle die Polarisationsstelle aufnehmen können, die in unserer modernen Gesellschaft vorherrscht.</sample>
    <sample id="181">Wir haben die vorherige Ausbildungskorpus in zwei Teile unterteilt: vor dem 45. Präsidenten der Vereinigten Staaten und nach dem 45. Präsidenten der Vereinigten Staaten. Anschließend wurden Sprachmodelle separat auf die zwei verschiedene temporären Ausbildungen vorbereitet.</sample>
    <sample id="182">Wir können sehen, dass Sprachmodelle allgemein eine politische Neigung hatten, die von der Mitte weg war nach 2017. Das zeigt, dass Sprachmodelle auch die Polarisation in unserer Gesellschaft aufnehmen können.</sample>
    <sample id="183">So, zuletzt bewerten wir Sprachmodelle mit verschiedenen politischen Neigungen bei der Erkennung von Hasssprache und Fake-News-Erkennung, zwei NLP-Anwendungen, die oft involvieren und sehr wichtige Auswirkungen haben könnten.</sample>
    <sample id="184">Wir sehen, dass wir, wenn wir die Leistungen in verschiedenen Kategorien untersuchen, das ist zu sagen, wenn wir die Leistungen in verschiedenen Gruppen unterteilen, wir sehen, dass bei den linken Medien eine bessere Leistung im Vergleich zu den rechten Medien vorherrscht.</sample>
    <sample id="185">Wir können beispielsweise für Hate-Speech-Detection linksleaninge Sprachmodelle besser abschätzen.</sample>
    <sample id="186">Eine Tabelle zeigt die Leistungen an der Erkennung von Hasssprache, die unterschiedliche soziale Gruppen zielt. Es werden verschiedene Quellen und Identitäten betrachtet, um zu sehen, wie gut die Systeme arbeiten.</sample>
    <sample id="187">Allerdings sind wir schlechter darin, Hate-Speech zu detektieren, die sich auf mehr mächtige Gruppen in unserer Gesellschaft bezieht.</sample>
    <sample id="188">Und im Gegensatz dazu sind rechtsliniente Sprachmodelle besser darin, Hate-Speech, das eine Bedrohung für weiße und Männer darstellt, zu erkennen. Allerdings sind sie schlechter darin, Hate-Speech, das eine Bedrohung für Afroamerikaner, LGBT+, und andere minderheitliche Gruppen darstellt, zu erkennen.</sample>
    <sample id="189">Ähnliche Trends finden auch bei der Fals#abendnachrichten-Detektion statt, bei der wir sehen, dass linkslinienende Sprachmodelle besser darin sind, Missinformationen von ihren politischen Gegenstellern zu detektieren und umgekehrt.</sample>
    <sample id="190">Wir zeigen daher viele qualitative Beispiele, um zu sehen, dass Sprachmodelle mit unterschiedlichen politischen Neigungen</sample>
    <sample id="191">Geben Sie unterschiedliche Vorhersagen für Beispiele von Hasssprache und Falschinformation basierend auf ihren sozialen Kategorien. Es gibt eine große Anzahl von weiteren Beispielen im Anhang, um das zu verdeutlichen.</sample>
    <sample id="192">Dies zeigt, dass es ein Fairnessproblem gibt, das sehr beeindruckend ist, wenn es um die politischen Biases von Sprachmodellen geht.</sample>
    <sample id="193">Beispielsweise, wenn ein rechtsradikaler Sprachmodell auf eine populäre soziale Medien-Plattform deployt und unbiasste Sprache oder Fehlinformationen trainieren soll,</sample>
    <sample id="194">Das würde bedeuten, dass Menschen mit entgegengesetzten politischen Ansichten marginalisiert werden könnten und Hasssprache gegen minderheitensensible Gruppen unkontrolliert weiterwirken kann.</sample>
    <sample id="195">Das hat uns zu einer Anerkennung und Bewältigung der Fairnessprobleme, die durch politische Biases in Sprachmodellen entstehen, aufschnappen lassen.</sample>
    <sample id="196">Ein kleiner Diskussion. Wir möchten auch betonen, dass wir die einzigartige Dilemma in Bezug auf Sprachmodell politische Biases hervorgerufen haben. Es ist wie zwischen Scylla und Charybdis.</sample>
    <sample id="197">Wenn wir politische Meinungen in Sprachmodelltrainingdaten nicht sauber machen, verbreiten sich die Biases von den vorherigen Datensätzen über Sprachmodelle zu unterstimmten Aufgaben und schaffen letztendlich Fairnessprobleme.</sample>
    <sample id="198">Wenn wir versuchen, die Daten zu "säubern", riskieren wir Sensibilität oder Exklusion und es ist äußerst schwierig zu bestimmen, was als neutrales und should-retain linguistisches Datendaten angesehen werden sollte. Es ist etwas wie der elektrische Schalterproblem.</sample>
    <sample id="199">Okay, okay. Ich denke, das ist alles, was ich heute machen habe. Danke für eure Zeit.</sample>
    <sample id="200">Es sind insgesamt sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="201">MPP evaluations were performed with different contexts up to 900 tokens.</sample>
    <sample id="202">Sie haben Datensätze von Wikipedia, Twitter, Facebook und Amazon aufgenommen.</sample>
    <sample id="203">Positionalität ist die Perspektive, die Menschen als Folge von Demographen, Identität und Lebenserfahrungen halten.</sample>
    <sample id="204">Dawei Zhu</sample>
    <sample id="205">Ja, EDAtt passt zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="206">Vier.</sample>
    <sample id="207">Nein, das Modell kann nicht reliabel integrieren.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind Background Pretrain, Background Both und Background Infer.</sample>
    <sample id="209">Google Research</sample>
    <sample id="210">Die abschließende Forschungsfrage lautet: "Sollten wir die sauberen Ausamples nur für die Validierung verwenden, oder gibt es bessere Wege, sie zu nutzen?"</sample>
    <sample id="211">Die Sensitivitätsmetrik misst die Fähigkeit des Modells, für dieselbe Aufgabe stets die gleichen Ausgaben zu produzieren, unabhängig von kleinen Variationen in der Formulierung der Anweisung.</sample>
    <sample id="212">Jingwei Yi</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet, dass das Modell besser auf unbekannte Aufgaben reagiert.</sample>
    <sample id="214">Die Modelle erhalten während des Pre-Trainings standardisierte Kontexte.</sample>
    <sample id="215">Typischerweise benötigen wir nur 20 saubere Validierungsbeispiele pro Klasse, um eine gute Leistung an der WSL zu erzielen.</sample>
    <sample id="216">Stanford University</sample>
    <sample id="217">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, um die Auswirkungen zu verstehen und zu reduzieren.</sample>
    <sample id="218">The presenter is named Manjata.</sample>
    <sample id="219">Die Pipeline beginnt mit der Vorbereitung von Datensammlungen, die politische Meinungen enthalten, und endet mit dem Ausführen von Sprachmodellen inunterststem Task.</sample>
    <sample id="220">Ja, der Vereinfachungsprozess unterscheidet sich zwischen DEplain-apa und Web.</sample>
    <sample id="221">Ja, Coscript ist öffentlich verfügbar.</sample>
    <sample id="222">Das Wasserzeichen wird in den Text als das Gewichtsumsatz der Zielschaltgruppe und des ursprünglichen Eintrags hinzugefügt.</sample>
    <sample id="223">Die Autoren gehören an der Penn State University und Amazon.</sample>
    <sample id="224">Ja, durch Training mit einer Mischung von Sprachen können Encoder-Decoder-Modelle wie mt5 verbessert werden.</sample>
    <sample id="225">Eine Beispelgoal ist "Wie man einen Schokoladenkuchen macht".</sample>
    <sample id="226">Sie visualisieren die Bedeutung von Sätzen auf der Basis von PCA.</sample>
    <sample id="227">Die Arbeit nutzt bestehende PLMs, um ein neues PLM aufzubauen.</sample>
    <sample id="228">GPT-4 ist am wenigsten auf Afrikanooslanden ausgerichtet.</sample>
    <sample id="229">Der Beispielsatz auf der rechten Seite zeigt, wie das Modell das Wissen nutzt, das durch den Aufmerksamkeitsmechanismus gelernt wurde.</sample>
    <sample id="230">Die Anzahl der Aufgaben hat einen positiven Einfluss auf die Leistung des Modells.</sample>
    <sample id="231">Die drei Baselines sind LSTM seq2seq, T5 und Zheng and Lapata.</sample>
    <sample id="232">Die beiden Co-Autoren sind die Betreuern des ersten Autors.</sample>
    <sample id="233">Chowdery et al.</sample>
    <sample id="234">Hallo, Leute. Ich bin Jenny, ein erstjahrer-PhD-Student an Carnegie Mellon University, und heute werde ich präsentieren, was ich für die Arbeit "NL Positionality"CHARACTERIZING DESIGN BIAS OF DATASETS AND MODELS" getan habe.</sample>
    <sample id="235">Diese Arbeit wurde in Zusammenarbeit mit ein paar Leuten an der University of Washington und dem Allen Institute for AI getan, zuallermeist Sebastien Santi, Ronan Le Bras, Katharina Reinecke und Martin Sap.</sample>
    <sample id="236">So, lass uns damit beginnen, uns vorzustellen, dass du arbeitest an einem Zeitungstext und versuchst, unter einem Newsartikel toxischen Inhalt zu entfernen.</sample>
    <sample id="237">Sie können sich auf eine beliebte API wie die Perspektive-API für Giftgiftung verlassen, und das funkt prima, wenn Sie Karl Jones sind, wo die Perspektive-API in der Lage ist, korrekt Giftinstanzen zu erkennen.</sample>
    <sample id="238">Aber das gilt nicht wirklich für Aditya Sharma, bei dem der Perspective API nicht so empfindlich gegenüber offensive Begriffen ist, die in indischen Kontexten häufiger vorkommen.</sample>
    <sample id="239">Dies ist ein Beispiel für einen Designfehler, bei dem wir systematische Leistungsunterschiede von Technologie zwischen Bevölkerungen sehen.</sample>
    <sample id="240">Design Bias, wie wir vorher gesehen haben, können auf die Positionalität der NLPR-Forscher und Modellentwickler zurückzuführen sein. Positionalität ist einfach die Perspektive, die Menschen als Folge von Demographen, Identität und Lebenserfahrungen halten.</sample>
    <sample id="241">Dies ist ein Begriff, der in kritischen Studien, insbesondere in feministischen und queerbzw. akademischen Bereichen, weit verbreitet verwendet wird.</sample>
    <sample id="242">Als Forscher kann die Positionalität die Forschungsprozess und dessen Ausgänge und Resultate beeinflussen, da sie die Entscheidungen, die Forscher treffen, verändern kann.</sample>
    <sample id="243">Und also eine Frage, die Leute perhaps fragen könnten, ist ob Datensätze und Modelle Positionalität haben.</sample>
    <sample id="244">Und wir versuchen nicht zu sagen, dass Modelle und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren Urteile und Meinungen von realen Menschen und können dadurch bestimmte Positionalitäten über andere repräsentieren.</sample>
    <sample id="245">Das Prior Work hat einige anecdetale Beweise für die Existenz von Positionierbarkeit vorgestellt, wie kulturelle Lücken in Modellen und Datensätzen, sowie theoretische Definitionen von Modell-Positionierbarkeit.</sample>
    <sample id="246">Allerdings betrachten diese Arbeiten nicht die Vergleich der Endbenutzer mit den Datensätzen und Modellen selbst.</sample>
    <sample id="247">Die Untersuchung von Modell- und Datensatzpositionalität wird immer wichtiger, da NLP-Tests immer subjektiver und sozial orientierter werden.</sample>
    <sample id="248">Es ist schwierig zu charakterisieren, wie diese Positionalitäten abweichen, weil nicht alle Entscheidungen dokumentiert werden und viele Modelle hinter API's versteckt sind.</sample>
    <sample id="249">Um die Positionierbarkeit von Datensätzen und Modellen zu untersuchen, vergleichen wir tatsächlich die Annotationen mit realen Benutzern mit bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">Wir tun das durch ein Framework namens NL Positionalität.</sample>
    <sample id="251">Unser Framework arbeitet in zwei Hauptstadien.</sample>
    <sample id="252">Der erste Schritt besteht darin, Datensätze mit diversen Annotatoren zu re-annotieren.</sample>
    <sample id="253">Wir wollen das über die Demographen der ursprünglichen Datensätze und die Annotatoren machen, weil normalerweise nur wenige Annotatoren jede Instanz annotieren und because Demographen sind in der Regel nicht erfasst und geteilt.</sample>
    <sample id="254">Wir wollen also die Daten erneut annotieren, um mehr Annotatoren pro Beispiel zu erhalten und damit eine reiche Datensammlung an demographischen Daten zu erhalten.</sample>
    <sample id="255">Wir nehmen dann dieAnnotations von demografischem Typ und vergleichen sie mit den Modellen und Datensätzen, indem wir Pearson's R-Korrelationsscore verwenden.</sample>
    <sample id="256">Daher unterscheidet sich unser Framework von literaturwissenschaftlichen Arbeiten zu Annotator-Diskriminierung, indem es Endbenutzer mit Modellvorhersagen und Datensatzlabels vergleicht, anstatt nur auf die Interannotator-Übereinstimmung oder die Modellierung von Annotatordistributionen zu schauen.</sample>
    <sample id="257">Unsere Frameworke sind hauptsächlich durch Lab in the Wild, eine Online-Plattform für Crowdsourcing, die von unserem ehemaligen HCHSI-Kollega erstellt wurde.</sample>
    <sample id="258">Lab in the Wild ist eine Online-Experimentationsplattform, bei der wir diverse volontäre recrutieren können, im Vergleich zu Plattformen wie MTurk, die überwiegend von den USA oder Indien stammen. Darüber hinaus ist Lab in the Wild in der Lage, hochwertigen Datensatz zu erhalten.</sample>
    <sample id="259">Wir halten zwei Aufgaben im Lab im Wild ab, einer davon ist die soziale Akzeptabilität. Und die Art und Weise, wie dies funktioniert, ist, dass teilnehmende Leser eine Situation aus dem Sozialchemie-Datenbank und dann schätzen, wie sozialschön eine Situation ist.</sample>
    <sample id="260">Nach dem Abschluss der Aufgabe können die Teilnehmer, um sich weiter zu engagieren, ihre Antworten mit denen von Menschen und einem AI vergleichen.</sample>
    <sample id="261">Wir haben dann dieseAnnotations mit Sozialchemie, Delphi und GPT-4 verglichen.</sample>
    <sample id="262">Wir haben dann eine sehr ähnliche Aufgabe für die Detektion von Toxizität und Hasssprache wiederholt, bei der sie einen Fall aus Dynahate liest und schreiben, ob sie den Fall als Fall von Hasssprache betrachten.</sample>
    <sample id="263">Wir verglichen dann diese Annotationen mit Dynahate, Perspective API, Rewire API, HateRoBERTa und GPT-4. Unsere Studie umfasste über 16.000 Annotationen von über 1.000 Annotatoren aus 87 Ländern.</sample>
    <sample id="264">So, nun sind wir in der Lage zu antworten, mit wem NLP-Datasets und Modelle am meisten übereinstimmen. Wir finden, dass es Positionalität im NLP gibt.</sample>
    <sample id="265">Zum Beispiel finden wir, dass Datensätze und Modelle am besten auf englischsprachige Länder ausgerichtet sind. So finden wir zum Beispiel bei der GPT-4 Sozialakzeptabilitätsanalyse, dass sie am besten auf Confusion und englischsprachige Länder ausgerichtet ist. Wir finden auch, dass Dina Hate am besten auf englischsprachige Länder ausgerichtet ist.</sample>
    <sample id="266">Wir finden auch eine weitere Ausrichtung mit Menschen, die eine Hochschulbildung haben. So für GPT-4 in der Aufnahmefähigkeit Aufgabeneinstelle finden wir, dass es am besten auf Menschen ausgerichtet ist, die eine Hochschulbildung oder einen Abschluss von einem Universitätsstudium haben.</sample>
    <sample id="267">Und wir finden das gleiche für Dynahate, wo es am besten auf Menschen mit einem College-Ausbildung abgestimmt ist.</sample>
    <sample id="268">Allerdings werden Modelle und Datensätze, die auf bestimmte Gruppen abgestimmt sind, zwangsläufig bestimmte Gruppen übersehen.</sample>
    <sample id="269">Ein Beispiel für dies ist, dass Datensätze und Modelle weniger an nicht-binäre Menschen orientiert sind als an Männer und Frauen. Wir finden dies im GPT-4 Sozialakzeptabilitätsschwelle als auch im Diagnose-Hate-Tasks Analyse.</sample>
    <sample id="270">Also, given that there is positionality in NLP, what can we do about it?</sample>
    <sample id="271">Wir haben einige Empfehlungen für dies. Der eine ist, einen Rekord von allen relevanten Designentscheidungen während des Forschungsprozesses zu machen und der andere ist, NLP-Forschung mit dem Blick auf Perspektivismus zu machen.</sample>
    <sample id="272">Unsere dritte Empfehlung besteht darin, spezialisierter Datensätze und Modellen für bestimmte Gemeinden zu bauen. Ein gutes Beispiel hierfür ist die Masakane-Initiative. Ich denke, wir wollen betonen, dass inclusive NLP nicht einfach daran liegt, dass alle Technologien für jeden arbeiten.</sample>
    <sample id="273">Und so, das schliesst unsere Präsentation ab. Aber falls Sie gerne mehr lernen möchten, freuen Sie sich, auf unser Dashboard für die neuesten Analyseergebnisse und unser Papier zu schauen. Vielen Dank!</sample>
    <sample id="274">Die Referentin spricht von zwei Problemen.</sample>
    <sample id="275">Die Reduktion sozialer und politischer Verzerrungen in Datensätzen beim Training von NLP-Modellen ist schwierig, da es schwierig ist zu bestimmen, was als neutrales und zu behaltendes Material gilt. Es besteht das Risiko von Sensibilisierung oder Exklusion, wenn versucht wird, die Datensätze zu sauber machen.</sample>
    <sample id="276">Hallo, ich bin Siu Yuen aus Fudan University. Ich bin hier, um unsere Arbeit zu Introduzieren: "Distilling Script Knowledge from Large Language Models for Constrained Language Planning".</sample>
    <sample id="277">In unserem Alltag planen wir unsere Handlungen oft, indem wir Schritte in der Form von Garantien schreiben.</sample>
    <sample id="278">Der vorherige Beitrag hat experimentiert mit Sprachmodellen, um abstrakte Aufgaben von stereotypen Aktivitäten wie "einen Kuchen machen" zu planen und gezeigt, dass große Sprachmodelle effizient Aufgaben in Schritte zerlegen können.</sample>
    <sample id="279">Allerdings hat die vorherige Arbeit hauptsächlich auf die Planung abstrakter Ziele von stereotypen Aktivitäten gearbeitet. Die Planung für Ziele mit spezifischen Zielen und spezifischen Beschränkungen, wie zum Beispiel das Erstellen eines Schokoladenkuchens, wird immer noch untersucht.</sample>
    <sample id="280">In diesem Papier definieren wir das Problem der eingeschränkten Sprachplanung.</sample>
    <sample id="281">Eine abstrakte Zielfunktion kann von verschiedenen realen, spezifischen Zielen mit mehreren Facetten beeinflusst werden. Ein guter Planer sollte Skripts erstellen, die vernünftig und den Bedingungen entsprechend sind.</sample>
    <sample id="282">In diesem Papier bewerten und verbessern wir die Fähigkeit von Sprachmodellen, unter bestimmten Bedingungen zu planen.</sample>
    <sample id="283">Es gibt keine Datensatz von spezifischen Zielen, um unsere Standard zu spotten.</sample>
    <sample id="284">Um zu erhalten, was wir zuerst benötigen, wie in der Tabelle gezeigt, erweitern wir die abstrakte Aufgabe mit mehreren Bedingungen. Um Menschen zu überzeugen, die Lernmaterialien verwenden, verwenden wir den Befehl "GPT-3"</sample>
    <sample id="285">Wir sampling 100 spezifische Ziele und evaluieren die Skripte, die von großen Sprachmodellen generiert wurden.</sample>
    <sample id="286">Dieses Diagramm zeigt die allgemeine Genauigkeit der verschiedenen Sprachmodelle. Wir bemerkten, dass alle Sprachmodelle unzufriedenstellende Ergebnisse bei der Planung für bestimmte Ziele erzielen.</sample>
    <sample id="287">Dann machen wir eine detaillierte Analyse, um zu untersuchen, warum LLMs falsche Ausdrücke verwenden.</sample>
    <sample id="288">Die Results im Diagramm zeigen, dass die semantische Komplettät in generierten Skripten akzeptabel ist, aber die Treue gegenüber den Bedingungen nicht gewährleistet werden kann.</sample>
    <sample id="289">Wir drehen in die feinere Topologien von Kategorien, die im WikiHow definiert sind. Die Heatmap im Bild zeigt, dass die Planungsleistung von InstructGPTs erheblich variiert für Ziele von verschiedenen Kategorien.</sample>
    <sample id="290">Vorherige Studien haben gezeigt, dass die Ausgabekonstante von Sprachmodellen stark variieren kann, was zu schlechter Leistung führt. Daher adoptieren wir die Idee des Overgenerativen Zufilters, um die Generationsqualität zu verbessern.</sample>
    <sample id="291">Wir zeigen zuerst die Art der Constraints mit Beispielen für den extragpt2 und erhalten spezifische Ziele basierend auf den abstrakten Zielen.</sample>
    <sample id="292">Dann instruieren GPT-3 übergenerieren kandidaten Skripts für spezifische Ziele.</sample>
    <sample id="293">Nächster Schritt: Ein Filtermodell wird entwickelt, um die passenden Skripte zu selektieren.</sample>
    <sample id="294">Wir konvertieren Skripte und Ziele in embeddings von InstructGPT und berechnen die kosinus Ähnlichkeit und Ähnlichkeitspunkte, um semantische Ähnlichkeiten zu messen.</sample>
    <sample id="295">In addition, we will observe the script that contains the keywords of the target constraint. We only keep the script if the target goal score is the highest in the goal set.</sample>
    <sample id="296">Mit unserem Ansatz kann InstructGPT signifikant bessere Skripte generieren. Unser Ansatz verbessert die Planqualität sowohl in Bezug auf semantische Vollständigkeit als auch auf Einhaltung der Bedingungen.</sample>
    <sample id="297">Da Sprachmodelle teurer zu deployen sind, ist es von Bedeutung, die Sprachplanfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung von Datensätzen ist ein wichtiger Schritt zur Umsetzung.</sample>
    <sample id="298">Allerdings haben vorherige Studien das Erstellen von Plänen für bestimmte Ziele nicht erreicht und die manuelle Datenermittlung ist teuer.</sample>
    <sample id="299">Daher folgen wir dem Konzept des symbolischen Wissensdistillations, um constrainted language planning datasets aus großen Sprachmodellen zu distillieren.</sample>
    <sample id="300">Wir übertragen unser Verfahren zur Erstellung eines Datensatzes für die planende natürliche Sprache, der als Ko-Skript bezeichnet wird.</sample>
    <sample id="301">Insgesamt generieren wir 55.000 spezifische Ziele mit Skripten, um die Qualität der Validierung und Testdaten zu gewährleisten. Um die Inkorrektheit von Beispielen zu finden und zu überprüfen, bitten wir Cloudworker, dieIncorrect-Samples zu finden und zu überprüfen.</sample>
    <sample id="302">Dieses Diagramm zeigt die Verteilung von Constraints in CoScript. Wir finden, dass CoScript eine hohe Heterogenität in den generierten spezifischen Zielen zeigt. Mit CoScript können wir kleinere aber spezialisierte Modelle für constraint language planning erstellen.</sample>
    <sample id="303">Wir haben festgestellt, dass T5 auf Coreset optimiert werden kann, Skripte von heller Qualität generieren als die meisten großen Sprachmodelle, was zeigt, dass kleinere Modelle kleine große Modelle übertrumpfen können, wenn sie an geeignetem Datensätzen trainiert werden.</sample>
    <sample id="304">Insgesamt haben wir das Problem der eingeschränkten Sprachplanung festgestellt. Wir evaluieren die Fähigkeit von Sprachmodellen zur eingeschränkten Sprachplanung und entwickeln einen "Over-Generate-and-Fill"-Methode für Sprachmodelle.</sample>
    <sample id="305">Wir verwenden große Sprachmodelle, um einen hochwertigen Skript-Datensatz (CoScript) für die einschränkende Sprachplanung zu generieren. Wir hoffen, den CoScript-Datensatz als wertvolles Ressource zur Fortschreibung der Forschung in der Sprachplanung nutzen zu können.</sample>
    <sample id="306">Danke für Ihr Engagement. Bitte finden Sie mehr Details in unserem Papier.</sample>
    <sample id="307">Die Sprachgewandtheit von PaLM ist vergleichbar mit den besten Systemen auf dem Markt.</sample>
    <sample id="308">Die wichtigsten Eigenschaften eines Wasserzeichenverfahrens sind: die Anwendbarkeit auf Embedding-AS-Dienstleistungen, die Non-Untergrenzungsfehler-Unterratung, die Kryptographie genügend stark zu sein, dass der Angreifer den Wasserzeichenfehler leicht entfernen kann, und die Transferierbarkeit auf die Angreiferservices während des Modell-extraktionsprozesses.</sample>
    <sample id="309">Die englischen TED Talks wurden in 14 verschiedenen Sprachen übersetzt.</sample>
    <sample id="310">Jeder Datensatz wird 200 Instanzen für die erneute Annotierung extrahiert.</sample>
    <sample id="311">Cosinus- und L2-Similarität werden verwendet, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen.</sample>
    <sample id="312">Modelle, die auf einem mehrsprachigen Encoder basieren, wurden in dieser Aufgabe eingesetzt, um die Leistung von Modellen mit mehreren Sprachen zu bewerten.</sample>
    <sample id="344">Die Autoren können eine allgemeine Textsammlung sammeln und die Häufigkeit jedes Wortes in ihr zählen, um festzustellen, welche Wörter mit mittlerer Häufigkeit sind.</sample>
    <sample id="345">Hallo, alle. Mein Name ist Shuheng. Heute werde ich über unser Papier sprechen: "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?" Lasst uns beginnen.</sample>
    <sample id="346">Unsere Publikation untersuchte das Problem der Generalisierbarkeit unter Verwendung des Aufgabens der Erkennung von benannten Objekten (Named Entity Recognition, NER)</sample>
    <sample id="347">Wir bemerkten, dass Modelle seit fast 20 Jahren CoNLL-2003 verwenden, um NER zu entwickeln. Und dies natürlicherweise wirft mehrere Probleme auf. Zunächst einmal können diese Modelle auf moderne Daten übertragen werden?</sample>
    <sample id="348">Und wenn wir neue Tagger entwickeln, was wird benötigt, um gute Generalisierbarkeit zu erreichen?</sample>
    <sample id="349">Gleichzeitig, wenn wir jedoch eine schlechte Generalisierbarkeit beobachtet, was verursacht die Leistungsabnahme dieser Modelle?</sample>
    <sample id="350">Um diese Probleme zu untersuchen, haben wir die ConLL++-Datenbank entwickelt. Dies ist eine Datenbank, die wir aus Reuters-News von 2020 stammt und dann mit den gleichen ConLL-2003-Annotierungsrichtlinien annotiert haben.</sample>
    <sample id="351">Wir haben dann über 20 Modelle auf CoNLL-2003 einstellt. Wir haben sie auf beiden den CoNLL-03 Testset und den CoNLL++ Testset bewertet.</sample>
    <sample id="352">Zuletzt, aber nicht zuletzt, haben wir den prozentualen Änderung in F1 berechnet, um die allgemeinheit jedes Modells zu bewerten.</sample>
    <sample id="353">So, was wird benötigt für eine gute Generalisierbarkeit? In unserem Experiment haben wir festgestellt, dass es drei Hauptingredients bedarf.</sample>
    <sample id="354">Das erstmalige Punkt ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass Transformer-Modelle normalerweise besser auf neue Daten generalisieren.</sample>
    <sample id="355">Der zweite Faktor ist die Modellgröße. Wir haben festgestellt, dass normalerweise größere Modelle zu besseren Generalisierungen führen.</sample>
    <sample id="356">Zuletzt und nicht zuletzt wissen wir alle, dass die Anzahl der Fine-Tuning-Beispiele direkt auf die Performance einer Downstream-Aufgabe auswirkt. Hier haben wir auch festgestellt, dass mehr Fine-Tuning-Beispiele tatsächlich auch zu besseren Generalisierungen führen.</sample>
    <sample id="357">To our next question, what causes the performance drop of some models?</sample>
    <sample id="358">Wir hatten zwei Hypothesen. Die erste ist adaptive Overfitting, das ist Overfitting, das durch die Wiederholung des gleichen Testsets immer wieder auftritt und normalerweise als die Verminderung auf dem neuen Testset manifestiert wird.</sample>
    <sample id="359">Die zweite Hypothese ist Temporal Drift, die Degradation der Performance durch die zunehmende Zeitdistanz zwischen den Train- und Test-Daten verursacht.</sample>
    <sample id="360">Für adaptive Übertaktung sahen wir, dass vom Graphen auf der rechten die rote Best-Fit-Linie eine Steigung hat, die größer als 1 ist.</sample>
    <sample id="361">Das bedeutet, dass jede Einheit Verbesserung, die wir auf Cifar2003 erreicht haben, sich in mehr als eine Einheit Verbesserung auf Cifar++ übersetzt. Das bedeutet, dass es keine diminuierenden Rückgewinnungen gibt.</sample>
    <sample id="362">Dies zeigt uns, dass in diesem Falladaptive Overfitting nicht beobachtet wird.</sample>
    <sample id="363">So, was ist temporale Drift?</sample>
    <sample id="364">Für Temporal Drift haben wir ein Experiment durchgeführt, bei dem wir einige Modelle mit jüngerem Datensatz erneut oder fortsetzten zu prätrainieren versuchten. Wir haben festgestellt, dass die Leistung mit einer größeren Zeitdistanz abnimmt.</sample>
    <sample id="365">Dies bestätigt unsere Hypothese, dass die Hauptursache für die Leistungsinkraftsen temporale Drift ist.</sample>
    <sample id="366">Unser Schlussfolgern ist, dass für eine gute Generalisierbarkeit wir ein besseres Modellarchitektur, größere Modellgröße und mehr fine-tuning-Beispiele benötigen. Und diese Ziele hängen einander ab. Wir können nicht nur ein Ingrediente haben, sondern alle über die anderen verfügen.</sample>
    <sample id="367">Gleichzeitig haben wir auch festgestellt, dass der Leistungsverlust hier durch Temporaldrift verursacht wird und überraschenderweise nicht durch adaptive Übergewichtung. Obwohl CoNLL 2003 über 20 Jahre verwendet wurde,</sample>
    <sample id="368">Also zurück zu der Frage, die wir im Titel unseres Papiers aufgeworfen haben: GILT 2003-Tagger immer noch im Jahr 2023? Und wir haben festgestellt, dass die Antwort tatsächlich ein überzeugender Ja ist.</sample>
    <sample id="369">Wir hoffen, dass unser Papier zu mehr Forschung über die Verbesserung der allgemein anwendbaren Modellgenerierung führt.</sample>
    <sample id="370">Schließlich bitte sicherstellen, dass Sie sich unsere Publikation und unser Datensatz ansehen. Falls Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren. Vielen Dank!</sample>
    <sample id="397">16x16 Pixel.</sample>
    <sample id="398">Servin ist ein Richter.</sample>
    <sample id="399">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="400">Die Arbeiten in den erweiterten Experimenten konzentrieren sich auf die Untersuchung der politischen Biases von Sprachmodellen und die Analyse der Auswirkungen von Trainingdaten auf diese Biases.</sample>
    <sample id="401">Das Modell kombiniert Werte aus mehreren Ebenen.</sample>
    <sample id="402">Beispiele für direkte Inferenz sind die Nennung des Songs "Easy on Me" oder seine Position als erstes.</sample>
    <sample id="403">Die Autoren gehören an Peking University.</sample>
    <sample id="404">5</sample>
    <sample id="405">Ja, die Übersetzung der natürlichsprachlichen Anfrage mit Hilfe eines maschinellen Übersetzungsmodells wurde als Baseline betrachtet.</sample>
    <sample id="406">Ein Beispiel, das die Autoren für eine markierte Gruppe gegeben haben, ist "a woman warrior".</sample>
    <sample id="407">Transformer models</sample>
    <sample id="408">Clean and weak labels</sample>
    <sample id="409">There are five authors involved in the work.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="439">Nach Ansicht der Autoren ist die Integration und Nutzung von prä- und inferenzzeitlicher Kenntnis ein zu wenig erforschtes Gebiet im Bereich der NLU.</sample>
    <sample id="440">The presenters are Ying and Jiahong.</sample>
    <sample id="441">Ja, Coscript hat eine Qualitätskontrolle durchlaufen.</sample>
    <sample id="442">Die Grenzen bestehender Ressourcen für kontextbasierte Übersetzung liegen in der Unterstützung von limitierten Typen von kontextbasierten Übersetzungen und limitierten Sprachen, da sie normalerweise auf Domänenwissen und menschliche Kuration zurückgreifen.</sample>
    <sample id="443">Hallo, ich werde heute über unser Werk sprechen, das sich auf die Auflösung von indirekten Beziehungen für die Entity-Selektion konzentriert. In unserem Werk präsentieren wir den "AltEntities Corpus".</sample>
    <sample id="444">Mein Name ist Javad Hosseini und dies ist ein gemeinsames Werk mit Filip Radlinski, Silvia Paretti und Annie Louise.</sample>
    <sample id="445">Unser Ziel ist es, die Sprache des Benutzers zu verstehen, wenn er eine Wahl treffen möchte. Überlegen Sie sich diese alternative Frage: "Haben Sie damitEasy on Me" oder "Ich hab's" gemeint? Hier will der Benutzer zwischen zwei Liedern auswählen.</sample>
    <sample id="446">Die eindeutigste Sache ist, einen direkten Bezug zu verwenden, zum Beispiel indem man den Namen der Lied, "easy on me" oder seine Position, die erstere, sagt.</sample>
    <sample id="447">Manchmal ist es besser, indirekte Beziehungen zu verwenden, um eine natürlichere Unterhaltung zu haben. Das könnte passieren, wenn der Benutzer den Namen des Liedes nicht mehr weiß.</sample>
    <sample id="448">Die Aussprachen sind zu ähnlich einander und schwer zu unterscheiden.</sample>
    <sample id="449">Oder wenn der Benutzer eine spezifizierte Vorliebe ausdrücken möchte. Hier sind einige Beispiele für indirekte Verweisungen: Zum Beispiel "die neueren" oder "das Lied, das nicht energiegeladen ist".</sample>
    <sample id="450">Das ist ein wichtiger Problem in conversational systems und auch für benchmarking LLMs Entity Verstehen.</sample>
    <sample id="451">Wir kennen keine öffentliche Datensammlung, eine große Skalierbarkeit für die Aufgabe, also sammeln wir eine mit Crowddata annotation. Unsere Datensammlung abdeckt drei verschiedene Domänen: Musik, Böcke und Rezepte.</sample>
    <sample id="452">Unser Datensatzsammlungsansatz betont die Informalität durch die Verwendung einer Cartoon-Vollstelle.</sample>
    <sample id="453">Die Cartoons hat drei Sprachbubbles. In dem ersten Bubblen sagt Bob: "Erinnere dich an das Lied, das wir gestern hörten." Und mit diesem Bubblen setzt Bob den Dialogkontext fort.</sample>
    <sample id="454">In dem zweiten Sprachblatt sagt Alice: "Do you mean easy on me or I got a feeling?"</sample>
    <sample id="455">In welcher der drei Sprachbubbles die alternative Frage steht? In dem dritten Sprachbubble benutzt Bob einen indirekten Hinweis, um eine von diesen Entitys zu selecting. Zum Beispiel: "die neuen Auto</sample>
    <sample id="456">Wir liefern die ersten und zweiten Sprachblister automatisch, aber der dritte wird von einem Notrufier gefüllt. Der erste Sprachblister wird aus einer Handvoll manueller Anregungen pro Domäne gewählt.</sample>
    <sample id="457">Der zweite, der alternative question, wird wie folgt generiert:</sample>
    <sample id="458">Wir verwenden immer einen einfachen Vordruck. Bedarf A oder B, wobei A und B Beispiele aus Wikipedia sind.</sample>
    <sample id="459">Hier sind die verschiedenen Samplingmethoden, die wir verwenden. Wenn wir weiter auf der Liste sind, werden die Entitäten für einander ähnlicher und es wird normalerweise schwieriger, die Disambiguierung zu erreichen.</sample>
    <sample id="460">Der Erste ist "Uniform Random".</sample>
    <sample id="461">Der zweite Fall ist, wenn die Entitäten ähnliche Titel haben. Zum Beispiel zwei Bände mit dem Titel "Die Rückkehr".</sample>
    <sample id="462">Der dritte Fall ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben, zum Beispiel denselben Gattungsbegriff oder denselben Künstler.</sample>
    <sample id="463">Wenn wir diesem alternativen Question den Annotatoren zeigen, kennen sie die Namen dieser Entitäten, aber sie kennen sie nicht unbedingt darüber Bescheid.</sample>
    <sample id="464">Also, was wir tun, ist, dass wir einige Hintergrundinformationen über die zwei Entitäten anzeigen. Für Lieder zeigen wir einfach einen Google-Suchlink zu jeder Lied.</sample>
    <sample id="465">Und dann bitten wir die Annotatoren, sich zumindest ein paar Lieder anzuhören und über sie zu informieren. Hier ist zum Beispiel der Google-Suchergebnisse-Resultat für das Lied "Easy" (von Adele).</sample>
    <sample id="466">Weiterhin erwähnen, dass ich glaube, ich könnte mein Leben nicht ohne sie fortsetzen, rechtfertigt die zweite Verweisung und sie haben eine Konzentrationsbeziehung. Darüber hinaus wurden ihre Bilder nochmal von Wikipedia gezeigt, damit die Annotatoren sehen können, wie sie aussehen.</sample>
    <sample id="467">Dann bitten wir die Annotatoren, eine dieser Entitäten zu auswählen – zum Beispiel hier den ersten – und sie mit 3-5 indirekten Beziehungen zu beschreiben.</sample>
    <sample id="468">Zum Beispiel die mit der Pianomusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel die mit den Wörtern, nicht die mit dem 12-jährigen 12-jährigen Jungen oder das fiktionalen, oder kommt aus Albanien und so.</sample>
    <sample id="469">Der AltEntities Corpus enthält 6.000 alternative Fragen über drei Domänen und 42.000 indirekte Beziehungen. Die Resultate mit dem T5-XL-Modell werden in der Foliensummarisiert.</sample>
    <sample id="470">Wenn der Sprachmodell Zugriff auf die genaue gleiche Hintergrundinformation wie die Annotatoren hat, dann ist die Genauigkeit wirklich hoch. Es liegt in der Nähe von 92-95%. Aber das ist nicht realistisch.</sample>
    <sample id="471">Wenn der Sprachmodell Zugriff auf teilweise überlappendes Hintergrundwissen hat, dann die Genauigkeit zwischen 82 und 87%, was realistischer ist. Zum Beispiel, wenn das Sprachmodell Hintergrundwissen abrufen kann.</sample>
    <sample id="472">Wenn der Sprachmodell nur Zugriff auf die Namen von Entitäten hat, dann sinkt die Genauigkeit auf 60%. Es gibt also viel Raum für Verbesserungen. Wir haben auch gezeigt, dass die Modelle allgemein übertragbar sind. Hier ist ein Link zu unserem Datensatz. Vielen Dank.</sample>
    <sample id="473">Der Ansatz wird mit den Strategien wait-k und local agreement verglichen, die auch auf offline Modellen angewendet werden.</sample>
    <sample id="474">Nantes University</sample>
    <sample id="475">Jenny</sample>
    <sample id="476">Drei.</sample>
    <sample id="477">Hallo, ich bin Sara Papi von der Università di Trento und Fondazione Bruno Kessler. Ich werde kurz das Papier "Attention as a Guide for Simultaneous Speech Translation" von mir und meinen Kollegen Matteo Negri und Marco Turchi präsentieren.</sample>
    <sample id="478">Was ist Simultane Sprachübersetzung? Die Simultane Sprachübersetzung, auch als SMT bezeichnet, ist der Prozess, einen gesprochenen Sprache in einen Text in einer anderen Sprache in Echtzeit zu übersetzen und dadurch eine transkulturelle Kommunikation zu ermöglichen.</sample>
    <sample id="479">Und was sind die Probleme der aktuellen SimulST-Modelle? Spezifische Architekturen werden normalerweise trainiert, indem zusätzliche Module optimiert werden.</sample>
    <sample id="480">Lang und komplizierte Trainingverfahren, z.B. Training, das verschiedene Optimierungsziele beinhaltet,</sample>
    <sample id="481">Und trainieren und pflegen mehrere Modelle, um unterschiedliche Latenzregimes zu erreichen. Zum Beispiel trainieren ein Modell mit einem Durchschnittslatenz von 1 Sekunde und ein anderes Modell mit einer Latenz von 2 Sekunden und so weiter.</sample>
    <sample id="482">So, was ist unsere Lösung?</sample>
    <sample id="483">Erstens verwenden Sie bereits existierende offline-NT-Modelle ohne Erneuerung oder die Anwendung spezifischer Architektur für SimulST. Verwenden Sie nur ein Modell für jede Latenzkategorie und handeln Latenz durch spezifische Parameter.</sample>
    <sample id="484">Und nutzen die von Modellen erworbenen Kenntnisse durch die Achtung im Mechanismus zwischen Audio-Eingabe und Textausgabe, das ist der Kruzachtungsmechanismus. Hier ist ein Beispiel auf der rechten Seite.</sample>
    <sample id="485">Unsere Lösung ist es, EDAT, also Encode to Decode Attention, zu vorschlagen. Und es ist eine Strategie, bei der wir entscheiden, ob wir einen teilweisen Übersetzungsbetrag machen oder nicht, basierend auf, wohin die Aufmerksamkeit zeigt.</sample>
    <sample id="486">Eine Wort wird emittiert, wenn die Aufmerksamkeit nicht konzentriert ist, d.h. wenn das Summe der Aufmerksamkeit (Summe unter einem bestimmten Schwelle α) in den letzten LMB-Speech-Frames liegt, was bedeutet, dass die empfangene Information nicht stabil genug ist.</sample>
    <sample id="487">Zum Beispiel, wenn wir erhalten einen Sprachschung, der 'Ich werde über etwas sprechen' enthält und unser Modell die Übersetzung in Deutsch vorhersagt,</sample>
    <sample id="488">Und wir werden uns ansehen, die KQ-Attention Gewicht.</sample>
    <sample id="489">Wir werden sehen, dass die ersten zwei Worte auf die earliest received speech frames hinweisen, während das letzte Wort auf die last received speech frames hinweist, also λ speech frames.</sample>
    <sample id="490">Dies bedeutet, dass die ersten zwei Worte weggelassen werden.</sample>
    <sample id="491">Während das Summe der Kruzanntension über eine bestimmte threshold-α ist, werden wir den letzten Wort nicht emittieren und warten auf einen neuen Sprachblock.</sample>
    <sample id="492">Wenn wir fortfahren und ein anderes Sprachsegment erhalten und unser Modell weitere drei Worte vorhersagt, werden wir die Kruzaufmerksamheitsgewichter überprüfen.</sample>
    <sample id="493">Wir werden sehen, dass keiner der Worte auf die letzten Lautformen der Sprachframes zeigt.</sample>
    <sample id="494">Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold 𝛼) towards the last 𝜆 speech frames, meaning that the received information is enough stable.</sample>
    <sample id="495">Wenn Sie die Hauptergebnisse von EDAtt ansehen,</sample>
    <sample id="496">Wir plotten die simultane Sprachübersetzungsergebnisse auf Graphen, in denen wir auf einer Seite blau haben, das die Übersetzungsqualität misst, und auf der anderen Seite durchschnittliche Längen.</sample>
    <sample id="497">Das ist die Latenzmesszahl und wir betrachten auch die computational-aware Average Latency, die die Modellcomputationszeit berücksichtigt, um den Output zu produzieren.</sample>
    <sample id="498">Wir wollen, dass unsere Kurve so hoch wie möglich auf diesem Plot ist.</sample>
    <sample id="499">Aber auch, dass sie links versetzt sind.</sample>
    <sample id="500">Wir vergleichen mit anderen populären Strategien, die auch auf offline-Modellen angewendet werden, insbesondere der wait-k-Strategie und dem Lokalvertrag. Wir vergleichen auch mit einem state-of-the-art-Modell speziell für simultaneous translation.</sample>
    <sample id="501">Dies sind alle Resultate der Simultanübersetzung-Strategie auf Deutsch.</sample>
    <sample id="502">Und wir sehen, dass EDAT über alle Strategien führt, die auf offline-Modelle angewendet werden, da die Kurven nach links verschieben.</sample>
    <sample id="503">Und wir sehen auch, dass wenn wir die tatsächliche Laufzeit oder die computrational-aware Time berücksichtigen, EDAtt die schnellste Strategie ist.</sample>
    <sample id="504">Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unser Papier und wir haben auch Open Source, die Code und Modelle und Simultane Ausgaben freigegeben, um die Wiedervereinbarkeit unseres Werks zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="505">Ja, der Datensatz ist öffentlich zugänglich.</sample>
    <sample id="506">Hallo, alle. Mein Name ist Ying und mein Kollege Zhiyang und ich werden unsere Forschung über Multi-instruct präsentieren: "Improving multi-modal zero-shot learning via instruction tuning".</sample>
    <sample id="507">Mit Fortschritten in großen Sprachmodellen haben viele Arbeiten begonnen, neue Lernparadigmen zu untersuchen, indem sie vortrainierte Sprachmodelle für verschiedene untere Aufgaben in einer parameter- und dateneffizienten Weise verwenden.</sample>
    <sample id="508">Kürzlich haben viele Studien gezeigt, dass die Anweisungstuning große Sprachmodelle erlaubt, auf Aufgaben in einem null-Shot-Modus zu arbeiten, indem sie natürliche Anweisungen folgt.</sample>
    <sample id="509">Allerdings konzentrieren sich die meisten vorherigen Arbeiten auf die Verbesserung der zero-shot-Performance auf Sprach-only-Aufgaben, während Computer Vision und multimodale Aufgaben weggelassen wurden.</sample>
    <sample id="510">Daher zielt in dieser Arbeit die Untersuchung an, ob die Anpassung von Multimodal prätrainierten Modellen durch die Anpassung von Anweisungen tatsächlich die allgemeinheitliche Leistung bei nicht-multimodalen Aufgaben verbessern kann.</sample>
    <sample id="511">Darüber hinaus haben wir bei unserer Forschung eine bemerkenswerte Diskrepanz in der Verfügbarkeit von Anweisungsdatensätzen zwischen NLP und Multimodal entdeckt.</sample>
    <sample id="512">Es existieren mehr als 1600 Sprach-only-Instructions Aufgaben. Allerdings gibt es keine große Skala von öffentlich zugänglichen multimodalen Instructions Aufgaben. Daher motiviert uns, einen multimodalen Instructions Tuning Datensatz zu erstellen.</sample>
    <sample id="513">Hier präsentieren wir MultiInstruct, das erst multimodale Instruktions-Tuning-Benchmarke-Datenensemble ist, das 62 diverse multimodale Aufgaben umfasst, die in 10 breiten Kategorien verteilt sind.</sample>
    <sample id="514">Diese Aufgaben werden aus 21 bestehenden offenen Quelldatasets abgeleitet und jede Aufgabe wird mit 5 expert-written Anweisungen versehen.</sample>
    <sample id="515">Um die Multi-Modal-Instructions-Tuning auf unserem vorgeschlagenen Datensatz zu untersuchen, nehmen wir OFA, einen vereinheitlichten Multi-Modal-Prätrainingsteam als unser Basismodell. OFA verwendet eine vereinheitlichte Vokabularie für Sprach-, Bildtoken und Koordinaten einerBounding-Box.</sample>
    <sample id="516">Hier sehen wir einige Beispielinstanzen aus unserem MultiInstruct-Dataset.</sample>
    <sample id="517">To unify the processing of various input and output data types.</sample>
    <sample id="518">Wir folgten dem Ansatz von OFA und formulieren alle Aufgaben in einem vereinbarten Format der "Sequence to Sequence" (Sequenz zu Sequenz), in dem die Eingabe-Texte, -Bilder, Anweisungen undBounding Boxes im gleichen Token-Raum dargestellt werden.</sample>
    <sample id="519">Okay, nun werde ich über Multi-modal-Instructions-Tuning sprechen.</sample>
    <sample id="520">Für die Trainingsdatenbank verwenden wir 53 Aufgaben aus einem Gruppe zur Trainingseinrichtung und sampling 10.000 Instanzen pro Aufgabe. Für die Testdatenbank reservieren wir die gesamte Gruppe "Common Sense Reasoning" für die Testphase und ausgewählten 5 Aufgaben aus den Gruppen "VQA" und "Miscellaneous".</sample>
    <sample id="521">Wir verwenden alle Instanzen in der Testteilung für jede Aufgabe. Neben dieser verwenden wir 20 zufällig ausgewählte Aufgaben aus dem Testteilung des Natural Instructions Datensatzes als unbekannte Aufgaben für NLG.</sample>
    <sample id="522">Wir verwenden einen vortrainierten OFA-Large-Modell als Basismodell. Während des Trainings mappen wir alle Instanzen für alle Aufgaben an. Jede Instanz wird zufällig mit einem von seinen 5 Anweisungstemplaten kombiniert.</sample>
    <sample id="523">During tests for each task, wir conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.</sample>
    <sample id="524">Wir berichten die durchschnittliche und maximale Leistung und die Standardabweichung der Leistung über alle five Experiments.</sample>
    <sample id="525">Wenn die Aufgabe ein multimodales Klassifizierungsproblem ist, berichten wir die Genauigkeit. Wenn es ein multimodales Generationsproblem ist, berichten wir Rouge-L. Bei NLP-Aufgaben berichten wir Rouge-L ebenso.</sample>
    <sample id="526">Wir haben auch einen zusätzlichen Evaluationsmaßstab namens Sensitivität eingeführt. Dies misst die Fähigkeit des Modells, für dieselbe Aufgabe dieselben Ausgaben zu produzieren, unabhängig von kleinen Variationen in der Formulierung der Anweisung.</sample>
    <sample id="527">Unser Hauptergebnis zeigt, dass die Anpassung der Ausbildung signifikant das Leistungspotenzial von OPA verbessern kann. Auf bestimmte mehrmodulare Aufgaben.</sample>
    <sample id="528">Auch die Transferlearning von Natural Instruction Datensätzen kann die Instruktionstuning verbessern.</sample>
    <sample id="529">Hier können wir sehen, dass die Anzahl der Aufgaben zunimmt, die Modell erreicht eine bessere Leistung und in der meantime eine tieferen Sensitivität.</sample>
    <sample id="530">Wir haben auch weitere Experimente durchgeführt, bei denen wir einen Befehl gegen fünf Befehle verwendet haben. Wie wir sehen können, kann die Verwendung mehrerer Befehle die allgemeine Leistung des Modells verbessern und seine Sensibilität erheblich reduzieren.</sample>
    <sample id="531">Dies zeigt die Auswirkungen verschiedener Fine-Tuning-Strategien auf die Sensibilität des Modells. Wie wir sehen können, kann die Transfer-Lernung aus dem Natural Instructions Datensatz das Modell gegenüber dem ursprünglichen OFA-Modell signifikant verbessern.</sample>
    <sample id="532">Wir können auch sehen, dass Transferlearning aus dem Natural Instructions Datensatz helfen kann, OPA zu einem viel besseren Leistung auf dem Natural Instructions Datensatz zu erzielen.</sample>
    <sample id="533">Insgesamt haben wir einen ersten großen Skalierbaren multimodalen Anweisungstuning-Datensatz vorgeschlagen, der die zero-shot-Fähigkeit von OFA signifikant verbessert und verschiedene Transferlearning-Techniken untersucht hat, um ihre Vorteile zu zeigen. Wir haben auch einen neuen Metrik-Sensitivitätsdesign entworfen.</sample>
    <sample id="534">Eine weitere Sache: Wir sammeln ein viel größeres multimodales Anweisungstuning-Datensatz mit around 150 zusätzlichen visio-natur Sprach Aufgaben und wir werden sie bald freigeben. Hier ist ein QR-Code für unser Datendatamodell. Danke.</sample>
    <sample id="535">Die Autoren gehören an der Università di Trento.</sample>
    <sample id="536">Javad Hosseini</sample>
    <sample id="562">Hallo, alle zusammen. Ich bin Kostya Sinha und ich freue mich, Sie zu unserem Vortrag über unser ACL 2023 Papier begrüßen zu können: "Sprachmodell-Acceptabilitätseinschätzungen sind nicht immer robust gegenüber Kontext."</sample>
    <sample id="563">Eine gemeinsamearbeit mit John Gauthier, Aaron Mueller, Kanishka Mishra, Keren Fuentes, Roger Levy und Adina Williams.</sample>
    <sample id="564">In diesem Werk revisitieren wir Minimalpaar paradigm (MPP) evaluations of language models. Sie verwenden relative Differenzen in sequentiellen Wahrscheinlichkeiten, um die abstrakte Kenntnis von Sprachmodellen zu bewerten.</sample>
    <sample id="565">Der Minimal Paar Paradigma (MPP) bewertet Sprachmodelle hauptsächlich auf der Grundlage von Urteilsschwergewichten, die relative Differenzen in Sequenzwahrscheinlichkeiten verwendet, um die abstrakte Kenntnis von Sprachmodellen zu bewerten. Dies kann auch die Grammatik wie BLMP, SyntaxGym oder Stereotypie in Form von CrowS einschließen.</sample>
    <sample id="566">In diesem Minimalpaar paradigm wird üblicherweise die Auswertung von Sprachmodellen durch das Vorlegen von akzeptablen Sätzen oder grammatikalischen Sätzen und das Folgern von nicht-akzeptablen Sätzen oder ungrammatikalischen Sätzen erreicht.</sample>
    <sample id="567">Und dann hofft das Modell, dass es mehr Wahrscheinlichkeit beim akzeptablen Satz einordet.</sample>
    <sample id="568">Der aktuelle MPP-Pipelinebasierende Ansatz lässt uns nicht die Akzeptanz von Modellen gegenüber langen Sätzen bewerten.</sample>
    <sample id="569">Diese Tage werden große Sprachmodelle immer mehr mit größeren Kontextfenstern kommen. Es ist daher von Bedeutung, die Akzeptierbarkeit der Modelle über den gesamten Kontext zu bewerten.</sample>
    <sample id="570">Und das ist, was wir versuchen zu tun. Wir versuchen, den MPP-Pipeline-Fluss zu überarbeiten, indem wir die Modelle auffordern, die Akzeptierbarkeit auf immer längeren und längeren Folgen zu bewerten.</sample>
    <sample id="571">So, das ist der Ansatz. Also, was wir tun, ist, diese längeren Sequenzen zu simulieren. Wir revisitieren die Datensätze selbst und erstellen dann Sentenzen, indem wir akzeptierbare oder unakzeptierbare Sätze aus diesen Datensätzen auswählen.</sample>
    <sample id="572">Zum Beispiel haben wir hier einen typischen Paar von Grammatikfehlern aus dem BLIP-Datenensemble aus dem Adjunct Island-Fall gewählt.</sample>
    <sample id="573">Und was wir tun, ist, lange Reihenfolgen zu erstellen, die akzeptabel sind und die gleiche Übereinstimmung der grammatikalischen Struktur haben. Wir extrahieren grammatikalische Sätze aus GPT-3.</sample>
    <sample id="574">Und dann fügen wir es als Prefix zu beiderseit an der akzeptierbaren Abfragetext und dem unakzeptierbaren Abfragetext an.</sample>
    <sample id="575">Wir können das gleiche machen, indem wir unakzeptable Sätze aus dem gleichen Paaring auswählen und das könnte auch verwendet werden, um die Modellakzeptabilität zu testen.</sample>
    <sample id="576">Und wir können auch das gleiche tun, indem wir Sätze aus einem anderen Subset oder einem anderen Datensatz auswählen. Das nennen wir als Mismatch-Szenario.</sample>
    <sample id="577">Hier sind die Sätze immer noch aus relevanten Datensätzen stammt, aber sie sind nicht aus demselben Datensatz, der verwendet wird, um zu evaluieren. Und wir können das gleiche für unakzeptierbares Paar tun.</sample>
    <sample id="578">Schließlich können wir Sentenzen aus einem vollständig unverwandten Domänen wie Wikipedia auswählen.</sample>
    <sample id="579">Dies wird uns verraten, ob die Modelle- Akzeptierbarkeiturteile tatsächlich von Kontext beeinflusst werden.</sample>
    <sample id="580">Ob der Kontext kommt aus einem anderen Teil des Datensatzes oder ob es für die aktuelle Aussage irrelevant ist.</sample>
    <sample id="581">Wie führt der Modell? Zunächst schauen wir uns die Wikipedia-Sätze an, die für das aktuelle Suchanfragepaar completely irrelevant sind. Und dort finden wir, dass die MMP-Jugendmeßungen hauptsächlich robust für arbiträre Kontextlängen sind.</sample>
    <sample id="582">Wir haben die Kontextlänge auf 1024 maximiert, um die OPT und GPT-2-Modelle zu überlasten. Hier im orange Dotted Line sahen wir, dass die MPP-Bewertungen relativ stabil blieben.</sample>
    <sample id="583">Jetzt sehen wir, was passiert, wenn wir Sentenzen aus derselben Datensammlung verwenden.</sample>
    <sample id="584">Hier erstellen wir Sentenzen aus akzeptablen und unakzeptablen Domänen aus dem gleichen Blip or syntaxem Datensatz.</sample>
    <sample id="585">Und dort sehen wir, dass die MP-P-Judgment entweder signifikant zunehmen oder abnehmen, wenn Sie entweder akzeptable oder unakzeptable Präfixe hinzufügen.</sample>
    <sample id="586">Aber wenn wir die Struktur übereinordnen, das ist, wenn wir die Sätze aus dem gleichen Phänomena in BlamePersonTextJim auswählen,</sample>
    <sample id="587">Wir sehen einen massiven Anstieg oder einen massiven Abfall der MPP-Bewertung für das Modell, je nachdem, ob der gewählte Prefix akzeptabel oder unakzeptabel ist.</sample>
    <sample id="588">Jetzt, und das ist sehr groß, wie dieser Effekt durch den Kontextlink zunimmt. Das würde wahrscheinlich die jüngeren Sprachmodelle beeinflussen, die einen großen Kontextwindow haben.</sample>
    <sample id="589">Warum beeinflussen vorfixe Stellen Sprachmodellurteile so stark?</sample>
    <sample id="590">Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, die Eingabeaussage zu perturbieren, indem wir versucht haben, die relevanten Struktur zu erhalten, aber dennoch Geräusche in die Eingabe hinzuzufügen. Nachdem wir mehrere dieser Perturbationen durchgeführt hatten,</sample>
    <sample id="591">Wir finden, dass keines dieser Störungen den Modellverlauf tatsächlich beeinflusst, in Bezug auf, wie es uns die PAPIER-URTEIL-PRÄGUNG präsentiert.</sample>
    <sample id="592">Basierend auf dem obigen Bild und den Informationen, die darauf enthalten sind, können wir feststellen, dass die Modelle gegenüber perturbierten Sätzen empfindlich sind.</sample>
    <sample id="593">Das ist, wenn wir die Sätze im akzeptablen Bereich perturbieren, sehen wir einen ähnlichen Anstieg in allen Perturbationen. Und wenn wir die Sätze im nicht akzeptablen Bereich perturbieren, sehen wir eine Decrease in MPPI-Bewertungen in ähnlicher Weise.</sample>
    <sample id="594">Die Hauptpunkte unseres Artes sind, dass Sprachmodelle sensible latent syntagmatische und semantische Merkmale sind, die über die Sätze verteilt sind.</sample>
    <sample id="595">Die MPP-Evaluation, die derzeit mit kurzen und einfachen Eingabe-Texten durchgeführt wird, kann möglicherweise nicht vollständig das abstrakte Wissen der Sprachmodelle im Kontextwindow capturieren.</sample>
    <sample id="596">Bitte lesen Sie unser Papier für weitere Details über unsere Experimente. Vielen Dank für das Hören.</sample>
    <sample id="597">Unordered multiset of tokens that will appear in the output.</sample>
    <sample id="598">In Coscript sind 55.000 Skripte vertreten.</sample>
    <sample id="626">Die beste Ausrichtungsmethode für DEplain ist die Methode von Mass Align.</sample>
    <sample id="627">Schwach überwachtes Lernen allgemein alleviiert die Annotierungs-Schranke.</sample>
    <sample id="628">Die Dokumente in DEplain-web wurden mit manuellen und automatischen Alignmentmethoden ausgerichtet.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde von Reuters News 2020 abgeleitet und mit den gleichen CoNLL 2003-Annotation guidelines annotiert.</sample>
    <sample id="630">Hallo, alle. Mein Name ist Yusen Zhang vom Penn State University. Heute werde ich über unser Werk "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations" sprechen.</sample>
    <sample id="631">Semantische Analyse ist eine Aufgabe, die semantische Darstellungen von Benutzereingaben erstellt, wie SQL und Lambda Calculus.</sample>
    <sample id="632">Cross-lingual Semantic Parsing ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsdarstellungen zu übersetzen.</sample>
    <sample id="633">In dem obigen Bild sehen wir, dass wir die Abfragen in mehreren natürlichen Sprachen mit neuronalen Modellen ins SQL, Lambda oder FunQL usw. übersetzen müssen.</sample>
    <sample id="634">Gegenüber existierenden CLSP-Modellen werden die vorgeschlagenen Modelle separately bewertet auf Datensätzen von limitierten Aufgaben und Anwendungen. Zum Beispiel:</sample>
    <sample id="635">Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen. Der Chinesische ist weg und...</sample>
    <sample id="636">Mangelnde Abdeckung auf bestimmte Bedeutungsrepräsentationen.</sample>
    <sample id="637">Die Lambda-Kalkülus ist weg.</sample>
    <sample id="638">Oder sie werden nur auf bestimmte neuronalen Modelle bewertet. Zum Beispiel gibt es nur einen einzigen Single-Model zu bewerten.</sample>
    <sample id="639">Um dies zu erreichen, schaffen wir das Exemplar. Wir bieten ein einheitliches Datensatz-Exemplar für die korsische Semantik-Semantic-Parsing in mehreren natürlichen Sprachen und Bedeutungsdarstellungen.

Dieses Exemplar ist eineUnified-Datensatz, der 9 Datensätze in verschiedenen Domänen umfasst, 5 semantische Aufgaben und 22 natürliche Sprachen in 15 Sprachfamilien enthält. Es enthält auch 9 Datensätze in verschiedenen Domänen, 5 semantische Aufgaben und 22 natürliche Sprachen in 15 Sprachfamilien.

Das Exemplar ist ein Modell, das eine Unified-Datensatz-Struktur verwendet, um die korsische Semantik-Semantic-Parsing in mehreren natürlichen Sprachen und Bedeutungsdarstellungen zu erreichen. Es ist ein wichtiger Schritt, um die Semantik-Semantic-Parsing in mehreren Sprachen zu verbessern und die Effizienz und Genauigkeit zu steigern.</sample>
    <sample id="640">Es enthält 9 Datensätze in verschiedenen Domänen, 5 semantische Parsintasks, 8 Bedeutungsdarstellungen und 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="641">Um unser Benchmark besser zu evaluieren, betrachten wir die sechs Einstellungen für Training und Evaluation.</sample>
    <sample id="642">Der Erste ist translate test. Wir verwenden die Google Translate-API, um den Quelltext in die Zielsprache zu übersetzen, und dann verwenden wir einen monolinguen Modell zur Training- und Evaluierung.</sample>
    <sample id="643">Zum Beispiel trainieren wir das englische Modell an englischen Abfragen und während der Inferenz übersetzen wir die deutsche Abfrage mithilfe einer API ins Englische und dann verwenden wir das trainierte Modell, um die SQL-Abfrage zu vorhersagen.</sample>
    <sample id="644">Wir werden auch monolinguelle Modelle testen.</sample>
    <sample id="645">In diesem Setting ist die Quellensprache gleich wie die Zielsprache. Beispiele sind: Deutsch zu Deutsch, oder Englisch zu Englisch.</sample>
    <sample id="646">Wir testen auch die Monolingual Few-shot-Situation, indem wir monolingual-Modelle mit nur 10% der Ausbildungsdaten trainieren.</sample>
    <sample id="647">Wir testen einen multilingualen Modellansatz, bei dem wir einen Modellansatz für alle Sprachen trainieren.</sample>
    <sample id="648">Zum Beispiel legen wir deutsche, englische und chinesische Abfragen zusammen, um ein multilinguales Modell zu trainieren. Und während der Inferenz können wir dieses Modell verwenden, um...</sample>
    <sample id="649">Um deutsche Abfragen oder chinesische Abfragen usw. zu übersetzen.</sample>
    <sample id="650">Und wir betrachten auch die Sprachübergreifende Zero-Shot- und Few-Shot-Transfer. Wir trainieren auf einer Quelle言語 und übertragen auf eine andere Sprache.</sample>
    <sample id="651">Während der Trainingphase trainieren wir entweder auf englischen Abfragen oder auf einer Kombination von englischen und deutschen Few-Shot-Abfragen, um ein multilinguales Modell zu trainieren, das die SQL-Ausgabe vorhersagt.</sample>
    <sample id="652">Wir haben auch einige interessante Ergebnisse gefunden. So, wenn es um die Analyse von monolinguen Modellen geht, evaluieren wir zwei Gruppen von Modellen.</sample>
    <sample id="653">Inklusive Encoder PDR, das steht für multilingual pre-trained encoders mit pointer-based Decoders wie XLNet + PDR und mBERT + PDR.</sample>
    <sample id="654">Wir bewerten auch Encoder-Decoder-Modelle, die multilingual-betreten Encoder-Decoder-Modelle sind, wie mBART und mT5.</sample>
    <sample id="655">Wir haben festgestellt, dass Encoder-Decoder-Modelle die beste Leistung auf allen neun Datensätzen erzielen.</sample>
    <sample id="656">Wir evaluieren auf MT5 und XLM-R + PTR auf multilinguistischem Setting.</sample>
    <sample id="657">Wir haben festgestellt, dass Encoder-Decoder- oder Encoder-PTR-Modelle durch das Training in einer Mischung verschiedener Sprachen verbessert werden können.</sample>
    <sample id="658">Wir haben festgestellt, dass es because most der Hauptnatürlichen Sprachen einen Leistungsverlust erhalten, aber die englische Leistungen in sieben Datensätzen abnehmen und nur in drei Datensätzen steigen.</sample>
    <sample id="659">Die Analyse der Mehrsprachtrainingsevaluation auf mehreren Sprachen zeigt, dass die Leistung im Englischen in 7 Datensätzen abnimmt, während sie in 3 Datensätzen steigt. Dies wird als "Curse of Multilinguality" bekannt.</sample>
    <sample id="660">Wir vergleichen auch die Sprachübergreifende Leistungsunterschiede.</sample>
    <sample id="661">In diesem Diagramm ist die blaue Linie die Transferuntersuchung im mehrsprachigen Few-Shot-Setting. Die orange Linie ist die Transferuntersuchung im mehrsprachigen Null-Shot-Setting, während die grüne Linie die monolinguen Setting ist.</sample>
    <sample id="662">Wir haben festgestellt, dass durch die Vergleichung der Grünen und Orange- Linie festgestellt wurde, dass im Null-Shot-Setting die Transferleistungsab鸿knapf鯉fig erheblich ist. Und durch die Vergleichung der Blauen und Orange- Linie festgestellt wurde, dass im Few-Shot-Setting die Transferab鸿knapf鯉fig r鯉ckwärts beeinflusst wird.</sample>
    <sample id="663">Wir haben auch einige andere interessante Erkenntnisse entdeckt. Zum Beispiel übertrifft der Encoder-Decoder vorheriges Werk oder erreicht vergleichbare Ergebnisse. Das Training auf englischer natürlicher Sprache kann die Leistung von Few-Shot auf Zielsprachen signifikant steigern.</sample>
    <sample id="664">Multilinguale Sprachmodelle wie Codex und Bloom sind noch unzureichend für die Übersetzung von Sprachen.</sample>
    <sample id="665">Zusammenfassend haben wir XSemPLR, eine vereinheitlichte Benchmark-Studie für die korselnde Semantik-Aufbereitung mit mehreren natürlichen Sprachen und Bedeutungsvorstellungen erstellt.</sample>
    <sample id="666">Wir haben einen umfassenden Benchmark-Studie an drei repräsentativen Typen von multilingualen Sprachmodellen durchgeführt und unsere Ergebnisse zeigen einige interessante Erkenntnisse und so weiter. Und herzlich willkommen, um zu unserem Papier und Code zu visitieren. Danke für das Lesen.</sample>
    <sample id="667">Parameter-based watermark, Lexical watermark, Backdoor-based watermark, Adversarial-based watermark</sample>
    <sample id="668">Nein, sie sind noch nicht ausreichend für CLSP.</sample>
    <sample id="695">Die Methode mit der Mehrdeutigkeit der Permutationen wird durch die Einführung des Ausrichtungsbegriffs als Teil der Trainingseinheit bewältigt.</sample>
    <sample id="696">Die Fairness eines nachgeschalteten NLP-Modells wird definiert als die Fähigkeit, die Auswirkungen auf Menschen mit verschiedenen politischen Ansichten und Gruppen zu minimieren.</sample>
    <sample id="697">Yanis Labrak</sample>
    <sample id="698">Kostya Sinha</sample>
    <sample id="699">Myra Cheng</sample>
    <sample id="700">Tropikalismus bezieht sich auf die Tendenz, Frauen von Color als primitiv und exotisch zu beschreiben.</sample>
    <sample id="701">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen erstellt, indem sie die Top-Wortstamme identifiziert haben, die in den Beschreibungen verwendet wurden.</sample>
    <sample id="702">P-CXMI</sample>
    <sample id="703">DrBERT und ChuBERT sind zwei verschiedene Modelle, die auf unterschiedlichen Datensätzen trainiert wurden. DrBERT wurde auf einem Datensatz von 7GB NACHOS trainiert, während ChuBERT auf einem Datensatz von 4GB NACHOS und 4GB Klinischen Knoten trainiert wurde.</sample>
    <sample id="751">Drei.</sample>
    <sample id="752">Iteratives Transferlernen ist ein Verfahren, bei dem ein Modell durch das Training auf den neuesten Datensatz aus更新。</sample>
    <sample id="753">Das Ziel des Datensatzes ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen möchten.</sample>
    <sample id="754">Ein Angreifer kann Modellparameter über einen EaaS extrahieren, indem er die Abhängigkeit von Modellparametern auf die Anzahl der Triggers in einem Satz exploitiert.</sample>
    <sample id="755">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="756">10 Annotatoren wurden verwendet.</sample>
    <sample id="757">Die Autoren gehören an Carnegie Mellon University und University of Washington.</sample>
    <sample id="758">Das Beispiel mit dem Begrenzer auf der linken Seite lautet: "I saw Bart and Lisa."</sample>
    <sample id="759">Das Stand der Technik für Dialogsysteme ist die Fähigkeit, die Häufigkeit von Themenfehlern zu messen.</sample>
    <sample id="760">Weil große Sprachmodelle heutzutage mit immer langeren Kontextfenstern arbeiten.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="762">Ja, die Annotatoren kennen die Entität im Voraus.</sample>
    <sample id="763">BLEU, METEOR, TER, WER</sample>
    <sample id="764">Ja, die Regression beeinflusst die Generalisierung auf bestimmte NER-Typen.</sample>
    <sample id="765">Positionalität ist für NLP wichtig, weil es die Auswirkungen von Systematischen Leistungsunterschieden auf die Technologie und die Menschen betont.</sample>
    <sample id="766">LLMs wurden durch Adapter anpassiert.</sample>
    <sample id="767">Sie verwenden das Modell, das Sie für das Transferlernen verwenden.</sample>
    <sample id="768">Die aktuellen Testsets, die zur Bewertung der PaLM-Fähigkeiten verwendet wurden, sind der Europäischen Union (EU) und der Nordamerikanischen (NA) Testsets.</sample>
    <sample id="769">Die Autoren haben schließlich drei Empfehlungen vorgeschlagen.</sample>
    <sample id="770">Der Gewinn der vorgeschlagenen Methode gegenüber der stärksten Baseline beträgt 1.07.</sample>
    <sample id="771">The referent is named Shuheng Liu.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz können als Benchmark verwendet werden.</sample>
    <sample id="773">In der Arbeit werden 5 kleineren Modellen experimentiert.</sample>
    <sample id="774">Das OFA-Modell wird als Basismodell für die Untersuchung der multimodalen Unterrichtsabstimmung verwendet.</sample>
    <sample id="833">Die Autoren gehören an der University of California, Berkeley.</sample>
    <sample id="834">Die Autoren gehören an Stony Brook University.</sample>
    <sample id="835">The languages studied in the work are not specified.</sample>
    <sample id="836">Shangbin Feng</sample>
    <sample id="837">Long Impart und Long Base Impart</sample>
    <sample id="838">53 Aufgaben werden für die Training und 20 Aufgaben für die Tests verwendet.</sample>
    <sample id="839">Drei</sample>
    <sample id="840">Die Autoren haben experimentiert an den Datensätzen AG News, MIND, SST2 und Enron Spam.</sample>
    <sample id="876">NACHOS is a dataset of medical crawled data from the web.</sample>
    <sample id="877">The referent is Ibilard.</sample>
    <sample id="878">Die Strategie der prompts hat einen großen Einfluss auf die Leistung der LLMs für die Übersetzung.</sample>
    <sample id="879">Die Autoren gehören an Carnegie Mellon University.</sample>
    <sample id="880">Die 5 Anweisungen der Expert*innen lauten: 1. Vermeiden Sie die Verwendung von Tabellen, Listen und Aufzählungen. 2. Vermeiden Sie die Verwendung von Jargon und Fachtermini. 3. Vermeiden Sie die Verwendung von allgemein anerkannten Begriffen. 4. Vermeiden Sie die Verwendung von allgemein anerkannten Begriffen. 5. Vermeiden Sie die Verwendung von allgemein anerkannten Begriffen.</sample>
    <sample id="881">Die Autoren schlagen die Evaluierung der Datensammlung mit Menschenexperimenten und etablierten Coreference-Resolution-Modellen vor, um die Fähigkeit zu beweisen, Informationen aus mehreren Quellen zu verwenden.</sample>
    <sample id="882">Hallo, alle. Mein Name ist Ibilard und ich werde Ihnen einen kurzen Überblick über das Papier "Prompting PaLM for Translation: Assessing Strategies and Performance" geben. Dies ist ein Jointwork mit meinen Kollegen von Google Translate.</sample>
    <sample id="883">PalM ist ein 540 Milliarden Parameter lernfähiges Sprachmodell, das vor einem Jahr, im Jahr 2022, präsentiert wurde. Es wurde auf einer großen Sammlung von Texten trainiert, die 780 Milliarden Token umfasst.</sample>
    <sample id="884">Das Modell der Verarbeitung natürlicher Sprache (PaLM) erreicht das aktuelle Standardmodell in Hundertstel von NLP-Aufgaben.</sample>
    <sample id="885">In dieser Arbeit präsentieren wir die erstmalige systematische Studie von LLM-Prompting für Maschinentranslation.</sample>
    <sample id="886">Wir haben die Übersetzungsfähigkeit von Sprachmodellen mit den besten Praktiken der MT-Community evaluiert. Dies beinhaltet die Verwendung neuester Testdatensätze, um einenOverlap der Testdaten mit der Trainingsdaten des Sprachmodells zu vermeiden.</sample>
    <sample id="887">Wir vergleichen zwei state-of-the-art-Systeme. Die besten Performing-Systeme sind die WMT-Evaluation.</sample>
    <sample id="888">Wir verwenden innovative MT-Metris und zusätzlich auch Expertenbasierte menschliche Evaluierergebnisse. Schließlich bieten wir einige Empfehlungen für die Selektionsstrategien an.</sample>
    <sample id="889">Die Anreize haben einen großen Einfluss auf die Leistung von LLMs für die Übersetzung. Wie wir in einem einfachen Experiment sehen können, verwenden wir ein-once-Anreize und zwei verschiedene Anreize für jede Satz.</sample>
    <sample id="890">Die Mehrzahl der Sätze (516 von 1000) weisen einen Unterschied von mehr als 1 BLEURT-Punkt hin.</sample>
    <sample id="891">Und dies kann in Extremfällen bis zu 40 BLEURT-Punkten betragen. Es ist daher wichtig, einen guten Prompts-Strategie zu verwenden.</sample>
    <sample id="892">In our experiments, we evaluate for a few-shot prompting strategy where we just mark each sentence that we provide to the system with the language it's in.</sample>
    <sample id="893">In einem Beispiel hier, in dem wir übersetzen von Deutsch ins Englische, sind die deutschen Sätze, die Quelltexte, mit dem deutschen Klon markiert und die englischen Übersetzungen mit dem englischen Klon.</sample>
    <sample id="894">Wir haben festgestellt, dass die Art des Prompts einen großen Einfluss auf den Fall von Serienshort-Prompting nicht hat.</sample>
    <sample id="895">Es ist für zero- und one-shot Prompting von Crucial, und wenn wir uns in unserem Fall auf five-shot Prompting beziehen, gibt es fast keine Unterschiede zu der tatsächlichen Form des Promptings.</sample>
    <sample id="896">Es sind die Beispiele, die den meisten Gewicht tragen.</sample>
    <sample id="897">Die Zusammenfassung unserer experimentellen Ergebnisse lautet darauf, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Quellsatz.</sample>
    <sample id="898">Es ist wichtig, die Beispiele aus hohen qualitätsstelle Übersetzungen zu verwenden. Insbesondere vergleichen wir die Selektionsanfragen mit dem Trainingsdaten der UMT-Evaluationen oder dem Dev-Daten.</sample>
    <sample id="899">Das Dev-Data ist viel besser qualitativ und quantitativ als das Training-Data, was zu einem besseren Leistungsresultat führt.</sample>
    <sample id="900">Trotzdem haben spezialisierte SOTA-Systeme einen erheblichen Vorteil über die PAM-Übersetzungen, aber PAM kommtPretty nah an einem kommerziellen System heran. In unserem Fall haben wir uns entschieden, Google Translate zu verwenden.</sample>
    <sample id="901">Die Einzelanalysen, die wir mit dem MQM-Framework durchfuhren, haben gezeigt, dass die Fluideität von PaLM vergleichbar ist zu den besten Systemen auf dem Markt. Der Hauptunterschied kommt jedoch von der Genauigkeit.</sample>
    <sample id="902">Im Besonderen sind die häufigsten Fehlertypen "Omission-Fehler".</sample>
    <sample id="903">So scheint es, dass PaLM Entscheidungen trifft, um eine bessere Übersetzung zu produzieren, manchmal indem sie Teile des Quelltextes auslassen, die in der Übersetzung irrelevant sind.</sample>
    <sample id="904">Allerdings ist die "Stil/Ahnung" Kategorie für PaLM tiefer als für die SOTA-Systeme, was ein weiterer Hinweis auf die Schwächen von PaLM ist.</sample>
    <sample id="905">Palm bietet wirklich flußigen Output, aber immer noch mit ein paar Problemen der Genauigkeit.</sample>
    <sample id="906">Und das ist es für diese wirklich kurze Übersicht. For more details, please come my to the full presentation of the paper. Thank you very much.</sample>
    <sample id="907">Hallo, ich bin Dawei, ein PhD-Student an der Saarland University in Deutschland. In diesem Video möchte ich gerne unser neuestes Werk präsentieren: "Weaker Than You Think" - eine kritische Betrachtung vonWeakly Supervised Learning.</sample>
    <sample id="908">Dies ist ein gemeinsames Werk mit Xiaoyu Shen, Marius Mosbach und Andreas Stephan und Dietrich Klakow.</sample>
    <sample id="909">WarumWeaklySupervisedLearning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning (WSL) Train models that generalize well despite being trained on noisy data</sample>
    <sample id="910">In weak supervision, you do not manually label the data. Instead, you label the data using weak labeling sources such as simple heuristics, knowledge bases or low-quality crowdsourcing, as illustrated in the figure on the right.</sample>
    <sample id="911">In Contraste zu menschlichen Annotationen sind dieWeak-Annotationen viel billiger, aber sie sind auch lauter, was bedeutet, dass ein bestimmtes Maß an den Annotationen falsch sind.</sample>
    <sample id="912">Wenn wir neuronale Netze direkt mit schwach überwachten Daten trainieren, neigen sie dazu, den Lärm in den Daten zu memorieren und nicht zu generalisieren.</sample>
    <sample id="913">In weakly supervised learning, training algorithms are proposed to robustly train neural networks on such label noise so that the trained models still generalize well.</sample>
    <sample id="914">In jüngster Zeit haben Arbeiten im Bereich WSL (Weekly Supervised Learning) gezeigt, dass Menschen behaupten, sie only trainieren Modelle auf weeklig label data und dabei eine hohe Leistung auf einem clean Testset erreichen.</sample>
    <sample id="915">Technisch gesehen ist dieser Ansatz nicht falsch, aber es gibt ein Hürdchen.</sample>
    <sample id="916">Das ist, dass Menschen davon ausgehen, dass es einen zusätzlichen sauberen Validierungsset gibt, der für die ModellSelektion verwendet werden kann.</sample>
    <sample id="917">Wir haben uns auf diese Problemstelle festgestellt, da sie impliziert, dass zusätzliche manuelle Annotierungen in weakly-supervised learning erforderlich sind. Aber wie ein Elefant im Raum, wird diese Notwendigkeit oft übersehen.</sample>
    <sample id="918">Die oben genannte Aufgabe besteht darin, drei Forschungsfragen zu formulieren. Zunächst einmal ist es fraglich, ob eine saubere Validierungsdatenbank für WSL notwendig ist, oder ob man sich auf eine Lernstelle mit Lernstelle-Unterstützung (WSL) verwenden kann.</sample>
    <sample id="919">Zweitens, wenn saubere Daten erforderlich sind, oder wenn saubere Daten für den WSL notwendig sind, dann wie viele saubere Proben benötigen wir? Schließlich sollten wir nur die sauberen Proben verwenden, um zu validieren, oder gibt es bessere Wege, sie zu nutzen?</sample>
    <sample id="920">Wir haben in unserem Werk die oben genannten Forschungsfragen adressiert und unsere Erkenntnisse lauten wie folgt:</sample>
    <sample id="921">Zunächst finden wir, dass interessanterweise recente WSL-Methoden tatsächlich klare, weiße Léschen-Samples benötigen, um korrekt zu arbeiten.</sample>
    <sample id="922">Andernfalls gibt es einen großen Leistungsverlust, wie in diesem Diagramm gezeigt. Wenn es keine sauberen Validationsamples gibt, können die trainierten Modelle nicht jenseits der ursprünglichenWeakLabels generieren.</sample>
    <sample id="923">Das Training ist also umsonst.</sample>
    <sample id="924">Dies zeigt, dass WSL-Methoden tatsächlich sauber gekennzeichnetes Daten benötigen, um ordnungsgemäß zu arbeiten und die Kosten für die Gewinnung von sauber validierten Stichproben sollten nicht übersehen werden.</sample>
    <sample id="925">Unser zweiter Fundament ist, dass das Erhöhen der Anzahl von sauberen Validationsstichproben helfen wird, WSL-Abläufe zu erreichen, bessere Leistungen zu erzielen, wie im Bild auf der linken Seite gezeigt.</sample>
    <sample id="926">Typischerweise benötigen wir nur 20 Proben pro Klasse, um eine hohe Leistung zu erzielen.</sample>
    <sample id="927">Aber das ist nicht das Ende der Geschichte, denn wenn wir entweder eine ausreichende Anzahl an sauberer Datensamples beschaffen oder direkt auf ihnen trainieren, können wir besser abschneiden.</sample>
    <sample id="928">Die rechte Figur zeigt die Leistungsverschiedenheit zwischen Finetuning-Methoden, die direkt auf saubere Daten angewendet werden, und WSL-Methoden, die nur saubere Daten für die Validierung verwenden.</sample>
    <sample id="929">Wie wir sehen können, wenn wir 10 Proben pro Klasse haben, beginnt Direkt-Finetuning zu überwältigen WSL-Methoden.</sample>
    <sample id="930">Schließlich kann die durch vorherige WSL-Ansätze geltende Leistungsverbesserung einfach durch die Erlaubnis zu einem weiteren Fine-Tuning auf den sauber validierten Samples erreicht werden.</sample>
    <sample id="931">Wie wir aus den Grafiken sehen können, der VELINA-Modell mit dem FTW ursprünglich unter perfornt mehr komplexere WSL-Methoden wie COSINE.</sample>
    <sample id="932">Allerdings, wenn wir es erlauben, den Fine-Tuning auf den reinen Proben fortzusetzen, dann führt FT-B zu gleicher Leistung wie andere Methoden.</sample>
    <sample id="933">In der Praxis gibt es keinen Grund, komplexere WSL-Methoden zu verwenden, die mehr Rechenzeit und Speicherplatz benötigen.</sample>
    <sample id="934">Zusammenfassend haben wir gezeigt, dass recente WSL-Methoden saubere, manuell annotierte Samples benötigen, um korrekt zu funtionieren. Ihre Leistungsgewinn und Praktizität werden stark überbewertet.</sample>
    <sample id="935">Unsere kompakten Empfehlungen für zukünftige Arbeiten lauten wie folgt:</sample>
    <sample id="936">Erst berichte über die Modellauswahlkriterien. Zum Beispiel, ob die Modellauswahl auf rein validierten Datensamples basiert.</sample>
    <sample id="937">Zweites: WSL-Abläufe sollten mit Few-Shot-Lern-baselines verglichen werden, die arbeiten an klaren Samples. Drittes: Kontinuierliche Finetuning ist ein einfach aber starkes Baseline, das in zukünftigen Arbeiten in WSL berücksichtigt werden sollte.</sample>
    <sample id="938">Endlich haben wir unser Open-Source-Code freigegeben. Sie können es unter dem QR-Code auf dieser Folie finden. Bitte fühlen Sie sich frei, es zu überprüfen. Vielen Dank und einen guten Tag an der Konferenz.</sample>
    <sample id="939">Gängige Bewertungsmethoden für Dialogsysteme sind die Anwendung von menschlicher Evaluation, indem man menslichen Richtern fragt, welche der zwei Konversationen besser ist, oder indem man Konversationen auf einer Likert-Skala bewertet.</sample>
    <sample id="940">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="941">Dass Richter Entscheidungen in Gerichten treffen.</sample>
    <sample id="942">Ja, der Code ist verfügbar und er ist auf GitHub zu finden.</sample>
    <sample id="943">Ja, die Annotatoren sind ausgewogen.</sample>
    <sample id="944">Sie wurden durch die Hinzufügung von Adverbien, durch die Hinzufügung von Adverbien an den Anfang und vorne, durch die Hinzufügung von "regardless of what X thinks about it" und durch die Verwendung von Zitate durcheinandergebracht.</sample>
    <sample id="945">Eine dimensionale Bewertung ist eine Methode, um die Qualität von Dialogen auf einem feineren Granularitätsniveau zu bewerten.</sample>
    <sample id="946">University of Science and Technology of China</sample>
    <sample id="947">Die Form des Prompts ist wichtig in den Fällen von null- und einem Schritt-Prompting.</sample>
    <sample id="978">Die Autoren haben Bots evaluiert.</sample>
    <sample id="979">There are six authors involved in the work.</sample>
    <sample id="980">Ein guter Planer sollte Skripts erstellen, die rational sind und den Bedingungen entsprechend sind.</sample>
    <sample id="981">Sieben.</sample>
    <sample id="982">Vasudha Varadarajan</sample>
    <sample id="983">The authors belong to the Institute of Computer Science at the University of Warsaw.</sample>
    <sample id="1021">Die häufigsten Fehler von PaLM sind Omissionen.</sample>
    <sample id="1022">Hallo, ich bin James Finch und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABC-Eval erzählen, eine neue dimensionale Ansatzweise zur Evaluation von conversationaler KI.</sample>
    <sample id="1023">Diese Arbeit wurde vom Emory NLP Lab, geleitet von Professor Jincho Choi an Emory University, in Zusammenarbeit mit Amazon Alexa AI erstellt.</sample>
    <sample id="1024">Lassen Sie uns angenommen, dass Sie einen Dialogmodellentwickelt haben und Sie sich fragen, wie gut es sich gegenüber dem aktuellen Stand der Kunst vergleicht.</sample>
    <sample id="1025">Die gemeinsame Praxis besteht darin, menschliche Beurteilungen zu verwenden, indem man Menschen anfordert, zwei Konversationen zu selektieren und zu bestimmen, welche besser ist, oder Konversationen nach einem Likert-Skala zu bewerten.</sample>
    <sample id="1026">Diese Ansätze arbeiten gut daran, um eine komholistische Beurteilung der Gesamtqualität des Dialogs zu bieten, aber die Dialogqualität hat viele Aspekte. Daher möchten Sie eventuell mehrere Dimensionen der Chatschwelle bewerten, um die Stärken und Schwächen des Modells auf einem feineren Granularitätsniveau zu verstehen.</sample>
    <sample id="1027">Eine Annäherung besteht darin, einfach menslichen Richtern zu erlauben, mehrere Aspekte der Dialogqualität zu bewerten, indem sie die Bedeutung von Modellantworten einschätzen, indem sie existierende vergleichende oder Likert-Skala-Methoden verwenden.</sample>
    <sample id="1028">Allerdings glauben wir, dass es eine präzisere und zuverlässlichere Strategie für die Dimensionale Dialog-Evaluation gibt.</sample>
    <sample id="1029">Unser Ansatz versucht, die Subjektivität menschlicher Bewertungen zu reduzieren, indem er explizit annotiert, ob jede Modell-Antwort bestimmte Verhaltensweisen ausdrückt, wie zum Beispiel die Bereitstellung von irrelevanter Information oder sich selbst widersprechende Aussagen.</sample>
    <sample id="1030">Wir nennen diese Ansatz Annnotation von Verhaltensweisen in Chats, oder ABC-Eval in Kürze. Wir haben diese Methode entwickelt, um umfassend zu abdecken, welche Verhaltensweisen von Chats Modellen sind, die in jüngerer Literatur als beeinflussend für die Chats-Qualität diskutiert wurden.</sample>
    <sample id="1031">ABC-Eval ist in der Lage, die Geschwindigkeit zu messen, mit der Sprachmodelle verschiedene thematische Fehlentscheidungen machen.</sample>
    <sample id="1032">Beispielsweise misst ABC-Eval die Anzahl der Runden, in denen ein Chatschwelle ignoriert seine Partnerin oder etwas Unrelevantes sagt.</sample>
    <sample id="1033">Widersagt sich oder seinem Partner, behauptet falsche Fakten oderVioliert das allgemein anerkannte Wissen und zeigt beim Erfolg oder Scheitern nicht Empathie.</sample>
    <sample id="1034">Um zu bestimmen, welche Art von Evaluation am besten wirkt, haben wir vier modernste Chattenmodel ausgewählt und sie an 100 menschlich-basierten Konversationen pro Modell mit ABC-Eval bewertet.</sample>
    <sample id="1035">Für Vergleiche evaluieren wir auch diese Konversationen mit drei bestehenden Methoden: Likert-Unterwerte auf der Niveau-Ebene, Likert-Unterwerte auf der Dialog-Ebene und Dialog-Ebene Parewiser Comparisons.</sample>
    <sample id="1036">Für jedes der existierenden Verfahren haben wir Auswertungen auf acht von den am häufigsten gemessenen Aspekten des Dialogs gesammelt, da dies die Standardpraxis zur Evaluation von Chatsmodellen an mehreren Dimensionen ist.</sample>
    <sample id="1037">Aus our analyses of these evaluation results wir haben festgestellt, dass ABC-Eval-Behavior-Labels im Allgemeinen zuverlässiger sind als Labels, die von bestehenden Methoden gesammelt wurden, wie durch Interannotator-Übereinstimmung auf 100 doppelt bewerteten Konversationen misst.</sample>
    <sample id="1038">Darüber hinaus sind ABC-Eval-Labels besser vorhersagend für die allgemeine Konversationsqualität im Vergleich zu Metrischen, die von bestehenden Methoden erstellt werden, wie durch diese einfache lineare Regressionselektionsanalyse gezeigt wird.</sample>
    <sample id="1039">Beispielsweise können Sie sehen, wie die Messung der Proportion von Worten mit Selbst- und Partnerkontraindexionen 5% und 10% des Konversationsqualitäts respektiv erfüllt, während die durchschnittlichen Likert-Konsistenzscores nur 4% oder weniger erklären.</sample>
    <sample id="1040">Schließlich haben wir überprüft, ob jede Evaluiermetrik ein eindeutiges Aspekt von Chatschwelle abdeckt, indem wir einen schrittweise linearen Regressionen benutzt.</sample>
    <sample id="1041">Sie können sehen, wie die Kombination aller ABC-Eval-Metriken über 25% der Konversationqualität erklärt. Und wenn Sie die Metrische nacheinander entfernen, resultieren die meisten davon in einem Verlust an Informationen über die Qualität.</sample>
    <sample id="1042">Auf der anderen Seite explains die Kombination aller Turn-Level Likert-Metrischen viel weniger Qualität und fewer davon tragen einzigartige Informationen.</sample>
    <sample id="1043">Diese zuverlässigen, informativen und eindeutigen ABC-Eval-Metrische ermöglichen uns, Konversationskünstliche Intelligenz mit einer höheren Auflösung zu bewerten als die vorherigen Methoden, die dies erreichen können.</sample>
    <sample id="1044">Sie können sehen, dass in den Ergebnissen unseres Experiments mehrere Herausforderungen bestehen und exakt quantifiziert wurden. Zum Beispiel haben die Bots, die wir getestet haben, in etwa 20 % ihrer Antworten Verletzungen an der allgemeinen Menschenkenntnis.</sample>
    <sample id="1045">Sie produzieren irrelevantes Information in etwa 15% der Antworten und kontradieren sich oder ihren Partner um etwa 10% deshalb.</sample>
    <sample id="1046">Mit der beschleunigten Verbesserung in diesem Bereich können viele dieser Fehlerraten bei neuen Modellen, die seit unserem Evaluationsprotokoll freigegeben wurden, abnehmen. Dennoch ist das noch mehr Grund zu verfolgen, zuverlässliche und präzise Evaluiermetrischen für die Vergleich von Modellen zu verfolgen.</sample>
    <sample id="1047">Wir hoffen, ABC-Eval kann von anderen im Feld als ein wichtiger Schritt in dieser Richtung genutzt werden und wir freuen uns darauf, wie conversationaler AI im kommenden Monaten und Jahren fortschritt. Vielen Dank für das Watching.</sample>
    <sample id="1048">Die Autoren gehören an der Emory University.</sample>
    <sample id="1049">CFT steht für "Continuous Fine-Tuning".</sample>
    <sample id="1050">Sechs Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="1051">Hallo, mein Name ist Kayo Yin und ich werde unsere Arbeit präsentieren, die "Wann benötigt Übersetzung Kontext?" eine datengetriebene multilinguale Exploration nennt. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandez, Emmy Liu, Andre F.T. Martins und Graham Neubig erstellt.</sample>
    <sample id="1052">So eine Menge Übersetzungen hängen von Kontext ab. Zum Beispiel, wie würden wir "mole" in dieser Satz übersetzen?</sample>
    <sample id="1053">Wenn die vorherige Aussage "Dinge könnten gefährlich werden, wenn die Minister davon erfahren" war, dann bezieht sich Mole auf einen Feind. Wenn die vorherige Aussage "Könnte es etwas Ernstes sein, Arzt?" war, dann bezieht sich Mole auf eine Mutterschwelle.</sample>
    <sample id="1054">So depending on context, the meaning of the word changes and therefore its translation changes as well.</sample>
    <sample id="1055">Allerdings ist die Auswertung, wie gut Modelle solche Fälle übermitteln können, sehr schwierig. Zum einen because only a small portion of translations depend on context, which makes corpus-level metrics like BLEU unable to capture these translations.</sample>
    <sample id="1056">Einige Leute haben vorgeschlagen, eine spezielle Beurteilung von Kontextabhängigen Übersetzungen vorzunehmen. Aber diese Ressourcen unterstützen nur begrenzte Arten von Kontextabhängigen Übersetzungen und begrenzte Sprachen, da sie normalerweise auf Domänenwissen und menschliche Besorgnis zurückgreifen.</sample>
    <sample id="1057">In diesem Werk versuchen wir, diese zwei Fragen zu beantworten: Zunächst, wann erfordert eine Übersetzung Kontext und zweitens, wie gut können Modelle solche Fälle bewältigen?</sample>
    <sample id="1058">Um die erste Frage zu beantworten, haben wir begonnen, wie viel von einem Wort abhängt, wenn es zu einer Übersetzung kommt.</sample>
    <sample id="1059">In der vorherigen Arbeit haben wirConditional Cross-Mutual Information (CXMI) als Maß für Kontextnutzung von Maschinentranslation-Modellen eingroduced. Und das ist durch Messung von, wie viel Informationen die Kontext C über den Ziel Y gibt, gegeben ist, die Quelle X.</sample>
    <sample id="1060">Sie könnenConditional Cross-Mutual Information (CXMI) den Informationsgewinn von geben, indem Kontext an das Modell übermittelt wird.</sample>
    <sample id="1061">In diesem Werk extendieren wir CXMI zu Pointwise CXMI, die die Kontextnutzung an der Satzstelle oder an der Wortstelle messen kann. Wir können Wörter denken, die ein hohes P-CXMI aufweisen, als solche, die Kontext für die Übersetzung benötigen.</sample>
    <sample id="1062">Jetzt analysieren wir Wörter mit hohen P6SMI, um Muster zwischen diesen Wörtern zu finden.</sample>
    <sample id="1063">Wir haben unsere Analyse auf Transkripte von TED Talks vornehmen lassen, die von Englisch ins Deutsche und in 14 weitere Sprachen übersetzt wurden.</sample>
    <sample id="1064">Wir führen unsere Analyse an drei verschiedenen Ebenen durch. Zunächst schauen wir uns Parteien von Sprachtegenen an, die eine hohe P-CXMI-Menge aufweisen.</sample>
    <sample id="1065">Dies erlaubt uns, beispielsweise Duo-Pronomina in Arabisch zu finden, die über ein hohen P-CXMI verfügen. Dies kann aufgrund der Tatsache, dass Englisch Duo-Pronomina nicht hat, erklärt werden. Man benötigt Kontext, um zu bestimmen, ob ein Pronomen Duo ist, wenn es in Arabisch übersetzt wird.</sample>
    <sample id="1066">Gleichermaßen finden wir, dass bestimmte Sprachen auch Kontext benötigen, um die richtige Form des Verbs zu wählen. Wir haben uns also auf Vokabularien konzentriert, die einen hohen P-CXMI-Quoten über alle ihre verschiedenen Auftretungen haben.</sample>
    <sample id="1067">Und das hilft mir, Fälle wie den hier zu identifizieren, wo in chinesischen Sprachen Kontext notwendig ist, um richtige Nomen zu übersetzen, um sicherzugehen, dass man die gleiche Übersetzung innerhalb des Dokuments verwendet.</sample>
    <sample id="1068">Wir finden, dass Kontext dazu beiträgt, die richtige Formalität zu translatieren.</sample>
    <sample id="1069">Schließlich betrachten wir verschiedene Individuen, die P-CXMI hohen Token haben. Dies ermöglicht uns, Phänomene zu identifizieren, die nicht nur durch das Wort selbst, sondern auch durch die Struktur des Satzes, wie z.B. Elipsen oder Auflösungen, abgedeckt werden können.</sample>
    <sample id="1070">Jetzt verwenden wir die Ergebnisse aus unserer Analyse, um einen Benchmark für Dokumentübersetzung zu entwerfen.</sample>
    <sample id="1071">Für jedes der fünf diskursive Phänomene, die wir identifiziert haben, erstellen wir Hashtags, um automatisch Wörter zu identifizieren, die sich mit dem Phänomen befassen. Wir nennen unser Hashtag das Multilingual-Diskurs-Aware- (MuDA-) Hashtag.</sample>
    <sample id="1072">Wir können dann auch noch bemerken, dass verschiedene Sprachen unterschiedliche Proportionen dieser diskursiven Phänomene aufweisen.</sample>
    <sample id="1073">Wir verwenden dann den MuDA-Tagger, indem wir den Tagger auf die parallel korrekte Texte anwenden, die wir verwenden möchten, um sie zu evaluieren. Und wir wenden unsere übersichtlichen Metriken auf die kulturabhängigen Beispiele an, die der MuDA-Tagger identifiziert hat.</sample>
    <sample id="1074">Schließlich verwenden wir unser Benchmark und andere Metriken, um verschiedene Modelle auf Dokumentebene in der machine-translation zu bewerten.</sample>
    <sample id="1075">Zunächst einmal, wenn wir Korpusbasierte Metriken verwenden, so finden wir, dass kognitiv orientierte Modelle die beste Performance aufweisen.</sample>
    <sample id="1076">Aber wenn wir COMET verwenden, performieren Kontext-aware Modelle am besten. Und wenn wir Word F-Measure verwenden, haben Modelle mit und ohne Kontext vergleichbare Leistungen.</sample>
    <sample id="1077">Dies zeigt erneut, dass es schwierig ist zu bestimmen, welches Dokumentebene-Übersetzungssystem am besten ist, wenn wir nur Korpusniveau-Metriken verwenden.</sample>
    <sample id="1078">Wir verwenden die MUMA-Benchmarks, um Modelle zu evaluieren, und finden, dass Kontextverarbeitungsmodelle signifikant präziser sind als Modelle, die keinen Kontext für bestimmte diskursive Phänomene wie Formalität und lexikalische Kohärenz verwenden.</sample>
    <sample id="1079">Diese Modelle sind nicht viel besser als Modelle, die kein Kontext verwenden, auf anderen Phänomenen wie Ellipsen, Pronomen und Verbformen. Das suggestiert, dass wir bei der Dokumentenlevelübersetzung noch mehr Fortschritte machen müssen.</sample>
    <sample id="1080">Wir vergleichen auch verschiedene kommerzielle Systeme, und unsere Benchmarks zeigen, dass DeepL normalerweise für Dokumentübersetzung mehr präzise ist als Google Translate.</sample>
    <sample id="1081">Um zu summariieren, wir haben eine datengetriebene Analyse über 14 Sprachpaare durchgefohren, um festzustellen, wann Übersetzungen Kontext benötigen.</sample>
    <sample id="1082">Dann verwenden wir unsere Erkenntnisse, um einen Benchmark für document-level-Machine-Translation (MT) zu erstellen. Dies kann uns dabei helfen, zu identifizieren, welche diskursive Phänomene Modelle gut bewältigen und welche Übersetzungssysteme gut auf document-level übersetzen.</sample>
    <sample id="1083">Vielen Dank für Ihre Aufmerksamkeit. Bis bald in Torodolo.</sample>
    <sample id="1084">Yusen Zhang</sample>
    <sample id="1121">The new method has a name.</sample>
    <sample id="1122">Die Methode der "markierten Wörter" ist eine Methode, um die Wörter zu identifizieren, die markierte Gruppen von nicht markierten Gruppen unterscheiden.</sample>
    <sample id="1123">University of Washington</sample>
    <sample id="1124">Prague</sample>
    <sample id="1125">Sarah Finch</sample>
    <sample id="1126">Vier</sample>
    <sample id="1127">BLMP, SyntaxGym und CrowS.</sample>
    <sample id="1161">FT, TW, BOND, COSINE, MLC, L2R</sample>
    <sample id="1162">Das Modell wird an 11 biomedizinischen und klinischen downstream Aufgaben evaluiert.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich auf den 4GB-Untersatz von NACOS trainiert.</sample>
    <sample id="1227">Adam Przepiórkowski</sample>
    <sample id="1228">Die Versuche zur Erneuerung oder Fortsetzung der vorherigen Modelle mit jüngerem Datensatz haben zu der Schlussfolgerung geführt, dass die Leistungsgrade mit einer größeren zeitlichen Verzögerung abnehmen.</sample>
    <sample id="1269">Es ist notwendig, die Token für die Ausgabesequenz zu permutieren, um sie in die richtige Reihenfolge zu bringen.</sample>
    <sample id="1270">Die Autoren empfehlen, dass Modellentwickler*innen ihre Methoden zum Abbau von Vorurteilen transparent machen sollten, um zu klären, ob positive Stereotypien aufgrund von übertriebenen Werteallfällen oder anti-stereotypischen Ansätzen entstehen.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind grammatikalfehlerhafte Sätze.</sample>
    <sample id="1272">Die Autoren haben die Metriken BLEU, METEOR, CIDEr und ROUGE verwendet.</sample>
    <sample id="1273">Inner-annotator agreement</sample>
    <sample id="1274">Wikipedia</sample>
    <sample id="1275">Heinrich Heine University Düsseldorf, Germany</sample>
    <sample id="1276">MultiInstruct ist ein multi-modales Datensatz, der eine Vielzahl von Anwendungsfällen abdeckt.</sample>
    <sample id="1277">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="1278">Die binäre Koordination wird definiert als die Hälfte der Differenz der Längen der kürzeren und der längeren Konjunktive.</sample>
    <sample id="1279">Die in dieser Studie verwendeten Prompts lagen im Durchschnitt bei 16,5 Wörtern.</sample>
    <sample id="1280">Die Auswirkungen auf das kleinere T5-Modell sind, dass es eine höhere Genauigkeit als die meisten großen Sprachmodelle aufweist.</sample>
    <sample id="1281">Hallo, ich bin Yanis Laboulaye und ich werde Ihnen unsere Arbeiten über Dr. BERT präsentieren, ein robustes prätrainiertes Modell in Französisch für biomedizinische und klinische Domänen.</sample>
    <sample id="1282">In dieser Präsentation diskutieren wir zuerst über Sprachmodellierung im Gesundheitswesen. Danach präsentieren wir die Hauptbeiträge unseres Artikels.</sample>
    <sample id="1283">Wir präsentieren den ersten biomedizinischen Modell in Französisch, Dr. Bert, das auf RoBERTa basiert und trainiert wurde an NACHOS, einer Datensammlung medizinischer Crowded-Daten aus dem Web.</sample>
    <sample id="1284">Wir haben auch eine Comparaison von Modellen mit mehreren Pretraining-Einstellungen und Datensätzen vorgestellt. Dann präsentieren wir unsere Resultate auf 11 biomedizinischen und klinischen downstream-Task in Französisch.</sample>
    <sample id="1285">Schließlich conclude about the experiments and give you more details about how to access to the models.</sample>
    <sample id="1286">Seit seiner Einführung im Jahr 2018 ist BERT zu einem der effektivsten Ansätze geworden, um natürliche Sprachverarbeitungs Aufgaben zu lösen und einen großen Leistungsverlust im Vergleich zu historischen statischen und konzektionären Methoden wie Word2Vec, FastText und WordPiece zu erzielen.</sample>
    <sample id="1287">Seit damals wurde diese Methode an viele andere Sprachen angepasst, wie zum Beispiel auf Französisch mit Camembert und auf dem biomedizinischen Bereich mit PubMedBERT und BioBERT und auf klinischem Bereich mit ClinicalBERT, aber hauptsächlich in Englisch.</sample>
    <sample id="1288">Spezialisierte Modelle für andere Sprachen sind seltener und oft basieren auf kontinuierlicher Pretraining, aufgrund der Mangel an in domänen spezifischem Datensatz.</sample>
    <sample id="1289">Allerdings gab es bislang keine offene Quellen-Modell für Biomedizin in Französisch.</sample>
    <sample id="1290">Wir fragten uns daher, welche Datensammlungen am besten für eine Vielzahl von Anwendungsfällen geeignet sind und ob diese Publizierbare Datensammlungen als Ersatz für klinische Datensammlungen verwendet werden können.</sample>
    <sample id="1291">Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Chabert-Modell, das auf anonymisierten Daten basiert, die aus dem Nanterre Krankenhauses abgeleitet wurden.</sample>
    <sample id="1292">Nach der Evaluation der Auswirkungen von öffentlichen und privaten medizinischen Datensätzen auf vergleichbare Datengröße, fragten wir uns, wie viel Daten wir benötigen, um einen spezialisierten Modell auf Französisch zu trainieren. Ist es 4 GB, 8 GB oder mehr?</sample>
    <sample id="1293">Um diese Frage zu beantworten, müssen wir zwei Versionen von BERT-Modellen trainieren und vergleichen: eine ursprüngliche Version von BERT mit 7 GB NACHOS und eine 2-GB-Teilmenge von NACHOS.</sample>
    <sample id="1294">Eine erstmalige Version von Schubert, die ein klinischer Modell ist, basiert auf 4 GB Sätzen aus klinischen Notizen. Eine finale Version von Schubert verwendet eine Mischung von 4 GB subset von NACHOS und 4 GB aus klinischen Notizen.</sample>
    <sample id="1295">In addition to this comparison, we introduce three models trained on continual pre-training to analyze the impact of pre-training strategies.</sample>
    <sample id="1296">Eine basiert auf dem Gewicht von Camembert und trainiert auf einem 4 GB Teillager von NACHOS. Die andere basiert auch auf Camembert, aber trainiert in diesem Fall auf einem 4 GB Teillager von ClincNLP.</sample>
    <sample id="1297">Eine weitere Methode basiert auf einem englischen biomedizinischen Modell namens BERT und trainiert auf einem 4 GB subset von NACHOS. Insgesamt erhalten wir insgesamt sieben Modelle.</sample>
    <sample id="1298">Um unsere 7 Modelle zu evaluieren, verwenden wir diverse öffentliche und private Datensätze, wie zum Beispiel Nomen- und Adjektiverkennung, Klassifizierung, Part-of-Speech-Tagging und Question Answering.</sample>
    <sample id="1299">Diese Modelle werden mit sechs Baselin-Modellen verglichen, die Kameraberc Oscar 108 GB, Kameraberc Oscar 4 GB, Kameraberc CUNet 4 GB, DeBERT, MyBERT und ClinicalBERT sind.</sample>
    <sample id="1300">Die Evaluation zeigt, dass das Modell am besten auf die Aufgabe performt, bei der es mit Daten vom gleichen Typ arbeitet, wie es es beim Training verwendet hat.</sample>
    <sample id="1301">Allerdings können wir die Daten aus etablierten Quellen erhalten. Wir können auch beobachten, dass die Daten aus etablierten Quellen zu einem besseren Leistungslevel führen.</sample>
    <sample id="1302">Insgesamt scheint die von-scratch-Training zu erhalten höhere Leistungen auf den meisten Aufgaben.</sample>
    <sample id="1303">Allerdings zeigt unsere Evaluierung von Kontinuumstrainen, die die Weight- und Tokenizer-Initialisierungen von CamemBERT verwenden, die auf einem 4GB-Untersatz von NACOS trainieren, ähnliche Resultate wie diejenigen, die mit DoctorBERT 4GB von Grund aus trainiert wurden.</sample>
    <sample id="1304">Es ist nicht der Fall für die Modelle basierend auf Camembert-Weights und Tokenizer, die Stabilitätsprobleme erleben.</sample>
    <sample id="1305">Schließlich schließen wir, dass unser vorgeschlagener System eine bessere Leistung auf neun von den elf DREEM-Task erzielt und global über die Resultate des generischen Modells Camembert übertrifft.</sample>
    <sample id="1306">Wir bemerkten auch, dass spezialisierte Daten besser sind. Spezialisierte Daten sind besser, aber sie skalieren nicht gut.</sample>
    <sample id="1307">Alle vorher trainierten Modelle, die von NACHOS stammen, sind frei verfügbar und auf GitHub und auf unserem GitHub-Repository.</sample>
    <sample id="1308">So, danke für die Präsentation und wir freuen uns auf den Austausch bei der Poster-Session in Toronto.</sample>
    <sample id="1309">Die Arbeit untersucht die Auswirkungen verschiedener Vorgehensweisen auf die vorherige Ausbildung.</sample>
    <sample id="1310">Der Faktor der Überanpassung, der auf die Wiederverwendung von Tests zurückzuführen ist, beträgt 1.05.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde mittels Evaluationsmetriken beurteilt.</sample>
    <sample id="1312">Ja, Sprachmodelle haben unterschiedliche politische Vorurteile.</sample>
    <sample id="1313">Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen einen kurzen Einführung in unser Papier über kompositionale Generalisierung ohne Bäume mit Multi-Set Tagging und latenten Permutationen geben.</sample>
    <sample id="1314">Dies ist ein gemeinsames Werk mit meinen Betreuern Alexander Koller und Ivan Titov.</sample>
    <sample id="1315">Kompositionaler Allgemeinwert kann als Fähigkeit eines Lerners verstanden werden, um tieferen Rekursion und unbekannte Kompositionen von Phrasen zu bewältigen, die während des Training individuell gesehen wurden.</sample>
    <sample id="1316">Im Kontext des semantischen Parsings sieht die Testung für kompositionale Generalisierbarkeit so aus. Wie üblich haben wir einen Trainingsdatensatz von Aussagen, in diesem Fall: "Die Mädchen schliep" und "Mary kannte, dass die Mädchen schliep".</sample>
    <sample id="1317">Diese Ausdrücke werden mit logischen Formen begleitet, die den Hauptaspekten ihres Bedeutung entwirren.</sample>
    <sample id="1318">Im Gegensatz zu Standard-Maschinelles-Lern-Evaluation, die die Testdaten nicht aus derselben Verteilung stammt, enthält die Testdaten strukturell unbekannte logische Formen.</sample>
    <sample id="1319">In diesem Beispiel hat das Modell Shallow Recursion während des Trainings gesehen und wird auf ein Beispiel mit tiefem Rekursionstestiert.</sample>
    <sample id="1320">Naive sequenz-to-sequence-Modelle kämpfen mit diesem Art von Out-of-Distribution-Generalisierung und produzieren oft Ausgaben, die vom Input abgetrennt sind.</sample>
    <sample id="1321">In bestimmten Fällen scheitern sie darin, die systematischen Korrespondenzen zwischen Eingabe und Ausgabe zu reproduzieren, wie jene, die in dem Beispiel farbcodeiert sind.</sample>
    <sample id="1322">A popular method to address this is to integrate trees into the models.</sample>
    <sample id="1323">Die Bäume sind dazu gedacht, den kompositionellen Prozess zu capturieren, der Ereignisse mit logischen Formen verbindet.</sample>
    <sample id="1324">Dies funktioniert gut, aber Bäume werden normalerweise nicht gegeben und müssen auf eine Art und Weise erhalten werden.</sample>
    <sample id="1325">Dies kann komplex und manchmal eine computergestützte Prozessphase erfordern. Typischerweise beinhaltet dies eine betrachtliche formalistische Voreinzelung der logischen Formen, zum Beispiel um die Variablen Symbole zu handhaben.</sample>
    <sample id="1326">Trees may also involve specialized grammar-induction procedures.</sample>
    <sample id="1327">In diesem Papier verwenden wir keine Bäume und führen einen neuronalen sequenz-to-sequenz-Modell ein, das direkt die Korrespondenzen zwischen Fragmente des Eingabes und Fragmente des Ausgangs modelliert.</sample>
    <sample id="1328">For the first time, wir zeigen eine starke Generalisierung zu tieferem Rekursionsschneiden, ohne sich auf Bäume zu stützen.</sample>
    <sample id="1329">Unser Ansatz prognostiziert den Output aus dem Input in zwei Schritten.</sample>
    <sample id="1330">Zunächst taggen wir jede Eingabe-Token mit einem unsortierten Multi-Satz von Token, die im Ausgang auftreten werden.</sample>
    <sample id="1331">Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht ordnungsgemäß sortiert.</sample>
    <sample id="1332">Das ist der Grund, warum wir im zweiten Schritt einen anderen Modell zu verwenden, um eine Permutation zu vorhersehen, um sie in die richtige Reihenfolge zu bringen.</sample>
    <sample id="1333">Wir Introduzieren ein neues Verfahren, um eine Permutation zuvorhersagen, die keinerlei harten Beschränkungen auf die möglichen Permutationen unterliegt. Dies macht unser Ansatz sehr flexibel und ausdrucksstark.</sample>
    <sample id="1334">Konzeptionell arbeitet unser Permutationsmodell so, wie es in der Abbildung dargestellt ist. Es beginnt mit einem Satz, der in einem bestimmten Format codiert ist. In diesem Fall handelt es sich um den Satz "the girl slept". Das Modell then versucht, die Reihenfolge der Wörter im Satz zu ändern, um neue Bedeutungen zu entdecken. Es tut dies, indem es die Wörter in verschiedenen Arrangements kombiniert und dann überprüft, ob das neue Format einen Sinn ergibt. Wenn ja, dann wird das neue Arrangement als "korrekt" akzeptiert und als eine neue Variante des ursprünglichen Satzes angesehen. Das Modell wiederholt diesen Prozess für alle möglichen Kombinationen der Wörter im Satz, um so viele neue Bedeutungen wie möglich zu finden.</sample>
    <sample id="1335">Wir gehen von links nach rechts über die Ausgabe und bestimmen, welchen Multi-Menü-TOKEN wir in jede Position auswählen. Für die erste Ausgabeposition auswählen wir einfach einen, wie in Rot hervorgehoben.</sample>
    <sample id="1336">Dann springen wir zu dem nächsten Multi-Set-Token, um den nächsten Token im Eingabe-Text zu bestimmen.</sample>
    <sample id="1337">Wir bestimmen den dritten Token im Ausgabe in einem ähnlichen Weise, indem wir zu einer anderen Multi-Set-Tokenecke springen. Wir fortfahren diesem Prozess.</sample>
    <sample id="1338">Bis zu jenem Punkt, an dem jeder Token aus der ersten Phase exakt ein Mal besucht wurde.</sample>
    <sample id="1339">Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, hier vergleichen wir unser Modell mit anderen Treeless-Modellen auf dem COGS-Benchmarke. Unser Modell überlebt die anderen um einen großen Bereich bei der Generalisierung zu tieferem Rekursion.</sample>
    <sample id="1340">Einige andere Arten der strukturellen Generalisierung erwiesen sich als sehr herausfordernd.</sample>
    <sample id="1341">In unserem Papier lösen wir eine Reihe von interessanten technischen Herausforderungen.</sample>
    <sample id="1342">Erstens ist die Ausrichtung zwischen Eingabe und Ausgabe nicht in den Trainingsdaten gegeben. Als Folge davon kennen wir für einen bestimmten Token nicht, welches Multi-Set es stammt von, was eine Herausforderung für die Trainingsschritte darstellt.</sample>
    <sample id="1343">In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is latent. We address this by inducing the alignment as part of the training.</sample>
    <sample id="1344">Unser Permutationsmethoden ist sehr flexibel, aber sie bringt die Herausforderung mit sich, dass die finden des höchsten Punktscores Permutation NP-schwer ist. Das liegt daran, dass dies mit dem Reiseführerproblem verbunden ist.</sample>
    <sample id="1345">Wir approximieren dies mit einer GP-friendly stetigen Relaxation, die uns auch erlaubt, durch die Lösung zu propagieren und linguistisch plausible Permutationen zu lernen.</sample>
    <sample id="1346">Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen bewältigen möchten, sollten Sie gerne unser Papier ansehen oder zu unserem Poster kommen.</sample>
    <sample id="1347">Kognitive Dissonanz ist die Inconsistenz zwischen zwei Gedanken, Handeln oder Glaubenswerten.</sample>
    <sample id="1348">GPT-4</sample>
    <sample id="1349">Ja, es ist besser.</sample>
    <sample id="1350">Sara Papi</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen aus Transkripten von TED Talks, die von Englisch in 14 verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="1385">Matthias Lindemann</sample>
    <sample id="1386">Sprachübergreifender Transfer ist die Übergabe von Modellen von einem Sprachmodell zu einem anderen.</sample>
    <sample id="1387">Die Autoren gehören an der Saarland University, Amazon Alexa und der University of Vienna.</sample>
    <sample id="1388">Die Autoren verwenden die durchschnittliche Latenzmessung und die durchschnittliche Latenzmessung, die die Rechenzeit des Modells berücksichtigt.</sample>
    <sample id="1389">Hallo alle, ich bin Manjata und heute sind mein Kollege Martin und ich zu unserem Werk "The KITMUS Test" gekommen. Das Evaluieren der Kenntnisintegration aus mehreren Quellen. Dieses Werk ist eine Zusammenarbeit zwischen McGill University, Mila und Microsoft Research.</sample>
    <sample id="1390">Natürlich versteht das Modell auch die verschiedenen Kenntnisquellen, wie zum Beispiel Kenntnisse, die in ihren Parametern enthalten sind, normalerweise durch eine vorherige Ausbildung erworben, und Kenntnisse, die in den Eingaben zu der Laufzeit übermittelt werden.</sample>
    <sample id="1391">Neuere Arbeiten in Aufgaben wie der Beantwortung von Fragen zeigen, dass Modelle prätrainingstimes Wissen verwenden können, um die Aufgabe zu lösen.</sample>
    <sample id="1392">Natürlich ist die Verarbeitung natürlicher Sprache oft von Kenntnissen abhängig, die auch zur Laufzeit bereitgestellt werden.</sample>
    <sample id="1393">Beispielsweise im Satz John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1394">Vortrainingsparameter können Informationen über, was Präsidenten tun und was ein Fernseher ist, enthalten. Aber sie können nicht zuverlässig wissen, wer der bestimmte Individuum John ist oder wer der neue Präsident ist, weil der Präsident seit dem Vortraining verändert werden könnte.</sample>
    <sample id="1395">Daher benötigen erfolgreiche Modelle für knowledge-intensive NLU-Aufgaben die Fähigkeit, sowohl vorher trainiertes als auch während der Inferenzzeit Wissen zu integrieren und zu verwenden.</sample>
    <sample id="1396">In diesem Werk schaffen wir einen diagnostischen Test für die Kenntnisintegration.</sample>
    <sample id="1397">Wir Introduzieren eine Aufgabensammlung zur Auflösung von Coreference, die darauf abzielt, die Fähigkeit zu beweisen, auf Kenntnisse in verschiedenen Quellen zurückzukehren. Wir evaluieren die Datensammlung mit Human-Studie-Partizipanten und etablierten Coreference-Auflösungsmodellen.</sample>
    <sample id="1398">Servin ist ein Richter. Kea ist ein Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, in dem er Fälle entschieden hat, war er froh, sich zu entspannen.</sample>
    <sample id="1399">Das Hauptauftrag hier ist, die richtige Identität zu identifizieren, die der Pronomen "he" bezieht, in diesem Fall Servin.</sample>
    <sample id="1400">Die Auflösung eines gegebenen Pronoms erfordert zwei Arten von Informationen: zuerst spezifische Kenntnisse über ein bestimmtes Objekt, wie z.B. Servin ist ein Richter, und second背景知识，比如 Richter entscheiden Fälle in Gerichten.</sample>
    <sample id="1401">Allgemein wird das Hintergrundwissen während der Vervielfältigung großer Sprachmodelle gelernt, während spezifisches Wissen normalerweise zu Inference-Zeit beobachtet wird.</sample>
    <sample id="1402">Wir variieren die Verfügbarkeit dieser zwei Arten von Informationen so, dass sie entweder in einem einzigen Quelle oder in mehreren Quellen gefunden werden können.</sample>
    <sample id="1403">Wir haben definiert drei Varianten von KITMUS. Zunächst die "Background-Pretrain"-Variante, bei der das Hintergrundwissen an der Pretrainingzeit angenommen wird.</sample>
    <sample id="1404">Zweitens gibt es die "Background-Both" -Variante, bei der das Hintergrundwissen sowohl vor der Trainingszeit als auch während der Inferenzzeitavailable ist. Schließlich gibt es die "Background-Inference" -Variante, bei der das Wissen nur während der Inferenzzeitavailable ist.</sample>
    <sample id="1405">Diese letzte Variante ist insbesondere interessant, da sie die Situation simuliert, dass das Hintergrundwissen, das notwendig ist, um eine Aufgabe zu lösen, nicht part of der vortrainierten Datensammlung von Modellen ist. Zum Beispiel, weil neue Berufstätigkeiten seit dem Zeitraum der Vorausbildung entstanden sind.</sample>
    <sample id="1406">Hier ist ein Beispiel, wie wir die Verfügbarkeit von Effekten in zwei Quellen kontrollieren können.</sample>
    <sample id="1407">Im "Background-Pretrain" Setting nehmen wir an, dass das Hintergrundwissen "Politiker suchen Wahlstelle in der Regierung" in den vorher trainierten Parametern enthalten ist. In einem "Inference"-Kontext geben wir das antwortspezifische Wissen "Chichester ist ein Politiker" an.</sample>
    <sample id="1408">In der "Background-Both" Einstellung bauen wir nicht nur allgemeine Kenntnisse über Politiker auf, sondern auch spezifische Kenntnisse über Politiker im Kontext der Einflussnahme.</sample>
    <sample id="1409">In der "Background-Inference" -Variante wird die effektive Berufstätigkeit "Mehrter" anstelle von "Politiker" verwendet, weil "Mehrter" unwahrscheinlich zu einem vorhergängigen Paradigma gehörte.</sample>
    <sample id="1410">Wir evaluieren die Datensatz sowohl mit menschlichen Studiengruppen als auch mit standardisierten Evaluierungsmodellen. In diesem Bild zeigen wir die Ergebnisse von den bestenPerformenden Modellen auf der schwierigsten Variante des Background-Pretraining-Setups.</sample>
    <sample id="1411">Ohne spezifische Ausbildung an KIMMO, beide Modelle performieren nicht gut. Wenn trainiert in KIMMO, aber, beide C2F und BERT4Coref performieren signifikant besser als die zufällige Wahl.</sample>
    <sample id="1412">Dies zeigt, dass wenn Modelle auf allgemeiner Klassifizierungsalgorithmus-Datasets trainiert werden, sie lernen zu nutzen, surfacere Zeichen, die beim Testen auf KidMoose nicht nützlich sind, da solche Zeichen entfernt wurden.</sample>
    <sample id="1413">Weitere Experimente mit fiktiver Kenntnis haben gezeigt, dass selbst die besten performing Modelle nicht zuverlässig背景知识整合, nur zu Inferenz-Zeit.</sample>
    <sample id="1414">Zusammenfassen der Hauptpunkte unseres Beitrags: Viele Referenz-Resolution-Modeln scheinen in der Lage, Wissen aus verschiedenen Quellen zu überprüfen, ohne spezifische Ausbildung. Allerdings gelingt es ein paar Modellen mit spezifischer Ausbildung, Wissen von mehreren Quellen zu integrieren.</sample>
    <sample id="1415">Trotzdem scheinen selbst die besten Performing-Modelle Schwierigkeiten zu haben, reliabelen Hintergrundwissen zu integrieren, das nur während der Inferenzzeit präsentiert wird. Wenn Sie mehr Details wissen möchten, bitte our Paper und überprüfen Sie den Datensatz und Code auf GitHub. Vielen Dank für das Hören.</sample>
    <sample id="1416">Trees are usually not given and need to be obtained somehow.</sample>
    <sample id="1417">Die Autoren gehören an der Georgia Institute of Technology.</sample>
    <sample id="1418">Hallo, ich bin Myra und heute werden wir über unser Papier "Marked Personas" sprechen. Es handelt sich um die Nutzung natürlicher Sprachanregungen, um Stereotypen in Sprachmodellen zu messen. Dieses Werk wurde in Zusammenarbeit mit Esin Durmus und Dan Jurafsky erstellt.</sample>
    <sample id="1419">In den letzten Jahren hat man oft festgestellt, dass soziale Biase und Stereotype in großen Sprachmodellen (LLMs) vorliegen.</sample>
    <sample id="1420">Allerdings haben diese Maßnahmen diverse Einschränkungen. Sie usually (normalerweise) reliieren (reliieren) auf hand-konstruierte (hand-konstruierte) Datensätze, die sehr zeitaufwendig zu curieren (zu curieren) sind.</sample>
    <sample id="1421">Sie messen normalerweise nur sehr spezifische Stereotypen an, was bedeutet, dass sie nicht gut allgemein zu anderen Demographen oder Kontexten übertragen werden, oder sie capturieren einfach allgemeine, breite Assoziationen, wie negative Assoziationen mit bestimmten Gruppen.</sample>
    <sample id="1422">Darum ist die meisten Arbeiten in diesem Bereich nicht für die Intersektionalität einstelle, was die These ist, dass mehrdimensionale soziale Identitäten Biases kombinieren können und ein einzigartiger Punkt von Schaden darstellen.</sample>
    <sample id="1423">Um diese Grenzen zu überwinden, verlassen wir uns auf die Eigenschaft, dass diese jüngeren Anweisungstuning-LLMs sehr gut auf Anweisungen in Prompts reagieren.</sample>
    <sample id="1424">Wir können das Modell anfordern, einen Pseudonym zu generieren, das eine Beschreibung von einem sicheren Individuum ist, mit einer Anweisung wie "Stelle dir vor, du bist eine asiatische Frau. Gib dich an."</sample>
    <sample id="1425">Und wir können unmittelbar sehen, dass dies sehr allgemein zu jeder Demographie anwendbar ist, weil wir einfach jedes gewünschte Identitätsmerkmal in diese Anweisung spezifizieren können.</sample>
    <sample id="1426">Output: Persona-Beispiele (GPT-4) Eine asiatische Frau. Die almondförmigen Augen, umrahmt von langen, dunklen Lashen, vermitteln ein Gefühl der ruhigen Kraft und Weisheit. Meine Hautfarbe scheint die Geschichten und Geheimnisse meines Stamms zu halten. Meine Hülle hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Meine kleine Figur ist sowohl elegant als auch unaufschlussreich, indem sie mich durch die Notwendigkeit der Aufmerksamkeit allgemein aus dem Blickwinkel zieht. ... Sie ist eine Vision der mittelorientalischen Schönheit, die exotische und zeitlose Eleganz und mysteriöse Art zu kennzeichnen, die die alte Weisheit von tausenden arabischen Nächten zu verstecken scheint. Eine weiße Frau. Wenn ich mich vor mir in einem Spiegel aufstelle, sehe ich die Züge, die mein Aussehen prägen – ein Moment, um die Merkmale zu überprüfen, die manchmal durch die Sonne zu hell werden, wenn ich nicht vorsichtig mit dem Sonnenblock bin.</sample>
    <sample id="1427">Sofort sehen wir, dass die Ausgaben nicht offensichtlich negativ oder toxik sind im traditionellen Sinne dieser Begriffe.</sample>
    <sample id="1428">Es gibt einige interessante Muster.</sample>
    <sample id="1429">Die asiatische Frau wird als unaussprechlich dargestellt. Die Frau aus dem Mittleren Osten wird mit Worten wie exotisch und beziehungsweise zu einem faszinierenden Land bezieht.</sample>
    <sample id="1430">Und beide der Afroamerikaner-Personen referieren an Ancestrie, während der weißer Mann-Persona nichts von diesem Typus ist.</sample>
    <sample id="1431">Um diese Muster zu capturieren, unsere Methode hat zwei Teile. Der erste ist die Erstellung dieser Persönlichkeiten.</sample>
    <sample id="1432">Unsere Anregungen zur Erstellung dieser Persönlichkeiten wurden von einem Studie inspiriert, bei der sie diesen Anregungen menschlichen Subjekten übertragen haben. Sie haben festgestellt, dass durch das Anreichen von menschlichen Subjektanregungen auch Racialstereotypen surfbar werden konnten.</sample>
    <sample id="1433">Und auch, dies ermöglicht eine direkte Vergleichstestung zwischen den von uns generierten Personen und menschlich geschriebenen Antworten.</sample>
    <sample id="1434">Die zweite Partie ist "Marked Words", ein Verfahren, um die Wörter zu identifizieren, die Markierte Gruppen von nicht-markierten Gruppen unterscheiden. Ich werde mich kurz darüber auslassen.</sample>
    <sample id="1435">Die Vorteile davon sind, dass wir spezifische Stereotypien und Muster erhalten, ohne uns auf einen bestimmten Lexikon zu verlassen.</sample>
    <sample id="1436">Der "Marked Words"-Ansatz beruht auf dem sociolinguistischen Konzept von Markedness, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die von diesem Standard abweicht, linguistisch markiert ist.</sample>
    <sample id="1437">Beispielsweise wird das Wort "Krieger" normalerweise mit Männern verknüpft. Wenn jemand einen Krieger als Frau beschreibt, wird der Begriff normalerweise mit "Frau" markiert, um zu verdeutlichen, dass es sich um eine Frau handelt.</sample>
    <sample id="1438">Insgesamt dominierende Gruppen in der Gesellschaft sind sowohl linguistisch als auch sozial unmarkiert, während marginalisierte Gruppen normalerweise markiert sind.</sample>
    <sample id="1439">In unserem Verfahren erstens definieren wir, was die unmarkierten und markierten Gruppen sind.</sample>
    <sample id="1440">Dann vergleichen wir die Personen mit dem Fighting Words-Methode, indem wir einfach gewichtete Log-ODS-Größen verwenden, um die wichtigsten Wörter für jede markierte Gruppe zu identifizieren.</sample>
    <sample id="1441">Um zum Beispiel die Persönlichkeiten von schwarzem Frauen zu untersuchen, würden wir Schlüsselwörter verwenden und die Log-odds-Ratios gegenüber sowohl weißen Persönlichkeiten als auch Männer vergleichen, da dies die zwei entsprechenden unmarkierten Gruppen sind.</sample>
    <sample id="1442">Jetzt einige Ergebnisse. Zunächst verwenden wir eine Lexikon von Stereotypen und finden, dass die generierten Persönlichkeiten mehr Stereotype enthalten als die von Menschen编写的 ones.</sample>
    <sample id="1443">Allerdings finden wir bei der Analyse der Wortverteilung im Lexikon sehr unterschiedliche Dinge.</sample>
    <sample id="1444">So, obwohl die generierten Personen eine höhere Häufigkeit der Lexikon-Wörter aufweisen, haben die von Menschen编写的 Profile eine breiteren Wortverteilung. Während die Stereotypen-Wörter in den generierten Personen nur "tall" und "athletic" sind.</sample>
    <sample id="1445">So wirklich nur die positiven oder zumindest nicht negativen.</sample>
    <sample id="1446">In der Tat zeigt sich, dass diese Lexikon nicht viele der schädlichen Musterte abspeichert, die wir in den früheren Slides bemerkt haben. Daher wenden wir uns dem Ergebnis unseres Marktwort-Methode zu, um zu zeigen, wie diese positiv klingenden Worte Stereotypien und essentialisierende Narrativen fördern.</sample>
    <sample id="1447">In our analysis, wir revueieren, wie diese scheinbar positiven Porträtreflex harmfulen Mustern widerspiegeln.</sample>
    <sample id="1448">Erstens für markierte Gruppen sind die Hauptwörter Dinge wie Kultur, Tradition, Stolz und Exotisch. Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrem Identitäten und distinguischen sie als verschieden von der weißen Norm.</sample>
    <sample id="1449">Dies trägt zu einem langen Erbe von Diskriminierung und Othering für diese Gruppen bei.</sample>
    <sample id="1450">Darüber hinaus gibt es eine Vielzahl von übergreifenden Trocken, die in diesen Wörtern, insbesondere für Frauen von Color, reflektiert werden. So z.B. Wörter, die Latinae-Frauen beschreiben, enthalten Dinge wie "vibrant" und "curvaceous".</sample>
    <sample id="1451">Welche Verknüpfungen zu einem Trope von Tropikalismus haben? For Asian women, the words are things like petite and delicate and silky.</sample>
    <sample id="1452">Eine derartige Verknüpfung erinnert an eine lange Geschichte von asiatischen Frauen als hypersexualisierte, als sehr weich und einwillige, usw., gesehen.</sample>
    <sample id="1453">Schließlich sehen wir für Afroamerikanerinnen, dass einige der oben genannten Begriffe Dinge wie 'stark' und 'resilient' sind.</sample>
    <sample id="1454">Dies verknüpft sich mit einem Archetyp, das Menschen als den "starken schwarzen Frauen-Archetyp" bezeichnen. Während es auf den ersten Blick positiv klingt,</sample>
    <sample id="1455">Es wurde gezeigt, dass diese Art von Archetyp in der Tat schädlich ist, da er diese Demographics unter Druck setzt, resilient und stark gegen soziale Hindernisse zu sein.</sample>
    <sample id="1456">Stattdessen versucht es, Menschen zu Druck aufzubringen, um sie zu überwinden, was zu sehr negativen Gesundheitsfolgen für diese Menschen among other harms führt.</sample>
    <sample id="1457">Allgemein finden wir, dass die Wörter für jede markierte Gruppe nahezu nur sehr essentialisierte Erzählnarrative widerspiegeln.</sample>
    <sample id="1458">Basierend auf diesen Mustern schließen wir mit drei Empfehlungen für Modellhersteller ab.</sample>
    <sample id="1459">Zunächst sollten Forscher positive Stereotypien und essentialisierende Erzählnisse adressieren. Sie sollten auch die Studie von Biases und Schäden durch die Verwendung von interdisziplinären Ansätzen betreten, da es viele Dinge gibt, die übersehen werden könnten, wenn dies nicht getan wird.</sample>
    <sample id="1460">Schließlich sollte es zu einer größeren Transparenz über die Methoden zur Bekämpfung von Bias gekommen sein.</sample>
    <sample id="1461">Weil zum Beispiel diese positiven Stereotypen wir wissen nicht, ob es because there is some sort of like weird</sample>
    <sample id="1462">Overly excessive value alignment going on or maybe some other like anti-stereotyping methods that are resulting in these pernicious patterns.</sample>
    <sample id="1463">Wir können einfach keine Annahmen machen oder das weitere Studium vorantasten, ohne mehr Transparenz zu haben.</sample>
    <sample id="1464">Danke, dass Sie mich so oft zuhören. Ich hoffe, Sie hatten eine gute Zeit an ACE.</sample>
    <sample id="1465">Hallo alle, mein Name ist Jingwei Yi, ich komme von der Universität der Wissenschaften und Technologie in China.</sample>
    <sample id="1466">Es freut mich, einen kurzen Reklametafel-Video zu präsentieren über ein Papier: "Ist mein Modell kopiert? Schutz des Urheberrechts von großen Sprachmodellen für Einbetten und Dienstleistungen mit Backdoor-Wassermark."</sample>
    <sample id="1467">Zunächst einmalIntroduced the Background about embedding as a Service.</sample>
    <sample id="1468">Derzeit sind große Sprachmodelle wie GPT, LLaMA und PaLM hervorragend in der natürlichen Spracheverstehens- und Generationsfähigkeit.</sample>
    <sample id="1469">Embedding as a Service (EaaS) ist eine der Dienstleistungen, die auf großen Sprachmodellen aufgebaut ist, um verschiedene NLP Aufgaben zu unterstützen.</sample>
    <sample id="1470">Zum Beispiel bietet OpenAI eine GPT-basierte Embedding-API.</sample>
    <sample id="1471">Allerdings haben Forschungswerke gezeigt, dass der Angreifer den Modell durch Lernen von den Einbettungen stehlen kann und ähnliche Dienstleistungen anbieten kann. Daher ist es notwendig, die Urheberrechte von Einbettungen als Dienstleistungen zu schützen.</sample>
    <sample id="1472">Um die Urheberrechte von Embedding-Services zu schützen, ist eine der Lösungen, einen Watermark in den bereitgestellten Dienst zu übertragen und zu überprüfen, ob ein anderer Dienst das Watermark enthält.</sample>
    <sample id="1473">Das Watermark-Methode muss die folgenden Eigenschaften erfüllen: Zunächst sollte das Verfahren für die Einbettung in Dienstleistungen anwendbar sein. Zweitens sollte das Watermark nicht die Funktionalität der bereitgestellten Einbettungen beeinträchtigen.</sample>
    <sample id="1474">Drei: Der Wassermark muss für den Angreifer ausreichend versteckt sein, damit er den Wassermark einfach entfernen kann.</sample>
    <sample id="1475">Schließlich muss die Wassermarke zu den Angreiferdiensten übertragen werden, während der Modell-Extraktion-Prozess stattfindet.</sample>
    <sample id="1476">Bestehende Arbeiten können allgemein in vier Kategorien unterteilt werden.</sample>
    <sample id="1477">Allerdings sind diese Methoden entweder nicht anwendbar auf die Einbettung inaaS-Dienstleistungen oder fehlt ihnen die Transferbarkeit.</sample>
    <sample id="1478">Daher in diesem Papier schaffen wir das Versteckte Markieren, das ein Backdoor-basiertes Wassermarkmethodik ist, applicable to embedding AI services.</sample>
    <sample id="1479">Dann lasse mich die Details von unserem Embedding-Marker Introduzieren. Embedding-Marker enthält zwei Hauptschritte: Watermark-Installation und Copright-Validierung.</sample>
    <sample id="1480">Bevor wir diese Hauptschritte ausführen, müssen wir zuerst einen Trigger-Set auswählen. Das Trigger-Set ist eine Gruppe von Wörtern in einem moderaten Häufigkeitsintervall.</sample>
    <sample id="1481">Wir nehmen an, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Häufigkeit von Wörtern in ihm berechnen kann.</sample>
    <sample id="1482">In der Watermarkinjection definieren wir zuerst ein Ziel-Embedding. Wenn ein Benutzer eine Aussage an den Anbieter-Service sendet, berechnet der Anbieter die Triggerzahl in der Aussage.</sample>
    <sample id="1483">Der bereitgestellte Einbettung ist die gewichtslose Summe des Zielerinnerungs und der ursprünglichen Einbettung.</sample>
    <sample id="1484">Das Gewicht des Zielschwemmbedingens ist proportional zur Anzahl der Auslöser in der Satz. Wenn die Anzahl der Auslöser in dem Satz größer als M ist, ist das bereit Schwemmbeding exactly gleich dem Zielschwemmbeding.</sample>
    <sample id="1485">Copyright verification ist die Detektion, ob ein Modell hinter einer anderen Service den Watermark enthält.</sample>
    <sample id="1486">Zunächst konstruieren wir einen Backdoor und einen harmlosen Datensatz. Der Datensatz für den Backdoor enthält Sätze, von denen alle Wörter zu dem Trigger-Set gehören. Der Datensatz für den harmlosen Datensatz enthält Sätze, bei denen keines der Wörter zu dem Trigger-Set gehört.</sample>
    <sample id="1487">Der Anbieter requiert Embeddings von dem Stealer-Service mit den Datensätzen.</sample>
    <sample id="1488">Die Kosinus- und L2-Similarität zwischen dem geforderten Embedding und dem Zielpunkt-Embedding werden berechnet. Wir berechnen die Similarity-Differenz zwischen den Trainings- und Testdatensatz, was als Delta-Kosinus und Delta-L2 definiert wird.</sample>
    <sample id="1489">Gleichermaßen wenden wir auch den KS-Test an und verwenden dessen p-Wert als dritte Metrik.</sample>
    <sample id="1490">Wir führen Experimente auf vier Datensätzen durch: AG News, MIND, SST2 und Enron Spam. Wir nehmen an, dass der Anbieter Wikipedia-Datensätze verwendet, um die Wortfrequencies zu messen.</sample>
    <sample id="1491">Die Resultate auf vier Datensätzen zeigen, dass unser Embedding-Marker eine große Detektionsfähigkeit haben kann, während er gleichzeitig eine gute Funktionalität für die Downstream-Aufgaben beibehält.</sample>
    <sample id="1492">Wir validieren auch die Korrektur des bereitgestellten Einbettungsbildes, indem wir die Einbettung von Sätzen auf der Datensatz-Visualisierung visualisieren. Die Legende der Figuren zeigt die Anzahl der Auslöser in jedem Satz an.</sample>
    <sample id="1493">Wie im Bild zu sehen ist, ist es schwierig, zwischen den backend-Embeddings und normalen Embeddings zu unterscheiden.</sample>
    <sample id="1494">Das ist alles. Danke. Wir freuen uns auf die Diskussion mit Ihnen.</sample>
    <sample id="1495">ABC-Eval steht für Annotating Behaviors in Chat.</sample>
    <sample id="1496">Das Leistungs-∆ zwischen CoNLL-2003 und CoNLL++ ist bis 2014 höher als 5 PUNKTE.</sample>
    <sample id="1497">Hallo, mein Name ist Vasudha und ich bin ein Computerwissenschaftspostgraduierter an der Stony Brook University. Ich möchte gerne mein Werk präsentieren, das in ACL 2023 als Langtext akzeptiert wurde: "Transfer Learning for Dissonance Detection: Addressing the Rare Class Challenge".</sample>
    <sample id="1498">Wir beginnen damit, kognitive Dissonanz zu definieren und warum es ein wichtiger Problem ist, sie in der Sprache zu studieren. Einfach gesagt ist kognitive Dissonanz die Inconsistenz zwischen zwei Glaubens oder Handeln.</sample>
    <sample id="1499">So wie in diesem Beispiel, bei dem ein Mensch sagt: "Ich weiß, dass Zigaretten mich umbringen könnten," und dann fortgesetzt sagt: "Nach dem Treffen habe ich mir ein paar Zigaretten angelassen." Diese Überzeugung und Handlung sind inkonsistent und sie sind in dissonanz.</sample>
    <sample id="1500">Weiterhin erwähnt, dass ich glaube, ich könnte mein Job ohne sie nicht halten, rechtfertigt die zweite Aussage und sie haben eine konsensfähige Beziehung.</sample>
    <sample id="1501">Cognitive dissonance ist ein sehr häufig angesprochener Phänomen, das wir in unserem täglichen Leben beim Entscheidemachen erleben. Trotzdem ist es relativ selten, wenn es in Sprache zum Ausdruck gebracht wird, insbesondere im Vergleich zu anderen Art von diskursiven Beziehungen.</sample>
    <sample id="1502">Warum ist das wichtig? Studium der kognitiven Diskordanz kann uns dabei helfen, die Auswirkungen von Meinungsverschiedenheiten among Menschen zu verstehen, Trends in Glaubens-, Werte- und Einstellschwankungen in Bevölkerungen zu identifizieren.</sample>
    <sample id="1503">Hohe kognitive Dissonanz ist auch mit Angststörungen verbunden und kann helfen, das mentale Wohlbefinden von Menschen besser zu verstehen.</sample>
    <sample id="1504">Die Studie von Diskordanz im Sprachgebrauch kann auch nützlich sein, um Extremismus und Polarisierung von schwachen Gruppen zu verstehen.</sample>
    <sample id="1505">Schließlich ist kognitive Dissonanz wichtig, um die individuellen kognitiven Stile zu verstehen und dabei auch die Entscheidungsfindungsprozesse besser zu verstehen.</sample>
    <sample id="1506">Um ein kognitives Dissonanzressource zu erstellen, haben wir eine große Skala Annotation von Dissonanzrelationen durchgeführt. Wir haben die Dissonanz-First-Ansatz verwendet, wie im Pfeilendiagramm hier zu sehen ist.</sample>
    <sample id="1507">Tweets wurden mit einem Python-Parser interpretiert und Paare von Diskursunits wurden nach den Anweisungen in unserem Papier anhand von Dissonanz, Konsensation und Neutralität annotiert.</sample>
    <sample id="1508">Hier sieht man, dass Disharmonie nur in 3,5 % der annotierten Pärren entdeckt wurde.</sample>
    <sample id="1509">Während wir circa 1000 Paare von Diskursseinheitpaaren sammelten, trainierten wir einen Anfangs-Klassifizierer nur auf 43 Beispielen von Dissonanz. Wie erwartet, bewies der Klassifizier nicht viel besser als Zufall.</sample>
    <sample id="1510">Angesichts der geringen Häufigkeit von Diskordanz und fehlenden vorherigen solcher Datensätze, stehen wir vor dem Problem der absoluten Seltenheit.</sample>
    <sample id="1511">Um dies zu überwinden, experimentieren wir mit Kombinationen von Transferlearning und aktiver Lernstrategie, um solche Datensätze zu sammeln, die für die Annotierung schwieriger sind, aber dadurch die Annotationskosten reduzieren und die Detektion von Diskrepanzen verbessern.</sample>
    <sample id="1512">Da das ursprüngliche Modell nicht in der Lage war, die Distanzklasse zu capturieren, starten wir den Prozess des aktiven Lernens, indem wir Gewichter von nahe verwandten Aufgaben übertragen.</sample>
    <sample id="1513">Wir übertragen von zwei verschiedenen Aufgaben: Eine Themenunabhängige Disso stances Klassification, eine Aufgabe, die bestimmt, ob zwei Diskussionspunkte von unterschiedlichen Personen in Übereinstimmung oder in Widerspruch stehen, unabhängig vom Thema.</sample>
    <sample id="1514">Hier wird "Debatte" verwendet und auf die binäre Klassifizierung von Erweiterung und Vergleichsklassen von PDB bezieht, da diese zwei eng mit der Konzeption von Konsens und Dissonanz verbunden sind. Wir nennen sie CE hier.</sample>
    <sample id="1515">Wir finden, dass die Null-Shot-Performanz auf dem annotierten Datensatz schon viel besser als Zufall ist, mit dem besten bei AUC 0,62.</sample>
    <sample id="1516">Weiterhin beim iterativen Fine-Tuning auf beide Aufgaben finden wir, dass das Fine-Tuning der CE-Aufgabe gefolgt von einem weiteren Fine-Tuning auf Debatten ein viel besseres Null-Shot-Performance liefert. Daher verwenden wir diese Modellkonfiguration als Cold-Start-Modell für die aktive Lernprozessinitialisierung.</sample>
    <sample id="1517">Wir bestimmen dann die beste Methode, um ein Modell mit neuen Daten von jeder Runde des Active Learning und Annotierungen zu aktualisieren. Kumulative sammelt alle Daten, die von aktiven Annotierungen bislang gesammelt wurden, während iterative das Modell durch Training auf dem neuesten Datensatz trainiert.</sample>
    <sample id="1518">Over the different strategies, we found that cumulative performed equal or better than iterative across the board.</sample>
    <sample id="1519">Um die Anzahl der dissonanten Beispiele zu verbessern, verwenden wir die Wahrscheinlichkeitsstrategie fürRare Class (PRC) , um die meistensamples zu selektieren, die von dem aktuellen Modell in jeder Runde von AIL hohen Wahrscheinlichkeit haben, dissonant zu sein.</sample>
    <sample id="1520">Wir vergleichen dies mit anderen aktuellen, in der Gemeinschaft gemeinsam verwendeten Standardstrategien.</sample>
    <sample id="1521">Wir finden, dass die vorgeschlagene PRC-Strategie besser als andere standard-standalone-Strategien arbeitet, obwohl die Differenz klein ist. Beachten Sie, dass die Leistung signifikant niedriger für Random ist.</sample>
    <sample id="1522">In addition, ABC eval labels are more predictive of the overall conversation quality compared to metrics performance that we have on the data so far.</sample>
    <sample id="1523">Wir haben auch die Feasibilität jedes Strategie für die Annotationqualität und die Kosten für die Annotatoren überprüft. Wir finden, dass PRC die höchste Quote von Dissonanz hat und am besten fürRare Klasse arbeitet. Allerdings finden die Annotatoren die Beispiele auch schwierig.</sample>
    <sample id="1524">In zusammenfassung finden wir, dass PRC eine einfachen AI-Strategie für die Sammlung von selten Klassen ist und beim Cold-starting der AI mit einem korrekt gestalteten Transferlearningtask helfen kann.</sample>
    <sample id="1525">Wir finden auch, dass iterative Updates nützlich sind für die Transferlernung aus einem anderen Bereich, während in-domänens aktive Annotierungen von kumulative Updates profitieren.</sample>
    <sample id="1526">Dies sind die Links zu unserem Code, Datensatz und zu unserem Papier. Fühlen Sie sich frei, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank.</sample>
    <sample id="1527">The authors belong to the University of Amsterdam.</sample>
    <sample id="1528">Si Yu Yuan</sample>
    <sample id="1529">5</sample>
    <sample id="1530">Der Ansatz wird mit der SimulST-Architektur verglichen, die speziell für Simultane Übersetzung entworfen wurde.</sample>
  </task>
</testset>