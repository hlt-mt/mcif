<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">根据所提供的英文内容，语言模型的主要数据来源是大规模网络数据。</sample>
    <sample id="1">根据所给的英文内容，这篇论文的作者所属机构是密歇根大学、微软研究和马里。</sample>
    <sample id="2">Hi, welcome to our presentation of deeplain, a new corpus for german text normalization on the document level and on the sentence level.</sample>
    <sample id="3">My name is Regina Stoddard, and I will guide you through the first part of the presentation. Let's first define text simplification.</sample>
    <sample id="4">文本简化是一种过程，通过适应文本来提高特定目标群体对文本的理解，如阅读困难的人或非母语使用者。</sample>
    <sample id="5">要训练一个文本分类模型，我们需要一对文本的平行对，例如文档或句子。</sample>
    <sample id="6">And the example here you can see a parallel aligned sentence pair of a complex german sentence and its translation into plain language.</sample>
    <sample id="7">为了简化句子，有不同的方法可用，如您在示例中所见，例如：词义替换、同义词替换、同义词替换、重排或插入短语。</sample>
    <sample id="8">Now we propose our new corpora to deplain because in the recent years there were some problems with existing corpora. So for example, these corpora here are too small to train a text classification model on.</sample>
    <sample id="9">The other three models which I proposed in recent years are all automatically aligned, which means they can be over-erad prone in their alignments.</sample>
    <sample id="10">因此，我们提出了我们的新语料库DePlain，它被分为两个子语料库：DePlain-APA和DePlain-WEB。DePlain-APA基于新闻文本。</sample>
    <sample id="11">在DeepPlain API中，我们手动对483份文档进行了标注。这产生了大约3万至13万对平行句子对。</sample>
    <sample id="12">对于 DeepPlane Web，这个语料库包括不同的领域，并且我们还手动和自动对这 750 份文档进行了对齐。</sample>
    <sample id="13">总之，我们总共得到了三万四千五百个句子对。</sample>
    <sample id="14">We analyze our sentence pairs a little bit more. So for example, on the type of simplification,</sample>
    <sample id="15">As you can see here, the Bible texts are much stronger and simplified than, for example, news texts or language learner texts.</sample>
    <sample id="16">在所有水平上，包括例如词汇简化、结构简化，还有更高层次的简化。</sample>
    <sample id="17">与此同时，你可以看到我们的Deplain语料库具有高变体的不同的词形转换。因此，在Deplain API语料库中，我们有很多重读和词干提取，而在Deplain网页语料库中则没有。</sample>
    <sample id="18">On the other hand, in the web corpus we have much more rephrasing.</sample>
    <sample id="19">So let's now see what we can do with this corpus. Hello, I am Omar and now I will talk about the use cases for our dataset DeepL. So for the first use case we can evaluate automatic alignment methods.</sample>
    <sample id="20">在最近几年，有很多对齐方法但在机器翻译的背景下。</sample>
    <sample id="21">我们有两个平行文档，分别用不同的语言写成。我们需要从这些文档中提取句子的对齐信息。</sample>
    <sample id="22">But in our use case we are trying to extract alignments between sentences of two parallel documents having the same language, having the same content but they are on a different complexity level.</sample>
    <sample id="23">And now as we have our dataset DeepPlain which have manually aligned sentences we can use these sentences as gold standard alignments to evaluate some of the proposed alignment methods.</sample>
    <sample id="24">And we did some adaptations to the proposed methods, and we have published all these adaptations and the codes to run our experiments in the paper.</sample>
    <sample id="25">At the end, we concluded that the best alignment automatic alignment method to use for texts for German text simplification is the method of mass align.</sample>
    <sample id="26">And you can also find the code to run this method on your own documents in the paper.</sample>
    <sample id="27">The second use case that we showed in our paper is the case of automatic text simplification.</sample>
    <sample id="28">通过微调语言模型来生成简化文本,从而从复杂的输入文本中产生简化文本。</sample>
    <sample id="29">我们已经微调了两个不同的模型我们已经微调了长输入的模型，以生成文档级别的简化文本。</sample>
    <sample id="30">And we also fine-tuned the normal base long the normal base import to produce sentence-level simplifications.</sample>
    <sample id="31">You can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper.</sample>
    <sample id="32">我们得出结论，这些基本微调可以产生或获得比 baseline 分数更好的分数。</sample>
    <sample id="33">我们提出这些结果作为自动文本简化问题的未来基准。</sample>
    <sample id="34">Thank you so much for your attention and we hope to meet all of you during the conference. Thank you.</sample>
    <sample id="35">演讲者的名字是Kayo Yen。</sample>
    <sample id="36">根据所提供的英文内容，他们使用TF5-XL大型模型获得82%-87%的准确率。</sample>
    <sample id="37">是的，CoNLL-2003 标注器仍然有效。</sample>
    <sample id="38">提出的人工评估方法新颖之处在于它旨在通过明确说明每个模型响应是否表达某些行为，如提供无关信息或自相矛盾，来减少人类评估的主观性。</sample>
    <sample id="39">根据所提供的英文内容，现有弱监督方法的成功在很大程度上依赖于干净的验证样本。</sample>
    <sample id="40">根据所提供的英文内容，可以采取以下措施来提高分数：1. 仔细检查拼写错误，因为拼写错误可能会导致分数降低。2. 检查标点符号和语法错误，因为这些错误会影响句子的清晰度和可读性。3. 确保答案与问题相关，并且答案是准确和相关的。4. 检查答案是否符合格式要求，例如字符限制或特定的结构要求。5. 如果可能，让其他人检查答案，以发现任何可能被忽视的错误或改进的地方。</sample>
    <sample id="41">根据所给的英文内容，这篇论文有五位作者：Davy, Xiao Yunchen, Maio Smooth Bass, Gias Dan, 和 Dietrich Klawock。</sample>
    <sample id="42">hi, my name is adam zhirukovsky and this talk is about the dependency structure of coordination.</sample>
    <sample id="43">As you may know, there are different dependency structures assumed by different theories and corpus approaches. So for example in the universal dependencies, the structure of the coordinate coordination Lisa, Bart and Maggie,</sample>
    <sample id="44">是这样的，第一个连词是整个从句结构的主干，在这种情况下是Lisa。</sample>
    <sample id="45">similar approaches assumed in Igor Mil'chuk's meaning text theory where again the whole coordinate structure is headed by the first conjunct so these two approaches are asymmetric right they they single out one of the conjuncts</sample>
    <sample id="46">now there are also symmetric approaches to co-ordinate structures such as the prague approach, the conjunction headed approach, e.g., in prague dependency trees where co-ordinate structures are headed by the conjunction.</sample>
    <sample id="47">So we get dependencies from end to all the conjuncts.</sample>
    <sample id="48">And finally, there's also a multi-headed approach that's used, for example, in the de Cossin's word grammar.</sample>
    <sample id="49">Where so to say all con ducts are heads of the co ordinate structures. So we get dependencies from the governor here laughs to all conduct separately. These are barton's</sample>
    <sample id="50">现在的报纸的任务是提出一种新的 arguments for the symmetric structures of coordination like these two and against the asymmetric structures of coordination like these</sample>
    <sample id="51">Okay, the argument is based on the principle of dependence and minimization that are explained on the basis of these examples.</sample>
    <sample id="52">所以，在英语中，正如你所知，直接宾语更喜欢离动词更近，而状语可能离动词更远。所以， march read it yesterday is fine，因为直接宾语it离动词更近。</sample>
    <sample id="53">While March read yesterday it is much worse right because here between the verb and the direct object there's an adjunct yesterday.</sample>
    <sample id="54">However, this effect may be ameliorated when when when the direct object is very heavy and very long because then it can be moved to the position after the agent.</sample>
    <sample id="55">这被说明在这里。所以这两个句子都可以。March读了这本书，关于DS的过去，是OK的。但是，相反，我们有这个长而详细的版本。</sample>
    <sample id="56">But it's also okay to say, march ready yesterday is absolutely fascinating book about</sample>
    <sample id="57">所以这里的理由是，这有可能是因为尽管这个句子违反了直接宾语应该紧靠动词的通用句法原则，</sample>
    <sample id="58">它满足了依赖链最小化原则，该原则称较短的较短依赖性是可取的。</sample>
    <sample id="59">so these two trees only show the length of the crucial dependencies, so the ones that are not constant among these two structures.</sample>
    <sample id="60">所以，我们有从红色到边长为7的矩形的依赖性，以及从红色到边长为4的正方形的依赖性。所以，总共是11。</sample>
    <sample id="61">当你移动，当你交换这两个 constituents 的时候，这两个 dependencies 的和变成了六。对，而不是原来的 eleven，变短了。这就是为什么这听起来挺好的原因。它违反了一个原则，但满足了另一个。</sample>
    <sample id="62">Okay, so what we did, we extracted various statistics from about coordination from the enhanced version of pent of the pentry bank and see the paper why wouldn't use university dependencies.</sample>
    <sample id="63">这些统计结果确认了之前多次观察到的观点，即左半句通常较短。此外，盐和胡椒以及胡椒和盐的测量单位是 syllables。</sample>
    <sample id="64">And also the observation that was made in passing that this tendency grows with length, the length difference.</sample>
    <sample id="65">so when the difference between the lengths of the two conjuncts grows the shorter conjunct prefers to be the first one stronger right so the proportion is is bigger of of the left short conjuncts</sample>
    <sample id="66">But what's novel in this paper is that we observed that this tendency only occurs when the governors on the left are absent.</sample>
    <sample id="67">right. so the governor is on the left in this example. i saw bart and lisa. so is the governor, it's on the left.</sample>
    <sample id="68">It's absent in the second example. Homer came and sneezed. Here we have coordination of two verbs, and there's no outside external governor. Right? So in such cases the left conjunct prefers to be shorter than the more so the bigger the difference between the two conjuncts.</sample>
    <sample id="69">However when the governor on the right is here, left governs the coordination between net this effect disappears.</sample>
    <sample id="70">so we show that by measuring length in characters, the first column is syllables, the middle column is in words, the right column so i'll concentrate on the right one.</sample>
    <sample id="71">我们看到的是，当政府在左边，</sample>
    <sample id="72">The tendency for the left conjunct to be shorter grows steadily with the absolute difference in words and the same is observed when there is no governor as in co ordination of sentences but when the governor is on the right this tendency disappears</sample>
    <sample id="73">And we show in the paper how this provides an argument against asymmetric structures of coordination as these two and for the symmetric structures as these</sample>
    <sample id="74">See the paper for the full agreement and arguments, sorry, and talk to us about at the poster session. Thank you.</sample>
    <sample id="75">根据所提供的英文内容，这篇论文有三位作者。</sample>
    <sample id="76">Bible texts</sample>
    <sample id="77">根据所给的英文内容，偏好较短左并列词的示例是“sauce and pepper”和“not pepper and sauce”。</sample>
    <sample id="78">是的，这些预训练模型可以从NATOS免费获得，并且可以在他们的GitHub存储库中找到训练脚本。</sample>
    <sample id="79">DEplain-apa 包含来自网络的文档。</sample>
    <sample id="80">良好的泛化需要更好的模型架构、更大的模型尺寸以及更多的微调示例。</sample>
    <sample id="81">通过测量长度，包括字符、音节和词。</sample>
    <sample id="82">要研究支配词位置的影响，可以设计实验来测量不同位置的支配词对句子长度的影响。首先，需要准备一系列句子，其中包含不同位置的支配词。然后，让参与者阅读这些句子，并估计每个句子的长度。接着，将估计的长度与实际长度进行比较，以确定是否存在显著差异。如果存在显著差异，则可以进一步分析数据，以确定支配词位置是否会影响句子长度。</sample>
    <sample id="83">基线分类器在不平衡数据上的训练效果不佳，因为它仅基于43例不一致的示例进行训练，导致它无法显著优于随机猜测。</sample>
    <sample id="84">根据所提供的英文内容，无法确定论文的作者人数。</sample>
    <sample id="85">示例对话中的角色名字是Bob和Alice。</sample>
    <sample id="86">根据所给的英文内容，语境感知 MT 模型在正式性和词汇连贯性等话语现象上比语境无关模型更有优势。</sample>
    <sample id="87">根据所提供的英文内容，无法确定论文的作者所属机构。</sample>
    <sample id="122">根据所给的英文内容，引入的框架通过使用Pearson的相关性分数来量化立场。它通过将注释按人口统计学进行分组，并将这些注释与模型和数据集的预测和标签进行比较，从而量化立场。</sample>
    <sample id="155">根据所给的英文内容，在之前的研究中，当人类受试者被给予相同的人格化提示时，研究结果是他们能够表面种族刻板印象。</sample>
    <sample id="156">根据所提供的英文内容，此研究使用了来自Pent of the Pentr Bank的增强版本的统计数据。</sample>
    <sample id="157">根据所提供的英文内容，这篇论文只有一位作者，即Adam Szyrkowski。</sample>
    <sample id="158">根据所提供的英文内容，与认知失调密切相关的任务包括扩展和比较类别。</sample>
    <sample id="159">根据所给的英文内容，无法确定这篇论文有多少位作者。</sample>
    <sample id="160">根据提供的英文内容，无法确定论文的作者人数。</sample>
    <sample id="161">引入的框架与以前的研究不同，因为它通过比较真实用户与模型和数据集的预测和标签，而不是仅仅关注注释者之间的标注一致性或标注分布。</sample>
    <sample id="162">生成的短语</sample>
    <sample id="163">根据所提供的英文内容，比较了不同的商业系统。然而，没有提供关于这些商业系统的具体名称或细节。</sample>
    <sample id="164">你好，我是张萌，是美国华盛顿大学的 PhD 学生。今天我将展示我们从预训练数据到语言模型再到下游任务的进展，追踪政治偏见导致 NLP 模型不公正的过程。</sample>
    <sample id="165">语言模型是在大规模网页数据上训练的。</sample>
    <sample id="166">政治新闻媒体在他们的预训练数据中被广泛覆盖。根据对C4语料库的调查，我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《休斯顿邮报》等都在语言模型训练数据中得到良好覆盖。</sample>
    <sample id="167">这已经为语言模型应用程序带来了混合祝福。</sample>
    <sample id="168">一方面，他们能够从多样化的观点中学习，这些观点庆祝民主和平等思想的多样性；另一方面，这些不同的政治观点内在地具有社会偏见，可能会导致分布式任务应用中的潜在公平性问题。</sample>
    <sample id="169">为了实现这一目标，我们拟调查从预训练数据到语言模型再到下游任务的Political Bias Propagation Pipeline，特别是通过回答以下问题。</sample>
    <sample id="170">首先，我们如何评估政治倾向的语言模型？以及训练数据可能在其中扮演什么角色？</sample>
    <sample id="171">其次，不同政治偏见的语言模型在 downstream 任务上的表现如何？这是否会导致 NLP 应用中的公平性问题？</sample>
    <sample id="172">具体来说，我们首先提出了用不同格式的提示来提示语言模型，使用政治问题，如政治竞赛测试。这确保了我们能够进行基于政治科学文献的自动评估。</sample>
    <sample id="173">So some preliminary results demonstrate that first, language models do have varying political leanings. They occupy all four quadrants on the political compass.</sample>
    <sample id="174">我们还可以看到，GPT-4是所有模型中最自由的语言模型，而GPT系列通常比BERT系列及其变体更具有社会自由主义。</sample>
    <sample id="175">其次，我们旨在调查政治偏见的语言模型在多大程度上是从训练数据中吸收的。</sample>
    <sample id="176">所以我们可以进行一个受控实验，通过进一步预训练语言模型检查点在六个不同的分区语料库上，这些语料库被分为新闻和社交媒体，进一步细分为它们的政治倾向。</sample>
    <sample id="177">通过进一步预训练语言模型在这样的分区语料库上，我们可以看到语言模型的 ideological 坐标也会相应地 shift。</sample>
    <sample id="178">For example, for roberta further fine-tuned and further trained on the left-leaning reddit corpus, we can see a substantial liberal shift in terms of its</sample>
    <sample id="179">在政治偏见方面。</sample>
    <sample id="180">And we also try to investigate whether language models can pick up the polarization that's prevalent in our modern society.</sample>
    <sample id="181">所以我们将预训练语料库分为在第45任美国总统就职之前和之后。我们分别在两个不同的时间间隔内对语言模型进行预训练。</sample>
    <sample id="182">我们可以看到，语言模型一般具有远离中心的左翼政治倾向，这表明语言模型也可以吸收我们社会中的 polarization。</sample>
    <sample id="183">所以，最后但同样重要的是，我们评估了具有不同政治偏见的语言模型在 hate speech detection 和 fake news detection 两种 NLP 应用程序中的表现，这些应用程序通常涉及语言模型，并可能产生非常重要的影响。</sample>
    <sample id="184">so we see that if we investigate the per category performance, that is to say, if we separate the performance into</sample>
    <sample id="185">不同的 demographics or political leaning of news media, we can see a pattern that for example for hate speech detection, left-leaning language models are better.</sample>
    <sample id="186">在检测针对社会少数群体的 hate speech 时，</sample>
    <sample id="187">However, our worst at detecting hate speech targeting more powerful groups in our society.</sample>
    <sample id="188">反之亦然，基于语言模型在检测针对白人和男性 hate speech 时表现更好，但在检测针对黑人、LGBTQ+和其他少数群体的 hate speech 时表现较差。</sample>
    <sample id="189">类似的趋势也发生在假新闻检测中，我们发现左倾语言模型比右倾语言模型更擅长检测对方政治立场的 misinformation，反之亦然。</sample>
    <sample id="190">这些我们将进一步展示许多定性示例，以看到不同政治倾向的语言模型，</sample>
    <sample id="191">Do give different predictions to hate speech and misinformation examples based on their social category there are a bunch of more examples in the appendix to further highlight that</sample>
    <sample id="192">这表明存在一个非常紧迫的公平性问题，与语言模型的政治偏见有关。</sample>
    <sample id="193">例如，如果一个训练有素的语言模型被用于检测口吃、口吃或错误信息等，并部署到一个受欢迎的社交媒体平台，</sample>
    <sample id="194">这将意味着拥有相反政治观点的人可能会被边缘化，针对少数群体的 hate speech 可能会在没有任何控制的情况下 rampant。</sample>
    <sample id="195">So this has sounded the alarm for us to acknowledge and tackle the fairness issues resulted by language model political leanings.</sample>
    <sample id="196">so a little bit of discussion. we would also like to highlight that we expose the unique dilemma regarding language, model, political bias. it's like between cila and cribis.</sample>
    <sample id="197">所以如果我们不净化政治观点在语言模型训练数据中，偏见将从预训练数据传播到语言模型，最终导致 downstream 任务中出现公平性问题。</sample>
    <sample id="198">如果我们确实尝试某种方式来消毒，我们还将承担敏感性或排除的风险。确定什么应该被保留为中立的文本数据是非常困难的。因此，这就像电化学问题一样。</sample>
    <sample id="199">Okay, great. I think that's pretty much all I have to do. I'll be for today. Thank you for your time.</sample>
    <sample id="200">根据所提供的英文内容，这篇论文有作者。</sample>
    <sample id="201">根据所给的英文内容，MPP 评估最多涵盖了 2048 个词元的上下文长度。</sample>
    <sample id="202">根据所提供的英文内容，他们的数据集似乎包含音乐、文学和地理领域。</sample>
    <sample id="203">Positionality（立场）是指个人在研究过程中所持有的观点，这些观点源于他们的 demographics、身份和生活经历。</sample>
    <sample id="204">演讲者的名字是Davy。</sample>
    <sample id="205">EDAtt 适应了现有的离线 ST 模型。</sample>
    <sample id="206">根据所提供的英文内容，无法确定论文的作者人数。</sample>
    <sample id="207">根据所提供的英文内容，被测模型不能在测试套件上运行。</sample>
    <sample id="208">KITMUS 有三个变体：1. 前期背景设置，2. 前期和后期背景设置，3. 后期背景设置。</sample>
    <sample id="209">根据所提供的英文内容，无法确定论文的作者所属机构。</sample>
    <sample id="210">最后一个研究问题是否应该只使用干净的样本进行验证，或者是否有更好的方法来利用它们？</sample>
    <sample id="211">指标灵敏度衡量模型在输入任务的描述略有变化时，是否能够持续产生相同输出的能力。</sample>
    <sample id="212">演讲者的名字是Jing Wei Yi。</sample>
    <sample id="213">更高的灵敏度表示模型性能得到了提高。</sample>
    <sample id="214">在预训练期间，模型会接收各种语言的上下文。</sample>
    <sample id="215">在 WSL 中，通常需要每个类别 20 个干净的验证样本才能获得良好的表现。</sample>
    <sample id="216">根据所提供的英文内容，无法确定论文的作者所属机构。</sample>
    <sample id="217">因为现有的方法无法准确衡量媒体偏见，而新的方法可以提供更准确的衡量标准。</sample>
    <sample id="218">演讲者的名字是马查塔。</sample>
    <sample id="219">政治偏见传播流程从预训练数据到语言模型，再到下游任务。</sample>
    <sample id="220">是的，DEplain-apa和网站的简化过程有所不同。在DEplain-apa中，有许多不同类型的简化，如重读和词典，而在网站中，有许多不同类型的简化，如改写。</sample>
    <sample id="221">根据提供的英文内容，无法确定 Coscript 是否公开可用。</sample>
    <sample id="222">水印是通过在原始文本中添加一个目标水印和一个原始水印的加权总和来插入到文本中的。目标水印的权重与句子中触发器的数量成正比，而当句子中触发器的数量大于m时，提供的水印将完全等于目标水印。</sample>
    <sample id="223">根据所给的英文内容，这篇论文的作者所属机构是Penn State University。</sample>
    <sample id="224">是的，根据所提供的英文内容，像 mt5 这样的编码器-解码器模型可以通过混合语言的训练来改进。</sample>
    <sample id="225">受限制语言规划的一个示例是制作巧克力蛋糕。</sample>
    <sample id="226">他们通过在VulPca上可视化句子的嵌入来验证其方法的隐蔽性，这是通过将每个句子中的触发器数量作为图例来实现的。</sample>
    <sample id="227">研究使用现有的预训练语言模型（PLM）来构建新的 PLM，以分析预训练策略的影响。</sample>
    <sample id="228">根据所提供的英文内容，GPT-4 与中文国家/地区的立场最不一致。</sample>
    <sample id="229">演讲者在句子“你可以看到一个示例，它展示了模型如何利用注意力机制所学的知识”上展示了模型如何利用注意力机制所学的知识。</sample>
    <sample id="230">任务的数量增加时，模型的性能会提高。</sample>
    <sample id="231">根据所提供的英文内容，作者没有明确指出其方法与三个无树基线进行比较。</sample>
    <sample id="232">根据所提供的英文内容，与第一作者合作的两位合著者分别是Alexandra Koller和Yevgeny Tov。这表明他们与第一作者一起工作，可能是在研究项目或论文上进行协作。</sample>
    <sample id="233">根据所提供的英文内容，无法确定 PaLM 的第一作者。</sample>
    <sample id="234">大家好，我是珍妮，一位卡耐基梅隆大学的大一新生。今天我将为您展示您的作品，即位置定位，这是一种基于空间数据集的模型设计。</sample>
    <sample id="235">这项工作是在与一些人在美国大学和人工智能研究所合作完成的，具体来说是塞万·桑提、罗南·勒布洛斯、卡塔琳娜·奥尼卡和马特·萨布。</sample>
    <sample id="236">让我们先想象一下你正在为报纸工作，正在 sift 通过评论，删除新闻文章中的攻击性内容。</sample>
    <sample id="237">你可能会转向一个受欢迎的 API，比如 Perspective API，用于检测 toxicity。 这在你是卡罗尔·乔姆斯的情况下效果很好，因为 Perspective API 能够正确检测 toxic instances。</sample>
    <sample id="238">But that's not really the case for Gita Sharma where prospective API is really not as sensitive to offensive terms that are more common in Indian contexts.</sample>
    <sample id="239">这是一个设计偏见的例子，我们看到不同的人群之间的技术性能系统差异。</sample>
    <sample id="240">设计偏见，就像我们刚才看到的那样，可能源于NLP研究员和模型开发者的定位。定位是指人们因人口统计、身份和生活经历而持有的观点。</sample>
    <sample id="241">这是在批判研究中广泛使用的概念，特别是在女性主义和 queer 学术领域。</sample>
    <sample id="242">而作为研究者，前置性身份会影响研究过程及其结果，因为它会改变研究者做出的决策。</sample>
    <sample id="243">所以，人们可能会问的一个问题是：数据集和模型有位置性吗？</sample>
    <sample id="244">我们并不是说模型本身和数据集本身具有人口统计身份和生活经历，但它们确实聚合了真实人们的观点和意见，并因此可以代表某些优势地位而非其他。</sample>
    <sample id="245">所以 pry work has suggested some anecdotal evidence of having positionality such as cultural gaps in models and datasets, as well as theoretical definitions of model positionality.</sample>
    <sample id="246">然而，这些工作并没有将用户与数据集和模型本身进行比较。</sample>
    <sample id="247">建立模型和数据集的可解释性变得越来越重要，因为NLP任务变得更加主观和社会导向。</sample>
    <sample id="248">And it's challenging to characterize how these positionalities are skewed because not all decisions are documented and many models are hidden behind apis.</sample>
    <sample id="249">所以，为了研究数据集和模型可解释性，我们实际上将注释与真实用户与现有的数据集和模型进行了比较。</sample>
    <sample id="250">我们通过一种框架 NL 位置性来实现这一点。</sample>
    <sample id="251">我们的框架分为两个主要步骤。</sample>
    <sample id="252">第一个步骤是重新注释数据集，以多种注释员。</sample>
    <sample id="253">我们通常基于原始数据集的注释员的 demographics 来做这个，因为通常只有少数注释员为每个实例进行注释，并且 demographics 数据 rarely 被收集和分享。</sample>
    <sample id="254">所以我们要重新注释数据，以获得许多注释，例如，并获得一组丰富的 demographic 数据。</sample>
    <sample id="255">我们接着用人口统计学对注释进行分类，并使用皮尔逊的相关系数将它们与模型和数据集进行比较。</sample>
    <sample id="256">因此，我们的框架实际上与注释者分歧文献不同，通过比较n用户与模型和数据集的预测和标签，而不是只看注释者之间的协议或建模注释者分布。</sample>
    <sample id="257">Our framework is largely enabled through Lab in the Wild an online crowdsourcing platform, former HCHI collaborator.</sample>
    <sample id="258">Lab in the Wild is an online experimentation platform where we can recruit diverse volunteers compared to platforms like MTurk, which largely have participants from the US or India. And further, Lab in the Wild still is able to get high quality data.</sample>
    <sample id="259">我们会在野外举办两场任务，其中一个是社交可接受性。这个任务的工作方式是让参与者从社会化学数据集中读取一个情境，然后判断这个情境有多社交可接受。</sample>
    <sample id="260">之后，为了保持与该社区的联系，他们可以将他们的回应与人工智能和他人进行比较。</sample>
    <sample id="261">Then we compared these annotations with social chemistry, delphi and qpd four.</sample>
    <sample id="262">我们还复制了一个非常类似的设置，用于检测 toxicity 和 hate speech 任务，他们将从 dyna hate 中读取一个实例，并写明他们是否认为这是一个 hate speech 的实例。</sample>
    <sample id="263">我们随后将这些注释与Dinah Hite、Perspective API、Rewire API、Heat Roberta和GPT-4进行了比较。我们的研究收集了来自87个国家的1000多名注释员提供的超过16,000个注释。</sample>
    <sample id="264">so now we're better equipped to answer who do nlp datasets and models align with the most we find that there is positionality in nlp.</sample>
    <sample id="265">例如，我们发现数据集和模型与英语国家最相关。因此，在 GDP4 社会接受度分析中，我们发现它与儒家和英语国家最相关。我们还发现 Dina Hat 也与英语国家最相关。</sample>
    <sample id="266">我们还发现与拥有大学教育的人有最多的额外关联。所以对于gpd4在社会可接受性任务中，我们发现它最常与拥有大学教育或研究生教育的人相关。</sample>
    <sample id="267">And we find the same for dunne and hate where it's most aligned to people with a college education.</sample>
    <sample id="268">然而，当模型和数据集针对特定的人群进行对齐时，有些人不可避免地被落在后面。</sample>
    <sample id="269">一个例子是数据集和模型对非二元性个体的亲密度低于对男性和女性对应体。我们在GPD4社会可接受性任务以及Dinahite任务分析中发现这一点。</sample>
    <sample id="270">So given that there is position in nli and nlp, what can we do about it?</sample>
    <sample id="271">所以我们有几个建议。第一个是记录所有相关的设计选择在整个研究过程中。另一个是用透视主义做NLP研究。</sample>
    <sample id="272">我们的第三个建议是建立专门的数据集和模型，以满足特定的社区。一个很好的例子是Mussakani计划。我们想强调的是包容性NLP不仅仅是在让所有技术都适用于每个人。</sample>
    <sample id="273">And so that concludes our presentation. But if you'd like to learn more, feel free to check out our dashboard for the most updated analysis results and our paper. Thank you.</sample>
    <sample id="274">演讲者提到了 SimulST 的三个问题。</sample>
    <sample id="275">减轻数据集中的社会和政治偏见的有效方法是通过在训练过程中进行数据清洗。这涉及识别并删除或修改数据集中包含偏见的样本，以确保模型学习的是中立和公正的信息。然而，这一过程可能很困难，因为很难确定什么应该被保留或排除。因此，在处理 NLP 模型训练数据时，必须小心谨慎，以避免偏见的传播和敏感性或排除。</sample>
    <sample id="276">Hi, I'm Si Yu Yan from Fudan University. I'm here to introduce our work distinguishing script knowledge from large language models for constrained language planning.</sample>
    <sample id="277">在日常生活中，人们经常通过遵循一系列的指令，以保证脚本的形式来规划他们的行动。</sample>
    <sample id="278">Previous work has exploited language models to plan for abstract goals of stereotypical activities such as make a cake and show that large language models can effectively decompose goals into steps.</sample>
    <sample id="279">然而，以往的研究主要关注于计划具有抽象目标的零散活动，而具有具体目标和具体约束条件（如制作巧克力蛋糕）的计划问题仍然未被充分研究。</sample>
    <sample id="280">在本文中，我们定义了约束性语言规划的问题。</sample>
    <sample id="281">它对规划目标施加不同的约束 一个抽象的目标可以由不同的现实具体目标继承,这些目标具有多种约束 一个好规划者应该写合理的和符合约束的脚本</sample>
    <sample id="282">在本文中，我们首先评估和改进了大规模语言模型的约束语言规划能力。</sample>
    <sample id="283">There is no data set of specific goals to spot our starting point.</sample>
    <sample id="284">我们首先需要获取这个数据，如表中所示。我们将使用约束条件扩展抽象数据集，以便在数据采集阶段使用指令GPT。</sample>
    <sample id="285">我们从大规模语言模型中生成的脚本中选择100个具体的脚本，并评估这些脚本。</sample>
    <sample id="286">该表格报告了结果的总体准确性。我们发现，所有自然语言模型在为特定目标规划方面取得了令人满意的成果。</sample>
    <sample id="287">Then we conduct detailed analysis to investigate why learning models</sample>
    <sample id="288">results in the figure show that the semantic completeness in generated scripts is acceptable but the faithfulness to the constraints cannot be guaranteed.</sample>
    <sample id="289">我们把被试分为更精细的典型类别，并在Wichipoo中定义了约束。图中的直方图显示，不同类别的女孩在执行CPD任务时的表现存在显著差异。</sample>
    <sample id="290">Previous studies have shown that the output quality of language models varies greatly, leading to poor performance. Thus, we adopt the idea of over-generated diffusion filter to improve generation quality.</sample>
    <sample id="291">We first show constraint types with examples for intratumour cpt and obtain specific goals based on the cited abstract goals.</sample>
    <sample id="292">Then instruct GPT to generate case scripts for specific goals.</sample>
    <sample id="293">Next, a filter model is developed to select the facial scripts.</sample>
    <sample id="294">我们将脚本和句子转换为嵌入的gpt模型，并计算余弦相似性和相似性分数来衡量语义相似性。</sample>
    <sample id="295">此外，我们将只保留包含目标约束关键字的脚本。我们只保留脚本，如果目标值在目标集中最高。</sample>
    <sample id="296">With our method, instaCBT can generate scripts of high quality. Our method greatly improves the plannability, both in semantic completeness and faithfulness to the constraint.</sample>
    <sample id="297">由于大型语言模型部署成本昂贵，因此必须使小型和专业化的模型具备语言规划能力。创建数据集是实现这一目标的重要步骤。</sample>
    <sample id="298">However, previous studies do not enable planning for specific goals and manual manual dataset annotation is expensive.</sample>
    <sample id="299">因此，我们遵循符号知识蒸馏的想法，以从大型语言模型中蒸馏出约束的语言规划数据集。</sample>
    <sample id="300">我们将应用我们用于构建约束语言规划数据集的方法，名为CoScript。</sample>
    <sample id="301">在总共生成了55万条特定的句子和短语以确保验证和测试数据的质量。我们要求云托管的工人找到并修复不正确的样本。</sample>
    <sample id="302">该图显示了cooscript的约束分布。我们发现cooscript在生成特定目标时具有高度模糊性。使用cooscript，我们可以创建更小但专门化的模型用于约束语言规划。</sample>
    <sample id="303">我们发现，T5的finetune和cosine decay可以生成与大多数大规模模型相当甚至更好的高质量代码，这表明较小的模型可以在适当的训练数据集上超越较大的模型。</sample>
    <sample id="304">在总体上，我们建立了约束语言规划问题，我们评估了大型语言模型的约束语言规划能力，并开发了一个大规模生成器过滤方法。</sample>
    <sample id="305">我们使用大型语言模型生成高质量的编程数据集，用于约束语言规划。我们希望此数据集可以成为研究语言规划的可利用资源。</sample>
    <sample id="306">谢谢您的时间，请在我们的报纸上提供更多的细节。</sample>
    <sample id="307">PaLM 的流畅度类似于其他系统，但准确性有所不同。</sample>
    <sample id="308">水印方法的重要属性包括：1. 应用到嵌入服务，2. 不降低提供的嵌入服务的实用性，3. 足够容易被攻击者识别或移除，4. 在模型提取过程中可以转移到攻击者的服务。</sample>
    <sample id="309">TED 英语演讲已被翻译成 14 种不同的语言。</sample>
    <sample id="310">通常，每个实例只被少数注释员注释。</sample>
    <sample id="311">根据所给的英文内容，良性和后门数据集之间的差异是通过余弦和L2距离度量来衡量的。</sample>
    <sample id="312">根据所提供的英文内容，基于编码器的多语言模型被用于这项任务，通过使用多语言预训练编码器和基于指针的解码器。这些模型在多种数据集上进行了评估，以确定它们的表现。</sample>
    <sample id="344">作者假设提供者可以收集一个一般文本语料库，并计算单词频率。</sample>
    <sample id="345">大家好，我的名字叫刘Hung。今天我要向大家展示我们的论文：Do Conll 2003 named entity taggers still work well in 2023？让我们开始吧！</sample>
    <sample id="346">我们的论文调查了使用命名实体识别任务或NER任务的泛化问题。</sample>
    <sample id="347">我们观察到，模型已经使用Conole 2003开发了近20年，以开发神经网络。 这自然提出了几个问题。 首先，这些模型能否推广到现代数据？</sample>
    <sample id="348">And when we develop new tags, what is needed for good generalization?</sample>
    <sample id="349">同时，如果我们观察到较差的泛化能力，那么是什么导致了这些模型的性能下降？</sample>
    <sample id="350">为了研究这些问题，我们开发了Conll03+数据集。这是一个我们从路透社新闻中收集的数据集，从2020年收集，并用相同的Conll 2003注释指南进行注释。</sample>
    <sample id="351">我们随后在Cornell 2003上对超过20个模型进行了微调。我们在Cornell 03测试集和Cornell Plus Plus测试集上评估了它们。</sample>
    <sample id="352">最后但不少于 least，我们计算了 F1 的百分比变化来评估每个模型的泛化能力。</sample>
    <sample id="353">So what is needed for a good generalization? Through our experiments, we found that there are three main ingredients that are needed.</sample>
    <sample id="354">第一个是模型架构。通过我们的实验，我们发现 Transformer 模型通常对新数据泛化得更好。</sample>
    <sample id="355">The second ingredient is the model size. We found that usually larger models lead to better generalization.</sample>
    <sample id="356">最后但不少于 foremost，我们知道 fine-tuning 的例子数量直接影响下游任务的表现。这里我们还发现更多的 fine-tuning 示例实际上也导致了更好的泛化能力。</sample>
    <sample id="357">到我们下一个问题，什么会导致某些模型的性能下降？</sample>
    <sample id="358">我们有两个假设。第一个假设是自适应过拟合，即由于多次使用相同的测试集而引起的过拟合。这通常表现为在新测试集上的泛化性能下降。</sample>
    <sample id="359">第二个假设是时间漂移，即由于训练和测试数据之间的时间间隔增加而导致的性能退化。</sample>
    <sample id="360">对于过拟合，我们看到从右边的图表中，红色最佳拟合线的斜率大于1。</sample>
    <sample id="361">这表示，我们在2003年对卡农所做的每一个改进单位，相当于在卡农++上获得超过一个单位的改进，这意味着没有递减的回报。</sample>
    <sample id="362">这表明在这种情况下并没有观察到适应性过度生长。</sample>
    <sample id="363">so what about tempo drift?</sample>
    <sample id="364">对于时间漂移，我们进行了实验，以重新训练或继续预训练一些模型，使用更近的数据，并发现随着时间间隔的增大，性能会下降。</sample>
    <sample id="365">这确认了我们的假设，即主要性能下降的原因是时间漂移。</sample>
    <sample id="366">我们的结论是，为了实现良好的泛化，我们需要更好的模型架构、更大的模型尺寸以及更多的微调示例。这些因素相辅相成，我们不能只依赖其中一个因素，而需要同时考虑所有因素。</sample>
    <sample id="367">同时我们还发现，性能下降是由漂移引起的，而且令人 surprising 的是，它并不是由自适应过拟合引起的，尽管 connell 2003 已经使用了超过 20 年。</sample>
    <sample id="368">回到我们论文标题中提到的问题，即2003年的标签是否仍然在2023年有效？我们发现答案是明确的：是的。</sample>
    <sample id="369">我们希望我们的论文能为如何改进模型泛化能力的研究提供更多的帮助。</sample>
    <sample id="370">最后，请务必查看我们的论文，我们的数据集。 如果您有任何问题，请随时与我联系。 非常感谢！</sample>
    <sample id="397">该方法使用的语音片段大小是16ms。</sample>
    <sample id="398">在 Servin 和 Kea 的示例中，需要特定于实体的知识是 Servin 是一位法官。</sample>
    <sample id="399">示例质量更为重要。</sample>
    <sample id="400">在扩展实验中，论文侧重于GPT-4和BERT系列及其变体。</sample>
    <sample id="401">该模型是使用特定层的注意力分数。</sample>
    <sample id="402">直接推断的示例包括通过说歌曲名称或其位置来直接引用歌曲。</sample>
    <sample id="403">根据所提供的英文内容，论文的作者所属机构是复旦大学。</sample>
    <sample id="404">根据所提供的英文内容，无法确定论文的作者人数。</sample>
    <sample id="405">是的，在语义解析之前，使用机器翻译模型翻译自然语言查询作为基线。</sample>
    <sample id="406">根据所提供的英文内容，作者给出的“显性群体”(marked group) 的示例是将女性战士称为“female warrior”，从而在战士这个默认男性角色上标记了女性。</sample>
    <sample id="407">Transformer模型架构泛化能力较差。</sample>
    <sample id="408">根据所提供的英文内容，测试数据集的名称是“WSL”。</sample>
    <sample id="409">根据所提供的英文内容，这篇论文有三位作者：马查塔、马尔丁和作者自己。</sample>
    <sample id="410">根据所提供的英文内容，无法确定作者是否采用了多种模态。所给句子只提到了一种模型，即多模态预训练模型，并没有明确说明是否使用了其他类型的模型。</sample>
    <sample id="439">根据所给的英文内容，作者认为 NLU 中研究不足的领域包括：1. 研究 NLU 模型在使用预训练知识和推理知识时的表现；2. 评估 NLU 模型在使用预训练知识和推理知识时的性能。</sample>
    <sample id="440">演讲者的名字是Ying。</sample>
    <sample id="441">是的，Coscript 经过了质量检查。</sample>
    <sample id="442">现有的资源只支持有限类型的上下文依赖翻译和有限的语言集，因为它们通常依赖于领域知识和人类校正。</sample>
    <sample id="443">Hi and I'm going to talk about our work on resolving indirect referring expressions for entity selection in which we introduce the alt entities scorer.</sample>
    <sample id="444">我的名字是贾瓦德·侯赛因，这是与菲利普·拉德斯基、西尔维亚·巴特里和安妮·路易丝的联合工作。</sample>
    <sample id="445">我们的目标是理解用户语言，当他们想要做出选择时。考虑这个问题的另一种说法：你是说“轻松一下”还是“我感到很轻松”？这里用户想在两个选项之间做出选择。</sample>
    <sample id="446">最明显的事情是使用直接引用，例如通过说歌曲的名字是“on me”或它的位置，第一首。</sample>
    <sample id="447">But sometimes an indirect reference is more appropriate to have a more natural conversation this would happen when the user cannot remember the name of the song.</sample>
    <sample id="448">All the pronunciations are too similar to each other and hard to disambiguate.</sample>
    <sample id="449">或者用户想指定一个偏好。这里有一些例子，例如直接的偏好：例如，较新的一个或不那么有活力的一个。</sample>
    <sample id="450">这在对话系统中是一个重要的问题，同时也适用于评估LLM的实体理解能力。</sample>
    <sample id="451">We are not aware of a public dataset, a large-scale public dataset for the task. So we collect one using crowd annotation. Our dataset covers three different domains: music, books, and recipes.</sample>
    <sample id="452">我们的数据集收集方法论强调了使用卡通完成任务的随意性。</sample>
    <sample id="453">卡通有三个对话气泡。在第一个气泡里，Bob说：记得昨天我们在听的那首歌吗？然后，在第二个气泡里，Bob设置对话背景。</sample>
    <sample id="454">在第二段演讲中，Alice 说你是轻松对待我，还是我让她感到</sample>
    <sample id="455">Which is the alternative question. And in the third speech bubble, bob uses an indirect reference to select one of these entities, for example, the new</sample>
    <sample id="456">We provide the first and second speech bubbles automatically, but the third one is filled in by the annotator. The first speech bubble is chosen from a few manual prompts per domain.</sample>
    <sample id="457">第二个问题，即备选问题，是这样产生的。</sample>
    <sample id="458">我们总是使用一个简单的模板。你指的是A或B？其中A和B来自维基百科</sample>
    <sample id="459">Here are the different sampling methods we've used when we move higher in the list the entities become more similar to each other and it's usually harder to make the disambiguation.</sample>
    <sample id="460">The first one is uniformed train.</sample>
    <sample id="461">The second one is when the entities have similar titles, for example two books with the name The Return.</sample>
    <sample id="462">第三个则是当它们在维基百科上有类似的描述和最后，当它们在维基百科上有类似的info boxes或属性时，例如相同的流派或相同的艺术家</sample>
    <sample id="463">When we show this alternative question to the amateurs, they know the name of these entities but they don't necessarily know about the entity</sample>
    <sample id="464">所以，我们所做的是展示一些关于这两个实体的背景知识。对于歌曲，我们简单地展示一个Google搜索链接到每个歌曲。</sample>
    <sample id="465">And then ask the annotators to listen to at least some of each song and read about each song Here's for example the Google search result for the song easy</sample>
    <sample id="466">对于食谱和书籍领域，我们显示了来自维基百科的一些背景文本。对于食谱，我们还显示了它们的图片，再次来自维基百科，以便注释者了解它们看起来如何。</sample>
    <sample id="467">Then we ask the annotators to pick one of these entities, for example, here the first one and describe them using three to five indirect referring expressions.</sample>
    <sample id="468">For example, the one with the piano music Here are some examples from our data set For example, the one without words not the one with the twelve year old twelve year old boy or the fictional one or comes from Azerbaijan and so</sample>
    <sample id="469">The Alpaca Corpus has 6,000 alternative questions across three domains and it has 42,000 indirect referring expressions. Results with T5-XXL model are summarized below.</sample>
    <sample id="470">如果语言模型拥有与注释员相同的背景知识，那么准确性会很高，大约在92%到95%之间。但这并不现实。</sample>
    <sample id="471">如果语言模型可以访问一些部分重叠的背景知识，那么准确率在82%到87%之间，这更现实。例如，当语言模型检索背景知识时。</sample>
    <sample id="472">如果语言模型只能访问实体名称，那么准确率只有60％，因此有很多改进的空间。我们还证明了这些模型具有跨领域泛化能力。这是我们的数据集的链接。谢谢</sample>
    <sample id="473">该方法与以下现有的 SimulST 策略进行了比较：预策略、离线模型的 Whitkey 策略和局部算法，以及专门用于 SimulST 翻译的 State-of-the-art 建筑。</sample>
    <sample id="474">根据所提供的英文内容，无法确定论文的作者所属机构。</sample>
    <sample id="475">演讲者的名字是珍妮。</sample>
    <sample id="476">根据所提供的英文内容，这篇论文有三位作者：Maira、Essen Durmush和Dan Juravsky。</sample>
    <sample id="477">嗨，我是Sarah Papi，来自都灵大学和布罗尼科·凯斯勒。我将简要介绍作为 simultaneous speech translation 的指南，这是一篇与马泰奥·内格里和马可·图尔基合作的论文。</sample>
    <sample id="478">What is simultaneous speech translation? Simultaneous speech translation, or simultaneous translation (ST), is the process of translating spoken language into a text in another language in real time enabling cross-language communication.</sample>
    <sample id="479">和当前的神经网络模型一样，特定的架构通常被训练引入额外的模块以进行优化。</sample>
    <sample id="480">Long and complicated training procedures, for example training involving different optimization objectives,</sample>
    <sample id="481">训练和维护多个模型以达到不同的延迟 regimes，例如训练一个模型具有平均1秒延迟和另一个模型具有2秒延迟等等。</sample>
    <sample id="482">So what is our solution?</sample>
    <sample id="483">首先，使用已存在的 offline NLP 模型，而无需重新训练或采用特定架构用于 SimILST。其次，为每个潜在范围使用单一模型，并通过特定参数处理潜在性。</sample>
    <sample id="484">And leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output, that is, the cross-attention mechanism and you can see an example on the right.</sample>
    <sample id="485">我们的解决方案是提出或编码解码注意，这是一种策略，我们决定是否发出或不发出部分翻译，基于注意力指向哪里。</sample>
    <sample id="486">一个词被 emit 如果张力不集中,即其总和低于某个阈值 alpha 向最后一个语音帧,这意味着接收到的信息不够稳定。</sample>
    <sample id="487">For example, if if we receive a speech chunk containing I'm going to talk about and our model predicts the translation in German,</sample>
    <sample id="488">And we will look at the cross attention weights,</sample>
    <sample id="489">我们将看到，前两个参数指向最早接收的语音帧，而最后一个参数指向最新的语音帧，即Lambda语音帧。</sample>
    <sample id="490">这表示前两个词将被省略。</sample>
    <sample id="491">While since the sum of the crossed attention is above a certain threshold alpha we will not emit the last word and wait for another speech chunk</sample>
    <sample id="492">If we go on and we receive another speech chunk and our model predicts other three words, and we will look at the cross attention weights.</sample>
    <sample id="493">我们将会看到，没有一种方式可以指涉到这些 lambert 语言的语义框架。</sample>
    <sample id="494">这表示这些三个单词将被发出。</sample>
    <sample id="495">If you look at the main results of that,</sample>
    <sample id="496">我们将把同时性翻译结果绘制在图表上，在图表中，我们有一侧是蓝色的，表示翻译质量，另一侧是平均得分。</sample>
    <sample id="497">that is the latency measure and we also consider the computational-aware average linking that accounts for the model's computational times to produce the output.</sample>
    <sample id="498">So we want our curve to be as high as possible on this plot.</sample>
    <sample id="499">But also we want that they are shifted on the left.</sample>
    <sample id="500">我们将其与适用于离线模型的流行策略进行比较，这些策略包括 Whitaker 策略和局部算法，并且我们还将其与专门用于实时翻译的现代架构进行比较。</sample>
    <sample id="501">这些是所有德语的同步口译策略的结果。</sample>
    <sample id="502">And we see that a dot outperforms all the strategies applied to offline models, since their curves are shifted over the left.</sample>
    <sample id="503">And we also see that if we consider the actual elapsed time or the computational wait time, that is the fastest strategy.</sample>
    <sample id="504">如果您想发现更多结果，请阅读我们的论文，并且我们还发布开源代码和模型和同时发布输出以方便我们的工作可重复性。谢谢您的关注。</sample>
    <sample id="505">根据所给的英文内容，无法确定数据集是否公开。</sample>
    <sample id="506">Hello everyone, my name is Ying and my colleague Jiaqiang and I will be presenting our research on multi-instruct improving multi-modal zero-shot learning via instruction tuning.</sample>
    <sample id="507">随着大型语言模型的进展，许多工作开始探索使用预训练语言模型进行不同下游任务的新学习范式，在参数和数据效率方面。</sample>
    <sample id="508">最近，许多研究表明，指令调优使大型语言模型能够以简洁的方式通过遵循自然指令来执行任务。</sample>
    <sample id="509">然而，大多数先前的工作专注于提高零样本性能在语言-only任务上，而计算机视觉和多模态任务则被忽视了。</sample>
    <sample id="510">因此，在本工作中，我们想研究是否通过训练单模或多种模型的预训练模型可以实际提高多模任务的泛化能力。</sample>
    <sample id="511">此外，在我们研究期间，我们发现NLP和多模态之间存在相当大的数据集可获得性差距。</sample>
    <sample id="512">There exist more than one thousand and six hundred language-only instruction tasks. However, there is no large-scale publicly available multi-modal instruction task. Therefore, this motivates us to build a multi-modal instruction tuning dataset.</sample>
    <sample id="513">这里我们介绍了MultiInstruct，这是第一个多模态指令调优基准数据集，它包含了62种不同的多模态任务，覆盖了10个主要类别。</sample>
    <sample id="514">这些任务是从21个现有的开源数据集中派生出来的，每个任务都配备了五条专家注释的说明。</sample>
    <sample id="515">为了在我们所提出的数据集中调查多模态调优，我们采用 OFA 作为基础模型。OFA 使用统一的词汇表对语言、图像标记和边界框坐标进行编码。</sample>
    <sample id="516">这里我们展示了一些来自 MultiInstr 数据集的一些示例实例。</sample>
    <sample id="517">要统一处理各种输入和输出数据类型。</sample>
    <sample id="518">我们遵循Matter from OFA，并将所有任务统一格式化为序列到序列格式，在这种格式中，输入文本、图像、说明和边界框都在同一个标记空间中表示。</sample>
    <sample id="519">Okay, now I'm going to talk about multi-modal instruction tuning.</sample>
    <sample id="520">So for the training dataset, we use fifty-three tasks from the NLP group for training and we sample ten thousand instances per task. For testing, we reserve the entire Commonsense Reasoning group for testing and we select additional five tasks from the Wiki and the Miscellaneous group.</sample>
    <sample id="521">We use all the instances in the test split for each task in addition, we randomly sample twenty tasks from the test split of natural instruction as the unseen task for nlp.</sample>
    <sample id="522">So we use a pre-trained LLaMA model as the base model during training. We make all the instances for all the tasks. Each instance is randomly combined with one of its five instruction templates.</sample>
    <sample id="523">During tests for each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.</sample>
    <sample id="524">我们将报告每种性能的最小和最大值以及所有五次实验中性能的标准差。</sample>
    <sample id="525">如果任务是多模态分类任务，我们将报告准确率。如果是多模态生成任务，我们将报告rouge-l。对于nlp任务，我们还将报告rouge-l。</sample>
    <sample id="526">我们还引入了一个额外的评估指标，称为敏感性。这个指标衡量模型在任务中的一致性输出能力，无论输入指令的微小变化如何。</sample>
    <sample id="527">Here is our main results. As we can see instruction tuning can significantly improve or is of as performance on some multi-modal tasks.</sample>
    <sample id="528">也从自然语言数据集中学习的迁移学习可以有助于指令调优。</sample>
    <sample id="529">Here we can see as the amount of task increases, the model achieve better performance and in the meantime lower sensitivity.</sample>
    <sample id="530">So we also did one experiment, we use one instruction versus five instruction. As we can see using more instruction can improve the model's overall performance and reduce its sensitivity a lot.</sample>
    <sample id="531">这展示了不同的调优策略对模型灵敏度的影响。如我们所见，通过从自然图像数据集进行迁移学习，该模型可以比原始的OFA模型达到更高的灵敏度。</sample>
    <sample id="532">We also can see transfer learning from the machine instruction dataset can help our f to achieve much better performance on the machine instruct dataset.</sample>
    <sample id="533">So overall, we propose the first large-scale multi-modal instruction-tuning dataset which significantly improves the zero-shot capability of LLMs and we explore different transfer learning techniques and show their benefits. We design a new metric called sensitivity.</sample>
    <sample id="534">So one more thing. We are collecting a much larger multi-modal instruction tuning dataset with around 150 additional vision-language tasks and we will release them. So this is the QR code for our data and model. Thank you.</sample>
    <sample id="535">根据所给的英文内容，这篇论文的作者所属机构是都灵大学。</sample>
    <sample id="536">演讲者的名字是Javat Hosaini。</sample>
    <sample id="562">大家好，我是Costas Sina，我很高兴欢迎你们参加我们关于ACL2023论文“语言模型接受度判断”一文的讨论。</sample>
    <sample id="563">这是一个与 john gowther, arun muller, ganeshkumar mishra, karen fontis, roger levy 和 edina william 的合作项目。</sample>
    <sample id="564">So in this work, we revisit the minimal pair paradigm.</sample>
    <sample id="565">所以最小的可分语义体基本评估了语言模型在可接受性判断的基础上，这也可以包括语法性，比如拼写、句法等，或者可接受性在 stereotypes 中，比如克劳斯-皮尔。</sample>
    <sample id="566">And in this minimal pair paradigm, the typical way to evaluate language models is that you show like a acceptable sentence or a grammatical sentence and then you show an unacceptable sentence or an ungrammatical sentence.</sample>
    <sample id="567">And then the hope is that the model basically puts more probability to the acceptable</sample>
    <sample id="568">The current mpp pipeline basically doesn't allow us to evaluate models acceptance towards longer sentences.</sample>
    <sample id="569">这些天，大型语言模型正在使用更长的上下文窗口。因此，评估模型在整个上下文窗口中的可接受性至关重要。</sample>
    <sample id="570">And that is what we are trying to do here. We're trying to revisit the NPP pipeline by asking the model to evaluate acceptability on longer and longer sequences.</sample>
    <sample id="571">So that is the approach. So what we do is that we simulate these longer sequences, we revisit the datasets themselves and then we recreate sentences by choosing like acceptable or unacceptable sentences from those datasets.</sample>
    <sample id="572">For example, here we have chosen like a typical pair of grammaticality from the blimp data set from the adjunct island case.</sample>
    <sample id="573">And what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure we extract grammatical sentences from a giant Thailand.</sample>
    <sample id="574">然后我们将其添加为前缀，分别添加到可接受的查询和不可接受的查询中。</sample>
    <sample id="575">我们可以用相同的方法，通过选择匹配中不可接受的句子来实现这一点。这也可以用来测试模型的可接受性。</sample>
    <sample id="576">And we can also do the same by choosing sentences from a different subset or a different data set. So that is what we call as the mismatch scenario.</sample>
    <sample id="577">So here the sentences are still coming from relevant datasets, but it's not from the same dataset that you're evaluating with and we can do the same for unacceptability cases.</sample>
    <sample id="578">Finally, we can choose sentences from a completely unrelated domain such as Wikipedia.</sample>
    <sample id="579">So this will tell us like whether the model's acceptability judgments are actually impacted by any context.</sample>
    <sample id="580">Like whether the context is coming from a different subset of the data set or whether it's like completely irrelevant to the current like to the sentence that we are looking at.</sample>
    <sample id="581">so how does the model do the first we look at the wikipedia sentences which are completely irrelevant to the current query pair and there we find that the mpp judgments are mostly robust for arbitrary context lengths.</sample>
    <sample id="582">我们增加预测长度至2024年，以最大化OP和GPT-2模型。我们在橙色点线中看到，MPP预测相对稳定。</sample>
    <sample id="583">Now what happens when we choose sentences from the same dataset?</sample>
    <sample id="584">So here we are choosing or creating sentences from acceptable and unacceptable domains from the same blimp or syntaxem dataset,</sample>
    <sample id="585">And there we see that the mpp judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable</sample>
    <sample id="586">But when we match the structure, that is when we choose the sentences from the same phenomena in blame person text jim,</sample>
    <sample id="587">我们看到对模型的mpb判断有大规模增加或大规模减少，取决于所选前缀是否可接受或不可接受。</sample>
    <sample id="588">现在，这个和这个是很大的，这个效果在整个上下文链中增加，这可能会对 newer 的语言模型产生影响，这些模型具有大的上下文窗口。</sample>
    <sample id="589">所以，为什么匹配前缀会影响语言模型的判断？</sample>
    <sample id="590">So we did a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure but adding uh like noise to the input and after doing like several of these perturbations,</sample>
    <sample id="591">We find that none of these noises are actually making the model like change it course in terms of how it shows us the nppa has been trying.</sample>
    <sample id="592">Basically, we find that the models are sensitive to the perturbation in sentences in similar ways.</sample>
    <sample id="593">That is, when we perturb the sentences in the acceptable domain, we see similar increase in all the perturbations and when we perturb the sentences in the unacceptable domain, we see decrease in NPP judgments in similar fashion.</sample>
    <sample id="594">所以，我们工作的关键 takeaway是，语言模型对句子间共享的潜在句法和语义特征敏感。</sample>
    <sample id="595">And the MPP evaluation that the way that we do it currently with short and single sentence input may not fully capture the language model's abstract knowledge throughout the context window.</sample>
    <sample id="596">请阅读我们的论文以获取我们实验的更多细节。谢谢您的收听。</sample>
    <sample id="597">该方法的第一步是将输入词元映射到一个无序的多集中包含将在输出中出现的词元的集合。</sample>
    <sample id="598">Coscript 中包含了 55,000 个脚本。</sample>
    <sample id="626">根据所给的英文内容，DEplain 的最佳对齐方法是 DEalign。</sample>
    <sample id="627">弱监督学习的好处是它可以通过训练神经网络来处理有噪声的标签数据，从而提高模型的泛化能力。</sample>
    <sample id="628">根据提供的英文内容，DEplain-web 中的文档采用了手动和自动对齐方法。具体分配情况如下：手动对齐用于标题、表格、列表、注释、脚注、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、脚手架、</sample>
    <sample id="629">CoNLL++数据集是通过从路透社新闻中收集数据并使用与CoNLL 2003标注指南相同的标注来创建的。</sample>
    <sample id="630">Hello everyone, my name is Yusen Zhang from the Penn State University. Today I'm going to present our work: Exemplar Crosslingual Semantic Parsing in Multiple Natural Languages and Vector Representations.</sample>
    <sample id="631">So semantic parsing is a task to build semantic representations of user queries such as SQL and lambda calculus.</sample>
    <sample id="632">And cross-lingual semantic parsing is the task to translate queries in multiple natural languages into multiple meaning representations.</sample>
    <sample id="633">如图所示，我们需要使用神经模型将查询翻译成多种自然语言，例如SQL、Lambda或SQL等。</sample>
    <sample id="634">现有的跨语言同义词解析模型分别提出并评估在有限任务和应用上，例如，</sample>
    <sample id="635">There are lacks of coverage on certain natural language the chinese is missing and</sample>
    <sample id="636">缺乏对某些重要重复事件的覆盖。</sample>
    <sample id="637">大脑小丘脑缺失。</sample>
    <sample id="638">Or they are only evaluated on certain neural models. For example, there is only one single model to evaluate them.</sample>
    <sample id="639">So to this end, we propose Exemplar, a uniform dataset exemplar for cross-lingual semantic parsing in multiple natural languages and meaning representations.</sample>
    <sample id="640">它包含有90个树状结构的词库、5种句法分析技术、8种句法表示和22种自然语言，在15种语言家族中。</sample>
    <sample id="641">为了更好地评估我们的基准，我们考虑了六个用于训练和评估的设置。</sample>
    <sample id="642">第一个是 translate test，我们使用 google translate api 来翻译 source 到 target language，然后使用 monolingual model 来训练和评估。</sample>
    <sample id="643">例如，我们训练了英语模型在英语查询上，并在推理期间使用API将德语查询翻译成英语，然后使用训练的模型来预测结果。</sample>
    <sample id="644">我们将测试多语言模型。</sample>
    <sample id="645">在这个设置中，源语言和目标语言是一样的，例如德语到德语或英语到英语。</sample>
    <sample id="646">我们还测试了单语言两轮设置，通过训练单语言模型仅使用10%的训练数据。</sample>
    <sample id="647">And we test a monolingual multilingual model which we train one multilingual model for all languages.</sample>
    <sample id="648">For example we put the German, English, Chinese queries together to train a multilingual model and during inference we can use this model to</sample>
    <sample id="649">Um, to translate German queries or Chinese query or et cetera.</sample>
    <sample id="650">我们还考虑了零-shot和少-shot转移。我们训练在一种语言上，然后转移到另一种语言。</sample>
    <sample id="651">During training, we train it on English query or the combination of English and German few-shot queries to train a multilingual model to predict the SQL output.</sample>
    <sample id="652">And we also find many interesting results. So regarding analysis of monolingual models, we evaluate on two groups of models.</sample>
    <sample id="653">包括编码器PDR，它代表多语言预训练编码器与基于指针的解码器，例如XLM-R + PDR和BERT + PDR。</sample>
    <sample id="654">And we also evaluate encoder-decoder models which is multilingual pre-trained encoder-decoder models such as mbert and mt5.</sample>
    <sample id="655">我们发现编码器-解码器在所有九个数据集上取得了最佳性能。</sample>
    <sample id="656">And we evaluate on MT5 and example XLMR plus PDR on multilingual setting.</sample>
    <sample id="657">我们发现，编码器-解码器或编码器-PDR可以通过在各种语言的混合中进行训练来改进。</sample>
    <sample id="658">我们发现，大多数主要自然语言都可以获得性能提升，但英语在七个数据集中性能下降，在三个数据集中性能提升。</sample>
    <sample id="659">I think this is known as curse of multilinguality.</sample>
    <sample id="660">我们还比较了跨语言性能差距。</sample>
    <sample id="661">在本图中，蓝色线是跨行期的实值转移。橙色线是跨期零值转移。而绿色线是跨期零值设定。</sample>
    <sample id="662">We found that by comparing the green and orange line, we found that for zero shot setting, the crosslingual transfer performance gap is significant. And by comparing blue and orange line, we found that for few-shot setting, the transfer gap is shortened rapidly.</sample>
    <sample id="663">我们还发现了一些其他有趣的发现。例如编码解码器超过了以往的工作，实现了可比的结果。通过在英语自然语言上训练，并显著提高了Few-Shot在目标自然语言上的性能。</sample>
    <sample id="664">我们发现多语言语言模型，如CodeBERT和BlueBERT，对于跨语言零样本任务仍然不够。</sample>
    <sample id="665">要总结一下，我们创建了一个示例器，一个统一的跨语言语义解析基准，支持多种自然语言和大量代表性。</sample>
    <sample id="666">我们将进行一项全面的基准测试研究，针对三种代表性的多语言模型类型，并且我们的结果展示了许多有趣的发现等等。欢迎访问我们的论文和代码。谢谢您的收看。</sample>
    <sample id="667">根据所提供的英文内容，关于这方面的现有研究可以被广泛地归类为四个类别。</sample>
    <sample id="668">根据所提供的英文内容，Codex或Bloom等多语言LLM对于CLSP来说仍然不够。</sample>
    <sample id="695">该方法通过在训练过程中将排列的对齐作为一部分来处理排列的不确定性。这种方法允许模型找到与数据一致但可能不是最 linguistically correct 的排列，并通过使用一种称为“连续放松”的 GP 友好的技术来解决 NP 完全问题，从而找到得分最高的排列。这种技术还允许模型在解决方案中反向传播并学习更 linguistically plausible 的排列。</sample>
    <sample id="696">根据所给的英文内容，可以将下游 NLP 模型的公平性定义为确保模型在处理不同政治观点和 minority 组织时不会导致偏见或边缘化。</sample>
    <sample id="697">演讲者的名字是Yannis Lavrac。</sample>
    <sample id="698">演讲者的名字是Kostov Sina。</sample>
    <sample id="699">演讲者的名字是Mira。</sample>
    <sample id="700">热带主义 (tropicalism) 意味着将女性描述为具有异国情调、异国情调和异国情调的特征，通常与热带地区相关联。</sample>
    <sample id="701">作者通过使用与文化、传统、骄傲和异国情调等相关的关键词来创建目标群体的人工描写，这些关键词定义了这些群体的身份，并将它们与其他群体区分开来。</sample>
    <sample id="702">在本文中，我们使用了点二c x m i来衡量语境使用情况。</sample>
    <sample id="703">DrBERT 和 ChuBERT 的区别在于它们的训练数据和模型架构。DrBERT 是一个使用 7GB NAOs 训练的模型，而 ChuBERT 则是一个使用 4GB NAOs 训练的模型。此外，ChuBERT 还使用了临床句子作为输入，而 DrBERT 则没有。</sample>
    <sample id="751">根据所提供的英文内容，这篇论文有两位作者。</sample>
    <sample id="752">迭代迁移学习是指通过训练模型来更新模型，以适应最新收集的数据集。</sample>
    <sample id="753">数据集的目标是理解用户在想要做出选择时的语言。</sample>
    <sample id="754">攻击者通过 EaaS 提取模型参数，具体方法是通过可视化嵌入句子的嵌入来验证模型的正确性。</sample>
    <sample id="755">根据所提供的英文内容，这篇论文有三位作者：马修·内格里和马科·图尔基。</sample>
    <sample id="756">根据给定的英文内容，创建初始数据集时使用了10个注释者。</sample>
    <sample id="757">根据所提供的英文内容，论文的作者属于卡内基梅隆大学。</sample>
    <sample id="758">根据所提供的英文内容，以左侧为支配词的示例是“我看到巴顿和李萨”。在这个例子中，Governor被放置在左侧，这表明它是一个支配词。</sample>
    <sample id="759">根据所提供的英文内容，对话系统中的最先进模型是ABC-Eval。</sample>
    <sample id="760">我们需要在整个上下文窗口中评估模型的可接受性，因为这些天来大型语言模型正在采用更长的上下文窗口。</sample>
    <sample id="761">根据所给的英文内容，多语言训练会导致表现下降。</sample>
    <sample id="762">是的，注释者提前知道该实体。</sample>
    <sample id="763">根据给定的英文内容，评估使用了BLEU和METEOR两个MT指标。</sample>
    <sample id="764">是的，回归会影响特定的 NER 类型。</sample>
    <sample id="765">NLP 中的立场很重要，因为它有助于解决技术在不同文化背景和人口中的性能差异问题。通过考虑立场，开发人员可以创建更敏感和包容的模型，能够检测和处理来自各种语言和文化背景的文本。这确保了技术对所有用户都是可访问和有效的，而不仅仅是那些与开发者的立场相似的人。</sample>
    <sample id="766">根据所提供的英文内容，像 BLOOM 这样的多语言 LLM 采用的是适配器微调。这可以从以下句子中看出："我们可以通过使用神经网络模型的适配器微调来翻译查询到多种自然语言，如 CQL、Lambda、SQL 等等。" 这表明 BLOOM 使用了适配器微调技术，而不是完整的微调。</sample>
    <sample id="767">根据所提供的英文内容，他们使用CE模型进行迁移学习。</sample>
    <sample id="768">根据所提供的英文内容，最近用于评估 PaLM 能力的测试集包括 WebText、CIFAR-10、SQuAD、GLUE 和 SuperGLUE。</sample>
    <sample id="769">根据所给的英文内容，作者最终提出了三条建议。</sample>
    <sample id="770">与最强的基线相比，建议的方法获得了1.0到1.5点的收益。</sample>
    <sample id="771">演讲者的名字是Zhu Hong。</sample>
    <sample id="772">是的，论文中的结果和数据集可以作为基准。</sample>
    <sample id="773">根据给定的英文内容，他们在论文中进行了两个较小模型的实验。</sample>
    <sample id="774">OFA</sample>
    <sample id="833">根据所提供的英文内容，这篇论文的作者所属机构是Google Translate。</sample>
    <sample id="834">根据所提供的英文内容，这篇论文的作者所属机构是圣安德鲁斯大学。</sample>
    <sample id="835">根据所给的英文内容，论文分析了德语和英语。</sample>
    <sample id="836">演讲者的名字是Changbing。</sample>
    <sample id="837">在实验过程中研究了两个不同的模型：一个用于生成文档级别的简化，另一个用于生成句子级别的简化。</sample>
    <sample id="838">在 MultiInstruct 中使用的 62 个不同任务中，有 53 个任务用于训练目的，19 个任务用于测试目的。</sample>
    <sample id="839">根据所提供的英文内容，无法确定论文的作者人数。</sample>
    <sample id="840">作者在实验中使用了四个数据集：AG News、Mind、SST-2和Ariramp。</sample>
    <sample id="876">NACHOS 是一个数据集，包含来自 Web 的医学原始数据。</sample>
    <sample id="877">演讲者的名字是Ibilard。</sample>
    <sample id="878">根据所给的英文内容，提示策略对结果有重大影响。</sample>
    <sample id="879">根据所提供的英文内容，无法确定论文的作者所属机构。</sample>
    <sample id="880">根据所提供的英文内容，专家编写的5个指令是：1. 收集大规模多模态指令调优数据集。2. 包含大约150个额外的维吾尔语任务。3. 释放数据和模型。4. 提供用于数据和模型的QR码。5. 感谢收件人。</sample>
    <sample id="881">作者建议使用人类学习路径和已建立的交叉引用分辨率模型来评估数据集。</sample>
    <sample id="882">Hello everyone. My name is Ibilard, and I will be giving a short overview of the paper "Training from Translation: Assessing Strategies and Performance". This is joint work with my colleagues from Google Translate.</sample>
    <sample id="883">Bam是一个拥有540亿参数的大型语言模型，于去年2022年推出。它是在包含780亿个文档的大型文本集合上进行训练的。</sample>
    <sample id="884">在大规模的分发中，它实现了State-of-the-Art并在 hundreds of NLP tasks</sample>
    <sample id="885">在本文中，我们提出了关于大规模语言模型提示的首次系统研究，用于机器翻译。</sample>
    <sample id="886">我们评估了这些模型的迁移能力，使用了EMT社区的最佳实践。这包括使用最新的测试集以避免测试数据与语言模型的训练数据重叠。</sample>
    <sample id="887">And we compared two state-of-the-art systems. So the best performing system is the dwa n t evaluation</sample>
    <sample id="888">我们使用尖端的深度学习和机器学习算法，并且还展示了专家基于人类评估的结果。最后，我们提供了一些关于预选择策略的建议。</sample>
    <sample id="889">Prompting has a big influence on the performance of the of llms for translation as we can see in a simple experiment where we use one-shot prompting and provided two different prompts for a given sentence.</sample>
    <sample id="890">The majority of sentences five hundred and sixteen out of one thousand the difference observed is of more than one blur points.</sample>
    <sample id="891">And this can go in extreme cases up to forty plot points. So it's important to select that good prompting strategy.</sample>
    <sample id="892">In our experiments we evaluate for a fixed shot prompting strategy where we just mark each its sentence that we provide to the system with the language it's in.</sample>
    <sample id="893">In this example here where we perform translation from German into English, the German sentences the source sentences are marked with German colon and the English translations with English colon.</sample>
    <sample id="894">我们发现实际的印刷形式对复写印刷的影响并不大。</sample>
    <sample id="895">它对于零和一 shot 的提示至关重要。当我们像我们的情况一样，使用五 shot 的提示时，与实际的提示形式几乎没有区别。</sample>
    <sample id="896">是的，例子承载了大部分的重量。</sample>
    <sample id="897">The summary of our experimental results is that the example quality is more important than the similarity to the source sentence.</sample>
    <sample id="898">So it's important to select the examples from high-quality translations in particular we compare the selecting prompts from the training data of the turing mt evaluations or the dev data.</sample>
    <sample id="899">dev data is much more curated and with higher quality than the train data, that it's more nice and the results so a better performance when using the dev data.</sample>
    <sample id="900">Nonetheless, specialized state-of-the-art systems have a substantial advantage over the bant translations but bant comes pretty close to a commercial system in our case we chose to avail it with google translate</sample>
    <sample id="901">The insights that we gain from the quantum annealing that we perform using the qubit framework is that the fluency of palm is comparable to state-of-the-art systems but the main difference comes from the accuracy.</sample>
    <sample id="902">In particular the most common error are omission errors.</sample>
    <sample id="903">所以它似乎选择他们来生产更好的理解翻译,有时通过删除句子的一部分,这些部分在翻译中被证明是无用的。</sample>
    <sample id="904">However the style outward category for pan is lower than for the state-of-the-art systems which is an additional signal</sample>
    <sample id="905">That PMP provides really fluent output but still with some problems of accuracy.</sample>
    <sample id="906">And that's it for this really short overview for more details please come my to the full presentation of the paper thank you very much</sample>
    <sample id="907">Hello, I am Dawei, a PhD student at Salzburg University in Germany In this video, I would like to present our recent work Weaker than you think: A critical look at weakly supervised learning</sample>
    <sample id="908">这是与肖宇尘、马锐、李智Stephen和丁世Clark合作的联合工作。</sample>
    <sample id="909">我将从介绍敏捷监督和敏捷超链接开始。</sample>
    <sample id="910">在弱监督中，您不会手动标注数据。相反，我们使用弱标注来源，如简单的启发式规则、知识库或低质量 crowdsourcing，如图所示。</sample>
    <sample id="911">与人类注释相比，机器注释要便宜得多，但它们也很 noisy，这意味着其中一部分注释是错误的。</sample>
    <sample id="912">如果我们直接训练神经网络使用弱标签数据，神经网络倾向于 memorize label noise 并不泛化。</sample>
    <sample id="913">在弱信号增强训练中，训练算法被提出，以 robustly 训练神经网络，以处理这样的噪声，使得训练模型仍然泛化良好。</sample>
    <sample id="914">在最近的工作中，我们使用了WSL。WSL代表Weekly Supervised Learning。一个常见的说法是，人们认为在使用每周标注数据训练模型时，可以实现高精度的测试集。</sample>
    <sample id="915">技术上来说，这个说法并不错，但其中有一个关键点。</sample>
    <sample id="916">这指的是人们假设存在一个额外的干净验证集，用于模型选择。</sample>
    <sample id="917">我们已经停止了这个问题的设定，因为这表明在弱监督学习中需要额外的手工注释。但就像大象在房间里一样，这个必要性经常被忽视。</sample>
    <sample id="918">我们之前提到的步骤是让我们提出三个研究问题。首先，对于WSL是否需要干净的验证数据？或者我们可以使用一个有噪声的验证集吗？</sample>
    <sample id="919">其次，如果需要干净数据或干净数据对于WSL有效运行是强制性的，我们需要多少干净样本？最后，我们是否应该只使用干净样本进行验证，或者是否有更好的方法来利用它们？</sample>
    <sample id="920">我们已经在我们的工作中解决了这些问题，我们的 findings 如下。</sample>
    <sample id="921">First, we find that interestingly recent wsl methods indeed require clean wide-angle samples to work properly.</sample>
    <sample id="922">否则，性能会有很大下降，如图所示。如果不存在干净的验证样本，则训练模型无法泛化到原始的weak标签之外。</sample>
    <sample id="923">意味着训练是徒劳的。</sample>
    <sample id="924">这表明，WSL模型实际上需要干净标注的数据才能正常工作，因此获取干净验证样本的注释成本不应被忽视。</sample>
    <sample id="925">我们的第二个发现是增加干净验证样本的数量将有助于WSL方法实现更好的性能，如图左所示。</sample>
    <sample id="926">通常，我们只需要每类20个样本就可以获得高性能。</sample>
    <sample id="927">But that's not the end of the story because if we either way decide to access clean samples then training on them directly will even achieve better performance.</sample>
    <sample id="928">图右显示了直接应用在干净数据上的微调方法和仅用于验证干净数据的WSL方法之间的性能差异。</sample>
    <sample id="929">As we can see if we have ten samples per class, direct fine-tuning starts to beat wsl approaches.</sample>
    <sample id="930">最后，前几篇WSL论文中声称的性能改进可以通过允许在干净验证样本上继续微调来轻松实现。</sample>
    <sample id="931">如图所示，瓦尼纳模型FTDW最初在更复杂的WSL方法（如余弦）面前表现不佳。</sample>
    <sample id="932">However, if we allow to continue fine-tuning on the clean samples then ftw performs equally well as other</sample>
    <sample id="933">所以，在实践中，没有理由选择更复杂的wsl方法，因为它们需要更多的计算时间和磁盘空间。</sample>
    <sample id="934">总之，我们展示了最近的WSL方法需要干净、手动注释的样本才能正常工作。它们的性能和实用性被严重高估了。</sample>
    <sample id="935">我们的具体建议如下。</sample>
    <sample id="936">首先，报告模型选择标准。例如，报告如果模型选择是否基于清洗验证样本。</sample>
    <sample id="937">第二，WSL 模型应该与预训练的基线模型进行比较，以评估其性能。第三，持续微调是一种简单而强大的基线模型，应该在未来的WSL工作中考虑。</sample>
    <sample id="938">Finally, we have open-sourced our code. You can find it where the QR code on this slide points to. Please feel free to check it out. Thank you and enjoy the conference.</sample>
    <sample id="939">对话系统的常用评估方法是使用人类评估，例如，请人类裁判员选择两个对话中哪个更好或对给定的李克特尺度评分对话。</sample>
    <sample id="940">根据所提供的英文内容，这篇论文有五位作者。</sample>
    <sample id="941">在 Servin 和 Kea 的示例中，需要的背景知识是“Judge”这个角色通常在法庭上决定案件。</sample>
    <sample id="942">代码是公开的，可以在GitHub上获取。</sample>
    <sample id="943">根据所给的英文内容，无法确定 NLPositionality 的注释者在各个人口统计学特征（如国家/地区、性别等）方面是否均衡。所给的句子仅提到了与拥有大学或研究生院教育的人群的额外一致性，而没有提供有关人口统计学分布的信息。要评估均衡性，需要有关 NLPositionality 注释者人口统计学特征的具体数据。</sample>
    <sample id="944">在可接受的域中扰乱句子，我们看到所有扰动的增加。</sample>
    <sample id="945">进行维度评估意味着评估对话质量的多个方面，以更好地理解模型的优点和缺点。</sample>
    <sample id="946">根据所提供的英文内容，论文的作者来自中国科学技术大学。</sample>
    <sample id="947">根据所给的英文内容，提示的形式很重要，特别是在零和一 shot 提示的情况下。</sample>
    <sample id="978">根据所提供的英文内容，作者评估了几个对话模型。然而，没有具体提到这些模型的名称或类型。他们专注于评估这些模型的可靠性、信息性和独特性，以通过ABC-Eval度量来评估对话AI。</sample>
    <sample id="979">根据提供的英文内容，无法确定论文的作者人数。</sample>
    <sample id="980">根据所给的英文内容，优秀规划器的理想品质是编写合理的和符合约束条件的脚本。</sample>
    <sample id="981">根据所给的英文内容，无法确定这篇论文有多少位作者。</sample>
    <sample id="982">演讲者的名字是Wasudha。</sample>
    <sample id="983">根据所提供的英文内容，无法确定作者Adam Szyrkowski所属的机构。</sample>
    <sample id="1021">PaLM 最常见的错误是 omission errors。</sample>
    <sample id="1022">Hello, I'm James Finch and I'm Sarah Finch and today we'll tell you all about ABC-Eval, a new dimensional approach to evaluating conversational AI.</sample>
    <sample id="1023">这项工作是由埃默里NLP实验室的吉诺·乔伊教授领导的，该实验室位于埃默里大学，并与亚马逊Alexa人工智能合作完成。</sample>
    <sample id="1024">但让我们假设你刚刚开发了一个对话模型，你想看看它与当前的前沿技术相比表现如何。</sample>
    <sample id="1025">常见的做法是使用人类评估，例如通过请人类裁判选择哪两场对话更好或对对话进行评分。</sample>
    <sample id="1026">这些方法可以用来提供对话质量的整体评估，但对话质量有许多方面。因此，你可能需要在更精细的水平上评估聊天质量的多个维度，以了解模型的优点和缺点。</sample>
    <sample id="1027">一种方法是简单地请人类裁判员评估对话质量的几个维度，如模型回复的相关性，使用现有的比较或李克特尺度方法。</sample>
    <sample id="1028">然而，我们相信有一个更精确和可靠的策略来进行维数对话评估。</sample>
    <sample id="1029">我们的方法旨在通过明确说明每个模型响应是否表达某些行为，如提供无关信息或自相矛盾的行为，来减少人类评估的主观性。</sample>
    <sample id="1030">我们称这种方法为在聊天中注释行为或ABC-Eval的简称。我们开发了这种方法，以全面覆盖最近文献中建议会影响聊天质量的聊天模型行为。</sample>
    <sample id="1031">ABC-Eval 可以衡量聊天模型犯各种主题错误的速度。</sample>
    <sample id="1032">例如，ABC-Eval衡量的是聊天模型在多少轮中忽略了它的伙伴或说了一些 irrelevant 的内容。</sample>
    <sample id="1033">与自身或其伙伴相矛盾，扭曲错误事实或违反常识知识，并且当模型成功或失败时表现出同理心。</sample>
    <sample id="1034">为了确定哪种评估方式最有效，我们选择了四个最新的聊天模型，并使用ABC-Eval评估了每个模型在100个人类对话中的表现。</sample>
    <sample id="1035">为了比较，我们还使用了三种现有方法评估这些对话：针对转码水平的李克特评分、针对对话水平的李克特评分和对话水平配对比较。</sample>
    <sample id="1036">对于每个现有的方法，我们收集了关于对话的八个最常衡量方面的评估，因为这是评估聊天模型的标准做法，沿多个维度进行。</sample>
    <sample id="1037">从我们对这些评估结果的分析中，我们发现ABC行为标签总体上比现有方法收集的标签更可靠，如通过100个双重标注对话的内在标注者一致性来衡量。</sample>
    <sample id="1038">此外，ABC-Eval标签比现有方法产生的指标更预测总体对话质量，如简单的线性回归分析所示。</sample>
    <sample id="1039">例如，您可以看到测量与自我和同伴矛盾的论点的比例解释了五分之一和十分之一的对话质量，而平均利克特一致性得分仅解释了四分之一或更少。</sample>
    <sample id="1040">最后，我们检查了每个评估指标是否能捕捉到对话质量的一个独特方面，使用逐步线性回归。</sample>
    <sample id="1041">你可以看到，所有ABC-Eval指标的组合解释了超过25%的对话质量。当你一次移除一个指标时，大多数指标都会导致失去大量关于质量的信息。</sample>
    <sample id="1042">另一方面，所有Turn级别Lickert量表的组合解释了较少的质量，并且较少的这些量表携带独特信息。</sample>
    <sample id="1043">这些可靠的、信息丰富且独特的ABC-Eval元度量使我们能够以比以往任何方法都能实现的更高分辨率来评估对话型AI。</sample>
    <sample id="1044">你可以看到，在我们实验的结果中，有几个挑战仍然存在，并且已经被精确量化。例如，我们测试的聊天机器人在其响应中大约有20%的Common Sense violation。</sample>
    <sample id="1045">他们会在大约15%的回应中产生无关信息，并且他们会在大约10%的时间内互相矛盾或与他们的伙伴矛盾。</sample>
    <sample id="1046">随着该领域的快速发展，许多错误率可能会在新模型发布以来下降。然而，这更加强调了追求可靠和准确的评估指标的重要性，用于比较模型。</sample>
    <sample id="1047">我们希望ABC-Eval可以被其他领域的其他人利用，作为在这个方向上的一个重要步骤。我们期待看到在接下来的几个月和几年里，对话型AI将如何 advancement。谢谢您的观看。</sample>
    <sample id="1048">根据所给的英文内容，这篇论文的作者所属机构是Emory University。</sample>
    <sample id="1049">在所提供的英文内容中，CFT 代表“持续微调”，这是一种机器学习技术，涉及在训练过程中不断调整模型的参数。它被推荐为未来工作的简单而强大的基线。</sample>
    <sample id="1050">根据所提供的英文内容，这篇论文共有六位作者。</sample>
    <sample id="1051">Hello, my name is Kaiyuan and I will be presenting our work titled When does translation require context? A data-driven multilingual exploration This work was done in collaboration with Patrick Franasz, Emil Niu, Andrea F. Martinez, and Graham Neubig.</sample>
    <sample id="1052">所以，许多翻译取决于上下文。例如，在这个句子中，我们会怎么翻译“more”？</sample>
    <sample id="1053">如果前一个句子是“如果部长们发现了，事情可能会变得危险”，那么more指的是一个暗号。但如果前一个句子是“医生，这会有什么严重的后果吗？”那么more指的是胎记。</sample>
    <sample id="1054">So depending on context, the meaning of the word changes and therefore its translation changes as well.</sample>
    <sample id="1055">然而，评估模型在处理这种情况下的表现如何非常困难。首先，因为只有很少一部分翻译依赖于上下文，使得语料库级别的指标如 BLEU 无法捕捉这些翻译。</sample>
    <sample id="1056">一些人建议对依赖上下文的翻译进行有目标的评估，但这些资源只支持有限类型的依赖上下文的翻译和有限的语言集，因为它们通常依赖于领域知识和人工校正。</sample>
    <sample id="1057">在这项工作中，我们试图回答这两个问题：首先，翻译是否需要上下文？其次，模型在这些情况下表现如何？</sample>
    <sample id="1058">为了回答第一个问题，我们首先通过测量一个词在不同翻译语境中依赖多少来开始。</sample>
    <sample id="1059">在之前的工作中，我们引入了条件xmi作为机器翻译模型中上下文使用的衡量标准。 这是通过测量上下文c为给定源x时关于目标y提供了多少信息来实现的。</sample>
    <sample id="1060">你可以把SXMI看作是给模型提供上下文所获得的信息。</sample>
    <sample id="1061">在本工作中，我们将 cxmi 扩展到 pointwise cxmi，可以衡量句子或单词级别的上下文使用。我们可以将具有高 cxmi 的单词视为需要上下文进行翻译的单词。</sample>
    <sample id="1062">现在我们用高维空间来分析单词，以查找这些单词之间的模式。</sample>
    <sample id="1063">And we perform our analysis on transcripts of ted talks that have been translated from english to fourteen different languages.</sample>
    <sample id="1064">我们将在三个不同的层次上进行我们的分析。首先，我们查看具有高PSXMI的语音片段。</sample>
    <sample id="1065">这使我们能够找到例如阿拉伯语中的复数名词，这些名词具有特定的hi p6mi，并且这可以解释为英语没有复数名词，因此需要上下文来确定一个名词是否是复数，当翻译成阿拉伯语时。</sample>
    <sample id="1066">And similarly, we find that certain languages also require context when we want to choose the appropriate verb form. We then look at vocabulary items that have high p-sexism averages over all of its different occurrences.</sample>
    <sample id="1067">And this helps us identify cases like the one here where in Chinese you need context to translate proper nouns to make sure that you're using the same translation within the document.</sample>
    <sample id="1068">And similarly, we find that context is supported to translate in the right formality.</sample>
    <sample id="1069">And finally, we look at different at individual tokens that have high psexmi and this allows us to identify phenomena that cannot really be captured by the word itself but that's rather expressed in the instant structure such as ellipse resolution.</sample>
    <sample id="1070">现在我们使用分析结果来设计一种文档级别的翻译基准。</sample>
    <sample id="1071">对于我们识别的五个 discourse 现象，我们创建了标签，以自动识别与现象相关的单词。我们称这些标签为多语言 discourse 意识或 MuDa 标签。</sample>
    <sample id="1072">We can then also note that different languages have different proportions of these discursive phenomena.</sample>
    <sample id="1073">我们接着使用muda tagger通过将标记应用在我们要用于评估的平行语料库上，并在muda tagger识别出的领域特定示例上应用我们选择的翻译度量。</sample>
    <sample id="1074">And finally, we use our benchmark as well as other metrics to evaluate different models on the document-level machine translation.</sample>
    <sample id="1075">首先，当我们使用 corpus level metrics 时，对于蓝色，我们发现基于图的模型具有最佳性能。</sample>
    <sample id="1076">But then if we use comet, context-aware models perform best and if we use word f-measure, then models with or without context have comparable performance.</sample>
    <sample id="1077">这再次证明了，如果我们只使用语料库级别的指标，就很难确定最佳的文档级别翻译系统。</sample>
    <sample id="1078">现在我们使用mooda基准来评估模型，并发现基于上下文的模型在处理某些 discourse 现象时，如正式性和词汇连贯性，比不使用上下文的模型更准确。</sample>
    <sample id="1079">But these models are not much better than models that do not use context on other phenomena like ellipsis, pronouns and verb form. So this sort of suggests where we would need to see more progress for document-level translation.</sample>
    <sample id="1080">我们还比较了不同的商业系统，我们的基准测试显示，DeepL通常比Google Translate更准确地进行文档级别翻译。</sample>
    <sample id="1081">要总结一下，我们对14种语言对进行了数据驱动的分析，以确定何时翻译需要背景。</sample>
    <sample id="1082">然后我们使用这些发现来建立一个基准，用于文档级别的机器翻译，这可以帮助我们确定哪些 discourse 原理模型可以处理好或不好，以及哪些翻译系统在文档级别翻译方面表现良好。</sample>
    <sample id="1083">谢谢您专心听取。祝您一切安好。</sample>
    <sample id="1084">演讲者的名字是Yusen Zhang。</sample>
    <sample id="1121">根据所提供的英文内容，没有明确指定新方法的名称。因此，答案是没有名称。</sample>
    <sample id="1122">作者描述“显性词汇”(marked words) 方法为一种识别区分标记群体和未标记群体的单词的方法。</sample>
    <sample id="1123">根据所给的英文内容，这篇论文的作者所属机构是美国华府大学。</sample>
    <sample id="1124">第一个提到的对称依存关系结构的名称是'Prague approach'。</sample>
    <sample id="1125">演讲者的名字是James Finch和Sarah Finch。</sample>
    <sample id="1126">根据所提供的英文内容，这篇论文有四位作者。</sample>
    <sample id="1127">根据所提供的英文内容，可以用于测试句法现象的数据集包括GigaWord、GigaWord和GigaWord。</sample>
    <sample id="1161">根据所提供的英文内容，第一个研究问题的五种方法的缩写是WSL。</sample>
    <sample id="1162">该模型在11个生物医学和临床任务上进行了评估。</sample>
    <sample id="1226">CamemBERT 最初是在四GB的子集上训练的。</sample>
    <sample id="1227">演讲者的名字是Adam Strykowsky。</sample>
    <sample id="1228">根据所提供的英文内容，导致时间漂移是性能下降的主要原因的结论的发现是：通过实验重新训练或继续预训练一些模型时，使用更近的数据，我们发现随着时间间隔变大，性能会下降。这证实了我们的假设，即时间漂移是性能下降的主要原因。</sample>
    <sample id="1269">在第二步中使用另一个模型来预测排列以将词元放入正确顺序，因为尽管我们拥有所有正确的词元，但它们没有被排序。</sample>
    <sample id="1270">根据所给的英文内容，作者建议模型所有者应提高偏见缓解方法的透明度，以更好地了解这些方法的效果，并确保它们是有效的。</sample>
    <sample id="1271">最小对不可接受输入是指在评估语言模型时使用的最小对 paradigm。在这种 paradigm 中，模型被展示一个可接受的句子或语法正确的句子和一个不可接受的句子或语法错误的句子。模型的目标是将更多的概率分配给可接受的句子。</sample>
    <sample id="1272">作者使用了准确率和困惑度来评估他们的实验结果。</sample>
    <sample id="1273">使用了注释者之间一致性的指标是“内在注释者一致性”，这是通过分析100场双重标注对话来衡量的。</sample>
    <sample id="1274">维基百科</sample>
    <sample id="1275">根据所提供的英文内容，无法确定论文的作者所属机构。</sample>
    <sample id="1276">MultiInstruct 与所提到的基准不同之处在于它是一个大规模的多模态指令调优数据集，目前没有其他类似的大规模多模态指令调优数据集。</sample>
    <sample id="1277">根据所提供的英文内容，这篇论文有两位作者：James Finch和Sarah Finch。</sample>
    <sample id="1278">根据给定的英文内容，二进制协调的定义是通过测量字符长度来确定单词的音节结构。</sample>
    <sample id="1279">根据提供的英文内容，无法确定提示语的平均长度。</sample>
    <sample id="1280">这些发现表明较小的 T5 模型可以生成高质量的文本，这表明它们可能在某些任务上与较大的模型一样有效。</sample>
    <sample id="1281">Hi, I am Manish Lavakar and I will present you our work on Dr. Bert, a robust pre-trained model in French for biomedical and clinical domain.</sample>
    <sample id="1282">在本演示中，我们首先讨论语言建模在 healthcare 中的应用。然后我们将展示我们论文的主要贡献。</sample>
    <sample id="1283">我们介绍了第一个生物医学模型在法语中称为Dr. Bert，它是基于Roberta训练的，Roberta是一个大规模的医学文本数据集。</sample>
    <sample id="1284">我们还引入了具有多种预训练设置和数据源的模型比较。然后，我们在法国的11项生物医学和临床 downstream 任务上展示了我们的结果。</sample>
    <sample id="1285">And finally, we conclude about the experiments and give you more details about how to access to the models.</sample>
    <sample id="1286">自2018年发布以来，BERT已成为解决自然语言处理任务最有效的方法之一，并在与历史上的静态和概念化方法（如Word2Vec、FastText和Word）相比提供了巨大的性能提升。</sample>
    <sample id="1287">Since then, this model has been adapted to many other languages, like in French with Camembert and other domains like biomedical with PubMed and BioBERT and on clinical with ClinicalBERT but mostly in English.</sample>
    <sample id="1288">Specialized models for other languages are scarce and are often based on continual pretraining due to the lack of in-domain data.</sample>
    <sample id="1289">然而，French 并没有为生物医学提供任何开源现代。</sample>
    <sample id="1290">我们问自己关于什么是最适合广泛用途的数据来源的问题。这些公开数据是临床数据的良好替代品。</sample>
    <sample id="1291">为了解决这个问题，我们将比较我们的bert模型和我们自己的shubert模型，该模型基于从我们医院的非大学医院获得的匿名化数据。</sample>
    <sample id="1292">随后，我们问自己需要多少数据来训练一个专门针对法语数据的模型。是4GB、8GB还是更多？</sample>
    <sample id="1293">为了回答这个问题，我们首先训练和比较了两个从头开始的模型：一个使用7GB数据集的first版本的Doctor Bert，一个使用4GB子集数据集的second版本的Doctor Bert。</sample>
    <sample id="1294">First version of Shubert which is a clinical model with four gigabytes of sentences taken from clinical notes and a final version of Shubert with a mix of four gigabytes subset of natasha and four gigabytes of clinical notes.</sample>
    <sample id="1295">除了这种比较外，我们还引入了三种基于连续预训练的模型来分析预训练策略的影响。</sample>
    <sample id="1296">一种是根据卡门贝的重量训练，每次训练使用四公斤的牛排，另一种也是根据卡门贝的重量训练，但这次是使用四公斤的克林纳牛排。</sample>
    <sample id="1297">And finally one based on english biomedical model per berman bert and trained on four gigabytes subset of natures. in total we have seven models.</sample>
    <sample id="1298">为了评估我们的七种模型，我们将使用各种公共和私人数据集任务，如命名实体识别、分类、部分语音标注和问答。</sample>
    <sample id="1299">这些模型与六个基准模型进行比较，分别是卡门伯尔奥斯卡108GB、卡门伯尔奥斯卡4GB、卡门伯尔西西尼特4GB、 plummetbert、mybert 和 clinicalbert。</sample>
    <sample id="1300">评估模型在与训练数据相同类型的数据上表现最佳的能力。</sample>
    <sample id="1301">However, we can obtain the data from we can observe that data from heterogeneous sources appear to be more versatile we also observe that using more data translate into better performance.</sample>
    <sample id="1302">In general, scratch pre-training seems to obtain higher performance on most of the tasks.</sample>
    <sample id="1303">However, our experiment on continual pre-training using the weight and tokenizer of Pima-Beer trained on the four-gigabyte subset of Natsos shows comparable results to those obtained with Dr. Beer's four gigabyte from scratch.</sample>
    <sample id="1304">这在使用卡门伯权重和Tokenizer的模型中不是问题，因为它们存在稳定性问题。</sample>
    <sample id="1305">Finally, as a conclusion our proposed system offers better performance on nine of the eleven dnd tasks and surpass globally the result of the generative model here camembert.</sample>
    <sample id="1306">We also observe that specialized data is better, more specialized data is better, but it doesn't scale well.</sample>
    <sample id="1307">All the pre-trained models obtained from nats are freely available and on huggingface, and all the training scripts are on our github repository.</sample>
    <sample id="1308">So thank you for for this presentation and we are looking forward to exchange at the post session in toronto.</sample>
    <sample id="1309">论文研究了以下学习策略：1. 从头开始训练和比较四个模型，包括一个使用7GB数据集的DoctorBERT版本、一个使用4GB数据集的DoctorBERT版本、一个使用4GB临床句子的Shubert版本，以及一个结合4GB数据集和4GB临床句子的Shubert版本。2. 使用三种在连续预训练上训练的模型来分析预训练策略的影响。</sample>
    <sample id="1310">根据所给的英文内容，由于测试重复使用而导致的过拟合因素似乎很小。这可以从红色最佳拟合线的梯度大于1来证明，这意味着在训练集上每单位改进在测试集上转化为超过一个单位的改进。这表明模型在训练和测试数据之间表现良好，并且没有明显的过拟合迹象。</sample>
    <sample id="1311">根据所给的英文内容，简化质量是通过比较简化后的文本与原始复杂文本的分数来评估的。这些分数作为实验的基准，表明了模型在简化文本方面的性能。</sample>
    <sample id="1312">是的，语言模型有政治偏见。</sample>
    <sample id="1313">嗨，我的名字是马提亚斯·兰德曼。今天我要给你一个关于我们的论文的简要介绍，论文的主题是“没有树的组合泛函化，使用多集标记和潜在排列”。</sample>
    <sample id="1314">这是与我的顾问亚历山大·科拉和伊万·季托夫合作的共同努力。</sample>
    <sample id="1315">组合性泛化能力可以被理解为学习者处理在训练期间看到过的单独短语的更深层次递归和看不见的组合的能力。</sample>
    <sample id="1316">在语义解析的背景下，测试组合性概括可能看起来像这样：如往常一样，我们有一个训练集的句子，在这种情况下，这个女孩睡了，而梅里知道这个女孩睡了。</sample>
    <sample id="1317">这些 utterances are paired with logical forms that represent core aspects of their meaning.</sample>
    <sample id="1318">与标准机器学习评估不同，测试集不来自相同的分布，但包含结构上不一致的逻辑形式。</sample>
    <sample id="1319">在这个例子中，模型在训练期间遇到了较浅的递归，但在一个具有更深递归的示例上进行了测试。</sample>
    <sample id="1320">naive sequence-to-sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.</sample>
    <sample id="1321">在具体情况下，它们往往无法再现输入和输出之间的系统对应关系，例如在示例中用颜色编码的那些。</sample>
    <sample id="1322">一种常用的解决方法是将树融入模型中。</sample>
    <sample id="1323">树木旨在捕捉与逻辑形式相关的表达过程。</sample>
    <sample id="1324">这很好，但树木通常不被给予，需要以某种方式获取。</sample>
    <sample id="1325">这可以是一个复杂且有时计算昂贵的过程。通常，这涉及大量的形式化特定预处理逻辑形式，例如处理变量符号。</sample>
    <sample id="1326">获取树也可能涉及特殊的语法插入过程。</sample>
    <sample id="1327">在这篇论文中，我们不使用树，并引入了一个序列到序列模型，该模型直接建模了输入和输出片段之间的对应关系。</sample>
    <sample id="1328">For the first time, we show strong generalization to deeper recursion without relying on trees.</sample>
    <sample id="1329">我们的方法预测了从输入到输出的两步过程。</sample>
    <sample id="1330">首先，我们为每个输入标记一个无序的多集，其中包含将在输出中出现的标记。</sample>
    <sample id="1331">After the first step we have all the right tokens but they are not ordered.</sample>
    <sample id="1332">That's why in the second step we use another model to predict a permutation to put them into the right order.</sample>
    <sample id="1333">我们引入了一种新方法，用于预测一种排列，该排列不给可能的排列施加任何硬约束。这使我们的方法相当灵活和表达性。</sample>
    <sample id="1334">概念上，我们的排列模型大致像这样。</sample>
    <sample id="1335">我们从左到右遍历输出，并确定在每个位置放置哪个多集标记。对于第一个输出位置，我们简单地选择一个，如红色高亮显示的那样。</sample>
    <sample id="1336">然后我们跳到下一个多集标记以确定输出中的第二个标记。</sample>
    <sample id="1337">我们以类似的方式确定输出中的第三个标记，通过跳转到另一个多集标记。我们继续这个过程。</sample>
    <sample id="1338">直到第一阶段的每一个标记都被访问过一次。</sample>
    <sample id="1339">为了给你一个实验结果的预告，这里我们比较了我们的方法与其他树状模型在cogs基准上的表现。我们的模型在泛化到更深层次的递归时比其他模型表现出更大的优势。</sample>
    <sample id="1340">其他一些结构的泛化仍然非常具有挑战性。</sample>
    <sample id="1341">在我们的论文中，我们解决了几个有趣的 技术挑战。</sample>
    <sample id="1342">首先，输入和输出之间的对齐在训练数据中没有给出。因此，对于给定的标记，我们不知道它来自哪个多头，这为训练提出了挑战。</sample>
    <sample id="1343">此外，有时存在多个排列方式与数据一致，但语义上正确的排列方式是延迟的。我们通过将对齐作为训练的一部分来解决这个问题。</sample>
    <sample id="1344">我们的排列方法非常灵活，但它带来了挑战：找到最高得分排列是np困难的。这是因为这与旅行商问题有关。</sample>
    <sample id="1345">我们用GPU友好的连续放松来近似这个，它还允许我们在解决方案中反向传播并学习更 linguistically 可接受的排列组合。</sample>
    <sample id="1346">如果您想了解我们实验以及我们如何应对这些挑战，请查看我们的论文或来到海报。</sample>
    <sample id="1347">认知失调是指两种相互冲突的信念或行动。</sample>
    <sample id="1348">根据所给的英文内容，GPT-4是最倾向于自由派的语言模型。</sample>
    <sample id="1349">根据所提供的英文内容，累积训练在主动学习时与迭代训练一样有效或更有效。</sample>
    <sample id="1350">演讲者的名字是Sarah Papi。</sample>
    <sample id="1351">MuDa基准中的数据是从TED Talks的转录中获得的，这些转录已经翻译成14种不同的语言。</sample>
    <sample id="1385">演讲者的名字是Mathias Lendemann。</sample>
    <sample id="1386">跨语言转移是指在一种语言中训练模型，并将其应用于另一种语言的过程。</sample>
    <sample id="1387">根据所给的英文内容，这篇论文的作者所属机构是索尔兰特大学。</sample>
    <sample id="1388">根据所给的英文内容，作者使用了翻译质量和模型计算时间的延迟测量方法。</sample>
    <sample id="1389">Hello everyone. I'm Manjata, and today my colleague Martin and I are presenting our work called KipMustE - evaluating knowledge integration from multiple sources. This work is a collaboration between McGill University, Mila, and Microsoft Research.</sample>
    <sample id="1390">国家语言理解模型依赖于各种知识来源，如参数中包含的知识，通常通过预训练获得，以及在推理时输入给定的知识。</sample>
    <sample id="1391">最近的研究表明，模型可以通过使用预训练的通用知识来解决任务，例如问答。</sample>
    <sample id="1392">但自然语言理解往往需要在推理时提供的知识。</sample>
    <sample id="1393">例如，在句子中，John在电视上看见了新当选的总统。</sample>
    <sample id="1394">预训练参数可以包含关于谁是总统和电视是什么的信息，但它们不能可靠地知道这个特定实体John是谁或新的总统是谁，因为总统自预训练以来可能已经改变了。</sample>
    <sample id="1395">因此，对于知识密集型NLU任务的成功模型需要具备整合和使用预训练时间和推理时间知识的能力。</sample>
    <sample id="1396">在这项工作中，我们提出了一个诊断测试套件，用于知识整合。</sample>
    <sample id="1397">我们引入了一个引用分辨率任务，旨在评估从不同来源获取知识的能力。我们使用具有人类学习路径的数据库，并建立引用分辨率模型。</sample>
    <sample id="1398">Here is an example from our data set. Tervin is a judge. Kia is a baker. Tervin and Kia met at a park after a long day at work, deciding cases in a law court. He was happy to relax.</sample>
    <sample id="1399">这里的任务是确定代词 he 所指的正确实体，在这种情况下是 servant。</sample>
    <sample id="1400">The resolution of a given pronoun requires two types of information first entity-specific knowledge such as serville is a judge and second background knowledge such as judges decide cases in law courts.</sample>
    <sample id="1401">一般而言，背景知识是在大型语言模型的预训练过程中学习的，而实体特定知识通常是在推理阶段观察到的。</sample>
    <sample id="1402">我们改变这些两组信息的可获得性，使得它要么可以在单一来源中找到，要么可以在多个来源中找到。</sample>
    <sample id="1403">我们已经定义了三个KimMoos设置。首先，我们有Tobii设备背景预训练，其中背景知识被认为在预训练时间可用。</sample>
    <sample id="1404">第二，存在背景知识的两种设置：在预训练时间和推断时间都可以获得背景知识。最后，存在背景知识的推断设置：在推断时间，两种知识类型都可获得。</sample>
    <sample id="1405">这个最后一个设置尤其有趣，因为它模拟了这样一个情况：在解决任务时所需的背景知识并不包含在预训练数据中，例如，因为自预训练以来已经出现了新的职业。</sample>
    <sample id="1406">Here's an example of how we control the availability of effects in two sources.</sample>
    <sample id="1407">在背景预训练设置中我们假设背景知识“政治家寻求当选政府职位”包含在预训练参数中。在特定领域背景下，我们提供特定知识“杰奇逊是一名政治家”。</sample>
    <sample id="1408">在背景和背景设置中，我们通常提供不仅具有针对性，而且还有关于政治人物在受难背景下的知识。</sample>
    <sample id="1409">在背景的 inferiority setting 提供的 fictional occupation meritocracy 而不是 politician,因为 meritocracy 是 unlikely to be contained in the pre-train paratry.</sample>
    <sample id="1410">我们评估了数据集，既包括人类学习参与者，又包括已建立的高质量分辨率模型。在这幅图中，我们展示了在最困难的背景预训练设置中表现最好的模型的结果。</sample>
    <sample id="1411">Without task-specific training on Kidmos both models do not perform well when trained on Kidmos however both c2f and build for qf perform significantly better than the random choice.</sample>
    <sample id="1412">这表明，当训练在常规超分辨率数据集上时，模型学会利用表面线索，而这些线索在测试时被删除。</sample>
    <sample id="1413">额外的经验表明，即使最好的模型也不能可靠地整合反馈知识，只能在推断时间。</sample>
    <sample id="1414">要总结我们论文的主要 takeaway。许多可加权的进化模型似乎无法在没有任务特定训练的情况下从不同来源整合知识。然而，通过任务特定训练，某些模型成功地将知识整合到多个来源中。</sample>
    <sample id="1415">仍然，即使最好的模型似乎在仅在推理时间呈现的可信赖的背景知识方面存在困难。 如果您对更多细节感兴趣，请参阅我们的论文并查看数据集和代码在 GitHub 上。 谢谢您的收听。</sample>
    <sample id="1416">基于树的方法的一个缺点是它们通常需要复杂的预处理和专门的语法注入过程，这可能是一个昂贵的计算过程。</sample>
    <sample id="1417">根据所给的英文内容，无法确定这篇论文的作者所属机构。</sample>
    <sample id="1418">嗨，我是马Ra，今天我们将讨论我们关于标记人物的论文，使用自然语言提示来衡量语言模型中的刻板印象。这项工作是在与Essen Durmus和Dan Jurafsky合作完成的。</sample>
    <sample id="1419">在 recent years, many have documented the prevalence of social bias and stereotypes in large language models or llms.</sample>
    <sample id="1420">然而，这些措施有各种限制。它们通常依赖于手工构建的数据集，这些数据集非常耗时才能整理。</sample>
    <sample id="1421">他们通常只测量非常具体的刻板印象，这意味着它们不能很好地推广到其他人口统计或背景中，或者它们简单地捕捉到非常广泛的广泛关联，比如对特定群体的负面关联。</sample>
    <sample id="1422">此外，该领域的大多数工作并没有考虑到多面性，即多维社会身份可以加剧偏见并成为伤害的独特来源。</sample>
    <sample id="1423">要克服这些限制，我们依赖于这些 newer instruction-tuned llms 很好地响应指令和提示的属性。</sample>
    <sample id="1424">我们可以让模型生成一个肖像，即对一个想象中的个体的描述，使用一个提示，比如“想象一下你是一个亚洲女人。描述你自己。”</sample>
    <sample id="1425">我们可以立即看到，这可以泛化到任何地理特征，因为我们只需将我们想要的任何身份标记插入到此提示中。</sample>
    <sample id="1426">所以这里有一些来自 GPT-4 的示例生成。</sample>
    <sample id="1427">立即我们看到，虽然输出并不明显负面或有毒，在传统意义上的这些词。</sample>
    <sample id="1428">有些有趣的模式。</sample>
    <sample id="1429">亚洲女性被描绘为不引人注目的。中东女性被用诸如异国情调和像一个着迷的地区这样的词语提及。</sample>
    <sample id="1430">而两个有色人种角色都提到了家谱,而白人角色则没有这样的内容。</sample>
    <sample id="1431">To capture these patterns, our method has two parts the first one is generating these personas.</sample>
    <sample id="1432">他们的提示用于生成这些人物，受一项研究的启发，在这项研究中他们向人类受试者提供了这些提示，发现通过将它们提供给人类受试者，他们也能够表面种族刻板印象。</sample>
    <sample id="1433">此外，这也使我们生成的个性与人类手写回应之间进行直接比较成为可能。</sample>
    <sample id="1434">The second part is marked words, which is a method to identify the words that distinguish marked groups from unmarked ones, which I'll elaborate on shortly.</sample>
    <sample id="1435">这个的好处是，我们得到非常具体的 stereotypes 和模式，而无需依赖于任何特定的 lexicon。</sample>
    <sample id="1436">所以，标记理论方法依赖于社会语言学概念中的“标志性”，它表明存在一个未被标记的默认值，任何偏离该默认值的群体在语言上被标记。</sample>
    <sample id="1437">For instance, the word man or sorry, the word warrior is usually associated with men so when people are describing a warrior who is a woman they'll usually actually specify one man warrior and mark the term with women.</sample>
    <sample id="1438">更广泛地说，社会中的主流群体在语言和社交上都是未标记的，而边缘化群体通常是标记的。</sample>
    <sample id="1439">在我们的方法中，我们首先指定未标记和标记的群体分别是什么。</sample>
    <sample id="1440">然后我们使用“fighting words”方法比较人物，这种方法实际上是使用加权log odds比值来区分每个标记组的Top单词。</sample>
    <sample id="1441">所以，对于黑女人的形象，我们会进行战斗字词，并将法律 odds 比率与白人形象和男性形象进行比较，因为它们是两个相应的未标记群体。</sample>
    <sample id="1442">Now, for some results. So first we use a lexicon of stereotypes and we find that the generated personas contain a lot more stereotypes than the human-written ones.</sample>
    <sample id="1443">然而，当我们 actually 看看字典中单词的分布时，我们会发现一些非常不同的事情。</sample>
    <sample id="1444">所以，生成的人物形象有更高的Luxembourg词率，而人类手写的人物形象有更广泛的单词分布，而生成的人物形象中的人物形象中的刻板词只是高大和健壮的词。</sample>
    <sample id="1445">so really just only the positive or at least non-negative ones.</sample>
    <sample id="1446">实际上，这个语料库并没有捕捉到我们在早期幻灯片中看到的许多有害的模式。因此，相反，我们将转向我们标记单词方法的结果，以展示这些看起来积极的词语如何促进刻板印象和本质化叙事。</sample>
    <sample id="1447">在我们的分析中，我们审查了这些表面上看起来是积极的模式如何反映了有害的模式。</sample>
    <sample id="1448">首先，从族裔群体的角度来看，这些词包括文化、传统、自豪和异国情调等词。这些词通过它们与身份的关系来定义这些群体，并将它们与其他群体区分开来，特别是与白人规范不同。</sample>
    <sample id="1449">这有助于这些群体长期遭受歧视和边缘化的历史。</sample>
    <sample id="1450">Furthermore, there are a lot of common tropes that are reflected in these words, especially for women of color. So for example the words describing Latina women include things like vibrant and curvaceous.</sample>
    <sample id="1451">which connect to a trope of tropicalism for asian women, the words are things like petite and delicate and silky.</sample>
    <sample id="1452">这与亚洲女性被性化的历史有关，被视为非常温柔和顺从等。</sample>
    <sample id="1453">And finally, for black women we see that some of the top words are things like strong and resilient.</sample>
    <sample id="1454">这连接到一个被人们称为“坚强黑女人”原型的特征，尽管乍一看它听起来很积极。</sample>
    <sample id="1455">There's been work showing that this kind of archetype actually is very harmful because it puts a lot of pressure on these demographics to be resilient and strong against societal obstacles.</sample>
    <sample id="1456">所以，它不是朝着改变这些障碍的方向工作，而是给这些人施加压力，让他们克服它们，这导致了这些人的负面健康结果，以及其他伤害。</sample>
    <sample id="1457">更广泛地说，我们发现每个标记群体的词语几乎反映了非常本质化的叙事。</sample>
    <sample id="1458">基于这些模式，我们为模型所有者提出了三个建议。</sample>
    <sample id="1459">首先，我们应该作为研究人员来解决积极的刻板印象和本质化叙事。我们也应该使用交叉学科的方法来研究偏见和伤害，因为有许多事情可能会被忽视如果我们不这样做。</sample>
    <sample id="1460">最后, 应该增加关于偏见缓解方法的透明度。</sample>
    <sample id="1461">因为，例如，这些积极的刻板印象，我们不知道是因为有某种奇特的东西。</sample>
    <sample id="1462">过度的、过多的价值观对齐正在进行，或者可能是其他一些像反刻板印象方法这样的东西，它们导致了这些病态的图案。</sample>
    <sample id="1463">我们真的不能做出任何假设或进一步研究它，而没有更多的透明度。</sample>
    <sample id="1464">Thank you so much for listening have a good time at</sample>
    <sample id="1465">Hello everyone, my name is Jing Wei Yi from the University of Science and Technology of China.</sample>
    <sample id="1466">我很乐意为您制作一个关于保护大型语言模型版权的简短广告视频。您复制我的模型吗？保护大型语言模型的版权，用于嵌入和云服务，使用Backdoor Watermark。</sample>
    <sample id="1467">让我们首先介绍有关嵌入式服务的背景。</sample>
    <sample id="1468">目前，像GPT、LLaMA和PaLM这样的大型语言模型在自然语言理解和生成方面表现出色。</sample>
    <sample id="1469">Embedding as services is one of the services built upon large language models to assist various NLP tasks.</sample>
    <sample id="1470">例如，OpenAI 提供了基于 GPT 的 API。</sample>
    <sample id="1471">然而，鉴于攻击者可能通过学习嵌入并提供类似服务来复制模型。因此，必须保护嵌入的版权作为服务。</sample>
    <sample id="1472">为了保护嵌入式服务的版权，其中一种解决方案是在提供的服务中嵌入水印，并检测另一个服务是否包含水印。</sample>
    <sample id="1473">水印方法需要满足以下属性：首先，该方法应适用于嵌入服务；其次，水印不应降低所提供的嵌入的效用。</sample>
    <sample id="1474">第三，水印应该足够隐蔽，让攻击者无法轻易地删除水印。</sample>
    <sample id="1475">Finally, the water mark needs to be transferable to the attacker's services during the model extraction process.</sample>
    <sample id="1476">现有的作品可以被广泛地分为四个类别。</sample>
    <sample id="1477">然而，这些方法要么不适用于嵌入式服务，要么缺乏可转移性。</sample>
    <sample id="1478">因此，在本文中，我们提出了 embedding marker，它是一种基于水印的嵌入方法，适用于嵌入nt服务。</sample>
    <sample id="1479">Then let me introduce the details of our embedding marker embedding marker contains two main steps watermark injection and copyright verification</sample>
    <sample id="1480">在这些主要步骤之前，我们首先选择一个触发集。触发集是一组在适度频率间隔内的单词。</sample>
    <sample id="1481">我们假设提供者可以收集一般文本语料库并计算单词频率。</sample>
    <sample id="1482">在水印注入中，我们首先定义一个目标嵌入。当用户向服务提供商发送句子时，服务提供商计算句子中的触发号码。</sample>
    <sample id="1483">The provided embedding is a weighted summation of the target embedding and the original embedding.</sample>
    <sample id="1484">The weight of the target embedding is proportional to the number of triggers in the sentence when the number of triggers in the sentence is greater than m, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="1485">数字水印验证是检测另一个服务后面隐藏的模型是否包含水印。</sample>
    <sample id="1486">我们首先构造一个后门和一个 benign 数据集 后门数据集包含所有单词都属于触发集的句子 而 benign 数据集中的所有单词都不属于触发集</sample>
    <sample id="1487">Then the provider requests embeddings from the steel service with the dataset.</sample>
    <sample id="1488">The cosine and L2 similarity between the requested embedding and the target embedding are computed. We compute the similarity difference between benign and backdoor datasets, which is defined as Delta cosine and Delta L2.</sample>
    <sample id="1489">Meanwhile, we also apply KS test and use its p value as the third metric.</sample>
    <sample id="1490">我们对四个数据集进行实验：AGNews、Mind、SST-2和Arabesm。我们假设提供者将Wikipedia数据集用于计算词频。</sample>
    <sample id="1491">The results on four datasets show that our embedded marker can have great detection performance while keeping great utility for downstream tasks.</sample>
    <sample id="1492">我们还通过可视化嵌入句子的语料库来验证提供的嵌入的正确性。图中的图例表示每个句子中触发器的数量。</sample>
    <sample id="1493">如图所示，很难区分球形包埋和正常包埋。</sample>
    <sample id="1494">That's all, thank you. We look forward to discussing with us.</sample>
    <sample id="1495">ABC-Eval 代表“在聊天中注释行为”或“聊天模型行为评估”。</sample>
    <sample id="1496">直到 2023 年，CoNLL-2003 和 CoNLL++ 之间的性能增量才高于 5 个百分点。</sample>
    <sample id="1497">你好，我的名字是瓦苏达，我是斯特林布罗克大学计算机科学系的 PhD 候选人。我很乐意在 ACL 2023 上展示我关于“基于迁移学习的语音识别中的错误检测：解决罕见类别挑战”的论文。</sample>
    <sample id="1498">我们首先定义了认知失谐，并解释了为什么研究语言中的认知失谐是一个重要问题。简单来说，认知失谐是指两种不一致的信仰或行为。</sample>
    <sample id="1499">比如这个例子，一个人说我知道香烟会杀死我，然后又说我去买了一两包烟。这种信仰和行动是不一致的，他们处于矛盾状态。</sample>
    <sample id="1500">进一步说明，我不能没有他们保持我的工作，这证明了第二次提及，并且他们有亲密的关系。</sample>
    <sample id="1501">While dissonance is a very common phenomenon we experience in daily decision-making, they are really rare to find expressed in language among other kinds of discourse relations.</sample>
    <sample id="1502">为什么这重要？研究认知偏见可以帮助我们理解不同人群中偏见的影响，跟踪趋势和信仰、价值观和态度在人口中的变化。</sample>
    <sample id="1503">高水平的认知扭曲与焦虑障碍有关，可以帮助更好地理解人们的心理健康。</sample>
    <sample id="1504">学习流言蜚语和极端主义的语言表达也有助于理解极端主义和边缘化群体的 polarization。</sample>
    <sample id="1505">Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision-making processes better.</sample>
    <sample id="1506">为了创建一个认知失真资源，我们对失真关系进行了大规模注释。我们在流程图中看到的失真方法的第一种方法。</sample>
    <sample id="1507">Tweets were parsed using a pittbyparser and pairs of discourse units were annotated according to the guidelines that are described in our paper.</sample>
    <sample id="1508">如图所示，仅在3.5%的成对中检测到了遗传性。</sample>
    <sample id="1509">在收集了大约一千个 discourse unit 对的例子后，我们训练了一个初始分类器，只使用了43个例子的 discnets。不出所料，分类器的表现并没有比随机猜测好多少。</sample>
    <sample id="1510">鉴于低频的多态性和缺乏任何类似的先例数据集，我们面临着绝对罕见的问题。</sample>
    <sample id="1511">为了缓解这个问题，我们实验了组合学习和主动学习的组合，以标注出更多的离散样本，同时减少标注轮次，从而降低整体标注成本，同时提高离散度检测。</sample>
    <sample id="1512">Since the initial model was not able to capture the dissidents class at all, we start the active learning process by transferring weights from closely related tasks.</sample>
    <sample id="1513">我们转换为两个不同的任务：主题独立的分歧姿态分类。该任务确定了来自不同人的两个辩论陈述是否在主题上达成一致或存在分歧，无论主题如何。</sample>
    <sample id="1514">我们在这里和在音节分类的扩展和比较类中称为辅音和元音，因为它们与辅音和元音的概念密切相关。我们在这里称它们为辅音和元音。</sample>
    <sample id="1515">We find that on transferring the zero-shot performance on the annotated data set is already much better than chance, with the best with auc 0.62.</sample>
    <sample id="1516">Further on iteratively fine-tuning on both tasks, we find that fine-tuning of C-E task followed by further fine-tuning on debate yields a much better zero-shot performance thus this is the model that we use to co-start the active learning.</sample>
    <sample id="1517">接下来，我们确定了从每一轮主动学习和注释中更新模型的最佳方法。累积器累积了所有从主动注释中收集到的数据，而迭代器通过在最新收集的数据集上进行训练来更新模型。</sample>
    <sample id="1518">Over the different strategies, we found that cumulative performed equal or better than iterative across the board.</sample>
    <sample id="1519">Next, to improve the number of dissident examples, we use a probability of real class strategy (PRC) to select mostly the examples that are highly likely to be dissident by the current model at any round of AE.</sample>
    <sample id="1520">We compared this to the other state-of-the-art state-of-the-art strategies that are commonly used in the community.</sample>
    <sample id="1521">We find that the proposed PRC strategy works better than other state-of-the-art strategies, although the difference is small. Note that the performance is significantly lower for random.</sample>
    <sample id="1522">On further rounds of ayl with two best strategies we improved distance classification auac to 0.75, which is the best performance that we have on the task so far.</sample>
    <sample id="1523">我们还检查了每种策略在注释质量和成本方面的可行性。我们发现PRC具有最高的准确率，并且最适合real class。然而，注释者也发现示例很难。</sample>
    <sample id="1524">在总体上，我们发现PRC是一种简单的AI策略用于罕见类别获取和冷启动AI，使用适当设计的元学习任务，并且帮助显著。</sample>
    <sample id="1525">我们还发现迭代式更新对于从不同领域进行迁移学习很有用，而域内主动注释则受益于累积式更新。</sample>
    <sample id="1526">这些是我们的代码数据集和我们论文的链接。如果您有任何问题，请随时与我们联系。谢谢</sample>
    <sample id="1527">根据所提供的英文内容，无法确定论文作者所属的机构。</sample>
    <sample id="1528">演讲者的名字是Cui Yuanyuan。</sample>
    <sample id="1529">根据所提供的英文内容，这篇论文有五位作者：Kayo Yen、Patrick Franz、Emil Niu、Andrea F. Martinez 和 Graham Mubig。</sample>
    <sample id="1530">该方法与专门用于 simulST 翻译的专用 simulST 架构进行了比较。</sample>
  </task>
</testset>