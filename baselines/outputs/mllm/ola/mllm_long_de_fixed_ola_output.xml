<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind Webkraw Data, politische News-Medien und diverse Perspektiven.</sample>
    <sample id="1">Die Autoren gehören an McGill University, MILA und Microsoft Research.</sample>
    <sample id="2">This paper introduces LayoutMask, a novel multi-modal pre-training model designed to address the reading order issues in visually rich document understanding. Unlike existing models that use global word segmentation for reading order, LayoutMask employs local word segmentation and infers global reading orders by jointly using 1D and 2D word positions and semantic information. It also introduces two new masking strategies: whole word masking and layout-aware masking, which enhance text layout interactions during pre-training. The paper compares the performance of LayoutMask with different word positionings on FD and SRE datasets, demonstrating its effectiveness in handling complex layouts.</sample>
    <sample id="3">Hallo, herzlich willkommen zu unserem Vortrag über die Einführung von DPlain, ein neues Korpus für deutsche Textsimplifizierung auf Dokument- und Satzlevel. Mein Name ist Regina Schröder und ich werde Ihnen das erste Teil der Präsentation vorstellen. Lassen Sie uns mit der Textsimplifizierung beginnen. Textsimplifizierung ist ein Prozess, bei dem ein Text anpassiert wird, um seine Verständlichkeit für eine bestimmte Zielgruppe zu verbessern, sei es Menschen mit Leseschwierigkeiten oder non-native-Sprecher. Um ein Textsimplifizierungstool zu trainieren, benötigen wir Paare von Texten, zum Beispiel Dokumente oder Sätze. In diesem Beispiel sehen Sie ein Paar von parallel alignten Satzpaaren, einer komplexen deutschen Satz und seine Übersetzung ins einfachere Deutsche. Um einen Satz zu simplifizieren, gibt es verschiedene Techniken, wie Sie in diesem Beispiel sehen können, wie z.B. Lexikalsubstitution, Klauselletion, Klauselletion mit Umordnung oder die Einfügung von Brot. Wir now präsentieren unser neues Korpus DPlain, da in den letzten Jahren einige Probleme mit bestehenden Korpusen aufgetreten sind. Zum Beispiel sind diese Korpusse zu klein, um ein Textsimplifizierungstool zu trainieren. Die anderen drei Modelle, die in jüngster Zeit vorgestellt wurden, sind alle automatisch aligniert, was bedeutet, dass sie über einen erprobten Alignmentsprozess verfügen. Daher präsentieren wir unser neues Korpus DPlain, das in zwei Subkorpusen, DPlain API und DPlain Web, unterteilt ist. DPlain API basiert auf News-Texts und enthält 483 manuell alignierte Dokumente, was zu einem Durchschnitt von 13.000 parallelalignierten Satzpaaren führt. DPlain Web enthält hingegen 750 Dokumente, die teilweise manuell und teilweise mit automatischen Alignmentsmethoden aligniert wurden, was zu einem Gesamtzahl von 14.500 Satzpaaren führt. Wir analysieren unsere Satzpaare etwas detaillierter, z.B. auf die Art der Simplifizierung. Wie Sie sehen können, sind Bibeltexte stark simplifizierter als z.B. News-Texte oder Sprachlerner-Texte auf allen Ebenen, einschließlich Lexikal-, Struktursimplifizierung und allgemeine Simplifizierung. Darüber hinaus zeigt unser DPlain-Korpus eine hohe Vielfalt an verschiedenen Simplifizierungstransformationen. Zum Beispiel im DPlain-API-Korpus sind Reorganisierungen und Worteditionen stärker vertreten als in DPlain-Web, während im Web-Korpus hingegen mehr Umgestellungen vorkommen. Nun sehen wir an, was wir damit erreichen können. Hallo, ich bin Omar und nun werde ich über die Anwendungsfälle für unser Datensatz DPlain sprechen. Der erste Anwendungsfall, den wir in unserem Papier diskutieren, ist die Evaluierung von Automatisierungsverfahren zur Extraktion von Alignments. In jüngster Zeit sind viele Alignmentsverfahren entdeckt worden, aber in Kontexten, in denen wir zwei parallel schriftliche Dokumente in verschiedenen Sprachen haben und wir zwei Parallel-Dokumente mit denselben Inhalten und verschiedenen Komplexitätsstufen extrahieren möchten. In unserem Anwendungsfall versuchen wir, Alignments zwischen zwei parallel existierenden Dokumenten zu extrahieren, die dieselbe Sprache und dieselbe Inhalt haben, aber auf verschiedenen Komplexitätsstufen liegen. Aufgrund unseres DPlain-Korpus können wir manuelle Alignments als Goldstandard verwenden, um die Leistung einiger vorgeschlagener Automatisierungsverfahren zu bewerten. Wir haben auch Anpassungen an ein paar vorgeschlagene Verfahren vorgenommen und die Codes, um unsere Experimente zu reproduzieren, im Papier publiziert. Wir haben festgestellt, dass das beste Automatisierungsverfahren zur Extraktion von Alignments für deutsche Textsimplifizierung das Verfahren MassAlign ist. Sie können den Code, um dieses Verfahren auf Ihren eigenen Dokumenten zu verwenden, im Papier finden. Der zweite Anwendungsfall, den wir in unserem Papier diskutieren, ist die automatische Textsimplifizierung durch die Anpassung von Sprachmodellen, um eine simplifizierte Textausgabe aus einem komplexen Eingabe-Text zu erhalten. Wir haben zwei Modelle anpassen lassen: Wir haben das Modell Long Impart für die Erstellung von Dokumentebene-Simplifizierungen und das Modell Long Base Impart für die Erstellung von Satzebene-Simplifizierungen anpassen lassen. Sie können die Checkpoints und weitere Details über dieScores und die Evaluationsmetrischen in unserem Papier finden. Wir haben festgestellt, dass die Anpassung dieser Modelle besser als die Baseline-Scores ist und wir schlagen diese als Standardmesswerte für zukünftige Studien zur automatischen Textsimplifizierung vor. Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle beim Kongress kennenzulernen. Vielen Dank.</sample>
    <sample id="4">Kayo Yin</sample>
    <sample id="5">Ein Modell mit teilweise überlappendem Hintergrundwissen wurde verwendet, um die Genauigkeit von 82–87 % zu erreichen.</sample>
    <sample id="6">This paper presents a unified multi-lingual and cross-lingual summarization system called Many-to-Many Summarization (MTM-Summarization). MTM-Summarization enables a single summarization model to process a document in any source language and generate a summary in any target language. The authors conduct preliminary experiments on the widely used WikiLingua dataset, comparing MTM-Summarization with previous multi-lingual and cross-lingual summarization models. The results show that MTM-Summarization can better transfer task knowledge across different languages compared to previous models. Additionally, the authors propose a three-stage pre-training method named PACE to further improve the performance of MTM-Summarization.</sample>
    <sample id="7">Ja, sie funktionsieren immer noch.</sample>
    <sample id="8">Die vorgeschlagene Methode ist neu, weil sie eine präzisere und zuverlässigere Strategie für dimensionale Dialogbewertung verwendet. Sie versucht, die Subjektivität menschlicher Bewertungen zu reduzieren, indem sie explizit feststellt, ob jede Modell-Antwort bestimmte Verhaltensweisen ausdrückt, wie zum Beispiel die Bereitschaft, mit irrelevanter Information zu antworten oder sich selbst oder seinem Partner widersprechen.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Anzahl der sauber validierten Ausprägungen ab.</sample>
    <sample id="10">Das Modell hat nur Zugriff auf die Namen von Entitäten, was eine Genauigkeit von 60% ergibt. Es gibt also viel Raum für Verbesserungen.</sample>
    <sample id="11">The New Yorker Caption Contest is a popular weekly cartoon captioning competition. Researchers from AI2, University of Utah, Cornell University, University of Washington, Air Mail, and OpenAI have operationalized the contest data into three tasks: matching, quality ranking, and explanation generation. They have gathered over 700 annotated cartoons and a corpus of over 650 joke explanations. The best model, CLIP fine-tuned on the annotated corpus, achieves around 62% accuracy in the matching task, which is significantly lower than human performance at 94%. Models like GPT-4, even with additional annotations, still perform poorly compared to humans.</sample>
    <sample id="12">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="13">This paper presents a study on adaptive inference methods in low-resource settings, specifically focusing on multi-modal and early exit methods. The authors compare the performance of these methods using the BERT pre-trained language model. They propose a new fine-tuning method called "sweet," which separates weights in early exit architectures to avoid conflicting gradients. The results show that sweet closes the gap between early exit and multi-modal methods, but negatively affects later classifiers in some cases. Overall, the paper highlights the existence of conflicting gradients in early exit training processes and introduces a novel fine-tuning method for early exit architectures.</sample>
    <sample id="14">Der Vortrag von Adam Sipruckowsky befasst sich mit der Struktur von Koordinationen und untersucht, wie verschiedene Theorien und Ansätze die Abhängigkeitsstruktur interpretieren. Ein universeller Ansatz sieht die Koordination als eine Struktur, bei der der erste Conjunkt den Kopf der gesamten Struktur ist, wie in dem Beispiel "Lisa und Meggy". Eine ähnliche Annahme wird in Igor Miltruch's Meaning-Text-Theorie verwendet, wobei auch hier der erste Conjunkt den Kopf der Struktur ist. Beide Ansätze sind asymmetrisch, da sie einen bestimmten Conjunkt hervitragen. Eine symmetrische Annahme, wie die Prag-Annäherung, sieht die Koordination als eine Struktur, bei der die Konjunktion den Kopf der Struktur ist, so dass Abhängigkeiten vom Beginn zu allen Conjunkten bestehen. Eine weitere Annäherung, wie die multi-head-Ansatz, sieht alle Conjunkte als Köpfe der Koordinationsstruktur an, was Abhängigkeiten vom Governor (in diesem Fall "Lars") zu allen Conjunkten separately erstellt. Das Ziel des Vortrags ist es, einen neuen Argumentationsansatz für symmetrische Koordinationsstrukturen gegen asymmetrische Koordinationsstrukturen zu präsentieren. Der Argumentationsansatz basiert auf dem Prinzip der Abhängigkeitslängenminimierung, das auf den gegebenen Beispielen erläutert wird. In englisch ist es üblich, direkte Objekte in der Nähe des Verbs zu haben, während Ergometri umfangreiche Abstände haben können. Beispiele wie "March read it yesterday" sind besser, weil das direkte Objekt "it" in der Nähe des Verbs steht, während "March read yesterday it" schlecht ist, weil "yesterday" zwischen dem Verb und dem direchten Objekt steht. Allerdings kann der Effekt, wenn das direkte Objekt sehr lang ist, durch Verschieben nach dem Ergometrium neutralisiert werden, wie in "March read this absolutely fascinating book about the bees yesterday" gezeigt wird. Das Hauptargument ist, dass dieser Satz, obwohl gegen die grammatischen Regeln verstößt, die Prinzipien der Abhängigkeitslängenminimierung erfüllt, indem die kritischen Abhängigkeiten kürzer sind. Die Analyse zeigt, dass die Längen der kritischen Abhängigkeiten in einem Satz mit zwei Conjunkten (beispielsweise "March read this absolutely fascinating book about the bees yesterday") 11 Zeichen lang sind, während sie in einem Satz mit einem Conjunkt nach dem anderen (beispielsweise "March read yesterday this absolutely fascinating book about the bees") nur 6 Zeichen lang sind. Daher gilt der Satz als akzeptabel, obwohl er gegen ein Grammatikprinzip verstößt. Das Papier extrahiert statistische Daten aus der Erweiterter Version von Penn Treebank und zeigt, dass links stehende Conjunkte in der Regel kürzer sind, und dass diese Tendenz mit wachsendem Längenunterschied zwischen den Conjunkten zunimmt. Wenn derGovernor auf der linken Seite fehlt, bevorzugt das links stehende Conjunkt, je größer die Längenunterschiede zwischen den Conjunkten sind, um kürzer zu sein. Wenn derGovernor auf der rechten Seite steht, disapears der Effekt. Dieses Argumentationsschema bietet einen Beweis gegen asymmetrische Koordinationsstrukturen und für symmetrische Koordinationsstrukturen.</sample>
    <sample id="15">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="16">Bible texts</sample>
    <sample id="17">This paper introduces a method for multi-modal relation extraction, which aims to determine the semantic relationship between entities in a given text. The proposed method consists of five parts: representing the text and image with corresponding visual and textual graphs, merging the visual and textual graphs into a unified cross-modal graph (CMG), screening the initial CMG structures by fine-grainedly filtering nodes and adjusting edges, enriching the CMG features with multi-modal topic features, and using attention operations to integrate the multi-modal topic words. Experiments on the widely used MRD dataset show that the proposed method achieves significant improvements over existing models.</sample>
    <sample id="18">Salt and pepper and not pepper and salt.</sample>
    <sample id="19">This presentation introduces a survey on efficient open-domain question answering systems. It highlights the challenges of traditional two-stage models, such as large memory costs and slow inference speed due to the massive Wikipedia corpus and multiple language models. The proposed solutions include approximate nearest neighbor search, skipping rate, document filtering, and model compression. The analysis shows that retrieval-only systems are better suited for low-resource environments, while retrieval-and-reader systems are more appropriate for high-performance applications. Future work focuses on deploying these systems in low-power devices and considering new evaluation metrics.</sample>
    <sample id="20">Ja, Sie können die Modelle verwenden. Die Pre-Trained-Modelle sind frei zugänglich auf GitHub und die Trainingsskripte sind auf unserem GitHub Repository zu finden.</sample>
    <sample id="21">Die DEplain-apa enthält News-Texte.</sample>
    <sample id="22">Eine gute Generalisierung wird durch die Model-Architektur, die Modellgröße und mehr Fine-Tuning-Beispiele erreicht.</sample>
    <sample id="23">This paper presents a method to improve text-image models by augmenting the existing text representation with an additional text representation generated by a character-aware model. The authors conduct a comprehensive benchmark study on three representative types of multilingual language models and show that their approach significantly improves cross-lingual semantic parsing tasks. They also propose a unified benchmark for cross-lingual semantic parsing with multiple natural languages and input representations.</sample>
    <sample id="24">Die Tendenz wurde durch Messung der Längen in Zeichen, Silben und Wörtern bestimmt.</sample>
    <sample id="25">Die Experimente wurden so gestaltet, dass sie die Auswirkungen der Position des Begrenzers auf die Längen der linken und rechten Konjunkte in Koordinationssätzen untersuchten.</sample>
    <sample id="26">Ein Basisklassifikator, der mit unausgewogenen Daten trainiert wird, performt nicht viel besser als Zufall.</sample>
    <sample id="27">Die Anzahl der Autoren, die an der Arbeit beteiligt sind, wird nicht in dem gegebenen Text erwähnt.</sample>
    <sample id="28">Bob und Alice.</sample>
    <sample id="29">Kontextsensitive MÜ-Modelle schneiden besser ab als kontextagnostics Modelle bei Diskursphänomenen wie Formalität und lexikalischer Kohärenz.</sample>
    <sample id="30">This paper introduces a simple yet effective ensemble learning framework for large language models called LLM-Blender. It focuses on pairwise ranking and generative fusion to select the best model for each input example. The framework runs multiple models, ranks their outputs using a pairwise ranking module, and then fuses the top-ranked candidates using a generative fusion model. Experiments show that LLM-Blender outperforms individual models like Open Assistant and Vicuna in 68% and 76% of examples, respectively, demonstrating its potential as a promising framework for ensemble learning.</sample>
    <sample id="31">Die Autoren sind an Johns Hopkins University, Purdue University und MIT (Massachusetts Institute of Technology) tätig.</sample>
    <sample id="33">Das Framework quantifiziert die Positionalität, indem es dieAnnotations von realen Benutzern mit den Datensätzen und Modellvorhersagen vergleicht. Es verwendet dabei eine Pearson's r Korrelationskennzahl.</sample>
    <sample id="34">The CREST framework is a joint approach for generating counterfactual examples and providing selective rationalizations. It combines selective rationalization with counterfactual generation to produce valid, fluent, and diverse counterfactuals that focus on the critical parts of the input. The framework uses a rationale generator to create counterfactuals based on the input and then trains a rationale extractor to highlight meaningful rationales. The results show that CREST generates more plausible explanations than other approaches and outperforms other methods in various datasets.</sample>
    <sample id="36">This paper presents a method for enhancing multilingual machine translation by introducing language-specific layers (LLs) in a transformer model. The approach involves training one regular transformer layer per language, which can be used to select the correct sub-layer at both training and inference times. This method allows for increased capacity per language while maintaining constant inference costs. The placement of LLs is learned through a process involving shared, source, and target weights, with the best placement determined by selecting the component with the largest weight. Experiments on the WMT 21 newstest dataset show significant improvements over baseline models and language adapters, particularly for low-resource languages.</sample>
    <sample id="37">Die Menschen, die dieselben Persona-Prompts erhalten hatten, wurden in der Studie in der Lage, Rassistische Stereotypien zu surfen.</sample>
    <sample id="38">Die Studie verwendet die statistischen Daten aus der erweiterten Version von Penn Treebank.</sample>
    <sample id="39">Es sind zwei Autoren an der Arbeit beteiligt.</sample>
    <sample id="40">Englisch: Topik unabhängige Dissonanz-Stoffe Klassifizierung und binärer Klassifizierung von Erweiterung und Vergleichsklassen von BERT.</sample>
    <sample id="41">This paper introduces PEACoK, a world-level personal common sense knowledge graph that contains about 3.8 thousand persons and 40 thousand distinctive attributes, forming about 100 thousand person inferences or facts. It includes about 9.2 thousand attributes connected to two or more persons, contributing to rich interconnections. The graph is built in three steps: selecting persons from existing common sense knowledge graphs, inducing attributes of persons from both common sense knowledge graphs and large-scale pre-trained language models, and cross-checking the annotations of PEACoK relations using a joint human-AI majority voting scheme. Experiments show that PEACoK can help language models learn and generalize person knowledge, achieving better results on various natural language generation metrics and higher acceptance rates in human evaluation. Additionally, PEACoK knowledge can improve downstream narrative modeling by augmenting dialogue generation tasks with relevant facts retrieved from the graph.</sample>
    <sample id="42">Zwei Autoren arbeiten an der Arbeit beteiligt.</sample>
    <sample id="43">Die Arbeit beteiligen sechs Autoren.</sample>
    <sample id="44">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten in der Art, dass es die Trolle von politischem Bias in NLP-Modellen über die gesamte Pipeline von Datensammlung bis hin zu Modelltraining und -nutzung verfolgt.</sample>
    <sample id="45">Die generierten Persönlichkeiten.</sample>
    <sample id="46">DieBenchmark zeigt, dass DeepL normalerweise besser als Google Translate für Dokumentenlevelübersetzungen ist.</sample>
    <sample id="47">Hallo, ich bin Changbin, PhD-Student an der University of Washington. Heute präsentiere ich unser Werk von der Vorbereitung von Datensätzen bis hin zu Sprachmodellen und Downstream-Aufgaben, insbesondere die Verfolgung von politischen Biases, die zu unfairen NLP-Modellen führen können. Sprachmodelle werden auf großen Datensätzen aus Webkrawls trainiert, die politische News-Medien gut abdecken. Laut einer Umfrage des C4 Corpus können wir sehen, dass New York Times, Los Angeles Times, The Guardian, Huffington Post usw. in den Datensätzen für Sprachmodelltraining gut abgedeckt sind. Dies hat sowohl Vorteile als auch Nachteile für die Anwendung von Sprachmodellen. Auf der einen Seite können sie von diversen Perspektiven lernen und damit dem Demokratie und der Pluralität von Ideen Geltung verleihen. Auf der anderen Seite sind diese verschiedenen politischen Meinungen inherent sozial biasettschuldig und können zu potentiellen Fairness-Problemen in Downstream-Aufgaben führen. Um dies zu untersuchen, haben wir vorgeschlagen, die politische Bias-Propagation- Pipeline von Vorbereitungsdaten über Sprachmodelle bis hin zu Downstream-Aufgaben zu untersuchen. Dazu haben wir folgende Fragen gestellt: Wie können wir die politische Neigung von Sprachmodellen bewerten und welche Rolle spielen dabei die Vorbereitungsdaten? Wie performieren Sprachmodelle mit verschiedenen politischen Neigungen bei Downstream-Aufgaben und ob das zu Fairness-Problemen in NLP-Anwendungen führt? Wir haben zuerst vorgeschlagen, Sprachmodelle mit verschiedenen Prompt-Formulierungen zu prompten, indem wir politische FragHQecke wie die politische Kompass-Test-Fragebank verwenden. Damit können wir sicherstellen, dass die Evaluierung fundiert ist in der politischen Wissenschaft. Einige vorläufige Resultate demonstrieren, dass Sprachmodelle eine Vielzahl von politischen Neigungen aufweisen, sie auf einem Quadranten im politischen Kompass liegen. Wir können auch sehen, dass GPT-4 die liberalste Sprachmodell ist und GPT-Serie allgemein mehr sozial liberal als BERT-Serie und ihre Variationen. Zweitens haben wir versucht, die Auswirkungen der politischen Neigungen von Sprachmodellen auf Downstream-Aufgaben zu untersuchen. Wir haben zuerst die Datensätze in sechs unterschiedliche politische Körpereinheiten geteilt und dann Sprachmodelle auf verschiedenen Datensätzen trainiert. Wir haben festgestellt, dass die ideologischen Koordinaten der Sprachmodelle sich entsprechend verschieben, zum Beispiel bei Roberta, die nach einem weiteren Training auf einem linken Datensatz ein substantielles liberales Verschieben in ihren politischen Neigungen zeigt. Wir haben auch versucht, ob Sprachmodelle die Polarisation in unserer Gesellschaft aufnehmen können. Wir haben die Datensätze in zwei Zeitpunkte vor und nach dem 45. Präsidenten der USA geteilt und Sprachmodelle auf den beiden Datensätzen separat trainiert. Wir haben festgestellt, dass Sprachmodelle allgemein eine politische Neigung haben, die weiter weg vom Mittelpunkt liegt nach 2017. Das zeigt, dass Sprachmodelle auch die Polarisation in unserer Gesellschaft aufnehmen können. Schließlich haben wir Sprachmodelle mit verschiedenen politischen Neigungen auf Hate-Speech-Detection und Fake-News-Detection-Aufgaben evaluiert, die oft in NLP-Anwendungen verwendet werden und sehr wichtige Implikationen haben. Wir haben festgestellt, dass wenn wir die Performance pro Kategoriengruppe unterteilen, also wenn wir die Performance nach verschiedenen Demographics oder politischen Neigungen von Medien unterteilen, ein Muster auftreten kann. Zum Beispiel beim Hate-Speech-Detection sind linken Sprachmodellen besser darin, Hate-Speech, die sich auf soziale Minderheiten richtet, zu detektieren, aber schlechter darin, Hate-Speech, die sich auf mehr mächtige Gruppen in unserer Gesellschaft richtet, zu detektieren. Und umgekehrt: rechtsneuen Sprachmodellen sind besser darin, Hate-Speech, die sich auf Weiße und Männer richtet, zu detektieren, aber schlechter darin, Hate-Speech, die sich auf Afroamerikaner, LGBTQ+ und andere Minderheiten richtet, zu detektieren. Similar Trends finden wir beim Fake-News-Detection, wo wir sehen, dass linken Sprachmodellen besser darin ist, Missinformationen aus der gegenüberliegenden politischen Neugruppe zu detektieren, und umgekehrt. Wir zeigen auch viele qualitative Beispiele an, um zu zeigen, dass Sprachmodelle mit verschiedenen politischen Neigungen unterschiedliche Vorhersagen für Hate-Speech- und Missinformationsexempel basierend auf ihren sozialen Charakter machen. Es gibt noch viele weitere Beispiele im Anhang, um das zu verdeutlichen. Das zeigt, dass es ein Fairnessproblem gibt, das sehr dringlich ist, bezüglich der politischen Neigungen von Sprachmodellen. Zum Beispiel, wenn rechtsneuen Sprachmodellen für die Detektion von Hate-Speech oder Missinformation etc. trainiert werden und verwendet werden, bedarf das zu einer Popularsozialmedienplattform, dass Menschen mit gegenüberliegender politischer Meinung marginalisiert werden und Hate-Speech, die sich auf Minderheiten richtet, unkontrolliert weiterhin rampant sind. Das sollte uns an die Hand fassen, um die Fairnessprobleme, die durch politische Neigungen von Sprachmodellen entstehen, zu beachten und zu bekämpfen. Ein bisschen Diskussion: wir möchten auch betonen, dass wir die einzigartige Dilemma bezüglich der politischen Neigungen von Sprachmodellen prezentieren. Es sieht ähnlich aus wie zwischen Sisyphus und Cerberus: Wenn wir die politischen Meinungen in den Datensätzen nicht sauber machen, propagieren die Biases von den Datensätzen über Sprachmodelle bis hin zu Downstream-Aufgaben und schaffen Fairness-Probleme. Wenn wir versuchen, etwas zu sauber machen, riskieren wir Sensibilisierungen oder Exklusionen und es ist schwierig zu bestimmen, was wirklich neutral ist und should retained in Sprachmodelltraining-Datasets. Es sieht ähnlich aus wie das elektroelektro-Problem. Okay, das war's. Ich denke, das war alles, was ich heute für euch gehabt habe. Danke für eure Zeit.</sample>
    <sample id="48">Die Arbeit beteiligen sechs Autoren.</sample>
    <sample id="49">MPP-Auswertungen wurden bis zu 124 Token Kontextlänger durchgeführt.</sample>
    <sample id="50">The presentation introduces DePlain, a new corpus for German text simplification at both the document and sentence levels. It addresses issues with existing corpora, such as small size and alignment errors. DePlain is divided into two sub-corpora: DePlain API, based on news texts with 30,130 manually aligned sentence pairs, and DePlain Web, covering various domains with 30,450 sentence pairs, including both manual and automatic alignments. The corpus showcases diverse simplification techniques like lexical substitution, clause deletion, reordering, and insertion of words. The presentation also highlights use cases for DePlain, including evaluating automatic alignment methods and fine-tuning language models for text simplification, demonstrating improved scores over baseline models.</sample>
    <sample id="51">Sie haben Songs, Rezepte undbücher aufgenommen.</sample>
    <sample id="52">Positionalität ist die Perspektive, die Menschen als Resultat von ihren Demografien, Identitäten und Lebenserfahrungen halten.</sample>
    <sample id="53">Der Referent*in heißt Dawei Zhu.</sample>
    <sample id="54">This paper presents a cognitive dissonance detection system using transfer and active learning techniques. The authors define cognitive dissonance as the inconsistency between beliefs or actions, illustrated by an example of a person stating they know cigarettes are harmful but still smoking. They highlight the importance of studying dissonance in understanding social dynamics, mental health issues, and decision-making processes. The paper describes a large-scale annotation process for identifying dissonance in language, followed by the development of a classifier trained on limited data. Active learning strategies are employed to improve the classifier's performance, with a focus on selecting the most informative examples for annotation. The results show that the proposed strategy significantly improves the classification accuracy of cognitive dissonance detection.</sample>
    <sample id="55">Ja, EDAtt passt zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="56">Ein Autor.</sample>
    <sample id="57">Das Modell scheint in der Testsuite nicht zu funktionsieren.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind: 1) die Vorausbildung im Hintergrund (Background Pretrain), 2) die Vorausbildung im Hintergrund und die Infrastruktur (Background Both), und 3) die Infrastruktur im Hintergrund (Background Infer).</sample>
    <sample id="59">This presentation introduces DrBERT, a robust pre-trained model in French for biomedical and clinical domains. It compares DrBERT with other models trained on different data sources and sizes, evaluating their performance on 11 biomedical and clinical downstream tasks. The results show that from-scratch pre-training generally yields better performance, but continual pre-training using the weight and tokenizer of a biomedical model can achieve comparable results with less data. The proposed system outperforms the generic model Camembert on nine tasks and provides freely available pre-trained models and training scripts.</sample>
    <sample id="60">Google Research</sample>
    <sample id="61">Die abschließende Forschungsfrage lautet: Sollten wir nur die sauberen Samples verwenden, um die Modellauswahl zu überprüfen, oder gibt es bessere Wege, sie zu nutzen?</sample>
    <sample id="62">This paper presents a systematic study of knowledge distillation for natural language generation (NLG) using pseudo-target training. The main goal is to compress large language models while preserving their performance. The study explores different architectures, pruning techniques, and knowledge distillation methods, including word-level and sequence-level distillation. It focuses on task-specific NLG tasks like summarization, question generation, common sense reasoning, and simplification, using unlabeled data and medium-sized teacher models. The research highlights the importance of unlabeled data, the benefits of generating multiple pseudo-targets, and introduces a novel joint teaching technique to address student exposure bias and improve learning.</sample>
    <sample id="63">Die Sensitivitätsmetrik misst die Fähigkeit des Modells, für dieselbe Aufgabe immer die gleichen Ausgaben zu produzieren, unabhängig von kleinen Variationen in der Anweisung.</sample>
    <sample id="64">Jin Wei</sample>
    <sample id="65">Eine höhere Sensitivität ist ein negativer Ausdruck und bedeutet, dass das Modell für kleine Veränderungen in den Eingabeinrichtungen zu empfindlich ist.</sample>
    <sample id="66">This paper surveys the task of mathematical reasoning and the development of deep learning methods for solving mathematical problems. It covers various aspects of mathematical reasoning, including text-based data, visual contexts, and table contexts. The paper also discusses the challenges of automatic theorem proving and the role of neural network architectures in mathematical reasoning tasks. Additionally, it highlights the limitations of large language models (LLMs) in performing precise mathematical reasoning and proposes solutions such as self-consistency and tool-augmented LLMs to address these limitations.</sample>
    <sample id="67">This paper investigates interference in multilingual translation models and proposes methods to mitigate it. The authors find that severe interference occurs when the model is small compared to the data size, and tuning the sampling temperature is key for strong performance. They also discover that language similarity and the number of languages do not have a large impact on interference levels. The results suggest that modest scale and tuned temperature can reduce the problem significantly without any other specialized method.</sample>
    <sample id="68">Die Modelle erhalten während des Pre-Trainings einen Kontext, der eine Abhängigkeit auf Grammatik und Semantik besitzt.</sample>
    <sample id="69">Typischerweise benötigen WSL-Abläufe 20 saubere Validierungsbeispiele pro Klasse, um eine gute Leistung zu erzielen.</sample>
    <sample id="70">Die Autoren gehören an Stanford University.</sample>
    <sample id="71">This paper presents the AltEntities Corpus, a dataset designed to address the challenge of resolving indirect referring expressions for entity selection in conversational systems. The dataset includes three domains: music, books, and recipes, and features a cartoon completion setup with three speech bubbles. In the first bubble, a user mentions a song or book, the second bubble poses an alternative question, and the third bubble contains an indirect reference to select one of the entities. The dataset emphasizes informativeness and is collected using crowdsourcing. The paper also discusses the performance of T5-XL model on this task, showing high accuracy when the model has access to the same background knowledge as the annotators.</sample>
    <sample id="72">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, um die Copright-Verletzungen zu schützen und die Güte der Medien zu erhalten.</sample>
    <sample id="73">Servin</sample>
    <sample id="74">This paper presents a study on the positionality of NLP models and datasets, specifically in relation to their performance in detecting toxic content. The research highlights the importance of considering the demographic identities and life experiences of NLP researchers and model developers, as these can influence the design and outcomes of NLP tasks. The paper also discusses the challenges of studying model and dataset positionality due to the lack of documentation and hidden models behind APIs.</sample>
    <sample id="75">This paper presents the QuesT dataset, a large-scale entity-seeking dataset with implicit set constraints. It includes over 3 million queries and verifies answer entities for relevance. The dataset is used to study the effectiveness of systems in handling selective information needs. The authors propose a semi-supervised joint entity and relation extraction task using a heterogeneous graph and a conceptual demonstration of label propagation process. They also conduct experiments on four datasets, showing significant improvement over all baselines for both NER and relation tasks.</sample>
    <sample id="76">Die Pipeline beginnt mit der Evaluierung der politischen Neigungen von Sprachmodellen, gefolgt von der Untersuchung dessen, wie Sprachmodelle mit verschiedenen politischen Neigungen auf Downstream-Aufgaben performieren und ob dadurch potenzielle Gerechtigkeitseinschränkungen in NLP-Anwendungen entstehen.</sample>
    <sample id="77">This video presents a study on enhancing summarization factual consistency through natural language feedback. Conducted by researchers from Yale University and Microsoft Research, the work introduces a new dataset named "defacto," which includes human demonstrations and feedback for improving summary factual consistency. The study proposes three new NLP tasks: summary editing, feedback generation, and automatic factual error correction. By analyzing the defacto dataset, the researchers provide insights into the factual consistency of summarization models and offer strong baseline models for each task. The video also highlights the dataset's advantages, such as its ground-truth annotations, which are valuable for training factuality metrics and evaluating factual accuracy.</sample>
    <sample id="78">Ja, es gibt einen Unterschied. Der DEplain-apa-Korpus basiert auf News-Texten und enthält 483 manuell alignierte Dokumente, was zu einem Resultat von etwa 30.000 13.000 parallelen Satzpaaren führt. Der DEplain-Web-Korpus hingegen enthält 750 Dokumente in verschiedenen Domänen und wird teilweise manuell und teilweise mit automatischen Alignierungsmethoden aligniert, was zu einem Gesamtresultat von 30.450 Satzpaaren führt.</sample>
    <sample id="79">Ja, die Coscript-Dataset ist öffentlich verfügbar.</sample>
    <sample id="80">Das Wasserzeichen wird definiert, indem die Anzahl der Auslöser in einem Satz bestimmt wird. Der bereitgestellte Embedding ist eine Gewichtsummation des Zielsatzes und des ursprünglichen Embeddings, wobei das Gewicht des Zielsatzes proportional zur Anzahl der Auslöser im Satz ist. Wenn die Anzahl der Auslöser im Satz größer als M ist, dann ist der bereitgestellte Embedding exakt gleich dem Zielsatz.</sample>
    <sample id="81">Die Autoren gehören an der Peking University.</sample>
    <sample id="82">This video introduces a study on unsupervised automated essay scoring (AES) using multiple heuristic signals as pseudo ground truth. The study aims to address the challenge of collecting labeled essays for training AES models, which is time-consuming and labor-intensive. The proposed framework, called URRA, uses a combination of heuristic quality signals to generate partial order pairs, which are then aggregated into a unified supervision for training a neural AES model. Experimental results demonstrate that URRA outperforms unsupervised baselines with significant improvements in both transductive and inductive settings.</sample>
    <sample id="83">Ja, Encoder-Decoder-Modelle wie mt5 können durch Training mit einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="84">This paper presents a partially dynamic neural network framework for dynamic networks, addressing the issue of excessive parameter usage in fully dynamic networks. The proposed method partitions parameters into dynamic and static ones, using scale factors to control their intensity. Experiments show that this approach achieves better performance than both static and fully dynamic networks while maintaining fewer parameters and less computation.</sample>
    <sample id="85">Eine Beispiel für eingeschränkte Sprachplanung ist die Erstellung von Spezialitäten wie einem Schokolade-Kuchen mit bestimmten Bedingungen.</sample>
    <sample id="86">Sie visualisieren die Einbettungen von Sätzen auf einem 2D-Plot (PCA) und zeigen, dass es schwierig ist, die Einbettungen von Backdoor-Sätzen von normalen Einbettungen zu unterscheiden.</sample>
    <sample id="87">Die Arbeit bestehende PLMs nutzt, um ein neues PLM aufzubauen, indem sie die gleichen Datensätze verwenden.</sample>
    <sample id="88">GPT-4 ist am wenigsten auf Indien ausgerichtet.</sample>
    <sample id="89">Ein Beispiel, das zeigt, wie das Modell das Wissen nutzt, das durch den Aufmerksamkeitsmechanismus gelernt wurde, ist "I'm going to talk about" in einem Sprachsegment.</sample>
    <sample id="90">This paper explores the feasibility of using language learners as annotators for natural language processing (NLP) tasks. It presents a proof-of-concept study comparing the annotation accuracy and learning effects of language learners with native speakers. The study targets three languages: English, Korean, and Indonesian, and includes four common NLP tasks. Language learners are categorized into basic, intermediate, and advanced levels based on their proficiency. The results show that language learner annotations are nearly accurate, especially for simpler tasks, and can be on par with native speakers when aggregated by majority voting. Additionally, training simulations using learner annotations achieve high performance, sometimes outperforming models trained with native speaker labels. The study suggests that language learners can contribute to NLP research, particularly in low-resource languages where it is challenging to recruit native speakers.</sample>
    <sample id="91">Je mehr Aufgaben es gibt, desto besser perforiert das Modell und desto tiefer sensitivity.</sample>
    <sample id="92">Die Autoren vergleichen ihre Methode mit drei Baselines: Transformer, BERT und RoBERTa.</sample>
    <sample id="93">Die beiden Co-Autoren sind die Berater des ersten Autors.</sample>
    <sample id="94">This paper proposes a backdoor-based watermark method, Embedding Marker, to protect the copyright of embedding as services. It contains two main steps: watermark injection and copyright verification. The watermark injection step defines a target embedding based on the number of triggers in the sentence, while the copyright verification step detects whether another service contains the watermark by computing the cosine and L2 similarity between the requested embedding and the target embedding, and applying the KS test. Experiments on four datasets show that Embedding Marker has great detection performance while keeping great utility for downstream tasks.</sample>
    <sample id="95">David Villegas</sample>
    <sample id="96">Hallo, ich bin Jenny, ein erstjahriger PhD-Studentin an der Carnegie Mellon University. Heute präsentiere ich unser Werk "NL Positionality: Characterizing Design Biases of Datasets and Models". Dieses Werk wurde in Zusammenarbeit mit Forschern an der University of Washington und dem Allen Institute for AI, insbesondere Sebastian Santi, Ronan Le Bras, Katharina Reinecke und Martin Sap, entworfen. Wir beginnen damit, uns vorzustellen. Ich bin Jenny, ein erstjahriger PhD-Studentin an der Carnegie Mellon University. Heute präsentiere ich unser Werk "NL Positionality: Characterizing Design Biases of Datasets and Models". Dieses Werk wurde in Zusammenarbeit mit Forschern an der University of Washington und dem Allen Institute for AI, insbesondere Sebastian Santi, Ronan Le Bras, Katharina Reinecke und Martin Sap, entworfen. Wir beginnen damit, uns vorzustellen. Ich bin Jenny, eine erstjahrige PhD-Studentin an der Carnegie Mellon University. Heute präsentiere ich unser Werk "NL Positionality: Characterizing Design Biases of Datasets and Models". Dieses Werk wurde in Zusammenarbeit mit Forschern an der University of Washington und dem Allen Institute for AI, insbesondere Sebastian Santi, Ronan Le Bras, Katharina Reinecke und Martin Sap, entworfen. Wir beginnen damit, uns vorzustellen.</sample>
    <sample id="97">Die Referentin spricht von zwei Problemen von SimulST: spezifischen Architektur-Training und langer, komplexerer Training-Prozeduren.</sample>
    <sample id="98">Die Reduktion sozialer und politischer Verzerrungen in Datensätzen beim Training von NLP-Modellen ist schwierig, da es schwierig ist zu bestimmen, was als neutrales Datensatz gilt. Es gibt keine eindeutige Lösung, um Datensätze zu reinigen, ohne dabei die Sensibilität oder Exklusion zu riskieren.</sample>
    <sample id="99">Hallo, ich bin C. Yuan von Fudan University und hier, um unsere Arbeit zu Introduzieren: "Distilling Script Knowledge from Large Language Models for Constrained Language Planning". In unserem täglichen Leben planen Menschen oft ihre Handlungen nach Schritt-für-Schritt-Anweisungen in Form von Skripten. Vorherige Arbeiten haben untersucht, wie Sprachmodelle verwendet werden können, um abstrakte Ziele von stereotypischen Aktivitäten zu planen, wie zum Beispiel einen Kuchen zu backen. Es wurde gezeigt, dass große Sprachmodelle effektiv in der Lage sind, Ziele in Schritte zu zerlegen. Allerdings haben vorherige Arbeiten hauptsächlich auf die Planung abstrakter Ziele von stereotypischen Aktivitäten geconcentriert, während die Planung für Ziele mit spezifischen Zielspezifikationen, wie zum Beispiel einen Schokoladenkuchen zu backen, noch ununtersucht blieb. In diesem Papier definieren wir das Problem der eingeschränkten Sprachplanung, das verschiedene Einschränkungen auf die Planung von Zielen imposed. Ein abstraktes Ziel kann durch verschiedene real-life spezifische Ziele mit mehrfachen Einschränkungen erweitert werden. Ein guter Planer sollte Skripte schreiben, die rational und denkbare sind und den Einschränkungen angepasst sind. In diesem Papier erstellen wir zuerst eine evaluierbare und verbesserte Sprachplanungsfähigkeit von großen Sprachmodellen. Da keine Datensammlung von spezifischen Zielen existiert, um unser Studium zu unterstützen, müssen wir zuerst die Ziele erhalten. Im Tabellentitel sehen wir an, wie wir abstrakte Ziele mit mehrfachen Einschränkungen für Menschen in einem Loope-Datenzugriff mit einer Anweisung GPT-3.5-Turbo auswerten. Wir sampling 100 spezifische Ziele und evaluieren die generierten Skripte von großen Sprachmodellen. Das Tabellentitel zeigt die allgemeine Genauigkeit der Ergebnisse an. Wir finden, dass alle großen Sprachmodelle unzufriedenstellende Resultate bei der Planung von spezifischen Zielen erhalten. Dann conducten wir detaillierte Analysen, um zu überprüfen, warum große Sprachmodelle solche Resultate erhalten. Das Diagramm im Bild zeigt, dass die semantische Komplettlosigkeit in den generierten Skripte akzeptabel ist, aber die Einhaltung der Einschränkungen nicht gewährleistet werden kann. Wir dichten in mehrere gradiertere topologische Kategorien der Einschränkungen ein, die in WikiHow definiert sind. Das Heatmap im Bild zeigt, dass die Planungsleistung von Anweisungen GPT-3.5-Turbo variabel für Ziele von verschiedenen Kategorien variiert. Vorherige Studien haben gezeigt, dass die Ausgabequalität von großen Sprachmodellen in einem hohen Varianz liegt, was zu schlechter Leistung führt. Daher adoptieren wir die Idee des "Over-Generativen Filter" zu verbessern die Generationsqualität. Wir zeigen zuerst die verschiedenen Typen von Anweisungen GPT-3.5-Turbo mit Beispielen an und erhalten spezifische Ziele basierend auf den abstrakten Zielen. Dann overgenerates GPT-3.5-Turbo Skripte für spezifische Ziele. Next, ein Filter-Modell wird entwickelt, um die passenden Skripte zu selektieren. Wir konvertieren Skripte und Ziele in embeddings von GPT-3.5-Turbo und berechnen die koseinähnliche Ähren als Ährenscore, um die semantische Ähren相似性 zu messen. In addition, wir bewerten das Skripte, das die Schlüsselwörter der Zielschwelle enthält. Wir only klicken das Skripte, wenn die Zielschwelle am höchsten in dem Zielsatz steht. Mit unserem Methoden GPT-3.5-Turbo können wir Skripte von hohen Qualität generieren. Unsere Methode greatly improves die Planungsfähigkeit sowohl in semantischer Komplettlosigkeit als auch in Einhaltung der Einschränkungen. Da große Sprachmodelle teurer zu deployen sind, ist es wichtig, die Sprachplanungsfähigkeit von kleineren und spezialisierten Modellen zu enabling. Die Erstellung von Datensätzen ist ein wichtiger Schritt zu Ende. Allerdings machen vorherige Studien keine Planung für spezifische Ziele, und die manuelle Datensatznotation ist teuer. Daher folgen wir der Idee der symbolischen Kenntnisdistillation, um die Datensätze für die eingeschränkte Sprachplanung zu distillieren. Wir verwenden unsere Methode, um die Datensätze für die eingeschränkte Sprachplanung zu bauen, die als "Ko-Skript" bezeichnet wird. Insgesamt generieren wir 55.000 spezifische Ziele mit Skripte, um die Qualität der Validierung und der Testdaten zu sicher. Wir bitten Cloud-sourcing Workers, die inkorrekten Samples zu finden und zu überprüfen. Das Bild zeigt die einschränkende Verteilung von Ko-Skript. Wir finden Ko-Skript eine hohere Häufigkeit in den generierten spezifischen Zielen. Mit Ko-Skript können wir kleinere, aber spezialisierte Modelle für die eingeschränkte Sprachplanung verwenden. Wir finden, dass T5-Funktion auf Ko-Skript Skripte von hohen Qualität generieren kann, was mehr große Sprachmodelle übertrifft. Indicating, dass kleinere Modelle große große Modelle unterstützen können, wenn sie auf geeignetem Datensätzen trainiert werden. In summary, wir definieren das Problem der eingeschränkten Sprachplanung, evaluieren die eingeschränkte Sprachplanungsfähigkeit von großen Sprachmodellen und entwickeln einen "Over-Generativen Filter" - Methode für große Sprachmodelle. Wir verwenden große Sprachmodelle, um eine Datensatz von hohen Qualität zu generieren, der als Ko-Skript bezeichnet wird, für die eingeschränkte Sprachplanung. Wir hoffen, Ko-Skript Datensatz kann ein wertvoller Ressource zur Fortschrittsarbeit in der Sprachplanung dienen. Vielen Dank für Ihre Zeit. Sie können weitere Details von Ko-Skript in unserem Papier finden.</sample>
    <sample id="100">This paper presents a few-shot reranking method for multi-hop question answering (QA) using language model prompting. The proposed approach combines unsupervised retrieval with few-shot language model-based reranking to efficiently rank candidate chains for answering complex questions that require multiple reasoning steps. The method involves retrieving a pool of candidate chains, converting them into prompts, and scoring each chain based on the probability of the question given the chain prompt. Experiments on the Hotpot-QA dataset show that the proposed method outperforms fully supervised systems like Dr. Kit and performs comparably to state-of-the-art multi-hop retrievers. Additionally, the paper evaluates the downstream QA performance when using the proposed method as a retriever, demonstrating strong performance in multi-hop QA tasks.</sample>
    <sample id="101">Die Sprachgewandtheit von PaLM ist vergleichbar mit den besten Systemen, aber es macht einen zusätzlichen Fehler in der Genauigkeit.</sample>
    <sample id="102">Die wichtigsten Eigenschaften eines Wasserzeichenverfahrens sind: es sollte anwendbar auf embedding services, should not degrade the utility of the provided embeddings, should be covert enough to the attacker or the attacker can remove the watermark easily, and should be transferable to the attacker's services during the model extraction process.</sample>
    <sample id="103">Die englischen TED Talks wurden in 14 verschiedenen Sprachen übersetzt.</sample>
    <sample id="104">Vier Instanzen werden extrahiert.</sample>
    <sample id="105">Cosinus- und L2-Similarität.</sample>
    <sample id="106">The paper presents a dataset called QUEST, which consists of over 30 million entity-seeking queries containing implicit set operations. The answer entities are verified for relevance to the query, and their associated documents are marked with attributable spans for different query constraints. The dataset poses a challenging retrievable problem since systems need to effectively search over a large document corpus to find multiple answer sets where the attribution for different query constraints can come from different parts of the document. The paper shows that there is a large room for improvement on retriever performance based on the recall of the complete answer set indicated here by the mRecall@100 scores. The N2N system performance in terms of F1 scores is fairly low showcasing the difficulty of systems in handling such queries. Finally, through our analysis we find that queries with set intersection and set difference are particularly challenging and have the lowest F1 scores.</sample>
    <sample id="107">Modelle, die auf einem mehrsprachigen Encoder basieren, wurden in dieser Aufgabe eingesetzt, um die beste Leistung auf allen neun Datensätzen zu erzielen.</sample>
    <sample id="108">This paper revisits the minimal pair paradigm for evaluating language models' acceptability judgments, which can include grammaticality and acceptability in terms of stereotypes. The current NLP pipeline does not allow evaluation on longer sentences, but this work aims to revise it by asking models to evaluate acceptability on longer sequences. The authors simulate longer sequences by recreating sentences with acceptable or unacceptable prefixes from relevant datasets. They find that MPPE judgments are robust for arbitrary context lengths but vary significantly when using sentences from the same dataset or different subsets. This suggests that language models are sensitive to latent syntactic and semantic features shared across sentences, and the current evaluation method may not capture abstract knowledge throughout the context window.</sample>
    <sample id="109">This paper presents a dataset of natural language instructions and their corresponding inputs and outputs, collected in a fully automatic manner without any human annotations. The dataset contains 64K examples, with an additional 240K examples when considering instruction paraphrases. The generated examples are evaluated for correctness, creativity, and diversity, with more than 50% of the generated examples being correct and containing valuable information for instruction tuning. The model trained on this dataset outperforms a baseline model on several benchmarks, demonstrating the ability of language models to produce creative and diverse data.</sample>
    <sample id="111">Die Autoren nehmen an, dass der Anbieter eine allgemeine Textkorpora sammeln und die Häufigkeit jedes Wortes therein zählen kann.</sample>
    <sample id="112">Guten Tag, heute präsentiere ich unser Papier "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?" Ich werde die Bedeutung und den Inhalt des Papiers erklären. Das Papier untersucht das Problem der allgemein anzuwendbaren Erkennung von benannten Entitäten (NER) mithilfe des NER-Task. Wir haben festgestellt, dass Modelle seit fast 20 Jahren auf CoNLL-2003 verwendet wurden, um NER-Modelle zu entwickeln. Dies führt zu mehreren Problemen: Wie können diese Modelle modernen Datensätzen allgemein anwenden? Was ist notwendig, um gute allgemein anzuwendbare Erkennungen zu erzielen? Wenn wir jedoch eine schlechtere allgemein anzuwendbare Erkennung beobachteten, welche Ursache für die Leistungsinkraftsenkung dieser Modelle ist? Um diese Fragen zu untersuchen, haben wir den CoNLL++-Datensatz erstellt. Dieser Datensatz wurde aus Reuters-News 2020 entnommen und mit den gleichen Annotierungsguidelines wie CoNLL-2003 annotiert. Wir haben über 20 Modelle auf CoNLL-2003 optimiert und sie auf both CoNLL-2003 und CoNLL++-Testdatensätzen evaluiert. Wir haben auch den prozentualen Verlust an F1-Maßstab verwendet, um die allgemein anzuwendbare Erkennung jedes Modells zu messen. Um zu erfahren, was für eine gute allgemein anzuwendbare Erkennung erforderlich ist, haben wir durch unsere Experimente festgestellt, dass es drei Hauptkomponenten gibt. Die erste Komponente ist die Modellarchitektur. Unsere Experimente haben gezeigt, dass Transformer-Modelle normalerweise besser auf neue Daten generalisieren können. Der zweite Faktor ist die Modellgröße. Wir haben festgestellt, dass normalerweise größere Modelle zu besseren allgemein anzuwendbaren Erkennungen führen. Schließlich kennen wir alle, dass die Anzahl der Optimierungsbeispiele direkt auf die Leistung des unterliegenden Aufgabengebiets wirkt. Hier haben wir auch festgestellt, dass mehr Optimierungsbeispiele tatsächlich auch zu einer besseren allgemein anzuwendbaren Erkennung führen. Unsere nächste Frage war, welche Ursache für die Leistungsinkraftsenkung einiger Modelle ist. Wir hatten zwei Hypothesen: Die eine Hypothese ist adaptive Übergewichtung, die durch das Wiedervereinben des gleichen Testdatensatzes immer wieder auftritt und normalerweise als Verminderung der neuen Testdaten manifestiert wird. Die andere Hypothese ist Temporal Drift, die Leistungsdegeneration ist, die durch die zunehmende Zeitdistanz zwischen dem Trainings- und Testdatensatz entsteht. Bei der adaptive Übergewichtung haben wir gesehen, dass die rote "best fit" Linie einen Gradienten von mehr als 1 hat. Das bedeutet, dass jede Einheit Verbesserung, die wir auf CoNLL-2003 erreichten, zu mehr als einer Einheit Verbesserung auf CoNLL++ führt, was zeigt, dass adaptive Übergewichtung in diesem Fall nicht auftritt. Was also ist Temporal Drift dann? Für Temporal Drift haben wir ein Experiment durchgeführt, bei dem wir einige Modelle mit jüngster Datensatz forttrainieren ließen. Wir haben festgestellt, dass die Leistungsgrade mit einem größeren Temporal Gap abnimmt. Dies bestätigt unsere Hypothese, dass die Hauptursache für die Leistungsinkraftsenkung Temporal Drift ist. Unsere Schlussfolgerung lautet, dass für eine gute allgemein anzuwendbare Erkennung benötigt werden ein besseres Modellarchitektur, eine größere Modellgröße und mehr Optimierungsbeispiele. Und diese Komponenten hängen einander ab. Gleichzeitig haben wir festgestellt, dass die Leistungsinkraftsenkung durch Temporal Drift auftritt und überraschenderweise nicht durch adaptive Übergewichtung auftritt, obwohl CoNLL-2003 seit über 20 Jahren verwendet wurde. Also zur Frage, die wir im Titel unseres Papiers gestellt haben: "Do CoNLL-2003 taggers still work well in 2023?" Die Antwort lautet, dass die Antwort tatsächlich ein eindeutiges Ja ist. Wir hoffen, dass unser Papier zu mehr Forschung über die Verbesserung der allgemein anzuwendbaren Erkennung von Modellen inspiriert. Und last but not least, bitte überprüfen Sie unser Papier, unser Datensatz und kontaktieren Sie mich, wenn Sie Fragen haben. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="114">This paper introduces a novel approach to addressing the challenges of large language models, particularly focusing on the heavy parameter problem. The authors propose Group Head Attention (GHA), which utilizes a divide-and-conquer strategy to compress multi-head attention by dividing heads into groups and pruning redundant heads. This method achieves significant parameter compression while maintaining performance on various tasks such as machine translation, language modeling, and abstract summarization. The GHA method is evaluated on two models, achieving up to 90% parameter compression with comparable or better performance. The paper also discusses the potential for task-specific automatic pruning, suggesting that redundant parameters can be pruned without sacrificing performance, making large language models more efficient and practical for real-world applications.</sample>
    <sample id="115">Die Sprachsegmentgröße wird auf 3 Milliarden Punkte festgelegt.</sample>
    <sample id="116">Servin ist ein Richter.</sample>
    <sample id="117">Der wichtige Faktor ist die Qualität des Beispiels.</sample>
    <sample id="118">This paper presents a novel approach to improving pre-training techniques for code-switched NLP. The authors propose new MLM techniques and architectural changes to handle code-switching, which is common in linguistically diverse communities like India. They introduce SwitchMLM, which focuses on switch points (transition points between languages) and uses auxiliary losses to enhance language information. The results show that their combined method outperforms other baselines on sentiment analysis tasks. Probing experiments verify the increased switch point information in intermediate layers, motivating further enhancements to the model.</sample>
    <sample id="119">Die Arbeiten konzentrieren sich auf Sprachmodelle mit verschiedenen politischen Neigungen, einschließlich GPT-4 und GPT-3-Series, um die Auswirkungen von politischem Bias zu untersuchen.</sample>
    <sample id="120">Das Modell verwendet Aufmerksamkeitswerte aus einer bestimmten Ebene.</sample>
    <sample id="121">Beispiele für direkte Inferenz sind die Nennung des Songs "Easy on Me" oder seine Position als erstes.</sample>
    <sample id="122">Die Autoren gehören an Peking University.</sample>
    <sample id="123">This research presents MultiInstruct, a multi-modal instruction tuning benchmark dataset consisting of 62 diverse multi-modal tasks covering 10 broad categories. Derived from 21 existing open-source datasets, each task is equipped with five expert-written instructions. The dataset aims to address the lack of publicly available multi-modal instruction tasks and investigates whether instruction tuning on multi-modal pre-trained models can improve generalization to unseen multi-modal tasks. Using OFA as the base model, the study evaluates the performance of instruction-tuned models across various tasks, reporting mean and max performance and standard deviation. Results show that instruction tuning significantly improves OFA's performance on unseen multi-modal tasks, and transfer learning from natural instruction datasets benefits instruction tuning.</sample>
    <sample id="124">This presentation introduces a study on improving the temporal reasoning capabilities of large language models (LLMs). The researchers break down temporal reasoning into three levels: time-to-time, time-to-event, and event-to-event. They evaluate the performance of different LLMs on a comprehensive dataset that covers all three levels and long temporal coverage. The study proposes a new training strategy with two components: temporal span extraction pre-training and time-sensitive reinforcement learning. The results show that the proposed model significantly outperforms other models in various temporal reasoning tasks, including L1 month prediction, L2, and L3 reasoning.</sample>
    <sample id="125">Die Arbeit beteiligen sechs Autoren.</sample>
    <sample id="126">Ja, die Übersetzung der natürlichsprachlichen Anfrage mit einem maschinellen Übersetzungsmodell wurde als Baseline betrachtet.</sample>
    <sample id="127">This paper introduces a method for transferring reasoning abilities from large language models to smaller models using a technique called diverse reasoning. The authors propose using large models as "reasoning teachers" to generate step-by-step solutions for complex tasks, which are then used as training data for smaller models. They compare their method with existing baselines and show that it significantly outperforms vanilla fine-tuning on most tasks, even with the smallest model that has 0.3 billion parameters. The authors also discuss the scalability of their method and the trade-offs involved in development and inference costs.</sample>
    <sample id="128">This paper presents a method for measuring stereotypes in language models using natural language prompts. The authors, Myra, Senn Darmuch, and Dan Juravsky, address the limitations of existing methods by relying on instruction-tuned language models that can generate personas based on specific identity markers. They use a two-part approach: generating personas with prompts inspired by human studies and identifying marked words to distinguish between marked and unmarked groups. The results show that generated personas contain more stereotypes than human-written ones, but have a wider distribution of words. The study highlights the challenges of integrating background knowledge into language models and suggests that task-specific training can help them integrate knowledge from multiple sources.</sample>
    <sample id="129">Die Autoren geben das "starke schwarze Frau" Archetyp als Beispiel für eine markierte Gruppe an.</sample>
    <sample id="130">Die Modellarchitekturen, die nicht gut generalisieren, sind diejenigen, die nicht die Transformatormodellarchitektur verwenden.</sample>
    <sample id="131">Clean test sets.</sample>
    <sample id="132">Die Arbeit beteiligen zwei Autoren.</sample>
    <sample id="133">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="135">ABC-Eval: A New Dimensional Approach to Evaluating Conversational AI

James Finch, Sarah Finch, and colleagues from Emory University and Amazon Alexa AI present ABC-Eval, a novel method for evaluating conversational AI models. This approach assesses multiple dimensions of chat quality by annotating model responses with specific behaviors, such as providing irrelevant information or contradicting oneself. The study evaluates four state-of-the-art chat models using 100 human-bot conversations, comparing results with existing methods like Likert ratings and pairwise comparisons. Findings indicate that ABC-Eval's behavior labels are more reliable and predictive of overall conversation quality, enabling higher-resolution evaluation of conversational AI.</sample>
    <sample id="136">This paper presents a new evaluation set for assessing the mathematical abilities of language models, addressing the limitations of existing benchmarks. The proposed framework, Fermat, includes arithmetic types, number understanding, mathematical operations, and training dependency. By fine-tuning models with math teachers' templates and analyzing their performance on diverse tasks, the study highlights the importance of linguistic and mathematical diversity in improving numerical reasoning capabilities.</sample>
    <sample id="137">This paper introduces Tell2Design, a large-scale dataset for language-guided floor plan generation. It presents a sequence-to-sequence model that generates 2D floor plans from natural language instructions, addressing the challenge of designing based on specific requirements described in text. The dataset includes 5051 human-annotated and 76,000 artificially generated instructions, with an average of more than 200 words per instruction. The model outperforms text conditional image generation baselines by over 10 IU scores, demonstrating its effectiveness in aligning generated designs with user specifications.</sample>
    <sample id="138">Nach Ansicht der Autoren ist ein zu wenig erforschtes Gebiet im Bereich der NLU die Fähigkeit von Modellen, Wissen aus verschiedenen Quellen zu integrieren und zu verwenden.</sample>
    <sample id="139">Die Referenten heißen Ying Shen, Zhiyang Xu und Lifu Huang.</sample>
    <sample id="140">Ja, Coscript wurde von CloudSource Workers überprüft.</sample>
    <sample id="141">Bestehende Ressourcen für kontextbasierte Übersetzung haben Grenzen, da sie nur bestimmte Typen von kontextbasierten Übersetzungen und begrenzte Sprachensegmente unterstützen.</sample>
    <sample id="142">Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus) Mohammad Javad Hosseini, Filip Radlinski, Silvia Paretti, Annie Louis Google Research</sample>
    <sample id="143">Der Ansatz wird mit den Whitkey-Strategien und dem Lokalqualifikationsansatz verglichen.</sample>
    <sample id="144">Die Autoren gehören an Nantes University.</sample>
    <sample id="145">Jenny T. Liang</sample>
    <sample id="146">This paper presents a comprehensive analysis of omission in dialogue summarization, a subtask of text summarization. The authors introduce the background and challenges of dialogue summarization, highlighting the prevalence of omission as a significant issue affecting summary quality. They propose a new dataset for detecting omissions in dialogue summaries, which includes high-quality labels generated through an automatic method and human evaluation. The paper explores three baseline models for omission detection and evaluates their performance using precision, recall, and F1 score. Additionally, the authors demonstrate the effectiveness of a post-editing method that refines summaries by incorporating detected omissions, showing improved summary quality. This work provides a foundation for further research in addressing the omission problem in dialogue summarization.</sample>
    <sample id="147">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="148">Hallo, ich bin Sara Papi von der Università di Trento und Fondazione Bruno Kessler. Ich werde kurz die Papier "Attention as a Guide for Simultaneous Speech Translation" von Matteo Negri und Marco Turchi präsentieren. Was ist Simultane Sprachübersetzung? Simultane Sprachübersetzung (SMT) ist die Prozess von Übersetzen gesprochenem Sprache in Text in einer anderen Sprache in Echtzeit, indem es krußsprachliche Kommunikation ermöglicht. Und was sind die Probleme der aktuellen SMT-Modelle? Spezielle Architekturen werden normalerweise trainiert, indem sie zusätzliche Module optimieren. Long and complicated training procedures, for example, training involving different optimization objectives, and training and maintaining several models to reach different latency regimes, for example, training a model with an average of 1 second latency and another one with 2 seconds latency and so on. Also, was ist unsere Lösung? Zunächst verwenden wir schon existierende off-the-shelf-Modelle, ohne sie zu retrainieren oder spezielle Architekturen für SMT zu adoptieren. Wir verwenden nur ein Modell für jede Latenzregel und handeln Latenz durch spezifische Parameter und nutzen die Kenntnisse, die schon durch die Achtung-Mechanismus zwischen Audio-Eingabe und Textausgabe erworben wurden. Hier sehen Sie ein Beispiel auf der rechten Seite. Unsere Lösung ist die Vorgeschlagene Achtung oder Encoder-Decoder-Achtung, und es ist eine Strategie, bei der wir feststellen, ob wir einen teilweisen Übersetzung emittieren oder nicht, basierend auf, wo die Achtung zeigt. Ein Wort wird emittiert, wenn die Achtung nicht konzentriert ist, das ist, wenn die Summe unter einem bestimmten Schwelle α liegt, in den letzten Lambda-Speech-Frames, was bedeutet, dass die empfangene Information stabil genug ist. Zum Beispiel, wenn wir erhalten haben, dass ein Sprachsegment "Ich werde über etwas sprechen" enthalten ist und unser Modell die Übersetzung in Deutsch vorhersagt, und wir schauen uns die Achtungswerte an, die auf der rechten Seite dargestellt werden, wir sehen, dass die ersten zwei Worte auf die earliest received speech frames zeigt, während die letzte Wort auf die last received speech frames zeigt, also lambda speech frames zeigt. Das bedeutet, dass die ersten zwei Worte emittiert werden. Da die Summe der Achtungswerte über einem bestimmten Schwelle α liegt, werden wir das letzte Wort nicht emittieren und warten auf ein anderes Sprachsegment. Wenn wir fortfahren und ein anderes Sprachsegment erhalten haben, und unser Modell weitere drei Worte vorhersagt, und wir schauen uns die Achtungswerte an, wir sehen, dass keines der Worte auf die last lambda lambda speech frames zeigt. Das bedeutet, dass diese drei Worte emittiert werden. Wenn wir die Hauptergebnisse der Achtung betrachten, plotten wir die Simultane Sprachübersetzung-Rезультатen auf Grafiken, in denen wir auf der linken Seite blau dargestellt haben, die Translation-Qualität messen und durchschnittliche Latenz, das ist die Latenzmessung, und wir berücksichtigen auch die durchschnittliche Reaktionszeit, die die modellischen Reaktionszeiten zur Berechnung des Output betrachtet. Wir wollen, dass unsere Kurve so hoch wie möglich auf dieser Plattform ist, aber wir wollen auch, dass sie links verschiebt sind. Und wir vergleichen mit anderen Strategien, die auf off-the-shelf-Modellen angewandt wurden, die die White-Ki-Strategie und die Lokalqualifikation sind. Und wir vergleichen auch mit den state-of-the-art-Architektur speziell für Simultane Sprachübersetzung. Hier sind die Hauptergebnisse der Simultane Sprachübersetzung-Strategie auf Deutsch. Und wir sehen, dass Achtung übernimmt alle Strategien, die auf off-the-shelf-Modelle angewandt wurden, da die Kurven rechtsverschoben sind. Und wir sehen auch, dass wenn wir die tatsächliche Elapsed-Time oder die durchschnittliche Reaktionszeit berücksichtigen, Achtung die schnellste Strategie ist. Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unser Papier und wir haben auch Open Source, die Code und Modelle und Simultane Ausgabe freigegeben, um die Wiederholbarkeit unseres Werks zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="149">Ja, der Datensatz ist öffentlich zugänglich.</sample>
    <sample id="150">Meeting Q&amp;A: Extractive Question-Answering on Meeting Transcripts

This paper presents a new dataset, Meeting Q&amp;A, for extractive question answering (QA) based on questions asked by participants in meetings and their corresponding answer sentences. The dataset contains 7,700 questions from the AMI Corpus, with 30% unanswerable, 40% multi-span answers, and 48% multi-speaker answers. Questions are longer, open-ended, and elicit detailed responses. The dataset is used to evaluate various QA models, including short context, single span, and multi-span variants. Results show significant performance gaps between fine-tuned models and human performance, with zero-shot results comparable to larger instruction-tuned models like BLIP-5. The dataset highlights challenges in identifying rhetorical questions and speaker attribution, especially in zero-shot settings.</sample>
    <sample id="151">Hallo, wir präsentieren heute unsere Forschung zu MultiInstruct: Eine Verbesserung des multi-modalen Zero-Shot-Learnings durch die Optimierung der Anweisungen. Mit Fortschritten in großen Sprachmodellen haben viele Arbeiten begonnen, neue Lernparadigmen zu untersuchen, indem sie kalt trainierte Sprachmodelle für verschiedene unternehmende Aufgaben in einem effizienten und datenarmen Modus verwenden. In jüngster Zeit haben mehrere Studien gezeigt, dass die Optimierung der Anweisungen große Sprachmodelle dazu bringt, auf Eingabe-Aufgaben in einer Zero-Shot-Weise zu arbeiten, indem sie natürliche Anweisungen folgen. Allerdings haben die meisten vorherigen Arbeiten sich hauptsächlich auf die Verbesserung der Zero-Shot-Performance auf Sprachonly-Aufgaben konzentriert, während Computer Vision- und multi-modale Aufgaben weggelassen wurden. Daher wollen wir in dieser Arbeit untersuchen, ob die Optimierung der Anweisungen auf multi-modul trainierte Modelle tatsächlich die allgemeinste Anpassung an Eingabe-Multi-Modell-Aufgaben verbessern kann. Zudem haben wir bei unserem Forschungsbeginn festgestellt, dass es einen erheblichen Unterschied im Verfügbare von Anweisungsdatensätzen zwischen NLPA und multi-modul gibt. Es existieren mehr als 1600 Sprachonly-Anweisungs Aufgaben, aber es gibt keinen großen öffentlich zugänglichen multi-modul-Anweisungs Aufgabensatz. Daher motiviert uns, einen multi-modul-Anweisungs Optimierungs Datensatz zu erstellen. Hier präsentieren wir MultiInstruct, den ersten multi-modul-Anweisungs Optimierungs Datensatz, der 62 diverse multi-modul Aufgaben umfasst, die 10 Hauptkategorien abdecken. Diese Aufgaben werden aus 21 bestehenden offenen Quellen Datensätzen abgeleitet und jede Aufgabe ist mit 5 Experten definiertem Anweisungen ausgestattet. Um die Optimierung der Anweisungen auf unserem vorgeschlagenen Datensatz zu untersuchen, nehmen wir OFA, eine vereinheitlichte multi-modul trainierte Modell als Basismodell. OFA verwendet eine vereinheitlichte Vokabel für Sprach-, Bild-, Token und Koordinate vonBounding-Boxes. Hier zeigen wir einige Beispielinstanzen aus unserem MultiInstruct Datensatz. Um die vereinheitlichte Verarbeitung von verschiedenen Eingabe- und Ausgabedatentypen zu gewährleisten, folgen wir dem Ansatz von OFA und formulieren alle Aufgaben in einem vereinheitlichten sequenz-to-sequence Format, in dem die Eingabe-Texte, Bildeinzelheiten, Anweisungen undBounding-Boxes im gleichen Tokenraum dargestellt werden. Okay, nun werde ich über multi-modul-Anweisungs Optimierung sprechen. Also für die Trainingsdatenbank benutzen wir 53 Aufgaben aus dem NLP Gruppe für Training und wir sampling 10.000 Instanzen pro Aufgabe. Für die Testphase reservieren wir die gesamte Commonsense Reasoning Gruppe für die Testphase und wir selecten weitere 5 Aufgaben aus dem Wiki und denMiscellaneous Gruppe. Wir verwenden alle Instanzen in der Testsplit für jede Aufgabe. In addition wir randomisieren sampling 20 Aufgaben aus der Testsplit von Natural Instruction als Anweisung Aufgabensatz für NLPA. So wir verwenden einen trainierten OFA Large Modell als Basismodell. During Training wir mix all die Instanzen für all die Aufgaben. Jede Instanz wird zufällig kombiniert mit einem von 5 Anweisung Template. Also during Test für jede Aufgabe wir conduct the total of 5 experiments by evaluating the Modell using 1 von 5 Anweisungen in each experiment. Wir report the min and max performance and the standard deviation of the performance across all five experiments. If the task is a multi-modul classification task wir report accuracy. If it's a multi-modul generation task wir report ROUGE. For NLPA tasks wir report ROUGE as well. We also introduced a additional evaluation metric called sensitivity. So this measures the Modell's ability to consistently produce the same outputs for the same task regardless of slight variation in the wording of the instruction. Here is our main results. As we can see Anweisungs Optimierung can significantly improve OSA's performance on seeing multi-modul tasks. Also transfer learning from natural instruction datensatz can benefit Anweisungs Optimierung. Here we can see as the amount of task increases the model achieve better performance and in the meantime lower sensitivity. So we also do one experiment we use one instruction versus five instruction. As we can see using more instruction can improve the model's overall performance and reduce its sensitivity a lot. So this shows the effect of different fine-tuning strategy on the model's sensitivity. As we can see by transfer learning from natural instruction datensatz the model can achieve much better sensitivity compared to our original OFA model. We also can see transfer learning from natural instruction datensatz can help OFA to achieve much better performance on the natural instruction datensatz. So overall we propose the first large-scale multi-modul Anweisungs Optimierungs Datensatz which significantly improves the zero-shot capability of OFA and we explore different transfer learning technique and show their benefits. We design a new metric called sensitivity. So one more thing we are collecting a much larger multi-modul Anweisungs Optimierungs Datensatz with around 150 additional visual language tasks and we will release them so this is the QR code for our data and model. Thank you.</sample>
    <sample id="152">This paper presents new language models for classical philology, specifically designed for ancient Greek and Latin texts. The authors introduce two monolingual models (GreekBERT and LatinBERT) and a multilingual model (GreekLatinEnglishBERT) pre-trained on ancient Greek, Latin, and English data. They leverage various resources, including OpenGreek and Latin, and the Internet Archive, to create high-quality pre-training corpora. The models outperform existing state-of-the-art models in tasks such as speech tagging, dependency parsing, and lemmatization. The paper also analyzes the performance of the T5 encoder-decoder architecture and investigates the impact of multilinguality on model performance.</sample>
    <sample id="153">This paper presents a framework for resolving ambiguities in prompts provided to text-to-image generative models. The authors curate a benchmark dataset covering different types of ambiguities and propose frameworks to mitigate and evaluate these ambiguities. They use a language model to generate clarifying questions or possible visual setups, which are then answered by the user to disambiguate the prompt. The disambiguated prompts are used to generate images, and an automatic evaluation framework is proposed to assess the faithfulness of the generated images to the user's intention. The results show that resolving ambiguities has a positive effect on faithful generation and that the automatic evaluation framework agrees with human evaluation.</sample>
    <sample id="154">Die Autoren Sara Papi, Matteo Negri und Marco Turchi gehören an der Università di Trento und Fondazione Bruno Kessler.</sample>
    <sample id="155">Javad Hosseini</sample>
    <sample id="157">This paper introduces a dialogue summarization method that combines static and dynamic graph structures to capture the semantic relationships between utterances. The proposed model uses an utterance encoder to generate vector representations of utterances, constructs a static graph using existing dialogue structure modeling methods, and then employs a dynamic graph module to capture the semantic relationships based on deep vector representations. A pretrained language model is used as the summary generator to fuse the static and dynamic dialogue structures into a final summary. The model is evaluated on the Ubuntu dataset and achieves state-of-the-art performance.</sample>
    <sample id="158">This paper introduces a dual cache method for long document neural coreference resolution. The proposed method uses a local cache and a global cache to store local and global entities, respectively. The local cache employs an LRU eviction policy, while the global cache uses an LFU policy. The model achieves better performance than baseline methods on public benchmarks with training data, even when using unbounded memory. Without training data, the model with unbounded memory performs slightly better, but the dual cache is still faster. The dual cache significantly reduces cache misses compared to a single cache and has the highest performance-cost ratio among cache-based models.</sample>
    <sample id="159">Hallo, ich bin Koustuv Sinha und ich freue mich, Sie willkommen zu unserem Vortrag auf unserem ACL 2023 Papier "Sprachmodell-Acceptabilitätsschätzungen sind nicht immer robust gegenüber Kontext" willkommen zu begrüßen. Dies ist ein gemeinsames Werk mit John Gauthier, Aaron Mueller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina Williams. In diesem Werk revisitieren wir das Minimal Pair Paradigma. Das Minimal Pair Paradigma bewertet Sprachmodelle auf Basis von Acceptabilitätsbewertungen, die auch Grammatik, wie Bleep-Syntactic-Jam, oder Akzeptierbarkeit in Bezug auf Stereotypen wie CrowdSparks einschließen können. In diesem Paradigma wird üblicherweise geprüft, ob ein Sprachmodell einem akzeptablen Satz oder einem grammatikalischen Satz mehr Wahrscheinlichkeit zuweist als einem unakzeptablen Satz oder einem ungrammatikalischen Satz. Der aktuelle MPP-Pipeline bietet leider keine Möglichkeit, die Akzeptanz von Modellen gegenüber langen Sätzen zu bewerten. Heute werden große Sprachmodelle mit immer langeren Kontextfenstern entwickelt, daher ist es von Bedeutung, die Akzeptierbarkeit von Modellen über den Kontextwindow zu bewerten. Hier versuchen wir, die MPP-Pipeline zu revisitieren, indem wir die Modellbewertung auf lange und lange Sequenzen ausstrecken. Um dies zu erreichen, simulieren wir diese langen Sequenzen, indem wir die Datensätze revisitieren und dann Sätze erstellen, indem wir akzeptablen oder unakzeptablen Sätze aus diesen Datensätzen auswählen. Zum Beispiel haben wir einen typischen Paar von Grammatikfehlern aus dem Bleep-Datensatz aus dem Adjunct Island Fall gewählt und haben versucht, lange Sequenzen zu erstellen, die akzeptabel sind und die gleiche Grammatikstruktur haben. Wir extrahieren Grammatik-Sätze aus dem Adjunct Island und fügen sie als Prefix zu beiden akzeptablen und unakzeptablen Abfragen hinzu. Wir können dasselbe machen, indem wir Sätze aus einem anderen Datensatz oder einer verschiedenen Gruppe auswählen. Wir nennen dies als Missmatch-Szenario. Hier sind die Sätze immer noch aus relevanten Datensätzen stammt, aber sie stammt nicht aus dem Datensatz, auf den wir bewerten. Wir können dasselbe für die Unakzeptierbarkeitsbewertung tun. Schließlich können wir Sätze aus einem vollständig unverwandten Bereich wie Wikipedia auswählen. Dies zeigt uns, ob die Bewertungen der Modell-Akzeptierbarkeit durch den Kontext beeinflusst werden, ob der Kontext aus einem anderen Datensatz stammt oder ob er für die aktuelle Abfrage irrelevant ist. Wie bewertet das Modell? Zunächst schauen wir uns die Wikipedia-Sätze an, die completely irrelevant zu der aktuellen Abfragenpaar sind. Wir finden, dass die MPP-Bewertungen hauptsächlich robust gegenüber beliebiger Kontextlängen sind. Wir haben die Kontextlängen bis zu 1244 für die Max-out OTP und GP T2-Modelle gesteigert und sahen hier im orange Balken, dass die MPP-Bewertungen relativ stabil sind. Nun sehen wir, was passiert, wenn wir Sätze aus demselben Datensatz verwenden. Hier warten wir auf Sätze aus akzeptablen und unakzeptablen Domänen aus demselben Bleep-Syntactic-Jam-Datensatz und sehen, dass die MPP-Bewertungen entweder stark steigen oder fallen, wenn wir akzeptable oder unakzeptable Präfixe verwenden. Aber wenn wir die Struktur匹配, also wenn wir Sätze aus demselben Phänomeno im Bleep-Syntactic-Jam-Datensatz verwenden, sehen wir einen enormen Anstieg oder einen enormen Abfall der MPP-Bewertungen für das Modell, je nachdem, ob der gewählte Präfix akzeptabel oder unakzeptabel ist. Nun und nun ist dies sehr großartig, wie dieser Effekt throughout die Kontextlängen zunimmt und das würde wahrscheinlich die neuen Sprachmodelle beeinträchtigen, die einen großen Kontextwindow haben. Warum beeinträchtigen die match-Präfixe die Sprachmodellbewertungen so stark? Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, die Eingabeaussage zu perturbieren, indem wir versucht haben, die relevanten Strukturen zu erhalten, aber dennoch Lärm zu denken. Nachdem wir mehrere dieser Perturbationen durchgegangen sind, haben wir festgestellt, dass keines der Lärm actually die Modell bewertungen verändert hat, indem es die MPP-Bewertungen beeinträchtigt. Basically haben wir festgestellt, dass die Modelle sensible zu den perturbten Sätzen sind, die ähnlich sind. Dass wir perturbte Sätze in einem akzeptablen Bereich verwenden, sehen wir eine ähnliche Steigerung an allen Perturbationen und wenn wir perturbte Sätze in einem unakzeptablen Bereich verwenden, sehen wir einen Abfall in MPP-Bewertungen in ähnlicher Weise. Also die Haupttakeaways von unserem Werk sind, dass Sprachmodelle sensible zu latenten syntagmatischen und semantischen Merkmalen sind, die sich über die Sätze teilen, und die MPP-Evaluation, die wir momentan mit kurzen und einfachen Eingabeaussagen durchführen, mag nicht vollständig das abstrakte Wissen der Sprachmodelle über den Kontextwindow abdecken. Lesen Sie bitte unser Papier für weitere Details über unsere Experimente. Vielen Dank für das Hören.</sample>
    <sample id="160">Unordered Multiset of Tokens</sample>
    <sample id="161">In Coscript sind 55.000 Skripte vertreten.</sample>
    <sample id="163">Die beste Ausrichtungsmethode für DEplain ist die Methode von Massalign.</sample>
    <sample id="164">Schwach überwachtes Lernen ist viel billiger, da es die Datenermittlung nicht erfordert.</sample>
    <sample id="165">This paper presents an unsupervised learning method called LIPOR (Likelihood Learning with Posterior Regularization) for adaptive reasoning. It treats explanations as latent variables and maximizes the marginal likelihood of the outcome given the context by marginalizing over all possible explanations. To prefer plausible explanations, a regularizer is introduced to enforce mutual exclusivity among explanations. The LIPOR objective consists of maximizing the likelihood of outcomes and preferring some explanations over others. The paper compares LIPOR to zero-shot models and the previous best unsupervised approach on Alpha-ALI, achieving over four absolute points in accuracy.</sample>
    <sample id="166">This research introduces a neural divide-and-conquer reasoning framework for image retrieval from linguistically complex text. It addresses the challenge of retrieving images from texts with complex visual-linguistic representations by integrating symbolic reasoning with deep learning models. The proposed method consists of two main components: a symbol generator that creates symbolic representations of the text-image pairs, and a neural symbolic reasoner that integrates these representations to retrieve the final solution. Experimental results demonstrate the effectiveness of the proposed method in outperforming baseline models on various datasets.</sample>
    <sample id="167">Die Dokumente in DEplain-web wurden auf der einen Seite manuell und auf der anderen Seite mit automatischen Alignmentmethoden ausgerichtet.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde durch die Sammlung von Artikeln aus Reuters News aus dem Jahr 2020 erstellt und mit den gleichen Annotieranweisungen wie CoNLL-2003 annotiert.</sample>
    <sample id="169">This paper presents a systematic study of prompting strategies for large language models (LLMs) in machine translation. It evaluates the translation capability of LLMs using best practices from the NMT community, comparing state-of-the-art systems and showing expert-based human evaluation results. The study concludes that example quality is more important than similarity to the source sentence, and that specialized state-of-the-art systems still have an advantage over LLM translations.</sample>
    <sample id="170">Hallo, jeder. Mein Name ist Justin Jung vom Peking University. Heute werde ich über mein Werk sprechen: "Exemplar: Korsinglog Semantik Parsen in mehreren natürlichen Sprachen und vielen Repräsentationen." Semantik Parsen ist die Aufgabe, semantische Repräsentationen von Benutzereingaben wie SQL und Lambda Calculus zu erstellen. Korsinglog Semantik Parsen ist die Aufgabe, Eingaben in mehreren natürlichen Sprachen in mehrere Repräsentationen zu übersetzen. Wie in diesem Bild gezeigt, müssen wir die Eingabe in mehrere natürliche Sprachen mit neuronalen Modellen in SQL, Lambda oder FunkQL und so weiter übersetzen. Existierende korsinglog Semantik Parsen-Modelle werden separat vorgeschaffen und auf Datensätzen von limitierten Aufgaben evaluiert. Zum Beispiel gibt es Lücken in der Abdeckung auf bestimmte natürliche Sprachen - das Chinesische wird fehlend, und Lücken in der Abdeckung auf bestimmte Repräsentationen - das Lambda-Kalkül wird fehlend, oder sie werden nur auf bestimmte neuronalen Modelle evaluiert. Zum Beispiel gibt es nur ein einziges Modell, um sie zu evaluieren. Um dies zu beheben, schaffen wir Exemplar, um einen uniformen Datensatz Exemplar für korsinglog Semantik Parsen in mehreren natürlichen Sprachen und vielen Repräsentationen zu bieten. Er enthält 9 Datensätze in verschiedenen Domänen, 5 Semantik Parsen Aufgaben, 8 Repräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien. Um unser Benchmark besser zu evaluieren, betrachten wir sechs Szenarien für Training und Evaluation. Der erste ist "Translate Test". Wir verwenden die Google-Übersetzungs-API, um die Quelle in die Zielsprache zu übersetzen, dann verwenden wir einen monolingualen Modell zu trainieren und zu evaluieren. Zum Beispiel trainieren wir ein englisches Modell auf einem englischen Query und während der Inferenz übersetzen wir einen deutschen Query mit API in englisch und verwenden dann das trainierte Modell, um den SQL zu predictieren. Wir testen auch monolingual-Modell in diesem Setting. In diesem Setting ist die Quellsprache dieselbe wie die Zielsprache, zum Beispiel Deutsch zu Deutsch oder Englisch zu Englisch. Wir testen auch monolingual-Few-Shot-Setting, bei dem wir Modell-Modelle mit nur 10% des Trainingsdatums trainieren. Wir testen auch monolingual-Multi-Lingual-Model, bei dem wir einen Multi-Lingual-Model für alle Sprachen trainieren. Zum Beispiel: wir legen deutsche, englische, chinesische Abfragen zusammen, um ein Multi-Lingual-Model zu trainieren, und während der Inferenz können wir verwenden, um ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...</sample>
    <sample id="171">Existierende Arbeiten können allgemein in vier Kategorien kategorisiert werden.</sample>
    <sample id="172">Nein, Codex und Bloom sind noch nicht ausreichend für CLSP-Tasks.</sample>
    <sample id="174">This video provides an overview of ArgAnalysis35K, a large-scale dataset for argument quality analysis. The dataset is unique due to its high-quality arguments, diverse range of motions, and the inclusion of analysis elements that combine claims and premises. It also introduces instance-based annotator reliability and a relevance model to capture the relevance of arguments to specific themes.</sample>
    <sample id="175">Die Methode mit der Mehrdeutigkeit der Permutationen wird durch die Induktion der Ausrichtung als Teil des Trainings bewältigt.</sample>
    <sample id="176">Die Fairness eines nachgeschalteten NLP-Modells wird definiert, indem man prüft, ob das Modell in der Identifikation von Hasssprache oder Falschinformation gegenüber bestimmten sozialen Gruppen effizienter ist.</sample>
    <sample id="177">The presenter is Yanis Labrak.</sample>
    <sample id="178">The speaker's name is Zhu Hong.</sample>
    <sample id="179">This paper introduces Symbolic Tom, a plug-and-play method to enhance theory of mind reasoning in large language models (LLMs). It presents an inference-time algorithm that computes explicit graphical representations of mental states for multiple characters. These graphs are used to answer complex questions about characters' beliefs and intentions, improving the model's performance on out-of-domain tasks. The method is evaluated against supervised baselines and shows significant gains in accuracy, particularly in handling second-order false belief questions and generalizing across different datasets.</sample>
    <sample id="180">Myra Cheng</sample>
    <sample id="181">This paper introduces a method for generating constrained language plans using large language models. It defines the problem of constrained language planning, which involves imposing different constraints on goal-oriented planning. The authors evaluate and improve the constrained language planning ability of large language models by extending abstract goals with multi-faceted constraints. They develop an over-generated script filter to select feasible scripts based on semantic similarity and constraint adherence. The method is applied to build a high-quality dataset for constrained language planning, demonstrating that smaller models can generate high-quality scripts when trained on suitable data sets.</sample>
    <sample id="182">Tropikalismus bezieht sich auf die Tendenz, bestimmte Gruppen von Menschen als "tropisch" zu sehen, was in diesem Fall eine Form von hypersexuellerisierungsstereotypisierung ist.</sample>
    <sample id="183">Die Autoren haben Menschen gebildete Befehle gegeben, um Menschen zu beschreiben, indem sie bestimmte Identitäten in einem Pseudo-Identitäten-Skript eingesetzt haben.</sample>
    <sample id="184">In dieser Arbeit wurde CXMI (Contextualized Cross-lingual Machine Translation Information) verwendet, um die Kontextnutzung zu messen.</sample>
    <sample id="185">DrBERT ist ein robustes prätrainingsoffenes Modell in Französisch für Bio-medizinische und klinische Anwendung, das auf Roberta basiert und trainiert wurde auf NACHOS, einem Datensatz von Medienkrawel-Daten aus der Web. ChuBERT hingegen basiert auf anonymisierten Daten, die aus dem Non-Universität Hospital Data Warehouse abgeleitet wurden.</sample>
    <sample id="187">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="188">Iteratives Transferlernen ist ein Verfahren, bei dem ein Modell auf einem Datensatz trainiert wird und dann auf einem neuen Datensatz weitertrainiert wird, um das Modell zu verbessern.</sample>
    <sample id="189">Das Ziel des Datensatzes ist, die Informalität in der Sprache zu berücksichtigen und alternative Fragen zu generieren, um die Entscheidungsfindung bei indirekten Beziehungen zu verbessern.</sample>
    <sample id="190">Ein Angreifer kann Modellparameter über einen EaaS extrahieren, indem er die Watermark-Methoden verwendet, um den Watermark zu entfernen und die Parameter zu extrahieren.</sample>
    <sample id="191">Die Arbeit beteiligen sich drei Autoren: Sara Papi, Matteo Negri und Marco Turki.</sample>
    <sample id="192">The presentation introduces a novel optimizer called "Can" that aims to achieve fast convergence similar to traditional adaptive methods and low memory usage like memory-efficient optimizers. It uses non-negative matrix factorization (NMF) for memory reduction and incorporates a confidence-guided adaptive updating strategy to handle the instability in updates. The optimizer is tested on training tasks of three large language models, showing significant improvements in validation accuracy and efficiency compared to existing optimizers like Adam and AdaFactor.</sample>
    <sample id="193">Um den ursprünglichen Datensatz zu erstellen, wurden 43 Annotatoren verwendet.</sample>
    <sample id="194">Die Autoren sind an Carnegie Mellon University und University of Washington.</sample>
    <sample id="195">This paper presents a systematic study of large language model prompting for machine translation. We evaluate the translation capability of such models using the best practices of the NMT community, and compare two state-of-the-art systems. We use state-of-the-art NMT metrics and show expert-based human evaluation results. We provide some recommendations for prompt selection strategies. The prompting has a big influence on the performance of the LLMs for translation. In our experiments, we conclude that the example quality is more important than the similarity to the source sentence. It's important to select the examples from high-quality translations. We compare the selecting prompts from the training data of the NMT evaluations or the dev data. The dev data is much more curated and with higher quality than the train data. The results show better performance when using the dev data.</sample>
    <sample id="196">Die Beispiele mit dem Begrenzer auf der linken Seite sind "Lisa bought and Meggy" und "Egor Milchuk's meaning text theory."</sample>
    <sample id="197">Die Stand der Technik für Dialogsysteme wird von Menschen bewertet, indem sie Entscheidungen treffen, um zu bestimmen, welche von zwei Konversationen besser ist, oder indem sie Konversationen auf einer Likert-Skala bewerten.</sample>
    <sample id="198">Weil große Sprachmodelle heutzutage mit immer langeren Kontextfenstern arbeiten und es wichtig ist, die Akzeptanz der Modelle über das gesamte Kontextfenster zu bewerten.</sample>
    <sample id="199">Ja, das mehrsprachige Training hat in einigen Datensätzen zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="200">Ja, die Annotatoren kennen die Entität im Voraus.</sample>
    <sample id="201">Die MT-Metriken wurden für die Bewertung verwendet.</sample>
    <sample id="202">Ja, die Regression beeinträchtigt bestimmte NER-Typen negativ.</sample>
    <sample id="203">Positionalität ist für NLP wichtig, weil sie die Systematiker performanceunterschiede technologien zwischen Bevölkerungen und die Aggregation von Urteilen und Meinungen realer Menschen in Datensätze und Modellen repräsentieren kann.</sample>
    <sample id="204">Die mehrsprachigen LLMs wie BLOOM wurden durch Adapter angepasst.</sample>
    <sample id="205">This paper presents a study on the political biases in language models and their impact on downstream tasks. The authors investigate how language models learn from diverse political perspectives, which can lead to social biases in NLP applications. They evaluate the political leanings of language models using the political compass test and conduct controlled experiments with pre-trained language models on partisan corpora. The results show that language models have varying political leanings and can pick up polarization from training data. The authors also examine the performance of language models on hate speech and fake news detection tasks, revealing patterns of bias based on political leanings. The study highlights the need to address fairness issues resulting from language model political biases and discusses the challenges of sanitizing political opinions in training data.</sample>
    <sample id="206">Sie verwenden das Modell CEA (Comparison and Expansion) für das Transferlernen.</sample>
    <sample id="207">Die besten übersetzten Systeme wurden verwendet, um die Übersetzungsfähigkeiten von PaLM zu bewerten.</sample>
    <sample id="208">Die Autoren haben schließlich drei Empfehlungen vorgeschlagen.</sample>
    <sample id="209">Die vorgeschlagene Methode bringt einen Gewinn von 17,3% gegenüber dem stärksten Baseline.</sample>
    <sample id="210">Shuheng Liu</sample>
    <sample id="211">Ja, die Studie schlägt die Ergebnisse und den Datensatz als Benchmark für zukünftige Studien zur automatischen Textsimplifizierung vor.</sample>
    <sample id="212">In der Arbeit werden 55.000 spezifische Ziele mit Skripten generiert, um die Qualität der Validations- und Testdaten zu gewährleisten.</sample>
    <sample id="213">Die Basismodell-Unterrichtsabstimmung wird als Basismodell verwendet.</sample>
    <sample id="215">The paper presents an argument for the symmetric structures of coordination against asymmetric structures. It is based on the principle of dependency length minimization, which states that shorter dependencies are preferred. The paper shows that left conjuncts tend to be shorter when the governor on the left is absent, and this tendency grows with the length difference between the two conjuncts. This effect disappears when the governor is on the right. The paper provides evidence from statistics extracted from the enhanced version of the Penn Treebank and supports the argument for symmetric structures of coordination.</sample>
    <sample id="217">This paper introduces a method for generating controllable dialogues with multiple attributes using a disentangled control generation (DCG) approach. The proposed DCG model learns attribute concepts from input values and uses a disentanglement loss to disentangle different attribute combinations. A unified reference-free evaluation framework (MAE) is introduced to assess the quality of generated dialogues, which does not require large-scale labeled data. Experiments show that the DCG model outperforms baseline methods in terms of controllability and test quality, demonstrating its effectiveness in transforming single attributes into unseen combinations.</sample>
    <sample id="218">Die Autoren gehören an Google Translate.</sample>
    <sample id="219">This paper presents a multi-stage pipeline for highlighting financial signals in financial reports. The authors propose a highlighting task to compare and contrast the context between target and reference reports, which are the report of interest and the report at its previous year, respectively. They define three types of pairs: type B pairs with higher syntactic and semantic similarities, revise pairs with similar syntactical patterns but different meanings, and mismatch pairs with new information or company operations. The model uses an external dataset (ESNL) for out-of-domain fine-tuning and a revised pair dataset for in-domain fine-tuning. The results show that the proposed method achieves the best performance on the final dataset and preserves the generalization capability.</sample>
    <sample id="220">Die Autoren sind an der Stony Brook University.</sample>
    <sample id="221">Die Arbeit untersuchte Sprachpaare, die von Google Translate verwendet wurden.</sample>
    <sample id="222">This work investigates data interventions for enabling out-of-domain generalization in open-domain question answering (QA). It identifies the type of dataset shift a new domain exhibits and determines which data interventions are effective for specific types of shifts. The authors use Wikipedia as the source domain and test generalizability on seven target datasets spanning six different domains. They explore zero-shot and few-shot methods, including generating examples from the target domain to prompt large language models and controlling interactions among question, answer, and context variables. The results show that few-shot techniques improve retriever performance by 8% and reader performance by 11% on average. For zero-shot techniques, changing format does not significantly affect model performance, but closed-style questions are easier to curate. The study also examines compatibility between the source model and target datasets using existing taxonomy in machine learning. The results indicate that all target sets respond well to few-shot adaptations, while concept and covariate shifts respond better to zero-shot adaptations.</sample>
    <sample id="223">Sarah Papi</sample>
    <sample id="224">Während der Experimente wurden zwei Modelle untersucht: Long Impart und Normal Base Long Impart.</sample>
    <sample id="225">53 Aufgaben werden für die Trainingphase verwendet, und 10 Aufgaben werden für die Testphase verwendet.</sample>
    <sample id="226">Es sind zwei Autoren an der Arbeit beteiligt.</sample>
    <sample id="227">This paper introduces a novel framework for grounded language understanding, named Pangu, which leverages the strength of language models in discrimination rather than generation. The framework consists of a symbolic agent that interacts with an environment to propose candidate plans, while a language model is used only to score and rank these candidates. This approach allows language models to focus on evaluating the validity and grammar of proposed plans without generating them, addressing the challenges of current methods that often produce invalid or non-executable plans. The paper demonstrates Pangu's effectiveness across various language models and training settings, including fine-tuning and in-context learning, showing strong performance and sample efficiency.</sample>
    <sample id="228">Die Autoren haben experimentiert an den Datensätzen AGNews, 20NewsGroup, SST-2 und Yahoo! Answers.</sample>
    <sample id="229">This paper presents a joint work on detecting improvable claims for argumentative writing support. The authors introduce two new tasks: suboptimal claim detection and claim improvement suggestion. They explore how to model the quality of argumentative texts based on implicit revision patterns found in collaborative online debate platforms such as Kiyo. The paper delves into four main challenges: representativeness and reliability, model complexity and architecture, contextual information, and topical and user bias. The authors conclude that revision-based data can be effectively employed for the given tasks, and modeling the distance between two claim versions is beneficial for detecting suboptimal claims.</sample>
    <sample id="231">NACHOS ist ein Datensatz von medizinischen Crowdedata, der vom Web stammt.</sample>
    <sample id="232">The speaker's name is Ibilard.</sample>
    <sample id="233">This paper introduces a novel strategy for simultaneous speech translation (SST) using encoder-decoder attention mechanisms. The proposed method, called "ADT," utilizes pre-trained offline models without retraining or specific architecture modifications. It dynamically decides whether to emit partial translations based on the cross-attention weights between audio input and textual output. The strategy ensures high translation quality while maintaining low latency and computational efficiency. Experimental results demonstrate that ADT outperforms existing strategies applied to offline models, achieving superior performance in terms of translation quality, latency, and computational resources.</sample>
    <sample id="234">Die Strategie der Prompting beeinflusst die Ergebnisse, indem sie die Reliabilität und Informationsfähigkeit der Evaluiermethoden verbessert.</sample>
    <sample id="235">Die Autoren gehören an Carnegie Mellon University.</sample>
    <sample id="236">Jede Aufgabe im Datensatz ist mit 5 Anweisungen der Expert*innen ausgestattet.</sample>
    <sample id="237">Die Autoren schlagen einen Diagnostik-Test-Satz für die Integrität von Kenntnis vor, der eine Korreferenz-Resolutionsaufgabe enthält, um zu beweisen, dass Modelle in der Lage sind, Kenntnis aus verschiedenen Quellen zu ziehen.</sample>
    <sample id="238">This video presents a new benchmark dataset, MeetingBank, which addresses the challenges of high-quality meeting summaries and the difficulty in locating trustworthy resources for public meetings. The dataset includes 1366 city council meetings with nearly 7000 instances, featuring meeting transcripts, reference summaries, and URLs containing useful resources. Data collection involves converting audio to transcripts using speech-to-text APIs, identifying meeting types from websites, and aligning time stamps to segment transcripts. The dataset provides statistics on meeting duration, token count, speaker frequency, and year period. Evaluation metrics include coverage and density scores, with results indicating that GPT-3 performs well in fluency and coherence but less so in informativeness and factuality. Human evaluation further assesses summary quality based on criteria such as informativeness, factuality, fluency, coherence, and redundancy.</sample>
    <sample id="239">Hallo, alle zusammen. Mein Name ist Ibilard, und ich werde Ihnen einen kurzen Überblick über das Papier "Prompting PaLM for Translation: Assessing Strategies and Performance" geben. Dies ist einJoint-work mit meinen Kollegen von Google Translate. PaLM ist ein 540 Milliarden Parameter langer Sprachmodell, das vor einem Jahr, im Jahr 2022, präsentiert wurde. Es ist trainiert auf einer großen Sammlung von Texten, die 780 Milliarden Token umfasst. Auf dem Datensatz der Evaluation erreicht es das State-of-the-Art in Hunderten von NLP- Aufgaben. In diesem Werk präsentieren wir die erstmalige systematische Studie von LLM-Sprachmodell-Prompting für maschinelle Übersetzung. Wir evaluieren die Übersetzungsfähigkeit solcher Modelle unter Verwendung der besten Praktiken der IMT-Community. Das impliziert, die neuesten Testsets zu verwenden, um einen Ablauf der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden. Und wir vergleichen zwei State-of-the-Art-Systeme, also die besten performenden Systeme der IMT-Evaluation. Wir verwenden state-of-the-art- Newman-MIT-Metris und zusätzlich auch Expert-basierte menschliche Evaluationsergebnisse. Letztendlich, wir bieten einige Empfehlungen für Promptselektionsstrategien. Das Prompting hat einen großen Einfluss auf die Leistung der LLMs für Übersetzung, wie wir in einem einfachen Experiment sehen können, bei dem wir ein-shot-Prompting verwenden und zwei verschiedene Prompts für eine bestimmte Anzahl von Sätzen verwenden. Die Mehrzahl der Sätze, 516 von 1000, die Differenz abserviert, ist von mehr als einem BLEU-Punkt, und dies kann in extremen Fällen bis zu 40 BLEU-Punkten betragen. Es ist wichtig, einen guten Prompting-Strategie zu auswählen. In our experiments, wir sind für eine 5-shot-Prompting-Strategie gekommen, bei der wir einfach jede Anzahl von Sätzen, die wir dem System übergeben, mit dem Sprache markieren, die es übersetzen soll. In diesem Beispiel hier, wo wir Übersetzungen von Deutsch ins Englische machen, werden die Quellsätze mit dem deutschen Klon markiert und die englischen Übersetzungen mit dem englischen Klon markiert. Wir haben gesehen, dass die Form der Prompting-Beispiele keinen großen Einfluss auf die Leistung hat, in unserem Fall bei 5-shot-Prompting. Es ist für 0- und 1-shot-Prompting crucial, und wenn wir uns auf 5-shot-Prompting konzentrieren, gibt es fast keine Unterschiede in der Form der Prompting-Beispiele. Es sind die Beispiele, die den meisten Gewicht tragen. Der Auszug aus unserem experimentellen Resultat lautet, dass die Qualität der Beispiele wichtiger ist als die Ähnlichkeit zu den Quellsätzen. Es ist wichtig, Beispiele von hohen Qualität zu auswählen. Insbesondere verglichen wir die Selektionsprompts aus dem Trainingsdatensatz der IMT-Evaluation mit den Dev-Daten. Die Dev-Daten sind viel präziser und mit heller Qualität als der Trainingsdatensatz, was zu besseren Resultaten führt. Trotzdem haben spezialisierte State-of-the-Art-Systeme einen substantiellen Vorteil über die PaLM Übersetzungen. Aber PaLM kommt relativ nah an einem kommerziellen System heran. In unserem Fall haben wir Google Translate verwendet. Die Erkenntnisse, die wir aus der Evaluierung gewonnen haben, die wir mit dem IMT-Framework durchgegangen sind, bestehen darin, dass die Fluideität von PaLM vergleichbar ist mit State-of-the-Art-Systemen, aber der Hauptunterschied kommt von der Genauigkeit. Im Detail betrachtet, die häufigsten Fehlertypen sind Omission-Fehler. Es scheint, dass PaLM Entscheidungen trifft, um ein besseres klingendes Übersetzung zu produzieren, indem es Teile des Quellsatzes weist, die in der Übersetzung irrelevant sind. Allerdings ist die Stilqualität für PaLM kleiner als für die State-of-the-Art-Systeme, was ein weiterer Hinweis darauf ist, dass PaLM einen fluotten Output liefert, aber immer noch mit ein paar Problemen der Genauigkeit. Und das ist alles für diese kurze Überblick.Für weitere Details bitte mich zu der vollständigen Präsentation des Papiers kontaktieren. Vielen Dank.</sample>
    <sample id="240">Hallo, ich bin Dawei, ein PhD-Student an der Saarland University in Deutschland. In diesem Video möchte ich gerne unsere jüngste Arbeit präsentieren: "Weaker Than You Think" – eine kritische Betrachtung vonWeakly Supervised Learning (WSL). Das ist einJoint Work mit Xiaoyu Shen, Marius Mosbach und Andreas Stephan, und Dietrich Klakow. Ich möchte beginnen mit einer kurzen Einführung in dieWeak Supervision undWeakly Supervised Learning. InWeak Supervision werden die Daten nicht manuell labeliert, sondern durchWeak Labeling Sources wie einfachen heuristischen Regeln, Knowledgespaces oder Low-Quality Crowdsourcing labeliert, wie Sie im rechten Bild dargestellt sehen können. Im Vergleich zu menschlichen Annotatoren sindWeak Annotatoren viel billiger, aber sie sind auch lauter, was bedeutet, dass ein bestimmtes Maß an fehlerhaften Annotatoren existiert. Wenn wir Direkt neuronalen Netze aufWeakly labeliertes Data trainieren, tendieren die neuronalen Netze, das Labelnoise zu memorieren und nicht zu generieren. InWeakly Supervised Learning werden Trainingsalgorithmen vorgeschlagen, um robuste neuronalen Netze unter solcher Labelnoise zu trainieren, damit die trainierten Modelle immer noch gut generalisieren können. In recent works in WSL, also WSL steht fürWeakly Supervised Learning, wird oft behauptet, dass die only train models on the weakly labeled data and achieve high performance on clean test sets. Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken, der ist, dass Menschen davon ausgehen, dass es einen zusätzlichenClean validation setavailable for model selection gibt. Wir haben uns auf diese Problemstellung konzentriert, da dies impliziert, dass zusätzliche manuelle Annotierungen inWeakly Supervised Learning erforderlich sind, aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen. Die offizielle Abkehrung lautet: Um zu fragen: IstClean validation data notwendig für WSL? Oder können wir eventuell einen lauten Validationsset verwenden? Zweitens, wennClean Data erforderlich ist, oder wennClean Data für WSL notwendig ist, dann wie vieleClean Samples benötigen wir? Endlich, sollten wirClean Samples nur verwenden, um zu validieren, oder gibt es bessere Wege, sie zu nutzen? Wir haben diese Forschungsfragen in unserem Werk adressiert und unsere Findungen lauten wie folgt: Erstens finden wir, dass interessanterweise, recent WSL-Methoden tatsächlichClean validation samples benötigen, um zu arbeiten, ansonsten gibt es einen großen Performance-Schwankung, wie Sie im Bild sehen können. Wenn es keineClean validation samples gibt, dann können die trainierten Modelle nicht über die ursprünglichenWeak labels hinaus generalisieren, was bedeutet, dass das Training sinnlos ist. Dies zeigt, dass WSL-Methoden in WirklichkeitClean labeled Data benötigen, um zu arbeiten, und die Annotationskosten für die ObtentionClean validation samples sollten nicht übersehen werden. Unsere zweite Erfindung lautet, dass die Erhöhung der Anzahl derClean validation samples helfen wird, WSL-Methoden zu erreichenBetter Performance, wie Sie im linken Bild sehen können. Typischerweise benötigen wir nur 20 Samples pro Klasse, umHigh Performance zu erreichen. Aber das ist nicht das Ende der Geschichte, denn wenn wir entwederClean Samples entscheiden, dann das Training auf ihnen direkt führt zuEvenBetter Performance. Das rechtsfigur zeigt die Performance-Differenz zwischenFine-tuning-Methoden, die direkter aufClean Data angewendet werden, und WSL-Methoden, dieClean Data nur für Validierung verwenden. Wie Sie sehen können, wenn wir 10 Samples pro Klasse haben, beginntFine-tuning, um WSL-Methoden zu übertrumpfen. Schließlich können die Performance-Besserungen, die in früheren WSL-Methoden geltend sind, leicht erreicht werden, indem es erlaubt wird, weiterFine-tuning aufClean validation samples fortzusetzen. Wie Sie aus dem Bild sehen können, der VELA-Model termedFTW ursprünglich unterperformiert gegenüber komplexeren WSL-Methoden wie cosine. Allerdings, wenn es erlaubt ist, weiterFine-tuning aufClean Samples fortzusetzen, dannPerform equally well als andere Methoden. Also in der Praxis gibt es keinen Grund, komplexere WSL-Methoden zu verwenden, die mehr Rechenzeit und Speicherräumungen erfordern. Um zu summieren, wir haben gezeigt, dass recent WSL-MethodenClean manually annotated Samples benötigen, um zu arbeiten, und ihre Performance-gewinn und Praktizität werden stark überbewertet. Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt: Erstens berichten Sie die ModellSelektionskriterien, z.B. ob die ModellSelektionClean validation samples verwendet. Zweitens, WSL-Methoden sollten mitFew-Shot Learning Baselines verglichen werden, dieClean Samples verwenden. Drittens, continuierliches Fine-tuning ist ein simpeler und starke Baseline, der in zukünftigen Arbeiten in WSL berücksichtigt werden sollte. Endlich haben wirOpen Source our code. Sie können es unter der QR-Code auf dieser Folie finden. Bitte fühlen Sie sich frei, es zu überprüfen. Danke, und genießen Sie die Konferenz.</sample>
    <sample id="241">This paper presents a human-in-the-loop evaluation framework for early detection of misinformation on social media platforms, specifically focusing on COVID-19 treatment claims. The framework involves two main components: claim detection and policy violation verification. The claim detection component uses keyword filtering, a trained T5 model for question answering, and ranking by trendiness to identify and rank potential misinformation. The policy violation verification component uses a stance classification model to flag tweets that violate platform policies. The framework is evaluated based on early detection (before the first appearance in news articles) and policy violation detection. Results show a high decision rate for policy violations and a significant number of detections per human hour, highlighting the framework's ability to capture the complex interplay between systems and human content moderators in a realistic end-to-end setting.</sample>
    <sample id="242">Gängige Bewertungsmethoden für Dialogsysteme sind die Anwendung von Human-Jugendurte und Likert-Ratings auf der Turnebene, auf der Dialogebene und die Dialogebene, parewise Comparisons.</sample>
    <sample id="243">Die Arbeit beteiligen sechs Autoren.</sample>
    <sample id="244">Im Beispiel mit Servin und Kea wird benötigt, dass Servin ein Richter ist und dass Richter in Gerichtsgebäuden Fälle entscheiden.</sample>
    <sample id="245">This paper presents a two-step pipeline for identifying high-agreement workers on Amazon Mechanical Turk (MTurk) for summarization tasks. The pipeline includes a pre-task qualification setting and an endurance task to assess workers' ability to handle heavy workloads. The results show that 26 MTurk workers passed the first stage, with 8 gold and 18 silver workers, while 12 workers passed the second stage, with 4 gold and 8 silver workers. The figure on the right shows the Krippendorff Alpha coefficient between different workers, indicating high agreement in terms of inter-annotator agreement. The analysis also reveals a significant Spearman's correlation between the pipeline and the Cloud Research worker, suggesting similar quality to cloud research workers at a lower cost.</sample>
    <sample id="246">Ja, der Code ist verfügbar und kann auf GitHub abgerufen werden.</sample>
    <sample id="247">This paper introduces a new dataset, FactKG, for knowledge graph-based fact verification. It utilizes DBpedia as the knowledge graph and includes claims in both written and colloquial styles. The dataset supports five types of reasoning: one-hop, conjunction, existence, multi-hop, and negation. A method involving a collocational style transfer model and presupposition templates is proposed for claim verification. Experimental results show that the gear model, which uses graph evidence, outperforms all other baselines, including claim-only baselines that do not utilize graph evidence. This demonstrates the effectiveness of integrating knowledge graphs for reliable fact verification in natural language claims.</sample>
    <sample id="248">Ja, die Annotatoren für NLPositionality sind in Bezug auf jede demographische Gruppe, d. h. Land, Geschlecht usw., ausgewogen.</sample>
    <sample id="249">Sie wurden durch die Einfügung von akzeptablen oder unakzeptablen Präfixen, die aus dem gleichen Datensatz stammten, durcheinander gebracht.</sample>
    <sample id="250">Eine dimensionale Bewertung ist eine Methode, um die Qualität von Dialogen auf einer Finer-Grained-Ebene zu bewerten.</sample>
    <sample id="251">Die Autoren sind an der University of Science and Technology of China.</sample>
    <sample id="252">This presentation introduces U-Creat, an unsupervised case retrieval system using event extraction. Developed by Sai Kiran Tanikella and colleagues at IIT Kanpur, U-Creat addresses the challenge of retrieving relevant legal documents from a vast pool of cases. The system leverages unsupervised learning techniques and an event-based approach to achieve high retrieval efficiency and low inference time across Indian and Canadian legal systems. Key contributions include the ILPC dataset, a comprehensive benchmark for prior case retrieval tasks, and the U-Creat pipeline, which utilizes dependency parsing and event extraction to match query and candidate documents. Experiments with various models demonstrate that event-based models significantly outperform baseline methods, offering a promising avenue for further development in legal information retrieval.</sample>
    <sample id="253">Abstract: This work presents a double-domain adaptation model, named DisorBERT, for detecting signs of mental disorders in social media. Developed by researchers from Mexico and Spain, DisorBERT aims to improve the detection of mental health issues by analyzing social media posts. The model uses domain adaptation techniques to adjust its vocabulary and understanding based on specific mental health data, enhancing its ability to detect mental disorders. Experimental results using the BERT dataset show that DisorBERT achieves a good balance between precision and recall, outperforming other models. Future work plans to explore the application of different lexical resources and clinical data to further enhance the model's effectiveness.</sample>
    <sample id="254">This research paper presents a document-level distant relation extraction framework with uncertainty-guided label denoising. The proposed method leverages distant unlabeled data to generate pseudo labels, which are then refined using instance-level uncertainty estimation and dynamic class uncertainty thresholds. The multi-phase training strategy is designed to iteratively re-label the DSE data, improving the performance of the document model. The results show that the proposed framework outperforms several state-of-the-art baselines on two public datasets.</sample>
    <sample id="255">Die Form des Prompts ist in den Fällen von Null- und Ein-Shot-Prompting wichtig.</sample>
    <sample id="257">Die Autoren haben Bots evaluiert, die in einem Test auf kognitiven Diskonsens und Irritationen im Dialog abhängig sind.</sample>
    <sample id="258">This paper proposes using large language models (LLMs) as an alternative to human evaluations for assessing the quality of texts in natural language processing. The authors explore the idea of instructing LLMs with specific instructions to evaluate text samples, aiming to achieve similar results to human evaluations but with greater stability and reproducibility. They conduct experiments using GPT-2 and ChatGPT, comparing their outputs with human evaluations by English teachers. The results show that while some smaller LLMs do not significantly outperform human-written texts, larger models like DaVinci and ChatGPT demonstrate a clear preference for human-written texts, suggesting they can serve as viable alternatives in certain tasks.</sample>
    <sample id="259">This paper presents Exemplar, a unified benchmark for cross-lingual semantic parsing in multiple natural languages and many representations. It introduces a dataset containing 90 datasets from various domains, 5 semantic parsing tasks, 80 mini-representations, and 22 natural languages across 15 language families. The paper evaluates the performance of different models, including encoder-decoder and encoder-only models, on six settings: translate test, monolingual model, monolingual fine-tune, multilingual model, zero-shot transfer, and few-shot transfer. The results show that encoder-decoder models outperform previous work, especially when trained on a mixture of languages. The paper also highlights the limitations of multilingual language models such as Code and Blue for cross-lingual semantic parsing tasks.</sample>
    <sample id="260">Die Arbeit beteiligen sechs Autoren.</sample>
    <sample id="261">Ein guter Planer sollte Skripts schaffen, die realistisch und zu den Bedingungen passen.</sample>
    <sample id="262">Die Arbeit beteiligen sechs Autoren.</sample>
    <sample id="263">This paper presents a systematic investigation of label bias problems in in-context learning (ICL) for text classification tasks. It introduces a new type of bias called domain label bias, which captures the effect of task corpus on model predictions. The authors propose a calibration method called domain context calibration to mitigate all types of biases. This method uses random in-domain words sampled from the task corpus as content-free text to estimate and correct label biases. Experiments show that domain context calibration significantly improves ICL performance, especially on tasks with large domain label bias. The method is robust across different models and datasets, demonstrating its effectiveness in handling diverse bias scenarios.</sample>
    <sample id="264">This paper introduces a novel task called Transferable Audio-Visual Text Generation (TAVT) to address the challenge of multi-modal domain shift in audio-visual text generation. The main contribution is a framework that includes an Audio-Visual Map Network, an Audio-Visual Encoder, and a Language Model Generator. The Audio-Visual Map Network maps different visual concepts across domains into a unified audio-visual semantic space, while the Audio-Visual Encoder and Language Model Generator generate text based on this unified space. The framework also incorporates a contrastive learning component to fine-tune the model for new multi-modal domains with limited labeled data. Experimental results show that TAVT outperforms state-of-the-art approaches on both cross-domain and cross-dataset settings, demonstrating its effectiveness in handling low-resource domains and improving performance.</sample>
    <sample id="265">James Finch</sample>
    <sample id="266">Die Autoren gehören an der Université de Paderborn.</sample>
    <sample id="268">Die häufigsten Fehler von PaLM sind Omissionen, bei denen PaLM Teile des Quelltextes weist, die in der Übersetzung nicht verwendet werden.</sample>
    <sample id="269">Hallo, ich bin James Finch und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABC-Eval erzählen, eine neue dimensional-basierte Methode zur Beurteilung von conversationaler KI. Dieses Werk wurde vom Emory NLP Lab, geleitet von Professor Jinho Choi an Emory University, in Zusammenarbeit mit Amazon Alexa AI erstellt. Lassen Sie uns angenommen, dass Sie einen Dialogmodell entwickelt haben und es auswerten möchten, wie gut es sich gegenüber dem aktuellen Stand der Kunst vergleicht. Die gemeinsame Praxis besteht darin, menschliche Beurteilungen zu verwenden, indem man menschlichen Richtern fragt, welche der zwei Konversationen besser ist, oder die Konversationen auf einer Likert-Skala bewertet.</sample>
    <sample id="270">Die Autoren gehören an der Emory University.</sample>
    <sample id="271">CFT steht für "Continuos Fine-Tuning".</sample>
    <sample id="272">Sechs Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="273">Kato Yin: Hallo, mein Name ist Kato Yin und ich werde heute über unser Werk "Wann benötigt Übersetzung Kontext?" präsentieren. Dieses Werk wurde in Zusammenarbeit mit Patrick Fernandez, Emmy Liu, Andre F.T. Martins und Graham Neubig erstellt. Viele Übersetzungen hängen von Kontext ab. Zum Beispiel, wie würde man "Mole" in diesem Satz übersetzen? Wenn das vorherige Wort "Dinge könnten gefährlich werden, wenn die Minister davon erfahren" war, dann bezieht sich "Mole" auf einen Spion. Aber wenn das vorherige Wort "Könnte es etwas Ernstes sein, Arzt?" war, dann bezieht sich "Mole" auf eine Geburtsmarke. Abhängig vom Kontext ändert sich also die Bedeutung des Wortes und somit auch die Übersetzung. Allerdings ist es schwierig zu beurteilen, wie gut Modelle solche Fälle handhaben können. Zunächst einmal because nur ein kleiner Teil von Übersetzungen hängt von Kontext ab, was bedeutet, dass Metrisken auf Niveau der Korpus (wie BLEU) diese Übersetzungen nicht abschätzen können. Ein paar Leute haben vorgeschlagen, eine spezielle Beurteilung auf Kontext abhängige Übersetzungen durchzuführen, aber diese Ressourcen unterstützen nur limitierte Typen von Kontext abhängigen Übersetzungen und limitete Sprachen, da sie normalerweise auf Domänenknowledge und menschliche Erstellung berufen. In unserem Werk versuchen wir, zwei Fragen zu beantworten: Erstens, wann benötigt Übersetzung Kontext? Und zweitens, wie gut können Modelle solche Fälle handhaben? Um die erste Frage zu beantworten, haben wir zuerst gemessen, wie viel ein Wort von Kontext abhängt. In unserem vorherigen Werk haben wir CXMI (Contextualized Crosslingual Machine Translation Index) als Maß für Kontextnutzung von Maschinell übersetzten Modellen eingeführt. Das wird durch Messung des Informationsgewinns durch Kontext für die Zielübersetzung gegeben, gegebene Quelle. Man kann CXMI den Informationsgewinn von geben Kontext für das Modell denken. In unserem Werk haben wir CXMI auf P-W-CXMI erweitert, um Kontextnutzung an der Satellevel oder an der Wortlevel messen zu können. Wir können Wörter mit hohen P-CXMI als solche, die Kontext benötigen, um übersetzt zu werden, denken. Jetzt analysieren wir Wörter mit hohen P-CXMI, um Muster zwischen diesen Wörtern zu finden. Wir führen unsere Analyse auf Transkripten von TED Talks durch, die von Englisch ins 14 verschiedenen Sprachen übersetzt wurden. Wir führen unsere Analyse an drei verschiedenen Niveaus durch: zuerst schauen wir an Sprochensegmente mit hohen P-CXMI an, was uns dabei erlaubt, beispielsweise dual pronouns in Arabisch mit hohen P-CXMI zu finden und das zu erklären, weil Englisch keine dual pronouns hat, also Kontext benötigt, um zu bestimmen, ob ein Pronomen dual ist, wenn es ins Arabische übersetzt wird. Auf ähnliche Weise finden wir, dass bestimmte Sprachen beim Entscheiden über die richtige Verbform Kontext benötigen. Wir schauen dann an Vokabeln mit hohen P-CXMI über alle ihre verschiedenen Auftretensweisen an, was uns dabei half, Muster zu identifizieren, bei denen in Chinesisch Kontext benötigt ist, um die richtige Übersetzung von Nomen zu finden, um sicherzugehen, dass dieselbe Übersetzung im Dokument verwendet wird. Auf ähnliche Weise finden wir, dass Kontext unterstützt die Übersetzung in der richtigen Formalität. Und schließlich schauen wir an einzelne Token mit hohen P-CXMI an, was uns dabei erlaubt, Phänomene zu identifizieren, die nicht von dem Wort selbst, sondern von der Satzstruktur ausgedrückt werden, zum Beispiel Ellipsesresolution. Also verwenden wir unsere Auswertungsergebnisse aus der Analyse, um einen Benchmark für Dokumentebasierter Übersetzung zu entwerfen.Für jede der 5 diskursbedingten Phänomene, die wir identifiziert haben, erstellen wir Tagger, um Wörter zu automatisch identifizieren, die zu diesem Phänomen gehören, und nennen unser Tagger Multilingual Diskursaware (MDA) Tagger. Wir können dann auch beachten, dass verschiedene Sprachen unterschiedliche Proportionen dieser diskursbedingten Phänomene haben. Wir verwenden den MDA Tagger, indem wir ihn auf ein parallel korpus anwenden, den wir verwenden möchten, um eine Evaluierung zu durchführen, und wir überwachen unsere Übersetzungsmethoden von Wahl auf die Kontextabhängigen Beispiele, die der MDA Tagger identifiziert hat. Und schließlich verwenden wir unser Benchmark, zusammen mit anderen Metrisken, um verschiedene Modelle auf Dokumentebasierter Übersetzung zu bewerten. Zunächst einmal, wenn wir Korpusbasierte Metrisken verwenden, also z.B. BLEU, finden wir, dass Kontextagnoskop Modelle die beste Performance haben. Aber wenn wir BLEU verwenden, finden wir, dass Kontext-aware Modelle die beste Performance haben. Und wenn wir Word F-Measure verwenden, finden wir, dass Modelle mit und ohne Kontext vergleichbare Performance haben. Dies zeigt, dass es schwierig ist zu bestimmen, welche Dokumentebasierter Übersetzungssysteme am besten performieren, wenn wir nur Korpusbasierte Metrisken verwenden. Nun verwenden wir den MDA Benchmark, um Modelle zu bewerten, und finden, dass Kontext-aware Modelle signifikant besser als Modelle, die Kontext für bestimmte diskursbedingte Phänomene wie Formalität und lexikalische Kohärenz verwenden, sind. Aber diese Modelle sind nicht so gut wie Modelle, die Kontext für andere Phänomene wie Ellipsespronomen und Verbformen verwenden. Dies zeigt, dass wir bei Dokumentebasierter Übersetzung noch Fortschritte machen müssen. Wir vergleichen auch verschiedene kommerzielle Systeme und unser Benchmark zeigt, dass DeepL normalerweise besser als Google Translate auf Dokumentebasierter Übersetzung performiert. Insgesamt haben wir einen datengetriebenen Analyseansatz über 14 Sprachpaare durchzuführen, um zu bestimmen, wann Übersetzungen Kontext benötigen, und dann verwenden wir unsere Auswertungsergebnisse, um einen Benchmark für Dokumentebasierter Übersetzung zu entwerfen, der uns dabei helfen kann, zu identifizieren, welche diskursbedingten Phänomene Modelle gut oder nicht gut handhaben und welche Übersetzungssysteme gut auf Dokumentebasierter Übersetzung performieren. Vielen Dank für Ihre Aufmerksamkeit. Ich sehe Sie in Torododo.</sample>
    <sample id="274">Usen Zhang</sample>
    <sample id="276">This paper presents a dataset, IndicMT Eval, designed to evaluate machine translation metrics for Indian languages. The study focuses on five languages from two language families: Dravidian (Tamil and Malayalam) and Indo-Aryan (Hindi, Marathi, and Gujarati). The dataset consists of 7,000 samples, each with multiple candidate translations generated by seven different translation models. Human annotators evaluated these translations, marking errors, their severity, and providing overall scores. The paper compares various evaluation metrics, including overlap-based, embedding-based, and Comet variants, analyzing their correlation with human scores and performance across different error types. The results show that Comet variants, particularly Comet-MQM, outperform baseline metrics in terms of correlation and robustness.</sample>
    <sample id="277">Sie hat keinen Namen.</sample>
    <sample id="278">Die Autoren beschreiben die Methode der „markierten Wörter“ als eine Art von Analyse, bei der sie Suchbegriffe in Texten verwenden, um zu bestimmen, ob bestimmte Stereotypien und essentialisierende Narrativen in den Texten vorkommen. Sie verwenden diese Methode, um zu identifizieren, wie Stereotypien und essentialisierende Narrativen in den Texten vorkommen und wie sie die Gesellschaft beeinflussen können.</sample>
    <sample id="279">Die Autoren gehören an der University of Washington.</sample>
    <sample id="280">This paper presents a novel attention-based correlation-aware multimodal fusion framework for emotion recognition in conversations, called MultiEmo. It addresses the challenges of existing methods by proposing a multi-modal feature extractor named VisiNet, which captures visual cues without encoding redundant scene-related information. The framework also introduces a multi-modal fusion model called MultiAtt, which integrates textual, audio, and visual modalities through stacked bidirectional multi-head cross-attention layers. Additionally, it employs a sample-weighted focal contrastive loss to focus on minority classes and improve inter-class distances. Experimental results demonstrate that MultiEmo achieves state-of-the-art performances on two ERRC benchmark datasets, MELD and iEMOval, with significant improvements in minority and semantically similar emotions.</sample>
    <sample id="281">This paper presents a data-driven exploration of when translation requires context, focusing on multilingual discourse phenomena. It introduces CXMI, a measure for context usage by machine translation models, and extends it to sentence and word levels. The analysis is conducted on TED Talks translated into 14 languages, identifying patterns in context-dependent translations. A benchmark is created using the MuDA tagger, which identifies words related to specific discourse phenomena. The results show that context-aware models perform better for certain phenomena like formality and lexical cohesion, while models without context are more accurate for others like ellipsis resolution. The benchmark helps evaluate document-level translation systems and identify areas for improvement.</sample>
    <sample id="282">This paper presents a new method for non-parallel story author-style transfer with discourse representation and content enhancing. The proposed model, named StyleTrans, generates the target style text by transferring the source text with style-specific content keywords masked and then generating the whole text by incorporating these keywords explicitly. The training framework consists of two stages: the first stage uses an adversarial training framework to recover the input, disentangle sentence embeddings, capture sentence-level dependency, and produce style signals; the second stage is unrelated to style transfer and aims to fill in the correct style-specific content and remove the mask tokens. The results show that StyleTrans outperforms strong baselines in terms of style control and content preservation.</sample>
    <sample id="283">Prague</sample>
    <sample id="284">The paper presents a novel fuzzy span mechanism for enhancing universal information extraction (UIE). It addresses the ambiguity in labeling spam boundaries and the mismatch between Transformer feature extraction and UIE. The proposed method uses a continuous distribution of correct probabilities to model the fuzzy spam boundary, which is converted into discrete values for calculation. The model incorporates BCE loss and KL divergence to optimize attention distribution, achieving significant performance improvements in named entity recognition, relationship extraction, and aspect sentiment triple extraction tasks.</sample>
    <sample id="285">This paper presents a new evaluation framework for fact error correction in dialogue summarization. The authors argue that current evaluation methods are flawed and propose a taxonomy of fact errors based on content and form. They also introduce a three-step evaluation framework consisting of alignment, classification, and comparison. The results show that training models with human-annotated reference summaries can improve performance, and combining human-annotated data with synthetic data is a promising direction. However, current models struggle to correct fact errors by addition and cannot address attribute errors, modality errors, and link errors.</sample>
    <sample id="286">Sarah Finch</sample>
    <sample id="287">Vier Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="288">Die Blimp und Syntax Gym Datensätze können zum Testen syntaktischer Phänomene verwendet werden.</sample>
    <sample id="290">WSSL, FTW, COSINE, FINE-TUNING, CONTINUOUS-FINE-TUNING</sample>
    <sample id="291">Das Modell wird anhand von Aufgaben wie Namensentwicklung, Klassifizierung, Part-of-Speech-Segmung und Fragebehandlung evaluiert.</sample>
    <sample id="294">CamemBERT wurde ursprünglich auf NACHOS trainiert.</sample>
    <sample id="295">Der Referent*in heißt Adam Siprowski.</sample>
    <sample id="296">This video presents a collaborative work between the University of Turin and Amazon Alexa, focusing on irony detection in natural language processing. The researchers developed a corpus called EPIC (English Prospective Irony Corpus), collecting data from social media platforms like Reddit and Twitter over a one and a half year period. They gathered about 300 short conversations for five varieties of English, annotated by 74 annotators using a crowdsourcing platform. The results showed significant differences in inter-annotator agreement based on various dimensions such as gender, age group, and nationality. The researchers also developed perspective-aware models to model these differences, which showed higher confidence in their predictions compared to gold-standard aggregated models.</sample>
    <sample id="297">This project develops a typology and glossary of dog whistles, performs a case study on historical U.S. political speeches, evaluates dog whistle recognition in language models like GPT-3, and conducts a case study on toxicity detection to show how dog whistles can evade content moderation online. The research highlights the context-dependent nature of dog whistles and their role in political influence and hate speech.</sample>
    <sample id="298">Die Versuche, die Modelle mit jüngster Daten zu erneut trainieren, haben gezeigt, dass die Leistung mit einer größeren zeitlichen Verzögerung abnimmt.</sample>
    <sample id="299">This paper proposes a training method to reduce the reliance of NLI models on shortcuts and improve their out-of-distribution performance. The key insight is that NLI models suffer from poor performance on underrepresented hard training instances with patterns that could indicate the shortcuts in the dominant easy examples. These hard examples are pivotal for ensuring good generalization performance on out-of-distribution samples. The proposed method uses a minimax training objective between a learner and auxiliary model to generate example weights that encourage the learner to focus on regions of the input space where it incurs high losses, thus prioritizing learning from underrepresented hard examples. The method does not make assumptions about the type of shortcuts contained in the dataset and relies on the learner's own training dynamics to generate example weights. The auxiliary model is modeled using a feedforward network. The method is evaluated on three commonly used NLI datasets and their corresponding out-of-distribution test sets, showing consistent improvement in out-of-distribution performance while maintaining high in-distribution accuracy.</sample>
    <sample id="300">This paper introduces the task of interactive dictation, which enables users to dictate and edit documents using their voice in a natural and intuitive manner. The authors propose a new task that combines flexible interleaving of dictation and editing, using intuitive and open-ended natural language utterances to specify edits. They design a data collection interface and build a dataset for this task, and create a baseline system that performs each of the four steps involved: ASR recognition, segmentation, command extraction and normalization, and document state execution. The authors evaluate different architectures and output types for the interpretation model, finding that GPT-3 models are more accurate but slower, while predicting intermediate programs allows for improved efficiency with minimal impact on accuracy.</sample>
    <sample id="302">Die Token für die Ausgabesequenz müssen permutiert werden, um die richtige Reihenfolge der Ausgabesequenz zu bestimmen.</sample>
    <sample id="303">Die Autoren empfehlen, dass Modellentwickler*innen ihre Methoden zum Abbau von Vorurteilen transparenter machen sollten, um zu verstehen, ob positive Stereotypien und essentialisierende Narrativen durch übertriebene Wertealignment- oder anti-Stereotypie-Methoden entstehen.</sample>
    <sample id="304">Inakzeptable Minimalpaareingaben sind diejenigen, die eine grammatische oder stilistische Anomalie enthalten.</sample>
    <sample id="305">This paper presents a critical analysis of weakly supervised learning (WSL), focusing on the necessity of clean validation data for effective model training. It addresses three main research questions: whether clean validation data is required, how many samples are needed, and if clean samples should be used solely for validation. The study finds that recent WSL methods require clean validation samples to perform well, with a significant performance drop without them. Additionally, increasing the number of clean validation samples improves WSL performance, but fine-tuning directly on clean data often yields better results. The paper concludes that the performance gains and practicality of WSL are overestimated and recommends reporting model selection criteria, comparing WSL with fine-tuning baselines, and considering continuous fine-tuning as a simple yet powerful approach.</sample>
    <sample id="306">This paper presents a study on the ability of large language models to track entities in language models. The research question is to what extent can large language models track entities? The authors designed an evaluation task involving boxes and objects, where the input consists of a description of the initial contents of each box, and the task is to complete the input by predicting the contents of each box after multiple state-changing operations. The results show that most models simply repeat the initial state, while only GPT-3.5 exhibits non-trivial tracking behavior. The authors found that pre-training on code is responsible for this capacity surface in pre-trained language models, and that smaller models like T5 base can learn to perform entity tracking if directly fine-tuned. However, it remains unclear whether the state-tracking abilities observed generalize beyond the setup.</sample>
    <sample id="307">Die Autoren haben die Performance der Modelle anhand von Public und Private Datasets bewertet, indem sie die Aufgaben wie Namensentwicklung, Klassifizierung, Part-of-Speech tagging und Question Answering mit sechs Baseline Modellen verglichenen.</sample>
    <sample id="308">This presentation by Jenny T. Liang explores the concept of "NL Positionality," which refers to the design biases in natural language processing (NLP) datasets and models that arise from the perspectives of their creators. The speaker explains how these biases can lead to systematic performance differences in technology across different populations, using examples like the detection of toxic content in comments. The presentation introduces a framework called NL Positionality, which involves re-annotating datasets with diverse annotators and comparing their annotations to existing datasets and models. This framework helps identify the alignment of NLP systems with specific demographics and educational levels, highlighting issues such as cultural gaps and the lack of representation for non-binary individuals. Recommendations include keeping records of design choices, conducting research with a perspective on positivism, and building specialized datasets and models for specific communities.</sample>
    <sample id="309">Inner-annotator agreement</sample>
    <sample id="310">Wikipedia</sample>
    <sample id="311">Die Autoren gehören an der Technischen Hochschule Darmstadt.</sample>
    <sample id="312">MultiInstruct ist der erste MultiModell-Instruction-Tuning-Benchmarke, die 62 diverse MultiModell Aufgaben umfasst, die in 10 Hauptkategorien unterteilt sind.</sample>
    <sample id="313">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="314">Die binäre Koordination ist eine Asymmetrische Struktur.</sample>
    <sample id="315">Die in dieser Studie verwendeten Prompts lagen im Durchschnitt bei 13 Wörtern.</sample>
    <sample id="316">Die Auswirkungen auf das kleinere T5-Modell sind, dass es die besten Skripts generieren kann, die die höchste Similaritätsscore zu den Zielkonstanten haben.</sample>
    <sample id="317">This paper presents a new approach for few-shot information extraction using large code generation models. The traditional method of training language models like GPT-3 in a task-to-task manner during pre-training leads to mismatched outputs during inference, requiring extensive structured training data and decoding strategies. Our proposed method, CodeIE, transforms the input test into a structured format using code generation tasks, ensuring aligned structures in both input and output stages. We evaluate our method on named entity recognition and relation extraction datasets, demonstrating superior performance over traditional baseline models.</sample>
    <sample id="318">Hallo, ich bin Yanis Labrak und ich werde Ihnen heute über unsere Arbeiten zu Dr. BERT, einem robusten vortrainierten Modell in Französisch für biomedizinische und klinische Domänen, vorstellen. In dieser Präsentation werden wir zuerst über Sprachmodellierung im Gesundheitswesen sprechen. Danach präsentieren wir die Hauptbeiträge unseres Artikels. Wir Introduzieren das erstmalige biomedizinische Modell in Französisch namens Dr. BERT, das auf Roberta basiert und trainiert wurde auf NACHOS, einer Datensammlung von medizinischen Crowd-Daten aus der Web. Wir Introduzieren auch einen Vergleich von Modellen mit mehreren vortrainierten Einstellungen und Datensätzen. Dann präsentieren wir unsere Resultate auf 11 biomedizinischen und klinischen downstream Aufgaben in Französisch. Schließlich diskutieren wir über die Experimente und geben Ihnen weitere Details, wie Sie Zugang zu den Modellen erhalten können. Seither es im Jahr 2018 freigegeben wurde, ist BERT zu einem der effektivsten Ansatzpunkte zur Bewältigung von Natural Language Processing-Aufgaben geworden und bietet einen großen Leistungsverlust im Vergleich zu historischen statischen und konsolidierten Methoden wie Word2Vec, FastText oder Elmo. Seither hat sich das Modell an viele andere Sprachen angepasst, wie zum Beispiel in Französisch mit Camembert und in anderen Domänen wie biomedizin mit PUMA BERT und BioBERT und in klinisch mit Kliniker BERT, aber hauptsächlich in Englisch. Spezialisierte Modelle für andere Sprachen sind seltener und oft aufgrund des Mangels an in-domänischem Datensatz auf kontinuierliche vortraining basierend. Allerdings gab es in Französisch noch keinen offenen Quellens Modell für biomedizin und klinische Aufgaben. Also fragten wir uns, was die geeignetste Datensammlung für eine Vielzahl von Anwendungsfällen ist und diese Crowdsourcing-Daten als E subsitution für klinische Daten verwenden. Um diese Frage zu beantworten, verglichen wir Dr. BERT mit unserem Shubert Modell, das auf anonymisierten Datensätzen basiert, die vom Non-Universität Hospital der University of Texas abgekauft wurden. Danach fragten wir uns, wie viel Datensatz wir benötigen, um ein spezialisiertes Modell auf Französisch zu trainieren. Ist es 4 GB, 8 GB oder mehr? Um diese Frage zu beantworten, haben wir zuerst einen von Null auf null trainierten Modell, eine erste Version von Dr. BERT mit 7 GB von NACHOS, eine zweite Version von 4 GB subset von NACHOS, eine erste Version von Shubert, die ein klinisches Modell ist, mit 4 GB von Sätzen, die aus klinischen Knoten stammen, und eine finale Version von Shubert mit einem Mix von 4 GB subset von NACHOS und 4 GB von klinischen Knoten. Neben dieser Vergleichsanalyse Introduzieren wir drei Modelle, die auf kontinuierliche vortraining basieren, um die Auswirkungen von vortraining Strategien zu analysieren: eine basierend auf dem Gewicht von Camembert und trainiert auf 4 GB subset von NACHOS, eine andere basierend auf Camembert, aber trainiert auf 4 GB von klinischen Knoten und letztendlich eine basierend auf einem englischen biomedizinischen Modell namens PUMA BERT und trainiert auf 4 GB subset von NACHOS. Insgesamt haben wir sieben Modelle. Um unsere sieben Modelle zu evaluieren, gewussten wir public and private downstream Aufgaben wie Name Entity Recognition, Klassification, Part-of-Speech tagging und Question Answering.Diese Modelle werden mit sechs Baseline-Modellen verglichen, die Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCNet 4 GB, PUMA BERT BioBERT und Kliniker BERT sind. Die Evaluation zeigt, dass die Modelle am besten auf der Aufgabe performen, wenn sie auf Datensätze mit gleicher Natur trainiert wurden, aber wir können auch die Datensätze von heterogenen Quellen beobachtet haben, die besser versiegelten. Wir können auch beobachtet haben, dass mehr Datensatz zu besseren Leistungen führt. Insgesamt scheint die von Null auf Null trainierte Methode zu besseren Leistungen auf meisten Aufgaben zu führen. Allerdings haben unsere Experimente mit kontinuierlicher vortraining, die auf dem Gewicht und Tokenizer von PUMA BERT basieren und auf 4 GB subset von NACHOS trainiert wurden, vergleichbare Resultate zu denjenigen mit Dr. BERT 4 GB von Null auf Null, was nicht der Fall ist, wenn wir ein Modell mit Gewichten und Tokenizer von Camembert verwenden, das unter Stabilitätproblemen leidet. Schliesslich als Schlussfolgerung unserem System bietet ein besseres Leistungsresultat auf 9 der 11 downstream Aufgaben und überwiegt global das Resultat des generischen Modells hier Camembert. Wir können auch beobachtet haben, dass spezialisierte Datensätze besser sind, mehr spezialisierte Datensätze sind besser, aber sie nicht so gut skaliert werden. Das vortrainierte Modell, das von NACHOS stammt, ist frei verfügbar und auf YouTube und all die Trainingsskripte sind auf unserem GitHub Repository. Also danke für die Präsentation und wir freuen uns auf die Diskussion bei der Post-Session in Toronto.</sample>
    <sample id="319">Die Arbeit untersucht die Auswirkungen von verschiedenen Lernstrategien, einschließlich der Kontinuierlichen Pretraining, auf die Leistung von Modellen in der Bio-medizinischen und klinischen Domäne.</sample>
    <sample id="320">Die Überanpassung, die auf die Wiederverwendung von Tests zurückzuführen ist, wurde als nicht beobachtet ermittelt.</sample>
    <sample id="321">Die Qualität der Vereinfachung wurde über die Art und Häufigkeit der Simplifikationstransformationen analysiert, indem man beispielsweise den Typ der Simplifikationen betrachtete.</sample>
    <sample id="322">This paper presents a study on how language models learn about morality in text. The authors apply explainable AI techniques to understand what these models learn and focus on understanding how morality is expressed differently across different domains. They use the Mora Foundation Twitter Corpus, which contains 35,000 tweets collected in seven different domains. The study finds that language models recognize that morality can be expressed differently in different domains, such as ALM and BLM, and that using just one single model for many different domains can lead to misunderstandings of morality in a dangerous way.</sample>
    <sample id="323">This paper presents a joint work with John Gao, Aaron Mueller, Kanishka Mishra, Gaurav Fintels, Roger Levy, and Adina Rado. The paper discusses the limitations of language model acceptability judgments in the context of commonsense question answering. The authors propose a new method that achieves good results when compared to other methods such as RLM and HKG.</sample>
    <sample id="324">Ja, Sprachmodelle können unterschiedliche politische Vorurteile aufweisen.</sample>
    <sample id="325">Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen einen kurzen Einblick in unser Papier über "Kompositionelle allgemeinheit ohne Bäume mit Multiset Tagging und latenten Permutationen" geben. Dies ist ein gemeinsames Projekt mit meinen Betreuern Alexander Koller und Ivan Titov. Kompositionelle allgemeinheit kann als die Fähigkeit eines Lerners verstanden werden, um tieferen Rekursionen und unbekannten Kompositionen von Phrasen zu bewältigen, die während des Trainings individuell gesehen wurden. In Bezug auf syntaktische Analyse kann die Testung der Kompositionelle allgemeinheit wie folgt aussehen: Wie usual haben wir eine Trainingsmenge von Ausdrücken, in diesem Fall "Die Frau schläft" und "Mary weiß, dass die Frau schläft".Diese Ausdrücke werden mit logischen Formen Paarungen, die Hauptaspekte ihres Bedeutungsviels repräsentieren. Im Gegensatz zu Standard-Maschinelern-Evaluation-Methode enthält die Testmenge nicht aus derselben Verteilung stammt, sondern enthält strukturell unbekannte logische Formen. In diesem Beispiel hat das Modell Shallow-Rekursion während des Trainings gesehen und wird an einem Beispiel mit tiefere Rekursion getestet. Naive sequenz-to-sequence-Modelle kämpfen mit diesem Art der Out-of-Distribution-Allgemeinheit und produzieren oft Ausgaben, die dettach'd vom Input sind. In particular, sie often fail to reproduce the systematic correspondences between input and output, such as those that are color-coded in the example. A popular method to address this is to integrate trees into the models. The trees are intended to capture the compositional process that relates utterances with the logical forms. This works well, but trees are usually not given and need to be obtained somehow. This can be complicated and sometimes a computationally expensive process. Typically, this involves considerable formalism-specific pre-processing of the logical forms, for example, to handle variable symbols. Obtaining trees may also involve specialized grammar induction procedures. In this paper, we don't use trees and introduce a neural sequence-to-sequence model that directly models the correspondences between fragments of the input and fragments of the output. For the first time, we show strong generalization to deeper recursion without relying on trees. Our approach predicts the output from the input in two steps. First, we tag each input token with an unordered multiset of tokens that will appear in the output. After the first step, we have all the right tokens but they're not ordered. That's why, in the second step, we use another model to predict a permutation to put them into the right order. We introduce a new method to predict a permutation that does not put any hard constraints on the possible permutations. This makes our approach quite flexible and expressive. Conceptually, our permutation model works roughly like this. We go from left to right over the output and determine which multiset token to put in every position. For the first output position, we simply select one as highlighted in red. Then we jump to the next multiset token to determine the second token in the output. We determine the third token in the output in a similar way by jumping to another multiset token. We continue this process until every token from the first stage has been visited exactly once. To give you a teaser of the experimental results, here we compare our method with other treeless models on the CoNLL benchmark. Our model outperforms the others by a large margin on generalization to deeper recursion. Some other kinds of structural generalization remain very challenging though. In our paper, we solve a couple of interesting technical challenges. First of all, the alignment between input and output is not given in the training data. As a consequence, for a given token, we don't know which multiset it came from, which poses a challenge for training. In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is latent. We address this by inducing the alignment as part of the training. Our permutation method is very flexible, but it brings the challenge that finding the highest scoring permutation is NP-hard. That's because this is related to the traveling salesman problem. We approximate this with a GPU-friendly continuous relaxation that also allows us to backpropagate through the solution and learn the linguistically more plausible permutations. If you want to learn more about our experiments and how we address these challenges, please have a look at our paper or come to our poster.</sample>
    <sample id="326">Kognitive Dissonanz ist die Inconsistenz zwischen zwei Glaubens oder Handeln, die in einem Menschen vorkommt.</sample>
    <sample id="327">This paper presents a new dimensional approach to evaluating conversational AI, called ABC Eval. It aims to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors such as responding with irrelevant information or contradicting itself. The authors developed this method to comprehensively cover chat model behaviors that have been suggested to affect chat quality in recent literature. They evaluated four state-of-the-art chat models on 100 human-bot conversations per model using ABC Eval and compared it with three existing methods: Likert ratings on the turn level, Likert ratings on the dialogue level, and dialogue-level pairwise comparisons. The results show that ABC Eval is capable of measuring the rates at which chat models will commit various thematic errors.</sample>
    <sample id="328">GPT-4</sample>
    <sample id="329">This paper presents a method for generating structured pseudo-labels to improve zero-shot video sentence localization. The proposed method uses pre-trained image caption models to generate more complex free-form pseudo-queries, which are then matched with video frames to generate pseudo events. These pseudo events guarantee high relevance between the video and the queries while maintaining low relevance between the video and other events. The method also reduces the weight of noisy samples and corrects noisy labels to reduce label noise. Experimental results show that the proposed method outperforms existing methods on two datasets.</sample>
    <sample id="330">Ja, kumulatives Training ist besser als iteratives Training für aktives Lernen.</sample>
    <sample id="331">Sara Papi</sample>
    <sample id="332">Die Daten für die MuDa-Benchmark stammen aus Transkripten von TED Talks, die von Englisch ins Deutsche übersetzt wurden.</sample>
    <sample id="333">This paper proposes a novel training framework to enhance the generalization ability of neural machine translation (NMT) models. The proposed framework, called Ink, injects knowledge into NMT by aligning contextualized representations with token embeddings and the same target token. This process refines the representation space, leading to improved translation performance. Experiments on the WMT'19 German-to-English news translation task show that Ink achieves state-of-the-art results with less memory usage and faster inference speed.</sample>
    <sample id="335">Matthias Lindemann</sample>
    <sample id="336">Sprachübergreifender Transfer bezieht sich auf die Training von Modellen an einem Quellsprache und dann die Anwendung auf ein anderes Sprachmodell.</sample>
    <sample id="337">This paper presents a novel approach for out-of-vocabulary (OOV) word embedding learning based on graph-based relation mining. The proposed method leverages the lexical rules of word formation and association to infer the meaning of OOV words, constructing a word relationship graph that represents the lexical rules of word formation and association. By utilizing a graph neural network and applying contrastive learning in the loss function, the model can effectively learn OOV words by word formation and improve the performance of downstream tasks. The results demonstrate the effectiveness of the proposed method on both intrinsic and extrinsic tasks, and its potential for application in other languages with different word segmentation strategies.</sample>
    <sample id="338">This presentation introduces a collaborative research effort focused on evaluating the quality of human-generated explanations for natural language processing tasks. The researchers propose a unified data structure to standardize various tasks and evaluate the utility of explanations using two metrics: the Simulatability Score and a new metric called TrueScore, which assesses both the helpfulness during fine-tuning and inference stages. The study demonstrates that even low-quality human explanations can significantly improve model performance, particularly in tasks like common sense question answering and natural language inference. The findings support the development of high-quality human-annotated datasets and highlight the importance of considering task-specific factors when evaluating explanations.</sample>
    <sample id="339">Die Autoren gehören an der Saarland University, Amazon Alexa und der University of Vienna.</sample>
    <sample id="340">This paper presents ParaAMR, a large-scale syntactically diverse paraphrase dataset constructed by AMR back-translation. We demonstrate that ParaAMR benefits several NLP applications compared to existing paraphrase datasets, including learning sentence embeddings, synthetic control paraphrase generation, and data augmentation for future learning. Our dataset is available at this link.</sample>
    <sample id="341">Die Autoren verwenden die Messungen "Average Latency" und "Computational Latency" als Latenzmessungen.</sample>
    <sample id="342">This paper introduces a dynamic heterogeneous graph-based knowledge retrieval method for answering questions in the Common Sense QA task. The proposed method retrieves relevant knowledge from both language models and knowledge bases by building a subgraph through entity matching and uses GNNs to generate answers. Experiments show that the performance of the proposed method is better than existing methods, especially when the number of demonstrations exceeds eight.</sample>
    <sample id="343">Hallo, alle Leute. Ich bin Makkat und heute präsentiere ich mit Martin ein Werk namens "Kipmuster" an. Das Werk bewertet die Integrität von mehreren Quellen. Dieses Werk ist eine Zusammenarbeit zwischen McGill University, Mira und Microsoft Research. Sprachverstehensmodelle ziehen auf eine Vielzahl von Kenntnisquellen hervor, wie zum Beispiel Kenntnisse in ihren Parametern, normalerweise durch vorheriges Training erworben, und Kenntnisse, die in Eingabezeiten gegeben werden. Jüngere Arbeiten in Aufgaben wie der Antwortfindung zeigen, dass Modelle Kenntnisse aus vorheriger Zeit verwenden können, um die Aufgabe zu lösen. Aber Sprachverstehensprozesse oft erfordern Kenntnisse, die auch in Eingabezeiten geliefert werden. Zum Beispiel in einem Satz: "John sah den neu gewählten Präsidenten auf TV." Voreinzelte Parameter können Informationen über das Amt des Präsidenten und was ein TV ist enthalten, aber sie können nicht zuverlässig wissen, wer der bestimmte Satz spezifische Entity John ist oder wer der neue Präsident ist, da der Präsident seit dem Voreinzelten verändert wurde. Daher benötigen erfolgreiche Modelle für intellektlich intensive NLU-Aufgaben die Fähigkeit, sowohl vorherige als auch Eingabezeit Kenntnisse zu integrieren und zu verwenden. In diesem Werk präsentieren wir einen Diagnostischen Test-Satz für Kenntnisintegration. Wir Introduzieren einen Korreferenz-Resolution-Aufgabentyp, der darauf abzielt, die Fähigkeit zu beweisen, Kenntnisse aus verschiedenen Quellen zu verwenden. Wir evaluieren den Datensatz mit Menschenstudie teilnehmenden und etablieren Korreferenz-Resolution-Modelle. Hier ist ein Beispiel aus unserem Datensatz: "Termin ist ein Richter. Kia ist ein Bäcker. Termin und Kia haben sich in einem Park getroffen. Nach einem langen Tag im Dienst, bei der sie Fälle in einem Gerichtshof entschieden haben, war er glücklich, sich zu entspannen." Das Ziel hier ist, die richtige Entity zu identifizieren, die das Pronomen "he" bezieht, was in diesem Fall Servin ist. Die Auflösung eines bestimmten Pronomens erfordert zwei Arten von Informationen: Erstens Entity-specific-Kenntnisse, wie Servin ein Richter ist, und zweitens Hintergrund-Kenntnisse, wie Richter Fälle in Gerichten entscheiden. Normalerweise werden Hintergrund-Kenntnisse während des Voreinzelns von großen Sprachmodellen gelernt, während Entity-specific-Kenntnisse normalerweise in der Eingabezeit beobachtet werden. Wir variieren die Verfügbarkeit dieser beiden Arten von Informationen so, dass sie entweder in einer Quelle oder in mehreren Quellen enthalten sind. Wir haben definiert, drei Szenarien von Kipmuster: Erstens die "Vorausblick" -Szenario, bei dem Hintergrund-Kenntnisse angenommen werden, dass sie in der Voreinzelzeit verfügbar sind. Zweitens die "Hintergrund-Beide" -Szenario, bei dem Hintergrund-Kenntnisse in der Voreinzelzeit und in der Eingabezeit verfügbar sind. Drittens die "Hintergrund-Eingabe" -Szenario, bei dem beide Kenntnisarten nur in der Eingabezeit verfügbar sind. Das letzte Szenario ist insbesondere interessant, da es die Situation simuliert, bei der das Hintergrund-Kenntnis, das für die Aufgabe erforderlich ist, nicht Teil der Voreinzel-Daten des Modells ist. Zum Beispiel, weil neue Berufe seit dem Voreinzelzeitraum entstanden sind. Hier ist ein Beispiel, wie wir die Verfügbarkeit von Fakten in den Quellen steuern: In der "Vorausblick" -Szenario nehmen wir an, dass das Hintergrund-Kenntnis "Politiker suchen Wahlmandate in der Regierung" in den Voreinzelparameter enthalten ist. In einem Eingabekontext liefern wir die antity-specific-Kenntnis "Chesterfield ist ein Politiker". In der "Hintergrund-Beide" -Szenario liefern wir nicht nur die antity-specific-Kenntnis, sondern auch Hintergrund-Kenntnis über Politiker in einem Eingabekontext. In der "Hintergrund-Eingabe" -Szenario liefern wir die fiktionalen Berufe "Mitarbeiter" anstelle von "Politiker", weil "Mitarbeiter" unwahrscheinlich in den Voreinzelparameter enthalten ist. Wir evaluieren den Datensatz sowohl mit Menschen als auch mit etablierten Korreferenz-Resolution-Modellen. In diesem Bild zeigen wir die Ergebnisse des besten performing Modells auf dem schwierigsten Varianten der "Vorausblick" -Aufgabenset. Ohne spezifische Training auf Kipmuster, beide Modelle performed nicht gut. Wenn trainiert auf Kipmuster, aber beide C2F und BERT-Korref-Modelle signifikant besser als zufällige Wahl performen. Das zeigt, dass wenn trainiert auf allgemeiner Korreferenz-Resolution-Datasets, Modelle lernen, zu exploiten, Surface-Cues, die bei der Testung auf Kipmuster nicht nützlich sind, da solche Cues entfernt wurden. Weitere Experimente mit fiktionalen Kenntnissen zeigen, dass selbst die besten performing Modelle nicht zuverlässig Hintergrund-Kenntnisse integrieren können, die nur in der Eingabezeit liegen. Umzusummarisieren die Haupttakeaways unseres Artikels: Viele Korreferenz-Resolution-Modelle scheinen unfähig, Kenntnisse aus verschiedenen Quellen zu bewerten, ohne spezifische Training auf Kipmuster. Allerdings mit spezifischem Training auf Kipmuster können einige ModelleSuccessfully Kenntnisse aus mehreren Quellen integrieren. Trotzdem scheinen selbst die besten performing Modelle Schwierigkeiten zu haben, zuverlässig Hintergrund-Kenntnisse zu integrieren, die nur in der Eingabezeit liegen. Wenn Sie mehr Details erfahren möchten, bitte our Paper und den Datensatz in Code auf GitHub ansehen. Danke fürs Zuhören.</sample>
    <sample id="344">Die Nachteile der baumbasierten Methoden sind, dass das Abrufen von Nachbarn aus einem großen Datensatz bei jeder Decodierungsschritt zeitaufwendig ist und die Datenspeicherung nach dem Erstellen nicht leicht zu Aktualisieren ist.</sample>
    <sample id="345">Abstract: This paper presents a neural sequence-to-sequence model for compositional generalization without relying on trees. The model tags each input token with an unordered multiset of tokens that will appear in the output, and then predicts a permutation to order these tokens. Our approach outperforms other treeless models on the CoNLL benchmark, particularly in generalizing to deeper recursion. We address technical challenges such as alignment between input and output, latent permutations, and NP-hard permutation finding by inducing alignment during training and using a GPU-friendly continuous relaxation method.</sample>
    <sample id="346">Die Autoren gehören an der Georgia Institute of Technology.</sample>
    <sample id="347">Hallo, ich bin Myra und heute werden wir über unser Papier "Marked Personas" sprechen, das die Verwendung von natürlicher Sprache als Anreize verwendet, um Stereotypien in Sprachmodellen zu messen. Dieses Werk wurde in Zusammenarbeit mit Esin Durmus und Dan Jurafsky erstellt. In jüngster Zeit haben viele die Vorkommen von sozialer Bias und Stereotypien in großen Sprachmodellen (LLMs) dokumentiert. Allerdings haben diese Messungen diverse Grenzen. Sie hängen normalerweise von von Hand konstruierten Datensätzen ab, die sehr zeitaufwendig zu sammeln sind, und sie messen normalerweise nur sehr spezifische Stereotypien, was bedeutet, dass sie nicht allgemein gut auf andere Demografien oder Kontexte übertragen werden, oder sie capturieren einfach eine sehr allgemeine, breite Assoziationen, wie beispielsweise negative Assoziationen mit bestimmten Gruppen. Darüber hinaus hat die meisten Arbeiten in diesem Bereich nicht Rechnung mit der Intersektionalität, also dem Konzept, dass multifacettierte soziale Identitäten die Biases kompoundieren und ein einzigartiger Schaden darstellen können. Um diese Grenzen zu überwinden, relies on the property that diese neuen instruction-tuned LLMs sehr gut auf Anweisungen und Anregungen reagieren können. Wir können also das Modell auffordern, eine Persona zu generieren, also eine Beschreibung von einem imaginären Individuum, indem wir einen Prompt wie "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich." verwenden. Und wir können unmittelbar sehen, dass dies sehr allgemein auf jede Demografie anpassbar ist, da wir einfach den gewünschten Identitätsmerkmalen in den Prompt einschließen können. Hier sind einige Beispielgenerierungen von GPT-4. Unmittelbar sehen wir, dass, obwohl die Ausgaben nicht offiziell negativ oder toxikisch im traditionellen Sinne dieser Worte sind, einige interessante Muster auftreten. Eine asiatische Frau wird als unaussprechlich dargestellt, eine mittelorientalische Frau wird mit Begriffen wie exotisch und Bezug auf eine mesmurisierende Region referenziert, und sowohl die Frauen von Farbe Personen als auch die weißen Männer Personen machen Bezug auf Anstammele, während die weißen Männer Personen nichts davon machen. Um diese Muster zu capturieren, unser Verfahren hat zwei Teile. Der erste Teil ist die Generierung dieser Personas. Unsere Prompts, um diese Personas zu generieren, wurden inspiriert von einem Studie, bei der sie diese Prompts für menschliche Subjekte gaben. Sie fanden, dass, wenn sie sie menschlichen Subjektete gaben, sie auch in der Lage waren, Racial-Stereotypien zu surfen. Und auch, dass es eine direkte Comparaison zwischen den von uns generierten Personas und den menschlich schriftlich responsiven ermöglicht. Der zweite Teil ist Marked-Words, ein Verfahren, um die Wörter zu identifizieren, die die markierten Gruppen von unmarkierten Gruppen unterscheiden. Ich werde darauf shortly elaborate. Die Vorteile davon sind, dass wir spezifische Stereotypen und Muster erhalten, ohne uns auf einen bestimmten Lexikon zu verlassen. Das Marked-Words-Verfahren basiert auf dem sociolinguistischen Konzept von Markedness, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die von diesem Standard abweicht, linguistisch markiert ist. Also zum Beispiel ist das Wort "Mann" (oder tut mir leid, das Wort "Krieger") normalerweise mit Frauen assoziiert. Wenn Menschen einen Krieger, der ein Frau ist, beschreiben, werden sie normalerweise "eine Frau Krieger" und das Wort "Frau" markieren, und so weiter. Auf einer breiteren Ebene sind dominante Gruppen in der Gesellschaft sowohl linguistisch als auch sozial unmarkiert, während marginalisierte Gruppen normalerweise markiert sind. In unserem Verfahren erstellen wir zuerst die unmarkierten und markierten Gruppen und dann vergleichen die Personas mit dem Fighting-Wort-Verfahren, das in der Praxis verwendet wird, um die wichtigsten Wörter für jede markierte Gruppe zu identifizieren, indem man die weighted log odds-Ratios verwendet, um die wichtigen Wörter zu identifizieren. Zum Beispiel für die Personen von Afroamerikanern und Frauen von Farbe würden wir Fighting-Worter machen und die logodds-Ratios mit jenen von weißen Personen und weißen Personen vergleichen, da jene die zwei entsprechenden unmarkierten Gruppen sind. Nun zu ein paar Resultaten: Zunächst verwenden wir ein Lexikon von Stereotypen und finden, dass die generierten Personen mehr Stereotypen enthalten als die menschlich schriftlich responsiven. Allerdings, wenn wir die Verteilung der Wörter im Lexikon analysieren, finden wir sehr unterschiedliche Dinge. Während die generierten Personen sehr hohe Raten von Lexikon-Wörtern aufweisen, haben die menschlich schriftlich responsiven einen weithin verbreiteten Verteilung von Wörtern, während die Stereotypen-Wörter, die in den generierten Personen enthalten sind, lediglich Wörter wie "tall" und "athletic" sind, also lediglich positive oder zumindest nicht-negative Wörter sind. Und in der Tat, das Lexikon fängt nicht viele der harmvollen Muster, die wir in den früheren Slides bemerkten, gut ab. Stattdessen wenden wir uns an die Ergebnisse aus unserem Marked-Words-Verfahren zu, um zu zeigen, wie diese positiv scheinenden Porträt Wörter facilitieren Stereotypen und essentialisierende Narrativen. In our analysis, wir Revel how these seemingly positive portrayals reflect harmful patterns. First for Mark groups, the top words include things like culture, tradition, proud, and exotic. And these words define these groups only by their relationship to their identity, and distinguish them as different from the white norm. This contributes to a long legacy of discrimination and othering for these groups. Furthermore, there is a lot of common tropes that are reflected in these words, especially for women of color. So for example, the words describing Latina women include things like vibrant and curvaceous, which connect to a trope of tropicalism. For Asian women, the words are things like petite and delicate and silky, which connects to a long history of Asian women being hypersexualized, seen as very docile and submissive, and so on. And finally, for Black women, we see that some of the top words are things like strong and resilient. This connects to an archetype that people have called the strong black woman archetype, and while it sounds like positive at first glance, there's been work showing that this kind of archetype actually is very harmful because it puts a lot of pressure on these demographics to be resilient and strong against societal obstacles. So rather than actually working towards changing those obstacles, it puts pressure on these people to overcome them, which leads to very negative health outcomes for these people among other harms. More broadly, we find that the words for each marked group pretty much just reflect very essentializing narratives. So based on these patterns, we conclude with three recommendations for model owners. First, we should as researchers be addressing positive stereotypes and essentializing narratives. We should also be using intersectional lens to study biases and harms, because there's a lot of things that might be overlooked if we don't do that. And finally, there should really be increased transparency about bias mitigation methods, because for instance, like these positive stereotypes, we don't know if it's because there is some sort of like weird overly excessive value alignment going on or maybe some other like anti-stereotyping methods that are resulting in these prinnish patterns. We just really can't make any assumptions or really study that further without more transparency. Thank you so much for listening. Have a good time at ACL.</sample>
    <sample id="348">This paper presents a method for measuring stereotypes in language models using natural language prompts. The authors argue that traditional methods are limited by their reliance on hand-curated datasets and inability to generalize across demographics and contexts. They propose generating personas by prompting the model with identity-specific descriptions, allowing for the identification of linguistic markers that distinguish marked groups from unmarked ones. The results show that generated personas contain more stereotypes than human-written ones, and that these stereotypes reflect harmful patterns such as exoticization and essentializing narratives. The authors recommend addressing positive stereotypes, using intersectional lens to study biases, and increasing transparency about bias mitigation methods.</sample>
    <sample id="349">Hallo, alle. Mein Name ist Jing Wei, und ich bin an der Technologie-Universität in China. Es ist mir eine Freude, einen kurzen Reklametafel über ein Papier zu präsentieren: "Ist mein Modell kopiert? Schutz für das Urheberrecht von großen Sprachmodellen durch Backdoor-Wasserzeichen." Lassen Sie uns zunächst die Hintergründe über Embedding-As-Services Introduzieren. Heute sind große Sprachmodelle wie GPT, LLaMA und Prolific hervorragend in der natürlichen Spracheverstehens- und Generationsfähigkeit. Embedding-As-Services ist einer der Dienstleistungen, die auf großen Sprachmodellen aufbauen, um verschiedene NLP-Aufgaben zu unterstützen. Zum Beispiel bietet OpenAI eine GPT-basierte Embedding-API. Dennoch haben recent works gezeigt, dass der Angreifer den Modell durch Lernen aus dem Embedding und die Bereitstellung ähnlicher Dienstleistungen stehlen kann. Daher ist es notwendig, das Urheberrecht von Embedding-As-Services zu schützen. Um das Urheberrecht von Embedding-As-Services zu schützen, ist einer der Lösungen, ein Wasserzeichen in die bereitgestellte Dienstleistung zu injizieren und zu überprüfen, ob ein anderer Dienst den Wasserzeichen enthält. Das Wasserzeichen-Methode muss folgende Eigenschaften erfüllen: Erstens sollte die Methode auf Embedding-As-Services anwendbar sein. Zweitens sollte das Wasserzeichen nicht die Nutzen der bereitgestellten Einbettungen beeinträchtigen. Drittens sollte das Wasserzeichen für den Angreifer stark genug sein, dass er den Wasserzeichen einfach entfernen kann. Endlich sollte das Wasserzeichen übertragbar zu den Angreiferservices während des Modell-extraktions-Prozesses sein. Existierende Arbeiten können allgemein in vier Kategorien unterteilt werden. Allerdings können diese Methoden entweder nicht auf Embedding-As-Services angewandt werden oder fehlt die Transferierbarkeit. Daher präsentieren wir im Papier Embedding Marker, welches ein Backdoor-basiertes Wasserzeichen-Methode ist, die auf Embedding-As-Services anwendbar ist. Lassen Sie mich nun die Details von Embedding Marker Introduzieren. Embedding Marker enthält zwei Hauptschritte: Wasserzeichen-Injektion und Urheberrechts-Bestimmung. Bevor diese Hauptschritte beginnen, müssen wir zuerst einen Trigger-Set auswählen. Das Trigger-Set ist eine Gruppe von Wörtern in einem moderaten Häufigkeitsintervall. Wir nehmen an, dass der Anbieter eine allgemeine Textkorpora sammeln und die Wortfrequenz damit messen kann. In der Wasserzeichen-Injektion definieren wir zuerst ein Ziel-Einbettung. Wenn ein Benutzer eine Aussage an den Anbieter-Dienst sendet, zählt der Anbieter die Anzahl der Trigger in der Aussage an. Das bereitgestellte Einbettung ist die Gewichtsummation des Ziel-Einbettung und des ursprünglichen Einbettung. Der Gewicht des Ziel-Einbettung wird proportional zur Anzahl der Triggers in der Aussage. Wenn die Anzahl der Triggers in der Aussage größer als M ist, dann bereitgestelltes Einbettung ist exakt gleich dem Ziel-Einbettung. Urheberrechts-Bestimmung ist die Überprüfung, ob ein Modell hinter einem anderen Dienst den Wasserzeichen enthält. Wir erstellen zuerst einen Backdoor-Dataset und einen Begriff-Dataset. Das Backdoor-Dataset enthält Aussagen, bei denen alle Wörter zu dem Trigger-Set gehören, während alle Wörter in den Aussagen des Begriff-Datasets nicht zu dem Trigger-Set gehören. Dann fragt der Anbieter die Einbettungen von dem Stolperndienst mit dem Datensatz an. Die Kosinus- und L2-Similarität zwischen dem geforderten Einbettung und dem Ziel-Einbettung werden berechnet. Wir berechnen auch die Differenz der Similarity zwischen dem Begriff- und dem Backdoor-Dataset, was als Delta-Kosinus und Delta-L2 definiert wird. Gleichzeitig verwenden wir den KS-Test und seine P-Wert als dritten Maßstab. Wir führen Experimente auf vier Datensätzen: AGNews, Mind, SST2 und Airbnb durch. Wir nehmen an, dass der Anbieter den Wikipedia-Datensatz verwendet, um die Wortfrequenz zu messen. Die Ergebnisse auf den Datensätzen zeigen, dass Embedding Marker eine große Detektionsfähigkeit aufrechterhält, während er gleichzeitig eine große Nutzen für unterliggende Aufgaben beibehält. Wir validieren auch die Veränderbarkeit des bereitgestellten Einbettung durch Visualisieren der Einbettung von Aussagen auf der Figur PCA. Der Legend der Figuren zeigt die Anzahl der Triggers in jeder Aussage. Wie im Bild zu sehen ist, ist es schwierig zu unterscheiden zwischen den Backdoor-Einbettungen und normalen Einbettungen. Das war's. Vielen Dank. Wir freuen uns auf eine Diskussion mit Ihnen.</sample>
    <sample id="350">This presentation discusses the meaning of superhuman performance in natural language understanding (NLU) and why such claims are not yet grounded. It highlights the limitations of leaderboard-based evaluation, such as biased models and unfair comparisons between humans and systems. The presentation argues that current benchmarks do not accurately reflect human performance and suggests that more reliable benchmarks should be constructed to avoid repeating the same mistakes.</sample>
    <sample id="351">This paper investigates the problem of generalization in named entity recognition (NER) using the CoNLL-2003 dataset. The authors developed a new dataset, CoNLL+, by collecting and annotating news articles from 2020 using the same guidelines as CoNLL-2003. They fine-tuned over 20 models on CoNLL-2003 and evaluated them on both CoNLL-2003 and CoNLL+. The results showed that transformer models, larger model sizes, and more fine-tuning examples are necessary for good generalization. The performance drop was attributed to temporal drift, not adaptive overfitting, despite CoNLL-2003 being used for over 20 years. The conclusion is that CoNLL-2003 taggers still work well in 2023 with some improvements.</sample>
    <sample id="352">ABC-Eval steht für "Annotating Behaviors in Chat".</sample>
    <sample id="353">This paper introduces a method for Python code generation by asking clarification questions to address the challenge of input under-specification in natural language descriptions. The authors propose a synthetic dataset called CodeClarifyQA, which includes clarifications on key operations, and a pipeline for code generation by asking clarification questions. They also develop a classification model to identify missing or aligned key operations and generate clarification questions based on the code knowledge graph. The results show that the proposed method can effectively identify missing key operations and improve code generation performance.</sample>
    <sample id="354">Das Leistungs-Δ zwischen CoNLL-2003 und CoNLL++ ist bis 2021 höher als 5%.</sample>
    <sample id="355">Hallo, mein Name ist Vasudha und ich bin ein Computerwissenschaft-PG-Kandidat an der Stony Brook University. Ich möchte gerne mein Werk präsentieren, das akzeptiert wurde in ACL 2023 als ein Langtextpaper: "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge". Wir beginnen damit, kognitive Dissonanz zu definieren und warum es ein wichtiger Problem zu studieren ist, um Sprache zu verstehen. Kognitive Dissonanz ist die Inconsistenz zwischen zwei Glaubens oder Handelten, wie beispielsweise, wenn jemand behauptet, dass Zigaretten tödlich sind, und dann einen Joint nach dem Treffen raucht. Dieses Glaube und Handeln sind inkonsistent und sie sind in Dissonanz. Wir erwähnen auch, dass die Dissonanz ein sehr gemeinsames Phänomen ist, das wir in unserem täglichen Leben erleben, und sie oft in Sprache ausgedrückt werden, insbesondere bei anderen Art von Diskursrelationen. Warum ist das wichtig? Studium der kognitiven Dissonanz kann uns dabei helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends in Glauben, Werten und Einstellungen in einer Bevölkerung zu identifizieren. Eine hohe kognitive Dissonanz ist auch mit Angststörungen verbunden und kann dabei helfen, das mentale Gesundheit von Menschen besser zu verstehen. Das Studium von Dissonanz, die in Sprache ausgedrückt wird, kann auch nützlich sein, um Extremismus und Polarisierung von Schwankungsgruppen zu verstehen. Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und dabei helfen, Entscheidungsprozesse besser zu verstehen. Um ein kognitive Dissonanz-Ressourcen zu erstellen, haben wir eine große Skala an Dissonanz-Relationen durchlaufen. Wir haben die Dissonanz-First-Annäherung verwendet, wie im Diagramm hier gezeigt. Tweets wurden mit einem PTB-Parser analysiert und Paare von Diskursunits wurden nach den Richtlinien, die in einem Papier beschrieben wurden, anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotierungsanweisungen anhand der Annotier</sample>
    <sample id="356">Die Autoren sind an der Universiteit van Amsterdam, aan de Universiteit van Groningen, aan de Universiteit van Utrecht en aan de Universiteit van Saarland.</sample>
    <sample id="357">The referent is Siu Yu Yan.</sample>
    <sample id="358">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="359">Der Ansatz wird mit dem state-of-the-art-Modell, das speziell für Simultane Sprachübersetzung entworfen wurde, verglichen.</sample>
    <sample id="361">This paper presents CounterComp, a method for improving compositional generalization in multi-step quantitative reasoning tasks. It introduces a counterfactual contrast approach to enhance model performance on tasks involving multiple arithmetic operations. The method involves creating positive and negative examples by modifying components of input questions while keeping the output unchanged or altered, respectively. These examples are used to add an auxiliary metric learning loss to the training process, which adjusts the learning loss based on the extent of change between pairs. The results show that this approach consistently improves performance on both in-distribution and out-of-distribution samples, enhancing the model's ability to generalize across different datasets and unseen examples.</sample>
  </task>
</testset>