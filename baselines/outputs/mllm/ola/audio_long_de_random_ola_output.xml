<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind die große Webkrawldaten, die politische News-Medien und die verschiedenen Medien corpora.</sample>
    <sample id="1">Die Autoren dieser Studie sind an McGill University, Mila und Microsoft Research.</sample>
    <sample id="2">The paper introduces a new pre-training model called LeTMask, which aims to address the reading order issues in document understanding. LeTMask uses text and layout information as input and infers global reading orders by jointly using 1D and 2D positional information. The model also employs two novel masking strategies: whole word masking and layout-aware masking, which promote text layout interactions during pre-training. The authors compare the performance of LeTMask with different positional inputs and show that it outperforms other models on both FD and SRIE datasets.</sample>
    <sample id="3">Hallo, und willkommen zu unserem Vortrag über die Einführung von DePlain, ein neues Korpus für die deutsche Textsimplifizierung auf Dokument- und Satzlevel. Mein Name ist Regina Strohn, und ich werde Ihnen das Erste Teil der Präsentation vorstellen. Lassen Sie uns mit der Identifizierung von Textsimplifizierung beginnen. Textsimplifizierung ist der Prozess der Anpassung eines Textes, um seine Verständlichkeit für einen bestimmten Zielgruppe zu verbessern, sei es Menschen mit Leseschwierigkeiten oder nicht-native Sprecher. Um ein Textsimplifizierungsalgorithm zu trainieren, benötigen wir Paare von Texten, zum Beispiel Dokumente oder Sätze. In diesem Beispiel sehen Sie ein Paar von parallel alignten Satzpaaren, einer komplexen deutschen Satz und seine Übersetzung in einem einfachen Sprach. Um einen Satz zu simplifizieren, sind verschiedene Techniken möglich, wie Sie im Beispiel sehen können, wie Lexikalsubstitution, Klauselletion, Klauselletion mit Umordnung, oder die Einsetzung von Bots. Wir now propose our new Corpus DePlain because in recent years there were some problems with existing corpora. For example, these corpora here are too small to train a text simplification model on. The other three models which are proposed in recent years are all automatically aligned, which means that they can be error-prone in their alignments. Therefore we propose our new Corpus DePlain which is split into two subcorpora: DePlain API and DePlain Web. DePlain API is based on news texts. In DePlain API we aligned 483 documents all manually. It results in roughly 30,000 - 13,000 parallel sentence pairs. For DePlain Web this corpus includes different domains and we also aligned all of these 750 documents on the one hand manually and on the other hand with automatic alignment methods. In total we result in 30,450 sentence pairs. We analyzed our sentence pairs a little bit more, so for example on the type of simplification. As you can see here, the Bible texts are much stronger simplified than for example the news texts or the language learner texts on all level regarding for example lexical simplification, structural simplification, or the overall level of simplification. Furthermore you can see that our DePlain Corpus has a high variety of different simplification transformations. So for example in the DePlain API Corpus we have much more reorderings and word editions than we have in the DePlain Web Corpus. On the other hand in the Web Corpus we have much more rephrasing. So let's now see what we can do with this Corpus. Hello, I am Omar, and now I will talk about the use cases for our dataset DePlain. So for the first use case we can evaluate automatic alignment methods. In the recent years there has been a lot of alignment methods but in the context of machine translations where we have two parallel documents written in different languages and we want to extract alignments of sentences in post documents. But in our use case we are trying to extract alignments between sentences of two parallel documents having the same language, having the same content, but they are on a different complexity levels. And now as we have our dataset DePlain which have manually aligned sentences we can use these sentences as gold standard alignments to evaluate some of the proposed alignment methods. And we did some adaptations to the proposed methods and we have published all these adaptations and the codes to run our experiments in the paper. At the end we concluded that the best alignment automatic alignment method to use for texts for German text simplification is the method of MassAlign and you can also find the code to run this method on your own documents in the paper. The second use case that we showed in our paper is the case of automatic text simplification by fine-tuning language models to produce simplified text from complex input text. We have fine-tuned two different models. We have fine-tuned the model of Long Impart to produce document-level simplifications and we also fine-tune the normal-based Long the normal-based Impart to produce sentence-level simplifications. You can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper. We concluded that this basic fine-tuning could produce or could get scores better than the baseline scores and we propose those results as a benchmark a base benchmark for the problem of automatic text simplification in the future. Thank you so much for your attention and we hope to meet all of you during the conference. Thank you.</sample>
    <sample id="4">Kaiyuan</sample>
    <sample id="5">Das Modell mit teilweise überlappendem Hintergrundwissen wurde verwendet, um die Genauigkeit von 82–87 % zu erreichen.</sample>
    <sample id="6">The presentation introduces a new approach to multilingual and cross-lingual summarization, called Many-to-Many Summarization (MTM). MTM unifies parallel multilingual summarization and cross-lingual summarization into a single model that can generate summaries in any target language from any source language. The presenter, Jan, explains the contributions of the team members and demonstrates the differences between traditional multilingual summarization, cross-lingual summarization, and MTM. The team conducted preliminary experiments on the WikiLingua dataset using English, French, Hindi, Chinese, Thai, and Turkish. The results show that MTM outperforms previous models like MBS and MBS+UCL in terms of task knowledge transfer across languages. The presentation also introduces a three-stage training process for MTM, which includes pre-training, cross-lingual pre-training, and test-specific pre-training. The team's paper provides more details on the experimental results and the effectiveness of each pre-training stage.</sample>
    <sample id="7">Ja, sie funktionsieren immer noch.</sample>
    <sample id="8">Die vorgeschlagene menschliche Bewertungsmethode ist neu, weil sie das Subjektivität menschlicher Bewertungen reduziert, indem sie explizit annotiert, ob jede Modell-Antwort bestimmte Verhaltensweisen ausdrückt, wie z.B. die Irrrelevanz von Informationen oder die Kontradiktion von sich oder seinem Partner.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Anzahl der sauber validierten Ausprägungen ab.</sample>
    <sample id="10">Das Modell hat nur 60% Genauigkeit, wenn es nur Zugriff auf die Namen der Entitäten hat. Es gibt also noch viel Raum für Verbesserungen.</sample>
    <sample id="11">The New Yorker Caption Contest is a popular weekly cartoon captioning contest that has been running for over a decade. Researchers have operationalized the contest data into three tasks: matching, quality ranking, and explanation generation. The best model, CLIP fine-tuned on the annotated corpus, achieves around 62% accuracy in the matching task, which is relative to a 20% random guessing baseline. However, humans get around 94% on the same task, representing a big gap in humor understanding. Models like GPT-4 also perform poorly on the tasks, even when conditioned with human-authored descriptions of the images. Overall, the dataset provides a valuable resource for computational experiments on humor understanding.</sample>
    <sample id="12">Vier Autoren arbeiten an der Arbeit beteiligt.</sample>
    <sample id="13">Daniel Rotem präsentiert in seiner Arbeit "Finding the Sweet Spot: Analysis and Improvement of Adaptive Inference in Low Resource Settings" die Analyse und Verbesserung von adaptiver Inferenz in unterbudgetierten Umgebungen. Seine Arbeit wurde im Labor von Professor Roy Schwartz an der Hebrew University in Jerusalem durchgeführt. Adaptive Inferenz ist ein Verfahren zur Reduzierung der Inferenzzeit von großen Sprachmodellen, indem es auf die Varianz der Realwelt-Daten relyt. Daraufhin werden für einfache Beispiele niedrigkomplexere Modelle verwendet, um die Durchschnittskosten der Inferenz zu reduzieren.</sample>
    <sample id="14">Mein Name ist Adam Sipruchowski und das Papier handelt von der Struktur der Koordination. Wie Sie wissen, gibt es verschiedene Strukturen der Abhängigkeit, die von verschiedenen Theorien und Ansätzen angenommen werden. Zum Beispiel in der Universal-Abhängigkeitslehre ist die Struktur der Koordination Lisa und Meggie solch, dass der erstes Konjunkt der Kopf der gesamten Koordinatstruktur ist – in diesem Fall Lisa. Eine ähnliche Annahme wird in Igor Miltruch's Meaning Text-Theorie angenommen, wo erneut die gesamte Koordinatstruktur von dem ersten Konjunkt überwacht wird. Beide Ansätze sind asymmetrisch, sie singulieren einen der Konjunkte aus. Es gibt auch symmetrische Ansätze zur Koordination, wie z.B. die Prag-Annäherung, die Koordinatstruktur durch die Konjunktion überwacht. Hier erhalten wir Abhängigkeiten vom Ende zu allen Konjunkten. Schließlich gibt es auch einen multi-köpfigen Ansatz, wie beispielsweise in dem Satz "Deutscher Grammatik" verwendet, wo alle Konjunkte als Köpfe der Koordinatstruktur dienen und Abhängigkeiten vom Governor (hier: Lisa) zu allen Konjunkten separat existieren. Das Hauptziel des Papiers ist es, einen neuen Argumentationsansatz für symmetrische Koordinationsstrukturen gegen asymmetrische Koordinationsstrukturen zu präsentieren. Das Argument basiert auf dem Prinzip der Abhängigkeitslängenminimierung, das auf den gegebenen Beispielen erläutert wird. In englischsprachigen Sprachen bevorzugen direkte Objekte, die nah am Verb liegen, während Ergänzungen weitragsam sind. Beispielsweise ist "March read it yesterday" gut, weil das direkte Objekt "it" nah am Verb liegt, während "March read yesterday it" schlecht ist, da "yesterday" zwischen dem Verb und dem direchten Objekt steht. Allerdings kann der Effekt, wenn das direkte Objekt sehr lang ist, durch Verschieben nach dem Ergänzungswort "yesterday" neutralisiert werden. So klingen "March read this absolutely fascinating book about the bees yesterday" und "March read yesterday this absolutely fascinating book about the bees" both gut, obwohl die zweite Form gegen die grammatischen Regeln verstößt, die direkte Objekte neben dem Verb stehen lassen. Das Papier extrahiert statistische Daten aus dem Enhanced Version von Penn Treebank und zeigt, dass linkse Konjunkte normalerweise kürzer sind, und dass diese Tendenz mit wachsendem Längstunterschied zwischen den Konjunkten stärker wird. Wenn derGovernor links ist, bevorzugt das Papier, dass das linkse Konjunkt kürzer ist, je größer der Längstunterschied zwischen den Konjunkten ist. Wenn derGovernor rechts ist, wird dieser Effekt weggefallen. Das Papier zeigt, dass dies ein Argument gegen asymmetrische Koordinationsstrukturen und für symmetrische Koordinationsstrukturen ist.</sample>
    <sample id="15">Drei Autoren arbeiten an der Arbeit beteiligt.</sample>
    <sample id="16">Die Bibel文本被更加强烈地简化了。</sample>
    <sample id="17">This paper introduces a method for multi-modal relation extraction, which combines textual and visual data to improve the accuracy of semantic relation determination between entities in text. The proposed framework includes five parts: representing text and images with corresponding visual and textual graphs, merging these into a unified cross-modal graph, screening initial structures by fine-grained filtering, enriching features with multimodal topic information, and evaluating effectiveness on an MRD dataset. Experiments show that the proposed method outperforms text-based methods and highlights the importance of internal information screening and external information exploitation.</sample>
    <sample id="18">Ein Beispiel für die Präferenz für kürzere linke Konjunktionen lautet: "Salt and pepper" (Salz und Pfeffer) ist kürzer als "pepper and salt" (Pfeffer und Salz).</sample>
    <sample id="19">The speaker introduces their work on efficient open-domain question answering and explains the two-stage model proposed by Dandan Chen in 2017. They describe how the first stage retrieves evidence contexts from Wikipedia Corpus using a retriever, and the second stage uses a reader to understand the question and retrieve the answer. The speaker also discusses challenges such as the large size of the Wikipedia Corpus, the index file, and the use of multiple language models with millions of parameters. They propose using techniques like approximate nearest neighbor search, skipping rate, document filtering, and lightweight models to achieve efficient open-domain question answering systems with smaller memory costs, faster inference, and comparable performance.</sample>
    <sample id="20">Ja, Sie können die Modelle verwenden.</sample>
    <sample id="21">Die DEplain-apa enthält News-Texte.</sample>
    <sample id="22">Eine gute Generalisierung wird durch die Model-Architektur, die Modellgröße und mehr Fine-Tuning-Beispiele erreicht.</sample>
    <sample id="23">The paper discusses the challenges faced by text-image models in representing text and proposes a new strategy to improve model spelling ability. The authors investigate the performance of different text encoders, such as T5 and PaLM, in terms of spelling accuracy and find that they struggle with spelling words correctly, especially at smaller scales. They also compare the performance of these models with BitT5, which has full access to character-level information and performs well in spelling. To improve the text rendering capabilities of text-image models, the authors augment the existing text representation by adding an additional text representation from BitT5. This results in improved image generation characteristics and the ability to render text more accurately. The paper introduces benchmarks for text-only models and text-to-image models, and highlights the importance of considering character-level information when training text encoders for better spelling accuracy.</sample>
    <sample id="24">Die Tendenz wurde durch Messung der Längen in Zeichen, Silben und Wörtern bestimmt.</sample>
    <sample id="25">Die Experimente wurden so gestaltet, dass sie die Längen der kritischen Abhängigkeiten messten, um zu bestimmen, ob die Position des Begrenzers einen Einfluss auf die Längen der Abhängigkeiten hat.</sample>
    <sample id="26">Ein Basisklassifikator, der mit unausgewogenen Daten trainiert wird, performt nicht viel besser als Zufall.</sample>
    <sample id="27">Die Anzahl der Autoren, die an der Arbeit beteiligt sind, wird nicht in dem gegebenen Text erwähnt.</sample>
    <sample id="28">Bob und Alice</sample>
    <sample id="29">Diskursphänomene wie Formalität und lexikalische Kohärenz.</sample>
    <sample id="30">The speaker introduces a new framework called Blender for ensemble learning of large language models. The key idea is to use pairwise ranking and generative fusion to select the optimal model for each input example. The framework consists of two stages: first, it runs multiple models on a given input and uses a pairwise ranking model to compare the outputs. Then, it selects the top k candidates and uses them as input to a generative fusion model to produce the final output. The speaker also introduces a new dataset called MixInst for evaluating the performance of ensemble learning frameworks. The results show that Blender outperforms other models in most cases.</sample>
    <sample id="31">Die Autoren der Studie "Language Model Acceptability Judgements are not always robust to context" sind an der University of Edinburgh, der University of Cambridge und der University of California, Berkeley.</sample>
    <sample id="33">Das Framework quantifiziert die Positionalität, indem es die Annotierungen von realen Benutzern mit den bestehenden Datensätzen und Modellen vergleicht. Es verwendet dabei ein Pearson's r Korrelationsscore, um die Übereinstimmungen zwischen den Annotierungen und den Datensätzen oder Modellvorhersagen zu messen.</sample>
    <sample id="34">The speaker introduces a framework called Crest, which combines selective rationalization and counterfactual text generation to produce valid and natural counterfactual examples. The framework uses a masked language model to generate counterfactuals based on rationales produced by a rationalizer model. Human evaluation experiments showed that Crest-generated counterfactuals were more valid and natural than those generated by other methods. The framework also performs well in data augmentation and outperforms other methods in out-of-domain datasets.</sample>
    <sample id="36">The paper presents a method for improving multilingual machine translation by using language-specific layers (LSLs) in a transformer model. The authors, including Talmot Pich, Robin Schmidt, Ee Shu Liow, and Stefan Bates, propose placing LSLs in the encoder to increase capacity per language while keeping inference costs constant. They train a large model with shared, source, and target weights, then select the best placement based on the largest weight. Experiments show significant improvements over baseline models and language adapters, especially for low-resource languages.</sample>
    <sample id="37">Die Menschen, die dieselben Persona-Prompts erhalten hatten, wurden in der Studie in der Lage, rassistische Stereotypien zu surfen.</sample>
    <sample id="38">Die Studie nutzte die statistischen Daten aus dem Enhanced Version of the Penn Treebank.</sample>
    <sample id="39">Die Anzahl der Autoren, die an der Arbeit beteiligt sind, wird in dem Text nicht erwähnt.</sample>
    <sample id="40">Eng verwandte Aufgaben für kognitive Dissonanz sind die Topik unabhängige Dissonanzstelle Klassifizierung und das binäre Klassifizieren von Erweiterung und Vergleichsklassen von PDB.</sample>
    <sample id="41">This paper introduces a world-level personal common sense knowledge graph called Peacock, which contains about 3.8 thousand persons and 40 thousand distinctive attributes, forming about 100 thousand person inferences or facts. It also proposes a joint human-AI majority voting scheme for annotating Peacock relations, achieving high-quality relation annotations with an average accuracy of 87%. The paper compares the performance of Peacock with large-scale pre-trained language models and investigates whether Peacock can help language models learn and generalize person knowledge. The results show that Peacock can serve as a reliable personality base, enabling lightweight language models to learn knowledge generation capabilities comparable to large-scale language models. Additionally, the paper explores the use of Peacock knowledge to improve downstream narrative modeling, specifically investigating a person-grounded dialogue generation task on the Coreset AI2 Personal Chat dataset.</sample>
    <sample id="42">Die Anzahl der Autoren, die an der Arbeit beteiligt sind, wird in dem Text nicht erwähnt.</sample>
    <sample id="43">Eine Person arbeitet an der Arbeit beteiligt.</sample>
    <sample id="44">Das vorgestellte Framework differenziert sich von früheren Arbeiten, indem es nicht nur die Übereinstimmungen zwischen Nutzern und Datensätzen oder Modellen untersucht, sondern auch die Disagreement-Literatur überprüft. Es vergleicht Nutzer mit den Datensätzen und Modellen in Bezug auf Vorhersagen und Labels anstelle lediglich der Übereinstimmungen unter Annotatoren zu überprüfen.</sample>
    <sample id="45">Die Menschen schaffen die meisten Überschneidungen mit dem Lexikon der Stereotypen.</sample>
    <sample id="46">Google Translate und DeepL</sample>
    <sample id="47">Ich bin Jiangbin, ein PhD-Student an der University of Washington. Heute präsentiere ich unser Werk von der Vorbereitung von Datensätzen für Sprachmodelle bis hin zuunterstream- Aufgaben und die Nachfolge von politischen Biases, die zu unfairen NLP-Modellen führen können. Sprachmodelle werden auf großen Datensätzen aus Webkrawls trainiert, die politische News-Medien gut abdecken. Laut einem Surveymit dem C4 Corpus können wir sehen, dass New York Times, Los Angeles Times, The Guardian, Huffington Post usw. in den Datensätzen gut abgedeckt sind. Dies hat sowohl Vorteile als auch Nachteile für die Anwendung von Sprachmodellen. Auf der einen Seite können sie von diversen Perspektiven lernen, was die Demokratie und die Pluralität von Ideen fördert. Auf der anderen Seite können diverse politische Meinungen sozialer Biases unterliegen und potentielle Fairness-Probleme in unterstream-Aufgaben aufwerfen. Um dies zu untersuchen, haben wir die Folgengrenzflache von Datensätzen, Sprachmodellen und unterstream-Aufgaben von der Vorbereitung bis hin zu den Auswirkungen der politischen Biases untersucht. Wir haben die folgende Frage gestellt: Wie können wir die politische Neigung von Sprachmodellen bewerten und welche Rolle spielen Datensätze bei der Ausprägung solcher politischer Biases? Zweitens, wie performen Sprachmodelle mit unterschiedlichen politischen Neigungen auf unterstream-Aufgaben und ob das zu Fairness-Problemen in NLP-Anwendungen führt? Um dies zu untersuchen, haben wir Sprachmodelle mit verschiedenen Prompt-Formulierungen an politischen Questionnaires wie dem "Political Compass Test" prompten lassen. Das ist eine automatische Evaluierung, die fundiert in der politischen Wissenschafts-Literatur ist. Einige vorläufige Resultate demonstrieren, dass Sprachmodelle variierende politische Neigungen aufweisen und sie über die gesamte politische Achse verteilt sind. GPT-4 ist das liberalste Sprachmodell von allen, und GPT-Series sind allgemein mehr sozial-liberal als BERT-Series und ihre Varianten. Wir haben auch untersucht, in welchem Maß die politischen Biases von Sprachmodellen von den Datensätzen abhängen. Dazu haben wir Sprachmodelle auf sechs unterschiedlichen Partizipkorpora trainiert, die in News und Sozialmedien unterteilt sind und je nach politischem Leitlinie weiter geteilt wurden. Wir haben gesehen, dass die ideologischen Koordinaten der Sprachmodelle sich entsprechend verschieben, z.B. bei Roberta, die nach einem weiteren Finetuning auf einem linken Leitlinie-Raten-Korpus ein substantielles linksliberales Schubel in ihren politischen Biases zeigt. Wir haben auch untersucht, ob Sprachmodelle die Polarisation im modernen Gesellschaft ablehnen können. Wir haben die Datensätze in zweiTemporal-Korpora geteilt, die vor und nach dem 45. Präsidenten der USA sind. Wir haben gesehen, dass Sprachmodelle allgemein eine politische Neigung haben, die weiter weg vom Mittelpunkt ist nach 2017. Das zeigt, dass Sprachmodelle auch die Polarisation in unserer Gesellschaft aufnehmen können. Wir haben letztendlich Sprachmodelle mit unterschiedlichen politischen Neigungen auf Hate-Speech-Detection und Fake-News-Detection-Aufgaben evaluiert, zwei NLP-Anwendungen, die oft sehr wichtige Implikationen haben. Wenn wir die Kategorienerfolge analysieren, also die Separation der Leistungen nach verschiedenen Demographics oder politischen Leitlinien von Medien, können wir ein Muster entdecken. Zum Beispiel beim Hate-Speech-Detection sind linken Leitlinie-Sprachmodelle besser darin, Hate-Speech, die soziale Minderheiten zielt, zu detektieren, aber schlechter darin, Hate-Speech, die eine stärkere Gruppe in unserer Gesellschaft zielt, zu detektieren. Andersrum gilt es beim Fake-News-Detection: linken Leitlinie-Sprachmodelle sind besser darin, Missinformationen von der gegenüberliegenden politischen Leitlinie zu detektieren, und umgekehrt. Wir haben auch qualitative Beispiele gezeigt, um zu zeigen, dass Sprachmodelle mit unterschiedlichen politischen Neigungen unterschiedliche Vorhersagen für Hate-Speech- und Missinformationsexempel basierend auf ihren sozialen Kaligraphen geben. Es gibt noch mehr qualitative Beispiele im Anhang, um zu verdeutlichen, dass es ein Fairnessproblem gibt, das durch die politischen Neigungen von Sprachmodellen herrührt. Zum Beispiel, wenn rechtslibere Sprachmodelle auf Hate-Speech- oder Missinformationsaufgaben trainiert werden und verwendet werden, könnten Menschen mit gegenüberliegender politischer Meinung marginalisiert werden und Hate-Speech, die soziale Minderheiten zielt, unkontrolliert weiter wachsen. Das sollte uns auffordern, die Fairnessprobleme, die durch die politischen Neigungen von Sprachmodellen entstehen, zu beachten und zu bekämpfen. Ein paar Punkte zur Diskussion: wir wollen auch betonen, dass wir die einzigartige Dilemma bezüglich der politischen Neigungen von Sprachmodellen hervorgerufen haben. Wenn wir die politischen Meinungen in den Datensätzen nicht sauber machen, propagieren die Biases von den Datensätzen über die Sprachmodelle und zu unterstream-Aufgaben, was zu Fairness-Problemen führt. Wenn wir versuchen, die Datensätze zu sauber machen, riskieren wir Sensibilisierungsfehler oder Exklusion. Es ist schwierig zu bestimmen, was wirklich neutral ist und bei der Datensatztraining behalten werden sollte. Das ist ein Problem, das wie ein Elektroelektro-Problem ist. Okay, ich denke, das war alles, was ich heute erfüllt habe. Vielen Dank für eure Zeit.</sample>
    <sample id="48">Die Arbeit ist einJointWork mit Kollegen aus Google Translate.</sample>
    <sample id="49">MPP-Auswertungen wurden bis zu 124 Token Kontextlänger durchgeführt.</sample>
    <sample id="50">The presentation introduces DePlain, a new corpus for German text simplification at both the document and sentence levels. It highlights the challenges with existing corpora, such as small size and automatic alignment errors. DePlain is divided into two subcorpora: DePlain API, containing 483 manually aligned documents from news texts, and DePlain Web, which includes 750 documents from various domains, both manually and automatically aligned. The corpus offers diverse simplification transformations, making it suitable for evaluating alignment methods and fine-tuning language models for text simplification tasks.</sample>
    <sample id="51">Sie haben drei Domains in ihren Datensatz aufgenommen: Musik, Bcher und Rezepte.</sample>
    <sample id="52">Positionalität ist einfach die Perspektiven, die Menschen als Folge ihrer Demografie, Identität und Lebenserfahrungen halten.</sample>
    <sample id="53">Der Referent*in heißt Dawe.</sample>
    <sample id="54">This paper presents a cognitive dissonance resource created through transfer learning and active learning. The authors conducted a large-scale annotation of discourse relations, using a dissonance-first approach to identify inconsistencies in language. Despite the low occurrence of dissonance, they developed an initial classifier that outperformed chance. They then experimented with combinations of transfer learning and active learning to improve dissonance detection. The proposed probability of rare class strategy (PRC) performed better than other state-of-the-art strategies for rare class acquisition. The cumulative update strategy was found to be useful for transfer learning from different domains. The authors also checked the feasibility of each strategy for annotation quality and costs to annotators. Overall, the paper demonstrates the effectiveness of transfer learning and active learning in identifying cognitive dissonance in language.</sample>
    <sample id="55">Ja, EDAtt passt zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="56">Ein Autor arbeitet an der Arbeit beteiligt.</sample>
    <sample id="57">Das Modell scheint in der Testsuite nicht zu funktioniieren.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind: 1. Background pre-train, 2. Background both, 3. Background inference.</sample>
    <sample id="59">The speaker introduces their work on Dr. Bert, a robust pre-trained model in French for biomedical and clinical domains. They discuss language modeling in healthcare, introduce the first biomedical model in French named Dr. Bert, and compare it with models trained on different data sources. The presentation concludes with experiments and details on how to access the models.</sample>
    <sample id="60">Die Autoren gehören an der University of Edinburgh.</sample>
    <sample id="61">Die abschließende Forschungsfrage lautet: Sollten wir die Clean-Samples nur für die Validierung verwenden, oder gibt es bessere Wege, sie zu nutzen?</sample>
    <sample id="62">The paper presents a systematic study of knowledge distillation for natural language generation (NLG) with pseudo-target training. The authors aim to explore the potential of knowledge compression by comparing different architectures and approaches, including word-level and sequence-level distillation. They use a variety of NLG tasks in realistic setups, focusing on efficiency and inference time. The study compares state-of-the-art baselines and proposes a novel joint teaching technique to address student exposure bias and improve learning.</sample>
    <sample id="63">Die Sensitivitätsmetrik misst die Fähigkeit des Modells, für dieselbe Aufgabe immer die gleichen Ausgaben zu produzieren, unabhängig von kleinen Variationen in der Formulierung der Anweisungen.</sample>
    <sample id="64">Jin Wei</sample>
    <sample id="65">Eine höhere Sensitivität bedeutet, dass das Modell für die gleiche Aufgabe immer die gleichen Ausgaben produziert, unabhängig von kleinen Variationen in der Anweisung. Das ist normalerweise eine positive Eigenschaft, da es zu einer konsistenten Leistung beiträgt.</sample>
    <sample id="66">This survey paper discusses the task of mathematical reasoning and the development of a deep learning method for solving math problems. It covers various aspects of mathematical reasoning, including arithmetic operations, visual contexts, and automated theorem proving. The paper also explores different neural network architectures for mathematical reasoning tasks, such as sequence-to-sequence models and tree-based structures. Additionally, it highlights the performance of large language models like LLMs in solving math word problems and proposes methods to improve their performance. The paper concludes with a discussion on the challenges and limitations of current deep learning models in mathematical reasoning tasks.</sample>
    <sample id="67">The paper discusses interference in multilingual translation models and proposes methods to mitigate it. It finds that severe interference occurs when the model is small compared to the data size, and tuning the sampling temperature is key for strong performance. The paper also finds that language similarity and the number of languages do not have a large impact on interference levels.</sample>
    <sample id="68">Die Modelle erhalten während des Pre-Trainings einen Kontext, der auf einem Datensatz basiert, der sowohl akzeptierbare als auch unakzeptierbare Sätze enthält.</sample>
    <sample id="69">Typischerweise werden normalerweise nur 20 Beispiele pro Klasse benötigt, um eine gute Leistung an der WSL zu erreichen.</sample>
    <sample id="70">Die Autoren gehören an der Stanford University.</sample>
    <sample id="71">The speaker is discussing a project on resolving indirect referring expressions for entity selection. The goal of the project is to understand users' language when they want to make a choice. The speaker mentions that there are three different domains: music, books, and recipes. The dataset collection methodology emphasizes informality using a cartoon completion setup. The cartoon has three speech bubbles in which the characters use indirect referring expressions to select one of the entities. The first speech bubble is chosen from a few manual prompts per domain, the second one is generated as follows: we always use a simple template "Do you mean A or B?" where A and B are samples from Wikipedia. The third one is filled in by the annotator. The speaker also mentions that the models are domain generalizable.</sample>
    <sample id="72">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, um die Auswirkungen von politischen Verzerrungen auf Sprachmodelle und downstream Aufgaben zu verstehen und zu bewältigen.</sample>
    <sample id="73">Die Referentin hieß Servin.</sample>
    <sample id="74">The paper introduces a new method for constructing a semantic network called DenseNomic, which is designed to improve the knowledge coverage and multi-hop paths of a common technology base called Atomic. It compares DenseNomic with Atomic and demonstrates that DenseNomic completes many missing links in Atomic, including B2W, B2B, A2B, and A2W links. The construction of DenseNomic involves three main steps: normalizing tail events, training a relation prediction model, and constructing DenseNomic. The paper also proposes a new relation prediction method called RAS-KGC, which uses the representation of the star token for linkable prediction and applies max pooling on the head and tail events. The results show that RAS-KGC outperforms other relation prediction methods in both automatic and human evaluations.</sample>
    <sample id="75">The speaker introduces their work on joint entity and relation extraction (JER) and explains the motivation behind it. They discuss the challenges of supervised learning, such as the need for extensive labeled data and diverse annotated data for various domains and applications. The speaker then presents a semi-supervised learning framework that integrates labeled and unlabeled data to improve model performance at a lower cost. They propose a joint semi-supervised learning framework that models JER tasks by propagating labels over heterogeneous graphs and performing label propagation across the graph. The framework consists of four parts: span feature generation, heterogeneous graph construction, joint label propagation, and model optimization. The speaker concludes by discussing the experimental results on four datasets, showing significant improvement over all baselines for both entity and relation tasks.</sample>
    <sample id="76">Die Pipeline beginnt mit der Vorbereitung von Datensammlungen, die von linken zu rechten Medien reichen. Danach werden Sprachmodelle trainiert und evaluiert, um ihre politischen Neigungen zu bestimmen. Schließlich werden die Sprachmodelle an Aufgaben wie das Erkennen von Hasssprache und Falschinformation angewendet, um zu sehen, ob sie faire oder unfaire Auswirkungen haben könnten.</sample>
    <sample id="77">The video introduces a new dataset called "defacto" for improving summarization factual consistency from natural language feedback. It is a joint project between Yale University and Microsoft Research, with most of the work done when the first author was an intern at Microsoft Research. The dataset contains human demonstrations and feedback to enhance the factual consistency of summarization models. Three new NLP tasks are proposed: summary editing, feedback generation, and automatic factual error correction. The dataset includes 2.5k data points, with 70% containing factual errors. Human-edited summaries receive higher automatic factual accuracy scores compared to initial system outputs but have lower textual overlap with reference summaries. The dataset also provides valuable annotations for training factuality metrics and evaluating factuality metrics.</sample>
    <sample id="78">Ja, es existiert eine Varianz in den Vereinfachungsverfahren. In DEplain-apa sind die Reorganisierungen und Worteditionen stärker vertreten, während in Web mehr Redeformulierungen vorkommen.</sample>
    <sample id="79">Ja, es ist öffentlich verfügbar.</sample>
    <sample id="80">Das Wasserzeichen wird in den Text über einen Prozess namens 'Watermark Injection' eingebettet. Hierbei wird ein Trigger-Set, eine Gruppe von Wörtern mit moderater Häufigkeit, verwendet. Wenn ein Benutzer eine Anfrage sendet, wird der Anbieter die Häufigkeit der Triggers in der Anfrage berechnen und das Gewicht des Zielsignals proportional zur Häufigkeit der Triggers anpassen. Der berechnete Embedding ist eine Gewichtsummation des Zielsignals und des ursprünglichen Embeddings.</sample>
    <sample id="81">The authors belong to the Peking University.</sample>
    <sample id="82">The video discusses a new framework for unsupervised automated essay scoring (AES) that uses multiple heuristics to generate pseudo ground-truth scores and train a neural AES model. The proposed framework, called URRA, contains a heuristics-assess ranking module (HERM) and a deep pairwise rank aggregation module (DPRAM). HERM generates partial order pairs by ranking essays according to different heuristics, while DPRAM aggregates these pairs into a unified supervision signal. Experiments on both transductive and inductive settings demonstrate that URRA outperforms unsupervised baselines with significant improvements.</sample>
    <sample id="83">Ja, Encoder-Decoder-Modelle wie mt5 können durch Training mit einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="84">The speaker discusses the development of a framework for dynamic neural networks, which can adapt their architecture and parameters based on input. They compare traditional static networks to dynamic ones, highlighting the benefits of dynamic networks but also the challenges due to excessive parameter usage. The speaker proposes a method to partition parameters into dynamic and static ones, using scale factors to control the intensity of each mode. This approach results in better performance with fewer parameters and less computation compared to fully dynamic networks. The speaker also mentions future work on extending this method to other types of networks and hardware structures.</sample>
    <sample id="85">Eine Beispiel für eingeschränkte Sprachplanung ist die Erstellung von Kochrezepten mit bestimmten Bedingungen, wie zum Beispiel die Erstellung von einem Schokoladenkuchen.</sample>
    <sample id="86">Sie visualisieren die Einbettungen von Sätzen auf der Figur BPCA, um zu zeigen, dass es schwierig ist, die Backdoor-Einbettungen von normalen Einbettungen zu unterscheiden.</sample>
    <sample id="87">Die Arbeit bestehende PLMs verwendet die gleiche Datensammlung, um ein neues PLM aufzubauen.</sample>
    <sample id="88">GPT-4 ist am wenigsten auf Indien ausgerichtet.</sample>
    <sample id="89">Ein Beispiel, das zeigt, wie das Modell das Wissen nutzt, das durch den Aufmerksamkeitsmechanismus gelernt wurde, zeigt die Kruz-Attention-Weights.</sample>
    <sample id="90">The paper discusses the feasibility of using language learners as annotators for natural language processing (NLP) data annotation. The authors conducted a proof-of-concept study to examine the accuracy and learning effects of using language learners compared to native speakers. They recruited 120 language learners and conducted experiments with three languages: English, Korean, and Indonesian. The results showed that language learners' annotations are nearly accurate, especially for simpler tasks and easy to medium level questions. Additionally, language learners can almost match the performance of native speakers when their labels are aggregated by majority voting. The paper also suggests that training simulations with learners' annotations can outperform models trained with native speakers' labels. Overall, the paper demonstrates the potential of using language learners as annotators for NLP research, particularly in low-resource languages where it is difficult to recruit native speakers.</sample>
    <sample id="91">Die Anzahl der Aufgaben hat einen positiven Einfluss auf die Leistung des Modells.</sample>
    <sample id="92">Die Autoren vergleichen ihre Methode mit drei Baselines auf dem CoNLL Benchmark: (1) BERT, (2) RoBERTa, und (3) XLNet.</sample>
    <sample id="93">Die beiden Co-Autoren sind dem ersten Autor als Berater zugeordnet.</sample>
    <sample id="94">The speaker introduces a paper titled "Paper: Are You Copying My Model? Protecting the Copyright of Large Language Models for Embedding and Services" by Jing Wei from the University of Science and Technology of China. The paper discusses the need to protect the copyright of embedding services, which are built upon large language models like GPT, LLaMA, and PaLM. The paper proposes a backdoor-based watermark method called Embedding Marker that is applicable to embedding services and can detect whether another service contains the watermark. The paper also validates the covertness of the provided embedding by visualizing the embeddings of sentences on four datasets.</sample>
    <sample id="95">Avi Lillard</sample>
    <sample id="96">Hallo, ich bin Jenny, ein erstes Jahr PhD-Studentin an der Carnegie Mellon University. Heute präsentiere ich das Werk "NL Positionality: Characterizing Design Bias via Human Data Sets and Models" in collaboration mit Forschern an der University of Washington und dem Allen Institute for AI (Sebastian Santi, Roman Lobraz, Katrina Rynica und Martin Sapp). Das Werk handelt von Systematischen Leistungsunterschieden technologischer Werkzeuge zwischen Bevölkerungen. Designbiases können durch die Positionalität der NL-Forscher und Modellentwickler entstehen. Positionalität ist die Perspektive, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen halten. Forscher können dadurch Entscheidungen treffen, die die Leistungen technologischer Werkzeuge beeinflussen. Ein Beispiel für ein Designbiast ist die Sensitivität von Perspektive API für die Erkennung von toxicen Inhalten. Perspektive API ist gut in den USA, aber nicht in Indien. Das Werk zeigt, dass Modelle und Datensätze aggregieren Urteile und Meinungen von Menschen und können bestimmte Positionalitäten über andere verfolgen. Um die Positionalität von Datensätzen und Modellen zu studieren, re-annotieren wir Datensätze mit diversen Annotatoren. Wir vergleichen dann die Annotierungen mit dem Demografie und den Modell- und Datensatz-Leistungen. Unsere Studie hat über 16.000 Annotierungen von über 1.000 Annotatoren aus 87 Ländern erfasst. Wir haben festgestellt, dass Datensätze und Modelle eine Positionalität aufweisen. Zum Beispiel sind Datensätze und Modelle am besten auf englischsprachige Länder ausgerichtet. Wir haben auch festgestellt, dass Datensätze und Modelle Menschen mit College- oder Universitätsausbildung bevorzugen. Allerdings werden bestimmte Bevölkerungen unberücksichtigt, beispielsweise nicht-binäre Menschen im Vergleich zu Männer und Frauen. Um die Positionalität in NLP zu reduzieren, empfehlen wir, relevante Designentscheidungen zu notieren, NLP-Forschung mit einem Blick auf Perspektivismus zu betreiben und spezialisierte Datensätze und Modelle für bestimmte Gemeinschaften zu erstellen. Ein Beispiel hierfür ist die Musakani-Initiative. Inklusive NLP soll nicht nur sicherstellen, dass alle Technologien für alle arbeiten, sondern auch sicherstellen, dass sie für alle fair sind.</sample>
    <sample id="97">Die Referentin spricht von zwei Problemen der aktuellen SimulST-Modelle: spezifischen Architektur-Modellen und komplexen Trainingverfahren.</sample>
    <sample id="98">Die Reduktion sozialer und politischer Verzerrungen in Datensätzen beim Training von NLP-Modellen ist ein komplexes Problem, das durch die Sanierung der Datensätze schwierig zu bewältigen ist. Es existieren keine einfachen Lösungen, um zu bestimmen, was als neutrales Datensatz gilt, und es besteht das Risiko von Censorship oder Exklusion, wenn versucht wird, die Datensätze zu sanieren.</sample>
    <sample id="99">Die Präsentation beginnt mit einer Einführung in das Werk der Forscherin C. Wu, die von Fudan University stammt. Sie präsentiert ein Werk, das die Unterscheidung zwischen Skriptkenntnis und Sprachmodellen für die Planung in Alltagssituationen untersucht. In Alltagssituationen planen Menschen oft durch die Folge von Schrittebeteiligtenintraktionen in Form von Skripten. Vorherige Arbeiten haben gezeigt, dass Sprachmodelle in der Lage sind, abstrakte Ziele von stereotypischen Aktivitäten zu planen, wie zum Beispiel das Brotbacken. Es wurde gezeigt, dass große Sprachmodelle effektiv in der Lage sind, Ziele in Schritte zu zerlegen. Allerdings haben vorherige Arbeiten hauptsächlich auf die Planung abstrakter Ziele von stereotypischen Aktivitäten abgelaufen, nicht aber auf die Planung spezifischer Ziele mit bestimmten Bedingungen, wie zum Beispiel das Backen eines Schokoladenkuchens. In diesem Papier wird das Problem der eingeschränkten Sprachplanung definiert, bei dem verschiedene Bedingungen auf die Planung angewendet werden. Ein abstraktes Ziel kann durch verschiedene real-life spezifische Ziele mit mehrfachen Bedingungen erweitert werden. Ein guter Planer sollte Skripte erstellen, die both reasonable and faithful to constraints. In diesem Papier werden zuerst die eingeschränkten Sprachplanungsfähigkeit von großen Sprachmodellen evaluiert und verbessert. Da keine Datensammlung von spezifischen Zielen existiert, um die Studie zu unterstützen, müssen diese Ziele zuerst erworben werden. Im Tabellentitel werden die abstrakten Ziele mit mehrfachen Bedingungen für Menschen im Lernprozess erweitert. Eine Stichprobe von 100 spezifischen Zielen wird gewählt und die resultierenden Skripte von großen Sprachmodellen werden bewertet. Das Tabellentitel berichtet über die allgemeine Genauigkeit der Ergebnisse. Es wird festgestellt, dass alle großen Sprachmodelle unzufriedenstellende Resultate auf der Planung spezifischer Ziele erzielen. Danach wird eine detaillierte Analyse durchgeführt, um die Ursachen für die schlechten Resultate zu untersuchen. Das Diagramm zeigt, dass die semantische Komplettät der generierten Skripte akzeptabel ist, aber die Treue zu den Bedingungen nicht gewährleistet werden kann. Die Bedingungen werden in mehreren topologischen Kategorien unterteilt, und die Performance von Instruct GPT-3 wird für Ziele in verschiedenen Kategorien untersucht. Vorherige Studien haben gezeigt, dass die Ausgabequalität von großen Sprachmodellen in einem hohen Varianz liegt, was zu schlechter Performance führt. Um die Ausgabequalität zu verbessern, wird die Idee des "Over-generated" Filter verwendet. Zunächst werden die verschiedenen Typen von Bedingungen mit Beispielen für Instruct GPT-3 erläutert und spezifische Ziele basierend auf den abstrakten Zielen erstellt. Dann werden die generierten Skripte von Instruct GPT-3 für spezifische Ziele übergeneriert. Eine Filter-Modelle wird dann verwendet, um die passenden Skripte zu selectieren. Die Skripte werden in Instruct GPT-3 embeddings konvertiert und die semantische Ähnlichkeit wird mittels Cosinus-Similarität gemessen. In addition, the script containing the keywords of the target constraint is only kept if the target goal score is the highest in the goal set. With our method, Instruct GPT-3 can generate scripts of higher quality. Our method greatly improves the planning ability, both in semantics completeness and faithfulness to the constraint. Since large language models are costly to deploy, it is essential to enable language planning ability of smaller and specialized models. Creating datasets is an essential step towards this end. However, previous studies do not enable planning for specific goals, and manual manual dataset annotation is expensive. Thus, we follow the idea of symbolic knowledge distillation to distill constrained language planning datasets from large language models. We apply our method for building a dataset of constrained language planning, named as CoScript. In total, we generate 55,000 specific goals with scripts to ensure the quality of validation and test sets. We ask crowdsourced workers to find and revise the incorrect samples. This figure shows the constrained distribution of CoScript. We find CoScript shows high productivity in the generated specific goals. With CoScript, we can train smaller but specialized models for constrained language planning. We find that T5 fine-tuned on CoScript can generate scripts of higher quality than most large language models, indicating that smaller models can surpass large large larger models when properly trained on suitable datasets. In summary, we establish the constrained language planning problem. We evaluate the constrained language planning ability of large language models and develop an over-generated filter method for large language models. We use large language models to generate a high-quality script dataset, CoScript, for constrained language planning. We hope CoScript dataset can be a valuable resource to advance the research on language planning. Thanks for your time. Please find more details of CoScript in our paper.</sample>
    <sample id="100">The speaker introduces the concept of multi-hop QA, which involves answering questions that require multiple reasoning steps. They explain how each step typically corresponds to a document in the corpus and use an example to illustrate this process. The speaker then discusses the challenges of training retrievers for multi-hop QA, including the need for large amounts of data and domain expertise. They introduce their approach, called PromptRank, which combines unsupervised retrieval with few-shot language model-based reranking. The main steps involve retrieving candidate chains using TF-IDF retrieval and hyperlink traversal, reranking these candidates using a few-shot language model, and constructing chain prompts to score each chain by the probability of the question given the chain prompt. The speaker also mentions additional techniques such as instruction search and instruction sampling to improve performance. The results show that PromptRank outperforms fully supervised systems and performs comparably to state-of-the-art multi-hop retrievers.</sample>
    <sample id="101">Die Sprachgewandtheit von PaLM ist vergleichbar mit den besten Systemen, aber es gibt noch Raum für Verbesserungen.</sample>
    <sample id="102">Die wichtigsten Eigenschaften eines Wasserzeichenverfahrens sind: es sollte anwendbar auf embedding services, die Watermark should not degrade the utility of the provided embeddings, die Watermark should be covert enough to the attacker or the attacker can remove the watermark easily, und die Watermark needs to be transferable to the attacker's services during the model extraction process.</sample>
    <sample id="103">Die englischen TED Talks wurden in 14 verschiedenen Sprachen übersetzt.</sample>
    <sample id="104">Ein Datensatz wird normalerweise über mehrere Annotatoren anhand der Demographics erneuert, um eine reiche Datensammlung zu erhalten.</sample>
    <sample id="105">Cosine and L2 similarity.</sample>
    <sample id="106">The speaker introduces a dataset called Ques, which consists of over 3,000 entity-seeking queries with implicit set operations. The queries contain multiple constraints or preferences, and the answer entities are verified for relevance to the query. The dataset poses a challenging retrievable problem since systems need to effectively search over a large document corpus to find multi-answer sets where the attribution for different query constraints can come from different parts of the document. The dataset is constructed by relying on Wikipedia category names from four domains of interest: films, books, plants, and animals. Set operations are performed over these atomic categories to get queries with set constraints. Human annotators paraphrase templatic queries, validate them for fluency and naturalness, and verify the relevance of entities in the answer set and mark evidence in the document as its attribution. The dataset is used to evaluate the effectiveness of systems for handling selective information needs with implicit set constraints.</sample>
    <sample id="107">Modelle, die auf einem mehrsprachigen Encoder basieren, wurden in diesem Aufgabe eingesetzt, um die beste Leistung auf allen neun Datensätzen zu erzielen. Sie wurden auch evaluiert und konnten durch Training in einer Mischung von verschiedenen Sprachen verbessert werden.</sample>
    <sample id="108">The speaker introduces a new approach to evaluating language models by revisiting the minimal pair paradigm. This method involves showing acceptable and unacceptable sentences to determine if the model assigns higher probabilities to the acceptable ones. The current MPP pipeline does not account for longer sentences, which are becoming more common in large language models. To address this, the speaker proposes simulating longer sequences by recreating sentences with acceptable or unacceptable structures from relevant datasets. This includes matching grammatical structures, using the same dataset, and even choosing unrelated domain sentences. The results show that MPP judgments are robust for arbitrary context lengths but vary significantly when using sentences from the same dataset or different subsets. The speaker concludes that language models are sensitive to latent syntactic and semantic features and that the current evaluation methods may not fully capture their abstract knowledge across the context window.</sample>
    <sample id="109">The paper presents a dataset of natural language instructions and their corresponding inputs and outputs, collected in a fully automatic manner without any human annotations. The dataset contains 64K examples, with an additional 240K examples when considering instruction paraphrases. The generated examples are evaluated for correctness, creativity, and diversity, with more than 50% of the generated examples being correct and containing valuable information for instruction tuning. The paper also shows that training on the Natural Instructions dataset outperforms a baseline on all benchmarks, even when the cost of generating examples is amortized.</sample>
    <sample id="111">Die Autoren können eine allgemeine Textkorpora sammeln und die Häufigkeit jedes Wortes therein zählen, um festzustellen, welche Wörter mit mittlerer Häufigkeit sind.</sample>
    <sample id="112">Hallo, alle. Mein Name ist Zhu Heng. Heute werde ich unsere Papier präsentieren: "Do Conll 2003 named entity taggers still work well in 2023?" Lassen Sie uns beginnen. Unser Papier untersucht das Problem der allgemeinisierten Named Entity Recognition (NER) Aufgabe, auch bekannt als NER Aufgabe. Wir beobachteten, dass Modelle seit fast 20 Jahren Conll 2003 verwendet haben, um NER zu entwickeln, und dies natürlicherweise führt zu mehrere Probleme. Zunächst einmal können diese Modelle auf modernes Datendaten allgemeinisieren? Und wenn wir neue Tagger erstellen, was ist für eine gute allgemeinisierte Notwendig? Gleichzeitig, wenn wir eine schlechtes allgemeinisieren beobachtet, was verursacht die Leistungsabnahme dieser Modelle? Um diese Probleme zu untersuchen, haben wir den Conll Plus Plus Datensatz entwickelt. Dies ist ein Datensatz, den wir aus Reuters-News von 2020 erfasst und mit den gleichen Conll 2003 Annotierungsempfehlungen annotiert haben. Wir haben dann über 20 Modelle an Conll 2003 optimiert und sie auf sowohl den Conll 03 Testset als auch den Conll Plus Plus Testset evaluiert. Und letzt but not least, wir haben die prozentuale Änderung in F1 berechnet, um die allgemeinisierte Leistung jedes Modells zu messen. Also, was ist für eine gute allgemeinisierte Notwendig? Unsere Experimente haben gezeigt, dass es drei Hauptingredients gibt, die benötigt werden. Der Erste ist die Modellarchitektur. Unsere Experimente haben gezeigt, dass Transformer-Modelle normalerweise besser auf neue Daten allgemeinisieren. Der Zweite Einzel ist die Modellgröße. Wir haben festgestellt, dass normalerweise größere Modelle zu besseren allgemeinisierten führen. In last but not least, wir wissen alle, dass die Anzahl der Optimierungsbeispiele direkt auf die Leistung der Downstream-Aufgabe wirkt. Hier haben wir auch festgestellt, dass mehr Optimierungsbeispiele tatsächlich auch zu besseren allgemeinisierten führen. Unsere nächste Frage war, was verursacht die Leistungsabnahme einiger Modelle? Wir hatten zwei Hypothesen. Der Erste ist adaptive Overfitting, das ist Overfitting, das durch das Wiedervereinben des gleichen Testsets über und über manifestiert wird und normalerweise als die Diminution Returns auf einem neuen Testset manifestiert wird. Der Zweite Hypothese ist temporal Drift, das ist die Leistungsdegeneration, die durch die zunehmende Temporalabstand zwischen dem Train und dem Test-Dataset verursacht wird. Für adaptive Overfitting haben wir gesehen, dass vom Grafik auf der rechten die rote "best fit" Linie eine Gradient hat, die größer als 1 ist. Das bedeutet, dass jede Einheit der Verbesserung, die wir auf Conll 2003 erreichten, zu mehr als einer Einheit der Verbesserung auf Conll Plus Plus führt, was bedeutet, dass es keine Diminution Returns gibt. Und das zeigt uns, dass adaptive Overfitting in diesem Fall nicht beobachtet wird. Also, was ist mit temporal Drift dann? Für temporal Drift haben wir ein Experiment durchzuführen, um die Erneuerung oder die fortlaufende Pretraining einiger Modelle mit recent data zu überprüfen. Und wir haben festgestellt, dass die Leistungsdegeneration mit einem größeren Temporalabstand eintritt. Und das bestätigt unsere Hypothese, dass die Hauptursache der Leistungsabnahme die temporal Drift ist. Unsere Schlussfolgerung lautet, dass für eine gute allgemeinisierte Leitlinie wir einen besseren Modellarchitektur, größere Modellgröße und mehr Optimierungsbeispiele benötigen. Und diese Goalse hand in hand wir können einfach nur ein Ingredient haben, aber die anderen. Gleichzeitig haben wir auch festgestellt, dass die Leistungsabnahme hier durch temporal Drift verursacht wird und kind of surprisingly ist es nicht durch adaptive Overfitting verursacht, obwohl Conll 2003 seit über 20 Jahren verwendet wurde. Also, zurück zu der Frage, die wir im Titel unseres Papiers gestellt haben: "Do Conll 2003 taggers still work in 2023?" Und wir haben festgestellt, dass die Antwort eine resounding Ja ist. Wir hoffen, unser Papier inspiriert weitere Forschungen darüber, wie man die allgemeinisierte Leitlinie der Modelle verbessern kann. Und letzt but not least, bitte machen Sie sicher, sich an unser Papier, our dataset und falls Sie Fragen haben, sich gerne zu kontaktieren. Vielen Dank so viel.</sample>
    <sample id="114">The speaker introduces a new method for pruning large language models, focusing on the heavy parameter problem. They propose a group head attention strategy using a divide-and-conquer approach to compress multi-head attention. This method involves two stages: group constraint training and voting-to-stay algorithm. The first stage divides attention heads into groups, making intra-group heads more similar and inter-group heads more separate. The second stage prunes heads with low votes, retaining only one head per group. This approach achieves significant parameter compression while maintaining performance on tasks like machine translation, language modeling, and abstract summarization.</sample>
    <sample id="115">Die Sprachsegmentgröße wird auf Lambda-Speech-Frames festgelegt.</sample>
    <sample id="116">Die Wahrnehmung von Servin als Richter und Kea als Bäcker.</sample>
    <sample id="117">Der wichtige Faktor zwischen der Qualität des Beispiels und der Ähnlichkeit mit dem Ausgangssatz ist die Qualität des Beispiels.</sample>
    <sample id="118">The presentation introduces the ACAL 2023 submission, which focuses on improving pre-training techniques for code-switched NLP. The speaker defines code-switching and provides an example of a code-mixed sentence in English and Hindi. They highlight the importance of building computational models for code-switching tasks, as multilingual pre-trained models like MBERT and XLM-R do not perform well on such tasks. The main contributions of the work include proposing novel MLM techniques tailored to code-switching, architectural changes, and auxiliary losses. The speaker explains the concept of switch points and proposes methods like switch-MLM, frequency-MLM, and residual connections with layer probing techniques to increase the amount of switch point information in the final layer. The results show that the proposed methods outperform standard MLM on sentiment analysis tasks. The presentation also discusses linear and conditional probing experiments to verify the claim about switch point information. The speaker concludes by summarizing the proposed new MLM objective and architectural changes motivated by the results.</sample>
    <sample id="119">Die Arbeiten in den erweiterten Experimenten konzentrieren sich auf Sprachmodelle mit verschiedenen politischen Neigungen.</sample>
    <sample id="120">Das Modell verwendet Aufmerksamkeitswerte aus einer bestimmten Ebene.</sample>
    <sample id="121">Beispiele für direkte Inferenz sind "the name of the song easy on me" oder "its position, the first one."</sample>
    <sample id="122">Die Autoren gehören an Fudan University.</sample>
    <sample id="123">The research presented in the video focuses on improving multi-modal zero-shot learning through instruction tuning. The researchers, named E and J, explore the effectiveness of instruction tuning on large language models for various downstream tasks, including computer vision and multi-modal tasks. They address the lack of publicly available multi-modal instruction datasets and introduce Multi-Inst, a multi-modal instruction tuning benchmark dataset consisting of 62 diverse multi-modal tasks from 21 existing open-source datasets. The dataset includes five expert-written instructions for each task. Using OFA, a unified multi-modal pre-trained model, they evaluate the performance of instruction tuning on their proposed dataset, reporting improvements in accuracy, ROUGE-L, and sensitivity metrics. The results show that instruction tuning can significantly enhance the performance of OFA on unseen multi-modal tasks, with better performance and lower sensitivity as the number of tasks increases. The researchers also demonstrate the benefits of transfer learning from natural instruction datasets, which can further improve the model's performance and sensitivity.</sample>
    <sample id="124">The speaker introduces the Temp Reason dataset, which covers all three levels of temporal reasoning and long temporal coverage. The dataset is evaluated in three QA problem settings: closed book, open book, and reasoning QA. The speaker proposes a training strategy with two main components: temporal span extraction pre-training and time-sensitive reinforcement learning. The results show that the proposed Temp 5 model significantly improves the performance of T5-SFT and Temp 5 in OB QA and Reason QA settings.</sample>
    <sample id="125">Die englische Version des Textes zeigt, dass die Anzahl der Autoren an der Arbeit beteiligt ist.</sample>
    <sample id="126">Ja, die Übersetzung der natürlichsprachlichen Anfrage mit Hilfe eines maschinellen Übersetzungsmodells wurde als Baseline betrachtet.</sample>
    <sample id="127">The speaker introduces a method for transferring the reasoning abilities of large language models to smaller models. The method involves using large models to generate step-by-step solutions for complex tasks, which are then used as training data for smaller models. The speaker also proposes a novel technique called diverse reasoning, which generates multiple solutions using stochastic temperature sampling. The speaker compares their method with existing baselines and finds that it achieves notable performance on many tasks, especially text-based ones. The speaker also discusses the scalability of the method and the trade-offs involved in development and inference costs.</sample>
    <sample id="128">This paper presents a diagnostic test suite for evaluating knowledge integration in natural language understanding (NLU) models. The authors propose a co-reference resolution task to assess the ability of models to integrate knowledge from different sources, including pre-trained and inference-time knowledge. They define three settings: background pre-training, background both, and background inference. Experiments show that even the best-performing models struggle to reliably integrate background knowledge presented only at inference time. The results suggest that many co-reference resolution models are unable to reason over knowledge from different sources without task-specific training.</sample>
    <sample id="129">Die Autoren haben als Beispiel für eine markierte Gruppe einen schwarzen Frau genommen.</sample>
    <sample id="130">Die Modellarchitekturen, die nicht gut generalisieren, sind diejenigen, die nicht auf Transformervorgaben basieren.</sample>
    <sample id="131">Die Testdatensätze heißen "clean validation data" und "clean samples".</sample>
    <sample id="132">Die Arbeit beteiligen zwei Autoren.</sample>
    <sample id="133">Die Autoren arbeiten mit mehreren Modalitäten, nicht nur mit Text.</sample>
    <sample id="135">In einem Vortrag präsentieren James Finch und Sarah Finch eine neue Methode zur Evaluierung von Dialogmodellen, die sie ABC-Eval nennen. Sie haben eine Methode entwickelt, um die Verhaltensfehler von Chatmodellen zu überprüfen, indem sie bestimmte Verhaltensmerkmale wie Irrrelevanz, Widersprüche und Fehlentscheidungen messen. Sie haben auch eine Analyse von vier hochwertigen Chatmodellen durchgeführt und festgestellt, dass ABC-EvalLabels in Bezug auf die allgemeine Dialogqualität prägnanter sind als bestehende Methoden.</sample>
    <sample id="136">The speaker, Jazan Alvan, presents his work on numerical reasoning conducted with his supervisor Neefisa at the University of Sheffield. He introduces a new evaluation set called Fermat, which tests models' performance in number understanding, mathematical operations, and training dependency. The baseline evaluation shows most models perform poorly, but fine-tuning with math teachers' templates improves results. The study highlights the importance of language and mathematical diversity in improving model performance.</sample>
    <sample id="137">The speaker introduces Tell to Design, a dataset for language-guided floor plan generation published in AIC 2023. The dataset focuses on the floor plan domain and aims to enable users to design by telling instructions with specific focus on the floor plan domain as the initial area of research. The task is defined as generating reasonable 2D floor plan designs that comply with the provided language instructions. The input is a set of natural language instructions that characterize the key components of the corresponding floor plan design, which includes semantics that specify the type and functionality of each room, geometry that specifies the shape and dimension of each room, and topology that describes the relationships among different rooms. The desirable output is a structured interior layout that aligns with the input language instructions. The dataset consists of 5,501 human-annotated language instructions collected from crowdsourcing platforms and around 76,000 language instructions generated artificially from predefined templates. The main challenges of this novel task are performing design generation under strict constraints compared with artwork like text conditional image generation, understanding the big picture of the entire floor plan from document-level structured text with fuzzy and entangled information, and handling ambiguous, incomplete, or misleading information in human instructions. The method uses a sequence-to-sequence model under the encoder-decoder framework where room bounding boxes are reconstructed into a structured target sequence. The model is initialized by a pre-trained language model T5 for better language understanding abilities and uses a normal language modeling objective where X is the set of instructions in natural language and Y is the target bounding box sequence and L is the target sequence length. The model achieves the highest Iou scores with a micro Iou of 54 and a macro Iou of 53, outperforming other text conditional image generation baselines by a large margin. This can be attributed to our sequence-to-sequence model in controlling the target box sequence generation based on the semantic information extracted from the language instructions. In contrast, text conditional image generation methods fail to perform well because those models are designed to generate artwork-like images with high-level visual concepts from short text instead of following multiple instructions with various constraints for specific design. When training only on artificial instructions while testing on human-written ones, our method cannot perform well, indicating there is a language distribution gap between artificial and human instructions. Nevertheless, when artificial instructions are used for warming up before training on human instructions, the performance of our method is significantly improved with over 10 Iou score increment. This suggests that despite the language gap, artificial and human instructions are mutually beneficial data portions during training.</sample>
    <sample id="138">Nach Ansicht der Autoren ist ein zu wenig erforschtes Gebiet im Bereich der NLU die Integrität von Kenntnis.</sample>
    <sample id="139">Die Referenten heißen Yin und Zhi Yang.</sample>
    <sample id="140">Ja, Coscript wurde von Cloudworkers überprüft.</sample>
    <sample id="141">Bestehende Ressourcen für kontextbasierte Übersetzung haben Grenzen, da sie nur bestimmte Typen von kontextbasierten Übersetzungen und bestimmte Sprachen unterstützen.</sample>
    <sample id="142">Hallo, ich werde über unser Projekt sprechen, das sich um die Resolution von indirekten Bezugssätzen für die Entity-Selektion bemüht. In diesem Projekt haben wir die Altentities-Korpus eingeführt. Mein Name ist Javad Hosseini und ich arbeite in collaboration mit Philipp Radlinski, Sylvia Parthie und Annie Lewis. Unsere Zielgruppe sind Benutzer, die ihre Sprache verstehen möchten, wenn sie Entscheidungen treffen möchten. Betrachten Sie beispielsweise die alternative Frage: "Bedeutest du 'Easy on Me' oder 'I Got a Feeling'? Hier muss der Benutzer zwischen zwei verschiedenen Liedern entscheiden. Der offensichtlichste Ansatz besteht darin, direkte Beziehungen zu verwenden, indem man den Namen des Liedes ('Easy on Me') oder seine Position (das Erste) erwähnt. Manchmal ist es jedoch besser, indirekte Beziehungen zu verwenden, um eine natürlichere Konversation zu ermöglichen. Dies kann passieren, wenn der Benutzer den Namen des Liedes nicht mehr kennt, die Aussprachen zu ähnlich sind, um zu diskutieren, oder wenn der Benutzer eine spezifische Präferenz machen möchte. Hier sind einige Beispiele für indirekte Beziehungen: 'Das jüngere Lied' oder 'Das Lied, das nicht energiegeladen ist'. Ein wichtiger Problemfall in conversational Systems und auch bei Benchmarking LLMs (Language Learning Models) ist die Verstehensfähigkeit von indirekten Beziehungen. Wir kennen noch keine öffentliche Datensätze auf große Skala für diese Aufgabe an. Daher haben wir einen Datensatz durch Crowd Annotation erstellt. Unser Datensatz deckt drei verschiedene Domänen ab: Musik, Bücher und Rezepte. Unsere Datensatzsammlungmethodologie betont Infomalität, indem sie einen Cartoon-Skript benutzt. Der Cartoon hat drei Sprachbubbles: In dem ersten Bubbles sagt Bob: 'Erinnere dich an das Lied, das wir gestern gehört haben.' Und mit dieser Kontexteinstelle sagt Bob im nächsten Bubbles: 'Bedeutest du 'Easy on Me' oder 'I Got a Feeling'?'. Im dritten Bubbles verwendet Bob eine indirekte Beziehung, um eine der beiden Entities zu selecting, z.B. 'Das jüngere Lied'. Wir liefern automatisch den ersten und den zweiten Sprachbubbles, aber den dritten Bubbles füllt der Notratter ein. Der erste Bubbles wird aus einer Handvoll manueller Anregungen pro Domäne gewählt. Der zweite Bubbles, der alternative question, wird wie folgt generiert: Wir verwenden immer einen einfachen Template: 'Do you mean A or B?' , wobei A und B aus Wikipedia abgeleitet werden. Hier sind einige Samplingmethoden, die wir verwenden: Wenn wir weiter auf der Liste sind, werden die Entities immer ähnlicher, was normalerweise schwieriger zu disambiguieren macht. Der erste Ansatz ist die uniform distribution. Der zweite Ansatz ist, wenn die Entities ähnliche Titel haben, z.B. zwei Bcher mit dem Titel 'Die Rettung'. Der dritte Ansatz ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben. Und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben, z.B. denselben Genres oder denselben Künstler für ein Lied. Wenn wir den Benutzern eine alternative question präsentieren, kennen sie den Namen der Entities, aber sie kennen sie nicht unbedingt als Entities. Also tun wir, dass wir ihnen etwas Hintergrundinformation über die Entities anzeigen. Für Lieder simply zeigen wir einen Google-Suchergebnislink zu dem Lied an und bitten die Notratter, das Lied zu hören und über es zu lesen. Hier zum Beispiel die Google-Suchergebnisse für 'Easy on Me'.Für die Rezepte und die Buch-Domäne zeigen wir einige Hintergrundtexte aus Wikipedia an.Für Rezepte zeigen wir auch die Bilder von Wikipedia an, damit die Notratter sehen können, wie sie aussehen. Dann bitten wir die Notratter, eine der Entities zu warten und sie mit drei bis fünf indirekten Bezugssätzen zu beschreiben. Hier sind einige Beispiele aus unserem Datensatz: 'Der Lied mit dem Pianomusik', 'Der Lied, das nicht Worte hat', 'Der Lied, das 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jährigen Jungen 12-jähr</sample>
    <sample id="143">Der Ansatz wird mit den bestehenden SimulST-Richtlinien wie dem Whitkey-Strategie und dem Lokal-Quotenansatz verglichen.</sample>
    <sample id="144">The authors belong to the University of Montreal.</sample>
    <sample id="145">The speaker's name is Jenny.</sample>
    <sample id="146">The speaker introduces a paper on the analysis of omission in dialog summarization, discussing the challenges and methods for detecting and correcting omissions in generated summaries. The paper presents an automatic method for producing omission labels and evaluates different model architectures using the proposed dataset. The results show that omission detection is a valuable task for improving summary quality.</sample>
    <sample id="147">Die Arbeit wird von drei Autoren betreten: Ersen Dermush, Dan Juravsky und Myra.</sample>
    <sample id="148">Hallo, ich bin Sarah Papi aus der Universidad de Toronto und Fundación Bruno Kessler. Ich werde kurz die Aufmerksamkeit auf ein Werk als Leitstelle für Simultane Sprachübersetzung lenken. Das ist ein gemeinsames Werk mit Matteo Negri und Marko Turki. Was ist Simultane Sprachübersetzung? Simultane Sprachübersetzung (oder SMT) ist die Prozess von Übersetzen gesprochenem Sprachen in Text in einer anderen Sprache in Echtzeit, indem es krußsprachliche Kommunikation ermöglicht. Und was sind die Probleme der aktuellen SMT-Modelle? Spezielle Architekturen werden oft trainiert, indem zusätzliche Module optimiert werden. Längen und komplexen Trainingverfahren, zum Beispiel Training, das verschiedene Optimierungsziele umfasst, und Training und Wartung mehrerer Modelle, um verschiedene Latenzregimes zu erreichen, zum Beispiel Training eines Modells mit einem Durchschnittslatenz von 1 Sekunde und ein anderes Modell mit 2 Sekunden Latenz usw. Also, was ist unsere Lösung? Zunächst verwenden wir schon existierende offene NLP-Modelle, ohne sie zu trainieren oder spezielle Architekturen für SMT zu adoptieren. Wir verwenden nur ein Modell für jede Latenzregel und handeln Latenz durch spezifische Parameter durch. Und wir nutzen die Kenntnisse, die das Modell durch den Ablenmechanismus zwischen Audio-Eingabe und Textausgabe gewonnen hat, um die Übersetzung zu optimieren. Hier ein Beispiel auf der rechten Seite. Unsere Lösung ist die Vorgeschlagene Ablenmethode (Encoder-Decoder Ablenmethode) und es ist eine Strategie, bei der wir entscheiden, ob wir einen teilweise Übersetzung ausstoßen oder nicht, basierend auf, wo die Ablenpunkte aufwarten. Ein Wort wird ausgestoßen, wenn die Ablen nicht konzentriert sind, das heißt, wenn die Summe unter einem bestimmten Schwelle α liegt, in den letzten Lambda-Speech-Frames. Das bedeutet, dass die empfangene Information stabil genug ist. Zum Beispiel, wenn wir erhalten haben: "Ich werde über etwas sprechen" und unser Modell die Übersetzung in Deutsch vorhersagt, dann schauen wir uns die Ablenwerte an. Wir sehen, dass die ersten zwei Worte auf die ersten erhaltenen Speech-Frames hinweisen, während die letzte Worte auf die letzten erhaltenen Speech-Frames hinweisen, also auf die Lambda-Speech-Frames. Das bedeutet, dass die ersten zwei Worte ausgestoßen werden. Da die Summe der Ablenwerte über einem bestimmten Schwelle α liegt, werden wir die letzte Worte nicht ausstoßen und warten auf einen neuen Speech-Schank. Wenn wir fortfahren und einen neuen Speech-Schank erhalten, und unser Modell weitere drei Worte vorhersagt, dann schauen wir uns die Ablenwerte an. Wir sehen, dass keines der Worte auf die letzten Lambda-Speech-Frames hinweist. Das bedeutet, dass diese drei Worte ausgestoßen werden. Wenn wir die Hauptergebnisse der Ablenmethode betrachten, plotten wir die Simultane Sprachübersetzungsergebnisse auf Grafiken, in denen wir auf der linken Seite blau sehen, wie hoch die Übersetzungqualität ist, und auf der rechten Seite die durchschnittliche Latenzmesszahl, die die Latenzmesszahl ist. Wir berücksichtigen auch die durchschnittliche Reaktionszeit, die die modell-basierte Reaktionszeit berücksichtigt. Wir wollen, dass unsere Kurve so hoch wie möglich auf dieser Achse ist, aber wir wollen auch, dass sie links verschiebt ist. Und wir vergleichen sie mit anderen Strategien, die auf offene Modelle angewandt wurden, wie der White-Ki-Strategie und dem Lokalqualifikationsansatz. Und wir vergleichen auch mit den state-of-the-art-Architektur speziell für Simultane Sprachübersetzung. Hier sind die Ergebnisse der Simultane Sprachübersetzung-Strategie auf Deutsch. Und wir sehen, dass die Ablenmethode alle Strategien übertrifft, die auf offene Modelle angewandt wurden, da die Kurven links verschieben sind. Und wir sehen auch, dass wenn wir die tatsächliche Laufzeit oder die durchschnittliche Reaktionszeit berücksichtigen, die Ablenmethode die schnellste Strategie ist. Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unser Papier und wir haben auch Open-Source-Code und Modelle und Simultane Auswertungen freigegeben, um die Wiederholbarkeit unseres Werks zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="149">Ja, der Datensatz ist öffentlich zugänglich.</sample>
    <sample id="150">The paper presents a new dataset called Meeting Q&amp;A, which consists of questions asked by participants in meetings and their corresponding answers. The dataset is unique because it includes long documents that are often domain-specific and information-rich. The paper also introduces a variety of methods for question answering, including short context models, single span models, and multi-span models. The results show that existing QA models struggle to identify rhetorical questions and predict the speaker who answered a question, especially in zero-shot settings. Overall, the paper highlights the challenges of existing QA models in both fine-tuned and zero-shot settings and suggests that more research is needed to improve QA performance on this dataset.</sample>
    <sample id="151">Hallo, alle. Mein Name ist Eing und mein Kollege Jieyang und ich präsentieren heute unsere Forschung zu Multi-Instruct: Eine Methode zur Verbesserung von Few-Shot-Lernprozessen durch die Optimierung der Anweisungen für große Sprachmodelle. Mit Fortschritten in großen Sprachmodellen haben viele Arbeiten begonnen, neue Lernparadigmen zu untersuchen, bei denen wir große Sprachmodelle für verschiedene unternehmensnahe Aufgaben in einem effizienten und datenarmen Weise verwenden. Kürzlich haben viele Studien gezeigt, dass die Optimierung der Anweisungen große Sprachmodelle dazu bringt, auf Einfachstelle Aufgaben in einem Few-Shot-Muster zu bewältigen, indem sie natürliche Anweisungen folgen. Allerdings haben die meisten vorherigen Arbeiten sich hauptsächlich auf die Verbesserung der Few-Shot-Performanzen auf Sprachonly-Aufgaben konzentriert, während Computer Vision- und Multi-Muster-Aufgaben weggelassen wurden. Daher zielen wir in dieser Arbeit an, zu überprüfen, ob die Optimierung der Anweisungen auf Multi-Muster-Trainingsmodelle tatsächlich die allgemeinere Anpassung an Einfachstelle Multi-Muster-Aufgaben verbessern kann. Darüber hinaus haben wir bei unserem Forschungsbeginn festgestellt, dass es eine erhebliche Lücke im Verfügbarkeitsspektrum von Anweisungsdatensätzen zwischen NLPA und Multi-Muster gibt. Es existieren mehr als 1600 Sprachonly-Anweisungs Aufgaben, aber es gibt keinen großen öffentlich zugänglichen Datensatz für Multi-Muster-Anweisungs Aufgaben. Das motiviert uns, einen Datensatz für die Optimierung der Anweisungen auf Multi-Muster-Modelle zu erstellen. Hier präsentieren wir Multi-Instruct, den ersten Datensatz für die Optimierung der Anweisungen auf Multi-Muster-Modelle, der 62 diverse Aufgaben umfasst, die 10 Hauptkategorien abdecken. Diese Aufgaben werden aus 21 bestehenden offenen Quellens Datensätzen abgeleitet und jedes Aufgaben ist mit 5 expert-generierten Anweisungen ausgestattet. Um die Optimierung der Anweisungen auf Multi-Muster-Modelle auf unserem Datensatz zu untersuchen, verwenden wir den OFA (Unified Multi-Modal Pretraining Model) als Basismodell. OFA verwendet eine einheitliche Vokabularie für Sprache, Bildtokens und Koordinaten vonBounding Boxes. Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instruct-Datensatz an. Um die einheitliche Verarbeitung von verschiedenen Input- und Output-Datentypen zu gewährleisten, folgen wir dem Ansatz von OFA und formulieren alle Aufgaben in einem einheitlichen Format von Sequenz zu Sequenz, in dem die Eingabe-Texte, Bildeingabe, Anweisungen undBounding Boxes in einem tokenraum dargestellt werden. Okay, nun werde ich über die Optimierung der Anweisungen auf Multi-Muster-Modelle sprechen. So für die Trainingsdatenbank verwenden wir 53 Aufgaben aus dem NLP Gruppe für die Training und wir sampling 10.000 Instanzen pro Aufgabe. Für die Testphase reservieren wir die gesamte Commonsense Reasoning Gruppe für die Testphase und wir select additional 5 Aufgaben aus dem WikiQA und den Misconceptions Gruppe. Wir verwenden alle Instanzen in der Testsplit für jede Aufgabe. In addition wir randomly sampling 20 Aufgaben aus der Testsplit des Natural Instruction Datensatz als unsichere Aufgaben für NLP. Also verwenden wir einen voreinzelten OFA-Large-Modell als Basismodell. During Training wir mix all die Instanzen für alle Aufgaben. Jede Instanz wird zufällig kombiniert mit einem von 5 Anweisungen Template. Also during Test für jede Aufgabe wir conduct a total of 5 experiments by evaluating the Modell using 1 von den 5 Anweisungen in each experiment. Wir report the min and max performance and the standard deviation of the performance across all five experiments. If the task is a Multi-Muster-Klassifizierungs Aufgabe wir report accuracy. If it's a Multi-Muster-Generation Aufgabe wir report ROUGE-L. For NLP Aufgaben wir report ROUGE-L as well. We also introduced a additional evaluation metric called sensitivity. This measures the Modell's ability to consistently produce the same outputs for the same task regardless of slight variation in the wording of the instruction. Here are our main results. As we can see, Anweisungs Optimierung kann signifikant verbessern der OFA-Performance auf Einfachstelle Multi-Muster Aufgaben. Auch Transfer Learning von Natural Instruction Datensätzen kann die Anweisungs Optimierung benefited. Hier wir sehen, als die Anzahl der AufgabenIncreases die Modell erreicht Better Performance und in meantime Lower Sensitivity. So wir auch die 1 experiment wir use one Anweisung versus 5 Anweisungen. As we can see, using more Anweisungen can improve the Modell's overall performance and reduce its sensitivity a lot. So this shows the effect of different fine-tuning strategy on the model's sensitivity. As we can see, by transfer learning from Natural Instruction Datensätzen, the Modell can achieve much better sensitivity compared to the original OFA-Modell. We also can see transfer learning from Natural Instruction Datensätzen can help OFA to achieve much better performance on the Natural Instruction Datensatz. So overall wir propose the first large-scale Multi-Muster-Optimierung Datensatz which significantly improves the few-shot capability of OFA and we explore different transfer learning technique and show their benefits. We design a new metric called sensitivity. So one more thing, wir are collecting a much larger Multi-Muster-Optimierung Datensatz with around 150 additional vision-language tasks and we will release them soon. This is the GitHub code for our data and model. Thank you.</sample>
    <sample id="152">The presentation introduces the work of Frederic Rymensnijder and his team at the intersection of NLP and classical philology. They present a new language model designed specifically for classical philology, with goals to make existing models comparable, push the state of the art further, explore different model architectures, and introduce multilingual models. The team has pre-trained two monolingual models for ancient Greek, Grecberta and Greater, and two multilingual models, Philberta and Philter, pre-trained on ancient Greek, Latin, and English data. They have also developed a high-quality pre-training corpus from the Internet Archive. The team has benchmarked their models against previous models and analyzed their performance in speech tagging, dependency parsing, and lemmatization tasks. They have also investigated the semantic and world knowledge capabilities of their models and found that they outperform previous models. Overall, the presentation highlights the development of powerful language models for classical philology that can process both Latin and Greek texts using the same model.</sample>
    <sample id="153">The speaker, Ninarah Emrahabi, is a postdoctoral scientist at Amazon Alexa AI's Responsible AI team. She presents their work on resolving ambiguities in text-to-image generative models. The team studies existing ambiguities in prompts provided to text-to-image models and proposes frameworks to mitigate these ambiguities and evaluate the faithfulness of generated images to user intentions. They curate a benchmark dataset covering different types of ambiguities and use a language model to generate clarifying questions or possible visual setups. Users interact with the system to provide answers that satisfy their intended interpretation, resulting in disambiguated prompts. An automatic evaluation framework uses a VQA model to assess whether the generated images are faithful to user intentions. The paper shows positive effects of disambiguation on faithful generation and agreement between the automatic and human evaluation frameworks.</sample>
    <sample id="154">Die Autoren sind an der University of Trento und Fondazione Bruno Kessler.</sample>
    <sample id="155">Javah Hosaini</sample>
    <sample id="157">The speaker introduces a dialogue summarization method using a static-dynamic structure fusion graph. The method involves encoding utterances into vector representations, constructing a static graph, and using a dynamic graph module to capture semantic relationships between utterances based on their deep vector representation. The final summary is generated by fusing the static dialogue structure and the dynamic learned dialogue structure.</sample>
    <sample id="158">The speaker introduces a dual cache system for long documents, which uses a local and global cache to store local and global entities respectively. The system evaluates the frequency of new or updated entities and adds them to the appropriate cache. The dual cache system outperforms single cache methods and significantly reduces cache misses, making it more cost-effective.</sample>
    <sample id="159">Hallo, alle. Ich bin Koustos Sinha und ich freue mich, Sie willkommen zu unserem Talk über unser ACL 2023 Papier "Language model acceptability judgments are not always robust to context". Das ist ein gemeinsames Werk mit John Goldacre, Aaron Mueller, Kanishka Mishra, Garen Fenton, Roger Levy und Adina Villamizar. In diesem Werk revisitieren wir die Minimal Pair Paradigm. So, die Minimal Pair Paradigm basically evaluates language models on top of acceptability judgments, which can also include grammaticality like Blimp syntax gym or acceptability in terms of stereotypes such as crowdsource. In this minimal pair paradigm the typical way to evaluate language models is that you show a like acceptable sentence or grammatical sentence and then you show an unacceptable sentence or an ungrammatical sentence and then the hope is that the model basically puts more probability to the acceptable sentence. The current MPP pipeline basically doesn't allow us to evaluate models acceptance towards longer sentences. These days large language models are coming up with longer and longer context windows so it's crucial that we evaluate the models acceptability throughout the context window and that is what we are trying to do here. We are trying to revisit the MPP pipeline by asking the model to evaluate acceptability on longer and longer sequences. So that is the approach, so what we do is that we simulate these longer sequences, we revisit the datasets themselves and then we recreate sentences by choosing like acceptable or unacceptable sentences from those datasets. So for example here we have chosen like a typical pair of grammaticality from the Blimp dataset from the adjunct island case and what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure we extract grammatical sentences from adjunct island and then we add it as a prefix to both the acceptable query and the unacceptable query. So we can do the same thing by choosing unacceptable sentences from the same matching and that could also like be used to test the model's acceptability and we can also do the same by choosing sentences from a different subset or a different dataset. So that is what we call as the mismatch scenario. So here the sentences are still coming from relevant datasets but it's not from the same dataset that you are evaluating with and we can do the same for unacceptability case. Finally we can choose sentences from a completely unrelated domain such as Wikipedia. So this will tell us like whether the model's acceptability judgments are actually impacted by any context like whether the context is coming from a different subset of the dataset or whether it's like completely irrelevant to the current like to the sentence that we are looking at. So how does the model do? The first we look at the Wikipedia sentences which are completely irrelevant to the current query pair and there we find that the MPP judgments are mostly robust for arbitrary context length. We increased the context length toward up to 124 for to max out OPT and GPT-2 models and we saw here in the orange dot line the MPP judgments are relatively stable. Now what happens when we choose sentences from the same dataset. So here we are choosing or creating sentences from acceptable and unacceptable domains from the same Blimp or syntax gym dataset and there we see that the MPP judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable prefixes. But when we match the structure that is when we choose the sentences from the same phenomena in Blimp or syntax gym we see a massive increase or a massive decrease in of the MPP judgment for the model depending on whether the chosen prefix is acceptable or unacceptable. Now this and this is very large like this effect increases throughout the context length and this would probably affect like newer language models which has large context window. So why does the match prefix affect the language model judgment so much? So we did a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure but adding like noise to the input and after doing like several of these perturbations we find that none of these noises are actually making the model like change it course in terms of how it shows us the MPP judgment trend. Basically we find that the models are sensitive to the perturbed sentences in similar ways that is when we perturb the sentences in the acceptable domain we see similar increase in all the perturbations and when we perturb the sentences in the unacceptable domain we see decrease in MPP judgments in similar fashion. So the key takeaways of our work is that language models are sensitive to latent syntactic and semantic features which are shared across the sentences and the MPP evaluation the way that we do it currently with short and single sentence input may not fully capture the language models abstract knowledge throughout the context window. Please read our paper for more details of our experiments. Thank you for listening.</sample>
    <sample id="160">In dem ersten Schritt der Methode werden die Input-Token mit einem unsortierten Multi-Menge von Tokenen zugeordnet, die im Ausgang auftreten werden.</sample>
    <sample id="161">55.000</sample>
    <sample id="163">Die beste Ausrichtungsmethode für DEplain ist die Methode von Massalign.</sample>
    <sample id="164">Schwach überwachtes Lernen ist erschöpfungsbedarfsvoller und teurer, aber es erlaubt die Verwendung von schwachen Labelquellen wie einfachen heuristischen Regeln, Wissensbasen oder Low-Quality-Quellsourcing.</sample>
    <sample id="165">The speaker introduces a new method for adaptive reasoning called Lyport, which stands for Likelihood Learning with Posterior Regularization. This method treats explanations as latent variables and maximizes the marginal likelihood of the outcome given the context by marginalizing over all possible explanations. To prefer plausible explanations, an additional regularizer is used to enforce mutual exclusivity among explanations. The Lyport objective consists of two parts: maximizing the likelihood of outcomes and preferring some explanations over others. The speaker compares their results on Alpha-ALI, the most widely used adaptive reasoning dataset, to zero-shot models and the previous best unsupervised approach. They outperform all of them, including a strong zero-shot GPT-3 baseline, by over four absolute points in accuracy.</sample>
    <sample id="166">This paper introduces a novel neural network and cognitive reasoning framework for image retrieval from linguistically complex texts. The proposed method utilizes a divide-and-conquer strategy and dual process theory to address the challenge of image-text retrieval tasks, where traditional visual language models perform poorly on complex texts. The framework consists of two main components: a symbolic representation generator and a neural symbolic reasoner. The symbolic representation generator encodes images into symbolic representations, while the neural symbolic reasoner integrates these representations with logical operations to retrieve relevant images. Experimental results demonstrate that the proposed method outperforms baseline methods and achieves state-of-the-art performance on various datasets.</sample>
    <sample id="167">Die 750 Dokumente in DEplain-web wurden auf der einen Seite manuell und auf der anderen Seite mit automatischen Alignmentmethoden ausgerichtet.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde von Reuters News 2020 erfasst und danach mit den gleichen Annotieranweisungen wie CoNLL 2013 annotiert.</sample>
    <sample id="169">The speaker, Avi Beller, presents a short overview of the paper "Prompting PaLM for Translation: Assessing Strategies and Performance." The paper is a joint work with colleagues from Google Translate. PaLM is a 540 billion parameter large language model presented in 2022, trained on a large collection of texts comprising 780 billion tokens. It achieved state-of-the-art performance in hundreds of NLP tasks. This work presents the first systematic study of large language model prompting for machine translation. The authors evaluated the translation capability of such models using the best practices of the NMT community, involving the latest test sets to avoid overlap of the test data with the training data of the language model. They compared two state-of-the-art systems, the best-performing systems of the WMT evaluation, using state-of-the-art NMT metrics and expert-based human evaluation results. Finally, they provide some recommendations for prompt selection strategies. The prompting has a significant influence on the performance of the NLMs for translation, as seen in a simple experiment where one-shot prompting was used and two different prompts were provided for each sentence. The majority of sentences (516 out of 1000) showed a difference of more than one BLEU point, and this can go up to 40 points in extreme cases. It is important to select a good prompting strategy. In their experiments, they concluded that a five-shot prompting strategy, where each sentence is marked with its language, is crucial for zero and one-shot prompting. However, when it comes to five-shot prompting, there is nearly no difference between the actual form of the prompting and the examples that carry most of the weight. The summary of their experimental results is that example quality is more important than similarity to the source sentence, so it is important to select examples from high-quality translations. In particular, they compared selecting prompts from the training data of the WMT evaluations or the dev data. The dev data is much more curated and with higher quality than the training data, leading to better performance when using the dev data. Nevertheless, specialized state-of-the-art systems have a substantial advantage over PaLM translations. However, PaLM comes pretty close to a commercial system. In their case, they chose to evaluate with Google Translate. The insights gained from the evaluation performed using the NPM framework show that the fluency of PaLM is comparable to state-of-the-art systems, but the main difference comes from accuracy. In particular, the most common error is omission errors, where PaLM chooses to produce a better-sounding translation by dropping parts of the source sentence that are omitted in the translation. However, the style awkward category for PaLM is lower than for state-of-the-art systems, which is an additional signal that PaLM provides really fluent output but still with some problems of accuracy.</sample>
    <sample id="170">Hallo, alle. Mein Name ist Yusen Jiang vom Peking University. Heute werde ich unsere Arbeit präsentieren: "Exemplar: Korsinglot Semantik Parsing in mehreren natürlichen Sprachen und vielen Repräsentationen." Semantik Parsing ist die Aufgabe, semantische Repräsentationen von Benutzereingaben zu erstellen, wie SQL und Lambda Calculus. Korsinglot Semantik Parsing ist die Aufgabe, Eingaben in mehreren natürlichen Sprachen in mehrere Repräsentationen zu übersetzen. Wie in diesem Bild gezeigt, müssen wir die Abfragen in mehrere natürliche Sprachen mit neuronalen Modellen in SQL, Lambda Calculus und mehr übersetzen. Gegenwärtig werden korsinglot Semantik Parsing-Modelle separat vorgeschaffen und evaluiert auf Datensätzen von limitierten Aufgaben und Anwendungen. Zum Beispiel gibt es Lücken in der Abdeckung bestimmter natürlicher Sprachen, wie Chinesisch, und Lücken in der Abdeckung bestimmter Repräsentationen, wie Lambda Calculus. Oder sie werden nur auf bestimmte neuronalen Modelle evaluiert. Zum Beispiel gibt es nur ein einziges Modell, um sie zu evaluieren. Um dies zu beheben, haben wir Exemplar vorgeschaffen, um einen uniformen Datensatz Exemplar für korsinglot Semantik Parsing in mehreren natürlichen Sprachen und vielen Repräsentationen zu bieten. Er enthält 9 Datensätze in verschiedenen Domänen, 5 Semantik Parsing Aufgaben, 80 Repräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien. Um unser Benchmark besser zu evaluieren, betrachten wir sechs Szenarien für Training und Evaluation. Der erste ist die Übersetzungsstelle. Wir verwenden die Google-Übersetzungs-API, um die Quelle ins Zielsprache zu übersetzen, dann verwenden wir einen monolingual-Modell zur Training- und Evaluierphase. Zum Beispiel trainieren wir ein Englisch-Modell an englischen Abfragen und verwenden während der Inferenz die API, um eine deutsche Abfrage in Englisch zu übersetzen und dann das trainierte Modell zu verwenden, um den SQL-Output zu predictieren. Wir überprüfen auch monolingual-Modelle in diesem Setting, bei denen die Quellsprache dieselbe ist wie die Zielsprache, z.B. Deutsch nach Deutsch oder Englisch nach Englisch. Wir überprüfen auch monolingual-Few-Shot-Setting, bei dem Modell-Modelle nur 10% des Trainingsdatensatzes trainiert werden. Und wir überprüfen monolingual-Multilinguale Modelle, bei denen wir einen Multilingual-Modell für alle Sprachen trainieren, z.B. Deutsche, Englische, Chinesische Abfragen zusammen zu einem Multilingual-Modell trainieren und während der Inferenz können wir dieses Modell verwenden, um deutsche Abfragen oder chinesische Abfragen usw. zu übersetzen. Wir überprüfen auch Crosslingual-Zero-Shot- und Few-Shot-Transfer. Wir trainieren auf einer Quellsprache und übertragen sie auf eine andere Sprache. Zum Beispiel trainieren wir auf englischen Abfragen oder einer Kombination aus englischen und deutschen Few-Shot-Abfragen einen Multilingual-Modell und verwenden es, um den SQL-Output zu predictieren. Wir finden auch einige interessante Resultate. In Bezug auf die Analyse von Monolingual-Modellen evaluieren wir zwei Gruppen von Modellen, einschließlich Encoder PDR, was steht für multilinguistisch prétrainte Encoder mit Pointer-basiertem Decoder, wie z.B. XLNet plus PDR und Bert plus PDR. Wir evaluieren auch Encoder-Decoder-Modelle, das ist multilinguistisch prétrainte Encoder-Decoder-Modelle, wie z.B. BERT und MT5. Wir finden, dass Encoder-Decoder die beste Leistung auf all 9 Datensätzen erreicht. Wir evaluieren MT5 und XLM-R plus PDR auf einem multilingual-Setting. Wir finden, dass Encoder-Decoder oder Encoder-PDR durch Training in einer Mischung verschiedener Sprachen verbessert werden können. Und wir finden, dass es because die meisten der Hauptnatürlichen Sprachen einen Performance-Gewinn erhalten, except English-Performance in 7 Datensätzen abnimmt und in 3 Datensätzen gewinnt. Ich denke, das ist bekannt als Kurz der Multilingualität. Wir vergleichen auch die Crosslingual-Performancedistanz. In diesem Bild ist die blauen Linie Crosslingual Few-Shot-Transfer, die orange Linie Crosslingual Zero-Shot-Transfer und die grüne Linie die Monolingual-Setting. Wir finden, dass durch die Vergleich der grünen und orange Linie, die für Zero-Shot-Setting die Crosslingual-Transfer-Performancedistanz signifikant ist. Und durch die Vergleich der blauen und orange Linie, die für Few-Shot-Setting die Transferdistanz schnell reduziert. Wir finden auch einige weitere interessante Erkenntnisse. Zum Beispiel Encoder-Decoder überperformt vorherige Arbeiten oder erreicht vergleichbaren Resultaten, indem sie auf englische natürliche Sprache trainiert wird und dadurch die Performance von Few-Shot auf Zielsprachen significantly boostet. Wir finden auch multilinguale Sprachmodelle wie Codas und Blue, die noch unzureichend sind für Crosslingual-Semantik Parsing-Aufgaben. Insgesamt bieten wir Exemplar, einen vereinheitlichten Benchmark für Crosslingual-Semantik Parsing mit mehreren natürlichen Sprachen und vielen Repräsentationen. Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen von multilinguistischen Sprachmodellen durch und unsere Resultate zeigen viele interessante Erkenntnisse und mehr. Und herzlich willkommen, Besuch our Paper and Code. Thanks for listening.</sample>
    <sample id="171">Bestehende Arbeiten haben gezeigt, dass ein Angreifer den Modell durch Lernen von der Einbettung und Bereitstellung ähnlicher Dienstleistungen stehlen kann. Daher ist es notwendig, die Urheberrechte von Einbettungs-As-Dienstleistungen zu schützen.</sample>
    <sample id="172">Nein, Codex und Bloom sind noch nicht ausreichend für CLSP.</sample>
    <sample id="174">The speaker introduces the Arg Analysis 35K dataset, which is a large-scale dataset for argument quality analysis. The dataset is unique because it contains 55,000 argument analysis pairs, with 85% sourced from high-quality speeches, expert debaters, and intermediate debaters, and 15% from novice debaters. It also has a diverse range of arguments across 24 themes, including motions on various topics such as education, free speech, and accountability. The dataset includes an element of analysis instead of just keeping arguments, and it introduces the concept of instance-based annotator reliability to better capture reliable judgments. Additionally, the dataset uses a relevance model to assign scores to each argument based on its relevance to different themes, providing a more comprehensive and reliable scoring system.</sample>
    <sample id="175">Die Methode mit der Mehrdeutigkeit der Permutationen wird durch die Induktion als Teil des Trainings adressiert.</sample>
    <sample id="176">Die Fairness eines nachgeschalteten NLP-Modells wird definiert, indem man die Leitstelle der Modellperformen auf eine bestimmte Gruppe basiert.</sample>
    <sample id="177">The presenter is Yanis Slavac.</sample>
    <sample id="178">The speaker's name is not mentioned in the audio.</sample>
    <sample id="179">This paper introduces Symbolic Tom, a plug-and-play multi-character belief tracker for large language models (LLMs) that improves theory of mind reasoning skills. It presents an inference-time algorithm using explicit graphical representations to answer questions about characters' mental states and beliefs. The method outperforms supervised baselines on in-domain tasks and generalizes well to out-of-domain datasets, showing significant gains in accuracy. This approach leverages off-the-shelf NLP models and is beneficial for enhancing LLMs' understanding of complex narratives.</sample>
    <sample id="180">Die Referentin hält den Titel "Mayra" an sich.</sample>
    <sample id="181">This paper introduces a constrained language planning problem, which imposes different constraints on the goal of planning. We evaluate and improve the constrained language planning ability of large language models by generating specific goals with multi-faceted constraints using InstructGPT. We then develop an over-generated filter method to select feasible scripts based on semantic similarity and constraint adherence. Our method significantly improves the planning ability of smaller and specialized models in terms of both semantic completeness and feasibility to constraints. We also propose a symbolic knowledge distillation method to distill constrained language planning datasets from large language models, creating a high-quality dataset named CoScript for constrained language planning research.</sample>
    <sample id="182">Tropikalismus bezieht sich auf die Tendenz, bestimmte Gruppen von Menschen als "tropisch" zu sehen und zu beschreiben, was oft negative Auswirkungen auf die Art und Weise, wie diese Gruppen wahrgenommen werden, hat.</sample>
    <sample id="183">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen erstellt, indem sie Menschen mit den gleichen Anweisungen anhörten.</sample>
    <sample id="184">In dieser Arbeit wurde CXMI verwendet, um die Kontextnutzung von Maschinelern zu messen.</sample>
    <sample id="185">DrBERT und ChuBERT sind beide Bio-medizin-Modelle, die auf NLP-basiert sind. Der Hauptunterschied zwischen den beiden Modellen ist, dass DrBERT auf einem Datensatz von Medikamenten basiert, während ChuBERT auf anonymisierten Daten aus dem National Institutes of Health-Datenarchiv basiert.</sample>
    <sample id="187">Zwei Autoren arbeiten an der Arbeit beteiligt.</sample>
    <sample id="188">Iteratives Transferlernen ist ein Prozess, bei dem ein Modell auf einem Datensatz trainiert wird und dann auf einem neuen Datensatz trainiert wird, der sich von dem ursprünglichen Datensatz unterscheidet.</sample>
    <sample id="189">Das Ziel des Datensatzes ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen möchten.</sample>
    <sample id="190">Ein Angreifer kann Modellparameter über einen EaaS extrahieren, indem er die Watermark-Methode verwendet und den Watermark in den bereitgestellten Diensten detektiert.</sample>
    <sample id="191">Drei Autoren arbeiten an der Arbeit beteiligt.</sample>
    <sample id="192">The presentation introduces a new optimization method called "Ken" that aims to achieve both fast convergence and low memory usage in the training of large language models. The presenter, Yang Liu, explains that traditional adaptive gradient-based optimizers like Adam require significant memory for maintaining first and second moment estimates, while memory-efficient methods like AdaFactor suffer from performance penalties. To address this challenge, Ken uses non-negative matrix factorization (NMF) to reduce memory requirements and incorporates a confidence-guided adaptive updating strategy to minimize instability. Experiments on the book corpus and English Wikipedia show that Ken achieves comparable or better performance than Adam and AdaFactor with significantly reduced memory usage, making it suitable for training large models efficiently.</sample>
    <sample id="193">Um den ursprünglichen Datensatz zu erstellen, wurden 43 Annotatoren verwendet.</sample>
    <sample id="194">Die Autoren der Studie "NLP Positionality" sind an Carnegie Mellon University und Washington University in Seattle gebunden.</sample>
    <sample id="195">The presented framework, ROHT, is designed for answering complex questions by decomposing them into subquestions and utilizing knowledge from various sources. It consists of two stages: first, building a hierarchical question decomposition tree (HQDT) to understand the structure of the complex question, and second, performing probabilistic reasoning over HQDT to integrate knowledge from different sources and generate answers. The framework outperforms existing methods on challenging datasets when integrating knowledge from KB and text corpora.</sample>
    <sample id="196">Die Beispiele mit dem Begrenzer auf der linken Seite sind "Lisa bought and Meggy" und "Egor Milchuk's meaning text theory."</sample>
    <sample id="197">Die Stand der Technik für Dialogsysteme ist, Menschen zu befragen, um zu bestimmen, welche der zwei Konversationen besser ist oder sie auf einer Likert-Skala zu bewerten.</sample>
    <sample id="198">Die Akzeptanz der Modelle muss über das gesamte Kontextfenster bewertet werden, weil große Sprachmodelle inzwischen mit langen Kontextfenstern arbeiten und es wichtig ist, die Akzeptanz der Modelle für lange Sätze zu bewerten.</sample>
    <sample id="199">Ja, das mehrsprachige Training hat in ein paar Datensätzen zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="200">Ja, die Annotatoren kennen die Entität im Voraus.</sample>
    <sample id="201">Die MT-Metriken, die verwendet wurden, sind die Standard-MT-Metriken und Expert-basierte menschliche Evaluationsergebnisse.</sample>
    <sample id="202">Ja, die Regression beeinträchtigt bestimmte NER-Typen.</sample>
    <sample id="203">Positionalität ist für NLP wichtig, weil sie die Systematische Leistungsunterschiede von Technologien zwischen Bevölkerungen und die Auswirkungen auf die Entscheidungen von Forschern und Modellentwicklern beeinflussen kann.</sample>
    <sample id="204">LLMs wurden durch Adapter angepasst.</sample>
    <sample id="205">The speaker, Changbin, a PhD student at the University of Washington, is presenting their work on political biases in language models. They explain that language models are trained on large-scale web crawls, which include politically biased news media, leading to potential fairness issues in downstream tasks. To address this, they propose investigating the political bias propagation pipeline from pre-training data to language models and downstream tasks. They evaluate language models using different prompt formats and find varying political leanings. They also conduct controlled experiments with pre-trained language model checkpoints on partisan corpora, showing ideological shifts in language models based on training data. Finally, they evaluate language models on hate speech and fake news detection tasks, revealing patterns of performance based on political leanings. The speaker highlights the need to acknowledge and tackle fairness issues resulting from language model political biases.</sample>
    <sample id="206">Sie verwenden das Modell C-E für das Transferlernen.</sample>
    <sample id="207">Die besten übersetzten Testsets wurden verwendet, um die PaLM-Fähigkeiten zu bewerten.</sample>
    <sample id="208">Die Autoren haben schließlich drei Empfehlungen vorgeschlagen.</sample>
    <sample id="209">Die vorgeschlagene Methode überzeugt durch einen signifikanteren Gewinn von 1.56 gegenüber dem stärksten Baseline, was durch die Analyse des Konsistent-Distribution-Figurs gezeigt wird.</sample>
    <sample id="210">Der Referent im Video heißt Chu Heng.</sample>
    <sample id="211">Ja, die Ergebnisse und der Datensatz können als Benchmark verwendet werden.</sample>
    <sample id="212">In der Arbeit werden 10 kleineren Modellen experimentiert.</sample>
    <sample id="213">OFA</sample>
    <sample id="215">The speaker, Adam Siprowski, discusses the dependency structure of coordination in linguistics. He explains that different theories and approaches assume various dependency structures, such as the universal dependencies where the first conjunct is the head of the whole coordinate structure, and the Prague approach where the conjunction is the head. He also mentions a multi-headed approach used in De Catts' word grammar. The paper aims to argue for symmetric structures of coordination against asymmetric ones based on the principle of dependency length minimization. The speaker uses examples from English to illustrate how direct objects are preferred to be close to the verb, and how the dependency length minimization principle can explain why certain constructions are preferred over others. Statistics extracted from the enhanced version of the Penn Treebank confirm that left conjuncts tend to be shorter, especially when the governor is absent. The paper provides an argument against asymmetric structures of coordination and in favor of symmetric ones.</sample>
    <sample id="217">The speaker introduces a new method for generating controllable dialogues using a disentangled control generation (DCG) approach. This method learns attribute concepts from single values and uses a disentangled loss to disentangle different attribute combinations. The speaker also proposes a unified reference-free evaluation framework (MAE) for evaluating the quality of generated dialogues. The results show that the proposed method outperforms other baselines in terms of controllability and test quality.</sample>
    <sample id="218">Die Autoren gehören an der Stanford University.</sample>
    <sample id="219">The speaker introduces a research assistant at Academia Sinica and presents their work on comparing and contrasting multi-stage pipelines for uncovering financial signals in financial reports. The work is done with colleagues and advisors, and the background of financial report analysis is discussed. The target company is the Fortune 1000, and the annual report required by SEC contains many details of companies' important activities. Mining useful information requires lots of human efforts. The work was motivated by two observations: first, the words in a company's report are very similar, about 80% of tokens are the same, and the contents are largely dependent; second, the text similarity between two reports in continuous years is high. For example, the report in 2018 is similar to the one in 2017. Based on the observation, they introduce a highlighting task and a multi-stage pipeline. They first define the reference to target structures in their task. The target and reference refer to the report of our interest and the report at its previous year. So basically, a highlighting model should compare and contrast the context between targets and reference like this figure. So the goal of this highlighting task is to find the proportionality roots between a given pair T and R. Formally, the model will predict the highlight word importance, and therefore we can measure the performance of highlighting. For example, the word decrease is supposed to have higher importance in this context. This is our proposed pipeline. Stage 0 is document segmentation. Stage 1 is the relation classification. Stage 2 and stage 2 plus are our main and incremental fine-tuning. Due to the time limit, I would not talk about stage 0. More details can be found in our paper. For stage 1, we will classify all the pairs into three types. Type B refers to the pairs have higher syntactic and semantic similarities. These pairs are frequently appeared such as company's regulations. Reverse pair have similar syntactical pattern but in fact the two segments disclose very different meaning. Mismatch pair are more like a debut information or company's new operations. For the model fine-tuning stage, we first use an external dataset, ESNLI, for out-of-domain fine-tuning. ESNLI is a natural language inference dataset with token annotation. For example, the word fronting is the rationale according to the context of this pair. For in-domain fine-tuning, we use the reverse pairs, the reverse words as pseudo positive labels, and we randomly label few other words as negative. In addition, we mix different objectives. We use the soft labeling techniques by mixing cross entropy loss and KLDivergence. Therefore, we can alleviate the problem from low quality pseudo labels. The variation dataset include ESNLI pairs and our release final dataset. We use two metrics to judge the performance. Our Precision indicates the precision over recall. PCC means the correlation between prediction and annotations. This table shows that our domain-agnostic highlighting model achieve the best performance on final, and even preserve the generalization capability as you can see the performance on ESNLI. We further observe that our methods can benefit on simulation, the mismatch pairs, which we didn't use during training. In conclusion, we propose a highlighting task with our release final dataset and a simple pipeline with two-stage fine-tuning. There are many other future works we would like to try, including improving effectiveness or adding more features or like many other techniques in information retrieval can enhance the application as well. Yeah, that's it. So please refer to our paper and GitHub for more details and feel free to ask us if you have any question. Thank you.</sample>
    <sample id="220">Die Autoren sind an Stony Brook University.</sample>
    <sample id="221">In der Arbeit wurden die Sprachpaare englisch-deutsch und englisch-französisch untersucht.</sample>
    <sample id="222">The title of this work is "To adapt or to annotate: Challenges and interventions in open-domain question answering." The work aims to motivate the development of methods for adapting models to answer questions from different domains. The authors investigate data interventions that can enable out-of-domain generalization in open-domain question answering (ODQA). They identify the type of dataset shift a new domain exhibits and determine which data interventions are effective for a specific type of shift. The authors use Wikipedia as the source domain and test generalizability on seven target passage datasets spanning across six different domains. They observe that few-shot methods improve performance by 8% on average, while zero-shot techniques do not have access to any examples from the target domain. The authors also find that changing the format does not affect model performance, but closed-style questions are easier to curate than standard WQH questions. They conclude that all target sets respond well to few-shot adaptations, while datasets with concept and covariate shifts respond well to zero-shot adaptations.</sample>
    <sample id="223">Der Referent*in heißt Changbin.</sample>
    <sample id="224">Während der Experimente wurden zwei Modelle untersucht: ein Modell, das die Long Impart-Technik verwendet wurde, um Dokumentebasierungen zu produzieren, und ein Modell, das die Normal Bas Long Impart-Technik verwendet wurde, um Satzebasierungen zu produzieren.</sample>
    <sample id="225">53 Aufgaben werden für die Trainingssample verwendet, und 10 Aufgaben werden für die Testsample verwendet.</sample>
    <sample id="226">Es sind zwei Autoren an der Arbeit beteiligt.</sample>
    <sample id="227">The speaker discusses the challenges in grounding language understanding, which involves mapping natural language expressions to executable plans or programs. They argue that current language models lack grounding during pre-training, leading to a gap between pre-training and downstream applications. The proposed framework uses language models for discrimination instead of generation, with a symbolic agent proposing candidate plans and the language model scoring and ranking them. This approach is shown to be effective across different language models and settings, including fine-tuning and in-context learning.</sample>
    <sample id="228">Die Autoren haben experimentiert an den Datensätzen AG News, Mind, SST-2 und ER-Spam.</sample>
    <sample id="229">The speaker introduces a joint work with Henning Bach-smud on detecting improvable claims for argumentative writing support. The paper focuses on formulating what makes an argumentative claim good or bad and explores the challenges of working with revision-based data. The main challenges are representativeness and reliability, model complexity and architecture, contextual information, and topical and user bias. The paper presents detailed analysis of strategies tackling each challenge and a systematic comparison of approaches for the introduced tasks.</sample>
    <sample id="231">NACHOS is a dataset of medical crawled data from the web.</sample>
    <sample id="232">The speaker's name is Ibil Lillard.</sample>
    <sample id="233">This paper introduces a new strategy for simultaneous speech translation (SST) using encoder-decoder attention. The proposed method, called ADT, uses pre-trained offline models without retraining or specific architecture for SST. It handles latency through specific parameters and emits partial translations based on the attention mechanism between audio input and textual output. The results show that ADT outperforms other strategies applied to offline models in terms of translation quality, average latency, and computational efficiency.</sample>
    <sample id="234">Die Prompt-Strategie hat einen großen Einfluss auf die Leistung der LLMs für die Übersetzung, und es ist wichtig, eine gute Strategie zu verwenden.</sample>
    <sample id="235">Die Autoren dieser Studie sind an der University of Edinburgh, der University of Edinburgh School of Informatics und der University of Edinburgh School of Informatics.</sample>
    <sample id="236">Jede Aufgabe im Datensatz wird mit 5 verschiedenen Anweisungen versehen.</sample>
    <sample id="237">Die Autoren schlagen einen Diagnostik-Test-Satz für die Integrität von Wissensintegration vor. Sie Introduzieren einen Korreferenz-Resolution-Aufgabentyp, der darauf abzielt, die Fähigkeit zu bewerten, Informationen aus verschiedenen Quellen zu ziehen. Sie evaluieren den Datensatz mit menschlichen Studioparticipanten und etablieren Korreferenz-Resolution-Modelle.</sample>
    <sample id="238">The video introduces a new benchmark dataset called "MeetingBank" developed by Yibo Wen from the University of Central Florida. The dataset includes meeting transcripts, reference summaries, and URLs for city council meetings. It addresses challenges such as the scarcity of high-quality meeting summaries and the difficulty in locating trustworthy resources for public meetings. The dataset contains 1366 city council meetings with nearly 7000 instances, providing detailed statistics on meeting duration, token per meeting, speaker frequency, and year period. The dataset is used to measure the level of abstraction in meeting summaries using metrics like coverage and density. The video also evaluates different summarization systems, including extractive and abstractive models, and provides insights into their performance based on human evaluation criteria such as informativeness, factuality, fluency, coherence, and redundancy.</sample>
    <sample id="239">Hallo, alle zusammen. Mein Name ist Ibilard und ich werde einen kurzen Überblick über das Papier "Prompting PAM for Translation: Assessing Strategies and Performance" geben. Dies ist einJoint-work mit meinen Kollegen von Google Translate. PAM ist ein 540 Milliarden Parameter limes Language-Modell, das vor einem Jahr in 2022 präsentiert wurde. Es ist trainiert auf einer großen Sammlung von Texten, die 780 Milliarden Token umfasst. Auf dem Datensatz der Evaluation erreicht es das State-of-the-Art in Hunderten von NLP-Aufgaben. In diesem Werk präsentieren wir die erste systematische Studie von Limes Language-Model-Prompting für maschinelles Übersetzung. Wir evaluieren die Übersetzungsfähigkeit solcher Modelle unter Verwendung der besten Praktiken der MMT-Community. Das impliziert die Nutzung der neuesten Testsets, um einen Ablauf der Testdaten mit der Trainingdaten des Sprachmodells zu vermeiden. Und wir vergleichen zwei State-of-the-Art-Systeme, also die besten performenden Systeme der WMT-Evaluation. Wir verwenden state-of-the-art-Neurallm-Metriques und zusätzlich auch Expert-basierte Humanevaluationsergebnisse. Schließlich bieten wir einige Empfehlungen für Promptselstrategien. Das Prompting hat einen großen Einfluss auf die Performance der Limes Language-Model für Übersetzung. Wie wir in einem einfachen Experiment sehen können, bei dem wir ein-shot Prompting verwenden und zwei verschiedene Prompts für eine bestimmte Satzfolge verwenden, erreichen die meisten Satze (516 von 1000) einen Differenzabsatz von mehr als einem BLEU-Punkt. In extremen Fällen kann dies bis zu 40 BLEU-Punkte betragen. Es ist daher wichtig, einen guten Promptselstrategie zu wählen. In our experiments, wir schließen für ein five-shot Prompting-Strategie, bei der wir einfach jede Satzfolge, die wir dem System übergeben, mit dem Sprachnamen markieren. In diesem Beispiel hier, wo wir Übersetzungen von Deutsch ins Englische machen, werden die deutsche Satzfolgen (die Quellsatze) mit "Deutsch" markiert und die englischen Übersetzungen mit "Englisch" markiert. Wir haben festgestellt, dass die Form des Promptings im Fall von Mehrfach-Prompting einen großen Einfluss nicht mehr hat. Es ist crucial für zero- und one-shot Prompting, und wenn wir uns auf five-shot Prompting konzentrieren, gibt es fast keine Unterschiede zwischen den verschiedenen Formen des Promptings. Es sind die Beispiele, die den größten Anteil an Gewicht tragen. Der Auszug aus unserem Experimentsergebnis zeigt, dass die Qualität der Beispiele wichtiger ist als die Ähnlichkeit zu den Quellsätzen. Es ist daher wichtig, Beispiele von hohen Qualität Übersetzungen zu verwenden. Insbesondere vergleichen wir die Selektionsprompts aus dem Trainingsdatensatz der WMT-Evaluation mit den Dev-Daten. Die Dev-Daten sind viel präziser und mit höherer Qualität als der Trainingsdatensatz, was zu besseren Resultaten führt. Trotzdem hat das spezialisierte State-of-the-Art-System einen substantiellen Vorteil über die PAM Übersetzungen. Aber PAM kommtPretty close to a commercial system. In our case, wir haben uns entschieden, Google Translate zu verwenden. Die Erkenntnisse, die wir aus der Dev-Evaluation gewonnen haben, die wir unter Verwendung des MMT-Frameworks durchführten, zeigen, dass die Fluideität von PAM vergleichbar mit State-of-the-Art-Systemen ist. Der Hauptunterschied kommt jedoch von der Genauigkeit. Im Speziellen sind die häufigsten Fehlertypen Omission-Fehler. Es scheint, dass PAM dazu neigt, bessere Übersetzungen zu produzieren, indem es Teile der Quellsätze, die in der Übersetzung irrelevant sind, weglässt. Allerdings ist die Stilqualität von PAM kleiner als die von State-of-the-Art-Systemen, was ein weiterer Hinweis darauf ist, dass PAM einen fluotten Output liefert, aber immer noch einige Probleme mit Genauigkeit hat. Und das ist alles für diese kurze Überblick.Für weitere Details bitte mit mir zur vollständigen Präsentation des Papiers kommen. Vielen Dank.</sample>
    <sample id="240">Hallo, ich bin Dawei, ein PhD-Student an der Carl von Fricken University in Deutschland. In diesem Video möchte ich gerne unsere jüngsten Arbeiten präsentieren: "Weak than You Think" und "Critical Look at Weakly Supervised Learning". Das ist ein Joint-Work mit Xiaoyu Chen, Myo Smoothbath, Gaurav Deepen und Dietrich Klau. Ich möchte beginnen mit einer kurzen Einführung in "Weak Supervision" und "Weakly Supervised Learning". In "Weak Supervision" werden die Daten nicht manuell labeliert, sondern durch weak labeling sources wie Simple Heuristics, Knowledge Bases oder Low-Quality Crowdsourcing labeliert, wie Sie in der Figur auf der rechten Seite gesehen haben. Wenn wir das Compared zu menschlichen Annotierungen machen, sind die weak annotations viel billiger, aber sie sind auch noisier, was bedeutet, dass ein bestimmtes Maß an den Annotierungen falsch sind. Wenn wir Direkt neuronalen Netze auf weakly labeled Data trainieren, tendieren die neuronalen Netze, die Lernfehler zu memorieren und nicht zu generalisieren. In "Weakly Supervised Learning" werden Training-Algorithmen vorgeschlagen, um neuronalen Netze robust zu trainieren, so dass die trainierten Modelle immer noch gut generalisieren können. In jüngster Zeit in WSL (Weakly Supervised Learning) wird behauptet, dass Menschen Modelle auf weakly labeled Data trainieren und dabei hohen Leistungslevel auf sauberen Testsets erreichen. Technisch gesehen ist dies wahr, aber es gibt einen Haken: Menschen nehmen an, dass es einen extra sauberen Validationsset gibt, um ModellSelektion zu machen. Wir haben uns auf diese Problemstellung konzentriert, da dies impliziert, dass extra manuelle Annotierungen in "Weakly Supervised Learning" erforderlich sind, aber das ist oft übersehen worden. Die offizielle Definition adoptiert eine Reihe von drei Forschungsfragen: Erstens: Ist ein sauberer Validationsset für WSL notwendig, oder können wir ein noisieres Validationsset verwenden? Zweitens: Wenn ein sauberer Datensatz erforderlich ist, dann, wie viele saubere Samples benötigen wir? Drittens: Sollten wir nur die sauberen Samples für Validationszwecke verwenden, oder gibt es bessere Wege, sie zu nutzen? Wir haben in unserem Werk diese Forschungsfragen adressiert und unsere Findungen sind als Folge: Erstens: Interessanterweise erfordern jüngste WSL-Methoden tatsächlich saubere Validationsdaten, um korrekt zu arbeiten, andernfalls gibt es einen großen Leistungsverlust, wie Sie in der Figur sehen können. Wenn es keine sauberen Validationsdaten gibt, dann können die trainierten Modelle nicht über die ursprünglichen weak labels hinaus generalisieren, was bedeutet, dass das Training sinnlos ist. Dies zeigt, dass WSL-Ansätze tatsächlich saubere, manuell annotierte Daten benötigen, um korrekt zu arbeiten, und die Kosten für die Obtention von sauberen Validationsdaten sollten nicht übersehen werden. Unsere zweite Erfindung lautet, dass die Anzahl der sauberen Validationsdaten helfen kann, WSL-Ansätze zu verbessern, wie Sie in der Figur auf der linken Seite sehen können. Typischerweise benötigen wir nur 20 Samples pro Klasse, um einen hohen Leistungslevel zu erreichen. Aber das ist nicht das Ende der Geschichte, denn wenn wir entweder entscheiden, die sauberen Samples zu verwenden, dann das Training auf ihnen zu durchlaufen, wird es selbst noch besser erzielen. Der rechte Pfeil zeigt die Leistungsunterschiede zwischen Fine-Tuning Ansätzen, die direkt auf die sauberen Daten angewandt werden, und WSL-Ansätzen, die die sauberen Daten nur für Validationszwecke verwenden. Wie Sie sehen können, wenn wir 10 Samples pro Klasse haben, beginnt das Fine-Tuning zu übertragen WSL-Ansätze. Schließlich können die Leistungsverbesserungen, die in früheren WSL-Ansätzen geltend sind, leicht erreicht werden, indem wir die Kontinuierliche Fine-Tuning auf die sauberen Validationsdaten erlauben. Wie Sie aus den Figuren sehen können, unterperformt der VELA-Model "FTW" ursprünglich komplexere WSL-Methoden wie "Cosine", aber wenn wir ihm die Kontinuierliche Fine-Tuning auf die sauberen Samples erlauben, dann performt "FTW" ebenso gut wie andere Ansätze. Also in der Praxis gibt es keinen Grund, komplexere WSL-Ansätze zu verwenden, die mehr Rechenzeit und Diskraum benötigen. Um zu summaire, wir haben gezeigt, dass jüngste WSL-Ansätze saubere, manuell annotierte Datensätze benötigen, um korrekt zu arbeiten. Ihre Leistungsverbesserungen und Praktizität werden stark überbewertet. Unsere konkreten Empfehlungen für zukünftige Arbeiten sind als Folge: Erstens: Berichten Sie die ModellSelektionskriterien, z.B. ob die ModellSelektion mit einem sauberen Validationsset durchgeführt wurde. Zweitens: WSL-Ansätze sollten mit Few-Shot-Learning-Baselines verglichen werden, die auf sauberen Datensätzen arbeiten. Drittens: Kontinuierliche Fine-Tuning ist ein einfach aber starkes Baseline, das in zukünftigen Arbeiten in WSL berücksichtigt werden sollte. Endlich: Wir haben Open-Source-Code für unser Werk bereitgestellt. Sie können ihn unter dem QR-Code auf dieser Folie finden. Bitte fühlen Sie sich frei, es zu überprüfen. Danke, und ich hoffe, Sie genießen die Konferenz.</sample>
    <sample id="241">The speaker, Ethan, introduces his paper on "Human in the Loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments." The paper is a joint work with Yang Chen, Wei Shu, and Allen Gidler at Georgia Tech. The paper discusses the challenges of evaluating misinformation detection systems, including unrealistic evaluation methods and lack of human-centricity. The proposed framework aims to address these deficiencies by involving humans throughout the process and providing actionable outputs. The concrete implementation of this framework for COVID-19 treatment misinformation detection has two main components: claim detection and policy violation verification. The speaker evaluates the efficacy of the policy violation verification portion of the workflow and provides insights into the human workload required for such systems.</sample>
    <sample id="242">Gängige Bewertungsmethoden für Dialogsysteme sind die Anwendung von Human-Judgment, z.B. indem Human-Judge auswählen, welche der zwei Konversationen besser ist, oder indem sie Konversationen auf einer Likert-Skala bewerten.</sample>
    <sample id="243">There are five authors involved in the work.</sample>
    <sample id="244">Im Beispiel mit Servin und Kea wird benötigt, dass Servin ein Richter ist und dass Richter Entscheidungen in Gerichten treffen.</sample>
    <sample id="245">The presentation introduces a two-step pipeline for finding high-agreement Amazon Mechanical Turk workers, focusing on the challenges of automatic matrixes and the need for better understanding of best practices. The pipeline includes qualification settings, tasks, and endurance tests, with a reference-based task to assess general performance. The study found that 26 MTurk workers passed the first stage (gold and silver), and 12 passed the second stage (gold and silver). The Krippendorff Alpha value indicates good agreement, but there are limitations such as only testing English summarization on the MTurk platform and no guarantee of training crackness.</sample>
    <sample id="246">Ja, der Code ist verfügbar.</sample>
    <sample id="247">The speaker introduces a new dataset called "Fact KG" for fact verification via reasoning on knowledge graphs. The dataset uses Wikipedia as the knowledge graph and includes claims in both written and colloquial styles. The task involves retrieving evidence from Wikipedia and verifying claims using different types of reasoning, such as one-hop, conjunction, existence, multi-hop, and negation. The dataset is designed to be practical for use in modern dialogue systems that communicate with internal knowledge graphs. The speaker also mentions that their model outperforms all other baselines, including claim-only baselines and a model that only uses claims to verify without graph evidence.</sample>
    <sample id="248">Nein, die Annotatoren sind nicht auf jede demographische Gruppe ausgewogen.</sample>
    <sample id="249">Satzlängen wurden verändert, indem sie von einem Datensatz extrahiert und als Prefix hinzugefügt wurden.</sample>
    <sample id="250">Eine dimensionale Bewertung ist eine Methode, um die Qualität von Dialogmodellen auf einem feineren Granularitätslevel zu bewerten. Sie versucht, die subjektive menschliche Bewertung zu reduzieren, indem sie explizit feststellt, ob jede Modellresponse bestimmte Verhaltensweisen ausdrückt, wie zum Beispiel die Bereitschaft, irrelevantes Information zu geben oder sich selbst widersprechen.</sample>
    <sample id="251">Die Autoren gehören an der University of Science and Technology of China.</sample>
    <sample id="252">The presentation introduces the work of creating an unsupervised case retrieval system using event extraction. The speaker, Saikiran Nankillala, a master's student at IIT Kanpur, highlights the challenges faced by legal professionals in retrieving relevant past precedents due to the increasing volume of cases. The proposed system aims to address this issue by retrieving relevant candidates from a candidate pool based on similarity in factual situations. Two key contributions are made: the ILPCR dataset and the Ucreate pipeline. The ILPCR dataset is a new benchmark for PCr tasks, containing 7,700 legal cases with an average of 6.775 editations per query document. The Ucreate pipeline leverages unsupervised learning techniques and introduces an event-based approach for PCr tasks, demonstrating high retrieval efficiency, low inference time, and generalization across Indian and Canadian legal systems without requiring law or demographic-specific tuning.</sample>
    <sample id="253">The speaker, Maria Ydra Aragon, is presenting a work called "Dissorb," which is a double-domain adaptation model for detecting signs of mental disorders in social media. The work is a group effort of researchers from Mexico and Spain. The model uses domain adaptation to improve the performance of a model on a target domain by using knowledge learned from another related or similar domain. The model also incorporates knowledge from a lexicon to guide the masking process. The results show that the model tends to locate in the main diagonal of the region, indicating its good balance, while other methods have a high precision or recall but score low in the other dimension. The model also tends to be biased toward words related to mental disorders. The visualization tool provides an interactive head view in the form of a graph, allowing users to observe the most prominent words and sentences related to mental disorders.</sample>
    <sample id="254">The speaker introduces a document-level distant relation extraction framework with uncertainly guided label denoising to improve the label quality of DS data. The framework uses Monte Carlo dropout technology to model uncertainty in pre-training, instance-level uncertainty estimation for overlapping relations, and a dynamic class uncertainty threshold strategy for filtering pseudo labels. The proposed method outperforms previous baselines on two public datasets.</sample>
    <sample id="255">Die Form des Prompts ist für 0- und 1-Shot-Prompting wichtig, aber in Fällen mit mehreren Shotten hat die Form des Prompts keinen großen Einfluss.</sample>
    <sample id="257">Die Autoren haben vier state-of-the-art Chat-Modelle evaluiert.</sample>
    <sample id="258">The speaker, Chang Sun He, introduces a new method of using large language models to evaluate the quality of texts in natural language processing. The approach involves instructing large language models with specific ratings and using their output as a measure of text quality. This method is novel because prior works did not explore the idea of large language model evaluation. The motivation behind this work is to find an alternative to human evaluations, which are unstable and difficult to reproduce. The speaker compares the performance of different large language models, including GPT-2, T5, and ChatGPT, and finds that some models show a clear preference for human-written texts. The results suggest that large language models can be used as an alternative to human evaluations, but further research is needed to fully understand the benefits and drawbacks of this approach.</sample>
    <sample id="259">The speaker, Usen Zhang from Penn State University, introduces Exemplar Crosslingual Semantic Parsing, a task that involves translating queries in multiple natural languages into multiple semantic representations. The speaker explains the challenges of existing cross-lingual semantic parsing models and proposes Exemplar as a unified dataset for this task. Exemplar contains 9 datasets in various domains, 5 semantic parsing tasks, 80 semantic representations, and 22 natural languages in 15 language families. The speaker also discusses six settings for training and evaluation, including translation test, monolingual model, multilingual model, and cross-lingual zero-shot and few-shot transfer. The speaker evaluates the performance of different models, including encoder-decoder models and encoder-only models, and finds that encoder-decoder models outperform previous work. The speaker concludes by summarizing the results of the benchmark study and inviting readers to visit their paper and code.</sample>
    <sample id="260">Ein Autor arbeitet an der Arbeit beteiligt.</sample>
    <sample id="261">Ein guter Planer sollte Skripte erstellen, die realistisch und zu den Bedingungen passen.</sample>
    <sample id="262">Eine Person arbeitet an der Arbeit beteiligt.</sample>
    <sample id="263">The presented work focuses on mitigating label biases in in-context learning (ICL), a popular paradigm for utilizing large language models. The authors identify various design choices that introduce biases to the model's predictions, including vanilla label bias, context label bias, and domain label bias. To address these issues, they propose a novel calibration method called domain context calibration, which uses random in-domain words sampled from the task corpus as content-free text to estimate and mitigate the effect of all different label biases. The results show that domain context calibration significantly improves the performance of ICL on datasets with larger domain label biases, leading to better decision boundaries and more accurate predictions.</sample>
    <sample id="264">The speaker presents a paper on transferable audio-visual text generation, which aims to address the challenge of multi-modal domain shift in tasks like audio-visual text generation. The proposed method involves training a model that can quickly adapt to new multi-modal domains with limited labeled data. The framework consists of three components: an audio-visual meta map network, an audio-visual encoder, and a language model generator. The audio-visual meta map network maps different visual concepts across domains into a unified audio-visual semantic space, while the audio-visual encoder and language model generator are trained using a contrastive learning approach. The speaker also introduces a method for fine-tuning the model on a target domain by finetuning the meta parameters and evaluating the model on the target domain. The results show that the proposed approach outperforms baseline models on both cross-domain and cross-modality settings.</sample>
    <sample id="265">The speaker's name is Vasudeva.</sample>
    <sample id="266">Die Autoren gehören an der University of Pennsylvania.</sample>
    <sample id="268">Die häufigsten Fehler von PaLM sind Omissionen, bei denen PaLM Teile des Quelltextes weist.</sample>
    <sample id="269">Hallo, ich bin James Finch und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABC-Eval erzählen, eine neue dimensional-basierte Methode zur Beurteilung von conversational AI. Dieses Werk wurde vom Emory NLP Lab, geleitet von Professor Geno Choi an Emory University, in Zusammenarbeit mit Amazon Alexa AI erstellt. Nehmen Sie an, Sie haben einen Dialog-Modell entdeckt und möchten sehen, wie gut es sich gegenüber dem aktuellen Stand der Kunst vergleicht. Eine gemeinsame Praxis ist die Verwendung von menschlicher Beurteilung, indem man menschlichen Richtern fragt, welche der zwei Dialoge besser ist oder sie auf einer Likert-Skala bewertet.Diese Ansätze sind gut, um eine komholistische Beurteilung der Gesamtqualität des Dialogs zu erhalten, aber Dialogqualität hat viele Aspekte. Daher möchten Sie eventuell mehrere Dimensionen der Chatschwelle bewerten, um die Stärken und Schwächen des Modells auf einem feineren Granularitätslevel zu verstehen. Ein Ansatz besteht darin, einfach menschlichen Richtern zu beordern, mehrere Dimensionen der Dialogqualität zu bewerten, indem sie existierende vergleichbaren oder Likert-Skala-Methoden verwenden. Allerdings glauben wir, dass es eine präzisere und zuverlässigere Strategie für die dimensional-basierte Dialogbeurteilung gibt. Unsere Ansatz versucht, die Subjektivität menschlicher Beurteilungen zu reduzieren, indem wir explizit feststelle, ob jede Modell-Antwort bestimmte Verhaltensweisen ausdrückt, wie zum Beispiel die Bereitstellung von irrelevanter Information oder die Kontradiktion von sich oder seinem Partner. Wir nennen diese Ansatz "annotating behaviors in chat" oder "ABC-Eval" im Kurzform. Wir haben diese Methode entwickelt, um umfassend die Verhaltensweisen von Chatschwelle zu abdecken, die in jüngster Literatur als Auswirkungen auf die Chatschwelle vorgeschlagen wurden. ABC-Eval ist in der Lage, die Häufigkeit zu messen, in der ein Chatschwelle einen Partner ignoriert oder etwas irrelevantes sagt, sich oder seinen Partner kontradikt, falsche Fakten auslotet oder gegen allgemein akzeptierte Wissen verstößt, und wann das Modell Erfolg zeigt oder versagt, Empathie zu zeigen. Um zu bestimmen, welche Art von Beurteilung am besten geeignet ist, haben wir vier state-of-the-art Chatschwelle und sie auf 100 menschlich-basierte Dialoge pro Modell mit ABC-Eval bewertet.Für Vergleichszwecke haben wir auch diese Dialoge mit drei existierenden Methoden bewertet: Likert-Ratings auf Turnebene, Likert-Ratings auf Dialogebene und Dialogebene parewised Comparisons.Für jede der existierenden Methoden haben wir Bewertungen auf acht von den am häufigsten gemessenen Aspekten der Dialoge gesammelt, da dies standardmäßig ist, um Chatschwelle an mehreren Dimensionen zu bewerten.Aus our analyses of these evaluation results, we found that ABC-Eval-Behavior labels are overall more reliable than labels collected by existing methods, as measured by inter-annotator agreement on 100 doubly labeled conversations. In addition, ABC-Eval labels are more predictive of the overall conversation quality compared to metrics produced by existing methods, as shown by this simple linear regression analysis. For example, you can see how measuring the proportion of turns with self and partner contradictions explains 5% and 10% of conversation quality respectively, while the average Likert consistency scores explain only 4% or less. Finally, we checked whether each evaluation metric captures a unique aspect of chat quality using a stepwise linear regression. You can see how the combination of all ABC-Eval metrics explains over 25% of conversation quality, and as you remove the metrics one at a time, most of them result in losing a decent amount of information about the quality. On the other hand, the combination of all turn-level Likert metrics explains far less of the quality, and fewer of these metrics carry unique information. These reliable, informative, and distinct ABC-Eval metrics enable us to evaluate conversational AI with a higher resolution than previous methods are able to achieve. You can see in the results of our experiment that several challenges still remain and have been precisely quantified. For example, the bots we tested have common sense violations in around 20% of their responses, they produce irrelevant information in around 15% of the responses, and they contradict themselves or their partner around 10% of the time. With the rapid pace of improvement in the field, many of these error rates could see a decrease in new models released since our evaluation was conducted. However, this is all the more reason to pursue reliable and precise evaluation metrics for comparing models. We hope ABC-Eval can be leveraged by others in the field as a meaningful step in this direction, and we look forward to seeing how conversational AI will advance in the coming months and years. Thank you for watching.</sample>
    <sample id="270">Die Autoren gehören an der Emory University.</sample>
    <sample id="271">CFT steht für "Continuously Fine-Tuning". Es ist ein Verfahren, bei dem das Modell über die Laufzeit fortlaufend an den saubersten Datensamples optimiert wird, um die Leistung zu verbessern.</sample>
    <sample id="272">Die Arbeit beteiligen sechs Autoren.</sample>
    <sample id="273">Hallo, mein Name ist Kai Yen und ich werde heute über unser Werk "Wann benötigt eine Übersetzung Kontext?" sprechen. Dieses Werk wurde in Zusammenarbeit mit Patrick Franz, Emyu, Andra F. Martinez und Graham Navigo erstellt. Viele Übersetzungen hängen von Kontext ab. Zum Beispiel, wie würden wir "Mole" in diesem Satz übersetzen? Wenn das vorherige Wort "Dinge könnten gefährlich werden, wenn die Minister davon erfahren" war, dann bezieht sich "Mole" auf einen Spion. Aber wenn das vorherige Wort "Könnte es etwas Ernstes sein, Arzt?" war, dann bezieht sich "Mole" auf eine birthmark. Abhängig vom Kontext verändert sich sowohl die Bedeutung als auch die Übersetzung des Wortes. Allerdings ist es schwierig zu bewerten, wie gut Modelle solche Fälle handhaben können. Zum einen because nur ein kleiner Teil von Übersetzungen hängt von Kontext ab, was bedeutet, dass Metrisken auf der Eckelevel wie BLEU nicht in der Lage sind, diese Übersetzungen zu erfassen. Ein paar Leute haben vorgeschlagen, eine spezielle Bewertung auf Kontextabhängige Übersetzungen durchzuführen, aber diese Ressourcen unterstützen nur begrenzte Typen von Kontextabhängigen Übersetzungen und begrenzte Sprachen, da sie normalerweise auf Domänenwissen und menschliche Kuration berufen. In unserem Werk versuchen wir, zwei Fragen zu beantworten: Wann benötigt eine Übersetzung Kontext? Und wie gut können Modelle solche Fälle handhaben? Um die erste Frage zu beantworten, haben wir zuerst gemessen, wie viel ein Wort von Kontext abhängt. In einem vorherigen Werk haben wir CXMI (Contextualized Crosslingual Information) als Maß für Kontextnutzung von Maschinell übersetzten Modellen eingroduced. Das wird getan, indem man misst, wie viel Informationen das Kontext C für die Zielsprache Y gibt, gegeben ist, dass die Quelle X ist. Man kann den CXMI als die Information, die man durch das Giving von Kontext an das Modell gewinnt, denken. In unserem Werk haben wir CXMI auf P-W-CXMI erweitert, um Kontextnutzung auf Satz oder Wortebene zu messen. Wir können Wörter mit hohen P-CXMI als solche, die Kontext benötigen, um übersetzt zu werden, denken. Jetzt analysieren wir Wörter mit hohen P-CXMI, um Muster zwischen diesen Wörtern zu finden. Und wir führen unsere Analyse an Transkripten TED Talks durch, die von Englisch ins Deutsche übersetzt wurden. Wir führen unsere Analyse an drei verschiedenen Ebenen durch. Zunächst schauen wir uns Wörter mit hohen P-CXMI an, um zu sehen, ob es bestimmte Sprachmerkmale gibt, die hohen P-CXMI aufweisen. Und dies ermöglicht uns, beispielsweise Doppelpronomen in Arabisch zu finden, die hohen P-CXMI aufweisen, und das kann erklärt werden, weil Englisch keine Doppelpronomen hat, also Kontext benötigt, um festzustellen, ob ein Pronomen dual ist, wenn es ins Arabische übersetzt wird. Und analog finden wir auch Wörter, die bestimmte Grammatikpunkte benötigen, um korrekt übersetzt zu werden. Wir schauen uns dann Wörter mit hohen P-CXMI im Durchschnitt über alle ihre verschiedenen Auftretensformen an. Und dadurch können wir Fälle identifizieren, bei denen man Kontext benötigt, um die richtige Übersetzung zu finden. Und analog finden wir Wörter, die Kontext benötigen, um die richtige Formalität zu verwenden. Und endlich schauen wir uns Wörter an, die hohen P-CXMI aufweisen, und das ermöglicht uns, Phänomene zu identifizieren, die nicht durch ein Wort alleine, sondern durch die Satzstruktur ausgedrückt werden, zum Beispiel Ellipsenauflösung. Also nutzen wir unsere Erkenntnisse aus unserer Analyse, um einen Benchmark für Dokumentebasierter Übersetzung zu entwerfen. Für jede der 5 diskursiven Phänomene, die wir identifiziert haben, erstellen wir Tagger, um Wörter zu automatisch identifizieren, die zu diesem Phänomen gehören, und wir nennen unser Tagger Multi-Lingual Diskurswahrer (MLD) Tagger. Wir können dann auch beachten, dass verschiedene Sprachen unterschiedliche Proportionen dieser diskursiven Phänomene aufweisen. Wir verwenden dann den MLD-Tagger, indem wir den Tagger auf ein parallel korpus anwenden, den wir verwenden möchten, um eine Evaluierung zu durchführen. Und wir wenden unsere Übersetzungsmethoden auf die Kontextabhängigen Beispiele an, die der MLD-Tagger identifiziert hat. Und schließlich verwenden wir unser Benchmark, zusammen mit anderen Metrisken, um verschiedene Modelle auf Dokumentebasierter Übersetzung zu bewerten. Zunächst einmal, wenn wir Korpusbasierte Metrisken verwenden, also z.B. BLEU, finden wir, dass Kontextagnosische Modelle die besten Leistungen aufweisen. Aber wenn wir BLEU verwenden, finden wir, dass Kontextwahrer-Modelle die besten Leistungen aufweisen. Und wenn wir Word F-Measure verwenden, finden wir, dass Modelle mit und ohne Kontext vergleichbare Leistungen aufweisen. Dies zeigt, dass es schwierig ist zu bestimmen, welche Dokumentebasierter Übersetzungssysteme am besten performen, wenn wir nur Korpusbasierte Metrisken verwenden. Nun verwenden wir den MLD-B benchmark, um Modelle zu bewerten, und finden, dass Kontextwahrer-Modelle signifikant besser als Modelle, die Kontext für bestimmte diskursive Phänomene wie Formalität und lexikalische Kohärenz verwenden, sind. Aber diese Modelle sind nicht viel besser als Modelle, die Kontext für andere Phänomene wie Ellipsen, Pronomen und Verbformen verwenden. Das zeigt, dass wir bei Dokumentebasierter Übersetzung noch Fortschritte machen müssen. Wir vergleichen auch verschiedene kommerzielle Systeme und unser Benchmark zeigt, dass DeepL normalerweise besser als Google Translate auf Dokumentebasierter Übersetzung ist. Insgesamt haben wir einen datengetriebenen Analyseansatz über 14 Sprachpaare durchzuführen, um zu sehen, wann Übersetzungen Kontext benötigen. Und dann verwenden wir unsere Erkenntnisse, um einen Benchmark für Dokumentebasierter Übersetzung zu entwerfen, der uns dabei helfen kann, zu sehen, welche diskursive Phänomene Modelle gut oder schlecht handhaben und welche Übersetzungsistema gut auf Dokumentebasierter Übersetzung sind. Vielen Dank für eure Aufmerksamkeit. Ich sehe euch in Torododo.</sample>
    <sample id="274">Yusen Zhang</sample>
    <sample id="276">The presented work focuses on developing a dataset for evaluating machine translation metrics in Indian languages. The dataset includes translations of 200 sentences from five languages, with each sentence translated by seven different models. Human annotators evaluated the translations, marking errors and providing overall scores. The study found that Comet outperformed Comet baselines in three out of five languages and had higher correlations than Comet MQM across all languages.</sample>
    <sample id="277">Die neue Methode hat keinen Namen.</sample>
    <sample id="278">Die Methode der „markierten Wörter“ verwendet das soziolinguistische Konzept der Markiertheit, um die Wörde zu identifizieren, die markierte Gruppen von unmarkierten Gruppen unterscheidet.</sample>
    <sample id="279">Die Autoren gehören an der University of Washington.</sample>
    <sample id="280">The speaker introduces a new framework for emotion regulation in conversations, called MultiEmo. The framework consists of four key components: unimodal feature extraction, context modeling, multimodal fusion, and emotion classification. The speaker proposes a novel visual feature extractor called VisiNet, which captures visual cues by integrating facial expressions from multiple frames without encoding redundant scene-related information. The speaker also proposes a low-level multimodal fusion network called MultiTen, which integrates one modality with complementary information from the other modalities through stacked bidirectional multi-head cross-attention layers. The speaker introduces a sample-weighted focal contrastive loss to address the difficulty of distinguishing between semantically similar emotions. Experimental results demonstrate that MultiEmo achieves state-of-the-art performances on two ERCC benchmark datasets, MELD and iEMOval, with significant improvements in minority and semantically similar emotions.</sample>
    <sample id="281">The speaker introduces a data-driven exploration on when translation requires context, collaborating with Patrick Franzke, Emyu, Andri F. Martinez, and Graham Nivig. They discuss the challenges of evaluating models' performance in context-dependent translations and propose a benchmark for document-level translation using multilingual discourse-aware taggers. The analysis reveals that context-aware models outperform models without context for certain discourse phenomena like formality and lexical cohesion. The benchmark also shows that DeepL is more accurate than Google Translate for document-level translation.</sample>
    <sample id="282">This paper presents a new approach to style transfer in natural language generation, focusing on discourse-level transfer. The authors propose a model called StyleTrans, which combines discourse representation with style embedding to generate text in target styles while preserving the original content and style-specific features. They also introduce a new training objective to reduce style similarity between discourse representations and design a two-stage training framework to improve style control and content preservation. Experiments on Chinese and English datasets show that StyleTrans outperforms baseline methods in terms of style control, content preservation, and style visualization.</sample>
    <sample id="283">Prag</sample>
    <sample id="284">The speaker introduces a new spam boundary mechanism for enhancing universal information extraction. The current spam-based UIE model relies on identifying and labeling the spam boundaries of the target in the text, which can be ambiguous. To address this, the proposed method uses fuzzy instead of precise boundary labeling. Additionally, there is a mismatch between Transformer feature extraction and information extraction, so an adaptive attention mechanism is proposed to model the fuzzy spam boundary. The model predicts a continuous distribution of correct probability in a specific range, which is converted into discrete values for calculating Fuzzy Span Loss. The model also uses a mask function to trim attention distribution and achieve better performance in information extraction tasks such as named entity recognition, relationship extraction, and aspect sentiment triple extraction.</sample>
    <sample id="285">The speaker introduces a new evaluation framework for fact error correction in dialogue summarization, which uses reference summaries and a taxonomy of fact errors. The framework consists of alignment, classification, and comparison steps, and is used to train and evaluate fact error correction models. The results show that training with human-annotated reference summaries can improve the performance of fact error correction models, but current models struggle to correct errors by addition and cannot address attribute errors, modality errors, and link errors.</sample>
    <sample id="286">The speaker's name is James Finch.</sample>
    <sample id="287">There are four authors working on the project.</sample>
    <sample id="288">Die Blimp und Syntax Gym Datensätze können zum Testen syntaktischer Phänomene verwendet werden.</sample>
    <sample id="290">Die Abkürzungen der fünf Methoden für die erste Forschungsfrage sind FTW, COSINE, DICE, CLARKO und YOSHUN.</sample>
    <sample id="291">Das Modell wird anhand von Aufgaben wie Namensentwicklung, Klassifizierung, Part-of-Speech-Segmentation und Fragensbehandlung evaluiert.</sample>
    <sample id="294">CamemBERT wurde ursprünglich auf einem Datensatz von 4 GB trainiert, der aus dem Corpus der National Library of Medicine bestand.</sample>
    <sample id="295">Der Referent*in heißt Adam Sipruckowskyj.</sample>
    <sample id="296">In diesem Video präsentiert der Autor, Balrio Basili, eine Studie zur Ironie-Erkennung in natürlicher Sprache. Er und seine Teammitglieder haben eine Datensammlung namens EPIC erstellt, die aus sozialen Medien, Reddit und Twitter stammt und 300 kurze Konversationen beinhaltet. Sie wurden von 74 Annotatoren in verschiedenen englischen Sprachvarianzen anhand eines einfachen Notationsprototyps überprüft. Das Hauptresultat zeigt, dass die Interannotator-Übereinstimmung variiert und dass die "Perspektivbewussten" Modelle, die auf Splits der Datensammlung basieren, in Bezug auf die Konfidenz in ihren Vorhersagen signifikant sicherer sind. Eine weitere Untersuchung ergab, dass Generationen und geographische Verteilungen der Annotatoren Varierungen in der Interpretation von Ironie aufwiesen.</sample>
    <sample id="297">The project aims to develop a typology and glossary of dog whistles, perform a case study on historical US political speeches, evaluate dog whistle recognition in language models, and conduct a case study on toxicity detection. The team has collected over 340 terms and symbols from various sources, including Wikipedia and blogs, and categorized them by register type and persona. They have also analyzed the frequency of racial dog whistles in the US Congressional Record and found that they are more associated with conservatism over time. The team has evaluated the performance of GPT-3 in surfacing dog whistles and identifying their covert meanings, and has shown how dog whistles can evade content moderation through toxicity detection with Perspective API.</sample>
    <sample id="298">Die Versuche zur Erneuerung oder Fortsetzung der vorherigen Modelltraining mit neueren Daten haben gezeigt, dass die Leistung mit einer größeren zeitlichen Distanz zwischen dem Trainings- und Testdatensatz abnimmt.</sample>
    <sample id="299">The speaker, Michaela Skaragakis, discusses improving the robustness of AI models using Minimax training. She explains that AI models often rely on shortcuts, which are correlations between input attributes and labels during data creation. These shortcuts can lead to poor performance on out-of-distribution samples. The proposed method involves a training objective between a learner and an auxiliary model to reduce reliance on shortcuts and improve out-of-distribution performance. This method does not assume specific types of shortcuts and uses a feedforward network to model the auxiliary. The method is evaluated on three datasets and shows consistent improvement in out-of-distribution performance while maintaining high in-distribution accuracy.</sample>
    <sample id="300">In this video, we introduce a new task called Interactive Dictation and make initial steps towards solving it. Interactive Dictation is a process where users can use their voice to both dictate and edit a document in a natural and intuitive manner. In this example, a user starts by dictating "just wanted to ask about the event on the 23rd," which is transcribed verbatim into the text box. However, in the middle of speaking, the user realizes they made a mistake and corrects themselves saying "on Friday the 23rd." Ideally, the system can pick up that this was a speech correction and replace the correct span with the new utterance. Next, the user continues transcription saying "is the event still on," which gets transcribed into the text box. Finally, the user can issue a verbal command like "replace the event in the last sentence with it." The system can identify the correct occurrence of the event to replace with it. While speech-to-text systems are starting to proliferate, most of them support only dictation and do not support invoking edits through vocal commands. There are a few software that do recognize vocal edit commands such as Neutron's Dragon Naturally Speaking and the Microsoft Dictate function. However, these systems can be unintuitive because they require memorizing a fixed set of template commands. We know that a more natural and intuitive interface is possible when dictating to a human assistant even without agreed upon trigger words or commands. Humans can generally tell when you're commanding versus when you're dictating and what command you're invoking. Thus distinct from prior work, the interactive dictation task is characterized by the following key features: first flexible interleaving of dictation and editing not separated by a trigger word; second using intuitive and open-ended natural language utterances to specify edits. In summary, our contribution is threefold: first we introduce and formalize a new task, interactive dictation; second we design a data collection interface and build a dataset for this task; and finally we create a baseline system for this task. To begin, we formalize the task of interactive dictation as a four-step procedure. In the first step, an ASR recognition module parses raw audio into a speech transcript. Next, the speech transcript is segmented into separate dictation and command utterances. Third, each command is extracted and normalized, the ASR misdetctions and speech errors are fixed. Finally, each dictation and command utterance is executed in sequence until we arrive at the final document state. Note that in a real system, this all happens in real time as the user is speaking. Since this is a new task, we need to collect data. We need to collect our own data for which we design a new interface. So I'm going to transcribe the following email. I'm going to start by clicking Begin Transcription. Hey, I'm really sorry but I can't make it today. Note that this issued a dictation or insert text segment and whatever I said got transcribed both in this ASR field and also into the document state. Now I'm going to press the control button on my keyboard to issue a command. Change the comma after hey into an exclamation point. Okay, note that I just issued a command and unlike dictations, commands don't automatically show up in the document state. I must demonstrate the text, demonstrate the change using mouse and keyboard. Moreover, four commands, I can actually go into the ASR and fix it up. So I can keep doing this issuing commands and dictations in sequence until I've replicated this email. Using this annotation interface, we collect the dataset. More details about how these trajectories were collected can be found in the paper. Finally, we build a baseline system that performs each of these four steps. We train a model to perform each of these. We train a separate model to perform each of these steps. You can see the paper for more details but in particular, for the interpretation model, we experiment with two different architectures, T5 and GPT-3, and two different types of outputs. We either have the model predict programs that can be executed into the next state or we have it directly predict the next state. First, for the segmentation model, we see that it's both fairly accurate and efficient. Next, we evaluate the ASR repair and interpretation models directly, using exact match of the predicted end state against the gold end state. We find that there is a generally a trade-off between runtime and accuracy and that generally GPT-3 models are more accurate but also much slower. Furthermore, for GPT-3, GPT-3 models predicting state directly is much more accurate than predicting intermediate programs. For T5 model, this distinction is much less pronounced and predicting programs allows us to significantly improve efficiency with minimal impact on accuracy. As you can see, however, there's clearly much more room for progress here and we welcome more work on this task. To facilitate future work, we have released code at the following site. Please also check out the paper for more details.</sample>
    <sample id="302">Die Token für die Ausgabesequenz werden permutiert, um die richtigen Token in die richtige Reihenfolge zu sortieren.</sample>
    <sample id="303">Die Autoren empfehlen, dass Modellentwickler*innen ihre Methoden zum Abbau von Vorurteilen transparenter machen sollten, um die Ursachen für prägnante Mustern zu untersuchen und zu überprüfen, ob sie auf einen übertriebenen Wertealltag oder anti-Vorurteiler-Methoden zurückzuführen sind. Ohne Transparenz können die Ursachen nicht geklärt werden und es ist schwierig, effektive Methoden zur Bekämpfung von Vorurteilen zu finden.</sample>
    <sample id="304">Inakzeptable Minimalpaareingaben sind diejenigen, die Grammatikalität oder Akzeptabilität in Form von Stereotypen wie Sprachrollen enthalten.</sample>
    <sample id="305">The speaker, Dawe, a PhD student at Saarland University in Germany, introduces a video about their recent work on weakly supervised learning (WSL). They discuss the challenges of training neural networks on weakly labeled data, which can be noisy and lead to memorization rather than generalization. The video explores whether clean validation sets are necessary for WSL, how many clean samples are required, and if there are better ways to utilize clean samples. The findings suggest that WSL approaches require clean, manually annotated samples to work properly, and that the performance gain and practicality of WSL are often overestimated. The speaker recommends reporting model selection criteria, comparing WSL approaches with fine-tuning baselines, and considering continuous fine-tuning as a simple yet strong baseline.</sample>
    <sample id="306">The paper presents a study on the ability of language models to track entities in language. The authors argue that this is a crucial ability for understanding long discourses, but there have been no systematic investigations into whether pre-trained language models can perform such tasks. The research question addressed in the paper is to what extent large language models can track entities. The authors designed an evaluation task involving boxes and objects, where the input to the model starts with a description of the initial contents of each box, and the task of the language model is to complete the input by predicting the contents of each box. The authors found that most models simply repeat the initial state, while only text-davinci-03 excels at non-trivial tracking. They also found that all GPT 3.5 models exhibit non-trivial entity tracking behavior, whereas all models that do not have code as a substantial part of their pre-training do not.</sample>
    <sample id="307">Die Autoren haben die Performance der Modelle anhand von Public und Private Datasets bewertet, indem sie die Modelle an 11 Aufgaben wie Name and entity recognition, classification, part-of-speech tagging und question answering verglichenen.</sample>
    <sample id="308">Jenny, eine first-year PhD-Schülerin an Carnegie Mellon University, präsentiert heute ein Werk über die Positionalität in der Charakterisierung von Design durch Big-Data-sets und Modellen. Das Werk wurde in Zusammenarbeit mit Forschern an der University of Washington und dem AI-Stiftungsnetwork "Sebastian Santi, Roman Labroz, Katrina Rynica und Martin Sapp" erstellt. Jenny diskutiert die Systematische Leistungsunterschiede technologischer Werkzeuge zwischen Bevölkerungen und zeigt, dass diese Unterschiede auf die Positionalität der NL-P-Forscher und Modellentwickler zurückzuführen sind. Sie zeigt auch, dass Datensätze und Modelle die Meinungen und Ansichten von Menschen aggregieren und bestimmte Positionalitäten über andere vertreten können. Um dies zu untersuchen, haben sie eine Methode namens NL-Positionalität entwickelt, die die Annotationen mit realen Benutzern vergleicht. Sie haben über 16.000 Annotierungen von über 1.000 Annotatoren aus 87 Ländern gesammelt. Sie haben festgestellt, dass Datensätze und Modelle sich am besten mit englischsprachigen Ländern und Menschen mit College- oder Universitätsausbildung allignieren. Sie empfehlen, die Rechtsprotokolle zu pflegen, NL-P-Forschungen mit Blick auf Perspektivismus zu betreiben und spezialisierte Datensätze und Modelle für bestimmte Gemeinschaften zu erstellen.</sample>
    <sample id="309">Inter annotator agreement</sample>
    <sample id="310">Wikipedia</sample>
    <sample id="311">Die Autoren der Präsentation sind an der Technischen Hochschule Darmstadt.</sample>
    <sample id="312">MultiInstruct ist der erste MultiModell-Instruction-Tuning-Benchmarks-Datensatz, der 62 diverse MultiModell Aufgaben abdeckt, die in 10 Hauptkategorien unterteilt sind.</sample>
    <sample id="313">Zwei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="314">Die Definition der binären Koordination lautet: "Die binäre Koordination ist eine Art von Koordinationsstruktur, bei der zwei Elemente (meistens Wörter) in einem Satz durch einen Koordinationskonjunkt verbinden werden."</sample>
    <sample id="315">Die in dieser Studie verwendeten Prompts lagen im Durchschnitt bei 18 Wörtern.</sample>
    <sample id="316">Die Auswirkungen auf das kleinere T5-Modell sind positiv, da es die Qualität der generierten Skripte erheblich verbessert hat.</sample>
    <sample id="317">The speaker introduces a new method called CodeIE for transforming unstructured text into structured information extraction tasks. This method uses code pre-training language models like CodeT5 to generate structured outputs during the inference stage, aligning with the input format. The approach significantly outperforms traditional models on named entity recognition and relation extraction tasks, as demonstrated on the OntoNotes 5 dataset. The analysis reveals that CodeIE's performance is better due to its ability to handle structural errors and generate outputs with labels not present in the predefined label set.</sample>
    <sample id="318">Hallo, ich bin Yanis Lavrac und ich werde Ihnen heute unsere Arbeiten über Dr. Bert präsentieren, ein robustes Sprachmodell in Französisch für die Biomedizinische und klinische Domäne. In dieser Präsentation werden wir zuerst über Sprachmodellierung im Gesundheitswesen sprechen. Danach präsentieren wir die Hauptbeiträge unseres Artikels. Wir Introduzieren das erstmalige biomedizinische Modell in Französisch, Dr. Bert, das auf Roberta basiert und auf NACTOS trainiert wurde, einer Datensammlung von Medikamenten- und Krankenhausdaten aus der Web. Wir präsentieren auch einen Vergleich von Modellen mit verschiedenen Pretraining-Einstellungen und Datensätzen. Schließlich präsentieren wir unsere Resultate auf 11 biomedizinischen und klinischen Aufgaben im Französisch. Zum Schluss diskutieren wir über die Experimente und geben Ihnen mehr Details über, wie Sie den Modellen Zugang gewähren können. Seither es im Jahr 2018 freigegeben wurde, hat Bert sich zu einem der effektivsten Ansätze zur Bewältigung von Natural Language Processing-Aufgaben etabliert und einen großen Leistungsverlust gegenüber historischen statischen und konzektionären Methoden wie Word2Vec, FastText und Elmo aufwiesen. Seither wurde das Modell an viele andere Sprachen angepasst, wie zum Beispiel auf Französisch mit Camembert und auf verschiedenen Domänen wie biomedizinisch mit POMBERT und BioBERT und klinisch mit KLINICALBERT, aber hauptsächlich in Englisch. Spezialisierte Modelle für andere Sprachen sind seltener und oft aufgrund des Mangelns an in-domänenspezifischem Datensatz auf kontinuierliche Pretraining-basiertes Modell angewiesen. Allerdings gab es bislang keine offene Quelldatenbank für biomedizinische Aufgaben auf Französisch. Um diese Lücke zu schließen, fragten wir uns, welche Datensammlungen für eine Vielzahl von Anwendungsfällen geeignet sind, und diese kranken Daten als Ersatz für klinische Daten verwenden. Um diese Frage zu beantworten, verglichen wir Bert mit unserem Shubert-Modell, das auf anonymisierten Datensätzen aus dem National University Hospital Data Warehouse basiert. Wir fragten uns dann, wie viel Datendaten wir benötigen, um ein spezialisiertes Modell auf Französisch zu trainieren. Ist es 4 GB, 8 GB oder mehr? Um diese Frage zu beantworten, trainierten und verglichen wir vier von Grund aus neue Modelle: eine Erste Version von Bert mit 7 GB von NACTOS, eine Zweite Version von 4 GBsubset von NACTOS, eine Erste Version von Shubert, ein klinisches Modell mit 4 GB von Sätzen aus Kliniknotizen, und eine Endversion von Shubert mit einem Mix von 4 GBsubset von NACTOS und 4 GB von Kliniknotizen. Neben dieser Vergleichsstudie präsentierte man drei Modelle, die auf kontinuierliche Pretraining-basiertes Modell trainiert wurden, um die Auswirkungen von Pretraining-Strategien zu analysieren: eine basierend auf dem Gewicht von Camembert und trainiert auf 4 GBsubset von NACTOS, eine basierend auf Camembert, aber trainiert auf 4 GB von Kliniknotizen, und eine basierend auf einem englischen biomedizinischen Modell mit POMBERT und trainiert auf 4 GBsubset von NACTOS. Insgesamt haben wir insgesamt sieben Modelle. Um unsere sieben Modelle zu evaluieren, wurden sie an öffentlichen und privaten Aufgaben wie Namensentwicklung, Klassifizierung, Part-of-Speech-Segmentation und Question Answering übernommen.Diese Modelle wurden mit sechs Baseline-Modellen verglichen, die Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCNet 4 GB, POMBERT BioBERT und KLINICALBERT sind. Die Evaluierung zeigt, dass das Modell am besten auf der Aufgabe mit Datensätzen der gleichen Natur wie dem Modell trainiert wurde performt. Allerdings haben wir festgestellt, dass Datensätze aus heterogenen Quellen besser versiegelt sind. Wir haben auch festgestellt, dass mehr Datendata zu besseren Performen führt. Insgesamt scheint das von Grund aus neu trainierte Modell, Bert, auf 9 der 11 Aufgaben die besten Leistungen zu erzielen und global über die Leistungen des generischen Modells Camembert hinausgeht. Wir haben auch festgestellt, dass spezialisierte Datensätze besser sind, aber sie nicht so gut skaliert werden. Das Pretraining-Modell, das auf NACTOS basiert, ist frei zugänglich und auf Kaggle und alle Trainingsskripte sind auf unserem GitHub-Repository zu finden. Also, danke für die Präsentation und wir freuen uns auf das Treffen bei der Post-Session in Toronto.</sample>
    <sample id="319">Die Arbeit untersucht die Auswirkungen von verschiedenen Lernstrategien auf die Leistung von Modellen.</sample>
    <sample id="320">Der Faktor der Überanpassung, der auf die Wiederverwendung von Tests zurückzuführen ist, wird als "adaptive overfitting" bezeichnet.</sample>
    <sample id="321">Die Qualität der Vereinfachung wurde anhand der Typen von Vereinfachung bewertet, indem die Bibel文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本文本</sample>
    <sample id="322">The speaker, Enrico, is presenting at ACL 23 and discussing the challenge of teaching language models to understand morality in text. He explains that human morality is subjective and can be interpreted differently by different people. He introduces the moral foundation theory, which suggests that there are five different ways in which humans perceive morality, each with its own moral foundation. The speaker applies explainable AI techniques to language models trained to understand morality in text, using a dataset called Mora Foundation Twitter Corpus. He finds that language models can recognize differences in how morality is expressed across different domains, such as ALM and BLM. This highlights the importance of considering the domain-specific nuances of morality when training language models.</sample>
    <sample id="323">The paper discusses a method for answering questions in the Commonsense QA task using language models and knowledge bases. The authors propose a method that involves building an HKG (Hierarchical Knowledge Graph) based on a knowledge base, removing subwords to form a precise entity set, encoding QA contexts and entities into the HKG, and using a masked self-attention mechanism to update entity and relation embeddings. They also incorporate HKG path information into the QA context and use MLP (Multi-Layer Perceptron) to predict the final answer probabilities. The results of their experiments show that their method achieves good performance compared to other methods.</sample>
    <sample id="324">Ja, Sprachmodelle haben politische Vorurteile.</sample>
    <sample id="325">Hallo, mein Name ist Matthias Lendmann und heute werde ich Ihnen einen kurzen Einführung in unser Papier über kompositionale Generalisierung ohne Bäume mit Mehrstelle-Tagging und latenten Permutationen geben. Dies ist ein gemeinsames Projekt mit meinen Betreuern Alexander Koller und Ivan Titov. Kompositionale Generalisierung kann als die Fähigkeit eines Lerners verstanden werden, um tieferes Rekursion und unbekannte Kompositionen von Phrasen zu bewältigen, die während des Trainings individuell gesehen wurden. In Kontext des semantischen Parsings können Tests für kompositionale Generalisierung wie folgt aussehen: Wie usual haben wir eine Trainingssammlung von Ausdrücken, in diesem Fall "die Frau schläft" und "Mary weiß, dass die Frau schläft".Diese Ausdrücke werden mit logischen Formen Paarungen, die Hauptaspekte ihres Bedeutungsviels repräsentieren. Im Gegensatz zu Standard-Maschinelern-Evaluation-Sätzen enthält die Test-Sammlung strukturell unbekannte logische Formen. In diesem Beispiel hat das Modell während des Trainings Shallow-Rekursion gelernt und wird auf ein Beispiel mit tieferem Rekursionstestiert. Naive sequenz-to-sequence-Modelle kämpfen mit dieser Art von "out-of-distribution"-Generalisierung und produzieren oft Ausgaben, die vom Input abgefallen sind. In bestimmten Fällen scheitern sie, die systematischen Korrespondenzen zwischen Input und Output zu reproduzieren, wie jene, die in der Beispelkolorierung hervorgehoben sind. Ein beliebtes Verfahren, um dies zu beheben, ist die Integration von Bäumen in die Modelle. Die Bäume sind dazu bestimmt, die kompositionale Prozesse zu captur, die Verknüpfungen zwischen Ausdrücken und logischen Formen repräsentieren. Dies funktionsfähig, aber Bäume sind normalerweise nicht gegeben und müssen auf eine Art und Weise erhalten werden. Dies kann kompliziert und manchmal computationally teurer sein. Typischerweise impliziert dies eine betrachtliche Formalismus-Spezifische Voreinstellen der logischen Formen, zum Beispiel um zu handeln, variable Symbole zu behandeln. Das Abrufen von Bäumen kann auch involieren spezialisierte Grammatikinduktionsprozeduren. In diesem Papier verwenden wir keine Bäume und Introduzieren ein neuronales sequenz-to-sequence-Modell, das Direkt die Korrespondenzen zwischen Fragmente des Inputs und Fragmente des Outputs modelliert. Auf diese Weise können wir starke Generalisierungen zu tieferem Rekursionsschwergewichten without relying on Bäume. Unsere Ansatz vorhersagt den Output vom Input in zwei Schritten. Zunächst taggen wir jede Input-Tokenein unsortierter Multi-Sets von Token, die im Ausgang auftreten werden. Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht sortiert. Deshalb benutzen wir im nächsten Schritt einen anderen Modell, um die Permutation vorherzusagen, um sie in die richtige Reihenfolge zu sortieren. Wir Introduzieren ein neues Verfahren, um die Permutation vorherzusagen, das keine harten Beschränkungen auf die möglichen Permutationen macht. Dies macht unser Ansatz flexibel und ausdrucksstark. Konzeptionell unserem Permutationen-Modell arbeitet es so: Wir gehen von links nach rechts über den Ausgang und bestimmen, welches Multi-Sets Token in jeder Position platziert werden soll. Für die erste Ausgangsposition einfach einen aus dem Rot hervorgehobenen Token auswählen. Dann springen wir zu einem neuen Multi-Sets Token, um die nächste Token im Ausgang zu bestimmen. Wir bestimmen die dritte Token im Ausgang in einem ähnlichen Weise, indem wir zu einem anderen Multi-Sets Token springen. Wir fortfahren mit diesem Prozess, bis jedes Token aus dem ersten Schritt genau einmal besucht wurde. Um Ihnen einen Anreiz an unsere experimentellen Ergebnisse zu geben, hier vergleichen wir unser Verfahren mit anderen Bäume-frei-Modellen auf dem CoNLL Benchmark. Unser Modell überlebt die anderen um ein großes Abstand auf Generalisierung zu tieferem Rekursionsschwergewicht. Ein paar andere Arten von Strukturalisierungen bleiben sehr herausfordernd. In unserem Papier lösen wir ein paar interessante technische Herausforderungen. Zunächst einmal ist dieALIGN between Input und Ausgang nicht im Trainingsdatensatz gegeben. Als Folge davon, für einen bestimmten Token wissen wir nicht, welches Multi-Sets Token es stammt, was eine Herausforderung für die Trainingsschritte darstellt. In addition, manchmal gibt es mehrere Permutationen, die mit den Daten konsistent sind, aber die linguistisch korrekte ist latent. Wir bewältigen dies durch die Induktion derALIGN als Teil des Trainings. Unsere Permutation-Methode ist sehr flexibel, aber sie bringt die Herausforderung, dass die finden der höchsten Punktscores Permutationen NP-hard ist, da dies mit dem Travelling-Salesman-Problem verbunden ist. Wir approximieren dies mit einer GPU-friendlichen kontinuierlichen Relaxation, die uns auch erlaubt, durch die Lösung zu propagieren und linguistisch plausible Permutationen zu lernen. Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen bewältigen möchten, bitte haben Sie einen Blick auf unser Papier oder kommen zu unserem Poster.</sample>
    <sample id="326">Kognitive Dissonanz ist die Inconsistenz zwischen zwei Glaubens oder Handeln, die in einem Menschen vorkommt.</sample>
    <sample id="327">This paper presents a new multi-modal architectural model called Magi-Tower, which adapts the insights of pre-trained unimodal experts at different levels to facilitate more comprehensive cross-modal alignment and fusion. Magi-Tower uses managers in each cross-modal layer to gather and combine the insights of pre-trained unimodal experts, allowing for effective exploitation of different levels of unimodal semantic knowledge. With only 4 million images for visual-language pre-training, Magi-Tower achieves superior performance on various downstream tasks, outperforming Bridge-Tower by up to 39.15% accuracy on the Visual Genome Test Standard.</sample>
    <sample id="328">GPT-4 ist das am linksten stehende Sprachmodell.</sample>
    <sample id="329">The speaker introduces a method for generating structured pseudo-labels to improve video-to-text localization. They propose using pretrained image caption models to generate complex free-form pseudo-queries, which are then matched with video frames to create pseudo-events. These events are ranked based on their relevance and used as pseudo-labels to train the model, reducing label noise. The method outperforms existing zero-shot methods on two datasets, achieving state-of-the-art performance.</sample>
    <sample id="330">Ja, kumulatives Training ist besser als iteratives Training für aktives Lernen.</sample>
    <sample id="331">The speaker is Sarah Papi from the University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="332">Die Daten für die MuDa-Benchmark stammen aus Transcripts von TED Talks, die von Englisch ins Deutsche übersetzt wurden.</sample>
    <sample id="333">The paper introduces a new framework called Ink for injecting common knowledge into neural machine translation (NMT) models. It aims to improve the generalization ability of NMT by smoothing predictions according to nearest neighbors in the representation space. The framework consists of two steps: extracting common knowledge from a data store and using it to adjust the representation, then updating the data store with the refreshed representations. Experiments on the WMT 19 German-English news translation task show that Ink outperforms the state-of-the-art CM system and achieves the best performance after smoothing the representation space.</sample>
    <sample id="335">The name of the person is Mateus Lendemann.</sample>
    <sample id="336">Sprachübergreifender Transfer bezieht sich auf die Training von Modellen an einem Quellsprache und dann das Anwenden auf ein anderes Sprachmodell.</sample>
    <sample id="337">The presentation discusses the challenges of handling out-of-vocabulary (OOV) words in natural language processing and introduces a neural approach to improve word embedding. It explains how OOV words are represented using a word relationship graph that captures lexical rules and associations, and how a graph neural network processes this information. The model is trained to predict the number of nodes for each OOV word to reduce noise and incorporates a readout block to summarize the graph representation. The model's performance is demonstrated on both intrinsic and extrinsic tasks, showing its effectiveness in learning OOV words by word formation.</sample>
    <sample id="338">The speaker, Bing Chen, presents a research paper on the evaluation of human explanations in natural language processing. The paper proposes a new metric called "true" that extends the Simulatability Score to evaluate the helpfulness of explanations during fine-tuning. The study finds that human-annotated explanations can still benefit model predictions, even if they are considered low-quality by humans. The proposed metric outperforms the Simulatability Score in evaluating dataset qualities and task-specific characteristics. The work lays the foundation for high-quality human-robot collaboration annotation jobs and recommends researchers perform similar quality checks in the future.</sample>
    <sample id="339">Die Autoren sind an der University of Salzburg in Deutschland.</sample>
    <sample id="340">The presented work, ParaAMR, aims to construct a large-scale syntactically diverse paraphrase dataset by leveraging AMR (Abstractive Meaning Representations) graphs. The authors propose using AMR back translation to generate diverse paraphrases from a given sentence. They use a pre-trained AMR parser to obtain the AMR graph of the source sentence, change the focus node, and modify the corresponding edges and their labels. Then, they utilize an AMR graph-to-text generator to produce text from the modified graphs. The generated texts share the same AMR graph structure, ensuring similar semantics, but have different syntax due to the emphasis on the focus node at the beginning of the sentence. The proposed dataset, ParaAMR, consists of around 15 million source sentences with approximately 6.9 paraphrases per source sentence. The authors compare their dataset with those generated by back translation methods and present quantitative analysis indicating that ParaAMR has higher syntactic diversity scores while preserving good semantic similarity. They also demonstrate that ParaAMR can benefit several NLP applications, such as learning sentence embeddings, syntactic control paraphrase generation, and data augmentation for future learning.</sample>
    <sample id="341">Die Autoren verwenden die Messungen der Translation Quality, der Latenzmessung und der computational-aware Latenzmessung.</sample>
    <sample id="342">The speaker introduces a large-scale personalized dialogue dataset that automatically constructs from live streaming. The paper, conducted by the speaker and colleagues from Shanghai Jiao Tong University and Shaping AI, focuses on addressing the limitations of existing dialogue datasets in terms of scale, data sources, and annotation methods. The proposed dataset includes video sources and detailed persona annotations, which are crucial for developing applications like virtual streamers and virtual employees. The presentation also discusses the challenges in constructing such a dataset, including the need for effective matching mechanisms and the lack of personalized dialogue data for each persona. The experimental results show that the dataset outperforms existing open-domain dialogue datasets in terms of response modeling and address recognition tasks.</sample>
    <sample id="343">Hallo, alle. Ich bin Mackshatta und heute präsentiere ich mit Martin mein Werk "Kipmuster" an. Wir evaluierten die Integrität von mehreren Quellen. Das Werk ist eine Kooperation von McGill University, Mira und Microsoft Research. Natürliche Sprachverstehensmodelle ziehen auf eine Vielzahl von Kenntnisquellen, wie zum Beispiel Kenntnisse in den Parametern, die normalerweise durch vorheriges Training erworben wurden, und Kenntnisse, die in der Eingabezeit übermittelt werden. Kürzlich haben Arbeiten zu Aufgaben wie der Beantwortung von Fragen gezeigt, dass Modelle Kenntnisse aus der vorherigen Trainingphase verwenden können, um die Aufgabe zu lösen. Aber natürliche Sprachverstehensfähigkeit erfordert oft Kenntnisse, die auch zur Eingabezeit übermittelt werden. Zum Beispiel in der Aussage: "John sah den neuen gewählten Präsidenten auf TV." Vorausbildete Parameter können Informationen über das Amt des Präsidenten und was ein TV ist enthalten, aber sie können nicht sicher wissen, wer der bestimmte John ist oder wer der neue Präsident ist, da der Präsident seit dem Vorausbildtraining verändert wurde. Daher benötigen erfolgreiche Modelle für intellektuell-intensiven NLU-Aufgaben die Fähigkeit, sowohl Kenntnisse aus der vorherigen Trainingphase als auch Kenntnisse zur Eingabezeit zu integrieren und zu verwenden. In unserem Werk präsentieren wir einen Diagnostischen Test für Kenntnisintegration. Wir haben einen Aufgabentest erstellt, um zu beweisen, ob das Modell die Fähigkeit hat, Kenntnisse aus verschiedenen Quellen zu verwenden. Wir evaluieren die Datensammlung mit Menschenexperimentspunkten und etablieren Kenntnisintegrationsmodelle. Hier ist ein Beispiel aus der Datensammlung: "Servin ist ein Richter. Kia ist ein Bäcker. Servin und Kia haben sich an einem Park getroffen. Nach einem langen Tag im Gericht, bei der er Fälle im Gerichtssaal entschieden hat, war er glücklich, sich zu entspannen." Das Ziel hier ist, den korrekten Entity zu identifizieren, das das Pronomen "he" bezieht, was in diesem Fall Servin ist. Die Auflösung eines bestimmten Pronomens erfordert zwei Arten von Informationen: Erstens die spezifische Kenntnis, d.h. Servin ist ein Richter, und zweitens die Hintergrundkenntnis, d.h. Richter entscheiden Fälle im Gerichtssaal. Normalerweise wird Hintergrundkenntnis während des Vorausbildens von großen Sprachmodellen gelernt, während spezifische Kenntnisse normalerweise in der Eingabezeit beobachtet werden. Wir variieren die Verfügbarkeit dieser beiden Arten von Informationen so, dass sie entweder in einer Quelle oder in mehreren Quellen enthalten sind. Wir haben definiert, drei Einstellungen von Kipmuster: Erstens die "Vorausbild" Einstellung, bei der Hintergrundkenntnis angenommen wird, als sei sie zur Eingabezeit verfügbar. Zweitens die "Hintergrund sowohl" Einstellung, bei der Hintergrundkenntnis sowohl zur Eingabezeit als auch zur Vorausbildzeit verfügbar ist. Drittens die "Hintergrund Eingabe" Einstellung, bei der beide Kenntnisarten nur zur Eingabezeit verfügbar sind. Die letzte Einstellung ist insbesondere interessant, da sie die Situation simuliert, in der das Hintergrundkenntnis, das für die Aufgabe erforderlich ist, nicht Teil des Vorausbild-Datasets der Modelle ist. Zum Beispiel, weil neue Berufe seit dem Vorausbildzeitraum entstanden sind. Hier ist ein Beispiel, wie wir die Verfügbarkeit von Fakten in den Quellen kontrollieren: In der "Vorausbild" Einstellung nehmen wir an, dass das Hintergrundkenntnis "Politiker suchen Wahlmandate im Parlament" in den Vorausbildparametern enthalten ist. In einem Kontext der Eingabezeit liefern wir das spezifische Kenntnis "Chesterfield ist ein Politiker". In der "Hintergrund sowohl" Einstellung liefern wir neben dem spezifischen Kenntnis auch das Hintergrundkenntnis über Politiker in einem Kontext der Eingabezeit. In der "Hintergrund Eingabe" Einstellung liefern wir das fiktionalen Beruf "Mitarbeiter" anstelle von "Politiker", da "Mitarbeiter" unwahrscheinlich in den Vorausbildparametern enthalten ist. Wir evaluieren die Datensammlung sowohl mit Menschenexperimentspunkten als auch mit etablierten Kenntnisintegrationsmodellen. In diesem Bild zeigen wir die Ergebnisse der besten performing-Modelle auf dem schwierigsten Varianten der "Vorausbild" Einstellung. Ohne spezifisches Training auf Kipmuster bewältigen beide Modelle nicht gut. Wenn trainiert auf Kipmuster, hingegen, both C2F und BERT-KQR signifikant besser als zufällige Wahl performen. Dies zeigt, dass Modelle, die auf allgemeinen Kenntnisintegrationsdatensätzen trainiert wurden, lernen zu exploitieren, die Surfaceskue, die bei der Evaluierung auf Kipmuster nicht verwendet werden. Weitere Experimente mit fiktiver Kenntnis deuten darauf hin, dass selbst die besten performing-Modelle Schwierigkeiten haben, Hintergrundkenntnis zu integrieren, die nur zur Eingabezeit verfügbar sind. Umzusummarisieren die Haupttakeaways unseres Artikels: Viele Kenntnisintegrationsmodelle scheinen unfähig zu sein, Kenntnisse aus verschiedenen Quellen zu integrieren, ohne spezifisches Training. Allerdings, wenn spezifisch trainiert, können einige Modelle Kenntnisse aus mehreren Quellen integrieren. Trotzdem scheinen selbst die besten performing-Modelle Schwierigkeiten zu haben, Hintergrundkenntnis zu integrieren, die nur zur Eingabezeit verfügbar sind. Wenn Sie mehr Details wissen möchten, bitte our Paper und den Datensatz im Code auf GitHub überprüfen. Danke fürs Zuhören!</sample>
    <sample id="344">Die Nachteile der baumbasierten Methoden sind, dass sie meist nicht gegeben und daher zu erhalten sein müssen, was oft komplex und computationsintensiv ist.</sample>
    <sample id="345">The paper introduces a neural sequence-to-sequence model that directly models the correspondences between fragments of the input and fragments of the output. The model predicts the output from the input in two steps: first, it tags each input token with an unordered multiset of tokens that will appear in the output, and then it uses another model to predict a permutation to put them into the right order. The approach is flexible and expressive, and it outperforms other treeless models on generalization to deeper recursion. However, finding the highest scoring permutation is NP-hard, so the authors approximate this with a GPU-friendly continuous relaxation that also allows them to back-propagate through the solution and learn linguistically more plausible permutations.</sample>
    <sample id="346">Die Autoren der Studie "Do CoNLL 2003 Named Entity Taggers Still Work Well in 2023?" sind aus der University of California, Berkeley.</sample>
    <sample id="347">Hallo, ich bin Myra und heute werden wir über unser Papier "Marked Personas" sprechen, das die Verwendung natürlicher Sprachanregungen verwendet, um Stereotypien in Sprachmodellen zu messen. Dieses Werk wurde in Zusammenarbeit mit ESDermouch und Dan Jorowski erstellt. In jüngster Zeit haben viele die Vorgängigkeit von sozialer Diskriminierung und Stereotypien in großen Sprachmodellen (LLMs) festgestellt. Allerdings haben diese Messungen diverse Grenzen. Sie hängen normalerweise von von Hand konstruierten Datensätzen ab, die sehr zeitaufwendig zu sammeln sind, und sie messen normalerweise nur sehr spezifische Stereotypien, was bedeutet, dass sie nicht gut auf andere Demografien oder Kontexte übertragen werden, oder sie capturieren einfach eine allgemeine, breite Assoziation, wie beispielsweise negative Assoziationen mit bestimmten Gruppen. Darüber hinaus hat die meisten Arbeiten in diesem Bereich nicht für Intersektionalität gekauft, was die These ist, dass multifaktautierte soziale Identitäten die Biasse kompounden und ein einzigartiger Schaden darstellen können. Um diese Grenzen zu überwinden, vertrauen wir auf die Eigenschaft, dass diese neuen instruction-tune LLMs sehr gut auf Anweisungen und Anregungen reagieren können. Wir können also den Modell zu einem Persona anfordern, das eine beschreibung von einem imaginären Individuum ist, indem wir einen Anregung wie "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich." verwenden. Und wir können unmittelbar sehen, dass dies sehr allgemein zu allen Demografien anpassbar ist, da wir einfach den gewünschten Identitätsmerkmal in die Anregung einschließen können. Hier sind einige Beispielgenerierungen von GPT-4. Unmittelbar sehen wir, dass, während die Ausgaben nicht offiziell negativ oder toxikisch im traditionellen Sinne dieser Worte sind, einige interessante Muster auftreten. Eine asiatische Frau wird als unaussprechlich dargestellt, eine mittelorientalische Frau wird mit Worten wie "exotisch" und "bezaubernd" referiert und eine Frau mit Farbe wird Beziehungen zur Ancestry hergestellt, während der weißer Mann-Persona nichts von Art ist. Um diese Muster zu capturieren, haben wir zwei Teile. Der erste Teil ist die Generierung dieser Personas. Unsere Anregungen, um diese Personas zu generieren, wurden inspiriert von einer Studie, bei der sie diese Anregungen menschlichen Subjekten übertragen haben. Sie haben festgestellt, dass, wenn man sie Menschen überträgt, sie auch Racial-Stereotypien surfen können. Und auch dadurch können wir direkte Comparisons zwischen den von uns generierten Personas und den menschlich schriftlich responsiven machen. Der zweite Teil ist der Markwörter-Methode, die eine Methode ist, um die Worte zu identifizieren, die Markte Gruppe von unmarkierten Gruppen unterscheiden. Ich werde kurz darauf elaborieren. Die Vorteile davon sind, dass wir sehr spezifische Stereotypien und Muster finden, ohne uns auf einen bestimmten Lexikon zu verlassen. Der Markwörter-Methode basiert auf dem soziolinguistischen Konzept der Markiertheit, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die von diesem Standard abweicht, linguistisch markiert ist. Also zum Beispiel ist das Wort "Mann" (oder Entschuldigung, das Wort "Krieger") normalerweise mit Frauen verbunden, also wenn jemand einen Krieger, der ein Frau ist, beschreibt, wird normalerweise "eine Frau Krieger" und das Wort "Frau" markiert. Und allgemeiner: Dominante Gruppen in Gesellschaft sind sowohl linguistisch als auch sozial unmarkiert, während marginalisierte Gruppen normalerweise markiert sind. In unserem Methodenansatz erstellen wir zuerst die unmarkierten und markierten Gruppen und dann vergleichen die Personas mithilfe der Fighting-Wörter-Methode, die aufweighted Log odds-Ratios verwendet, um die Top-Wörter für jede markierte Gruppe zu identifizieren. Also zum Beispiel: für die Personas von Afroamerikanerinnen würden wir Fighting-Wörter machen und die Log odds-Ratios gegen beides weibliche Personas und Männer-Personas vergleichen, da jene die zwei entsprechenden unmarkierten Gruppen sind. Nun zu ein paar Ergebnissen. Zunächst verwenden wir ein Lexikon von Stereotypen und finden, dass die generierten Personas mehr Stereotypen enthalten als die menschlich schriftlich responsiven. Allerdings, wenn wir die Verteilung der Wörter im Lexikon ansehen, finden wir sehr unterschiedliche Dinge. Während die generierten Personas sehr hohe Raten von Lexikon-Wörtern aufweisen, haben die menschlich schriftlich responsiven eine weiträumige Verteilung von Wörtern, während die Stereotypen-Wörter, die in den generierten Personas enthalten sind, lediglich Wörter wie "tall" und "athletic" sind, also lediglich positive oder zumindest nicht-negative Wörter sind. Und in Wirklichkeit, das Lexikon fängt nicht viele der harmvollen Muster, die wir in den früheren Slides gesehen haben, gut ab. Stattdessen wenden wir uns an die Resultate von unserem Markwörter-Methode zu, um zu zeigen, wie diese positiv-scheinenden Porträt Wörter facilitieren Stereotypen und essentialisierende Erzähler. In our analysis, wir Revel how these seemingly positive Portraits reflect harmful patterns. First for Mark groups, the top words include things like culture, tradition, proud, and exotic, and these words define these groups only by their relationship to their identity and distinguish them as different from the white norm. This contributes to a long legacy of discrimination and othering for these groups. Furthermore, there is a lot of common tropes that are reflected in these words, especially for women of color. So for example, the words describing Latina women include things like vibrant and curvaceous, which connect to a trope of tropicalism. For Asian women, the words are things like petite and delicate and silky, which connects to a long history of Asian women being hypersexualized, seen as very docile and submissive, and so on. And finally, for Black women, we see that some of the top words are things like strong and resilient. This connects to an archetype that people have called the strong black woman archetype, and while it sounds like positive at first glance, there has been work showing that this kind of archetype actually is very harmful because it puts a lot of pressure on these demographics to be resilient and strong against societal obstacles. So rather than actually working towards changing those obstacles, it puts pressure on these people to overcome them, which leads to very negative health outcomes for these people among other harms. More broadly, we find that the words for each marked group pretty much just reflect very essentializing narratives. So based on these patterns, we conclude with three recommendations for model owners. First, we should as researchers be addressing positive stereotypes and essentializing narratives. We should also be using intersectional lens to study biases and harms, because there's a lot of things that might be overlooked if we don't do that. And finally, there should really be increased transparency about bias mitigation methods, because for instance, like these positive stereotypes, we don't know if it's because there is some sort of like weird overly excessive value alignment going on or maybe some other like anti-stereotyping methods that are resulting in these prinnish patterns. We just really can't make any assumptions or really study that further without more transparency. Thank you so much for listening. Have a good time at ACL.</sample>
    <sample id="348">The speaker, Maya, discusses a study on measuring stereotypes in language models using natural language prompts. The study, conducted with researchers from the University of Edinburgh and the University of Toronto, aims to address the limitations of previous methods by using instruction-tuned language models (LLMs) that can generate personas based on specific identity markers. The study identifies patterns in generated personas, such as the use of words like "exotic" for Middle Eastern women and "tall and athletic" for black men, which reflect harmful stereotypes. The marked words method is introduced to identify these patterns without relying on specific lexicons. The results show that generated personas contain more stereotypes than human-written ones, and that positive-seeming portraits can facilitate harmful narratives. The study concludes with recommendations for model owners to address positive stereotypes, use intersectional lens to study biases, and increase transparency about bias mitigation methods.</sample>
    <sample id="349">Hallo, alle. Mein Name ist Jing Wei, und ich bin von der Technologisch-Universität in China. Es ist mir eine Freude, einen kurzen Reklametafel über ein Papier zu präsentieren: "Are you copying my model? Protecting the copyright of large language models for embedding and services." Wir werden einen Watermark-Methoden vorgestellt, um die Copright-Privilegien von Einbettungs- und Dienstleistungen zu schützen.</sample>
    <sample id="350">Die Präsentation von Simon De Deyne und Kollegen diskutiert die Bedeutung von "superhuman performance" in der Naturwissenschaft (NLW) und warnt vor falschen Schlüssen, die auf unzulässigen Vergleichen zwischen Menschen und Modellen basieren. Sie analysieren zwei prominente Benchmark-Tests, SuperGLUE und Squad, und entdecken, dass Menschen oft auf einem kleinen Teil der Testdaten evaluiert werden und dass die "Menschliche Baseline" oft unzulänglich ist. Sie argumentieren, dass solche Vergleiche nicht zuverlässig sind und dass die Güte von Menschen stark von Motivation und anderen Faktoren abhängt. Sie empfehlen,Benchmark-Tests zu überarbeiten, um solche Mängel zu beheben und zu vermeiden, dass Ansprüche über die Überlegenheit von Modellen gegenüber Menschen getroffen werden.</sample>
    <sample id="351">Abstract: This paper investigates the generalization problem of named entity taggers using the CoNLL 2003 dataset. The authors developed a new dataset, CoNLL+, by collecting and annotating news articles from 2020 using the same guidelines as CoNLL 2003. They fine-tuned over 20 models on CoNLL 2003 and evaluated them on both CoNLL 2003 and CoNLL+. The results show that transformer models with larger size and more fine-tuning examples generalize better to new data. The main causes of performance drop are temporal drift and adaptive overfitting, which is not observed in this case. The paper concludes that for good generalization, better model architecture, larger model size, and more fine-tuning examples are needed.</sample>
    <sample id="352">ABC-Eval steht für "Annotating Behaviors in Chat" (Annotieren von Verhaltensmustern in Chats).</sample>
    <sample id="353">The paper introduces a method for Python code generation by asking clarification questions. The authors propose a task of generating code by asking clarification questions and focus on clarifying operation-level specifications. They also propose a method to create a synthetic dataset with clarifications on key operations and a pipeline of code generation by asking clarification questions. The authors evaluate their method using a dataset of code snippets and find that it performs well in identifying missing key operations. However, they also note some common errors and potential directions for improvement, including taxonomy and distinguishing aligned operations from operations with similar names.</sample>
    <sample id="354">Das Leistungs-Δ zwischen CoNLL-2003 und CoNLL++ ist bis 2021 höher als 5 Punkte.</sample>
    <sample id="355">Hallo, mein Name ist Vasudeva und ich bin ein Kandidat im Bachelor-Studiengang Computertechnik an der Stony Brook University. Ich möchte gerne mein Werk "Transfer Learning for Discourse Detection: Addressing the Rare Class Challenge" als Long Paper präsentieren, das ich in ACCL 2023 akzeptiert habe. Wir beginnen damit, kognitive Diskordanz zu definieren und warum es ein wichtiger Problem ist, sie in der Sprache zu studieren. Kognitive Diskordanz sind zwei Glaubens oder Handlungselemente, die inkonsistent sind. Ein Beispiel wäre, wenn jemand behauptet, dass Zigaretten tödlich sind, und dann einen Joint nach dem Treffen nimmt. Dieses Glaube und Handeln sind inkonsistent und sie sind in Diskordanz. Wir erwähnen auch, dass Diskordanz ein sehr gemeinsames Phänomen ist, das wir in unserem täglichen Leben beim Entscheidungsfinden erfahren. Diskordanz wird oft in Sprache ausgedrückt, insbesondere in anderen Arten von Diskursrelationen. Warum ist dies wichtig? Studium der kognitiven Diskordanz kann uns dabei helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends in Glauben, Werten und Einstellungen in einer Bevölkerung zu identifizieren. Hochgradige Diskordanz ist auch mit Angststörungen verbunden und kann dabei helfen, das mentale Gesundheit von Menschen besser zu verstehen. Das Studium von Diskordanz, das in Sprache ausgedrückt wird, kann auch dazu beitragen, Extremismus und Polarisation von schwachen Gruppen zu verstehen. Schließlich ist kognitive Diskordanz wichtig, um die individuellen kognitiven Stile von Personen zu verstehen und Entscheidungsprozesse besser zu verstehen. Um ein Ressource für kognitive Diskordanz zu erstellen, haben wir eine große Skalierung von Diskordanzrelationen durchgeführt. Wir haben die Diskordanz-First-Annäherung verwendet, wie in diesem Diagramm zu sehen. Tweets wurden mit einem Python-Parser analysiert und Paare von Diskursunits wurden nach den Richtlinien in einem Papier anhand von Diskordanz annotiert. Wie man sehen kann, wurde Diskordanz nur in 3,5 % der annotierten Paare gefunden. Nach der Sammlung von around 1000 Beispielen von Diskursunit-Paaren haben wir einen Trainingsdatensatz von 43 Beispielen erstellt. Der Initial-Classifier hat nicht viel besser als zufällig performiert, da die Diskordanz eine relativeRareität ist und keine vorherige Datensammlung existiert. Um dies zu überwinden, experimentieren wir mit Kombinationen von Transferlearning und aktiver Lernstrategie, um so viele Diskordanzbeispiele wie möglich zu sammeln, indem wir die Annotationskosten reduzieren. Da der ursprüngliche Modell nicht in der Lage war, die Diskordanzklasse zu ermitteln, beginnen wir den aktiven Lernprozess, indem wir Gewichtungen von nahe verwandten Aufgaben übertragen. Wir übertragen zwei verschiedene Aufgaben: Topik-unabhängige Diskordanzstelle-Klassifizierung, die bestimmt, ob zwei Aussagen von unterschiedlichen Personen in einem Streit oder in Übereinstimmung stehen, und die Binär-klassifizierung von Ausdehnung und Vergleichsklassen von PDB, da diese beiden Aufgaben eng mit der Konzeption von Diskordanz und Diskordanz verbunden sind. Wir finden, dass die Übertragung des Null-Shot-Performances auf den annotierten Datensatz schon viel besser als zufällig performiert, mit einem besten Modell mit AUC 0,62. Nach iterativer Optimierung beider Aufgaben finden wir, dass die Optimierung der CE-Aufgabe gefolgt von weiterer Optimierung der Streitstelle eine viel bessere Null-Shot-Performance liefert. Das ist der Modelltyp, den wir verwenden, um den aktiven Lernprozess zu starten. Wir bestimmen dann die beste Methode, um ein Modell mit neuen Daten von jeder Runde des aktiven Annotierprozesses zu aktualisieren. Die Kummulative-Strategie sammelt alle Daten von aktiven Annotierungen, während die Iterative-Strategie das Modell durch Training auf den neuesten Datensatz trainiert. Über die verschiedenen Strategien finden wir, dass die Kummulative-Strategie gleichermaßen oder besser als die Iterative-Strategie performiert. Um die Anzahl von Diskordanzbeispielen zu verbessern, verwenden wir die Wahrscheinlichkeit derRare-Klasse-Strategie (PRC) , um die meisten Beispiele zu auswählen, die most likely zu Diskordanz zu gehören, basierend auf der aktuellen Modellperformance. Wir vergleichen dies mit anderen modernen state-of-the-art-Strategien, die in der Gemeinschaft allgemein verwendet werden. Wir finden, dass die vorgeschlagene PRC-Strategie besser als andere modernen Strategien performiert, obwohl die Differenz relativ klein ist. Beachte, dass die Performance signifikant schlechter für Random-Strategie ist. Nach mehreren Runden des aktiven Annotierprozesses verbessern wir die Diskordanzkennung mit einem AUC von 0,75, was die beste Performance auf der Aufgabe ist. Wir überprüfen auch die Feasibilität jedes Strategie für Annotatorqualität und Kosten. Wir finden, dass PRC die höchste Quote von Diskordanz hat und am besten fürRare-Klasse arbeitet. Allerdings finden die Annotatoren die Beispiele schwierig. Insgesamt finden wir, dass PRC eine einfachen AL-Strategie fürRare-Klasse-Aquisition ist und das Kostendeutlich mit der korrekt gestalteten Transfer-LernAufgaben hilft. Wir finden auch, dass die Iterative-Update-Strategie nützlich ist, um Transfer-Lernung aus einem anderen Bereich zu übernehmen, da die in-Domain-aktiven Annotierungen von Kummulative-Updates profitieren. Hier sind die Links zu unserem Datensatz und unserem Papier. Fühlen Sie sich frei, uns zu kontaktieren, falls Sie Fragen haben. Vielen Dank.</sample>
    <sample id="356">Die Autoren gehören an der Humboldt-Universität zu Berlin.</sample>
    <sample id="357">The speaker's name is Si Yu Yan.</sample>
    <sample id="358">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="359">Der Ansatz wird mit dem Whitkey- und dem Local-Quadrat-Strategie verglichen.</sample>
    <sample id="361">This paper presents CounterComp, a method for improving compositional generalization in multi-step quantitative reasoning tasks. The authors propose using counterfactual scenarios to train models on a variety of question-answer pairs, allowing them to learn meaningful tokens and operations that can generalize to new questions. By adding an auxiliary metric learning loss with a dynamic margin, the model is encouraged to attend to more meaningful tokens during training. The results show that this approach consistently improves performance on both in-distribution and out-of-distribution samples, demonstrating the potential of CounterComp for enhancing the ability of language models to reason about complex quantitative data.</sample>
  </task>
</testset>