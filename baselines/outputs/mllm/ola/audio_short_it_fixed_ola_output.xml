<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="it">
    <sample id="0">I modelli linguistici sono addestrati su grandi quantità di dati web, tra cui notizie politiche.</sample>
    <sample id="1">I fornitori dell'articolo sono una collaborazione tra McGill University, Mira e Microsoft Research.</sample>
    <sample id="2">Hi. Welcome to our presentation of deeplain, a new corpus for german text normalization on the document level and on the sentence level.</sample>
    <sample id="3">My name is regina sturgeon and i will guide you through the first part of the presentation let's first define text simplification.</sample>
    <sample id="4">Text simplification is the process of adapting a text to improve the text comprehension of it for a specific target group as people with reading problems or non-native speakers.</sample>
    <sample id="5">Per addestrare un modello di classificazione di testi, è necessario avere coppie parallele di testi. Ad esempio, due documenti o due frasi.</sample>
    <sample id="6">In this example, here you can see a parallel aligned sentence pair of a complex German sentence and its translation into plain language.</sample>
    <sample id="7">Per semplificare la frase diverse tecniche sono possibili come si può vedere nell'esempio, come la sostituzione lessicale, la clausellazione, la clausellazione reordered o l'inserimento di parole.</sample>
    <sample id="8">Ora proponiamo i nostri nuovi corpi di legno per pianificare, perché in ultimi anni c'erano dei problemi con i corpi esistenti. Ad esempio, questi corpi attuali sono troppo piccoli per trainare un modello di testificazione.</sample>
    <sample id="9">The other three models which I propose in recent years are all automatically aligned, which means they can be over error-prone in their alignments.</sample>
    <sample id="10">Therefore we propose our new corpus Deplain, which is split into two subcorpora: Deplain-apa and Deplain-wap. Deplain-apa is based on news texts.</sample>
    <sample id="11">In Deep Plain API, we aligned four hundred and eighty three documents all manually. It results in roughly thirty thousand thirteen thousand parallel sentence pairs.</sample>
    <sample id="12">For deep plain web this corpus includes different domains and we also align all of these seven hundred fifty documents on the one hand manually and on the other hand with automatic alignment methods.</sample>
    <sample id="13">In totale, risultano in trenta mille e quattrocentoventi sentenze per</sample>
    <sample id="14">We analyze our sentence pairs a little bit more. So for example on the type of simplification,</sample>
    <sample id="15">Come puoi vedere qui, i testi della Bibbia sono molto più semplificati rispetto ad esempio i testi di notizie o i testi per gli apprendenti di lingua.</sample>
    <sample id="16">All'livello di, per esempio, lexical semplificazione, strutturale semplificazione o al livello globale di semplificazione.</sample>
    <sample id="17">Tuttavia, si può vedere che il dataset corporeo di DeepL ha una ampia varietà di diverse trasformazioni di semantica. Quindi, ad esempio, nel dataset di DeepL API corporeo, abbiamo molti più reorganizzazioni e traduzioni rispetto a quanto avviene nel dataset di DeepL Web corporeo.</sample>
    <sample id="18">On the other hand, in the web corpus we have much more rephrasing.</sample>
    <sample id="19">So let's now see what we can do with this corpus hello, i am omar and now i will talk about the use cases for our data set deeplink so for the first use case we can evaluate automatic alignment methods.</sample>
    <sample id="20">In recent years, there has been a lot of alignment methods but in the context of machine translations.</sample>
    <sample id="21">Dove abbiamo due documenti paralleli scritti in lingue diverse e vogliamo estrarre allineamenti di frasi tra i due documenti.</sample>
    <sample id="22">Ma nel nostro caso stiamo cercando di estrarre alleanze tra le frasi di due documenti paralleli che hanno lo stesso linguaggio, hanno lo stesso contenuto ma sono a un livello di complessità diverso.</sample>
    <sample id="23">E ora che abbiamo il dataset Deepplain, che ha frasi手动对齐的手写，我们可以使用这些句子作为标准的对齐来评估一些已提出的对齐方法。</sample>
    <sample id="24">And we did some adaptations to the proposed methods and we have published all these adaptations and the codes to run our experiments in the paper.</sample>
    <sample id="25">Al termine, si è concluso che il miglior algoritmo di allineamento automatico da usare per i testi di semplificazione del tedesco è il metodo di mass align.</sample>
    <sample id="26">E puoi anche trovare il codice per eseguire questo metodo sui propri documenti in Word.</sample>
    <sample id="27">The second use case that we showed in our paper is the case of automatic text simplification.</sample>
    <sample id="28">By fine-tuning language models to produce simplified text from complex input text.</sample>
    <sample id="29">We have fine-tuned two different models we have fine-tuned the model of long import to produce document-level simplifications.</sample>
    <sample id="30">E anche finetuned the normal base long the normal base import to produce sentence-level simplifications.</sample>
    <sample id="31">You can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper.</sample>
    <sample id="32">We concluded that this, this basic fine-tuning could produce or could get scores better than the baseline scores.</sample>
    <sample id="33">E proponevamo quei risultati come un punto di riferimento, una base di riferimento per il problema della semplificazione automatica dei testi in futuro.</sample>
    <sample id="34">Thank you so much for your attention and we hope to meet all of you during the conference. Thank you.</sample>
    <sample id="35">Il nome della relatrice o del relatore è Kai Yen.</sample>
    <sample id="36">Il modello utilizzato per ottenere l'accuratezza dell'82%-87% è il T5-XLARGE.</sample>
    <sample id="37">Sì, i tagger CoNLL-2003 funzionano ancora.</sample>
    <sample id="38">Il nuovo approccio proposto mira a ridurre la soggettività della valutazione umana rendendo più oggettiva la valutazione dei modelli rispondendo in modo chiaro se o no esprime certi comportamenti, come fornire informazioni non rilevanti o contradire se stessa.</sample>
    <sample id="39">Il successo dell'attuale approccio scarsamente supervisionato si basa in larga misura sulla necessità di campioni di validazione puliti per consentire all'algoritmo di apprendere e generalizzare adeguatamente. Se non ci sono campioni di validazione puliti, i modelli di addestramento non possono generalizzare al di fuori dei vizi esistenti, rendendo l'addestramento inutile.</sample>
    <sample id="40">I progressi che possono essere fatti per migliorare il punteggio sono quelli che riguardano la capacità di fornire informazioni accurate e pertinenti in risposta alle domande. Questo può essere fatto migliorando la comprensione del contesto e della lingua, in grado di riconoscere le entità menzionate e di fornire informazioni dettagliate e pertinenti in risposta alle domande.</sample>
    <sample id="41">Ci sono quattro autori coinvolti nell'articolo.</sample>
    <sample id="42">Hi, my name is Adam Strykowsky and this talk is about the dependency structure of coordination.</sample>
    <sample id="43">Come potete vedere, ci sono strutture di dipendenze diverse assunti da diverse teorie e approcci. Ad esempio, in universali dipendenze la struttura di coordinate coordinata Lisa, Bart e Maggie.</sample>
    <sample id="44">Is such that the first conjunct is the head of the whole coordinate structure, so in this case Lisa.</sample>
    <sample id="45">Approcci simili sono assunti in Igore Mil'utskii's meaning-text theory, dove di nuovo la struttura complessiva è guidata dal primo congiunto. Quindi questi due approcci sono isometrici, giusto? Essi singolano uno dei congiunti.</sample>
    <sample id="46">There are also symmetric approaches to co-ordinate structures, such as the prague approach, the conjunction headed approach, and the prague dependency treebanks where co-ordinate structures are headed by the conjunction.</sample>
    <sample id="47">So we get dependencies from end to all the conjuncts.</sample>
    <sample id="48">E finalmente c'è anche un approccio multi-headed che è usato, ad esempio, in De Cattsone's Word Grammar.</sample>
    <sample id="49">Where so to say all conducts are heads of the co-ordinate structures. So we get dependencies from the governor here laughs to all conduct separately. These are barton's</sample>
    <sample id="50">Ora, il Journal of the Paper è di produrre un nuovo argomento per le strutture simmetriche di coordinazione come queste due e contro le strutture asimmetriche di coordinazione come queste</sample>
    <sample id="51">Ok, l'argomento è basato sul principio di dipendenza elettro minimizzazione che ho spiegato sulla base di questi esempi.</sample>
    <sample id="52">Quindi in inglese come mi potete vedere, come potete vedere, i oggetti diretti preferiscono di stare vicino al verbo, mentre gli aggiunti possono stare più lontano. Giusto? Quindi, March read it yesterday è corretto, perché l'oggetto direttore è vicino al verbo.</sample>
    <sample id="53">While march read yesterday it is much worse right because here between the verb and the direct object there's an adjunct yesterday.</sample>
    <sample id="54">Tuttavia, questo effetto può essere attenuato quando um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um um</sample>
    <sample id="55">Questo è illustrato qui. Quindi entrambe queste frasi sono corrette. March ha letto questo libro absolutely fascinating su di noi ieri. Ok, allora invece di "it" ci hanno queste due lettere n e p.</sample>
    <sample id="56">But it's also okay to say, march ready yesterday, this absolutely fascinating book about bees.</sample>
    <sample id="57">La ragione qui è che questa è possibile perché anche se questa frase viola il principio grammaticale generale che gli oggetti diretti dovrebbero stare vicino al verbo,</sample>
    <sample id="58">It satisfies the principle of dependency length minimization, which says that shorter shorter dependencies are preferred.</sample>
    <sample id="59">Sono due alberi che solo mostriamo la lunghezza delle dipendenze cruciali, cioè le strutture che non sono costanti tra queste due strutture.</sample>
    <sample id="60">E qui abbiamo la dipendenza da red to the adjunct of length seven, misurato in parole e da red to book of length four. Quindi, in totale, è undici.</sample>
    <sample id="61">Quando si sposta o si scambia queste due costituenti, la somma di queste due dipendenze diventa sei. Giusto? Invece di undici, sei, molto più breve. Questo è il motivo per cui suona piuttosto bene. Giusto? Violenta uno principio, ma soddisfa un altro.</sample>
    <sample id="62">Ok, quindi cosa abbiamo fatto? Abbiamo estraendo statistiche molto importanti riguardanti la condivisione, dalla versione migliorata del Penc o del Penc Bank. Ecco il paper, per quale ragione non usare le stipendi universitari?</sample>
    <sample id="63">E queste statistiche confermano l'osservazione fatta molte volte prima che le congiunzioni destre tendono a essere più lunghe. Così, saltpetre e notpean salts misurati in sillabe.</sample>
    <sample id="64">E anche l'osservazione che è stata fatta in passaggio che questa tendenza cresce con la lunghezza della differenza</sample>
    <sample id="65">Quando la differenza tra le lunghezze dei due congiunti cresce, il congiunto più corto preferisce essere il primo, giusto? Quindi la proporcione è più grande per il congiunto più corto.</sample>
    <sample id="66">Ma, quello che è nuovo in questo articolo è che notiamo che questa tendenza si verifica solo quando i governanti di sinistra sono assenti.</sample>
    <sample id="67">So the governor is on the left in this example. I saw Bart and Lisa, so the governor is on the left.</sample>
    <sample id="68">It's absent in the second example. Homer came and sneezed. Here we have coordination of two verbs and there's no outside external governor. Right? So in such cases, the left conjunct prefers to be shorter than the more so the bigger the difference between the two conjuncts.</sample>
    <sample id="69">Tuttavia, quando i governanti di destra, come qui, lafayette governa la coordinazione tra le nazioni, questo effetto scompare.</sample>
    <sample id="70">So we showed that by measuring length in characters, the first column in syllables, the middle column in words, the right column so I'll concentrate on the right one.</sample>
    <sample id="71">What we see here is that when the governor is on the left,</sample>
    <sample id="72">La tendenza per il primo congiunto essere più corto cresce costantemente con la differenza assoluta in parole e lo stesso è osservato quando c'è un segno di coordinazione tra le frasi ma quando il segno è a destra questa tendenza scompare.</sample>
    <sample id="73">E in questo articolo mostriamo come queste strutture di coordinazione assimmetriche forniscano un argomento a favore delle strutture simmetriche.</sample>
    <sample id="74">So see the paper for the full agreement and arguments sorry and talk to us about at the poster session. thank you</sample>
    <sample id="75">C'è un articolo scritto da tre autori.</sample>
    <sample id="76">I domini della Bibbia e dei testi di apprendimento del linguaggio risultano più semplificati rispetto ad un testo di notizie.</sample>
    <sample id="77">Soltanto e non soltanto.</sample>
    <sample id="78">Sì, i modelli sono liberi di utilizzo e possono essere usati per la tua ricerca.</sample>
    <sample id="79">DEplain-apa è basato su testi di news.</sample>
    <sample id="80">Un modello architettura migliore, dimensioni del modello più grandi e esempi di finetuning più accurati.</sample>
    <sample id="81">La tendenza dei congiunti a sinistra a essere più brevi è stata misurata misurando la lunghezza in caratteri del primo colonna in sillabe, del medio colonna e del terzo colonna.</sample>
    <sample id="82">Gli esperimenti sono stati progettati per misurare la lunghezze dei caratteri nella prima colonna, nella seconda colonna e nella terza colonna rispettivamente. L'effetto della posizione del governatore è stato studiato in modo specifico sulla terza colonna.</sample>
    <sample id="83">Un classificatore base addestrato su dati non bilanciati non è efficace, poiché non ha accesso a un sufficiente numero di esempi di ciascuna classe.</sample>
    <sample id="84">Mi dispiace, non ho accesso all'articolo specificato. Tuttavia, se stai cercando informazioni su un articolo specifico, ti consiglio di consultare il testo dell'articolo o i riferimenti per vedere quanti autori sono coinvolti.</sample>
    <sample id="85">Bob e Alice</sample>
    <sample id="86">I modelli di MT sensibili al contesto migliorano rispetto a quelli indipendenti dal contesto su fenomeni del discorso come formalità e coesione lessicale.</sample>
    <sample id="87">I fornitori dell'articolo sono affiliati a diverse istituzioni, tra cui la University of Edinburgh, la University of Cambridge e la University of Oxford.</sample>
    <sample id="122">Il framework quantifica esattamente la posizionalità utilizzando un punteggio di correlazione di Pearson per confrontare le annotazioni demografiche con le previsioni e le etichette dei modelli e dei set di dati.</sample>
    <sample id="155">Il risultato dello studio precedente è stato che i soggetti umani hanno anche potuto rivelare stereotipi razionali quando gli hanno stati forniti gli stessi prompt di persona.</sample>
    <sample id="156">In questo studio, le fonti di dati utilizzate sono le statistiche estratte dal versione migliorata del banco dei beni e le pubblicazioni universitarie.</sample>
    <sample id="157">Il numero di autori coinvolti nell'articolo non è specificato nella descrizione fornita.</sample>
    <sample id="158">Le attività strettamente correlate alla dissonanza cognitiva sono la classificazione di dichiarazioni di posizione politica e la classificazione di espansione e comparazione.</sample>
    <sample id="159">Il numero di autori coinvolti nell'articolo non è specificato nella descrizione fornita.</sample>
    <sample id="160">Il numero di autori che hanno partecipato all'articolo non è specificato nella descrizione fornita.</sample>
    <sample id="161">Il framework differisce dai precedenti studi in quanto confronta i modelli e i dataset con le previsioni e le etichette, invece di concentrarsi solamente sull'acordo tra gli annotatori o le distribuzioni degli annotatori.</sample>
    <sample id="162">La configurazione generata da un modello di linguaggio si sovrappone maggiormente al lessico degli stereotipi rispetto alle due configurazioni umane.</sample>
    <sample id="163">I sistemi commerciali che sono stati confrontati sono DeepL e Google Translate.</sample>
    <sample id="164">Ciao, mi chiamo Changbing, sono uno studente di PhD all'Università di Washington. Oggi sto presentando il nostro lavoro, che va dal training dei dati fino ai modelli di linguaggio e fino alle compiti di basso livello, monitorando le tracce di bias politici che portano a modelli NLP non equi.</sample>
    <sample id="165">I modelli di linguaggio sono addestrati su grandi quantità di dati web.</sample>
    <sample id="166">I media di notizie politiche sono bene rappresentati nei loro dataset di addestramento. Secondo un sondaggio del C4F, possiamo vedere che New York Times, Los Angeles Times, The Guardian, Huffington Post ecc. sono bene rappresentati nel dataset di addestramento linguistico.</sample>
    <sample id="167">Questo ha creato un mix blessing per le applicazioni dei modelli di linguaggio.</sample>
    <sample id="168">Sul lato di un lato, erano in grado di imparare da diverse prospettive che celebrano la democrazia e la pluralità di idee sul lato opposto, queste diverse opinioni politiche sono inerentemente socialmente biased e potrebbero portare a problemi di giustizia potenziale in applicazioni di task sottoposti.</sample>
    <sample id="169">Per raggiungere questo scopo, proponiamo di indagare la catena di propagazione dei bias politici dal dataset di addestramento alla lingua e alle compiti di basso livello, in modo specifico chiedendo le domande seguenti:</sample>
    <sample id="170">Prima di tutto, come valutiamo la linearità politica dei modelli linguistici e in che modo i dati pretrainati potrebbero influenzare queste bias politici?</sample>
    <sample id="171">Secondariamente, come i modelli di linguaggio con diverse politiche dei limiti si comportano su compiti di downstream e se tale comportamento potrebbe portare a problemi di equità in applicazioni NLP?</sample>
    <sample id="172">Sono in particolare, propone di stimare modelli di linguaggio con diverse formattazioni di prompt utilizzando domande politiche come il test di competenza politica. Questo ci assicura di poter effettuare una valutazione automatica ben fondata nella letteratura di scienze politiche.</sample>
    <sample id="173">Quindi, i risultati preliminari dimostrano che i modelli di linguaggio hanno vari inclinazioni politiche. Occupano tutti e quattro i quadranti del compasso politico.</sample>
    <sample id="174">Possiamo anche vedere che GPT-4 è il modello linguistico più liberale tra tutti e che le serie GPT sono in generale più liberali rispetto alla serie BERT e le sue variazioni.</sample>
    <sample id="175">Secondariamente, ci siamo proposti di indagare fino a che punto i bias politici dei modelli di linguaggio vengono davvero presi in considerazione dalla nostra addestrata.</sample>
    <sample id="176">Siamo in grado di condurre un esperimento controllato, pretrainando i modelli di lingua su sei gruppi differenti separati in notizie e social media, ulteriormente suddivisi in base alla loro orientazione politica.</sample>
    <sample id="177">Inoltre, pretrainare modelli di linguaggio su particolari corpus può far vedere che le coordinate ideologiche del modello si spostano corrispondentemente.</sample>
    <sample id="178">For example, for roberta further fine-tuning further trained on the left-leaning reddit corpus we can see a substantial liberal shift in terms of its</sample>
    <sample id="179">In termini di bias politici.</sample>
    <sample id="180">E anche provare a indagare se i modelli di linguaggio possono catturare la polarizzazione che è prevalentissima nella nostra società moderna.</sample>
    <sample id="181">Siamo divisi pretraining corpus in pre 45° Presidente degli Stati Uniti e dopo 45° Presidente degli Stati Uniti. Separatamente pretrainiamo modelli di linguaggio sui due differenti tempi corpus.</sample>
    <sample id="182">Possiamo vedere che i modelli di linguaggio in genere hanno un orientamento politico che è più distante dal centro dopo il 2017. Quindi, questo indica che i modelli di linguaggio possono anche prendere iniziata la polarizzazione nella nostra società.</sample>
    <sample id="183">Quindi, nonostante tutto, valutiamo i modelli di linguaggio con diverse inclinazioni politiche in quanto alla rilezione di discursi odiosi e di notizie fake, due applicazioni NLP che spesso coinvolgono modelli di linguaggio e possono avere implicazioni molto significative.</sample>
    <sample id="184">So we see that if we investigate the per category performance, that is to say, if we separate the performance into</sample>
    <sample id="185">Different demographics or political leaning of news media we can see a pattern that for example for hate speech detection, left-leaning language models are better.</sample>
    <sample id="186">At detecting hate speech targeting socially minority groups,</sample>
    <sample id="187">However, our worst at detecting hate speech targeting more powerful groups in our society.</sample>
    <sample id="188">E viceversa, i modelli di linguaggio ritaliano sono migliori nel rilevare la discriminazione razziale che targetta i bianchi e gli altri, tuttavia peggiori nel rilevare la discriminazione razziale che targetta le altre comunità minoritarie come i neri, i transessuali e gli LGBTQ+.</sample>
    <sample id="189">Simili tendenze si verificano anche per la deteczione dei falsi notiziari, in cui si notano che i modelli di linguaggio sinistra sono migliori nel rilevare la menzogna dai politici di destra e viceversa.</sample>
    <sample id="190">This in we further show many qualitative examples to see that language models with different political leanings,</sample>
    <sample id="191">Devo dare diverse predizioni per esempi di discorso razzista e informazione sbagliata basati sulla propria classe sociale. Ci sono un sacco di esempi in appendix per sottolineare meglio</sample>
    <sample id="192">Questo indica che c'è un problema di giustizia che è molto rilevante riguardo le bias politici dei modelli di linguaggio.</sample>
    <sample id="193">Ad esempio, se i modelli di lingua rilasciati dovessero essere finetuned per rilevare l'insincerità o le informazioni sbagliate e successivamente distribuiti su piattaforme social come Twitter,</sample>
    <sample id="194">Questa sarebbe significato che le persone con opinioni politiche opposte potrebbero essere marginalizzate e che il discorso di odio che colpisce gruppi minoritari potrebbe continuare senza alcun controllo.</sample>
    <sample id="195">Sì, questa ha suonato l'alarme per noi di riconoscere e affrontare i problemi di giustizia derivanti da modelli linguistici politicamente orientati.</sample>
    <sample id="196">So a little bit of discussion. we would also like to highlight that we expose the unique dilemma regarding language, multi-political biases. it's like between cila and kurbidis.</sample>
    <sample id="197">Se non sanizziamo le opinioni politiche in un dataset di addestramento linguistico, i bias potrebbero propagarsi da un dataset di addestramento a modelli linguistici e quindi a compiti di basso livello, creando problemi di giustizia.</sample>
    <sample id="198">Se dobbiamo tentare di sanitizzare in qualche modo, dobbiamo anche correre il rischio di censure o esclusione e è incredibilmente difficile determinare cosa è realmente neutra e dovrebbe essere retained in linguaggio monitorato da data. Quindi è come un problema di elettricità elettrica.</sample>
    <sample id="199">Okay, great. I think that's pretty much all I have to do. I'll be for today. Thank you for your time.</sample>
    <sample id="200">Il numero di autori coinvolti nell'articolo non è specificato nella descrizione fornita.</sample>
    <sample id="201">Le valutazioni MPP sono state eseguite fino a 1204 token di lunghezza del contesto.</sample>
    <sample id="202">Il loro set di dati include diverse esempi, tra cui un esempio senza parole, un esempio con un bambino di 12 anni o uno fictizio, e un esempio che provenire da Azerbaijani.</sample>
    <sample id="203">La posizionalità è la prospettiva che le persone hanno come risultato dei propri demografici, identità e esperienze di vita.</sample>
    <sample id="204">Il nome del relatore o della relatrice non è specificato nella descrizione fornita.</sample>
    <sample id="205">Sì, il modello ST offline esistente è adattato utilizzando solo un modello per ogni regime di latenza e gestendo la latenza tramite parametri specifici.</sample>
    <sample id="206">Il contenuto inglese non fornisce informazioni su quanti autori sono coinvolti nell'articolo.</sample>
    <sample id="207">No, il modello non funziona sulla suite di test.</sample>
    <sample id="208">Le tre varianti di KITMUS sono: 1) Setting con background pretrain, dove la conoscenza è supposta essere disponibile solo durante il tempo di pretrain; 2) Setting con background entrambe, dove la conoscenza è disponibile sia durante il tempo di pretrain che durante il tempo di inferenza; 3) Setting con background inferenza, dove entrambe le tipologie di conoscenza sono disponibili solo durante il tempo di inferenza.</sample>
    <sample id="209">I fornitori di servizi di calcolo hanno affiliazione con l'IST.</sample>
    <sample id="210">La terza domanda di ricerca è: "Sono necessari solo i campioni puliti per la validazione o ci sono altre migliori modalità per utilizzarli?"</sample>
    <sample id="211">La sensibilità della metrica misura la capacità del modello di produrre gli stessi output per la stessa attività anche con una variazione nella formula di istruzione.</sample>
    <sample id="212">Il nome della relatrice o del relatore è Jing Wei Yi.</sample>
    <sample id="213">Una maggiore sensibilità indica una performance del modello migliore.</sample>
    <sample id="214">I modelli di lingua vengono addestrati su un contesto linguistico vasto e diverso.</sample>
    <sample id="215">In genere, si possono ottenere prestazioni elevate con soltanto 20 campioni di convalida puliti per classe.</sample>
    <sample id="216">I fornitori dell'articolo sono in collaborazione con Essin Dermush e Dan Juravsky.</sample>
    <sample id="217">È necessario sviluppare nuovi metodi per misurare i bias dell'informazione perché i modelli di linguaggio hanno vari politici inclinazioni che occupano tutti i quadranti del compasso politico.</sample>
    <sample id="218">Il nome della relatrice o del relatore è Matcha.</sample>
    <sample id="219">L'infrastruttura di propagazione dei bias politici ha un aspetto che celebra la democrazia e la pluralità di idee, ma anche un aspetto che potrebbe portare a problemi di giustizia nella programmazione di compiti di downstream.</sample>
    <sample id="220">Sì, il processo di semplificazione differisce per DEplain-apa e web.</sample>
    <sample id="221">Il testo non fornisce informazioni su se il co-scrivere è disponibile pubblicamente o no.</sample>
    <sample id="222">La filigrana viene inserita esattamente quando il numero di trigger nel testo è maggiore di M.</sample>
    <sample id="223">I fornitori dell'articolo sono affiliati all'University of Pennsylvania.</sample>
    <sample id="224">Sì, i modelli codificatore-decodificatore come mt5 possono migliorare con l'addestramento su una combinazione di lingue.</sample>
    <sample id="225">Un esempio di pianificazione linguistica vincolata è la creazione di un dolcetto al cioccolato.</sample>
    <sample id="226">Gli autori si accertano della segretezza del loro metodo validando la covertura dell'involucro fornendo un esempio di embedding di frasi su Vowpal Pca.</sample>
    <sample id="227">Il lavoro utilizza i PLM esistenti per costruire uno nuovo in modo che possa analizzare l'effetto delle strategie di pretraining.</sample>
    <sample id="228">GPT-4 è meno allineato con i paesi che non parlano inglese.</sample>
    <sample id="229">La relatrice mostra il modo in cui il modello sfrutta la conoscenza appresa attraverso il meccanismo dell'attenzione nella frase "and you can see an example on the right".</sample>
    <sample id="230">La quantità di attività aumenta la performance del modello.</sample>
    <sample id="231">I tre approcci di riferimento con cui gli autori confrontano il loro metodo sono i modelli TreeLSTM, i modelli TreeRNN e i modelli TreeLSTM con structural regularization.</sample>
    <sample id="232">I due coautori hanno un rapporto di collaborazione con il primo autore.</sample>
    <sample id="233">Il contenuto non fornisce informazioni su chi sia il primo autore di PaLM.</sample>
    <sample id="234">Ciao a tutti, mi chiamo Jenny, sono una studentessa di primo anno di laurea in Ingegneria dell'Informazione all'Università Carnegie Mellon e oggi presenterò il mio lavoro sull'ottimizzazione caratterizzata da dataset di modelli.</sample>
    <sample id="235">Questo lavoro è stato fatto in collaborazione con alcuni studiosi all'Università di Washington e l'Alumni Institute for AI, cioè Sebastian Santi, Ronin LeBross, Katrina Iriyekina e Martin Sapp.</sample>
    <sample id="236">Allora, iniziamo da un'immagine che stai scrivendo un articolo per un giornale e stai cercando di rimuovere il contenuto tattico tra i commenti.</sample>
    <sample id="237">Potresti ricorrere a un API popolare come l'API di Perspecktive per la rilevazione del tossicità e quest'ultima funziona davvero bene se sei Karl Jones dove l'API di Perspecktive è in grado di rilevare correttamente le istanze tossiche.</sample>
    <sample id="238">Ma non è proprio così per Dithia Sharma, dove l'AI non è particolarmente sensibile a termini più comuni in contesti indiani.</sample>
    <sample id="239">Ecco un esempio di bias nel design, dove vediamo differenze sistematiche nel rendimento delle tecnologie tra popolazioni.</sample>
    <sample id="240">Le bias di progettazione come quelli che abbiamo appena visto prima potrebbero essere dovuti alla posizionalità dei ricercatori e dei sviluppatori di modelli NLP. La posizionalità è semplicemente le percezioni che le persone hanno come risultato dei propri demografici, identità e esperienze di vita.</sample>
    <sample id="241">Questo è un concetto ampiamente usato in studi critici, specificamente in ambienti accademici femministi e queer.</sample>
    <sample id="242">E come ricercatore, la propria posizionalità può influenzare il processo di ricerca e i suoi risultati, poiché è capace di modificare le decisioni che i ricercatori prendono.</sample>
    <sample id="243">E quindi una domanda che le persone potrebbero fare è: hanno i set di dati e i modelli posizionalità?</sample>
    <sample id="244">E non stiamo cercando di dire che i modelli in sé stessi e i dataset in sé stessi hanno identità demografiche e esperienze della vita, ma essi possono aggregare giudizi e opinioni di persone reali e possono dunque rappresentare certe posizionalità su altre.</sample>
    <sample id="245">So, prior work has suggested some anecdotal evidence of having positionality such as cultural gaps in models and datasets as well as theoretical definitions of model positionality.</sample>
    <sample id="246">Tuttavia, queste works non sembrano considerare il confronto tra gli utenti e i datasets e i modelli stessi.</sample>
    <sample id="247">Studiare modello e dataset positonality è sempre più importante, poiché i test NLP diventano sempre più soggettivi e orientati socialmente.</sample>
    <sample id="248">E è difficile caratterizzare come queste posizionalità siano sbiassistantate, poiché non tutti i decisioni sono documentati e molti modelli sono nascosti dietro api.</sample>
    <sample id="249">Così per studiare la posizionalità dei dataset e dei modelli, confrontiamo le annotazioni con quelli degli utenti reali con i dataset e i modelli esistenti.</sample>
    <sample id="250">Facciamo questo attraverso il framework NLP positionalità.</sample>
    <sample id="251">Il framework funziona in due passi principali.</sample>
    <sample id="252">Il primo passo è re-annotare i set di dati con diverse annotatori.</sample>
    <sample id="253">E optiamo di fare questo analizzando le statistiche dei set di dati originali annotatori, poiché di solito solo un paio di annotatori annotano ogni istanza e poiché le statistiche sono raramente raccolte e condivise.</sample>
    <sample id="254">E quindi ci optiamo per rinnovare i dati per ottenere molte annotazioni per un esempio e per ottenere un insieme ricco di dati demografici.</sample>
    <sample id="255">Poi prendiamo le annotazioni per demografia e le confrontiamo con i modelli e i set di dati utilizzando il coefficiente di correlazione di Pearson.</sample>
    <sample id="256">Ecco, il nostro framework differisce dalla letteratura di disaccordi degli annotatori in quanto confronta utenti finali con modelli e dataset, previsioni e etichette, invece di concentrarsi solo sull'inter-annotatore accordo o la modellazione delle distribuzioni degli annotatori.</sample>
    <sample id="257">Our framework is largely enabled through Lab in the Wild an online crowdsourcing platform former HCHI collaborator.</sample>
    <sample id="258">In Lab in the Wild è un piattaforma online di esperimentazione che ci permette di reclutare diversi volontari rispetto ai piattaforme come MTurk, che hanno maggiormente partecipanti provenenti dagli Stati Uniti o dall'India. Inoltre, Lab in the Wild è in grado di ottenere anche dei dati di alta qualità.</sample>
    <sample id="259">We host two tasks on lab of the wild, one of them being social acceptability and the way this works is that participants will read a situation from the social chemistry data set and then they'll rate how socially acceptable a situation is.</sample>
    <sample id="260">Successivamente, per rimanere in contatto con la città, possono confrontare le risposte con un ai e con gli altri.</sample>
    <sample id="261">We then compared these annotations with social chemistry, delphi and qpd four.</sample>
    <sample id="262">We then replicate a very similar setup for the toxicity and hate speech detection task where they'll read an instance from datanite and write whether they think it's instance of hate speech.</sample>
    <sample id="263">We then compared these annotations with dina hate, perspective api, rewriter api, hate roberta and gbd4 our study in the end amassed over sixteen thousand annotations from over a thousand annotators from eighty seven countries.</sample>
    <sample id="264">So now we're better equipped to answer who do nlp datasets and models align with the most we find that there is positionality in nlp.</sample>
    <sample id="265">Ad esempio, notiamo che i set di dati e i modelli sono più legati ai paesi che parlano inglese. Quindi, per l'analisi di accettabilità societaria del GDP4, scopriamo che è più legato ai paesi che parlano confuciano e inglese. Troviamo anche che Dina Hatt è altrettanto legata ai paesi che parlano inglese.</sample>
    <sample id="266">We also find most additional alignment with people who have a college education. So for gpd four in the social acceptability task, we find that it's most aligned to people with a college education or graduate school education.</sample>
    <sample id="267">E troppo simile per Donnied Hite, dove è maggiormente allineato con le persone che hanno un'istruzione universitaria.</sample>
    <sample id="268">Tuttavia, quando i modelli e i set di dati sono allineati a specifici popolazioni, alcune sono inevitabilmente lasciate indietro.</sample>
    <sample id="269">Un esempio di questo è che i dataset e i modelli sono meno simili ai non binari rispetto ai controparti maschi e femminili. Lo notiamo anche nel task di accettabilità sociale GPD4 e nel task di analisi di dinehate.</sample>
    <sample id="270">So given that there is position in nli and nlp, what can we do about it?</sample>
    <sample id="271">Siamo d'opinione che ci siano poche raccomandazioni per questo. La prima è di tenere un registro di tutti i design rilevanti durante il processo di ricerca e l'altra è di fare ricerche NLP con un'ottica di prospettivismo.</sample>
    <sample id="272">La nostra terza raccomandazione è di costruire insiemi di dati specializzati e modelli specifici per comunità. Un esempio di questo è l'iniziativa Musaikani. Vogliamo sottolineare che NLP inclusivo non è solo un modo di far funzionare tutte le tecnologie per tutti.</sample>
    <sample id="273">E così, quello conclude la nostra presentazione. Ma se volete imparare di più, vi prego di controllare il nostro dashboard per i risultati più aggiornati dell'analisi e il nostro articolo. Grazie mille!</sample>
    <sample id="274">La relatrice menziona tre problemi associati a SimulST: i modelli specifici di architettura sono usualmente addestrati introducendo moduli aggiuntivi da ottimizzare, i procedimenti di addestramento sono lungi e complicati, ad esempio addestrare coinvolgendo diverse obiettivi di ottimizzazione e addestrare e mantenere diversi modelli per raggiungere differenti regimi di latenza, ad esempio addestrare un modello con un'average di 1 secondo di latenza e un altro modello con 2 secondi di latenza e così via.</sample>
    <sample id="275">Non c'è un modo sicuro per mitigare i bias sociali e politici nei set di dati durante l'addestramento dei modelli di NLP. Tuttavia, è importante sottolineare che la sanitizzazione dei set di dati non è sufficiente per eliminare completamente i bias.</sample>
    <sample id="276">Hi, I'm Si Yu Yan from Fudan University. I'm here to introduce our work distinguishing script knowledge from large language models for constrained language planning.</sample>
    <sample id="277">In everyday life, humans often plan their actions by following step-by-step instructions in the form of guaranteed scripts.</sample>
    <sample id="278">Un precedente lavoro ha sfruttato modelli di linguaggio per pianificare azioni astratte di attività stereotipate, come fare un pasticcino, e dimostrato che i modelli di linguaggio possono efficacemente decomporre le azioni in passaggi.</sample>
    <sample id="279">Tuttavia, i precedenti studi hanno maggiormente focalizzato sul pianificare per gli obiettivi astratti di azioni teoretiche pianificando per gli obiettivi con specifici obiettivi specifici vincoli come fare un pasticcio di cioccolato rimane sottostudiato.</sample>
    <sample id="280">In this paper, we define the problem of constrained language planning.</sample>
    <sample id="281">Che impongono diverse limitazioni al processo di pianificazione un obiettivo generale può essere ereditato da diversi obiettivi specifici reali con constraint multi-fattori un buon pianificatore dovrebbe redigere script che sono ragionevoli e fedeli alle limitazioni.</sample>
    <sample id="282">In questo articolo, valutiamo e miglioriamo la capacità di pianificazione del linguaggio dei modelli di lingua grande.</sample>
    <sample id="283">Se no, data sottile o speciale di gusto esiste per spostare i nostri standard.</sample>
    <sample id="284">We have to acquire this goal first as shown in the table we extend the abstract goal with multi-faceted constraints for humanising the loop data acquisition use instruct GPT.</sample>
    <sample id="285">We sample one hundred specific goals and evaluate the scripts generated from large language models.</sample>
    <sample id="286">Questa tabella riporta l'accuratezza generale dei risultati che abbiamo ottenuto. Abbiamo scoperto che tutti i modelli di linguaggio arrivano a risultati insoddisfacenti quando si tratta di pianificazione per obiettivi specifici.</sample>
    <sample id="287">Then we conduct detailed analysis to investigate why learning models for</sample>
    <sample id="288">I risultati in Figura 7.16 dimostrano che la coerenza semantica dei testi generati è accettabile, ma la fedeltà ai vincoli non può essere garantita.</sample>
    <sample id="289">We dig into more fine-grained topological categories of constraints defined in wikiHow. The heatmap in the figure shows that the planning performance of InstructGPT-3 varies considerably for goals of different categories.</sample>
    <sample id="290">Studi precedenti hanno dimostrato che l'output dei modelli di rete neurale è spesso a variazioni elevate, portando a prestazioni peggiorate. Di conseguenza, adottiamo l'idea di un filtra sovr generato per migliorare la qualità della generazione.</sample>
    <sample id="291">We first show constraint types with examples for intratumor cpt and obtain specific goals based on the cited abstract goals.</sample>
    <sample id="292">Then instruct gpt-3 to generate case studies for specific goals.</sample>
    <sample id="293">Next, a filter model is developed to select the facial scripts.</sample>
    <sample id="294">Convertiamo script e code in istruzioni gpt embeddings e calcoliamo coseno similitudine e similitudine scores per misurare somatici similitudini.</sample>
    <sample id="295">In addition, we will observe the script that contains the key words of the target constraint we only keep the script if the target goal score is the highest in the goal set.</sample>
    <sample id="296">Con il nostro metodo, le istruzioni GPT possono generare scritti di alta qualità. Il nostro metodo migliora grandemente la pianificazione sia in termini di completezza semantica che di fedeltà ai vincoli.</sample>
    <sample id="297">Poiché i modelli di linguaggio sono costosi da deploy, è essenziale abilitare la capacità di pianificazione del linguaggio dei modelli più piccoli e specializzati Creare un dataset è un passo essenziale verso l'obiettivo.</sample>
    <sample id="298">Tuttavia, studi precedenti non hanno avviato pianificazione per specifici obiettivi e la manual manual dataset annotazione è costosa.</sample>
    <sample id="299">Tale è il concetto di distillazione del sapere simbolico che cerchiamo di applicare per estrarre i dataset di linguaggi più limitati da modelli di lingua.</sample>
    <sample id="300">Appli useremo il nostro metodo per la costruzione di un dataset di lingua pianificata conosciuta come code script.</sample>
    <sample id="301">In totale, generiamo cinquantacinquemila specifici dataset con script per assicurare la qualità della validazione e dei set di test. Chiediamo a fornitori di lavoro cloud di trovare e revisionare campioni incorretti.</sample>
    <sample id="302">Questa figura mostra la distribuzione limitata di Coreset. Ci vediamo con Coreset che ha un'alta polarizzata in generale specifico goal. Con Coreset, possiamo creare modelli più piccoli ma specializzati per pianificazione linguistica.</sample>
    <sample id="303">We find that t5 fine-tuning on a corpus can generate scripts of higher quality than most large language models indicating that smaller models can surpass larger models when properly trained on suitable datasets.</sample>
    <sample id="304">In sintesi, stabilizziamo il problema di pianificazione linguistica con vincoli. Utilizziamo la capacità di pianificazione linguistica con vincoli dei modelli di lingua grandi e sviluppo un nuovo filtraggio di generazione per i modelli di lingua grandi.</sample>
    <sample id="305">Usiamo modelli di linguaggio a larga scala per generare un insieme di dati di alta qualità in uno script per pianificazione linguistica. Speriamo che il dataset possa essere un risorsa utilizzabile per avanzare la ricerca sul piano linguistico.</sample>
    <sample id="306">Grazie per il tuo tempo. Per favore, fornisci maggiori dettagli sullo script in our paper.</sample>
    <sample id="307">La fluidità di PaLM è comparabile a quella dei sistemi di arti intelligenti, ma la differenza principale deriva dalla precisione.</sample>
    <sample id="308">Le proprietà importanti di un metodo di filigrana sono che dovrebbe essere applicabile a servizi di imbeddimento, non dovrebbe indebolire l'utility dei servizi di imbeddimento forniti, dovrebbe essere abbastanza evidente per gli attacchieri o essi possono facilmente rimuovere la filigrana e dovrebbe essere trasferibile ai servizi degli attacchieri durante il processo di estrazione del modello.</sample>
    <sample id="309">I discorsi TED tradotti in inglese sono stati tradotti in 14 lingue diverse.</sample>
    <sample id="310">Usualmente solo un paio di annotatori annotano ogni istanza.</sample>
    <sample id="311">La metrica di distanza utilizzata per misurare la differenza tra set di dati benigni e backdoor è la differenza della somma dei coseno e della somma dei quadrati.</sample>
    <sample id="312">I modelli basati su codificatori multilingue sono stati utilizzati per valutare il loro prestabilito su due gruppi di modelli, inclusi i codificatori PDR e i modelli ad encoder-decoder multilingue pre-addestrati.</sample>
    <sample id="344">Gli autori decidono quali sono le parole a frequenza moderata selezionando un set di parole in un intervallo di frequenza moderata.</sample>
    <sample id="345">Ciao a tutti, il mio nome è Zhu Hong. Oggi, intendo presentare il mio articolo: "I tag di entità di 2003 di CoNLL continuano a funzionare bene nel 2023?". Vediamo cosa ne pensiamo.</sample>
    <sample id="346">Il nostro articolo ha indagato il problema della generalizzabilità utilizzando la comprensione di entità con nome o la comprensione di entità nello contesto.</sample>
    <sample id="347">Siamo in grado di osservare che i modelli hanno utilizzato KONDA 2003 per sviluppare NER per quasi venti anni e questo naturalmente solleva diversi problemi. In primo luogo, possono questi modelli generalizzarsi a dati moderni?</sample>
    <sample id="348">And when we develop new tags, what is needed for good generalization?</sample>
    <sample id="349">Allo stesso tempo, se osserviamo una scarsa generalizzazione, cosa causa il crollo delle prestazioni di questi modelli?</sample>
    <sample id="350">Per investigare questi problemi, sviluppiamo il dataset cono plus plus. Questo è un dataset che abbiamo raccolto da Reuters News nel 2020 e lo abbiamo annotato utilizzando le stesse direttive di annotazione del 2013 del cono.</sample>
    <sample id="351">We then fine-tuned over twenty models on conll 2003 we evaluated them on both the conll 03 test set and the conll plus plus test set.</sample>
    <sample id="352">In conclusione, non è stato calcolato il percentuale cambiamento in F1 per valutare la generalizzabilità di ciascun modello.</sample>
    <sample id="353">So what is needed for a good generalization through our experiments we found that there are three main ingredients that are needed</sample>
    <sample id="354">The first one is the model architecture. Through our experiments, we found that the Transformer models normally generalise better to new data.</sample>
    <sample id="355">Il secondo ingrediente è il modello di dimensione. Abbiamo scoperto che, di solito, modelli più grandi portano a una migliore generalizzazione.</sample>
    <sample id="356">Infine, non ultima cosa, sappiamo che il numero di esempi di finetuning直接影响 downstream任务的表现。这里我们还发现，更多的finetuning例子实际上也导致了更好的泛化能力。</sample>
    <sample id="357">To our next question what causes the performance drop of some models?</sample>
    <sample id="358">We had two hypotheses the first one is adaptive overfitting which is overfitting caused by reusing the same test set over and over again and this is usually manifested as the diminution returns on the new test set.</sample>
    <sample id="359">La seconda ipotesi è il drift temporale, che è la degradazione del performance causata da l'intervallo crescente di tempo tra i dati di training e i dati di test.</sample>
    <sample id="360">For adaptive overfitting we saw that from the graph on the right the red best fit line has a gradient that is greater than one.</sample>
    <sample id="361">Questo significa che ogni unità di miglioramento che realizziamo su Chrome 2013 si traduce in più di una unità di miglioramento su Chrome ++, il che significa che non ci sono rendimenti che diminuiscono.</sample>
    <sample id="362">E questo ci dimostra che l'adattivo sovraperdono in questo caso non è osservato.</sample>
    <sample id="363">So what about tempo travega?</sample>
    <sample id="364">Per il tempo di drift, abbiamo fatto un esperimento per retrain o continuare a pretrainare alcuni modelli con più recenti dati e abbiamo scoperto che le prestazioni peggiorano con un intervallo temporale più grande.</sample>
    <sample id="365">E questo conferma la nostra ipotesi che il principale motivo della diminuzione del prestabilito è il drift temporale.</sample>
    <sample id="366">La nostra conclusione è che per una buona generalizzazione, avremmo bisogno di un modello architettura migliore, dimensioni del modello più grandi, insieme a esempi di finetuning migliori. Questi due elementi devono andare di pari passo; non possiamo avere solo un ingrediente, ma bisogna considerare anche gli altri.</sample>
    <sample id="367">Allo stesso tempo, abbiamo anche scoperto che il drop di prestazione qui è causato da drift temporale e, sorprendentemente, non è causato da sovraperload adattativa anche se Contra 2003 è stato utilizzato per più di venti anni.</sample>
    <sample id="368">And going back to the question that you raised in the title of our paper, do connell two thousand and three tags still work in two thousand and twenty three? and we found that the answer is actually a resounding yes.</sample>
    <sample id="369">We hope our paper causes more research on how to improve generalizations of the models.</sample>
    <sample id="370">E infine, per favore assicurati di controllare il nostro articolo, il dataset e se hai alcuna domanda, non esitare a contattarmi. Ti ringhio mille volte.</sample>
    <sample id="397">Il segmento parlato utilizza un approccio di dimensione 256x256.</sample>
    <sample id="398">Nell'esempio con Servin e Kea, le conoscenze specifiche dell'entità necessarie sono che Servin è un giudice e che i giudici decidono cause in una corte di legge.</sample>
    <sample id="399">La qualità dell'esempio è il fattore più importante.</sample>
    <sample id="400">L'articolo si concentra su GPT-4 e GPT-3.</sample>
    <sample id="401">Il modello utilizza i punteggi di attenzione di un livello specifico.</sample>
    <sample id="402">Gli esempi di inferenza diretta sono direttamente legati all'argomento o al fatto che stiamo discutendo.</sample>
    <sample id="403">I ricercatori dell'articolo sono affiliati all'Università di Fudan.</sample>
    <sample id="404">Il numero di autori coinvolti nell'articolo non è specificato nella descrizione fornita.</sample>
    <sample id="405">Sì, è stato considerato come un approccio standard.</sample>
    <sample id="406">Gli autori hanno fornito l'esempio di un "uomo-bataglia" come gruppo contrassegnato.</sample>
    <sample id="407">I modelli di rete neurale convoluzionale non generalizzano adeguatamente.</sample>
    <sample id="408">I nomi dei set di dati di test sono finetuning approach e wsl approach.</sample>
    <sample id="409">Ci sono due autori coinvolti nell'articolo.</sample>
    <sample id="410">Il testo non fornisce informazioni sulla modalità di lavoro dell'autore.</sample>
    <sample id="439">Secondo gli autori, l'area della NLU che è poco studiata è la capacità di integrare e utilizzare sia il conoscimento acquisito in anticipo che quello acquisito in tempo reale.</sample>
    <sample id="440">I nomi dei relatori sono Ying e Jiaxuan.</sample>
    <sample id="441">Sì, i coscripts sono stati sottoposti a controlli di qualità.</sample>
    <sample id="442">Le risorse esistenti per la traduzione dipendente dal contesto hanno limiti in quanto supportano solo tipi limitati di traduzioni dipendenti dal contesto e set di lingue limitati, poiché solitamente si basano su conoscenze umane e curazione.</sample>
    <sample id="443">Hi and I'm going to talk about our work on resolving indirect referring expressions for entity selection in which we introduce the alt entities scorers.</sample>
    <sample id="444">My name is Javad Hosseini, and this is a joint work with Philip Radlinski, Sylvia Parati, and Annie Lewis.</sample>
    <sample id="445">Il nostro obiettivo è di comprendere la lingua degli utenti quando vogliono fare una scelta e considerare questa domanda alternativa: Hai voluto dire "facile per me" o "ho un problema"? Qui, l'utente vuole scegliere tra due opzioni.</sample>
    <sample id="446">The most obvious thing is to use a direct reference, for example by saying the name of the song easy on me or its position, the first.</sample>
    <sample id="447">Ma a volte un indiretto riferimento è più appropriato per avere una conversazione più naturale. Questo potrebbe succedere quando l'utente non ricorda il nome del</sample>
    <sample id="448">All the pronunciations are too similar to each other and hard to disambiguate.</sample>
    <sample id="449">Ora, quando un utente vuole specificare una preferenza, ecco alcuni esempi in direttive. Ad esempio, la nuova versione o una che non è energetica.</sample>
    <sample id="450">Questo è un problema importante in sistemi di elaborazione del linguaggio naturale e anche per la valutazione delle performance dei sistemi di intelligenza artificiale.</sample>
    <sample id="451">Non conosciamo un insieme di dati pubblico a larga scala per il compito, quindi raccolgiamo uno utilizzando la crowdsourcing. Il nostro insieme di dati copre tre domini diversi: musica, libri e ricette.</sample>
    <sample id="452">Our data set collection methodology emphasizes informality using a cartoon completion set.</sample>
    <sample id="453">Il cartoon ha tre bubble di dialogo. In la prima bubble Bob dice: ricorda quella canzone che stavi ascoltando ieri? E con quello Bob stabilisce il contesto del dialogo.</sample>
    <sample id="454">In this in the second speech bubble alice says do you mean easy on me or i got a feeling</sample>
    <sample id="455">Which is the alternative question. and in the third speech bubble bob uses an indirect reference to select one of these entities, for example the new</sample>
    <sample id="456">We provide the first and second speech bubbles automatically, but the third one is filled in by the annotator. The first speech bubble is chosen from a few manual prompts per domain.</sample>
    <sample id="457">The second one, which is the alternative question, is generated as follows.</sample>
    <sample id="458">We always use a simple template. Do you mean A or B? Where A and B are samples from Wikipedia.</sample>
    <sample id="459">Ecco le diverse tecniche di campionamento che abbiamo usato quando ci siamo spostati verso l'alto nella lista le entità diventano più simili tra loro e è di solito più difficile fare la disambigazione.</sample>
    <sample id="460">The first one is uniformed.</sample>
    <sample id="461">The second one is when the entities have similar titles, for example two books with the name The Retreat.</sample>
    <sample id="462">Il terzo è quando hanno descrizioni simili su Wikipedia e infine, anche quando hanno infobox o attributi simili su Wikipedia, ad esempio lo stesso genere o lo stesso artista.</sample>
    <sample id="463">When we show this alternative question to the amateurs, they know the name of these entities but they don't necessarily know about the entity.</sample>
    <sample id="464">Quello che facciamo è di fornire qualche conoscenza di sfondo sulla due entità per i canti. Simplemente mostriamo un link di ricerca Google per ciascun</sample>
    <sample id="465">And then ask the annotators to listen to at least some of each song and read about each song here's for example the google search result for the song easy</sample>
    <sample id="466">Per il dominio ricette e libri, mostriamo alcune informazioni di sfondo da Wikipedia. Per le ricette, inoltre, mostriamo le immagini, anche da Wikipedia, in modo che gli annotatori possano vedere come sembrano.</sample>
    <sample id="467">Allora chiediamo ai annotatori di scegliere uno di questi enti, ad esempio, il primo qui e descrivere gli enti utilizzando 3-5 espressioni indirette.</sample>
    <sample id="468">For example, the one with the piano music here are some examples from our data set for example, the one without words not the one with the twelve year old twelve year old boy or the fictional one or comes from azerbaijan and so</sample>
    <sample id="469">L'Entiti's Corpus ha 6.000 domande alternative su tre domini e ha 42.000 espressioni indiretamente riferite. I risultati con il modello T5XLarge sono riassunti di seguito.</sample>
    <sample id="470">Se il modello di linguaggio ha accesso alla esatta stessa conoscenza di sfondo degli autori, allora l'accuratezza è davvero alta. Sono circa il 92 al 95 percento. Ma questa non è realistica.</sample>
    <sample id="471">Se il modello di linguaggio ha accesso a qualche conoscenza di sfondo parzialmente sovrapposibile, allora l'accuratezza è tra i 82 e i 87 percenti, che è più realistico. Ad esempio, quando il modello di linguaggio recupera la conoscenza di sfondo.</sample>
    <sample id="472">Se il modello di linguaggio ha accesso solo ai nomi di entità, allora l'accuratezza è solo del 60 percento, quindi c'è molto spazio per miglioramento. Abbiamo anche dimostrato che i modelli sono generalizzabili in un dominio qui. Ecco un link al dataset. Grazie.</sample>
    <sample id="473">L'approccio viene confrontato con le politiche SimulST esistenti, tra cui la strategia di Whitaker e la strategia locale, e anche con l'architettura dell'arte di Stato specificamente dedicata alla SimulST.</sample>
    <sample id="474">I fornitori di articoli sono affiliati a l'Université de Lorraine, l'Institut national de la santé et de la recherche médicale, l'Université de Strasbourg e l'Université de Toulouse.</sample>
    <sample id="475">La relatrice o il relatore è Jenny, una prima-year PhD student at Carnegie Mellon University.</sample>
    <sample id="476">Ci sono tre autori coinvolti nell'articolo: Essin Dermush, Dan Juravsky e l'autore principale, Myra.</sample>
    <sample id="477">Ciao, sono Sarah Papi da Università di Trento e Fondazione Bruno Kessler. E io presenterò brevemente un articolo che serve come guida per la traduzione parallela di testi. Questo articolo è stato scritto insieme a Matteo Negri e Marco Turki.</sample>
    <sample id="478">Cosa è traduzione simultanea? La traduzione simultanea o Simultaneous Speech Translation (SST) è il processo di tradurre un linguaggio parlato in un altro linguaggio in tempo reale, rendendo la comunicazione tra le lingue possibile.</sample>
    <sample id="479">E cosa sono i problemi dei modelli di similitudine correnti? Le specifiche architettura sono usualmente addestrate introducendo moduli aggiuntivi da otimizzare.</sample>
    <sample id="480">Long and complicated training procedures for example, training involving different optimization objectives,</sample>
    <sample id="481">E addestrando e mantenendo diversi modelli per raggiungere differenti regimi di latenza, ad esempio addestrando un modello con un'average di un secondo di latenza e un altro modello con due secondi di latenza, eccetera.</sample>
    <sample id="482">So what is our solution?</sample>
    <sample id="483">Prima di usare modelli esistenti offline preesatti senza retrain o adottare specifiche architettura per simile st. Usare solo un modello per ogni regime latenza e gestire la latenza tramite parametri specifici.</sample>
    <sample id="484">E sfrutta le conoscenze acquisite dal modello attraverso il meccanismo di attenzione tra input audio e output testo che è il meccanismo di attenzione cruciale. E puoi vedere un esempio a destra.</sample>
    <sample id="485">La nostra soluzione è di proporgere adattare o encoder decoder l'attenzione e è una strategia per cui decidiamo di emettere o non emettere una traduzione parziale basata su dove l'attenzione punta.</sample>
    <sample id="486">Un segnale è emitto se la tensione non è concentrata, cioè se la somma è inferiore a un certo livello di trazione alpha verso le ultime lampo di speech frames, che significa che i segnali ricevuti non sono abbastanza stabili.</sample>
    <sample id="487">Ad esempio, se se riceviamo un speech shung che contiene "I'm going to talk about" e il modello predice la traduzione in tedesco,</sample>
    <sample id="488">And we will look at the cross attention weights,</sample>
    <sample id="489">Vedremo che i primi due parametri puntano alle prime ricevute cornici di speech, mentre l'ultimo parametra puntava alle ultime ricevute cornici di speech, ossia lambda speech frames.</sample>
    <sample id="490">Questo significa che i primi due caratteri verranno omessi.</sample>
    <sample id="491">Mentre il somma della tensione di cruce è sopra un certo livello alfa non emetteremo la luce rossa e aspetteremo per un nuovo spicchio.</sample>
    <sample id="492">If we go on and we receive another speech chunk and our model predicts other three words, and we will look at the cross attention weights.</sample>
    <sample id="493">We will see that no word points to the last lambent lamp of speech frames.</sample>
    <sample id="494">Questo significa che queste tre parole verranno emesse.</sample>
    <sample id="495">If we look at the main results of that,</sample>
    <sample id="496">We will plot the simultaneous speech translation results on graphs in which we have blue on one side that measures the translation quality and average latency.</sample>
    <sample id="497">That is the latency measure and we also consider the computational aware average linking that accounts for the model's computational times to produce the output.</sample>
    <sample id="498">So we want our curve to be as high as possible on this plot.</sample>
    <sample id="499">But also we want that they are shifted on the left.</sample>
    <sample id="500">E confrontiamo con strategie preposte che sono anche applicate a modelli offline, tra cui la strategia dei weight keys e l'approccio locale. E confrontiamo anche con l'architettura di sistema dell'arte, specificamente dedicata alla traduzione simultanea.</sample>
    <sample id="501">Questi sono tutti i risultati dell'approccio di traduzione parallela su tedesco.</sample>
    <sample id="502">And we see that a dot outperforms all the strategies applied to offline models since their curves are shifted over the left.</sample>
    <sample id="503">E anche che se consideriamo il tempo reale di scadenza o il tempo computazionale adatto, è la strategia più veloce.</sample>
    <sample id="504">Se vuoi scoprire più risultati leggi il nostro articolo e anche rilasciamo open source il codice e i modelli e i simultaneous householder per facilitare la riproducibilità del nostro lavoro. Grazie per l'attenzione.</sample>
    <sample id="505">Sì, il set di dati è pubblico.</sample>
    <sample id="506">Ciao a tutti, il mio nome è Ying e il mio collega Jiaqiang e io presenteremo il nostro ricerchiamo su Multi-Instruct, migliorando il machine learning multi-modal con l'inserimento di istruzioni.</sample>
    <sample id="507">Così con le avanzate in grandi modelli linguistici, molte ricerche hanno iniziato a esplorare nuove paradigmi di imparare utilizzando modelli pre-allenati per diverse attività di basso livello in un modo efficiente in termini di parametri e di dati.</sample>
    <sample id="508">Recentemente, molte ricerche hanno dimostrato che l'addestramento con istruzioni consente ai modelli di linguaggio grandi di svolgere compiti di pensiero in modo rapido e efficiente seguendo istruzioni naturali.</sample>
    <sample id="509">Tuttavia, la maggior parte dei precedenti studi sulla calibrazione dell'inserimento si sono concentrati su migliorare le prestazioni senza suolo di un任务 linguisticamente solo, mentre le compere visione e i task multi-modal hanno stato lasciato fuori.</sample>
    <sample id="510">Quindi in questo lavoro, ci piacerebbe indagare se l'adattamento dell'instruzione o i modelli pre-allenati multi-modal possono realmente migliorare la generalizzabilità per compiti multi-modal.</sample>
    <sample id="511">Inoltre, durante la nostra ricerca, abbiamo scoperto una considerabile disparità nella disponibilità di dataset di istruzioni tra NLP e multi-modal.</sample>
    <sample id="512">Esistono più di mille e seicento dataset di istruzioni in lingua solo. Tuttavia, non esiste alcun dataset di istruzioni multi-modal largamente pubblicato. Questo ci ha spinto a creare un dataset di istruzioni multi-modal per la tuning.</sample>
    <sample id="513">Ecco, presentiamo Multi-Instruct, il primo set di benchmark per l'addestramento di istruzioni multi-modal che comprende 62 diverse attività multi-modal, coprendo 10 category diverse.</sample>
    <sample id="514">Questi task sono derivati da ventuno esistenti set di dati open source e ogni task è equipaggiato con cinque istruzioni esperte.</sample>
    <sample id="515">Per investigare l'ottimizzazione multi-modal di nostra propria base di dati, utilizziamo OFA, un modello unificato per la traduzione multi-modal come nostra base model. OFA usa un vocabolario unificato per le token del linguaggio e immagine e le coordinate di un bounding box.</sample>
    <sample id="516">Ecco alcuni esempi di istanze dalla nostra multinstretta base di dati.</sample>
    <sample id="517">Unificare il trattamento di varie tipologie di input e output dei dati.</sample>
    <sample id="518">We follow the method from OFA and formulate all the tasks in a unified sequence-to-sequence format in which the input texts, images, instructions, and bounding boxes are represented in the same token space.</sample>
    <sample id="519">Okay, now I'm going to talk about multi-modal instruction tuning.</sample>
    <sample id="520">Quindi, per il dataset di training utilizziamo cinquantatre task provenienti da NQ Group per il training e selezioniamo diecimila istanze per task. Per il testing riserviamo interamente il dataset di Comprehension Reasoning Group e selezioniamo ulteriormente cinque task provenienti da Wiki e MScNLI Group.</sample>
    <sample id="521">We use all the instances in the test split for each task in addition, we randomly sample twenty tasks from the test split of natural instruction as the unseen task for llm.</sample>
    <sample id="522">So we use a pre-trained LLaMA model as the base model during training. We make all the instances for all the tasks. Each instance is randomly combined with one of its five instruction templates.</sample>
    <sample id="523">During test for each task we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.</sample>
    <sample id="524">Report the mean and max performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="525">Se la task è un task di classificazione multi-modal, rapporteremo l'accuratezza. Se è un task di generazione multi-modal, rapporteremo rouge-l. Per un task NLP, rapporteremo rouge-l anche.</sample>
    <sample id="526">We also introduced a additional evaluation metric called sensitivity. so this measures the model's ability to consistently produce the same outputs for the same task regardless of slight variation in the wording of the instruction.</sample>
    <sample id="527">Ecco i nostri principali risultati. Come possiamo vedere, l'addestramento dell'instruzione può migliorare in modo significativo le prestazioni di OLS e OFA su compiti multi-modal.</sample>
    <sample id="528">Anche transfer learning da dataset di istruzioni naturale può migliorare l'adattamento dell'instruzione.</sample>
    <sample id="529">Qui possiamo vedere che, con l'aumento del numero di task, il modello raggiunge un'efficienza migliore e allo stesso tempo una sensibilità più bassa.</sample>
    <sample id="530">We also did one experiment where we use one instruction versus five instruction. As we can see, using more instruction can improve the model's overall performance and reduce its sensitivity a lot.</sample>
    <sample id="531">Così, questa dimostra l'effetto di diverse strategie di finetuning sul sensibilità del modello. Come possiamo vedere, utilizzando imitazione da dataset di istruzioni naturali, il modello può raggiungere una sensibilità molto migliore rispetto al modello OAF originale.</sample>
    <sample id="532">We also can see transfer learning from the machine instruction dataset can help our f to achieve much better performance on the machine instruct dataset.</sample>
    <sample id="533">In generale, proponiamo il primo insieme di dati di addestramento multi-modal su larga scala che ha significativamente migliorato la capacità di rilevamento di OIFAI e esploriamo diverse tecniche di imparare tramite il transito e mostriamo i loro benefici. Inoltre, progettiamo un nuovo metrico chiamato sensibilità.</sample>
    <sample id="534">So one more thing, we are collecting a much larger multi-modal instruction tuning data set with around 150 additional vision-language tasks and we will release them. So this is the QR code for our data and model. Thank you.</sample>
    <sample id="535">I fornitori del paper sono affiliati all'Università di Trento e Fondazione Bruno Kessler.</sample>
    <sample id="536">Il nome della relatrice o del relatore è Javad Hosseini.</sample>
    <sample id="562">Ciao, gente! Sono Costas Tsitsina e sono felice di benvenuti alla nostra discussione sul mio articolo AC 2023, riguardo i giudizi sulla accettabilità dei modelli linguistici. Non sempre i giudizi sulla accettabilità dei modelli linguistici sono robusti al contesto.</sample>
    <sample id="563">È un lavoro a squadra con john gowther, aram muller, ganeshkumar mishra, karen fuentes, roger levy e adina william.</sample>
    <sample id="564">So in this work we revisit the minimal pair paradigm.</sample>
    <sample id="565">La valutazione minimale per partito basically evaluates language models on top of acceptability judgments which can also include grammaticality like plump syntax jim or acceptability in terms of stereotypes such as grouse pairs.</sample>
    <sample id="566">In this minimal pair paradigm, the typical way to evaluate language models is that you show like a acceptable sentence or a grammatical sentence and then you show an unacceptable sentence or an ungrammatical sentence.</sample>
    <sample id="567">E allora, l'ipotesi del modello basically mette più probabilità all'intervallo accettabile.</sample>
    <sample id="568">The current mpp pipeline basically doesn't allow us to evaluate models acceptance towards longer sentences.</sample>
    <sample id="569">These days, large language models are coming up with longer and longer context windows. So it's crucial that we evaluate the model's acceptability throughout the context window.</sample>
    <sample id="570">E quello è quello che stiamo cercando di fare qui. Stiamo cercando di revisita il PNP pipeline by asking the model to evaluate acceptability on longer and longer sequences.</sample>
    <sample id="571">So that is the approach. So what we do is that to simulate these longer sequences, we revisit the datasets themselves and then we recreate sentences by choosing like acceptable or unacceptable sentences from those datasets.</sample>
    <sample id="572">For example, here we have chosen like a typical pair of grammaticality from the blimp data set from the adjunct island case.</sample>
    <sample id="573">E quello che facciamo è ricreare lunghe sequenze che sono accettabili e hanno lo stesso matching della struttura grammaticale. Estraiamo frasi grammaticali da un'origine indiana.</sample>
    <sample id="574">E quindi lo aggiungiamo come prefisso sia alla query accettabile che alla query non accettabile.</sample>
    <sample id="575">So we can do the same thing by choosing unacceptable sentences from the same matching and that could also like be used to test the model's acceptability.</sample>
    <sample id="576">And we can also do the same by choosing sentences from a different subset or a different data set. so that is what we call as the mismatch scenario.</sample>
    <sample id="577">So here the sentences are still coming from relevant data sets, but it's not from the same data set that you're evaluating with and we can do the same for unacceptability cases.</sample>
    <sample id="578">Finalmente, possiamo scegliere i testi da un dominio completamente non correlato, come Wikipedia.</sample>
    <sample id="579">So this will tell us like whether the model's acceptability judgments are actually impacted by any context.</sample>
    <sample id="580">Whether the context is coming from a different subset of the data set or whether it's like completely irrelevant to the current like to the sentence that we are looking at.</sample>
    <sample id="581">Quindi come fa il modello? In primo luogo, analizziamo le sentenze di Wikipedia che sono completamente irrelevanti al momento del query. E lì trovi che i giudizi del MPP sono maggiormente robusti per contesti arbitrari.</sample>
    <sample id="582">We increased the context length toward up to thousand and twenty four for to max out OPT and GPT-2 models, and we saw here in the orange dot line the MPP judgments are relatively stable.</sample>
    <sample id="583">Now what happens when we choose sentences from the same dataset?</sample>
    <sample id="584">So here we are choosing or creating sentences from acceptable and unacceptable domains from the same blimp or syntaxnet dataset,</sample>
    <sample id="585">E lì vediamo che i mpp judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable</sample>
    <sample id="586">But when we match the structure, that is when we choose the sentences from the same phenomena in blame person text jim,</sample>
    <sample id="587">Vediamo un aumento o una riduzione massiva del mpp giudizio per il modello in base a quando il prefisso scelto è accettabile o non accettabile.</sample>
    <sample id="588">Ora, questa è e questa è molto grande. Questo effetto aumenta lungo il contesto locale e queste probabilmente affetteranno modelli di lingua più nuovi che hanno un contesto di grandi finestre.</sample>
    <sample id="589">So why does the match prefix affect the language model judgment so much?</sample>
    <sample id="590">So we did a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure but adding uh like noise to the input and after doing like several of these perturbations,</sample>
    <sample id="591">We find that none of these noises are actually making the model like change it course in terms of how it shows us the nppj has been trying.</sample>
    <sample id="592">Basically, we find that the models are sensitive to the perturbation sentences in similar ways.</sample>
    <sample id="593">That is, when we perturb the sentences in the acceptable domain we see similar increase in all the perturbations and when we perturb the sentences in the unacceptable domain we see decrease in mpp judgements in similar fashion.</sample>
    <sample id="594">Quindi i principali punti di rilievo del nostro lavoro è che i modelli di linguaggio sono sensibili a caratteristiche sintattiche e semantiche latenti che si condividono tra le frasi.</sample>
    <sample id="595">E la valutazione MPP che facciamo attualmente con input singoli e brevi frasi non può catturare completamente le conoscenze astratte dei modelli di linguaggio attraverso tutto il contesto.</sample>
    <sample id="596">Per favore, leggete il nostro articolo per maggiori dettagli dei nostri esperimenti. Grazie per l'attenzione.</sample>
    <sample id="597">Il primo passaggio del metodo mappa i token di input con un insieme non ordinato di token che appariranno nell'output.</sample>
    <sample id="598">Coscript rappresenta 55,000 script.</sample>
    <sample id="626">Il metodo di allineamento migliore per DEplain è il metodo di mass alline.</sample>
    <sample id="627">Il vantaggio dell'apprendimento scarsamente supervisionato è che i modelli di rete neurali possono essere robustamente addestrati anche con label rumorosi, rendendo più generalizzabili.</sample>
    <sample id="628">I documenti in DEplain-web sono stati allineati con metodi di allineamento manuali e automatici.</sample>
    <sample id="629">Il set di dati CoNLL++ è stato creato raccolgendo notizie da Reuters News nel 2020 e annotandole con le stesse direttive di annotazione del 2003.</sample>
    <sample id="630">Ciao a tutti, mi chiamo Yusen Zhang dalla Università di Penn State. Oggi presenterò il mio lavoro: exemplar crosslinguistic semantic parsing in multiple natural languages and many representations.</sample>
    <sample id="631">So semantic parsing is a task to build semantic representations of user queries such as sql and lambda calculus.</sample>
    <sample id="632">Cross-lingual semantic parsing is the task to translate queries in multiple natural languages into multiple meaning representations.</sample>
    <sample id="633">Come si è detto nel mio articolo, dobbiamo tradurre la query in molti linguaggi naturali utilizzando modelli neurali come il C2C, LAMBERT o FUMQL e altri.</sample>
    <sample id="634">Esistenti modelli di parsing semantici multilingue sono separatamente proposti e valutati su un insieme di limitate applicazioni, ad esempio,</sample>
    <sample id="635">There are leaks of coverage on certain natural language the chinese is missing and</sample>
    <sample id="636">Lack of coverage on certain minor repetitions.</sample>
    <sample id="637">La lombardocalicis è mancante.</sample>
    <sample id="638">Or they are only evaluated on certain neural models. For example, there's only one single model to evaluate them.</sample>
    <sample id="639">So to this end, we propose Exemplar, a uniform dataset exemplar for cross-lingual semantic parsing in multiple natural languages and meaning representations.</sample>
    <sample id="640">Contiene no di testi in diverse lingue, cinque sistemi di parsing testo, otto modi di rappresentazione e ventidue lingue naturali in quindici famiglie linguistiche.</sample>
    <sample id="641">E per valutare meglio il benchmark, consideriamo i sei parametri per la formazione e l'evaluatione.</sample>
    <sample id="642">The first one is translate test we use google translate api to translate source to the target language then use monolingual model to train and evaluation.</sample>
    <sample id="643">Ad esempio, trainiamo il modello inglese su query inglese e durante l'inferenza traduciamo la query tedesca in inglese utilizzando un API e quindi usiamo il modello addestrato per prevedere il SQL.</sample>
    <sample id="644">And we'll also test monolingual module.</sample>
    <sample id="645">In this setting, the source language is the same as target language for example german to german or english to english.</sample>
    <sample id="646">Inoltre, testiamo un setting monolingue finito allenando modelli monolingue con solo il 10% dei dati di addestramento.</sample>
    <sample id="647">E testiamo un modello multilingue, che adesso trainiamo un modello multilingue per tutte le lingue.</sample>
    <sample id="648">For example we put the German, English, Chinese queries together to train a multilingual model and during inference we can use this model to</sample>
    <sample id="649">Um to translate german queries or chinese query or et cetera.</sample>
    <sample id="650">E consideriamo anche il crosslinguaggio zero-shot e few-shot transfer. Ci trainiamo su un solo linguaggio e lo trasferiamo ad un altro linguaggio.</sample>
    <sample id="651">Durante la formazione, i modelli sono addestrati su query in inglese o la combinazione di query in inglese e tedesco, per addestrare un modello multilingue e prevedere il output SQL.</sample>
    <sample id="652">E anche trovo molti risultati interessanti. Quindi, riguardo l'analisi dei modelli monolingue, valutiamo due gruppi di modelli.</sample>
    <sample id="653">Incluso encoder PDR, che sta per Multilingua Pre-Training Encoder with Pointer-based Decoders, come ad esempio XLNet + PDR e Bert + PDR.</sample>
    <sample id="654">E valutiamo anche modelli encoder-decoder, che sono modelli encoder-decoder multilingue pre-allenati, come mbert e mt5.</sample>
    <sample id="655">Siamo riusciti a trovare che encoder-decoder ottiene il migliore prestigio su tutti i nove dataset.</sample>
    <sample id="656">E valutiamo su mt5 e esempi xlm-r plus pdr su multilingua.</sample>
    <sample id="657">Siamo riusciti a dimostrare che encoder-decoder o encoder-pdr possono essere migliorati addestrandoli in un mix di diverse lingue.</sample>
    <sample id="658">E si è scoperto che è proprio per via di questo che la maggior parte delle lingue naturali principali possono ottenere un miglioramento delle prestazioni, tranne l'inglese, il cui rendimento diminuisce in sette dataset e aumenta solo in tre dataset.</sample>
    <sample id="659">I think this is known as curse of multilinguality.</sample>
    <sample id="660">We also compared the cross-language performance gap.</sample>
    <sample id="661">In this figure, the blue line is cross-lingual few-shot transfer. The orange line is cross-lingual zero-shot transfer while the green line is the model-in-the-setting.</sample>
    <sample id="662">We found that by comparing the green and orange line, we found that for zero shot setting, the crosslingual transfer performance gap is significant and by comparing blue and orange line, we found that few shot setting, the transfer gap is shortened rapidly.</sample>
    <sample id="663">Trovi anche alcune altre scoperte interessanti. Ad esempio, encoder-decoder supera precedenti work e ottiene risultati comparabili per la traduzione in lingua naturale inglese e in modo significativamente migliora le prestazioni di few-shot su lingue naturali.</sample>
    <sample id="664">E si sono rivelati modelli di linguaggi multilingue come Coda es e Blue, sono ancora inadeguati per le task di traduzione crosslingua.</sample>
    <sample id="665">In sintesi, è stato creato un esemplare unificato di benchmark per il parsing di testi omogenei con diverse lingue e varianti.</sample>
    <sample id="666">Conducing a comprehensive benchmark study on three representative types of multilingual language models and our results show many interesting findings and et cetera. And welcome to visit our paper and code. Thanks for listening.</sample>
    <sample id="667">I lavori esistenti possono essere classificati in quattro category.</sample>
    <sample id="668">No, gli LLM multilingue come Codex o Bloom non sono sufficienti per il CLSP.</sample>
    <sample id="695">Il metodo affronta l'ambiguità delle permutazioni inducendo l'allineamento come parte della formazione.</sample>
    <sample id="696">L'equità di un modello NLP a valle si riferisce alla capacità del modello di fornire risposte equamente e senza bias, non importa la politica o le opinioni personali del utente.</sample>
    <sample id="697">Il nome della relatrice o del relatore è Yanis Lavrac.</sample>
    <sample id="698">Il nome della relatrice o del relatore è Costas Zissin.</sample>
    <sample id="699">Il nome della relatrice o del relatore è Myra.</sample>
    <sample id="700">Il tropicalismo indica un stereotipo che si riferisce alle donne di colore, in questo caso le donne latine.</sample>
    <sample id="701">Gli autori hanno elaborato le rappresentazioni umane dei gruppi target utilizzando parole chiave come cultura, tradizione, orgoglio e esotismo. Queste parole definiscono i gruppi solo in relazione alla loro identità e li distinguono da norma bianca.</sample>
    <sample id="702">In questo lavoro, si è utilizzato C6Mi per misurare l'utilizzo del contesto.</sample>
    <sample id="703">DrBERT è un modello a 7 GB di NAOs, mentre ChuBERT è un modello clinico a 4 GB di sentenze tratte da note cliniche.</sample>
    <sample id="751">Ci sono due autori coinvolti nell'articolo.</sample>
    <sample id="752">Il trasferimento iterativo dell'apprendimento aggiorna il modello in base ai dati raccolti nella ultima sessione di annotazione.</sample>
    <sample id="753">Il set di dati ha come obiettivo comprendere il linguaggio dell'utente quando vuole fare una scelta e considerare queste domande alternative.</sample>
    <sample id="754">Un utente malintenzionato può estrarre i parametri del modello attraverso un EaaS utilizzando la validazione del coeurate del modello. Questo è fatto analizzando il modello e rilevando i parametri che lo definiscono.</sample>
    <sample id="755">C'è un articolo che coinvolge tre autori.</sample>
    <sample id="756">Sono stati impiegati 10 annotatori per creare il set di dati iniziale.</sample>
    <sample id="757">Gli autori dell'articolo sono affiliati all'University of Washington e all'Allen Institute for AI.</sample>
    <sample id="758">Il governo a sinistra in questo esempio è il caso di Bart e Lisa.</sample>
    <sample id="759">I modelli all'avanguardia nei sistemi di dialogo sono quelli che utilizzano l'apprendimento automatico e la macinazione di grandi quantità di dati per imparare a rispondere alle domande dei utenti in modo più umano e naturale.</sample>
    <sample id="760">Perché i modelli stanno diventando più grandi e hanno un contesto più lungo.</sample>
    <sample id="761">Sì, la formazione attraverso la modalità multilingue ha causato un calo delle prestazioni rispetto al modello inglese monolingue.</sample>
    <sample id="762">Sì, gli annotatori conoscono l'entità in anticipo.</sample>
    <sample id="763">La valutazione è stata effettuata utilizzando diverse metriche di traduzione automatica (MT), tra cui la precisione, la ricchezza e la correttezza.</sample>
    <sample id="764">Sì, il regresso nella generalizzazione influenza specifici tipi di NER.</sample>
    <sample id="765">La posizionalità nella NLP è importante perché le istanze di offensività possono variare in base alla posizione del termine nella frase o nella storia.</sample>
    <sample id="766">I modelli di lingua multilingue come BLOOM sono stati adattati utilizzando adattatori o con una messa a punto integrale.</sample>
    <sample id="767">Per il trasferimento dell'apprendimento, si ricorre al modello di co-iniziare l'apprendimento attivo.</sample>
    <sample id="768">I recenti set di test utilizzati per valutare le capacità di PaLM sono il SQuAD 2.0 e la comprensione del testo.</sample>
    <sample id="769">I autori hanno proposto tre suggerimenti alla fine.</sample>
    <sample id="770">Il guadagno del metodo proposto rispetto al metodo di riferimento è che consente di ottenere modelli più piccoli ma specializzati per la pianificazione linguistica con constraint.</sample>
    <sample id="771">Il nome del relatore è Chu Huang.</sample>
    <sample id="772">Sì, i risultati e il set di dati dell'articolo possono essere utilizzati come parametri di riferimento.</sample>
    <sample id="773">Il numero di modelli più piccoli utilizzati nell'articolo non è specificato.</sample>
    <sample id="774">Il modello OFA viene utilizzato come modello di base per analizzare l'ottimizzazione delle istruzioni multimodali.</sample>
    <sample id="833">Gli autori dell'articolo sono affiliati a Google Translate.</sample>
    <sample id="834">I fornitori dell'articolo sono la Stony Brook University e la Computer Science PhD Program.</sample>
    <sample id="835">L'articolo ha analizzato le coppie linguistiche inglese-italiano e inglese-tedesco.</sample>
    <sample id="836">Il nome della relatrice o del relatore è Changbing.</sample>
    <sample id="837">I modelli di Long Impart e Normal Base Impart sono stati studiati durante gli esperimenti.</sample>
    <sample id="838">Per scopi di addestramento vengono utilizzate 53 delle 62 diverse attività utilizzate in MultiInstruct. Per scopi di test, vengono utilizzate 10 attività separate.</sample>
    <sample id="839">Il numero di autori coinvolti nell'articolo non è specificato nella descrizione fornita.</sample>
    <sample id="840">Gli autori hanno effettuato i test su quattro set di dati: AGNews, Mind, SST2 e ER-Sem.</sample>
    <sample id="876">NACHOS è un dataset di dati medici raccolti dalla rete.</sample>
    <sample id="877">Il nome del relatore è Ida Vilad.</sample>
    <sample id="878">La strategia del prompting ha un grosso impatto sulle prestazioni.</sample>
    <sample id="879">I fornitori di autori dell'articolo sono Patrick Franasz, Emil Niu, Andrea F. Martinez e Graham Mubig.</sample>
    <sample id="880">I 5 istruzioni scritte da esperti sono: 1. Utilizza il dataset per addestrare il modello. 2. Utilizza il modello per risolvere i compiti di lingua umana. 3. Utilizza il modello per creare nuovi modelli. 4. Utilizza il modello per migliorare la qualità dei modelli esistenti. 5. Utilizza il modello per sviluppare nuove applicazioni.</sample>
    <sample id="881">Gli autori propongono un compito di risoluzione di riferimento corretto per testare i modelli sull'utilizzo di informazioni provenienti da più fonti.</sample>
    <sample id="882">Hello everyone. My name is Ilya Sutskever and I will be giving a short review of the paper, "Training Probing Translations: Assessing Strategies and Performance". This is joint work with my colleagues from Google Translate.</sample>
    <sample id="883">Bam è un modello di lingua naturale a 540 miliardi di parametri presentato l'anno scorso, nel 2022. È stato addestrato su una vasta raccolta di testi che comprende 780 miliardi di documenti.</sample>
    <sample id="884">La libreria di PyTorch è la più avanzata esistente in centinaia di NLP task.</sample>
    <sample id="885">In this work, we present the first systematic study of large language model prompting for machine translation.</sample>
    <sample id="886">Valutiamo la capacità di traduzione dei modelli utilizzando le migliori pratiche della comunità M2P. Questo implica l'uso dei set di test più recenti per evitare qualsiasi sovrapposizione dei dati di test con i dati di addestramento del modello linguistico.</sample>
    <sample id="887">And we compared two state-of-the-art systems, so the best performing system is the davenport evaluation.</sample>
    <sample id="888">Usiamo state-of-the-art e nuovi metodi metrici e inoltre mostriamo anche i risultati di valutazione basati su esperti. Infine, forniamo alcune raccomandazioni per le strategie di preselezione.</sample>
    <sample id="889">Il prompting ha un grosso influsso sulle prestazioni dei modelli di lingua per la traduzione come possiamo vedere in un esperimento semplice dove utilizziamo un solo prompting e forniamo due diversi prompt per una stessa frase.</sample>
    <sample id="890">The majority of sentences five hundred and sixteen out of one thousand the difference observed is of more than one blur point.</sample>
    <sample id="891">And this can go in extreme cases up to forty plot points. So it's important to select that good prompting strategy.</sample>
    <sample id="892">In our experiments we utilize for a fixed shot prompting strategy where we just mark each its sentence that we provide to the system with the language it's in.</sample>
    <sample id="893">In this example here, where we perform translation from German into English, the German sentences the source sentences are marked with German colon and the English translations with English colon.</sample>
    <sample id="894">We saw that the actual form of the printing doesn't have a big influence in the case of serial short printing.</sample>
    <sample id="895">It's crucial for zero and one shot prompting and when we go as in our case to five shot prompting there is nearly no difference to the actual form of the of the prompting.</sample>
    <sample id="896">It's the examples that carry most of the weight.</sample>
    <sample id="897">The summary of our experimental results is that the example quality is more important than the similarity to the source sentence.</sample>
    <sample id="898">È importante selezionare gli esempi da traduzioni di alta qualità in particolare. Inoltre, confrontiamo i prompt selezionati con i dati di addestramento e le valutazioni di DMT o i dati di dev.</sample>
    <sample id="899">The dev data is much more curated and with higher quality than the train data, that it's more nice and the results so a better performance when using the dev data.</sample>
    <sample id="900">Nondimeno, i sistemi specializzati hanno un vantaggio sostanziale rispetto alle traduzioni umane ma una viene quasi a trovarsi di fronte a un sistema di traduzione automatica. In tal caso, ci siamo voluti avvicinare a Google Translate.</sample>
    <sample id="901">I insights che otteniamo dalla umanizzazione che eseguiamo utilizzando il framework MQM sono che la fluidità di Palm è comparabile a state of the art dei sistemi ma la differenza principale deriva dalla precisione.</sample>
    <sample id="902">In particolare i most comuni errori ar omission errors.</sample>
    <sample id="903">Sembra che palmi scelga diem per produrre una traduzione più accurata, a volte rimuovendo parti della frase sorgente che non sono pertinenti alla traduzione.</sample>
    <sample id="904">Tuttavia, la tasso di uscita per BAN è inferiore rispetto ai sistemi di mercato, che rappresenta un segnale aggiuntivo.</sample>
    <sample id="905">That PAM provides really fluent output but still with some problems of accuracy.</sample>
    <sample id="906">And that's it for this really short overview for more details please come my to the full presentation of the paper thank you very much</sample>
    <sample id="907">Ciao, mi chiamo Dawe, sono uno studente di PhD all'Università di Salamanca in Spagnia. In questo video vorrei presentare il mio recente lavoro, "Wickeder than you think", o un'analisi critica della supervisione online.</sample>
    <sample id="908">This is joint work with chih yu shen, myroslav smolensk and geras stefan and dietrich klopp.</sample>
    <sample id="909">I'd like to begin with a brief introduction to weak supervision and weakly supervised learning.</sample>
    <sample id="910">In weak supervision, non manually etichettate i dati invece etichettiamo i dati utilizzando fonti di etichettatura deboli come regole semplici, basi di conoscenza o qualsiasi altra fonte di etichettatura di bassa qualità, come illustrato nella figura a sinistra.</sample>
    <sample id="911">When compared to human annotations, weak annotations are much cheaper yet they are also noisy, meaning that a certain amount of the annotations are incorrect.</sample>
    <sample id="912">Se addestriamo reti neurali direttamente su dati etichettati settimanalmente, le reti neurali tendono a memorizzare il rumore dei riquadri e non generalizzano.</sample>
    <sample id="913">In weakly supervised learning, training algorithms are proposed to robustly train neural networks under such label noise so that the trained models still generalize well.</sample>
    <sample id="914">In recent works in WSL so WSL stands for Weekly Supervised Learning a common claim is that people say that they only train models on the weekly labeled data and achieve high performance on clean test sets.</sample>
    <sample id="915">Tecnicamente, questa affermazione non è vera ma c'è un problema.</sample>
    <sample id="916">Che è che i fornitori di modelli hanno l'assurdo pregiudizio che esiste un set di validazione aggiuntivo, accessibile per la selezione del modello.</sample>
    <sample id="917">We can't stop on this problem setting as this implies that additional manual annotations are required in weakly supervised learning but, like an elephant in the room, this necessity is often overlooked.</sample>
    <sample id="918">Il riferimento adottato ci obbliga a chiedere tre domande di ricerca. Prima, è necessaria la validazione dei dati puliti per WSL o possiamo forse usare un set di validazione rumoroso invece?</sample>
    <sample id="919">Secondo, se i dati puliti sono richiesti o se i dati puliti sono necessari per che WSL funzioni, allora quanti campioni puliti dobbiamo avere? Infine, dovremmo utilizzare solo i campioni puliti per la validazione o ci sono altre migliori maniere di utilizzarli?</sample>
    <sample id="920">We addressed these research questions in our work, and our findings are as follows.</sample>
    <sample id="921">Prima di tutto, scopriamo che recenti metodi WSL in effetti richiedono campioni di traino di dimensione grande per funzionare correttamente.</sample>
    <sample id="922">Altrimenti ci è un grosso sisma di performance, come si vede in questa figura. Se non ci sono campioni di validazione puliti, allora i modelli di addestramento non possono generalizzare al di fuori dei relativi etichettati originari.</sample>
    <sample id="923">Significando che l'addestramento è inutile.</sample>
    <sample id="924">Questo indica che i modelli WSL effettivamente richiedono un'annotazione accurata per funzionare correttamente e il costo di annotazione per ottenere campioni di validazione puliti non dovrebbe essere trascurato.</sample>
    <sample id="925">Il nostro secondo scoperto è che aumentare il numero di campioni di validazione puliti aiuterà i modelli WSL ad ottenere prestazioni migliori, come illustrato nella figura sulla sinistra.</sample>
    <sample id="926">Tipically, we only need twenty samples per class to attain high performance.</sample>
    <sample id="927">Ma, quello non è il termine finale della storia, perché se decidiamo di accedere a campioni puliti, allora addestrare modelli direttamente su di essi otterrà anche un'performance migliore.</sample>
    <sample id="928">Il grafico a sinistra illustra la differenza di prestazione tra i modelli fin-tuned direttamente sul dataset originale e quelli fin-tuned solo con i modelli fin-tuned direttamente sul dataset originale.</sample>
    <sample id="929">Come possiamo vedere, se abbiamo dieci campioni per classe, diretti fin-tuning inizia a superare le approssimazioni WSL.</sample>
    <sample id="930">Infatti, l'incremento delle prestazioni dichiarato in precedenti approcci WSL può essere facilmente raggiunto consentendo di continuare il fin-tuning su campioni di validazione puliti.</sample>
    <sample id="931">Come possiamo vedere dai grafici, il modello Venera denominato FTDW inizialmente sottoperfora rispetto ai metodi più complessi di WSL come cosine.</sample>
    <sample id="932">However, if we allow to continue fine-tuning on the clean samples then ftw performs equally well as other</sample>
    <sample id="933">Quindi in pratica non c'è motivo di usare metodi più complessi di WSL che richiedono più tempo di elaborazione e spazio su disco.</sample>
    <sample id="934">In sintesi, abbiamo dimostrato che recenti modelli di apprendimento supervisionato richiedono campioni puliti e manualmente annotati per funzionare correttamente. Le loro prestazioni e praticità sono pesantemente sovrastimata.</sample>
    <sample id="935">Our concrete recommendations for future work are as follows.</sample>
    <sample id="936">Prima, rapporta i criteri di selezione del modello. Ad esempio, rapporta se la selezione del modello è basata su campioni di validazione puliti.</sample>
    <sample id="937">Secondo, i modelli WSL dovrebbero essere confrontati con baselines a lungo termine come i modelli pre-addestrati su dataset. Terzo, l'ottimizzazione continuata è un modello semplice ma potente che dovrebbe essere considerato in future work in WSL.</sample>
    <sample id="938">Finalmente, abbiamo aperto sorgente il nostro codice. Puoi trovarlo nella Q&amp;amp;A del slide qui dietro. Per favore, senti di fare un check-in. Grazie e buona conferenza.</sample>
    <sample id="939">I metodi di valutazione comuni per i sistemi di dialogo includono l'uso di giudizi umani, come chiedere ai giudici umani di selezionare quale delle due conversazioni sia migliore o di valutare le conversazioni utilizzando una scala di Likert.</sample>
    <sample id="940">Ci sono cinque autori coinvolti nell'articolo.</sample>
    <sample id="941">Per risolvere il problema dell'identità dell'entità che il pronome "he" si riferisce a, è necessario conoscere due tipi di informazione: le conoscenze specifiche dell'entità e le conoscenze di sfondo. In questo caso, le conoscenze specifiche di Servin sono che è un giudice e le conoscenze di sfondo sono che i giudici decidono cause in tribunali.</sample>
    <sample id="942">Sì, il codice è disponibile su GitHub.</sample>
    <sample id="943">Sì, gli annotatori per NLPositionality sono bilanciati rispetto a ciascun gruppo demografico, ad esempio Paese, genere, ecc.</sample>
    <sample id="944">Le frasi nel dominio accettabile sono state perturbate in modo simile, con un aumento di tutte le perturbazioni.</sample>
    <sample id="945">Valutare dimensioni significa valutare diverse aspetti di qualcosa per capire le sue caratteristiche e le sue caratteristiche.</sample>
    <sample id="946">I fornitori dell'articolo sono affiliati all'Università di Scienze e Tecnologia di Cina.</sample>
    <sample id="947">La forma del prompting è cruciale per il caso di zero e uno shot prompting.</sample>
    <sample id="978">I modelli di dialogo che i ricercatori hanno testato sono quelli dei bot.</sample>
    <sample id="979">Il numero di autori coinvolti nell'articolo non è specificato nella descrizione fornita.</sample>
    <sample id="980">Un buon pianificatore dovrebbe redigere script che siano ragionabili e fedeli alle vincoli.</sample>
    <sample id="981">Il numero di autori coinvolti nell'articolo non è specificato nella descrizione fornita.</sample>
    <sample id="982">Il nome della relatrice o del relatore è Vasudeva.</sample>
    <sample id="983">I fornitori di servizi di sicurezza e la Harvard Business School.</sample>
    <sample id="1021">Gli errori più comuni di PaLM sono omission errors.</sample>
    <sample id="1022">Ecco, sono James Finch e sono Sarah Finch. Oggi ti useremo per dirti tutto su ABC-Eval, un nuovo approccio dimensionale per valutare l'intelligenza artificiale di conversazione.</sample>
    <sample id="1023">Questo lavoro è stato fatto dal laboratorio NLP di Emory, guidato dal professor Geno Choi all'Emory University e in collaborazione con Amazon Alexa AI.</sample>
    <sample id="1024">Be that say that you just developed a dialogue model and you want to see how well it compares against the current state of the art.</sample>
    <sample id="1025">La pratica comune è di utilizzare un giudizio umano, come ad esempio chiedendo a giudici umani di scegliere quale delle due conversazioni sia migliore o di valutare le conversazioni utilizzando una scala di Likert.</sample>
    <sample id="1026">Questi approcci funzionano bene per fornire valutazioni holistiche della qualità del dialogo in generale, ma la qualità del dialogo ha molti aspetti. Quindi, potresti voler valutare diverse dimensioni della qualità del chat per capire le forze e le debolezze del modello a un livello più fine.</sample>
    <sample id="1027">Un approccio è quello di chiedere semplicemente ai giudici umani di valutare diversi aspetti della qualità del dialogo, come la rilevanza delle risposte dei modelli, utilizzando metodi esistenti basati su scala comparativa o scala Likert.</sample>
    <sample id="1028">Tuttavia, crediamo che ci sia un策略更精确和可靠的维度对话评估。</sample>
    <sample id="1029">Il nostro approccio tenta di ridurre la soggettività della valutazione umana, mettendo in evidenza esplicitamente se o no ogni risposta del modello esprime certi comportamenti, come fornire informazioni non rilevanti o contraddire se stessa.</sample>
    <sample id="1030">Chiamiamo questa approccio annotazione comportamenti in chat o ABC-Eval in breve. Abbiamo sviluppato questo metodo per coprire in modo esaustivo i comportamenti dei modelli di chat che sono stati suggeriti di influenzare la qualità del chat recentemente nella letteratura.</sample>
    <sample id="1031">ABC-Eval è capace di misurare le tassi con cui i modelli di chat commettono errori stilistici vari.</sample>
    <sample id="1032">Ad esempio, ABC-Eval misura il numero di turni in cui un modello di chat ignora il proprio interlocutore o dice qualcosa di non rilevante.</sample>
    <sample id="1033">Contradice se stesso o il proprio partner, elenca fatti errati o viola le conoscenze comuni e quando il modello riesce o fallisce a dimostrare compassione.</sample>
    <sample id="1034">Per determinare quale tipo di valutazione è più efficace, abbiamo selezionato quattro modelli di chatbot di ultima generazione e li abbiamo valutati su 100 conversazioni umano-bots per modello utilizzando ABC-Eval.</sample>
    <sample id="1035">Per confronto, abbiamo anche valutato queste conversazioni utilizzando tre metodi esistenti: valutazioni con una scala di Likert al livello della parola, valutazioni con una scala di Likert al livello del dialogo e confronti a livello di dialogo bivariato.</sample>
    <sample id="1036">Per ciascuno dei metodi esistenti, abbiamo raccolto valutazioni su otto degli aspetti più comunemente misurati del dialogo, poiché questa è la pratica standard per valutare i modelli di chattenzio al lungo di diverse dimensioni.</sample>
    <sample id="1037">Dall'analisi dei risultati di queste valutazioni, abbiamo scoperto che le etichette di comportamento ABC (EVAL) sono in generale più affidabili rispetto alle etichette raccolte da metodi esistenti, come misurato dalla concordanza tra gli annotatori su 100 conversazioni doppioni etichettate.</sample>
    <sample id="1038">Inoltre, i etichett ABC EVL sono più predittivi della qualità della conversazione rispetto ai metri prodotti da metodi esistenti, come dimostrato da questa analisi di regressione lineare semplice.</sample>
    <sample id="1039">Ad esempio, si può vedere come misurare la proporcione di turni con contrasti tra se stessi e partner spiega il 5% e il 10% della qualità della conversazione rispettivamente, mentre i punteggi di consistenza di Likert spiegano solo il 4% o meno.</sample>
    <sample id="1040">Infine, abbiamo verificato se ogni metrica di valutazione cattura un aspetto unico della qualità del chat utilizzando una regressione lineare a passi.</sample>
    <sample id="1041">Puoi vedere come la combinazione di tutti i metriche ABC eval spiega più del 25% della qualità della conversazione e, se ne rimuove una ad una, la maggior parte di queste perdono una quantità decente di informazioni sulla qualità.</sample>
    <sample id="1042">Sul altro lato, la combinazione di tutti i livelli di metriche di Likert spiega molto meno della qualità e meno di queste metriche trasmettono informazioni uniche.</sample>
    <sample id="1043">Questi metri ABC EVL affidabili, informativi e distinti ci permettono di valutare l'intelligenza artificiale conversazionale con una risoluzione più alta rispetto ai metodi precedenti che possono raggiungere.</sample>
    <sample id="1044">Puoi vedere che in risultati del nostro esperimento cheSeveral challenges still remain and have been precisely quantified for example, the bots we tested have common sense violations in around twenty percent of their responses.</sample>
    <sample id="1045">Prodotto informazione inerente circa il 15 percento delle risposte e contraddicono se stessi o i propri partner circa il 10 percento del tempo.</sample>
    <sample id="1046">Con l'accelerato ritmo di miglioramento nel campo, molte di queste tassi di errori potrebbero vedere un declino in nuove versioni rilasciate da quando è stata condotta la nostra valutazione. Tuttavia, questo è tutto più motivo per perseguire metri di valutazione affidabili e precisi per confrontare i modelli.</sample>
    <sample id="1047">Speriamo che ABC eval possa essere sfruttata da altri nel campo come un passo significativo in questa direzione e ci guardiamo avanti a vedere come l'IA conversazionale avanzerà nei prossimi mesi e anni. Grazie per il tuo supporto.</sample>
    <sample id="1048">Gli autori dell'articolo sono affiliati all'Emory NLP Lab, all'Emory University e collaborano con Amazon Alexa AI.</sample>
    <sample id="1049">CFT significa Continuous Fine Tuning.</sample>
    <sample id="1050">Ci sono sette autori coinvolti nell'articolo.</sample>
    <sample id="1051">Ciao, mi chiamo Kaiyuan e presenterò il nostro lavoro intitolato "Quando la traduzione richiede contesto: un'esplorazione multilingue guidata da dati". Questo lavoro è stato realizzato in collaborazione con Patrick Franasz, Emil Niu, Andrea F. D. Martins e Graham Neubig.</sample>
    <sample id="1052">So a lot of translations depend on context. For example, how would we translate mole in this sentence?</sample>
    <sample id="1053">Se la frase precedente era che le cose potrebbero iniziare a diventare pericolose se i ministri scoprono, allora Moore si riferisce a un segreto. Ma se la frase precedente era che potrebbe essere qualcosa di serio, dottore, allora Moore si riferisce a una cicca natale.</sample>
    <sample id="1054">So depending on context, the meaning of the word changes and therefore its translation changes as well.</sample>
    <sample id="1055">Tuttavia, valutare quanto bene i modelli possano tradurre casi come questi è piuttosto difficile. In primo luogo, poiché solo una piccola parte delle traduzioni dipende dal contesto, che rende le metriche a livello di corpus come BLEU incapaci di catturare queste traduzioni.</sample>
    <sample id="1056">Alcuni hanno suggerito una valutazione specificata per traduzioni dipendenti dal contesto ma questi risorse possono supportare solo tipi limitati di traduzioni dipendenti dal contesto e insiemi limitati di lingue poiché di solito si basano su conoscenze umane e curazione.</sample>
    <sample id="1057">In this work, we try to answer these two questions first, when does translation require context and second, how well do models handle these cases?</sample>
    <sample id="1058">To answer the first question, we started by measuring how much a word depends on context during translation.</sample>
    <sample id="1059">In the previous work, we introduced cxmi as a measure for context usage by machine translation models and this is done by measuring how much information the context c provides about the target y given the source x.</sample>
    <sample id="1060">Puoi pensare a c x m i come all'informazione guadagnata fornendo contesto al modello.</sample>
    <sample id="1061">In this work, we extend c x m i to point-wise c x m i which can measure context usage at the sentence level or at the word level we can think of words that have high p c x m i as ones that require context for translation.</sample>
    <sample id="1062">Now we analyze words with high p six a m i to look for patterns between these words.</sample>
    <sample id="1063">And we performed our analysis on transcripts of ted talks that have been translated from english to fourteen different languages.</sample>
    <sample id="1064">We perform our analysis at three different levels. First, we look at parts of speech tags that have high means p x c x m i.</sample>
    <sample id="1065">E questa ci consente di trovare, ad esempio, i prononi in arabo che hanno la stessa iperesemmate e queste possono essere spiegate in quanto l'inglese non ha pronomi doppii, quindi è necessario contesto per determinare se un pronome è doppio quando tradotto in arabo.</sample>
    <sample id="1066">Inoltre, scopriamo che certe lingue richiedono contesto quando dobbiamo scegliere la forma appropriata di un verbo. In tal caso, analizziamo gli oggetti vocabolari che hanno un'average di frequenza elevata per tutte le sue occorrenze diverse.</sample>
    <sample id="1067">And this helps us identify cases like the one here where in chinese you need context to translate proper nouns to make sure that you're using the same translation within the document.</sample>
    <sample id="1068">And similarly, we find that context is supported to translate in the right formality.</sample>
    <sample id="1069">E infine, analizziamo i token individuali che hanno alta PESMI e questo ci consente di identificare fenomeni che non possono essere catturati solo dal testo in sé ma piuttosto esprimendosi nella struttura istantanea, ad esempio l'elispe risoluzione.</sample>
    <sample id="1070">Ora utilizziamo i nostri findings dalla nostra analisi per progettare un benchmark per la traduzione di documenti in italiano.</sample>
    <sample id="1071">Per ciascuno dei cinque fenomeni discorsivi che abbiamo identificato, creiamo tagger per automaticamente identificare parole che appartengono al fenomeno e chiamiamo il nostro tagger il multi lingua discours aware o muuda tagger.</sample>
    <sample id="1072">We can then also note that different languages have different proportions of these discursive phenomena.</sample>
    <sample id="1073">We then use the muda tagger by applying the tagger on the parallel corpora that we want to use for evaluation and we apply our translation metrics of choice on the cognitively dependent examples that the muda tagger has identified.</sample>
    <sample id="1074">And finally we use our benchmark as well as other metrics to evaluate different models on the document level machine translation.</sample>
    <sample id="1075">Prima di tutto, quando usiamo corpus di metri so, per blu, trovi che i modelli cognitivi hanno le prestazioni migliori.</sample>
    <sample id="1076">But then if we use comet, context-aware models perform best and if we use word f measure, then models with or without context have comparable performance.</sample>
    <sample id="1077">Questo di nuovo dimostra che è difficile determinare il miglior sistema di traduzione a livello di documento se utilizziamo metriche a livello di corpus.</sample>
    <sample id="1078">Ora utilizziamo il modello benchmark per valutare i modelli e scopriamo che i modelli che usano contesto sono significativamente più accurati rispetto ai modelli che non usano contesto per certi fenomeni discorsivi, come la formalità e la coesione lessicale.</sample>
    <sample id="1079">Ma queste strutture non sono molto migliori delle strutture che non usano contesto per其他现象，比如椭圆、词性和词形。因此这表明我们需要在文档级别翻译上取得更多进展。</sample>
    <sample id="1080">We also compare different commercial systems, and our benchmarks show that deepblue is usually more accurate than google translate for document-level translation.</sample>
    <sample id="1081">In sintesi, eseguiamo un'analisi basata su dati per identificare quando le traduzioni richiedono contesto.</sample>
    <sample id="1082">E quindi utilizziamo i nostri raffinamenti per costruire un benchmark per la traduzione di documenti, che ci aiuta a identificare quali modelli di fenomeni discorsivi possono gestire bene o no e quali sistemi di traduzione sono buoni per la traduzione di documenti.</sample>
    <sample id="1083">Grazie mille per l'attenzione, ci vediamo in ritardo.</sample>
    <sample id="1084">Il nome del relatore è Usen John.</sample>
    <sample id="1121">Il nuovo metodo non ha un nome specifico.</sample>
    <sample id="1122">Il metodo utilizza le parole contrassegguate per identificare le parole che distinguono i gruppi contrasseguiti da quelli non contrasseguiti.</sample>
    <sample id="1123">I fornitori dell'articolo sono studenti di PhD all'Università di Washington.</sample>
    <sample id="1124">La prima struttura di dipendenza simmetrica menzionata è il PragaApproach.</sample>
    <sample id="1125">Il relatore è James Finch e la relatrice è Sarah Finch.</sample>
    <sample id="1126">Ci sono quattro autori coinvolti nell'articolo.</sample>
    <sample id="1127">I test di fenomeni sintattici possono utilizzare insiemi di dati come grammaticalità, plausibilità e accettabilità in termini di stereotipi.</sample>
    <sample id="1161">I metodi per la prima domanda di ricerca sono abbreviati come WSL.</sample>
    <sample id="1162">Il modello viene valutato su 11 attività di immissione biomedica e clinica.</sample>
    <sample id="1226">CamemBERT viene inizialmente addestrato su un subset di 4 GB di Natsos.</sample>
    <sample id="1227">Il nome del relatore è Adam Strykowski.</sample>
    <sample id="1228">I risultati dell'experiment hanno dimostrato che la performance degli modelli degrada con un intervallo temporale più grande, confermando l'ipotesi che la deriva temporale è la causa principale della perdita di prestazioni.</sample>
    <sample id="1269">I token devono essere permutati per la sequenza di output perché, anche se hanno tutti i token necessari, non sono ordinati correttamente. Utilizzando un modello aggiuntivo, è possibile prevedere una permutazione che li metterà in ordine corretto.</sample>
    <sample id="1270">Gli autori hanno suggerito di aumentare la trasparenza sui metodi di mitigazione dei bias per capire se i modelli stanno producendo pregiudizi in base a stereotipi positivi o anti-stereotipi, o se ci sono altre cause.</sample>
    <sample id="1271">I input inaccettabili di coppia minima sono le frasi grammaticalmente sbagliate o non grammaticalizzate che il modello deve distinguere da那些可接受的句子。</sample>
    <sample id="1272">I testi non specificano le metriche di valutazione utilizzate.</sample>
    <sample id="1273">La metrica utilizzata per misurare l'accordo tra i fornitori è la percentuale di accordo inter-annotatore.</sample>
    <sample id="1274">Il dominio scelto per aggiungere frasi completamente scollegate alle query inaccettabili e accettabili è Wikipedia.</sample>
    <sample id="1275">I fornitori di documenti e i fornitori di servizi di traduzione.</sample>
    <sample id="1276">MultiInstruct differisce dagli altri parametri di riferimento in quanto include un dataset di istruzioni multi-modal, mentre la maggior parte dei precedenti modelli si concentrano su task linguisticamente soli.</sample>
    <sample id="1277">Ci sono due autori coinvolti nell'articolo: il team del laboratorio NLP dell'Emory e Amazon Alexa AI.</sample>
    <sample id="1278">La coordinazione binaria si riferisce alla capacità di un essere umano di percepire due stili di scrittura contemporaneamente.</sample>
    <sample id="1279">I prompt sono stati utilizzati per un periodo di 12 settimane in media.</sample>
    <sample id="1280">I risultati suggeriscono che i modelli più piccoli di T5 possono superare i modelli più grandi quando sono adeguatamente addestrati su dataset appropriate.</sample>
    <sample id="1281">Hi, I am Manish Lavakar and I will present you our work on Dr. Bert, a robust pre-trained model in French for biomedical and clinical domain.</sample>
    <sample id="1282">In questa presentazione, innanzitutto parliamo di modellazione linguistica in salute. Poi presenteremo i principali contributi del nostro articolo.</sample>
    <sample id="1283">Introduciamo il primo modello biomedico in francese, chiamato Dr. Bert, che è basato su Roberta e train on Natsos, che è un dataset di dati medici scarolati dalla rete.</sample>
    <sample id="1284">We also introduce a comparison of models with multiple pre-training settings and data sources. Then, we present our results on eleven biomedical and clinical downstream tasks in French.</sample>
    <sample id="1285">And finally, we conclude about the experiments and give you more details about how to access to the models.</sample>
    <sample id="1286">Da quando è stato rilasciato nel 2018, BERT è diventato uno dei metodi più efficaci per risolvere compiti di elaborazione del linguaggio naturale e ha offerto un'enorme migliora rispetto ai metodi statici e costituzionalizzati storici come Word2Vec, FastText o WordPiece.</sample>
    <sample id="1287">Da allora, questo modello è stato adattato a molte altre lingue, come in francese con Camembert e in tedesco con BioMedBert e BioBert, ma anche in clinico con ClinicalBert. Ma in generale, è stato adattato maggiormente in inglese.</sample>
    <sample id="1288">Modello specializzato per altre lingue che è scarso e spesso basato su continuo pretraining a causa della mancanza di grandi quantità di dati.</sample>
    <sample id="1289">Tuttavia, French non aveva nessun open source moderno per biomedicina finora.</sample>
    <sample id="1290">We, so we ask ourselves question about what is the most appropriate data sources for a wide range of usage and those crowd data are good substitution for clinical data.</sample>
    <sample id="1291">Per risolvere questa questione, confrontiamo il modello di Bert con il nostro modello Shubert, che è basato su un'analisi dei dati ottenuti dal non-profit hospital ad attuare la nostra casa.</sample>
    <sample id="1292">Successivamente ci chiediamo quanta memoria dobbiamo usare per addestrare un modello specializzato su dati in francese. Sono 4 GB, 8 GB o di più?</sample>
    <sample id="1293">To answer this question we first train and compare four from scratch models a first version of drbert with seven gigabytes of natoos a second version of four gigabytes subset of natoos,</sample>
    <sample id="1294">Una prima versione di Shubert che è un modello clinico con 4 gigabyte di sentenze tratti da note cliniche e una versione finale di Shubert con un mix di 4 gigabyte subset di nazioni e 4 gigabyte di note cliniche.</sample>
    <sample id="1295">In addition to this comparison, we introduce three models trained on continual pre-training to analyze the impact of pre-training strategies.</sample>
    <sample id="1296">One based on the weight of camembert and trained on four gigabits of data, another also based on camembert but trained this time on the four gigabytes of klinkenlauts.</sample>
    <sample id="1297">And finally one based on english biomedical model per berta and trained on four gigabytes subset of natures. in total we have seven models.</sample>
    <sample id="1298">To evaluate our seven models, we use them to perform public and private downstream tasks such as named entity recognition classification, part-of-speech tagging, and question answering.</sample>
    <sample id="1299">Questi modelli sono confrontati a sei modelli Benzine, tra cui Camber Oscar 108 GB, Camber Oscar 4 GB, Camber Cisnet 4 GB, Tummett by Albert e Clinical Albert.</sample>
    <sample id="1300">The evaluation of highlight that model perform best on the task with data of the same nature as those on which the model has been trained.</sample>
    <sample id="1301">Tuttavia, possiamo ottenere i dati da fonti etologiche e osservare che i dati da fonti etologiche appaiano più versatile. Inoltre, osserviamo che l'uso di più dati traduce in un migliore prestazione.</sample>
    <sample id="1302">In generale, l'addestramento da zero sembra ottenere prestazioni più elevate per la maggior parte dei task.</sample>
    <sample id="1303">Tuttavia, i nostri esperimenti su continuo pretraining, utilizzando il weight e tokenizer di patentbert train on the four gigabyte subset of natasha, hanno dato risultati simili a quelli ottenuti con doctorbert four gigabyte da scritto.</sample>
    <sample id="1304">Non è il caso per il modello basato su camber weights e tokenizer, che soffre di problemi di stabilità.</sample>
    <sample id="1305">Finalmente, come conclusione il nostro proprio sistema offre un better performance on nine of the eleven dnd tasks and surpass globally the result of the generative model here camembert.</sample>
    <sample id="1306">We also observe that specialized data is better, more specialized data is better, but it doesn't scale well.</sample>
    <sample id="1307">All the pre-trained models obtained from nats are freely available and on youtube face, and all the training scripts are on our github repository.</sample>
    <sample id="1308">So thank you for for this presentation and we are looking forward to exchange at the post session in toronto.</sample>
    <sample id="1309">Nel lavoro vengono esaminate strategie di apprendimento come l'addestramento a partire da zero e l'apprendimento continuo con pre-addestramento.</sample>
    <sample id="1310">Il fattore di overfitting dovuto al riutilizzo del test è zero.</sample>
    <sample id="1311">La qualità della semplificazione è stata valutata utilizzando i punteggi ottenuti da due modelli finetunati, il modello di Long Impart per la semplificazione a livello di documento e il modello di Long Impart base per la semplificazione a livello di frase. I punteggi ottenuti sono stati considerati migliori rispetto ai punteggi di riferimento e hanno fungendo come benchmark per il problema di automatic text simplification in futuro.</sample>
    <sample id="1312">Sì, i modelli linguistici presentano bias politici diversi.</sample>
    <sample id="1313">Ciao, mi chiamo Matthias Lendemann e oggi voglio darti un'introduzione rapida al nostro articolo sulla generalizzazione di composizione senza alberi utilizzando etichettatura multi-set e permutazioni latenti.</sample>
    <sample id="1314">Questo è un lavoro di gruppo con i miei consiglieri Alexander Koller e Ivan Titov.</sample>
    <sample id="1315">La generalizzazione composizionale può essere compresa come la capacità di un apprendente di gestire una maggiore ricorsione e composizioni nascoste di frasi che hanno essere state viste individualmente durante la formazione.</sample>
    <sample id="1316">In contesto di parsing semantico, testare per generalizzazioni compostionali potrebbe apparire così: come di consueto, abbiamo un insieme di esempi di frasi in questo caso, la gallina dormì e Mary sapeva che la gallina dormì.</sample>
    <sample id="1317">Queste affermazioni sono associate con forme logiche che rappresentano gli aspetti principali del loro significato.</sample>
    <sample id="1318">In contrast to standard machine learning evaluation, the test set does not come from the same distribution but contains structurally unseen logical forms.</sample>
    <sample id="1319">In questo esempio, il modello ha visto ricorso superficiale durante la formazione e è testato su un esempio con ricorso più profondo.</sample>
    <sample id="1320">Naive sequence-to-sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.</sample>
    <sample id="1321">In particolare, essi spesso falliscono a riprodurre le corrispondenze sistematiche tra input e output, come quelli che sono color codeati nell'esempio.</sample>
    <sample id="1322">Un metodo popolare per affrontare questo è integrare i alberi nei modelli.</sample>
    <sample id="1323">I alberi sono intesi a catturare il processo di composizione che si relata ad affermazioni con le forme logiche.</sample>
    <sample id="1324">Questo funziona bene ma i trappole sono di solito non fornite e devono essere ottenute in qualche modo.</sample>
    <sample id="1325">Questo può essere complicato e spesso un processo computazionalmente costoso. Di solito, questo implica un'elaborata formalizzazione specifica di pre-elaborazione delle forme logiche, ad esempio per gestire simboli variabili.</sample>
    <sample id="1326">Obtaining trees may also involve specialized grammar induction procedures.</sample>
    <sample id="1327">In questo articolo, non utilizziamo alberi e introduciamo un nuovo modello sequenza a sequenza che modella direttamente le corrispondenze tra frammenti dell'input e frammenti dell'output.</sample>
    <sample id="1328">Per la prima volta, mostriamo una forte generalizzazione a una ricorrenza più profonda senza fare ricorso a alberi.</sample>
    <sample id="1329">Il nostro approccio prevede l'output dal input in due passi.</sample>
    <sample id="1330">Prima di tutto, taggiamo ogni token di input con un insieme non ordinato di token che appariranno nell'output.</sample>
    <sample id="1331">After the first step we have all the right tokens but they are not ordered.</sample>
    <sample id="1332">That's why in the second step we use another model to predict a permutation to put them into the right order.</sample>
    <sample id="1333">Introduciamo un nuovo metodo per prevedere una permutazione che non imposa alcun vincolo rigoroso sulle possibili permutazioni. Questo rende il nostro approccio piuttosto flessibile e espressivo.</sample>
    <sample id="1334">Conceptually our permutation model works roughly like this.</sample>
    <sample id="1335">We go from left to right over the output and determine which multi-set token to put in every position for the first output position we simply select one as highlighted in red.</sample>
    <sample id="1336">Allora, saltiamo al token multisets successivo per determinare il token successivo nell'output.</sample>
    <sample id="1337">Determiniamo il terzo token nell'output in modo simile saltando a un altro token multi-settato. Continuiamo questo processo.</sample>
    <sample id="1338">Until every token from the first stage has been visited exactly once.</sample>
    <sample id="1339">Per darti un sapore dei risultati sperimentali, qui confrontiamo il nostro metodo con altri modelli TreeLSTM sul benchmark Cogs. Il nostro modello supera gli altri di un margine significativo in quanto a generalizzazioni verso una ricorsione più profonda.</sample>
    <sample id="1340">Alcuni altri tipi di strutturale generalizzazioni rimangono molto difficili, tuttavia.</sample>
    <sample id="1341">In our paper, we solve a couple of interesting technical challenges.</sample>
    <sample id="1342">In primo luogo, l'alignment tra input e output non è dato dai dati di addestramento. Di conseguenza, per un token specifico non conosciamo da quale multi-settore è derivato, il che rappresenta un problema durante l'addestramento.</sample>
    <sample id="1343">Inoltre, a volte ci sono molte permutazioni che sono coerenti con i dati, ma la versione grammaticalmente corretta è latente. Abbiamo affrontato questo problema inducendo l'allestimento come parte della formazione.</sample>
    <sample id="1344">Il nostro metodo di permutazione è molto flessibile, ma introduce il sfidone di trovare la permutazione con punteggio più elevato, che è NP-difficile. Questo è perché è legato al problema del commercialista viaggiatore.</sample>
    <sample id="1345">Approximiamo questa con un rilassamento continuo amico al GPU che inoltre ci consente di propagare all'indietro attraverso la soluzione e imparare le permutazioni linguisticamente più plausibili.</sample>
    <sample id="1346">Se vuoi imparare di più sulle nostre esperienze e su come affrontiamo queste sfide, ti prego di dare un'occhiata al nostro articolo o di venire a vedere il nostro poster.</sample>
    <sample id="1347">La dissonanza cognitiva è quando ci sono due credenze o azioni che non sono in accordo tra di loro.</sample>
    <sample id="1348">Il modello linguistico più liberale è GPT-4.</sample>
    <sample id="1349">Sì, l'addestramento cumulativo funziona meglio di quello iterativo nell'apprendimento attivo.</sample>
    <sample id="1350">La relatrice o il relatore è Sarah Papi.</sample>
    <sample id="1351">I dati nel parametro di riferimento MuDa sono stati tratti da transcrizioni di TED Talks tradotte in 14 lingue diverse.</sample>
    <sample id="1385">Il nome del relatore è Mateusz Lendemann.</sample>
    <sample id="1386">Il trasferimento interlinguistico è un processo in cui un modello di intelligenza artificiale viene addestrato su un linguaggio e successivamente utilizzato per prevedere il output in un altro linguaggio.</sample>
    <sample id="1387">I fornitori dell'articolo sono affiliati all'Università di Salamanca in Germania.</sample>
    <sample id="1388">Gli autori si basano su due misure di latenza: la media dei tempi di elaborazione e la media dei tempi di elaborazione computazionale.</sample>
    <sample id="1389">Ciao a tutti, mi chiamo Manjata e oggi io e il mio collaboratore Martin stiamo presentando il nostro lavoro "Kit must have" che valuta l'integrazione di conoscenze da diverse fonti. Questo lavoro è un合作 tra McGill University, Mila e Microsoft Research.</sample>
    <sample id="1390">I modelli di intelligenza linguistica nazionale si basano su una varietà di fonti di conoscenza, tra cui la conoscenza contenuta nei loro parametri, di solito acquisita tramite un pre-training e la conoscenza fornita in input durante il tempo di inferenza.</sample>
    <sample id="1391">Recenti opere in task come la risoluzione di domande hanno dimostrato che i modelli possono utilizzare conoscenze precedentemente imparate per risolvere il compito.</sample>
    <sample id="1392">Ma la comprensione del linguaggio naturale spesso richiede conoscenza che è anche fornita in tempo reale.</sample>
    <sample id="1393">Ad esempio, in la frase John vide il nuovo eletto presidente al televisore.</sample>
    <sample id="1394">I parametri di addestramento precedenti possono contenere informazioni su cosa è un presidente e cosa è un atto, ma non possono rilevabilmente conoscere chi sia questa entità specifica di momento o chi sia il nuovo presidente, poiché il presidente potrebbe essere cambiato dopo l'addestramento.</sample>
    <sample id="1395">Tuttavia, modelli riusciti per compiti di intelligenza artificiale ad alta intensità di conoscenza richiedono la capacità di integrare e utilizzare sia conoscenze pre-addestrate in anticipo che conoscenze acquisite durante l'inferenza.</sample>
    <sample id="1396">In questa work proponiamo un insieme di test diagnostic per la integrazione conoscitiva.</sample>
    <sample id="1397">Introduciamo un compito di risoluzione di riferimento corretto progettato per testare la capacità di estrarre conoscenze disponibili in diverse fonti. Evaluiamo il dataset con percorsi di studio umani e modelli di risoluzione di riferimento corretti.</sample>
    <sample id="1398">Ecco un esempio dalla nostra base di dati. Tervin è un giudice. Kia è un pastoressa. Tervin e Kia si sono incontrati in un parco dopo una lunga giornata di lavoro, decidendo casi in un tribunale. Era felice di rilassarsi.</sample>
    <sample id="1399">La task qui consiste a identificare l'entità corretta che il pronome "he" si riferisce a, in questo caso, è "servo".</sample>
    <sample id="1400">La risoluzione di un pronome richiede due tipi di informazione: prima, conoscenza specifica dell'entità, come ad esempio "Savell è un giudice" e, secondo, conoscenza di sfondo, come ad esempio "I giudici decidono cause in tribunali".</sample>
    <sample id="1401">In generale, le conoscenze di sfondo sono acquisite durante la pre-addestramento dei modelli di lingua larga, mentre le conoscenze specifiche dell'entità vengono tipicamente osservate durante l'inferenza.</sample>
    <sample id="1402">Vary the availability of these two pieces of information such that it may either be found in a single source or in multiple sources.</sample>
    <sample id="1403">We have defined three settings of kipmos first with the tablica setting background pretrain where background knowledge is assumed to be available at pretraining time.</sample>
    <sample id="1404">Second, there is the background both setting where background knowledge is available at both pre-training time and inference time. Lastly, the background inference setting where both knowledge types are available only at inference time.</sample>
    <sample id="1405">Questa ultima impostazione è particolarmente interessante, poiché simula il caso in cui la conoscenza del contesto necessaria per risolvere un compito non è parte dei modelli pre-addestrati. Ad esempio, poiché nuove occupazioni sono sviluppate dopo l'epoca di addestramento.</sample>
    <sample id="1406">Ecco un esempio di come controllare l'accessibilità dei file in due sorgenti.</sample>
    <sample id="1407">In un contesto di allenamento precedente, supponiamo che il connaissances politici di un individuo siano contenuti in i parametri di allenamento precedente. In un contesto specifico, forniamo la conoscenza anti-specifica di Churchill come politico.</sample>
    <sample id="1408">In the background both setting we additionally provide not only anti-specific but also background knowledge about politicians in the interview context.</sample>
    <sample id="1409">In the background inferior setting provide the fictional occupation miretto instead politician because miretto is unlikely to be contained in a pre-trained</sample>
    <sample id="1410">Valutiamo il dataset sia con partecipanti umani che con modelli di frequenza e risoluzione. In questa figura mostriamo i risultati dei migliori modelli sul variante più difficile del setup pre-addestrato in background.</sample>
    <sample id="1411">Without task-specific training on kinmos both models do not perform well when trained on kinmos however both c2f and build for qf perform significantly better than the random choice.</sample>
    <sample id="1412">Suggerisce che quando addestrati su un insieme di dati di riferimento generale, i modelli imparano a sfruttare cenni superficiali che non sono utili quando si testa su KidMoos, poiché tali cenni sono stati rimossi.</sample>
    <sample id="1413">Additional experiences with fictional knowledge indicate that even the best-performing models cannot reliably integrate background knowledge provided only at inference time.</sample>
    <sample id="1414">Per riassumere i principali punti di rilievo del nostro articolo, molte rappresentazioni rivoluzionarie sembrano incapaci di razionalizzare conoscenze provenienti da diverse fonti senza un addestramento specifico. Tuttavia, con un addestramento specifico, alcune delle nostre rappresentazioni riescono a integrare conoscenze provenienti da diverse fonti.</sample>
    <sample id="1415">Anche i modelli migliori sembrano avere difficoltà a integrare le informazioni di retrodominio presentate solo in fase di inferenza. Se siete interessati ad ulteriori dettagli, vi prego di leggere il paper e controllare il dataset in codice su GitHub. Grazie per l'attenzione.</sample>
    <sample id="1416">I metodi basati su alberi possono essere complessi e computazionalmente costosi, e richiedono una formalizzazione specifica di pre-elaborazione dei modelli logici per gestire simboli variabili. Inoltre, ottenere gli alberi può anche implicare processi di indurre grammatica specializzata.</sample>
    <sample id="1417">I dettagli sull'identità e le affiliazioni degli autori dell'articolo non sono forniti nella voce di testo.</sample>
    <sample id="1418">Ciao, mi chiamo Myra e oggi parliamo del mio articolo su personaggi marcato con i bias usando promempi di linguaggio naturale per misurare i pregiudizi in modelli di linguaggio. Questo lavoro è stato fatto in collaborazione con Essam Dermouche e Dan Juravsky.</sample>
    <sample id="1419">Negli anni recenti, molti hanno documentato la prevalenza di bias sociali e stereotipi in grandi modelli linguistici o LLMs.</sample>
    <sample id="1420">Tuttavia, queste misure hanno varie limitazioni. Di solito si basano su datasettelli costruiti a mano che richiedono molto tempo per essere curati.</sample>
    <sample id="1421">E anche di solito misurano solo stereotipi molto specifici, che significa che non generalizzano bene a altre demografiche o contesti o semplicemente catturano associazioni molto generali e ampie, come le associazioni negative con particolari gruppi.</sample>
    <sample id="1422">Tuttavia, la maggior parte del lavoro in questo campo non tiene conto della intersecatività, che è la nozione che identità sociali multifacettate possono combinare bias e essere unico luogo di danno.</sample>
    <sample id="1423">Per superare queste limitazioni, ci si basa sul fatto che questi modelli più recenti addestrati con istruzioni sono molto bravi nel rispondere a istruzioni e promem.</sample>
    <sample id="1424">Così possiamo chiedere al modello di generare un profilo, che è una descrizione di un individuo immaginario utilizzando un prompt come: immagina che tu sia una donna asiatica. Descrivi te stesso.</sample>
    <sample id="1425">E possiamo vedere immediatamente che questa è molto generalizzabile a qualsiasi demografia, poiché possiamo specificare qualsiasi segnaposto che vogliamo in questo prompt.</sample>
    <sample id="1426">Ecco qui alcune generazioni esempi da GPT-4.</sample>
    <sample id="1427">Subito vediamo che, anche se gli output non sono negativi o tossici nel senso tradizionale di queste parole,</sample>
    <sample id="1428">Ci sono alcuni interessanti modelli,</sample>
    <sample id="1429">La donna asiatica è descritta come non accattante la donna del Medio Oriente è riferita utilizzando parole come esotici e come riferendosi a una regione mesmerica.</sample>
    <sample id="1430">E entrambe le donne di colore personaggi fanno riferimento all'antistretto, mentre il personaggio bianco non ha niente del genere.</sample>
    <sample id="1431">To capture these patterns, our method has two parts the first one is generating these personas.</sample>
    <sample id="1432">I prompti per generare queste personaggi sono stati ispirati a un studio in cui hanno fornito questi prompti a soggetti umani, scoprendo che fornendogli i prompti, anche i soggetti umani erano in grado di raffigurare stereotipi razionali.</sample>
    <sample id="1433">E anche questo rende possibile una comparazione diretta tra le nostre persone generate e le risposte umane scritte.</sample>
    <sample id="1434">The second part is marked words, which is a method to identify the words that distinguish marked groups from unmarked ones, which I'll elaborate on shortly.</sample>
    <sample id="1435">Il beneficio di questo è che otteniamo stereotipi e模式特定，而无需依赖任何特定的词汇表。</sample>
    <sample id="1436">Il metodo dei segni marcato si basa sul concetto sociolinguistico di marcità, che afferma che ci è un default non marcato e qualsiasi gruppo che devia da quell' default è linguisticamente marcato.</sample>
    <sample id="1437">Ad esempio, la parola "uomo" o scusate, la parola "guerriero" è solitamente associata con gli uomini. Quindi quando le persone stanno descrivendo un guerriero che è una donna, di solito specificano "uomo guerriero" e mettono il termine con "donna".</sample>
    <sample id="1438">E più in generale, i gruppi dominanti in una società sono sia linguisticamente che socialmente non segnalati, mentre i gruppi marginalizzati sono generalmente segnalati.</sample>
    <sample id="1439">In our method, we first designate what the unmarked and marked groups are.</sample>
    <sample id="1440">E quindi confrontiamo i personaggi utilizzando il metodo dei pesi logit, che è in sostanza utilizzare le proporzioni logit ponderate per distinguere le parole più importanti per ciascun gruppo marcato.</sample>
    <sample id="1441">Per esempio, per le persone nere, faremmo analisi di combattimento e confronterei le proporzioni dei rapporti di legge e ordine rispetto sia alle persone bianche che alle persone maschili, poiché queste sono le due gruppi non marcato corrispondenti.</sample>
    <sample id="1442">Adesso, per i risultati. Allora, per prima cosa, utilizziamo un lessico di stereotipi e scopriamo che le personaggi generate contengono molto più stereotipi rispetto a quelli scritti umani.</sample>
    <sample id="1443">Tuttavia, quando ci guardiamo alla distribuzione dei vocaboli nel lessico, trovi diverse cose.</sample>
    <sample id="1444">Quindi, mentre le personaggi generate hanno tassi molto più alti di parole come "luxembourg" umanamente scritti hanno una distribuzione molto più ampia di parole, i verbi tipici che sono in personaggi generati sono davvero solo parole come "tall" e "athletic".</sample>
    <sample id="1445">So really just only the positive or at least non-negative ones.</sample>
    <sample id="1446">In effetti, questa lessicografia non cattura molte delle patterns dannose che vedemmo in precedenza. Quindi invece di farlo, useremo i risultati del nostro metodo di parole segnalate per dimostrare come queste parole positive facilitano i stereotipi e le narrativa essenziali.</sample>
    <sample id="1447">In our analysis, we review how these seemingly positive court trials reflect harmful patterns.</sample>
    <sample id="1448">Prima di tutto, i gruppi di marca hanno parole chiave che includono cose come cultura, tradizione, orgoglio e esotismo. Queste parole definiscono questi gruppi solo in relazione alla loro identità e li distinguono come diversi dal normale bianco.</sample>
    <sample id="1449">Questo ha portato a una lunga eredità di discriminazione e marginalizzazione per questi gruppi.</sample>
    <sample id="1450">Tuttavia, ci sono molte troppe comuni che sono riflette in queste parole, specialmente per le donne di colore. Ad esempio, le parole che descrivono le donne latine includono cose come vibrante e curvaceous.</sample>
    <sample id="1451">Which connect to a trope of tropicalism for asian women. The words are things like petite and delicate and silky,</sample>
    <sample id="1452">Che si collega a una lunga storia di donne asiatiche che sono stati sessualizzati, visti come molto dolci e sottomissi, eccetera.</sample>
    <sample id="1453">E finalmente, per le donne nere, vediamo che alcune delle parole chiave sono cose come forti e resilienti.</sample>
    <sample id="1454">This connects to an archetype that people have called the strong black woman archetype. And while it sounds like positive at first glance,</sample>
    <sample id="1455">Ci sono state ricerche che hanno dimostrato che questo tipo di archetipo è davvero dannoso, perché mette un'enorme pressione su queste demografie per essere resilienti e forti contro le difficoltà sociali.</sample>
    <sample id="1456">Sostiene che invece di cercare di superare queste ostacoli, mette pressione su queste persone per superarli, cosa che conduce a un insieme di risultati negativi sulla salute di queste persone tra gli altri danni.</sample>
    <sample id="1457">In modo più ampio, scopriamo che le parole per ciascun gruppo di marcatura quasi completamente riflettono narrativa essenzializzante.</sample>
    <sample id="1458">Così, sulla base di questi modelli, concludiamo con tre raccomandazioni per i proprietari dei modelli.</sample>
    <sample id="1459">Prima di tutto, dovremmo come ricercatori affrontare i stereotipi positivi e le narrazioni essenziali. Dovremmo anche utilizzare le lenti intersezionali per studiare le bias e i danni, perché ci sono molte cose che potrebbero essere trascurate se non lo facciamo.</sample>
    <sample id="1460">E infine, dovrebbero esserci maggior trasparenza sulla gestione dei bias.</sample>
    <sample id="1461">Because for instance like these positive stereotypes we don't know if it's because there is some sort of like weird</sample>
    <sample id="1462">Overly excessive value alignment going on or maybe some other like anti-stereotyping methods that are resulting in these pernicious patterns.</sample>
    <sample id="1463">We just really can't make any assumptions or really study that further without more transparency.</sample>
    <sample id="1464">Grazie mille per l'attenzione. Spero che tu abbia un buon tempo a E.</sample>
    <sample id="1465">Hello everyone. My name is Jing Wei Yi from the University of Science and Technology of China.</sample>
    <sample id="1466">È mio piacere di fornire un breve video di pubblicità su Ab, Paper Are You Coping My Model proteggendo i diritti d'autore dei modelli di lingua grande per imbedding e servizi Vibe backdoor watermark.</sample>
    <sample id="1467">Prima di tutto, introduciamo il contesto riguardante i servizi di imbedding.</sample>
    <sample id="1468">Attualmente, i modelli di lingua grandi come GPT, LLaMA e PaLM sono eccezionali in comprendere e generare lingua naturale.</sample>
    <sample id="1469">Embedding as services is one of the services built upon large language models to assist various NLP tasks.</sample>
    <sample id="1470">For example, openai offers a gbt-based embedding api.</sample>
    <sample id="1471">Tuttavia, recenti studi hanno dimostrato che l'attaccatore può steal the model through learning from the embedding and provide similar services. Di conseguenza, è necessario proteggere la proprietà intellettuale dell'embedding come servizio.</sample>
    <sample id="1472">Per proteggere i diritti d'autorité dei servizi di embedding, una delle soluzioni è imprimere un marchio d'acqua nel servizio fornito e rilevare se un altro servizio contiene il marchio d'acqua.</sample>
    <sample id="1473">Il metodo di segnalatura dovrebbe soddisfare le seguenti proprietà: in primo luogo, il metodo dovrebbe essere applicabile all'inserimento di servizi; in secondo luogo, la segnalatura non dovrebbe indebolire l'utile dei servizi inclusi.</sample>
    <sample id="1474">Terzo, il segno d'acqua dovrebbe essere abbastanza nascosto per l'attaccante o l'attaccante potrebbe facilmente rimuovere il segno d'acqua.</sample>
    <sample id="1475">Finalmente, il watarmag needs to be transferable to the attacker's services during the model extraction process.</sample>
    <sample id="1476">Esistenti opere possono essere generalmente classificate in quattro category.</sample>
    <sample id="1477">Tuttavia, queste tecniche non sono applicabili all'embeddining ad servizi o mancano di trasferibilità.</sample>
    <sample id="1478">Therefore, in this paper we propose embedding marker which is a backdoor-based watermark method applicable to embedding as services.</sample>
    <sample id="1479">Then let me introduce the details of our embedding marker embedding marker contains two main steps watermark injection and copyright verification.</sample>
    <sample id="1480">Prima di questi passi principali, scegliamo un insieme di trigger. L'insieme di trigger è un gruppo di parole in un intervallo di frequenza moderato.</sample>
    <sample id="1481">We assume the provider can collect a general text corpus and count the word frequency with it.</sample>
    <sample id="1482">In Watermark injection, we first define a target embedding when a user sends a sentence to the provider service. The provider counts the trigger number in the sentence.</sample>
    <sample id="1483">The provided embedding is a weighted summation of the target embedding and the original embedding.</sample>
    <sample id="1484">The weight of the target embedding is proportional to the number of triggers in the sentence when the number of triggers in the sentence is greater than m the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="1485">Copyright verification is to detect whether a model behind another service contains the watermark.</sample>
    <sample id="1486">Viene prima costruito un backend e un dataset benigno. Il dataset backend contiene sentenze di cui tutti i vocaboli appartengono al set trigger, mentre tutti i vocaboli delle sentenze del dataset benigno non appartengono al set trigger.</sample>
    <sample id="1487">The provider requests embeddings from the steel service with the dataset.</sample>
    <sample id="1488">La cosine e l'LT2 similitudine tra il embedding richiesto e l'embedding di destinazione è calcolata. Calcoliamo la differenza di similarità tra Bnine e Backdoor dataset, che è definita come delta coseno e delta LT2.</sample>
    <sample id="1489">Meanwhile, we also apply kstest and use its p value as the third metric.</sample>
    <sample id="1490">Conduciamo esperimenti su quattro dataset: agnews, mind, sst-2 e hsnb. Assumiamo che il provider applichi wikitext dataset per conteggio frequenza di parole.</sample>
    <sample id="1491">I risultati su quattro dataset dimostrano che il nostro modello di embedding può ottenere un buon livello di prestazione di deteczione, mentre mantiene un buon livello di utilità per i compiti di downstream.</sample>
    <sample id="1492">We also validate the covertness of the provided embedding by visualizing the embedding of sentences on the dataset BoolPCA The legend of the figures means the number of triggers in each sentence.</sample>
    <sample id="1493">Come si vede nella figura, è difficile distinguere tra le impiantazioni a retrodotto e le impiantazioni normali.</sample>
    <sample id="1494">That's all, thank you. We'll come to discuss with us.</sample>
    <sample id="1495">ABC-Eval si riferisce all'approccio di annotazione dei comportamenti in chat sviluppato per coprire completamente i comportamenti dei modelli di chatta che hanno essere suggeriti di influenzare la qualità del chatta recentemente.</sample>
    <sample id="1496">La differenza di rendimento tra CoNLL-2003 e CoNLL++ è superiore a 5 punti percentuali fino all'anno 2023.</sample>
    <sample id="1497">Ciao, mi chiamo Vasudeva e sono un candidato per il PhD in Scienze Informatiche alla Stony Brook University. Vorrei presentare il mio articolo accettato in ACL 2023 come un paper lungo su "Apprendimento tramite transfer per la deteczione di diffondersi: affrontando lo sfidone della classe rara".</sample>
    <sample id="1498">We begin by defining cognitive dissonance and why it is an important problem to study in language simply put cognitive dissonance is two beliefs or actions that are inconsistent.</sample>
    <sample id="1499">Come in questo esempio, in cui una persona afferma di sapere che i sigarette possono uccidermi e successivamente dice di aver fumato un paio di sigarette dopo la riunione. Questa credenza e azione sono incoerenti e si contraddicono.</sample>
    <sample id="1500">Further mentioning that I don't think I could keep my job without them justifies the second occurrence and they have a consensual relationship.</sample>
    <sample id="1501">While dissonance is a very common phenomenon we experience in daily decision making, they are really rare to find expressed in language among other kinds of risk relations.</sample>
    <sample id="1502">So why does this matter studying cognitive dissonance can help us understand the effects of disinformation among people track trends in belief, values and attitude changes in populations.</sample>
    <sample id="1503">High cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better.</sample>
    <sample id="1504">Studiare disabilità espressive in lingua può anche essere benefico in comprendere l'estremismo e polarizzazione dei gruppi vulnerabili.</sample>
    <sample id="1505">Infine, la disfunzione cognitiva è importante per comprendere i stili cognitivi personali degli individui e aiuta a capire meglio i processi di decisione.</sample>
    <sample id="1506">To the goal of creating a cognitive dissonance resource, we conducted a large-scale annotation of dissonance relations. We used a dissonance first approach as seen in the flowchart here.</sample>
    <sample id="1507">Tweets were parsed using a pittbyparser and pairs of discourse units were annotated according to the guidelines that are described in our paper.</sample>
    <sample id="1508">Come si può vedere qui, la discesa era presente solo in 3,5 percento dei pares analizzati.</sample>
    <sample id="1509">Collecting around a thousand examples of discourse unit pairs, we ran training for an initial classifier trained only on forty three examples of discourses to no surprise the classifier performed not much better than chance.</sample>
    <sample id="1510">Data set Given the low occurrence of dissonance and absence of any prior such data set we are facing the problem of absolute rarity.</sample>
    <sample id="1511">Per alleviare questo, sperimentiamo su combinazioni di apprendimento passivo e apprendimento attivo per raccogliere più campioni di dissonanza in modo da ridurre i costi di annotazione senza compromettere la capacità di rilevare la dissonanza.</sample>
    <sample id="1512">Since the initial model was not able to capture the dissidents class at all, we start the active learning process by transferring weights from closely related tasks.</sample>
    <sample id="1513">We transform into two different tasks topic independent disentangle stance classification, a task that determines if two debate statements from different people are in agreement or in disagreement irrespective of topic.</sample>
    <sample id="1514">Chiamato debate qui e su classificazione binaria di espansione e compressa classi di pittura b since queste due sono strettamente legate alla concezione di consonanza e dissonanza e le chiamo c e qui.</sample>
    <sample id="1515">We find that on transferring the zero-shot performance on the annotated data set is already much better than chance, with the best with auc 0.62.</sample>
    <sample id="1516">Further on iteratively fine-tuning on both tasks we find that fine-tuning of ce tasks followed by further fine-tuning on debate yields a much better zero-shot performance thus this is the model that we use to co-start the active learning.</sample>
    <sample id="1517">Successivamente, determiniamo il miglior metodo per aggiornare un modello con nuovi dati da ogni iterazione di apprendimento attivo e annotazioni. Cumulativo accumula tutti i dati raccolti finora, mentre iterativo aggiorna il modello addestrando su ultima serie di dati raccolti.</sample>
    <sample id="1518">Over the different strategies we found that cumulative performed equal or better than iterative across the board.</sample>
    <sample id="1519">Next, to improve the number of dissidents examples, we use a probability of real class strategy (prc) to select mostly the examples that are highly likely to be dissidents by the current model at any round of a.</sample>
    <sample id="1520">We compared this to the other state-of-the-art state-of-the-art strategies that are commonly used in the community.</sample>
    <sample id="1521">We find that the proposed prc strategy works better than other state-of-the-art strategies although the difference is small. note that the performance is significantly lower for random.</sample>
    <sample id="1522">On further rounds of ayl with two best strategies we improved distance classification auac to point seven five, which is the best performance that we have on the task so far.</sample>
    <sample id="1523">We also checked the feasibility of each strategy for annotation quality and cost to annotators. We find that PRC has the highest percentage of dissonance and works best for real class, however the annotators also find the examples difficult.</sample>
    <sample id="1524">In summary, we find that prc is a simple a l. strategy for rare class acquisition and cold-starting a l with appropriately designed transfer learning tasks and help significantly.</sample>
    <sample id="1525">We also find that iterative update is useful for transfer learning from a different domain whereas in-domain active annotations benefit from cumulative updates.</sample>
    <sample id="1526">These are the links to our code dataset and our paper feel free to get in touch with us if you have any questions thank you</sample>
    <sample id="1527">I fornitori di informazioni non hanno specificato le affiliazioni degli autori dell'articolo.</sample>
    <sample id="1528">Il nome della relatrice o del relatore è Si Yu Yan.</sample>
    <sample id="1529">Ci sono cinque autori coinvolti nell'articolo.</sample>
    <sample id="1530">L'approccio viene confrontato con l'architettura simulST dedicata.</sample>
  </task>
</testset>