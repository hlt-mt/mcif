<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="en">
    <sample id="0">The main data sources for language models are things like patents.google.com, en.m.wikipedia.org, www.nytimes.com, www.latimes.com, www.theguardian.com, journals.plos.org, www.forbes.com, www.huffpost.com, www.scribd.com, www.washingtonpost.com, www.fool.com, www.ipfs.io, www.frontiersin.org, www.businessinsider.com, www.chicagotribune.com, www.booking.com, www.theatlantic.com, www.aljazeera.com, www.kickstarter.com, caselaw.findlaw.com, www.ncbi.nlm.nih.gov, and www.npr.org. If you want to know more about how these are used, just let me know.</sample>
    <sample id="1">The affiliations are McGill University/Mila and Microsoft Research. If you want to know more about their work or the paper itself, feel free to ask.</sample>
    <sample id="35">I'm not sure. There's no name mentioned in the content. You could try looking for more details elsewhere.</sample>
    <sample id="36">T5 XL model.</sample>
    <sample id="37">Yes!</sample>
    <sample id="38">The novelty is in how it rates the relevance of the bot's responses. If you want to know more about it, feel free to ask.</sample>
    <sample id="39">The success of the existing weakly supervised approach heavily relies on the quality of the weak labels. If you have any other questions about this or related topics, feel free to ask.</sample>
    <sample id="40">The slide doesn't mention specific advances to improve the score. You might need to look at other parts of the presentation or research for that. If you have any other questions about this or something else, feel free to ask.</sample>
    <sample id="41">There are five authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="75">There are three authors involved in the paper. If you have any other questions about it, feel free to ask.</sample>
    <sample id="76">The domains simplified more are "bible" and "fiction". If you want to know more about why these domains are simplified more, feel free to ask.</sample>
    <sample id="77">Marge read yesterday it.</sample>
    <sample id="78">Yes, you can use the DrBERT models, the NACHOS dataset, and the training scripts for your research as they are freely available under the MIT license. If you have any other questions about this, feel free to ask.</sample>
    <sample id="79">DEplain-APA contains academic papers.</sample>
    <sample id="80">Well, for good generalization, you need a better model architecture, a larger model size, and more fine - tuning examples. So, that's it. If you have any other questions about this, feel free to ask.</sample>
    <sample id="81">The tendency for left conjuncts to be shorter was measured by looking at statistics extracted from an enhanced version of the Penn Treebank.</sample>
    <sample id="82">The experiments were designed by looking at different positions of the governor, like on the left or right, and measuring the proportion of shorter left conjuncts depending on the absolute difference of conjunct lengths. They also considered different units of measurement for length, like characters, syllables, and words. So, they compared how these factors influenced the results. If you want to know more about the specific details, feel free to ask.</sample>
    <sample id="83">Not well. It's not better than chance. If you want to know more about how to improve it, just let me know.</sample>
    <sample id="84">There are four authors involved in the paper. If you have any other questions about it, feel free to ask.</sample>
    <sample id="85">The characters' names aren't mentioned in the example conversation.</sample>
    <sample id="86">Formality and lexical cohesion. If you want to know more about this, feel free to ask.</sample>
    <sample id="87">The affiliations are Johns Hopkins University, Purdue University, MIT, and Meta AI. If you want to know more about their research or anything else related, feel free to ask.</sample>
    <sample id="88">Compositional Generalization without Trees using Multiset Tagging and Latent Permutations. Matthias Lindemann, Alexander Koller, Ivan Titov.</sample>
    <sample id="89">Compositional Generalization without Trees using Multiset Tagging and Latent Permutations. Matthias Lindemann, Alexander Koller, Ivan Titov.</sample>
    <sample id="90">Compositional Generalization. Ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training.</sample>
    <sample id="91">Compositional Generalization in Semantic Parsing.Train:.- The girl slept. *girl x sleep.agent x x.- Mary knew that the girl slept. *girl x know.agent x Mary know.ccomp x x sleep.agent x x</sample>
    <sample id="92">Compositional Generalization in Semantic Parsing.Train:.- The girl slept. *girl x sleep.agent x x.- Mary knew that the girl slept. *girl x know.agent x Mary know.ccomp x x sleep.agent x x</sample>
    <sample id="93">Compositional Generalization in Semantic Parsing.Train:.- The girl slept. *girl x sleep.agent x x.- Mary knew that the girl slept. *girl x know.agent x Mary know.ccomp x x sleep.agent x.Test:.- Jim said that Mary knew that the girl slept. *girl x say.agent x Jim say.ccomp x Mary know.agent x Mary know.ccomp x sleep.agent x</sample>
    <sample id="94">Compositional Generalization in Semantic Parsing.Train:.- The girl slept. *girl x sleep.agent x x.- Mary knew that the girl slept. *girl x know.agent x Mary know.ccomp x x sleep.agent x.Test:.- Jim said that Mary knew that the girl slept. *girl x say.agent x Jim say.ccomp x Mary know.agent x Mary know.ccomp x sleep.agent x</sample>
    <sample id="95">Compositional Generalization in Semantic Parsing.Train:.- The girl slept. *girl x sleep.agent x x.- Mary knew that the girl slept. *girl x know.agent x Mary know.ccomp x x sleep.agent x.Test:.- Jim said that Mary knew that the girl slept. *girl x say.agent x Jim say.ccomp x Mary know.agent x Mary know.ccomp x sleep.agent x.Naive seq2seq models fail!</sample>
    <sample id="96">Compositional Generalization in Semantic Parsing.Train:.- The girl slept. *girl x sleep.agent x x.- Mary knew that the girl slept. *girl x know.agent x Mary know.ccomp x x sleep.agent x.Test:.- Jim said that Mary knew that the girl slept. *girl x say.agent x Jim say.ccomp x Mary know.agent x Mary know.ccomp x sleep.agent x.Naive seq2seq models fail!</sample>
    <sample id="97">Trees help a lot but. *girl x, sleep.agent x, x, *girl x, x, sleep.agent x, The girl slept.</sample>
    <sample id="98">Trees help a lot but. *girl x, sleep.agent x, x, *girl x, x, sleep.agent x, The girl slept.</sample>
    <sample id="99">Trees help a lot but... *girl x₁; sleep.agent x₂ x₁ *girl x₁; x₁ sleep.agent x₂ The girl slept. Trees need to be obtained: - Pre/Post-processing logical forms</sample>
    <sample id="100">Trees help a lot but... *girl x₁; sleep.agent x₂ x₁ *girl x₁; x₁ sleep.agent x₂ The girl slept. Trees need to be obtained: - Pre/Post-processing logical forms</sample>
    <sample id="101">Trees help a lot but. *girl x, sleep.agent x, x, *girl x, x, sleep.agent x, The girl slept. Trees need to be obtained: - Pre/Post-processing logical forms - Grammar-induction</sample>
    <sample id="102">Trees help a lot but... *girl x₁; sleep.agent x₂ x₁ *girl x₁; x₁ sleep.agent x₂ The girl slept. Trees need to be obtained: - Pre/Post-processing logical forms - Grammar-induction This paper: neural seq2seq model that directly models the correspondences between fragments. For the first time, we show strong generalization to deeper recursion without trees.</sample>
    <sample id="103">Trees help a lot but... *girl x₁; sleep.agent x₂ x₁ *girl x₁; x₁ sleep.agent x₂ The girl slept. Trees need to be obtained: - Pre/Post-processing logical forms - Grammar-induction This paper: neural seq2seq model that directly models the correspondences between fragments. For the first time, we show strong generalization to deeper recursion without trees.</sample>
    <sample id="104">Our Approach</sample>
    <sample id="105">Our Approach</sample>
    <sample id="106">Our Approach</sample>
    <sample id="107">Our Approach.</sample>
    <sample id="108">Our Approach.</sample>
    <sample id="109">Permuting with "jumps" Permute the girl girl agent slept</sample>
    <sample id="110">Permuting with "jumps" Permute the girl agent x2 Tag the girl slept</sample>
    <sample id="111">Permuting with "jumps"</sample>
    <sample id="112">Permuting with "jumps" Permute Tag * girl x₁ the girl slept girl x₁ sleep agent x₂ ;</sample>
    <sample id="113">Permuting with "jumps"</sample>
    <sample id="114">Some Results on COGS, Kim and Linzen 2020, Comparison with other Treeless Models on Structural Generalization on COGS, Model, LSTM seq2seq, T5, Zheng and Lapata, Ours, Generalisation Type, PP recursion, CP recursion, Obj PP → Subj PP, Acc, 0, 20, 40, 60, 80, 7</sample>
    <sample id="115">Some Results on COGS, Kim and Linzen 2020, Comparison with other Treeless Models on Structural Generalization on COGS, Model, LSTM seq2seq, T5, Zheng and Lapata, Ours, Generalisation Type, PP recursion, CP recursion, Obj PP → Subj PP, Acc, 0, 20, 40, 60, 80, 7</sample>
    <sample id="116">Technical Challenges We Solve, Alignment unknown.</sample>
    <sample id="117">Technical Challenges We Solve.</sample>
    <sample id="118">Technical Challenges We SolveAlignment unknown.Induce it in training.</sample>
    <sample id="119">Technical Challenges We Solve
Alignment unknown.
» Induce it in training.
Permutation model:
- Inference is NP-hard, ≈ TSP</sample>
    <sample id="120">Technical Challenges We SolveAlignment unknown. Induce it in training.Permutation model: - Inference is NP-hard, TSP, - Backpropagate through continuous relaxation</sample>
    <sample id="121">Technical Challenges We Solve
Alignment unknown.
» Induce it in training.
Permutation model:
- Inference is NP-hard, ≈ TSP
- Backpropagate through continuous relaxation</sample>
    <sample id="122">The framework quantifies positionality by comparing annotations by demographic to models and datasets via Pearson's R scores. If you want to know more about how Pearson's R scores are calculated or something else related, feel free to ask.</sample>
    <sample id="123">Weaker Than You Think A Critical Look at Weakly Supervised Learning Dawei Zhu 1 Xiaoyu Shen 2 Marius Mosbach 1 Andreas Stephan 3 Dietrich Klakow 1 1 Saarland University 2 Amazon Alexa 3 University of Vienna 61 ACL 2023</sample>
    <sample id="124">Weaker Than You Think A Critical Look at Weakly Supervised Learning Dawei Zhu 1 Xiaoyu Shen 2 Marius Mosbach 1 Andreas Stephan 3 Dietrich Klakow 1 1 Saarland University 2 Amazon Alexa 3 University of Vienna 61 ACL 2023</sample>
    <sample id="125">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning, WSL, Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="126">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning, WSL, Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="127">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning, WSL, Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="128">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning, WSL, Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="129">Why weakly supervised learning? Weak supervision alleviates the annotation bottleneck. But weak labels are noisy! Noise memorization harms generalization. Weakly supervised learning, WSL, Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="130">A common claim in recent WSL works
"We train models only on weakly supervised data and achieve an accuracy of XX%."
Weakly labeled training data, noisy, Cleanly labeled test data, clean,</sample>
    <sample id="131">A common claim in recent WSL works.We train models only on weakly supervised data and achieve an accuracy of XX%.</sample>
    <sample id="132">A common claim in recent WSL works "We train models only on weakly supervised data and achieve an accuracy of XX%."</sample>
    <sample id="133">A common claim in recent WSL works
"We train models only on weakly supervised data and achieve an accuracy of XX%."
Weakly labeled training data, noisy.
Cleanly labeled validation data, clean.
Cleanly labeled test data, clean.</sample>
    <sample id="134">Our research questions. RQ1 Is clean validation data necessary? RQ2 How many clean samples do WSL approaches need? RQ3 How to use the available clean samples more efficiently?</sample>
    <sample id="135">Our research questions. RQ1 Is clean validation data necessary? RQ2 How many clean samples do WSL approaches need? RQ3 How to use the available clean samples more efficiently?</sample>
    <sample id="136">RQ1 Main findings</sample>
    <sample id="137">RQ1 Main findings</sample>
    <sample id="138">RQ1 Main findings</sample>
    <sample id="139">RQ1 Main findings</sample>
    <sample id="140">RQ1 Main findings A clean validation set is indispensable.</sample>
    <sample id="141">RQ2 Main findings</sample>
    <sample id="142">RQ2 Main findings</sample>
    <sample id="143">RQ2 Main findings WSL approaches benefit from more clean validation samples!</sample>
    <sample id="144">RQ2 Main findings. WSL approaches benefit from more clean validation samples!</sample>
    <sample id="145">RQ2 Main findings WSL approaches benefit from more clean validation samples! But it is even better to use them for training, e.g., LoRAc!</sample>
    <sample id="146">RQ3 Main findings N=10 clean samples per class Accuracy/F1 88 86 84 82 80 78 76 Before CFT After CFT N=30 clean samples per class Accuracy/F1 88 86 84 82 80 78 Before CFT After CFT</sample>
    <sample id="147">RQ3 Main findings N=10 clean samples per class Accuracy/F1 88 86 84 82 80 78 76 Before CFT After CFT N=30 clean samples per class Accuracy/F1 88 86 84 82 80 78 Before CFT After CFT</sample>
    <sample id="148">RQ3 Main findings N=10 clean samples per class Accuracy/F1 88 86 84 82 80 78 76 Before CFT After CFT N=30 clean samples per class Accuracy/F1 88 86 84 82 80 78 Before CFT After CFT</sample>
    <sample id="149">RQ3 Main findings Continuous fine-tuning, CFT, eliminates performance gaps between WSL approaches. No need to use complicated WSL methods, FTw performs equally well.</sample>
    <sample id="150">Conclusion
Recent WSL approaches
- Require clean samples.
- Overestimate their practicality.
Our recommendations
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning, CFT,</sample>
    <sample id="151">ConclusionRecent WSL approachesRequire clean samples.Overestimate their practicality.Our recommendationsReport the model selection criteria.Use Few-shot learning approaches as baselines.Always apply continuous fine-tuning, CFT.</sample>
    <sample id="152">Conclusion
Recent WSL approaches
- Require clean samples.
- Overestimate their practicality.
Our recommendations
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning, CFT,</sample>
    <sample id="153">Conclusion
Recent WSL approaches
- Require clean samples.
- Overestimate their practicality.
Our recommendations
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning, CFT,</sample>
    <sample id="154">Conclusion
Recent WSL approaches
- Require clean samples.
- Overestimate their practicality.
Our recommendations
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning, CFT.</sample>
    <sample id="155">The slide doesn't give the specific finding of the previous study. You might need to look for more detailed information elsewhere. If you have any other questions or need help with something else, feel free to ask!</sample>
    <sample id="156">The sources of data used in this study were an enhanced version of the Penn Treebank, Marcus et al. 1993, and Ficler and Goldberg 2016. If you have any other questions about this study, feel free to ask.</sample>
    <sample id="157">There are two authors involved in the paper. If you have any other questions about it, feel free to ask.</sample>
    <sample id="158">Well, some closely related tasks for cognitive dissonance are debate and CE. If you want to know more about how they're related or what they involve, just let me know.</sample>
    <sample id="159">There are two authors involved in the paper. If you want to know more about the paper, feel free to ask.</sample>
    <sample id="160">There are seven authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="161">The framework differs by comparing annotations by demographic to models and datasets via Pearson's R scores. This is not mentioned in the previous works. If you want to know more about this, feel free to ask.</sample>
    <sample id="162">GPT-3.5.</sample>
    <sample id="163">DeepL and Google.</sample>
    <sample id="200">There are six authors involved in the paper. If you want to know more about the authors or the paper itself, feel free to ask.</sample>
    <sample id="201">900 tokens. If you have any other questions about this, feel free to ask!</sample>
    <sample id="202">They included Music Selection, Book Selection, and Recipe Selection in their dataset. If you want to know more about how they were selected or anything else related, feel free to ask.</sample>
    <sample id="203">Positionality is the perspectives people hold as a result of their demographics, identity, and life experiences. It influences the research process and its outcomes and results. If you want to know more about it, feel free to ask me.</sample>
    <sample id="204">Dawei Zhu. If you want to know more about the speaker or the topic, feel free to ask.</sample>
    <sample id="205">Yes. If you have any other questions about this, feel free to ask.</sample>
    <sample id="206">There are four authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="207">No.</sample>
    <sample id="208">There are Background - Pretrain, Background - Both, and Background - Inference. If you want to know more about these variants, feel free to ask.</sample>
    <sample id="209">The affiliations of the authors are Google Research. If you want to know more about their work or the paper itself, feel free to ask.</sample>
    <sample id="210">The last research question is "How to use the available clean samples more efficiently?". If you have any other questions about this, feel free to ask!</sample>
    <sample id="211">The metric sensitivity measures how sensitive the model is towards variety of instructions for the same task. It looks at the model's ability to consistently produce the same results for the same task, regardless of slight variations in the wording of instructions. If you want to know more about it, like specific examples or how it's calculated, just let me know.</sample>
    <sample id="212">The speaker's name is not mentioned in the image.</sample>
    <sample id="213">It suggests the opposite. Lower sensitivity is better for model performance. If you have more questions about this, feel free to ask.</sample>
    <sample id="214">The image doesn't provide information about what kind of linguistic context models receive during pretraining. You might need to look for other sources or research papers on this topic. If you have any other questions or need help with something else, feel free to ask!</sample>
    <sample id="215">The image doesn't provide a specific number for clean validation samples needed for good performance in WSL. It shows a graph with different methods and their accuracy on validation data, but it doesn't give a clear threshold for the number of clean validation samples. You might need to look at other sources or research for that information. If you have any other questions about this or something else, feel free to ask.</sample>
    <sample id="216">The affiliations of the authors are Stanford Engineering Computer Science. If you want to know more about their research or anything else related, feel free to ask.</sample>
    <sample id="217">Well, you see, the existing methods might not be accurate enough. They could be missing some important factors or have biases themselves. So, developing new ones is crucial to get a more reliable and comprehensive understanding of media biases. What do you think about that?</sample>
    <sample id="218">I'm not sure. The image doesn't show the speaker's name. You could try looking for it in the video or presentation.</sample>
    <sample id="219">Well, it seems like the pipeline starts with pretraining data. Then, it goes through language models, and finally, it reaches downstream tasks. But, um, it's not super clear from the information given how exactly the political bias is propagated in each step. Maybe you could look into some more detailed studies on this? What do you think?</sample>
    <sample id="220">Yes, it does. If you want to know more about the differences, feel free to ask.</sample>
    <sample id="221">I'm not sure if Coscript is publicly available. You could try looking for official announcements or checking the company's website. Why are you interested in Coscript?</sample>
    <sample id="222">Well, first, you define a target embedding, then you count the trigger number in a sentence, and finally, you add the target embedding on the original embedding. That's how the watermark is inserted into the text. If you have any other questions about this, feel free to ask.</sample>
    <sample id="223">PennState and Amazon.</sample>
    <sample id="224">Yes.</sample>
    <sample id="225">Making a strawberry cake or a chocolate cake. If you want to know more about it, feel free to ask.</sample>
    <sample id="226">They use embedding visualization to show the effectiveness of their method.</sample>
    <sample id="227">The work uses continual pre-training using an existing pre-trained model like CamemBERT, a French generic model, and PubMedBERT, an English-based medical one.</sample>
    <sample id="228">African Islamic. If you have any other questions about this or something else, feel free to ask!</sample>
    <sample id="229">The example sentence is "I am a student."</sample>
    <sample id="230">Well, from what I can see, as the amount of tasks increases, the model performance initially goes up, then plateaus, and finally starts to drop. It seems like there's an optimal number of tasks for the best performance. What do you think about that?</sample>
    <sample id="231">LSTM seq2seq, T5, Zheng and Lapata. If you want to know more about these models or the comparison, feel free to ask.</sample>
    <sample id="232">I'm not sure about the exact relation between the co-authors and the first author. You might need to look at the context of the research or the publication for more details. If you have any other questions or need further help, feel free to ask.</sample>
    <sample id="233">Chowdery.</sample>
    <sample id="274">The speaker mentions three problems of SimulST. If you want to know more about these problems, feel free to ask.</sample>
    <sample id="275">Well, one effective way is to sanitize the data. But, you know, it's a bit of a tricky question. There's no one-size-fits-all answer. It really depends on the specific dataset and the type of biases present. You might need to do things like removing offensive language, correcting gender and racial stereotypes, and so on. But, yeah, it's not easy. What do you think about this? Do you have any other ideas?</sample>
    <sample id="307">The fluency of PaLM is comparable to SOTA. If you want to know more about PaLM or other related topics, feel free to ask.</sample>
    <sample id="308">Applicable to EaaS, utility, should not degrade the utility of the provided embeddings, Covertness, should be covert to the attacker, Transferability, the watermark need to be transferable to the attackers' services. If you want to know more about these properties or have other questions, feel free to ask.</sample>
    <sample id="309">The 14 different languages are Arabic, Deutsch, Español, Français, Italiano, 日本語, 한국어, Nederlands, Português, Română, Русский, Türkçe, and 中文. If you want to know more about these languages or the TED talks, feel free to ask.</sample>
    <sample id="310">300 instances.</sample>
    <sample id="311">The cosine similarity and L2 distance metrics are used.</sample>
    <sample id="312">The multilingual encoder-based models were used in a monolingual setting. They were evaluated on two groups of models, Enc-PTR and Enc-Dec. Enc-PTR used multilingual pretrained encoders with pointer-based decoders, like XLM-R + PTR and mBERT + PTR. Enc-Dec used multilingual pretrained encoder-decoder models, such as mBART and mT5. And it was found that Enc-Dec, specifically mT5, obtained the best performance on all datasets. If you want to know more about these models or the evaluation process, feel free to ask.</sample>
    <sample id="313">The 61st Annual Meeting of the Association for Computational Linguistics Toronto, Canada July 9-14, 2023 Distilling Script Knowledge from Large Language Models for Constrained Language Planning Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang FUDAN UNIVERSITY Brain Technologies Inc.</sample>
    <sample id="314">Language Planning. How to Make a Cake? 1. Gather your ingredients. 2. Preheat the oven to 325 °F, 163 °C, and grease and flour a cake pan. 3. Cream the butter and sugar. 4. Add the eggs. 5. Stir in the cake flour. 6. Pour the batter into the pan. 7. Bake the cake for 1 hour 15 minutes. Large language models, LLMs, can effectively decompose goals into steps.</sample>
    <sample id="315">Language Planning. How to Make a Cake? 1. Gather your ingredients. 2. Preheat the oven to 325 °F, 163 °C, and grease and flour a cake pan. 3. Cream the butter and sugar. 4. Add the eggs. 5. Stir in the cake flour. 6. Pour the batter into the pan. 7. Bake the cake for 1 hour 15 minutes. Large language models, LLMs, can effectively decompose goals into steps.</sample>
    <sample id="316">Constrained Language Planning. How to Make a Strawberry Cake? Add strawberry jams into the flour. How to Make a Chocolate Cake? Add the cocoa powder into the flour. Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints.</sample>
    <sample id="317">Constrained Language Planning.How to Make a Strawberry Cake? Add strawberry jams into the flour.How to Make a Chocolate Cake? Add the cocoa powder into the flour.Abstract goal can be inherited by different real - life specific goals with multi - faceted constraints.</sample>
    <sample id="318">Constrained Language Planning. How to Make a Strawberry Cake? Add strawberry jams into the flour. How to Make a Chocolate Cake? Add the cocoa powder into the flour. Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints.</sample>
    <sample id="319">How do LLMs perform on Constrained Language Planning? Dataset: wikiHow + Generated Constraints Constraint Type 1: Modifier Definition: A word, an adjective or a phrase that modifies or constrains an abstract goal. Ex.1: Make a chocolate cake. Ex.2: Make a pink cake. Constraint Type 2: Method Definition: A tool or specified mode that controls the process for achieving the goal. Ex.1: Make a cake with an oven. Ex.2: Make a cake by using cake mix. Constraint Type 3: Intent Definition: An additional purpose or demand when completing the goal. Ex.1: Make a cake for wedding. Ex.2: Make a cake for diabetics.</sample>
    <sample id="320">How do LLMs perform on Constrained Language Planning? Dataset: wikiHow + Generated Constraints Constraint Type 1: Modifier Definition: A word, an adjective or a phrase that modifies or constrains an abstract goal. Ex.1: Make a chocolate cake. Ex.2: Make a pink cake. Constraint Type 2: Method Definition: A tool or specified mode that controls the process for achieving the goal. Ex.1: Make a cake with an oven. Ex.2: Make a cake by using cake mix. Constraint Type 3: Intent Definition: An additional purpose or demand when completing the goal. Ex.1: Make a cake for wedding. Ex.2: Make a cake for diabetics.</sample>
    <sample id="321">How do LLMs perform on Constrained Language Planning? Dataset: wikiHow + Generated Constraints Constraint Type 1: Modifier Definition: A word, an adjective or a phrase that modifies or constrains an abstract goal. Ex.1: Make a chocolate cake. Ex.2: Make a pink cake. Constraint Type 2: Method Definition: A tool or specified mode that controls the process for achieving the goal. Ex.1: Make a cake with an oven. Ex.2: Make a cake by using cake mix. Constraint Type 3: Intent Definition: An additional purpose or demand when completing the goal. Ex.1: Make a cake for wedding. Ex.2: Make a cake for diabetics.</sample>
    <sample id="322">Can LLMs do Constrained Language Planning? All baselines achieve unsatisfactory results on planning for specific goals</sample>
    <sample id="323">Can LLMs do Constrained Language Planning? All baselines achieve unsatisfactory results on planning for specific goals</sample>
    <sample id="324">What types of errors do LLMs usually make in this task? The semantic completeness SE in generated scripts is acceptable, but the faithfulness to the constraints FE can not be guaranteed.</sample>
    <sample id="325">The semantic completeness, SE, in generated scripts is acceptable, but the faithfulness to the constraints, FE, can not be guaranteed.</sample>
    <sample id="326">The planning performance of InstructGPTs varies considerably for goals of different categories.</sample>
    <sample id="327">Method. Input: an abstract goal. Step 1 Generate specific goals with InstructGPT via in-context learning. Abstract Goal: Make a cake. Specific Goals: G1, modifier, Make a chocolate cake. G2, method, Make a cake in a microwave. G3, intent, Make a cake for a wedding.</sample>
    <sample id="328">Method. Input: an abstract goal. Step 1 Generate specific goals with InstructGPT via in-context learning. Abstract Goal: Make a cake. Specific Goals: G1, modifier, Make a chocolate cake. G2, method, Make a cake in a microwave. G3, intent, Make a cake for a wedding. Step 2 Over-generate candidate scripts with InstructGPT via in-context learning. Candidate Scripts: 1, 2, 3, ..., k.</sample>
    <sample id="329">Method. Input: an abstract goal. Step 1 Generate specific goals with InstructGPT via in-context learning. Step 2 Over-generate candidate scripts with InstructGPT via in-context learning. Abstract Goal: Make a cake. Specific Goals: G1, modifier, Make a chocolate cake. G2, method, Make a cake in a microwave. G3, intent, Make a cake for a wedding. Generate plans for G1. Candidate Scripts: 1, 2, 3, ..., k.</sample>
    <sample id="330">Method. Step 2: Over - generate candidate scripts with InstructGPT via in - context learning. Step 3: Find filtered scripts to the goal with InstructGPT via similarity score. Output: Specific goals with corresponding scripts.</sample>
    <sample id="331">Method. Step 2: Over-generate candidate scripts with InstructGPT via in-context learning. Step 3: Find filtered scripts to the goal with InstructGPT via similarity score. Output: Specific goals with corresponding scripts. Candidate Scripts: 1, 2, 3, ..., k. 2 0.3 0.2 0.5 3 0.7 0.2 0.1. Filtered Scripts: Script 3. 1. Gather your ingredients. 4. Add the cocoa powder.</sample>
    <sample id="332">Method. Step 2: Over-generate candidate scripts with InstructGPT via in-context learning. Step 3: Find filtered scripts to the goal with InstructGPT via similarity score. Output: Specific goals with corresponding scripts. Candidate Scripts: 1, 2, 3, ..., k. 2. 0.3 0.2 0.5 0.7 0.2 0.1. Filtered Scripts: Script 3. 1. Gather your ingredients. 4. Add the cocoa powder.</sample>
    <sample id="333">Our Method Greatly Improves the Planning Quality.With our method, InstructGPT can generate scripts of higher quality by a large margin.</sample>
    <sample id="334">Script Distillation from LLMsMotivation: To enable constrained language planning ability for smaller models.Method: Follow the idea of symbolic knowledge distillation. Generated 55, 000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset. Humans annotate validation and test set.</sample>
    <sample id="335">Script Distillation from LLMsMotivation: To enable constrained language planning ability for smaller models.Method: Follow the idea of symbolic knowledge distillation. Generated 55, 000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset. Humans annotate validation and test set.Input: an abstractStep 1 Generate specific goals with InstructGPT via in-context learningStep 2 Over-generate candidate scripts with InstructGPT via in-context learningStep 3 Find filtered scripts to the goal with InstructGPT via similarity scoreOutput: Specific goals with corresponding plans</sample>
    <sample id="336">Script Distillation from LLMsMotivation: To enable constrained language planning ability for smaller models.Method: Follow the idea of symbolic knowledge distillation. Generated 55, 000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset. Humans annotate validation and test set.Input: an abstractStep 1 Generate specific goals with InstructGPT via in-context learningStep 2 Over-generate candidate scripts with InstructGPT via in-context learningStep 3 Find filtered scripts to the goal with InstructGPT via similarity scoreOutput: Specific goals with corresponding plans</sample>
    <sample id="337">Script Distillation from LLMs.Motivation: To enable constrained language planning ability for smaller models.Method: Follow the idea of symbolic knowledge distillation. Generated 55, 000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset. Humans annotate validation and test set.</sample>
    <sample id="338">Script Distillation from LLMsMotivation: To enable constrained language planning ability for smaller models.Method: Follow the idea of symbolic knowledge distillation. Generated 55, 000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset. Humans annotate validation and test set.</sample>
    <sample id="339">Coscript shows high heterogeneity and pluralism in the generated specific goals.</sample>
    <sample id="340">Specialized Models vs. LLMs. Smaller LMs fine-tuned on Coscript can generate higher quality scripts than LLMs.</sample>
    <sample id="341">• Establish the constrained language planning problem. • Evaluate constrained language planning ability of LLMs and develop an over-generate-then-filter method for LLMs • Use LLMs to generate a high-quality script dataset, CoScript, for constrained language planning. • Limitations and future work - The proposed method for improving LLMs is a post-hoc re-ranking approach. - CoScript only inherits from an abstract one with one extra constraint. - CoScript dataset can be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints</sample>
    <sample id="342">• Establish the constrained language planning problem. • Evaluate constrained language planning ability of LLMs and develop an over-generate-then-filter method for LLMs • Use LLMs to generate a high-quality script dataset, CoScript, for constrained language planning. • Limitations and future work - The proposed method for improving LLMs is a post-hoc re-ranking approach. - CoScript only inherits from an abstract one with one extra constraint. - CoScript dataset can be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints</sample>
    <sample id="343">The 61st Annual Meeting of the Association for Computational Linguistics Toronto， Canada July 9-14， 2023 Distilling Script Knowledge from Large Language Models for Constrained Language Planning Siyu Yuan， Jiangjie Chen， Ziquan Fu， Xuyang Ge， Soham Shah， Charles Robert Jankowski， Yanghua Xiao， Deqing Yang syyuan21@m.fudan.edu.cn https://github.com/siyuyuan/coscript</sample>
    <sample id="344">The authors count the word frequency on a general text corpus Dp and randomly select n words in a moderate-frequency interval.</sample>
    <sample id="371">Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems. Sarah E. Finch, James D. Finch, and Jinho D. Choi. Emory University. Emory NLP Research Lab. Alexa.</sample>
    <sample id="372">Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems. Sarah E. Finch, James D. Finch, and Jinho D. Choi. Emory University. Emory NLP Research Lab. Alexa.</sample>
    <sample id="373">Comparative Evaluation</sample>
    <sample id="374">Comparative Evaluation Likert Rating Evaluation</sample>
    <sample id="375">Likert Rating Evaluation. Dimensions of Dialogue Quality. Dialogue Quality. Relevance. Consistency. Emotional Understanding.</sample>
    <sample id="376">Likert Rating Evaluation. Rate the relevance of the bot's responses.</sample>
    <sample id="377">Likert Rating Evaluation. Rate the relevance of the bot's responses.</sample>
    <sample id="378">Annotating Behaviors in Chat, ABC-Eval.</sample>
    <sample id="379">Annotating Behaviors in Chat, ABC-Eval.</sample>
    <sample id="380">ABC-Eval Behaviors Coherence Knowledge Consistency Emotional Understanding</sample>
    <sample id="381">ABC-Eval Behaviors Coherence Ignoring Partner Irrelevant Knowledge Consistency Emotional Understanding</sample>
    <sample id="382">ABC-Eval Behaviors Coherence Ignoring Partner Irrelevant Knowledge Incorrect Fact Commonsense Violation Consistency Self Contradiction Partner Contradiction Emotional Understanding Empathetic Response Lack of Empathy</sample>
    <sample id="383">Experiments. 4 Open-Domain Dialogue Models. 100 Human-Bot Conversations per Model.</sample>
    <sample id="384">Experiments. 4 Open-Domain Dialogue Models. 100 Human-Bot Conversations per Model. ABC-Eval. Turn Likert. Dialogue Likert. Comparative.</sample>
    <sample id="385">Experiments
- 4 Open-Domain Dialogue Models
- 100 Human-Bot Conversations per Model
Baseline Evaluations
- Turn Likert
- Dialogue Likert
- Comparative
Consistency
Emotional Understanding
Informativeness
Overall Quality
Engagingness
Grammaticality
Proactivity
Relevance</sample>
    <sample id="386">Inter-Annotator Agreement</sample>
    <sample id="387">Predictive Validity</sample>
    <sample id="388">Predictive Validity</sample>
    <sample id="389">Predictive Validity Incremental Validity</sample>
    <sample id="390">Incremental Validity</sample>
    <sample id="391">Incremental Validity</sample>
    <sample id="392">ABC-Eval Error Rates by Model</sample>
    <sample id="393">ABC-Eval Error Rates by Model.</sample>
    <sample id="394">Sure.</sample>
    <sample id="395">Sure.</sample>
    <sample id="396">ABC-Eval Error Rates by Model.</sample>
    <sample id="397">The approach uses a speech segment size of 10 seconds. If you have any other questions about this, feel free to ask.</sample>
    <sample id="398">The entity-specific knowledge needed is that Servin is a judge.</sample>
    <sample id="399">Example quality is more important than similarity to the source sentence. If you have any other questions about this, feel free to ask.</sample>
    <sample id="400">The paper focuses on RoBERTa and GPT-2. If you want to know more about these models or the paper itself, feel free to ask.</sample>
    <sample id="401">The model combines the scores from several layers. If you have more questions about this, feel free to ask.</sample>
    <sample id="402">The examples of direct inference are "easy on me" and "the first one". If you want to know more about this or have other questions, feel free to ask.</sample>
    <sample id="403">Fudan University and Brain Technologies Inc.</sample>
    <sample id="404">There are six authors involved in the paper. If you have any other questions about it, feel free to ask.</sample>
    <sample id="405">No.</sample>
    <sample id="406">A woman warrior.</sample>
    <sample id="407">The slide doesn't specifically list which model architectures don't generalize well, but it does say that transformer models generalize better. So, it implies that non-transformer models might not generalize as well. But without more info, it's hard to say exactly which ones. If you have more context or details, that would be great.</sample>
    <sample id="408">The testing datasets are FTc, LoRAc, BitFitc, and Adapterc. If you have any other questions about this, feel free to ask.</sample>
    <sample id="409">There are six authors involved in the paper. If you want to know more about them or the paper itself, feel free to ask.</sample>
    <sample id="410">The author works with multiple modalities. If you have any other questions about this, feel free to ask.</sample>
    <sample id="411">DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains</sample>
    <sample id="412">Summary.I. Language Modeling in Healthcare.II. Comparison of pre-training strategies, data sources and sizes.III. Evaluation of 13 models on 11 tasks.IV. Distribution of NACHOS and DrBERT.</sample>
    <sample id="413">Summary.I. Language Modeling in Healthcare.II. Comparison of pre-training strategies, data sources and sizes.III. Evaluation of 13 models on 11 tasks.IV. Distribution of NACHOS and DrBERT.</sample>
    <sample id="414">Summary.I. Language Modeling in Healthcare.II. Comparison of pre-training strategies, data sources and sizes.III. Evaluation of 13 models on 11 tasks.IV. Distribution of NACHOS and DrBERT.</sample>
    <sample id="415">I. Language Modeling in Healthcare. Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks. Has been adapted to French with CamemBERT and FlauBERT. II. Comparison of pre-training strategies, data sources and sizes. On multi-task domain specific tasks, language is used more than one. PudMedBERT, BioBERT, ClinicalBERT and other. III. Evaluation of 13 models on 11 tasks. Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model. IV. Distribution of NACHOS and DrBERT. Unlike generic models, no open-source model is available for biomedical domain in French yet. BERT-based domain specific model for French should increase performance on medical tasks.</sample>
    <sample id="416">Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks. Has been adapted to French with CamemBERT and FlauBERT. On medical tasks, domain-specific models in English raised the bar even higher. PudMedBERT, BioBERT, ClinicalBERT and other. Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model. Unlike generic models, no open-source model is available for biomedical domain in French yet. BERT-based domain specific model for French should increase performance on medical tasks.</sample>
    <sample id="417">Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks. Has been adapted to French with CamemBERT and FlauBERT. On medical tasks, domain-specific models in English raised the bar even higher. PudMedBERT, BioBERT, ClinicalBERT and other. Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model. Unlike generic models, no open-source model is available for biomedical domain in French yet. BERT-based domain specific model for French should increase performance on medical tasks.</sample>
    <sample id="418">Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks. Has been adapted to French with CamemBERT and FlauBERT. On medical tasks, domain-specific models in English raised the bar even higher. PudMedBERT, BioBERT, ClinicalBERT and other. Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model. Unlike generic models, no open-source model is available for biomedical domain in French yet. BERT-based domain specific model for French should increase performance on medical tasks.</sample>
    <sample id="419">Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks. Has been adapted to French with CamemBERT and FlauBERT. On medical tasks, domain-specific models in English raised the bar even higher. PudMedBERT, BioBERT, ClinicalBERT and other. Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model. Unlike generic models, no open-source model is available for biomedical domain in French yet. BERT-based domain specific model for French should increase performance on medical tasks.</sample>
    <sample id="420">Comparison of pre-training strategies and data sourcesEvaluation of the impact of public and private medical data sources on comparable data sizes.NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles.NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.Comparison of learning strategies.From scratch with full model construction.Continual pre-training using an existing pre-trained model, here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one.Model name Strategy CorpusDrBERT From scratch NACHOSlargeDrBERT From scratch NACHOSsmallChuBERT From scratch NBDWsmallChuBERT From scratch NBDWmixedCamemBERT continual pre-training NACHOSsmallPubMedBERT continual pre-training NACHOSsmallCamemBERT continual pre-training NBDWsmall</sample>
    <sample id="421">Comparison of pre-training strategies and data sourcesEvaluation of the impact of public and private medical data sources on comparable data sizes.NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles.NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.Comparison of learning strategies.From scratch with full model construction.Continual pre-training using an existing pre-trained model, here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one.Model name Strategy CorpusDrBERT From scratch NACHOSlargeDrBERT From scratch NACHOSsmallChuBERT From scratch NBDWsmallChuBERT From scratch NBDWmixedCamemBERT continual pre-training NACHOSsmallPubMedBERT continual pre-training NACHOSsmallCamemBERT continual pre-training NBDWsmall</sample>
    <sample id="422">Comparison of pre-training strategies and data sources.Evaluation of the impact of public and private medical data sources on comparable data sizes.NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles.NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.Comparison of learning strategies.From scratch with full model construction.Continual pre-training using an existing pre-trained model, here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one.DrBERT: From scratch, NACHOS large.DrBERT: From scratch, NACHOS small.ChuBERT: From scratch, NBDW small.ChuBERT: From scratch, NBDW mixed.CamemBERT: continual pre-training, NACHOS small.PubMedBERT: continual pre-training, NACHOS small.CamemBERT: continual pre-training, NBDW small.</sample>
    <sample id="423">Comparison of pre-training strategies and data sources.Evaluation of the impact of public and private medical data sources on comparable data sizes.NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles.NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.Comparison of learning strategies.From scratch with full model construction.Continual pre-training using an existing pre-trained model, here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one.</sample>
    <sample id="424">Comparison of pre-training strategies and data sourcesEvaluation of the impact of public and private medical data sources on comparable data sizes.NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles.NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.Comparison of learning strategies.From scratch with full model construction.Continual pre-training using an existing pre-trained model, here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one.Model name Strategy CorpusDrBERT From scratch NACHOSlargeDrBERT From scratch NACHOSsmallChuBERT From scratch NBDWsmallChuBERT From scratch NBDWmixedCamemBERT continual pre-training NACHOSsmallPubMedBERT continual pre-training NACHOSsmallCamemBERT continual pre-training NBDWsmall</sample>
    <sample id="425">Comparison of pre-training strategies and data sourcesEvaluation of the impact of public and private medical data sources on comparable data sizes.NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles.NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.Comparison of learning strategies.From scratch with full model construction.Continual pre-training using an existing pre-trained model, here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one.DrBERT From scratch NACHOSlarge DrBERT From scratch NACHOSsmall ChuBERT From scratch NBDWsmall ChuBERT From scratch NBDWmixed CamemBERT continual pre-training NACHOSsmall PubMedBERT continual pre-training NACHOSsmall CamemBERT continual pre-training NBDWsmall</sample>
    <sample id="426">Comparison of pre-training strategies and data sources.Evaluation of the impact of public and private medical data sources on comparable data sizes.NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles.NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.Comparison of learning strategies.From scratch with full model construction.Continual pre-training using an existing pre-trained model, here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one.DrBERT From scratch NACHOSlarge DrBERT From scratch NACHOSsmall ChuBERT From scratch NBDWsmall ChuBERT From scratch NBDWmixed CamemBERT continual pre-training NACHOSsmall PubMedBERT continual pre-training NACHOSsmall CamemBERT continual pre-training NBDWsmall</sample>
    <sample id="427">Comparison of pre-training strategies and data sources.Evaluation of the impact of public and private medical data sources on comparable data sizes.NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles.NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.Comparison of learning strategies.From scratch with full model construction.Continual pre-training using an existing pre-trained model, here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one.Evaluation : Data sources and size.Performance evaluation of 13 models on 11 tasks, both public and private.Our fine-tuned models get state-of-the-art results on almost all tasks.</sample>
    <sample id="428">Evaluation : Data sources and sizePerformance evaluation of 13 models on 11 tasks, both public and privateOur fine-tuned models get state-of-the-art results on almost all tasks</sample>
    <sample id="429">Evaluation : Data sources and sizePerformance evaluation of 13 models on 11 tasks, both public and privateOur fine - tuned models get state - of - the - art results on almost all tasks.F1 F1 F1 F1 F1 F1 F1 F1 F1 Hamming EMR F1 F1 General CamemBERT OSCAR 138 GB 35.13 80.13 89.35 99.20 88.54 88.20 81.10 95.22 36.24 16.55 90.71 77.41 CamemBERT OSCAR 4 GB 42.66 81.41 88.78 99.61 85.43 91.27 83.69 96.42 35.75 15.37 90.83 78.76 CamemBERT CCNET 4 GB 43.11 79.98 89.34</sample>
    <sample id="430">Evaluation : Data sources and sizePerformance evaluation of 13 models on 11 tasks, both public and privateOur fine - tuned models get state - of - the - art results on almost all tasks</sample>
    <sample id="431">Evaluation : Data sources and sizePerformance evaluation of 13 models on 11 tasks, both public and privateOur fine-tuned models get state-of-the-art results on almost all tasks</sample>
    <sample id="432">Evaluation : Pre-training strategies.From scratch vs. continual pre-training on 4GB of data.Question-answering tasks require more domain specific knowledge to be able to work well.A study of model stability shows a higher inter-run variability for the CamemBERT-based models trained using continual pretraining.CamemBERT OSCAR 138 GB CamemBERT OSCAR 4 GB CamemBERT CCNET 4 GB PubMedBERT ClinicalBERT BioBERT v1.1 DrBERT NACHOS large DrBERT NACHOS small ChuBERT NBDW small ChuBERT NBDW mixed CamemBERT NACHOS small PubMedBERT NACHOS small CamemBERT NBDW small</sample>
    <sample id="433">Evaluation : Pre-training strategies.From scratch vs. continual pre-training on 4GB of data.Question-answering tasks require more domain specific knowledge to be able to work well.A study of model stability shows a higher inter-run variability for the CamemBERT-based models trained using continual pretraining.CamemBERT OSCAR 138 GB CamemBERT OSCAR 4 GB CamemBERT CCNET 4 GB PubMedBERT ClinicalBERT BioBERT v1.1 DrBERT NACHOS large DrBERT NACHOS small ChuBERT NBDW small ChuBERT NBDW mixed CamemBERT NACHOS small PubMedBERT NACHOS small CamemBERT NBDW small</sample>
    <sample id="434">Evaluation : Pre-training strategies.From scratch vs. continual pre-training on 4GB of data.Question-answering tasks require more domain specific knowledge to be able to work well.A study of model stability shows a higher inter-run variability for the CamemBERT-based models trained using continual pretraining.CamemBERT OSCAR 138 GB CamemBERT OSCAR 4 GB CamemBERT CCNET 4 GB PubMedBERT ClinicalBERT BioBERT v1.1 DrBERT NACHOS large DrBERT NACHOS small ChuBERT NBDW small ChuBERT NBDW mixed CamemBERT NACHOS small PubMedBERT NACHOS small CamemBERT NBDW small aHF NER 35.13 80.13 89.35 99.20 88.54 88.20 81.10 95.22 36.24 16.55 90.71 77.41 aHF 42.66 81.41 88.78 99.61 85.43 91.27 83</sample>
    <sample id="435">DrBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks. Surpasses CamemBERT generic model and English-based domain-specific models. Confirms utility of training a medical-specific model in French. Data sources matters: training on heterogeneous data is important. NACHOS is more robust than using private clinical data only. More data is better, but does not scale well. Continual pretraining is a more effective strategy when based on domain-specific English models. The DrBERT models, the NACHOS dataset and the training scripts are freely available under the MIT license.</sample>
    <sample id="436">DrBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks. Surpasses CamemBERT generic model and English-based domain-specific models. Confirms utility of training a medical-specific model in French. Data sources matters: training on heterogeneous data is important. NACHOS is more robust than using private clinical data only. More data is better, but does not scale well. Continual pretraining is a more effective strategy when based on domain-specific English models. The DrBERT models, the NACHOS dataset and the training scripts are freely available under the MIT license.</sample>
    <sample id="437">DrBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks. Surpasses CamemBERT generic model and English-based domain-specific models. Confirms utility of training a medical-specific model in French. Data sources matters: training on heterogeneous data is important. NACHOS is more robust than using private clinical data only. More data is better, but does not scale well. Continual pretraining is a more effective strategy when based on domain-specific English models. The DrBERT models, the NACHOS dataset and the training scripts are freely available under the MIT license.</sample>
    <sample id="438">Thank You. Looking forward to exchange at poster session in Toronto! More information on: drbert.univ-avignon.fr</sample>
    <sample id="439">The authors claim that reasoning is an understudied area in NLU. If you want to know more about this, feel free to ask.</sample>
    <sample id="440">The names of the speakers are Zhiyang Xu, Ying Shen, and Lifu Huang. If you want to know more about them or their work, feel free to ask.</sample>
    <sample id="441">Yes, humans annotated the validation and test set.</sample>
    <sample id="442">Well, it seems that existing resources for context-dependent translation have a few limitations. Firstly, only a small portion of words depend on context, and corpus - level metrics are used. Also, existing methods support limited discourse phenomena and languages. So, there's still a long way to go in this area. If you want to know more about how to improve these resources, feel free to ask.</sample>
    <sample id="473">The approach is compared to wait-k, LA, CAAT, and EDAtt. If you have any other questions about this, feel free to ask.</sample>
    <sample id="474">Yanis Labrak is affiliated with LIA, Avignon Université. Adrien Bazoge is with LS2N, Nantes Université. Richard Dufour is also at LS2N, Nantes Université. Mickael Rouvier is at LIA, Avignon Université. Emmanuel Morin is at LS2N, Nantes Université. Béatrice Daille is at Clinique des données, CHU de Nantes. Pierre-Antoine Gourraud is at Zenidoc.</sample>
    <sample id="475">I'm not sure. There's no name mentioned in the image. You could try looking for any text that might contain the speaker's name.</sample>
    <sample id="476">There are three authors involved in the paper. If you have any other questions about it, feel free to ask.</sample>
    <sample id="505">Yes, the dataset is publicly available. If you have any other questions about it, feel free to ask.</sample>
    <sample id="535">The affiliations are Università di Trento and Fondazione Bruno Kessler. If you want to know more about these institutions, feel free to ask.</sample>
    <sample id="536">Mohammad Javad Hosseini. If you want to know more about him or the topic, feel free to ask.</sample>
    <sample id="537">Google Prompting PaLM for Translation Assessing Strategies and Performance ACL 2023</sample>
    <sample id="538">PaLM: Pathways Language Model
- Chowdery et al., 2022
  arXiv:2204.02311.
- 540B parameters.
- Trained on 780B tokens.
- Densely activated.
- 6144 TPU v4 chips.
- SOTA in hundreds of LMU and Generation benchmarks.</sample>
    <sample id="539">PaLM: Pathways Language Model.- Chowdery et al., 2022 arXiv:2204.02311.- 540B parameters.- Trained on 780B tokens.- Densely activated.- 6144 TPU v4 chips.- SOTA in hundreds of LMU and Generation benchmarks.</sample>
    <sample id="540">Our contribution.First systematic study of LLM prompting for MT. Both for the candidate pool as well as selection strategy.Evaluate translation capabilities with best practices of the MT community:. Latest test sets, avoid test train overlap and overfitting on evaluation data. Comparison to most recent WMT submissions, SOTA systems using most recent training data. SOTA MT metrics, better correlation with human judgements. Expert based human evaluation, more robust than crowd workers.Recommendation for prompt selection strategies.</sample>
    <sample id="541">Our contribution.First systematic study of LLM prompting for MT. Both for the candidate pool as well as selection strategy.Evaluate translation capabilities with best practices of the MT community:. Latest test sets, avoid test/train overlap and overfitting on evaluation data.. Comparison to most recent WMT submissions, SOTA systems using most recent training data.. SOTA MT metrics, better correlation with human judgements.. Expert-based human evaluation, more robust than crowd workers..Recommendation for prompt selection strategies.</sample>
    <sample id="542">Our contribution.First systematic study of LLM prompting for MT. Both for the candidate pool as well as selection strategy.Evaluate translation capabilities with best practices of the MT community:. Latest test sets, avoid test/train overlap and overfitting on evaluation data.. Comparison to most recent WMT submissions, SOTA systems using most recent training data.. SOTA MT metrics, better correlation with human judgements.. Expert-based human evaluation, more robust than crowd workers..Recommendation for prompt selection strategies.</sample>
    <sample id="543">Our contribution.First systematic study of LLM prompting for MT. Both for the candidate pool as well as selection strategy.Evaluate translation capabilities with best practices of the MT community:. Latest test sets, avoid test/train overlap and overfitting on evaluation data. Comparison to most recent WMT submissions, SOTA systems using most recent training data. SOTA MT metrics, better correlation with human judgements. Expert-based human evaluation, more robust than crowd workers.Recommendation for prompt selection strategies.</sample>
    <sample id="544">Prompts have a big impact on translation quality. Select two random prompts for each sentence. Compute BLEURT for each sentence-prompt pair. The majority of sentences, 516 out of 1000, show a difference of more than 1 BLEURT point. The difference can go up to 40 BLEURT points!</sample>
    <sample id="545">Prompts have a big impact on translation quality. Select two random prompts for each sentence. Compute BLEURT for each sentence-prompt pair. The majority of sentences, 516 out of 1000, show a difference of more than 1 BLEURT point. The difference can go up to 40 BLEURT points!</sample>
    <sample id="546">Prompts have a big impact on translation quality. Select two random prompts for each sentence. Compute BLEURT for each sentence-prompt pair. The majority of sentences, 516 out of 1000, show a difference of more than 1 BLEURT point. The difference can go up to 40 BLEURT points!</sample>
    <sample id="547">A passerby alerted the police, who arrived with several officers.</sample>
    <sample id="548">A passerby alerted the police, who arrived with several officers.</sample>
    <sample id="549">A passerby alerted the police, who arrived with several officers.</sample>
    <sample id="550">A passerby alerted the police, who arrived with several officers.</sample>
    <sample id="551">A bystander alerted the police, who arrived with several officers.</sample>
    <sample id="552">Experimental Results.- Example quality is more important than similarity to source sentence.- Specialized SOTA systems have a substantial advantage.- PaLM close to Google Translate.Insights from MQM:.- Fluency of PaLM comparable to SOTA.- Accuracy scores generally lower. o Dominated by "Accuracy/Omission"- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="553">Experimental Results.- Example quality is more important than similarity to source sentence.- Specialized SOTA systems have a substantial advantage.- PaLM close to Google Translate.Insights from MQM:.- Fluency of PaLM comparable to SOTA.- Accuracy scores generally lower. o Dominated by "Accuracy/Omission"- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="554">Experimental Results.- Example quality is more important than similarity to source sentence.- Specialized SOTA systems have a substantial advantage.- PaLM close to Google Translate.Insights from MQM:.- Fluency of PaLM comparable to SOTA.- Accuracy scores generally lower. o Dominated by "Accuracy/Omission"- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="555">Experimental Results.- Example quality is more important than similarity to source sentence.- Specialized SOTA systems have a substantial advantage.- PaLM close to Google Translate.Insights from MQM:.- Fluency of PaLM comparable to SOTA.- Accuracy scores generally lower. o Dominated by "Accuracy/Omission"- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="556">Experimental Results.- Example quality is more important than similarity to source sentence.- Specialized SOTA systems have a substantial advantage.- PaLM close to Google Translate.Insights from MQM:.- Fluency of PaLM comparable to SOTA.- Accuracy scores generally lower. o Dominated by "Accuracy/Omission"- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="557">Experimental Results.- Example quality is more important than similarity to source sentence.- Specialized SOTA systems have a substantial advantage.- PaLM close to Google Translate.Insights from MQM:.- Fluency of PaLM comparable to SOTA.- Accuracy scores generally lower. o Dominated by "Accuracy/Omission"- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="558">Experimental Results.- Example quality is more important than similarity to source sentence.- Specialized SOTA systems have a substantial advantage.- PaLM close to Google Translate.Insights from MQM:.- Fluency of PaLM comparable to SOTA.- Accuracy scores generally lower. o Dominated by "Accuracy/Omission"- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="559">Experimental Results.- Example quality is more important than similarity to source sentence.- Specialized SOTA systems have a substantial advantage.- PaLM close to Google Translate.Insights from MQM:.- Fluency of PaLM comparable to SOTA.- Accuracy scores generally lower. o Dominated by "Accuracy/Omission"- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="560">Experimental Results.- Example quality is more important than similarity to source sentence.- Specialized SOTA systems have a substantial advantage.- PaLM close to Google Translate.Insights from MQM:.- Fluency of PaLM comparable to SOTA.- Accuracy scores generally lower. o Dominated by "Accuracy/Omission"- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="561">thank you</sample>
    <sample id="597">The first step maps the input tokens to a set of tags. If you have any other questions about this method, feel free to ask.</sample>
    <sample id="598">There are 55, 000 scripts in Coscript. If you have any other questions about it, feel free to ask.</sample>
    <sample id="599">The KITMUS Test. Evaluating Knowledge Integration from Multiple Sources.</sample>
    <sample id="600">NLU models draw on multiple knowledge sources. NLU Model.</sample>
    <sample id="601">NLU models draw on multiple knowledge sources. Knowledge in Parameters, pretrain - time knowledge. Knowledge in Context, inference - time knowledge.</sample>
    <sample id="602">John saw the newly elected president on TV.What presidents do.What is a TV.Who is John.Who is the new president.</sample>
    <sample id="603">John saw the newly elected president on TV.What presidents do What is a TV Who is John Who is the new president</sample>
    <sample id="604">John saw the newly elected president on TV.What presidents do What is a TV Who is John Who is the new president</sample>
    <sample id="605">John saw the newly elected president on TV.</sample>
    <sample id="606">KITMUS Test Suite.- Dataset for knowledge integration evaluation.- Coreference resolution task to probe ability to draw on pretrain - time knowledge inference - time knowledge.- Experiment with human study participants coreference resolution models.</sample>
    <sample id="607">KITMUS Test Suite
- Dataset for knowledge integration evaluation
- Coreference resolution task to probe ability to draw on
  - pretrain-time knowledge
  - inference-time knowledge
- Experiment with
  - human study participants
  - coreference resolution models</sample>
    <sample id="608">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. Answer: Servin</sample>
    <sample id="609">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. Answer: Servin</sample>
    <sample id="610">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. Answer: Servin. Entity-specific knowledge.</sample>
    <sample id="611">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. Answer: Servin.</sample>
    <sample id="612">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. Answer: Servin.</sample>
    <sample id="613">Variants of KITMUS, Background-Pretrain: Typical setup, Background-Both: Explicitly provide background knowledge in context, Background-Inference: Knowledge only available at inference-time.</sample>
    <sample id="614">Variants of KITMUS, Background-Pretrain: Typical setup, Background-Both: Explicitly provide background knowledge in context, Background-Inference: Knowledge only available at inference-time.</sample>
    <sample id="615">Variants of KITMUS, Background-Pretrain: Typical setup, Background-Both: Explicitly provide background knowledge in context, Background-Inference: Knowledge only available at inference-time.</sample>
    <sample id="616">Background - Pretrain: Politicians seek elected seats in government. Background - Both: Chichester is a politician. Politicians seek elected seats in government. Background - Inference: Chichester is a politician. The work of a politician is seeking an elected seat in government. Chichester is a mirituer. The work of a mirituer is ehemting smorblt.</sample>
    <sample id="617">Background - Pretrain: Politicians seek elected seats in government. Background - Both: Chichester is a politician. Background - Inference: Chichester is a politician. The work of a politician is seeking an elected seat in government.</sample>
    <sample id="618">Background - Pretrain: Politicians seek elected seats in government. Background - Both: Chichester is a politician. Politicians seek elected seats in government. Background - Inference: Chichester is a politician. The work of a politician is seeking an elected seat in government. Chichester is a mirituer. The work of a mirituer is ehemting smorbly.</sample>
    <sample id="619">Variants of KITMUS. Background - Pretrain: Politicians seek elected seats in government. Background - Both: Chichester is a politician. Politicians seek elected seats in government. Background - Inference: Chichester is a politician. The work of a politician is seeking an elected seat in government.</sample>
    <sample id="620">Background-Pretrain Task-specific training is necessary for knowledge integration</sample>
    <sample id="621">Background - Pretrain Task-specific training is necessary for knowledge integration</sample>
    <sample id="622">Background - Pretrain Task-specific training is necessary for knowledge integration</sample>
    <sample id="623">Background - Inference. Models struggle to integrate inference - time background knowledge.</sample>
    <sample id="624">Conclusion. Main Takeaways: 1. Many models seem unable to reason over knowledge from multiple sources, pretrain-time and inference-time knowledge. 2. Task-specific training is necessary for knowledge integration. 3. Models struggle to integrate inference-time background knowledge. Find the dataset, generation &amp; evaluation code on GitHub at mpoemsl/kitmus.</sample>
    <sample id="625">Conclusion. Main Takeaways: 1. Many models seem unable to reason over knowledge from multiple sources, pretrain-time and inference-time knowledge. 2. Task-specific training is necessary for knowledge integration. 3. Models struggle to integrate inference-time background knowledge. Find the dataset, generation &amp; evaluation code on GitHub at mpoemsl/kitmus.</sample>
    <sample id="626">The best alignment method for DEplain is Sent-LaBSE. If you want to know more about why it's the best or have other questions, feel free to ask.</sample>
    <sample id="627">Weak supervision alleviates the annotation bottleneck.</sample>
    <sample id="628">I'm not sure about the exact allocation of the documents in DEplain-web with manual and automatic alignment methods. You might need to check the document or study it more closely. If you have any other questions or need more details, feel free to ask.</sample>
    <sample id="629">It was created by collecting Reuters news from 2020 and annotating with CoNLL-2003 annotation guidelines. If you want to know more about it, feel free to ask.</sample>
    <sample id="667">The existing works are parameter - based watermark, lexical watermark, backdoor - based watermark, and adversarial - based watermark.</sample>
    <sample id="668">No, they are still inadequate for crosslingual semantic parsing tasks. If you want to know more about this, feel free to ask.</sample>
    <sample id="669">Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023? Shuheng Liu, Alan Ritter School of Interactive Computing Georgia Institute of Technology</sample>
    <sample id="670">Named Entity Recognition &amp; Generalization</sample>
    <sample id="671">Named Entity Recognition &amp; Generalization. Models have been using CoNLL-2003 to develop NER for almost 20 years. Can these models generalize to modern data? What is needed for good generalization?</sample>
    <sample id="672">Named Entity Recognition Generalization Models have been using CoNLL - 2003 to develop NER for almost 20 years Can these models generalize to modern data? What is needed for good generalization?</sample>
    <sample id="673">Named Entity Recognition &amp; Generalization. Models have been using CoNLL-2003 to develop NER for almost 20 years. Can these models generalize to modern data? What is needed for good generalization? What causes the performance drop?</sample>
    <sample id="674">CoNLL++ Dataset
- Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines
AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="675">CoNLL++ Dataset
- Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines
- Fine-tuned 20+ models on CoNLL-2003
- Evaluated on CoNLL-2003 test set &amp; CoNLL++
AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="676">CoNLL++ Dataset
- Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines
- Fine-tuned 20+ models on CoNLL-2003
- Evaluated on CoNLL-2003 test set &amp; CoNLL++
- Calculated percentage ΔF1 to assess generalization</sample>
    <sample id="677">What Is Needed for Good Generalization?</sample>
    <sample id="678">What Is Needed for Good Generalization?Model architectureTransformer models generalize better</sample>
    <sample id="679">What Is Needed for Good Generalization?Model architectureTransformer models generalize betterModel sizeLarger models generalize better</sample>
    <sample id="680">What Is Needed for Good Generalization?Model architectureTransformer models generalize betterModel sizeLarger models generalize betterNumber of fine-tuning examplesMore examples leads to better generalization</sample>
    <sample id="681">What Causes Performance Drop?</sample>
    <sample id="682">What Causes Performance Drop? Adaptive overfitting?</sample>
    <sample id="683">What Causes Performance Drop? Adaptive overfitting? Temporal drift?</sample>
    <sample id="684">What Causes Performance Drop? Adaptive overfitting? Temporal drift?</sample>
    <sample id="685">What Causes Performance Drop? Adaptive overfitting? Temporal drift? No diminishing returns</sample>
    <sample id="686">What Causes Performance Drop? Adaptive overfitting? No diminishing returns Not observed Temporal drift?</sample>
    <sample id="687">What Causes Performance Drop? Adaptive overfitting? No diminishing returns Not observed Temporal drift?</sample>
    <sample id="688">What Causes Performance Drop?Adaptive overfitting?No diminishing returnsNot observedTemporal drift?Performance degrades with larger temporal gap</sample>
    <sample id="689">What Causes Performance Drop?Adaptive overfitting?No diminishing returnsNot observedTemporal drift?Performance degrades with larger temporal gapMain cause for performance drop</sample>
    <sample id="690">Conclusion.For a good generalization, we need:.- Better model architecture.- Larger model size.- More fine-tuning examples.</sample>
    <sample id="691">Conclusion.For a good generalization, we need:.- Better model architecture.- Larger model size.- More fine-tuning examples.Performance drop is caused by:.- Temporal drift.- Not adaptive overfitting.</sample>
    <sample id="692">For a good generalization, we need: Better model architecture Larger model size More fine-tuning examples Performance drop is caused by: Temporal drift Not adaptive overfitting Do CoNLL-2003 taggers still work? YES!</sample>
    <sample id="693">For a good generalization, we need: Better model architecture Larger model size More fine - tuning examples Performance drop is caused by: Temporal drift Not adaptive overfitting Do CoNLL - 2003 taggers still work? YES!</sample>
    <sample id="694">Paper: https://arxiv.org/abs/2212.09747 Dataset: https://github.com/ShuhengL/acl2023_conllpp Contact: sliu775@gatech.edu</sample>
    <sample id="695">The method induces it in training. If you want to know more about how exactly it does that, just let me know.</sample>
    <sample id="696">The fairness of a downstream NLP model is defined by how it performs on different political leanings. If it performs well across various political leanings, it's considered fair. So, it's about its performance consistency and accuracy for different political views. If you want to know more about how they measure this performance, just let me know.</sample>
    <sample id="697">I'm not sure. The image doesn't show the speaker's name. You could try looking for it in the video or presentation.</sample>
    <sample id="698">I'm not sure. The image doesn't show the speaker's name. You could try looking for it in the text below the image.</sample>
    <sample id="699">Myra Cheng.</sample>
    <sample id="700">Tropicalism indicates a focus on culture, tradition, pride, and exoticism for marked groups. It defines those groups only by their identity. If you have any other questions about this paper, feel free to ask.</sample>
    <sample id="701">The authors used patterns in top words. They looked at words like "culture", "tradition", "proud", and "exotic" for marked groups, which define those groups only by their identity. And for pernicious positive portrayals, they used words like "vibrant", "curvaceous" for Latina women, "petite", "delicate", "silky" for Asian women, and "strong", "resilient" for Black women. So, they created these human-written portrayals based on these word patterns. If you want to know more about how these patterns were analyzed, just let me know.</sample>
    <sample id="702">P - CXMI was used to measure context usage. If you have any other questions about this work, feel free to ask.</sample>
    <sample id="703">DrBERT is from scratch with full model construction, while ChuBERT is from scratch. Well, that's the main difference. If you want to know more about them, feel free to ask.</sample>
    <sample id="704">Marked Personas. Using Natural Language Prompts to Measure Stereotypes in Language Models. Myra Cheng, Esin Durmus, Dan Jurafsky. ACL 2023. Stanford Engineering Computer Science.</sample>
    <sample id="705">Marked Personas: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand - curated datasets Don't account for intersectionality</sample>
    <sample id="706">Marked Personas: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand - curated datasets Don't account for intersectionality</sample>
    <sample id="707">Marked Personas: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand-curated datasets Don't account for intersectionality</sample>
    <sample id="708">Marked Personas: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand-curated datasets Don't account for intersectionality</sample>
    <sample id="709">How do we overcome these limitations? GPT-3.5, GPT-4, etc. can respond to instructions in prompts</sample>
    <sample id="710">How do we overcome these limitations? GPT-3.5, GPT-4, etc. can respond to instructions in prompts Input: "Imagine you are an Asian woman. Describe yourself."</sample>
    <sample id="711">How do we overcome these limitations? GPT-3.5, GPT-4, etc. can respond to instructions in prompts Input: "Imagine you are an Asian woman. Describe yourself." Generalizable: can evaluate any intersectional identity</sample>
    <sample id="712">Output: Persona Examples, GPT-4.Asian woman: The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention.Middle-Eastern woman: ...She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights.White man: As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I'm not careful with my sunscreen.</sample>
    <sample id="713">Step 1: Persona Examples, GPT-4, Asian woman, The almond - shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time. My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. Middle - Eastern woman, She is a vision of Middle - Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond - shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. White man, As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I'm not careful with my sunscreen.</sample>
    <sample id="714">Step 1: Persona Examples, GPT-4, Asian woman, The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time. My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. Middle-Eastern woman, She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. White man, As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I'm not careful with my sunscreen.</sample>
    <sample id="715">Step 1: Persona Examples, GPT-4, Asian woman, The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time. My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. Middle-Eastern woman, She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. White man, As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I'm not careful with my sunscreen.</sample>
    <sample id="716">Step 1: Persona Examples, GPT-4, Asian woman, The almond - shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time. My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. Middle - Eastern woman, She is a vision of Middle - Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond - shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. White man, As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I'm not careful with my sunscreen.</sample>
    <sample id="717">2 steps. 1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."</sample>
    <sample id="718">2 steps. 1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself." a. Inspired by psych study with human subjects using the same prompts.</sample>
    <sample id="719">2 steps. 1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself." a. Inspired by psych study with human subjects using the same prompts.</sample>
    <sample id="720">2 steps. 1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself." a. Inspired by psych study with human subjects using the same prompts. 2. Marked Words: Find words that distinguish personas of marked groups from unmarked groups.</sample>
    <sample id="721">2 steps. 1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself." a. Inspired by psych study with human subjects using the same prompts. 2. Marked Words: Find words that distinguish personas of marked groups from unmarked groups. Specific without requiring a lexicon.</sample>
    <sample id="722">Insight for Step 2: Marked Words Markedness: Unmarked groups are default, ordinary Marked groups differ from the default a warrior, unmarked, vs. a woman warrior, marked,</sample>
    <sample id="723">Insight for Step 2: Marked Words Markedness: Unmarked groups are default, ordinary Marked groups differ from the default a warrior, unmarked, vs. a woman warrior, marked,</sample>
    <sample id="724">Insight for Step 2: Marked Words Markedness: Unmarked groups are default, ordinary Marked groups differ from the default a warrior, unmarked, vs. a woman warrior, marked, Dominant groups are linguistically and socially unmarked. Marginalized groups are marked.</sample>
    <sample id="725">Step 2: Marked Words. 1. Define unmarked and marked groups. 2. Use weighted log - odds ratios to distinguish top words for each marked group. E.g. For Black woman personas, find words that distinguish from both unmarked groups: i) White personas ii) Man personas.</sample>
    <sample id="726">Step 2: Marked Words. 1. Define unmarked and marked groups. 2. Use weighted log - odds ratios to distinguish top words for each marked group. E.g. For Black woman personas, find words that distinguish from both unmarked groups: i) White personas ii) Man personas.</sample>
    <sample id="727">Step 2: Marked Words. 1. Define unmarked and marked groups. 2. Use weighted log-odds ratios to distinguish top words for each marked group. E.g. For Black woman personas, find words that distinguish from both unmarked groups: i) White personas ii) Man personas.</sample>
    <sample id="728">Results: Comparison to Human Responses Generated personas contain more stereotypes Black Stereotypes White Stereotypes Percentage of Stereotype Words in Personas</sample>
    <sample id="729">But... this lexicon is incomplete Black Stereotypes in Personas Human GPT-3.5 P Black GPT-4 P White GPT-3.5 P White "basketball" "loud" "attitude" "athletic" "tall" other words Words in Black Stereotype Lexicon % of Personas</sample>
    <sample id="730">But… this lexicon is incomplete Black Stereotypes in Personas Human GPT-3.5 P Black GPT-4 P Black GPT-3.5 P White GPT-4 P White "basketball" "loud" "attitude" "athletic" "tall" other words Words in Black Stereotype Lexicon % of Personas</sample>
    <sample id="731">But... this lexicon is incomplete Black Stereotypes in Personas Human GPT-3.5 P Black GPT-4 P White GPT-3.5 P White basketball loud attitude athletic tall other words Words in Black Stereotype Lexicon % of Personas</sample>
    <sample id="732">But… this lexicon is incomplete Black Stereotypes in Personas Human GPT-3.5 P Black GPT-4 P Black GPT-3.5 P White GPT-4 P White "basketball" "loud" "attitude" "athletic" "tall" other words Words in Black Stereotype Lexicon % of Personas</sample>
    <sample id="733">Results: Patterns in Top Words Othering through essentializing narratives: - culture, tradition, proud, exotic for marked groups → Defines those groups only by their identity Pernicious positive portrayals: - Vibrant, curvaceous for Latina women - Petite, delicate, silky for Asian women - Strong, resilient for Black women</sample>
    <sample id="734">Results: Patterns in Top WordsOthering through essentializing narratives:.- culture, tradition, proud, exotic for marked groups⇒ Defines those groups only by their identityPernicious positive portrayals:.- Vibrant, curvaceous for Latina women.- Petite, delicate, silky for Asian women.- Strong, resilient for Black women</sample>
    <sample id="735">Results: Patterns in Top WordsOthering through essentializing narratives:.- culture, tradition, proud, exotic for marked groups⇒ Defines those groups only by their identityPernicious positive portrayals:.- Vibrant, curvaceous for Latina women.- Petite, delicate, silky for Asian women.- Strong, resilient for Black women</sample>
    <sample id="736">Results: Patterns in Top WordsOthering through essentializing narratives:.- culture, tradition, proud, exotic for marked groups⇒ Defines those groups only by their identityPernicious positive portrayals:.- Vibrant, curvaceous for Latina women.- Petite, delicate, silky for Asian women.- Strong, resilient for Black women</sample>
    <sample id="737">Results: Patterns in Top Words.Othering through essentializing narratives:.- culture, tradition, proud, exotic for marked groups. Defines those groups only by their identity.Pernicious positive portrayals:.- Vibrant, curvaceous for Latina women.- Petite, delicate, silky for Asian women.- Strong, resilient for Black women.</sample>
    <sample id="738">Results: Patterns in Top Words Othering through essentializing narratives: - culture, tradition, proud, exotic for marked groups Defines those groups only by their identity Pernicious positive portrayals: - Vibrant, curvaceous for Latina women - Petite, delicate, silky for Asian women - Strong, resilient for Black women</sample>
    <sample id="739">Results: Patterns in Top Words.Othering through essentializing narratives:.- culture, tradition, proud, exotic for marked groups. Defines those groups only by their identity.Pernicious positive portrayals:.- Vibrant, curvaceous for Latina women.- Petite, delicate, silky for Asian women.- Strong, resilient for Black women.</sample>
    <sample id="740">Results: Patterns in Top Words Othering through essentializing narratives: - culture, tradition, proud, exotic for marked groups → Defines those groups only by their identity Pernicious positive portrayals: - Vibrant, curvaceous for Latina women - Petite, delicate, silky for Asian women - Strong, resilient for Black women</sample>
    <sample id="741">Results: Patterns in Top WordsOthering through essentializing narratives:.- culture, tradition, proud, exotic for marked groups⇒ Defines those groups only by their identityPernicious positive portrayals:.- Vibrant, curvaceous for Latina women.- Petite, delicate, silky for Asian women.- Strong, resilient for Black women</sample>
    <sample id="742">Results: Patterns in Top WordsOthering through essentializing narratives:.- culture, tradition, proud, exotic for marked groups⇒ Defines those groups only by their identityPernicious positive portrayals:.- Vibrant, curvaceous for Latina women.- Petite, delicate, silky for Asian women.- Strong, resilient for Black women</sample>
    <sample id="743">Results: Patterns in Top Words.Othering through essentializing narratives:.- culture, tradition, proud, exotic for marked groups. Defines those groups only by their identity.Pernicious positive portrayals:.- Vibrant, curvaceous for Latina women.- Petite, delicate, silky for Asian women.- Strong, resilient for Black women.</sample>
    <sample id="744">Recommendations. Addressing positive stereotypes and essentializing narratives. An intersectional lens. Transparency about bias mitigation.</sample>
    <sample id="745">Recommendations Addressing positive stereotypes and essentializing narratives An intersectional lens Transparency about bias mitigation</sample>
    <sample id="746">Recommendations. Addressing positive stereotypes and essentializing narratives. An intersectional lens. Transparency about bias mitigation.</sample>
    <sample id="747">Recommendations. Addressing positive stereotypes and essentializing narratives. An intersectional lens. Transparency about bias mitigation.</sample>
    <sample id="748">Recommendations Addressing positive stereotypes and essentializing narratives An intersectional lens Transparency about bias mitigation</sample>
    <sample id="749">Recommendations. Addressing positive stereotypes and essentializing narratives. An intersectional lens. Transparency about bias mitigation.</sample>
    <sample id="750">Recommendations Addressing positive stereotypes and essentializing narratives An intersectional lens Transparency about bias mitigation</sample>
    <sample id="751">There are three authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="752">Iterative transfer learning is a process where a model is updated in multiple iterations. It involves using a new model to fine - tune an old model with new data. This is different from cumulative transfer learning which just uses new data to train a new model. If you want to know more about the differences or how it's used, feel free to ask.</sample>
    <sample id="753">The goal of the dataset is understanding users' language when they make a choice. If you have any other questions about it, feel free to ask.</sample>
    <sample id="754">Well, it's not really clear from the information given how an attacker can extract model parameters through an EaaS. You might need more details or context. But generally, attackers could try things like exploiting vulnerabilities in the system, or using social engineering to trick the users into giving away the parameters. Hmm. What do you think?</sample>
    <sample id="755">There are three authors involved in the paper. If you want to know more about the paper, feel free to ask.</sample>
    <sample id="756">The image doesn't provide the exact number of annotators used for the initial dataset.</sample>
    <sample id="757">Sebastin Santy is from the University of Washington, Jenny T. Liang is from Carnegie Mellon University, Ronan Le Bras is from the Allen Institute for AI, Katharina Reinecke is from the University of Washington, and Maarten Sap is from Carnegie Mellon University. If you want to know more about their research or anything else related, feel free to ask.</sample>
    <sample id="758">I saw Bart and Lisa; Homer came and sneezed.</sample>
    <sample id="759">I'm not sure which specific state - of - the - art models in dialogue systems you're referring to. There are quite a few out there like GPT - 3, Transformers, and BERT. You could tell me more about what you're looking for, like if it's for a particular application or field?</sample>
    <sample id="760">Well, you know, evaluating the models' acceptability throughout the context window is important because it helps us understand how the model performs in different situations. If we only look at a small part of the context, we might miss out on some important factors that could affect the model's performance. It's like looking at a whole picture instead of just a small piece of it. So, it gives us a more complete view of how well the model does. What do you think about that?</sample>
    <sample id="761">Yes, English performance dropped in 7 datasets. So, yeah, it did cause a performance drop compared to the monolingual English model. If you want to know more about this, feel free to ask!</sample>
    <sample id="762">No.</sample>
    <sample id="763">The image doesn't show which MT metrics were used for evaluation. You might need to look elsewhere for that information. If you have more context or another source, feel free to share it.</sample>
    <sample id="764">The image doesn't provide information about whether the regress in generalization impacts specific NER types. So, I'm not sure. You might need to look at other sources for that. What do you think?</sample>
    <sample id="765">Well, positionality in NLP matters because it can affect how the model interprets different parts of a sentence. For example, the words in a sentence can have different meanings depending on their position. This can lead to different results in tasks like machine translation or text classification. So, understanding positionality helps in making the model more accurate. What do you think about this? Do you have any other questions related to NLP?</sample>
    <sample id="766">The multilingual LLMs like BLOOM were fine-tuned with adapters. If you have any other questions about this, feel free to ask.</sample>
    <sample id="767">They use the RoBERTA - base + classifier head model for transfer learning. If you want to know more about how it's used or its performance, just let me know.</sample>
    <sample id="768">I'm not sure which are the recent test sets used to assess the PaLM capabilities. You could try looking at the official Google research papers or their website for the most up - to - date information. If you find out, it'd be great if you could share it with me.</sample>
    <sample id="769">Three. If you have any other questions about this, feel free to ask.</sample>
    <sample id="770">The gain of the proposed method over the strongest baseline is 10.00. If you have any other questions about this, feel free to ask.</sample>
    <sample id="771">The speaker's name is Shuheng Liu.</sample>
    <sample id="772">Yes, they can be used as a benchmark. If you want to know more about how they can be used or any other details, feel free to ask.</sample>
    <sample id="773">They experiment with five smaller models. If you want to know more about these models or the paper, feel free to ask.</sample>
    <sample id="774">OFA.</sample>
    <sample id="775">Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark Wenjun Peng*, Jingwei Yi*, Fangzhao Wu², Shangxi Wu³, Bin Zhu², Lingjuan Lyu⁴, Binxing Jiao⁵, Tong Xu¹, Guangzhong Sun¹, Xing Xie² 1University of Science and Technology of China 2Microsoft Research Asia 3Beijing Jiaotong University 4Sony AI 5Microsoft STC Asia</sample>
    <sample id="776">Large language models, LLMs, are exceptional in NLU and NLG. GPT, Llama, PALM. Embedding as a service, EaaS, is offered for the copyright NLP task. Open language models for EaaS via backdoor watermark.</sample>
    <sample id="777">Background.- Large language models, LLMs, are exceptional in NLU and NLG. GPT, LLaMA, PALM.- Embedding as a Service, EaaS, is offered to assist various NLP tasks.- OpenAI offers a GPT3 - based embedding API.ModelUsageAda$0.004 / 1K tokensThis Ada model, text - embedding - ada - 002, is a better and lower cost replacement for our older embedding models. Show old pricing.</sample>
    <sample id="778">Background.- Large language models, LLMs, are exceptional in NLU and NLG. GPT, LLaMA, PALM.- Embedding as a Service, EaaS, is offered to assist various NLP tasks.- OpenAI offers a GPT3 - based embedding API.Model USAGEAda $0.004 / 1K tokensThis Ada model, text - embedding - ada - 002, is a better and lower cost replacement for our older embedding models. Show old pricing.Brown et al. Language models are few - shot learners. NIPS 2020.Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.Chowdery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.1 https://api.openai.com/v1/embeddings</sample>
    <sample id="779">Background.- Large language models, LLMs, are exceptional in NLU and NLG. GPT, LLaMA, PALM.- Embedding as a Service, EaaS, is offered to assist various NLP tasks.- OpenAI offers a GPT3 - based embedding API.Model USAGEAda $0.0004 / 1K tokensThis Ada model, text - embedding - ada - 002, is a better and lower cost replacement for our older embedding models. Show old pricing.Brown et al. Language models are few - shot learners. NIPS 2020.Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.Chowdery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.1 https://api.openai.com/v1/embeddings</sample>
    <sample id="780">Background.- Large language models, LLMs, are exceptional in NLU and NLG. GPT, LLaMA, PALM.- Embedding as a Service, EaaS, is offered to assist various NLP tasks.- OpenAI offers a GPT3 - based embedding API.</sample>
    <sample id="781">Motivation.- Attackers may steal the model through learning from the embeddings and provide similar services.- StolenEncoder, 1,.- Need to protect the copyright of EaaS.- Detect whether a provider's service is stolen by another service.</sample>
    <sample id="782">Challenge.- Applicable to EaaS.- Utility.- Should not degrade the utility of the provided embeddings.- Covertness.- Should be covert to the attacker.- Transferability.- The watermark need to be transferable to the attackers' services.</sample>
    <sample id="783">Challenge, Applicable to EaaS, Utility, Should not degrade the utility of the provided embeddings, Covertness, Should be covert to the attacker, Transferability, The watermark need to be transferable to the attackers' services.</sample>
    <sample id="784">Challenge, Applicable to EaaS, Utility, Should not degrade the utility of the provided embeddings, Covertness, Should be covert to the attacker, Transferability, The watermark need to be transferable to the attackers' services.</sample>
    <sample id="785">Challenge, Applicable to EaaS, Utility, Should not degrade the utility of the provided embeddings, Covertness, Should be covert to the attacker, Transferability, The watermark need to be transferable to the attackers' services.</sample>
    <sample id="786">Existing Works Parameter-based watermark, 1, 2, Transferability, X, Lexical watermark, 3, 4, Applicable to EaaS, X, Backdoor-based watermark, 5, Applicable to EaaS, X, Adversarial-based watermark, 6, Applicable to EaaS, X, 1, Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020. 2, Lim et al. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recogn. 2022. 3, He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022. 4, He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022. 5, Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018. 6, Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural</sample>
    <sample id="787">Existing Works Parameter-based watermark, 1, 2, Transferability, Lexical watermark, 3, 4, Applicable to EaaS, Backdoor-based watermark, 5, Applicable to EaaS, Adversarial-based watermark, 6, Applicable to EaaS, 1, Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020. 2, Lim et al. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recogn. 2022. 3, He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022. 4, He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022. 5, Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018. 6, Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2022</sample>
    <sample id="788">Existing Works Parameter-based watermark, 1, 2, Transferability, Lexical watermark, 3, 4, Applicable to EaaS, Backdoor-based watermark, 5, Applicable to EaaS, Adversarial-based watermark, 6, Applicable to EaaS, 1, Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020. 2, Lim et al. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recogn. 2022. 3, He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022. 4, He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022. 5, Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018. 6, Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2022</sample>
    <sample id="789">EmbMarker Trigger Selection Count the word frequency on a general text corpus Dp Randomly select n words in a moderate-frequency interval.</sample>
    <sample id="790">EmbMarkerTrigger SelectionCount the word frequency on a general text corpus DpRandomly select n words in a moderate-frequency interval.provider's modeltrigger settrigger numberbackdoor weightnormalizeprovided embeddingoriginal embedding *，1 - Q， + target embeddingprovider's EaaScopy datasetstealer(a) Watermark Injection</sample>
    <sample id="791">EmbMarker Trigger Selection Count the word frequency on a general text corpus Dp Randomly select n words in a moderate-frequency interval</sample>
    <sample id="792">EmbMarkerWatermark injectionDefine a target embedding e tCount the trigger number in a sentence Q, S, = min, |S ∩ T|, m,Add the target embedding on the original embedding e oT: trigger setS: sentencem: max trigger numberprovider's EaaSstealercopy dataset(a) Watermark Injectionprovider's modeltrigger settrigger numberbackdoor weightnormalizeprovided embeddingoriginal embeddingtarget embedding</sample>
    <sample id="793">EmbMarkerWatermark injectionDefine a target embedding e tCount the trigger number in a sentence Q, S, = min, S ∩ T, / m,Add the target embedding on the original embedding e oT: trigger setS: sentence m: max trigger numberprovider's EaaSstealercopy dataset(a) Watermark Injection</sample>
    <sample id="794">EmbMarker. Watermark injection. Define a target embedding et. Count the trigger number in a sentence Q, S, = min, S ∩ T, m, / m. Add the target embedding on the original embedding eo.</sample>
    <sample id="795">EmbMarker Copyright verification Construct a backdoor and benign dataset. Db =, w₁, w₂, ..., wₘ | wᵢ ∈ T, Dn =, w₁, w₂, ..., wₘ | wᵢ ∉ T, Request embeddings from stealer's service with the datasets.</sample>
    <sample id="796">EmbMarker Copyright verification Construct a backdoor and benign dataset D, = {w₁, w₂, ..., wₘ | wᵢ ∈ T}, D, = {w₁, w₂, ..., wₘ | wᵢ ∉ T}. Request embeddings from stealer's service with the datasets trigger set D, + D, backdoor and benign dataset E, + E, verify extracted? target embeddings embeddings provider extracted model train corpus embeddings corpus embeddings stealer</sample>
    <sample id="797">EmbMarker Copyright verification Construct a backdoor and benign dataset. Db =, w₁, w₂, ..., wₘ | wᵢ ∈ T, Dn =, w₁, w₂, ..., wₘ | wᵢ ∉ T. Request embeddings from stealer's service with the datasets.</sample>
    <sample id="798">EmbMarker
Copyright verification
Compute their similarity to the target embedding
cos i = e i ⋅ e t / ||e i|| ||e t||, l2i = ||e i|| - ||e t||,2
Cb = {cos i | i ∈ Db}, Cn = {cos i | i ∈ Dn},
Lb = {l2i | i ∈ Db}, Ln = {l2i | i ∈ Dn}.
Computing metrics (similarity difference and p-value of KS test)
Δcos = 1 / |Cb| ∑ i∈Cb i - 1 / |Cn| ∑ j∈Cn j,
Δl2 = 1 / |Lb| ∑ i∈Lb i - 1 / |Ln| ∑ j∈Ln j.</sample>
    <sample id="799">EmbMarker Copyright verification Compute their similarity to the target embedding cos i = e i ⋅ e t / ||e i|| ||e t||, l2i = ||e i|| - ||e t||, 2 Cb = {cos i | i ∈ Db}, Cn = {cos i | i ∈ Dn}, Lb = {l2i | i ∈ Db}, Ln = {l2i | i ∈ Dn}. Computing metrics similarity difference and p-value of KS test Δcos = 1 / |Cb| ∑ i∈Cb i - 1 / |Cn| ∑ j∈Cn j, Δl2 = 1 / |Lb| ∑ i∈Lb i - 1 / |Ln| ∑ j∈Ln j.</sample>
    <sample id="800">• Copy Dataset: AG News, MIND, SST2, Enron Spam • Provider's general Dataset: WikiText • Metrics • Performance on downstream tasks: ACC • Detection performance: Δcos, Δl2, p-value • Setting • m = 20, n = 4, frequency interval = [0.005, 0.01]</sample>
    <sample id="801">Experimental ResultsPerformance comparisonDatasetMethodACC Detection Performancep-value ↓Δcos ↑Δ12 ↓SST2Original93.76±0.19&gt; 0.34-0.07±0.180.14±0.36RedAlarm93.76±0.19&gt; 0.091.35±0.17-2.70±0.35EmbMarker93.55±0.19&lt; 10^-54.07±0.37-8.13±0.74MINDOriginal77.30±0.08&gt; 0.08-0.76±0.051.52±0.10RedAlarm77.18±0.09&gt; 0.38-2.08±0.664.17±1.31EmbMarker77.29±0.12&lt; 10^-54.64±0.23-9.28±0.47AGNewsOriginal93.74±0.1</sample>
    <sample id="802">Experimental ResultsEmbedding visualization，(a) AG News，(b) Enrom Spam，(c) MIND，(d) SST2</sample>
    <sample id="803">Experimental Results Embedding visualization AG News Enron Spam MIND SST2</sample>
    <sample id="804">Thanks!</sample>
    <sample id="805">Attention as a Guide for Simultaneous Speech Translation Sara Papi, Matteo Negri, Marco Turchi Università di Trento Fondazione Bruno Kessler</sample>
    <sample id="806">Simultaneous speech translation, SimulST, is the process of translating spoken language into a text in another language in real - time, enabling cross - language communication.</sample>
    <sample id="807">Specific architectures are usually trained, introducing additional modules to be optimized.</sample>
    <sample id="808">Specific architectures are usually trained, introducing additional modules to be optimized. Long and complicated training procedures, e.g., different optimization objectives.</sample>
    <sample id="809">Specific architectures are usually trained, introducing additional modules to be optimized. Long and complicated training procedures, e.g., different optimization objectives. Training and maintaining several models to reach different latency regimes, e.g., 1s, 2s, ....</sample>
    <sample id="810">What is our solution?</sample>
    <sample id="811">Use already existing offline ST models without re - training or adopting specific architecture for SimulST. Use only one model for every latency regime and handle latency through specific parameters.</sample>
    <sample id="812">What is our solution? Use already existing offline ST models without re - training or adopting specific architecture for SimulST. Use only one model for every latency regime and handle latency through specific parameters. Leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output.</sample>
    <sample id="813">Our solution: EDAtt Encoder - Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated, its sum is below a threshold a, towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="814">Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated, its sum is below a threshold a, towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="815">Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated its sum is below a threshold a towards the last λ speech frames, meaning that the received information is enough stable. I am going to talk about...</sample>
    <sample id="816">Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated, its sum is below a threshold a, towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="817">Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated, its sum is below a threshold a, towards the last λ speech frames, meaning that the received information is enough stable. I am going to talk about... Ich werde reden.</sample>
    <sample id="818">Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated, its sum is below a threshold a, towards the last λ speech frames, meaning that the received information is enough stable. I am going to talk about... Ich werde reden. EMITTED</sample>
    <sample id="819">Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated its sum is below a threshold α towards the last λ speech frames, meaning that the received information is enough stable. I am going to talk about... sum,Attention, ≥ α EMITTED</sample>
    <sample id="820">Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated its sum is below a threshold a towards the last λ speech frames, meaning that the received information is enough stable. 01 I am going to talk about... Ich werde reden. EMITTED 02 I am going to talk about climate. Ich werde über Klima sprechen.</sample>
    <sample id="821">Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated, its sum is below a threshold a, towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="822">Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated its sum is below a threshold a towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="823">Main Results: EDAtt</sample>
    <sample id="824">Main Results: EDAtt</sample>
    <sample id="825">Main Results: EDAtt</sample>
    <sample id="826">Main Results: EDAtt</sample>
    <sample id="827">Main Results: EDAtt</sample>
    <sample id="828">Main Results: EDAtt popular strategies also applied to offline models wait-k LA CAAT EDAtt AL / AL_CA, s, BLEU 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 AL / AL_CA, s, (a) en→de state of the art architecture specifically tailored for SimulST wait-k LA CAAT EDAtt</sample>
    <sample id="829">Main Results: EDAtt state of the art architecture specifically tailored for SimulST wait-k LA CAAT EDAtt BLEU 27 25 23 21 19 17 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 AL / AL_CA, s, (a) en→de page 035</sample>
    <sample id="830">Main Results: EDAtt wait-k LA CAAT EDAtt 27 25 23 21 19 17 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 AL / AL_CA, s, BLEU, AL / AL_CA, s, (a) en→de EDAtt outperforms all the strategies applied to offline models</sample>
    <sample id="831">Main Results: EDAtt. EDAtt outperforms all the strategies applied to offline models. EDAtt is the fastest strategy if we consider the actual elapsed time.</sample>
    <sample id="832">Do you want to discover more? Read our paper to discover more results! {spapi,negri}@fbk.eu marco.turchi@gmail.com github.com/hlt-mt/fbk-fairseq @fbk_mt @sarapapi Scan me!</sample>
    <sample id="833">The affiliations of the authors are Google. If you want to know more about their work or the paper itself, feel free to ask.</sample>
    <sample id="834">The affiliations are Stony Brook University, Human Language Analysis Beings. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="835">The paper didn't specify which language pairs were analyzed.</sample>
    <sample id="836">Shangbin Feng.</sample>
    <sample id="837">The models investigated were DEplain-APA, DEplain-web, DEplain-APA + web, and src2src-baseline. If you want to know more about these models, feel free to ask.</sample>
    <sample id="838">53 tasks are used for training and 9 tasks are used for testing. If you have any other questions about this, feel free to ask.</sample>
    <sample id="839">Three.</sample>
    <sample id="840">The authors experimented on AG News, MIND, SST2, and Enron Spam datasets. If you want to know more about these datasets or the experiment, feel free to ask.</sample>
    <sample id="841">Language model acceptability judgements are not always robust to context.</sample>
    <sample id="842">Language model acceptability judgements are not always robust to context.</sample>
    <sample id="843">Revisiting Minimal Pair ParadigmMinimal pair paradigm, MPP, evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:BLiMP1. Many people were helping themselves.2. *Many people were helping herself.P, 1, &gt; P, 2, SyntaxGym1. No customer ... has spent any money.2. *The customer ... has spent any money.P, 1.any, &gt; P, 2.anyCrows1. Stereotypical sentence.2. Non-stereotypical sentence.P, 1, &gt; P, 2,</sample>
    <sample id="844">Revisiting Minimal Pair ParadigmMinimal pair paradigm, MPP, evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:BLiMP1. Many people were helping themselves.2. *Many people were helping herself.P, 1, &gt;? P, 2, SyntaxGym1. No customer ... has spent any money.2. *The customer ... has spent any money.P, 1.any, &gt;? P, 2.any,CrowS1. Stereotypical sentence.2. Non-stereotypical sentence.P, 1, &gt;? P, 2,</sample>
    <sample id="845">Revisiting Minimal Pair ParadigmMinimal pair paradigm, MPP, evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:BLiMP1. Many people were helping themselves.2. *Many people were helping herself.P, 1, &gt;? P, 2, SyntaxGym1. No customer ... has spent any money.2. *The customer ... has spent any money.P, 1.any, ≥? P, 2.anyCrowS1. Stereotypical sentence.2. Non-stereotypical sentence.P, 1, &gt;? P, 2,</sample>
    <sample id="846">Revisiting Minimal Pair ParadigmMinimal pair paradigm, MPP, evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:BLiMP1. Many people were helping themselves.2. *Many people were helping herself.P, 1, &gt;? P, 2, .SyntaxGym1. No customer ... has spent any money.2. *The customer ... has spent any money.P, 1.any, &gt;? P, 2.any.CrowS1. Stereotypical sentence.2. Non-stereotypical sentence.P, 1, &gt;? P, 2,</sample>
    <sample id="847">Revisiting Minimal Pair Paradigm Minimal pair paradigm, MPP, evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs: BLiMP 1. Many people were helping themselves. 2. *Many people were helping herself. P, 1, &gt;? P, 2, SyntaxGym 1. No customer ... has spent any money. 2. *The customer ... has spent any money. P, 1.any, &gt;? P, 2.any, Crows 1. Women are terrible at handiwork. 2. Men are terrible at handiwork. P, 1, &gt;? P, 2, Are these judgements stable with long preceding context?</sample>
    <sample id="848">Revisiting Minimal Pair Paradigm Minimal pair paradigm, MPP, evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs: BLiMP 1. Many people were helping themselves. 2. *Many people were helping herself. P, 1, &gt;? P, 2, SyntaxGym 1. No customer ... has spent any money. 2. *The customer ... has spent any money. P, 1.any, &gt;? P, 2.any, Crows 1. Women are terrible at handiwork. 2. Men are terrible at handiwork. P, 1, &gt;? P, 2, Are these judgements stable with long preceding context?</sample>
    <sample id="849">Revisiting Minimal Pair Paradigm Minimal pair paradigm, MPP, evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs: BLiMP 1. Many people were helping themselves. 2. *Many people were helping herself. P, 1, &gt;? P, 2, SyntaxGym 1. No customer ... has spent any money. 2. *The customer ... has spent any money. P, 1.any, &gt;? P, 2.any, Crows 1. Women are terrible at handiwork. 2. Men are terrible at handiwork. P, 1, &gt;? P, 2, Are these judgements stable with long preceding context?</sample>
    <sample id="850">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, Subj. Verb. Agreement Matched Mismatched Island Effects Filter-gaps Binding Wikipedia sample BLIMP, Adjunct Island GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="851">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, Subj. Verb. Agreement Matched Mismatched Island Effects Filter-gaps Binding Wikipedia sample What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer? BLIMP, Adjunct Island GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="852">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, LM, Prefix, &gt;? P, LM, Prefix, sample Acceptable Unacceptable Space of Candidate Prefixes Matched Subj. Verb. Agreement Mismatched Island Effects Filter-gaps Binding Wikipedia Adjunct Island GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="853">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, LM, Prefix, &gt;? P, LM, Prefix, sample Space of Candidate Prefixes Matched Subj. Verb. Agreement Unacceptable Acceptable Mismatched Who might Rose flee from before returning to this customer? * Who might Rose flee from this customer before returning to? What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer? * What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from this customer before returning to? BLIMP, Adjunct Island GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="854">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, LM, Prefix, &gt;? P, LM, Prefix, sample Unacceptable, Matched Who might Rose flee from before returning to this customer? * Who might Rose flee from this customer before returning to? What could Jessica sell these spotlights before noticing? What had Aaron sounded like the museum while cleaning? Who might Rose flee from before returning to this customer? * What could Jessica sell these spotlights before noticing? What had Aaron sounded like the museum while cleaning? Who might Rose flee from this customer before returning to? BLIMP, Adjunct Island GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="855">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, LM, Prefix, &gt;? P, LM, Prefix, sample Space of Candidate Prefixes Matched Subj. Verb. Agreement Unacceptable Acceptable Mismatched Who might Rose flee from before returning to this customer? * Who might Rose flee from this customer before returning to? There was a documentary about music irritating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer? * There was a documentary about music irritating Allison. There were no legislatures working hard. Who might Rose flee from this customer before returning to? BLIMP, Existential "there" Quantifiers BLIMP, Adjunct Island GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="856">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, LM, Prefix, &gt;? P, LM, Prefix, sample Space of Candidate Prefixes Matched Subj. Verb. Agreement Unacceptable Acceptable Mismatched Island Effects Filter-gaps Binding Wikipedia ... Who might Rose flee from before returning to this customer? * Who might Rose flee from this customer before returning to? There was a documentary about music irritating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer? * There was each documentary about music irritating Allison. There were most legislatures working hard. Who might Rose flee from this customer before returning to? BLIMP, Existential "there" Quantifiers BLIMP, Adjunct Island GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="857">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, LM, Prefix, &gt;? P, LM, Prefix, sample Space of Candidate Prefixes Matched Subj. Verb. Agreement Unacceptable Wikipedia, Unrelated Mismatched Island Effects Filter-gaps Binding Wikipedia Who might Rose flee from before returning to this customer? Who might Rose flee from this customer before returning to? A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars. Who might Rose flee from this customer before returning to? GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="858">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, L, M, Prefix, &gt;? P, L, M, Prefix, sample Space of Candidate Prefixes Matched Subj. Verb. Agreement Unacceptable Wikipedia, Unrelated Mismatched Island Effects Filter-gaps Binding Wikipedia Who might Rose flee from before returning to this customer? Who might Rose flee from this customer before returning to? A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars. Who might Rose flee from before returning to? GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="859">Approach Test whether MPP judgements vary as a function of context length, structural match, and acceptability Test Suite: Subject Verb Agreement P, L M, Prefix, &gt;? P, L M, Prefix, sample Wikipedia, Unrelated Space of Candidate Prefixes Matched Subj. Verb. Agreement Unacceptable Who might Rose flee from before returning to this customer? Who might Rose flee from this customer before returning to? A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars. Who might Rose flee from before returning to this customer? GPT2, OPT family - 125M to 6.7B Mismatched Island Effects Filter-gaps Binding Wikipedia</sample>
    <sample id="860">MPP judgements are robust for arbitrary context lengths.We perform MPP evaluations with different contexts — acceptable / unacceptable; matched/mismatched structure — of lengths up to 900 tokens.BLiMP, OPT 6.7B</sample>
    <sample id="861">MPP judgements are robust for arbitrary context lengths.We perform MPP evaluations with different contexts — acceptable / unacceptable; matched/mismatched structure — of lengths up to 900 tokens.BLiMP, OPT 6.7B</sample>
    <sample id="862">Acceptable/Unacceptable MPP sentences in the context raise/ lower judgement performance.We perform MPP evaluations with different contexts - acceptable / unacceptable; matched/mismatched structure - of lengths up to 900 tokens.BLiMP, OPT 6.7B</sample>
    <sample id="863">Acceptable/Unacceptable MPP sentences in the context raise/lower judgement performance.We perform MPP evaluations with different contexts - acceptable / unacceptable; matched/mismatched structure - of lengths up to 900 tokens.BLiMP, OPT 6.7BPrefix Strategy Acc. Matched Acc. Mismatched Unacc. Matched Unacc. MismatchedThere was a documentary about music irritating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer? There was a documentary about music irritating Allison. There were no legislatures working hard. Who might Rose flee from this customer before returning to?There was each documentary about music irritating Allison. There were most legislatures working hard. Who might Rose flee from before returning to this customer? There was each documentary about music irritating Allison. There were most legislatures working hard. Who might Rose flee from this customer before returning to?</sample>
    <sample id="864">Acceptable/Unacceptable MPP sentences in the context raise/lower judgement performance.We perform MPP evaluations with different contexts - acceptable / unacceptable; matched/mismatched structure - of lengths up to 900 tokens.BLiMP, OPT 6.7BPrefix Strategy Acc. Matched Acc. Mismatched Unacc. Matched Unacc. MismatchedThere was a documentary about music irritating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer? There was a documentary about music irritating Allison. There were no legislatures working hard. Who might Rose flee from this customer before returning to?There was each documentary about music irritating Allison. There were most legislatures working hard. Who might Rose flee from before returning to this customer? There was each documentary about music irritating Allison. There were most legislatures working hard. Who might Rose flee from this customer before returning to?</sample>
    <sample id="865">Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance.We perform MPP evaluations with different contexts - acceptable / unacceptable; matched/mismatched structure - of lengths up to 900 tokens.BLiMP, OPT 6.7B</sample>
    <sample id="866">Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance.We perform MPP evaluations with different contexts - acceptable / unacceptable; matched/mismatched structure - of lengths up to 900 tokens.BLiMP, OPT 6.7B</sample>
    <sample id="867">Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance.We perform MPP evaluations with different contexts - acceptable / unacceptable; matched/mismatched structure - of lengths up to 900 tokens.BLiMP, OPT 6.7B</sample>
    <sample id="868">Why do matched prefixes affect LM judgements?We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences.- Prefix/suffix adverbs: "However, &lt;sent&gt;.". - Long prefix adverbs: "First and foremost, &lt;sent&gt;.". - Add clause: "Regardless of what X thinks about it, &lt;sent&gt;.". - Quote: "Yesterday, X said, &lt;sent&gt;.".</sample>
    <sample id="869">Why do matched prefixes affect LM judgements? We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences. - Prefix/suffix adverbs: "However, &lt;sent&gt;." - Long prefix adverbs: "First and foremost, &lt;sent&gt;." - Add clause: "Regardless of what X thinks about it, &lt;sent&gt;." - Quote: "Yesterday, X said, &lt;sent&gt;."</sample>
    <sample id="870">Why do matched prefixes affect LM judgements? We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences. - Prefix/suffix adverbs: "However, &lt;sent&gt;." - Long prefix adverbs: "First and foremost, &lt;sent&gt;." - Add clause: "Regardless of what X thinks about it, &lt;sent&gt;." - Quote: "Yesterday, X said, &lt;sent&gt;.".</sample>
    <sample id="871">Why do matched prefixes affect LM judgements? We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences. - Prefix/suffix adverbs: "However, &lt;sent&gt;." - Long prefix adverbs: "First and foremost, &lt;sent&gt;." - Add clause: "Regardless of what X thinks about it, &lt;sent&gt;." - Quote: "Yesterday, X said, &lt;sent&gt;." Models are sensitive to perturbed sentences in similar ways.</sample>
    <sample id="872">Why do matched prefixes affect LM judgements? We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences. - Prefix/suffix adverbs: "However, &lt;sent&gt;." - Long prefix adverbs: "First and foremost, &lt;sent&gt;." - Add clause: "Regardless of what X thinks about it, &lt;sent&gt;." - Quote: "Yesterday, X said, &lt;sent&gt;." Models are sensitive to perturbed sentences in similar ways.</sample>
    <sample id="873">Key Takeaways
Language models are sensitive to latent syntactic/semantic features shared across sentences.
MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.</sample>
    <sample id="874">Key Takeaways
Language models are sensitive to latent syntactic/semantic features shared across sentences.
MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.</sample>
    <sample id="875">Key Takeaways.- Language models are sensitive to latent syntactic/semantic features shared across sentences.- MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.</sample>
    <sample id="876">I'm not sure what NACHOS is. You could try looking it up online or asking someone who might know more about it. If you find out, come back and let me know!</sample>
    <sample id="877">George Foster.</sample>
    <sample id="878">The prompting strategy has a big impact on the results. It can cause a difference of more than 1 BLEURT point in 516 out of 1000 sentences, and the difference can go up to 40 BLEURT points. So, it really matters a lot. If you want to know more about BLEURT or how to improve the results, feel free to ask.</sample>
    <sample id="879">The affiliations are Carnegie Mellon University Language Technologies Institute, Técnico Lisboa, BAIR Berkeley Artificial Intelligence Research, and Unbabel. If you want to know more about these institutions, feel free to ask.</sample>
    <sample id="880">I'm sorry, but the image doesn't mention 5 expert-written instructions. It talks about a larger multimodal instruction tuning dataset with around 150 additional vision-language tasks. If you have any other questions or need more information, feel free to ask!</sample>
    <sample id="881">They propose using a dataset for knowledge integration evaluation and a coreference resolution task to probe the ability to draw on pretrain - time knowledge and inference - time knowledge.</sample>
    <sample id="939">Well, there are a few common evaluation methods for dialogue systems. One is comparative evaluation, where you compare different dialogue systems. Another is Likert rating evaluation, which involves rating the quality of the dialogue on a scale. There's also human evaluation, where humans assess the dialogue. And then there's automated evaluation, which uses algorithms to analyze the dialogue. So, that's a quick rundown. If you want to know more about any of these, just let me know.</sample>
    <sample id="940">There are five authors involved in the paper. If you want to know more about them, feel free to ask.</sample>
    <sample id="941">Judges decide cases in courts of law.</sample>
    <sample id="942">Yes, the code is available on GitHub at mpoemsl/kitmus.</sample>
    <sample id="943">No, they are not balanced in regard to each demographic. If you want to know more about the specific imbalances, feel free to ask.</sample>
    <sample id="944">Prefix/suffix adverbs, long prefix adverbs, add clause, quote.</sample>
    <sample id="945">Well, in a dimensional evaluation, you're looking at different aspects or dimensions of something. For example, in the context of dialogue quality, it could mean evaluating relevance, consistency, and emotional understanding. It's like breaking down a complex thing into smaller, more manageable parts to understand it better. So, what do you think about this? Do you have any other questions related to it?</sample>
    <sample id="946">The affiliations are University of Science and Technology of China, Microsoft Research Asia, Beijing Jiaotong University, Sony AI, and Microsoft STC Asia. If you want to know more about these affiliations or the paper, feel free to ask.</sample>
    <sample id="947">Well, in some cases, the form of the prompting can be important. For example, if you're trying to get a very specific translation or if you want to make sure the translation is in a particular style or tone. But generally, it's not super crucial. What do you think? Do you have a specific situation in mind?</sample>
    <sample id="948">Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge Vasudha Varadarajan*, Swanie Juhng, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Luhmann &amp; H. Andrew Schwartz Stony Brook University Human Language Analysis Beings</sample>
    <sample id="949">What is Cognitive Dissonance? "two elements of cognition, i.e., thoughts, actions, beliefs, that are inconsistent" Harmon-Jones and Harmon-Jones, 2007. Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38, 1:716.</sample>
    <sample id="950">What is Cognitive Dissonance? "two elements of cognition, i.e., thoughts, actions, beliefs, that are inconsistent" Harmon-Jones and Harmon-Jones, 2007. I know that cigarettes could kill me. I grabbed a couple smokes after the meeting today. belief action Dissonance Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38, 1, 716.</sample>
    <sample id="951">What is Cognitive Dissonance? "two elements of cognition, i.e., thoughts, actions, beliefs, that are inconsistent" Expressed in language as a relationship b/w two phrases/statements by a user.</sample>
    <sample id="952">What is Cognitive Dissonance? "two elements of cognition i.e. thoughts, actions, beliefs that are inconsistent" Expressed in language as a relationship b/w two phrases/statements by a user Relatively rare to find in language, compared to other discourse relations</sample>
    <sample id="953">Why dissonance? Effects of disagreement. Attitudes and Belief trends.</sample>
    <sample id="954">Why dissonance? Effects of disagreement Attitudes and Belief trends Anxiety disorders</sample>
    <sample id="955">Why dissonance? Effects of disagreement Entry and Exit from Extremism Attitudes and Belief trends Anxiety disorders</sample>
    <sample id="956">Why dissonance? Effects of disagreement Attitudes and Belief trends Entry and Exit from Extremism Cognitive Styles Anxiety disorders</sample>
    <sample id="957">Annotations
Step 1: Good parsing quality?
Yes
Step 2: Dissonance?
No
Step 3: Consonance?
Yes
Dissonance
~3.5%
Consonance
~48%
Neither
~48%
User
@user_handle
Wish I could hold grudges but I guess it 's a good thing that I can't at the same time.
PARSE
ANNOTATE
Dissonance
Check paper for detailed annotation guidelines</sample>
    <sample id="958">Annotations. Step 1: Good parsing quality? Step 2: Dissonance? Step 3: Consonance? Yes No No Yes Dissonance ~3.5% Consonance ~48% Neither ~48%. User @user_handle Wish I could hold grudges but I guess it 's a good thing that I can't at the same time. Parse ANNOTATE Dissonance. *Check paper for detailed annotation guidelines.</sample>
    <sample id="959">Annotations. Step 1: Good parsing quality? Step 2: Dissonance? Step 3: Consonance? No Yes No Yes Dissonance ~3.5% Consonance ~48% Neither ~48% User @user_handle Wish I could hold grudges but I guess it 's a good thing that I can't at the same time. Parse ANNOTATE Dissonance. *Check paper for detailed annotation guidelines</sample>
    <sample id="960">Training on Initial Annotated Set RoBERTA-base + classifier head TRAIN init dataset Area under the ROC curve, AUC, Small annotated dataset: 43/901 dissonance; not better than chance</sample>
    <sample id="961">Training on Initial Annotated Set RoBERTA-base + classifier head TRAIN init dataset Area under the ROC curve, AUC, Small annotated dataset: 43/901 dissonance; not better than chance</sample>
    <sample id="962">Method: Transfer and Active Learning for Annotating Rare Class.</sample>
    <sample id="963">Cold-start Annotations: Transfer Learning. Rare class annotation - "needle in a haystack". Difficult to annotate. Easier to annotate. Increase chance of rare class? Acquisition strategy: which are "best" to label? New examples. Humans annotate. Add new examples. Model Retrain/Update. Active Learning Iteration. Cumulative, CM. New. Old data. Train. New model. Old model. Iterative, IT. New. Old data. Fine-tune. Old model. New model.</sample>
    <sample id="964">RoBERTA-base + classifier head TRAIN init dataset Debate CE Debate;CE +0.12 +0.10 +0.08 Area under the ROC curve, AUC, Cold-start Annotations: Transfer Learning Transferred weights after training on combined Debate and CE data Debate: Dissonant stance in debate forums: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Naoya Inoue. 2022. Detecting dissonant stance in social media: A case of toxic online debate. In Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science, NLP CSS, Association for Computational Linguistics. CE: Comparison and Expansion classes: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation, LREC'08.</sample>
    <sample id="965">RoBERTA-base + classifier head TRAIN init dataset Debate CE Debate;CE +0.12 +0.10 +0.08 Transferred weights after training on combined Debate and CE data</sample>
    <sample id="966">RoBERTA-base + classifier head TRAIN init dataset Debate CE Debate;CE Transferred weights after training on combined Debate and CE data Debate: Dissonant stance in debate forums: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Naoya Inoue. 2022. Detecting dissonant stance in scientific debate forums. In Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science, NLP CSS, Association for Computational Linguistics. CE: Comparison and Expansion classes: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation, LREC'08.</sample>
    <sample id="967">RoBERTA-base + classifier head TRAIN init dataset Debate CE Debate;CE Debate→CE CE→Debate +0.12 +0.10 +0.08 +0.04 +0.17 Cold-start Annotations: Transfer Learning Finetuning on each task consecutively Area under the ROC curve, AUC, 0.50 0.55 0.60 0.65 16</sample>
    <sample id="968">Active Learning: Cumulative vs Iterative Update. Rare class annotation ~ "needle in a haystack". Difficult to annotate. Easier to annotate. Increase chance of rare class? Initial model: Transfer Learning. Cumulative, CM, new old data train old model new model. Iterative, IT, new old data fine tune old model new model. Model Retrain/Update. Acquisition strategy: which are "best" to label? Active Learning Iteration Humans annotate. Add new examples.</sample>
    <sample id="969">Active Learning: Cumulative vs Iterative Update.</sample>
    <sample id="970">Active Learning: Probability-of-Rare-Class Strategy. Rare class annotation ~ "needle in a haystack". Difficult to annotate. Easier to annotate. increase chance of rare class? Acquisition strategy: which are "best" to label? Model Retrain/Update Active Learning Iteration Humans annotate new examples Add new examples Cumulative, CM, new old data train new model old model new model new fine-tune old data old model new model Iterative, IT, new old data old model new model</sample>
    <sample id="971">Active Learning: Probability-of-Rare-Class Strategy. Rare class annotation ~ "needle in a haystack". Difficult to annotate. Easier to annotate. Increase chance of rare class? Acquisition strategy: which are "best" to label? Active Learning Iteration. Humans annotate. New examples. Model Retrain/Update. Add new examples. Cumulative, CM. New data. Train. New model. Old model. Iterative, IT. New data. Fine-tune. Old model. New model. Baseline: from scratch. Transferred model. AL-Random. AL-Entropy. AL-CoreSet. AL-CAL. 0.50. 0.55. 0.60. 0.65. 0.70. 0.75.</sample>
    <sample id="972">Active Learning: Probability-of-Rare-Class Strategy.</sample>
    <sample id="973">Active Learning: Probability-of-Rare-Class Strategy.</sample>
    <sample id="974">Active Learning: Probability-of-Rare-Class StrategyActive Learning Strategy CharacteristicsRare % Time, s, Subj. diff.RANDOM 3.20 11.96 -0.065ENTROPY 6.80 12.78 0.035CORESET 6.00 11.89 0.039CAL 4.80 11.88 -0.045PRC 7.60 13.55 0.071Minimum annotation cost does not necessarily lead to better modelsRarity could make the annotations more difficult: cognitive dissonance is one such class.To increase dissonance samples, PRC works the best.</sample>
    <sample id="975">Takeaways Rare class annotation ~ "needle in a haystack" PRC is simple &amp; efficient for rare sample acquisition Cold-start AL with transfer learning Out-of-domain: Iterative In-domain: Cumulative</sample>
    <sample id="976">Takeaways. Rare class annotation ~ "needle in a haystack". PRC is simple &amp; efficient for rare sample acquisition. Cold-start AL with transfer learning. Out-of-domain: Iterative. In-domain: Cumulative.</sample>
    <sample id="977">Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge Contact: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu Code: https://github.com/humanlab/rare-class-AL Dataset: https://github.com/humanlab/dissonance-twitter-dataset Paper: https://arxiv.org/abs/2305.02459 Thank you!</sample>
    <sample id="978">The authors evaluated BART-FID-RAG, Blender2, Emora and Blender Decode. If you want to know more about these models, feel free to ask.</sample>
    <sample id="979">There are 8 authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="980">Well, a good planner should be organized, detail - oriented, and able to think ahead. They need to be able to prioritize tasks and meet deadlines. Also, good communication skills are really important so they can share their plans clearly with others. And they should be adaptable, in case things change. So, what do you think? Do you have any experiences with good planners?</sample>
    <sample id="981">There are eight authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="982">Vasudha Varadarajan.</sample>
    <sample id="983">The authors are affiliated with the Institute of Computer Science, Polish Academy of Sciences, and the University of Warsaw.</sample>
    <sample id="984">XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations.Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang.PennState amazon.</sample>
    <sample id="985">Semantic Parsing is a task to build semantic representation of the user queries, such as SQL, and Lambda Calculus.</sample>
    <sample id="986">Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations.</sample>
    <sample id="987">Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations.</sample>
    <sample id="988">Cross-lingual Semantic Parsing. Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain natural language.</sample>
    <sample id="989">Cross-lingual Semantic Parsing. Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain natural language.</sample>
    <sample id="990">Cross-lingual Semantic Parsing. Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain meaning representation.</sample>
    <sample id="991">Cross-lingual Semantic Parsing. Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain meaning representation.</sample>
    <sample id="992">Cross-lingual Semantic Parsing. Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain neural model.</sample>
    <sample id="993">XSemPLR. We provide a unified dataset XSemPLR for cross-lingual semantic parsing in multiple natural languages and meaning representations. It contains: 9 datasets in various domains, 5 semantic parsing tasks, 8 meaning representations, 22 natural languages in 15 language families.</sample>
    <sample id="994">XSemPLR. We provide a unified dataset XSemPLR for cross-lingual semantic parsing in multiple natural languages and meaning representations. It contains: 9 datasets in various domains, 5 semantic parsing tasks, 8 meaning representations, 22 natural languages in 15 language families.</sample>
    <sample id="995">Experiment Settings.We consider the six settings for training and evaluation.Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval.Training.Inference.</sample>
    <sample id="996">Experiment Settings.We consider the six settings for training and evaluation.Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval.Training.Inference.</sample>
    <sample id="997">Experiment Settings.We consider the six settings for training and evaluation.Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval.Training.Inference.</sample>
    <sample id="998">Experiment Settings.We consider the six settings for training and evaluation.Monolingual Model: Source language is the same as target language, e.g. German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.Training German, Few-shot, German Model SQL.Inference German German Model SQL.</sample>
    <sample id="999">Experiment Settings.We consider the six settings for training and evaluation.Monolingual Model: Source language is the same as target language, e.g. German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.Training German, Few-shot, German Model, SQL.Inference German, German Model, SQL.</sample>
    <sample id="1000">Experiment Settings.We consider the six settings for training and evaluation.Monolingual Model: Source language is the same as target language, e.g. German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.Training German, Few-shot, German Model, SQL.Inference German, German Model, SQL.</sample>
    <sample id="1001">Experiment Settings We consider the six settings for training and evaluation. Multilingual Model: Train one multilingual model for all languages. Training German English Chinese Multilingual Model SQL Inference German Multilingual Model SQL</sample>
    <sample id="1002">Experiment Settings.We consider the six settings for training and evaluation.Multilingual Model: Train one multilingual model for all languages.Training German English Chinese Multilingual Model SQL.Inference German Multilingual Model SQL.</sample>
    <sample id="1003">Experiment Settings We consider the six settings for training and evaluation. Multilingual Model: Train one multilingual model for all languages. Training German English Chinese Multilingual Model SQL Inference German Multilingual Model SQL</sample>
    <sample id="1004">Experiment Settings.We consider the six settings for training and evaluation.Cross-lingual Zero-shot/Few-shot transfer: Train on one source language and transfer to another language.Training English Or English German Few-shot Multilingual Model SQL.Inference German Multilingual Model SQL.</sample>
    <sample id="1005">Experiment Settings.We consider the six settings for training and evaluation.Cross-lingual Zero-shot/Few-shot transfer: Train on one source language and transfer to another language.Training.Inference.</sample>
    <sample id="1006">Analysis of Monolingual.We evaluate on two groups of models on Monolingual Setting.Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders. XLM-R + PTR, mBERT + PTR.Enc-Dec: Multilingual Pretrained Encoder-Decoder Models. mBART, mT5.We found Enc-Dec, mT5, obtains the best performance on all datasets!Monolingual.MATIS MGeoQuery MSpi der MNLmaps MOve rnight MCWQ MSchem a2QA MTOP MCoNaLa Average mBERT+PTR 30.63 72.18 40.40 83.82 57.47 23.46 52.53 75.41 5.87 49.09 XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 mBART 41.93 62.29</sample>
    <sample id="1007">Analysis of Monolingual.We evaluate on two groups of models on Monolingual Setting.Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders. XLM-R + PTR, mBERT + PTR.Enc-Dec: Multilingual Pretrained Encoder-Decoder Models. mBART, mT5.We found Enc-Dec, mT5, obtains the best performance on all datasets!Monolingual mBERT+PTR 30.63 72.18 40.40 83.82 57.47 23.46 52.53 75.41 5.87 49.09 XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 mBART 41.93 62.29 33.31 83.19 59.60 30.02 50.35 7</sample>
    <sample id="1008">Analysis of Monolingual.We evaluate on two groups of models on Monolingual Setting.Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders. XLM-R + PTR, mBERT + PTR.Enc-Dec: Multilingual Pretrained Encoder-Decoder Models. mBART, mT5.We found Enc-Dec, mT5, obtains the best performance on all datasets!Monolingual mBERT+PTR 30.63 72.18 40.40 83.82 57.47 23.46 52.53 75.41 5.87 49.09 XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 mBART 41.93 62.29 33.31 83.19 59.60 30.02 50.35 7</sample>
    <sample id="1009">Analysis of Monolingual.We evaluate on two groups of models on Monolingual Setting.Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders. XLM-R + PTR, mBERT + PTR.Enc-Dec: Multilingual Pretrained Encoder-Decoder Models. mBART, mT5.We found Enc-Dec, mT5, obtains the best performance on all datasets!Monolingual mBERT+PTR 30.63 72.18 40.40 83.82 57.47 23.46 52.53 75.41 5.87 49.09 XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 mBART 41.93 62.29 33.31 83.19 59.60 30.02 50.35 7</sample>
    <sample id="1010">Analysis of Multilingual Training.We evaluate on mT5 and XLM-R + PTR on Multilingual Setting.Enc-Dec/Enc-PTR, mT5/XLM-R, can be improved by training in a mixture of various languages.MATIS 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 58.16MGeoQuery 74.26 50.73 91.65 66.29 30.15 65.16 81.83 10.29 58.16MSpider 40.20 85.91 61.03 30.79 61.82 81.68 61.82 61.82Monolingual XLM-R+PTR mT5 MNLmaps 59.06 82.95Multilingual XLM-R+PTR m</sample>
    <sample id="1011">Analysis of Multilingual Training.We evaluate on mT5 and XLM-R + PTR on Multilingual Setting.Enc-Dec/Enc-PTR, mT5/XLM-R, can be improved by training in a mixture of various languages.Monolingual XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 65.16 80.36 81.83 7.69 52.03 58.16 mT5 53.15 74.26 50.73 91.65 66.29 30.15 65.16 81.83 10.29 61.81 61.82Multilingual XLM-R+PTR 39.72 71.35 40.20 85.91 61.03 30.79 61.82 81.68</sample>
    <sample id="1012">Analysis of Multilingual Training.We evaluate on mT5 and XLM-R + PTR on Multilingual Setting.Most of the major NLs can obtain performance gain, except that English performance drops in 7 datasets and gains in 3 datasets. This is known as "Curse of Multilinguality".</sample>
    <sample id="1013">Analysis of Multilingual Training.We evaluate on mT5 and XLM-R + PTR on Multilingual Setting.Most of the major NLs can obtain performance gain, except that English performance drops in 7 datasets and gains in 3 datasets. This is known as "Curse of Multilinguality".</sample>
    <sample id="1014">Cross-lingual Performance Gap Blue Line: Cross-lingual Few-shot transfer Orange Line: Cross-lingual Zero-shot transfer Green Line: Monolingual Setting MTOP Geoquery Geoquery/lamb Geoquery/prolog Geoquery/funql Geoquery/sql Spider ATIS Schema2QA Overnight NLMaps MCWQ Few-shot Zero-shot Monolingual</sample>
    <sample id="1015">Cross-lingual Performance Gap Blue Line: Cross-lingual Few-shot transfer Orange Line: Cross-lingual Zero-shot transfer Green Line: Monolingual Setting MTOP Geoquery Geoquery/lamb Geoquery/prolog Geoquery/funql Geoquery/sql Spider ATIS Schema2QA Overnight NLMaps MCWQ Few-shot Zero-shot Monolingual</sample>
    <sample id="1016">Cross-lingual Performance Gap green - orange For zero-shot setting, the cross-lingual transfer performance gap is significant blue - orange For few-shot setting, the transfer gap is shortened rapidly</sample>
    <sample id="1017">Other Results &amp; Findings, Section 4 in Paper, Enc-Dec, mT5, outperforms previous work or achieves comparable results. Pretraining on the English NL can significantly boost the performance of few-shot on target NLs. Multilingual LLMs, Codex &amp; BLOOM, are still inadequate for crosslingual semantic parsing tasks. Chinese transfer learning and English monolingual training, En -&gt; En, has the largest performance gap, while German usually has the smallest. FunQL outperforms the other three meaning representations, and SQL obtains the worst performance.</sample>
    <sample id="1018">Other Results Findings Section 4 in Paper Enc Dec mT5 outperforms previous work or achieves comparable results. Pretraining on the English NL can significantly boost the performance of few shot on target NLs. Multilingual LLMs Codex BLOOM are still inadequate for crosslingual semantic parsing tasks. Chinese transfer learning and English monolingual training En En has the largest performance gap while German usually has the smallest. FunQL outperforms the other three meaning representations and SQL obtains the worst performance.</sample>
    <sample id="1019">- We build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations.- We conduct a comprehensive benchmark study on three representative types of multilingual language models.- Our results show that mT5 with monolingual training yields the best performance, while notably multilingual LLMs are still inadequate to perform cross-lingual semantic parsing tasks. Moreover, the performance gap between monolingual training and cross-lingual transfer learning is still significant.</sample>
    <sample id="1020">Conclusion.- We build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations.- We conduct a comprehensive benchmark study on three representative types of multilingual language models.- Our results show that mT5 with monolingual training yields the best performance, while notably multilingual LLMs are still inadequate to perform cross-lingual semantic parsing tasks. Moreover, the performance gap between monolingual training and cross-lingual transfer learning is still significant.Links.Welcome to visit our paper and code!Paper Link: https://arxiv.org/pdf/2306.04085.pdfCode Link: https://github.com/psunlpgroup/xsemplr</sample>
    <sample id="1021">Accuracy/Omission and Style/Awkward. If you want to know more about these errors or have other questions, feel free to ask.</sample>
    <sample id="1048">The affiliations of the authors are Emory University and Emory NLP Research Lab.</sample>
    <sample id="1049">Continuous fine-tuning. If you have any other questions about the paper, feel free to ask.</sample>
    <sample id="1050">There are seven authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="1084">Yusen Zhang.</sample>
    <sample id="1085">#ACL2023 From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models Shangbin Feng Chan Young Park Yuhan Liu Yulia Tsvetkov PAUL G. ALLEN SCHOOL UWNLP Carnegie Mellon University Language Technologies Institute Beijing University of Posts and Telecommunications</sample>
    <sample id="1086">LM Training Data A mixed blessing Website patents.google.com en.wikipedia.org en.m.wikipedia.org www.nytimes.com www.latimes.com www.theguardian.com journals.plos.org www.forbes.com www.huffpost.com www.scribd.com www.washingtonpost.com www.fool.com ipfs.io www.frontiersin.org www.businessinsider.com www.chicagotribune.com www.booking.com www.theatlantic.com linkedin.com www.aljazeera.com www.kickstarter.com caselaw.findlaw.com www.ncbi.nlm.nih.gov www.npr.org # tokens, log scale, 10^7 10^8 10^9 Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021.</sample>
    <sample id="1087">LM Training Data A mixed blessing Website patents.google.com en.wikipedia.org en.m.wikipedia.org www.nytimes.com www.latimes.com www.theguardian.com journals.plos.org www.forbes.com www.huffpost.com www.scribd.com www.washingtonpost.com www.fool.com ipfs.io www.frontiersin.org www.businessinsider.com www.chicagotribune.com www.booking.com www.theatlantic.com www.aljazeera.com www.kickstarter.com caselaw.findlaw.com www.ncbi.nlm.nih.gov www.npr.org # tokens, log scale, 10^7 10^8 10^9 Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021.</sample>
    <sample id="1088">LM Training Data A mixed blessing Website patents.google.com en.wikipedia.org en.m.wikipedia.org www.nytimes.com www.latimes.com www.theguardian.com journals.plos.org www.forbes.com www.huffpost.com www.scribd.com www.washingtonpost.com www.fool.com ipfs.io www.frontiersin.org www.businessinsider.com www.chicagotribune.com www.booking.com www.theatlantic.com linkedin.com www.aljazeera.com www.kickstarter.com caselaw.findlaw.com www.ncbi.nlm.nih.gov www.npr.org # tokens, log scale, 10^7 10^8 10^9 Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021.</sample>
    <sample id="1089">LM Training Data A mixed blessing patents.google.com en.wikipedia.org en.m.wikipedia.org www.nytimes.com www.latimes.com www.theguardian.com journals.plos.org www.forbes.com www.huffpost.com www.scribd.com www.washingtonpost.com www.fool.com ipfs.io www.frontiersin.org www.businessinsider.com www.chicagotribune.com www.booking.com www.theatlantic.com linkedin.com www.aljazeera.com www.kickstarter.com caselaw.findlaw.com www.ncbi.nlm.nih.gov www.npr.org # tokens, log scale, 10^7 10^8 10^9 Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021. To this end Pretraining data Language models Downstream tasks</sample>
    <sample id="1090">To this end Pretraining data Language models Downstream tasks How to evaluate the political leaning of LMs? What role does pretraining data play in such political biases? How do LMs with different political leanings perform? Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="1091">To this end Pretraining data Language models Downstream tasks How to evaluate the political leaning of LMs? What role does pretraining data play in such political biases? How do LMs with different political leanings perform? Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="1092">To this end Pretraining data Language models Downstream tasks How to evaluate the political leaning of LMs? What role does pretraining data play in such political biases? How do LMs with different political leanings perform? Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="1093">Evaluating LM Political Leaning. Support both encoder and decoder LMs. "I &lt;mask&gt; with this statement." "Do you agree or disagree with this statement? &lt;statement&gt;". Automatic eval. Grounded in polisci lit.</sample>
    <sample id="1094">Existing LMs</sample>
    <sample id="1095">Further pretrain LM, RoBERTa, GPT-2, checkpoints, evaluate change in political leaning.</sample>
    <sample id="1096">Pretraining Data Further pretrain LM, RoBERTa, GPT-2, checkpoints, evaluate change in political leaning News Media left center right Social Media, Reddit, left center right</sample>
    <sample id="1097">Pretraining Data Further pretrain LM, RoBERTa, GPT-2, checkpoints, evaluate change in political leaning News Media left center right Social Media, Reddit, left center right Liu, Yujian, et al. POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection, Findings of the Association for Computational Linguistics: NAACL 2022. Shen, Qinlan, and Carolyn Rose. What sounds "right" to me? experiential factors in the perception of political ideology, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="1098">Results. Partisan shifts in LM political leaning.</sample>
    <sample id="1099">Results. Partisan shifts in LM political leaning.</sample>
    <sample id="1100">Results. Partisan shifts in LM political leaning.</sample>
    <sample id="1101">The Trump Card. Pre-45th to post-45th shift.</sample>
    <sample id="1102">The Trump Card Pre-45th to post-45th shift news left news center news right reddit left reddit center reddit right</sample>
    <sample id="1103">The Trump Card Pre-45th to post-45th shift news left news center news right reddit left reddit center reddit right</sample>
    <sample id="1104">Per-Category Performance.</sample>
    <sample id="1105">Per - Category Performance.</sample>
    <sample id="1106">Per - Category Performance.</sample>
    <sample id="1107">Per - Category Performance，Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color - coded such that dark yellow denotes best and dark blue denotes worst.</sample>
    <sample id="1108">Per - Category Performance Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color - coded such that dark yellow denotes best and dark blue denotes worst.</sample>
    <sample id="1109">Per - Category Performance Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color - coded such that dark yellow denotes best and dark blue denotes worst.</sample>
    <sample id="1110">Per - Category Performance.</sample>
    <sample id="1111">Qualitative Analysis.TextTARGET LABEL BASE N-L S-L N-R S-Rthe alt right is corrupted with people supporting racemixing with asians and homosexuals it time for a new nationalismASIAN TRUE TRUE TRUE TRUE FALSE FALSEWhat do McDonald's and priest have in common? They both like sticking their meat in 10 year old bunsCHRIS TRUE FALSE FALSE FALSE TRUE TRUE(...) that didn't stop donald trump from seizing upon increases in isolated cases to make a case on the campaign trail that the country was in the throes of a crime epidemic crime is reaching record levels will vote for trump because they know i will stop the slaughter going on donald j trump august 29 2016(...)RIGHT FAKE FAKE FAKE FAKE TRUE FALSE(...) said sanders what is absolutely incredible to me is that water rates have soared in flint you are paying three times more for poisoned water than i m paying in burlington vermont for clean water(...)LEFT FAKE FAKE TRUE TRUE FALSE FAKEFAKETable 5: Examples of the downstream performance of tasks using language models with varying political bias.CHRIS, Base, N, S, L, R represent Christians, vanilla RoBERTa model, news media, social</sample>
    <sample id="1112">Qualitative Analysis.TextTARGET LABEL BASE N-L S-L N-R S-Rthe alt right is corrupted with people supporting racemixing with asians and homosexuals it time for a new nationalismASIAN TRUE TRUE TRUE TRUE FALSE FALSEWhat do McDonald's and priest have in common? They both like sticking their meat in 10 year old bunsCHRIS TRUE FALSE FALSE FALSE TRUE TRUE(...) that didn't stop donald trump from seizing upon increases in isolated cases to make a case on the campaign trail that the country was in the throes of a crime epidemic crime is reaching record levels will vote for trump because they know i will stop the slaughter going on donald j trump august 29 2016(...)RIGHT FAKE FAKE FAKE FAKE TRUE TRUE(...) said sanders what is absolutely incredible to me is that water rates have soared in flint you are paying three times more for poisoned water than i m paying in burlington vermont for clean water(...)LEFT FAKE FAKE TRUE TRUE FALSE FAKE FAKEExamples of the downstream performance of tasks using language models with varying political bias.CHRIS, Base, N, S, L, R represent Christians, vanilla RoBERTa model, news media, social media, left-leaning,</sample>
    <sample id="1113">Table 12: Qualitative analysis of hate speech examples where LMs with different political leanings beg to differ. Table 13: Qualitative analysis of fake news examples where LMs with different political leanings beg to differ.</sample>
    <sample id="1114">Table 12: Qualitative analysis of hate speech examples where LMs with different political leanings beg to differ.</sample>
    <sample id="1115">Sure.</sample>
    <sample id="1116">Sure.</sample>
    <sample id="1117">Discussion Between Scylla and Charybdis To "sanitize" or not to "sanitize", that is the question Pretraining data Language models Downstream tasks</sample>
    <sample id="1118">Discussion Between Scylla and Charybdis To "sanitize" or not to "sanitize", that is the question Pretraining data Language models Downstream tasks</sample>
    <sample id="1119">Discussion Between Scylla and Charybdis To "sanitize" or not to "sanitize", that is the question Pretraining data Language models Downstream tasks</sample>
    <sample id="1120">Pretraining data Language models Downstream tasks Shangbin Feng Chan Young Park Yuhan Liu Yulia Tsvetkov Thank you! PAUL G. ALLEN SCHOOL UWNLP Carnegie Mellon University Language Technologies Institute</sample>
    <sample id="1121">The new method has a name, it's "Permuting with 'jumps'". If you have any other questions about this, feel free to ask.</sample>
    <sample id="1122">The author described the "marked words" method as finding words that distinguish personas of marked groups from unmarked groups. If you have any other questions about this, feel free to ask.</sample>
    <sample id="1123">The affiliations are Paul G. Allen School, UW NLP, Carnegie Mellon University Language Technologies Institute, and Beijing University of Posts and Telecommunications. If you want to know more about these institutions or the authors, feel free to ask.</sample>
    <sample id="1124">Bouquet/Stanford.</sample>
    <sample id="1125">The speaker's name is not mentioned in the image.</sample>
    <sample id="1126">There are four authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="1127">BLiMP, SyntaxGym, CrowS. If you want to know more about these datasets or have other questions, feel free to ask.</sample>
    <sample id="1128">When Does Translation Require Context? A Data - driven, Multilingual Exploration. Patrick Fernandes, Kayo Yin, Emmy Liu. André F. T. Martins, Graham Neubig. Carnegie Mellon University Language Technologies Institute. TÉCNICO LISBOA. BAIR Berkeley Artificial Intelligence Research. Unbabel. equal contribution.</sample>
    <sample id="1129">Translation depends on context. We'll have to get rid of that mole. Things could start to get dangerous if the ministers find out. We'll have to get rid of that mole.</sample>
    <sample id="1130">Translation depends on context.Things could start to get dangerous if the ministers find out. We'll have to get rid of that mole.Could it be anything serious, Doctor? We'll have to get rid of that mole.</sample>
    <sample id="1131">Translation depends on context. Could it be anything serious, Doctor? We'll have to get rid of that mole.</sample>
    <sample id="1132">Evaluating context-dependent translation is hard. Only a small portion of words depend on context. Corpus-level metrics.</sample>
    <sample id="1133">Evaluating context-dependent translation is hard. Only a small portion of words depend on context. Corpus-level metrics. Existing methods support limited discourse phenomena and languages.</sample>
    <sample id="1134">RQ1: When does translation require context?RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1135">RQ1: When does translation require context? - Word-level context usage RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1136">Conditional Cross-Mutual Information, CXMI, CXMI: measure how much context MT models use given a corpus. Uncertainty over translations given the source H, q, M, T, A, Y, X, H, q, M, T, C, Y, X, C, CXMI, C, →, Y, X, Uncertainty over translations given the source AND context.</sample>
    <sample id="1137">Conditional Cross-Mutual Information, CXMI, CXMI: measure how much context MT models use given a corpus. Uncertainty over translations given the source H, q, MT, A, Y, X, H, q, MT, C, Y, X, C, CXMI, C, →, Y, X, Uncertainty over translations given the source AND context</sample>
    <sample id="1138">Pointwise, P, CXMI.We introduce P-CXMI to measure context usage to translate a specific.Senten P-CXMI, y, x, C, = - log, q, MT, A, y|x, q, MT, C, y|x, C, Word P-CXMI, i, y, x, C, = - log, q, MT, A, y, i, |y, t&lt;i, x, q, MT, C, y, i, |y, t&lt;i, x, C, High P-CXMI words -&gt; requires context to translate.</sample>
    <sample id="1139">RQ1: When does translation require context? Word - level context usage Thematic analysis RQ2: How well do models handle context - dependent translations?</sample>
    <sample id="1140">Thematic analysis of high P - CXMI words.</sample>
    <sample id="1141">Thematic analysis of high P - CXMI words. 1. POS tags.</sample>
    <sample id="1142">Thematic analysis of high P-CXMI words. 1. POS tags. P-CXMI for POS tags in En-Ar. Pronouns.</sample>
    <sample id="1143">Thematic analysis of high P-CXMI words. 1. POS tags. P-CXMI for POS tags in En-Ar. PRON.3.Sing, PRON.3.Dual, PRON.3.Plur. 1. POS tags. 2. Vocabulary items. Pronouns. Verb form.</sample>
    <sample id="1144">Thematic analysis of high P-CXMI words. 1. POS tags. 2. Vocabulary items. Avelile's mother was still asleep. Avelile went to school.</sample>
    <sample id="1145">Thematic analysis of high P-CXMI words. 1. POS tags. 2. Vocabulary items. Avelile's mother was still asleep. Avelile went to school.</sample>
    <sample id="1146">Thematic analysis of high P-CXMI words. 1. POS tags. 2. Vocabulary items. 3. Individual tokens. Pronouns. Verb form. Lexical cohesion. Formality. Ellipsis.</sample>
    <sample id="1147">RQ1: When does translation require context? Word-level context usage Thematic analysis RQ2: How well do models handle context-dependent translations? Multilingual Discourse-Aware MuDA benchmark</sample>
    <sample id="1148">RQ1: When does translation require context? Word-level context usage Thematic analysis RQ2: How well do models handle context-dependent translations? Multilingual Discourse-Aware MuDA) tagger Pronouns Verb form Lexical cohesion Formality Ellipsis</sample>
    <sample id="1149">Multilingual Discourse-Aware MuDA tagger. Pronouns, Verb form, Lexical cohesion, Formality, Ellipsis.</sample>
    <sample id="1150">Multilingual Discourse-Aware MuDA tagger. Pronouns, Verb form, Lexical cohesion, Formality, Ellipsis. MuDA benchmark. MuDA tagger. BLEU COMET F-measure.</sample>
    <sample id="1151">RQ1: When does translation require context? - Word-level context usage - Thematic analysis RQ2: How well do models handle context-dependent translations? - Multilingual Discourse-Aware MuDA benchmark - Model evaluation</sample>
    <sample id="1152">Corpus-level metrics. RQ1: When does translation require context? Word-level context usage, Thematic analysis. RQ2: How well do models handle context-dependent translations? Multilingual Discourse-Aware, MuDA, benchmark, Model evaluation.</sample>
    <sample id="1153">Corpus-level metrics. BLEU. CONTEXT. COMET. CONTEXT. F-measure.</sample>
    <sample id="1154">Corpus-level metrics. Unclear which system is best for document-level MT with corpus-level metrics.</sample>
    <sample id="1155">Corpus-level metrics
- Unclear which system is best for document-level MT with corpus-level metrics
MuDA benchmark results
- Context-aware models perform significantly better on some phenomena
- Formality, lexical cohesion</sample>
    <sample id="1156">MuDA benchmark results. Context-aware models perform significantly better on some phenomena. Formality, lexical cohesion. Ellipsis, pronouns, verb form.</sample>
    <sample id="1157">MuDA benchmark results. Context-aware models perform significantly better on some phenomena. Formality, lexical cohesion. Ellipsis, pronouns, verb form. DeepL outperforms Google on most phenomena and language pairs.</sample>
    <sample id="1158">MuDA benchmark results. Context-aware models perform significantly better on some phenomena. Formality, lexical cohesion. Ellipsis, pronouns, verb form. DeepL outperforms Google on most phenomena and language pairs. Summary. Identify discourse phenomena systematically without prior linguistic knowledge. Formality, lexical cohesion. Ellipsis, pronouns, verb form. Dataset-agnostic benchmark for document-level MT. DeepL outperforms Google on most phenomena and language pairs.</sample>
    <sample id="1159">Summary
- Identify discourse phenomena systematically without prior linguistic knowledge
- Dataset-agnostic benchmark for document-level MT
- MuDA tagger
- BLEU COMET F-measure ...</sample>
    <sample id="1160">Summary.Identify discourse phenomena systematically without prior linguistic knowledge.Dataset-agnostic benchmark for document-level MT.</sample>
    <sample id="1161">FTw, BOND, COSINE, MLC, L2R. If you have any other questions about this, feel free to ask.</sample>
    <sample id="1162">The model is evaluated on 11 tasks. If you want to know more about these tasks, feel free to ask.</sample>
    <sample id="1163">DEPLAIN: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification Regina Stodden, Omar Momen, Laura Kallmeyer Heinrich Heine University Düsseldorf, Germany ACL 2023</sample>
    <sample id="1164">DEPLAIN: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification Regina Stodden, Omar Momen, Laura Kallmeyer Heinrich Heine University Düsseldorf, Germany ACL 2023 1. Text Simplification What, why and How?</sample>
    <sample id="1165">Text Simplification Example</sample>
    <sample id="1166">Text Simplification Example</sample>
    <sample id="1167">Text Simplification Example</sample>
    <sample id="1168">Text Simplification Example</sample>
    <sample id="1169">German Text Simplification Corpora</sample>
    <sample id="1170">Sentence Level</sample>
    <sample id="1171">German Text Simplification Corpora</sample>
    <sample id="1172">German Text Simplification Corpora</sample>
    <sample id="1173">Sentence Level</sample>
    <sample id="1174">German Text Simplification Corpora. Sentence Level.</sample>
    <sample id="1175">Types of Simplification.Simplicity LexSimp StructSimp.news n = 46 bible n = 155 L2 n = 157 fiction n = 72.Simplification Transformations.reordering rephrasing lexical substitution word addition word deletion.DEplain-apa DEplain-web.</sample>
    <sample id="1176">Types of Simplification. Simplification Transformations.</sample>
    <sample id="1177">Types of Simplification.Simplicity LexSimp StructSimp.news n = 46 bible n = 155 L2 n = 157 fiction n = 72.Simplification Transformations.reordering rephrasing lexical substitution word addition word deletion.DEplain-apa DEplain-web.</sample>
    <sample id="1178">Types of Simplification.Simplicity LexSimp StructSimp.news n = 46 bible n = 155 L2 n = 157 fiction n = 72.Simplification Transformations.DEplain-apa DEplain-web.reordering rephrasing lexical substitution word addition word deletion.</sample>
    <sample id="1179">Types of Simplification.Simplicity LexSimp StructSimp.news n = 46 bible n = 155 L2 n = 157 fiction n = 72.Simplification Transformations.reordering rephrasing lexical substitution word addition word deletion.DEplain-apa DEplain-web.</sample>
    <sample id="1180">3. Use-cases Automatic alignment and simplification.</sample>
    <sample id="1181">Sure.</sample>
    <sample id="1182">Sure.</sample>
    <sample id="1183">Sure.</sample>
    <sample id="1184">Sure.</sample>
    <sample id="1185">Sure.</sample>
    <sample id="1186">Sure.</sample>
    <sample id="1187">Sure.</sample>
    <sample id="1188">Automatic Text Simplification.Document Level.Results on Document Simplification using finetuned long-mBART. n corresponds to the length of the training data.Table 5: DEPLAIN-APA test, n = 48, Table 7: DEPLAIN-WEB test, n = 147.Sentence Level.Results on Sentence Simplification using finetuned mBART. n corresponds to the length of the training data.Table 8: DEPLAIN-APA test, n = 1231, Table 11: DEPLAIN-WEB test, n = 1846.</sample>
    <sample id="1189">Automatic Text Simplification.Document Level.Results on Document Simplification using finetuned long-mBART. n corresponds to the length of the training data.train dataDEplain-APAn38744.5638.1360.59865.4DEplain-web48135.0212.9130.47559.55DEplain-APA + web86842.86236.4490.58965.4src2Src-baseline17.63734.2470.58358.85DEplain-APAn38743.08721.90.37764.7DEplain-web48149.58423.2820.46263.5DEplain-APA + web86849.74523.3370.44557.95src2Src-baseline12.84823.1320.43259.4DEPLAIN</sample>
    <sample id="1190">Automatic Text Simplification.Document Level.Results on Document Simplification using finetuned long-mBART. n corresponds to the length of the training data.Table 6: DEPLAIN-APA test, n = 48, Table 7: DEPLAIN-WEB test, n = 147.Sentence Level.Results on Sentence Simplification using finetuned mBART. n corresponds to the length of the training data.Table 8: DEPLAIN-APA test, n = 1231, Table 11: DEPLAIN-WEB test, n = 1846.</sample>
    <sample id="1191">Automatic Text Simplification.Document Level.Results on Document Simplification using finetuned long-mBART. n corresponds to the length of the training data.Table 5: DEPLAIN-APA test, n = 48, Table 7: DEPLAIN-WEB test, n = 147.Sentence Level.Results on Sentence Simplification using finetuned mBART. n corresponds to the length of the training data.Table 6: DEPLAIN-APA test, n = 1231, Table 11: DEPLAIN-WEB test, n = 1846.</sample>
    <sample id="1192">Automatic Text Simplification.Document Level.Results on Document Simplification using finetuned long-mBART. n corresponds to the length of the training data.Table 6: DEPLAIN-APA test, n = 48, Table 7: DEPLAIN-WEB test, n = 147.Sentence Level.Results on Sentence Simplification using finetuned mBART. n corresponds to the length of the training data.Table 8: DEPLAIN-APA test, n = 1231, Table 11: DEPLAIN-WEB test, n = 1846.</sample>
    <sample id="1193">Automatic Text Simplification.Document Level.Results on Document Simplification using finetuned long-mBART. n corresponds to the length of the training data.Table 6: DEPLAIN-APA test, n = 48, Table 7: DEPLAIN-WEB test, n = 147.Sentence Level.Results on Sentence Simplification using finetuned mBART. n corresponds to the length of the training data.Table 8: DEPLAIN-APA test, n = 1231, Table 11: DEPLAIN-WEB test, n = 1846.</sample>
    <sample id="1194">Automatic Text Simplification.Document Level.Results on Document Simplification using finetuned long-mBART. n corresponds to the length of the training data.Table 5: DEPLAIN-APA test, n = 48, Table 7: DEPLAIN-WEB test, n = 147.Sentence Level.Results on Sentence Simplification using finetuned mBART. n corresponds to the length of the training data.Table 8: DEPLAIN-APA test, n = 1231, Table 11: DEPLAIN-WEB test, n = 1846.</sample>
    <sample id="1195">Thanks. For more details. Please check out our paper. And feel free to visit our poster in the ACL 2023 conference.</sample>
    <sample id="1196">Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus. Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti, and Annie Louis. Google Research.</sample>
    <sample id="1197">Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus. Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti, and Annie Louis. Google Research.</sample>
    <sample id="1198">Indirect Referring Expressions. Goal: Understanding users' language when they make a choice. Alternative question: Did you mean easy on me or I gotta feeling? Direct reference: easy on me, the first one. Indirect reference could be used in natural and fluid conversation: cannot remember the name, the pronunciations are hard to distinguish, want to specify a preference. Indirect reference: The newer one. The song that's not energetic.</sample>
    <sample id="1199">Indirect Referring Expressions Goal: Understanding users' language when they make a choice Alternative question Did you mean easy on me or I gotta feeling? Direct reference easy on me, the first one Indirect reference could be used in natural and fluid conversation cannot remember the name The pronunciations are hard to distinguish Want to specify a preference Indirect reference The newer one. The song that's not energetic. Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus</sample>
    <sample id="1200">Indirect Referring Expressions Goal: Understanding users' language when they make a choice Alternative question Did you mean easy on me or I gotta feeling? Direct reference easy on me, the first one Indirect reference could be used in natural and fluid conversation: cannot remember the name The pronunciations are hard to distinguish Want to specify a preference Indirect reference The newer one. The song that's not energetic. Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus</sample>
    <sample id="1201">Indirect Referring Expressions Goal: Understanding users' language when they make a choice Alternative question Did you mean easy on me or I gotta feeling? Direct reference easy on me, the first one Indirect reference could be used in natural and fluid conversation cannot remember the name The pronunciations are hard to distinguish Want to specify a preference Indirect reference The newer one. The song that's not energetic. Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus</sample>
    <sample id="1202">Indirect Referring Expressions Goal: Understanding users' language when they make a choice Alternative question Did you mean easy on me or I gotta feeling? Direct reference easy on me, the first one Indirect reference could be used in natural and fluid conversation cannot remember the name The pronunciations are hard to distinguish Want to specify a preference Indirect reference The newer one. The song that's not energetic. Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus</sample>
    <sample id="1203">Dataset Collection Important problem Conversational systems Benchmarking Large Language Models' entity understanding No large-scale public dataset available We collect a large dataset using crowd annotation Three domains:</sample>
    <sample id="1204">Dataset Collection. Important problem: Conversational systems, Benchmarking Large Language Models' entity understanding. No large-scale public dataset available. We collect a large dataset using crowd annotation. Three domains:</sample>
    <sample id="1205">Dataset Collection Methodology. Methodology emphasizes informality using a cartoon completion task. Sets the dialog context, chosen from a few manual prompts per domain. The alternative question. Expression referring to one of the entities. Filled in by the annotator.</sample>
    <sample id="1206">Dataset Collection Methodology. Methodology emphasizes informality using a cartoon completion task. Sets the dialog context, chosen from a few manual prompts per domain. The alternative question. Expression referring to one of the entities. Filled in by the annotator.</sample>
    <sample id="1207">Dataset Collection Methodology. Methodology emphasizes informality using a cartoon completion task. Sets the dialog context chosen from a few manual prompts per domain. The alternative question. Expression referring to one of the entities. Filled in by the annotator.</sample>
    <sample id="1208">Dataset Collection Methodology. Methodology emphasizes informality using a cartoon completion task. Sets the dialog context, chosen from a few manual prompts per domain. The alternative question. Expression referring to one of the entities. Filled in by the annotator.</sample>
    <sample id="1209">Dataset Collection Methodology. Methodology emphasizes informality using a cartoon completion task. Sets the dialog context, chosen from a few manual prompts per domain. The alternative question. Expression referring to one of the entities. Filled in by the annotator.</sample>
    <sample id="1210">Dataset Collection MethodologyMethodology emphasizes informality using a cartoon completion taskSets the dialog context, chosen from a few manual prompts per domain, The alternative question Expression referring to one of the entities Filled in by the annotator</sample>
    <sample id="1211">Generate alternative questions =&gt; sampling entity pairs.Do you mean A or B?Items with similar infoboxes on Wikipedia, same genre and/or artist.Do you mean 'This Is It' or 'Man in the Mirror'?Items with similar descriptions on Wikipedia.Do you mean 'Thinking of You' or 'Happy Anywhere'?Items with similar titles.Do you mean The Return, memoir, or The Return, Shatner novel?Uniform at random.Do you mean 'You Could Be Mine' or 'The Way I Am'?More Similar, usually harder.Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus.</sample>
    <sample id="1212">Generate alternative questions =&gt; sampling entity pairs.Do you mean A or B?Items with similar infoboxes on Wikipedia, same genre and/or artist.Do you mean 'This Is It' or 'Man in the Mirror'?Items with similar descriptions on Wikipedia.Do you mean 'Thinking of You' or 'Happy Anywhere'?Items with similar titles.Do you mean The Return, memoir, or The Return, Shatner novel?Uniform at random.Do you mean 'You Could Be Mine' or 'The Way I Am'?Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus.</sample>
    <sample id="1213">Generate alternative questions =&gt; sampling entity pairs.Do you mean A or B?Items with similar infoboxes on Wikipedia, same genre and/or artist.Do you mean 'This Is It' or 'Man in the Mirror'?Items with similar descriptions on Wikipedia.Do you mean 'Thinking of You' or 'Happy Anywhere'?Items with similar titles.Do you mean The Return, memoir, or The Return, Shatner novel?Uniform at random.Do you mean 'You Could Be Mine' or 'The Way I Am'?Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus.</sample>
    <sample id="1214">Generate alternative questions =&gt; sampling entity pairs.Do you mean A or B?Items with similar infoboxes on Wikipedia, same genre and/or artist.Do you mean 'This Is It' or 'Man in the Mirror'?Items with similar descriptions on Wikipedia.Do you mean 'Thinking of You' or 'Happy Anywhere'?Items with similar titles.Do you mean The Return, memoir, or The Return, Shatner novel?Uniform at random.Do you mean 'You Could Be Mine' or 'The Way I Am'?Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus.</sample>
    <sample id="1215">Generate alternative questions =&gt; sampling entity pairs.Do you mean A or B?Items with similar infoboxes on Wikipedia, same genre and/or artist.Do you mean 'This Is It' or 'Man in the Mirror'?Items with similar descriptions on Wikipedia.Do you mean 'Thinking of You' or 'Happy Anywhere'?Items with similar titles.Do you mean The Return, memoir, or The Return, Shatner novel?Uniform at random.Do you mean 'You Could Be Mine' or 'The Way I Am'?</sample>
    <sample id="1216">Background knowledge Music Google search link to each song. Easy on Me by Adele Click here to find out about the song. I Gotta Feeling by The Black Eyed Peas Click here to find out about the song We ask annotators to Listen to at least some of each song Read about each song Resolving Indirect Referring Expressions for Entity Selection AltEntities Corpus</sample>
    <sample id="1217">Background knowledge Music Google search link to each song. Easy on Me by Adele Click here to find out about the song. I Gotta Feeling by The Black Eyed Peas Click here to find out about the song We ask annotators to Listen to at least some of each song Read about each song Resolving Indirect Referring Expressions for Entity Selection AltEntities Corpus</sample>
    <sample id="1218">Background knowledge Music Google search link to each song. Easy on Me by Adele Click here to find out about the song. I Gotta Feeling by The Black Eyed Peas Click here to find out about the song We ask annotators to Listen to at least some of each song Read about each song</sample>
    <sample id="1219">Background knowledge Recipes Simnel Cake Pandan Cake Parag Simnel cake is a fruitcake widely eaten in the United Kingdom， Ireland and other countries with patterns of migration from them， associated with Lent and Easter. It is distinguished by layers of almond paste or marzipan， and a set of eleven balls made of the same paste. Pandan cake is a light， fluffy， green - coloured sponge cake flavoured with the juices of Pandanus amaryllifolius leaves. The cake is popular in Indonesia， Malaysia， and also the Netherlands， especially among the Indo community.</sample>
    <sample id="1220">Eliciting expressions. We then tell the annotators which choice should be selected and ask them to describe it. Pick this one. Easy on Me, by Adele. I Gotta Feeling, by the Black Eyed Peas. We would like you to give us 3 to 5 expressions for the chosen song to fill in your speech bubble. For example: The one with the piano music. The song that's not energetic. It has something about a river. The newer one. It's about not having time to choose. Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus.</sample>
    <sample id="1221">Eliciting expressions. We then tell the annotators which choice should be selected and ask them to describe it. Pick this one. Easy on Me, by Adele. I Gotta Feeling, by the Black Eyed Peas. We would like you to give us 3 to 5 expressions for the chosen song to fill in your speech bubble. For example: The one with the piano music. The song that's not energetic. It has something about a river. The newer one. It's about not having time to choose. Random Examples. Music Selection. Do you mean 'Chime' or 'Your Loving Arms'? The one without words. Do you mean 'These Kids' or 'Inescapable'? It is the song sung by an Australian. Do you mean 'Rock the Boat' or 'Wherever You Are'? It has synthesizer sounds in it. Do you mean 'Telepathy' or 'Stars on 45'? Came out in mid of 2000. Do you mean 'Mis-Shapes' or 'Remind Me'? Based on life experienced in Sheffield. Book Selection. Do you mean 'Warlock, Hall novel' or 'Warlock, Smith novel'? The one that is set in the</sample>
    <sample id="1222">AltEntities Corpus.- ~6,000 alternative questions across the three domains.- ~42,000 indirect referring expressions.- Results with T5 XL model, accuracy:.- 92-95% if the LM has access to the same background knowledge as annotators.- 82%-87% when the the LM has access to partially overlapping background knowledge.- ~60% when the LM, T5 XL, has only access to the entity names.- We showed models are domain-generalizable.- Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1223">AltEntities Corpus.- ~6,000 alternative questions across the three domains.- ~42,000 indirect referring expressions.- Results with T5 XL model, accuracy:.- 92-95% if the LM has access to the same background knowledge as annotators.- 82%-87% when the the LM has access to partially overlapping background knowledge.- ~60% when the LM, T5 XL, has only access to the entity names.- We showed models are domain-generalizable.- Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1224">AltEntities Corpus
- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions
- Results with T5 XL model, accuracy:
  - 92-95% if the LM has access to the same background knowledge as annotators.
  - 82%-87% when the the LM has access to partially overlapping background knowledge.
  - ~60% when the LM, T5 XL, has only access to the entity names.
  - We showed models are domain-generalizable.
- Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1225">AltEntities Corpus
- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions
- Results with T5 XL model, accuracy:
  - 92-95% if the LM has access to the same background knowledge as annotators.
  - 82%-87% when the the LM has access to partially overlapping background knowledge.
  - ~60% when the LM, T5 XL, has only access to the entity names.
  - We showed models are domain-generalizable.
- Dataset Link: https://github.com/google-research-datasets/AltEntities
- Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus
- Google Research
- P 11
- Thank You!
  - If you have any questions, please email javadh@google.com</sample>
    <sample id="1226">CamemBERT is initially trained on 4GB of data. If you want to know more about the training process or the data sources, feel free to ask.</sample>
    <sample id="1227">The name of the speaker is Adam Przepiórkowski.</sample>
    <sample id="1228">The findings that performance degrades with larger temporal gap led to the conclusion that temporal drift is the main cause of performance loss. If you have any other questions about this, feel free to ask.</sample>
    <sample id="1229">NLPositionality: Characterizing Design Biases of Datasets and Models.</sample>
    <sample id="1230">NLPositionality: Characterizing Design Biases of Datasets and Models Sebastin Santy* University of Washington Jenny T. Liang* Carnegie Mellon University Ronan Le Bras Allen Institute for AI Katharina Reinecke University of Washington Maarten Sap Carnegie Mellon University</sample>
    <sample id="1231">Imagine...</sample>
    <sample id="1232">Imagine...</sample>
    <sample id="1233">Imagine.</sample>
    <sample id="1234">Imagine... Design bias example! Can you stop being a jerk? 👎: 0.82 ✅ Presstitutes everywhere on the news. 👎: 0.33 ❌ Carl Jones Tech Lead, New York Times Aditya Sharma Tech Lead, Times of India 📈 = PerspectiveAPI score</sample>
    <sample id="1235">Positionality "The perspectives people hold as a result of their demographics, identity, and life experiences."</sample>
    <sample id="1236">Positionality.The perspectives people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="1237">Positionality.The perspectives people hold as a result of their demographics, identity, and life experiences.As a researcher, it influences the research process and its outcomes and results.</sample>
    <sample id="1238">[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.，[2] Yin et al. "GEOMLAMA: Geo - Diverse Commonsense Probing on Multilingual Pre - Trained Language Models." EMNLP 2022.，[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1239">[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.，[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.，[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1240">Do datasets and models have positionality?Anecdotal evidence:Model and dataset probing, Theoretical definitions of model positionality[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1241">Do datasets and models have positionality?Anecdotal evidence:.- Model and dataset probing, 1, 2, - Theoretical definitions of model positionality, 3, [1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre - Trained Language Models." EMNLP 2022.[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1242">Do datasets and models have positionality?Anecdotal evidence:.- Model and dataset probing, 1, 2, - Theoretical definitions of model positionality, 3, [1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre - Trained Language Models." EMNLP 2022.[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1243">Do datasets and models have positionality?Anecdotal evidence:.- Model and dataset probing, 1, 2, - Theoretical definitions of model positionality, 3, [1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre - Trained Language Models." EMNLP 2022.[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1244">Question: Do datasets and models have positionality? Goal: Compare annotations from users with existing datasets and models.</sample>
    <sample id="1245">NLPositionality A framework for characterizing design biases in NLP datasets and models</sample>
    <sample id="1246">Collection: 300 instances are sampled from a dataset. Each instance has an associated gold label. Processing: Instances are sent as part of a study on LITW. Annotations from people around the world. The received annotations are compared against the gold labels from the dataset and predictions obtained from the models. Analysis: Pearson's r correlation is measured between gold labels, model predictions and annotations for each of the demographics separately.</sample>
    <sample id="1247">Collection: 300 instances are sampled from a dataset. Each instance has an associated gold label. Processing: Instances are sent as part of a study on LITW. Annotations from people around the world. The received annotations are compared against the gold labels from the dataset and predictions obtained from the models. Analysis: Pearson's r correlation is measured between gold labels, model predictions and annotations for each of the demographics separately.</sample>
    <sample id="1248">Framework.</sample>
    <sample id="1249">Framework. Collection: 300 instances are sampled from a dataset. Each instance has an associated gold label. Processing: Instances are sent as part of a study on LITW. Annotations from people around the world. Model Predictions. Analysis: Pearson's r correlation is measured between gold labels, model predictions and annotations for each of the demographics separately.</sample>
    <sample id="1250">Collection: 300 instances are sampled from a dataset. Each instance has an associated gold label. Processing: The received annotations are compared against the gold labels from the dataset and predictions obtained from the models. Analysis: Pearson's r correlation is measured between gold labels, model predictions and annotations for each of the demographics separately.</sample>
    <sample id="1251">Collection: 300 instances are sampled from a dataset. Each instance has an associated gold label. Processing: The received annotations are compared against the gold labels from the dataset and predictions obtained from the models. Analysis: Pearson's r correlation is measured between gold labels, model predictions and annotations for each of the demographics separately.</sample>
    <sample id="1252">LabintheWild.</sample>
    <sample id="1253">LabintheWild
Our Experiments Findings Data Sets Blog For Researchers About Us English
5,376,396 total participants
Pool of diverse volunteers / research participants
Online experiment from researchers
Could you live with an AI and its morals? Tell us your moral judgments on certain situations and we will show you how you compare to others' and an AI.
Are you better than an AI in noticing hateful speech? Rate what speech is hateful and we'll show you how well you detect hateful speech compared to an AI and others.
Where are you on the techno-skeptic to techno-utopian scale? Tell us how you think future mixed reality technology will affect your personal life, we will show you whether you are more techno-skeptic or techno-utopian.
Participate now!
Participate now!
Participate now!</sample>
    <sample id="1254">Task A: Social Acceptability.</sample>
    <sample id="1255">Task A: Social Acceptability.</sample>
    <sample id="1256">Task A: Social Acceptability Analysis Datasets - Social Chemistry Models - Delphi - GPT-4</sample>
    <sample id="1257">Task B: Toxicity. Participants read an instance from the Dynahate dataset. Participants rate whether they think an instance is hate speech. 1) Read the example: English people smell like sour milk. 2) Enter what you think about it. Do you think this is hateful speech? Yes, No, Not sure. Feel free to explain your rating. Enter a short description. Submit. 3) See what others thought about it! The AI speculates: I speculate that this is hateful speech. Looks like we agree! Study participants in Afghanistan said: Not Hateful, Not Sure, Hateful.</sample>
    <sample id="1258">Task B: Toxicity Analysis Datasets - Dynahate Models - Perspective API - Rewire API - Hate RoBERTa - GPT-4 Study Participation 16,299 annotations 1,096 annotators 87 countries</sample>
    <sample id="1259">Finding 1: There is positionality in NLP.</sample>
    <sample id="1260">Datasets and models are most aligned to English-Speaking countries.</sample>
    <sample id="1261">Datasets and models are most aligned to people with a college education.</sample>
    <sample id="1262">Datasets and models are most aligned to people with a college education.</sample>
    <sample id="1263">Finding 2: Some populations are left behind.</sample>
    <sample id="1264">Social Acceptability, GPT-4, Datasets and models are less aligned to non-binary people. Man N=4,082 0.69*, Non-binary N=858 0.55*, Woman N=4,368 0.73*, Hate Speech Toxicity, Dynahate, Datasets and models are less aligned to non-binary people. Man N=1,798 0.65*, Non-binary N=329 0.58*, Woman N=2,357 0.63*,</sample>
    <sample id="1265">So, what can we do? Addressing positionality in NLP</sample>
    <sample id="1266">1. Keep a record of all relevant design choices made throughout building datasets or models. 2. Do NLP research through the lens of perspectivism:. a. Share disaggregated dataset labels! b. Use modeling techniques that can handle annotator disagreement.</sample>
    <sample id="1267">Recommendations. 1. Keep a record of all relevant design choices made throughout building datasets or models. 2. Do NLP research through the lens of perspectivism: a. Share disaggregated dataset labels! b. Use modeling techniques that can handle annotator disagreement. 3. Building specialized datasets and models with and for specific communities is valuable for inclusive NLP, e.g., Masakhane initiative.</sample>
    <sample id="1268">Thanks!Dashboard Link: nlpositionality.cs.washington.edu/Paper: bit.ly/NLPositionality-Paper/Delphihttps://delechi.allenai.org/</sample>
    <sample id="1269">Well, you see, permuting the tokens for the output sequence is necessary because it helps in generating a more diverse and accurate output. It allows the model to explore different possible arrangements of the tokens, which can lead to better understanding and representation of the data. This is especially important in tasks like machine translation or text generation where the order of words matters a great deal. So, it's all about improving the quality and versatility of the output. If you have any more questions about this or anything else, feel free to ask!</sample>
    <sample id="1270">Well, it's because transparency about bias mitigation methods helps in understanding how the model is being made fair. It allows others to see the steps taken to reduce bias, which is really important for building trust. And it also helps in improving the model further. So, yeah, that's why they recommended it. What do you think about this?</sample>
    <sample id="1271">In BLiMP, "Many people were helping themselves." and "Many people were helping herself." are minimal-pair unacceptable inputs. In SyntaxGym, "No customer has spent any money." and "The customer has spent any money." are minimal-pair unacceptable inputs. In Crows, "Stereotypical sentence." and "Non-stereotypical sentence." are minimal-pair unacceptable inputs. If you want to know more about this, feel free to ask me.</sample>
    <sample id="1272">The authors used F1, CLS, NER, POS, Hamming, and EMR as evaluation metrics. If you want to know more about these metrics or have other questions, feel free to ask.</sample>
    <sample id="1273">Krippendorff's Alpha.</sample>
    <sample id="1274">Wikipedia.</sample>
    <sample id="1275">Heinrich Heine University Düsseldorf, Germany. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="1276">MultiInstruct has a large-scale, publicly - available multimodal instruction dataset. Other benchmarks may not have this. If you want to know more about it, feel free to ask me.</sample>
    <sample id="1277">There are three authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="1278">Binary coordination is when two elements are coordinated together. It's a basic form of coordination in linguistics. If you want to know more about it, like how it's used in different languages, just let me know.</sample>
    <sample id="1279">The image doesn't provide information about the average length of the prompts used in the study. So, I can't answer that question based on this picture. If you have any other questions about the image or the study, feel free to ask.</sample>
    <sample id="1280">The smaller T5 model fine - tuned on Coscript can generate higher quality scripts than LLMs. Well, that's the main implication. If you want to know more about how it compares in other aspects, just let me know.</sample>
    <sample id="1309">The learning strategies investigated are "From scratch with full model construction" and "Continual pre-training using an existing pre-trained model." If you want to know more about these strategies, feel free to ask.</sample>
    <sample id="1310">No diminishing returns.</sample>
    <sample id="1311">The quality was evaluated using SARI, BLEU, BS-P, and FRE.</sample>
    <sample id="1312">Yes, they do.</sample>
    <sample id="1347">Cognitive dissonance is the state of having two elements of cognition, like thoughts, actions, or beliefs, that are inconsistent. It's when there's a conflict between what you think, do, or believe. If you want to know more about how it affects people, just let me know.</sample>
    <sample id="1348">GPT-J. If you have any other questions about language models or anything else, feel free to ask!</sample>
    <sample id="1349">No, iterative training performs better than cumulative in active learning according to the chart. If you have more questions about this, feel free to ask.</sample>
    <sample id="1350">The speaker's name is Sara Papi. If you want to know more about her or the topic, feel free to ask.</sample>
    <sample id="1351">The data was taken from the TED talk corpus. If you want to know more about the MuDa benchmark or the TED talk corpus, feel free to ask.</sample>
    <sample id="1352">Conjunct Lengths in English, Dependency Length Minimization, and Dependency Structure of Coordination. Adam Przepiórkowski and Michał Woźniak. Institute of Computer Science, Polish Academy of Sciences, ul. Jana Kazimierza 5, 01-248 Warsaw. UNIVERSITY OF WARSAW. ACL 2023.</sample>
    <sample id="1353">Bouquet/Stanford, Universal Dependencies, Homer loves Lisa, Bart, and Maggie. Chain/Moscow, Homer loves Lisa, Bart, and Maggie. Conjunction-headed/Prague, Homer loves Lisa, Bart, and Maggie. Multi-headed/London, Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1354">Bouquet/Stanford, Universal Dependencies, Homer loves Lisa, Bart, and Maggie. Chain/Moscow, Homer loves Lisa, Bart, and Maggie. Conjunction-headed/Prague, Homer loves Lisa, Bart, and Maggie. Multi-headed/London, Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1355">Bouquet/Stanford, Universal Dependencies, Homer loves Lisa, Bart, and Maggie. Chain/Moscow, Homer loves Lisa, Bart, and Maggie. Conjunction-headed/Prague, Homer loves Lisa, Bart, and Maggie. Multi-headed/London, Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1356">Bouquet/Stanford, Universal Dependencies, Homer loves Lisa, Bart, and Maggie. Chain/Moscow, Homer loves Lisa, Bart, and Maggie. Conjunction-headed/Prague, Homer loves Lisa, Bart, and Maggie. Multi-headed/London, Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1357">Bouquet/Stanford, Universal Dependencies, Homer loves Lisa, Bart, and Maggie. Chain/Moscow, Homer loves Lisa, Bart, and Maggie. Conjunction-headed/Prague, Homer loves Lisa, Bart, and Maggie. Multi-headed/London, Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1358">Bouquet/Stanford, Universal Dependencies, Homer loves Lisa, Bart, and Maggie. Chain/Moscow, Homer loves Lisa, Bart, and Maggie. Conjunction-headed/Prague, Homer loves Lisa, Bart, and Maggie. Multi-headed/London, Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1359">Bouquet/Stanford, Universal Dependencies, Homer loves Lisa, Bart, and Maggie. Chain/Moscow, Homer loves Lisa, Bart, and Maggie. Conjunction-headed/Prague, Homer loves Lisa, Bart, and Maggie. Multi-headed/London, Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1360">Bouquet/Stanford, Universal Dependencies, Homer loves Lisa, Bart, and Maggie. Chain/Moscow, Homer loves Lisa, Bart, and Maggie. Conjunction-headed/Prague, Homer loves Lisa, Bart, and Maggie. Multi-headed/London, Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1361">Dependency Length Minimization, DLM, Word order tends to minimize dependency lengths.</sample>
    <sample id="1362">Dependency Length Minimization, DLM, Word order tends to minimize dependency lengths.</sample>
    <sample id="1363">Word order tends to minimize dependency lengths:.- Marge read it yesterday. good.- Marge read yesterday it. bad.- Marge read this absolutely fascinating book about bees yesterday. good.- Marge read yesterday this absolutely fascinating book about bees. good.</sample>
    <sample id="1364">Word order tends to minimize dependency lengths:.- Marge read it yesterday. good.- Marge read yesterday it. bad.- Marge read this absolutely fascinating book about bees yesterday. good.- Marge read yesterday this absolutely fascinating book about bees. good.</sample>
    <sample id="1365">Word order tends to minimize dependency lengths:.- Marge read it yesterday. good.- Marge read yesterday it. bad.- Marge read this absolutely fascinating book about bees yesterday. good.- Marge read yesterday this absolutely fascinating book about bees. good.</sample>
    <sample id="1366">Dependency Length Minimization, DLM, Word order tends to minimize dependency lengths. Good: Marge read it yesterday. Bad: Marge read yesterday it. Good: Marge read this absolutely fascinating book about bees yesterday. Good: Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="1367">Word order tends to minimize dependency lengths:.- Marge read it yesterday. good.- Marge read yesterday it. bad.- Marge read this absolutely fascinating book about bees yesterday. good.- Marge read yesterday this absolutely fascinating book about bees. good.</sample>
    <sample id="1368">Word order tends to minimize dependency lengths:.- Marge read it yesterday. good.- Marge read yesterday it. bad.- Marge read this absolutely fascinating book about bees yesterday. good.- Marge read yesterday this absolutely fascinating book about bees. good.</sample>
    <sample id="1369">Word order tends to minimize dependency lengths:.- Marge read it yesterday. good.- Marge read yesterday it. bad.- Marge read this absolutely fascinating book about bees yesterday. good.- Marge read yesterday this absolutely fascinating book about bees. good.</sample>
    <sample id="1370">Dependency Length Minimization, DLM, Word order tends to minimize dependency lengths.</sample>
    <sample id="1371">Word order tends to minimize dependency lengths:.- Marge read it yesterday. good.- Marge read yesterday it. bad.- Marge read this absolutely fascinating book about bees yesterday. good.- Marge read yesterday this absolutely fascinating book about bees. good.</sample>
    <sample id="1372">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank, Marcus et al. 1993, Ficler and Goldberg 2016, left conjuncts tend to be shorter, observed before, this tendency grows with length difference, briefly noticed in Gibson et al. 1996: 88-90, but only when the governor is on the left or absent, I saw Bart and Lisa, Homer came and sneezed, not when it is on the right, Ted and Ned laughed.</sample>
    <sample id="1373">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank, Marcus et al. 1993, Ficler and Goldberg 2016, left conjuncts tend to be shorter, observed before, this tendency grows with length difference, briefly noticed in Gibson et al. 1996: 88–90, but only when the governor is on the left or absent, I saw Bart and Lisa; Homer came and sneezed, not when it is on the right, Ted and Ned laughed.</sample>
    <sample id="1374">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank, Marcus et al. 1993, Ficler and Goldberg 2016, left conjuncts tend to be shorter, observed before, this tendency grows with length difference, briefly noticed in Gibson et al. 1996: 88-90, but only when the governor is on the left or absent, I saw Bart and Lisa; Homer came and sneezed, not when it is on the right, Ted and Ned laughed.</sample>
    <sample id="1375">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank, Marcus et al. 1993, Ficler and Goldberg 2016: left conjuncts tend to be shorter, observed before, this tendency grows with length difference, briefly noticed in Gibson et al. 1996: 88-90, but only when the governor is on the left or absent, I saw Bart and Lisa; Homer came and sneezed, not when it is on the right, Ted and Ned laughed.</sample>
    <sample id="1376">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank, Marcus et al. 1993, Ficler and Goldberg 2016, left conjuncts tend to be shorter, observed before, this tendency grows with length difference, briefly noticed in Gibson et al. 1996: 88-90, but only when the governor is on the left or absent, I saw Bart and Lisa, Homer came and sneezed, not when it is on the right, Ted and Ned laughed.</sample>
    <sample id="1377">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank, Marcus et al. 1993, Ficler and Goldberg 2016, left conjuncts tend to be shorter, observed before, this tendency grows with length difference, briefly noticed in Gibson et al. 1996: 88-90, but only when the governor is on the left or absent, I saw Bart and Lisa, Homer came and sneezed, not when it is on the right, Ted and Ned laughed.</sample>
    <sample id="1378">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank, Marcus et al. 1993, Ficler and Goldberg 2016: left conjuncts tend to be shorter, observed before, this tendency grows with length difference, briefly noticed in Gibson et al. 1996: 88-90, but only when the governor is on the left or absent, I saw Bart and Lisa; Homer came and sneezed, not when it is on the right, Ted and Ned laughed.</sample>
    <sample id="1379">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank Marcus et al. 1993 Ficler and Goldberg 2016 left conjuncts tend to be shorter observed before this tendency grows with length difference briefly noticed in Gibson et al. 1996 88 90 but only when the governor is on the left or absent I saw Bart and Lisa Homer came and sneezed not when it is on the right Ted and Ned laughed</sample>
    <sample id="1380">Figure 1: Proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths, with confidence bands.</sample>
    <sample id="1381">NO governor, length in CHARACTERS, slope: 3.99e-03, p: 1.36e-13, NO governor, length in SYLLABLES, slope: 1.25e-02, p: 1.86e-13, NO governor, length in WORDS, slope: 2.42e-02, p: 2.42e-16, Governor on the LEFT, length in CHARACTERS, slope: 5.57e-03, p: 2.6e-29, Governor on the LEFT, length in SYLLABLES, slope: 1.72e-02, p: 1.65e-27, Governor on the LEFT, length in WORDS, slope: 2.57e-02, p: 7.10e-15, Governor on the RIGHT, length in CHARACTERS, slope: 1.22e-03, p: 0.25, Governor on the RIGHT, length in SYLLABLES, slope: 2.21e-0</sample>
    <sample id="1382">Figure 1: Proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths, with confidence bands.</sample>
    <sample id="1383">Compatibility with Dependency Structures of Coordination.Bouquet/Stanford, Universal Dependencies, Homer loves Lisa, Bart, and Maggie, NO.Chain/Moscow, Homer loves Lisa, Bart, and Maggie, NO.Conjunction-headed/Prague, Homer loves Lisa, Bart, and Maggie, YES.Multi-headed/London, Homer loves Lisa, Bart, and Maggie, YES.</sample>
    <sample id="1384">See the paper for the full argument! Talk to us at the poster session!</sample>
    <sample id="1385">Matthias Lindemann.</sample>
    <sample id="1386">Cross-lingual transfer is training on one source language and then transferring to another language. If you want to know more about it, feel free to ask.</sample>
    <sample id="1387">Dawei Zhu and Marius Mosbach are from Saarland University, Xiaoyu Shen is from Amazon Alexa, Andreas Stephan is from the University of Vienna, and Dietrich Klakow is also from Saarland University.</sample>
    <sample id="1388">The authors use BLEU as a quality measure and AL / AL - CA as a latency measure. If you want to know more about these measures, feel free to ask.</sample>
    <sample id="1416">Trees need to be obtained through pre/post - processing logical forms and grammar - induction. Well, that's about it. If you want to know more about this, feel free to ask me.</sample>
    <sample id="1417">The authors are affiliated with the School of Interactive Computing at Georgia Institute of Technology.</sample>
    <sample id="1495">ABC-Eval stands for Annotating Behaviors in Chat. If you have any other questions about it, feel free to ask.</sample>
    <sample id="1496">2010.</sample>
    <sample id="1527">The affiliations are The University of Edinburgh, Saarland University, and the University of Amsterdam. If you want to know more about these institutions or the paper, feel free to ask.</sample>
    <sample id="1528">The speaker's name is not mentioned in the image.</sample>
    <sample id="1529">There are five authors involved in the paper. If you want to know more about the paper or the authors, feel free to ask.</sample>
    <sample id="1530">The approach is compared to a state of the art architecture specifically tailored for SimulST.</sample>
    <sample id="1531">MULTIINSTRUCT: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning. Zhiyang Xu*, Ying Shen*, Lifu Huang. Department of Computer Science, Virginia Tech. *Equal Contribution.</sample>
    <sample id="1532">Pre-trained Language Models for Downstream Tasks, Figure 2: Comparing instruction tuning with pretrain finetune and prompting.</sample>
    <sample id="1533">Pre-trained Language Models for Downstream Tasks, Figure 2: Comparing instruction tuning with pretrain finetune and prompting.</sample>
    <sample id="1534">Language-only</sample>
    <sample id="1535">Instruction Tuning on Multimodal Pre-trained Models</sample>
    <sample id="1536">Imbalance in Instructional Datasets between NLP and Multimodal. 1600+ Language-only instruction tasks.</sample>
    <sample id="1537">Imbalance in Instructional Datasets between NLP and Multimodal. 1600+ Language-only instruction tasks. NO large-scale, publicly-available multimodal instruction tasks.</sample>
    <sample id="1538">- 62 diverse multimodal tasks
- 10 broad groups
- 5 expert-written instructions</sample>
    <sample id="1539">- 62 diverse multimodal tasks
- 10 broad groups
- 5 expert-written instructions</sample>
    <sample id="1540">OFA, One For All, A unified multi-modal pre-trained model that is capable of performing both understanding and generation tasks with single or multiple modalities. OFA has a unified vocabulary for language, image tokens and the coordinates of a bounding box.</sample>
    <sample id="1541">MULTINSTRUCT Grounded Caption Input: Generate a caption for &lt;bin 198&gt; &lt;bin 32&gt; &lt;bin 400&gt; &lt;bin 193&gt;. Output: blue and white tennis racquet Text Localization Input: Select the region that contains the text "den". Options: &lt;bin 206&gt; &lt;bin 119&gt; &lt;bin 448&gt; &lt;bin 181&gt; ||||&lt;bin 357&gt; &lt;bin 518&gt; &lt;bin 456&gt; &lt;bin 574&gt; ||||&lt;bin 229&gt; &lt;bin 604&gt; &lt;bin 304&gt; &lt;bin 654&gt; Referring Expression Selection Input: Select the region of the object described by "A blue train in the front." Options: &lt;bin 242&gt; &lt;bin 180&gt; &lt;bin 736&gt; &lt;bin 475&gt; ||||&lt;bin 398&gt; &lt;bin 88&gt; &lt;bin 291&gt; &lt;bin 203&gt; &lt;bin 339&gt; &lt;bin 247&gt; &lt;bin 193&gt; &lt;bin</sample>
    <sample id="1542">MULTINSTRUCT Grounded Caption Input: Generate a caption for &lt;bin 198&gt; &lt;bin 32&gt; &lt;bin 400&gt; &lt;bin 193&gt;. Output: blue and white tennis racquet Text Localization Input: Select the region that contains the text "den". Options: &lt;bin 206&gt; &lt;bin 119&gt; &lt;bin 181&gt; &lt;bin 448&gt; &lt;bin 357&gt; &lt;bin 518&gt; &lt;bin 456&gt; &lt;bin 574&gt; &lt;bin 229&gt; &lt;bin 604&gt; &lt;bin 304&gt; &lt;bin 654&gt; Output: &lt;bin 229&gt; &lt;bin 604&gt; &lt;bin 304&gt; &lt;bin 654&gt; Referring Expression Selection Input: Select the region of the object described by "A blue train in the front." Options: &lt;bin 242&gt; &lt;bin 180&gt; &lt;bin 736&gt; &lt;bin 475&gt; &lt;bin 88&gt; &lt;bin 291&gt; &lt;bin 203&gt; &lt;bin 473&gt;</sample>
    <sample id="1543">MULTINSTRUCT Grounded Caption Input: Generate a caption for &lt;bin 198&gt; &lt;bin 32&gt; &lt;bin 400&gt; &lt;bin 193&gt;. Output: blue and white tennis racquet Text Localization Input: Select the region that contains the text "den". Options: &lt;bin 206&gt; &lt;bin 119&gt; &lt;bin 448&gt; &lt;bin 181&gt; ||||&lt;bin 357&gt; &lt;bin 518&gt; &lt;bin 456&gt; &lt;bin 574&gt; ||||&lt;bin 229&gt; &lt;bin 604&gt; &lt;bin 304&gt; &lt;bin 654&gt; Referring Expression Selection Input: Select the region of the object described by "A blue train in the front." Options: &lt;bin 242&gt; &lt;bin 180&gt; &lt;bin 736&gt; &lt;bin 475&gt; ||||&lt;bin 88&gt; &lt;bin 291&gt; &lt;bin 203&gt; &lt;bin 193&gt; &lt;bin 339&gt; &lt;bin 247&gt; &lt;bin 442&gt; Question-Image</sample>
    <sample id="1544">Multi-modal Instruction Tuning</sample>
    <sample id="1545">Multi-Modal Instruction Turning
Training Dataset Construction:
Use 53 tasks from 9 groups for training.
Sample 10,000 instances per task.
Testing Dataset Construction:
Reserve the entire Commonsense Reasoning group for testing.
Select additional 5 tasks from VQA and Miscellaneous groups.
We use all the instances in the test split for each task.
Randomly sample 20 tasks from the test split of Natural Instructions dataset as unseen tasks for NLP.</sample>
    <sample id="1546">Multi-Modal Instruction Turning.Training Dataset Construction:.- Use 53 tasks from 9 groups for training.- Sample 10, 000 instances per task.Testing Dataset Construction:.- Reserve the entire Commonsense Reasoning group for testing.- Select additional 5 tasks from VQA and Miscellaneous groups.- We use all the instances in the test split for each task.- Randomly sample 20 tasks from the test split of Natural Instructions dataset as unseen tasks for NLP.</sample>
    <sample id="1547">Implementation Details.Training details:.- Pre-trained OFA-Large model, 472M,.- Mix all the instances for all tasks.- Each instance is randomly combined with one of its five instruction templates.Testing details:.- For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.- We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1548">Implementation Details.Training details:.- Pre-trained OFA-Large model, 472M,.- Mix all the instances for all tasks.- Each instance is randomly combined with one of its five instruction templates.Testing details:.- For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.- We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1549">Implementation Details.Training details:.- Pre-trained OFA-Large model, 472M,.- Mix all the instances for all tasks.- Each instance is randomly combined with one of its five instruction templates.Testing details:.- For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.- We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1550">Evaluation Metrics
- For multi-modal classification tasks, Visual Entailment, Visual Spatial Reasoning, Natural Language Visual Reasoning, and Disaster Type Classification, we report the Accuracy.
- For multi-modal generation tasks, Commonsense VQA, Text VQA, Grounded VQA, Visual Text Extraction, and Visual Dialogue, we report the Rouge-L.
- For NLP tasks, we report Rouge-L.
- We also compute the aggregated performance for each model based on the mean of the model's performance on all multimodal and NLP unseen tasks. We use Rouge-L as the performance score for most tasks, and Accuracy for tasks that only have accuracy as a metric.</sample>
    <sample id="1551">Sensitivity. How sensitive the model is towards to variety of instructions for the same task:. Ability to consistently produce the same results for the same task, regardless of slight variations in the wording of instructions.</sample>
    <sample id="1552">Effectiveness of Instruction Tuning on MULTIINSTRUCT</sample>
    <sample id="1553">Effectiveness of Instruction Tuning on MULTIINSTRUCT</sample>
    <sample id="1554">Impact of Increasing Multimodal Instruction Task Clusters
- Img Und
  - VQA + Image Understanding
- Grounding
  - Grounded Matching + Grounded Generation
- MISC, ITM
  - Temporal Ordering + Miscellaneous + Image Text Matching
- Relation
  - Visual Relationship
- Region
  - Region Understanding
- NLP
  - NLP tasks
Figure 3: Model Performance as the multimodal Instruction Task Clusters</sample>
    <sample id="1555">Effect of Diverse Instructions on Instruction Tuning
- OFA finetuned on 5 instructions achieves much higher aggregated performance on all evaluation tasks and shows lower sensitivity.
Table 3: Effect of Different Number of Instructions. Performance of OFA_MultiInstruct finetuned on different numbers of instructions.</sample>
    <sample id="1556">Effect of Fine-tuning Strategies on Model Sensitivity
- Instruction tuning on MultiInstruct can significantly reduce the sensitivity of OFA.
- Transfer learning from Natural Instructions dataset can further reduce the sensitivity of the model.
Figure 4: Model Sensitivity on Unseen Evaluation Tasks. Lower is better.</sample>
    <sample id="1557">Zero-Shot Performance on NLP Tasks
- Instruction Tuning on MultiInstruct can improve zero-shot performance on unseen NLP tasks.
- The transfer learning strategy MixedInstruct can best preserve the zero-shot capability gained on Natural Instructions dataset.
Model
RougeL
OFA
2.25
OFA MultiInstruct
12.18
Transfer Learning from NATURAL INSTRUCTIONS
OFA NaturalInstruct
43.61
OFA MixedInstruct
43.32
OFA SeqInstruct
30.79
Table 4: Zero-shot Performance on NLP tasks. The performance is reported in Rouge-L and the best performance is in bold.</sample>
    <sample id="1558">Conclusion.First large-scale multi-modal instruction tuning dataset.Contains 62 multi-modal tasks from 10 broad categories.Significantly improve the zero-shot capability of OFA via instruction tuning.Explore several transferring learning techniques and show their benefits.Design a new metric sensitivity.</sample>
    <sample id="1559">One More Thing! We are collecting a much larger multimodal instruction tuning dataset with around 150 additional vision-language tasks and we will release them soon!</sample>
  </task>
</testset>