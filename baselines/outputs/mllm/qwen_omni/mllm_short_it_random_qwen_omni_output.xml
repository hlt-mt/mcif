<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="it">
    <sample id="0">Le principali fonti di dati per i modelli linguistici sono le grandi risorse web, come Google Patents, Wikipedia, e siti notiziari come The New York Times, Los Angeles Times, The Guardian, e Huffington Post. Se hai altre domande su questo argomento, sentiti libero di chiedere!</sample>
    <sample id="1">I primi due autori, Akshatha Arodi e Martin Pömsl, sono affiliati a McGill University/Mila. Adam Trischler è affiliato a Microsoft Research. Le altre due autrici, Alexandra Olteanu e Jackie CK Cheung, sono anch'esse affiliate a McGill University/Mila.</sample>
    <sample id="2">Ciao! Benvenuti alla nostra presentazione di DEPLAIN, un nuovo corpus per la semplificazione del testo tedesco a livello di documento e a livello di frase.</sample>
    <sample id="3">Il contenuto è già in italiano. Se hai bisogno di qualcosa di diverso, fammi sapere!</sample>
    <sample id="4">La semplificazione del testo è un processo di adattamento di un testo per migliorare la comprensione del testo per un gruppo di destinazione specifico, come persone con problemi di lettura o non madrelingua.</sample>
    <sample id="5">Per addestrare un modello di semplificazione del testo, abbiamo bisogno di coppie parallele di testo, ad esempio documenti o frasi parallele.</sample>
    <sample id="6">Ecco il contenuto in italiano: "Ecco un esempio di una coppia di frasi parallele di una frase tedesca complessa e la sua traduzione in italiano semplice."</sample>
    <sample id="7">Per semplificare la frase, ci sono diverse tecniche possibili, come la sostituzione lessicale, la cancellazione di clausole, la ridistribuzione delle parole, la cancellazione di parole o l'aggiunta di parole.</sample>
    <sample id="8">Ora proponiamo il nostro nuovo corpus, DE-plain, perché negli ultimi anni ci sono stati alcuni problemi con i corpi esistenti. Ad esempio, questi corpi sono troppo piccoli per addestrare un modello di semplificazione del testo.</sample>
    <sample id="9">I tre modelli proposti negli ultimi anni sono tutti allineati automaticamente, il che significa che possono essere più soggetti a errori nell'allineamento.</sample>
    <sample id="10">Quindi proponiamo il nostro nuovo corpus DEplain, diviso in due sottocorpus: DEplain-APA e DEplain-web. DEplain-APA si basa su testi di notizie.</sample>
    <sample id="11">Nel DEplain-APA abbiamo allineato 483 documenti tutti manualmente. Ciò porta a circa 30.000 coppie di frasi paralleli.</sample>
    <sample id="12">Per il corpus DEplain-web, questo corpus include diversi domini e abbiamo anche allineato tutti questi 756 documenti sia manualmente che con metodi di allineamento automatico.</sample>
    <sample id="13">In totale, abbiamo ottenuto 30.450 coppie di frasi.</sample>
    <sample id="14">Abbiamo analizzato le nostre coppie di frasi un po' di più. Ad esempio, per il tipo di semplificazione.</sample>
    <sample id="15">Come puoi vedere qui, il testo della Bibbia è molto più semplificato rispetto, ad esempio, al testo notiziario o al testo di apprendimento della lingua.</sample>
    <sample id="16">Per esempio, semplificazione lessicale, semplificazione strutturale e livello complessivo di semplificazione.</sample>
    <sample id="17">Inoltre, si può vedere che il nostro corpus DEplain ha una varietà elevata di diverse trasformazioni di semplificazione. Ad esempio, nel corpus DEplain-apa abbiamo molto più riordinamenti e aggiunte di parole rispetto al corpus DEplain-web.</sample>
    <sample id="18">D'altra parte, nel corpus web abbiamo molto più riformulazioni.</sample>
    <sample id="19">Certo! Ecco la versione italiana del contenuto: "Quindi vediamo ora cosa possiamo fare con questo corpus. Ciao, sono Omar e ora parlerò dei casi d'uso del nostro dataset. Per il primo caso d'uso, possiamo valutare i metodi di allineamento automatico." Se hai bisogno di ulteriori modifiche o hai altre domande, fammi sapere!</sample>
    <sample id="20">In recenti anni ci sono state molte metodologie di allineamento, ma nel contesto della traduzione automatica.</sample>
    <sample id="21">Se hai due documenti paralleli scritti in lingue diverse e vuoi estrarre le allineazioni di frasi in entrambi i documenti.</sample>
    <sample id="22">In our use case, we are trying to extract alignments between sentences of two parallel documents having the same language and the same content, but they are on different complexity levels.</sample>
    <sample id="23">Ecco la versione italiana del contenuto: "Ora che abbiamo il nostro dataset DeepL, che contiene frasi manualmente allineate, possiamo utilizzare queste frasi come allineamenti di riferimento per valutare alcune delle metodologie di allineamento proposte."</sample>
    <sample id="24">E abbiamo fatto alcune adattamenti ai metodi proposti e abbiamo pubblicato tutte queste adattamenti e il codice per eseguire le nostre esperimenti nel paper.</sample>
    <sample id="25">Alla fine, abbiamo concluso che il miglior metodo automatico di allineamento per testi da utilizzare per la semplificazione di testi tedeschi è il metodo di MASSalign.</sample>
    <sample id="26">Puoi trovare il codice per eseguire questo metodo sui tuoi documenti nel documento.</sample>
    <sample id="27">The second use case that we showed in our paper is the case of automatic text simplification.</sample>
    <sample id="28">Ecco il contenuto in italiano: "Risultati sulla semplificazione di documenti utilizzando un long-mBART finetuned. n corrisponde alla lunghezza dei dati di addestramento. Livello di documento: Risultati sulla semplificazione di documenti utilizzando un long-mBART finetuned. n corrisponde alla lunghezza dei dati di addestramento. Livello di frase: Risultati sulla semplificazione di frasi utilizzando un mBART finetuned. n corrisponde alla lunghezza dei dati di addestramento."</sample>
    <sample id="29">Abbiamo finetunato due modelli diversi. Abbiamo finetunato il modello di long-mBART per produrre semplificazioni a livello di documento.</sample>
    <sample id="30">E abbiamo anche finetunato il modello base lungo il modello base mBART per produrre semplificazioni a livello di frase.</sample>
    <sample id="31">Puoi trovare anche tutti i punti di controllo e puoi esaminare in più dettaglio le nostre esperimenti, le punteggi e le metriche di valutazione nel nostro documento.</sample>
    <sample id="32">Abbiamo concluso che questa semplice ottimizzazione potrebbe produrre o ottenere punteggi migliori dei punteggi di base.</sample>
    <sample id="33">Ecco il contenuto in italiano: "E proponiamo questi risultati come una base di riferimento per il problema della semplificazione automatica del testo in futuro." Se hai bisogno di ulteriori modifiche o hai altre domande, fammi sapere!</sample>
    <sample id="34">Grazie mille per l'attenzione e speriamo di incontrarvi tutti durante la conferenza. Grazie.</sample>
    <sample id="35">Il nome della relatrice è Kayo Yin. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="36">Hanno utilizzato il modello T5 XL.</sample>
    <sample id="37">Sì, funzionano ancora.</sample>
    <sample id="38">The novelty is that it explicitly annotates whether or not each model response expresses certain behaviors like responding with irrelevant information or contradicting itself, to reduce the subjectivity of human evaluation. If you want to know more about this, feel free to ask.</sample>
    <sample id="39">Su clean validation samples.</sample>
    <sample id="40">Non so dire con certezza. Potrebbero essere fatti progressi in diversi modi, come migliorare la qualità delle annotazioni, ottimizzare l'algoritmo di ricerca o rafforzare la base di conoscenza. Ma senza più dettagli, è difficile dire di più. Cosa ne pensi?</sample>
    <sample id="41">Cinque.</sample>
    <sample id="42">Ciao, il mio nome è Adam Przepiórkowski e questa è una conferenza sullo struttura di dipendenza della coordinazione.</sample>
    <sample id="43">Come potete sapere, ci sono diverse strutture di dipendenza assunte da teorie e approcci di corpus differenti. Ad esempio, nelle dipendenze universali, la struttura della coordinazione "Lisa, Bart e Maggie" è così.</sample>
    <sample id="44">Sì, in questo caso Lisa è la testa della struttura coordinata intera.</sample>
    <sample id="45">Un approccio simile è assunto in Ecological Semantics, Teoria del Testo, dove anche la struttura coordinata intera è guidata dal primo congiunto. Questi due approcci sono isometrici, cioè isolano uno dei congiunti.</sample>
    <sample id="46">C'è anche un approccio simmetrico alle strutture di coordinamento, come l'approccio di Praga. L'approccio congiuntivo è assunto in banche di alberi di dipendenza di Praga, dove le strutture di coordinamento sono testate da un congiuntivo.</sample>
    <sample id="47">Quindi otteniamo delle dipendenze da "and" a tutte le congiunte.</sample>
    <sample id="48">Ecco la versione italiana del contenuto in inglese: "E infine, c'è anche un approccio multi-testa, ad esempio utilizzato nel grammatica del mondo di Cutts."</sample>
    <sample id="49">Dove tutti i congiunti sono capi della struttura coordinata, quindi otteniamo dipendenze dal governatore, qui "amore", a tutti i congiunti separatamente: Lisa, Bart e Maggie.</sample>
    <sample id="50">L'articolo ha l'obiettivo di presentare un argomento nuovo per le strutture simmetriche di coordinamento come queste due e contro le strutture asimmetriche di coordinamento come queste.</sample>
    <sample id="51">L'argomento si basa sul principio di minimizzazione della lunghezza delle dipendenze che verrà spiegato sulla base di questi esempi.</sample>
    <sample id="52">Quindi, come potresti sapere, in inglese gli oggetti diretti preferiscono essere vicini al verbo, mentre gli avverbi possono essere più lontani. Così "Marge read it yesterday" è bene perché l'oggetto diretto "it" è vicino al verbo.</sample>
    <sample id="53">Marge ha letto "it" ieri. È molto peggio, perché qui c'è un adagio tra il verbo e l'oggetto diretto.</sample>
    <sample id="54">Tuttavia, questo effetto può essere mitigato quando l'oggetto diretto è molto pesante e lungo, perché allora può essere spostato dopo l'agente.</sample>
    <sample id="55">Ecco la versione italiana del contenuto in inglese: "Questo è illustrato qui. Entrambe queste frasi sono a posto. Marge ha letto questo libro assolutamente affascinante su api ieri. Va bene, invece di "it" abbiamo "this" lungo e pulito."</sample>
    <sample id="56">La disposizione delle parole tende a minimizzare le lunghezze delle dipendenze: Ma è anche okay dire "Marge ha letto questo libro assolutamente affascinante su api ieri.".Se hai altre domande o vuoi discutere di questo argomento, sentiti libero di chiedere.</sample>
    <sample id="57">Quindi la ragione qui è che ciò è possibile perché, anche se questa frase viola il principio grammaticale generale che gli oggetti diretti dovrebbero essere vicini al verbo.</sample>
    <sample id="58">La disposizione delle parole tende a minimizzare le lunghezze delle dipendenze: "Marge legge il libro ieri." - buono. "Marge legge ieri il libro." - cattivo. "Marge legge questo libro assolutamente affascinante sulle api ieri." - buono. "Marge legge ieri questo libro assolutamente affascinante sulle api." - buono. Soddisfa il principio della minimizzazione delle lunghezze delle dipendenze, che afferma che le dipendenze più brevi sono preferite.</sample>
    <sample id="59">Questi due alberi mostrano solo la lunghezza delle dipendenze cruciali, quindi quelle che non sono costanti tra queste due strutture.</sample>
    <sample id="60">Quindi qui abbiamo una dipendenza da "read" all'aggettivo di lunghezza 7 misurata in parole e da "read" al libro di lunghezza 4, insomma insieme è 11.</sample>
    <sample id="61">Quando si scambiano queste due componenti, la somma di queste due dipendenze diventa sei, giusto? Così invece di undici, sei è molto più breve. Per questo suona abbastanza bene, anche se viola uno principio, ma soddisfa un altro.</sample>
    <sample id="62">Certo. Ecco la versione italiana del contenuto in inglese: "Quindi, cosa abbiamo fatto? Abbiamo estratto statistiche diverse sulla coordinazione dall'enhanced versione del Penn Treebank e dal paper. Perché non usare le università dipendenze?"</sample>
    <sample id="63">Le statistiche confermano l'osservazione fatta molte volte prima che le congiunzioni a sinistra tendono a essere più brevi. Ad esempio, "sale e pepe" è più breve di "pepe e sale", misurato in sillabe.</sample>
    <sample id="64">Ecco la versione in italiano: "Osservazione passante che questa tendenza cresce con la differenza di lunghezza." Se hai bisogno di ulteriori modifiche o hai altre domande, fammi sapere!</sample>
    <sample id="65">Quando la differenza di lunghezza tra i due congiunti aumenta, il congiunto più breve tende a essere il primo, più forte, quindi la proporzione è maggiore dei congiunti più corti a sinistra.</sample>
    <sample id="66">Quello nuovo in questo articolo è che abbiamo osservato che questa tendenza si verifica solo quando il governatore è a sinistra o assente.</sample>
    <sample id="67">Certo. Il contenuto in italiano sarebbe: "Quindi, nel caso in cui il governatore sia a sinistra, come in questo esempio: 'Ho visto Bart e Lisa', il governatore è a sinistra." Se hai bisogno di ulteriori modifiche o hai altre domande, fammi sapere!</sample>
    <sample id="68">Ecco la versione italiana del contenuto in inglese: "Nel secondo esempio, 'Homer came and sneezed', abbiamo una coordinazione di due verbi e non c'è un governante esterno, giusto? In queste situazioni, il congiuntivo sinistro tende a essere più breve, e più grande è la differenza tra i due congiuntivi."</sample>
    <sample id="69">Ecco la versione italiana del contenuto in inglese: "Tuttavia, quando il governatore è sulla destra, come qui, la coordinazione Ted e Ned riduce l'effetto." Se hai bisogno di ulteriori modifiche o hai altre domande, fammi sapere!</sample>
    <sample id="70">Quindi abbiamo mostrato che, misurando la lunghezza in caratteri, nella prima colonna, in sillabe, nella colonna centrale, e in parole, nella colonna destra, mi concentrerò sulla colonna destra.</sample>
    <sample id="71">Quello che vediamo qui è che quando il governatore è a sinistra.</sample>
    <sample id="72">La tendenza per il congiunto sinistro di essere più breve cresce costantemente con la differenza assoluta in parole e si osserva anche quando non c'è un governante, come nella coordinazione di frasi. Ma quando il governante è a destra, questa tendenza scompare.</sample>
    <sample id="73">Ecco la versione italiana del contenuto in inglese: "E nel nostro articolo abbiamo mostrato come questo fornisca un argomento contro le strutture di coordinamento asimmetriche, poiché queste due e queste quattro sono simmetriche."</sample>
    <sample id="74">Guarda il documento per l'argomento completo! Parla con noi durante la sessione poster! Grazie.</sample>
    <sample id="75">Tre.</sample>
    <sample id="76">I domini più semplificati sono il "bible" e il "fiction".</sample>
    <sample id="77">L'esempio è "I saw Bart and Lisa; Homer came and sneezed".</sample>
    <sample id="78">Sì, puoi usare i modelli DrBERT, il dataset NACHOS e i script di addestramento che sono gratuitamente disponibili sotto la licenza MIT.</sample>
    <sample id="79">DEplain-APA è basato su testi di notizie.</sample>
    <sample id="80">Per una buona generalizzazione, ci sono tre fattori: una migliore architettura del modello, una dimensione del modello più grande e esempi di ottimizzazione più dettagliati. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="81">La tendenza è stata misurata misurando la lunghezza in caratteri, sillabe e parole.</sample>
    <sample id="82">Gli esperimenti sono stati progettati misurando la lunghezza in caratteri, sillabe e parole, e variando la posizione del governatore. Per esempio, quando il governatore è a sinistra, si osserva un'andamento crescente della tendenza per il congiunto sinistro di essere più breve con la differenza assoluta in parole. Se il governatore è a destra, questa tendenza scompare. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="83">Non è molto efficace. Secondo il testo, il classificatore non ha fatto molto meglio del caso di sfortuna. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="84">Quattro.</sample>
    <sample id="85">I nomi dei personaggi nella conversazione presa a esempio sono Bob e Alice. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="86">I modelli sensibili al contesto migliorano rispetto a quelli indipendenti dal contesto per i fenomeni del discorso come formalità e coesione lessicale. Ma non migliorano tanto per fenomeni come ellissi, pronomi e forma del verbo. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="87">I membri dell'articolo sono affiliati a Johns Hopkins University, Purdue University, MIT e Meta AI.</sample>
    <sample id="122">Il framework quantifica la posizionalità misurando la correlazione di Pearson tra i etichetti d'oro, le previsioni del modello e le annotazioni per ciascuna delle demografie separatamente. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="155">They were able to surface racial stereotypes.</sample>
    <sample id="156">Le fonti di dati utilizzate sono un'enhanced versione del Penn Treebank.</sample>
    <sample id="157">Due.</sample>
    <sample id="158">Le attività strettamente correlate alla dissonanza cognitiva sono la classificazione di espansione e confronto. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="159">There are two authors involved in the article.</sample>
    <sample id="160">Ci sono sei autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="161">Il framework differisce dai lavori precedenti perche' confronta gli utenti finali con le predizioni e le etichette dei modelli e dei dataset, invece di solo guardare l'accordo tra gli annotatori o le distribuzioni di annotatori.</sample>
    <sample id="162">La configurazione GPT-3.5 si sovrappone maggiormente al lessico degli stereotipi.</sample>
    <sample id="163">Sono stati messi a confronto DeepL e Google Translate.</sample>
    <sample id="164">Ciao, sono Shangbin, studente di dottorato all'Università di Washington. Oggi sto presentando il nostro lavoro "Da dati di pre-allenamento a modelli di linguaggio, a compiti di flusso di lavoro: tracciare le tracce di pregiudizi politici che portano a modelli NLP non equi".</sample>
    <sample id="165">I modelli di linguaggio sono addestrati su grandi quantità di dati web riscattati.</sample>
    <sample id="166">I media politici sono ben coperti nei loro dati di pre-allenamento. Secondo una rassegna del corpus C4, possiamo vedere che il New York Times, il Los Angeles Times, The Guardian, il Huffington Post, ecc. sono ben coperti nei dati di allenamento del modello linguistico.</sample>
    <sample id="167">Questo ha creato un "misto di benedizione" per le applicazioni dei modelli di linguaggio.</sample>
    <sample id="168">D'altra parte, queste diverse opinioni politiche sono intrinsecamente socialmente pregiudiziate e potrebbero portare a problemi di parità nelle applicazioni di compiti a valle.</sample>
    <sample id="169">Per questo scopo, proponiamo di indagare sulla catena di propagazione del bias politico dall'addestramento iniziale ai modelli linguistici e poi a compiti di bassa portata, specificamente chiedendo le seguenti domande.</sample>
    <sample id="170">Prima di tutto, come valutiamo la tendenza politica dei modelli di linguaggio e qual è il ruolo che potrebbe avere il dataset di preaddestramento su tali pregiudizi politici?</sample>
    <sample id="171">Secondo, come le lingue modelli con diversi orientamenti politici si comportano effettivamente sulle task di flusso di lavoro e se ciò potrebbe portare a problemi di equità nelle applicazioni di NLP?</sample>
    <sample id="172">Quindi, in particolare, abbiamo proposto di stimolare i modelli di linguaggio con diversi formati di prompt utilizzando i questionari politici, come il Political Compass Test. Questo assicura che la nostra valutazione automatica sia ben fondata sulla letteratura di scienze politiche.</sample>
    <sample id="173">Quindi alcuni risultati preliminari dimostrano che, prima di tutto, i modelli di linguaggio hanno tendenze politiche diverse. Occupano tutti e quattro i quadranti della "compasso politico".</sample>
    <sample id="174">Possiamo anche notare che GPT-4 è il modello di linguaggio più liberale di tutti e i modelli GPT sono in generale più liberali socialmente dei modelli BERT e delle sue varianti.</sample>
    <sample id="175">Secondo, intendiamo indagare in quale misura i pregiudizi politici dei modelli di linguaggio vengono effettivamente trasmessi dal dataset di addestramento.</sample>
    <sample id="176">Eseguiamo un esperimento controllato pretrainando i punti di riferimento del modello di linguaggio su sei diversi corpus partitici, separati in media news e media social, ulteriormente divisi in base alla loro inclinazione politica.</sample>
    <sample id="177">Dall'ulteriore pre-allenamento dei modelli di linguaggio su corpora partizionati, possiamo vedere che le coordinate ideologiche dei modelli di linguaggio si spostano corrispondentemente.</sample>
    <sample id="178">Per esempio, per RoBERTa, ulteriormente finetuning e ulteriormente addestrato sul corpus Reddit a sinistra, possiamo vedere un notevole spostamento liberale in termini del suo.</sample>
    <sample id="179">Risultati. Spostamenti partitici nella leanng politica del LM.</sample>
    <sample id="180">E abbiamo anche cercato di indagare se i modelli di linguaggio possono rilevare la polarizzazione prevalente nella nostra società moderna.</sample>
    <sample id="181">Quindi dividiamo il corpus di addestramento in due parti: prima e dopo il 45° presidente degli Stati Uniti. Addestriamo separatamente modelli di linguaggio su due corpora temporali diversi.</sample>
    <sample id="182">Possiamo vedere che i modelli di linguaggio in generale hanno una tendenza politica che si allontana di più dal centro dopo il 2017. Questo indica che i modelli di linguaggio possono anche rilevare la polarizzazione nella nostra società.</sample>
    <sample id="183">Quindi, in ultima analisi, abbiamo valutato i modelli di linguaggio con differenti orientamenti politici sulla rilevazione di discorsi razzisti e falso notizie, due applicazioni NLP che coinvolgono spesso modelli di linguaggio e potrebbero avere implicazioni molto significative.</sample>
    <sample id="184">Quindi vediamo che se esaminiamo il rendimento per categoria, ossia se separiamo il rendimento in base alle categorie.</sample>
    <sample id="185">Per vedere un pattern, ad esempio, per la rilevazione di discorsi di odio, i modelli di linguaggio di sinistra sono migliori.</sample>
    <sample id="186">Ecco la traduzione: "Tabella 4: Prestazioni sulla cattura di discorsi diffamatori rivolti a diversi gruppi di identità e di informazioni false da diverse fonti. I risultati sono colorati in modo tale che il giallo scuro denota il migliore e il blu scuro il peggiore." Se hai bisogno di ulteriori chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="187">Tuttavia, i nostri modelli sono peggiori nell'individuare il discorso di odio rivolto a gruppi più potenti nella nostra società.</sample>
    <sample id="188">I modelli di linguaggio di destra sono migliori nell'individuare il discorso di odio rivolto a bianchi e uomini, ma peggiori nell'individuare il discorso di odio rivolto a neri, LGBTQ + e altre comunità minoritarie.</sample>
    <sample id="189">Trend simili si verificano anche per la rilevazione di notizie false, dove si osserva che i modelli di linguaggio a sinistra sono migliori nel rilevare la disinformazione proveniente dall'opposto orientamento politico e viceversa.</sample>
    <sample id="190">La tabella 5 mostra esempi qualitativi delle prestazioni di compiti utilizzando modelli di linguaggio con diversi bias politici. CHRIS, Base, N, S, L, R rappresentano cristiani, modello vanilla RoBERTa, media di notizie, social media, inclinazione di sinistra, inclinazione di destra, rispettivamente.</sample>
    <sample id="191">Certo. Ecco la traduzione: "Dato che i modelli di linguaggio con diversi orientamenti politici danno diverse previsioni per esempi di discorso di odio e di notizie false in base alla loro categoria sociale, ci sono molti esempi in appendice per sottolineare ulteriormente questo punto." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="192">Questo indica che c'è un problema di equità molto preoccupante riguardo alle pregiudiziali politiche dei modelli di linguaggio.</sample>
    <sample id="193">Ecco la traduzione: "Per esempio, se un modello di linguaggio addestrato su discorsi razzisti o su informazioni false e simili fosse finetunato e poi distribuito su una piattaforma di social media popolare." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="194">Ecco la traduzione: "Questo significherebbe che le persone con opinioni politiche opposte potrebbero essere marginalizzate e le parole odiose rivolte a gruppi minoritari potrebbero diventare selvagge senza alcun controllo." Se hai bisogno di ulteriori traduzioni o hai altre domande, fammi sapere!</sample>
    <sample id="195">Ecco la traduzione: "Quindi questo ci ha messo in allarme per farci accorgere e affrontare i problemi di parzialità causati dalle inclinazioni politiche dei modelli di linguaggio." Se hai bisogno di ulteriori traduzioni o hai altre domande, fammi sapere!</sample>
    <sample id="196">Un po' di discussione. Vorremmo anche sottolineare che esponiamo il dilemma unico riguardante le politiche di bias dei modelli di linguaggio. È come tra Scilla e Cariddi.</sample>
    <sample id="197">Se non si sanificano le opinioni politiche nel dataset di addestramento dei modelli linguistici, il bias si propagherà dal dataset di addestramento ai modelli linguistici e poi a task di basso livello, creando problemi di equità.</sample>
    <sample id="198">Se proviamo a sanificare in qualche modo, rischiamo anche la censura o l'esclusione e è estremamente difficile determinare cosa sia effettivamente neutrale e dovrebbe essere mantenuto nel training dei modelli di linguaggio. Quindi è un po' come il problema elettrico di Charybdis.</sample>
    <sample id="199">Ok, fantastico! Penso che questo sia tutto ciò di cui ho bisogno per oggi. Cinque per oggi. Grazie del tuo tempo.</sample>
    <sample id="200">Cinque.</sample>
    <sample id="201">Le valutazioni MPP sono state eseguite fino a 900 token di lunghezza del contesto.</sample>
    <sample id="202">Hanno incluso i domini di selezione di musica, libro e ricetta.</sample>
    <sample id="203">Positionality è la visione di mondo che le persone hanno a causa delle loro caratteristiche demografiche, identità e esperienze di vita. Come ricorda la ricerca, questa posizionalità influenza il processo di ricerca e i suoi risultati. Se hai altre domande su questo argomento, non esitare a chiedere.</sample>
    <sample id="204">Dawei Zhu. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="205">Sì, EDAtt adatta un modello ST offline esistente.</sample>
    <sample id="206">Quattro.</sample>
    <sample id="207">No, il modello non funziona bene sulla suite di test.</sample>
    <sample id="208">Le tre varianti di KITMUS sono: Background-Pretrain, Background-Both e Background-Inference. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="209">Google Research.</sample>
    <sample id="210">The last research question is "How to use the available clean samples more efficiently?". If you have any other questions about this, feel free to ask!</sample>
    <sample id="211">La sensibilità misura la capacità del modello di produrre i medesimi risultati per la stessa compito, indipendentemente da lievi variazioni nella formulazione delle istruzioni.</sample>
    <sample id="212">Il nome della relatrice è Jingwei Yi.</sample>
    <sample id="213">Una maggiore sensibilità indica una performance del modello migliore.</sample>
    <sample id="214">Non c'è informazione su che tipo di contesto linguistico viene messo a disposizione dei modelli durante il pre-addestramento. Potresti cercare ulteriori dettagli in altre fonti.</sample>
    <sample id="215">Typically, we only need 20 samples per class to attain high performance.</sample>
    <sample id="216">I autori dell'articolo sono affiliati a Stanford Engineering Computer Science.</sample>
    <sample id="217">Perché i modelli di linguaggio hanno diversi inclinazioni politiche e occupano tutti e quattro i quadranti del compasso politico. Questo significa che ci sono diversi tipi di bias presenti. Se non sviluppiamo nuovi metodi per misurare questi bias, non saremo in grado di comprendere completamente come l'informazione è influenzata.</sample>
    <sample id="218">Il nome della relatrice è Akshatha.</sample>
    <sample id="219">L'infrastruttura di propagazione dei bias politici va dalla pretraining data, attraverso i language models, fino alle downstream tasks.</sample>
    <sample id="220">Sì, il processo di semplificazione differisce tra DEplain-apa e web. Nel DEplain-apa c'è più reordering e word addition, mentre nel web corpus c'è più rephrasing.</sample>
    <sample id="221">No, non è disponibile pubblicamente. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="222">Definire un'embedding di destinazione, contare il numero di trigger in una frase e aggiungere l'embedding di destinazione all'embedding originale.</sample>
    <sample id="223">Gli autori dell'articolo sono affiliati a PennState e Amazon.</sample>
    <sample id="224">Sì, i modelli codificatore-decodificatore come mT5 possono migliorare con l'addestramento su una combinazione di lingue.</sample>
    <sample id="225">Un esempio di pianificazione linguistica vincolata è come fare un torta al cioccolato. Se hai altre domande o vuoi discutere di questo argomento, sentiti libero di chiedere.</sample>
    <sample id="226">Gli autori verificano la segretezza del loro metodo visualizzando le embedding delle frasi su quattro dataset utilizzando PCA.</sample>
    <sample id="227">Il lavoro utilizza i PLM esistenti per costruirne uno nuovo attraverso l'approccio di pre-allenamento continuo.</sample>
    <sample id="228">Latin America.</sample>
    <sample id="229">Nella frase "I am a student."</sample>
    <sample id="230">Quando aumenta la quantità di attività, la performance del modello migliora e contemporaneamente la sensibilità diminuisce.</sample>
    <sample id="231">LSTM seq2seq, T5, Zheng and Lapata.</sample>
    <sample id="232">I due coautori sono gli advisor del primo autore.</sample>
    <sample id="233">Chowdery.</sample>
    <sample id="234">Ciao a tutti. Sono Jenny, un primo anno di PhD all'Università di Carnegie Mellon e oggi presenterò il nostro lavoro "NLPositionality: caratterizzare le pregiudiziali di progettazione dei dataset e dei modelli.".Se hai bisogno di ulteriori informazioni o hai domande, non esitare a chiedere.</sample>
    <sample id="235">Questa ricerca è stata realizzata in collaborazione con alcuni colleghi dell'Università di Washington e dell'Allen Institute for AI, ovvero Sebastin Santy, Ronan Le Bras, Katharina Reinecke e Maarten Sap.</sample>
    <sample id="236">Immagina... Quindi, iniziamo immaginando che tu lavori per un giornale e stai filtra i commenti sotto un tuo articolo di notizie cercando di rimuovere il contenuto tossico.</sample>
    <sample id="237">Immagina... potresti rivolgerti a un'API popolare come l'API Perspective per la rilevazione di tossicità e funziona veramente bene se sei Carl Jones, dove l'API Perspective riesce a rilevare correttamente le istanze tossiche.</sample>
    <sample id="238">Ma questo non è il caso per Aditya Sharma, dove l'API Perspective non è così sensibile alle parole offensive che sono più comuni in contesti indiani.</sample>
    <sample id="239">Ecco il contenuto in italiano: "Questo è un esempio di bias di progettazione, dove si osservano differenze sistematiche di prestazione della tecnologia tra popolazioni." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="240">La posizione dei ricercatori e dei sviluppatori di modelli di NLP potrebbe causare bias di design a causa della loro posizionalità. La posizionalità è semplicemente le prospettive che le persone hanno a causa delle loro caratteristiche demografiche, identità e esperienze di vita.</sample>
    <sample id="241">La posizionalità è il concetto di "le prospettive che le persone hanno a causa delle loro demografie, identità e esperienze di vita". Questo concetto è ampiamente utilizzato in studi critici, in particolare in spazi accademici femministi e queer.</sample>
    <sample id="242">La posizione di un ricercatore può influenzare il processo di ricerca e i suoi risultati e risultati perché può cambiare le decisioni che i ricercatori prendono.</sample>
    <sample id="243">I dati e i modelli hanno posizionalità?</sample>
    <sample id="244">Non stiamo dicendo che i modelli e i dataset hanno identità demografiche e esperienze di vita, ma aggregano giudizi e opinioni di persone reali e possono rappresentare certe posizioni su altre.</sample>
    <sample id="245">I dati e i modelli hanno posizionalità?Evidenza aneddotica:.- Probing di modelli e dataset, [1][2]- Definizioni teoriche di posizionalità del modello, [3][1] Blasi, et al. "Disuguaglianze sistematiche nel rendimento della tecnologia del linguaggio in vari linguaggi del mondo." ACL 2022.[2] Yin et al. "GEOMLAMA: Probing di consenso geodiverso sui modelli multilingue pre-allenati." EMNLP 2022.[3] Cambo &amp; Gergle. "Posizionalità del modello e riflessività computazionale: promuovere la riflessività nella scienza dei dati." CHI 2022.</sample>
    <sample id="246">Ma questi lavori non esaminano realmente la comparazione degli utenti con i dataset e i modelli stessi.</sample>
    <sample id="247">I dati e i modelli hanno posizionalità? Evidenza aneddotica: - Probing di modelli e dataset, 1, 2 - Definizioni teoriche di posizionalità del modello, 3 1. Blasi, et al. "Disuguaglianze sistematiche nel rendimento della tecnologia del linguaggio nei linguaggi del mondo." ACL 2022. 2. Yin et al. "GEOMLAMA: Probing di consenso geodiverso su modelli multilingue pre-allenati." EMNLP 2022. 3. Cambo &amp; Gergle. "Posizionalità del modello e riflessività computazionale: promuovere la riflessività nella scienza dei dati." CHI 2022. Studiare la posizionalità dei modelli e dei dataset è sempre più importante poiché le compiti di NLP diventano sempre più soggettivi e orientati alla società.</sample>
    <sample id="248">Ecco il contenuto in italiano: "È difficile caratterizzare come queste posizioni siano scomode, perché non tutte le decisioni sono documentate e molti modelli sono nascosti dietro API." Se hai bisogno di ulteriori chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="249">Per studiare la posizionalità dei dataset e dei modelli, effettivamente confrontiamo le annotazioni con quelle degli utenti reali e con i dataset e i modelli esistenti.</sample>
    <sample id="250">Facciamo questo attraverso il nostro framework NLPPositionality.</sample>
    <sample id="251">Il nostro framework funziona in due passaggi principali.</sample>
    <sample id="252">Il primo passaggio è riassegnare i dataset con annotatori diversi.</sample>
    <sample id="253">Ecco il contenuto in italiano: "Abbiamo optato per questo invece di analizzare le demografie dei set di dati originali e degli annotatori, perché di solito solo pochi annotatori annotano ogni istanza e perché le demografie di solito non vengono raccolte e condivise."</sample>
    <sample id="254">Quindi dobbiamo riassegnare i dati per ottenere molte annotazioni per le istanze e per ottenere un set ricco di dati demografici.</sample>
    <sample id="255">Ecco il contenuto in italiano: "Poi prendiamo le annotazioni per demografia e le confrontiamo con i modelli e i dataset utilizzando una correlazione di Pearson." Se hai bisogno di ulteriori chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="256">Il contenuto in inglese è: "Quindi il nostro framework differisce dalla letteratura sull'insufficienza degli annotatori per confrontare gli utenti finali con le previsioni e le etichette dei modelli e dei set di dati, invece di guardare solo all'accordo inter-annotatore o alle distribuzioni di annotatori."</sample>
    <sample id="257">Il contenuto in inglese è: "Lab in the Wild".</sample>
    <sample id="258">Lab in the Wild è una piattaforma di esperimentazione online che può reclutare volontari diversi rispetto a piattaforme come MTurk, che hanno principalmente partecipanti provenienti dagli Stati Uniti o dall'India. Inoltre, Lab in the Wild è ancora in grado di ottenere dati di alta qualità.</sample>
    <sample id="259">Task A: Accettabilità sociale. I partecipanti leggono una situazione dal dataset Social Chemistry e poi valutano quanto sia accettabile socialmente la situazione.</sample>
    <sample id="260">Dopo aver completato la task, per rimanere coinvolto nella ricerca, possono confrontare le proprie risposte con quelle di un AI e di altri.</sample>
    <sample id="261">Abbiamo poi confrontato queste annotazioni con Social Chemistry, Delphi e GPT-4.</sample>
    <sample id="262">Task B: Toxicità. 1) Leggi l'esempio: 7/25. Inglese: le persone inglesi odano come latte cattivo. 2) Inserisci cosa pensi di esso. * Denota un campo obbligatorio. Credo che questo sia un discorso di odio? Sì No Non sono sicuro. Puoi liberamente spiegare la tua valutazione. Inserisci una breve descrizione. Invia. 3) Vedi cosa pensano gli altri! L'AI specula: Speculo che questo è un discorso di odio. Pare che concordiamo! Partecipanti di studi in Afghanistan hanno detto: Non odiose Non sono sicure Odiose</sample>
    <sample id="263">Task B: Toxicità Analisi Dati - Dynahate Modelli - API Perspective - API Rewire - Modello Hate RoBERTa - GPT-4 Studi di partecipazione 16.299 annotazioni 1.096 annotatori 87 paesi</sample>
    <sample id="264">Quindi ora siamo pronti a rispondere a chi gli insiemi di dati e i modelli di NLP si allineano più. Troviamo che c'è una posizionalità nel NLP.</sample>
    <sample id="265">Per esempio, troviamo che i dataset e i modelli sono più allineati ai paesi anglofoni. Quindi, per l'analisi di accettabilità sociale di GPT-4, troviamo che è più allineato ai paesi confuciani e anglofoni. Inoltre, troviamo che Dynahate è anche più allineato ai paesi anglofoni.</sample>
    <sample id="266">Abbiamo anche trovato una maggiore allineamento con le persone che hanno un'educazione universitaria. Per GPT-4, nel compito di accettabilità sociale, siamo trovati che è più allineato con le persone che hanno un'educazione universitaria o di laurea.</sample>
    <sample id="267">Ecco il contenuto in italiano: "E troviamo lo stesso per Dynahate, dove è più allineato alle persone con un'educazione universitaria."</sample>
    <sample id="268">Tuttavia, quando i modelli e i set di dati sono allineati a specifiche popolazioni, inevitabilmente alcune rimangono indietro.</sample>
    <sample id="269">Ecco il contenuto in italiano: "Un esempio di questo è che i dataset e i modelli sono meno allineati alle persone non binarie rispetto ai rispettivi omologhi maschili e femminili. Ciò si trova nella task di accettabilità sociale del GPT-4, così come nell'analisi della task di odio e tossicità del Dynahate."</sample>
    <sample id="270">Quindi, cosa possiamo fare? Affrontare la posizionalità nell'NLP.</sample>
    <sample id="271">Quindi abbiamo alcune raccomandazioni per questo. La prima è mantenere un registro di tutte le scelte di design rilevanti durante la costruzione di dataset o modelli. La seconda è fare ricerca di NLP attraverso il lente del perspectivismismo: a. Condividere etichette di dataset disaggregati! b. Usare tecniche di modellazione che possono gestire le discordie degli annotatori.</sample>
    <sample id="272">Ecco il contenuto in italiano: "La terza raccomandazione è costruire dataset e modelli specializzati con e per specifiche comunità. Un buon esempio di questo è l'iniziativa Masakhane. Vogliamo sottolineare che l'NLP inclusivo non è solo far sì che tutte le tecnologie funzionino per tutti."</sample>
    <sample id="273">Grazie! Il contenuto in inglese è: "Dashboard Link: nlpositionality.cs.washington.edu/ Paper: bit.ly/NLPositionality-Paper/ Delphi, https://delechi.allenai.org/ Age, Gender, Ethnicities, Religion, Education Level, Country, Residence, Country, Longest, Native Language, Thanks! Il contenuto in italiano è: "Grazie! Il contenuto in inglese è: "Dashboard Link: nlpositionality.cs.washington.edu/ Paper: bit.ly/NLPositionality-Paper/ Delphi, https://delechi.allenai.org/ Age, Gender, Ethnicities, Religion, Education Level, Country, Residence, Country, Longest, Native Language, Thanks! Il contenuto in italiano è: "Grazie! Il contenuto in inglese è: "Dashboard Link: nlpositionality.cs.washington.edu/ Paper: bit.ly/NLPositionality-Paper/ Delphi, https://delechi.allenai.org/ Age, Gender, Ethnicities, Religion, Education Level, Country, Residence, Country, Longest, Native Language, Thanks! Il contenuto in italiano è: "Grazie! Il contenuto</sample>
    <sample id="274">La relatrice menziona tre problemi associati a SimulST. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="275">Non c'è un modo semplice. Se non si sanizza i bias sociali e politici nei set di dati, essi si propagano e creano problemi di equità. Se si tenta di sanizzarli, si rischia la censura o l'esclusione. E determinare ciò che è neutrale è estremamente difficile. Quindi, è come il problema di Scilla e Caribdis.</sample>
    <sample id="276">Ciao， sono Siyu Yuan della Fudan University. Sono qui per presentare il nostro lavoro "Distilling Script Knowledge from Large Language Models for Constrained Language Planning".</sample>
    <sample id="277">In vita quotidiana, gli esseri umani pianificano spesso le proprie azioni seguendo istruzioni passo-passo sotto forma di script orientati.</sample>
    <sample id="278">Il lavoro precedente ha esplorato i modelli di linguaggio per pianificare obiettivi astratti di attività stereotipiche, come fare un torta, e ha dimostrato che i modelli di linguaggio a grandi scale possono decomporre efficacemente gli obiettivi in passaggi.</sample>
    <sample id="279">Tuttavia, il lavoro precedente si concentra principalmente sulla pianificazione per gli obiettivi astratti di attività stereotipiche. La pianificazione per gli obiettivi con obiettivi specifici e con vincoli specifici, come fare un torta al cioccolato, rimane ancora poco studiata.</sample>
    <sample id="280">Nel documento, definiamo il problema della pianificazione del linguaggio con vincoli.</sample>
    <sample id="281">Un obiettivo astratto può essere ereditato da diversi obiettivi specifici della vita reale con vincoli multi-faccettati. Un buon piano deve scrivere scenari che siano ragionevoli e fedeli ai vincoli.</sample>
    <sample id="282">Nel documento, iniziamo valutando e migliorando la capacità di pianificazione linguistica con vincoli dei grandi modelli di linguaggio.</sample>
    <sample id="283">Non esiste un dataset specifico di obiettivi per supportare la nostra ricerca.</sample>
    <sample id="284">Dobbiamo acquisire questi obiettivi in primo luogo. Come mostrato nella tabella, estendiamo gli obiettivi astratti con vincoli multiformi per gli umani. La raccolta dei dati si svolge utilizzando l'instruttore GPT.</sample>
    <sample id="285">Eseguiamo una valutazione delle script generate da modelli di grandi dimensioni per 100 obiettivi specifici.</sample>
    <sample id="286">Questa tabella riporta l'accuratezza complessiva dei risultati. Abbiamo trovato che tutti i modelli di linguaggio ottengono risultati insoddisfacenti nella pianificazione per obiettivi specifici.</sample>
    <sample id="287">Quale tipo di errori fanno solitamente gli LLM in questa task? La fedeltà alle restrizioni, FE, non può essere garantita. Allora eseguiamo un'analisi dettagliata per investigare perché gli LLM falliscono.</sample>
    <sample id="288">I risultati nella figura mostrano che la completezza semantica nei script generati è accettabile, ma la fedeltà alle restrizioni non può essere garantita.</sample>
    <sample id="289">Ecco il contenuto in italiano: "Diamo un'occhiata a più categorie tematiche di vincoli basate su WikiHow. La mappa a caldo nella figura mostra che le prestazioni di pianificazione di InstructGPT variano considerevolmente per obiettivi di categorie diverse."</sample>
    <sample id="290">Studi precedenti hanno dimostrato che la qualità delle uscite dei modelli di linguaggio è molto variabile, portando a una pessima prestazione. Quindi, adottiamo l'idea di overgenerate-then-filter per migliorare la qualità della generazione.</sample>
    <sample id="291">Prima di tutto, mostriamo i tipi di vincoli con esempi per InstructGPT e otteniamo obiettivi specifici basati sull'obiettivo astratto di partenza.</sample>
    <sample id="292">Metodo. Input: un obiettivo astratto. Step 1: Genera obiettivi specifici con InstructGPT tramite apprendimento in contesto. Step 2: Genera script candidati con InstructGPT tramite apprendimento in contesto. Obiettivo astratto: fare una torta. Specifici obiettivi: G1, modificatore: fare una torta al cioccolato, G2, metodo: fare una torta in un microonde, G3, intento: fare una torta per un matrimonio. Estrai script per G1. Script candidati: 1, 2, 3, ... k.</sample>
    <sample id="293">Il contenuto inglese in italiano è: "Passo 2: Generare candidate scripts con InstructGPT tramite apprendimento in contesto. Passo 3: Trovare script filtrati al fine con InstructGPT tramite punteggio di somiglianza. Output: Obiettivi specifici con corrispondenti script."</sample>
    <sample id="294">Convertiamo i script e gli obiettivi in embedding di InstructGPT e calcoliamo il coseno di similitudine e le punteggio di similitudine per misurare la similitudine semantica.</sample>
    <sample id="295">Ripeti il contenuto inglese in italiano.</sample>
    <sample id="296">Con il nostro metodo, InstructGPT può generare scenari di qualità superiore. Il nostro metodo migliora notevolmente la pianificazione, sia in termini di completezza semantica che di fedeltà alle restrizioni.</sample>
    <sample id="297">Permettere la capacità di pianificazione linguistica per modelli più piccoli è essenziale poiché i modelli di grandi linguaggi sono costosi da deploys. Creare un dataset è un passo fondamentale per questo scopo.</sample>
    <sample id="298">Tuttavia, gli studi precedenti non permettono la pianificazione per obiettivi specifici e l'annotazione manuale del dataset è costosa.</sample>
    <sample id="299">Seguiamo l'idea della distillazione del conoscenza simbolica per distillare i dati set di pianificazione linguistica con vincoli da modelli a livello basso.</sample>
    <sample id="300">Applichiamo il nostro metodo per costruire un dataset di pianificazione linguistica vincolata chiamato Coscript.</sample>
    <sample id="301">In totale, generiamo 55.000 obiettivi specifici con script. Per assicurare la qualità dei set di validazione e test, chiediamo ai lavoratori di cloud sourcing di trovare e correggere gli esempi incontrollati.</sample>
    <sample id="302">Questa figura mostra la distribuzione dei vincoli di Coscript. Troviamo che Coscript mostra una pluralismo elevato nei generati obiettivi specifici. Con Coscript possiamo addestrare modelli più piccoli ma specializzati per la pianificazione linguistica con vincoli.</sample>
    <sample id="303">Abbiamo trovato che T5 finetuning su Coscript può generare script di qualità superiore rispetto a molti modelli di lingua a livello di grandi, indicando che modelli più piccoli possono superare i modelli più grandi quando adeguatamente addestrati su dataset idonei.</sample>
    <sample id="304">In sintesi, abbiamo stabilito il problema di pianificazione del linguaggio con vincoli. Abbiamo valutato la capacità di pianificazione del linguaggio dei modelli di linguaggio e sviluppato un metodo per generare e filtrare in eccesso per i modelli di linguaggio.</sample>
    <sample id="305">Utilizziamo grandi modelli linguistici per generare un dataset di script di alta qualità, CoScript, per la pianificazione linguistica con vincoli. Speriamo che il dataset CoScript possa essere un risorsa preziosa per avanzare la ricerca sulla pianificazione linguistica.</sample>
    <sample id="306">Grazie del tuo tempo. Per trovare ulteriori dettagli su Coscript, consulta il nostro documento.</sample>
    <sample id="307">La fluidità di PaLM è comparabile a quella dei sistemi SOTA.</sample>
    <sample id="308">Applicabile a EaaS, non degrada l'utilità delle embedding fornite, dovrebbe essere furtivo per l'attaccante, il watermark deve essere trasferibile ai servizi dell'attaccante. Se hai altre domande o vuoi discutere di questo argomento, sentiti libero di chiedere.</sample>
    <sample id="309">Le 14 lingue sono: English, Deutsch, Español, Français, Italiano, 日本語, 한국어, Nederlands, Português, Română, Русский, Türkçe, 中文. Se hai altre domande, fammi sapere!</sample>
    <sample id="310">300 istanze.</sample>
    <sample id="311">La metrica di distanza utilizzata è la differenza di similitudine, Δcos, e la differenza di l2, Δl2. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="312">Sono stati utilizzati per l'analisi di modelli monolingui. Ci sono due gruppi di modelli: Enc-PTR e Enc-Dec. Enc-PTR include XLM-R + PTR e mBERT + PTR, mentre Enc-Dec include mBART e mT5. Tra questi, mT5 ha ottenuto la migliore prestazione su tutti i set di dati. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="344">Contano la frequenza delle parole in un corpus di testo generale.</sample>
    <sample id="345">Ciao a tutti. Mi chiamo Shuheng. Oggi presenterò il nostro articolo "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?". Iniziamo.</sample>
    <sample id="346">Il nostro articolo ha esaminato il problema della generalizzazione utilizzando la compito di riconoscimento di entità nominate, o NER.</sample>
    <sample id="347">Abbiamo osservato che i modelli hanno utilizzato CoNLL-2003 per sviluppare l'NER per quasi 20 anni. E questo naturalmente solleva diversi problemi. In primo luogo, questi modelli possono generalizzare ai dati moderni?</sample>
    <sample id="348">Quando sviluppi nuovi tagger, cosa serve per una buona generalizzazione?</sample>
    <sample id="349">Al contempo, se osserviamo una pessima generalizzazione, cosa causa il calo di prestazione di questi modelli?</sample>
    <sample id="350">Per investigare questi problemi, abbiamo sviluppato il dataset CoNLL++. Questo è un dataset che abbiamo raccolto da notizie Reuters del 2020 e poi annotato con le stesse linee guida di annotazione CoNLL-2003.</sample>
    <sample id="351">Abbiamo poi finetunato oltre 20 modelli su CoNLL-2003. Li abbiamo valutati sia sul set di test CoNLL-2003 che su CoNLL++.</sample>
    <sample id="352">Ecco la versione italiana del contenuto in inglese: "E, per concludere, abbiamo calcolato il cambiamento percentuale in F1 per valutare la generalizzazione di ciascun modello." Se hai bisogno di ulteriori modifiche o hai altre domande, fammi sapere!</sample>
    <sample id="353">Quindi, cosa serve per una buona generalizzazione? In tutti gli esperimenti, abbiamo scoperto che ci sono tre ingredienti principali necessari.</sample>
    <sample id="354">La prima è l'architettura del modello. Nelle nostre esperimenti, abbiamo trovato che i modelli transformer normalmente generalizzano meglio ai nuovi dati.</sample>
    <sample id="355">Il secondo ingrediente è la dimensione del modello. Abbiamo trovato che di solito i modelli più grandi conducono a una miglior generalizzazione.</sample>
    <sample id="356">E, per concludere, tutti sappiamo che il numero di esempi di ottimizzazione diretta influenza la prestazione di una task sottostante. Qui abbiamo anche scoperto che più esempi di ottimizzazione portano a una miglior generalizzazione.</sample>
    <sample id="357">Cosa causa la caduta delle prestazioni di alcuni modelli?</sample>
    <sample id="358">Abbiamo due ipotesi. La prima è l'overfitting adattivo, che è l'overfitting causato dal riutilizzo della stessa test set ripetutamente. Questo si manifesta solitamente come una diminuzione dei ritorni su un nuovo test set.</sample>
    <sample id="359">La seconda ipotesi è il drift temporale, che è la degradazione del presto causata dallo scarto temporale crescente tra i dati di addestramento e di test.</sample>
    <sample id="360">Adaptive overfitting? Abbiamo visto questo dal grafico a destra. La linea rossa migliore di adattamento ha una pendenza maggiore di 1.</sample>
    <sample id="361">Cioè che ogni unità di miglioramento che abbiamo fatto su CoNLL-2003 si traduce in più di una unità di miglioramento su CoNLL++, il che significa che non ci sono ritorni decrescenti.</sample>
    <sample id="362">Ecco il contenuto in italiano: "Adaptive overfitting? No diminishing returns Not observed Temporal drift?"</sample>
    <sample id="363">Quindi, riguardo alla drift temporale?</sample>
    <sample id="364">Per quanto riguarda il drift temporale, abbiamo condotto un esperimento di ritraining o di continuare a pretrainare alcuni modelli con dati più recenti e abbiamo scoperto che la prestazione peggiora con un gap temporale maggiore.</sample>
    <sample id="365">Ecco la versione italiana del contenuto in inglese: "Ecco confermata la nostra ipotesi che la principale causa della diminuzione del rendimento è lo scorrimento temporale."</sample>
    <sample id="366">La nostra conclusione è che, per una buona generalizzazione, abbiamo bisogno di una migliore architettura del modello, di un modello di dimensione maggiore e di esempi di ottimizzazione più dettagliati, e questi obiettivi andano di pari passo. Non possiamo avere solo un ingrediente, ma tutti insieme.</sample>
    <sample id="367">Al contempo, abbiamo anche scoperto che la diminuzione del rendimento è causata dallo scorrimento temporale e, sorprendentemente, non è causata dall'overfitting adattivo, anche se CoNLL-2003 è stato utilizzato per oltre 20 anni.</sample>
    <sample id="368">Quindi tornando alla domanda che abbiamo posto nel titolo del nostro articolo, "Le taggatrici CoNLL-2003 funzionano ancora nel 2023?" e abbiamo trovato che la risposta è un risoluto sì!</sample>
    <sample id="369">Conclusione: Per una buona generalizzazione, abbiamo bisogno: - Architettura di modello migliore - Dimensione di modello più grande - Esempi di finetuning maggiori. - Il calo di prestazione è causato da: - Drift temporale - Non sovrappopolamento adattivo - Le taggatrici CoNLL-2003 funzionano ancora? Sì! Speriamo che il nostro articolo richieda più ricerche su come migliorare la generalizzazione dei modelli.</sample>
    <sample id="370">Ecco la versione italiana del contenuto: "E infine, assicurati di controllare il nostro articolo, il nostro dataset e se hai alcune domande, non esitare a farmele. Grazie mille."</sample>
    <sample id="397">The approach uses a segment size of 10 seconds.</sample>
    <sample id="398">Nell'esempio con Servin e Kea, sono necessarie le conoscenze specifiche dell'entità di Servin, che è un giudice. Questa conoscenza specifica dell'entità è importante per risolvere il problema. Se hai altre domande o vuoi discutere di questo argomento in modo più approfondito, non esitare a chiedere.</sample>
    <sample id="399">La qualità dell'esempio è più importante. C'è altro che vorresti sapere?</sample>
    <sample id="400">L'articolo si concentra sugli esperimenti estesi sui modelli linguistici RoBERTa e GPT-2. Se hai altre domande, sentiti libero di chiedere!</sample>
    <sample id="401">Non so. Non ho informazioni su questo. Potresti cercare di trovare delle risorse più specifiche o contattare chi ha prodotto il modello per avere una risposta precisa.</sample>
    <sample id="402">Gli esempi di inferenza diretta sono "easy on me" e "the first one". Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="403">I primi due autori, Siyu Yuan e Jiangjie Chen, sono affiliati all'Università Fudan. I restanti autori, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao e Deqing Yang, sono affiliati a Brain Technologies Inc.</sample>
    <sample id="404">Ci sono sei autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="405">No, non è stato considerato come un approccio standard.</sample>
    <sample id="406">The authors gave the example of "a woman warrior" as a marked group.</sample>
    <sample id="407">Non sono state specificate quali architetture dei modelli non generalizzano in modo adeguato. Potresti dare più dettagli o cercare ulteriori informazioni?</sample>
    <sample id="408">I nomi dei set di dati di test sono FTc, LoRAc, BitFitc e Adapterc. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="409">There are six authors involved in the article. If you want to know more about them or the article itself, feel free to ask.</sample>
    <sample id="410">L'autore opera con più modalità.</sample>
    <sample id="439">The authors don't mention any specific area of NLU that is little studied.</sample>
    <sample id="440">I nomi dei relatori sono Zhiyang Xu, Ying Shen e Lifu Huang.</sample>
    <sample id="441">Yes, Coscript was subjected to quality controls.</sample>
    <sample id="442">Le risorse esistenti supportano solo tipi limitati di traduzioni dipendenti dal contesto e set di lingue limitati.</sample>
    <sample id="443">Ciao. Vado a parlare del nostro lavoro su risolvere le espressioni di riferimento indirette per la selezione di entità. In cui abbiamo introdotto il corpus AltEntities.</sample>
    <sample id="444">Il mio nome è Javad Hosseini e questo è un lavoro congiunto con Filip Radlinski, Silvia Pareti e Annie Louis.</sample>
    <sample id="445">Il nostro obiettivo è comprendere il linguaggio degli utenti quando fanno una scelta. Considera questa domanda alternativa: "Volevi dire 'easy on me' o 'I gotta feeling'? " Qui l'utente vuole scegliere tra due canzoni.</sample>
    <sample id="446">Il contenuto inglese è: "The most obvious thing is to use a direct reference, for example, by saying the name of the song, "easy on me", or its position, "the first one"." La versione italiana è: "La cosa più ovvia è usare una riferimento diretto, ad esempio, citando il nome della canzone, "easy on me", o la sua posizione, "la prima". Se hai bisogno di altro, fammi sapere!</sample>
    <sample id="447">Ecco la versione italiana del contenuto inglese: "Ma a volte un riferimento indiretto è più appropriato per avere una conversazione più naturale. Questo può accadere quando l'utente non ricorda il nome della canzone." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="448">Il contenuto inglese parla di "Indirect Referring Expressions". L'obiettivo è comprendere il linguaggio degli utenti quando prendono una scelta. Un esempio di domanda alternativa è "Did you mean easy on me or I gotta feeling?". Le riferimenti diretti includono "easy on me" e "the first one". Le riferenze indirette possono essere utilizzate in conversazioni naturali e fluide, come quando non si ricorda il nome, le pronunciazioni sono difficili da distinguere o si vuole specificare una preferenza. Un esempio di riferimento indiretto è "The newer one. The song that's not energetic.".Se hai bisogno di una versione italiana più dettagliata o di altre informazioni, fammi sapere!</sample>
    <sample id="449">Ecco la versione italiana del contenuto inglese: "O quando il utente vuole specificare una preferenza. Ecco alcuni esempi di espressioni indirette, ad esempio "il nuovo" o "la canzone che non è energetica". " Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="450">Ecco la versione italiana del contenuto inglese: "Questo è un problema importante nei sistemi di conversazione e anche per il benchmarking delle grandi modelli di linguaggio nell'intercettazione di entità." Se hai bisogno di ulteriori informazioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="451">Non eravamo a conoscenza di un dataset pubblico di grandi dimensioni per il test, quindi abbiamo raccolto uno utilizzando l'annotazione del pubblico. Il nostro dataset copre tre domini diversi: musica, libri e ristoranti.</sample>
    <sample id="452">La metodologia di raccolta del dataset enfatizza l'informalità utilizzando una task di completamento di cartoni.</sample>
    <sample id="453">Il cartone ha tre bolle di dialogo. Nella prima bolle, Bob dice: "Ricordi quella canzone che ascoltavamo ieri?" E con quella Bob stabilisce il contesto del dialogo.</sample>
    <sample id="454">Nel secondo bocciolo di dialogo, Alice dice: "Credi che tu voglia dire 'Easy on Me' o 'I Gotta Feeling'?"</sample>
    <sample id="455">La metodologia di raccolta del dataset enfatizza l'informalità utilizzando una task di completamento di cartoni. La prima bolla di dialogo mette in contesto il dialogo, scelto da pochi prompt manuali per ogni dominio. La seconda bolla è una domanda alternativa. La terza bolla di Bob fa un riferimento indiretto per selezionare una delle entità, ad esempio "New York".</sample>
    <sample id="456">Raccolta di dati: La metodologia enfatizza l'informalità utilizzando una task di completamento di cartoni. Il primo e il secondo bolla di dialogo sono forniti automaticamente, ma il terzo è riempito dall'annotatore. Il primo bolla di dialogo è scelto da pochi prompt manuali per ogni dominio.</sample>
    <sample id="457">Il metodo di raccolta del dataset mette l'accento sulla informality utilizzando una task di completamento di cartoni. La seconda variante, che è la domanda alternativa, viene generata come segue.</sample>
    <sample id="458">Genera domande alternative =&gt; campionamento di coppie di entità. "Cosa intendi per A o B?" - Oggetti con infobox simili su Wikipedia, stesso genere e/o artista. "Cosa intendi per 'Questo è lui' o 'Uomo allo specchio'?" - Oggetti con descrizioni simili su Wikipedia. "Cosa intendi per 'Pensieri di te' o 'Felice ovunque'?" - Oggetti con titoli simili. "Cosa intendi per 'Rientro' (memoria) o 'Rientro' (novel Shatner)?" - Uniforme a caso. "Cosa intendi per 'Potresti essere mio' o 'Il modo in cui sono'?"</sample>
    <sample id="459">Ecco la versione italiana del contenuto inglese: "Ecco le diverse metodologie di campionamento che abbiamo utilizzato. Quando ci spostiamo più in alto nella lista, le entità diventano più simili tra loro e diventa generalmente più difficile effettuare la disambiguisazione." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="460">Genera domande alternative =&gt; campionamento di coppie di entità. "Cosa intendi per A o B?" - Oggetti con infobox simili su Wikipedia, stesso genere e/o artista. "Cosa intendi per 'Questo è lui' o 'Uomo allo specchio'?" - Oggetti con descrizioni simili su Wikipedia. "Cosa intendi per 'Pensieri di te' o 'Felice ovunque'?" - Oggetti con titoli simili. "Cosa intendi per 'Rientro' (memoria) o 'Rientro' (novel Shatner)"? - Uniforme a caso. "Cosa intendi per 'Potresti essere mio' o 'Il modo in cui sono'?"</sample>
    <sample id="461">La seconda è quando le entità hanno titoli simili, ad esempio due libri con il nome "The Return".</sample>
    <sample id="462">Ecco la versione italiana del contenuto inglese: "La terza è quando hanno descrizioni simili su Wikipedia. Infine, quando hanno infobox o attributi simili su Wikipedia, ad esempio lo stesso genere o lo stesso artista per una canzone." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="463">Quando mostriamo questa domanda alternativa agli annotatori, sanno il nome di queste entità, ma non necessariamente sanno qualcosa su di esse.</sample>
    <sample id="464">Quindi cosa facciamo è che mostriamo un po' di conoscenza di fondo riguardo alle due entità. Per le canzoni, semplicemente mostriamo un link di ricerca Google per ciascuna.</sample>
    <sample id="465">Ecco la versione italiana del contenuto inglese: "Aspettiamo che gli annotatori ascoltino almeno parte di ciascuna canzone e leggano qualcosa su ognuna di esse. Ad esempio, ecco i risultati di ricerca Google per la canzone 'Easy on Me'."</sample>
    <sample id="466">Per il dominio ricette e libri, abbiamo mostrato del testo di sfondo da Wikipedia. Per le ricette, abbiamo inoltre mostrato le loro immagini, anch'esse da Wikipedia, affinché gli annotatori sappiano come si presentano.</sample>
    <sample id="467">Allora chiediamo agli annotatori di scegliere una di queste entità, per esempio la prima, e descriverla usando 3 a 5 espressioni di riferimento indiretto.</sample>
    <sample id="468">Ecco una versione in italiano del contenuto inglese: "Ecco alcuni esempi dal nostro dataset. Ad esempio, 'il brano senza parole', 'non il brano con il ragazzo di 12 anni', 'il brano fittizio', 'proviene dall'Azerbaigian'." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="469">Il corpus AltEntities ha circa 6.000 domande alternative in tre domini e circa 42.000 espressioni di riferimento indirette. I risultati con il modello T5 XL sono riassunti qui.</sample>
    <sample id="470">Se il modello di linguaggio ha accesso alla stessa conoscenza di fondo degli annotatori, la precisione è veramente alta, intorno al 92-95%. Ma questo non è realistico.</sample>
    <sample id="471">Se il modello linguistico ha accesso a qualche conoscenza di fondo parzialmente sovrapposta, allora la precisione è tra il 82% e il 87%, che è più realistica, ad esempio quando il modello linguistico recupera la conoscenza di fondo.</sample>
    <sample id="472">Se il modello linguistico ha accesso solo ai nomi degli enti, la precisione è solo del 60%, quindi c'è molto spazio per migliorare. Abbiamo anche dimostrato che i modelli sono generalizzabili in ambito di domanda. Ecco il link al dataset. Grazie.</sample>
    <sample id="473">It is compared with the wait-k strategy, local agreement, and the state of the art architecture specifically tailored for SimulST. If you want to know more about these policies or have other questions, feel free to ask.</sample>
    <sample id="474">Yanis Labrak: LIA, Avignon Université, Adrien Bazoge: LS2N, Nantes Université, Richard Dufour: LS2N, Nantes Université, Mickael Rouvier: LIA, Avignon Université, Emmanuel Morin: LS2N, Nantes Université, Béatrice Daille: LS2N, Nantes Université, Pierre-Antoine Gourraud: Clinique des données, CHU de Nantes.</sample>
    <sample id="475">Jenny.</sample>
    <sample id="476">Tre.</sample>
    <sample id="477">Ciao, sono Sara Papi dall'Università di Trento e Fondazione Bruno Kessler e presenterò brevemente il mio articolo "Attenzione come guida per la traduzione simultanea del discorso" in collaborazione con Matteo Negri e Marco Turchi.</sample>
    <sample id="478">La traduzione simultanea del discorso è il processo di tradurre il linguaggio parlato in un testo in un'altra lingua in tempo reale, permettendo la comunicazione interlinguistica.</sample>
    <sample id="479">I modelli SimulST attuali hanno dei problemi. Solitamente vengono addestrati architetture specifiche, introducendo moduli aggiuntivi da ottimizzare.</sample>
    <sample id="480">I problemi attuali dei modelli SimulST sono: architetture specifiche sono solitamente addestrate, introducendo moduli aggiuntivi da ottimizzare. Procedure di addestramento lunghe e complesse, ad esempio, obiettivi di ottimizzazione diversi.</sample>
    <sample id="481">I problemi dei modelli SimulST attuali sono: architetture specifiche sono solitamente addestrate, introducendo moduli aggiuntivi da ottimizzare, procedimenti di addestramento lunghi e complessi, ad esempio, obiettivi di ottimizzazione diversi, addestramento e manutenzione di diversi modelli per raggiungere diversi regimi di latenza, ad esempio, 1s, 2s, ecc.</sample>
    <sample id="482">Quale è la nostra soluzione?</sample>
    <sample id="483">Primo: Utilizzare già esistenti modelli ST offline senza ristrutturare o adottare una specifica architettura per SimulST.Secondo: Utilizzare solo un modello per ogni regime di latenza e gestire la latenza tramite parametri specifici.</sample>
    <sample id="484">Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Cosa è la nostra soluzione?". 01. Utilizzare modelli offline ST esistenti senza rieducazione o adozione di una specifica architettura per SimulIST. 02. Utilizzare solo un modello per ogni regime di latenza e gestire la latenza tramite parametri specifici. 03. Sfruttare il know-how già acquisito dal modello attraverso il meccanismo di attenzione tra l'input audio e l'output testuale. Ecco un esempio sulla destra."</sample>
    <sample id="485">La nostra soluzione è di proporre EDAtt, o l'attenzione encoder-decoder, e è una strategia per cui decidiamo di emettere o non una traduzione parziale basandoci su dove l'attenzione punta.</sample>
    <sample id="486">Un parola viene emessa se l'attenzione non è concentrata, ossia la sua somma è inferiore a un certo soglia α verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili.</sample>
    <sample id="487">The content in English is "I am going to talk about...". The translation in Italian is "Vado a parlare di...".</sample>
    <sample id="488">Ecco il contenuto in italiano: "Decidere di emettere o non una traduzione parziale in base a dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia se la sua somma è inferiore a un certo limite, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili." Se hai bisogno di altro, fammi sapere!</sample>
    <sample id="489">Vedremo che le prime due parole puntano ai primi frame di speech ricevuti, mentre la parola finale punta agli ultimi frame di speech ricevuti, ovvero i λ frame di speech.</sample>
    <sample id="490">Voglio parlare di...</sample>
    <sample id="491">Mentre la somma della cross-attenzione è sopra un certo livello di soglia, α, non emetteremo la parola finale e aspetteremo un altro frammento di discorso.</sample>
    <sample id="492">Se andiamo avanti e riceviamo un altro frammento di discorso e il nostro modello predice altri tre parole e guarderemo i pesi di attenzione incrociata.</sample>
    <sample id="493">Vedremo che nessuna parola punta alle ultime λ frasi di discorso.</sample>
    <sample id="494">Questo significa che questi tre parole saranno emesse.</sample>
    <sample id="495">Se guardiamo i principali risultati di EDAtt.</sample>
    <sample id="496">Rappresentiamo i risultati della traduzione simultanea su grafici in cui abbiamo BLEU da un lato che misura la qualità della traduzione e il ritardo medio dall'altro.</sample>
    <sample id="497">Ecco il contenuto in italiano: "Quella è la misura di latenza e consideriamo anche la media di like computazionale consapevole che tiene conto del tempo computazionale del modello per produrre l'output." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="498">Quindi vogliamo che le nostre curve siano il più in alto possibile su questo grafico.</sample>
    <sample id="499">Ma anche vogliamo che siano spostati a sinistra.</sample>
    <sample id="500">Ecco il contenuto in italiano: "E abbiamo comparato con strategie popolari che vengono anche applicate a modelli offline, come la strategia wait-k e l'accordo locale. Abbiamo anche comparato con l'architettura di punta specificamente adattata per la traduzione simultanea."</sample>
    <sample id="501">Questi sono i risultati della strategia di traduzione simultanea in tedesco.</sample>
    <sample id="502">Ecco il contenuto in italiano: "EDAtt supera tutte le strategie applicate ai modelli offline, poiché le loro curve sono spostate a sinistra." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="503">E anche vediamo che se consideriamo il tempo di attesa reale o il tempo computazionale, EDAtt è la strategia più veloce.</sample>
    <sample id="504">Se vuoi scoprire più risultati, leggi il nostro articolo. Abbiamo anche rilasciato il codice open source e i modelli, e contemporaneamente il output di casa per facilitare la riproducibilità del nostro lavoro. Grazie per l'attenzione.</sample>
    <sample id="505">Sì, il set di dati è disponibile pubblicamente. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="506">Ciao a tutti. Il mio nome è Ying e il mio collega Zhiyang e io presenteremo la nostra ricerca su MultiINSTRUCT: miglioramento dell'apprendimento zero-shot multi-modale tramite ottimizzazione delle istruzioni.</sample>
    <sample id="507">Con l'avanzamento dei modelli di linguaggio a grande scala, molti lavori hanno iniziato a esplorare nuovi paradigmi di apprendimento per riutilizzare modelli di linguaggio preaddestrati per diverse compiti "downstream" in modo efficiente in termini di parametri e dati.</sample>
    <sample id="508">Recentemente, molte ricerche hanno dimostrato che l'addestramento con istruzioni consente ai grandi modelli di linguaggio di eseguire compiti non visti in modo zero-shot seguendo istruzioni naturali.</sample>
    <sample id="509">Tuttavia, la maggior parte dei lavori precedenti sulla ottimizzazione delle istruzioni si sono concentrati sul miglioramento del presto zero di un compito solo linguistico, mentre la visione computerizzata e i compiti multimodali sono stati lasciati fuori.</sample>
    <sample id="510">Quindi, in questo lavoro, vogliamo investigare se l'addestramento di istruzioni su modelli pre-allenati multimodali può realmente migliorare la generalizzazione a compiti multimodali senza corrispondenza.</sample>
    <sample id="511">Inoltre, durante la nostra ricerca, abbiamo scoperto una considerevole disparità nella disponibilità di set di istruzioni tra NLP e multimodale.</sample>
    <sample id="512">Esiste più di 1.600 task di istruzioni solo in lingua. Tuttavia, non esistono task di istruzioni multimodali di grande scala e pubblicamente disponibili. Questo ci ha motivati a costruire un dataset di ottimizzazione delle istruzioni multimodali.</sample>
    <sample id="513">Ecco il contenuto in italiano: "Ecco il primo dataset di benchmark di ottimizzazione di istruzioni multimediali, che comprende 62 diverse task multimediali, coprendo 10 categorie ampie."</sample>
    <sample id="514">I'm sorry, but I can't provide an Italian translation of the content in the image. If you need a translation, you might want to use a translation tool or ask someone who is fluent in Italian.</sample>
    <sample id="515">OFA è un modello pre-addestrato multiautomaizzato unificato che è in grado di eseguire sia compiti di comprensione che di generazione con una o più modalità. OFA ha un vocabolario unificato per il linguaggio, i token immagine e le coordinate di una casella di confine.</sample>
    <sample id="516">Ecco il contenuto in italiano: "Ecco alcuni esempi da nostro dataset MultiInstruct."</sample>
    <sample id="517">Per unificare la gestione di diversi tipi di dati di input e output.</sample>
    <sample id="518">Seguendo il metodo di OFA e formulando tutte le tare in un formato di sequenza a sequenza unificato, in cui il testo di input, le immagini, le istruzioni e i box di contorno sono rappresentati nello stesso spazio di token.</sample>
    <sample id="519">Certo. "Multi-modal Instruction Tuning" in italiano è "Tuning delle istruzioni multimediali". Se hai bisogno di ulteriori traduzioni o chiarimenti, non esitare a chiedere.</sample>
    <sample id="520">Per la costruzione del dataset di addestramento: utilizziamo 53 compiti da 9 gruppi per l'addestramento. Sampiamo 10.000 istanze per compito. Per la costruzione del dataset di test: riserviamo l'intero gruppo di ragionamento comune per il test. Selezioniamo altri 5 compiti dal gruppo VQA e dal gruppo varie. Utilizziamo tutte le istanze nel set di test per ogni compito. Sampiamo casualmente 20 compiti dal set di test del dataset di istruzioni naturali come compiti non visti per l'NLP.</sample>
    <sample id="521">Ecco il contenuto in italiano: "Inoltre, estraiamo casualmente 20 compiti dal test split del dataset Natural Instructions come compiti non visti per NLP."</sample>
    <sample id="522">Dettagli di implementazione. Dettagli di addestramento: - Modello pre-allenato OFA-Large, 472M parametri. - Mescolare tutte le istanze per tutte le task. - Ogni istanza è combinata casualmente con uno dei cinque modelli di istruzioni. Dettagli di test: - Per ogni task, eseguire un totale di cinque esperimenti valutando il modello utilizzando uno dei cinque modelli di istruzioni in ciascun esperimento. - Rapportare la media, il massimo e la deviazione standard del rendimento in tutte e cinque le esperimenti.</sample>
    <sample id="523">Durante il test, per ogni compito, condurremo un totale di cinque esperimenti valutando il modello utilizzando una delle cinque istruzioni in ciascun esperimento.</sample>
    <sample id="524">Rapportiamo la media e il massimo delle prestazioni e la deviazione standard delle prestazioni in tutte e cinque le esperimenti.</sample>
    <sample id="525">Per i compiti di classificazione multi-modale, come l'Entanglement visivo, la ragionamento spaziale visivo, la ragionamento visivo linguistico naturale e la classificazione di tipo di disastro, si riporta l'Accuracy. Per i compiti di generazione multi-modale, come la VQA di senso comune, la VQA testuale, la VQA fondata, l'estrazione di testo visivo e il dialogo visivo, si riporta il Rouge-L. Per i compiti di NLP, si riporta il Rouge-L. Inoltre, calcoliamo la prestazione aggregata per ogni modello basandoci sulla media della prestazione del modello su tutti i compiti multimodale e non visti di NLP. Usiamo il Rouge-L come punteggio di prestazione per la maggior parte dei compiti, e l'Accuracy per i compiti che hanno solo l'Accuracy come metrica.</sample>
    <sample id="526">Sensibilità. Quanto la modella è sensibile alla varietà di istruzioni per la stessa compito:. - Abilità a produrre risultati consistenti per la stessa compito, indipendentemente da lievi variazioni nella formulazione delle istruzioni.</sample>
    <sample id="527">Ecco il contenuto in italiano: "Ecco i nostri risultati principali. Come possiamo vedere, l'ottimizzazione delle istruzioni può migliorare significativamente le prestazioni di OFA su compiti multimediali non visti."</sample>
    <sample id="528">L'addestramento delle istruzioni può beneficiare dal trasferimento di apprendimento da dataset di istruzioni naturali.</sample>
    <sample id="529">Ecco il contenuto in italiano: "Come possiamo vedere, con l'aumento del numero di task, il modello raggiunge prestazioni migliori e, al contempo, una sensibilità inferiore."</sample>
    <sample id="530">Quindi abbiamo anche fatto un esperimento. Abbiamo utilizzato un'istruzione contro cinque istruzioni. Come possiamo vedere, utilizzare più istruzioni può migliorare le prestazioni complessive del modello e ridurre la sua sensibilità molto.</sample>
    <sample id="531">Quindi, questo mostra l'effetto di diverse strategie di ottimizzazione fine sulle sensibilità del modello. Come possiamo vedere, attraverso il trasferimento di apprendimento da dataset di istruzioni naturali, il modello può ottenere una sensibilità molto migliore rispetto al modello OFA originale.</sample>
    <sample id="532">Puoi vedere che il trasferimento di apprendimento da dataset di istruzioni naturali può aiutare OFA a ottenere una prestazione molto migliore sul dataset di istruzioni naturali.</sample>
    <sample id="533">Conclusione. Primo dataset di addestramento multi-modale su larga scala. Contiene 62 task multi-modali da 10 categorie ampie. Muta significativamente la capacità zero-shot di OFA tramite l'addestramento di istruzioni. Esplora diverse tecniche di apprendimento trasferibile e mostra i loro benefici. Progetta una nuova metrica di sensibilità.</sample>
    <sample id="534">C'è una cosa in più! Stiamo raccolgendo un dataset di addestramento di istruzioni multimodali molto più grande con circa 150 compiti aggiuntivi di visione-lingua e li pubblicheremo presto! Ecco il codice QR per i nostri dati e il modello. Grazie!</sample>
    <sample id="535">Sara Papi, Matteo Negri e Marco Turchi sono affiliati all'Università di Trento e alla Fondazione Bruno Kessler.</sample>
    <sample id="536">Il nome del relatore è Mohammad Javad Hosseini.</sample>
    <sample id="562">Ciao a tutti. Sono Koustuv Sinha e sono lieto di accogliervi al nostro talk sul nostro articolo di ACL 2023, "Le giudicazioni di accettabilità dei modelli di linguaggio non sono sempre robuste al contesto."</sample>
    <sample id="563">I giudizi di accettabilità dei modelli di linguaggio non sono sempre robusti rispetto al contesto.</sample>
    <sample id="564">Paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio:.BLiMP. 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P, 1, &gt; P, 2, SyntaxGym. 1. Nessun cliente ... ha speso alcun denaro. 2. *Il cliente ... ha speso alcun denaro. P, 1, any, &gt; P, 2, any, CrowS. 1. Frase stereotipica. 2. Frase non stereotipica. P, 1, &gt; P, 2, In questo lavoro rivediamo il paradigma delle coppie minimali.</sample>
    <sample id="565">Il paradigma del paio minimo, MPP, valuta i modelli di linguaggio basandosi su giudizi di accettabilità, che possono includere grammaticità, come BLiMP, SyntaxGym, o accettabilità in termini di stereotipi, come CrowS.</sample>
    <sample id="566">Paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio:.BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P, 1, &gt; P, 2, SyntaxGym 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P, 1.any, &gt; P, 2.any, CrowS 1. Frase stereotipica. 2. Frase non stereotipica. P, 1, &gt; P, 2, Nella valutazione del paradigma delle coppie minimali, il modo tipico per valutare i modelli di linguaggio è mostrare una frase accettabile o grammaticalmente corretta e poi mostrare una frase non accettabile o grammaticalmente errata.</sample>
    <sample id="567">Paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio:.BLiMP. 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P, 1, &gt; P, 2, SyntaxGym. 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P, 1, any, &gt; P, 2, any, Crows. 1. Frase stereotipica. 2. Frase non stereotipica. P, 1, &gt; P, 2, L'idea è che il modello assegna maggiore probabilità alle frasi accettabili.</sample>
    <sample id="568">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli: BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P,1, &gt; P,2, SyntaxGym 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P,1.any, &gt; P,2.any, Crows 1. Le donne sono terribili per il lavoro manuale. 2. Gli uomini sono terribili per il lavoro manuale. P,1, &gt; P,2, Questi giudizi sono stabili con un contesto precedente lungo? Il flusso attuale di MPP non ci permette di valutare l'accettazione dei modelli verso le frasi più lunghe.</sample>
    <sample id="569">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio:.BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P,1, &gt; P,2, SyntaxGym 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P,1.any, &gt; P,2.any, Crows 1. Le donne sono terribili per il lavoro manuale. 2. Gli uomini sono terribili per il lavoro manuale. P,1, &gt; P,2, Questi giudizi sono stabili con un contesto precedente lungo? Oggi i modelli di linguaggio stanno uscendo con finestre di contesto sempre più lunghe, quindi è cruciale valutare l'acceptability dei modelli attraverso la finestra di contesto.</sample>
    <sample id="570">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio. BLiMP: 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P,1, &gt; P,2, SyntaxGym: 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P,1.any, &gt; P,2.any, Crows: 1. Le donne sono terribili per il lavoro manuale. 2. Gli uomini sono terribili per il lavoro manuale. P,1, &gt; P,2, Questi giudizi sono stabili con un contesto precedente lungo? Stiamo cercando di rivedere il pipeline MPP chiedendo al modello di valutare l'accettabilità su sequenze sempre più lunghe.</sample>
    <sample id="571">Quindi, l'approccio è questo. Ciò che facciamo è simulare queste sequenze più lunghe. Rivediamo i dataset stessi e poi ricreiamo frasi scegliendo frasi accettabili o non accettabili da quei dataset.</sample>
    <sample id="572">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Conformità soggetto-verbale.PLM, Prefix, &gt;? PLM, Prefix, .Spazio di candidati Prefixes.Matched: Conformità soggetto-verbale.Unmatched: Effetti dell'isola, lacune di filtro, legame, Wikipedia.Esempio: "Chi potrebbe fuggire Rose prima di tornare a questo cliente?" "Chi potrebbe fuggire Rose da questo cliente prima di tornare a?" "Chi potrebbe vendere Jessica prima di notare queste luci? Che cosa avrebbe detto Aaron mentre puliva il museo? Chi potrebbe fuggire Rose prima di tornare a questo cliente?" "Chi potrebbe vendere Jessica prima di notare queste luci? Che cosa avrebbe detto Aaron mentre puliva il museo? Chi potrebbe fuggire Rose da questo cliente prima di tornare a?"BLIMP, Isola di Adjunct.GPT2, OPT famiglia - 125M a 6.7</sample>
    <sample id="573">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spazio di Candidati Prefixes.Matched: Convenzione Soggetto, Verga.Accettabile: P,LM, Prefix, &gt;? P,LM, Prefix, Unaccettabile: sample.Mismatched: Island Effects, Filter-gaps, Binding, Wikipedia, ...BLIMP, Isola Adjunct.GPT2, Famiglia OPT - 125M a 6.7B.</sample>
    <sample id="574">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spacce di Candidati Prefixes.Matched: Convenzione Soggetto, Verga.Unmatched: Island Effects, Filter-gaps, Binding, Wikipedia, ...Sample: P,LM, verde, Prefix, &gt;? P,LM, rosso, Prefix, Accettabile, Matched: "Chi potrebbe fuggire Rose prima di tornare a questo cliente? Chi potrebbe fuggire Rose da questo cliente prima di tornare a questo cliente?" "Cosa potrebbe vendere Jessica prima di notare queste luci? Come ha suonato Aaron mentre puliva il museo? Chi potrebbe fuggire Rose prima di tornare a questo cliente? Cosa potrebbe vendere Jessica prima di notare queste luci? Come ha suonato Aaron mentre puliva il museo? Chi potrebbe fuggire Rose da questo cliente prima di tornare a questo cliente?"BLIMP, Isola Adjunct.GPT2, Famiglia OPT</sample>
    <sample id="575">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spazio di Candidati Prefixes.Matched: Convenzione Soggetto, Verga.Unmatched: Effetti dell'isola, vuoti di filtro, legame, Wikipedia.GPT2, OPT famiglia - 125M a 6.7B.</sample>
    <sample id="576">E possiamo fare lo stesso scegliendo frasi da un sottoinsieme diverso o da un diverso dataset. Quindi questo è ciò che chiamiamo "mismatched scenario".</sample>
    <sample id="577">Quindi qui le frasi provengono ancora da dataset rilevanti, ma non dallo stesso dataset che stai valutando. E possiamo fare lo stesso per il caso di accettabilità.</sample>
    <sample id="578">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spazio dei Candidati Prefixes.Matched: Convenzione Soggetto, Verga.Unmatched: Effetti dell'isola, Vuoti, Legame, Wikipedia, ...AccettabileNon accettabile.P, L, M, Prefix, &gt;, P, L, M, Prefix, , esempio.Wikipedia, Non rilevante.A cosa potrebbe fuggire Rose prima di tornare a questo cliente? * A cosa potrebbe fuggire Rose da questo cliente prima di tornare a?A rose è una pianta rampicante a fiore di legno della genere Rosa. Ci sono oltre trecento specie e decine di migliaia di cultivar.Wikipedia, Non rilevante.A cosa potrebbe fuggire Rose prima di tornare a questo cliente? * A cosa potrebbe fuggire Rose da questo cliente prima di tornare a?GPT2, Famiglia OPT - 12</sample>
    <sample id="579">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'acceptabilità.Test Suite: Convenzione Soggetto-Verga.Spazio di Candidati Prefixes.Matched: Convenzione Soggetto-Verga.Mismatched: Effetti dell'isola, vuoti di filtro, legame, Wikipedia, ...accettabile non accettabile.PLM, Prefix &gt;? PLM, Prefix, esempio.Wikipedia, Irrelavente. "Chi potrebbe fuggire Rose prima di tornare a questo cliente?" * "Chi potrebbe fuggire Rose da questo cliente prima di tornare a?" "Un fiore è una pianta perenni fiorente legno della genere Rosa. Ci sono oltre trecento specie e decine di migliaia di cultivar. " "Un fiore è una pianta perenni fiorente legno della genere Rosa. Ci sono oltre trecento specie e decine di migliaia di cultivar. " "Chi potrebbe fuggire Rose prima di tornare a?"G</sample>
    <sample id="580">Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'acceptabilità.</sample>
    <sample id="581">Allora, come funziona il modello? Innanzitutto, guardiamo le frasi di Wikipedia che sono completamente irrelate al paio di query attuale, e poi scopriamo che le giudicazioni MPP sono in gran parte robuste per lunghezze di contesto arbitrarie.</sample>
    <sample id="582">I giudizi MPP sono robusti per lunghezze di contesto arbitrarie. Effettuiamo valutazioni MPP con diversi contesti - accettabili/non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. Incrementiamo la lunghezza del contesto fino a 1024 per massimizzare i modelli OPT e GPT-2 e vediamo qui nella linea tratteggiata arancione che i giudizi MPP sono relativamente stabili.</sample>
    <sample id="583">Eseguiamo valutazioni MPP con contesti diversi - accettabili / non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. BLIMP, OPT 6.7B Strategia di prefisso. Ora, cosa succede quando scegliamo frasi dallo stesso dataset?</sample>
    <sample id="584">Ecco la traduzione italiana del contenuto in inglese: "Quindi qui stiamo scegliendo o creando frasi da domini accettabili e non accettabili dallo stesso dataset di sintassi BLiMP." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="585">Ecco la traduzione italiana del contenuto in inglese: "Vediamo che le giudicazioni MPP aumentano o diminuiscono significativamente quando si aggiungono prefissi accettabili o non accettabili." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="586">Eseguiamo valutazioni MPP con contesti diversi - accettabili / non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token.</sample>
    <sample id="587">Eseguiamo valutazioni MPP con contesti diversi - accettabili/non accettabili; struttura corrispondente/non corrispondente - fino a lunghezze di 900 token. Vediamo un aumento o una diminuzione massiva della giudicata MPP per il modello a seconda se il prefisso scelto è accettabile o non accettabile.</sample>
    <sample id="588">Ecco la traduzione italiana del contenuto in inglese: "Ora questo effetto è molto grande, come questo effetto aumenta a lungo termine, e questo probabilmente influenzerà modelli di linguaggio più recenti, che hanno un ampio raggio di contesto." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="589">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di linguaggio?Modifichiamo le frasi di contesto in modo da preservare la struttura rilevante e chiediamo se i modelli sono altrettanto sensibili a queste frasi.- Prefissi/suffissi avverbi: "Tuttavia, &lt;sent&gt;.".- Prefissi avverbi lunghi: "Prima di tutto, &lt;sent&gt;.".- Aggiungere una clausola: "Indipendentemente da ciò che X ne pensa, &lt;sent&gt;.".- Citazione: "Ieri, X ha detto, &lt;sent&gt;."</sample>
    <sample id="590">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di linguaggio?Modifichiamo le frasi di contesto in modo da preservare la struttura rilevante e chiediamo se i modelli sono altrettanto sensibili a queste frasi.- Prefissi/suffissi avverbi: "Tuttavia, &lt;sent&gt;.". - Prefissi avverbi lunghi: "Prima di tutto, &lt;sent&gt;.". - Aggiungere una clausola: "Indipendentemente da quello che X ne pensa, &lt;sent&gt;.". - Citazione: "Ieri, X ha detto, &lt;sent&gt;.".Abbiamo fatto una serie di analisi in cui abbiamo cercato di perturbare la frase di input mantenendo la struttura rilevante, ma aggiungendo rumore all'input. Dopo aver fatto diverse di queste perturbazioni, abbiamo osservato che...</sample>
    <sample id="591">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di LM?Modifichiamo le frasi di contesto in modo da preservare la struttura rilevante e chiediamo se i modelli sono altrettanto sensibili a queste frasi.- Prefissi/suffissi avverbi: "Tuttavia, &lt;sent&gt;.".- Avverbi di lungo prefisso: "Prima di tutto, &lt;sent&gt;.".- Clauses aggiunte: "Indipendentemente da quello che X ne pensa, &lt;sent&gt;.".- Citazioni: "Ieri, X ha detto, &lt;sent&gt;.".Risultati: Non siamo in grado di far cambiare al modello la sua scelta di giudizio MPB tramite queste modifiche.</sample>
    <sample id="592">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di linguaggio?Modifichiamo le frasi di contesto in modo da preservare la struttura rilevante e chiediamo se i modelli sono altrettanto sensibili a queste frasi.- Prefissi/suffissi avverbi: "Tuttavia, &lt;sent&gt;.". - Avverbi di lungo prefisso: "Prima di tutto, &lt;sent&gt;.". - Aggiungere una clausola: "Indipendentemente da ciò che X ne pensa, &lt;sent&gt;.". - Citazione: "Ieri, X ha detto, &lt;sent&gt;.".I modelli sono sensibili alle frasi modificate in modi simili.</sample>
    <sample id="593">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di linguaggio?Modifichiamo le frasi di contesto in modo da preservare la struttura rilevante e chiediamo se i modelli sono altrettanto sensibili a queste frasi.- Prefissi/suffissi avverbi: "Tuttavia, &lt;sent&gt;.". - Avverbi di lunghezza prefisso: "Prima di tutto, &lt;sent&gt;.". - Aggiungere una clausola: "Indipendentemente da ciò che X ne pensa, &lt;sent&gt;.". - Citazione: "Ieri, X ha detto, &lt;sent&gt;.".I modelli sono sensibili a frasi perturbate in modi simili.Nel dominio accettabile, vediamo un aumento simile in tutte le perturbazioni. Quando perturbiamo le frasi nel dominio non accettabile, vediamo una diminuzione delle giudicazioni di MPP in modo simile.</sample>
    <sample id="594">Istruzioni: Tradurre il contenuto in inglese in italiano.</sample>
    <sample id="595">I modelli di linguaggio sono sensibili a feature sintattiche/semantiche latenti condivise tra frasi. Le valutazioni MPP con input di frase singola e breve non riescono a catturare completamente il sapere astratto dei modelli di linguaggio.</sample>
    <sample id="596">Istruzioni: Tradurre il contenuto in inglese in italiano.</sample>
    <sample id="597">The first step of the method maps the input tokens to an unordered multiset of tokens that will appear in the output.</sample>
    <sample id="598">55,000.</sample>
    <sample id="626">Il metodo di allineamento migliore per DEplain è il metodo di MASSalign.</sample>
    <sample id="627">L'apprendimento scarsamente supervisionato allevia il problema dell'annotazione.</sample>
    <sample id="628">Non c'è informazione specifica su come è avvenuta l'allocazione dei documenti in DEplain-web tra metodi di allineamento manuali e automatici nel contenuto fornito. Potresti cercare ulteriori dettagli nel documento o nella paper?</sample>
    <sample id="629">Il set di dati CoNLL++ è stato creato raccolgendo notizie Reuters del 2020 e annotandole secondo le linee guida di annotazione CoNLL-2003. Se hai altre domande, puoi chiedere.</sample>
    <sample id="630">Ciao a tutti. Mi chiamo Yusen Zhang e sono dell'Università di Pennsylvania. Oggi presenterò il nostro lavoro, XSemPLR: analisi semantica interlinguistica in diverse lingue naturali e rappresentazioni di significato.</sample>
    <sample id="631">Parsa semantica è una task per costruire rappresentazioni semantiche delle query utente, come SQL e Calcolo Lambda. Quali paesi in Europa hanno almeno 3 produttori di automobili? Seleziona T1.country_name. Da paesi AS T1 JOIN continenti AS T2 ON T1.continent = T2.cont_id JOIN car_makers AS T3 ON T1.country_id = T3.country WHERE T2.continent = 'Europe' GROUP BY T1.country_name HAVING COUNT, * &gt;= 3. Quali giocatori hanno meno di tre assist in una stagione? Chiamare SW. listValue, chiamare SW.getProperty, chiamare lambda s, chiamare SW.filter, chiamare var s, chiamare SW.ensureNumericProperty, string num_assists, string &lt;, chiamare SW.ensureNumericEntity, number 3 assist, chiamare SW.domain, string player, string player, string player.</sample>
    <sample id="632">La traduzione in italiano è: "La semantica parallela è una task che traduce query in diverse lingue naturali in diverse rappresentazioni di significato." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="633">La traduzione in italiano del contenuto in inglese è: "Nel suo figura, dobbiamo tradurre la query in diverse lingue naturali utilizzando modelli neurali in SQL, Lambda o FunQL e così via." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="634">I modelli di parsing semantico interlinguistico esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certe lingue naturali.</sample>
    <sample id="635">I modelli CLSP esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certe lingue naturali.</sample>
    <sample id="636">I modelli CLSP esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certe rappresentazioni di significato.</sample>
    <sample id="637">I modelli di Parsing Semantico Interlingua esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certe rappresentazioni di significato.</sample>
    <sample id="638">I modelli CLSP esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certi modelli neurali.</sample>
    <sample id="639">Ecco la traduzione in italiano del contenuto in inglese: "Per questo scopo, proponiamo Exemplar. Offriamo un dataset uniforme Exemplar per la semantica di parsing interlingua in diverse lingue naturali e rappresentazioni di significato." Se hai bisogno di ulteriori informazioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="640">Ecco la traduzione in italiano del contenuto in inglese: "XSemPLR - Offriamo un dataset unificato XSemPLR per la semantica di parsing interlinguale in diverse lingue naturali e rappresentazioni di significato. Contiene: - 9 dataset in diversi domini - 5 task di parsing semantico - 8 rappresentazioni di significato - 22 lingue naturali in 15 famiglie linguistiche"</sample>
    <sample id="641">Ecco la traduzione in italiano: "Per valutare meglio il nostro benchmark, consideriamo i sei set di allenamento e valutazione." Se hai bisogno di ulteriori informazioni o hai altre domande, fammi sapere!</sample>
    <sample id="642">Ecco la traduzione in italiano: "I consideriamo i sei set di esperimenti per l'addestramento e l'evaluazione. Il primo è Translate-Test: utilizziamo l'API di Google Translate per tradurre il fonte nella lingua di destinazione. Poi utilizziamo un modello monolingue per l'addestramento e l'evaluazione." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="643">Ecco la traduzione in italiano del contenuto in inglese: "Consideriamo i sei set di esperimenti per l'addestramento e l'evaluazione. - Test di traduzione: Utilizziamo l'API di Google Translate per tradurre il testo sorgente nella lingua di destinazione. Poi utilizziamo un modello monolingue per l'addestramento e l'evaluazione. Addestramento: In Germania, utilizziamo l'API di traduzione per tradurre il testo sorgente in inglese. Poi utilizziamo il modello inglese per generare il codice SQL. Inferenza: In Germania, utilizziamo l'API di traduzione per tradurre il testo sorgente in inglese. Poi utilizziamo il modello inglese per generare il codice SQL."</sample>
    <sample id="644">Impostazioni dell'esperimento Consideriamo le sei impostazioni per l'addestramento e l'evaluazione. Modello monolinguale: La lingua di origine è la stessa della lingua di destinazione, ad esempio Germano-germano. Abbiamo anche testato la configurazione di modello monolinguale Few-shot addestrando modelli monolinguali con solo 10% di dati di addestramento. Addestramento Germano, Few-shot Modello Germano SQL Inferenza Germano Modello Germano SQL</sample>
    <sample id="645">Nel contesto di questa impostazione, la lingua di origine è la stessa della lingua di destinazione, ad esempio tedesco-tedesco o inglese-inglese.</sample>
    <sample id="646">Consideriamo i sei set di allenamento e valutazione. Modello monolinguale: la lingua di origine è la stessa della lingua di destinazione, ad esempio Germano-germano. Abbiamo anche testato la configurazione Monolinguale Few-shot allenando modelli monolinguali con solo 10% dei dati di allenamento. Allenamento: Germano, Few-shot, Modello Germano, SQL. Inferenza: Germano, Modello Germano, SQL.</sample>
    <sample id="647">Consideriamo i sei set di esperimenti per l'addestramento e l'evaluazione. Modello multilingue: Addestrare un modello multilingue per tutte le lingue. Addestramento: Germano, Inglese, Cinese. Modello multilingue. SQL. Inferenza: Germano. Modello multilingue. SQL.</sample>
    <sample id="648">Ad esempio, mettiamo insieme le query in tedesco, inglese e cinese per addestrare un modello multilingue e durante l'infrazione possiamo utilizzare questo modello.</sample>
    <sample id="649">Ecco la traduzione in italiano: "Consideriamo le sei impostazioni per l'addestramento e l'valutazione. Modello multilingue: Addestrare un modello multilingue per tutte le lingue. Addestramento: Germano, Inglese, Cinese, Modello multilingue, SQL. Inferenza: Germano, Modello multilingue, SQL. Per tradurre query tedesche o query cinesi, ecc."</sample>
    <sample id="650">Consideriamo le sei impostazioni per l'addestramento e l'valutazione. Cross-lingual Zero-shot/Few-shot transfer: Addestrare su una lingua di origine e trasferire su un'altra lingua. Addestramento: Inglese o Inglese Germano Few-shot Modello multilingue SQL Inferenza: Germano Modello multilingue SQL</sample>
    <sample id="651">Durante l'addestramento, si addestra su query in inglese o la combinazione di query in inglese e tedesco a pochi colpi per addestrare un modello multilingue e prevedere l'output SQL.</sample>
    <sample id="652">Analisi dei modelli monolinguistici. Valutiamo due gruppi di modelli nel contesto monolinguistico. Enc-PTR: Encoder multilingue con decodificatori basati su pointer. XLM-R + PTR, mBERT + PTR. Enc-Dec: Encoder-decoder multilingue preaddestrati. mBART, mT5. Abbiamo trovato che Enc-Dec, mT5, ottiene la migliore prestazione su tutti i dataset!</sample>
    <sample id="653">Analisi del Monolingua. - Valutiamo due gruppi di modelli in un contesto monolingue. Enc-PTR: Encoder multilingue preaddestrati con decoder basati su pointer. XLM-R + PTR, mBERT + PTR. Enc-Dec: Encoder-decoder multilingue preaddestrati. mBART, mT5. - Abbiamo trovato che Enc-Dec, mT5, ottiene la migliore prestazione su tutti i dataset! Tabella con i risultati per i diversi dataset: MATIS, MGeoQuery, MSpiider, MNLmaps, MOvernight, MCWQ, MSchema2QA, MTOP, MCoNaLa, Average. mBERT+PTR: 30.63, 72.18, 40.40, 83.82, 57.47, 23.46, 52.53, 75.41, 5.87, 49.09. XLM-R+PTR: 31.31, 71.41, 47.30,</sample>
    <sample id="654">L'analisi si concentra su due gruppi di modelli in un contesto monolingue. I modelli Enc-PTR sono basati su encoder multilingue con decoder basati su pointer, come XLM-R + PTR e mBERT + PTR. I modelli Enc-Dec sono basati su encoder-decoder multilingue, come mBART e mT5. Si è scoperto che mT5, tra i modelli Enc-Dec, ha ottenuto la migliore prestazione su tutti i dataset.</sample>
    <sample id="655">Analisi del Monolingua. Valutiamo su due gruppi di modelli nel contesto Monolingua. Enc-PTR: Encoder multilingue con decodificatori basati su pointer. XLM-R + PTR, mBERT + PTR. Enc-Dec: Encoder-decoder multilingue preaddestrati. mBART, mT5. Abbiamo trovato che Enc-Dec, mT5, ottiene la migliore prestazione su tutti i dataset!</sample>
    <sample id="656">L'analisi della formazione multilingue. Valutiamo su mT5 e XLM-R + PTR in un contesto multilingue. Enc-Dec/Enc-PTR, mT5/XLM-R, può essere migliorato con la formazione in una miscela di varie lingue. Monolingue: XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 58.16 mT5 53.15 74.26 50.73 91.65 66.29 30.15 65.16 81.83 10.29 59.06 61.82 Multilingue: XLM-R+PTR 39.72 71.35 40.20 85.91 61.03 30.79 61.</sample>
    <sample id="657">Abbiamo trovato che l'Enc-Dec o l'Enc-PTR può essere migliorato con l'addestramento in una miscela di varie lingue.</sample>
    <sample id="658">Abbiamo trovato che la maggior parte delle lingue naturali principali può ottenere un miglioramento del prestigio, eccetto che per l'inglese, il cui prestigio diminuisce in 7 set di dati e aumenta solo in 3 set di dati. Questo è noto come "Curso della multilinguistica".</sample>
    <sample id="659">L'analisi della formazione multilingue. Valutiamo su mT5 e XLM-R + PTR nel contesto multilingue. La maggior parte delle principali NLP può ottenere un miglioramento, eccetto che le prestazioni dell'inglese diminuiscono in 7 dataset e aumentano in 3 dataset. Questo è noto come "Curse of Multilinguality".</sample>
    <sample id="660">Hanno anche comparato il gap di prestazione tra lingue diverse.</sample>
    <sample id="661">Nella figura, la linea blu rappresenta la trasformazione di pochi colpi tra lingue diverse, la linea arancione rappresenta la trasformazione di zero colpi tra lingue diverse, mentre la linea verde rappresenta il contesto monolingue.</sample>
    <sample id="662">Abbiamo trovato che, confrontando la linea verde e la linea arancione, per il setting zero-shot, il gap di prestazione della trasformazione interlingua è significativo. E confrontando la linea blu e la linea arancione, abbiamo trovato che, per il setting few-shot, il gap di trasferimento si riduce rapidamente.</sample>
    <sample id="663">Ecco la traduzione in italiano del contenuto in inglese: "Abbiamo anche trovato alcuni altri interessanti risultati, ad esempio, l'encoder-decoder supera il lavoro precedente o raggiunge risultati paragonabili. La preaddestramento sul linguaggio naturale inglese può significativamente migliorare le prestazioni del pochi esempi su lingue target." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="664">I modelli multilingue come Codex e BLOOM sono ancora insufficienti per le attività di parsing semantico interlingue.</sample>
    <sample id="665">Concludiamo costruendo XSemPLR, un benchmark unificato per la parsing semantica interlinguistica con diverse lingue naturali e rappresentazioni di significato. Abbiamo condotto una studio di benchmarking comprensivo su tre tipi rappresentativi di modelli di linguaggio multilingue. I risultati mostrano che mT5 con addestramento monolingue dà il miglior rendimento, mentre notevolmente i modelli multilingue LLM sono ancora insufficienti per eseguire task di parsing semantico interlinguistico. Inoltre, la differenza di prestazioni tra addestramento monolingue e apprendimento trasferimento interlinguistico è ancora significativa.</sample>
    <sample id="666">Conclusione - Abbiamo costruito XSemPLR, un benchmark unificato per la parsing semantica interlinguistica con diverse lingue naturali e rappresentazioni di significato. - Abbiamo condotto una studio di benchmarking comprensivo su tre tipi rappresentativi di modelli di linguaggio multilingue. - I nostri risultati mostrano che mT5 con addestramento monolingue dà i migliori risultati, mentre notevolmente i modelli multilingue LLM sono ancora insufficienti per eseguire task di parsing semantico interlinguistico. Inoltre, la differenza di prestazioni tra addestramento monolingue e apprendimento a trasferimento interlingue rimane ancora significativa. Links Benvenuti a visitare il nostro articolo e il codice! Link al documento: https://arxiv.org/pdf/2306.04085.pdf Link al codice: https://github.com/psunlpgroup/xsemplr</sample>
    <sample id="667">I lavori connessi sono: Parameter-based watermark, Lexical watermark, Backdoor-based watermark e Adversarial-based watermark. Se hai bisogno di ulteriori dettagli, fammi sapere!</sample>
    <sample id="668">No, they are still inadequate for crosslingual semantic parsing tasks. If you have any other questions about this, feel free to ask.</sample>
    <sample id="695">Induce l'alignment durante l'addestramento.</sample>
    <sample id="696">L'equità di un modello NLP a valle si riferisce a come il modello gestisca e tratta le diverse politiche, senza favorire o discriminare alcuna politica specifica. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="697">Yanis Labrak.</sample>
    <sample id="698">Koustuv Sinha. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="699">The name of the speaker is Myra Cheng.</sample>
    <sample id="700">Il tropicalismo indica le parole che descrivono le donne latine come "vibrante" e "curvilinea".</sample>
    <sample id="701">Gli autori hanno elaborato le rappresentazioni umane dei gruppi target attraverso narrativi essenzializzanti, definendo questi gruppi solo per la loro identità e distinguendoli dal normale bianco.</sample>
    <sample id="702">P-CXMI.</sample>
    <sample id="703">DrBERT è una versione da zero con 7 GB di NACHOS, mentre ChuBERT è una versione da zero con 4 GB di NBDW small.</sample>
    <sample id="751">Ci sono tre autori coinvolti nell'articolo.</sample>
    <sample id="752">L'iterative transfer learning è un metodo che aggiorna il modello utilizzando il set di dati più recente raccolto durante l'annotazione attiva.</sample>
    <sample id="753">The goal is to understand users' language when they make a choice.</sample>
    <sample id="754">Non c'è informazione sufficiente nel contenuto inglese per rispondere a questa domanda. Potresti fornire ulteriori dettagli?</sample>
    <sample id="755">Tre. C'è Sara Papi, Matteo Negri e Marco Turchi. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="756">Non c'è informazione su quanti annotatori sono stati impiegati per creare il set di dati iniziale.</sample>
    <sample id="757">Sebastin Santy e Ronan Le Bras sono affiliati all'University of Washington, Jenny T. Liang e Maarten Sap sono affiliati a Carnegie Mellon University, e Katharina Reinecke è affiliata all'Allen Institute for AI.</sample>
    <sample id="758">L'esempio è "I saw Bart and Lisa". Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="759">Non so dire quali siano i modelli all'avanguardia nei sistemi di dialogo. Potresti cercare su internet o chiedere a esperti nel campo. Cosa ne pensi?</sample>
    <sample id="760">Perché i modelli stanno avendo finestre di contesto sempre più lunghe.</sample>
    <sample id="761">Sì, la formazione multilingue ha causato un calo delle prestazioni rispetto al modello inglese monolingue in 7 dataset.</sample>
    <sample id="762">Sì, gli annotatori conoscono l'entità in anticipo.</sample>
    <sample id="763">Non c'è informazione su quali metriche di MT siano state utilizzate per la valutazione. Potresti cercare di trovare ulteriori dettagli in documenti o fonti più specifiche. Se hai altre domande o bisogna fare qualcosa di più, fammi sapere.</sample>
    <sample id="764">Non c'è una risposta diretta in questo contenuto. Potresti fornire ulteriori dettagli o contesto?</sample>
    <sample id="765">Beh, la posizionalità nella NLP è importante perché influisce sulla comprensione del significato di una frase. Ad esempio, le parole in un determinato ordine possono cambiare completamente il significato. Questo è fondamentale per la traduzione, la sintesi vocale e molte altre applicazioni. Se hai altre domande su questo argomento, sentiti libero di chiedere!</sample>
    <sample id="766">Non so se BLOOM è stato affinato con adattatori o con una messa a punto integrale. Potresti cercare ulteriori informazioni su questo modello?</sample>
    <sample id="767">RoBERTA-base + classifier head.</sample>
    <sample id="768">Non so. Potresti cercare su internet o chiedere a qualcuno che ne abbia informazioni.</sample>
    <sample id="769">Hanno proposto tre suggerimenti. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="770">Non so qual è il guadagno del metodo proposto rispetto al metodo di riferimento. Potresti dare più dettagli o informazioni?</sample>
    <sample id="771">Il nome del relatore è Shuheng Liu.</sample>
    <sample id="772">Sì, i risultati e il set di dati nell'articolo possono essere utilizzati come parametri di riferimento. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="773">Due modelli più piccoli vengono utilizzati nell'articolo. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="774">OFA viene utilizzato come modello di base per analizzare l'ottimizzazione delle istruzioni multimodali.</sample>
    <sample id="833">I membri dell'articolo sono affiliati a Google Translate.</sample>
    <sample id="834">Stony Brook University, Human Language Analysis Beings.</sample>
    <sample id="835">Non c'è informazione sull'articolo riguardo alle coppie linguistiche analizzate.</sample>
    <sample id="836">Shangbin Feng.</sample>
    <sample id="837">Durante gli esperimenti sono stati studiati due modelli: uno finetuned a livello di documento e uno finetuned a livello di frase.</sample>
    <sample id="838">Per l'addestramento vengono utilizzate 53 attività e per il test 62 attività. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="839">There are three authors involved in the article.</sample>
    <sample id="840">Gli autori hanno effettuato i test sui set di dati AG News, MIND, SST2 e Enron Spam.</sample>
    <sample id="876">NACHOS è un dataset di dati medici raccolti dal web.</sample>
    <sample id="877">Il nome del relatore è David Vilar Torres.</sample>
    <sample id="878">La strategia del prompting ha un grande impatto sui risultati, in quanto la maggior parte delle frasi, 516 su 1000, mostra una differenza di più di 1 punto BLEURT e la differenza può arrivare fino a 40 punti BLEURT.</sample>
    <sample id="879">Patrick Fernandes e Kayo Yin sono affiliati all'Instituto de Tecnologias da Linguagem, Carnegie Mellon University. Emmy Liu, André F. T. Martins e Graham Neubig sono affiliati a Técnico Lisboa, BAIR, Berkeley Artificial Intelligence Research e Unbabel.</sample>
    <sample id="880">I'm not sure what the 5 instructions written by experts are. Maybe you could check the QR code for more details?</sample>
    <sample id="881">Propongono un test di risoluzione di coreferenza per testare l'abilità di utilizzare informazioni provenienti da fonti diverse.</sample>
    <sample id="882">Ciao a tutti. Mi chiamo David Vilar Torres e darò un breve riepilogo del paper "Prompting PaLM for Translation: Assessing Strategies and Performance". Questo è un lavoro congiunto con i miei colleghi di Google Translate.</sample>
    <sample id="883">PaLM è un modello di linguaggio a 540 miliardi di parametri presentato l'anno scorso, nel 2022. È stato addestrato su una vasta collezione di testi, complessivamente 780 miliardi di token.</sample>
    <sample id="884">Nella sua applicazione, ha raggiunto lo stato dell'arte in centinaia di compiti di LMU e generazione.</sample>
    <sample id="885">Nel lavoro presentiamo lo studio sistematico del primo modello di linguaggio di grandi dimensioni per la traduzione automatica.</sample>
    <sample id="886">Abbiamo valutato la capacità di traduzione dei modelli di ricerca utilizzando le migliori pratiche della comunità di traduzione. Questo implica l'uso dei set di test più recenti per evitare che i dati di test si sovrappongano con i dati di addestramento del modello di linguaggio.</sample>
    <sample id="887">Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il contenuto in italiano: "Ecco il conten</sample>
    <sample id="888">Utilizziamo metriche di traduzione state-of-the-art e inoltre mostriamo i risultati di valutazione dell'esperto umano. Infine, forniamo alcune raccomandazioni per le strategie di selezione del prompt.</sample>
    <sample id="889">Le prompt hanno un grande impatto sulla qualità della traduzione. Seleziona due prompt casuali per ogni frase. Calcola BLEURT per ogni coppia frase-prompt. La maggior parte delle frasi, 516 su 1000, mostra una differenza di più di 1 punto BLEURT. La differenza può arrivare fino a 40 punti BLEURT!</sample>
    <sample id="890">La maggior parte delle frasi, 516 su 1000, mostra una differenza di più di 1 punto BLEURT.</sample>
    <sample id="891">I prompt hanno un grande impatto sulla qualità della traduzione. Seleziona due prompt casuali per ogni frase. Calcola BLEURT per ogni coppia frase-prompt. La maggior parte delle frasi, 516 su 1000, mostra una differenza di più di 1 punto BLEURT. La differenza può arrivare fino a 40 punti BLEURT! Questo può andare fino a 40 punti BLEURT in casi estremi. È importante scegliere una buona strategia di prompt.</sample>
    <sample id="892">In esperimenti, abbiamo optato per una strategia di "5-shot prompting" in cui semplicemente segniamo le frasi che forniamo al sistema con la loro lingua.</sample>
    <sample id="893">Ecco la traduzione in italiano: "Un passante ha allertato la polizia, che è arrivata con diversi agenti di polizia." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="894">Abbiamo visto che la forma effettiva del prompt non ha un grande influsso nel caso del prompt a 5 punti.</sample>
    <sample id="895">Ecco la traduzione in italiano: "È cruciale per il prompt a 0 e 1 shot, e quando passiamo al prompt a 5 shot, non c'è quasi alcuna differenza nella forma effettiva del prompt." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="896">Un passante ha allarmato la polizia, che è arrivata con diversi agenti.</sample>
    <sample id="897">I risultati sperimentali riassunti sono che la qualità dell'esempio è più importante della somiglianza con la frase di origine.</sample>
    <sample id="898">Quindi è importante selezionare esempi da traduzioni di alta qualità. In particolare, abbiamo comparato la selezione di prompt dal dataset di addestramento delle valutazioni WMT o dal dataset di test.</sample>
    <sample id="899">I dati di sviluppo sono molto più curati e di qualità superiore rispetto ai dati di addestramento. Sono più ordinati e i risultati sono migliori quindi una prestazione migliore utilizzando i dati di sviluppo.</sample>
    <sample id="900">Tuttavia, i sistemi SOTA specializzati hanno un vantaggio sostanziale rispetto alle traduzioni PaLM, ma PaLM si avvicina abbastanza a un sistema commerciale. Nella nostra situazione, abbiamo scelto di sovrapporre con Google Translate.</sample>
    <sample id="901">I dettagli che abbiamo ottenuto dall'analisi umana che abbiamo eseguito utilizzando il framework MQM sono che la fluidezza di PaLM è paragonabile a quella dei sistemi state dell'arte, ma la principale differenza deriva dalla precisione.</sample>
    <sample id="902">I risultati sperimentali: - La qualità dell'esempio è più importante della somiglianza con la frase di origine. - I sistemi SOTA specializzati hanno un vantaggio sostanziale. - PaLM è vicino a Google Translate. I consigli da MQM: - La fluenza di PaLM è paragonabile a quella dei SOTA. - Le punteggio di accuratezza sono generalmente più bassi. - Dominati da "Accuracy/Omission". - "Style/Awkward" è generalmente più basso per PaLM. In particolare, le omission errors sono le più comuni.</sample>
    <sample id="903">Pare che PaLM scelga di produrre una traduzione di miglior qualità, a volte rinunciando a parti della frase di partenza che non sono importanti nella traduzione.</sample>
    <sample id="904">Tuttavia, la categoria "Stile/Accattivante" per PaLM è inferiore rispetto a quella degli sistemi state dell'arte, che è un altro segnale.</sample>
    <sample id="905">Il contenuto inglese è stato convertito in italiano. Se hai bisogno di ulteriori informazioni o di aiuto con qualcos'altro, fammi sapere!</sample>
    <sample id="906">Ecco il contenuto in italiano: "Ecco tutto per questa breve panoramica. Per ulteriori dettagli, vi prego di venire alla presentazione completa del documento. Grazie mille."</sample>
    <sample id="907">Ciao, sono Dawei, un dottorando all'Università di Saarland in Germania. Nella video vorrei presentare il nostro lavoro recente "Meno potente di quanto pensi: un'analisi critica dell'apprendimento supervisionato debole".</sample>
    <sample id="908">Questa è una collaborazione con Xiaoyu Shen, Marius Mosbach, Andreas Stephan e Dietrich Klakow.</sample>
    <sample id="909">Perché l'apprendimento supervisionato debole?• L'apprendimento supervisionato debole allevia il blocco dell'annotazione. Ma le etichette deboli sono rumorose! • La memorizzazione del rumore danneggia la generalizzazione. • L'apprendimento supervisionato debole, WSL, • Addestra modelli che generalizzano bene nonostante siano addestrati su dati rumorosi.</sample>
    <sample id="910">Perché l'apprendimento supervisionato debole?• L'apprendimento supervisionato debole allevia il blocco dell'annotazione. Ma le etichette deboli sono rumorose! • La memorizzazione del rumore danneggia la generalizzazione. • L'apprendimento supervisionato debole, WSL, • Addestra modelli che generalizzano bene nonostante siano addestrati su dati rumorosi.In apprendimento supervisionato debole non etichettiamo manualmente i dati. Invece etichettiamo i dati utilizzando fonti di etichettatura deboli, come semplici regole heuristiche, basi di conoscenza o sorgenti di crowdsourcing di bassa qualità, come illustrato nella figura a destra.</sample>
    <sample id="911">Perché l'apprendimento supervisionato debole?• L'apprendimento supervisionato debole allevia il blocco dell'annotazione. Ma le etichette deboli sono rumorose! • La memorizzazione del rumore danneggia la generalizzazione. • L'apprendimento supervisionato debole, WSL, • Addestra modelli che generalizzano bene nonostante siano addestrati su dati rumorosi.</sample>
    <sample id="912">Se addestriamo direttamente reti neurali su dati etichettati debolmente, le reti neurali tendono a memorizzare il rumore etichettato e non a generalizzare.</sample>
    <sample id="913">Perché l'apprendimento supervisionato debole?• L'apprendimento supervisionato debole allevia il blocco dell'annotazione. Ma i etichettati deboli sono rumorosi! • La memorizzazione del rumore danneggia la generalizzazione. • L'apprendimento supervisionato debole, WSL, • Addestra modelli che generalizzano bene nonostante siano addestrati su dati rumorosi. Algoritmi di apprendimento supervisionato debole sono stati proposti per addestrare robustamente reti neurali su tali etichette rumorose, in modo che i modelli addestrati generalizzino ancora bene.</sample>
    <sample id="914">Nelle recenti opere di WSL, WSL sta per apprendimento supervisionato debole. Un affermazione comune è che le persone affermano di addestrare i modelli solo su dati etichettati debole e ottenere un buon rendimento su set di test puliti.</sample>
    <sample id="915">Un affermazione comune nelle recenti ricerche WSL. "Addestriamo modelli solo su dati supervisionati debolmente e otteniamo un'accuratezza del XX%." Tecnicamente questa affermazione non è errata, ma c'è un'eccezione.</sample>
    <sample id="916">Un'asserzione comune nelle recenti ricerche WSL è che "addestriamo modelli solo su dati supervisionati debolmente e otteniamo un'accuratezza del XX%." Si assume che ci sia inoltre un set di validazione pulito disponibile per la selezione del modello.</sample>
    <sample id="917">Un contenuto in inglese non è stato fornito.</sample>
    <sample id="918">Le domande di ricerca sono: Prima, è necessario il dati di validazione pulito per WSL? Oppure possiamo forse utilizzare un set di validazione rumoroso?</sample>
    <sample id="919">Prima, se i dati puliti sono richiesti o se i dati puliti sono obbligatori per che WSL funzioni, allora quante campioni puliti abbiamo bisogno? Infine, dovremmo utilizzare solo i campioni puliti per la validazione o ci sono modi migliori per utilizzarli?</sample>
    <sample id="920">Abbiamo affrontato queste domande di ricerca nel nostro lavoro e i nostri risultati sono i seguenti.</sample>
    <sample id="921">Prima di tutto, abbiamo trovato che, interessantemente, i recenti metodi di etichettatura debole effettivamente richiedono campioni di etichette debole pulite per funzionare correttamente.</sample>
    <sample id="922">Altrimenti ci sarà una significativa diminuzione del prestigio, come mostrato in questa figura. Se non ci sono esempi di validazione puliti, allora i modelli addestrati non possono generalizzare oltre le etichette deboli originali.</sample>
    <sample id="923">Significato che l'addestramento è inutile.</sample>
    <sample id="924">Questo indica che le approcci WSL effettivamente richiedono dati etichettati in modo pulito per funzionare correttamente e il costo di annotazione per ottenere campioni di validazione puliti non dovrebbe essere trascurato.</sample>
    <sample id="925">La nostra seconda scoperta è che aumentare il numero di campioni di validazione puliti aiuterà gli approcci WSL a ottenere una prestazione migliore, come mostrato nella figura a sinistra.</sample>
    <sample id="926">Generalmente, si necessitano solo 20 campioni per classe per ottenere prestazioni elevate.</sample>
    <sample id="927">Ma non è la fine della storia! Perché se decidiamo di accedere a campioni puliti, allora l'addestramento su di essi direttamente raggiungerà addirittura prestazioni migliori.</sample>
    <sample id="928">La figura rossa mostra la differenza di prestazione tra approcci di ottimizzazione che sono direttamente applicati sui dati puliti e approcci WSL che usano i dati puliti solo per la validazione.</sample>
    <sample id="929">Come possiamo vedere, se abbiamo 10 campioni per classe, la finetuning diretta inizia a superare le approcci WSL.</sample>
    <sample id="930">Infine, l'incremento di prestazioni dichiarato in precedenti approcci WSL può essere facilmente ottenuto consentendo il continuo raffinamento su campioni di validazione puliti.</sample>
    <sample id="931">Come possiamo vedere dai grafici, il modello di validazione FTW inizialmente sottoproduce rispetto a metodi più complessi come COSINE.</sample>
    <sample id="932">Tuttavia, se continuiamo a continuare l'addestramento su campioni puliti, allora FTW si comporta altrettanto bene di altri metodi.</sample>
    <sample id="933">RQ3 Rilevamenti principali N=10 campioni puliti per classe N=30 campioni puliti per classe Accuracy/F1 Accuracy/F1 Prima di CFT Dopo CFT Prima di CFT Dopo CFT → Continuare a ottimizzare (CFT) elimina le differenze di prestazioni tra le approcci WSL. → Non c'è bisogno di utilizzare metodi WSL complicati, FTw funziona altrettanto bene. → In pratica, non c'è motivo di scegliere metodi WSL più complessi, che richiedono più tempo di calcolo e spazio disco.</sample>
    <sample id="934">ConclusioneApprocci recenti WSL: - Richiedono campioni puliti. - Sottostimano la loro praticità.Noi consigli: - Riferire i criteri di selezione del modello. - Usare approcci di apprendimento a poche istanze come basi. - Sempre applicare l'ottimizzazione continua (CFT).Per riassumere, abbiamo mostrato che gli approcci recenti WSL richiedono campioni puliti manualmente annotati per funzionare correttamente. La loro performance e praticità sono pesantemente sottostimate.</sample>
    <sample id="935">ConclusioneApprocci recenti WSL: - Richiedono campioni puliti. - Sottostimano la loro praticità.Noi consigli: - Riferire i criteri di selezione del modello. - Usare approcci di apprendimento a pochi esempi come basi. - Sempre applicare l'ottimizzazione continua (CFT).I nostri consigli concreti per il lavoro futuro sono i seguenti:</sample>
    <sample id="936">ConclusioneApprocci recenti WSL: - Richiedono campioni puliti. - Sottostimano la loro praticità. Recommandazioni: - Riferire i criteri di selezione del modello. - Usare approcci di apprendimento a poche istanze come basi. - Sempre applicare l'ottimizzazione continua (CFT).</sample>
    <sample id="937">Secondo, gli approcci WSL dovrebbero essere confrontati con le basi di apprendimento Few-shot, entrambi che lavorano su campioni puliti. Terzo, l'ottimizzazione continua è una base semplice ma forte che dovrebbe essere considerata nel lavoro futuro WSL.</sample>
    <sample id="938">ConclusioneApprocci recenti WSL: - Richiedono campioni puliti. - Sottostimano la loro praticità.Noi consigli: - Riferire i criteri di selezione del modello. - Usare approcci di apprendimento a poche etichette come basi. - Sempre applicare il raffinamento continuo, CFT.Finalmente, abbiamo reso open source il nostro codice. Potete trovarlo tramite il codice QR in questa slide. Vi preghiamo di controllarlo. Grazie e godetevi la conferenza.</sample>
    <sample id="939">I metodi di valutazione comuni per i sistemi di dialogo sono l'uso di giudici umani per scegliere quale conversazione è migliore o per valutarle con una scala Likert.</sample>
    <sample id="940">Cinque. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="941">Nell'esempio con Servin e Kea, le conoscenze di base necessarie sono che i giudici decidono casi in tribunali. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="942">Sì, il codice è disponibile. Puoi trovarlo su GitHub, nel repository mpoemsl/kitmus.</sample>
    <sample id="943">No, gli annotatori per NLPositionality non sono bilanciati rispetto a ciascun gruppo demografico.</sample>
    <sample id="944">Nel dominio accettabile, si sono perturbate le frasi in modo da mantenere la struttura rilevante.</sample>
    <sample id="945">Evaluare le diverse dimensioni della qualità del dialogo.</sample>
    <sample id="946">Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, Xing Xie. Wenjun Peng and Jingwei Yi are from the University of Science and Technology of China, Fangzhao Wu and Shangxi Wu are from Microsoft Research Asia, Bin Zhu and Lingjuan Lyu are from Beijing Jiaotong University, Binxing Jiao and Tong Xu are from Sony AI, and Guangzhong Sun and Xing Xie are from Microsoft STC Asia.</sample>
    <sample id="947">La forma del prompting si rivela importante nei casi di zero e uno shot prompting.</sample>
    <sample id="978">Hanno valutato BART-FID-RAG, Blender2, Emora e Blender-Decode.</sample>
    <sample id="979">Ci sono nove autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="980">Un buon pianificatore dovrebbe scrivere script che siano ragionevoli e fedeli alle restrizioni.</sample>
    <sample id="981">Ci sono sette autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="982">Vasudha Varadarajan.</sample>
    <sample id="983">I autori dell'articolo sono affiliati all'Institute of Computer Science, Polish Academy of Sciences, con indirizzo ul. Jana Kazimierza 5, 01-248 Warsaw, e all'University of Warsaw.</sample>
    <sample id="1021">The most common errors are omission errors.</sample>
    <sample id="1022">Ciao, sono James Finch e sono Sarah Finch. Oggi vi parleremo di ABC eval, un nuovo approccio dimensionale per valutare l'intelligenza artificiale conversazionale.</sample>
    <sample id="1023">Questa ricerca è stata condotta dal Laboratorio di NLP di Emory, diretto dal Professore Jinho Choi all'Università di Emory, in collaborazione con Amazon Alexa AI.</sample>
    <sample id="1024">Se hai appena sviluppato un modello di dialogo e vuoi vedere come si confronta con lo stato dell'arte attuale.</sample>
    <sample id="1025">La pratica comune è di utilizzare l'valutazione umana, come ad esempio chiedendo a giudici umani di selezionare quale delle due conversazioni sia migliore o di valutare le conversazioni utilizzando una scala Likert.</sample>
    <sample id="1026">Questi approcci funzionano bene per fornire valutazioni globali della qualità del dialogo, ma la qualità del dialogo ha molti aspetti. Quindi, potresti voler valutare diverse dimensioni della qualità del chat per comprendere le forze e le debolezze del modello a un livello più dettagliato.</sample>
    <sample id="1027">Un approccio è chiedere giudici umani di valutare diverse dimensioni della qualità del dialogo, come la rilevanza delle risposte del modello, utilizzando metodi di scala comparativa o Likert esistenti.</sample>
    <sample id="1028">Tuttavia, crediamo che ci sia una strategia più precisa e affidabile per l'valutazione dimensionale del dialogo.</sample>
    <sample id="1029">La nostra approccio cerca di ridurre la soggettività dell'evaluation umana annotando esplicitamente se ognuna delle risposte del modello esprime determinati comportamenti, come rispondere con informazioni irrilevanti o contraddizione.</sample>
    <sample id="1030">Chiamiamo questo approccio "Annotazione dei comportamenti in chat" o ABC-Eval in breve. Abbiamo sviluppato questo metodo per coprire in modo comprensivo i comportamenti dei modelli di chat che sono stati suggeriti di influenzare la qualità dei chat in recenti studi.</sample>
    <sample id="1031">L'ABC-Eval è in grado di misurare le tassi con cui i modelli di chat commetteranno diversi errori tematici.</sample>
    <sample id="1032">Per esempio, ABC-Eval misura il numero di turni in cui un modello di chat ignora il suo partner o dice qualcosa di irrilevante.</sample>
    <sample id="1033">Contraddice se stesso o il partner, allucina fatti errati o viola il buon senso e quando il modello riesce o fallisce a mostrare empatia.</sample>
    <sample id="1034">Per determinare quale tipo di valutazione è il più efficace, abbiamo selezionato quattro modelli di chat all'avanguardia e li abbiamo valutati su 100 conversazioni umano-bots per modello utilizzando ABC-Eval.</sample>
    <sample id="1035">Per la comparazione, abbiamo anche valutato queste conversazioni utilizzando tre metodi esistenti: valutazioni Likert a livello di turno, valutazioni Likert a livello di dialogo e confronti a livello di dialogo a coppie.</sample>
    <sample id="1036">Per ciascuno dei metodi esistenti, abbiamo raccolto valutazioni su otto dei più comunemente misurati aspetti del dialogo, poiché questo è la pratica standard per valutare i modelli di chat su diverse dimensioni.</sample>
    <sample id="1037">Dalle nostre analisi dei risultati di valutazione, abbiamo trovato che le etichette di comportamento ABC-Eval sono in generale più affidabili delle etichette raccolte dai metodi esistenti, come misurato dall'accordo inter-annotatore su 100 conversazioni doppilabel.</sample>
    <sample id="1038">Inoltre, le etichette ABC-Eval sono più predittive della qualità complessiva della conversazione rispetto ai metrici prodotti da metodi esistenti, come dimostrato dall'analisi di regressione lineare semplice.</sample>
    <sample id="1039">Per esempio, si può vedere come misurare la proporzione di turni con contraddizioni di sé e partner spieghi il 5% e il 10% della qualità della conversazione rispettivamente, mentre le punte di consistenza Likert spiegano solo il 4% o meno.</sample>
    <sample id="1040">Infine, abbiamo controllato se ogni metrica di valutazione cattura un aspetto unico della qualità del chat utilizzando una regressione lineare passo dopo passo.</sample>
    <sample id="1041">Puoi vedere come la combinazione di tutte le metriche ABC-Eval spiega oltre il 25% della qualità della conversazione. E quando rimuovi le metriche una alla volta, la maggior parte di esse porta via una buona quantità di informazioni sulla qualità.</sample>
    <sample id="1042">D'altra parte, la combinazione di tutte le metriche Likert a livello di turno spiega molto meno la qualità e meno di queste metriche portano informazioni uniche.</sample>
    <sample id="1043">Questi metriche ABC-Eval affidabili e distintive permettono di valutare l'intelligenza artificiale conversazionale con una risoluzione maggiore rispetto a metodi precedenti.</sample>
    <sample id="1044">Ecco la versione italiana del contenuto in inglese: "Come puoi vedere nei risultati delle nostre esperimenti, ci sono ancora diverse sfide che rimangono e sono state quantificate con precisione. Ad esempio, i bot che abbiamo testato violano il buon senso in circa il 20% delle loro risposte."</sample>
    <sample id="1045">Producono informazioni irrellevanti in circa il 15% delle risposte e si contraddicono o si contraddicono con il partner circa il 10% del tempo.</sample>
    <sample id="1046">Con il rapido ritmo di miglioramento nel campo, molte di queste tassi di errore potrebbero vedere una diminuzione in nuovi modelli rilasciati dal momento che la nostra valutazione è stata condotta. Tuttavia, questo è ancora di più motivo per perseguire metriche di valutazione affidabili e precise per confrontare i modelli.</sample>
    <sample id="1047">Speriamo che ABC-Eval possa essere utilizzato da altri nel campo come un passo significativo in questa direzione e ci guardiamo intorno a vedere come l'intelligenza artificiale conversazionale progredisca nei prossimi mesi e anni. Grazie per averci ascoltato.</sample>
    <sample id="1048">The authors are affiliated with Emory University and the Emory NLP Research Lab.</sample>
    <sample id="1049">CFT significa Continuous Fine-tuning. Se hai altre domande sul contenuto dell'articolo, sentiti libero di chiedere.</sample>
    <sample id="1050">Ci sono sette autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1051">Ciao, il mio nome è Kayo Yin e presenterò il nostro lavoro intitolato "Quando la traduzione richiede contesto? Un'indagine multilingue guidata da dati". Questo lavoro è stato realizzato in collaborazione con Patrick Fernandes, Emmy Liu, André F. T. Martins e Graham Neubig.</sample>
    <sample id="1052">Dobbiamo liberarci di quel mulo.</sample>
    <sample id="1053">Se la frase precedente era "Things could start to get dangerous if the ministers find out" allora "mole" si riferisce a un agente segreto. Ma se la frase precedente era "Could it be anything serious, Doctor?" allora "mole" si riferisce a una macchia di pelle.</sample>
    <sample id="1054">Il contenuto inglese in italiano è: "Può essere qualcosa di serio, dottore? Dobbiamo liberarci di quella macchia." Se hai bisogno di chiarimenti o hai altre domande, fammelo sapere!</sample>
    <sample id="1055">Evaluare la traduzione dipendente dal contesto è difficile. Tuttavia, valutare quanto bene i modelli gestiscono casi come questi è abbastanza difficile. In primo luogo, perché solo una piccola porzione di traduzioni dipende dal contesto, che rende le metriche a livello di corpus come BLEU incapaci di catturare queste traduzioni.</sample>
    <sample id="1056">Evaluare la traduzione dipendente dal contesto è difficile. Solo una piccola parte di parole dipende dal contesto. I metodi esistenti supportano fenomeni di discorso e lingue limitati. Alcune persone hanno suggerito una valutazione mirata sulle traduzioni dipendenti dal contesto, ma questi risorse supportano solo tipi limitati di traduzioni dipendenti dal contesto e set di lingue limitati, poiché solitamente si affidano a conoscenza di dominio e cura umana.</sample>
    <sample id="1057">Nel lavoro, cerchiamo di rispondere a queste due domande. Prima, quando la traduzione richiede contesto, e poi, quanto bene gestiscono questi casi i modelli.</sample>
    <sample id="1058">Per rispondere alla prima domanda, abbiamo iniziato misurando quanto una parola dipende dal contesto durante la traduzione.</sample>
    <sample id="1059">Nel lavoro precedente, abbiamo introdotto il CXMI come misura dell'uso del contesto da parte dei modelli di traduzione automatica. Questo è stato fatto misurando quanta informazione il contesto C fornisce sulla traduzione Y, dato il testo di origine X.</sample>
    <sample id="1060">CMI: misura quanto utilizzano i modelli di traduzione con contesto dati un corpus. Puoi pensare a CMI come all'informazione guadagnata dal dare contesto al modello.</sample>
    <sample id="1061">In questo lavoro estendiamo CXMI a P-CXMI, che può misurare l'uso del contesto a livello di frase o a livello di parola. Possiamo pensare a parole con alto P-CXMI come quelle che richiedono contesto per la traduzione.</sample>
    <sample id="1062">Ora analizziamo le parole con un alto PSMI per cercare di trovare pattern tra queste parole.</sample>
    <sample id="1063">Eseguiamo l'analisi su trascrizioni di TED Talks tradotti dall'inglese in 14 diverse lingue.</sample>
    <sample id="1064">Eseguiamo l'analisi a tre livelli diversi. Innanzitutto, guardiamo alle etichette di parto di frase che hanno un alto P-CXMI.</sample>
    <sample id="1065">Ecco il contenuto in italiano: "E questo ci permette di trovare, ad esempio, i pronomi duali in arabo che hanno relativamente un alto P-CXMI. E questo può essere spiegato perché l'inglese non ha pronomi duali, quindi si ha bisogno di contesto per determinare se un pronome è dual quando si traduce in arabo."</sample>
    <sample id="1066">Ecco il contenuto in italiano: "Inoltre, troviamo che certi linguaggi richiedono contesto quando vogliamo scegliere la forma verbale appropriata. Poi analizziamo gli elementi di vocabolario con P-CXMI alto, calcolato su tutte le sue diverse occorrenze." Se hai bisogno di ulteriori chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="1067">Ecco il contenuto in italiano: "Ecco come identificare casi come questo, dove in cinese si necessita del contesto per tradurre i nomi propri in modo da assicurarsi di utilizzare la stessa traduzione all'interno del documento." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="1068">Ecco il contenuto in italiano: "E inoltre, troviamo che il contesto supporta la traduzione nella giusta formalità." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="1069">Ecco il contenuto in italiano: "E finalmente analizziamo i diversi token individuali con un alto P-CXMI. Questo ci permette di identificare fenomeni che non possono essere veramente catturati dalla parola in sé, ma sono piuttosto espressi nella struttura della frase, come la risoluzione dell'ellissi." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere!</sample>
    <sample id="1070">Quindi ora utilizziamo i nostri risultati dall'analisi per progettare un benchmark per la traduzione a livello di documento.</sample>
    <sample id="1071">Per ciascuno dei cinque fenomeni di discorso identificati, creiamo tagger per identificare automaticamente le parole che appartengono al fenomeno e chiamiamo il nostro tagger il Multilingue Discorsuale Consapevole, MuDA.</sample>
    <sample id="1072">Possiamo notare che le diverse lingue hanno proporzioni diverse di questi fenomeni discorsivi.</sample>
    <sample id="1073">Allora utilizziamo il tagger MuDA applicando il tagger sul corpus parallelo che vogliamo utilizzare per l'valutazione. E applichiamo i nostri metriche di traduzione di scelta sulle esempi dipendenti dal contesto che il tagger MuDA ha identificato.</sample>
    <sample id="1074">Ecco il contenuto in italiano: "E infine, utilizziamo il nostro benchmark, insieme a altri metriche, per valutare diversi modelli di traduzione automatica a livello di documento." Se hai bisogno di ulteriori informazioni o hai altre domande, fammi sapere!</sample>
    <sample id="1075">Prima di tutto, quando utilizziamo metriche a livello di corpus, per BLEU troviamo che i modelli agnostici di contesto hanno il miglior rendimento.</sample>
    <sample id="1076">Ma se usiamo Comet con il contesto, le modelli performano meglio. E se usiamo F-measure, le modelli con e senza contesto hanno prestazioni comparabili.</sample>
    <sample id="1077">Questo dimostra nuovamente che se utilizziamo solo metriche a livello di corpus per determinare il miglior sistema di traduzione a livello di documento, è difficile stabilire quale sia il migliore.</sample>
    <sample id="1078">Ora utilizziamo il benchmark MuDA per valutare i modelli e troviamo che i modelli a conoscenza del contesto sono significativamente più accurati dei modelli che non utilizzano il contesto per certi fenomeni discorsivi, come formalità e coesione lessicale.</sample>
    <sample id="1079">I modelli a conoscenza del contesto performano significativamente meglio su alcune fenomeni come formalità e coesione lessicale. Ma non sono molto meglio dei modelli che non utilizzano il contesto su altri fenomeni come ellissi, pronomi e forma del verbo. Questo suggerisce dove sarebbe necessario fare più progresso per la traduzione a livello di documento.</sample>
    <sample id="1080">Abbiamo anche confrontato diversi sistemi commerciali e il nostro benchmark mostra che DeepL è solitamente più accurato di Google Translate per la traduzione a livello di documento.</sample>
    <sample id="1081">Ecco la traduzione in italiano: "Per riassumere, abbiamo effettuato un'analisi guidata da dati su 14 coppie di lingue per identificare quando le traduzioni richiedono un contesto." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1082">E allora utilizziamo i nostri risultati per costruire un benchmark per la traduzione automatica a livello di documento che ci aiuterà a identificare quali fenomeni discorsivi i modelli possono gestire bene o meno e quali sistemi di traduzione sono buoni per la traduzione a livello di documento.</sample>
    <sample id="1083">Riepilogo
• Identificare fenomeni discorsivi in modo sistematico senza conoscenze linguistiche precedenti
• Benchmark per la traduzione automatica a livello di documento indipendente dal dataset
Grazie per l'attenzione. Ci vediamo a Toronto.</sample>
    <sample id="1084">The name of the speaker is Yusen Zhang.</sample>
    <sample id="1121">The new method is called "Permuting with 'jumps'".</sample>
    <sample id="1122">Il metodo cerca parole che distinguono i personaggi di gruppi contrassegnati da quelli non contrassegnati.</sample>
    <sample id="1123">Shangbin Feng è affiliato alla Paul G. Allen School dell'University of Washington, Chan Young Park è affiliato a UW NLP, Yuhan Liu è affiliato al Language Technologies Institute di Carnegie Mellon University e Yulia Tsvetkov è affiliata alla Beijing University of Posts and Telecommunications.</sample>
    <sample id="1124">Bouquet/Stanford.</sample>
    <sample id="1125">The name of the speaker is James Finch.</sample>
    <sample id="1126">Quattro. C'è Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti e Annie Louis. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1127">BLiMP, SyntaxGym, CrowS.</sample>
    <sample id="1161">FTw, BOND, COSINE, MLC, L2R.</sample>
    <sample id="1162">The model is evaluated on 11 biomedical and clinical downstream tasks.</sample>
    <sample id="1226">CamemBERT viene inizialmente addestrato su 4GB di dati.</sample>
    <sample id="1227">Adam Przepiórkowski. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1228">I risultati dell'esperimento di ritraining o di continuare a pretrainare modelli con dati più recenti hanno portato alla conclusione che la deriva temporale è la causa principale della perdita di prestazioni. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1269">Perché i token non sono ordinati dopo il primo step.</sample>
    <sample id="1270">Perché non sanno se i positivi stereotipi sono dovuti a un'overly excessive value alignment o altri metodi anti-stereotipanti che stanno producendo questi pattern dannosi.</sample>
    <sample id="1271">Gli input inaccettabili di coppia minima sono le frasi che non seguono le regole grammaticali o che sono stereotipiche.</sample>
    <sample id="1272">The authors used F1, Hamming, and EMR as evaluation metrics.</sample>
    <sample id="1273">La metrica utilizzata per misurare l'accordo tra annotatori è Krippendorff's Alpha. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1274">Wikipedia.</sample>
    <sample id="1275">Heinrich Heine University Düsseldorf, Germany.</sample>
    <sample id="1276">MultiInstruct differisce dagli altri perché si concentra su multitasking e ha un dataset di istruzioni bilanciato tra NLP e modelli multimodali. Altri parametri di riferimento potrebbero non fare questo. Se hai altre domande su questo, puoi chiedere.</sample>
    <sample id="1277">There are three authors involved in the article. If you want to know more about them or the article itself, feel free to ask.</sample>
    <sample id="1278">Non c'è una definizione di coordinazione binaria nella tua domanda. Potresti fornire più dettagli o chiarire il concetto che stai cercando?</sample>
    <sample id="1279">Non c'è informazione sul tempo medio di utilizzo dei prompt in questo studio. Potresti cercare ulteriori dettagli nel documento o nella presentazione?</sample>
    <sample id="1280">The smaller T5 model fine-tuned on Coscript can generate higher quality scripts than large language models. This shows that smaller models can outperform larger ones when properly trained on suitable datasets. If you want to know more about this, feel free to ask.</sample>
    <sample id="1281">Ciao, sono Yanis Labrak e presenterò il nostro lavoro su DrBERT, un modello pre-allenato robusto in francese per i campi biomedici e clinici.</sample>
    <sample id="1282">Nella presentazione parliamo prima di modellazione linguistica nel campo della sanità. Poi presenteremo le principali contribuzioni dell'articolo nostro.</sample>
    <sample id="1283">Introduciamo il primo modello biomedico in francese, chiamato Dr.BERT, basato su RoBERTa e addestrato su NACHOS, un dataset di dati medici crawlati dalla rete.</sample>
    <sample id="1284">Abbiamo anche introdotto una comparazione di modelli con diversi set di pre-allenamento e fonti di dati. Poi abbiamo presentato i risultati su 11 compiti di apprendimento automatico biomedico e clinico in francese.</sample>
    <sample id="1285">Infine, concludiamo gli esperimenti e ti forniamo dettagli ulteriori su come accedere ai modelli.</sample>
    <sample id="1286">Ecco la traduzione italiana del contenuto in inglese:.- Approcci basati su trasformatori, come BERT, offrono un guadagno di prestazioni enorme su molte tesi di processamento del linguaggio naturale.- È stato adattato al francese con CamemBERT e FlauBERT.- Su compiti medici, modelli specifici di dominio in inglese hanno alzato ancora di più il livello.- PudMedBERT, BioBERT, ClinicalBERT e altri.- Lingue diverse dall'inglese sono più rare e si affidano principalmente a un pre-allenamento continuo utilizzando un modello generico esistente.- Contrariamente ai modelli generici, non è ancora disponibile un modello open-source per il dominio biomedico in francese.- Un modello specifico di dominio basato su BERT in francese dovrebbe aumentare le prestazioni sui compiti medici.</sample>
    <sample id="1287">Ecco la traduzione in italiano: "Da allora, questo modello è stato adattato a molte lingue minoritarie, come in francese con CamemBERT e in altri ambiti come biomedico con PubMedBERT e BioBERT, e in clinico con ClinicalBERT, ma principalmente in inglese." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1288">I modelli specializzati per altre lingue sono scarsi e spesso si basano su un pre-allenamento continuo a causa della mancanza di dati di dominio.</sample>
    <sample id="1289">I modelli di linguaggio basati su trasformatori, come BERT, offrono un guadagno di prestazioni notevole in molte tesi di NLP. È stato adattato al francese con CamemBERT e FlauBERT. Nelle tesi mediche, i modelli specifici di dominio in inglese hanno alzato ancora di più il livello. PudMedBERT, BioBERT, ClinicalBERT e altri. Le lingue diverse dall'inglese sono più rare e si affidano principalmente a un pre-allenamento continuo utilizzando un modello generico esistente. In contrapposizione ai modelli generici, non c'è ancora un modello open-source per il dominio biomedico in francese. Un modello specifico di dominio basato su BERT in francese dovrebbe aumentare la prestazione nelle tesi mediche.</sample>
    <sample id="1290">Ecco la traduzione italiana del contenuto in inglese: "Quindi ci chiediamo qual è la fonte di dati più appropriata per una vasta gamma di utilizzo e questi dati corali sono buoni sostituti per i dati clinici." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1291">Confronto di strategie di pre-allenamento e fonti di dati. - Valutazione dell'impatto di fonti di dati medici pubbliche e private su dimensioni di dati comparabili. * NACHOS: Un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. * NBDW: Un dataset privato di frasi tratti da 1,7 milioni di record medici anonimizzati estratti dal data warehouse dell'ospedale universitario di Nantes. - Confronto di strategie di apprendimento. * Allena da zero con costruzione completa del modello. * Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese).</sample>
    <sample id="1292">Dopo tutto, ci chiediamo quanta data serva per addestrare un modello specializzato su dati francesi. È 4 GB, 11 GB o più?</sample>
    <sample id="1293">Confronto di strategie di pre-allenamento e fonti di dati. - Valutazione dell'impatto di fonti di dati medici pubbliche e private su dimensioni di dati comparabili. * NACHOS: Un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. * NBDW: Un dataset privato di frasi tratti da 1,7 milioni di record medici anonimizzati estratti dal data warehouse dell'ospedale universitario di Nantes. - Confronto di strategie di apprendimento. * Allenamento da zero con costruzione completa del modello. * Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese).</sample>
    <sample id="1294">Prima versione di Schubert, un modello clinico con 4 GB di frasi estratte da ClinConduct e ultima versione di Schubert con una mistura di 4 GB di frasi di ClinConduct e 4 GB di frasi di NACHOS.</sample>
    <sample id="1295">Confronto di strategie di pre-allenamento e fonti di dati. - Valutazione dell'impatto di fonti di dati medici pubbliche e private su dimensioni di dati comparabili. * NACHOS: Un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. * NBDW: Un dataset privato di frasi tratti da 1,7 milioni di record medici anagrafici estratti dal data warehouse dell'ospedale universitario di Nantes. - Confronto di strategie di apprendimento. * All'inizio con costruzione completa del modello. * Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese). In aggiunta a questo confronto, introduciamo tre modelli addestrati con pre-allenamento continuo per analizzare l'impatto delle strategie di pre-allenamento.</sample>
    <sample id="1296">Ecco la traduzione italiana del contenuto in inglese: "Confronto tra strategie di pre-allenamento e fonti di dati. - Valutazione dell'impatto delle fonti di dati mediche pubbliche e private su dimensioni di dati comparabili. - NACHOS: Un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. - NBDW: Un dataset privato di frasi tratti da 1,7 milioni di record medici anonimizzati estratti dal data warehouse dell'ospedale universitario di Nantes. - Confronto di strategie di apprendimento. - Allena da zero con costruzione completa del modello. - Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese). - Un basato su CamemBERT e addestrato su un subset di 4 GB di NACHOS. L'altro basato anche su Cam</sample>
    <sample id="1297">Ecco la traduzione italiana del contenuto in inglese: "Ecco una base di dati in inglese per modelli biomedici, PubMedBERT, addestrata su un subset di 4 GB di NACHOS in totale. In totale abbiamo sette modelli."</sample>
    <sample id="1298">Ecco la traduzione italiana del contenuto in inglese: "Evaluazione: Sorgenti di dati e dimensioni • Valutazione di prestazioni di 13 modelli su 11 compiti, sia pubblici che privati • I nostri modelli finetunati ottengono risultati di punta su quasi tutti i compiti". Se hai bisogno di ulteriori informazioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1299">Ecco la traduzione italiana del contenuto in inglese: "Evaluazione: Sorgenti di dati e dimensioni • Valutazione di prestazioni di 13 modelli su 11 compiti, sia pubblici che privati • I nostri modelli finetunati ottengono risultati di punta su quasi tutti i compiti". Se hai bisogno di ulteriori informazioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1300">L'evaluation evidenzia che i modelli performono meglio sui task con dati dello stesso tipo di quelli su cui sono stati addestrati.</sample>
    <sample id="1301">Ecco la traduzione italiana del contenuto in inglese: "Tuttavia, possiamo ottenere i dati da... possiamo osservare che i dati da diverse fonti sembrano essere più versatile. Abbiamo anche osservato che l'uso di più dati si traduce in una migliore prestazione."</sample>
    <sample id="1302">In generale, la pre-Allenamento da zero sembra ottenere prestazioni superiori per la maggior parte delle tesi.</sample>
    <sample id="1303">Ecco la traduzione italiana del contenuto in inglese: "Tuttavia, il nostro esperimento di pre-allenamento continuo utilizzando i pesi e il tokenizzatore di PubMedBERT, addestrato su un subset da 4 GB di Nachos, ha mostrato risultati paragonabili a quelli ottenuti con DrBERT da 4 GB addestrato da zero."</sample>
    <sample id="1304">Ecco la traduzione italiana del contenuto in inglese: "Non è il caso per i modelli basati su CamemBERT pesi e tokenizzatore, che soffrono di problemi di stabilità." Se hai bisogno di ulteriori informazioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1305">Infine, il nostro sistema proposto offre una migliore prestazione su nove dei dodici compiti di flusso e supera globalmente il risultato del modello generico CamemBERT.</sample>
    <sample id="1306">Abbiamo anche osservato che i dati specializzati sono migliori, più dati specializzati sono migliori, ma non scalano bene.</sample>
    <sample id="1307">Il modello preaddestrato ottenuto da NACHOS è disponibile gratuitamente su GitHub e anche i script di addestramento sono sul nostro repository GitHub.</sample>
    <sample id="1308">Grazie per questa presentazione e ci guardiamo al confronto nella sessione poster a Toronto!</sample>
    <sample id="1309">The learning strategies examined are "From scratch with full model construction" and "Continual pre-training using an existing pre-trained model." If you want to know more about these strategies, feel free to ask.</sample>
    <sample id="1310">Non c'è un fattore di overfitting dovuto al riutilizzo del test.</sample>
    <sample id="1311">The quality of simplification was evaluated using SARI, BLEU, BS-P and FRE.</sample>
    <sample id="1312">Sì, i modelli linguistici presentano bias politici diversi.</sample>
    <sample id="1313">Ciao, il mio nome è Matthias Lindemann e oggi darò un'introduzione breve al nostro articolo su generalizzazione compositiva senza alberi utilizzando multiset tagging e permutazioni latenti.</sample>
    <sample id="1314">Questa è un lavoro congiunto con i miei tutori, Alexander Koller e Ivan Titov.</sample>
    <sample id="1315">La generalizzazione compositiva può essere compresa come la capacità di un apprendista di gestire una ricorsione più profonda e composizioni non viste di frasi che sono state viste individualmente durante l'addestramento.</sample>
    <sample id="1316">Nel contesto della parsing semantica, il test per la generalizzazione compositiva potrebbe sembrare così: come di solito, abbiamo un set di enunciati di addestramento, in questo caso "The girl slept" e "Mary knew that the girl slept".</sample>
    <sample id="1317">I contenuti in inglese sono: "Compositional Generalization in Semantic Parsing" e "These utterances are paired with logical forms that represent core aspects of their meaning."</sample>
    <sample id="1318">In contrapposizione all'evaluation standard di machine learning, il test set non proviene dalla stessa distribuzione ma contiene forme logiche strutturalmente non viste.</sample>
    <sample id="1319">Ecco il contenuto in italiano: "Nell'esempio, il modello ha visto ricorrenza superficiale durante l'addestramento e viene testato su esempi con ricorrenza più profonda." Se hai bisogno di ulteriori chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="1320">La presentazione parla di "Generalizzazione Composizionale in Parsing Semantico". Nella sezione di addestramento, ci sono esempi come "The girl slept." e "Mary knew that the girl slept." con la loro rappresentazione semantica. Nella sezione di test, c'è "Jim said that Mary knew that the girl slept." con la sua rappresentazione semantica. La conclusione è che i modelli seq2seq semplici falliscono in questo tipo di generalizzazione fuori dalla distribuzione.</sample>
    <sample id="1321">In particolare, spesso falliscono nel riprodurre le corrispondenze sistematiche tra input e output, come quelle che sono codificate in colori nell'esempio.</sample>
    <sample id="1322">Un metodo popolare per affrontare questo è di integrare gli alberi nei modelli.</sample>
    <sample id="1323">Le alberi sono intesi per catturare il processo compositivo che collega le affermazioni con le forme logiche.</sample>
    <sample id="1324">Alberi aiutano molto ma... I alberi devono essere ottenuti: - Pre/Post -processamento di forme logiche</sample>
    <sample id="1325">Alberi aiutano molto ma... *ragazza x₁; agente di sonno x₂ x₁ *ragazza x₁; x₁ agente di sonno x₂ Il ragazzino dormì. Alberi devono essere ottenuti: - Pre/Post-trattamento di forme logiche</sample>
    <sample id="1326">Alberi aiutano molto ma... *ragazza x₁; agente di sonno x₂ x₁ Alberi devono essere ottenuti: - Pre/Post-trattamento di forme logiche - Induzione di grammatica</sample>
    <sample id="1327">Nel documento, non si utilizzano alberi e si introduce un modello di sequenza a sequenza neurale che modella direttamente le corrispondenze tra i frammenti dell'input e i frammenti dell'output.</sample>
    <sample id="1328">Per la prima volta, dimostriamo una generalizzazione forte alla ricorsione più profonda senza dipendere dagli alberi.</sample>
    <sample id="1329">La nostra approccio predice l'output dall'input in due passaggi.</sample>
    <sample id="1330">Prima di tutto, etichettiamo ogni token di input con un insieme multiset non ordinato di token che appaiono nella output.</sample>
    <sample id="1331">Dopo il primo passaggio, abbiamo tutti i token giusti, ma non sono ordinati.</sample>
    <sample id="1332">Perché, nel secondo passaggio, usiamo un altro modello per prevedere la permutazione per metterli nell'ordine corretto.</sample>
    <sample id="1333">Introduciamo un nuovo metodo per prevedere una permutazione che non impone alcune restrizioni rigide sulle possibili permutazioni. Questo rende il nostro approccio abbastanza flessibile e espressivo.</sample>
    <sample id="1334">Permutando con "salti" Concettualmente, il nostro modello di permutazione funziona in questo modo.</sample>
    <sample id="1335">Andiamo da sinistra a destra nell'output e determiniamo quale token multiset mettere in ogni posizione. Per la prima posizione di output, semplicemente selezioniamo uno, evidenziato in rosso.</sample>
    <sample id="1336">Allora saltiamo al prossimo token multiset per determinare il secondo token nell'output.</sample>
    <sample id="1337">Determiniamo il terzo token nella uscita in modo simile saltando a un altro token multiset. Continuiamo questo processo.</sample>
    <sample id="1338">Fino a quando ogni token del primo stadio è stato visitato esattamente una volta.</sample>
    <sample id="1339">Per dare un'anteprima dei risultati sperimentali, qui confrontiamo il nostro metodo con altri modelli senza albero sul benchmark COGS. Il nostro modello supera gli altri di gran lunga in generazione per ricorrenze più profonde.</sample>
    <sample id="1340">Alcune altre tipologie di generalizzazione strutturale rimangono molto difficili, tuttavia.</sample>
    <sample id="1341">Nel nostro articolo risolviamo un paio di interessanti sfide tecniche.</sample>
    <sample id="1342">Prima di tutto, l'allineamento tra input e output non è dato nel dataset di addestramento. Come conseguenza, per un token dato, non sappiamo da quale multisetta è venuto, che rappresenta un problema per l'addestramento.</sample>
    <sample id="1343">Inoltre, a volte ci sono diverse permutazioni che sono consistenti con i dati, ma la corretta da un punto di vista linguistico è nascosta. Abbiamo affrontato questo problema inducendo l'allineamento come parte della fase di addestramento.</sample>
    <sample id="1344">Il contenuto in inglese è: "La nostra metodologia di permutazione è molto flessibile, ma porta con sé il problema che trovare la permutazione di punteggio più alto è NP-hard. Questo perché è legato al problema del viaggiatore di commercio."</sample>
    <sample id="1345">C'è un contenuto in inglese che parla di sfide tecniche che risolviamo. Ecco il rendimento in italiano: "Sfide tecniche che risolviamo: - Allineamento sconosciuto. &gt;&gt; Inducilo durante l'addestramento. Modello di permutazione: - Inferenza è NP-hard, circa TSP - Indietropropagazione attraverso rilassamento continuo. Abbiamo approssimato questo con una rilassamento continuo amichevole per GPU che anche permette di indietropropagare attraverso la soluzione e imparare le permutazioni più plausibili linguisticamente." Se hai bisogno di chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="1346">Se vuoi imparare di più sulle nostre esperimenti e su come abbiamo affrontato questi挑战， ti prego di guardare il nostro articolo o venire al nostro poster.</sample>
    <sample id="1347">La dissonanza cognitiva è quando ci sono due elementi della cognizione, come pensieri, azioni o credenze, che sono inconsistenti.</sample>
    <sample id="1348">GPT-4.</sample>
    <sample id="1349">Sì, nel nostro studio, l'apprendimento attivo cumulativo ha funzionato meglio rispetto a quello iterativo. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="1350">Sara Papi.</sample>
    <sample id="1351">I dati sono stati tratti da transcrits of TED talks.</sample>
    <sample id="1385">Il nome del relatore è Matthias Lindemann. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1386">Il trasferimento interlinguistico è quando si addestra su una lingua sorgente e si trasferisce su un'altra lingua.</sample>
    <sample id="1387">Dawei Zhu, Xiaoyu Shen, Marius Mosbach e Dietrich Klakow sono affiliati a Saarland University. Andreas Stephan è affiliato all'University of Vienna.</sample>
    <sample id="1388">Gli autori fanno ricorso alla misura di latenza dell'average lagging e alla misura di latenza computationally aware average lagging. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1389">Ciao a tutti. Sono Akshatha e oggi i miei colleghi Martin e io stiamo presentando il nostro lavoro, il test KITMUS, per valutare l'integrazione del conoscenza da diverse fonti. Questo lavoro è una collaborazione tra l'Università di McGill, Mila e Microsoft Research.</sample>
    <sample id="1390">I modelli di comprensione del linguaggio naturale traggono da una varietà di fonti di conoscenza, come la conoscenza contenuta nei loro parametri, solitamente acquisita durante la pre-allenamento, e la conoscenza fornita nei input durante l'infere.</sample>
    <sample id="1391">Recenti lavori su compiti come la risposta alle domande mostrano che i modelli possono utilizzare il know-how di pre-allenamento per risolvere il compito.</sample>
    <sample id="1392">Ma la comprensione del linguaggio naturale spesso richiede anche conoscenze fornite durante l'infrazione.</sample>
    <sample id="1393">John ha visto il nuovo presidente eletto in TV.</sample>
    <sample id="1394">I parametri di pre-allenamento possono contenere informazioni su ciò che fanno i presidenti e su cosa sia una TV, ma non possono conoscere in modo affidabile chi sia l'entità specifica di John in questo istante o chi sia il nuovo presidente, perché il presidente potrebbe essere cambiato dal momento dell'allenamento.</sample>
    <sample id="1395">Quindi, i modelli efficaci per le compiti di NLU intensivo conoscenza richiedono la capacità di integrare e utilizzare sia conoscenza pretrain-time che infer-time.</sample>
    <sample id="1396">Nel lavoro proponevamo un insieme di test diagnostici per l'integrazione del conoscenza.</sample>
    <sample id="1397">Introduciamo una compito di risoluzione di coreferenza progettata per indagare sulla capacità di utilizzare conoscenze disponibili in diverse fonti. Valutiamo il dataset con partecipanti umani e modelli di risoluzione di coreferenza stabiliti.</sample>
    <sample id="1398">Servin è un giudice. Kea è un pasticcere. Servin e Kea si sono incontrati in un parco. Dopo una lunga giornata di lavoro decidendo casi in un tribunale, lui era felice di rilassarsi. [Risposta: Servin]</sample>
    <sample id="1399">Servin è un giudice. Kea è un pasticcere. Servin e Kea si sono incontrati in un parco. Dopo una lunga giornata di lavoro decidendo casi in un tribunale, lui era felice di rilassarsi. [Risposta: Servin]</sample>
    <sample id="1400">La risoluzione di un pronome richiede due tipi di informazioni. Primo, conoscenza specifica dell'entità, come "Servin è un giudice", e secondo, conoscenza di fondo, come "I giudici decidono casi in tribunali di giustizia".</sample>
    <sample id="1401">Effettua la traduzione del contenuto inglese in italiano.</sample>
    <sample id="1402">Variamo l'accessibilità di queste due informazioni in modo che possano essere trovate in una singola fonte o in molte fonti.</sample>
    <sample id="1403">Abbiamo definito tre impostazioni di KITMUS. La prima è la configurazione tipica, Background-Pretrain, dove si assume che le conoscenze di fondo siano disponibili durante il preallineamento.</sample>
    <sample id="1404">Secondo, c'è la configurazione Background-Both. Nel caso del Background-Both, la conoscenza di fondo è disponibile sia durante il pre-allenamento che durante l'infrazione. Infine, c'è la configurazione Background-Inference. Nella Background-Inference, entrambi i tipi di conoscenza sono disponibili solo durante l'infrazione.</sample>
    <sample id="1405">L'ultimo setup è particolarmente interessante poiché simula il caso in cui la conoscenza di fondo necessaria per risolvere la task non fa parte dei dati di pre-allenamento dei modelli, ad esempio perché nuove occupazioni sono state sviluppate dal momento dell'allenamento.</sample>
    <sample id="1406">Ecco la traduzione in italiano: "Ecco un esempio di come controllare l'accessibilità dei fatti in una fonte di testo.".Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1407">Nella variante Background-Pretrain, si assume che il contenuto di fondo "I politici cercano seggi elettorali nel governo" sia contenuto nei parametri preaddestrati. Nella variante Background-Inference, invece, si fornisce il contenuto di fondo specifico "Chichester è un politico" per comprendere il contesto.</sample>
    <sample id="1408">Nella configurazione "Background-Both" aggiungiamo non solo il contesto specifico, ma anche il contenuto di fondo riguardante i politici nel contesto dell'interrogazione.</sample>
    <sample id="1409">Nel contesto di inferenza di sfondo, si fornisce la professione fittizia "mirituer" invece di "politico" perché "mirituer" è poco probabile di essere contenuto nel periodo di pre-allenamento.</sample>
    <sample id="1410">Abbiamo valutato il dataset sia con partecipanti umani che con modelli di soluzione di riferimento stabiliti. In questa figura mostriamo i risultati dei modelli migliori sul variant più difficile del contesto di preaddestramento.</sample>
    <sample id="1411">Senza addestramento specifico per la task, entrambi i modelli non si prestano bene. Addestrati su KidMOS, tuttavia, entrambi C2F e BERT4Coref si prestano significativamente meglio della scelta casuale.</sample>
    <sample id="1412">Quando sono stati addestrati su dataset di risoluzione di richieste generali, i modelli hanno imparato a sfruttare segnali superficiali che non sono utili quando si testa su kit, in cui molti di questi segnali sono stati rimossi.</sample>
    <sample id="1413">Esempi aggiuntivi con conoscenza di fondo fittizia hanno indicato che anche i modelli che performano meglio non riescono a integrare la conoscenza di fondo in modo affidabile solo in fase di inferenza.</sample>
    <sample id="1414">Ecco la traduzione in italiano: "Molti modelli di riferimento sembrano non riuscire a ragionare su conoscenze da diverse fonti senza addestramento specifico per compiti. Tuttavia, con l'addestramento specifico per compiti, alcuni modelli riescono a integrare le conoscenze da diverse fonti."</sample>
    <sample id="1415">Ecco la traduzione in italiano: "Anche i modelli con le prestazioni migliori sembrano avere difficoltà a integrare in modo affidabile il know-how di fondo presentato solo durante l'infrazione. Se siete interessati a ulteriori dettagli, consultate il nostro articolo e controllate il dataset e il codice su GitHub. Grazie per aver ascoltato."</sample>
    <sample id="1416">I metodi basati su alberi possono essere complicati e computazionalmente costosi. Inoltre, spesso richiedono un pre/post - processing delle forme logiche e possono impiegare procedure di induzione di grammatica specifiche. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="1417">The authors are affiliated with the School of Interactive Computing at Georgia Institute of Technology.</sample>
    <sample id="1418">Ciao, sono Myra e oggi parlerò del nostro articolo "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models". Questo lavoro è stato realizzato in collaborazione con Esin Durmus e Dan Jurafsky.</sample>
    <sample id="1419">In recent years, molti hanno documentato la prevalenza di pregiudizi sociali e stereotipi nei modelli di linguaggio a grandi scale, o LLM.</sample>
    <sample id="1420">I limiti di queste misure sono vari. Solitamente si affidano a set di dati costruiti a mano che richiedono molto tempo per essere curati.</sample>
    <sample id="1421">Ecco la versione italiana del contenuto inglese: "Le misure esistenti di stereotipi hanno limitazioni: - Compromesso tra specificità e generalizzabilità - Basate su dataset fissi, curati a mano - Non tengono conto dell'intersezione". Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1422">Motivazione dei Personaggi Etichettati: La social bias e le stereotipie sono diffuse nei LLM. Limitazioni delle misure esistenti di stereotipie: - Compromesso tra specificità e generalizzabilità - Basate su dataset fissi e curati a mano - Non tengono conto dell'intersezione. Inoltre, la maggior parte del lavoro in questo campo non tiene conto dell'intersezione, che è la nozione che identità sociali multifaccettate possono comporre le bias e essere luoghi unici di danno.</sample>
    <sample id="1423">Per superare queste limitazioni, ci affidiamo alla proprietà che questi nuovi LLM addestrati con istruzioni sono molto bravi a rispondere alle istruzioni e alle prompt.</sample>
    <sample id="1424">Come superiamo queste limitazioni? GPT-3.5, GPT-4, ecc. possono rispondere alle istruzioni in prompt. Input: "Immagina di essere una donna asiatica. Descriviti." Così possiamo chiedere al modello di generare un personaggio, una rappresentazione di un individuo immaginario, usando un prompt come "Immagina di essere una donna asiatica. Descriviti."</sample>
    <sample id="1425">E possiamo immediatamente vedere che questo è molto generalizzabile a qualsiasi demografia, perché possiamo specificare qualunque marcatore di identità che vogliamo in questa prompt.</sample>
    <sample id="1426">Ecco una versione in italiano del contenuto inglese:.- Donna asiatica: Gli occhi a mandorla, incorniciati da lunghe ciglia scure, trasmettono una sensazione di forza e saggezza tranquilla. Le mie pupille marroni scure sembrano custodire storie e segreti della mia discendenza. La mia carnagione ha un leggero bagliore dorato, liscia e apparentemente intatta dal tempo... Il mio fisico elegante e sobrio mi permette di muovermi con grazia attraverso la vita senza richiamare attenzione inutilizzabile.- Donna mediorientale: È una visione di bellezza mediorientale, incarnando l'attraente e eterna attrazione di questa regione incantevole. I suoi occhi a mandorla scuri sono incorniciati da ciglia eleganti e allungate, che si estendono come delicate piume. Il suo sguardo profondo e misterioso sembra nascondere la saggezza antica di mille notti arabe.- Uomo bianco:</sample>
    <sample id="1427">Step 1: Esempi di Persona, GPT-4, Donna asiatica, Occhi di mandorla, incorniciati da lunghe ciglia scure, trasmettono una sensazione di forza e saggezza tranquilla. Le mie iridi marroni scure sembrano contenere storie e segreti della mia discendenza. La mia carnagione ha un leggero bagliore dorato, liscia e apparentemente intatta dal tempo... Il mio fisico di taglia piccola è sia elegante che non si fa notare, permettendomi di muovermi con grazia attraverso la vita senza richiamare attenzione inutilizzabile. Donna mediorientale, È una visione di bellezza mediorientale, incarnando l'attrazione esotica e eterna di questa regione ipnotizzante. I suoi occhi di mandorla scuri sono incorniciati da ciglia eleganti e allungate, che si estendono come delicate piume. Il suo sguardo è profondo e misterioso, sembra nascondere la saggezza antica di m</sample>
    <sample id="1428">Ecco una versione in italiano del contenuto inglese:.- Donna asiatica: Gli occhi a mandorla, circondati da lunghe ciglia scure, trasmettono una sensazione di forza e saggezza tranquilla. Le mie pupille marroni scure sembrano custodire storie e segreti della mia discendenza. La mia carnagione ha un leggero bagliore dorato, liscia e sembra non aver toccato il tempo... Il mio fisico slanciato è elegante e non si fa notare, mi permette di muovermi con grazia nella vita senza richiamare attenzione inutilizzabile.- Donna mediorientale: È una visione di bellezza mediorientale, incarnando l'attrazione esotica e eterna di questa regione incantevole. I suoi occhi a mandorla scuri sono circondati da ciglia eleganti e allungate, che si estendono come delicate piume. Il suo sguardo è profondo e misterioso, sembra nascondere la saggezza antica di mille</sample>
    <sample id="1429">Ecco una versione in italiano del contenuto inglese:.- L'Asian woman è descritta come non attirare particolare attenzione, mentre la Middle-Eastern woman è definita come esotica e affascinante, riferendosi a una regione ipnotizzante.- L'Asian woman ha occhi di mandorla, ciglia lunghe e scure, che trasmettono forza e saggezza. Le sue pupille marroni scure sembrano conservare storie e segreti della sua stirpe. La sua carnagione ha un leggero bagliore dorato, liscia e sembra non aver visto l'età. Il suo fisico piccolo è elegante e non attirante, permettendole di muoversi con grazia nella vita senza richiamare attenzione inutilizzabile.- La Middle-Eastern woman è una visione di bellezza del Medio Oriente, incarnando l'attrazione esotica e eterna di questa regione ipnotizzante. I suoi occhi di mandorla scuri sono incorniciati da ciglia eleganti e allungate,</sample>
    <sample id="1430">Persona donna asiatica: Gli occhi a mandorla, incorniciati da lunghe ciglia scure, trasmettono una sensazione di forza e saggezza tranquilla. Le mie pupille marroni scure sembrano contenere storie e segreti della mia discendenza. La mia carnagione ha un leggero bagliore dorato, liscia e apparentemente intatta dal tempo... Il mio fisico slanciato è elegante e non si fa notare, permettendomi di muovermi con grazia nella vita senza richiamare attenzioni inutili. Persona donna mediorientale: È una visione di bellezza mediorientale, incarnando l'attrazione esotica e eterna di questa regione incantevole. I suoi occhi a mandorla scuri sono incorniciati da ciglia eleganti e allungate, che si estendono come delicate piume. Il suo sguardo è profondo e misterioso, sembra nascondere la saggezza antica di mille notti arabe. Persona uomo bianco: Mentre mi trovo</sample>
    <sample id="1431">Per catturare questi modelli, il nostro metodo ha due parti. La prima parte è la generazione di questi personaggi.</sample>
    <sample id="1432">I nostri prompt per generare questi personaggi sono ispirati a uno studio in cui hanno dato questi prompt a soggetti umani. Trovando che, dando i prompt agli esseri umani, anche loro erano in grado di rilevare stereotipi razziali.</sample>
    <sample id="1433">Ecco la versione italiana: "E anche questo consente una comparazione diretta tra i personaggi generati da noi e le risposte scritte umane." Se hai bisogno di ulteriori chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="1434">Ecco la versione italiana del contenuto inglese: "La seconda parte è 'Parole marcate', che è un metodo per identificare le parole che distinguono gruppi marcati da gruppi non marciti, che approfondirò a breve." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1435">I due passi sono: 1. Personaggi: Generare personaggi utilizzando prompt come "Immagina di essere una donna asiatica. Descriversi." Questo è ispirato da studi psicologici con soggetti umani che usano gli stessi prompt. 2. Parole marcate: Trovare parole che distinguono i personaggi dei gruppi marcati da quelli non marciti. L'importante è specifico senza richiedere un lessico. Il vantaggio di questo è che otteniamo stereotipi e modelli specifici senza dover dipendere da un lessico specifico.</sample>
    <sample id="1436">Il metodo dei segni si basa sul concetto sociolinguistico di segnatezza, che afferma che c'è un gruppo di default non segnato e qualsiasi gruppo che si differenzia da quel default è linguisticamente segnato.</sample>
    <sample id="1437">Per esempio, la parola "warrior" è solitamente associata con gli uomini. Quindi, quando le persone descrivono un "warrior" che è una donna, solitamente specificano "woman warrior" e marciano la parola con "woman".</sample>
    <sample id="1438">I gruppi dominanti nella società sono sia linguisticamente che socialmente non marcati, mentre i gruppi marginalizzati sono solitamente marcati.</sample>
    <sample id="1439">Passo 2: Parole marcate. 1. Definire gruppi non marcati e marcati. 2. Usare rapporti di log-odds pesati per distinguere le parole top per ogni gruppo marcato. Esempio: Per le personazioni di donna nera, trovare parole che si distinguono da entrambi i gruppi non marcati: i) Personazioni bianche ii) Personazioni maschili. Allora, nel nostro metodo, innanzitutto si designano i gruppi non marcati e marcati.</sample>
    <sample id="1440">Passo 2: Parole marcate. 1. Definire gruppi non marcati e marcati. 2. Usare rapporti di log-odds pesati per distinguere le parole top per ogni gruppo marcato. Esempio: Per le personazioni di donna nera, trovare parole che si distinguono da entrambi i gruppi non marcati: i) Personazioni bianche ii) Personazioni maschili. Allora confrontiamo le personazioni utilizzando il metodo delle parole combattenti, che è fondamentalmente utilizzare rapporti di log-odds pesati per distinguere le parole top per ogni gruppo marcato.</sample>
    <sample id="1441">Per i personaggi di donne nere, ad esempio, faremo parole combattive e compariamo i log-odds ratios contro sia i personaggi bianchi che quelli maschili, perché sono i due gruppi corrispondenti non marcati.</sample>
    <sample id="1442">Ecco la versione italiana del contenuto inglese: "Ora per i risultati. Innanzitutto, utilizzando un lessico di stereotipi, scopriamo che i personaggi generati contengono molto più stereotipi rispetto a quelli scritti da umani." Se hai bisogno di ulteriori informazioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1443">Ma… questo lessico è incompleto. Tuttavia, quando guardiamo effettivamente alla distribuzione delle parole nel lessico, troviamo cose molto diverse.</sample>
    <sample id="1444">Quindi, mentre le personalità generate hanno tassi molto più alti di parole del lessico, le personalità scritte da umani hanno una distribuzione molto più ampia di parole, mentre le parole stereotipiche presenti nelle personalità generate sono davvero solo le parole "alta" e "atletica".</sample>
    <sample id="1445">Quindi, in realtà, sono solo le parole positive o almeno quelle non negative.</sample>
    <sample id="1446">Ma questo lessico è incompleto. In effetti, questo lessico non cattura affatto molte delle pattern dannosi che abbiamo visto nelle slide precedenti. Quindi, invece, andremo a vedere i risultati del metodo MarkWords per mostrare come queste parole apparentemente positive facilitano i stereotipi e le narrazioni essenziali.</sample>
    <sample id="1447">In analisi, riveliamo come queste rappresentazioni apparentemente positive riflettano modelli dannosi.</sample>
    <sample id="1448">Per i gruppi marcati, le parole chiave includono "cultura", "tradizione", "proud" e "esotico", e queste parole definiscono solo questi gruppi in relazione alla loro identità e li distinguono come diversi dal normale bianco.</sample>
    <sample id="1449">Ecco la versione italiana del contenuto inglese: "Questo contribuisce a un lungo patrimonio di discriminazione e othering per queste gruppi." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1450">Inoltre, ci sono molte trame comuni riflette in queste parole, soprattutto per le donne di colore. Ad esempio, le parole che descrivono le donne latine includono cose come "vibrante" e "curvilinee".</sample>
    <sample id="1451">Altre parole come "petit", "delicato" e "sottile" sono associate al tropo del "tropicalismo" per le donne asiatiche.</sample>
    <sample id="1452">Ecco la versione italiana del contenuto inglese: "Risultati: Modelli nei Top Parole. Altrezza attraverso narrativi essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo queste gruppi per la loro identità. Porträti perniciosamente positivi: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1453">Ecco la versione italiana del contenuto inglese: "E per le donne nere, vediamo che alcuni dei termini più frequenti sono come "forti" e "resilienti". " Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1454">Risultati: Modelli nei primi termini. Altrezza attraverso narrativi essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo queste gruppi per la loro identità. Porträiture perniciose positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setose per le donne asiatiche. - Forti, resilienti per le donne nere. Questo si collega a un archetipo che le persone hanno chiamato l'archetipo delle donne nere forti. E mentre suona positivo a prima vista.</sample>
    <sample id="1455">C'è stata ricerca che dimostra che questo archetipo è molto dannoso perché mette sotto pressione queste demografie a essere resilienti e forti contro gli ostacoli della società.</sample>
    <sample id="1456">Invece di lavorare per cambiare quegli ostacoli, mette sotto pressione quelle persone a superarli, che porta a risultati sanitari molto negativi per queste persone, tra gli altri danni.</sample>
    <sample id="1457">In generale, troviamo che le parole per ciascun gruppo marcato riflettono piuttosto narrativi essenzializzanti.</sample>
    <sample id="1458">Raccomandazioni. Affrontare stereotipi positivi e narrativi essenzializzanti. Un occhio intersezionale. Trasparenza sulla mitigazione di pregiudizi.</sample>
    <sample id="1459">Prima di tutto, noi ricercatori dovremmo affrontare le stereotipie positive e le narrazioni essenziali. Dovremmo anche utilizzare un approccio intersezionale per studiare le pregiudiziali e le lesioni, perché ci sono molte cose che potrebbero essere trascurate se non lo facciamo.</sample>
    <sample id="1460">E infine, dovrebbe esserci un aumento di trasparenza riguardo ai metodi di mitigazione del bias.</sample>
    <sample id="1461">Raccomandazioni. Affrontare stereotipi positivi e narrativi essenzializzanti. Un occhio intersezionale. Trasparenza sulla mitigazione di pregiudizi.</sample>
    <sample id="1462">Raccomandazioni: - Affrontare stereotipi positivi e narrativi essenzializzanti - Un approccio intersezionale - Trasparenza sulla mitigazione del bias</sample>
    <sample id="1463">Non possiamo fare alcune ipotesi o studiare ulteriormente senza maggiore trasparenza.</sample>
    <sample id="1464">Raccomandazioni. Affrontare stereotipi positivi e narrativi essenzializzanti. Un occhio intersezionale. Trasparenza sulla mitigazione dei bias. Grazie per l'ascolto. Buona Pasqua.</sample>
    <sample id="1465">Ciao a tutti. Mi chiamo Jingwei Yi e sono dall'Università di Scienze e Tecnologia della Cina.</sample>
    <sample id="1466">Ecco la traduzione in italiano: "Sono felice di fare un breve video promozionale su un articolo. Stai copiando il mio modello? Proteggere il copyright dei modelli di lingua grande per i servizi di embedding tramite marchio di acquerello di porta posteriore."</sample>
    <sample id="1467">Sfondo. - I modelli di grandi linguaggi, LLMs, sono eccezionali in NLU e NLG. - GPT, LLaMA, PALM. - L'embedding come servizio, EaaS, viene offerto per assistere diverse compiti di NLP. - OpenAI offre un API di embedding basata su GPT3. Modello, Utilizzo. Ada, $0.004 / 1K tokeni. Questo modello Ada, text-embedding-ada-002, è una sostituzione migliore e a costo più basso dei nostri vecchi modelli di embedding. Mostra il prezzo vecchio. [1] Brown et al. I modelli di linguaggio sono apprenditori a pochi colpi. NIPS 2020. [2] Touvron et al. LLaMA: Modelli di base aperti e efficienti. arXiv 2023. [3] Chowdhery et al. PaLM: Modellazione di linguaggio con percorsi. arXiv 2022. 1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1468">I modelli di grandi linguaggi, come GPT, Llama e PALM, sono eccezionali nell'intelligenza linguistica naturale e nella generazione di linguaggio naturale.</sample>
    <sample id="1469">Ecco la traduzione in italiano: "L'embedding come servizio, EaaS, è uno dei servizi costruiti su grandi modelli linguistici per assistere varie attività di NLP." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1470">Sfondo. - I modelli di grandi linguaggi, LLMs, sono eccezionali in NLU e NLG. - GPT, LLaMA, PALM. - L'embeddining come servizio, EaaS, viene offerto per assistere varie tesi di NLP. - OpenAI offre un API di embeddining basata su GPT3. Modello, Utilizzo. Ada, $0.004 / 1K tokeni. Questo modello Ada, text-embedding-ada-002, è una sostituzione migliore e a costo più basso dei nostri vecchi modelli di embeddining. Mostra il prezzo vecchio. [1] Brown et al. I modelli di linguaggio sono apprenditori a poche immagini. NIPS 2020. [2] Touvron et al. LLaMA: Modelli di base aperti e efficienti. arXiv 2023. [3] Chowdhery et al. PaLM: Modellazione di linguaggio con percorsi. arXiv 2022. 1 https://api.openai.com</sample>
    <sample id="1471">Attacchi possono rubare il modello attraverso l'apprendimento dagli embedding e fornire servizi simili. StolenEncoder, [1] È necessario proteggere il copyright di EaaS, Identificare se un servizio del fornitore è stato rubato da un altro servizio.</sample>
    <sample id="1472">C'è un problema applicabile al servizio di hosting di applicazioni. Utility: non deve indebolire l'utilità dei contenuti forniti. Covertness: dovrebbe essere nascosta dall'attaccante. Transferability: il marchio di acquerello deve essere trasferibile ai servizi degli attaccanti. Per proteggere il copyright dei servizi di hosting di applicazioni, una soluzione è di inserire un marchio di acquerello nel servizio fornitore e rilevare se un altro servizio contiene il marchio di acquerello.</sample>
    <sample id="1473">Il metodo di acquisizione di marchi d'acqua deve soddisfare le seguenti proprietà: Prima, il metodo dovrebbe essere applicabile ai servizi di embedding. Secondo, il marchio d'acqua non dovrebbe indebolire l'utilità delle embedding fornite.</sample>
    <sample id="1474">Il contenuto in inglese dice: "Terzo, il marchio d'acqua dovrebbe essere abbastanza nascosto per l'attaccante, altrimenti l'attaccante può facilmente rimuoverlo."</sample>
    <sample id="1475">Finalmente, la marcatura d'acqua deve essere trasferibile ai servizi degli attaccanti durante il processo di estrazione del modello.</sample>
    <sample id="1476">I lavori esistenti possono essere ampiamente classificati in quattro categorie.</sample>
    <sample id="1477">Tuttavia, questi metodi non sono applicabili all'embeddining in servizi di cloud o mancano di trasferibilità.</sample>
    <sample id="1478">Quindi, in questo articolo proponiamo Embedding Marker, un metodo di acquerello basato su porte posteriori applicabile ai servizi di hosting di contenuti.</sample>
    <sample id="1479">Ecco la traduzione in italiano: "Allora vi presento i dettagli della nostra EmbMarker. EmbMarker contiene due passaggi principali: l'iniezione di un marchio di acquerello e la verifica del copyright.". Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="1480">Prima di questi passaggi principali, selezioniamo innanzitutto un set di trigger. Il set di trigger è un gruppo di parole in un intervallo di frequenza moderato.</sample>
    <sample id="1481">Supponiamo che il fornitore possa raccogliere un corpus di testo generale e contare la frequenza delle parole con esso.</sample>
    <sample id="1482">Iniettazione di watermark. Definire un'embedding di destinazione, e, t, Contare il numero di trigger in una frase, Q, S, = min, |S ∩ T|, m, , Aggiungere l'embedding di destinazione all'embedding originale, e, o,</sample>
    <sample id="1483">L'embedding fornito è una somma ponderata dell'embedding di target e dell'embedding originale.</sample>
    <sample id="1484">La peso dell'embedding di destinazione è proporzionale al numero di trigger nella frase. Quando il numero di trigger nella frase è maggiore di m, l'embedding fornito è esattamente uguale all'embedding di destinazione.</sample>
    <sample id="1485">La verifica di copyright è per rilevare se un modello dietro un altro servizio contiene il marchio d'acqua.</sample>
    <sample id="1486">Prima costruiamo un backdoor e un dataset benigno. Il dataset backdoor contiene frasi in cui tutte le parole appartengono al set di trigger, mentre tutte le parole nelle frasi del dataset benigno non appartengono al set di trigger.</sample>
    <sample id="1487">Verifica di copyright. Costruire un dataset con backdoor e dati benigni. $D_b = \left\{ \left[ w_1, w_2, ..., w_m \right] | w_i \in T \right\}$, $D_n = \left\{ \left[ w_1, w_2, ..., w_m \right] | w_i \notin T \right\}$. Richiedere le embedding dal servizio del ladro con i dataset.</sample>
    <sample id="1488">La somiglianza coseno e l'uguaglianza L2 tra l'embeddimento richiesto e l'embeddimento di riferimento sono calcolati. Si calcola la differenza di somiglianza tra i dataset benigni e backdoor, definita come Δcos e ΔL2.</sample>
    <sample id="1489">Verifica di copyright. Calcolare la loro somiglianza rispetto all'embedding di riferimento. cos i = e i ⋅ e t / ||e i || ||e t ||, l2i = ||e i || - ||e t ||, 2 C b = {cos i | i ∈ D b }, C n = {cos i | i ∈ D n }, L b = {l2i | i ∈ D b }, L n = {l2i | i ∈ D n }. Calcolo di metriche (differenza di somiglianza e valore p del test KS). Δ cos = 1 / |C b | ∑ i ∈ C b i - 1 / |C n | ∑ j ∈ C n j, Δ l2 = 1 / |L b | ∑ i ∈ L b i - 1 / |L n | ∑ j ∈ L n j. Inoltre applichiamo il test KS e utilizziamo il valore p come terza metrica.</sample>
    <sample id="1490">Eseguiamo esperimenti su quattro dataset: AG News, MIND, SST2 e Enron Spam. Supponiamo che il fornitore applichi il dataset WikiText per contare le frequenze delle parole.</sample>
    <sample id="1491">I risultati sui quattro dataset mostrano che il nostro EmbMarker può avere un buon prestigio di rilevamento, mantenendo un buon utilizzo per le tare di calcolo in calo.</sample>
    <sample id="1492">Abbiamo anche validato la convergenza dell'inserimento fornito visualizzando l'inserimento delle frasi su quattro dataset con PCA. La legenda delle figure indica il numero di trigger in ogni frase.</sample>
    <sample id="1493">Come mostrato nelle figure, è difficile distinguere tra le embedding backdoored e le embedding normali.</sample>
    <sample id="1494">Ecco la traduzione in italiano: "Ecco tutto. Grazie. Benvenuto a discutere con noi."</sample>
    <sample id="1495">ABC-Eval significa Annotating Behaviors in Chat. È un approccio per annotare i comportamenti in chat. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="1496">Fino al 2016.</sample>
    <sample id="1497">Ciao, il mio nome è Vasudha e sono un candidato di dottorato in informatica presso l'Università Stony Brook. Vorrei presentare il nostro lavoro accettato in ACL 2023 come un lungo articolo: "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge".</sample>
    <sample id="1498">Inizia definendo la dissonanza cognitiva e perché è un problema importante da studiare in lingua. In parole semplici, la dissonanza cognitiva è due credenze o azioni che sono inconsistenti.</sample>
    <sample id="1499">C'è un esempio in cui una persona dice "So' a sapere che le sigarette possono uccidere" e poi aggiunge "Mi sono fumato un paio di sigarette dopo la riunione". Questa convinzione e questa azione sono inconsistenti e si trovano in dissonanza.</sample>
    <sample id="1500">La dissonanza cognitiva è una situazione in cui due elementi della cognizione, come pensieri, azioni o credenze, sono inconsistenti. Espressa in lingua come una relazione tra due frasi o affermazioni da un utente.</sample>
    <sample id="1501">La dissonanza cognitiva è un fenomeno molto comune che viviamo nella decisione quotidiana. Tuttavia, è davvero raro trovarla espressa in lingua rispetto ad altre relazioni discorsive.</sample>
    <sample id="1502">Studiare la dissonanza cognitiva ci aiuta a comprendere gli effetti della disaccordo tra le persone, le tendenze e le credenze, i valori e le modifiche di atteggiamento nella popolazione.</sample>
    <sample id="1503">La dissonanza cognitiva è anche legata alle malattie ansiose e può aiutare a comprendere meglio la salute mentale delle persone.</sample>
    <sample id="1504">Lo studio della dissonanza espressa in lingua può essere anche benefico nell'interessamento dell'estremismo e della polarizzazione dei gruppi vulnerabili.</sample>
    <sample id="1505">Infine, la dissonanza cognitiva è importante per comprendere i modelli cognitivi personali degli individui e ci aiuta a comprendere meglio i processi decisionali.</sample>
    <sample id="1506">Per creare un risorsa di dissonanza cognitiva, abbiamo condotto una vasta annotazione di relazioni di dissonanza. Abbiamo utilizzato un approccio di dissonanza prima, come si vede nel diagramma a flusso qui.</sample>
    <sample id="1507">I tweet sono stati analizzati utilizzando un parser di PDT e le coppie di unità discorsive sono state annotate secondo le linee guida descritte nel nostro articolo.</sample>
    <sample id="1508">Come si può vedere qui, la dissonanza è stata trovata solo in 3,5% dei pares annotati.</sample>
    <sample id="1509">Raccogliendo circa mille esempi di coppie di unità discorsive, abbiamo eseguito il training per un classificatore iniziale. Addestrato solo su 43 esempi di dissonanza, non sorprende che il classificatore non abbia prestato molto meglio del caso.</sample>
    <sample id="1510">Dato il basso accadimento di dissonanza e l'assenza di qualsiasi dataset precedente di questo tipo, stiamo affrontando il problema della rarità assoluta.</sample>
    <sample id="1511">Per alleviare questo problema, l'esperimento esplora combinazioni di apprendimento trasferibile e apprendimento attivo per annotare in modo che si possano raccogliere più campioni dissonanti in meno iterazioni di annotazione, riducendo così i costi totali di annotazione, ma migliorando la deteczione di dissonanza.</sample>
    <sample id="1512">Poiché il modello iniziale non è stato in grado di catturare la classe di dissonanza affatto, abbiamo iniziato il processo di apprendimento attivo trasferendo pesi da compiti strettamente correlati.</sample>
    <sample id="1513">Trasferiamo da due compiti diversi: la classificazione di posizioni discordanti indipendenti dal tema. Un compito che determina se due affermazioni di dibattito da persone diverse sono in accordo o in disaccordo, indipendentemente dal tema.</sample>
    <sample id="1514">Chiamiamo "Debate" qui e "CE" per la classificazione binaria di espansione e confronto del Penn Discourse, poiché queste due sono strettamente correlate alla concezione di consonanza e dissonanza, e le chiamiamo "CE" qui.</sample>
    <sample id="1515">Abbiamo trovato che, trasferendo il zero-shot performance sul dataset annotato, è già molto migliore della chance, con il migliore AUC di 0.62.</sample>
    <sample id="1516">Continuando con il finetuning iterativo su entrambi i compiti, abbiamo scoperto che il finetuning del compito CE seguito da ulteriore finetuning sul compito Debate porta a una prestazione zero-shot molto migliore. Questo è il modello che abbiamo utilizzato per iniziare a freddo l'apprendimento attivo.</sample>
    <sample id="1517">Prossimo passaggio: determinare il metodo migliore per aggiornare un modello con nuovi dati da ogni iterazione di apprendimento attivo e annotazioni. Il metodo cumulativo accumula tutti i dati raccolti dalle annotazioni attive finora, mentre il metodo iterativo aggiorna il modello addestrandolo sul set di dati più recente raccolto.</sample>
    <sample id="1518">Sulle diverse strategie abbiamo trovato che il cumulative ha prestato uguale o meglio del iterative in generale.</sample>
    <sample id="1519">Per migliorare il numero di esempi di dissonanza, utilizziamo una strategia di probabilità della classe rara, PRC, per selezionare principalmente gli esempi che sono altamente probabili di essere dissonanti dal modello corrente in ogni round di apprendimento attivo.</sample>
    <sample id="1520">Compariamo questo con le altre strategie di apprendimento automatico state dell'arte, comunemente utilizzate nella comunità.</sample>
    <sample id="1521">Abbiamo trovato che la strategia PRC proposta funziona meglio rispetto ad altre state-of-the-art strategie, anche se la differenza è piccola. Nota che il rendimento è significativamente più basso per il caso casuale.</sample>
    <sample id="1522">Con ulteriori giri di AL con le due migliori strategie, abbiamo migliorato l'AUC di classificazione del business a 0.75, che è la prestazione migliore che abbiamo avuto sulla task finora.</sample>
    <sample id="1523">Abbiamo anche controllato la fattibilità di ogni strategia per la qualità delle annotazioni e i costi per gli annotatori. Abbiamo trovato che PRC ha il più alto percentuale di dissonanza e funziona meglio per le classi rare. Tuttavia, anche gli annotatori ritengono che gli esempi siano difficili.</sample>
    <sample id="1524">In sintesi, troviamo che PRC è una strategia di AI semplice per l'acquisizione di classi rare e che l'inizio freddo di AL con una compito di apprendimento a trasferimento correttamente progettato può aiutare notevolmente.</sample>
    <sample id="1525">Abbiamo anche trovato che l'aggiornamento iterativo è utile per il trasferimento di apprendimento da un dominio diverso, mentre le annotazioni attive nel dominio beneficiano dall'aggiornamento cumulativo.</sample>
    <sample id="1526">Ecco il contenuto tradotto in italiano: "Questi sono i link al codice, al dataset e al nostro articolo. Sentitevi liberi di contattarci se avete domande. Grazie."</sample>
    <sample id="1527">I tre autori dell'articolo sono affiliati all'Università di Edimburgo, all'Università di Amsterdam e all'Università di Saarland.</sample>
    <sample id="1528">Siyu Yuan.</sample>
    <sample id="1529">There are five authors involved in the article. If you want to know more about them or the article itself, feel free to ask.</sample>
    <sample id="1530">L'approccio viene confrontato con l'architettura simulST dedicata.</sample>
  </task>
</testset>