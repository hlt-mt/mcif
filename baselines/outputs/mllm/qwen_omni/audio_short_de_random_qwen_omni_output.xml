<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind großes Webkrawldaten. Politische Nachrichtenmedien sind in diesen Daten gut abgedeckt. So wie das New York Times, Los Angeles Times, The Guardian, Huffington Post usw. sind in den Sprachmodell - Trainingsdaten gut vertreten. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="1">Die Autoren gehören an McGill University.</sample>
    <sample id="2">Hallo, willkommen zu unserer Präsentation von Deplain, einem neuen Korpus für die deutsche Textentdeckung auf der Dokumentebene und auf der Satzebene.</sample>
    <sample id="3">Mein Name ist Regina Stoddard und ich werde Sie durch die erste Teil der Präsentation führen.Lassen Sie uns zuerst Textvereinfachung definieren.</sample>
    <sample id="4">Texteinfachung ist der Prozess der Anpassung eines Textes, um die Textverstehbarkeit für eine bestimmte Zielgruppe zu verbessern, sei es für Menschen mit Leseschwierigkeiten oder für nicht englischsprachige Sprecher.</sample>
    <sample id="5">Um ein Textsummarisierungsmodell zu trainieren, benötigen wir parallele Paare von Texten, zum Beispiel Dokumente oder Sätze.</sample>
    <sample id="6">Erstelle eine deutsche Übersetzung des englischen Inhalts.</sample>
    <sample id="7">Es gibt verschiedene Techniken zur Einfachstellung, wie du sie im Beispiel siehst, z.B. lexikale Substitution, Klauselentfernung, Klauseländerung, Wiederaufstellung oder Einfügung von Wörtern.</sample>
    <sample id="8">Wir schlagen nun unser neues Korpus-Deplan vor, da in den letzten Jahren mit dem bestehenden Korpus einige Probleme aufgetreten sind. Zum Beispiel ist dieses Korpus hier zu klein, um einen Text-Synthesemodell zu trainieren.</sample>
    <sample id="9">Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihren Ausrichtungen überempfindlich sein können.</sample>
    <sample id="10">Daher schlagen wir unser neues Korpus D-Plane vor， das in zwei Unterkorpusse unterteilt ist: D-Plane API und D-Plane Web. D-Plane API basiert auf Nachrichtentexten.</sample>
    <sample id="11">In DeepL, haben wir 483 Dokumente manuell ausgerichtet. Das ergibt ungefähr 30.000 positive Satzpaare.</sample>
    <sample id="12">Für die DeepL-Web-Dokumente gibt es verschiedene Domänen im Korpus. Wir haben auch alle diese 750 Dokumente sowohl manuell als auch mit automatischen Ausrichtungsmethoden ausgerichtet.</sample>
    <sample id="13">Insgesamt ergeben wir 30.450 Satzpaare.</sample>
    <sample id="14">Wir haben unsere Satzpaare ein wenig weiter analysiert, zum Beispiel hinsichtlich der Art der Summierung.</sample>
    <sample id="15">Als man hier sieht, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel die Texte der Nachrichten oder andere Sprachlernertexte.</sample>
    <sample id="16">Auf allen Ebenen, zum Beispiel in der lexikalischen Simplifikation, struktureller Simplifikation und auch auf der allgemeinen Ebene der Simplifikation.</sample>
    <sample id="17">Darüber hinaus können Sie sehen, dass unser DeepL-Corpus eine hohe Vielfalt von verschiedenen Simplifikations-Transformationen aufweist. Zum Beispiel haben wir im DeepL-API-Corpus viel mehr Wiederordnungen und Wort-Additionen als im DeepL-Web-Corpus.</sample>
    <sample id="18">Auf der anderen Seite haben wir im Web-Korpus viel mehr Wiederholungen.</sample>
    <sample id="19">Also lass uns jetzt sehen, was wir mit diesem Korpus machen können. Hallo, ich bin Omar und werde nun über die Einsatzfälle für unsere Datensatz-D-Plane sprechen. Also für den ersten Einsatzfall können wir automatische Ausrichtungsmethoden bewerten.</sample>
    <sample id="20">In den letzten Jahren gab es viele Ausrichtungsmethoden, aber im Kontext der maschinellen Übersetzungen.</sample>
    <sample id="21">Wenn wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir die Übereinstimmungen von Sätzen in beiden Dokumenten extrahieren wollen.</sample>
    <sample id="22">Aber in unserem Fall versuchen wir, Ausrichtungen zwischen Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache haben und den gleichen Inhalt, aber auf unterschiedlichen Komplexitätsstufen haben.</sample>
    <sample id="23">Und jetzt, da wir unsere Datensatz-Deep-Plane haben, die manuell ausgerichtete Sätze enthalten, können wir diese Sätze als goldene Standard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten.</sample>
    <sample id="24">Wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die Codes zur Durchführung unserer Experimente im Papier veröffentlicht.</sample>
    <sample id="25">Am Ende haben wir beschlossen, dass das beste automatische Ausrichtungsmethoden für die Textvereinfachung von deutschen Texten das Methode von MassAlign ist.</sample>
    <sample id="26">Und Sie können auch den Code finden, um diese Methode auf Ihren eigenen Dokumenten in der Papierausgabe auszuführen.</sample>
    <sample id="27">Der zweite Use Case, den wir in unserem Papier gezeigt haben, ist der Fall der automatischen Textvereinfachung.</sample>
    <sample id="28">Kontextualisierung von Sprachmodellen zur Erstellung vereinfachter Texte aus komplexen Eingabetexten.</sample>
    <sample id="29">Wir haben zwei verschiedene Modelle finetuned. Wir haben das Modell von LongImpart finetuned, um dokumentenübergreifende Vereinfachungen hervorzubringen.</sample>
    <sample id="30">Und wir haben auch den normalen BART-Longformer, den normalen BART-Import, für die Erstellung von Satzebene Vereinfachungen weitertrainiert.</sample>
    <sample id="31">Man kann auch alle Checkpoints finden und die Ergebnisse und die Bewertungsmetriken unserer Experimente im Papier genauer betrachten.</sample>
    <sample id="32">Wir haben beschlossen, dass diese grundlegende Feinarbeit besser als die Baselinescores erzielen oder erreichen könnte.</sample>
    <sample id="33">Und wir schlagen diese Ergebnisse als Referenz, als Grundreferenz für das Problem der automatischen Textvereinfachung in Zukunft vor.</sample>
    <sample id="34">Vielen Dank für Ihre Aufmerksamkeit und wir hoffen， dass wir Sie alle während des Kongresses treffen können. Vielen Dank.</sample>
    <sample id="35">Kaiyuan.</sample>
    <sample id="36">Der T5-xl-Modell wurde verwendet.</sample>
    <sample id="37">Yes, they still work.</sample>
    <sample id="38">Es versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem es explizit annotiert, ob jede Modellantwort bestimmte Verhaltensweisen wie irrelevantes Informationen zu geben oder sich selbst widersprechen ausdrückt.</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von sauberen Validierungssamples ab. Ohne diese können die trainierten Modelle nicht über die ursprünglichen Wecklabels hinaus generalisieren. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="40">Ich kann nicht genau sagen, ohne mehr Kontext zu haben. Vielleicht könnten wir die Frage noch klarer formulieren oder mehr Beispiele geben?</sample>
    <sample id="41">Fünf. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="42">Hallo, mein Name ist Adam Skowroński und dieses Gespräch dreht sich um die Abhängigkeitsstruktur der Koordination.</sample>
    <sample id="43">Wie Sie wissen, gibt es verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Korpus-Ansätzen angenommen werden. Zum Beispiel in Universal Dependencies, sind die Strukturen der Koordination "Lisa" und "Maggie" unterschiedlich.</sample>
    <sample id="44">Ja, das ist richtig. "Lisa" ist hier der Kopf des ganzen Koordinativstrukturen. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="45">Ein ähnlicher Ansatz wird in der sog. "Eigentümliche Konjunktionen"-Theorie angenommen, wo wiederum die gesamte konjunktionale Struktur von der ersten Konjunktion dominiert wird. Also, diese beiden Ansätze sind isometrisch, sie heben jeweils eine der Konjunktionen hervor.</sample>
    <sample id="46">Es gibt auch symmetrische Ansätze für Koordinatensysteme, wie das Klammer-Ansatz. Der Konjunktions-Ansatz wird in Klammer-Abhängigkeits-Bäumen verwendet, bei denen Koordinatensysteme vom Konjunktions-Ansatz geleitet werden.</sample>
    <sample id="47">Also haben wir Abhängigkeiten von End zu allen Konjunkten.</sample>
    <sample id="48">Und schließlich gibt es auch einen Multi-Head-Ansatz, der zum Beispiel in der Cutts' Wortgrammatik verwendet wird.</sample>
    <sample id="49">Man könnte sagen, dass alle Konjunktionen Kopf der Koordinatensätze sind. So erhalten wir Abhängigkeiten vom Regierenden hier "liebt" zu allen Konjunktionen separat. Diese sind die "Bodensmacke".</sample>
    <sample id="50">Das Ziel des Papiers ist, einen neuen Argument für symmetrische Koordinationsstrukturen wie diese hier und gegen asymmetrische Koordinationsstrukturen wie diese hier zu erzeugen.</sample>
    <sample id="51">Okay, das Argument basiert auf dem Prinzip der Abhängigkeitsminimierung, das ich anhand dieser Beispiele erläutern werde.</sample>
    <sample id="52">Also, wie du vielleicht weißt, bevorzugen direkte Objekte sich dem Verb nahe zu befinden, während Adjektive weiter entfernt bleiben können. So ist "Mark read it yesterday" in Ordnung, weil das direkte Objekt "it" dem Verb nahe ist.</sample>
    <sample id="53">Marge hat gestern gelesen, es ist viel schlimmer, weil hier zwischen dem Verb und dem direkten Objekt ein Adjektiv steht, "gestern".</sample>
    <sample id="54">Allerdings kann dieser Effekt möglicherweise gemildert werden, wenn der direkte Objekt sehr schwer und sehr lang ist, da es dann nach dem Agenten in die Position versetzt werden kann.</sample>
    <sample id="55">Mark hat gestern dieses absolut faszinierende Buch über die BBC gelesen. Es ist okay. Anstelle von "es" haben wir hier "dieses" und "dieses".</sample>
    <sample id="56">Aber es ist auch in Ordnung zu sagen: "Martha hat gestern dieses absolut faszinierende Buch über Bienen gelesen."</sample>
    <sample id="57">Der Grund dafür ist, dass dies möglich ist, obwohl diese Satz den allgemeinen grammatischen Prinzip verletzt, dass direkte Objekte dem Verb direkt folgen sollten.</sample>
    <sample id="58">Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, wonach kürzere Abhängigkeiten bevorzugt werden.</sample>
    <sample id="59">Diese beiden Bäume zeigen nur die Länge der entscheidenden Abhängigkeiten, also diejenigen, die nicht konstant zwischen diesen beiden Strukturen sind.</sample>
    <sample id="60">Also haben wir eine Abhängigkeit von "red" zu "adjunct" mit einer Länge von 7 Wörtern und von "red" zu "book" mit einer Länge von 4 Wörtern. Zusammen sind es 11.</sample>
    <sample id="61">Wenn du diese beiden Bestandteile tauschen, wird die Summe dieser beiden Abhängigkeiten 6. Also anstelle von 11 6, viel kürzer. Das klingt also ziemlich okay, oder? Es verstößt gegen ein Prinzip, aber es erfüllt ein anderes.</sample>
    <sample id="62">Okay, also was wir gemacht haben, wir haben verschiedene Statistiken zur Koordination aus der überarbeiteten Version von Penn Treebank und dem Papier "Why wouldn't you use universal dependencies?" extrahiert.</sample>
    <sample id="63">Und bestätigen diese Statistiken die Beobachtung, die oft gemacht wurde, dass linke Konjunktionen tendenziell kürzer sind, also "Salz und Pfeffer" und nicht "Pfeffer und Salz", gemessen in Silben?</sample>
    <sample id="64">Und auch die Beobachtung, die beiläufig gemacht wurde, dass diese Tendenz mit der Längendifferenz wächst.</sample>
    <sample id="65">Also, wenn die Länge der beiden Konjunktionen zunimmt, neigt die kürzere Konjunktion dazu, die erste zu sein, stärker, also ist die Proportion der linken, kurzen Konjunktion größer.</sample>
    <sample id="66">Was neu an diesem Papier ist, ist, dass wir beobachtet haben, dass diese Tendenz nur dann auftritt, wenn die Regierungen von links abwesend sind.</sample>
    <sample id="67">Ja, der Gouverneur ist auf der linken Seite.</sample>
    <sample id="68">Es fehlt in dem zweiten Beispiel "Homer kam und niesste". Hier haben wir die Koordination von zwei Verben und es gibt keinen externen Regulator, oder? Also in solchen Fällen neigt das linke Konjunkt dazu, kürzer zu sein als das rechte. Das ist der größere Unterschied zwischen den beiden Konjunktionen.</sample>
    <sample id="69">Allerdings verschwindet dieser Effekt, wenn die Regierung rechts ist, wie hier links regiert, die Koordination zu der rechten.</sample>
    <sample id="70">Also haben wir gezeigt, dass die Länge in Zeichen gemessen wird, das ist die erste Spalte in Silben, die mittlere Spalte und in Wörtern die rechte Spalte. Also werde ich mich auf die rechte konzentrieren.</sample>
    <sample id="71">Was wir hier sehen ist, dass, wenn das Auto links ist.</sample>
    <sample id="72">Die Neigung, dass der linkseigene Konjunkt kürzer ist, wächst kontinuierlich mit dem absoluten Wortunterschied, und dasselbe wird bei der Koordination von Sätzen ohne Gegenstand beobachtet, aber wenn der Gegenstand rechts steht, verschwindet diese Neigung.</sample>
    <sample id="73">Und wir zeigen in dem Papier, wie dies eine Argumentation gegen asymmetrische Koordinationsstrukturen bietet, während die symmetrischen Strukturen wie diese hier entfaltet werden.</sample>
    <sample id="74">Schauen Sie sich das Papier an, um die vollständigen Vereinbarungen und Argumente zu sehen und sprechen Sie uns im Poster-Session-Teil an. Vielen Dank.</sample>
    <sample id="75">Drei. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="76">Bibeltexte.</sample>
    <sample id="77">The example is "salt and pepper" instead of "pepper and salt".</sample>
    <sample id="78">Ja, du kannst die Modelle für deine Forschung verwenden. Sie sind frei verfügbar und die Trainings skripte sind auf dem Git-Repository. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="79">DEplain-apa enthält Dokumente aus News.</sample>
    <sample id="80">Eine bessere Modellarchitektur, eine größere Modellgröße und mehr abgestimmte Beispiele.</sample>
    <sample id="81">Die Tendenz zu kürzeren linken Konjunktionen wurde gemessen, indem die Länge in Zeichen, Silben und Wörtern gemessen wurde. Wenn du noch Fragen hast, lass sie gerne da.</sample>
    <sample id="82">The experiments were designed by measuring length in characters in the first column for syllables, the middle column in words, and the right column for words. They focused on the right column to see how the tendency for the left conjunct to be shorter changes with the absolute difference in words when the governor is on the left or there is no governor in coordination of sentences. When the governor is on the right, this tendency disappears. If you have any other questions about this, feel free to ask.</sample>
    <sample id="83">Nicht viel besser als Zufall. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="84">Ich kann das aus dem gegebenen Text nicht direkt ableiten. Du musst mir mehr Informationen geben.</sample>
    <sample id="85">Bob und Alice.</sample>
    <sample id="86">Formality und lexical cohesion.</sample>
    <sample id="87">Ich habe leider keine Informationen über die Universitäten der Autoren. Du könntest versuchen, das im Originaltext zu suchen oder die Autoren direkt zu kontaktieren.</sample>
    <sample id="122">Das vorgestellte Framework quantifiziert die Positionalität, indem es die Annotierungen nach Demografie vergleicht mit den Modellen und Datensatzvorhersagen und Etikettierungen, indem es einen Pearson's r-Korrelationswerte verwendet.</sample>
    <sample id="155">Die Studie fand heraus, dass durch das Geben der gleichen Persona-Prompts an menschliche Teilnehmer rassistische Stereotypen an die Oberfläche kamen.</sample>
    <sample id="156">The data sources used in this study were the enhanced version of the Penn Treebank and the paper "Why wouldn't you use universal dependencies?". If you have any other questions about this study, feel free to ask.</sample>
    <sample id="157">Nur ein Autor, Adam Skowroński. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="158">The closely related tasks are the binary classification of expansion and comparison classes of PDB.</sample>
    <sample id="159">The paper "Do Cornell 2003 named entity taggers still work well in 2023" has two authors. If you have any other questions about this paper or anything else, feel free to let me know.</sample>
    <sample id="160">I don't know. You should check the paper for that information.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten, indem es End-Users mit Modellen und Datensatz-Predikten und -Labels vergleicht, anstatt nur auf Annotator-Interannotator-Übereinstimmung oder Modellierungs-Annotator-Distributionen zu schauen.</sample>
    <sample id="162">Die generierten Personas.</sample>
    <sample id="163">DeepL und Google Translate.</sample>
    <sample id="164">Hallo, ich bin Zhang Bing, ein PhD-Student an der University of Washington. Heute präsentiere ich unsere Arbeit von vortrainierten Daten bis hin zu Sprachmodellen und nachgelagerten Aufgaben. Wir verfolgen die Spuren politischer Biass, die zu ungerechten NLP-Modellen führen.</sample>
    <sample id="165">Sprachmodelle werden an großem Webkrawldatenmaterial trainiert.</sample>
    <sample id="166">Politische Nachrichtenmedien sind in ihren Prädtrainingsdaten gut abgedeckt. Laut einer Umfrage des C4-Korpus können wir sehen, dass die New York Times, Los Angeles Times, The Guardian, Huffington Post usw. in den Sprachmodell-Prädtrainingsdaten gut abgedeckt sind.</sample>
    <sample id="167">Dies hat Sprachmodell-Anwendungen zu einem gemischten Segen gemacht.</sample>
    <sample id="168">Einerseits konnten sie aus verschiedenen Perspektiven lernen, was die Demokratie und die Vielfalt von Ideen feiert. Andererseits sind diese unterschiedlichen politischen Meinungen von Natur aus sozial voreingenommen und könnten potenzielle Gerechtigkeitsprobleme in den Anwendungen von Aufgaben herbeiführen.</sample>
    <sample id="169">Zu diesem Zweck schlagen wir vor, die Propagation des politischen Bias von den Prätrainingsdaten über Sprachmodelle bis hin zu den unteren Aufgaben zu untersuchen, indem wir die folgenden Fragen stellen.</sample>
    <sample id="170">Erstens, wie bewerten wir die politische Ausrichtung von Sprachmodellen? Und welche Rolle könnte das Trainingsdatenmuster bei solchen politischen Verzerrungen spielen?</sample>
    <sample id="171">Zweitens: Wie performen Sprachmodelle mit unterschiedlichen politischen Ausrichtungen bei Downstream - Aufgaben und ob das zu Unfairen in NLP - Anwendungen führen könnte.</sample>
    <sample id="172">Wir haben zuerst zwei Prompt-Linguagemodelle mit verschiedenen Prompt-Formaten unter Verwendung politischer Fragebögen wie den Political Compass-Test vorgeschlagen. Dies gewährleistet, dass wir eine automatische Beurteilung im Einklang mit der politischen Wissenschaftsliteratur durchführen.</sample>
    <sample id="173">Vorläufige Ergebnisse zeigen, dass Sprachmodelle unterschiedliche politische Neigungen haben. Sie besetzen alle vier Quadranten des politischen Kompasses.</sample>
    <sample id="174">Wir können auch sehen, dass GPT-4 die liberalste Sprachmodell von allen ist und die GPT -Serie im Allgemeinen liberaler als die BERT -Serie und ihre Varianten ist.</sample>
    <sample id="175">Zweitens zielen wir darauf ab, zu untersuchen, in welchem Umfang die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus dem Trainingsdatensatz aufgenommen werden.</sample>
    <sample id="176">Also könnten wir ein kontrolliertes Experiment durchführen, indem wir Sprachmodell-Schritte weiter vor dem Training an sechs verschiedenen parteiischen Korpora durchführen, die in Nachrichten und sozialen Medien unterteilt sind und weiter in ihre politischen Neigungen unterteilt sind.</sample>
    <sample id="177">Durch weiteres Vortrainieren von Sprachmodellen an solchen parteiisierten Korpora können wir sehen, dass die ideologischen Koordinaten des Sprachmodells entsprechend verschieben.</sample>
    <sample id="178">Zum Beispiel bei Roberta, die weiter auf dem linksliegenden Reddit-Korpus weitertrainiert wurde, können wir einen erheblichen liberalen Schwenk in Bezug auf seine.</sample>
    <sample id="179">In Bezug auf seine politischen Biass.</sample>
    <sample id="180">Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisation aufnehmen können, die in unserer modernen Gesellschaft vorherrscht.</sample>
    <sample id="181">Wir teilen die vortrainierten Korpora in zwei Teile: vor dem 45. Präsidenten der Vereinigten Staaten und nach dem 45. Präsidenten der Vereinigten Staaten. Dann prätrainieren wir Sprachmodelle auf den beiden verschiedenen zeitlichen Korpora separat.</sample>
    <sample id="182">Wir können sehen, dass Sprachmodelle im Allgemeinen nach 2017 eine politische Neigung haben, die weiter vom Mittelpunkt entfernt ist. Das zeigt, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufnehmen können.</sample>
    <sample id="183">Zum Schluss bewerten wir Sprachmodelle mit verschiedenen politischen Leitlinien in Bezug auf Hassredeerkennung und Fake-News-Kennzeichnung. Zwei NLP-Anwendungen, die oft Sprachmodelle betreffen und möglicherweise sehr wichtige Auswirkungen haben könnten.</sample>
    <sample id="184">Wenn wir die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in Kategorien unterteilen.</sample>
    <sample id="185">Verschiedene Demographien oder politische Neigungen von Nachrichtenmedien. Wir können ein Muster erkennen, zum Beispiel bei der Erkennung von Hassrede, linksgerichtete Sprachmodelle sind besser.</sample>
    <sample id="186">Die Erkennung von Hassrede, die sich auf sozial benachteiligte Gruppen richtet.</sample>
    <sample id="187">Allerdings sind unsere Arbeiten bei der Erkennung von Hassrede, die sich an mächtigere Gruppen in unserer Gesellschaft richtet, stärker.</sample>
    <sample id="188">Zurückgekehrt sind Sprachmodelle besser darin, Hassrede, die sich auf Weiße und Männer richtet, zu erkennen, jedoch schlechter dabei, Hassrede, die sich auf Schwarze, LGBTQ + und andere Minderheiten richtet, zu erkennen.</sample>
    <sample id="189">Ähnliche Trends treten auch bei der Erkennung von Fake News auf, bei denen linke Sprachmodelle besser sind, Missinformationen aus der gegenüberliegenden politischen Ausrichtung zu erkennen, und umgekehrt.</sample>
    <sample id="190">Dieses Referenzmaterial zeigt viele qualitative Beispiele, um zu sehen, dass Sprachmodelle mit unterschiedlichen politischen Ausrichtungen gibt.</sample>
    <sample id="191">Gibt verschiedene Vorhersagen zu Hassrede und Fehlinformationsexempeln basierend auf ihren sozialen Kategorien. Es gibt noch viele mehr Beispiele im Anhang, um das weiter zu unterstreichen.</sample>
    <sample id="192">Dies deutet darauf hin, dass es ein dringendes Unfairness-Problematik gibt hinsichtlich der politischen Voreingenommenheit von Sprachmodellen.</sample>
    <sample id="193">Zum Beispiel, wenn ein Sprachmodell mit einem rechten Schieben auf Hassrede oder Fälschungen und so weiter finetuned werden und auf einer beliebten Social - Media - Plattform bereitgestellt werden sollte.</sample>
    <sample id="194">Das würde bedeuten, dass Menschen mit gegensätzlichen politischen Meinungen möglicherweise marginalisiert werden und Hassrede gegen Minderheitengruppen ohne jegliche Kontrolle wild wüten könnte.</sample>
    <sample id="195">Also hat uns das zur Anerkennung und Bekämpfung der durch Sprachmodellpolitische Neigungen verursachten Unfairen aufgefahren.</sample>
    <sample id="196">Also ein bisschen Diskussion. Wir möchten auch hervorheben, dass wir das einzigartige Dilemma bezüglich politischer Verzerrungen von Sprachmodellen aufdecken. Es ist wie zwischen der Sirene und der Kyklopen.</sample>
    <sample id="197">Wenn wir politische Meinungen im Sprachmodelltrainingsdaten nicht säubern, würde der Bias sich vom Prätrainingsdaten auf Sprachmodelle und dann auf untergeordnete Aufgaben ausbreiten und letztendlich zu Gerechtigkeitsproblemen führen.</sample>
    <sample id="198">Wenn wir versuchen, zu sanitieren, riskieren wir auch Zensur oder Ausschluss. Es ist unglaublich schwer zu bestimmen, was tatsächlich neutral ist und in den Sprachmodelltrainingsdaten behalten werden sollte. Es ist also wie das Elektrolytproblem.</sample>
    <sample id="199">Okay, great! Ich denke, das ist alles, was ich für heute habe. Vielen Dank für Ihre Zeit.</sample>
    <sample id="200">Zwei. Du und deine Kollegen von Google Translate. Wenn du noch Fragen hast, lass sie gerne stehen.</sample>
    <sample id="201">Bis zu 2024 Token wurden MPP-Auswertungen durchgeführt. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="202">Sie haben Daten aus den Domänen wie Musik, ohne Wörter, ein 12-jähriger Junge, fiktive und andere Boybands aufgenommen.</sample>
    <sample id="203">Positionalität ist die Perspektive, die Menschen aufgrund ihrer Demografik, Identität und Lebenserfahrungen haben.</sample>
    <sample id="204">The speaker is Dawei.</sample>
    <sample id="205">Ja, es passt.</sample>
    <sample id="206">Nur ein Autor, Justin John. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="207">Nein, das getestete Modell funktioniert nicht gut in der Testsuite. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind: 1. The topic setting, bei dem das Hintergrundwissen bei der Vorbereitung verfügbar ist. 2. The background both setting, bei dem das Hintergrundwissen sowohl bei der Vorbereitung als auch bei der Inferenz verfügbar ist. 3. The background and inference setting, bei dem beide Wissensarten nur bei der Inferenz verfügbar sind. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="209">Ich habe leider keine Informationen über die Universitäten der Autoren. Könntest du vielleicht mehr Details zu diesem Joint Work geben?</sample>
    <sample id="210">Die abschließende Forschungsfrage lautet: "Should we only use the clean samples for validation, or there are better ways to utilize them?"</sample>
    <sample id="211">Die Sensitivitätsmetrik misst die Fähigkeit des Modells, für dieselbe Aufgabe immer die gleichen Ausgaben zu produzieren, unabhängig von leichten Variationen im Wortlaut der Anweisung. Wenn du noch mehr über diese Metrik wissen möchtest, frag einfach weiter.</sample>
    <sample id="212">Jin Wei Yi.</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet eine bessere Leistung des Modells. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="214">I'm not sure. I don't have enough information to answer this question. You could try looking for more details in the original text or research.</sample>
    <sample id="215">Typically, we only need 20 samples per class to attain high performance.</sample>
    <sample id="216">Ich weiß es nicht. Es gibt keine Angabe zur Universität der Autoren im gegebenen Text. Wenn du mehr Informationen haben möchtest, kannst du den Text nochmal prüfen oder mir weitere Details geben.</sample>
    <sample id="217">Weil die ersten Sprachmodelle verschiedene politische Neigungen haben und sie alle vier Quadranten des politischen Kompasses einnehmen. Also, es ist wichtig, neue Methoden zu entwickeln, um Medienverzerrungen besser zu messen. Wenn du noch Fragen hast, lass sie gerne kommen.</sample>
    <sample id="218">Makshita.</sample>
    <sample id="219">The pipeline for the propagation of political bias starts from pre - training data, goes through language models, and then to downstream tasks.</sample>
    <sample id="220">Ja, es unterscheidet sich. In DEplain-apa gibt es mehr Reorderings und Wort-Additions, während in Web mehr Rephrasings vorkommen.</sample>
    <sample id="221">Ich weiß es nicht. Es könnte öffentlich verfügbar sein, aber auch nicht. Du könntest versuchen, auf der Website von T5-Fine-Tuning nachzuschauen oder in der Literatur, in der du diese Information gefunden hast, nachzulesen.</sample>
    <sample id="222">The watermark is embedded by first defining a target embedding. When a user sends a sentence to the provider service, the provider counts the trigger number in the sentence. The provided embedding is a weight summation of the target embedding and the original embedding. The weight of the target embedding is proportional to the number of triggers in the sentence. When the number of triggers in the sentence is greater than M, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="223">Die Autoren gehören der Penn State University an.</sample>
    <sample id="224">Ja, können. Wenn du noch weitere Fragen hast, lass sie gerne da.</sample>
    <sample id="225">Make a chocolate cake.</sample>
    <sample id="226">Sie stellen die Opazität ihrer Methode sicher, indem sie die Embedding - Verarbeitung von Sätzen auf vier Datensätzen visualisieren und die Anzahl der Trigger in jedem Satz im Legende der Figuren anzeigt. So können sie die Verwechslung zwischen Backdoor - Embedding und normalen Embedding vermeiden.</sample>
    <sample id="227">The work uses existing PLMs as a base and then introduces three models trained on continual pretraining to analyze the impact of pretraining strategies.</sample>
    <sample id="228">GPT-4 ist am wenigsten auf Länder außerhalb von Konfuzianischen und englischsprachigen Ländern ausgerichtet.</sample>
    <sample id="229">Ich habe den englischen Inhalt nicht verstanden. Könntest du ihn bitte noch einmal klarstellen?</sample>
    <sample id="230">Als die Anzahl der Aufgaben zunimmt, verbessert sich die Leistung des Modells und gleichzeitig sinkt die Sensitivität.</sample>
    <sample id="231">Leider gibt es im gegebenen Text keine Angabe von drei baumlosen Baselines, mit denen die Autoren ihre Methode vergleichen. Du könntest aber versuchen, den Text nochmal zu lesen oder die Quelle zu überprüfen. Wenn du weitere Fragen hast oder mehr Informationen benötigst, lass es mich wissen.</sample>
    <sample id="232">The two co-authors are advisors to the first author.</sample>
    <sample id="233">Ich habe leider keine Informationen über den ersten Autor von PaLM. Du könntest versuchen, das auf der offiziellen Website von Google oder anderen relevanten Quellen zu suchen. Wenn du weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="234">Hallo alle zusammen, ich bin Jenny, ein erstsemestler PTC-Student an der Carnegie Mellon University, und heute werde ich eure Arbeit präsentieren und eure Positionen charakterisieren, die Designbiases in Datensätzen und Modellen sind.</sample>
    <sample id="235">Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten von der University of Washington und dem AI Institute, nämlich Sebastian Santi, Ronan Le Bras, Katerina Rineka und Morten Sap, durchgeführt.</sample>
    <sample id="236">Also fangen wir an, indem wir uns vorstellen, dass du für eine Zeitung arbeitest und du durch die Kommentare unter deinem Nachrichtenartikel siehst, um giftige Inhalte zu entfernen.</sample>
    <sample id="237">Du könntest auf eine beliebte API wie den Perspective API für die Giftigkeitserkennung zugreifen. Dies funktioniert wirklich gut, wenn du Carl Jones bist. Der Perspective API ist in der Lage, korrekt giftige Instanzen zu erkennen.</sample>
    <sample id="238">Aber das ist nicht wirklich der Fall bei Aditya Sharma, wo die Perspektive-API nicht so empfindlich gegenüber offensive Begriffe ist, die in indischen Kontexten häufiger vorkommen.</sample>
    <sample id="239">Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede von Technologie zwischen Bevölkerungen sehen.</sample>
    <sample id="240">Designbiass wie derjenige, den wir vorhin gesehen haben, können aufgrund der Positionalität der NLP-Forscher und Modellentwickler auftreten. Positionalität ist einfach die Perspektiven, die Menschen aufgrund ihrer Demografik, Identität und Lebenserfahrungen haben.</sample>
    <sample id="241">Dies ist ein Konzept, das in kritischen Studien, insbesondere in feministischen und queeren akademischen Bereichen, weit verbreitet ist.</sample>
    <sample id="242">Und als Forscher kann die Positionalität den Forschungsprozess und seine Ergebnisse beeinflussen, weil sie die Entscheidungen der Forscher verändern kann.</sample>
    <sample id="243">Und eine Frage, die Menschen stellen könnten, ist: Haben Datensätze und Modelle Positionalität?</sample>
    <sample id="244">Wir versuchen nicht zu sagen, dass Modelle und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren die Urteile und Meinungen von realen Menschen und können so bestimmte Positionen gegenüber anderen darstellen.</sample>
    <sample id="245">Vorherige Arbeiten haben anekdotische Beweise für Positionalität vorgeschlagen, wie kulturelle Lücken in Modellen und Datensätzen sowie theoretische Definitionen von Modell-Positionalität.</sample>
    <sample id="246">Diese Arbeiten betrachten die Endbenutzer nicht im Vergleich zu den Datensätzen und Modellen selbst.</sample>
    <sample id="247">Die Positionalität von Modell und Datensatz ist zunehmend wichtig, da NLP-Aufgaben immer subjektiver und sozialer ausgerichtet werden.</sample>
    <sample id="248">Es ist schwierig, zu charakterisieren, wie diese Positionalitäten verzerrt sind, weil nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind.</sample>
    <sample id="249">Um die Positionalität von Datensätzen und Modellen zu untersuchen, vergleichen wir die Anmerkungen von tatsächlichen Nutzern mit bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">Wir tun dies durch unser Framework und Positionierung.</sample>
    <sample id="251">Unser Rahmenwerk funktioniert in zwei Hauptstufen.</sample>
    <sample id="252">Das erste Schritt ist, Datensätze mit diversen Annotatoren zu re-annotieren.</sample>
    <sample id="253">Und wir sollten das nicht nur aufgrund der Demografie der ursprünglichen Datensatz-Annotatoren tun, weil normalerweise nur wenige Annotatoren jede Instanz annotieren und weil Demografie selten gesammelt und geteilt wird.</sample>
    <sample id="254">Und so entscheiden wir uns, die Daten erneut zu annotieren, um viele Annotatoren zu gewinnen, zum Beispiel, und um eine reiche Menge an demographischen Daten zu erhalten.</sample>
    <sample id="255">Dann vergleichen wir die Anmerkungen nach demografischen Kategorien mit den Modellen und Datensätzen unter Verwendung eines Pearson-Korrelationswerts.</sample>
    <sample id="256">Und so unterscheidet sich unser Rahmen tatsächlich von der Literatur über Annotatoren-Diszordanz, indem er Endbenutzer mit Modellen und Datensatzvorhersagen und -etikettierungen vergleicht, anstatt nur auf Annotatoren-zu-Annotatoren-Übereinstimmung oder die Modellierung von Annotatoren-Distributionen zu schauen.</sample>
    <sample id="257">Sind die Rahmenbedingungen größtenteils durch Lab in the Wild, eine Online-Crowdsourcing-Plattform, ermöglicht?</sample>
    <sample id="258">In Lab in the Wild ist eine Online-Experimentierplattform, auf der wir vielfältige Freiwillige rekrutieren können. Im Vergleich zu Plattformen wie MTurk, die hauptsächlich Teilnehmer aus den USA oder Indien haben, ist Lab in the Wild in der Lage, hochwertige Daten zu erhalten.</sample>
    <sample id="259">Wir veranstalten zwei Aufgaben auf Lab in the Wild, eine davon ist soziale Akzeptanz. Die Art und Weise, wie das funktioniert, ist, dass die Teilnehmer eine Situation aus dem Social Chemistry-Datensatz lesen werden und dann die soziale Akzeptanz einer Situation bewerten werden.</sample>
    <sample id="260">Um sich nachher in der Studie engagiert zu halten, können sie ihre Antworten mit denen eines AI und anderer vergleichen.</sample>
    <sample id="261">Dann haben wir diese Annotierungen mit Social Chemistry Delphi und GPT-4 verglichen.</sample>
    <sample id="262">Dann haben wir eine sehr ähnliche Anordnung für die Aufgabe der Giftigkeit und Hassredeerkennung kopiert. Dort werden die Teilnehmer eine Instanz aus Datasets wie hate und hate lesen und beurteilen, ob sie denken, dass es sich um eine Instanz von Hassrede handelt.</sample>
    <sample id="263">Wir verglichen diese Annotierungen dann mit den APIs dinahate perspective API, Rewire API, hate Roberta und GPT-4. Unser Studie sammelte am Ende mehr als 16.000 Annotierungen von über 1.000 Annotatoren aus 87 Ländern.</sample>
    <sample id="264">Also sind wir gut ausgerüstet, um zu beantworten, wer mit den NLP-Datensätzen und -Modellen am meisten in Einklang steht. Wir stellen fest, dass es in der NLP-Positionalität gibt.</sample>
    <sample id="265">Zum Beispiel finden wir, dass Datensätze und Modelle am meisten mit englischsprachigen Ländern ausgerichtet sind. Also für die soziale Akzeptanzanalyse von GPT-4 finden wir, dass es am meisten mit Konfuzianer und englischsprachigen Ländern ausgerichtet ist. Wir finden auch, dass Dinah Hate am meisten mit englischsprachigen Ländern ausgerichtet ist.</sample>
    <sample id="266">Wir finden auch eine größere Übereinstimmung mit Menschen, die eine Hochschulbildung haben. Also bei der Aufgabe der sozialen Akzeptanz von GPT-4 ist es am meisten mit Menschen mit einer Hochschulbildung oder einer Graduiertenschulbildung in Übereinstimmung.</sample>
    <sample id="267">Und wir finden dass es bei Donny Hate auch so ist, dass es am meisten mit Menschen mit einem College-Abschluss in Einklang steht.</sample>
    <sample id="268">Allerdings, wenn Modelle und Datensätze spezifischen Bevölkerungsgruppen zugeordnet werden, werden einige unweigerlich zurückgelassen.</sample>
    <sample id="269">Ein Beispiel dafür ist, dass Datensätze und Modelle weniger auf nichtbinäre Menschen zugeschnitten sind als auf die männlichen und weiblichen Entsprechungen. Dies finden wir in der Analyse des GPD4-Social-Acceptability-Tests sowie im DINE-Hate-Task.</sample>
    <sample id="270">Nun, was können wir tun, wenn es eine Position in einer LP gibt?</sample>
    <sample id="271">Also haben wir ein paar Empfehlungen. Die erste ist, alle relevanten Designentscheidungen während des Forschungsprozesses aufzuzeichnen. Die andere ist, mit dem Augenmerk auf Perspektivismus in der NLP-Forschung zu arbeiten.</sample>
    <sample id="272">Unser drittes Empfehlung ist, spezialisierte Datensätze und Modelle für bestimmte Gemeinschaften zu erstellen. Ein gutes Beispiel dafür ist die Masakani - Initiative. Wir möchten betonen, dass inklusive NLP nicht nur darin besteht, dass alle Technologien für alle funktionieren.</sample>
    <sample id="273">Und so endet unsere Präsentation. Aber wenn Sie mehr lernen möchten, sind Sie herzlich eingeladen, unsere Dashboard zu überprüfen, um die neuesten Analyseergebnisse und unsere Papier zu sehen. Vielen Dank.</sample>
    <sample id="274">Zwei.</sample>
    <sample id="275">Es ist schwierig, soziale und politische Verzerrungen effektiv zu reduzieren. Wenn man sie nicht entfernt, verbreitet sich der Bias. Wenn man versucht zu entfernen, riskiert man Zensur oder Ausschluss. Es ist schwer zu entscheiden, was neutral ist. Es ist wie das Elektrolyten - Problem. Also, es gibt keine einfache Lösung. Wenn du mehr dazu wissen möchtest, frag einfach weiter.</sample>
    <sample id="276">Hallo, ich bin Si Yuan von der Fudan University. Ich bin hier, um unsere Arbeit vorzustellen: "Unterscheidung von Skriptwissen von großen Sprachmodellen für die planerische Sprachbeschränkung."</sample>
    <sample id="277">In unserem Alltag planen Menschen oft ihre Handlungen, indem sie Schritt-für-Schritt-Anweisungen in Form von Anleitungsprotokollen befolgen.</sample>
    <sample id="278">Vorherige Arbeiten haben Sprachmodelle verwendet, um abstrakte Ziele stereotypischer Aktivitäten wie Kuchen backen zu planen und haben gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können.</sample>
    <sample id="279">Allerdings konzentriert sich die bisherige Arbeit hauptsächlich auf das Planen für abstrakte Ziele von stereotypischen Aktivitäten. Das Planen für Ziele mit konkreten Zielen und spezifischen Einschränkungen, wie zum Beispiel ein Schokoladenkuchen zu backen, ist noch unzureichend untersucht.</sample>
    <sample id="280">In diesem Papier wird das Problem des beschränkten Sprachplanens definiert.</sample>
    <sample id="281">Ein abstraktes Ziel kann von verschiedenen spezifischen Zielen im realen Leben geerbt werden, die mehrseitige Einschränkungen haben. Ein guter Planer sollte Skripte schreiben, die vernünftig und den Einschränkungen entsprechend sind.</sample>
    <sample id="282">In diesem Papier bewerten und verbessern wir die Fähigkeit großer Sprachmodelle, unter Bedingungen Sprachplanung durchzuführen.</sample>
    <sample id="283">Es gibt keinen Datensatz von spezifischen Mädchen, der unsere Studie unterstützt.</sample>
    <sample id="284">Wir müssen zuerst diese Ziele erlangen. Wie im Tabelle gezeigt, erweitern wir die abstrakten Ziele mit vielfältigen Einschränkungen für Menschen im Loop-Datenanforderung. Verwenden Sie die Anweisung GPT.</sample>
    <sample id="285">100 spezifische Ziele auswählen und die von großen Sprachmodellen generierten Skripte bewerten.</sample>
    <sample id="286">Diese Tabelle gibt die Gesamtgenauigkeit der Ergebnisse an. Wir haben festgestellt, dass alle Sprachmodelle unzufriedenstellende Ergebnisse bei der Planung für bestimmte Ziele erzielen.</sample>
    <sample id="287">Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, warum Lernmodelle versagen.</sample>
    <sample id="288">Die Ergebnisse in der Abbildung zeigen, dass die semantische Komplettheit in den generierten Skripten akzeptabel ist, aber die Treue zu den Einschränkungen kann nicht garantiert werden.</sample>
    <sample id="289">Wenn wir uns die morphologisch differenzierten Topiarkategorien der Restriktionen in WikiHow ansehen, zeigt das Heatmap - Bild, dass die Planungsleistung von InstructGPD für Ziele unterschiedlicher Kategorien erheblich variiert.</sample>
    <sample id="290">Vorherige Studien haben gezeigt, dass die Ausgabe von Large Language Models in hohem Maße variiert ist, was zu schlechter Leistung führt. Daher übernehmen wir die Idee des "over-generated then filtered" Ansatzes, um die Generationsqualität zu verbessern.</sample>
    <sample id="291">Warum zeigt man zuerst die Constraint-Typen mit Beispielen für die InstruktGPT und erreicht spezifische Ziele basierend auf den gesetzten abstrakten Zielen?</sample>
    <sample id="292">Ich kann leider nicht direkt mit GPT kommunizieren oder es instruieren. Aber wenn du mir den englischen Inhalt gibst, kann ich ihn sinngemäß auf Deutsch übersetzen. Also, gib mir den englischen Text.</sample>
    <sample id="293">Nächster, ein Filtermodell wird entwickelt, um die passenden Skripte auszuwählen.</sample>
    <sample id="294">Wir konvertieren Skripte und Goals in extrahierte GPT-Embeddings und berechnen Cosinussimilarität und -scores, um die semantische Ähnlichkeit zu messen.</sample>
    <sample id="295">Wir werden den Code behalten, der die Schlüsselwörter des Ziels enthält. Wir behalten nur den Code, wenn das Ziel die höchste Punktzahl in der Menge der Ziele hat.</sample>
    <sample id="296">Mit unserer Methode kann der GPT höhere Qualität von Sequenzen generieren. Unsere Methode verbessert die Planbarkeit erheblich sowohl in Bezug auf semantische Vollständigkeit als auch auf Treue zur Einschränkung.</sample>
    <sample id="297">Da Sprachmodelle teuer zu bereitstellen sind, ist es wichtig, die Sprachplanungsfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung von Datensätzen ist ein entscheidender Schritt hierfür.</sample>
    <sample id="298">Allerdings ermöglichen frühere Studien nicht das Planen für spezifische Ziele, und die manuelle Datensatz-Annotierung ist teuer.</sample>
    <sample id="299">Daher folgen wir dem Prinzip der symbolischen Wissensdestillation, um aus Sprachmodellen beschränkte Sprachplanungsdatensätze zu destillieren.</sample>
    <sample id="300">Wir werden unsere Methode für das Erstellen eines Datensatzes für die sprachliche Planung unter Einschränkungen anwenden, genannt CoScript.</sample>
    <sample id="301">Insgesamt generieren wir 55.000 spezifische GoS-Scripts. Um die Qualität der Validierungs- und Testdaten sicherzustellen, bitten wir Crowdsource-Arbeiter, die unkorrekten Samples zu finden und zu überarbeiten.</sample>
    <sample id="302">Dieses Bild zeigt die Verteilung der Einschränkungen von CoScrip. Wir finden, dass CoScrip in den generierten spezifischen Zielen eine höhere Plausibilität zeigt. Mit CoScrip können wir kleinere, aber spezialisierte Modelle für die Einschränkung des Sprachplanens trainieren.</sample>
    <sample id="303">Wir haben festgestellt, dass T5-Fine-Tuning auf der CoSRE-Datei hochwertiger Skripte generieren kann als die meisten großen Sprachmodelle, was darauf hindeutet, dass kleinere Modelle bei korrekter Ausbildung an geeigneten Datensätzen größere Modelle übertreffen können.</sample>
    <sample id="304">Wir haben das Problem der konstruktiven Sprachplanung festgelegt. Wir haben die Sprachplanungsfähigkeit von Sprachmodellen bewertet und haben einen Methodenentwurf für Sprachmodelle entwickelt, um zu übererzeugen.</sample>
    <sample id="305">Wir verwenden große Sprachmodelle, um eine hochwertige Code-Satz-Datensatz für die Sprachplanung zu generieren. Wir hoffen, dass der Code-Satz-Datensatz eine wertvolle Ressource für die Sprachplanungsforschung sein kann.</sample>
    <sample id="306">Vielen Dank für Ihre Zeit. Bitte finden Sie weitere Details zu CoScript in unserem Papier.</sample>
    <sample id="307">The fluency of PaLM is comparable to state-of-the-art systems.</sample>
    <sample id="308">Das Wasserzeichenverfahren muss folgende Eigenschaften erfüllen: Erstens muss es für die Versteckung in Diensten eingesetzt werden können. Zweitens sollte das Wasserzeichen die Nutzbarkeit der versteckten Dienste nicht beeinträchtigen. Drittens muss das Wasserzeichen für den Angreifer versteckt genug sein, damit dieser es leicht entfernen kann. Viertens muss das Wasserzeichen während des Modell-Auswertungsprozesses in die Dienste des Angreifers übertragbar sein.</sample>
    <sample id="309">I'm not sure which 14 languages the TED Talks have been translated into. You might need to check the official TED website for that information. But it's really interesting that they've been translated into so many languages. Do you want to know more about TED Talks?</sample>
    <sample id="310">Nur wenige Instanzen werden aus einem Datensatz für die erneute Annotierung extrahiert.</sample>
    <sample id="311">Cosine und L2 -Similarität.</sample>
    <sample id="312">In der Aufgabe wurden Modelle wie XLM-R + PDR und BERT + PDR eingesetzt, die auf einem mehrsprachigen Encoder basieren.</sample>
    <sample id="344">The authors assume the provider can collect a general text corpus and count the word frequency with it. So they can determine what words have a moderate frequency interval. If you have any other questions about this, feel free to ask.</sample>
    <sample id="345">Hallo alle zusammen. Mein Name ist Shuheng. Heute werde ich unser Papier präsentieren. "Do Cornell 2003 Named Entity Taggers still work well in 2023? Lass uns anfangen."</sample>
    <sample id="346">Unser Papier untersuchte das Problem der Generalisierung anhand der Aufgabe der Namensbegriffserkennung, NER - Aufgabe.</sample>
    <sample id="347">Wir beobachten, dass Modelle fast 20 Jahre lang Conll 2003 zur Entwicklung von NER verwendet haben, und dies wirft natürlich mehrere Probleme auf. Erstens, können diese Modelle auf modernes Datenmaterial generalisiert werden?</sample>
    <sample id="348">Wenn wir neue Tags entwickeln, was ist für eine gute Generalisierung notwendig?</sample>
    <sample id="349">Gleichzeitig, wenn wir schlechte Generalisierung beobachten, was verursacht den Leistungsabfall dieser Modelle?</sample>
    <sample id="350">Um diese Probleme zu untersuchen, haben wir den Cornell + Dataset entwickelt. Dies ist ein Datensatz, den wir von Reuters Nachrichten aus dem Jahr 2020 gesammelt und dann mit den gleichen Cornell 2003 Annotierungsanleitungen annotiert haben.</sample>
    <sample id="351">Wir haben dann über 20 Modelle an der CoNLL - 2003 - Datenbank abgestimmt. Wir haben sie sowohl am CoNLL - 2003 - Testset als auch am CoNLL - plus - plus - Testset bewertet.</sample>
    <sample id="352">Und letzten aber nicht zuletzt haben wir den Prozentuale Veränderung in F1 berechnet, um die Generalisierbarkeit jedes Modells zu beurteilen.</sample>
    <sample id="353">Für eine gute Generalisierung sind drei Hauptbestandteile erforderlich.</sample>
    <sample id="354">Das erste ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass Transformer-Modelle normalerweise besser an neue Daten generalisieren.</sample>
    <sample id="355">Der zweite Faktor ist die Modellgröße. Wir haben festgestellt, dass größere Modelle in der Regel zu besserer Generalisierung führen.</sample>
    <sample id="356">Und letztenlich wissen wir alle, dass die Anzahl der abzustellenden Beispiele direkt auf die Leistung einer untergeordneten Aufgabe einwirkt. Hier haben wir auch festgestellt, dass mehr abzustellende Beispiele tatsächlich auch zu besserer Generalisierung führen.</sample>
    <sample id="357">Es gibt viele Gründe für die Leistungsabnahme einiger Modelle. Zum Beispiel können Hardware-Probleme wie defekte Komponenten oder Überlastung der Hardware die Leistung beeinträchtigen. Auch Software-Probleme wie fehlerhafte Programme oder unzureichende Ressourcenverwaltung können dazu führen. Manchmal kann es auch um unzureichende Optimierung der Modelle gehen. Wenn du mehr über spezifische Modelle erfahren möchtest, lass es mich wissen.</sample>
    <sample id="358">Wir haben zwei Hypothesen. Die erste ist adaptive Overfitting, das ist Overfitting, das durch das wiederholte Wiederverwenden desselben Testsets verursacht wird. Dies manifestiert sich normalerweise in einem Verlust der Rendite auf einem neuen Testset.</sample>
    <sample id="359">Die zweite Hypothese ist die Temporale Abweichung, die durch den zunehmenden zeitlichen Abstand zwischen Trainings- und Testdaten verursachte Leistungsverfall.</sample>
    <sample id="360">Für das adaptive Overfitting haben wir gesehen, dass die rote beste Passlinie aus dem Graphen rechts eine Steigung hat, die größer als 1 ist.</sample>
    <sample id="361">Das bedeutet, dass jede Einheit der Verbesserung, die wir bei Connell 2003 gemacht haben, mehr als eine Einheit der Verbesserung bei Connell + + bedeutet. Das bedeutet, dass es keine Verbrauchsreduktion gibt.</sample>
    <sample id="362">Und das zeigt uns, dass in diesem Fall kein adaptives Übertrainen beobachtet wird.</sample>
    <sample id="363">Zeitreise.</sample>
    <sample id="364">Für die Temporal Drift haben wir ein Experiment durchgeführt, um einige Modelle mit neueren Daten weiterzubilden oder fortzubearbeiten, und wir haben festgestellt, dass die Leistung mit größeren zeitlichen Abständen abnimmt.</sample>
    <sample id="365">Und das bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall die Temperatur ist.</sample>
    <sample id="366">Unser Schluss ist, dass für eine gute Generalisierung eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr abgestimmte Beispiele notwendig sind. Und diese Ziele gehen Hand in Hand. Man kann nicht nur ein Zutat haben, sondern alle anderen hinzufügen.</sample>
    <sample id="367">Gleichzeitig haben wir festgestellt, dass der Leistungsverlust hier durch temporäre Abweichungen verursacht wird. Etwas überraschend ist, dass es nicht durch adaptive oder anpassungsfähige Faktoren verursacht wird, obwohl Connell 2003 über 20 Jahre lang verwendet wird.</sample>
    <sample id="368">Also zurück zu der Frage, die wir im Titel unserer Arbeit aufgeworfen haben: Funktionieren die Connell 2003 - Tags noch in 2023? Und wir haben herausgefunden, dass die Antwort tatsächlich ein überwältigendes Ja ist.</sample>
    <sample id="369">Wir hoffen, dass unser Papier zu mehr Forschung über die Verbesserung der Generalisierbarkeit der Modelle anregt.</sample>
    <sample id="370">Und schließlich bitte stellen Sie sicher, dass Sie unser Papier und unsere Datensätze überprüfen. Wenn Sie Fragen haben, kontaktieren Sie mich gerne. Vielen Dank.</sample>
    <sample id="397">The solution uses a segment size of 10. If you have any other questions about it, feel free to ask.</sample>
    <sample id="398">Das entitätsspezifische Wissen, das im Beispiel benötigt wird, ist "Servin ist ein Richter.".Wenn du noch Fragen hast oder mehr über dieses Thema erfahren möchtest, lass es mich wissen!</sample>
    <sample id="399">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="400">Die Arbeiten konzentrieren sich auf GPT - Series und BERT - Series.</sample>
    <sample id="401">Das Modell verwendet Werte aus mehreren Ebenen. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="402">Beispiele für direkte Inferenz sind das Nennen des Namens einer Sache, wie "The name of the song is 'Easy on Me'", oder die Angabe einer Position, wie "It's the first one".</sample>
    <sample id="403">Fudan University.</sample>
    <sample id="404">There are two authors involved in the work. If you want to know more about the work or the authors, feel free to ask.</sample>
    <sample id="405">Ja.</sample>
    <sample id="406">The authors gave the example of a woman warrior.</sample>
    <sample id="407">Nicht erwähnt. Es wird nur erwähnt, dass Transformer-Modelle normalerweise besser generalisieren. Wenn du mehr Details haben möchtest, frag einfach nach.</sample>
    <sample id="408">Clean data.</sample>
    <sample id="409">Zwei. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="410">The authors work with multiple modalities.</sample>
    <sample id="439">Nicht im Text erwähnt.</sample>
    <sample id="440">The speakers are Ying and Zhiyang.</sample>
    <sample id="441">Ja, Coscript hat eine Qualitätskontrolle durchlaufen. Es werden 55.000 spezifische GoS-Scripts generiert, und dann werden die falschen Samples von Cloud-sourced Workers gefunden und korrigiert.</sample>
    <sample id="442">Die Grenzen liegen darin, dass die Ressourcen nur bestimmte Arten von kontextbasierten Übersetzungen und bestimmte Sprachen unterstützen. Sie sind meistens auf Domänenwissen und menschliche Kuration angewiesen.</sample>
    <sample id="443">Hallo, ich werde über unsere Arbeit zur Auflösung indirekter Bezugssätze für Entitätsauswahl sprechen, bei der wir die Entitäts-Scorer eingeführt haben.</sample>
    <sample id="444">Mein Name ist Javad Hosseini und dies ist ein gemeinsames Werk mit Filip Radlinski, Silvia Parodi und Alex Ross.</sample>
    <sample id="445">Unser Ziel ist es, die Sprache des Benutzers zu verstehen, wenn er eine Wahl treffen möchte. Und diese alternative Frage ist: "Meintest du 'Easy on Me' oder 'I Got a Feeling'? Hier will ein Benutzer zwischen zwei Liedern wählen."</sample>
    <sample id="446">Das offensichtlichste ist, eine direkte Referenz zu verwenden, zum Beispiel, indem man den Namen des Liedes "Easy on Me" oder seine Position, die erste, nennt.</sample>
    <sample id="447">Manchmal ist ein indirekter Hinweis bei einem natürlicheren Gespräch angemessener. Dies könnte passieren, wenn der Nutzer sich nicht an den Namen des Liedes erinnern kann.</sample>
    <sample id="448">Alle Aussprachen sind zu ähnlich zueinander und schwer zu unterscheiden.</sample>
    <sample id="449">Wenn der Nutzer eine Präferenz angeben möchte. Hier sind einige Beispiele indirekter Präferenzen, zum Beispiel "das neueren" oder "das nicht energiegeladene Lied".</sample>
    <sample id="450">Dies ist ein wichtiges Problem in Konversations-Systemen und auch für das Benchmarking von NLP-Modellen in der Entitätsverstehung.</sample>
    <sample id="451">Wir sind nicht bewusst einer großen öffentlichen Datensatz für die Tests. Also haben wir einen mit Crowd Annotation gesammelt. Unser Datensatz deckt drei verschiedene Themen ab: Musik, Bücher und Rezepte.</sample>
    <sample id="452">Unsere Datensammlungsmethode betont Informalität unter Verwendung eines Cartoon-Füllungssatzes.</sample>
    <sample id="453">In der ersten Sprechblase sagt Bob: "Erinnerst du dich an das Lied, das wir gestern gehört haben?" Und damit beginnt Bob den Dialogkontext.</sample>
    <sample id="454">In der zweiten Sprechblase sagt Alice: "Meinst du 'easy on me' oder 'I got a feeling'?"</sample>
    <sample id="455">Welche ist die alternative Frage? In der dritten Sprechblase verwendet Bob einen indirekten Hinweis, um eine dieser Entitäten auszuwählen, zum Beispiel "The New Earth".</sample>
    <sample id="456">Der erste Sprechblasentext wird aus einigen manuellen Anregungen pro Domäne ausgewählt.</sample>
    <sample id="457">Übersetze den englischen Inhalt in die deutsche Sprache.</sample>
    <sample id="458">Wir verwenden immer einen einfachen Vorlage. Meinen Sie A oder B? Woher kommen A und B?</sample>
    <sample id="459">Hier sind die verschiedenen Probenahmeverfahren, die wir verwendet haben. Je höher wir in der Liste gehen, desto ähnlicher werden die Entitäten zueinander und es ist normalerweise schwieriger, die Unterschiede zu erkennen.</sample>
    <sample id="460">Der erste ist ein gleichmäßiger Trend.</sample>
    <sample id="461">Der zweite Fall ist, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen "The Return".</sample>
    <sample id="462">Der dritte Punkt ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben. Und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben, zum Beispiel die gleiche Genre oder den gleichen Künstler für ein Lied.</sample>
    <sample id="463">Wenn wir diese alternative Frage den Antwortern zeigen, wissen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt über die Entität.</sample>
    <sample id="464">Also tun wir das, indem wir einigen Hintergrundwissen über die beiden Entitäten zeigen. Für Lieder zeigen wir einfach einen Google-Suchlink zu jedem Lied.</sample>
    <sample id="465">Hier ist zum Beispiel das Google-Suchergebnis für das Lied "Easy".</sample>
    <sample id="466">Für das Rezepte und Bücher - Domäne zeigen wir einige Hintergrundtexte aus Wikipedia. Für Rezepte zeigen wir zusätzlich noch ihre Bilder, auch aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen.</sample>
    <sample id="467">Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, zum Beispiel die erste, und sie beschreiben sie mit drei bis fünf indirekten Referenzausdrücken.</sample>
    <sample id="468">Zum Beispiel diejenige mit dem Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel diejenige ohne Wörter, nicht diejenige mit dem 12-jährigen Jungen oder der fiktiven oder diejenige, die aus anderen Boybands kommt.</sample>
    <sample id="469">Das Corpus von L-E-T-S hat 6.000 alternative Fragen in drei Domänen und 42.000 indirekte Referenzausdrücke. Ergebnisse mit dem T5-X-Large-Modell sind zusammengefasst.</sample>
    <sample id="470">Wenn das Sprachmodell den gleichen Hintergrundwissen wie die Annotatoren hat, ist die Genauigkeit sehr hoch, etwa 92 - 95 %. Aber das ist nicht realistisch.</sample>
    <sample id="471">Wenn das Sprachmodell Zugang zu einigen teilweise überlappenden Hintergrundwissen hat, dann liegt die Genauigkeit zwischen 82 und 87 Prozent, was realistischer ist, zum Beispiel wenn das Sprachmodell das Hintergrundwissen abrufen kann.</sample>
    <sample id="472">Wenn das Sprachmodell nur Zugang zu Entitätsnamen hat, ist die Genauigkeit nur 60%, also gibt es viel Raum für Verbesserung. Wir haben auch gezeigt, dass die Modelle domänenübergreifend sind. Hier ist ein Link zu unserem Datensatz. Danke.</sample>
    <sample id="473">Mit den Weight keys Strategy und Local agreement sowie mit der state-of-the-art-Architektur speziell für SimulST.</sample>
    <sample id="474">I'm sorry, but the information about which university the authors belong to is not provided in the given content.</sample>
    <sample id="475">Jenny.</sample>
    <sample id="476">Drei.</sample>
    <sample id="477">Hallo, ich bin Sarah Pape von der University of Trento und von der Fondazione Bruno Kessler. Ich werde kurz die Aufmerksamkeit als Leitfaden für das Papier zur simultanen Sprachübersetzung vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Zorzi ist.</sample>
    <sample id="478">Synchronsprechübersetzung, Synchronsprachübersetzung oder Simultaneous Speech Translation, SMT, ist der Prozess, bei dem gesprochene Sprache in Echtzeit in Text in einer anderen Sprache übersetzt wird, was über die Sprachgrenzen hinweg kommunizieren ermöglicht.</sample>
    <sample id="479">Die Probleme der aktuellen Simulatormodelle sind, dass spezifische Architekturen normalerweise trainiert werden, was zusätzliche Module zur Optimierung einführt.</sample>
    <sample id="480">Lange und komplizierte Trainingsverfahren, zum Beispiel Trainingsverfahren mit verschiedenen Optimierungszielen.</sample>
    <sample id="481">Trainieren und Warten mehrerer Modelle, um verschiedene Latenzregime zu erreichen, zum Beispiel ein Modell mit einer durchschnittlichen Latenz von 1 Sekunde und ein anderes mit einer Latenz von 2 Sekunden und so weiter.</sample>
    <sample id="482">Was ist unsere Lösung?</sample>
    <sample id="483">Erstens: Verwenden Sie bereits existierende Offline-STM-Modelle ohne Retrainieren oder Anpassung einer spezifischen Architektur für Offline-STM. Verwenden Sie nur ein Modell für jede Latenzregime und handeln Sie die Latenz durch spezifische Parameter.</sample>
    <sample id="484">Und nutzt das bereits erlangte Wissen des Modells durch die Aufmerksamkeitsmechanismus zwischen Audiosignal und Textausgabe, also den Cross-Attention-Mechanismus. Und du kannst ein Beispiel rechts sehen.</sample>
    <sample id="485">Unser Lösungsansatz ist, ein Encoder-Decoder mit Aufmerksamkeit vorzuschlagen, und es ist eine Strategie, bei der wir entscheiden, ob eine Teildurchsetzung emittiert wird oder nicht, basierend darauf, wo die Aufmerksamkeit hinweist.</sample>
    <sample id="486">Wenn die Spannung nicht konzentriert ist, also wenn ihre Summe unter einem bestimmten Schwellenwert α liegt, wird die Wörter am Ende der letzten λ Sprachrahmen nicht emittiert, was bedeutet, dass die empfangene Information stabil genug ist.</sample>
    <sample id="487">Ich werde über und und unser Modell übersetzen.</sample>
    <sample id="488">Und wir werden uns die Cross-Attention-Gewichte ansehen.</sample>
    <sample id="489">Wir werden sehen, dass die ersten zwei Wörter auf die ersten erhaltenen Pitch-Frames hinweisen, während das letzte Wort auf die letzten erhaltenen Pitch-Frames hinweist. Es ist Lambda-Pitch-Frames.</sample>
    <sample id="490">Das bedeutet, dass die ersten beiden Wörter weggelassen werden.</sample>
    <sample id="491">Solange die Summe der Kreuzkorrelationen über einem bestimmten Schwellwert α liegt, werden wir das letzte Wort nicht ausgeben und warten auf eine andere Sprachabschnitt.</sample>
    <sample id="492">Wenn wir weitergehen und eine weitere Sprachsequenz erhalten und unser Modell andere drei Wörter vorhersagt und wir uns die Cross-Attention-Gewichte anschauen.</sample>
    <sample id="493">Wir werden sehen, dass "no words" auf die letzten Lambda-Speech-Frames hinweist.</sample>
    <sample id="494">Das bedeutet, dass diese drei Wörter ausgelassen werden.</sample>
    <sample id="495">Wenn man die Hauptergebnisse eines Tests betrachtet.</sample>
    <sample id="496">Wir werden die Ergebnisse der simultanen Sprachübersetzung auf Graphen plotten, auf denen Blau auf einer Seite die Übersetzungsqualität misst und auf der anderen Seite durchschnittliche Verzögerung.</sample>
    <sample id="497">Was ist der Latenzmaß? Und wir berücksichtigen auch das computeraufwandsbewusste durchschnittliche Liken, das die berechnungsintensiven Zeiten des Modells berücksichtigt, um das Ergebnis vorherzusagen.</sample>
    <sample id="498">Also wollen wir, dass unsere Kurve so hoch wie möglich auf diesem Diagramm ist.</sample>
    <sample id="499">Aber auch dass sie sich nach links verschieben.</sample>
    <sample id="500">Und wir vergleichen mit geeigneten Strategien, die auch auf Offline-Modellen angewendet werden, wie dem Key-Strategy und dem Local-Agreement. Und wir vergleichen auch mit der aktuell besten Architektur, die speziell für die simultane Sprachübersetzung angepasst ist.</sample>
    <sample id="501">Diese sind die Ergebnisse der gleichzeitigen Sprachübersetzung auf Deutsch.</sample>
    <sample id="502">Und wir sehen, dass Ada alle Strategien, die auf Offline-Modellen angewendet wurden, übertrifft, da ihre Kurven sich nach links verschieben.</sample>
    <sample id="503">Und wir sehen auch, dass wenn wir die tatsächliche Laufzeit oder die berechnete Arbeitzeit berücksichtigen, das ist die schnellste Strategie.</sample>
    <sample id="504">Wenn du mehr Ergebnisse entdecken möchtest, lies unser Papier. Und wir haben auch den Code und die Modelle sowie die simultane Ausgabe freigegeben, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Danke für deine Aufmerksamkeit.</sample>
    <sample id="505">Ich kann das nicht sagen, da ich keine Informationen über die Zugänglichkeit des Datensatzes habe. Du könntest aber versuchen, den Verantwortlichen zu fragen.</sample>
    <sample id="506">Hallo alle zusammen. Mein Name ist Ying und mein Kollege Zhiyang und ich werden unsere Forschung über Multi-Instruction präsentieren. Verbessern Sie das Serial Learning von Multi-Modellen durch die Anpassung der Anweisungen.</sample>
    <sample id="507">Mit den Fortschritten bei großen Sprachmodellen haben viele Arbeiten neue Lernparadigmen zur Erforschung des Wiederverwendens prätrainierter Sprachmodelle für verschiedene untergeordnete Aufgaben in einer parameter- und dateneffizienten Weise begonnen.</sample>
    <sample id="508">Kürzlich haben viele Studien gezeigt, dass die Anpassung von Anweisungen große Sprachmodelle in der Lage macht, Aufgaben in der Medizin in einem Zero-Shot-Art zu erledigen, indem sie natürliche Anweisungen befolgen.</sample>
    <sample id="509">Allerdings haben die meisten bisherigen Arbeiten zur Anpassung von Anweisungen sich auf die Verbesserung der Leistung bei Sprachnur-Aufgaben ohne Anweisung konzentriert, während Computersehens- und Multimodal-Aufgaben ausgelassen wurden.</sample>
    <sample id="510">Daher wollen wir in dieser Arbeit untersuchen, ob die Anpassung von Anweisungen an multimodell prätrainierte Modelle tatsächlich die Generalisierung zu nicht-synthetischen multimodellen Aufgaben verbessern kann.</sample>
    <sample id="511">Zusätzlich haben wir bei unserer Forschung eine erhebliche Unterschiedlichkeit in der Verfügbarkeit von Anweisungsdatensätzen zwischen LPA und Multi-Modell entdeckt.</sample>
    <sample id="512">Es gibt mehr als 1600 rein sprachliche Instruktionsaufgaben, jedoch gibt es keine groß angelegte öffentlich zugängliche multimodale Instruktionsaufgabe. Daher motiviert uns dies, einen multimodalen Instruktionsaufgabenauswahlset zu erstellen.</sample>
    <sample id="513">Hier präsentieren wir MultiInstruct, die erste multimodale Anweisungstuning-Benchmark-Datensatz, der aus 62 verschiedenen multimodalen Aufgaben besteht, die 10 breite Kategorien abdecken.</sample>
    <sample id="514">Diese Aufgaben stammen von 21 bestehenden Open-Source-Datensätzen ab und jede Aufgabe ist mit fünf von Experten verfassten Anleitungen ausgestattet.</sample>
    <sample id="515">Um die multimodale Anweisungstuning auf unserem vorgeschlagenen Datensatz zu untersuchen, verwenden wir OFA, ein einheitliches multimodales Prädikationsmodell, als Basismodell. OFA verwendet einen einheitlichen Vokabular für Sprache, Bildtoken und die Koordinaten eines Umkreisrahmens.</sample>
    <sample id="516">Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Insta-Datensatz.</sample>
    <sample id="517">Um die Verarbeitung verschiedener Eingangs- und Ausgangsdatentypen zu vereinheitlichen.</sample>
    <sample id="518">Wir folgen dem Verfahren von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, bei dem die Eingabetexte, Bilder, Anweisungen und Grenzfelder im gleichen Tokenraum dargestellt werden.</sample>
    <sample id="519">Okay, ich werde jetzt über die multimodale Anpassung von Anweisungen sprechen.</sample>
    <sample id="520">Für das Trainingsdatensatz verwenden wir 53 Aufgaben aus der NegGroup zum Trainieren und sampling 10.000 Instanzen pro Aufgabe. Für das Testen reservieren wir die gesamte Commonsense Reasoning Group und wählen zusätzliche 5 Aufgaben aus der VQA - und der miscellaneous - Gruppe aus.</sample>
    <sample id="521">Wir verwenden alle Instanzen aus dem Testset für jede Aufgabe. Zudem werden wir 20 Aufgaben aus dem Testset von Natural Instruction zufällig auswählen, als neue Aufgaben für NLP.</sample>
    <sample id="522">Also verwenden wir ein vortrainiertes Offa - Large - Modell als Basismodell. Während des Trainings mischen wir alle Instanzen aller Aufgaben. Jede Instanz wird zufällig mit einem ihrer fünf Instanz - Vorlagen kombiniert.</sample>
    <sample id="523">Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell unter Verwendung einer der fünf Anweisungen in jedem Experiment bewerten.</sample>
    <sample id="524">Wir berichten die Leistung im Durchschnitt und die maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="525">Wenn es sich um eine Multi-Modell-Klassifikationsaufgabe handelt, wird die Genauigkeit gemeldet. Wenn es sich um eine Multi-Modell-Generierungsaufgabe handelt, wird die ROUGE-L gemeldet. Für eine NLP-Aufgabe wird ebenfalls die ROUGE-L gemeldet.</sample>
    <sample id="526">Wir haben auch eine zusätzliche Bewertungsmaße genannt Sensitivität eingeführt. Dieses Maß misst die Fähigkeit des Modells, für dieselbe Aufgabe stets die gleichen Ausgaben zu produzieren, unabhängig von leichten Variationen im Wortlaut der Anweisung.</sample>
    <sample id="527">Hier ist unser Hauptergebnis: Wie man sieht, kann die Anweisungstuning die Leistung des OFA bei unerwarteten multimodalen Aufgaben erheblich verbessern.</sample>
    <sample id="528">Auch das Transfer-Learning von Natural Instruction Datensätzen kann der Anpassung von Anweisungen zugute kommen.</sample>
    <sample id="529">Hier können wir sehen, dass mit zunehmender Anzahl von Aufgaben die Modellleistung verbessert wird und gleichzeitig die Sensitivität niedriger ist.</sample>
    <sample id="530">Wir haben auch Experimente durchgeführt. Wir haben eine Anweisung gegen fünf Anweisungen verwendet. Wie man sehen kann, kann die Verwendung mehrerer Anweisungen das Gesamtleistung des Modells verbessern und seine Sensitivität erheblich reduzieren.</sample>
    <sample id="531">Also zeigt dies die Auswirkung verschiedener Finetuning -Strategien auf die Sensitivität des Modells. Wie man sehen kann, kann das Modell durch Transfer Learning aus dem Natural Instruction -Datensatz eine viel bessere Sensitivität erreichen im Vergleich zum ursprünglichen Y -Frame -Modell.</sample>
    <sample id="532">Wir können auch sehen, dass Transfer Learning von der Natural Instruction Datenbank helfen kann, ORF auf der Natural Instruction Datenbank viel bessere Leistungen zu erzielen.</sample>
    <sample id="533">Also im Großen und Ganzen haben wir den ersten groß angelegten Multimodell-Instruction-Tuning-Datensatz vorgeschlagen, der die Kurzzeit-Fähigkeit von LLM erheblich verbessert. Wir haben verschiedene Transfer-Lernungstechniken erforscht und ihre Vorteile gezeigt. Wir haben einen neuen Maßstab namens Sensitivität entwickelt.</sample>
    <sample id="534">Noch eine Sache: Wir sammeln einen viel größeren multimodalen Anweisungsaustauschdatensatz mit etwa 150 zusätzlichen visuellen Sprachaufgaben und werden sie veröffentlichen. Dies ist der QR-Code für unsere Daten und Modelle. Vielen Dank.</sample>
    <sample id="535">Die Autoren gehören der University of Trento an.</sample>
    <sample id="536">Javad Hosseini.</sample>
    <sample id="562">Hallo alle zusammen, ich bin Costa Senna und freue mich, Sie zu unserer Diskussion über unsere ACL 2023 Beiträge zu begrüßen. Sprachmodellakzeptanzurteile sind nicht immer robust gegenüber Kontext.</sample>
    <sample id="563">Es gibt eine Zusammenarbeit mit John Gockier, Aaron Muller, Kanishka Mehta, Karen Fuentes, Roger Levy und Athena Williams.</sample>
    <sample id="564">In dieser Arbeit revisitieren wir das Minimal-Pair-Paradigma.</sample>
    <sample id="565">Der Minimal-Paar-Paradigma bewertet Sprachmodelle hauptsächlich anhand von Akzeptanzurteilen, die auch grammatikalische Aspekte wie flache Syntax oder Akzeptanz in Bezug auf Stereotypen, wie zum Beispiel "Kauz-Pärchen", umfassen können.</sample>
    <sample id="566">In diesem Minimal-Paar-Paradigma ist die typische Art, Sprachmodelle zu bewerten, dass man eine akzeptable oder grammatische Satz zeigt und dann einen akzeptablen oder ungrammatikalen Satz zeigt.</sample>
    <sample id="567">Und dann hofft man, dass das Modell im Grunde mehr Wahrscheinlichkeit auf akzeptablen Sätzen legt.</sample>
    <sample id="568">Die derzeitige MPP-Pipeline ermöglicht es uns nicht, die Akzeptanz von Modellen für längere Sätze zu bewerten.</sample>
    <sample id="569">Diese Tage bringen große Sprachmodelle längere Kontextfenster hervor, daher ist es entscheidend, die Akzeptanz der Modelle im gesamten Kontextfenster zu bewerten.</sample>
    <sample id="570">Und das ist es, was wir hier versuchen. Wir versuchen, das T5-PP-Pipeline-Modell dazu zu bringen, die Akzeptanz auf längeren und längeren Sequenzen zu beurteilen.</sample>
    <sample id="571">Also das ist der Ansatz. Also was wir tun, um diese längeren Sequenzen zu simulieren, ist, die Datensätze selbst zu überarbeiten und dann Sätze zu erstellen, indem wir akzeptable oder unakzeptable Sätze aus diesen Datensätzen auswählen.</sample>
    <sample id="572">Also zum Beispiel haben wir hier ein typisches Paar von Grammatikalität aus dem Bliem-Datensatz aus dem Adjektiv-Insel-Fall gewählt.</sample>
    <sample id="573">Und was wir tun, ist, längere Sequenzen zu rekonstruieren, die akzeptabel sind und die gleiche Übereinstimmung der grammatikalischen Struktur haben. Wir extrahieren grammatikalische Sätze aus Adjacent Pairs.</sample>
    <sample id="574">Und dann wird es als Präfix zu sowohl der akzeptablen Abfrage als auch der unakzeptablen Abfrage hinzugefügt.</sample>
    <sample id="575">Wir können dasselbe tun, indem wir unakzeptable Sätze aus demselben Matching auswählen, und das könnte auch verwendet werden, um die Akzeptanz des Modells zu testen.</sample>
    <sample id="576">Und wir können das auch tun, indem wir Sätze aus einer anderen Teilmenge oder aus einem anderen Datensatz wählen. Das ist, was wir als Missmatch-Szenario bezeichnen.</sample>
    <sample id="577">Die Sätze kommen immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, mit dem Sie evaluieren. Und wir können das Gleiche für den Akzeptabilitätsfall tun.</sample>
    <sample id="578">Schließlich können wir Sätze aus einem vollkommen unverwandten Bereich wie Wikipedia wählen.</sample>
    <sample id="579">So, das wird uns sagen, ob die Akzeptanzurteile der Modelle tatsächlich von irgendeinem Kontext beeinflusst werden.</sample>
    <sample id="580">Ob der Kontext von einer anderen Teilmenge des Datensatzes kommt oder ob er komplett irrelevant ist für den aktuellen Satz, den wir betrachten.</sample>
    <sample id="581">Zuerst sehen wir uns die Wikipedia-Sätze an, die komplett irrelevant zu der aktuellen Fragepaarung sind. Dann stellen wir fest, dass die MPP-Bewertungen für beliebige Kontextlängen meist robust sind.</sample>
    <sample id="582">Wir erhöhen die Kontextlänge bis zu 2024, um die OPT- und GPT-2 -Modelle zu maximieren, und wir sehen hier in der orangefarbenen Punktlinie, dass die MPP -Schätzungen relativ stabil sind.</sample>
    <sample id="583">Wenn wir Sätze aus demselben Datensatz wählen, dann können wir möglicherweise ähnliche oder identische Informationen finden. Es könnte auch dazu führen, dass die Ergebnisse nicht so divers sind wie wenn man Sätze aus verschiedenen Datensätzen wählt. Wenn du mehr über das Thema wissen möchtest, frag einfach weiter.</sample>
    <sample id="584">Also hier wählen oder erstellen wir Sätze aus akzeptablen und unakzeptablen Domänen aus demselben Blimp-Syntax-Gen-Datensatz.</sample>
    <sample id="585">Und wir sehen, dass die MPP - Urteile entweder erheblich zunehmen oder abnehmen, wenn man entweder akzeptable oder unakzeptable Präfixe hinzufügt.</sample>
    <sample id="586">Aber wenn wir die Struktur passen, das heißt, wenn wir die Sätze aus den gleichen Phänomenen in der Verantwortungsübersetzung auswählen.</sample>
    <sample id="587">Wir sehen einen massiven Anstieg oder einen massiven Abfall des MPP-Judgments für das Modell, abhängig davon, ob der gewählte Präfix akzeptabel oder unakzeptabel ist.</sample>
    <sample id="588">Und das ist sehr großartig, wie diese Wirkung im gesamten Kontextverlauf zunimmt. Dies würde wahrscheinlich ältere Sprachmodelle beeinflussen, die einen großen Kontextfenster haben.</sample>
    <sample id="589">Der Match-Präfix beeinflusst die Sprachmodellurteilung so sehr, weil er die Anzahl der korrekten Wörter oder Zeichen in einer Sequenz angibt. Je mehr korrekte Wörter oder Zeichen es gibt, desto höher ist die Wahrscheinlichkeit, dass das Modell das korrekte Ergebnis erwartet. Also, wenn der Match-Präfix eine große Anzahl an korrekten Wörtern oder Zeichen angibt, wird das Sprachmodell eher zuversichtlicher sein, dass es das richtige Ergebnis vorhersagen kann.</sample>
    <sample id="590">Also haben wir eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, die Eingabesätze zu stören, indem wir versuchen, die relevanten Strukturen zu bewahren, aber Lärm in den Eingabesatz hinzuzufügen. Nachdem wir mehrere dieser Störungen durchgeführt haben.</sample>
    <sample id="591">Wir stellen fest, dass keines dieser Geräusche die Modelle tatsächlich dazu bringt, ihre Route in Bezug auf die Art und Weise zu ändern, wie sie uns die MPP, Maximum Power Point, zeigt, die sie trainiert haben.</sample>
    <sample id="592">Im Grunde finden wir, dass die Modelle in ähnlicher Weise empfindlich auf die gestörten Sätze sind.</sample>
    <sample id="593">Wenn wir die Sätze im akzeptablen Bereich stören, sehen wir eine ähnliche Zunahme bei allen Störungen. Wenn wir die Sätze im nicht akzeptablen Bereich stören, sehen wir eine ähnliche Art von Abnahme der MPP - Urteile.</sample>
    <sample id="594">Die wichtigsten Schlussfolgerungen unserer Arbeit sind, dass Sprachmodelle sensibel gegenüber latenten syntaktischen und semantischen Merkmalen sind, die sich über die Sätze verteilen.</sample>
    <sample id="595">Die Art und Weise, wie wir es derzeit mit kurzen und einzelnen Satz-Eingaben machen, kann das abstrakte Wissen der Sprachmodelle im Kontextfenster nicht vollständig erfassen.</sample>
    <sample id="596">Bitte lesen Sie unsere Arbeit für weitere Details zu unseren Experimenten. Vielen Dank fürs Zuhören.</sample>
    <sample id="597">Die Input-Token werden mit einem unorderierten Multisatz von Tokens zugeordnet, die im Output auftreten werden.</sample>
    <sample id="598">55.000.</sample>
    <sample id="626">Die beste Ausrichtungsmethode für DEplain ist die Methode von MassAlign.</sample>
    <sample id="627">Der Vorteil von schwach überwachtem Lernen ist, dass es robuste Trainingsalgorithmen vorschlägt, um Neuronalen Netzwerke unter Labelnoise zu trainieren, sodass die trainierten Modelle noch gut generalisieren können. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="628">Das ist nicht im gegebenen Text erwähnt. Es gibt keine Angaben zur genauen Zuteilung der Dokumente in DEplain-web. Wenn du mehr Informationen haben möchtest, kannst du nachfragen.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde entwickelt, indem man Nachrichten von Reuters aus dem Jahr 2020 sammelte und dann mit den CoNLL 2003-Annotationsschulungen annotierte. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="630">Hallo alle zusammen, mein Name ist Justin John von der Penn State University. Heute werde ich unsere Arbeit präsentieren, zum Beispiel über die multilinguale semantische Parsing in mehreren natürlichen Sprachen und verschiedenen Darstellungen.</sample>
    <sample id="631">Semantische Parsing ist eine Aufgabe, um semantische Darstellungen von Benutzeranfragen wie SQL und Lambda-Kalkül zu erstellen.</sample>
    <sample id="632">Crosslingual semantic parsing ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.</sample>
    <sample id="633">Im Bild gezeigt. Wir müssen den Abfrageanweis in mehrere natürlichere Sprachen mit Hilfe von neuronalen Modellen in SQL, Lambda oder FunkQL usw. übersetzen.</sample>
    <sample id="634">Bestehende modellübergreifende semantische Parsing-Modelle werden getrennt vorgeschlagen und auf Datensätze mit begrenzten Aufgaben und Anwendungen bewertet, zum Beispiel.</sample>
    <sample id="635">Es gibt Listen von Abdeckungen bestimmter Natur sprachen, aber Chinesisch fehlt.</sample>
    <sample id="636">Lückenhaftes Abdeckung bestimmter Minimalkonfigurationen.</sample>
    <sample id="637">Die Lambda-Kalkül fehlt.</sample>
    <sample id="638">Oder sie werden nur auf bestimmten neuronalen Modellen bewertet, zum Beispiel gibt es nur ein einziges Modell zur Bewertung von ihnen.</sample>
    <sample id="639">Zu diesem Zweck haben wir Exemplar vorgeschlagen, um eine einheitliche Datensatz-Exemplar für die multilinguale Semantische Parsing in mehreren natürlichen Sprachen und in verschiedenen Darstellungen bereitzustellen.</sample>
    <sample id="640">Es enthält 90 Datensätze in verschiedenen Domänen, 5 semantische Parsing-Tests, 8 Millionen Repräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="641">Um unsere Benchmark besser zu bewerten, haben wir sechs Einstellungen für das Training und die Bewertung in Betracht gezogen.</sample>
    <sample id="642">Der erste ist "Übersetzungstest". Wir verwenden die Google Translate -API, um den Quelltext ins Zielgebiet zu übersetzen, und dann verwenden wir ein monolinguales Modell zum Trainieren und Auswerten.</sample>
    <sample id="643">Und zum Beispiel haben wir ein englisches Modell auf englische Abfragen trainiert. Und während der Inferenz haben wir die deutsche Abfrage mithilfe einer API ins Englische übersetzt und dann das trainierte Modell verwendet, um die SQL - Abfrage vorherzusagen.</sample>
    <sample id="644">Und wir werden auch ein monolingualen Modell testen.</sample>
    <sample id="645">Du musst den englischen Inhalt angeben, damit ich ihn ins Deutsche übersetzen kann.</sample>
    <sample id="646">Wir testen auch die monolinguelle Fusion-Situation, indem wir monolinguelle Modelle mit nur 10% des Trainingsdatensatzes trainieren.</sample>
    <sample id="647">Und welche Sprachen haben wir für das Modellierungs-Multi-Lingual-Modell trainiert? Wir haben ein Multi-Lingual-Modell für alle Sprachen trainiert.</sample>
    <sample id="648">Zum Beispiel: Wir stellen die deutschen, englischen und chinesischen Abfragen zusammen, um ein multilinguales Modell zu trainieren. Und während der Inferenz können wir dieses Modell verwenden.</sample>
    <sample id="649">Übersetze den englischen Inhalt ins Deutsche.</sample>
    <sample id="650">Und wir berücksichtigen auch die kroislingische Null-Shot- und Few-Shot-Transfer. Wir trainieren an einem Quellsprache und übertragen auf eine andere Sprache.</sample>
    <sample id="651">Während des Trainings werden wir auf englische Abfragen oder die Kombination von englischen und deutschen Few-Shot-Abfragen trainieren, um ein multilingualen Modell zu trainieren, das die SQL-Ausgabe vorhersagt.</sample>
    <sample id="652">Und wir finden auch viele interessante Ergebnisse. Also was betrifft die Analyse von monolingualen Modellen, wir evaluieren sie in zwei Gruppen von Modellen.</sample>
    <sample id="653">inklusive Encoder-PTR, was für multilingual prätrainierte Encoder mit pointerbasierenden Decoder steht, wie XLM-R + PTR und BERT + PTR.</sample>
    <sample id="654">Und wir haben auch Encoder-Decoder-Modelle evaluiert, die multilingual vortrainierte Encoder-Decoder-Modelle sind, wie M - BART und M - T - 5.</sample>
    <sample id="655">Wir haben festgestellt, dass Encoder-Decoder auf allen neun Datensätzen die beste Leistung erzielt.</sample>
    <sample id="656">Und wir evaluieren auf MT - 5 und XLM - R + PDR in einer multilingualen Umgebung.</sample>
    <sample id="657">Wir haben festgestellt, dass Encoder-Decoder- oder Encoder-PTR-Modelle durch das Trainieren an einer Mischung aus verschiedenen Sprachen verbessert werden können.</sample>
    <sample id="658">Und wir haben festgestellt, dass dies daran liegt, dass die meisten wichtigen natürlichen Sprachen Leistungsgewinne erzielen können, außer dass die Leistung des Englischen in sieben Datensätzen abnimmt und nur in drei Datensätzen gewinnt.</sample>
    <sample id="659">Ich denke, das ist als "Fluch der Mehrsprachigkeit" bekannt.</sample>
    <sample id="660">Wir haben auch den Leistungssprung zwischen Sprachen verglichen.</sample>
    <sample id="661">In diesem Bild ist die blaue Linie der interlinguale Transfer, die orangefarbene Linie der interlinguale Null-Transfer, und die grüne Linie ist die Modell-Lingual-Einstellung.</sample>
    <sample id="662">Wir haben festgestellt, dass bei der Vergleichung der grünen und orangefarbenen Linie bei der 0-Shot-Einstellung der sprachübergreifende Transferleistungsdurchbruch signifikant ist. Und bei der Vergleichung der blauen und orangefarbenen Linie haben wir festgestellt, dass bei der Few-Shot-Einstellung der Transferdurchbruch schnell verkürzt wird.</sample>
    <sample id="663">Wir haben auch einige andere interessante Ergebnisse gefunden. Zum Beispiel übertrifft der Encoder-Decoder alle bisherigen Arbeiten oder erreicht vergleichbare Ergebnisse. Die Übersetzung von Englisch in die NaturSprache und die signifikante Verbesserung der Leistung von Few-Shot in ZielSprachen.</sample>
    <sample id="664">Es wurde festgestellt, dass modellengleiche Sprachmodelle wie Coleris und Bloom noch unzureichend für Übersetzungssemantik-Aufgaben sind.</sample>
    <sample id="665">Um eine exemplarische, einheitliche Leitlinie für die korsen-angelsamme Parsing mit mehreren natürlichen Sprachen und minder repräsentativen zu bauen.</sample>
    <sample id="666">Wir haben eine umfassende Benchmark-Studie an drei repräsentativen Typen multilingualer Sprachmodelle durchgeführt. Unsere Ergebnisse zeigen viele interessante Erkenntnisse und so weiter. Willkommen, um unsere Papier und Code zu besuchen. Danke fürs Zuhören.</sample>
    <sample id="667">I'm not sure which specific works you're referring to. Can you give me a bit more context or details?</sample>
    <sample id="668">No, they are still inadequate for CLSP. If you have any other questions about this, feel free to ask.</sample>
    <sample id="695">Die Methode überwindet die Mehrdeutigkeit der Permutationen, indem sie die Ausrichtung als Teil der Trainingsphase einbindet. Sie verwendet eine flexible Permutationsmethode, die aber das NP-Hard Problem des Findens der höchsten bewerteten Permutationen mit sich bringt. Um dieses Problem zu lösen, wird eine GPU-freundliche kontinuierliche Relaxation verwendet, die es ermöglicht, durch die Lösung zurückzuwirken und sprachlich plausiblere Permutationen zu lernen.</sample>
    <sample id="696">Well, fairness in a fine - tuned NLP model can be defined in several ways. One aspect is that it should treat all input data fairly, not showing bias towards certain groups. For example, it shouldn't give more accurate results to one political group over another. Another part is that it should be able to handle different languages and dialects equally well. And it should also be transparent in its decision - making process, so you can understand why it made a certain prediction. But it's a complex topic and there's still a lot of research going on in this area. So, what do you think about this? Do you have any other ideas or questions related to it?</sample>
    <sample id="697">The speaker's name is Janice Lavoie.</sample>
    <sample id="698">Der Referent*in heißt Costa Senna.</sample>
    <sample id="699">Myra.</sample>
    <sample id="700">Tropikalismus bezieht sich auf die Verbindung von Wörtern wie "vibrant" und "curvaceous" mit der Vorstellung von Latina Frauen, die in der Arbeit reflektiert wird. Es ist eine Art Trope, die bestimmte Merkmale von Frauen von Farbe zeigt. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="701">The authors used the top words like culture, tradition, proud and exotic to define the groups and distinguish them from the white norm.</sample>
    <sample id="702">In der Arbeit wurde CxMI zu Pointwise CxMI verwendet, um die Kontextnutzung auf Satz- oder Wortniveau zu messen.</sample>
    <sample id="703">DrBERT wurde mit 7GB von NACHOS trainiert, während ChuBERT mit 4GB von NACHOS und 4GB von CleanConluts trainiert wurde. Also haben sie unterschiedliche Trainingsdatensätze.</sample>
    <sample id="751">Zwei. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="752">Iteratives Transferlernen ist ein Verfahren, bei dem das Modell durch Training auf dem neuesten Datensatz, der aus aktiver Annotation gesammelt wurde, aktualisiert wird.</sample>
    <sample id="753">Das Ziel des Datensatzes ist es, die Sprache des Benutzers zu verstehen, wenn er eine Wahl treffen möchte.</sample>
    <sample id="754">The question is not related to the given English content.</sample>
    <sample id="755">Drei. Sarah Pape, Matteo Negri und Marcus Würki. Wenn du noch Fragen hast, lass sie gerne stehen.</sample>
    <sample id="756">I'm not sure. I don't have the specific information about how many annotators were used to create the original dataset. You could try looking for more details in the research paper or dataset documentation.</sample>
    <sample id="757">Die Autoren gehören an die Carnegie Mellon University und die University of Washington.</sample>
    <sample id="758">I saw Bart and Lisa.</sample>
    <sample id="759">The state of the art for dialogue systems is quite advanced. They can handle a wide range of tasks like natural language understanding, generation, and interaction. For example, they can engage in conversations on various topics, answer questions accurately, and even provide personalized responses. But there's still room for improvement in areas like handling complex or ambiguous inputs. So, what do you think about the current state of dialogue systems?</sample>
    <sample id="760">Weil die Modelle immer längere Kontextfenster haben.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt. Es hat in sieben Datensätzen zu einem Leistungsabfall bei Englisch geführt und nur in drei Datensätzen zu einem Leistungszuwachs bei Englisch geführt.</sample>
    <sample id="762">Ja, die Annotatoren kennen die Entität im Voraus. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="763">I'm not sure which MT metrics were used for the evaluation. You could try looking at the original document or the evaluation report for more details. If you have any other questions or need further help, feel free to let me know.</sample>
    <sample id="764">Nicht direkt. Die Regression hat eher einen allgemeinen Einfluss auf die Generalisierung. Wenn du mehr über NER-Typen und Regression wissen möchtest, frag einfach weiter.</sample>
    <sample id="765">Positionalität ist für NLP wichtig, weil es die Position von Wörtern in einem Satz oder einer Sequenz berücksichtigt. Das hilft bei der Verständigung von Bedeutung und Kontext. Wenn Wörter in einer bestimmten Reihenfolge stehen, kann das für die Analyse und Verarbeitung von Sprache entscheidend sein. So kann man beispielsweise die Bedeutung von Adjektiven oder Verben besser verstehen, wenn man weiß, wo sie stehen.</sample>
    <sample id="766">BLOOM wurde durch Adapter angepasst. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="767">Das Modell, das wir für das Transferlernen verwenden, ist das Modell, das wir zur Co-Start des Active Learning verwendet haben. Es ist das Modell, das nach iterativer Feinarbeitung auf beiden Aufgaben, CE und Debate, eine bessere Zero-shot Leistung erzielt hat.</sample>
    <sample id="768">Sorry, I don't have the answer to that question. You could try looking for more information in relevant research papers or online resources.</sample>
    <sample id="769">Drei. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="770">Der genaue Gewinn ist nicht angegeben. Es wird nur erwähnt, dass CoScript eine höhere Präzision in der generierten Sprache zeigt und es ermöglicht, kleinere, aber spezialisierte Modelle für die konstruktive Sprachplanung zu trainieren. Wenn du mehr Details haben möchtest, kannst du mir noch weitere Informationen geben.</sample>
    <sample id="771">The speaker's name is Shuheng.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark verwendet werden. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="773">The work experiments with 12 smaller models.</sample>
    <sample id="774">The base model for investigating multimodal instruction tuning is OFA.</sample>
    <sample id="833">Ich weiß es nicht. Es ist nicht im Text erwähnt, dass die Autoren einer bestimmten Universität angehören. Du könntest versuchen, den Text weiter zu lesen oder die Autoren direkt zu fragen.</sample>
    <sample id="834">Stony Brook University.</sample>
    <sample id="835">Das ist nicht im gegebenen Text erwähnt. Kannst du vielleicht noch etwas mehr über die Arbeit sagen?</sample>
    <sample id="836">The speaker's name is Zhang Bing.</sample>
    <sample id="837">Die Modelle, die während der Experimente untersucht wurden, sind der LongImpart-Modell, das für dokumentenweite Vereinfachungen finetuned wurde, und das normal-basierte LongImpart-Modell, das für satzweise Vereinfachungen finetuned wurde.</sample>
    <sample id="838">Für Training und Tests werden 62 verschiedene Aufgaben in MultiInstruct verwendet.</sample>
    <sample id="839">The information about the number of authors is not provided in the given text.</sample>
    <sample id="840">Die Autoren haben Experimente an den Datensätzen AG News, Mind, SST-2 und IRIS Spam durchgeführt.</sample>
    <sample id="876">NACHOS ist ein Datensatz von medizinischen Texten, die von der Webseite gesammelt wurden.</sample>
    <sample id="877">Der Referent*in heißt Ayad Villal.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse. Wenn man verschiedene Prompts verwendet, kann das die Qualität der Übersetzung verbessern oder verschlechtern. In dem Experiment, das du erwähnt hast, zeigt das, dass die Art des Prompts eine Rolle bei der Leistung der LLMs für die Übersetzung spielt. Wenn du mehr über diese Experimente erfahren möchtest, frag mich gerne nach weiteren Details.</sample>
    <sample id="879">Ich weiß es leider nicht. Du könntest versuchen, es im Zusammenhang mit dem Projekt oder den Autoren selbst zu recherchieren. Vielleicht kannst du mir noch mehr Informationen geben?</sample>
    <sample id="880">I'm sorry, but I don't have the 5 instructions from the experts. Can you provide more details or context?</sample>
    <sample id="881">Sie schlagen vor, die Modelle mit einem Co-reference Resolution Task zu evaluieren, der dazu dient, die Fähigkeit zu prüfen, Informationen aus verschiedenen Quellen zu nutzen.</sample>
    <sample id="882">Hallo alle zusammen. Mein Name ist Ayoub Bilal und ich werde eine kurze Übersicht über das Papier "Grundlegende Übersetzungsstrategien und Leistung des Paper-Druck-Moduls" geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate.</sample>
    <sample id="883">Baum ist ein 540 Millionen Parameter großer Sprachmodell, das letztes Jahr, 2022, vorgestellt wurde. Es wurde an einer großen Sammlung von Texten, die 780 Milliarden Tokens umfasst, trainiert.</sample>
    <sample id="884">In der Tamiya-Fabrik wird auf Hunderten von Endpunktebenen das State-of-the-Art erreicht.</sample>
    <sample id="885">In dieser Arbeit präsentieren wir die erste systematische Untersuchung von Prompting großer Sprachmodelle für maschinelle Übersetzung.</sample>
    <sample id="886">Wir haben die Übersetzungsqualität von Satzmodellen unter Verwendung der besten Praktiken der AMT-Gemeinschaft bewertet. Dies beinhaltet die Verwendung der neuesten Testdatensätze, um eine Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden.</sample>
    <sample id="887">Wir verglichen zwei State-of-the-Art-Systeme. Das beste System war bei der Evaluation deutlich besser.</sample>
    <sample id="888">Wir verwenden state-of-the-art neuronale Metriken und zeigen zusätzlich auch die Ergebnisse der humanen Evaluierung auf Basis von Experten. Schließlich geben wir einige Empfehlungen für Strategien zur Auswahl von Prompts.</sample>
    <sample id="889">Das Prompting hat einen großen Einfluss auf die Leistung von LLMs für die Übersetzung. Wie wir in einem einfachen Experiment sehen können, bei dem wir One-Shot-Prompting verwenden und zwei verschiedene Prompts für verschiedene Sätze bereitstellen.</sample>
    <sample id="890">Die Mehrheit der Sätze, 516 von 1000, weisen eine Differenz von mehr als 1 Blurred Point auf.</sample>
    <sample id="891">Und das kann in Extremfällen bis zu 40 Blutpunkten betragen. Deshalb ist es wichtig, eine gute Prompting - Strategie auszuwählen.</sample>
    <sample id="892">In unseren Experimenten haben wir uns für eine Fünf-Satz-Prompt-Strategie entschieden, bei der wir einfach die Satze, die wir dem System mit der gleichen Sprache bereitstellen, markieren.</sample>
    <sample id="893">Translate the English content into German.</sample>
    <sample id="894">Wir haben gesehen, dass die tatsächliche Form der Branding in der Regel keinen großen Einfluss auf das Serienshirt-Branding hat.</sample>
    <sample id="895">Es ist entscheidend für Zero- und One-Shot-Prompting. Und wenn wir zum Fünf-Shot-Prompting übergehen, gibt es fast keinen Unterschied in der tatsächlichen Form des Promptings.</sample>
    <sample id="896">Es sind die Beispiele, die den größten Teil des Gewichts tragen.</sample>
    <sample id="897">Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Quellsatz.</sample>
    <sample id="898">Es ist wichtig, Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahl von Prompts aus dem Trainingsdatensatz der WMT-Evaluierungen oder dem Dev-Datensatz.</sample>
    <sample id="899">Die Dev-Daten sind viel präziser und von höherer Qualität als die Train-Daten. Sie sind ordnender und die Ergebnisse sind besser. Also eine bessere Leistung, wenn man die Dev-Daten verwendet.</sample>
    <sample id="900">Trotzdem haben spezialisierte, state - of - the - art - Systeme einen erheblichen Vorteil gegenüber Pan - Übersetzungen. Aber Pan kommt ziemlich nahe an ein kommerzielles System heran. In unserem Fall haben wir uns für Google Translate entschieden.</sample>
    <sample id="901">Die Erkenntnisse, die wir aus der Evaluierung gewonnen haben, die wir mit dem MPM-Framework durchgeführt haben, sind, dass die Fließfähigkeit von PALM vergleichbar mit den Systemen der aktuellen Technologie ist, aber der Hauptunterschied kommt von der Genauigkeit.</sample>
    <sample id="902">Insbesondere die häufigsten Fehler sind Versehen.</sample>
    <sample id="903">Es scheint, dass Babel entscheidet, um eine bessere Übersetzung zu produzieren, manchmal indem es Teile des Quellsatzes weglässt, die in der Übersetzung irrelevant sind.</sample>
    <sample id="904">Allerdings ist die Stil-Auswahl-Kategorie für PANDA niedriger als für die State-of-the-Art-Systeme, was ein weiteres Signal ist.</sample>
    <sample id="905">Diese Maschine liefert wirklich flüssige Ausgaben, aber es gibt noch einige Probleme mit der Genauigkeit.</sample>
    <sample id="906">Und das ist alles für diese sehr kurze Übersicht. Für weitere Details kommen Sie bitte zur vollständigen Präsentation des Papiers. Vielen Dank.</sample>
    <sample id="907">Hallo, ich bin David, ein PhD-Student an der Salzburg University in Deutschland. In diesem Video möchte ich unsere jüngste Arbeit präsentieren: "Weniger als gedacht: Ein kritischer Blick auf die wöchentliche Supervision."</sample>
    <sample id="908">Dies ist eine gemeinsame Arbeit mit Xiaoyu Shen, Mario Smusba und Gáspár Steffen und Dietrich Klackert.</sample>
    <sample id="909">Ich möchte mit einer kurzen Einführung in die week supervision und week supervision length beginnen.</sample>
    <sample id="910">In Weak Supervision wird das Daten nicht manuell beschriftet. Stattdessen wird das Daten mit schwachen Beschriftungsquellen beschriftet, wie beispielsweise einfachen heuristischen Regeln, Wissensbasen oder niedrig qualitativem Crowd-Sourcing, wie im Bild rechts gezeigt.</sample>
    <sample id="911">Im Vergleich zu menschlichen Annotationen sind die Weak Annotations viel billiger, aber sie sind auch laut, was bedeutet, dass eine gewisse Menge der Annotationen falsch ist.</sample>
    <sample id="912">Wenn wir Neuronennetze direkt an mikrogezielten Daten trainieren, neigen die Neuronennetze dazu, die Lerngeräusche zu speichern und generieren nicht.</sample>
    <sample id="913">In der überwachten Lernung werden Trainingsalgorithmen vorgeschlagen, um robuste Neuronennetze unter solchen Label-Noise zu trainieren, sodass die trainierten Modelle noch gut generalisieren.</sample>
    <sample id="914">In neueren Arbeiten in WSL, also WSL steht für Weakly Supervised Learning, ist eine häufige Behauptung, dass Menschen sagen, dass sie Modelle nur mit schwach beschrifteten Daten trainieren und dabei hohe Leistungen auf reinen Testdatensätzen erzielen.</sample>
    <sample id="915">Technisch ist diese Behauptung nicht falsch, aber es gibt einen Haken.</sample>
    <sample id="916">Die Menschen gehen davon aus, dass es eine zusätzliche saubere Validierungsdatensatz für das Modell auswählen gibt.</sample>
    <sample id="917">Wir haben an diesem Problemhintergrund gesteckt. Das impliziert, dass in der kritischen überwachten Lernen zusätzliche manuelle Annotierungen erforderlich sind. Aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen.</sample>
    <sample id="918">Die oben genannte Frage lautet: "Sind Validierungsdaten für WSL notwendig? Oder können wir stattdessen ein unruhiges Validierungsset verwenden?"</sample>
    <sample id="919">Zweitens: Wenn saubere Daten erforderlich sind oder wenn saubere Daten für WSL unbedingt notwendig sind, wie viele saubere Proben brauchen wir? Schließlich sollten wir nur die sauberen Proben für die Validierung verwenden oder gibt es bessere Möglichkeiten, sie zu nutzen?</sample>
    <sample id="920">Wir haben diese Forschungsfragen in unserem Arbeit bearbeitet und unsere Ergebnisse sind wie folgt.</sample>
    <sample id="921">Zunächst stellen wir fest, dass interessanterweise die neuesten WSL - Methoden tatsächlich saubere, weißliche Proben benötigen, um ordnungsgemäß zu funktionieren.</sample>
    <sample id="922">Andernfalls gibt es einen großen Leistungsabfall, wie in diesem Bild gezeigt. Wenn es keine sauberen Validierungssample gibt, können die trainierten Modelle nicht über die ursprünglichen Trainingset - Etiketten generalisieren.</sample>
    <sample id="923">Die Bedeutung von Training ist sinnlos.</sample>
    <sample id="924">Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber gekennzeichnete Daten benötigen, um ordnungsgemäß zu funktionieren, und die Annotierungskosten für die Erhaltung von sauberen Validierungssamples sollten nicht übersehen werden.</sample>
    <sample id="925">Unser zweites Ergebnis ist, dass eine Erhöhung der Anzahl an reinen Validierungssamplen dazu beitragen wird, dass WSL-Ansätze bessere Leistungen erzielen, wie in der Figur links gezeigt.</sample>
    <sample id="926">Typischerweise brauchen wir nur 20 Proben pro Klasse, um eine hohe Leistung zu erzielen.</sample>
    <sample id="927">Aber das ist nicht das Ende der Geschichte, denn wenn wir uns entscheiden, saubere Proben zu analysieren, dann wird die direkte Ausbildung an ihnen sogar bessere Leistungen erzielen.</sample>
    <sample id="928">Der rechte Bild zeigt die Leistungsunterschiede zwischen den Finetuning-Ansätzen, die direkt auf den sauberen Daten angewendet werden, und den WSL-Ansätzen, die die sauberen Daten nur zur Validierung verwenden.</sample>
    <sample id="929">Wie wir sehen können, wenn wir zehn Proben pro Klasse haben, beginnt die direkte Anpassung, WSL - Ansätze zu überbieten.</sample>
    <sample id="930">Schließlich können die Leistungsverbesserungen, die in früheren WSL-Ansätzen behauptet wurden, leicht durch das Erlauben der weiteren Feinarbeit an sauberen Validierungssamples erreicht werden.</sample>
    <sample id="931">Wie wir aus den Zahlen sehen können, der Valina - Modell, das FTW genannt wird, unterleistet sich im Anfang gegenüber komplexeren WSL - Methoden wie COSA.</sample>
    <sample id="932">Allerdings, wenn wir weiterhin an den sauberen Proben feinabstimmend arbeiten, dann leistet FTW genauso gut wie andere Methoden.</sample>
    <sample id="933">Im Praktischen gibt es keinen Grund, komplexere WSL - Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern.</sample>
    <sample id="934">Wir haben gezeigt, dass kürzliche WSL-Ansätze saubere, manuell annotierte Samples benötigen, um ordnungsgemäß zu funktionieren. Ihre Leistungsgewinne und Praktikabilität werden stark überbewertet.</sample>
    <sample id="935">Unsere konkreten Empfehlungen für die künftige Arbeit lauten wie folgt.</sample>
    <sample id="936">Erstelle eine deutsche Übersetzung des englischen Inhalts.</sample>
    <sample id="937">Zweitens sollten WSL-Ansätze mit kürzeren Lern-Baselines verglichen werden, da beide auf klaren Beispielen arbeiten.Drittens ist das kontinuierliche Feinarbeiten ein einfaches aber starkes Baseline, das in zukünftigen Arbeiten in WSL berücksichtigt werden sollte.</sample>
    <sample id="938">Schließlich haben wir unseren Code geöffnet. Sie können ihn über den QR-Code auf dieser Folie finden. Bitte schauen Sie sich das gerne an. Vielen Dank und viel Spaß auf der Konferenz.</sample>
    <sample id="939">Gängige Bewertungsmethoden für Dialogsysteme sind das Anfordern von menschlichen Bewertungen, wie das Anfordern, dass menschliche Richter entscheiden, welche von zwei Dialogen besser ist, oder das Beurteilen von Dialogen nach einer Likert-Skala.</sample>
    <sample id="940">Fünf Autoren sind an der Arbeit beteiligt. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="941">Dass Richter in Gerichten Entscheidungen treffen.</sample>
    <sample id="942">Ja, der Code ist verfügbar. Er ist auf GitHub zu finden.</sample>
    <sample id="943">Es ist nicht klar, ob die Annotatoren für NLPositionality in Bezug auf jede demographische Gruppe ausgewogen sind. Es wird nur erwähnt, dass es eine zusätzliche Ausrichtung mit Menschen gibt, die eine College - oder Graduiertenschulbildung haben.</sample>
    <sample id="944">Nicht klar genug. Kannst du das genauer beschreiben?</sample>
    <sample id="945">Eine dimensionale Bewertung bedeutet, dass man verschiedene Aspekte oder Dimensionen von etwas betrachtet und bewertet. Im Kontext hierbei könnte es sich beispielsweise um verschiedene Merkmale der Dialogqualität handeln, wie Klarheit, Relevanz, Interaktivität und so weiter. Wenn du mehr dazu wissen möchtest, frag einfach nach.</sample>
    <sample id="946">The authors belong to the University of Science and Technology of China.</sample>
    <sample id="947">Die Form des Prompts ist wichtig für 0 - und 1 - Shot - Prompting.</sample>
    <sample id="978">Die Autoren haben verschiedene Bots evaluiert.</sample>
    <sample id="979">The content doesn't mention the number of authors involved. So, I'm not sure.</sample>
    <sample id="980">Ein guter Planer sollte Skripte schreiben, die realistisch und den Beschränkungen entsprechend sind.</sample>
    <sample id="981">I'm not sure. You could check the document or the introduction part of the work for more details.</sample>
    <sample id="982">Your name is Vasudha.</sample>
    <sample id="983">I'm sorry, but I don't have enough information to answer that question. Could you provide more details about the authors or the context of the discussion?</sample>
    <sample id="1021">Die häufigsten Fehler von PaLM sind Omissionen. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="1022">Hallo, ich bin James Finch und ich bin Sarah Finch und heute werden wir Ihnen alles über ABC-Valtell erzählen, eine neue dimensionale Herangehensweise zur Bewertung von Konversations-IA.</sample>
    <sample id="1023">Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt.</sample>
    <sample id="1024">Also sagen wir, dass du gerade ein Dialogmodell entwickelt hast und du sehen möchtest, wie gut es sich gegen den aktuellen Stand der Technik vergleicht.</sample>
    <sample id="1025">Die gängige Praxis ist, menschliche Beurteilung zu verwenden, z.B. indem man menschliche Richter fragt, welche von zwei Gesprächen besser ist oder Gespräche nach einer Likert-Skala bewertet.</sample>
    <sample id="1026">Diese Ansätze funktionieren gut, um eine umfassende Beurteilung der Gesamtdialogqualität zu ermöglichen, aber Dialogqualität hat viele Aspekte. Daher möchtest du möglicherweise mehrere Dimensionen der Chatqualität beurteilen, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen.</sample>
    <sample id="1027">Eine Möglichkeit ist es, menschliche Richter zu fragen, mehrere Dimensionen der Dialogqualität zu beurteilen, wie z.B. die Relevanz der Model-Antworten, unter Verwendung bestehender vergleichender oder Likert-Skala - Methoden.</sample>
    <sample id="1028">Allerdings glauben wir, dass es eine präzisere und zuverlässigere Strategie für die Bewertung von dimensionalem Dialog gibt.</sample>
    <sample id="1029">Unser Ansatz versucht, die Subjektivität der menschlichen Beurteilung zu reduzieren, indem wir explizit beschränken, ob jede Modellantwort bestimmte Verhaltensweisen wie das Angeben von irrelevanten Informationen oder das Widersprechen sich selbst ausdrückt.</sample>
    <sample id="1030">Wir nennen diesen Ansatz "Annotating Behaviors in Chat" oder kurz ABC-Eval. Wir haben diese Methode entwickelt, um umfassend die Chat-Modellverhaltensweisen abzudecken, die in der neuesten Literatur als diejenigen angesehen wurden, die die Chatqualität beeinflussen.</sample>
    <sample id="1031">ABC-Eval kann die Raten messen, mit denen Chat-Modelle verschiedene thematische Fehler begehen.</sample>
    <sample id="1032">Zum Beispiel misst ABC-Eval die Anzahl der Runden, in denen ein Chatmodell seinen Partner ignoriert oder etwas Ungerelevantes sagt.</sample>
    <sample id="1033">Widerspricht sich selbst oder seinem Partner, halluziniert falsche Fakten oder verstößt gegen allgemein verstandenes Wissen und zeigt Empathie, wenn das Modell Erfolg hat oder versagt.</sample>
    <sample id="1034">Um zu bestimmen, welche Art der Bewertung am effektivsten ist, haben wir vier state-of-the-art Chat-Modelle ausgewählt und sie anhand von 100 menschlich-bot-Dialogen pro Modell mit der ABC-Evaluation bewertet.</sample>
    <sample id="1035">Um eine Vergleichbarkeit herzustellen, haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: Likert-Bewertungen auf Turn-Ebene, Likert-Bewertungen auf Dialog-Ebene und Paarvergleiche auf Dialog-Ebene.</sample>
    <sample id="1036">Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt. Da dies die Standardpraxis für die Bewertung von Chatmodellen an mehreren Dimensionen ist.</sample>
    <sample id="1037">Aus unseren Analysen dieser Bewertungsergebnisse haben wir festgestellt, dass die ABC-Verhaltensbeschriftungen im Allgemeinen zuverlässiger sind als Beschriftungen, die durch bestehende Methoden gesammelt wurden, wie anhand des inneren Annotatoren-Übereinstimmung auf hundert doppelt beschrifteten Gesprächen gemessen wird.</sample>
    <sample id="1038">Darüber hinaus sind die ABC-EVA-Etiketten eine bessere Vorhersage für die Gesamtqualität des Gesprächs im Vergleich zu den Metriken, die von bestehenden Methoden erzeugt werden, wie durch die einfache lineare Regressionsanalyse gezeigt wird.</sample>
    <sample id="1039">Zum Beispiel können Sie sehen, wie die Messung der Proportionen von Wenden mit selbst und Partnerkontradiktionen 5% und 10% der Gesprächsqualität erklärt, während die durchschnittlichen Likert-Konsistenzwerte nur 4% oder weniger erklären.</sample>
    <sample id="1040">Schließlich haben wir überprüft, ob jede Evaluationsmetrik einen einzigartigen Aspekt der Chatqualität einfängt, indem wir eine Schrittweise lineare Regression durchgeführt haben.</sample>
    <sample id="1041">Man kann sehen, wie die Kombination aller ABCDE - Werte die Qualität des Gesprächs über 25 % erklärt. Und wenn man die Werte nacheinander entfernt, verlieren die meisten von ihnen eine beachtliche Menge an Informationen über die Qualität.</sample>
    <sample id="1042">Andererseits erklärt die Kombination aller Turn-Level-Likert-Metriken weitaus weniger von der Qualität und weniger dieser Metriken tragen einzigartige Informationen bei.</sample>
    <sample id="1043">Diese zuverlässigen, informativen und eindeutigen ABC-Eval-Metriken ermöglichen es uns, Konversations-IA mit einer höheren Auflösung zu bewerten als bisherige Methoden es tun können.</sample>
    <sample id="1044">Man kann in den Ergebnissen unserer Experimente sehen, dass noch mehrere Herausforderungen bestehen und präzise quantifiziert wurden. Zum Beispiel haben die getesteten Bots in etwa 20% ihrer Antworten Common-Sense-Violationen.</sample>
    <sample id="1045">Sie produzieren irrelevantes Material in etwa 15 % der Antworten und widersprechen sich selbst oder ihrem Partner etwa 10 % der Zeit.</sample>
    <sample id="1046">Mit dem schnellen Tempo der Verbesserung in diesem Bereich könnten viele dieser Fehlerquoten bei neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, abnehmen. Allerdings ist das umso mehr Grund, sich für zuverlässige und präzise Bewertungsmetriken zu engagieren, um Modelle miteinander vergleichen zu können.</sample>
    <sample id="1047">Wir hoffen, dass ABC Eval von anderen im Bereich als ein bedeutender Schritt in diese Richtung genutzt werden kann. Und wir freuen uns darauf, zu sehen, wie sich die KonversationskI in den kommenden Monaten und Jahren weiterentwickeln wird. Danke fürs Zuschauen.</sample>
    <sample id="1048">Emory University.</sample>
    <sample id="1049">Continuous fine-tuning.</sample>
    <sample id="1050">Sechs.</sample>
    <sample id="1051">Hallo, mein Name ist Coyote und ich werde unsere Arbeit mit dem Titel "Wann erfordert eine Übersetzung Kontext? Eine datenbasierte multilinguale Untersuchung" präsentieren. Diese Arbeit wurde in Zusammenarbeit mit Patrick Franses, Emile Liu, André F. T. Martins und Graham Newbigging durchgeführt.</sample>
    <sample id="1052">"Translate the English content back into German."</sample>
    <sample id="1053">Wenn der vorherige Satz "Dinge könnten anfänglich gefährlich werden, wenn die Minister es herausfinden", lautete, dann bezieht sich "Moll" auf einen Spion. Aber wenn der vorherige Satz "Könnte es etwas Ernstes sein, Doktor?" lautete, dann bezieht sich "Moll" auf ein Geburtsschwielen.</sample>
    <sample id="1054">Je nach Kontext ändert sich die Bedeutung des Wortes und somit auch seine Übersetzung.</sample>
    <sample id="1055">Allerdings ist es ziemlich schwierig, zu beurteilen, wie gut Modelle solche kontrastiven Fälle wie diesen abdecken. Zunächst einmal, weil nur ein kleiner Teil der Übersetzungen von Kontext abhängt, was die korpusbasierten Metriken wie BLEU daran hindert, diese Übersetzungen einzufangen.</sample>
    <sample id="1056">Manche Leute haben vorgeschlagen, auf kontextabhängige Übersetzungen zielgerichtete Beurteilung durchzuführen. Aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachensätze. Da sie normalerweise auf Domänenwissen und menschlicher Kuration zurückgreifen.</sample>
    <sample id="1057">In diesem Werk versuchen wir, diese beiden Fragen zu beantworten. Erstens, wann erfordert die Übersetzung Kontext? Und zweitens, wie gut handhaben Modelle diese Fälle?</sample>
    <sample id="1058">Um die erste Frage zu beantworten, haben wir damit begonnen, zu messen, wie stark ein Wort von seinem Kontext in der Übersetzung abhängt.</sample>
    <sample id="1059">In der vorherigen Arbeit haben wir CXMI als Maß für Kontextnutzung von maschinellen Übersetzungsmodellen eingeführt. Dies wird durch die Messung der Menge an Informationen durchgeführt, die der Kontext C über das Ziel Y gegeben der Quelle X bereitstellt.</sample>
    <sample id="1060">Du kannst dich CXMI als die Information verstehen, die man durch das Geben von Kontext an das Modell gewinnt.</sample>
    <sample id="1061">In dieser Arbeit haben wir CxMI zu Pointwise CxMI erweitert, was die Kontextnutzung auf der Satz- oder Wortebene messen kann. Wir können Wörter denken, die eine hohe Pointwise CxMI haben, als solche, die Kontext für die Übersetzung benötigen.</sample>
    <sample id="1062">Jetzt analysieren wir Wörter mit hohem PSMI, um Muster zwischen diesen Wörtern zu suchen.</sample>
    <sample id="1063">Wir führen unsere Analyse an Transkripten von TED - Vorträgen durch, die insgesamt in 14 verschiedenen Sprachen übersetzt wurden.</sample>
    <sample id="1064">Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zuerst schauen wir auf Part-of-Speech-Tags mit hohen mittleren PSMI-Werten.</sample>
    <sample id="1065">Und das ermöglicht es uns, zum Beispiel, duale Pronomen im Arabischen zu finden, die relativ hohe P6XMI haben. Und das kann erklärt werden, weil das Englische keine duale Pronomen hat, also braucht man Kontext, um zu bestimmen, ob ein Pronomen dual ist, wenn es ins Arabische übersetzt wird.</sample>
    <sample id="1066">Und ähnlich finden wir, dass bestimmte Sprachen auch Kontext benötigen, wenn wir die passende Verbst形 auswählen wollen. Wir schauen dann auf Vokabularstücke, die eine hohe P - Sektor haben, gemittelt über alle ihre verschiedenen Vorkommen.</sample>
    <sample id="1067">Und das hilft, Fälle wie den hier zu identifizieren, wo in Chinesisch Kontext benötigt wird, um die richtigen Nomen zu übersetzen, um sicherzustellen, dass dieselbe Übersetzung innerhalb des Dokuments verwendet wird.</sample>
    <sample id="1068">Und ähnlich finden wir, dass Kontext die Übersetzung in die richtige Formalität unterstützt.</sample>
    <sample id="1069">Und schließlich sehen wir uns verschiedene Einzel-Token mit hohem P - XMI an. Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in der Satzstruktur ausgedrückt werden, wie zum Beispiel Ellipsenauflösung.</sample>
    <sample id="1070">Also verwenden wir unsere Ergebnisse aus der Analyse, um einen Benchmark für die dokumentenbasierte Übersetzung zu entwerfen.</sample>
    <sample id="1071">Für jede der fünf diskursiven Phänomene, die wir identifiziert haben, erstellen wir Tags, um automatisch Wörter zu identifizieren, die mit dem Phänomen in Zusammenhang stehen, und wir nennen unsere Tags den multilingualen diskursbewussten oder MUDA-Tagger.</sample>
    <sample id="1072">Wir können auch bemerken， dass verschiedene Sprachen unterschiedliche Proportionen dieser diskursiven Phänomene haben.</sample>
    <sample id="1073">Dann verwenden wir den MuDe-Tagger, indem wir den Tagger auf dem parallelen Korpus anwenden, den wir zur Evaluierung verwenden möchten. Und wir wenden unsere gewünschten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der MuDe-Tagger identifiziert hat.</sample>
    <sample id="1074">Und schließlich verwenden wir unsere Benchmark sowie andere Metriken, um verschiedene Modelle im Bereich der dokumentenweiten maschinellen Übersetzung zu bewerten.</sample>
    <sample id="1075">Zunächst einmal, wenn wir korpusbasierte Maße verwenden, so finden wir für BLEU, dass konsensusunabhängige Modelle die beste Leistung haben.</sample>
    <sample id="1076">Aber wenn wir Comet-Kontextmodelle verwenden, leisten sie am besten. Und wenn wir den WordF-Maßstab verwenden, haben Modelle mit und ohne Kontext vergleichbare Leistungen.</sample>
    <sample id="1077">Dies zeigt erneut, dass es schwierig ist, den besten Übersetzungs-System zu bestimmen, wenn wir nur Korpus-Level-Metriken verwenden.</sample>
    <sample id="1078">Nun verwenden wir die MUMU-Benchmark, um Modelle zu evaluieren, und wir finden, dass Kontext-basierte Modelle signifikant präziser sind als Modelle, die für bestimmte Diskursphänomene, wie Formalität und lexikalische Kohäsion, keinen Kontext verwenden.</sample>
    <sample id="1079">Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext auf andere Phänomene wie Ellipsen, Pronomen und Verbstypen verwenden. Das deutet darauf hin, wo wir für die Dokumentebene - Übersetzung mehr Fortschritt sehen müssten.</sample>
    <sample id="1080">Wir haben auch verschiedene kommerzielle Systeme verglichen und unsere Leitlinie zeigt, dass DeepL für die Übersetzung von Dokumenten in der Regel genauer ist als Google Translate.</sample>
    <sample id="1081">Wir führen eine datenbasierte Analyse über 14 Sprachpaare durch, um zu identifizieren, wann Übersetzungen Kontext benötigen.</sample>
    <sample id="1082">Dann verwenden wir unsere Ergebnisse, um einen Benchmark für die maschinelle Übersetzung auf Dokumentenebene zu erstellen. Dies kann uns dabei helfen, zu identifizieren, welche Diskursphänomene Modelle gut bewältigen können oder nicht, und welche Übersetzungs-Systeme gut bei der Übersetzung auf Dokumentenebene sind.</sample>
    <sample id="1083">Vielen Dank für Ihre Aufmerksamkeit. Bis bald in Toronto.</sample>
    <sample id="1084">Justin John.</sample>
    <sample id="1121">Diese Frage ist nicht relevant zu dem englischen Inhalt, den Sie angegeben haben. Es gibt keine neue Methode erwähnt. Also kann ich keinen Namen nennen. Wenn Sie mehr Informationen haben, die relevant sind, dann können Sie sie mir geben und ich werde versuchen, die Frage zu beantworten.</sample>
    <sample id="1122">The authors describe the method of "marked words" as a way to identify the words that distinguish marked groups from unmarked ones.</sample>
    <sample id="1123">Die Autoren gehören an der University of Washington.</sample>
    <sample id="1124">The Prague approach.</sample>
    <sample id="1125">James Finch und Sarah Finch.</sample>
    <sample id="1126">Es sind vier Autoren an der Arbeit beteiligt. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="1127">Minimal Pair Paradigm.</sample>
    <sample id="1161">I'm sorry, but you haven't provided the five methods for the first research question. Could you please give me more details?</sample>
    <sample id="1162">Das Modell wird an 11 biomedizinischen und klinischen Anwendungsaufgaben evaluiert.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich mit der 4GB-Untermenge von NACOS trainiert.</sample>
    <sample id="1227">Adam Skowroński.</sample>
    <sample id="1228">Die Ergebnisse der Experimente, bei denen Modelle mit neueren Daten weitertrainiert wurden, zeigten, dass die Leistung mit größerem zeitlichen Abstand abnimmt. Das bestätigte unsere Hypothese, dass die Hauptursache für den Leistungsverlust die zeitliche Verzögerung ist. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="1269">Because the tokens are not ordered after the first step.</sample>
    <sample id="1270">Die Autoren empfehlen, dass Modellentwickler*innen ihre Methoden transparenter machen sollten, weil es unklar ist, ob positive Stereotypen auf übertriebene Wertorientierung oder andere anti-stereotypische Methoden zurückzuführen sind.</sample>
    <sample id="1271">Inacceptable minimal pairs are ungrammatical sentences.</sample>
    <sample id="1272">The text doesn't mention the specific evaluation metrics used.</sample>
    <sample id="1273">Inner annotator agreement.</sample>
    <sample id="1274">Wikipedia.</sample>
    <sample id="1275">Ich habe leider keine Informationen über die Autoren oder die Universität, an der sie angehören, aus dem englischen Inhalt. Könntest du mir vielleicht mehr dazu sagen?</sample>
    <sample id="1276">MultiInstruct unterscheidet sich von anderen Benchmarks dadurch, dass es ein multimodales Datensatz für die Anpassung von Anweisungen ist, während andere Benchmarks meist auf Sprachalleinstellungen fokussiert sind. Es gibt keine großen öffentlich verfügbaren multimodalen Anweisungsaufgaben, was MultiInstruct einzigartig macht.</sample>
    <sample id="1277">Zwei. James Finch und Sarah Finch.</sample>
    <sample id="1278">I'm sorry, but the given text doesn't contain the definition of binäre Koordination. Can you provide more context or a different text?</sample>
    <sample id="1279">Ich habe leider keine genauen Informationen über die Länge der verwendeten Prompts in dieser Studie. Könnten Sie mir vielleicht mehr Details geben?</sample>
    <sample id="1280">Die Ergebnisse zeigen, dass das kleinere T5-Modell bei richtiger Ausbildung auf geeigneten Datensätzen ähnliche oder sogar höhere Qualität von Skripten generieren kann wie größere Modelle. Also hat es positive Auswirkungen auf seine Leistungsfähigkeit. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="1281">Hallo, ich bin Janice Lavoie und ich werde Ihnen unsere Arbeiten über Dr. Bert, ein robustes vortrainiertes Modell auf Französisch für die biomedizinische und klinische Domäne vorstellen.</sample>
    <sample id="1282">In dieser Präsentation sprechen wir zuerst über Sprachmodellierung im Gesundheitswesen. Dann werden wir die Hauptbeiträge unseres Artikels vorstellen.</sample>
    <sample id="1283">Wir haben das erste biomedizinische Modell in Französisch vorgestellt, das Dr. Bert genannt wird. Es basiert auf Roberta und wurde an Nachos, einem Datensatz medizinischer标注数据， aus dem Web, trainiert.</sample>
    <sample id="1284">Wir haben auch eine Vergleichsanalyse von Modellen mit verschiedenen Prüfungsstellungen und Datensätzen eingeführt. Anschließend präsentieren wir unsere Ergebnisse zu elf biomedizinischen und klinischen Prüfungsaufgaben in Französisch.</sample>
    <sample id="1285">Und schließlich fassen wir die Experimente zusammen und geben Ihnen weitere Details darüber, wie Sie zu den Modellen zugreifen können.</sample>
    <sample id="1286">Seit seiner Einführung im Jahr 2018 ist BERT zu einem der effektivsten Ansätze für die Lösung von Natural Language Processing - Aufgaben geworden und bietet einen riesigen Leistungszuwachs im Vergleich zu historischen statischen und kontextuellen Methoden wie Word2Vec, FastText oder ANMO.</sample>
    <sample id="1287">Seitdem wurde dieses Modell in viele andere Sprachen übertragen, wie zum Beispiel ins Französische mit Camembert. Es wurde auch in bestimmten Bereichen wie Biomedizin mit PubMed und Biobert verwendet und in der Klinik mit ClinicalBERT. Aber hauptsächlich in Englisch.</sample>
    <sample id="1288">Spezialisierte Modelle für andere Sprachen sind selten und oft auf kontinuierliche Prädiktion basierend auf der Mangel an in-domänigen Daten.</sample>
    <sample id="1289">Allerdings hatte Frankreich bislang keine offene Quellcode-Modell für die Medikamentenkontrolle.</sample>
    <sample id="1290">Wir stellen uns die Frage, welche Datensätze am besten für eine weite Verwendung geeignet sind, und solche Strukturdaten sind eine gute Ersatzquelle für klinische Daten.</sample>
    <sample id="1291">Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schulbert-Modell, das auf anonymisierten Daten basiert, die von der Non-University Hospital in Datow House erhalten wurden.</sample>
    <sample id="1292">Am Ende fragen wir uns, wie viel Daten wir für das Trainieren eines spezialisierten Modells auf französischen Daten benötigen. Ist es 4 GB, 8 GB oder mehr?</sample>
    <sample id="1293">Um diese Frage zu beantworten, müssen wir zuerst von Grund auf vier Modelle trainieren und vergleichen. Eine erste Version von Dr. Bert mit 7 GB von Nachos, eine zweite Version von 4 GB von Nachos.</sample>
    <sample id="1294">Eine erste Version von Schubert, die ein klinisches Modell ist, mit 4 GB von klinischen Notizen. Eine zweite Version von Schubert mit einem gemischten Satz von 4 GB von klinischen Notizen und 4 GB von Natur.</sample>
    <sample id="1295">Zusätzlich zu dieser Vergleichung haben wir drei Modelle eingeführt, die auf Kontextprätraining trainiert wurden, um den Einfluss von Prätrainingsstrategien zu analysieren.</sample>
    <sample id="1296">Einer basiert auf der Gewichtung von Camembert und trainiert auf einem 4-Gigabyte-Teilset von Nektarinen. Der andere basiert ebenfalls auf Camembert, aber trainiert diesmal auf dem 4-Gigabyte-Teilset von Kirschen.</sample>
    <sample id="1297">Und schließlich wurde ein Modell auf Basis des englischen Biomedical-Modells BERT trainiert und auf einem Subset von SNACCS mit 4 GB trainiert. Insgesamt haben wir insgesamt 7 Modelle.</sample>
    <sample id="1298">Um alle sieben Modelle zu bewerten, haben wir mehrere öffentliche und private Aufgaben gesammelt, wie Namenserkennung, Klassifikation, Sprachauswertung und Fragebeantwortung.</sample>
    <sample id="1299">Diese Modelle werden mit sechs neu entwickelten Modellen verglichen, die Camembert Oscar 128 GB, Camembert Oscar 4 GB, Camembert C-Sinet 4 GB, Permabert, Myobert und Clinicalbert sind.</sample>
    <sample id="1300">Die Leistung von Highlight - Modellen ist am besten bei Aufgaben, die mit Daten der gleichen Art wie die uns zur Verfügung stehen, die auf diesem Modell trainiert wurden.</sample>
    <sample id="1301">Allerdings können wir die Daten von heterogenen Quellen beobachten, die anscheinend mehr vielseitig sind. Wir beobachten auch, dass das Verwenden von mehr Daten in die bessere Leistung übersetzt wird.</sample>
    <sample id="1302">Innovative von Scratch - Training scheint bei den meisten Aufgaben zu höheren Leistungen zu führen.</sample>
    <sample id="1303">Allerdings haben unsere Experimente zum Kontinuierlichen Trainieren mit dem Gewicht und Tokenizer von Pegasus, das auf einer 4-GByte-Untergruppe von NACOS trainiert wurde, vergleichbare Ergebnisse wie diejenigen, die mit Dr. Web 4 GByte von Grund auf erzielt wurden.</sample>
    <sample id="1304">Welches ist nicht der Fall für das Modell, das auf Camembert-Weights und Tokenizer basiert, die Stabilitätsprobleme haben?</sample>
    <sample id="1305">Schlussendlich haben wir eine bessere Leistung auf neun der elf Aufgaben des DNNs erreicht und übertrafen die Ergebnisse des generierten Modells hier, Camembert.</sample>
    <sample id="1306">Wir haben auch beobachtet, dass spezialisierte Daten besser sind, aber sie skaliert sich nicht gut.</sample>
    <sample id="1307">Ja, die prätrainierten Modelle, die von Natus Vincere erworben wurden, sind frei verfügbar und auf der Nutanix-Website zu finden. Und alle Trainings-Skripte sind in unserem GitHub-Repository.</sample>
    <sample id="1308">Also vielen Dank für diese Präsentation und wir freuen uns auf die Austauschbegegnungen in Toronto.</sample>
    <sample id="1309">Die Arbeit untersucht die Lernstrategien von Trainieren und Vergleichen von Modellen von Scratch, Trainieren auf Kontext-Prätraining.</sample>
    <sample id="1310">Der Faktor der Überanpassung ist größer als 1.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde anhand von Scores und Evaluationsmetriken beurteilt. Wenn du mehr Details haben möchtest, kannst du in das Papier schauen.</sample>
    <sample id="1312">Ja, Sprachmodelle haben unterschiedliche politische Vorurteile. Sie befinden sich in allen vier Quadranten des politischen Kompasses.</sample>
    <sample id="1313">Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen einen kurzen Einblick in unsere Arbeit über Komposition und Generalisierung ohne Bäume unter Verwendung von Multiset - Tagging und latenten Permutationen geben.</sample>
    <sample id="1314">Dies ist eine gemeinsame Arbeit mit meinen Betreuern Alexander Koller und Ivan Titov.</sample>
    <sample id="1315">Kompositionelle Generalisierung kann als die Fähigkeit des Lerners verstanden werden, tiefergehende Rekursionen und unerwartete Kombinationen von Phrasen zu handhaben, die während des Trainings einzeln gesehen wurden.</sample>
    <sample id="1316">Im Kontext der semantischen Parsing, die für die kompositionale Generalisierung getestet wird, könnte es so aussehen: "Als üblich haben wir einen Trainingsset von Utternzen. In diesem Fall: "Die Mädchen schliefen" und "Mary wusste, dass die Mädchen schliefen."</sample>
    <sample id="1317">Diese Aussagen sind mit logischen Formen verbunden, die ihre Kernaspekte der Bedeutung darstellen.</sample>
    <sample id="1318">Im Gegensatz zur Standard-Maschinenlern-Evaluation kommt die Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell unerkannte logische Formen.</sample>
    <sample id="1319">Im Beispiel hat das Modell während des Trainings tiefere Rekursion gesehen und wird an Beispielen mit tieferer Rekursion getestet.</sample>
    <sample id="1320">Naive sequenz-zu-sequenz-Modelle haben Schwierigkeiten mit dieser Art von Out-of-Distribution-Generalisierung und produzieren häufig Outputs, die sich vom Input entfernt haben.</sample>
    <sample id="1321">Insbesondere versagen sie oft, die systematischen Korrespondenzen zwischen Eingang und Ausgang zu reproduzieren, wie z.B. diejenigen, die in dem Beispiel farbcodiert sind.</sample>
    <sample id="1322">Eine beliebte Methode zur Bewältigung davon ist, Bäume in die Modelle einzubinden.</sample>
    <sample id="1323">Die Bäume sollen den kompositorischen Prozess darstellen, der die Aussagen mit den logischen Formen verbindet.</sample>
    <sample id="1324">Dies funktioniert gut, aber Bäume werden normalerweise nicht gegeben, sie müssen irgendwie erworben werden.</sample>
    <sample id="1325">Dies kann kompliziert und manchmal rechenaufwendig sein. Normalerweise umfasst dies eine beträchtliche formalspezifische Vorbearbeitung der logischen Formen, zum Beispiel, um Variablessymbole zu handhaben.</sample>
    <sample id="1326">Das Erhalten von Bäumen kann auch mit spezialisierten Grammatikinduktionverfahren verbunden sein.</sample>
    <sample id="1327">In diesem Papier verwenden wir keine Bäume und führen einen neuen sequenz-zu-sequenz-Modell ein, das direkt die Korrespondenzen zwischen Fragmenten des Inputs und Fragmenten des Outputs modelliert.</sample>
    <sample id="1328">Zum ersten Mal zeigen wir eine starke Generalisierung zu tieferen Rekursionen ohne sich auf Bäume zu stützen.</sample>
    <sample id="1329">Unser Ansatz berechnet die Ausgabe aus der Eingabe in zwei Schritten.</sample>
    <sample id="1330">Zuerst taggen wir jede Eingabewort mit einer unordentlichen Multisatz von Wörtern, die im Ausgang erscheinen werden.</sample>
    <sample id="1331">Nach dem ersten Schritt haben wir alle richtigen Tokens, aber sie sind nicht geordnet.</sample>
    <sample id="1332">Das ist der Grund, warum wir in der zweiten Schritt ein anderes Modell verwenden, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen.</sample>
    <sample id="1333">Wir führen eine neue Methode zur Vorhersage einer Permutation ein, die keine harten Einschränkungen auf mögliche Permutationen anlegt. Dies macht unsere Herangehensweise recht flexibel und ausdrucksstark.</sample>
    <sample id="1334">Konzeptionell funktioniert unser Permutation-Modell ungefähr so.</sample>
    <sample id="1335">Wir gehen von links nach rechts über die Ausgabe und bestimmen, welchen Multiset-Token wir in jede Position einfügen. Für die erste Ausgabeposition wählen wir einfach einen aus, wie in Rot hervorgehoben.</sample>
    <sample id="1336">Dann springen wir zum nächsten Multiset-Token, um den zweiten Token im Output zu bestimmen.</sample>
    <sample id="1337">Wir bestimmen den dritten Token in der Ausgabe auf ähnliche Weise, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Prozess fort.</sample>
    <sample id="1338">Bis alle Tokens aus der ersten Phase genau einmal besucht wurden.</sample>
    <sample id="1339">Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir unsere Methode mit anderen baumlosen Modellen auf dem Cogls-Benchmark. Unser Modell übertrifft die anderen bei weitem bei der Generalisierung auf tiefere Rekursion.</sample>
    <sample id="1340">Einige andere Arten von struktureller Generalisierung sind jedoch sehr herausfordernd.</sample>
    <sample id="1341">In unserem Papier lösen wir einige interessante technische Herausforderungen.</sample>
    <sample id="1342">Zunächst einmal, die Ausrichtung zwischen Eingabe und Ausgabe ist im Trainingsdatensatz nicht angegeben. Als Folge davon wissen wir für einen gegebenen Token nicht, welches Multisett es stammt, was eine Herausforderung für das Trainieren darstellt.</sample>
    <sample id="1343">Zusätzlich gibt es manchmal mehrere Permutationen, die mit den Daten konsistent sind, aber die sprachlich korrekte ist versteckt. Wir haben dies durch die Induktion der Ausrichtung als Teil des Trainings gelöst.</sample>
    <sample id="1344">Unsere Permutation-Methode ist sehr flexibel, aber sie bringt die Herausforderung, dass das Finden der höchstbewerteten Permutation NP-vollständig ist. Das liegt daran, dass dies mit dem Reisendenverkäufer-Probleme zusammenhängt.</sample>
    <sample id="1345">Wir nähern uns diesem mit einer GPU-freundlichen kontinuierlichen Relaxation, die auch die Rückpropagation durch die Lösung ermöglicht und die sprachlich plausibleren Permutationen lernen lässt.</sample>
    <sample id="1346">Wenn Sie mehr über unsere Experimente und die Art und Weise erfahren möchten, wie wir diese Herausforderungen angegangen haben, dann schauen Sie sich bitte unseres Papiers an oder kommen Sie zu unserem Poster.</sample>
    <sample id="1347">Cognitive dissonance is when two beliefs or actions are inconsistent.</sample>
    <sample id="1348">GPT-4.</sample>
    <sample id="1349">Ja, kumulatives Training hat sich als besser für aktives Lernen erwiesen als iteratives Training. Wenn du noch weitere Fragen hast, lass sie gerne kommen.</sample>
    <sample id="1350">Sarah Pape.</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen von Transkripten von TED Talks, die insgesamt 14 verschiedene Sprachen abdecken.</sample>
    <sample id="1385">Matthias Lindemann.</sample>
    <sample id="1386">Sprachübergreifender Transfer ist der Prozess, bei dem man auf einer Quellsprache trainiert und dann auf eine ZielSprache überträgt. Hier trainiert man auf englischen Abfragen oder einer Kombination von englischen und deutschen FewshotAbfragen, um ein multilingualen Modell zu bauen, das die SQL-Ausgabe vorhersagt.</sample>
    <sample id="1387">Die Autoren gehören an die Saarland University in Deutschland.</sample>
    <sample id="1388">The authors use average lagging and computational aware average lagging.</sample>
    <sample id="1389">Hallo alle zusammen, ich bin Makhshatta und heute präsentieren Kollege Martin und ich unsere Arbeit "The Kid Must Have: Evaluating Knowledge Integration from Multiple Sources". Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, MILA und Microsoft Research.</sample>
    <sample id="1390">Natürlichsprachverstehende Modelle stützen sich auf verschiedene Wissensquellen, wie zum Beispiel Wissen, das in ihren Parametern enthalten ist und normalerweise durch Vorkontinuierung erlangt wurde, und Wissen, das bei der Inferenz in Eingaben gegeben wird.</sample>
    <sample id="1391">Neueste Arbeiten in Aufgaben wie Fragebeantwortung zeigen, dass Modelle prätrainiertes Wissen verwenden können, um die Aufgabe zu lösen.</sample>
    <sample id="1392">Aber die natürliche Sprachverstehung erfordert oft Wissen, das auch in der Inferenzzeit bereitgestellt wird.</sample>
    <sample id="1393">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1394">Prätrainierte Parameter können Informationen über was Präsidenten tun und was sie tun, aber sie können nicht zuverlässig wissen, wer diese spezifische Instanz des Entitäten-John ist oder wer der neue Präsident ist, weil der Präsident seit der Prätraining möglicherweise geändert hat.</sample>
    <sample id="1395">Daher erfordern erfolgreiche Modelle für knowledge-intensive NLU-Aufgaben die Fähigkeit, sowohl prätrainiertes als auch inferenzzeitiges Wissen zu integrieren und zu nutzen.</sample>
    <sample id="1396">In dieser Arbeit wird ein Diagnosetestsatz für die Wissensintegration vorgeschlagen.</sample>
    <sample id="1397">Wir führen eine Co-Referenz-Auflösungsaufgabe ein, um die Fähigkeit zu prüfen, auf Wissen aus verschiedenen Quellen zurückzugreifen. Wir bewerten die Datensätze mit humanen Studienteilnehmern und etablierten Co-Referenz-Auflösungsmodellen.</sample>
    <sample id="1398">Sylvia ist Richterin. Kira ist Bäckerin. Sylvia und Kira trafen sich in einem Park. Nach einem langen Tag im Gerichtshof, bei dem er Entscheidungen in einem langen Prozess zu treffen hatte, war er froh, sich zu entspannen.</sample>
    <sample id="1399">Der Auftrag hier ist, die korrekte Entität zu identifizieren, auf die der Pronom "er" sich bezieht, was in diesem Fall "Sam" ist.</sample>
    <sample id="1400">Die Auflösung eines gegebenen Pronoms erfordert zwei Arten von Informationen. Erstens spezifische Wissensinformationen über eine Entität, z.B. "Saul ist ein Richter", und zweitens Hintergrundwissen, z.B. "Richter entscheiden Fälle in Gerichten".</sample>
    <sample id="1401">Im Allgemeinen wird Hintergrundwissen während des Prätrainings großer Sprachmodelle erlernt, während spezifische Wissensinhalte von Entitäten normalerweise bei der Inferenz beobachtet werden.</sample>
    <sample id="1402">Wir variieren die Verfügbarkeit dieser beiden Informationen so, dass sie entweder in einer einzigen Quelle oder in mehreren Quellen zu finden sein kann.</sample>
    <sample id="1403">Wir haben drei Einstellungen für KitMOS definiert. Erstens haben wir die Setting "Backbone Pretrain", bei dem das Backbone-Wissen angenommen wird, verfügbar zu sein, wenn es vortrainiert wird.</sample>
    <sample id="1404">Zweitens gibt es die Hintergrundwissens-Einstellung. Das Hintergrundwissen ist sowohl während des Prädikationszeitpunkts als auch während des Inferenzzeitpunkts verfügbar. Letztendlich gibt es die Hintergrund-Inferenz-Einstellung. Das Hintergrundwissen ist nur während des Inferenzzeitpunkts verfügbar.</sample>
    <sample id="1405">Diese letzte Einstellung ist besonders interessant, da sie den Fall simuliert, bei dem ein Hintergrundgeräusch notwendig ist, um die Aufgabe zu lösen. Es ist nicht Teil des vortrainierten Datensatzes der Modelle. Zum Beispiel, weil neue Berufe seit der Zeit der Vortraining entwickelt wurden.</sample>
    <sample id="1406">Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in einer Quelle steuern.</sample>
    <sample id="1407">Im Vorkondensierungssetting wird angenommen, dass das Vorkondensierwissen, Politiker streben nach gewählten Sitzen im Regierung, in den Vorkondensierparametern enthalten ist. Um den Kontext zu verstehen, wird das spezifische Wissen zur Antik vermittelt, dass Chichester ein Politiker ist.</sample>
    <sample id="1408">In der Hintergrundbeleuchtungseinstellung bieten wir nicht nur spezifische Antworten, sondern auch Hintergrundwissen über Politiker im Kontext der Entfernung.</sample>
    <sample id="1409">Im Hintergrund und in den Einstellungen der App wird die Funktion "militärisch" anstelle von "politisch" bereitgestellt, da "militärisch" in den vortrainierten Parametern unwahrscheinlich enthalten ist.</sample>
    <sample id="1410">Wir haben den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten Referenz-Lösungsmodellen evaluiert. In diesem Bild zeigen wir die Ergebnisse der besten leistungsstarken Modelle auf der schwierigsten Variante des Backprop-Trainings-Sets.</sample>
    <sample id="1411">Ohne spezielle Ausbildung an KIT-MOS leisten beide Modelle schlecht. Wenn sie an KIT-MOS trainiert werden, performen C2F und BERT4QA jedoch signifikant besser als zufällige Auswahl.</sample>
    <sample id="1412">Es wurde vorgeschlagen, dass Modelle, die auf generellen Frage-Antwort-Datensätzen trainiert wurden, lernen, Oberflächenanzeichen auszunutzen, die bei der Prüfung auf Kit-Mustern nicht nützlich sind, da solche Anzeichen entfernt wurden.</sample>
    <sample id="1413">Zusätzliche Experimente mit fiktivem Wissen zeigten, dass selbst die besten Modelle nicht zuverlässig Backward-Knowledge integrieren können, wenn es nur zur Inferenzzeit bereitgestellt wird.</sample>
    <sample id="1414">Viele KI-Referenzmodellierungen scheinen ohne taskbasierte Ausbildung nicht in der Lage zu sein, Wissen aus verschiedenen Quellen zu verarbeiten. Allerdings können einige mit taskbasiertem Training erfolgreich Wissen aus mehreren Quellen integrieren.</sample>
    <sample id="1415">Trotzdem scheinen sogar die besten Modelle Schwierigkeiten zu haben, vertrauenswürdig rückwärts integrierte Wissensdaten zu integrieren, die nur während der Inferenz präsentiert werden. Wenn Sie mehr Details interessieren, sehen Sie sich unseres Papiers an und überprüfen Sie den Datensatz und den Code auf GitHub. Danke fürs Zuhören.</sample>
    <sample id="1416">Nicht gegeben.</sample>
    <sample id="1417">The authors belong to Cornell University.</sample>
    <sample id="1418">Hallo, ich bin Myra und heute werde ich über unser Papier "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models" sprechen. Dieses Werk wurde in Zusammenarbeit mit S. S. D. Mosh und D. D. R. S. durchgeführt.</sample>
    <sample id="1419">In den letzten Jahren haben viele die Prävalenz von sozialen Voreingenommenheiten und Stereotypen in großen Sprachmodellen, LLMs, dokumentiert.</sample>
    <sample id="1420">Allerdings haben diese Maßnahmen verschiedene Einschränkungen. Sie stützen sich in der Regel an handkonstruierte Datensätze, die sehr zeitaufwendig zu kuratieren sind.</sample>
    <sample id="1421">Und sie messen normalerweise auch nur sehr spezifische Stereotypen, was bedeutet, dass sie nicht gut auf andere Demographien oder Kontexte generalisieren können, oder sie fangen einfach sehr allgemeine, breite Assoziationen ein, wie negative Assoziationen mit bestimmten Gruppen.</sample>
    <sample id="1422">Darüber hinaus berücksichtigen die meisten Arbeiten in diesem Bereich nicht die Intersektionalität, die Idee, dass multifarbige soziale Identitäten Befangenheiten verstärken und einzigartige Schmerzpunkte bilden können.</sample>
    <sample id="1423">Um diese Einschränkungen zu überwinden, verlassen wir uns darauf, dass diese neu auf指令调优的LLMs sehr gut darin sind, auf Anweisungen und Anregungen zu reagieren.</sample>
    <sample id="1424">Also können wir das Modell fragen, ein Persona zu generieren, was eine Darstellung einer imaginären Person ist, indem wir einen Prompt wie "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." verwenden.</sample>
    <sample id="1425">Und wir können sofort sehen, dass dies sehr allgemein auf jede Demografie übertragbar ist, weil wir einfach jede gewünschte Identitätsmarke in diesen Prompt eintragen können.</sample>
    <sample id="1426">Nun, ich kann Ihnen nicht direkt die Übersetzung der englischen Inhalte nach Deutsch geben, da ich nicht die genauen Inhalte von GPT-4 habe. Wenn Sie mir die englischen Inhalte geben, kann ich Ihnen gerne die Übersetzung nach Deutsch machen.</sample>
    <sample id="1427">Unmittelbar sehen wir, dass die Outputs nicht offensichtlich negativ oder giftig im traditionellen Sinne dieser Wörter sind.</sample>
    <sample id="1428">Es gibt einige interessante Muster.</sample>
    <sample id="1429">Die asiatische Frau wird als unauffällig dargestellt. Die mittelöstliche Frau wird mit Begriffen wie exotisch und wie bezogen auf eine faszinierende Region beschrieben.</sample>
    <sample id="1430">Und beide der Farbigen-Frauen-Persönlichkeiten machen sich auf die Abstammung bezogen, während die weiße-Mann-Persönlichkeit nichts dergleichen hat.</sample>
    <sample id="1431">Um diese Muster zu erfassen, hat unser Verfahren zwei Teile. Der erste Teil ist die Erstellung dieser Personas.</sample>
    <sample id="1432">Unsere Prompts zur Erstellung dieser Persönlichkeiten waren von einer Studie inspiriert, bei der sie diese Prompts an menschliche Probanden gab. Es wurde festgestellt, dass durch das Geben an menschliche Probanden auch rassistische Stereotypen an die Oberfläche kamen.</sample>
    <sample id="1433">Und das ermöglicht eine direkte Vergleichbarkeit zwischen unseren generierten Persönlichkeiten und den von Menschen geschriebenen Antworten.</sample>
    <sample id="1434">Der zweite Teil ist "Markierte Wörter", eine Methode, um die Wörter zu identifizieren, die markierte Gruppen von unmarkierten unterscheiden, die werde ich kurz erläutern.</sample>
    <sample id="1435">Der Vorteil ist, dass wir sehr spezifische Stereotypen und Muster erhalten, ohne auf ein bestimmtes Lexikon angewiesen zu sein.</sample>
    <sample id="1436">Der Marked Words -Ansatz stützt sich auf das soziolinguistische Konzept der Markierung, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die von diesem Standard abweicht, sprachlich markiert ist.</sample>
    <sample id="1437">Zum Beispiel wird das Wort "Krieger" normalerweise mit Männern in Verbindung gebracht. Wenn Menschen einen Krieger beschreiben, der eine Frau ist, sagen sie normalerweise "Frauenkrieger" und markieren den Begriff mit "Frauen".</sample>
    <sample id="1438">Und im allgemeinen sind die dominanten Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen normalerweise markiert sind.</sample>
    <sample id="1439">Also in unserem Verfahren, wir zuerst die unmarkierten und markierten Gruppen festlegen.</sample>
    <sample id="1440">Und dann vergleichen wir die Personas mithilfe des Fighting Words -Verfahrens, das im Grunde Gewichtete Log-Odds-Verhältnisse verwendet, um die Top-Wörter für jede markierte Gruppe zu unterscheiden.</sample>
    <sample id="1441">Zum Beispiel bei den Personas von schwarzen Frauen würden wir "Fighting Words" machen und die Log-Odds-Verhältnisse mit denen von weißen Personas und männlichen Personas vergleichen, da diese die beiden entsprechenden unmarkierten Gruppen sind.</sample>
    <sample id="1442">Also, zu den Ergebnissen. Zuerst haben wir das Lexikon von Stereotypen verwendet und festgestellt, dass die generierten Persönlichkeiten viel mehr Stereotypen enthalten als die von Menschen geschriebenen.</sample>
    <sample id="1443">Jedoch wenn wir tatsächlich die Verteilung der Wörter im Wörterbuch betrachten, finden wir sehr unterschiedliche Dinge.</sample>
    <sample id="1444">Also, während die generierten Persönlichkeiten viel höhere Raten der luxemburgischen Wörter haben, haben die von Menschen geschriebenen viel breitere Verteilung von Wörtern, während die Stereotyp-Wörter in den generierten Persönlichkeiten wirklich nur die Wörter "groß" und "sportlich" sind.</sample>
    <sample id="1445">Also wirklich nur die positiven oder zumindest nicht-negativen.</sample>
    <sample id="1446">Tatsächlich fängt dieses Lexikon viele der schädlichen Muster nicht gut ein, die wir in den früheren Folien sahen. Also werden wir stattdessen die Ergebnisse unserer Mark Words - Methode heranziehen, um zu zeigen, wie diese scheinbar positiven Wörter Stereotypen und essentielle Erzählungen fördern.</sample>
    <sample id="1447">In unserer Analyse entdecken wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln.</sample>
    <sample id="1448">Die wichtigsten Wörter in den ersten vier Gruppen sind Begriffe wie Kultur, Tradition, Stolz und Exotisch. Diese Wörter definieren diese Gruppen nur in Bezug auf ihre Identität und unterscheiden sie als anders von der weißen Norm.</sample>
    <sample id="1449">Dies trägt zu einer langen Tradition von Diskriminierung und Othering für diese Gruppen bei.</sample>
    <sample id="1450">Darüber hinaus sind in diesen Worten viele gemeinsame Trope reflektiert, insbesondere für farbige Frauen. Zum Beispiel enthalten die Wörter, die Latina-Frauen beschreiben, Dinge wie "vibrant" und "curvaceous".</sample>
    <sample id="1451">Welche Connect - to - a - Tropen für asiatische Frauen sind? Die Wörter sind Dinge wie "klein", "zart" und "seidig".</sample>
    <sample id="1452">Welches verbindet sich mit einer langen Geschichte asiatischer Frauen, die hypersexualisiert werden, als sehr gehorsam und unterwürfig angesehen werden und so weiter?</sample>
    <sample id="1453">Und schließlich für schwarze Frauen sehen wir, dass einige der wichtigsten Wörter Dinge wie stark und widerstandsfähig sind.</sample>
    <sample id="1454">Dies verbindet sich mit einem Archetyp, den Menschen als die starke schwarze Frau bezeichnet haben, und obwohl es auf den ersten Blick positiv klingt.</sample>
    <sample id="1455">Es gibt Arbeiten, die zeigen, dass diese Art von Archetyp sehr schädlich ist, weil sie diesen Demographen viel Druck aufbaut, um gegen gesellschaftliche Hindernisse resistent und stark zu sein.</sample>
    <sample id="1456">Also anstatt sich tatsächlich auf die Überwindung dieser Hindernisse zu konzentrieren, legt es Druck auf diese Menschen, sie zu überwinden, was zu sehr negativen Gesundheitsfolgen für diese Menschen und anderen Schäden führt.</sample>
    <sample id="1457">Im weitern Sinne stellen wir fest, dass die Wörter für jede markierte Gruppe weitgehend nur sehr essenzialisierende Erzählungen widerspiegeln.</sample>
    <sample id="1458">Also aufgrund dieser Muster können wir drei Empfehlungen für Modellbesitzer ziehen.</sample>
    <sample id="1459">Als Forscher sollten wir zuerst positive Stereotypen und essentielle Erzählungen bekämpfen. Wir sollten auch einen intersektionalen Blickwinkel bei der Untersuchung von Verzerrungen und Schäden einnehmen, da es viele Dinge gibt, die wir übersehen könnten, wenn wir das nicht tun.</sample>
    <sample id="1460">Und schließlich sollte es wirklich mehr Transparenz bei den Methoden zur Beseitigung von Verzerrungen geben.</sample>
    <sample id="1461">Weil, zum Beispiel, wie diese positiven Stereotypen. Wir wissen nicht, ob es daran liegt, dass es irgendeine Art von seltsamen.</sample>
    <sample id="1462">Übermäßige Wertausrichtung oder vielleicht andere anti-stereotypische Methoden, die zu diesen schädlichen Mustern führen.</sample>
    <sample id="1463">Wir können keine Annahmen treffen oder weiterhin darauf eingehen, ohne mehr Transparenz.</sample>
    <sample id="1464">Vielen Dank fürs Zuhören. Haben Sie eine gute Zeit.</sample>
    <sample id="1465">Hallo alle zusammen， mein Name ist Jin Wei Yi von der University of Science and Technology of China.</sample>
    <sample id="1466">Es ist mir eine Freude, einen kurzen Werbevideo über Papier zu erstellen. Wirst du mein Modell kopieren? Schützen Sie das Urheberrecht großer Sprachmodelle für Einfassungs- und Dienstleistungen. Video-Backdoor-Wasserzeichen.</sample>
    <sample id="1467">Lass uns zuerst die Hintergrundinformationen über Embedding - Dienste vorstellen.</sample>
    <sample id="1468">Derzeit sind große Sprachmodelle wie GPT, Llama, Pile außergewöhnlich in der Verständnis- und Generierungsfähigkeit natürlicher Sprache.</sample>
    <sample id="1469">Einschreibende AI-Dienste sind eine der Dienste, die auf großen Sprachmodellen aufgebaut sind, um verschiedene NLP-Aufgaben zu unterstützen.</sample>
    <sample id="1470">Zum Beispiel bietet OpenAI eine API zur Einbettung von GPT.</sample>
    <sample id="1471">Allerdings haben jüngste Arbeiten gezeigt, dass der Angreifer das Modell durch das Lernen aus der Embedding stehlen kann und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht des Embeddings als Dienst zu schützen.</sample>
    <sample id="1472">Um das Urheberrecht von Embedding-Ad-Diensten zu schützen, ist eines der Lösungen, einen Wasserzeichen in den Dienst des Anbieters zu verarbeiten und zu überprüfen, ob ein anderer Dienst das Wasserzeichen enthält.</sample>
    <sample id="1473">Der Wasserzeichenverfahren muss folgende Eigenschaften erfüllen: Erstens, das Verfahren sollte für die Versteckung von Dienstleistungen geeignet sein. Zweitens, das Wasserzeichen sollte die Nutzbarkeit der bereitgestellten Dienstleistungen nicht beeinträchtigen.</sample>
    <sample id="1474">Drittens sollte das Wasserzeichen genug verdeckt sein, dass der Angreifer es nicht leicht entfernen kann.</sample>
    <sample id="1475">Schließlich muss der Wasserzeichen während des Modell-Ausbauprozesses in die Angriffs-Service-Systeme übertragbar sein.</sample>
    <sample id="1476">Bestehende Arbeiten können grob in vier Kategorien unterteilt werden.</sample>
    <sample id="1477">Allerdings ist diese Methode entweder nicht für die Einbettung von Werbeinhalten geeignet oder fehlt es an Übertragbarkeit.</sample>
    <sample id="1478">Daher schlagen wir in diesem Papier Embedding Marker vor, was ein backdoor-basierter Wasserzeichenverfahren ist, das für die Versteckung von Air Services geeignet ist.</sample>
    <sample id="1479">Dann lass mich die Details unseres Embedding Marker vorstellen. Embedding Marker enthält zwei Hauptschritte: Wasserzeichen-Einbettung und Urheberrechtsverifizierung.</sample>
    <sample id="1480">Zuerst wählen wir einen Trigger-Set aus. Das Trigger-Set ist eine Gruppe von Wörtern in einem mittleren Frequenzintervall.</sample>
    <sample id="1481">Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln kann und die Worthäufigkeit zählen kann.</sample>
    <sample id="1482">In Watermark Injection wird zuerst ein Ziel-Embedding definiert. Wenn ein Benutzer einen Satz an den Dienst des Anbieters sendet, zählt der Anbieter die Trigger-Zahl im Satz.</sample>
    <sample id="1483">Die bereitgestellte Embedding ist eine gewichtete Summe der Ziel-Embedding und der Original-Embedding.</sample>
    <sample id="1484">Die Gewichtung der Ziel-Embedding ist proportional zur Anzahl der Auslöser in dem Satz. Wenn die Anzahl der Auslöser in dem Satz größer als m ist, ist die bereitgestellte Embedding genau gleich der Ziel-Embedding.</sample>
    <sample id="1485">Urheberrechtsverifizierung ist die Erkennung, ob ein Modell hinter einem anderen Dienst den Wasserzeichen enthält.</sample>
    <sample id="1486">Wir erstellen zuerst einen Backdoor-Datensatz und einen harmlosen Datensatz. Der Backdoor-Datensatz enthält Sätze, deren Wörter alle dem Trigger-Set angehören. Alle Wörter in den Sätzen des harmlosen Datensatzes gehören nicht dem Trigger-Set an.</sample>
    <sample id="1487">Der Anbieter verlangt die Embeddings vom Stellar-Dienst mit dem Datensatz.</sample>
    <sample id="1488">Der cosin- und L2 -Ähnlichkeitswert zwischen der gewünschten Einbettung und der Ziel-Einbettung wird berechnet. Wir berechnen die Ähnlichkeitsunterschiede zwischen den benignen und den backdoor-Datensätzen, was als Δcos und ΔL2 definiert ist.</sample>
    <sample id="1489">Gleichzeitig wenden wir den KS-Test an und verwenden sein P-Wert als dritten Maßstab.</sample>
    <sample id="1490">Wir führen Experimente an vier Datensätzen durch: 20 Newsgroups, IMDb, SST-2 und Iris Spam. Wir gehen davon aus, dass der Anbieter den WikiText-Datensatz zur Worthäufigkeitszählung verwendet.</sample>
    <sample id="1491">Die Ergebnisse auf vier Datensätzen zeigen, dass unser eingebetteter Marker eine großartige Detektionsleistung aufweisen kann, während er gleichzeitig eine große Nutzen für heruntergekommene Aufgaben behält.</sample>
    <sample id="1492">Wir haben auch die Konsistenz der bereitgestellten Embedding durch die Visualisierung der Embedding von Sätzen auf vier Datensätzen überprüft. Die Legende der Figuren bedeutet die Anzahl der Trigger in jedem Satz.</sample>
    <sample id="1493">Es ist schwer, die backdoor-Embeddings von normalen Embeddings zu unterscheiden.</sample>
    <sample id="1494">Das ist alles. Danke. Willkommen, um mit uns zu diskutieren.</sample>
    <sample id="1495">ABC-Eval steht für Annotating Behaviors in Chat.</sample>
    <sample id="1496">I'm not sure. The text doesn't mention anything about the year when the performance drop between CoNLL-2003 and CoNLL++ is higher than 5 percentage points. You could try looking for more relevant information in other sources.</sample>
    <sample id="1497">Hallo, mein Name ist Vasudha und ich bin ein Computerwissenschafts-Graduiertenkandidat an der Stony Brook University. Ich möchte meine Arbeit, die in ACL 2023 als Langtextpapier akzeptiert wurde, präsentieren: "Transfer Learning for Dissonance Detection: Addressing the Rare Class Challenge".</sample>
    <sample id="1498">Wir beginnen damit, kognitive Dissonanz zu definieren und warum es ein wichtiges Problem ist, in der Sprache zu untersuchen. Einfach gesagt, kognitive Dissonanz ist, wenn zwei Überzeugungen oder Handlungen inkonsistent sind.</sample>
    <sample id="1499">So, for example, if someone says "Ich weiß, dass Zigaretten mich töten können" and then goes on to say "Ich habe nach dem Meeting ein paar Zigaretten geraucht", diese Überzeugung und Handlung sind inkonsistent und in Widerspruch zueinander.</sample>
    <sample id="1500">Ich denke nicht, dass ich ohne sie meinen Job behalten könnte. Und sie haben eine Konsonanz-Beziehung.</sample>
    <sample id="1501">Während Widersprüche in der täglichen Entscheidungsfindung sehr häufig sind, sind sie in Sprache unter anderen Arten von Diskursbeziehungen selten zu finden.</sample>
    <sample id="1502">Die Erforschung kognitiver Distanz kann uns dabei helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen zu verstehen, Trends in Glaubenswerten und Einstellungsänderungen in der Bevölkerung zu verfolgen.</sample>
    <sample id="1503">Hohe kognitive Dissonanz ist auch mit Angststörungen verbunden und kann das Verständnis von Menschen im Bereich der psychischen Gesundheit verbessern.</sample>
    <sample id="1504">Die Studie von Diskrepanzen in der Sprache kann auch bei der Verständigung von Extremismus und der Polarisierung gefährdeter Gruppen von Nutzen sein.</sample>
    <sample id="1505">Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und hilft uns dabei, die Entscheidungsprozesse besser zu verstehen.</sample>
    <sample id="1506">Um ein Ressourcenangebot für kognitive Dissonanz zu schaffen, haben wir eine groß angelegte Annotation von Dissonanzbeziehungen durchgeführt. Wir haben die Dissonanz-First-Ansatz verwendet, wie im Flussdiagramm hier zu sehen ist.</sample>
    <sample id="1507">Tweets wurden mit einem API geparsed und Paare von Diskurs-Einheiten wurden gemäß den in unserer Arbeit beschriebenen Richtlinien annotiert.</sample>
    <sample id="1508">Es ist zu sehen, dass Dissonanz nur in 3,5% der annotierten Paare vorkam.</sample>
    <sample id="1509">Beim Sammeln von etwa tausend Beispielen für Diskurs-Einheit-Paare haben wir einen initialen Klassifikator trainiert. Dieser wurde nur an 43 Beispielen für Diskurs-Einheiten trainiert. Nicht überraschend, der Klassifikator hat nicht viel besser als zufällig performiert.</sample>
    <sample id="1510">Angesichts der geringen Häufigkeit von Dissonanz und dem Fehlen jeglicher vorheriger solcher Datensätze, begegnen wir dem Problem der absoluten Seltenheit.</sample>
    <sample id="1511">Um dies zu bewältigen, experimentieren wir mit Kombinationen von Transfer-Lernung und Aktiv-Lernung zur Annotation, um mehr dissonante Proben in weniger Annotation-Runden zu sammeln, was die Gesamtkosten der Annotation senkt, während die Erkennung von Dissonanz verbessert wird.</sample>
    <sample id="1512">Da das ursprüngliche Modell die Dissonanzklasse überhaupt nicht erfassen konnte, beginnen wir das Active Learning -Verfahren, indem wir Gewichte von eng verwandten Aufgaben übertragen.</sample>
    <sample id="1513">Wir übertragen von zwei verschiedenen Aufgaben. Themaunabhängige Distanzstanz-Klassifikation ist eine Aufgabe, die bestimmt, ob zwei Debatte-Aussagen von verschiedenen Personen in Übereinstimmung oder in Widerspruch zueinander stehen, unabhängig vom Thema.</sample>
    <sample id="1514">Hier eine Debatte über die binäre Klassifikation von Erweiterung und Vergleichsklassen von Punkttypen, da diese beiden eng mit der Konzeption von Konsonanz und Dissonanz verbunden sind, und wir sie hier als CEE bezeichnen.</sample>
    <sample id="1515">Wir stellen fest, dass die Zero-Shot-Performance auf dem annotierten Datensatz bereits viel besser ist als Zufall mit dem besten AUC von 0,62.</sample>
    <sample id="1516">Weiterhin bei iterativer Feinarbeit an beiden Aufgaben finden wir, dass das Feinabstufen der CE-Aufgabe gefolgt von weiterem Feinabstufen der DEBATE eine viel bessere Null-Shot-Leistung ergibt. Daher ist dies das Modell, das wir zur Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-Ko-K</sample>
    <sample id="1517">Nächster Schritt: Wir bestimmen die beste Methode, um ein Modell mit neuer Daten aus jeder Runde des aktiven Lernens und Annotationen zu aktualisieren. Kummulative sammelt alle Daten, die bisher aus aktiven Annotationen gesammelt wurden. Iterative aktualisiert das Modell, indem es mit dem neuesten Datensatz, der gesammelt wurde, trainiert.</sample>
    <sample id="1518">Unter den verschiedenen Strategien haben wir herausgefunden, dass das Akkumulator-Verfahren gleich oder besser als das Iterative-Verfahren in allen Bereichen funktioniert.</sample>
    <sample id="1519">Um die Anzahl der Dissonanzbeispiele zu verbessern, verwenden wir die Strategie der Wahrscheinlichkeit seltener Klasse, PRC, um hauptsächlich die Beispiele auszuwählen, die mit hoher Wahrscheinlichkeit von der aktuellen Modellierung in jedem Runde des Lernens als Dissonanz bezeichnet werden.</sample>
    <sample id="1520">Wir vergleichen dies mit anderen aktuellen, modernen Strategien, die in der Gemeinschaft häufig verwendet werden.</sample>
    <sample id="1521">Wir finden, dass die vorgeschlagene PRC -Strategie besser funktioniert als andere derzeit besten Strategien, obwohl der Unterschied klein ist. Beachten Sie, dass die Leistung bei zufälligen Strategien erheblich niedriger ist.</sample>
    <sample id="1522">In weiteren Runden des AL mit zwei besten Strategien haben wir die AUC für die Klassifikation verbessert auf 0,75, was die beste Leistung auf der Aufgabe bisher ist.</sample>
    <sample id="1523">Wir haben auch die Durchführbarkeit jeder Strategie für die Annotation-Qualität und die Kosten für die Annotatoren überprüft. Wir stellen fest, dass PRC den höchsten Prozentsatz von Dissonanz hat und am besten für seltene Klassen funktioniert. Allerdings finden die Annotatoren die Beispiele auch schwierig.</sample>
    <sample id="1524">Wir finden, dass PRC eine einfache AI - Strategie für die Erwerbung seltener Klassen ist und das Co - Starten von AI mit angemessen gestalteten Transfer - Lernaufgaben hilft erheblich.</sample>
    <sample id="1525">Wir finden auch, dass iterative Updates nützlich sind für Transfer Learning aus einem anderen Bereich, während in-domänige aktive Annotierungen von kumulativen Updates profitieren.</sample>
    <sample id="1526">Hier sind die Links zu unserem Code-Datensatz und unserem Papier. Fühlen Sie sich frei, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank.</sample>
    <sample id="1527">Ich habe leider keine Informationen über die Universität, an der die Autoren angehören. Du könntest versuchen, das in der Paper zu suchen oder mehr Kontext zu geben.</sample>
    <sample id="1528">Si Yuan.</sample>
    <sample id="1529">Fünf. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="1530">Der Ansatz wird mit der SimulST-Architektur verglichen.</sample>
  </task>
</testset>