<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind großes Skalierungs-Webkrawldaten. Politische Nachrichtenmedien sind in ihren Prätrainingsdaten gut abgedeckt.</sample>
    <sample id="1">Die Autoren gehören an die McGill University.</sample>
    <sample id="2">Das Papier von Li et al. aus der AD-Gruppe befasst sich mit dem Thema Dokumentverstehen, insbesondere mit visuell reichen Dokumenten. Es geht um das Verstehen von Formen, Rechnungen und Plakaten. Die Autoren haben eine neue Prädiktionsmethode namens LayoutMask entwickelt. Diese Methode verwendet nur Text- und Layoutinformationen und zielt darauf ab, die Text-Layout-Interaktionen und Layout-Vertretungen während der Prädiktion zu verbessern. LayoutMask unterscheidet sich von früheren Studien in drei Aspekten: der Wahl der Prädiktionsposition, der Maskierungstechnik und den Prädiktionsoberzielen. Stattdessen von globaler Prädiktionsposition wird eine lokale Prädiktionsposition verwendet, die sich auf Segmentordnungen bezieht. Diese Methode soll die globalen Lesereihenfolgen durch die Verknüpfung von 1D- und 2D-Positionen und semantischen Informationen schließen. Die Prädiktionsoberziele umfassen Maskenlängenmodellierung,</sample>
    <sample id="3">Hallo, ich bin Regina Stöten und werde Sie durch die erste Teil der Präsentation führen.Lassen Sie uns zuerst Texte definieren.Texte sind eine Art von Informationen, die in Form von Schriftzeichen oder Symbolen dargestellt werden. Sie können aus Wörtern, Zahlen, Zeichen oder Symbolen bestehen.Texte können in verschiedenen Formen und für verschiedene Zwecke verwendet werden. Sie können in Form von Büchern, Zeitungen, Zeitschriften, Dokumenten, E - Mailen, Webseiten, Videos, Audiodateien usw. erscheinen.Texte können auch in verschiedenen Sprachen geschrieben werden. Sie können in deutscher, englischer, französischer, spanischer, italienischer, russischer, chinesischer, japanischer, koreanischer, arabischer, hebräischer und vielen anderen Sprachen geschrieben werden.Texte können auch in verschiedenen Formaten gespeichert werden. Sie können in Form von Textdateien, PDF - Dateien, HTML - Dateien, XML - Dateien, JSON - Dateien usw. gespeichert werden.Texte können auch in verschiedenen Kontexten verwendet werden</sample>
    <sample id="4">Coyote.</sample>
    <sample id="5">The model used to achieve the accuracy of 82-87% is not mentioned in the text.</sample>
    <sample id="6">John presents their work on unifying multilingual and cross - lingual summarization. They unify various summarization tasks into a many - to - many setting. This model can summarize a document in any source language and generate a summary in any target language. They conduct preliminary studies and find that many - to - many summarization helps transfer task knowledge better across languages. They propose a pre - training method for the model. They compare multilingual, cross - lingual and their many - to - many summarization. Their model outperforms others in experiments. They also conduct ablation studies and human studies to show the effectiveness of their work. So, it's a great work on summarization. If you want to know more about it, you can check out their paper.</sample>
    <sample id="7">Yes, they still work.</sample>
    <sample id="8">Die neuere menschliche Bewertungsmethode ist ABC eval. Es versucht, die Subjektivität menschlicher Bewertung zu reduzieren, indem es explizit annotiert, ob bestimmte Modelleigenschaften in den Modellantworten vorkommen.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Anzahl der sauberen Validierungssamples ab. Je mehr saubere Samples vorhanden sind, desto besser leistet der Ansatz.</sample>
    <sample id="10">Das ist eine interessante Frage. Es gibt verschiedene Möglichkeiten, das Ergebnis zu verbessern. Zum Beispiel könnte man mehr Anwenderfeedback einholen, um die Anpassungen besser zu verstehen. Oder man könnte zusätzliche Tests durchführen, um sicherzustellen, dass das System in verschiedenen Situationen funktioniert. Und man könnte auch andere Methoden ausprobieren, um die Indirektausdrücke zu generieren. Was meinst du dazu?</sample>
    <sample id="11">Jack Hessel, ein Forschungs-Wissenschaftler bei AI2, präsentiert die Ergebnisse der "Do Androids Laugh at Electric Sheep" -Untersuchung, die von der New Yorker Caption Contest -Datenbasis abgeleitet wurde. Zusammen mit Kollegen aus Utah, Cornell, Washington, Airmail und OpenAI wurde untersucht, ob große Sprachmodelle Humor verstehen können. ChatGPT kann einfache Witze erzeugen und sogar erklären. Google's Palm hat bereits Witze erklärt. Allerdings ist die Frage, ob Sprachmodelle wirklich Humor verstehen, noch offen. ChatGPT hat Schwierigkeiten, Witze zu verstehen, die auf Puns basieren. Die New Yorker Caption Contest bietet eine Plattform, um die Humorverstehung von Sprachmodellen zu testen. Es gibt drei Aufgaben: Matching, Qualitätseranking und Erklärungserstellung. Die besten Modelle erreichen nur etwa 62% Genauigkeit im Matching, was weit hinter der menschlichen Leistung von 94% zurückbleibt. GPT-4 kann ohne Computer Vision nicht direkt mit Pixeln arbeiten, aber auch mit einer mens</sample>
    <sample id="12">An der Arbeit sind sechs Autoren beteiligt.</sample>
    <sample id="13">Daniel Rotem presents his work on adaptive inference in low-resource settings. Adaptive inference reduces inference time of large language models by using low-capacity models for easy samples. Two common methods are multi-model and early exit. Multi-model stores multiple models with classifiers, trained separately, and run sequentially. Early exit fits classifiers after intermediate layers, trained together, and stops computation early. Multi-model is versatile and extendable but expensive and has overhead. Early exit is faster and memory efficient but has shared parameters leading to lower performance due to conflicting gradients. The hypothesis is that conflicting gradients cause performance degradation. An illustration shows how gradients from different classifiers interfere. To test, individual early exit models were compared to separate multi-model classifiers. Multi-model classifiers outperformed early exit by 2.3% on average. The speed-accuracy trade-off was measured, showing multi-model is better for high inference speeds but early exit outperforms later. A novel method called Suite is presented, which avoids conflicting gradients by updating each transformer layer only from its following classifier. Suite closes the gap between early exit and multi-model but negatively affects later classifiers in some cases.</sample>
    <sample id="14">Hallo, mein Name ist Adam Skorupski und dieses Vortrag ist über die Abhängigkeitsstruktur der Koordination. Wie Sie wissen, gibt es verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Korpus-Ansätzen angenommen werden. Zum Beispiel in der universellen Abhängigkeit ist die Struktur der Koordination Lisa, Bart und Maggie so, dass der erste Konjunkt der Kopf der ganzen Koordinationsstruktur ist. In diesem Fall Lisa. Ein ähnlicher Ansatz wird in Igor Melchuk's "Meaning Text Theory" angenommen, wo wiederum die gesamte Koordinationsstruktur vom ersten Konjunkt geleitet wird. Diese beiden Ansätze sind symmetrisch, sie heben einen der Konjunkte hervor. Es gibt auch symmetrische Ansätze zur Koordination, wie der "Conjunction Headed Approach" in der "Prop-Dependency Treebank", wo Koordinationsstrukturen vom Konjunktionssatz geleitet werden. So erhalten wir Abhängigkeiten von "and" zu allen Konjunkten. Und schließlich gibt es auch einen multi-headed</sample>
    <sample id="15">Drei.</sample>
    <sample id="16">Bible texts werden stärker vereinfacht.</sample>
    <sample id="17">Abstract: This work introduces a method for multimodal relation extraction. It addresses internal information overutilization and external information underexploitation. A graph information bottlenecks - guided feature refinement is proposed. The multimodal topic information is considered as additional semantic supplementary. The method consists of five parts: representing text and image, merging visual and textual syngraphs into a unified backbone cross - model graph, screening the initial graph structures, enriching compressed CMG features with multimodal topic features, and evaluating on MIRE dataset. The proposed method outperforms text - based methods and other multimodal baselines.</sample>
    <sample id="18">March read this absolutely fascinating book about bees yesterday.</sample>
    <sample id="19">The work focuses on efficient open-domain question answering. It uses a two - stage model. The first stage retrieves evidence contexts from the Wikipedia corpus using a retriever with a question encoder and a document encoder. The second stage uses a reader to understand the question and retrieve evidence for reasoning. Challenges include the large size of the Wikipedia corpus, the bottleneck of searching the index file, and the need for efficient techniques due to multiple language models with millions of parameters. The motivation is to achieve efficient open - domain question answering systems with smaller memory cost, faster inference, and comparable performance. Efficient techniques include approximate nearest neighbor search for retrieval, skipping read for faster reading, and document filtering and embedding dimension compression for reducing the index file. To reduce model size, lightweight models, parameter sharing, or designing fewer models are considered. Existing models are compared in terms of data, showing that retrieval - and - reader systems balance speed, memory, and performance well.</sample>
    <sample id="20">Ja, die Modelle sind frei verfügbar und die Trainings-Skripte sind auf eurer GitHub-Repository. Also, ja, du kannst sie für deine Forschung verwenden. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="21">DEplain-apa enthält Dokumente aus News-Texten.</sample>
    <sample id="22">Ein besseres Modellarchitektur, größere Modellgröße und mehr Anpassungsbeispiele.</sample>
    <sample id="23">Dan Garrett spricht über die Verbesserung der Fähigkeit von Text-Bild-Modellen, visuelle Texte darzustellen. Text-Bild-Modellforschung hat große Fortschritte gemacht, aber viele Modelle sind schlecht darin, Text darzustellen. Das Imagine -Modell, das durch T5 -XXL -Text -Codierung und Diffusion -Modell -Eingabe funktioniert, kann komplexe Texte in Bilder umwandeln. Allerdings versagen sie bei einfacheren Text -Bild -Eingaben, die ein Wort erfordern. Die T5 -Text -Codierung mit SentencePiece -Tokenisierung ist das Problem. Sie codiert Text in Subwörter, was es schwierig macht, einzelne Buchstaben zu generieren. Experimente zeigten, dass T5 bei kleineren Skalen schlecht in der Rechtschreibung ist. PALM -Modelle haben bessere Rechtschreibfähigkeiten, aber sie sind groß und unpraktisch. ByteT5, das die Einzelbuchstaben des Eingabestrangs erhält, ist gut in der Rechtschreibung. Die</sample>
    <sample id="24">Die Tendenz wurde gemessen, indem die Längendifferenz zwischen den beiden Konjunktionen gemessen wurde.</sample>
    <sample id="25">The experiments were designed to observe how the position of the adjunct affects the coordination structure. They analyzed sentences with different adjunct positions and compared the resulting coordination structures.</sample>
    <sample id="26">Wenn ein Basisklassifikator mit unausgewogenen Daten trainiert wird, dann ist er nicht gut. Er kann nicht gut auf die Mehrheit der Klassen reagieren und seine Genauigkeit ist oft sehr niedrig.</sample>
    <sample id="27">Das ist eine Frage, die ich nicht beantworten kann, da ich den englischen Inhalt nicht verstehe. Bitte übersetzen Sie den Inhalt ins Deutsche, dann kann ich Ihnen besser helfen.</sample>
    <sample id="28">Bob und Alice.</sample>
    <sample id="29">Bei den Diskursphänomenen, die mit dem MÜ-Tagger identifiziert werden, schneiden kontextsensitive MÜ-Modelle besser ab als kontextagnostische Modelle.</sample>
    <sample id="30">Das Papier präsentiert LLM-Blender, ein einfaches aber effektives Ensemble-Learning-Framework für Large Language Models. Es basiert auf Parabase-Ranking und generativer Fusion. Die Forscher sind aus AI2 und USC. Viele Large Language Models werden regelmäßig veröffentlicht, aber nicht alle sind gleich gut. Ein Leaderboard zeigt, dass einige Modelle besser sind als andere im Durchschnitt. Allerdings kann die beste Modelle für einzelne Inputs nicht immer verwendet werden. Die Forscher haben eine zweistufige Methode namens LLM-Blender vorgeschlagen. Sie laufen verschiedene Modelle an, vergleichen ihre Outputs und wählen die besten. Dazu wird ein Parabase-Ranking-Modul verwendet, um die Modelle zu bewerten. Es gibt drei Methoden zur Aggregation der Ergebnisse, wobei die maximale Logit die beste Lösung ist. Experimente zeigen, dass Parabase-Ranking besser mit dem Oracle-Ranking korreliert als andere Methoden. Um das Ensemble-Learning-Framework zu evaluieren, wurde ein neuer Datensatz namens Mixed Instruct erstellt. Es zeigt, dass die Top-2 Modelle Open</sample>
    <sample id="31">I'm not sure which university the authors belong to. You could try looking for more information about the authors or the paper.</sample>
    <sample id="33">The framework quantifies positionalities by comparing annotations by demographic with models and datasets using a Pearson's r correlation score.</sample>
    <sample id="34">Mark Sturges präsentiert Crest, ein gemeinsames Framework für rationale Kontextgenerierung. Es kombiniert rationale Erklärungen und Kontextgenerierung. Der erste Teil generiert Kontexte, indem ein rationalisierender Modell eine rationale Erklärung produziert. Diese wird dann verwendet, um den Originalinput zu maskieren und einen positiven Goldlabel zuzuordnen. Ein Editor füllt die maskierten Bereiche mit neuen Tokens. Die Qualität von Crest wird durch Vergleich mit anderen Arbeiten und menschliche Bewertung bestimmt. Crest erzeugte Kontexte wurden als realistischer und natürlicher beurteilt. Eine interessante Anwendung ist die Datenverstärkung. Eine alternative Methode kombiniert rationale Erklärungen sowohl für Faktual als auch für Kontextgenerierung. Es gibt vier Experimente mit verschiedenen Einstellungen. Crest erreicht die beste Kürzung in der eigenen Domäne. In der Kontrast-Datenbank ist es mit menschlichen Kontexten vergleichbar. In der Auto-Datenbank übertrifft es andere Methoden. Die rationale Erklärungen von Crest sind interpretierbar. Sie werden in</sample>
    <sample id="36">Das Video ist ein Vorgeschmack auf die Lernung von Sprachspezifischen Schichten für multilingualen Maschinentranslation. Es wird von Dilem Sura Beach präsentiert und ist ein Joint - Work mit Robin Schmidt, Yishu Liao und Stefan Bartsch. Multilingualer Maschinentranslation hat Vorteile wie Skalierbarkeit, Geschwindigkeit und Verbesserungen für Sprachen mit geringem Ressourcenanteil. Allerdings hat es auch Nachteile wie begrenzte Sprachkapazität. Die Lösung, die vorgestellt wird, sind Sprachspezifische Schichten, LSLs. Diese werden in einem regulären Transformer - Layer eingesetzt und helfen, die Sprachkapazität zu steigern, wo es am wichtigsten ist, während die Inferenzkosten konstant bleiben. Die LSLs werden durch die Quelle oder das Ziel der Sprache ausgewählt. Es wird gezeigt, wie die LSLs in der Modellarchitektur platziert werden können und wie sie die Inferenzkosten senken. Die Experimente zeigen, dass die LSLs in</sample>
    <sample id="37">The result was that they were able to surface racial stereotypes.</sample>
    <sample id="38">Die Datenquellen wurden aus der Enhanced Version des Penn Treebank verwendet.</sample>
    <sample id="39">Drei.</sample>
    <sample id="40">Topic - independent dissonance stance classification und on binary classification of expansion and comparison classes of PDB.</sample>
    <sample id="41">The work introduces Peacock, a personal common sense knowledge graph for consistent and engaging narratives. It has about 3, 800 personas, 40, 000 attributes, and 100, 000 inferences. It represents real - world personas with rich world knowledge and context interconnections. The relations of personas and their attributes are framed in three dimensions. Peacock is built in three steps: selecting personas, inducing attributes, and cross - sourcing annotations. It helps language models learn and generalize personal knowledge. Compared to baselines, it achieves better automatic evaluation results and higher accept rate in human evaluation. It also improves downstream narrative modeling, like the personal - grounded dialogue generation task.</sample>
    <sample id="42">I'm not sure. The passage doesn't mention the number of authors. You could try looking for more information in the paper itself.</sample>
    <sample id="43">Ich kann das aus dem gegebenen Text nicht direkt ableiten. Es gibt aber Hinweise darauf, dass es mehrere Autoren gibt, da es um eine Arbeit geht, die in ACL 2023 als Long Paper akzeptiert wurde. Wenn du mehr Details haben möchtest, kannst du mir noch etwas mehr über die Arbeit erzählen.</sample>
    <sample id="44">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten, indem es End-Nutzer mit Modellen und Datensatzvorhersagen und -etikettierungen vergleicht, anstatt nur Annotatorenübereinstimmung oder Modellierungs-Annotatordistributionen zu betrachten.</sample>
    <sample id="45">The generated personas have the most overlaps with the lexicon of stereotypes.</sample>
    <sample id="46">Es wird nicht erwähnt, welche kommerziellen Systeme verglichen wurden.</sample>
    <sample id="47">Hallo, ich bin Zhang Bing, ein PhD-Student an der University of Washington. Heute präsentiere ich unsere Arbeit von der Vorkonditionierung von Daten bis hin zu Sprachmodellen und Downstream-Aufgaben. Wir verfolgen die Spuren politischer Biass, die zu unfairen NLP-Modellen führen. Sprachmodelle werden an großem Skalendaten aus dem Web trainiert. Politische Nachrichtenmedien sind in ihren Vorkonditionierungsdaten gut abgedeckt. Laut einer Umfrage des C4-Korpus können wir sehen, dass New York Times, Los Angeles Times, The Guardian, Huffington Post usw. in den Sprachmodelltrainingsdaten gut abgedeckt sind. Dies hat für Sprachmodellanwendungen ein gemischtes Segen geschaffen. So haben sie auf der einen Seite die Möglichkeit, aus verschiedenen Perspektiven zu lernen, was die Demokratie und die Vielfalt von Ideen feiert. Auf der anderen Seite sind diese verschiedenen politischen Meinungen von Natur aus sozial voreingenommen und können potenzielle Fairnessprobleme in Downstream-Aufgabenan</sample>
    <sample id="48">The paper is a joint work with the author's colleagues from Google Translate. So there are at least two authors, the author and his colleagues. But the exact number of colleagues is not mentioned.</sample>
    <sample id="49">Bis zu 1024 Token Kontextlänge wurden MPP-Auswertungen durchgeführt.</sample>
    <sample id="50">Der Vortrag geht um die Präsentation des neuen Korpus Deep Lane für die deutsche Texteinfachung auf Dokument- und Satzebene. Regina Stönn führt durch. Texteinfachung ist das Anpassen von Texten, um die Verständlichkeit für bestimmte Zielgruppen zu verbessern. Es werden parallelisierte Textpaare benötigt, wie zum Beispiel Dokumente oder Sätze. Ein Beispiel zeigt ein parallelisiertes Sattpaar eines komplexen deutschen Satzes und seiner Einfachung. Es gibt verschiedene Techniken zur Einfachung, wie lexikalische Substitution, Klammerauslassung, Klammerentfernung, Reordering und Worteingabe.Die Präsentanten stellen ihren neuen Korpus Deep Lane vor, da bisherige Korpora zu klein waren oder automatisch ausgerichtet waren, was zu fehlerhaften Ausrichtungen führen konnte. Deep Lane ist in zwei Unterkorpora unterteilt: Deep Lane APA und Deep Lane Web. Deep Lane APA basiert auf News-Texten und wurde manuell ausgerichtet, was zu etwa 30.000 parallelen Sattpaaren führt.</sample>
    <sample id="51">Sie haben drei Domains aufgenommen: Musik, Bücher und Rezepte.</sample>
    <sample id="52">Positionalität ist die Perspektive, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben.</sample>
    <sample id="53">The speaker's name is Dawei.</sample>
    <sample id="54">Abstract: This paper presents a study on cognitive dissonance detection in language. It defines cognitive dissonance as inconsistent beliefs or actions, like a person knowing cigarettes are harmful but still smoking. The study aims to understand the effects of disagreement, track trends in beliefs, and relate high dissonance to mental health issues. A large - scale annotation of dissonance relations was conducted using a dissonance - first approach. However, due to the rarity of dissonance, transfer learning and active learning were employed to improve detection. Transfer learning from related tasks like topic - independent dissonance classification and binary classification of expansion and comparison classes of PDB was used. Active learning strategies, including cumulative and iterative updates, were compared. The proposed probability of rare class strategy, PRC, was found to be more effective than other state - of - the - art strategies. This work contributes to understanding cognitive dissonance in language and its implications for mental health and extremism.</sample>
    <sample id="55">Ja.</sample>
    <sample id="56">Nur ein Autor, John, ist an der Arbeit beteiligt.</sample>
    <sample id="57">Ja, das getestete Modell funktioniert in der Testsuite.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind: 1) The typical setting, 2) The background both setting, 3) The background inference setting.</sample>
    <sample id="59">The presentation introduces Dr. Bert, a robust pre-trained model in French for biomedical and clinical domains. It starts with language modeling in healthcare, then presents the main contributions. Dr. Bert is based on Roberta and trained on Nachos, a dataset of medical crawled data. A comparison of Dr. Bert with multiple pre-training settings and data sources is made. Results on 11 biomedical and clinical downstream tasks in French are shown. The experiments conclude that Dr. Bert performs best on tasks with data of the same nature as the model's training data. More data leads to better performance. From-scratch pre-training seems to yield higher performance on most tasks. However, the model based on Camembert weights and tokenizer suffers from stability issues. The proposed system outperforms the generated model Camembert on 9 out of 11 downstream tasks. Specialized data is better but doesn't scale well. The pre-trained models are freely available on the Hugging Face interface, and training scripts are on their GitHub repository.</sample>
    <sample id="60">Ich habe leider keine Informationen über die Universität der Autoren. Du könntest versuchen, das im Originaltext zu suchen oder weitere Informationen zu suchen.</sample>
    <sample id="61">Die abschließende Forschungsfrage ist: Sollten wir nur die sauberen Samples für die Validierung verwenden oder gibt es bessere Wege, sie zu nutzen?</sample>
    <sample id="62">Das Papier von Intaka de On und Kollegen ist eine systematische Studie zur Wissensverdichtung für NLG mit Pseudotarget - Training. Es geht um die Kompression großer NLG - Modelle, die teuer und langsam sind. Das Hauptziel ist, die Modelle zu komprimieren, ohne ihre Leistung zu verlieren. Sie untersuchen verschiedene Kompressionsmethoden wie Püren und Wissensverdichtung. Es gibt zwei Hauptarten von Wissensverdichtung: Wort - und Sequenz - Niveau. Im Gegensatz zu anderen Arbeiten, die sich auf Klassifikation oder Prädikationsaufgaben konzentrieren, untersuchen sie verschiedene NLG - Aufgaben in realistischen Szenarien. Sie verwenden mittelgroße Datensätze, viel unlabeled Daten und praktische Modelle. Die Studie umfasst vier Aufgaben: Zusammenfassung, Frage - Erstellung, Konsens - und Vereinfachung. Sie testen verschiedene Ansätze für Wissensverdichtung und zeigen, dass unlabeled Daten und mehrere Pseudotargets die Leistung verbessern.</sample>
    <sample id="63">Die Sensitivitätsmetrik misst die Fähigkeit des Modells, konstante Ausgaben für dieselbe Aufgabe zu produzieren, unabhängig von leichten Variationen in der Formulierung der Anweisung.</sample>
    <sample id="64">Jin Wei Yi.</sample>
    <sample id="65">Eine höhere Sensitivität bedeutet nicht immer eine bessere Leistung des Modells. Es kann auch zu einer geringeren Leistung führen.</sample>
    <sample id="66">Mathematical reasoning is crucial for human intelligence. It involves comprehending and making decisions based on numeric data and language. Deep learning methods are being developed to solve math problems and prove theorems. Tasks include math word problems with single or multiple operations, and extending to mathematical information like images, figures, and tables. Two primary categories are visual contexts and table contexts. Solving geometry problems is a high school education subject. It involves identifying geometric relations, applying theorem knowledge, and performing calculations. This can be formalized as a neuro - symbolic reasoning problem over geometric diagrams, theorems, and solvers. Another important line is automatic theorem proving. Some datasets have been proposed to test the human - level intelligence of language models. Various neural network architectures have been proposed for mathematical reasoning tasks. For example, a second - to - sixth model uses an encoder - decoder architecture. Mathematical expressions can be represented as tree - based structures. Pre - trained language models like large - scale language models, LLMs, have shown remarkable performance on various NLP tasks. They can be applied to solve math word problems. However, they lack the ability to perform precise mathematical reasoning. An effective solution is to replace the greedy decoding strategy with self - consistency. Another approach is to design tool</sample>
    <sample id="67">Interferenz in multilingualen Übersetzungsmodellen kann Synergie oder negative Auswirkungen haben. Bei kleinen Modellen ist Interferenz stark, aber mit zunehmendem Modell - und Datensatz - Maßstab verschwindet sie. Die wichtigste Rolle spielt die Temperatur - Abstimmung. Bei einfachen monolingualen Fällen gibt es Skalierungsgesetze für Modell - und Datensatz - Größen, die das Verlustverhalten vorhersagen können. Im multilingualen Fall ist es komplizierter, da andere Faktoren wie Datensatz - Größen anderer Sprachen, Sprachähnlichkeit und Anzahl der Sprachen beeinflussen können. Es zeigt sich, dass Sprachähnlichkeit und Anzahl der Sprachen nicht großen Einfluss haben. Interferenz wird definiert als das Verhältnis der Verluste eines bilingualen und eines multilingualen Modells. Bei der Verwendung von vier Transformer - Varianten und 15 WMT - Sprachen wird gezeigt, dass die Modell - und Datensatz - Größen die Interfer</sample>
    <sample id="68">Nicht bekannt.</sample>
    <sample id="69">Typically, we only need 20 samples per class to attain high performance.</sample>
    <sample id="70">Ich habe leider keine Informationen über die Universität der Autoren. Kannst du mir mehr dazu sagen?</sample>
    <sample id="71">The work focuses on resolving indirect referring expressions for entity selection. The researchers introduced the "alt entities corpus" to better understand users' language when making choices. They discuss the importance of indirect references, like "the newer one" or "the song that's not energetic, " especially when users can't remember names or when pronunciations are similar. There's no large public dataset for this task, so they collected one using crowd annotation. The dataset covers music, books, and recipes. It uses a cartoon completion setup with three speech bubbles. The first bubble sets the dialogue context, the second presents an alternative question, and the third uses an indirect reference to select an entity. The first and second bubbles are automatically generated, while the third is filled in by the annotator. Different sampling methods are used to make the entities more similar, making disambiguation harder. Annotators are shown background knowledge about the entities, like Google search links for songs or Wikipedia text for recipes and books. They then pick an entity and describe it using indirect referring expressions. This corpus is important for understanding and benchmarking entity understanding in conversational systems.</sample>
    <sample id="72">Weil die bestehenden Methoden nicht ausreichen, um die Medienverzerrungen in den neuen Medien zu messen.</sample>
    <sample id="73">The referent is Makshita.</sample>
    <sample id="74">The paper introduces Dens atomic, a knowledge graph with high logic coverage and massive multi-hop paths. It compares Dens atomic to Atomic, highlighting that Dens atomic has more multi-hop paths and completes missing links in Atomic. The construction of Dens atomic involves normalizing tail events, training a relation prediction model, and constructing Dens atomic. The traditional method for completion of Atomic has limitations like sparse graph structure and difficulty in propagating information. To address these, the paper proposes Realistic KGC, which predicts relations given head and tail events. Realistic KGC utilizes no graph structure information and takes advantage of semantic information. It also employs an inter - cluster completion strategy. The paper evaluates Realistic KGC on constructed Dens atomic, showing higher logic coverage and better performance in relation prediction and multi-hop path accuracy.</sample>
    <sample id="75">Sure. The motivation for the work is to address the challenges of fully supervised models requiring extensive labor for high - quality data annotation and the need for diverse annotated data for various domains and applications. Semi - supervised learning can use a small amount of labeled data to obtain powerful models at a lower cost. However, current studies neglect the interconnections between NER and RE tasks. The proposed joint semi - supervised learning framework models NER and RE tasks by propagating labels over heterogeneous graphs and considering inter - connections among both labeled and unlabeled data. It consists of four parts: span feature generation, heterogeneous graph construction, joint label propagation, and model optimization.</sample>
    <sample id="76">The pipeline for the propagation of political biases includes pretraining data, language models, and downstream tasks.</sample>
    <sample id="77">This video shares work on improving summarization factual consistency from natural language feedback. It's a joint effort from Yale University and Microsoft Research. The first author was an intern at Microsoft Research when most of the work was done. A new dataset called DeFacto is introduced, containing human demonstrations and feedback for improving summarization factual consistency. Comprehensive analysis is provided, and three new NLP tasks are proposed: summary editing, feedback generation, and automatic factual error correction. The focus is on abstractive text summarization, specifically studying factual consistency of summarization models. Human demonstrations and feedback are based on system-generated summaries. Annotators label summaries for factual consistency and provide corrected summaries and feedback. Data is collected on the XSum dataset. Around 2.5k data points are annotated, 70% containing factual errors. Human-edited summaries receive higher automatic factual scores but have lower textural overlap with reference summaries. The first task studied is summary editing, where models follow human feedback. Both fine - tuned and zero - shot large language models effectively leverage human feedback. The second task is feedback generation, which remains challenging for both fine - tuned and large language models. The third task is automatically correcting factual errors while generating explanations.</sample>
    <sample id="78">Ja, es gibt Unterschiede. In DEplain-apa gibt es mehr Reorderings und Wort-Additionen, während in Web mehr Rephrasings vorkommen.</sample>
    <sample id="79">Ja.</sample>
    <sample id="80">In Watermark Injection wird zuerst ein Target Embedding definiert. Wenn ein Nutzer einen Satz an den Provider-Service sendet, zählt der Provider die Trigger in dem Satz. Der bereitgestellte Embedding ist eine Gewichtssumme aus dem Target Embedding und dem ursprünglichen Embedding. Der Gewichtswert des Target Embeddings ist proportional zur Anzahl der Trigger im Satz. Wenn die Anzahl der Trigger im Satz größer als m ist, ist der bereitgestellte Embedding genau gleich dem Target Embedding.</sample>
    <sample id="81">The authors are from Penn State University.</sample>
    <sample id="82">Das Video geht über eine Arbeit zur automatischen Aufsatzbewertung, AES. Es gibt zwei Ansätze, die bisher vorgeschlagen wurden. Der erste von Chen et al. 2010 nutzt die Anzahl einzigartiger Wörter als Anfangsbeurteilung und verbreitet diese dann iterativ. Der zweite von Zhang und Li 2021 verwendet die Wortanzahl als schwache Supervision. Beide haben jedoch Probleme mit der Leistung. Die Autoren dieser Arbeit sind inspiriert davon, dass eine einzige Qualitätssignal nicht ausreicht, um die Aufsatzqualität vollständig zu beschreiben. Sie schlagen einen neuen Ansatz vor, der mehrere Heuristische Qualitätssignale als Pseudo-Grundwahrheiten verwendet und dann ein neuronales AES-Modell trainiert, das von der Aggregation dieser Signale lernt. Dieser Ansatz, URA, enthält einen Heuristischen Aufsatz-Ranking-Modul, HER, das Partial-Ordnungs-Paare generiert, und ein tiefes Paarweises-Ranking-Aggregations-Modul, DPR,</sample>
    <sample id="83">Ja, Encoder-Decoder-Modelle wie MT5 können durch Training mit einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="84">The speaker, Xia He, introduces his paper at ACL 2023 about a framework for dynamic networks. He explains that traditional networks are static, while dynamic networks can change architecture or parameters based on input. Examples include mixture of experts and dynamic convolution. Implementing dynamic networks is easy, just replacing static layers. However, existing dynamic networks are often fully dynamic, leading to excessive parameter use. The speaker's hypothesis is that a partly dynamic network with partially dynamic subnetworks can maintain the power of the original network. He built a framework called PANDA, partitioning parameters into dynamic and static. The method used is additive mode partitioning. Experiments show PANDA outperforms static and fully dynamic networks while maintaining fewer parameters and less computation. Omission studies found optimal dynamic ratios for dynamic convolution and mixture of experts. Scale factors for dynamic and static parameters are important, and their sum constraint affects accuracy.</sample>
    <sample id="85">Make a chocolate cake.</sample>
    <sample id="86">They ensure the opaqueness of their method by making the watermark covert enough to the attacker, so the attacker can't easily remove it.</sample>
    <sample id="87">The work uses existing PLMs as a base and then fine-tunes them on specific biomedical and clinical datasets. This approach helps in building a new PLM that is more suitable for these domains. If you want to know more about the specific datasets or the fine-tuning process, feel free to ask.</sample>
    <sample id="88">GPT-4 ist am wenigsten auf Indien ausgerichtet.</sample>
    <sample id="89">Im Beispiel wird gezeigt, dass wenn ein Satz wie "I'm going to talk about" erhalten wird und das Modell die Übersetzung in Deutsch vorhersagt, die ersten zwei Wörter auf die ersten erhaltenen Sprachrahmen zeigen, während das letzte Wort auf die letzten erhaltenen Sprachrahmen zeigt. Das bedeutet, dass die ersten zwei Wörter ausgelassen werden, da die Summe der Quer-Aufmerksamkeitsgewichte unter einem bestimmten Schwellwert alpha liegt.</sample>
    <sample id="90">Das Papier von Han Liu und anderen untersucht, ob Sprachlernende als Annotatoren für Daten in der NLP eingesetzt werden können. Sie haben eine Studie durchgeführt, in der sie Sprachlernende in verschiedene Sprachniveaus unterteilten und mit Native-Sprechern verglichen. Die Ergebnisse zeigen, dass die Annotierungen von Lernenden nahezu genauso genau sind wie die von Native-Sprechern, insbesondere für einfache Aufgaben. Wenn die Annotierungen von Lernenden durch Mehrheitsentscheidung aggregiert werden, sind sie fast mit denen von Native-Sprechern gleichwertig. Zudem haben Sprachlernende durch das Annotieren ihre Sprachkenntnisse verbessert. Das Papier schlägt also eine neue Möglichkeit für Datenkonstruktion vor, indem Sprachlernende als Annotatoren eingesetzt werden. Es bietet die Möglichkeit, NLP - Forschung für viele Sprachen zu erweitern, auch für Sprachen mit schwierig zu findenden Native-Sprechern.</sample>
    <sample id="91">Als die Anzahl der Aufgaben zunimmt, erreicht das Modell bessere Leistung und gleichzeitig eine niedrigere Sensitivität.</sample>
    <sample id="92">I'm not sure which paper you're referring to. Could you provide more details?</sample>
    <sample id="93">The two co-authors are the advisors of the first author.</sample>
    <sample id="94">The speaker, Jingwei Yi from the University of Science and Technology of China, is giving a short advertisement video about a paper. The paper discusses protecting the copyright of large language model embedding services. It introduces the background of embedding services, which are built on large language models like GPT, Llama, and Palm for various NLP tasks. However, there are risks of attackers stealing the model through learning from the embedding. To protect the copyright, a backdoor watermark method called Embedding Marker is proposed. It has two main steps: watermark injection and copyright verification. In watermark injection, a trigger set is selected, and the provided embedding is a weighted sum of the target embedding and the original embedding. Copyright verification uses a backdoor and benign dataset to detect if the model contains the watermark. Experiments on four datasets show good detection performance while maintaining utility for downstream tasks. The provided embedding is also visually validated as covert.</sample>
    <sample id="95">I will add ist der erste Autor von PaLM.</sample>
    <sample id="96">Hallo, ich bin Jenny, ein erstsemestler Masterstudent an der Carnegie Mellon University. Heute werde ich über meine Arbeit "Analyse der Positionalität: Charakterisierung von Designbiass in Datensätzen und Modellen" präsentieren. Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten von der University of Washington und dem Allen Institute for AI durchgeführt, insbesondere Sebastian Santi, Ronan Le Bras, Katerina Rineke und Martin Zap. Lass uns damit beginnen, dass du dir vorstellst, dass du für eine Zeitung arbeitest und durch die Kommentare unter deinem Nachrichtenartikel schürst, um giftige Inhalte zu entfernen. Du könntest auf eine beliebte API wie den Perspective API für Giftigkeitserkennung zurückgreifen. Dies funktioniert wirklich gut, wenn du Carl Jones bist, wo der Perspective API korrekt giftige Instanzen erkennen kann. Aber das ist nicht der Fall für Dipti Sharma, wo der Perspective API nicht so empfindlich auf offensive Begriffe ist, die in indischen Kontexten häufiger vorkommen. Dies ist ein Beispiel für einen Designbias, bei dem wir system</sample>
    <sample id="97">Die Referentin geht auf zwei Probleme von SimulST ein.</sample>
    <sample id="98">Das ist eine komplexe Frage. Eine Möglichkeit könnte sein, dass man versucht, Daten aus verschiedenen Quellen zu sammeln, um eine breitere Perspektive zu haben. Aber es gibt auch Herausforderungen, wie z.B. dass manche Quellen möglicherweise noch immer politisch verzerrt sind. Es gibt keine einfache Lösung dafür. Wenn du mehr über spezifische Ansätze oder Studien in diesem Bereich erfahren möchtest, lass es mich wissen.</sample>
    <sample id="99">Hallo, ich bin Si Yuan von der Fudan University. Ich bin hier, um unsere Arbeit vorzustellen: "Script-Kenntnisse von großen Sprachmodellen für beschränkte Sprachplanung". In unserem Alltag planen Menschen ihre Handlungen oft nach Schritt-für-Schritt-Anweisungen in Form von Skripten. Vorige Arbeiten haben die Nutzung großer Sprachmodelle für die Planung abstrakter Ziele von stereotypischen Aktivitäten, wie das Backen eines Kuchens, untersucht und gezeigt, dass große Sprachmodelle effektiv Ziele in Schritte zerlegen können. Allerdings haben frühere Arbeiten hauptsächlich auf die Planung abstrakter Ziele von stereotypischen Aktivitäten fokussiert. Die Planung spezifischer Ziele mit spezifischen Beschränkungen, wie das Backen eines Schokoladenkuchens, bleibt noch unerforscht.In dieser Arbeit definieren wir das Problem der beschränkten Sprachplanung, bei dem verschiedene Beschränkungen auf die Ziele der Planung auferlegt werden</sample>
    <sample id="100">Multi-hop QA involves answering questions that require multiple reasoning steps. Each step corresponds to a document. For example, to find a 1988 Christmas comedy film Brian Doyle-Murray starred in, first find all his movies, then find the 1988 one. Retriever training maximizes the probability of the ground truth chain given a question. Existing systems need thousands of examples, which can be expensive, especially for low-resource domains. Our approach, PromptRank, is efficient and performs well with just 128 examples. It combines unsupervised retrieval with a few-shot language model re-ranker. First, retrieve candidate chains using TF-IDF and hyperlink traversal. Then, re-rank them using the language model. The scoring function is the likelihood of the question given the chain. We construct a chain prompt by inserting the chain documents and adding an indicator token. We also explore instruction search, instruction sampling, and temperature scaling. PromptRank outperforms fully supervised systems and is comparable to state-of-the-art multi-hop dense retrievers. Each component of PromptRank is important for its performance.</sample>
    <sample id="101">The fluency of PaLM is comparable to state-of-the-art systems.</sample>
    <sample id="102">Das Wasserzeichenverfahren muss anwendbar auf Embedding - Services sein, den Nutzen der bereitgestellten Embeddings nicht vermindern, versteckt genug für den Angreifer sein, damit dieser den Wasserzeichen nicht leicht entfernen kann und während des Modell - Extraktionsprozesses übertragbar auf die Angreiferservices sein.</sample>
    <sample id="103">The English TED Talks were translated into 14 different languages.</sample>
    <sample id="104">The text doesn't specify how many instances are extracted from a dataset for re-annotation.</sample>
    <sample id="105">The cosine and L2 similarity between the requested embedding and the target embedding are computed. We computed the similarity difference between benign and backdoor datasets, which is defined as delta cosine and delta L2.</sample>
    <sample id="106">Der englische Text beschreibt ein Forschungsprojekt namens Quest, das von Sathya und Kollegen aus Google DeepMind entwickelt wurde. Es geht um die Modellierung von Informationssuchanfragen mit mehreren Einschränkungen oder Präferenzen. Zwei Beispiele werden vorgestellt: Jane, die eine Reptilart in Costa Rica identifizieren möchte, und Austin, der nach historischen Romanen in Frankreich sucht. Quest ist ein Datensatz, der 13.000 Anfragen mit impliziten Setoperationen enthält. Die Anfragen werden von Menschen paraphrasiert und dann von Annotatoren überprüft. Der Datensatz stellt eine herausfordernde Retrievalaufgabe dar, da Systeme große Dokumente durchsuchen müssen, um mehrere Antwortsets zu finden. Die Anfragen enthalten verschiedene Kombinationen von Einschränkungen, wie Intersektionen und Differenzen von Sets. Quest wurde durch Kombination von Wikipedia-Kategorien aus vier Bereichen und durch Annotatoren erstellt, die die Anfragen paraphrasierten und überprü</sample>
    <sample id="107">In der Aufgabe wurden Encoder-Decoder-Modelle, die auf einem mehrsprachigen Encoder basieren, eingesetzt.</sample>
    <sample id="108">Die Arbeit von Costa Senna und Kollegen untersucht, wie Sprachmodelle in Bezug auf Akzeptanzurteile robust sind. Sie beziehen sich auf den Minimal Pair Paradigm, bei dem Modelle auf Akzeptanzurteile, Grammatikalität und Stereotypakzeptanz getestet werden. Das aktuelle MPP - Pipeline - Verfahren hat Schwächen bei der Bewertung von längeren Sätzen. Die Forscher versuchen, die Akzeptanzurteile der Modelle in längeren Kontextfenstern zu bewerten. Sie simulieren längere Sequenzen, indem sie Sätze aus Datensätzen erstellen, die akzeptabel oder unakzeptabel sind. Zum Beispiel verwenden sie Sätze aus dem Blimp - Datensatz und erstellen längere Sequenzen, die die gleiche grammatische Struktur haben. Sie testen die Modelle sowohl mit akzeptablen als auch mit unakzeptablen Präfixen. Bei der Wahl von Sätzen aus verschiedenen Datensätzen oder sogar aus unverwandten Bereichen wie Wikipedia wird untersucht, ob die Modelle von Kontext beeinflusst werden. Bei</sample>
    <sample id="109">The paper presents a method for creating a large dataset of natural language instructions without human labor. It uses a pretrained language model, specifically a variant of GPT-3, to generate instructions and corresponding inputs and outputs. The model is prompted with examples from the Supernatural Instruction dataset. The generated data is diverse in tasks, content, and phrasing. The resulting dataset contains 64k examples, with about 240k when instruction paraphrases are considered. The generated examples are analyzed for correctness, creativity, and diversity. More than 50% of the examples are correct. The dataset is used to fine-tune an 11 billion parameter T5 model, which outperforms both T0 and T5 instruct on several benchmarks. Training on the dataset is faster and cheaper than human annotation. This method shows the potential of language models to produce creative and diverse data, which is difficult to achieve with crowdworkers.</sample>
    <sample id="111">The authors assume the provider can collect a general text corpus and count the word frequency with it.</sample>
    <sample id="112">Hallo alle zusammen, mein Name ist Shuheng. Heute werde ich unser Papier präsentieren: "Do CoNLL-2003 Named Entity Taggers still work well in 2023?". Lass uns anfangen.Unser Papier untersucht das Problem der Generalisierung unter Verwendung der Aufgabe der benannten Entitätserkennung, NER -Aufgabe. Wir beobachten, dass Modelle CoNLL-2003 für fast 20 Jahre verwendet haben, um NER zu entwickeln, und dies wirft natürlich mehrere Probleme auf. Erstens, können diese Modelle auf modernes Datenmaterial generalisieren? Und wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung notwendig? Gleichzeitig, wenn wir eine schlechte Generalisierung beobachten, was verursacht den Leistungsabfall dieser Modelle?Um diese Probleme zu untersuchen, haben wir den CoNLL++ Datensatz entwickelt. Dies ist ein Datensatz, den wir aus Reuters - Nachrichten von 2020 gesammelt und mit den gleichen CoNLL-2003</sample>
    <sample id="114">Abstract: This work focuses on addressing the heavy parameter problem of large language models. It proposes group head attention, using a divide - and - conquer strategy. The first stage is group constraint training, dividing attention heads into groups to make intra - group heads more similar and inter - group heads more separate. The second stage is the voting - to - stay algorithm, which prunes redundant multi - head attention, keeping only one head per group. This approach achieves significant parameter compression, up to 90% in extreme conditions, while maintaining good performance on tasks like machine translation, language modeling, and abstract summarization.</sample>
    <sample id="115">The answer is not directly stated in the given text.</sample>
    <sample id="116">Im Beispiel wird das Wissen benötigt, dass Servin ein Richter ist.</sample>
    <sample id="117">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="118">The presentation is about improving pre - training techniques for code - switched NLP. It defines code - switching, gives an example, and explains why multilingual pre - trained models like M - BERT and X - LEMMA don't perform well on code - switch tasks. The main contributions are novel MLM techniques tuned for code - switching, architectural changes, and auxiliary loss. Switch - MLM is proposed, which focuses on switch points, groups of two tokens transitioning between languages. It has a surrogate method called frequency MLM. Architectural modifications include residual connections and an auxiliary LID - based loss. Results show the combined method performs best on sentiment analysis tasks. Probing experiments verify the claim that the proposed methods increase switch - point information in intermediate and final layers.</sample>
    <sample id="119">In den erweiterten Experimenten konzentrieren sich die Arbeiten auf GPT-4 und GPT-3.</sample>
    <sample id="120">Das Modell verwendet Werte aus mehreren Ebenen.</sample>
    <sample id="121">Beispiele für direkte Inferenz sind das Nennen des Namens des Liedes, zum Beispiel "Easy on Me", oder die Angabe seiner Position, zum Beispiel "das erste Lied".</sample>
    <sample id="122">Fudan University.</sample>
    <sample id="123">Das Forschungsprojekt von Ying und Zhiyang befasst sich mit der Verbesserung der Multi-Modell - Serial - Learning - Leistung durch Anpassung an Anweisungen. Sie erkunden, ob Anpassung an Anweisungen bei Multi - Modell - prätrainierten Modellen zu einer besseren Generalisierung auf nicht gesehene Multi - Modell - Aufgaben führt. Sie entdecken eine große Unterschiedlichkeit in der Verfügbarkeit von Anweisungsdatensätzen zwischen NLP und Multi - Modell. Deshalb bauen sie Multi - Instruct, den ersten Multi - Modell - Anpassung - Anweisungsdatensatz, auf. Dieser umfasst 62 diverse Multi - Modell - Aufgaben aus 10 großen Kategorien. Sie verwenden OFA als Basismodell und formulieren alle Aufgaben in einem einheitlichen Sequenz - zu - Sequenz - Format. Für die Auswertung verwenden sie 5 Experten - geschriebene Anweisungen. Sie finden heraus, dass Anpassung an Anweisungen OFA erheblich verbessert. Transfer - Lernen von Natural Instruction - Dat</sample>
    <sample id="124">The work focuses on benchmarking and improving temporal reasoning of LMs. It breaks down temporal reasoning into three levels: time - to - time, time - to - event, and event - to - event. The first level deals with simple time calculations. The second level involves understanding events in relation to time, like what team Messi played for in 2010. The third level requires reasoning about multiple events over time. The study found that prior works overemphasized L2 reasoning. They conducted a preliminary experiment on L1 prediction of years, evaluating three LMs. ChatGPT showed strong bias towards the 2000 - 2020 time period. They proposed a new dataset covering all three reasoning levels and long temporal coverage. The dataset was evaluated in three QA settings: closed - book, open - book, and a new reasoning - QA setting. A training strategy with temporal span extraction pre - training and time - sensitive reinforcement learning was proposed. The final model, Time - T5, significantly outperformed other models in OBQA and Reasoning - QA settings.</sample>
    <sample id="125">The presentation is given by Yanis Lavaque, so there is one author.</sample>
    <sample id="126">Ja.</sample>
    <sample id="127">NAMGILHO, ein Masterstudent an KAI in Korea, präsentiert eine Arbeit über "Große Sprachmodelle als Lehrer des Denkens". Sie beschreiben, dass Chain - of - Thought - Denken eine Technik ist, um große Sprachmodelle zu ermöglichen, komplexe Aufgaben zu lösen. Allerdings funktioniert diese Technik nur auf riesigen Modellen wie GPT - 3 oder POM. Dies ist ein Problem, da diese Modelle viel Speicher und Rechnungsfähigkeit benötigen und in vielen Situationen teuer oder unmöglich zu bereitstellen sind. Sie schlagen vor, diese riesigen Modelle als Lehrer zu verwenden, um ihre Denkfähigkeiten auf viel kleinere Modelle zu übertragen. Sie haben auch eine neue Technik namens "diverse Denken" vorgeschlagen. Sie haben hunderte von Beispielen analysiert, um zu überprüfen, ob und warum kleine Modelle komplexe Denkschritte, die zuvor nur große Modelle erledigen konnten, durchführen können. Sie beginnen mit der Erklärung von Chain - of - Thought - Denken. V</sample>
    <sample id="128">The work presents a diagnostic test suite for knowledge integration in natural language understanding models. It introduces a coreference resolution task to evaluate models' ability to use knowledge from different sources. The dataset is evaluated with human participants and established models. Three settings are defined: background pretrain, background both, and background inference. The results show that models trained on the dataset perform better than random choice, suggesting they learn to exploit surface cues. However, even the best models struggle with integrating background knowledge presented only at inference time. This highlights the need for task-specific training for models to effectively integrate knowledge from multiple sources.</sample>
    <sample id="129">The authors gave the example of the persona of a black woman.</sample>
    <sample id="130">Nicht genannte Modellarchitekturen generalisieren nicht gut.</sample>
    <sample id="131">The test datasets are not mentioned in the text.</sample>
    <sample id="132">Zwei.</sample>
    <sample id="133">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="135">ABC eval is a new approach to evaluating conversational AI. It was developed by the Emory NLP lab and Amazon Alexa AI. Instead of relying on human evaluation, ABC eval annotates model responses to measure various behaviors like irrelevant information, contradictions, and common sense violations. It was tested on four state - of - the - art chat models and found to be more reliable and predictive than existing methods. The results showed that ABC eval metrics can explain a significant portion of conversation quality. It also highlighted challenges in the models, such as common sense violations and irrelevant information. The hope is that ABC eval can be used by others in the field to advance conversational AI.</sample>
    <sample id="136">Der Vortrag von Chad Savan und Nafisa von der University of Sheffield präsentiert ihre Arbeit "Fermat: An Alternative to Accuracy in Numerical Reasoning". Sie motivieren sich durch die Vielzahl realer Anwendungen für numerische Denkprozesse und die Notwendigkeit der Faktenkorrektheit in solchen Prozessen, wie z.B. Faktenprüfung. Sie stellen ein neues Evaluationsset vor, das auf arithmetischen Typen basiert, um die Fähigkeiten von Modellen in Bereichen wie Zahlverstehen, mathematische Operationen und Trainingsabhängigkeit zu testen. Sie ändern die Darstellung der Zahlen, um realitätsnaher zu sein und testen die Modellleistung bei verschiedenen Arten von Zahlen und Operationen. Sie finden, dass die meisten Modelle schlecht in diesen Bereichen performen, aber durch Feinarbeitung die Leistung verbessert wird. Sie untersuchen auch die Auswirkungen von Trainingsvorlagen auf die Modellleistung.</sample>
    <sample id="137">The work "Tell to Design: A Dataset for Language - Guided Floorplan Generation" from the Singapore University of Technology and Design focuses on a new task in machine learning. It aims to enable users to design floor plans by telling instructions, specifically in the domain of floor plan design. The task involves generating 2D floor plan designs that comply with given natural language instructions.The dataset is constructed using publicly available floor plans and human - annotated language instructions collected from Amazon Mechanical Turk. There are 5051 human - annotated instructions and around 76000 artificial instructions generated from predefined templates. The average number of words per instruction is over 200, exceeding 10 sentences.The main challenges of this task are: strict constraints on design generation, understanding the big picture of the entire floor plan from document - level structured text with fuzzy and entangled information, and dealing with ambiguous, incomplete, or misleading information in human instructions.To solve this, the researchers cast the floor plan generation task as a sequence - to - sequence problem under the encoder - decoder framework. They use a transformer - based encoder - decoder structure and initialize the model with a pre - trained language model, T5, for better language understanding. The model is trained using a normal language modeling objective</sample>
    <sample id="138">NLU-Modelle, die die Fähigkeit haben, Wissen aus verschiedenen Quellen zu integrieren und zu nutzen, ist nach Ansicht der Autoren ein zu wenig erforschtes Gebiet.</sample>
    <sample id="139">The speakers are Ying and Zhiyang.</sample>
    <sample id="140">Ja.</sample>
    <sample id="141">Die Ressourcen unterstützen nur begrenzte Typen kontextabhängiger Übersetzungen und begrenzte Sprachpaare, da sie auf Domänenwissen und menschlicher Kreation beruhen.</sample>
    <sample id="142">Hallo, ich werde über unsere Arbeit zur Auflösung indirekter Referenzierungen für Entitätenauswahl sprechen, bei der wir das "altentitiescorpus" eingeführt haben. Mein Name ist Javad Hosseini und es ist eine gemeinsame Arbeit mit Filip Radlinski, Silvio Parodi und Ali Louis.Unser Ziel ist es, das Verständnis der Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen möchten. Betrachten Sie diese alternative Frage: "Meintest du 'Easy on Me' oder 'I Got a Feeling'?" Hier möchte der Benutzer zwischen zwei Liedern wählen.Das offensichtlichste ist es, eine direkte Referenz zu verwenden, zum Beispiel, indem man den Namen des Liedes, "Easy on Me", oder seine Position, die erste, nennt. Aber manchmal ist eine indirekte Referenz für eine natürlichere Konversation angemessen.Dies kann passieren, wenn der Benutzer sich nicht an den Namen des Liedes erinnern kann oder wenn die Aussprachen zu ähnlich sind und es schwierig ist, sie zu unterscheiden. Oder wenn der Benutzer eine</sample>
    <sample id="143">Mit den bestehenden SimulST-Richtlinien, die auf off-line-Modellen angewendet werden, wie der Whitkey-Strategie und dem lokalen Abkommen, sowie mit den state-of-the-art-Architekturen, die speziell für die simultane Sprachübersetzung entwickelt wurden, wird der Ansatz verglichen.</sample>
    <sample id="144">I'm sorry, but the information about which university the authors belong to is not provided in the given content.</sample>
    <sample id="145">Jenny.</sample>
    <sample id="146">The talk is about analyzing omission in dialogue summarization. It starts by introducing dialogue summarization as a subtask of text summarization. It mentions that large scale pretrained language models have made progress but still have common errors like factual errors and omission. Omission is a major factor affecting the quality of dialogue summarization. The speaker analyzed the percentage of summaries with omission problems and found that even state - of - the - art models have a high omission rate. They also showed the position distribution of omitted information in dialogues. To better analyze and solve the omission problem, they defined the task of omission detection. They constructed a dataset for this task, which provides high - quality omission labels. They explored three frameworks as baselines and used precision, recall, and F1 score to evaluate omission detection models. The results showed that the task is challenging. Finally, they discussed using omissions to refine summaries.</sample>
    <sample id="147">There are three authors involved in the work.</sample>
    <sample id="148">Hallo Sarah! Ich bin ein deutscher Assistent. Ich kann den englischen Inhalt für dich übersetzen. Was genau möchtest du übersetzen?</sample>
    <sample id="149">Das ist nicht im Text erwähnt.</sample>
    <sample id="150">Archy K. präsentiert ein RECL Paper über extractive Question Answering auf Meeting Transkripten. Er dankt Kollegen von Adobe Research und UNC Chapel Hill. Millionen Meetings weltweit führen zu vielen Transkripten, die als neues NLP - Forschungsfeld dienen. Die Transkripte sind lange, domänenspezifisch und informativ, aber bisher wurden nur Summarisierung und Action - Items extrahiert. Archy K. stellt Meeting QA vor, ein extractive QA - Datensatz mit Fragen und Antworten aus Meetings. Die Daten wurden aus öffentlichen Transkripten des AMI - Korpus gesammelt. Es gibt eine hohe Interannotator - Übereinstimmung. Meeting QA enthält 7.700 Fragen, 30% sind unantwortbar, 40% haben mehrere Antwortspannen und 48% mehrere Sprecher. Die Fragen sind hauptsächlich in Ja - Nein - Formulierungen, aber auch rhetorisch. Die Längenverteilung der Transkripte, Fragen und Antworten ist gegeben. Archy K. beschreibt</sample>
    <sample id="151">Hallo alle zusammen, mein Name ist Ying und mein Kollege Zhiyang und ich werden unsere Forschung über MultiInstruct präsentieren, die die Zero-Shot-Lernung von Multi-Modell-Prätrainierungsmodellen durch Anpassung an Anweisungen verbessert. Mit den Fortschritten bei großen Sprachmodellen haben viele Arbeiten neue Lernparadigmen für die Wiederverwendung von Prätrainierungsmodellen für verschiedene untergeordnete Aufgaben in einer parameter- und dateneffizienten Weise erforscht. Kürzlich haben viele Studien gezeigt, dass Anpassung an Anweisungen große Sprachmodellen ermöglicht, auf unähnliche Aufgaben in einer Zero-Shot-Art durch das Folgen natürlicher Anweisungen zu performieren. Allerdings konzentrieren sich die meisten früheren Arbeiten auf Anpassung an Anweisungen hauptsächlich darauf, die Zero-Shot-Performance auf Sprachnur-Aufgaben zu verbessern, während Computer Vision und Multi-Modell-Aufgaben ausgelassen wurden. Daher wollen wir in dieser Arbeit untersuchen, ob Anpassung an</sample>
    <sample id="152">Fredrik Riemenschneider präsentiert sich und seine Arbeit an der Schnittstelle von NLP und klassischer Philologie. Er führt bei seiner Präsentation "Exploring Large Language Models for Classical Philology" über nützliche Ressourcen für Altgriechisch und Lateinisch. Er diskutiert die Implikationen und Herausforderungen der Mehrsprachigkeit in diesen Modellen.Die Präsentation beginnt mit einem Überblick über die aktuelle Lage von Sprachmodellen und Klassik. Es gibt verschiedene Modelle, wie z.B. Latin BERT, Ancient Greek BERT und eine weitere Ancient Greek BERT, die in den letzten Jahren entwickelt wurden. Diese Modelle sind alle BERT - Typen, also spezifische Encoder - nur - Modelle und alle sind monolingual. Es gibt jedoch Bedarf nach Modellen, die sowohl Altgriechisch als auch Lateinisch beherrschen. Die bestehenden Modelle sind nicht auf Altgriechische Texte vortrainiert und ihre Leistung ist unbekannt. Es gibt ein Mangel an robusten Evaluierungen, was die Verständnis ihrer Fähigkeiten</sample>
    <sample id="153">In this work, we study ambiguities in text - to - image models. We curate a benchmark dataset with different types of ambiguities. Then, we use a framework to disambiguate prompts by either asking clarifying questions or generating visual setups. After disambiguation, we input the prompts into a text - to - image model to generate images and evaluate if they are faithful to user intention. Our findings show that our framework has a positive effect on faithful generation and that our automatic evaluation framework agrees with human evaluation. If you want to know more, refer to our paper.</sample>
    <sample id="154">Die Autoren gehören der University of Toronto an.</sample>
    <sample id="155">The name of the referent is Javad Hosseini.</sample>
    <sample id="157">The work introduces a dialogue summarization method using a static - dynamic structure fusion graph. It aims to distill silent information from dialogue context into a concise summary. This is a challenging and interesting task in text summarization research. The method uses an utterance encoder to encode dialogue context utterances into vector representations. It constructs a static graph using existing dialogue structure modeling methods. Then, a static - dynamic graph module combines multiple static graphs and captures semantic relationships between utterances based on their deep vector representations. Finally, a pre - trained language model generates the summary by fusing static and dynamic dialogue structures. The model structure is detailed, including four main components: utterance encoder, static graph construction, static - dynamic graph module, and summary generator.</sample>
    <sample id="158">The talk is about a work on dual cache for long document neural coreference resolution. Coreference resolution is about identifying and clustering mentions referring to the same entity in a document. Conventional methods have quadratic complexity, but cache - based methods use a fixed - size cache to reduce it to linear. However, in long documents, topic changes cause mentions to be scattered, leading to high cache misses with the LRU policy. The study shows that high - frequency entities are mentioned globally and cause most cache misses. So, dual cache is proposed. It has a local cache with LRU eviction policy for local entities and a global cache with LFU policy for global entities. The model scans the document left - to - right, classifies mentions, and adds them to the appropriate cache. Evaluation on benchmarks shows that dual cache outperforms single cache methods, reduces cache misses, and has the highest performance - cost ratio. It's more cost - effective than single cache methods.</sample>
    <sample id="159">Hallo alle zusammen, ich bin Gustav Sinner und freue mich, Sie zu unserer Präsentation unserer ACL 2023-Papiere zu begrüßen. "Sprachmodellakzeptabilitätsurteile sind nicht immer robust gegenüber Kontext". Dies ist ein gemeinsames Projekt mit John Gog, Aaron Müller, Kanishka Mishra, Karen Venters, Roger Levy und Athena Villalón.So in diesem Projekt haben wir den Minimal-Pair-Paradigma erneut beleuchtet. Das Minimal-Pair-Paradigma bewertet Sprachmodelle hauptsächlich anhand von Akzeptabilitätsurteilen, die auch grammatikalische Fragen wie Blimp-Syntax-Fehler oder Akzeptabilität in Bezug auf Stereotypen wie Crow's Pairs umfassen.In diesem Minimal-Pair-Paradigma wird die typische Art, Sprachmodelle zu bewerten, so dass man einen akzeptablen Satz oder einen grammatischen Satz zeigt und dann einen unakzeptablen Satz oder einen ungrammatikalen Satz zeigt. Man hofft, dass das Modell mehr Wahrscheinlichkeit dem akzept</sample>
    <sample id="160">Im ersten Schritt der Methode werden die Input-Token mit einem unordered multiset of tokens zugeordnet, die in der Ausgabe auftreten werden.</sample>
    <sample id="161">Coscript enthält 55.000 spezifische Skripte.</sample>
    <sample id="163">Die beste Ausrichtungsmethode für DEplain ist die Methode von Mass Align.</sample>
    <sample id="164">Schwach überwachtes Lernen ist günstiger als menschliche Annotierungen, aber auch ungenauer.</sample>
    <sample id="165">The paper presents an approach to adaptive reasoning. It starts with a context, like Emily being stuck in traffic, and an outcome, like Emily making her flight. There are possible explanations, such as her flight being delayed or leaving on time. The goal is to find a plausible explanation that bridges the gap between the context and outcome. The paper introduces an unsupervised learning method called LiPoR, which stands for Likelihood Learning with Posterior Regularization. This method treats explanations as a latent variable and aims to maximize the marginal likelihood of the outcome given the context. However, it also needs a regularizer to prefer plausible explanations. The regularizer enforces mutual exclusivity among explanations. The LiPoR objective consists of maximizing the likelihood of outcomes and preferring some explanations over others.</sample>
    <sample id="166">This abstract introduces a new divide - and - conquer learning framework for image retrieval from linguistically complex texts. It addresses the challenge of highly similar images and long descriptions. The framework is inspired by divide - and - conquer strategy and dual - process theory. It uses a proposition generator to decompose complex propositions into simple ones. System 1, the visual - linguistic interactor, performs visual - propositional information interaction. System 2, the neural symbolic reasoner, integrates reasoning states and results of simple propositions. The final solution is obtained by combining inference results of System 1 and System 2. Experimental results show that the proposed method outperforms baselines. The method is process - interpretable and suggests that neuro - symbolic calculation could improve large language models' compositional reasoning and planning capacity. Divide - and - conquer is compared to self - asking - child's thoughts in decomposing complex reasoning into simple problems.</sample>
    <sample id="167">In DEplain-web wurden 750 Dokumente manuell und automatisch ausgerichtet.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde von Reuters-Nachrichten aus dem Jahr 2020 gesammelt und dann mit den gleichen CoNLL 2003-Annotationsempfehlungen annotiert.</sample>
    <sample id="169">Palm ist ein 540 Millionen Parameter großer Sprachmodell, das im letzten Jahr vorgestellt wurde. Es wurde an einer großen Textsammlung mit 780 Milliarden Tokens trainiert. Bei der Veröffentlichung erreichte es den besten Stand der Technik in vielen NLP - Aufgaben.Dieses Papier präsentiert die erste systematische Studie zur Prompting - Technik für maschinelle Übersetzung. Die Übersetzungsqualität der Modelle wurde mit den besten Praktiken der AMT - Gemeinschaft evaluiert. Das beinhaltet das Vermeiden von Überschneidungen zwischen Test - und Trainingsdaten. Zwei der besten Systeme wurden verglichen, und die Ergebnisse wurden mit modernen AMT - Metriken und expertenbasierten menschlichen Evaluierungen präsentiert.Ein wichtiger Faktor für die Leistung der LLMs bei der Übersetzung ist die Prompting - Technik. Eine einfache Experimente mit One - Shot - Prompting zeigte, dass die meisten Sätze, 516 von 1000, eine Differenz von mehr</sample>
    <sample id="170">Hallo allemaal, mein Name ist Yu Sun Zhang aus der Penn State University. Heute werde ich unsere Arbeit "Exemplar: Crosslingual Semantische Parsing in mehreren natürlichen Sprachen und mehreren Repräsentationen" vorstellen.Semantische Parsing ist eine Aufgabe, um semantische Repräsentationen von Benutzeranfragen zu bauen, wie z.B. SQL und Lambda Calculus. Und crosslingual semantische Parsing ist die Aufgabe, Anfragen in mehreren natürlichen Sprachen in mehrere Repräsentationen zu übersetzen. Wie in diesem Bild gezeigt, müssen wir die Anfrage in mehreren natürlichen Sprachen mit neuronalen Modellen in SQL, Lambda oder FunQL usw. übersetzen.Derzeitige crosslingual semantische Parsing -Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel gibt es Mängel bei der Abdeckung bestimmter natürlicher Sprachen, wie z.B. Chinesisch fehlt, und Mängel bei der Abdeckung bestimmter Repr</sample>
    <sample id="171">Existing works can be broadly classified into four categories. However, these methods either not applicable to embedding as services or lack of transferability.</sample>
    <sample id="172">No, they are not sufficient for CLSP.</sample>
    <sample id="174">The speaker, Thea, introduces the paper "ArgAnalysis 35k", a large dataset for argument quality analysis. She explains that it's unique because it's the largest with high - quality arguments, sourced from high - quality tournaments, expert debaters, intermediate debaters, and novice debaters. It has a diverse range of arguments based on 24 themes, not just pre - selected motions. The dataset includes analysis, which is a combination of claims, premises, and more, not just claims or premises. This analysis helps explain the argument better. The speaker also mentions instance - based annotator reliability, where only biased judgments are eliminated, not all of an annotator's work. This makes the dataset a good use case for instance - based analysis.</sample>
    <sample id="175">Die Methode adressiert die Mehrdeutigkeit der Permutationen, indem sie die Ausrichtung als Teil des Trainings induziert. So können die korrekten Permutationen ermittelt werden. Wenn du mehr über die Methode erfahren möchtest, frag einfach weiter.</sample>
    <sample id="176">Well, the fairness of a downstream NLP model is often defined in terms of how well it performs across different demographic groups or political leanings. For example, in hate speech detection, a fair model should be equally good at detecting hate speech regardless of the target group's political leaning. It's about ensuring that the model doesn't unfairly favor or discriminate against certain groups. So, in your case, if a right-leaning model is better at detecting hate speech against white and male groups but worse against black, LGBTQ+ groups, that's not fair. What do you think about this?</sample>
    <sample id="177">Yannick Slavac.</sample>
    <sample id="178">Kostas Sina.</sample>
    <sample id="179">Melanie Clark discusses mining language models for theory of mind. She uses the Sally - Anne test to probe understanding. Large language models perform poorly on false belief tasks. Her research aims to improve theory of mind reasoning in these models. She presents Symbolic Tom, an inference time method using explicit graphical representations. This method computes belief graphs for characters. It then efficiently answers questions by detecting entities, retrieving appropriate belief graphs, and performing recursion. Experiments show Symbolic Tom outperforms supervised baselines on the Tommy dataset and two new datasets. It demonstrates improved performance across different models and tasks.</sample>
    <sample id="180">The speaker's name is Myra.</sample>
    <sample id="181">This paper introduces a work on distinguishing script knowledge from large language models for constrained language planning. It focuses on planning for goals with specific constraints, unlike previous work which mainly dealt with abstract goals of stereotypical activities. The authors define the problem of constrained language planning, which imposes different constraints on the goals of planning. They evaluate and improve the constrained language planning ability of large language models. Since no dataset of specific goals existed, they acquired 100 specific goals and evaluated the scripts generated from large language models. They found that all large language models achieved unsatisfactory results on planning for specific goals. Detailed analysis revealed that while the semantic completeness in generated scripts was acceptable, the faithfulness to the constraints could not be guaranteed. They then adopted the idea of over - generated then filter to improve generation quality. This method greatly improved the planning ability in semantic completeness and faithfulness to the constraints. The authors also created a dataset named Co - script for constrained language planning, which contains 55, 000 specific goals with scripts. This dataset was validated and tested by crowdsourced workers. The paper concludes that Co - script shows a high constraint distribution and high plausibility in the generated specific goals.</sample>
    <sample id="182">Tropikalismus bezieht sich hierbei auf die Tendenz, bestimmte Merkmale oder Eigenschaften mit der Tropenregion in Verbindung zu bringen. Es kann dazu führen, dass bestimmte Gruppen oder Identitäten als "exotisch" oder "unterschiedlich" dargestellt werden.</sample>
    <sample id="183">The authors used prompts to generate these personas.</sample>
    <sample id="184">In dieser Arbeit wurde CXMI, Contextualized Mutual Information, zur Messung der Kontextnutzung verwendet.</sample>
    <sample id="185">DrBERT ist auf Roberta basiert und auf Nachos trainiert, während ChuBERT anonymisierte Daten aus dem Non - University Hospital verwendet.</sample>
    <sample id="187">Zwei.</sample>
    <sample id="188">Iteratives Transferlernen ist ein Ansatz, bei dem man zuerst von einer verwandten Aufgabe Wissen überträgt, um die Leistung auf der ursprünglichen Aufgabe zu verbessern. Danach wird das Modell auf der ursprünglichen Aufgabe weitertrainiert. So kann man die Leistung stufenweise verbessern. Wenn du mehr darüber wissen möchtest, lass es mich wissen!</sample>
    <sample id="189">Das Ziel des Datensatzes ist, um die Verständnisfähigkeit von LLMs für die Erkennung von Indirekten Referenzierungen in der Entitätsauswahl zu verbessern.</sample>
    <sample id="190">The attacker may steal the model through learning from the embedding and provide similar services.</sample>
    <sample id="191">Drei.</sample>
    <sample id="192">Der Vortrag von Yang Luo geht über eine Optimierungsmethode für das Trainieren großer Sprachmodelle. Adam ist eine verbreitete Methode, die viel Speicher verbraucht, während AdaFactor eine effizientere Methode ist, aber langsamer ist. Yang Luo präsentiert CAM, eine Methode, die gleichzeitig schnelle Konvergenz und geringe Speicherverwendung bietet. Sie verwendet nichtnegative Matrixfaktorisierung, um den Speicherbedarf zu reduzieren. CAM korrigiert Fehler in AdaFactor und verbessert die Genauigkeit bei gleicher Anzahl an Trainingsstufen. Es ist besonders gut bei großen Modellen und bei steigender Batchgröße.</sample>
    <sample id="193">I'm sorry, the answer is not provided in the text. You might need to look for more information elsewhere.</sample>
    <sample id="194">Die Autoren gehören an die Carnegie Mellon University und die University of Washington.</sample>
    <sample id="195">Der englische Inhalt beschreibt ein neues Framework namens ROHT, Reasoning over Hierarchical Question Decomposition Tree, für erklärbares Fragebeantworten, XQA. Es gibt zwei Hauptansätze in XQA: neuronale symbolische Methoden, die Fragen in formale Darstellungen übersetzen, und dekomponierungs - basierte Methoden, die natürliche Sprache als Zwischenschritte verwenden. Beide haben Nachteile. ROHT ist ein zweistufiges Framework. Zuerst wird die hierarchische Struktur einer komplexen Frage durch ein Hierarchical Question Decomposition Tree, HQDT, dargestellt. Dann wird probabilistisch über dem HQDT nachgedacht, um Wissen aus KB und Textkorpora zu nutzen. Es wird gezeigt, dass ROHT auf zwei Datenbanken, KQA Pro und Music, besser als andere KB - QA - Methoden leistet. Wenn Wikipedia als zusätzlicher Textkorpora hinzugefügt wird, zeigt ROHT - Mixed erhebliche Verbesserungen im Vergleich zu ROHT - KB. Das zeigt, dass das Kombinieren von Wissen aus KB und</sample>
    <sample id="196">March read this absolutely fascinating book about bees yesterday.</sample>
    <sample id="197">The state of the art chat models are the ones that were evaluated in the study. They were tested on 100 human bot conversations per model using ABC eval.</sample>
    <sample id="198">Weil große Sprachmodelle immer längere Kontextfenster haben.</sample>
    <sample id="199">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="200">Ja, die Annotatoren kennen die Entität im Voraus.</sample>
    <sample id="201">State-of-the-art MT-Metriken wurden für die Bewertung verwendet.</sample>
    <sample id="202">Nicht direkt erwähnt.</sample>
    <sample id="203">Positionalität ist für NLP wichtig, weil sie die Perspektiven von Menschen berücksichtigt, die durch ihre Demografie, Identität und Lebenserfahrungen geprägt sind. Das kann die Entscheidungen von Forschern beeinflussen und somit die Ergebnisse und Ausgänge von Forschungsprozessen. Also, wenn Modelle und Datensätze Positionalität haben, können sie bestimmte Positionalitäten über andere repräsentieren.</sample>
    <sample id="204">Nicht bekannt.</sample>
    <sample id="205">Der Vortrag von Zhang Bing, PhD-Student an der University of Washington, geht über die Verfolgung politischer Biass in Sprachmodellen. Er erläutert, dass Sprachmodelle auf großem Skala webgekraulten Daten trainiert werden, wobei politische Nachrichtenmedien gut abgedeckt sind. Dies hat sowohl Vorteile als auch Nachteile für Sprachmodell - Anwendungen. Auf der einen Seite können sie aus verschiedenen Perspektiven lernen, was die Demokratie und Vielfalt von Ideen feiert. Auf der anderen Seite sind diese politischen Meinungen im Wesentlichen sozial voreingenommen und können Potenziale für Unfairness in Downstream - Aufgabenanwendungen schaffen.Der Vortrag untersucht den Pipeline - Verlauf der politischen Biass von der Prätrainingsdaten zu Sprachmodellen bis hin zu Downstream - Aufgaben. Es wird vorgeschlagen, die politische Biass der Sprachmodelle zu evaluieren und die Rolle der Prätrainingsdaten bei solchen Biass zu untersuchen. Es wird auch untersucht, wie Sprachmodel</sample>
    <sample id="206">Wir verwenden das Modell, das wir mit der Kombination von Transferlernung und aktiver Lernung erzeugt haben, um Dissonanz zu erkennen. Es ist ein Modell, das wir für das Transferlernen verwendet haben.</sample>
    <sample id="207">Die neuesten Testsets wurden verwendet.</sample>
    <sample id="208">The authors have not specified the exact number of recommendations they have made.</sample>
    <sample id="209">The paper doesn't directly state the exact percentage increase in performance over the strongest baseline. It mainly focuses on showing improvements in semantic completeness and faithfulness to constraints. You might need to look at specific performance metrics in the results section to get a more precise figure.</sample>
    <sample id="210">The speaker's name is Xu Hang.</sample>
    <sample id="211">Ja, die Ergebnisse und der Datensatz können als Benchmark verwendet werden. Wenn du mehr Details wissen möchtest, lass es mich wissen.</sample>
    <sample id="212">The paper evaluates and improves the constrained language planning ability of large language models.</sample>
    <sample id="213">OFA.</sample>
    <sample id="215">Der Vortrag von Adam Skorowski geht um die Abhängigkeitsstruktur der Koordination. Es gibt verschiedene Ansätze, wie z.B. die universelle Abhängigkeit, die die erste Konjunktion als Kopf der ganzen Koordinationstruktur ansetzt. Dann gibt es die symmetrischen Ansätze wie die Theorie von Igor Melchuk, wo auch die erste Konjunktion Kopf ist. Es gibt auch symmetrische Ansätze wie die Prag - Ansätze, wo die Konjunktion Kopf ist. Und dann gibt es den multi - Kopf - Ansatz wie in der Katzens - Wort - Grammatik, wo alle Konjunktionen Kopf sind.Das Ziel des Papiers ist, eine neue Argumentation für die symmetrischen Koordination - Strukturen zu erzeugen und gegen die asymmetrischen Strukturen. Das Argument basiert auf dem Prinzip der Abhängigkeitslängenminimierung. In englischer Sprache bevorzugen direkte Objekte sich nah am Verb zu befinden, während Adjunkte weiter entfernt sein können. Beispiele wie</sample>
    <sample id="217">Das Team von Wei Hao Zhen und Lu Lu Zhao von der Beijing University of Posts and Telecommunications präsentiert ihre Arbeit zur kontrollierbaren Dialogerzeugung mit mehreren Attributen. Sie erkennen, dass bisherige Methoden nur einzelne Attribute behandeln und die kontrollierbare Dialogerzeugung mit mehreren Attributen nicht gut abdecken. Ihre Beiträge sind: Sie entwerfen DCG, ein entangled kontrollierbares Modell, das kontrollierbare Konzepte von sichtbaren Werten lernt und die entangled Verluste verwendet, um verschiedene Attributkombinationen zu enttarnen. Sie stellen auch ein einheitliches Referenzfreies Evaluierungsrahmen MAE vor, um die Effektivität ihrer Methode und Evaluierungsmaße zu beweisen. Ihre Modelle basieren auf dem DialogGPT - Framework mit einem kompositionellen Prompt - Modul. Sie entwerfen zwei Arten von Prompts, die auf Attributbezogene Informationen von der Trainings - Sprachmodell basieren. Zudem stellen sie ein einheitliches Evaluierungsrahmen vor, das ohne zusätz</sample>
    <sample id="218">Das ist nicht im Text erwähnt.</sample>
    <sample id="219">Das Forschungsprojekt von Jiahui Zhu und seinen Kollegen befasst sich mit der Analyse von finanziellen Berichten. Sie nutzen den 10-K-Standard als Zielgruppe, der viele Details über wichtige Aktivitäten von Unternehmen enthält. Das Ziel ist es, nützliche Informationen aus diesen Berichten zu extrahieren, was viel menschliche Arbeit erfordert.Die Forscher beobachten, dass die Wörter in den Berichten sehr ähnlich sind, etwa 80% der Tokens sind identisch. Dies motiviert sie, eine Multi-Stage-Pipeline zu entwickeln, um die Texte zu vergleichen und zu kontrastieren. Sie definieren ein Referenz- und Zielstrukturmodell, um die Unterschiede zwischen den Berichten zu finden.Die Pipeline besteht aus mehreren Stufen: Dokumentsegmentierung, Relationen, Verhältnisse, automatisches und interner Feinarbeiten. Für die Modellierung werden externe Daten wie ESNI verwendet. Die Ergebnisse zeigen, dass ihr Modell die beste Leistung auf dem finalen Datenset erreicht und auch die Generalisierbarkeit auf unsehene Be</sample>
    <sample id="220">Stony Brook University.</sample>
    <sample id="221">Leider ist in der Zusammenfassung nichts über die untersuchten Sprachpaare erwähnt. Du könntest aber versuchen, im Originalpapier nachzulesen.</sample>
    <sample id="222">Das Papier untersucht Herausforderungen und Interventionen in offenen Domänen für Fragebeantwortung. Es geht darum, wie man eine Frage wie "Was wird in den Pflanzen von Narora, Kakrapur, Tarapur produziert?" beantwortet. Zuerst werden relevante Passagen aus einer Dokumentenbank, hier Wikipedia, mit einem Retrieval - Modell gefunden. Dann nimmt ein Reader - Modell die Frage und die relevanten Passagen als Input und generiert die Antwort. Beide Modelle werden auf einer allgemeinen Domäne wie Wikipedia trainiert. Wenn man eine biomedizinische Frage beantworten möchte, könnte man Wikipedia durch einen biomedizinischen Corpus ersetzen, aber das reicht oft nicht aus, da diese Domänen spärlich sind und das Quellmodell auf Wikipedia - Corpus trainiert ist. Es ist nicht klar, wie man Transfer ermöglicht. Eine naive Lösung wäre, Wikipedia und PubMed - Corpus zusammenzusetzen. Wenn man die Dokumentensammlung erweitert, um auch biomedizinische Dokumente zu enthalten, sollte das die Vorhersage der Frage nicht beeinflussen.</sample>
    <sample id="223">The speaker's name is Zhang Bing.</sample>
    <sample id="224">Die Modelle, die während der Experimente untersucht wurden, sind die Modelle von MassAlign.</sample>
    <sample id="225">53 Aufgaben werden für Training verwendet, und alle 62 Aufgaben werden für Tests verwendet.</sample>
    <sample id="226">Zwei.</sample>
    <sample id="227">Die aktuelle Forschung im Bereich Sprachmodelle hat große Erfolge erzielt, aber es fehlt noch etwas. Grundlegender Sprachverständnis, also die Verbindung natürlicher Sprache mit einer Umgebung, ist wichtig. Das ist für Anwendungen wie Smart Assistenten, Suchmaschinen und medizinische Datenbanken relevant. Der Hauptgrund für die Herausforderung ist die mangelnde Verankerung während des Prädtrainings. Die meisten Sprachmodelle werden mit Textkorpusen prätrainiert, ohne Verankerung. Dies führt zu einem Unterschied zwischen Prädtraining und der Anwendung, was die Aufgabe des Grundlegenden Sprachverständnisses schwierig macht. Bestehende Forschung nutzt Sprachmodelle zur direkten Generierung von Plänen, aber die generierten Pläne können nicht immer grammatikalisch korrekt oder gültig sein. Ein neues Framework wird vorgeschlagen, bei dem Sprachmodelle sich auf die Diskriminierung konzentrieren. Ein symbolischer Agent interagiert mit der Umgebung und vorschlägt Kandidaten, während Sprach</sample>
    <sample id="228">Die Autoren haben Experimente an 4 Datensätzen durchgeführt: AG News, Mind, SSD2 und Iris Spam.</sample>
    <sample id="229">Text revision is crucial in professional writing, especially in argumentative writing. It's a recursive process until optimal phrasing is achieved. The right words and expressions are important as they directly influence the text's effect on the audience. For example, in the claim "cell phones cause brain cancer, " revisions like specifying "cell phone radiation" and clarifying "may cause" improve it. Our paper focuses on how to determine if an argumentative claim is phrased well enough. We introduce two tasks: suboptimal claim detection and claim improvement suggestion. We explore challenges like representativity, model complexity, contextual dependence, and topical and user bias when working with revision - based data. For instance, some claim revisions may be typical for the debate as a whole, while others depend on the parent claim.</sample>
    <sample id="231">NACHOS ist ein Datensatz von medizinischen Crawled Daten aus dem Web.</sample>
    <sample id="232">Der Referent ist Ida Villar.</sample>
    <sample id="233">Simultaneous speech translation, SMT, is the real - time translation of spoken language into text in another language. Current SMT models face problems like complex training procedures and latency issues. Our solution uses existing offline SMT models without retraining. It employs a cross - attention mechanism between audio input and text output. The encoder - decoder attention strategy decides whether to emit partial translation based on attention concentration. This approach outperforms other strategies in terms of latency and computational efficiency. The results are presented in graphs showing high translation quality and low latency. The code and models are open - sourced for reproducibility.</sample>
    <sample id="234">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse. Bei einer 5-Shot-Prompt-Strategie, die wir in unseren Experimenten gewählt haben, ist es fast keine Unterschiede in der Form der Prompting zu sehen. Es sind die Beispiele, die den größten Einfluss haben. Wenn wir zum Beispiel von 0- und 1-Shot-Prompting zu 5-Shot-Prompting kommen, gibt es fast keinen Unterschied in der Form der Prompting. Es sind die Beispiele, die den größten Gewicht haben.</sample>
    <sample id="235">Ich habe leider keine Informationen über die Universitäten, an denen die Autoren angehören. Könnten Sie mir vielleicht mehr Details geben?</sample>
    <sample id="236">I'm sorry, but the text doesn't provide the 5 expert-written instructions. You might need to look for them in the full research paper or dataset. If you have any other questions about the research, feel free to ask.</sample>
    <sample id="237">Sie schlagen vor, ein diagnostisches Test-Suite für Wissensintegration zu entwickeln.</sample>
    <sample id="238">Das Video präsentiert den MeetingBank-Datensatz, der für die Entwicklung von Summarisierungstechnologien in verschiedenen Meetingbereichen gedacht ist. Er besteht aus 1.366 Stadtgemeinderatssitzungen und fast 7.000 Beispielen. Es gibt Daten wie Anzahl der Meetings, Dauer, Token pro Meeting, Anzahl der Sprecher und Jahrperiode. Statistiken für Summarisierungsbeispiele pro Stadt und durchschnittliche Satz- und Tokenanzahl in Quelle und Zusammenfassung werden bereitgestellt. Die Summarisierungen werden anhand von Strukturmaßen wie Abdeckung und Dichte gemessen. Die Analyse zeigt, dass die meisten Summarisierungen zwischen 70% und 90% Abdeckung haben. Für Modellbewertung wurden die Top 10 Summarisierungssysteme auf dem MeetingBank-Testset evaluiert. Es gibt interessante Beobachtungen, wie z.B. dass Extraktive Systeme gute Ergebnisse erzielen können. GPT-3 zeigt laut automatischen Metriken schlechte Leistung</sample>
    <sample id="239">Hallo Leute, mein Name ist Ida Villar und ich werde Ihnen einen kurzen Überblick über das Papier "Prompting Pan for Translation: Assessing Strategies and Performance" geben. Dies ist ein gemeinsames Projekt mit meinen Kollegen von Google Translate.Pan ist ein 540 Millionen Parameter kleiner Sprachmodell, das letztes Jahr, 2022, vorgestellt wurde. Es wurde an einer großen Sammlung von Texten, die 780 Milliarden Tokens umfasst, trainiert. Bei der Veröffentlichung erreichte es den State-of -the -Art in hunderten von NLP -Aufgaben.In dieser Arbeit präsentieren wir die erste systematische Studie von Prompting für maschinelle Übersetzung mit Sprachmodellen. Wir bewerten die Übersetzungsqualität solcher Modelle, indem wir die besten Praktiken der AMT -Community verwenden. Das beinhaltet die Verwendung der neuesten Testdatensätze, um eine Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden. Wir vergleichen es mit zwei State -of -the -Art</sample>
    <sample id="240">Hallo, ich bin Dawei, ein PhD-Student an der Saarland University in Deutschland. In diesem Video möchte ich unsere jüngste Arbeit präsentieren: "Wider than you think: A critical look at weakly supervised learning". Es ist ein gemeinsames Projekt mit Xiao Yu Shen, Mario Smuth, Gustav Steffen und Dittich Klarko.Ich möchte mit einer kurzen Einführung in das schwache Supervision und das schwache überwachte Lernen beginnen. Im schwachen Supervision wird das Datenmaterial nicht manuell beschriftet. Stattdessen wird es mit schwachen Beschriftungsquellen beschriftet, wie beispielsweise einfachen heuristischen Regeln, Wissensdatenbanken oder niedriger qualitätige Crowd sourcing, wie in der Abbildung rechts dargestellt.In verglichen mit menschlichen Annotierungen sind die schwachen Annotierungen viel billiger, aber sie sind auch unzuverlässig, was bedeutet, dass ein gewisser Teil der Annotierungen falsch ist. Wenn wir Neuronen direkt auf schwach beschrifteten Daten trainieren, neigen die Neuronen dazu, die Bes</sample>
    <sample id="241">Ethan bespricht ein Papier über die menschliche Beteiligung in der Früherkennung von Fehlinformationen, insbesondere in Bezug auf Behandlungen für COVID-19. Es wird kritisiert, dass viele automatisierte Ansätze für die Erkennung von Fehlinformationen auf Social - Media - Plattformen zu unrealistischen Bewertungen neigen und das Problem des Lecks von Gegenbeweisen aufweisen. Die vorgeschlagene Evaluierungs - Rahmen - Methode soll diese Mängel beheben. Sie ist end - zu - end und integriert menschliche Rückmeldung. Es gibt zwei Hauptkomponenten: die Erkennung von täuschenden Behauptungen und die Überprüfung von Verhaltens - Verstößen. Der erste Teil verwendet einen T5 - Modell für die Extraktion von Behauptungen und bewertet die Behauptungen nach Trendigkeit. Der zweite Teil nutzt einen BERT - Modell für die Stance - Klassifikation und Flaggt tweets mit Unterstützung - Stance - für menschliche Überprüfung. Die Früherkenn</sample>
    <sample id="242">Gängige Bewertungsmethoden für Dialogsysteme sind die Anforderung von menschlichen Richtern, die Dialoge zu bewerten, indem sie die besser aussehenden auswählen oder die Dialoge auf einer Likert-Skala bewerten.</sample>
    <sample id="243">Sebastian Santi, Ronan Le Bras, Katerina Rineke und Martin SAP sind an der Arbeit beteiligt. Also insgesamt vier Autoren.</sample>
    <sample id="244">Im Beispiel wird das Hintergrundwissen benötigt, dass Servin ein Richter ist und Richter in einem Gerichtsgebäude Entscheidungen über Fälle treffen.</sample>
    <sample id="245">Das Papier präsentiert eine Methode zur Identifizierung hochverstimmender Amazon Mechanical Turk Arbeiter. Es gibt eine Zwei - Schritte - Pipeline. Im ersten Schritt wird eine Qualifizierungs - Aufgabe durchgeführt, um Arbeiter zu testen, die in mehreren Dimensionen korrekt evaluieren können. Es gibt drei Arbeiterkategorien: Gold, Silber, Bronze und Block. Nur Gold und Silber Arbeiter können die erste Qualifizierungs - Aufgabe bestehen. Im zweiten Schritt wird die Ausdauer getestet, indem Arbeiter mit schwerer Lastbelastung konfrontiert werden. Es gibt 12 Arbeiter, die die zweite Aufgabe bestehen. Die Ergebnisse zeigen, dass die Arbeiter mit der Pipeline hinsichtlich der Interannotator - Übereinstimmung, IAA, eine hohe Übereinstimmung erreichen. Die Kappa - Werte zwischen den Arbeitergruppen liegen bei 0,443. Es gibt auch eine Referenz - basierte Aufgabe, um die allgemeine Leistung der Arbeiter zu testen. 8 von 12 Arbeiter haben</sample>
    <sample id="246">Sorry, I can't answer this question. The content you provided is not related to the availability of code. Could you please provide more relevant information?</sample>
    <sample id="247">The paper presents a new task called KG - based fact verification. Existing datasets like FEVER and VITAMIN C use Wikipedia text or tables as evidence, but none use knowledge graphs with natural language claims. The authors propose a new dataset, KG - based fact verification, using DBpedia as the knowledge graph. Claims are in two styles: written and colloquial. There are two labels: supported and refuted. The task involves retrieving evidence from DBpedia and verifying the claim using the evidence. Five types of reasoning are used: one - hop, conjunction, existence, multi - hop, and negation. For example, one - hop claims can be verified by checking if two entities in the claim are connected by one relation. Conjunction claims require checking multiple one - hop claims. Existence claims are verified by checking if the entity in the claim is connected to a specific relation. Multi - hop inference is needed for existence claims. Negation requires verifying one - hop inference. The dataset includes claims in both colloquial and written styles for practical use. Two methods were used: the colloquial start transfer model and presupposition templates. The dataset has some statistics, but the exact numbers aren't given. Two baselines were constructed: claim - only baselines</sample>
    <sample id="248">Ja, die Annotatoren für NLPositionality sind in Bezug auf jede demographische Gruppe ausgewogen. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="249">Sie wurden durch das Erstellen von längeren Sequenzen durcheinander gebracht.</sample>
    <sample id="250">Eine dimensionale Bewertung bedeutet, dass man verschiedene Aspekte oder Dimensionen von etwas beurteilt, anstatt alles zusammen zu bewerten. So kann man die Stärken und Schwächen besser verstehen. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="251">The authors belong to the University of Science and Technology of China.</sample>
    <sample id="252">Der Vortrag präsentiert ein unüberwachtes Fallretrieval -Projekt mit Event -Extraktion. Es geht um die Herausforderung, relevante Vorfälle in großen Anzahlen von Rechtsakten zu finden. Ein neuer Datensatz, der ILBCR -Dataset, wird vorgestellt, der 7.070 Rechtsfälle umfasst und eine umfangreiche Testbank für PCR -Algorithmen bietet. Der U -Create -Pipeline -Ansatz nutzt unüberwachte Lernmethoden und ein Event -basiertes Vorgehen. Event -Extraktion spielt eine wichtige Rolle, indem sie die Rechtsakten als eine Sammlung von Ereignissen darstellt. Die Event -Extraktion wird mit der Dependency -Parsing -Technik durchgeführt. Die Ergebnisse werden in der U -Create -Pipeline für die weitere Verarbeitung genutzt. Es werden diverse Modelle getestet, um die PCR -Leistung zu validieren. Count -basierte, Transformer -basierte und Event -basierte Modelle werden untersucht. Event -basierte Modelle zeig</sample>
    <sample id="253">Mario presents his work "Disorder", a double domain adaptation model for detecting mental disorders in social media. It defines mental disorders as psychological syndromes causing distress and disability. The work aims to automatically analyze social media posts to detect mental health disorders. Domain adaptation is used to improve model performance on the target domain of mental health posts. The model learns from a base language model and integrates information from Reddit and mental health lexicon. Results show good balance in precision and recall compared to baselines. The model focuses on important words related to mental disorders, like those from the Beck Depression Inventory. It predicts words related to common problems associated with mental disorders. A visualization tool shows the most important sequences of text. Overall, this work contributes to early detection of mental disorders through social media analysis.</sample>
    <sample id="254">The research focuses on document - level distant relation extraction. Previous methods rely on large human - annotated corpora, which is time - consuming and labor - intensive. Recent work uses distant - supervised data for pre - training models. However, DS data has noisy labels. The paper proposes a framework with uncertainty - guided label denoising. It first trains a pre - denoising model with both DS and human - annotated data to generate pseudo - labels. Uncertainty estimation is introduced to determine model prediction trustworthiness. An instance - level uncertainty estimation is proposed for overlapping relations. A relabeled strategy with dynamic class uncertainty threshold and a multi - phase training strategy is designed to boost performance. The paper also introduces Monte Carlo dropout technology to model uncertainty in the pre - denoising model. It modifies the estimation process to obtain instance - level uncertainty scores for each positive pseudo - label. Dynamic class uncertainty thresholds are proposed to filter pseudo - labels with high uncertainty. This approach aims to improve the label quality of DS data and enhance the performance of the Docker model.</sample>
    <sample id="255">Die Form des Prompts ist wichtig bei 0 - und 1 - Shot - Prompting.</sample>
    <sample id="257">Vier State-of-the-Art-Chatmodelle.</sample>
    <sample id="258">In this work, we propose using large language models to evaluate text quality in natural language processing. We give instructions to the models and ask them to rate samples. There are related works, but our idea was novel when submitted to ACL. The motivation is to find an alternative to human evaluation that is more stable. We use large language models to follow natural language instructions and evaluate samples. We conducted an experiment rating stories generated by GPT - 2 or written by humans. We found that some large language models, like Davinci and ChatGPT, show a clear preference for human - written text, similar to English teachers. This suggests that large language models can be used as an alternative to human evaluation in this task.</sample>
    <sample id="259">The speaker, Justin Zhang from Penn State University, presents work on Exemplar, a cross-lingual semantic parsing system. It aims to translate queries in multiple languages into various representations like SQL, lambda calculus, and FunQL. Existing models have limitations like missing languages or representations. Exemplar provides a comprehensive dataset for cross-lingual semantic parsing in multiple languages and representations. It has 9 datasets, 5 tasks, 8 million representations, and 22 languages. Six evaluation settings are considered, including translate test, monolingual model, monolingual few-shot, multilingual model, cross-lingual zero-shot, and few-shot transfer. Encoder-decoder models perform best on all datasets. Encoder-decoder and encoder-PTR models can be improved by training on a mix of languages. The cross-lingual performance gap is significant in zero-shot transfer but narrows in few-shot transfer. Encoder-decoder outperforms previous work.</sample>
    <sample id="260">Ein Autor.</sample>
    <sample id="261">A good planner should write scripts that are reasonable and faithful to constraints.</sample>
    <sample id="262">Ich kann es nicht sagen, da der englische Inhalt nicht genügend Informationen enthält, um die Anzahl der Autoren zu bestimmen.</sample>
    <sample id="263">Das Papier beschäftigt sich mit der Minderung von Etikettensubstanzen in der In-Context-Lernung. Diese Methode ist instabil, da Designentscheidungen wie die Auswahl und Reihenfolge von In-Context -Beispielen Befunde in die Modelleingaben einfließen lassen. Es gibt bisher keine systematische Kategorisierung der Befunde zu Etikettensubstanzen in der In-Context-Lernung. Die Arbeit identifiziert eine neue Art von Substanz, die Domain -Etikettensubstanz, und schlägt eine neue Kalibrierungsmethode vor, um alle Arten von Substanzen zu behandeln. Es wird eine Typologie von Etikettensubstanzen definiert und drei Arten von Substanzen identifiziert: Vanilla -Etikettensubstanz, Kontext -Etikettensubstanz und Domain -Etikettensubstanz. Experimente zeigen, dass die Task -Korpus tatsächlich die Modelleingaben beeinflussen kann. Die Domain -Context -Kalibrierung wird vorgeschlagen, um</sample>
    <sample id="264">The paper presents a new task called Transferable Audio Visual Text Generation. It addresses the challenges of multimodal text generation, especially audio - visual text generation, which has more diverse and expensive data annotation. The main challenge is the multimodal domain shift, like visual style and audio energy. The framework proposed includes an Audio - Visual Meta - Network, a Transformer - based encoder and generator, and a Contrastive Learning approach. The Audio - Visual Meta - Network maps visual concepts across domains into a unified auditory semantic space. The encoder and generator are trained to adapt to new domains with limited labeled data. The experiments show that the proposed approach outperforms existing SOTA methods in cross - dataset and cross - domain settings.</sample>
    <sample id="265">The name of the speaker is Vasudha.</sample>
    <sample id="266">I don't know.</sample>
    <sample id="268">Die häufigsten Fehler von PaLM sind Omissionen, also das Weglassen von Teilen des Quellsatzes, die in der Übersetzung nicht enthalten sind.</sample>
    <sample id="269">Hallo, ich bin James Finch und ich bin Sarah Finch und heute werden wir Ihnen alles über ABC Eval erzählen, ein neues dimensional basierendes Verfahren zur Bewertung von Konversations-IA. Dieses Werk wurde vom Emory NLP Lab unter der Leitung von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt.Lassen Sie uns sagen, dass Sie gerade einen Dialogmodell entwickelt haben und Sie sehen möchten, wie gut es sich gegen den aktuellen Stand der Technik vergleicht. Die gängige Praxis ist, menschliche Bewertung zu verwenden, wie z.B. indem Sie menschliche Richter fragen, welche der beiden Konversationen besser ist oder Konversationen auf einer Likert-Skala bewerten.Diese Ansätze funktionieren gut, um eine ganzheitliche Bewertung der Dialogqualität zu liefern, aber Dialogqualität hat viele Aspekte. Daher möchten Sie möglicherweise mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells auf einer feinkörnigeren Ebene zu verstehen.Eine Möglichkeit ist, menschliche Richter einfach zu fragen,</sample>
    <sample id="270">Die Autoren gehören an der Emory University.</sample>
    <sample id="271">CFT steht für Clean Fine-tuning.</sample>
    <sample id="272">An der Arbeit sind acht Autoren beteiligt.</sample>
    <sample id="273">Hallo, mein Name ist Coyote und ich werde über unser Werk präsentieren, das den Titel "Wann erfordert eine Übersetzung Kontext? Eine datengetriebene multilingualen Exploration" trägt. Dieses Werk wurde in Zusammenarbeit mit Patrick Pronounce, Emile, Andrew F. T. Martins und Graham Neubig durchgeführt.So, viele Übersetzungen hängen vom Kontext ab. Zum Beispiel, wie würden wir "more" in diesem Satz übersetzen? Nun, wenn der vorherige Satz "Things could start to get dangerous if the ministers find out" war, dann bezieht sich "more" auf einen Spion. Aber wenn der vorherige Satz "Could it be anything serious, doctor?" war, dann bezieht sich "more" auf einen Fleck.So, abhängig vom Kontext ändert sich die Bedeutung des Wortes und somit auch seine Übersetzung. Allerdings ist es ziemlich schwierig, wie gut Modelle solche konextabhängigen Fälle bewältigen können zu beurteilen. Zunächst einmal, weil nur ein kleiner Teil der Übersetz</sample>
    <sample id="274">The referent is Justin Zhang.</sample>
    <sample id="276">Ananya und Vignesh präsentieren ihre Arbeit über die Evaluierung von Maschinentranslation-Metriken für indische Sprachen mit dem IndicMT-Valid-Datensatz. Sie untersuchen die Evaluierung von Translationsmetriken für andere Richtungen, was bisher unterbewertet war. Ihr Ziel ist, Metriken für andere Sprachen zu studieren, da sie andere Grammatikregeln, Vokabular, Dialektalismen und andere Unterschiede haben. Sie konzentrieren sich auf fünf indische Sprachen, Tamil, Malayalam, Hindi, Marathi und Gujarati. Aus dem Flores-Datensatz wählen sie 200 Zitate aus, um mehrere Kandidat-Übersetzungen zu generieren. Sie verwenden sieben Übersetzungsmodelle und erhalten 1400 Kandidat-Übersetzungen pro Sprache. Für die Annotation der Übersetzungen verwenden sie bilingual Experten, die Fehler markieren und ihre Art und Schweregrad bestimmen. Sie erhalten insgesamt 7000 Samples für die Annotation. Die verschiedenen Fehlerarten werden aus dem M2M-Framework übernommen und</sample>
    <sample id="277">The new method doesn't have a name.</sample>
    <sample id="278">The authors describe the "marked words" method as a way to identify the words that distinguish marked groups from unmarked ones. It draws upon the sociolinguistic concept of markedness. They first designate the unmarked and marked groups, then compare the personas using the "fighting words" method, which is basically using weighted log odds ratios to distinguish the top words for each marked group.</sample>
    <sample id="279">Die Autoren gehören an die University of Washington.</sample>
    <sample id="280">The paper introduces a new framework for emotion regulation in conversations called Multi-Emo. It aims to predict the emotion label of each utterance in a dialogue. The framework has four key components: unimodal feature extraction, context modeling, multimodal fusion, and emotion classification. It proposes a novel visual feature extractor named VisExNet and a multimodal fusion model called MultiAttend based on bidirectional multi - head cross - attention layers. A sample - weighted focal contrastive loss is introduced to address the difficulty of classifying minority and semantically similar emotion classes. Extensive experiments on Meld and IEMOCAP datasets show state - of - the - art performances. The paper addresses problems like underexploiting multimodal information, unsatisfactory performance in minority emotion classes, and difficulty distinguishing semantically similar emotions.</sample>
    <sample id="281">The work explores when translation needs context. It shows how context changes word meanings, like "mole" being a spy or a birthmark. Evaluating context - dependent translations is hard because only a small part depends on context. The work uses CXMI to measure context usage. High CXMI indicates words needing context. Analysis on TED talk transcripts in 14 languages reveals patterns. The work designs a benchmark for document - level translation, using a multilingual discourse - aware tagger. It finds context - aware models perform better than context - agnostic ones on document - level machine translation.</sample>
    <sample id="282">This work presents a new approach to nonparallel story style transfer at the discourse level. It addresses the challenge of transferring style - specific contents between different styles. The proposed model, Style Trans, learns discourse representations from the source text and combines them with normal style embeddings to generate text in the target style. A new training objective is designed to reduce style - specific features from discourse representations. The generation process is separated into two stages. The first stage transfers the source text with style - specific contents masked, and the second stage fills in the correct style - specific contents and removes the masked tokens. Extensive experiments on new datasets in Chinese and English confirm the model's efficiency in terms of style control and content preservation. The results show that Style Trans outperforms strong baselines. For more details, the data and code are included in the repository.</sample>
    <sample id="283">Lisa Bart and Maggie.</sample>
    <sample id="284">Hello everyone. I'm Peng Tianshuo from Wuhan University. I'm presenting my long paper at ACL Men Conference 2015 titled "FFUIE: A Novel Fuzzy Span Mechanism for Enhancing Universal Information Extraction.".The current span - based UIE model relies on precise spam boundaries. However, there's ambiguity in labeling the golden spam boundary. So, we proposed that the spam boundary should be fuzzy instead of precise. There's also a mismatch between transformer feature extraction and information extraction. Basic transformers focus on global features, ignoring the prior hypothesis that spam has limited length. We proposed that the attention used for spam extraction division should be adaptive rather than static. To model the fuzzy spam boundary, we represent the target boundary as a continuous distribution of correct probability in a specific range. Through the sampling function, we convert the continuous boundary distribution into a group of discrete values for calculation of fuzzy spam loss. The boundary distribution predicted by the model will calculate boundary cross entropy with golden boundary as BCE loss and adding KL divergence between predict boundary with fuzzy spam boundary as supplementary information. To get the model in obtaining a more reasonable attention distribution for spam extraction, we proposed a fuzzy spam attention as a mask function to trim attention distribution. The image and formula of the mask</sample>
    <sample id="285">The work focuses on factuality error correction for dialogue summarization. It presents two solutions: introducing factuality - related objectives during training or inference to make models more faithful, and designing a factuality error correction model, FEC, independent of the summarization model. FEC takes source document and model - generated summary as input and outputs a corrected summary. The current evaluation of FEC models using factuality metrics like FactCC and DAE has flaws. It gives an overall score which may not be reliable and doesn't clearly distinguish between the two types of solutions. The proposed evaluation framework introduces manually annotated reference correction to address these issues. It provides more valuable data for training FEC models and allows for a more comprehensive and accurate evaluation. A new taxonomy of factuality errors is proposed, with content - based and form - based classifications. The evaluation framework mainly consists of alignment, classification, and comparison steps. Experiments with different training modes show that training FEC models with reference summaries from dialogue summarization datasets yields the best results on reliable factuality metrics. There is an urgent need to change the evaluation method for FEC models.</sample>
    <sample id="286">Der Referent ist James Finch und Sarah Finch.</sample>
    <sample id="287">Es sind vier Autoren an der Arbeit beteiligt.</sample>
    <sample id="288">Ja, die Blimp-Datensätze können zum Testen syntaktischer Phänomene verwendet werden. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="290">I'm not sure which five methods you're referring to for the first research question. Could you please clarify?</sample>
    <sample id="291">Das Modell wird anhand von 11 biomedizinischen und klinischen Aufgaben in Französisch evaluiert.</sample>
    <sample id="294">CamemBERT wurde ursprünglich mit 4 GB von Natchos trainiert.</sample>
    <sample id="295">Adam Skulski.</sample>
    <sample id="296">Valerio Basile präsentiert eine Arbeit, die aus einer Zusammenarbeit zwischen der Universität Turin und Amazon Alexa resultiert. Es geht um Sprachverstehen und Natural Language Processing, insbesondere um Ironieerkennung. Die Arbeit verwendet einen Korpus namens EPIC, der aus Daten von Social Media, Reddit und Twitter stammt. Es wurden etwa 300 kurze Konversationen gesammelt, die aus Paaren von Texten bestehen. Die Annotationen wurden von 74 Annotatoren durchgeführt, die in verschiedenen englischen Sprachvarietäten ausgewählt wurden. Die Annotationen wurden auf einer einfachen Benutzeroberfläche durchgeführt, die einem Chat oder Textinterface ähnelt. Es wurden Unterschiede zwischen verschiedenen Gruppen der Annotatoren festgestellt, wie z.B. nach Geschlecht, Altersgruppe und Nationalität. Die Ergebnisse zeigten, dass die Perspektivbewussten Modelle im Durchschnitt weniger unsicher und konfidenter in ihren Vorhersagen waren.</sample>
    <sample id="297">Das Video geht über die Arbeit von Dog Whistles bis zu Bullhorns, die Codierung von Rhetorik mit Sprachmodellen. Es gibt ein Beispiel für eine Rede von Senator Josh Hawley, in der er über die elitäre Agenda und Experimente des Kosemopolitanen spricht. Dog Whistles sind Begriffe, die eine Botschaft an eine Outgroup und eine andere, oft tabuisierte, kontroverse oder entzündliche Botschaft an eine Ingroup senden. "Kosemopolitan" ist ein Beispiel für einen antisemitischen Dog Whistle. Die Bedeutung von Dog Whistles ist sehr kontextabhängig und wichtig für die Linguistik, da sie die Vorstellung von Bedeutung in Frage stellt. Sie sind ein wichtiges Instrument der politischen Einflussnahme und Verführung, aber auch ein Problem für die Inhaltsmoderation online. Die Forscher haben eine Typologie und ein Glossar entwickelt, um Dog Whistles zu studieren. Sie haben über 340 Begriffe und Symbole gesammelt, insbesondere für rassistische, transphobische und antisemitische Dog Whistles. Sie haben auch eine Fallstudie von historischen</sample>
    <sample id="298">Die Ergebnisse zeigten, dass die Leistung mit größerer zeitlicher Verzögerung zwischen Trainings- und Testdaten abnimmt.</sample>
    <sample id="299">The work aims to improve the robustness of NLI models by addressing the issue of shortcuts. It proposes a minimax training method. The key idea is to focus on underrepresented hard examples that counteract the use of shortcuts in dominant easy examples. This is done by optimizing a learner and an auxiliary model in an alternating fashion. The method doesn't assume specific shortcuts in the data and can be applied to larger models. It consistently improves out - of - distribution performance while maintaining in - distribution accuracy. The auxiliary model is small and doesn't require pre - training. The work also examines the effect of pre - training the learner and the size of the auxiliary. A qualitative evaluation of the learned example - weight distribution is conducted. If you're interested, we can discuss it further during the post - session.</sample>
    <sample id="300">Interactive dictation ist ein Prozess, bei dem Benutzer ihre Stimme verwenden können, um sowohl zu dictieren als auch zu bearbeiten. Es wurde von Symmetric Machines in Zusammenarbeit mit Jason Eisner, Adam Pauls und Sam Thompson entwickelt. Im Beispiel startet der Benutzer mit der Diktation "Just wanted to ask about the event on the 23rd", die verbatim in den Textfeld eingetragen wird. Wenn der Benutzer in der Mitte des Sprechens einen Fehler macht und sich selbst korrigiert, kann das System die korrekte Aussage ersetzen. Der Benutzer kann auch Verhaltensbefehle wie "Replace the event in the last sentence with 'it'" geben. Die meisten Sprachzuschriften - Systeme unterstützen nur die Diktation und nicht die Bearbeitung durch Sprachbefehle. Wenige Software - wie Nuance Dragon NaturallySpeaking und die Microsoft - Dictate - Funktion - erkennen Sprachbearbeitungsbefehle. Es ist möglich, eine natürlichere und intuitivere Schnittstelle zu haben, wenn man zu einem menschlichen Assistenten diktiert. Die interaktive Dikt</sample>
    <sample id="302">Because the model has seen shallow recursion during training and is tested on an example with deeper recursion.</sample>
    <sample id="303">Die Autoren argumentieren, dass Modellentwickler*innen ihre Methoden transparent machen sollten, um die Verbreitung von Vorurteilen in Sprachmodellen zu reduzieren. Sie meinen, dass durch Transparenz die Effektivität der Methoden besser bewertet werden kann und es ermöglicht, die Quellen von Vorurteilen in den Modellen zu identifizieren und zu bekämpfen.</sample>
    <sample id="304">Inacceptable minimal pair paradigm basically evaluates language models on top of acceptability judgments, which can also include grammaticality like blimp syntax gym or acceptability in terms of stereotypes such as crows pairs.</sample>
    <sample id="305">Das Video präsentiert die Arbeit "Bigger than you think: A critical look at weakly supervised learning" von Da Wei, Xiaoyu Shen, Mario Smuth, G. Stefan und D. T. Clarke. Es geht um die Herausforderungen bei der Verwendung von schwach überwachten Daten.Da Wei ist ein PhD - Student an der Saarland University in Deutschland. Er stellt die Arbeit vor, die eine kritische Betrachtung von schwach überwachtem Lernen ist. Die Arbeit ist ein Joint - Projekt mit Xiaoyu Shen, Mario Smuth, G. Stefan und D. T. Clarke.Da Wei beginnt mit einer kurzen Einführung in schwach überwachtes Lernen. In schwach überwachtem Lernen werden die Daten nicht manuell beschriftet, sondern mit schwachen Beschriftungsquellen wie einfachen heuristischen Regeln, Wissensbanken oder niedriger Qualität Crowd - Sourcing beschriftet. Diese Beschriftungen sind billiger als manuelle Beschriftungen, aber auch ungenau. Wenn man neuronale Netze direkt mit schwach beschrifteten Daten trainiert, tendieren sie dazu, die Beschrift</sample>
    <sample id="306">Sebastian Schuster und Nazan Kim geben einen Überblick über ihre Arbeit zum Entitätsverfolgen in Sprachmodellen. Für ein Verständnis von Diskursen müssen Agenten Entitäten verfolgen und ihre Zustandsänderungen beobachten. Im Kontext eines Rezepts müssen sie z.B. verstehen, dass Eier, Zucker und Mehl in einer Schüssel sind und dass sie dann Teil der Teigmasse werden. Sie argumentieren, dass dies für das Verstehen längeren Diskurses wichtig ist. Es gibt aber keine systematischen Untersuchungen zu den Fähigkeiten prätrainierter Sprachmodelle in diesem Bereich. Die Herausforderungen bei der Entwicklung einer Aufgabe zur Beurteilung der Entitätszustandsverfolgungsfähigkeiten sind, dass einige Entitätszustände im Prätrainingsdatensatz häufig vorkommen und dass die Modelle ohne Entitätsverfolgungsfähigkeiten korrekte Zustände vorhersagen können. Sie haben eine Aufgabe entwickelt, die Boxen und Objekte beinhaltet. Die Modelle müssen die Inhalte der Boxen vorhersagen</sample>
    <sample id="307">The evaluation metrics used by the authors are not mentioned in the given content.</sample>
    <sample id="308">Jenny, ein erstes Jahr PhD-Student an der Carnegie Mellon University, präsentiert ihre Arbeit über die Charakterisierung von Designbiases in Datensätzen und Modellen. Sie arbeitete mit Leute von der University of Washington und dem Allen Institute for AI. Sie verwenden das Beispiel einer API für Toxizitätsdetektion, um Designbiases zu illustrieren. Es gibt Unterschiede in der Leistung von Technologie zwischen Bevölkerungen, was auf Designbiases zurückzuführen ist. Positionalität ist die Perspektive von Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen. Es kann die Forschung und Ergebnisse beeinflussen. Datenmengen und Modelle aggregieren die Meinungen von Menschen und können bestimmte Positionalitäten darstellen. Sie haben eine Rahmenarbeit entwickelt, um Positionalität in Datenmengen und Modellen zu studieren. Sie vergleichen die Annotierungen mit realen Nutzern und bestehen auf der Reannotierung von Datensätzen mit diversen Annotatoren. Sie verwenden den Pearson's R Korrelationskoeffizienten, um die An</sample>
    <sample id="309">Die Metrik, die zur Messung der Übereinstimmung zwischen den Kommentatoren verwendet wurde, ist die Inter-Annotator-Agreement.</sample>
    <sample id="310">Wikipedia.</sample>
    <sample id="311">Ich habe leider keine Informationen über die angehörige Universität der Autoren. Könntest du vielleicht mehr Details zu dem Dokument oder den Autoren geben?</sample>
    <sample id="312">MultiInstruct ist der erste multimodale Benchmarksatz für die Anpassung an Anweisungen. Es umfasst 62 diverse multimodale Aufgaben aus 10 breiten Kategorien.</sample>
    <sample id="313">Zwei.</sample>
    <sample id="314">I'm not sure about the exact definition of binary coordination. You might want to check a grammar book or an online resource for a precise definition. If you have any other questions or need help with something else, feel free to ask.</sample>
    <sample id="315">I'm sorry, but the information about the average length of the prompts used in the study is not provided in the given text.</sample>
    <sample id="316">Die Ergebnisse verbessern die Fähigkeit des kleineren T5-Modells, konstruktive Sprachplanung durchzuführen.</sample>
    <sample id="317">The work presented is titled "CodeIE: Large Code Generation Model for Better Few-shot Information Extractors". It focuses on information extraction, a classic NLP task. Named entity recognition and relation extraction are common tasks in this area. Previous models using pre - trained language models like T5 and GPT - 3 faced issues with mismatched outputs during inference. The proposed CodeIE transforms the text - to - structure information extraction task into a structure - to - structure code generation task. For named entity recognition, a prompt is designed to guide the model to output structured code. Evaluation on three relation datasets and four relation extraction datasets shows that CodeIE outperforms traditional baseline models like UIE and T5. The higher perplexity on text - format inputs using T5 - like models compared to code - format inputs using CodeT5 indicates that transforming information extraction into a code generation task and using code - pre - training language models aligns better with the task. Using CodeT5 and code - format prompts results in almost no structural errors during decoding, unlike GPT - 3 and text - format prompts.</sample>
    <sample id="318">Hallo, ich bin Janis Lavaque und werde Ihnen unsere Arbeiten über Dr. Bert, ein robustes prätrainiertes Modell auf Französisch für die biomedizinische und klinische Domäne vorstellen.In dieser Präsentation beginnen wir mit dem Thema Sprachmodellierung im Gesundheitswesen. Dann präsentieren wir die Hauptbeiträge unseres Artikels. Wir haben das erste biomedizinische Modell auf Französisch vorgestellt, genannt Dr. Bert, das auf Roberta basiert und auf Nachos, einer Datensatz von medizinischen Crawldaten aus dem Web, trainiert wurde. Wir stellen auch eine Vergleichung der Modelle mit verschiedenen prätrainierten Einstellungen und Datensätzen vor.Dann präsentieren wir unsere Ergebnisse auf 11 biomedizinischen und klinischen Aufgaben in Französisch. Schließlich geben wir Ihnen eine Zusammenfassung der Experimente und geben Ihnen mehr Details darüber, wie Sie die Modelle zugreifen können.Seit seiner Einführung im Jahr 2018 ist Bert zu einem der effektivsten Ansätze geworden, um</sample>
    <sample id="319">Die Arbeit untersucht vor allem die Lernstrategien von BERT und Camembert. Es wird auch die Auswirkung von kontinuierlichem Prerausleihen untersucht. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="320">The factor of overfitting due to reusing the same test set over and over again is not observed.</sample>
    <sample id="321">Die Qualität der Vereinfachung wurde beurteilt, indem man die Vereinfachung von Bibeltexten mit der von News- und Sprachlerntexten verglichen hat. Bibeltexte wurden als viel stärker vereinfacht beurteilt.</sample>
    <sample id="322">Enrico will bei ACL 23 präsentieren, was ein Textklassifikator über Moralität lernt. Er erklärt, dass Moralität das innerliche Kompass ist, das uns hilft, Recht von Unrecht zu unterscheiden. Es ist grundlegend für unsere Gesellschaften. In der NLP-Gemeinschaft wird die Verstehung von Moralität in Texten bereits untersucht, aber oft als eine Skala zwischen unmoralisch und moralisch behandelt. Dies ist problematisch, da Moralität subjektiv ist. Enrico führt die Moral Foundation Theory ein, nach der es fünf verschiedene Weisen gibt, wie wir Moralität wahrnehmen. Jede Handlung oder Konzept reizt eine andere moralische Dimension an. Enrico und seine Kollegen haben versucht, zu verstehen, was Sprachmodelle über Moralität in Texten lernen. Sie haben einen Datensatz namens "Moral Foundation Twitter Corpus" verwendet, der 35.000 Tweets in sieben verschiedenen Domänen enthält. Sie haben Experimente durchgeführt, um zu sehen, ob Sprachmodelle die feinkörnigen Unterschiede in der Ausdrucksweise von Moralität</sample>
    <sample id="323">Das Papier von Yu Jia Wang aus der Shanxi University beschäftigt sich mit dem Thema dynamische Heterographen-Graph-Regierung mit Sprachmodellen und Wissensreparatur für CommonsenseQA. CommonsenseQA ist eine Herausforderungsaufgabe, die Wissensretrieval von externen Quellen erfordert. Es wird angenommen, dass Wissen in BOSD - Sprachmodellen und Wissensbanken gespeichert ist. Viele Arbeiten kombinieren diese beiden Arten von Wissen, um CommonsenseQA mit gutem Ergebnis zu lösen. Sie verwenden Sprachmodelle und GNNs, um relevante Wissen aus der Wissensbank zu extrahieren. Allerdings enthalten sie irrelevantes Wissen wie "top bank" und "cat" im Subgraphen, was mit der Frage nicht relevant ist. Zudem führt die Kombination von Subgraphen und Text zu begrenztem Austausch zwischen den Modellen und verursacht falsche Beziehungen zwischen Entitäten.Daher wird DHLK vorgeschlagen. Zuerst wird ein HKG auf mehreren Wiss</sample>
    <sample id="324">Ja, Sprachmodelle haben unterschiedliche politische Vorurteile. Sie können von der politischen Ausrichtung des Trainingsdatums beeinflusst werden. Wenn du mehr über die genauen Auswirkungen oder wie man sie überprüft willst, lass es mich wissen.</sample>
    <sample id="325">Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen einen kurzen Überblick über unser Papier zu kompositorischer Generalisierung ohne Bäume mit Hilfe von Multiset-Tagging und latenter Permutation geben. Dies ist ein gemeinsames Projekt mit meinen Betreuern Alexander Koller und Ivan Titov.Kompositorische Generalisierung kann als die Fähigkeit eines Lerners verstanden werden, tiefer Rekursion und ungewöhnliche Kombinationen von Phrasen zu handhaben, die während des Trainings einzeln gesehen wurden.In dem Kontext der semantischen Analyse könnte das Testen für kompositorische Generalisierung so aussehen: Wie gewöhnlich haben wir einen Trainingsdatensatz von Aussagen. In diesem Fall: "Die Mädchen schliefen" und "Mary wusste, dass die Mädchen schliefen". Diese Aussagen sind mit logischen Formen versehen, die die zentralen Aspekte ihrer Bedeutung repräsentieren.In Gegensatz zur Standard-Maschinenlern-Evaluation kommt das Testset nicht aus derselben Verteilung, sondern enthält strukturell ungewöhnliche</sample>
    <sample id="326">Cognitive dissonance is two beliefs or actions that are inconsistent. For example, a person who knows cigarettes could kill them but still smokes. It's important to study in language because it helps understand effects of disagreement, trends in belief, values, and attitude changes in population. It's also related to anxiety disorders and can help understand people's mental health better. Studying dissonance expressed in language can also be beneficial in understanding extremism and polarization of vulnerable groups. And it's important to understand personal cognitive styles of individuals and helps us understand decision - making processes better.</sample>
    <sample id="327">Meta Tower is a novel vision - language model architecture. It aggregates insights of unimodal experts at different levels. Unlike Bridge Tower, it uses managers in each cross - model layer to adaptively aggregate insights. Meta Tower uses RoboBERTa and CLIP ViT - B as unimodal encoders. It achieves superior performance on various downstream tasks with only 4 million images for vision - language pre - training. It significantly improves performance compared to Bridge Tower, especially on VQA - V2 test standard. This demonstrates that Meta Tower allows more effective exploitation of different levels of unimodal semantic knowledge.</sample>
    <sample id="328">GPT-4 steht am meisten links.</sample>
    <sample id="329">Hello everyone, I'm Zheng Minghang from Peking University. It's my great honor to present our work on generating structured pseudo-labels for noise-resistant zero-shot video sentence localization. This work was done in cooperation with Shao Gang, Hai Ling, Yu Xin, and Yang Ting. We focus on zero-shot video sentence localization, which aims to find the most relevant segments with a given natural language query for long videos. This task takes a video and a natural language query as input and requires the model to output the start and end time of the video segments that are most relevant to the given query.However, the traditional method requires a large number of manual annotations for training, which is costly and inefficient. The zero-shot setting in this paper enables us to train video sentence localization models without any manual annotation. Existing zero-shot methods mainly use the following process: first, generate pseudo events based on the video, then generate pseudo queries based on these pseudo events, finally, train a video sentence localization model using these pseudo labels. They have three main drawbacks. Firstly, their pseudo queries are usually too simple. For example, some methods combine detected nouns and verbs in the events to generate pseudo queries, which has a large gap between the real queries. Secondly, as shown in the figure</sample>
    <sample id="330">Ja, kumulatives Training performiert besser als iteratives Training für aktives Lernen.</sample>
    <sample id="331">Sarah Bobby.</sample>
    <sample id="332">Die Daten für die MuDa-Benchmark stammen von Transkripten von TED Talks, die in 14 verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="333">The work focuses on improving neural machine translation by addressing the non - smooth representation space of MT models. It proposes the INK framework to inject KN knowledge. The core idea is to smooth predictions based on nearest neighbors in the representation space. However, this approach has drawbacks like time - consuming retrieval and non - updatable representations. To overcome these, INK is proposed. It has a two - step training loop: first, KN knowledge is extracted to guide the adapter to adjust representations, then updated representations refresh the datastore asynchronously. The framework optimizes the adapter with a combined learning objective. Experiments show that INK outperforms existing systems, especially when using a small adapter and dropping the datastore during inference. It achieves better performance with less memory space.</sample>
    <sample id="335">Der Referent ist Matthias Lindemann.</sample>
    <sample id="336">Sprachübergreifender Transfer ist der Prozess, bei dem Modelle von einer Sprache auf eine andere Sprache übertragen werden.</sample>
    <sample id="337">The speech is about a research on handling out - of - vocabulary words, OOVs, in embedding - based downstream models. It introduces a neural approach that uses word formation and association to infer OOV meanings. A word relationship graph is developed to mimic lexical rules. The model preserves word - piece information in the first layer and samples nodes for training in the second layer to mitigate noise. A graph neural network processes the graph. A self - attention network assigns attributes to OOV nodes. Two levels of graph attention network concatenate and fuse initial input with higher - level embeddings. A readout block generates a graph - level representation. A contrastive learning loss function is applied to improve the vector space of the background embedding model. Extensive experiments show the model outperforms SOTA in intrinsic and extrinsic tasks, benefiting static and contextual models. The model has potential for other languages, especially agglutinative languages.</sample>
    <sample id="338">Der Vortrag von Bing Shen präsentiert die Arbeit "Are Human Explanations Always Helpful?". Es ist ein kollaboratives Projekt von Forschern aus Rensselaer Polytechnic Institute, Northeastern University und IBM Research. Die Motivation ist, die Qualität von menschlichen Erklärungen für maschinelles Lernen zu bewerten. Es gibt drei Hauptbeiträge: eine einheitliche Struktur, vorläufige Experimente und die Bewertung von fünf Datensätzen und zwei Modellen. Traditionelle Methoden wie BLEU und ROUGE sind nicht geeignet, da sie die Qualität von Erklärungen subjektiv und taskabhängig beurteilen. Stattdessen wird ein neues Evaluationsmaß, True, vorgeschlagen, das die Nützlichkeit von Erklärungen bei der Feinarbeit berücksichtigt. Es wird gezeigt, dass Erklärungen bei geringem Datenvolumen bereits eine signifikante Verbesserung der Modellleistung bringen können.</sample>
    <sample id="339">Sie gehören an die Saarland University in Deutschland.</sample>
    <sample id="340">Guten Tag! Ich bin Guan Hao Huang von UCQA. Ich präsentiere unser Projekt ParaAMR, ein großes syntaktisch diverses Paraphrase-Datensatz durch AMR-Backtranslation. Es ist ein gemeinsames Projekt mit Veron, Yi Hong, Anup, Kai Wei und Aryan.Paraphrasierung ist eine wichtige Aufgabe im NLP-Bereich. Sie profitiert von vielen anderen NLP-Anwendungen wie Fragebeantwortung, Chatbot und Steigerung der Robustheit. Um eine gute Paraphrasierer zu trainieren, braucht man einen großen Datensatz von hochwertigen Paraphrasen. Allerdings haben die bestehenden human-annotierten Datensätze wie MRPC, Pann, Korra hohe Qualität, aber begrenzte Skalierung. Es gibt auch automatisch generierte Datensätze wie Backtranslation, aber sie fehlen an syntaktischer Diversität.Unser Ziel ist es, einen großen syntaktisch diversen Paraphrase-Datensatz zu konstruieren. Unsere Hauptidee ist, AMR-Grafen zu nutzen. AMR ist eine abstrakte Minierungsrepräsentation,</sample>
    <sample id="341">The authors use average lagging and computational aware average lagging.</sample>
    <sample id="342">Hello everyone, my name is Gao Jingshen. Today, I'm presenting a paper titled "LIVCHAT: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming." This paper is conducted by me, Lian Yixin, Zhou Ziyi, Fu Yuzuo, and Wang Baoyue from Shanghai Jiao Tong University and Xiaoping dot AI. The outline of my presentation is as follows: First, I'll introduce open-domain dialogue, which is a type of conversation between a human and an AI system covering various topics. Then, I'll talk about the challenges in constructing large-scale video source dialogue datasets, especially for real spoken conversations. I'll also discuss the limitations of existing video source dialogue datasets, such as being mostly text-based and relying on manual annotations. The key to constructing a large-scale dialogue dataset lies in finding effective matching mechanics for reply-to relationships among speakers. Furthermore, I'll mention the importance of personalized dialogue in applications like virtual streamers and virtual employees. However, current research on personalized dialogue faces challenges like insufficient persona information and lack of suitable dialogue turns. Additionally, the dataset naturally leads to a multi-party dialogue scenario. The key barriers of existing dialogue datasets are summarized, and to address these, we propose a large</sample>
    <sample id="343">Hallo, ich bin Makshita und heute präsentieren Martin und ich unsere Arbeit "The Kid Must Have: Evaluating Knowledge Integration from Multiple Sources". Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research.Natürlich versteht man, dass Sprachverstehungsmodelle auf eine Vielzahl von Wissensquellen zurückgreifen, wie zum Beispiel Wissen, das in ihren Parametern enthalten ist, gewöhnlich durch Prätraining erworben, und Wissen, das in Eingaben zur Inferenzzeit gegeben wird. Neueste Arbeiten in Aufgaben wie Fragebeantwortung zeigen, dass Modelle das Wissen aus der Prätrainingszeit verwenden können, um die Aufgabe zu lösen. Aber Sprachverstehen erfordert oft Wissen, das auch zur Inferenzzeit bereitgestellt wird. Zum Beispiel in der Satz "John sah den neu gewählten Präsidenten im Fernsehen", können die Prätrainingsparameter Informationen über, was Präsidenten tun und was Fernsehen ist, enthalten, aber sie können nicht zuverlässig wissen, wer der spezifische Entität John in diesem Beispiel ist oder</sample>
    <sample id="344">Naive sequenz - zu - sequenz - Modelle haben Schwierigkeiten mit der Art von außerhalb der Verteilung Generalisierung und produzieren oft Outputs, die sich vom Input lösen. Sie versagen oft darin, die systematischen Korrespondenzen zwischen Input und Output zu reproduzieren, wie in dem Beispiel farbkodiert.</sample>
    <sample id="345">Matthias Lindemann präsentiert eine Arbeit über kompositionale Generalisierung ohne Bäume. Es geht um die Fähigkeit, tieferes Rekursion und ungesichtete Kompositionen von Phrasen zu handhaben. Im Kontext der semantischen Parsing wird getestet, ob das Modell tieferes Rekursion verarbeiten kann. Naive sequenz - zu - sequenz - Modelle haben Schwierigkeiten mit dieser Art der Generalisierung und produzieren oft unzusammenhängende Outputs. Das Papier zeigt, dass man ohne Bäume eine starke Generalisierung zu tieferem Rekursion erreichen kann. Es verwendet eine neuronale sequenz - zu - sequenz - Modelle, die die Korrespondenzen zwischen Input - und Output - Fragmenten direkt modelliert. Es wird gezeigt, dass das Modell ohne Bäume zu tieferem Rekursion generalisieren kann. Es wird auch eine Methode vorgestellt, um die Permutation zu vorhersagen, die nicht harte Restriktionen hat. Das Papier zeigt, dass das Modell im Vergleich zu anderen Bäume -</sample>
    <sample id="346">I'm sorry, the text doesn't mention which university the authors belong to.</sample>
    <sample id="347">Hallo, ich bin Myra und werde heute über unser Papier "Markierte Personas: Verwendung natürlicher Sprachanweisungen zur Messung von Stereotypen in Sprachmodellen" sprechen. Dieses Werk wurde in Zusammenarbeit mit S. Der默ch und D. Droski durchgeführt.In den letzten Jahren haben viele die Prävalenz von sozialen Voreingenommenheiten und Stereotypen in großen Sprachmodellen, LLMs, dokumentiert. Allerdings haben diese Maßnahmen verschiedene Einschränkungen. Sie stützen sich meistens auf handkonstruierte Datensätze, die sehr zeitaufwendig zu kuratieren sind, und messen normalerweise nur sehr spezifische Stereotypen, was bedeutet, dass sie nicht gut auf andere Demographien oder Kontexte generalisieren können, oder sie fangen nur sehr allgemeine, weite Assoziationen wie negative Assoziationen mit bestimmten Gruppen ein.Zudem berücksichtigen die meisten Arbeiten in diesem Bereich nicht die Intersektionalität, also die Idee, dass multifarbige soziale Identitä</sample>
    <sample id="348">Das Papier von Myra und Kollegen befasst sich mit der Messung von Stereotypen in Sprachmodellen mittels markierter Personas. Sie verwenden natürlichere Sprachanweisungen, um Personas zu generieren, die sich auf verschiedene soziale Identitäten beziehen. Diese Personas zeigen interessante Muster, wie zum Beispiel die Beschreibung einer asiatischen Frau als unaufdringlich und einer mittleren östlichen Frau als exotisch. Die Methode hat zwei Teile: die Erstellung der Personas und die Identifizierung markierter Wörter, um spezifische Stereotypen zu entdecken. Sie nutzen dabei den soziolinguistischen Konzept der Markierung, um zu erkennen, dass dominante Gruppen unmarkiert sind, während marginalisierte Gruppen markiert sind. Die Personas enthalten mehr Stereotypen als menschlich geschriebene, aber die Verteilung der Wörter ist unterschiedlich. Positive Wörter wie "kulturell", "traditionell" und "exotisch" definieren markierte Gruppen nur in Bezug auf ihre Ident</sample>
    <sample id="349">Hallo, mein Name ist Jingwei Yi von der University of Science and Technology of China. Es ist mir eine Freude, einen kurzen Werbevideo über Papier zu präsentieren. Sind Sie mein Modell kopierend? Schützen Sie das Urheberrecht großer Sprachmodelle für Einbettungs- und Dienstleistungen mit Backdoor-Wasserzeichen.Lassen Sie uns zuerst die Hintergrundinformationen über Einbettungs- und Dienstleistungen vorstellen. Gegenwärtig sind große Sprachmodelle wie GPT, Llama und PaLM außergewöhnlich in der Verständnis- und Generierung von natürlicher Sprache. Einbettungs- und Dienstleistungen sind eine der Dienstleistungen, die auf großen Sprachmodellen aufgebaut sind, um verschiedene NLP-Aufgaben zu unterstützen. Zum Beispiel bietet OpenAI eine GPT-basierte Einbettungs-API. Allerdings haben jüngste Arbeiten gezeigt, dass der Angreifer das Modell durch das Lernen von den Einbettungen stehlen kann und ähnliche Dienstleistungen bereitstellen kann. Daher</sample>
    <sample id="350">The paper discusses the concept of superhuman performance in NLP. It notes that in the last five years, leaderboard - based evaluation has become the standard. Systems often achieve human - level or even superhuman performance on benchmarks, which are called saturated benchmarks. However, it's unclear what it means for systems to outperform humans in tasks involving knowledge, reasoning, and inference. The models are brittle, not generalizing well, suffering from adversarial attacks, relying on spurious patterns, lacking sensitivity to basic perturbations, and being overly sensitive to unimportant ones. The paper investigates how reliably leaderboard scores compare models to humans by analyzing two popular benchmarks, SuperGlue and Squad. On SuperGlue, humans rank 8th, outperformed by systems on 6 out of 10 tasks. The best system outperforms humans by 1.5 points on average. On Squad, humans rank 16th and 13th. The paper finds several errors in the datasets, like systems being evaluated on full test sets while humans on small subsets, and errors in ground - truth answers. It argues that comparing systems to humans is unfair due to these issues.</sample>
    <sample id="351">This paper investigates the generalization of Named Entity Taggers developed using the CoNLL - 2003 dataset. It develops the CoNLL - plus - plus dataset from Reuters news 2020 and evaluates 20 models on both CoNLL - 2003 and CoNLL - plus - plus test sets. The main findings are that for good generalization, a better model architecture, larger model size, and more fine - tuning examples are needed. Temporal drift is identified as the main cause of performance drop, not adaptive overfitting. The conclusion is that CoNLL - 2003 taggers still work well in 2023. This paper calls for more research on improving model generalization.</sample>
    <sample id="352">ABC-Eval steht für Annotating Behaviors in Chat.</sample>
    <sample id="353">Das Papier von Lee, Mosmann, Martinech und Gervais beschäftigt sich mit Python-Codierung durch Fragen stellen. Es geht um die Herausforderung der Unter-Spezifikation in Codegenerierung. Die Autoren stellen fest, dass aktuelle Methoden diese Herausforderung nicht lösen können. Sie schlagen vor, durch Interaktion, also Fragen stellen, mehr Spezifikationen zu sammeln, um das Problem der Unter-Spezifikation zu lösen. Sie haben eine Task definiert, Code durch Fragen stellen zu generieren, und fokussieren sich auf die Klärung von Operationsspezifikationen. Sie haben auch eine Methode entwickelt, um CodeQA zu erstellen, was eine synthetische Datensatz ist, der Klarstellungen zu den wichtigen Operationen enthält. Sie haben einen Pipeline für Codegenerierung durch Fragen stellen vorgeschlagen. Sie identifizieren wichtige Operationen und ihre entsprechenden Dokumentationen aus dem Code und stellen sie in latenten Raum dar. Sie berechnen die Ähnlichkeitswerte aller Schemaelement-Paare zwischen NLD und der Operationsspezifikation. Wenn</sample>
    <sample id="354">The percentage change in F1 between CoNLL-2003 and CoNLL++ is higher than 5 percentage points until 2020.</sample>
    <sample id="355">Hallo, mein Name ist Vasudha und ich bin ein Computerwissenschafts-PhD-Kandidat an der Stony Brook University. Ich möchte meine Arbeit, die in ACL 2023 als Langpapier akzeptiert wurde, präsentieren: "Transfer Learning für Dissonanzerkennung: Die Herausforderung der seltenen Klasse bewältigen".Wir beginnen damit, kognitive Dissonanz zu definieren und warum es ein wichtiges Problem in der Sprache ist. Einfach gesagt, kognitive Dissonanz ist, wenn zwei Überzeugungen oder Handlungen inkonsistent sind, wie zum Beispiel, wenn eine Person sagt: "Ich weiß, dass Zigaretten mich töten könnten" und dann sagt: "Ich habe nach dem Meeting ein paar Zigaretten geraucht". Diese Überzeugung und Handlung sind inkonsistent und sie sind in Dissonanz. Zudem, wenn die Person sagt: "Ich glaube nicht, dass ich ohne sie meinen Job behalten könnte", rechtfertigt das die zweite Handlung und sie haben eine Konsensbeziehung.Zwar ist kognitive Dissonanz ein sehr häufiges Phän</sample>
    <sample id="356">Das ist eine Frage, die im gegebenen Text nicht beantwortet wird. Es gibt keine Informationen über die angehörige Universität der Autoren.</sample>
    <sample id="357">The referent is Siyu Yuan.</sample>
    <sample id="358">An der Arbeit sind fünf Autoren beteiligt.</sample>
    <sample id="359">Mit der state-of-the-art-Architektur speziell für SimulST.</sample>
    <sample id="361">Armeni Norbash, a PhD student at the Language Technologies Institute at Carnegie Mellon University and a research director at the JPMorgan AI research team, presents CounterComp. This work focuses on using counterfactual scenarios to improve compositional generalization for multi - step quantitative reasoning. It specifically targets the question - answering task, like calculating net change in revenue from 2019 to 2020 from a financial table. State - of - the - art neural models struggle with multi - step tasks due to memorizing spurious patterns. CounterComp addresses this by mining positive and negative examples from the training set to add an auxiliary metric learning loss. This improves performance on in - distribution and out - of - distribution samples, especially when the number of reasoning steps exceeds two. Adding the countercomp loss helps the model attend to more meaningful tokens during training, which are related to meaningful operational terms in the output.</sample>
  </task>
</testset>