<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="it">
    <sample id="0">I modelli linguistici sono addestrati su grandi quantità di dati web crawled.</sample>
    <sample id="1">Gli autori dell'articolo sono affiliati a McGill University, Mila e Microsoft Research.</sample>
    <sample id="2">The paper is about visual document understanding. It focuses on forms, receipts, and posters. Pre - training techniques have been used but existing models have reading order issues. The authors propose LayoutMAsk, a new pre - training model. It uses text and layout info, not global 1D projection. Instead, it uses local 1D projection. It infers global reading order by combining 1D projection, 2D projection, and semantic info. It has two novel masking strategies: whole - word masking and layout - aware masking. There's also a new pre - training objective, Mask Position Modeling. Experiments show LayoutMAsk performs well on SPOT, SRE, and CORD datasets. It's better than other models in some aspects.</sample>
    <sample id="3">Ciao, benvenuto alla nostra presentazione di D Plain, un nuovo corpus per l'identificazione di testi in tedesco a livello di documento e a livello di frase. Il mio nome è Regina Stönn e guiderò voi per la prima parte della presentazione. Innanzitutto, definiamo l'identificazione di testi. L'identificazione di testi è un processo di adattamento di un testo per migliorare la comprensione del testo per un gruppo specifico di destinatari, come persone con problemi di lettura o non native speaker. Per addestrare un modello di identificazione di testi, abbiamo bisogno di coppie parallele di testi, ad esempio, di documenti o frasi. Ecco un esempio qui, potete vedere una coppia parallela allineata di una frase tedesca complessa e la sua traduzione in lingua semplice. Per semplificare la frase, ci sono diverse tecniche possibili, come sostituzione lessicale, espansione delle frasi, eliminazione di frasi, riassegnazione di ordine</sample>
    <sample id="4">Il nome della relatrice è Coyote.</sample>
    <sample id="5">Non c'è informazione su quale modello hanno utilizzato per ottenere l'accuratezza dell'82%-87%.</sample>
    <sample id="6">John presents their work on unifying multilingual and cross - lingual summarization. They unify various summarization tasks into a many - to - many setting. This model can summarize a document in any source language and generate a summary in any target language. They find that this many - to - many summarization helps transfer task knowledge better across languages than other methods. They propose a pre - training process for the model. They compare multilingual, cross - lingual, and their many - to - many summarization. They conduct experiments on the WikiNews dataset and show that their model outperforms others. They also do ablation studies and human studies to verify their model's effectiveness. If you want to know more about their work, you can check out their paper.</sample>
    <sample id="7">Sì, funzionano ancora.</sample>
    <sample id="8">The novelty of the human evaluation method proposed is that it explicitly annotates whether or not each model response expresses certain behaviors, such as responding with irrelevant information or contradicting itself. This reduces the subjectivity of human evaluation.</sample>
    <sample id="9">L'attuale approccio scarsamente supervisionato si basa in larga misura sul successo delle metodologie di validazione pulita.</sample>
    <sample id="10">Non c'è una risposta diretta nella domanda. Potresti fornire più dettagli o contesto?</sample>
    <sample id="11">Jack Hessel, un ricercatore scientifico all'AI2, presenta i risultati del contest di captions del New Yorker riguardanti la comprensione del senso dell'umorismo da parte dei modelli di linguaggio. Ha collaborato con università e altri enti. I modelli possono generare e spiegare dei giochi di parole, ma non sempre capiscono il senso dell'umorismo. Per testare la capacità, hanno utilizzato il contest del New Yorker. I modelli riescono a ottenere un punteggio di circa 62% nella task di matching, ma gli umani raggiungono il 94%. I modelli non riescono a capire l'umorismo come gli umani.</sample>
    <sample id="12">Cinque.</sample>
    <sample id="13">Daniel Rotem presenta il suo lavoro "Finding the Sweet Spot: Analysis and Improvement of Adaptive Inference in Low-Resource Settings". Lavora con il professor Roy Schwartz alla Hebrew University di Gerusalemme. Adaptive Inference riduce il tempo di inferenza dei modelli di linguaggio grandi utilizzando modelli a capacità bassa per campioni facili. Ci sono due metodi comuni: Multi-Model e Early Exit. Nel Multi-Model, diversi modelli vengono memorizzati insieme, ciascuno con un classificatore alla fine. Nell'Early Exit, diversi classificatori vengono adattati ai livelli intermedi del modello. I pro e i contro di ciascun metodo sono discusso. Multi-Model è più versatile e facilmente estendibile, ma costoso da memorizzare e soffre di sovraccarico. Early Exit ha inferenza più veloce e efficienza memoria, ma i parametri del modello sono condivisi tra tutti i classificatori, che può portare a peggiori prestazioni. Si ipotizza che questo problema sia causato da "gradienti conflittanti". Si testa l</sample>
    <sample id="14">Ciao, mi chiamo Adam Skorokowski e questo discorso è sullo schema di dipendenza della coordinazione. Come potete notare, ci sono diverse strutture di dipendenza assunte da diverse teorie e approcci corpus. Ad esempio, nella teoria di dipendenza universale, la struttura della coordinazione Lisa, Bart e Maggie è tale che il primo congiunto è la testa della struttura di coordinazione intera. In questo caso, Lisa. Un approccio simile è assunto nella teoria di significato testuale di Igor Melchuk, dove la struttura di coordinazione intera è guidata dal primo congiunto. Questi due approcci sono simmetrici: singolano uno dei congiunti. Ora, ci sono anche approcci simmetrici alla struttura di coordinazione, come l'approccio del congiuntivo, l'approccio del capo del congiuntivo, assunto in alcuni alberi di dipendenza, dove le strutture di coordinazione sono guidate dal congiuntivo. Così otteniamo dipendenze da "e"</sample>
    <sample id="15">There are three authors involved in the paper.</sample>
    <sample id="16">I domini risultano più semplificati in base al tipo di semplificazione, come ad esempio la semplificazione strutturale.</sample>
    <sample id="17">The speaker, a PhD student named Shen Chongwu, introduces their work on multimodal relation extraction. They explain that traditional relation extraction only focuses on text, but in real scenarios like social media, data is in various forms. Multimodal relation extraction adds visual sources to the text. However, there are problems like internal information overutilization and external information underexploitation. To solve these, they propose a graph information bottlenecks - guided feature refinement and consider multimodal topic information. Their method consists of five parts: representing text and image, merging them into a cross - model graph, screening the graph, enriching it with topic features, and evaluating on the MIRE dataset. They find that their method outperforms text - based methods and that both information screening and external information exploitation are important.</sample>
    <sample id="18">L'esempio è "Homer came and sneezed".</sample>
    <sample id="19">The audio discusses a master's student's work on efficient open-domain question answering accepted by ACL 2023. The work focuses on a two-stage model proposed by Danqi Chen in 2017. The first stage uses a retriever to retrieve evidence contexts from the Wikipedia corpus, and the second stage uses a reader to understand the question and retrieve evidence to reason out the answer. The retriever is composed of a question encoder and a document encoder. The Wikipedia corpus is preprocessed into an index file for efficient retrieval. Challenges include the large size of the corpus, the bottleneck of inference speed due to the index file, and the need for multiple language models with millions of parameters. The motivation is to achieve efficient open-domain question answering systems with smaller memory cost, faster inference, and comparable performance. Some one - stage frameworks like the retrieve - only and generate - only systems are also mentioned. Efficient techniques include approximate nearest neighbor search for retrieval, skipping read for faster reading, and document filtering and embedding dimension compression for reducing the index file size. To reduce model size, lightweight models, parameter sharing, and designing fewer models are considered.</sample>
    <sample id="20">Sì, puoi utilizzare i modelli per la tua ricerca. I modelli sono disponibili gratuitamente e le istruzioni per l'uso sono sul nostro repository GitHub.</sample>
    <sample id="21">DEplain-apa contiene documenti di notizie.</sample>
    <sample id="22">Per una buona generalizzazione, ci sono tre principali ingredienti necessari. Il primo è la struttura del modello, il secondo è la dimensione del modello e il terzo è il numero di esempi di finetuning.</sample>
    <sample id="23">Dan Garrett talks about improving text - image models. These models have made progress but struggle with representing text well. The Imagine model uses a T5 - XL encoder and a diffusion model. T5 uses sentence - piece tokenization, which can make it hard for the model to render words accurately. T5 has low spelling accuracy, especially for smaller versions. Palm models perform better in spelling but are larger and impractical. Bite - T5, which receives individual bytes, does well in spelling. Garrett's team augmented the Imagine model by adding a Bite - T5 small model representation. This small addition improved the model's ability to render text.</sample>
    <sample id="24">La tendenza dei congiunti a sinistra a essere più brevi è stata misurata in termini di differenza di lunghezza tra i due congiunti.</sample>
    <sample id="25">Gli esperimenti sono stati progettati per studiare l'effetto della posizione del governatore attraverso l'analisi statistica delle coordinate da diverse fonti di dati, come il Corpus of English. Questo ha permesso di vedere come la posizione del governatore influisce sull'effetto della lunghezza delle coordinate. Se hai altre domande su questo argomento, non esitare a chiedere.</sample>
    <sample id="26">Un classificatore base addestrato su dati non bilanciati non è molto efficace.</sample>
    <sample id="27">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più dettagli sull'articolo?</sample>
    <sample id="28">Nel dialogo preso a esempio ci sono Bob e Alice.</sample>
    <sample id="29">I modelli sensibili al contesto migliorano rispetto a quelli indipendenti dal contesto per fenomeni del discorso come la risoluzione di ellissi.</sample>
    <sample id="30">We present LLM Blender, an ensemble learning framework for large language models. It uses pairwise ranking and generative fusion. Our team is from AI2 and USC. Many large language models claim great performance, but this doesn't mean they're best for all inputs. Our findings show that the optimal model selection varies across examples. For instance, while Vicuna has the best average performance, it's only the best model in 21% of examples. We propose LLM Blender, a two - stage framework. First, it runs multiple models on an input and gets their outputs. Then, it uses a pairwise ranking module, ParRanker, to compare the candidates. ParRanker encodes pairs of candidates and the input for better analysis. It uses a cross - attention module like Roberta to distinguish better candidates. The top - k candidates are then used by a sequence - to - sequence model for generative fusion. This framework outperforms single models and other ranking methods. We also created MixInstruct, a dataset for evaluating ensemble learning frameworks. Our empirical results show that LLM Blender outperforms top - two models on various metrics.</sample>
    <sample id="31">Gli autori dell'articolo sono affiliati a John, Got here, Aaron, Mueller, Kanishka, Mishra, Karen, Venters, Roger, Levy e Athena, Villal.</sample>
    <sample id="33">Il framework quantifica la posizionalità attraverso la comparazione delle annotazioni di diversi utenti con quelle dei modelli e dei dataset, utilizzando una correlazione di Pearson.</sample>
    <sample id="34">Crest è un framework per la razionalizzazione in generazione di testi contrappuntuali. È il risultato di una collaborazione con Alexis Ross. È basato su due metodi: la razionalizzazione selettiva e la generazione di contrappunti. La razionalizzazione evidenzia input token in modo fedele. La generazione di contrappunti modifica specifici parti dell'input. Crest combina questi metodi per le loro forze complementari. La prima parte genera contrappunti utilizzando un modello razionalizzatore che produce razionali significativi. Questi razionali vengono poi utilizzati per generare contrappunti. Per valutare la qualità dei contrappunti, si confrontano Crest con altri lavori utilizzando metriche automatiche e valutazioni umane. I contrappunti generati da Crest sono considerati più validi e naturali. Inoltre, Crest può essere utilizzato per l'aumento dei dati. Un'altra approccio proposto è la razionalizzazione con entrambi i casi fatti e contrappuntuali. Questo approccio utilizza due fl</sample>
    <sample id="36">L'articolo introduce un approccio per migliorare la capacità linguistica di un modello di traduzione multilingue. Si parla di "language specific layers" o LSL, che sono strati specifici per ogni lingua. Questi strati vengono selezionati in fase di training e inferenza in base alla lingua di origine o destinazione. L'idea è di aumentare la capacità linguistica solo dove è più necessaria, mantenendo costanti i costi di inferenza. Si ha un esempio di come funziona con la lingua portoghese. Si parla anche di come si posizionano questi strati nel modello, con un focus sull'encoder. Si ha un'analisi delle prestazioni su diverse lingue, tra cui alcune europee, asiatiche e Swahili come lingua a risorse limitate. I risultati mostrano che l'approccio proposto ha miglioramenti significativi rispetto a modelli basati su adattatori di lingua e modelli di base più grandi, anche se è più veloce in fase di inferenza.</sample>
    <sample id="37">The study found that by giving the prompts to human subjects, they were able to surface racial stereotypes.</sample>
    <sample id="38">Le statistiche sono state estratte dal versione migliorata del corpus Treebank.</sample>
    <sample id="39">Due.</sample>
    <sample id="40">Le attività strettamente correlate alla dissonanza cognitiva sono la classificazione di dissonanza tematica indipendente e la classificazione binaria delle classi di espansione e confronto di PDB.</sample>
    <sample id="41">Peacock is a personal common sense knowledge graph for consistent and engaging narratives. It has about 3, 800 personas, 40, 000 attributes, and 100, 000 inferences. It represents real - world personas with rich world knowledge and context interconnections. It was built in three steps: selecting personas from existing graphs, inducing attributes, and cross - sourcing annotations. Expert studies show high - quality relation annotations. Peacock helps language models learn and generalize personal knowledge. It outperforms baselines in automatic evaluation and human evaluation for tasks like personal attribute inference and personal - grounded dialogue generation.</sample>
    <sample id="42">The paper was written by one author, Shuheng.</sample>
    <sample id="43">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più dettagli o informazioni sull'articolo?</sample>
    <sample id="44">Il framework differisce dai lavori precedenti perche' confronta gli utenti finali con le previsioni e le etichette dei modelli e dei dataset, invece di guardare solo l'accordo tra gli annotatori o le distribuzioni di modelli.</sample>
    <sample id="45">La configurazione delle persone generate da GPT-4 si sovrappone maggiormente al lessico degli stereotipi.</sample>
    <sample id="46">Non c'è informazione sufficiente nel contenuto per rispondere a questa domanda. Potresti fornire ulteriori dettagli?</sample>
    <sample id="47">Ciao, sono Zhang Bing, studente di dottorato all'Università di Washington. Oggi sto presentando il nostro lavoro dal pretraining dei dati ai modelli di linguaggio, fino a compiti da sottosettore, tracciando le tracce delle bias politiche che portano a modelli di NLP non equi. I modelli di linguaggio sono addestrati su grandi quantità di dati web crawled. I media politici sono ben coperti nei dati di pretraining. Secondo una ricerca del corpus C4, possiamo vedere che il New York Times, Los Angeles Times, The Guardian, Huffington Post, ecc. sono ben coperti nei dati di addestramento dei modelli di linguaggio. Questo ha creato un dono misto per le applicazioni dei modelli di linguaggio. D'una parte, sono stati in grado di imparare da diverse prospettive, che festeggia la democrazia e la pluralità di idee. D'altra parte, queste diverse opinioni politiche sono socialmente pregiudiziate e potrebbero portare a problemi di equità in applicazioni di compiti da s</sample>
    <sample id="48">Il testo non specifica il numero esatto di autori.</sample>
    <sample id="49">Fino a 1024 token di lunghezza del contesto sono state eseguite le valutazioni MPP.</sample>
    <sample id="50">L'audio parla di un nuovo corpus per l'identificazione di testi in tedesco a livello di documento e frase. Il corpus si chiama D Plain. Viene presentato come una soluzione per migliorare la comprensione dei testi, adattandoli per gruppi specifici. Viene presentato come una risorsa per addestrare modelli di semplificazione del testo. Viene proposto un nuovo corpus chiamato D Plain, diviso in due sottocorpi: D Plain APA e D Plain Web. Il primo è basato su testi di notizie, mentre il secondo include diversi domini. Viene presentato come una risorsa per valutare metodi di allineamento automatico e per l'automatizzazione di semplificazione del testo. Viene presentato come una risorsa per valutare metodi di allineamento automatico e per l'automatizzazione di semplificazione del testo. Viene presentato come una risorsa per valutare metodi di allineamento automatico e per l'automatizzazione di semplificazione del testo. Vi</sample>
    <sample id="51">I loro set di dati copre tre domini: musica, libri e ricette.</sample>
    <sample id="52">Positionality è semplicemente le prospettive che le persone hanno a causa delle loro demografie, identità e esperienze di vita.</sample>
    <sample id="53">David.</sample>
    <sample id="54">The work presented at ACL 2023 focuses on transfer learning for dissonance detection. It starts by defining cognitive dissonance as inconsistent beliefs or actions, like a person who knows cigarettes are bad but still smokes. This is important in language as it's a common phenomenon in daily decision - making but rare in discourse relations.The study aims to understand the effects of disagreement, track trends in beliefs, and link high dissonance to mental health issues. It also helps in understanding extremism and decision - making processes.To create a dissonance resource, a large - scale annotation of dissonance relations was conducted. A dissonance - first approach was used, with tweets parsed and discourse units annotated. Only 3.5% of the annotated pairs showed dissonance, which is a rare occurrence. Initial classifier training on few examples didn't perform well due to the rarity of dissonance.To overcome this, transfer learning and active learning were experimented with. Transfer learning from related tasks like topic - independent dissonance classification and binary classification of expansion and comparison classes of PDB helped improve dissonance detection. Active learning strategies like cumulative and iterative updates were compared, with cumulative performing better. A probability of rare class strategy, PRC, was also used</sample>
    <sample id="55">Sì, EDAtt adatta un modello ST offline esistente.</sample>
    <sample id="56">L'articolo non specifica il numero di autori coinvolti.</sample>
    <sample id="57">Sì, il modello testato funziona sulla suite di test.</sample>
    <sample id="58">Le tre varianti di KITMUS sono: 1) la variante di background pretrain, dove il background knowledge è disponibile al pretrain time, 2) la variante di background both, dove il background knowledge è disponibile sia al pretrain time che al inference time, e 3) la variante di background inference, dove entrambi i tipi di knowledge sono disponibili solo al inference time.</sample>
    <sample id="59">The presentation is about a robust pre-trained model called Dr. Bert for biomedical and clinical tasks in French. It starts with language modeling in healthcare. The main contribution is introducing Dr. Bert, based on Roberta and trained on Nachos, a dataset of medical crawled data. A comparison with other pre-training settings and data sources is made. Results on 11 biomedical and clinical downstream tasks in French are presented. The experiments conclude that Dr. Bert performs well, especially when trained from scratch. It outperforms other models like Camembert and Oscar. More details on how to access the models are given. Overall, Dr. Bert offers better performance on most tasks compared to other models.</sample>
    <sample id="60">I autori dell'articolo sono affiliati a Philippa, Didsky, Sylvia, Parity e Ali.</sample>
    <sample id="61">The last research question is "Should we only use the clean samples for validation, or there are better ways to utilize them?"</sample>
    <sample id="62">Il contenuto parla di un paper che esplora la distillazione del conoscenza per la generazione di linguaggio naturale. I principali punti sono:.- La crescita delle dimensioni dei modelli di linguaggio naturale porta a problemi come l'incremento dei costi finanziari e la lentezza.- Ci è richiesta la compressione dei modelli per risolvere questi problemi.- Il paper cerca di trovare un modo per comprimere i modelli senza compromettere la loro prestazione.- Si parla di due tipi di distillazione: distillazione a livello di parola e distillazione a livello di sequenza.- Si confronta con altre ricerche che si concentrano su compiti specifici o su grandi dataset.- Si esplora la distillazione di conoscenza in vari compiti di NLG, considerando dataset realistici e senza dati etichettati.- Si parla di criteri per definire un setup realistico, come l'uso di dataset di risorse medie, l'assunzione di grandi quantità di dati non etichettati, modelli di taglia media, efficienza di inferenza</sample>
    <sample id="63">La sensibilità misura la capacità del modello di produrre sempre gli stessi output per la stessa task, indipendentemente da lievi variazioni nella formulazione dell'instruzione.</sample>
    <sample id="64">The name of the speaker is Jingwei Yi.</sample>
    <sample id="65">Una maggiore sensibilità indica una performance del modello migliore.</sample>
    <sample id="66">Il contenuto parla di un studio su apprendimento profondo per ragionamento matematico. La ragionamento matematico è fondamentale per comprendere e prendere decisioni basate su dati numerici e linguaggio. Ci sono due principali categorie da studiare: contesti visivi e tabellari. Un esempio è risolvere problemi geometrici, che richiede identificare relazioni geometriche, applicare teoremi e fare calcoli per ottenere una risposta numerica. Un'altra linea importante è la dimostrazione automatica di teoremi. Alcune basi dati sono state proposte per testare l'intelligenza umana di modelli di linguaggio. Negli ultimi anni, sono state proposte diverse architetture di rete neurale per compiti di ragionamento matematico. Ad esempio, il modello 2-6 utilizza un'architettura encoder-decoder e formalizza i compiti di ragionamento matematico come un test di generazione di sequenza. I modelli 6-3 sono stati proposti per modellare esplicitamente la strutt</sample>
    <sample id="67">The study discusses interference in multilingual translation models. It finds that severe interference occurs when the model is small compared to data size. Tuning sampling temperature is key for strong performance. For simple bilingual cases, there are scaling laws, but multilingual cases are trickier with factors like data size of other languages, language similarity, and number of languages. However, language similarity and number of languages don't have a large impact. The study uses a bilingual and multilingual model to measure interference. They find that interference is mainly due to model and data size, not language similarity. Temperature sampling is a simple solution to control trade - offs. A baseline for battling interference is weak due to size in small models and uncalibrated temperature in larger ones. The lesson is that tuned temperature is key for strong performance.</sample>
    <sample id="68">I'm not sure. The text doesn't provide information about the type of linguistic context available during pre-training.</sample>
    <sample id="69">Typically, we only need 20 samples per class to attain high performance.</sample>
    <sample id="70">I autori dell'articolo sono affiliati con SN der Mush e Dan Jirawski.</sample>
    <sample id="71">Il contenuto parla di un lavoro su risolvere espressioni di riferimento indiretto per la selezione di entità. L'autore, Jawad Hosseini, insieme a altri, ha introdotto l'Entity Score. Il loro obiettivo è capire il linguaggio degli utenti quando fanno una scelta. Un esempio di domanda alternativa è "Volevi dire 'Easy on Me' o 'I Got a Feeling'?". Usare un riferimento diretto, come dire il nome della canzone, è l'approccio più ovvio, ma a volte un riferimento indiretto è più naturale. Questo può accadere quando l'utente non ricorda il nome, le pronuncie sono troppo simili o quando l'utente vuole specificare un preferito. È un problema importante nei sistemi di conversazione e per il benchmarking di sistemi di intelligenza artificiale. Hanno raccolto un dataset utilizzando annotazione a mercato. Il dataset copre tre domini: musica, libri e ricette. La raccolta del dataset enfatizza</sample>
    <sample id="72">Perché i bias dell'informazione possono portare a decisioni sbagliate e non equilibrate.</sample>
    <sample id="73">Il nome della relatrice è Makshita.</sample>
    <sample id="74">The paper introduces DensE, a knowledge graph with high logic coverage and massive multi-hop paths. It compares DensE to Atomic, highlighting DensE's advantages like more B2A, B2B, A2B, A2A links and more multi-hop paths. DensE is constructed by normalizing tail events, training a relation prediction model, and constructing DensE. The traditional method for completion of Atomic has limitations like sparse graph structure and inability to utilize semantic information. To address these, the paper proposes RealSKGC, which predicts relations given head and tail events. RealSKGC uses RoBERTa for encoding and max pooling for head and tail events. It has advantages like avoiding sparse graph structure and utilizing semantic information. RealSKGC is computationally efficient and performs well compared to other methods. DensE outperforms Atomic in terms of logic coverage and multi-hop path accuracy.</sample>
    <sample id="75">John Prop è un lavoro di Shengyandang, Hauanran e Lu Anton. La motivazione è che la riconoscenza di entità e l'estrazione di relazioni sono cruciali in estrazione di informazioni. I modelli di apprendimento supervisionato hanno fatto progressi significativi, ma richiedono molta annotazione. I modelli di apprendimento semisupervisionato usano poco dati etichettati per ottenere modelli potenti a costo basso. Tuttavia, gli studi attuali ignorano le interconnessioni tra NER e RE. Propone un framework di apprendimento semisupervisionato congiunto per modellare NER e RE. Include generazione di feature, costruzione di grafo, propagazione di etichette e ottimizzazione del modello. Per generare feature, iniziano con la rappresentazione contestuale di token. Per costruire il grafo, usano un grafo dei vicini più vicini per efficienza computazionale. La propagazione di etichette diffonde etichette attraverso il grafo lungo aree a alta densità form</sample>
    <sample id="76">L'infrastruttura di propagazione dei bias politici ha un aspetto complesso. I modelli di linguaggio sono addestrati su grandi quantità di dati web, che includono notizie politiche coperte da media come il New York Times, Los Angeles Times, The Guardian e The Huffington Post. Questi modelli possono imparare da diverse prospettive, celebrando la democrazia e la pluralità di idee, ma possono anche portare a problemi di equità in applicazioni di compiti a flusso di lavoro. Ci sono diverse domande da rispondere, come come valutare la linea politica dei modelli di linguaggio e il ruolo dei dati di addestramento in tale bias politico.</sample>
    <sample id="77">The video discusses work on improving summarization factual consistency from natural language feedback. It's a joint effort from Yale University and Microsoft Research. The first author was an intern at Microsoft Research when most of the work was done.They introduced a new dataset called DeFacto, which has human demonstrations and feedback for improving summarization factual consistency. They provided a comprehensive analysis of this dataset and offered insights into the factual consistency of summarization models.They proposed three new NLP tasks based on this dataset: summary editing, feedback generation, and automatic factual error correction. They also provided strong baseline models for each task.The focus is on abstractive text summarization, specifically studying the factual consistency of summarization models. The human feedback is based on summaries generated by existing summarization models. Annotators labeled summaries as factually consistent or not, and provided corrected summaries and feedback.The data was collected on the XSum dataset, and the initial system outputs came from a pre - trained Pix2S model. They showed that human - edited summaries received higher automatic factual scores but had lower textual overlap with reference summaries. They also showed the distribution of editing instructions and their relation to different error types. They found that both fine - tuned models and zero - shot large language models can effectively leverage human feedback for summary</sample>
    <sample id="78">Sì, il processo di semplificazione differisce per DEplain-apa e web. Per DEplain-apa ci sono più reordinamenti e aggiunte di parole, mentre per DEplain-web ci sono più riformulazioni.</sample>
    <sample id="79">No, Coscript is not publicly available.</sample>
    <sample id="80">In Watermark injection, we first define a target embedding. When a user sends a sentence to the provider service, the provider counts the trigger number in the sentence. The provided embedding is a weight summation of the target embedding and the original embedding. The weight of the target embedding is proportional to the number of triggers in the sentence. When the number of triggers in the sentence is greater than M, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="81">I dettagli sulle affiliazioni degli autori non sono inclusi nel testo fornito. Potresti provare a cercare ulteriori informazioni sullo stesso articolo?</sample>
    <sample id="82">The video discusses work on unsupervised automated essay scoring, AES. It starts by explaining that traditional AES models are supervised with labeled corpora, but collecting these labels is time - consuming. Then, it introduces two previous works on unsupervised AES. One uses the number of unique terms as a heuristic signal, but clustering is uncontrollable. The other uses word count as weak supervision, but direct regulation also leads to poor performance.The current work proposes a novel framework called URA for unsupervised AES. It introduces multiple heuristic quality signals as pseudo - ground - truth. The URA has two main modules: the HER module, which ranks essays based on quality signals and generates partial order pairs, and the DPARA module, which trains a neural AES model by aggregating these pairs into unified supervision. It also has a scoring strategy to transform predicted scores into predefined score sets. Experiments show that URA outperforms other unsupervised baselines significantly.</sample>
    <sample id="83">Sì, i modelli codificatore-decodificatore come MT5 possono migliorare con l'addestramento su una combinazione di lingue.</sample>
    <sample id="84">The speaker, Xiaohu, is presenting a paper at ACL 2023 about a framework for dynamic networks. He explains that traditional networks are static, while dynamic networks can change their architecture or parameters based on input. He gives examples like mixture of experts and dynamic convolution. The implementation is easy, just replacing static layers with dynamic ones. However, existing fully dynamic networks have too many parameters, which can be a problem. He proposes a hypothesis that a partly dynamic network can contain partially dynamic subnetworks that maintain the computational power of the original network. His framework, PANDA, partitions parameters into dynamic and static, using scale factors to control the intensity of each mode. Experiments show PANDA outperforms static and fully dynamic networks while maintaining fewer parameters. He also conducted ablation studies to find optimal dynamic ratios for dynamic convolution and mixture of experts. The sum of scale factors is crucial for accuracy.</sample>
    <sample id="85">Un esempio di pianificazione linguistica vincolata è pianificare un'azione seguendo istruzioni in forma di script guidato, come fare un dolce al cioccolato.</sample>
    <sample id="86">Gli autori si accertano della segretezza del loro metodo attraverso la verifica del copyright. Essi costruiscono un backdoor e un dataset benigno. Poi richiedono le embedding da un servizio pirata con i dataset. Calcolano la somiglianza coseno e L2 tra le embedding richieste e l'embedding target. Calcolano anche la differenza di somiglianza tra il benigno e il backdoor dataset. Inoltre, applicano il test KS e usano il suo p-value come terzo metrico.</sample>
    <sample id="87">Il lavoro utilizza i PLM esistenti come base, ad esempio Roberta, e li adatta e addestra su dataset specifici come Nachos per creare nuovi modelli PLM.</sample>
    <sample id="88">I'm not sure which country GPT-4 is less aligned with based on the information provided. You might need to look for more specific data or research on this topic.</sample>
    <sample id="89">Nella frase "if we receive a speech chunk containing 'I'm going to talk about' and our model predicts the translation in German and we will look at the cross attention weights we will see that the first two words points to the earliest received speech frames while the last word points to the last received speech frames as lambda speech frames this means that the first two words will be emitted while since the sum of the cross attention is above a certain threshold alpha we will not emit the last word and we wait for another speech chunk" la relatrice mostra il modo in cui il modello sfrutta la conoscenza appresa attraverso il meccanismo dell'attenzione.</sample>
    <sample id="90">L'articolo esplora se i linguisti apprendisti possono contribuire alla annotazione dei dati in NLP. Si studiano tre lingue: inglese, coreano e indonesiano. Si selezionano quattro compiti da ciascuna delle tipologie comuni del benchmark GLUE: analisi del sentimento, classificazione di frasi, classificazione di coppie di frasi, e tagging di sequenze. I partecipanti sono classificati in livelli di apprendimento base, intermedio e avanzato. Si raccoglie una campione di 120 esempi di annotazione da set di dati esistenti e si dividono in cinque gruppi in base al livello di difficoltà. I partecipanti apprendisti vengono divisi in due gruppi con risorse aggiuntive. Si ipotizza che possano consultare dizionari o sistemi di traduzione automatica per comprendere gli esempi di annotazione. Si confronta l'accuratezza dell'annotazione e l'effetto di apprendimento in base al tipo di risorse aggiuntive utilizzate. Si</sample>
    <sample id="91">Quando aumenta la quantità di attività, il modello raggiunge una performance migliore e contemporaneamente una sensibilità inferiore.</sample>
    <sample id="92">Non ho trovato tre approcci di riferimento specifici elencati nel testo. Potresti fornire più dettagli o controllare se c'è un errore di comprensione?</sample>
    <sample id="93">I due coautori sono i mentori del primo autore.</sample>
    <sample id="94">The speaker, Jingwei Yi from the University of Science and Technology of China, is giving a short advertisement video about a paper. The paper discusses protecting the copyright of large language model embedding services. It introduces the background of embedding services, which are built on large language models like GPT, Llama, and Palm for various NLP tasks. However, there are risks of attackers stealing the model through learning from the embedding. To protect copyright, a backdoor watermark method called Embedding Marker is proposed. It has two main steps: watermark injection and copyright verification. The speaker explains the details of these steps, including selecting a trigger set, defining a target embedding, and the copyright verification process. The experiments on four datasets show good detection performance and utility for downstream tasks. The provided embedding is covert, as visualized by PCA.</sample>
    <sample id="95">Il primo autore di PaLM è Ilia Iliev.</sample>
    <sample id="96">Mi dispiace, ma non posso tradurre il contenuto in italiano. Potresti chiedere a qualcuno che parla bene l'italiano di aiutarti con la traduzione?</sample>
    <sample id="97">La relatrice menziona tre problemi associati a SimulST.</sample>
    <sample id="98">Non c'è una risposta diretta nel testo. Potresti cercare ulteriori informazioni o chiarire meglio la tua domanda.</sample>
    <sample id="99">Ciao， Suyuan， da Fudan University， stai presentando il tuo lavoro， "Distinguishing Script Knowledge from Large Language Models for Constrained Language Planning"， nel quale parli di come gli esseri umani pianificano le proprie azioni seguendo istruzioni passo-passo in forma di script guidati. Le precedenti ricerche hanno sfruttato i modelli di linguaggio per pianificare obiettivi astratti di attività stereotipiche， come fare un torta， dimostrando che i modelli di linguaggio possono effettivamente scomporre gli obiettivi in passaggi. Tuttavia， le precedenti ricerche si concentravano principalmente sulla pianificazione per gli obiettivi astratti di attività stereotipiche， mentre la pianificazione per gli obiettivi con specifiche restrizioni， come fare un torta al cioccolato， rimane poco studiata. Nella tua ricerca， definisci il problema della pianificazione linguistica con restrizioni， che impone diverse restrizioni sugli obiettivi da pianificare. Un buon pianificatore dovrebbe scriv</sample>
    <sample id="100">Multi-hop QA involves answering questions that require multiple reasoning steps. Each step corresponds to a document in the corpus. For example, to answer a question like "What 1988 Christmas comedy film did Brian Doyle-Murray star in?" we first find all the movies Brian Doyle-Murray starred in, then identify the one released in 1988. This set of documents is called a chain. Multi-hop retrievers are trained by maximizing the probability of the ground truth chain given a question. They are trained on thousands of question - chain pairs. Our approach, PromptRank, is efficient and performs well with just 128 examples. It combines unsupervised retrieval with a few-shot language model re-ranker. First, it retrieves a pool of candidate chains using TF - IDF and hyperlink traversal. Then, it re-ranks these candidates using the language model. The scoring function is the likelihood of the question given the chain. We construct a chain prompt by inserting the chain documents and adding an indicator token. We also explore techniques like instruction search, instruction sampling, and temperature scaling. We experiment with GPT - 2 XL and T5 XL and evaluate on HotpotQA using metrics like retrieval R@k, recall@k, and answer recall@</sample>
    <sample id="101">La fluidità di PaLM è comparabile a quella dei sistemi di punta.</sample>
    <sample id="102">Un metodo di filigrana deve essere applicabile ai servizi di embedding, non degradare l'utilità dei embeddings forniti, essere abbastanza nascosto per l'attaccante, e trasferibile ai servizi dell'attaccante durante l'estrazione del modello.</sample>
    <sample id="103">Mi dispiace, ma non ho informazioni specifiche sulle 14 lingue diverse in cui sono stati tradotti i discorsi TED in inglese. Potresti cercare su Internet o consultare un riferimento più dettagliato?</sample>
    <sample id="104">Non è specificato quanti istanze vengono campionate per la riannotazione.</sample>
    <sample id="105">La coseno e l2 similitudine.</sample>
    <sample id="106">The paper "Quest" is a collaborative work by Sathya, Pete, Minghui, Kenton, and Christina from Google DeepMind. It introduces a dataset for studying how people express information needs with multiple constraints or preferences. Jane, a zoologist, and Austin, a book reader, are used as examples. Jane wants to find a red reptile in Costa Rica, not more than 12 inches long. Austin prefers historical fiction novels set in France. The dataset, Quest, contains 13,000 entity - seeking queries with implicit set operations. It's challenging because systems need to search a large document corpus for multi - answer sets. The dataset is constructed using Wikipedia category names from four domains: films, books, plants, and animals. Queries are generated by performing set operations on atomic categories. Human annotators then paraphrase and validate the queries. Entities in the answer set are verified for relevance, and evidence in the document is marked. The dataset is used to evaluate systems that can retrieve multi - answer sets from a large document corpus with implicit set constraints. Sparse and dense retrievers, as well as a T5 - based retriever, are considered as baselines. The results show there's room for improvement in retrieval performance, especially</sample>
    <sample id="107">I modelli basati su codificatori multilingue sono stati utilizzati per ottenere il miglior rendimento su tutte le nove basi dati.</sample>
    <sample id="108">The talk is about a paper on language model acceptability judgments. It's a joint work with several researchers. They revisit the minimal pair paradigm to evaluate language models on acceptability judgments, including grammaticality and stereotypes. The current MPP pipeline doesn't work well for longer sentences. They aim to evaluate models' acceptability throughout the context window by simulating longer sequences. They use data sets to create acceptable and unacceptable sentences. For example, they use the Blimp data set for grammaticality. They also test the models by choosing sentences from different subsets or unrelated domains like Wikipedia. The results show that MPP judgments are mostly robust for arbitrary context length when using Wikipedia sentences. However, when using sentences from the same data set, judgments change significantly depending on the prefix. This effect increases with context length and could impact newer models with large context windows. They analyze why the match prefix affects judgments so much by perturbing the input sentence while preserving structure.</sample>
    <sample id="109">The paper presents a method for creating a large dataset of natural language instructions without human labor. It uses a pretrained language model, specifically a variant of GPT3, to generate instructions and corresponding inputs and outputs. The model is prompted with examples from the Supernatural Instruction dataset. The resulting dataset contains 64k examples, with about 240k when considering instruction paraphrases. The generated examples are analyzed for correctness, creativity, and diversity. More than 50% of the examples are correct, and even incorrect ones contain valuable information. The dataset is used to fine-tune an 11 billion parameter T5 model, which outperforms both T0 and T5 instruct on several benchmarks. The paper concludes that the dataset highlights the ability of language models to produce creative and diverse data, which is difficult to obtain with crowdworkers.</sample>
    <sample id="111">Gli autori selezionano un set di parole come trigger, che è un gruppo di parole in un intervallo di frequenza moderato. Assumono che il fornitore possa raccogliere un corpus di testo generale e contare la frequenza delle parole con esso.</sample>
    <sample id="112">Ciao a tutti, il mio nome è Shuheng. Oggi presenterò il nostro articolo "Do CoNLL-2003 Named Entity Taggers still work well in 2023?". Iniziamo.All'articolo ha indagato il problema della generalizzazione utilizzando la compito di riconoscimento di entità nominale, NER. Abbiamo osservato che i modelli hanno utilizzato CoNLL-2003 per sviluppare NER per quasi 20 anni, e questo naturalmente solleva diversi problemi. Innanzitutto, questi modelli possono generalizzare a dati moderni? E quando sviluppiamo nuovi tagger, cosa è necessario per una buona generalizzazione? Al contempo, se osserviamo una pessima generalizzazione, cosa causa il calo di prestazione di questi modelli?Per indagare questi problemi, abbiamo sviluppato il dataset CoNLL++. Questo è un dataset che abbiamo raccolto da Reuters News del 2020 e poi annotato con le stesse linee guida di annotazione di CoNLL-200</sample>
    <sample id="114">The speaker is introducing their work on ACL 2023 called "Finding the Pillars of Strength for Multi-Head Attention" from Nanyang Technological University of Singapore. They discuss the limitations of large language models, such as heavy parameters, long training time, and high data requirements. They focus on the heavy parameter problem and propose a solution called Group Head Attention, which uses a divide - and - conquer strategy. The first stage is group constraint training, aiming to make intra - group heads similar and inter - group heads separate. The second stage is the Voting to Stay algorithm, which prunes redundant multi - head attention. They evaluate their models on machine translation, language modeling, and abstract summarization tasks, achieving good performance with significant parameter compression.</sample>
    <sample id="115">L'approccio utilizza segmenti di parola.</sample>
    <sample id="116">Nell'esempio con Servin e Kea, è necessaria la conoscenza specifica dell'entità che Servin è un giudice.</sample>
    <sample id="117">La qualità dell'esempio è più importante.</sample>
    <sample id="118">The speaker is presenting their ACL 2023 submission on improving pre - training techniques for code - switched NLP. They define code - switching as a phenomenon where words are in different languages in the same sentence, like "laptop" and "bag" in English and Hindi. They note that multilingual pre - trained models like M - BERT and XLM - R don't perform well on code - switching tasks. Their main contributions are proposing novel MLM techniques for code - switching, like Switch - MLM, and architectural changes and auxiliary losses. They also offer a surrogate method called Frequency - MLM. They propose residual connections and an auxiliary LID - based loss to help with code - switching. Their combined method performs best on sentiment analysis tasks. They use probing experiments to verify that their methods increase switch - point information in the intermediate and final layers.</sample>
    <sample id="119">L'articolo si concentra sugli modelli linguistici GPT4, GPT3, BERT e sue varianti.</sample>
    <sample id="120">Il modello combina i punteggi di più livelli.</sample>
    <sample id="121">Esempi di inferenza diretta sono il nome del brano, ad esempio "Easy on Me", o la sua posizione, come "la prima".</sample>
    <sample id="122">I'm sorry, but the information about the affiliations of the authors is not provided in the text you've shared. Could you provide more details or context?</sample>
    <sample id="123">The audio discusses a research on multi-instruct, improving multi-model zero-shot learning via instruction tuning. It highlights the gap in instruction data for multimodal tasks compared to language-only tasks. They built MultiInstruct, a multimodal instruction tuning benchmark dataset with 62 diverse tasks. Using OFA as the base model, they trained and tested on various tasks. The results showed that instruction tuning significantly improves OFA's performance on seen multimodal tasks. Transfer learning from natural instruction datasets also benefits instruction tuning. More instructions improve performance and reduce sensitivity.</sample>
    <sample id="124">The work focuses on benchmarking and improving temporal reasoning of LMs. It breaks down temporal reasoning into three levels: time - to - time, time - to - event, and event - to - event. The first level deals with simple time calculations. The second level involves understanding events in relation to time, like what team Messi played for in 2010. The third level is about reasoning between multiple events, such as Messi's teams after Barcelona. The study found that prior works overemphasized L2 reasoning. They conducted a preliminary experiment on L1 prediction of years, finding that some LMs had a bias towards the 2000 - 2020 time period. They proposed a new dataset covering all three levels of reasoning and long temporal coverage. They evaluated temporal reasoning in three QA settings: closed - book, open - book, and a new reasoning - QA setting. They also proposed a training strategy with temporal span extraction pre - training and time - sensitive reinforcement learning. The final model, Time - T5, significantly outperformed other models in OBQA and Reasoning - QA settings.</sample>
    <sample id="125">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più dettagli?</sample>
    <sample id="126">No, non è stato considerato come un approccio standard.</sample>
    <sample id="127">Il lavoro di Nam Geu Ho e collaboratori riguarda il trasferimento delle capacità di ragionamento di modelli di linguaggio grandi a modelli più piccoli. Propone l'uso di modelli grandi come "docenti di ragionamento" per insegnare le loro capacità a modelli più piccoli. Introduce una tecnica chiamata "diverse ragionamento" per migliorare l'efficacia dell'insegnamento. Analizza la capacità dei modelli piccoli di eseguire complessi compiti che richiedono ragionamento, che in passato erano solamente possibili con modelli grandi. Confronta il loro metodo con baselines esistenti e dimostra che può ottenere prestazioni significative anche con modelli piccoli. Mostra come diversi fattori, come il dataset, il modello docente e il modello studente, possono influenzare le prestazioni. Il riassunto conclude con l'invito a leggere il paper per ulteriori dettagli.</sample>
    <sample id="128">L'audio parla di un lavoro di Makshita e Martin su "The Kid Must Have", che valuta l'integrazione del conoscenza da diverse fonti. I modelli di comprensione del linguaggio naturale utilizzano una varietà di fonti di conoscenza, come i parametri pre-allenati e le informazioni fornite in tempo di inferenza. Recentemente, i modelli possono utilizzare la conoscenza pre-allenata per risolvere compiti come la risposta alle domande, ma spesso richiedono anche conoscenza fornita in tempo di inferenza. Per esempio, nel frase "John saw the newly elected president on TV", i parametri pre-allenati possono contenere informazioni su ciò che i presidenti fanno e cosa sia la TV, ma non possono sapere chi sia John o il nuovo presidente perché potrebbe essersi cambiato dal pre-allenamento. Quindi, i modelli efficaci per compiti di NLU intensivi di conoscenza devono essere in grado di integrare e utilizzare sia la conoscenza pre-allenata che quella in tempo di inferenza. Propone un insieme di test diagnostici per l</sample>
    <sample id="129">The authors provided the example of Asian women.</sample>
    <sample id="130">I architetture dei modelli che non generalizzano in modo adeguato sono quelle che non sono basate su trasformatori.</sample>
    <sample id="131">Non ci sono nomi specifici dei set di dati di test menzionati nel contenuto.</sample>
    <sample id="132">There are two authors involved in the article.</sample>
    <sample id="133">L'autore opera con più modalità.</sample>
    <sample id="135">ABC eval è un approccio dimensionale per valutare l'intelligenza artificiale conversazionale. È stato sviluppato dal lab Emory NLP di Emory University, in collaborazione con Amazon Alexa AI. La valutazione tradizionale usa giudici umani per scegliere tra conversazioni o dare valutazioni su scala Likert. ABC eval cerca di ridurre la soggettività valutando se le risposte del modello esprimono determinati comportamenti, come informazioni irrellevanti o contraddizioni. È più preciso e affidabile. Sono state valutate 4 modelli di chat state dell'arte su 100 conversazioni umano-bots ciascuno. ABC eval è più affidabile e prevedibile rispetto a metodi esistenti. Le metriche ABC eval spiegano più del 25% della qualità delle conversazioni. Ci sono ancora sfide da affrontare, come le violazioni di buon senso nelle risposte dei bot. Con il progresso rapido nel campo, queste errori potrebbero diminuire in nuovi modelli. ABC eval può essere utilizzato</sample>
    <sample id="136">The work presented by Chad Savan and his supervisor Nafisa at the University of Sheffield focuses on numerical reasoning. They aim to address the issue of models performing poorly in numerical tasks, especially with smaller models. They introduce Fermat, a flexible evaluation set based on arithmetic types, to test models' understanding of numbers, mathematical operations, and training dependency. Fermat includes math - worded questions from the Illinois Common Core, with numbers changed to mimic real - life scenarios. They find that most models perform poorly across all aspects, but fine - tuning with math - teachers - written templates improves performance. Training dependency is also examined, showing that even when the exact expression is seen, accuracy is still low, suggesting the importance of linguistic notions. The impact of training templates is also investigated, with four graphs showing different performance levels. Overall, the work aims to better understand and improve models' numerical reasoning abilities.</sample>
    <sample id="137">The work shares a dataset for language - guided floorplan generation. It focuses on the need for designs meeting requirements in natural language, different from less constrained generation like artwork. The dataset is constructed from publicly available floorplans and human - annotated language instructions, with 5051 human - annotated and 76000 artificial instructions. The main challenges are strict constraints, understanding the big picture from fuzzy text, and dealing with ambiguous information. The method uses a sequence - to - sequence approach under the encoder - decoder framework, treating instructions as input and bounding boxes as target sequence. It's initialized by a pre - trained language model for better understanding and uses a normal language modeling objective.</sample>
    <sample id="138">The area of NLU that is not well studied is the ability to integrate and use both pretrain time and inference time knowledge.</sample>
    <sample id="139">I nomi dei relatori sono Ying e Zhiyang.</sample>
    <sample id="140">Yes.</sample>
    <sample id="141">Le risorse esistenti supportano solo tipi limitati di traduzioni dipendenti dal contesto e set di lingue limitati, poiché si affidano generalmente a conoscenza di dominio e creazione umana.</sample>
    <sample id="142">Certo. Ecco una versione in italiano del contenuto inglese: "Ciao, sto parlando del nostro lavoro sul risolvere espressioni di riferimento indirette per la selezione di entità. Abbiamo introdotto il corpus di entità alternative. Il mio nome è Javad Hosseini e questo è un lavoro in collaborazione con Filip Radlinski, Silvio Parodi e Ali Louis. Il nostro obiettivo è capire il linguaggio degli utenti quando vogliono prendere una decisione. Considera questa domanda alternativa: "Volevi dire 'Easy on Me' o 'I Got a Feeling'? " Qui l'utente vuole scegliere tra una delle due canzoni. La cosa più ovvia è usare un riferimento diretto, ad esempio citando il nome della canzone, 'Easy on Me', o la sua posizione, la prima. Ma a volte un riferimento indiretto è più appropriato per avere una conversazione più naturale. Questo può accadere quando l'utente non riesce a ricordare il nome della canzone, o quando le pronunciaz</sample>
    <sample id="143">SimulST is compared with proper strategies that are also applied to offline models, such as the Whitkey strategy and local agreement, and with state-of-the-art architectures specifically tailored for simultaneous speech translation.</sample>
    <sample id="144">Non so qual è l'affiliazione degli autori dell'articolo. Potresti dare più dettagli?</sample>
    <sample id="145">Jenny</sample>
    <sample id="146">L'abstract parla di un problema di omissione nell'estrazione di sommari da dialoghi. Si inizia con l'introduzione del contesto, che è la sommariizzazione di dialoghi, un sotto - compito della sommariizzazione di testo. Si parla delle diverse aree di applicazione e dei progressi recenti, specialmente con i modelli di linguaggio pre - addestrati. Si evidenzia che, sebbene questi modelli generino sommari fluenti e coerenti, essi possono avere errori di omissione che rendono i sommari non utilizzabili in applicazioni reali. Si analizzano i dati e si trova che circa il 70% dei sommari generati ha problemi di omissione. Si parla della distribuzione casuale delle informazioni omesse nel dialogo e della difficoltà per i modelli attuali nell'identificare le informazioni chiave. Per analizzare meglio il problema e risolverlo, si propone di rilevare le omissioni possibili nei sommari di dialoghi. Si costruisce un nuovo dataset per fornire etichette di</sample>
    <sample id="147">Tre.</sample>
    <sample id="148">Simultaneous speech translation, o SMT, è il processo di tradurre il linguaggio parlato in testo in un'altra lingua in tempo reale, permettendo la comunicazione tra lingue. I modelli attuali di SMT presentano problemi come architetture specifiche addestrate introducendo moduli aggiuntivi per ottimizzarli, procedimenti di addestramento lunghi e complessi, ad esempio addestramento coinvolgente diversi obiettivi di ottimizzazione, e addestramento e mantenimento di diversi modelli per raggiungere diversi regimi di latenza, ad esempio addestrando un modello con un'average di 1 secondo di latenza e un altro con 2 secondi di latenza e così via. La nostra soluzione è di utilizzare modelli offline esistenti senza rieddurre o adottare specifiche architetture per SMT, utilizzare solo un modello per ogni regime di latenza e gestire la latenza attraverso parametri specifici, e sfruttare il know - how già acquisito dal modello attraverso</sample>
    <sample id="149">Sì, il set di dati è disponibile pubblicamente. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="150">Il contenuto parla di un paper presentato da Archi Key su MeetingQA, un dataset di Q&amp;A basato su trascrizioni di riunioni. Si evidenzia che le riunioni generano molte trascrizioni, che possono essere utilizzate per l'NLP. Il dataset MeetingQA è unico perché le trascrizioni sono lunghe e ricche di informazioni, ma i precedenti studi si concentravano solo sulla sommarizzazione e l'estrazione degli item d'azione. Archi Key ha introdotto MeetingQA, un dataset di Q&amp;A basato su domande e risposte in riunioni. Il processo di raccolta dei dati ha utilizzato trascrizioni pubbliche di riunioni dal corpus AMI. Si è selezionato le domande basandosi sulla punteggiatura e si è filtrato fuori le domande troppo brevi. Per annotare le risposte, si sono reclutati annotatori. Il dataset contiene 7.700 domande, divise tra train, dev e test. 30% delle domande sono non risolvibili, 40% hanno ris</sample>
    <sample id="151">Mi dispiace, ma non ho la capacità di tradurre il contenuto in italiano. Potresti fornire il testo in inglese che desideri tradurre?</sample>
    <sample id="152">Frederic Riemenschneider presenta un'intersezione tra NLP e filologia classica. Esegue un'analisi di modelli di linguaggio grande per filologia classica, introducendo risorse per greco e latino antichi. Esplora le implicazioni e sfide della multilinguialità in questi modelli. Presenta modelli di linguaggio come Latin BERT, Ancient Greek BERT e altri. Questi modelli sono tutti BERT e monolingui, ma la multilingualità è desiderata. Si prevede di creare nuovi modelli specifici per la filologia classica, con obiettivi di rendere i modelli esistenti comparabili, spingere l'arte, esplorare architetture diverse e introdurre modelli multilingui. Si sono creati modelli monolingui come GriBERTA e GREATER, e multilingui come FilBERTA e Filter. Si raccolgono dati di pre-allenamento per greco antico, utilizzando Open Greek and Latin e nuovi risorse. Si sviluppa un nuovo corpus di pre-allenamento dall'Internet Archive</sample>
    <sample id="153">Nina, a postdoctoral scientist at Amazon Alexa's Responsible AI team, presents her work on resolving ambiguities in text - to - image generative models. They study existing ambiguities in prompts, like "The girl enters the room with flowers, " which can be interpreted in different ways. Their goal is to propose frameworks to mitigate these ambiguities and evaluate if the generated images are faithful to users' intentions.The pipeline starts with curating a benchmark dataset covering various types of ambiguities. Then, a prompt disambiguation framework is used, either by asking clarifying questions or generating different visual setups. Once the prompts are disambiguated, they are input into a text - to - image model to generate images, and the automatic evaluation framework is used to check if the images are faithful to users' intentions.The findings show that disambiguation using their framework has a positive effect on faithful generation. Their automatic evaluation framework agrees with human evaluation, making it reliable for evaluating text - to - image models. For more details, refer to their paper.</sample>
    <sample id="154">I'm sorry, but the information about the affiliations of the authors of the article is not provided in the text.</sample>
    <sample id="155">Il nome del relatore è Javad Hosseini.</sample>
    <sample id="157">The speaker introduces their work on dialogue summarization using a static - dynamic structure fusion graph. They aim to distill silent information from dialogue context into a concise summary. This is a challenging and interesting task in text summarization research. They show an example dialogue about three people going to a concert and its summary. Many existing methods heavily depend on external linguistic tools for static graph construction, which can be unreliable and cause error propagation. Their SDDS model has four main components: utterance encoder, static graph construction, static - dynamic graph module, and a pre - trained language model for summary generation. They propose four heuristic dialogue structure modeling methods to capture static dialogue structure information, including discourse passing graph, speaker relationship modeling method, and positional graph.</sample>
    <sample id="158">Dual Cache è un metodo per la risoluzione di coreferenza in documenti lunghi. Il compito di coreferenza è identificare le menzioni e clusterizzare quelle che si riferiscono allo stesso ente. Con i metodi tradizionali, si deve enumerare tutte le coppie di menzioni, che ha una complessità quadratica. I metodi basati su cache recentemente proposti usano una cache di dimensioni fissa e riducono la complessità a livello lineare. Tuttavia, nella cache basata sui documenti lunghi, il tema cambia molte volte, causando le menzioni degli enti a essere sparsi in tutto il testo. La politica di evicione LRU porta a un alto rate di miss nella cache. I nostri studi hanno mostrato che gli enti ad alta frequenza sono menzionati globalmente e fanno la maggior parte delle cache miss. Proponiamo Dual Cache, che ha una cache locale e una cache globale. La cache locale usa la politica di evicione LRU e la cache globale usa la politica di evicione LFU. Dual Cache funziona</sample>
    <sample id="159">Ciao a tutti, sono Costas Senna e sono felice di accogliervi al nostro talk sulle nostre paper di ACL 2023. I giudizi di accettabilità dei modelli di linguaggio non sono sempre robusti al contesto. Questo è un lavoro congiunto con John Gog, Aaron Muller, Kanishka Mishra, Karen Venters, Roger Levy e Athena Villalón. Quindi, in questo lavoro, rivediamo il paradigma del "minimale pair". Il paradigma del "minimale pair" valuta i modelli di linguaggio sulla base dei giudizi di accettabilità, che possono includere grammaticità, come gli esempi di grammatica, o accettabilità in termini di stereotipi, come le coppie di "crow". Nella variante del "minimale pair" tipica, si mostra una frase accettabile o grammaticalmente corretta e poi si mostra una frase non accettabile o grammaticalmente errata, e si spera che il modello assegna una probabilità maggiore alla frase accettab</sample>
    <sample id="160">In un unordered multiset of tokens.</sample>
    <sample id="161">55000.</sample>
    <sample id="163">Il metodo di allineamento migliore per DEplain è il metodo di mass align.</sample>
    <sample id="164">L'apprendimento scarsamente supervisionato ha l'vantaggio di essere più economico rispetto all'apprendimento supervisionato umano, ma può essere anche rumoroso.</sample>
    <sample id="165">The paper presents an approach to adaptive reasoning. It starts with a context, like Emily being stuck in traffic, and an outcome, like Emily making her flight. There are possible explanations, such as her flight being delayed or leaving on time. The goal is to find a plausible explanation that bridges the gap between the context and outcome. The paper proposes an unsupervised learning method called LiPoR, which stands for Likelihood Learning with Posterior Regularization. This method treats explanations as a latent variable and aims to maximize the marginal likelihood of the outcome given the context. However, it also needs a regularizer to prefer plausible explanations. The regularizer enforces mutual exclusivity among explanations. LiPoR's objective has two parts: maximizing the likelihood of outcomes and preferring some explanations over others. The regularizer, denoted by Omega, takes the max between the entropy of P of Z given X, Y and the log of M, where M is the number of plausible explanations. When the entropy is larger than the log of M, it means there are more than M explanations receiving probability mass, and in that case, the entropy of P of Z given X, Y is minimized to prefer a subset of explanations.</sample>
    <sample id="166">L'articolo introduce un nuovo framework per la ricerca immagine da test linguistici complessi. Questa ricerca è difficile perché le immagini sono simili e le descrizioni lunghe. I modelli di linguaggio visuale tradizionali performano bene nelle tare di ricerca immagine - frase ma falliscono con test linguistici complessi. Per risolvere questo problema, l'autore si ispira alla strategia di divide e conquista e alla teoria del processo umano. Si propone di utilizzare un modello di generazione di proposizioni per decomporre le complesse proposizioni in rappresentazioni di proposizioni semplici. Un modello di interazione visivo - linguistica, System 1, esegue le operazioni visive e interagisce con le informazioni. Il modello di ragionamento simbolico, System 2, integra i risultati delle operazioni simboliche per ottenere la soluzione finale. I risultati sperimentali dimostrano che il metodo proposto, ND-DR, supera le baselines. Inoltre, due casi specifici verificano la performance del metodo.</sample>
    <sample id="167">In DEplain-web, 750 documents have been aligned manually and with automatic alignment methods.</sample>
    <sample id="168">Il set di dati CoNLL++ è stato creato raccolgendo dati da Reuters news del 2020 e annotandoli con le stesse linee guida di annotazione di CoNLL 2003.</sample>
    <sample id="169">Il paper parla di un modello di linguaggio a 540 milioni di parametri chiamato Palm, presentato nel 2022. È stato addestrato su un grande insieme di testo con 780 miliardi di token. All'epoca della pubblicazione, ha raggiunto i punteggi più alti in molte tabelle di NLB. Questo lavoro presenta la prima studio sistematico di prompt per modelli di linguaggio a larghe scale per la traduzione automatica. Valutano la qualità della traduzione utilizzando le migliori pratiche della comunità AMT. Utilizzano i set di test più recenti per evitare sovrapposizioni tra i dati di test e di addestramento del modello. Confrontano con sistemi di punteggi più alti e usano metriche AMT state of the art. Inoltre, mostrano valutazioni umane basate su esperti. Danno alcune raccomandazioni per le strategie di selezione di prompt. Il prompt ha un grande impatto sulla performance del modello di traduzione. Con un semplice esperiment</sample>
    <sample id="170">Mi dispiace, ma non ho la capacità di tradurre il contenuto in inglese in italiano. Potresti fornire il testo in inglese che vuoi tradurre?</sample>
    <sample id="171">I lavori connessi possono essere classificati in quattro categorie. Ma questi metodi non sono applicabili alle embedding as services o mancano di trasferibilità.</sample>
    <sample id="172">No, they are not sufficient for CLSP.</sample>
    <sample id="174">The speaker, Thea, introduces a paper on "organ analysis 35k", a large dataset for argument quality analysis. She explains that it's unique compared to other datasets as it has high - quality arguments sourced from high - quality tournaments, expert debaters, intermediate debaters, and novice debaters. It has a diverse range of arguments based on 24 themes, unlike datasets with pre - selected motions. The dataset includes analysis, which is a combination of claims, premises, and more, not just claims or premises. This analysis helps explain the argument better. The speaker also mentions instance - based annotator reliability, where only biased judgments are eliminated, not all of an annotator's work. This allows for better utilization of the annotations.</sample>
    <sample id="175">Induce l'alignment come parte della formazione.</sample>
    <sample id="176">L'equità di un modello NLP a valle si definisce come la capacità del modello di fornire risultati equi e non discriminatori per tutte le categorie di utenti, indipendentemente dalla loro etnia, genere, orientamento sessuale o altre caratteristiche.</sample>
    <sample id="177">Yannick Slavac</sample>
    <sample id="178">Kostas Sina.</sample>
    <sample id="179">Il contenuto audio parla di come i modelli di linguaggio possano comprendere il concetto di "theory of mind", ovvero la capacità di ragionare sulle mentalità degli altri. Si usa il test di Sally-Anne come esempio. I modelli di linguaggio fanno ancora pessimo su questo tipo di compito. Per migliorare, si propone un metodo chiamato Symbolic Tom che usa rappresentazioni grafiche esplicite. Questo metodo precalcola rappresentazioni grafiche per tutte le combinazioni di personaggi in una storia. Si usa un algoritmo di inferenza per calcolare queste rappresentazioni. Dopo averle calcolate, si può rispondere efficacemente a qualsiasi domanda. Ad esempio, si può rispondere a domande come "dove crede Alice che Bob cercherà l'apple?" Si testa il metodo con vari modelli di linguaggio e si confronta con basi di linee supervisionate. Si ottengono miglioramenti significativi in termini di prestazioni, come 65 punti di precisione in più per GPT3. Si testa anche la</sample>
    <sample id="180">Myra.</sample>
    <sample id="181">This paper introduces a work on distinguishing script knowledge from large language models for constrained language planning. It focuses on planning for goals with specific constraints, unlike previous work which mainly dealt with abstract goals of stereotypical activities. The authors define the problem of constrained language planning, which involves different constraints on goals. They evaluate and improve the constrained language planning ability of large language models. To acquire specific goals, they extend abstract goals with multifaceted constraints and use InstructGPT for human - in - the - loop data acquisition. They find that all large language models perform unsatisfactorily on planning for specific goals. Detailed analysis reveals that while semantic completeness is acceptable, faithfulness to constraints cannot be guaranteed. They then propose an over - generated then filter method to improve generation quality. This method involves showing constraint types to InstructGPT, obtaining specific goals, over - generating scripts, and using a filter model to select faithful scripts. The method greatly improves planning ability in semantic completeness and faithfulness to constraints. The authors also discuss the importance of creating a dataset for constrained language planning, which is costly and time - consuming. They follow the idea of symbolic knowledge distillation to distill a constrained language planning dataset from large language models. They generate 55, 000</sample>
    <sample id="182">Il tropicalismo indica un'identità o un'attribuzione basata sulla cultura, tradizione, orgoglio e l'esotismo di un gruppo, che lo distingue dallo standard bianco.</sample>
    <sample id="183">The authors used natural language prompts to generate personas, which are depictions of imagined individuals. They specified different identity markers in the prompts to make the personas generalizable to any demographic.</sample>
    <sample id="184">In questo lavoro è stato utilizzato il CXMI, Contextualized Mutual Information, per misurare l'utilizzo del contesto.</sample>
    <sample id="185">DrBERT è basato su Roberta e addestrato su Nachos, mentre ChuBERT è basato su Camembert e addestrato su 4 GB di dati.</sample>
    <sample id="187">Due autori sono coinvolti nell'articolo.</sample>
    <sample id="188">L'apprendimento iterativo di trasferimento è un approccio dove si trasferiscono i modelli o i pesi da una task a un'altra in iterazioni successive.</sample>
    <sample id="189">The goal is to understand users' language when they want to make a choice.</sample>
    <sample id="190">Un utente malintenzionato può estrarre i parametri del modello attraverso un EaaS aprendo il modello tramite imparare dagli embedding e fornendo servizi simili.</sample>
    <sample id="191">Tre.</sample>
    <sample id="192">The audio is about a presentation on a new optimizer called CAM for large language model training. It addresses the issue of memory usage in existing optimizers like Adam and AdaFactor. CAM uses non-negative matrix factorization to reduce memory requirements while maintaining fast convergence. It calculates an instability matrix to adaptively adjust the update step. Experiments on BookCorpus and English Wikipedia show that CAM outperforms Adam and AdaFactor in terms of validation accuracy and training speed, especially for large models. It also shows better performance with larger batch sizes.</sample>
    <sample id="193">I'm not sure how many annotators were used for the initial dataset. You might need to check the details in your paper or research report. If you have any other questions about this work, feel free to ask.</sample>
    <sample id="194">I'm sorry, but the information about the affiliations of the authors is not provided in the text.</sample>
    <sample id="195">RHOHT è un framework per la risoluzione di domande complesse. Costruisce un albero di decomposizione gerarchica delle domande. I nodi foglia sono domande atomiche. Si fondono conoscenze da KB e corpus testuale a diversi livelli dell'albero. Si calcola una certezza per ciascun nodo. Risolvono la domanda complessa con ragionamento probabilistico dall'alto in basso. Si determina le risorse di conoscenza appropriate per ogni nodo. Gli esecutori ottengono le risposte con probabilità. Un aggregatore seleziona le risposte migliori. RHOHT ha ottenuto buoni risultati su due dataset di QA complesse, KQApro e Music.</sample>
    <sample id="196">L'esempio in cui il governatore è a sinistra è "I saw Bart and Lisa".</sample>
    <sample id="197">I modelli all'avanguardia nei sistemi di dialogo sono quelli selezionati per l'analisi con ABC eval. Non specificano nomi specifici dei modelli.</sample>
    <sample id="198">Perché i modelli linguistici stanno avendo finestre di contesto sempre più lunghe.</sample>
    <sample id="199">No, il modello multilingue ha ottenuto le migliori prestazioni su tutte le 9 dataset.</sample>
    <sample id="200">Sì, gli annotatori conoscono l'entità in anticipo.</sample>
    <sample id="201">Siamo utilizzati state of the art MT metriche.</sample>
    <sample id="202">Sì, il regresso nella generalizzazione può influire su specifici tipi di NER.</sample>
    <sample id="203">Perché le NLP diventano sempre più soggettive e orientate socialmente.</sample>
    <sample id="204">Con una messa a punto integrale.</sample>
    <sample id="205">The presentation discusses how political biases in pretraining data affect language models and downstream tasks. It shows that well - covered political news media in training data create a mixed blessing. On one hand, diverse perspectives are learned, but on the other, social biases can lead to fairness issues. The study investigates political bias propagation from pretraining data to language models to downstream tasks. It evaluates political leanings of models using political questionnaires and finds varying leanings. Controlled experiments show that pretraining on partisan corpora shifts ideological coordinates. It also examines if models pick up societal polarization. In hate speech and fake news detection, left - and right - leaning models perform differently based on social categories. This indicates a pressing fairness issue regarding political biases in language models.</sample>
    <sample id="206">They use a dissonance first approach.</sample>
    <sample id="207">The latest test sets.</sample>
    <sample id="208">I'm sorry, but the content you provided doesn't contain any information about how many suggestions the authors proposed at the end. Could you please provide more details or context?</sample>
    <sample id="209">Il metodo proposto migliora significativamente la capacità di pianificazione linguistica sia in termini di completezza semantica che di fedeltà alle restrizioni.</sample>
    <sample id="210">Shuheng.</sample>
    <sample id="211">Sì, i risultati e il set di dati nell'articolo possono essere utilizzati come parametri di riferimento. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="212">L'articolo non specifica quanti modelli più piccoli vengono utilizzati.</sample>
    <sample id="213">OFA viene utilizzato come modello di base per analizzare l'ottimizzazione delle istruzioni multimodali.</sample>
    <sample id="215">The talk is about the dependency structure of coordination. Different theories have different approaches. Universal Dependencies and Meaning Text Theory assume the first conjunct is the head. The PropBank approach has the conjunction as the head. The Cutson's Word Grammar has all conjuncts as heads. The aim is to argue for symmetric structures against asymmetric ones. The argument is based on the principle of dependency length minimization. In English, direct objects prefer to be close to the verb. When the direct object is heavy, it can be moved to after the adjunct. This violates the principle that direct objects should be next to the verb but satisfies dependency length minimization. Statistics from the Penn Treebank confirm that left conjuncts tend to be shorter when the governor is on the left. This tendency grows with the length difference between conjuncts. However, when the governor is on the right, the effect disappears.</sample>
    <sample id="217">The work focuses on multi - attribute controllable dialogue generation. Previous methods had limitations like focusing on single attributes or being limited by annotated data. The researchers proposed DCG, a disentangled controllable generation method. It learns attribute concepts from seen values and uses a disentangle loss. They also introduced a unified reference - free evaluation framework, MAE, for different granularities of attributes. Experiments showed that DCG outperforms other baselines in controllability and test quality. The model uses a compositional prompt module based on the dialogue GPT framework. Two types of prompts are designed: attribute - oriented and task - oriented. These prompts help the model focus on specific information and global features. A disentanglement loss is used to train multiple compositional prompts. A unified evaluation framework is proposed to address the lack of metrics for multi - attribute controllable dialogue generation. The results confirm the effectiveness of the method for transforming seen attributes to unseen combinations.</sample>
    <sample id="218">L'autore, I'll be lad, lavora con i colleghi di Google Translate.</sample>
    <sample id="219">Hi everyone. I'm Zhang Huiju, a researcher at Academia Sinica. I'll present our work on a multi - stage pipeline for uncovering financial signals in financial reports. This work is with Yu Xiang Huang and Chen Weiling, advised by Prof. Zhe Li at Tsinghua. I'll talk about the background of financial report analysis, which is the goal of this work, and text definition and approaches. In this work, we consider the Form 10K as our target corpus, which is an annual report required by SEC. It contains many details of companies' important activities. However, mining useful information requires lots of human efforts. This work was motivated by two observations. First, we observed that the words in a company's report are very similar, about 80% of tokens are the same, and the contents are really dependent. This figure illustrates the text similarity between two reports in continuous years. For example, the report in 2018 is similar to the one in 2017. Based on the observation, we introduce a highlighting task in a multi - stage pipeline. Following the motivation, we first define the reference to target structures in our task. The target and reference refer to the report of our</sample>
    <sample id="220">I'm sorry, but the information about the affiliations of the authors is not provided in the text you've given. Could you perhaps provide more details or context?</sample>
    <sample id="221">Non so qual è la lingua di origine e la lingua di destinazione analizzate nell'articolo. Potresti fornire più dettagli o leggerlo per me?</sample>
    <sample id="222">L'articolo esplora le sfide e le interruzioni nell'QA di dominio aperto. Si prende in esame un esempio di domanda riguardante Narora, Kakrapar e Tarapur. Per rispondere, si cerca di trovare passaggi pertinenti da un corpus di Wikipedia utilizzando un modello di ritiro. Poi, un modello di lettore prende in input la domanda e i passaggi pertinenti per generare la risposta. Tuttavia, se si vuole rispondere a domande biomediche, il corpus di Wikipedia può rispondere solo a poche domande specifiche del dominio. Si può anche sostituire Wikipedia con un corpus biomedico, ma questo può non essere sufficiente poiché i domini sono sparsi e il modello di base è addestrato su Wikipedia. Per abilitare la trasformazione, si può espandere la raccolta di documenti per includere documenti biomedici. Tuttavia, quando si ritira, le prime passaggi si concentrano su parole come "piante", causando una risposta errata dal modello di lettore.</sample>
    <sample id="223">Xiangbin.</sample>
    <sample id="224">Durante gli esperimenti sono stati studiati tre modelli.</sample>
    <sample id="225">53 attività vengono utilizzate per addestramento e 9 per test.</sample>
    <sample id="226">The article involves two authors.</sample>
    <sample id="227">The text discusses the current challenges in language model research, particularly the lack of grounding during pre - training. It mentions that most language models, including large - scale ones, are pre - trained on text corpora without grounding. This gap between pre - training and downstream applications makes grounding language understanding difficult. Existing research often uses language models to directly generate plans, but these plans may not always be grammatical or valid. The authors propose a new framework called Pangu, which focuses on discrimination instead of generation. A symbolic agent proposes candidate plans, and a language model scores and ranks them. This approach separates the neural world from the symbolic world, making it easier for language models to handle. The framework is tested on large - base question - answering tasks and shows strong performance across different settings and language models. It also demonstrates good sample efficiency, especially with Codex.</sample>
    <sample id="228">Gli autori hanno effettuato i test su quattro set di dati: AG News, Mind, SSD2 e Iris Spam.</sample>
    <sample id="229">Il contenuto parla di un lavoro con Henning Bocksmuth su rilevare migliorabili affermazioni per supporto di argomentazione. L'autrice, Gabriela Skudlinskaia, inizia presentando l'importanza della revisione testuale nel writing professionale. Spiega che la revisione è un processo ricorsivo che porta all'ottimizzazione della frase per l'autore. Nella argomentazione, trovare le parole giuste è cruciale per l'effetto sul pubblico. L'autrice illustra il processo di revisione con un esempio di una tesi sull'effetto dei raggi radioattivi dei cellulari sulla salute. Il lavoro si concentra su come determinare se un'affermazione argomentativa è stata formulata in modo ottimale. Introduce due task: rilevare affermazioni subottimali e suggerire miglioramenti. L'autrice considera di apprendere direttamente dai modelli di revisione umani invece di definire esplicitamente cosa rende un'affermazione buona o cattiva. Esplora i problemi che si presentano lavor</sample>
    <sample id="231">NACHOS è un dataset di dati medici crawlati dalla rete.</sample>
    <sample id="232">Il nome della relatrice o del relatore è Ida Villar.</sample>
    <sample id="233">Simultaneous speech translation, or Simo ST, is translating spoken language into text in real - time. Current models have problems like complex training procedures and need different models for different latency. Our solution uses existing offline models without retraining, uses one model for all latency regimes, and handles latency through parameters. It uses the attention mechanism between audio input and text output. We propose a dot or encoder - decoder attention strategy. It decides whether to emit partial translation based on attention concentration. If the sum of cross - attention weights is below a threshold, words are emitted. Otherwise, they are not. The results show that our approach outperforms other strategies in terms of translation quality and latency. The code and models are open - sourced for reproducibility.</sample>
    <sample id="234">La strategia del prompting ha un grande impatto sui risultati. In un semplice esperimento con uno shot prompting, il cambiamento osservato in 516 su 1000 frasi è di più di un punto di errore, e in casi estremi può arrivare fino a 40 punti di errore. È importante selezionare una buona strategia di prompting. Se hai altre domande o vuoi discutere di questo argomento, sentiti libero di chiedere.</sample>
    <sample id="235">I'm sorry, but the information about the affiliations of the authors is not provided in the text.</sample>
    <sample id="236">Non sono state fornite le 5 istruzioni scritte da esperti nel testo. Potresti dare più dettagli o cercare altrove?</sample>
    <sample id="237">Propongono un insieme di test diagnostici per l'integrazione del conoscenza.</sample>
    <sample id="238">The video introduces a new benchmark dataset called MeetingBank. It's for summarization technologies in different meeting domains. The speaker, Yebo, from the University of Central Florida, explains the challenges in creating the dataset, like getting high - quality meeting summaries and finding trustworthy public meeting resources.The dataset includes 1366 city council meetings and nearly 7000 instances. It has statistics on meetings, duration, tokens, speakers, and years. There are also summarization instances and average sentence and token counts.The speaker measures the level of abstraction in meeting summaries using coverage and density scores. Coverage shows how much of the summary appears in the source transcripts, and density shows how much is extractive. For model evaluation, top - tier summarization systems were tested on MeetingBank. Extractive summarizers like Oracle and LexRank performed well, while GPT - 3 didn't do as well. Human evaluation was also conducted based on five criteria: informativeness, factuality, fluency, coherence, and readability.</sample>
    <sample id="239">Ciao a tutti, il mio nome è Ida Villar e leggerò un breve riassunto del mio articolo "Prompting Pan from Translation: Assessing Strategies and Performance". Questo è un lavoro in collaborazione con i miei colleghi di Google Translate.Pan è un modello di linguaggio a 540 milioni di parametri presentato l'anno scorso, nel 2022. È stato addestrato su una vasta collezione di testo, composta da 780 miliardi di token. Al momento della pubblicazione, ha raggiunto i risultati più avanzati in centinaia di compiti di NLP.In questo lavoro, presentiamo la prima studio sistematico del prompting per modelli di linguaggio a larghe scale per la traduzione automatica. Abbiamo valutato la capacità di traduzione di questi modelli utilizzando le migliori pratiche della comunità AMT. Questo implica l'uso dei set di test più recenti per evitare che i dati di test si sovrappongano con i dati di addestramento del modello di linguaggio. Abbiamo comparato due sistemi di</sample>
    <sample id="240">Ciao, sono Dawei, un dottorando presso l'Università di Stoccarda in Germania. In questo video vorrei presentare il nostro lavoro recente "Wider than you think: A critical look at weakly supervised learning". Questo è un lavoro in collaborazione con Xiaoyu Shen, Mario Smuth, Stefan G. und Dietrich Klakow.Inizierò con una breve introduzione a supervisione debole e apprendimento supervisionato debole. Nella supervisione debole, non etichettiamo manualmente i dati. Invece, etichettiamo i dati utilizzando fonti di etichettatura debole, come regole heuristiche semplici, basi di conoscenza o fonti di etichettatura di qualità bassa, come illustrato nella figura a destra. Quando confrontati con le annotazioni umane, le annotazioni debole sono molto più economiche, ma sono anche rumorose, il che significa che una certa quantità di annotazioni sono incorrette. Se addestriamo direttamente reti neurali su dati etichettati debole, le reti neurali tendono a memorizzare</sample>
    <sample id="241">L'articolo discute un approccio per la valutazione di sistemi di rilevamento di fake news in tempo reale, con un caso di studio sui trattamenti per il COVID-19. Si critica l'uso di dataset retrospettivi e la possibilità di counter evidence rivelata dopo la pubblicazione. Si propone un quadro di valutazione per sistemi che integrano feedback umano e sono assistivi piuttosto che autoritativi. Il sistema è diviso in due componenti: la rilevazione di false affermazioni e la verifica delle violazioni di politica. La prima parte utilizza un modello T5 per estrarre affermazioni da tweet raw e le classifica per trend. La seconda parte utilizza un modello di classificazione per identificare tweet che violano le politiche social media. Si valuta l'efficacia del sistema in termini di precisione e di lavoro umano richiesto.</sample>
    <sample id="242">I metodi di valutazione comuni per i sistemi di dialogo sono l'uso di giudici umani per selezionare quale delle due conversazioni è migliore o per valutare le conversazioni utilizzando una scala Likert.</sample>
    <sample id="243">C'è un elenco di autori, ma non so esattamente quanti sono. Potresti contare per me?</sample>
    <sample id="244">Per risolvere l'esempio con Servin e Kea, sono necessarie conoscenze di base come "Servin è un giudice" e "giudici decidono casi in tribunali".</sample>
    <sample id="245">Il contenuto parla di un lavoro intitolato "A Needle in a Haystack: An Analysis of High Agreement Workers on MTurk for Summarization". L'autore, Linlin Jiang, presenta un pipeline a due passi per trovare lavoratori MTurk con alta concordanza. Il primo passo è la qualificazione, che include una serie di task per testare le capacità degli annotatori. I lavoratori vengono classificati in quattro tipi: oro, argento, bronzo e blocco. Solo i lavoratori oro e argento passano il primo task. Il secondo passo è un task di tolleranza che testa la capacità degli annotatori di gestire un carico di lavoro pesante. I lavoratori che passano questo task sono quelli che possono raggiungere una concordanza alta in termini di IAA, interannotator agreement. Il pipeline ha ottenuto otto lavoratori oro e otto lavoratori argento, il 6% dei 200 partecipanti. Inoltre, il pipeline ha ottenuto una concordanza alta tra i lavoratori, con un Krippendorff's Alpha di 0,</sample>
    <sample id="246">No, il codice non è disponibile.</sample>
    <sample id="247">The audio introduces a new fact verification task using knowledge graphs. Existing datasets like FEVER and VITAMIN C use Wikipedia text or tables, but none use knowledge graphs with natural language claims. The proposed task, KG - based fact verification, is reliable as evidence is intuitive in KGs. It can be used in modern dialogue systems for consistency checks. A new dataset, fact KG, is introduced, using DBpedia. Claims are in two styles, written and colloquial. There are two labels, supported and refuted. The task involves retrieving evidence from DBpedia and verifying claims using it. Five types of reasoning are used: one hop, conjunction, existence, multi-hop, and negation. For example, one hop claims can be verified by checking if two entities in the claim are connected by a relation. The dataset includes claims in both styles for practical use. Two methods were used: a colloquial start transfer model and presupposition templates. Some statistics of the dataset are also mentioned.</sample>
    <sample id="248">No, gli annotatori per NLPositionality non sono bilanciati rispetto a ciascun gruppo demografico.</sample>
    <sample id="249">Le frasi nel dominio accettabile sono state perturbate aggiungendo rumore all'input.</sample>
    <sample id="250">Avere una valutazione dimensionale significa valutare diverse aspetti o dimensioni della qualità del dialogo, non solo la qualità globale.</sample>
    <sample id="251">The authors are affiliated with the University of Science and Technology of China.</sample>
    <sample id="252">The audio is about a presentation on unsupervised case retrieval using event extraction. The speaker, Saikiran, is a master's student at IIT Kanpur. They discuss the challenges of prior case retrieval in legal work due to the increasing volume of cases. The work has two key contributions: the ILPCR dataset and the U-Create pipeline. The ILPCR dataset is a benchmark for PCR tasks with 7070 legal cases and 6.775 average citations per query document. The U-Create pipeline uses unsupervised learning and an event-based approach. Event extraction is crucial, using dependency parsing with Spacy. The pipeline processes query and candidate documents sequentially. The event extraction block has three steps: preprocessing, dependency parsing, and post-processing. Interaction matrices are computed for ranking candidates. Various models were experimented with, including count-based, transformer-based, and event-based models. Transformer-based models performed worse than baseline methods, showing the complexity of the legal domain. Event-based models were also explored.</sample>
    <sample id="253">Mario is presenting his work "Disorder", a double domain adaptation model for detecting mental disorders in social media. It's a group effort from Mexico and Spain. He defines mental disorders as psychological syndromes causing distress and disability. There are various types like depression, PTSD, bulimia, anorexia, etc. Social media is a vast resource for research on mental health issues. His work aims to automatically analyze social media posts to detect mental health disorders, providing evidence for early warning. Domain adaptation is used to improve model performance on specific domains like Reddit and mental health. The approach starts with a base language model, integrates information from Reddit and mental health, and incorporates lexical knowledge. The results on the ARIS datasets show good balance in precision and recall. The model focuses on important words related to mental disorders. It generates more negative and psychological oriented words compared to a base model. The most important sequences of text are visualized using a graph.</sample>
    <sample id="254">The audio discusses a research on uncertainty - guided label denoising for document - level distant relation extraction. It starts by introducing the problem of previous methods relying on large human - annotated corpora, which are time - consuming and labor - intensive. Then it talks about how recent work uses distant - supervised data to pre - train models for better performance but faces the issue of noisy labels in DS data. The speaker proposes a framework with uncertainty - guided label denoising to improve label quality. They first train a pre - denoising model with both DS and human - annotated data to generate pseudo - labels. To deal with false pseudo - labels, they introduce uncertainty estimation. For overlapping relations, they propose instance - level uncertainty estimation. They also design a relabeled strategy with dynamic class uncertainty threshold and a multi - phase training strategy to boost performance. Uncertainty estimation is important for misclassification detection, out - of - distribution instance detection, and active learning. They use Monte Carlo dropout technology to model uncertainty in the pre - denoising model. To solve the issue of separating false - positive pseudo - labels from correct ones, they modify the estimation process to obtain instance - level uncertainty scores for each positive pseudo - label. They propose dynamic class uncertainty thresholds to filter pseudo - labels</sample>
    <sample id="255">Per 0 e 1 shot prompting la forma del prompting si rivela importante.</sample>
    <sample id="257">Hanno valutato quattro modelli di dialogo di stato dell'arte.</sample>
    <sample id="258">The audio discusses using large language models for evaluating text quality in natural language processing. It proposes giving instructions to the models to rate samples. The speaker mentions related work like G and that using large language models for evaluation isn't novel. However, when submitted to ACL, no prior work explored large language model evaluation. The motivation is to find an alternative to human evaluation that's more stable. The speaker conducted an experiment rating stories generated by GPT - 2 or written by humans. They used large language models to rate based on grammar, coherence, likability, and relevance. Human raters, English teachers, were used for ground truth ratings. The results showed that some smaller models didn't show a preference for human - written stories, but two models, Davinci and ChatGPT, did. This suggests that large language models can be used as an alternative to human evaluation in this task.</sample>
    <sample id="259">Ecco una sintesi: L'articolo parla di un lavoro di John da Penn State University su Exemplar, un modello per la parsing semantica multilingue. Esso si occupa di tradurre query in diverse lingue naturali in rappresentazioni multiple, come SQL, Lambda Calculus, FunQL, ecc. I modelli esistenti hanno limitazioni, come mancanza di copertura su certe lingue o rappresentazioni. Exemplar fornisce un dataset unificato per la parsing semantica multilingue, con 90 set in diversi domini, 5 task di parsing semantico, 8 rappresentazioni e 22 lingue in 15 famiglie linguistiche. Viene considerato 6 set di allenamento e valutazione, tra cui tradurre test, modello monolingue, modello monolingue a pochi shot, modello multilingue, zero shot e few shot crosslingue. Si analizzano modelli monolingui e multilingui, con encoder-decoder ottenendo il miglior prestigio su tutti i 9 set. Si confrontano i modelli su MT5 e</sample>
    <sample id="260">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni?</sample>
    <sample id="261">Un buon pianificatore dovrebbe scrivere script che siano ragionevoli e fedeli alle restrizioni.</sample>
    <sample id="262">The content doesn't specify the number of authors involved in the article.</sample>
    <sample id="263">L'articolo parla di come mitigare le bias di etichetta nell'apprendimento in contesto. L'apprendimento in contesto è instabile a causa di scelte di design come l'ordine degli esempi in contesto. Prima di tutto, si identifica un nuovo tipo di bias, il bias di dominio dell'etichetta. Si propone un metodo di calibrazione per gestire tutti i tipi di bias. Si considera una configurazione di classificazione con un contesto di esempi etichettati, un testo da classificare e nomi di etichetta. Si definiscono tre tipi di bias: bias vanilla, bias del contesto e bias di dominio dell'etichetta. Per confermare l'effetto del corpus di un compito sulle previsioni del modello, si eseguono esperimenti con parole casuali. Si trova che parole casuali del dominio del compito possono fortemente influenzare le previsioni del modello, mentre parole casuali inglesi non lo fanno. Il modello si comporta diversamente su compiti con piccolo e grande bias</sample>
    <sample id="264">The paper discusses the challenge of multimodal text generation, especially audio - visual text generation. It points out that current models like machine translation and image captioning have flourished due to large scale pre - training and huge model capacity. However, audio - visual text generation faces more difficult data annotation and degradation due to varying conditions in different domains.The paper proposes a new task called transfer - able audio - visual text generation. The main challenge is multimodal domain shift, like visual style and audio energy. It suggests using a unified audio - semantic space to align visual concepts across domains.The framework aims to train a model that can quickly adapt to new multimodal domains with limited labeled data. It consists of three components: audio - visual meta - network, audio - visual encoder, and language model generator. The audio - visual meta - network maps different visual concepts into a unified audio - semantic space. It uses a set of learnable tokens called visual prefixes for audio clusters to improve the semantic of audio. The encoder and generator use an alpha - tuning mechanism to evaluate the contribution of different modalities to each word. The loss function and training details are also introduced. The paper builds two benchmarks based on MS - VTT and MS - BD for evaluation. It compares its approach with the state -</sample>
    <sample id="265">The name of the speaker is Vasudha.</sample>
    <sample id="266">Non so qual è l'affiliazione degli autori dell'articolo. Potresti dare più dettagli?</sample>
    <sample id="268">The most common errors are omission errors.</sample>
    <sample id="269">Ciao, sono James Finch e sono Sarah Finch e oggi vi parleremo di ABC eval, una nuova approccio dimensionale per l'valutazione dell'intelligenza artificiale conversazionale. Questo lavoro è stato fatto dal laboratorio Emory NLP, diretto dal professor Gino Choi all'Emory University, in collaborazione con Amazon Alexa AI. Supponiamo che tu hai appena sviluppato un modello di dialogo e vuoi vedere come si confronta con lo stato dell'arte attuale. La pratica comune è di utilizzare l'valutazione umana, come chiedere a giudici umani di selezionare quale delle due conversazioni sia migliore o di valutare le conversazioni utilizzando una scala Likert. Questi approcci funzionano bene per fornire valutazioni globali dell'qualità del dialogo, ma l'qualità del dialogo ha molti aspetti. Quindi, potresti voler valutare più dimensioni della qualità del chat per comprendere le forze e le debolezze del modello a un livello più fine. Un approccio è semplicemente</sample>
    <sample id="270">The authors are affiliated with the Emory NLP Lab led by Professor Gino Choi at Emory University and in collaboration with Amazon Alexa AI.</sample>
    <sample id="271">CFT significa Continual Fine-tuning.</sample>
    <sample id="272">Ci sono sette autori coinvolti nell'articolo.</sample>
    <sample id="273">Ciao! Mi chiamo Coyote e presenterò il nostro lavoro intitolato "Quando la traduzione richiede contesto: un'indagine multilingue dati - guidata". Questo lavoro è stato realizzato in collaborazione con Patrick Pronounce, Emi Lu, Andre F. T. Martins e Graham Neubig. Quindi, molte traduzioni dipendono dal contesto. Ad esempio, come tradurremmo "more" in questa frase? Beh, se la frase precedente era "things could start to get dangerous if the ministers find out", allora "more" si riferisce a un agente. Ma se la frase precedente era "Could it be anything serious, doctor?", allora "more" si riferisce a un macchie. Quindi, a seconda del contesto, il significato della parola cambia e quindi la sua traduzione cambia anche. Tuttavia, valutare come bene i modelli gestiscono casi come questi è abbastanza difficile. In primo luogo, perché solo una piccola porzione delle traduzioni dipende dal contesto, il che rende le metriche a livello di corpus come BLE</sample>
    <sample id="274">The name of the presenter is Justin Zhang.</sample>
    <sample id="276">The audio discusses a study on evaluating machine translation metrics for Indian languages. It highlights the need to study these metrics for other languages besides English. The study focuses on five Indian languages, Tamil, Malayalam, Hindi, Marathi, and Gujarati. They selected 200 sentences from the FLORES dataset and generated candidate translations using seven translation models. For human annotation, bilingual expert annotators were employed to evaluate the translations, marking errors, their types, severity, and providing an overall score. Error types were categorized into accuracy, fluency, and special category errors. The study found that newer models like NLLB and IndicTrans had fewer errors compared to older models like CBIT. Metrics like Comet metric variants showed the highest overall correlations for all languages. However, some metrics had skewed ranges of scores, making it hard to interpret them effectively. Splitting the dataset based on error types provided a more nuanced picture.</sample>
    <sample id="277">The new method is called "Multiset tagging and latent permutations".</sample>
    <sample id="278">Le parole contrassegnate sono una metodologia per identificare le parole che distinguono gruppi contrassegnati da quelli non contrassegnati.</sample>
    <sample id="279">I autori dell'articolo sono affiliati all'Università di Washington.</sample>
    <sample id="280">L'abstract parla di un lavoro che si occupa dell'emozione regolazione in conversazioni. L'obiettivo è prevedere l'etichetta emotiva di ogni enunciato in un dialogo. I modelli esistenti si concentrano sulla modellizzazione del parlante e del contesto, ma non esplorano bene la complementarietà delle informazioni multimediali. Il lavoro propone MultiEmo, un framework a livello di attenzione basato sulla fusione multimediale. Include un estrattore di feature unimodale, un modello di fusione multimediale basato su layer a testa multipla bidirezionali, una perdita focal contrastiva pesata per le classi minoritarie e semantica simile, e ha ottenuto prestazioni state dell'arte sui dataset Meld e IEMOCAP.</sample>
    <sample id="281">Coyote presents a work titled "When does translation require context? A data - driven multilingual exploration" done in collaboration with others. The work shows how context affects translation, using "mole" as an example. It then discusses the difficulty in evaluating models for context - dependent translations due to the small portion of translations relying on context. The work aims to answer two questions: when translation needs context and how well models handle these cases. To measure context usage, they use p - CXMI, which can measure at the sentence or word level. They analyze words with high p - CXMI on TED talk transcripts translated into 14 languages. They find patterns like dual pronouns in Arabic needing context and proper nouns in Chinese requiring context. They design a benchmark for document - level translation using tags for phenomena identified. When using corpus - level metrics, context - agnostic models perform best for BLEU, but context - aware models for Comet. WordF measure shows comparable performance for models with and without context. Using the MUDA benchmark, context - aware models are significantly more accurate than those without context.</sample>
    <sample id="282">Xuekai Zhu presenta un nuovo lavoro intitolato "StoryTrans: Non-Parallel Story Author Style Transfer with Discourse Representations and Content Enhancing" a ACL 2023. Il lavoro si concentra sulla trasformazione di stile tra storie non parallele a livello di storia, discorso e contenuto. Finora, la maggior parte delle ricerche si è concentrata sul livello di token o frase, come la trasformazione sentimentale o formale del testo. Il loro lavoro è un passo avanti significativo nel trasferimento di stile a livello di storia e discorso, che è cruciale per emulare lo stile dell'autore. Le sfide principali sono le complesse preferenze linguistiche dell'autore, come le strutture discorsive, che rendono difficile trasferire il contenuto specifico dello stile di un autore ad un altro. Per affrontare queste sfide, hanno proposto un modello di generazione chiamato StyleTrans, che impara le rappresentazioni discorsive dal testo di origine e le combina con le embedding di stile normali per generare</sample>
    <sample id="283">La prima struttura di dipendenza simmetrica menzionata è quella di Lisa Bart e Maggie.</sample>
    <sample id="284">The paper presents a new method for universal information extraction called FFUIE. It addresses the ambiguity in labeling spam boundaries and the mismatch between transformer feature extraction and information extraction. FFUIE uses a fuzzy spam boundary mechanism, where the boundary is represented as a continuous distribution of correct probability. It also proposes a fuzzy spam attention layer to guide the model's division process. Experiments on three information extraction tasks show that FFUIE achieves better performance than existing models. It demonstrates strong generalization capabilities and better information extraction ability with a simple structure. The visualization of the attention distribution shows that the model focuses on semantic information within a limited range of preceding tokens.</sample>
    <sample id="285">The speaker, Mingqiao from Peking University, presents their work on benchmarking factor error correction for dialogue summarization with a fan - grant evaluation framework. They discuss two main solutions: introducing factuality - related objectives in training or inference to make summarization models more faithful, and designing a factuality error correction model, FEC, independent of the summarization model. FEC takes the source document and model - generated summary as input and outputs a corrected summary. The speaker argues that there are flaws in how FEC models are evaluated, specifically with factuality metrics like FactCC and DAE, which may not be reliable and can lead to incorrect evaluation. They propose introducing manually annotated reference correction to address these issues, which provides more valuable data for training FEC models and allows for a more comprehensive and accurate evaluation. A new taxonomy of factuality errors is also proposed, with two classifications: content - based and form - based. The evaluation framework is built on the basis of ERRANT, an evaluation metric for grammar error correction, consisting of alignment, classification, and comparison steps. Experiments with different training modes show that training FEC models with reference summaries from dialogue summarization datasets yields the best results on reliable factuality metrics, highlighting the urgent need to change the evaluation method for FEC models.</sample>
    <sample id="286">The name of the speaker is James Finch.</sample>
    <sample id="287">Quattro.</sample>
    <sample id="288">I can't answer this question directly from the given content.</sample>
    <sample id="290">Non ho trovato le abbreviazioni dei cinque metodi per la prima domanda di ricerca nel contenuto fornito. Potresti fornire ulteriori dettagli?</sample>
    <sample id="291">The model is evaluated on multiple public and private downstream tasks such as named entity recognition, classification, part-of-speech tagging, and question answering.</sample>
    <sample id="294">CamemBERT viene inizialmente addestrato su 4 gigabyte di dati.</sample>
    <sample id="295">Adam Skulski</sample>
    <sample id="296">Valerio Basile presenta un lavoro frutto di una collaborazione tra l'Università di Torino e Amazon Alexa. L'approccio è basato su apprendimento supervisionato e richiede grandi set di dati manualmente annotati. Si concentra sull'ironia, un fenomeno linguistico latente e pragmatico. Hanno sviluppato un corpus chiamato EPIC, raccolto da social media, Reddit e Twitter, con 300 conversazioni brevi. Hanno utilizzato Prolific per la sottoscrizione e hanno selezionato 15 annotatori per ciascuna varietà di inglese. Hanno notato differenze tra gruppi di annotatori in base a diversi parametri. Hanno costruito modelli "perspettiva - consapevoli" per modellare queste differenze. I modelli mostrano una maggiore certezza nelle loro previsioni.</sample>
    <sample id="297">Il contenuto parla di un progetto che analizza le "dog whistles", segnali codificati in linguaggio. Si parla di un glossario con oltre 340 termini e simboli, specialmente per le "dog whistles" razziste, transfobe e antisemite. Si esplora come queste "dog whistles" siano usate in discorsi politici americani, in particolare nel contesto del "southern strategy" repubblicano. Si valuta l'efficacia di modelli di linguaggio nei riconoscimenti di queste "dog whistles". Si dimostra come queste "dog whistles" possano evadere la moderazione dei contenuti online, rendendo le frasi meno tossiche. In sintesi, il progetto mira a comprendere e analizzare meglio queste tecniche di comunicazione codificata.</sample>
    <sample id="298">Perder la prestazione è causato dalla deriva temporale.</sample>
    <sample id="299">The audio discusses improving the robustness of NLI models using minimax training. It points out that NLI models rely on shortcuts, which are correlations between input attributes and labels. These shortcuts make models perform well on in - distribution samples but fail on out - of - distribution adversarial tests. Current shortcut mitigation methods often require access to an auxiliary model and have limitations like needing domain - specific knowledge and assuming the learner will exploit the same shortcuts. The proposed method aims to reduce reliance on shortcuts by focusing on under - represented hard examples. It uses a minimax training objective between a learner and an auxiliary model. The learner tries to minimize NLI task loss while the auxiliary maximizes it by generating example weights. This way, the learner learns from hard examples that counteract shortcuts. The method doesn't assume shortcut types and uses a feed - forward network for the auxiliary. It's evaluated on three NLI datasets and shows consistent improvement in out - of - distribution performance while maintaining high in - distribution accuracy. The paper also explores if improvements transfer to larger models and conducts a qualitative evaluation of the learned example weight distribution. If you want to know more about this, feel free to ask me.</sample>
    <sample id="300">L'audio parla di un'interazione con un assistente virtuale. Si inizia con una domanda su un evento il 23. La persona realizza un errore e corregge dicendo "il 23 di venerdì". Poi chiede se l'evento è ancora in piedi. Successivamente, si può dare un comando verbale come "sostituisci l'evento nella frase precedente con 'esso'". Si parla di come la maggior parte dei sistemi di riconoscimento vocale supportano solo la dizione e non le modifiche vocali. Ci sono pochi software che riconoscono comandi vocali, come Dragon NaturallySpeaking e Microsoft Dictate. Si parla di come è possibile un'interazione più naturale e intuitiva come con un assistente umano. L'interazione di dizione è caratterizzata da un intrecciato di dizione e editing, senza parole di trigger. Il contributo principale è introdurre e formalizzare il compito di dizione interattiva, progettare un'interfaccia di raccolta di dati e creare un sistema di base per il compito.</sample>
    <sample id="302">Perché i token non sono ordinati dopo la prima fase.</sample>
    <sample id="303">Perché gli autori ritengono che la trasparenza sui metodi di mitigazione dei bias possa aiutare a migliorare la fiducia dei proprietari dei modelli nei loro modelli.</sample>
    <sample id="304">Gli input inaccettabili di coppia minima sono le frasi inaccettabili o non grammaticali che vengono mostrate insieme alle frasi accettabili o grammaticali nel paradigma di coppia minima.</sample>
    <sample id="305">The audio discusses weakly supervised learning, WSL. It explains that in WSL, data is labeled using weak sources like simple rules or low - quality crowdsourcing, which are cheaper but noisy. Directly training neural networks on this noisy data leads to memorization of the noise and poor generalization. The audio then presents research findings on WSL. It shows that clean validation samples are necessary for WSL to work properly, as without them, the models can't generalize beyond the weak labels. Increasing the number of clean validation samples improves performance. However, directly fine - tuning on clean data can achieve better performance than WSL approaches. The audio concludes that complex WSL methods aren't necessary if you can allow continued fine - tuning on clean samples.</sample>
    <sample id="306">Il contenuto audio parla di un'analisi su come i modelli di linguaggio gestiscono l'identificazione e il seguimento degli enti in un discorso. Sebastian Schuster e Najung Kim presentano un'analisi su come un agente deve comprendere un discorso, seguendo gli enti e come cambiano stato. Usano un esempio di ricetta per illustrare come un agente deve capire che gli ingredienti finiscono in una ciotola e diventano parte del farina. L'obiettivo principale è capire in che misura i grandi modelli di linguaggio sono in grado di seguire gli enti. Ci sono diversi ostacoli nel progettare una task per valutare questa capacità, come la presenza di pattern di pre - training che potrebbero influenzare la predizione corretta. Najung Kim spiega come hanno progettato la task coinvolgendo scatole e oggetti. L'input iniziale descrive il contenuto iniziale di ogni scatola e il modello deve completare l'input predando il contenuto finale. Hanno test</sample>
    <sample id="307">The authors used multiple public and private downstream tasks such as named entity recognition, classification, part-of-speech tagging, and question answering.</sample>
    <sample id="308">Ecco una sintesi: La presentazione è di Jenny, un primo anno di PhD all'Università Carnegie Mellon. Parla di caratterizzare i bias di progettazione nei modelli di dati e modello. Lavora in collaborazione con l'Università di Washington e l'AI Institute. Esempio di bias di progettazione: l'API Perspective non riconosce le parole offensive comuni in contesti indiani. Questo è un esempio di bias di progettazione. La posizionalità è il punto di vista delle persone a causa delle loro demografie, identità e esperienze di vita. I modelli e i dataset aggregano giudizi e opinioni di persone reali, rappresentando certe posizionalità. La ricerca studia la posizionalità dei modelli e dei dataset attraverso un framework chiamato NL Positionality. Comparano le annotazioni di diversi utenti con quelle dei modelli e dei dataset. Il framework differisce dalla letteratura sull'acqua degli annotatori perché confronta gli utenti con le previsioni e le etichette dei modelli e dei dataset, non solo l'accordo tra annotatori</sample>
    <sample id="309">L'inter-annotator agreement.</sample>
    <sample id="310">Wikipedia.</sample>
    <sample id="311">Non so qual è l'affiliazione degli autori dell'articolo. Potresti fornire più dettagli o un link all'articolo?</sample>
    <sample id="312">MultiInstruct differisce dagli altri parametri di riferimento in quanto si concentra sulla generazione di un dataset per compiti multimediali, mentre molti studi precedenti si sono concentrati sui compiti linguistici solo.</sample>
    <sample id="313">There are two authors involved in the article.</sample>
    <sample id="314">Non c'è una definizione di coordinazione binaria specifica qui. Potresti fornire più dettagli o contesto?</sample>
    <sample id="315">Non c'è informazione sul tempo di utilizzo dei prompt in questo studio.</sample>
    <sample id="316">The results show that the T5 smaller model has high variance in output quality, leading to bad performance.</sample>
    <sample id="317">The speaker, Peng Li from Fudan University, presents their work titled CodeIE. They explain that information extraction is a classic NLP task, involving extracting structured info from unstructured text. Common tasks include NER and RE. They discuss previous models using pre - trained language models like T5 and GPT - 3, which operate in a text - to - text manner during pre - training but have mismatched outputs during inference. To solve this, they propose CodeIE, transforming the task into a code - to - code code generation task. For NER, they design a prompt that defines a function for NER, adds comments, and initializes an entity list. They evaluate their method on three NER datasets and four RE datasets, comparing it to traditional prompts. Their approach using code - like language models and code - format prompts significantly outperforms traditional models like UIE and T5. They analyze that perplexity is higher on text - format inputs using T5 - like models, indicating better alignment with the information extraction task. With GPT - 3 and text - format prompts, there are many structural errors, but with CodeT5 and code - format prompts, errors are minimal.</sample>
    <sample id="318">Ciao, sono Janice Lavaque e presenterò i nostri lavori su Dr. Bert, un modello preaddestrato robusto in francese per il campo biomedico e clinico. In questa presentazione, iniziamo parlando di modellazione linguistica nel campo sanitario. Poi presenteremo le principali contribuzioni del nostro articolo. Introdurremo il primo modello biomedico in francese, chiamato Dr. Bert, basato su Roberta e addestrato su Natchez, un dataset di dati medici catturati dalla rete. Inoltre, faremo una comparazione dei modelli con diversi set di dati e configurazioni di preaddestramento. Successivamente, presenteremo i risultati su 11 compiti di biomedico e clinico non strutturati in francese. Infine, concluderemo gli esperimenti e forniremo dettagli su come accedere ai modelli. Da quando è stato rilasciato nel 2018, Bert è diventato uno degli approcci più efficaci per risolvere compiti di processamento del linguaggio</sample>
    <sample id="319">The work examines strategies of pretraining.</sample>
    <sample id="320">Il fattore di overfitting dovuto al riutilizzo del test non è grande, in quanto non si osserva la diminuzione dei ritorni.</sample>
    <sample id="321">The quality of simplification was evaluated by comparing the simplified text to the original text.</sample>
    <sample id="322">Enrico presenterà a ACL 23 su come un classificatore di testo impara la moralità. La moralità è ciò che ci aiuta a distinguere il giusto dallo sbagliato, il nostro compasso interno. È fondamentale per le società e per i modelli di linguaggio comprendere e riconoscere la moralità nei testi. L'approccio alla comprensione della moralità nei testi è stato già affrontato nella comunità di NLP, ma spesso viene trattata come una scala singola tra immorale e morale. Tuttavia, la moralità è soggettiva e diversi individui la etichettano diversamente. Per esempio, l'aborto può essere etichettato come immorale da alcuni e come morale da altri. La teoria delle fondamenta morali è una teoria popolare e ben stabilita che dice che ci sono cinque modi diversi in cui percepiamo la moralità, come ci sono cinque gusti diversi sulla lingua. Ogni azione o concetto "ticchetta" un diverso aspetto morale. Ogni individuo priorizza quest</sample>
    <sample id="323">The audio discusses a paper on dynamic heterogeneous graph reasoning with language models and knowledge repairation for Commonsense QA. It points out problems in existing methods like introducing irrelevant knowledge and limited interaction between models. The proposed method, DHLK, builds a HKG based on multiple knowledge bases. It uses a two-stage pretraining strategy and KRL to optimize structure and knowledge distribution. The HKG is encoded and fused with the language model. It removes subwords of precise entities and retrieves key entities from WordNet and Wiktionary. Entities with weak relevance are dynamically removed. The method uses RoBERTa and MaskSelfAttention to encode and fuse QA context and entities in the HKG. It applies attention to model subgraphs and incorporates relations into MaskSelfAttention. The HKG graph embedding is obtained by max-pooling question key entities. Finally, it predicts answers by inputting HKG graph embedding, patch-enhanced QA context embedding, and QA context embedding into an MLP.</sample>
    <sample id="324">Sì, i modelli linguistici hanno diversi bias politici.</sample>
    <sample id="325">Mi dispiace, ma non posso rendere il contenuto in italiano. Potresti fornire il testo in inglese che desideri tradurre?</sample>
    <sample id="326">La dissonanza cognitiva è quando due credenze o azioni sono inconsistenti. Ad esempio, se una persona dice che sa che le sigarette possono ucciderla e poi fuma.</sample>
    <sample id="327">The work presents Meta Tower, a novel vision - language model architecture. It aggregates insights from unimodal experts at different levels. The architecture consists of text and visual encoders, a cross - model encoder, and managers. Managers adaptively combine insights from different unimodal experts. Meta Tower uses RoboBERTa and CLIP ViT - B as unimodal encoders. It achieves superior performance on various downstream tasks with only 4 million images for pre - training. Compared to Bridge Tower, Meta Tower significantly improves performance, especially on VQA - V2 test standard. It outperforms many base - size models trained on 4 million data and surpasses some models trained with more data or parameters. The visualization of average aggregation weights shows a similar progressive trend in each cross - model layer for textural and visual managers, which is inconsistent with the intuition that the need for unimodal semantic knowledge decreases with increasing model layers.</sample>
    <sample id="328">GPT-4 è il modello linguistico più liberale.</sample>
    <sample id="329">The work focuses on zero-shot video sentence localization. It aims to find relevant video segments for a given natural language query. Existing methods require manual annotation, which is costly. This paper proposes a noise - resistant structural pseudo - label generation method. It uses a pre - trained image caption model to generate complex pseudo - queries. Then, it measures relevance between video frames and pseudo - queries to generate pseudo - events. It reduces the weight of noisy samples and corrects noisy labels to reduce label noise. The method is tested on two datasets and shows good performance.</sample>
    <sample id="330">Yes, the cumulative training performs equal or better than iterative across the board.</sample>
    <sample id="331">Sarah Bobby.</sample>
    <sample id="332">I dati sono stati tratti da un corpus di discorsi multilingue.</sample>
    <sample id="333">The audio discusses a work on injecting key knowledge in nearest neighbor machine translation. It starts by acknowledging collaborators from Nanjing University and the University of Hong Kong. The work focuses on neural machine translation, highlighting the problem of non - smooth representation spaces in neural networks, which limits generalization. The authors propose the INK framework to inject key knowledge. It involves a training loop with two steps: extracting key knowledge from a datastore to guide an adapter to adjust representations, and then updating representations to refresh the datastore asynchronously. The training loop runs until convergence. The framework optimizes the adapter with a combined learning objective. Experiments show that INK outperforms the state - of - the - art KMT system and achieves the best performance after smoothing the representation space. The INK framework is more effective than using an adapter baseline, bringing larger performance improvements. It also shows that INK achieves higher BLEU scores with less memory space. The audio concludes by proposing a novel training framework that iteratively refines the representation space.</sample>
    <sample id="335">Il nome del relatore è Matthias Lindemann.</sample>
    <sample id="336">Il trasferimento interlinguistico è un processo in cui un modello di apprendimento automatico viene addestrato su un insieme di dati in una lingua e poi utilizzato per compiti in altre lingue.</sample>
    <sample id="337">The speech is about a research on handling out - of - vocabulary words in embedding - based downstream models. It starts by acknowledging the difficulty in representing out - of - vocabulary words but their importance. The researchers observe word formation and associate it with relevant words to infer meaning. They develop a neural approach using a word relationship graph. Each word or word piece is a node in the graph, and its embedding is a node feature. They preserve all nodes in the first layer for complete word piece information. For the second layer, they sample a fixed number of nodes to mitigate noise. They use a graph neural network to process the word relationship graph. To assign node attributes to out - of - vocabulary nodes, they use a self - attention network. They apply two levels of graph attention network to capture graph information. They incorporate a residual block to get a graph - level representation. They use a simple one - layer graph convolutional network for word formation. To make the vector space of the background embedding model better, they apply contrastive learning in the loss function. They demonstrate that their model outperforms SOTA in intrinsic and extrinsic tasks. It can benefit static and contextual models in downstream tasks. They discuss the possibility of applying the model to other languages, especially agglutin</sample>
    <sample id="338">Benjamin, un rappresentante del suo gruppo di ricerca, presenta un lavoro intitolato "Sono le spiegazioni umane sempre utili per l'valutazione obiettiva delle spiegazioni naturali umane in lingua naturale?". È un lavoro di collaborazione tra Rensselaer Polytechnic Institute, Northeastern University e IBM Research. Il lavoro si concentra su tre sezioni: una struttura unificata, esperimenti preliminari e l'valutazione di cinque dataset e due modelli. Molti ricercatori hanno cercato assistenza umana, inclusi i lavoratori di massa e gli esperti, per annotare etichette e spiegazioni naturali umane, per addestrare i modelli a generare spiegazioni umane comprensibili e migliorare le prestazioni di previsione e la capacità di ragionamento dei modelli. Prima di utilizzare le spiegazioni come standard, si deve valutare la qualità delle spiegazioni umane annotate. Le spiegazioni umane possono essere soggettive e dipendenti dal compito. Il lavoro propone una nuova matrice</sample>
    <sample id="339">I'm sorry, but the information about the affiliations of the authors is not provided in the text you've given. Could you provide more details or context?</sample>
    <sample id="340">Il lavoro presenta ParaAMR, un gran dataset di parafilie sinteticamente diverso ottenuto tramite backtranslation. È un progetto congiunto con Veron, Yi Hong, Anup, Kai Wei e Arun. La generazione di parafilie è un compito importante nell'NLP, beneficia applicazioni come la risposta alle domande e il miglioramento della robustezza. I dati umanamente annotati esistenti come MRPC, PANCORR hanno qualità ma sono limitati in scala. I dataset automaticamente generati come backtranslation mancano di diversità sintattica. ParaAMR utilizza AMR, un grafo diretto che cattura il significato astratto di una frase. Si propone di utilizzare backtranslation per generare parafilie sinteticamente diverse. Si ottengono i grafici AMR di una frase sorgente, si cambia il focus, si modifica il grafo e si genera testo. Ci sono circa 15 milioni di frasi sorgenti in ParaAMR e circa 6,9 parafilie per frase sorgente. Parafilie ParaAMR sono più sinteticamente diverse</sample>
    <sample id="341">The authors use one model for every latency regime.</sample>
    <sample id="342">The paper presents a large-scale personalized dialogue dataset called LiveChat, constructed from live streaming. It's a video - sourced dataset, different from existing text - sourced ones. The dataset is crucial for developing applications like virtual streamers and virtual employees. Challenges in current research include insufficient persona information and lack of suitable dialogue turns. The dataset can address these issues. It's constructed in three steps: collecting original streaming videos, extracting audio and transcribing, collecting audience comments and constructing dialogues, and collecting persona information. The persona extraction includes basic profiles by manual labeling and rules, and technical profiles by rules and a trained persona classifier. Compared to other open - domain dialogue datasets, LiveChat is video - sourced, has larger scale, detailed persona annotations, and longer average sessions. Experiments show that extracted persona and longer average sessions benefit response modeling. For address recognition, single stream better outperforms double stream. The performance of the proposed dialogue models on LiveChat is also investigated.</sample>
    <sample id="343">Ciao a tutti, sono Maksym, e oggi, insieme al mio coautore Martin, stiamo presentando il nostro lavoro "The Kid Must Have: Evaluating Knowledge Integration from Multiple Sources". Questo lavoro è una collaborazione tra l'Università di McGill, Mila e Microsoft Research. I modelli di comprensione del linguaggio naturale si basano su una varietà di fonti di conoscenza, come quelle contenute nei loro parametri, acquisite tramite un pre-allenamento, e quelle date in input durante l'infrazione. Recenti lavori in task come la risposta alle domande mostrano che i modelli possono utilizzare la conoscenza acquisita durante il pre-allenamento per risolvere il task. Ma la comprensione del linguaggio naturale spesso richiede conoscenza che viene fornita durante l'infrazione. Ad esempio, nella frase "John saw the newly elected president on TV", i parametri pre-allenati possono contenere informazioni su ciò che i presidenti fanno e su cosa sia la TV, ma non possono conoscere con certezza chi sia l'entità specifica di John o chi sia il nuovo</sample>
    <sample id="344">I svantaggi dei metodi basati su alberi sono che sono spesso non dati e devono essere ottenuti in qualche modo. Questo può essere complicato e talvolta costoso computazionalmente. Inoltre, richiedono una pre-elaborazione formale specifica delle forme logiche, ad esempio per gestire simboli variabili.</sample>
    <sample id="345">Il paper di Matthias Lindemann introduce un modello di composizione e generalizzazione senza alberi utilizzando multiset tagging e permutazioni latenti. L'obiettivo è mostrare una forte generalizzazione a ricorsione più profonda senza dipendere da alberi. Il modello prevede l'output dall'input in due passaggi. Prima, ogni token di input viene etichettato con un multiset di token che appariranno nell'output. Dopo il primo passaggio, i token giusti sono presenti ma non ordinati. Nella seconda fase, un altro modello predice una permutazione per metterli nell'ordine corretto. Il modello di permutazione predice una permutazione senza restrizioni rigide, rendendo l'approccio flessibile e espressivo. Concettualmente, il modello di permutazione determina quale multiset token mettere in ogni posizione dell'output, partendo da sinistra a destra. Il modello ha ottenuto risultati superiore agli altri modelli senza alberi sul benchmark Cogs, in particolare per la generalizzazione a</sample>
    <sample id="346">I'm sorry, but the information about the affiliations of the authors is not provided in the text you've given. Could you provide more details or context?</sample>
    <sample id="347">Ciao! Sono Myra e oggi parlerò del nostro articolo "Personaggi marcati: utilizzare promemoria di lingua naturale per misurare stereotipi in modelli di linguaggio". Questo lavoro è stato fatto in collaborazione con Sander Moosh e Dan Jurafsky.Nel corso degli anni, molti hanno documentato la prevalenza di pregiudizi sociali e stereotipi in grandi modelli di linguaggio, LLM. Tuttavia, queste misure hanno varie limitazioni. Solitamente si affidano a set di dati manualmente costruiti, che sono molto tempo消费的 da curare, e misurano solo stereotipi molto specifici, non generalizzandosi bene a altre demografie o contesti, o semplicemente catturando associazioni molto generali e vaste, come associazioni negative con gruppi specifici.Inoltre, la maggior parte del lavoro in questo campo non tiene conto dell'intersezione, il concetto che identità sociali multifaccettate possono comporre pregiudizi e essere luoghi unici di danno.Abbiamo superato quest</sample>
    <sample id="348">L'articolo parla di un metodo per misurare stereotipi in modelli di linguaggio utilizzando personaggi generati da prompt naturali. I limiti dei metodi esistenti sono che dipendono da dataset manuali e misurano stereotipi specifici. Questo lavoro usa personaggi generati per essere generalizzabili a qualsiasi demografia. Si analizzano i personaggi generati da GPT-4 e si notano interessanti pattern. Il metodo ha due parti: generazione di personaggi e identificazione di parole distintive. La seconda parte, Marked Words, identifica parole che distinguono gruppi marcati da quelli non marciti. Rispetto ai personaggi umani scritti, quelli generati contengono più stereotipi, ma la distribuzione delle parole è diversa. I risultati mostrano come parole apparentemente positive facilitino stereotipi e narrazioni essenziali.</sample>
    <sample id="349">Ciao, sono Jin Wei Yi dalla University of Science and Technology of China. È un piacere presentare un video di pubblicità breve su Paper. Stai copiando il mio modello? Proteggere il copyright dei modelli di grandi lingue per servizi di embedding attraverso un marchio di acquerello. Iniziamo con l'introduzione del contesto riguardante i servizi di embedding. Attualmente, modelli di grandi lingue come GPT, Llama, Pile sono eccezionali nell'intersezione tra intelligenza artificiale e intelligenza naturale. I servizi di embedding sono uno dei servizi costruiti su modelli di grandi lingue per assistere nelle varie attività di NLP. Ad esempio, OpenAI offre un API di embedding basata su GPT. Tuttavia, recenti studi hanno dimostrato che l'attaccante può rubare il modello attraverso l'apprendimento da embedding e fornire servizi simili. Quindi, è necessario proteggere il copyright dei servizi di embedding. Per proteggere il copyright dei servizi di embedding,</sample>
    <sample id="350">Il contenuto parla di un paper intitolato "What's the Meaning of Superhuman Performance in Today's NLU" presentato da Simone Deske. Nel corso degli ultimi cinque anni, la valutazione basata su leaderboard è diventata lo standard di fatto nell'NLP. I sistemi spesso raggiungono livelli umani o superumani in questi benchmark, chiamati "benchmarks saturati". Tuttavia, non è chiaro cosa significhi superare gli umani in compiti che richiedono ragionamento e inferenza. I modelli sono brittici in molti modi, come non essere in grado di generalizzare, soffrire di attacchi avversari, dipendere troppo da modelli sporadici, mancare di sensibilità a perturbazioni basali come la negazione e essere sovra-sensibili a perturbazioni meno importanti. In questo paper, si analizzano due benchmark popolari, SuperGlue e Squad, per vedere quanto i leaderboard corrispondano veramente agli umani. Su SuperGlue, gli umani si classificano al 8º posto, mentre</sample>
    <sample id="351">The paper investigates if Conll 2003 named entity taggers still work well in 2023. It looks at generalization using NER task. Models using Conll 2003 for 20 years raise questions. The paper develops Conll + dataset from 2020 news. They fine - tune 20 models on Conll 2003 and evaluate on Conll 2003 and Conll + test sets. They calculate F1 percentage change for generalization. Good generalization needs better model architecture, larger model size, and more fine - tuning examples. Performance drop is mainly due to temporal drift, not adaptive overfitting. The answer is yes, Conll 2003 taggers still work well. The paper calls for more research on improving model generalization.</sample>
    <sample id="352">ABC-Eval è un approccio dimensionale per valutare l'intelligenza artificiale conversazionale. È stato sviluppato dal lab Emory NLP di Emory University, in collaborazione con Amazon Alexa AI. Questo metodo cerca di ridurre la soggettività delle valutazioni umane, annotando se le risposte del modello esprimono determinati comportamenti, come rispondere con informazioni irrilevanti o contraddizione.</sample>
    <sample id="353">L'articolo introduce un approccio innovativo per la generazione di codice Python attraverso domande di chiarimento. Si focalizza sulla soluzione del problema dell'input under specification, comune nei casi reali. L'idea è che le domande di chiarimento possano raccogliere informazioni mancanti e migliorare la precisione della generazione di codice. Si propone un metodo per creare un dataset sintetico, CodeQA, che contiene domande di chiarimento su operazioni chiave. Un pipeline di codifica che include un predicatore di domande di chiarimento, un selezionatore di domande e un generatore di codice è stato sviluppato. Gli esperimenti mostrano che le domande di chiarimento aiutano la generazione di codice, migliorando le prestazioni in termini di metriche di valutazione. Tuttavia, ci sono ancora alcuni errori che indicano la necessità di migliorare ulteriormente il metodo. L'articolo conclude con la presentazione di un'analisi dettagliata dei risultati e delle potenziali direzioni per il futuro.</sample>
    <sample id="354">Fino al 2020.</sample>
    <sample id="355">Mi dispiace, ma non ho capito cosa devi tradurre in italiano. Puoi fornire il testo in inglese che vuoi tradurre?</sample>
    <sample id="356">Gli autori dell'articolo sono affiliati a Alexander Cola e Ivan Titov.</sample>
    <sample id="357">Siyu Yuan.</sample>
    <sample id="358">There are five authors involved in the article.</sample>
    <sample id="359">L'approccio viene confrontato con architetture specifiche dedicate a simulST.</sample>
    <sample id="361">Armen Norbash, a PhD student at Carnegie Mellon University, presents Counter Comp. It uses counterfactual scenarios to improve compositional generalization for multi - step quantitative reasoning. The work focuses on question - answering tasks, like calculating net change in revenue from 2019 to 2020. State - of - the - art models struggle with multi - step tasks due to memorizing spurious patterns. The proposed method mines counterfactual scenarios from the input to avoid this. It uses positive and negative examples to add an auxiliary metric learning loss to the training procedure. This improves performance on in - distribution and out - of - distribution samples. The method helps the model attend to more meaningful tokens during training. For more info, check out the poster or contact the listed contacts.</sample>
  </task>
</testset>