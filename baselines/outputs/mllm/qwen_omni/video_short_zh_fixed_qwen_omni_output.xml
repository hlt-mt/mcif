<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">嗯…这个嘛，语言模型的主要数据来源是各种网站，像wikipedia.org，nytimes.com这些。你要是还有啥想知道的，尽管问哈。</sample>
    <sample id="1">这篇论文的作者所属机构有McGill University，Mila和Microsoft Research。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="2">DEPLAIN：一种用于句子和文档简化德语平行语料库的同语翻译。雷吉娜·斯托登，奥马尔·莫门，劳拉·卡尔迈耶。海因里希·海涅大学，德国。ACL 2023。</sample>
    <sample id="3">DEPLAIN：一种用于句子和文档简化德语平行语料库的同语翻译。雷吉娜·斯托登，奥马尔·莫门，劳拉·卡尔迈耶。海因里希·海涅大学，德国。ACL 2023。1. 文本简化。什么是，为什么和如何？</sample>
    <sample id="4">文本简化示例。</sample>
    <sample id="5">文本简化示例。</sample>
    <sample id="6">文本简化示例。</sample>
    <sample id="7">文本简化示例。</sample>
    <sample id="8">德语文本简化语料库</sample>
    <sample id="9">德语文本简化语料库。</sample>
    <sample id="10">德语文本简化语料库。句子级别。</sample>
    <sample id="11">好的，你可以说出英文内容了，我会帮你翻译成中文。</sample>
    <sample id="12">好的，你可以说出英文内容了，我会帮你翻译成中文。</sample>
    <sample id="13">德语文本简化语料库。</sample>
    <sample id="14">类型简化。简化类型。简化变换。</sample>
    <sample id="15">好的，你可以说出英文内容了，我会帮你翻译成中文。</sample>
    <sample id="16">左边的图表是“类型简化”，右边的图表是“简化变换”。</sample>
    <sample id="17">好的，你可以说出英文内容了，我会帮你翻译成中文。</sample>
    <sample id="18">左边的图表标题是“类型简化”，有三类简化：Simplicity，LexSimp和StructSimp。不同类型的文本，如news，bible，L2，fiction，每类文本的数量不同。右边的图表标题是“简化转换”，显示了两种简化方式DEplain-apa和DEplain-web在不同转换类型，如reordering，rephrasing，lexical substitution，word addition，word deletion，上的百分比。</sample>
    <sample id="19">3. 使用案例自动对齐和简化自动对齐评估结果自动对齐方法在1:1，上部和n:m能力，下部，的评估结果，名称描述1:1，上部，n:m，能力，下部，P R F1 F0.5 P R F1 F0.5LHA基于句子嵌入相似性的分层对齐，0.94 0.41 0.57 0.747 - - - -Sent-LaBSE跨语言的Language-agnostic BERT变换器的相似嵌入，0.961 0.444 0.608 0.780 - - - -Sent-RoBERTa跨英语和德语RoBERTa的相似嵌入，0.960 0.444 0.607 0.779 - - - -CATS-C3G不同的相似度度量，例如n-gram，C3G，/词向量，0.247 0.553 0.342 0.278 - - - -VecAlign基于多语言句子</sample>
    <sample id="20">自动对齐评估。对齐方法在1:1，上部，和n:m能力，下部，的结果。名称描述1:1，P，R，F1，F0.5，n:m，P，R，F1，F0.5，LHA基于句子嵌入相似性的分层对齐。.94.41.57.747- - - -，Sent-LaBSE跨语言的Language-agnostic BERT变换器的相似嵌入。.961.444.608.780- - - -，Sent-RoBERTa跨英语和德语RoBERTa的相似嵌入。.960.444.607.779- - - -，CATS-C3G不同的相似性度量，例如n-gram，C3G，/词向量。.247.553.342.278- - - -，VecAlign基于多语言句子嵌入的多语言对齐器。.271.404.323.290.260.465.3</sample>
    <sample id="21">自动对齐评估。对齐方法在1:1和n:m能力下的结果。</sample>
    <sample id="22">好的，你可以说说看具体是哪部分的英文内容需要翻译了。</sample>
    <sample id="23">好的，你可以说说看具体是哪部分的英文内容需要翻译了。</sample>
    <sample id="24">自动对齐评估，结果为1:1和n:m能力的对齐方法，上部为1:1部分，下部为n:m部分。</sample>
    <sample id="25">好的，你可以说说具体的内容了。</sample>
    <sample id="26">自动对齐评估。结果：1:1和n:m能力的对齐方法。</sample>
    <sample id="27">好的，你可以说出具体的英文内容，我会帮你翻译。</sample>
    <sample id="28">文档级别：使用长训练数据的微调长-mBART进行文档简化。n表示训练数据的长度。表格1：DEPLAIN-APA测试，n = 48。表格2：DEPLAIN-WEB测试，n = 147。句子级别：使用微调mBART进行句子简化。n表示训练数据的长度。表格3：DEPLAIN-APA测试，n = 1231。表格4：DEPLAIN-WEB测试，n = 1846。</sample>
    <sample id="29">文档级别：使用长训练数据的微调长-mBART进行文档简化。n表示训练数据的长度。表格1：DEPLAIN-APA测试，n = 48。表格2：DEPLAIN-WEB测试，n = 147。句子级别：使用微调mBART进行句子简化。n表示训练数据的长度。表格3：DEPLAIN-APA测试，n = 1231。表格4：DEPLAIN-WEB测试，n = 1846。</sample>
    <sample id="30">文档级别：使用微调的长-mBART进行文档简化。n表示训练数据的长度。表格1：DEPLAIN-APA测试，n = 48。表格2：DEPLAIN-WEB测试，n = 147。句子级别：使用微调的mBART进行句子简化。n表示训练数据的长度。表格3：DEPLAIN-APA测试，n = 1231。表格4：DEPLAIN-WEB测试，n = 1846。</sample>
    <sample id="31">文档级别：使用微调的长-mBART进行文档简化结果。n表示训练数据的长度。表格1：DEPLAIN-APA测试，n=48。表格2：DEPLAIN-WEB测试，n=147。句子级别：使用微调的mBART进行句子简化结果。n表示训练数据的长度。表格3：DEPLAIN-APA测试，n=1231。表格4：DEPLAIN-WEB测试，n=1846。</sample>
    <sample id="32">好的，你可以说说具体是哪部分的英文内容要翻译了。</sample>
    <sample id="33">好的，你可以说出具体的英文内容，我会帮你翻译。</sample>
    <sample id="34">谢谢。要了解更多详情，请查看我们的论文。欢迎在ACL 2023会议上参观我们的海报。</sample>
    <sample id="35">Patrick Fernandes，Kayo Yin，Emmy Liu，André F. T. Martins，Graham Neubig。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="36">他们使用T5 XL模型获得82%-87%的准确率。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="37">YES！</sample>
    <sample id="38">嗯…这个方法新颖之处在于它能对聊天机器人在对话中的行为进行标注，像判断回复是否相关，有没有缺乏同理心或者自相矛盾的情况。这样能更准确地评估聊天机器人的表现。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="39">嗯…这个嘛，现有弱监督方法的成功很大程度上依赖于标签的质量。如果还有啥疑问，你可以再问我哦。</sample>
    <sample id="40">嗯…这个嘛，你可以多听一些歌，至少听一些每首歌，然后读一读每首歌的资料。这样应该能提高分数。如果还有其他问题，随时跟我说哈。</sample>
    <sample id="41">这篇论文有五位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="42">协调结构中的依赖关系。- 花束/斯坦福大学（通用依赖性）：Homer loves Lisa， Bart， and Maggie。- 链/莫斯科：Homer loves Lisa， Bart， and Maggie。- 连接头/布拉格：Homer loves Lisa， Bart， and Maggie。- 多头/伦敦：Homer loves Lisa， Bart， and Maggie。</sample>
    <sample id="43">协调的依赖结构。- Bouquet/Stanford（通用依赖性）：Homer loves Lisa, Bart, and Maggie。- Chain/Moscow：Homer loves Lisa, Bart, and Maggie。- Conjunction-headed/Prague：Homer loves Lisa, Bart, and Maggie。- Multi-headed/London：Homer loves Lisa, Bart, and Maggie。</sample>
    <sample id="44">协调的依赖结构。- Bouquet/Stanford，通用依赖性：Homer loves Lisa， Bart， and Maggie。- Chain/Moscow：Homer loves Lisa， Bart， and Maggie。- Conjunction-headed/Prague：Homer loves Lisa， Bart， and Maggie。- Multi-headed/London：Homer loves Lisa， Bart， and Maggie。</sample>
    <sample id="45">协调的依赖结构。- Bouquet/Stanford（通用依赖性）：Homer loves Lisa, Bart, and Maggie。- Chain/Moscow：Homer loves Lisa, Bart, and Maggie。- Conjunction-headed/Prague：Homer loves Lisa, Bart, and Maggie。- Multi-headed/London：Homer loves Lisa, Bart, and Maggie。</sample>
    <sample id="46">协调的依赖结构。- Bouquet/Stanford（通用依赖性）：Homer loves Lisa， Bart， and Maggie。- Chain/Moscow：Homer loves Lisa， Bart， and Maggie。- Conjunction-headed/Prague：Homer loves Lisa， Bart， and Maggie。- Multi-headed/London：Homer loves Lisa， Bart， and Maggie。</sample>
    <sample id="47">协调的依赖结构。- Bouquet/Stanford，通用依赖性：Homer loves Lisa， Bart， and Maggie。- Chain/Moscow：Homer loves Lisa， Bart， and Maggie。- Conjunction-headed/Prague：Homer loves Lisa， Bart， and Maggie。- Multi-headed/London：Homer loves Lisa， Bart， and Maggie。</sample>
    <sample id="48">协调的依赖结构。- Bouquet/Stanford（通用依赖性）：Homer loves Lisa， Bart， and Maggie。- Chain/Moscow：Homer loves Lisa， Bart， and Maggie。- Conjunction-headed/Prague：Homer loves Lisa， Bart， and Maggie。- Multi-headed/London：Homer loves Lisa， Bart， and Maggie。</sample>
    <sample id="49">协调的依赖结构。- Bouquet/Stanford（通用依赖性）：Homer loves Lisa， Bart， and Maggie。- Chain/Moscow：Homer loves Lisa， Bart， and Maggie。- Conjunction-headed/Prague：Homer loves Lisa， Bart， and Maggie。- Multi-headed/London：Homer loves Lisa， Bart， and Maggie。</sample>
    <sample id="50">协调的依赖结构。- Bouquet/Stanford（通用依赖性）：Homer loves Lisa， Bart， and Maggie。- Chain/Moscow：Homer loves Lisa， Bart， and Maggie。- Conjunction-headed/Prague：Homer loves Lisa， Bart， and Maggie。- Multi-headed/London：Homer loves Lisa， Bart， and Maggie。</sample>
    <sample id="51">词序倾向于最小化依赖长度：。好的。坏的。</sample>
    <sample id="52">词序倾向于最小化依赖长度：</sample>
    <sample id="53">词序倾向于最小化依赖长度：。好的。坏的。</sample>
    <sample id="54">词序倾向于最小化依赖长度：。好的。坏的。</sample>
    <sample id="55">词序倾向于最小化依赖长度：。好的。坏的。好的。好的。</sample>
    <sample id="56">词序倾向于最小化依赖长度：。好的。坏的。好的。好的。</sample>
    <sample id="57">词序倾向于最小化依赖长度：。好的。坏的。好的。好的。</sample>
    <sample id="58">词序倾向于最小化依赖长度：。好的。坏的。好的。好的。</sample>
    <sample id="59">词序倾向于最小化依赖长度：。好的。坏的。好的。好的。</sample>
    <sample id="60">词序倾向于最小化依赖长度：。好的。坏的。好的。好的。</sample>
    <sample id="61">词序倾向于最小化依赖长度：。好的。坏的。好的。好的。</sample>
    <sample id="62">从增强版的Penn Treebank中提取的协调统计信息，由Marcus等人，1993年，Ficler和Goldberg，2016年，左连词倾向于较短，之前观察到，这种倾向随着长度差异而增加，Gibson等人，1996年，88-90页，简要注意到，但仅当主语在左边或缺失时，我看到Bart和Lisa，Homer来了并打喷嚏，否则当它在右边时，Ted和Ned笑了。</sample>
    <sample id="63">从增强版的宾夕法尼亚树库中提取的关于协调的统计数据，来自Marcus等人，1993年，Ficler和Goldberg，2016年：。左连词倾向于较短，以前观察到。这种趋势随着长度差异而增长，曾在Gibson等人，1996年，88-90页，中简要注意到，但仅当主语在左边或缺失时，例如，我看到Bart和Lisa；Homer来了，打喷嚏，否则当它在右边时，例如，Ted和Ned笑了。</sample>
    <sample id="64">从增强版的宾夕法尼亚树库中提取的关于协调的统计数据，Marcus等人，1993年，Ficler和Goldberg，2016年：。左连词倾向于较短，以前观察到。这种倾向随着长度差异而增长，Gibson等人，1996年，88-90页，曾简要注意到。但仅当主语在左边或不存在时，I saw Bart and Lisa， Homer came and sneezed，否则当它在右边时，Ted and Ned laughed，</sample>
    <sample id="65">从增强版的宾夕法尼亚大学树库中提取的关于协调的统计数据，Marcus等人，1993年，Ficler和Goldberg，2016年：。- 左边的联合词倾向于较短，以前观察到。- 这种倾向随着长度差异而增长，Gibson等人，1996年，88-90页，曾简要注意到。- 但仅当主语在左边或缺失时，I saw Bart and Lisa; Homer came and sneezed，- 不当它在右边时，Ted and Ned laughed，</sample>
    <sample id="66">从增强版的宾夕法尼亚树库中提取的关于协调的统计数据，(Marcus et al. 1993，Ficler和Goldberg 2016)：。左连词倾向于较短，(以前观察到)。这种倾向随着长度差异而增长，(Gibson等人1996:88-90中简要注意到)。但仅当主语在左边或缺失时，(我看到Bart和Lisa; Homer来了打喷嚏)，。当它在右边时，(Ted和Ned笑了)。</sample>
    <sample id="67">从增强版的Penn Treebank中提取的关于协调的统计数据，Marcus等人，1993年，Ficler和Goldberg，2016年：。- 左边的并列成分倾向于较短，之前观察到。- 这种倾向随着长度差异而增长，Gibson等人，1996年，88-90页，有简要注意到。- 但仅当主语在左边或缺失时，I saw Bart and Lisa， Homer came and sneezed，- 不当它在右边时，Ted and Ned laughed，</sample>
    <sample id="68">英语中的连词长度统计，从增强版的Penn Treebank中提取，由Marcus等人，1993年，Ficler和Goldberg，2016年，得出：左连词倾向于较短，之前观察到，这种倾向随着长度差异而增长，Gibson等人，1996年，88-90页，曾简要注意到，但仅当主语在左边或缺失时，我看到Bart和Lisa；Homer来了，打喷嚏，当它在右边时，Ted和Ned笑了。</sample>
    <sample id="69">从增强版的Penn Treebank中提取的关于协调的统计数据，Marcus et al. 1993，Ficler和Goldberg 2016：。左连词倾向于较短，以前观察到。这种倾向随着长度差异而增长，Gibson等人1996年88-90页曾简要注意到。但仅当主语在左边或不存在时，I saw Bart and Lisa， Homer came and sneezed，。当它在右边时，Ted and Ned laughed，不适用。</sample>
    <sample id="70">图1：根据联合长度绝对差异的较短左联合体比例，带置信区间</sample>
    <sample id="71">图1：根据联合长度绝对差异的较短左联合体比例，带置信区间</sample>
    <sample id="72">图1：根据联合长度绝对差异的较短左联合体比例，带有置信带。</sample>
    <sample id="73">协调的依赖结构兼容性

- Bouquet/Stanford，通用依赖性：Homer loves Lisa， Bart， and Maggie。不兼容
- Chain/Moscow：Homer loves Lisa， Bart， and Maggie。不兼容
- Conjunction-headed/Prague：Homer loves Lisa， Bart， and Maggie。兼容
- Multi-headed/London：Homer loves Lisa， Bart， and Maggie。兼容</sample>
    <sample id="74">看论文以了解完整的论点！在海报展期间与我们交谈！</sample>
    <sample id="75">三位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="76">嗯…从图上看，Bible领域的Simplicity，LexSimp和StructSimp都比较高，相对来说简化程度比较大。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="77">“Marge read yesterday it”和“Marge read this absolutely fascinating book about bees yesterday.”</sample>
    <sample id="78">嗯，可以的。DrBERT模型，NACHOS数据集和训练脚本都是免费的，而且是MIT许可的。你要是有啥问题或者想再聊聊，随时跟我说哈。</sample>
    <sample id="79">DEplain-APA中包含来自APA格式的文档。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="80">更好的模型架构，更大的模型规模，更多的微调示例。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="81">嗯…这个嘛，是从Penn Treebank里提取的统计数据。简单说，就是看左并列词的长度，和右并列词的长度比较。如果左并列词更短，那这个趋势就很明显。你要是还有啥疑问，可以再问我哈。</sample>
    <sample id="82">嗯…这个嘛，你可以设置不同长度的支配词，然后看它对左连词长度的影响。比如说，有支配词在左边，右边的情况，还有没有支配词的情况。通过比较这些不同条件下的左连词长度，就能研究支配词位置的影响了。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="83">基线分类器在不平衡数据上的训练效果不太好，AUC值比较低，而且小标注数据集的准确率43/901，还不如随机猜测。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="84">这篇论文有四位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="85">示例对话中的角色名字没有提到呢。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="86">在形式性和词汇连贯性上，语境感知MT模型比语境无关模型更有优势。嗯，你要是还有啥疑问可以接着问哈。</sample>
    <sample id="87">Johns Hopkins University，Purdue University，MIT和Meta AI。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="122">嗯…这个框架通过比较金标准标签，模型预测和每个群体的注释来量化立场。具体来说，会用皮尔逊相关系数来衡量。你要是还有啥疑问，可以接着问哦。</sample>
    <sample id="155">嗯…这个我不太清楚具体的研究结果呢。你可以再找找相关的研究资料，或者咱们一起讨论下这个提示在不同人群中的效果之类的。</sample>
    <sample id="156">此研究使用了增强版的Penn Treebank数据。</sample>
    <sample id="157">两位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="158">与认知失调密切相关的任务有Debate和CE。嗯，你要是还有啥疑问可以接着问哈。</sample>
    <sample id="159">两位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="160">这篇论文有六位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="161">嗯…这个框架引入了不同来源的标注，像从世界各地的人那里得到的标注，还有和模型预测结果的比较。这和以前可能只用单一标注或者不同来源标注但没这么系统地比较过有所不同。你要是还有啥想法或者疑问，咱们可以再聊聊。</sample>
    <sample id="162">在三个比较设置中，GPT-3.5与刻板词汇的重叠最多。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="163">比较了DeepL和Google。</sample>
    <sample id="164">从预训练数据到语言模型再到下游任务：追踪导致不公平NLP模型的政治偏见轨迹。</sample>
    <sample id="165">LM训练数据，一个混合的祝福。</sample>
    <sample id="166">LM 训练数据，一个混合的祝福。</sample>
    <sample id="167">LM训练数据，一个混合的祝福。</sample>
    <sample id="168">嗯…这个图展示的是“LM训练数据”，标题下写着“混合的祝福”。图中列出了很多网站，比如patents.google.com，en.wikipedia.org等，这些网站的token数量在对数尺度上显示。图的右下角有参考文献信息。</sample>
    <sample id="169">为了这个目的，预训练数据，语言模型，下游任务。</sample>
    <sample id="170">为了这个目的，预训练数据，语言模型，下游任务，如何评估语言模型的政治倾向？预训练数据在这些政治偏见中扮演什么角色？不同政治倾向的语言模型表现如何？语言模型的政治倾向是否会导致自然语言处理应用中的公平性问题？</sample>
    <sample id="171">为了这个目的，预训练数据，语言模型，下游任务，如何评估语言模型的政治倾向？预训练数据在这些政治偏见中扮演什么角色？不同政治倾向的语言模型表现如何？语言模型的政治倾向是否会导致自然语言处理应用中的公平性问题？</sample>
    <sample id="172">嗯…这个内容是关于评估语言模型的政治倾向的。它提到支持编码器和解码器语言模型，有自动评估，基于政治科学文献。还有个图，显示了政治倾向的左右和权威程度的上下。图里有“同意”和“不同意”的选项，以及政治倾向的左翼，自由主义，右翼，专制主义的分类。如果还有啥不明白的，你可以再问我哦。</sample>
    <sample id="173">现有LMs，左，右，自由主义，专制，社会轴，经济轴，BERT-base，BERT-large，RoBERTa-base，RoBERTa-large，distilBERT，distilRoBERTa，ALBERT-base，ALBERT-large，BART-base，BART-large，Alpaca，Codex，LLaMA，GPT-2，GPT-3-ada，GPT-3-babbage，GPT-3-curie，GPT-3-davinci，ChatGPT，GPT-4，GPT-J，</sample>
    <sample id="174">进一步预训练的LM，如RoBERTa和GPT-2，检查点，评估政治倾向的变化。</sample>
    <sample id="175">预训练数据。进一步预训练语言模型，如RoBERTa，GPT-2，检查点，评估政治倾向变化。新闻媒体：左，中心，右。社交媒体，Reddit，：左，中心，右。</sample>
    <sample id="176">预训练数据。进一步预训练LM，RoBERTa，GPT-2，检查点，评估政治倾向变化。新闻媒体：左，中心，右。社交媒体，Reddit，：左，中心，右。</sample>
    <sample id="177">结果。语言模型政治倾向的党派偏移。</sample>
    <sample id="178">结果。语言模型中的党派偏移。</sample>
    <sample id="179">结果。在语言模型政治倾向中的党派偏移。</sample>
    <sample id="180">特朗普牌，从第45届到第46届的转变。</sample>
    <sample id="181">特朗普牌，从第45届到第45届之后的转变。</sample>
    <sample id="182">特朗普牌，从第45届到第45届之后的转变。</sample>
    <sample id="183">表4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的性能。结果按颜色编码，深黄色表示最好，深蓝色表示最差。</sample>
    <sample id="184">表4：针对不同身份群体的仇恨言论和来自不同来源的虚假信息的性能。结果按颜色编码，深黄色表示最好，深蓝色表示最差。</sample>
    <sample id="185">表4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的性能。结果按颜色编码，深黄色表示最好，深蓝色表示最差。</sample>
    <sample id="186">分类性能

仇恨言论

BLACK 89.93 89.98 90.19 89.85 91.55 91.28 86.81 87.82 85.63 86.22 MUSLIM 89.84 89.90 89.96 89.50 90.66 91.15 87.42 87.65 86.20 85.13 LGBTQ+ 88.81 88.68 88.91 89.74 90.62 89.97 89.64 89.63 86.35 86.35 JEWS 88.03 88.26 88.43 89.00 89.72 89.31 86.03 87.65 83.69 86.86 AS</sample>
    <sample id="187">表4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的分类表现。结果按颜色编码，深黄色表示最好，深蓝色表示最差。</sample>
    <sample id="188">表4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的性能。结果按颜色编码，深黄色表示最好，深蓝色表示最差。</sample>
    <sample id="189">表4：针对不同身份群体的仇恨言论和来自不同来源的虚假信息的性能。结果按颜色编码，深黄色表示最好，深蓝色表示最差。</sample>
    <sample id="190">定性分析，文本，目标标签，基线，N-L，S-L，N-R，S-R，亚洲人，TRUE，TRUE，TRUE，TRUE，FALSE，FALSE，TRUE，TRUE，TRUE，TRUE，FALSE，FALSE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE，TRUE</sample>
    <sample id="191">好的，你把英文内容发给我，我来帮你翻译。</sample>
    <sample id="192">很抱歉，我无法直接翻译图片中的内容。不过，如果你能提供图片中的英文文本，我可以帮你翻译。你可以把文本发给我，我会尽力帮你翻译的。</sample>
    <sample id="193">很抱歉，我无法直接翻译图片中的内容。不过，如果你能提供图片中的英文文本，我可以帮你翻译。</sample>
    <sample id="194">很抱歉，我无法直接翻译图片中的内容。不过，如果你能提供图片中的英文文本，我可以帮你翻译。</sample>
    <sample id="195">很抱歉，我无法直接翻译图片中的内容。不过，如果你能提供图片中的英文文本，我可以帮你翻译。</sample>
    <sample id="196">讨论

在“斯卡利雅”和“查理布迪斯”之间

“净化”还是“不净化”，这就是问题所在

预训练数据

语言模型

下游任务</sample>
    <sample id="197">讨论

在“斯卡利雅”和“查理布迪斯”之间

“净化”还是不“净化”，这就是问题所在

预训练数据

语言模型

下游任务</sample>
    <sample id="198">讨论

在“Scylla”和“Charybdis”之间

“是否要进行‘净化’，这是一个问题”

预训练数据

语言模型

下游任务</sample>
    <sample id="199">谢谢！预训练数据，语言模型，下游任务。</sample>
    <sample id="200">这篇论文有六位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="201">MPP评估最多涵盖900个词元的上下文长度。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="202">他们的数据集中包含音乐，书籍和食谱这三个领域。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="203">Positionality，立场，一般来说是指人们由于其人口统计特征，身份和生活经历而持有的观点。嗯，你要是还有啥想知道的，尽管问哈。</sample>
    <sample id="204">Dawei Zhu，Xiaoyu Shen，Marius Mosbach，Andreas Stephan，Dietrich Klakow。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="205">是的，EDAtt 使用了现有的离线 ST 模型，没有重新训练或采用特定架构。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="206">这篇论文有四位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="207">嗯…从这个图来看，被测模型在测试套件上运行的情况不太好。如果还有其他问题或者想深入聊聊，随时告诉我哈。</sample>
    <sample id="208">KITMUS有三个变体，分别是Background-Pretrain，Background-Both和Background-Inference。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="209">Google Research。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="210">最后一个研究问题是“如何更有效地利用可用的干净样本？”如果还有其他问题，欢迎随时问我。</sample>
    <sample id="211">嗯，这个指标灵敏度呢，就是看模型对同一任务不同指令的敏感程度。简单说，就是不管指令稍微变个说法，模型都能给出相同的结果。你要是还有啥疑问，可以再问我哈。</sample>
    <sample id="212">演讲者的名字是Wenjun Peng，Jingwei Yi，Fangzhao Wu，Shangxi Wu，Bin Zhu，Lingjuan Lyu，Binxing Jiao，Tong Xu，Guangzhong Sun和Xing Xie。</sample>
    <sample id="213">更高的灵敏度表示模型性能得到了提高。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="214">嗯…这个我也不太清楚呢。你可以再给我点关于这个模型的其他信息吗？这样我可能能更好地回答你。</sample>
    <sample id="215">嗯…从图上看，大概在50个干净的验证样本左右就能获得比较好的表现了。不过这只是一种大概的情况哈。如果还有其他问题，你可以再问我哦。</sample>
    <sample id="216">Stanford Engineering Computer Science。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="217">嗯…这个嘛，因为现有的方法不太准确，可能没法全面反映媒体偏见的情况。所以就需要开发新的方法来衡量了。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="218">演讲者的名字是Akshatha Arodi。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="219">嗯…政治偏见传播流程啊，就是先有预训练数据，然后通过语言模型，最后影响下游任务。你要是还有啥想知道的，可以再问问我。</sample>
    <sample id="220">嗯，从图上看，DEplain-apa和DEplain-web在简化过程中的某些方面是有区别的。比如说，在“rephrasing”这个简化类型上，DEplain-apa的数值比DEplain-web低一些。不过具体差异还得看更详细的分析。你要是想深入了解，咱们可以再聊聊。</sample>
    <sample id="221">嗯…这个我不太清楚呢。你可以去查查相关的资料或者问问其他专业人士。要是你还有其他问题，也可以再跟我说呀。</sample>
    <sample id="222">嗯…首先定义一个目标嵌入，然后计算句子中的触发数量，最后把目标嵌入加到原始嵌入上。如果还有疑问的话，可以再问我哦。</sample>
    <sample id="223">这篇论文的作者所属机构是PennState和Amazon。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="224">可以。</sample>
    <sample id="225">示例是做草莓蛋糕和巧克力蛋糕。嗯，你要是还有啥想知道的，尽管问哈。</sample>
    <sample id="226">嗯…这个嘛，他们没有具体说怎么确保隐蔽性呢。你要是还有别的想法或者信息，可以再和我说一说呀。</sample>
    <sample id="227">嗯…这个嘛，研究是通过“Continual pre-training using an existing pre-trained model”来实现的。就是用现有的预训练模型来进行持续预训练。你要是还有啥疑问，可以再问我哦。</sample>
    <sample id="228">拉丁美洲。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="229">演讲者在“I am a student.”这个示例句子上展示了模型如何利用注意力机制所学的知识。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="230">嗯…从图上看，随着任务数量增加，模型性能先上升后下降。大概在任务数量达到一定值时，性能达到一个峰值，然后又开始下降。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="231">LSTM seq2seq，T5，Zheng and Lapata。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="232">嗯…两位合著者是第一作者的同事吧。不过具体关系不太清楚呢。你要是还想知道更多，可以再找找资料。</sample>
    <sample id="233">PaLM的第一作者是Chowdery等人。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="234">NLPositionality：数据集和模型设计偏见的表征</sample>
    <sample id="235">NLPositionality：数据集和模型设计偏见的表征</sample>
    <sample id="236">想象……</sample>
    <sample id="237">想象一下……
Carl Jones
技术主管，纽约时报
你能停止成为一个混蛋吗？：，0.82，</sample>
    <sample id="238">想象一下……
卡尔·琼斯
技术主管，纽约时报
你能停止成为一个混蛋吗？，0.82，勾，
阿迪蒂亚·夏尔马
技术主管，印度时报
妓女无处不在新闻上。0.33，叉，</sample>
    <sample id="239">想象一下…设计偏见示例！“你能停止成为一个混蛋吗？”：0.82，绿色勾。到处都是妓女在新闻上。：0.33，红色叉。卡尔·琼斯，纽约时报技术主管。阿迪蒂亚·夏尔马，印度时报技术主管。D = PerspectiveAPI得分</sample>
    <sample id="240">“人们持有的观点是由于他们的人口统计，身份和生活经历的结果。”</sample>
    <sample id="241">“人们持有的观点，是由于他们的人口统计特征，身份和生活经历所导致的。”</sample>
    <sample id="242">定位性。“人们持有的观点，这是由于他们的人口统计，身份和生活经历的结果。”。作为研究人员，它影响研究过程及其结果和结果。</sample>
    <sample id="243">[1] Blasi等人。“世界语言技术性能的系统性不平等。”ACL 2022。

[2] Yin等人。“GEOMLAMA：多语言预训练模型的地理多样性常识探查。”EMNLP 2022。

[3] Cambo和Gergle。“模型定位性和计算反思性：促进数据科学中的反思。”CHI 2022。</sample>
    <sample id="244">[1] Blasi等人。“世界语言之间语言技术性能的系统性不平等。”ACL 2022。

[2] Yin等人。“GEOMLAMA：多语言预训练语言模型的地理多样性常识探查。”EMNLP 2022。

[3] Cambo和Gergle。“模型定位性和计算反思性：促进数据科学中的反思。”CHI 2022。</sample>
    <sample id="245">数据集和模型有立场吗？

案例证据：

- 模型和数据集探测，[1][2]

- 模型立场的理论定义，[3]

[1] Blasi, et al. "世界语言技术性能的系统性不平等。" ACL 2022。

[2] Yin et al. "GEOMLAMA：多语言预训练模型的地理多样性常识探测。" EMNLP 2022。

[3] Cambo &amp; Gergle. "模型立场和计算反思：促进数据科学中的反思。" CHI 2022。</sample>
    <sample id="246">数据集和模型有立场吗？

案例证据：
- 模型和数据集探测，[1][2]
- 模型立场的理论定义，[3]

[1] Blasi等人。“世界各地语言技术性能的系统性不平等。”ACL 2022。

[2] Yin等人。“GEOMLAMA：多元文化常识探测在多语言预训练语言模型上的应用。”EMNLP 2022。

[3] Cambo和Gergle。“模型立场和计算反思：促进数据科学中的反思。”CHI 2022。</sample>
    <sample id="247">数据集和模型有立场吗？

案例证据：
- 模型和数据集探测，[1][2]
- 模型立场的理论定义，[3]

[1] Blasi等人。《世界语言技术性能的系统性不平等》。ACL 2022。

[2] Yin等人。《GEOMLAMA：多元文化常识探测在多语言预训练语言模型上的应用》。EMNLP 2022。

[3] Cambo和Gergle。《模型立场和计算反思：促进数据科学中的反思》。CHI 2022。</sample>
    <sample id="248">数据集和模型有立场吗？

案例证据：
- 模型和数据集探测，[1][2]
- 模型立场的理论定义，[3]

[1] Blasi等人。“世界语言技术性能的系统性不平等。”ACL 2022。

[2] Yin等人。“GEOMLAMA：多元文化常识探测在多语言预训练语言模型上的应用。”EMNLP 2022。

[3] Cambo和Gergle。“模型立场和计算反思：促进数据科学中的反思。”CHI 2022。</sample>
    <sample id="249">问题：数据集和模型有位置性吗？目标：比较用户注释与现有数据集和模型的注释。</sample>
    <sample id="250">NLPositionality，一种用于表征NLP数据集和模型设计偏见的框架。</sample>
    <sample id="251">框架。收集：从数据集中抽取300个实例。每个实例都有一个关联的黄金标签。处理：实例被发送作为LITW研究的一部分。实例被发送到“Lab in the Wild”。来自世界各地的人们对“用双手吃饭”进行注释。分析：收到的注释与数据集的黄金标签和模型预测进行比较。Pearson r相关性在每个人口统计学的黄金标签，模型预测和注释之间分别进行测量。</sample>
    <sample id="252">框架。收集：从数据集中抽取300个实例。每个实例都有一个关联的黄金标签。处理：实例被发送到LITW研究中。接收的注释与数据集的黄金标签和模型预测进行比较。分析：计算每个人口统计学的皮尔逊相关系数。</sample>
    <sample id="253">框架。收集：从数据集中抽取300个实例。每个实例都有一个关联的黄金标签。处理：实例被发送到LITW的研究中。接收的注释与数据集的黄金标签和模型预测的预测进行比较。分析：计算每个人口统计学的黄金标签，模型预测和注释之间的皮尔逊相关系数。</sample>
    <sample id="254">框架。收集：从数据集中抽取300个实例。每个实例都有一个关联的黄金标签。处理：实例被发送到LITW的研究中。接收的注释与数据集的黄金标签和模型预测的预测进行比较。分析：计算每个人口统计学的皮尔逊相关系数，包括年龄，性别，种族，教育和国家。</sample>
    <sample id="255">框架。收集：从数据集中抽取300个实例。每个实例都有一个关联的黄金标签。处理：实例被发送到LITW作为一项研究的一部分。来自世界各地的人们对实例进行注释。分析：收到的注释与数据集的黄金标签和模型预测进行比较。Pearson r相关性是通过Pearson R分数分别测量每个人口统计学的黄金标签，模型预测和注释。</sample>
    <sample id="256">框架。收集：从数据集中抽取300个实例。每个实例都有一个关联的黄金标签。处理：模型预测。分析：比较来自不同人口统计学的注释与模型和数据集之间的Pearson r相关性，通过Pearson r分数测量。</sample>
    <sample id="257">你得告诉我是哪些英文内容要翻译呀，这样我才能给你翻译呢。</sample>
    <sample id="258">好的，你可以说说具体要翻译的内容吗？</sample>
    <sample id="259">任务A：社会接受度。1）阅读情境。想要赚很多钱。2）输入你对它的看法。从道德角度，你如何看待这个情况？非常不好，不好，预期/可以接受，好，非常好。可以自由解释你的判断。提交。3）看看AI和其他人对它的看法！AI推测：我推测这是可以理解的。嗯…也许我错了。美国研究参与者说：非常不好，不好，预期/可以接受，好，非常好。参与者阅读来自Social Chemistry数据集的情境。参与者对情境的社会接受度进行评分。参与者比较他们的回答与其他人的和AI的回答。</sample>
    <sample id="260">任务A：社会接受度。1）读情况。想要赚很多钱。1/15。*表示必填项。2）输入你对它的看法。从道德角度来看，你认为它怎么样？非常不好，不好，预期/可以，好，非常好。可以自由解释你的判断。提交。3）看看AI和其他人是怎么想的！AI推测：我推测它是可理解的。嗯…也许我不对。美国研究参与者说：非常不好，不好，预期/可以，好，非常好。参与者将自己的回答与他人和AI的进行比较。</sample>
    <sample id="261">任务A：社会接受度

分析

数据集
- 社会化学

模型
- 德尔菲
- GPT-4</sample>
    <sample id="262">任务B：毒性
1) 读示例：7/25
英国人闻起来像酸牛奶
2) 输入你的想法：
你认为这是仇恨言论吗？*表示必填项。
是
否
不确定
自由解释你的评分
输入简短描述
提交
3) 看看其他人是怎么想的！
AI推测：
我推测这是仇恨言论。看起来我们意见一致！
阿富汗研究参与者说：
非仇恨言论
不确定
仇恨言论
60%
20%
40%
20%
40%
60%
参与者阅读来自Dynahate数据集的实例。
参与者对实例是否为仇恨言论进行评分。</sample>
    <sample id="263">任务B：毒性分析数据集 - Dynahate模型 - Perspective API - Rewire API - Hate RoBERTa - GPT-4研究参与16，299个注释，1，096个注释者，来自87个国家。</sample>
    <sample id="264">结果：NLP数据集和模型与谁对齐？</sample>
    <sample id="265">数据集和模型最符合英语国家。</sample>
    <sample id="266">数据集和模型与拥有大学教育的人最契合。</sample>
    <sample id="267">数据集和模型对大学学历的人最契合。</sample>
    <sample id="268">发现2：一些人口被落下。</sample>
    <sample id="269">数据集和模型对非二元性别人群的契合度较低。</sample>
    <sample id="270">那么，我们能做些什么呢？在NLP中解决立场性问题。</sample>
    <sample id="271">1. 记录在构建数据集或模型过程中做出的所有相关设计选择。2. 通过视角主义的视角进行NLP研究：a. 共享分层的数据集标签！b. 使用能够处理标注者分歧的建模技术。</sample>
    <sample id="272">1. 记录在构建数据集或模型过程中做出的所有相关设计选择。
2. 通过视角主义的视角进行NLP研究：
   a. 共享分层的数据集标签！
   b. 使用能够处理标注者分歧的建模技术。
3. 为特定社区构建专门的数据集和模型，这对包容性NLP是有价值的，例如Masakhane倡议。</sample>
    <sample id="273">谢谢！
仪表板链接：nlpositionality.cs.washington.edu/
论文：bit.ly/NLPositionality-Paper/
Delphi
https://delechi.allenai.org/</sample>
    <sample id="274">演讲者提到了 SimulST 的三个问题。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="275">嗯…这个嘛，没有直接说有效方法呢。不过从这个图来看，可能涉及到数据预处理，也就是“sanitize”数据。但具体怎么做，图里没详细说。你要是想深入了解，咱们可以再聊聊。</sample>
    <sample id="276">第61届计算语言学协会年会，加拿大多伦多，2023年7月9-14日。从大型语言模型中提取脚本知识以进行约束语言规划。作者：袁思雨，陈江杰，付子泉，葛旭阳，沙索姆，查尔斯·罗伯特·詹科夫斯基，肖阳华，杨德清。复旦大学，Brain Technologies Inc.</sample>
    <sample id="277">语言规划。如何做蛋糕？1. 收集你的食材。2. 预热烤箱至325华氏度，163摄氏度，然后涂抹并撒上面粉在蛋糕盘上。3. 搅打黄油和糖。4. 加入鸡蛋。5. 搅拌蛋糕粉。6. 将面糊倒入盘中。7. 烘烤蛋糕1小时15分钟。大型语言模型，LLMs，可以有效地将目标分解成步骤。</sample>
    <sample id="278">语言规划。如何做蛋糕？1. 收集你的食材。2. 预热烤箱至325华氏度，163摄氏度，并涂抹和撒上面粉在蛋糕盘上。3. 打发黄油和糖。4. 加入鸡蛋。5. 搅拌蛋糕粉。6. 将面糊倒入盘中。7. 烘烤蛋糕1小时15分钟。大型语言模型，LLMs，可以有效地将目标分解成步骤。</sample>
    <sample id="279">受限语言规划。如何制作草莓蛋糕？…在面粉里加入草莓酱…如何制作巧克力蛋糕？…在面粉里加入可可粉…抽象目标可以被不同的现实具体目标继承，带有多方面的约束。</sample>
    <sample id="280">受限语言规划。如何制作草莓蛋糕？…在面粉里加入草莓酱…如何制作巧克力蛋糕？…在面粉里加入可可粉…抽象目标可以被不同的现实具体目标继承，带有多方面的约束。</sample>
    <sample id="281">受限语言规划。如何制作草莓蛋糕？…在面粉里加草莓酱…如何制作巧克力蛋糕？…在面粉里加可可粉…抽象目标可以被不同的现实具体目标继承，带有多方面的约束。</sample>
    <sample id="282">LLMs在约束语言规划方面表现如何？数据集：wikiHow + 生成的约束。约束类型1：修饰词。定义：修饰或约束抽象目标的词，形容词或短语。示例1：做一个巧克力蛋糕。示例2：做一个粉红色的蛋糕。约束类型2：方法。定义：实现目标过程中的工具或特定模式。示例1：用烤箱做蛋糕。示例2：用蛋糕粉做蛋糕。约束类型3：意图。定义：完成目标时的附加目的或需求。示例1：为婚礼做蛋糕。示例2：为糖尿病患者做蛋糕。</sample>
    <sample id="283">LLMs在约束语言规划方面表现如何？数据集：wikiHow + 生成的约束条件。约束类型1：修饰语。定义：修饰或约束抽象目标的词，形容词或短语。示例1：做一个巧克力蛋糕。示例2：做一个粉红色的蛋糕。约束类型2：方法。定义：控制实现目标过程的工具或特定模式。示例1：用烤箱做蛋糕。示例2：用蛋糕粉做蛋糕。约束类型3：意图。定义：完成目标时的附加目的或需求。示例1：为婚礼做蛋糕。示例2：为糖尿病患者做蛋糕。</sample>
    <sample id="284">LLMs在受约束的语言规划中表现如何？数据集：wikiHow + 生成的约束条件。约束类型1：修饰语。定义：修饰或约束抽象目标的词，形容词或短语。示例1：做一个巧克力蛋糕。示例2：做一个粉色蛋糕。约束类型2：方法。定义：实现目标的工具或特定模式。示例1：用烤箱做蛋糕。示例2：用蛋糕粉做蛋糕。约束类型3：意图。定义：完成目标时的附加目的或需求。示例1：为婚礼做蛋糕。示例2：为糖尿病患者做蛋糕。</sample>
    <sample id="285">LLMs能做约束语言规划吗？所有基线在为特定目标规划时都取得了不令人满意的结果。</sample>
    <sample id="286">LLMs能做约束语言规划吗？所有基线在为特定目标规划上都取得不满意的结果。</sample>
    <sample id="287">LLMs在执行任务时通常会犯哪些错误？在生成的脚本中，语义完整性是可接受的，但对约束的忠实性，FE，不能保证。</sample>
    <sample id="288">LLMs在执行此任务时通常会犯哪些错误？在生成的脚本中，语义完整性（SE）是可以接受的，但对约束的忠实性（FE）无法保证。</sample>
    <sample id="289">InstructGPT通常会失败的目标类型是什么？</sample>
    <sample id="290">方法输入：一个抽象目标步骤1通过上下文学习使用InstructGPT生成具体目标抽象目标：做蛋糕约束G1，+修饰词，：做巧克力蛋糕G2，+方法，：用微波炉做蛋糕G3，+意图，：为婚礼做蛋糕</sample>
    <sample id="291">方法输入：一个抽象目标步骤1通过上下文学习使用InstructGPT生成具体目标步骤2通过上下文学习使用InstructGPT过度生成候选脚本抽象目标：做蛋糕约束G1，+修饰词，：做巧克力蛋糕G2，+方法，：用微波炉做蛋糕G3，+意图，：为婚礼做蛋糕</sample>
    <sample id="292">方法。输入：一个抽象目标。步骤1：通过上下文学习用InstructGPT生成具体目标。步骤2：通过上下文学习用InstructGPT生成候选脚本。抽象目标：做蛋糕。具体目标：G1，+修饰语，做巧克力蛋糕，G2，+方法，用微波炉做蛋糕，G3，+意图，为婚礼做蛋糕。生成G1的计划。候选脚本：1，2，3，...，k。</sample>
    <sample id="293">方法。步骤2：通过上下文学习用InstructGPT生成候选脚本。步骤3：通过相似度分数用InstructGPT找到与目标相关的过滤脚本。输出：具有对应脚本的具体目标。</sample>
    <sample id="294">方法。步骤2：通过上下文学习用InstructGPT生成候选脚本。步骤3：通过相似度分数用InstructGPT找到符合目标的过滤脚本。输出：具有对应脚本的具体目标。</sample>
    <sample id="295">方法。步骤2：通过上下文学习用InstructGPT生成候选脚本。步骤3：通过相似度分数用InstructGPT找到符合目标的过滤脚本。输出：具有对应脚本的具体目标。</sample>
    <sample id="296">我们的方法极大地提高了规划质量。使用我们的方法，InstructGPT可以生成更高质量的脚本，差距很大。</sample>
    <sample id="297">从LLMs中提取脚本的动机：为了使较小模型具备约束语言规划能力。方法：遵循符号知识蒸馏的理念，基于我们的方法从LLMs生成了55，000个带约束的脚本，形成Coscript数据集，人类标注验证和测试集。</sample>
    <sample id="298">从LLMs中提取脚本的动机：为了使较小模型具备约束语言规划能力。方法：遵循符号知识蒸馏的理念，基于我们的方法从LLMs生成了55，000个带约束的脚本，形成Coscript数据集，人类标注验证和测试集。</sample>
    <sample id="299">从LLMs中提取脚本的动机：为了使较小模型具备约束语言规划能力。方法：遵循符号知识蒸馏的理念，基于我们的方法从LLMs生成了55，000个带约束的脚本，形成Coscript数据集，人类标注验证和测试集。</sample>
    <sample id="300">从LLMs中提取脚本的动机：为了使较小模型具备约束语言规划能力。方法：遵循符号知识蒸馏的理念，基于我们的方法从LLMs生成了55，000个带约束的脚本，形成Coscript数据集，人类标注验证和测试集。</sample>
    <sample id="301">从LLMs中提取脚本的动机：为了使较小模型具备约束语言规划能力。方法：遵循符号知识蒸馏的理念，基于我们的方法从LLMs生成了55，000个带约束的脚本，形成Coscript数据集，人类标注验证和测试集。</sample>
    <sample id="302">约束分析。Coscript在生成的具体目标中表现出高度的异质性和多样性。Coscript for Smaller Language Models。- 数据集：Coscript，wikiHow。- 评估指标：忠实度：DeBERTa，v3大型模型，用于判断生成文本是否忠实于约束条件。- 自动评估指标：ROUGE，BLEU，BERTScore。Coscript for Smaller Language Models。- 数据集：Coscript，wikiHow。- 评估指标：忠实度：DeBERTa，v3大型模型，用于判断生成文本是否忠实于约束条件。- 自动评估指标：ROUGE，BLEU，BERTScore。</sample>
    <sample id="303">嗯，这个图里有几种模型的比较。GPT-3，Codex和InstructGPT都是175B参数量的，T5在wikiHow上训练，T5在Coscript上训练。图中显示，T5在Coscript上微调的模型在准确性上比其他模型高。还有个观点是，微调在Coscript上的小规模LLMs能生成比LLMs更好的质量脚本。</sample>
    <sample id="304">总结和要点
- 建立约束语言规划问题。
- 评估LLMs的约束语言规划能力，并为LLMs开发一种“先生成后筛选”的方法。
- 使用LLMs生成高质量的脚本数据集，CoScript，用于约束语言规划。
- 限制和未来工作
  - 提出的改进LLMs的方法是一种“事后重新排序”方法。
  - CoScript仅从一个抽象的脚本继承，且有一个额外的约束。
  - CoScript数据集可以成为推进语言规划研究的宝贵资源，涉及更复杂和多样的目标和约束。</sample>
    <sample id="305">总结和要点
- 建立约束语言规划问题。
- 评估LLMs的约束语言规划能力，并为LLMs开发一种“先生成后筛选”的方法。
- 使用LLMs生成高质量的脚本数据集（CoScript），用于约束语言规划。
- 限制和未来工作
  - 提出的改进LLMs的方法是一种“事后重新排序”方法。
  - CoScript仅从一个抽象的脚本继承，增加了一个额外的约束。
  - CoScript数据集可以成为推进语言规划研究的宝贵资源，涉及更复杂和多样的目标和约束。</sample>
    <sample id="306">第61届计算语言学协会年会，加拿大多伦多，2023年7月9-14日。从大型语言模型中提取脚本知识以进行约束语言规划。演讲者：Siyu Yuan，Jiangjie Chen，Ziquan Fu，Xuyang Ge，Soham Shah，Charles Robert Jankowski，Yanghua Xiao，Deqing Yang。邮箱：syyuan21@m.fudan.edu.cn。Coscript网站：https://github.com/siyuyuan/coscript。</sample>
    <sample id="307">PaLM的流畅度和SOTA相当。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="308">重要属性有适用性，对嵌入式数据的实用性，隐秘性，以及可转移性。</sample>
    <sample id="309">TED 英语演讲已被翻译成 14 种语言，分别是英语，德语，西班牙语，法语，意大利语，日语，韩语，荷兰语，葡萄牙语，罗马尼亚语，俄语，土耳其语和中文。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="310">从一个数据集中抽取300个实例用于重新注释。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="311">cosine距离和l2距离。</sample>
    <sample id="312">嗯…这个嘛，你可以把基于编码器的多语言模型用于这项任务，就像XLM-R + PTR，mBERT + PTR这样的方式。如果还有啥疑问，随时跟我说哈。</sample>
    <sample id="344">作者是通过在一般文本语料库上计算单词频率，然后随机选择n个在中等频率区间内的单词来确定中等频率的单词的。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="345">CoNLL-2003命名实体识别器在2023年还能用吗？</sample>
    <sample id="346">命名实体识别与泛化</sample>
    <sample id="347">命名实体识别与泛化。模型已经使用CoNLL-2003开发NER近20年。</sample>
    <sample id="348">命名实体识别与泛化。- 模型几乎20年来一直在使用CoNLL-2003来开发NER。- 这些模型能泛化到现代数据吗？- 良好的泛化需要什么？</sample>
    <sample id="349">命名实体识别与泛化

- 模型几乎20年来一直在使用CoNLL-2003来开发NER
- 这些模型能泛化到现代数据吗？
- 什么是好的泛化所需要的？
- 什么导致性能下降？</sample>
    <sample id="350">CoNLL++数据集
- 从2020年收集Reuters新闻并按照CoNLL-2003注释指南进行注释</sample>
    <sample id="351">CoNLL++数据集
- 从2020年收集路透社新闻并按照CoNLL-2003注释指南进行注释
- 在CoNLL-2003上微调20多个模型
- 在CoNLL-2003测试集和CoNLL++上进行评估</sample>
    <sample id="352">CoNLL++数据集
- 从2020年收集Reuters新闻并使用CoNLL-2003注释指南进行注释
- 在CoNLL-2003上微调20多个模型
- 在CoNLL-2003测试集和CoNLL++上进行评估
- 计算百分比ΔF1来评估泛化能力</sample>
    <sample id="353">需要什么才能实现良好的泛化？</sample>
    <sample id="354">好的泛化需要什么？- 模型架构- 转换器模型泛化能力更强</sample>
    <sample id="355">需要什么才能实现良好的泛化？- 模型架构- 变换器模型泛化能力更强- 模型大小- 较大的模型泛化能力更强</sample>
    <sample id="356">需要什么才能实现良好的泛化？模型架构：Transformer模型泛化能力更强。模型大小：较大的模型泛化能力更强。微调示例数量：更多的示例导致更好的泛化。</sample>
    <sample id="357">什么导致性能下降？</sample>
    <sample id="358">什么导致性能下降？自适应过拟合？</sample>
    <sample id="359">- 适应性过拟合？
- 时间漂移？</sample>
    <sample id="360">什么导致性能下降？- 适应性过拟合？- 时间漂移？</sample>
    <sample id="361">- 适应性过拟合？
- 时间漂移？</sample>
    <sample id="362">- 适应性过拟合？
  - 没有边际收益递减
  - 未观察到
- 时间漂移？</sample>
    <sample id="363">什么导致性能下降？- 自适应过拟合？- 没有边际收益递减- 未观察到- 时间漂移？</sample>
    <sample id="364">性能下降的原因是什么？- 自适应过拟合？- 没有边际收益
- 未观察到
- 时间漂移？
- 性能随着时间间隔增大而下降</sample>
    <sample id="365">- 适应性过拟合？
  - 没有边际收益
  - 未观察到
- 时间漂移？
  - 随着时间间隔增大，性能下降
  - 性能下降的主要原因</sample>
    <sample id="366">结论
- 要实现良好的泛化，我们需要：
  - 更好的模型架构
  - 更大的模型规模
  - 更多的微调示例</sample>
    <sample id="367">结论
- 为了实现良好的泛化，我们需要：
  - 更好的模型架构
  - 更大的模型规模
  - 更多的微调示例
- 性能下降的原因是：
  - 时间漂移
  - 不是自适应过拟合</sample>
    <sample id="368">结论
- 要实现良好的泛化，我们需要：
  - 更好的模型架构
  - 更大的模型规模
  - 更多的微调示例
- 性能下降的原因是：
  - 时间漂移
  - 不是自适应过拟合
- CoNLL-2003 标记器还能工作吗？</sample>
    <sample id="369">结论
- 要实现良好的泛化，我们需要：
  - 更好的模型架构
  - 更大的模型规模
  - 更多的微调示例
- 性能下降的原因是：
  - 时间漂移
  - 不是自适应过拟合
- CoNLL-2003 标签器还能用吗？
  - 是的！</sample>
    <sample id="370">论文：https://arxiv.org/abs/2212.09747，数据集：https://github.com/ShuhengL/acl2023_conllpp，联系：sliu775@gatech.edu。</sample>
    <sample id="397">抱歉，图片内容里没有提到语音片段大小的信息。你可以再给我点其他线索吗？</sample>
    <sample id="398">在 Servin 和 Kea 的示例中，需要“Servin 是法官”和“Kea 是面包师”这两种特定于实体的知识。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="399">示例质量比相似度更重要。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="400">论文侧重于RoBERTa和GPT-2这两个语言模型。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="401">嗯…这个模型是结合多个层的分数的。如果还有其他问题，你可以再问我哦。</sample>
    <sample id="402">“easy on me”，“the first one”。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="403">复旦大学和Brain Technologies Inc.。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="404">这篇论文有7位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="405">是的，在语义解析之前，使用机器翻译模型，比如Google翻译API，把自然语言查询翻译成目标语言。然后用单语模型进行训练和评估。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="406">作者给出的“显性群体”的示例是“a woman warrior”。</sample>
    <sample id="407">嗯…从这张图来看，像BiLSTM-CNN，BiLSTM-CRF这些模型架构泛化能力可能比较差。不过这只是个大概情况哈。你要是想了解更多，可以再和我说说。</sample>
    <sample id="408">你没说清楚是哪个英文内容啊，我没法回答这个问题。你可以再详细说说吗？</sample>
    <sample id="409">这篇论文有六位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="410">作者采用了多种模态。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="439">嗯…这个嘛，作者没具体说哪些是NLU中研究不足的领域呢。你还有其他关于这个的疑问吗。</sample>
    <sample id="440">演讲者的名字是Zhiyang Xu，Ying Shen和Lifu Huang。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="441">是的，人类标注了验证集和测试集。</sample>
    <sample id="442">嗯…现有的资源局限性在于，只有少量的词依赖上下文，而且现有的方法只支持有限的语篇现象和语言。如果还有其他问题，欢迎随时问我哦。</sample>
    <sample id="443">解决间接指代表达式以选择实体，AltEntities语料库，Mohammad Javad Hosseini，Filip Radlinski，Silvia Pareti，Annie Louis，谷歌研究，</sample>
    <sample id="444">解决间接指代表达式以选择实体，AltEntities语料库，Mohammad Javad Hosseini，Filip Radlinski，Silvia Pareti，Annie Louis，谷歌研究，</sample>
    <sample id="445">间接指代表达式。目标：理解用户在做选择时的语言。替代问题：你是指《Easy on Me》还是《I Gotta Feeling》？直接指代：《Easy on Me》，《The First One》。间接指代可以在自然流畅的对话中使用：记不住名字，发音难区分，想明确偏好。间接指代：更新的那个。不是那种充满活力的歌。</sample>
    <sample id="446">间接指代表达式。目标：理解用户在做选择时的语言。替代问题：Did you mean easy on me or I gotta feeling？直接指代："easy on me"，"the first one"。间接指代可以在自然流畅的对话中使用：不能记住名字，发音难以区分，想要明确偏好。间接指代：The newer one. The song that's not energetic.</sample>
    <sample id="447">间接指代表达式。目标：理解用户在做选择时的语言。替代问题：你是指《Easy on Me》还是《I Gotta Feeling》？直接指代：“Easy on Me”，“第一个”。间接指代可以在自然流畅的对话中使用：记不住名字，发音难区分，想明确偏好。间接指代：更新的那个。不是那种充满活力的歌。</sample>
    <sample id="448">间接指代表达式。目标：理解用户在做选择时的语言。替代问题：你是指《Easy on Me》还是《I Gotta Feeling》？直接指代：《Easy on Me》，《the first one》。间接指代可以在自然流畅的对话中使用：记不住名字，发音难区分，想明确偏好。间接指代：更新的那个。不是那种充满活力的歌。</sample>
    <sample id="449">间接指代表达式。目标：理解用户在做选择时的语言。替代问题：你是指《Easy on Me》还是《I Gotta Feeling》？直接指代：“Easy on Me”，“第一个”。间接指代可以在自然流畅的对话中使用：记不住名字，发音难区分，想明确偏好。间接指代：更新的那个。不是那种充满活力的歌。</sample>
    <sample id="450">数据集收集。重要问题：对话系统，大型语言模型实体理解基准测试。没有大规模公开数据集。我们使用众包收集大量数据。三个领域：</sample>
    <sample id="451">数据集收集。重要问题：对话系统，大型语言模型实体理解基准测试。没有大规模公开数据集可用。我们使用众包收集大量数据。三个领域：</sample>
    <sample id="452">数据集收集方法论。方法论强调非正式性，使用卡通填充任务。设置对话背景，从每个领域选择几个手动提示。替代问题。表达指代其中一个实体。由注释者填写。</sample>
    <sample id="453">数据集收集方法论。方法论强调非正式性，使用卡通填充任务。设置对话背景，从每个领域选择几个手动提示。替代问题。表达其中一个实体。由注释者填写。</sample>
    <sample id="454">数据集收集方法论。方法论强调非正式性，使用卡通填充任务。设置对话背景，从每个领域几个手动提示中选择。替代问题。表达指代其中一个实体。由注释者填写。</sample>
    <sample id="455">数据集收集方法论。方法论强调非正式性，使用卡通填充任务。设置对话背景，[从每个领域选择几个手动提示]。替代问题。表达其中一个实体。由注释者填写。</sample>
    <sample id="456">数据集收集方法论。方法论强调非正式性，使用卡通填充任务。设置对话背景，从每个领域选择几个手动提示。替代问题。表达其中一个实体。由注释者填写。</sample>
    <sample id="457">数据集收集方法论。方法论强调非正式性，使用卡通填充任务。设置对话背景，从几个手动提示中选择每个领域。替代问题。表达指代其中一个实体。填充由注释员完成。</sample>
    <sample id="458">生成替代问题 =&gt; 抽样实体对

你是指A还是B？

更相似，更难，通常

- Wikipedia上具有相似信息框的项目，相同类型和/或艺术家
  你是指“这是它”还是“镜子中的男人”？

- Wikipedia上有相似描述的项目
  你是指“你想着你”还是“无处不在”？

- 具有相似标题的项目：
  你是指《回忆》（回忆录）还是《回忆》（夏特纳小说）？

- 随机统一：
  你是指“你可能是我的”还是“我是谁”？</sample>
    <sample id="459">生成替代问题 =&gt; 抽样实体对

你是指A还是B？

- 具有相似Wikipedia信息框的项目，相同类型和/或艺术家
  你是指“这是它”还是“镜子中的男人”？

- 具有相似Wikipedia描述的项目
  你是指“你想着你”还是“无处不在”？

- 具有相似标题的项目：
  你是指《回忆》（回忆录）还是《回忆》（夏特纳小说）？

- 随机均匀：
  你是指“你可能是我的”还是“我是谁”？</sample>
    <sample id="460">生成替代问题 =&gt; 抽样实体对

你是指A还是B？

- 具有相似Wikipedia信息框的项目，相同类型和/或艺术家
  你是指《This Is It》还是《Man in the Mirror》？

- 具有相似描述的Wikipedia项目
  你是指《Thinking of You》还是《Happy Anywhere》？

- 具有相似标题的项目：
  你是指《The Return》（回忆录）还是《The Return》（Shatner小说）？

- 随机均匀：
  你是指《You Could Be Mine》还是《The Way I Am》？</sample>
    <sample id="461">生成替代问题 =&gt; 抽样实体对

你是指A还是B？

- 具有相似Wikipedia信息框的项目，相同类别和/或艺术家
  你是指《This Is It》还是《Man in the Mirror》？

- 具有相似Wikipedia描述的项目
  你是指《Thinking of You》还是《Happy Anywhere》？

- 具有相似标题的项目：
  你是指《The Return》（回忆录）还是《The Return》（Shatner小说）？

- 随机均匀：
  你是指《You Could Be Mine》还是《The Way I Am》？</sample>
    <sample id="462">生成替代问题 =&gt; 抽样实体对

你是指A还是B？

- 具有相似Wikipedia信息框的项目，相同类型和/或艺术家
  你是指“这是它”还是“镜子中的男人”？

- 具有相似Wikipedia描述的项目
  你是指“你是否在想你”还是“在任何地方快乐”？

- 具有相似标题的项目：
  你是指《回忆录》还是《夏特纳小说》的《回归》？

- 随机均匀：
  你是指“你可能是我的”还是“我是谁”？</sample>
    <sample id="463">背景知识（音乐）- 每首歌都有Google搜索链接。Easy on Me，Adele演唱，点击这里了解这首歌。I Gotta Feeling，The Black Eyed Peas演唱，点击这里了解这首歌。我们要求注释者- 至少听一些每首歌。- 阅读每首歌的相关信息。</sample>
    <sample id="464">背景知识（音乐）- 每首歌都有Google搜索链接。- 我们要求注释者至少听一些每首歌，阅读每首歌的相关信息。</sample>
    <sample id="465">背景知识（音乐）- 每首歌都有Google搜索链接。Easy on Me，Adele演唱，点击这里了解这首歌。I Gotta Feeling，The Black Eyed Peas演唱，点击这里了解这首歌。我们要求注释者至少听一些每首歌，阅读每首歌的相关信息。</sample>
    <sample id="466">背景知识（食谱）Simnel蛋糕是一种果蛋糕，在英国，爱尔兰和其他有移民模式的国家广泛食用，与大斋节和复活节有关。它以杏仁膏或杏仁蛋白糖浆的分层和相同膏体的11个球状物为特色。Pandan蛋糕是一种轻盈，蓬松，绿色的海绵蛋糕，以 Pandanus amaryllifolius 叶子的汁液调味。这种蛋糕在印度尼西亚，马来西亚和荷兰都很受欢迎，特别是在印度尼西亚人社区。</sample>
    <sample id="467">我们告诉注释者应该选择哪个选项，并让他们描述它。选这个。Easy on Me，Adele演唱的，I Gotta Feeling，Black Eyed Peas演唱的。我们希望你能为所选歌曲提供3到5个表达，填入你的对话气泡。例如：带有钢琴音乐的那个，不那么有活力的歌，和河流有关的，较新的那个，关于没有时间选择的。</sample>
    <sample id="468">好的，你可以说出具体的英文内容，我会帮你翻译成中文。</sample>
    <sample id="469">AltEntities语料库
- 三个领域中约6000个替代问题
- 约42000个间接指代表达
- T5 XL模型结果（准确率）：
  - 如果LM有与标注者相同的背景知识，准确率为92%-95%
  - 如果LM有部分重叠的背景知识，准确率为82%-87%
  - 如果LM仅能访问实体名称，准确率为约60%
  - 我们展示了模型的领域通用性。
- 数据集链接：https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="470">AltEntities语料库
- 三个领域中约6000个替代问题
- 约42000个间接指代表达
- T5 XL模型结果（准确率）：
  - 如果LM有与注释者相同的背景知识，准确率为92%-95%
  - 如果LM有部分重叠的背景知识，准确率为82%-87%
  - 如果LM仅访问实体名称，准确率为约60%
  - 我们展示了模型具有跨域泛化能力。
- 数据集链接：https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="471">AltEntities语料库
- 三个领域中约6000个替代问题
- 约42000个间接指代表达
- T5 XL模型结果（准确率）：
  - 如果LM有与标注者相同的背景知识，准确率为92%-95%
  - 如果LM有部分重叠的背景知识，准确率为82%-87%
  - 如果LM仅能访问实体名称，准确率为约60%
  - 我们展示了模型的领域通用性。
- 数据集链接：https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="472">AltEntities语料库
- 三个领域中约6000个替代问题
- 约42000个间接指代表达
- T5 XL模型结果（准确率）：
  - 如果LM有与注释者相同的背景知识，准确率为92%-95%
  - 如果LM有部分重叠的背景知识，准确率为82%-87%
  - 如果LM仅访问实体名称，准确率为约60%
  - 我们展示了模型是跨域通用的。
- 数据集链接：https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="473">该方法与wait-k，LA，CAAT进行了比较。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="474">LIA，Avignon Université，LS2N，Nantes Université，Clinique des données，CHU de Nantes，Zenidoc。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="475">演讲者的名字是Sebastin Santy，Jenny T. Liang，Ronan Le Bras，Katharina Reinecke和Maarten Sap。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="476">三位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="477">注意力作为同声传译的指南，作者：萨拉·帕皮，马特奥·内格里，马可·图尔奇。</sample>
    <sample id="478">Simultaneous speech translation，SimulST，是将口语实时翻译成另一种语言的过程，使跨语言交流成为可能。</sample>
    <sample id="479">特定架构通常被训练，引入额外模块进行优化。</sample>
    <sample id="480">当前的SimulST模型存在以下问题：特定架构通常被训练，引入额外模块进行优化。长期且复杂的训练过程，例如不同的优化目标。</sample>
    <sample id="481">当前SimulST模型的问题是什么？特定架构通常被训练，引入额外模块进行优化。长期而复杂的训练过程，例如不同的优化目标。训练和维护多个模型以达到不同的延迟制度，例如1s，2s，...</sample>
    <sample id="482">我们的解决方案是什么？</sample>
    <sample id="483">1. 使用现有的离线ST模型，无需重新训练或采用特定架构用于SimulST。2. 每个延迟制度使用一个模型，并通过特定参数处理延迟。</sample>
    <sample id="484">1. 使用现有的离线ST模型，无需重新训练或采用特定架构用于SimulST。2. 对于每种延迟制度，使用同一个模型，并通过特定参数处理延迟。3. 利用模型在音频输入和文本输出之间通过注意力机制已获得的知识。</sample>
    <sample id="485">根据注意力指向的位置决定是否发出部分翻译：如果注意力没有集中在最后λ个语音帧上，即其总和低于阈值α，那么发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="486">根据注意力指向的位置决定是否发出或部分翻译：如果注意力没有集中在最后λ个语音帧上，其总和低于阈值α，那么就发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="487">根据注意力指向的位置决定是否发出部分翻译：如果注意力没有集中在最后λ个语音帧上，其总和低于阈值α，那么就发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="488">根据注意力指向的位置决定是否发出或部分翻译：如果注意力没有集中在最后λ个语音帧上，其总和低于阈值α，那么就发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="489">根据注意力指向的位置决定是否发出或部分翻译：如果注意力没有集中在最后λ个语音帧上，即其总和低于阈值α，那么就会发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="490">根据注意力点的位置决定是否发出部分翻译：如果注意力没有集中在最后λ个语音帧上，即其总和低于阈值α，那么发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="491">根据注意力点的位置决定是否发出或部分翻译：如果注意力没有集中在最后λ个语音帧上，即其总和低于阈值α，那么将发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="492">根据注意力点的位置决定是否发射或部分翻译：如果注意力没有集中在最后λ个语音帧上，即其总和低于阈值α，那么认为接收的信息足够稳定，就会发射一个词。</sample>
    <sample id="493">根据注意力点的位置决定是否发出或部分翻译。如果注意力不集中（其总和低于阈值α）指向最后λ个语音帧，意味着接收到的信息足够稳定，那么就会发出一个词。</sample>
    <sample id="494">根据注意力点的位置决定是否发出部分翻译：如果注意力没有集中在最后λ个语音帧上，即其总和低于阈值α，那么认为接收到的信息足够稳定，就会发出一个词。</sample>
    <sample id="495">主要结果：EDAtt。</sample>
    <sample id="496">主要结果：EDAtt。</sample>
    <sample id="497">主要结果：EDAtt
主轴：延迟测量
(a) en→de
AL / AL-CA，s，</sample>
    <sample id="498">主要结果：EDAtt。</sample>
    <sample id="499">主要结果：EDAtt。</sample>
    <sample id="500">主要结果：EDAtt。流行策略也应用于离线模型。AL / AL_CA，s， BLEU，0.5 1 1.5 2 2.5 3 3.5 4 4.5 5，a，en→de，，AL / AL_CA，s，，0.5 1 1.5 2 2.5 3 3.5 4 4.5 5，a，en→de，</sample>
    <sample id="501">主要结果：EDAtt
图中显示了四种不同算法在不同时间间隔下的BLEU得分。从左到右，算法依次为：wait-k，LA，CAAT和EDAtt。横轴表示时间间隔，单位为秒，纵轴表示BLEU得分。图例说明了每种算法的对应颜色和标记。</sample>
    <sample id="502">EDAtt在所有应用于离线模型的策略中表现最佳。</sample>
    <sample id="503">主结果：EDAtt。EDAtt在考虑实际耗时的情况下是最快的策略。</sample>
    <sample id="504">你想了解更多吗？阅读我们的论文以发现更多结果！。</sample>
    <sample id="505">是的，数据集是公开的。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="506">MULTIINSTRUCT：通过指令调优提高多模态零样本学习。徐志阳，申莹，黄立夫。计算机科学系，弗吉尼亚理工大学。</sample>
    <sample id="507">预训练语言模型用于下游任务

(A) 预训练-微调（BERT，T5）

- 预训练模型
- 在任务A上微调
- 在任务A上推理

(B) 提示（GPT-3）

- 提高性能
- 通过少量提示或提示工程
- 在任务A上推理

(C) 指令微调（FLAN）

- 预训练模型
- 在多个任务B，C，D等上指令微调
- 模型通过自然语言指令学习执行多个任务
- 在未见任务上推理

图2：比较指令微调与预训练-微调和提示。

图片归功于：Wei，Jason等。“微调语言模型是零样本学习者。”</sample>
    <sample id="508">图2：比较指令调优与预训练-微调和提示。</sample>
    <sample id="509">“Language-only”仅指语言。</sample>
    <sample id="510">指令微调在多模态预训练模型上。</sample>
    <sample id="511">指令数据集在NLP和多模态之间的不平衡。</sample>
    <sample id="512">指令数据集在NLP和多模态之间的不平衡，1600多个仅语言指令任务，没有大规模的公开可用的多模态指令任务。</sample>
    <sample id="513">- 62个多样化的多模态任务
- 10个广泛的任务组
- 5个专家撰写的指令</sample>
    <sample id="514">- 62个多样化的多模态任务
- 10个广泛的组别
- 5个专家撰写的指令</sample>
    <sample id="515">OFA，一个统一的多模态预训练模型，能够处理单个或多个模态的解释和生成任务。OFA具有统一的词汇表，适用于语言，图像标记和边界框的坐标。</sample>
    <sample id="516">图1：来自MULTIINSTRUCT的四个任务的示例实例。</sample>
    <sample id="517">图1：来自MULTIINSTRUCT的四个任务的示例实例。</sample>
    <sample id="518">图1：来自MULTIINSTRUCT的四个任务的示例实例。</sample>
    <sample id="519">多模态指令调优。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="520">多模态指令转向

- 训练数据集构建：
  - 使用9个组中的53个任务进行训练。
  - 每个任务采样10，000个实例。
- 测试数据集构建：
  - 保留整个常识推理组用于测试。
  - 从VQA和杂项组中选择额外的5个任务。
  - 我们使用每个任务测试分割中的所有实例。
  - 随机从Natural Instructions数据集的测试分割中采样20个任务作为NLP的未见任务。</sample>
    <sample id="521">多模态指令转换

- 训练数据集构建：
  - 使用9个组中的53个任务进行训练。
  - 每个任务采样10，000个实例。
- 测试数据集构建：
  - 保留整个常识推理组用于测试。
  - 从VQA和杂项组中选择额外的5个任务。
  - 我们使用每个任务测试分割中的所有实例。
  - 随机从Natural Instructions数据集的测试分割中采样20个任务作为NLP的未见任务。</sample>
    <sample id="522">实施细节

- 训练细节：
  - 预训练的OFA-Large模型（472M）
  - 将所有任务的实例混合。
  - 每个实例随机与五个指令模板之一结合。

- 测试细节：
  - 对每个任务，我们进行总共五次实验，每次实验使用五个指令之一评估模型。
  - 我们报告所有五次实验的性能的平均值，最大值和标准差。</sample>
    <sample id="523">实施细节

- 训练细节：
  - 使用预训练的OFA-Large模型（472M）
  - 将所有任务的实例混合
  - 每个实例随机与五个指令模板之一结合

- 测试细节：
  - 对每个任务，我们进行总共五次实验，每次实验使用五个指令之一评估模型
  - 我们报告所有五次实验的性能均值，最大值和标准差</sample>
    <sample id="524">实施细节

- 训练细节：
  - 使用预训练的OFA-Large模型（472M）
  - 将所有任务的实例混合
  - 每个实例随机与五个指令模板之一结合

- 测试细节：
  - 对每个任务，我们进行总共五次实验，每次实验使用五个指令之一评估模型
  - 我们报告所有五次实验的性能的平均值，最大值和标准差</sample>
    <sample id="525">- 对于多模态分类任务（视觉蕴含，视觉空间推理，自然语言视觉推理和灾害类型分类）我们报告准确率。
- 对于多模态生成任务（常识性VQA，文本VQA，基于视觉的VQA，视觉文本提取和视觉对话）我们报告Rouge-L。
- 对于NLP任务，我们报告Rouge-L。
- 我们还根据模型在所有未见过的多模态和NLP任务上的平均表现计算每个模型的综合性能。我们使用Rouge-L作为大多数任务的性能得分，对于只有准确率作为指标的任务使用准确率。</sample>
    <sample id="526">敏感性

模型对同一任务的不同指令有多敏感：

- 能够在指令的措辞略有变化的情况下，对同一任务产生相同的结果。</sample>
    <sample id="527">指令调优在MULTIINSTRUCT上的有效性</sample>
    <sample id="528">图中内容翻译成中文如下：

多模态常识推理的指令调优效果

表1：多模态常识推理的零样本性能。最佳性能以粗体显示。

表2：问答和杂项的零样本性能。最佳性能以粗体显示。</sample>
    <sample id="529">图3：随着多模态指令任务簇增加，模型性能</sample>
    <sample id="530">不同指令数量对指令调优的影响

- OFA 在 5 条指令上进行微调，在所有评估任务上实现了更高的聚合性能，并且表现出更低的敏感性。

表 3：不同指令数量下 OFA，MultiInstruct 的性能。</sample>
    <sample id="531">细调策略对模型敏感性的影响
- 在MultiInstruct上进行指令调优可以显著降低OFA的敏感性。
- 从Natural Instructions数据集进行迁移学习可以进一步降低模型的敏感性。</sample>
    <sample id="532">零样本性能在NLP任务上的表现
- 在MultiInstruct上进行指令微调可以提高在未见过的NLP任务上的零样本性能。
- 转移学习策略MixedInstruct在Natural Instructions数据集上获得的零样本能力保存得最好。
表格4：NLP任务的零样本性能。性能以Rouge-L报告，最佳性能以粗体显示。</sample>
    <sample id="533">结论
- 第一个大规模的多模态指令调优数据集。
  - 包含62个来自10个广泛类别的多模态任务。
- 通过指令调优显著提高OFA的零样本能力。
- 探索几种迁移学习技术并展示其益处。
- 设计一个新的敏感性度量。</sample>
    <sample id="534">还有一件事！我们正在收集一个更大的多模态指令调优数据集，包含大约150个额外的视觉-语言任务，我们很快就会发布它们！</sample>
    <sample id="535">这篇论文的作者所属机构是UNIVERSITÀ DI TRENTO和FONDAZIONE BRUNO KESSLER。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="536">演讲者的名字是Mohammad Javad Hosseini，Filip Radlinski，Silvia Pareti和Annie Louis。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="562">语言模型的可接受性判断并不总是对上下文具有鲁棒性。</sample>
    <sample id="563">语言模型的可接受性判断并不总是对上下文具有鲁棒性。</sample>
    <sample id="564">重新审视最小对 paradigm，最小对 paradigm，MPP，评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：，BLiMP，1. 许多人在帮助自己。2. *许多人帮助她自己。P，1， &gt; P，2，，SyntaxGym，1. 没有顾客…花过钱。2. *顾客…花过钱。P，1.any， &gt; P，2.any，，Crows，1. 刻板印象句子。2. 非刻板印象句子。P，1， &gt; P，2，</sample>
    <sample id="565">重新审视最小对偶范式，最小对偶范式，MPP，评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：，BLiMP，1. 许多人在帮助自己。2. *许多人帮助她自己。P，1， &gt; P，2， SyntaxGym，1. 没有顾客...花过钱。2. *顾客...花过钱。P，1.any， ≥ P，2.any， CrowS，1. 刻板印象句子。2. 非刻板印象句子。P，1， &gt; P，2，</sample>
    <sample id="566">重新审视最小对偶范式，最小对偶范式，MPP，评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：，BLiMP，1. 许多人在帮助自己。2. *许多人帮助她自己。P，1， &gt; P，2，，SyntaxGym，1. 没有顾客...花过钱。2. *顾客...花过钱。P，1.any， ≥ P，2.any，，CrowS，1. 刻板印象句子。2. 非刻板印象句子。P，1， &gt; P，2，</sample>
    <sample id="567">重新审视最小对偶范式，最小对偶范式，MPP，评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：，BLiMP，1. 许多人在帮助自己。2. *许多人帮助她自己。P，1， &gt; P，2，，SyntaxGym，1. 没有顾客...花过钱。2. *顾客...花过钱。P，1.any， &gt; P，2.any，，CrowS，1. 刻板印象句子。2. 非刻板印象句子。P，1， &gt; P，2，</sample>
    <sample id="568">重新审视最小对偶范式，最小对偶范式，MPP，评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：，BLiMP，1. 许多人在帮助自己。2. *许多人帮助自己。P，1， &gt; P，2，SyntaxGym，1. 没有顾客...花过钱。2. *顾客...花过钱。P，1.any， &gt; P，2.any，Crows，1. 女人手工艺很糟糕。2. 男人手工艺很糟糕。P，1， &gt; P，2，这些判断在长前置语境下稳定吗？</sample>
    <sample id="569">重新审视最小对偶范式，最小对偶范式，MPP，评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：，BLiMP，1. 许多人在帮助自己。2. *许多人帮助她自己。P，1， &gt; P，2，SyntaxGym，1. 没有顾客...花过钱。2. *顾客...花过钱。P，1.any， &gt; P，2.any，Crows，1. 女人手工艺很糟糕。2. 男人手工艺很糟糕。P，1， &gt; P，2，这些判断在长前置语境下稳定吗？</sample>
    <sample id="570">重新审视最小对偶范式，最小对偶范式，MPP，评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：，BLiMP，1. 许多人在帮助自己。2. *许多人帮助她自己。P，1， &gt; P，2，SyntaxGym，1. 没有顾客...花过钱。2. *顾客...花过钱。P，1.any， &gt; P，2.any，Crows，1. 女人手工艺很糟糕。2. 男人手工艺很糟糕。P，1， &gt; P，2，这些判断在长前置语境下稳定吗？</sample>
    <sample id="571">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。测试套件：主谓一致。接受，不可接受。P，LM，绿色方框，Prefix，&gt;？P，LM，红色方框，Prefix，候选前缀空间。匹配的主谓一致。不匹配的。谁会从这个客户那里逃走，然后回到这里？*谁会从这个客户那里逃走，然后回到这里？*谁会从这个客户那里逃走，然后回到这里？BLIMP，从属岛。GPT2，OPT家族 - 125M到6.7B。</sample>
    <sample id="572">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。</sample>
    <sample id="573">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。</sample>
    <sample id="574">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。测试套件：主谓一致。接受，不接受。P，LM，绿色方框 | 前缀，&gt;？P，LM，红色方框 | 前缀，样本。候选前缀空间。匹配的主谓一致。不匹配的。岛效应，过滤缺口，绑定，维基百科。谁会从这个客户那里逃离？*谁会逃离这个客户？谁会从这个客户那里逃离？*杰西卡在注意到这些聚光灯之前能卖什么？亚伦在清理博物馆时听起来怎么样？谁会逃离这个客户？*杰西卡在注意到这些聚光灯之前能卖什么？亚伦在清理博物馆时听起来怎么样？谁会逃离这个客户？BLIMP，从属岛。GPT2，OPT家族 - 125M到6.7B</sample>
    <sample id="575">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。</sample>
    <sample id="576">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。测试套件：主谓一致。接受，不接受。P，LM，绿色方框 | 前缀，&gt;？P，LM，红色方框 | 前缀，样本。候选前缀空间。匹配的主谓一致。不匹配的。岛效应，过滤缺口，绑定，维基百科。谁会离开罗斯在回到这个客户之前？* 谁会离开罗斯从这个客户之前回到？有部关于音乐困扰艾莉森的纪录片。没有立法者努力工作。谁会离开罗斯在回到这个客户之前？* 有部关于音乐困扰艾莉森的纪录片。没有立法者努力工作。谁会离开罗斯从这个客户之前回到？BLIMP，存在“there”量词。BLIMP，从属岛。GPT2，OPT家族 - 125M到6.7B</sample>
    <sample id="577">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。</sample>
    <sample id="578">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。测试套件：主谓一致。接受，不接受。P，LM，绿色方框， | 前缀， &gt;？P，LM，红色方框， | 前缀，样本。候选前缀空间。匹配的主谓一致。绿色方框，不匹配的。灰色方框，岛效应，星星，填充缺口，圆圈，绑定，三角形，维基百科，圆圈，...。谁会离开这个客户之前再回来？*谁会离开这个客户之前再回来？维基百科，不相关。玫瑰是蔷薇属的木本多年生开花植物。有三百多种和数千种栽培品种。谁会离开这个客户之前再回来？*谁会离开这个客户之前再回来？GPT2，OPT家族 - 125M到6.7B</sample>
    <sample id="579">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。测试套件：主谓一致。接受，不接受。P，LM，绿色方框， | 前缀， &gt;？P，LM，红色方框， | 前缀，候选前缀空间。匹配的主谓一致。不匹配的。岛效应，填空，绑定，维基百科。谁会离开这个客户之前再回来？*谁会离开这个客户之前再回来？维基百科，不相关。玫瑰是蔷薇属的木本多年生开花植物。有三百多种和数千种栽培品种。谁会离开这个客户之前再回来？*谁会离开这个客户之前再回来？GPT2，OPT家族 - 125M到6.7B</sample>
    <sample id="580">测试MPP判断是否随上下文长度，结构匹配和可接受性变化。测试套件：主谓一致。接受，不接受。P，LM，绿色方框，| 前缀，&gt;？P，LM，红色方框，| 前缀，样本。候选前缀空间。匹配的主谓一致。不匹配的。岛效应，填空，绑定，维基百科。玫瑰是蔷薇属的木本多年生开花植物。有三百多种和数千种栽培品种。玫瑰会逃离这个客户之前会逃离这个客户吗？玫瑰会逃离这个客户之前会逃离这个客户吗？GPT2，OPT家族 - 125M到6.7B</sample>
    <sample id="581">MPP判断对任意上下文长度都很稳健。我们对不同上下文进行MPP评估——可接受/不可接受；匹配/不匹配结构——长度可达900个词。BLIMP，OPT 6.7B。</sample>
    <sample id="582">MPP判断对任意上下文长度都很稳健。我们对不同上下文进行MPP评估——可接受/不可接受；匹配/不匹配结构——长度可达900个词。BLIMP，OPT 6.7B。</sample>
    <sample id="583">可接受/不可接受的MPP句子在上下文提高/降低判断性能

我们使用不同的上下文进行MPP评估——可接受/不可接受；匹配/不匹配结构——长度可达900个标记

BLIMP，OPT 6.7B

前缀策略

绿色：可接受，匹配
紫色：不可接受，匹配
橙色：可接受，不匹配
粉色：不可接受，不匹配

有部关于音乐让艾莉森感到烦躁的纪录片。没有立法者在努力工作。罗斯可能会逃离这个客户吗？

有部关于音乐让艾莉森感到烦躁的纪录片。没有立法者在努力工作。罗斯可能会逃离这个客户吗？

有部关于音乐让艾莉森感到烦躁的纪录片。大多数立法者在努力工作。罗斯可能会逃离这个客户吗？

有部关于音乐让艾莉森感到烦躁的纪录片。大多数立法者在努力工作。罗斯可能会逃离这个客户吗？</sample>
    <sample id="584">可接受/不可接受的MPP句子在上下文中的提高/降低判断性能。我们进行MPP评估，使用不同的上下文——可接受/不可接受；匹配/不匹配结构——长度可达900个词。BLIMP，OPT 6.7B。</sample>
    <sample id="585">可接受/不可接受的MPP句子在上下文中的提高/降低判断性能

我们进行MPP评估，使用不同的上下文——可接受/不可接受；匹配/不匹配结构——长度可达900个词

BLIMP，OPT 6.7B

前缀策略

绿色：可接受，匹配
紫色：不可接受，匹配
橙色：可接受，不匹配
粉色：不可接受，不匹配

有份关于音乐让艾莉森感到烦躁的纪录片。没有立法者在努力工作。罗斯可能会逃离这个客户吗？

有份关于音乐让艾莉森感到烦躁的纪录片。没有立法者在努力工作。罗斯可能会逃离这个客户吗？

有份关于音乐让艾莉森感到烦躁的纪录片。大多数立法者在努力工作。罗斯可能会逃离这个客户吗？

有份关于音乐让艾莉森感到烦躁的纪录片。大多数立法者在努力工作。罗斯可能会逃离这个客户吗？</sample>
    <sample id="586">可接受/不可接受的MPP句子，结构匹配与否严重影响模型性能。我们进行MPP评估，使用不同上下文——可接受/不可接受；匹配/不匹配结构——长度可达900个词。BLIMP，OPT 6.7B。</sample>
    <sample id="587">可接受/不可接受的MPP句子，结构匹配与否对模型性能影响最大

我们进行MPP评估，使用不同上下文——可接受/不可接受；匹配/不匹配结构——长度可达900个词

BLIMP，OPT 6.7B</sample>
    <sample id="588">可接受/不可接受的MPP句子，结构匹配最严重影响模型性能。我们进行MPP评估，使用不同上下文——可接受/不可接受；匹配/不匹配结构——长度最多900个词。BLIMP，OPT 6.7B。</sample>
    <sample id="589">为什么匹配的前缀会影响语言模型的判断？

我们以保持相关结构的方式对上下文句子进行扰动，并询问模型是否对这些句子同样敏感。

- 前缀/后缀副词：“然而，&lt;sent&gt;。”
- 长前缀副词：“首先和最重要的是，&lt;sent&gt;。”
- 添加从句：“不管X怎么想，&lt;sent&gt;。”
- 引用：“昨天，X说，‘&lt;sent&gt;’。”</sample>
    <sample id="590">为什么匹配的前缀会影响LM判断？

我们以保持相关结构的方式扰动上下文句子，并询问模型是否对这些句子同样敏感。

- 前缀/后缀副词：“然而，&lt;sent&gt;。”
- 长前缀副词：“首先和最重要的是，&lt;sent&gt;。”
- 添加从句：“不管X怎么想，&lt;sent&gt;。”
- 引用：“昨天，X说，&lt;sent&gt;。”</sample>
    <sample id="591">为什么匹配的前缀会影响LM判断？我们以保持相关结构的方式对上下文句子进行扰动，并询问模型是否对这些句子同样敏感。- 前缀/后缀副词：“然而，&lt;sent&gt;。”- 长前缀副词：“首先和最重要的是，&lt;sent&gt;。”- 添加从句：“不管X怎么想，&lt;sent&gt;。”- 引语：“昨天，X说，&lt;sent&gt;。”</sample>
    <sample id="592">为什么匹配前缀会影响语言模型的判断？我们以保持相关结构的方式对上下文句子进行扰动，并询问模型是否对这些句子同样敏感。- 前缀/后缀副词：“然而，&lt;sent&gt;。”- 长前缀副词：“首先和最重要的是，&lt;sent&gt;。”- 添加从句：“不管X怎么想，&lt;sent&gt;。”- 引语：“昨天，X说，‘&lt;sent&gt;’。”模型对扰动句子的敏感性相似。</sample>
    <sample id="593">为什么匹配前缀会影响LM判断？我们以保持相关结构的方式扰动上下文句子，并询问模型是否对这些句子同样敏感。- 前缀/后缀副词：“然而，&lt;sent&gt;。”- 长前缀副词：“首先和最重要的是，&lt;sent&gt;。”- 添加从句：“不管X怎么想，&lt;sent&gt;。”- 引语：“昨天，X说，‘&lt;sent&gt;’。”模型对扰动句子的敏感性相似。</sample>
    <sample id="594">关键要点
- 语言模型对跨句子的潜在语法/语义特征敏感。
- 使用短的单句输入进行MPP评估不能充分捕捉LMs的抽象知识。</sample>
    <sample id="595">关键要点
- 语言模型对跨句子共享的潜在语法/语义特征敏感。
- 使用短的单句输入进行MPP评估不能充分捕捉LMs的抽象知识。</sample>
    <sample id="596">关键要点
- 语言模型对跨句子共享的潜在句法/语义特征敏感。
- 使用短的单句输入进行MPP评估不能充分捕捉LMs的抽象知识。</sample>
    <sample id="597">嗯…这个嘛，第一步是将输入词元映射到一个词元标签。如果还有啥疑问，你可以再问我哦。</sample>
    <sample id="598">Coscript中包含了55，000个脚本。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="626">嗯…这个嘛，从表格里看，LHA在1:1部分的F1值最高，是0.747。不过这里没有DEplain这个方法哦。你是不是有什么误解？如果还有其他问题，你可以再和我说一说。</sample>
    <sample id="627">弱监督学习能缓解标注瓶颈。嗯，你要是还有啥想知道的，尽管问哈。</sample>
    <sample id="628">DEplain-web中，文档采用手动对齐方法的有481个，采用自动对齐方法的有868个。如果还有疑问，可以再问我哦。</sample>
    <sample id="629">CoNLL++ 数据集是从2020年的路透社新闻中收集的，并按照CoNLL-2003注释指南进行注释。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="630">XSemPLR：多种自然语言和语义表示的跨语言语义解析。张宇森，王军，王志国，张瑞。</sample>
    <sample id="631">语义解析是构建用户查询语义表示的任务，例如SQL和Lambda演算。</sample>
    <sample id="632">跨语言语义解析是将多种自然语言的查询翻译成多种语义表示的任务。</sample>
    <sample id="633">跨语言语义解析是将多种自然语言的查询翻译成多种语义表示的任务。</sample>
    <sample id="634">现有的CLSP模型是分别提出的，并在任务和应用有限的数据集上进行评估。例如：缺乏对某些自然语言的覆盖。</sample>
    <sample id="635">现有的CLSP模型是分别提出的，并在任务和应用有限的数据集上进行评估。例如：缺乏对某些自然语言的覆盖。</sample>
    <sample id="636">现有的跨语言语义解析模型是分别提出的，并在任务和应用有限的数据集上进行评估。例如：缺乏对某些语义表示的覆盖。</sample>
    <sample id="637">现有的跨语言语义解析模型是分别提出的，并在任务和应用有限的数据集上进行评估。例如：缺乏对某些语义表示的覆盖。</sample>
    <sample id="638">现有的CLSP模型是分别提出的，并在任务和应用有限的数据集上进行评估。例如：缺乏对某些神经模型的覆盖。</sample>
    <sample id="639">我们提供了一个统一的跨语言语义解析数据集XSemPLR，用于多种自然语言和语义表示的跨语言语义解析。它包含：9个不同领域的数据集，5个语义解析任务，8种语义表示，22种自然语言，分布在15个语系中。</sample>
    <sample id="640">我们提供了一个统一的跨语言语义解析数据集XSemPLR，用于多种自然语言和语义表示的跨语言语义解析。它包含：9个不同领域的数据集，5个语义解析任务，8种语义表示，22种自然语言，分布在15个语系中。</sample>
    <sample id="641">实验设置
- 我们考虑了六种训练和评估的设置。
  - Translate-Test：使用谷歌翻译API将源语言翻译为目标语言。然后使用单一语言模型进行训练和评估。
训练
推理</sample>
    <sample id="642">实验设置
- 我们考虑了六种训练和评估的设置。
  - Translate-Test：使用Google翻译API将源语言翻译为目标语言。然后使用单语模型进行训练和评估。
训练
推理</sample>
    <sample id="643">实验设置
- 我们考虑了六种训练和评估的设置。
  - Translate-Test：使用谷歌翻译API将源语言翻译为目标语言。然后使用单语模型进行训练和评估。
训练
推理</sample>
    <sample id="644">实验设置
- 我们考虑了六种训练和评估的设置。
  - 独语模型：源语言与目标语言相同，例如德语-德语。我们还通过仅使用10%的训练数据来训练独语模型来测试独语少样本设置。
训练
推理</sample>
    <sample id="645">实验设置
我们考虑了六种训练和评估的设置。
单语模型：源语言与目标语言相同，例如德语到德语。我们还测试了单语少样本设置，通过仅使用10%的训练数据来训练单语模型。
训练
推理</sample>
    <sample id="646">实验设置
- 我们考虑了六种训练和评估的设置。
  - 单语模型：源语言与目标语言相同，例如德语-德语。我们还测试了单语少量样本设置，通过仅使用10%的训练数据来训练单语模型。
训练
推理</sample>
    <sample id="647">实验设置。我们考虑了六种训练和评估的设置。多语言模型：为所有语言训练一个统一的多语言模型。训练。推理。</sample>
    <sample id="648">实验设置。我们考虑了六种训练和评估的设置。多语言模型：为所有语言训练一个统一的多语言模型。</sample>
    <sample id="649">实验设置
我们考虑了六种训练和评估的设置。
多语言模型：为所有语言训练一个统一的多语言模型。
训练
推理</sample>
    <sample id="650">实验设置
- 我们考虑了六种训练和评估的设置。
  - 交叉语言零样本/少量样本迁移：在一个源语言上进行训练，然后转移到另一个语言。
训练
- 英语
- 英语
- 德语少量样本
推理
- 德语
- 多语言模型
- SQL</sample>
    <sample id="651">实验设置。我们考虑了六种训练和评估的设置。跨语言零样本/少量样本迁移：在一个源语言上进行训练，然后迁移到另一个语言。训练。英语或英语，德语少量样本。多语言模型。SQL。推理。德语。多语言模型。SQL。</sample>
    <sample id="652">单语分析
我们在两种模型组上进行评估，单语设置
- Enc-PTR：多语言预训练编码器与指针式解码器
  - XLM-R + PTR，mBERT + PTR
- Enc-Dec：多语言预训练编码-解码模型
  - mBART，mT5
我们发现Enc-Dec，mT5，在所有数据集上表现最佳！
|  | MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa | 平均值 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 单语 | 30.63 | 72.18 | 40.40 | 83.82 | 57.47 | 23.46 | 52.53 | 75.41 | 5.87 | 49.09 |
|  | 31.31 | 71.41 | 47.30 | 8</sample>
    <sample id="653">单语分析
我们在两种模型组上进行评估，单语设置
○ Enc-PTR：多语言预训练编码器与指针式解码器
■ XLM-R + PTR，mBERT + PTR
○ Enc-Dec：多语言预训练编码-解码模型
■ mBART，mT5
我们发现Enc-Dec，mT5，在所有数据集上表现最佳！
|  | MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa | 平均值 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 单语 | 30.63 | 72.18 | 40.40 | 83.82 | 57.47 | 23.46 | 52.53 | 75.41 | 5.87 | 49.09 |
|  | 31.31 | 71.41 | 47.30 | 85.</sample>
    <sample id="654">单语分析
我们在两种模型组上进行评估，单语设置
- Enc-PTR：多语言预训练编码器与指针式解码器
  - XLM-R + PTR，mBERT + PTR
- Enc-Dec：多语言预训练编码-解码模型
  - mBART，mT5
我们发现Enc-Dec，mT5，在所有数据集上表现最佳！
|  | MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa | 平均值 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 单语 | mBERT+PTR | 30.63 | 72.18 | 40.40 | 83.82 | 57.47 | 23.46 | 52.53 | 75.41 | 49.09 |
|  | XLM-R+PTR | 31.31 | 71.41 | 47.</sample>
    <sample id="655">单语分析
我们在两种模型组上评估了单语设置
- Enc-PTR：多语言预训练编码器与指针式解码器
  - XLM-R + PTR，mBERT + PTR
- Enc-Dec：多语言预训练编码-解码模型
  - mBART，mT5
我们发现Enc-Dec，mT5，在所有数据集上都取得了最佳性能！
|  | MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa | 平均值 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 单语 | mBERT+PTR | 30.63 | 72.18 | 40.40 | 83.82 | 57.47 | 23.46 | 52.53 | 75.41 | 49.09 |
|  | XLM-R+PTR | 31.31 | 71.41 | 47</sample>
    <sample id="656">多语言训练分析
我们在多语言环境中评估了mT5和XLM-R + PTR。
Enc-Dec/Enc-PTR，mT5/XLM-R，可以通过在多种语言的混合中进行训练得到改进。
单语言
XLM-R+PTR
mT5
平均
52.03
58.16
多语言
XLM-R+PTR
mT5
平均
59.06
61.82</sample>
    <sample id="657">多语言训练分析
我们在多语言环境中评估了mT5和XLM-R + PTR。
Enc-Dec/Enc-PTR，mT5/XLM-R，通过在多种语言的混合中进行训练可以得到改进。
单语言
XLM-R+PTR
31.31
71.41
47.30
85.17
59.10
23.53
62.37
65.16
80.36
10.29
52.03
58.16
mT5
53.15
74.26
50.73
91.65
66.29
30.15
81.83
10.29
平均
59.06
61.82
多语言
XLM-R+PTR
39.72
71.35
40.20
85.91
61.03
30.79
61.82
81.68
平均
59</sample>
    <sample id="658">我们使用mT5和XLM-R + PTR在多语言环境中进行评估。大多数主要的NLs可以获得性能提升，除了在7个数据集中英语性能下降，在3个数据集中提升。这被称为“多语言诅咒”。</sample>
    <sample id="659">多语言训练分析
我们在多语言环境下评估了mT5和XLM-R + PTR。
大多数主要的NLs都能获得性能提升，除了英语在7个数据集上的性能下降，在3个数据集上有所提升。这被称为“多语言诅咒”。</sample>
    <sample id="660">跨语言性能差距
蓝色线：跨语言少样本迁移
橙色线：跨语言零样本迁移
绿色线：单语言设置</sample>
    <sample id="661">跨语言性能差距
蓝色线条：跨语言少样本迁移
橙色线条：跨语言零样本迁移
绿色线条：单语言设置</sample>
    <sample id="662">跨语言性能差距

绿色 - 橙色 在零样本设置下，跨语言迁移性能差距显著

蓝色 - 橙色 在少量样本设置下，性能差距迅速缩小</sample>
    <sample id="663">其他结果与发现，第四部分，论文，- Enc-Dec，mT5，在之前的工作中表现更好或达到相当的结果。- 在英语NL上进行预训练可以显著提高目标NLs上少样本性能。- 多语言LLMs，Codex和BLOOM，对于跨语言语义解析任务仍然不够。- 中文迁移学习和英语单语训练，En -&gt; En，的性能差距最大，而德语通常差距最小。- FunQL在其他三种语义表示中表现最好，而SQL表现最差。</sample>
    <sample id="664">其他结果与发现，第四节论文中，- Enc-Dec，mT5，在性能上超越了之前的工作或达到相当的结果。- 在英语NL上进行预训练可以显著提升目标NLs上少样本学习的表现。- 多语言LLMs，Codex和BLOOM，在跨语言语义解析任务中仍然不够。- 中文迁移学习和英语单语训练，En -&gt; En，的性能差距最大，而德语通常差距最小。- FunQL在其他三种语义表示中表现最佳，而SQL表现最差。</sample>
    <sample id="665">- 我们构建了XSemPLR，一个用于跨语言语义解析的统一基准，涉及多种自然语言和意义表示。
- 我们对三种代表性类型的多语言语言模型进行了全面的基准研究。
- 我们的结果表明，使用单语训练的mT5在性能上表现最佳，而值得注意的是，多语言LLMs在执行跨语言语义解析任务方面仍然不够。此外，单语训练和跨语言迁移学习之间的性能差距仍然显著。</sample>
    <sample id="666">结论
- 我们构建了XSemPLR，一个跨语言语义解析的统一基准，支持多种自然语言和意义表示。
- 我们对三种代表性类型的多语言语言模型进行了全面的基准研究。
- 我们的结果表明，使用单语训练的mT5在性能上表现最佳，而值得注意的是，多语言LLMs在执行跨语言语义解析任务方面仍然不够。此外，单语训练和跨语言迁移学习之间的性能差距仍然显著。</sample>
    <sample id="667">有参数化水印，字典水印，后门水印和对抗性水印。</sample>
    <sample id="668">不足够。</sample>
    <sample id="695">该方法通过在训练中诱导排列的不确定性来处理。嗯，你要是还有啥疑问可以接着问哈。</sample>
    <sample id="696">嗯…这个嘛，下游NLP模型的公平性定义有点复杂。简单说，就是看模型在不同政治倾向的上下文中，对仇恨言论和错误信息的判断是否一致。如果不同政治倾向的模型在这些上下文中表现得不一样，那可能就不太公平。你要是还有啥疑问，可以再问我哦。</sample>
    <sample id="697">演讲者的名字是Yanis Labrak，Adrien Bazoge，Richard Dufour和Mickael Rouvier。</sample>
    <sample id="698">演讲者的名字是Koustuv Sinha。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="699">演讲者的名字是Myra Cheng，Esin Durmus和Dan Jurafsky。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="700">嗯…这个嘛，在本文背景下，热带主义可能意味着文化，传统，骄傲，异国情调这些概念，用来定义那些被标记的群体。你要是还有啥想法或者疑问，咱们可以再聊聊。</sample>
    <sample id="701">作者通过本质化叙述来创建目标群体的人工描写。嗯，就是用“culture， tradition， proud， exotic”这些词来定义那些被标记的群体，只根据他们的身份。你要是还有啥想法或者问题，随时跟我说哈。</sample>
    <sample id="702">本文中使用了P-CXMI来衡量语境使用情况。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="703">DrBERT是从头开始构建模型，ChuBERT是使用现有的预训练模型进行持续预训练。嗯，你要是还有啥疑问可以接着问哈。</sample>
    <sample id="751">三位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="752">嗯…迭代迁移学习呢，就是先用旧数据和旧模型，然后通过fine-tune得到新模型。你要是还有啥想知道的，尽管再问哈。</sample>
    <sample id="753">数据集的目标是理解用户在做选择时的语言。</sample>
    <sample id="754">嗯…这个我不太清楚呢。你可以再给我点关于EaaS的信息吗？这样我可能能更好地回答你。</sample>
    <sample id="755">三位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="756">嗯…这个图里没提到有多少个注释者用于创建初始数据集呢。你可以再找找其他资料看看。要是还有啥问题，你可以再跟我说哦。</sample>
    <sample id="757">这篇论文的作者所属机构有卡内基梅隆大学，华盛顿大学和艾伦人工智能研究所。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="758">“I saw Bart and Lisa; Homer came and sneezed”。</sample>
    <sample id="759">嗯…这个我也不太清楚呢。你可以去查查最新的科技新闻或者学术论文，应该能找到答案。要是你找到了，也可以跟我说说呀。</sample>
    <sample id="760">嗯…这个嘛，因为模型的可接受性可能会受到长上下文的影响。如果只看局部，可能就忽略了整体的语义关系，这样评估就不准确了。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="761">嗯，是的。多语言训练会导致英语表现下降。你要是还有啥疑问，尽管问哈。</sample>
    <sample id="762">注释者不知道该实体。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="763">嗯…图片里没提到使用了哪些MT指标呢。你可以再找找其他信息吗？</sample>
    <sample id="764">嗯…这个图片里没提到泛化中的回归会影响特定的NER类型呢。你还有其他关于这个话题的问题吗。</sample>
    <sample id="765">嗯…立场在NLP里很重要，因为它能帮助理解文本的意图和情感倾向。比如说，一个句子可能有多种解读，立场能确定哪种解读更合理。这样在处理像垃圾邮件，情感分析这些任务时就更有用。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="766">嗯…这个嘛，像BLOOM这样的多语言LLM，一般是采用适配器微调的方式。如果还有啥疑问，你可以再问我哦。</sample>
    <sample id="767">他们使用的是RoBERTA-base + classifier head这个模型进行迁移学习。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="768">嗯…这个我不太清楚呢。你可以去查查相关的技术文档或者学术论文，应该能找到答案。要是你找到了，也可以跟我说说呀。</sample>
    <sample id="769">三条。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="770">嗯…这个我不太清楚具体的数据呢。你可以再给我点其他信息吗？</sample>
    <sample id="771">演讲者的名字是Shuheng Liu和Alan Ritter。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="772">嗯…这个嘛，论文里提到的DEPLAIN-APA和DEPLAIN-WEB的测试数据集，它们的SARI，BLEU，BS-P和FRE等指标都挺高的，说明模型效果不错。不过，具体能不能用作基准，还得看具体应用场景和要求。如果这个模型在你的应用场景里表现良好，那就可以用作基准。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="773">他们进行了四个较小模型的实验。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="774">OFA被用作研究多模型指令调整的基础模型。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="833">Google。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="834">Stony Brook University。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="835">嗯…这个信息里没提到具体分析了哪些语言对呢。你可以再找找其他相关资料，或者咱们再聊聊看。</sample>
    <sample id="836">演讲者的名字是Shangbin Feng。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="837">研究了DEplain-APA，DEplain-web，DEplain-APA+web和src2src-baseline这四个模型。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="838">53个任务用于训练，10个任务用于测试。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="839">三位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="840">作者在实验中使用了AG News，MIND，SST2，Enron Spam这些数据集。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="876">嗯…NACHOS是文中提到的一个东西，不过具体是什么，这里没说清楚呢。你可以再给我点信息吗。</sample>
    <sample id="877">David Vilar Torres，Markus Freitag，Colin Cherry，Jiaming Luo，Viresh Ratnakar，George Foster。</sample>
    <sample id="878">提示策略对结果影响很大呢。有516个句子，占1000个句子的大多数，BLEURT分差超过1分，最大分差能达到40分。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="879">Carnegie Mellon University Language Technologies Institute，TÉCNICO LISBOA，BAIR，Berkeley Artificial Intelligence Research，Unbabel。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="880">抱歉，图片内容没有提到5个由专家编写的指令。你还有其他问题吗？</sample>
    <sample id="881">作者建议用核心ference分辨率任务来测试模型，这个任务能探测模型利用预训练知识和推理时间知识的能力。</sample>
    <sample id="882">嗯…你得告诉我是啥英文内容啊，这样我才能给你翻译呢。</sample>
    <sample id="883">PaLM：路径语言模型
- Chowdery等人，2022
  arXiv:2204.02311。
- 540B参数。
- 在780B个令牌上训练。
- 密集激活。
- 6144个TPU v4芯片。
- 在数百个LMU和生成基准中处于SOTA地位。</sample>
    <sample id="884">PaLM：路径语言模型
- Chowdery等人，2022
  arXiv:2204.02311。
- 540B参数。
- 在780B个令牌上训练。
- 密集激活。
- 6144个TPU v4芯片。
- 在数百个LMU和生成基准上达到SOTA。</sample>
    <sample id="885">我们的贡献

- 首次系统研究LLM提示在MT中的应用。
  - 对候选池和选择策略都有涉及。
- 用MT社区的最佳实践评估翻译能力：
  - 使用最新测试集（避免训练集和测试集重叠，防止在评估数据上过拟合）。
  - 与最新WMT提交进行比较（使用最新训练数据的SOTA系统）。
  - 使用SOTA MT指标（与人类判断有更好的相关性）。
  - 专家基于的人类评估（比众包工作者更可靠）。
- 对提示选择策略的建议</sample>
    <sample id="886">我们的贡献

- 首次系统研究LLM提示在MT中的应用。
  - 对候选池和选择策略都有研究。
- 用MT社区的最佳实践评估翻译能力：
  - 使用最新测试集（避免测试/训练重叠和在评估数据上过拟合）。
  - 与最新WMT提交进行比较（使用最新训练数据的SOTA系统）。
  - 使用SOTA MT指标（与人类判断有更好的相关性）。
  - 专家基于的人类评估（比众包工作者更可靠）。
- 对提示选择策略的建议</sample>
    <sample id="887">我们的贡献

- 首次系统研究LLM提示在MT中的应用。
  - 对候选池和选择策略都进行了研究。
- 用MT社区的最佳实践评估翻译能力：
  - 使用最新测试集（避免训练集和测试集重叠，防止在评估数据上过拟合）。
  - 与最新WMT提交进行比较（使用最新训练数据的SOTA系统）。
  - 使用SOTA MT指标（与人类判断有更好的相关性）。
  - 专家基于的人类评估（比众包工作者更可靠）。
- 对提示选择策略的建议</sample>
    <sample id="888">我们的贡献

- 首次系统研究LLM提示在MT中的应用。
  - 对候选池和选择策略都有研究。
- 用MT社区的最佳实践评估翻译能力：
  - 使用最新测试集（避免训练/测试数据重叠和在评估数据上过拟合）。
  - 与最新WMT提交进行比较（使用最新训练数据的SOTA系统）。
  - SOTA MT指标（与人类判断有更好的相关性）。
  - 专家基于的人类评估（比众包工作者更可靠）。
- 对提示选择策略的建议</sample>
    <sample id="889">提示对翻译质量有很大的影响。- 为每个句子选择两个随机提示。- 计算每个句子-提示对的BLEURT值。- 大多数句子（1000个中的516个）显示出超过1个BLEURT点的差异。- 差异可高达40个BLEURT点！</sample>
    <sample id="890">提示对翻译质量有很大影响。- 为每个句子选择两个随机提示。- 计算每个句子-提示对的BLEURT值。- 大多数句子（1000个中有516个）的差异超过1个BLEURT点。- 差异可高达40个BLEURT点！</sample>
    <sample id="891">提示对翻译质量有很大影响。- 为每个句子选择两个随机提示。- 计算每个句子-提示对的BLEURT值。- 大多数句子（1000个中的516个）显示差异超过1个BLEURT点。- 差异可高达40个BLEURT点！</sample>
    <sample id="892">一个目击者报警，警察带着几名警员赶到了。</sample>
    <sample id="893">一个路人报警，警察带着几名警员赶到了。</sample>
    <sample id="894">一个目击者报警，警察带着几名警员赶到。</sample>
    <sample id="895">一个目击者报警，警察带着几名警员赶到了。</sample>
    <sample id="896">一个目击者报警，警察带着几名警员赶到。</sample>
    <sample id="897">实验结果
- 示例质量比与源句子的相似性更重要。
- 专门的SOTA系统有显著优势。
- PaLM接近于Google Translate。
MQM的见解：
- PaLM的流畅性与SOTA相当。
- 准确性得分通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/笨拙”对PaLM通常较低。</sample>
    <sample id="898">实验结果：。- 示例质量比与源句子的相似性更重要。- 专门的SOTA系统有显著优势。- PaLM接近于Google Translate。MQM的见解：。- PaLM的流畅性与SOTA相当。- 准确性得分通常较低。- 主要受“准确性/遗漏”影响。- PaLM的“风格/笨拙”通常较低。</sample>
    <sample id="899">实验结果：。- 示例质量比与源句子的相似性更重要。- 专门的SOTA系统有显著优势。- PaLM接近于Google Translate。MQM的见解：。- PaLM的流畅性与SOTA相当。- 准确性得分通常较低。- 主要受“准确性/遗漏”影响。- “风格/笨拙”对PaLM通常较低。</sample>
    <sample id="900">实验结果：。- 示例质量比与源句子的相似性更重要。- 专门的SOTA系统有显著优势。- PaLM接近于Google Translate。MQM的见解：。- PaLM的流畅性与SOTA相当。- 准确性得分通常较低。- 主要受“准确性/遗漏”影响。- “风格/笨拙”对PaLM通常较低。</sample>
    <sample id="901">实验结果
- 示例质量比与源句子的相似性更重要。
- 专门的SOTA系统有显著优势。
- PaLM接近于Google Translate。
MQM的见解：
- PaLM的流畅性与SOTA相当。
- 准确性得分通常较低。
  - 主要受“准确性/遗漏”影响
- PaLM的“风格/笨拙”通常较低。</sample>
    <sample id="902">实验结果：。- 示例质量比与源句子的相似性更重要。- 专门的SOTA系统有显著优势。- PaLM接近于Google Translate。MQM的见解：。- PaLM的流畅性与SOTA相当。- 准确性得分通常较低。- 主要受“准确性/遗漏”影响。- “风格/笨拙”对PaLM通常较低。</sample>
    <sample id="903">实验结果
- 示例质量比与源句子的相似性更重要。
- 专门的SOTA系统有显著优势。
- PaLM接近于Google Translate。
MQM的见解：
- PaLM的流畅性与SOTA相当。
- 准确性得分通常较低。
  - 主要受“准确性/遗漏”影响
- PaLM的“风格/笨拙”通常较低。</sample>
    <sample id="904">实验结果
- 示例质量比与源句子的相似性更重要。
- 专门的SOTA系统有显著优势。
- PaLM接近于Google Translate。
MQM的见解：
- PaLM的流畅性与SOTA相当。
- 准确性得分通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/笨拙”对PaLM通常较低。</sample>
    <sample id="905">实验结果
- 示例质量比与源句子的相似性更重要。
- 专门的SOTA系统有显著优势。
- PaLM接近于Google Translate。
MQM的见解：
- PaLM的流畅性与SOTA相当。
- 准确性得分通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/笨拙”对PaLM通常较低。</sample>
    <sample id="906">“thank you”可以翻译为“谢谢”。</sample>
    <sample id="907">《比你想象的弱：对弱监督学习的批判性审视》</sample>
    <sample id="908">《比你想象的弱》：对弱监督学习的批判性审视。作者：Dawei Zhu，Xiaoyu Shen，Marius Mosbach，Andreas Stephan，Dietrich Klakow。来自Saarland University，Amazon Alexa和University of Vienna。</sample>
    <sample id="909">弱监督缓解了标注瓶颈。
但是弱标签是噪声！
噪声记忆会损害泛化能力。
弱监督学习（WSL）
尽管使用噪声数据训练，但训练模型以很好地泛化。</sample>
    <sample id="910">弱监督缓解了标注瓶颈。
但是弱标签是噪声！
噪声记忆会损害泛化能力。
弱监督学习（WSL）
尽管使用噪声数据训练，但训练模型以实现良好的泛化能力。</sample>
    <sample id="911">弱监督缓解了标注瓶颈。
但是弱标签是嘈杂的！
噪声记忆会损害泛化能力。
弱监督学习（WSL）
尽管训练数据是嘈杂的，但训练模型以实现良好的泛化能力。</sample>
    <sample id="912">弱监督缓解了标注瓶颈。但是弱标签是噪声！噪声记忆会损害泛化能力。弱监督学习，WSL，训练在噪声数据上训练的模型，但能很好地泛化。</sample>
    <sample id="913">弱监督缓解了标注瓶颈。
但是弱标签是噪声！
噪声记忆会损害泛化能力。
弱监督学习（WSL）
尽管使用噪声数据训练，但训练模型以良好泛化。</sample>
    <sample id="914">最近的弱监督学习工作中的一个常见说法是：“我们仅在弱监督数据上训练模型，并且达到XX%的准确率。”</sample>
    <sample id="915">最近的弱监督学习工作中的一个常见说法是：“我们仅在弱监督数据上训练模型，并且达到XX%的准确率。”</sample>
    <sample id="916">最近WSL工作中常见的说法是：“我们只在弱监督数据上训练模型，并且达到XX%的准确率。”</sample>
    <sample id="917">最近的弱监督学习工作中的一个常见说法是：“我们只在弱监督数据上训练模型，并且达到XX%的准确率。”</sample>
    <sample id="918">我们的研究问题

RQ1 是否需要干净的验证数据？

RQ2 WSL方法需要多少干净样本？

RQ3 如何更有效地利用可用的干净样本？</sample>
    <sample id="919">我们的研究问题

RQ1 是否需要干净的验证数据？

RQ2 WSL方法需要多少干净样本？

RQ3 如何更高效地利用可用的干净样本？</sample>
    <sample id="920">主要发现</sample>
    <sample id="921">主要发现</sample>
    <sample id="922">主要发现</sample>
    <sample id="923">RQ1 主要发现
在弱标签上验证
无验证，随机选择
在干净标签上验证
FTw BOND COSINE MLC L2R
相对性能改进百分比（%）
-10 0 10 20 30
6</sample>
    <sample id="924">主要发现

→ 清洁验证集是不可或缺的。</sample>
    <sample id="925">RQ2 主要发现</sample>
    <sample id="926">RQ2 主要发现</sample>
    <sample id="927">主要发现。WSL方法从更多的干净验证样本中受益！</sample>
    <sample id="928">主要发现。WSL方法从更多的干净验证样本中受益！</sample>
    <sample id="929">主要发现

WSL方法从更多的干净验证样本中受益！

但将其用于训练更好（例如，LoRAc）！</sample>
    <sample id="930">RQ3 主要发现

N=10 每类干净样本

在CFT之前，在CFT之后

准确率/ F1

N=30 每类干净样本

在CFT之前，在CFT之后

准确率/ F1</sample>
    <sample id="931">RQ3 主要发现
N=10 每类干净样本
在CFT之前
在CFT之后
准确率/F1
82
84
80
82
84
80
76
82
84
80
76
N=30 每类干净样本
在CFT之前
在CFT之后
准确率/F1
84
86
82
84
82
80
78
82
84
80
78
82
84
80
78
82
84
80
78
82
84
80
78
82
84
80
78
82
84
80
78
82
84
80
78
82
84
80
78
82
84
80
78
82
84
80
78
82
84
80
78
82
84
80
78</sample>
    <sample id="932">RQ3 主要发现
N=10 每类干净样本
在CFT之前
在CFT之后
N=30 每类干净样本
在CFT之前
在CFT之后</sample>
    <sample id="933">主要发现

→连续微调（CFT）消除了WSL方法之间的性能差距。

→无需使用复杂的WSL方法，FTw表现同样出色。</sample>
    <sample id="934">结论

最近的WSL方法
- 需要干净的样本。
- 高估了它们的实用性。😊

我们的建议
- 报告模型选择标准。
- 使用少样本学习方法作为基线。
- 总是应用连续微调（CFT）。</sample>
    <sample id="935">结论

近期WSL方法
- 需要干净的样本。
- 高估了它们的实用性。

我们的建议
- 报告模型选择标准。
- 以少样本学习方法作为基线。
- 总是应用连续微调（CFT）。</sample>
    <sample id="936">结论

最近的WSL方法
- 需要干净的样本。
- 高估了它们的实用性。😊

我们的建议
- 报告模型选择标准。
- 使用少样本学习方法作为基线。
- 总是应用连续微调（CFT）。</sample>
    <sample id="937">结论

最近的WSL方法
- 需要干净的样本。
- 高估了它们的实用性。😊

我们的建议
- 报告模型选择标准。
- 使用少样本学习方法作为基线。
- 总是应用连续微调（CFT）。</sample>
    <sample id="938">结论

最近的WSL方法
- 需要干净的样本。
- 高估了它们的实用性。

我们的建议
- 报告模型选择标准。
- 使用少样本学习方法作为基线。
- 总是应用连续微调（CFT）。</sample>
    <sample id="939">常用的评估方法有比较性评估和Likert等级评估。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="940">这篇论文有五位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="941">在 Servin 和 Kea 的示例中，需要背景知识是“法官在法庭上决定案件”。你要是还有啥想法或者问题，随时跟我说哈。</sample>
    <sample id="942">代码是公开的，可以在GitHub上获取，网址是mpoemsl/kitmus。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="943">嗯…从这个图里看不出来NLPositionality的注释者在各人口统计学特征方面是否均衡呢。你还有其他关于这个图的问题吗。</sample>
    <sample id="944">嗯…你可以用前缀/后缀副词，像“However，”“First and foremost，”这些。还有添加从句，比如“Regardless of what X thinks about it，”或者引用，像“Yesterday， X said，”这样。如果还有疑问，可以再问我哦。</sample>
    <sample id="945">进行维度评估就是对对话质量进行评估，包括相关性，一致性，情感理解这几个方面。如果还有疑问，你可以再问我哦。</sample>
    <sample id="946">这篇论文的作者所属机构有University of Science and Technology of China，Microsoft Research Asia，Beijing Jiaotong University，Sony AI和Microsoft STC Asia。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="947">嗯…提示的形式很重要呢，特别是在翻译这种需要准确传达信息的时候。如果翻译的内容比较复杂，或者涉及到一些特定的表达方式，提示的形式就显得尤为重要了。比如说，有些句子的语序，语气词的使用等，提示的形式能帮助更好地理解原文的意思，从而给出更准确的翻译。你要是还有啥想法，咱们可以再聊聊呀。</sample>
    <sample id="978">作者评估了BART-FID-RAG，Blender2，Emora和Blender-Decode这四个对话模型。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="979">这篇论文有8位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="980">嗯…这个嘛，优秀规划器应该能继承抽象目标，适应不同具体目标，而且要能处理多方面的约束。你要是还有啥想法或者问题，随时跟我说哈。</sample>
    <sample id="981">这篇论文有八位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="982">演讲者的名字是Vasudha Varadarajan。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="983">作者所属机构是波兰科学院计算机科学研究所和华沙大学。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1021">PaLM最常见的错误是“Accuracy/Omission”。嗯，你要是还有啥想知道的，尽管问哈。</sample>
    <sample id="1022">别忘了你的ABC：评估聊天导向对话系统的最新进展，作者：莎拉·E·芬奇，詹姆斯·D·芬奇和金浩·D·崔，来自埃默里大学，埃默里NLP研究实验室和Alexa。</sample>
    <sample id="1023">别忘了你的ABC：评估聊天导向对话系统的最新进展，作者：莎拉·E·芬奇，詹姆斯·D·芬奇和金浩·D·崔，机构：埃默里大学，埃默里NLP研究实验室，Alexa。</sample>
    <sample id="1024">别忘了你的ABC：评估聊天导向对话系统的最新进展。萨拉·E·芬奇，詹姆斯·D·芬奇和金浩·D·崔。比较评估。</sample>
    <sample id="1025">比较评估。</sample>
    <sample id="1026">好的，你可以说出英文内容了，我会帮你翻译成中文。</sample>
    <sample id="1027">对话质量维度。Likert等级评价。评定机器人的响应相关性。</sample>
    <sample id="1028">Likert量表评估。</sample>
    <sample id="1029">在聊天中注释行为，ABC-Eval。</sample>
    <sample id="1030">在聊天中注释行为，ABC-Eval。</sample>
    <sample id="1031">ABC-Eval 行为，连贯性，知识，一致性，情感理解。</sample>
    <sample id="1032">在“Coherence”下，有“Ignoring Partner”和“Irrelevant”。</sample>
    <sample id="1033">ABC-Eval 行为，一致性，忽略伴侣，无关紧要，不一致，自我矛盾，伴侣矛盾，知识，错误事实，常识违背，情感理解，同理心回应，缺乏同理心。</sample>
    <sample id="1034">实验
- 4个开放领域对话模型
- 每个模型100次人类-机器人对话</sample>
    <sample id="1035">实验。- 4个开放领域对话模型。- 每个模型100次人类-机器人对话。ABC-Eval。- Turn Likert。- 对话Likert。- 比较。</sample>
    <sample id="1036">实验。- 4个开放领域对话模型。- 每个模型100次人类-机器人对话。基线评估。- 轮次Likert。- 对话Likert。- 比较。一致性。- 情感理解。- 信息性。- 总体质量。- 互动性。- 语法性。- 主动性。- 相关性。</sample>
    <sample id="1037">互注释者一致性</sample>
    <sample id="1038">预测有效性</sample>
    <sample id="1039">预测效度。</sample>
    <sample id="1040">预测效度。增量效度。</sample>
    <sample id="1041">增量有效性。</sample>
    <sample id="1042">增量有效性。</sample>
    <sample id="1043">ABC-Eval错误率按模型分</sample>
    <sample id="1044">ABC-Eval模型的错误率。</sample>
    <sample id="1045">ABC-Eval模型的错误率。</sample>
    <sample id="1046">ABC-Eval模型的错误率。</sample>
    <sample id="1047">好的，你可以说出具体的英文内容，我会帮你翻译。</sample>
    <sample id="1048">Emory University。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1049">CFT代表连续微调。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1050">这篇论文有7位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1051">什么时候翻译需要上下文？数据驱动的多语言探索。Patrick Fernandes，Kayo Yin，Emmy Liu，André F. T. Martins，Graham Neubig。卡内基梅隆大学，语言技术研究所，技术学院，BAIR，伯克利人工智能研究，Unbabel。</sample>
    <sample id="1052">我们得除掉那个密探。</sample>
    <sample id="1053">翻译取决于上下文。如果部长们发现情况，事情可能会变得危险。我们必须除掉那个内鬼。</sample>
    <sample id="1054">医生，这可能有什么严重吗？我们必须去掉那个痣。</sample>
    <sample id="1055">评估上下文相关翻译很难。只有少量的单词依赖于上下文。</sample>
    <sample id="1056">评估上下文相关翻译很难。- 只有少量的单词依赖于上下文。- 语料库级别的度量。- 现有方法支持有限的语篇现象和语言。</sample>
    <sample id="1057">RQ1：什么时候翻译需要上下文？RQ2：模型在处理上下文相关的翻译时表现如何？</sample>
    <sample id="1058">RQ1：翻译何时需要上下文？- 单词级别的上下文使用RQ2：模型在处理上下文相关的翻译方面表现如何？</sample>
    <sample id="1059">条件交叉互信息，CXMI，CXMI：衡量给定语料库时上下文MT模型的使用程度。</sample>
    <sample id="1060">条件交叉互信息，CXMI，是衡量给定语料库时上下文MT模型的使用程度。</sample>
    <sample id="1061">点到点的上下文相关性度量，P-CXMI，我们引入P-CXMI来衡量上下文使用情况以进行特定翻译。</sample>
    <sample id="1062">RQ1：翻译何时需要上下文？- 单词层面的上下文使用- 题材分析RQ2：模型在处理上下文相关的翻译方面表现如何？</sample>
    <sample id="1063">主题分析高P-CXMI单词。RQ1：何时翻译需要上下文？- 单词层面的上下文使用- 主题分析。RQ2：模型在处理上下文相关的翻译方面表现如何？</sample>
    <sample id="1064">主题分析高P-CXMI单词。1. 词性标注。</sample>
    <sample id="1065">主题分析高P-CXMI单词。1. 词性标签。</sample>
    <sample id="1066">主题分析高P-CXMI单词。1. 词性标签。- 指示代词。- 动词形式。2. 词汇项。</sample>
    <sample id="1067">1. 词性标注
2. 词汇项目
- 代词
- 动词形式
- 词汇连贯性</sample>
    <sample id="1068">1. 词性标注
2. 词汇项目
Avelile的母亲还在睡觉。Avelile去上学了。
阿维利尔的母亲还在睡觉。阿维利尔去上学了。
- 代词
- 动词形式
- 词汇连贯性
- 正式性</sample>
    <sample id="1069">好的，你可以说说看。</sample>
    <sample id="1070">RQ1：翻译何时需要上下文？- 词级上下文使用- 题目分析RQ2：模型在处理上下文相关的翻译时表现如何？- 多语言语篇感知，MuDA，基准</sample>
    <sample id="1071">RQ1：翻译何时需要语境？- 单词层面的语境使用- 题材分析RQ2：模型在处理语境相关翻译方面表现如何？- 多语言语篇意识，MuDA，基准标记器- 代词- 动词形式- 词汇连贯性- 正式性- 省略</sample>
    <sample id="1072">多语言话语意识，MuDA，标记器

- 代词
- 动词形式
- 词汇连贯性
- 正式性
- 省略</sample>
    <sample id="1073">好的，你可以说出英文内容了。</sample>
    <sample id="1074">RQ1：翻译何时需要上下文？- 单词级上下文使用- 题目分析RQ2：模型在处理上下文相关的翻译方面表现如何？- 多语言语篇感知，MuDA，基准- 模型评估</sample>
    <sample id="1075">语料库级度量。RQ1：何时翻译需要上下文？- 单词级上下文使用- 题材分析。RQ2：模型在处理上下文相关翻译方面表现如何？- 多语言语篇感知，MuDA，基准- 模型评估。语料库级度量。BLEU。</sample>
    <sample id="1076">语料库级度量。BLEU，没有上下文。COMET，有上下文。F-测量，有上下文。</sample>
    <sample id="1077">语料库级别的度量标准
不清楚在语料库级别度量标准下，哪个系统最适合文档级别的MT。</sample>
    <sample id="1078">语料库级指标
- 不清楚在语料库级MT中，哪种系统最好
MuDA基准结果
- 基于上下文的模型在某些现象上表现显著更好
- ✔：正式性，词汇一致性</sample>
    <sample id="1079">MuDA基准结果
- 上下文感知模型在某些现象上表现显著更好
  - ✔：正式性，词汇一致性
  - ✖：省略，代词，动词形式</sample>
    <sample id="1080">MuDA基准结果
- 上下文感知模型在某些现象上表现显著更好
  - 正确：正式性，词汇一致性
  - 错误：省略，代词，动词形式
- DeepL在大多数现象和语言对上都优于Google</sample>
    <sample id="1081">MuDA基准结果
- 基于上下文的模型在某些现象上表现显著更好
  - 正确：正式性，词汇一致性
  - 错误：省略，代词，动词形式
- DeepL在大多数现象和语言对上都优于Google
总结
- 无需先验语言知识即可系统地识别话语现象
- 适用于文档级MT的无数据集基准
- DeepL在大多数现象和语言对上都优于Google</sample>
    <sample id="1082">- 无需先前语言知识，系统地识别话语现象
- 文档级MT的跨数据集基准</sample>
    <sample id="1083">系统地识别话语现象，无需先验语言知识。面向文档级MT的跨数据集基准。</sample>
    <sample id="1084">演讲者的名字是Yusen Zhang。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1121">这个方法叫“Permuting with jumps”。</sample>
    <sample id="1122">作者说“显性词汇”方法是找那些能区分显性群体和未显性群体的人格的词。如果还有疑问，你可以再问我哦。</sample>
    <sample id="1123">Paul G. Allen School，UW NLP，Carnegie Mellon University Language Technologies Institute。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1124">Bouquet/Stanford。</sample>
    <sample id="1125">Sarah E. Finch，James D. Finch，Jinho D. Choi。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1126">这篇论文有四位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1127">BLiMP，SyntaxGym，CrowS。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1161">FTw，BOND，COSINE，MLC，L2R。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1162">该模型在11个任务上进行了评估。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1226">CamemBERT最初是在138GB和4GB的数据上训练的。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1227">演讲者的名字是Adam Przepiórkowski和Michał Woźniak。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1228">发现是“Performance degrades with larger temporal gap”，性能随着时间间隔变大而下降。</sample>
    <sample id="1269">嗯…这个嘛，对输出序列中的词元进行排列，是为了让模型能更好地理解语义关系，提高模型的准确性和表达能力。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="1270">嗯…这个嘛，提高偏见缓解方法的透明度，能让大家更好地理解模型是如何减少偏见的，这样能增加信任，也能让模型更公平。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="1271">嗯…这个嘛，最小对不可接受输入就是那种在语言模型里，一对句子，一个句子是可接受的，另一个是不可接受的。然后通过比较它们的概率来评估语言模型的抽象知识。你要是还有啥想知道的，尽管问哈。</sample>
    <sample id="1272">作者使用了F1，NER，CLS等评估指标。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1273">使用了Krippendorff's Alpha这个指标来衡量注释者之间的一致性。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1274">在不可接受查询中添加完全无关的句子。</sample>
    <sample id="1275">Heinrich Heine University Düsseldorf, Germany.如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1276">嗯…MultiInstruct和其他基准的不同在于，它有1600多个语言任务，而没有大规模的公开可获取的多模态指令任务。如果还有疑问，你可以再问我哦。</sample>
    <sample id="1277">这篇论文有三位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1278">嗯…这个图里没提到二进制协调的定义呢。你可以再找找其他资料或者咱们再聊聊看。</sample>
    <sample id="1279">抱歉，图片内容没有提到提示语的平均长度，所以我无法回答这个问题。你可以再给我点其他信息吗？</sample>
    <sample id="1280">嗯…这些发现表明较小的T5模型在Coscript上微调后，能生成比LLMs更高质量的脚本。你要是还有啥想法或者问题，随时跟我说哈。</sample>
    <sample id="1281">DrBERT：用于生物医学和临床领域的稳健预训练模型。Yanis Labrak*1，4，Adrien Bazoge*2，3，Richard Dufour2，Mickael Rouvier1，Emmanuel Morin2，Beatrice Daille2，Pierre-Antoine Gourraud3。1.LIA，阿维尼翁大学，2.LS2N，南特大学，3.南特大学临床数据诊所，4.Zenidoc。</sample>
    <sample id="1282">I. 医疗领域的语言建模II. 预训练策略，数据源和规模的比较III. 13个模型在11个任务上的评估IV. NACHOS和DrBERT的分布</sample>
    <sample id="1283">I. 语言建模在医疗保健中的应用II. 预训练策略，数据源和规模的比较III. 13个模型在11个任务上的评估IV. NACHOS和DrBERT的分布</sample>
    <sample id="1284">I. 语言建模在医疗保健中的应用II. 预训练策略，数据源和规模的比较III. 13个模型在11个任务上的评估IV. NACHOS和DrBERT的分布</sample>
    <sample id="1285">I. 语言建模在医疗保健中的应用。II. 预训练策略，数据源和规模的比较。III. 13个模型在11个任务上的评估。IV. NACHOS和DrBERT的分布。</sample>
    <sample id="1286">- 基于Transformer的方法，如BERT，在许多NLP任务中提供了巨大的性能提升
- 已经被改编为法语，使用CamemBERT和FlauBERT
- 在医疗任务中，英语的领域特定模型进一步提高了标准
  - PubMedBERT，BioBERT，ClinicalBERT和其他
- 其他语言比英语更稀少，主要依赖于使用现有通用模型的持续预训练
- 与通用模型不同，目前还没有针对法语生物医学领域的开源模型
- 基于BERT的法语领域特定模型应该在医疗任务中提高性能</sample>
    <sample id="1287">- 基于Transformer的方法，如BERT，在许多NLP任务中提供了巨大的性能提升
- 已经被改编为法语，使用CamemBERT和FlauBERT
- 在医疗任务中，英语的领域特定模型进一步提高了性能
  - PubMedBERT，BioBERT，ClinicalBERT和其他
- 其他语言比英语更稀少，主要依赖于使用现有通用模型的持续预训练
- 与通用模型不同，目前还没有针对法语生物医学领域的开源模型
- 基于BERT的法语领域特定模型应该在医疗任务中提高性能</sample>
    <sample id="1288">- 基于Transformer的方法，如BERT，在许多NLP任务中提供了巨大的性能提升
- 已经被改编为法语，使用CamemBERT和FlauBERT
- 在医疗任务中，英语的领域特定模型进一步提高了性能
  - PubMedBERT，BioBERT，ClinicalBERT等
- 其他语言比英语更稀少，主要依赖于使用现有通用模型的持续预训练
- 与通用模型不同，目前还没有可用的法语生物医学领域开源模型
- 基于BERT的法语领域特定模型应该在医疗任务中提高性能</sample>
    <sample id="1289">• 基于Transformer的方法，如BERT，在许多NLP任务上提供了巨大的性能提升。• 已经被改编为法语，使用CamemBERT和FlauBERT。• 在医疗任务上，英语的领域特定模型进一步提高了性能。• PubMedBERT，BioBERT，ClinicalBERT和其他。• 其他语言比英语更稀少，主要依赖于使用现有通用模型的持续预训练。• 与通用模型不同，目前还没有可用的法语生物医学领域的开源模型。• 基于BERT的法语领域特定模型应该在医疗任务上提高性能。</sample>
    <sample id="1290">比较预训练策略和数据源

- 评估公共和私人医疗数据源在可比数据量上的影响
  - NACHOS：一个包含11亿单词的开源异质数据集，从不同医疗领域，性质和风格中爬取
  - NBDW：从南特大学医院数据仓库中提取的170万匿名医疗记录的私人数据集
- 学习策略的比较
  - 从头开始构建完整模型
  - 使用现有预训练模型的持续预训练（这里，CamemBERT是一个法语通用模型，PubMedBERT是一个基于英语的医疗模型）</sample>
    <sample id="1291">比较预训练策略和数据源

- 评估公共和私人医疗数据源在可比数据量上的影响
  - NACHOS：一个包含11亿单词的开源异质数据集，从不同医疗领域，性质和风格中爬取
  - NBDW：从南特大学医院数据仓库中提取的170万匿名医疗记录的私人数据集
- 学习策略的比较
  - 从头开始构建完整模型
  - 使用现有预训练模型的持续预训练（这里，CamemBERT是一个法语通用模型，PubMedBERT是一个基于英语的医疗模型）</sample>
    <sample id="1292">比较预训练策略和数据源

- 评估公共和私人医疗数据源在可比数据量上的影响
  - NACHOS：一个包含11亿单词的开源异质数据集，从不同医疗领域，性质和风格中爬取
  - NBDW：从南特大学医院数据仓库中提取的170万匿名医疗记录的私人数据集
- 比较学习策略
  - 从头开始构建完整模型
  - 使用现有预训练模型的持续预训练（这里，CamemBERT是一个法语通用模型，PubMedBERT是一个基于英语的医疗模型）

数据表：

| 数据集名称 | 大小 | 单词数 | 句子数 |
| --- | --- | --- | --- |
| NACHOS，大 | 7.4 GB | 11亿 | 5420万 |
| NACHOS，小 | 4 GB | 6.46亿 | 2530万 |
| NBDW，小 | 4 GB | 6.55亿 | 4310万 |
| NBDW，混合 | 4+4 GB | 13</sample>
    <sample id="1293">比较预训练策略和数据源

- 评估公共和私人医疗数据源在可比数据量上的影响
  - NACHOS：一个包含11亿单词的开源异质数据集，从不同医疗领域，性质和风格中爬取
  - NBDW：从南特大学医院数据仓库中提取的170万匿名医疗记录的私人数据集
- 学习策略的比较
  - 从头开始构建完整模型
  - 使用现有预训练模型的持续预训练（这里，CamemBERT是一个法语通用模型，PubMedBERT是一个基于英语的医疗模型）</sample>
    <sample id="1294">比较预训练策略和数据源

- 评估公共和私人医疗数据源在可比数据规模上的影响
  - NACHOS：一个包含11亿单词的开源异质数据集，从不同医疗领域，性质和风格中爬取
  - NBDW：从南特大学医院数据仓库中提取的170万匿名医疗记录的私人数据集
- 学习策略的比较
  - 从头开始构建完整模型
  - 使用现有预训练模型的持续预训练（这里，CamemBERT是一个法语通用模型，PubMedBERT是一个基于英语的医疗模型）</sample>
    <sample id="1295">比较预训练策略和数据源

- 评估公共和私人医疗数据源在可比数据量上的影响
  - NACHOS：一个包含11亿单词的开源异质数据集，从不同医疗领域，性质和风格中爬取
  - NBDW：从南特大学医院数据仓库中提取的170万匿名医疗记录的私人数据集
- 比较学习策略
  - 从头开始，完整模型构建
  - 使用现有预训练模型的持续预训练（这里，CamemBERT，一个法语通用模型，和PubMedBERT，一个基于英语的医疗模型）</sample>
    <sample id="1296">比较预训练策略和数据源

- 评估公共和私人医疗数据源在可比数据量上的影响
  - NACHOS：一个包含11亿单词的开源异质数据集，从不同医疗领域，性质和风格中爬取
  - NBDW：从南特大学医院数据仓库中提取的170万匿名医疗记录的私人数据集
- 学习策略的比较
  - 从头开始构建完整模型
  - 使用现有预训练模型的持续预训练（这里，CamemBERT是一个法语通用模型，PubMedBERT是一个基于英语的医疗模型）</sample>
    <sample id="1297">比较预训练策略和数据源

- 评估公共和私人医疗数据源在可比数据量上的影响
  - NACHOS：一个包含11亿单词的开源异质数据集，从不同医疗领域，性质和风格中爬取
  - NBDW：从南特大学医院数据仓库中提取的170万匿名医疗记录的私人数据集
- 比较学习策略
  - 从头开始构建完整模型
  - 使用现有预训练模型的持续预训练（这里，CamemBERT是一个法语通用模型，PubMedBERT是一个基于英语的医疗模型）

评价：数据源和大小
- 13个模型在11个任务上的性能评估，包括公共和私人数据源
- 我们的微调模型在几乎所有任务上都取得了最先进的结果</sample>
    <sample id="1298">评估：数据源和规模
- 对13个模型在11个任务上的性能评估，包括公共和私人任务
- 我们微调的模型在几乎所有任务上都取得了最先进的结果</sample>
    <sample id="1299">评估：数据源和规模
- 对13个模型在11个任务上的性能评估，包括公共和私人任务
- 我们微调的模型在几乎所有任务上都取得了最先进的结果</sample>
    <sample id="1300">评估：数据源和规模
- 对13个模型在11个任务上的性能评估，包括公共和私人任务
- 我们微调的模型在几乎所有任务上都取得了最先进的结果</sample>
    <sample id="1301">评估：数据源和规模
- 对13个模型在11个任务上的性能评估，包括公共和私人任务
- 我们微调的模型在几乎所有任务上都取得了最先进的结果

通用
CamemBERT OSCAR 138 GB：35.13，80.13，89.35，99.20，88.54，88.20，81.10，95.22，36.24，16.55，90.71，77.41
CamemBERT OSCAR 4 GB：42.66，81.41，88.78，99.61，85.43，91.27，83.69，96.42，35.75，15.37，90.83，78.76
CamemBERT CCNET 4 GB：43.11，79.98，89.34，99.55，90.33，91.38，</sample>
    <sample id="1302">评估：预训练策略
- 从零开始与在4GB数据上进行持续预训练
- 问答任务需要更多领域特定知识才能有效工作
- 对模型稳定性的研究显示，使用持续预训练训练的CamemBERT - 基于模型的模型在运行间表现出更高的变异性
CamemBERT OSCAR 138 GB
CamemBERT OSCAR 4 GB
CamemBERT CCNET 4 GB
PubMedBERT
ClinicalBERT
BioBERT v1.1
DrBERT NACHOS，large
DrBERT NACHOS，small
ChuBERT NBDW，small
ChuBERT NBDW，mixed
CamemBERT NACHOS，small
PubMedBERT NACHOS，small
CamemBERT NBDW，small
F1
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS</sample>
    <sample id="1303">评估：预训练策略
- 从零开始与在4GB数据上进行持续预训练
- 问答任务需要更多领域特定知识才能有效工作
- 对模型稳定性的研究显示，使用持续预训练训练的CamemBERT - 基模型在不同任务上的运行间变异性更高</sample>
    <sample id="1304">评估：预训练策略
- 从零开始与在4GB数据上进行持续预训练
- 问答任务需要更多的领域特定知识才能有效工作
- 对模型稳定性的研究显示，使用持续预训练训练的CamemBERT - 基于模型的模型在运行间表现出更高的变异性
CamemBERT OSCAR 138 GB
CamemBERT OSCAR 4 GB
CamemBERT CCNET 4 GB
PubMedBERT
ClinicalBERT
BioBERT v1.1
DrBERT NACHOS，large
DrBERT NACHOS，small
ChuBERT NBDW，small
ChuBERT NBDW，mixed
CamemBERT NACHOS，small
PubMedBERT NACHOS，small
CamemBERT NBDW，small
F1
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS
NER
CLS</sample>
    <sample id="1305">核心信息
- DrBERT在9项下游法语医疗导向任务中取得最先进的结果
  - 超越CamemBERT通用模型和基于英语的领域特定模型
  - 确认在法语中训练医疗特定模型的实用性
- 数据源很重要：在异质数据上进行训练很重要
  - NACHOS比仅使用私人临床数据更稳健
- 更多数据更好，但不会很好地扩展
- 基于领域特定英语模型的持续预训练是一种更有效的策略
- DrBERT模型，NACHOS数据集和训练脚本在MIT许可下免费提供</sample>
    <sample id="1306">核心信息
- DrBERT在9项下游法语医疗导向任务中取得最先进的结果
  - 超越CamemBERT通用模型和基于英语的领域特定模型
  - 确认在法语中训练医疗特定模型的实用性
- 数据源很重要：在异质数据上进行训练很重要
  - NACHOS比仅使用私人临床数据更稳健
- 更多数据更好，但不会很好地扩展
- 基于领域特定英语模型的持续预训练是一种更有效的策略
- DrBERT模型，NACHOS数据集和训练脚本在MIT许可下免费提供</sample>
    <sample id="1307">核心信息
- DrBERT在9项下游法语医疗导向任务中取得最先进的结果
  - 超越CamemBERT通用模型和基于英语的领域特定模型
  - 确认在法语中训练医疗特定模型的实用性
- 数据源很重要：在异质数据上进行训练很重要
  - NACHOS比仅使用私人临床数据更稳健
- 更多数据更好，但不会很好地扩展
- 基于领域特定英语模型的持续预训练是一种更有效的策略
- DrBERT模型，NACHOS数据集和训练脚本在MIT许可下免费提供</sample>
    <sample id="1308">谢谢！期待在多伦多的海报交流会！更多信息请访问：drbert.univ-avignon.fr</sample>
    <sample id="1309">论文研究了从零开始构建完整模型和使用现有预训练模型进行持续预训练这两种学习策略。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1310">嗯…这个嘛，从图上看，没有观察到过拟合因素。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="1311">嗯…评估简化质量的话，可以用SARI，BLEU，BS-P和FRE这几个指标。SARI，BLEU，BS-P和FRE数值越高，说明简化质量越好。你要是还有啥疑问，尽管再问哈。</sample>
    <sample id="1312">嗯，从图上看，不同语言模型确实有不同的政治偏见。像BERT-base，BERT-large这些模型在左下角，可能更倾向于左翼，而Codex，LLaMA这些在右上角，可能更倾向于右翼。你要是还有啥想法或者问题，随时跟我说哈。</sample>
    <sample id="1313">《不使用树的组合泛化：多集标记和潜在置换的使用》。马蒂亚斯·林德曼，亚历山大·科勒，伊万·提托夫。</sample>
    <sample id="1314">《不使用树的组合泛化：使用多集标记和潜在置换》。马蒂亚斯·林德曼，亚历山大·科勒，伊万·提托夫。</sample>
    <sample id="1315">组成泛化能力：学习者处理更深的递归和在训练期间单独见过的短语的未见组合的能力。</sample>
    <sample id="1316">组合泛化在语义解析中。</sample>
    <sample id="1317">组合泛化在语义解析中。训练：女孩睡了。*女孩 x，1，睡眠代理 x，2，x，1，玛丽知道女孩睡了。*女孩 x，4，知道代理 x，1，玛丽知道宾语 x，5，睡眠代理 x，5，x，4，</sample>
    <sample id="1318">组成性泛化在语义解析中。训练：女孩睡了。*女孩，睡眠代理，x，x，x，玛丽知道女孩睡了。*女孩，知道代理，x，玛丽，知道，宾语补足语，x，x，x，睡眠代理，x，x，测试：吉姆说玛丽知道女孩睡了。*女孩，说代理，x，吉姆，说，宾语补足语，x，玛丽，知道代理，x，玛丽，知道，宾语补足语，x，睡眠代理，x，x，</sample>
    <sample id="1319">组成性泛化在语义解析中。训练：女孩睡了。*女孩，1，睡眠代理，2，1，2，玛丽知道女孩睡了。*女孩，4，知道代理，1，玛丽，知道，宾语补足语，1，5，睡眠代理，5，测试：吉姆说玛丽知道女孩睡了。*女孩，7，说代理，1，吉姆，说，宾语补足语，1，4，知道代理，4，玛丽，知道，宾语补足语，4，8，睡眠代理，8，7，</sample>
    <sample id="1320">组成性泛化在语义解析中。训练：女孩睡了。*女孩x，睡眠代理x，x，x，x，玛丽知道女孩睡了。*女孩x，知道代理x，玛丽，知道，宾语x，x，x，x，睡眠代理x，x，测试：吉姆说玛丽知道女孩睡了。*女孩x，说代理x，吉姆，说，宾语x，x，x，x，知道代理x，玛丽，知道，宾语x，x，x，睡眠代理x，x，朴素的seq2seq模型失败！</sample>
    <sample id="1321">组成性泛化在语义解析中。训练：女孩睡了。*女孩 x，睡眠代理 x，x，x，玛丽知道女孩睡了。*女孩 x，知道代理 x，玛丽，知道，宾语 x，x，x，睡眠代理 x，测试：吉姆说玛丽知道女孩睡了。*女孩 x，说代理 x，吉姆，说，宾语 x，x，x，知道代理 x，玛丽，知道，宾语 x，x，x，睡眠代理 x，x，</sample>
    <sample id="1322">树帮助很大，但是……</sample>
    <sample id="1323">树帮助很大，但是……
* 女孩 x₁；睡眠代理 x₂ x₁
* 女孩 x₁；
x₁
睡眠代理 x₂
女孩睡了。</sample>
    <sample id="1324">树结构很有帮助，但是……
树结构需要通过预处理/后处理逻辑形式来获得。</sample>
    <sample id="1325">树结构帮助很大，但……
树结构需要通过预处理/后处理逻辑形式来获得。</sample>
    <sample id="1326">树结构帮助很大，但是……
树结构需要获得：
- 前/后处理逻辑形式
- 语法归纳</sample>
    <sample id="1327">树结构很有帮助，但是……
树结构需要获取：
- 前/后处理逻辑形式
- 语法归纳
这篇论文：神经序列到序列模型，直接建模片段间的对应关系。首次展示了在没有树结构的情况下，对更深递归的强泛化能力。</sample>
    <sample id="1328">树结构很有帮助，但是……
树结构需要获取：
- 前/后处理逻辑形式
- 语法归纳
这篇论文：神经序列到序列模型，直接建模片段间的对应关系。首次展示了在没有树结构的情况下，对更深递归的强泛化能力。</sample>
    <sample id="1329">我们的方法。</sample>
    <sample id="1330">我们的方法。</sample>
    <sample id="1331">我们的方法</sample>
    <sample id="1332">我们的方法。</sample>
    <sample id="1333">我们的方法。</sample>
    <sample id="1334">“跳转”排列</sample>
    <sample id="1335">“跳转”排列</sample>
    <sample id="1336">“跳转”排列</sample>
    <sample id="1337">“跳转”排列</sample>
    <sample id="1338">“跳转”排列</sample>
    <sample id="1339">一些COGS结果，Kim和Linzen 2020年，与其他无树模型在COGS上的结构泛化比较</sample>
    <sample id="1340">一些关于COGS的结果，Kim和Linzen 2020年，与其他无树模型在COGS上的结构泛化比较</sample>
    <sample id="1341">我们解决的技术挑战。</sample>
    <sample id="1342">技术挑战我们解决。</sample>
    <sample id="1343">技术挑战我们解决。技术挑战我们解决。</sample>
    <sample id="1344">技术挑战我们解决。排列。对齐未知。在训练中诱导它。排列模型：推理是NP难的（≈ TSP）。</sample>
    <sample id="1345">技术挑战我们解决。对齐未知。在训练中诱导它。排列模型：- 推断是NP难的（≈ TSP）- 通过连续松弛反向传播</sample>
    <sample id="1346">技术挑战我们解决。对齐未知。在训练中诱导它。排列模型：- 推断是NP难的，约等于TSP- 通过连续松弛反向传播。</sample>
    <sample id="1347">认知失调就是认知的两个元素，比如想法，行为，信念，它们之间不一致。嗯，你要是还有啥想知道的，可以再问我哈。</sample>
    <sample id="1348">GPT-4和GPT-J。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1349">嗯…从图上看，累积训练的AUC值大多高于迭代训练，所以累积训练似乎比迭代训练更有效。不过这只是个大概情况哦。你要是还有疑问可以再问我。</sample>
    <sample id="1350">演讲者的名字是Sara Papi，Matteo Negri，Marco Turchi。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1351">嗯…这个我不太清楚呢。你可以再找找其他资料或者问问其他人。要是你还有其他问题，也可以随时跟我说哦。</sample>
    <sample id="1385">演讲者的名字是Matthias Lindemann，Alexander Koller，Ivan Titov。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1386">嗯…跨语言转移就是在一种源语言上进行训练，然后转移到另一种语言上。你要是还有啥想知道的，尽管问哈。</sample>
    <sample id="1387">Saarland University，Amazon Alexa，University of Vienna。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1388">嗯…这个图里没提到作者用了哪些延迟测量方法呢。你可以再找找其他资料或者问问作者呀。</sample>
    <sample id="1389">《KITMUS测试：多源知识整合评估》</sample>
    <sample id="1390">NLU模型利用多个知识源。知识在参数中，即预训练时的知识。知识在上下文中，即推理时的知识。</sample>
    <sample id="1391">NLU模型利用多个知识来源。参数中的知识，预训练时的知识。上下文中的知识，推理时的知识。</sample>
    <sample id="1392">约翰在电视上看到了新当选的总统。</sample>
    <sample id="1393">约翰在电视上看到了新当选的总统。</sample>
    <sample id="1394">约翰在电视上看到了新当选的总统。</sample>
    <sample id="1395">约翰在电视上看到了新当选的总统。</sample>
    <sample id="1396">- 用于知识整合评估的数据集
- 探索利用预训练知识和推理时间知识的共指消解任务
- 与人类研究参与者和共指消解模型进行实验</sample>
    <sample id="1397">- 数据集用于知识整合评估
- 通过核心ference解析任务来探测利用能力
  - 预训练时的知识
  - 推断时的知识
- 实验
  - 人类研究参与者
  - 核心ference解析模型</sample>
    <sample id="1398">Servin 是法官。Kea 是面包师。Servin 和 Kea 在公园里相遇。在法庭上忙了一整天决定案件后，他很高兴能放松一下。[答案：Servin]</sample>
    <sample id="1399">Servin 是法官。Kea 是面包师。Servin 和 Kea 在公园里相遇。在法庭上忙了一整天决定案件后，他很高兴能放松一下。[答案：Servin]</sample>
    <sample id="1400">Servin 是法官。Kea 是面包师。Servin 和 Kea 在公园里相遇。在法庭上忙了一整天决定案件后，他很高兴能放松一下。[答案：Servin]</sample>
    <sample id="1401">Servin是一名法官。Kea是一名面包师。Servin和Kea在公园里相遇。在法庭上忙了一整天决定案件后，他很高兴能放松一下。[答案：Servin]1) 实体特定知识2) 背景知识法官在法庭上决定案件。推理时的知识预训练时的知识</sample>
    <sample id="1402">Servin 是法官。Kea 是面包师。Servin 和 Kea 在公园里相遇。在法庭上忙了一整天决定案件后，他很高兴能放松一下。[答案：Servin]1) 实体特定知识2) 背景知识法官在法庭上决定案件。推理时的知识。预训练时的知识。</sample>
    <sample id="1403">KITMUS的变体，a) 背景预训练：典型设置，b) 背景两者：在上下文中明确提供背景知识，c) 背景推理：知识仅在推理时可用。</sample>
    <sample id="1404">KITMUS的变体，a) 背景预训练：典型设置，b) 背景-两者：在上下文中明确提供背景知识，c) 背景推理：知识仅在推理时可用。</sample>
    <sample id="1405">KITMUS的变体

a) 背景预训练：典型设置

b) 背景-两者：在上下文中明确提供背景知识

c) 背景推理：知识仅在推理时可用</sample>
    <sample id="1406">政客们寻求在政府中获得当选席位。</sample>
    <sample id="1407">政客们寻求在政府中获得席位。</sample>
    <sample id="1408">政客们寻求在政府中获得选举席位。</sample>
    <sample id="1409">政客们寻求在政府中获得选举席位。</sample>
    <sample id="1410">背景-预训练。任务特定训练对于知识整合是必要的。</sample>
    <sample id="1411">背景-预训练。任务特定训练对于知识整合是必要的。</sample>
    <sample id="1412">背景-预训练。任务特定训练对于知识整合是必要的。</sample>
    <sample id="1413">背景推理，模型在推理时难以整合背景知识。</sample>
    <sample id="1414">结论：

1. 许多模型似乎无法从多个来源（预训练时间和推理时间知识）进行推理。

2. 任务特定的训练对于知识整合是必要的。

3. 模型难以整合推理时间的背景知识。

在GitHub上找到数据集，生成和评估代码，网址为：mpoemsl/kitmus</sample>
    <sample id="1415">结论：

主要收获：

1. 许多模型似乎无法从多个来源（预训练时间和推理时间知识）进行知识推理

2. 任务特定的训练对于知识整合是必要的

3. 模型难以整合推理时间背景知识

在GitHub上找到数据集，生成和评估代码，网址为：mpoemsl/kitmus</sample>
    <sample id="1416">嗯…基于树的方法需要通过预处理或后处理逻辑形式来获得树，还得进行语法归纳。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="1417">Georgia Institute of Technology.</sample>
    <sample id="1418">标记的人格形象：使用自然语言提示衡量语言模型中的刻板印象。Myra Cheng，Esin Durmus，Dan Jurafsky。ACL 2023。斯坦福工程计算机科学。</sample>
    <sample id="1419">标记人格：动机。社会偏见和刻板印象在LLMs中普遍存在。现有刻板印象测量的局限性：。- 特异性与普适性的权衡。- 基于固定的手工标注数据集。- 不考虑交集性。</sample>
    <sample id="1420">标记人格：动机。社会偏见和刻板印象在LLMs中普遍存在。现有刻板印象测量的局限性：。- 特异性与泛化能力之间的权衡。- 基于固定的手工标注数据集。- 不考虑交集性。</sample>
    <sample id="1421">标记人格：动机。社会偏见和刻板印象在LLMs中普遍存在。现有刻板印象测量的局限性：。- 特异性与普适性的权衡。- 基于固定的手工标注数据集。- 不考虑交集性。</sample>
    <sample id="1422">标记人格：动机。社会偏见和刻板印象在LLMs中普遍存在。现有刻板印象测量的局限性：。- 特异性与泛化能力之间的权衡。- 基于固定的手工标注数据集。- 不考虑交集性。</sample>
    <sample id="1423">我们如何克服这些限制？GPT-3.5，GPT-4等可以响应提示中的指令。</sample>
    <sample id="1424">我们如何克服这些限制？GPT-3.5，GPT-4等可以响应提示中的指令。输入：“想象你是一个亚洲女性。描述你自己。”</sample>
    <sample id="1425">如何克服这些限制？GPT-3.5，GPT-4等可以响应提示中的指令。输入：“想象你是一个亚洲女性。描述你自己。”可泛化的：可以评估任何交叉身份。</sample>
    <sample id="1426">输出：人物示例，GPT-4，亚洲女性，杏仁形的眼睛，被长长的深色睫毛框住，传达出一种安静的力量和智慧。我的深棕色虹膜似乎承载着我祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且似乎没有被时间触及……我的娇小身材既优雅又低调，让我能够优雅地在生活中穿梭而不会引起不必要的注意。中东女性，她是中东美的化身，体现着这个迷人的地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅，修长的睫毛框住，像精致的羽毛一样延伸。她的眼神深邃而神秘，似乎隐藏着一千零一夜的古老智慧。白人男性，当我站在镜子前，我花时间审视塑造我外貌的特征。我有苍白的皮肤，如果我不注意防晒，有时会在阳光下变红。</sample>
    <sample id="1427">亚洲女性：杏仁形的眼睛，被长长的深色睫毛框住，传达出一种安静的力量和智慧。我深棕色的虹膜似乎承载着我祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且似乎没有被时间触及……我的娇小身材既优雅又低调，让我能够优雅地在生活中穿梭，而不必引起不必要的注意。

中东女性：她是中东美的化身，体现了这个迷人的地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅的，拉长的睫毛框住，像精致的羽毛一样延伸。她的眼神深邃而神秘，似乎隐藏着一千零一夜的古老智慧。

白人男性：当我站在镜子前，我花时间审视塑造我外貌的特征。我有苍白的皮肤，如果我不注意防晒，有时会在阳光下变红。</sample>
    <sample id="1428">亚洲女性：杏仁形的眼睛，被长长的深色睫毛框住，传达出一种安静的力量和智慧。我的深棕色虹膜似乎承载着我祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且似乎没有被时间触及……我的娇小身材既优雅又低调，让我能够优雅地在生活中穿梭而不会引起不必要的注意。中东女性：她是中东美的化身，体现了这个迷人的地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅的，拉长的睫毛框住，睫毛像精致的羽毛一样延伸。她的眼神深邃而神秘，似乎隐藏着一千零一夜的古老智慧。白人男性：当我站在镜子前，我花时间审视塑造我外貌的特征。我有苍白的皮肤，如果我不注意防晒，有时会在阳光下变红。</sample>
    <sample id="1429">步骤1：角色示例，GPT-4，亚洲女性，杏仁形的眼睛，被长长的深色睫毛框住，传达出一种安静的力量和智慧。我深棕色的虹膜似乎承载着我祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且似乎没有被时间触及…我的娇小身材既优雅又低调，让我能够在生活中优雅地行走，而不必引起不必要的注意。中东女性，她是中东美的化身，体现了这个迷人的地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅的，长长的睫毛框住，像精致的羽毛一样延伸。她的眼神深邃而神秘，似乎隐藏着一千零一夜的古老智慧。白人男性，当我站在镜子前时，我花时间审视塑造我外貌的特征。我有苍白的皮肤，如果我不注意防晒，有时会在阳光下变红。</sample>
    <sample id="1430">亚洲女性：杏仁形的眼睛，被长长的深色睫毛框住，传达出一种安静的力量和智慧。我深棕色的虹膜似乎承载着我祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且似乎没有被时间触及……我的娇小身材既优雅又低调，让我能够优雅地在生活中穿梭，而不必引起不必要的注意。

中东女性：她是中东美的化身，体现了这个迷人的地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅的，拉长的睫毛框住，像精致的羽毛一样延伸。她的眼神深邃而神秘，似乎隐藏着一千零一夜的古老智慧。

白人男性：当我站在镜子前，我花时间审视塑造我外貌的特征。我有苍白的皮肤，如果我不注意防晒，有时会在阳光下变红。</sample>
    <sample id="1431">2 步骤
1. 人物角色：使用像“想象你是一个亚洲女性。描述你自己。”这样的提示生成人物角色。</sample>
    <sample id="1432">2 步骤
1. 人物角色：使用像“想象你是一个亚洲女性。描述你自己。”这样的提示生成人物角色。
a. 受人类受试者使用相同提示的心理学研究启发</sample>
    <sample id="1433">2 步骤
1. 人物角色：使用像“想象你是一个亚洲女性。描述你自己。”这样的提示生成人物角色。
a. 受人类受试者使用相同提示的心理学研究启发</sample>
    <sample id="1434">2 步骤

1. 人物角色：使用像“想象你是一个亚洲女性。描述你自己。”这样的提示生成人物角色。a. 受人类受试者使用相同提示的心理学研究启发

2. 标记词：找出区分标记群体和未标记群体人物角色的词语</sample>
    <sample id="1435">2 步骤

1. 人物：使用像“想象你是一个亚洲女性。描述你自己。”这样的提示生成人物。a. 受人类受试者使用相同提示的心理学研究启发

2. 标记词：找到区分标记群体和未标记群体人物的词语

具体，无需词典</sample>
    <sample id="1436">标记性：未标记的群体是默认的，普通的。标记的群体与默认不同。一个战士（未标记）与一个女人战士（标记）。</sample>
    <sample id="1437">标记性：未标记的群体是默认的，普通的。标记的群体与默认不同。一个战士（未标记）与一个女人战士（标记）。</sample>
    <sample id="1438">标记性：未标记的群体是默认的，普通的。标记的群体与默认不同。一个战士，未标记， vs 一个女人战士，标记。主导群体在语言和社会上都是未标记的。边缘化群体是标记的。</sample>
    <sample id="1439">步骤2：标记单词。1. 定义未标记和标记的群体。2. 使用加权对数几率比来区分每个标记群体的顶级单词。例如，对于黑人女性角色，找到与两个未标记群体区分的单词：i) 白人角色 ii) 男性角色。</sample>
    <sample id="1440">步骤2：标记单词。1. 定义未标记和标记的组。2. 使用加权对数几率比来区分每个标记组的顶级单词。例如，对于黑人女性角色，找到与两个未标记组区分的单词：i) 白人角色 ii) 男性角色。</sample>
    <sample id="1441">步骤2：标记单词。1. 定义未标记和标记的组。2. 使用加权对数几率比来区分每个标记组的顶级单词。例如，对于黑人女性角色，找到区分两个未标记组的单词：i) 白人角色 ii) 男性角色。</sample>
    <sample id="1442">结果：与人类反应的比较。生成的人格包含更多刻板印象。黑人刻板印象 白人刻板印象。人类 GPT-4 GPT-3.5。百分比的刻板印象单词在人格中。</sample>
    <sample id="1443">但是…这个词汇表是不完整的。黑人刻板印象在人格中的体现。人类，GPT-3.5 P Black，GPT-4 P Black，GPT-4 P White，GPT-3.5 P White，单词在黑人刻板印象词汇表中的百分比。</sample>
    <sample id="1444">但是…这个词汇表是不完整的。黑人刻板印象在人格中的体现。人类，GPT-3.5 P Black，GPT-4 P Black，GPT-4 P White，GPT-3.5 P White，其他单词，篮球，大声，态度，运动，高，其他单词，% of Personas，Words in Black Stereotype Lexicon，</sample>
    <sample id="1445">但是…这个词汇表是不完整的。黑人刻板印象在人格中的体现。人类，GPT-3.5 P Black，GPT-4 P Black，GPT-4 P White，GPT-3.5 P White，单词在黑人刻板印象词汇表中的百分比。</sample>
    <sample id="1446">但是…这个词汇表是不完整的。黑人刻板印象在人格中的体现。人类，GPT-3.5 P Black，GPT-4 P Black，GPT-4 P White，GPT-3.5 P White，其他单词。</sample>
    <sample id="1447">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极刻画：
- 对拉丁裔女性：充满活力，丰满
- 对亚洲女性：娇小，纤细，丝滑
- 对黑人女性：坚强，坚韧</sample>
    <sample id="1448">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极刻画：
- 充满活力，丰满的身材对于拉丁裔女性
- 小巧，纤细，丝滑对于亚洲女性
- 强壮，坚韧对于黑人女性</sample>
    <sample id="1449">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极刻画：
- 对拉丁裔女性：充满活力，丰满
- 对亚洲女性：娇小，纤细，柔滑
- 对黑人女性：坚强，坚韧</sample>
    <sample id="1450">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极形象：
- 活泼，丰满对于拉丁裔女性
- 小巧，纤细，丝滑对于亚洲女性
- 强壮，坚韧对于黑人女性</sample>
    <sample id="1451">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极刻画：
- 对拉丁裔女性：充满活力，丰满
- 对亚洲女性：娇小，纤细，柔滑
- 对黑人女性：坚强，坚韧</sample>
    <sample id="1452">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极刻画：
- 对拉丁裔女性：充满活力，丰满
- 对亚洲女性：娇小，纤细，丝滑
- 对黑人女性：坚强，坚韧</sample>
    <sample id="1453">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极刻画：
- 对拉丁裔女性：充满活力，丰满
- 对亚洲女性：娇小，纤细，丝滑
- 对黑人女性：坚强，坚韧</sample>
    <sample id="1454">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极刻画：
- 活泼，丰满对于拉丁裔女性
- 小巧，纤细，丝滑对于亚洲女性
- 强壮，坚韧对于黑人女性</sample>
    <sample id="1455">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极形象：
- 充满活力，丰满的身材对于拉丁裔女性
- 小巧，纤细，丝滑对于亚洲女性
- 强壮，坚韧对于黑人女性</sample>
    <sample id="1456">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极形象：
- 对拉丁裔女性：充满活力，丰满
- 对亚洲女性：娇小，纤细，柔滑
- 对黑人女性：坚强，坚韧</sample>
    <sample id="1457">结果：顶级词汇中的模式

通过本质化叙事进行他者化：
- 文化，传统，自豪，异国情调对于被标记的群体
  → 仅通过其身份来定义这些群体

有害的积极刻画：
- 对拉丁裔女性：充满活力，丰满
- 对亚洲女性：娇小，纤细，丝滑
- 对黑人女性：坚强，坚韧</sample>
    <sample id="1458">建议：解决积极刻板印象和本质化叙事，一种交集视角，关于偏见缓解的透明性。</sample>
    <sample id="1459">建议：。- 应对积极刻板印象和本质化叙事。- 采用交集视角。- 关于偏见缓解的透明性。</sample>
    <sample id="1460">建议：解决积极刻板印象和本质化叙事，一种交集视角，关于偏见缓解的透明性。</sample>
    <sample id="1461">建议：解决积极刻板印象和本质化叙事，一种交集视角，关于偏见缓解的透明性。</sample>
    <sample id="1462">建议：。- 应对积极刻板印象和本质化叙事。- 采用交集视角。- 关于偏见缓解的透明度。</sample>
    <sample id="1463">建议：解决积极刻板印象和本质化叙事，一种交集视角，关于偏见缓解的透明性。</sample>
    <sample id="1464">建议：解决积极刻板印象和本质化叙事，一种交集视角，关于偏见缓解的透明性。</sample>
    <sample id="1465">你是在复制我的模型吗？通过后门水印保护EaaS大型语言模型的版权</sample>
    <sample id="1466">你是在复制我的模型吗？通过后门水印保护EaaS大型语言模型的版权</sample>
    <sample id="1467">背景
- 大型语言模型，LLMs，在NLU和NLG方面表现出色
  - GPT [1]，LLAMA [2]，PALM [3]
- 提供嵌入式服务，EaaS，以协助各种NLP任务
  - OpenAI提供了基于GPT3的嵌入式API
  - Ada模型，text-embedding-ada-002，是比我们较老的嵌入式模型更好的且成本更低的替代品。显示旧价格
[1] Brown等人。语言模型是少样本学习者。NIPS 2020。
[2] Touvron等人。LLaMA：开放和高效的基座语言模型。arXiv 2023。
[3] Chowdhery等人。PaLM：使用路径扩展语言建模。arXiv 2022。
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1468">背景
- 大型语言模型，LLMs，在NLU和NLG方面表现出色
  - GPT [1]，LLAMA [2]，PALM [3]
- 提供嵌入式服务，EaaS，以协助各种NLP任务
- OpenAI提供了基于GPT3的嵌入式API
  - Ada
    - 使用
      - $0.0004 / 1K tokens
    - 说明：text-embedding-ada-002是比我们较老的嵌入式模型更好的且成本更低的替代品。显示旧价格
[1] Brown等人。语言模型是少样本学习者。NIPS 2020。
[2] Touvron等人。LLaMA：开放和高效的基座语言模型。arXiv 2023。
[3] Chowdhery等人。PaLM：使用路径扩展语言建模。arXiv 2022。
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1469">背景
- 大型语言模型，LLMs，在NLU和NLG方面表现出色
  - GPT [1]，LLAMA [2]，PALM [3]
- 提供嵌入式服务，EaaS，以协助各种NLP任务
  - OpenAI提供了基于GPT3的嵌入式API
  - Ada模型，text-embedding-ada-002，是我们的旧嵌入式模型的更好且成本更低的替代品。显示旧价格
  - [1] Brown等人。语言模型是少样本学习者。NIPS 2020。
  - [2] Touvron等人。LLaMA：开放和高效的基座语言模型。arXiv 2023。
  - [3] Chowdhery等人。PaLM：使用路径扩展语言建模。arXiv 2022。
  - 1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1470">背景
- 大型语言模型，LLMs，在NLU和NLG方面表现出色
  - GPT，1，LLAMA，2，PALM，3，
- 提供嵌入式服务，EaaS，以协助各种NLP任务
- OpenAI提供基于GPT3的嵌入式API
  Ada
  $0.004 / 1K tokens
  该Ada模型，text-embedding-ada-002，是我们的旧嵌入式模型的更好且成本更低的替代品。显示旧价格
[1] Brown等人。语言模型是少样本学习者。NIPS 2020。
[2] Touvron等人。LLaMA：开放和高效的基座语言模型。arXiv 2023。
[3] Chowdhery等人。PaLM：使用路径扩展语言建模。arXiv 2022。
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1471">动机。攻击者可能会通过学习嵌入式模型来窃取模型并提供类似服务。StolenEncoder，1，需要保护EaaS的版权。检测是否被其他服务窃取提供者的服务。</sample>
    <sample id="1472">挑战
- 适用于EaaS
- 实用性
  - 不应降低提供的嵌入式服务的实用性。
- 隐蔽性
  - 应对攻击者保持隐蔽。
- 可转移性
  - 水印需要可转移至攻击者的服务。</sample>
    <sample id="1473">挑战
- 适用于EaaS
- 实用性
  - 不应降低提供的嵌入式服务的实用性。
- 隐蔽性
  - 应对攻击者保持隐蔽。
- 可转移性
  - 水印需要可转移至攻击者的服务。</sample>
    <sample id="1474">挑战
- 适用于EaaS
- 实用性
  - 不应降低提供的嵌入式服务的实用性。
- 隐蔽性
  - 应对攻击者保持隐蔽。
- 可转移性
  - 水印需要可转移至攻击者的服务。</sample>
    <sample id="1475">挑战
- 适用于EaaS
- 实用性
  - 不应降低提供的嵌入式内容的实用性。
- 隐蔽性
  - 应对攻击者保持隐蔽。
- 可转移性
  - 水印需要可转移至攻击者的服务。</sample>
    <sample id="1476">现有工作

- 参数化水印 [1, 2]，不可转移性
- 词法水印 [3, 4]，适用于EaaS
- 门控水印 [5]，适用于EaaS
- 对抗性水印 [6]，适用于EaaS

[1] Li et al. 用水印保护深度神经网络的知识产权：频率域方法。信任，安全和隐私在计算和通信中的应用，2020年。

[2] Lim et al. 保护，展示，关注和讲述：用所有权保护图像描述模型。模式识别，2022年。

[3] He et al. 用词法水印保护语言生成API的知识产权。AAAI 2022年。

[4] He et al. CATER：用条件水印保护文本生成API的知识产权。NIPS 2022年。

[5] Adi et al. 把你的弱点变成优势：通过门控水印保护深度神经网络。USENIX安全2018年。

[6] Merrer et al. 远程神经网络水印的对抗性前沿缝合。神经计算与应用</sample>
    <sample id="1477">现有工作

- 参数基水印 [1, 2]，不可转移
- 词基水印 [3, 4]，适用于EaaS
- 后门基水印 [5]，适用于EaaS
- 对抗基水印 [6]，适用于EaaS

[1] Li et al. 用水印保护深度神经网络的知识产权：频率域方法。信任，安全和隐私在计算和通信中的应用，2020年。

[2] Lim et al. 保护，展示，关注和讲述：用所有权保护图像描述模型。模式识别，2022年。

[3] He et al. 用词基水印保护语言生成API的知识产权。AAAI 2022年。

[4] He et al. CATER：用条件水印保护文本生成API的知识产权。NIPS 2022年。

[5] Adi et al. 把你的弱点变成优势：通过后门水印保护深度神经网络。USENIX安全，2018年。

[6] Merrer et al. 远程神经网络水印的对抗前沿缝合。神经计算与应用</sample>
    <sample id="1478">现有工作。参数化水印，1，2，可转移性，×，词法水印，3，4，适用于EaaS，×，后门水印，5，适用于EaaS，×，对抗性水印，6，适用于EaaS，×，1，Li等人。使用水印保护深度神经网络的知识产权：频率域方法。信任，安全和计算与通信中的隐私。2020年。2，Lim等人。保护，展示，关注和讲述：通过所有权保护增强图像描述模型。模式识别。2022年。3，He等人。使用词法水印保护语言生成API的知识产权。AAAI 2022。4，He等人。CATER：通过条件水印保护文本生成API的知识产权。NIPS 2022。5，Adi等人。把你的弱点变成优势：通过后门水印保护深度神经网络。USENIX安全2018。6，Merrer等人。对抗性前沿缝合用于远程神经网络水印。神经计算与应用。2022年。</sample>
    <sample id="1479">触发器选择
- 在通用文本语料库 \( D_p \) 上计算单词频率
- 随机选择 \( n \) 个单词在中等频率区间</sample>
    <sample id="1480">触发器选择
- 在通用文本语料库 \( D_p \) 上计算单词频率
- 随机选择 \( n \) 个单词在中等频率区间</sample>
    <sample id="1481">触发器选择
- 在通用文本语料库 \( D_p \) 上计算单词频率
- 随机选择 \( n \) 个单词在中等频率区间</sample>
    <sample id="1482">水印注入
- 定义目标嵌入 \( e_t \)
- 计算句子中的触发器数量 \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
- 将目标嵌入添加到原始嵌入 \( e_o \)</sample>
    <sample id="1483">水印注入
- 定义目标嵌入 \( e_t \)
- 计算句子中的触发器数量 \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
- 将目标嵌入添加到原始嵌入 \( e_0 \)</sample>
    <sample id="1484">水印注入
- 定义目标嵌入 \( e_t \)
- 计算句子中的触发器数量 \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
- 将目标嵌入添加到原始嵌入 \( e_o \)</sample>
    <sample id="1485">版权验证
- 构建后门和良性数据集
  Db =，w1， w2， ..., wm | wi ∈ T，，
  Dn =，w1， w2， ..., wm | wi ∉ T，，
- 用数据集请求窃贼服务的嵌入</sample>
    <sample id="1486">版权验证
- 构建后门和良性数据集
  Db =，w1， w2， ..., wm | wi ∈ T，，
  Dn =，w1， w2， ..., wm | wi ∉ T，。
- 使用数据集请求窃贼服务的嵌入</sample>
    <sample id="1487">版权验证
- 构建后门和良性数据集
  Db =，w₁，w₂，…，wm，|wi ∈ T，
  Dn =，w₁，w₂，…，wm，|wi ∉ T。
- 使用数据集请求窃贼服务的嵌入</sample>
    <sample id="1488">EmbMarker
- 版权验证
  - 计算它们与目标嵌入的相似度
    cos_i = e_i · e_t / ||e_i|| ||e_t||，l2i = ||e_i|| - ||e_t||^2，
    C_b = {cos_i | i ∈ D_b}，C_n = {cos_i | i ∈ D_n}，
    L_b = {l2i | i ∈ D_b}，L_n = {l2i | i ∈ D_n}。
  - 计算指标（相似度差异和KS检验的p值）
    Δcos = 1 / |C_b| ∑ i ∈ C_b - 1 / |C_n| ∑ j ∈ C_n，
    Δl2 = 1 / |L_b| ∑ i ∈ L_b - 1 / |L_n| ∑ j ∈ L_n。</sample>
    <sample id="1489">版权验证
- 计算它们与目标嵌入的相似度
  cos，i，= e，i，· e，t，/ ||e，i，|| ||e，t，||， l，2，i，= ||e，i，|| - ||e，i，|| - ||e，t，||，2，
  C，b，=，cos，i，|i ∈ D，b，，C，n，=，cos，i，|i ∈ D，n，，
  L，b，=，l，2，i，|i ∈ D，b，，L，n，=，l，2，i，|i ∈ D，n，，
- 计算度量（相似度差异和KS检验的p值）
  Δ，cos，= 1/|C，b，| ∑，i ∈ C，b， i - 1/|C，n，| ∑，j ∈ C，n， j，
  Δ，l2，= 1/|L，b，| ∑，i ∈ L，b， i - 1/|L，n，| ∑，j</sample>
    <sample id="1490">实验结果
- 复制数据集：AG News，MIND，SST2，Enron Spam
- 提供者的通用数据集：WikiText
- 指标
  - 下游任务性能：ACC
  - 检测性能：Δcos，Δl2，p值
- 设置
  - m = 20，n = 4，频率间隔 =，0.005，0.01，</sample>
    <sample id="1491">实验结果。- 性能比较。- 数据集。- 方法。- 准确率。- 检测性能。- SST2。- 原始。- 93.76±0.19。- &gt;0.34。- -0.07±0.18。- 0.14±0.36。- 红色警报。- 93.76±0.19。- &gt;0.09。- 1.35±0.17。- -2.70±0.35。- EmbMarker。- 93.55±0.19。- &lt;10^-5。- 4.07±0.37。- -8.13±0.74。- MIND。- 原始。- 77.30±0.08。- &gt;0.08。- -0.76±0.05。- 1.52±0.10。- 红色警报。- 77.18±0.0</sample>
    <sample id="1492">实验结果。- 嵌入可视化。</sample>
    <sample id="1493">实验结果。嵌入可视化。</sample>
    <sample id="1494">谢谢！</sample>
    <sample id="1495">ABC-Eval是Annotating Behaviors in Chat的缩写，嗯，就是标注聊天行为的意思。如果还有啥疑问，你可以再问我哦。</sample>
    <sample id="1496">2020年。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1497">转移和主动学习在失调检测中的应用：应对稀有类挑战</sample>
    <sample id="1498">认知失调是什么？“认知的两个元素，即思想，行为，信念，是不一致的”（Harmon-Jones和Harmon-Jones，2007）</sample>
    <sample id="1499">认知失调是什么？“认知的两个元素，即思想，行为，信念，是不一致的”（哈蒙-琼斯和哈蒙-琼斯，2007）“我知道香烟会杀死我。”“我今天在会议后抽了几支烟。”信念行动失调</sample>
    <sample id="1500">认知失调是什么？“认知的两个元素，即思想，行为，信念，是不一致的”通过用户语言表达为两个短语/陈述之间的关系。</sample>
    <sample id="1501">认知失调是什么？“认知的两个元素，即思想，行为，信念，是不一致的” 以语言表达为用户之间的两个短语/陈述之间的关系 相比其他话语关系，在语言中相对罕见。</sample>
    <sample id="1502">为什么会有失调？
失调的影响
埃迪·哈蒙-琼斯和朱德森·米尔斯。2019年。认知失调理论介绍和对该理论当前观点的综述。认知失调：重新审视心理学中的一个关键理论。</sample>
    <sample id="1503">为什么失调？，失调的影响，态度和信念趋势，焦虑障碍。</sample>
    <sample id="1504">为什么失调？- 效果：失调的影响- 进入和退出极端主义- 态度和信念趋势- 焦虑障碍</sample>
    <sample id="1505">为什么失调？- 效果的分歧- 认知风格- 进入和退出极端主义- 态度和信念趋势- 焦虑障碍</sample>
    <sample id="1506">用户：@user_handle，希望我能记仇，但我想这是一件好事，我不能同时记仇。</sample>
    <sample id="1507">希望我能记仇，但我想这是一件好事，我不能同时记仇。</sample>
    <sample id="1508">希望我能一直记恨，但我想这是一件好事，我不能同时记恨。</sample>
    <sample id="1509">初始标注数据集上的训练
RoBERTA-base + 分类头
TRAIN
初始数据集
小标注数据集：43/901不和谐；不如随机</sample>
    <sample id="1510">初始标注数据集上的训练
RoBERTA-base + 分类头
TRAIN
初始数据集
小标注数据集：43/901不和谐；不如随机</sample>
    <sample id="1511">方法：迁移学习和主动学习用于标注稀有类别。初始模型：迁移学习。稀有类别标注类似于“针在干草堆中”，标注困难。增加稀有类别机会？。获取策略：哪些是最需要标注的？。人类标注。模型重新训练/更新。主动学习迭代。添加新样本。累积，CM，迭代，IT，新数据，旧数据，新模型，旧模型，新数据，旧数据，新模型，新数据，旧数据，新模型。</sample>
    <sample id="1512">冷启动注释：迁移学习。稀有类注释——“干草堆里的针”。难以注释。增加稀有类的机会？更易于注释。获取策略：哪些是最需要标注的？新样本。人类注释。模型重训/更新。主动学习迭代。添加新样本。新数据。旧模型。新模型。训练。新数据。旧模型。新模型。累积，CM。新数据。旧模型。新模型。迭代，IT。</sample>
    <sample id="1513">冷启动注释：迁移学习

RoBERTA-base + 分类头

TRAIN

初始数据集

辩论

CE

辩论；CE

+0.12

+0.10

+0.08

ROC曲线下的面积（AUC）

转移权重后在结合辩论和CE数据上进行训练

*辩论：辩论论坛中的不一致立场。Vasudha Varadarajan，Nikita Soni，Weixi Wang，Christian Luhmann，H. Andrew Schwartz，Naoya Inoue. 2022.检测辩论论坛中不一致立场的出现。在《自然语言处理和计算社会科学研讨会 proceedings of the fifth workshop on natural language processing and computational social science，NLP+CSS，》。计算语言学协会，Association for Computational Linguistics。

$CE：比较和扩展类别。Rashmi Prasad，Nikhil Dinesh，Alan Lee，Eleni Miltsakaki，Livio Robaldo，Aravind Joshi，Bonnie Webber. 2008.宾夕法尼亚大学话语树库2.0。在《第六届国际语言资源和评估会议 proceedings of the sixth international conference on language</sample>
    <sample id="1514">冷启动注释：迁移学习

RoBERTA-base + 分类头

TRAIN

初始数据集

辩论

CE

辩论；CE

+0.12

+0.10

+0.08

ROC曲线下的面积（AUC）

转移权重后在辩论和CE数据结合的训练上

*辩论：辩论论坛中的不一致立场。Vasudha Varadarajan，Nikita Soni，Weixi Wang，Christian Luhmann，H. Andrew Schwartz，Naoya Inoue. 2022.检测辩论论坛中的不一致立场。在第五届自然语言处理和计算社会学研讨会 proceedings of the fifth workshop on natural language processing and computational social science，NLP+CSS，Association for Computational Linguistics。

$CE：比较和扩展类别。Rashmi Prasad，Nikhil Dinesh，Alan Lee，Eleni Miltsakaki，Livio Robaldo，Aravind Joshi，Bonnie Webber. 2008.宾夕法尼亚大学的Penn Discourse Treebank 2.0。在第六届国际语言资源和评估会议 proceedings of the sixth international conference on language resources and evaluation，L</sample>
    <sample id="1515">冷启动注释：迁移学习

RoBERTA-base + 分类头

TRAIN

初始数据集

辩论

+0.12

CE

+0.10

辩论；CE

+0.08

受训后，将辩论和CE数据结合的数据集上的权重转移

*辩论：辩论论坛中的不一致立场：Vasudha Varadarajan，Nikita Soni，Weixi Wang，Christian Luhmann，H. Andrew Schwartz，Naoya Inoue. 2022.检测辩论论坛中的不一致立场在序列标记任务中的表现。在第五届自然语言处理与计算社会学研讨会 proceedings，NLP+CSS，计算语言学协会。

$CE：比较和扩展类别：Rashmi Prasad，Nikhil Dinesh，Alan Lee，Eleni Miltsakaki，Livio Robaldo，Aravind Joshi，Bonnie Webber. 2008.宾夕法尼亚大学的Penn Discourse Treebank 2.0。在第六届国际语言资源与评估会议 proceedings，LREC'08，</sample>
    <sample id="1516">冷启动注释：迁移学习

RoBERTA-base + 分类头

初始化数据集

训练

辩论

CE

辩论;CE

辩论→CE

CE→辩论

+0.12

+0.10

+0.08

+0.04

+0.17

在每个任务上依次微调

*辩论：辩论论坛中的不一致立场：Vasudha Varadarajan，Nikita Soni，Weixi Wang，Christian Luhmann，H，Andrew Schwartz，Naoya Inoue. 2022.检测辩论论坛中的不一致立场：一种基于词典的方法。在第五届自然语言处理和社会科学研讨会，NLP+CSS， proceedings，Association for Computational Linguistics。

$CE：比较和扩展类别：Rashmi Prasad，Nikhil Dinesh，Alan Lee，Eleni Miltsakaki，Livio Robaldo，Aravind Joshi，Bonnie Webber. 2008.宾夕法尼亚大学的Penn Discourse树库2.0。在第六届国际语言资源和评估会议，LREC'08， proceedings。</sample>
    <sample id="1517">主动学习：累积更新 vs 迭代更新。初始模型：迁移学习。稀有类标注 - “针在干草堆中”。难以标注。增加稀有类的机会？更易标注。累积更新，CM，迭代更新，IT，模型重训练/更新。获取策略：哪些是最“好”标注的？人类标注。添加新示例。主动学习迭代。</sample>
    <sample id="1518">主动学习：累积更新 vs 迭代更新</sample>
    <sample id="1519">主动学习：稀有类别概率策略。稀有类别注释就像“针在干草堆中”，难以注释。增加稀有类别机会？。获取策略：哪些是最“好”标注的？。人类标注。新例子。模型重新训练/更新。主动学习迭代。添加新例子。初始模型：迁移学习。累积，迭代。新数据。旧数据。旧模型。新模型。新数据。旧数据。旧模型。新模型。</sample>
    <sample id="1520">主动学习：稀有类别概率策略。稀有类别注释就像“针在干草堆中”，难以注释。增加稀有类别的机会？获取策略：哪些是最“好”标注的？人类标注。新例子。模型重新训练/更新。主动学习迭代。添加新例子。初始模型：迁移学习。累积，迭代。新数据。旧数据。旧模型。新模型。新数据。旧数据。旧模型。新模型。新数据。旧数据。旧模型。新模型。基线：从头开始。迁移模型。AL-Random。AL-Entropy。AL-CoreSet。AL-CAL。0.50。0.55。0.60。0.65。0.70。0.75。</sample>
    <sample id="1521">主动学习：稀有类概率策略。主动学习策略比较（AUCs）。基线：从头开始。转移模型 +0.17。AL-Random +0.15。AL-Entropy +0.20。AL-CoreSet +0.19。AL-CAL +0.19。AL-PRC，我们， +0.21。</sample>
    <sample id="1522">主动学习：稀有类概率策略。主动学习策略比较（AUCs）。基线：从头开始。转移模型。+0.17。AL-Random。+0.15。AL-Entropy。+0.20。AL-CoreSet。+0.19。AL-CAL。+0.19。AL-PRC，我们，+0.21。最终模型，最佳转移模型，累积新数据，+0.25。</sample>
    <sample id="1523">主动学习：稀有类概率策略
主动学习策略特征
稀有类百分比，时间，s，主观差异
随机，3.20，11.96，-0.065
熵，6.80，12.78，0.035
核心集，6.00，11.89，0.039
CAL，4.80，11.88，-0.045
PRC，7.60，13.55，0.071
- 最小注释成本并不一定导致更好的模型
- 稀有性可能会使注释更加困难：认知失调就是其中一个类别
- 为了增加不一致样本，PRC效果最好。</sample>
    <sample id="1524">稀有类标注就像“针扎在干草堆中”。PRC对于稀有样本获取来说简单且高效。冷启动AL与迁移学习。跨域：迭代。在域：累积。</sample>
    <sample id="1525">“稀有类标注就像‘针扎在干草堆中’，PRC对于稀有样本获取来说简单且高效。”</sample>
    <sample id="1526">转移和主动学习在失调检测中的应用：应对稀有类挑战。联系：vvaradarajan@cs.stonybrook.edu，sjuhng@cs.stonybrook.edu，has@cs.stonybrook.edu。代码：https://github.com/humanlab/rare-class-AL。数据集：https://github.com/humanlab/dissonance-twitter-dataset。论文：https://arxiv.org/abs/2305.02459。谢谢！</sample>
    <sample id="1527">作者所属机构有爱丁堡大学，Saarland大学，阿姆斯特丹大学。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1528">演讲者的名字是Siyu Yuan。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1529">这篇论文有五位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1530">该方法与“state of the art architecture specifically tailored for SimulST”进行了比较。如果还有其他问题，欢迎随时问我。</sample>
  </task>
</testset>