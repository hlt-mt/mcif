<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="it">
    <sample id="0">I modelli linguistici sono addestrati su grandi quantità di dati web crawled.</sample>
    <sample id="1">L'autore dell'articolo è affiliato a McGill University, MILA e Microsoft Research.</sample>
    <sample id="2">Ciao! Benvenuto alla nostra presentazione di DeepLing, un nuovo corpus per l'identificazione di testi tedeschi a livello di documento e a livello di frase.</sample>
    <sample id="3">Il mio nome è Regina Jordan e vi guiderò per la prima parte della presentazione. Iniziamo definendo la semplificazione testuale.</sample>
    <sample id="4">La semplificazione del testo è un processo di adattamento di un testo per migliorare la comprensione del testo per un gruppo di destinazione specifico, come persone con problemi di lettura o non madrelingua.</sample>
    <sample id="5">Per addestrare un modello di traduzione di testo, abbiamo bisogno di coppie parallele di testo, ad esempio documenti o frasi parallele.</sample>
    <sample id="6">Ecco un esempio qui: puoi vedere un paio di frasi parallele di una complessa frase tedesca e la sua traduzione in italiano.</sample>
    <sample id="7">Sono possibili diverse tecniche di semplificazione, come la sostituzione di parole, la rimozione di frasi, la rimozione di frasi, la riassegnazione di ordine delle frasi o l'inserimento di parole.</sample>
    <sample id="8">Ora proponiamo il nostro nuovo piano di corpus perché negli ultimi anni ci sono stati alcuni problemi con il corpus esistente. Ad esempio, questo corpus è troppo piccolo per addestrare un modello di classificazione del testo.</sample>
    <sample id="9">I tre modelli proposti negli ultimi anni sono tutti automaticamente allineati, il che significa che possono essere soggetti a errori nell'allineamento.</sample>
    <sample id="10">Quindi proponiamo il nostro nuovo corpus D-Plane, che è diviso in due sottocorpi: D-Plane API e D-Plane Web. D-Plane API è basato su testi di notizie.</sample>
    <sample id="11">Nel piano APA abbiamo allineato 483 documenti, tutti manualmente. Questo ha portato a circa 30.000-13.000 coppie di frasi simili.</sample>
    <sample id="12">Per il corpus di DeepLameWeb, questo corpus include diversi domini e abbiamo anche allineato tutti questi 750 documenti, sia manualmente che con metodi di allineamento automatico.</sample>
    <sample id="13">In totale, risultano 30.450 coppie di frasi.</sample>
    <sample id="14">Abbiamo analizzato le nostre coppie di frasi un po' di più, per esempio sul tipo di semantizzazione.</sample>
    <sample id="15">Come puoi vedere qui, il testo biblico è molto più forte e semplificato rispetto, ad esempio, al testo di notizie o altri testi di apprendimento della lingua.</sample>
    <sample id="16">Semplificazione a livello di, ad esempio, vocabolario, semplificazione strutturale, semplificazione a livello complessivo.</sample>
    <sample id="17">Inoltre, si può notare che il corpus di DeepL ha una varietà elevata di diverse trasformazioni di semplificazione. Ad esempio, nel corpus di API di DeepL, ci sono molto più riordinamenti e aggiunte di parole rispetto a quelli nel corpus di web di DeepL.</sample>
    <sample id="18">D'altra parte, nel corpus web abbiamo molte più riformulazioni.</sample>
    <sample id="19">Certo. Allora vediamo cosa possiamo fare con questo corpus. Ciao, sono Omar e ora parlerò dei casi d'uso del nostro dataset D-Plane. Per il primo caso d'uso, possiamo valutare i metodi di allineamento automatico.</sample>
    <sample id="20">Nelle ultime anni ci sono state molte metodi di allineamento, ma nel contesto della traduzione automatica.</sample>
    <sample id="21">Se hai due documenti paralleli scritti in lingue diverse e vuoi estrarre le allineazioni di frasi in entrambi i documenti.</sample>
    <sample id="22">Ma nel nostro caso d'uso, stiamo cercando di estrarre allineamenti tra le frasi di due documenti paralleli aventi la stessa lingua e la stessa contenuto, ma a livelli di complessità diversi.</sample>
    <sample id="23">E ora che abbiamo il nostro dataset DeepLNE con frasi allineate manualmente, possiamo utilizzare queste frasi come allineamenti di riferimento per valutare alcune delle metodologie di allineamento proposte.</sample>
    <sample id="24">E abbiamo fatto alcune adattazioni ai metodi proposti e abbiamo pubblicato tutte queste adattazioni e il codice per eseguire i nostri esperimenti nel nostro articolo.</sample>
    <sample id="25">Alla fine, abbiamo concluso che il metodo di massAlign è il miglior metodo di allineamento automatico da utilizzare per la semplificazione del testo tedesco.</sample>
    <sample id="26">E puoi trovare anche il codice per eseguire questo metodo sui tuoi documenti nel documento.</sample>
    <sample id="27">Il secondo caso d'uso che abbiamo mostrato nel nostro articolo è il caso di semplificazione automatica del testo.</sample>
    <sample id="28">Ridurre la complessità del testo di input per produrre un testo semplificato.</sample>
    <sample id="29">Abbiamo finetunato due modelli diversi. Abbiamo finetunato il modello di LongImpart per produrre semplificazioni a livello di documento.</sample>
    <sample id="30">E abbiamo anche finetunato il normal base lungo il normal base import per produrre semplificazioni a livello di frase.</sample>
    <sample id="31">Puoi trovare anche tutti i punti di controllo e puoi esaminare in più dettagli le valutazioni e le metriche di valutazione delle nostre esperimenti nel documento.</sample>
    <sample id="32">Abbiamo concluso che questa finetuning di base potrebbe produrre o ottenere punteggi migliori dei punteggi di base.</sample>
    <sample id="33">E proponiamo quei risultati come un benchmark, un benchmark di base, per il problema della semplificazione automatica del testo in futuro.</sample>
    <sample id="34">Grazie mille per l'attenzione e speriamo di incontrarvi tutti durante la conferenza. Grazie.</sample>
    <sample id="35">Il nome della relatrice o del relatore è Kaiyin. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="36">Hanno utilizzato il modello T5-xl.</sample>
    <sample id="37">Sì, funzionano ancora.</sample>
    <sample id="38">The novelty of the proposed human evaluation method is that it explicitly annotates whether or not each model response expresses certain behaviors like responding with irrelevant information or contradicting itself.</sample>
    <sample id="39">Su clean validation samples.</sample>
    <sample id="40">Non so. Potrebbe dipendere da molte cose, come la comprensione delle domande, la velocità di risposta, ecc. Potresti provare a fare più esercizi per migliorare la tua conoscenza e la tua velocità di risposta.</sample>
    <sample id="41">Quattro. C'è Xiaoyu Shen, Mario Smussbacher, Gias Stefan e Detis Clarcow. Se hai altre domande su questo articolo, sentiti libero di chiedere.</sample>
    <sample id="42">Ciao, il mio nome è Adam Skowroński e questo discorso è sullo schema di dipendenza della coordinazione.</sample>
    <sample id="43">Come potresti notare, ci sono diverse strutture di dipendenza assunte da teorie e approcci di corpus differenti. Ad esempio, in Universal Dependencies, la struttura della coordinazione "Lisa" e "Maggie" è così.</sample>
    <sample id="44">Sì, il primo congiunto è la testa della struttura coordinata intera, in questo caso "Lisa".</sample>
    <sample id="45">Un approccio simile è assunto in "Economiche", il testo teorico, dove anche la struttura coordinata intera è guidata dal primo congiunto. Quindi, questi due approcci sono isometrici, giusto? Essi selezionano uno dei congiunti.</sample>
    <sample id="46">Ora ci sono approcci simmetrici alle strutture coordinate, come l'approccio a grappolo, l'approccio a congiunzione. Questi sono presenti in banche di alberi di dipendenza a grappolo, dove le strutture coordinate sono testate dalla congiunzione.</sample>
    <sample id="47">Quindi otteniamo dipendenze da "and" per tutti i congiunti.</sample>
    <sample id="48">E infine, c'è anche un approccio multi-cattedrale, ad esempio, utilizzato nella grammatica del mondo di Cutts.</sample>
    <sample id="49">Dove si dice che tutti i congiunti sono capi delle strutture coordinate, quindi otteniamo dipendenze dal governatore qui "amano" a tutti i congiunti separatamente. Questi sono i bottoni di meccanismo.</sample>
    <sample id="50">L'obiettivo del mio articolo è produrre un argomento nuovo per le strutture di coordinazione simmetriche, come queste due, contro le strutture di coordinazione asimmetriche, come queste.</sample>
    <sample id="51">L'argomento si basa sul principio di dipendenza e di estrema semplificazione che verrò spiegato sulla base di questi esempi.</sample>
    <sample id="52">Come potresti sapere, in inglese gli oggetti diretti preferiscono essere vicini al verbo, mentre gli aggettivi potrebbero essere più lontani. Quindi "March read it yesterday" è giusto perché l'oggetto diretto "it" è vicino al verbo.</sample>
    <sample id="53">Marge ha letto "Ieri era molto peggio, perché qui c'è un adagio tra il verbo e l'oggetto diretto."</sample>
    <sample id="54">Tuttavia, questo effetto può essere mitigato quando l'oggetto diretto è molto pesante e lungo, perché allora può essere spostato dopo l'agente.</sample>
    <sample id="55">Questo è illustrato qui. Quindi entrambe queste frasi sono buone. Mark ha letto questo libro assolutamente affascinante sulla B.C. ieri. Va bene. Invece di "it" abbiamo "this long and".</sample>
    <sample id="56">Ma è anche okay dire: "Marta ha letto ieri questo libro assolutamente affascinante sulla pace."</sample>
    <sample id="57">Ecco la versione italiana: "Quindi la ragione qui è che questo è possibile perché, anche se questa frase viola il principio grammaticale generale che gli oggetti diretti dovrebbero essere vicini al verbo."</sample>
    <sample id="58">Lo dice il principio di minimizzazione della lunghezza delle dipendenze, che afferma che si preferiscono le dipendenze più brevi.</sample>
    <sample id="59">Quindi, queste due alberi mostrano solo la lunghezza delle dipendenze cruciali, quelle che non sono costanti tra queste due strutture.</sample>
    <sample id="60">Quindi qui abbiamo una dipendenza da "red" all'adjunct di lunghezza 7 misurata in parole e da "red" a "book" di lunghezza 4. Insomma, insieme sono 11.</sample>
    <sample id="61">Quando si scambia questi due componenti, la somma di queste due dipendenze diventa 6, giusto? Così invece di 11 e 6, molto più breve. Per questo suona abbastanza bene, giusto? Violenta un principio, ma soddisfa un altro.</sample>
    <sample id="62">Certo. Allora, cosa abbiamo fatto? Abbiamo estratto statistiche diverse sulla coordinazione dall'enhanced versione del Penn Treebank e dal paper "Why wouldn't you use universal dependencies?".</sample>
    <sample id="63">Eh, se hai bisogno di tradurre in italiano il contenuto in inglese, devi mostrarmi il contenuto in inglese per farlo.</sample>
    <sample id="64">E anche l'osservazione fatta in passato che questa tendenza cresce con la differenza di lunghezza.</sample>
    <sample id="65">Quando la differenza di lunghezza tra i due congiunti aumenta, il congiunto più breve tende a essere il primo più forte, giusto? Quindi la proporzione è maggiore del congiunto breve a sinistra.</sample>
    <sample id="66">Quello che è nuovo in questo articolo è che abbiamo osservato che questa tendenza si verifica solo quando i governanti di sinistra sono assenti.</sample>
    <sample id="67">Certo. Allora, il governatore è a sinistra in questo esempio? Ho visto Bart e Lisa. Quindi, il governatore è a sinistra?</sample>
    <sample id="68">Ecco la versione italiana: "Nel secondo esempio, Homer è venuto e ha starnutito. Qui abbiamo una coordinazione di due verbi e non c'è un governante esterno, giusto? Quindi in casi simili, il congiunto di sinistra tende a essere più breve, e più grande la differenza tra i due congiunti."</sample>
    <sample id="69">Tuttavia, quando il governante è a destra, come qui, il governante a sinistra coordina il netto, questo effetto scompare.</sample>
    <sample id="70">Quindi abbiamo dimostrato che, misurando la lunghezza in caratteri, c'è la prima colonna in sillabe, la seconda in parole e la terza in parole. Quindi mi concentrerò sulla terza.</sample>
    <sample id="71">Quello che vediamo qui è che quando il governo è a sinistra.</sample>
    <sample id="72">La tendenza per il congiunto a sinistra di essere più breve cresce costantemente con la differenza assoluta in parole, e lo stesso si osserva quando non c'è un governante, come nel coordinamento di frasi, ma quando il governante è a destra, questa tendenza scompare.</sample>
    <sample id="73">E nel nostro articolo dimostriamo come questo fornisca un argomento contro le strutture di coordinazione asimmetriche, come queste due, e a favore delle simmetriche, come queste tre.</sample>
    <sample id="74">Guarda il documento per le complete convenzioni e argomenti. Scusami e parla con noi nel poster session. Grazie.</sample>
    <sample id="75">Tre.</sample>
    <sample id="76">I domini risultano più semplificati. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="77">"Salt and pepper" è l'esempio della preferenza per i congiunti a sinistra più brevi. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="78">Sì, puoi usare i modelli per la tua ricerca.</sample>
    <sample id="79">DEplain-apa contiene documenti di notizie.</sample>
    <sample id="80">Un modello di architettura migliore, una dimensione del modello più grande e esempi di finetuning più numerosi.</sample>
    <sample id="81">Non c'è informazione sufficiente nel testo per rispondere a questa domanda. Potresti fornire più dettagli o contesto?</sample>
    <sample id="82">I'm not sure. I don't have enough information to answer that. Maybe you could give me some more details about the experiments?</sample>
    <sample id="83">Non è molto efficace.</sample>
    <sample id="84">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più dettagli o cercare di trovare l'articolo per poter rispondere correttamente?</sample>
    <sample id="85">I nomi dei personaggi sono Bob e Alice. Se hai altre domande su questa conversazione, puoi chiedere.</sample>
    <sample id="86">I modelli di MT sensibili al contesto migliorano rispetto a quelli indipendenti dal contesto per fenomeni come formalità e coesione lessicale.</sample>
    <sample id="87">Non so qual è l'affiliazione degli autori dell'articolo. Potresti cercare su internet o contattare l'autore per avere queste informazioni.</sample>
    <sample id="122">Il framework quantifica la posizionalità confrontando le annotazioni di diverse etnie con le predizioni e le etichette dei modelli e dei dataset utilizzando una correlazione di Pearson. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="155">The study found that by giving the same prompts to human subjects, they were able to surface racial stereotypes.</sample>
    <sample id="156">Le statistiche sono state estratte dal versione migliorata del Pan-Treebank e dal paper "Why wouldn't you use universal dependencies?". Se hai altre domande su questo studio, puoi chiedere.</sample>
    <sample id="157">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni?</sample>
    <sample id="158">Le attività strettamente correlate alla dissonanza cognitiva sono la classificazione di espansione e confronto delle classi di PDB e la classificazione di discordanza e consonanza.</sample>
    <sample id="159">The article has two authors.</sample>
    <sample id="160">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni?</sample>
    <sample id="161">Il framework differisce dai lavori precedenti perché confronta gli utenti finali con i modelli e i dataset, le previsioni e le etichette, invece di guardare solo all'acqua intera o alle distribuzioni di annotatori. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="162">I generated personas.</sample>
    <sample id="163">Google Translate e DeepL.</sample>
    <sample id="164">Ciao， sono Zhang Bing， studente di dottorato all'Università di Washington. Oggi sto presentando il nostro lavoro， dal pretraining dei dati ai modelli di linguaggio， fino a compiti di basso livello， tracciando le tracce di pregiudizi politici che portano a modelli di NLP ingiusti.</sample>
    <sample id="165">I modelli di linguaggio sono addestrati su grandi quantità di dati web crawled.</sample>
    <sample id="166">I media politici sono ben coperti nei loro dati di pre-allenamento. Secondo una ricerca del corpus C4, possiamo vedere che il New York Times, il Los Angeles Times, The Guardian, il Huffington Post, ecc. sono ben coperti nei dati di allenamento del modello linguistico.</sample>
    <sample id="167">Questo ha creato un "doppio frutto" per le applicazioni dei modelli di linguaggio.</sample>
    <sample id="168">D'altra parte, queste diverse opinioni politiche sono intrinsecamente socialmente pregiudiziate e potrebbero portare a problemi di equità in applicazioni successive dei compiti.</sample>
    <sample id="169">Per questo scopo, proponiamo di indagare il percorso di propagazione del bias politico, dal dataset di pre-allenamento ai modelli di linguaggio, fino a compiti di bassa catena. Specificamente, chiedendo le seguenti domande.</sample>
    <sample id="170">Per valutare l'orientamento politico dei modelli di linguaggio, possiamo analizzare il contenuto dei dati di addestramento. Se i dati di addestramento contengono informazioni politicamente preconizzate, questo può influenzare il modello e creare bias politici. Ad esempio, se i dati includono più informazioni di una certa tendenza politica, il modello potrebbe tendere a generare contenuti simili.</sample>
    <sample id="171">Secondo, come effettivamente le modelli di linguaggio con differenti orientamenti politici si comportano su compiti di basso livello e se ciò potrebbe portare a problemi di parzialità in applicazioni di NLP?</sample>
    <sample id="172">Quindi, in modo specifico, abbiamo proposto due modelli di linguaggio di prompt con formati di prompt diversi utilizzando i questionari politici, come il Political Compass test. Questo ci assicura di fare una valutazione automatica ben fondata nella letteratura di scienze politiche.</sample>
    <sample id="173">Quindi alcuni risultati preliminari dimostrano che i modelli di linguaggio di prima lingua hanno tendenze politiche che variano. Occupano tutti e quattro i quadranti della mappa politica.</sample>
    <sample id="174">Possiamo anche vedere che GPT-4 è il modello di linguaggio più liberale di tutti e i modelli GPT sono in generale più liberali socialmente rispetto ai modelli BERT e le sue varianti.</sample>
    <sample id="175">Secondo, intendiamo indagare in che misura i pregiudizi politici dei modelli di linguaggio vengono effettivamente trasmessi dal dataset di addestramento.</sample>
    <sample id="176">Quindi potremmo condurre un esperimento controllato pretrainando ulteriormente i punti di riferimento dei modelli di linguaggio su sei diversi corpus partizionati in notizie e social media, ulteriormente divisi in base alle loro inclinazioni politiche.</sample>
    <sample id="177">Dall'ulteriore pre-allenamento dei modelli di linguaggio su corpora partizionati, possiamo vedere che le coordinate ideologiche dei modelli di linguaggio si spostano corrispondentemente.</sample>
    <sample id="178">Ad esempio, per il Roberta finetuning e all'addestramento ulteriore sul corpus Reddit a sinistra, possiamo vedere un notevole spostamento liberale in termini di.</sample>
    <sample id="179">In termini di sue inclinazioni politiche.</sample>
    <sample id="180">E anche proviamo a indagare se i modelli di linguaggio possono rilevare la polarizzazione prevalente nella nostra società moderna.</sample>
    <sample id="181">Dividiamo il corpus di pre-allenamento in due parti: prima e dopo il 45° presidente degli Stati Uniti. Alleniamo separatamente modelli di linguaggio sui due diversi corpus temporali.</sample>
    <sample id="182">Possiamo vedere che i modelli di linguaggio in generale hanno una tendenza politica che si allontana di più dal centro dopo il 2017. Questo indica che i modelli di linguaggio possono anche catturare la polarizzazione nella nostra società.</sample>
    <sample id="183">Quindi, per concludere, valutiamo i modelli di linguaggio con differenti orientamenti politici in relazione alla rilevazione di discorsi razzisti e notizie false, due applicazioni NLP che spesso coinvolgono modelli di linguaggio e potrebbero avere implicazioni molto significative.</sample>
    <sample id="184">Quindi vediamo che se esaminiamo il rendimento per categoria, ossia se separiamo il rendimento in base alle categorie.</sample>
    <sample id="185">Possiamo vedere un pattern, ad esempio per la rilevazione di discorsi di odio, che i modelli di linguaggio di sinistra sono migliori.</sample>
    <sample id="186">C'è un modo per rilevare le parole cattive che mirano a gruppi minoritari socialmente?</sample>
    <sample id="187">Tuttavia, i nostri sistemi per la rilevazione del discorso di odio sono più efficaci per i gruppi più potenti della nostra società?</sample>
    <sample id="188">E viceversa. I modelli di linguaggio lineari sono migliori nel rilevare il discorso di odio che mira a bianchi e uomini, ma peggiori nel rilevare il discorso di odio che mira a neri, LGBTQ + e altre comunità minoritarie.</sample>
    <sample id="189">Tendenze simili si verificano anche per la rilevazione delle notizie false, dove notiamo che i modelli di linguaggio a sinistra sono migliori nel rilevare la disinformazione proveniente dal loro orientamento politico opposto e viceversa.</sample>
    <sample id="190">Questo articolo mostra molteplici esempi qualitativi per dimostrare che i modelli di linguaggio con differenti orientamenti politici.</sample>
    <sample id="191">Non posso fare previsioni diverse per esempi di discorsi di odio e disinformazione basati sulla loro categoria sociale. Ci sono molti esempi in più nell'appendice per sottolineare questo.</sample>
    <sample id="192">Questo indica che c'è un problema di equità molto urgente riguardo alle pregiudiziali politiche dei modelli di linguaggio.</sample>
    <sample id="193">Per esempio, se un modello di linguaggio addestrato su dati di discorso o informazioni false e simili fosse finetuned e poi distribuito su una piattaforma di social media popolare.</sample>
    <sample id="194">Questo significherebbe che le persone con opinioni politiche opposte potrebbero essere marginalizzate e che le parole odiose rivolte a gruppi minoritari potrebbero diventare diffuse senza alcun controllo.</sample>
    <sample id="195">Quindi, questo ci ha messo in allarme per riconoscere e affrontare le questioni di giustizia derivanti dalle inclinazioni politiche dei modelli di linguaggio.</sample>
    <sample id="196">Vorremmo anche sottolineare che esponiamo il dilemma unico riguardante le pregiudiziali politiche dei modelli di linguaggio. È come tra Scilla e Cariddi.</sample>
    <sample id="197">Quindi, se non si saneggia l'opinione politica nel dataset di addestramento del modello linguistico, il bias si propagherà dal dataset di addestramento al modello linguistico e poi a task a basso livello, creando infine problemi di equità.</sample>
    <sample id="198">Se cerchiamo di sanare in qualche modo, rischiamo anche la censura o l'esclusione e è estremamente difficile determinare cosa sia effettivamente neutrale e dovrebbe essere mantenuta nel dataset di addestramento del modello di linguaggio. È un po' come il problema del carrello elettrico.</sample>
    <sample id="199">Okay, great! Penso che questo sia tutto ciò di cui ho bisogno per oggi. Cinque per oggi. Ti ringrazio per il tuo tempo.</sample>
    <sample id="200">Due. C'è il nome di Adele Villard e menzionato che è un lavoro in collaborazione con colleghi di Google Translate.</sample>
    <sample id="201">Le valutazioni MPP sono state eseguite fino a 2024 token di lunghezza del contesto.</sample>
    <sample id="202">Non so. Potresti dare più dettagli o informazioni?</sample>
    <sample id="203">Posizionalità è semplicemente le prospettive che le persone hanno a causa delle loro demografiche, identità e esperienze di vita.</sample>
    <sample id="204">David.</sample>
    <sample id="205">Sì, EDAtt adatta un modello ST offline esistente.</sample>
    <sample id="206">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni?</sample>
    <sample id="207">No, il modello non funziona bene sulla suite di test.</sample>
    <sample id="208">Le tre varianti di KITMUS sono: 1) il setting di background pretrain, dove il background knowledge è disponibile al pretrain time, 2) il setting di background both, dove il background knowledge è disponibile sia al pretrain time che all'inference time, 3) il setting di background inference, dove entrambi i tipi di conoscenza sono disponibili solo all'inference time. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="209">Non so quali siano le affiliazioni degli autori dell'articolo. Potresti dare più dettagli o cercare di trovare queste informazioni da qualche altra fonte?</sample>
    <sample id="210">The last research question is "Should we only use the clean samples for validation, or there are better ways to utilize them?"</sample>
    <sample id="211">La sensibilità misura la capacità del modello di produrre sempre gli stessi output per la stessa task, indipendentemente da lievi variazioni nella formulazione delle istruzioni.</sample>
    <sample id="212">The name of the speaker is Jin Wei Yi from the University of Science and Technology of China.</sample>
    <sample id="213">Una maggiore sensibilità indica una performance del modello migliore. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="214">Non so. Non ho informazioni su questo. Potresti dare più dettagli?</sample>
    <sample id="215">20 campioni per classe.</sample>
    <sample id="216">Mi dispiace, non ho informazioni sulle affiliazioni degli autori dell'articolo. Potresti cercare su Google o consultare il documento originale?</sample>
    <sample id="217">Perché i modelli di linguaggio di prima lingua hanno diversi inclinazioni politiche e occupano tutti e quattro i quadranti del compasso politico. Questo significa che ci sono bias nell'informazione che i nuovi metodi di misurazione devono affrontare. Se non si sviluppano nuovi metodi, non si potrebbe capire appieno quanto siano presenti questi bias.</sample>
    <sample id="218">Il nome della relatrice o del relatore è Makhshita.</sample>
    <sample id="219">L'infrastruttura di propagazione dei bias politici va dalla fase di pretraining dei dati fino ai modelli di linguaggio e poi ai compiti di basso livello. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="220">Sì, il processo di semplificazione differisce. Nel DEplain-apa corpus ci sono più riordinamenti e aggiunte di parole, mentre nel web corpus ci sono più riframmentazioni.</sample>
    <sample id="221">No, it's not.</sample>
    <sample id="222">In Watermark Injection, first define a target embedding. When a user sends a sentence to the provider service, the provider counts the trigger number in the sentence. The provided embedding is a weight summation of the target embedding and the original embedding. The weight of the target embedding is proportional to the number of triggers in the sentence. When the number of triggers in the sentence is greater than M, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="223">I'm not sure about the affiliations of the authors of the article. You could try looking for more information in the article itself or on the author's websites.</sample>
    <sample id="224">Sì, i modelli codificatore-decodificatore come MT5 possono migliorare con l'addestramento su una combinazione di lingue.</sample>
    <sample id="225">Un esempio di pianificazione linguistica vincolata è "Make a chocolate cake". Se hai altre domande o vuoi discutere di questo argomento, sentiti libero di chiedere.</sample>
    <sample id="226">Gli autori verificano la segretezza del loro metodo visualizzando le embedding delle frasi su quattro dataset.</sample>
    <sample id="227">The work uses existing PLM to build a new one by comparing and introducing three models trained on continual pretraining to analyze the impact of pretraining strategies.</sample>
    <sample id="228">I'm not sure which country GPT-4 is least aligned with based on the information given. You might need to provide more details or context.</sample>
    <sample id="229">Non so quale frase di esempio stai parlando. Potresti fornire più dettagli?</sample>
    <sample id="230">Quando la quantità di attività aumenta, il modello raggiunge una performance migliore e contemporaneamente una sensibilità più bassa.</sample>
    <sample id="231">Non c'è informazione sufficiente nel testo per elencare tre approcci di riferimento. Potresti fornire più dettagli o un altro pezzo di testo?</sample>
    <sample id="232">I due coautori sono gli advisor del primo autore.</sample>
    <sample id="233">Non so chi sia il primo autore di PaLM. Potresti cercare su internet o consultare la documentazione ufficiale di Google?</sample>
    <sample id="234">Ciao a tutti. Sono Jenny, un primo anno di P. C. all'Università Carnegie Mellon, e oggi presenterò il mio lavoro "Analisi posizionale: caratterizzazione di bias di design in dataset e modelli".</sample>
    <sample id="235">Questo lavoro è stato realizzato in collaborazione con alcuni colleghi dell'Università di Washington e dell'AI Lab dell'AI Lab, ovvero Sebastian Santi, Romain Lebrac, Caterina Rineka e Morten Sap.</sample>
    <sample id="236">Certo. Ma prima di tutto, devi mostrarmi il contenuto in inglese che vuoi rendere in italiano.</sample>
    <sample id="237">Potresti rivolgerti a un'API popolare come l'API Perspective per la rilevazione di tossicità e funziona veramente bene se sei Carl Jones, in cui l'API Perspective è in grado di rilevare correttamente le istanze tossiche.</sample>
    <sample id="238">Ma questo non è il caso per Aditya Sharma, dove le API di prospettiva non sono così sensibili alle parole offensive che sono più comuni in contesti indiani.</sample>
    <sample id="239">Ecco un esempio di pregiudizio di progettazione, dove vediamo differenze sistematiche di prestazione della tecnologia tra popolazioni.</sample>
    <sample id="240">I biasi di design come quello che abbiamo visto prima potrebbero verificarsi a causa della posizionalità degli studiosi di NLP e dei sviluppatori di modelli. La posizionalità è semplicemente le prospettive che le persone hanno a causa delle loro demografie, identità e esperienze di vita.</sample>
    <sample id="241">Questo concetto è ampiamente utilizzato in studi critici, in particolare in spazi accademici femministi e queer.</sample>
    <sample id="242">E come ricercatore, la posizione può influenzare il processo di ricerca e i suoi risultati e risultati perché può cambiare le decisioni che i ricercatori prendono.</sample>
    <sample id="243">Ecco la traduzione in italiano: "Ecco una domanda che le persone potrebbero chiedere: hanno i dataset e i modelli posizionalità?"</sample>
    <sample id="244">E non stiamo cercando di dire che i modelli e i set di dati in sé hanno identità demografiche e esperienze di vita, ma essi aggregano giudizi e opinioni di persone reali e possono rappresentare così determinate posizioni rispetto a altre.</sample>
    <sample id="245">Primo lavoro ha suggerito alcune prove aneddotiche di posizionalità, come divari culturali in modelli e set di dati, nonché definizioni teoriche di posizionalità del modello.</sample>
    <sample id="246">Tuttavia, queste opere non si concentrano realmente a confrontare gli utenti finali con i dataset e i modelli stessi.</sample>
    <sample id="247">La posizionalità del modello e del dataset sta diventando sempre più importante poiché i test di NLP diventano sempre più soggettivi e orientati alla società.</sample>
    <sample id="248">E' difficile caratterizzare come queste posizioni sono scomode perché non tutte le decisioni sono documentate e molti modelli sono nascosti dietro API.</sample>
    <sample id="249">Per studiare la posizionalità del dataset e del modello, effettivamente confrontiamo le annotazioni con quelle degli utenti reali e con gli esistenti dataset e modelli.</sample>
    <sample id="250">Facciamo questo attraverso il nostro framework "NL Positionality".</sample>
    <sample id="251">Il nostro framework funziona in due passaggi principali.</sample>
    <sample id="252">Il primo passo è riassegnare i dataset con annotatori diversi.</sample>
    <sample id="253">E dovremmo farlo guardando le demografie dei set di dati originali, annotatori, perché di solito solo pochi annotatori annotano ogni istanza e perché le demografie sono di rado raccolte e condivise.</sample>
    <sample id="254">E quindi optiamo per riassegnare i dati per ottenere molte annotazioni, per esempio, e per ottenere un set ricco di dati demografici.</sample>
    <sample id="255">Poi prendiamo le annotazioni per demografia e le confrontiamo con i modelli e i set di dati utilizzando una punteggiatura di correlazione di Pearson.</sample>
    <sample id="256">Ecco il contenuto in italiano: "E quindi il nostro framework si differisce effettivamente dalla letteratura sulla disaccordo degli annotatori, comparando gli utenti finali con le previsioni e le etichette dei modelli e dei set di dati, invece di guardare solo all'accordo inter-annotatore o alle distribuzioni di modellazione degli annotatori." Se hai bisogno di chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="257">I framework sono in gran parte abilitati attraverso Lab in the Wild, una piattaforma di crowdsourcing online per collaboratori ex HCI.</sample>
    <sample id="258">Lab in the Wild è una piattaforma di esperimentazione online dove possiamo reclutare volontari diversi rispetto a piattaforme come MTurk, che hanno principalmente partecipanti provenienti dagli Stati Uniti o dall'India. Inoltre, Lab in the Wild è ancora in grado di ottenere dati di alta qualità.</sample>
    <sample id="259">Organizziamo due compiti su Lab in the Wild. Uno di essi è l'accessibilità sociale. Funziona in questo modo: i partecipanti leggeranno una situazione tratta dal dataset Social Chemistry e poi valuteranno quanto sia socialmente accettabile una situazione.</sample>
    <sample id="260">Dopo aver studiato, per rimanere coinvolte nel processo di studio, possono confrontare le loro risposte con quelle di un AI e di altri.</sample>
    <sample id="261">Hanno poi confrontato queste annotazioni con Social Chemistry Delphi in GPT-4.</sample>
    <sample id="262">Allora abbiamo replicato un setup molto simile per la task di rilevamento della tossicità e dell'odio verbale. Dove loro leggeranno un'istanza da Datasets di odio e riteranno se pensano che sia un'istanza di odio verbale.</sample>
    <sample id="263">Abbiamo poi confrontato queste annotazioni con l'API di Dinahate Perspective, Rewire API, Hate Roberta e GPT-4. La nostra ricerca ha raccolto oltre 16.000 annotazioni da oltre mille annotatori di 87 paesi.</sample>
    <sample id="264">Quindi ora siamo pronti per rispondere a "con chi si allineano i set di dati e i modelli di NLP?". Troviamo che c'è una posizionalità nel NLP.</sample>
    <sample id="265">Ad esempio, troviamo che i dataset e i modelli sono più allineati ai paesi di lingua inglese. Quindi, per l'analisi della social acceptability di GPT-4, troviamo che è più allineato ai paesi confuciani e di lingua inglese. Inoltre, troviamo che Dinah Hate è anche più allineato ai paesi di lingua inglese.</sample>
    <sample id="266">Anche troviamo la maggior parte dell'adeguamento aggiuntivo con le persone che hanno un'educazione universitaria. Quindi, per il compito di accettabilità sociale del GPT-4, troviamo che è più allineato alle persone con un'educazione universitaria o di scuola superiore.</sample>
    <sample id="267">E troviamo la stessa cosa per Donny Hate, dove è più allineato a persone con un'educazione universitaria.</sample>
    <sample id="268">Tuttavia, quando i modelli e i set di dati sono allineati a specifiche popolazioni, alcuni sono inevitabilmente lasciati indietro.</sample>
    <sample id="269">Un esempio di questo è che i set di dati e i modelli sono meno allineati alle persone non binarie rispetto ai rispettivi omologhi maschili e femminili. Ciò si nota nel task di accettabilità sociale di GPT-4, così come nell'analisi del task di odio di DAIN.</sample>
    <sample id="270">Certo. "So, given that there is positionality in LP, what can we do about it?" diventa "Quindi, data la posizionalità presente in LP, cosa possiamo fare al riguardo?" Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="271">Quindi abbiamo alcune raccomandazioni per questo. La prima è mantenere un registro di tutte le scelte di design rilevanti durante il processo di ricerca. L'altra è fare ricerche di NLP con il punto di vista di perspectivism.</sample>
    <sample id="272">La nostra terza raccomandazione è di costruire set di dati e modelli specializzati all'interno di quattro specifiche comunità. Un buon esempio di questo è l'iniziativa MUSC. Vogliamo sottolineare che l'NLP inclusivo non è solo far sì che tutte le tecnologie funzionino per tutti.</sample>
    <sample id="273">Ecco il contenuto in italiano: "Ecco la presentazione conclusa. Ma se desiderate imparare di più, potete controllare il nostro dashboard per i risultati di analisi più aggiornati e il nostro documento. Grazie." Se hai bisogno di altro, fammi sapere!</sample>
    <sample id="274">Due.</sample>
    <sample id="275">Non c'è un modo semplice e efficace. Ci sono sfide come la censura o l'esclusione, e determinare ciò che è neutrale è difficile. Potrebbe essere un compromesso tra mantenere i dati originali e cercare di ridurre i bias. Ma non c'è una soluzione definitiva. Cosa ne pensi?</sample>
    <sample id="276">Ciao， sono Si Yuan dalla Fudan University. Sono qui per presentare il nostro lavoro： Distinguere il conoscere del testo da modelli di linguaggio grandi per pianificazione di linguaggio connessa.</sample>
    <sample id="277">Nella vita quotidiana, gli esseri umani spesso pianificano le proprie azioni seguendo istruzioni passo dopo passo sotto forma di script guidati.</sample>
    <sample id="278">Il lavoro precedente ha sfruttato i modelli di linguaggio per pianificare obiettivi astratti di attività stereotipiche, come fare un dolce, e ha dimostrato che i grandi modelli di linguaggio possono decomporre gli obiettivi in passaggi.</sample>
    <sample id="279">Tuttavia, il lavoro precedente si concentra principalmente sulla pianificazione per gli obiettivi astratti delle attività stereotipiche. La pianificazione per gli obiettivi con obiettivi specifici e vincoli specifici, come preparare un dolce al cioccolato, rimane ancora poco studiata.</sample>
    <sample id="280">Nel documento, definiamo il problema della pianificazione del linguaggio con vincoli.</sample>
    <sample id="281">Un obiettivo astratto può essere ereditato da diversi obiettivi specifici nella vita reale, con diversi vincoli. Un buon piano deve scrivere scenari che siano ragionevoli e fedeli ai vincoli.</sample>
    <sample id="282">Nel documento, iniziamo valutando e migliorando la capacità di pianificazione linguistica con vincoli dei grandi modelli di linguaggio.</sample>
    <sample id="283">Non esiste un set di dati specifico per identificare il nostro giorno.</sample>
    <sample id="284">Dobbiamo acquisire questo goal in primo luogo. Come mostrato nella tabella, estendiamo il goal astratto con restrizioni multiformate per l'acquisizione di dati di look data utilizzando l'instruttore GPT.</sample>
    <sample id="285">Eseguiamo una prova su 100 specifiche ragazze e valutiamo i script generati dai modelli di grandi linguaggi.</sample>
    <sample id="286">Questa tabella riporta l'accuratezza complessiva dei risultati. Abbiamo trovato che tutti i modelli di linguaggio online ottengono risultati insoddisfacenti per quanto riguarda la pianificazione per obiettivi specifici.</sample>
    <sample id="287">Poi eseguiamo un'analisi dettagliata per investigare perché le reti neurali falliscono.</sample>
    <sample id="288">I risultati nella figura mostrano che la completezza semantica nei script generati è accettabile, ma la fedeltà alle restrizioni non può essere garantita.</sample>
    <sample id="289">Diamo un'occhiata alle categorie di restrizioni più granulari in WikiHow. La mappa a caldo nella figura mostra che le prestazioni di pianificazione di InstructGPD variano notevolmente per obiettivi di diverse categorie.</sample>
    <sample id="290">Studi precedenti hanno dimostrato che la qualità di output dei modelli di reti neurali presenta una varianza elevata, che porta a una pessima prestazione. Pertanto, adottiamo l'idea del filtro over-generated per migliorare la qualità della generazione.</sample>
    <sample id="291">Per prima cosa, mostrare i tipi di vincoli con esempi per il modello di istruzione GPT e ottenere obiettivi specifici basati sugli obiettivi astratti definiti.</sample>
    <sample id="292">Mi dispiace, ma non capisco cosa stai chiedendo. Potresti fornire più dettagli?</sample>
    <sample id="293">Un modello di filtro viene sviluppato per selezionare le scritture più adatte.</sample>
    <sample id="294">Convertiamo i script e i testi in vettori di embedding di GPT e calcoliamo le similitudini coseno e le punteggio di similitudine per misurare la similitudine semantica.</sample>
    <sample id="295">Rimuoviamo il script che contiene le parole chiave del target. Manteniamo solo il script se il target ha il punteggio più alto nel set di target.</sample>
    <sample id="296">Con il nostro metodo, il CBT può generare script di qualità superiore. Il nostro metodo migliora notevolmente la pianificabilità, sia in termini di completezza semantica che di fedeltà alle restrizioni.</sample>
    <sample id="297">Poiché i modelli di linguaggio sono costosi da deporre, è essenziale abilitare la capacità di pianificazione linguistica di modelli più piccoli e specializzati. La creazione di un dataset è un passo essenziale per questo scopo.</sample>
    <sample id="298">Tuttavia, gli studi precedenti non consentono di pianificare per obiettivi specifici e l'annotazione manuale del dataset è costosa.</sample>
    <sample id="299">Pertanto, seguiamo l'idea di distillazione del sapere simbolico per distillare i dati di pianificazione del linguaggio vincolati da modelli di livello basso.</sample>
    <sample id="300">Vedremo di applicare il nostro metodo per la costruzione di un dataset di pianificazione linguistica congiunta, chiamato CoScript.</sample>
    <sample id="301">In totale generiamo 55.000 script di test specifici. Per assicurare la qualità delle test site di validazione, chiediamo ai lavoratori di crowdsourcing di trovare e correggere le campioni errati.</sample>
    <sample id="302">Questa figura mostra la distribuzione dei vincoli di CoScribe. Troviamo che CoScribe mostra un'alta plausibilità nei generati specifici. Con CoScribe possiamo addestrare modelli più piccoli ma specializzati per la pianificazione linguistica con vincoli.</sample>
    <sample id="303">Abbiamo scoperto che il funzionamento di T5L su un set di dati specifico può generare script di qualità superiore rispetto a molti modelli di grandi dimensioni, indicando che modelli più piccoli possono superare i modelli più grandi quando sono adeguatamente addestrati su set di dati idonei.</sample>
    <sample id="304">Abbiamo stabilito il problema di pianificazione del linguaggio con vincoli. Abbiamo valutato la capacità di pianificazione del linguaggio con vincoli dei modelli di linguaggio e abbiamo sviluppato un metodo di filtro per i modelli di linguaggio che sovragera.</sample>
    <sample id="305">Utilizziamo grandi modelli di linguaggio per generare un dataset di codice di alta qualità per la pianificazione del linguaggio con vincoli. Speriamo che il dataset di codice possa essere un risorsa preziosa per avanzare la ricerca sulla pianificazione del linguaggio.</sample>
    <sample id="306">Mi dispiace, ma non ho accesso al contenuto del tuo documento. Potresti fornirmi più informazioni su cosa esattamente stai cercando in quel codice script? Così posso aiutarti meglio.</sample>
    <sample id="307">La fluidità di PaLM è comparabile a quella dei sistemi di punta.</sample>
    <sample id="308">Prima, il metodo deve essere applicabile all'inserimento di servizi. Secondo, la filigrana non deve indebolire l'utilità dei servizi forniti. Terzo, la filigrana deve essere abbastanza nascosta per l'attaccante, altrimenti l'attaccante può eliminarla facilmente. Quarta, la filigrana deve essere trasferibile ai servizi dell'attaccante durante il processo di estrazione del modello.</sample>
    <sample id="309">Mi dispiace, non ho la lista delle 14 lingue specifiche. Potresti cercare su un sito ufficiale TED o un database di traduzioni. Se hai altre domande su TED Talks, sono qui per aiutarti.</sample>
    <sample id="310">Il testo non specifica quanti esempi vengono campionati per la riannotazione.</sample>
    <sample id="311">La cos e l2 similitudine.</sample>
    <sample id="312">Sono stati valutati in due gruppi di modelli. Uno è il gruppo di modelli basati su codificatori multilingue con decodificatori a base di puntatore, come XLM-R + PDR e BERT + PDR. L'altro gruppo è il gruppo di modelli basati su codificatori e decodificatori, come M-BART e MT5. Se hai altre domande, puoi chiedere.</sample>
    <sample id="344">Gli autori selezionano un set di parole di frequenza moderata basandosi su un corpus di testo generale raccolto dal provider e contando la frequenza delle parole.</sample>
    <sample id="345">Ciao a tutti. Il mio nome è Shuheng. Oggi presenterò il nostro articolo "Do Cornell 2003 Named Entity Taggers still work well in 2023?". Iniziamo.</sample>
    <sample id="346">Il nostro articolo ha indagato il problema della generalizzazione utilizzando la compito di riconoscimento di entità nominative, NER.</sample>
    <sample id="347">Abbiamo osservato che i modelli hanno utilizzato CoNLL-2003 per lo sviluppo di NER per quasi 20 anni e questo naturalmente solleva diversi problemi. In primo luogo, questi modelli possono generalizzare a dati moderni?</sample>
    <sample id="348">Quando sviluppiamo nuovi tagger, cosa serve per una buona generalizzazione?</sample>
    <sample id="349">Al tempo stesso, se osserviamo una pessima generalizzazione, cosa causa il calo di prestazione di questi modelli?</sample>
    <sample id="350">Per investigare questi problemi, abbiamo sviluppato il dataset Conll +. Questo è un dataset che abbiamo raccolto da Reuters News nel 2020 e poi annotato con le stesse linee guida di annotazione Conll 2003.</sample>
    <sample id="351">Abbiamo finetunato oltre 20 modelli su CoNLL-2003. Li abbiamo valutati sia sul set di test CoNLL-2003 che sul set di test CoNLL++.</sample>
    <sample id="352">E, per concludere, abbiamo calcolato il cambiamento percentuale in F1 per valutare la generalizzazione di ciascun modello.</sample>
    <sample id="353">Per una buona generalizzazione, ci sono tre ingredienti principali che sono necessari.</sample>
    <sample id="354">La prima è l'architettura del modello. Nelle nostre esperimenti, abbiamo trovato che i modelli transformer normalmente generalizzano meglio a nuovi dati.</sample>
    <sample id="355">Il secondo ingrediente è la dimensione del modello. Abbiamo trovato che, di solito, modelli più grandi portano a una migliore generalizzazione.</sample>
    <sample id="356">E, per finire, tutti sappiamo che il numero di esempi di finetuning ha un effetto diretto sulle prestazioni di una task a basso livello. Qui abbiamo anche scoperto che più esempi di finetuning porta a una miglior generalizzazione.</sample>
    <sample id="357">Cosa causa la diminuzione delle prestazioni di alcuni modelli?</sample>
    <sample id="358">Abbiamo due ipotesi. La prima è l'overfitting adattivo, che è l'overfitting causato dal riutilizzo della stessa test set ripetutamente. Questo si manifesta solitamente come una diminuzione dei ritorni su un nuovo test set.</sample>
    <sample id="359">La seconda ipotesi è il drift temporale, che è il degrado delle prestazioni causato dallo scarto temporale crescente tra i dati di addestramento e di test.</sample>
    <sample id="360">Per quanto riguarda l'overfitting, abbiamo visto che dalla grafica a destra la linea di miglior fit rossa ha una pendenza maggiore di 1.</sample>
    <sample id="361">Questo significa che ogni unità di miglioramento che abbiamo fatto su Cono 2003 si traduce in più di una unità di miglioramento su Cono Plus, che significa che non ci sono ritorni decrescenti.</sample>
    <sample id="362">E questo ci mostra che, in questo caso, non si osserva sovrappopolamento adattivo.</sample>
    <sample id="363">Quindi, cosa c'è da dire sul tempo?</sample>
    <sample id="364">Per il drift temporale, abbiamo fatto un esperimento per riformare o continuare a preformare alcuni modelli con dati più recenti e abbiamo scoperto che la prestazione peggiora con un gap temporale più grande.</sample>
    <sample id="365">E conferma la nostra ipotesi che la principale causa della diminuzione del rendimento è la temperatura.</sample>
    <sample id="366">La nostra conclusione è che, per una buona generalizzazione, avremmo bisogno di una migliore architettura del modello, di un modello di dimensione maggiore e di esempi di finetuning in più, e questi obiettivi andano di pari passo. Non possiamo avere solo un ingrediente, ma tutti insieme.</sample>
    <sample id="367">Al tempo stesso, abbiamo anche scoperto che il calo di prestazioni qui è causato da drift temporale e, sorprendentemente, non è causato da adattamento o overfitting, anche se Connell 2003 è stato utilizzato per oltre 20 anni.</sample>
    <sample id="368">Quindi tornando alla domanda che abbiamo sollevato nel titolo del nostro articolo, funzionano ancora i tag di Connell 2003 nel 2023? E abbiamo scoperto che la risposta è un risoluto sì.</sample>
    <sample id="369">Speriamo che il nostro articolo possa stimolare più ricerche su come migliorare la generalizzazione dei modelli.</sample>
    <sample id="370">E inoltre, assicurati di controllare il nostro articolo e il nostro set di dati. Se hai alcune domande, non esitare a farmele sapere. Grazie mille.</sample>
    <sample id="397">The approach uses a segment size of 10 seconds.</sample>
    <sample id="398">Nell'esempio con Servin e Kea, sono necessarie le conoscenze specifiche dell'entità come "Servin è un giudice". Questa conoscenza specifica dell'entità è importante per risolvere il pronome "he" e capire a chi si riferisce. Se hai altre domande o vuoi discutere di questo argomento in modo più approfondito, sentiti libero di chiedere.</sample>
    <sample id="399">La qualità dell'esempio.</sample>
    <sample id="400">L'articolo si concentra sugli modelli linguistici GPT serie.</sample>
    <sample id="401">Non c'è informazione sufficiente nel testo per rispondere a questa domanda. Potresti fornire ulteriori dettagli?</sample>
    <sample id="402">Gli esempi di inferenza diretta sono direttamente riferirsi al nome della canzone, ad esempio "The Name of the Song is 'Easy on Me'", o alla sua posizione, come "The First One".</sample>
    <sample id="403">I'm not sure. I don't have enough information to answer that. You could try looking for more details in the article itself.</sample>
    <sample id="404">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più dettagli?</sample>
    <sample id="405">No.</sample>
    <sample id="406">The authors gave the example of "woman warrior" as a marked group.</sample>
    <sample id="407">Non hai fornito informazioni su quali architetture dei modelli non generalizzano in modo adeguato. Potresti fornire ulteriori dettagli?</sample>
    <sample id="408">Non so.</sample>
    <sample id="409">There are three authors involved in the article.</sample>
    <sample id="410">L'autore opera con più modalità.</sample>
    <sample id="439">The authors don't mention any area of NLU that is little studied in this statement.</sample>
    <sample id="440">I nomi dei relatori sono Ying e Zhiyang.</sample>
    <sample id="441">Yes, Coscript has been subject to quality controls.</sample>
    <sample id="442">Le risorse esistenti supportano solo tipi limitati di traduzioni dipendenti dal contesto e set di lingue limitati.</sample>
    <sample id="443">Ciao. Volevo parlare del nostro lavoro sul risolvere le espressioni di riferimento indirette per la selezione di entità. In cui abbiamo introdotto l'entity score.</sample>
    <sample id="444">Il mio nome è Javad Hosseini e questo è un lavoro congiunto con Filip Radlinski, Silvia Parodi e Aric Wiss.</sample>
    <sample id="445">Certo. "Il nostro obiettivo è capire la lingua degli utenti quando vogliono prendere una decisione. Considera questa domanda alternativa: "Volevi dire 'Easy on Me' o 'I Got a Feeling'? Qui un utente vuole scegliere tra una di queste due canzoni."</sample>
    <sample id="446">La cosa più ovvia è usare un riferimento diretto, ad esempio, dicendo "Il nome della canzone è "Easy on Me" o la sua posizione, la prima."</sample>
    <sample id="447">Ma a volte un riferimento indiretto è più appropriato per avere una conversazione più naturale. Questo potrebbe accadere quando l'utente non riesce a ricordare il nome della canzone.</sample>
    <sample id="448">Non so cosa specificamente tu vuoi tradurre. Puoi fornire il contenuto inglese che vuoi che io traduca in italiano?</sample>
    <sample id="449">Quando il utente vuole specificare una preferenza. Ecco alcuni esempi di frasi indirette, ad esempio "il più recente" o "la canzone che non è energica".</sample>
    <sample id="450">Questo è un problema importante nei sistemi di conversazione e anche per il benchmarking degli algoritmi di comprensione dell'entità.</sample>
    <sample id="451">Non eravamo a conoscenza di un dataset pubblico di grandi dimensioni per il test, quindi abbiamo raccolto uno utilizzando la curatela di massa. Il nostro dataset copre tre temi diversi: musica, libri e ricette.</sample>
    <sample id="452">La nostra metodologia di raccolta dei dati enfatizza l'informalità utilizzando un set di completamento di cartoni.</sample>
    <sample id="453">Nel primo bollo Bob dice: "Ricordi quella canzone che ascoltavamo ieri?" E con questo Bob mette in contesto il dialogo.</sample>
    <sample id="454">Nel secondo boccale di discorso, Alice dice: "Credi che sia facile per me o ho un sentimento?"</sample>
    <sample id="455">C'è un'altra domanda?</sample>
    <sample id="456">Il primo palloncino di discorso viene scelto tra pochi promossi manualmente per domanda.</sample>
    <sample id="457">Mi dispiace, ma non hai fornito il contenuto inglese che vuoi tradurre in italiano. Potresti dirmi cosa c'è da tradurre?</sample>
    <sample id="458">Non ho capito bene la tua domanda. Potresti fornire più dettagli o chiarire cosa stai cercando?</sample>
    <sample id="459">Quando ci spostiamo più in alto nella lista, le entità diventano più simili tra loro e spesso è più difficile fare la disambiguazione.</sample>
    <sample id="460">Il primo è "uniforme".</sample>
    <sample id="461">La seconda è quando le entità hanno titoli simili, ad esempio due libri con il nome "The Return".</sample>
    <sample id="462">Il terzo caso è quando hanno descrizioni simili su Wikipedia e infine quando hanno info box o attributi simili su Wikipedia, ad esempio la stessa genere o lo stesso artista per una canzone.</sample>
    <sample id="463">Quando mostriamo questa domanda alternativa agli ambasciatori, essi conoscono il nome di queste entità, ma non necessariamente sanno qualcosa sulle entità stesse.</sample>
    <sample id="464">Quindi cosa facciamo è mostrare un po' di conoscenza di fondo riguardo alle due entità. Per le canzoni, semplicemente mostriamo un link di ricerca su Google per ciascuna canzone.</sample>
    <sample id="465">Ecco un esempio di risultato di ricerca Google per la canzone "Easy".</sample>
    <sample id="466">Per il dominio di ricette e libri, mostriamo alcuni testi di sfondo da Wikipedia. Per le ricette, inoltre, mostriamo le loro immagini, anch'esse da Wikipedia, affinché gli annotatori sappiano come si presentano.</sample>
    <sample id="467">Allora chiediamo agli annotatori di scegliere una di queste entità, ad esempio la prima, e descriverle utilizzando tre a cinque espressioni indirette diverse.</sample>
    <sample id="468">Per esempio, il tipo con la musica per pianoforte. Ecco alcuni esempi dal nostro set di dati. Per esempio, il tipo senza parole, non il tipo con il ragazzino di 12 anni o il tipo fittizio o proveniente da altri generi musicali.</sample>
    <sample id="469">Il corpus di Entities ha 6.000 domande alternative in tre domini e 42.000 espressioni di riferimento indiretto. Risorse con il modello T5x large o riassunte.</sample>
    <sample id="470">Se il modello di linguaggio ha accesso alla stessa conoscenza di fondo degli annotatori, la precisione è veramente alta, intorno al 92 - 95%. Ma questo non è realistico.</sample>
    <sample id="471">Se il modello linguistico ha accesso a qualche conoscenza di fondo parzialmente sovrapposta, allora la precisione è tra il 82% e il 87%, che è più realistico, ad esempio quando il modello linguistico recupera la conoscenza di fondo.</sample>
    <sample id="472">Se il modello linguistico ha accesso solo ai nomi di entità, allora l'accuratezza è solo del 60%, quindi c'è molto spazio per migliorare. Abbiamo anche dimostrato che i modelli sono generalizzabili in ambito di dominio. Ecco il link al dataset. Grazie.</sample>
    <sample id="473">The weight keys strategy and the local agreement are the offline models' strategies that SimulST is compared with.</sample>
    <sample id="474">Mi dispiace, non ho informazioni sulle affiliazioni degli autori dell'articolo. Potresti cercare su Google Scholar o sul sito del rivista?</sample>
    <sample id="475">Jenny.</sample>
    <sample id="476">Tre.</sample>
    <sample id="477">Ciao， sono Sarah Pape， dall'Università di Toronto e dalla Fondazione Bruno Kessler. Verrò a presentare brevemente "The Attention as a Guide for Simultaneous Speech Translation"， un lavoro a joint con Matteo Negri e Marco Zorcic.</sample>
    <sample id="478">La traduzione simultanea vocale, o Simultaneous Speech Translation, SST, è il processo di tradurre il linguaggio parlato in testo in un'altra lingua in tempo reale, permettendo la comunicazione tra lingue diverse.</sample>
    <sample id="479">E cosa sono i problemi dei modelli attuali di simulazione? Le architetture specifiche sono solitamente addestrate introducendo moduli aggiuntivi da ottimizzare.</sample>
    <sample id="480">Procedimenti di addestramento lunghi e complessi, ad esempio addestramento coinvolgente di diversi obiettivi di ottimizzazione.</sample>
    <sample id="481">Addestrare e mantenere diversi modelli per raggiungere diversi regimi di latenza, ad esempio addestrare un modello con un'average di 1 secondo di latenza e un altro con 2 secondi di latenza e così via.</sample>
    <sample id="482">Certo. Ma non hai fornito il contenuto in inglese che vuoi tradurre in italiano. Potresti dirmi cosa c'è da tradurre?</sample>
    <sample id="483">Prima di tutto, utilizzare modelli di istruzione offline esistenti senza rieducazione o adozione di una specifica architettura per il CLST. Usare solo un modello per ogni regime di latenza e gestire la latenza attraverso parametri specifici.</sample>
    <sample id="484">E utilizza il contenuto già acquisito dal modello attraverso il meccanismo di attenzione tra l'input audio e l'output testuale, ovvero il meccanismo di attenzione incrociata. E puoi vedere un esempio a destra.</sample>
    <sample id="485">La nostra soluzione è di proporre un encoder-decoder con attenzione, e è una strategia in cui decidiamo di emettere o non emettere una traduzione parziale in base a dove l'attenzione punta.</sample>
    <sample id="486">Se la tensione non è concentrata, ossia se la somma è inferiore a un certo soglia alpha, verso le ultime lambda di frame di parola, significa che l'informazione ricevuta è abbastanza stabile.</sample>
    <sample id="487">Voglio parlare di.</sample>
    <sample id="488">E guarderemo i pesi di attenzione reciproca.</sample>
    <sample id="489">Vedremo che le prime due parole indicano i primi frame di parola ricevuti, mentre la parola finale indica gli ultimi frame di parola ricevuti. E poi ci sono i frame di parola lambda.</sample>
    <sample id="490">Significa che le prime due parole saranno eliminate.</sample>
    <sample id="491">Mentre la somma delle attenzioni incrociate è superiore a un certo livello α, non emetteremo l'ultimo pezzo e aspetteremo un altro frammento di discorso.</sample>
    <sample id="492">Se andiamo avanti e riceviamo un altro frammento di discorso e il nostro modello predice altri tre parole e guarderemo i pesi di attenzione incrociata.</sample>
    <sample id="493">Vedremo che noWord indica meno frame di parola.</sample>
    <sample id="494">Questo significa che queste tre parole saranno emesse.</sample>
    <sample id="495">Se guardi i principali risultati di una ricerca.</sample>
    <sample id="496">Vedremo di rappresentare i risultati simultanei di traduzione su grafici in cui avremo il blu da un lato che misura la qualità della traduzione e il verde da un altro lato che misura il ritardo medio.</sample>
    <sample id="497">La misura di latenza e consideriamo anche il calcolo consapevole di media di gradimento che tiene conto del tempo computazionale del modello per fornire l'output.</sample>
    <sample id="498">Quindi vogliamo che le cure siano il più in alto possibile su questa pianta.</sample>
    <sample id="499">Ma anche vogliamo che siano spostati a sinistra.</sample>
    <sample id="500">E compare con strategie appropriate che sono applicate anche ai modelli offline, ovvero la strategia di chiave di peso e l'accordo locale. E compare anche con l'architettura di punta specificamente adattata per la traduzione simultanea.</sample>
    <sample id="501">Mi dispiace, ma non ho capito bene la tua domanda. Potresti fornire più dettagli? Ad esempio, cosa vuoi rendere in italiano?</sample>
    <sample id="502">E vediamo che AD outperforms tutte le strategie applicate ai modelli offline poiché le loro curve sono spostate a sinistra.</sample>
    <sample id="503">E anche vediamo che se consideriamo il tempo di elusione reale o il tempo di lavoro computazionale, è la strategia più veloce.</sample>
    <sample id="504">Se vuoi scoprire più risultati, leggi il nostro articolo. Abbiamo anche rilasciato il codice e i modelli open source e il codice di simulazione per facilitare la riproducibilità del nostro lavoro. Grazie per l'attenzione.</sample>
    <sample id="505">Non so se il set di dati è disponibile pubblicamente. Potresti controllare il link o la fonte dove hai trovato questa informazione. Se hai altre domande, puoi chiedere.</sample>
    <sample id="506">Ciao a tutti. Il mio nome è Ying e il mio collega Zhiyang e io presenteremo la nostra ricerca su Multi - Instruct: migliorare l'apprendimento a zero delle multimodalità tramite l'addestramento con istruzioni.</sample>
    <sample id="507">Con l'avanzamento dei modelli di linguaggio a grandi scale, molti lavori hanno iniziato a esplorare nuove paradigmi di apprendimento per riutilizzare i modelli di linguaggio preaddestrati per compiti diurni diversi in modo efficiente in termini di parametri e dati.</sample>
    <sample id="508">Recentemente, molte ricerche hanno dimostrato che l'addestramento di istruzioni consente ai modelli di linguaggio a grandi scale di eseguire compiti di NLP in modo zero-shot seguendo istruzioni naturali.</sample>
    <sample id="509">Tuttavia, la maggior parte dei lavori precedenti sulla ottimizzazione delle istruzioni si sono concentrati sul miglioramento del presto zero-shot nelle sole compiti di lingua, mentre le compiti di visione computer e multimediali sono state trascurate.</sample>
    <sample id="510">Quindi, in questo lavoro, vogliamo investigare se l'addestramento di istruzioni a modelli preaddestrati multimodal può realmente migliorare la generalizzazione a compiti multimodal non visti.</sample>
    <sample id="511">Inoltre, durante la nostra ricerca, abbiamo scoperto una considerevole disparità nella disponibilità dei set di dati di istruzione tra LPA e multimodal.</sample>
    <sample id="512">Esistono più di 1.600 task di istruzione unicamente linguistici. Tuttavia, non esiste un dataset di istruzione multimodale di grande scala e pubblicamente disponibile. Questo ci ha motivati a costruire un dataset di istruzione multimodale per l'addestramento.</sample>
    <sample id="513">Ecco il contenuto in italiano: "Presentiamo MultiInstruct, il primo benchmark di intunamento di istruzioni multimediali che comprende 62 compiti multimediali diversi coprendo 10 categorie di base." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="514">Questi compiti sono derivati da 21 set di dati open source esistenti e ogni compito è dotato di 5 istruzioni scritte da esperti.</sample>
    <sample id="515">Per l'indagine sull'addestramento di modello multimodale con il nostro dataset proposto, prendiamo OFA, un modello preaddestrato multimodale unificato, come modello base. OFA usa un vocabolario unificato per i token di lingua, immagine e le coordinate di un rettangolo di confine.</sample>
    <sample id="516">Ecco alcuni esempi di istanze dalla nostra dataset multistrato.</sample>
    <sample id="517">Per unificare il trattamento di diversi tipi di dati di input e output.</sample>
    <sample id="518">Seguiamo il metodo di OFA e formuliamo tutte le tare in un formato di sequenza a sequenza unificato, in cui il testo di input, le immagini, le istruzioni e i box di confine sono rappresentati nello stesso spazio di token.</sample>
    <sample id="519">Mi dispiace, ma non ho capito cosa vuoi rendere in italiano. Potresti fornire il contenuto in inglese che vuoi tradurre?</sample>
    <sample id="520">Per il dataset di addestramento, utilizziamo 53 task dal gruppo NAG per l'addestramento e selezioniamo 10.000 istanze per task. Per il test, riserviamo l'intero gruppo di ragionamento comune per il test e selezioniamo altri 5 task dal gruppo VQA e il gruppo variegato.</sample>
    <sample id="521">Usiamo tutte le istanze nel set di test per ogni compito. Inoltre, estraiamo a caso 20 compiti dal set di test di Natural Instruction come compiti di sintesi per NLP.</sample>
    <sample id="522">Quindi utilizziamo un modello preaddestrato di LFA grande come modello base. Durante l'addestramento, mescoliamo tutte le istanze per tutte le tare. Ogni istanza viene combinata casualmente con uno dei suoi cinque modelli di istruzione.</sample>
    <sample id="523">Quindi durante il test, per ogni compito, condurremo un totale di cinque esperimenti valutando il modello utilizzando una delle cinque istruzioni in ogni esperimento.</sample>
    <sample id="524">Riferisci la media e la deviazione standard del rendimento in tutti e cinque gli esperimenti.</sample>
    <sample id="525">Se il compito è una classificazione multi-modello, rapportiamo l'accuratezza. Se è una generazione multi-modello, rapportiamo l'ROUGE-L. Per i compiti di NLP, rapportiamo anche l'ROUGE-L.</sample>
    <sample id="526">Abbiamo anche introdotto un altro metrica di valutazione chiamata sensibilità. Questa misura la capacità del modello di produrre sempre gli stessi output per la stessa compito, indipendentemente da lievi variazioni nella formulazione delle istruzioni.</sample>
    <sample id="527">Ecco il contenuto in italiano: "Ecco i nostri principali risultati. Come possiamo vedere, l'addestramento di istruzione può migliorare significativamente le prestazioni di OFA su compiti multiformato non visti." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="528">La trasformazione di apprendimento da dataset di istruzioni naturali può beneficiare dell'ottimizzazione delle istruzioni.</sample>
    <sample id="529">Ecco il contenuto in italiano: "Come aumenta la quantità di compiti, il modello raggiunge prestazioni migliori e, al contempo, una sensibilità più bassa." Se hai bisogno di chiarimenti o di tradurre altro, fammi sapere!</sample>
    <sample id="530">Abbiamo anche fatto un esperimento. Abbiamo utilizzato un insieme di istruzioni contro cinque insiemi di istruzioni. Come possiamo vedere, utilizzare più istruzioni può migliorare le prestazioni complessive del modello e ridurre la sua sensibilità molto.</sample>
    <sample id="531">Quindi questo mostra l'effetto di diverse strategie di finetuning sulla sensibilità del modello. Come possiamo vedere, tramite il transfer learning dal dataset di istruzioni naturali, il modello può ottenere una sensibilità molto migliore rispetto al modello originale di YF1.</sample>
    <sample id="532">Possiamo anche vedere che il trasferimento di apprendimento da dataset di istruzioni naturali può aiutare OFA a ottenere prestazioni molto migliori sul dataset di istruzioni naturali.</sample>
    <sample id="533">Quindi, in generale, abbiamo proposto il primo dataset di addestramento di istruzioni a scala larga multi-modello che ha migliorato significativamente la capacità di istruzione a lungo raggio dell'IA. Esploriamo diverse tecniche di apprendimento a trasferimento e mostriamo i loro vantaggi. Abbiamo progettato un nuovo metrico chiamato sensibilità.</sample>
    <sample id="534">Ecco il contenuto in italiano: "Un'altra cosa: stiamo raccolgendo un insieme di dati di addestramento di istruzioni multimodale molto più grande, con circa 150 task di visione e linguaggio aggiuntivi, e li stiamo per rilasciare. Questo è il codice QR per i nostri dati e il modello. Grazie."</sample>
    <sample id="535">Sarah Pape è affiliata all'Università di Toronto e alla Fondazione Bruno Kessler. Matteo Negri e Marco Zorzi non sono specificati come affiliati nell'articolo.</sample>
    <sample id="536">Il nome del relatore è Javad Hosseini.</sample>
    <sample id="562">Ciao a tutti. Sono Costas Finner e sono lieto di accogliervi al nostro talk sul nostro articolo di ACL 2023 "I giudizi di accettabilità dei modelli di linguaggio non sono sempre robusti al contesto".</sample>
    <sample id="563">C'è un lavoro di gruppo con John Gockier, Aaron Muller, Kanishka Mehta, Karen Fuentes, Roger Levy e Athena Williams.</sample>
    <sample id="564">In questo lavoro rivediamo il paradigma dei minimi paia.</sample>
    <sample id="565">Il paradigma delle coppie minimali valuta i modelli di linguaggio sulla base di giudizi di accettabilità, che possono includere grammaticalità, come sintassi errata o accettabilità in termini di stereotipi, come le coppie di cugine.</sample>
    <sample id="566">Nel paradigma del minimal pair, il modo tipico per valutare i modelli di linguaggio è mostrare una frase accettabile o grammaticalmente corretta e poi una frase non accettabile o grammaticalmente errata.</sample>
    <sample id="567">E la speranza è che il modello metta in modo più probabile le frasi accettabili.</sample>
    <sample id="568">Il pipeline attuale di MPP non ci permette di valutare l'acceptance dei modelli verso le frasi più lunghe.</sample>
    <sample id="569">Questi giorni i modelli di linguaggio a grandi scale stanno presentando finestre di contesto sempre più lunghe, quindi è cruciale valutare l'acceptability del modello attraverso tutta la finestra di contesto.</sample>
    <sample id="570">Ecco la traduzione in italiano: "E questo è ciò che stiamo cercando di fare qui. Stiamo cercando di rivedere il pipeline di T5P chiedendo al modello di valutare l'accettabilità su sequenze sempre più lunghe." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere.</sample>
    <sample id="571">Quindi, l'approccio è questo. Quindi, cosa facciamo è iniziare a simulare queste sequenze più lunghe. Rivediamo i dataset stessi e poi ricreiamo frasi scegliendo frasi accettabili o non accettabili da quei dataset.</sample>
    <sample id="572">Ecco un esempio: abbiamo scelto una coppia tipica di grammaticità dal dataset Bliem, dal caso dell'isola adiuvante.</sample>
    <sample id="573">E cosa facciamo è creare sequenze più lunghe che siano accettabili e che abbiano la stessa corrispondenza della struttura grammaticale. Estraiamo frasi grammaticali da Adjunct Island.</sample>
    <sample id="574">E poi lo aggiungiamo come prefisso sia alla query accettabile che alla query non accettabile.</sample>
    <sample id="575">Possiamo fare la stessa cosa scegliendo frasi non accettabili dallo stesso matching e questo potrebbe anche essere utilizzato per testare l'acceptability del modello.</sample>
    <sample id="576">E possiamo fare lo stesso scegliendo frasi da un sottoinsieme diverso o da un diverso dataset. Quindi questo è ciò che chiamiamo la situazione di malaccoppiamento.</sample>
    <sample id="577">Quindi le frasi stanno ancora venendo da dataset rilevanti, ma non sono dallo stesso dataset che stai valutando. E possiamo fare lo stesso per il caso di accettabilità.</sample>
    <sample id="578">Infine, possiamo scegliere frasi da un dominio completamente diverso, come Wikipedia.</sample>
    <sample id="579">Quindi questo ci dirà se le giudicazioni di accettabilità dei modelli sono effettivamente influenzate da qualsiasi contesto.</sample>
    <sample id="580">Se il contesto proviene da un sottoinsieme diverso del dataset o se è completamente irrilevante per la frase che stiamo analizzando.</sample>
    <sample id="581">Prima di tutto, guardiamo le frasi di Wikipedia che sono completamente irrellevanti al paio di query attuale. Poi scopriamo che i giudizi MPP sono in gran parte robusti per lunghezze di contesto arbitrarie.</sample>
    <sample id="582">Aumentiamo la lunghezza del contesto fino a 2024 per massimizzare i modelli OPT e GPT-2 e abbiamo visto qui nella linea punteggiata arancione che i giudizi MPP sono relativamente stabili.</sample>
    <sample id="583">Quando scegliamo frasi dallo stesso dataset?</sample>
    <sample id="584">Quindi qui stiamo scegliendo o creando frasi da domini accettabili e non accettabili dallo stesso dataset di testo di Blimp.</sample>
    <sample id="585">E là vediamo che le giudicanti MPP aumentano o diminuiscono significativamente quando si aggiungono sia prefissi accettabili sia prefissi non accettabili.</sample>
    <sample id="586">Ma quando si adatta la struttura， ossia quando si sceglie le frasi da fenomeni simili nel testo di colpevolizzazione.</sample>
    <sample id="587">Vediamo un aumento o una diminuzione massiva della valutazione MPP del modello a seconda di se il prefisso scelto è accettabile o non accettabile.</sample>
    <sample id="588">E questo è molto grande come questo effetto aumenta a lungo termine e questo probabilmente influenzerà come i nuovi modelli di linguaggio che hanno un ampio finestra di contesto.</sample>
    <sample id="589">The match prefix can affect the language model's judgment a great deal because it provides important context. It helps the model understand the meaning of the text better. For example, if the match prefix is a common phrase or a specific word, it can guide the model in predicting the next words more accurately. So, it really plays a crucial role in how the model makes its judgments.If you have any other questions about this or want to discuss more about language models, feel free to let me know.</sample>
    <sample id="590">Ecco la traduzione in italiano: "Quindi abbiamo fatto una serie di analisi in cui abbiamo cercato di perturbare la frase d'ingresso, tentando di preservare la struttura rilevante, ma aggiungendo rumore all'ingresso. Dopo aver fatto diverse di queste perturbazioni." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="591">Ritroviamo che nessuno di questi rumori sta realmente facendo che il modello cambi la sua traiettoria in termini di come ci mostra che le feature sono state addestrate.</sample>
    <sample id="592">In sostanza, troviamo che i modelli sono sensibili alle perturbazioni di frasi in modo simile.</sample>
    <sample id="593">Quando perturbiamo le frasi nell'area accettabile, vediamo un aumento simile in tutte le perturbazioni. Quando perturbiamo le frasi nell'area non accettabile, vediamo una diminuzione delle giudicanti MPP in modo simile.</sample>
    <sample id="594">I principali punti da ricordare del nostro lavoro sono che i modelli di linguaggio sono sensibili alle caratteristiche sintattiche e semantiche latenti che sono condivise tra le frasi.</sample>
    <sample id="595">E l'evaluation del MPP, la maniera in cui lo facciamo attualmente con input brevi e singole frasi, potrebbe non catturare completamente il knowldege astratto del modello linguistico attraverso il contesto.</sample>
    <sample id="596">Per favore, leggi il nostro articolo per ulteriori dettagli sulle nostre esperimenti. Ti ringraziamo per l'ascolto.</sample>
    <sample id="597">unordered multiset</sample>
    <sample id="598">55,000.</sample>
    <sample id="626">Il metodo di allineamento migliore per DEplain è il metodo di mass align.</sample>
    <sample id="627">Non c'è una domanda specifica in inglese per cui rispondere. Potresti fornire una domanda più chiara?</sample>
    <sample id="628">The documents in DEplain-web were aligned using both manual and automatic alignment methods. The exact allocation process is not specified in the given text.</sample>
    <sample id="629">Il set di dati CoNLL++ è stato creato raccolgendo notizie da Reuters nel 2020 e poi annotandole secondo le stesse linee guida di annotazione del CoNLL 2003.</sample>
    <sample id="630">Ciao a tutti. Mi chiamo Justin John e sono dell'Università di Pennsylvania. Oggi presenterò il nostro lavoro: "Esempi di analisi semantica multilingue in diverse lingue naturali e rappresentazioni mentali.".Se hai bisogno di ulteriori informazioni o hai domande, non esitare a chiedere.</sample>
    <sample id="631">La semantica di parsing è una task per costruire rappresentazioni semantiche di query di utente come SQL e Lambda Calculus.</sample>
    <sample id="632">La traduzione in italiano è: "La semantica parallela è il compito di tradurre query in più lingue naturali in più rappresentazioni di significato." Se hai bisogno di chiarimenti o hai altre domande, fammi sapere.</sample>
    <sample id="633">Come mostrato nella figura, dobbiamo tradurre la query in diverse lingue naturali utilizzando modelli neurali in SQL, Lambda o FunQL ecc.</sample>
    <sample id="634">Esistono modelli di parsing semantico interlingua già proposti e valutati su set di dati di compiti e applicazioni limitati, ad esempio.</sample>
    <sample id="635">C'è un'assenza di copertura su certe lingue naturali.</sample>
    <sample id="636">C'è un gap di copertura su certe rappresentazioni di minore importanza.</sample>
    <sample id="637">Il calcolo lambda è mancante.</sample>
    <sample id="638">O forse sono valutati solo su certi modelli neurali, ad esempio esiste solo un singolo modello per valutarli.</sample>
    <sample id="639">Per questo scopo, proponiamo Exemplar, che fornisce un insieme di dati uniforme per la semantica di collegamento tra lingue in diverse rappresentazioni naturali.</sample>
    <sample id="640">Contiene 90 dataset in diversi domini, 5 task di parsing semantico, 8 milioni di rappresentazioni e 22 lingue naturali in 15 famiglie linguistiche.</sample>
    <sample id="641">E per valutare meglio il nostro benchmark, consideriamo le sei impostazioni per l'addestramento e l'analisi.</sample>
    <sample id="642">Il primo è il test di traduzione. Utilizziamo l'API di Google Translate per tradurre il testo fontale in lingua di destinazione. Poi utilizziamo il modello monolinguale per la formazione e l'valutazione.</sample>
    <sample id="643">Ad esempio, abbiamo addestrato un modello in inglese su query in inglese e durante l'infersis, traduciamo la query in tedesco utilizzando un API in inglese e poi utilizziamo il modello addestrato per prevedere il SQL.</sample>
    <sample id="644">E testeremo anche il modello monolinguale.</sample>
    <sample id="645">Non capisco bene la tua domanda. Potresti fornire il contenuto in inglese che vuoi tradurre in italiano?</sample>
    <sample id="646">Abbiamo anche testato la configurazione di fusione monolinguale, addestrando modelli monolinguali con solo il 10% dei dati di addestramento.</sample>
    <sample id="647">E testa un modello multilingue, che addestra un modello multilingue per tutte le lingue.</sample>
    <sample id="648">Ad esempio, mettiamo insieme le query in tedesco, inglese e cinese per addestrare un modello multilingue e durante l'inferezione possiamo utilizzare questo modello.</sample>
    <sample id="649">Non capisco bene la tua domanda. Se vuoi tradurre un contenuto in inglese in italiano, puoi fornire il contenuto in inglese e io lo tradurrò per te.</sample>
    <sample id="650">E consideriamo anche il trasferimento zero-shot e few-shot tra lingue. Alleniamo su una lingua di origine e trasferiamo su un'altra lingua.</sample>
    <sample id="651">Quindi durante l'addestramento, addestreremo su query in inglese o su una combinazione di query brevi in inglese e tedesco per addestrare un modello multilingue e prevedere l'output SQL.</sample>
    <sample id="652">E anche troviamo molti risultati interessanti. Quindi, riguardo all'analisi dei modelli monolinguistici, valuteremo due gruppi di modelli.</sample>
    <sample id="653">Includendo il PTR, che sta per encoder multilingue preaddestrati con decoder basati su pointer, come XLM-R + PTR e BERT + PTR.</sample>
    <sample id="654">E valutiamo anche i modelli encoder-decoder, che sono modelli encoder-decoder multilingue preaddestrati, come M - BART e M - T - 5.</sample>
    <sample id="655">Abbiamo trovato che l'encoder-decoder ottiene la migliore prestazione su tutti e nove i dataset.</sample>
    <sample id="656">Evaluiamo su MT - 5 e XLM - R + PDR in un contesto multilingue.</sample>
    <sample id="657">Abbiamo scoperto che l'encoder-decoder o l'encoder-PTR possono essere migliorati addestrando in una miscela di varie lingue.</sample>
    <sample id="658">E abbiamo scoperto che questo perché la maggior parte delle lingue naturali principali può ottenere un miglioramento di prestazioni, eccetto che per l'inglese, la cui prestazione diminuisce in sette set di dati e aumenta solo in tre set di dati.</sample>
    <sample id="659">Credo che questo sia noto come "maldizione della multilinguismo". Se hai bisogno di tradurre altro, fammi sapere.</sample>
    <sample id="660">Abbiamo anche confrontato il gap di prestazione tra lingue diverse.</sample>
    <sample id="661">Nella figura la linea blu rappresenta il trasferimento di linguaggio tra lingue diverse, la linea arancione rappresenta il trasferimento di linguaggio zero-shot tra lingue diverse, mentre la linea verde rappresenta la configurazione del modello di linguaggio.</sample>
    <sample id="662">Abbiamo trovato che, confrontando la linea verde e la linea arancione, per il setting zero-shot, il gap di prestazione della trasferimento tra lingue è significativo. Confrontando la linea blu e la linea arancione, abbiamo trovato che, per il setting few-shot, il gap di trasferimento si riduce rapidamente.</sample>
    <sample id="663">Abbiamo anche trovato alcuni altri interessanti risultati. Ad esempio, l'encoder-decoder ha superato il lavoro precedente o ha ottenuto risultati paragonabili per la traduzione di lingue naturali in inglese e ha significativamente migliorato le prestazioni di FewShot per lingue target naturali.</sample>
    <sample id="664">Ecco la traduzione in italiano: "E siamo trovati che i modelli multilingue come Codex e Bloom sono ancora insufficienti per le compiti di parsing semantico interlingue." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="665">Ecco la traduzione in italiano: "Costruiremo Exemplar, un benchmark unificato per il parsing semantico a diversi angoli con diverse lingue naturali e rappresentazioni semantiche." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="666">Eseguiamo una completa analisi di benchmark su tre tipi rappresentativi di modelli multilingue. I nostri risultati mostrano molte interessanti scoperte. E così via. E benvenuti a visitare il nostro articolo e il codice. Grazie per l'ascolto.</sample>
    <sample id="667">I lavori connessi sono quelli che appartengono alle quattro categorie esistenti. Ma non hai detto quali siano le quattro categorie. Potresti dirmelo?</sample>
    <sample id="668">No, they are still inadequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="695">Induce l'alignment come parte della formazione.</sample>
    <sample id="696">L'equità di un modello NLP a valle si riferisce a come il modello tratta diverse categorie di dati o gruppi di persone in modo equo e non discriminatorio. Se un modello è equo, dovrebbe fornire risultati simili per input simili indipendentemente da fattori come la razza, il genere o l'età.</sample>
    <sample id="697">Yanis Lavoie.</sample>
    <sample id="698">Costa Senna.</sample>
    <sample id="699">Myra.</sample>
    <sample id="700">Il tropicalismo indica un insieme di stereotipi e immagini associate alle donne latine, come essere vibranti e curvilinee.</sample>
    <sample id="701">Gli autori hanno elaborato le rappresentazioni umane dei gruppi target attraverso parole come cultura, tradizione, orgoglio e esotico. Queste parole definiscono i gruppi solo in relazione alla loro identità e li distinguono come diversi dalla norma bianca.</sample>
    <sample id="702">P6CXML è stato utilizzato per misurare l'utilizzo del contesto in questo lavoro.</sample>
    <sample id="703">DrBERT è una versione con 7GB di NACOS, mentre ChuBERT ha 4GB di frasi prese da ClinConsort. ChuBERT ha una versione finale con un mix di 4GB di NACOS e 4GB di ClinConsort.</sample>
    <sample id="751">Due.</sample>
    <sample id="752">Il trasferimento iterativo dell'apprendimento è un metodo che aggiorna il modello con nuovi dati raccolti da ogni ciclo di apprendimento attivo e annotazione. Accumula tutti i dati raccolti finora e aggiorna il modello iterativamente, addestrandolo sul set di dati più recente raccolto.</sample>
    <sample id="753">The goal of the dataset is to understand the user's language when they want to make a choice.</sample>
    <sample id="754">Non ho abbastanza informazioni per rispondere a questa domanda. Potresti fornire ulteriori dettagli?</sample>
    <sample id="755">Tre. Se hai altre domande su questo articolo, sentiti libero di chiedere.</sample>
    <sample id="756">Non so quanti annotatori sono stati impiegati per creare il set di dati iniziale. Potresti cercare di trovare questa informazione in documenti o relazioni ufficiali sul progetto. Se hai altre domande o se vuoi discutere di questo argomento, sono qui per te.</sample>
    <sample id="757">Sebastian Santi, Ronan Le Bras, Katerina Rineka e Morten Sapp sono affiliati all'University of Washington e all'Allen Institute for AI.</sample>
    <sample id="758">L'esempio in cui il governatore è a sinistra è "I saw Bart and Lisa". Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="759">I modelli all'avanguardia nei sistemi di dialogo sono quelli che utilizzano tecniche avanzate come l'apprendimento automatico, l'intelligenza artificiale e l'analisi di linguaggio naturale. Questi modelli sono in grado di comprendere e generare risposte più complesse e accurate. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="760">Perché i modelli con finestre di contesto più lunghe sono sempre più comuni.</sample>
    <sample id="761">Sì.</sample>
    <sample id="762">No, gli annotatori non necessariamente conoscono l'entità in anticipo.</sample>
    <sample id="763">Non so qual è il contenuto inglese di cui stai parlando. Puoi fornire più dettagli?</sample>
    <sample id="764">No, il regresso nella generalizzazione non influisce su specifici tipi di NER. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="765">La posizionalità nella NLP è importante perché influisce sulla comprensione del significato di una parola o frase. Ad esempio, "bank" può significare "banca" o "piede" a seconda della posizione. Questo aiuta a migliorare l'accuratezza delle analisi e del traducono. Se hai altre domande su NLP, sentiti libero di chiedere.</sample>
    <sample id="766">I LLM multilingue come BLOOM sono stati affinati con una messa a punto integrale.</sample>
    <sample id="767">Non so qual è il modello specifico che fanno ricorso per il trasferimento dell'apprendimento. Potresti dare più dettagli o chiarire meglio la tua domanda?</sample>
    <sample id="768">I recenti set di test utilizzati per valutare le capacità di PaLM includono test di comprensione del linguaggio, test di generazione di testo, test di comprensione visiva e test di comprensione del linguaggio naturale. Se hai altre domande su PaLM o test, puoi chiedere.</sample>
    <sample id="769">Tre.</sample>
    <sample id="770">Non so qual è il guadagno del metodo proposto rispetto al metodo di riferimento. Potresti dare più dettagli o informazioni?</sample>
    <sample id="771">The name of the presenter is Shuheng.</sample>
    <sample id="772">Sì， i risultati e il set di dati nell'articolo possono essere utilizzati come parametri di riferimento. Se hai altre domande su questo argomento， puoi chiedere pure.</sample>
    <sample id="773">Non so quanti modelli più piccoli vengono utilizzati nell'articolo. Potresti dare più dettagli o informazioni?</sample>
    <sample id="774">OFA viene utilizzato come modello di base per analizzare l'ottimizzazione delle istruzioni multimodal.</sample>
    <sample id="833">L'autore, Aida Villar, lavora con i colleghi di Google Translate.</sample>
    <sample id="834">I'm not sure about the specific affiliations of the authors of your paper. You might need to check the paper itself or the conference website for that information. But it's great that you have a paper accepted at ACL 2023! If you have any other questions about your work or the conference, feel free to ask.</sample>
    <sample id="835">Non so qual è il contenuto dell'articolo. Non puoi dirmi qualcosa su di esso?</sample>
    <sample id="836">Zhang Bing.</sample>
    <sample id="837">Hanno studiato due modelli: il modello di LongImpart finetuned per produzioni di semplificazioni a livello di documento e il modello di LongImpart basato su normal finetuned per produzioni di semplificazioni a livello di frase.</sample>
    <sample id="838">53 attività vengono utilizzate per scopi di addestramento e test.</sample>
    <sample id="839">The text doesn't mention the number of authors involved in the article.</sample>
    <sample id="840">Gli autori hanno effettuato i test sui set di dati AG News， Mind， SST - 2 e IRIS Spam.</sample>
    <sample id="876">NACHOS è un dataset di dati cronologici medici raccolti da internet.</sample>
    <sample id="877">Il nome della relatrice o del relatore è Aida Villar.</sample>
    <sample id="878">La strategia del prompting ha un grande impatto sui risultati. Se hai altre domande o vuoi discutere di questo argomento in modo più approfondito, sentiti libero di chiedere.</sample>
    <sample id="879">Non so quali siano le affiliazioni degli autori dell'articolo. Potresti dare più informazioni?</sample>
    <sample id="880">Non ho informazioni su quali siano le 5 istruzioni scritte da esperti. Potresti fornire ulteriori dettagli o contesto?</sample>
    <sample id="881">Propongono un compito di risoluzione di riferimento comune progettato per verificare la capacità di utilizzare conoscenze disponibili in diverse fonti.</sample>
    <sample id="882">Ciao a tutti. Il mio nome è Aida Villar e vorrei dare un breve riassunto del mio articolo "Translation Assessment Strategies and Performance: A Joint Work with My Colleagues from Google Translate".</sample>
    <sample id="883">La lingua di Balm è un modello di linguaggio a 5,4 miliardi di parametri presentato l'anno scorso, nel 2022. È stato addestrato su una vasta collezione di testi, comprensiva di 180 miliardi di token.</sample>
    <sample id="884">Nel campo della fabbricazione, è stato raggiunto uno stato dell'arte in centinaia di linee di produzione.</sample>
    <sample id="885">Nel lavoro presentiamo lo studio sistematico iniziale del promptaggio del modello di linguaggio per la traduzione automatica.</sample>
    <sample id="886">Abbiamo valutato la capacità di traduzione dei modelli di ricerca utilizzando le migliori pratiche della comunità AMT. Questo implica l'uso dei set di test più recenti per evitare che i dati di test si sovrappongano con i dati di addestramento del modello di linguaggio.</sample>
    <sample id="887">Quando si confrontano due sistemi all'avanguardia, il sistema con la migliore prestazione in valutazione di doppia valutazione è sicuramente il migliore.</sample>
    <sample id="888">Utilizziamo metriche di intelligenza artificiale di punta e inoltre mostriamo i risultati di valutazione del modello umano basato su esperti. Infine, forniamo alcune raccomandazioni per le strategie di selezione di prompt.</sample>
    <sample id="889">La prompting ha un grande impatto sulle prestazioni dei modelli di linguaggio per la traduzione. Come possiamo vedere in un semplice esperimento, dove si utilizza la prompting a una sola volta e si forniscono due differenti prompt per la stessa frase.</sample>
    <sample id="890">La maggioranza delle frasi, 516 su 1000, la differenza osservata è di più di 1 punto di chiarezza.</sample>
    <sample id="891">E questo può arrivare fino a 40 punti di errore in casi estremi. Quindi è importante selezionare una buona strategia di prompt.</sample>
    <sample id="892">Nelle nostre esperimenti, ci siamo fermati a una strategia di prompt a cinque punti, dove segniamo le sue frasi che forniamo al sistema con la loro lingua originale.</sample>
    <sample id="893">Certo. Potresti fornire il contenuto inglese da tradurre in italiano?</sample>
    <sample id="894">Abbiamo visto che la forma effettiva del prompt non ha un grande influsso nel caso del prompt di serie.</sample>
    <sample id="895">È cruciale per il zero e uno shot prompting e quando passiamo, come nel nostro caso, al cinque shot prompting, c'è quasi nessuna differenza nella forma effettiva del prompting.</sample>
    <sample id="896">E sono gli esempi che portano la maggior parte del peso.</sample>
    <sample id="897">Il riassunto dei risultati sperimentali è che la qualità dell'esempio è più importante della somiglianza con la frase di riferimento.</sample>
    <sample id="898">Quindi è importante selezionare esempi da traduzioni di alta qualità. In particolare, confrontiamo la selezione di prompt dai dati di addestramento delle valutazioni WMT o dai dati di test.</sample>
    <sample id="899">I dati di sviluppo sono molto più curati e di qualità superiore rispetto ai dati di addestramento. Sono più ordinati e i risultati sono migliori quando si utilizzano i dati di sviluppo.</sample>
    <sample id="900">Tuttavia, i sistemi di traduzione specializzati hanno un vantaggio sostanziale rispetto ai traduttori umani. Tuttavia, Pan si avvicina abbastanza a un sistema commerciale. Nella nostra situazione, abbiamo scelto di operare con Google Translate.</sample>
    <sample id="901">Le conoscenze che abbiamo acquisito dall'analisi di email utilizzando il framework MKM sono che la fluidezza di Palm è paragonabile a quella dei sistemi all'avanguardia, ma la principale differenza deriva dalla precisione.</sample>
    <sample id="902">In particolare, gli errori più comuni sono gli errori di omissione.</sample>
    <sample id="903">Palm sceglie di produrre una traduzione migliore, a volte eliminando parti della frase di partenza che non sono importanti nella traduzione.</sample>
    <sample id="904">Tuttavia, la categoria di stile di software per il sistema è inferiore a quella per i sistemi di punta, che è un altro segnale.</sample>
    <sample id="905">Quel modulo fornisce un output veramente fluido, ma ha ancora alcuni problemi di accuratezza.</sample>
    <sample id="906">Ecco tutto per questa breve panoramica. Per ulteriori dettagli, vi prego di venire alla presentazione completa del documento. Grazie mille.</sample>
    <sample id="907">Ciao， sono Dawei， un dottorando all'Università di Stoccarda in Germania. Nella video vorrei presentare il nostro lavoro recente "Wegereit denkt nicht"， un'analisi critica del tasso di sussidi settimanali.</sample>
    <sample id="908">Questa è una collaborazione con Xiaoyu Shen, Mario Smusba e gli ospiti Stefan e Detis Clarko.</sample>
    <sample id="909">Vorrei iniziare con una breve introduzione alla supervisione del week supervision e alla supervisione settimanale.</sample>
    <sample id="910">Nella supervisione debole non etichettiamo manualmente i dati. Invece etichettiamo i dati utilizzando fonti di etichettatura debole, come semplici regole heuristiche, basi di conoscenza o sorgenti di qualità bassa di crowdsourcing, come illustrato nella figura a destra.</sample>
    <sample id="911">Quando confrontati con le annotazioni umane, le annotazioni di macchina sono molto più economiche, ma sono anche rumorose, il che significa che una certa quantità di annotazioni sono errate.</sample>
    <sample id="912">Se addestriamo direttamente le reti neurali su dati etichettati a livello di esempio, le reti neurali tendono a memorizzare il rumore etichettato e non a generalizzare.</sample>
    <sample id="913">Nell'apprendimento supervisionato a bassa qualità, vengono proposti algoritmi di addestramento per addestrare robustamente reti neurali in presenza di rumore di etichetta in modo che i modelli addestrati si generalizzino bene.</sample>
    <sample id="914">Nelle recenti opere in WSL, una affermazione comune è che le persone affermano di addestrare solo modelli su dati etichettati settimanalmente e ottenere prestazioni elevate su set di test puliti.</sample>
    <sample id="915">Tecnicamente questa affermazione non è sbagliata, ma c'è un'eccezione.</sample>
    <sample id="916">Quando si assume che sia disponibile un set di validazione aggiuntivo pulito per la selezione del modello.</sample>
    <sample id="917">Il problema di questa impostazione è che implica la necessità di annotazioni manuali aggiuntive in apprendimento supervisionato. Ma, come un elefante nella stanza, questa necessità viene spesso ignorata.</sample>
    <sample id="918">Il riferito dubbio ci fa chiedere tre domande di ricerca. La prima è: è necessario il dataset di validazione pulito per WSL, o forse possiamo utilizzare un dataset di validazione rumoroso invece?</sample>
    <sample id="919">Secondo, se i dati puliti sono richiesti o se i dati puliti sono obbligatori per far funzionare WSL, allora quante campioni puliti abbiamo bisogno? Infine, dobbiamo utilizzare solo i campioni puliti per la validazione o ci sono modi migliori per utilizzarli?</sample>
    <sample id="920">Abbiamo affrontato queste domande di ricerca nel nostro lavoro e i nostri risultati sono i seguenti.</sample>
    <sample id="921">Prima di tutto, notiamo che, interessantemente, i metodi recenti di WSL richiedono effettivamente campioni di dati di addestramento puliti per funzionare correttamente.</sample>
    <sample id="922">Altrimenti ci sarà una significativa perdita di prestazioni， come mostrato in questa figura. Se non ci sono campioni di validazione puliti， allora i modelli addestrati non possono generalizzare oltre le etichette di test originali.</sample>
    <sample id="923">Significato profondo di "il training è inutile".</sample>
    <sample id="924">Questo indica che gli approcci WSL effettivamente richiedono dati ben etichettati per funzionare correttamente e il costo di annotazione per ottenere campioni di validazione puliti non dovrebbe essere trascurato.</sample>
    <sample id="925">La nostra seconda scoperta è che aumentare il numero di campioni di validazione pulita aiuterà gli approcci WSL a ottenere una prestazione migliore, come mostrato nella figura a sinistra.</sample>
    <sample id="926">Generalmente, si hanno bisogno di solamente 20 campioni per classe per ottenere prestazioni elevate.</sample>
    <sample id="927">Ma non è la fine della storia, perché se decidiamo di accedere a campioni puliti e di addestrare direttamente su di essi, otterremo addirittura prestazioni migliori.</sample>
    <sample id="928">Il grafico a destra mostra la differenza di prestazione tra approcci di finetuning che vengono applicati direttamente sui dati puliti e approcci WSL che usano i dati puliti solo per la validazione.</sample>
    <sample id="929">Come possiamo vedere, se abbiamo 10 campioni per classe, l'ottimizzazione diretta inizia a superare le approcci WSL.</sample>
    <sample id="930">Infine, l'incremento di prestazioni dichiarato in precedenti approcci WSL può essere facilmente ottenuto consentendo di continuare l'ottimizzazione su campioni di validazione puliti.</sample>
    <sample id="931">Come possiamo vedere dai grafici, il modello Valina, chiamato FTW, inizialmente sottoproduce rispetto a metodi WSL più complessi come Cosine.</sample>
    <sample id="932">Tuttavia, se decidiamo di continuare a finetunare sui campioni puliti, allora FTW si comporta altrettanto bene di altri metodi.</sample>
    <sample id="933">Quindi, in pratica, non c'è motivo di scegliere metodi WSL più complessi, che richiedono più tempo di calcolo e spazio disco.</sample>
    <sample id="934">Abbiamo dimostrato che gli approcci recenti di WSL richiedono campioni puliti e manualmente annotati per funzionare correttamente. Le loro prestazioni e praticità sono stata pesantemente sovrastimate.</sample>
    <sample id="935">Le nostre raccomandazioni concrete per il lavoro futuro sono le seguenti.</sample>
    <sample id="936">Prima di tutto, riportare i criteri di selezione del modello, ad esempio, riportare se la selezione del modello è stata fatta con campioni di validazione puliti.</sample>
    <sample id="937">Secondo, gli approcci WSL dovrebbero essere confrontati con baselines di apprendimento a corto termine, poiché entrambi operano su esempi di testo. Terzo, l'ottimizzazione continua è una baselines semplice ma potente che dovrebbe essere considerata in future work in WSL.</sample>
    <sample id="938">Infine, abbiamo reso il nostro codice open source. Puoi trovarlo attraverso il codice QR sulla diapositiva. Sentiti libero di controllarlo. Grazie e goditi la conferenza.</sample>
    <sample id="939">I metodi di valutazione comuni per i sistemi di dialogo sono l'uso di giudici umani per selezionare quale conversazione è migliore o per valutarle su una scala Likert.</sample>
    <sample id="940">Cinque. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="941">Le conoscenze di base necessarie sono quelle sul fatto che i giudici decidono casi in tribunali di diritto.</sample>
    <sample id="942">Sì, il codice è disponibile su GitHub.</sample>
    <sample id="943">No, gli annotatori per NLPositionality non sono bilanciati rispetto a ciascun gruppo demografico come Paese o genere.</sample>
    <sample id="944">Non sono state perturbate in modo specifico nel dominio accettabile.</sample>
    <sample id="945">Evaluare dimensionale significa valutare più aspetti diversi di qualcosa. Nell'ambito del dialogo, significa valutare diversi aspetti del dialogo come la coerenza, la comprensione, la naturalità delle risposte, ecc. per capire meglio le forze e le debolezze del modello. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="946">The authors are affiliated with the University of Science and Technology of China.</sample>
    <sample id="947">La forma del prompting si rivela importante in caso di zero-shot e uno-shot prompting.</sample>
    <sample id="978">Non c'è informazione specifica sui modelli di dialogo che hanno valutato gli autori nel testo.</sample>
    <sample id="979">The answer is not provided in the given English content.</sample>
    <sample id="980">Un buon pianificatore dovrebbe scrivere scenari che siano ragionevoli e fedeli alle restrizioni.</sample>
    <sample id="981">The article has three authors.</sample>
    <sample id="982">Vasudha</sample>
    <sample id="983">I'm sorry, but I don't have the information about the affiliations of the authors of the article you mentioned. You might need to check the article itself or the publication where it was published. If you have any other questions or need further assistance, feel free to let me know.</sample>
    <sample id="1021">Gli errori più comuni di PaLM sono gli omission errors.</sample>
    <sample id="1022">Ciao, sono James Finch e sono Sarah Finch. Oggi vi parleremo di ABC eval, una nuova approccio dimensionale per valutare l'intelligenza artificiale conversazionale.</sample>
    <sample id="1023">Questo lavoro è stato fatto dal laboratorio di NLP di Emory, diretto dal professor Gino Choi all'Università di Emory e in collaborazione con Amazon Alexa AI.</sample>
    <sample id="1024">Se diciamo che hai appena sviluppato un modello di dialogo e vuoi vedere come si confronta con lo stato dell'arte attuale.</sample>
    <sample id="1025">La pratica comune è di utilizzare l'valutazione umana, come ad esempio chiedendo giudici umani di selezionare quale delle due conversazioni sia migliore o di valutare le conversazioni utilizzando una scala Likert.</sample>
    <sample id="1026">Questi approcci funzionano bene per fornire valutazioni globali della qualità del dialogo, ma la qualità del dialogo ha molti aspetti. Quindi, potresti voler valutare diverse dimensioni della qualità del chat per comprendere le forze e le debolezze del modello a un livello più dettagliato.</sample>
    <sample id="1027">Un approccio consiste nel chiedere giudici umani di valutare diverse dimensioni della qualità del dialogo, come la rilevanza delle risposte del modello, utilizzando metodi di confronto o scala Likert esistenti.</sample>
    <sample id="1028">Tuttavia, crediamo che esista una strategia più precisa e affidabile per l'valutazione del dialogo dimensionale.</sample>
    <sample id="1029">La nostra approccio cerca di ridurre la soggettività dell'valutazione umana annotando esplicitamente se ognuna delle risposte del modello esprime determinati comportamenti, come rispondere con informazioni irrellevanti o contraddizione.</sample>
    <sample id="1030">Chiamiamo questo approccio "annotazione dei comportamenti in chat" o ABC-Eval in breve. Abbiamo sviluppato questo metodo per coprire in modo comprensivo i comportamenti dei modelli di chat che sono stati suggeriti di influenzare la qualità dei chat in recenti studi.</sample>
    <sample id="1031">Il contenuto in inglese è già in italiano. Se vuoi che lo traduca in un'altra lingua, fammi sapere.</sample>
    <sample id="1032">Ad esempio, l'indice di valutazione misura il numero di giri in cui un modello di chat ignora il suo partner o dice qualcosa di irrilevante.</sample>
    <sample id="1033">Contraddice se stesso o il suo partner. Illude con informazioni errate o viola il buon senso. E quando il modello riesce o fallisce a mostrare empatia.</sample>
    <sample id="1034">Per determinare qual è l'evaluation più efficace, abbiamo selezionato quattro modelli di chat di punta e li abbiamo valutati su 100 conversazioni umano-robot per modello utilizzando ABC eval.</sample>
    <sample id="1035">Per la comparazione, abbiamo anche valutato queste conversazioni utilizzando tre metodi esistenti: valutazioni LICKER a livello di turno, valutazioni LICKER a livello di dialogo e confronti a livello di dialogo a coppie.</sample>
    <sample id="1036">Per ciascuno dei metodi esistenti, abbiamo raccolto valutazioni su otto degli aspetti di dialogo più comunemente misurati, poiché questo è la pratica standard per valutare i modelli di chat su diverse dimensioni.</sample>
    <sample id="1037">Dalle nostre analisi di questi risultati di valutazione, abbiamo trovato che le etichette di comportamento ABCBEval sono in generale più affidabili rispetto alle etichette raccolte con metodi esistenti, come misurato dall'accordo inter-annotatore su 100 conversazioni doppilabel.</sample>
    <sample id="1038">Inoltre, le etichette ABC-Eval sono più predittive della qualità complessiva della conversazione rispetto ai metrici prodotti dai metodi esistenti, come dimostrato dall'analisi di regressione lineare semplice.</sample>
    <sample id="1039">Per esempio, si può vedere come misurare la proporzione di turni con contraddizioni di sé e partner spiega il 5% e il 10% della qualità della conversazione rispettivamente, mentre le punteggia di consistenza di Likert medie spiegano solo il 4% o meno.</sample>
    <sample id="1040">Infine, abbiamo controllato se ogni metrica di valutazione cattura un aspetto unico della qualità del chat utilizzando una regressione lineare passo dopo passo.</sample>
    <sample id="1041">Puoi vedere come la combinazione di tutte le metriche ABCDE spiega oltre il 25% della qualità della conversazione e, quando le rimuovi una alla volta, la maggior parte di esse porta via una buona quantità di informazioni sulla qualità.</sample>
    <sample id="1042">D'altra parte, la combinazione di tutte le metriche Likert a livello di volta spiega ben poco della qualità e meno di queste metriche portano informazioni uniche.</sample>
    <sample id="1043">Questi metriche di valutazione ABCDEF sono affidabili, informative e distintive e permettono di valutare l'intelligenza artificiale conversazionale con una risoluzione maggiore rispetto a metodi precedenti.</sample>
    <sample id="1044">Puoi vedere che nei risultati dell'esperimento ci sono ancora diversi ostacoli e sono stati quantificati con precisione. Ad esempio, i bot che abbiamo testato hanno violazioni di buon senso in circa il 20% delle loro risposte.</sample>
    <sample id="1045">Producono informazioni irrilevanti in circa il 15% delle risposte e si contraddicono o si contraddicono con il partner circa il 10% delle volte.</sample>
    <sample id="1046">Con il rapido ritmo di miglioramento nel campo, molte di queste tassi di errore potrebbero registrare una diminuzione nei nuovi modelli rilasciati dal momento in cui è stata condotta la nostra valutazione. Tuttavia, questo è ancora più motivo per perseguire metriche di valutazione affidabili e precise per confrontare i modelli.</sample>
    <sample id="1047">Speriamo che ABC Eval possa essere utilizzato da altri nel campo come un passo significativo in questa direzione. E aspettiamo di vedere come l'intelligenza artificiale conversazionale progredirà nei prossimi mesi e anni. Grazie per averci seguito.</sample>
    <sample id="1048">The authors are affiliated with Emory NLP Lab at Emory University and in collaboration with Amazon Alexa AI.</sample>
    <sample id="1049">CFT significa Continual Fine-tuning.</sample>
    <sample id="1050">Cinque.</sample>
    <sample id="1051">Ciao! Mi chiamo Coyote e presenterò il nostro lavoro intitolato "Quando la traduzione richiede un contesto: un'indagine multilingue basata su dati". Questo lavoro è stato realizzato in collaborazione con Patrick Franch, Emi Lu, Andrew F. T. Martins e Graham Newbigging.</sample>
    <sample id="1052">In questo caso, "more" potrebbe essere tradotto come "più". Ma dipende anche dal contesto. Se vuoi una traduzione più precisa, puoi fornire il contesto.</sample>
    <sample id="1053">Se la frase precedente era "Cose potrebbero iniziare a diventare pericolose se i ministri scoprono", allora "Moll" si riferisce a un agente segreto. Ma se la frase precedente era "Potrebbe essere qualcosa di serio, dottore?", allora "Moll" si riferisce a una macchia di nascita.</sample>
    <sample id="1054">Sì, a seconda del contesto il significato della parola cambia e quindi la sua traduzione cambia anche.</sample>
    <sample id="1055">Tuttavia, valutare quanto bene i modelli gestiscono casi come questo è abbastanza difficile. In primo luogo, perché solo una piccola parte delle traduzioni dipende dal contesto, il che rende inutili i metriche a livello di corpus come BLEU per catturare queste traduzioni.</sample>
    <sample id="1056">E alcuni hanno suggerito l'valutazione mirata delle traduzioni dipendenti dal contesto, ma questi risorse supportano solo tipi limitati di traduzioni dipendenti dal contesto e set di lingue limitati, in quanto solitamente si affidano a conoscenze di dominio e cura umana.</sample>
    <sample id="1057">In questo lavoro cerchiamo di rispondere a queste due domande. Prima, quando la traduzione richiede contesto? E poi, quanto bene gestiscono questi casi i modelli?</sample>
    <sample id="1058">Per rispondere alla prima domanda, abbiamo iniziato misurando quanto una parola dipende dal contesto durante la traduzione.</sample>
    <sample id="1059">Nel lavoro precedente abbiamo introdotto CXMI come misura per i contesti utilizzati dai modelli di traduzione automatica. Questo è stato fatto misurando quanta informazione il contesto C fornisce sulla target Y, dato il source X.</sample>
    <sample id="1060">Puoi pensare al CMI come all'informazione guadagnata dal dare contesto al modello.</sample>
    <sample id="1061">Nel lavoro, estendiamo il CXMI a Pointwise CXMI, che può misurare l'uso del contesto a livello di frase o a livello di parola. Possiamo considerare le parole che hanno un alto p-CXMI come quelle che richiedono contesto per la traduzione.</sample>
    <sample id="1062">Ora analizziamo le parole con un alto PSMI per cercare di trovare dei modelli tra queste parole.</sample>
    <sample id="1063">Eseguiamo l'analisi sui trascrizioni di TED Talks tradotte in 14 diverse lingue.</sample>
    <sample id="1064">Eseguiamo l'analisi a tre livelli. Innanzitutto, guardiamo alle tag di parto di frase con alti valori di PSMI.</sample>
    <sample id="1065">E questo ci permette di trovare, ad esempio, i pronomi dual in arabo che hanno relativamente alta P63. E questo può essere spiegato perché l'inglese non ha pronomi dual, quindi si ha bisogno del contesto per determinare se un pronome è dual quando si traduce in arabo.</sample>
    <sample id="1066">E similmente, scopriamo che certe lingue richiedono contesto quando vogliamo scegliere la forma verbale appropriata. Poi guardiamo i vocaboli che hanno un alto PCE, PCE medio, calcolato su tutte le sue diverse occorrenze.</sample>
    <sample id="1067">E questo ci aiuta a identificare casi come questo, dove in cinese si ha bisogno di contesto per tradurre correttamente i nomi propri, per assicurarsi di usare la stessa traduzione all'interno del documento.</sample>
    <sample id="1068">E in modo simile, troviamo che il contesto è supportato per la traduzione nella giusta formalità.</sample>
    <sample id="1069">E infine esaminiamo diversi token con alta P Xi. Questo ci permette di identificare fenomeni che non possono essere veramente catturati dalla parola in sé, ma sono piuttosto espressi nella struttura della frase, come la risoluzione di ellissi.</sample>
    <sample id="1070">Quindi ora utilizziamo i nostri risultati dall'analisi per progettare un benchmark per la traduzione a livello di documento.</sample>
    <sample id="1071">Per ciascuno dei cinque fenomeni di discorso che abbiamo identificato, creiamo tagger per identificare automaticamente le parole che si riferiscono al fenomeno e chiamiamo il nostro tagger il tagger multilingue consapevole del discorso, MUDA.</sample>
    <sample id="1072">Possiamo notare anche che diverse lingue hanno proporzioni diverse di questi fenomeni discorsivi.</sample>
    <sample id="1073">Poi utilizziamo MUDATagger applicando il tagger al corpus parallelo che vogliamo utilizzare per l'valutazione e applichiamo i nostri metrici di traduzione di scelta sugli esempi dipendenti dal contesto che MUDATagger ha identificato.</sample>
    <sample id="1074">E infine, utilizziamo il nostro benchmark, insieme ad altri metriche, per valutare diversi modelli di traduzione automatica a livello di documento.</sample>
    <sample id="1075">Prima di tutto, quando utilizziamo metriche di livello di corpus, per il BLEU troviamo che i modelli agnostici del contesto hanno la migliore prestazione.</sample>
    <sample id="1076">Ma allora, se usiamo Comet, i modelli con contesto performano meglio. E se usiamo Word F - measure, allora i modelli con e senza contesto hanno prestazioni comparabili.</sample>
    <sample id="1077">Questo dimostra nuovamente che è difficile determinare il miglior sistema di traduzione documentale se si utilizzano metriche a livello di corpus da sole.</sample>
    <sample id="1078">Ora utilizziamo il benchmark MML per valutare i modelli e troviamo che i modelli che usano il contesto sono significativamente più accurati dei modelli che non usano il contesto per certi fenomeni discorsivi, come la formalità e la coesione lessicale.</sample>
    <sample id="1079">Ma questi modelli non sono molto migliori di quelli che non utilizzano il contesto su altri fenomeni come ellissi, pronomi e forme del verbo. Quindi, questo suggerisce dove dovremmo vedere un maggiore progresso per la traduzione a livello di documento.</sample>
    <sample id="1080">Abbiamo anche confrontato diversi sistemi commerciali e il nostro benchmark mostra che DeepL è solitamente più accurato di Google Translate per la traduzione a livello di documento.</sample>
    <sample id="1081">Eseguiamo un'analisi guidata da dati su 14 coppie di lingue per identificare quando le traduzioni richiedono un contesto.</sample>
    <sample id="1082">E poi utilizziamo i nostri risultati per costruire un benchmark per la traduzione automatica a livello di documento che ci aiuterà a identificare quali fenomeni discorsivi i modelli possono gestire bene o meno e quali sistemi di traduzione sono buoni per la traduzione a livello di documento.</sample>
    <sample id="1083">Grazie mille per l'attenzione. Ci vediamo a Toronto.</sample>
    <sample id="1084">Justin John.</sample>
    <sample id="1121">The new method is called "Depth-First Search".</sample>
    <sample id="1122">Il metodo delle "parole contrassegnate" è una tecnica per identificare le parole che distinguono gruppi contrassegnati da quelli non contrassegnati.</sample>
    <sample id="1123">I'm not sure about the specific affiliations of the authors in this article. You might need to check the article itself for that information. If you have any other questions about the article, feel free to ask.</sample>
    <sample id="1124">La prima struttura di dipendenza simmetrica menzionata è il "dependency treebanks".</sample>
    <sample id="1125">James Finch and Sarah Finch.</sample>
    <sample id="1126">Quattro.</sample>
    <sample id="1127">I minimal pair paradigm.</sample>
    <sample id="1161">Non so quali siano le abbreviazioni dei cinque metodi per la prima domanda di ricerca. Potresti fornire più dettagli o informazioni?</sample>
    <sample id="1162">Il modello viene valutato su 11 attività biomediche e cliniche di screening.</sample>
    <sample id="1226">CamemBERT viene addestrato sulle 4 gigabyte di subset di NACOS.</sample>
    <sample id="1227">Adam Skowroński.</sample>
    <sample id="1228">L'esperimento di retrain o continuare a pretrainare modelli con dati più recenti ha portato alla conclusione che la deriva temporale è la causa principale della perdita di prestazioni.</sample>
    <sample id="1269">Perché i token non sono ordinati dopo il primo passo.</sample>
    <sample id="1270">Perché non sanno se i positivi stereotipi sono causati da un'overly excessive value alignment o altri metodi anti-stereotipanti che producono questi dannosi modelli.</sample>
    <sample id="1271">Gli input inaccettabili di coppia minima sono le frasi grammaticalmente errate.</sample>
    <sample id="1272">Non sono state menzionate le metriche di valutazione utilizzate. Potresti cercare di trovare ulteriori informazioni nel testo originale?</sample>
    <sample id="1273">L'accordo tra annotatori è stato misurato con l'inter-annotator agreement.</sample>
    <sample id="1274">Wikipedia.</sample>
    <sample id="1275">Non c'è informazione su affiliazioni degli autori nell'articolo.</sample>
    <sample id="1276">MultiInstruct differisce dagli altri parametri di riferimento in quanto si concentra sulla generazione di dati di istruzioni per modelli multimodal. Mentre gli altri parametri di riferimento si concentrano spesso su compiti linguistici solo, MultiInstruct cerca di migliorare la generalizzazione a compiti multimodal inesistenti. Inoltre, ha un dataset di istruzioni multimodal che non esiste in scala larga per altri parametri di riferimento. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="1277">There are two authors involved in the article.</sample>
    <sample id="1278">Non c'è una definizione di coordinazione binaria nella tua domanda. Potresti fornire più dettagli o chiarire il contesto?</sample>
    <sample id="1279">I'm not sure. I don't have enough information to answer that. You could try looking for more details in the study itself.</sample>
    <sample id="1280">I più piccoli modelli T5 possono generare testi di qualità superiore rispetto a molti modelli a grandi scale quando addestrati correttamente su dataset adatti.</sample>
    <sample id="1281">Ciao， sono Janice Lavaque e presenterò i nostri lavori su Dr.Bert， un modello di pre - addestramento robusto in francese per l'intelligenza artificiale biomedica e clinica.</sample>
    <sample id="1282">Nella presentazione iniziamo parlando del modellaggio linguistico nel campo della sanità. Poi presenteremo le principali contribuzioni del nostro articolo.</sample>
    <sample id="1283">Introduciamo il primo modello biomedico in francese, chiamato Dr. Bert, che si basa su Roberta e viene addestrato su NACHOS, un dataset di dati clinici catturati dalla rete.</sample>
    <sample id="1284">Abbiamo anche introdotto una comparazione del modello con diversi set di pre - allena e fonti di dati. Poi abbiamo presentato i nostri risultati su 11 compiti di apprendimento automatico biomedico e clinico in francese.</sample>
    <sample id="1285">E infine, concludiamo sull'esperimento e ti forniamo ulteriori dettagli su come accedere ai modelli.</sample>
    <sample id="1286">Da quando è stato rilasciato nel 2018, BERT è diventato uno dei metodi più efficaci per risolvere compiti di elaborazione del linguaggio naturale e offre un notevole miglioramento di prestazioni rispetto a metodi statici e contestualizzati storici come Word2Vec, FastText o ANMO.</sample>
    <sample id="1287">Da allora, questo modello è stato adattato a molte lingue straniere, come in francese con Camembert, in ambito biomedicale con PubMedBERT e Biobert, e in ambito clinico con ClinicalBERT, ma principalmente in inglese.</sample>
    <sample id="1288">I modelli specializzati per altre lingue sono scarsi e spesso si basano su un preallineamento continuo a causa della mancanza di dati di dominio.</sample>
    <sample id="1289">Tuttavia, il modello di open source per BioMedical in C++ non esisteva.</sample>
    <sample id="1290">Quindi ci chiediamo qual è il più adatto per una varietà di utilizzo e i dati strutturati sono buoni sostituti dei dati clinici.</sample>
    <sample id="1291">Per rispondere a questa domanda, abbiamo comparato il modello di BERT con il nostro modello di sub-BERT, che è basato su dati anonimizzati ottenuti da un ospedale non universitario a Detroit.</sample>
    <sample id="1292">Dopo tutto, ci chiediamo quanta data dobbiamo avere per addestrare un modello specializzato su dati francesi. È di 4 GB, 8 GB o più?</sample>
    <sample id="1293">Per rispondere a questa domanda, prima dobbiamo addestrare e confrontare quattro modelli da zero. La prima versione di Dr. Bert ha 7 gigabyte di NACOS, la seconda versione ha 4 gigabyte di NACOS.</sample>
    <sample id="1294">Una prima versione di Schubert, che è un modello clinico, con 4 GB di istruzioni predefinite da ClinConduct. Una versione finale di Schubert con una combinazione di 4 GB di set di istruzioni naturali e 4 GB di ClinConduct.</sample>
    <sample id="1295">In aggiunta a questa comparazione, introduciamo tre modelli addestrati con preaddestramento controllato per analizzare l'impatto delle strategie di preaddestramento.</sample>
    <sample id="1296">Un basato sul peso del camembert e addestrato su un subset da 4 GB di nachos. L'altro basato anch'esso sul camembert ma addestrato questa volta su un subset da 4 GB di caramelle.</sample>
    <sample id="1297">E infine, basandoci sul modello di BERT in lingua inglese, possiamo costruire e addestrare su un subset di 4 GB di SNACCHOS. In totale, abbiamo sette modelli.</sample>
    <sample id="1298">Per valutare tutti e sette i modelli, abbiamo raccolto molteplici compiti pubblici e privati, come riconoscimento di immagini di oggetti, classificazione, rilevamento di oggetti in foto, e risposta a domande.</sample>
    <sample id="1299">Questo modello è stato comparato a sei modelli di rinnovamento, che sono Camembert Oscar 128 GB, Camembert Oscar 4 GB, Camembert C-Sinet 4 GB, Premidbert, Mayobert e Clinicalbert.</sample>
    <sample id="1300">La versione di Highlight che esegue meglio la task con dati dello stesso tipo è quella che è stata addestrata su.</sample>
    <sample id="1301">Tuttavia, possiamo ottenere i dati da… possiamo osservare che i dati da diverse fonti sembrano essere più versatile. Abbiamo anche osservato che utilizzare più dati si traduce in una migliore prestazione.</sample>
    <sample id="1302">In generale, l'innovazione da zero sembra ottenere prestazioni superiori in quasi tutte le tare.</sample>
    <sample id="1303">Tuttavia, il nostro esperimento di ottimizzazione continua utilizzando il pesaggio e il tokenizzatore di Pemidbert, addestrato su un subset da 4 GB di Natchos, ha mostrato risultati paragonabili a quelli ottenuti con Dr. Bert da 4 GB addestrato da zero.</sample>
    <sample id="1304">Non è il caso per il modello basato su Camembert weights and tokenizer, che soffrono di problemi di stabilità.</sample>
    <sample id="1305">Infine, la nostra proposta di sistema offre una migliore prestazione su nove dei dodici compiti e supera globalmente il risultato del modello generico qui riportato.</sample>
    <sample id="1306">Abbiamo anche osservato che i dati specializzati sono migliori, più dati specializzati sono meglio, ma non scalano bene.</sample>
    <sample id="1307">I modelli pre-allenati ottenuti da Natus sono disponibili gratuitamente e l'interfaccia utente e tutti i script di allena mento sono sul nostro repository GitHub.</sample>
    <sample id="1308">Quindi ti ringrazio per questa presentazione e ci guardiamo al post sessione a Toronto.</sample>
    <sample id="1309">The learning strategies examined are pre-training strategies.</sample>
    <sample id="1310">Non so. Non ho abbastanza informazioni per rispondere a questa domanda. Potresti fornire ulteriori dettagli?</sample>
    <sample id="1311">The quality of simplification was evaluated by looking at the scores and evaluation metrics in the paper.</sample>
    <sample id="1312">Sì, i modelli linguistici presentano bias politici diversi.</sample>
    <sample id="1313">Ciao， il mio nome è Matthias Lindemann e oggi darò un'introduzione breve al nostro articolo su generalizzazione compositiva senza alberi utilizzando la taggatura multiset e le permutazioni latenti.</sample>
    <sample id="1314">Questo è un lavoro congiunto con i miei tutori, Aleksander Kola e Ivan Tito.</sample>
    <sample id="1315">La generalizzazione compositiva può essere compresa come la capacità di un apprenditore di gestire una ricorsione più profonda e composti di frasi non visti che sono stati visti individualmente durante l'addestramento.</sample>
    <sample id="1316">Come di consueto, abbiamo un set di enunciati di addestramento. In questo caso, "The girl slept" e "Mary knew that the girl slept."</sample>
    <sample id="1317">Questi enunciati sono associati a forme logiche che rappresentano aspetti fondamentali del loro significato.</sample>
    <sample id="1318">In contrapposizione all'evaluazione standard di machine learning, il set di test non proviene dalla stessa distribuzione ma contiene forme logiche strutturalmente non viste.</sample>
    <sample id="1319">Nell'esempio, il modello ha visto ricorsione superficiale durante l'addestramento e viene testato su esempi con ricorsione più profonda.</sample>
    <sample id="1320">I modelli di sequenza a sequenza semplici hanno difficoltà con questo tipo di generalizzazione fuori dalla distribuzione e spesso producono output che sono disgiunti dall'input.</sample>
    <sample id="1321">In particolare, spesso falliscono a riprodurre le corrispondenze sistematiche tra input e output, come quelle che sono colorate nel esempio.</sample>
    <sample id="1322">Un metodo popolare per affrontare questo è l'integrazione degli alberi nei modelli.</sample>
    <sample id="1323">I alberi sono intesi a catturare il processo compositivo che si lega alle affermazioni con le forme logiche.</sample>
    <sample id="1324">Questo funziona bene, ma gli alberi di solito non vengono dati e devono essere ottenuti in qualche modo.</sample>
    <sample id="1325">Questo può essere complicato e talvolta un processo computazionalmente costoso. Generalmente questo implica un pre-elaborazione formale specifica delle forme logiche, ad esempio per gestire i simboli variabili.</sample>
    <sample id="1326">Ottenerli alberi potrebbe anche coinvolgere procedure di induzione di grammatica specializzate.</sample>
    <sample id="1327">Nel nostro articolo non utilizziamo alberi e presentiamo un nuovo modello di sequenza a sequenza che modella direttamente le corrispondenze tra i frammenti dell'input e i frammenti dell'output.</sample>
    <sample id="1328">Per la prima volta dimostriamo una generalizzazione forte alla ricorsione più profonda senza dipendere da alberi.</sample>
    <sample id="1329">Il nostro approccio predice l'output dall'input in due passaggi.</sample>
    <sample id="1330">Prima di tutto, etichettiamo ogni token di input con un multiset non ordinato di token che appaiono nell'output.</sample>
    <sample id="1331">Dopo il primo passaggio, abbiamo tutti i token giusti, ma non sono ordinati.</sample>
    <sample id="1332">Perché, nel secondo passaggio, usiamo un altro modello per predire una permutazione per metterli nell'ordine giusto.</sample>
    <sample id="1333">Introduciamo un nuovo metodo per prevedere una permutazione che non impone alcune restrizioni rigide sulle possibili permutazioni. Questo rende la nostra approccio abbastanza flessibile ed espressivo.</sample>
    <sample id="1334">Il nostro modello di permutazione funziona in modo simile a questo.</sample>
    <sample id="1335">Passiamo da sinistra a destra attraverso l'output e determiniamo quale token multiset mettere in ogni posizione. Per la prima posizione di output, semplicemente selezioniamo uno, come evidenziato in rosso.</sample>
    <sample id="1336">Poi saltiamo al prossimo token multiset per determinare il secondo token nell'output.</sample>
    <sample id="1337">Determiniamo il terzo token nell'output in una maniera simile saltando a un altro token multiset. Continuiamo questo processo.</sample>
    <sample id="1338">Fino a quando ogni token della prima fase è stato visitato esattamente una volta.</sample>
    <sample id="1339">Per dare un'anteprima dei risultati sperimentali, qui confrontiamo il nostro metodo con altri modelli di alberi su il benchmark Cog. Il nostro modello supera gli altri di gran lunga in generizzazione per ricorsioni più profonde.</sample>
    <sample id="1340">Alcune altre tipologie di generalizzazione strutturale rimangono molto difficili.</sample>
    <sample id="1341">Nel nostro articolo risolviamo un paio di interessanti sfide tecniche.</sample>
    <sample id="1342">Prima di tutto, l'allineamento tra input e output non è dato nel dataset di addestramento. Come conseguenza, per un token dato, non sappiamo da quale multi-settore è venuto, che rappresenta un'ottativa per l'addestramento.</sample>
    <sample id="1343">Inoltre, a volte ci sono diverse permutazioni che sono consistenti con i dati, ma la corretta dal punto di vista linguistico è latente. Abbiamo affrontato questo problema introducendo l'individuazione dell'alignment come parte della fase di addestramento.</sample>
    <sample id="1344">Il metodo di permutazione è molto flessibile, ma presenta il problema che trovare la permutazione con la punteggiatura più alta è NP-hard. Questo perché è legato al problema del viaggiatore di commercio.</sample>
    <sample id="1345">Approssimiamo questo con una rilassazione continua amichevole per GPU che ci permette anche di propagare indietro attraverso la soluzione e imparare le permutazioni più plausibili dal punto di vista linguistico.</sample>
    <sample id="1346">Se vuoi apprendere di più sulle nostre esperimenti e su come abbiamo affrontato queste sfide, ti prego di leggere il nostro articolo o visitare il nostro poster.</sample>
    <sample id="1347">La dissonanza cognitiva è quando due credenze o azioni sono inconsistenti.</sample>
    <sample id="1348">Il modello linguistico più liberale è GPT-4.</sample>
    <sample id="1349">Yes.</sample>
    <sample id="1350">Sarah Pape.</sample>
    <sample id="1351">I dati nel parametro di riferimento MuDa sono stati tratti da transcrits di TED talks tradotti in 14 diverse lingue.</sample>
    <sample id="1385">Il nome del relatore è Matthias Lindemann.</sample>
    <sample id="1386">Il trasferimento interlinguistico è un tipo di trasferimento di apprendimento che si basa su un linguaggio intermedio, chiamato interlingua, per trasferire conoscenze da un linguaggio a un altro. In questo caso, si sta parlando di trasferimento zero-shot e few-shot, dove si addestra su un linguaggio di origine e si trasferisce a un altro. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="1387">I'm not sure about the specific affiliations of the authors in that article. You might need to check the article itself or the university's website for more accurate information. If you have any other questions about the article or your research, feel free to ask.</sample>
    <sample id="1388">Gli autori fanno ricorso alla latenza misurata e alla latenza computazionale.</sample>
    <sample id="1389">Ciao a tutti, sono Maksym, e oggi il mio collega Martin e io stiamo presentando il nostro lavoro "The Kid Must Have: Evaluating Knowledge Integration from Multiple Sources". Questo lavoro è una collaborazione tra l'Università di McGill, MILA e Microsoft Research.</sample>
    <sample id="1390">I modelli di intelligenza artificiale naturale traggono conoscenza da una varietà di fonti, come quelle contenute nei loro parametri, solitamente acquisite tramite un pre-allenamento, e quelle fornite in input durante l'infrazione.</sample>
    <sample id="1391">Recenti lavori su compiti come la risoluzione di domande mostrano che i modelli possono utilizzare il loro conoscenza preaddestrata per risolvere il compito.</sample>
    <sample id="1392">Ma l'intersezione del linguaggio naturale spesso richiede conoscenze che vengono fornite anche in tempo di inferenza.</sample>
    <sample id="1393">Ad esempio, nella frase "John saw the newly elected president on TV".</sample>
    <sample id="1394">I parametri di pre-allenamento possono contenere informazioni su cosa i precedenti hanno fatto e cosa il TV è, ma non possono conoscere in modo affidabile chi sia l'entità specifica John in questo istante o chi sia il nuovo presidente, perché il presidente potrebbe essere cambiato dal momento della pre-allenamento.</sample>
    <sample id="1395">Quindi, i modelli di successo per le compiti di NLU intensivi di conoscenza richiedono la capacità di integrare e utilizzare sia il know-how di pre-allenamento che il know-how di inferenza.</sample>
    <sample id="1396">Nel lavoro, proponiamo un insieme di test diagnostici per l'integrazione del conoscenza.</sample>
    <sample id="1397">Introduciamo una compito di risoluzione di riferimento coevo progettato per verificare la capacità di utilizzare il know-how disponibile in diverse fonti. Valutiamo il dataset con partecipanti umani di studi e modelli di risoluzione di riferimento stabiliti.</sample>
    <sample id="1398">Sylvain è un giudice. Kia è un pasticcere. Sylvain e Kia si sono incontrati in un parco. Dopo una lunga giornata di lavoro, decidendo casi in una lunga corte, lui era felice di rilassarsi.</sample>
    <sample id="1399">Non capisco il contesto del tuo messaggio. Puoi fornire più dettagli?</sample>
    <sample id="1400">La risoluzione di un pronome richiede due tipi di informazione. Primo, conoscenza specifica dell'entità, come "il giudice è un giudice", e secondo, conoscenza di fondo, come "i giudici decidono casi in tribunali".</sample>
    <sample id="1401">In generale, le conoscenze di fondo vengono imparate durante la pre-allenamento dei grandi modelli di linguaggio, mentre le conoscenze specifiche di entità sono solitamente osservate durante l'infrazione.</sample>
    <sample id="1402">Variamo l'accessibilità di queste due informazioni in modo che possano essere trovate in una singola fonte o in molte fonti.</sample>
    <sample id="1403">Abbiamo definito tre impostazioni di KidMOS. La prima è la configurazione di tipo "topic", dove il background è pretrainato, ovvero si assume che il background sia disponibile durante il pretrain.</sample>
    <sample id="1404">Secondo, c'è la configurazione di conoscenza di fondo. La conoscenza di fondo è disponibile sia durante il pre-allenamento che durante l'infrazione. Infine, la configurazione di conoscenza di fondo durante l'infrazione. Le due tipologie di conoscenza sono disponibili solo durante l'infrazione.</sample>
    <sample id="1405">Questo ultimo set di dati è particolarmente interessante, poiché simula il caso in cui il rumore di fondo è necessario per risolvere la compito, non fa parte dei dati di pre-allenamento dei modelli. Ad esempio, perché nuove occupazioni sono state sviluppate dal momento dell'allenamento.</sample>
    <sample id="1406">Ecco un esempio di come controllare l'accessibilità di fattori di risorsa in una società.</sample>
    <sample id="1407">Nella configurazione di pre-allenamento di BERT, si assume che il conoscenza di fondo dei politici che cercano seggi elettorali nel governo sia contenuta nei parametri pre-allenati. Per comprendere il contesto, forniamo la conoscenza specifica dell'entità: Chichester è un politico.</sample>
    <sample id="1408">Nel contesto di Backprop Setting, inoltre, forniamo non solo risposte specifiche, ma anche conoscenze di fondo sui politici nel contesto interno.</sample>
    <sample id="1409">In un contesto di video in cui si fornisce una professione fittizia, "militura" invece di "politician" perché "militura" è poco probabile di essere contenuta nel pre-allenamento.</sample>
    <sample id="1410">Abbiamo valutato il dataset sia con partecipanti umani che con modelli di soluzione di riferimento stabiliti. In questa figura mostriamo i risultati dei modelli con prestazioni migliori nella variante più difficile del contesto di pre-allenamento di Backprop.</sample>
    <sample id="1411">Se non si ha un addestramento specifico su Kidnus, entrambi i modelli non si prestano bene. Quando addestrati su Kidnus, tuttavia, entrambi C2F e BERT4QA si prestano significativamente meglio rispetto a un modello casuale.</sample>
    <sample id="1412">Questo suggerisce che, quando addestrati su set di dati di risoluzione di domande generali, i modelli imparano a sfruttare "cose superficiali", che non sono utili quando si testa su Kit Moser, poiché queste "cose superficiali" sono state eliminate.</sample>
    <sample id="1413">Esempi aggiuntivi di conoscenza fittizia hanno indicato che anche i modelli che performano meglio non riescono a integrare la conoscenza del contesto in modo affidabile solo durante l'infrazione.</sample>
    <sample id="1414">Molti modelli di riferimento evoluzione sembrano incapaci di ragionare su conoscenze da diverse fonti senza addestramento specifico per la compito. Tuttavia, con l'addestramento specifico per la compito, alcuni modelli riescono a integrare le conoscenze da molte fonti.</sample>
    <sample id="1415">Comunque, anche i modelli con le prestazioni migliori sembrano avere difficoltà a integrare in modo affidabile il conoscenza retrospettiva presentata solo durante l'infrazione. Se sei interessato a ulteriori dettagli, consulta il nostro articolo e controlla il dataset e il codice su GitHub. Grazie per l'ascolto.</sample>
    <sample id="1416">I vantaggi dei metodi basati su alberi sono che funzionano bene, ma i disavvantaggi sono che i dati alberi non vengono spesso forniti e devono essere ottenuti in qualche modo, che può essere complicato e computazionalmente costoso. Inoltre, richiede un pre - elaborazione formale delle forme logiche, ad esempio per gestire le simboli variabili. L'ottenimento di alberi può anche coinvolgere procedure di induzione di grammatica specializzate.</sample>
    <sample id="1417">I'm sorry, but the information about the affiliations of the authors of the article "Do Cornell 2003 Named Entity Taggers Still Work Well in 2023?" is not provided in the text you've given me. You might need to look for more details in the full text of the article or in the references section. If you have any other questions or need further assistance, feel free to let me know.</sample>
    <sample id="1418">Ciao， sono Myra e oggi parlerò del nostro articolo "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models". Questo lavoro è stato realizzato in collaborazione con S. Sander, Mush e Dan Jurafsky.</sample>
    <sample id="1419">Negli ultimi anni, molti hanno documentato la prevalenza di pregiudizi sociali e stereotipi nei modelli di linguaggio a grandi scale, o LLM.</sample>
    <sample id="1420">Tuttavia, queste misure presentano varie limitazioni. Solitamente si affidano a set di dati costruiti a mano che sono molto tempo消费的 da curare.</sample>
    <sample id="1421">E inoltre solitamente misurano solo stereotipi molto specifici, il che significa che non generalizzano bene a altre demografie o contesti, o semplicemente catturano associazioni molto generali e ampie, come associazioni negative con particolari gruppi.</sample>
    <sample id="1422">Inoltre, la maggior parte del lavoro in questo campo non tiene conto dell'intersezionalità, che è la nozione che identità sociali multifaccettate possono comporre pregiudizi e essere luoghi unici di danno.</sample>
    <sample id="1423">Per superare queste limitazioni, ci affidiamo alla proprietà che questi nuovi LLMs addestrati alle istruzioni sono molto bravi a rispondere alle istruzioni e alle promemoria.</sample>
    <sample id="1424">Quindi possiamo chiedere al modello di generare un personaggio, che è una rappresentazione di un individuo immaginario, utilizzando un prompt come "Immagina che tu sia una donna asiatica, descriviti".</sample>
    <sample id="1425">E possiamo subito vedere che questo è molto generalizzabile a qualsiasi demografia, perché possiamo specificare qualunque marcatore di identità che vogliamo in questa prompt.</sample>
    <sample id="1426">Mi dispiace, ma non hai fornito il contenuto inglese da tradurre. Puoi inviarmi il testo in inglese che vuoi tradurre in italiano?</sample>
    <sample id="1427">Subito notiamo che, mentre le uscite non sono negativi o tossici nel senso tradizionale di queste parole.</sample>
    <sample id="1428">C'è qualche interessante pattern.</sample>
    <sample id="1429">L'Asia donna è descritta come inosservabile. La donna del Medio Oriente è riferita usando parole come "esotico" e "come riferito a una regione ipnotizzante".</sample>
    <sample id="1430">E entrambe le personaggi di donne di colore fanno riferimento all'ancestralità, mentre il personaggio del uomo bianco non ne fa assolutamente nulla.</sample>
    <sample id="1431">Per catturare questi modelli, il nostro metodo ha due parti. La prima parte è la generazione di questi personaggi.</sample>
    <sample id="1432">Le nostre promemoria per generare questi personaggi sono state ispirate da uno studio in cui hanno dato queste promemoria a soggetti umani. Trovando che, dando queste promemoria a soggetti umani, sono anche riusciti a rilevare stereotipi razziali.</sample>
    <sample id="1433">E questo consente una comparazione diretta tra i personaggi generati da noi e le risposte scritte da umani.</sample>
    <sample id="1434">La seconda parte è "parole marcate", che è un metodo per identificare le parole che distinguono i gruppi marcati da quelli non marciti, che approfondirò a breve.</sample>
    <sample id="1435">Il vantaggio di questo è che otteniamo veri e propri stereotipi e modelli senza dover ricorrere a nessun lessico specifico.</sample>
    <sample id="1436">Il metodo del "marcato" si basa sul concetto sociolinguistico di "marcatura", che afferma che esiste un valore di default non marcato e qualsiasi gruppo che si differenzia da tale default è linguisticamente marcato.</sample>
    <sample id="1437">Per esempio, la parola "warrior" è solitamente associata a uomini. Quindi, quando le persone descrivono un guerriero che è una donna, solitamente specificano "woman warrior" e mettono in evidenza il termine "woman".</sample>
    <sample id="1438">E più in generale, i gruppi dominanti nella società sono sia linguisticamente che socialmente non marcati, mentre i gruppi marginalizzati sono solitamente marcati.</sample>
    <sample id="1439">In questo metodo, innanzitutto designiamo quali sono i gruppi non marcato e marcato.</sample>
    <sample id="1440">E poi confrontiamo i personaggi utilizzando il metodo delle parole da combattere, che è fondamentalmente utilizzare le ratio di logaritmi pesati per distinguere le parole più importanti per ciascun gruppo marcato.</sample>
    <sample id="1441">Per esempio, per le personae di donne nere, faremmo "parole di battaglia" e compariamo le log-odds ratio sia contro le personae bianche che contro le personae maschili, perché queste sono le due gruppi corrispondenti non marcate.</sample>
    <sample id="1442">Allora, per i risultati. Innanzitutto, utilizziamo un lessico di stereotipi e scopriamo che i personaggi generati contengono molto più stereotipi rispetto a quelli scritti da umani.</sample>
    <sample id="1443">Tuttavia, quando effettivamente guardiamo alla distribuzione delle parole nel lessico, troviamo cose molto diverse.</sample>
    <sample id="1444">Quindi, mentre le personazioni generate hanno un tasso molto più alto di parole di lusso, le scritte umane hanno una distribuzione molto più ampia di parole. Le parole stereotipate presenti nelle personazioni generate sono davvero solo le parole "alta" e "atletica".</sample>
    <sample id="1445">Sì, solo i positivi o perlomeno quelli non negativi.</sample>
    <sample id="1446">E in realtà, questo lessico non cattura bene molte delle pattern dannosi che abbiamo visto nelle prime slide. Quindi invece, per farlo, andremo a vedere i risultati del metodo Mark Words per mostrare come queste parole positive sembranti facilitano stereotipi e narrazioni essenzializzanti.</sample>
    <sample id="1447">Nell'analisi, riveliamo come queste rappresentazioni apparentemente positive riflettano modelli dannosi.</sample>
    <sample id="1448">I primi quattro gruppi di parole includono parole come cultura, tradizione, orgoglio e esotico. E queste parole definiscono solo questi gruppi in relazione alla loro identità e li distinguono come diversi dal normale bianco.</sample>
    <sample id="1449">Questo contribuisce a un lungo patrimonio di discriminazione e di "altro" per queste gruppi.</sample>
    <sample id="1450">Inoltre, ci sono molte trame comuni riflettute in queste parole, soprattutto per le donne di colore. Ad esempio, le parole che descrivono le donne latine includono cose come "vibrante" e "curvilinea".</sample>
    <sample id="1451">Per le donne asiatiche, i termini come "piccola", "delicata" e "sottile" sono parte del tropo del "tropicalismo".</sample>
    <sample id="1452">C'è un lungo passato di donne asiatiche che sono state sovrasessualizzate e viste come molto docili e sottomesse.</sample>
    <sample id="1453">E per le donne nere, vediamo che alcuni dei termini più importanti sono cose come "forte" e "resiliente".</sample>
    <sample id="1454">Questo si collega a un archetipo che le persone hanno chiamato l'archetipo della donna nera forte. E mentre suona positivo a prima vista.</sample>
    <sample id="1455">C'è stata una ricerca che dimostra che questo archetipo è veramente dannoso perché mette sotto molta pressione queste demografie affinché siano resilienti e forti contro gli ostacoli della società.</sample>
    <sample id="1456">Invece di lavorare per cambiare quegli ostacoli, mette sotto pressione quelle persone a superarli, che porta a risultati negativi per la salute di queste persone, tra gli altri danni.</sample>
    <sample id="1457">In modo più ampio, notiamo che le parole per ogni gruppo marcato riflettono piuttosto narrazioni essenzializzanti.</sample>
    <sample id="1458">Quindi, basandoci su questi modelli, concludiamo con tre raccomandazioni per i proprietari di modelli.</sample>
    <sample id="1459">Prima di tutto, come ricercatori dovremmo affrontare le stereotiphe positive e le narrazioni essenziali. Dovremmo anche utilizzare un approccio intersezionale per studiare le pregiudiziali e i danni perché ci sono molte cose che potrebbero essere trascurate se non lo facciamo.</sample>
    <sample id="1460">E infine dovrebbe esserci una maggiore trasparenza riguardo ai metodi di mitigazione del bias.</sample>
    <sample id="1461">Per esempio, come questi stereotipi positivi, non sappiamo se sia perché c'è qualche sorta di strano.</sample>
    <sample id="1462">Eccessiva allineamento di valori o forse metodi anti-stereotipizzanti che stanno portando a questi modelli dannosi?</sample>
    <sample id="1463">Non possiamo fare alcuna ipotesi o studiare ulteriormente senza una maggiore trasparenza.</sample>
    <sample id="1464">Grazie mille per l'ascolto. Buona giornata.</sample>
    <sample id="1465">Ciao a tutti. Il mio nome è Jin Wei Yi e sono dell'Università di Scienze e Tecnologia della Cina.</sample>
    <sample id="1466">È un piacere fare un breve video pubblicitario su carta. Stai copiando il mio modello? Protetto il copyright dei grandi modelli di linguaggio per servizi di incastro e di servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi di incastro e servizi</sample>
    <sample id="1467">Mi dispiace, ma non hai fornito il contenuto in inglese da tradurre. Potresti dirmi cosa c'è da tradurre?</sample>
    <sample id="1468">Attualmente, modelli di linguaggio a grandi scale come GPT, Llama, e Pile sono eccezionali nell'intera comprensione e generazione del linguaggio naturale.</sample>
    <sample id="1469">Le servizi di embedding AI sono uno dei servizi costruiti su grandi modelli di linguaggio per assistere varie compiti di NLP.</sample>
    <sample id="1470">Ad esempio, OpenAI offre un API di embedding basata su GPT.</sample>
    <sample id="1471">Tuttavia, recenti studi hanno dimostrato che l'attaccante può rubare il modello attraverso l'apprendimento dall'embedding e fornire servizi simili. Quindi, è necessario proteggere il copyright dell'embedding come servizio.</sample>
    <sample id="1472">Per proteggere i diritti d'autore dei servizi di insegna, una delle soluzioni è di inserire un marchio d'acqua nel servizio del fornitore e rilevare se un altro servizio contiene il marchio d'acqua.</sample>
    <sample id="1473">Il metodo di watermark deve soddisfare le seguenti proprietà: prima, il metodo deve essere applicabile all'inserimento di servizi di terze parti. Secondo, il watermark non deve indebolire l'utilità dei servizi di inserimento forniti.</sample>
    <sample id="1474">Terzo, il marchio acquerello dovrebbe essere abbastanza nascosto da far sì che l'attaccante non possa rimuoverlo facilmente.</sample>
    <sample id="1475">Infine, il marchio acqueo deve essere trasferibile ai servizi dell'attaccante durante il processo di estrazione del modello.</sample>
    <sample id="1476">Le opere esistenti possono essere ampiamente classificate in quattro categorie.</sample>
    <sample id="1477">Tuttavia, questo metodo non è applicabile ai servizi di inserimento di pubblicità o manca di trasferibilità.</sample>
    <sample id="1478">Pertanto, in questo articolo proponiamo Embedding Marker, un metodo di watermarck basato su backdoor applicabile all'inserimento di servizi di assistenza.</sample>
    <sample id="1479">L'embedder marker contiene due passaggi principali: l'iniezione del watermark e la verifica del copyright.</sample>
    <sample id="1480">Prima di questi passaggi principali, dobbiamo prima selezionare un set di trigger. Il set di trigger è un gruppo di parole in un intervallo di frequenza moderato.</sample>
    <sample id="1481">Supponiamo che il fornitore possa raccogliere un corpus di testo generale e contare le frequenze delle parole.</sample>
    <sample id="1482">Nell'iniezione di watermark, definiamo prima un target embedding. Quando un utente invia una frase al servizio del fornitore, il fornitore conta il numero di trigger nella frase.</sample>
    <sample id="1483">L'embedding fornito è una somma pesata dell'embedding del target e dell'embedding originale.</sample>
    <sample id="1484">La massa dell'embedding di riferimento è proporzionale al numero di trigger nella frase. Quando il numero di trigger nella frase è maggiore di m, l'embedding fornito è esattamente uguale all'embedding di riferimento.</sample>
    <sample id="1485">La verifica di copyright è per rilevare se un modello dietro un altro servizio contiene il marchio d'acqua.</sample>
    <sample id="1486">Prima costruiamo un dataset di porta posteriore e uno di dataset benigno. Il dataset di porta posteriore contiene frasi in cui tutte le parole appartengono al set di triger, mentre tutte le parole nelle frasi del dataset benigno non appartengono al set di triger.</sample>
    <sample id="1487">Il fornitore richiede le embedding dal servizio di Steeler con il dataset.</sample>
    <sample id="1488">La somiglianza coseno e l2 tra l'embedding richiesto e l'embedding di riferimento sono calcolati. Viene calcolata la differenza di somiglianza tra i set di dati benigni e backdoor, definita come Δcos e Δl2.</sample>
    <sample id="1489">Nel frattempo, applichiamo anche il test di KS e utilizziamo il suo valore p come il terzo metrico.</sample>
    <sample id="1490">Eseguiamo esperimenti su quattro dataset: 20news - 20, Mind, SST - 2 e IRIS - Spam. Supponiamo che il fornitore applichi il dataset di wikitext per contare le frequenze delle parole.</sample>
    <sample id="1491">I risultati su quattro dataset mostrano che il nostro marker di embedding può avere un buon prestigio di rilevamento, mentre mantiene un'ottima utilità per le tare di scendimento.</sample>
    <sample id="1492">Abbiamo anche validato la coerenza dell'embedding fornito visualizzando l'embedding delle frasi su quattro dataset. Il leggenda delle figure indica il numero di trigger in ogni frase.</sample>
    <sample id="1493">Come mostrato nelle figure, è difficile distinguere tra le embedding indietro porte e le embedding normali.</sample>
    <sample id="1494">Ecco la traduzione in italiano: "Ecco tutto. Grazie. Benvenuto a discutere con noi." Se hai bisogno di altro, fammi sapere!</sample>
    <sample id="1495">ABC-Eval significa "annotating behaviors in chat" in italiano, che è un approccio per valutare i comportamenti dei modelli di chat.</sample>
    <sample id="1496">The performance drop between CoNLL-2003 and CoNLL++ is caused by temporal drifts, not adaptive overfitting. So, the answer to your question is not directly related to the performance difference being over 5 percentage points. If you have more questions about this, feel free to ask.</sample>
    <sample id="1497">Ciao, il mio nome è Vasudha e sono un candidato di dottorato in informatica presso l'Università di Stony Brook. Vorrei presentare un lavoro accettato in ACL 2023 come un lungo articolo: "Transfer Learning per la rilevazione di dissonanze: affrontare il problema della classe rara".</sample>
    <sample id="1498">Iniziamo definendo la dissonanza cognitiva e perché è un problema importante da studiare in lingua. In parole semplici, la dissonanza cognitiva è due credenze o azioni che sono incompatibili.</sample>
    <sample id="1499">Ecco il contenuto in italiano: "Come in questo esempio, quando una persona afferma 'So che le sigarette potrebbero uccidermi' e poi dice 'Ho preso un paio di sigarette dopo la riunione', questa fede e l'azione sono incoerenti e in disaccordo." Se hai bisogno di chiarimenti o di traduzioni di altri testi, fammi sapere!</sample>
    <sample id="1500">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="1501">La dissonanza è un fenomeno molto comune che esperiamo nella decisione quotidiana, ma è davvero raro trovarla espressa in lingua, tra le altre relazioni discorsive.</sample>
    <sample id="1502">Studiare la distanza cognitiva ci può aiutare a comprendere gli effetti della disaccordo tra le persone, a tracciare tendenze e cambiamenti di credenze, valori e atteggiamenti nella popolazione.</sample>
    <sample id="1503">La dissonanza cognitiva alta è anche legata ai disturbi d'ansia e può aiutare a comprendere meglio la salute mentale delle persone.</sample>
    <sample id="1504">Lo studio della dissonanza espressa in lingua può essere anche benefico nell'interpretare l'estremismo e la polarizzazione dei gruppi vulnerabili.</sample>
    <sample id="1505">Infine, la dissonanza cognitiva è importante per comprendere i modelli cognitivi personali degli individui e ci aiuta a comprendere meglio i processi decisionali.</sample>
    <sample id="1506">Per creare un risorsa di dissonanza cognitiva, abbiamo condotto una vasta annotazione di relazioni di dissonanza. Abbiamo utilizzato l'approccio di dissonanza "prima" come mostrato nel flusso di lavoro qui.</sample>
    <sample id="1507">I tweet sono stati passati utilizzando un parser di API e le coppie di unità discorsive sono state annotate secondo le linee guida descritte nel nostro articolo.</sample>
    <sample id="1508">Come si può vedere qui, la dissonanza è stata trovata solo in 3,5% dei pares annotati.</sample>
    <sample id="1509">Raccogliendo circa mille esempi di coppie di unità discorsive, abbiamo addestrato un classificatore iniziale. Addestrato solo su quarantatré esempi di dissenso, non sorprendentemente, il classificatore non ha prestato molto meglio del caso.</sample>
    <sample id="1510">Dato il basso accadimento di dissonanze e l'assenza di qualsiasi dataset precedente, stiamo affrontando il problema della rarità assoluta.</sample>
    <sample id="1511">Per alleviare questo problema, esperimentiamo con combinazioni di apprendimento trasferito e apprendimento attivo per annotare in modo che si possano raccogliere più campioni dissonanti in meno iterazioni di annotazione, riducendo così i costi totali di annotazione, ma migliorando la deteczione della dissonanza.</sample>
    <sample id="1512">Poiché il modello iniziale non è stato in grado di catturare la classe di dissonanza affatto, abbiamo iniziato il processo di apprendimento attivo trasferendo i pesi da compiti strettamente correlati.</sample>
    <sample id="1513">Trasferiamo da due differenti compiti. Classificazione di distanze indipendente dal tema. Un compito che determina se due affermazioni di dibattito da persone diverse sono in accordo o in disaccordo, indipendentemente dal tema.</sample>
    <sample id="1514">Chiamiamo dibattito qui e sulla classificazione binaria di espansione e confronto delle classi di armonia. Poiché queste due sono strettamente legate alla concezione di consonanza e dissonanza e le chiamiamo CEE qui.</sample>
    <sample id="1515">Abbiamo notato che il prestigio zero-shot sul dataset annotato è già molto migliore della chance, con il migliore avendo un AUC di 0.62.</sample>
    <sample id="1516">Sul finetuning iterativo su entrambe le task, troviamo che il finetuning della task CE seguito da un ulteriore finetuning sulla task Debate dà un prestigio zero-shot molto migliore. Questo è il modello che abbiamo utilizzato per iniziare il costrutto di apprendimento attivo.</sample>
    <sample id="1517">Prossimamente determineremo il metodo migliore per aggiornare il modello con nuovi dati da ogni ciclo di apprendimento attivo e annotazioni. Il metodo cumulativo accumula tutti i dati raccolti finora dall'apprendimento attivo e annotazioni. Il metodo iterativo aggiorna il modello addestrandolo sul set di dati più recente raccolto.</sample>
    <sample id="1518">Tra le diverse strategie, abbiamo trovato che accumulativo ha eseguito uguale o meglio di iterativo in tutte le situazioni.</sample>
    <sample id="1519">Per migliorare il numero di esempi di dissonanza, utilizziamo una strategia di probabilità di classe rara, PRC, per selezionare principalmente gli esempi che sono altamente probabili di essere dissonanti dal modello corrente in qualsiasi round di all.</sample>
    <sample id="1520">Compariamo questo con gli altri modelli di stato dell'arte, le strategie AI comunemente utilizzate nella comunità.</sample>
    <sample id="1521">Abbiamo trovato che la strategia di PRC proposta funziona meglio rispetto ad altre state-of-the-art strategie, anche se la differenza è piccola. Notare che il rendimento è significativamente più basso per il caso casuale.</sample>
    <sample id="1522">Nelle ulteriori giri di allenamento con le due migliori strategie, abbiamo migliorato l'AUC di classificazione di distanza a 0.75, che è la migliore prestazione che abbiamo avuto sulla task finora.</sample>
    <sample id="1523">Abbiamo anche controllato la fattibilità di ogni strategia per la qualità dell'annotazione e i costi per gli annotatori. Abbiamo trovato che PRC ha il più alto percentuale di dissonanza e funziona meglio per le classi rare. Tuttavia, anche gli annotatori ritengono che gli esempi siano difficili.</sample>
    <sample id="1524">In sintesi, troviamo che il PRC è una strategia di AI semplice per l'acquisizione di classi rare e che il costruire un AI con compiti di apprendimento trasferimento correttamente progettati può aiutare in modo significativo.</sample>
    <sample id="1525">Abbiamo anche trovato che l'aggiornamento iterativo è utile per il trasferimento di apprendimento da un dominio diverso, mentre le annotazioni attive in dominio beneficiano dell'aggiornamento cumulativo.</sample>
    <sample id="1526">Ecco i link al nostro dataset di codice e al nostro paper. Sentitevi liberi di contattarci se avete domande. Grazie.</sample>
    <sample id="1527">Non so qual è l'affiliazione degli autori dell'articolo. Potresti dare più informazioni?</sample>
    <sample id="1528">Si Yuan</sample>
    <sample id="1529">There are five authors involved in the article.</sample>
    <sample id="1530">Con l'architettura simulST dedicata viene confrontato l'approccio. Se hai altre domande, sentiti libero di chiedere.</sample>
  </task>
</testset>