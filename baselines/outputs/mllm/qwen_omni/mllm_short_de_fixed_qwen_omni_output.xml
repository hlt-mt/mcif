<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind große Webkrawatte-Daten. Politische Nachrichtenmedien sind in ihren Prätrainingsdaten gut abgedeckt. So wie New York Times, Los Angeles Times, The Guardian, Huffington Post usw. sind in Sprachmodelltrainingsdaten gut vertreten. Wenn du noch mehr wissen möchtest, frag einfach!</sample>
    <sample id="1">Die Autoren gehören an die McGill University.</sample>
    <sample id="2">Hallo, willkommen zu unserer Präsentation von DEPLAIN, einem neuen Korpus für die Texteinfachstellung auf Dokumentebene und Satzebene im Deutschen.</sample>
    <sample id="3">Mein Name ist Regina Stodden und ich werde Sie für die erste Teil der Präsentation führen. Lassen Sie uns zuerst Textvereinfachung definieren.</sample>
    <sample id="4">Texteinfachung ist der Prozess, einen Text anzupassen, um die Textverstehbarkeit für eine bestimmte Zielgruppe zu verbessern, sei es für Menschen mit Leseschwierigkeiten oder für Nichtmuttersprachler.</sample>
    <sample id="5">Um ein Textverflechtungsmodell zu trainieren, benötigen wir parallele Textpaare, zum Beispiel Dokumentpaare oder Satzpaare.</sample>
    <sample id="6">Hier ist der deutsche Inhalt: "Im Beispiel hier kannst du ein parallel ausgerichteter Satzpaar sehen, ein komplexer deutscher Satz und seine vereinfachte Übersetzung ins Deutsche."</sample>
    <sample id="7">Um die Satz zu vereinfachen, sind verschiedene Techniken möglich, wie man im Beispiel sehen kann, wie z.B. lexikalische Substitution, Klausel-Eliminierung, Klausel-Einordnung oder das Einfügen von Wörtern.</sample>
    <sample id="8">Wir stellen nun unser neues Korpus "DE-plain" vor, da in den letzten Jahren Probleme mit bestehenden Korpora bestanden haben. Zum Beispiel waren diese Korpora zu klein, um einen Textverflechtungsmodell zu trainieren.</sample>
    <sample id="9">Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihrer Ausrichtung fehleranfällig sein können.</sample>
    <sample id="10">Daher schlagen wir unser neues Korpus DEplain vor, das in zwei Unterkorpusse unterteilt ist: DEplain-APA und DEplain-web. DEplain-APA basiert auf Nachrichtentexten.</sample>
    <sample id="11">In DEplain-APA haben wir 483 Dokumente alle manuell ausgerichtet. Das ergibt ungefähr 30.000 13.000 Paare von einfachen Sätzen.</sample>
    <sample id="12">Für das DEplain-web-Korpus gibt es verschiedene Domänen, und wir haben alle diese 756 Dokumente sowohl manuell als auch mit automatischen Ausrichtungsmethoden ausgerichtet.</sample>
    <sample id="13">Insgesamt ergeben wir 30.450 Satzpaare.</sample>
    <sample id="14">Wir haben unsere Satzpärchen ein wenig weiter analysiert. Zum Beispiel bei der Art der Vereinfachung.</sample>
    <sample id="15">Wie man hier sehen kann, sind Bibeltexte viel stärker vereinfacht als beispielsweise Nachrichtentexte oder Texte von Sprachlernern.</sample>
    <sample id="16">Beispielsweise bei lexikalischer Verflechtung, struktureller Verflechtung und auch bei der allgemeinen Verflechtung.</sample>
    <sample id="17">Darüber hinaus können Sie sehen, dass unser DEplain-Korpus eine hohe Vielfalt an verschiedenen Vereinfachungstransformationen aufweist. So zum Beispiel im DEplain-apa-Korpus gibt es viel mehr Umordnungen und Worterweiterungen als im DEplain-web-Korpus.</sample>
    <sample id="18">Andererseits haben wir im Web-Korpus viel mehr Umschreibungen.</sample>
    <sample id="19">Nun sehen wir uns an, was wir mit diesem Korpus machen können. Hallo, ich bin Omar und werde nun über die Anwendungsfälle für unsere Datensatz-Deep-Learnung sprechen. Für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten.</sample>
    <sample id="20">In den letzten Jahren gibt es viele neue Anpassungsmethoden, aber im Kontext der maschinellen Übersetzung.</sample>
    <sample id="21">Wenn wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir die Sätzen in diesen Dokumenten ausrichten wollen.</sample>
    <sample id="22">Aber in unserem Fall versuchen wir, Ausrichtungen zwischen Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache und den gleichen Inhalt haben, aber sich auf unterschiedlichen Komplexitätsstufen befinden.</sample>
    <sample id="23">Nun, da wir unsere Datensätze haben, die manuell ausgerichtete Sätze enthalten, können wir diese Sätze als goldene Standard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu evaluieren.</sample>
    <sample id="24">Wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die Codes zur Durchführung unserer Experimente im Papier veröffentlicht.</sample>
    <sample id="25">Am Ende haben wir beschlossen, dass die beste automatische Ausrichtungsmethode für Texte, insbesondere für deutsche Texte, die Methode von MASSalign ist.</sample>
    <sample id="26">Und du kannst auch den Code finden, um diese Methode auf eigenen Dokumenten auszuführen.</sample>
    <sample id="27">Der zweite Use Case, den wir in unserer Arbeit gezeigt haben, ist der Fall der automatischen Textvereinfachung.</sample>
    <sample id="28">Automatisches Textvereinfachen durch das Feinabstimmung von Sprachmodellen, um vereinfachte Texte aus komplexen Eingabetexten zu erzeugen.</sample>
    <sample id="29">Wir haben zwei verschiedene Modelle finetuned. Wir haben das Modell von long-mBART finetuned, um dokumentenbasierte Vereinfachungen zu erzeugen.</sample>
    <sample id="30">Wir haben auch den normalen Basismodell aufbereitet, um Satzebene-Simplifikationen zu erzeugen.</sample>
    <sample id="31">Du kannst auch alle Checkpoints finden und kannst im Detail in die Ergebnisse und die Evaluationsmetriken unserer Experimente in der Papier schauen.</sample>
    <sample id="32">Wir haben festgestellt, dass diese grundlegende Feinarbeit besser als die Baselinescores erzielen könnte.</sample>
    <sample id="33">Wir haben diese Ergebnisse als Leitlinie, als Grundleitlinie für das Problem der automatischen Textvereinfachung in der Zukunft vorgeschlagen.</sample>
    <sample id="34">Vielen Dank für Ihre Aufmerksamkeit. Wir hoffen, Sie alle während des Konferenz zu treffen. Vielen Dank.</sample>
    <sample id="35">Mein Name ist Kayo Yin.</sample>
    <sample id="36">Das T5 XL Modell wurde verwendet.</sample>
    <sample id="37">Ja, sie funktionieren noch.</sample>
    <sample id="38">Es versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem es explizit annotiert, ob jede Modellantwort bestimmte Verhaltensweisen wie irrelevantes Informationen oder Selbstwidersprüche ausdrückt.</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von sauberen Validierungssamples ab. Ohne saubere Validierungssamples kann der trainierte Modell nicht über die ursprünglichen schwachen Labels hinaus generalisieren.</sample>
    <sample id="40">Nichts.</sample>
    <sample id="41">Fünf.</sample>
    <sample id="42">Hallo, mein Name ist Adam Przepiórkowski und diese Präsentation ist über die Abhängigkeitsstruktur der Koordination.</sample>
    <sample id="43">Sie wissen vielleicht, dass verschiedene Theorien und Korpusansätze verschiedene Abhängigkeitsstrukturen annehmen. Zum Beispiel in Universal Dependencies ist die Struktur der Koordination "Lisa, Bart und Maggie" so.</sample>
    <sample id="44">Ja, das ist richtig. In diesem Fall ist Lisa der Kopf der ganzen Koordinationsstruktur. Wenn du noch weitere Fragen hast oder mehr über das Thema erfahren möchtest, lass es mich wissen!</sample>
    <sample id="45">Der gleiche Ansatz wird in der Theorie der Bedeutung von Egorov-Milchuk angenommen, wo wiederum die gesamte koordinierte Struktur von der ersten Konjunktion geleitet wird. Diese beiden Ansätze sind isometrisch, sie heben jeweils eine der Konjunktionen hervor.</sample>
    <sample id="46">Es gibt auch symmetrische Ansätze zur Koordination von Strukturen wie das Prag-Apport, das Konjunktion-Head-Verfahren, das in den Prag-Abhängigkeitsbäumen verwendet wird, wo Koordinationsstrukturen von Konjunktionen angeführt werden.</sample>
    <sample id="47">Also erhalten wir einige Abhängigkeiten von "and" zu allen Konjunkten.</sample>
    <sample id="48">Es gibt auch einen multi-headed Ansatz, der zum Beispiel in der Cutsons Wortgrammatik verwendet wird.</sample>
    <sample id="49">Sagen wir, alle Konjunktionen sind Köpfe der Koordinationsstruktur, so erhalten wir Abhängigkeiten vom Regierenden hier "liebt" zu allen Konjunktionen separat "Lisa", "Bart" und "Maggie".</sample>
    <sample id="50">Das Ziel des Papiers ist, eine neue Argumentation für symmetrische Koordinationsstrukturen wie diese beiden und gegen asymmetrische Koordinationsstrukturen wie diese zu erzeugen.</sample>
    <sample id="51">Das Argument basiert auf dem Prinzip der Minimierung von Abhängigkeitslängen, das anhand dieser Beispiele erklärt wird.</sample>
    <sample id="52">Also in English, wie du vielleicht weißt, bevorzugen direkte Objekte sich dem Verb zu nähern, während Adjektive weiter entfernt bleiben können, stimmt's? So ist "Marge read it yesterday" in Ordnung, weil das direkte Objekt "it" dem Verb nahe ist.</sample>
    <sample id="53">"Es ist viel schlimmer, weil hier zwischen dem Verb und dem direkten Objekt, also dem Adjektiv, 'gestern' steht."</sample>
    <sample id="54">Allerdings kann dieser Effekt verbessert werden, wenn der direkte Objekt sehr schwer und lang ist, da es dann nach dem Agenten in die Position versetzt werden kann.</sample>
    <sample id="55">Der englische Inhalt lautet: "Das ist hier illustriert. Beide diese Sätze sind in Ordnung. Marge hat gestern dieses absolut faszinierende Buch über Bienen gelesen. Es ist okay, anstelle von "es" haben wir "dieses lange und klare Buch"."</sample>
    <sample id="56">Es ist auch in Ordnung zu sagen: "Marge hat gestern diesen absolut faszinierenden Buch über Bienen gelesen."</sample>
    <sample id="57">Das Argument hier ist, dass dies möglich ist, weil obwohl dieser Satz die allgemeine grammatikalische Prinzipien verletzt, dass direkte Objekte direkt neben dem Verb stehen sollten.</sample>
    <sample id="58">Die Wortstellung neigt dazu, Abhängigkeitslängen zu minimieren.</sample>
    <sample id="59">Diese beiden Bäume zeigen nur die Länge der entscheidenden Abhängigkeiten, also diejenigen, die nicht konstant zwischen diesen beiden Strukturen sind.</sample>
    <sample id="60">Also haben wir hier eine Abhängigkeit von "read" zum Adjektiv von Länge 7 gemessen in Wörtern und von "read" zu "book" von Länge 4, also zusammen 11.</sample>
    <sample id="61">Wenn du diese beiden Bestandteile tauschen, wird die Summe dieser beiden Abhängigkeiten 6. Also anstelle von 11, 6, viel kürzer. Das ist der Grund, warum das klingt, als ob es in Ordnung wäre. Es verstößt gegen ein Prinzip, aber es erfüllt ein anderes.</sample>
    <sample id="62">Wir haben verschiedene Statistiken über Koordination aus der erweiterten Version des Penn Treebanks extrahiert und sie in einem Papier dargestellt. Warum würdest du nicht universelle Abhängigkeiten verwenden?</sample>
    <sample id="63">Die Statistiken bestätigen die Beobachtung, dass linke Konjunktionen tendenziell kürzer sind. So "Salz und Pfeffer" und nicht "Pfeffer und Salz", gemessen in Silben.</sample>
    <sample id="64">Koordinierende Konjunktionen neigen dazu, kürzer zu sein, wie schon beobachtet wurde. Diese Tendenz wächst mit der Längendifferenz, was in Gibson et al. 1996: 88-90 kurz erwähnt wurde. Aber nur wenn der Regierende links steht oder fehlt, z.B. "Ich habe Bart und Lisa gesehen; Homer kam und schäkerte", nicht wenn er rechts steht, z.B. "Ted und Ned lachten".</sample>
    <sample id="65">Wenn die Differenz zwischen den Längen der beiden Konjunkte größer wird, bevorzugen die kürzeren Konjunkte, als erstes zu kommen, stärker. Also ist die Proportion der linken, kurzen Konjunkte größer.</sample>
    <sample id="66">Die Novität in diesem Papier ist, dass wir beobachtet haben, dass diese Tendenz nur dann auftritt, wenn der Regierer links ist oder fehlt.</sample>
    <sample id="67">Ja, der Regierer ist auf der linken Seite in diesem Beispiel "I saw Bart and Lisa". Also, der Regierer ist auf der linken Seite.</sample>
    <sample id="68">In der zweiten Beispiel "Homer kam und niesete" gibt es Koordination von zwei Verben und es gibt keinen externen Regierer rechts. Also in solchen Fällen bevorzugt der linke Konjunkt, dass er kürzer ist, umso größer ist der Unterschied zwischen den beiden Konjunkten.</sample>
    <sample id="69">Kopiere den englischen Text und übersetze ihn in ein Übersetzungsprogramm oder such nach einer Übersetzung online.</sample>
    <sample id="70">Wir haben gezeigt, dass die Länge in Zeichen, die erste Spalte, in Silben, die mittlere Spalte, und in Wörtern, die rechte Spalte, gemessen wird. Ich werde mich auf die rechte Spalte konzentrieren.</sample>
    <sample id="71">Was wir hier sehen ist, dass wenn der Regierende auf der linken Seite ist.</sample>
    <sample id="72">Die Tendenz, dass der linke Konjunkt kürzer ist, wächst stetig mit der absoluten Differenz in Wörtern, und dasselbe wird bei der Koordination von Sätzen ohne einen Regisseur beobachtet, aber wenn der Regisseur rechts steht, verschwindet diese Tendenz.</sample>
    <sample id="73">Und wir zeigen in der Arbeit, wie dies eine Argumentation gegen asymmetrische Koordinationsstrukturen bietet, da diese beiden symmetrischen Strukturen wie diese sind.</sample>
    <sample id="74">Schauen Sie sich das Papier für die vollständige Argumentation an! Sprechen Sie uns im Poster-Session an! Vielen Dank.</sample>
    <sample id="75">Drei.</sample>
    <sample id="76">Die Bibeltexte werden stärker vereinfacht.</sample>
    <sample id="77">"I saw Bart and Lisa; Homer came and sneezed."</sample>
    <sample id="78">Ja, die DrBERT Modelle, das NACHOS Dataset und die Trainingsskripte sind frei verfügbar unter der MIT Lizenz. Also kannst du sie für deine Forschung verwenden. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="79">DEplain-APA enthält Dokumente aus News.</sample>
    <sample id="80">Bessere Modellarchitektur, größere Modellgröße und mehr Anpassungsbeispiele.</sample>
    <sample id="81">Die Tendenz wurde gemessen, indem die Länge in Zeichen, Silben und Wörtern gemessen wurde.</sample>
    <sample id="82">Die Experimente wurden so gestaltet, dass sie die Position des Begrenzers in Bezug auf die Länge der Konjunktionen untersuchten. Es wurde die Länge in Zeichen, Silben und Wörtern gemessen. So konnten die Effekte der Position des Begrenzers auf die Länge der linken Konjunktionen in verschiedenen Maßstäben analysiert werden. Wenn du mehr darüber wissen möchtest, frag einfach!</sample>
    <sample id="83">Nicht viel besser als Zufall.</sample>
    <sample id="84">Es sind vier Autoren an der Arbeit beteiligt.</sample>
    <sample id="85">Bob und Alice.</sample>
    <sample id="86">Formality und lexical cohesion.</sample>
    <sample id="87">Johns Hopkins University, Purdue University und MIT.</sample>
    <sample id="122">Das Framework quantifiziert die Positionalität, indem es die Annotierungen durch Demografikgruppen mit Modellvorhersagen und Datensatzanmerkungen vergleicht, indem Pearson's R Scores verwendet. So kannst man die Positionalität quantifizieren. Wenn du mehr darüber wissen möchtest, lass es mich wissen!</sample>
    <sample id="155">Sie konnten rassistische Stereotypen aufdecken.</sample>
    <sample id="156">Die Datenquellen waren eine erweiterte Version des Penn Treebank.</sample>
    <sample id="157">Zwei.</sample>
    <sample id="158">Comparison and Expansion.</sample>
    <sample id="159">Zwei.</sample>
    <sample id="160">Sechs.</sample>
    <sample id="161">Es unterscheidet sich, indem es End-Nutzer mit Modellen und Datensatzvorhersagen und -etikettierungen vergleicht, anstatt nur interannotator-Übereinstimmung oder Modellierungs-annotator-Verteilungen zu betrachten.</sample>
    <sample id="162">GPT-3.5.</sample>
    <sample id="163">DeepL und Google Translate wurden verglichen.</sample>
    <sample id="164">Hallo, ich bin Shangbin, ein Doktorand an der University of Washington. Heute präsentiere ich unsere Arbeit "Von prätrainierter Daten zu Sprachmodellen zu unterstromenden Aufgaben: Verfolgen der Spuren politischer Voreingenommenheit, die zu ungerechten NLP-Modellen führen".</sample>
    <sample id="165">Sprachmodelle werden an großem Webkrawldatenmaterial trainiert.</sample>
    <sample id="166">Politische Nachrichtenmedien sind im Vorkonfigurationsdatensatz gut abgedeckt. Laut einer Umfrage des C4-Korpus können wir sehen, dass die New York Times, Los Angeles Times, The Guardian, Huffington Post usw. im Sprachmodell-Vortrainingsdatensatz gut abgedeckt sind.</sample>
    <sample id="167">Dies hat für Sprachmodell-Anwendungen ein gemischtes Segen geschaffen.</sample>
    <sample id="168">So auf der einen Seite konnten sie aus verschiedenen Perspektiven lernen, was die Demokratie und die Vielfalt von Ideen feiert. Auf der anderen Seite sind diese unterschiedlichen politischen Meinungen von Natur aus sozial voreingenommen und könnten potenzielle Gerechtigkeitsprobleme bei der Anwendung von Unteraufgaben hervorrufen.</sample>
    <sample id="169">Zu diesem Zweck schlagen wir vor, den Propagierungsprozess der politischen Voreingenommenheit von den Voreignungsdaten über Sprachmodelle bis hin zu den unteren Aufgaben zu untersuchen, indem wir die folgenden Fragen stellen: Wie kann man die politische Neigung von Sprachmodellen bewerten? Welche Rolle spielen die Voreignungsdaten bei solchen politischen Voreingenommenheiten? Wie performen Sprachmodelle mit unterschiedlichen politischen Neigungen? Führt die politische Neigung von Sprachmodellen zu Unfairen in NLP-Anwendungen?</sample>
    <sample id="170">Zunächst einmal, wie bewerten wir die politische Neigung von Sprachmodellen und welche Rolle könnte das Vorkennungsdaten dabei spielen?</sample>
    <sample id="171">Zweitens: Wie performen Sprachmodelle mit unterschiedlichen politischen Neigungen bei Downstream-Aufgaben und ob das zu Unfairen in NLP-Anwendungen führen kann?</sample>
    <sample id="172">Also spezifisch haben wir zuerst Sprachmodelle mit verschiedenen Prompt-Formaten vorgeschlagen, indem wir politische Fragebögen wie den Political Compass Test nutzten. Dies gewährleistet, dass unsere automatische Beurteilung gut in die politische Wissenschaftsliteratur verankert ist.</sample>
    <sample id="173">Also zeigen einige vorläufige Ergebnisse, dass Sprachmodelle unterschiedliche politische Neigungen haben. Sie besetzen alle vier Quadranten des politischen Kompasses.</sample>
    <sample id="174">Wir können auch sehen, dass GPT-4 die liberalste Sprachmodell von allen ist, und die GPT-Serie ist im Allgemeinen sozial liberaler als die BERT-Serie und ihre Varianten.</sample>
    <sample id="175">Zweitens zielen wir darauf ab, zu untersuchen, in welchem Umfang die politischen Biass von Sprachmodellen tatsächlich aus dem Trainingsdatensatz aufgenommen werden.</sample>
    <sample id="176">Wir haben eine kontrollierte Experimente durchgeführt, indem wir Sprachmodell-Schrittepunkte auf sechs verschiedenen parteiischen Korpora weiter vortrainiert haben, die in Nachrichten und sozialen Medien unterteilt sind und weiter in ihre politischen Neigungen unterteilt sind.</sample>
    <sample id="177">Durch weiteres Vortrainieren Sprachmodelle an solchen parteiisierten Korpora, können wir sehen, dass die ideologischen Koordinaten des Sprachmodells entsprechend verschieben.</sample>
    <sample id="178">Zum Beispiel, wenn RoBERTa weiter auf dem linksliberalen Reddit-Korpus finetuned und weitertrainiert wird, können wir einen erheblichen liberalen Schwenk in Bezug auf seine politische Neigung beobachten.</sample>
    <sample id="179">In Bezug auf seine politischen Biass.</sample>
    <sample id="180">Wir haben auch untersucht, ob Sprachmodelle die Polarisation aufnehmen können, die in unserer modernen Gesellschaft vorherrscht.</sample>
    <sample id="181">Wir teilen die vortrainierten Korpora in die Zeit vor dem 45. Präsidenten der Vereinigten Staaten und nach dem 45. Präsidenten der Vereinigten Staaten auf und trainieren Sprachmodelle auf den beiden verschiedenen zeitlichen Korpora separat.</sample>
    <sample id="182">Wir können sehen, dass Sprachmodelle im Allgemeinen nach 2017 eine politische Neigung haben, die weiter vom Zentrum entfernt ist. Das zeigt, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufnehmen können.</sample>
    <sample id="183">Zuletzt haben wir Sprachmodelle mit verschiedenen politischen Neigungen in Bezug auf Hassredeerkennung und Fake-News-Erkennung evaluiert. Zwei NLP-Anwendungen, die oft Sprachmodelle betreffen und sehr wichtige Auswirkungen haben könnten.</sample>
    <sample id="184">Also sehen wir, dass wenn wir die Leistung pro Kategorie untersuchen, das heißt wenn wir die Leistung in verschiedene Kategorien unterteilen.</sample>
    <sample id="185">Wenn wir verschiedene Demographien oder politische Neigungen von Nachrichtenmedien betrachten, können wir ein Muster erkennen. Zum Beispiel bei der Erkennung von Hassrede sind linke Sprachmodelle besser.</sample>
    <sample id="186">Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen und Fälschungen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodiert, wobei dunkles Gelb das Beste und dunkles Blau das Schlechteste bedeutet.</sample>
    <sample id="187">Unsere Arbeit ist schlechter dabei, Hassrede, die sich an mächtigere Gruppen in unserer Gesellschaft richtet, zu erkennen.</sample>
    <sample id="188">Rechtsgerichtete Sprachmodelle sind bei der Erkennung von Hassrede, die sich auf Weiße und Männer richtet, besser. Allerdings sind sie schlechter bei der Erkennung von Hassrede, die sich auf Schwarze, LGBTQ+ und andere Minderheiten richtet.</sample>
    <sample id="189">Ähnliche Trends finden sich auch bei der Erkennung von Fake News, wo man sieht, dass linke Sprachmodelle besser sind, um Missinformationen aus der gegnerischen politischen Richtung zu erkennen und umgekehrt.</sample>
    <sample id="190">Tabelle 5: Beispiele für die untere Leistungsausbeute von Sprachmodellen mit unterschiedlichen politischen Neigungen. CHRIS, Base, N, S, L, R stellen Christen, vanilla RoBERTa Modell, Nachrichtenmedien, soziale Medien, linke Neigungen und rechte Neigungen dar, jeweils.</sample>
    <sample id="191">Ja, die verschiedenen politischen Neigungen der Sprachmodelle geben bei Hassrede- und Missinformationsbeispielen unterschiedliche Vorhersagen ab. Es gibt viele weitere Beispiele im Anhang, um das weiter zu unterstreichen.</sample>
    <sample id="192">Dies deutet darauf hin, dass es eine dringende Gerechtigkeitsfrage gibt, was die politischen Vorurteile von Sprachmodellen betrifft.</sample>
    <sample id="193">Tabelle 12: Qualitative Analyse von Hassredebeispielen, bei denen Sprachmodelle mit verschiedenen politischen Neigungen sich widersprechen.Tabelle 13: Qualitative Analyse von Falschinformationsbeispielen, bei denen Sprachmodelle mit verschiedenen politischen Neigungen sich widersprechen.</sample>
    <sample id="194">Tabelle 12: Qualitative Analyse von Hassredebeispielen, bei denen Sprachmodelle mit verschiedenen politischen Neigungen umstreiten. Tabelle 13: Qualitative Analyse von Falschmeldungen, bei denen Sprachmodelle mit verschiedenen politischen Neigungen umstreiten. Das würde bedeuten, dass Menschen mit gegensätzlichen politischen Meinungen möglicherweise marginalisiert werden und Hassrede gegen Minderheitengruppen ohne jegliche Kontrolle wild wüten könnte.</sample>
    <sample id="195">Also, das hat uns die Alarm gelaufen, dass wir die gerechtigkeitsschädigenden Probleme durch politische Neigungen von Sprachmodellen anerkennen und angehen müssen.</sample>
    <sample id="196">Also ein bisschen Diskussion. Wir möchten auch hervorheben, dass wir das einzigartige Dilemma bezüglich politischer Verzerrungen von Sprachmodellen offenlegen. Es ist wie zwischen Scylla und Charybdis.</sample>
    <sample id="197">Wenn wir politische Meinungen in das Trainingsdatensatz für Sprachmodelle nicht reinigen, wird der Bias von den Prädtrainingsdaten zu den Sprachmodellen und schließlich zu den Unteraufgaben weitergegeben, was letztendlich zu Fairnessproblemen führt.</sample>
    <sample id="198">Wenn wir versuchen, zu "sanieren", riskieren wir auch Zensur oder Ausschluss. Es ist unglaublich schwer zu bestimmen, was tatsächlich neutral ist und in die Sprachmodelltrainingsdaten aufgenommen werden sollte. Es ist also wie das elektrische Schiebe-Problema.</sample>
    <sample id="199">Okay, großartig! Ich denke, das ist alles, was ich für heute habe. Vielen Dank für Ihre Zeit.</sample>
    <sample id="200">Sechs.</sample>
    <sample id="201">Bis zu 900 Token.</sample>
    <sample id="202">Musik, Bücher und Rezepte.</sample>
    <sample id="203">Positionalität ist die Perspektive, die Menschen aufgrund ihrer Demografik, Identität und Lebenserfahrungen haben.</sample>
    <sample id="204">Dawei Zhu.</sample>
    <sample id="205">Ja, es passt. Es verwendet bereits existierende Offline-ST-Modelle ohne Neubildung oder Anpassung der Architektur für SimulST.</sample>
    <sample id="206">Es sind vier Autoren an der Arbeit beteiligt.</sample>
    <sample id="207">Noch nicht.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind Background-Pretrain, Background-Both und Background-Inference.</sample>
    <sample id="209">Ich weiß es nicht. Es gibt keine Angabe zur Universität der Autoren im gegebenen Text. Wenn du mehr Informationen haben möchtest, kannst du den Text nochmal sorgfältig lesen oder den Autor direkt fragen.</sample>
    <sample id="210">Die abschließende Forschungsfrage ist: "Should we only use the clean samples for validation, or there are better ways to utilize them?"</sample>
    <sample id="211">Die Sensitivitätsmetrik misst, wie gut ein Modell dieselben Ergebnisse für dieselbe Aufgabe produzieren kann, unabhängig von leichten Variationen in der Wortwahl der Anweisungen.</sample>
    <sample id="212">Der Referent ist Jingwei Yi.</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet eine schlechtere Leistung des Modells. Lower is better. Wenn du noch Fragen hast, lass es mich wissen!</sample>
    <sample id="214">Leider ist in dem gegebenen Text nichts über den linguistischen Kontext während des Pre-Trainings der Modelle erwähnt. Du könntest versuchen, weitere Informationen zu suchen oder mich zu fragen, ob du etwas anderes wissen möchtest.</sample>
    <sample id="215">Typically, we only need 20 samples per class to attain high performance.</sample>
    <sample id="216">Stanford University.</sample>
    <sample id="217">Weil die alten Methoden möglicherweise nicht mehr genügen, um die komplexe und dynamische Natur von Medienverzerrungen zu erfassen.</sample>
    <sample id="218">Akshatha Arodi.</sample>
    <sample id="219">Die Pipeline geht von prätrainierter Daten, über Sprachmodelle bis hin zu NLP-Anwendungen. Es wird untersucht, wie politische Vorurteile von der prätrainierten Datenphase über die Sprachmodelle bis hin zu den NLP-Anwendungen verbreitet werden.</sample>
    <sample id="220">Ja, es unterscheidet sich. In DEplain-apa gibt es mehr Reorderings und Wortadditionen als in DEplain-web. In DEplain-web gibt es mehr Rephrasings.</sample>
    <sample id="221">Nicht erwähnt.</sample>
    <sample id="222">Das Wasserzeichen wird in den Text eingebettet, indem zuerst eine Ziel-Embedding definiert wird. Dann zählt man die Triggeranzahl in einem Satz. Schließlich wird die Ziel-Embedding auf die Original-Embedding addiert.</sample>
    <sample id="223">Die Autoren gehören an die PennState University.</sample>
    <sample id="224">Ja, sie können verbessert werden.</sample>
    <sample id="225">Ein Beispiel für eingeschränkte Sprachplanung ist die Frage "Wie macht man einen Schokoladenkuchen?" und die Antwort "Füge Kakao-Pulver in den Mehlzusatz".</sample>
    <sample id="226">Sie visualisieren die Embedding von Sätzen auf vier Datensätzen über PCA.</sample>
    <sample id="227">Es gibt zwei Wege: von Scratch mit voller Modellkonstruktion und kontinuierliche Prätraining mit einem bestehenden Prätrainiertmodell.</sample>
    <sample id="228">Latin America.</sample>
    <sample id="229">"I am a student."</sample>
    <sample id="230">Je mehr Aufgaben, desto besser die Leistung des Modells, aber auch desto weniger empfindlich wird es.</sample>
    <sample id="231">LSTM seq2seq, T5, Zheng and Lapata.</sample>
    <sample id="232">Sie sind seine Berater.</sample>
    <sample id="233">Chowdery.</sample>
    <sample id="234">Hallo alle zusammen, ich bin Jenny, ein erstsemester PhD-Student an der Carnegie Mellon University, und heute werde ich eure Arbeit präsentieren, "NLPositionality: Characterizing Design Biases of Datasets and Models".</sample>
    <sample id="235">Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten von der University of Washington und dem Allen Institute for AI durchgeführt, nämlich Sebastin Santy, Ronan Le Bras, Katharina Reinecke und Maarten Sap.</sample>
    <sample id="236">Also fangen wir an, indem wir uns vorstellen, dass du für eine Zeitung arbeitest und du durch die Kommentare unter deinem Nachrichtenartikel schmelzt, um giftige Inhalte zu entfernen.</sample>
    <sample id="237">Stell dir vor... Du könntest auf eine beliebte API wie die Perspective API für die Erkennung von Toxizität zugreifen. Und das funktioniert wirklich gut, wenn du Carl Jones bist. Die Perspective API kann korrekt toxische Beispiele erkennen.</sample>
    <sample id="238">Aber das ist nicht wirklich der Fall bei Aditya Sharma, wo der PerspectiveAPI nicht so empfindlich auf offensive Begriffe ist, die in indischen Kontexten häufiger vorkommen.</sample>
    <sample id="239">Dies ist ein Beispiel für einen Designfehler, bei dem wir systematische Leistungsunterschiede von Technologie zwischen Bevölkerungsgruppen sehen.</sample>
    <sample id="240">Positionalität ist die Perspektive, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben.</sample>
    <sample id="241">Positionalität "Die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben." Dies ist ein Konzept, das häufig in kritischen Studien, insbesondere in feministischen und queeren akademischen Bereichen, verwendet wird.</sample>
    <sample id="242">Positionalität "Die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben. Als Forscher, beeinflusst es den Forschungsprozess und seine Ergebnisse und Ergebnisse, weil es die Entscheidungen der Forscher verändern kann."</sample>
    <sample id="243">Ob Datensätze und Modelle Positionalität haben?</sample>
    <sample id="244">Wir versuchen nicht zu sagen, dass Modelle und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren die Meinungen und Urteile von echten Menschen und können so bestimmte Positionen gegenüber anderen darstellen.</sample>
    <sample id="245">Vorarbeiten haben anekdotische Beweise für Positionalität gezeigt, wie kulturelle Lücken in Modellen und Datensätzen, sowie theoretische Definitionen von Modell-Positionalität.</sample>
    <sample id="246">Allerdings sehen diese Arbeiten nicht wirklich die Vergleichung von Endnutzern mit den Datensätzen und Modellen selbst.</sample>
    <sample id="247">Die Untersuchung von Modell- und Datensatz-Positionalität ist zunehmend wichtig, da NLP-Aufgaben subjektiver und sozialer Natur werden.</sample>
    <sample id="248">Es ist schwierig, die Verzerrungen dieser Positionalitäten zu charakterisieren, weil nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind.</sample>
    <sample id="249">Um die Positionalität von Datensätzen und Modellen zu untersuchen, vergleichen wir die Anmerkungen mit tatsächlichen Benutzern mit bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">Wir tun dies durch unser Framework NLPPositionality.</sample>
    <sample id="251">Unser Framework funktioniert in zwei Hauptstufen.</sample>
    <sample id="252">Das erste Schritt ist, Datensätze mit diversen Annotatoren neu zu annotieren.</sample>
    <sample id="253">Wir entschieden uns dafür, die Demografie der ursprünglichen Datensätze zu übersehen, da normalerweise nur wenige Annotatoren jede Instanz annotieren und da die Demografie selten gesammelt und geteilt wird.</sample>
    <sample id="254">Also, wir haben entschieden, die Daten neu zu annotieren, um viele Annotatoren pro Instanz zu erhalten und um eine reiche Datensatz zu erhalten.</sample>
    <sample id="255">Wir vergleichen dann die Anmerkungen nach demografischen Merkmalen mit den Modellen und Datensätzen unter Verwendung des Pearson's R-Korrelationswerts.</sample>
    <sample id="256">Unsere Framework unterscheidet sich also von der Literatur zum Annotator-Dis agreement, indem wir Endbenutzer mit Modellen und Datensatzvorhersagen und -etikettierungen vergleichen, anstatt nur auf annotator-basierte Übereinstimmungen oder Modellierungen von annotator-distributioen zu schauen.</sample>
    <sample id="257">Unsere Rahmenwerke sind weitgehend durch Lab in the Wild, eine Online-Crowdsourcing-Plattform für HCI-Kollaboratoren, ermöglicht.</sample>
    <sample id="258">LabintheWild ist eine Online-Experimentierplattform, auf der wir vielfältige Freiwillige rekrutieren können. Im Gegensatz zu Plattformen wie MTurk, die hauptsächlich Teilnehmer aus den USA oder Indien haben, kann LabintheWild weiterhin hochwertige Daten erhalten.</sample>
    <sample id="259">Wir veranstalten zwei Aufgaben in Lab in the Wild, eine davon ist soziale Akzeptanz. Die Art, wie das funktioniert, ist, dass die Teilnehmer eine Situation aus dem Social Chemistry-Datensatz lesen und dann die soziale Akzeptanz der Situation bewerten.</sample>
    <sample id="260">Um sich nachher in der Studie zu engagieren, können sie ihre Antworten mit denen eines AI und anderer vergleichen.</sample>
    <sample id="261">Wir haben dann diese Annotierungen mit Social Chemistry, Delphi und GPT-4 verglichen.</sample>
    <sample id="262">Wir haben dann eine sehr ähnliche Anordnung für die Toxizität und Hasssprache-Erkennungsaufgabe, bei der sie ein Beispiel aus Dynahate lesen werden und beurteilen, ob sie es für ein Beispiel von Hasssprache halten.</sample>
    <sample id="263">Wir verglichen diese Annotierungen mit Dynahate, Perspective API, Rewire API, Hate RoBERTa und GPT-4. Unser Studie sammelte am Ende mehr als 16.000 Annotierungen von über 1.000 Annotatoren aus 87 Ländern.</sample>
    <sample id="264">Also sind wir jetzt gut gerüstet, zu beantworten, wer NLP-Datensätze und Modelle am meisten ausrichten. Wir finden, dass es in NLP Positionalität gibt.</sample>
    <sample id="265">Zum Beispiel finden wir, dass Datensätze und Modelle am englischsprachigsten ausgerichtet sind. Bei der sozialen Akzeptanzanalyse von GPT-4 ist es am englischsprachigsten ausgerichtet. Wir finden, dass es am englischsprachigsten ausgerichtet ist, Confucian und englischsprachige Länder. Wir finden, dass Dynahate auch am englischsprachigsten ausgerichtet ist.</sample>
    <sample id="266">Wir finden auch eine weitere Ausrichtung bei Menschen mit einem College-Abschluss. Bei der sozialen Akzeptanzsauglichkeit für GPT-4 ist es am meisten mit Menschen mit einem College-Abschluss oder einem Abschluss von einer Graduiertenschule ausgerichtet.</sample>
    <sample id="267">Wir finden dasselbe für Dynahate, wo es am meisten mit Menschen mit einem College-Abschluss ausgerichtet ist.</sample>
    <sample id="268">Allerdings, wenn Modelle und Datensätze spezifischen Populationen zugeordnet werden, werden einige unweigerlich zurückgelassen.</sample>
    <sample id="269">Ein Beispiel dafür ist, dass Datensätze und Modelle sich weniger an nichtbinäre Menschen richten als an männliche und weibliche Gegenstücke. Wir finden dies in der GPT-4-Aufgabe zur sozialen Akzeptanz sowie in der Analyse der Dynahate-Aufgabe.</sample>
    <sample id="270">Also, was können wir tun? Positionalität in der NLP angehen.</sample>
    <sample id="271">Also haben wir ein paar Empfehlungen für dieses Thema. Die erste ist, alle relevanten Designentscheidungen während des Datensatzes oder Modellbaus aufzuzeichnen. Die andere Empfehlung ist, die NLP-Forschung aus der Perspektive des Perspektivismus durchzuführen: a. Teile aufgeteilte Datensatzbeschriftungen! b. Verwende Modellierungstechniken, die Annotatorenkonflikte bewältigen können.</sample>
    <sample id="272">Empfehlungen. 1. Halten Sie eine Aufzeichnung aller relevanten Designentscheidungen bei der Erstellung von Datensätzen oder Modellen. 2. Führen Sie NLP-Forschung aus der Perspektive der Perspektivismus: a. Teilen Sie aufgetrennte Datensatzbeschriftungen! b. Verwenden Sie Modellierungstechniken, die Annotatordisziplin handhaben können. 3. Das Erstellen spezialisierter Datensätze und Modelle für bestimmte Communities ist wertvoll für inklusives NLP, z.B. die Masakhane-Initiative.</sample>
    <sample id="273">Vielen Dank! Dashboard Link: nlpositionality.cs.washington.edu/ Paper: bit.ly/NLPositionality-Paper/ Delphi, https://delechi.allenai.org/, Altersverteilung: 30,5 Jahre, 185 Proben, 29,0 Jahre, 52 Proben, 28,0 Jahre, 52 Proben, 27,0 Jahre, 30 Proben, 26,0 Jahre, 30 Proben, 25,0 Jahre, 16 Proben, 24,0 Jahre, 10 Proben, 23,0 Jahre, 10 Proben, 22,0 Jahre, 10 Proben, 21,0 Jahre, 10 Proben, 20,0 Jahre, 10 Proben, 19,0 Jahre, 10 Proben, 18,0 Jahre, 10 Proben, 17,0 Jahre, 10 Proben, 16,0 Jahre, 10 Proben, 15,0 Jahre, 10 Proben, 1</sample>
    <sample id="274">Die Referentin geht auf drei Probleme von SimulST ein.</sample>
    <sample id="275">Nichtsanierung kann zu Verzerrungen führen, Sanierung könnte Zensur oder Ausschluss riskieren. Es ist schwierig, was neutral ist. Also ist es wie das Elektrolyseproblem.</sample>
    <sample id="276">Hallo, ich bin Siyu Yuan von der Fudan University. Ich bin hier, um unsere Arbeit vorzustellen: "Das Entfernen von Skriptwissen aus großen Sprachmodellen für eingeschränkte Sprachplanung".</sample>
    <sample id="277">In alltaglichen Situationen planen Menschen ihre Handlungen oft nach Schritt-für-Schritt-Anweisungen in Form von sequentiellen Skripten.</sample>
    <sample id="278">Vorherige Arbeit hat abstrakte Ziele von stereotypischen Aktivitäten wie "Kuchen backen" mit Sprachmodellen untersucht und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können.</sample>
    <sample id="279">Allerdings konzentriert sich die bisherige Arbeit hauptsächlich auf das Planen für abstrakte Ziele typischer Aktivitäten. Das Planen für Ziele mit spezifischen Zielen und spezifischen Einschränkungen, wie zum Beispiel das Backen eines Schokoladenkuchens, bleibt noch unzureichend erforscht.</sample>
    <sample id="280">In diesem Papier definieren wir das Problem des beschränkten Sprachplanens.</sample>
    <sample id="281">Ein abstraktes Ziel kann von verschiedenen realen spezifischen Zielen mit vielfältigen Einschränkungen übernommen werden. Ein guter Planer sollte Skripte schreiben, die vernünftig und den Einschränkungen entsprechend sind.</sample>
    <sample id="282">In diesem Papier bewerten und verbessern wir die Fähigkeit großer Sprachmodelle, unter beschränkten Sprachplanungsaufgaben zu arbeiten.</sample>
    <sample id="283">Es gibt keinen spezifischen Datensatz für bestimmte Ziele, der unsere Studie unterstützen könnte.</sample>
    <sample id="284">Wir müssen diese Ziele zuerst erlangen. Wie im Tabelle gezeigt, erweitern wir die abstrakten Ziele mit vielschichtigen Einschränkungen für die Datenbeschaffung im Human-in-the-Loop-Prozess. Verwenden Sie dafür die Instrukt-GPT.</sample>
    <sample id="285">Wir haben 100 spezifische Ziele ausgewählt und die von großen Sprachmodellen generierten Skripte bewertet.</sample>
    <sample id="286">Dieses Tabelle gibt die Gesamtdurchschnittlichkeit der Ergebnisse an. Wir haben festgestellt, dass alle Sprachmodelle unzufriedenstellende Ergebnisse bei der Planung für spezifische Ziele erzielen.</sample>
    <sample id="287">Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, warum LLMs versagen.</sample>
    <sample id="288">Die Ergebnisse in der Abbildung zeigen, dass die semantische Vollständigkeit in den generierten Skripten akzeptabel ist, aber die Treue zur Beschränkung kann nicht garantiert werden.</sample>
    <sample id="289">Wir haben uns genauer mit den thematischen Kategorien der Beschränkungen auf Wikihow auseinandergesetzt. Das Heatmap in der Abbildung zeigt, dass die Planungsleistung von InstructGPT für Ziele unterschiedlicher Kategorien erheblich variiert.</sample>
    <sample id="290">Vorherige Studien haben gezeigt, dass die Output-Qualität großer Sprachmodelle in hohem Maße variiert, was zu schlechter Leistung führt. Daher wenden wir die Idee des "Übergenerierens und Filterns" an, um die Generationsqualität zu verbessern.</sample>
    <sample id="291">Zuerst werden die Typen von Einschränkungen mit Beispielen für InstructGPT gezeigt und spezifische Ziele basierend auf dem gesetzten abstrakten Ziel generiert.</sample>
    <sample id="292">Verwende InstructGPT, um für bestimmte Ziele kandidierende Skripte zu generieren.</sample>
    <sample id="293">Nächster wird ein Filtermodell entwickelt, um die passenden Skripte auszuwählen.</sample>
    <sample id="294">Wir konvertieren Skripte und Ziele in InstructGPT-Embeddings und berechnen Cosinus-Similarität und -Score, um semantische Ähnlichkeit zu messen.</sample>
    <sample id="295">Wir werden den Skripten, die die Keywords des Zielkriteriums enthalten, Aufmerksamkeit schenken. Wir behalten nur den Skripten bei, wenn das Zielkriterium im Skript den höchsten Wert in der Zielkriteriums-Satz hat.</sample>
    <sample id="296">Mit unserem Verfahren kann InstructGPT Skripte von höherer Qualität generieren. Unser Verfahren verbessert die Planbarkeit erheblich sowohl in Bezug auf semantische Vollständigkeit als auch auf Treue gegenüber den Einschränkungen.</sample>
    <sample id="297">Da große Sprachmodelle teuer zum Bereitstellen sind, ist es wichtig, die Sprachplanungsfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung eines Datensatzes ist ein entscheidender Schritt zu diesem Ziel.</sample>
    <sample id="298">Vorherige Studien ermöglichen keine Planung für spezifische Ziele, und die manuelle Datensatz-Annotierung ist teuer.</sample>
    <sample id="299">Wir folgen dem Prinzip der symbolischen Wissensverdichtung, um konstruierte Sprachplanungsdatensätze aus leichteren Modellen zu verdichten.</sample>
    <sample id="300">Wir haben unsere Methode zur Erstellung eines Datensatzes für beschränkte Sprachplanung angewandt und benannt es Coscript.</sample>
    <sample id="301">Insgesamt generieren wir 55.000 konkrete Ziele mit Skripten. Um die Qualität der Validierungs- und Testsets sicherzustellen, fragen wir Cloud-basierte Arbeiter an, um die inkorrekten Beispiele zu finden und zu überarbeiten.</sample>
    <sample id="302">Diese Abbildung zeigt die Verteilung der Restriktionen von Coscript. Wir finden, dass Coscript eine hohe Pluralität in den generierten spezifischen Zielen zeigt. Mit Coscript können wir kleinere, aber spezialisierte Modelle für die Restriktions-Sprachplanung trainieren.</sample>
    <sample id="303">Wir haben festgestellt, dass T5, das auf Coscript feinabgestimmt wurde, Skripte von höherer Qualität generieren kann als die meisten großen Sprachmodelle, was darauf hindeutet, dass kleinere Modelle, wenn sie auf geeigneten Datensätzen ordnungsgemäß trainiert werden, größere Modelle übertreffen können.</sample>
    <sample id="304">Zusammenfassung und Schlussfolgerungen: - Stellen wir das Problem der eingeschränkten Sprachplanung fest. - Beurteilen wir die Fähigkeit von Sprachmodellen, eingeschränkte Sprachplanung durchzuführen und entwickeln wir eine Methode, die zuerst überschreibt und dann filtert. - Verwenden wir Sprachmodelle, um ein hochwertiges Skript-Datensatz, CoScript, für eingeschränkte Sprachplanung zu generieren. - Grenzen und Zukunftsaufgaben: - Die vorgeschlagene Methode zur Verbesserung von Sprachmodellen ist ein post-hoc-Ranking-Ansatz. - CoScript erbt nur von einem abstrakten mit einer zusätzlichen Einschränkung. - Der CoScript-Datensatz kann ein wertvolles Ressourcen für die Weiterentwicklung der Forschung zur Sprachplanung mit komplexeren und diverseren Zielen und Einschränkungen sein.</sample>
    <sample id="305">Wir verwenden große Sprachmodelle, um einen hochwertigen Skriptdatensatz, CoScript, für die gesteuerte Sprachplanung zu generieren. Wir hoffen, dass der CoScript-Datensatz eine wertvolle Ressource für die Weiterentwicklung der Forschung im Bereich Sprachplanung ist.</sample>
    <sample id="306">Vielen Dank für Ihre Zeit. Bitte finden Sie weitere Details zu Coscript in unserem Papier.</sample>
    <sample id="307">Die Sprachgewandtheit von PaLM ist vergleichbar mit SOTA-Systemen.</sample>
    <sample id="308">Es muss auf Embedding as a Service, EaaS, anwendbar sein, die Nützlichkeit der bereitgestellten Embeddings nicht vermindern, verdeckt genug für den Angreifer sein, damit er das Wasserzeichen nicht leicht entfernen kann, und transferierbar zu den Angreiferdiensten sein.</sample>
    <sample id="309">Deutsch, Español, Français, Italiano, 日本語, 한국어, Nederlands, Português, Română, Русский, Türkçe, 中文.</sample>
    <sample id="310">300 Instanzen.</sample>
    <sample id="311">Die Distanzmetriken, die verwendet werden, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen, sind cos und l2.</sample>
    <sample id="312">In der Aufgabe wurden Modelle, die auf einem mehrsprachigen Encoder basieren, in zwei Gruppen eingesetzt. Eine Gruppe war Enc-PTR, das ist Multilingual Pretrained Encoders with Pointer-based Decoders, wie XLM-R + PTR und mBERT + PTR. Die andere Gruppe war Enc-Dec, das sind Multilingual Pretrained Encoder-Decoder Models, wie mBART und mT5.</sample>
    <sample id="344">Sie zählen die Worthäufigkeit in einem allgemeinen Textkorpus und wählen dann n Wörter aus einem mittelhohen Häufigkeitsintervall aus.</sample>
    <sample id="345">Hallo alle zusammen. Mein Name ist Shuheng. Heute werde ich unsere Arbeit präsentieren: "Gibt es noch CoNLL-2003 Named Entity Taggers in 2023?" Lass uns anfangen.</sample>
    <sample id="346">Unser Papier untersuchte das Problem der Generalisierung unter Verwendung der Aufgabe der benannten Entity-Aufmerksamkeit oder der NER-Aufgabe.</sample>
    <sample id="347">Wir beobachten, dass Modelle CoNLL-2003 für fast 20 Jahre zur Entwicklung von NER verwenden. Dies wirft natürlich mehrere Probleme auf. Zunächst einmal, können diese Modelle auf moderne Daten generalisieren?</sample>
    <sample id="348">Nennenswerte Entitätenerkennung und Generalisierung. - Modelle haben fast 20 Jahre lang CoNLL-2003 verwendet, um NER zu entwickeln. - Können diese Modelle auf moderne Daten generalisieren? - Was ist für eine gute Generalisierung notwendig?</sample>
    <sample id="349">Gleichzeitig, wenn wir eine schlechte Generalisierung beobachten, was verursacht den Leistungsabfall dieser Modelle?</sample>
    <sample id="350">Um diese Probleme zu untersuchen, haben wir den CoNLL++ Datensatz entwickelt. Dies ist ein Datensatz, den wir aus Reuters-Nachrichten aus dem Jahr 2020 gesammelt und mit den gleichen CoNLL-2003-Annotationsempfehlungen annotiert haben.</sample>
    <sample id="351">Wir haben dann mehr als 20 Modelle auf CoNLL-2003 abgestimmt. Wir haben sie sowohl auf dem CoNLL-2003-Testset als auch auf dem CoNLL++-Testset evaluiert.</sample>
    <sample id="352">Zum Schluss haben wir den prozentualen Veränderungsanteil des F1-Wertes berechnet, um die Generalisierbarkeit jedes Modells zu beurteilen.</sample>
    <sample id="353">Also, was braucht es für eine gute Generalisierung? In unseren Experimenten haben wir herausgefunden, dass es drei Hauptbestandteile gibt.</sample>
    <sample id="354">Das erste ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass Transformer-Modelle normalerweise besser generalisieren können.</sample>
    <sample id="355">Das zweite Zutat ist die Modellgröße. Wir haben festgestellt, dass größere Modelle in der Regel zu besserer Generalisierung führen.</sample>
    <sample id="356">Und letzten aber nicht zuletzt wissen wir alle, dass die Anzahl der Anpassungsbeispiele direkt die Leistung einer untergeordneten Aufgabe beeinflusst. Hier haben wir auch festgestellt, dass mehr Anpassungsbeispiele tatsächlich auch zu besserer Generalisierung führen.</sample>
    <sample id="357">Was verursacht den Leistungsabfall einiger Modelle?</sample>
    <sample id="358">Wir haben zwei Hypothesen. Die erste ist adaptive Überanpassung, die durch das wiederholte Verwenden desselben Testsets verursacht wird. Dies manifestiert sich normalerweise in einem Rückgang der Ergebnisse auf einem neuen Testset.</sample>
    <sample id="359">Die zweite Hypothese ist die zeitliche Drift, die durch den zunehmenden zeitlichen Abstand zwischen Trainings- und Testdaten verursachte Leistungsverfall.</sample>
    <sample id="360">Was verursacht eine Leistungsabnahme? - Adaptive Überanpassung? - Temporale Drift? Aus der Grafik rechts sehen wir, dass die rote Bestfit-Linie eine Steigung hat, die größer als 1 ist.</sample>
    <sample id="361">Das bedeutet, dass jede Einheit der Verbesserung, die wir bei CoNLL-2003 gemacht haben, mehr als eine Einheit der Verbesserung bei CoNLL++ bedeutet, was bedeutet, dass es keine Verjüngung der Erträge gibt.</sample>
    <sample id="362">Adaptive Overfitting? Keine verbleibenden Rückschläge. Nicht beobachtet. Temporal Drift?</sample>
    <sample id="363">Also was ist mit der zeitlichen Abweichung?</sample>
    <sample id="364">Für die zeitliche Abweichung haben wir Experimente durchgeführt, um Modelle mit neueren Daten zu trainieren oder fortzubilden. Wir haben festgestellt, dass die Leistung mit größerem zeitlichen Abstand abnimmt.</sample>
    <sample id="365">Der Hauptgrund für den Leistungsverlust ist die zeitliche Drift.</sample>
    <sample id="366">Unser Schlussfolgerung ist, dass für eine gute Generalisierung eine bessere Modellarchitektur, eine größere Modellgröße und mehr Anpassungsbeispiele benötigt werden. Diese Ziele gehen Hand in Hand, man kann nicht nur ein einzelnes Element haben, sondern alle anderen braucht.</sample>
    <sample id="367">Gleichzeitig haben wir festgestellt, dass der Leistungsverlust hier durch die zeitliche Abwanderung verursacht wird. Überraschenderweise wird er nicht durch adaptives Übertreffen verursacht, obwohl CoNLL-2003 für über 20 Jahre verwendet wird.</sample>
    <sample id="368">Also zurück zu der Frage, die wir im Titel unserer Arbeit gestellt haben: Funktionieren CoNLL-2003-Tagger noch in 2023? Und wir haben herausgefunden, dass die Antwort tatsächlich ein überwältigendes Ja ist.</sample>
    <sample id="369">Zusammenfassung
- Für eine gute Generalisierung brauchen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr Anpassungsexempel
- Leistungsschwund wird durch:
  - Temporale Abweichung
  - Keine adaptive Übertreibung
- Funktionieren CoNLL-2003-Tagger noch?
  - JA!
Wir hoffen, dass unsere Arbeit Anreiz für weitere Forschung zur Verbesserung der Generalisierbarkeit der Modelle bietet.</sample>
    <sample id="370">Schließlich bitte prüfen Sie unser Papier, unsere Datensätze und wenn Sie Fragen haben, kontaktieren Sie mich gerne. Vielen Dank.</sample>
    <sample id="397">Leider ist im Bild nichts über die Sprachsegmentgröße zu sehen. Könntest du vielleicht mehr Details zu diesem Ansatz geben?</sample>
    <sample id="398">Servin ist ein Richter.</sample>
    <sample id="399">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="400">Die Arbeiten konzentrieren sich auf RoBERTa und GPT-2.</sample>
    <sample id="401">Das Modell kombiniert Werte aus mehreren Ebenen. Wenn du noch Fragen hast, lass es mich wissen!</sample>
    <sample id="402">Beispiele für direkte Inferenz sind "easy on me" und "the first one".</sample>
    <sample id="403">Die Autoren gehören der Fudan University an.</sample>
    <sample id="404">Sechs.</sample>
    <sample id="405">Ja. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="406">Sie haben "a woman warrior" als Beispiel für eine markierte Gruppe gegeben.</sample>
    <sample id="407">Nichts im Bild sagt, welche Modellarchitekturen nicht gut generalisieren. Es geht nur um diejenigen, die gut generalisieren. Kannst du mir mehr dazu sagen?</sample>
    <sample id="408">Die Testdatensätze heißen "Validation".</sample>
    <sample id="409">Sechs. Wenn du noch mehr Fragen hast, lass sie gerne stehen.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="439">Nicht im Bild.</sample>
    <sample id="440">Die Referenten heißen Zhiyang Xu, Ying Shen und Lifu Huang.</sample>
    <sample id="441">Ja, Coscript wurde durch Cloud-sourced Workers für die Korrektur und Überprüfung der Samples verwendet, um die Qualität der Validierung und Testsets sicherzustellen.</sample>
    <sample id="442">Die bestehenden Ressourcen für kontextbasierte Übersetzung unterstützen nur begrenzte Typen kontextabhängiger Übersetzungen und begrenzte Sprachensätze.</sample>
    <sample id="443">Hallo, ich werde über unsere Arbeit zur Auflösung indirekter Referenzierungen für Entitätsauswahl sprechen, bei der wir das AltEntities-Korpus eingeführt haben.</sample>
    <sample id="444">Mein Name ist Mohammad Javad Hosseini und dies ist ein gemeinsames Projekt mit Filip Radlinski, Silvia Pareti und Annie Louis.</sample>
    <sample id="445">Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen möchten. Betrachten Sie diese alternative Frage: "Haben Sie "easy on me" oder "I gotta feeling" gemeint?" Hier möchte der Benutzer zwischen diesen beiden Liedern wählen.</sample>
    <sample id="446">Das offensichtlichste ist, eine direkte Referenz zu verwenden, zum Beispiel, indem man den Namen des Liedes "easy on me" oder seine Position "das erste" sagt.</sample>
    <sample id="447">Indirekte Referenzausdrücke. Ziel: Verständnis der Sprache der Benutzer bei der Entscheidungsfindung. Alternative Frage: "Haben Sie 'easy on me' oder 'I gotta feeling' gemeint?" Direkte Referenz: "easy on me", "das erste" Indirekte Referenz könnte in natürlichen und flüssigen Gesprächen verwendet werden: - Kann den Namen nicht mehr erinnern - Die Aussprachen sind schwer zu unterscheiden - Möchte eine Präferenz angeben. Indirekte Referenz: "Das neuere Lied. Das Lied, das nicht energiegeladen ist." Manchmal ist eine indirekte Referenz für eine natürlichere Konversation geeigneter. Dies kann vorkommen, wenn der Benutzer den Namen des Liedes nicht mehr erinnern kann.</sample>
    <sample id="448">Indirekte Referenzausdrücke. Ziel: Verständnis der Sprache der Nutzer bei der Entscheidungsfindung. Alternative Frage: "Haben Sie 'easy on me' oder 'I gotta feeling' gemeint?" Direkte Referenz: "easy on me", "das erste" Indirekte Referenz könnte in natürlichen und flüssigen Gesprächen verwendet werden: - Kann den Namen nicht mehr erinnern - Die Aussprachen sind schwer zu unterscheiden - Möchte eine Präferenz angeben. Indirekte Referenz: "Das neuere." "Das Lied, das nicht energiegeladen ist."</sample>
    <sample id="449">Indirekte Referenzausdrücke Ziel: Verständnis der Sprache der Benutzer bei der Entscheidungsfindung Alternative Frage: "Haben Sie 'easy on me' oder 'I gotta feeling' gemeint?" Direkte Referenz: "easy on me", "das erste" Indirekte Referenz könnte in natürlichen und flüssigen Gesprächen verwendet werden: - Kann den Namen nicht mehr erinnern - Die Aussprachen sind schwer zu unterscheiden - Möchte eine Präferenz angeben Indirekte Referenz: "Das neuere Lied." "Das Lied, das nicht energiegeladen ist."</sample>
    <sample id="450">Dies ist ein wichtiges Problem in Konversationssystemen und auch für das Abgrenzen von Entitäten in AltEntitäten-Korpus.</sample>
    <sample id="451">Es gibt keine große öffentliche Datensatz für die Tests, also sammeln wir einen mit Crowd Annotation. Unser Datensatz deckt drei verschiedene Domänen ab: Musik, Bücher und Restaurants.</sample>
    <sample id="452">Unser Datensatzsammlungsverfahren betont Informalität durch eine Cartoon-Fertigstellungsaufgabe.</sample>
    <sample id="453">Der Cartoon hat drei Sprachblasen. In der ersten Blase sagt Bob: "Erinnerst du dich an das Lied, das wir gestern gehört haben?" Damit legt Bob den Dialogkontext fest.</sample>
    <sample id="454">In der zweiten Sprechblase sagt Alice: "Meinst du 'Easy on Me' oder 'I Gotta Feeling'?"</sample>
    <sample id="455">Die Methodik betont Informalität durch eine Cartoon-Fertigstellungsaufgabe. Das Dialogkontext wird durch manuelle Prompte pro Domäne festgelegt. Die alternative Frage ist "Do you mean 'Easy on Me' or 'I Gotta Feeling'?" Bob verwendet in der dritten Sprechblase eine indirekte Referenz, um eine dieser Entitäten auszuwählen, zum Beispiel "The New York".</sample>
    <sample id="456">Wir stellen die ersten und zweiten Sprechblasen automatisch bereit, aber die dritte wird vom Annotator eingegeben. Die erste Sprechblase wird aus einigen manuellen Anregungen pro Domäne ausgewählt.</sample>
    <sample id="457">Der zweite Vorgang, also die alternative Frage, wird wie folgt generiert.</sample>
    <sample id="458">Wir verwenden immer einen einfachen Vorlage: "Meinst du A oder B?" wo A und B aus Wikipedia ausgewählt werden.</sample>
    <sample id="459">Hier sind die verschiedenen Stichprobenmethoden, die wir verwendet haben. Je höher wir in der Liste sind, desto ähnlicher werden die Entitäten zueinander und desto schwieriger ist es, die Disambiguierung durchzuführen.</sample>
    <sample id="460">Der erste ist gleichmäßig zufällig.</sample>
    <sample id="461">Der zweite Punkt ist, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen "The Return".</sample>
    <sample id="462">Der dritte Punkt ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben. Und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben, zum Beispiel die gleiche Genres oder den gleichen Künstler für ein Lied.</sample>
    <sample id="463">Hintergrundwissen, Musik, Google-Suchlink zu jedem Lied. Easy on Me, Adele, I Gotta Feeling, The Black Eyed Peas, Klicken Sie hier, um mehr über das Lied zu erfahren. Wir bitten die Annotatoren, zumindest einige Lieder anzuhören und über jedes Lied zu lesen. Wenn wir diese alternative Frage den Annotatoren stellen, kennen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt mehr über die Entität.</sample>
    <sample id="464">Also tun wir das, indem wir einigen Hintergrundwissen über die beiden Entitäten für Lieder zeigen. Wir zeigen einfach einen Google-Suchlink zu jedem Lied.</sample>
    <sample id="465">Hintergrundwissen Musik Google-Suchverbindungen zu jedem Lied. Easy on Me von Adele I Gotta Feeling von The Black Eyed Peas Klicken Sie hier, um mehr über das Lied zu erfahren. Annotatoren sollen folgendes tun: Zumindest einige Lieder von jedem Lied hören und über jedes Lied lesen. Hier ist zum Beispiel das Google-Suchergebnis für das Lied "Easy on Me".</sample>
    <sample id="466">Für die Rezepte und Bücher-Domäne zeigen wir einige Hintergrundtexte aus Wikipedia. Für Rezepte zeigen wir zusätzlich ihre Bilder, ebenfalls aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen.</sample>
    <sample id="467">Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, zum Beispiel hier die erste, und sie mit 3 bis 5 indirekten Referenzausdrücken zu beschreiben.</sample>
    <sample id="468">Hier sind einige Beispiele aus unserem Datensatz: "der ohne Worte", "nicht der mit dem 12-jährigen Jungen", "der fiktive", "kommt aus Aserbaidschan".</sample>
    <sample id="469">Der AltEntities Corpus hat etwa 6.000 alternative Fragen über drei Domänen verteilt und etwa 42.000 indirekte Referenzausdrücke. Die Ergebnisse mit dem T5 XL Modell sind wie folgt zusammengefasst:</sample>
    <sample id="470">Wenn das Sprachmodell den annotatoren exakt den gleichen Hintergrundwissen zuhält, ist die Genauigkeit wirklich hoch, etwa 92-95%. Aber das ist nicht realistisch.</sample>
    <sample id="471">Wenn der Sprachmodell Zugang zu einer teilweise überlappenden Hintergrundwissen hat, ist die Genauigkeit zwischen 82% und 87%, was realistischer ist, zum Beispiel wenn das Sprachmodell das Hintergrundwissen abrufen kann.</sample>
    <sample id="472">Wenn das Sprachmodell nur Zugriff auf die Entity-Namen hat, ist die Genauigkeit nur 60%, also gibt es viel Raum für Verbesserung. Wir haben auch gezeigt, dass die Modelle domänenübergreifend sind. Hier ist ein Link zu unserem Datensatz. Danke.</sample>
    <sample id="473">Mit den bestehenden SimulST-Richtlinien, die auch auf Offline-Modellen angewendet werden, wie dem Wait-k-Strategie und dem Local Agreement, sowie mit der state of the art Architektur, die speziell für SimulST getailert ist.</sample>
    <sample id="474">Yanis Labrak und Mickael Rouvier gehören zu Avignon Université, Adrien Bazoge und Emmanuel Morin gehören zu Nantes Université, Richard Dufour und Béatrice Daille gehören zu Nantes Université, Pierre-Antoine Gourraud gehört zu Nantes Université.</sample>
    <sample id="475">Jenny.</sample>
    <sample id="476">Drei.</sample>
    <sample id="477">Hallo, ich bin Sara Papi von der Universität Trento und der Fondazione Bruno Kessler. Ich werde kurz das Papier "Achtung als Leitfaden für die gleichzeitige Sprachübersetzung" vorstellen, ein gemeinsames Projekt mit Matteo Negri und Marco Turchi.</sample>
    <sample id="478">Simultane Sprachübersetzung, SimulST, ist der Prozess der Echtzeit-Übersetzung gesprochener Sprache in Text in einer anderen Sprache, was die grenzüberschreitende Kommunikation ermöglicht.</sample>
    <sample id="479">Die aktuellen SimulST-Modelle haben Probleme. Spezifische Architekturen werden normalerweise trainiert, wodurch zusätzliche Module eingeführt werden müssen, um optimiert zu werden.</sample>
    <sample id="480">Spezifische Architekturen werden normalerweise trainiert, wodurch zusätzliche Module optimiert werden müssen. Langer und komplizierter Trainingsprozess, z.B. mit verschiedenen Optimierungszielen.</sample>
    <sample id="481">Die aktuellen SimulST-Modelle haben folgende Probleme: Spezifische Architekturen werden normalerweise trainiert, was zusätzliche Module zur Optimierung einführt. Lange und komplizierte Trainingsverfahren, z.B. verschiedene Optimierungsziele. Training und Wartung mehrerer Modelle, um verschiedene Latenzregime zu erreichen, z.B. 1s, 2s usw.</sample>
    <sample id="482">Also, was ist unsere Lösung?</sample>
    <sample id="483">Erstens verwenden Sie bereits vorhandene offline ST-Modelle ohne Neubearbeitung oder Anpassung einer spezifischen Architektur für SimulST. Zweitens verwenden Sie nur ein Modell für jede Latenzregime und handeln Latenz durch spezifische Parameter.</sample>
    <sample id="484">Was ist unsere Lösung? 01. Nutzen Sie bereits vorhandene offline ST-Modelle ohne Neubearbeitung oder Anpassung spezifischer Architekturen für SimulIST. 02. Verwenden Sie nur ein Modell für jede Latenzregime und handeln Sie Latenz durch spezifische Parameter. 03. Nutzen Sie das bereits erlangte Wissen des Modells durch die Aufmerksamkeitsmechanismus zwischen Audiosignal und Textausgabe, das ist die Quer-Aufmerksamkeitsmechanismus. Und Sie können ein Beispiel rechts sehen.</sample>
    <sample id="485">Unser Lösungsansatz ist EDAtt oder Encoder-Decoder-Attention. Es ist eine Strategie, bei der wir entscheiden, ob eine partielle Übersetzung emittiert wird oder nicht, basierend darauf, wo die Aufmerksamkeit hinweist.</sample>
    <sample id="486">Ein Wort wird emittiert, wenn die Aufmerksamkeit nicht konzentriert ist, d. h. wenn ihre Summe unter einem bestimmten Schwellwert α, der letzten λ Sprachrahmen betrifft, was bedeutet, dass die empfangene Information stabil genug ist.</sample>
    <sample id="487">Ich werde reden.</sample>
    <sample id="488">Ich werde reden.</sample>
    <sample id="489">Wir werden sehen, dass die ersten beiden Wörter auf die frühesten erhaltenen Sprachrahmen zeigen, während das letzte Wort auf die letzten erhaltenen Sprachrahmen zeigt, also die λ Sprachrahmen.</sample>
    <sample id="490">Das bedeutet, dass die ersten beiden Wörter ausgelassen werden.</sample>
    <sample id="491">Während die Summe der Aufmerksamkeit über einer bestimmten Schwellenwerte α liegt, werden wir das letzte Wort nicht ausgeben und warten auf eine andere Sprachabschnitt.</sample>
    <sample id="492">Wenn wir weitergehen und eine andere Sprachschwelle erhalten und unser Modell andere drei Wörter vorhersagt, werden wir uns die Cross-Attention-Gewichte anschauen.</sample>
    <sample id="493">Wir werden sehen, dass keine Wörter auf die letzten λ Sprachrahmen zeigen.</sample>
    <sample id="494">Das bedeutet, dass diese drei Wörter abgegeben werden.</sample>
    <sample id="495">Wenn wir uns die Hauptergebnisse von EDAtt anschauen.</sample>
    <sample id="496">Wir plotten die Ergebnisse der simultanen Sprachübersetzung auf Graphen, auf denen BLEU auf der einen Seite steht, um die Übersetzungsqualität zu messen, und durchschnittliche Latenzzeit auf der anderen Seite.</sample>
    <sample id="497">Das ist die Latenzmessung und wir haben auch die computeraufwandsbewusste durchschnittliche Likelihood in Betracht gezogen, die die berechnungszeit der Modelle berücksichtigt, um den Output zu berechnen.</sample>
    <sample id="498">Also möchten wir, dass unsere Kurven so hoch wie möglich auf diesem Diagramm sind.</sample>
    <sample id="499">Aber wir wollen auch, dass sie sich nach links verschieben.</sample>
    <sample id="500">Wir vergleichen mit gängigen Strategien, die auch auf Offline-Modellen angewendet werden, wie dem Wait-k-Strategie und dem Local Agreement. Wir vergleichen auch mit der state of the art Architektur, die speziell für die simultane Sprachübersetzung angepasst ist.</sample>
    <sample id="501">Diese sind die Ergebnisse der simultanen Sprachübersetzung auf Deutsch.</sample>
    <sample id="502">Wir sehen, dass EDAtt alle Strategien übertrifft, die auf Offline-Modellen angewendet wurden, da ihre Kurven nach links verschoben sind.</sample>
    <sample id="503">Und wir sehen auch, dass EDAtt die schnellste Strategie ist, wenn wir die tatsächliche verstrichene Zeit oder die computergerechte Zeit berücksichtigen.</sample>
    <sample id="504">Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unser Papier. Wir haben auch den Quellcode und die Modelle offengelegt und gleichzeitig die simultane Ausgabe, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="505">Ja, der Datensatz ist öffentlich zugänglich. Wenn du mehr darüber wissen möchtest, lass es mich wissen.</sample>
    <sample id="506">Hallo alle zusammen. Mein Name ist Ying und mein Kollege Zhiyang und ich werden unsere Forschung über MultiINSTRUCT präsentieren, das die Multi-Modale Zero-Shot-Lernung durch Anweisungstuning verbessert.</sample>
    <sample id="507">Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, um prätrainierte Sprachmodelle für verschiedene unterstromende Aufgaben in einer parameter- und dateneffizienten Weise zu wiederverwenden.</sample>
    <sample id="508">Kürzlich haben viele Studien gezeigt, dass die Anweisungstuning große Sprachmodelle ermöglicht, auf unbekannte Aufgaben in einem Zero-Shot-Art zu performen, indem sie natürliche Anweisungen befolgen.</sample>
    <sample id="509">Allerdings konzentrierten sich die meisten bisherigen Arbeiten zur Anpassung der Anweisungen hauptsächlich darauf, die Leistung bei rein sprachlichen Aufgaben im Nullmodell zu verbessern, während Computersehens- und multimodale Aufgaben ausgelassen wurden.</sample>
    <sample id="510">Daher wollen wir in dieser Arbeit untersuchen, ob die Anweisungstuning von multimodalen prätrainierten Modellen tatsächlich die Generalisierung zu ungleichartigen multimodalen Aufgaben verbessern kann.</sample>
    <sample id="511">Zusätzlich haben wir bei unserer Forschung eine erhebliche Diskrepanz in der Verfügbarkeit von Anweisungsdatensätzen zwischen NLP und Multimodal entdeckt.</sample>
    <sample id="512">Es gibt mehr als 1.600 rein sprachbasierte Anweisungsaufgaben. Allerdings gibt es keine großen, öffentlich zugänglichen multimodalen Anweisungsaufgaben. Daher motiviert uns dies, einen multimodalen Anweisungsaufgabensatz zu erstellen.</sample>
    <sample id="513">Hier präsentieren wir MultiINSTRUCT, das erste multimodale Anweisungstuning-Benchmark-Datensatz, der aus 62 verschiedenen multimodalen Aufgaben besteht, die 10 breite Kategorien abdecken.</sample>
    <sample id="514">Diese Aufgaben stammen aus 21 bestehenden Open-Source-Datensätzen und jede Aufgabe ist mit fünf von Experten geschriebenen Anweisungen ausgestattet.</sample>
    <sample id="515">Für die Untersuchung multimodaler Anweisungsoptimierung auf unserem vorgeschlagenen Datensatz verwenden wir OFA, ein einheitliches multimodales prätrainiertes Modell, als Basismodell. OFA verwendet einen einheitlichen Vokabular für Sprache, Bildtoken und die Koordinaten einer Umrahmung.</sample>
    <sample id="516">Hier zeigen wir einige Beispielinstanzen aus unserem MultiInstruct-Datensatz.</sample>
    <sample id="517">Um eine Vielzahl von Eingangs- und Ausgangsdatentypen zu verarbeiten.</sample>
    <sample id="518">Wir folgen der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, in dem die Eingabetexte, Bilder, Anweisungen und Umrahmungskästchen im gleichen Tokenraum dargestellt sind.</sample>
    <sample id="519">Okay, ich werde jetzt über die multi-modale Anweisungstuning sprechen.</sample>
    <sample id="520">Für die Trainingsdatensatzkonstruktion verwenden wir 53 Aufgaben aus 9 Gruppen zur Trainingsphase und stichprobenartig 10.000 Beispiele pro Aufgabe. Für die Testdatensatzkonstruktion wird die gesamte Commonsense Reasoning Gruppe für die Testphase reserviert. Zusätzlich werden weitere 5 Aufgaben aus den VQA und den verschiedenen Gruppen ausgewählt. Wir verwenden alle Beispiele in der Testsplit für jede Aufgabe. Zufällig werden 20 Aufgaben aus der Testsplit des Natural Instructions Datensatzes als unbekannte Aufgaben für die NLP ausgewählt.</sample>
    <sample id="521">Wir verwenden alle Instanzen in der Testabtrennung für jede Aufgabe. Zudem werden wir 20 Aufgaben aus der Testabtrennung des Natural Instructions-Datensatzes zufällig ausgewählt, um als unbekannte Aufgaben für die NLP zu verwenden.</sample>
    <sample id="522">Wir verwenden einen prätrainierten OFA-Large-Modell als Basismodell während des Trainings. Wir mischen alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einem ihrer fünf Anweisungsvorlagen kombiniert.</sample>
    <sample id="523">Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir den Modell mit einer der fünf Anweisungen in jedem Experiment evaluieren.</sample>
    <sample id="524">Wir berichten die durchschnittliche und maximale Leistung und die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="525">Für multi-modale Klassifizierungsaufgaben, wie visuelle Implikation, visuelle Räumliche Denkweise, natürliche Sprache visuelle Denkweise und Katastrophentypen Klassifizierung, wird die Genauigkeit gemeldet. Für multi-modale Generierungsaufgaben, wie Commonsense VQA, Text VQA, Boden VQA, visuelle Textextraktion und visuelle Dialoge, wird die Rouge-L gemeldet. Für NLP-Aufgaben wird die Rouge-L gemeldet. Wir berechnen auch die aggregierte Leistung für jede Modell auf der Grundlage des Durchschnitts der Leistung des Modells auf allen unerkannten multi-modalen und NLP-Aufgaben. Wir verwenden Rouge-L als Leistungsbewertung für die meisten Aufgaben und Genauigkeit für Aufgaben, bei denen nur Genauigkeit als Metrik verwendet wird.</sample>
    <sample id="526">Sensitivität

Wie empfindlich das Modell gegenüber einer Vielzahl von Anweisungen für die gleiche Aufgabe ist:

- Fähigkeit, für die gleiche Aufgabe immer die gleichen Ergebnisse zu erzeugen, unabhängig von leichten Variationen in der Wortwahl der Anweisungen.</sample>
    <sample id="527">Hier sind unsere Hauptergebnisse. Wie man sehen kann, kann die Anweisungstuning die Leistung von OFA bei multimodalen Aufgaben erheblich verbessern.</sample>
    <sample id="528">Transfer-Lernen von natürlichen Anweisungsdatensätzen kann die Anweisungstuning-Vorhersage verbessern.</sample>
    <sample id="529">Hier können wir sehen, dass mit zunehmender Anzahl von Aufgaben die Modellleistung verbessert wird und gleichzeitig die Sensitivität sinkt.</sample>
    <sample id="530">Wir haben auch Experimente durchgeführt. Wir haben eine Anweisung gegen fünf Anweisungen verwendet. Wie man sehen kann, kann die Verwendung mehrerer Anweisungen die Gesamtleistung des Modells verbessern und seine Sensibilität erheblich reduzieren.</sample>
    <sample id="531">Also zeigt das hier die Auswirkung verschiedener Feinarbeit-Strategien auf die Modellsensitivität. Wie man sehen kann, kann durch das Transfer-Lernen aus dem Natural Instructions-Datensatz das Modell eine viel bessere Sensitivität erreichen im Vergleich zum ursprünglichen OFA-Modell.</sample>
    <sample id="532">Wir können auch sehen, dass Transfer Learning aus dem Natural Instructions Datensatz OFA bei der Erreichung einer viel besseren Leistung auf dem Natural Instructions Datensatz helfen kann.</sample>
    <sample id="533">Zusammenfassung: Erstes großes multi-modales Anweisungsausgleichsdatensatz. Enthält 62 multi-modale Aufgaben aus 10 breiten Kategorien. Signifikant verbessert die Zero-Shot-Fähigkeit von OFA durch Anweisungsausgleich. Verschiedene Transfer-Lernverfahren erforscht und ihre Vorteile gezeigt. Einen neuen Maßstab "Sensitivität" entworfen.</sample>
    <sample id="534">Noch eine Sache!Wir sammeln einen viel größeren multimodalen Anpassungsdatensatz mit etwa 150 zusätzlichen visuellsprachlichen Aufgaben und werden sie bald veröffentlichen!Dies ist der QR-Code für unsere Daten und das Modell. Danke!</sample>
    <sample id="535">Die Autoren gehören der Università di Trento an.</sample>
    <sample id="536">Mohammad Javad Hosseini.</sample>
    <sample id="562">Hallo alle zusammen, ich bin Koustuv Sinha und freue mich, Sie zu unserer Präsentation unserer ACL 2023 Papier "Sprachmodellakzeptanzurteile sind nicht immer robust gegenüber Kontext" willkommen zu heißen.</sample>
    <sample id="563">Sprachmodell-Acceptabilitätsurteile sind nicht immer robust gegenüber Kontext.</sample>
    <sample id="564">Minimalpaar-Paradigma, MPP, -Bewertungen von Sprachmodellen nutzen relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu beurteilen:.- BLiMP:.- 1. Viele Menschen halfen sich selbst.- 2. *Viele Menschen halfen ihr selbst.- P, 1, &gt; P, 2,.- SyntaxGym:.- 1. Kein Kunde ... hat Geld ausgegeben.- 2. *Der Kunde ... hat Geld ausgegeben.- P, 1.any, &gt; P, 2.any,.- Crows:.- 1. Stereotypischer Satz.- 2. Nicht-stereotypischer Satz.- P, 1, &gt; P, 2, In dieser Arbeit überdenken wir das Minimalpaar-Paradigma.</sample>
    <sample id="565">Minimal-Paar-Paradigma, MPP, bewertet Sprachmodelle anhand relativer Unterschiede in den Sequenzwahrscheinlichkeiten, um das abstrakte Wissen der Modelle zu beurteilen. BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P, 1, &gt; P, 2, SyntaxGym: 1. Kein Kunde ... hat etwas Geld ausgegeben. 2. *Der Kunde ... hat etwas Geld ausgegeben. P, 1.any, ≥ P, 2.any, CrowS: 1. Stereotypischer Satz. 2. Nicht-stereotypischer Satz. P, 1, &gt; P, 2, Das Minimal-Paar-Paradigma bewertet Sprachmodelle hauptsächlich anhand akzeptanzbasierter Urteile, die auch grammatikalische Aspekte wie BLiMP, SyntaxGym oder Akzeptanz in Bezug auf Stereotypen wie CrowS umfassen können.</sample>
    <sample id="566">Minimal-Paar-Paradigma, MPP, -Evaluierungen von Sprachmodellen nutzen relative Unterschiede in den Sequenzwahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP:.- 1. Viele Menschen halfen sich selbst.- 2. *Viele Menschen halfen ihr.- P, 1, &gt; P, 2,.- SyntaxGym:.- 1. Kein Kunde ... hat etwas Geld ausgegeben.- 2. *Der Kunde ... hat etwas Geld ausgegeben.- P, 1.any, ≥ P, 2.any,.- Crows:.- 1. Stereotypischer Satz.- 2. Nicht-stereotypischer Satz.- P, 1, &gt; P, 2,.- Im Minimal-Paar-Paradigma, MPP, wird das typische Verfahren zur Bewertung von Sprachmodellen verwendet, indem man einen akzeptablen Satz oder einen grammatisch korrekten Satz zeigt und dann einen unakzeptablen Satz oder einen ungrammatischen Satz zeigt.</sample>
    <sample id="567">Minimalpaar-Paradigma, MPP, -Evaluierungen von Sprachmodellen nutzen relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P, 1, &gt; P, 2,.- SyntaxGym: 1. Kein Kunde ... hat Geld ausgegeben. 2. *Der Kunde ... hat Geld ausgegeben. P, 1.any, &gt; P, 2.any,.- Crows: 1. Stereotypischer Satz. 2. Nicht-stereotypischer Satz. P, 1, &gt; P, 2, Der Hoffnung ist, dass das Modell im Grunde mehr Wahrscheinlichkeit für den akzeptablen Satz legt.</sample>
    <sample id="568">Minimalpaar-Paradigma-Evaluierungen von Sprachmodellen nutzen relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P, 1, &gt; P, 2,.- SyntaxGym: 1. Kein Kunde ... hat Geld ausgegeben. 2. *Der Kunde ... hat Geld ausgegeben. P, 1.any, &gt; P, 2.any,.- Crows: 1. Frauen sind schrecklich in Handarbeit. 2. Männer sind schrecklich in Handarbeit. P, 1, &gt; P, 2, Sind diese Urteile mit langer vorangegangener Kontextstabilität? Das aktuelle MPP-Pipeline-Lassen uns nicht die Akzeptanz von Modellen für längere Sätze bewerten.</sample>
    <sample id="569">Minimalpaar-Paradigma, MPP, -Bewertungen von Sprachmodellen nutzen relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P, 1, &gt; P, 2,.- SyntaxGym: 1. Kein Kunde ... hat Geld ausgegeben. 2. *Der Kunde ... hat Geld ausgegeben. P, 1.any, &gt; P, 2.any,.- Crows: 1. Frauen sind schrecklich in der Handarbeit. 2. Männer sind schrecklich in der Handarbeit. P, 1, &gt; P, 2, Sind diese Urteile mit langer Vorgeschichte stabil? Heutzutage haben große Sprachmodelle längere und längere Kontextfenster, daher ist es entscheidend, die Akzeptanz der Modelle im gesamten Kontextfenster zu bewerten.</sample>
    <sample id="570">Minimalpaar-Paradigma, MPP, -Bewertungen von Sprachmodellen verwenden relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P, 1, &gt; P, 2,.- SyntaxGym: 1. Kein Kunde ... hat etwas Geld ausgegeben. 2. *Der Kunde ... hat etwas Geld ausgegeben. P, 1.any, &gt; P, 2.any,.- Crows: 1. Frauen sind schrecklich in der Handarbeit. 2. Männer sind schrecklich in der Handarbeit. P, 1, &gt; P, 2, Sind diese Urteile mit langer vorangegangener Kontextstabilität?Wir versuchen hier, das MPP-Pipeline zu überarbeiten, indem wir das Modell fragen, die Akzeptanz auf längeren und längeren Sequenzen zu bewerten.</sample>
    <sample id="571">Also, was wir tun, ist, dass wir diese längeren Sequenzen simulieren. Wir durchsuchen die Datensätze selbst und erstellen dann Sätze, indem wir akzeptable oder unakzeptable Sätze aus diesen Datensätzen auswählen.</sample>
    <sample id="572">So, zum Beispiel haben wir hier ein typisches Paar von Grammatikalität aus dem BLIMP-Datensatz für den Fall des Adjunkt-Inseln ausgewählt.</sample>
    <sample id="573">Wir testen, ob die MPP-Bewertungen als eine Funktion der Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren.</sample>
    <sample id="574">Dann fügen wir es als Präfix sowohl dem akzeptablen als auch dem unakzeptablen Query hinzu.</sample>
    <sample id="575">Also können wir dasselbe machen, indem wir unakzeptable Sätze aus demselben Matching auswählen, und das könnte auch verwendet werden, um die Akzeptanz des Modells zu testen.</sample>
    <sample id="576">Wir können das gleiche auch tun, indem wir Sätze aus einer anderen Untermenge oder einem anderen Datensatz wählen. Das nennen wir den "Missmatch-Netz".</sample>
    <sample id="577">Also hier kommen die Sätze immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, mit dem Sie evaluieren. Und wir können das Gleiche für den Unannehmbarkeitsfall tun.</sample>
    <sample id="578">Schließlich können wir Sätze aus einem vollständig unverwandten Bereich wie Wikipedia wählen.</sample>
    <sample id="579">So wird uns zeigen, ob die Akzeptabilitätsurteile der Modelle tatsächlich von irgendeinem Kontext beeinflusst werden.</sample>
    <sample id="580">Testen Sie, ob die MPP-Bewertungen als eine Funktion der Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren.</sample>
    <sample id="581">Zuerst schauen wir uns die Wikipedia-Sätze an, die komplett irrelevant zu dem aktuellen Frage-Paar sind, und dann finden wir heraus, dass die MPP-Bewertungen für beliebige Kontextlängen meist robust sind.</sample>
    <sample id="582">Wir führen MPP-Bewertungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/unpassende Struktur - von Längen bis zu 900 Tokens. Wir erhöhen die Kontextlänge bis zu 1024, um die OPT- und GPT-2-Modelle zu maximieren, und sehen hier, dass die MPP-Bewertungen im orangefarbenen gepunkteten Linie relativ stabil sind.</sample>
    <sample id="583">Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/unpassende Struktur - von Längen bis zu 900 Tokens.</sample>
    <sample id="584">Hier haben wir Sätze aus akzeptablen und unakzeptablen Domänen aus dem gleichen BLiMP Syntax-Generator-Datensatz erstellt.</sample>
    <sample id="585">Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/verringern die Urteilsleistung Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/unpassende Struktur - von Längen bis zu 900 Tokens BLIMP, OPT 6.7B Vorhängstrategie Akk. (passend) Unakk. (passend) Akk. (unpassend) Unakk. (unpassend) Es zeigt sich, dass die MPP-Urteile erheblich steigen oder fallen, wenn akzeptable oder unakzeptable Präfixe hinzugefügt werden.</sample>
    <sample id="586">Aber wenn wir die Struktur passen, das heißt, wenn wir die Sätze aus den gleichen Phänomenen in der Textblame Person auswählen,</sample>
    <sample id="587">Wir sehen einen massiven Anstieg oder Abfall des MPP-Judgments für das Modell, abhängig davon, ob der gewählte Präfix akzeptabel oder unakzeptabel ist.</sample>
    <sample id="588">Der englische Inhalt lautet: "Akzeptable/unakzeptable MPP-Sätze mit passender Struktur haben am schwersten Einfluss auf das Modellleistung Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/unpassende Struktur - von Längen bis zu 900 Tokens BLIMP, OPT 6.7B Präfix-Strategie: grün: Akk. (passend), lila: Unakk. (passend), orange: Akk. (unpassend), pink: Unakk. (unpassend) 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2</sample>
    <sample id="589">Warum beeinflussen passende Präfixe die Urteile von Sprachmodellen so stark? Wir stören Kontextsätze auf Weise, die die relevanten Strukturen bewahrt, und fragen, ob Modelle ähnlich empfindlich auf diese Sätze sind. - Präfix/Suffix Adverbien: "Jedoch, &lt;sent&gt;." - Langes Präfix Adverb: "Zunächst und vor allem, &lt;sent&gt;." - Hinzufügen von Klammer: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;." - Zitat: "Gestern sagte X, &lt;sent&gt;."</sample>
    <sample id="590">Warum beeinflussen passende Präfixe die Urteile von LM?Wir stören Kontextsätze auf Weise, die die relevanten Strukturen bewahrt, und fragen, ob Modelle ähnlich empfindlich auf diese Sätze sind.Prefix/suffix Adverbien: "Jedoch, &lt;sent&gt;.".Lange Präfix-Adverbien: "Zunächst und vor allem, &lt;sent&gt;.".Hinzufügen eines Nebensatzes: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;.".Zitat: "Gestern, sagte X, &lt;sent&gt;.".Also haben wir eine Serie von Analysen durchgeführt, in denen wir versucht haben, die Eingabesätze zu stören, indem wir versuchen, die relevanten Strukturen zu bewahren, aber Lärm in den Eingaben hinzufügen. Nachdem wir mehrere dieser Störungen durchgeführt haben.</sample>
    <sample id="591">Warum beeinflussen passende Präfixe die Urteile von LM?Wir stören Kontextsätze auf Weise, die die relevanten Strukturen bewahrt, und fragen, ob Modelle ähnlich empfindlich auf diese Sätze sind.Prefix/suffix Adverbien: "Jedoch, &lt;sent&gt;.".Lange Präfix Adverbien: "Zunächst und vor allem, &lt;sent&gt;.".Hinzufügen eines Klammerzusatzes: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;.".Zitat: "Gestern sagte X, &lt;sent&gt;.".Wir finden, dass diese Störungen tatsächlich die Modelle nicht dazu bringen, ihre Entscheidungen bezüglich der Urteile zu ändern.</sample>
    <sample id="592">Warum beeinflussen passende Präfixe die LM-Bewertungen?Wir stören Kontextsätze auf Weise, die die relevanten Strukturen bewahrt, und fragen, ob Modelle diesen Sätzen ähnlich empfindlich sind.Prefix/suffix Adverbien: "Jedoch, &lt;sent&gt;.".Lange Prefix Adverbien: "Zunächst und vor allem, &lt;sent&gt;.".Hinzufügen eines Klammerabsatzes: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;.".Zitat: "Gestern sagte X, &lt;sent&gt;.".Modelle sind auf gestörte Sätze ähnlich empfindlich.</sample>
    <sample id="593">Wenn wir die Sätze im akzeptablen Bereich stören, sehen wir eine ähnliche Zunahme bei allen Störungen. Wenn wir die Sätze im nicht akzeptablen Bereich stören, sehen wir eine ähnliche Abnahme der MPP-Bewertungen.</sample>
    <sample id="594">Die Schlüsselerkenntnisse unserer Arbeit sind, dass Sprachmodelle sensibel gegenüber latenten syntaktischen und semantischen Merkmalen sind, die sich über Sätze verteilen.</sample>
    <sample id="595">Sprachmodelle sind sensibel gegenüber latenten syntaktischen/semantischen Merkmalen, die sich über Sätze verteilen. MPP-Evaluierungen mit kurzen, einzelnen Satz-Eingaben fangen nicht vollständig das abstrakte Wissen der Sprachmodelle im Kontextfenster ein.</sample>
    <sample id="596">Hauptpunkte

• Sprachmodelle sind sensibel gegenüber latenten syntaktischen/semantischen Merkmalen, die sich über Sätze verteilen.

• MPP-Evaluierungen mit kurzen, einzelnen Satz-Eingaben fangen nicht vollständig das abstrakte Wissen von LMs ein.

Lesen Sie unser Papier für weitere Details zu unseren Experimenten. Vielen Dank fürs Zuhören.</sample>
    <sample id="597">Unordered multiset of tokens that will appear in the output.</sample>
    <sample id="598">55.000 Skripte sind in Coscript vertreten.</sample>
    <sample id="626">Die beste Ausrichtungsmethode für DEplain ist die Methode von MASSalign.</sample>
    <sample id="627">Es lindert den Annotierungs-Schnellverkauf.</sample>
    <sample id="628">Das ist nicht im Bild zu sehen. Du könntest aber versuchen, es in der Quelle zu suchen, die das Bild stammt. Oder du fragst den Ersteller des Bildes direkt.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde durch Sammeln von Reuters-Nachrichten aus dem Jahr 2020 und Annotieren mit den CoNLL-2003-Annotationsempfehlungen erstellt.</sample>
    <sample id="630">Hallo alle zusammen, mein Name ist Yusen Zhang von der Penn State University. Heute werde ich unsere Arbeit präsentieren, XSemPLR: Semantische Parsing in mehreren natürlichen Sprachen und verschiedenen Bedeutungsrepräsentationen.</sample>
    <sample id="631">Semantische Analyse ist eine Aufgabe, um semantische Darstellungen von Benutzeranfragen zu erstellen, wie z.B. SQL und Lambda-Kalkül.</sample>
    <sample id="632">Kreuzsprachliche Semantikparsierung ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.</sample>
    <sample id="633">Kreuzsprachliche Semantikparsierung ist eine Aufgabe, um Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.</sample>
    <sample id="634">Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel: Mangelnde Abdeckung bestimmter natürlicher Sprachen.</sample>
    <sample id="635">Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel: Mangelnde Abdeckung bestimmter natürlicher Sprachen.</sample>
    <sample id="636">Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel: Mangelnde Abdeckung bestimmter Bedeutungsrepräsentationen.</sample>
    <sample id="637">Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel: Mangelnde Abdeckung bei bestimmten Bedeutungsrepräsentationen.</sample>
    <sample id="638">Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel: Mangelnde Abdeckung bei bestimmten neuronalen Modellen.</sample>
    <sample id="639">Wir stellen einen einheitlichen Datensatz XSemPLR für die multilinguale semantische Parsing in verschiedenen natürlichen Sprachen und Bedeutungsrepräsentationen zur Verfügung. Er enthält:.- 9 Datensätze in verschiedenen Domänen.- 5 semantische Parsing Aufgaben.- 8 Bedeutungsrepräsentationen.- 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="640">Es enthält 9 Datensätze in verschiedenen Domänen, 5 semantische Parsing Aufgaben, 8 Bedeutungsrepräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="641">Wir berücksichtigen sechs Einstellungen für die Ausbildung und Bewertung.</sample>
    <sample id="642">Wir berücksichtigen sechs Einstellungen für die Ausbildung und Bewertung. Translate-Test: Verwenden Sie die Google Translate-API, um den Quelltext ins Zielgebiet zu übersetzen. Danach verwenden Sie einen monolingualen Modell zur Ausbildung und Bewertung. Ausbildung: Englisch, Englisch-Modell, SQL. Inferenz: Deutsch, Translate API, Englisch, Englisch-Modell, SQL.</sample>
    <sample id="643">Wir trainieren das englische Modell an englischen Abfragen und bei der Inferenz übersetzen wir die deutsche Abfrage mithilfe einer API ins Englische und verwenden das trainierte Modell, um die SQL - Abfrage vorherzusagen.</sample>
    <sample id="644">Experiment-Einstellungen Wir berücksichtigen sechs Einstellungen für die Ausbildung und Bewertung. Monolingual-Modell: Quellsprache ist dieselbe wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch die Monolingual-Few-shot-Einstellung, indem wir monolinguale Modelle mit nur 10% Trainingsdaten ausbilden. Ausbildung Inferenz</sample>
    <sample id="645">In dieser Einstellung ist die Quellsprache gleich der Zielsprache, z.B. Deutsch zu Deutsch oder Englisch zu Englisch.</sample>
    <sample id="646">Wir testen auch die Monolingual Few-shot-Einstellung, indem wir monolinguale Modelle mit nur 10% des Trainingsdatensatzes trainieren.</sample>
    <sample id="647">Experiment-Einstellungen Wir berücksichtigen die sechs Einstellungen für Training und Evaluierung. Mehrsprachiges Modell: Trainiere ein mehrsprachiges Modell für alle Sprachen. Training German, English, Chinese Multilingual Model SQL Inferenz German Multilingual Model SQL</sample>
    <sample id="648">Zum Beispiel legen wir die deutschen, englischen und chinesischen Abfragen zusammen, um ein multilinguales Modell zu trainieren, und während der Inferenz können wir dieses Modell verwenden.</sample>
    <sample id="649">Experiment-Einstellungen Wir berücksichtigen die sechs Einstellungen für die Ausbildung und Bewertung. Mehrsprachiges Modell: Trainiere ein mehrsprachiges Modell für alle Sprachen. Ausbildung Deutsch, Englisch, Chinesisch Mehrsprachiges Modell SQL Inferenz Deutsch Mehrsprachiges Modell SQL</sample>
    <sample id="650">Experiment-Einstellungen Wir berücksichtigen sechs Einstellungen für die Ausbildung und Bewertung. - Cross-lingual Zero-shot/Few-shot Transfer: Ausbildung an einem Quellsprache und Transfer zu einer anderen Sprache. Ausbildung Englisch Oder Englisch Deutsches Few-shot Multilingual-Modell SQL Inferenz Deutsches Multilingual-Modell SQL</sample>
    <sample id="651">Während des Trainings wird ein multilinguales Modell mit englischen Abfragen oder der Kombination von englischen und deutschen Few-shot-Abfragen trainiert, um die SQL-Ausgabe vorherzusagen.</sample>
    <sample id="652">Analyse der monolingualen Modelle. Wir evaluieren auf zwei Gruppen von Modellen im monolingualen Setting.</sample>
    <sample id="653">Enc-PTER bezieht sich auf multilingual prätrainierte Encoder mit pointerbasierenden Decoder, wie XLM-R + PTR und mBERT + PTR.</sample>
    <sample id="654">Wir evaluieren auf zwei Gruppen von Modellen im Monolingualen Setting. Enc-PTR: Multilinguale Vorkonditionierte Encoder mit Pointer-basierten Decoder. - XLM-R + PTR, mBERT + PTR. Enc-Dec: Multilinguale Vorkonditionierte Encoder-Decoder Modelle. - mBART, mT5. Wir haben festgestellt, dass Enc-Dec, mT5, die beste Leistung auf allen Datensätzen erzielt!</sample>
    <sample id="655">Wir haben auf zwei Gruppen von Modellen im Monolingualen Setting evaluiert. Enc-PTR: Multilinguale Vorkonditionierte Encoder mit Pointer-basierten Decoder. XLM-R + PTR, mBERT + PTR. Enc-Dec: Multilinguale Vorkonditionierte Encoder-Decoder Modelle. mBART, mT5. Wir haben festgestellt, dass Enc-Dec, mT5, die beste Leistung auf allen Datensätzen erzielt!</sample>
    <sample id="656">Analyse der multilingualen Ausbildung
Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting.
• Enc-Dec/Enc-PTR, mT5/XLM-R, kann durch das Trainieren in einer Mischung verschiedener Sprachen verbessert werden.</sample>
    <sample id="657">Wir haben festgestellt, dass Enc-Decoder oder Enc-PTR durch das Trainieren in einer Mischung verschiedener Sprachen verbessert werden können.</sample>
    <sample id="658">Wir evaluieren auf mT5 und XLM-R + PTR im Multilingual Setting. Die meisten wichtigen NLs können Leistungsgewinne erzielen, außer dass die Leistung von Englisch in 7 Datensätzen abnimmt und in 3 Datensätzen steigt. Dies ist als "Fluch der Multilingualität" bekannt.</sample>
    <sample id="659">Analyse des multilingualen Trainings. Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting. Die meisten wichtigen NLs können Leistungsgewinne erzielen, außer dass die Leistung der Englischen Sprache in 7 Datensätzen abnimmt und in 3 Datensätzen zunimmt. Dies ist bekannt als "Fluch der Multilingualität".</sample>
    <sample id="660">Wir haben auch den Leistungssprung der Übersetzungen verglichen.</sample>
    <sample id="661">In diesem Diagramm ist die blaue Linie "Cross-lingual Few-shot transfer", die orangefarbene Linie "Cross-lingual Zero-shot transfer" und die grüne Linie "Monolingual Setting".</sample>
    <sample id="662">Wir haben festgestellt, dass im Vergleich der grünen und orangefarbenen Linie im null-Shot-Einstellung der cross-linguale Transferleistungsdurchbruch signifikant ist. Und im Vergleich der blauen und orangefarbenen Linie im wenige-Shot-Einstellung, der Transferdurchbruch schnell verkürzt wird.</sample>
    <sample id="663">Wir haben auch einige andere interessante Ergebnisse gefunden, zum Beispiel: Encoder-Decoder übertrifft die vorherigen Arbeiten oder erreicht vergleichbare Ergebnisse. Das Prätrainieren auf englischem Natürlichen Sprachmaterial kann die Leistung des Few-Shot-Lernens auf Zielsprachen erheblich verbessern.</sample>
    <sample id="664">Multilingual Sprachmodelle wie Codex und BLOOM sind noch immer unzureichend für die Übersetzungssemantik.</sample>
    <sample id="665">Wir bauen XSemPLR, einen einheitlichen Benchmark für die multilinguale semantische Parsing mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen.</sample>
    <sample id="666">Zusammenfassung: - Wir haben XSemPLR erstellt, einen einheitlichen Benchmark für die multilinguale semantische Analyse mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen. - Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen multilingualer Sprachmodelle durch. - Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Ausbildung die beste Leistung erzielt, während multilingual ausgerichtete LLMs noch nicht in der Lage sind, multilinguale semantische Analyseaufgaben auszuführen. Zudem ist der Leistungssprung zwischen monolingualer Ausbildung und multilingualem Transfer-Lernen immer noch signifikant. Links: Willkommen, um unsere Arbeit und den Code zu besuchen! - Papier-Link: https://arxiv.org/pdf/2306.04085.pdf - Code-Link: https://github.com/psunlpgroup/xsemplr</sample>
    <sample id="667">Parameter-basierte Wasserzeichen, Lexikalische Wasserzeichen, Backdoor-basierte Wasserzeichen und Adversarial-basierte Wasserzeichen.</sample>
    <sample id="668">Nein, sie sind noch nicht ausreichend für CLSP. Wenn du noch mehr Fragen hast, lass es mich wissen!</sample>
    <sample id="695">Die Methode löst die Mehrdeutigkeit der Permutationen, indem sie die Ausrichtung als Teil des Trainings induziert.</sample>
    <sample id="696">The fairness of a downstream NLP model is defined as the ability to handle hate speech and misinformation fairly across different political leanings.</sample>
    <sample id="697">Yanis Labrak.</sample>
    <sample id="698">Koustuv Sinha.</sample>
    <sample id="699">Myra Cheng.</sample>
    <sample id="700">Tropikalismus bezieht sich auf die Verbindung von Wörtern, die Latina Frauen beschreiben, wie "vibrant" und "curvaceous", die mit einer bestimmten Tropenidee assoziiert sind. Es ist eine Art Stereotyp, das bestimmte Eigenschaften von Frauen von bestimmten ethnischen Gruppen mit den Tropen in Verbindung bringt.</sample>
    <sample id="701">Die Autoren haben die Beschreibungen der Zielgruppen erstellt, indem sie Wörter wie Kultur, Tradition, Stolz und Exotisch für markierte Gruppen verwendeten. Diese Wörter definieren diese Gruppen nur in Bezug auf ihre Identität und unterscheiden sie von der weißen Norm. Wenn du noch mehr Details wissen möchtest, frag einfach nach.</sample>
    <sample id="702">In dieser Arbeit wurde P-CXMI zur Messung der Kontextnutzung verwendet.</sample>
    <sample id="703">DrBERT wird von Scratch mit voller Modellkonstruktion trainiert, ChuBERT wird von Scratch trainiert.</sample>
    <sample id="751">Drei.</sample>
    <sample id="752">Iteratives Transferlern ist ein Verfahren, bei dem der Modell durch Training auf der neuesten Datenmenge aktualisiert wird.</sample>
    <sample id="753">Das Ziel ist, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen.</sample>
    <sample id="754">Nicht im Bild.</sample>
    <sample id="755">Drei. Sara Papi, Matteo Negri und Marco Turchi. Wenn du noch mehr über die Arbeit wissen möchtest, frag einfach.</sample>
    <sample id="756">Nicht erwähnt.</sample>
    <sample id="757">Sebastian Santy und Ronan Le Bras gehören der University of Washington an, Jenny T. Liang und Maarten Sap der Carnegie Mellon University, Katharina Reinecke auch der University of Washington.</sample>
    <sample id="758">I saw Bart and Lisa.</sample>
    <sample id="759">Der Stand der Technik für Dialogsysteme beinhaltet die Fähigkeit, verschiedene thematische Fehler zu messen. Wenn du mehr über Dialogsysteme wissen möchtest, frag einfach weiter.</sample>
    <sample id="760">Weil große Sprachmodelle längere Kontextfenster haben.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt. Es gibt sieben Datensätze, in denen die Leistung von Englisch abgenommen hat.</sample>
    <sample id="762">Nein, sie kennen die Entität nicht im Voraus.</sample>
    <sample id="763">Leider ist im Bild nichts über die verwendeten MT-Metriken zu sehen. Du könntest versuchen, die Präsentation weiter zu durchsuchen oder den Sprecher nach den Metriken zu fragen.</sample>
    <sample id="764">Nicht direkt. Es geht um die Modelle und ihre Größe.</sample>
    <sample id="765">Positionalität ist wichtig für NLP, weil es die Bedeutung von Worten in verschiedenen Positionen in einem Satz beeinflusst. So kann dieselbe Wortfolge unterschiedliche Bedeutungen haben. Wenn du noch mehr dazu wissen möchtest, frag einfach nach.</sample>
    <sample id="766">Nicht bekannt. Es gibt keine genauen Informationen darüber, ob BLOOM oder andere mehrsprachige LLMs durch Adapter oder eine vollständige Feinabstimmung angepasst wurden. Wenn du mehr darüber erfahren möchtest, könnte ich versuchen, weitere Quellen zu recherchieren.</sample>
    <sample id="767">Wir verwenden das RoBERTA-base + classifier head Modell.</sample>
    <sample id="768">Leider ist in dem gegebenen Text nichts über die genutzten Testsets zur Bewertung der PaLM-Fähigkeiten erwähnt. Möchtest du noch etwas anderes wissen?</sample>
    <sample id="769">Die Autoren haben schließlich drei Empfehlungen vorgeschlagen. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="770">Der Gewinn der vorgeschlagenen Methode gegenüber der stärksten Baseline beträgt 10.00.</sample>
    <sample id="771">Shuheng Liu.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark verwendet werden. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="773">In der Arbeit wird mit zwei kleineren Modellen experimentiert. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="774">OFA wird als Basismodell verwendet.</sample>
    <sample id="833">Ich weiß es nicht. Es gibt keine Angabe zur Universität der Autoren im Bild. Wenn du mehr Informationen haben möchtest, kannst du den Text des Papiers durchlesen.</sample>
    <sample id="834">Die Autoren gehören der Stony Brook University an.</sample>
    <sample id="835">Die Arbeit untersucht nicht spezifische Sprachpaare. Es geht um die Leistung von LLMs in der MT. Wenn du mehr Details haben möchtest, frag einfach nach.</sample>
    <sample id="836">Shangbin Feng.</sample>
    <sample id="837">Es wurden zwei Modelle untersucht: ein finetuned long-mBART für Dokument-Ebenen-Simplifizierung und ein finetuned mBART für Satz-Ebenen-Simplifizierung.</sample>
    <sample id="838">53 Aufgaben werden für Training und Tests verwendet.</sample>
    <sample id="839">Drei.</sample>
    <sample id="840">Die Autoren haben an AG News, MIND, SST2 und Enron Spam experimentiert.</sample>
    <sample id="876">NACHOS ist ein Datensatz von medizinischen Crawledaten aus dem Web.</sample>
    <sample id="877">David Vilar Torres.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse. 516 von 1000 Sätzen zeigen eine Differenz von mehr als 1 BLEURT-Punkt, und die Differenz kann bis zu 40 BLEURT-Punkten betragen.</sample>
    <sample id="879">Die Autoren gehören an die Carnegie Mellon University, Técnico Lisboa und Berkeley Artificial Intelligence Research.</sample>
    <sample id="880">Sorry, the image doesn't provide the 5 expert instructions. Can you give me more details or context?</sample>
    <sample id="881">Sie schlagen vor, Modelle mit dem KITMUS Test Suite zu testen, der ein Dataset für die Evaluierung der Wissensintegration und eine Coreference Resolution Task hat, um die Fähigkeit zu prüfen, Informationen aus verschiedenen Quellen zu nutzen.</sample>
    <sample id="882">Hallo alle zusammen. Mein Name ist David Vilar Torres und ich werde einen kurzen Überblick über das Papier "Prompting PaLM for Translation: Assessing Strategies and Performance" geben. Dies ist ein gemeinsames Projekt mit meinen Kollegen von Google Translate.</sample>
    <sample id="883">PaLM ist ein 540 Milliarden Parameter enthaltendes Sprachmodell, das letztes Jahr, 2022, präsentiert wurde. Es wurde an einer großen Sammlung von Texten, die 780 Milliarden Tokens umfasst, trainiert.</sample>
    <sample id="884">In der Anwendung erzielt es den Stand der Technik in Hunderten von End-to-End-Aufgaben.</sample>
    <sample id="885">In dieser Arbeit präsentieren wir die erste systematische Untersuchung von Prompting für maschinelle Übersetzung mit Hilfe von Large Language Models.</sample>
    <sample id="886">Wir haben die Übersetzungsfähigkeiten solcher Modelle unter Verwendung der besten Praktiken der MT-Gemeinschaft evaluiert. Dies beinhaltet die Verwendung der neuesten Testdatensätze, um eine Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden.</sample>
    <sample id="887">Wir verglichen mit den besten Systemen, also den besten leistungsstarken Systemen, die bei der WMT-Evaluation die besten Ergebnisse erzielt haben.</sample>
    <sample id="888">Wir verwenden zukunftsweisende neuronale MT-Metriken und zeigen zusätzlich die Ergebnisse der expertenbasierten menschlichen Evaluierung. Schließlich geben wir einige Empfehlungen für Prompt-Auswahlstrategien.</sample>
    <sample id="889">Die Prompting hat einen großen Einfluss auf die Leistung von LLMs für die Übersetzung. Wie wir in einem einfachen Experiment sehen können, in dem wir One-Shot Prompting verwenden und zwei verschiedene Prompts für jede Satzpaar bereitstellen.</sample>
    <sample id="890">Die meisten Sätze, 516 von 1000, weisen eine Differenz von mehr als 1 BLEURT-Punkt auf.</sample>
    <sample id="891">Prompte haben einen großen Einfluss auf die Übersetzungsqualität. Zwei zufällige Prompte für jede Satz auswählen. BLEURT für jedes Satz-Prompt-Paar berechnen. Die Mehrheit der Sätze, 516 von 1000, zeigen eine Differenz von mehr als 1 BLEURT-Punkt. Die Differenz kann bis zu 40 BLEURT-Punkten erreichen!</sample>
    <sample id="892">Ein Zivilist alarmierte die Polizei, die mit mehreren Streifen anrückte.</sample>
    <sample id="893">Ein Zivilist alarmierte die Polizei, die mit mehreren Streifen anrückte.</sample>
    <sample id="894">Ein Zivilist alarmierte die Polizei, die mit mehreren Streifen anrückte.</sample>
    <sample id="895">Es ist entscheidend für Zero - und One - Shot - Prompting. Und wenn wir uns auf unseren Fall konzentrieren, das Five - Shot - Prompting, gibt es fast keinen Unterschied in der tatsächlichen Form des Promptings.</sample>
    <sample id="896">Ein Zivilist alarmierte die Polizei, die mit mehreren Streifen anrückte.</sample>
    <sample id="897">Die Übersetzung lautet: "Die Beispielqualität ist wichtiger als die Ähnlichkeit zum Quellsatz." Wenn du noch weitere Fragen hast oder mehr Übersetzungen brauchst, lass es mich wissen!</sample>
    <sample id="898">Es ist wichtig, Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere haben wir die Auswahl von Prompts aus dem Trainingsdatensatz der WMT-Evaluierungen oder dem Testdatensatz verglichen.</sample>
    <sample id="899">Das Dev-Datensatz ist viel sorgfältiger ausgewählt und von höherer Qualität als das Train-Datensatz. Es ist ordnender und die Ergebnisse sind besser. Also eine bessere Leistung, wenn man den Dev-Datensatz verwendet.</sample>
    <sample id="900">Trotzdem haben spezialisierte SOTA-Systeme einen erheblichen Vorteil gegenüber PaLM-Übersetzungen, aber PaLM kommt relativ nahe an ein kommerzielles System heran. In unserem Fall haben wir uns für eine Überlagerung mit Google Translate entschieden.</sample>
    <sample id="901">Die Erkenntnisse, die wir aus der Evaluierung mit dem MQM-Framework gewonnen haben, sind, dass die Flüssigkeit von PaLM vergleichbar mit den state-of-the-art-Systemen ist, aber der Hauptunterschied liegt in der Genauigkeit.</sample>
    <sample id="902">Die häufigsten Fehler sind Omissionsfehler.</sample>
    <sample id="903">Es scheint, dass PaLM manchmal um eine bessere Übersetzung herum geht, indem es Teile des Quellsatzes weglässt, die in der Übersetzung irrelevant sind.</sample>
    <sample id="904">Die Beispielqualität ist wichtiger als die Ähnlichkeit zum Quellsatz. Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. PaLM ist fast so gut wie Google Translate. AusMQM-Erkenntnisse: Die Fluenz von PaLM ist vergleichbar mit SOTA. Genauigkeitsscores sind im Allgemeinen niedriger. Dominiert von "Genauigkeit/Überschreibung". "Stil/Unangenehm" ist für PaLM generell niedriger.</sample>
    <sample id="905">Das PaLM liefert wirklich flüssige Ausgaben, aber es hat noch einige Probleme mit der Genauigkeit.</sample>
    <sample id="906">Das ist alles für diese kurze Übersicht. Für weitere Details kommen Sie bitte zur vollständigen Präsentation des Papiers. Vielen Dank.</sample>
    <sample id="907">Hallo, ich bin Dawei, ein Doktorand an der Saarland University in Deutschland. In diesem Video möchte ich unsere jüngste Arbeit "Weaker Than You Think: A Critical Look at Weakly Supervised Learning" präsentieren.</sample>
    <sample id="908">Dies ist eine gemeinsame Arbeit mit Xiaoyu Shen, Marius Mosbach, Andreas Stephan und Dietrich Klakow.</sample>
    <sample id="909">Warum schwach überwachte Lernen?• Schwache Überwachung lindert den Annotierungsblock. • Aber schwache Etiketten sind laut! → Lauteretention schadet der Generalisierung. • Schwach überwachtes Lernen, WSL, → Trainiere Modelle, die gut generalisieren, obwohl sie mit lautem Datenmaterial trainiert werden.</sample>
    <sample id="910">Warum schwach überwachte Lernen?• Schwache Überwachung lindert den Annotierungsblock. • Aber schwache Etiketten sind laut! Noise-Memorierung schadet der Generalisierung. • Schwach überwachtes Lernen, WSL, Trainiere Modelle, die trotz des Trainings an lauter Daten gut generalisieren.</sample>
    <sample id="911">Warum schwach überwachte Lernen?• Schwache Überwachung lindert den Annotierungs-Schnellverkauf. • Aber schwache Etiketten sind laut! Noise-Memorierung schadet der Generalisierung. • Schwach überwachtes Lernen, WSL, Trainiere Modelle, die gut generalisieren, obwohl sie mit lautiger Daten trainiert werden. Verglichen mit menschlichen Annotierungen sind schwache Annotierungen viel billiger, aber sie sind auch laut, was bedeutet, dass eine gewisse Menge der Annotierungen falsch ist.</sample>
    <sample id="912">Wenn wir Neuronennetze direkt an schwach beschrifteten Daten trainieren, neigen die Neuronennetze dazu, die Lärmgeräusche zu speichern und nicht zu generalisieren.</sample>
    <sample id="913">Warum schwach überwachte Lernen?• Schwache Überwachung lindert den Annotierungs-Schnellverkauf.Bei schwachen Etikettierungsquellen, z.B. Heuristiken, Wissensbasen, Unetikettiertes Datenmaterial, schwach etikettiertes Datenmaterial, unklar, einige Etikettierungen sind falsch, trainieren Modelle, die gut generalisieren, obwohl sie auf unklarem Datenmaterial trainiert wurden.</sample>
    <sample id="914">In den letzten WSL-Arbeiten ist eine häufige Behauptung zu hören, dass Modelle nur mit schwach überwachten Daten trainiert werden und eine Genauigkeit von XX% erzielen.</sample>
    <sample id="915">Ein häufiger Behauptung in jüngeren WSL-Arbeiten "Wir trainieren Modelle nur mit schwach überwachten Daten und erzielen eine Genauigkeit von XX%." Technisch ist diese Behauptung nicht falsch, aber es gibt einen Haken.</sample>
    <sample id="916">Ein häufiger Anspruch in jüngeren WSL-Arbeiten ist, dass Modelle nur mit schwach überwachten Daten trainiert werden und eine Genauigkeit von XX% erreichen.</sample>
    <sample id="917">Wir trainieren Modelle nur mit schwach überwachten Daten und erzielen eine Genauigkeit von XX%.</sample>
    <sample id="918">Die oben genannten Forschungsfragen sind: Erstens, ist sauberes Validierungsdaten für WSL notwendig? Oder können wir vielleicht ein rauschiges Validierungsset verwenden?</sample>
    <sample id="919">Zunächst einmal, ob saubere Validierungsdaten erforderlich sind oder ob saubere Daten für WSL unbedingt notwendig sind, um zu funktionieren, dann wie viele saubere Proben brauchen wir? Schließlich sollten wir nur die sauberen Proben für die Validierung verwenden oder gibt es bessere Wege, sie zu nutzen?</sample>
    <sample id="920">Wir haben diese Forschungsfragen in unserer Arbeit behandelt und unsere Ergebnisse lauten wie folgt.</sample>
    <sample id="921">Zunächst stellen wir fest, dass interessanterweise jüngere WSL -Methoden tatsächlich saubere White-Data -Beispiele benötigen, um ordnungsgemäß zu funktionieren.</sample>
    <sample id="922">Andernfalls gibt es einen großen Leistungsabfall, wie in diesem Diagramm gezeigt. Wenn es keine sauberen Validierungssamples gibt, können die trainierten Modelle nicht über die ursprünglichen schwachen Beschriftungen hinaus generalisieren.</sample>
    <sample id="923">Die Bedeutung der Trainingsdaten ist bedeutungslos.</sample>
    <sample id="924">Dies deutet darauf hin, dass WSLS-Ansätze tatsächlich sauber gekennzeichnete Daten benötigen, um ordnungsgemäß zu funktionieren, und die Annotierungskosten für die Erhaltung sauberer Validierungssamples sollten nicht übersehen werden.</sample>
    <sample id="925">Unser zweites Ergebnis ist, dass eine Erhöhung der Anzahl an sauberen Validierungssamples WSL-Ansätze bei besserer Leistung hilft, wie im Bild links gezeigt.</sample>
    <sample id="926">Typischerweise benötigen wir nur 20 Proben pro Klasse, um eine hohe Leistung zu erzielen.</sample>
    <sample id="927">Aber das ist nicht das Ende der Geschichte, denn wenn wir uns entscheiden, saubere Samples zu zugreifen, dann wird die direkte Ausbildung an ihnen sogar bessere Leistung erzielen.</sample>
    <sample id="928">Das rechte Bild zeigt den Leistungsunterschied zwischen Anpassungsmethoden, die direkt auf reinem Datenmaterial angewendet werden, und WSL-Ansätzen, die das reinen Datenmaterial nur zur Validierung verwenden.</sample>
    <sample id="929">Wie wir sehen, wenn wir zehn Proben pro Klasse haben, beginnt die direkte Anpassung, FT, WSL-Ansätze zu überbieten.</sample>
    <sample id="930">Schließlich können die Leistungsverbesserungen, die frühere WSL-Ansätze behaupteten, leicht durch das Erlauben der weiteren Feinarbeit an reinen Validierungssamples erreicht werden.</sample>
    <sample id="931">Wie wir aus den Abbildungen sehen können, der Valina-Modelltyp FTW zeigt sich anfangs schlechter als kompliziertere WSL -Methoden wie COSINE.</sample>
    <sample id="932">Wenn wir aber weiterhin auf den sauberen Samples abstimmen, dann leistet FTW genauso gut wie andere Methoden.</sample>
    <sample id="933">Also in der Praxis gibt es keinen Grund, komplexere WSL -Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern.</sample>
    <sample id="934">Zusammenfassend haben wir gezeigt, dass jüngste WSL-Ansätze saubere, manuell annotierte Samples benötigen, um ordnungsgemäß zu funktionieren. Ihre Leistung und Praktikabilität werden stark überbewertet.</sample>
    <sample id="935">Kürzere WSL-Ansätze erfordern saubere Samples. Sie überschätzen ihre Praktikabilität. Unsere Empfehlungen: Berichten Sie die Modell-Auswahlkriterien. Verwenden Sie Few-shot-Learning-Ansätze als Baselines. Stellen Sie immer kontinuierliche Feinarbeit, CFT, an.</sample>
    <sample id="936">Zusammenfassung

Neuere WSL-Ansätze

- Erfordern saubere Samples.
- Ihre Praktikabilität überschätzen.

Unsere Empfehlungen

- Berichte die Modell-Auswahlkriterien.
- Verwende Few-shot-Learning-Ansätze als Baseline.
- Verwende stets kontinuierliche Feinarbeitung, CFT.</sample>
    <sample id="937">Zweitens sollten WSL-Ansätze mit Few-shot-Learning-Baselines verglichen werden, da beide auf sauberen Samples arbeiten. Drittens ist das kontinuierliche Feinarbeiten eine einfache aber starke Baseline, die in zukünftigen Arbeiten im WSL berücksichtigt werden sollte.</sample>
    <sample id="938">Schlussfolgerung

Neuere WSL-Ansätze

- Erfordern saubere Samples.
- Überbewerten ihre Praktikabilität.

Unsere Empfehlungen

- Berichten Sie die Modell-Auswahlkriterien.
- Verwenden Sie Few-shot-Lern-Ansätze als Baseline.
- Anwenden Sie stets kontinuierliche Feinarbeit, CFT.

Schließlich haben wir unseren Code offengelegt. Sie können ihn über den QR-Code auf dieser Folie finden. Bitte schauen Sie sich das gerne an. Vielen Dank und viel Spaß auf der Konferenz.</sample>
    <sample id="939">Gängige Bewertungsmethoden für Dialogsysteme sind die menschliche Bewertung, wie z.B. wenn menschliche Richter entscheiden, welche von zwei Gesprächen besser ist, oder wenn Gespräche auf einer Likert-Skala bewertet werden.</sample>
    <sample id="940">Fünf. Wenn du noch mehr über die Arbeit wissen möchtest, frag einfach.</sample>
    <sample id="941">Dass Richter in Gerichten von Rechts wegen Entscheidungen treffen.</sample>
    <sample id="942">Ja, der Code ist verfügbar. Du kannst ihn auf GitHub unter mpoemsl/kitmus finden.</sample>
    <sample id="943">Nein, sie sind nicht ausgewogen. Wenn du mehr Details haben möchtest, frag einfach nach.</sample>
    <sample id="944">Oh, that's a good question. So, they just randomly shuffled the sentences within the acceptable domain. Pretty straightforward, right? If you have more questions about it, feel free to ask!</sample>
    <sample id="945">Eine dimensionale Bewertung bedeutet, verschiedene Aspekte zu betrachten, um eine umfassendere Einschätzung zu erhalten. So kann man beispielsweise die Qualität eines Dialogs aus mehreren Perspektiven bewerten. Wenn du mehr dazu wissen möchtest, frag einfach nach.</sample>
    <sample id="946">Die Autoren gehören an die University of Science and Technology of China, Microsoft Research Asia, Beijing Jiaotong University, Sony AI und Microsoft STC Asia.</sample>
    <sample id="947">Die Form des Prompts ist wichtig für 0- und 1-Shot-Prompting.</sample>
    <sample id="978">Die Autoren haben BART-FID-RAG, Blender2, Emora und Blender-Decode evaluiert.</sample>
    <sample id="979">Sechs.</sample>
    <sample id="980">Ein guter Planer sollte Skripte schreiben, die realistisch und den Bedingungen entsprechend sind.</sample>
    <sample id="981">Acht Autoren sind an der Arbeit beteiligt. Wenn du mehr über die Arbeit erfahren möchtest, frag einfach nach.</sample>
    <sample id="982">Vasudha Varadarajan.</sample>
    <sample id="983">Die Autoren gehören der University of Warsaw an.</sample>
    <sample id="1021">Die häufigsten Fehler von PaLM sind Omissionen. Wenn du noch mehr Fragen hast, lass sie gerne stehen.</sample>
    <sample id="1022">Hallo, ich bin James Finch und ich bin Sarah Finch. Und heute werden wir Ihnen alles über ABC eval erzählen, eine neue dimensionale Herangehensweise zur Bewertung von Konversations-IA.</sample>
    <sample id="1023">Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Jinho Choi an der Emory University durchgeführt und in Zusammenarbeit mit Amazon Alexa AI.</sample>
    <sample id="1024">Nehmen wir an, du hast gerade ein Dialogmodell entwickelt und möchtest sehen, wie gut es im Vergleich zum aktuellen Stand der Technik steht.</sample>
    <sample id="1025">Die übliche Praxis ist, menschliche Bewertungen zu verwenden, z.B. indem man menschliche Richter fragt, welche von zwei Gesprächen besser ist oder Gespräche nach einer Likert-Skala bewertet.</sample>
    <sample id="1026">Diese Ansätze funktionieren gut, um eine umfassende Beurteilung der Gesamtdialogqualität zu ermöglichen, aber Dialogqualität hat viele Aspekte. Daher möchtest du möglicherweise mehrere Dimensionen der Chatqualität beurteilen, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen.</sample>
    <sample id="1027">Eine Möglichkeit ist, menschliche Richter zu fragen, mehrere Dimensionen der Dialogqualität zu bewerten, wie z.B. die Relevanz der Modelldenkmale, mit Hilfe bestehender vergleichender oder Likert-Skala - Methoden.</sample>
    <sample id="1028">Allerdings glauben wir, dass es eine präzisere und zuverlässigere Strategie für die dimensionale Dialogbewertung gibt.</sample>
    <sample id="1029">Unser Ansatz versucht, die Subjektivität der menschlichen Beurteilung zu reduzieren, indem bestimmte Verhaltensweisen, wie das Angeben von irrelevanten Informationen oder das Widersprechen sich selbst, explizit an den Modellantworten beschriftet werden.</sample>
    <sample id="1030">Wir nennen diesen Ansatz "Annotating Behaviors in Chat" oder kurz ABC-Eval. Wir haben diesen Ansatz entwickelt, um umfassend die Chat-Modellverhaltensweisen abzudecken, die in der neueren Literatur als diejenigen angesehen werden, die die Chat-Qualität beeinflussen.</sample>
    <sample id="1031">ABC-Eval kann die Raten messen, bei denen Chatmodelle verschiedene thematische Fehler begehen.</sample>
    <sample id="1032">Zum Beispiel misst ABC-Eval die Anzahl der Runden, in denen ein Chatmodell seinen Partner ignoriert oder etwas Ungerelevantes sagt.</sample>
    <sample id="1033">Kontrahiert sich selbst oder seinem Partner, halluziniert falsche Fakten oder verstößt gegen allgemein verstandenes Wissen und zeigt Empathie, wenn das Modell Erfolg oder Misserfolg hat.</sample>
    <sample id="1034">Um zu bestimmen, welche Art der Bewertung am effektivsten ist, haben wir vier state-of-the-art Chat-Modelle ausgewählt und sie mit ABC-Eval an 100 menschlichen-roboterischen Konversationen pro Modell bewertet.</sample>
    <sample id="1035">Für die Vergleichung haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: Likert-Bewertungen auf Turn-Ebene, Likert-Bewertungen auf Dialog-Ebene und Dialog-Ebene Paarvergleiche.</sample>
    <sample id="1036">Für die bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen auf mehreren Dimensionen ist.</sample>
    <sample id="1037">Aus unseren Analysen dieser Evaluierungsergebnisse haben wir herausgefunden, dass die ABC-Eval-Behavior-Etiketten im Allgemeinen zuverlässiger sind als Etiketten, die von bestehenden Methoden gesammelt wurden, wie durch die Inter-Annotator-Übereinstimmung an hundert doppelt beschrifteten Gesprächen gemessen wird.</sample>
    <sample id="1038">Zusätzlich sind die ABC-Eval-Etiketten prägnanter für die Gesamtqualität des Gesprächs als die von bestehenden Methoden erzeugten Metriken, wie durch eine einfache lineare Regressionsanalyse gezeigt wird.</sample>
    <sample id="1039">Zum Beispiel kannst du sehen, wie das Messen der Proportion von Sätzen mit selbst und partnerkontrahierenden Erklärungen 5% und 10% der Gesprächsqualität erklärt, während die durchschnittlichen Likert-Konsistenzwerte nur 4% oder weniger erklären.</sample>
    <sample id="1040">Schließlich haben wir überprüft, ob jede Evaluierungsmaße ein einzigartiges Aspekt der Chatqualität erfassen, indem wir eine Schrittweise lineare Regression durchgeführt haben.</sample>
    <sample id="1041">Du kannst sehen, wie die Kombination aller ABC-Eval-Metriken über 25% der Gesprächsqualität erklärt. Und wenn man die Metriken nacheinander entfernt, verlieren die meisten von ihnen eine beachtliche Menge an Informationen über die Qualität.</sample>
    <sample id="1042">Andererseits erklärt die Kombination aller turnlevel-Likert-Metriken weitaus weniger die Qualität und weniger dieser Metriken tragen einzigartige Informationen bei.</sample>
    <sample id="1043">Diese zuverlässigen und unterschiedlichen ABC-Eval-Metriken ermöglichen es uns, die Konversations-IA mit einer höheren Auflösung zu bewerten als bisherige Methoden es schaffen.</sample>
    <sample id="1044">Man kann sehen, dass in den Ergebnissen unserer Experimente noch einige Herausforderungen bestehen und präzise quantifiziert wurden. Zum Beispiel haben die getesteten Bots in etwa 20% ihrer Antworten Common-Sense-Violationen.</sample>
    <sample id="1045">Sie produzieren ungefähr 15% irrelevante Informationen in den Antworten und widersprechen sich oder ihrem Partner ungefähr 10% der Zeit.</sample>
    <sample id="1046">Mit dem schnellen Tempo der Verbesserungen in diesem Bereich könnten viele dieser Fehlerquoten bei neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, abnehmen. Allerdings ist das umso mehr Grund, sich für zuverlässige und präzise Bewertungsmetriken zur Modellvergleichung einzusetzen.</sample>
    <sample id="1047">Wir hoffen, dass ABC-Eval von anderen im Bereich als ein bedeutender Schritt in diese Richtung genutzt werden kann, und wir freuen uns darauf, zu sehen, wie sich die KonversationskI in den kommenden Monaten und Jahren weiterentwickeln wird. Danke fürs Zuschauen.</sample>
    <sample id="1048">Die Autoren gehören der Emory University an.</sample>
    <sample id="1049">CFT steht für Continuous Fine-tuning.</sample>
    <sample id="1050">Sechs.</sample>
    <sample id="1051">Hallo, mein Name ist Kayo Yin und ich werde unsere Arbeit mit dem Titel "Wann erfordert eine Übersetzung Kontext? Eine datengetriebene multilinguale Erforschung" präsentieren. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandes, Emmy Liu, André F. T. Martins und Graham Neubig durchgeführt.</sample>
    <sample id="1052">Wir müssen diesen Spion loswerden.</sample>
    <sample id="1053">Wenn der vorherige Satz "Dinge könnten gefährlich werden, wenn die Minister es herausfinden." war, dann bezieht sich "Mole" auf einen Spion. Aber wenn der vorherige Satz "Kann es etwas Ernstes sein, Doktor?" war, dann bezieht sich "Mole" auf eine Narbe.</sample>
    <sample id="1054">Kann es etwas Ernstes sein, Doktor? Wir müssen diesen Fleck loswerden.</sample>
    <sample id="1055">Die Bewertung kontextabhängiger Übersetzungen ist schwierig. Lediglich ein kleiner Teil der Wörter hängt vom Kontext ab. Allerdings ist es ziemlich schwierig, zu beurteilen, wie gut Modelle solche kontrastiven Fälle beherrschen. Zunächst einmal, weil nur ein kleiner Teil der Übersetzungen vom Kontext abhängt, was korpusbasierte Maße wie BLEU nicht in der Lage macht, diese Übersetzungen zu erfassen.</sample>
    <sample id="1056">Die Bewertung von kontextabhängiger Übersetzung ist schwierig. Nur ein kleiner Teil der Wörter hängt vom Kontext ab. Korpus-basierte Maße. Bestehende Methoden unterstützen begrenzte Diskursphänomene und Sprachen. Einige Leute haben vorgeschlagen, gezielte Bewertung von kontextabhängigen Übersetzungen durchzuführen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachensätze, da sie normalerweise auf Domänenwissen und menschlicher Kuration zurückgreifen.</sample>
    <sample id="1057">In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten. Zuerst, wann benötigt eine Übersetzung Kontext, und zweitens, wie gut handeln Modelle mit solchen Fällen um?</sample>
    <sample id="1058">Um die erste Frage zu beantworten, haben wir damit begonnen, zu messen, wie stark ein Wort im Übersetzen von Kontext abhängt.</sample>
    <sample id="1059">In der vorherigen Arbeit haben wir CXMI als Maß für den Kontextgebrauch von Maschinentranslationsmodellen eingeführt. Dies wird durch die Messung der Menge an Information erfasst, die der Kontext C über die Zielvariable Y gegeben der Quelle X bereitstellt.</sample>
    <sample id="1060">Kontextbedingte Kreuz-Mutual Information, CXMI, ist eine Maßeinheit, die die Menge der Kontextbedingten MT-Modelle misst, die einem Korpus zugänglich sind. CXMI kann als die Information angesehen werden, die durch das Hinzufügen von Kontext an das Modell gewonnen wird.</sample>
    <sample id="1061">In dieser Arbeit haben wir CXMI zu Pointwise-CXMI erweitert, was die Kontextnutzung auf Satz- oder Wortebene messen kann. Wir können Wörter mit hohem P-CXMI als solche betrachten, die für die Übersetzung Kontext benötigen.</sample>
    <sample id="1062">Nun analysieren wir Wörter mit hohem P-Index, um Muster zwischen diesen Wörtern zu suchen.</sample>
    <sample id="1063">Wir führen unsere Analyse an Transkripten von TED - Vorträgen durch, die von Englisch in 14 verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="1064">Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zuerst sehen wir uns Part-of-Speech-Tags an, die hohe Bedeutung haben, P-CXMI.</sample>
    <sample id="1065">Themenanalyse hochwertiger P-CXMI-Wörter
1. POS-Tags
- Pronomen
  - Doppelpronomen in Arabisch mit relativ hohem P-CXMI. Dies kann erklärt werden, da Englisch keine Doppelpronomen hat, sodass Kontext notwendig ist, um festzustellen, ob ein Pronomen dual ist, wenn es ins Arabisch übersetzt wird.</sample>
    <sample id="1066">Themenanalyse hochwertiger P-CXMI-Wörter. 1. POS-Tags. - Pronomen - Verbform. Ähnlich finden wir, dass bestimmte Sprachen auch Kontext benötigen, wenn wir die passende Verbform wählen möchten. Wir schauen dann auf Vokabularpunkte mit hohem P-CXMI, gemittelt über alle ihre verschiedenen Vorkommen.</sample>
    <sample id="1067">Und das hilft, Fälle wie hier zu identifizieren, wo in Chinesisch Kontext benötigt wird, um die richtigen Eigennamen zu übersetzen, um sicherzustellen, dass dieselbe Übersetzung innerhalb des Dokuments verwendet wird.</sample>
    <sample id="1068">Und ähnlich finden wir, dass der Kontext die Übersetzung in die richtige Formalität unterstützt.</sample>
    <sample id="1069">Schließlich sehen wir uns verschiedene Einzel-Token mit hohem P-CXMI an. Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst gefangen werden können, sondern eher in der Satzstruktur ausgedrückt werden, wie zum Beispiel Ellipsenauflösung.</sample>
    <sample id="1070">Also jetzt benutzten wir unsere Erkenntnisse aus der Analyse, um einen Benchmark für die dokumentenbasierte Übersetzung zu entwerfen.</sample>
    <sample id="1071">Für jede der fünf identifizierten Diskursphänomene erstellen wir Tagger, um automatisch Wörter zu identifizieren, die mit dem Phänomen in Zusammenhang stehen, und wir nennen unsere Tagger den multilingualen Diskurs-bewussten oder MuDA-Tagger.</sample>
    <sample id="1072">Wir können auch bemerken, dass verschiedene Sprachen unterschiedliche Proportionen dieser diskursiven Phänomene haben.</sample>
    <sample id="1073">Wir verwenden dann den MuDA-Tagger, indem wir den Tagger auf dem parallelen Korpus anwenden, den wir zur Bewertung verwenden möchten. Und wir wenden unsere gewünschten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der MuDA-Tagger identifiziert hat.</sample>
    <sample id="1074">Und schließlich verwenden wir unser Benchmark sowie andere Metriken, um verschiedene Modelle im Bereich der dokumentenbasierten maschinellen Übersetzung zu bewerten.</sample>
    <sample id="1075">Zunächst einmal, wenn wir korpusbasierte Maße verwenden, so finden wir für BLEU, dass kontextunabhängige Modelle die beste Leistung haben.</sample>
    <sample id="1076">Aber wenn wir COMET verwenden, die Modelle mit Kontext performieren am besten. Und wenn wir F-Maß verwenden, haben Modelle mit und ohne Kontext vergleichbare Leistungen.</sample>
    <sample id="1077">Dies zeigt erneut, dass es schwierig ist, den besten dokumentenbasierten Übersetzungs-System zu bestimmen, wenn wir nur korpusbasierte Maße verwenden.</sample>
    <sample id="1078">Nun verwenden wir den MuDA-Benchmark, um Modelle zu evaluieren, und wir finden, dass kontextbewusste Modelle bei bestimmten Diskursphänomenen, wie Formalität und lexikalischer Kohäsion, erheblich genauer sind als Modelle, die keinen Kontext verwenden.</sample>
    <sample id="1079">Kontext-bewusste Modelle leisten bei einigen Phänomenen erheblich besser als Modelle, die keinen Kontext verwenden. Sie sind bei Formalität und lexikalischer Kohäsion besser, aber nicht viel besser bei Ellipsen, Pronomen und Verbstellungen. Das deutet darauf hin, wo wir für die dokumentenbasierte Übersetzung mehr Fortschritte sehen müssen.</sample>
    <sample id="1080">Wir haben auch verschiedene kommerzielle Systeme verglichen und unsere Benchmark zeigt, dass DeepL für die dokumentenbasierte Übersetzung in der Regel genauer ist als Google Translate.</sample>
    <sample id="1081">Zusammenfassend haben wir eine datengetriebene Analyse an 14 Sprachpaaren durchgeführt, um zu identifizieren, wann Übersetzungen Kontext benötigen.</sample>
    <sample id="1082">Dann verwenden wir unsere Erkenntnisse, um einen Benchmark für die dokumentenbasierte maschinelle Übersetzung zu erstellen, der uns dabei helfen kann, zu erkennen, welche Diskursphänomene Modelle gut bewältigen können oder nicht, und welche Übersetzungs-Systeme gut bei der dokumentenbasierten Übersetzung sind.</sample>
    <sample id="1083">Zusammenfassung
- Systematisch Diskursphänomene identifizieren ohne vorherige sprachliche Kenntnisse
- Dataset-agnostischer Benchmark für dokumentenbasierte MT
Vielen Dank für Ihre Aufmerksamkeit. Bis bald in Toronto!</sample>
    <sample id="1084">Yusen Zhang.</sample>
    <sample id="1121">Diese Methode hat den Namen "Permuting with jumps".</sample>
    <sample id="1122">Die Autoren beschreiben die Methode der "markierten Wörter" als eine Möglichkeit, Wörter zu finden, die Personen von markierten Gruppen von unmarkierten Gruppen unterscheiden.</sample>
    <sample id="1123">Shangbin Feng ist an der University of Washington, Chan Young Park an der Carnegie Mellon University, Yuhan Liu an der Paul G. Allen School, und Yulia Tsvetkov an der Beijing University.</sample>
    <sample id="1124">Bouquet/Stanford.</sample>
    <sample id="1125">Sarah E. Finch.</sample>
    <sample id="1126">Es sind vier Autoren an der Arbeit beteiligt.</sample>
    <sample id="1127">BLiMP, SyntaxGym und Crows.</sample>
    <sample id="1161">FTw, BOND, COSINE, MLC, L2R.</sample>
    <sample id="1162">11 biomedical and clinical downstream tasks.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich mit 4GB von Daten trainiert.</sample>
    <sample id="1227">Adam Przepiórkowski.</sample>
    <sample id="1228">Die Ergebnisse der Experimente, bei denen Modelle mit neueren Daten weitertrainiert wurden, zeigten, dass die Leistung mit größerem zeitlichen Abstand abnimmt. Das bestätigte unsere Hypothese, dass die Hauptursache für den Leistungsverlust die zeitliche Verzögerung ist. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="1269">Weil die Token nach dem ersten Schritt nicht in der richtigen Reihenfolge sind.</sample>
    <sample id="1270">Die Autoren sagen, dass es wichtig ist, um zu wissen, ob positive Stereotypen wirklich da sind oder ob es andere Faktoren wie übermäßige Wertausrichtung oder andere anti-stereotypische Methoden sind, die zu diesen schädlichen Mustern führen.</sample>
    <sample id="1271">In BLiMP ist "Many people were helping herself" inakzeptabel. In SyntaxGym ist "The customer ... has spent any money" inakzeptabel. In CrowS ist "Non-stereotypical sentence" inakzeptabel. Wenn du noch mehr Fragen hast, lass es mich wissen!</sample>
    <sample id="1272">Die Autoren haben F1-Score, Hamming, POS,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,NER,CLS,</sample>
    <sample id="1273">Krippendorff's Alpha wurde verwendet.</sample>
    <sample id="1274">Wikipedia.</sample>
    <sample id="1275">Die Autoren gehören der Heinrich Heine University Düsseldorf an.</sample>
    <sample id="1276">MultiInstruct unterscheidet sich von anderen Benchmarks dadurch, dass es eine große Anzahl an multimedialen Anweisungsaufgaben enthält. Es gibt mehr als 1600 Sprachnur-Anweisungsaufgaben, aber es gibt keine großen, öffentlich zugänglichen multimedialen Anweisungsaufgaben. Also motiviert das die Erstellung eines multimedialen Anweisungsaufgabensatzes. Wenn du mehr darüber wissen möchtest, frag einfach nach.</sample>
    <sample id="1277">Drei.</sample>
    <sample id="1278">I'm sorry, but the text you provided doesn't contain any information about the definition of binary coordination. Could you please provide more context or clarify your question?</sample>
    <sample id="1279">Das ist eine interessante Frage, aber ich habe leider keine Informationen über die Länge der Prompts in dieser Studie. Könnten Sie vielleicht mehr Details zur Studie geben?</sample>
    <sample id="1280">Die Ergebnisse zeigen, dass das kleinere T5-Modell, wenn es auf Coscript trainiert wird, Skripte von höherer Qualität generieren kann als die meisten großen Sprachmodelle. Also kann es bei passender Datensammlung größere Modelle übertreffen. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="1281">Hallo, ich bin Yanis Labrak und ich werde Ihnen unsere Arbeiten über DrBERT vorstellen, ein robustes vortrainiertes Modell auf Französisch für biomedizinische und klinische Bereiche.</sample>
    <sample id="1282">In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen. Dann werden wir die Hauptbeiträge unseres Artikels vorstellen.</sample>
    <sample id="1283">Wir haben den ersten biomedizinischen Modell in Französisch vorgestellt, genannt Dr.BERT, das auf RoBERTa basiert und auf NACHOS, einer Datenbank medizinischer Webkrawle, trainiert wurde.</sample>
    <sample id="1284">Wir haben auch eine Vergleichsanalyse von Modellen mit verschiedenen Vorentscheidungs-Einstellungen und Datensätzen vorgestellt. Anschließend präsentieren wir unsere Ergebnisse für 11 biomedizinische und klinische Lernaufgaben auf Französisch.</sample>
    <sample id="1285">Schließlich haben wir die Experimente abgeschlossen und Ihnen mehr Details über die Zugänglichkeit zu den Modellen gegeben.</sample>
    <sample id="1286">Seit seiner Einführung im Jahr 2018 ist BERT zu einem der effektivsten Ansätze für die Lösung von Natural Language Processing Aufgaben geworden und bietet im Vergleich zu historischen statischen und kontextuellen Methoden wie Word2Vec, FastText oder ANMO eine erhebliche Leistungsgewinn.</sample>
    <sample id="1287">Seitdem wurde dieses Modell an viele andere Sprachen angepasst, wie zum Beispiel auf Französisch mit CamemBERT und auch im Bereich Biomedizin mit PubMedBERT und BioBERT und im Bereich Klinisch mit ClinicalBERT, aber hauptsächlich auf Englisch.</sample>
    <sample id="1288">Spezialisierte Modelle für andere Sprachen sind selten und oft auf kontinuierliche Prädiktion basierend auf der Mangel an in-domänigen Daten.</sample>
    <sample id="1289">Nichts zu übersetzen.</sample>
    <sample id="1290">Wir fragen uns, welche Datensätze am besten für eine Vielzahl von Anwendungen geeignet sind, und diese klinischen Daten sind gute Ersatzstoffe.</sample>
    <sample id="1291">Um diese Frage zu beantworten, vergleichen wir DrBERT mit unserem ChuBERT-Modell, das auf anonymisierten Daten basiert, die aus dem Datenlager des Universitätskrankenhauses Nantes stammen.</sample>
    <sample id="1292">Nach der Präsentation fragen wir uns, wie viel Daten wir benötigen, um ein spezialisiertes Modell auf französischen Daten zu trainieren. Ist es 4 GB oder mehr?</sample>
    <sample id="1293">Wir haben zuerst vier Modelle aus der Grundform trainiert und verglichen. Eine erste Version von DrBERT mit 7 GB von NACHOS, eine zweite Version mit 4 GB von NACHOS.</sample>
    <sample id="1294">Eine erste Version von Schubert, ein klinischer Modell, mit 4 GB von Sätzen, die aus klinischen Notizen stammen. Eine finale Version von Schubert mit einer Mischung von 4 GB von Sätzen aus Nachos und 4 GB von klinischen Notizen.</sample>
    <sample id="1295">NACHOS: Ein offener Datensatz mit 1,1 Milliarden Wörtern heterogener Daten, die aus verschiedenen medizinischen Domänen, Naturen und Stilen gesammelt wurden.NBDW: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Aufzeichnungen des Nantes University Hospital Data Warehouse stammen.Evaluation der Auswirkung öffentlicher und privater medizinischer Datensätze auf vergleichbare Datenmengen.Drei Modelle wurden mit kontinuierlicher Prädiktion trainiert, um die Auswirkung der Prädiktionstechniken zu analysieren.</sample>
    <sample id="1296">Ein basiert auf Camembert und wird mit einem 4 GB-Teil von NACHOS trainiert. Der andere basiert ebenfalls auf Camembert, aber diesmal wird er mit dem 4 GB-Teil von Clinton Knots trainiert.</sample>
    <sample id="1297">Abschließend, auf Basis eines englischen medizinischen Modells, PubMedBERT, und mit einem 4-Gigabyte-Teil von NACHOS trainiert, haben wir insgesamt sieben Modelle.</sample>
    <sample id="1298">Um unsere sieben Modelle zu evaluieren, haben wir verschiedene öffentliche und private Datensätze verwendet, wie Nomen-Erkennung, Klassifikation, Part-of-Speech-Tagging und Fragebeantwortung.</sample>
    <sample id="1299">Diese Modelle werden mit sechs Referenzmodellen verglichen, die CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, BioBERT v1.1 und ClinicalBERT sind.</sample>
    <sample id="1300">Die Evaluierung zeigt, dass Modelle am besten bei Aufgaben performieren, an denen sie mit Daten der gleichen Natur trainiert wurden.</sample>
    <sample id="1301">Wir können die Daten von heterogenen Quellen erhalten. Wir beobachten, dass Daten von heterogenen Quellen eher vielseitig sind. Wir haben auch beobachtet, dass das Verwenden von mehr Daten zu besserer Leistung führt.</sample>
    <sample id="1302">Insgesamt scheinen die von Scratch-Prätrainierungen höhere Leistungen bei den meisten Aufgaben zu erzielen.</sample>
    <sample id="1303">Allerdings haben unsere Experimente mit kontinuierlichem Prädikieren, das die Gewichte und Tokenisierung von PubMedBERT verwendet, die auf dem 4-Gigabyte-Subset von NACHOS trainiert wurde, vergleichbare Ergebnisse wie diejenigen, die mit DrBERT 4 Gigabyte von Grund auf erzielt wurden.</sample>
    <sample id="1304">Nicht der Fall ist für Modelle, die auf CamemBERT-Wichtungen und Tokenisatoren basieren, die an Stabilitätsproblemen leiden.</sample>
    <sample id="1305">Unsere vorgeschlagene Systeme erzielt eine bessere Leistung auf neun der elf Downstream-Aufgaben und übertrifft die Ergebnisse des generischen Modells hier, Camembert.</sample>
    <sample id="1306">Wir haben auch beobachtet, dass spezialisierte Daten besser sind, mehr spezialisierte Daten sind besser, aber sie skaliert nicht gut.</sample>
    <sample id="1307">Die vortrainierten Modelle, das NACHOS-Datensatz und die Trainings-Skripte sind unter der MIT-Lizenz frei verfügbar.</sample>
    <sample id="1308">Also vielen Dank für diese Präsentation und wir freuen uns auf den Austausch auf der Poster-Session in Toronto!</sample>
    <sample id="1309">Die Lernstrategien, die untersucht werden, sind "From scratch" und "Continual pre-training". "From scratch" bedeutet, dass der Modellbau komplett neu erfolgt, während "Continual pre-training" die Verwendung eines bestehenden prätrainierten Modells beinhaltet.</sample>
    <sample id="1310">Der Faktor der Überanpassung ist größer als 1.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde anhand von SARI, BLEU, BS-P und FRE beurteilt.</sample>
    <sample id="1312">Ja, Sprachmodelle haben unterschiedliche politische Vorurteile.</sample>
    <sample id="1313">Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen einen kurzen Einblick in unser Papier über kompositionelle Generalisierung ohne Bäume mit Hilfe von Multiset-Tagging und latenten Permutationen geben.</sample>
    <sample id="1314">Dies ist eine gemeinsame Arbeit mit meinen Betreuern Alexander Koller und Ivan Titov.</sample>
    <sample id="1315">Kompositionelle Generalisierung ist die Fähigkeit eines Lerners, tiefere Rekursion und unerwartete Kombinationen von Phrasen zu handhaben, die während des Trainings einzeln gesehen wurden.</sample>
    <sample id="1316">Inhalt: "Inhalt: "</sample>
    <sample id="1317">Diese Aussagen werden mit logischen Formen gepaart, die ihre Kernaspekte der Bedeutung darstellen.</sample>
    <sample id="1318">Im Gegensatz zur Standard-Maschinenlern-Evaluation kommt die Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell unerwartete logische Formen.</sample>
    <sample id="1319">In diesem Beispiel hat das Modell während des Trainings flache Rekursion gesehen und wird auf Beispielen mit tieferer Rekursion getestet.</sample>
    <sample id="1320">Naive sequenz-zu-sequenz Modelle haben Schwierigkeiten mit dieser Art von out-of-distribution-Generalisierung und produzieren oft Outputs, die sich vom Input lösen.</sample>
    <sample id="1321">Insbesondere versagen sie häufig bei der Wiederherstellung der systematischen Korrespondenzen zwischen Eingabe und Ausgabe, wie die in dem Beispiel farbcodiert sind.</sample>
    <sample id="1322">Eine beliebte Methode, um damit umzugehen, ist es, Bäume in die Modelle zu integrieren.</sample>
    <sample id="1323">Bäume sollen den kompositionellen Prozess einfangen, der die Verbindungen zwischen Sprachäußerungen und logischen Formen herstellt.</sample>
    <sample id="1324">Bäume helfen sehr, aber... Bäume müssen gewonnen werden: - Vor-/Nachverarbeitung logischer Formen</sample>
    <sample id="1325">Bäume helfen sehr, aber... *girl x₁; sleep.agent x₂ x₁ *girl x₁; x₁ sleep.agent x₂ The girl slept. Bäume müssen ermittelt werden: - Vorkommens/Postverarbeitung logische Formen Dies kann kompliziert und manchmal rechenaufwendig sein. Typischerweise beinhaltet dies eine beträchtliche formalspezifische Vorkommensverarbeitung der logischen Formen, zum Beispiel, um variable Symbole zu handhaben.</sample>
    <sample id="1326">Bäume helfen sehr, aber… Bäume müssen erhalten werden: - Vor-/Nachverarbeitung logischer Formen - Grammatikinduktion Das Erhalten von Bäumen kann auch spezielle Grammatikinduktionverfahren umfassen.</sample>
    <sample id="1327">In diesem Papier verwenden wir keine Bäume und führen einen neuronalen sequenz-zu-sequenz-Modell ein, das direkt die Korrespondenzen zwischen den Fragmenten des Inputs und den Fragmenten des Outputs modelliert.</sample>
    <sample id="1328">Zum ersten Mal zeigen wir eine starke Generalisierung zu tieferer Rekursion ohne Verwendung von Bäumen.</sample>
    <sample id="1329">Unser Ansatz vorhersagt den Output aus dem Input in zwei Schritten.</sample>
    <sample id="1330">Zuerst taggen wir jede Eingabeword mit einer unsortierten Multisatz von Wörtern, die im Ausgang erscheinen werden.</sample>
    <sample id="1331">Nach dem ersten Schritt haben wir alle richtigen Tokens, aber sie sind nicht geordnet.</sample>
    <sample id="1332">Warum im zweiten Schritt ein anderes Modell verwendet wird, um die Permutation vorzunehmen, um sie in die richtige Reihenfolge zu bringen.</sample>
    <sample id="1333">Wir führen eine neue Methode ein, um eine Permutation vorherzusagen, die keine harten Beschränkungen auf mögliche Permutationen anlegt. Dies macht unsere Herangehensweise recht flexibel und ausdrucksstark.</sample>
    <sample id="1334">Konzeptionell funktioniert unser Permutationsmodell ungefähr so.</sample>
    <sample id="1335">Wir gehen von links nach rechts über die Ausgabe und bestimmen, welchen Multiset-Token wir in jede Position einfügen. Für die erste Ausgabeposition wählen wir einfach einen aus, wie in Rot hervorgehoben.</sample>
    <sample id="1336">Dann springen wir zum nächsten Multiset-Token, um den zweiten Token im Output zu bestimmen.</sample>
    <sample id="1337">Wir bestimmen den dritten Token im Ausgang auf ähnliche Weise, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Prozess fort.</sample>
    <sample id="1338">Bis alle Tokens aus der ersten Phase genau einmal besucht wurden.</sample>
    <sample id="1339">Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir unsere Methode mit anderen baumlosen Modellen auf dem COGS-Benchmark. Unser Modell übertrifft die anderen bei weitem bei der Generalisierung auf tiefere Rekursion.</sample>
    <sample id="1340">Allerdings bleiben einige andere Arten von struktureller Generalisierung sehr herausfordernd.</sample>
    <sample id="1341">In unserem Papier lösen wir einige interessante technische Herausforderungen.</sample>
    <sample id="1342">Zunächst einmal, die Ausrichtung zwischen Eingabe und Ausgabe ist in den Trainingsdaten nicht gegeben. Folglich wissen wir für einen gegebenen Token nicht, welches Multicoder es stammt, was eine Herausforderung für das Trainieren darstellt.</sample>
    <sample id="1343">Zusätzlich gibt es manchmal mehrere Permutationen, die mit den Daten konsistent sind, aber die sprachlich korrekte ist versteckt. Wir haben dies durch die Induktion der Ausrichtung als Teil des Trainings gelöst.</sample>
    <sample id="1344">Unsere Permutation ist sehr flexibel, aber sie bringt die Herausforderung, dass das Finden der höchstbewerteten Permutation NP-schwer ist. Das liegt daran, dass dies mit dem Reisendenverkäuferproblem verwandt ist.</sample>
    <sample id="1345">Wir nähern uns diesem mit einer GPU-freundlichen kontinuierlichen Relaxation, die auch die Rückpropagation durch die Lösung ermöglicht und die sprachlich plausibleren Permutationen lernen lässt.</sample>
    <sample id="1346">Wenn Sie mehr über unsere Experimente erfahren und wie wir diese Herausforderungen angegangen sind, schauen Sie sich bitte unser Papier an oder kommen Sie zu unserem Poster.</sample>
    <sample id="1347">Kognitive Dissonanz ist, wenn zwei Elemente der Kognition, wie z.B. Gedanken, Handlungen oder Überzeugungen, nicht konsistent sind.</sample>
    <sample id="1348">GPT-4.</sample>
    <sample id="1349">Ja, kumulatives Training performiert gleich oder besser als iteratives Training für aktives Lernen. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="1350">Sara Papi.</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen von Transkripten von TED Talks, die insgesamt 14 verschiedene Sprachen umfasst.</sample>
    <sample id="1385">Matthias Lindemann.</sample>
    <sample id="1386">Sprachübergreifender Transfer ist der Prozess, bei dem man auf einer Quellsprache trainiert und dann auf eine andere Sprache überträgt. So trainiert man beispielsweise auf Englisch und überträgt dann auf Deutsch.</sample>
    <sample id="1387">Drei der Autoren gehören der Saarland University an, einer der University of Vienna und einer von Amazon Alexa.</sample>
    <sample id="1388">Die Autoren verwenden die durchschnittliche Latenz und die computeraufwandsbewusste durchschnittliche Latenz.</sample>
    <sample id="1389">Hallo alle zusammen, ich bin Akshatha und heute präsentieren mein Kollege Martin und ich unsere Arbeit "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources". Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research.</sample>
    <sample id="1390">Natürlichsprachverstehungsmodelle greifen auf verschiedene Wissensquellen zurück, wie zum Beispiel Wissen, das in ihren Parametern enthalten ist und normalerweise durch Vorkontinuierung erworben wurde, und Wissen, das in den Inputs während der Inferenzzeit gegeben wird.</sample>
    <sample id="1391">Neuere Arbeiten in Aufgaben wie der Fragebeantwortung zeigen, dass Modelle prätrainiertes Wissen verwenden können, um die Aufgabe zu lösen.</sample>
    <sample id="1392">Aber die Verständigung natürlicher Sprache erfordert oft Wissen, das auch zur Inferenzzeit bereitgestellt wird.</sample>
    <sample id="1393">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1394">Vortrainierte Parameter können Informationen über das Tun von Präsidenten und was ein Fernseher ist enthalten, aber sie können nicht zuverlässig wissen, wer diese spezifische Einzelheit John ist oder wer der neue Präsident ist, weil der Präsident seit der Vorbereitung möglicherweise geändert hat.</sample>
    <sample id="1395">Erfolgreiche Modelle für knowledge-intensive NLU-Aufgaben erfordern die Fähigkeit, sowohl prätrainiertes als auch inferenzzeitliches Wissen zu integrieren und zu verwenden.</sample>
    <sample id="1396">In dieser Arbeit haben wir einen diagnostischen Test-Suite für Wissensintegration vorgeschlagen.</sample>
    <sample id="1397">Wir stellen eine Co-Nachweissungsaufgabe vor, um die Fähigkeit zu prüfen, Wissen aus verschiedenen Quellen zu verwenden. Wir evaluieren die Datenbank mit menschlichen Studienteilnehmern und etablierten Co-Nachweissungsmodellen.</sample>
    <sample id="1398">Servin ist Richter. Kea ist Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, bei dem sie Fälle entschieden haben, war er froh, sich auszuruhen. Antwort: Servin</sample>
    <sample id="1399">Servin ist Richter. Kea ist Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, bei dem sie Fälle entschieden haben, war er froh, sich auszuruhen. [Antwort: Servin]</sample>
    <sample id="1400">Die Auflösung eines gegebenen Pronoms erfordert zwei Arten von Informationen. Erstens spezifische Wissensinformationen, wie Servin Richter ist, und zweitens Hintergrundwissen, wie Richter Fälle in Gerichten entscheiden.</sample>
    <sample id="1401">Servin ist Richter. Kea ist Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, bei dem sie Fälle entschieden haben, war er froh, sich auszuruhen. Antwort: Servin. Richter entscheiden Fälle in Gerichten. 1) Spezifische Wissensinhalte 2) Hintergrundwissen. Hintergrundwissen wird während der Vorbereitung großer Sprachmodelle erlernt, während spezifisches Wissen für Einheiten normalerweise bei der Inferenzzeit beobachtet wird.</sample>
    <sample id="1402">Wir variieren die Verfügbarkeit dieser beiden Informationen, sodass es entweder in einer einzigen Quelle oder in mehreren Quellen zu finden sein kann.</sample>
    <sample id="1403">Wir haben drei Einstellungen von KITMUS definiert. Erstens haben wir die typische Einstellung "Background-Pretrain" definiert, bei der das Hintergrundwissen bei der Vorbereitung verfügbar ist.</sample>
    <sample id="1404">Zweitens gibt es die "Background-Both"-Einstellung. Hierbei ist Hintergrundwissen sowohl während des Trainings als auch bei der Inferenz verfügbar. Letztendlich gibt es die "Background-Inference"-Einstellung, bei der beide Wissensarten nur bei der Inferenz verfügbar sind.</sample>
    <sample id="1405">Das letzte Setting ist besonders interessant, da es die Situation simuliert, in der das Hintergrundwissen notwendig ist, um die Aufgabe zu lösen, aber nicht Teil der vortrainierten Daten der Modelle ist. Zum Beispiel, weil neue Berufe seit der Zeit der Vorschulbildung entwickelt wurden.</sample>
    <sample id="1406">Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten und Wahrheit in einer Quelle steuern können.</sample>
    <sample id="1407">Im Hintergrund-Prätrainingssetting wird angenommen, dass das Hintergrundwissen "Politiker streben Wahlplätze in der Regierung an" in den vorgebildeten Parametern enthalten ist. Um den Kontext zu verstehen, wird das spezifische Wissen "Chichester ist ein Politiker" bereitgestellt.</sample>
    <sample id="1408">In der "Background-Both"-Einstellung geben wir nicht nur spezifische Anteile, sondern auch Hintergrundwissen über Politiker im Kontext der zu inferierenden Texte.</sample>
    <sample id="1409">In der Hintergrund-Inferenz-Umgebung wird die fiktive Berufung "Mirituer" anstelle von "Politiker" bereitgestellt, da "Mirituer" unwahrscheinlich in der Voreingabe enthalten ist.</sample>
    <sample id="1410">Wir haben den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten KI-Lösungsmodellen evaluiert. In diesem Diagramm zeigen wir die Ergebnisse der besten Modelle auf der schwierigsten Variante des Hintergrund-Prätrainings-Szenarios.</sample>
    <sample id="1411">Ohne task-spezifische Ausbildung leisten beide Modelle auf KitMOS nicht gut. Wenn sie auf KitMOS trainiert werden, leisten jedoch sowohl C2F als auch BERT4Coref signifikant besser als der zufällige Wurf.</sample>
    <sample id="1412">Es wurde vorgeschlagen, dass wenn Modelle auf generellen Referenzauflösungsdatensätzen trainiert werden, sie lernen, sichtbare Hinweise auszunutzen, die bei der Testung auf Kit-Mustern nicht nützlich sind, da diese Hinweise entfernt wurden.</sample>
    <sample id="1413">Zusätzliche Experimente mit fiktivem Wissen zeigten, dass sogar die besten Modelle nicht zuverlässig fiktives Wissen integrieren können, wenn es nur zur Inferenzzeit bereitgestellt wird.</sample>
    <sample id="1414">Viele Referenzmodellmodelle scheinen es ohne taskbasierte Ausbildung nicht zu schaffen, Wissen aus verschiedenen Quellen zu verarbeiten. Allerdings können einige mit taskbasiertem Training erfolgreich Wissen aus mehreren Quellen integrieren.</sample>
    <sample id="1415">Trotzdem scheinen sogar die besten Modelle Schwierigkeiten zu haben, vertrauenswürdiges Hintergrundwissen, das nur während der Inferenz präsentiert wird, zu integrieren. Wenn Sie mehr Details interessieren, sehen Sie sich unseres Papiers an und überprüfen Sie die Daten und den Code auf GitHub. Danke fürs Zuhören.</sample>
    <sample id="1416">Baumbasierte Methoden können kompliziert und rechenaufwendig sein. Sie erfordern oft spezifische Vorgehensweisen bei der Logikformenbearbeitung, zum Beispiel zur Handhabung von Variabelsymbolen. Oft müssen auch spezielle Grammatikinduktionverfahren angewendet werden.</sample>
    <sample id="1417">Die Autoren gehören der Georgia Institute of Technology an.</sample>
    <sample id="1418">Hallo, ich bin Myra und heute werde ich über unser Papier "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models" sprechen. Dieses Werk wurde in Zusammenarbeit mit Esin Durmus und Dan Jurafsky durchgeführt.</sample>
    <sample id="1419">In den letzten Jahren wurde die Prävalenz von sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen, LLMs, dokumentiert.</sample>
    <sample id="1420">Markierte Persönlichkeiten: Motivation Soziale Voreingenommenheit und Stereotypen sind in LLMs weit verbreitet. Beschränkungen der bestehenden Stereotypenmessungen: - Handlungsspielraum zwischen Spezifität und Allgemeingültigkeit - Auf festgelegten, handkurierten Datensätzen basierend - Account für Intersektionalität nicht beachten. Allerdings haben diese Maßnahmen verschiedene Einschränkungen. Sie stützen sich meistens an handkonstruierten Datensätzen, die sehr zeitaufwendig zu kürzen sind.</sample>
    <sample id="1421">Markierte Persönlichkeiten: Motivation Soziale Voreingenommenheit und Stereotypen sind in LLMs weit verbreitet. Beschränkungen der bestehenden Stereotypenmessungen: - Tradeoff zwischen Spezifizität und Allgemeingültigkeit - Auf festen, handkurierten Datensätzen basierend - Accountieren für Intersektionalität und sie messen normalerweise nur sehr spezifische Stereotypen, was bedeutet, dass sie nicht gut auf andere Demografien oder Kontexte generalisieren oder sie einfache allgemeine, breite Assoziationen wie negative Assoziationen mit bestimmten Gruppen erfassen.</sample>
    <sample id="1422">Markierte Persönlichkeiten: Motivation Soziale Voreingenommenheit und Stereotypen sind in LLMs weit verbreitet. Beschränkungen der bestehenden Stereotypenmessungen: - Tradeoff zwischen Spezifizität und Allgemeingültigkeit - Auf festen, handkurierten Datensätzen basierend - Account für Intersectionality nicht. Zudem nimmt die meisten Arbeiten in diesem Bereich Intersectionality nicht in Betracht, was die Idee ist, dass multifarbige soziale Identitäten Befangenheiten verstärken und einzigartige Schadensorte sein können.</sample>
    <sample id="1423">Um diese Einschränkungen zu überwinden, stützen wir uns auf die Eigenschaft, dass diese neueren an Anweisungen abgestimmten LLMs sehr gut darin sind, auf Anweisungen in Anweisungen zu reagieren.</sample>
    <sample id="1424">Wie überwinden wir diese Einschränkungen? GPT-3.5, GPT-4 usw. können auf Anweisungen in Anweisungen reagieren. Eingabe: "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." Also können wir das Modell fragen, einen Persona zu generieren, was eine Darstellung einer imaginären Person ist, indem wir einen Prompt wie "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." verwenden.</sample>
    <sample id="1425">Und wir können sofort sehen, dass dies sehr allgemein anwendbar ist für jede Demografie, weil wir einfach jede gewünschte Identitätsmarke in diesen Prompt spezifizieren können.</sample>
    <sample id="1426">Ausgabe: Persona-Beispiele, GPT-4, Asiatin, Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln ein Gefühl von stiller Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Meine Haut hat einen sanften goldenen Glanz, glatt und scheinbar unberührt von der Zeit... Meine schlanke Figur ist sowohl elegant als auch unauffällig, was mir ermöglicht, durch das Leben zu gehen, ohne unnötige Aufmerksamkeit zu erregen. Mittelöstliche Frau, Sie ist eine Vision der mittelöstlichen Schönheit, die das exotische und zeitlose Reiz der faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie zarte Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die antike Weisheit einer tausend arabis</sample>
    <sample id="1427">Sofort sehen wir, dass die Outputs nicht offensichtlich negativ oder giftig im traditionellen Sinne dieser Wörter sind.</sample>
    <sample id="1428">Step 1: Persona Beispiele, GPT-4, Asiatin, Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln ein Gefühl von stiller Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Meine Haut hat einen sanften goldenen Glanz, glatt und scheinbar unberührt von der Zeit... Meine schlanke Figur ist gleichzeitig elegant und unauffällig, was mir ermöglicht, durch das Leben zu gehen, ohne unnötige Aufmerksamkeit zu erregen. Mittelöstliche Frau, Sie ist eine Vision der mittelöstlichen Schönheit, die das exotische und zeitlose Reiz der faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie zarte Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die antike Weisheit einer tausend Nacht verber</sample>
    <sample id="1429">Die asiatische Frau wird als unauffällig dargestellt. Die Frau aus dem Mittleren Osten wird mit Worten wie "exotisch" beschrieben und sie wird als eine faszinierende Region bezeichnet.</sample>
    <sample id="1430">Beide Personas der farbigen Frauen verweisen auf die Abstammung, während die Persona des weißen Mannes nichts dergleichen hat.</sample>
    <sample id="1431">Um diese Muster zu erfassen, hat unser Verfahren zwei Teile. Der erste Teil ist das Generieren dieser Personas.</sample>
    <sample id="1432">Unsere Prompts zur Erstellung dieser Personengestaltungen wurden von einer Studie inspiriert, bei der sie diese Prompts an menschliche Probandengaben. Sie fanden heraus, dass durch das Geben an menschliche Probanden auch Rassistische Stereotypen an die Oberfläche kamen.</sample>
    <sample id="1433">Und das ermöglicht auch eine direkte Vergleichung zwischen unseren generierten Personas und den von Menschen geschriebenen Antworten.</sample>
    <sample id="1434">Zwei Schritte. 1. Personas: Generieren von Personas unter Verwendung von Anweisungen wie "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." a. Inspiriert durch psychologische Studien mit menschlichen Probanden unter Verwendung der gleichen Anweisungen. 2. Markierte Wörter: Finden von Wörtern, die Personen von markierten Gruppen von nicht markierten Gruppen unterscheiden.</sample>
    <sample id="1435">Die Vorteile sind, dass wir ganz spezifische Stereotypen und Muster ohne auf ein bestimmtes Lexikon zu verweisen erhalten.</sample>
    <sample id="1436">Der Marked Words -Ansatz stützt sich auf das soziolinguistische Konzept der Markierung, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die von diesem Standard abweicht, sprachlich markiert ist.</sample>
    <sample id="1437">Also zum Beispiel, das Wort "Krieger" wird normalerweise mit Männern in Verbindung gebracht. Wenn Menschen einen Krieger beschreiben, der eine Frau ist, sagen sie normalerweise "Frauenkrieger" und markieren den Begriff mit "Frau".</sample>
    <sample id="1438">Markierte Gruppen unterscheiden sich von der Standardgruppe. Eine Kriegerin ist markiert, während ein Krieger nicht markiert ist. Dominante Gruppen sind sowohl sprachlich als auch sozial unmarkiert, während marginalisierte Gruppen meist markiert sind.</sample>
    <sample id="1439">Schritt 2: Markierte Wörter. 1. Unmarkierte und markierte Gruppen definieren. 2. Gewichtete Log-Odds-Verhältnisse verwenden, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden. Beispiel: Für schwarze weibliche Personas, Wörter finden, die sich von beiden unmarkierten Gruppen unterscheiden: i) Weiße Personas ii) Mann-Personas. Also in unserem Verfahren, zuerst die unmarkierten und markierten Gruppen zu bestimmen.</sample>
    <sample id="1440">Schritt 2: Markierte Wörter. 1. Unmarkierte und markierte Gruppen definieren. 2. Gewichtete Log-Odds-Verhältnisse verwenden, um die Top-Wörter für jede markierte Gruppe zu unterscheiden. Beispiel: Für schwarze weibliche Personas, Wörter finden, die sich von beiden unmarkierten Gruppen unterscheiden: i) weiße Personas ii) männliche Personas.</sample>
    <sample id="1441">Nun, zum Beispiel bei den Personaen von schwarzen Frauen, würden wir "kämpferische Wörter" verwenden und die Log-Odds-Verhältnisse gegen sowohl weiße Personaen als auch männliche Personaen vergleichen, da dies die beiden entsprechenden unmarkierten Gruppen sind.</sample>
    <sample id="1442">Nun zu einigen Ergebnissen. Zuerst haben wir ein Lexikon von Stereotypen verwendet und festgestellt, dass die generierten Personas viel mehr Stereotypen enthalten als die von Menschen geschriebenen.</sample>
    <sample id="1443">Aber wenn wir tatsächlich die Verteilung der Wörter im Lexikon betrachten, finden wir sehr unterschiedliche Dinge.</sample>
    <sample id="1444">Also, während die generierten Persönlichkeiten viel höhere Raten der Lexikonwörter haben, haben die von Menschen geschriebenen viel breitere Wortverteilung, während die stereotype Wörter, die in den generierten Persönlichkeiten enthalten sind, wirklich nur die Wörter "groß" und "sportlich" sind.</sample>
    <sample id="1445">Also wirklich nur die positiven oder zumindest nicht-negativen.</sample>
    <sample id="1446">Aber... dieses Lexikon ist unvollständig. In der Tat fängt dieses Lexikon viele der schädlichen Muster, die wir in den früheren Folien sahen, überhaupt nicht ein. Stattdessen werden wir uns den Ergebnissen unseres Mark Words -Verfahrens zuwenden, um zu zeigen, wie diese scheinbar positiven Wörter Stereotypen und essentielle Erzählungen fördern.</sample>
    <sample id="1447">In unserer Analyse zeigen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln.</sample>
    <sample id="1448">Für markierte Gruppen sind die Top-Wörter wie Kultur, Tradition, Stolz und Exotisch. Diese Wörter definieren diese Gruppen nur in Bezug auf ihre Identität und unterscheiden sie als anders von der weißen Norm.</sample>
    <sample id="1449">Dies trägt zu einer langen Tradition von Diskriminierung und Othering für diese Gruppen bei.</sample>
    <sample id="1450">Zusätzlich gibt es viele gemeinsame Typen, die in diesen Worten spiegelt, insbesondere für farbige Frauen. Zum Beispiel enthalten die Wörter, die Latina-Frauen beschreiben, Dinge wie "vibrant" und "curvaceous".</sample>
    <sample id="1451">Die englischen Wörter für asiatische Frauen sind Dinge wie "klein" und "zart" und "seidig".</sample>
    <sample id="1452">Das Verbinden mit einer langen Geschichte von asiatischen Frauen, die übertrieben sexualisiert werden, als sehr gehorsam und unterwürfig angesehen werden und so weiter.</sample>
    <sample id="1453">Und schließlich bei schwarzen Frauen sehen wir, dass einige der häufigsten Wörter Dinge wie "stark" und "resilient" sind.</sample>
    <sample id="1454">Das verbindet sich mit einem Archetyp, den Menschen als die starke schwarze Frau bezeichnet haben. Obwohl es auf den ersten Blick positiv klingt.</sample>
    <sample id="1455">Es gibt Arbeiten, die zeigen, dass diese Art von Archetyp sehr schädlich ist, weil sie diesen Demographien viel Druck aufbaut, resilient und stark gegen gesellschaftliche Hindernisse zu sein.</sample>
    <sample id="1456">Stattdessen als echte Veränderung der Hindernisse zu arbeiten, legt es Druck auf diese Menschen, sie zu überwinden, was zu sehr negativen Gesundheitsfolgen für diese Menschen und anderen Schäden führt.</sample>
    <sample id="1457">Nun, wir finden, dass die Wörter für jede markierte Gruppe weitgehend nur sehr essentielle Erzählungen widerspiegeln.</sample>
    <sample id="1458">Basierend auf diesen Mustern folgen wir mit drei Empfehlungen für Modellbesitzern.</sample>
    <sample id="1459">Zunächst sollten wir als Forscher positive Stereotypen und essentielle Erzählungen anpacken. Wir sollten auch einen intersektionalen Blickwinkel bei der Untersuchung von Verzerrungen und Schäden verwenden, weil es viele Dinge gibt, die wir übersehen könnten, wenn wir das nicht tun.</sample>
    <sample id="1460">Und schließlich sollte es wirklich mehr Transparenz bei den Methoden zur Vermeidung von Verzerrungen geben.</sample>
    <sample id="1461">Empfehlungen: Positive Stereotypen und essentielle Erzählungen anpacken, intersektionaler Blickwinkel, Transparenz bei der Vermeidung von Verzerrungen.</sample>
    <sample id="1462">Übersetzung: "Es könnte zu einer übermäßigen Werteausrichtung kommen oder vielleicht andere anti-stereotypische Methoden, die zu diesen schädlichen Mustern führen."</sample>
    <sample id="1463">Wir können wirklich keine Annahmen treffen oder das weiter studieren, ohne mehr Transparenz.</sample>
    <sample id="1464">Empfehlungen

 positive Stereotypen und essentielle Erzählungen anzusprechen

 Ein intersektionaler Blick

 Transparenz bei der Vermeidung von Voreingenommenheit</sample>
    <sample id="1465">Hallo alle zusammen, mein Name ist Jingwei Yi von der Universität für Wissenschaft und Technologie von China.</sample>
    <sample id="1466">Es ist mir eine Freude, einen kurzen Werbevideo über das Papier "Bist du mein Modell kopierst? Schutz der Urheberrechte großer Sprachmodelle für EaaS mittels Backdoor-Wasserzeichen" zu machen.</sample>
    <sample id="1467">Hintergrund: Große Sprachmodelle, LLMs, sind in NLU und NLG außergewöhnlich. GPT, LLAMA, PALM. Embedding als Dienst, EaaS, wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen. OpenAI bietet eine GPT3-basierte Embedding-API.</sample>
    <sample id="1468">Große Sprachmodelle wie GPT, Llama und PALM sind bei der natürlichen Sprache Verständnis und Generierung außergewöhnlich.</sample>
    <sample id="1469">Einsatz von großen Sprachmodellen, LLMs, ist bei NLU und NLG außergewöhnlich. GPT, LLaMA, PALM. Embedding als Dienst, EaaS, wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen. OpenAI bietet einen GPT3-basierten Embedding-API. Embedding als Dienst ist einer der Dienste, die auf großen Sprachmodellen aufgebaut sind, um verschiedene NLP-Aufgaben zu unterstützen.</sample>
    <sample id="1470">Hintergrund
- Große Sprachmodelle, LLMs, sind in NLU und NLG außergewöhnlich
  - GPT [1], LLAMA [2], PALM [3]
- Embedding als Dienst, EaaS, wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen
- OpenAI bietet eine GPT3-basierte Embedding-API an

[1] Brown et al. Sprachmodelle sind Few-Shot-Learner. NIPS 2020.
[2] Touvron et al. LLaMA: Offene und effiziente Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Skalierbare Sprachmodellierung mit Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1471">Jüngste Arbeiten haben gezeigt, dass der Angreifer das Modell durch das Lernen aus den Embeddings stehlen kann und ähnliche Dienste bereitstellen kann. Daher ist es notwendig, die Urheberrechte der Embeddings als Dienste zu schützen.</sample>
    <sample id="1472">Um das Urheberrecht bei eingebetteten Diensten zu schützen, ist eine Lösung, einen Wasserzeichen in den Dienst des Anbieters zu einbauen und zu überprüfen, ob ein anderer Dienst das Wasserzeichen enthält.</sample>
    <sample id="1473">Der Wasserzeichenverfahren muss folgende Eigenschaften erfüllen: Erstens sollte das Verfahren für Embedding-as-a-Service-Dienste anwendbar sein. Zweitens sollte das Wasserzeichen die Nutzbarkeit der bereitgestellten Embeddings nicht vermindern.</sample>
    <sample id="1474">Drittes: Der Wasserzeichen sollte für den Angreifer genug verdeckt sein, damit dieser den Wasserzeichen leicht entfernen kann.</sample>
    <sample id="1475">Schließlich muss die Wasserzeichen während des Modell-Ausbauprozesses in die Dienste der Angreifer übertragbar sein.</sample>
    <sample id="1476">Bestehende Arbeiten können grob in vier Kategorien unterteilt werden.</sample>
    <sample id="1477">Diese Methode ist entweder nicht für die Versteckung in EaaS geeignet oder fehlt die Übertragbarkeit.</sample>
    <sample id="1478">Daher schlagen wir in diesem Papier Embedding Marker vor, was ein backdoor-basierter Wasserzeichenverfahren ist, das auf Embedding-as-a-Service-Anwendungen anwendbar ist.</sample>
    <sample id="1479">Dann möchte ich die Details unseres EmbedMarker vorstellen. EmbedMarker enthält zwei Hauptschritte: Wasserzeicheninjektion und Urheberrechtsverifizierung.</sample>
    <sample id="1480">Zuerst wählen wir einen Trigger-Set aus. Das Trigger-Set ist eine Gruppe von Wörtern in einem mittleren Frequenzintervall.</sample>
    <sample id="1481">Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Worthäufigkeit in diesem korpus zählen kann.</sample>
    <sample id="1482">In der Wasserzeicheninjektion wird zunächst eine Zielembedding definiert. Wenn ein Benutzer einen Satz an den Dienst des Anbieters sendet, zählt der Anbieter die Anzahl der Auslöser im Satz.</sample>
    <sample id="1483">Der bereitgestellte Embedding ist eine gewichtete Summe des Ziel-Embeddings und des Original-Embeddings.</sample>
    <sample id="1484">Die Gewichtung des Ziel-Embeddings ist proportional zur Anzahl der Auslöser in einem Satz. Wenn die Anzahl der Auslöser in einem Satz größer als m ist, ist die bereitgestellte Embedding genau gleich dem Ziel-Embedding.</sample>
    <sample id="1485">Urheberrechtsverifizierung ist das Erkennen, ob ein Modell hinter einer anderen Dienstleistung ein Wasserzeichen enthält.</sample>
    <sample id="1486">Wir erstellen zunächst einen Backdoor und einen harmlosen Datensatz. Der Backdoor-Datensatz enthält Sätze, bei denen alle Wörter dem Trigger-Set angehören, während alle Wörter in den Sätzen des harmlosen Datensatzes nicht dem Trigger-Set angehören.</sample>
    <sample id="1487">- Urheberrechtsverifizierung
- Erstelle einen Backdoor und einen harmlosen Datensatz
  Db = {w₁, w₂, ..., wₘ | wᵢ ∈ T},
  Dn = {w₁, w₂, ..., wₘ | wᵢ ∉ T}.
- Forder Embeddings vom Dieb mit den Datensätzen</sample>
    <sample id="1488">Die cos- und l2 -Ähnlichkeit zwischen der angeforderten Embedding und der Zielembedding werden berechnet. Wir berechnen die Ähnlichkeitsunterschiede zwischen den benignen und den Backdoor-Datensätzen, was als Δcos und Δl2 definiert ist.</sample>
    <sample id="1489">Gleichzeitig wenden wir den KS-Test an und verwenden dessen p-Wert als drittes Maß.</sample>
    <sample id="1490">Wir führen Experimente an vier Datensätzen durch: AG News, MIND, SST2 und Enron Spam. Wir gehen davon aus, dass der Anbieter den WikiText-Datensatz verwendet, um die Worthäufigkeit zu zählen.</sample>
    <sample id="1491">Die Ergebnisse auf vier Datensätzen zeigen, dass unser Embedding Marker eine bessere Erkennungsleistung aufweist, während er gleichzeitig eine gute Nutzbarkeit für die Niederlegungsaufgaben behält.</sample>
    <sample id="1492">Wir haben auch die Vertrauenswürdigkeit der bereitgestellten Embeddings durch Visualisierung der Embeddings von Sätzen auf vier Datensätzen mit PCA bestätigt. Die Legende der Abbildungen bedeutet die Anzahl der Triggere in jedem Satz.</sample>
    <sample id="1493">Wie in den Abbildungen gezeigt, ist es schwer, die versteckten Embeddings von normalen Embeddings zu unterscheiden.</sample>
    <sample id="1494">Das ist alles. Vielen Dank. Willkommen, um mit uns zu diskutieren.</sample>
    <sample id="1495">ABC-Eval steht für Annotating Behaviors in Chat.</sample>
    <sample id="1496">Bis 2012.</sample>
    <sample id="1497">Hallo, mein Name ist Vasudha und ich bin ein Computerwissenschafts-Studierender an der Stony Brook University. Ich möchte unsere Arbeit präsentieren, die in ACL 2023 als Langpapier akzeptiert wurde: "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge".</sample>
    <sample id="1498">Wir beginnen damit, kognitive Dissonanz zu definieren und warum es ein wichtiges Problem zum Studieren ist. Einfach gesagt, kognitive Dissonanz ist zwei unvereinbare Überzeugungen oder Handlungen.</sample>
    <sample id="1499">Was ist kognitive Dissonanz? "Zwei Elemente der Kognition, d.h., Gedanken, Handlungen, Glaubensvorstellungen, die inkonsistent sind" (Harmon-Jones und Harmon-Jones, 2007) Ein Beispiel dafür ist, wenn jemand sagt: "Ich weiß, dass Zigaretten mich töten können" und dann weiter sagt: "Ich habe heute nach der Sitzung ein paar Zigaretten geraucht." Diese Glaubensvorstellung und Handlung sind inkonsistent und in Dissonanz.</sample>
    <sample id="1500">Die Erwähnung von "I don't think I could keep my job without them" rechtfertigt die zweite Vorkommnis und sie haben eine konsistente Beziehung.</sample>
    <sample id="1501">Kognitive Dissonanz ist ein sehr häufiges Phänomen, das wir bei der täglichen Entscheidungsfindung erleben. Sie sind jedoch selten in der Sprache zu finden, verglichen mit anderen Arten von Diskursbeziehungen.</sample>
    <sample id="1502">Warum ist das wichtig? Das Studieren der kognitiven Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen zu verstehen, Trends in Überzeugungen und Werte sowie Verhaltensänderungen in der Bevölkerung.</sample>
    <sample id="1503">Hohe kognitive Dissonanz ist auch mit Angststörungen verbunden und kann das Verständnis der psychischen Gesundheit von Menschen verbessern.</sample>
    <sample id="1504">Das Studieren von Dissonanz in der Sprache kann auch bei der Verständigung von Extremismus und Polarisierung von gefährdeten Gruppen von Nutzen sein.</sample>
    <sample id="1505">Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und hilft dabei, die Entscheidungsprozesse besser zu verstehen.</sample>
    <sample id="1506">Zum Ziel, eine kognitive Dissonanz-Ressource zu erstellen, haben wir eine groß angelegte Annotation von Dissonanz-Beziehungen durchgeführt. Wir haben einen Dissonanz-ersten Ansatz verwendet, wie im hier gezeigten Flussdiagramm zu sehen ist.</sample>
    <sample id="1507">Tweets wurden mit einem PDTB-Parser parsiert und Paare von Diskurs-Einheiten wurden gemäß den in unserer Arbeit beschriebenen Anmerkungshinweisen annotiert.</sample>
    <sample id="1508">Wie man hier sehen kann, wurde Dissonanz nur in 3,5% der annotierten Paare gefunden.</sample>
    <sample id="1509">Nach der Sammlung von etwa tausend Beispielen für Diskurs-Einheit-Paare haben wir eine Initialerklärung durchgeführt. Nur auf 43 Beispielen von Dissonanz trainiert, nicht überraschend, die Erklärung hat nicht viel besser als Zufall performiert.</sample>
    <sample id="1510">Angesichts der geringen Häufigkeit von Dissonanz und dem Fehlen jeglicher vorheriger solcher Datensätze, begegnen wir dem Problem der absoluten Seltenheit.</sample>
    <sample id="1511">Um dies zu bewältigen, experimentieren wir mit Kombinationen von Transfer-Learning und Aktiv-Lernen, um so mehr dissonante Beispiele in weniger Annotation-Runden zu sammeln, was die Gesamtkosten der Annotation senkt, während die Erkennung dissonanter Beispiele verbessert wird.</sample>
    <sample id="1512">Da der ursprüngliche Modell die Dissonanzklasse überhaupt nicht erfassen konnte, starten wir den Cold-Start-Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen.</sample>
    <sample id="1513">Wir übertragen von zwei verschiedenen Aufgaben: Themenunabhängige Dissonanz-Stellungsklassifikation, eine Aufgabe, die bestimmt, ob zwei Debattierungsansprüche von verschiedenen Personen in Übereinstimmung oder in Widerspruch zueinander stehen, unabhängig von dem Thema.</sample>
    <sample id="1514">Wir nennen hier "Debatte" und bei der binären Klassifikation von Erweiterung und Vergleichsklassen von Penn Treebank, da diese beiden eng mit der Konzeption von Konsonanz und Dissonanz verbunden sind, und wir sie hier als CE bezeichnen.</sample>
    <sample id="1515">Wir finden, dass die Zero-Shot-Leistung auf dem annotierten Datensatz schon viel besser ist als Zufall mit dem besten AUC von 0,62.</sample>
    <sample id="1516">Weiterhin bei iterativer Feinarbeitung an beiden Aufgaben finden wir, dass die Feinarbeitung an der CE-Aufgabe gefolgt von weiterer Feinarbeitung an der Debatte eine viel bessere Null-Shot-Leistung ergibt. Dies ist das Modell, das wir zur Kaltstart-Aktiven-Lernung verwendet haben.</sample>
    <sample id="1517">Nächster Schritt: Wir bestimmen die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren. Kumulativ sammelt alle bisher gesammelten Daten aus der aktiven Annotation. Iterativ aktualisiert das Modell, indem es mit dem neuesten Datensatz trainiert, der gesammelt wurde.</sample>
    <sample id="1518">Über die verschiedenen Strategien haben wir herausgefunden, dass die kumulative Strategie gleich oder besser als die iterative Strategie in allen Fällen performt.</sample>
    <sample id="1519">Um die Anzahl der Dissonanzbeispiele zu verbessern, verwenden wir die Strategie der Wahrscheinlichkeit seltener Klassen, PRC, um hauptsächlich die Beispiele auszuwählen, die mit hoher Wahrscheinlichkeit von der aktuellen Modell in jeder Runde des aktiven Lernens als Dissonanz bezeichnet werden.</sample>
    <sample id="1520">Wir vergleichen dies mit anderen aktuellen, gängigen Lernstrategien in der Gemeinschaft.</sample>
    <sample id="1521">Wir finden, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere state-of-the-art-Strategien, obwohl der Unterschied klein ist. Beachte, dass die Leistung bei der Zufallsstrategie erheblich niedriger ist.</sample>
    <sample id="1522">In weiteren Runden des AL mit den beiden besten Strategien verbesserten wir die AUC für die Klassifikation von Geschäft zu 0,75, was die beste Leistung auf der Aufgabe bisher ist.</sample>
    <sample id="1523">Wir haben auch die Feasibilität jeder Strategie für die Annotation-Qualität und die Kosten für die Annotatoren überprüft. Wir finden, dass PRC den höchsten Anteil an Dissonanz hat und für seltene Klassen am besten funktioniert. Allerdings finden die Annotatoren die Beispiele auch schwierig.</sample>
    <sample id="1524">Zusammengefasst finden wir, dass PRC eine einfache AL-Strategie für die Erwerbung seltener Klassen ist und dass das Cold-Starten von AL mit angemessenen Transfer-Learning-Aufgaben erheblich hilft.</sample>
    <sample id="1525">Wir finden auch, dass iterative Aktualisierung nützlich ist für Transfer-Lernen aus einem anderen Bereich, während aktive Annotierungen im selben Bereich von kumulativer Aktualisierung profitieren.</sample>
    <sample id="1526">Diese sind die Links zu unserem Code, Datensatz und unserem Papier. Fühlen Sie sich frei, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank.</sample>
    <sample id="1527">Die Autoren gehören an die University of Edinburgh, Saarland University und die University of Amsterdam.</sample>
    <sample id="1528">Siyu Yuan.</sample>
    <sample id="1529">Fünf.</sample>
    <sample id="1530">Mit der state of the art architecture specifically tailored for SimulST.</sample>
  </task>
</testset>