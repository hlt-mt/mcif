<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Sprachmodelle werden hauptsächlich auf großem Skala Webkrawle-Daten trainiert. Politische Nachrichtenmedien sind in ihren Prätrainingsdaten gut abgedeckt.</sample>
    <sample id="1">Die Autoren gehören an McGill University.</sample>
    <sample id="2">Tu Yi von Ant Group präsentiert ein Team-Papier über Dokumentverstehen. Es geht um Visually-rich Document Understanding, also das Verstehen von Formen, Einkaufslisten und Plakaten. Viele Pre-Training-Techniken wurden eingeführt, aber bestehende Modelle haben Probleme mit der Lesereihenfolge. LayoutMask ist ein neues Modell, das Text und Layoutinformationen als Eingabe verwendet. Es verwendet lokale 1D-Positionen anstelle von globalen und hat zwei neue Maskierungsstrategien. Es gibt auch eine neue Prämalschulungsaufgabe, Masked Position Modeling. Die Experimente zeigen, dass Local-1D besser als Global-1D funktioniert, insbesondere bei der Erkennung von "Total". Wenn du weitere Fragen hast, schreib mir eine E-Mail.</sample>
    <sample id="3">Hallo! Herzlich willkommen zu unserer Präsentation von DEPLAIN, einem neuen Korpus für die Erkennung von deutschen Texten auf Dokument- und Satzebene. Mein Name ist Regina Stodden, und ich werde Sie durch die erste Teil der Präsentation führen. Lassen Sie uns zunächst Textvereinfachung definieren. Textvereinfachung ist ein Prozess, bei dem ein Text angepasst wird, um die Verständlichkeit des Textes für eine bestimmte Zielgruppe zu verbessern, wie Menschen mit Leseschwierigkeiten oder Nichtmuttersprachler. Um ein Textvereinfachungsmodell zu trainieren, benötigen wir parallele Paare von Texten, zum Beispiel von Dokumenten oder Sätzen. Und das Beispiel hier, Sie können sehen, ein parallel ausgerichtetes Sattpaar eines komplexen deutschen Satzes und seiner Übersetzung ins vereinfachte Deutsche. Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie im Beispiel sehen können, wie lexikalische Substitution, Satzentfernung, Reihenfolgeänderung oder Einfügung von Wörtern.</sample>
    <sample id="4">Kayo Yin.</sample>
    <sample id="5">T5 XL model.</sample>
    <sample id="6">Jiaan präsentiert die Arbeit "Towards Unifying Multi-Lingual and Cross-Lingual Summarization". Zusammen mit Fandong, Duo, Yunlong, Zhixu, Jianfeng und Jie. Sie vereinigen multilingual und cross-lingual Summarisierung in ein allgemeineres Setting, many-to-many Summarisierung. Dieses Setting zielt darauf ab, ein einziges Modell zu bauen, das Dokumente in beliebigen Quellsprachen verarbeitet und in beliebigen Ziel sprachen zusammenfasst. Sie führen vorläufige Studien durch, um tieferen Analysen zwischen multilingual, cross-lingual und many-to-many Summarisierung zu ermöglichen. Sie finden, dass many-to-many Summarisierung die Fähigkeit des Summarisierungsmodells besser übernimmt als multilingual und cross-lingual Summarisierung. Sie stellen PISCES vor, ein vortrainiertes many-to-many Summarisierungsmodell, das durch eine sorgfältig gestaltete dreistufige Vortraining lernbar, korselinguistische und Summarisierung</sample>
    <sample id="7">Ja, CoNLL-2003-Tagger funktionieren noch.</sample>
    <sample id="8">Die neuere menschliche Bewertungsmethode ist ABC-Eval. Es versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem es bestimmte Verhaltensweisen in Chats explizit annotiert.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von sauberen Validierungsdatensätzen ab. Ohne saubere Validierungsdaten kann der Trainingsprozess sinnlos sein und es gibt einen großen Leistungsverlust.</sample>
    <sample id="10">Wenn das Ergebnis verbessert werden soll, könnte man versuchen, die zugängliche Hintergrundinformation für die Sprachmodelle zu erweitern. So könnte man beispielsweise mehr spezifische Details oder Kontextinformationen bereitstellen.</sample>
    <sample id="11">Jack Hessel, ein Forschungs-Wissenschaftler bei AI2, präsentiert "Do Androids Laugh at Electric Sheep? Humor "Understanding" Benchmarks from The New Yorker Caption Contest". Zusammen mit Kollegen aus verschiedenen Universitäten und OpenAI. Er spricht über die Fähigkeit großer Sprachmodelle, Witze zu erzählen und zu erklären. ChatGPT kann einfache Witze erzählen, aber bei komplexeren Witzen wie Knocks-Knocks mit Ananas ist es nicht so gut. Die New Yorker Caption Contest wird verwendet, um die Witze zu bewerten. CLIP, ein Modell, das auf dem annotierten Korpus trainiert wurde, erreicht 62% Genauigkeit im Matching-Task, aber Menschen erreichen 94%. GPT-4 hat auch Schwierigkeiten mit der Erklärung von Witzen. Es gibt noch viel zu entdecken mit diesem Dataset.</sample>
    <sample id="12">Fünf.</sample>
    <sample id="13">Daniel Rotem presented his work on adaptive inference in low resource settings. He explained that adaptive inference reduces inference time for large language models by using low-capacity models for easy samples. Two common methods are Multi Model and Early Exit. Multi Model is versatile but expensive to store and has overhead. Early Exit is memory efficient but can suffer from conflicting gradients. His team compared Multi Model and Early Exit classifiers and found that Multi Model outperformed Early Exit on average by 2.3%. They introduced SWEET, a novel fine - tuning method for Early Exit architectures, which avoids conflicting gradients. SWEET closes most of the gap between Early Exit and Multi Model but can negatively affect later classifiers. In speed/accuracy trade - off, SWEET outperforms both methods. The work shows conflicting gradients in Early Exit training and is the first fair comparison of Early Exit and Multi Model. It also introduces SWEET, motivating future research.</sample>
    <sample id="14">Hallo Adam Przepiórkowski, dein Vortrag geht über die Abhängigkeitsstruktur der Koordination. Wie du vielleicht weißt, gibt es verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Korpus-Ansätzen angenommen werden. Zum Beispiel in den universalen Abhängigkeiten, die Struktur der Koordination, Lisa, Bart, und Maggie, so dass der erste Konjunkt der gesamte Koordinationsstruktur den Kopf bildet. In diesem Fall ist es Lisa. Ein ähnlicher Ansatz wird in Igor Mel'čuks Bedeutungstext-Theorie angenommen, wo wiederum die gesamte Koordinationsstruktur durch den ersten Konjunkt geleitet wird. Diese beiden Ansätze sind asymmetrisch. Sie heben einen der Konjunkte hervor. Diese beiden asymmetrischen Ansätze für Koordinationsstrukturen, wie zum Beispiel der Prager Ansatz. Die Konjunktion geleitete Ansatz, die in Prager Abhängigkeitsbaumsammlungen angenommen wird, wo Koordinationsstrukturen durch die Konj</sample>
    <sample id="15">Drei. Wenn du noch Fragen hast, lass es mich wissen!</sample>
    <sample id="16">Bible texts werden stärker vereinfacht.</sample>
    <sample id="17">Abstract: This work focuses on multimodal relation extraction. It aims to determine semantic relations between entities in texts with various modalities. Problems like internal-information over-utilization and external-information under-exploitation are identified. A Graph Information Bottleneck principle - guided feature refinement is proposed. The method involves representing text and images with scene graphs, merging them into a unified cross - modal graph, CMG. Then, nodes and edges in CMG are filtered and adjusted. Multimodal topic features are used to enrich the context. Experiments on a MRE dataset show that the proposed method outperforms text - based methods and other multimodal baselines. The ablation study reveals that information screening and exploiting external information contribute to performance. The work introduces a novel idea of simultaneous information subtraction and addition for multimodal relation extraction.</sample>
    <sample id="18">"Salt and pepper" ist das Beispiel für die Präferenz für kürzere linke Konjunktionen.</sample>
    <sample id="19">The speaker, Zhang Qin from Shenzhen University, presents their work "A Survey for Efficient Open Domain Question Answering" accepted by ACL 2023. They focus on open-domain question answering, using a two-stage model with a question encoder and document encoder for retrieval. Challenges include large Wikipedia corpus, slow index file search, and multiple language models. Their motivation is to achieve efficient systems with smaller memory, faster inference, and comparable performance. They discuss core techniques like approximate nearest neighbor search, skip reading, and index size reduction. Comparisons show trade-offs between retrieval and reader systems. Conclusions suggest index size reduction or model size reduction for resource limitations. Future works include low-power device deployment and more evaluation metrics.</sample>
    <sample id="20">Ja, die Modelle sind frei verfügbar auf Hugging Face und unter der MIT Lizenz. Du kannst sie für deine Forschung verwenden. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="21">DEPLAIN-apa enthält Dokumente aus der Nachrichtenbranche.</sample>
    <sample id="22">Ein guter Modellarchitektur, größere Modellgröße und mehr Anpassungsbeispiele.</sample>
    <sample id="23">Dan Garrette spricht über Verbesserungen bei der Fähigkeit von Text-Bild-Modellen, visuelle Texte darzustellen. Die Text-Bild-Modellforschung hat große Fortschritte gemacht, aber viele Modelle sind schlecht darin, Text darzustellen. Der Imagen-Modell verwendet einen T5-XXL-Encoder, um Text zu verarbeiten, und einen Diffusion-Modell, um Bilder zu generieren. T5 nutzt SentencePiece-Tokenisierung, was die Modellleistung bei der Schreibfähigkeit beeinträchtigt. PaLM-Modelle sind besser in der Schreibfähigkeit, aber sie sind groß und trainiert auf viel Daten. ByT5, das die Einzelbytes des Inputs verwendet, ist gut in der Schreibfähigkeit. T5 hat Schwierigkeiten mit häufigen Wörtern, weil sie in einem einzigen Token oder ein paar Subwords dargestellt werden. ByT5 kann die Schreibfähigkeit verbessern, indem man eine zusätzliche Text-Darstellung des ByT5-small-Modells dem Imagen-Modell hinzufügt. Das verbessert die Bildgenerierung und</sample>
    <sample id="24">Die Tendenz zu kürzeren linken Konjunktionen wurde gemessen, indem die Länge in Zeichen, Silben und Wörtern gemessen wurde.</sample>
    <sample id="25">Die Experimente wurden so gestaltet, dass sie die Position des Begrenzers untersuchten. Es wurde die Länge der Konjunktionen gemessen, sowohl in Zeichen, Silben als auch in Wörtern. Es wurde beobachtet, wie sich die Tendenz, dass der linke Konjunkt kürzer ist, wenn der Begrenzer links ist oder fehlt, verstärkt. Wenn der Begrenzer rechts ist, verschwindet diese Tendenz. So wurden die Auswirkungen der Position des Begrenzers untersucht. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="26">Wenn ein Basisklassifikator mit unausgewogenen Daten trainiert wird, dann performiert er nicht viel besser als Zufall.</sample>
    <sample id="27">Ich kann es nicht sagen, da du den Inhalt in chinesischer Sprache hast und ich nur Englisch spreche. Kannst du den Inhalt bitte in Englisch wiedergeben?</sample>
    <sample id="28">Bob und Alice.</sample>
    <sample id="29">Formalität und lexikalische Kohäsion.</sample>
    <sample id="30">Das Team von AI2 und USC präsentiert "LLM-Blender", ein einfaches aber effektives Ensemble-Learning-Framework für große Sprachmodelle. Es basiert auf Paarvergleich und generativer Fusion. Viele Sprachmodelle haben gute Leistungen, aber die beste Modelle für verschiedene Eingaben variieren. Die LLM-Blender hat zwei Phasen. In der ersten Phase werden n Modelle ausgeführt und ihre Outputs verglichen. In der zweiten Phase werden die besten Kandidaten verwendet, um eine finale Ausgabe zu generieren. Der Paarvergleichsmodul PairRanker ist ein wichtiger Teil. Es vergleicht Paare von Kandidaten zusammen mit dem Eingabeinput, um die Qualität besser zu analysieren. Das PaarRanker ist besser als andere Methoden, da es die Paarvergleiche verwendet, um die Kandidaten sorgfältiger zu vergleichen. Das LLM-Blender hat gute Ergebnisse und ist ein vielversprechendes Ensemble-Learning-Framework. Es verbessert die Leistung erheblich.</sample>
    <sample id="31">Ich kann die Antwort nicht geben, da ich die genauen Universitäten der Autoren nicht aus dem gegebenen Text ableiten kann. Du könntest versuchen, den Text weiter zu lesen oder die Autoren direkt zu fragen.</sample>
    <sample id="33">Das vorgestellte Framework quantifiziert die Positionalität durch die Vergleichung der Annotations mit realen Nutzern mit den Modellen und Datensätzen. Es verwendet eine Pearson's R Korrelationsscore.</sample>
    <sample id="34">Marcos Treviso präsentiert "CREST: A Joint Framework for Rationalization and Counterfactual Text Generation". Es kombiniert rationale Erklärungen und counterfactual Texterzeugung. Der erste Teil generiert counterfactuals, indem er rationale Erklärungen verwendet, um die ursprüngliche Eingabe zu maskieren und neue Tokens einzufügen. Die Qualität der counterfactuals wird durch menschliche Beurteilung evaluiert. CREST kann auch für Datenverstärkung verwendet werden. Ein weiterer Aspekt ist die rationalisierung mit tatsächlichen und counterfactualen Beispielen, was zu plausibleren Erklärungen führt. CREST ist eine effektive Methode für die Erzeugung kontrollierter, plausibler counterfactuals.</sample>
    <sample id="36">Das Papier geht über "Learning Language-Specific Layers for Multilingual Machine Translation". Es zeigt Vorteile wie Skalierbarkeit, Geschwindigkeit und Verbesserungen für niedrige-Ressourcen-Sprachpaare. Allerdings hat es auch Nachteile wie begrenzte Kapazität pro Sprache. Die Ziele sind, die Kapazität pro Sprache zu erhöhen, wo es am wichtigsten ist, und die Inferenzkosten konstant zu halten. Die Lösung sind Language-Specific Layers, LSLs, also eine reguläre Transformer-Schicht pro Sprache. Diese wird bei der Inferenz verwendet, um die richtige Untereinheit auszuwählen. Die LSLs werden im Encoder platziert, um die Kapazität pro Sprache zu erhöhen. Es wird gezeigt, dass die LSLs in den unteren Schichten des Encoders wichtiger sind und in den oberen weniger. Die Platzierung der LSLs wird durch das Modell gelernt. Die Ergebnisse wurden mit WMT21 News Translation Masked Sources für 10 Sprachen trainiert und auf Flores-101 evaluiert. Die LSLs</sample>
    <sample id="37">Die Ergebnisse der vorherigen Studie zeigten, dass die menschlichen Teilnehmenden bei gleichen Persona-Prompts weniger Stereotypen in ihren Antworten enthielten als die generierten Personas.</sample>
    <sample id="38">Die Studie nutzte die erweiterte Version des Penn Treebank als Datenquelle.</sample>
    <sample id="39">Ein Autor.</sample>
    <sample id="40">Eng verwandte Aufgaben für kognitive Dissonanz sind die Stellungsklassifikation von Debatten und die Klassifikation von Erweiterung und Vergleichsklassen des PDTB.</sample>
    <sample id="41">Das Team aus EPFL University und Sony Group hat PeaCoK, eine Persona Commonsense Knowledge Graph, vorgestellt. Es umfasst 3.800 Personae und 40.000 Attribute, die 100.000 persönliche Inferenzen oder Fakten bilden. Es wird in drei Schritten erstellt: Auswahl von Personae aus bestehenden Graphen, Induktion von Attributen und Crowdsourcing der Relationen. PeaCoK hilft Sprachmodellen, Persona-Wissen zu lernen und generalisieren. Bei einer Persona-attrribut-Inferenz-Übung erreicht Comet-BART, trainiert auf PeaCoK, bessere Ergebnisse als GPT-3 und GPT-3.5. Bei der Persona-basierten Dialogerstellung auf ConvAI2 PersonaChat-Datensatz verbessern PeaCoK-augmentierte Modelle die Dialogerstellung in Bezug auf Fluß, Konsistenz, Engagement und Persona-Ausdruck. PeaCoK ist eine wichtige Quelle für persona-basierte Wissensgenerierung und narrative Modellierung.</sample>
    <sample id="42">I'm not sure. The text doesn't mention the number of authors involved. You could try looking for more information in the paper itself.</sample>
    <sample id="43">Ich kann es leider nicht sagen, da ich den genauen Namen der Autoren nicht habe. Wenn du mehr Informationen hast, kannst du sie mir nochmal schicken.</sample>
    <sample id="44">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten, indem es die Annotations durch Endbenutzer mit den Modellen und Datensätzen vergleicht, anstatt nur Annotatorenübereinstimmungen oder Modellierungen von Annotatorenverteilungen zu betrachten.</sample>
    <sample id="45">Die generated personas haben die meisten Überschneidungen mit dem Lexikon der Stereotypen.</sample>
    <sample id="46">DeepL und Google Translate.</sample>
    <sample id="47">Hallo, ich bin Shangbin, Doktorand an der University of Washington. Heute präsentiere ich unsere Arbeit "Von Prätrainingsdaten zu Sprachmodellen zu Downstream-Aufgaben: Verfolgen der Spuren politischer Biass, die zu unfairen NLP-Modellen führen". Also werden Sprachmodelle an großem Skalierungswortkrawall-Daten trainiert. Politische Nachrichtenmedien werden gut in ihren Prätrainingsdaten abgedeckt. Laut einer Umfrage des C4 Corpus können wir sehen, dass New York Times, Los Angeles Times, The Guardian, Huffington Post usw. gut in Sprachmodell-Trainingsdaten abgedeckt sind. Dies hat ein gemischtes Segen für Sprachmodell-Anwendungen geschaffen. Auf der einen Seite konnten sie von diversen Perspektiven lernen, was die Demokratie und die Vielfalt von Ideen feiert. Auf der anderen Seite sind diese verschiedenen politischen Meinungen von Natur aus sozial voreingenommen und könnten potenzielle Fairnessprobleme in Downstream-Aufgaben-Anwendungen hervorrufen.</sample>
    <sample id="48">David Vilar und seine Kollegen von Google Translate. Also mehrere Autoren. Wenn du mehr über die Arbeit wissen möchtest, kannst du das Papier vollständig präsentieren besuchen.</sample>
    <sample id="49">Bis zu 1024 Token Kontextlänge wurden MPP-Auswertungen durchgeführt. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="50">DEPLAIN ist ein neuer Korpus für die deutsche Textidentifikation auf Dokument- und Satzebene. Es wird vorgestellt, wie Texte für Menschen mit Leseschwierigkeiten oder Nichtmuttersprachler vereinfacht werden können. Es gibt zwei Unterkorpusse: DEPLAIN-apa mit 483 manuell ausgerichteten Dokumenten und DEPLAIN-web mit 750 Dokumenten, die manuell und automatisch ausgerichtet wurden. Die Simplifizierungstechniken variieren je nach Korpus. Der DEPLAIN-Korpus wird für die Evaluierung von automatischen Ausrichtungsmethoden und für die automatische Textvereinfachung durch das Anpassen von Sprachmodellen verwendet. Die besten Ergebnisse wurden mit dem Methoden der MASSalign erzielt. Vielen Dank fürs Zuhören.</sample>
    <sample id="51">Sie haben die Domains Musik, Bücher und Rezepte in ihren Datensatz aufgenommen.</sample>
    <sample id="52">Positionalität ist die Perspektive, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben.</sample>
    <sample id="53">Dawei.</sample>
    <sample id="54">Abstract: Vasudha, a PhD candidate at Stony Brook University, presents their work "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge" accepted into ACL 2023. They define cognitive dissonance as inconsistent beliefs or actions, like a person stating they know cigarettes could kill them but still smoking. Studying dissonance in language helps understand disagreement effects, track trends, and mental health. They conducted a large-scale annotation of dissonance relations using a dissonance-first approach. However, dissonance is rare in language. To tackle this, they use transfer learning and active learning. They transfer weights from related tasks like topic-independent dissonance stance classification and binary classification of expansion and comparison classes. They find that the PRC strategy works best for rare class acquisition. After several rounds of active learning, they improve dissonance classification AUC to 0.75. This work is significant for understanding cognitive dissonance in language and its implications.</sample>
    <sample id="55">Ja.</sample>
    <sample id="56">Nur ein Autor ist an der Arbeit beteiligt, und zwar Yusen Zhang.</sample>
    <sample id="57">Nicht immer. Ohne spezifische Trainings auf KITMUS funktioniert das Modell nicht gut. Aber wenn es auf KITMUS trainiert wird, performen C2F und BERT4Coref besser als zufällige Auswahl.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind "Background-Pretrain", "Background-Both" und "Background-Inference".</sample>
    <sample id="59">DrBERT is a robust pre-trained model in French for biomedical and clinical domains. It's based on RoBERTa and trained on NACHOS, a web-crawled medical data set. Compared to other models like Word2vec, fastText, and English models like PubMedBERT and BioBERT, DrBERT offers better performance. It's the first specialized French model for biomedical tasks. DrBERT was trained with different data sources and pre-training settings. It outperformed CamemBERT and other models on 11 downstream tasks. The models are freely available on Hugging Face under MIT license and training scripts are on GitHub.</sample>
    <sample id="60">Ich kann leider keine Angaben zu den Universitäten der Autoren machen, da das Originaltext nicht genügend Informationen enthält. Wenn du weitere Details hast, kannst du sie gerne mitteilen.</sample>
    <sample id="61">Die abschließende Forschungsfrage lautet: "Should we only use the clean samples for validation, or there are better ways to utilize them?"</sample>
    <sample id="62">Nitay Calderon, zusammen mit Amir und Subhabrata von Microsoft und seinem PhD Advisor Roi, hat ein Papier über das Systematische Studium von Wissensverdichtung für Natürliche Sprachenerzeugung mit Pseudo-Zieltraining geschrieben. Sie erkennen, dass große Sprachmodelle komplex, langsam und teuer sind. Deshalb ist die Modellkomprimierung gefragt. Ihr Ziel ist, die Modellleistung zu bewahren, während sie komprimiert wird. Sie untersuchen verschiedene Verfahren wie Pruning und Wissensverdichtung. Es gibt zwei Hauptarten von Wissensverdichtung: Wortebene und Sequenzebene. Sie führen eine systematische Studie für verschiedene NLG - Aufgaben durch, wie Zusammenfassung, Frageerstellung, Kognition und Einfachstellung und Stiltransfer. Sie testen verschiedene Architekturen, Pruning - Effekte, Wissenselektrons und neue Techniken wie das gemeinsame Unterrichten. Sie zeigen, wie unbeschriftetes Datenmaterial und mehrere Pseudo-Ziele die Modellleistung verbessern. Schließlich stellen sie eine neue</sample>
    <sample id="63">Die Sensitivitätsmetrik misst das Modellvermögen, konstante Ausgaben für dieselbe Aufgabe zu produzieren, unabhängig von leichten Variationen im Wortlaut der Anweisung.</sample>
    <sample id="64">Jingwei Yi.</sample>
    <sample id="65">Eine höhere Sensitivität bedeutet eine schlechtere Leistung des Modells.</sample>
    <sample id="66">"Deep Learning for Mathematical Reasoning" surveys the task of mathematical reasoning and deep learning method development. It covers text - based and multimodal data like images, figures, and tables. It discusses visual and tabular contexts, geometric problem solving, and automated theorem proving. Neural network architectures like sequence - to - sequence and sequence - to - tree models are introduced. Pre - trained language models, especially large language models, are applied to math word problems. Limitations of LLMs in mathematical reasoning are mentioned. Solutions like self - consistency and program - aided LLMs are proposed. Low - resource settings and domain - specific benchmarks are briefly touched on.</sample>
    <sample id="67">Interferenz in multilingualen Übersetzungsmodellen kann positiv oder negativ sein. Einige Methoden zur Reduzierung der Interferenz haben oft nur bei kleinen Modellen bewiesen werden können und sind nicht immer besser als ein abgestimmtes Baseline. Interferenz tritt vor allem bei sehr kleinen Modellen im Vergleich zur Datenmenge auf. Tunen der Sampling-Temperatur ist entscheidend für starke Leistung. Bei einfachen bilingualen Fällen gibt es Skalierungsgesetze für Modell- und Datenmenge, die ein Verlust vorhersagen können. Bei multilingualen Fällen sind andere Faktoren wie Datenmenge anderer Sprachen, Sprachähnlichkeit und Gesamtzahl der Sprachen relevant. Die Sprachähnlichkeit hat keinen großen Einfluss auf die Interferenzniveaus. Severe Interferenz tritt nur bei den kleinsten Modellen auf und verschwindet mit zunehmender Skalierung. Die beste Kontrolle der Trade-offs ist die Temperatur-Sampling-Regelung. Ein Baseline für die Bekämpfung von Interferenz ist schwach aufgrund der Größe</sample>
    <sample id="68">Die Modelle erhalten einen linguistischen Kontext, der aus akzeptablen und unakzeptablen Sätzen besteht, die aus den Daten der BLiMP oder SyntaxGym-Datensätze stammen.</sample>
    <sample id="69">Typischerweise werden normalerweise 20 saubere Validierungsbeispiele pro Klasse benötigt, um eine hohe Leistung an der WSL zu erzielen.</sample>
    <sample id="70">Ich habe leider keine Informationen über die Universitäten der Autoren. Du könntest versuchen, das im Originaltext zu suchen oder weitere Quellen zu überprüfen.</sample>
    <sample id="71">Das Team von Javad Hosseini und anderen hat das AltEntities Corpus für die Aufklärung indirekter Referenzausdrücke in der Entitätsauswahl vorgestellt. Ihr Ziel ist, das Verständnis von Nutzern bei der Auswahl zu verstehen. Indirekte Referenzen können nützlich sein, wenn der Name nicht bekannt ist, die Aussprache ähnlich ist oder eine Präferenz ausgedrückt werden soll. Sie haben eine Datenbank für Musik, Bücher und Rezepte gesammelt. Die Daten werden informell mit einer Cartoon - Komplettlösung gesammelt. In der zweiten Sprechblase wird eine Alternative Frage gestellt, wie "Do you mean 'Easy on Me' or 'I Gotta Feeling'?" Die dritte Sprechblase enthält eine indirekte Referenz. Die Annotatoren wählen eine Entität aus und beschreiben sie mit indirekten Referenzausdrücken. Das Corpus hat 6.000 alternative Fragen und 42.000 indirekte Referenzausdrücke. Die Ergebnisse mit dem T5 XL - Modell zeigen, dass die Genauigkeit</sample>
    <sample id="72">Weil es eine faire Anwendung von Sprachmodellen in NLP-Anwendungen verhindern kann.</sample>
    <sample id="73">Akshatha.</sample>
    <sample id="74">Das Papier präsentiert "Dense-ATOMIC: Richtung dicht verbundener ATOMIC mit hoher Wissensabdeckung und massiven Multi-hop-Pfaden". ATOMIC ist eine große Wissensbasis für alltägliche Fakten und Urteile. Es fehlen in ATOMIC viele B-to-B, A-to-B und A-to-A Links, was die Wissensabdeckung beeinträchtigt. Dense-ATOMIC wird auf ATOMIC aufgebaut und viele fehlende Links ergänzt. Es gibt Multi-hop-Pfade wie "X bittet Y um Heirat, Y sagt ja, X lächelt". Die Konstruktion von Dense-ATOMIC umfasst drei Teile: Normalisierung von Zielereignissen, Training eines Beziehungsprädikationsmodells und Konstruktion von Dense-ATOMIC. Rel-CSKGC wird vorgeschlagen, um Beziehungen zu prädizieren. Es nutzt semantische Informationen und vermeidet die Probleme der spärlichen Struktur. Es wird eine Intra- und Inter-Cluster-Belebungstechnik verwendet. Rel-CSK</sample>
    <sample id="75">Zheng Yandan presents Jointprop, a joint semi-supervised learning framework for name entity recognition, NER, and relation extraction, RE. The motivation is to address the lack of interconnections between NER and RE tasks in existing studies. They propose a framework with four parts: span feature generation, heterogeneous graph construction, joint label propagation, and model optimization. The framework aims to propagate labels across graphs and consider connections among data. Experiments on four datasets show that joint learning benefits from codependency in joint datasets and significantly improves over baselines on single-task datasets for both NER and RE tasks.</sample>
    <sample id="76">The pipeline for the propagation of political biases includes pretraining data, language models, and downstream tasks. Pretraining data contains political news media, which can lead to diverse perspectives but also inherent social biases. Language models learn from these pretraining data and might inherit political leanings. These political leanings can then affect downstream tasks like hate speech detection and fake news detection, leading to potential fairness issues.</sample>
    <sample id="77">This video shares work on improving summarization factual consistency. It introduces the DeFacto dataset with human demonstrations and feedback. The work proposes three new NLG tasks: summary editing, feedback generation, and automatic factual error correction. It focuses on abstractive text summarization. The dataset is based on XSum and uses Pegasus model outputs. Around 2.5K data points were collected, 70% with errors. Human-edited summaries get higher factuality scores but lower textual overlap. Summary editing is effective with human feedback. Feedback generation is challenging. Automatic error correction with explanation is comparable to baseline models. The dataset is valuable for training factuality metrics and meta-evaluation. It's released on GitHub.</sample>
    <sample id="78">Ja, es unterscheidet sich. In DEPLAIN-apa gibt es mehr Reordernings und Wortzuweisungen als in DEPLAIN-web. In DEPLAIN-web gibt es mehr Rephrasings.</sample>
    <sample id="79">Ja, Coscript ist öffentlich verfügbar. Wenn du mehr Details haben möchtest, kannst du das Papier durchsuchen.</sample>
    <sample id="80">Das Wasserzeichen wird in den Text eingebettet, indem zuerst ein Trigger-Set aus Worten in einem mittleren Frequenzintervall ausgewählt wird. Dann wird ein Ziel-Embedding definiert. Wenn ein Benutzer einen Satz an den Provider-Service sendet, zählt der Provider die Anzahl der Trigger im Satz. Der bereitgestellte Embedding ist eine Gewichtssumme des Ziel-Embeddings und des Original-Embeddings. Der Gewichtswert des Ziel-Embeddings ist proportional zur Anzahl der Trigger im Satz. Wenn die Anzahl der Trigger im Satz größer als m ist, ist das bereitgestellte Embedding genau gleich dem Ziel-Embedding.</sample>
    <sample id="81">Penn State University.</sample>
    <sample id="82">Das Video geht über die Arbeit "Aggregating Multiple Heuristic Signals as Supervision for Unsupervised Automated Essay Scoring". Es geht um das automatische Punkten von Essays ohne menschliche Intervention. State-of-the-art AES-Modelle werden meistens mit großen beschrifteten Korpora in einem überwachten Modus trainiert, was zeitraubend und mühsam ist. Unsupervised AES kann die Anforderungen an Ground-truth-Scores für die Trainierung loswerden und hat Potenzial in der Forschung und Praxis. Zwei Arbeiten haben die Unsupervised AES Aufgabe angegangen. Eine nutzt die Anzahl einzigartiger Begriffe als Initialscore, die andere Wortanzahl als schwache Supervision. Beide haben schlechte Leistung gezeigt. Die Autoren schlagen vor, mehrere Heuristische Qualitätssignale als Pseudo-Groundtruth einzuführen und eine neuronale AES-Modell zu trainieren, das von der Aggregation dieser Signale lernt. Der ULRA - Framework hat sich in Experimenten sowohl in transduktiven als auch in induktiven Einstellungen als überlegen erwiesen. Er ist</sample>
    <sample id="83">Ja, Encoder-Decoder-Modelle wie mT5 können durch Training mit einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="84">Shwai He präsentiert sein Papier "PAD-Net: An Efficient Framework for Dynamic Networks" für ACL 2023. Er beginnt mit dem Hintergrund der dynamischen Netzwerke, die im Gegensatz zu statischen Netzwerken ihre Architektur oder Parameter basierend auf dem Input ändern können. Er erwähnt Beispiele wie Mixture of Experts und dynamische Konvolution. Die Implementierung dynamischer Netzwerke ist einfach, indem statische Schichten durch dynamische ersetzt werden. Allerdings haben vollständig dynamische Netzwerke oft zu vielen Parametern geführt, was in vielen Situationen unannehmbar ist. Seine Hypothese ist, dass vollständig dynamische Netzwerke Teils dynamische Unter-Netzwerke enthalten, die die Repräsentationskraft des Original-Netzwerks aufrechterhalten. PAD-Net, Partially Dynamic Network, ist sein eigenes Framework, bei dem die Parameter in dynamische und statische geteilt werden. Es gibt zwei Skalenfaktoren, um die Intensität der beiden Modi zu beschreiben. Die Methode zur Teilung ist iterative Mod</sample>
    <sample id="85">Ein Beispiel für eingeschränkte Sprachplanung ist "make a chocolate cake". Es gibt viele spezifische Anforderungen wie die Art des Backofens, die Zutaten und die Backzeit.</sample>
    <sample id="86">Wir stellen die Opazität unserer Methode sicher, indem wir den Wasserzeichen in den bereitgestellten Embeddings versteckt. Die Wasserzeichen sind so konzipiert, dass sie nicht die Nutzbarkeit der bereitgestellten Embeddings beeinträchtigen. Sie sind auch so versteckt, dass der Angreifer sie leicht entfernen kann. Und während der Modellentnahme können die Wasserzeichen übertragbar sein.</sample>
    <sample id="87">The work uses existing PLMs as a base for pre-training, then fine-tunes them on specific biomedical and clinical data sets like NACHOS and clinical notes. This helps in building a new PLM that is more specialized for the French biomedical and clinical domains.</sample>
    <sample id="88">GPT-4 ist am wenigsten ausgerichtet an nichtbinäre Personen.</sample>
    <sample id="89">Der Beispielsatz ist: "If we receive a speech chunk containing 'I'm going to talk about...' and our model predicts the translation in German, and we will look at the cross-attention weights, we'll see that the first two words points to the earliest received speech frames, while the last word points to the last received speech frames, as lambda speech frames. This means that the first two words will be emitted while since the sum of the cross-attention is above a certain threshold alpha, we will not emit the last word and we wait for another speech chunk."</sample>
    <sample id="90">Das Papier von Haneul Yoo und Kollegen untersucht, ob Sprachlernende für die Datenbeschriftung in der NLP eingesetzt werden können. Sie haben eine Studie durchgeführt, in der sie Sprachlernende in drei Sprachen - Englisch, Koreanisch und Indonesisch - als Beschriftungsmitarbeiter einsetzten. Sie haben vier Aufgabenarten aus dem GLUE-Benchmark ausgewählt und die Lernenden in drei Niveaugruppen unterteilt. Die Ergebnisse zeigen, dass Beschriftungen von Lernenden fast genauso genau sind wie von Muttersprachlern, insbesondere für einfache Aufgaben. Wenn die Beschriftungen von Lernenden durch Mehrheitswahl mit denen von Muttersprachlern kombiniert werden, sind sie fast auf dem gleichen Niveau. Die Lernenden verbessern sich auch in ihrer Sprachkenntnis und Vokabular. Das Papier zeigt, dass Lernende eine alternative Möglichkeit für die Datenbeschriftung in Sprachen mit geringer oder mittlerer Ressourcenzahl bieten können. Es könnte die NLP-Forschung für viele Sprachen er</sample>
    <sample id="91">Als die Anzahl der Aufgaben zunimmt, erreicht das Modell bessere Leistung und gleichzeitig eine niedrigere Sensibilität.</sample>
    <sample id="92">Leider habe ich im Text keine Angaben zu drei baumlosen Baselines, mit denen die Autoren ihre Methode vergleichen. Du könntest aber versuchen, im Paper nachzulesen oder den Autoren direkt zu fragen. Vielleicht kannst du mir noch weitere Fragen stellen?</sample>
    <sample id="93">The two co-authors are advisors to the first author.</sample>
    <sample id="94">Jingwei Yi from the University of Science and Technology of China presents a short ad video about their paper. They discuss embedding as services for large language models like GPT, LLAMA, and PALM. Embedding as services assist various NLP tasks. However, attackers can steal the model through learning from the embedding. To protect copyright, they propose Embedding marker, a backdoor based watermark method. It has two main steps: watermark injection and copyright verification. They select a trigger set of moderately frequent words. In watermark injection, the provider adjusts the embedding based on the number of triggers in a sentence. For copyright verification, they use a backdoor and benign data set. The provider computes similarities and uses a KS test. Experiments on four data sets show great detection performance and utility for downstream tasks. The provided embedding is visually hard to distinguish from normal ones.</sample>
    <sample id="95">David Vilar ist der erste Autor von PaLM. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="96">Hallo Leute. Ich bin Jenny, ein erstes Jahr PhD-Student an der Carnegie Mellon University, und heute werde ich euer Werk NLPositionality präsentieren, das die Designbiasken der Datensätze und Modelle charakterisiert. Dieses Werk wurde in Zusammenarbeit mit einigen Leuten von der University of Washington und dem Allen Institute for AI durchgeführt, nämlich Sebastian Santy, Ronan Le Bras, Katharina Reinecke und Maarten Sap. Lass uns damit beginnen, dass du arbeitest für eine Zeitung und durchsuchst die Kommentare unter deinem Nachrichtenartikel, um giftige Inhalte zu entfernen. Du könntest auf ein beliebtes API wie Prospective API für Giftigkeitserkennung zurückgreifen, und das funktioniert wirklich gut, wenn du Carl Jones bist. Wenn Prospective API giftige Instanzen korrekt erkennen kann. Aber das ist nicht der Fall für Aditya Sharma. Wenn Prospective AP wirklich nicht so empfindlich auf offensive Begriffe ist, die in indischen Kontexten häufiger vorkommen. Dies ist ein Beispiel für eine Designbiaskonstruktion, bei der wir systematische Leistungsunt</sample>
    <sample id="97">Die Referentin geht auf drei Probleme von SimulST ein.</sample>
    <sample id="98">Es ist schwierig, soziale und politische Verzerrungen effektiv zu reduzieren. Wenn man die politischen Meinungen in den Datensätzen nicht reinigt, wird die Verzerrung von den Trainingsdaten auf die Sprachmodelle übertragen und schließlich zu Unfairness in den NLP-Anwendungen führen. Wenn man versucht, die Meinungen zu reinigen, könnte es zu Zensur oder Ausschluss kommen. Es ist sehr schwierig zu bestimmen, was neutral ist und in den Datensätzen behalten werden sollte. Es ist wie das Problem des elektrischen Tunnels.</sample>
    <sample id="99">Hallo, ich bin Siyu Yuan von der Fudan University. Ich möchte unsere Arbeit "Distilling Script Knowledge from Large Language Models for Constrained Language Planning" vorstellen.In unserem Alltag planen Menschen ihre Handlungen oft nach Schritt-für-Schritt-Anweisungen in Form von zielorientierten Skripten. Vorige Arbeiten haben verwendet, dass Sprachmodelle für abstrakte Ziele stereotypischer Aktivitäten wie "einen Kuchen backen" planen können und gezeigt, dass große Sprachmodelle effektiv Ziele in Schritte zerlegen können. Allerdings haben vorige Arbeiten sich hauptsächlich auf das Planen für abstrakte Ziele stereotypischer Aktivitäten konzentriert. Das Planen für Ziele mit spezifischen Einschränkungen, wie "einen Schokoladenkuchen backen", bleibt noch unerforscht.In dieser Arbeit definieren wir das Problem des beschränkten Sprachplans, das verschiedene Einschränkungen auf die Ziele des Plans aufbaut. Ein abstraktes Ziel kann durch verschiedene realleben spezifische Ziele</sample>
    <sample id="100">Multi-hop QA involves answering questions that need multiple reasoning steps, often using documents from a corpus. For example, to find a 1988 Christmas comedy film Brian Doyle-Murray starred in, you first find his movies and then the 1988 one. Multi-hop retrievers are trained to maximize the probability of the correct chain given a question. PromptRank is a data-efficient approach that uses an unsupervised retrieval method and a few-shot language model reranker. It retrieves candidate chains using TF-IDF and hyperlink traversal, then reranks them based on the probability of the question given the chain prompt. PromptRank outperforms fully supervised systems and performs well on HotpotQA. It uses GPT2-XL and T5-XL and evaluates on R@K recall and answer recall AR@K. PromptRank shows strong few-shot path retrieval performance and the instruction is crucial for eliciting language models' reasoning over chain documents.</sample>
    <sample id="101">The fluency of PaLM is comparable to state-of-the-art systems.</sample>
    <sample id="102">Ein Wasserzeichenverfahren sollte auf Embedding as services anwendbar sein, die Wasserzeichen den Nutzen der bereitgestellten Embeddings nicht vermindern, versteckt genug sein, dass der Angreifer sie nicht leicht entfernen kann und während des Modell-Ausbauprozesses übertragbar ist.</sample>
    <sample id="103">14 different languages.</sample>
    <sample id="104">Die genaue Anzahl der Instanzen, die für die erneute Annotierung aus einem Datensatz extrahiert werden, ist nicht angegeben.</sample>
    <sample id="105">Cosine und L2 - Distanz.</sample>
    <sample id="106">Chaitanya und seine Kollegen präsentieren das Paper QUEST. Es geht um die Suche nach Informationen mit mehreren Bedingungen. Jane und Austin sind Beispiele dafür. QUEST ist ein Retrieval-Datensatz mit über 3.000 Anfragen, die implizite Set-Operationen enthalten. QUEST wird konstruiert, indem man Wikipedia-Kategorien aus vier Bereichen verwendet und dann Set-Operationen darin durchführt. Anwender überprüfen die Relevanz der Ergebnisse und markieren die relevanten Abschnitte im Dokument. Die Evaluierung zeigt, dass es viel Verbesserungspotenzial gibt. Die Arbeit hofft, dass QUEST Zukunftsforschern bei der Entwicklung von verbesserten Systemen für die Informationssuche mit selektiven Bedürfnissen hilft.</sample>
    <sample id="107">In der Aufgabe wurden Modelle, die auf einem mehrsprachigen Encoder basieren, wie mBART und mT5, eingesetzt.</sample>
    <sample id="108">Koustav Sinha und seine Kollegen haben eine Studie über die Akzeptanzurteile von Sprachmodellen veröffentlicht. Sie erkunden, dass die Minimal-Paar-Paradigmen, die Sprachmodelle auf Akzeptanzurteile testen, nicht immer robust sind. Ihre Arbeit konzentriert sich auf die Evaluierung von Sprachmodellen anhand länglicher Sequenzen. Sie simulieren längere Sequenzen, indem sie akzeptable und unakzeptable Sätze aus Datensätzen wie BLiMP und SyntaxGym auswählen. Sie untersuchen, wie Sprachmodelle akzeptanzurteilend sind, wenn sie längere Kontextfenster haben. Sie finden, dass die MPP-Urteile für Wikipedia-Sätze, die irrelevant sind, relativ stabil sind. Wenn Sätze aus demselben Datensatz verwendet werden, steigen oder fallen die MPP-Urteile erheblich, wenn akzeptable oder unakzeptable Präfixe hinzugefügt werden. Die Studie zeigt, dass Sprachmodelle empfindlich auf verborgene syntaktische und semantische Merkmale in den Sätzen</sample>
    <sample id="109">Or präsentiert "Unnatural Instructions: Tuning Language Models with, fast, Almost No Human Labor". Es geht darum, wie man mit wenig menschlicher Arbeit ein großes, vielfältiges Dataset für Anweisungen erstellen kann. Sie verwenden einen GPT-3 -ähnlichen Modellvarianten, um Anweisungen und Inputs zu generieren. Dann generieren sie Outputs und machen Paraphrasen. Das Ergebnis ist ein Dataset mit 64.000 Beispielen, von denen es mit Paraphrasen etwa 240.000 gibt. Die Beispiele sind kreativ und vielfältig. Sie testen es mit einem 11 Milliarden Parameter großen T5 -Modell und finden, dass es besser als andere Modelle auf verschiedenen Benchmarks leistet. Unnatural Instructions zeigt die Fähigkeit von Sprachmodellen, kreative und vielfältige Daten zu generieren, was mit Menschenarbeit schwierig ist. Es ist schneller und billiger als Menschenarbeit.</sample>
    <sample id="111">The authors assume the provider can collect a general text corpus and count the word frequency with it.</sample>
    <sample id="112">Hallo alle zusammen, mein Name ist Shuheng. Heute werde ich unser Papier "Do CoNLL-2003 named entity taggers still work well in 2023?" präsentieren. Lass uns anfangen. Unser Papier untersuchte das Problem der Generalisierung unter Verwendung der Named Entity Recognition Task oder der NER Task. Wir beobachten, dass Modelle seit fast 20 Jahren in CoNLL-2003 verwendet wurden, um NER zu entwickeln, und dies wirft natürlich mehrere Probleme auf. Zunächst einmal, können diese Modelle auf moderne Daten generalisieren? Und wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung notwendig? Gleichzeitig, wenn wir eine schlechte Generalisierung beobachten, was verursacht den Leistungsabfall dieser Modelle? Um diese Probleme zu untersuchen, haben wir den CoNLL++ Dataset entwickelt. Dies ist ein Datensatz, den wir aus den Reuters News von 2020 gesammelt und dann mit den gleichen CoNLL-2003 Annotierungshinweisen annotiert haben</sample>
    <sample id="114">The work introduces "Finding the Pillars of Strength for Multi-Head Attention" from Nanyang Technological University of Singapore. It discusses limitations of large language models like heavy parameters, long training time, and token-hungry nature. The focus is on the heavy parameter problem. The multi-head attention redundancy is optimized through grouped head attention. Two strategies are used: group-constrained training to make intra-group heads similar and inter-group heads separate, and Voting-to-Stay algorithm to prune redundant heads. The models, GHT and GHT-PS, perform well on machine translation, abstract summarization, and language modeling tasks. They achieve significant parameter compression and performance improvements. Future work aims at task-specific automatic pruning based on the Lottery Ticket Hypothesis.</sample>
    <sample id="115">Die Sprachsegmentgröße wird nicht explizit erwähnt. Es wird aber erwähnt, dass die Entscheidung, ob ein Wort emittiert wird, basierend auf der Konzentration der Aufmerksamkeit auf frühere oder spätere Sprachrahmen erfolgt.</sample>
    <sample id="116">Im Beispiel wird das entitätsspezifische Wissen benötigt, dass Servin ein Richter ist.</sample>
    <sample id="117">Der wichtige Faktor ist die Qualität des Beispiels.</sample>
    <sample id="118">The presentation is about improving pretraining techniques for code-switched NLP. Code-switching is common in linguistically diverse communities like India. Multilingual models like mBERT and XLM-R don't perform well on code-switched tasks. The main contributions are novel MLM techniques, SwitchMLM, and FrequencyMLM. SwitchMLM focuses on switch-points, which are transitions between languages. FrequencyMLM uses negative log likelihood from monolingual corpora. Architectural modifications like residual connections are proposed. The combined method performs best on sentiment analysis tasks. Probing experiments show increased switch-point information in intermediate and final layers. This motivates further architectural changes and an auxiliary loss.</sample>
    <sample id="119">In den erweiterten Experimenten konzentrieren sich die Arbeiten auf GPT-4, GPT-Serie, BART-Serie und ihre Varianten.</sample>
    <sample id="120">Das Modell verwendet Werte aus mehreren Ebenen.</sample>
    <sample id="121">Examples of direct inference are saying the name of the song "Easy on Me" or its position, "the first one".</sample>
    <sample id="122">Fudan University.</sample>
    <sample id="123">Ying und Zhiyang präsentieren ihre Forschung über MultiInstruct, ein Benchmark-Datensatz für die Anpassung von Multi-Modalen Prädikationsmodellen durch Anweisungstuning. Sie untersuchen, ob Anweisungstuning bei multi-modalen Aufgaben tatsächlich zu besseren Ergebnissen führt. Ihr Datensatz umfasst 62 diverse Aufgaben aus 10 Kategorien, abgeleitet von 21 offenen Datensätzen. Sie verwenden OFA als Grundmodell und trainieren es mit 53 Aufgaben. Für die Tests werden 10.000 Instanzen pro Aufgabe verwendet. Sie messen die Leistung mit verschiedenen Metriken wie Genauigkeit und Rouge-L. Ihre Ergebnisse zeigen, dass Anweisungstuning OFA bei sichtbaren multi-modalen Aufgaben verbessert. Transfer-Learning von natürlichen Anweisungsdatensätzen hilft, die Sensitivität zu reduzieren und die Leistung zu verbessern. Sie planen, einen größeren Datensatz zu sammeln und veröffentlichen ihn.</sample>
    <sample id="124">Tan Qingyu from the National University of Singapore and Alibaba presented their work on temporal reasoning in large language models. They broke it into three levels: time-to-time, time-to-event, and event-to-event. They found prior works focused on L2 reasoning too much. They conducted a preliminary experiment on L1 year prediction, finding biases in LMs. They proposed TempReason dataset for comprehensive temporal reasoning study. They also proposed a training strategy with Temporal span extraction pre-training and time-sensitive reinforcement learning. Their TempT5 model outperformed others in OBQA and ReasonQA. They concluded by analyzing temporal reasoning biases and proposing a training paradigm.</sample>
    <sample id="125">I don't know how many authors are involved in the work. You could try looking for more information in the presentation or other sources.</sample>
    <sample id="126">Ja.</sample>
    <sample id="127">Namgyu Ho, Laura Schmid und Se-Young Yun präsentieren ihre Arbeit "Large Language Models Are Reasoning Teachers". Sie stellen fest, dass chain-of-thought -Reasoning nur auf riesigen Modellen wie GPT-3 oder PALM funktioniert, was teuer und schwierig ist. Sie schlagen vor, diese großen Modelle als "Lehrer" zu nutzen, um ihre Fähigkeiten an kleinere Modelle zu übertragen. Sie entwickeln eine Technik namens "diverse reasoning", um die Übertragung zu verbessern. Sie testen viele Beispiele, um zu sehen, ob kleine Modelle komplexe Aufgaben lösen können, die früher nur große Modelle konnten. Sie beginnen mit Fragen aus bestehenden Benchmark -Daten. Anschließend wird chain-of-thought -Prompting auf großen Modellen angewendet, um Schritt-für-Schritt -Lösungen für komplexe Aufgaben zu generieren. Diese Lösungen werden als Trainingsdaten für kleinere Modelle verwendet. Sie finden, dass diese Methode, die sie "fine -tuned CoT" nennen, komplexe Aufgaben gut lösen kann</sample>
    <sample id="128">The authors present a diagnostic test suite, KITMUS, for evaluating knowledge integration in natural language understanding models. They introduce a coreference resolution task to probe for the ability to use knowledge from different sources. The test has three settings: Background-Pretrain, Background-Both, and Background-Inference. The authors evaluate the data set with human participants and established models. They find that without task-specific training, models perform poorly. However, with training on KITMUS, some models improve significantly. The study suggests that many models struggle with integrating backward knowledge presented only at inference time. For more details, see the paper and check out the data set and code on GitHub.</sample>
    <sample id="129">The authors gave the example of Asian women as a marked group.</sample>
    <sample id="130">Nicht genannt. Es wird nur erwähnt, dass transformer Modelle normalerweise besser generalisieren.</sample>
    <sample id="131">Die Testdatensätze heißen clean test sets.</sample>
    <sample id="132">Zwei.</sample>
    <sample id="133">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="135">James Finch and Sarah Finch introduce ABC-Eval, a new dimensional approach to evaluating conversational AI. Developed by the Emory NLP Lab and Amazon Alexa AI, it aims to provide a more precise and reliable evaluation than human evaluation. ABC-Eval annotates chat model behaviors like irrelevant responses or contradictions. It was tested on four state-of-the-art chat models across 100 human-bot conversations. Compared to existing methods, ABC-Eval shows higher reliability and predictive power. It can measure various thematic errors and explain a significant portion of conversation quality. Challenges remain, but ABC-Eval offers a higher resolution for evaluating conversational AI.</sample>
    <sample id="136">Jasivan und Nafise präsentieren ihre Arbeit "FERMAT: An Alternative to Accuracy for Numerical Reasoning" aus der University of Sheffield. Sie motivieren sich durch die vielen realen Anwendungen von numerischer Vernunft und die Notwendigkeit der Faktizität in downstream - Aufgaben wie Faktenprüfung. Ein Beispiel ist die Beurteilung von Aussagen wie "Chris Brown wurde berühmt, als er 16 Jahre alt war", basierend auf einer Tabelle. Sie stellen FERMAT vor, ein flexibles Evaluationsset für arithmetische Typen, das Fragen aus Illinois und CommonCore extrahiert. Es testet die Modelle anhand von Zahlenverstehen, mathematischen Operationen und Trainingsabhängigkeit. Sie finden, dass viele Modelle schlecht in diesen Bereichen performen. Durch Feinabstimmung mit mathematiklehrer geschriebenen Vorlagen, die Zahlen durch Nummerhalter ersetzen, verbessern sich die Ergebnisse. Sie entdecken, dass Sprach- und mathematische Diversität wichtig sind. Zusammenfassung: Jasivan und Nafise präsentieren F</sample>
    <sample id="137">Das Paper "Tell2Design: A Dataset for Language-Guided Floor Plan Generation" von Sicong aus der Singapore University of Technology and Design beschreibt eine neue Aufgabe in der maschinellen Lernen, die es ermöglicht, 2D-Floorpläne direkt aus Sprachanweisungen zu generieren. Es wird ein neues Dataset, Tell2Design, vorgestellt, das aus öffentlich verfügbaren Floorplänen und dazugehörigen Sprachanweisungen besteht. Die Hauptaufgabe ist es, Floorpläne zu generieren, die den Anweisungen entsprechen. Es gibt drei Hauptforderungen: strenge Bedingungen, das Verständnis des Gesamteinbaus aus unstrukturiertem Text und die Unklarheiten in den menschlichen Anweisungen. Die Methode verwendet einen Encoder-Decoder-Frame, um die Anweisungen als Eingabesequenz und die Raumgrenzen als Zielsequenz zu behandeln. Der Modell wird ein prätrainierter T5-Modell für bessere Sprachverstehen verwendet. Das T2D-Modell erzielt die höchsten Io</sample>
    <sample id="138">Die Autoren meinen, dass das Gebiet der Integration von Wissen aus verschiedenen Quellen im Bereich der NLU zu wenig erforscht ist.</sample>
    <sample id="139">Ying und Zhiyang.</sample>
    <sample id="140">Ja, Coscript hat eine Qualitätskontrolle durchlaufen. Crowd-sourced Workers haben die fehlerhaften Samples gefunden und korrigiert.</sample>
    <sample id="141">Die bestehenden Ressourcen für kontextbasierte Übersetzung unterstützen nur begrenzte Typen von kontextbasierten Übersetzungen und begrenzte Sprachensätze, da sie meistens auf Domänenwissen und menschlicher Kuration angewiesen sind.</sample>
    <sample id="142">Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo! Ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übers</sample>
    <sample id="143">Der Ansatz wird mit Wait-k strategy und Local Agreement verglichen.</sample>
    <sample id="144">I'm sorry, but I don't have enough information to answer that question. The text doesn't mention which university the authors belong to. If you have any other questions about the presentation, feel free to ask.</sample>
    <sample id="145">Jenny.</sample>
    <sample id="146">Yicheng, ein Doktorand von Fudan University, gibt einen Vortrag über die Analyse von Omissionen in Dialogsummarisierung. Er stellt die Hintergrundwissen über Dialogsummarisierung vor, die als Teil der Textsummarisierung betrachtet wird. Es gibt viele Szenarien in Dialogsummarisierung. Wie man in verschiedenen Domänen wichtige Informationen aus Dialogen extrahiert, ist wertvoll und lohnenswert zu erforschen. In den letzten Jahren wurden große Fortschritte in Dialogsummarisierung erzielt, insbesondere mit Hilfe großer prätrainierter Sprachmodelle. Trotzdem haben diese Modelle noch Fehler, wie zum Beispiel Faktenfehler, die die Qualität beeinträchtigen. Omission ist ein Hauptfaktor. Es gibt nur wenige Arbeiten, die dieses Problem systematisch analysieren. Yicheng hat die Omissionrate von Summenfassungen aus fünf Domänen und sechs prätrainierten Modellen untersucht. Er findet, dass sogar die besten Modelle eine hohe Omissionrate haben. Um das Omissionproblem besser zu analysieren</sample>
    <sample id="147">An der Arbeit sind drei Autoren beteiligt.</sample>
    <sample id="148">Hallo Sara Papi von der Universität von Trient und der Fondazione Bruno Kessler. Ich werde kurz das Papier "Achtung als Leitfaden für die gleichzeitige Sprachübersetzung" vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist. Was ist gleichzeitige Sprachübersetzung? Gleichzeitige Sprachübersetzung, oder SimulST, ist der Prozess, den gesprochenen Sprache in Echtzeit in eine andere Sprache in Textform zu übersetzen, um interkulturelle Kommunikation zu ermöglichen. Und welche Probleme haben die aktuellen SimulST-Modelle? Spezifische Architekturen werden normalerweise trainiert, wobei zusätzliche Module optimiert werden müssen. Längere und komplizierte Trainingsprozesse, zum Beispiel Trainingsprozesse mit verschiedenen Optimierungszielen. Und das Trainieren und Warten mehrerer Modelle, um verschiedene Latenzregime zu erreichen. Zum Beispiel das Trainieren eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines anderen Modells mit einer</sample>
    <sample id="149">Ja, der Datensatz ist öffentlich zugänglich. Wenn du mehr darüber wissen möchtest, kannst du mich kontaktieren.</sample>
    <sample id="150">Archiki präsentiert das Paper "MEETINGQA: Extractive Question-Answering on Meeting Transcripts". Es geht um die Herausforderungen und Möglichkeiten von Meetingtranskripten für NLP. Die Meetingtranskripte sind lang, domänenspezifisch und informativ. Viele bisherige Arbeiten konzentrieren sich auf Zusammenfassung und Extraktion von Aktionselementen. Das Team hat MeetingQA, ein neues Dataset für extrahierendes Q&amp;A, erstellt. Es enthält Fragen und Antworten aus Meetingtranskripten. Die Daten wurden aus öffentlichen Meetingtranskripten des AMI-Korpus gesammelt. Es gibt eine hohe Inter-Annotator-Konsistenz. MeetingQA hat 7.700 Fragen, 30% davon sind unbeantwortbar. Die Fragen sind meistens in "Ja/Nein"-Formulierung und erfordern detaillierte Antworten. Es gibt auch rhetorische Fragen. Die Modelle haben auf dem Testset einen hohen F1-Wert von 84,6. Es gibt Unterschiede zwischen kurzen und langen Kontextmodellen</sample>
    <sample id="151">Hallo alle zusammen, mein Name ist Ying und mein Kollege Zhiyang und wir werden unsere Forschung über MultiInstruct präsentieren, die Multi-Modal Zero-Shot-Learning durch Anweisungstuning verbessert. Mit dem Fortschritt großer Sprachmodelle haben viele Arbeiten neue Lernparadigmen erforscht, um prätrainierte Sprachmodelle für verschiedene unterstromige Aufgaben in einer parameter- und dateneffizienten Weise zu nutzen. Kürzlich haben viele Studien gezeigt, dass Anweisungstuning große Sprachmodelle ermöglicht, auf unbekannte Aufgaben in einem zero-shot-Mass zu performieren, indem sie natürliche Anweisungen folgen. Allerdings haben die meisten bisherigen Arbeiten über Anweisungstuning sich auf die Verbesserung der zero-shot-Performance auf Sprachnur-Aufgaben konzentriert, während Computer Vision und Multi-Modal-Aufgaben ausgelassen wurden. Daher wollen wir untersuchen, ob das Anweisungstuning von Multi-Modal-Prätrainingsmodellen tatsächlich die Allgemeingültigkeit für unbekannte Multi-Modal-Aufgaben</sample>
    <sample id="152">Frederick Riemenschneider präsentiert die Verbindung von NLP und klassischer Philologie. Er führt nützliche Ressourcen für Altgriechisch und Latein ein. Er diskutiert die Implikationen und Herausforderungen der Multilinguistischen Modelle. Er stellt die Entwicklung neuer Sprachmodelle für klassische Philologie vor, die monolinguale und multilinguale Modelle umfassen. Er beschreibt die Herangehensweise bei der Datensammlung, insbesondere für das Internet-Archiv. Er erläutert die Benchmarking -Verfahren für die Modelle und zeigt, dass sie die aktuellen State -of -the -Art -Modelle für Altgriechisch und Latein übertrumpfen. Er untersucht auch, wie T5 -Encoder funktionieren und die Auswirkungen der Multilinguistischen Modelle. Er schließt mit einer kurzen Zusammenfassung seiner Arbeit und verweist auf seine Papier für weitere Details.</sample>
    <sample id="153">Ninareh Mehrabi, a postdoc at Amazon Alexa AI's Responsible AI team, presented their work on resolving ambiguities in text-to-image generative models. They studied ambiguous prompts like "The girl enters the room with flowers" and aimed to propose frameworks to mitigate ambiguities and evaluate faithful image generation. Their pipeline involved curating a benchmark dataset, using a language model for clarifying questions or generating visual setups, and then evaluating the generated images with a VQA model. Findings showed positive effects of disambiguation and agreement between automatic and human evaluations. For more details, refer to their paper.</sample>
    <sample id="154">Die Autoren gehören der University of Trento an.</sample>
    <sample id="155">Javad Hosseini</sample>
    <sample id="157">Shen Gao from Shandong University introduces their work "Dialogue Summarization with Static-Dynamic Structure Fusion Graph". It aims to distill salient info from a dialogue into a concise summary. Existing methods mainly use pre-computed static graph structures but have drawbacks like relying on unreliable external tools and not adapting dynamically. Their SDDS model has four components: Utterance Encoder, Static-Dynamic Graph module, and Summary Generator. They use four heuristic methods for dialogue structure modeling, like Discourse Parsing Graph and speaker relationship modeling. For capturing utterance position, they use relative distance. To integrate static and dynamic graphs, they propose a fusion method. The code and data are on GitHub.</sample>
    <sample id="158">The speaker introduces the task of coreference resolution, which is to link mentions of the same entity in a document. Conventional methods have quadratic complexity, while cache-based methods reduce it to linear. However, LRU eviction in long documents with topic switches leads to high cache misses. The speaker proposes a dual cache with a local cache using LRU and a global cache using LFU. The model classifies mentions and adds them to the appropriate cache based on frequency. Evaluation on benchmarks shows dual cache outperforms single cache methods, reducing cache misses and having a higher performance/cost ratio.</sample>
    <sample id="159">Hallo, ich bin Koustav Sinha, und ich freue mich, euch zu unserer Diskussion über unser ACL 2023-Papier willkommen zu heißen. Sprachmodellakzeptanzurteile sind nicht immer robust gegenüber Kontext. Dies ist ein gemeinsames Projekt mit John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy und Adina Williams. In diesem Papier überarbeiten wir die minimalen-Paar-Paradigmen. Die minimalen-Paar-Paradigmen bewerten Sprachmodelle anhand von Akzeptanzurteilen. Dies kann auch Grammatikalität wie BLiMP, SyntaxGym oder Akzeptanz in Bezug auf Stereotypen wie CrowS-Paare umfassen. In dieser minimalen-Paar-Paradigma wird die typische Art, Sprachmodelle zu evaluieren, dass man einen akzeptablen Satz oder einen grammatischen Satz zeigt und dann einen akzeptablen Satz oder einen ungrammatischen Satz zeigt. Man hofft, dass das Modell mehr Wahrscheinlichkeit dem akzeptablen Satz zuweist. Die</sample>
    <sample id="160">Im ersten Schritt der Methode werden die Input-Token mit einem unordentlichen Multisatz von Tokens zugeordnet, die im Output vorkommen werden.</sample>
    <sample id="161">In CoScript sind insgesamt 55.000 Skripte vertreten. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="163">Die beste Ausrichtungsmethode für DEplain ist die Methode von MASSalign.</sample>
    <sample id="164">Schwach überwachtes Lernen ist günstiger als manuell beschriftetes Daten. Es ist aber auch lautiger, also enthält es einige falsch beschriftete Daten. Wenn man direkt mit neuronalen Netzen auf schwach beschrifteten Daten trainiert, tendieren diese dazu, das Label-Rauschen zu merken und nicht gut zu generalisieren.</sample>
    <sample id="165">The speaker, Wenting Zhao, presents a paper on abductive commonsense reasoning. They start with an example of Emily stuck in traffic and making it to her flight, with explanations like her flight being delayed or on time. The goal is to find a plausible explanation. Their paper introduces LiPoR, an unsupervised method for abductive reasoning. It treats explanations as a latent variable and maximizes the marginal likelihood of the outcome given the context. A regularizer is added to prefer plausible explanations based on mutual exclusivity. LiPoR outperforms other models on the AlphaNLI dataset. You can find the paper at tinyurl.com/zhao-lipor.</sample>
    <sample id="166">Yunxin from Harbin Institute of Technology, Shenzhen introduces a new work on image retrieval from linguistically complex text. This task is challenging due to highly similar images and long descriptions. Typical methods like visual language models perform well on image sentence retrieval but drop on complex text. Inspired by Divide-and-Conquer and Dual-Process Theory, a Neural Divide-and-Conquer Reasoning Framework, NDCR, is proposed. It uses a Proposition Generator for decomposing complex text into simple propositions. System 1, Visual-Linguistic Interactor, performs visual-proposition interaction. System 2, Neural-Symbolic Reasoner, integrates reasoning states and results. NDCR combines System 1 and 2 to handle complex reasoning. Experimental results show NDCR outperforms baselines. It also verifies the effectiveness of each module through abolition experiments. Two cases demonstrate the method's interoperability. Suggestions include exploring neural symbolic calculation for compositional reasoning and integrating Dual-Process Theory with Divide-and-Conquer.</sample>
    <sample id="167">In DEPLAIN-web wurden 750 Dokumente ausgerichtet. 450 davon wurden manuell und 300 automatisch ausgerichtet.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde aus Reuters News von 2020 gesammelt und dann mit den gleichen CoNLL-2003-Annotationsempfehlungen annotiert.</sample>
    <sample id="169">David Vilar und seine Kollegen präsentieren eine Studie über die Prompting-Strategien für PaLM, einen 540 Milliarden Parameter großen Sprachmodell. PaLM wurde 2022 vorgestellt und trainiert auf 780 Milliarden Tokens. Es erreichte damals State-of -the -Art in vielen NLP -Aufgaben.Die Studie ist die erste systematische Untersuchung von Prompting für Maschinentranslation. Sie vergleicht PaLM mit dem besten System, WMT, und verwendet state -of -the -art -MT -Metriken sowie Expertenbewertungen. Ein Experiment zeigt, dass ein Prompting -Unterschied von mehr als einer BLEURT -Punkte ausmachen kann. Ein 5 -Shot -Prompting -Strategie, bei der jede Satz mit seiner Sprache markiert wird, wurde gewählt. Die Ergebnisse zeigen, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Quellsatz. PaLM erreicht eine vergleichbare Fluenzität wie State -of -the -art -Systeme, aber mit weniger Genauigkeit. Omission -Fehler</sample>
    <sample id="170">Hallo alle zusammen, mein Name ist Yusen Zhang von der Penn State University. Heute werde ich unsere Arbeit "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations" präsentieren. So, das Semantische Parsing ist eine Aufgabe, um semantische Darstellungen von Benutzeranfragen wie SQL und Lambda Calculus zu erstellen. Und das Cross-Lingual Semantic Parsing ist die Aufgabe, Anfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsdarstellungen zu übersetzen. Wie in diesem Bild gezeigt, müssen wir die Anfrage in mehreren natürlichen Sprachen mit neuronalen Modellen in SQL, Lambda oder FunQL usw. übersetzen. Die bestehenden Cross-Lingual Semantic Parsing-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen bewertet. Zum Beispiel gibt es viel Abdeckung für bestimmte natürliche Sprachen. Aber Chinesisch fehlt und es gibt eine geringe Abdeckung für bestimmte Bedeutungsdarstellungen. Das Lambda-Calculus fehlt, oder sie</sample>
    <sample id="171">Es gibt bereits Arbeiten, die gezeigt haben, dass Angreifer das Modell durch das Lernen von Embedding stehlen können und ähnliche Dienste bereitstellen können. Diese Arbeiten haben gezeigt, dass es notwendig ist, die Urheberrechte von Embedding als Dienstleistung zu schützen.</sample>
    <sample id="172">No, they are still inadequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="174">Thea, co-author of "ArgAnalysis35K", explains why this dataset is unique. It's the largest with 35K argument-analysis pairs, mostly from high-quality sources. It has diverse arguments based on 24 themes, not pre-selected motions. It introduces analysis as a coherent thing explaining arguments better. It uses instance-based annotator reliability to better utilize annotations. And it has a relevance model to score arguments' relevance to themes. This makes it more diverse, relevant, and reliable. Check out the paper and poster for more details.</sample>
    <sample id="175">Die Methode umgeht die Mehrdeutigkeit der Permutationen, indem sie die beste Permutation mit einer GPU - freundlichen kontinuierlichen Relaxierung annähernd berechnet. Diese Relaxierung ermöglicht es auch, durch die Lösung zurückzubrechen und sprachlich plausiblere Permutationen zu lernen. Wenn du mehr darüber erfahren möchtest, schau doch mal in unserem Papier oder komm zu unserem Poster.</sample>
    <sample id="176">Nicht klar definiert. Es gibt keine klare Definition für die Fairness eines nachgeschalteten NLP-Modells im gegebenen Inhalt.</sample>
    <sample id="177">Yanis Labrak.</sample>
    <sample id="178">Koustav Sinha.</sample>
    <sample id="179">The paper presents SymbolicToM, a method to improve Theory of Mind reasoning in large language models. It uses graphical representations for mental state tracking. It compares against supervised models like fine-tuned GPT-3 and Textual Time Travel. SymbolicToM shows performance gains across various datasets, especially in out-of-domain and linguistic diversity scenarios. It avoids overfitting and provides more interpretable reasoning. For more details, refer to the paper.</sample>
    <sample id="180">Myra.</sample>
    <sample id="181">Abstract: This paper addresses constrained language planning, focusing on goals with specific constraints. It evaluates large language models' ability in this area and proposes an over - generate - then - filter method. The authors create a dataset, CoScript, for constrained language planning using large language models. They find that smaller models like T5 fine - tuned on CoScript can generate higher - quality scripts than most large models. The CoScript dataset is valuable for advancing research on language planning.</sample>
    <sample id="182">Tropikalismus bezieht sich auf eine Troppe, die besonders für Frauen von Farbe charakteristisch ist. Es wird durch Wörter wie "vibrant" und "curvaceous" beschrieben, was eine Verbindung zur Tropik herstellt und dazu beiträgt, dass diese Gruppe als anders definiert wird. Es ist eine negative Struktur, die zu Diskriminierung und Abtrennung führt. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="183">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen erstellt, indem sie den Menschen bestimmte Anweisungen gegeben haben, wie zum Beispiel "Stell dir vor, du bist eine asiatische Frau. Beschreib dich selbst."</sample>
    <sample id="184">In dieser Arbeit wurde Pointwise CXMI zur Messung der Kontextnutzung verwendet.</sample>
    <sample id="185">DrBERT ist ein Modell, das auf RoBERTa basiert und auf NACHOS trainiert wurde, einer Datenbank medizinischer Webkrawle. ChuBERT ist ein klinisches Modell, das anonymisierte Daten aus dem Datenlager des Nantes University Hospital verwendet. Also, der Unterschied liegt in der Datenquelle und dem Fokus. DrBERT ist auf medizinische Webkrawle ausgerichtet, während ChuBERT auf klinische Notizen basiert.</sample>
    <sample id="187">Zwei.</sample>
    <sample id="188">Iteratives Transferlernen ist ein Ansatz, bei dem man zuerst von einer verwandten Aufgabe, wie z.B. der Stellungsklassifikation von Debattenaussagen, die Gewichtswerte überträgt. Anschließend wird auf der Zielaufgabe weitertrainiert.</sample>
    <sample id="189">Das Ziel des Datensatzes ist, die Verständnisfähigkeit von Sprachmodellen für indirekte Referenzierungen in der Auswahl von Entitäten zu verbessern.</sample>
    <sample id="190">Ein Angreifer kann Modellparameter über einen EaaS extrahieren, indem er lernen kann von den Embedding und ähnliche Dienste bereitstellt.</sample>
    <sample id="191">Drei. Sara Papi, Matteo Negri und Marco Turchi.</sample>
    <sample id="192">The presentation is about CAME, a confidence-guided adaptive memory efficient optimization method. It addresses the challenge of having fast convergence like traditional methods and low memory usage like memory-efficient methods. NMF is introduced as a basis for memory reduction. Adafactor has errors in deep neural network training, slowing convergence. CAME handles erroneous updates by calculating instability and adjusting momentum. Experiments on BookCorpus, English Wikipedia, and large language models like BERT, GPT-2, and T5 show CAME outperforms Adam and Adafactor in terms of accuracy and memory efficiency. It's especially good for large batch training.</sample>
    <sample id="193">Das ist nicht im Text erwähnt, also kann ich es nicht sagen. Du könntest versuchen, den Text nochmal zu lesen oder die Quelle zu kontaktieren.</sample>
    <sample id="194">Die Autoren gehören an die Carnegie Mellon University und die University of Washington.</sample>
    <sample id="195">Die Arbeit beschreibt das Framework RoHT, Reasoning over Hierarchical Question Decomposition Tree, für erklärbares Fragebeantworten. Es geht darum, komplexe Fragen in eine Hierarchie von Subfragen zu zerlegen und dann über diese Struktur zu gründen. Es gibt zwei Hauptchallenges: die Festlegung der Fragezerlegungsgranularität und das Finden der optimalen Lösung unter verschiedenen Möglichkeiten. RoHT ist ein zweistufiges Framework. Zuerst wird der Hierarchische Fragezerlegungsbäume, HQDT, für eine komplexe Frage erstellt. Anschließend wird probabilistisches Reasoning über den HQDT durchgeführt, um Kenntnisse aus einer Wissensbank und einem Textkorpus zu fusionieren. Die Evaluierung auf zwei Datenbanken zeigt, dass RoHT die Leistung erheblich verbessert. Es ist besonders effektiv, wenn Kenntnisse aus Wissensbanken und Textkorpora kombiniert werden. RoHT hat Vorteile gegenüber anderen Methoden wie TransferNet. Es ist eine innovative Methode für erklärbares Fragebeantworten.</sample>
    <sample id="196">"I saw Bart and Lisa".</sample>
    <sample id="197">The state-of-the-art for dialogue systems is being evaluated using ABC-Eval, a new dimensional approach. It measures rates of thematic errors like ignoring partners, contradicting, hallucinating facts, and violating common sense. It's more reliable and predictive than existing methods.</sample>
    <sample id="198">Weil große Sprachmodelle längere Kontextfenster haben und es wichtig ist, die Modelle in Bezug auf die Akzeptanz über das gesamte Kontextfenster zu bewerten.</sample>
    <sample id="199">Nein, das mehrsprachige Training hat nicht zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt. Stattdessen hat es die Leistung verbessert.</sample>
    <sample id="200">Ja, die Annotatoren kennen die Entität im Voraus.</sample>
    <sample id="201">Die MT-Metriken, die für die Bewertung verwendet wurden, sind BLEURT.</sample>
    <sample id="202">Nicht direkt erwähnt. Es geht mehr um die allgemeine Generalisierung von NER-Taggern. Wenn du mehr Details haben möchtest, frag doch mal nach.</sample>
    <sample id="203">Positionalität ist für NLP wichtig, weil sie die Systematik von Leistungsunterschieden von Technologien zwischen Bevölkerungsgruppen zeigt. Es kann die Entscheidungen von Forschern beeinflussen und die Forschungsergebnisse verändern. Es ist wichtig, weil NLP-Aufgaben zunehmend subjektiv und sozial orientiert werden.</sample>
    <sample id="204">Nicht erwähnt.</sample>
    <sample id="205">Shangbin, ein Doktorand an der University of Washington, präsentiert die Arbeit "Von Prätrainingsdaten zu Sprachmodellen zu Downstream-Aufgaben: Verfolgen der Spuren politischer Biass, die zu unfairen NLP-Modellen führen". Die Sprachmodelle werden an großem Web-Crawl-Datenmaterial trainiert, das politische Nachrichtenmedien gut abdeckt. Das C4 Corpus zeigt, dass New York Times, Los Angeles Times, The Guardian, Huffington Post usw. gut in die Sprachmodelltrainingsdaten aufgenommen werden. Dies hat sowohl Vorteile als auch Nachteile für Sprachmodellanwendungen. Auf der einen Seite können sie aus verschiedenen Perspektiven lernen, was die Demokratie und die Vielfalt von Ideen feiert. Auf der anderen Seite sind diese verschiedenen politischen Meinungen von Natur aus sozial voreingenommen und könnten potenzielle Fairnessprobleme in Downstream-Aufgabenanwendungen verursachen. Sie untersuchen die Verbreitung politischer Biass vom Prätrainingsdatenmaterial über Sprachmodelle zu Downstream-A</sample>
    <sample id="206">Wir verwenden das CE-Modell für das Transferlernen.</sample>
    <sample id="207">Die aktuellen Testsets, die zur Bewertung der PaLM-Fähigkeiten verwendet wurden, um zu vermeiden, dass das Testdatenmaterial mit dem Trainingsdatenmaterial des Sprachmodells überschneidet, waren die besten Praktiken der MT-Gemeinschaft.</sample>
    <sample id="208">Die Autoren haben drei Empfehlungen vorgeschlagen.</sample>
    <sample id="209">Der genaue Gewinn der vorgeschlagenen Methode gegenüber der stärksten Baseline ist nicht direkt angegeben. Es wird erwähnt, dass T5 fine-tuned auf CoScript besser als die meisten großen Sprachmodelle leistet, was darauf hindeutet, dass die Methode eine positive Auswirkung hat. Aber die genaue Größe des Gewinns ist nicht bekannt. Wenn du mehr Details haben möchtest, kannst du das Papier durchsehen.</sample>
    <sample id="210">Shuheng.</sample>
    <sample id="211">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark verwendet werden. Wenn du noch weitere Fragen hast, lass es mich wissen.</sample>
    <sample id="212">In the paper, they experiment with one smaller model, T5 fine-tuned on CoScript.</sample>
    <sample id="213">OFA.</sample>
    <sample id="215">Adam Przepiórkowski spricht über die Abhängigkeitsstruktur von Koordination. Er vergleicht verschiedene Ansätze wie universal dependencies, Igor Mel'čuk's Theorie und die Pragmerichtung. Die asymmetrischen Ansätze heben das erste Konjunkt hervor, während die symmetrischen Ansätze alle Konjunkte gleich behandeln. Seine Arbeit basiert auf dem Prinzip der Abhängigkeitslängenminimierung. Sie zeigt, dass in englischer Sprache direkte Objekte dem Verb nahe sein sollten, aber wenn sie sehr schwer und lang sind, können sie nach einem Adjektiv stehen. Die statistischen Daten aus dem Penn Treebank bestätigen, dass linksliegende Konjunkte tendenziell kürzer sind, wenn der Regulator links ist oder fehlt. Wenn der Regulator rechts ist, verschwindet diese Tendenz. Dieser Vorgang bietet ein Argument gegen asymmetrische Koordinationsstrukturen und für symmetrische Strukturen.</sample>
    <sample id="217">Das Team von Weihao Zeng, Lulu Zhao und Keqing He aus der Beijing University of Posts and Telecommunications hat sich mit der kontrollierten Dialogerzeugung für mehrere Attribute beschäftigt. Sie haben DCG, Disentangled Controllable Generation, vorgestellt, das Attributekonzepte aus gesehenen Werten lernt und durch die disentanglement Loss verschiedene Attributekombinationen trennt. Sie haben auch ein einheitliches referenzloses Evaluierungsframework, MAE, entwickelt, um die Kontrollierbarkeit von Dialogen zu messen. Ihre Modelle basieren auf dem DialoGPT-Framework und verwenden zusammengesetzte Promptmodule. Sie haben experimentell gezeigt, dass DCG die Kontrollierbarkeit und Textgleichheit von Dialogen verbessert. DCG übertrifft andere Baseline-Modelle bei der Kontrollierbarkeit und Textgleichheit von nicht gesehenen Attributekombinationen. Sie haben auch eine Visualisierung der koncatenierten Prompt-Embeddings von drei Attributen mit PCA vorgelegt, um die Fähigkeit des Modells zu demonstrieren, Attributekomb</sample>
    <sample id="218">Ich kann es nicht sagen, da der Text nichts über die Universität der Autoren sagt.</sample>
    <sample id="219">Jia-Huei Ju, ein Forschungsassistent von Academia Sinica, präsentiert die Arbeit "A Compare-and-contrast Multistage Pipeline for Uncovering Financial Signals in Financial Reports". Sie arbeiten mit Yu-Shiang Huang, Cheng-Wei Lin und den Professoren Che Lin und Chuan-Ju Wang. Ihr Ziel ist die Analyse von Finanzberichten, insbesondere des Form 10-K, das eine jährliche Berichterstattung der SEC ist. Sie beobachten, dass viele Wörter in den Berichten ähnlich sind und Inhalte jahresweise variieren. Daraus resultiert die Einführung eines Hervorhebungsauftrags und eines mehrstufigen Pipelines. Sie definieren Referenz-Ziel-Strukturen, wobei Ziel und Referenz die Berichte des Interesses und des Vorjahres sind. Das Ziel des Hervorhebungsauftrags ist, die rationale Wörter der Beziehung zwischen einem gegebenen Paar, T und R, zu finden. Sie teilen den Prozess in Stufen auf: Segmentierung, Relationserkennung, Out-of-Domain und</sample>
    <sample id="220">Stony Brook University.</sample>
    <sample id="221">Leider ist im gegebenen Text nichts über untersuchte Sprachpaare erwähnt. Du könntest aber versuchen, den Originaltext zu überprüfen oder den Autoren direkt zu fragen.</sample>
    <sample id="222">Das Thema dieses Werks ist die Herausforderung und Intervention bei der Domänenanpassung in offenen Frage-Antwort-Szenarien. Es wird ein Beispiel gegeben, wie man eine Frage über die Produktion in den Pflanzen von Narora, Kakrapur und Tarapur beantwortet. Die Retriever- und Reader-Modelle werden auf einer allgemeinen Quelle wie Wikipedia trainiert. Wenn man eine medizinische Frage beantworten möchte, kann Wikipedia nicht ausreichen, da die Domänen oft sehr spärlich sind. Die Autoren untersuchen verschiedene Dateninterventionen, um die allgemeine Anpassungsfähigkeit in offenen Frage-Antwort-Szenarien zu verbessern. Sie identifizieren die Art der Datenverschiebung, die ein neuer Domänenbereich aufweist, und bestimmen, welche Art von Dateninterventionen für eine bestimmte Art der Verschiebung effektiv ist. Sie testen die allgemeine Anpassungsfähigkeit des Quellmodells an sieben Zielpassagen und -datensätze aus sechs verschiedenen Domänen. Sie untersuchen zwei Methoden für die</sample>
    <sample id="223">Shangbin</sample>
    <sample id="224">Die Modelle, die untersucht wurden, sind MASSalign und die beiden mBART Modelle, das long-mBART und das normal base mBART.</sample>
    <sample id="225">Für das Training werden 53 Aufgaben aus 9 Gruppen verwendet, und für die Tests werden 10 Aufgaben aus 3 Gruppen verwendet.</sample>
    <sample id="226">Zwei.</sample>
    <sample id="227">Die aktuelle Forschung auf dem Gebiet von Sprachmodellen hat große Erfolge erzielt, aber es fehlt noch etwas: die grundlegende Sprachverständnis. Dies bedeutet, dass eine natürliche Sprachausdrucks in eine Art Plan oder Programm umgewandelt wird, das in einem spezifischen Umfeld ausgeführt werden kann. Viele Anwendungen wie intelligente Assistenten, semantische Suchen und Anfragen an medizinische Datenbanken in natürlicher Sprache sowie Hausroboter, die natürliche Sprachanweisungen befolgen, erfordern eine solche Umwandlung. Der Grund für die Herausforderung ist, dass die Sprachmodelle während des Vorkontrainings nicht grundiert werden. Die Forschung auf verschiedenen grundlegenden Sprachverständnisaufgaben nutzt Sprachmodelle, um direkt einen Plan zu generieren, was auf die Generationsfähigkeit der Sprachmodelle zurückzuführen ist. Allerdings kann der generierte Plan nicht immer grammatikalisch korrekt oder gültig sein. In unserem Arbeit haben wir einen neuen Rahmen für grundlegendes Sprach</sample>
    <sample id="228">Die Autoren haben Experimente an den Datensätzen AG News, MIND, SST2 und Enron Spam durchgeführt.</sample>
    <sample id="229">Gabriella Skitalinskaya and Henning Wachsmuth present their work on detecting improvable claims for argumentative writing support. They start by explaining the importance of text revision in professional writing, especially in argumentative writing. They introduce two tasks: Suboptimal-Claim detection and Claim Improvement Suggestion. Their work focuses on argumentative text and explores challenges like representativity, model complexity, contextual dependence, and bias. They conclude that revision-based data can be effectively used for these tasks and that contextual information's impact varies. For more details, refer to their paper.</sample>
    <sample id="231">NACHOS ist ein Datensatz von medizinischen Crawledaten aus dem Web, auf dem DrBERT trainiert wurde.</sample>
    <sample id="232">David Vilar.</sample>
    <sample id="233">Simultaneous speech translation, SimulST, translates spoken language into text in real time. Current models have problems like long training procedures and need multiple models for different latencies. The paper proposes EDAtt, Encoder-Decoder Attention, a strategy for SimulST. It uses existing offline ST models without re-training. EDAtt decides to emit partial translations based on attention. It outperforms offline strategies like Wait-k and Local Agreement in terms of translation quality and latency. The paper also provides open source code and models for reproducibility.</sample>
    <sample id="234">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse. Bei einer einfachen Experimente mit einem Shot Prompting und zwei verschiedenen Prompts pro Satz, waren 516 von 1.000 Sätzen besser als die anderen. Die Differenz betrug mehr als eine BLEURT-Punkte und in Extremfällen sogar bis zu 40 BLEURT-Punkte. Es ist also wichtig, eine gute Prompt-Strategie auszuwählen.</sample>
    <sample id="235">Ich habe den englischen Inhalt nicht analysiert. Also kann ich die Frage nicht beantworten. Wenn du mir mehr Informationen über die Autoren oder die Arbeit geben könntest, kann ich versuchen, die Antwort zu finden.</sample>
    <sample id="236">Leider habe ich den genauen Text der 5 Anweisungen der Expert*innen nicht. Du könntest versuchen, den Text des Beitrags zu kopieren und zu suchen, ob es dort die Anweisungen enthält. Oder du kannst mir mehr über die Struktur der Anweisungen sagen, dann kann ich dir vielleicht weiterhelfen.</sample>
    <sample id="237">Die Autoren schlagen vor, ein diagnostisches Test-Suite für die Wissensintegration zu erstellen. Sie haben einen Coreference Resolution Task eingeführt, um die Fähigkeit zu prüfen, Informationen aus verschiedenen Quellen zu nutzen. Sie evaluieren die Daten mit menschlichen Studienteilnehmern und etablierten Coreference Resolution Modellen.</sample>
    <sample id="238">Yebowen Hu präsentiert MeetingBank, ein neues Benchmark-Datensatz für Meeting-Summariertchnologie. Er beschreibt die Herausforderungen bei der Erstellung des Datensatzes, wie die Erstellung hochwertiger Zusammenfassungen und das Finden vertrauenswürdiger Ressourcen. Die Daten umfassen City Council Meetings, Transkripte, Referenzsummen und URLs. Die Daten werden mit Speechmatics API für Transkripte generiert und dann mit Meeting-IDs verknüpft. Es gibt 1.366 Meetings und fast 7.000 Instanzen. Die Summarisierung wird gemessen anhand von Abstraktionsebenen wie Coverage und Density. Bei der Modellbewertung wurden 10 Systeme getestet, darunter BART-Large, Pagasus, Longformer, DialogLM und HMNet. GPT-3 zeigt in der menschlichen Beurteilung die höchsten Gesamtscores, besonders in Fluency und Cohesion, aber in Informativität und Faktualität sind die Ergebnisse weniger beeindruckend. MeetingBank ist</sample>
    <sample id="239">Hallo alle zusammen, mein Name ist David Vilar und ich werde einen kurzen Review des Papiers "Prompting PaLM for Translation: Assessing Strategies and Performance" geben. Dies ist ein gemeinsames Projekt mit meinen Kollegen von Google Translate. PaLM ist ein 540 Milliarden Parameter großer Sprachmodell, das im letzten Jahr 2022 vorgestellt wurde. Es wurde an einer großen Sammlung von Texten, die 780 Milliarden Tokens umfassen, trainiert. Bei der Veröffentlichung erreichte es den besten Stand der Technik in Hunderten von NLP-Aufgaben. In diesem Arbeit präsentieren wir die erste systematische Studie zur Prompting-Technik großer Sprachmodelle für maschinelle Übersetzung. Wir haben die Übersetzungsfähigkeit solcher Modelle unter Verwendung der besten Praktiken der MT-Gemeinschaft evaluiert. Das bedeutet, dass wir die neuesten Testsets verwenden, um eine Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden. Und wir haben uns mit den besten Systemen verglichen</sample>
    <sample id="240">Hallo, ich bin Dawei, ein PhD-Student an der Saarland University in Deutschland. In diesem Video möchte ich unsere jüngste Arbeit "Weaker Than You Think: A Critical Look at Weakly Supervised Learning" präsentieren. Es ist ein gemeinsames Projekt mit Xiaoyu Shen, Marius Mosbach, Andreas Stephan und Dietrich Klakow. Ich möchte mit einer kurzen Einführung zu Weak Supervision und Weakly Supervised Learning beginnen. In Weak Supervision werden die Daten nicht manuell beschriftet. Stattdessen werden die Daten mit Weak Labeling Quellen beschriftet, wie beispielsweise einfache heuristische Regeln, Wissensbanken oder niedrigqualitative Crowdsourcing, wie im rechten Bild gezeigt wird. Im Vergleich zu menschlichen Annotierungen sind die schwächeren Annotierungen viel billiger, aber sie sind auch laut, was bedeutet, dass ein gewisser Teil der Annotierungen falsch ist. Wenn wir neuronale Netze direkt mit schwach beschrifteten Daten trainieren, tendieren die neuronalen Netze dazu, das Label Lärm zu merken und nicht zu generalis</sample>
    <sample id="241">Ethan und seine Kollegen haben ein Papier über die menschenbasierte Bewertung für frühe Falschinformationserkennung geschrieben. Sie haben festgestellt, dass viele automatische Systeme für Falschinformationserkennung auf zwei Punkte nicht rechtzeitig reagieren. Erstens werden diese Systeme oft unrealistisch bewertet, da die Bewertungsdaten nicht live sind und es das Problem von geleaktem Gegenbeweis gibt. Zweitens sind diese Methoden nicht menschenzentriert. Sie haben einen menschenbasierten Evaluierungskader vorgeschlagen, um diese Mängel zu beheben. Ihr System ist end-zu-end und integriert menschliche Rückmeldung. Es hat zwei Hauptkomponenten: die Erkennung von irreführenden Behauptungen und die Überprüfung von Verstößen gegen Regeln. Sie haben auch eine menschenbasierte Workflow-Evaluation durchgeführt. Das System kann 124,2 Verstöße pro Menschendarstellung detektieren. Sie hoffen, dass ihre Arbeit die Entwicklung zukünftiger menschenbasiierter F</sample>
    <sample id="242">Gängige Bewertungsmethoden für Dialogsysteme sind die menschliche Bewertung, wie z.B. das Anfordern, dass menschliche Richter aus zwei Gesprächen wählen, welches besser ist, oder die Bewertung von Gesprächen anhand einer Likert-Skala.</sample>
    <sample id="243">An der Arbeit sind sechs Autoren beteiligt.</sample>
    <sample id="244">Im Beispiel mit Servin und Kea wird das Hintergrundwissen benötigt, dass Servin ein Richter ist und dass Richter in einem Gerichtssaal Entscheidungen treffen.</sample>
    <sample id="245">The work presents a two-step pipeline for finding high-agreement MTurk Workers for summarization. It starts with qualification settings, including pre-task qualifications like location, number of HITs, and HIT Approval Rate. The qualification task tests annotators' ability to evaluate multiple dimensions correctly, categorizing them into gold, silver, bronze, and block. Only gold and silver workers pass. The endurance task assesses capacity for heavy workload. The reference-based task tests general performance on true annotation tasks. The pipeline results in 6% of 200 participants, 4 gold and 8 silver workers. It's a best practice for high-agreement annotations at large scale and lower cost, avoiding resource waste. Limitations include only English summarization on MTurk, non-"panacea" questions, no guarantee of correctness training, and only Google funding.</sample>
    <sample id="246">Ja, der Code ist verfügbar. Er befindet sich auf GitHub.</sample>
    <sample id="247">Jiho Kim von KAIST AI präsentiert das Papier "FACTKG: Fact Verification via Reasoning on Knowledge Graphs". Es gibt bereits Fact-Verification-Datasets wie FEVER und VitaminC, die Wikipedia-Text oder Tabellen als Beweismaterial verwenden. Es gab aber kein Dataset, das Wissensgraphen als Beweismaterial für natürliche Sprachansprüche nutzt. Sie stellen eine neue Aufgabe, die Wissensgraphen-basierte Fact-Verification, vor. Wissensgraphen sind wertvoll, weil man direkt zu den Ansprüchen verbinden kann und eine zuverlässige Reasoning möglich ist. Sie stellen ein neues Dataset, FactKG, vor, das Wissensgraphen aus DBpedia verwendet. Es gibt zwei Labels: SUPPORTED und REFUTED. Es gibt fünf Arten von Reasoning: one-hop, conjunction, existence, multi-hop und negation. Es gibt zwei Arten von Ansprüchen: geschriebene und umgangssprachliche. Es gibt zwei Methoden, um umgangssprachliche Ansprüche zu generieren: einen umgangssprachlichen Stiltransfer-Modell und Vora</sample>
    <sample id="248">Nein, die Annotatoren für NLPositionality sind nicht in Bezug auf jede demographische Gruppe ausgewogen. Es gibt Positionalitäten in NLP, wie z.B. dass Daten und Modelle am meisten mit englischsprachigen Ländern ausgerichtet sind und dass sie sich mit Menschen mit einem College-Abschluss am besten anpassen.</sample>
    <sample id="249">Die Sätze innerhalb der akzeptablen Domain wurden durcheinander gebracht, indem man akzeptable und unakzeptable Sätze aus derselben BLiMP oder SyntaxGym-Datensatz auswählte und dann entweder akzeptable oder unakzeptable Präfixe hinzufügte.</sample>
    <sample id="250">Eine dimensionale Bewertung bedeutet, mehrere Aspekte der Gesprächsqualität zu bewerten, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen.</sample>
    <sample id="251">The authors belong to the University of Science and Technology of China.</sample>
    <sample id="252">Sai Kiran Tanikella präsentiert die Arbeit "U-CREAT: Unsupervised Case Retrieval using Events extrAcT". Es geht um die Herausforderung, relevante Vorgängerbeispiele für Rechtler zu finden, insbesondere bei steigender Fallmenge. Die Arbeit beinhaltet zwei Hauptbeiträge: den IL-PCR-Datensatz und den U-CREAT-Pipeline. Der IL-PCR-Datensatz ist ein neuer Benchmark für Prior Case Retrieval, mit 7.070 legalen Fällen und durchschnittlich 6.775 Zitate pro Anfrage. Die U-CREAT-Pipeline nutzt unüberwachte Lernverfahren und einen ereignsbasierten Ansatz. Sie extrahiert Ereignisse aus Dokumenten mit einer Abhängigkeitsanalyse. Die Event-Extraktion ist entscheidend. Die U-CREAT-Pipeline verwendet drei Schritte: Vorbearbeitung, Abhängigkeitsanalyse und Postbearbeitung. Die Ergebnisse zeigen, dass event-basierte Modelle signifikant besser als andere Modelle sind. U-CREAT ist der</sample>
    <sample id="253">Mario Ezra Aragón präsentiert "DisorBERT", ein Modell zur Erkennung von Zeichen von psychischen Störungen in sozialen Medien. Es handelt sich um eine Gruppenarbeit von Forschern aus Mexiko und Spanien. Ein psychisches Störungssyndrom ist eine psychologische Störung mit Stress und Behinderung, die das Denken, Gefühle, Stimmung und Verhalten beeinträchtigt. Social Media bietet die Möglichkeit zur Untersuchung von Menschen, die mit psychischen Problemen kämpfen. Das Ziel ist, durch automatische Analyse von Posts zu warnen und Beweise für die Entstehung von Störungen zu liefern. Domain Adaptation wird verwendet, um das Modell an einen spezifischen Bereich wie Reddit und psychische Gesundheit anzupassen. Das Modell lernt zuerst die Sprache von Social Media und spezialisiert sich dann auf die Störungsdomäne. Es zeigt bessere Ergebnisse als MentalBERT. In Zukunft soll das Modell mit anderen lexikalischen Ressourcen und klinischem Daten verwendet werden.</sample>
    <sample id="254">Das Forschungsarbeit präsentiert ein Framework für die Dokumentenrelationsextraktion mit unsicherheitsgeleiteter Etikettentönung. Es verwendet DS-Daten und human-annotierte Daten. Zuerst wird ein Modell trainiert, um Pseudoetiketten zu generieren. Dann wird Unsicherheitsabschätzung eingeführt, um zu entscheiden, ob Modelldurchgänge vertrauenswürdig sind. Ein Instanzniveau - Unsicherheitsabschätzungsmethode wird vorgeschlagen, um Unsicherheitswerte für überlappende Beziehungen zu ermitteln. Eine dynamische Klassenunsicherheitsgrenze wird vorgeschlagen, um Pseudoetiketten mit hohem Unsicherheitswert zu filtern. Eine mehrphasige Trainingsstrategie wird entwickelt, um DS-Daten iterativ zu relabeln. Das Framework übertrifft verschiedene Baseline - Modelle auf öffentlichen Datensätzen. Die Hauptbeiträge sind: das Framework mit unsicherheitsgeleiteter Etikettentönung, die Instanzniveau - Unsicherheitsabsch</sample>
    <sample id="255">Die Form des Prompts ist wichtig bei zero and one-shot prompting.</sample>
    <sample id="257">Vier state-of-the-art Chat-Modelle.</sample>
    <sample id="258">The speaker, Chiang Cheng-Han, introduces a new work on using large language models for evaluating text quality in natural language processing. They propose instructing large language models to rate samples based on natural language instructions. This is novel as no prior work explored this idea. The motivation is to find an alternative to human evaluation, which is unstable and hard to reproduce. They conduct an experiment rating stories generated by GPT-2 and written by humans on grammar, coherence, likability, and relevance. They use human evaluation results as ground truth. Two large language models, Davinci and ChatGPT, show a clear preference for human-written text, similar to human raters. The speaker encourages viewers to read the paper or visit their poster stand at ACL for more details.</sample>
    <sample id="259">Yusen Zhang präsentiert "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations". Es geht um die Übersetzung von Abfragen in verschiedenen Sprachen in verschiedene Bedeutungsrepräsentationen. XSemPLR bietet einen einheitlichen Datensatz für die Übersetzung in verschiedene Sprachen und Bedeutungsrepräsentationen. Es umfasst 9 Datensätze, 5 Semantikabfragen, 8 Bedeutungsrepräsentationen und 22 Sprachen. Es gibt sechs Einstellungen für Training und Evaluierung, wie Translate-Test, Monolingual-Modell, Monolingual Few-shot, Multilingual-Modell, Cross-lingual Zero-shot und Few-shot Transfer. Encoder-Decoder-Modelle zeigen die besten Ergebnisse auf allen neun Datensätzen. Es gibt interessante Ergebnisse wie die Verbesserung durch Mischung von Sprachen und die Bedeutung von Few-shot Transfer. XSemPLR ist ein einheitliches Benchmark für die Übersetzung in verschiedene Sprachen und Bedeutungsrepräsentationen.</sample>
    <sample id="260">Nur ein Autor ist an der Arbeit beteiligt.</sample>
    <sample id="261">Ein guter Planer sollte sinnvoll und den Bedingungen entsprechend schreiben.</sample>
    <sample id="262">Ich kann es leider nicht sagen, da der englischen Inhalt nicht genügend Informationen enthält, um die Anzahl der Autoren zu bestimmen. Wenn du mehr Details hast, kann ich dir gerne weiterhelfen.</sample>
    <sample id="263">Das Papier untersucht Label-Bias-Probleme in in-context Learning. Es beginnt mit einer Typologie von Label-Biasen und identifiziert eine neue Art, die Domain-Label-Bias. Es wird ein neues Kalibrierungsverfahren vorgeschlagen, um alle Bias-Arten zu behandeln. Domain-Context-Kalibrierung verwendet zufällige in-domain-Wörter aus dem Aufgabenkorpus, um die Effekte der Domain-Label-Bias zu berücksichtigen. Experimente zeigen, dass es die Leistung von in-context Learning signifikant verbessert, insbesondere bei Aufgaben mit großer Domain-Label-Bias. Es wird auch gezeigt, dass das Verfahren für größere Modelle wie GPT-3 wirksam ist. Wenn du mehr erfahren möchtest, kannst du das Papier lesen.</sample>
    <sample id="264">Lin Wang, a Zhejiang University grad student, presents his paper "TAVT: Towards Transferable Audio-Visual Text Generation". He notes that uni-model text gen tasks like machine translation and image captioning have advanced due to large-scale pre-training and big models. However, multimodal tasks like audio-visual text gen face challenges like arduous data annotation and severe degradation due to domain shifts. He proposes Transferable Audio-Visual Text Generation to address these. The main challenge is multi-modal domain shifts. He posits a unified audio semantic space for aligning visual concepts across domains. The framework has three components: an audio-visual meta-mapper network, an encoder and language model generator, and counterfactual contrastive learning. The meta-mapper network maps visual concepts into a unified audio semantic space. The encoder and generator use a transformer-based approach with an alpha to evaluate modality contribution. A Dual Counterfactual Contrastive Learning is proposed for better visual-textual alignment. In experiments, TAVT outperforms SOTA models on cross-datasets and cross-domain settings, especially in low-resource domains. Ablation experiments show the impact of audio features.</sample>
    <sample id="265">Vasudha</sample>
    <sample id="266">I'm not sure which university the authors belong to. You could try looking for more information in the paper or at the poster session.</sample>
    <sample id="268">Omission errors.</sample>
    <sample id="269">Hallo, ich bin James Finch. Und ich bin Sarah Finch. Und heute werden wir Ihnen alles über ABC-Eval erzählen, eine neue dimensionale Herangehensweise zur Bewertung von KonversationskI. Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Jinho Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt. Lassen Sie uns sagen, dass Sie gerade einen Dialogmodell entwickelt haben und Sie möchten sehen, wie gut es im Vergleich zum aktuellen State-of-the-Art steht. Die übliche Praxis ist, Menschenbewertungen zu verwenden, z.B. indem man menschlichen Urteilen fragt, welche von zwei Konversationen besser ist oder Konversationen auf einer Likert-Skala bewertet. Diese Ansätze funktionieren gut, um eine umfassende Bewertung der Gesamtqualität von Dialogen zu ermöglichen, aber Dialogqualität hat viele Aspekte. Daher möchten Sie möglicherweise mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells auf einer feinkörnigeren Ebene zu verstehen. Eine Möglichkeit ist, einfach mensch</sample>
    <sample id="270">Die Autoren gehören an die Emory University.</sample>
    <sample id="271">CFT steht für Continuous Fine-Tuning.</sample>
    <sample id="272">An der Arbeit sind sechs Autoren beteiligt.</sample>
    <sample id="273">Hallo, mein Name ist Kayo Yin und ich werde unsere Arbeit präsentieren, die den Titel "Wann erfordert eine Übersetzung Kontext? Eine datenbasierte, multilingualen Erforschung" trägt. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandes, Emmy Liu, André F. T. Martins und Graham Neubig durchgeführt. Also viele Übersetzungen hängen vom Kontext ab. Zum Beispiel, wie würden wir "Mole" in diesem Satz übersetzen? Wenn der vorherige Satz "Dinge könnten gefährlich werden, wenn die Minister es herausfinden" lautet, bezieht sich "Mole" auf einen Spion. Aber wenn der vorherige Satz "Kann es etwas Ernsthaftes sein, Arzt?" lautet, bezieht sich "Mole" auf eine Geburtstätte. So, abhängig vom Kontext, ändert sich die Bedeutung des Wortes, und somit auch seine Übersetzung. Allerdings ist es ziemlich schwierig, zu beurteilen, wie gut Modelle solche Fälle übersetzen können</sample>
    <sample id="274">Yusen Zhang.</sample>
    <sample id="276">Ananya und Vignesh präsentieren ihre Arbeit "IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation Metrics for Indian Languages". Sie konzentrieren sich auf die Bewertung von Übersetzungsmodellen für indische Sprachen, insbesondere Dravidische und Indo-Arische Sprachen. Sie verwenden den Flores-Datensatz und sieben Übersetzungsmodelle, um 1.400 Kandidatentexte pro Sprache zu generieren. Bilingual Experten bewerten die Übersetzungen detailliert, markieren Fehler und geben eine Gesamtschätzung. Sie untersuchen verschiedene Bewertungsmethoden, wie chrF, LabSE, BERTscore und COMET, und finden heraus, dass COMET die besten Ergebnisse auf allen Sprachen zeigt. IndicCOMET MQM übertrifft die COMET-Basismethoden auf drei Sprachen und ist insgesamt robust. Sie laden ihre öffentlich verfügbare Datensatz zur Verfügung.</sample>
    <sample id="277">Die neue Methode hat den Namen "Multiset Tagging and Latent Permutations".</sample>
    <sample id="278">The authors describe the "marked words" method as a way to identify words that distinguish marked groups from unmarked ones. It draws on the sociolinguistic concept of "markedness", where dominant groups are unmarked and marginalized groups are marked. They first designate what the unmarked and marked groups are, then compare the personas using the Fightin' Words method, which uses weighted log-odds ratios to distinguish the top words for each marked group.</sample>
    <sample id="279">Die Autoren gehören an der University of Washington.</sample>
    <sample id="280">Shi Tao präsentiert sein Werk "MultiEMO: Ein Aufmerksamkeitsbasiertes Correlation-bewusstes Multimodal-Fusion-Framework für Emotionserkennung in Gesprächen". Er stellt die Aufgabe der Emotionseinstellung in Gesprächen vor, die die emotionale Etikettierung jeder Redezeile im Dialog vorhersagen soll. Die Arbeit identifiziert Herausforderungen wie die unternutzte Komplementarität der multimodalen Informationen, die schlechte Leistung bei Minderheitsemotionen und die Schwierigkeit, semantisch ähnliche Emotionen zu unterscheiden. Das vorgeschlagene MultiEMO-Framework besteht aus vier Komponenten: unimodaler Merkmalsextraktion, Kontextmodellierung, multimodaler Fusion und Emotionsklassifikation. Es beinhaltet einen neuen visuellen Merkmalsextraktor, MultiAttn, ein Fusionsmodell, und eine gewichtete Fokussierungskontrastverlustfunktion. Experimente auf MELD und IEMOCAP zeigen, dass MultiEMO die besten Ergebnisse erzielt.</sample>
    <sample id="281">Kayo Yin and colleagues present a study on when translation needs context. They use CXMI and its extension, Pointwise CXMI, to measure context usage. Analyzing TED talk transcripts, they find patterns in words requiring context, like dual pronouns in Arabic and formality in Chinese. They create a MuDA tagger for discourse phenomena. Using this, they evaluate models on document - level translation. Context - aware models perform better on some phenomena but not others. DeepL is more accurate than Google Translate for document - level. This study helps identify discourse phenomena models handle well and which translation systems are good at document - level.</sample>
    <sample id="282">Xuekai Zhu presents "StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing" at ACL 2023. This work focuses on story-level style transfer, a step forward from token or sentence level. The main challenge is imitating author's discourse-level linguistic choices and content association with writing topics. StoryTrans, the proposed model, learns discourse representations and combines them with style embeddings. It uses a two-stage training framework. The first stage uses self-reconstruction and disentanglement losses for style and content separation. The second stage fills in style-specific content. Extensive experiments on Chinese and English datasets show StoryTrans outperforms baselines in style control and content preservation. It can enrich storylines and rewrite sentences while maintaining source semantics. Data and code are included in the repo.</sample>
    <sample id="283">Prague</sample>
    <sample id="284">Peng Tianshuo from Wuhan University presented a paper on ACL's Main Conference 4,915. The paper discusses FSUIE, a novel fuzzy span mechanism for enhancing universal information extraction. It addresses the overreliance on precise span boundaries in current span-based UIE models and proposes a fuzzy span boundary. This avoids ambiguity in labeling golden span boundaries. FSUIE also addresses the mismatch between transformer feature extraction and information extraction by proposing adaptive attention for span extraction. It uses a fuzzy span attention as a mask function to trim attention distribution. Experiments on named entity recognition, relationship extraction, and aspect sentiment triplet extraction show that FSUIE achieves significant performance improvements. It demonstrates strong generalization capabilities and competitive performance in various information extraction tasks. The ablation study shows that FSA and FSL contribute to better convergence speed and information extraction capability. Overall, FSUIE achieves excellent results in a wide range of information extraction tasks.</sample>
    <sample id="285">Mingqi Gao von der Peking University präsentiert ihre Arbeit "Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with Fine-grained Evaluation Framework". Sie diskutieren zwei Hauptlösungen für Faktualfehler in Summarisierungen: Einführung von Faktualitätsobjektiven in die Trainings- oder Inferenzphase und die Entwicklung unabhängiger FEC-Modelle. FEC-Modelle werden bisher mit Faktualitätsmetriken wie FactCC und DAE bewertet, was jedoch Schwächen hat. Die Autoren schlagen vor, manuell annotierte Referenzkorrekturen einzuführen, um die Bewertung zu verbessern und die FEC-Modelle effektiver zu trainieren. Sie haben eine neue Taxonomie für Faktualfehler entwickelt und einen Evaluierungsrahmen auf ERRANT basiert aufgebaut. Ihre Ergebnisse zeigen, dass FEC-Modelle mit Referenzsummen aus Dialogsummarisierungsdatensätzen die besten Ergebnisse erzielen. Es gibt dringend die Notwendigkeit, die Bewertungsmethoden für FEC-Modelle zu ändern.</sample>
    <sample id="286">James Finch und Sarah Finch.</sample>
    <sample id="287">An der Arbeit sind fünf Autoren beteiligt.</sample>
    <sample id="288">BLiMP und SyntaxGym.</sample>
    <sample id="290">Ich habe den englischen Inhalt nicht verstanden. Könntest du bitte noch einmal klarer formulieren, was du wissen möchtest?</sample>
    <sample id="291">Named entity recognition, classification, part-of-speech tagging und question answering.</sample>
    <sample id="294">CamemBERT wurde ursprünglich mit anonymisierten Daten aus dem Datensatz NACHOS trainiert.</sample>
    <sample id="295">Adam Przepiórkowski.</sample>
    <sample id="296">Valerio Basile präsentiert eine Arbeit, die aus einer Zusammenarbeit zwischen der Universität Turin und Amazon Alexa stammt. Es geht um Natural Language Understanding und -Processing. Sie brauchen viel Daten, insbesondere manuell annotierte Daten. Die Arbeit konzentriert sich auf Ironie, eine schwierige Aufgabe für moderne NLP-Modelle. Sie entwickelten das EPIC-Korpus, um Ironie zu studieren. Daten wurden von Social Media, Reddit und Twitter gesammelt. Es gibt 300 kurze Konversationen in fünf englischen Varietäten. Annotatoren aus verschiedenen Gruppen haben die Daten annotiert. Es gibt Unterschiede in der Inter-Annotator-Übereinstimmung. Perspektivbewusste Modelle zeigen weniger Unsicherheit. Es gibt auch Unterschiede in der Alters- und geografischen Verteilung der Annotatoren. Wenn Sie Fragen haben, freuen wir uns auf eine Diskussion.</sample>
    <sample id="297">Das Projekt beschäftigt sich mit "Dogwhistles" in politischen Reden. Es gibt eine Typologie und ein Glossar mit über 340 Begriffen und Symbolen, insbesondere für rassistische, transphobische und antisemitische Dogwhistles. Die Register, Persönlichkeit und Typen der Dogwhistles werden charakterisiert. Ein Fallstudie untersucht die Häufigkeit von Dogwhistles in historischen US-amerikanischen politischen Reden und zeigt, dass sie mit der Republikanischen Südstaatsstrategie korreliert sind. Experimente mit GPT-3 zeigen, dass es Dogwhistles in der Glossar aufspüren kann, aber die Leistung variiert. Dogwhistles können auch die Toxizitätsdetektion umgehen, indem sie standardgruppenbezogene Bezeichnungen durch Dogwhistles ersetzen. Zusammenfassend entwickelt das Projekt eine Typologie und ein Glossar, führt eine Fallstudie zu Dogwhistle-Frequenz und politischen Reden durch und untersucht Dogwhistle-erkennung und -moderation.</sample>
    <sample id="298">Die Ergebnisse einer Experimente, bei denen Modelle mit neueren Daten weitertrainiert wurden, zeigten, dass die Leistung mit größerem zeitlichen Abstand zwischen Trainings- und Testdaten abnimmt. Dies bestätigt die Hypothese, dass die Hauptursache für den Leistungsverlust die zeitliche Verzögerung ist.</sample>
    <sample id="299">The work discusses improving NLI model robustness by addressing shortcuts. It shows that NLI models rely on shortcuts, which are spurious correlations. These shortcuts make models perform well on in - distribution but not on out - of - distribution. The proposed minimax training method aims to reduce reliance on shortcuts. It focuses on hard examples that counteract dominant easy examples. The method uses a feed - forward network for the auxiliary and is evaluated on MNLI, FEVER, and QQP datasets. It outperforms ERM training and shortcut mitigation methods in out - of - distribution performance. The work also explores if improvements transfer to larger models, synthetic shortcuts, and out - of - domain test sets.</sample>
    <sample id="300">Interactive dictation ist ein Prozess, bei dem Benutzer mit ihrer Stimme sowohl Dokumente zu dictieren als auch zu bearbeiten können. Es wurde von Semantic Machines in Zusammenarbeit mit Jason Eisner, Adam Pauls und Sam Thomson entwickelt. Es ermöglicht, dass Benutzer Fehler korrigieren können, indem sie sich selbst korrigieren, und dass der System diese Korrekturen erkennt und anwendet. Die Arbeit formaliert das Task als einen vierstufigen Prozess: Erste Schritt ist die Erkennung des Sprachtranskripts durch ein ASR-Modul, dann wird das Transkript in separate Dictation - und Befehlsutterances unterteilt, die Befehle werden extrahiert und normalisiert, und die ASR -Fehlern und Sprachfehler werden behoben. Jede Dictation - und Befehlsutterance wird dann in Reihenfolge ausgeführt. Die Arbeit sammelt Daten mit einem neuen Annotation -Interface und baut einen Basissystem auf, das die vier Schritte ausführt. Es trainiert separate Modelle für jede Schritt. Es gibt eine</sample>
    <sample id="302">Weil die Token für die Ausgabesequenz nicht in der richtigen Reihenfolge angeordnet sind, nachdem sie im ersten Schritt mit einem unordentlichen Multisatz von Tokens versehen wurden.</sample>
    <sample id="303">Die Autoren empfehlen, dass Modellentwickler*innen ihre Methoden transparenter machen sollten, weil es so möglich ist, die Ursachen für positive Stereotypen und essentielle Erzählungen zu untersuchen. Ohne Transparenz können wir nicht übernehmen, ob positive Stereotypen auf eine übertriebene Wertorientierung oder andere Anti-Stereotypen-Methoden zurückzuführen sind.</sample>
    <sample id="304">Inacceptable Minimalpaareingaben sind solche, die nicht akzeptabel sind. Sie können beispielsweise aus dem BLiMP-Datensatz stammen, wie in der Adjunct Island-Fall. Wenn man unakzeptable Sätze aus dem gleichen Matching oder aus einer anderen Datenbank wählt, kann das auch verwendet werden, um die Modelle akzeptierbarkeit zu testen.</sample>
    <sample id="305">Dawei, ein PhD-Student an der Saarland University in Deutschland, präsentiert sein neuestes Werk "Weaker Than You Think: A Critical Look at Weakly Supervised Learning". Zusammen mit Xiaoyu Shen, Marius Mosbach, Andreas Stephan und Dietrich Klakow geht es um die Herausforderungen bei der Verwendung von schwach überwachten Daten. Schwach überwachte Daten werden nicht manuell beschriftet, sondern mit einfachen Regeln, Wissensbanken oder Crowdsourcing. Diese sind billiger, aber auch ungenau. Wenn man direkt mit diesen Daten neuralen Netzwerken trainiert, lernen sie die Lärmmerkmale und generalisieren nicht gut. In der schwach überwachten Lernen werden Trainingsalgorithmen vorgeschlagen, um robust gegen Lärmmerkmale zu sein. Ein häufiger Anspruch ist, dass man nur mit schwach überwachten Daten trainiert und gute Ergebnisse auf sauberen Testdatensätzen erzielt. Allerdings ist das falsch, da man zusätzlich saubere Validierungsdaten benötigt. Die Arbeit beantwortet drei Forschungsfragen:</sample>
    <sample id="306">Sebastian Schuster und Najoung Kim geben eine kurze Übersicht über ihre Arbeit zum Entity Tracking in Sprachmodellen. Ein Agent muss entitäten verfolgen und deren Zustandänderungen im Verlauf eines Diskurses verstehen. Zum Beispiel in einem Rezept: Eier, Zucker und Mehl werden in eine Schüssel gelegt und dann zu einer leichten Teigmasse gemischt. Das ist eine wichtige Fähigkeit für das Verstehen längeren Diskurses. Es gibt aber keine systematischen Untersuchungen, was prätrainierte Sprachmodelle in diesem Bereich leisten können. Die Herausforderungen bei der Entwicklung einer Aufgabe zur Beurteilung der Entitätszustandsverfolgungsfähigkeiten sind, dass einige Entitätszustände im Prädtrainsdatenmaterial häufig vorkommen und dass der Modell einfach die korrekten Zustände vorhersagen kann, wenn er nur einfache Heuristiken zwischen Wörtern und Entitätszuständen lernt. Sie haben eine Aufgabe entwickelt, die Boxen und Objekte beinhaltet. Der Modell wird die Anfangsinhalte</sample>
    <sample id="307">Die Autoren haben Named Entity Recognition, Classification, Part-of-Speech Tagging und Question Answering verwendet.</sample>
    <sample id="308">Jenny, eine erste Jahr PhD-Studentin an der Carnegie Mellon University, präsentiert ihre Arbeit "NLPositionality", die die Designbiass von Datensätzen und Modellen charakterisiert. Sie arbeitete mit Leuten aus der University of Washington und dem Allen Institute for AI zusammen. Sie verwenden ein Framework, um die Positionalität von Datensätzen und Modellen zu studieren. Dazu re-annotieren sie Datensätze mit diversen Annotatoren und vergleichen die Annotations mit den Modellen und Datensätzen. Sie finden, dass NLP-Datensätze und -Modelle Positionalität haben, z.B. sind sie am meisten mit englischsprachigen Ländern und Menschen mit College-Abschluss ausgerichtet. Sie empfehlen, alle relevanten Designentscheidungen im Forschungsprozess aufzuzeichnen, NLP-Forschung mit dem Augenmerk auf Perspektivismus durchzuführen und spezielle Datensätze und Modelle für bestimmte Gemeinschaften zu erstellen. Wenn du mehr erfahren möchtest, kannst du unsere Dashboard und unser Papier überprüfen.</sample>
    <sample id="309">Inter-annotator Agreement.</sample>
    <sample id="310">Wikipedia.</sample>
    <sample id="311">Ich habe den englischen Inhalt analysiert, aber es ist nicht klar, an welche Universität die Autoren angehören. Es gibt keine Angaben dazu im Text. Wenn du weitere Informationen hast, kannst du sie mir mitteilen.</sample>
    <sample id="312">MultiInstruct ist der erste große Multi-Modell-Instruction-Tuning-Benchmark-Datensatz. Es besteht aus 62 verschiedenen Multi-Modell-Aufgaben, die 10 breite Kategorien abdecken. Diese Aufgaben stammen aus 21 bestehenden offenen Datensätzen und sind mit fünf Experten geschriebenen Anweisungen ausgestattet.</sample>
    <sample id="313">Zwei. Wenn du noch weitere Fragen hast, lass sie gerne stehen.</sample>
    <sample id="314">Binäre Koordination ist eine Art von Koordination, bei der zwei Elemente direkt miteinander verbunden sind. Es gibt verschiedene Ansätze zur Definition, wie zum Beispiel in universal dependencies, wo der erste Konjunkt der Kopf der ganzen Koordinationsstruktur ist. In Igor Mel'čuk's meaning text theory ist das auch so. Im Prague approach wird die Konjunktion als Kopf der Koordinationsstruktur angesehen. In der multi-headed approach in Hudson's Word Grammar sind alle Konjunkte Kopf der Koordinationsstruktur.</sample>
    <sample id="315">Das ist eine interessante Frage, aber leider habe ich im Text nichts über die Länge der verwendeten Prompts in dieser Studie gesagt. Es wäre schön, wenn du mir mehr Informationen geben könntest, damit ich dir eine genaue Antwort geben kann.</sample>
    <sample id="316">Das T5-fine-tuned auf CoScript kann Skripte von höherer Qualität generieren als die meisten großen Sprachmodelle. Das zeigt, dass kleinere Modelle bei richtiger Ausbildung an geeigneten Datensätzen größere Modelle überholen können.</sample>
    <sample id="317">Peng Li from Fudan University presents "CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors". Information extraction aims to extract structured info from unstructured text. Previous models like T5 and GPT-3 use text - to - text pre - training but struggle with structured outputs. CodeIE transforms the task into a code - to - code generation task. For named entity recognition, a function is defined to extract entities. CodeIE outperforms traditional models like UIE and GPT - 3 in few - shot tasks. It has lower perplexity on code format inputs and avoids structural errors. Codex model generally outperforms GPT - 3 in information extraction tasks. Code format prompts improve recall compared to text format prompts. The paper and code are publicly available.</sample>
    <sample id="318">Hallo, ich bin Yanis Labrak und ich werde Ihnen unsere Arbeiten über "DrBERT: Ein robustes vorkonfizuriertes Modell auf Französisch für biomedizinische und klinische Domänen" vorstellen. In dieser Präsentation sprechen wir zuerst über Sprachmodellierung im Gesundheitswesen. Dann werden wir die Hauptbeiträge unseres Artikels vorstellen. Wir stellen das erste biomedizinische Modell auf Französisch vor, DrBERT, das auf RoBERTa basiert und auf NACHOS, einer Datenbank medizinischer Webkrawle, trainiert wurde. Wir haben auch eine Vergleichsanalyse von Modellen mit verschiedenen Vorkonfigurations-Einstellungen und Datenquellen vorgestellt. Anschließend präsentieren wir unsere Ergebnisse an 11 biomedizinischen und klinischen Aufgabenstellungen auf Französisch. Und schließlich geben wir Ihnen am Ende der Experimente Einblicke und verleihen Ihnen mehr Details dazu, wie Sie diese Modelle zugreifen können.Seit seiner Einführung im Jahr 2018 ist B</sample>
    <sample id="319">Die Arbeit untersucht die Lernstrategien von from-scratch-Pre-Training und control Pre-Training.</sample>
    <sample id="320">Der Faktor der Überanpassung, der auf die Wiederverwendung von Tests zurückzuführen ist, ist größer als 1. Das zeigt sich daran, dass jede Einheit der Verbesserung auf CoNLL-03 mehr als eine Einheit der Verbesserung auf CoNLL++ bedeutet. Also gibt es keine Verzögerung der Erträge.</sample>
    <sample id="321">Die Qualität der Vereinfachung wurde beurteilt, indem man die Art der Vereinfachung analysiert hat. So wurde beispielsweise festgestellt, dass Bibeltexte viel stärker vereinfacht werden als Nachrichtentexte oder Texte für Sprachlerner. Es gab auch eine hohe Vielfalt an verschiedenen Vereinfachungstransformationen.</sample>
    <sample id="322">Enrico präsentiert bei ACL 23 über, was ein Text-Klassifikator über Moralität lernt. Er erklärt, dass Moralphilosophie uns hilft, Gut und Böse zu unterscheiden. Moralphilosophie ist grundlegend für unsere Gesellschaften. Moralphilosophie wird in Texten oft als eine Skala zwischen moralisch und unmoralisch betrachtet, aber es ist sehr subjektiv. Moralphilosophie kann in fünf verschiedenen Dimensionen wahrgenommen werden, wie z.B. Gerechtigkeit und Autorität. Enrico und seine Kollegen haben versucht, zu verstehen, wie Sprachmodelle Moralphilosophie in verschiedenen Domänen verstehen. Sie haben einen Datenbestand namens Moral Foundation Twitter Corpus verwendet. Sie haben gezeigt, dass Sprachmodelle die Unterschiede in der Moralphilosophie in verschiedenen Domänen erkennen können. Zum Beispiel haben sie gezeigt, dass Sprachmodelle die Unterschiede in der Moralphilosophie zwischen ALM und BLM erkennen können. Sie warnen aber auch, dass das Verwenden eines einzigen Modells für viele verschiedene Domänen zu F</sample>
    <sample id="323">Yujie Wang von der Shanxi University präsentiert ein Papier mit dem Titel "Dynamic Heterogeneous-Graph Reasoning with Language Models and Knowledge Representation Learning for Commonsense QA". Commonsense QA ist eine herausfordernde Aufgabe, die Maschinen verlangt, Fragen zu beantworten, die auf allgemeines Wissen basieren, um ihre Sprachverständnisfähigkeiten zu testen. Holmes meint, dass Wissen in Sprachmodellen und Wissensbanken gespeichert ist. Viele Arbeiten kombinieren beide Arten von Wissen für Commonsense QA. Allerdings entstehen bei der Subgraph-Retrieval einige unerwünschte Entities. DHLK wird vorgeschlagen, um diese Probleme zu lösen. Es baut auf mehreren Wissensbanken auf und verwendet KRL zur Optimierung. DHLK entfernt subword-basierte Entities, verwendet RoBERTa und Mask Self-Attention zur Codierung und Fügung von QA-Kontexten und Entities. Es dynamisch entfernt relevanzschwache Entities. HKG wird durch TransE optimiert. DHLK verwendet Relation Mask Self-Attention und RMSA</sample>
    <sample id="324">Ja, Sprachmodelle haben unterschiedliche politische Vorurteile. Sie haben verschiedene politische Neigungen und können politische Vorurteile von Trainingsdaten aufnehmen. Zum Beispiel haben GPT-4 die liberalste politische Neigung unter den untersuchten Modellen.</sample>
    <sample id="325">Hallo! Mein Name ist Matthias Lindemann, und heute werde ich Ihnen einen kurzen Einblick in unser Papier über "Kompositionelle Generalisierung ohne Bäume unter Verwendung von Multiset-Tagging und versteckten Permutationen" geben. Dies ist ein gemeinsames Projekt mit meinen Betreuern Alexander Koller und Ivan Titov. Kompositionelle Generalisierung kann als die Fähigkeit eines Lerners verstanden werden, tieferen Rekursion und unerwartete Kombinationen von Phrasen zu handhaben, die während des Trainings einzeln gesehen wurden. Im Kontext des semantischen Parsing könnte die Generalisierung wie folgt aussehen. Wir haben wie gewöhnlich einen Trainingsdatensatz von Utternances. In diesem Fall: "Die Mädchen schliefen." und "Mary wusste, dass die Mädchen schliefen." Diese Utternances sind mit logischen Formen verbunden, die die zentralen Aspekte ihrer Bedeutung darstellen. Im Gegensatz zur standardmäßigen maschinellen Lernbewertung enthält das Testset nicht die gleiche Verteilung, sondern enthält strukture</sample>
    <sample id="326">Cognitive dissonance is two beliefs or actions that are inconsistent. For example, a person says "I know that cigarettes could kill me" and then smokes after a meeting. This inconsistency is dissonance.</sample>
    <sample id="327">Xiao Xu, a third-year PhD student from Harbin Institute of Technology, presents "ManagerTower: Aggregating the Insights of Uni-Modal Experts for Vision-Language Representation Learning" at ACL 2023. This work, done during an internship in the MSRIC group with Intel Cognitive Computing Group support, aims to train a smart AI system understanding both image and text. Vision-Language learning has seen progress with large-scale self-supervised pre-training and transformer-based models. The work proposes ManagerTower, a novel VL modal architecture. It uses RoBERTa and CLIP-ViT base as unimodal encoders. ManagerTower adapts insights from pre-trained unimodal experts at different levels, improving performance, especially on Wikivideo test standard by 39.15%. It outperforms METER and BridgeTower, showing effective exploitation of different levels of universal semantic knowledge. Paper, code, and modals are available on Archive and Github.</sample>
    <sample id="328">GPT-4.</sample>
    <sample id="329">Minghang Zheng from Peking University presents their work on "Generating Structured Pseudo Labels for Noise-resistant Zero-shot Video Sentence Localization". They focus on zero-shot video sentence localization, which aims to find relevant video segments for a given query. Many existing methods require costly manual annotations. Their proposed method uses a pre-trained image caption model to generate complex pseudo-queries and a pre-trained model to measure relevance between frames and queries. They also generate pseudo-events based on event temporal structure and reduce label noise by re-weighting samples and refining labels. Experiments on ActivityNet Captions and Charades-STA show their method outperforms others on most metrics.</sample>
    <sample id="330">Ja, kumulatives Training ist besser als iteratives Training für aktives Lernen.</sample>
    <sample id="331">Sara Papi.</sample>
    <sample id="332">Die Daten für die MuDa-Benchmark stammen von einem parallelen Korpus.</sample>
    <sample id="333">Wenhao from Nanjing University introduces their work "INK: Injecting kNN Knowledge in Nearest Neighbor Machine Translation". They acknowledge collaborators from Shanghai AI Lab, Nanjing University, and the University of Hong Kong. Their work focuses on neural machine translation, aiming to improve the generalization ability of NMT models. They observe that neural networks often induce a non-smooth representation space, leading to poor performance in areas with sparsely dispersed low-frequency tokens. To enhance performance, they propose kNN-MT, which smooths predictions based on nearest neighbors. However, this approach has drawbacks like time-consuming neighbor retrieval and difficulty updating the datastore. To overcome these, they introduce the INK framework. The INK training loop has two steps: extracting kNN knowledge to guide adapter adjustment and updating representations asynchronously. They optimize the adapter with a combined learning objective. Experiments show that INK outperforms state-of-the-art kNN-MT systems, achieving higher BLEU scores with less memory and faster inference.</sample>
    <sample id="335">Matthias Lindemann.</sample>
    <sample id="336">Sprachübergreifender Transfer ist der Prozess, bei dem ein Modell in einem Quellsprachsetting trainiert wird und dann auf eine ZielSprache übertragen wird.</sample>
    <sample id="337">Das Forschungsprojekt "Graph-based Relation Mining for Context-free Out-of-vocabulary Word Embedding Learning" beschäftigt sich mit der Verarbeitung von OOV-Wörtern. Es wird ein neues Ansatz vorgestellt, der sich auf Wortbildung und Assoziation stützt. Ein Wort-Beziehungs-Graph wird entwickelt, um die Bedeutung von OOV-Wörtern zu inferieren. Ein Self-Attention-Netzwerk gibt Attributen an OOV-Nodes. Zwei Ebenen von Graph-Attention-Netzwerken und ein Readout-Block sorgen für eine node- und graph-niveau Repräsentation. Ein einfaches Graph-Convolutional-Netzwerk reicht aus, um die Wortformation zu erfassen. Die Modelle sind in verschiedenen Aufgaben erfolgreicher als Baseline-Modelle. Sie können sowohl statische als auch kontextuelle Modelle in downstream-Aufgaben profitieren. Agglutinative Sprachen sind gut geeignet, fusional Sprachen stellen mehr Herausforderungen dar. English wird durch sinnvolle Wortsegmentierung gut behandelt. Das Modell kann auf andere Sprachen angew</sample>
    <sample id="338">Bingsheng präsentiert die Arbeit "Are Human Explanations Always Helpful?". Es ist ein Zusammenarbeit von Forschern aus Rensselaer Polytechnic Institute, Northeastern University und IBM Research. Die Motivation, verwandte Arbeiten und die drei Hauptbeiträge werden vorgestellt. Die Forscher haben fünf große Datensätze für verschiedene Aufgaben verwendet. Sie haben eine einheitliche Datenstruktur entwickelt und untersucht, wie Erklärungen bei der Feinabstimmung und Inferenz helfen. Sie haben einen neuen Bewertungsmetric namens TREU vorgeschlagen, der die Nützlichkeit von Erklärungen bei der Feinabstimmung berücksichtigt. Ihre Ergebnisse zeigen, dass ihre Metrik die Bewertung von menschengemachten Erklärungen besser als die Simulatabilitätsscore. Sie empfehlen, Forscher in Zukunft ähnliche Qualitätsschecks durchzuführen. Weitere Details finden Sie in der Arbeit.</sample>
    <sample id="339">Die Autoren gehören an der Saarland University in Deutschland.</sample>
    <sample id="340">Kuan-Hao Huang präsentiert ParaAMR, ein großes, syntaktisch vielfältiges Paraphrasendatensatz. Es wird durch AMR-Back-Translation erstellt. Es gibt etwa 15 Millionen Quellsätze und etwa 6,9 Paraphrasen pro Quellsatz. Verglichen mit anderen Back-Translation-Datensätzen generiert ParaAMR meistens syntaktisch vielfältigere Paraphrasen. Es hat ähnliche semantische Ähnlichkeitswerte wie andere Back-Translation-Datensätze, aber höhere syntaktische Diversitätswerte. Es kann für verschiedene NLP-Anwendungen genutzt werden, wie zum Beispiel das Lernen von Satzembeddings, syntaktische Kontrollparaphrasengeneration und Datenverstärkung für Few-Shot-Learning. ParaAMR ist verfügbar unter einer bestimmten Link.</sample>
    <sample id="341">The authors use average lagging and computational aware average lagging.</sample>
    <sample id="342">Hello everyone. My name is Gao Jingsheng. Today I'm going to present our paper, "LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming". This paper was conducted by me, Lian Yixin, Zhou Ziyi, Fu Yuzhuo, and Wang Baoyuan from Shanghai Jiao Tong University and Xiaobing.AI. The paper starts with an introduction to open-domain dialogue, which is a type of conversation between a human and an AI covering various topics without a specific goal. Existing large-scale corpora mainly consist of online chat conversations, mostly text-sourced. However, constructing a large-scale video-sourced dialogue dataset is significant as it is closer to real spoken conversation. The paper then discusses the challenges in existing video-sourced dialogue datasets, such as limited scale due to manual annotations and the lack of large-scale Chinese multi-party dialogue. To address these challenges, the paper proposes a large-scale personalized dialogue dataset called LiveChat. The dataset is constructed in three steps: extracting origin streaming videos from Chinese TikTok, Douyin, extracting audio and transcribing it into utterances, collecting audience comments and constructing dialogues using a reply-to-whom matching method, and collecting persona information for personalized dialogue</sample>
    <sample id="343">Hallo alle zusammen, ich bin Akshatha, und heute präsentieren mein Co-Autor Martin und ich unsere Arbeit "The KITMUS Test: Evaluierend Kenntnisintegration aus mehreren Quellen." Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research. Natürliche Sprachverständnismodelle greifen auf eine Vielzahl von Wissensquellen zurück, wie zum Beispiel das Wissen, das in ihren Parametern enthalten ist, gewöhnlich durch eine Vorkennzeichnung erworben, und das Wissen, das bei der Inferenzzeit in den Eingaben gegeben wird. Neueste Arbeiten in Aufgaben wie Fragebeantwortung zeigen, dass Modelle das Wissen aus der Vorkennzeichnungzeit verwenden können, um die Aufgabe zu lösen. Aber das natürliche Sprachverständnis erfordert oft auch Wissen, das bei der Inferenzzeit bereitgestellt wird. Zum Beispiel in der Satz "John sah den neu gewählten Präsidenten im Fernsehen." Vorkennzeichnungsparameter können Informationen über was Präsidenten tun und was ein Fernseher ist enthalten</sample>
    <sample id="344">Baumbasierte Methoden sind kompliziert und computereinsatzintensiv. Sie erfordern oft formalspezifische Vorverarbeitung der logischen Formen, um Variable-Symbole zu behandeln. Oft müssen spezielle Grammatik-induktion-Procedures verwendet werden.</sample>
    <sample id="345">Das Papier von Matthias Lindemann, Alexander Koller und Ivan Titov beschäftigt sich mit "Compositional Generalization without Trees using Multiset Tagging and Latent Permutations". Es geht um die Fähigkeit von Lernern, tieferen Rekursionen und unerwarteten Kombinationen von Phrasen zu handhaben, die während des Trainings einzeln gesehen wurden. Im Kontext von semantischer Parsing wird auf eine Trainingsdatensatz von Sätzen wie "The girl slept." und "Mary knew that the girl slept." eingegangen. Diese Sätze haben logische Formen, die ihre Bedeutung darstellen. Im Gegensatz zu standardmäßigen maschinellen Lernverfahren, die auf derselben Verteilung wie die Trainingsdaten basieren, enthält das Testset strukturell unerwartete logische Formen. Naive seq2seq Modelle haben Schwierigkeiten mit dieser Art von ausserhalb der Verteilung generischer Fähigkeit und produzieren oft Outputs, die sich vom Input lösen. Ein populärer Ansatz ist, Bäume in die Modelle zu</sample>
    <sample id="346">Ich habe leider keine Informationen über die Universität der Autoren. Du könntest versuchen, das in der Paper zu suchen oder mich zu fragen, ob du weitere Details hast.</sample>
    <sample id="347">Hallo Myra, ich werde den englischen Inhalt ins Deutsche übersetzen. Hier ist die Übersetzung: "Hallo, ich bin Myra und heute werde ich über unser Papier 'Markierte Personas: Verwendung natürlicher Sprachanweisungen zur Messung von Stereotypen in Sprachmodellen' sprechen. Dieses Werk wurde in Zusammenarbeit mit Esin Durmus und Dan Jurafsky durchgeführt. In den letzten Jahren wurde dokumentiert, wie häufig soziale Voreingenommenheit und Stereotypen in großen Sprachmodellen, oder LLMs, vorkommen. Allerdings haben diese Maßnahmen verschiedene Einschränkungen. Sie stützen sich meistens auf von Hand konstruierte Datensätze, die sehr zeitaufwendig zu kuratieren sind, und sie messen normalerweise nur sehr spezifische Stereotypen, was bedeutet, dass sie nicht gut auf andere Demographien oder Kontexte übertragbar sind, oder sie fangen einfach sehr allgemeine breite Assoziationen wie negative Assoziationen mit bestimmten Gruppen ein. Zudem berücks</sample>
    <sample id="348">Das Papier "Marked Personas" untersucht Stereotypen in Sprachmodellen. Es wird mit Esin Durmus und Dan Jurafsky gemacht. Es gibt Probleme mit bestehenden Methoden, die oft nur spezifische Stereotypen messen und nicht gut generalisieren. Die Autoren nutzen neue Anweisungsgestützte Sprachmodelle, um Personas zu generieren, indem sie Anweisungen geben, z.B. "Stell dir eine asiatische Frau vor". Sie identifizieren dann markierte Wörter, die Unterschiede zwischen markierten und unmarkierten Gruppen zeigen. Ergebnisse zeigen, dass generierte Personas mehr Stereotypen enthalten als handgeschriebene. Positive Wörter wie "kulturell", "traditionell" und "stolz" definieren Gruppen nur in Bezug auf ihre Identität und unterscheiden sie vom weißen Norm. Das führt zu einer langen Geschichte von Diskriminierung und Absonderung. Es wird empfohlen, positive Stereotypen und essentielle Erzählungen zu adressieren, ein intersektionaler Ansatz zu verwenden und mehr Transparen</sample>
    <sample id="349">Hallo alle zusammen, mein Name ist Jingwei Yi von der Universität für Wissenschaft und Technologie China. Es ist mir eine Freude, einen kurzen Werbevideo für unser Papier zu präsentieren. Sind Sie mein Modell kopiert? Schutz der Urheberrechte großer Sprachmodelle für die Einbettung als Dienstleistung über Backdoor-Wasserzeichen. Lassen Sie uns zuerst die Hintergrundinformationen zur Einbettung als Dienstleistung vorstellen. Derzeit sind große Sprachmodelle wie GPT, LLAMA, PALM in der natürlichen Sprachverstehung und -generierung außergewöhnlich. Die Einbettung als Dienstleistung ist eine Dienstleistung, die auf großen Sprachmodellen aufgebaut ist, um verschiedene NLP-Aufgaben zu unterstützen. Zum Beispiel bietet OpenAI eine GPT-basierte Einbettungs-API. Allerdings haben kürzliche Arbeiten gezeigt, dass der Angreifer das Modell durch das Lernen aus der Einbettung stehlen kann und ähnliche Dienstleistungen bereitstellt. Daher ist es notwendig,</sample>
    <sample id="350">Hello everyone, welcome to the presentation of our paper, "What’s the Meaning of Superhuman Performance in Today’s NLU?". I'm Simone Tedeschi, and this is a joint work with several renowned researchers. In the last five years, leaderboard-based evaluation has become the de facto standard in NLP, and the main objective became to reach the top spot in popular benchmarks. Systems often achieve human-level or even superhuman performance in such benchmarks, leading to conclusions that some tasks are now solved by these models. However, it's still unclear what it means to outperform humans in tasks involving knowledge, reasoning, and inference. These models are brittle in many ways, like not being able to generalize, suffering from adversarial attacks, relying on spurious patterns, and being over-sensitive to basic perturbations. In this paper, we investigate how reliably leaderboard scores compare models and humans. We analyze two popular benchmarks, SuperGLUE and SQuAD. In SuperGLUE, humans rank 8th, outperformed by systems on 6 out of 10 tasks. The best system outperformed humans by 1.5 points on average. On SQuAD, humans are largely outperformed by systems ranking 16th and</sample>
    <sample id="351">The paper investigates if CoNLL-2003 named entity taggers still work well in 2023. It looks at generalization problems in NER. Models from CoNLL-2003 are used for almost 20 years. The paper develops CoNLL++ dataset from 2020 Reuters News. It fine-tunes over 20 models on CoNLL-03 and CoNLL++. Good generalization needs better model architecture, larger model size, and more fine-tuning examples. Performance drop is mainly due to temporal drift. The conclusion is that CoNLL-2003 taggers still work well in 2023. The paper calls for more research on improving model generalization.</sample>
    <sample id="352">ABC-Eval steht für annotating behaviors in chat. Es ist eine Methode zur präzisen und zuverlässigen Dimensionaler Bewertung von Chatmodellen.</sample>
    <sample id="353">Das Papier "Python Code Generation by Asking Clarification Questions" von Haau-Sing Li et al. befasst sich mit der Codegenerierung und Programmsynthese. Es geht um die Herausforderung der Input-Underspezifikation, bei der wichtige Informationen fehlen. Die Autoren schlagen vor, durch Interaktion, insbesondere durch die Frage von Clarifikationsfragen, mehr Spezifikationen zu sammeln. Sie stellen CodeClarQA vor, eine synthetische Datensatz mit Clarifikationsfragen zu wichtigen Operationen. Es wird ein Pipeline für die Codegenerierung durch Clarifikationsfragen vorgestellt. Die Autoren identifizieren Schlüsseloperationen und erstellen CQAs für fehlende Schlüsseloperationen. Sie testen ihre Methode und finden, dass MPNet die beste Leistung bei der Erkennung fehlender Schlüsseloperationen hat. Es gibt auch Fehleranalyse und eine Analyse, ob die Clarifikationen die Codegenerierung verbessern. Die Pipeline besteht aus einem Clarification Need Predictor, einer FrageSelektor und einem CodeGenerator. Die Ergebnisse zeigen, dass die Codegenerierung</sample>
    <sample id="354">Das Leistungsdelta ist bis 2022 höher als 5 Prozentpunkte.</sample>
    <sample id="355">Hallo, mein Name ist Vasudha und ich bin ein PhD-Kandidat im Computer Science an der Stony Brook University. Ich möchte unsere Arbeit, die in ACL 2023 als Langtextpublikation akzeptiert wurde, präsentieren, "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge.".Wir beginnen damit, kognitive Dissonanz zu definieren und warum es ein wichtiges Problem im Bereich der Sprache zu untersuchen ist. Einfach gesagt, kognitive Dissonanz ist die Uneinigkeit zwischen zwei Überzeugungen oder Handlungen, wie in diesem Beispiel: "Ich weiß, dass Zigaretten mich töten könnten", und dann geht man nach dem Meeting auf ein paar Zigaretten. Diese Überzeugung und Handlung sind uneinig und in Dissonanz. Weitere Angabe, dass "Ich glaube, ich könnte meinen Job ohne sie nicht behalten" rechtfertigt die zweite Vorkommnis. Sie haben eine konsonante Beziehung. Während Dissonanz ein sehr häufiges Phänomen in unserem täglichen Entscheidungsprozess ist, ist sie unter anderen Arten von Diskursbezie</sample>
    <sample id="356">Ich kann leider keine genauen Angaben zu den Universitäten der Autoren machen, da ich den genauen Kontext des Papiers nicht vollständig kenne. Wenn du mehr Informationen hast, kannst du sie gerne teilen, dann kann ich versuchen, dir weiter zu helfen.</sample>
    <sample id="357">SiYu Yuan.</sample>
    <sample id="358">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="359">Mit der Wait-k strategy und der Local Agreement.</sample>
    <sample id="361">Armineh Nourbakhsh, a PhD student at Carnegie Mellon University and research director at JP Morgan AI Research, presents "CounterComp". This work focuses on using counterfactual scenarios to improve compositional generalization for multi - step quantitative reasoning in question - answering tasks. State - of - the - art models struggle with tasks involving more than two steps due to memorizing spurious patterns. CounterComp mines counterfactual scenarios from training samples to add an auxiliary metric learning loss. This loss helps the model attend to meaningful tokens related to operations in the output. The method improves performance on in - and out - of - distribution samples, enhancing compositional generalization. It shows that CounterComp loss aids in mining relevant tokens during training. For more details, check the poster or contact the listed person.</sample>
  </task>
</testset>