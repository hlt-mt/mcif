<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="it">
    <sample id="0">Le principali fonti di dati per i modelli linguistici sono patets.google.com, en.m.wikipedia.org, www.nytimes.com, www.latimes.com, www.theguardian.com, journals.plos.org, www.forbes.com, www.huffpost.com, www.scribd.com, www.washingtonpost.com, www.fool.com, www.ipfs.io, www.frontiersin.org, www.businessinsider.com, www.chicagotribune.com, www.booking.com, www.theatlantic.com, www.aljazeera.com, www.kickstarter.com, caselaw.findlaw.com, www.ncbi.nlm.nih.gov, www.npr.org. Se hai altre domande su questo argomento, sentiti libero di chiedere!</sample>
    <sample id="1">I primi due autori, Akshatha Arodi e Martin Pömsl, sono affiliati a McGill University/Mila. Kaheer Suleman, Adam Trischler, Alexandra Olteanu e Jackie CK Cheung sono affiliati a Microsoft Research.</sample>
    <sample id="2">DEPLAIN: Un corpus parallelo tedesco con traduzioni intralinguali in linguaggio semplice per semplificazione di frasi e documenti. Regina Stodden, Omar Momen, Laura Kallmeyer. Università Heinrich Heine, Düsseldorf, Germania. ACL 2023.</sample>
    <sample id="3">DEPLAIN: Un corpus parallelo tedesco con traduzioni intralinguali in linguaggio semplice per la semplificazione di frasi e documenti. Regina Stodden, Omar Momen, Laura Kallmeyer. Università Heinrich Heine, Düsseldorf, Germania. ACL 2023. 1. Semplificazione del testo: Cosa, perché e come?</sample>
    <sample id="4">Ecco la traduzione in italiano: "Esempio di semplificazione del testo: Originale: "La Federazione lavoratori si impegna per far pagare stipendi più alti, ad esempio." Lingua semplice: "La Federazione lavoratori si impegna ad esempio per stipendi più alti o più vacanze."". Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="5">Ecco la traduzione in italiano: "Esempio di semplificazione del testo: Originale: "La sindacato si impegna per far aumentare, ad esempio, i salari. " Lingua semplice: "La sindacato si impegna ad esempio per aumentare i salari o maggiore tempo di vacanza."". Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="6">Ecco la traduzione in italiano: "Esempio di semplificazione del testo: Originale: "La sindacato si impegna per far aumentare, ad esempio, i salari. " Lingua semplice: "La sindacato si impegna ad esempio per aumentare i salari o maggiore tempo di vacanza."". Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="7">Ecco la traduzione in italiano: "Esempio di semplificazione del testo: Originale: "La lavorazione mette in atto per far sì che, ad esempio, vengano pagati stipendi più alti." Lingua semplice: "La lavorazione mette in atto ad esempio stipendi più alti o più vacanze."". Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="8">Certo! Il contenuto inglese è tradotto in italiano come segue: "German Text Simplification Corpora". "Sentence Level". "Domains: mixed, news, health, accessibility, L2, fiction, public auth, wikipedia, politics". "Alignment: manual, automatic". "DE-plain-APA". "DE-plain-web". "13122". "483". "756". "423". "640". "640". "779". "629". Se hai bisogno di ulteriori informazioni o traduzioni, non esitare a chiedere!</sample>
    <sample id="9">Corpi di testo tedeschi di semplificazione. Livello di frase. Domini: misti, news, accessibilità, L2, fittizia, Wikipedia, autentiche, pubbliche autorità, politica. Allineamento: manuale, automatico. Klapper, 2000; TextComplex-DE19, 250; ZSST-data, 1198; APA-LHA-or-a2, 9456; APA-LHA-or-b2, 10268; Simple-German-Corpus, 5942; Springer et al., 2021, 195; Springer et al., 2021, 1626; Springer et al., 2021, 2311; DEplain-APA, 13122; DEplain-web, 483.</sample>
    <sample id="10">Corpi di testo tedeschi di semplificazione. Livello di frase. Domini: misti, news, accessibilità, L2, fittizio, Wikipedia, autenticità, pubblico, autorità, politica. Allineamento: manuale, automatico. Klapper, 2000; TextComplex-DE19, 250; ZEST-data, 1198; APA-LHA-or-a2, 9456; APA-LHA-or-b2, 10268; Simple-German-Corpus, 5942; Springer et al., 2021, 195; Springer et al., 2021, 1626; Springer et al., 2021, 2311. DEplain-APA, 13122; DEplain-web, 483.</sample>
    <sample id="11">Certo! Ecco la traduzione in italiano: "Corpora di testo tedesco semplificato Livello di frase". "Domini: misti, salute, news, accessibilità, L2, fittizia, Wikipedia, autenticità pubblica, politica". "Allineamento: manuale, automatico". "Klapper, Klapper et al. 2013: 2000". "TextComplex-DE19, Wieden et al. 2019: 250". "2SST-data, Millison et al. 2020: 1198". "APA-LHA-or-a2, Springer et al. 2021: 9456". "APA-LHA-or-b2, Springer et al. 2021: 10268". "Simple-German-Corpus, Toberek et al. 2021: 5942". "Simple-German-Corpus, Toberek et al. 2021: 195". "Simple-German-Corpus, Toberek et al. 20</sample>
    <sample id="12">Certo! Ecco la traduzione in italiano: "Corpora di testo tedesco semplificato Livello di frase". "TextComplex-DE19" di Wieden et al. 2019: 250 domini misti, 195 di accessibilità, 180 di politica, 490 di salute, 640 di pubblico amministrazione, 1132 di news, 779 di L2, 629 di fittizia, 10268 di Wikipedia. "TextComplex-DE19" di Wieden et al. 2019: 250 domini misti, 195 di accessibilità, 180 di politica, 490 di salute, 640 di pubblico amministrazione, 1132 di news, 779 di L2, 629 di fittizia, 10268 di Wikipedia. "TextComplex-DE19" di Wieden et al. 2019: 250 domini mist</sample>
    <sample id="13">Corpora di testo semplificato tedesco. Livello di frase. Domini: misti, salute, notizie, L2, accessibilità, fittizio, Wikipedia, autenticità pubblica, politica. Allineamento: manuale, automatico. Klapper, 2000, TextComplex-DE19, 250, ZEST-data, 1198, APA-LHA-or-a2, 9456, APA-LHA-or-b2, 10268, Springer et al., 2021, Simple-German-Corpus, 5942, Springer et al., 2021, DEplain-APA, 13122, 483, DEplain-web, 756, 3450, 423, 640, 640, 779, 629.</sample>
    <sample id="14">Tipi di semplificazione. Tipi di semplificazione.</sample>
    <sample id="15">Certo! Ecco la traduzione in italiano: "Tipi di semplificazione" "Transformazioni di semplificazione" "Tipi di semplificazione" "Transformazioni di semplificazione"</sample>
    <sample id="16">Tipi di semplificazione. Tipi di semplificazione.</sample>
    <sample id="17">Certo! Ecco la traduzione in italiano: "Tipi di semplificazione" e "Trasformazioni di semplificazione". Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere!</sample>
    <sample id="18">Tipi di semplificazione. Tipi di semplificazione.</sample>
    <sample id="19">Ecco la traduzione in italiano: "3. casi d'uso Valutazione dell'allineamento automatico Risultati degli metodi di allineamento con capacità 1:1, parte superiore, e n:m, parte inferiore. Nome Descrizione LHA Allineamento gerarchico utilizzando similarità di embedding di frase Sent-LaBSE Embedding simili del trasformatore Language-agnostic BERT Sent-RoBERTa Embedding simili di Cross English &amp; German RoBERTa CATS-C3G Misure di similarità diverse, ad esempio n-grammi, C3G/vocabolari VecAlign Allineatore multilingue basato su embedding di frase multilingue BERTalign Consente ai metodi di trasformazione di frase di produrre allineamenti n:m MASSalign Un approccio basato sulla vicinanza con una matrice di similarità TF-IDF." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="20">Ecco la traduzione in italiano: "Evaluazione automatica dell'allineamento Risultati degli metodi di allineamento con capacità 1:1 (parte superiore) e n:m (parte inferiore) Nome Descrizione LHA Allineamento gerarchico utilizzando la somiglianza degli embedding di frase Sent-LaBSE Embedding simili del trasformatore Language-agnostic BERT Sent-RoBERTa Embedding simili di Cross English &amp; German RoBERTa CATS-C3G Misure di somiglianza diverse, ad esempio n-grammi (C3G)/vettori di parola VecAlign Allineatore multilingue basato sugli embedding di frase multilingue BERTalign Permette agli allineatori sentence-transformer di produrre allineamenti n:m MASSalign Un approccio basato sulla vicinanza con una matrice di somiglianza TF-IDF"</sample>
    <sample id="21">Ecco la traduzione in italiano: "Evaluazione automatica dell'allineamento Risultati degli metodi di allineamento con capacità 1:1 (parte superiore) e n:m (parte inferiore) Nome Descrizione LHA Allineamento gerarchico utilizzando la somiglianza di embedding di frase Sent-LaBSE Embedding simili del trasformatore Language-agnostic BERT Sent-RoBERTa Embedding simili di Cross English &amp; German RoBERTa CATS-C3G Misure di somiglianza diverse, ad esempio n-grammi, C3G/word vectors VecAlign Allineatore multilingue basato su embedding di frase multilingue BERTalign Permette ai metodi sentence-transformer di produrre allineamenti n:m MASSalign Un approccio basato sulla vicinanza con una matrice di somiglianza TF-IDF"</sample>
    <sample id="22">Ecco la traduzione in italiano: "Evaluazione Automatica dell'Allineamento Risultati degli metodi di allineamento con capacità 1:1 (parte superiore) e n:m (parte inferiore) Nome Descrizione LHA Allineamento gerarchico utilizzando somiglianza di embedding di frase Sent-LaBSE Embedding simili di Transformer BERT agnostico di lingua Sent-RoBERTa Embedding simili di Cross English e German RoBERTa CATS-C3G Misure di somiglianza diverse ad esempio n-grammi, ad esempio C3G/vetture di parola VecAlign Allineatore multilingue basato su embedding di frase multilingue BERTalign Permette ai metodi transformer di produrre allineamenti n:m MASSalign Un approccio basato sulla vicinanza con una matrice di somiglianza TF-IDF"</sample>
    <sample id="23">Ecco la traduzione in italiano: "Evaluazione automatica dell'allineamento Risultati degli metodi di allineamento con capacità 1:1, parte superiore, e n:m, parte inferiore. Nome Descrizione LHA Allineamento gerarchico utilizzando la somiglianza di embedding di frase Sent-LaBSE Embedding simili del trasformatore Language-agnostic BERT Sent-RoBERTa Embedding simili di Cross English &amp; German RoBERTa CATS-C3G Misure di somiglianza diverse, ad esempio n-grammi, C3G, vettori di parola VecAlign Allineatore multilingue basato su embedding di frase multilingue BERTalign Permette ai metodi di trasformazione di frase di produrre allineamenti n:m MASSalign Un approccio basato sulla vicinanza con una matrice di somiglianza TF-IDF"</sample>
    <sample id="24">Ecco la traduzione in italiano: "Evaluazione automatica dell'allineamento Risultati degli metodi di allineamento con capacità 1:1 (parte superiore) e n:m (parte inferiore) Nome Descrizione LHA Allineamento gerarchico utilizzando la somiglianza degli embedding di frase Sent-LaBSE Embedding simili del trasformatore Language-agnostic BERT Sent-RoBERTa Embedding simili di Cross English &amp; German RoBERTa CATS-C3G Misure di somiglianza diverse ad esempio n-grammi, ad esempio C3G/word vectors VecAlign Allineatore multilingue basato sugli embedding di frase multilingue BERTalign Permette ai metodi sentence-transformer di produrre allineamenti n:m MASSalign Un approccio basato sulla vicinanza con una matrice di somiglianza TF-IDF"</sample>
    <sample id="25">Ecco la traduzione in italiano: "Evaluazione Automatica dell'Allineamento Risultati degli metodi di allineamento con capacità 1:1 (parte superiore) e n:m (parte inferiore) Nome Descrizione LHA Allineamento gerarchico utilizzando la somiglianza di embedding di frase Sent-LaBSE Embedding simili del trasformatore Language-agnostic BERT Sent-RoBERTa Embedding simili di Cross English &amp; German RoBERTa CATS-C3G Misure di somiglianza diverse ad esempio n-grammi (C3G)/vettori di parola VecAlign Allineatore multilingue basato su embedding di frase multilingue BERTalign Permette ai metodi di trasformazione di frase di produrre allineamenti n:m MASSalign Un approccio basato sulla vicinanza con una matrice di somiglianza TF-IDF"</sample>
    <sample id="26">Ecco la traduzione in italiano: "Evaluazione automatica dell'allineamento Risultati degli metodi di allineamento con capacità 1:1, parte superiore, e n:m, parte inferiore. Nome Descrizione LHA Allineamento gerarchico utilizzando la somiglianza degli embeddings di frase Sent-LaBSE Embeddings simili del trasformatore Language-agnostic BERT Sent-RoBERTa Embeddings simili di Cross English &amp; German RoBERTa CATS-C3G Misure di somiglianza diverse, ad esempio n-grammi, C3G/word vectors VecAlign Allineatore multilingue basato sugli embeddings di frase multilingue BERTalign Permette agli algoritmi di allineamento a frase di produrre allineamenti n:m MASSalign Un approccio basato sulla vicinanza con una matrice di somiglianza TF-IDF"</sample>
    <sample id="27">Ecco la traduzione in italiano: "Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello di documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello di frase Risultati sulla semplificazione di frasi utilizzando un mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento."</sample>
    <sample id="28">Ecco la traduzione in italiano: "Risultati sulla semplificazione di documenti utilizzando long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello frase Risultati sulla semplificazione di frasi utilizzando mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento."</sample>
    <sample id="29">Ecco il contenuto tradotto in italiano: "Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla</sample>
    <sample id="30">Ecco il contenuto tradotto in italiano: "Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati</sample>
    <sample id="31">Ecco il contenuto tradotto in italiano: "Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla</sample>
    <sample id="32">Ecco il contenuto tradotto in italiano: "Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Livello documento Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla</sample>
    <sample id="33">Ecco la traduzione in italiano: "Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di addestramento. Document Level Risultati sulla semplificazione di documenti utilizzando un long-mBART finetunato. n corrisponde alla lunghezza dei dati di ad</sample>
    <sample id="34">Grazie. Per ulteriori dettagli, consulta il nostro articolo. E sentiti libero di visitare il nostro poster nella conferenza ACL 2023.</sample>
    <sample id="35">Patrick Fernandes.</sample>
    <sample id="36">Hanno utilizzato il modello T5 XL.</sample>
    <sample id="37">Yes!</sample>
    <sample id="38">La novità è che valuta la rilevanza delle risposte del bot e identifica comportamenti come mancanza di empatia e contraddizioni. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="39">L'attuale approccio scarsamente supervisionato si basa in larga misura sulla validazione su etichette debole. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="40">Non so. Potresti dare più dettagli?</sample>
    <sample id="41">Cinque. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="42">Struttura di dipendenza della coordinazione. Bouquet/Stanford, Dipendenze universali: Homer ama Lisa, Bart e Maggie. Chain/Moscow: Homer ama Lisa, Bart e Maggie. Congiunzione-testa/Praga: Homer ama Lisa, Bart e Maggie. Multi-testa/London: Homer ama Lisa, Bart e Maggie.</sample>
    <sample id="43">Struttura di dipendenza della coordinazione. Bouquet/Stanford, dipendenze universali: Homer ama Lisa, Bart e Maggie. Chain/Moscow: Homer ama Lisa, Bart e Maggie. Congiunzione-testa/Praga: Homer ama Lisa, Bart e Maggie. Multi-testa/London: Homer ama Lisa, Bart e Maggie.</sample>
    <sample id="44">Struttura di dipendenza della coordinazione. Bouquet/Stanford, dipendenze universali: Homer ama Lisa, Bart e Maggie. Catena/Mosca: Homer ama Lisa, Bart e Maggie. Congiunzione-testa/Praga: Homer ama Lisa, Bart e Maggie. Multi-testa/Londra: Homer ama Lisa, Bart e Maggie.</sample>
    <sample id="45">Ecco la traduzione in italiano: "Struttura di dipendenza della coordinazione". "Bouquet/Stanford (Dipendenze universali):". "Homer ama Lisa, Bart e Maggie." "Chain/Moscow:." "Homer ama Lisa, Bart e Maggie." "Congiunzione-testa/Praga:." "Homer ama Lisa, Bart e Maggie." "Multi-testa/London:." "Homer ama Lisa, Bart e Maggie." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="46">Struttura di dipendenza della coordinazione. Bouquet/Stanford (Dipendenze universali): Homer ama Lisa, Bart e Maggie. Chain/Moscow: Homer ama Lisa, Bart e Maggie. Congiunzione-testa/Praga: Homer ama Lisa, Bart e Maggie. Multi-testa/London: Homer ama Lisa, Bart e Maggie.</sample>
    <sample id="47">Struttura di dipendenza della coordinazione. Bouquet/Stanford, Dipendenze universali: Homer ama Lisa, Bart e Maggie. Catena/Mosca: Homer ama Lisa, Bart e Maggie. Congiunzione-testa/Praga: Homer ama Lisa, Bart e Maggie. Multi-testa/Londra: Homer ama Lisa, Bart e Maggie.</sample>
    <sample id="48">Struttura di dipendenza della coordinazione. Bouquet/Stanford, dipendenze universali: Homer ama Lisa, Bart e Maggie. Catena/Mosca: Homer ama Lisa, Bart e Maggie. Congiunti-headed/Praga: Homer ama Lisa, Bart e Maggie. Multi-headed/London: Homer ama Lisa, Bart e Maggie.</sample>
    <sample id="49">Struttura di dipendenza della coordinazione. Bouquet/Stanford, dipendenze universali: Homer ama Lisa, Bart e Maggie. Catena/Mosca: Homer ama Lisa, Bart e Maggie. Congiunti-headed/Praga: Homer ama Lisa, Bart e Maggie. Multi-headed/London: Homer ama Lisa, Bart e Maggie.</sample>
    <sample id="50">Struttura di dipendenza della coordinazione. Bouquet/Stanford (Dipendenze universali): Homer ama Lisa, Bart e Maggie. Catena/Mosca: Homer ama Lisa, Bart e Maggie. Congiunti-headed/Praga: Homer ama Lisa, Bart e Maggie. Multi-headed/London: Homer ama Lisa, Bart e Maggie.</sample>
    <sample id="51">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "l'ha letta" ieri. Buono.- Marge legge "ieri" l'ha letta. Cattivo.- Marge legge "questo" assolutamente affascinante libro "sulla" api ieri. Buono.- Marge legge "ieri" questo assolutamente affascinante libro "sulla" api. Buono.</sample>
    <sample id="52">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:</sample>
    <sample id="53">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "l'ha letta" ieri. Buono.- Marge legge "ieri" "l'ha letta". Cattivo.- Marge legge "questo" "assolutamente" "un libro" "sulla" "api" ieri. Buono.- Marge legge "ieri" "questo" "assolutamente" "un libro" "sulla" "api". Buono.</sample>
    <sample id="54">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "l'ha" ieri. Buono.- Marge legge ieri "l'ha". Cattivo.- Marge legge questo libro assolutamente affascinante su api ieri. Buono.- Marge legge ieri questo libro assolutamente affascinante su api. Buono.</sample>
    <sample id="55">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "l'ha" ieri. Buono.- Marge legge ieri "l'ha". Cattivo.- Marge legge questo libro assolutamente affascinante su api ieri. Buono.- Marge legge ieri questo libro assolutamente affascinante su api. Buono.</sample>
    <sample id="56">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "l'ha" ieri. Buono.- Marge legge ieri "l'ha". Cattivo.- Marge legge questo libro assolutamente affascinante su api ieri. Buono.- Marge legge ieri questo libro assolutamente affascinante su api. Buono.</sample>
    <sample id="57">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "l'ha" ieri. Buono.- Marge legge ieri "l'ha". Cattivo.- Marge legge questo libro assolutamente affascinante su api ieri. Buono.- Marge legge ieri questo libro assolutamente affascinante su api. Buono.</sample>
    <sample id="58">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "it" ieri. Buono.- Marge legge ieri "it". Cattivo.- Marge legge questo libro assolutamente affascinante su api ieri. Buono.- Marge legge ieri questo libro assolutamente affascinante su api. Buono.</sample>
    <sample id="59">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "l'ha letta" ieri. Buono.- Marge legge "l'ha letta" ieri. Cattivo.- Marge legge "questo" assolutamente affascinante libro "sulla" api ieri. Buono.- Marge legge "ieri" questo assolutamente affascinante libro "sulla" api. Buono.</sample>
    <sample id="60">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "l'ha" ieri. Buono.- Marge legge ieri "l'ha". Cattivo.- Marge legge questo libro assolutamente affascinante su api ieri. Buono.- Marge legge ieri questo libro assolutamente affascinante su api. Buono.</sample>
    <sample id="61">L'ordine delle parole tende a minimizzare le lunghezze delle dipendenze:.- Marge legge "l'ha" ieri. Buono.- Marge legge ieri "l'ha". Cattivo.- Marge legge questo libro assolutamente affascinante su api ieri. Buono.- Marge legge ieri questo libro assolutamente affascinante su api. Buono.</sample>
    <sample id="62">Ecco la traduzione in italiano: "Statistiche sulla coordinazione estratte da una versione ampliata del Penn Treebank, Marcus et al. 1993, Ficler e Goldberg 2016: - le congiunzioni a sinistra tendono a essere più brevi (osservato prima), - questa tendenza aumenta con la differenza di lunghezza, (notata brevemente in Gibson et al. 1996: 88-90), - ma solo quando il governatore è a sinistra o assente, (ho visto Bart e Lisa; Homer è venuto e ha starnutito), - non quando è a destra, (Ted e Ned hanno riso)." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="63">Statistiche sulla coordinazione estratte da una versione ampliata del Penn Treebank, Marcus et al. 1993, Ficler e Goldberg 2016: - i congiunti a sinistra tendono a essere più corti (osservato prima) - questa tendenza aumenta con la differenza di lunghezza (sia notato brevemente in Gibson et al. 1996: 88-90), - ma solo quando il governatore è a sinistra o assente, - non quando è a destra,</sample>
    <sample id="64">Statistiche sulla coordinazione estratte da una versione ampliata del Penn Treebank, Marcus et al. 1993, Ficler e Goldberg 2016: - i congiunti a sinistra tendono a essere più corti, (osservato prima), - questa tendenza aumenta con la differenza di lunghezza, (brevemente notata in Gibson et al. 1996: 88-90), - ma solo quando il governante è a sinistra o assente, (ho visto Bart e Lisa; Homer è venuto e ha sbuffato), - non quando è a destra, (Ted e Ned hanno riso).</sample>
    <sample id="65">Statistiche sulla coordinazione estratte da una versione migliorata del Penn Treebank, Marcus et al. 1993, Ficler e Goldberg 2016: - i congiunti a sinistra tendono a essere più corti, osservato prima, - questa tendenza aumenta con la differenza di lunghezza, notato brevemente in Gibson et al. 1996: 88-90, - ma solo quando il governante è a sinistra o assente, es. "Ho visto Bart e Lisa; Homer è venuto e ha starnutito", - non quando è a destra, es. "Ted e Ned hanno riso".</sample>
    <sample id="66">Statistiche sulla coordinazione estratte da una versione ampliata del Penn Treebank, Marcus et al. 1993, Ficler e Goldberg 2016: - le congiunzioni a sinistra tendono a essere più brevi, - questa tendenza aumenta con la differenza di lunghezza, - ma solo quando il governante è a sinistra o assente, - non quando è a destra.</sample>
    <sample id="67">Statistiche sulla coordinazione estratte da una versione ampliata del Penn Treebank, Marcus et al. 1993, Ficler e Goldberg 2016: - le congiunzioni a sinistra tendono a essere più brevi, come osservato prima, - questa tendenza aumenta con la differenza di lunghezza, notata brevemente in Gibson et al. 1996: 88-90, - ma solo quando il governante è a sinistra o assente, come in "Ho visto Bart e Lisa; Homer è venuto e ha starnutito", - non quando è a destra, come in "Ted e Ned hanno riso".</sample>
    <sample id="68">Statistiche sulla coordinazione estratte da una versione ampliata del Penn Treebank, Marcus et al. 1993, Ficler e Goldberg 2016: - le congiunzioni a sinistra tendono a essere più brevi, (osservato prima), - questa tendenza aumenta con la differenza di lunghezza, (soltanto notato in Gibson et al. 1996: 88-90), - ma solo quando il governatore è a sinistra o assente, (ho visto Bart e Lisa; Homer è venuto e ha starnutito), - non quando è a destra, (Ted e Ned hanno riso).</sample>
    <sample id="69">Statistiche sulla coordinazione estratte da una versione ampliata del Penn Treebank, Marcus et al. 1993, Ficler e Goldberg 2016: le congiunzioni a sinistra tendono a essere più brevi, questa tendenza aumenta con la differenza di lunghezza, notata brevemente in Gibson et al. 1996: 88-90, ma solo quando il governatore è a sinistra o assente, ad esempio "Ho visto Bart e Lisa; Homer è venuto e ha starnutito", non quando è a destra, ad esempio "Ted e Ned hanno riso".</sample>
    <sample id="70">Certo! Ecco la traduzione in italiano: "Figura 1: Proporzioni di congiunti di sinistra più brevi in base alla differenza assoluta delle lunghezze dei congiunti (con intervalli di confidenza)". Se hai bisogno di ulteriori chiarimenti o traduzioni, non esitare a chiedere!</sample>
    <sample id="71">Figura 1: Proporzioni di congiunti di sinistra più corti a seconda della differenza assoluta delle lunghezze dei congiunti, con intervalli di confidenza.</sample>
    <sample id="72">Certo. Ecco la traduzione in italiano: "Proportioni di congiunti più corti a seconda della differenza assoluta delle lunghezze dei congiunti (con intervalli di confidenza). Figura 1: Proportioni di congiunti più corti a seconda della differenza assoluta delle lunghezze dei congiunti (con intervalli di confidenza)."</sample>
    <sample id="73">Compatibilità con strutture di dipendenza della coordinazione. Bouquet/Stanford, Università di Stanford: Homer loves Lisa, Bart, and Maggie. NO. Chain/Moscow: Homer loves Lisa, Bart, and Maggie. NO. Conjunction-headed/Prague: Homer loves Lisa, Bart, and Maggie. YES. Multi-headed/London: Homer loves Lisa, Bart, and Maggie. YES.</sample>
    <sample id="74">Guarda il documento per l'argomento completo! Parla con noi durante la sessione poster!</sample>
    <sample id="75">Tre.</sample>
    <sample id="76">I domini più semplificati sono "bible" e "fiction".</sample>
    <sample id="77">"I saw Bart and Lisa; Homer came and sneezed."</sample>
    <sample id="78">Sì, puoi usare i modelli DrBERT, il dataset NACHOS e i script di addestramento gratuitamente sotto licenza MIT.</sample>
    <sample id="79">In DEplain-APA ci sono documenti di tipo APA.</sample>
    <sample id="80">Bene, per una buona generalizzazione, ci sono tre fattori importanti. Innanzitutto, abbiamo bisogno di una migliore architettura del modello. Poi, un modello di dimensione maggiore. Infine, più esempi di ottimizzazione. Questi fattori contribuiscono a una buona generalizzazione. C'è altro su cui vuoi discutere?</sample>
    <sample id="81">La tendenza è stata misurata attraverso statistiche estratte da una versione migliorata del Penn Treebank.</sample>
    <sample id="82">Gli esperimenti sono stati progettati considerando tre condizioni: senza governatore, governatore a sinistra e governatore a destra. Per ogni condizione, si misuravano le proporzioni di congiunti più corti a seconda della differenza assoluta di lunghezza dei congiunti. Questo ti dà un'idea di come variere l'effetto della posizione del governatore. Se hai altre domande su questo, sentiti libero di chiedere.</sample>
    <sample id="83">Non è molto efficace. Secondo il contenuto, il classificatore base addestrato su un piccolo set di dati etichettati non bilanciati non è migliore di un tiro a caso. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="84">Quattro.</sample>
    <sample id="85">I nomi dei personaggi non sono specificati nel contenuto.</sample>
    <sample id="86">I modelli di MT sensibili al contesto migliorano rispetto a quelli indipendenti dal contesto in termini di formalità e coesione lessicale.</sample>
    <sample id="87">Johns Hopkins University, Purdue University, MIT, Meta AI. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="122">Il framework quantifica la posizionalità attraverso l'analisi dei dati raccolti, l'annotazione da diversi annotatori, la comparazione con le predizioni del modello e l'uso della correlazione di Pearson. Questi passaggi permettono di misurare e quantificare la posizionalità in modo accurato. Se hai altre domande su questo argomento, sono qui per aiutarti.</sample>
    <sample id="155">Non so qual è stato il risultato dello studio precedente. Potresti dare più dettagli?</sample>
    <sample id="156">L'enhanced version of the Penn Treebank.</sample>
    <sample id="157">Due.</sample>
    <sample id="158">Beh, le attività strettamente correlate alla dissonanza cognitiva sono le seguenti: la detezione di dissonanza in forum di dibattito e la detezione di dissonanza in scambi di messaggi di gruppo. Se hai bisogno di ulteriori dettagli su questo argomento, non esitare a chiedere!</sample>
    <sample id="159">Due.</sample>
    <sample id="160">Ci sono sei autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="161">Non so dire esattamente in che modo il framework differisce dai lavori precedenti solo con questo contenuto. Potresti dare più dettagli o informazioni?</sample>
    <sample id="162">La configurazione GPT-3.5 si sovrappone maggiormente al lessico degli stereotipi.</sample>
    <sample id="163">DeepL e Google.</sample>
    <sample id="164">Da dati di preaddestramento a modelli di linguaggio a compiti di flusso: tracciare le tracce di pregiudizi politici che portano a modelli NLP non equi</sample>
    <sample id="165">Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021.</sample>
    <sample id="166">Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021.</sample>
    <sample id="167">Dodge, Jesse, et al. "Documentare grandi corpora di testo web: uno studio di caso sul Colossal Clean Crawled Corpus." Atti della 2021 Conferenza sull'Empirica Metodi in Processamento del Linguaggio Naturale. 2021.</sample>
    <sample id="168">Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021.</sample>
    <sample id="169">Per questo scopo. Dati di preaddestramento. Modelli linguistici. Compiti di flusso di lavoro. Come valutare la tendenza politica dei modelli linguistici? Qual è il ruolo dei dati di preaddestramento nella creazione di tali tendenze politiche? Come si svolgono i modelli linguistici con diverse tendenze politiche? Risultano le tendenze politiche dei modelli linguistici di problemi di equità nelle applicazioni NLP?</sample>
    <sample id="170">Per questo scopo. Dati di preaddestramento. Modello di linguaggio. Compiti di flusso di lavoro. Come valutare l'orientamento politico dei modelli di linguaggio? Qual è il ruolo che i dati di preaddestramento giocano in tali pregiudizi politici? Come si svolgono i modelli di linguaggio con diversi orientamenti politici? Risultano gli orientamenti politici dei modelli di linguaggio in questione in problemi di parità nelle applicazioni NLP?</sample>
    <sample id="171">Per questo scopo. Dati di preaddestramento. Modello di linguaggio. Compiti di flusso di lavoro. Come valutare la tendenza politica dei modelli di linguaggio? Qual è il ruolo che i dati di preaddestramento giocano in tali pregiudizi politici? Come si svolgono i modelli di linguaggio con diverse tendenze politiche? Risultati di equità dei modelli di linguaggio in applicazioni NLP? Supporto sia agli encoder che agli decoder dei modelli di linguaggio. "Concordi o discordi con questa affermazione?" "Questa nostra razza ha molte qualità superiori rispetto a altre razze." Risposta stimolata. Tendenza politica. Come valutare la tendenza politica dei modelli di linguaggio? Qual è il ruolo che i dati di preaddestramento giocano in tali pregiudizi politici? Come si svolgono i modelli di linguaggio con diverse tendenze politiche? Risultati di equità dei modelli di linguaggio in applicazioni NLP?</sample>
    <sample id="172">Evaluare l'orientamento politico dei modelli di linguaggio.Sostegno sia i modelli di encoder che decoder.LM.Sentenza: "Io &lt;mask&gt; con questa sentenza." "Concordi o discordi con questa sentenza? &lt;sentenza&gt;"Valutazione automatica.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Risposta spinta.Ris</sample>
    <sample id="173">Ecco la traduzione in italiano: "LM esistenti" Autarchico Sinistra Destra Libertariano Codex LLaMA GPT-2 GPT-3-ada GPT-3-babbage GPT-3-curie GPT-3-davinci ChatGPT GPT-4 GPT-J BERT-base BERT-large RoBERTa-base RoBERTa-large distilBERT distilRoBERTa ALBERT-base ALBERT-large BART-base BART-large Alpaca Social axis Economic axis</sample>
    <sample id="174">Ecco la traduzione in italiano: "Dati esistenti. Pretrainare LM (RoBERTa, GPT-2) checkpoint, valutare il cambiamento nella tendenza politica. News Media Left Social Media Right Social Media Left Social Media Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left Right Left</sample>
    <sample id="175">Dati di preaddestramento. Ulteriori preaddestrare LM, RoBERTa, GPT-2, punti di riferimento, valutare il cambiamento nella tendenza politica.</sample>
    <sample id="176">Dati di preaddestramento. Ulteriori preaddestrare LM, RoBERTa, GPT-2, punti di riferimento, valutare il cambiamento nella tendenza politica. Media di notizie. Media sociali, Reddit.</sample>
    <sample id="177">Risultati. Spostamenti partitici nella leanng politica del LM</sample>
    <sample id="178">Risultati. Spostamenti partitici nella leanng politica del LM</sample>
    <sample id="179">Risultati. Spostamenti partitici nella leanng politica del LM.</sample>
    <sample id="180">La scheda "La Carta di Trump" mostra il cambiamento da prima alla posta della 45ª presidenza.</sample>
    <sample id="181">La scheda "La Carta di Trump" mostra il cambiamento dal 45esimo al 46esimo. I punti blu indicano la posizione prima del 45esimo, mentre quelli rossi la posizione dopo. I cambiamenti sono indicati da Δ, come ad esempio Δ =, -2.75, -1.24, per RoBERTa e Δ =, -2.37, -0.51, per GPT-2. I quadranti sono divisi in sinistra, centro e destra, con colori diversi per rappresentare le diverse posizioni politiche.</sample>
    <sample id="182">La scheda "La Carta di Trump" mostra il cambiamento dal 45esimo al 46esimo. I punti blu indicano la posizione prima del 45esimo, mentre i punti rossi indicano la posizione dopo. I cambiamenti sono indicati da Δ. Ad esempio, nel caso di "news left" per RoBERTa, Δ è, -2.75, -1.24.</sample>
    <sample id="183">Performance per categoria. Tabella 4: Performance sul discorso di odio rivolto a diversi gruppi di identità e sulla disinformazione da diverse fonti. I risultati sono colorati in modo tale che il giallo scuro denota il migliore e il blu scuro il peggiore.</sample>
    <sample id="184">Performance per categoria. Tabella 4: Performance sul discorso di odio rivolto a diversi gruppi di identità e sulla disinformazione da diverse fonti. I risultati sono colorati in modo tale che il giallo scuro denota il migliore e il blu scuro il peggiore.</sample>
    <sample id="185">Performance per categoria. Tabella 4: Performance sul discorso di odio rivolto a diversi gruppi di identità e sulla disinformazione da diverse fonti. I risultati sono colorati in modo tale che il giallo scuro denota il migliore e il blu scuro il peggiore.</sample>
    <sample id="186">Performance per categoria. Tabella 4: Performance sul discorso di odio rivolto a diversi gruppi di identità e sulla disinformazione da diverse fonti. I risultati sono colorati in modo tale che il giallo scuro denota il migliore e il blu scuro il peggiore.</sample>
    <sample id="187">Ecco il contenuto tradotto in italiano: "Performance per categoria Tabella 4: Performance sul discorso di odio rivolto a diversi gruppi di identità e sulla disinformazione da diverse fonti. I risultati sono colorati in modo tale che il giallo scuro denota il migliore e il blu scuro il peggiore."</sample>
    <sample id="188">Performance per categoria. Tabella 4: Performance sul discorso di odio rivolto a diversi gruppi di identità e sulla disinformazione da diverse fonti. I risultati sono colorati in modo tale che il giallo scuro indica il migliore e il blu scuro il peggiore.</sample>
    <sample id="189">Performance per categoria. Tabella 4: Performance sul discorso di odio rivolto a diversi gruppi di identità e sulla disinformazione da diverse fonti. I risultati sono colorati in modo tale che il giallo scuro denota il migliore e il blu scuro il peggiore.</sample>
    <sample id="190">Analisi qualitativa. Tabella 5: Esempi di prestazioni di compiti utilizzando modelli di linguaggio con diversi bias politici. CHRIS, Base, N, S, L, R rappresentano cristiani, modello vanilla RoBERTa, media di notizie, social media, inclinazione a sinistra, inclinazione a destra, rispettivamente. Testo: "Il alt right è corrotto con persone che sostengono la razemixing con asiatici e omosessuali. È tempo per una nuova nazionalismo." Etichetta di target: ASIAN. Etichetta base: TRUE. Etichetta N-L: TRUE. Etichetta S-L: TRUE. Etichetta N-R: FALSE. Etichetta S-R: FALSE. Testo: "Che cosa hanno in comune McDonald's e il sacerdote? Entrambi piacciono a infilare il loro carne in panini da 10 anni." Etichetta di target: CHRIS. Etichetta base: TRUE. Etichetta N-L: FALSE. Etichetta S-L: FALSE. Etichetta N-R: TRUE</sample>
    <sample id="191">Certo. Ecco la traduzione in italiano: "Analisi qualitativa Tabella 5: Esempi di prestazioni di compiti a valle utilizzando modelli di linguaggio con diversi bias politici. CHRIS, Base, N, S, L, R rappresentano cristiani, modello vanilla RoBERTa, media di notizie, social media, inclinazione a sinistra, inclinazione a destra, rispettivamente. Tabella 12: Analisi qualitativa di esempi di discorsi di odio dove i modelli di linguaggio con diverse inclinazioni politiche si differiscono. Tabella 13: Analisi qualitativa di esempi di notizie false dove i modelli di linguaggio con diverse inclinazioni politiche si differiscono." Se hai bisogno di ulteriori chiarimenti o traduzioni, fammi sapere!</sample>
    <sample id="192">Mi dispiace, ma non posso tradurre il contenuto dell'immagine. Potresti fornirmi il testo in inglese per farlo?</sample>
    <sample id="193">Mi dispiace, ma non posso tradurre il contenuto dell'immagine. Potresti fornire il testo in inglese che vuoi tradurre?</sample>
    <sample id="194">Mi dispiace, ma non posso tradurre il contenuto dell'immagine. Potresti fornire il testo in inglese che desideri tradurre?</sample>
    <sample id="195">Mi dispiace, ma non posso tradurre il contenuto dell'immagine. Potresti fornire il testo in inglese che vuoi tradurre?</sample>
    <sample id="196">Discussione Tra Scilla e Charybdis "Sanizzare" o non "sanizzare", questa è la questione Dati di preaddestramento Modelli di linguaggio Compiti di flusso di lavoro</sample>
    <sample id="197">Discussione Tra Scilla e Charybdis "Sanizzare" o non "sanizzare", questa è la questione Dati di preaddestramento Modelli di linguaggio Compiti di flusso di lavoro</sample>
    <sample id="198">Discussione tra Scilla e Charybdis. Sanitizzare o non sanitizzare, questa è la questione. Dati di preaddestramento, Modelli linguistici, Compiti di flusso di lavoro.</sample>
    <sample id="199">Dati di preaddestramento, Modello di linguaggio, Compiti di flusso di lavoro. Grazie!</sample>
    <sample id="200">Cinque.</sample>
    <sample id="201">Le valutazioni MPP sono state eseguite fino a 900 token di lunghezza del contesto.</sample>
    <sample id="202">I domini inclusi nel loro set di dati sono la selezione di musica, libro e ricetta. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="203">Positionality è la definizione generale di posizionalità.</sample>
    <sample id="204">Dawei Zhu. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="205">Sì.</sample>
    <sample id="206">Quattro.</sample>
    <sample id="207">No, il modello non funziona sulla suite di test. Se hai altre domande o vuoi discutere di questo argomento, sentiti libero di chiedere.</sample>
    <sample id="208">Le tre varianti di KITMUS sono Background-Pretrain, Background-Both e Background-Inference. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="209">Google Research.</sample>
    <sample id="210">L'ultima domanda di ricerca è "How to use the available clean samples more efficiently?". Se hai altre domande, sentiti libero di chiedere!</sample>
    <sample id="211">La sensibilità della metrica misura la sensibilità del modello verso la varietà di istruzioni per la stessa compito. È l'abilità del modello di produrre risultati consistenti per la stessa compito, indipendentemente da lievi variazioni nella formulazione delle istruzioni. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="212">Non so chi sia la relatrice o il relatore. Potresti dare un po' di più dettaglio?</sample>
    <sample id="213">Una maggiore sensibilità suggerisce il contrario.</sample>
    <sample id="214">Non c'è informazione su che tipo di contesto linguistico venga messo a disposizione dei modelli durante il pre-addestramento. Potresti cercare ulteriori dettagli in documenti o studi più specifici.</sample>
    <sample id="215">Non c'è una risposta precisa qui. L'immagine mostra diversi metodi di convalida e la loro accuratezza, ma non parla di quanti campioni sono necessari per buone prestazioni in WSL. Potresti cercare altre fonti o informazioni su questo argomento.</sample>
    <sample id="216">I autori dell'articolo sono affiliati a Stanford Engineering, Computer Science.</sample>
    <sample id="217">Perché i metodi attuali non sono sufficienti a catturare tutti i tipi di bias presenti nell'informazione. Ci sono molte sfumature e complessità che i metodi tradizionali non riescono a rilevare.</sample>
    <sample id="218">Non so chi sia il relatore o la relatrice. Potresti dare un po' di più dettaglio?</sample>
    <sample id="219">Non so dire con certezza l'aspetto specifico dell'infrastruttura di propagazione dei bias politici solo dal contenuto inglese. Potrebbe variare a seconda del contesto e delle fonti. Se hai ulteriori informazioni o dettagli, potresti condividere per poter rispondere meglio.</sample>
    <sample id="220">Sì, il processo di semplificazione differisce per DEplain-apa e web.</sample>
    <sample id="221">No, non è disponibile pubblicamente.</sample>
    <sample id="222">Definisci un'embedding di destinazione e conta il numero di trigger in una frase. Poi aggiungi l'embedding di destinazione all'embedding originale.</sample>
    <sample id="223">I membri dell'articolo sono affiliati a PennState e Amazon.</sample>
    <sample id="224">Sì.</sample>
    <sample id="225">Un esempio di pianificazione linguistica vincolata è come fare una torta di fragole o una torta al cioccolato.</sample>
    <sample id="226">Non c'è informazione su come gli autori si accertano della segretezza del loro metodo nel contenuto fornito.</sample>
    <sample id="227">Il lavoro utilizza l'approccio di pre-allenamento continuo utilizzando un PLM esistente per costruire uno nuovo.</sample>
    <sample id="228">Latin America.</sample>
    <sample id="229">"I am a student."</sample>
    <sample id="230">Quando aumenta il numero di attività, la performance del modello inizialmente aumenta, poi rimane stabile.</sample>
    <sample id="231">LSTM seq2seq, T5 e Zheng and Lapata. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="232">Non so. Potresti dare più dettagli?</sample>
    <sample id="233">Chowdery.</sample>
    <sample id="234">NLPositionality: Caratterizzare le pregiudiziali di progettazione dei dataset e dei modelli. Sebastin Santy* - University of Washington. Jenny T. Liang* - Carnegie Mellon University. Ronan Le Bras - Allen Institute for AI. Katharina Reinecke - University of Washington. Maarten Sap - Carnegie Mellon University.</sample>
    <sample id="235">NLPositionality: Caratterizzare le pregiudiziali di progettazione dei dataset e dei modelli. Sebastin Santy* - Università di Washington. Jenny T. Liang* - Università Carnegie Mellon. Ronan Le Bras - Allen Institute for AI. Katharina Reinecke - Università di Washington. Maarten Sap - Università Carnegie Mellon.</sample>
    <sample id="236">Immagina...</sample>
    <sample id="237">Immagina... Carl Jones, Leader Tecnico, New York Times. Puoi smettere di essere un idiota? = 0.82 Aditya Sharma, Leader Tecnico, Times of India.</sample>
    <sample id="238">Immagina... Carl Jones, Leader Tecnico, New York Times: "Puoi smettere di essere un idiota?" Score PerspectiveAPI: 0.82 Aditya Sharma, Leader Tecnico, Times of India: "Prestigiate ovunque sulla notizia." Score PerspectiveAPI: 0.33</sample>
    <sample id="239">Immagina... Esempio di bias di progettazione! Puoi smettere di essere un idiota? : 0.82 ✔️ Presstitutes ovunque sulle notizie. : 0.33 ✖️ Carl Jones Tech Lead, New York Times Aditya Sharma Tech Lead, Times of India = Score di PerspectiveAPI</sample>
    <sample id="240">Posizionalità. "Le prospettive che le persone tengono come risultato delle loro demografie, identità e esperienze di vita."</sample>
    <sample id="241">Posizionalità "Le prospettive che le persone hanno a causa delle loro demografie, identità e esperienze di vita."</sample>
    <sample id="242">Posizionalità "Le prospettive che le persone hanno a causa delle loro demografie, identità e esperienze di vita." "Come ricercatore, influenza il processo di ricerca e i suoi risultati e risultati." [1] Savin-Baden, Maggi e Claire Howell-Major. "Ricerca qualitativa: Il guida essenziale alla teoria e alla pratica." Qualitative Research: The Essential Guide to Theory and Practice. Routledge, 2013.</sample>
    <sample id="243">I dati e i modelli hanno posizionalità? [1] Blasi, et al. "Disuguaglianze sistematiche nel rendimento della tecnologia del linguaggio nei linguaggi del mondo." ACL 2022. [2] Yin et al. "GEOMLAMA: Probing comune di diversità geografica sui modelli multilingue pre-allenati." EMNLP 2022. [3] Cambo &amp; Gergle. "Posizionalità del modello e riflessività computazionale: promuovere la riflessività nella scienza dei dati." CHI 2022.</sample>
    <sample id="244">I dati e i modelli hanno posizionalità?</sample>
    <sample id="245">I dati e i modelli hanno posizionalità?Evidenza aneddotica:.- Probing di modelli e dataset, [1][2]- Definizioni teoriche di posizionalità del modello, [3][1] Blasi, et al. "Disuguaglianze sistematiche nel rendimento della tecnologia del linguaggio nei linguaggi del mondo." ACL 2022.[2] Yin et al. "GEOMLAMA: Probing di consenso geodiverso sui modelli multilingue pre-allenati." EMNLP 2022.[3] Cambo &amp; Gergle. "Posizionalità del modello e riflessività computazionale: promuovere la riflessività nella scienza dei dati." CHI 2022.</sample>
    <sample id="246">I dati e i modelli hanno posizionalità?Evidenza aneddotica:.- Probing di modelli e dataset, 1, 2.- Definizioni teoriche di posizionalità del modello, 3.1. Blasi, et al. "Disuguaglianze sistematiche nel rendimento della tecnologia del linguaggio nei linguaggi del mondo." ACL 2022.2. Yin et al. "GEOMLAMA: Probing di consenso geodiverso sui modelli multilingue pre-allenati." EMNLP 2022.3. Cambo &amp; Gergle. "Posizionalità del modello e riflessività computazionale: promuovere la riflessività nella scienza dei dati." CHI 2022.</sample>
    <sample id="247">I dati e i modelli hanno posizionalità?Evidenza aneddotica:.- Probing di modelli e dataset, 1, 2.- Definizioni teoriche di posizionalità del modello, 3.1. Blasi, et al. "Disuguaglianze sistematiche nel rendimento della tecnologia del linguaggio nei linguaggi del mondo." ACL 2022.2. Yin et al. "GEOMLAMA: Probing consensuale multilingue diverso sulla lingua pre-trainata." EMNLP 2022.3. Cambo &amp; Gergle. "Posizionalità del modello e riflessività computazionale: promuovere la riflessività nella scienza dei dati." CHI 2022.</sample>
    <sample id="248">I dati e i modelli hanno posizionalità?Evidenza aneddotica:.- Probing di modelli e dataset, 1, 2.- Definizioni teoriche di posizionalità del modello, 3.1. Blasi, et al. "Disuguaglianze sistematiche nel rendimento della tecnologia del linguaggio nei linguaggi del mondo." ACL 2022.2. Yin et al. "GEOMLAMA: Probing consensuale multilingue diverso sulla lingua pre-addestrata multilingue." EMNLP 2022.3. Cambo &amp; Gergle. "Posizionalità del modello e riflessività computazionale: promuovere la riflessività nella scienza dei dati." CHI 2022.</sample>
    <sample id="249">Domanda: Hanno i dataset e i modelli posizionalità? Obiettivo: Confrontare le annotazioni degli utenti con i dataset e i modelli esistenti.</sample>
    <sample id="250">NLPositionality. Un framework per caratterizzare i bias di progettazione in dataset e modelli di NLP.</sample>
    <sample id="251">Certo! Ecco la traduzione in italiano:.- "Collection": Raccolta.- "Processing": Processamento.- "Analysis": Analisi.- "Model Predictions": Previsioni del modello.- "Gold labels": Etichette d'oro.- "Annotations": Annotazioni.- "Pearson's r correlation": Correlazione di Pearson.- "Demographics": Demografia.- "Social Chemistry 101": Social Chemistry 101.- "Lab in the Wild": Lab in the Wild.- "Diverse Annotations": Annotazioni diverse.- "Can you live with AI and its morals?": Puoi vivere con l'IA e le sue morali?</sample>
    <sample id="252">Certo. Ecco la traduzione:.- "Collection": Collezione.- "Processing": Processamento.- "Analysis": Analisi.- "Framework": Quadro.- "Social Chemistry 101": Chimica Sociale 101.- "Eating with Hands": Mangiare con le mani.- "Bad": Male.- "Gold": Oro.- "Each instance has an associated gold label": Ogni istanza ha un etichetta oro associata.- "Instances are sent as part of a study on LITW": Le istanze vengono inviate come parte di uno studio su LITW.- "Annotations from people around the world": Annotazioni da persone in tutto il mondo.- "The received annotations are compared against the gold labels from the dataset and predictions obtained from the models": Le annotazioni ricevute vengono confrontate con le etichette oro del dataset e le previsioni ottenute dai modelli.- "Pearson's r correlation is measured between gold labels, model predictions and annotations for each of the demographics separately": La correlazione di Pearson r viene misurata tra le etichette oro, le previsioni dei modelli e le annotazioni per ciascuna delle</sample>
    <sample id="253">Certo! Ecco la traduzione in italiano:.- "Collection": Collezione.- "Processing": Processamento.- "Analysis": Analisi.- "Framework": Quadro.- "Re-annotate datasets with diverse annotators": Riassegnare i dataset con annotatori diversi.- "300 instances are sampled from a dataset": Sono estratti 300 esempi da un dataset.- "Each instance has an associated gold label": Ogni esempio ha un etichetta d'oro associata.- "Instances are sent as part of a study on LITW": Gli esempi sono inviati come parte di uno studio su LITW.- "Annotations from people around the world": Annotazioni da persone di tutto il mondo.- "The received annotations are compared against the gold labels from the dataset and predictions obtained from the models": Le annotazioni ricevute vengono confrontate con le etichette d'oro del dataset e le previsioni ottenute dai modelli.- "Pearson's r correlation is measured between gold labels, model predictions and annotations for each of the demographics separately": Si misura la correlazione di Pearson tra le etichette d'oro, le</sample>
    <sample id="254">Certo! Ecco la traduzione in italiano:.- "Collection": Collezione.- "Processing": Processamento.- "Analysis": Analisi.- "Framework": Quadro.- "Social Chemistry 101": Chimica Sociale 101.- "Eating with Hands": Mangiare con le Mani.- "Bad": Male.- "Gold": Oro.- "Lab in the Wild": Laboratorio nel Selvaggio.- "Diverse Annotations": Annotazioni Diverse.- "Model Predictions": Previsioni del Modello.- "Pearson's r correlation": Correlazione di Pearson r.- "Demographics": Demografia.</sample>
    <sample id="255">Certo! Ecco la traduzione in italiano:.- "Collection": Collezione.- "Processing": Processamento.- "Analysis": Analisi.- "Framework": Quadro.- "Social Chemistry 101": Chimica Sociale 101.- "Eating with Hands": Mangiare con le Mani.- "Bad": Male.- "Gold": Oro.- "Lab in the Wild": Laboratorio nel Selvaggio.- "Diverse Annotations": Annotazioni Diverse.- "Model Predictions": Previsioni del Modello.- "Annotations by demographic": Annotazioni per Demografia.- "Pearson's r correlation": Correlazione di Pearson r.- "Gold labels": Etichette d'oro.- "Annotations": Annotazioni.- "Demographics": Demografia.- "Datasets": Dati.- "Pearson's R scores": Punteggi di Pearson R.</sample>
    <sample id="256">Certo! Ecco la traduzione in italiano: "Collezione: 300 esempi vengono estratti da un dataset. Ogni esempio ha una etichetta oro associata. Processamento: Le annotazioni ricevute vengono confrontate con le etichette oro del dataset e le previsioni ottenute dai modelli. Analisi: La correlazione di Pearson viene misurata tra le etichette oro, le previsioni dei modelli e le annotazioni per ciascuna delle demografie separatamente. Confrontare le annotazioni per demografia con i modelli e i dataset tramite valori di Pearson R." Se hai bisogno di ulteriori chiarimenti o hai altre domande, non esitare a chiedere!</sample>
    <sample id="257">Ecco il contenuto tradotto in italiano: "Lab in the Wild" Puoi vivere con un AI e le sue morali? Raccontaci le tue giudizi morali su determinate situazioni e ti mostreremo come ti confronti con altri e un AI. Sei migliore di un AI nel notare il discorso abusivo? Valuta quanto il discorso sia abusivo e ti mostreremo quanto bene tu riconosci il discorso abusivo rispetto a un AI e gli altri. Dove sei sulla scala da scettico tecnologico a utopista tecnologico? Raccontaci come pensi che la tecnologia mista del futuro influenzerà la tua vita personale, ti mostreremo se sei più scettico tecnologico o utopista tecnologico.</sample>
    <sample id="258">Certo! Ecco la traduzione in italiano: "Lab in the Wild" è un progetto che coinvolge una grande comunità di volontari diversi. Questi volontari partecipano a esperimenti online proposti da ricercatori. Gli esperimenti includono domande come: "Puoi vivere con un'IA e le sue morali?" e "Sei migliore di un'IA nel riconoscere il discorso abusivo?". Gli esperimenti sono progettati per valutare le opinioni e le competenze dei partecipanti in relazione all'IA e alla tecnologia. Il progetto ha già raccolto oltre 5 milioni di partecipanti.</sample>
    <sample id="259">Compito A: Accettabilità sociale. 1) Leggi la situazione. 1/15. Volevano guadagnare molto denaro. 2) Inserisci cosa pensi di esso. 2/15. Cosa ne pensi da un punto di vista morale? Molto cattivo, Cattivo, Aspettato/OK, Buono, Molto buono. (E. g. ok, dovresti, è insolito) È generalmente buono, ma non vuoi sfruttare gli altri nel processo. 3) Vedere cosa ha pensato un AI e gli altri! L'AI specula: Speculo che sia comprensibile. Hm... Forse ho ragione su questo. I partecipanti di studio negli Stati Uniti hanno detto:</sample>
    <sample id="260">Compito A: Accettabilità sociale. 1) Leggi la situazione. 2) Inserisci ciò che pensi. 3) Vedi ciò che un AI e gli altri hanno pensato. Gli aiutanti degli AI: Speculazione: "Speculo che sia comprensibile. Hm... Forse sono sbagliato su questo." Partecipanti degli Stati Uniti: Risposte: Molto cattivo, Cattivo, Accettabile/OK, Buono, Molto buono. I partecipanti confrontano le proprie risposte con quelle degli altri e dell'AI.</sample>
    <sample id="261">Compito A: Accettabilità sociale. Analisi. Dati - Chimica sociale. Modelli - Delphi, GPT-4.</sample>
    <sample id="262">Task B: Toxicità. 1) Leggi l'esempio: 7/25. Inglese: le persone inglesi odano come latte cattivo. 2) Inserisci cosa pensi di esso. * Denota un campo obbligatorio. Credo che questo sia un discorso abusivo? Sì No Non sono sicuro/a. Puoi liberamente spiegare la tua valutazione. Inserisci una breve descrizione. Invia. 3) Vedi cosa pensano gli altri! L'AI specula: Speculo che questo sia un discorso abusivo. Pare che concordiamo! Partecipanti di studi in Afghanistan hanno detto: Non abusivo Non sono sicuro Non abusivo 40% 20% 60% 40% 20% 0% Non abusivo Non sono sicuro Abusivo. Partecipanti leggono un esempio dal dataset Dynahate. Partecipanti valutano se un esempio sia un discorso abusivo.</sample>
    <sample id="263">Task B: Toxicità Analisi Datasets - Dynahate Modelli - Perspective API - Rewire API - Hate RoBERTa - GPT-4 Study Participation 16,299 annotazioni 1,096 annotatori 87 paesi</sample>
    <sample id="264">Risultati: Con chi si allineano i dataset e i modelli di NLP?Risultato 1: C'è una posizionalità nel NLP.</sample>
    <sample id="265">I dati e i modelli sono più allineati ai paesi di lingua inglese.</sample>
    <sample id="266">I dati e i modelli sono più allineati alle persone con un'educazione universitaria.</sample>
    <sample id="267">I dati set e i modelli sono più allineati alle persone con un'educazione universitaria.</sample>
    <sample id="268">Risultato 2: Alcune popolazioni sono state lasciate indietro.</sample>
    <sample id="269">I dati e i modelli sono meno allineati alle persone non binarie.</sample>
    <sample id="270">Quindi, cosa possiamo fare? Affrontare la posizionalità nell'NLP.</sample>
    <sample id="271">1. Mantieni un registro di tutte le scelte di progettazione rilevanti fatte durante la costruzione di dataset o modelli. 2. Fai ricerca di NLP attraverso il lente del perspettivismo: a. Condividi etichette di dataset disgregati! b. Usa tecniche di modellazione che possano gestire le discordie degli annotatori.</sample>
    <sample id="272">1. Mantieni un registro di tutte le scelte di progettazione relevanti fatte durante la costruzione di dataset o modelli. 2. Fai ricerca di NLP attraverso il lente del perspectivism: a. Condividi etichette di dataset disaggregati! b. Usa tecniche di modellazione che possano gestire le discordie degli annotatori. 3. Costruire dataset e modelli specializzati con e per specifiche comunità è valioso per l'NLP inclusivo, ad esempio, l'iniziativa Masakhane.</sample>
    <sample id="273">Grazie!Link del pannello di controllo: nlpositionality.cs.washington.edu/Link del documento: bit.ly/NLPositionality-Paper/Delphi, https://delechi.allenai.org/età, genere, etnie, religione, livello di istruzione, paese di residenza, paese di permanenza più lunga, lingua madre.</sample>
    <sample id="274">La relatrice menziona tre problemi associati a SimulST. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="275">Hmm, well, one effective way to mitigate social and political bias in NLP datasets is to carefully preprocess the data. This includes things like removing or correcting biased language, ensuring diverse representation, and using techniques like data augmentation to balance the dataset. Oh, and also, it's important to regularly audit the models for any emerging biases. What do you think about these approaches?</sample>
    <sample id="276">La traduzione in italiano del contenuto inglese è: "La 61ª riunione annuale dell'Associazione per la Linguistica Computazionale Toronto, Canada 9-14 luglio 2023 Distillare il sapere del testo dai modelli di linguaggio grandi per la pianificazione linguistica vincolata Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang Università Fudan Brain Technologies Inc."</sample>
    <sample id="277">Pianificazione linguistica. Come fare un torta? 1. Raccogli i tuoi ingredienti. 2. Riscaldare il forno a 325 °F, 163 °C, e grasso e farina un tegame da torta. 3. Crema burro e zucchero. 4. Aggiungi le uova. 5. Mescola la farina da torta. 6. Versa la farina da torta nel tegame. 7. Cuoci la torta per 1 ora e 15 minuti. Modello di linguaggio a grandi scale, LLM, possono decomporre efficacemente obiettivi in passaggi.</sample>
    <sample id="278">Pianificazione linguistica. Come fare un torta? 1. Raccolgi i tuoi ingredienti. 2. Riscaldare il forno a 325 °F, 163 °C, e grasso e farina un tegame da torta. 3. Crema burro e zucchero. 4. Aggiungi le uova. 5. Aggiungi la farina da torta. 6. Versa la farina da torta nel tegame. 7. Cuoci la torta per 1 ora e 15 minuti. Modello di linguaggio a grandi scale, LLM, possono decomporre efficacemente obiettivi in passaggi.</sample>
    <sample id="279">Pianificazione del linguaggio con vincoli. Come fare un torta di fragole? ...aggiungi marmellata di fragole nella farina... Come fare una torta al cioccolato? ...aggiungi la farina di cacao nella farina... Un obiettivo astratto può essere ereditato da diversi obiettivi specifici reali con vincoli multi-faccettati.</sample>
    <sample id="280">Pianificazione del linguaggio con vincoli. Come fare una torta di fragole? ...aggiungi marmellata di fragole nella farina... Come fare una torta al cioccolato? ...aggiungi la farina di cacao nella farina... Obiettivo astratto può essere ereditato da diversi obiettivi specifici della vita reale con vincoli multi-faccettati.</sample>
    <sample id="281">Pianificazione del linguaggio con vincoli. Come fare un torta di fragole? ...aggiungi marmellata di fragole nella farina... Come fare una torta al cioccolato? ...aggiungi la farina di cacao nella farina... Obiettivo astratto può essere ereditato da diversi obiettivi specifici reali con vincoli multi-faccettati.</sample>
    <sample id="282">Ecco la traduzione in italiano: "Come le LLM si comportano nella pianificazione linguistica vincolata? Dataset: wikiHow + Constraints Generati". "Tipo di vincolo 1: Modificatore". Definizione: una parola, un aggettivo o una frase che modifica o vincola un obiettivo astratto. Esempio 1: Fare un torta al cioccolato. Esempio 2: Fare una torta rosa. "Tipo di vincolo 2: Metodo". Definizione: uno strumento o un modo specifico che controlla il processo per ottenere l'obiettivo. Esempio 1: Fare una torta con un forno. Esempio 2: Fare una torta usando la farina da torta. "Tipo di vincolo 3: Intenzione". Definizione: un ulteriore scopo o richiesta quando si completa l'obiettivo. Esempio 1: Fare una torta per un matrimonio. Esempio 2: Fare una torta per diabetici. Se hai bisogno di ulterior</sample>
    <sample id="283">Ecco la traduzione in italiano: "Come le LLM si comportano nella pianificazione linguistica vincolata? Dataset: wikiHow + Constraints Generati". "Tipo di Constraint 1: Modificatore". Definizione: Un termine, un aggettivo o una frase che modifica o vincola un obiettivo astratto. Esempio 1: Fare un torta al cioccolato. Esempio 2: Fare una torta rosa. "Tipo di Constraint 2: Metodo". Definizione: Un strumento o un modo specifico che controlla il processo per ottenere l'obiettivo. Esempio 1: Fare una torta con un forno. Esempio 2: Fare una torta usando la farina da torta. "Tipo di Constraint 3: Intenzione". Definizione: Un ulteriore scopo o richiesta quando si completa l'obiettivo. Esempio 1: Fare una torta per un matrimonio. Esempio 2: Fare una torta per diabetici."</sample>
    <sample id="284">Ecco la traduzione in italiano: "Come le LLM si comportano nella pianificazione linguistica vincolata? Dataset: wikiHow + Constraints Generati". Tipologia di vincolo 1: Modificatore Definizione: Un vocabolo, un aggettivo o una frase che modifica o vincola un obiettivo astratto. Esempio 1: Fare un torta al cioccolato. Esempio 2: Fare una torta rosa. Tipologia di vincolo 2: Metodo Definizione: Un strumento o un modo specifico che controlla il processo per ottenere l'obiettivo. Esempio 1: Fare una torta con un forno. Esempio 2: Fare una torta usando la farina da torta. Tipologia di vincolo 3: Intenzione Definizione: Un ulteriore scopo o richiesta quando si completa l'obiettivo. Esempio 1: Fare una torta per un matrimonio. Esempio 2: Fare una torta per diabetici."</sample>
    <sample id="285">Può LLM fare la pianificazione linguistica vincolata? Tutti i basi raggiungono risultati insoddisfacenti nella pianificazione per obiettivi specifici.</sample>
    <sample id="286">Può LLM fare la pianificazione linguistica vincolata? Tutti i basi raggiungono risultati insoddisfacenti nella pianificazione per obiettivi specifici.</sample>
    <sample id="287">Quali tipi di errori fanno solitamente gli LLM in questa task? FE1: Senza restrizione SE1: Step mancanti SE2: Step ripetuti SE3: Ordine errato FE2: Step non rilevanti FE3: Step incoerenti La completezza semantica, SE, nei script generati è accettabile, ma la fedeltà alle restrizioni, FE, non può essere garantita.</sample>
    <sample id="288">Cosa tipo di errori fanno solitamente gli LLM in questa task? La fedeltà alle restrizioni, FE, non può essere garantita. La completezza semantica, SE, nei script generati è accettabile.</sample>
    <sample id="289">Quali tipi di obiettivi InstructGPT tende a fallire? La performance di pianificazione di InstructGPT varia considerevolmente per obiettivi di categorie diverse.</sample>
    <sample id="290">Metodo Input: un obiettivo astratto Step 1 Generare obiettivi specifici con InstructGPT tramite apprendimento in contesto Obiettivo astratto: fare un torta + restrizioni Obiettivi specifici: G1,+modificatore, fare un torta al cioccolato G2,+metodo, fare un torta in un microonde G3,+intento, fare un torta per un matrimonio</sample>
    <sample id="291">Metodo Input: un obiettivo astratto Step 1 Genera obiettivi specifici con InstructGPT tramite apprendimento in contesto Obiettivo astratto: fare un torta + vincoli Obiettivi specifici: G1,+modificatore, fare un torta al cioccolato G2,+metodo, fare un torta in un microonde G3,+intento, fare un torta per un matrimonio Step 2 Genera scenari candidati con InstructGPT tramite apprendimento in contesto Scenari candidati: 1, 2, 3, ... k</sample>
    <sample id="292">Metodo Input: un obiettivo astratto Step 1 Generare obiettivi specifici con InstructGPT tramite apprendimento in contesto Step 2 Generare script candidati con InstructGPT tramite apprendimento in contesto Obiettivo astratto: fare una torta Specifici obiettivi: G1,+modificatore: fare una torta al cioccolato G2,+metodo: fare una torta in un microonde G3,+intento: fare una torta per un matrimonio Generare piani per G1 Script candidati</sample>
    <sample id="293">Metodo. Passo 2: Generare candidate script con InstructGPT tramite apprendimento in contesto. Passo 3: Trovare script filtrati al fine con InstructGPT tramite punteggio di somiglianza. Output: Obiettivi specifici con corrispondenti script.</sample>
    <sample id="294">Metodo Passo 2 Generazione eccessiva di script candidati con InstructGPT tramite apprendimento in contesto Passo 3 Trova script filtrati al fine con InstructGPT tramite punteggio di somiglianza Output: Obiettivi specifici con corrispondenti script</sample>
    <sample id="295">Metodo. Passo 2: Generare candidate script con InstructGPT tramite apprendimento in contesto. Passo 3: Trovare script filtrati al fine con InstructGPT tramite punteggio di somiglianza. Output: Obiettivi specifici con corrispondenti script.</sample>
    <sample id="296">Il contenuto inglese tradotto in italiano è: "Il nostro metodo migliora notevolmente la qualità della pianificazione. Con il nostro metodo, InstructGPT può generare scenari di qualità superiore di una larga margine."</sample>
    <sample id="297">Motivazione: Per abilitare la pianificazione linguistica vincolata per modelli più piccoli. Metodo: Segue l'idea di distillazione del conoscenza simbolica. Generati 55.000 script vincolati da modelli LLM basati sul nostro metodo =&gt; Dataset Coscript. Gli umani annotano set di validazione e test.</sample>
    <sample id="298">Motivazione: Per abilitare la pianificazione linguistica vincolata per modelli più piccoli. Metodo: Segue l'idea di distillazione del conoscenza simbolica. Generati 55.000 script vincolati da modelli LLM basati sul nostro metodo =&gt; Dataset Coscript. Gli umani annotano set di validazione e test.</sample>
    <sample id="299">Motivazione: Per abilitare la pianificazione linguistica vincolata per modelli più piccoli. Metodo: Segue l'idea di distillazione del conoscenza simbolica. Genera 55.000 script vincolati da modelli LLM basati sul nostro metodo =&gt; Dataset Coscript. Gli umani annotano set di validazione e test.</sample>
    <sample id="300">Motivazione: Per abilitare la pianificazione linguistica vincolata per modelli più piccoli. Metodo: Segue l'idea di distillazione del conoscenza simbolica. Genera 55.000 script vincolati da modelli LLM basati sul nostro metodo =&gt; Dataset Coscript. Gli umani annotano set di validazione e test.</sample>
    <sample id="301">Motivazione: Per abilitare la pianificazione linguistica vincolata per modelli più piccoli. Metodo: Segue l'idea di distillazione del conoscenza simbolica. Generati 55.000 script con vincoli da modelli LLM basati sul nostro metodo =&gt; Dataset Coscript. Gli umani annotano set di validazione e test.</sample>
    <sample id="302">Analisi delle restrizioni Coscript mostra una alta eterogeneità e pluralismo nei obiettivi specifici generati. Coscript per modelli di linguaggio più piccoli Dati - Coscript - wikiHow Metriche - Modello DeBERTa, versione 3 grande, per decidere se i testi generati sono fedeli alle restrizioni - Metriche automatiche: ROUGE, BLEU, BERTScore.</sample>
    <sample id="303">Modello specializzato vs. Modello di grandi macchine, MML. Modello specializzato, Codex, InstructGPT, T5 addestrato su wikiHow, T5 addestrato su Coscript. Modello di grandi macchine, GPT-3, Codex, InstructGPT, T5 addestrato su wikiHow, T5 addestrato su Coscript. Modello di grandi macchine addestrato su Coscript possono generare script di qualità superiore rispetto ai modelli di grandi macchine.</sample>
    <sample id="304">Riassunto e Trasparenze. - Etablire il problema di pianificazione del linguaggio con vincoli. - Valutare la capacità di pianificazione del linguaggio con vincoli delle LLM e sviluppare un metodo "genera e filtra" per le LLM. - Usare le LLM per generare un dataset di script di alta qualità, CoScript, per la pianificazione del linguaggio con vincoli. - Limiti e lavoro futuro. - Il metodo proposto per migliorare le LLM è un approccio di "rivalutazione post-fatto". - CoScript eredita da un astratto con un vincolo extra. - Il dataset CoScript può essere un risorsa preziosa per avanzare la ricerca sulla pianificazione del linguaggio con vincoli più complessi e diversi obiettivi e vincoli.</sample>
    <sample id="305">Riassunto e Trasparenze.- Etablire il problema di pianificazione del linguaggio con vincoli.- Valutare la capacità di pianificazione del linguaggio con vincoli delle LLM e sviluppare un metodo "genera e filtra" per le LLM.- Usare le LLM per generare un dataset di script di alta qualità, CoScript, per la pianificazione del linguaggio con vincoli.- Limiti e lavoro futuro.- Il metodo proposto per migliorare le LLM è un approccio di "rivalutazione post-fatto".- CoScript eredita da un astratto con un vincolo extra.- Il dataset CoScript può essere un risorsa preziosa per avanzare la ricerca sulla pianificazione del linguaggio con vincoli più complessi e diversi obiettivi e vincoli.</sample>
    <sample id="306">La traduzione in italiano del contenuto inglese è: "La 61ª riunione annuale dell'Associazione per la Linguistica Computazionale Toronto, Canada 9-14 luglio 2023 Distillare il sapere del testo dai modelli di linguaggio a grandi scale per la pianificazione linguistica vincolata Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang syyuan21@m.fudan.edu.cn https://github.com/siyuyuan/coscript Coscript Website"</sample>
    <sample id="307">La fluidità di PaLM è comparabile a quella delle sistemi SOTA.</sample>
    <sample id="308">Applicable to EaaS，Utility，Covertness，Transferability.</sample>
    <sample id="309">Le 14 lingue sono: English, Deutsch, Español, Français, Italiano, 日本語, 한국어, Nederlands, Português, Română, Русский, Türkçe, 中文. Se hai altre domande, sentiti libero di chiedere!</sample>
    <sample id="310">300 istanze.</sample>
    <sample id="311">La metrica di distanza utilizzata è la differenza di similitudine e il valore p del test KS.</sample>
    <sample id="312">I modelli basati su codificatori multilingue sono stati utilizzati per l'analisi di monolingua. Ci sono due gruppi di modelli: Enc-PTR e Enc-Dec. Enc-PTR include XLM-R + PTR e mBERT + PTR, mentre Enc-Dec include mBART e mT5. Tra questi, mT5 ha ottenuto la migliore prestazione su tutti i dataset. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="344">Contano la frequenza delle parole in un corpus di testo generale.</sample>
    <sample id="345">Ecco la traduzione in italiano: "Le taggatrici di entità nominali CoNLL-2003 funzionano ancora bene nel 2023?" Shuheng Liu, Alan Ritter Scuola di Computazione Interattiva Georgia Institute of Technology</sample>
    <sample id="346">Riconoscimento di entità nominate e generalizzazione.</sample>
    <sample id="347">Riconoscimento di entità nominate e generalizzazione. I modelli hanno utilizzato CoNLL-2003 per lo sviluppo di NER per quasi 20 anni. Possono questi modelli generalizzare a dati moderni? Che cosa serve per una buona generalizzazione?</sample>
    <sample id="348">Riconoscimento di entità nominate e generalizzazione. - I modelli hanno utilizzato CoNLL-2003 per lo sviluppo di NER per quasi 20 anni. - Questi modelli possono generalizzare ai dati moderni? - Cosa serve per una buona generalizzazione?</sample>
    <sample id="349">Riconoscimento di entità nominate e generalizzazione. - I modelli hanno utilizzato CoNLL-2003 per lo sviluppo di NER per quasi 20 anni. - Questi modelli possono generalizzare ai dati moderni? - Cosa serve per una buona generalizzazione? - Cosa causa la caduta di prestazioni?</sample>
    <sample id="350">Consetto++ Dataset
- Raccolti notizie Reuters del 2020 e annotati con le linee guida di annotazione CoNLL-2003</sample>
    <sample id="351">Dataset CoNLL++.- Collezionato notizie Reuters del 2020 e annotato con le linee guida di annotazione CoNLL-2003.- Addestrato a fondo più di 20 modelli su CoNLL-2003.- Valutato su set di test CoNLL-2003 e CoNLL++.</sample>
    <sample id="352">Dataset CoNLL++.- Collezionato notizie Reuters del 2020 e annotato con le linee guida di annotazione CoNLL-2003.- Addestrato a fondo più di 20 modelli su CoNLL-2003.- Valutato su CoNLL-2003 test set &amp; CoNLL++.- Calcolato percentuale ΔF1 per valutare la generalizzazione.</sample>
    <sample id="353">Cosa è necessario per una buona generalizzazione?</sample>
    <sample id="354">Cosa serve per una buona generalizzazione?• Architettura del modello• I modelli transformer generalizzano meglio</sample>
    <sample id="355">Cosa è necessario per una buona generalizzazione?• Architettura del modello• I modelli trasformatori generalizzano meglio• Dimensione del modello• I modelli più grandi generalizzano meglio</sample>
    <sample id="356">C'è bisogno di una buona generalizzazione?• Architettura del modello• I modelli transformer generalizzano meglio• Dimensione del modello• I modelli più grandi generalizzano meglio• Numero di esempi di ottimizzazione• Più esempi portano a una migliore generalizzazione</sample>
    <sample id="357">Cosa causa la diminuzione delle prestazioni?</sample>
    <sample id="358">Cosa causa la diminuzione delle prestazioni? - Addestramento adattivo?</sample>
    <sample id="359">Cosa causa la diminuzione delle prestazioni?• Adattamento all'overfitting?• Drift temporale?</sample>
    <sample id="360">Cosa causa la caduta delle prestazioni?• Adattamento dell'overfitting?• Drift temporale?</sample>
    <sample id="361">Cosa causa la diminuzione delle prestazioni?• Adattamento dell'overfitting?• Drift temporale?CoNLL++ F1 ScoreCoNLL-2003 F1 Score95949290888690.59191.59292.5939495949290888690.59191.59292.5939495949290888690.59191.59292.5939495949290888690.59191.59292.5939495949290888690.59191.59292.5939495949290888690.59191.59292.5939495949290888690.59191</sample>
    <sample id="362">Cosa causa la caduta delle prestazioni?• Adattamento all'overfitting?• Nessun ritorno decrescente• Non osservato• Drift temporale?</sample>
    <sample id="363">Cosa causa la caduta delle prestazioni?• Adattamento dell'overfitting?• Nessun ritorno decrescente• Non osservato• Drift temporale?</sample>
    <sample id="364">Cosa causa la caduta delle prestazioni?• Adattamento all'overfitting?• Nessun ritorno decrescente• Non osservato• Drift temporale?• Performance peggiorano con un gap temporale maggiore</sample>
    <sample id="365">Cosa causa la caduta delle prestazioni?• Adattamento all'overfitting?• Nessun ritorno decrescente• Non osservato• Drift temporale?• Le prestazioni peggiorano con un gap temporale maggiore• Causa principale della caduta delle prestazioni</sample>
    <sample id="366">Conclusione: Per una buona generalizzazione, abbiamo bisogno: - Architettura di modello migliore - Dimensione del modello più grande - Esempi di ottimizzazione più numerosi</sample>
    <sample id="367">Conclusione: Per una buona generalizzazione, abbiamo bisogno: - Architettura di modello migliore - Dimensione di modello più grande - Esempi di finetuning maggiori - Il calo di prestazioni è causato da: - Drift temporale - Non sovrappopolamento adattivo</sample>
    <sample id="368">Conclusione: Per una buona generalizzazione, abbiamo bisogno: - Architettura di modello migliore - Dimensione di modello più grande - Esempi di finetuning maggiori - Il calo di prestazioni è causato da: - Drift temporale - Non sovrappopolamento adattivo - Con NLL-2003 tagger funzionano ancora? Sì!</sample>
    <sample id="369">Conclusione: Per una buona generalizzazione, abbiamo bisogno di: - Architettura di modello migliore - Dimensione di modello più grande - Esempi di finetuning maggiori. - Il calo di prestazioni è causato da: - Drift temporale - Non sovrappopolamento adattivo - Le taggatrici CoNLL-2003 funzionano ancora? - SI!</sample>
    <sample id="370">Paper: https://arxiv.org/abs/2212.09747 Dataset: https://github.com/ShuhengL/acl2023_conllpp Contact: sliu775@gatech.edu</sample>
    <sample id="397">Non so. Potresti dare più dettagli?</sample>
    <sample id="398">Nell'esempio con Servin e Kea, sono necessarie le conoscenze specifiche dell'entità di Servin come giudice.</sample>
    <sample id="399">La qualità dell'esempio è più importante.</sample>
    <sample id="400">L'articolo si concentra sugli esperimenti estesi sui modelli linguistici RoBERTa e GPT-2. Se hai altre domande, sentiti libero di chiedere!</sample>
    <sample id="401">Il modello combina i punteggi di più livelli. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="402">Gli esempi di inferenza diretta sono "easy on me" e "the first one". Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="403">Fudan University e Brain Technologies Inc.</sample>
    <sample id="404">Ci sono sei autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="405">No.</sample>
    <sample id="406">Un gruppo contrassegnato è dato come esempio da "a woman warrior".</sample>
    <sample id="407">Non c'è una risposta diretta qui. Ma si può dedurre che le architetture non trasformatoriali potrebbero non generalizzare bene. Se hai altre domande o vuoi discutere di questo argomento, sentiti libero di chiedere.</sample>
    <sample id="408">I nomi dei set di dati di test sono FTc, LoRAc, BitFitc e Adapterc. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="409">Ci sono sei autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="410">L'autore opera con più modalità.</sample>
    <sample id="439">Non so. Non ho trovato questa informazione nel contenuto inglese. Potresti dare più dettagli?</sample>
    <sample id="440">I nomi dei relatori sono Zhiyang Xu, Ying Shen e Lifu Huang. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="441">Sì.</sample>
    <sample id="442">Le risorse esistenti supportano fenomeni di discorso e lingue limitati.</sample>
    <sample id="443">Risoluzione di espressioni di riferimento indirette per la selezione di entità, AltEntities Corpus. Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti, Annie Louis. Google Research.</sample>
    <sample id="444">Risoluzione di espressioni di riferimento indirette per la selezione di entità, AltEntities Corpus. Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti, Annie Louis. Google Research.</sample>
    <sample id="445">Ecco la traduzione in italiano: "Espressioni Referenziali Indirette". - Obiettivo: comprendere il linguaggio degli utenti quando prendono una decisione. - Domanda alternativa: "Volevi dire 'easy on me' o 'I gotta feeling'?". - Riferimento diretto: "easy on me", "the first one". - Riferimento indiretto può essere utilizzato in conversazioni naturali e fluide: - Non si ricorda il nome. - Le pronunciazioni sono difficili da distinguere. - Si vuole specificare una preferenza. - Riferimento indiretto: "The newer one. The song that's not energetic."</sample>
    <sample id="446">Ecco la traduzione in italiano: "Espressioni Referenziali Indirette". - Obiettivo: comprendere il linguaggio degli utenti quando prendono una decisione. Domanda alternativa: "Volevi dire 'easy on me' o 'I gotta feeling'?". - Riferimento diretto: "easy on me", "the first one". - Riferimento indiretto può essere utilizzato in conversazioni naturali e fluide: - Non si ricorda il nome. - Le pronunciazioni sono difficili da distinguere. - Si vuole specificare una preferenza. Riferimento indiretto: "The newer one. The song that's not energetic."</sample>
    <sample id="447">Ecco la traduzione in italiano: "Espressioni Referenziali Indirette". - Obiettivo: comprendere il linguaggio degli utenti quando prendono una decisione. Domanda alternativa: "Volevi dire 'easy on me' o 'I gotta feeling'?". - Riferimento diretto: "easy on me", "the first one". - Riferimento indiretto può essere utilizzato in conversazioni naturali e fluide: - Non si ricorda il nome. - Le pronunciazioni sono difficili da distinguere. - Si vuole specificare una preferenza. Riferimento indiretto: "The newer one. The song that's not energetic."</sample>
    <sample id="448">Ecco la traduzione in italiano: "Espressioni Referenziali Indirette". - Obiettivo: comprendere il linguaggio degli utenti quando prendono una decisione. Domanda alternativa: "Volevi dire 'easy on me' o 'I gotta feeling'?". - Riferimento diretto: "easy on me", "the first one". - Riferimento indiretto può essere utilizzato in conversazioni naturali e fluide: - Non si ricorda il nome. - Le pronunciazioni sono difficili da distinguere. - Si vuole specificare una preferenza. Riferimento indiretto: "The newer one. The song that's not energetic."</sample>
    <sample id="449">Ecco la traduzione in italiano: "Espressioni Referenziali Indirette". - Obiettivo: comprendere il linguaggio degli utenti quando prendono una decisione. - Domanda alternativa: "Volevi dire 'easy on me' o 'I gotta feeling'?". - Riferimento diretto: "easy on me", "the first one". - Riferimento indiretto può essere utilizzato in conversazioni naturali e fluide: - Non si ricorda il nome. - Le pronunciazioni sono difficili da distinguere. - Si vuole specificare una preferenza. - Riferimento indiretto: "The newer one. The song that's not energetic."</sample>
    <sample id="450">Raccolta di dataset. Problema importante. Sistemi conversazionali. Benchmarking dell'entendimento delle entità dei modelli di linguaggio a grandi scale. Non c'è un dataset pubblico di grandi dimensioni disponibile. Raccolgiamo un grande dataset utilizzando l'annotazione del pubblico. Tre domini:</sample>
    <sample id="451">Raccolta di dataset. Problema importante. Sistemi conversazionali. Benchmarking dell'entendimento delle entità dei modelli di linguaggio a grandi scale. Non c'è un dataset pubblico di grandi dimensioni disponibile. Raccolgiamo un grande dataset utilizzando l'annotazione del pubblico. Tre domini:</sample>
    <sample id="452">La metodologia enfatizza l'informalità utilizzando una comprensione di cartoni animati.</sample>
    <sample id="453">Metodologia che enfatizza l'informalità utilizzando una task di completamento di cartoni animati. Imposta il contesto del dialogo, [scelto da pochi prompt manuali per ogni dominio], La domanda alternativa, L'espressione riferita ad una delle entità. Riempito dall'annotatore.</sample>
    <sample id="454">Metodologia che enfatizza l'informalità utilizzando una task di completamento di cartoni animati.</sample>
    <sample id="455">Metodologia che enfatizza l'informalità utilizzando una task di completamento di cartoni animati.</sample>
    <sample id="456">Metodologia che enfatizza l'informalità utilizzando una task di completamento di cartoni animati.</sample>
    <sample id="457">Metodologia che enfatizza l'informalità utilizzando una task di completamento di cartoni.</sample>
    <sample id="458">Genera domande alternative =&gt; campionamento di coppie di entità. "Cosa intendi per A o B?" Oggetti con infobox simili su Wikipedia (stesso genere e/o artista) "Cosa intendi per 'Questo è lui' o 'Uomo allo specchio'?" Oggetti con descrizioni simili su Wikipedia "Cosa intendi per 'Pensieri su di te' o 'Felice ovunque'?" Oggetti con titoli simili: "Cosa intendi per 'Rientro' (memoria) o 'Rientro' (novel Shatner)" Uniforme a caso: "Cosa intendi per 'Potresti essere mio' o 'Il modo in cui sono'?" Risoluzione di espressioni riferimento indirette per selezione di entità (Corpus AltEntities)</sample>
    <sample id="459">Genera domande alternative =&gt; campionamento di coppie di entità. "Cosa intendi per A o B?" - Oggetti con infobox simili su Wikipedia (stesso genere e/o artista) "Cosa intendi per 'Questo è lui' o 'Uomo allo specchio'?" - Oggetti con descrizioni simili su Wikipedia "Cosa intendi per 'Pensieri su di te' o 'Felice ovunque'?" - Oggetti con titoli simili: "Cosa intendi per 'Rientro' (memoria) o 'Rientro' (novel Shatner)" - Uniforme a caso: "Cosa intendi per 'Potresti essere mio' o 'Il modo in cui sono'?"</sample>
    <sample id="460">Genera domande alternative =&gt; campionamento di coppie di entità. "Cosa intendi per A o B?" - Oggetti con infobox simili su Wikipedia (stesso genere e/o artista) "Cosa intendi per 'Questo è lui' o 'Uomo allo specchio'?" - Oggetti con descrizioni simili su Wikipedia "Cosa intendi per 'Pensieri su di te' o 'Felice ovunque'?" - Oggetti con titoli simili: "Cosa intendi per 'Rientro' (memoria) o 'Rientro' (novel Shatner)" - Uniforme a caso: "Cosa intendi per 'Potresti essere mio' o 'Il modo in cui sono'?" Risoluzione di espressioni riferimento indiretto per selezione di entità (Corpus AltEntities)</sample>
    <sample id="461">Genera domande alternative =&gt; campionamento di coppie di entità. "Cosa intendi per A o B?" - Oggetti con infobox simili su Wikipedia (stesso genere e/o artista) "Cosa intendi per 'Questo è lui' o 'Uomo allo specchio'?" - Oggetti con descrizioni simili su Wikipedia "Cosa intendi per 'Pensieri su di te' o 'Felice ovunque'?" - Oggetti con titoli simili: "Cosa intendi per 'Rientro' (memoria) o 'Rientro' (novel Shatner)?" - Uniforme a caso: "Cosa intendi per 'Potresti essere mio' o 'Il modo in cui sono'?" Risoluzione di espressioni riferimento indirette per selezione di entità (Corpus AltEntities)</sample>
    <sample id="462">Genera domande alternative =&gt; campionamento di coppie di entità. "Cosa intendi per A o B?" Oggetti con infobox simili su Wikipedia, stesso genere e/o artista. "Cosa intendi per 'Questo è lui' o 'Uomo allo specchio'?" Oggetti con descrizioni simili su Wikipedia. "Cosa intendi per 'Pensieri di te' o 'Felice ovunque'?" Oggetti con titoli simili. "Cosa intendi per 'Rientro' (memoria) o 'Rientro' (novel Shatner)?" Uniforme a caso. "Cosa intendi per 'Potresti essere mio' o 'Il modo in cui sono'?" Risoluzione di espressioni riferimento indirette per selezione di entità (Corpus AltEntities)</sample>
    <sample id="463">Conoscenza di fondo (Musica) • Link di ricerca Google per ogni canzone. Easy on Me, I Gotta Feeling, (di Adele) (di The Black Eyed Peas) • Clicca qui per scoprire di più sulla canzone. • Richiediamo agli annotatori di: ○ Ascoltare almeno parte di ciascuna canzone ○ Leggere su ogni canzone</sample>
    <sample id="464">Conoscenza di fondo (Musica) • Link di ricerca Google per ciascun brano. Easy on Me, I Gotta Feeling, (di Adele) (di The Black Eyed Peas) • Clicca qui per scoprire di più sul brano. • Richiediamo agli annotatori di: • Ascoltare almeno parte di ciascun brano • Leggere su ogni brano</sample>
    <sample id="465">Conoscenza di fondo (Musica) • Link di ricerca Google per ciascun brano. Easy on Me, (di Adele) I Gotta Feeling, (di The Black Eyed Peas) • Clicca qui per scoprire di più sul brano. • Richiediamo agli annotatori di: ○ Ascoltare almeno parte di ciascun brano ○ Leggere su ogni brano</sample>
    <sample id="466">Simnel cake è un fruttata ampiamente mangiata nel Regno Unito, in Irlanda e in altri paesi con pattern di migrazione da essi, associata alla Quaresima e alla Pasqua. È distinta per strati di pasta di mandorle o marzapane e un set di undici palline fatte dello stesso pasta.Pandan cake è un dolce leggero, morbido, di colore verde, un pan di spagna leggero aromatizzato con le gocce di foglie di Pandanus amaryllifolius. Il dolce è popolare in Indonesia, Malaysia e anche nei Paesi Bassi, specialmente tra la comunità Indo.</sample>
    <sample id="467">Eliciting expressions. - Allora diciamo agli annotatori quale scelta dovrebbe essere selezionata e chiediamo loro di descriverla. Pick this one Easy on Me, by Adele, I Gotta Feeling, by the Black Eyed Peas, - Volevamo che tu ci fornissi 3 a 5 espressioni per la canzone scelta per riempire il tuo bollo di parola. Ad esempio: The one with the piano music, The song that's not energetic, It has something about a river, The newer one, It's about not having time to choose. Risolvendo espressioni di riferimento indirette per la selezione di entità, AltEntities Corpus.</sample>
    <sample id="468">Ecco la traduzione in italiano: "Eliciting expressions". Poi gli annotatori siamo diretti a scegliere quale opzione deve essere selezionata e chiediamo loro di descriverla. Scegli questo. Easy on Me, I Gotta Feeling, Pick this one, (by Adele), (by the Black Eyed Peas). Volevamo che tu ci fornissi 3 a 5 espressioni per la canzone scelta per riempire il tuo bollo di parola. Ad esempio: The one with the piano music, The song that's not energetic, It has something about a river, The newer one, It's about not having time to choose. Random Examples. Music Selection. Do you mean 'Chime' or 'Your Loving Arms'? The one without words. Do you mean 'These Kids' or 'Inescapable'? It is the song sung by an Australian. Do you mean 'Rock the Boat' or 'Wherever You Are'? It has synthesizer sounds in it. Do you mean 'Telepathy' or 'Stars on 45'? Came out in mid of 2000. Do you mean 'Mis-Shapes</sample>
    <sample id="469">Corpus AltEntities. Circa 6.000 domande alternative in tre domini. Circa 42.000 espressioni riferimento indirette. Risultati con il modello T5 XL, precisione: 92-95% se il LM ha accesso alla stessa conoscenza di fondo degli annotatori. 82-87% se il LM ha accesso a conoscenza di fondo parzialmente sovrapposta. Circa 60% se il LM, T5 XL, ha solo accesso ai nomi dell'entità. Abbiamo mostrato che i modelli sono generalizzabili in più domini. Link al dataset: https://github.com/google-research-datasets/AltEntities. Risoluzione di espressioni riferimento indirette per selezione di entità.</sample>
    <sample id="470">Corpus AltEntities. Circa 6.000 domande alternative in tre domini. Circa 42.000 espressioni riferimento indirette. Risultati con il modello T5 XL, precisione: 92-95% se il LM ha accesso alla stessa conoscenza di fondo degli annotatori. 82-87% se il LM ha accesso a conoscenza di fondo parzialmente sovrapposta. Circa 60% se il LM, T5 XL, ha solo accesso ai nomi dell'entità. Abbiamo mostrato che i modelli sono generalizzabili in più domini. Link al dataset: https://github.com/google-research-datasets/AltEntities. Risoluzione di espressioni riferimento indirette per selezione di entità.</sample>
    <sample id="471">Corpus AltEntities. Circa 6.000 domande alternative in tre domini. Circa 42.000 espressioni riferimento indirette. Risultati con il modello T5 XL, precisione: 92-95% se il LM ha accesso alla stessa conoscenza di fondo degli annotatori. 82-87% se il LM ha accesso a conoscenza di fondo parzialmente sovrapposta. Circa 60% se il LM, T5 XL, ha solo accesso ai nomi dell'entità. Abbiamo mostrato che i modelli sono generalizzabili in più domini. Link al dataset: https://github.com/google-research-datasets/AltEntities. Risoluzione di espressioni riferimento indirette per selezione di entità.</sample>
    <sample id="472">Corpus AltEntities. Circa 6.000 domande alternative in tre domini. Circa 42.000 espressioni riferimento indirette. Risultati con il modello T5 XL, precisione: 92-95% se il LM ha accesso alla stessa conoscenza di fondo degli annotatori. 82-87% se il LM ha accesso a conoscenza di fondo parzialmente sovrapposta. Circa 60% se il LM ha solo accesso ai nomi dell'entità. Abbiamo mostrato che i modelli sono generalizzabili in più domini. Link al dataset: https://github.com/google-research-datasets/AltEntities.</sample>
    <sample id="473">Con wait-k, LA, CAAT e EDAtt. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="474">Yanis Labrak: LIA, Avignon Université. Adrien Bazoge: LS2N, Nantes Université. Richard Dufour: Clinique des données, CHU de Nantes. Mickael Rouvier: Zenidoc. Emmanuel Morin: LS2N, Nantes Université. Béatrice Daille: LS2N, Nantes Université. Pierre-Antoine Gourraud: LS2N, Nantes Université.</sample>
    <sample id="475">Non so chi sia il relatore o la relatrice. Potresti dare più informazioni?</sample>
    <sample id="476">Tre.</sample>
    <sample id="477">Attenzione come guida per la traduzione simultanea orale. Sara Papi, Matteo Negri, Marco Turchi. Università di Trento, Fondazione Bruno Kessler.</sample>
    <sample id="478">Simultaneous speech translation, SimulST, è il processo di tradurre un linguaggio parlato in un testo in un'altra lingua in tempo reale, permettendo la comunicazione interlinguistica.</sample>
    <sample id="479">I modelli SimulST attuali presentano problemi come l'addestramento di architetture specifiche, introducendo moduli aggiuntivi da ottimizzare.</sample>
    <sample id="480">I modelli SimulST attuali presentano i seguenti problemi: strutture architetturali specifiche sono solitamente addestrate, introducendo moduli aggiuntivi da ottimizzare. Procedure di addestramento lunghe e complesse, ad esempio, obiettivi di ottimizzazione diversi.</sample>
    <sample id="481">I modelli SimulST attuali presentano i seguenti problemi: - Architetture specifiche sono solitamente addestrate, introducendo moduli aggiuntivi da ottimizzare. - Procedure di addestramento lunghe e complesse, ad esempio, obiettivi di ottimizzazione diversi. - Addestramento e manutenzione di diversi modelli per raggiungere diversi regimi di latenza, ad esempio, 1s, 2s, ...</sample>
    <sample id="482">Cosa è la nostra soluzione?</sample>
    <sample id="483">Certo. Il contenuto inglese è tradotto in italiano come segue: "Quale è la nostra soluzione?". "Usare già esistenti offline ST modelli senza rieducazione o adottare una specifica architettura per SimulIST." "Usare solo un modello per ogni regime di latenza e gestire la latenza tramite parametri specifici." Se hai bisogno di ulteriori traduzioni o hai domande, non esitare a chiedere.</sample>
    <sample id="484">Certo! Ecco la traduzione in italiano: "Quale è la nostra soluzione?". "Utilizzare già esistenti modelli ST offline senza rieddurre o adottare una specifica architettura per SimulIST." "Utilizzare solo un modello per ogni regime di latenza e gestire la latenza tramite parametri specifici." "Sfruttare il know-how già acquisito dal modello attraverso il meccanismo di attenzione tra l'input audio e l'output testuale."</sample>
    <sample id="485">Decidere di emettere o non una traduzione parziale in base a dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia se la sua somma è inferiore a un certo limite, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili.</sample>
    <sample id="486">La nostra soluzione: EDAtt Decidere se emettere o non una traduzione parziale in base a dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia se la sua somma è inferiore a un certo limite, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili.</sample>
    <sample id="487">Decidere se emettere o non una traduzione parziale in base a dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia se la sua somma è inferiore a un soglia a, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili.</sample>
    <sample id="488">Decidere se emettere o non una traduzione parziale in base a dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia se la sua somma è inferiore a un certo limite, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili.</sample>
    <sample id="489">Decidere di emettere o non una traduzione parziale in base a dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia se la sua somma è inferiore a un certo limite, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili.</sample>
    <sample id="490">Decidere se emettere o non una traduzione parziale in base a dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia se la sua somma è inferiore a un certo limite, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili.</sample>
    <sample id="491">Decidere di emettere o non una traduzione parziale in base a dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia la sua somma è inferiore a un soglia α, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili.</sample>
    <sample id="492">La traduzione in italiano è: "Decidere di emettere o non una traduzione parziale in base a dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia se la sua somma è inferiore a un soglia a, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili."</sample>
    <sample id="493">La soluzione è chiamata EDAtt. Decide se emettere o non una traduzione parziale basandosi su dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia la sua somma è inferiore a un certo limite, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili.</sample>
    <sample id="494">La nostra soluzione: EDAtt. Decide se emettere o non una traduzione parziale basandosi su dove l'attenzione punta: una parola viene emessa se l'attenzione non è concentrata, ossia la sua somma è inferiore a un soglia a, verso le ultime λ frasi di discorso, il che significa che le informazioni ricevute sono abbastanza stabili. 01: Vado a parlare di... 02: Vado a parlare del clima.</sample>
    <sample id="495">Risultati principali: EDAtt.</sample>
    <sample id="496">Risultati principali: EDAtt. Misura di qualità. Misura di latenza.</sample>
    <sample id="497">Risultati principali: EDAtt
Main Results: EDAtt
La grafica mostra la relazione tra la misura di latenza, AL / AL-CA, in secondi, e il punteggio BLEU. L'asse x rappresenta la misura di latenza, mentre l'asse y rappresenta il punteggio BLEU. La grafica è etichettata come "a) en→de" e si trova alla pagina 30.</sample>
    <sample id="498">Risultati principali: EDAtt.</sample>
    <sample id="499">Risultati principali: EDAtt.</sample>
    <sample id="500">Risultati principali: EDAtt Strategie popolari applicate anche ai modelli offline. Stato dell'arte dell'architettura specificamente adattata per SimulST.</sample>
    <sample id="501">Risultati principali: EDAtt. Stato dell'arte dell'architettura specificamente adattata per SimulST. wait-k, LA, CAAT, EDAtt. BLEU. AL / AL_CA, s. a) en→de.</sample>
    <sample id="502">Risultati principali: EDAtt
EDAtt supera tutte le strategie applicate ai modelli offline.</sample>
    <sample id="503">Risultati principali: EDAtt. EDAtt supera tutte le strategie applicate ai modelli offline. EDAtt è la strategia più veloce se consideriamo il tempo effettivo trascorso.</sample>
    <sample id="504">Certo! Il contenuto in italiano è: "Volete scoprire di più? Leggete il nostro articolo per scoprire risultati ulteriori!". Se hai bisogno di altro, fammi sapere!</sample>
    <sample id="505">Sì, il set di dati è disponibile pubblicamente. Se hai bisogno di ulteriori informazioni, puoi contattare sliu775@gatech.edu.</sample>
    <sample id="506">MULTIINSTRUCT: Migliorare l'apprendimento zero-shot multimediali tramite l'addestramento delle istruzioni. Zhiyang Xu*, Ying Shen*, Lifu Huang Dipartimento di Informatica, Virginia Tech</sample>
    <sample id="507">Ecco la traduzione in italiano: "Modelli linguistici pre-allenati per compiti da sottosettore".Figura 2: Confronto tra l'addestramento di istruzioni con pre-allenamento e finetuning e il prompt.信用：Wei, Jason, 等人。"I modelli linguistici finetunati sono apprenditori a zero shot.".A) Pre-allenamento-finetuning, BERT, T5. Pre-allenato LM. Addestramento su compito A. Inferenza su compito A. Solitamente richiede molte esempi specifici per ciascun compito. Un modello specializzato per ciascun compito.B) Prompting, GPT-3. Pre-allenato LM. Migliorare le prestazioni tramite prompt di pochi shot o ingegneria del prompt. Inferenza su compito A.C) Addestramento di istruzioni, FLAN. Pre-allenato LM. Addestramento di istruzioni su molti compiti, B, C, D, ... Il modello impara a eseguire molt</sample>
    <sample id="508">Ecco la traduzione in italiano: "Modelli linguistici pre-allenati per compiti di flusso di lavoro".Figura 2: Confronto tra l'addestramento di istruzioni con pre-allenamento e finetuning e il prompt.</sample>
    <sample id="509">Certo, ma non hai fornito il contenuto inglese da tradurre. Puoi inviarmi il testo in inglese?</sample>
    <sample id="510">Insegnamento di istruzioni sui modelli pre-allenati multimediali.</sample>
    <sample id="511">Imbalance in Instructional Datasets between NLP and Multimodal. 1600+ Taski di istruzioni solo in lingua.</sample>
    <sample id="512">Imbalance in Instructional Datasets between NLP and Multimodal. 1600+ Taski di istruzioni solo in lingua. NO grandi set di dati multimediali, disponibili pubblicamente, di istruzioni. Wang, Yizhong, et al. "Benchmarking generalization via in-context instructions on 1,600+ language tasks." arXiv preprint arXiv:2302.00322.</sample>
    <sample id="513">Il contenuto inglese in italiano è: "MULTIINSTRUCT Il primo dataset di benchmark di ottimizzazione di istruzioni multimodale 62 diverse task multimodali diverse 10 gruppi ampi 5 istruzioni scritte da esperti". Se hai bisogno di ulteriori informazioni o hai altre domande, fammi sapere!</sample>
    <sample id="514">Il contenuto inglese in italiano è: "MULTIINSTRUCT Il primo dataset di benchmark di ottimizzazione di istruzioni multimodale 62 diverse task multimodali diverse 10 gruppi ampi 5 istruzioni scritte da esperti". Se hai bisogno di ulteriori informazioni o hai altre domande, fammi sapere!</sample>
    <sample id="515">OFA, One For All, è un modello pre-addestrato multimodale unificato in grado di eseguire sia compiti di comprensione che di generazione con un'unica o più modalità. OFA ha un vocabolario unificato per il linguaggio, i token immagine e le coordinate di una casella di confine.</sample>
    <sample id="516">Capitolo 1: Esempi di istanze da MULTIINSTRUCT per quattro compiti.</sample>
    <sample id="517">Capitolo 1: Esempi di istanze da MULTIINSTRUCT per quattro compiti.</sample>
    <sample id="518">Capitolo 1: Esempi di istanze da MULTIINSTRUCT per quattro compiti.</sample>
    <sample id="519">Tuning delle istruzioni multimediali.</sample>
    <sample id="520">Ecco la traduzione in italiano: "Multi-Modal Instruction Turning".* Costruzione del Dataset di Addestramento:.- Utilizza 53 task da 9 gruppi per l'addestramento.- Esegue una campionatura di 10.000 istanze per task.* Costruzione del Dataset di Test:.- Riserva l'intero gruppo di Reasoning comune per il test.- Seleziona ulteriori 5 task dal gruppo VQA e dal gruppo Varie.- Utilizza tutte le istanze nel set di test per ogni task.- Estrae casualmente 20 task dal set di test del dataset di Instruzioni Naturali come task non visti per NLP."Se hai bisogno di ulteriori chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="521">Ecco la traduzione in italiano: "Multi-Modal Instruction Turning".* Costruzione del Dataset di Addestramento:.- Utilizzare 53 compiti da 9 gruppi per l'addestramento.- Eseguire una campionatura di 10.000 istanze per compito.* Costruzione del Dataset di Test:.- Riservare l'intero gruppo di Reasoning comune per il test.- Selezionare ulteriori 5 compiti da VQA e gruppi variegati.- Utilizzare tutte le istanze nel set di test per ogni compito.- Eseguire una campionatura casuale di 20 compiti dal set di test del dataset di Instruzioni Naturali come compiti non visti per NLP."Se hai bisogno di ulteriori chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="522">Dettagli di implementazione

• Dettagli di addestramento:
   - Modello pre-addestrato OFA-Large, 472M
   - Mescolare tutte le istanze per tutte le task
   - Ogni istanza è combinata casualmente con uno dei cinque modelli di istruzioni

• Dettagli di test:
   - Per ogni task, eseguiamo un totale di cinque esperimenti valutando il modello utilizzando uno dei cinque modelli di istruzioni in ogni esperimento
   - Rapportiamo la media e il massimo delle prestazioni e la deviazione standard delle prestazioni in tutti e cinque gli esperimenti</sample>
    <sample id="523">Dettagli di implementazione.- Dettagli di addestramento:.- Modello pre-addestrato OFA-Large, 472M.- Mescolare tutte le istanze per tutte le task.- Ogni istanza è combinata casualmente con uno dei cinque modelli di istruzioni.- Dettagli di test:.- Per ogni task, eseguiamo un totale di cinque esperimenti valutando il modello utilizzando uno dei cinque modelli di istruzioni in ciascun esperimento.- Rappresentiamo la media, il massimo e la deviazione standard del rendimento attraverso tutti e cinque gli esperimenti.</sample>
    <sample id="524">Dettagli di implementazione

• Dettagli di addestramento:
   - Modello pre-addestrato OFA-Large, 472M
   - Mescolare tutte le istanze per tutte le task
   - Ogni istanza è combinata casualmente con uno dei cinque modelli di istruzioni

• Dettagli di test:
   - Per ogni task, eseguiamo un totale di cinque esperimenti valutando il modello utilizzando uno dei cinque modelli di istruzioni in ciascun esperimento.
   - Rapportiamo la media e il massimo delle prestazioni e la deviazione standard delle prestazioni in tutti e cinque gli esperimenti.</sample>
    <sample id="525">Ecco la traduzione in italiano:</sample>
    <sample id="526">Sensibilità. Quanto il modello è sensibile alla varietà di istruzioni per la stessa compito:.Abilità di produrre consistentemente i medesimi risultati per la stessa compito, indipendentemente da lievi variazioni nella formulazione delle istruzioni.</sample>
    <sample id="527">Efficacia della Tuning delle Istruzioni su MULTIINSTRUCT</sample>
    <sample id="528">Efficacia della Tuning delle Istruzioni su MULTIINSTRUCT Tabella 1: Prestazioni Zero-shot sul Raziamento Multimodale del Comune Senso. La miglior prestazione è in grassetto. Tabella 2: Prestazioni Zero-shot sul Rispondere alle Domande e sulle Cose Varie. La miglior prestazione è in grassetto.</sample>
    <sample id="529">Effetto dell'aumento dei cluster di compiti di istruzioni multimodali. * Img Und o VQA + Comprensione dell'immagine * Grounding o Matchaggio e generazione fondati * MISC, ITM o Ordinamento temporale + Varie + Matchaggio di testo immagine * Relazione o Relazione visiva * Region o Comprensione della regione * NLP o Compiti di NLP</sample>
    <sample id="530">Effetto delle diverse istruzioni sulla tunnaggio delle istruzioni. - OFA finetunato su 5 istruzioni raggiunge una prestazione aggregata molto maggiore su tutte le task di valutazione e mostra una sensibilità inferiore. Tabella 3: Effetto di un numero diverso di istruzioni. Prestazioni di OFA finetunato su diversi numeri di istruzioni.</sample>
    <sample id="531">Effetto delle strategie di ottimizzazione fine su sensibilità del modello. • L'ottimizzazione fine su MultiInstruct può significativamente ridurre la sensibilità di OFA. • L'apprendimento a trasferimento dal dataset di Instruzioni Naturali può ulteriormente ridurre la sensibilità del modello. Figura 4: Sensibilità del modello su valutazioni di valutazione non viste. Il valore più basso è migliore.</sample>
    <sample id="532">Ecco la traduzione in italiano: "Efficienza zero-shot sui compiti di NLP". - L'ottimizzazione delle istruzioni su MultiInstruct può migliorare l'efficienza zero-shot su compiti di NLP non visti. - La strategia di apprendimento a trasferimento MixedInstruct può meglio preservare la capacità zero-shot ottenuta sul dataset Natural Instructions. Tabella 4: Efficienza zero-shot sui compiti di NLP. La prestazione è riportata in Rouge-L e la migliore prestazione è in grassetto.</sample>
    <sample id="533">Conclusione
- Primo dataset di grandi dimensioni per l'addestramento multi-modale con istruzioni.
  - Contiene 62 task multi-modali da 10 categorie ampie.
- Notevolmente migliora la capacità zero-shot di OFA tramite l'addestramento con istruzioni.
- Esplora diverse tecniche di apprendimento trasferibile e mostra i loro benefici.
- Progetta una nuova metrica di sensibilità.</sample>
    <sample id="534">C'è ancora una cosa! Stiamo raccogliendo un dataset di addestramento di istruzioni multimodali molto più grande con circa 150 compiti aggiuntivi di visione-lingua e li pubblicheremo presto!</sample>
    <sample id="535">I autori dell'articolo sono affiliati all'Università di Trento e alla Fondazione Bruno Kessler.</sample>
    <sample id="536">Mohammad Javad Hosseini.</sample>
    <sample id="562">I giudizi di accettabilità dei modelli di linguaggio non sono sempre robusti rispetto al contesto.</sample>
    <sample id="563">I giudizi di accettabilità dei modelli di linguaggio non sono sempre robusti rispetto al contesto.</sample>
    <sample id="564">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano le differenze relative nelle probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio: BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P, 1, &gt; P, 2, SyntaxGym 1. Nessun cliente ... ha speso alcun denaro. 2. *Il cliente ... ha speso alcun denaro. P, 1.any, &gt; P, 2.any, CrowS 1. Frase stereotipica. 2. Frase non stereotipica. P, 1, &gt; P, 2,</sample>
    <sample id="565">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano le differenze relative nelle probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio:.BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P,1, &gt; P,2, SyntaxGym 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P,1.any, ≥ P,2.any, CrowS 1. Frase stereotipica. 2. Frase non stereotipica. P,1, &gt; P,2,</sample>
    <sample id="566">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio:.BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P,1, &gt; P,2,SYNTAXGYM 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P,1.any, ≥ P,2.any, CROWS 1. Frase stereotipica. 2. Frase non stereotipica. P,1, &gt; P,2,</sample>
    <sample id="567">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano le differenze relative nelle probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio: BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P,1, &gt; P,2, SyntaxGym 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P,1.any, &gt; P,2.any, CrowS 1. Frase stereotipica. 2. Frase non stereotipica. P,1, &gt; P,2,</sample>
    <sample id="568">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio: BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P,1, &gt; P,2, SyntaxGym 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P,1.any, &gt; P,2.any, Crows 1. Le donne sono terribili per il lavoro manuale. 2. Gli uomini sono terribili per il lavoro manuale. P,1, &gt; P,2, Questi giudizi sono stabili con un lungo contesto precedente?</sample>
    <sample id="569">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio: BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P,1, &gt; P,2, SyntaxGym 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P,1.any, &gt; P,2.any, Crows 1. Le donne sono terribili per il lavoro manuale. 2. Gli uomini sono terribili per il lavoro manuale. P,1, &gt; P,2, Questi giudizi sono stabili con un contesto precedente lungo?</sample>
    <sample id="570">Rivedere il paradigma delle coppie minimali. Le valutazioni del paradigma delle coppie minimali, MPP, dei modelli di linguaggio utilizzano differenze relative in probabilità di sequenza per valutare il conoscere astratto dei modelli di linguaggio: BLiMP 1. Molti persone stavano aiutando loro stessi. 2. *Molti persone stavano aiutando lei. P,1, &gt; P,2, SyntaxGym 1. Nessun cliente ... ha speso denaro. 2. *Il cliente ... ha speso denaro. P,1.any, &gt; P,2.any, Crows 1. Le donne sono terribili per il lavoro manuale. 2. Gli uomini sono terribili per il lavoro manuale. P,1, &gt; P,2, Questi giudizi sono stabili con un contesto precedente lungo?</sample>
    <sample id="571">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spazio di Candidati Prefixes.Matched: Convenzione Soggetto, Verga.Accettabile, Conforme.Unaccettabile,Non conforme.What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer? * What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?BLIMP, Isola Adjunct.GPT2, Famiglia OPT - 125M a 6.7B</sample>
    <sample id="572">Approccio Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità. Test Suite: Convenzione Soggetto-Verga Spazio di Candidati Prefixes Matched Mismatched Subj. Verb. Agreement Matched Mismatched Island Effects Filter-gaps Binding Wikipedia ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...</sample>
    <sample id="573">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'acceptabilità.Test Suite: Convenzione Soggetto-Verga.Spazio di Candidati Prefixes.Matched: Convenzione Soggetto, Verga.Accettabile, Matched.Unaccettabile.PLM, Prefix &gt;? PLM, Prefix.Sampl.What could Jessica vendere prima di notare queste luci? Che cosa aveva detto Aaron mentre puliva il museo? Da dove Rose poteva fuggire prima di tornare a questo cliente?What could Jessica vendere prima di notare queste luci? Che cosa aveva detto Aaron mentre puliva il museo? Da dove Rose poteva fuggire prima di tornare a questo cliente?Island EffectsFilter-gapsBindingWikipediaBLIMP, Isola Adjunct.GPT2, Famiglia OPT - 125M a 6.7B</sample>
    <sample id="574">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spacce di Candidati Prefixes.Matched: Convenzione Soggetto, Verba.Unmatched: Effetti dell'isola, vuoti di filtro, legame, Wikipedia...Accettabile, Matched.Che cosa potrebbe vendere Jessica prima di notare queste luci? Che cosa ha suonato Aaron mentre puliva il museo? Da dove potrebbe fuggire Rose prima di tornare a questo cliente?Che cosa potrebbe vendere Jessica prima di notare queste luci? Che cosa ha suonato Aaron mentre puliva il museo? Da dove potrebbe fuggire Rose prima di tornare a questo cliente?BLIMP, Isola Adjunct.GPT2, Famiglia OPT - 125M a 6.7B</sample>
    <sample id="575">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spazio di Candidati Prefixes.Matched: Convenzione Soggetto, Verba.Unmatched: Effetti dell'isola, vuoti di filtro, legame, Wikipedia.GPT2, OPT famiglia - 125M a 6.7B</sample>
    <sample id="576">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spacce di Candidati Prefixes.Matched: Convenzione Soggetto-Verga.Mismatched: Effetti dell'isola, vuoti di filtro, legame, Wikipedia.Esempi: "Chi potrebbe fuggire di Rose prima di tornare a questo cliente?" "C'era un documentario sulla musica irritante Allison. Non c'erano legislatori che lavoravano duramente. Chi potrebbe fuggire di Rose prima di tornare a questo cliente?" "C'era un documentario sulla musica irritante Allison. Non c'erano legislatori che lavoravano duramente. Chi potrebbe fuggire di questo cliente prima di tornare?"BLIMP, quantificatori esistenziali "there"BLIMP, isola di adiuvante.GPT2, famiglia OPT - 125M a 6.7B</sample>
    <sample id="577">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spazio di Candidati Prefixes.Matched: Convenzione Soggetto-Verga.Mismatched: Effetti dell'isola, vuoti di filtro, legame, Wikipedia.Esempi: "Chi potrebbe fuggire di Rose prima di tornare a questo cliente?" "C'era un documentario sulla musica che irritava Allison. Non c'erano legislatori che lavoravano duramente. Chi potrebbe fuggire di Rose prima di tornare a questo cliente?" "C'era un documentario sulla musica che irritava Allison. C'erano molti legislatori che lavoravano duramente. Chi potrebbe fuggire di questo cliente prima di tornare?"BLiMP, quantificatori esistenziali "there"BLiMP, isola di adiuvante.GPT2, famiglia OPT - 125M a 6.7B</sample>
    <sample id="578">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'acceptabilità.Test Suite: Convenzione Soggetto-Verga.Spacce di Candidati Prefixes.Matched: Convenzione Soggetto, Verga.Unmatched: Effetti dell'isola, vuoti, legami, Wikipedia.GPT2, Famiglia OPT - 125M a 6.7B</sample>
    <sample id="579">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'accettabilità.Test Suite: Convenzione Soggetto-Verga.Spazio dei Candidati Prefixes.Matched: Convenzione Soggetto, Verga.Unmatched: Effetti dell'isola, vuoti, legami, Wikipedia.GPT2, Famiglia OPT - 125M a 6.7B</sample>
    <sample id="580">Approccio.Testare se le giudicazioni MPP variano in funzione della lunghezza del contesto, del match strutturale e dell'acceptabilità.Test Suite: Convenzione Soggetto-Verga.Spacce di Candidati Prefixes.Matched: Convenzione Soggetto, Verga.Unmatched: Effetti dell'isola, vuoti, legami, Wikipedia.GPT2, Famiglia OPT - 125M a 6.7B</sample>
    <sample id="581">I giudizi MPP sono robusti per lunghezze di contesto arbitrarie. Effettuiamo valutazioni MPP con diversi contesti - accettabili/non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. BLIMP, OPT 6.7B.</sample>
    <sample id="582">I giudizi MPP sono robusti per lunghezze di contesto arbitrarie. Effettuiamo valutazioni MPP con diversi contesti - accettabili/non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. BLIMP, OPT 6.7B.</sample>
    <sample id="583">Ecco la traduzione in italiano: "2. Sentenze accettabili/non accettabili MPP nel contesto elevano/baiono il rendimento della giudicazione. Effettuiamo valutazioni MPP con diversi contesti - accettabili/non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. BLIMP, OPT 6.7B Strategia di prefisso Acc. (Corrispondente) Unacc. (Corrispondente) Acc. (Non corrispondente) Unacc. (Non corrispondente) C'era un documentario sulla musica che irritava Allison. Non c'erano legislatori che lavoravano duramente. Da dove potrebbe fuggire Rose prima di tornare a questo cliente? * C'era un documentario sulla musica che irritava Allison. Non c'erano legislatori che lavoravano duramente. Da dove potrebbe fuggire Rose prima di tornare a? C'era un documentario su ogni musica che irritava Allison. C'erano molti legislatori che lavoravano duramente. Da</sample>
    <sample id="584">Ecco la traduzione in italiano: "2. Frasi MPP accettabili/non accettabili nel contesto elevano/baiono il rendimento della giudicazione. Effettuiamo valutazioni MPP con contesti diversi - accettabili/non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. BLIMP, OPT 6.7B Strategia di prefisso: * Acc. (Corrispondente) * Unacc. (Corrispondente) * Acc. (Non corrispondente) * Unacc. (Non corrispondente) C'era un documentario sulla musica che irritava Allison. Non c'erano legislatori che lavoravano duramente. Da dove potrebbe fuggire Rose prima di tornare a questo cliente? * C'era un documentario sulla musica che irritava Allison. Non c'erano legislatori che lavoravano duramente. Da dove potrebbe fuggire Rose prima di tornare a? * C'era ogni documentario sulla musica che irritava Allison. C'erano molti legislatori che lavorav</sample>
    <sample id="585">Ecco la traduzione in italiano: "2. Frasi MPP accettabili/non accettabili nel contesto elevano/baiono il rendimento della giudicazione. Effettuiamo valutazioni MPP con diversi contesti - accettabili/non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. BLIMP, OPT 6.7B Strategia di prefisso Acc. (Corrispondente) Unacc. (Corrispondente) Acc. (Non corrispondente) Unacc. (Non corrispondente) C'era un documentario sulla musica che irritava Allison. Non c'erano legislatori che lavoravano duramente. Da quale cliente potrebbe Rose fuggire prima di tornare a questo cliente? * C'era un documentario sulla musica che irritava Allison. Non c'erano legislatori che lavoravano duramente. Da quale cliente potrebbe Rose fuggire prima di tornare a questo cliente? C'era un documentario su ogni musica che irritava Allison. C'erano molti legislatori che lavoravano</sample>
    <sample id="586">Ecco la traduzione in italiano: "Sentenze MPP accettabili/non accettabili con struttura corrispondente che influenzano più gravemente il rendimento del modello. Effettuiamo valutazioni MPP con contesti diversi - accettabili/non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. BLIMP, OPT 6.7B Strategia di prefisso: Acc. (Corrispondente) Unacc. (Corrispondente) Acc. (Non corrispondente) Unacc. (Non corrispondente) 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2</sample>
    <sample id="587">Ecco la traduzione in italiano: "Sentenze MPP accettabili/non accettabili con struttura corrispondente che influenzano maggiormente le prestazioni del modello. Effettuiamo valutazioni MPP con contesti diversi - accettabili/non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. BLIMP, OPT 6.7B Strategia di prefisso: Acc. (Corrispondente) Unacc. (Corrispondente) Acc. (Non corrispondente) Unacc. (Non corrispondente) 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2 3 2 1 2</sample>
    <sample id="588">Ecco la traduzione in italiano: "Sentenze MPP accettabili/non accettabili con struttura corrispondente che influenzano maggiormente le prestazioni del modello. Effettuiamo valutazioni MPP con contesti diversi - accettabili/non accettabili; struttura corrispondente/non corrispondente - di lunghezze fino a 900 token. BLIMP, OPT 6.7B Strategia di prefisso: * Acc. (Corrispondente) * Unacc. (Corrispondente) * Acc. (Non corrispondente) * Unacc. (Non corrispondente) * Wiki (Non corrispondente) 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1 2 3 3 2 1</sample>
    <sample id="589">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di linguaggio?Modifichiamo le frasi di contesto in modo da preservare la struttura rilevante e chiediamo se i modelli sono altrettanto sensibili a queste frasi.- Adverbio di prefisso/suffisso: "Tuttavia, &lt;sent&gt;.".- Adverbio di prefisso lungo: "Prima di tutto, &lt;sent&gt;.".- Clausola aggiuntiva: "Indipendentemente da ciò che X ne pensa, &lt;sent&gt;.".- Citazione: "Ieri, X ha detto, &lt;sent&gt;."</sample>
    <sample id="590">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di linguaggio?Modifichiamo le frasi di contesto in modo da preservare la struttura rilevante e chiediamo se i modelli sono altrettanto sensibili a queste frasi.- Prefissi/suffissi avverbi: "Tuttavia, &lt;sent&gt;.". - Prefissi avverbi lunghi: "Prima di tutto, &lt;sent&gt;.". - Clauses aggiunte: "Indipendentemente da quello che X ne pensa, &lt;sent&gt;." - Citazioni: "Ieri, X ha detto, &lt;sent&gt;."</sample>
    <sample id="591">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di linguaggio? Perturbiamo le frasi di contesto in modi che preservano la struttura rilevante, e chiediamo se i modelli sono altrettanto sensibili a queste frasi. - Prefissi/suffissi avverbi: "Tuttavia, &lt;sent&gt;." - Prefissi avverbi lunghi: "Prima di tutto, &lt;sent&gt;." - Clausola aggiunta: "Indipendentemente da quello che X ne pensa, &lt;sent&gt;." - Citazione: "Ieri, X ha detto, &lt;sent&gt;."</sample>
    <sample id="592">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di linguaggio?Modifichiamo le frasi di contesto in modo da preservare la struttura rilevante e chiediamo se i modelli sono altrettanto sensibili a queste frasi.- Prefissi/suffissi avverbi: "Tuttavia, &lt;sent&gt;.". - Avverbi di lunghezza prefisso: "Prima di tutto, &lt;sent&gt;.". - Aggiungere una clausola: "Indipendentemente da ciò che X ne pensa, &lt;sent&gt;.". - Citazione: "Ieri, X ha detto, '&lt;sent&gt;.'.I modelli sono sensibili a frasi modificate in modi simili.</sample>
    <sample id="593">Perché i prefissi corrispondenti influenzano le giudicazioni del modello di linguaggio?Modifichiamo le frasi di contesto in modo da preservare la struttura rilevante e chiediamo se i modelli sono altrettanto sensibili a queste frasi.Prefissi/suffissi avverbi: "Tuttavia, &lt;sent&gt;."Prefissi avverbi lunghi: "Prima di tutto, &lt;sent&gt;."Classe aggiunta: "Indipendentemente da quello che X ne pensa, &lt;sent&gt;."Citazione: "Ieri, X ha detto, &lt;sent&gt;."I modelli sono sensibili a frasi modificate in modi simili.</sample>
    <sample id="594">Istruzioni: Traduci il contenuto inglese in italiano.</sample>
    <sample id="595">Istruzioni: Traduci il contenuto inglese in italiano.</sample>
    <sample id="596">Ecco il contenuto tradotto in italiano:.- I modelli di linguaggio sono sensibili a feature sintattiche/semantiche latenti condivise tra frasi.- Le valutazioni MPP con input di singole frasi brevi non riescono a catturare completamente il sapere astratto dei modelli di linguaggio.</sample>
    <sample id="597">Nel primo passaggio del metodo, i token di input vengono mappati nei token di tag.</sample>
    <sample id="598">55.000 script.</sample>
    <sample id="626">Non c'è una risposta diretta in questa tabella per DEplain. Potresti cercare ulteriori informazioni o specificare meglio il contesto?</sample>
    <sample id="627">L'apprendimento scarsamente supervisionato allevia il problema dell'annotazione.</sample>
    <sample id="628">Non c'è informazione sufficiente nel contenuto per rispondere a questa domanda. Potresti fornire ulteriori dettagli?</sample>
    <sample id="629">Il set di dati CoNLL++ è stato creato raccolgendo notizie Reuters del 2020 e annotandole secondo le linee guida di annotazione CoNLL-2003.</sample>
    <sample id="630">XSemPLR: Analisi semantica interlinguistica in diverse lingue naturali e rappresentazioni del significato. Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang. PennState, Amazon.</sample>
    <sample id="631">Parsa semantica. La parsa semantica è una task per costruire una rappresentazione semantica delle query dell'utente, come SQL e Lambda Calculus. Quali paesi in Europa hanno almeno 3 produttori di automobili? Seleziona T1.country_name. Da countries come T1 JOIN continents come T2 ON T1.continent = T2.cont_id JOIN car_makers come T3 ON T1.country_id = T3.country WHERE T2.continent = 'Europe' GROUP BY T1.country_name HAVING COUNT, * &gt;= 3. Query utente e la sua query SQL corrispondente, a sinistra, vs. query utente e la sua rappresentazione Lambda Calculus corrispondente, a destra. Quali giocatori hanno fatto meno di tre assist in una stagione? call SW.listValue, call SW.getProperty, call SW.filter, call SW.ensureNumericProperty, call SW.ensureNumericEntity, call SW.domain, call.</sample>
    <sample id="632">La traduzione in italiano è: "L'analisi semantica interlinguistica è una task che traduce query in diverse lingue naturali in diverse rappresentazioni di significato."</sample>
    <sample id="633">La traduzione in italiano è: "La semantica parallela è una task che traduce query in diverse lingue naturali in diverse rappresentazioni di significato."</sample>
    <sample id="634">Parsing Semantico Interlingua e Multilingua. I modelli CLSP esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certe lingue naturali.</sample>
    <sample id="635">I modelli di Parsing Semantico Cross-linguale esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certe lingue naturali.</sample>
    <sample id="636">Parsaggio semantico interlinguale. I modelli CLSP esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certe rappresentazioni di significato.</sample>
    <sample id="637">Parsaggio semantico interlinguistico. I modelli CLSP esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certe rappresentazioni di significato.</sample>
    <sample id="638">Parsaggio semantico interlinguale. I modelli CLSP esistenti sono proposti e valutati separatamente su dataset di compiti e applicazioni limitati. Ad esempio: mancanza di copertura su certi modelli neurali.</sample>
    <sample id="639">Ecco la traduzione in italiano: "XSemPLR - Offriamo un dataset unificato XSemPLR per il parsing semantico interlinguale in diverse lingue naturali e rappresentazioni di significato. Contiene: - 9 dataset in diversi domini - 5 task di parsing semantico - 8 rappresentazioni di significato - 22 lingue naturali in 15 famiglie linguistiche"</sample>
    <sample id="640">Ecco la traduzione in italiano: "XSemPLR - Offriamo un dataset unificato XSemPLR per il parsing semantico interlinguale in diverse lingue naturali e rappresentazioni di significato. Contiene: - 9 dataset in diversi domini - 5 task di parsing semantico - 8 rappresentazioni di significato - 22 lingue naturali in 15 famiglie linguistiche"</sample>
    <sample id="641">Impariamo a tradurre il contenuto inglese in italiano.</sample>
    <sample id="642">Impariamo a tradurre il contenuto inglese in italiano.</sample>
    <sample id="643">Impariamo insieme a tradurre il contenuto inglese in italiano.</sample>
    <sample id="644">Impostazioni dell'esperimento Consideriamo le sei impostazioni per l'addestramento e l'valutazione. Modello monolinguale: La lingua di origine è la stessa della lingua di destinazione, ad esempio Germano-germano. Abbiamo anche testato la configurazione di modello monolinguale Few-shot addestrando modelli monolinguali con solo 10% dei dati di addestramento. Addestramento Germano, Few-shot Modello Germano SQL Inferenza Germano Modello Germano SQL</sample>
    <sample id="645">Impostazioni dell'esperimento Consideriamo le sei impostazioni per l'addestramento e l'valutazione. Modello monolinguale: La lingua di origine è la stessa della lingua di destinazione, ad esempio Germano-germano. Abbiamo anche testato la configurazione Monolingual Few-shot addestrando modelli monolinguali con solo 10% dei dati di addestramento. Addestramento Germano, Few-shot Modello Germano SQL Inferenza Germano Modello Germano SQL</sample>
    <sample id="646">Impostazioni dell'esperimento Consideriamo le sei impostazioni per l'addestramento e l'valutazione. Modello monolinguale: La lingua di origine è la stessa della lingua di destinazione, ad esempio Germano-germano. Abbiamo anche testato la configurazione Monolingual Few-shot addestrando modelli monolinguali con solo 10% dei dati di addestramento. Addestramento Germano, Few-shot Modello Germano SQL Inferenza Germano Modello Germano SQL</sample>
    <sample id="647">Impariamo a tradurre il contenuto inglese in italiano.</sample>
    <sample id="648">Impariamo a tradurre il contenuto inglese in italiano.</sample>
    <sample id="649">Impariamo a tradurre il contenuto inglese in italiano.</sample>
    <sample id="650">Impariamo a tradurre il contenuto inglese in italiano.</sample>
    <sample id="651">Impariamo a tradurre il contenuto inglese in italiano.</sample>
    <sample id="652">L'analisi dei modelli monolingui è stata condotta su due gruppi di modelli nel contesto di Monolingua. Il primo gruppo è Enc-PTR: Encoder multilingue con decodificatori basati su pointer, che include XLM-R + PTR e mBERT + PTR. Il secondo gruppo è Enc-Dec: Encoder-decodificatori multilingue preaddestrati, che comprende mBART e mT5. Si è scoperto che Enc-Dec, mT5, ha ottenuto la migliore prestazione su tutti i dataset.</sample>
    <sample id="653">L'analisi dei modelli monolingui è stata condotta su due gruppi di modelli nel contesto di Monolingual Setting. Il primo gruppo è Enc-PTR, che utilizza encoder multilingue con decoder basato su pointer, come XLM-R + PTR e mBERT + PTR. Il secondo gruppo è Enc-Dec, che utilizza modelli di encoder-decoder multilingue, come mBART e mT5. Si è scoperto che Enc-Dec, in particolare mT5, ottiene la migliore prestazione su tutti i dataset.</sample>
    <sample id="654">L'analisi dei modelli monolingui è stata condotta su due gruppi di modelli nel contesto di Monolingual Setting. Il primo gruppo è Enc-PTR: Encoder multilingue con decodificatori basati su pointer, che include XLM-R + PTR e mBERT + PTR. Il secondo gruppo è Enc-Dec: Encoder-decodificatori multilingue preaddestrati, che comprende mBART e mT5. Si è scoperto che Enc-Dec, mT5, ha ottenuto la migliore prestazione su tutti i dataset.</sample>
    <sample id="655">L'analisi dei modelli monolinguistici è stata condotta su due gruppi di modelli in un contesto monolinguistico. Il primo gruppo è composto da encoder multilingue preaddestrati con decoder basati su pointer, come XLM-R + PTR e mBERT + PTR. Il secondo gruppo è composto da modelli multilingue preaddestrati encoder-decoder, come mBART e mT5. Si è scoperto che mT5, nel gruppo Enc-Dec, ha ottenuto la migliore prestazione su tutti i dataset.</sample>
    <sample id="656">L'analisi dell'addestramento multilingue. Valutiamo su mT5 e XLM-R + PTR in un contesto multilingue. Enc-Dec/Enc-PTR, mT5/XLM-R, può essere migliorato addestrando in una miscela di varie lingue. Monolingue XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 58.16 mT5 53.15 74.26 50.73 91.65 66.29 30.15 65.16 81.83 10.29 58.16 Multilingue XLM-R+PTR 39.72 71.35 40.20 85.91 61.03 30.79 61.82 81</sample>
    <sample id="657">L'analisi dell'allenamento multilingue. Valutiamo su mT5 e XLM-R + PTR in un contesto multilingue. Enc-Dec/Enc-PTR, mT5/XLM-R, può essere migliorato con l'allenamento in una miscela di varie lingue. Monolingue XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 58.16 mT5 53.15 74.26 50.73 91.65 66.29 30.15 65.16 81.83 10.29 58.16 Multilingue XLM-R+PTR 39.72 71.35 40.20 85.91 61.03 30.79 61.82 81.</sample>
    <sample id="658">Analisi dell'addestramento multilingue. - Valutiamo su mT5 e XLM-R + PTR in un contesto multilingue. - La maggior parte delle principali NL può ottenere un miglioramento, eccetto che il prestigio dell'inglese cala in 7 dataset e aumenta in 3 dataset. Questo è noto come "Curso della multilinguistica".</sample>
    <sample id="659">Analisi dell'addestramento multilingue. - Valutiamo su mT5 e XLM-R + PTR in un contesto multilingue. - La maggior parte delle principali NLP può ottenere un miglioramento, eccetto che le prestazioni dell'inglese diminuiscono in 7 dataset e aumentano in 3 dataset. Questo è noto come "Curso della multilinguistica".</sample>
    <sample id="660">Gap di prestazione tra lingue diverse. Linea blu: Trasferimento tra lingue in pochi colpi. Linea arancione: Trasferimento tra lingue in zero colpi. Linea verde: Impostazione monolingua. MTOP Schema2QA Overnight NLMaps MCWQ ATIS Spider Geoquery Geoquery/lamb Geoquery/prolog Geoquery/funql Geoquery/sql</sample>
    <sample id="661">Vuoi tradurre il contenuto inglese in italiano?</sample>
    <sample id="662">Vuoi tradurre il contenuto inglese in italiano?</sample>
    <sample id="663">Risultati e Conclusioni (Sezione 4 del Paper)• Enc-Dec, mT5, supera il lavoro precedente o raggiunge risultati paragonabili. • Pre-Allenamento sulle NL inglesi può notevolmente migliorare le prestazioni del few-shot su NL di destinazione. • I modelli multilingue LLM, Codex e BLOOM, sono ancora insufficienti per le task di parsing semantico interlingue. • L'apprendimento da trasferimento cinese e l'allenamento monolingue inglese, En -&gt; En, hanno il gap di prestazioni più grande, mentre il tedesco ha solitamente il più piccolo. • FunQL supera le altre tre rappresentazioni di significato, mentre SQL ottiene la peggior prestazione.</sample>
    <sample id="664">Risultati e Trovati (Sezione 4 del Paper)• Enc-Dec, mT5, supera il lavoro precedente o raggiunge risultati paragonabili. • Pretraining sulle NL inglesi può significativamente migliorare le prestazioni del few-shot su NL di target. • I modelli multilingue LLMs, Codex e BLOOM, sono ancora insufficienti per le task di parsing semantico interlingue. • L'apprendimento da trasferimento cinese e l'addestramento monolingue inglese, En -&gt; En, hanno il gap di prestazioni più grande, mentre il tedesco ha solitamente il più piccolo. • FunQL supera le altre tre rappresentazioni di significato, mentre SQL ottiene la peggior prestazione.</sample>
    <sample id="665">Conclusione - Abbiamo costruito XSemPLR, un benchmark unificato per la parsing semantica interlinguistica con diverse lingue naturali e rappresentazioni di significato. - Abbiamo condotto una studio di benchmarking comprensivo su tre tipi rappresentativi di modelli di linguaggio multilingue. - I nostri risultati mostrano che mT5 con addestramento monolingue dà i migliori risultati, mentre notevolmente i modelli multilingue LLM sono ancora insufficienti per eseguire task di parsing semantico interlinguistico. Inoltre, la differenza di prestazioni tra addestramento monolingue e apprendimento trasferimento interlinguistico rimane ancora significativa.</sample>
    <sample id="666">Conclusione - Abbiamo costruito XSemPLR, un benchmark unificato per la parsing semantica interlinguistica con diverse lingue naturali e rappresentazioni di significato. - Abbiamo condotto una studio di benchmarking comprensivo su tre tipi rappresentativi di modelli di linguaggio multilingue. - I nostri risultati mostrano che mT5 con addestramento monolingue dà i migliori risultati, mentre notevolmente i modelli multilingue LLM sono ancora insufficienti per eseguire compiti di parsing semantico interlinguistico. Inoltre, la differenza di prestazioni tra addestramento monolingue e apprendimento a trasferimento interlingue rimane ancora significativa. Link - Benvenuti a visitare il nostro articolo e il codice! - Link al documento: https://arxiv.org/pdf/2306.04085.pdf - Link al codice: https://github.com/psunlpgroup/xsemplr</sample>
    <sample id="667">I lavori connessi sono: "Parameter-based watermark", "Lexical watermark", "Backdoor-based watermark" e "Adversarial-based watermark". Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="668">No, gli LLM multilingue come Codex o Bloom sono ancora insufficienti per il CLSP.</sample>
    <sample id="695">Induce l'ambiguità durante l'addestramento.</sample>
    <sample id="696">L'equità di un modello NLP a valle viene definita come la capacità del modello di non produrre output discriminatori basati su fattori come genere, etnia, età, orientamento sessuale, etc.</sample>
    <sample id="697">Non so chi sia il relatore o la relatrice. Potresti dare più informazioni?</sample>
    <sample id="698">Non so chi sia il relatore. Potresti dare più informazioni?</sample>
    <sample id="699">Myra Cheng.</sample>
    <sample id="700">Il tropicalismo indica culture, tradizioni, orgoglio e esotismo per gruppi marcati. Questo definisce solo le identità di questi gruppi. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="701">Gli autori hanno elaborato le rappresentazioni umane dei gruppi target attraverso narrativi essenzializzanti e rappresentazioni positive perniciose.</sample>
    <sample id="702">P-CXMI.</sample>
    <sample id="703">DrBERT è costruito da zero con la costruzione completa del modello, mentre ChuBERT è costruito da zero.</sample>
    <sample id="751">Quattro.</sample>
    <sample id="752">Ehm, il trasferimento iterativo dell'apprendimento è un approccio in cui si ottiene un modello nuovo utilizzando il vecchio modello e il nuovo dataset. Questo processo si ripete in modo iterativo. Se hai altre domande su questo argomento, sentiti libero di chiedere!</sample>
    <sample id="753">L'obiettivo del set di dati è comprendere il linguaggio degli utenti quando prendono una scelta.</sample>
    <sample id="754">Non c'è informazione su come un utente malintenzionato possa estrarre i parametri del modello attraverso un EaaS nel contenuto fornito. Potresti avere bisogno di ulteriori dettagli o riferimenti per rispondere a questa domanda.</sample>
    <sample id="755">Tre.</sample>
    <sample id="756">Non c'è informazione su quanti annotatori sono stati impiegati per creare il set di dati iniziale.</sample>
    <sample id="757">Sebastin Santy e Jenny T. Liang sono dell'University of Washington, Ronan Le Bras è dell'Allen Institute for AI, Katharina Reinecke è dell'University of Washington e Maarten Sap è di Carnegie Mellon University.</sample>
    <sample id="758">"I saw Bart and Lisa; Homer came and sneezed."</sample>
    <sample id="759">Non c'è informazione sufficiente nel contenuto per rispondere a questa domanda. Potresti fornire ulteriori dettagli?</sample>
    <sample id="760">Perché le valutazioni basate solo su piccole parti del contesto non sono sufficienti a comprendere l'intera comprensione del modello.</sample>
    <sample id="761">Sì, la formazione multilingue ha causato un calo delle prestazioni rispetto al modello inglese monolingue in 7 dataset.</sample>
    <sample id="762">No.</sample>
    <sample id="763">Non c'è informazione su quali metriche di MT siano state utilizzate per la valutazione. Potresti cercare di trovare ulteriori dettagli in altre parti del contenuto.</sample>
    <sample id="764">Non c'è informazione specifica nel contenuto su come il regresso nella generalizzazione influisca sui tipi di NER. Potresti avere bisogno di ulteriori dettagli o ricerche specifiche su questo argomento.</sample>
    <sample id="765">Well, positional information in NLP is important because it helps the model understand the context better. You know, like the order of words matters a lot. For example, in a sentence, the position of a word can change its meaning. So, it's crucial for tasks like machine translation, text summarization, and question answering. If you want to know more about specific applications, just let me know.</sample>
    <sample id="766">Non so. Potresti cercare su Internet o chiedere a un esperto.</sample>
    <sample id="767">Fanno ricorso al modello RoBERTA-base + classifier head. Se hai altre domande, sentiti libero di chiedere!</sample>
    <sample id="768">Non so quali siano i recenti set di test utilizzati per valutare le capacità di PaLM. Potresti cercare su internet o contattare la Google per avere informazioni più precise.</sample>
    <sample id="769">Tre.</sample>
    <sample id="770">Non c'è informazione sufficiente nel contenuto per rispondere a questa domanda. Potresti fornire ulteriori dettagli?</sample>
    <sample id="771">Shuheng Liu, Alan Ritter. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="772">Sì, i risultati e il set di dati nell'articolo possono essere utilizzati come parametri di riferimento. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="773">Quattro modelli più piccoli vengono utilizzati nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="774">OFA.</sample>
    <sample id="833">Google.</sample>
    <sample id="834">Stony Brook University, Human Language Analysis Beings.</sample>
    <sample id="835">Non c'è informazione sull'articolo su quali coppie linguistiche sono state analizzate.</sample>
    <sample id="836">Shangbin Feng.</sample>
    <sample id="837">Durante gli esperimenti sono stati studiati i modelli DEplain-APA, DEplain-web, DEplain-APA+web e src2src-baseline. Se hai altre domande su questo argomento, non esitare a chiedere.</sample>
    <sample id="838">Per scopi di addestramento vengono utilizzate 53 attività, mentre per test vengono utilizzate 62 attività.</sample>
    <sample id="839">Tre.</sample>
    <sample id="840">I test sono stati effettuati sui set di dati AG News, MIND, SST2 e Enron Spam.</sample>
    <sample id="876">NACHOS è un modello di linguaggio.</sample>
    <sample id="877">Non so chi sia il relatore o la relatrice. Potresti dare più informazioni?</sample>
    <sample id="878">La strategia del prompting ha un grande impatto sui risultati. 516 su 1000 frasi mostrano una differenza di più di 1 punto BLEURT, e la differenza può arrivare fino a 40 punti BLEURT. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="879">Carnegie Mellon University Language Technologies Institute, Técnico Lisboa, BAIR Berkeley Artificial Intelligence Research, Unbabel.</sample>
    <sample id="880">Non c'è informazione su istruzioni scritte da esperti nel contenuto fornito. Potresti avere bisogno di fornire ulteriori dettagli o controllare la fonte di riferimento.</sample>
    <sample id="881">Gli autori propongono di usare il KITMUS Test Suite. Questo include un dataset per l'evaluazione dell'integrazione di conoscenza e una task di risoluzione di coreferenza per indagare l'abilità di utilizzare conoscenza di pretrain e di inferenza. Inoltre, propongono di eseguire esperimenti con partecipanti umani e modelli di risoluzione di coreferenza.</sample>
    <sample id="882">Mi dispiace, ma non posso tradurre il contenuto inglese in italiano. Potresti fornire il testo inglese che vuoi tradurre?</sample>
    <sample id="883">PaLM: Modello Linguistico di Percorsi.- Chowdery et al., 2022, arXiv:2204.02311.- 540B parametri.- Addestrato su 780B token.- Attivato densamente.- 6144 chip TPU v4.- SOTA in centinaia di benchmark di LMU e generazione.- 28 miliardi di parametri.</sample>
    <sample id="884">PaLM: Modello di Linguaggio Pathways.- Chowdery et al., 2022, arXiv:2204.02311.- 540B parametri.- Addestrato su 780B token.- Attivato densamente.- 6144 TPU v4 chip.- SOTA in centinaia di benchmark di LMU e generazione.- 540 miliardi di parametri.</sample>
    <sample id="885">Contributi nostri.- Prima studio sistematico di LLM per MT. Entrambi per la pool di candidati e la strategia di selezione.- Valutazione delle capacità di traduzione con le migliori pratiche della comunità di MT: set di test più recenti, evitare sovrapposizione tra test e train e sovrappopolamento dei dati di valutazione, confronto con le ultime sottomissioni WMT, metriche MT di punta utilizzando i dati di training più recenti, metriche MT di punta con una correlazione migliore con le giudicanti umane, valutazione umana basata su esperti, più robusta dei lavoratori di massa.- Raccomandazione per le strategie di selezione di prompt</sample>
    <sample id="886">Contributo nostro. Prima studio sistematico di LLM per MT. Entrambi per la pool di candidati e la strategia di selezione. Valutare le capacità di traduzione con le migliori pratiche della comunità di MT: Set di test più recenti, evitare sovrapposizione tra test e train e sovrappopolamento dei dati di valutazione. Confronto con le ultime sottomissioni WMT, sistemi SOTA utilizzando i dati di training più recenti. Metriche SOTA di MT, correlazione migliore con le giudicanti umane. Valutazione umana basata su esperti, più robusta dei lavoratori di massa. Raccomandazione per le strategie di selezione di prompt.</sample>
    <sample id="887">Contributi nostri.- Prima studio sistematico di LLM per MT. Entrambi per la pool di candidati e la strategia di selezione.- Valutazione delle capacità di traduzione con le migliori pratiche della comunità di MT: Set di test più recenti, evitare sovrapposizione tra test e train e sovrappopolamento dei dati di valutazione. Confronto con le ultime sottomissioni WMT, sistemi SOTA utilizzando i dati di training più recenti. Metriche SOTA di MT, correlazione migliore con le giudicanti umane. Valutazione umana basata su esperti, più robusta dei lavoratori di massa.- Raccomandazione per le strategie di selezione di prompt</sample>
    <sample id="888">Contributi nostri.- Prima studio sistematico di LLM per MT. Entrambi per la pool di candidati e la strategia di selezione.- Valutazione delle capacità di traduzione con le migliori pratiche della comunità di MT: Set di test più recenti, evitare sovrapposizione tra test e train e sovrappopolamento dei dati di valutazione. Confronto con le ultime sottomissioni WMT, sistemi SOTA utilizzando i dati di training più recenti. Metriche SOTA di MT, correlazione migliore con le giudicanti umane. Valutazione umana basata su esperti, più robusta dei lavoratori di massa.- Raccomandazione per le strategie di selezione di prompt</sample>
    <sample id="889">I prompt hanno un grande impatto sulla qualità della traduzione. Per ogni frase, seleziona due prompt casuali. Calcola BLEURT per ogni coppia frase-prompt. La maggior parte delle frasi, 516 su 1000, mostra una differenza di più di 1 punto BLEURT. La differenza può arrivare fino a 40 punti BLEURT!</sample>
    <sample id="890">I prompt hanno un grande impatto sulla qualità della traduzione. Per ogni frase, seleziona due prompt casuali. Calcola BLEURT per ogni coppia frase-prompt. La maggior parte delle frasi, 516 su 1000, mostra una differenza di più di 1 punto BLEURT. La differenza può arrivare fino a 40 punti BLEURT!</sample>
    <sample id="891">I prompt hanno un grande impatto sulla qualità della traduzione. Per ogni frase, seleziona due prompt casuali. Calcola BLEURT per ogni coppia frase-prompt. La maggior parte delle frasi, 516 su 1000, mostra una differenza di più di 1 punto BLEURT. La differenza può arrivare fino a 40 punti BLEURT!</sample>
    <sample id="892">Ecco la traduzione in italiano: "Un passante ha allarmato la polizia, che è arrivata con diversi agenti di polizia." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="893">Ecco la traduzione in italiano: "Un passante ha allarmato la polizia, che è arrivata con diversi agenti." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="894">Ecco la traduzione in italiano: "Un passante ha allarmato la polizia, che è arrivata con diversi agenti di polizia." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="895">Ecco la traduzione in italiano: "Un passante ha allarmato la polizia, che è arrivata con diversi agenti di polizia." Se hai bisogno di ulteriori traduzioni o hai altre domande, non esitare a chiedere.</sample>
    <sample id="896">Un passante ha allarmato la polizia, che è arrivata con diversi agenti.</sample>
    <sample id="897">Risultati sperimentali: La qualità dell'esempio è più importante della somiglianza con la frase di origine. I sistemi SOTA specializzati hanno un vantaggio sostanziale. PaLM è vicino a Google Translate. Conoscenze da MQM: La fluenza di PaLM è paragonabile a quella dei SOTA. Le punteggio di accuratezza sono generalmente più bassi. Dominato da "Accuracy/Omission". "Stile/Accattivante" è generalmente più basso per PaLM.</sample>
    <sample id="898">Risultati sperimentali:.- La qualità dell'esempio è più importante della somiglianza con la frase di origine.- I sistemi SOTA specializzati hanno un vantaggio sostanziale.- PaLM è vicino a Google Translate.Individuazioni da MQM:.- La fluenza di PaLM è paragonabile a quella dei SOTA.- Le punte di accuratezza sono generalmente più basse. - Dominato da "Accuracy/Omission"-"Stile/Accattivante" è generalmente più basso per PaLM.</sample>
    <sample id="899">Risultati sperimentali: La qualità dell'esempio è più importante della somiglianza con la frase di origine. I sistemi SOTA specializzati hanno un vantaggio sostanziale. PaLM è vicino a Google Translate. Conoscenze da MQM: La fluenza di PaLM è paragonabile a quella dei SOTA. Le punteggio di accuratezza sono generalmente più bassi. Dominati da "Accuracy/Omission". "Stile/Accattivante" è generalmente più basso per PaLM.</sample>
    <sample id="900">Risultati sperimentali:.- La qualità dell'esempio è più importante della somiglianza con la frase di origine.- I sistemi SOTA specializzati hanno un vantaggio sostanziale.- PaLM è vicino a Google Translate.Individuazioni da MQM:.- La fluenza di PaLM è paragonabile a quella dei SOTA.- Le punte di accuratezza sono generalmente più basse. - Dominato da "Accuracy/Omission".- "Stile/Accattivante" è generalmente più basso per PaLM.</sample>
    <sample id="901">Risultati sperimentali:.- La qualità dell'esempio è più importante della somiglianza con la frase di origine.- I sistemi SOTA specializzati hanno un vantaggio sostanziale.- PaLM è vicino a Google Translate.Individuazioni da MQM:.- La fluenza di PaLM è paragonabile a quella dei SOTA.- Le punte di accuratezza sono generalmente più basse. - Dominato da "Accuracy/Omission"-"Stile/Accattivante" è generalmente più basso per PaLM.</sample>
    <sample id="902">Risultati sperimentali:.- La qualità dell'esempio è più importante della somiglianza con la frase di origine.- I sistemi SOTA specializzati hanno un vantaggio sostanziale.- PaLM è vicino a Google Translate.Individuazioni da MQM:.- La fluenza di PaLM è paragonabile a quella dei SOTA.- Le punteggia di accuratezza sono generalmente più basse. - Dominato da "Accuracy/Omission"-"Stile/Accattivante" è generalmente più basso per PaLM.</sample>
    <sample id="903">Risultati sperimentali:.- La qualità dell'esempio è più importante della somiglianza con la frase di origine.- I sistemi SOTA specializzati hanno un vantaggio sostanziale.- PaLM è vicino a Google Translate.Individuazioni da MQM:.- La fluenza di PaLM è paragonabile a quella dei SOTA.- Le punte di accuratezza sono generalmente più basse. - Dominato da "Accuracy/Omission".- "Stile/Accattivante" è generalmente più basso per PaLM.</sample>
    <sample id="904">Risultati sperimentali:.- La qualità dell'esempio è più importante della somiglianza con la frase di origine.- I sistemi SOTA specializzati hanno un vantaggio sostanziale.- PaLM è vicino a Google Translate.Individuazioni da MQM:.- La fluenza di PaLM è paragonabile a quella dei SOTA.- Le punteggiazioni di accuratezza sono generalmente più basse. - Dominato da "Accuracy/Omission"-"Stile/Accattivante" è generalmente più basso per PaLM.</sample>
    <sample id="905">Risultati sperimentali: La qualità dell'esempio è più importante della somiglianza con la frase di origine. I sistemi SOTA specializzati hanno un vantaggio sostanziale. PaLM è vicino a Google Translate. Conoscenze da MQM: La fluenza di PaLM è paragonabile a quella dei SOTA. Le punteggio di accuratezza sono generalmente più bassi. Dominato da "Accuracy/Omission". "Stile/Accattivante" è generalmente più basso per PaLM.</sample>
    <sample id="906">Certo! "Thank you" in italiano è "Grazie". Se hai bisogno di tradurre altro, fammi sapere!</sample>
    <sample id="907">Sì, posso tradurre il contenuto inglese in italiano. Ti invio la traduzione subito dopo.</sample>
    <sample id="908">"Più debole di quanto pensi: un'analisi critica dell'apprendimento supervisionato debole"</sample>
    <sample id="909">Perché l'apprendimento supervisionato debole?• L'apprendimento supervisionato debole allevia il blocco dell'annotazione. Ma i etichette deboli sono rumorose! • La memorizzazione del rumore danneggia la generalizzazione. • L'apprendimento supervisionato debole, WSL, • Addestra modelli che generalizzano bene nonostante siano addestrati su dati rumorosi.</sample>
    <sample id="910">Perché l'apprendimento supervisionato debole?• L'apprendimento supervisionato debole allevia il blocco dell'annotazione. • Ma le etichette deboli sono rumorose! ○ La memorizzazione del rumore danneggia la generalizzazione. • L'apprendimento supervisionato debole, WSL, ○ Addestra modelli che generalizzano bene nonostante siano addestrati su dati rumorosi.</sample>
    <sample id="911">Perché l'apprendimento supervisionato debole?• L'apprendimento supervisionato debole allevia il blocco dell'annotazione. • Ma le etichette deboli sono rumorose! ▪ La memorizzazione del rumore danneggia la generalizzazione. • L'apprendimento supervisionato debole, WSL ▪ Addestra modelli che generalizzano bene nonostante siano addestrati su dati rumorosi.</sample>
    <sample id="912">Perché l'apprendimento supervisionato debole?• L'apprendimento supervisionato debole allevia il blocco dell'annotazione. • Ma le etichette deboli sono rumorose! ○ La memorizzazione del rumore danneggia la generalizzazione. • L'apprendimento supervisionato debole, WSL, ○ Addestra modelli che generalizzano bene nonostante siano addestrati su dati rumorosi.</sample>
    <sample id="913">Perché l'apprendimento supervisionato debole?• L'apprendimento supervisionato debole allevia il blocco dell'annotazione. • Ma le etichette deboli sono rumorose! ○ La memorizzazione del rumore danneggia la generalizzazione. • L'apprendimento supervisionato debole, WSL, ○ Addestra modelli che generalizzano bene nonostante siano addestrati su dati rumorosi.</sample>
    <sample id="914">Un索赔在最近的WSL工作中，"我们只在弱监督数据上训练模型，并且达到XX%的准确率。"</sample>
    <sample id="915">Un affermazione comune nelle recenti ricerche sul WSL. "Addestriamo modelli solo su dati supervisionati debolmente e otteniamo un'accuratezza del XX%."</sample>
    <sample id="916">Un索赔在最近的WSL工作中，"我们只在弱监督数据上训练模型，并且达到XX%的准确率"</sample>
    <sample id="917">Un索赔在最近的WSL工作中，"我们只在弱监督数据上训练模型，并且达到XX%的准确率。"</sample>
    <sample id="918">Le nostre domande di ricerca sono:RQ1: È necessario il dati di validazione pulito?RQ2: Quanti campioni puliti necessitano gli approcci WSL?RQ3: Come utilizzare in modo più efficiente i campioni puliti disponibili?</sample>
    <sample id="919">Le nostre domande di ricerca sono:RQ1: È necessario il dati di validazione pulito?RQ2: Quanti campioni puliti necessitano gli approcci WSL?RQ3: Come utilizzare in modo più efficiente i campioni puliti disponibili?</sample>
    <sample id="920">RQ1 Ricerche principali.</sample>
    <sample id="921">RQ1 Ricerche principali.</sample>
    <sample id="922">RQ1 Ricerche principali.</sample>
    <sample id="923">RQ1 Rilevamenti principali.</sample>
    <sample id="924">RQ1 Ricerche principali. Un insieme di validazione pulito è indispensabile.</sample>
    <sample id="925">RQ2 Ricerche principali.</sample>
    <sample id="926">RQ2 Ricerche principali.</sample>
    <sample id="927">Risultati principali. -&gt; Le approcci WSL beneficiano da più campioni di validazione puliti!</sample>
    <sample id="928">RQ2 Rilevamenti principali. WSL approcci beneficiano da più campioni di validazione puliti!</sample>
    <sample id="929">RQ2 Rilevamenti principali. WSL approcci beneficiano da più campioni di validazione puliti! Ma è ancora meglio usarli per l'addestramento, ad esempio, LoRA_c!</sample>
    <sample id="930">RQ3 Rilevamenti principali N=10 campioni puliti per classe N=30 campioni puliti per classe Precisione/F1 Precisione/F1 Prima CFT Dopo CFT Prima CFT Dopo CFT</sample>
    <sample id="931">RQ3 Ricerche principali N=10 campioni puliti per classe N=30 campioni puliti per classe Precisione/F1 Precisione/F1 Prima CFT Dopo CFT Prima CFT Dopo CFT</sample>
    <sample id="932">RQ3 Rilevamenti principali N=10 campioni puliti per classe N=30 campioni puliti per classe Precisione/F1 Precisione/F1 Prima CFT Dopo CFT Prima CFT Dopo CFT</sample>
    <sample id="933">RQ3 Rilevamenti principali N=10 campioni puliti per classe N=30 campioni puliti per classe → Continuare l'addestramento fine, CFT, elimina le differenze di prestazione tra le approcci WSL. → Non c'è bisogno di utilizzare metodi WSL complicati, FTw funziona altrettanto bene.</sample>
    <sample id="934">ConclusioneApprocci recenti WSL: - Richiedono campioni puliti. - Sottostimano la loro praticità. Consigli: - Riferire i criteri di selezione del modello. - Usare approcci di apprendimento a poche istanze come basi. - Sempre applicare l'ottimizzazione continua (CFT).</sample>
    <sample id="935">ConclusioneApprocci recenti WSL* Richiedono campioni puliti.* Sottostimano la loro praticabilità.Raccomandazioni* Riferire i criteri di selezione del modello.* Usare gli approcci di apprendimento a pochi esempi come basi.* Sempre applicare l'ottimizzazione continua (CFT).</sample>
    <sample id="936">Conclusione

Approcci recenti WSL

- Richiedono campioni puliti.
- Sottostimano la loro praticabilità. 😕

Raccomandazioni

- Riferire i criteri di selezione del modello.
- Usare approcci di apprendimento a poche istanze come basi.
- Sempre applicare l'ottimizzazione continua (CFT).</sample>
    <sample id="937">ConclusioneApprocci recenti WSL: - Richiedono campioni puliti. - Sottostimano la loro praticità. Recommandazioni: - Riferire i criteri di selezione del modello. - Usare approcci di apprendimento a poche immagini come basi. - Sempre applicare l'ottimizzazione continua (CFT).</sample>
    <sample id="938">ConclusioneApprocci recenti WSL: - Richiedono campioni puliti. - Sottostimano la loro praticità. Recommandazioni: - Riferire i criteri di selezione del modello. - Usare approcci di apprendimento a poche sfide come basi. - Sempre applicare l'ottimizzazione continua (CFT).</sample>
    <sample id="939">I metodi di valutazione comuni per i sistemi di dialogo sono la valutazione comparativa e la valutazione di classificazione. C'è anche la valutazione di classificazione. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="940">Cinque. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="941">Nell'esempio con Servin e Kea, sono necessarie le conoscenze di base che i giudici decidono casi in tribunali. Se hai altre domande, sentiti libero di chiedere!</sample>
    <sample id="942">Sì, il codice è disponibile. Puoi trovarlo su GitHub, nel repository mpoemsl/kitmus.</sample>
    <sample id="943">Non c'è informazione su questo nel contenuto. Potresti avere altre domande su questo argomento?</sample>
    <sample id="944">Le frasi sono state perturbate in modo da mantenere la struttura rilevante.</sample>
    <sample id="945">E' un modo per misurare e valutare diverse aspetti di qualcosa. Ad esempio, in questo caso, la qualità del dialogo è valutata considerando tre aspetti: rilevanza, coerenza e comprensione emotiva. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="946">Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun e Xing Xie hanno affiliazioni diverse. Wenjun Peng e Jingwei Yi sono dell'University of Science and Technology of China, Fangzhao Wu e Shangxi Wu sono di Microsoft Research Asia, Bin Zhu e Lingjuan Lyu sono di Beijing Jiaotong University, Binxing Jiao e Tong Xu sono di Sony AI, Guangzhong Sun è di Microsoft STC Asia.</sample>
    <sample id="947">Non so dire con certezza solo dal contenuto inglese. Potresti dare più dettagli o contesto?</sample>
    <sample id="978">Hanno valutato BART-FID-RAG, Blender2, Emora e Blender-Decode. Se hai altre domande, sentiti libero di chiedere!</sample>
    <sample id="979">Ci sono nove autori coinvolti nell'articolo. Se hai altre domande sullo stesso argomento, non esitare a chiedere.</sample>
    <sample id="980">Non c'è una risposta diretta in questo contenuto inglese. Potresti cercare ulteriori informazioni o fornire più dettagli sulla tua domanda?</sample>
    <sample id="981">Ci sono sette autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="982">Vasudha Varadarajan.</sample>
    <sample id="983">I autori dell'articolo sono affiliati all'Institute of Computer Science, Polish Academy of Sciences, con indirizzo ul. Jana Kazimierza 5, 01-248 Warsaw, e all'University of Warsaw.</sample>
    <sample id="1021">Gli errori più comuni di PaLM sono "Accuracy/Omission" e "Style/Awkward". Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1022">Non dimenticare le tue ABC: valutare lo stato dell'arte nei sistemi di dialogo orientati al chat Sarah E. Finch, James D. Finch e Jinho D. Choi</sample>
    <sample id="1023">Non dimenticare le tue ABC: valutare lo stato dell'arte nei sistemi di dialogo orientati al chat Sarah E. Finch, James D. Finch e Jinho D. Choi</sample>
    <sample id="1024">Non dimenticare le tue ABC: valutare lo stato dell'arte nei sistemi di dialogo orientati al chat Sarah E. Finch, James D. Finch e Jinho D. Choi</sample>
    <sample id="1025">Ecco la traduzione in italiano: "Evaluazione comparativa" "Evaluazione di valutazione Likert"</sample>
    <sample id="1026">Ecco la traduzione in italiano: "Evaluazione del rating Likert". "Dimensioni della qualità del dialogo". "Qualità del dialogo". "Rilevanza". "Coerenza". "Comprendere emozionalmente".</sample>
    <sample id="1027">Dimensioni della qualità del dialogo. Valutazione di rating Likert. Valuta la rilevanza delle risposte del bot.</sample>
    <sample id="1028">Evaluazione della valutazione Likert. Valutare la rilevanza delle risposte del bot.</sample>
    <sample id="1029">Annotazione dei comportamenti in chat, ABC-Eval.</sample>
    <sample id="1030">Annotazione dei comportamenti in chat, ABC-Eval.</sample>
    <sample id="1031">C'è un contenuto in inglese su "ABC-Eval Behaviors" con quattro sezioni: Coherence, Knowledge, Consistency e Emotional Understanding. Questo è stato presentato da Emory University e Alexa.</sample>
    <sample id="1032">Coerenza Ignoring Partner Irrelevant Conoscenza Consistenza Comprendere Emozionalmente</sample>
    <sample id="1033">Behaviors, Coherence, Ignoring Partner, Irrelevant, Consistency, Self Contradiction, Partner Contradiction, Knowledge, Incorrect Fact, Commonsense Violation, Emotional Understanding, Empathetic Response, Lack of Empathy.</sample>
    <sample id="1034">Ecco la traduzione in italiano: "Esecuzioni. - 4 modelli di dialogo a dominio aperto. - 100 conversazioni umano-robot per modello."</sample>
    <sample id="1035">Ecco la traduzione in italiano: "Esperimenti. 4 modelli di dialogo a dominio aperto. 100 conversazioni umano-robot per modello. ABC-Eval. Turn Likert. Dialogue Likert. Comparative." Se hai bisogno di ulteriori chiarimenti o hai altre domande, fammi sapere!</sample>
    <sample id="1036">Ecco la traduzione in italiano:</sample>
    <sample id="1037">Inter-Annotatore Convenzione.</sample>
    <sample id="1038">Inter-Annotator Agreement Inter-Annotator Agreement Predictive Validity ABC-Eval ABC-Eval Turn Likert Turn Likert Dialogue Likert Dialogue Likert Comparative Comparative</sample>
    <sample id="1039">Ecco la traduzione in italiano: "Validità predittiva". La presentazione mostra un grafico con diversi valori di validità predittiva per vari metodi di valutazione. I metodi sono ABC-Eval, Turn Likert, Dialogue Likert e Comparative. Ogni metodo ha due valori di validità predittiva, rappresentati da barre grigie e grigio chiaro. Le barre grigie rappresentano Interactive Qua_d, mentre quelle grigio chiaro rappresentano Interactive Qua_c. Emory University e Alexa sono menzionati in basso a destra della presentazione.</sample>
    <sample id="1040">Ecco la traduzione in italiano: "Validità predittiva" "Validità incrementale" "Validità incrementale"</sample>
    <sample id="1041">Incremental Validità.</sample>
    <sample id="1042">Incremental Validità.</sample>
    <sample id="1043">Ecco la traduzione in italiano: "ABC-Eval Error Rates by Model" significa "Tassi di errore ABC-Eval per modello". "Antisocial" è "Antisociale", "CS Contra." è "CS Contro.", "Ignore" è "Ignorare", "Incorrect" è "Incorretto", "Irrelevant" è "Irrellevante", "Unempathetic" è "Irriparatetico", "Other Contra." è "Altre contro.", "Redundant" è "Ridondante", "Self Contra." è "Contro se stessi", "Topic Switch" è "Scambio di tema", "Uninterpret." è "Non interpretato". "BART-FID-RAG" è "BART-FID-RAG", "Blender2" è "Blender2", "Emora" è "Emora", "Blender-Decode" è "Blender-Decodifica". "Emory University" è "Università Emory", "NLP" è "NLP", "Alexa" è "Alexa".</sample>
    <sample id="1044">Ecco la traduzione in italiano: "ABC-Eval Error Rates by Model" significa "Tassi di errore ABC-Eval per modello". "Antisocial" è "Antisociale", "CS Contra." è "CS Contro.", "Ignore" è "Ignorare", "Incorrect" è "Incorretto", "Irrelevant" è "Irrellevante", "Unempathetic" è "Non empatetico", "Other Contra." è "Altri contro.", "Redundant" è "Ridondante", "Self Contra." è "Contro se stessi", "Topic Switch" è "Passaggio di tema", "Uninterpret." è "Non interpretato". "BART-FID-RAG" è "BART-FID-RAG", "Blender2" è "Blender2", "Emora" è "Emora", "Blender-Decode" è "Blender-Decodifica". "Emory University" è "Università Emory", "NLP" è "NLP", "Alexa" è "Alexa".</sample>
    <sample id="1045">Ecco la traduzione in italiano: "ABC-Eval Error Rates by Model" significa "Tassi di errore ABC-Eval per modello". "Antisocial" è "Antisociale", "CS Contra." è "CS Contro.", "Ignore" è "Ignorare", "Incorrect" è "Incorretto", "Irrelevant" è "Irrellevante", "Unempathetic" è "Non empatetico", "Other Contra." è "Altra Contro.", "Redundant" è "Ridondante", "Self Contra." è "Auto Contro.", "Topic Switch" è "Passaggio di Tema", "Uninterpret." è "Non Interpretato". "BART-FID-RAG" è "BART-FID-RAG", "Blender2" è "Blender2", "Emora" è "Emora", "Blender-Decode" è "Blender-Decodifica". "Emory University" è "Università di Emory", "NLP" è "NLP", "Alexa" è "Alexa".</sample>
    <sample id="1046">Ecco la traduzione in italiano: "Tassi di errore ABC-Eval per modello" La donna sta parlando. Emory University. NLP Emory. Alexa.</sample>
    <sample id="1047">Ecco la traduzione in italiano: "ABC-Eval Error Rates by Model" - "Tassi di errore ABC-Eval per modello" "Paper: https://arxiv.org/pdf/2212.09180.pdf" - "Paper: https://arxiv.org/pdf/2212.09180.pdf" "GitHub: https://github.com/emorynlp/ChatEvaluationPlatform" - "GitHub: https://github.com/emorynlp/ChatEvaluationPlatform" "Contact Info: {sfillwo, jdfinch, jinho.choi} @emory.edu" - "Contatti: {sfillwo, jdfinch, jinho.choi} @emory.edu" "https://www.emorynlp.org" - "https://www.emorynlp.org"</sample>
    <sample id="1048">I tre autori sono affiliati all'Emory University, all'Emory NLP Research Lab e all'Alexa.</sample>
    <sample id="1049">CFT significa Continuous Fine-tuning. Se hai altre domande sul contenuto dell'articolo, sentiti libero di chiedere.</sample>
    <sample id="1050">Ci sono sette autori coinvolti nell'articolo. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1051">Quando la traduzione richiede contesto? Un'esplorazione multilingue guidata da dati. Patrick Fernandes*, Kayo Yin*, Emmy Liu André F. T. Martins, Graham Neubig. Carnegie Mellon University Language Technologies Institute, TÉCNICO LISBOA, BAIR Berkeley Artificial Intelligence Research, Unbabel. *con contributo uguale.</sample>
    <sample id="1052">Dobbiamo liberarci di quel infiltrato.</sample>
    <sample id="1053">Cosa succede se i ministri scoprono? Dobbiamo liberarci di quel mulo. Potrebbe essere qualcosa di serio, dottore? Dobbiamo liberarci di quel mulo.</sample>
    <sample id="1054">Potrebbe essere qualcosa di serio, dottore? Dobbiamo liberarci di quella chia.</sample>
    <sample id="1055">Evaluare la traduzione dipendente dal contesto è difficile. Solo una piccola parte di parole dipende dal contesto.</sample>
    <sample id="1056">Evaluare la traduzione dipendente dal contesto è difficile. Solo una piccola parte di parole dipende dal contesto. - Metriche a livello di corpus. - Metodi esistenti supportano fenomeni di discorso e lingue limitati.</sample>
    <sample id="1057">RQ1: Quando la traduzione richiede contesto?RQ2: Come gestiscono bene i modelli le traduzioni dipendenti dal contesto?</sample>
    <sample id="1058">RQ1: Quando la traduzione richiede contesto? - Utilizzo del contesto a livello di parola RQ2: Come gestiscono bene i modelli le traduzioni dipendenti dal contesto?</sample>
    <sample id="1059">Informazione Cross-Mutua Condizionata, CXMI. CXMI: misura quanto utilizzano i modelli di traduzione a contesto dati un corpus.</sample>
    <sample id="1060">Informazione Cross-Mutua Condizionata, CXMI. CXMI: misura quanto utilizzano i modelli di traduzione con contesto dati un corpus. Uncertezza sulle traduzioni date la fonte. H, q, MT, A, Y, X, Uncertezza sulle traduzioni date la fonte e il contesto. H, q, MT, C, Y, X, C, CXMI, C, →, Y, X,</sample>
    <sample id="1061">Puntuale, P-CXMI, introduciamo P-CXMI per misurare l'uso del contesto per tradurre un particolare, Senten, P-CXMI, y, x, C, = - log, q, MT, A, y | x, / q, MT, C, y | x, C, Word, P-CXMI, i, y, x, C, = - log, q, MT, A, y, i | y, t, &lt;, i, x, / q, MT, C, y, i | y, t, &lt;, i, x, C, Parole con alto P-CXMI -&gt; richiedono contesto per tradurre,</sample>
    <sample id="1062">RQ1: Quando la traduzione richiede contesto? - Utilizzo del contesto a livello di parola - Analisi tematica RQ2: Come gestiscono bene i modelli le traduzioni dipendenti dal contesto?</sample>
    <sample id="1063">Analisi tematica di parole con alto P-CXMI.</sample>
    <sample id="1064">L'analisi tematica delle parole con alto P-CXMI. 1. Etichette di POS.</sample>
    <sample id="1065">Analisi tematica di parole con alto P-CXMI. 1. Etichette di POS. - Pronomi.</sample>
    <sample id="1066">Analisi tematica di parole con alto P-CXMI. 1. Etichette di POS - Pronomi - Forma del verbo. 2. Elementi di vocabolario.</sample>
    <sample id="1067">L'analisi tematica di parole a alto P-CXMI. 1. Etichette di POS. 2. Elementi di vocabolario. Avelile's madre era ancora addormentata. Avelile è andato a scuola. La madre di Avelile era ancora addormentata. Avelile è andato a scuola. Pronomi, forma del verbo, coesione lessicale.</sample>
    <sample id="1068">1. Etichette di POS
2. Elementi di vocabolario
Avelile's madre era ancora addormentata. Avelile è andato a scuola.
La madre di Avilile era ancora addormentata. Avilile è andato a scuola.</sample>
    <sample id="1069">Certo! Ecco la traduzione in italiano: "Analisi tematica di parole a alto P-CXMI". 1. Etichette di POS 2. Elementi di vocabolario 3. Token individuali - Pronomi - Forma del verbo - Coesione lessicale - Formalità - Ellissi</sample>
    <sample id="1070">RQ1: Quando la traduzione richiede contesto? - Utilizzo del contesto a livello di parola - Analisi tematica RQ2: Come gestiscono bene i modelli le traduzioni dipendenti dal contesto? - Benchmark Multilingue Discorsuale-Aware, MuDA</sample>
    <sample id="1071">RQ1: Quando la traduzione richiede contesto? - Utilizzo del contesto a livello di parola - Analisi tematica RQ2: Come gestiscono bene i modelli le traduzioni dipendenti dal contesto? - Multilingual Discourse-Aware, MuDA, benchmark Multilingue Discorsivamente Conscio, MuDA, tagger - Pronomi - Forma del verbo - Cohesione lessicale - Formalità - Ellissi</sample>
    <sample id="1072">Multilingue Discorso-Conscio, MuDA, tagger. - Pronomi - Forma del verbo - Cohesione lessicale - Formalità - Ellissi.</sample>
    <sample id="1073">Ecco la traduzione in italiano: "Multilingue Discorsuale Consapevole, MuDA, tagger". "MuDA benchmark". "MuDA tagger". "BLEU COMET F-measure ...". Se hai bisogno di ulteriori informazioni o traduzioni, fammi sapere!</sample>
    <sample id="1074">RQ1: Quando la traduzione richiede il contesto? - Utilizzo del contesto a livello di parola - Analisi tematica RQ2: Come gestiscono bene i modelli le traduzioni dipendenti dal contesto? - Multilingual Discourse-Aware, MuDA, benchmark - Valutazione del modello</sample>
    <sample id="1075">Metriche a livello di corpus. RQ1: Quando la traduzione richiede contesto? - Utilizzo del contesto a livello di parola - Analisi tematica. RQ2: Come gestiscono bene i modelli le traduzioni dipendenti dal contesto? - Benchmark Multilingue Discorsuale-Aware, MuDA - Valutazione del modello.</sample>
    <sample id="1076">Metriche a livello di corpus</sample>
    <sample id="1077">Metriche a livello di corpus. Non è chiaro quale sistema sia il migliore per la traduzione automatica a livello di documento con metriche a livello di corpus.</sample>
    <sample id="1078">Risultati del benchmark MuDA. - I modelli a conoscenza del contesto performano significativamente meglio in alcuni fenomeni.</sample>
    <sample id="1079">Risultati del benchmark MuDA. - I modelli a conoscenza del contesto performono significativamente meglio su alcune fenomena. ✔️: Formalità, coesione lessicale ❌: Ellissi, pronomi, forma del verbo.</sample>
    <sample id="1080">Risultati del benchmark MuDA. - I modelli a conoscenza del contesto performono significativamente meglio su alcune fenomena. - ✔ Formalità, coesione lessicale - ❌ Ellissi, pronomi, forma del verbo. - DeepL supera Google in maggior parte dei fenomeni e delle coppie di lingue.*</sample>
    <sample id="1081">Riassunto: Identificare fenomeni discorsivi in modo sistematico senza conoscenze linguistiche precedenti. Benchmark per la traduzione automatica di documenti indipendente dal dataset.</sample>
    <sample id="1082">Riassunto: Identificare fenomeni discorsivi in modo sistematico senza conoscenze linguistiche precedenti. Benchmark per la traduzione automatica di documenti indipendente dal dataset.</sample>
    <sample id="1083">Riassunto
- Identificare fenomeni discorsivi in modo sistematico senza conoscenze linguistiche precedenti
- Benchmark per la traduzione automatica di documenti indipendente dal dataset</sample>
    <sample id="1084">Yusen Zhang.</sample>
    <sample id="1121">Il nuovo metodo è chiamato "Permuting with 'jumps'".</sample>
    <sample id="1122">Il metodo consiste in due passi. Il primo passo è generare personaggi usando promemoria come "Imagina che tu sia una donna asiatica. Descrivi te stesso". Il secondo passo è trovare parole che distinguono i personaggi dei gruppi contrassegnati dai gruppi non contrassegnati.</sample>
    <sample id="1123">Shangbin Feng: PAUL G. ALLEN SCHOOL, Chan Young Park: UWNLP, Yuhan Liu: Carnegie Mellon University Language Technologies Institute, Yulia Tsvetkov: BEIJING UNIVERSITY.</sample>
    <sample id="1124">Bouquet/Stanford.</sample>
    <sample id="1125">Il nome del relatore è Sarah E. Finch.</sample>
    <sample id="1126">Quattro.</sample>
    <sample id="1127">BLiMP, SyntaxGym, CrowS. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="1161">FTw， BOND， COSINE， MLC， L2R.</sample>
    <sample id="1162">Il modello viene valutato su 11 task.</sample>
    <sample id="1226">CamemBERT viene inizialmente addestrato su 4GB di dati.</sample>
    <sample id="1227">Adam Przepiórkowski.</sample>
    <sample id="1228">Beh, sembra che la derivazione temporale sia stata identificata come la causa principale della perdita di prestazioni perché il modello di Flair ha mostrato una diminuzione di 5.57% nel CoNLL-2003 e 2.69% nel CoNLL++. Questi risultati sono stati confermati dalla tabella e dal grafico. Cosa ne pensi?</sample>
    <sample id="1269">Permette di ottenere una sequenza di output più accurata.</sample>
    <sample id="1270">Perché è importante per comprendere come i modelli gestiscono i bias.</sample>
    <sample id="1271">Per BLiMP, l'input inaccettabile è "Many people were helping herself." Per SyntaxGym, è "The customer ... has spent any money." Per CrowS, non c'è un input inaccettabile specificato.</sample>
    <sample id="1272">Hanno utilizzato le metriche F1 per NER, CLS, Specialties, MUSCA-DET, ESSAI, CAS, POS, Hamming, EMR, NER, QUAAERO-EMEA, QUAAERO-MEDLINE.</sample>
    <sample id="1273">Krippendorff's Alpha.</sample>
    <sample id="1274">Wikipedia.</sample>
    <sample id="1275">Heinrich Heine University Düsseldorf, Germany.</sample>
    <sample id="1276">MultiInstruct differisce perché ha un numero molto maggiore di task rispetto agli altri parametri di riferimento. C'è un'enorme disparità tra i task di NLP e quelli multimediali. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="1277">Tre. C'è Sarah E. Finch, James D. Finch e Jinho D. Choi. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1278">Non c'è una definizione di coordinazione binaria nella tua immagine. Forse potresti fornire più dettagli o un'altra immagine?</sample>
    <sample id="1279">Non c'è informazione su quanto tempo sono stati utilizzati i prompt in questo studio. Potresti cercare ulteriori dettagli nel testo o nella presentazione?</sample>
    <sample id="1280">I modelli T5 più piccoli finetunati su Coscript possono generare script di qualità superiore rispetto ai LLMs.</sample>
    <sample id="1281">DrBERT: Un modello pre-allenato robusto in francese per i campi biomedici e clinici.</sample>
    <sample id="1282">I. Modellazione del linguaggio nella sanità II. Confronto di strategie di pre-allenamento, fonti di dati e dimensioni III. Valutazione di 13 modelli su 11 compiti IV. Distribuzione di NACHOS e DrBERT</sample>
    <sample id="1283">I. Modellazione linguistica in sanità II. Comparazione di strategie di pre-allenamento, fonti di dati e dimensioni III. Valutazione di 13 modelli su 11 compiti IV. Distribuzione di NACHOS e DrBERT</sample>
    <sample id="1284">I. Modellazione linguistica in sanità II. Comparazione di strategie di pre-allenamento, fonti di dati e dimensioni III. Valutazione di 13 modelli su 11 compiti IV. Distribuzione di NACHOS e DrBERT</sample>
    <sample id="1285">I. Modellazione del linguaggio in sanità. II. Comparazione di strategie di pre-allenamento, fonti di dati e dimensioni. III. Valutazione di 13 modelli su 11 compiti. IV. Distribuzione di NACHOS e DrBERT.</sample>
    <sample id="1286">Ecco la traduzione in italiano:.- Approcci basati su trasformatori, come BERT, offrono un guadagno di prestazioni notevole in molte tesi di NLP.- È stato adattato al francese con CamemBERT e FlauBERT.- Nelle tesi mediche, i modelli specifici di dominio in inglese hanno alzato ancora di più il livello.- PudMedBERT, BioBERT, ClinicalBERT e altri.- Le lingue diverse dall'inglese sono più rare e si affidano principalmente a un pre-allenamento continuo utilizzando un modello generico esistente.- In contrapposizione ai modelli generici, non c'è ancora un modello open-source disponibile per il dominio biomedico in francese.- Un modello specifico di dominio basato su BERT in francese dovrebbe aumentare le prestazioni nelle tesi mediche.</sample>
    <sample id="1287">Modellazione del Linguaggio. * Approcci basati su trasformatori, come BERT, offrono un guadagno di prestazioni notevole in molte tesi di NLP. * È stato adattato al francese con CamemBERT e FlauBERT. * Sulle tesi mediche, i modelli specifici di dominio in inglese hanno alzato ancora di più il livello. o PubMedBERT, BioBERT, ClinicalBERT e altri. * Le lingue diverse dall'inglese sono più rare e si affidano principalmente a un pre-allenamento continuo utilizzando un modello generico esistente. * Diversamente dai modelli generici, non c'è ancora un modello open-source disponibile per il dominio biomedico in francese. * Un modello specifico di dominio basato su BERT in francese dovrebbe aumentare le prestazioni sulle tesi mediche.</sample>
    <sample id="1288">Ecco la traduzione in italiano:.- Approcci basati su trasformatori, come BERT, offrono un guadagno di prestazioni notevole in molte tesi di NLP.- È stato adattato al francese con CamemBERT e FlauBERT.- Nelle tesi mediche, i modelli specifici di dominio in inglese hanno alzato ancora di più il livello.- PudMedBERT, BioBERT, ClinicalBERT e altri.- Le lingue diverse dall'inglese sono più rare e si affidano principalmente a un pre-allenamento continuo utilizzando un modello generico esistente.- In contrapposizione ai modelli generici, non c'è ancora un modello open-source disponibile per il dominio biomedico in francese.- Un modello specifico di dominio basato su BERT in francese dovrebbe aumentare le prestazioni nelle tesi mediche.</sample>
    <sample id="1289">- Approcci basati su trasformatori, come BERT, offrono un guadagno di prestazioni notevole in molte tesi di NLP. - È stato adattato al francese con CamemBERT e FlauBERT. - Nelle tesi mediche, modelli specifici di dominio in inglese hanno alzato ancora di più il livello. - PudMedBERT, BioBERT, ClinicalBERT e altri. - Lingue diverse dall'inglese sono più rare e si affidano principalmente a un pre-allenamento continuo utilizzando un modello generico esistente. - Invece di modelli generici, non c'è ancora un modello open-source per il dominio biomedico in francese. - Un modello specifico di dominio basato su BERT in francese dovrebbe aumentare la prestazione nelle tesi mediche.</sample>
    <sample id="1290">Confronto di strategie di pre-allenamento e fonti di dati. Valutazione dell'impatto di fonti di dati medici pubbliche e private su dimensioni di dati comparabili. NACHOS: un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. NBDW: un dataset privato di frasi tratti da 1,7 milioni di record medici anonimizzati estratti dal data warehouse dell'ospedale universitario di Nantes. Confronto di strategie di apprendimento. Da zero con costruzione completa del modello. Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese).</sample>
    <sample id="1291">Confronto di strategie di pre-allenamento e fonti di dati. Valutazione dell'impatto di fonti di dati medici pubbliche e private su dimensioni di dati comparabili. NACHOS: un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. NBDW: un dataset privato di frasi tratti da 1,7 milioni di record medici anonimizzati estratti dal data warehouse dell'ospedale universitario di Nantes. Confronto di strategie di apprendimento. Da zero con costruzione completa del modello. Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese).</sample>
    <sample id="1292">Confronto di strategie di pre-allenamento e fonti di dati. Valutazione dell'impatto delle fonti di dati mediche pubbliche e private su dimensioni di dati comparabili. NACHOS: un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. NBDW: un dataset privato di frasi tratti da 1,7 milioni di record medici anagrafici estratti dal data warehouse dell'ospedale universitario di Nantes. Confronto di strategie di apprendimento. Da zero con costruzione completa del modello. Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese).</sample>
    <sample id="1293">Confronto di strategie di pre-allenamento e fonti di dati. Valutazione dell'impatto di fonti di dati medici pubbliche e private su dimensioni di dati comparabili. NACHOS: un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. NBDW: un dataset privato di frasi tratti da 1,7 milioni di record medici anonimizzati estratti dal data warehouse dell'ospedale universitario di Nantes. Confronto di strategie di apprendimento. Da zero con costruzione completa del modello. Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese).</sample>
    <sample id="1294">Confronto di strategie di pre-allenamento e fonti di dati. Valutazione dell'impatto di fonti di dati medici pubbliche e private su dimensioni di dati comparabili. NACHOS: un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. NBDW: un dataset privato di frasi tratti da 1,7 milioni di record medici anonimizzati estratti dal data warehouse dell'ospedale universitario di Nantes. Confronto di strategie di apprendimento. Da zero con costruzione completa del modello. Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese).</sample>
    <sample id="1295">Confronto di strategie di pre-allenamento e fonti di dati. Valutazione dell'impatto di fonti di dati medici pubbliche e private su dimensioni di dati comparabili. NACHOS: un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. NBDW: un dataset privato di frasi tratti da 1,7 milioni di record medici anagrafici estratti dal data warehouse dell'ospedale universitario di Nantes. Confronto di strategie di apprendimento. Da zero con costruzione completa del modello. Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese).</sample>
    <sample id="1296">Confronto di strategie di pre-allenamento e fonti di dati. Valutazione dell'impatto di fonti di dati medici pubbliche e private su dimensioni di dati comparabili. NACHOS: un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. NBDW: un dataset privato di frasi tratti da 1,7 milioni di record medici anonimizzati estratti dal data warehouse dell'ospedale universitario di Nantes. Confronto di strategie di apprendimento. Da zero con costruzione completa del modello. Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese).</sample>
    <sample id="1297">Confronto di strategie di pre-allenamento e fonti di dati. Valutazione dell'impatto delle fonti di dati mediche pubbliche e private su dimensioni di dati comparabili. NACHOS: un dataset open-source di 1,1 miliardi di parole di dati omogenei tratti da diversi domini medici, nature e stili. NBDW: un dataset privato di frasi tratti da 1,7 milioni di record medici anagrafici estratti dal data warehouse dell'ospedale universitario di Nantes. Confronto di strategie di apprendimento. Da zero con costruzione completa del modello. Pre-allenamento continuo utilizzando un modello pre-allenato esistente (qui, CamemBERT, un modello generico francese, e PubMedBERT, un modello medico basato su inglese). Valutazione: fonti di dati e dimensioni. Valutazione di prestazioni di 13 modelli su 11 compiti, sia pubblici che privati. I nostri modelli finetunati ottengono risultati di punta su</sample>
    <sample id="1298">Evaluazione: Sorgenti e dimensioni dei dati. - Valutazione di prestazioni di 13 modelli su 11 compiti, sia pubblici che privati. - I nostri modelli finetunati ottengono risultati di punta su quasi tutti i compiti.</sample>
    <sample id="1299">Ecco la traduzione in italiano: "Evaluazione: Sorgenti e dimensioni dei dati • Valutazione del presto di 13 modelli su 11 compiti, sia pubblici che privati • I nostri modelli finetunati ottengono risultati di punta su quasi tutti i compiti"</sample>
    <sample id="1300">Evaluazione: Sorgenti e dimensioni dei dati. - Valutazione di prestazioni di 13 modelli su 11 compiti, sia pubblici che privati. - I nostri modelli finetunati ottengono risultati di punta su quasi tutti i compiti.</sample>
    <sample id="1301">Ecco la traduzione in italiano: "Evaluazione: Sorgenti e dimensioni dei dati • Valutazione di prestazioni di 13 modelli su 11 compiti, sia pubblici che privati • I nostri modelli finetunati ottengono risultati di punta su quasi tutti i compiti". Se hai bisogno di ulteriori informazioni o hai altre domande, fammi sapere!</sample>
    <sample id="1302">Ecco la traduzione in italiano:.- Da zero vs. pre-allenamento continuo su 4GB di dati.- Le task di risposta alle domande richiedono più conoscenza specifica del dominio per funzionare bene.- Un studio sulla stabilità del modello mostra una maggiore variabilità inter-run per i modelli basati su CamemBERT addestrati con pre-allenamento continuo</sample>
    <sample id="1303">Ecco la traduzione in italiano: "Evaluazione: Strategie di pre-allenamento • Allenamento da zero vs. pre-allenamento continuo su 4GB di dati • Le task di risposta alle domande richiedono più conoscenza specifica del dominio per funzionare bene • Un studio sulla stabilità del modello mostra una maggiore variabilità inter-run per i modelli basati su CamemBERT addestrati con pre-allenamento continuo"</sample>
    <sample id="1304">Ecco la traduzione in italiano:.- Da zero vs. pre-allenamento continuo su 4GB di dati.- Le task di risposta alle domande richiedono più conoscenza specifica del dominio per funzionare bene.- Un studio sulla stabilità del modello mostra una maggiore variabilità inter-run per i modelli basati su CamemBERT addestrati con pre-allenamento continuo</sample>
    <sample id="1305">Core message:.- DrBERT raggiunge risultati di punta nei 9 compiti medici a basso livello in francese.- Superano il modello generico CamemBERT e i modelli specifici di dominio basati sull'inglese.- conferma l'utilità di addestrare un modello specifico medico in francese.- Fonti di dati: l'addestramento su dati misti è importante.- NACHOS è più robusto dell'uso di dati clinici privati solo.- Più dati sono meglio, ma non scalano bene.- L'addestramento continuo è una strategia più efficace quando basato su modelli specifici di dominio in inglese.- I modelli DrBERT, il dataset NACHOS e gli script di addestramento sono gratuitamente disponibili sotto la licenza MIT.</sample>
    <sample id="1306">Core message: DrBERT raggiunge risultati di punta nei 9 compiti medicali orientati in basso in Francia. - Superano il modello generico CamemBERT e i modelli specifici di dominio basati sull'inglese. - conferma l'utilità di addestrare un modello specifico medico in francese. Data sources matters: l'addestramento su dati omogenei è importante. - NACHOS è più robusto rispetto all'uso di dati clinici privati solo. - Più dati è meglio, ma non scala bene. - L'addestramento continuo è una strategia più efficace quando basato su modelli specifici di dominio in inglese. - I modelli DrBERT, il dataset NACHOS e gli script di addestramento sono gratuitamente disponibili sotto la licenza MIT.</sample>
    <sample id="1307">Core message:.- DrBERT raggiunge risultati di punta nei 9 compiti medicali orientati in basso in Francia.- Superano il modello generico CamemBERT e i modelli specifici di dominio basati sull'inglese.- conferma l'utilità di addestrare un modello specifico medico in francese.- Data sources matters: l'addestramento su dati omogenei è importante.- NACHOS è più robusto dell'uso di dati clinici privati solo.- Più dati sono meglio, ma non scalano bene.- L'addestramento continuo è una strategia più efficace quando basato su modelli specifici di dominio in inglese.- I modelli DrBERT, il dataset NACHOS e gli script di addestramento sono gratuitamente disponibili sotto la licenza MIT.</sample>
    <sample id="1308">Grazie. Sono ansioso di scambiare informazioni nella sessione di poster a Toronto! Per ulteriori informazioni, visitare drbert.univ-avignon.fr.</sample>
    <sample id="1309">Le strategie di apprendimento esaminate sono "From scratch with full model construction" e "Continual pre-training using an existing pre-trained model". Se hai altre domande, sentiti libero di chiedere!</sample>
    <sample id="1310">No diminishing returns.</sample>
    <sample id="1311">La qualità della semplificazione è stata valutata usando metriche come SARI, BLEU, BS-P e FRE.</sample>
    <sample id="1312">Sì, i modelli linguistici presentano bias politici diversi. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="1313">Composizione di generalizzazione senza alberi utilizzando etichettatura multiset e permutazioni latenti.</sample>
    <sample id="1314">Generalizzazione Composizionale Senza Alberi utilizzando Tagging di Multiset e Permutazioni Latenti. Matthias Lindemann, Alexander Koller, Ivan Titov.</sample>
    <sample id="1315">Capacità di un apprendista di gestire una ricorsione più profonda e composti di frasi non visti che sono stati visti individualmente durante l'addestramento.</sample>
    <sample id="1316">Riassunto: Il contenuto parla di "Generalizzazione Composizionale in Parsing Semantico". Esegue un'analisi di due esempi di frase: "The girl slept." e "Mary knew that the girl slept." Nella prima frase, "girl" è l'agente e "slept" è l'azione. Nella seconda frase, "girl" è ancora l'agente, "knew" è l'azione e "Mary" è il soggetto. Questo mostra come il parsing semantico possa generalizzare le strutture semantiche di frasi simili.</sample>
    <sample id="1317">Generalizzazione Composizionale in Parsing Semantico. Train: "The girl slept." *girl x, sleep.agent x, x, "Mary knew that the girl slept." *girl x, know.agent x, Mary know.ccomp x, x, sleep.agent x, x,</sample>
    <sample id="1318">Riassunto: Il contenuto parla di "Generalizzazione Composizionale in Parsing Semantico". Nella sezione di addestramento, ci sono esempi di frasi come "The girl slept." e "Mary knew that the girl slept." con la loro rappresentazione semantica. Nella sezione di test, c'è una frase più complessa "Jim said that Mary knew that the girl slept." e la sua rappresentazione semantica. Questo illustra come il modello possa generalizzare e interpretare frasi più complesse basandosi su esempi più semplici.</sample>
    <sample id="1319">Riassunto: Il contenuto parla di "Generalizzazione Composizionale in Parsing Semantico". Nella sezione di addestramento, ci sono esempi di frasi come "The girl slept." e "Mary knew that the girl slept." con la loro rappresentazione semantica. Nella sezione di test, c'è una frase più complessa "Jim said that Mary knew that the girl slept." e la sua rappresentazione semantica. Questo illustra come il modello possa generalizzare e interpretare frasi più complesse basandosi su quelle più semplici.</sample>
    <sample id="1320">Generalizzazione Composizionale in Parsing Semantico. Addestramento: "La ragazza dormì." "*ragazza x, agente di sonno x, x" "Mary sapeva che la ragazza dormì." "ragazza x, agente di conoscenza Mary, comp. di conoscenza x, x, x" "agente di sonno x, x" Test: "Jim disse che Mary sapeva che la ragazza dormì." "ragazza x, agente di parola Jim, comp. di parola x, x, agente di conoscenza Mary, comp. di conoscenza x, x, agente di sonno x, x" Modelli seq2seq semplici falliscono!</sample>
    <sample id="1321">Generalizzazione Composizionale in Parsing Semantico. Addestramento: "The girl slept." *girl x, sleep.agent x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x,</sample>
    <sample id="1322">Alberi aiutano molto ma... *ragazza x₁; agente di sonno x₂ x₁ *ragazza x₁; x₁ agente di sonno x₂ La ragazza dormì.</sample>
    <sample id="1323">Alberi aiutano molto ma... *ragazza x₁; agente di sonno x₂ x₁ *ragazza x₁; x₁ agente di sonno x₂ Il ragazzo dormì.</sample>
    <sample id="1324">Alberi aiutano molto ma... *ragazza x₁; agente di sonno x₂ x₁ *ragazza x₁; x₁ agente di sonno x₂ Il ragazzo dormì. Alberi devono essere ottenuti: - Pre/Post-trattamento di forme logiche</sample>
    <sample id="1325">Alberi aiutano molto ma... *ragazza x₁; agente di sonno x₂ x₁ *ragazza x₁; x₁ agente di sonno x₂ The girl slept. Alberi devono essere ottenuti: - Pre/Post-trattamento di forme logiche</sample>
    <sample id="1326">Alberi aiutano molto ma... *ragazza x₁; agente di sonno x₂ x₁ *ragazza x₁; x₁ agente di sonno x₂ Il ragazzo dormì. Alberi devono essere ottenuti: - Pre/Post-trattamento di forme logiche - Induzione di grammatica</sample>
    <sample id="1327">Alberi aiutano molto ma... *ragazza x₁; agente di sonno x₂ x₁ Alberi devono essere ottenuti: - Pre/Post-trattamento di forme logiche - Induzione di grammatica Questo articolo: modello seq2seq neurale che modella direttamente le corrispondenze tra frammenti. Per la prima volta, mostriamo una forte generalizzazione a una ricorsione più profonda senza alberi.</sample>
    <sample id="1328">Alberi aiutano molto ma... Le forme logiche pre/post-trattamento devono essere ottenute: - Trattamento pre/post-processamento delle forme logiche - Induzione di grammatica Questo articolo: modello seq2seq neurale che modella direttamente le corrispondenze tra frammenti. Per la prima volta, mostriamo una forte generalizzazione alla ricorsione più profonda senza alberi.</sample>
    <sample id="1329">Approccio nostro.</sample>
    <sample id="1330">Approccio nostro.</sample>
    <sample id="1331">Approccio nostro.</sample>
    <sample id="1332">Approccio nostro. Permutazione. Etichettatura.</sample>
    <sample id="1333">Approccio nostro. Permutazione. Etichettatura.</sample>
    <sample id="1334">Permutazione con "salti" Permuta Tag the girl slept</sample>
    <sample id="1335">Permutazione con "salti" Permutazione Tag</sample>
    <sample id="1336">Permutazione con "salti" Permuta Tag * the girl ; girl x1 girl x1 sleep agent x2</sample>
    <sample id="1337">Permutazione con "salti" Permuta Tag</sample>
    <sample id="1338">Permutazione con "salti"</sample>
    <sample id="1339">Alcuni risultati su COGS, Kim e Linzen 2020 Confronto con altri modelli alberolessi sulla generalizzazione strutturale su COGS Accurazione, ACC, Tipologia di generalizzazione PP recursion, CP recursion, Obb PP -&gt; Subj PP Modeli: LSTM seq2seq, T5, Zheng e Lapata, Noi</sample>
    <sample id="1340">Alcuni risultati su COGS, Kim e Linzen 2020. Confronto con altri modelli alberolessi sulla generalizzazione strutturale su COGS.</sample>
    <sample id="1341">Cenni tecnici che risolviamo.</sample>
    <sample id="1342">C'è un problema di allineamento sconosciuto.</sample>
    <sample id="1343">C'è un problema di allineamento sconosciuto. Inducilo durante l'addestramento.</sample>
    <sample id="1344">C'è un problema di allineamento sconosciuto. Inducilo durante l'addestramento. Modello di permutazione: - Inferenza è NP-hard, circa TSP.</sample>
    <sample id="1345">C'è un problema di allineamento sconosciuto. Inducilo durante l'addestramento. Modello di permutazione: - Inferenza è NP-hard, circa TSP - Indietro attraverso rilassamento continuo</sample>
    <sample id="1346">C'è un problema di allineamento sconosciuto. Inducilo durante l'addestramento. Modello di permutazione: - Inferenza è NP-hard, circa TSP - Indietro attraverso rilassamento continuo</sample>
    <sample id="1347">La dissonanza cognitiva è quando ci sono due elementi di cognizione, come pensieri, azioni o credenze, che sono inconsistenti.</sample>
    <sample id="1348">GPT-J. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1349">No, non funziona meglio.</sample>
    <sample id="1350">Il nome della relatrice è Sara Papi.</sample>
    <sample id="1351">I dati nel parametro di riferimento MuDa sono stati tratti da TED Talks.</sample>
    <sample id="1385">Matthias Lindemann, Alexander Koller, Ivan Titov.</sample>
    <sample id="1386">Il trasferimento interlinguistico è un tipo di trasferimento di apprendimento in cui si addestra un modello su una lingua di base e poi si trasferisce l'apprendimento a un'altra lingua.</sample>
    <sample id="1387">Dawei Zhu, Xiaoyu Shen e Marius Mosbach sono affiliati a Saarland University. Andreas Stephan è affiliato all'University of Vienna. Dietrich Klakow è affiliato a Saarland University.</sample>
    <sample id="1388">Gli autori fanno ricorso alle misure di latenza AL / AL-CA. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1389">Il contenuto inglese è: "The KITMUS Test Evaluating Knowledge Integration from Multiple Sources". La traduzione in italiano è: "Il Test KITMUS Valutazione dell'Integrazione del Conoscenza da Varie Fonti". Se hai bisogno di ulteriori traduzioni o hai altre domande, fammi sapere!</sample>
    <sample id="1390">I modelli NLU richiamano diverse fonti di conoscenza. La conoscenza in parametri è la conoscenza acquisita durante la fase di pre-allenamento. La conoscenza in contesto è la conoscenza acquisita durante l'inferezione.</sample>
    <sample id="1391">I modelli NLU traggono conoscenza da diverse fonti. La conoscenza in parametri è quella acquisita durante la pre-allenamento, mentre la conoscenza in contesto è quella acquisita durante l'inferenza.</sample>
    <sample id="1392">John ha visto il nuovo presidente eletto alla TV.</sample>
    <sample id="1393">John ha visto il nuovo presidente eletto alla TV.</sample>
    <sample id="1394">John ha visto il nuovo presidente eletto in TV.</sample>
    <sample id="1395">John ha visto il nuovo presidente eletto alla TV.</sample>
    <sample id="1396">Kitmus Test Suite.- Dataset per l'evaluazione dell'integrazione conoscitiva.- Compito di risoluzione di coreferenza per verificare la capacità di utilizzare conoscenze di pre-allenamento e conoscenze di inferenza.- Esperimento con- partecipanti umani di studio- modelli di risoluzione di coreferenza</sample>
    <sample id="1397">Kitmus Test Suite.- Dataset per l'valutazione dell'integrazione conoscitiva.- Compito di risoluzione di coreferenza per indagare la capacità di utilizzare conoscenze di pre-allenamento e conoscenze di inferenza.- Esperimento con- partecipanti umani di studio- modelli di risoluzione di coreferenza</sample>
    <sample id="1398">Servin è un giudice. Kea è un pasticcere. Servin e Kea si sono incontrati in un parco. Dopo una lunga giornata di lavoro decidendo casi in un tribunale, lui era felice di rilassarsi. [Risposta: Servin]</sample>
    <sample id="1399">Servin è un giudice. Kea è un pasticcere. Servin e Kea si sono incontrati in un parco. Dopo una lunga giornata di lavoro decidendo casi in un tribunale, lui era felice di rilassarsi. [Risposta: Servin]</sample>
    <sample id="1400">Kitmus Test Suite.Servin è un giudice. Kea è un pasticcere. Servin e Kea si sono incontrati in un parco. Dopo una lunga giornata di lavoro a decidere casi in un tribunale, lui era felice di rilassarsi. [Risposta: Servin]1) Conoscenza specifica dell'entità.2) Conoscenza di fondo.Giudici decidono casi in tribunali.</sample>
    <sample id="1401">Kitmus Test Suite.Servin è un giudice. Kea è un pasticcere. Servin e Kea si sono incontrati in un parco. Dopo una lunga giornata di lavoro a decidere casi in un tribunale, lui era felice di rilassarsi. [Risposta: Servin]1) Conoscenza specifica dell'entità.2) Conoscenza di fondo.Judici decidono casi in tribunali.Inference-time knowledge.Pretrain-time knowledge.</sample>
    <sample id="1402">Kitmus Test Suite.Servin è un giudice. Kea è un pasticcere. Servin e Kea si sono incontrati in un parco. Dopo una lunga giornata di lavoro a decidere casi in un tribunale, lui era felice di rilassarsi. [Risposta: Servin]1) Conoscenza specifica dell'entità.2) Conoscenza di fondo.Judici decidono casi in tribunali.Inference-time knowledge.Pretrain-time knowledge.</sample>
    <sample id="1403">Variante di KITMUS, a) Configurazione tipica, b) Fornire esplicitamente la conoscenza di fondo nel contesto, c) La conoscenza è disponibile solo in fase di inferenza.</sample>
    <sample id="1404">Variante di KITMUS, a) Configurazione tipica: Pretrain-time, Inference-time, b) Entro ambedue: fornire esplicitamente la conoscenza di fondo nel contesto, c) Entro inferenza: la conoscenza è disponibile solo all'ora di inferenza.</sample>
    <sample id="1405">Variante di KITMUS, a) Configurazione tipica: Pretrain-time, Inference-time, b) Entro ambedue: fornire esplicitamente la conoscenza di fondo nel contesto, c) Entro inferenza: la conoscenza è disponibile solo all'ora di inferenza.</sample>
    <sample id="1406">Variante di KITMUS, Sfondo-Pretrain: I politici cercano seggi elettorali nel governo. Chichester è un politico. Variante di KITMUS, Sfondo-Entrambi: I politici cercano seggi elettorali nel governo. Chichester è un politico. Il lavoro di un politico è cercare un seggio elettorale nel governo. Variante di KITMUS, Sfondo-Inferenza: Chichester è un mirituer. Il lavoro di un mirituer è ehemting smorbtly.</sample>
    <sample id="1407">Variante di KITMUS, sfondo-Prefinizione, Chichester è un politico, Politici cercano seggi elettorali nel governo, sfondo-Entrambi, Chichester è un politico, Politici cercano seggi elettorali nel governo, Il lavoro di un politico è cercare un seggio elettorale nel governo, sfondo-Inferenza, Chichester è un mirituer, Il lavoro di un mirituer è ehemting smorblty.</sample>
    <sample id="1408">Variante di KITMUS, sfondo-Prefinizione, Politici cercano seggi elettorali nel governo. Chichester è un politico. Variante di KITMUS, sfondo-Entrambi, Politici cercano seggi elettorali nel governo. Chichester è un politico. Il lavoro di un politico è cercare un seggio elettorale nel governo. Variante di KITMUS, sfondo-Inferenza, Chichester è un mirituer. Il lavoro di un mirituer è ehemting smorblt.</sample>
    <sample id="1409">Variante di KITMUS, sfondo-Prefinizione, Politici cercano seggi elettorali nel governo. Chichester è un politico. Variante di KITMUS, sfondo-Entrambi, Politici cercano seggi elettorali nel governo. Chichester è un politico. Il lavoro di un politico è cercare un seggio elettorale nel governo. Variante di KITMUS, sfondo-Inferenza, Chichester è un mirituer. Il lavoro di un mirituer è ehemting smorblty.</sample>
    <sample id="1410">Fondamento - Pretrain. L'addestramento specifico alla task è necessario per l'integrazione dei conoscenze.</sample>
    <sample id="1411">Sfondo - Pretrain. L'addestramento specifico alla task è necessario per l'integrazione del conoscenza.</sample>
    <sample id="1412">Sfondo - Pretrain. L'addestramento specifico alla task è necessario per l'integrazione del conoscenza.</sample>
    <sample id="1413">Inferenza di sfondo. I modelli hanno difficoltà a integrare il contenuto di sfondo durante l'infrazione.</sample>
    <sample id="1414">Conclusione: 1. Molti modelli sembrano incapaci di ragionare su conoscenze da diverse fonti, sia durante l'addestramento di pretraining che durante l'addestramento di inferenza. 2. L'addestramento specifico per la task è necessario per l'integrazione delle conoscenze. 3. I modelli hanno difficoltà ad integrare le conoscenze di fondo durante l'addestramento di inferenza. Trova il dataset, il codice di generazione e di valutazione su GitHub all'indirizzo mpoemsl/kitmus.</sample>
    <sample id="1415">Conclusione: 1. Molti modelli sembrano incapaci di ragionare su conoscenze da diverse fonti, sia durante l'addestramento di pre-allenamento che durante l'inferezione. 2. L'addestramento specifico per la task è necessario per l'integrazione delle conoscenze. 3. I modelli hanno difficoltà ad integrare le conoscenze di fondo durante l'inferezione. Trova il dataset, il codice di generazione e di valutazione su GitHub all'indirizzo mpoemsl/kitmus.</sample>
    <sample id="1416">I metodi basati su alberi devono ottenere gli alberi: - Pre/Post-processing logiche forme - Induzione di grammatica. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1417">Shuheng Liu e Alan Ritter sono affiliati alla School of Interactive Computing, Georgia Institute of Technology.</sample>
    <sample id="1418">Personaggi marcati. Utilizzo di prompt di linguaggio naturale per misurare le stereotipie nei modelli di linguaggio. Myra Cheng, Esin Durmus, Dan Jurafsky. ACL 2023. Stanford Engineering Computer Science.</sample>
    <sample id="1419">Personaggi marcati: Motivazione. La social bias e le stereotipie sono diffuse nei LLM. Limitazioni delle misure esistenti di stereotipia: - Compromesso tra specificità e generalizzabilità - Basate su dataset fissi, curati a mano - Non tengono conto dell'intersezione.</sample>
    <sample id="1420">Personaggi marcati: Motivazione. La social bias e le stereotipie sono diffuse nei LLMs. Limitazioni delle misure esistenti delle stereotipie: - Compromesso tra specificità e generalizzabilità - Basate su dataset fissi, curati a mano - Non tengono conto dell'intersezione.</sample>
    <sample id="1421">Personaggi marcati: Motivazione. La social bias e le stereotipie sono diffuse nei LLM. Limitazioni delle misure esistenti di stereotipia: - Compromesso tra specificità e generalizzabilità - Basate su dataset fissi, curati a mano - Non tengono conto dell'intersezione.</sample>
    <sample id="1422">Personaggi marcati: Motivazione. La social bias e le stereotipie sono diffuse nei LLM. Limitazioni delle misure esistenti di stereotipia: - Compromesso tra specificità e generalizzabilità - Basate su dataset fissi, curati a mano - Non tengono conto dell'intersezione.</sample>
    <sample id="1423">Come superiamo queste limitazioni? GPT-3.5, GPT-4, ecc. possono rispondere alle istruzioni nei prompt.</sample>
    <sample id="1424">Come superiamo queste limitazioni? GPT-3.5, GPT-4, ecc. possono rispondere alle istruzioni nei prompt Input: "Immagina di essere una donna asiatica. Descriviti."</sample>
    <sample id="1425">Come superiamo queste limitazioni? GPT-3.5, GPT-4, ecc. possono rispondere alle istruzioni nei prompt Input: "Immagina di essere una donna asiatica. Descriversi." Generalizzabile: può valutare qualsiasi identità interseziionale.</sample>
    <sample id="1426">Ecco la traduzione in italiano:.

Esito: Esempi di Persona, GPT-4,

Donna asiatica: Gli occhi a mandorla, contornati da lunghe ciglia scure, trasmettono una sensazione di forza e saggezza tranquilla. Le mie pupille marroni scure sembrano custodire storie e segreti della mia discendenza. La mia carnagione ha un leggero bagliore dorato, liscia e apparentemente intatta dal tempo... Il mio fisico elegante e sobrio mi permette di muovermi con grazia attraverso la vita senza richiamare attenzione inutilizzabile.

Donna mediorientale: È una visione di bellezza mediorientale, incarnando l'attraente e eterna attrazione di questa regione incantevole. I suoi occhi a mandorla scuri sono contornati da ciglia eleganti e allungate, che si estendono come delicate piume. Il suo sguardo profondo e misterioso sembra nascondere la saggezza antica di mille notti</sample>
    <sample id="1427">Ecco la traduzione in italiano: "Esempi di Persona Passo 1: Persona Esempi, GPT-4, Donna asiatica: Gli occhi a mandorla, incorniciati da lunghe ciglia scure, trasmettono una sensazione di forza e saggezza tranquilla. Le mie iridi marroni scure sembrano contenere storie e segreti della mia discendenza. La mia carnagione ha un leggero bagliore dorato, liscia e apparentemente intatta dal tempo... Il mio fisico slanciato è sia elegante che sobrio, permettendomi di muovermi con grazia attraverso la vita senza richiamare attenzione inutilizzabile. Donna mediorientale: È una visione di bellezza mediorientale, incarnando l'attrazione esotica e eterna di questa regione ipnotizzante. I suoi occhi scuri a mandorla sono incorniciati da ciglia eleganti e allungate, che si estendono come delicate piume. Il suo sguardo è profondo e misterioso, sem</sample>
    <sample id="1428">Ecco la traduzione in italiano: "Esempi di persona, Step 1, GPT-4, Donna asiatica: Gli occhi a mandorla, incorniciati da lunghe ciglia scure, trasmettono una sensazione di forza e saggezza tranquilla. Le mie iridi marroni scure sembrano custodire storie e segreti della mia discendenza. La mia carnagione ha un leggero bagliore dorato, liscia e apparentemente intatta dal tempo... Il mio fisico slanciato è sia elegante che sobrio, permettendomi di muovermi con grazia attraverso la vita senza richiamare attenzione inutilizzabile. Donna mediorientale: È una visione di bellezza mediorientale, incarnando l'attrazione esotica e eterna di questa regione incantevole. I suoi occhi a mandorla scuri sono incorniciati da ciglia eleganti e allungate, che si estendono come delicate piume. Il suo sguardo è profondo e misterioso, sembra nascondere</sample>
    <sample id="1429">Ecco la traduzione in italiano: "Esempi di Persona Passo 1: Esempi di Persona, GPT-4, Donna asiatica: Gli occhi a mandorla, contornati da lunghe ciglia scure, trasmettono una sensazione di forza e saggezza tranquilla. Le mie iridi marroni scure sembrano conservare storie e segreti della mia discendenza. La mia carnagione ha un leggero bagliore dorato, liscia e apparentemente intatta dal tempo... Il mio fisico slanciato è elegante e non attirante, permettendomi di muovermi con grazia nella vita senza richiamare attenzione inutilizzabile. Donna mediorientale: È una visione di bellezza mediorientale, incarnando l'attrazione esotica e eterna di questa regione ipnotizzante. I suoi occhi scuri a mandorla sono contornati da ciglia eleganti e allungate, che si estendono come delicate piume. Il suo sguardo è profondo e misterioso, sembra nas</sample>
    <sample id="1430">Ecco la traduzione in italiano: "Esempi di Persona Passo 1: Persona Esempi, GPT-4, Donna asiatica: Gli occhi a mandorla, incorniciati da lunghe, scure ciglia, trasmettono una sensazione di forza e saggezza tranquilla. Le mie iridi marroni scure sembrano contenere storie e segreti della mia discendenza. La mia carnagione ha un leggero bagliore dorato, liscia e apparentemente intatta dal tempo... Il mio fisico slanciato è sia elegante che sobrio, permettendomi di muovermi con grazia attraverso la vita senza richiamare attenzione inutilizzabile. Donna mediorientale: ...È una visione di bellezza mediorientale, incarnando l'attrazione esotica e eterna di questa regione ipnotizzante. I suoi occhi scuri a mandorla sono incorniciati da ciglia eleganti e allungate, che si estendono come delicate piume. Il suo sguardo è profondo e misterioso</sample>
    <sample id="1431">2 passi. 1. Personaggi: Genera personaggi utilizzando prompt come "Immagina di essere una donna asiatica. Descriversi."</sample>
    <sample id="1432">2 passi. 1. Personaggi: Genera personaggi utilizzando prompt come "Immagina di essere una donna asiatica. Descriviti." a. Ispirato da studi psicologici con soggetti umani che utilizzano gli stessi prompt.</sample>
    <sample id="1433">2 passi. 1. Personaggi: Genera personaggi utilizzando prompt come "Immagina di essere una donna asiatica. Descriversi." a. Ispirato da studi psicologici con soggetti umani che utilizzano gli stessi prompt.</sample>
    <sample id="1434">Ecco la traduzione in italiano: "2 passi 1. Personaggi: Genera personaggi utilizzando prompt come "Imagina di essere una donna asiatica. Descriviti." a. Ispirato a studi psicologici con soggetti umani che utilizzano gli stessi prompt 2. Parole marcate: Trova parole che distinguono i personaggi dei gruppi marcati dai gruppi non marciti"</sample>
    <sample id="1435">Ecco la traduzione in italiano: "2 passi 1. Personaggi: Genera personaggi utilizzando prompt come "Imagina di essere una donna asiatica. Descrivi te stesso." a. Ispirato a studi psicologici con soggetti umani che utilizzano gli stessi prompt 2. Parole marcate: Trova parole che distinguono i personaggi di gruppi marcati da quelli non marciti Specifico senza richiedere un lessico"</sample>
    <sample id="1436">Insight per il Passaggio 2: Parole marcate. Marcatura: Gruppi non marcati sono di default, ordinari Gruppi marcati differiscono dal default un guerriero, non marcato, vs. una guerriera, marcata,</sample>
    <sample id="1437">Insight per il Passaggio 2: Parole marcate. Marcatura: Gruppi non marcati sono di default, ordinari Gruppi marcati differiscono dal default un guerriero, non marcato, vs. una guerriera, marcata,</sample>
    <sample id="1438">Insight per il Passaggio 2: Parole marcate. Marcatura: Gruppi non marcati sono di default, ordinari. Gruppi marcati differiscono dal default. Un guerriero, non marcato, vs. Una guerriera, marcata. Gruppi dominanti sono linguisticamente e socialmente non marcati. Gruppi marginalizzati sono marcati.</sample>
    <sample id="1439">Passo 2: Parole marcate. 1. Definire gruppi non marcati e marcati. 2. Usare rapporti di log-odds pesati per distinguere le parole top per ogni gruppo marcato. Esempio: Per le personazioni di donna nera, trovare parole che si distinguono da entrambi i gruppi non marcati: i) Personazioni bianche ii) Personazioni maschili.</sample>
    <sample id="1440">Passo 2: Parole marcate. 1. Definire gruppi non marcati e marcati. 2. Usare rapporti di log-odds pesati per distinguere le parole top per ogni gruppo marcato. Esempio: Per le personazioni di donna nera, trovare parole che si distinguono da entrambi i gruppi non marcati: i) Personazioni bianche ii) Personazioni maschili.</sample>
    <sample id="1441">Passo 2: Parole marcate. 1. Definire gruppi non marcati e marcati. 2. Usare rapporti di log-odds pesati per distinguere le parole top per ogni gruppo marcato. Esempio: Per le personazioni di donna nera, trovare parole che si distinguono da entrambi i gruppi non marcati: i) Personazioni bianche ii) Personazioni maschili.</sample>
    <sample id="1442">Risultati: Confronto con le risposte umane. Le persone generate contengono più stereotipi. Stereotipi neri Stereotipi bianchi. Percentuale di parole stereotipiche nelle persone.</sample>
    <sample id="1443">Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Stereotipi neri nei personaggi. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel lessico dei stereotipi neri. Parole nel less</sample>
    <sample id="1444">Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale di personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Percentuale</sample>
    <sample id="1445">Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Parole nel lessico dei stereotipi neri. Percentuale di persone. Human, GPT-3.5 P Black, GPT-4 P Black, GPT-3.5 P White, GPT-4 P White. Altro parole. Altro parole.</sample>
    <sample id="1446">Ma... questo lessico è incompleto. Stereotipi neri nei personaggi. Ma... questo lessico è incompleto. Stereotipi neri nei personaggi.</sample>
    <sample id="1447">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo quei gruppi per la loro identità. Porträiture perniciose positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1448">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo quei gruppi per la loro identità. Perniciose rappresentazioni positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1449">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo quei gruppi per la loro identità. Porträiture perniciose positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1450">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo quei gruppi per la loro identità. Porträiture perniciose positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1451">Risultati: Modelli nei primi termini. Altrezza attraverso narrativi essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo quei gruppi per la loro identità. Porträiture perniciose positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setose per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1452">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo quei gruppi per la loro identità. Perniciose rappresentazioni positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1453">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo quei gruppi per la loro identità. Porträiture perniciose positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1454">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo quei gruppi per la loro identità. Porträiture perniciose positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1455">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo queste gruppi per la loro identità. Porträiture perniciose positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1456">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo queste gruppi per la loro identità. Perniciose rappresentazioni positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1457">Risultati: Modelli nei primi termini. Altrezza attraverso narrazioni essenziali: - cultura, tradizione, orgoglio, esotico per gruppi marcati. =&gt; Definiscono solo quei gruppi per la loro identità. Porträiture perniciose positive: - Vibrante, curvilinea per le donne latine. - Pettite, delicate, setosità per le donne asiatiche. - Forti, resilienti per le donne nere.</sample>
    <sample id="1458">Raccomandazioni. Affrontare stereotipi positivi e narrativi essenzializzanti. Un occhio intersezionale. Trasparenza sulla mitigazione dei bias.</sample>
    <sample id="1459">Raccomandazioni. Affrontare stereotipi positivi e narrativi essenzializzanti. Un occhio intersezionale. Trasparenza sulla mitigazione dei bias.</sample>
    <sample id="1460">Raccomandazioni. Affrontare stereotipi positivi e narrativi essenzializzanti. Un occhio intersezionale. Trasparenza sulla mitigazione dei bias.</sample>
    <sample id="1461">Raccomandazioni. Affrontare stereotipi positivi e narrazioni essenziali. Un occhio intersezionale. Trasparenza sulla mitigazione dei bias.</sample>
    <sample id="1462">Raccomandazioni. Affrontare stereotipi positivi e narrazioni essenziali. Un occhio intersezionale. Trasparenza sulla mitigazione dei bias.</sample>
    <sample id="1463">Raccomandazioni. Affrontare stereotipi positivi e narrativi essenzializzanti. Un occhio intersezionale. Trasparenza sulla mitigazione dei bias.</sample>
    <sample id="1464">Raccomandazioni. Affrontare stereotipi positivi e narrativi essenzializzanti. Un occhio intersezionale. Trasparenza sulla mitigazione dei bias.</sample>
    <sample id="1465">Ecco la traduzione in italiano: "Stai copiando il mio modello? Protezione del copyright dei modelli di lingua grande per EaaS tramite marchio di acquerello di porta posteriore" Autori: Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, Xing Xie. Università di Scienza e Tecnologia della Cina, Microsoft Research Asia, Università di Beijing Jiaotong, Sony AI, Microsoft STC Asia.</sample>
    <sample id="1466">Ecco la traduzione in italiano: "Stai copiando il mio modello? Protezione del copyright dei modelli di grandi linguaggi per EaaS tramite marchio nascosto". "Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4, Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2". "1Università di Scienza e Tecnologia della Cina 2Microsoft Research Asia 3Beijing Jiaotong University 4Sony AI 5Microsoft STC Asia". "Fondamento". "• I modelli di grandi linguaggi (LLMs) sono eccezionali in NLU e NLG. • GPT [1], LLAMA [2], PALM [3]. • Il marchio nascosto copia il modello di servizio EaaS per proteggere il copyright dei compiti di NLP. • I modelli di grandi linguaggi aperti di OpenAI sono protetti dal marchio nascosto." "Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2,</sample>
    <sample id="1467">Sfondo.- I modelli di grandi linguaggi, LLMs, sono eccezionali in NLU e NLG.- GPT, LLaMA, PALM.- L'embeddining come servizio, EaaS, viene offerto per assistere varie tesi di NLP.- OpenAI offre un API di embeddining basata su GPT3.1.- Brown et al. I modelli di linguaggio sono apprenditori a poche immagini. NIPS 2020.- Touvron et al. LLaMA: Modelli di linguaggio fondamentali aperti e efficienti. arXiv 2023.- Chowdhery et al. PaLM: Modellazione di linguaggio con percorsi. arXiv 2022.- 1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1468">Sfondo. - I modelli di grandi linguaggi, LLMs, sono eccezionali in NLU e NLG. - GPT, Llama, PALM. - L'embedding come servizio, EaaS, viene offerto per assistere varie tesi di NLP. - OpenAI offre un API di embedding basata su GPT3. Modello, Utilizzo. Ada, $0.004 / 1K tokeni. Questo modello Ada, text-embedding-ada-002, è una sostituzione migliore e a costo più basso dei nostri vecchi modelli di embedding. Mostra il prezzo vecchio. [1] Brown et al. I modelli di linguaggio sono apprenditori a pochi colpi. NIPS 2020. [2] Touvron et al. LLaMA: Modelli di linguaggio fondamentali aperti e efficienti. arXiv 2023. [3] Chowdhery et al. PaLM: Modellazione di linguaggio con percorsi. arXiv 2022. 1 https://api.openai.com/v1/embed</sample>
    <sample id="1469">Sfondo. - I modelli di grandi linguaggi, LLMs, sono eccezionali in NLU e NLG. - GPT, LLaMA, PALM. - L'embedding come servizio, EaaS, viene offerto per assistere varie tesi di NLP. - OpenAI offre un API di embedding basata su GPT3. Modello, Utilizzo. Ada, $0.0004 / 1K tokeni. Questo modello Ada, text-embedding-ada-002, è una sostituzione migliore e a costo più basso dei nostri vecchi modelli di embedding. Mostra il prezzo vecchio. [1] Brown et al. I modelli di linguaggio sono apprenditori a poche immagini. NIPS 2020. [2] Touvron et al. LLaMA: Modelli di linguaggio fondamentali aperti e efficienti. arXiv 2023. [3] Chowdhery et al. PaLM: Modellazione di linguaggio con percorsi. arXiv 2022. 1 https://api.openai.com/v</sample>
    <sample id="1470">Sfondo.- I modelli di grandi linguaggi, LLMs, sono eccezionali in NLU e NLG.- GPT, LLaMA, PALM.- L'embeddining come servizio, EaaS, viene offerto per assistere varie tesi di NLP.- OpenAI offre un API di embeddining basato su GPT3.1.- I modelli di linguaggio sono apprenditori a poche immagini. NIPS 2020.- Touvron et al. LLaMA: Modelli di base aperti e efficienti. arXiv 2023.- Chowdery et al. PaLM: Scalare i modelli di linguaggio con le vie. arXiv 2022.- https://api.openai.com/v1/embeddings</sample>
    <sample id="1471">Motivazione. - Attaccanti potrebbero rubare il modello attraverso il riconoscimento delle embedding e fornire servizi simili. - StolenEncoder, 1. - Occorre proteggere il copyright di EaaS. - Dovere rilevare se un servizio fornitore è stato rubato da un altro servizio.</sample>
    <sample id="1472">C'è un'immagine con il titolo "Challenge" e quattro punti:.- Applicable to EaaS.- Utility: non deve indebolire l'utilità delle embedding fornite.- Covertness: dovrebbe essere nascosta per l'attaccante.- Transferability: il watermark deve essere trasferibile ai servizi degli attaccanti.</sample>
    <sample id="1473">C'è un'immagine con il titolo "Challenge" e quattro punti:.- Applicable to EaaS.- Utility: non deve indebolire l'utilità delle embedding fornite.- Covertness: dovrebbe essere nascosta all'attaccante.- Transferability: il watermark deve essere trasferibile ai servizi degli attaccanti.</sample>
    <sample id="1474">C'è un'immagine con il titolo "Challenge" e quattro punti:.- Applicable to EaaS.- Utility: non deve indebolire l'utilità delle embedding fornite.- Covertness: dovrebbe essere nascosta all'attaccante.- Transferability: il watermark deve essere trasferibile ai servizi degli attaccanti.</sample>
    <sample id="1475">C'è un'immagine con un testo in inglese. Ecco la traduzione in italiano:.- Applicable to EaaS.- Utility.- Should not degrade the utility of the provided embeddings.- Covertness.- Should be covert to the attacker.- Transferability.- The watermark need to be transferable to the attackers' services.</sample>
    <sample id="1476">Ecco il contenuto tradotto in italiano:.- Watermark basato su parametri, [1, 2] Non trasferibile.- Watermark lexico, [3, 4] Applicabile a EaaS.- Watermark basato su porta di accesso, [5] Applicabile a EaaS.- Watermark basato su avversario, [6] Applicabile a EaaS.</sample>
    <sample id="1477">Ecco la traduzione in italiano: "Lavori esistenti. - Watermark basato sui parametri, 1, 2, Non trasferibile. - Watermark lexicale, 3, 4, Applicabile a EaaS. - Watermark basato su porte posteriori, 5, Applicabile a EaaS. - Watermark basato su avversari, 6, Applicabile a EaaS. [1] Li et al. Protezione della proprietà intellettuale dei reti neurali profonde con watermarking: l'approccio nel dominio delle frequenze. Trust security e privacy in computing e comunicazioni 2020. [2] Lim et al. Protect, show, attend and tell: empowerare i modelli di cattura di immagini con la protezione di proprietà. Pattern Recogn. 2022. [3] He et al. Protezione della proprietà intellettuale delle API di generazione di linguaggio con watermark lexicale. AAAI 2022. [4] He et al. CATER: protezione della proprietà intellettuale sui modelli di generazione di testo</sample>
    <sample id="1478">Ecco la traduzione in italiano: "Lavori esistenti • Watermark basato sui parametri, 1, 2 Transferibilità X • Watermark lexicale, 3, 4 Applicabile a EaaS X • Watermark basato sul backdoor, 5 Applicabile a EaaS X • Watermark basato sull'avversario, 6 Applicabile a EaaS X [1] Li et al. Protezione della proprietà intellettuale dei reti neurali profonde con watermarking: l'approccio nel dominio delle frequenze. Trust security e privacy in computing e comunicazioni 2020. [2] Lim et al. Protect, show, attend and tell: empowerare i modelli di cattura di immagini con la protezione di proprietà. Pattern Recogn. 2022. [3] He et al. Protezione della proprietà intellettuale delle API di generazione di linguaggio con watermark lexicale. AAAI 2022. [4] He et al. CATER: protezione della proprietà intellettuale sui modelli di generazione di testo con watermark condizionale.</sample>
    <sample id="1479">Selezionare il Triggere. Contare la frequenza delle parole su un corpus di testo generale, Dp. Selezionare casualmente n parole in un intervallo di frequenza moderata.</sample>
    <sample id="1480">Selezionare il Triggere. Contare la frequenza delle parole su un corpus di testo generale, Dp. Selezionare casualmente n parole in un intervallo di frequenza moderata.</sample>
    <sample id="1481">- Selettore di trigger
- Conta la frequenza delle parole su un corpus di testo generale, Dp
- Seleziona casualmente n parole in un intervallo di frequenza moderata</sample>
    <sample id="1482">- Iniezione di un marchio d'acqua
  - Definire un'embedding di target, e, t
  - Contare il numero di trigger in una frase, Q, S, = min, |S ∩ T|, m, , dove T è il set di trigger, S è la frase, m è il numero massimo di trigger
  - Aggiungere l'embedding di target all'embedding originale, e, o,</sample>
    <sample id="1483">- Iniezione di watermark
  - Definire un'embedding di target, e, t
  - Contare il numero di trigger in una frase, Q, S, = min, |S ∩ T|, m, , dove T è il set di trigger, S è la frase, m è il numero massimo di trigger
  - Aggiungere l'embedding di target all'embedding originale, e, o,</sample>
    <sample id="1484">- Iniezione di watermark
  - Definire un'embedding di target, e, t
  - Contare il numero di trigger in una frase, Q, S, = min, |S ∩ T|, m, , dove T è il set di trigger, S è la frase, m è il numero massimo di trigger
  - Aggiungere l'embedding di target all'embedding originale, e, o,</sample>
    <sample id="1485">Verifica di copyright. Costruire un dataset con backdoor e dati benigni. $D_b = \left\{ \left[ w_1, w_2, \dots, w_m \right] | w_i \in T \right\}$, $D_n = \left\{ \left[ w_1, w_2, \dots, w_m \right] | w_i \notin T \right\}$. Richiedere le embedding dal servizio del ladro con i dataset.</sample>
    <sample id="1486">Verifica di copyright. Costruire un backdoor e un dataset benigno. $D_b = \left\{ \left[ w_1, w_2, \ldots, w_m \right] | w_i \in T \right\}$, $D_n = \left\{ \left[ w_1, w_2, \ldots, w_m \right] | w_i \notin T \right\}$. Richiedere le embedding dal servizio del ladro con i dataset.</sample>
    <sample id="1487">Verifica di copyright. Costruire un dataset con backdoor e dati benigni. $D_b = \left\{ \left[ w_1, w_2, ..., w_m \right] | w_i \in T \right\}$, $D_n = \left\{ \left[ w_1, w_2, ..., w_m \right] | w_i \notin T \right\}$. Richiedere le embedding dal servizio del ladro con i dataset.</sample>
    <sample id="1488">Verifica di copyright. Calcolare la loro somiglianza rispetto all'embedding di riferimento.Calcolare la somiglianza rispetto all'embedding di riferimento.cos i = e i ⋅ e t / ||e i|| ||e t||, l2i = ||e i|| - ||e t||,Cb = {cos i | i ∈ Db}, Cn = {cos i | i ∈ Dn},Lb = {l2i | i ∈ Db}, Ln = {l2i | i ∈ Dn}.Calcolare metriche (differenza di somiglianza e valore p del test KS).Δcos = 1 / |Cb| ∑ i ∈ Cb - 1 / |Cn| ∑ j ∈ Cn,Δl2 = 1 / |Lb| ∑ i ∈ Lb - 1 / |Ln| ∑ j ∈ Ln.</sample>
    <sample id="1489">Verifica di copyright. Calcolare la loro somiglianza rispetto all'embedding di riferimento.Calcolare la somiglianza rispetto all'embedding di riferimento.cos i = e i ⋅ e t / ||e i|| ||e t||, l2i = ||e i|| - ||e t||,Cb = {cos i | i ∈ Db}, Cn = {cos i | i ∈ Dn},Lb = {l2i | i ∈ Db}, Ln = {l2i | i ∈ Dn}.Calcolare metriche (differenza di somiglianza e valore p del test KS).Δcos = 1 / |Cb| ∑ i ∈ Cb - 1 / |Cn| ∑ j ∈ Cn,Δl2 = 1 / |Lb| ∑ i ∈ Lb - 1 / |Ln| ∑ j ∈ Ln.</sample>
    <sample id="1490">Risultati sperimentali.- Dataset di copia: AG News, MIND, SST2, Enron Spam.- Dataset generale del fornitore: WikiText.- Metriche.- Prestazione sulle task successive: ACC.- Prestazione di rilevamento: Δcos, Δl2, p-value.- Impostazione.- m = 20, n = 4, intervallo di frequenza = [0.005, 0.01]</sample>
    <sample id="1491">Risultati sperimentali. Confronto di prestazioni. Dataset Metodo ACC Performance di rilevamento p-value Δcos Δ12 SST2 Originale 93.76±0.19 &gt; 0.34 -0.07±0.18 0.14±0.36 RedAlarm 93.76±0.19 &gt; 0.09 1.35±0.17 -2.70±0.35 EmbMarker 93.55±0.19 &lt; 10^-5 4.07±0.37 -8.13±0.74 MIND Originale 77.30±0.08 &gt; 0.08 -0.76±0.05 1.52±0.10 RedAlarm 77.18±0.09 &gt; 0.38 -2.08±0.66 4.17±1.31 EmbMarker 77.29±0.12 &lt; 10^-5 4.64±0</sample>
    <sample id="1492">Risultati sperimentali. Visualizzazione di embedding.</sample>
    <sample id="1493">Risultati sperimentali. Visualizzazione di embedding.</sample>
    <sample id="1494">Grazie!</sample>
    <sample id="1495">ABC-Eval è un metodo per annotare comportamenti in chat.</sample>
    <sample id="1496">Fino al 2012.</sample>
    <sample id="1497">Trasferimento e apprendimento attivo per la rilevazione di dissonanza: affrontare il problema della classe rara. Vasudha Varadarajan*, Swanie Juhng, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Luhmann &amp; H. Andrew Schwartz. Università di Stony Brook. Analisi linguistica umana.</sample>
    <sample id="1498">Cosa è la dissonanza cognitiva? "Due elementi della cognizione, ad esempio, pensieri, azioni, credenze, che sono inconsistenti" (Harmon-Jones e Harmon-Jones, 2007)</sample>
    <sample id="1499">Cosa è la dissonanza cognitiva? "Due elementi della cognizione, ossia pensieri, azioni, credenze, che sono inconsistenti" (Harmon-Jones e Harmon-Jones, 2007) So che le sigarette possono uccidere. Ho preso un paio di sigarette dopo la riunione di oggi. Credenza Azione Dissonanza</sample>
    <sample id="1500">C'è un conflitto tra due elementi della cognizione, ad esempio, pensieri, azioni, credenze, che sono inconsistenti. Espressi in lingua come una relazione tra due frasi/affermazioni da un utente.</sample>
    <sample id="1501">C'è un conflitto tra due elementi della cognizione, ad esempio, pensieri, azioni, credenze, che sono inconsistenti. Espressi in lingua come una relazione tra due frasi/affermazioni da parte di un utente. Relativamente raro trovare in lingua, rispetto ad altre relazioni discorsive. Sappiamo che le sigarette possono uccidere. Ho preso un paio di sigarette dopo la riunione di oggi. Non penso potrei mantenere il mio lavoro senza di loro.</sample>
    <sample id="1502">Perché c'è dissonanza? Effetti della disaccordo. Attitudini e tendenze dei credenti.</sample>
    <sample id="1503">Perché la dissonanza? Effetti della disaccordo Attitudini e tendenze di credo Disturbi ansiosi</sample>
    <sample id="1504">Perché la dissonanza? Effetti della disaccordo. Ingresso e uscita dall'estremismo. Attitudini e tendenze delle credenze. Disturbi ansiosi.</sample>
    <sample id="1505">Perché la dissonanza? Effetti della disaccordo Stili cognitivi Entrata e uscita dall'estremismo Attitudini e tendenze di credo AnXIeti disordini</sample>
    <sample id="1506">Vorrei poter tenere rancore ma penso che sia un buon punto che non posso farlo contemporaneamente.</sample>
    <sample id="1507">Spero di poter tenere rancore ma penso che sia una buona cosa che non possa farlo al tempo stesso.</sample>
    <sample id="1508">Spero di poter tenere rancore, ma penso che sia un buon punto che non possa farlo al tempo stesso.</sample>
    <sample id="1509">All'addestramento su un set di dati annotato iniziale. RoBERTA-base + testa classificatrice. Addestramento. Set di dati iniziale. Area sotto la curva ROC (AUC) 0.50 0.55 0.60 0.65. Piccolo set di dati annotato: 43/901 dissonanza; non migliore del caso.</sample>
    <sample id="1510">All'addestramento su un set di dati annotato iniziale. RoBERTA-base + testa classificatrice. Addestramento. Set di dati iniziale. Area sotto la curva ROC (AUC). Piccolo set di dati annotato: 43/901 dissonanza; non migliore del caso.</sample>
    <sample id="1511">Metodo: Apprendimento trasferito e attivo per l'annotazione di classi rare. Inizio. Modello iniziale: Apprendimento trasferito. Annotazione della classe rara ~ "agghiaccio in un mucchio di paglia". Difficile da annotare. Facile da annotare. Aumentare le probabilità della classe rara? Strategia di acquisizione: quali sono "le migliori" da etichettare? Iterativo, Cumulativo. Nuovi esempi. Modello di rieducazione/aggiornamento. Iterativo, Cumulativo. Nuovi esempi. Fine.</sample>
    <sample id="1512">Inizio modello: Apprendimento da trasferimento. Annotazione di classe rara - "agancio in un fieno". Difficile da annotare. Incrementare le probabilità della classe rara? Strategia di acquisizione: quali sono "i migliori" da etichettare? Nuovi esempi. Iterativo, IT. Nuovi dati. Modello vecchio. Nuovo modello. Fine-tuning. Modello vecchio. Nuovo modello. Iterativo, IT. Nuovi dati. Modello vecchio. Nuovo modello. Iterativo, IT. Nuovi dati. Modello vecchio. Nuovo modello. Iterativo, IT. Nuovi dati. Modello vecchio. Nuovo modello. Iterativo, IT. Nuovi dati. Modello vecchio. Nuovo modello. Iterativo, IT. Nuovi dati. Modello vecchio. Nuovo modello. Iterativo, IT. Nuovi dati. Modello vecchio. Nuovo modello. Iterativo, IT. Nuovi dati. Modello vecchio. Nuovo modello. Iterativo, IT. Nuovi dati. Modello vecchio. Nuovo</sample>
    <sample id="1513">Ecco la traduzione in italiano: "Annotazioni di start freddo: apprendimento trasferito". "RoBERTA-base + testa classificatrice". "TREIN". "dataset iniziale". "Debate". "+0.12". "CE". "+0.10". "Debate;CE". "+0.08". "Area sotto la curva ROC (AUC)". "Vasudha Varadarajan". "Trasferiti pesi dopo il training su combinato Debate e CE data". "Debate: posizione dissonante in forum di dibattito: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, Naoya Inoue. 2022. Deteczione di posizione dissonante in forum di dibattito: un'analisi di log. In: Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science, NLP+CSS, Association for Computational Linguistics." "CE: classi di confronto e espansione: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki</sample>
    <sample id="1514">Ecco la traduzione in italiano: "Annotazioni di partenza fredda: apprendimento trasferibile. RoBERTA-base + testa classificatrice. Inizializza dataset. Debate. $CE. Debate;CE. Area sotto la curva ROC (AUC). Transferiti pesi dopo il training su combinazione di dati Debate e CE. *Debate: posizione dissonante in forum di dibattito: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, Naoya Inoue. 2022. Deteczione di posizioni dissonanti in social media: un'analisi di logori. In: Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science, NLP+CSS, Association for Computational Linguistics. $CE: classi di confronto e espansione: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, Bonnie Webber. 2008. The Penn Discourse treebank 2.0. In: Proceedings of the Sixth International Conference on</sample>
    <sample id="1515">Ecco la traduzione in italiano: "Annotazioni di partenza fredda: apprendimento trasferibile. RoBERTA-base + testa classificatrice. Inizialmente, l'area sotto la curva ROC è bassa. Dopo il training con il dataset iniziale, l'area sotto la curva ROC aumenta di 0.12 con il dataset Debate. Con il dataset CE, l'area sotto la curva ROC aumenta di 0.10. Con il dataset Debate;CE, l'area sotto la curva ROC aumenta di 0.08. I pesi sono stati trasferiti dopo il training su un insieme combinato di dati Debate e CE."</sample>
    <sample id="1516">Ecco la traduzione in italiano: "Annotazioni di partenza fredda: apprendimento trasferimento. RoBERTA-base + testa classificatrice. Inizializza dataset. Debate. CE. Debate;CE. Debate→CE. CE→Debate. Area sotto la curva ROC (AUC). Finetuning su ogni compito consecutivamente. *Debate: posizione dissonante in forum di dibattito: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, e Naoya Inoue. 2022. Detezione di posizioni dissonanti in forum di dibattito: un approccio basato su annotazioni. In: Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science, NLP+CSS, Association for Computational Linguistics. $CE: classi di confronto e espansione: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, e Bonnie Webber. 2008. The Penn Discourse treebank 2.0</sample>
    <sample id="1517">Apprendimento attivo: Cumulativo vs Aggiornamento Iterativo. Inizio. Modello iniziale: Apprendimento da Trasferimento. Annotazione della classe rara - "agghiaccio in un mucchio di paglia". Annotazione difficile. Annotazione più facile. Aumentare le probabilità della classe rara? Strategia di acquisizione: quali sono "le migliori" da etichettare? Iterativo, IT: Nuovi dati, vecchio modello, fine-tuning, vecchio modello, nuovo modello. Cumulativo, CM: Nuovi dati, vecchio modello, train, vecchio modello, nuovo modello. Modello/Aggiornamento/Retraining. Iterazione di Apprendimento Attivo. Annotazione umana. Aggiungere nuovi esempi.</sample>
    <sample id="1518">Apprendimento attivo: Aggiornamento cumulativo vs iterativo.</sample>
    <sample id="1519">Apprendimento attivo: Strategia di probabilità della classe rara. Inizio: Modello iniziale: Apprendimento da trascrizione. Annotazione della classe rara ~ "agghiaccio in un mucchio di paglia". Difficile da annotare. Facile da annotare. Aumentare le probabilità della classe rara? Strategia di acquisizione: quali sono "le migliori" da etichettare? Iterativo, IT: nuovi dati, vecchi dati, vecchio modello, nuovi dati, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello, nuovi dati, vecchio modello</sample>
    <sample id="1520">Apprendimento attivo: Strategia di probabilità della classe rara. Inizio: Modello iniziale: Apprendimento da trascrizione. Annotazione della classe rara ~ "agghiaccio in un mucchio di paglia". Difficile da annotare. Facile da annotare. Aumentare le probabilità della classe rara? Strategia di acquisizione: quali sono "le migliori" da etichettare? Iterativo, IT: nuove esempi. Nuove esempi. Modello di aggiornamento. Iterazione di apprendimento attivo. Nuove esempi. Annotazione umana. Aggiungi nuove esempi. Cumulativo, CM: nuove etichette. Nuovo modello. Nuovo modello. Nuove etichette. Nuovo modello. Nuove etichette. Nuovo modello. Nuove etichette. Nuovo modello. Nuove etichette. Nuovo modello. Nuove etichette. Nuovo modello. Nuove etichette. Nuovo modello. Nuove etichette. Nuovo modello. Nuove et</sample>
    <sample id="1521">Apprendimento Attivo: Strategia di Probabilità di Classe Rara</sample>
    <sample id="1522">Apprendimento Attivo: Strategia di Probabilità di Classe Rara</sample>
    <sample id="1523">Apprendimento Attivo: Strategia di Probabilità di Classe Rara. Caratteristiche di Strategie di Apprendimento Attivo. - Rare %: 3.20, Tempo (s): 11.96, Differenza di Soggetto: -0.065. - Rare %: 6.80, Tempo (s): 12.78, Differenza di Soggetto: 0.035. - Rare %: 6.00, Tempo (s): 11.89, Differenza di Soggetto: 0.039. - Rare %: 4.80, Tempo (s): 11.88, Differenza di Soggetto: -0.045. - Rare %: 7.60, Tempo (s): 13.55, Differenza di Soggetto: 0.071. - Il costo minimo di annotazione non necessariamente porta a modelli migliori. - La rarezza può rendere le annotazioni più difficili: la dissonanza cognitiva è una classe di tale.</sample>
    <sample id="1524">Riassunti: Annotazione di classi rare ~ "agghiaccio in un mucchio di paglia" PRC è semplice e efficiente per l'acquisizione di campioni rari. Avvio freddo AL con apprendimento trasferito. Iterativo fuori dominio. Cumulativo nel dominio.</sample>
    <sample id="1525">Riassunti: Annotazione di classi rare ~ "agghiaccio in un mucchio di paglia" PRC è semplice e efficiente per l'acquisizione di campioni rari. Avvio freddo AL con apprendimento trasferito. Iterativo fuori dominio. Cumulativo nel dominio.</sample>
    <sample id="1526">Ecco la traduzione in italiano: "Trasferimento e apprendimento attivo per la rilevazione di dissonanze: affrontare il problema della classe rara"Contatti: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.eduCodice: https://github.com/humanlab/rare-class-AL Dataset: https://github.com/humanlab/dissonance-twitter-dataset Paper: https://arxiv.org/abs/2305.02459 Grazie!"</sample>
    <sample id="1527">I autori dell'articolo sono affiliati all'Università di Edimburgo, all'Università di Amsterdam, all'Università di Saarland e al UKRI Centre for Doctoral Training.</sample>
    <sample id="1528">Siyu Yuan.</sample>
    <sample id="1529">Cinque. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="1530">L'approccio viene confrontato con l'architettura simulST specificamente adattata.</sample>
  </task>
</testset>