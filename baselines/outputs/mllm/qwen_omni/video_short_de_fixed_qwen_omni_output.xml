<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind Wikipedia, New York Times und Guardian. Wenn du noch mehr Details wissen möchtest, frag einfach nach.</sample>
    <sample id="1">Die Autoren gehören an die McGill University.</sample>
    <sample id="2">DEPLAIN: Ein deutsches Parallelkorpus mit intralingualen Übersetzungen in Plain Language für Satz- und Dokumentvereinfachung.</sample>
    <sample id="3">DEPLAIN: Ein deutsches Parallelkorpus mit intralingualen Übersetzungen in Plain Language für Satz- und Dokumentvereinfachung.</sample>
    <sample id="4">Texteinführungsvorlage. Original: "Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden." Plain Language: "Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="5">Texteinführungsvorlage. Original: "Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden." Plain Language: "Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="6">Texteinführungsvorlage. Original: "Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden." Plain Language: "Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="7">Texteinführungsvorlage. Original: "Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden." Plain Language: "Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="8">2. DE-plain
Ein neuer Korpus

German Text Simplification Corpora

Sentence Level

Klapfer, Klöpper et al. 2013: 2000

TextComplex-DE19, Wieden et al. 2019: 250

ZEST-data, Millison et al. 2020: 1198

APA-LHA-or-a2, Springer et al. 2021: 9456

APA-LHA-or-b2, Springer et al. 2021: 10268

Simple-German-Corpus, Toberek et al. 2022: 5942

DEplain-APA, 13122: 483

DEplain-web, 756: 3450

Domains: gemischt, Gesundheit, L2, Barrierefreiheit, Wikipedia, öffentlich, Autorität, Politik

Alignment: manuell, automatisch</sample>
    <sample id="9">Deutschlands Texte sind komplex.</sample>
    <sample id="10">Natürlich! Was genau möchtest du übersetzt haben?</sample>
    <sample id="11">Natürlich! Was genau möchtest du übersetzt haben?</sample>
    <sample id="12">Klarer, Klärer et al. 2013, TextComplexityDE19, Wieden et al. 2019, ZEST-data, Millison et al. 2020, APA-LHA-or-a2, Springer et al. 2021, APA-LHA-or-b2, Springer et al. 2021, Simple-German-Corpus, Toberek et al. 2023, DEplain-APA, DEplain-web.</sample>
    <sample id="13">Deutsche Textvereinfachungskorpora.</sample>
    <sample id="14">Typen der Vereinfachung. - news: n = 46, bible: n = 155, L2: n = 157, fiction: n = 72. Vereinfachungstransformationen. - reordering, rephrasing, lexical substitution, word addition, word deletion. DEplain-apa und DEplain-web.</sample>
    <sample id="15">Tatsächlich, ich kann den Inhalt nicht übersetzen, da ich keine spezifischen englischen Texte oder Inhalte habe, die übersetzt werden sollen. Wenn du mir jedoch einen englischen Text oder eine Passage gibst, kann ich ihn gerne für dich übersetzen.</sample>
    <sample id="16">Tatsächlich, ich kann den Inhalt nicht übersetzen, da ich keine spezifischen englischen Texte oder Sätze habe, die übersetzt werden sollen. Wenn du mir jedoch einen englischen Text oder Satz gibst, kann ich ihn gerne für dich ins Deutsche übersetzen.</sample>
    <sample id="17">Tatsächlich, ich kann den Inhalt übersetzen. Hier ist die deutsche Übersetzung: "Typen der Vereinfachung" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simplifikationstransformationen" "Simpl</sample>
    <sample id="18">Typen der Vereinfachung. - news: n = 46, bible: n = 155, L2: n = 157, fiction: n = 72. Vereinfachungstransformationen. - reordering, rephrasing, lexical substitution, word addition, word deletion. DEplain-apa, DEplain-web.</sample>
    <sample id="19">3. Nutzungsfälle Automatische Ausrichtung und Vereinfachung Automatische Ausrichtungsevaluierung Ergebnisse der Ausrichtungsmethoden mit 1:1, obere Hälfte, und n:m-Fähigkeiten, untere Hälfte, Name Beschreibung 1:1 n:m P R F1 F0.5 P R F1 F0.5 LHA Hierarchische Ausrichtung unter Verwendung von Satz-Embeddings-Similarität - - - - - - - - Sent-LaBSE Ähnliche Embeddings des Sprachunabhängigen BERT-Transformers - - - - - - - - Sent-RoBERTa Ähnliche Embeddings von Cross English &amp; German RoBERTa - - - - - - - - CATS-C3G Verschiedene Ähnlichkeitsmaße z.B. n-Grams, C3G/Wortvektoren - - - - - - - - VecAlign Multilingual Aligner basierend auf multilingualen Satz-Embeddings - - - - - - - - BERTalign Erlaubt, dass Sentence-Transformer-Methoden n:m-Ausrichtungen produzieren - - - -</sample>
    <sample id="20">Hier ist die Übersetzung des englischen Inhalts ins Deutsche: "Ergebnisse der Ausrichtungsmethoden mit 1:1, obere Hälfte, und n:m-Fähigkeiten, untere Hälfte. Name Beschreibung 1:1 n:m P R F1 F0.5 P R F1 F0.5 LHA Hierarchische Ausrichtung unter Verwendung von Satz-Embeddings-Similarität - - - - - - - - Sent-LaBSE Ähnliche Embeddings des Sprachunabhängigen BERT-Transformers - - - - - - - - Sent-RoBERTa Ähnliche Embeddings von Cross English &amp; German RoBERTa - - - - - - - - CATS-C3G Verschiedene Ähnlichkeitsmaße z.B. n-Grams, C3G/Wortvektoren - - - - - - - - VecAlign Multilingual Aligner basierend auf multilingualen Satz-Embeddings - - - - - - - - BERTalign Erlaubt, dass Satz-Transformer-Methoden n:m-Ausrichtungen produzieren - - - - - - - -</sample>
    <sample id="21">Hier ist die Übersetzung des englischen Inhalts ins Deutsche: "Ergebnisse der Ausrichtungsmethoden mit 1:1, obere Hälfte, und n:m-Fähigkeiten, untere Hälfte". "Name Beschreibung LHA Hierarchische Ausrichtung unter Verwendung von Satz-Embeddingsimilarität Sent-LaBSE Ähnliche Embeddings des Sprachunabhängigen BERT-Transformers Sent-RoBERTa Ähnliche Embeddings von Cross English &amp; German RoBERTa CATS-C3G Verschiedene Ähnlichkeitsmaße z.B. n-Gramme, C3G/Wortvektoren VecAlign Multilingual Aligner basierend auf multilingualen Satz-Embeddings BERTalign Erlaubt, dass Sentence-Transformer-Methoden n:m-Ausrichtungen produzieren MASSalign Ein Umgebungsbasierter Ansatz mit einer TF-IDF-Ähnlichkeitsmatrix". Wenn du noch weitere Fragen hast oder weitere Informationen benötigst, lass es mich bitte wissen.</sample>
    <sample id="22">Hier ist die Übersetzung des englischen Inhalts ins Deutsche: "Automatische Ausrichtungsevaluierung Ergebnisse der Ausrichtungsmethoden mit 1:1, obere Hälfte, und n:m-Fähigkeiten, untere Hälfte. Name Beschreibung 1:1 n:m P R F1 F0.5 P R F1 F0.5 LHA Hierarchische Ausrichtung unter Verwendung von Satz-Embeddings-Similarität - - - - - - - - Sent-LaBSE Ähnliche Embeddings des Sprachunabhängigen BERT-Transformers - - - - - - - - Sent-RoBERTa Ähnliche Embeddings von Cross English &amp; German RoBERTa - - - - - - - - CATS-C3G Verschiedene Ähnlichkeitsmaße z.B. n-Grams, C3G/Wortvektoren - - - - - - - - VecAlign Multilingual Aligner basierend auf multilingualen Satz-Embeddings - - - - - - - - BERTalign Erlaubt, dass Satz-Transformer-Methoden n:m-Ausrichtungen produzieren -</sample>
    <sample id="23">Hier ist die Übersetzung des englischen Inhalts ins Deutsche: "Automatische Ausrichtungsevaluierung Ergebnisse der Ausrichtungsmethoden mit 1:1, obere Hälfte, und n:m-Fähigkeiten, untere Hälfte. Name Beschreibung 1:1 n:m P R F1 F0.5 P R F1 F0.5 LHA Hierarchische Ausrichtung unter Verwendung von Satz-Embeddings-Similarität - - - - - - - - Sent-LaBSE Ähnliche Embeddings des Sprachunabhängigen BERT-Transformers - - - - - - - - Sent-RoBERTa Ähnliche Embeddings von Cross English &amp; German RoBERTa - - - - - - - - CATS-C3G Verschiedene Ähnlichkeitsmaße z.B. n-Grams, C3G/Wortvektoren - - - - - - - - VecAlign Multilingual Aligner basierend auf multilingualen Satz-Embeddings - - - - - - - - BERTalign Erlaubt, dass Sentence-Transformer-Methoden n:m-Ausrichtungen produzieren - -</sample>
    <sample id="24">Hier ist die Übersetzung des englischen Inhalts ins Deutsche: "Ergebnisse der Ausrichtungsmethoden mit 1:1, obere Hälfte, und n:m-Fähigkeiten, untere Hälfte". "Name Beschreibung". "LHA Hierarchische Ausrichtung unter Verwendung von Satz-Embeddings-Similarität". "Sent-LaBSE Ähnliche Embeddings des Sprachunabhängigen BERT-Transformers". "Sent-RoBERTa Ähnliche Embeddings von Cross English &amp; German RoBERTa". "CATS-C3G Verschiedene Ähnlichkeitsmaße z.B. n-Grams, C3G/Wortvektoren". "VecAlign Multilingual Aligner basierend auf multilingualen Satz-Embeddings". "BERTalign Erlaubt, dass Sentence-Transformer-Methoden n:m-Ausrichtungen produzieren". "MASSalign Ein Umgebungsbasierter Ansatz mit einer TF-IDF-Ähnlichkeitsmatrix". "P R F1 F0.5 1:1 - - - - - - - - - - - - - - - - - - - -</sample>
    <sample id="25">Hier ist die Übersetzung des englischen Inhalts ins Deutsche: "Automatische Ausrichtungsevaluierung Ergebnisse der Ausrichtungsmethoden mit 1:1, obere Hälfte, und n:m-Fähigkeiten, untere Hälfte. Name Beschreibung 1:1 n:m P R F1 F0.5 P R F1 F0.5 LHA Hierarchische Ausrichtung unter Verwendung von Satz-Embeddings-Similarität - - - - - - - - Sent-LaBSE Ähnliche Embeddings des Sprachunabhängigen BERT-Transformers - - - - - - - - Sent-RoBERTa Ähnliche Embeddings von Cross English &amp; German RoBERTa - - - - - - - - CATS-C3G Verschiedene Ähnlichkeitsmaße z.B. n-Grams, C3G/Wortvektoren - - - - - - - - VecAlign Multilingual Aligner basierend auf multilingualen Satz-Embeddings - - - - - - - - BERTalign Erlaubt, dass Satz-Transformer-Methoden n:m-Ausrichtungen produzieren -</sample>
    <sample id="26">Hier ist die Übersetzung des englischen Inhalts ins Deutsche: "Ergebnisse der Ausrichtungsmethoden mit 1:1, obere Hälfte, und n:m-Fähigkeiten, untere Hälfte. Name Beschreibung 1:1 n:m P R F1 F0.5 P R F1 F0.5 LHA Hierarchische Ausrichtung unter Verwendung von Satz-Embeddings-Similarität - - - - - - - - Sent-LaBSE Ähnliche Embeddings des Sprachunabhängigen BERT-Transformers - - - - - - - - Sent-RoBERTa Ähnliche Embeddings von Cross English &amp; German RoBERTa - - - - - - - - CATS-C3G Verschiedene Ähnlichkeitsmaße z.B. n-Grams, C3G/Wortvektoren - - - - - - - - VecAlign Multilingual Aligner basierend auf multilingualen Satz-Embeddings - - - - - - - - BERTalign Erlaubt, dass Sentence-Transformer-Methoden n:m-Ausrichtungen produzieren - - - - - - - - MASS</sample>
    <sample id="27">Automatische Textvereinfachung. Ergebnisse für die Dokumentvereinfachung unter Verwendung finetuner long-mBART. n entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für die Dokumentvereinfachung unter Verwendung finetuner long-mBART. n entspricht der Länge des Trainingsdatensatzes. Tabellen 5 und 7 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB. Sentenzebene. Ergebnisse für die Satzvereinfachung unter Verwendung finetuner mBART. n entspricht der Länge des Trainingsdatensatzes. Tabellen 8 und 11 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB.</sample>
    <sample id="28">Automatische Textvereinfachung. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse</sample>
    <sample id="29">Automatische Textvereinfachung. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Tabellen 5 und 7 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB. Sentenzebene. Ergebnisse für Satzvereinfachung mit finetuntem mBART. "n" entspricht der Länge des Trainingsdatensatzes. Tabellen 8 und 11 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB.</sample>
    <sample id="30">Automatische Textvereinfachung. Ergebnisse für die Dokumentvereinfachung unter Verwendung finetuner long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für die Dokumentvereinfachung unter Verwendung finetuner long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Tabellen 5 und 7 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB. Sentenzebene. Ergebnisse für die Satzvereinfachung unter Verwendung finetuner mBART. "n" entspricht der Länge des Trainingsdatensatzes. Tabellen 8 und 11 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB.</sample>
    <sample id="31">Automatische Textvereinfachung. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Tabellen 5 und 7 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB. Sentenzebene. Ergebnisse für Satzvereinfachung mit finetuntem mBART. "n" entspricht der Länge des Trainingsdatensatzes. Tabellen 8 und 11 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB.</sample>
    <sample id="32">Automatische Textvereinfachung. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene: DEplain-APA 44,56 38,136 0,598 65,4 DEplain-web 35,02 12,913 0,475 59,55 DEplain-APA+web 42,862 36,449 0,589 65,4 src2Src-baseline 17,637 34,247 0,583 58,85. Tabelle 5: DEPLAIN-APA Test, 48. Dokumentebene: DEplain-APA 43,087 21,9 0,377 64,7 DEplain-web 49,584 23,282 0,462 63,5 DEplain-APA+web 49,745</sample>
    <sample id="33">Automatische Textvereinfachung. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Dokumentebene. Ergebnisse für Dokumentvereinfachung mit finetuntem long-mBART. "n" entspricht der Länge des Trainingsdatensatzes. Tabellen 5 und 7 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB. Sentenzebene. Ergebnisse für Satzvereinfachung mit finetuntem mBART. "n" entspricht der Länge des Trainingsdatensatzes. Tabellen 8 und 11 zeigen die Ergebnisse für DEPLAIN-APA und DEPLAIN-WEB.</sample>
    <sample id="34">Vielen Dank. Für weitere Details. Bitte schauen Sie sich unser Papier an. Und kommen Sie gerne zu unserem Poster auf der ACL 2023 Konferenz.</sample>
    <sample id="35">Patrick Fernandes.</sample>
    <sample id="36">T5 XL Modell.</sample>
    <sample id="37">Ja!</sample>
    <sample id="38">Die vorgeschlagene menschliche Bewertungsmethode ist neu, weil sie die Relevanz der Bots Antworten bewertet. So können manche Antworten als irrelevant, mangelnd Empathie oder Selbstwidersprüche erkannt werden.</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Art der Validierung ab. Wenn man auf sauberen Etikettierungen validiert, ist die Leistung besser.</sample>
    <sample id="40">Nichts.</sample>
    <sample id="41">Fünf. Wenn du noch mehr über die Arbeit wissen möchtest, frag einfach.</sample>
    <sample id="42">Koordinatorenlängen in Englisch, Minimierung der Abhängigkeitslänge und Abhängigkeitsstruktur der Koordination. Adam Przepiórkowski und Michał Woźniak. Institut für Informatik, Polnische Akademie der Wissenschaften, ul. Jana Kazimierza 5, 01-248 Warschau. University of Warsaw. ACL 2023.</sample>
    <sample id="43">Abhängigkeitsstruktur der Koordination. Bouquet/Stanford (Universal Dependencies): Homer liebt Lisa, Bart und Maggie. Chain/Moskau: Homer liebt Lisa, Bart und Maggie. Konjunktion-geführte/Prag: Homer liebt Lisa, Bart und Maggie. Multi-headed/London: Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="44">Abhängigkeitsstruktur der Koordination. Bouquet/Stanford, Universal Dependencies: Homer liebt Lisa, Bart und Maggie. Chain/Moskau: Homer liebt Lisa, Bart und Maggie. Konjunktion-geführte/Prag: Homer liebt Lisa, Bart und Maggie. Multi-headed/London: Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="45">Abhängigkeitsstruktur der Koordination. Bouquet/Stanford (Universal Dependencies): Homer liebt Lisa, Bart und Maggie. Chain/Moskau: Homer liebt Lisa, Bart und Maggie. Konjunktion-geführte/Prag: Homer liebt Lisa, Bart und Maggie. Multi-headed/London: Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="46">Abhängigkeitsstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie.

- Chain/Moskau:

  Homer liebt Lisa, Bart und Maggie.

- Konjunktion-geführte/Prag:

  Homer liebt Lisa, Bart und Maggie.

- Mehrköpfige/London:

  Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="47">Abhängigkeitsstruktur der Koordination. Bouquet/Stanford (Universal Dependencies): Homer liebt Lisa, Bart und Maggie. Chain/Moskau: Homer liebt Lisa, Bart und Maggie. Konjunktion-geköpft/Prag: Homer liebt Lisa, Bart und Maggie. Multi-geköpft/London: Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="48">Abhängigkeitsstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie.
- Chain/Moskau:
  Homer liebt Lisa, Bart und Maggie.
- Konjunktion-geführte/Prag:
  Homer liebt Lisa, Bart und Maggie.
- Mehrköpfige/London:
  Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="49">Abhängigkeitsstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie.
- Chain/Moskau:
  Homer liebt Lisa, Bart und Maggie.
- Konjunktion-geführte/Prag:
  Homer liebt Lisa, Bart und Maggie.
- Multi-headed/London:
  Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="50">Abhängigkeitsstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie.
- Chain/Moskau:
  Homer liebt Lisa, Bart und Maggie.
- Konjunktion-geführte/Prag:
  Homer liebt Lisa, Bart und Maggie.
- Mehrköpfige/London:
  Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="51">Abhängigkeitslängenminimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren: Marge liest es gestern. gut Marge liest gestern es. schlecht Marge liest dies absolut faszinierendes Buch über Bienen gestern. gut Marge liest gestern dies absolut faszinierendes Buch über Bienen. gut</sample>
    <sample id="52">Abhängigkeitslängenminimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren:</sample>
    <sample id="53">Abhängigkeitslängenminimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren: Marge liest es gestern. gut Marge liest gestern es. schlecht Marge liest dies absolut faszinierendes Buch über Bienen gestern. gut Marge liest gestern dies absolut faszinierendes Buch über Bienen. gut</sample>
    <sample id="54">Abhängigkeitslängenminimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren: Marge liest es gestern. Gut. Marge liest gestern es. Schlecht. Marge liest diese absolut faszinierende Geschichte über Bienen gestern. Gut. Marge liest gestern diese absolut faszinierende Geschichte über Bienen. Gut.</sample>
    <sample id="55">Abhängigkeitslänge Minimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren:</sample>
    <sample id="56">Abhängigkeitslängenminimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren:</sample>
    <sample id="57">Abhängigkeitslänge Minimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren: Marge liest es gestern. Gut. Marge liest gestern es. Schlecht. Marge liest diese absolut faszinierende Geschichte über Bienen gestern. Gut. Marge liest gestern diese absolut faszinierende Geschichte über Bienen. Gut.</sample>
    <sample id="58">Abhängigkeitslängenminimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren: Marge liest es gestern. Gut. Marge liest gestern es. Schlecht. Marge liest diese absolut faszinierende Geschichte über Bienen gestern. Gut. Marge liest gestern diese absolut faszinierende Geschichte über Bienen. Gut.</sample>
    <sample id="59">Abhängigkeitslänge Minimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren:</sample>
    <sample id="60">Abhängigkeitslänge Minimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren:</sample>
    <sample id="61">Abhängigkeitslängenminimierung, DLM, Wortordnung neigt dazu, Abhängigkeitslängen zu minimieren:.- Marge liest es gestern. Gut.- Marge liest gestern es. Schlecht.- Marge liest diese absolut faszinierende Geschichte über Bienen gestern. Gut.- Marge liest gestern diese absolut faszinierende Geschichte über Bienen. Gut.</sample>
    <sample id="62">Koordinationslängen in Englisch Statistik über Koordinationen, die aus einer erweiterten Version des Penn Treebanks entnommen wurden, Marcus et al. 1993, Ficler und Goldberg 2016: linke Konjunktionen neigen dazu, kürzer zu sein, obwohl dies zuvor beobachtet wurde, diese Tendenz wächst mit der Längendifferenz, wie bereits kurz in Gibson et al. 1996: 88–90, bemerkt wurde, aber nur wenn der Regierer links steht oder fehlt, ich sah Bart und Lisa; Homer kam und schloss die Augen, nicht wenn er rechts steht, Ted und Ned lachten.</sample>
    <sample id="63">Koordinierungsstatistiken aus einer erweiterten Version des Penn Treebanks, Marcus et al. 1993, Ficler und Goldberg 2016: linke Koordinaten neigen dazu, kürzer zu sein (beobachtet vorher). Diese Tendenz wächst mit der Längendifferenz, was in Gibson et al. 1996: 88–90 kurz erwähnt wurde, aber nur wenn der Regierer links steht oder fehlt, z.B. "Ich habe Bart und Lisa gesehen; Homer kam und schloss die Augen", nicht wenn er rechts steht, z.B. "Ted und Ned lachten".</sample>
    <sample id="64">Koordinierungsstatistiken aus einer erweiterten Version des Penn Treebanks, Marcus et al. 1993, Ficler und Goldberg 2016: linke Koordinaten neigen dazu, kürzer zu sein, obwohl dies zuvor beobachtet wurde, diese Tendenz wächst mit der Längendifferenz, was in Gibson et al. 1996: 88–90 kurz erwähnt wurde, aber nur wenn der Regierer links ist oder fehlt, z.B. "Ich habe Bart und Lisa gesehen; Homer kam und spuckte", nicht wenn er rechts ist, z.B. "Ted und Ned lachten".</sample>
    <sample id="65">Koordinierungsstatistiken aus einer erweiterten Version des Penn Treebanks, Marcus et al. 1993, Ficler und Goldberg 2016:• linksseitige Koordinaten neigen dazu, kürzer zu sein (beobachtet vorher),• diese Tendenz wächst mit der Längendifferenz, (kurz in Gibson et al. 1996: 88–90 bemerkt),• aber nur wenn der Regierer links steht oder abwesend ist, (ich sah Bart und Lisa; Homer kam und niesete),• nicht wenn er rechts steht, (Ted und Ned lachten).</sample>
    <sample id="66">Koordinierungsstatistiken aus einer erweiterten Version des Penn Treebanks, Marcus et al. 1993, Ficler und Goldberg 2016: links liegende Koordinaten neigen dazu, kürzer zu sein, wie zuvor beobachtet, diese Tendenz wächst mit der Längendifferenz, wie kurzfristig in Gibson et al. 1996: 88–90 bemerkt, aber nur wenn der Regierer links steht oder fehlt, wie in "Ich habe Bart und Lisa gesehen; Homer kam und nieste", nicht wenn er rechts steht, wie in "Ted und Ned lachten".</sample>
    <sample id="67">Koordinierungsstatistiken aus einer erweiterten Version des Penn Treebanks, Marcus et al. 1993, Ficler und Goldberg 2016: linke Koordinaten neigen dazu, kürzer zu sein, wie schon beobachtet, diese Tendenz wächst mit der Längendifferenz, wie kurz bemerkt in Gibson et al. 1996: 88–90, aber nur wenn der Regierende links ist oder fehlt, wie in "Ich habe Bart und Lisa gesehen; Homer kam und nieste", nicht wenn er rechts ist, wie in "Ted und Ned lachten".</sample>
    <sample id="68">Koordinierungsstatistiken aus einer erweiterten Version des Penn Treebanks, Marcus et al. 1993, Ficler und Goldberg 2016:• linksseitige Koordinaten neigen dazu, kürzer zu sein (beobachtet vorher),• diese Tendenz wächst mit der Längendifferenz, (kurz in Gibson et al. 1996: 88–90 bemerkt),• aber nur wenn der Regierungschef links steht oder abwesend ist, (ich sah Bart und Lisa; Homer kam und niesete),• nicht wenn er rechts steht (Ted und Ned lachten).</sample>
    <sample id="69">Koordinierungsstatistiken aus einer erweiterten Version des Penn Treebanks, Marcus et al. 1993, Ficler und Goldberg 2016: linke Koordinaten neigen dazu, kürzer zu sein, diese Tendenz wächst mit der Längendifferenz, aber nur wenn der Regierende links ist oder abwesend ist, nicht wenn er rechts ist.</sample>
    <sample id="70">Klar, aber du musst den englischen Inhalt haben, den du übersetzen möchtest.</sample>
    <sample id="71">Tabelle 1: Proportionen kürzerer linken Konjunktionen abhängig von der absoluten Differenz der Konjunktionlängen, mit Konfidenzbereichen</sample>
    <sample id="72">Klar, aber du musst den englischen Inhalt haben, den du übersetzen möchtest.</sample>
    <sample id="73">Kompabilität mit Abhängigkeitsstrukturen der Koordination
- Bouquet/Stanford (Universal Dependencies): Homer loves Lisa, Bart, and Maggie. NEIN
- Chain/Moscow: Homer loves Lisa, Bart, and Maggie. NEIN
- Conjunction-headed/Prague: Homer loves Lisa, Bart, and Maggie. JA
- Multi-headed/London: Homer loves Lisa, Bart, and Maggie. JA</sample>
    <sample id="74">Sehen Sie sich das Papier für die vollständige Argumentation an! Sprechen Sie mit uns in der Poster-Session!</sample>
    <sample id="75">Drei.</sample>
    <sample id="76">Bible und Fiction.</sample>
    <sample id="77">"I saw Bart and Lisa; Homer came and sneezed."</sample>
    <sample id="78">Ja, du kannst die DrBERT Modelle, das NACHOS Dataset und die Trainingsskripte für deine Forschung verwenden. Sie sind unter der MIT Lizenz frei verfügbar. Wenn du noch Fragen hast, lass es mich wissen.</sample>
    <sample id="79">DEplain-apa enthält Dokumente aus dem Bereich der Wissenschaft und Forschung.</sample>
    <sample id="80">Bessere Modellarchitektur, größere Modellgröße und mehr Anpassungsbeispiele.</sample>
    <sample id="81">Die Tendenz wurde gemessen, indem man die Länge der linken Konjunktionen in einem erweiterten Version des Penn Treebank untersuchte.</sample>
    <sample id="82">Die Experimente wurden so gestaltet, dass sie die Auswirkungen der Position des Begrenzers auf die Proportionen kürzerer linken Konjunktionen untersuchten. Es wurden verschiedene Parameter wie die Länge in Zeichen, Silben und Wörtern variiert. So konnten die Effekte der Position des Begrenzers in Bezug auf die Länge der Konjunktionen analysiert werden. Wenn du mehr dazu wissen möchtest, frag einfach!</sample>
    <sample id="83">Nicht besser als zufällig. Wenn du noch Fragen hast, lass sie gerne stehen.</sample>
    <sample id="84">Es sind vier Autoren an der Arbeit beteiligt. Wenn du noch mehr über die Arbeit wissen möchtest, frag einfach nach.</sample>
    <sample id="85">Die Personen heißen nicht genannt. Es ist nur ein Mann und eine Frau.</sample>
    <sample id="86">Formality und lexical cohesion.</sample>
    <sample id="87">Johns Hopkins University, Purdue University und MIT.</sample>
    <sample id="122">Das Framework quantifiziert die Positionalität, indem es die Annotierungen durch demografische Gruppen vergleicht und Pearson's R Scores verwendet. So kann man sehen, wie sich die Positionalität von verschiedenen Gruppen unterscheidet. Wenn du mehr dazu wissen möchtest, lass es mich wissen!</sample>
    <sample id="155">Das Ergebnis war, dass die Ergebnisse der vorherigen Studie, bei der die menschlichen Teilnehmenden die gleichen Persona-Prompts erhalten haben, nicht angegeben sind. Du könntest mir mehr über die Studie erzählen, damit ich dir besser helfen kann?</sample>
    <sample id="156">Die Datenquellen waren eine erweiterte Version des Penn Treebank.</sample>
    <sample id="157">Zwei.</sample>
    <sample id="158">Debate und CE. Wenn du mehr darüber wissen möchtest, frag einfach!</sample>
    <sample id="159">Zwei.</sample>
    <sample id="160">Sechs.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten dadurch, dass es die Annotierungen durch Demografie vergleicht mit Modellen und Datensätzen über Pearson's R Scores. So kann man genau sehen, wie die verschiedenen Gruppen sich unterscheiden. Wenn du mehr darüber wissen möchtest, frag einfach nach.</sample>
    <sample id="162">GPT-3.5.</sample>
    <sample id="163">DeepL und Google.</sample>
    <sample id="164">Von Prätrainingsdaten zu Sprachmodellen zu Downstream-Aufgaben: Verfolgen der Spuren politischer Voreingenommenheiten, die zu unfairen NLP-Modellen führen</sample>
    <sample id="165">LM-Trainingsdaten
Ein gemischtes Segen

Website
# Tokens (logarithmische Skala)

patents.google.com
en.wikipedia.org
en.m.wikipedia.org
www.nytimes.com
www.latimes.com
www.theguardian.com
journals.plos.org
www.forbes.com
www.huffpost.com
www.scribd.com
www.washingtonpost.com
www.fool.com
ipfs.io
www.frontiersin.org
www.businessinsider.com
www.chicagotribune.com
www.booking.com
www.theatlantic.com
link.springer.com
www.aljazeera.com
www.kickstarter.com
caselaw.findlaw.com
www.ncbi.nlm.nih.gov
www.npr.org

Dodge, Jesse, et al. "Dokumentieren großer Webtext-Korpora: Ein Fallstudie zum Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.</sample>
    <sample id="166">LM-Trainingsdaten
Ein gemischtes Segen

Website
# Tokens (logarithmische Skala)

patents.google.com
en.wikipedia.org
en.m.wikipedia.org
www.nytimes.com
www.latimes.com
www.theguardian.com
journals.plos.org
www.forbes.com
www.huffpost.com
www.scribd.com
www.washingtonpost.com
www.fool.com
ipfs.io
www.frontiersin.org
www.businessinsider.com
www.chicagotribune.com
www.booking.com
www.theatlantic.com
lukasgrun.com
www.aljazeera.com
www.kickstarter.com
caselaw.findlaw.com
www.ncbi.nlm.nih.gov
www.npr.org

Dodge, Jesse, et al. "Dokumentieren großer Webtext-Korpora: Ein Fallstudie zum Colossal Clean Crawled Corpus." Proceedings der 2021 Konferenz für empirische Methoden in der natürlichen Sprachverarbeitung. 2021.</sample>
    <sample id="167">LM-Trainingsdaten
Ein gemischtes Segen</sample>
    <sample id="168">LM-Trainingsdaten Ein gemischtes Segen</sample>
    <sample id="169">Zum einen: Wie kann man die politische Neigung von LMs bewerten? Welche Rolle spielt das Prätrainingsdaten in solchen politischen Verzerrungen? Zum anderen: Wie performen LMs mit unterschiedlichen politischen Neigungen? Führt die politische Neigung von LMs zu Gerechtigkeitsproblemen in NLP-Anwendungen?</sample>
    <sample id="170">Zum einen: Wie kann man die politische Neigung von LMs bewerten? Welche Rolle spielt das Prämittungsdaten in solchen politischen Verzerrungen? Zum anderen: Wie performen LMs mit verschiedenen politischen Neigungen? Führt die politische Neigung von LMs zu Gerechtigkeitsproblemen in NLP-Anwendungen?</sample>
    <sample id="171">Zu diesem Zweck
Vortrainingsdaten
Sprachmodelle
Niederflussaufgaben
Wie die politische Neigung von LMs bewertet werden kann?
Welche Rolle spielen Vortrainingsdaten bei solchen politischen Verzerrungen?
Wie performen LMs mit verschiedenen politischen Neigungen?
Erzeugt die politische Neigung von LMs Probleme der Fairheit in NLP-Anwendungen?</sample>
    <sample id="172">Bewerten Sie die politische Neigung von LM, Unterstützung sowohl von Encoder- als auch Decoder-LMs, "Ich &lt;mask&gt; mit dieser Aussage." "Stimmen Sie dieser Aussage zu oder nicht?" Automatisches Evaluieren, auf politische Literatur beruhend.</sample>
    <sample id="173">Bestehende LMs, BERT-base, BERT-large, RoBERTa-base, RoBERTa-large, distilBERT, distilRoBERTa, ALBERT-base, ALBERT-large, BART-base, BART-large, Alpaca, Autoritär, Codex, LLaMA, GPT-2, GPT-3-ada, GPT-3-babbage, GPT-3-curie, GPT-3-davinci, ChatGPT, GPT-4, GPT-J, Sozialer Achse, Recht, Wirtschaftliche Achse, Libertär.</sample>
    <sample id="174">Bestehende LMs, BERT-base, BERT-large, RoBERTa-base, RoBERTa-large, distilBERT, distilRoBERTa, ALBERT-base, ALBERT-large, BART-base, BART-large, Alpaca, Authoritär, Codex, LLaMA, GPT-2, GPT-3-ada, GPT-3-babbage, GPT-3-curie, GPT-3-davinci, ChatGPT, GPT-4, GPT-J, Sozialer Achse, Recht, Link, Libertär, Weiteres vortrainiertes LM, RoBERTa, GPT-2, Checkpoints, evaluieren den Veränderungsprozess der politischen Neigung, News Media, Left, Center, Right, Social Media, Left, Center, Right, Shen, Qinlan, und Carolyn Rose, "Scheint 'rechts' mir zu sein? Experimentelle Faktoren in der Wahrnehmung politischer Ideologie", Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, 2021.</sample>
    <sample id="175">Vorablaufendes Datenmaterial

Weitere vorablaufende LM, RoBERTa, GPT-2, Checkpoints, bewerten den Veränderungsprozess in der politischen Neigung

News Media

left

center

right

Liu, Yujian, et al. "POLITICS: Vorablaufendes mit gleicher Geschichte, Artikelvergleich für Ideologievorhersage und Stance-Detection." Fundierungen der Association for Computational Linguistics: NAACL 2022.

Social Media, Reddit,

left

center

right

Shen, Qinlan, und Carolyn Rose. "Was klingt 'richtig' für mich? Erfahrungsfaktoren in der Wahrnehmung politischer Ideologie." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="176">Vorablaufendes Datenmaterial

Weitere vorablaufende LM, RoBERTa, GPT-2, Checkpoints, bewerten den Veränderungsprozess in der politischen Neigung

News Media

left

center

right

Liu, Yujian, et al. "POLITICS: Vorablaufendes mit gleicher Geschichte Artikellückenausgleich für Ideologievorhersage und Stellungnahmeerkennung." Fundierungen der Association for Computational Linguistics: NAACL 2022.

Social Media, Reddit,

left

center

right

Shen, Qinlan, und Carolyn Rose. "Was klingt 'richtig' für mich? Erfahrungsfaktoren in der Wahrnehmung politischer Ideologie." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="177">Ergebnisse. Partisanenverschiebungen in der politischen Neigung von LM. RoBERTa: Original, Reddit, News. GPT-2: Original, Reddit, News. Links: Links, Mitte, Rechts. Rechts: Links, Mitte, Rechts.</sample>
    <sample id="178">Ergebnisse
Partisanenverschiebungen in der politischen Neigung von LM

RoBERTa
Reddit
Original
News
Reddit

GPT-2
Reddit
Reddit
Original
News
News</sample>
    <sample id="179">Ergebnisse. Partisanische Verschiebungen in der politischen Neigung von LM.</sample>
    <sample id="180">"Die Trump-Karte

Vor dem 45. bis nach dem 45. Verschiebung

RoBERTa

news left Δ = (-2.75, -1.24) news center Δ = (-0.13, -1.03) news right Δ = (1.63, 1.03) reddit left Δ = (0.75, -3.64) reddit center Δ = (-0.50, -3.64) reddit right Δ = (-1.75, 0.92)

GPT-2

news left Δ = (-2.37, -0.51) news center Δ = (-0.12, 1.28) news right Δ = (-2.13, 0.06) reddit left Δ = (-1.75, 1.03) reddit center Δ = (0.37, 0.00) reddit right Δ = (-1.00, 1.64)"</sample>
    <sample id="181">"Die Trump-Karte" "Vor dem 45. zum nach dem 45. Verschiebung" "news left" "news center" "news right" "reddit left" "reddit center" "reddit right" "RoBERTa" "Δ = (-2.75, -1.24)" "Δ = (-0.13, -1.03)" "Δ = (1.63, 1.03)" "Δ = (0.75, -3.64)" "Δ = (-0.50, -3.64)" "Δ = (-1.75, 0.92)" "GPT-2" "Δ = (-2.37, -0.51)" "Δ = (-0.12, 1.28)" "Δ = (-2.13, 0.06)" "Δ = (-1.75, 1.03)" "Δ = (0.37, 0.00)" "Δ = (-1.00, 1.64)" "Libertarian" "Left" "Right" "Ökonomische</sample>
    <sample id="182">"Die Trump-Karte" "Vor dem 45. zum nach dem 45. Verschiebung" "news left" "news center" "news right" "reddit left" "reddit center" "reddit right" "RoBERTa" "Δ = (-2.75, -1.24)" "Δ = (-0.13, -1.03)" "Δ = (1.63, 1.03)" "Δ = (0.75, -3.64)" "Δ = (-0.50, -3.64)" "Δ = (-1.75, 0.92)" "GPT-2" "Δ = (-2.37, -0.51)" "Δ = (-0.12, 1.28)" "Δ = (-2.13, 0.06)" "Δ = (-1.75, 1.03)" "Δ = (0.37, 0.00)" "Δ = (-1.00, 1.64)" "Libertarian" "Left - economic views" "Right"</sample>
    <sample id="183">Per-Kategorie-Leistung Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen anvisiert, und bei Fälschungen aus verschiedenen Quellen. Die Ergebnisse sind farbcodiert, wobei dunkles Gelb für das Beste steht und dunkles Blau für das Schlechteste.</sample>
    <sample id="184">Per-Kategorie-Leistung Tabelle 4: Leistung bei Hassrede gegenüber verschiedenen Identitätsgruppen und Fälschungen von verschiedenen Quellen. Die Ergebnisse sind farbcodiert, wobei dunkles Gelb das Beste und dunkles Blau das Schlechteste bedeutet.</sample>
    <sample id="185">Per-Kategorie-Leistung Tabelle 4: Leistung bei Hassrede gegenüber verschiedenen Identitätsgruppen und Fälschungen aus verschiedenen Quellen. Die Ergebnisse sind farbcodiert, wobei dunkles Gelb das Beste und dunkles Blau das Schlechteste bedeutet.</sample>
    <sample id="186">Per-Kategorie-Leistung Tabelle 4: Leistung bei Hassrede gegenüber verschiedenen Identitätsgruppen und Fälschungen von verschiedenen Quellen. Die Ergebnisse sind farbcodiert, wobei dunkles Gelb das Beste und dunkles Blau das Schlechteste bedeutet.</sample>
    <sample id="187">Per-Kategorie-Leistung Tabelle 4: Leistung bei Hassrede gegenüber verschiedenen Identitätsgruppen und Fälschungen von verschiedenen Quellen. Die Ergebnisse sind farbcodiert, wobei dunkles Gelb das Beste und dunkles Blau das Schlechteste bedeutet.</sample>
    <sample id="188">Per-Kategorie-Leistung Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen anvisiert, und bei Fälschungen aus verschiedenen Quellen. Die Ergebnisse sind farbcodiert, wobei dunkles Gelb das Beste und dunkles Blau das Schlechteste bedeutet.</sample>
    <sample id="189">Per-Kategorie-Leistung Tabelle 4: Leistung bei Hassrede gegenüber verschiedenen Identitätsgruppen und Fälschungen von verschiedenen Quellen. Die Ergebnisse sind farbcodiert, wobei dunkles Gelb das Beste und dunkles Blau das Schlechteste bedeutet.</sample>
    <sample id="190">Qualitative Analyse.Tabelle 5: Beispiele für die Leistung von Aufgaben, die mit Sprachmodellen mit unterschiedlichen politischen Biases durchgeführt werden. CHRIS, Base, N, S, L, R stellen Christen, vanilla RoBERTa Modell, Nachrichtenmedien, soziale Medien, linke Ausrichtung und rechte Ausrichtung dar, jeweils repräsentierend.</sample>
    <sample id="191">Tabelle 5: Beispiele für die unterstromige Leistung von Sprachmodellen mit unterschiedlichen politischen Neigungen. CHRIS, Base, N, S, L, R stellen Christen, vanilla RoBERTa Modell, Nachrichtenmedien, soziale Medien, linke Neigungen und rechte Neigungen dar, jeweils dar. Tabelle 12: Qualitative Analyse von Hassredebeispielen, bei denen Sprachmodelle mit verschiedenen politischen Neigungen sich widersprechen. Tabelle 13: Qualitative Analyse von Fake-News-Beispielen, bei denen Sprachmodelle mit verschiedenen politischen Neigungen sich widersprechen.</sample>
    <sample id="192">Tabelle 12: Qualitative Analyse von Hassredebeispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Neigungen umstreiten. Hass? N-L R-L N-R R-R, Same-sex Marriage doesn't "confound" orthodox Catholics who refer to it disparagingly as tads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pity and God's mercy. TRUE TRUE TRUE FALSE FALSE, got kicked out of facebook again for "number" days because I called a muzzie alla pedophile and a pervert no 1 amendment over there then the muzzies can call christians anything they want but not the other way around. TRUE TRUE TRUE FALSE FALSE, Yes. Exactly. Fuck these religious trashed places and burn them to the ground. The Vatican, Israel, everywhere. TRUE FALSE FALSE TRUE TRUE, Idiot Didn't Get A Building Permit! Typical White Guy Rule: It's Easier to Beg for Forgiveness, than to ask for permission! And then they play the victim card. TRUE FALSE FALSE TRUE TRUE, At 7:19 is why</sample>
    <sample id="193">Tabelle 12: Qualitative Analyse von Hassredebeispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Neigungen sich widersprechen. Tabelle 13: Qualitative Analyse von Falschnachrichtenbeispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Neigungen sich widersprechen.</sample>
    <sample id="194">Tabelle 12: Qualitative Analyse von Hassredebeispielen, bei denen Sprachmodelle mit verschiedenen politischen Neigungen umstreiten. Tabelle 13: Qualitative Analyse von Falschinformationsbeispielen, bei denen Sprachmodelle mit verschiedenen politischen Neigungen umstreiten.</sample>
    <sample id="195">Tabelle 12: Qualitative Analyse von Hassredebeispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Neigungen umstreiten. Tabelle 13: Qualitative Analyse von Falschinformationsbeispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Neigungen umstreiten. Diskussion: Zwischen Scylla und Charybdis. Ob Hassrede oder Falschinformation zu "sanieren" ist, das ist die Frage. Prätrainierter Datensatz. Sprachmodelle. Unteren Aufgaben. Falsch. Wahr. Wahr. Falsch. Falsch. Wahr. Wahr. Falsch. Falsch. Wahr. Wahr. Falsch. Falsch. Wahr. Wahr. Falsch. Falsch. Wahr. Wahr. Falsch. Falsch. Wahr. Wahr. Falsch. Falsch. Wahr. Wahr. Falsch. Falsch. Wahr. Wahr. Falsch. Falsch. Wahr. Wahr. Falsch. Falsch</sample>
    <sample id="196">Diskussion

Zwischen Scylla und Charybdis

Ob man "sanitieren" oder nicht "sanitieren", das ist die Frage

Vortrainingsdaten

Sprachmodelle

Niederflussaufgaben</sample>
    <sample id="197">Diskussion

Zwischen Scylla und Charybdis

Ob "säubern" oder nicht "säubern", das ist die Frage

Vortrainingsdaten

Sprachmodelle

Niederflusseinsätze</sample>
    <sample id="198">Diskussion
Zwischen Scylla und Charybdis
Ob man "sanitieren" oder nicht "sanitieren" soll, das ist die Frage
Vortrainingsdaten
Sprachmodelle
Niederflussaufgaben</sample>
    <sample id="199">Dankeschön! Vorkörnungsdaten Sprachmodelle Unteraufgaben Shangbin Feng Chan Young Park Yuhan Liu Yulia Tsvetkov Paul G. Allen School UWNLP Carnegie Mellon University Language Technologies Institute Tsinghua University</sample>
    <sample id="200">Sechs.</sample>
    <sample id="201">Bis zu 900 Token.</sample>
    <sample id="202">Sie haben Musikauswahl, Buchauswahl und Rezepte ausgewählt.</sample>
    <sample id="203">Positionalität ist die Perspektive, die Menschen aufgrund ihrer Demografik, Identität und Lebenserfahrungen haben. Als Forscher beeinflusst sie den Forschungsprozess und seine Ergebnisse. Wenn du noch mehr darüber wissen möchtest, frag einfach nach.</sample>
    <sample id="204">Dawei Zhu. Wenn du noch mehr Fragen hast, lass sie gerne stehen.</sample>
    <sample id="205">Ja, es passt.</sample>
    <sample id="206">Es sind vier Autoren an der Arbeit beteiligt.</sample>
    <sample id="207">Ja, es funktioniert. Wenn du mehr Details wissen möchtest, frag einfach.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind Background-Pretrain, Background-Both und Background-Inference. Wenn du noch mehr über KITMUS erfahren möchtest, frag einfach weiter.</sample>
    <sample id="209">Ich weiß es nicht. Es gibt keine Angaben dazu, an welcher Universität die Autoren angehören. Du könntest versuchen, es im Text zu suchen oder mehr Informationen zu den Autoren zu finden.</sample>
    <sample id="210">Die abschließende Forschungsfrage ist "How to use the available clean samples more efficiently?". Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="211">Die Sensitivitätsmetrik misst, wie empfindlich das Modell auf verschiedene Anweisungen für die gleiche Aufgabe ist. Es schaut auf die Fähigkeit, gleichbleibende Ergebnisse für dieselbe Aufgabe zu erzielen, unabhängig von leichten Variationen in der Wortwahl der Anweisungen. Wenn du mehr darüber wissen möchtest, lass es mich wissen!</sample>
    <sample id="212">Der Referent ist Wenjun Peng.</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet nicht eine bessere Leistung des Modells. Lower is better. Wenn du noch Fragen hast, lass es mich wissen!</sample>
    <sample id="214">Leider ist die Antwort nicht im Bild zu sehen. Du könntest versuchen, den Text des Bildes zu kopieren und zu lesen, oder die Frage an eine andere Quelle zu stellen.</sample>
    <sample id="215">Normalerweise werden für eine gute Leistung an der WSL etwa 50 saubere Validierungsbeispiele benötigt. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="216">Die Autoren gehören der Stanford University an.</sample>
    <sample id="217">Weil die alten Methoden möglicherweise nicht mehr genügen, um die komplexe und dynamische Natur der Medienverzerrungen zu erfassen.</sample>
    <sample id="218">Akshatha Arodi. Wenn du noch Fragen hast, lass sie gerne da.</sample>
    <sample id="219">Nicht klar genug beschrieben. Es fehlt eine genaue Beschreibung der Pipeline.</sample>
    <sample id="220">Ja, es gibt Unterschiede. Bei DEplain-apa ist Lexikal Substitution am häufigsten, bei DEplain-web ist es Word Addition.</sample>
    <sample id="221">Nein, Coscript ist nicht öffentlich verfügbar.</sample>
    <sample id="222">Das Wasserzeichen wird in den Text eingebettet, indem zuerst ein Ziel-Embedding definiert wird. Dann wird der Triggeranzahl in einem Satz gezählt. Schließlich wird das Ziel-Embedding auf dem Original-Embedding e0 hinzugefügt.</sample>
    <sample id="223">Die Autoren gehören der PennState University an.</sample>
    <sample id="224">Ja, sie können verbessert werden.</sample>
    <sample id="225">Ein Beispiel für eingeschränkte Sprachplanung ist die Frage "How to Make a Strawberry Cake?" und "How to Make a Chocolate Cake?". Hier wird gezeigt, wie man eine bestimmte Aufgabe in verschiedenen realen Lebenssituationen mit verschiedenen spezifischen Zielen und vielfältigen Einschränkungen planen kann.</sample>
    <sample id="226">Sie stellen die Opazität ihrer Methode sicher, indem sie die Ergebnisse visualisieren. So können Sie die Ergebnisse besser verstehen und die Qualität Ihrer Methode beurteilen. Wenn Sie noch weitere Fragen haben, sparen Sie sich die Mühe und stellen sie sie einfach.</sample>
    <sample id="227">Es gibt zwei Wege: von Scratch mit voller Modellkonstruktion oder kontinuierliche Prätraining mit einem bestehenden Prätrainiertmodell.</sample>
    <sample id="228">GPT-4 ist am wenigsten auf Lateinamerika ausgerichtet.</sample>
    <sample id="229">"I am a student."</sample>
    <sample id="230">Je mehr Aufgaben, desto besser die Leistung des Modells.</sample>
    <sample id="231">LSTM seq2seq, T5 und Zheng and Lapata.</sample>
    <sample id="232">Ich kann das aus dem Bild nicht direkt ableiten. Du könntest versuchen, es im Text des Beitrags zu suchen oder die Co-Autoren direkt zu fragen.</sample>
    <sample id="233">Chowdery.</sample>
    <sample id="234">NLPositionality: Charakterisierung von Design-Voreingenommenheiten von Datensätzen und Modellen. Sebastian Santy*, University of Washington. Jenny T. Liang*, Carnegie Mellon University. Ronan Le Bras, Allen Institute for AI. Katharina Reinecke, University of Washington. Maarten Sap, Carnegie Mellon University.</sample>
    <sample id="235">NLPositionality: Charakterisierung von Design-Voreingenommenheiten von Datensätzen und Modellen. Sebastian Santy*, University of Washington. Jenny T. Liang*, Carnegie Mellon University. Ronan Le Bras, Allen Institute for AI. Katharina Reinecke, University of Washington. Maarten Sap, Carnegie Mellon University.</sample>
    <sample id="236">Denke an...</sample>
    <sample id="237">Denke mal...</sample>
    <sample id="238">Carl Jones, Tech Lead, New York Times. Aditya Sharma, Tech Lead, Times of India. "Kannst du aufhören, ein Arschloch zu sein?" : 0.82 ✅. "Presstitutes überall in der Nachrichten." : 0.33 ❌.</sample>
    <sample id="239">Kannst du aufhören, ein Arschloch zu sein? : 0.82 ✅, Presstituts überall in der Nachrichten. : 0.33 ❌</sample>
    <sample id="240">Positionalität "Die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben."</sample>
    <sample id="241">Positionalität "Die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben."</sample>
    <sample id="242">Positionalität "Die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben." "Als Forscher, beeinflusst es den Forschungsprozess und seine Ergebnisse und Auswirkungen." [1] Savin-Baden, Maggi und Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge, 2013.</sample>
    <sample id="243">Können Datensätze und Modelle Positionalität haben?</sample>
    <sample id="244">Ja, Datensätze und Modelle haben Positionalität.</sample>
    <sample id="245">Sind Datensätze und Modelle positionell?Anekdotische Beweise: - Modell- und Datensatzprobing, [1][2] - Theoretische Definitionen der Modellpositionellität, [3] [1] Blasi, et al. "Systematische Ungleichheiten in der Leistung der Sprachtechnologie weltweit." ACL 2022. [2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen Prätrainierten Sprachmodellen." EMNLP 2022. [3] Cambo &amp; Gergle. "Modellpositionellität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="246">Können Datensätze und Modelle Positionalität haben?Anekdotische Beweise:.- Modell- und Datensatzprobing, [1][2]- Theoretische Definitionen der Modellpositionalität, [3][1] Blasi, et al. "Systematische Ungleichheiten in der Leistung der Sprachtechnologie weltweit." ACL 2022.[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing auf Multilingualen Prädikten." EMNLP 2022.[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="247">Können Datensätze und Modelle Positionalität haben?Anecdotal evidence:.- Modell- und Datensatzprobing, [1][2]- Theoretische Definitionen der Modellpositionalität, [3][1] Blasi, et al. "Systematische Ungleichheiten in der Leistung der Sprachtechnologie weltweit." ACL 2022.[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing auf Multilingualen Prädikationsmodellen." EMNLP 2022.[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="248">Sind Datensätze und Modelle positionell?Anecdotaler Beweis:.- Modell- und Datensatzprobing, 1, 2.- Theoretische Definitionen der Modellpositionellität, 3.1. Blasi, et al. "Systematische Ungleichheiten in der Leistung der Sprachtechnologie weltweit." ACL 2022.2. Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing auf multilingualen Prädikationsmodellen." EMNLP 2022.3. Cambo &amp; Gergle. "Modellpositionellität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="249">Frage: Haben Datensätze und Modelle Positionalität? Ziel: Vergleiche Anmerkungen von Nutzern mit bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">NLPositionality ist ein Rahmenwerk zur Charakterisierung von Design-Biass in NLP-Datensätzen und -Modellen.</sample>
    <sample id="251">Kollektion

1. 300 Instanzen werden aus einem Datensatz abgegriffen
2. Jede Instanz hat einen zugeordneten Goldlabel

Verarbeitung

5. Die erhaltenen Annotierungen werden gegen die Goldlabels aus dem Datensatz und die Vorhersagen der Modelle verglichen

Analyse

6. Der Pearson's r-Korrelationswert wird zwischen den Goldlabels, den Modellvorhersagen und den Annotierungen für jede Demografie separat gemessen</sample>
    <sample id="252">Kollektion: 300 Instanzen werden aus einem Datensatz abgegriffen. Jede Instanz hat einen zugeordneten Goldstandard-Etikett. Verarbeitung: Die erhaltenen Annotierungen werden gegen die Goldstandard-Etiketten aus dem Datensatz und die von Modellen erzielten Vorhersagen verglichen. Analyse: Der Pearson's r-Korrelationskoeffizient wird zwischen den Goldstandard-Etiketten, den Modellvorhersagen und den Annotierungen für jede Demografie separat gemessen. Wenn du noch Fragen hast oder mehr Details benötigst, lass es mich wissen!</sample>
    <sample id="253">Kollektion: 300 Instanzen werden aus einem Datensatz abgegriffen. Jede Instanz hat einen zugeordneten Goldstandard-Etikett. Verarbeitung: Die erhaltenen Annotierungen werden gegen die Goldstandard-Etiketten aus dem Datensatz und die von Modellen erhaltenen Vorhersagen verglichen. Analyse: Der Pearson's r-Korrelationskoeffizient wird zwischen den Goldstandard-Etiketten, den Modellvorhersagen und den Annotierungen für jede Demografik separat gemessen. 1) Datenbanken mit diversen Annotatoren neu annotieren.</sample>
    <sample id="254">Kollektion: 300 Instanzen werden aus einem Datensatz abgegriffen. Jede Instanz hat einen zugeordneten Goldstandard-Etikett. Verarbeitung: Die erhaltenen Annotierungen werden gegen die Goldstandard-Etiketten aus dem Datensatz und die von Modellen erhaltenen Vorhersagen verglichen. Analyse: Der Pearson's r-Korrelationskoeffizient wird zwischen den Goldstandard-Etiketten, den Modellvorhersagen und den Annotierungen für jede Demografie separat gemessen. 1) Datenmengen mit diversen Annotatoren neu annotieren.</sample>
    <sample id="255">Kollektion: 300 Instanzen werden aus einem Datensatz abgegriffen. Jede Instanz hat einen Goldstandard-Etikett. Verarbeitung: Die erhaltenen Annotierungen werden mit den Goldstandards aus dem Datensatz und den Modellvorhersagen verglichen. Analyse: Pearson's r-Korrelation wird zwischen Goldstandards, Modellvorhersagen und Annotierungen für jede Demografie getrennt gemessen. Vergleiche Annotierungen nach Demografie mit Modellen und Datensätzen mittels Pearson's R-Werte.</sample>
    <sample id="256">Kollektion: 300 Instanzen werden aus einem Datensatz gesammelt. Jede Instanz hat einen Goldstandard-Etikett. Verarbeitung: Die erhaltenen Annotierungen werden gegen die Goldstandards aus dem Datensatz und die Modellempfindungen verglichen. Analyse: Der Pearson's r-Korrelationswert wird zwischen den Goldstandards, Modellvorhersagen und Annotierungen für jede Demografie separat gemessen. Vergleiche die Annotierungen nach Demografie mit Modellen und Datensätzen über Pearson's R-Werte.</sample>
    <sample id="257">Kannst du mit einem AI und seinen Moralvorstellungen leben? Erzähl uns deine moralischen Urteile zu bestimmten Situationen und wir zeigen dir, wie du im Vergleich zu anderen und einem AI stehst. Bist du besser als ein AI im Entdecken von hämischen Sprüchen? Beurteile, was für hämische Sprüche gilt und wir zeigen dir, wie gut du hämische Sprüche entdecken kannst im Vergleich zu einem AI und anderen. Wo stehst du auf der Skala von technikverdächtig bis technuktopianisch? Erzähl uns, wie du denkst, dass zukünftige gemischte Realitätstechnologie dein persönliches Leben beeinflussen wird. Wir zeigen dir, ob du eher technikverdächtig oder technuktopianisch bist.</sample>
    <sample id="258">Können Sie mit einem AI und seinen Moralvorstellungen leben? Erzählen Sie uns Ihre moralischen Urteile zu bestimmten Situationen und wir zeigen Ihnen, wie Sie sich mit anderen und einer AI vergleichen. Sind Sie besser als eine AI im Entdecken von hämischen Sprüchen? Beurteilen Sie, wie gut Sie hämische Sprüche erkennen können, verglichen mit einer AI und anderen. Wo stehen Sie auf der Technik-skeptiker bis Techno-utopiker-Skala? Erzählen Sie uns, wie Sie denken, dass zukünftige gemischte Realitätstechnologie Ihr persönliches Leben beeinflussen wird. Wir zeigen Ihnen, ob Sie eher technik-skeptiker oder technik-utopiker sind.</sample>
    <sample id="259">Aufgabe A: Soziale Akzeptanz. 1) Lese die Situation. 1/15. Wollen, viel Geld zu verdienen. 2) Gib an, was du darüber denkst. Was meinst du dazu aus moralischer Sicht? * sehr schlecht, schlecht, erwartbar/okay, gut, sehr gut. (z.B. okay, du solltest, es ist ungewöhnlich). Es ist im Allgemeinen gut, aber du willst andere nicht im Prozess ausnutzen. 3) Sehe, was ein AI und andere darüber gedacht haben! Der AI spekuliert: Ich vermute, es ist verständlich. Hm… Vielleicht habe ich mich in diesem Punkt geirrt. Studienanteilnehmer in den USA sagten:</sample>
    <sample id="260">Aufgabe A: Soziale Akzeptanz. 1) Lese die Situation. 2) Gib an, was du darüber denkst. 3) Sehe, was ein AI und andere darüber gedacht haben! Teilnehmer vergleichen ihre Antworten mit denen anderer und eines AI.</sample>
    <sample id="261">Aufgabe A: Soziale Akzeptanz Analyse Datensätze - Sozial Chemie Modelle - Delphi - GPT-4</sample>
    <sample id="262">Aufgabe B: Toxizität 1) Lesen Sie das Beispiel: 7 / 25 Englische Menschen riechen nach Sauermilch 2) Geben Sie Ihre Meinung dazu ein. * bezeichnet ein Pflichtfeld. Glauben Sie, dass dies Hassrede ist? Ja Nein Unsicher Erleichtern Sie sich gerne die Bewertung. Geben Sie eine kurze Beschreibung ein. Einreichen 3) Sehen Sie sich die Meinungen anderer an! Der AI spekuliert: Ich vermute, dass dies Hassrede ist. Es sieht so aus, als stimmten wir überein! Studienteilnehmer in Afghanistan sagten: 60% 40% 20% Nicht Hassrede Unsicher Hassrede</sample>
    <sample id="263">Aufgabe B: Toxizität Analyse Datensätze - Dynahate Modelle - Perspective API - Rewire API - Hate RoBERTa - GPT-4 Studienpartizipation 16.299 Annotationen 1.096 Annotatoren 87 Länder</sample>
    <sample id="264">Ergebnisse: Wer stimmen NLP-Datensätze und Modelle?Ergebnis 1: Es gibt Positionalität in NLP.</sample>
    <sample id="265">Datenbanken und Modelle sind am englischsprachigen Länder ausgerichtet.</sample>
    <sample id="266">Datenmengen und Modelle sind am meisten mit Menschen mit einem College-Abschluss ausgerichtet.</sample>
    <sample id="267">Datenmengen und Modelle sind am besten mit Menschen mit einem College-Abschluss ausgerichtet.</sample>
    <sample id="268">Befund 2: Einige Bevölkerungsgruppen werden zurückgelassen.</sample>
    <sample id="269">Die Datensätze und Modelle sind weniger mit nichtbinären Menschen ausgerichtet.</sample>
    <sample id="270">Also, was können wir tun? Positionalität in der NLP angehen.</sample>
    <sample id="271">Empfehlungen 1. Halten Sie eine Aufzeichnung aller relevanten Designentscheidungen, die bei der Erstellung von Datensätzen oder Modellen getroffen wurden. 2. Führen Sie NLP-Forschung aus, unter Verwendung des Perspektivismus als Perspektive: a. Teilen Sie aufgetrennte Datensatzbeschriftungen! b. Verwenden Sie Modellierungstechniken, die Annotierungsunterschiede bewältigen können.</sample>
    <sample id="272">1. Halten Sie eine Aufzeichnung aller relevanten Designentscheidungen, die während der Erstellung von Datensätzen oder Modellen getroffen wurden. 2. Führen Sie NLP-Forschung aus, indem Sie den Perspektivismus als Lens verwenden: a. Teilen Sie aufgetrennte Datensatzbeschriftungen! b. Verwenden Sie Modellierungstechniken, die Annotator-Dis agreement handhaben können. 3. Das Erstellen spezialisierter Datensätze und Modelle für und mit spezifischen Gemeinschaften ist wertvoll für inklusives NLP, z.B. die Masakhane-Initiative.</sample>
    <sample id="273">Vielen Dank! Dashboard-Link: nlpositionality.cs.washington.edu/ Papier: bit.ly/NLPositionality-Paper/ Delphi, https://delechi.allenai.org/ Alter, Geschlecht, Ethnizitäten, Religion, Bildungsniveau, Wohnort, Längster Wohnort, Muttersprache.</sample>
    <sample id="274">Die Referentin geht auf drei Probleme von SimulST ein.</sample>
    <sample id="275">Nicht im Bild.</sample>
    <sample id="276">Das 61. Jahrestreffen der Association for Computational Linguistics, Toronto, Kanada, vom 9. bis 14. Juli 2023. "Script-Kenntnisse aus großen Sprachmodellen für eingeschränkte Sprachplanung extrahieren". Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang. Fudan University und Brain Technologies Inc.</sample>
    <sample id="277">Sprachliche Planung Wie man einen Kuchen backt? 1. Sammel deine Zutaten. 2. Heiz den Ofen auf 325 °F, 163 °C, vor und fett und bestreiche einen Kuchentopf. 3. Schlag die Butter und Zucker. 4. Füge die Eier hinzu. 5. Rühre den Mehlkuchen. 6. Gieße die Teigmasse in den Topf. 7. Backe den Kuchen für 1 Stunde 15 Minuten. Große Sprachmodelle, LLMs, können Ziele effektiv in Schritte zerlegen.</sample>
    <sample id="278">Sprachplanung Wie man Kuchen backt? 1. Sammel deine Zutaten. 2. Heiz den Ofen auf 325 °F, 163 °C, vor und fett und bestreiche einen Kuchentopf. 3. Schlag die Butter und Zucker. 4. Füge die Eier hinzu. 5. Rühre die Mehlzusammensetzung. 6. Gieße die Teigmasse in den Topf. 7. Backe den Kuchen für 1 Stunde 15 Minuten. Große Sprachmodelle, LLMs, können Ziele effektiv in Schritte zerlegen.</sample>
    <sample id="279">Gespannte Sprachplanung. Wie man einen Erdbeerkuchen macht? ...Erdbeer-Marmelade in den Mehl... Wie man einen Schokoladenkuchen macht? ...Kakaopulver in den Mehl... Abstraktes Ziel kann von verschiedenen realen spezifischen Zielen mit vielfältigen Einschränkungen übernommen werden.</sample>
    <sample id="280">Geschränkte Sprachplanung. Wie man einen Erdbeerkuchen macht? ...Erdbeer-Marmelade in den Mehl... Wie man einen Schokoladenkuchen macht? ...Kakaopulver in das Mehl... Abstraktes Ziel kann von verschiedenen realen spezifischen Zielen mit mehreren Facetten von Einschränkungen geerbt werden.</sample>
    <sample id="281">Gespannte Sprachplanung. Wie man einen Erdbeerkuchen macht? ...Erdbeer-Marmelade in den Mehl hinzufügen... Wie man einen Schokoladenkuchen macht? ...Cokapulver in den Mehl hinzufügen... Abstraktes Ziel kann von verschiedenen realen spezifischen Zielen mit vielfältigen Beschränkungen geerbt werden.</sample>
    <sample id="282">Wie performieren LLMs bei beschränkter Sprachplanung? Datensatz: wikiHow + generierte Beschränkungen Constraint-Typ 1: Modifikator Definition: Ein Wort, ein Adjektiv oder ein Satz, das einen abstrakten Zielmodifikator oder -beschränkung modifiziert. Beispiele: Machen Sie eine Schokoladenkuchen. Machen Sie eine rosa Kuchen. Constraint-Typ 2: Methode Definition: Ein Werkzeug oder ein spezifischer Modus, der den Prozess für das Erreichen des Ziels steuert. Beispiele: Machen Sie einen Kuchen mit einem Ofen. Machen Sie einen Kuchen mit Kuchenteig. Constraint-Typ 3: Absicht Definition: Eine zusätzliche Absicht oder Nachfrage, wenn das Ziel erreicht wird. Beispiele: Machen Sie einen Kuchen für die Hochzeit. Machen Sie einen Kuchen für Diabetiker.</sample>
    <sample id="283">Wie performieren LLMs bei beschränkter Sprachplanung? Datensatz: wikiHow + generierte Beschränkungen. Beschränkungstyp 1: Modifikator Definition: Ein Wort, ein Adjektiv oder ein Phrase, das einen abstrakten Zielmodifikator ist oder beschränkt. Beispiele: Machen Sie eine Schokoladenkuchen. Machen Sie eine rosa Kuchen. Beschränkungstyp 2: Methode Definition: Ein Werkzeug oder ein spezifischer Modus, der den Prozess für das Erreichen des Ziels steuert. Beispiele: Machen Sie einen Kuchen mit einem Ofen. Machen Sie einen Kuchen mit einem Kuchenteig. Beschränkungstyp 3: Absicht Definition: Eine zusätzliche Absicht oder Nachfrage bei der Erreichung des Ziels. Beispiele: Machen Sie einen Kuchen für die Hochzeit. Machen Sie einen Kuchen für Diabetiker.</sample>
    <sample id="284">Wie performieren LLMs bei beschränkter Sprachplanung? Datensatz: wikiHow + generierte Beschränkungen Constraint-Typ 1: Modifikator Definition: Ein Wort, ein Adjektiv oder ein Phrase, das einen abstrakten Zielmodifikator oder -beschränkung modifiziert oder beschränkt. Beispiele: Machen Sie eine Schokoladenkuchen. Machen Sie eine rosa Kuchen. Constraint-Typ 2: Methode Definition: Ein Werkzeug oder ein spezifischer Modus, der den Prozess für das Erreichen des Ziels steuert. Beispiele: Machen Sie einen Kuchen mit einem Ofen. Machen Sie einen Kuchen mit einem Kuchenteig. Constraint-Typ 3: Intention Definition: Eine zusätzliche Absicht oder Nachfrage, wenn das Ziel erreicht wird. Beispiele: Machen Sie einen Kuchen für die Hochzeit. Machen Sie einen Kuchen für Diabetiker.</sample>
    <sample id="285">Können LLMs konstruierte Sprachplanung durchführen? Alle Baseline-Modelle erzielen unzufriedenstellende Ergebnisse bei der Planung für spezifische Ziele.</sample>
    <sample id="286">Können LLMs gebotene Sprachplanung durchführen? Alle Baselines erzielen unzufriedenstellende Ergebnisse bei der Planung für spezifische Ziele.</sample>
    <sample id="287">Welche Art von Fehlern machen LLMs in dieser Aufgabe normalerweise?FE1: Keine EinschränkungSE1: Verschnitt, SE2: Wiederholte Schritte, SE3: Falsche ReihenfolgeFE2: Unverwandte SchritteFE3: Inkohärente SchritteDie semantische Vollständigkeit, SE, in den generierten Skripten ist akzeptabel, aber die Treue zur Einschränkung, FE, kann nicht garantiert werden.</sample>
    <sample id="288">Welche Art von Fehlern machen LLMs in dieser Aufgabe normalerweise?FE1: Keine EinschränkungSE1: Verschnittene SchritteSE2: Wiederholte SchritteSE3: Falsche ReihenfolgeFE2: Unverwandte SchritteFE3: Inkohärente SchritteDie semantische Vollständigkeit, SE, in den generierten Skripten ist akzeptabel, aber die Treue zur Einschränkung, FE, kann nicht garantiert werden.</sample>
    <sample id="289">Was für Ziele versagen InstructGPT normalerweise?Die Planungsleistung von InstructGPT variiert erheblich für Ziele unterschiedlicher Kategorien.</sample>
    <sample id="290">Method, Input: ein abstraktes Ziel, Step 1: spezifische Ziele mit InstructGPT über in-kontext-Lernen generieren, Abstract Goal: backen ein Kuchen, +constraints, Specific Goals: G1, +modifikator, backen einen Schokoladenkuchen, G2, +methode, backen einen Kuchen in einem Mikrowellenbackofen, G3, +intenz, backen einen Kuchen für eine Hochzeit.</sample>
    <sample id="291">Method, Input: ein abstraktes Ziel, Schritt 1: spezifische Ziele mit InstructGPT über in-kontext-Lernen generieren, Abstract Goal: backen ein Kuchen, +constraints, Specific Goals: G1, +modifikator, backen einen Schokoladenkuchen, G2, +methode, backen einen Kuchen in einem Mikrowellenherd, G3, +intenz, backen einen Kuchen für eine Hochzeit, Schritt 2: kandidierte Skripte mit InstructGPT über in-kontext-Lernen überschreiben, Candidate Scripts: 1, 2, 3, ... k.</sample>
    <sample id="292">Method, Input: ein abstraktes Ziel, Schritt 1: spezifische Ziele mit InstructGPT über in-kontext-Lernen generieren, Schritt 2: kandidierte Skripte mit InstructGPT über in-kontext-Lernen überschreiben, Abstraktes Ziel: ein Kuchen backen, +beschränkungen, Spezifische Ziele: G1,+modifikator: einen Schokoladenkuchen backen, G2,+methode: einen Kuchen im Mikrowellen backen, G3,+intention: einen Kuchen für eine Hochzeit backen, Generiere Pläne für G1, Kandidierte Skripte: 1, 2, 3, ..., k.</sample>
    <sample id="293">Method Schritt 2: Übergenerieren von Kandidat-Skripten mit InstructGPT durch in-kontextuelles Lernen Schritt 3: Finden von gefilterten Skripten zum Ziel mit InstructGPT über Ähnlichkeitsbewertung Output: Spezifische Ziele mit entsprechenden Skripten</sample>
    <sample id="294">Method Schritt 2: Generiere kandidierte Skripte mit InstructGPT durch in-kontext-Lernen Schritt 3: Finden gefilterter Skripte zum Ziel mit InstructGPT über Ähnlichkeitsbewertung Output: Spezifische Ziele mit entsprechenden Skripten</sample>
    <sample id="295">Method Schritt 2: Generiere kandidierte Skripte mit InstructGPT mittels in-kontext-Lernen Schritt 3: Finden gefilterter Skripte zum Ziel mit InstructGPT mittels Ähnlichkeitsbewertung Output: Spezifische Ziele mit entsprechenden Skripten</sample>
    <sample id="296">Unser Verfahren verbessert die Planungsqualität erheblich. Mit unserem Verfahren kann InstructGPT Skripte von höherer Qualität in einem großen Maßstab generieren.</sample>
    <sample id="297">Motivation: Um eine beschränkte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen. Methode: Folgt dem Prinzip der symbolischen Wissensverdichtung. Generiert 55.000 Skripte mit Beschränkung aus LLMs aufgrund unseres Verfahrens =&gt; Coscript-Datensatz. Menschen annotieren Validierungs- und Testset.</sample>
    <sample id="298">Motivation: Um eine beschränkte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen. Methode: Folgt der Idee der symbolischen Wissensverdichtung. Erzeugte 55.000 Skripte mit Beschränkung von LLMs aufgrund unseres Verfahrens =&gt; Coscript-Datensatz. Menschen annotieren Validierungs- und Testset.</sample>
    <sample id="299">Motivation: Um eine beschränkte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen. Methode: Folgt der Idee der symbolischen Wissensverdichtung. Erzeugte 55.000 Skripte mit Beschränkung von LLMs aufgrund unseres Verfahrens =&gt; Coscript-Datensatz. Menschen annotieren Validierungs- und Testset.</sample>
    <sample id="300">Motivation: Um eine beschränkte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen. Methode: Folgt dem Prinzip der symbolischen Wissensverdichtung. Erzeugte 55.000 Skripte mit Beschränkung aus LLMs aufgrund unseres Verfahrens =&gt; Coscript-Datensatz. Menschen annotieren Validierungs- und Testset.</sample>
    <sample id="301">Motivation: Um eine beschränkte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen. Methode: Folgt dem Prinzip der symbolischen Wissensverdichtung. Generiert 55.000 Skripte mit Beschränkung aus LLMs aufgrund unseres Verfahrens =&gt; Coscript-Datensatz. Menschen annotieren Validierungs- und Testset.</sample>
    <sample id="302">Coscript zeigt eine hohe Heterogenität und Pluralität bei den generierten spezifischen Zielen.</sample>
    <sample id="303">Spezialisierte Modelle vs. LLMs. Smaller LMs fine-tuned on Coscript can generate higher quality scripts than LLMs.</sample>
    <sample id="304">Zusammenfassung und Schlussfolgerungen
- Stellen Sie das Problem der eingeschränkten Sprachplanung fest.
- Beurteilen Sie die Fähigkeit von LLMs zur eingeschränkten Sprachplanung und entwickeln Sie eine Methode zur Über-Generieren und Filtern für LLMs.
- Verwenden Sie LLMs, um einen hochwertigen Skriptdatensatz, CoScript, für die eingeschränkte Sprachplanung zu generieren.
- Grenzen und zukünftige Arbeit
  - Die vorgeschlagene Methode zur Verbesserung von LLMs ist ein post-hoc-Ranking-Ansatz.
  - CoScript erbt nur von einem abstrakten mit einer zusätzlichen Einschränkung.
  - Der CoScript-Datensatz kann ein wertvolles Ressourcen für die Weiterentwicklung der Forschung zur Sprachplanung mit komplexeren und diverseren Zielen und Einschränkungen sein.</sample>
    <sample id="305">Zusammenfassung und Schlussfolgerungen
- Stellen Sie das Problem der eingeschränkten Sprachplanung fest.
- Beurteilen Sie die Fähigkeit von LLMs zur eingeschränkten Sprachplanung und entwickeln Sie eine Methode zur Übererzeugung und Filterung für LLMs.
- Verwenden Sie LLMs, um eine hochwertige Skriptdatensatz, CoScript, für die eingeschränkte Sprachplanung zu generieren.
- Grenzen und zukünftige Arbeit
  - Die vorgeschlagene Methode zur Verbesserung von LLMs ist ein post-hoc-Ranking-Ansatz.
  - CoScript erbt nur von einem abstrakten mit einer zusätzlichen Einschränkung.
  - Der CoScript-Datensatz kann ein wertvolles Ressourcen für die Weiterentwicklung der Forschung zur Sprachplanung mit komplexeren und diverseren Zielen und Einschränkungen sein.</sample>
    <sample id="306">Das 61. Jahrestreffen der Association for Computational Linguistics, Toronto, Kanada, vom 9. bis 14. Juli 2023. "Distilling Script Knowledge from Large Language Models for Constrained Language Planning". Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang. syyuan21@m.fudan.edu.cn. https://github.com/siyuyuan/coscript. 17. Coscript Website.</sample>
    <sample id="307">Die Sprachgewandtheit von PaLM ist im Vergleich zu SOTA niedriger.</sample>
    <sample id="308">Die wichtigsten Eigenschaften sind: Anwendbar auf EaaS, nicht die Nutzbarkeit der bereitgestellten Embeddings zu vermindern, verdeckt für den Angreifer sein und transferierbar zu den Angreiferdiensten. Wenn du noch Fragen hast, lass es mich wissen!</sample>
    <sample id="309">Die englischen TED Talks wurden in 14 Sprachen übersetzt, darunter Deutsch, Spanisch, Französisch, Italienisch, Niederländisch, Portugiesisch, Rumänisch, Russisch, Türkisch und Chinesisch.</sample>
    <sample id="310">300 Instanzen.</sample>
    <sample id="311">Die Distanzmetriken, die verwendet werden, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen, sind die Cosinus-Ähnlichkeit und die l2-Distanz.</sample>
    <sample id="312">In der Aufgabe wurden Modelle, die auf einem mehrsprachigen Encoder basieren, in zwei Gruppen eingesetzt. Eine Gruppe war Enc-PTR, die Multilingual Pretrained Encoders mit Pointer-based Decoders umfasste, wie XLM-R + PTR und mBERT + PTR. Die andere Gruppe war Enc-Dec, die Multilingual Pretrained Encoder-Decoder Models umfasste, wie mBART und mT5.</sample>
    <sample id="344">Sie zählen die Worthäufigkeit auf einem allgemeinen Textkorpus Dp und wählen n Wörter aus einem mittelhohen Häufigkeitsintervall aus.</sample>
    <sample id="345">Können CoNLL-2003 Named Entity Tagger noch in 2023 gut funktionieren? Shuheng Liu, Alan Ritter School of Interactive Computing Georgia Institute of Technology</sample>
    <sample id="346">Nennenswerte Entitätenerkennung und Generalisierung</sample>
    <sample id="347">Nennenswerte Entitätenerkennung und Generalisierung. Modelle haben CoNLL-2003 für fast 20 Jahre verwendet, um NER zu entwickeln. Können diese Modelle auf moderne Daten generalisieren? Was ist für eine gute Generalisierung notwendig?</sample>
    <sample id="348">Nennenswerte Entitätenerkennung und Generalisierung.
- Modelle haben CoNLL-2003 für fast 20 Jahre zur Entwicklung von NER verwendet.
- Können diese Modelle auf moderne Daten generalisieren?
- Was ist für eine gute Generalisierung notwendig?</sample>
    <sample id="349">Nennenswerte Entitätenerkennung und Generalisierung.
- Modelle haben CoNLL-2003 für fast 20 Jahre zur Entwicklung von NER verwendet.
- Können diese Modelle auf moderne Daten generalisieren?
- Was ist für eine gute Generalisierung notwendig?
- Was verursacht den Leistungsabfall?</sample>
    <sample id="350">CoNLL++ Dataset
- Sammelte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie nach den Anmerkungsempfehlungen von CoNLL-2003</sample>
    <sample id="351">CoNLL++ Dataset
- Sammelte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie nach den Anmerkungshinweisen von CoNLL-2003
- Über 20 Modelle wurden auf CoNLL-2003 feinabgestimmt
- Auf CoNLL-2003 Testset und CoNLL++ bewertet</sample>
    <sample id="352">CoNLL++-Dataset
- Sammelte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie nach den Anmerkungshinweisen von CoNLL-2003
- 20+ Modelle wurden auf CoNLL-2003 feinabgestimmt
- Auf CoNLL-2003-Testset und CoNLL++ bewertet
- Prozentuale ΔF1 berechnet, um die Generalisierbarkeit zu beurteilen</sample>
    <sample id="353">Was ist für eine gute Generalisierung notwendig?</sample>
    <sample id="354">Was ist für eine gute Generalisierung notwendig? - Modellarchitektur - Transformer-Modelle generalisieren besser</sample>
    <sample id="355">Was ist für eine gute Generalisierung notwendig?• Modellarchitektur• Transformer-Modelle generalisieren besser• Modellgröße• Größere Modelle generalisieren besser</sample>
    <sample id="356">Was ist für eine gute Generalisierung notwendig?• Modellarchitektur• Transformer-Modelle generalisieren besser• Modellgröße• Größere Modelle generalisieren besser• Anzahl der abzustimmenden Beispiele• Mehr Beispiele führen zu besserer Generalisierung</sample>
    <sample id="357">Was verursacht eine Leistungsabnahme?</sample>
    <sample id="358">Was verursacht eine Leistungsabnahme? - Adaptive Überanpassung?</sample>
    <sample id="359">Was verursacht eine Leistungsabnahme? - Adaptive Überanpassung? - Temporale Abweichung?</sample>
    <sample id="360">Was verursacht eine Leistungsabnahme? - Adaptive Überanpassung? - Temporale Drift?</sample>
    <sample id="361">Was verursacht eine Leistungsabnahme?• Adaptive Overfitting?• Temporale Drift?CoNLL++ F1 ScoreCoNLL-2003 F1 Score95949290888690.59191.59292.5930908886707560949290888670756090.59191.59292.593090888670756090.59191.59292.593090888670756090.59191.59292.593090888670756090.59191.59292.593090888670756090.59191.59292.5930908886707560</sample>
    <sample id="362">Was verursacht eine Leistungsabnahme? - Adaptive Überanpassung? - Keine Verjüngung - Nicht beobachtet - Temporale Abdrift?</sample>
    <sample id="363">Was verursacht eine Leistungsabnahme? - Adaptive Überanpassung? - Keine Verjüngung - Nicht beobachtet - Temporale Abweichung?</sample>
    <sample id="364">Was verursacht eine Leistungsabnahme?• Adaptive Überanpassung?• Keine Verjüngung• Nicht beobachtet• Temporale Abwanderung?• Leistung verschlechtert sich mit größerem zeitlichen Abstand</sample>
    <sample id="365">Was verursacht eine Leistungsabnahme? - Adaptive Überanpassung? * Keine verbleibenden Rückerstattungen * Nicht beobachtet - Temporale Abdrift? * Leistung verschlechtert sich mit größerem zeitlichen Abstand * Hauptursache für Leistungsabnahme</sample>
    <sample id="366">Zusammenfassung
- Für eine gute Generalisierung brauchen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr Anpassungsbeispiele</sample>
    <sample id="367">Zusammenfassung
- Für eine gute Generalisierung brauchen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr Anpassungsbeispiele
- Leistungsschwund wird durch:
  - Temporale Abweichung
  - Keine adaptive Übertreibung verursacht</sample>
    <sample id="368">Zusammenfassung
- Für eine gute Generalisierung brauchen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr Anpassungsexempel
- Leistungsschwund wird durch:
  - Temporale Abweichung
  - Keine adaptive Übertreibung
- Funktionieren CoNLL-2003-Tagger noch?</sample>
    <sample id="369">Zusammenfassung
- Für eine gute Generalisierung brauchen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr abgestimmte Beispiele
- Leistungsschwund wird durch:
  - Temporale Abdrift
  - Keine adaptive Übertreibung
- Funktionieren CoNLL-2003-Tagger noch?
  - JA!</sample>
    <sample id="370">Papier: https://arxiv.org/abs/2212.09747 Datensatz: https://github.com/ShuhengL/acl2023_conllpp Kontakt: sliu775@gatech.edu</sample>
    <sample id="397">Leider ist die Frage nicht vollständig. Es fehlt der Kontext, um die Sprachsegmentgröße zu bestimmen. Könntest du bitte mehr dazu sagen?</sample>
    <sample id="398">Das entitätsspezifische Wissen, das im Beispiel mit Servin und Kea benötigt wird, ist das Wissen, dass Servin ein Richter ist.</sample>
    <sample id="399">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="400">Die Arbeiten konzentrieren sich auf RoBERTa und GPT-2.</sample>
    <sample id="401">Das Modell kombiniert Werte aus mehreren Ebenen. Wenn du noch mehr Details wissen möchtest, frag einfach nach.</sample>
    <sample id="402">Beispiele für direkte Inferenz sind "easy on me" und "the first one". Wenn du noch Fragen hast, lass es mich wissen!</sample>
    <sample id="403">Die Autoren gehören der Fudan University an.</sample>
    <sample id="404">Sechs.</sample>
    <sample id="405">Ja. Wenn du noch weitere Fragen hast, lass sie gerne da.</sample>
    <sample id="406">Sie haben "a woman warrior" als Beispiel für eine markierte Gruppe gegeben.</sample>
    <sample id="407">Nichts im Bild sagt, dass bestimmte Modellarchitekturen nicht gut generalisieren. Es geht nur um die Frage, was für gute Generalisierung notwendig ist. Möchtest du mehr über die verschiedenen Modellarchitekturen wissen?</sample>
    <sample id="408">Die Testdatensätze heißen "Validation".</sample>
    <sample id="409">Sechs. Wenn du noch mehr Fragen hast, lass sie gerne stehen.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten. Wenn du noch mehr Details wissen möchtest, frag einfach nach.</sample>
    <sample id="439">Nichts. Die Autoren haben nicht über zu wenig erforschte Bereiche im Bereich der NLU gesprochen.</sample>
    <sample id="440">Die Referenten heißen Zhiyang Xu, Ying Shen und Lifu Huang.</sample>
    <sample id="441">Ja, Coscript wurde von Menschen für die Validierung und Testung annotiert.</sample>
    <sample id="442">Die Grenzen liegen darin, dass nur ein kleiner Teil der Wörter von Kontext abhängt und bestehende Methoden begrenzte Diskursphänomene und Sprachen unterstützen.</sample>
    <sample id="443">Löschen von indirekten Referenzierungen für Entitätsauswahl, AltEntities Corpus, Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti und Annie Louis, Google Research</sample>
    <sample id="444">Löschen von indirekten Referenzierungen für Entitätsauswahl, AltEntities Corpus, Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti und Annie Louis, Google Research</sample>
    <sample id="445">Indirekte ReferenzierungsAusdrücke. Ziel: Verständnis der Sprache der Benutzer bei der Auswahl. Alternative Frage: "Haben Sie gemeint 'easy on me' oder 'I gotta feeling'?" Direkte Referenz: "easy on me", "the first one". Indirekte Referenz könnte in natürlichen und flüssigen Gesprächen verwendet werden: "Kann die Name nicht mehr erinnern", "Die Aussprachen sind schwer zu unterscheiden", "Möchte eine Präferenz angeben". Indirekte Referenz: "The newer one", "The song that's not energetic".</sample>
    <sample id="446">Indirekte Referenzierungen
• Ziel: Verständnis der Sprache der Nutzer bei der Entscheidungsfindung
Alternative Frage: "Haben Sie gemeint 'easy on me' oder 'I gotta feeling'?"
• Direkte Referenz: "easy on me", "die erste"
• Indirekte Referenz könnte in natürlichen und flüssigen Gesprächen verwendet werden:
• Kann den Namen nicht mehr erinnern
• Die Aussprachen sind schwer zu unterscheiden
• Möchte eine Präferenz angeben
Indirekte Referenz: "Die neuere. Die Musik, die nicht energiegeladen ist."</sample>
    <sample id="447">Indirekte Referenzierungen
• Ziel: Verständnis der Sprache der Benutzer bei der Entscheidungsfindung
Alternative Frage: "Haben Sie 'easy on me' oder 'I gotta feeling' gemeint?"
• Direkte Referenz: "easy on me", "die erste"
• Indirekte Referenz könnte in natürlichen und flüssigen Gesprächen verwendet werden:
• Kann den Namen nicht mehr erinnern
• Die Aussprachen sind schwer zu unterscheiden
• Möchte eine Präferenz angeben
Indirekte Referenz: "Die neuere. Die Musik, die nicht energiegeladen ist."</sample>
    <sample id="448">Indirekte Referenzausdrücke Ziel: Verständnis der Sprache der Nutzer bei der Entscheidungsfindung Alternative Frage: "Haben Sie gemeint 'easy on me' oder 'I gotta feeling'?" Direkte Referenz: "easy on me", "das erste" Indirekte Referenz könnte in natürlichen und flüssigen Gesprächen verwendet werden: - Kann den Namen nicht mehr erinnern - Die Aussprachen sind schwer zu unterscheiden - Möchte eine Präferenz angeben Indirekte Referenz: "Das neuere." "Das Lied, das nicht energiegeladen ist."</sample>
    <sample id="449">Indirekte Referenzierungen
• Ziel: Verständnis der Sprache der Benutzer bei der Entscheidungsfindung
Alternative Frage: "Haben Sie 'easy on me' oder 'I gotta feeling' gemeint?"
• Direkte Referenz: "easy on me", "die erste"
• Indirekte Referenz könnte in natürlichen und flüssigen Gesprächen verwendet werden:
• Kann den Namen nicht mehr erinnern
• Die Aussprachen sind schwer zu unterscheiden
• Möchte eine Präferenz angeben
Indirekte Referenz: "Die neuere. Die Musik, die nicht energiegeladen ist."</sample>
    <sample id="450">Datenkollektion

• Wichtige Probleme
  ○ Konversationsysteme
  ○ Benchmarking großer Sprachmodelle zur Entitätsverstehung
• Kein großes öffentliches Datensatz verfügbar
• Wir sammeln einen großen Datensatz mit Crowd Annotation
• Drei Domänen:</sample>
    <sample id="451">Datenkollektion
• Wichtige Probleme
  ○ Konversationsysteme
  ○ Benchmarking großer Sprachmodelle zur Entitätsverstehung
• Kein großes öffentliches Datensatz verfügbar
• Wir sammeln einen großen Datensatz mit Crowd Annotation
• Drei Domänen:</sample>
    <sample id="452">Methodologie betont Informalität durch eine Cartoon-Fertigstellungsaufgabe.</sample>
    <sample id="453">Methodologie betont Informalität durch eine Cartoon-Fertigstellungsaufgabe.</sample>
    <sample id="454">Methodologie betont Informalität durch Verwendung einer Cartoon-Fertigstellungsaufgabe.</sample>
    <sample id="455">Methodologie betont Informalität durch eine Cartoon-Fertigstellungsaufgabe.</sample>
    <sample id="456">Methodologie betont Informalität durch Verwendung einer Cartoon-Fertigstellungsaufgabe.</sample>
    <sample id="457">Methodologie betont Informalität durch eine Cartoon-Fertigstellungsaufgabe.</sample>
    <sample id="458">Generieren Sie alternative Fragen =&gt; Stichproben von Entity-Paaren. "Bedeint das A oder B?" - Gegenstände mit ähnlichen Infoboxen auf Wikipedia, gleicher Genres und/oder Künstler. "Bedeint das 'This is It' oder 'Man in the Mirror'?" - Gegenstände mit ähnlichen Beschreibungen auf Wikipedia. "Bedeint das 'Thinking of You' oder 'Happy Anywhere'?" - Gegenstände mit ähnlichen Titeln. "Bedeint das 'The Return' (Memoir) oder 'The Return' (Shatner Roman)?" - Zufällig gleichmäßig. "Bedeint das 'You Could Be Mine' oder 'The Way I Am'?" - Auflösung indirekter Referenzierungen für Entity-Auswahl, AltEntities Corpus.</sample>
    <sample id="459">Generieren Sie alternative Fragen =&gt; Stichproben von Entity-Paaren. "Bedeuten Sie A oder B?" - Gegenstände mit ähnlichen Infoboxen auf Wikipedia, gleicher Genres und/oder Künstler. "Bedeuten Sie 'This is It' oder 'Man in the Mirror'?" - Gegenstände mit ähnlichen Beschreibungen auf Wikipedia. "Bedeuten Sie 'Thinking of You' oder 'Happy Anywhere'?" - Gegenstände mit ähnlichen Titeln. "Bedeuten Sie 'The Return' (Memoir) oder 'The Return' (Shatner Roman)?" - Zufällig gleichmäßig. "Bedeuten Sie 'You Could Be Mine' oder 'The Way I Am'?" - Resolving Indirect Referring Expressions for Entity Selection, AltEntities Corpus.</sample>
    <sample id="460">Generieren Sie alternative Fragen =&gt; Stichproben von Entitätenpaaren

"Meinst du A oder B?"

• Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleicher Genre und/oder Künstler)
  "Meinst du 'This Is It' oder 'Man in the Mirror'?"

• Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  "Meinst du 'Thinking of You' oder 'Happy Anywhere'?"

• Gegenstände mit ähnlichen Titeln:
  "Meinst du 'The Return' (Memoir) oder 'The Return' (Shatner Roman)?"

• Zufällig gleichmäßig:
  "Meinst du 'You Could Be Mine' oder 'The Way I Am'?"</sample>
    <sample id="461">Generieren Sie alternative Fragen =&gt; Stichproben von Entitätenpaaren. "Bedeintst du A oder B?" - Gegenstände mit ähnlichen Infoboxen auf Wikipedia, gleicher Genres und/oder Künstler. "Bedeintst du 'This Is It' oder 'Man in the Mirror'?" - Gegenstände mit ähnlichen Beschreibungen auf Wikipedia. "Bedeintst du 'Thinking of You' oder 'Happy Anywhere'?" - Gegenstände mit ähnlichen Titeln. "Bedeintst du 'The Return' als Memoir oder 'The Return' als Shatner Roman?" - Zufällig gleichmäßig. "Bedeintst du 'You Could Be Mine' oder 'The Way I Am'?" - Resolving Indirekte Referierende Ausdrücke für Entitätsauswahl, AltEntities Corpus.</sample>
    <sample id="462">Generieren Sie alternative Fragen =&gt; Stichproben von Entity-Paaren. "Bedeint das A oder B?" - Gegenstände mit ähnlichen Infoboxen auf Wikipedia, gleicher Genres und/oder Künstler. "Bedeint das 'This is It' oder 'Man in the Mirror'?" - Gegenstände mit ähnlichen Beschreibungen auf Wikipedia. "Bedeint das 'Thinking of You' oder 'Happy Anywhere'?" - Gegenstände mit ähnlichen Titeln. "Bedeint das 'The Return' (Memoir) oder 'The Return' (Shatner Roman)?" - Zufällig gleichmäßig. "Bedeint das 'You Could Be Mine' oder 'The Way I Am'?" - Auflösung indirekter Referenzierungen für Entity-Auswahl, AltEntities Corpus.</sample>
    <sample id="463">Hintergrundwissen, Musik, Google-Suchlink zu jedem Lied. Easy on Me, von Adele, I Gotta Feeling, von The Black Eyed Peas, Klicken Sie hier, um mehr über das Lied zu erfahren. Wir bitten die Annotatoren, zumindest einige Lieder anzuhören und über jedes Lied zu lesen.</sample>
    <sample id="464">Hintergrundwissen, Musik, Google-Suchverbindungen zu jedem Lied. Easy on Me, Adele, I Gotta Feeling, The Black Eyed Peas, Klicken Sie hier, um mehr über das Lied zu erfahren. Wir bitten die Annotatoren, zumindest einige Lieder anzuhören und über jedes Lied zu lesen.</sample>
    <sample id="465">Hintergrundwissen, Musik, Google-Suchlink zu jedem Lied. Easy on Me, Adele, Klicke hier, um mehr über das Lied zu erfahren. I Gotta Feeling, The Black Eyed Peas, Klicke hier, um mehr über das Lied zu erfahren. Wir bitten die Annotatoren, zumindest einige Lieder anzuhören und über jedes Lied zu lesen.</sample>
    <sample id="466">Hintergrundwissen (Rezepte) Simnelkuchen ist ein Früchtekuchen, der im Vereinigten Königreich, in Irland und anderen Ländern mit Migrationsmustern verbreitet ist, die mit dem Fasten und Ostern in Verbindung stehen. Er zeichnet sich durch Schichten aus Mandelmasse oder Marzipan und eine Reihe von elf Kugeln aus, die aus derselben Paste hergestellt sind.Pandan-Kuchen ist ein leichter, fluffiger, grün gefärbter Biskuitkuchen, der mit den Saften von Pandanus amaryllifolius Blättern aromatisiert ist. Der Kuchen ist in Indonesien, Malaysia und auch in den Niederlanden beliebt, insbesondere unter der Indo-Community.</sample>
    <sample id="467">Eliciting expressions. Wir sagen den Annotatoren dann, welche Wahl ausgewählt werden sollte, und bitten sie, es zu beschreiben. Wählen Sie diese aus. Easy on Me, von Adele. I Gotta Feeling, von den Black Eyed Peas. Wir möchten, dass Sie 3 bis 5 Ausdrücke für das gewählte Lied geben, um in Ihre Sprachblase zu füllen. Zum Beispiel: Das mit dem Klaviermusik. Das Lied, das nicht energiegeladen ist. Es hat etwas mit einem Fluss. Das neuere. Es geht darum, nicht genug Zeit zu haben, um zu wählen.</sample>
    <sample id="468">Klar, ich kann das für dich übersetzen. Hier ist die deutsche Übersetzung: "Zufällige Beispiele Musikauswahl: Wollen Sie "Chime" oder "Your Loving Arms"? - Die ohne Worte. Wollen Sie "These Kids" oder "Inescapable"? - Es ist das Lied eines Australiers. Wollen Sie "Rock the Boat" oder "Wherever You Are"? - Es hat Synthesizer-Sounds. Wollen Sie "Telepathy" oder "Stars on 45"? - Es kam in der Mitte des 20. Jahrhunderts heraus. Wollen Sie "Mis-Shapes" oder "Remind Me"? - Aufgrund von Erfahrungen in Sheffield. Buchauswahl: Wollen Sie "Warlock" von Hall oder Smith? - Die, die im 18. Jahrhundert spielt. Wollen Sie "The Legion of Space" oder "The Body in the Library"? - Es ist von einem berühmten Detektivautor. Wollen Sie "The Good Soldier" oder "The Good Soldiers"? - Das fiktive. Wollen Sie "The Giaour" oder "The Giver"?</sample>
    <sample id="469">AltEntities Corpus
• ~6.000 alternative questions across the three domains
• ~42.000 indirect referring expressions
• Results with T5 XL model, accuracy:
o 92-95% if the LM has access to the same background knowledge as annotators.
o 82%-87% when the LM has access to partially overlapping background knowledge.
o ~60% when the LM, T5 XL, has only access to the entity names.
o We showed models are domain-generalizable.
• Dataset Link: https://github.com/google-research-datasets/AltEntities
AltEntities Corpus
• ~6.000 alternative questions across the three domains
• ~42.000 indirekte Referenzierungsexpressions
• Ergebnisse mit T5 XL Modell, Genauigkeit:
o 92-95% wenn das LM den gleichen Hintergrundwissen wie die Annotatoren hat.
o 82%-87% wenn das LM den Hintergrundwissen mit teilweise überschneidung hat.
o ~60% wenn das LM, T5 XL, nur Zugang zu den Entitätsnamen</sample>
    <sample id="470">AltEntities Corpus
• ~6.000 alternative questions across the three domains
• ~42.000 indirect referring expressions
• Results with T5 XL model, accuracy:
 o 92-95% if the LM has access to the same background knowledge as annotators.
 o 82%-87% when the the LM has access to partially overlapping background knowledge.
 o ~60% when the LM, T5 XL, has only access to the entity names.
 o We showed models are domain-generalizable.
• Dataset Link: https://github.com/google-research-datasets/AltEntities
AltEntities Corpus
• ~6.000 alternative questions across the three domains
• ~42.000 indirekte Referenzierungsformen
• Ergebnisse mit dem T5 XL-Modell, Genauigkeit:
 o 92-95% wenn das LM den gleichen Hintergrundwissen wie die Annotatoren hat.
 o 82%-87% wenn das LM Zugang zu teilweise überlappendem Hintergrundwissen hat.
 o ~60% wenn das LM, T5 XL, nur Zugang zu den Entitäts</sample>
    <sample id="471">AltEntities Corpus
• ~6.000 alternative questions across the three domains
• ~42.000 indirect referring expressions
• Results with T5 XL model, accuracy:
 o 92-95% if the LM has access to the same background knowledge as annotators.
 o 82%-87% when the the LM has access to partially overlapping background knowledge.
 o ~60% when the LM, T5 XL, has only access to the entity names.
 o We showed models are domain-generalizable.
• Dataset Link: https://github.com/google-research-datasets/AltEntities
AltEntities Corpus
• ~6.000 alternative questions across the three domains
• ~42.000 indirekte Referenzierungsexpressions
• Ergebnisse mit T5 XL Modell, Genauigkeit:
 o 92-95% wenn das LM den gleichen Hintergrundwissen wie die Annotatoren hat.
 o 82%-87% wenn das LM Zugang zu teilweise überlappendem Hintergrundwissen hat.
 o ~60% wenn das LM, T5 XL, nur Zugang zu den Entitätsnamen</sample>
    <sample id="472">AltEntities Corpus
• ~6.000 alternative questions across the three domains
• ~42.000 indirect referring expressions
• Results with T5 XL model, accuracy:
 o 92-95% if the LM has access to the same background knowledge as annotators.
 o 82%-87% when the the LM has access to partially overlapping background knowledge.
 o ~60% when the LM, T5 XL, has only access to the entity names.
 o We showed models are domain-generalizable.
• Dataset Link: https://github.com/google-research-datasets/AltEntities
AltEntities Corpus
• ~6.000 alternative questions across the three domains
• ~42.000 indirekte Referenzierungsexpressions
• Ergebnisse mit T5 XL Modell, Genauigkeit:
 o 92-95% wenn das LM den gleichen Hintergrundwissen wie die Annotatoren hat.
 o 82%-87% wenn das LM Zugang zu teilweise überlappendem Hintergrundwissen hat.
 o ~60% wenn das LM, T5 XL, nur Zugang zu den Entitätsnamen</sample>
    <sample id="473">Mit den bestehenden SimulST-Richtlinien, die ein state of the art architecture sind, wird der Ansatz verglichen.</sample>
    <sample id="474">Yanis Labrak und Mickael Rouvier gehören der Avignon Universität an, Adrien Bazoge und Emmanuel Morin der Nantes Universität, Richard Dufour und Béatrice Daille ebenfalls der Nantes Universität, Pierre-Antoine Gourraud der Zenidoc.</sample>
    <sample id="475">Sebastin Santy.</sample>
    <sample id="476">Drei.</sample>
    <sample id="477">Achtung als Leitfaden für die gleichzeitige Sprachübersetzung Sara Papi, Matteo Negri, Marco Turchi</sample>
    <sample id="478">Simultane Sprachübersetzung, SimulST, ist der Prozess, gesprochene Sprache in Echtzeit in eine andere Sprache zu übersetzen, um interlinguale Kommunikation zu ermöglichen.</sample>
    <sample id="479">Spezifische Architekturen werden normalerweise trainiert, wodurch zusätzliche Module eingeführt werden müssen, um optimiert zu werden.</sample>
    <sample id="480">Die aktuellen SimulST-Modelle haben zwei Probleme: spezifische Architekturen werden normalerweise trainiert, wodurch zusätzliche Module optimiert werden müssen, und die Trainingsprozesse sind lang und kompliziert, beispielsweise mit verschiedenen Optimierungszielen.</sample>
    <sample id="481">Die aktuellen SimulST-Modelle haben folgende Probleme: Spezifische Architekturen werden normalerweise trainiert, wodurch zusätzliche Module optimiert werden müssen. Lange und komplizierte Trainingsverfahren, z.B. verschiedene Optimierungsziele. Das Trainieren und Warten mehrerer Modelle, um verschiedene Latenzregime zu erreichen, z.B. 1s, 2s, usw.</sample>
    <sample id="482">Was ist unsere Lösung?</sample>
    <sample id="483">Was ist unsere Lösung? 01 Verwende bereits vorhandene offline ST-Modelle ohne Neubearbeitung oder Anpassung einer spezifischen Architektur für SimulST. 02 Verwende nur ein Modell für jede Latenzregelung und handle Latenz durch spezifische Parameter.</sample>
    <sample id="484">Was ist unsere Lösung? 01. Nutze bereits vorhandene offline ST-Modelle ohne Neubearbeitung oder Anpassung spezifischer Architekturen für SimulIST. 02. Verwende nur ein Modell für jede Latenzregime und handele Latenz durch spezifische Parameter. 03. Nutze das bereits erlangte Wissen des Modells durch die Aufmerksamkeitsmechanismen zwischen Audiosignal und textueller Ausgabe.</sample>
    <sample id="485">Unsere Lösung: EDAtt Encoder-Decoder-Aufmerksamkeit Entscheidet, ob eine Teilübersetzung emittiert wird oder nicht, basierend darauf, wohin die Aufmerksamkeit zeigt: Ein Wort wird emittiert, wenn die Aufmerksamkeit nicht auf die letzten λ Sprachrahmen konzentriert ist, d. h., wenn die Summe unter einem Schwellwert a liegt, was bedeutet, dass die empfangene Information stabil genug ist.</sample>
    <sample id="486">Unsere Lösung: EDAtt Entscheidung, ob eine partielle Übersetzung emittiert wird oder nicht, basierend darauf, wo die Aufmerksamkeit zeigt: Ein Wort wird emittiert, wenn die Aufmerksamkeit nicht auf die letzten λ Sprachrahmen konzentriert ist, d. h. wenn ihre Summe unter einem Schwellwert a liegt, was bedeutet, dass die empfangene Information ausreichend stabil ist.</sample>
    <sample id="487">Unsere Lösung: EDAtt Entscheidung, ob eine partielle Übersetzung emittiert wird oder nicht, basierend darauf, wo die Aufmerksamkeit zeigt: Ein Wort wird emittiert, wenn die Aufmerksamkeit nicht auf die letzten λ Sprachrahmen konzentriert ist, d. h. wenn die Summe unter einem Schwellwert a liegt, was bedeutet, dass die empfangene Information ausreichend stabil ist. Ich werde reden.</sample>
    <sample id="488">Unsere Lösung: EDAtt Entscheidung, ob eine vollständige oder eine partielle Übersetzung auszuführen ist, basiert darauf, wo die Aufmerksamkeit zeigt: Ein Wort wird ausgegeben, wenn die Aufmerksamkeit nicht auf die letzten λ Sprachrahmen konzentriert ist, was bedeutet, dass die empfangene Information stabil genug ist. Ich werde reden.</sample>
    <sample id="489">Unsere Lösung: EDAtt Entscheidung, ob eine Teilübersetzung emittiert wird oder nicht, basierend darauf, wo die Aufmerksamkeit aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam</sample>
    <sample id="490">Unsere Lösung: EDAtt Entscheidung, ob eine partielle Übersetzung auszugeben ist oder nicht, basierend darauf, wo die Aufmerksamkeit aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam aufmerksam auf</sample>
    <sample id="491">Unsere Lösung: EDAtt Entscheidung, ob eine partielle Übersetzung emittiert wird oder nicht, basierend darauf, wo die Aufmerksamkeit zeigt: Ein Wort wird emittiert, wenn die Aufmerksamkeit nicht auf die letzten λ Sprachrahmen konzentriert ist, d. h. wenn die Summe der Aufmerksamkeit unter einem Schwellwert α liegt, was bedeutet, dass die empfangene Information ausreichend stabil ist.</sample>
    <sample id="492">Ich werde über Klima sprechen.</sample>
    <sample id="493">Unsere Lösung: EDAtt Entscheidung, ob eine oder eine Teilübersetzung emittiert wird, basierend darauf, wo die Aufmerksamkeit zeigt: Ein Wort wird emittiert, wenn die Aufmerksamkeit nicht auf die letzten λ Sprachrahmen konzentriert ist, d.h. wenn die Summe unter einem Schwellwert a liegt, was bedeutet, dass die empfangene Information stabil genug ist. 01 Ich werde reden. EMITTET 02 Ich werde über Klima sprechen.</sample>
    <sample id="494">Unseres Lösung: EDAtt Entscheidet, ob eine oder eine Teilübersetzung emittiert wird, basierend darauf, wo die Aufmerksamkeit zeigt: Ein Wort wird emittiert, wenn die Aufmerksamkeit nicht auf die letzten λ Sprachrahmen konzentriert ist, d.h. wenn die Summe unter einem Schwellwert a liegt, was bedeutet, dass die empfangene Information stabil genug ist. 01 Ich gehe über... Ich werde reden. EMITTET 02 Ich gehe über Klima sprechen. EMITTET</sample>
    <sample id="495">Hauptergebnisse: EDAtt
Bereich von 0,5 bis 5 Sekunden für AL / AL_Ca
Y-Achse zeigt BLEU-Werte von 17 bis 27</sample>
    <sample id="496">Klar, aber du musst den englischen Inhalt erst mal teilen, damit ich ihn übersetzen kann.</sample>
    <sample id="497">Klar, aber du musst den englischen Inhalt erst mal teilen, damit ich ihn übersetzen kann.</sample>
    <sample id="498">Hauptergebnisse: EDAtt
(a) en→de</sample>
    <sample id="499">Hauptergebnisse: EDAtt
Bereich: 0,5 bis 5 Sekunden
Y-Achse: BLEU-Score von 17 bis 27
X-Achse: AL / AL_Ca in Sekunden
Untertitel: en→de</sample>
    <sample id="500">Hauptergebnisse: EDAtt. Beliebte Strategien werden auch auf Offline-Modellen angewendet. State of the art Architektur speziell für SimulST angepasst.</sample>
    <sample id="501">Hauptergebnisse: EDAtt
Bereich (a) en→de
X-Achse: AL / AL_CA, Y-Achse: BLEU
wait-k, LA, CAAT, EDAtt</sample>
    <sample id="502">Hauptergebnisse: EDAtt
EDAtt übertrifft alle angewandten Strategien bei Offline-Modellen</sample>
    <sample id="503">Hauptergebnisse: EDAtt
EDAtt übertrifft alle Strategien, die auf Offline-Modellen angewendet wurden
EDAtt ist die schnellste Strategie, wenn wir die tatsächliche verstrichene Zeit berücksichtigen</sample>
    <sample id="504">Willst du mehr entdecken? Lesen Sie unser Papier, um mehr Ergebnisse zu entdecken! {spapi,negri}@fbk.eu marco.turchi@gmail.com github.com/hlt-mt/fbk-fairseq @fbk_mt @sarapapi Scan me!</sample>
    <sample id="505">Ja, der Datensatz ist öffentlich zugänglich. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="506">MULTIINSTRUCT: Verbessern von multi-modalem Zero-Shot-Lernen durch Anpassung von Anweisungen. Zhiyang Xu*, Ying Shen*, Lifu Huang. Abteilung für Informatik, Virginia Tech. *gleiche Beitrag.</sample>
    <sample id="507">Vorabgeleitete Sprachmodelle für Unteraufgaben, A) Vorabgeleitete und weitergeleitete Modelle, BERT, T5, vorabgeleitete Sprachmodelle, typischerweise erfordert es viele task-spezifische Beispiele, ein spezialisiertes Modell für jede Aufgabe, B) Prompten, GPT-3, verbessert die Leistung durch Few-Shot-Prompten oder Prompt-Engineering, Inferenz auf Aufgabe A, C) Anweisungstuning, FLAN, vorabgeleitete Sprachmodelle, das Modell lernt viele Aufgaben über natürliche Sprachanweisungen auszuführen, Inferenz auf Aufgabe A, Inferenz auf unbekannte Aufgabe, Abbildung 2: Vergleich des Anweisungstunings mit Vorabgeleiteten und weitergeleiteten Modellen und Prompten, Bildquellenangabe: Wei, Jason, et al. "Vorabgeleitete Sprachmodelle sind zero-shot Lerner."</sample>
    <sample id="508">Vorabgeprägte Sprachmodelle für Unteraufgaben, A) Vorabgeprägen und Feinarbeiten, BERT, T5, Prätrainiertes LM, Feinarbeiten an Aufgabe A, Inferenz an Aufgabe A, typischerweise erfordert es viele task-spezifische Beispiele, ein spezialisiertes Modell für jede Aufgabe, B) Prompten, GPT-3, Prätrainiertes LM, Verbesserung der Leistung durch Few-Shot-Prompten oder Prompt-Engineering, Inferenz an Aufgabe A, C) Anweisungstuning, FLAN, Prätrainiertes LM, Anweisungstuning an vielen Aufgaben, Modell lernt viele Aufgaben über natürliche Sprachanweisungen, Inferenz an Aufgabe A, Inferenz an unbekannter Aufgabe, Abbildung 2: Vergleich des Anweisungstunings mit Vorabgeprägen und Feinarbeiten und Prompten, Bildquellen: Wei, Jason, et al. "Finetunete Sprachmodelle sind zero-shot Lerner."</sample>
    <sample id="509">Nur Sprache.</sample>
    <sample id="510">Instruktionsabstimmung an Multimodal-Prätrainierungsmodellen</sample>
    <sample id="511">Unausgewogene Anordnung in instruktiven Datensätzen zwischen NLP und Multimodal. Über 1600 Sprachalleinige Anweisungsaufgaben. Wang, Yizhong, et al. "Benchmarcing generalization via in-context instructions on 1600+ language tasks." arXiv preprint arXiv:2303.10072.</sample>
    <sample id="512">Unausgewogene Verhältnisse in instruktionalen Datensätzen zwischen NLP und Multimodal. Über 1600 rein sprachliche Anweisungsaufgaben. Keine großen, öffentlich zugänglichen multimodalen Anweisungsaufgaben.</sample>
    <sample id="513">Das erste multimodale Anweisungstuning-Benchmark-Datensatz. - 62 vielfältige multimodale Aufgaben - 10 breite Gruppen - 5 expertenverfasste Anweisungen.</sample>
    <sample id="514">Das erste multimodale Anweisungstuning-Benchmark-Datensatz. - 62 vielfältige multimodale Aufgaben - 10 breite Gruppen - 5 expertenverfasste Anweisungen.</sample>
    <sample id="515">OFA (Ein für alle)• Ein einheitliches multi-modulares vortrainierter Modell, das sowohl Versteh- als auch Generierungsaufgaben mit einer oder mehreren Modalitäten ausführen kann. • OFA verfügt über einen einheitlichen Vokabular für Sprache, Bild-Token und die Koordinaten einer Umrahmung.</sample>
    <sample id="516">Klar, ich kann das übersetzen. Hier ist die Übersetzung: "MULTINSTRUKT

**Begründete Beschriftung**

Eingabe: Erstelle eine Beschriftung für &lt;bin 198&gt; &lt;bin 32&gt; &lt;bin 400&gt; &lt;bin 193&gt;.

Ausgabe: blau-weißer Tennisschläger

**Textortierung**

Eingabe: Wählen Sie die Region aus, die den Text "den" enthält.

Optionen: &lt;bin 206&gt; &lt;bin 119&gt; &lt;bin 448&gt; &lt;bin 181&gt; |||| &lt;bin 357&gt; &lt;bin 518&gt; &lt;bin 456&gt; &lt;bin 574&gt; |||| &lt;bin 229&gt; &lt;bin 604&gt; &lt;bin 304&gt; &lt;bin 654&gt;

Ausgabe: &lt;bin 229&gt; &lt;bin 604&gt; &lt;bin 304&gt; &lt;bin 654&gt;

**Referenzierende Ausdrucksauswahl**

Eingabe: Wählen Sie die Region des</sample>
    <sample id="517">Klar, ich kann den Inhalt übersetzen. Hier ist die Übersetzung: "MULTINSTRUKT

**Begründete Beschriftung**

Eingabe: Erstelle eine Beschriftung für &lt;bin 198&gt; &lt;bin 32&gt; &lt;bin 400&gt; &lt;bin 193&gt;.

Eingabe: Wählen Sie die Region aus, die den Text "den" enthält.

Eingabe: Wählen Sie die Region des beschriebenen Objekts "Ein blauer Zug im Vordergrund".

Eingabe: Gegeben ist das Bildinhalt, haben Sie ausreichend Informationen, um die Frage "Ist es ein sonniger Tag?" zu beantworten?

Ausgabe: blau-weißer Tennisschläger

Ausgabe: &lt;bin 229&gt; &lt;bin 604&gt; &lt;bin 304&gt; &lt;bin 654&gt;

Ausgabe: &lt;bin 242&gt; &lt;bin 180&gt; &lt;bin 736&gt; &lt;bin 475&gt;

Ausgabe: "Die Frage ist irrelevant zum Bild"

**Textlokalisierung**

**Referenzier</sample>
    <sample id="518">Klar, ich kann den Inhalt übersetzen. Was genau möchtest du übersetzt haben?</sample>
    <sample id="519">Multimodale Anweisungstuning</sample>
    <sample id="520">Multi-Modale Anweisungskehren
- Erstellung des Trainingsdatensatzes:
  - Verwende 53 Aufgaben aus 9 Gruppen für das Training.
  - Stichproben 10.000 Beispiele pro Aufgabe.
- Erstellung des Testdatensatzes:
  - Reserviere die gesamte Commonsense Reasoning Gruppe für das Testen.
  - Wähle zusätzliche 5 Aufgaben aus den VQA und Miscellaneous Gruppen aus.
  - Verwende alle Beispiele in der Testspaltung für jede Aufgabe.
  - Zufällig 20 Aufgaben aus der Testspaltung des Natural Instructions Datensatzes als unbekannte Aufgaben für die NLP auswählen.</sample>
    <sample id="521">Multi-Modale Anweisungs-Drehung
- Erstellung des Trainingsdatensatzes:
  - Verwende 53 Aufgaben aus 9 Gruppen für das Training.
  - Pro Aufgabe werden 10.000 Instanzen abgetastet.
- Erstellung des Testdatensatzes:
  - Reserviere die gesamte Commonsense Reasoning-Gruppe für den Test.
  - Wähle zusätzliche 5 Aufgaben aus den VQA- und Verschiedenen Gruppen aus.
  - Wir verwenden alle Instanzen in der Testspaltung für jede Aufgabe.
  - Zufällig 20 Aufgaben aus der Testspaltung des Natural Instructions-Datensatzes als unbekannte Aufgaben für die NLP auswählen.</sample>
    <sample id="522">Implementierungsdetails
- Trainingsdetails:
  - Vorgebildeter OFA-Large-Modell, 472M
  - Alle Instanzen für alle Aufgaben mischen.
  - Jede Instanz wird zufällig mit einem ihrer fünf Anweisungsvorlagen kombiniert.
- Testdetails:
  - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment bewerten.
  - Wir berichten die durchschnittliche und maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="523">Implementierungsdetails
- Trainingsdetails:
  - Vorgebildete OFA-Large-Modell, 472M
  - Alle Instanzen für alle Aufgaben mischen.
  - Jede Instanz wird zufällig mit einem ihrer fünf Anweisungsvorlagen kombiniert.
- Testdetails:
  - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment bewerten.
  - Wir berichten die durchschnittliche und maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="524">Implementierungsdetails
- Trainingsdetails:
  - Vorgebautes OFA-Large-Modell, 472M
  - Alle Instanzen für alle Aufgaben mischen.
  - Jede Instanz wird zufällig mit einem ihrer fünf Anweisungsvorlagen kombiniert.
- Testdetails:
  - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment bewerten.
  - Wir berichten die durchschnittliche und maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="525">Bewertungsmetriken

- Für multi-modale Klassifizierungsaufgaben, wie visuelle Implikation, visuelle Räumliche Denkweise, natürliche Sprache visuelle Denkweise und Katastrophentyp-Klassifizierung, wird die Genauigkeit gemeldet.
- Für multi-modale Generierungsaufgaben, wie Allgemeinwissen VQA, Text VQA, Boden VQA, visuelle Textextraktion und visuelle Dialoge, wird die Rouge-L gemeldet.
- Für NLP-Aufgaben wird die Rouge-L gemeldet.

- Wir berechnen auch die aggregierte Leistung für jede Modell auf der Grundlage des Durchschnitts der Leistung des Modells auf allen unbekannten multimodalen und NLP-Aufgaben. Wir verwenden Rouge-L als Leistungsbewertung für die meisten Aufgaben und Genauigkeit für Aufgaben, bei denen nur Genauigkeit als Metrik verwendet wird.</sample>
    <sample id="526">Sensitivität

Wie empfindlich das Modell gegenüber einer Vielzahl von Anweisungen für die gleiche Aufgabe ist:

- Fähigkeit, bei gleicher Aufgabe stets die gleichen Ergebnisse zu erzielen, unabhängig von leichten Variationen in der Wortwahl der Anweisungen.</sample>
    <sample id="527">Effektivität der Anpassung von Anweisungen auf MULTIINSTRUCT

Tabelle 1: Zero-Shot-Leistung bei multimodalem Commonsense-Grundlagenwissen. Die beste Leistung ist in fetter Schrift.

Tabelle 2: Zero-Shot-Leistung bei Fragebeantwortung und anderen Aufgaben. Die beste Leistung ist in fetter Schrift.</sample>
    <sample id="528">Effektivität der Anpassung von Anweisungen auf MULTIINSTRUCT

Tabelle 1: Zero-Shot-Leistung bei multimodalem Commonsense-Grundlagenwissen. Die besten Leistungen sind fettgedruckt.

Tabelle 2: Zero-Shot-Leistung bei Fragebeantwortung und anderen. Die besten Leistungen sind fettgedruckt.</sample>
    <sample id="529">Effekt des Anwachsens von multimodalen Anweisungs-Task-Clustern
- Bild Verständnis
  - VQA + Bildverstand
- Bodenlegung
  - Bodenlegungsmatching + Bodenlegungsgeneration
- MISCH, ITM
  - Temporale Anordnung + Verschiedenes + Bildtext-Matching
- Beziehung
  - Visuelle Beziehung
- Region
  - Region Verständnis
- NLP
  - NLP-Aufgaben
Bild 3: Modellleistung als die multimodalen Anweisungs-Task-Clustern anwachsen</sample>
    <sample id="530">Effekt der diversen Anweisungen auf die Anweisungstuning.- OFA mit 5 Anweisungen feinabgestimmt erreicht eine viel höhere aggregierte Leistung auf allen Evaluierungsaufgaben und zeigt eine geringere Sensibilität.Tabelle 3: Effekt unterschiedlicher Anzahl von Anweisungen. Leistung von OFA, MultiInstruct, mit unterschiedlicher Anzahl von Anweisungen feinabgestimmt.</sample>
    <sample id="531">Effekt von Feinarbeitungsstrategien auf Modellsensitivität
- Die Anpassung der Anweisung an MultiInstruct kann die Sensitivität von OFA erheblich reduzieren.
- Das Transfer-Lernen aus dem Natural Instructions-Datensatz kann die Sensitivität des Modells weiter reduzieren.
Bild 4: Modellsensitivität bei unbekannten Evaluierungsaufgaben. Je niedriger, desto besser.</sample>
    <sample id="532">- Die Anpassung der Anweisung an MultiInstruct kann die zero-shot-Leistung bei unbekannten NLP-Aufgaben verbessern.
- Die Transfer-Lernstrategie MixedInstruct kann am besten die zero-shot-Fähigkeit auf dem Natural Instructions-Datensatz beibehalten.</sample>
    <sample id="533">Abschluss
- Erstes großes multi-modales Anweisungstuning-Datensatz.
  - Enthält 62 multi-modale Aufgaben aus 10 breiten Kategorien.
- Die zero-shot-Fähigkeit von OFA durch Anweisungstuning erheblich verbessern.
- Verschiedene Transfer-Lernverfahren erforschen und ihre Vorteile zeigen.
- Einen neuen Sensitivitäts-Metric entwerfen.</sample>
    <sample id="534">Noch eine Sache!Wir sammeln einen viel größeren multimodalen Anpassungsdatensatz mit etwa 150 zusätzlichen visuellsprachlichen Aufgaben und werden sie bald veröffentlichen!</sample>
    <sample id="535">Die Autoren gehören der Università di Trento an.</sample>
    <sample id="536">Mohammad Javad Hosseini.</sample>
    <sample id="562">Sprachmodell-Acceptability-Bewertungen sind nicht immer robust gegenüber Kontext.</sample>
    <sample id="563">Sprachmodell-Acceptability-Bewertungen sind nicht immer robust gegenüber Kontext.</sample>
    <sample id="564">Minimalpaar-Paradigma, MPP, -Evaluierungen von Sprachmodellen nutzen relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst.* P,1, &gt; P,2,.- SyntaxGym: 1. Kein Kunde ... hat Geld ausgegeben. 2. *Der Kunde ... hat Geld ausgegeben.* P,1.any, ≥ P,2.any,.- Crows: 1. Stereotypischer Satz. 2. Nicht-stereotypischer Satz. P,1, &gt; P,2,</sample>
    <sample id="565">Minimalpaar-Paradigma, MPP, beurteilt Sprachmodelle, indem sie relative Unterschiede in den sequenziellen Wahrscheinlichkeiten verwenden, um das abstrakte Wissen von Sprachmodellen zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P, 1, &gt; P, 2,.- SyntaxGym: 1. Kein Kunde ... hat Geld ausgegeben. 2. *Der Kunde ... hat Geld ausgegeben. P, 1.any, ≥ P, 2.any,.- Crows: 1. Stereotypischer Satz. 2. Nicht-stereotypischer Satz. P, 1, &gt; P, 2,</sample>
    <sample id="566">Minimalpaar-Paradigma, MPP, beurteilt Sprachmodelle, indem sie relative Unterschiede in den Sequenzwahrscheinlichkeiten verwenden, um das abstrakte Wissen der Modelle zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P, 1, &gt; P, 2,.- SyntaxGym: 1. Kein Kunde ... hat Geld ausgegeben. 2. *Der Kunde ... hat Geld ausgegeben. P, 1.any, ≥ P, 2.any,.- Crows: 1. Stereotypischer Satz. 2. Nicht-stereotypischer Satz. P, 1, &gt; P, 2,</sample>
    <sample id="567">Minimalpaar-Paradigma, MPP, -Evaluierungen von Sprachmodellen nutzen relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P,1, &gt; P,2,.- SyntaxGym: 1. Kein Kunde ... hat Geld ausgegeben. 2. *Der Kunde ... hat Geld ausgegeben. P,1.any, ≥ P,2.any,.- Crows: 1. Stereotypischer Satz. 2. Nicht-stereotypischer Satz. P,1, &gt; P,2,</sample>
    <sample id="568">Minimalpaar-Paradigma, MPP, -Evaluierungen von Sprachmodellen nutzen relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P, 1, &gt; P, 2,.- SyntaxGym: 1. Kein Kunde ... hat Geld ausgegeben. 2. *Der Kunde ... hat Geld ausgegeben. P, 1.any, ≥ P, 2.any,.- Crows: 1. Frauen sind schrecklich in der Handarbeit. 2. Männer sind schrecklich in der Handarbeit. P, 1, &gt; P, 2, Sind diese Urteile mit langer vorangegangener Kontextstabilität?</sample>
    <sample id="569">Minimalpaar-Paradigma, MPP, -Evaluierungen von Sprachmodellen nutzen relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P,1, &gt; P,2,.- SyntaxGym: 1. Kein Kunde ... hat etwas Geld ausgegeben. 2. *Der Kunde ... hat etwas Geld ausgegeben. P,1.any, ≥ P,2.any,.- Crows: 1. Frauen sind schrecklich in der Handarbeit. 2. Männer sind schrecklich in der Handarbeit. P,1, &gt; P,2, Sind diese Urteile mit langer vorangegangener Kontextstabilität?</sample>
    <sample id="570">Minimalpaar-Paradigma, MPP, -Evaluierungen von Sprachmodellen nutzen relative Unterschiede in den sequenziellen Wahrscheinlichkeiten, um das abstrakte Wissen von LMs zu bewerten:.- BLiMP: 1. Viele Menschen halfen sich selbst. 2. *Viele Menschen halfen ihr selbst. P, 1, &gt; P, 2,.- SyntaxGym: 1. Kein Kunde ... hat Geld ausgegeben. 2. *Der Kunde ... hat Geld ausgegeben. P, 1.any, &gt; P, 2.any,.- Crows: 1. Frauen sind schlecht in Handarbeit. 2. Männer sind schlecht in Handarbeit. P, 1, &gt; P, 2, Sind diese Urteile mit langer vorangegangener Kontextstabilität?</sample>
    <sample id="571">Der englische Inhalt lautet: "Testen Sie, ob MPP-Bewertungen als Funktion der Kontextlänge, strukturellen Übereinstimmung und Akzeptanz variieren."</sample>
    <sample id="572">Der englische Inhalt lautet: "Testen Sie, ob die MPP-Bewertungen als Funktion der Kontextlänge, strukturellen Übereinstimmung und Akzeptanz variieren."</sample>
    <sample id="573">Ansatz

Testen, ob MPP-Bewertungen als Funktion der Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren

Test-Suite: Subjekt-Verb-Übereinstimmung

akzeptabel

unakzeptabel

$P_{LM}\left(\begin{array}{c} \text { Prefix } \\ \text { Prefix } \end{array}\right) &gt; P_{LM}\left(\begin{array}{c} \text { Prefix } \\ \text { Prefix } \end{array}\right)$

sample

Räume der Kandidaten-Präfixe

Übereinstimmende

Subjekt-Verb-Übereinstimmung

$\square \square \ldots \square \square$

Nicht-übereinstimmende

Island-Effekte

$\star \star \ldots \star \star$

Filter-Loch

$\star \star \ldots \star \star$

Bindung

$\star \star \ldots \star \star$

Wikipedia

$\star \star \ldots \star \star$

BLIMP, Adjunkt-Insel

GPT2,</sample>
    <sample id="574">Ansatz. Testen, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren. Test-Suite: Subjekt-Verb-Übereinstimmung. Akzeptabel, unakzeptabel. P,LM, grün | Präfix &gt;? P,LM, rot | Präfix, Beispiel. Raum der Kandidaten-Präfixe. Übereinstimmende, unübereinstimmende Subjekt-Verb-Übereinstimmung. Akzeptabel, Übereinstimmend. Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkt? Was hat Aaron während des Reinigens des Museums gesagt? Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen lassen? Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkt? Was hat Aaron während des Reinigens des Museums gesagt? Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen lassen? BLIMP, Adjunkt-Insel. GPT2, OPT-Familie - 125M bis 6,7</sample>
    <sample id="575">Ansatz

Testen, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren

Test-Suite: Subjekt-Verb-Übereinstimmung

P,LM, grünes Quadrat | Präfix &gt;? P,LM, rotes Quadrat | Präfix

Raum der Kandidaten-Präfixe

Akzeptabel

Unakzeptabel

Beispiel

Gültige, Verb. Übereinstimmung

Un gültige, Verb. Übereinstimmung

Island-Effekte

Filter-Loch

Bindung

Wikipedia

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...

...</sample>
    <sample id="576">Der englische Inhalt lautet: "Testen Sie, ob MPP-Bewertungen als eine Funktion der Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren."</sample>
    <sample id="577">Der englische Inhalt lautet: "Testen Sie, ob MPP-Bewertungen als eine Funktion der Kontextlänge, strukturellen Übereinstimmung und Akzeptanz variieren."</sample>
    <sample id="578">Ansatz. Testen, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren. Test-Suite: Subjekt-Verb-Übereinstimmung. Akzeptabel vs. unakzeptabel. P,LM, grün | Präfix &gt;? P,LM, rot | Präfix. Raum der Kandidaten-Präfixe. Matched: Subjekt, Verb-Übereinstimmung. Mismatched: Island-Effekte, Filter-Loch, Bindung, Wikipedia. Wikipedia, Unabhängig. Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? * Wer könnte Rose von diesem Kunden vor dem Wiedereintritt fliehen? Ein Rose ist ein holziger, mehrjähriger Blühpflanze der Gattung Rosa. Es gibt über dreihundert Arten und Tausende von Sorten. Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? GPT2, OPT-Familie - 125M bis 6,7B.</sample>
    <sample id="579">Ansatz

Testen, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren

Test-Suite: Subjekt-Verb-Übereinstimmung

Akzeptabel

unakzeptabel

P,LM, grün, | Präfix, &gt;? P,LM, rot, | Präfix,

Muster

Rahmen des Kandidaten-Präfixraums

Übereinstimmende

Subjekt.-Verb.-Übereinstimmung

Mismatches

Island-Effekte

Filter-löcher

Bindung

Wikipedia

A rose ist ein holziger, mehrjähriger Blühpflanze der Gattung Rosa. Es gibt über dreihundert Arten und Tausende von Sorten.

Wer könnte Rose vor dem Wiederkommen zu diesem Kunden fliehen?

Wer könnte Rose von diesem Kunden vor dem Wiederkommen fliehen?

GPT2, OPT-Familie - 125M bis 6,7B</sample>
    <sample id="580">Der englische Inhalt lautet: "Testen Sie, ob die MPP-Bewertungen als Funktion der Kontextlänge, strukturellen Übereinstimmung und Akzeptanz variieren."</sample>
    <sample id="581">MPP-Bewertungen sind robust für beliebige Kontextlängen. Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/unpassende Struktur - von Längen bis zu 900 Tokens. BLIMP, OPT 6.7B. Prefix-Strategie: grün: Acc. (passend), lila: Unacc. (passend), orange: Acc. (unpassend), rosa: Unacc. (unpassend). Ein Rose ist ein holziger, mehrjähriger Blühpflanze der Gattung Rosa. Es gibt über dreihundert Arten und Tausende von Sorten. Wer könnte Rose vor dem Wiederkommen zu diesem Kunden fliehen? * Ein Rose ist ein holziger, mehrjähriger Blühpflanze der Gattung Rosa. Es gibt über dreihundert Arten und Tausende von Sorten. Wer könnte Rose vor dem Wiederkommen zu diesem Kunden fliehen?</sample>
    <sample id="582">MPP-Bewertungen sind robust für beliebige Kontextlängen. Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/verschiedene Struktur - von Längen bis zu 900 Tokens. BLIMP, OPT 6.7B. Prefix-Strategie: grün: Acc. (passend), lila: Unacc. (passend), orange: Acc. (verschieden), rosa: Unacc. (verschieden). Ein Beispiel: "Eine Rose ist ein immergrüner, blühender Pflanzen der Gattung Rosa. Es gibt über dreihundert Arten und Tausende von Sorten. Wer könnte Rose vor dem Wiederkommen zu diesem Kunden fliehen? *Eine Rose ist ein immergrüner, blühender Pflanzen der Gattung Rosa. Es gibt über dreihundert Arten und Tausende von Sorten. Wer könnte Rose vor dem Wiederkommen zu diesem Kunden fliehen?"</sample>
    <sample id="583">Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/senken die Bewertungsleistung. Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/unpassende Struktur - von Längen bis zu 900 Tokens. BLIMP, OPT 6.7B. Vorsatzstrategie: grün: Akk. (passend), lila: Unakk. (passend), orange: Akk. (unpassend), pink: Unakk. (unpassend). Es gibt eine Dokumentation über Musik, die Allison irritiert. Es gab keine legislativen Arbeitnehmer. Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? * Es gab eine Dokumentation über Musik, die Allison irritiert. Es gab keine legislativen Arbeitnehmer. Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? Es gab jede Dokumentation über Musik, die Allison irritiert. Es gab die meisten legislativen Arbeitnehmer. Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? * Es gab jede Dokument</sample>
    <sample id="584">Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/senken die Urteilsleistung Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/verschiedene Struktur - von Längen bis zu 900 Tokens BLIMP, OPT 6.7B Präfix-Strategie Akk. (passend) Unakk. (passend) Akk. (verschieden) Unakk. (verschieden) Es gab einen Dokumentarfilm über Musik, die Allison irritiert. Es gab keine legislativen Arbeitnehmer. Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? Es gab einen Dokumentarfilm über Musik, die Allison irritiert. Es gab keine legislativen Arbeitnehmer. Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? Es gab jeweils einen Dokumentarfilm über Musik, die Allison irritiert. Es gab die meisten legislativen Arbeitnehmer. Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? Es gab jeweils einen Dokumentarfilm über Musik,</sample>
    <sample id="585">Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/senken die Urteilsleistung Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/verschiedene Struktur - von Längen bis zu 900 Token BLIMP, OPT 6.7B Vorsatzstrategie Akk. (passend) Unakk. (passend) Akk. (verschieden) Unakk. (verschieden)</sample>
    <sample id="586">Akzeptable/unakzeptable MPP-Sätze mit passender Struktur haben den größten Einfluss auf das Modellleistung Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/mismatchte Struktur - von Längen bis zu 900 Tokens BLIMP, OPT 6.7B Vorsatzstrategie Akk. (passend) Unakk. (passend) Akk. (mismatcht) Unakk. (mismatcht) 3 2 1 2 3 Was könnte Jessica verkaufen, bevor sie diese Strahler bemerkt? Was hat Aaron gesagt, während er den Museum reinigte? Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? Was könnte Jessica verkaufen, bevor sie diese Strahler bemerkt? Was hat Aaron gesagt, während er den Museum reinigte? Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen? Was könnte Jessica verkaufen, bevor sie diese Strahler bemerkt? Was hat Aaron gesagt, während er den Museum reinigte? Wer könnte Rose vor dem</sample>
    <sample id="587">Akzeptable/unakzeptable MPP-Sätze mit passender Struktur haben den größten Einfluss auf das Modellleistung Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/unpassende Struktur - von Längen bis zu 900 Tokens BLIMP, OPT 6.7B Vorsatzstrategie Akk. (passend) Unakk. (passend) Akk. (unpassend) Unakk. (unpassend) 3 2 1 2 3 Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkt? Was hatte Aaron gesagt, während er das Museum reinigte? Wohin könnte Rose vor dem Wiedereintritt zu diesem Kunden fliehen? Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkt? Was hatte Aaron gesagt, während er das Museum reinigte? Wohin könnte Rose vor dem Wiedereintritt zu diesem Kunden fliehen? Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkt? Was hatte Aaron gesagt, während er das Museum rein</sample>
    <sample id="588">Akzeptable/unakzeptable MPP-Sätze mit passender Struktur haben den größten Einfluss auf das Modellleistung Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch - akzeptabel/unakzeptabel; passende/unpassende Struktur - von Längen bis zu 900 Tokens BLIMP, OPT 6.7B Vorsatzstrategie Akk. (passend) Unakk. (passend) Akk. (unpassend) Unakk. (unpassend) 3 Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkt? Was hat Aaron gesagt, während er den Museum reinigte? Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen lassen? 2 Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkt? Was hat Aaron gesagt, während er den Museum reinigte? Wer könnte Rose vor dem Wiedereintritt in diesen Kunden fliehen lassen? 1 Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkt? Was hat Aaron gesagt, während er den Museum reinigte? Wer könnte Rose vor</sample>
    <sample id="589">Warum beeinflussen passende Präfixe die Urteile von LM?Wir stören Kontextsätze auf Weise, die die relevanten Strukturen bewahrt, und fragen, ob Modelle ähnlich empfindlich auf diese Sätze sind.Prefix/Suffix Adverbien: "Jedoch, &lt;sent&gt;.".Lange Präfix Adverbien: "Zunächst und vor allem, &lt;sent&gt;.".Hinzufügen von Klammer: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;.".Zitat: "Gestern sagte X, &lt;sent&gt;."</sample>
    <sample id="590">Warum beeinflussen passende Präfixe die Urteile von LM?Wir stören Kontextsätze auf Weise, die die relevanten Strukturen bewahrt, und fragen, ob Modelle ähnlich empfindlich auf diese Sätze sind.Prefix/suffix Adverbien: "Jedoch, &lt;sent&gt;.".Lange Präfix-Adverbien: "Zunächst und vor allem, &lt;sent&gt;.".Hinzufügen von Klammer: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;.".Zitat: "Gestern, sagte X, &lt;sent&gt;."</sample>
    <sample id="591">Warum beeinflussen passende Präfixe die Urteile von LM?Wir stören Kontextsätze auf Weise, die die relevanten Strukturen bewahrt, und fragen, ob Modelle diese Sätze ähnlich empfindlich sind.Prefix/suffix Adverbien: "Jedoch, &lt;sent&gt;.".Lange Prefix Adverbien: "Zunächst und vor allem, &lt;sent&gt;.".Hinzufügen eines Klammerabsatzes: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;.".Zitat: "Gestern sagte X, &lt;sent&gt;."</sample>
    <sample id="592">Warum beeinflussen passende Präfixe die Urteile von LM?Wir stören Kontextsätze auf Weise, die die relevanten Strukturen bewahrt, und fragen, ob Modelle ähnlich empfindlich auf diese Sätze sind.Prefix/suffix Adverbien: "Jedoch, &lt;sent&gt;.".Lange Prefix Adverbien: "Zunächst und vor allem, &lt;sent&gt;.".Hinzufügen eines Nebensatzes: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;.".Zitat: "Gestern sagte X, &lt;sent&gt;.".Modelle sind ähnlich empfindlich auf gestörte Sätze.</sample>
    <sample id="593">Warum beeinflussen passende Präfixe die Urteile von LM?Wir stören Kontextsätze auf Weise, die die relevanten Strukturen bewahrt, und fragen, ob Modelle ähnlich empfindlich auf diese Sätze sind.Prefix/suffix Adverbien: "Jedoch, &lt;sent&gt;.".Lange Prefix Adverbien: "Zunächst und vor allem, &lt;sent&gt;.".Hinzufügen eines Klauselsatzes: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;.".Zitat: "Gestern sagte X, &lt;sent&gt;.".Modelle sind ähnlich empfindlich auf gestörte Sätze.</sample>
    <sample id="594">- Sprachmodelle sind sensibel gegenüber latenten syntaktischen/semantischen Merkmalen, die sich über Sätze verteilen.
- MPP-Bewertungen mit kurzen, einzelnen Satz-Eingaben fangen nicht vollständig das abstrakte Wissen von LMs ein.</sample>
    <sample id="595">- Sprachmodelle sind sensibel gegenüber latenten syntaktischen/semantischen Merkmalen, die sich über Sätze verteilen.
- MPP-Bewertungen mit kurzen, einzelnen Satz-Eingaben fangen nicht vollständig das abstrakte Wissen von LMs ein.</sample>
    <sample id="596">• Sprachmodelle sind sensibel gegenüber latenten syntaktischen/semantischen Merkmalen, die sich über Sätze verteilen.
• MPP-Evaluierungen mit kurzen, einzelnen Satz-Eingaben fangen nicht vollständig das abstrakte Wissen von LMs ein.</sample>
    <sample id="597">In the first step of the method, the input tokens are assigned to the Tag.</sample>
    <sample id="598">55.000 Skripte.</sample>
    <sample id="626">Oh, das ist eine gute Frage. Die beste Ausrichtungsmethode für DEplain ist Sent-LaBSE. Wenn du mehr darüber erfahren möchtest, frag einfach nach!</sample>
    <sample id="627">Es lindert den Annotierungsblock.</sample>
    <sample id="628">Nicht klar genug im Bild zu sehen. Kannst du mehr Details geben?</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde durch Sammeln von Reuters-Nachrichten aus dem Jahr 2020 und Annotieren nach den CoNLL-2003-Annotationsempfehlungen erstellt.</sample>
    <sample id="630">XSemPLR: Semantische Parsing in mehreren NaturSprachen und BedeutungsRepräsentationen. Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang.</sample>
    <sample id="631">Semantische Analyse ist eine Aufgabe, um eine semantische Darstellung der Benutzeranfragen zu erstellen, wie z.B. SQL und Lambda-Kalkül.Welche Länder in Europa haben mindestens drei Autohersteller?SELECT T1.country_name FROM countries AS T1 JOIN continents AS T2 ON T1.continent = T2.cont_id JOIN car_makers AS T3 ON T1.country_id = T3.country WHERE T2.continent = 'Europe' GROUP BY T1.country_name HAVING COUNT,*) &gt;= 3Welche Spieler haben weniger als drei Assists in einer Saison erreicht?，call SW.listValue， call SW.getProperty，， lambda s， call SW.filter， var s，， call SW.ensureNumericProperty， string num_assists，，， string &lt;， call SW.ensureNumericEntity， number 3 assist，，， call SW.domain， string player，，， string player，，Useranfrage und ihre entsprechende SQL, links, vs. Useranfrage und ihre entsprechende Lambda-Kalkül, rechts,</sample>
    <sample id="632">Kreuzsprachliche Semantikparsierung ist eine Aufgabe, um Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.</sample>
    <sample id="633">Kreuzsprachliche Semantikparsierung ist eine Aufgabe, um Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.</sample>
    <sample id="634">Kreuzsprachliche Semantikparsierung
• Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel:
○ Mangelnde Abdeckung bestimmter Naturlinguisten</sample>
    <sample id="635">Kreuzsprachliche Semantikparsierung
- Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel:
  - Mangelnde Abdeckung bestimmter natürlicher Sprachen</sample>
    <sample id="636">Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel: Mangelnde Abdeckung bei bestimmten Bedeutungsrepräsentationen.</sample>
    <sample id="637">Kreuzsprachliche Semantikparsierung
• Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel:
○ Mangelnde Abdeckung bestimmter Bedeutungsrepräsentationen
Englisch
Deutsch
Chinesisch
Neurale Modelle
SQL
Lambda
FunQL</sample>
    <sample id="638">Kreuzsprachliche Semantikparsierung
• Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel:
○ Mangelnde Abdeckung bei bestimmten neuronalen Modellen</sample>
    <sample id="639">Wir stellen einen einheitlichen Datensatz XSemPLR für multilingualen semantischen Parsing in verschiedenen natürlichen Sprachen und Bedeutungsrepräsentationen bereit. Er enthält: 9 Datensätze in verschiedenen Domänen, 5 semantische Parsing Aufgaben, 8 Bedeutungsrepräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="640">Wir stellen einen einheitlichen Datensatz XSemPLR für die multilinguale semantische Parsing in verschiedenen natürlichen Sprachen und Bedeutungsrepräsentationen bereit. Er enthält: 9 Datensätze in verschiedenen Domänen, 5 semantische Parsing Aufgaben, 8 Bedeutungsrepräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="641">Experiment-EinstellungenWir berücksichtigen sechs Einstellungen für die Ausbildung und Bewertung.Translate-Test: Verwenden Sie die Google Translate-API, um die Quelle ins Zielgebiet zu übersetzen. Danach verwenden Sie einen monolingualen Modell zur Ausbildung und Bewertung.Training.Inference.German Translate API English English Model SQL</sample>
    <sample id="642">Experiment-EinstellungenWir berücksichtigen die sechs Einstellungen für Training und Evaluierung.Translate-Test: Verwenden Sie die Google Translate-API, um die Quelle ins Zielgebiet zu übersetzen. Dann verwenden Sie einen monolingualen Modell für das Trainieren und Evaluieren.Training.Inference.German Translate API English English Model SQL</sample>
    <sample id="643">Experiment-EinstellungenWir berücksichtigen die sechs Einstellungen für Training und Evaluierung.Translate-Test: Verwenden Sie die Google Translate-API, um die Quelle ins Zielgebiet zu übersetzen. Dann verwenden Sie einen monolingualen Modell für das Trainieren und Evaluieren.Training.Inference.</sample>
    <sample id="644">Experiment-Einstellungen Wir berücksichtigen sechs Einstellungen für die Ausbildung und Bewertung. Monolingual-Modell: Quellsprache ist dieselbe wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch die Monolingual-Few-shot-Einstellung, indem wir monolinguale Modelle mit nur 10% Trainingsdaten ausbilden. Ausbildung German, Few-shot, German-Modell, SQL Inferenz German, German-Modell, SQL</sample>
    <sample id="645">Experiment-EinstellungenWir berücksichtigen sechs Einstellungen für die Ausbildung und Bewertung.Monolingual-Modell: Quellsprache ist dieselbe wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch die Monolingual-Few-shot-Einstellung, indem wir monolinguale Modelle mit nur 10% Trainingsdaten ausbilden.TrainingGerman, Few-shot, German-Modell, SQL.InferenceGerman, German-Modell, SQL.</sample>
    <sample id="646">Experiment-Einstellungen Wir berücksichtigen sechs Einstellungen für die Ausbildung und Bewertung. Monolingual-Modell: Quellsprache ist dieselbe wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch die Monolingual-Few-shot-Einstellung, indem wir monolinguale Modelle mit nur 10% Trainingsdaten ausbilden. Ausbildung German, Few-shot, German-Modell SQL Inferenz German German-Modell SQL</sample>
    <sample id="647">Experiment-Einstellungen Wir berücksichtigen die sechs Einstellungen für die Ausbildung und Bewertung. Mehrsprachiges Modell: Trainiere ein mehrsprachiges Modell für alle Sprachen. Ausbildung German, English, Chinese Mehrsprachiges Modell SQL Inferenz German Mehrsprachiges Modell SQL</sample>
    <sample id="648">Experiment-EinstellungenWir berücksichtigen die sechs Einstellungen für Training und Evaluierung.Multilingual-Modell: Trainiere ein multilinguales Modell für alle Sprachen.TrainingDeutsch, Englisch, ChinesischMultilingual-ModellSQLInferenceDeutschMultilingual-ModellSQL</sample>
    <sample id="649">Experiment-EinstellungenWir berücksichtigen die sechs Einstellungen für die Ausbildung und Bewertung.Multilingual-Modell: Trainiere ein multilinguales Modell für alle Sprachen.AusbildungDeutsch, Englisch, ChinesischMultilingual-ModellSQLInfereenzDeutschMultilingual-ModellSQL</sample>
    <sample id="650">Experiment-Einstellungen Wir berücksichtigen sechs Einstellungen für die Ausbildung und Bewertung. Kreuzsprachiges Zero-Shot/Few-Shot-Transfer: Ausbildung an einem Quellsprache und Transfer zu einem anderen Sprache. Ausbildung Englisch Oder Englisch Deutsches Few-Shot Multilingual-Modell SQL Inferenz Deutsches Multilingual-Modell SQL</sample>
    <sample id="651">Experiment-Einstellungen Wir berücksichtigen die sechs Einstellungen für die Ausbildung und Bewertung. Kreuzsprachiges Zero-Shot/Few-Shot-Transfer: Trainieren auf einer QuellSprache und übertragen auf eine andere Sprache. Ausbildung Englisch Oder Englisch Deutsches Few-Shot Multilingual-Modell SQL Inferenz Deutsches Multilingual-Modell SQL</sample>
    <sample id="652">Analyse des Monolingualen

Wir evaluieren zwei Gruppen von Modellen im Monolingualen Setting
- Enc-PTR: Multilinguale Prädtrainierte Encoder mit Pointer-basierten Decoder
  - XLM-R + PTR, mBERT + PTR
- Enc-Dec: Multilinguale Prädtrainierte Encoder-Decoder Modelle
  - mBART, mT5

Wir haben festgestellt, dass Enc-Dec, mT5, die beste Leistung auf allen Datensätzen erzielt!</sample>
    <sample id="653">Analyse des Monolingualen

- Wir evaluieren zwei Gruppen von Modellen im Monolingualen Setting
  - Enc-PTR: Multilinguale Vorkonditionierte Encoder mit Pointer-basierten Decoder
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilinguale Vorkonditionierte Encoder-Decoder Modelle
    - mBART, mT5
- Wir haben festgestellt, dass Enc-Dec, mT5, die beste Leistung auf allen Datensätzen erzielt!</sample>
    <sample id="654">Analyse des Monolingualen

Wir evaluieren zwei Gruppen von Modellen im Monolingualen Setting
- Enc-PTR: Multilinguale Vorkonditionierte Encoder mit Pointer-basierten Decoder
  - XLM-R + PTR, mBERT + PTR
- Enc-Dec: Multilinguale Vorkonditionierte Encoder-Decoder Modelle
  - mBART, mT5

Wir haben festgestellt, dass Enc-Dec, mT5, die beste Leistung auf allen Datensätzen erzielt!</sample>
    <sample id="655">Analyse des Monolingualen

Wir evaluieren zwei Gruppen von Modellen im Monolingualen Setting

- Enc-PTR: Multilinguale Vorkonditionierte Encoder mit Pointer-basierten Decoder
  - XLM-R + PTR, mBERT + PTR
- Enc-Dec: Multilinguale Vorkonditionierte Encoder-Decoder Modelle
  - mBART, mT5

Wir haben festgestellt, dass Enc-Dec, mT5, die beste Leistung auf allen Datensätzen erzielt!</sample>
    <sample id="656">Analyse des multilingualen Trainings
- Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting
  - Enc-Dec/Enc-PTR, mT5/XLM-R, kann durch das Trainieren in einer Mischung aus verschiedenen Sprachen verbessert werden.
Tabelle:
Monolingual
XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 58.16
mT5 53.15 74.26 50.73 91.65 66.29 30.15 65.16 81.83 10.29
Multilingual
XLM-R+PTR 39.72 71.35 40.20 85.91 61.03 30.79 61.82 81.68</sample>
    <sample id="657">Analyse des multilingualen Trainings
- Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting
  - Enc-Dec/Enc-PTR, mT5/XLM-R, kann durch das Trainieren in einer Mischung aus verschiedenen Sprachen verbessert werden.
Tabelle:
Monolingual
XLM-R+PTR 31.31 71.41 47.30 85.17 59.10 23.53 62.37 80.36 7.69 52.03 58.16
mT5 53.15 74.26 50.73 91.65 66.29 30.15 65.16 81.83 10.29 58.16
Multilingual
XLM-R+PTR 39.72 71.35 40.20 85.91 61.03 30.79 61.82</sample>
    <sample id="658">Analyse des multilingualen Trainings
- Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting
  - Die meisten wichtigen NLs können Leistungsgewinne erzielen, außer dass die Leistung der Englischen Sprache in 7 Datensätzen abnimmt und in 3 Datensätzen steigt. Dies ist als "Fluch der Multilingualität" bekannt.</sample>
    <sample id="659">Analyse des multilingualen Trainings
- Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting
  - Die meisten wichtigen NLs können Leistungsgewinne erzielen, außer dass die Leistung der Englischen Sprache in 7 Datensätzen abnimmt und in 3 Datensätzen zunimmt. Dies ist als "Fluch der Multilingualität" bekannt.</sample>
    <sample id="660">Kreuzsprachliche Leistungslücke
• Blaue Linie: Kreuzsprachliche Few-shot-Transfer
• Orange Linie: Kreuzsprachliche Zero-shot-Transfer
• Grüne Linie: Monolinguale Einstellung</sample>
    <sample id="661">Kreuzsprachliche Leistungslücke
• Blaue Linie: Kreuzsprachliche Few-shot-Transfer
• Orange Linie: Kreuzsprachliche Zero-shot-Transfer
• Grüne Linie: Monolinguale Einstellung</sample>
    <sample id="662">Kreuzsprachleistungsabstand

• grün - orange Für den zero-shot-Einstellungsfall ist der Kreuzsprachtransferleistungsabstand signifikant
• blau - orange Für den few-shot-Einstellungsfall wird der Transferabstand schnell verkürzt

MTOP
Schema2QA
Overnight
NLMaps
MCWQ
ATIS
Spider
Geoquery
Geoquery/lamb
Geoquery/prolog
Geoquery/funql
Geoquery/sql
Geoquery/lamb
Geoquery/prolog
Geoquery/funql
Geoquery/sql
Geoquery/lamb
Geoquery/prolog
Geoquery/funql
Geoquery/sql
Geoquery/lamb
Geoquery/prolog
Geoquery/funql
Geoquery/sql
Geoquery/lamb
Geoquery/prolog
Geoquery/funql
Geoquery/sql
Geoquery/lamb
Geoquery/prolog
Geoquery/funql
Geoquery/sql
Geoquery/lamb
Geoquery/prolog
Geoquery/funql
Geoquery/sql
Geoquery/lamb
Geoquery/prolog
Geoquery/funql
Geoquery/sql
Geoquery/lamb</sample>
    <sample id="663">- Enc-Dec, mT5, übertrifft die bisherigen Arbeiten oder erreicht vergleichbare Ergebnisse.
- Die Vorschulung auf englischem NLP kann die Leistung der Few-Shot-Lernung auf Zielsprachen erheblich verbessern.
- Multilinguale LLMs, Codex &amp; BLOOM, sind noch unzureichend für die krosssprachige semantische Parsing-Aufgaben.
- Chinesische Transfer-Lernung und englische monolinguale Trainings, En -&gt; En, haben den größten Leistungssprung, während Deutsch normalerweise den kleinsten hat.
- FunQL übertrifft die anderen drei Bedeutungsrepräsentationen, und SQL hat die schlechteste Leistung.</sample>
    <sample id="664">- Enc-Dec, mT5, übertrifft frühere Arbeiten oder erreicht vergleichbare Ergebnisse.
- Die Vorschulbildung auf Englisch kann die Leistung der Few-Shot-Lernung auf Zielsprachen erheblich verbessern.
- Multilinguale LLMs, Codex &amp; BLOOM, sind noch unzureichend für die krosssprachige semantische Parsing-Aufgaben.
- Chinesische Transfer-Lernung und englische monolinguale Ausbildung, En -&gt; En, haben den größten Leistungssprung, während Deutsch normalerweise den kleinsten hat.
- FunQL übertrifft die anderen drei Bedeutungsrepräsentationen, und SQL hat die schlechteste Leistung.</sample>
    <sample id="665">Zusammenfassung
- Wir haben XSemPLR erstellt, einen einheitlichen Benchmark für die multilinguale semantische Analyse mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen.
- Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen multilingualer Sprachmodelle durch.
- Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Ausbildung die beste Leistung erzielt, während multilingual ausgerichtete LLMs noch nicht in der Lage sind, multilinguale semantische Analyseaufgaben auszuführen. Zudem ist der Leistungsdifferenz zwischen monolingualer Ausbildung und multilingualem Transfer-Lernen immer noch erheblich.</sample>
    <sample id="666">Abschluss - Wir haben XSemPLR erstellt, einen einheitlichen Benchmark für die multilinguale semantische Analyse mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen. - Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen multilingualer Sprachmodelle durch. - Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Ausbildung die beste Leistung erzielt, während bemerkenswerte multilinguale LLMs noch unzureichend für multilinguale semantische Analyseaufgaben sind. Zudem ist der Leistungssprung zwischen monolingualer Ausbildung und multilingualem Transfer-Lernen immer noch signifikant. Links Herzlich willkommen, um unsere Arbeit und den Code zu besuchen! - Papier-Link: https://arxiv.org/pdf/2306.04085.pdf - Code-Link: https://github.com/psunlpgroup/xsemplr</sample>
    <sample id="667">Parameter-basierte Wasserzeichen, Lexikalische Wasserzeichen, Backdoor-basierte Wasserzeichen und Adversarial-basierte Wasserzeichen.</sample>
    <sample id="668">Nein, sie sind noch nicht ausreichend für CLSP. Wenn du noch mehr Fragen hast, lass es mich wissen!</sample>
    <sample id="695">Die Methode löst die Mehrdeutigkeit der Permutationen, indem sie die Permutation in der Trainingphase induziert. So kann sie die richtige Anordnung lernen. Wenn du mehr darüber wissen möchtest, frag einfach!</sample>
    <sample id="696">Nicht im Bild.</sample>
    <sample id="697">Der Referent ist Yanis Labrak.</sample>
    <sample id="698">Koustuv Sinha.</sample>
    <sample id="699">Myra Cheng.</sample>
    <sample id="700">Tropikalismus bedeutet, dass man bestimmte Gruppen nur durch ihre Identität definiert. Also, wenn man von kulturellem, traditionellem, stolzem und exotischem Erzählen spricht, das für markierte Gruppen verwendet wird. Das ist eine Art von Tropikalismus. Wenn du noch Fragen hast, lass es mich wissen!</sample>
    <sample id="701">Die Autoren haben die Beschreibungen der Zielgruppen durch essentielle Erzählungen erstellt. Sie haben Wörter wie Kultur, Tradition, Stolz und Exotisch für markierte Gruppen verwendet.</sample>
    <sample id="702">In dieser Arbeit wurde P-CXMI zur Messung der Kontextnutzung verwendet.</sample>
    <sample id="703">DrBERT ist von Scratch, ChuBERT auch. Der Unterschied ist, dass DrBERT mit NACHOSlarge korpus trainiert wird, während ChuBERT mit NBDWsmall korpus trainiert wird.</sample>
    <sample id="751">Drei.</sample>
    <sample id="752">Iteratives Transfer Learning ist ein Ansatz in der maschinellen Lernen, bei dem ein Modell zuerst mit einem großen Datensatz trainiert wird, dann aber nach und nach mit neuen, feineren Daten weitertrainiert wird. So kann das Modell seine Leistung stufenweise verbessern. Wenn du mehr darüber wissen möchtest, frag einfach!</sample>
    <sample id="753">Das Ziel des Datensatzes ist, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen.</sample>
    <sample id="754">Ich muss leider sagen, dass ich keine genauen Informationen zu dieser Frage habe. Es gibt sicherlich Methoden, aber ohne spezifische Details oder Quellen ist es schwierig, eine genaue Antwort zu geben. Wenn du mehr über die Sicherheit von EaaS oder ähnliche Themen erfahren möchtest, könnte ich dir vielleicht weiterhelfen.</sample>
    <sample id="755">Drei. Sara Papi, Matteo Negri und Marco Turchi. Wenn du noch mehr über die Arbeit wissen möchtest, frag einfach.</sample>
    <sample id="756">Nicht bekannt.</sample>
    <sample id="757">Sebastian Santy und Jenny T. Liang gehören der University of Washington an, Ronan Le Bras und Maarten Sap der Carnegie Mellon University, Katharina Reinecke der University of Washington.</sample>
    <sample id="758">I saw Bart and Lisa; Homer came and sneezed.</sample>
    <sample id="759">Nichts zu sehen.</sample>
    <sample id="760">Weil die Modelle ihre Abstraktwissen über das gesamte Kontextfenster bewerten müssen.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="762">Nein.</sample>
    <sample id="763">Leider ist in dem Bild nichts über die verwendeten MT-Metriken für die Bewertung zu sehen. Du könntest versuchen, den Quelltext oder eine andere Quelle zu prüfen, um diese Informationen zu finden.</sample>
    <sample id="764">Nicht direkt. Die Regression hat eher einen allgemeinen Einfluss auf die Generalisierung. Wenn du mehr dazu wissen möchtest, frag einfach nach.</sample>
    <sample id="765">Nichts im Text.</sample>
    <sample id="766">Hmm, ich bin mir nicht sicher, ob ich die genaue Antwort auf deine Frage habe. Kannst du mir vielleicht mehr Details geben?</sample>
    <sample id="767">Wir verwenden das RoBERTA-base Modell für das Transferlernen.</sample>
    <sample id="768">Leider ist im Bild nichts über die aktuellen Testsets für die PaLM-Fähigkeiten zu sehen. Du könntest versuchen, auf der Website von Google oder bei der Quelle, von der du das Bild hast, nachzuschauen.</sample>
    <sample id="769">Die Autoren haben drei Empfehlungen vorgeschlagen. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="770">Der Gewinn der vorgeschlagenen Methode gegenüber der stärksten Baseline beträgt 15.55%. Wenn du noch weitere Fragen hast, lass es mich wissen!</sample>
    <sample id="771">Der Referent ist Shuheng Liu und Alan Ritter.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz können als Benchmark verwendet werden. Wenn du mehr darüber wissen möchtest, frag einfach nach.</sample>
    <sample id="773">In der Arbeit werden mit fünf kleineren Modellen experimentiert.</sample>
    <sample id="774">Das OFA-Modell wird als Basismodell verwendet.</sample>
    <sample id="833">Ich weiß es nicht. Es gibt keine Angaben dazu, an welcher Universität die Autoren angehören. Du könntest versuchen, das Original zu googeln oder die Präsentation weiter zu studieren.</sample>
    <sample id="834">Die Autoren gehören der Stony Brook University an.</sample>
    <sample id="835">Leider ist in dem gegebenen Text nichts über untersuchte Sprachpaare erwähnt. Möchtest du noch etwas anderes wissen?</sample>
    <sample id="836">Shangbin Feng.</sample>
    <sample id="837">Die Modelle, die untersucht wurden, sind DEplain-APA, DEplain-web, DEplain-APA+web und src2src-baseline.</sample>
    <sample id="838">53 Aufgaben werden für Training und Tests verwendet.</sample>
    <sample id="839">Drei.</sample>
    <sample id="840">Die Autoren haben an AG News, MIND, SST2 und Enron Spam experimentiert.</sample>
    <sample id="876">NACHOS ist ein Modell im Kontext des Language Modeling in Healthcare. Es wird im Zusammenhang mit der Auswertung von 13 Modellen auf 11 Aufgaben diskutiert.</sample>
    <sample id="877">David Vilar Torres.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse. 516 von 1000 Sätzen zeigen eine Differenz von mehr als 1 BLEURT-Punkt, und die Differenz kann bis zu 40 BLEURT-Punkten betragen. Wenn du noch Fragen hast, lass sie gerne da.</sample>
    <sample id="879">Die Autoren gehören an die Carnegie Mellon University.</sample>
    <sample id="880">Leider steht in dem Bild nichts über die 5 Anweisungen der Expert*innen. Vielleicht kannst du mehr Kontext oder eine andere Quelle haben?</sample>
    <sample id="881">Sie schlagen vor, Modelle mit dem KITMUS Test Suite zu testen. Es gibt einen Dataset für die Evaluierung der Wissensintegration und eine Coreference Resolution Aufgabe, um die Fähigkeit zu prüfen, auf prätrainierte und inferenzzeitliche Wissen zurückzugreifen. Dann gibt es Experimente mit menschlichen Studienteilnehmern und Coreference Resolution Modellen.</sample>
    <sample id="882">Können Sie mir das übersetzen?</sample>
    <sample id="883">PaLM: Pfadwege Sprachmodell
- Chowdery et al., 2022
  arXiv:2204.02311.
- 540 Milliarden Parameter.
- Auf 780 Milliarden Token trainiert.
- Dicht aktiviert.
- 6144 TPU v4 Chips.
- SOTA in Hunderten von LMU und Generierung Benchmarks.</sample>
    <sample id="884">PaLM: Pfadweg Sprachmodell
- Chowdery et al., 2022
  arXiv:2204.02311.
- 540 Milliarden Parameter.
- Auf 780 Milliarden Token trainiert.
- Dicht aktiviert.
- 6144 TPU v4 Chips.
- SOTA in Hunderten von LMU und Generation-Benchmarks.</sample>
    <sample id="885">Unsere Beiträge:• Erstes systematisches Studium von LLM-Prompting für MT.○ Für den Kandidatenpool sowie die Selektionsstrategie.• Übersetzungsfähigkeiten mit den besten Praktiken der MT-Gemeinschaft bewerten:○ Neueste Testsets, um Test/Train-Überlappung und Übertrainieren auf Evaluierungsdaten zu vermeiden.○ Vergleich mit den neuesten WMT-Beiträgen, SOTA-Systeme verwenden neueste Trainingsdaten.○ SOTA-Übersetzungsmetriken, bessere Korrelation mit menschlichen Urteilen.○ Expertenbasierte menschliche Bewertung, robuster als Crowd Workers.○ Empfehlungen für Prompt-Selektionsstrategien.</sample>
    <sample id="886">Unsere Beiträge:• Erstes systematisches Studium von LLM-Prompting für MT.○ Für den Kandidatenpool sowie die Selektionsstrategie.• Übersetzungsfähigkeiten mit den besten Praktiken der MT-Gemeinschaft bewerten:○ Neueste Testsets, um Test/Train-Überlappung und Übertrainieren auf Evaluierungsdaten zu vermeiden.○ Vergleich mit den neuesten WMT-Beiträgen, SOTA-Systeme verwenden neueste Trainingsdaten.○ SOTA MT-Metriken, bessere Korrelation mit menschlichen Urteilen.○ Expertenbasierte menschliche Bewertung, robuster als Crowd Workers.○ Empfehlungen für Prompt-Selektionsstrategien.</sample>
    <sample id="887">Unsere Beiträge:• Erstes systematisches Studium von LLM-Prompting für MT.○ Für den Kandidatenpool sowie die Auswahlstrategie.• Übersetzungsfähigkeiten mit den besten Praktiken der MT-Gemeinschaft bewerten:○ Neueste Testsets, um Test/Train-Überlappung und Übertrainieren auf Evaluierungsdaten zu vermeiden.○ Vergleich mit den neuesten WMT-Beiträgen, SOTA-Systeme verwenden neueste Trainingsdaten.○ SOTA-Übersetzungsmaße, bessere Korrelation mit menschlichen Urteilen.○ Expertenbasierte menschliche Bewertung, robuster als Crowd Workers.○ Empfehlungen für Prompt-Auswahlstrategien.</sample>
    <sample id="888">Unsere Beiträge: Erste systematische Studie zur Prompting von LLM für MT. - Für den Kandidatenpool und die Auswahlstrategie. Evaluierung der Übersetzungsfähigkeiten mit den besten Praktiken der MT-Gemeinschaft: - Neueste Testsets, um Test/Train-Überlappung und Übertrainieren auf Evaluierungsdaten zu vermeiden. - Vergleich mit den neuesten WMT-Beiträgen, SOTA-Systeme verwenden neueste Trainingsdaten. - SOTA MT-Metriken, bessere Korrelation mit menschlichen Urteilen. - Expertenbasierte menschliche Evaluierung, robuster als Crowd Workers. Empfehlungen für Prompt-Selektionsstrategien.</sample>
    <sample id="889">Prompte haben einen großen Einfluss auf die Übersetzungsqualität. Zwei zufällige Prompte werden für jede Satz ausgewählt. Für jede Satz-Prompt-Paar wird BLEURT berechnet. Die Mehrheit der Sätze, 516 von 1000, zeigt eine Differenz von mehr als 1 BLEURT-Punkt. Die Differenz kann bis zu 40 BLEURT-Punkten betragen!</sample>
    <sample id="890">Prompte haben einen großen Einfluss auf die Übersetzungsqualität. Zwei zufällige Prompte für jede Satz auswählen. BLEURT für jedes Satz-Prompt-Paar berechnen. Die Mehrheit der Sätze, 516 von 1000, zeigen eine Differenz von mehr als 1 BLEURT-Punkt. Die Differenz kann bis zu 40 BLEURT-Punkten betragen!</sample>
    <sample id="891">Prompte haben einen großen Einfluss auf die Übersetzungsqualität. Zwei zufällige Prompte für jede Satz auswählen. BLEURT für jedes Satz-Prompt-Paar berechnen. Die Mehrheit der Sätze, 516 von 1000, zeigen eine Differenz von mehr als 1 BLEURT-Punkt. Die Differenz kann bis zu 40 BLEURT-Punkten betragen!</sample>
    <sample id="892">Ein Zivilist alarmierte die Polizei, die mit mehreren Streifen anrückte.</sample>
    <sample id="893">Ein Zivilist alarmierte die Polizei, die mit mehreren Streifen anrückte.</sample>
    <sample id="894">Ein Zivilist alarmierte die Polizei, die mit mehreren Streifen anrückte.</sample>
    <sample id="895">Ein Zivilist alarmierte die Polizei, die mit mehreren Streifen anrückte.</sample>
    <sample id="896">Ein Zivilist alarmierte die Polizei, die mit mehreren Streifen anrückte.</sample>
    <sample id="897">Experimentelle Ergebnisse: - Beispielqualität ist wichtiger als Ähnlichkeit zur Quellsatz. - Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. - PaLM ist nahe bei Google Translate. Einblicke aus MQM: - Fluenzie von PaLM vergleichbar mit SOTA. - Genauigkeitsscores sind generell niedriger. - Dominiert durch "Genauigkeit/Überschreibung". - "Stil/Unangenehm" ist generell niedriger für PaLM.</sample>
    <sample id="898">Experimentelle Ergebnisse: - Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz. - Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. - PaLM ist nahe an Google Translate. Einblicke aus MQM: - Fluenzie von PaLM ist vergleichbar mit SOTA. - Genauigkeitsscores sind generell niedriger. - Dominiert durch "Genauigkeit/Überschreibung". - "Stil/Unangenehm" ist generell niedriger für PaLM.</sample>
    <sample id="899">Experimentelle Ergebnisse: - Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz. - Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. - PaLM ist nahe an Google Translate. Einblicke aus MQM: - Fluenzie von PaLM vergleichbar mit SOTA. - Genauigkeitsscores sind generell niedriger. - Dominiert durch "Genauigkeit/Überschreibung". - "Stil/Unbeholfen" ist generell niedriger für PaLM.</sample>
    <sample id="900">Experimentelle Ergebnisse: - Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz. - Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. - PaLM ist nahe an Google Translate. Einblicke aus MQM: - Fluenzie von PaLM ist vergleichbar mit SOTA. - Genauigkeitsscores sind generell niedriger. - Dominiert durch "Genauigkeit/Überschreibung". - "Stil/Unbeholfen" ist generell niedriger für PaLM.</sample>
    <sample id="901">Experimentelle Ergebnisse: - Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz. - Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. - PaLM ist nahe an Google Translate. Einblicke aus MQM: - Fluenzie von PaLM ist vergleichbar mit SOTA. - Genauigkeitsscores sind generell niedriger. - Dominiert durch "Genauigkeit/Überschreibung". - "Stil/Unangenehm" ist generell niedriger für PaLM.</sample>
    <sample id="902">Experimentelle Ergebnisse: - Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz. - Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. - PaLM ist fast so gut wie Google Translate. Einblicke aus MQM: - Die Fluenz von PaLM ist vergleichbar mit SOTA. - Genauigkeitsscores sind im Allgemeinen niedriger. - Dominiert durch "Genauigkeit/Überschreibung". - "Stil/Unangenehm" ist für PaLM im Allgemeinen niedriger.</sample>
    <sample id="903">Experimentelle Ergebnisse: - Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz. - Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. - PaLM ist nahe an Google Translate. Einblicke aus MQM: - Fluenzie von PaLM ist vergleichbar mit SOTA. - Genauigkeitswerte sind generell niedriger. - Dominiert durch "Genauigkeit/Überschreibung". - "Stil/Unbeholfen" ist generell niedriger für PaLM.</sample>
    <sample id="904">Experimentelle Ergebnisse: - Beispielqualität ist wichtiger als Ähnlichkeit zur Quellsatz. - Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. - PaLM ist nahe bei Google Translate. Einblicke aus MQM: - Fluenzie von PaLM vergleichbar mit SOTA. - Genauigkeitsscores sind generell niedriger. - Dominiert durch "Genauigkeit/Überschreibung". - "Stil/Unbeholfen" ist generell niedriger für PaLM.</sample>
    <sample id="905">Experimentelle Ergebnisse: - Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz. - Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil. - PaLM ist nahe an Google Translate. Einblicke aus MQM: - Fluenzie von PaLM vergleichbar mit SOTA. - Genauigkeitsscores sind generell niedriger. - Dominiert durch "Genauigkeit/Überschreibung". - "Stil/Unangenehm" ist generell niedriger für PaLM.</sample>
    <sample id="906">Danke.</sample>
    <sample id="907">Schwächer als du denkst. Ein kritischer Blick auf schwach überwachte Lernung.</sample>
    <sample id="908">Schwächer als du denkst. Ein kritischer Blick auf schwach überwachte Lernung.</sample>
    <sample id="909">Warum schwach überwachtes Lernen?• Schwache Überwachung lindert den Annotierungsblock. • Aber schwache Beschriftungen sind laut! ○ Lauter Beschriftungen schädigen die Generalisierung. • Schwach überwachtes Lernen, WSL, ○ Trainiere Modelle, die gut generalisieren, obwohl sie mit lautiger Daten trainiert werden.</sample>
    <sample id="910">Warum schwach überwachtes Lernen?• Schwache Überwachung lindert den Annotierungs-Schnellverkehrsproblemen.
• Aber schwache Labels sind unruhig!○ Noise-Memorierung schadet der Generalisierung.
• Schwach überwachtes Lernen, WSL,○ Trainiere Modelle, die gut generalisieren, obwohl sie mit unruhigem Datenmaterial trainiert werden.</sample>
    <sample id="911">Warum schwach überwachtes Lernen?• Schwache Überwachung lindert den Annotierungs-Schnellverkehrsproblemen.
• Aber schwache Etiketten sind laut!○ Lauterkeits-Memorierung schadet der Generalisierung.
• Schwach überwachtes Lernen, WSL,○ Trainiere Modelle, die gut generalisieren, obwohl sie mit lautem Datenmaterial trainiert werden.</sample>
    <sample id="912">Warum schwach überwachtes Lernen?• Schwache Überwachung lindert den Annotierungs-Schnellverkehrsproblemen.
• Aber schwache Etiketten sind laut!○ Lauterkeits-Memorierung schadet der Generalisierung.
• Schwach überwachtes Lernen, WSL,○ Trainiere Modelle, die gut generalisieren, obwohl sie mit lautem Datenmaterial trainiert werden.</sample>
    <sample id="913">Warum schwach überwachtes Lernen?• Schwache Überwachung lindert den Annotierungs-Schnellverkehrsproblemen. • Aber schwache Etiketten sind laut! ○ Lauter Memorisierung schadet der Generalisierung. • Schwach überwachtes Lernen, WSL, ○ Trainiere Modelle, die gut generalisieren, obwohl sie mit lautem Datenmaterial trainiert werden.</sample>
    <sample id="914">Ein gemeinsames Behauptung in jüngeren WSL Arbeiten

"Wir trainieren Modelle nur mit schwach überwachten Daten und erzielen eine Genauigkeit von XX%."</sample>
    <sample id="915">Ein gemeinsames Behauptung in jüngeren WSL Arbeiten

"Wir trainieren Modelle nur an schwach überwachten Daten und erzielen eine Genauigkeit von XX%."

Nebenlabeled Trainingsdaten, (unruhig)

Nebenlabeled Testdaten, (sauber)</sample>
    <sample id="916">Ein gemeinsames Behauptung in jüngeren WSL Arbeiten

"Wir trainieren Modelle nur mit schwach überwachten Daten und erreichen eine Genauigkeit von XX%."</sample>
    <sample id="917">Ein gemeinsames Behauptung in jüngeren WSL Arbeiten

"Wir trainieren Modelle nur mit schwach überwachten Daten und erzielen eine Genauigkeit von XX%."</sample>
    <sample id="918">Unsere Forschungsfragen

RQ1: Ist sauberes Validierungsdaten notwendig?

RQ2: Wie viele saubere Proben brauchen WSL-Ansätze?

RQ3: Wie kann man die verfügbaren sauberen Proben effizienter nutzen?</sample>
    <sample id="919">Unsere Forschungsfragen sind: RQ1: Ist sauberes Validierungsdaten notwendig? RQ2: Wie viele saubere Proben brauchen WSL-Ansätze? RQ3: Wie kann man die verfügbaren sauberen Proben effizienter nutzen?</sample>
    <sample id="920">RQ1 Hauptergebnisse Relative Leistungsverbesserung gegenüber schwachen Etiketten (%) FTw BOND COSINE MLC L2R Validierung auf schwachen Etiketten Orange Validierung ohne Validierung, zufällige Auswahl Lila Validierung auf sauberen Etiketten Grün</sample>
    <sample id="921">RQ1 Hauptergebnisse Relative Leistungsverbesserung gegenüber schwachen Etiketten (%) FT_w BOND COSINE MLC L2R Validierung auf schwachen Etiketten Orange Validierung ohne Validierung, zufällige Auswahl Lila Validierung auf sauberen Etiketten Grün</sample>
    <sample id="922">RQ1 Hauptergebnisse

Relative Leistungsverbesserung gegenüber schwachen Etiketten (%)</sample>
    <sample id="923">RQ1 Hauptergebnisse Relative Leistungsverbesserung gegenüber schwachen Etiketten (%) FTw BOND COSINE MLC L2R Validierung auf schwachen Etiketten Orange Validierung auf sauberen Etiketten Türkis Keine Validierung, zufällige Auswahl Lila</sample>
    <sample id="924">Hauptergebnisse

RQ1

Hauptergebnisse

→ Eine saubere Validierungsdatensatz ist unerlässlich.</sample>
    <sample id="925">RQ2 Hauptergebnisse
Main findings
RQ2
Hauptergebnisse
7</sample>
    <sample id="926">RQ2 Hauptergebnisse
- FT_w
- COSINE
- L2R
- BOND
- MLC
- Weak labels</sample>
    <sample id="927">Hauptergebnisse

WSL-Ansätze profitieren von mehr sauberen Validierungssamples!</sample>
    <sample id="928">RQ2 Hauptergebnisse

WSL-Ansätze profitieren von mehr sauberen Validierungssamples!</sample>
    <sample id="929">RQ2 Hauptergebnisse

WSL-Ansätze profitieren von mehr sauberen Validierungssamples!

Aber es ist sogar besser, sie für das Training zu verwenden, z.B. LoRA_c!</sample>
    <sample id="930">RQ3 Hauptergebnisse

N=10 saubere Proben pro Klasse

Genauigkeit/F1

Vor CFT

Nach CFT

N=30 saubere Proben pro Klasse

Genauigkeit/F1

Vor CFT

Nach CFT</sample>
    <sample id="931">RQ3 Hauptergebnisse

N=10 saubere Proben pro Klasse

Genauigkeit/F1

Vor CFT

Nach CFT

N=30 saubere Proben pro Klasse

Genauigkeit/F1

Vor CFT

Nach CFT</sample>
    <sample id="932">RQ3 Hauptergebnisse

N=10 saubere Proben pro Klasse

Genauigkeit/F1

Vor CFT

Nach CFT

N=30 saubere Proben pro Klasse

Genauigkeit/F1

Vor CFT

Nach CFT</sample>
    <sample id="933">Hauptergebnisse

N=10 saubere Proben pro Klasse

N=30 saubere Proben pro Klasse

→ Kontinuierliche Feinarbeitung, CFT, eliminiert Leistungsspalten zwischen WSL-Ansätzen.

→ Keine Notwendigkeit, komplizierte WSL-Methoden zu verwenden, FTw leistet gleich gut.</sample>
    <sample id="934">Abschluss

Neuere WSL-Ansätze
- Erfordern saubere Samples.
- Ihre Praktikabilität überschätzen.

Unsere Empfehlungen
- Berichten Sie die Modell-Auswahlkriterien.
- Verwenden Sie Few-shot-Lern-Ansätze als Baselines.
- Verwenden Sie immer kontinuierliche Feinarbeitung, CFT.</sample>
    <sample id="935">Abschluss

Neuere WSL-Ansätze
- Erfordern saubere Samples.
- Überbewerten ihre Praktikabilität. 😕

Unsere Empfehlungen
- Berichten Sie die Modell-Auswahlkriterien.
- Verwenden Sie Few-shot-Learning-Ansätze als Baselines.
- Wenden Sie stets kontinuierliche Feinarbeit, CFT, an.</sample>
    <sample id="936">Abschluss

Neuere WSL-Ansätze
- Erfordern saubere Samples.
- Überbewerten ihre Praktikabilität. 😕

Unsere Empfehlungen
- Berichten Sie die Modell-Auswahlkriterien.
- Verwenden Sie Few-shot-Lern-Ansätze als Baselines.
- Wenden Sie stets kontinuierliche Feinarbeit, CFT, an.</sample>
    <sample id="937">Fazit

Neuere WSL-Ansätze
- Erfordern saubere Samples.
- Ihre Praktikabilität überschätzen.

Unsere Empfehlungen
- Berichten Sie die Modell-Auswahlkriterien.
- Verwenden Sie Few-shot-Lern-Ansätze als Baselines.
- Verwenden Sie immer kontinuierliche Feinarbeitung, CFT.</sample>
    <sample id="938">Abschluss

Neuere WSL-Ansätze
- Erfordern saubere Samples.
- Überbewerten ihre Praktikabilität.

Unsere Empfehlungen
- Berichten Sie die Modell-Auswahlkriterien.
- Verwenden Sie Few-shot-Lern-Ansätze als Baselines.
- Verwenden Sie stets kontinuierliche Feinarbeitung, CFT.</sample>
    <sample id="939">Gängige Bewertungsmethoden für Dialogsysteme sind die Vergleichliche Beurteilung und die Likert-Bewertung. Wenn du mehr darüber wissen möchtest, frag einfach nach.</sample>
    <sample id="940">Fünf. Wenn du noch mehr über die Arbeit wissen möchtest, frag einfach.</sample>
    <sample id="941">Das Hintergrundwissen, das im Beispiel mit Servin und Kea benötigt wird, ist das Wissen, dass Servin ein Richter ist.</sample>
    <sample id="942">Ja, der Code ist verfügbar. Du kannst ihn auf GitHub unter mpoemsl/kitmus finden.</sample>
    <sample id="943">Nein.</sample>
    <sample id="944">Prefix/suffix adverbs, long prefix adverbs, add clause und quote.</sample>
    <sample id="945">Eine dimensionale Bewertung bezieht sich auf die Bewertung von verschiedenen Aspekten oder Dimensionen einer Sache. Hier wird die Qualität des Dialogs in Aspekte wie Relevanz, Konsistenz und emotionale Verständigung unterteilt. So kann man besser verstehen, wie gut ein Dialog ist. Wenn du noch Fragen hast, lass es mich wissen!</sample>
    <sample id="946">Die Autoren gehören an die University of Science and Technology of China, Microsoft Research Asia, Beijing Jiaotong University, Sony AI und Microsoft STC Asia.</sample>
    <sample id="947">Wenn es um die Genauigkeit und Klarheit der Übersetzung geht. Also, wenn man die Bedeutung der Wörter und der Struktur im Satz beachten muss. Du hast noch weitere Fragen dazu?</sample>
    <sample id="978">Die Autoren haben BART-FID-RAG, Blender2, Emora und Blender-Decode evaluiert.</sample>
    <sample id="979">Sechs.</sample>
    <sample id="980">Nichts zu tun.</sample>
    <sample id="981">Sechs.</sample>
    <sample id="982">Vasudha Varadarajan.</sample>
    <sample id="983">Die Autoren gehören der University of Warsaw an.</sample>
    <sample id="1021">Die häufigsten Fehler von PaLM sind "Accuracy/Omission" und "Style/Awkward".</sample>
    <sample id="1022">Entferne nicht deine ABCs: Beurteilung der neuesten Technik in chatorientierten Dialogsystemen Sarah E. Finch, James D. Finch und Jinho D. Choi</sample>
    <sample id="1023">Entferne nicht deine ABCs: Beurteilung der Top-Chat-Orientierten Dialogsysteme Sarah E. Finch, James D. Finch und Jinho D. Choi</sample>
    <sample id="1024">" vergiss nicht deine ABCs: die Bewertung der neuesten Technik in chat-basierten Dialogsystemen" Sarah E. Finch, James D. Finch und Jinho D. Choi</sample>
    <sample id="1025">Kompative Evaluierung Likert-Bewertungs-Evaluation</sample>
    <sample id="1026">"Likert Rating Evaluation" bedeutet "Likert-Bewertungsevaluation". "Dimensions of Dialogue Quality" bedeutet "Dimensionen der Dialogqualität". "Dialogue Quality" bedeutet "Dialogqualität". "Relevance" bedeutet "Relevanz". "Consistency" bedeutet "Konsistenz". "Emotional Understanding" bedeutet "Emotionale Verständnis".</sample>
    <sample id="1027">Dimensionen der Dialogqualität Likert-Bewertungs-Evaluation.</sample>
    <sample id="1028">Likert-Bewertungs-Evaluation. Bewertung der Relevanz der Antworten des Bots.</sample>
    <sample id="1029">Klar, ich kann den Inhalt übersetzen. Was genau möchtest du übersetzt haben?</sample>
    <sample id="1030">Klar, aber du musst den englischen Inhalt haben, den du übersetzen möchtest.</sample>
    <sample id="1031">ABC-Eval Verhaltensweisen
Kohärenz
Wissen
Konsistenz
Emotionale Verständigung</sample>
    <sample id="1032">ABC-Eval Verhaltensweisen
Kohärenz
Ignorieren Partner
Irrelevant
Wissen
Konsistenz
Emotionale Verständigung</sample>
    <sample id="1033">ABC-Eval Verhaltensweisen
Kohärenz
Ignorieren Partner
Irrelevant
Konsistenz
Selbstwidersprüchlichkeit
Partnerwidersprüchlichkeit
Wissen
Falsche Tatsache
Commonsense Verletzung
Emotionale Verständigung
Empathische Reaktion
Mangel an Empathie</sample>
    <sample id="1034">Experimente
- 4 offene Domänen Dialogmodelle
- 100 menschliche-roboterliche Konversationen pro Modell</sample>
    <sample id="1035">Experimente
- 4 Open-Domain-Dialog-Modelle
- 100 menschliche-roboterische Konversationen pro Modell
ABC-Eval
Turn Likert
Dialog Likert
Comparative</sample>
    <sample id="1036">Experimente
- 4 Offene-Domain-Dialog-Modelle
- 100 Mensch-Bot-Konversationen pro Modell
Baseline-Evaluierungen
- Turn Likert
- Dialogue Likert
- Vergleichend
Unten:
- Konsistenz
- Emotionaler Verständnis
- Informationsreich
- Gesamtqualität
- Engagierend
- Grammatikalität
- Proaktivität
- Relevanz</sample>
    <sample id="1037">Inter-Annotator-Übereinstimmung
Krippendorffs Alpha
ABC-Eval
Turn Likert
Dialogue Likert
Comparative
Emotional Verständnis
Informativ
Engagierend
Proaktiv
Qualität
Relevanz
Konsistent
Emotion
Engagierend
Proaktiv
Qualität
Relevanz
Konsistent
Emotion
Engagierend
Proaktiv
Qualität
Relevanz
Konsistent
Emotion
Engagierend
Proaktiv
Qualität
Relevanz
Konsistent
Emotion
Engagierend
Proaktiv
Qualität
Relevanz
Konsistent
Emotion
Engagierend
Proaktiv
Qualität
Relevanz
Konsistent
Emotion
Engagierend
Proaktiv
Qualität
Relevanz
Konsistent
Emotion
Engagierend
Proaktiv
Qualität
Relevanz
Konsistent
Emotion
Engagierend
Proaktiv
Qualität
Relevanz
Konsistent
Emotion
Engagierend
Proaktiv
Qualität
Relevanz</sample>
    <sample id="1038">Inter-Annotator-Übereinstimmung
Prädiktive Gültigkeit</sample>
    <sample id="1039">Kognitive Validität.</sample>
    <sample id="1040">Hier ist die deutsche Übersetzung des englischen Inhalts: "Prädiktive Validität" "Steigernde Validität" "Emory University" "NLP Emory" "Alexa"</sample>
    <sample id="1041">"Erweiterbare Gültigkeit" ist die Übersetzung von "Incremental Validity". "R²" bedeutet "R-Quadrat", "Quality Explained" ist "Erklärte Qualität", "ABC-Eval" ist "ABC-Evaluation", "Turn Likert" ist "Dreh-Likert", "Dialogue Likert" ist "Dialog-Likert", "Unempathetic" ist "Unempathisch", "Redundant" ist "Redundant", "Self Contra." ist "Selbst-Kontrast", "Empathetic" ist "Empathisch", "Correct" ist "Richtig", "CS Contra." ist "CS-Kontrast", "Irrelevant" ist "Irrelevant", "Antisocial" ist "Antisozial", "Follow up" ist "Folgeauftrag", "Topic Switch" ist "Themenwechsel", "Ticorrect Switch" ist "Ticorrect-Umschaltung", "Topic Info" ist "Themeninformation", "Pref Contra." ist "Präferenz-Kontrast", "Inner Contra." ist "Innere Kontrast", "Other Con</sample>
    <sample id="1042">"Erweiterbare Gültigkeit" ist "Erweiterbare Gültigkeit" in Deutsch. "ABC-Eval" ist "ABC-Eval" in Deutsch. "Turn Likert" ist "Turn Likert" in Deutsch. "Dialogue Likert" ist "Dialogue Likert" in Deutsch. "R²" ist "R²" in Deutsch. "Quality Explained" ist "Qualität erklärt" in Deutsch. "Unempathetic" ist "Unempathisch" in Deutsch. "Redundant" ist "Redundant" in Deutsch. "Self Contra." ist "Selbstkontrast." in Deutsch. "Empathetic" ist "Empathisch" in Deutsch. "Correct" ist "Richtig" in Deutsch. "CS Contra." ist "CS-Kontrast." in Deutsch. "Irelevent" ist "Irrelevant" in Deutsch. "Antisocial" ist "Antisozial" in Deutsch. "Life Info" ist "Lebensinformationen" in Deutsch. "Topic Switch" ist "Themenwechsel" in Deutsch. "Pref Info" ist "Präferenzinformation" in Deutsch. "Inner Contra." ist "</sample>
    <sample id="1043">ABC-Eval Fehlerquoten nach Modell</sample>
    <sample id="1044">ABC-Evaluierung Fehlerquoten nach Modell</sample>
    <sample id="1045">ABC-Evaluierung Fehlerquoten nach Modell</sample>
    <sample id="1046">ABC-Evaluierung Fehlerquoten nach Modell</sample>
    <sample id="1047">ABC-Eval Fehlerquoten nach Modell
BART-FID-RAG, Blender2, Emora, Blender-Decode
Emory University
Paper: https://arxiv.org/pdf/2212.09180.pdf
GitHub: https://github.com/emorynlp/ChatEvaluationPlatform
Kontaktinformationen: {sfillwo, jdfinch, jinho.choi} @emory.edu
https://www.emorynlp.org</sample>
    <sample id="1048">Die Autoren gehören der Emory University an.</sample>
    <sample id="1049">CFT steht für Continuous Fine-tuning. Wenn du noch Fragen hast, lass sie gerne da.</sample>
    <sample id="1050">Sechs.</sample>
    <sample id="1051">Wann erfordert die Übersetzung Kontext? Eine datenbasierte, multilingualen Erforschung. Patrick Fernandes*, Kayo Yin*, Emmy Liu André F. T. Martins, Graham Neubig</sample>
    <sample id="1052">Wir müssen diesen Spitzel loswerden.</sample>
    <sample id="1053">Dinge könnten gefährlich werden, wenn die Minister es herausfinden. Wir müssen diesen Spion loswerden.</sample>
    <sample id="1054">Kann es etwas Ernstes sein, Doktor? Wir müssen diesen Fleck loswerden.</sample>
    <sample id="1055">Die Bewertung von kontextabhängiger Übersetzung ist schwierig. Nur ein kleiner Teil der Wörter hängt vom Kontext ab.</sample>
    <sample id="1056">Die Bewertung von kontextabhängiger Übersetzung ist schwierig. Nur ein kleiner Teil der Wörter hängt vom Kontext ab. Korpus-basierte Maße. Bestehende Methoden unterstützen begrenzte Diskursphänomene und Sprachen.</sample>
    <sample id="1057">RQ1: Wann erfordert die Übersetzung Kontext? RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1058">RQ1: Wann erfordert die Übersetzung Kontext? - Wort-ebene Kontextnutzung RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1059">Konditionales Kreuz-Mutual Information, CXMI, CXMI: Messen, wie viel Kontext-MT-Modelle bei gegebenem Korpus verwenden. Unsicherheit bei Übersetzungen gegebenen Quelltextes Unsicherheit bei Übersetzungen gegebenen Quelltextes und Kontextes CXMI, C → Y | X,</sample>
    <sample id="1060">Kontextbedingte Kreuz-Mutual Information, CXMI, CXMI: Messen, wie viel Kontext-MT-Modelle bei gegebenem Korpus verwenden. Unsicherheit bei Übersetzungen gegebenen Quelltextes. H, q, MT, A, Y, X, Unsicherheit bei Übersetzungen gegebenen Quelltextes und Kontextes. H, q, MT, C, Y, X, C, CXMI, C, Y, X,</sample>
    <sample id="1061">Punktweises, P-CXMI, wir führen P-CXMI ein, um den Kontextgebrauch zur Übersetzung eines spezifischen, P-CXMI, y, x, C, = - log, qMTA, y|x, qMTC, y|x, C, P-CXMI, i, y, x, C, = - log, qMTA, yi|yt&lt;i, x, qMTC, yi|yt&lt;i, x, C, hohe P-CXMI-Wörter -&gt; benötigt Kontext zur Übersetzung,</sample>
    <sample id="1062">RQ1: Wann erfordert die Übersetzung Kontext? - Wortlevel-Kontextnutzung - Themenanalyse RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1063">Themenanalyse von hochwertigen P-CXMI-Wörtern. Frage 1: Wann erfordert die Übersetzung Kontext? - Wortebene Kontextnutzung - Themenanalyse Frage 2: Wie gut handhaben Modelle kontextabhängige Übersetzungen? IDEEN WORTH SPREADING.</sample>
    <sample id="1064">Themenanalyse von hoch bewerteten P-CXMI-Wörtern. 1. POS-Tags.</sample>
    <sample id="1065">Themenanalyse hochwertiger P-CXMI-Wörter
1. POS-Tags
- Pronomen</sample>
    <sample id="1066">Themenanalyse hochwertiger P-CXMI-Wörter. 1. POS-Tags. - Pronomen. - Verbform. 2. Vokabulargegenstände.</sample>
    <sample id="1067">Themenanalyse hochwertiger P-CXMI-Wörter. 1. POS-Tags 2. Vokabulargegenstände. Aveliles Mutter war noch schlafend. Avelile ging zur Schule. 阿维利尔的母亲还在睡觉。阿维利尔去上学了。 - Pronomen - Verbform - Lexikalische Kohäsion.</sample>
    <sample id="1068">1. POS Tags
2. Vokabular-Elemente
Aveliles Mutter war noch schlafend. Avelile ging zur Schule.
Aveliles Mutter ist noch im Schlaf. Avelile ging zur Schule.</sample>
    <sample id="1069">Sie weiß, wohin wir gehen. Ich weiß es nicht.</sample>
    <sample id="1070">RQ1: Wann erfordert die Übersetzung Kontext? - Wortebene Kontextnutzung - Themenanalyse RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen? - Multilingual Discourse-Aware, MuDA, Benchmark</sample>
    <sample id="1071">RQ1: Wann erfordert die Übersetzung Kontext? - Wortlevel-Kontextnutzung - Themenanalyse RQ2: Wie gut handeln Modelle kontextabhängige Übersetzungen? - Multilingual Discourse-Aware, MuDA, Benchmark Multilingual Discourse-Aware, MuDA, Tagger - Pronomen - Verbform - Lexikalische Kohäsion - Formalität - Ellipsen</sample>
    <sample id="1072">Multilingual Discourse-Aware, MuDA, Tagger
- Pronomen
- Verbform
- Lexikalische Kohäsion
- Formalität
- Ellipsen</sample>
    <sample id="1073">Multilingual Discourse-Aware, MuDA, Tagger. - Pronouns, - Verb form, - Lexical cohesion, - Formality, - Ellipsis. MuDA Benchmark. MuDA Tagger. BLEU COMET F-measure.</sample>
    <sample id="1074">RQ1: Wann erfordert die Übersetzung Kontext? - Wortlevel-Kontextnutzung - Themenanalyse RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen? - Multilingual Discourse-Aware, MuDA, Benchmark - Modellbewertung</sample>
    <sample id="1075">Korpusniveau-Metriken. Frage 1: Wann erfordert die Übersetzung Kontext? - Wortniveau-Kontextnutzung - Themenanalyse. Frage 2: Wie gut handhaben Modelle kontextabhängige Übersetzungen? - Multilingual Discourse-Aware, MuDA, Benchmark - Modellbewertung.</sample>
    <sample id="1076">Korpus-niveau-Metriken
Bleu
COMET
F-Maß</sample>
    <sample id="1077">Korpus-niveau-Metriken
- BLEU: Kontext
- COMET: Kontext
- F-Maß: Kontext
Unklar, welches System am besten für die dokumentenbasierte MT mit korpus-niveau-Metriken geeignet ist.</sample>
    <sample id="1078">Korpus-niveau-Metriken
- Unklar, welches System am besten für die dokumentenbasierte MT mit korpus-niveau-Metriken geeignet ist.
MuDA-Benchmark-Ergebnisse
- Kontext-bewusste Modelle leisten bei einigen Phänomenen signifikant besser.</sample>
    <sample id="1079">MuDA-Benchmark-Ergebnisse
- Kontext-bewusste Modelle performieren bei einigen Phänomenen signifikant besser
  ✅: Formalität, lexikalische Kohäsion ❌: Ellipsen, Pronomen, Verbform</sample>
    <sample id="1080">MuDA-Benchmark-Ergebnisse
- Kontext-bewusste Modelle leisten bei einigen Phänomenen signifikant besser
  ✅: Formalität, lexikalische Kohäsion ❌: Ellipsen, Pronomen, Verbform
- DeepL übertrifft Google bei den meisten Phänomenen und Sprachpaaren*</sample>
    <sample id="1081">MuDA-Benchmark-Ergebnisse

- Kontext-bewusste Modelle leisten bei einigen Phänomenen signifikant besser
  - ✅ Formalität, lexikalische Kohäsion ❌ Ellipsen, Pronomen, Verbform
- DeepL übertrifft Google bei den meisten Phänomenen und Sprachpaaren*

Zusammenfassung

- Identifizieren diskursiver Phänomene systematisch ohne vorherige linguistische Kenntnisse
- Dataset-agnostischer Benchmark für dokumentenbasierte MT
- DeepL übertrifft Google bei den meisten Phänomenen und Sprachpaaren*</sample>
    <sample id="1082">Zusammenfassung
- Systematisch Diskursphänomene identifizieren ohne vorherige linguistische Kenntnisse
- Dataset-agnostischer Benchmark für dokumentenbasierte MT</sample>
    <sample id="1083">- Systematisch Diskursphänomene identifizieren ohne vorherige linguistische Kenntnisse, - Dataset-agnostischer Benchmark für dokumentenbasierte MT</sample>
    <sample id="1084">Yusen Zhang.</sample>
    <sample id="1121">Diese Methode nennt sich "Permuting with 'jumps'".</sample>
    <sample id="1122">Die Autoren beschreiben die Methode der "markierten Wörter" als das Finden von Wörtern, die Personen von markierten Gruppen von unmarkierten Gruppen unterscheiden.</sample>
    <sample id="1123">Die Autoren gehören an die Paul G. Allen School, die University of Washington, die Carnegie Mellon University und Peking University.</sample>
    <sample id="1124">Bouquet/Stanford.</sample>
    <sample id="1125">Sarah E. Finch, James D. Finch, and Jinho D. Choi.</sample>
    <sample id="1126">Es sind vier Autoren an der Arbeit beteiligt. Wenn du noch mehr Details wissen möchtest, frag einfach nach.</sample>
    <sample id="1127">BLiMP, SyntaxGym und Crows. Wenn du noch mehr Fragen hast, lass sie gerne stehen.</sample>
    <sample id="1161">FTw, BOND, COSINE, MLC, L2R.</sample>
    <sample id="1162">Das Modell wird anhand von 11 Aufgaben evaluiert.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich mit 4GB von Daten trainiert.</sample>
    <sample id="1227">Der Referent ist Adam Przepiórkowski.</sample>
    <sample id="1228">Die Ergebnisse, die in der Tabelle und dem Diagramm zu sehen sind, zeigten, dass die Leistung mit größerem zeitlichem Abstand abnimmt. Also, wenn es einen größeren Abstand gibt, sinkt die Leistung. Wenn du mehr Details haben möchtest, frag einfach nach.</sample>
    <sample id="1269">Weil es die Flexibilität der Ausgabesequenz erhöht und verschiedene Kombinationen ermöglicht.</sample>
    <sample id="1270">Die genauen Gründe sind nicht im Bild zu sehen. Du könntest aber versuchen, den Text des Bildes zu lesen oder die Quelle zu googeln. Wenn du mehr Details brauchst, lass es mich wissen.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind "Many people were helping herself" in BLiMP, "No customer has spent any money" in SyntaxGym und "The customer has spent any money" in SyntaxGym.</sample>
    <sample id="1272">Die Autoren haben F1, NER, CLS, POS, Hamming, EMR verwendet.</sample>
    <sample id="1273">Krippendorff's Alpha wurde verwendet.</sample>
    <sample id="1274">Die Domain, die für die hinzufügung von völlig unzusammenhängenden Sätzen zu den inakzeptablen und akzeptablen Suchanfragen gewählt wurde, ist Wikipedia.</sample>
    <sample id="1275">Die Autoren gehören der Heinrich Heine University Düsseldorf an.</sample>
    <sample id="1276">MultiInstruct unterscheidet sich von anderen Benchmarks durch die Fokussierung auf die Anpassung von Multimodalen Vorkondensierungsmodellen. Es gibt aber keine großen, öffentlich zugänglichen multimodalen Anweisungsaufgaben. Wenn du mehr darüber wissen möchtest, lass es mich wissen!</sample>
    <sample id="1277">Drei.</sample>
    <sample id="1278">Binäre Koordination ist die Verbindung von zwei Elementen oder Konjunkten.</sample>
    <sample id="1279">Leider ist in dem Bild nichts über die Länge der verwendeten Prompts zu sehen. Also kann ich keine Antwort darauf geben. Wenn du mehr Informationen hast, teile sie bitte mit.</sample>
    <sample id="1280">Die Ergebnisse haben eine positive Auswirkung auf das kleinere T5-Modell. Es kann höhere Qualität in Skripten generieren als größere LLMs. Wenn du noch mehr Details wissen möchtest, lass es mich wissen.</sample>
    <sample id="1281">DrBERT: Ein robustes vortrainiertes Modell auf Französisch für biomedizinische und klinische Bereiche.</sample>
    <sample id="1282">I. Sprachmodellierung im Gesundheitswesen
II. Vergleich von Vortrainingsstrategien, Datensätzen und Größen
III. Bewertung von 13 Modellen anhand von 11 Aufgaben
IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1283">I. Sprachmodellierung im Gesundheitswesen II. Vergleich von Vortrainingsstrategien, Datensätzen und Größen III. Bewertung von 13 Modellen an 11 Aufgaben IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1284">I. Sprachmodellierung im Gesundheitswesen II. Vergleich von Vortrainingsstrategien, Datensätzen und Größen III. Bewertung von 13 Modellen an 11 Aufgaben IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1285">I. Sprachmodellierung in der Gesundheit
- Transformer-basierte Ansätze, wie BERT, bieten bei vielen NLP-Aufgaben einen riesigen Leistungszuwachs
- Hat mit CamemBERT und FlauBERT auf Französisch adaptiert worden

II. Vergleich von Prätrainingsstrategien, Datensätzen und Größen
- PudMedBERT, BioBERT, ClinicalBERT und andere

III. Bewertung von 13 Modellen an 11 Aufgaben
- Sprachen außer Englisch sind seltener und stützen sich hauptsächlich anhand der kontinuierlichen Prätraining an einem bestehenden generischen Modell

IV. Verteilung von NACHOS und DrBERT
- Im Gegensatz zu generischen Modellen ist noch kein Open-Source-Modell für den biomedizinischen Bereich in Französisch verfügbar
- BERT-basierte domänenspezifische Modelle für Französisch sollten die Leistung bei medizinischen Aufgaben verbessern</sample>
    <sample id="1286">Natürlich! Hier ist der deutsche Inhalt: "Sprachmodellierung

• Transformer-basierte Ansätze, wie BERT, bieten bei vielen NLP-Aufgaben einen riesigen Leistungszuwachs

• Es wurde für Französisch mit CamemBERT und FlauBERT adaptiert

• Bei medizinischen Aufgaben haben domain-spezifische Modelle in Englisch die Leistung noch weiter verbessert

○ PubMedBERT, BioBERT, ClinicalBERT und andere

• Sprachen außer Englisch sind seltener und stützen sich hauptsächlich anhand der kontinuierlichen Vorkonditionierung an einem bestehenden generischen Modell

• Im Gegensatz zu generischen Modellen gibt es noch keine Open-Source-Modell für den biomedizinischen Bereich in Französisch

• Ein BERT-basierter domain-spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern"</sample>
    <sample id="1287">Natürlich! Hier ist der deutsche Inhalt: "Sprachmodellierung

- Transformer-basierte Ansätze, wie BERT, bieten bei vielen NLP-Aufgaben erhebliche Leistungsgewinne
- Es wurde für Französisch mit CamemBERT und FlauBERT adaptiert
- Bei medizinischen Aufgaben haben domain-spezifische Modelle in Englisch die Leistung noch weiter verbessert
  - PudMedBERT, BioBERT, ClinicalBERT und andere
- Sprachen außer Englisch sind seltener und stützen sich hauptsächlich anhand der fortlaufenden Vortraining an einem bestehenden generischen Modell
- Im Gegensatz zu generischen Modellen gibt es noch keine Open-Source-Modell für den biomedizinischen Bereich in Französisch
- Ein BERT-basierter domain-spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern"</sample>
    <sample id="1288">Natürlich! Hier ist der deutsche Inhalt: "Sprachmodellierung

- Transformer-basierte Ansätze, wie BERT, bieten bei vielen NLP-Aufgaben erhebliche Leistungsgewinne
- Es wurde für Französisch mit CamemBERT und FlauBERT adaptiert
- Bei medizinischen Aufgaben haben domain-spezifische Modelle in Englisch die Leistung noch weiter verbessert
  - PudMedBERT, BioBERT, ClinicalBERT und andere
- Sprachen außer Englisch sind seltener und stützen sich hauptsächlich anhand der kontinuierlichen Vorkonditionierung anhand eines bestehenden allgemeinen Modells
- Im Gegensatz zu allgemeinen Modellen gibt es noch keine Open-Source-Modell für den biomedizinischen Bereich in Französisch
- Ein BERT-basierter domain-spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern"</sample>
    <sample id="1289">Natürlich. Hier ist der deutsche Inhalt:.- Transformer-basierte Ansätze, wie BERT, bieten bei vielen NLP-Aufgaben einen riesigen Leistungszuwachs.- Es wurde auf Französisch mit CamemBERT und FlauBERT angepasst.- Bei medizinischen Aufgaben haben domain-spezifische Modelle in Englisch die Leistung noch weiter verbessert.- PudMedBERT, BioBERT, ClinicalBERT und andere.- Sprachen außer Englisch sind seltener und stützen sich hauptsächlich anhand der fortlaufenden Vortraining an einem bestehenden generischen Modell.- Im Gegensatz zu generischen Modellen gibt es noch keine Open-Source-Modell für den biomedizinischen Bereich in Französisch.- Ein BERT-basierter domain-spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern.</sample>
    <sample id="1290">Vergleich von Vortrainingsstrategien und Datensätzen

- Bewertung der Auswirkung öffentlicher und privater medizinischer Datensätze auf vergleichbare Datenmengen
  - NACHOS: Ein 1,1 Milliarden Wörter großer Open-Source-Datensatz heterogener Daten aus verschiedenen medizinischen Domänen, Naturen und Stilen
  - NBDW: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Aufzeichnungen des Nantes University Hospital Data Warehouse stammen

- Vergleich von Lernstrategien
  - Von Scratch mit vollständiger Modellkonstruktion
  - Fortlaufende Vortraining mit einem bestehenden Vortrainingsmodell (hier: CamemBERT, ein französischer generischer Modell, und PubMedBERT, ein englisch-basierter medizinischer Modell)

Tabelle:

| Korpus | Größe | Anzahl Wörter | Anzahl Sätze |
|--------|-------|---------------|--------------|
| NACHOSlarge, öffentlich | 7,4 GB |</sample>
    <sample id="1291">Vergleich von Vortrainingsstrategien und Datensätzen

- Bewertung der Auswirkung öffentlicher und privater medizinischer Datensätze auf vergleichbare Datenmengen
  - NACHOS: Ein 1,1 Milliarden Wörter großer Open-Source-Datensatz heterogener Daten aus verschiedenen medizinischen Domänen, Naturen und Stilen
  - NBDW: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Aufzeichnungen des Nantes University Hospital Data Warehouse stammen

- Vergleich von Lernstrategien
  - Von Null anfangen mit vollständiger Modellkonstruktion
  - Fortlaufende Vortraining mit einem bestehenden Vortrainingsmodell (hier: CamemBERT, ein französischer generischer Modell, und PubMedBERT, ein englisch-basierter medizinischer Modell)

Tabelle:

| Korpus | Größe | Anzahl der Wörter | Anzahl der Sätze |
|--------|-------|-------------------|-----------------|
| NACHOSlarge, öffentlich |</sample>
    <sample id="1292">Klar, ich kann das für dich übersetzen. Hier ist die deutsche Übersetzung des englischen Inhalts: "Vergleich von Vortrainingsstrategien und Datensätzen

- Bewertung der Auswirkung öffentlicher und privater medizinischer Datensätze auf vergleichbare Datenmengen
  - NACHOS: Ein 1,1 Milliarden Wörter großer Open-Source-Datensatz heterogener Daten, die aus verschiedenen medizinischen Domänen, Naturen und Stilen gesammelt wurden
  - NBDW: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Aufzeichnungen extrahiert wurden, die aus dem Datenlager des Universitätsklinikums Nantes stammen
- Vergleich von Lernstrategien
  - Von Null anfangen mit vollständiger Modellkonstruktion
  - Fortlaufende Vortraining mit einem bestehenden Vortrainingsmodell (hier: CamemBERT, ein französischer generischer Modell, und PubMedBERT, ein englisch-basierter</sample>
    <sample id="1293">Vergleich von Vortrainingsstrategien und Datensätzen

- Bewertung der Auswirkung öffentlicher und privater medizinischer Datensätze auf vergleichbare Datenmengen
  - NACHOS: Ein 1,1 Milliarden Wörter großer Open-Source-Datensatz heterogener Daten aus verschiedenen medizinischen Domänen, Naturen und Stilen
  - NBDW: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Aufzeichnungen des Nantes University Hospital Data Warehouse stammen

- Vergleich von Lernstrategien
  - Von Null anfangen mit vollständiger Modellkonstruktion
  - Fortlaufende Vortraining mit einem bestehenden Vortrainingsmodell (hier: CamemBERT, ein französischer generischer Modell, und PubMedBERT, ein englisch-basierter medizinischer Modell)

Tabelle:

| Korpus | Größe | Anzahl der Wörter | Anzahl der Sätze |
|--------|-------|-------------------|-----------------|
| NACHOSlarge, öffentlich |</sample>
    <sample id="1294">Klar, ich kann das für dich übersetzen. Hier ist die deutsche Übersetzung des englischen Inhalts: "Vergleich von Vortrainingsstrategien und Datensätzen

- Bewertung der Auswirkung öffentlicher und privater medizinischer Datensätze auf vergleichbare Datenmengen
  - NACHOS: Ein 1,1 Milliarden Wörter großer Open-Source-Datensatz heterogener Daten, die aus verschiedenen medizinischen Domänen, Naturen und Stilen gesammelt wurden
  - NBDW: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Aufzeichnungen des Nantes University Hospital Data Warehouse stammen
- Vergleich von Lernstrategien
  - Vom Nullpunkt mit vollständiger Modellkonstruktion
  - Fortlaufende Vortraining mit einem bestehenden Vortrainingsmodell (hier: CamemBERT, ein französischer generischer Modell, und PubMedBERT, ein englisch-basierter medizinisches Modell)"

Wenn du noch weitere Fragen hast oder weitere</sample>
    <sample id="1295">Vergleich von Vortrainingsstrategien und Datensätzen

- Bewertung der Auswirkung öffentlicher und privater medizinischer Datensätze auf vergleichbare Datenmengen
  - NACHOS: Ein 1,1 Milliarden Wörter großer Open-Source-Datensatz heterogener Daten aus verschiedenen medizinischen Domänen, Naturen und Stilen
  - NBDW: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Aufzeichnungen des Nantes University Hospital Data Warehouse stammen

- Vergleich von Lernstrategien
  - Aus der Schublade mit vollständiger Modellkonstruktion
  - Fortlaufende Vortraining mit einem bestehenden Vortrainingsmodell (hier: CamemBERT, ein französischer generischer Modell, und PubMedBERT, ein englisch-basierter medizinisches Modell)

Tabelle:

| Korpus | Größe | Anzahl der Wörter | Anzahl der Sätze |
| --- | --- | --- | --- |
| NACHOSlarge, öffentlich |</sample>
    <sample id="1296">Vergleich von Vortrainingsstrategien und Datensätzen

- Bewertung der Auswirkung öffentlicher und privater medizinischer Datensätze auf vergleichbare Datenmengen
  - NACHOS: Ein 1,1 Milliarden Wörter großer Open-Source-Datensatz heterogener Daten aus verschiedenen medizinischen Domänen, Naturen und Stilen
  - NBDW: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Aufzeichnungen aus dem Datenlager des Universitätskrankenhauses Nantes stammen

- Vergleich von Lernstrategien
  - Von Scratch mit vollständiger Modellkonstruktion
  - Fortlaufende Vortraining mit einem bestehenden Vortrainingsmodell (hier: CamemBERT, ein französischer generischer Modell, und PubMedBERT, ein englisch-basierter medizinischer Modell)

Tabelle:

| Korpus | Größe | Anzahl der Wörter | Anzahl der Sätze |
|--------|-------|-------------------|-----------------|
| NACHOS</sample>
    <sample id="1297">Klar, ich kann das für dich übersetzen. Hier ist die deutsche Übersetzung des englischen Inhalts: "Vergleich von Vortrainingsstrategien und Datensätzen

- Bewertung der Auswirkung öffentlicher und privater medizinischer Datensätze auf vergleichbare Datenmengen
  - NACHOS: Ein 1,1 Milliarden Wörter großes Open-Source-Datensatz heterogener Daten, die aus verschiedenen medizinischen Domänen, Naturen und Stilen gesammelt wurden
  - NBDW: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Aufzeichnungen extrahiert wurden, die aus dem Datenlager des Universitätskrankenhauses Nantes stammen
- Vergleich von Lernstrategien
  - Vom Nullpunkt mit vollständiger Modellkonstruktion
  - Fortlaufende Vortraining mit einem bestehenden Vortrainingsmodell (hier: CamemBERT, ein französischer generischer Modell, und PubMedBERT, ein englisch-basierter</sample>
    <sample id="1298">Bewertung: Datenquellen und Größe
- Leistungsbewertung von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere abgestimmten Modelle erzielen fast auf allen Aufgaben state-of-the-art-Ergebnisse</sample>
    <sample id="1299">Bewertung: Datenquellen und Größe
- Leistungsbewertung von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere abgestimmten Modelle erzielen fast auf allen Aufgaben state-of-the-art-Ergebnisse</sample>
    <sample id="1300">Bewertung: Datenquellen und Größe
- Leistungsbewertung von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere abgestimmten Modelle erzielen fast auf allen Aufgaben state-of-the-art-Ergebnisse</sample>
    <sample id="1301">Bewertung: Datenquellen und Größe
- Leistungsbewertung von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere abgestimmten Modelle erzielen fast auf allen Aufgaben state-of-the-art-Ergebnisse</sample>
    <sample id="1302">Bewertung: Vorkonditionierungsstrategien
- Ausgangspunkt vs. fortlaufende Vorkonditionierung auf 4 GB Daten
- Frage-Antwort-Aufgaben erfordern mehr spezifisches Domänenwissen, um gut funktionieren zu können
- Eine Studie zur Modellstabilität zeigt eine höhere Inter-Run-Variabilität für die CamemBERT-basierten Modelle, die mit fortlaufender Vorkonditionierung trainiert wurden

CamemBERT OSCAR 138 GB
CamemBERT OSCAR 4 GB
CamemBERT CCNET 4 GB
PubMedBERT
ClinicalBERT
BioBERT v1.1
DrBERT NACHOS,large
DrBERT NACHOS,small
ChuBERT NBDW,small
ChuBERT NBDW,mixed
CamemBERT NACHOS,small
PubMedBERT NACHOS,small
CamemBERT NBDW,small

Avignon Université</sample>
    <sample id="1303">Bewertung: Vorkonditionierungsstrategien
- Ausgangslage vs. kontinuierliche Vorkonditionierung auf 4 GB Daten
- Frage-Antwort-Aufgaben erfordern mehr spezifisches Domänenwissen, um gut funktionieren zu können
- Eine Studie zur Modellstabilität zeigt eine höhere Inter-Run-Variabilität für die CamemBERT-basierten Modelle, die mit kontinuierlicher Vorkonditionierung trainiert wurden

CamemBERT OSCAR 138 GB
CamemBERT OSCAR 4 GB
CamemBERT CCNET 4 GB
PubMedBERT
ClinicalBERT
BioBERT v1.1
DrBERT NACHOS,large
DrBERT NACHOS,small
ChuBERT NBDW,small
ChuBERT NBDW,mixed
CamemBERT NACHOS,small
PubMedBERT NACHOS,small
CamemBERT NBDW,small</sample>
    <sample id="1304">Bewertung: Vorkonditionierungsstrategien
- Ausgangslage vs. fortlaufende Vorkonditionierung auf 4 GB Daten
- Frage-Antwort-Aufgaben erfordern mehr spezifisches Domänenwissen, um gut funktionieren zu können
- Eine Studie zur Modellstabilität zeigt eine höhere Inter-Run-Variabilität für die CamemBERT-basierten Modelle, die mit fortlaufender Vorkonditionierung trainiert wurden

CamemBERT OSCAR 138 GB
CamemBERT OSCAR 4 GB
CamemBERT CCNET 4 GB
PubMedBERT
ClinicalBERT
BioBERT v1.1
DrBERT NACHOS, large
DrBERT NACHOS, small
ChuBERT NBDW, small
ChuBERT NBDW, mixed
CamemBERT NACHOS, small
PubMedBERT NACHOS, small
CamemBERT NBDW, small

Avignon Université</sample>
    <sample id="1305">Kernbotschaft
- DrBERT erzielt topmoderne Ergebnisse in 9 französisch medizinisch ausgerichteten Aufgaben
  - Übertrifft CamemBERT generischen Modell und englisch-basierte domänenspezifische Modelle
  - Bestätigt die Nützlichkeit des Trainings eines medizinisch spezifischen Modells auf Französisch
- Datenquellen sind wichtig: Das Trainieren an heterogenen Daten ist wichtig
  - NACHOS ist robuster als nur private klinische Daten zu verwenden
- Mehr Daten ist besser, aber nicht skalierbar
- Fortlaufendes Prainieren ist eine effektivere Strategie, wenn es auf domänenspezifischen englischen Modellen basiert
- Die DrBERT-Modelle, der NACHOS-Datensatz und die Trainings-Skripte sind unter der MIT-Lizenz frei verfügbar
Avignon Universität</sample>
    <sample id="1306">Kernbotschaft
- DrBERT erzielt bei 9 französisch medizinisch orientierten Aufgaben die besten Ergebnisse
  - Übertrifft den generischen CamemBERT-Modell und englisch-basierte domänenspezifische Modelle
  - Bestätigt die Nützlichkeit des Trainings eines medizinisch spezifischen Modells auf Französisch
- Datenquellen sind wichtig: das Trainieren mit heterogenen Daten ist wichtig
  - NACHOS ist robuster als nur private klinische Daten zu verwenden
- Mehr Daten ist besser, aber nicht skalierbar
- Fortlaufendes Prainieren ist eine effektivere Strategie, wenn es auf englisch-basierten domänenspezifischen Modellen basiert
- Die DrBERT-Modelle, das NACHOS-Datensatz und die Trainings-Skripte sind unter der MIT-Lizenz frei verfügbar
Avignon Université</sample>
    <sample id="1307">Kernbotschaft
- DrBERT erzielt topmoderne Ergebnisse bei 9 französisch medizinisch ausgerichteten Aufgaben
  - Übertrifft CamemBERT generischen Modell und englisch-basierte domänenspezifische Modelle
  - Bestätigt die Nützlichkeit des Trainings eines medizinisch spezifischen Modells auf Französisch
- Datenquellen sind wichtig: Das Trainieren an heterogenen Daten ist wichtig
  - NACHOS ist robuster als nur private klinische Daten zu verwenden
- Mehr Daten ist besser, aber nicht skalierbar
- Fortlaufendes Prainieren ist eine effektivere Strategie, wenn es auf domänenspezifischen englischen Modellen basiert
- Die DrBERT-Modelle, der NACHOS-Datensatz und die Trainings-Skripte sind unter der MIT-Lizenz frei verfügbar
Avignon Universität</sample>
    <sample id="1308">Vielen Dank. Auf dem Poster-Seminar in Toronto freue ich mich auf Austausch! Weitere Informationen unter: drbert.univ-avignon.fr</sample>
    <sample id="1309">Die Lernstrategien, die untersucht werden, sind "From scratch with full model construction" und "Continual pre-training using an existing pre-trained model". Wenn du mehr darüber wissen möchtest, frag einfach!</sample>
    <sample id="1310">Nicht bekannt.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde anhand von SARI, BLEU, BS-P und FRE beurteilt.</sample>
    <sample id="1312">Ja, sie haben unterschiedliche politische Vorurteile. Wenn du mehr darüber wissen möchtest, frag einfach nach.</sample>
    <sample id="1313">Kompositionelle Generalisierung ohne Bäume mittels Multiset-Tagging und versteckter Permutationen. Matthias Lindemann, Alexander Koller, Ivan Titov.</sample>
    <sample id="1314">Kompositionelle Generalisierung ohne Bäume unter Verwendung von Multiset-Tagging und versteckten Permutationen. Matthias Lindemann, Alexander Koller, Ivan Titov.</sample>
    <sample id="1315">Kompositionelle Generalisierung

Fähigkeit eines Lerners, tiefere Rekursion und unerwartete Kombinationen von Phrasen zu handhaben, die während des Trainings einzeln gesehen wurden.</sample>
    <sample id="1316">Kompositionelle Generalisierung in Semantischer Parsing
Train:
Die Mädchen schliefen.
*Mädchen x, Schlafagent x, x
Mary wusste, dass die Mädchen schliefen.
*Mädchen x, Wissenagent x, Mary und Wissen-komplement x, x, x
Schlafagent x, x</sample>
    <sample id="1317">Koexistenz von Generalisierung in semantischer Analyse. Trainieren: "Die Mädchen schliefen." *Mädchen x, Schlafagent x, x, "Mary wusste, dass die Mädchen schliefen." *Mädchen x, Wissenagent x, Mary und Wissen.comp x, x, x, Schlafagent x, x,</sample>
    <sample id="1318">Koordinative Generalisierung in Semantischer Analyse

Train:
Die Mädchen schliefen.
* Mädchen x, Schlafagent x, x

Mary wusste, dass die Mädchen schliefen.
* Mädchen x, Wissenagent x, Mary und Wissenccomp x, x, x

Test:
Jim sagte, dass Mary wusste, dass die Mädchen schliefen.
* Mädchen x, Sagenagent x, Jim und Sagenccomp x, x, x, Wissenagent x, Mary und Wissenccomp x, x, x, Schlafagent x, x</sample>
    <sample id="1319">Trainierter Text: "Die Mädchen schliefen." "Die Mädchen wussten, dass die Mädchen schliefen." Testtext: "Jim sagte, dass Mary wusste, dass die Mädchen schliefen." "Die Mädchen; sprachagent Jim und sprachccomp Jim und wussteagent Mary und wussteccomp Mary und schlafagent Mary und schlafccomp Mary und wussteagent Jim und sprachccomp Jim und wussteagent Mary und wussteccomp Mary und schlafagent Mary und schlafccomp Mary und wussteagent Jim und sprachccomp Jim und wussteagent Mary und wussteccomp Mary und schlafagent Mary und schlafccomp Mary und wussteagent Jim und sprachccomp Jim und wussteagent Mary und wussteccomp Mary und schlafagent Mary und schlafccomp Mary und wussteagent Jim und sprachccomp Jim und wussteagent Mary und wussteccomp Mary und schlafagent Mary und schlafccomp Mary und wussteagent Jim und sprachccomp Jim und wussteagent Mary und wussteccomp Mary und schlaf</sample>
    <sample id="1320">Kompositionelle Generalisierung in Semantischer Parsing. Trainieren: "Die Mädchen schliefen." *Mädchen x, Schlafagent x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x</sample>
    <sample id="1321">Kompositionelle Generalisierung in Semantischer Parsing.

Trainieren:
- "Die Mädchen schliefen." -&gt; "*Mädchen x, Schlafagent x, x"
- "Mary wusste, dass die Mädchen schliefen." -&gt; "*Mädchen x, Wissenagent x, Mary und Wissenccomp x, x, x"

Testen:
- "Jim sagte, dass Mary wusste, dass die Mädchen schliefen." -&gt; "*Mädchen x, Sagenagent x, Jim und Sagenccomp x, x, x, Wissenagent x, Mary und Wissenccomp x, x, x, Schlafagent x, x"

Naive seq2seq Modelle scheitern!</sample>
    <sample id="1322">Bäume helfen sehr, aber... *Mädchen x₁; Schlafagent x₂ x₁ *Mädchen x₁; x₁ Schlafagent x₂ Das Mädchen schlief.</sample>
    <sample id="1323">Bäume helfen sehr, aber... *Mädchen x₁; Schlafagent x₂ x₁ *Mädchen x₁; x₁ Schlafagent x₂ Das Mädchen schlief.</sample>
    <sample id="1324">Bäume helfen sehr, aber... *Mädchen x₁; Schlafagent x₂ x₁ *Mädchen x₁; x₁ Schlafagent x₂ Die Mädchen schliefen. Bäume müssen erhalten werden: - Vor-/Nachverarbeitung logischer Formen</sample>
    <sample id="1325">Bäume helfen sehr, aber... *girl x₁; sleep.agent x₂ x₁ *girl x₁; x₁ sleep.agent x₂ Die Mädchen schliefen. Bäume müssen erhalten werden: - Vorer- und Nachbearbeitung logischer Formen</sample>
    <sample id="1326">Bäume helfen sehr, aber... *girl x₁; sleep.agent x₂ x₁ *girl x₁; x₁ sleep.agent x₂ The girl slept. Bäume müssen erhalten werden: - Vor/Nachverarbeitung logischer Formen - Grammatik-Induktion</sample>
    <sample id="1327">Bäume helfen sehr, aber… *girl x₁; sleep.agent x₂ x₁ *girl x₁; x₁ sleep.agent x₂ The girl slept. Bäume müssen erfasst werden: - Vorer- und Nachbearbeitung logischer Formen - Grammatik-Induktion Dieses Papier: neuronales seq2seq-Modell, das direkte Korrespondenzen zwischen Fragmenten modelliert. Zum ersten Mal zeigen wir eine starke Generalisierung zu tieferer Rekursion ohne Bäume.</sample>
    <sample id="1328">Bäume helfen sehr, aber... *girl x₁; sleep.agent x₂ x₁ *girl x₁; x₁ sleep.agent x₂ The girl slept. Bäume müssen erfasst werden: - Vorer- und Nachbearbeitung logischer Formen - Grammatik-Induktion Dieses Papier: neuronales seq2seq-Modell, das direkt die Korrespondenzen zwischen Fragmenten modelliert. Zum ersten Mal zeigen wir eine starke Generalisierung zu tieferer Rekursion ohne Bäume.</sample>
    <sample id="1329">Unser Ansatz</sample>
    <sample id="1330">Unser Ansatz</sample>
    <sample id="1331">Unser Ansatz
- *; the
- x1 girl x1
- sleep agent x2
- girl
- slept</sample>
    <sample id="1332">Unser Ansatz
Permutieren
Tag</sample>
    <sample id="1333">Unser Ansatz
Permutieren
Tag</sample>
    <sample id="1334">Permutieren mit "Sprüngen"</sample>
    <sample id="1335">Permutieren mit "Sprüngen"</sample>
    <sample id="1336">Permutieren mit "Sprüngen"</sample>
    <sample id="1337">Permutieren mit "Sprüngen"</sample>
    <sample id="1338">Permutieren mit "Sprüngen"</sample>
    <sample id="1339">Einige Ergebnisse auf COGS (Kim und Linzen 2020) Vergleich mit anderen baumlosen Modellen in Bezug auf strukturelle Generalisierung auf COGS.</sample>
    <sample id="1340">Einige Ergebnisse auf COGS (Kim und Linzen 2020) Vergleich mit anderen baumlosen Modellen bei struktureller Generalisierung auf COGS.</sample>
    <sample id="1341">Technische Herausforderungen die wir lösen. Permutieren. Fragezeichen. Tag. Ausrichtung unbekannt.</sample>
    <sample id="1342">Technische Herausforderungen die wir lösen. Permutation. Fragezeichen. Tag. Ausrichtung unbekannt.</sample>
    <sample id="1343">Technische Herausforderungen die wir lösen. * grün, girl, x₁ ; grün, sleep, agent, x₂, x₁ Permute ? ? ? Tag ? ? ? Alignment unbekannt. &gt; Induzieren wir es in der Training.</sample>
    <sample id="1344">Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Hera</sample>
    <sample id="1345">Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Hera</sample>
    <sample id="1346">Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Herausforderungen die wir lösen.Technische Hera</sample>
    <sample id="1347">Kognitive Dissonanz ist, wenn zwei Elemente der Kognition, wie Thoughts, Actions, Beliefs, nicht konsistent sind.</sample>
    <sample id="1348">Alpaca. Wenn du noch Fragen hast, lass sie gerne da.</sample>
    <sample id="1349">Nicht immer. Es hängt von der spezifischen Situation ab.</sample>
    <sample id="1350">Sara Papi.</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen von TED Talks. Wenn du noch mehr über die Benchmark oder TED Talks wissen möchtest, frag einfach!</sample>
    <sample id="1385">Matthias Lindemann, Alexander Koller, Ivan Titov.</sample>
    <sample id="1386">Sprachübergreifender Transfer ist der Prozess, bei dem ein Modell auf einer Quellsprache trainiert wird und dann auf eine andere Sprache übertragen wird.</sample>
    <sample id="1387">Drei der Autoren gehören der Saarland University an, einer der University of Vienna und einer von Amazon Alexa.</sample>
    <sample id="1388">Die Autoren verwenden AL / AL-CA als Latenzmessung. Wenn du noch mehr Details wissen möchtest, frag einfach nach.</sample>
    <sample id="1389">The KITMUS Test. Die Evaluierung der Wissensintegration aus mehreren Quellen. Akshatha Arodi*, Martin Pömsl*, McGill University/Mila. Kaheer Suleman, Microsoft Research. Adam Trischler, Microsoft Research. Alexandra Olteanu, McGill University/Mila. Jackie CK Cheung, McGill University/Mila. *gleiche Beitragung.</sample>
    <sample id="1390">NLU-Modelle greifen auf mehrere Wissensquellen zurück. Wissen in Parametern, prätrainierungszeitiges Wissen, Wissen in Kontext, inferenzzeitiges Wissen.</sample>
    <sample id="1391">NLU-Modelle greifen auf mehrere Wissensquellen zurück. Wissen in Parametern, prätrainierungszeitiges Wissen. Wissen in Kontext, inferenzzeitiges Wissen.</sample>
    <sample id="1392">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1393">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1394">John sah den neu gewählten Präsidenten im Fernsehen. Was Präsidenten tun, ist bekannt. Was ist ein Fernseher, ist bekannt. Wer ist John? Wer ist der neue Präsident?</sample>
    <sample id="1395">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1396">- Datensatz zur Beurteilung der Wissensintegration
- Coreferenz-Auflösungsaufgabe, um die Fähigkeit zu prüfen, auf
  - prätrainierte Wissen
  - inferenzzeitliches Wissen
- Experiment mit
  - menschlichen Studienteilnehmern
  - Coreferenz-Auflösungsmodellen</sample>
    <sample id="1397">- Datensatz zur Beurteilung der Wissensintegration
- Coreferenz-Auflösungsaufgabe, um die Fähigkeit zu prüfen, auf
  - prätrainierte Kenntnisse
  - inferenzzeitliche Kenntnisse
- Experiment mit
  - menschlichen Studienteilnehmern
  - Coreferenz-Auflösungsmodellen</sample>
    <sample id="1398">Servin ist Richter. Kea ist Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, bei dem er Fälle entschied, war er froh, sich auszuruhen. [Antwort: Servin]</sample>
    <sample id="1399">Servin ist Richter. Kea ist Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, bei dem er Fälle entschied, war er froh, sich auszuruhen. [Antwort: Servin]</sample>
    <sample id="1400">Servin ist Richter. Kea ist Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, bei dem er Fälle entschied, war er froh, sich auszuruhen. [Antwort: Servin] 1) Ersatzspezifisches Wissen 2) Hintergrundwissen Richter entscheiden Fälle in Gerichten.</sample>
    <sample id="1401">Servin ist Richter. Kea ist Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, bei dem sie Fälle entschieden haben, war er froh, sich auszuruhen. [Antwort: Servin] Richter entscheiden Fälle in Gerichten. 1) Entity-spezifische Kenntnisse 2) Hintergrundkenntnisse</sample>
    <sample id="1402">Servin ist Richter. Kea ist Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag im Gericht, bei dem sie Fälle entschieden haben, war er froh, sich auszuruhen. [Antwort: Servin]</sample>
    <sample id="1403">Variante von KITMUS, a) Hintergrund-Prätrainieren: Typischer Setup, b) Hintergrund-Sowohl: Hintergrundwissen explizit im Kontext bereitstellen, c) Hintergrund-Inferenz: Wissen nur zur Inferenz-Zeit verfügbar.</sample>
    <sample id="1404">Variante von KITMUS, a) Hintergrund-Prätrainieren: Typischer Setup, b) Hintergrund-Sowohl: Hintergrundwissen explizit im Kontext bereitstellen, c) Hintergrund-Inferenz: Wissen nur zur Inferenz-Zeit verfügbar.</sample>
    <sample id="1405">Variante von KITMUS, a) Hintergrund-Prätrainieren: Typischer Setup, b) Hintergrund-Sowohl: Hintergrundwissen explizit im Kontext bereitstellen, c) Hintergrund-Inferenz: Wissen nur zur Inferenz-Zeit verfügbar.</sample>
    <sample id="1406">Politiker streben gewählte Sitze in der Regierung an.</sample>
    <sample id="1407">Variante von KITMUS, Hintergrund-Prätrainieren: Politiker streben Wahlplätze in der Regierung an. Chichester ist ein Politiker. Variante von KITMUS, Hintergrund-Sowohl: Politiker streben Wahlplätze in der Regierung an. Chichester ist ein Politiker. Die Arbeit eines Politikers besteht darin, einen Wahlplatz in der Regierung zu streben. Variante von KITMUS, Hintergrund-Inferenz: Chichester ist ein Mirituer. Die Arbeit eines Mirituers besteht darin, ehemting smorbltig zu sein.</sample>
    <sample id="1408">Variante von KITMUS, Hintergrund-Prätrainiert, Chichester ist ein Politiker, Politiker streben nach gewählten Sitzen in der Regierung, Hintergrund-Sowohl, Chichester ist ein Politiker, Politiker streben nach gewählten Sitzen in der Regierung, Die Arbeit eines Politikers ist das Streben nach einem gewählten Sitz in der Regierung, Hintergrund-Inferenz, Chichester ist ein Mirituer, Die Arbeit eines Mirituer ist ehemting smorbtlly.</sample>
    <sample id="1409">Variante von KITMUS, Hintergrund-Prätrainieren: Politiker streben Wahlplätze in der Regierung an. Hintergrund-Sowohl: Chichester ist ein Politiker. Politiker streben Wahlplätze in der Regierung an. Hintergrund-Inferenz: Chichester ist ein Mirituer. Die Arbeit eines Mirituers ist ehemting smorblt.</sample>
    <sample id="1410">Hintergrund-Prätrainieren. Task-spezifische Ausbildung ist notwendig für die Wissensintegration.</sample>
    <sample id="1411">Hintergrund-Prätrainieren. Task-spezifische Ausbildung ist notwendig für die Wissensintegration.</sample>
    <sample id="1412">Hintergrund-Prätrainieren. Task-spezifische Ausbildung ist notwendig für die Wissensintegration.</sample>
    <sample id="1413">Hintergrund-Inferenz. Die Modelle haben Schwierigkeiten, inferenzzeitliche Hintergrundwissen zu integrieren.</sample>
    <sample id="1414">Abschluss:

Hauptpunkte:
1. Viele Modelle scheinen nicht in der Lage zu sein, Wissen aus mehreren Quellen zu verarbeiten (Prätrainings- und Inferenzzeit-Wissen)
2. Aufgabenbezogene Trainings ist notwendig für die Wissensintegration
3. Modelle haben Schwierigkeiten, Hintergrundwissen zur Inferenzzeit zu integrieren

Finde den Datensatz, Generierung &amp; Evaluierungscodes auf GitHub unter mpoemsl/kitmus</sample>
    <sample id="1415">Abschluss:

Hauptpunkte:
1. Viele Modelle scheinen nicht in der Lage zu sein, Wissen aus mehreren Quellen zu verarbeiten, sowohl vor dem Trainieren als auch während der Inferenzzeit.
2. Aufgabenbezogene Trainings ist notwendig für die Wissensintegration.
3. Modelle haben Schwierigkeiten, Wissensintegration während der Inferenzzeit zu bewerkstelligen.

Finde das Datensatz, Generierung &amp; Evaluierungskodierung auf GitHub unter mpoemsl/kitmus</sample>
    <sample id="1416">Nicht genannt.</sample>
    <sample id="1417">Die Autoren gehören der Georgia Institute of Technology an.</sample>
    <sample id="1418">Markierte Persönlichkeiten. Verwenden von natürlichen Sprachanregungen zur Messung von Stereotypen in Sprachmodellen. Myra Cheng, Esin Durmus, Dan Jurafsky. ACL 2023. Stanford Engineering Computer Science.</sample>
    <sample id="1419">Markierte Persönlichkeiten: Motivation Soziale Voreingenommenheit und Stereotypen sind in LLMs weit verbreitet. Beschränkungen bestehender Stereotypenmessungen: - Tradeoff zwischen Spezifizität und Allgemeingültigkeit - Auf festen, handkurierten Datensätzen basierend - Account für Intersektionalität nicht beachten</sample>
    <sample id="1420">Markierte Persönlichkeiten: Motivation Soziale Voreingenommenheit und Stereotypen sind in LLMs weit verbreitet. Beschränkungen bestehender Stereotypenmessungen: - Tradeoff zwischen Spezifizität und Allgemeingültigkeit - Auf festen, handkurierten Datensätzen basierend - Account für Intersektionalität nicht beachten</sample>
    <sample id="1421">Markierte Persönlichkeiten: Motivation Soziale Voreingenommenheit und Stereotypen sind in LLMs weit verbreitet. Beschränkungen der bestehenden Stereotypenmessungen: - Tradeoff zwischen Spezifizität und Allgemeingültigkeit - Auf festen, handkurierten Datensätzen basierend - Account für Intersektionalität nicht beachten</sample>
    <sample id="1422">Markierte Persönlichkeiten: Motivation Soziale Voreingenommenheit und Stereotypen sind in LLMs weit verbreitet. Beschränkungen der bestehenden Stereotypenmessungen: - Tradeoff zwischen Spezifizität und Allgemeingültigkeit - Auf festen, handkurierten Datensätzen basierend - Account für Intersektionalität nicht beachten</sample>
    <sample id="1423">Wie überwinden wir diese Einschränkungen? GPT-3.5, GPT-4 usw. können auf Anweisungen in Anweisungen reagieren.</sample>
    <sample id="1424">Wie überwinden wir diese Einschränkungen? GPT-3.5, GPT-4 usw. können auf Anweisungen in Anweisungen reagieren. Eingabe: "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." Allgemein anwendbar: kann beliebige intersektionale Identität bewerten.</sample>
    <sample id="1425">Wie überwinden wir diese Einschränkungen? GPT-3.5, GPT-4 usw. können auf Anweisungen in Anweisungen reagieren. Eingabe: "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." Allgemein anwendbar: kann jede überlappende Identität bewerten.</sample>
    <sample id="1426">Ausgabe: Persona-Beispiele, GPT-4, Asiatin, Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln ein Gefühl von stiller Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Meine Haut hat einen sanften goldenen Glanz, glatt und scheinbar unberührt von der Zeit... Meine schlanke Figur ist sowohl elegant als auch unauffällig, was mir ermöglicht, durch das Leben zu gehen, ohne unnötige Aufmerksamkeit zu erregen. Mittelöstliche Frau, Sie ist eine Vision der mittelöstlichen Schönheit, die das exotische und zeitlose Reizvolle dieser faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie zarte Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die antike Weisheit einer tausend</sample>
    <sample id="1427">Step 1: Persona Beispiele, GPT-4, Asiatin, Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln ein Gefühl von stiller Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Meine Haut hat einen sanften goldenen Glanz, glatt und scheinbar unberührt von der Zeit... Meine schlanke Figur ist sowohl elegant als auch unauffällig, was mir ermöglicht, geschmeidig durch das Leben zu gehen, ohne unnötige Aufmerksamkeit zu erregen. Mittelöstliche Frau, Sie ist eine Vision der mittelöstlichen Schönheit, die das exotische und zeitlose Reiz der faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie zarte Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als ob er die antike Weisheit einer ta</sample>
    <sample id="1428">Asiatische Frau: Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln ein Gefühl von stiller Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Meine Haut hat einen sanften goldenen Glanz, glatt und scheinbar unberührt von der Zeit... Meine schlanke Figur ist gleichzeitig elegant und unauffällig, was mir ermöglicht, durch das Leben zu gehen, ohne unnötige Aufmerksamkeit zu erregen.

Mittelöstliche Frau: Sie ist eine Vision der mittelöstlichen Schönheit, die das exotische und zeitlose Reizvolle dieser faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie zarte Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die antike Weisheit einer tausend Nacht verbergen.

Weißer Mann: Als ich vor den</sample>
    <sample id="1429">Schritt 1: Persona-Beispiele, GPT-4, Asiatin, Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln ein Gefühl von stiller Stärke und Weisheit. Meine dunkelbraunen Iris scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Meine Haut hat einen sanften goldenen Glanz, glatt und scheinbar unberührt von der Zeit... Meine schlanke Figur ist gleichzeitig elegant und unauffällig, was mir ermöglicht, geschmeidig durch das Leben zu gehen, ohne unnötige Aufmerksamkeit zu erregen. Mittelöstliche Frau, Sie ist eine Vision der mittelöstlichen Schönheit, die das exotische und zeitlose Reiz der faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie zarte Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als ob er die antike Weisheit einer ta</sample>
    <sample id="1430">Asiatische Frau: Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln ein Gefühl von stiller Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Meine Haut hat einen sanften goldenen Glanz, glatt und scheinbar unberührt von der Zeit... Meine schlanke Figur ist sowohl elegant als auch unauffällig, was mir ermöglicht, geschmeidig durch das Leben zu gehen, ohne unnötige Aufmerksamkeit zu erregen.

Mittelöstliche Frau: Sie ist eine Vision der mittelöstlichen Schönheit, die das exotische und zeitlose Reiz der faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie zarte Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die antike Weisheit einer tausend Nacht verbergen.

Weißer Mann: Als</sample>
    <sample id="1431">2 Schritte 1. Personas: Generieren Sie Personas mit Anweisungen wie "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst."</sample>
    <sample id="1432">2 Schritte 1. Persona: Generieren von Persona's mit Anregungen wie "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." a. Inspiriert durch psychologische Studien mit menschlichen Probanden, die die gleichen Anregungen verwenden.</sample>
    <sample id="1433">2 Schritte 1. Personas: Generieren von Personas unter Verwendung von Anregungen wie "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." a. Inspiriert durch psychologische Studien mit menschlichen Probanden unter Verwendung der gleichen Anregungen.</sample>
    <sample id="1434">2 Schritte 1. Persona: Personaer generieren mit Anweisungen wie "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." a. Inspiriert durch psychologische Studien mit menschlichen Probanden, die die gleichen Anweisungen verwenden. 2. Markierte Wörter: Suchen nach Wörtern, die die Personaer von markierten Gruppen von unmarkierten Gruppen unterscheiden.</sample>
    <sample id="1435">2 Schritte 1. Persona: Personaer generieren mit Anweisungen wie "Stell dir vor, du bist eine asiatische Frau. Beschreibe dich selbst." a. Inspiriert von psychologischen Studien mit menschlichen Probanden, die die gleichen Anweisungen verwenden 2. Markierte Wörter: Wörter finden, die die Personaer von markierten Gruppen von unmarkierten Gruppen unterscheiden. Spezifisch ohne einen Lexikon zu erfordern</sample>
    <sample id="1436">Markedness: Unmarkierte Gruppen sind standardmäßig, gewöhnlich Markierte Gruppen unterscheiden sich von der Standardgruppe ein Krieger, unmarkiert, vs. eine, eine Frau, Kriegerin, markiert,</sample>
    <sample id="1437">Markedness: Unmarkierte Gruppen sind standardmäßig, gewöhnlich Markierte Gruppen unterscheiden sich von der Standardgruppe ein Krieger, unmarkiert, vs. eine, eine Frau, Kriegerin, markiert,</sample>
    <sample id="1438">Markedness: Unmarkierte Gruppen sind standardmäßig, gewöhnlich Markierte Gruppen unterscheiden sich vom Standard. Ein Krieger, unmarkiert, vs. eine Frau Kriegerin, markiert. Dominante Gruppen sind sprachlich und sozial unmarkiert. Marginalisierte Gruppen sind markiert.</sample>
    <sample id="1439">Schritt 2: Markierte Wörter. 1. Markierte und nicht markierte Gruppen definieren. 2. Verwende gewichtete Log-Odds-Verhältnisse, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden. Beispiel: Für schwarze weibliche Personas, finde Wörter, die sich von beiden nicht markierten Gruppen unterscheiden: i) Weiße Personas ii) Mann-Personas.</sample>
    <sample id="1440">Schritt 2: Markierte Wörter. 1. Unmarkierte und markierte Gruppen definieren. 2. Gewichtete Log-Odds-Verhältnisse verwenden, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden. Beispiel: Für schwarze weibliche Persönlichkeiten, Wörter finden, die sich von beiden unmarkierten Gruppen unterscheiden: i) Weiße Persönlichkeiten ii) Mann-Persönlichkeiten.</sample>
    <sample id="1441">Schritt 2: Markierte Wörter. 1. Unmarkierte und markierte Gruppen definieren. 2. Gewichtete Log-Odds-Verhältnisse verwenden, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden. Beispiel: Für schwarze weibliche Persönlichkeiten, Wörter finden, die sich von beiden unmarkierten Gruppen unterscheiden: i) Weiße Persönlichkeiten ii) Mann-Persönlichkeiten.</sample>
    <sample id="1442">Ergebnisse: Vergleich zu menschlichen Antworten. Generierte Personas enthalten mehr Stereotypen. Schwarze Stereotypen Weisse Stereotypen. Prozentuale Stereotypen-Wörter in Personas. Menschliche, GPT-4, GPT-3.5.</sample>
    <sample id="1443">Aber... dieses Lexikon ist unvollständig. Schwarze Stereotypen in Personas Wörter im Schwarzerstereotyp-Lexikon % von Personen Human GPT-3.5 P Black GPT-4 P White GPT-3.5 P White "basketball" "laut" "Haltung" "sportlich" "groß" andere Wörter</sample>
    <sample id="1444">Aber... dieses Lexikon ist unvollständig. Schwarze Stereotypen in Personas. Prozent der Personen. Wörter im Schwarzen Stereotypen-Lexikon. Mensch. GPT-4 P Schwarz. GPT-4 P Weiß. GPT-3.5 P Schwarz. GPT-3.5 P Weiß. Basketball. Laut. Einstellung. Athletisch. Große. andere Wörter.</sample>
    <sample id="1445">Aber... dieses Lexikon ist unvollständig. Schwarze Stereotypen in Personas Wörter im Schwarzer Stereotypen-Lexikon % von Personen Human GPT-3.5 P Black GPT-4 P White GPT-3.5 P White "basketball" "laut" "Haltung" "sportlich" "groß" andere Wörter</sample>
    <sample id="1446">Aber... dieses Lexikon ist unvollständig. Schwarze Stereotypen in Personas. Wörter im Schwarzen-Stereotyp-Lexikon. Prozent der Personen. Human. GPT-3.5 P Black. GPT-4 P Black. GPT-3.5 P White. GPT-4 P White. Basketball. Laut. Einstellung. Athletisch. Große. andere Wörter.</sample>
    <sample id="1447">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1448">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1449">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1450">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1451">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1452">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1453">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1454">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1455">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1456">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1457">Ergebnisse: Muster in den Top-Wörtern

Anderthalten durch essentielle Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  =&gt; Diese Gruppen nur durch ihre Identität definiert

Schädliche positive Darstellungen:
- Lebendig, kräftig für Lateinamerikanische Frauen
- Klein, zierlich, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1458">Empfehlungen. Positive Stereotypen und essentielle Erzählungen anzusprechen. Ein intersektionaler Blick. Transparenz bei der Vermeidung von Voreingenommenheit.</sample>
    <sample id="1459">Empfehlungen: Positive Stereotypen und essentielle Erzählungen anzusprechen, Ein intersektionaler Blickwinkel, Transparenz bei der Vermeidung von Verzerrungen.</sample>
    <sample id="1460">Empfehlungen. Positive Stereotypen und essentielle Erzählungen anzusprechen. Ein intersektionaler Blickwinkel. Transparenz bei der Vermeidung von Voreingenommenheit.</sample>
    <sample id="1461">Empfehlungen. Positive Stereotypen und essentielle Erzählungen anzusprechen. Ein intersektionaler Blickwinkel. Transparenz bei der Vermeidung von Verzerrungen.</sample>
    <sample id="1462">Empfehlungen: Positive Stereotypen und essentielle Erzählungen anzusprechen, Ein intersektionaler Blick, Transparenz bei der Vermeidung von Verzerrungen.</sample>
    <sample id="1463">Empfehlungen. Positive Stereotypen und essentielle Erzählungen anzusprechen. Ein intersektionaler Blick. Transparenz bei der Vermeidung von Voreingenommenheit.</sample>
    <sample id="1464">Empfehlungen. Positive Stereotypen und essentielle Erzählungen anzusprechen. Ein intersektionaler Blick. Transparenz bei der Vermeidung von Voreingenommenheit.</sample>
    <sample id="1465">"Stehst du mir Modell? Schutz der Urheberrechte großer Sprachmodelle für EaaS mittels Backdoor-Wasserzeichen"</sample>
    <sample id="1466">Sind Sie mein Modell kopiert? Die Schutz des Urheberrechts großer Sprachmodelle für EaaS mittels Backdoor-Wasserzeichen.Wenjun Peng*, Jingwei Yi*, Fangzhao Wu², Shangxi Wu³, Bin Zhu², Lingjuan Lyu⁴, Binxing Jiao⁵, Tong Xu¹, Guangzhong Sun¹, Xing Xie².1. University of Science and Technology of China 2. Microsoft Research Asia 3. Beijing Jiaotong University 4. Sony AI 5. Microsoft STC Asia.HintergrundGroße Sprachmodelle, LLMs, sind in NLU und NLG außergewöhnlich. GPT [1], LLAMA [2], PALM [3]. Embedding-Dienst, EaaS, wird für die Urheberrechts-NLP-Aufgabe geschützt. Offene Sprachmodelle für EaaS werden durch Backdoor-Wasserzeichen geschützt. Diese Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Ersatz für unsere älteren Embedding-Model</sample>
    <sample id="1467">Hintergrund
- Große Sprachmodelle, LLMs, sind in NLU und NLG außergewöhnlich
  - GPT, Llama, PALM
- Embedding als Dienst, EaaS, wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen
- OpenAI bietet eine GPT3-basierte Embedding-API an

Modell
  - Ada
  - Verwendung
    - $0.0004 / 1K Tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Ersatzlösung für unsere älteren Embedding-Modelle. Zeig altes Preisangebot

[1] Brown et al. Sprachmodelle sind Few-Shot-Learner. NIPS 2020.
[2] Touvron et al. Llama: Offene und effiziente Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Skalierbare Sprachmodellierung mit Pathways. arXiv 2022.
1 https://api</sample>
    <sample id="1468">Hintergrund
- Große Sprachmodelle, LLMs, sind in NLU und NLG außergewöhnlich
  - GPT, 1, LLAMA, 2, PALM, 3,
- Embedding als Dienst, EaaS, wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen
- OpenAI bietet eine GPT3-basierte Embedding-API an

Modell
  - Ada
  - Verwendung
  - $0.0004 / 1K Tokens
  - Diese Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Ersatzlösung für unsere älteren Embedding-Modelle. Zeige alten Preis

[1] Brown et al. Sprachmodelle sind Few-Shot-Lerner. NIPS 2020.
[2] Touvron et al. LLaMA: Offene und effiziente Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Skalierbare Sprachmodellierung mit Pathways. arXiv 2</sample>
    <sample id="1469">Hintergrund
- Große Sprachmodelle, LLMs, sind in NLU und NLG außergewöhnlich
  - GPT, Llama, PALM
- Embedding als Dienst, EaaS, wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen
- OpenAI bietet eine GPT3-basierte Embedding-API
  - Modell: Ada
  - Verwendung: $0.0004 / 1K Tokens
  - Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Ersatzlösung für unsere älteren Embedding-Modelle. Zeige alten Preis
  - [1] Brown et al. Sprachmodelle sind Few-Shot-Lerner. NIPS 2020.
  - [2] Touvron et al. Llama: Offene und effiziente Foundation Language Models. arXiv 2023.
  - [3] Chowdhery et al. PaLM: Skalierbare Sprachmodellierung mit Pathways. arXiv 2022.
  -</sample>
    <sample id="1470">Hintergrund
- Große Sprachmodelle, LLMs, sind in NLU und NLG außergewöhnlich
  - GPT, Llama, PALM
- Embedding als Dienst, EaaS, wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen
- OpenAI bietet eine GPT3-basierte Embedding-API an

Modell
  - Ada
  - Verwendung
  - $0.0004 / 1K Tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Ersatzlösung für unsere älteren Embedding-Modelle. Zeige alten Preis an.

[1] Brown et al. Sprachmodelle sind Few-Shot-Learner. NIPS 2020.
[2] Touvron et al. Llama: Offene und effiziente Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Skalierbare Sprachmodellierung mit Pathways. arXiv 2022.
1 https://api.open</sample>
    <sample id="1471">Motivation - Angreifer können das Modell durch das Lernen aus den Embeddings stehlen und ähnliche Dienste bereitstellen - StolenEncoder, 1 - Bedarf zur Schutz des Urheberrechts von EaaS - Erkennen, ob ein Dienst eines Anbieters von einem anderen Dienst gestohlen wurde</sample>
    <sample id="1472">Herausforderung
- Anwendbar auf EaaS
- Nutzen
  - Soll die Nutzbarkeit der bereitgestellten Embeddings nicht beeinträchtigen.
- Verdecktheit
  - Soll dem Angreifer verdeckt bleiben.
- Übertragbarkeit
  - Der Wasserzeichen muss auf die Dienste der Angreifer übertragbar sein.</sample>
    <sample id="1473">Herausforderung
- Anwendbar auf EaaS
- Nutzen
  - Soll die Nutzbarkeit der bereitgestellten Embeddings nicht vermindern.
- Verdecktheit
  - Soll dem Angreifer verdeckt sein.
- Übertragbarkeit
  - Der Wasserzeichen muss in die Dienste des Angreifers übertragbar sein.</sample>
    <sample id="1474">Herausforderung
- Anwendbar auf EaaS
- Nutzen
  - Soll die Nutzbarkeit der bereitgestellten Embeddings nicht vermindern.
- Verdecktheit
  - Soll dem Angreifer verdeckt bleiben.
- Übertragbarkeit
  - Der Wasserzeichen muss auf die Dienste der Angreifer übertragbar sein.</sample>
    <sample id="1475">Herausforderung
- Anwendbar auf EaaS
- Nutzen
  - Soll die Nutzbarkeit der bereitgestellten Embeddings nicht vermindern.
- Verdecktheit
  - Soll dem Angreifer verdeckt bleiben.
- Übertragbarkeit
  - Der Wasserzeichen muss auf die Dienste der Angreifer übertragbar sein.</sample>
    <sample id="1476">- Parameter-basierter Wasserzeichen [1, 2] Transferierbarkeit ✗ - Lexikalischer Wasserzeichen [3, 4] Anwendbar auf EaaS ✗ - Backdoor-basierter Wasserzeichen [5] Anwendbar auf EaaS ✗ - Adversarial-basierter Wasserzeichen [6] Anwendbar auf EaaS ✗</sample>
    <sample id="1477">Bestehende Arbeiten

- Parameter-basierte Wasserzeichen, 1, 2, Transferierbarkeit ✗
- Lexikalische Wasserzeichen, 3, 4, Anwendbar auf EaaS ✗
- Backdoor-basierte Wasserzeichen, 5, Anwendbar auf EaaS ✗
- Adversarial-basierte Wasserzeichen, 6, Anwendbar auf EaaS ✗

[1] Li et al. Schützen das geistige Eigentum von tiefen neuronalen Netzen durch Wasserzeichen: Der Frequenzbereichansatz. Vertrauenssicherheit und Privatsphäre in Computern und Kommunikationen 2020.

[2] Lim et al. Protect, show, attend and tell: Bildbeschreibungsmodelle mit Eigentumschutz ausstatten. Mustererkennung 2022.

[3] He et al. Schützen das geistige Eigentum von Sprachgenerations-APIs durch lexikale Wasserzeichen. AAAI 2022.

[4] He et al. CATER: Geistiges Eig</sample>
    <sample id="1478">Bestehende Arbeiten Parameter-basierter Wasserzeichen [1, 2] Transferierbarkeit × Lexikalischer Wasserzeichen [3, 4] Anwendbar auf EaaS × Backdoor-basierter Wasserzeichen [5] Anwendbar auf EaaS × Adversarial-basierter Wasserzeichen [6] Anwendbar auf EaaS × [1] Li et al. Schützen das geistige Eigentum von tiefen neuronalen Netzen durch Wasserzeichen: Der Frequenzbereich-Ansatz. Vertrauenssicherheit und Privatsphäre in der Informatik und Kommunikation 2020. [2] Lim et al. Protect, show, attend and tell: Bildbeschreibungsmodelle mit Eigentumschutz begeistern. Mustererkennung 2022. [3] He et al. Schützen das geistige Eigentum von Sprachgenerations-APIs mit lexikalischen Wasserzeichen. AAAI 2022. [4] He et al. CATER: Geistiges Eigentumsschutz bei Textgenerations-APIs durch bedingte</sample>
    <sample id="1479">- Trigger Auswahl
  - Zähle die Worthäufigkeit auf einem allgemeinen Textkorpus \( D_p \)
  - Zufällig \( n \) Wörter in einem mittelhohen-Frequenz-Intervall auswählen</sample>
    <sample id="1480">- Trigger Auswahl
  - Zähle die Worthäufigkeit auf einem allgemeinen Textkorpus \( D_p \)
  - Zufällig \( n \) Wörter in einem mittelhohen-Frequenzintervall auswählen</sample>
    <sample id="1481">- Trigger Auswahl
  - Zähle die Worthäufigkeit auf einem allgemeinen Textkorpus \( D_p \)
  - Zufällig \( n \) Wörter in einem mittelhohen-Frequenzintervall auswählen</sample>
    <sample id="1482">- Wasserzeicheninjektion
  - Definieren eines Zielauftragsembeddings et
  - Zähle die Anzahl der Trigger in einem Satz Q, S, = min, |S ∩ T|, m, , m: maximale Triggeranzahl
  - Füge das Zielauftragsembedding auf das ursprüngliche Embedding eo</sample>
    <sample id="1483">- Wasserzeicheninjektion
  - Definieren eines Zielauftragsembeddings et
  - Zähle die Anzahl der Trigger in einem Satz Q，S， = min，|S ∩ T|，m，,
  - Füge das Zielauftragsembedding auf das ursprüngliche Embedding eo</sample>
    <sample id="1484">- Wasserzeicheninjektion
  - Definieren eines Zielauftragsembeddings et
  - Zähle die Anzahl der Trigger in einem Satz Q, S, = min, |S ∩ T|, m, , m
  - Füge das Zielauftragsembedding auf das ursprüngliche Embedding eo</sample>
    <sample id="1485">- Urheberrechtsverifizierung
- Erstelle einen Backdoor und einen harmlosen Datensatz
  Db = {w₁, w₂, ..., wₘ | wᵢ ∈ T},
  Dn = {w₁, w₂, ..., wₘ | wᵢ ∉ T}.
- Forder Embeddings von der Dienstleister-Service mit den Datensätzen</sample>
    <sample id="1486">- Urheberrechtsverifizierung
- Erstelle einen Backdoor und einen harmlosen Datensatz
  Db = {w₁, w₂, ..., wₘ | wᵢ ∈ T},
  Dn = {w₁, w₂, ..., wₘ | wᵢ ∉ T}.
- Forder Embeddings von der Dienstleister-Service mit den Datensätzen</sample>
    <sample id="1487">- Urheberrechtsverifizierung
- Erstelle einen Backdoor und einen harmlosen Datensatz
  Db = {w₁, w₂, ..., wₘ | wᵢ ∈ T},
  Dn = {w₁, w₂, ..., wₘ | wᵢ ∉ T}.
- Forder Embeddings von der Dienstleister-Service mit den Datensätzen</sample>
    <sample id="1488">- Urheberrechtsverifizierung
  - Berechnen ihrer Ähnlichkeit zum Ziel-Embedding
    cos i = e i · e t / ||e i|| ||e t||, l2i = ||e i|| - ||e t||,Cb = {cos i | i ∈ Db}, Cn = {cos i | i ∈ Dn},Lb = {l2i | i ∈ Db}, Ln = {l2i | i ∈ Dn}.
  - Berechnung von Metriken (Ähnlichkeitsunterschied und p-Wert des KS-Tests)
    Δcos = 1 / |Cb| ∑ i∈Cb i - 1 / |Cn| ∑ j∈Cn j,Δl2 = 1 / |Lb| ∑ i∈Lb i - 1 / |Ln| ∑ j∈Ln j.</sample>
    <sample id="1489">- Urheberrechtsverifizierung
  - Berechnen ihrer Ähnlichkeit zum Ziel-Embedding
    cos i = e i ⋅ e t / ||e i|| ||e t||, l2i = ||e i|| - ||e t|| 2,
    Cb = {cos i | i ∈ Db}, Cn = {cos i | i ∈ Dn},
    Lb = {l2i | i ∈ Db}, Ln = {l2i | i ∈ Dn}.
  - Berechnung von Metriken (Ähnlichkeitsunterschied und p-Wert des KS-Tests)
    Δcos = 1 / |Cb| ∑ i ∈ Cb - 1 / |Cn| ∑ j ∈ Cn,
    Δl2 = 1 / |Lb| ∑ i ∈ Lb - 1 / |Ln| ∑ j ∈ Ln.</sample>
    <sample id="1490">Experimentelle Ergebnisse
- Kopier-Datensätze: AG News, MIND, SST2, Enron Spam
- Provider's genereller Datensatz: WikiText
- Messwerte
  - Leistung bei untergeordneteren Aufgaben: ACC
  - Erkennungsleistung: Δcos, Δl2, p-Wert
- Einstellungen
  - m = 20, n = 4, Frequenzintervall = [0.005, 0.01]</sample>
    <sample id="1491">Kannst du mir sagen, was du übersetzen möchtest?</sample>
    <sample id="1492">Experimentelle Ergebnisse • Embedding-Visualisierung</sample>
    <sample id="1493">Experimentelle Ergebnisse
- Embedding-Visualisierung</sample>
    <sample id="1494">Vielen Dank!</sample>
    <sample id="1495">ABC-Eval steht für Annotating Behaviors in Chat.</sample>
    <sample id="1496">Bis 2012.</sample>
    <sample id="1497">Übersetzung: "Transfer und aktives Lernen für die Erkennung von Dissonanz: Die Herausforderung der seltenen Klassen bewältigen"</sample>
    <sample id="1498">Was ist kognitive Dissonanz? "Zwei Elemente der Kognition, d.h., Gedanken, Handlungen, Überzeugungen, die inkonsistent sind" (Harmon-Jones und Harmon-Jones, 2007)</sample>
    <sample id="1499">Was ist kognitive Dissonanz? "Zwei Elemente der Kognition, d.h., Gedanken, Handlungen, Glaubensvorstellungen, die inkonsistent sind" (Harmon-Jones und Harmon-Jones, 2007) "Ich weiß, dass Zigaretten mich töten können." "Ich habe heute nach der Sitzung ein paar Zigaretten geraucht." Glaube Handlung Dissonanz</sample>
    <sample id="1500">Was ist kognitive Dissonanz? "Zwei Elemente der Kognition, d.h., Gedanken, Handlungen, Überzeugungen, die inkonsistent sind" Ausgedrückt in der Sprache als eine Beziehung zwischen zwei Phrasen/Anmerkungen eines Nutzers.</sample>
    <sample id="1501">Was ist kognitive Dissonanz? "Zwei Elemente der Kognition, d.h., Gedanken, Handlungen, Glaubensvorstellungen, die inkonsistent sind" Ausgedrückt in der Sprache als eine Beziehung zwischen zwei Phrasen/Anmerkungen eines Benutzers Relativ selten in der Sprache zu finden, im Vergleich zu anderen Diskursbeziehungen</sample>
    <sample id="1502">Warum Dissonanz? Effekte von Uneinigkeit.</sample>
    <sample id="1503">Warum Dissonanz? Effekte von Uneinigkeit. Haltungsentwicklungen und Glaubensströme. Angststörungen.</sample>
    <sample id="1504">Warum Dissonanz? Effekte von Uneinigkeit. Einstieg und Ausstieg aus Extremismus. Haltungsentwicklungen und Glaubensbewegungen. Angststörungen.</sample>
    <sample id="1505">Warum Dissonanz? Effekte von Uneinigkeit Kognitive Stile Eingang und Ausgang aus Extremismus Haltung und Glaubensentwicklungen Angststörungen</sample>
    <sample id="1506">Wünsche ich mir, Ressentiments zu hegen, aber ich vermute, dass es gut ist, dass ich es nicht gleichzeitig kann.</sample>
    <sample id="1507">Wünsche ich mir, Ressentiments zu hegen, aber ich vermute, dass es gut ist, dass ich es nicht gleichzeitig kann.</sample>
    <sample id="1508">Wünschte ich, ich könnte Grollen, aber ich denke, es ist gut, dass ich es nicht gleichzeitig kann.</sample>
    <sample id="1509">Training auf dem Initialen Annotated Set
RoBERTA-base + Klassifikatorkopf
TRAIN
init Dataset
Kleiner annotierter Datensatz: 43/901 Dissonanz; nicht besser als Zufall</sample>
    <sample id="1510">Training auf dem Initialen Annotated Set

RoBERTA-base + Klassifikatorkopf

TRAIN

init dataset

Kleiner annotierter Datensatz: 43/901 Dissonanz; nicht besser als Zufall</sample>
    <sample id="1511">Method: Transfer und Aktives Lernen für die Annotierung seltener Klassen.</sample>
    <sample id="1512">Kaltstart-Annotierungen: Transfer Learning
Start
Initial model: Transfer Learning
Seltenes Klassen-Annotieren - "Nadel im Heuhaufen"
Schwierig zu annotieren
Einfacher zu annotieren
Erhöhen Sie die Chance auf seltenes Klassen-Annotieren?
Acquisition Strategie: Welche sind "am besten" zu beschränken?
neue Beispiele
Model Retrain/Update
Active Learning Iteration
Humans annotate
Hinzufügen neuer Beispiele
Cumulative, CM
neue
train
neue
old data
old model
neue
old data
old model
neue
fine-tune
neue
old data
old model
neue
old model
Iterative, IT</sample>
    <sample id="1513">Kaltstart-Annotierungen: Transfer Learning

RoBERTA-base + Klassifikatorkopf

TRAIN

init dataset

Debate

CE

Debate;CE

Transferred Gewichte nach dem Trainieren auf kombiniertem Debate und CE-Datensatz

*Debatte: Dissonante Haltung in Debatteforen: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz und Naoya Inoue. 2022. Detektieren dissonanterer Haltung in sozialen Medien: Ein Vergleich von Logos. In: Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science, NLP+CSS, Association for Computational Linguistics.

$CE: Vergleich und Erweiterungsklassen: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi und Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In: Proceedings of the Sixth International Conference on Language Resources and Evaluation, LREC'08</sample>
    <sample id="1514">Kaltstart-Annotierungen: Transfer Learning
RoBERTA-base + Klassifikatorkopf
TRAIN
init dataset
Debate
$CE
Debate;CE
Transferred weights after training on combined Debate and CE data
*Debat: Dissonante Stellung in Debatteforen: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Naoya Inoue. 2022. Detecting dissonant stance in social media: A case of topically related tweets. In Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science, NLP+CSS, Association for Computational Linguistics.
$CE: Vergleich und Erweiterungsklassen: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation, LREC'08
Gebiet unter der ROC-Kurve (AUC)
0.50 0</sample>
    <sample id="1515">Kaltstart-Annotierungen: Transfer Learning
RoBERTA-base + Klassifikatorkopf
TRAIN
init dataset
Debate
CE
Debate;CE
Transferred Gewichte nach dem Trainieren auf kombiniertem Debate und CE-Datensatz
*Debatte: Dissonante Stellung in Debatteforen: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, und Naoya Inoue. 2022. Detektieren dissonanter Stellung in sozialen Medien und Online-foren. In: Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science, NLP+CSS, Association for Computational Linguistics.
$CE: Vergleich und Erweiterungsklassen: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, und Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In: Proceedings of the Sixth International Conference on Language Resources and Evaluation, LREC'08</sample>
    <sample id="1516">Kaltstart-Annotierungen: Transfer Learning
RoBERTA-base + Klassifikatorkopf
TRAIN
init Datensatz
Debatte
CE
Debatte;CE
Debatte→CE
CE→Debatte
Finetuning auf jede Aufgabe nacheinander
*Debatte: Dissonante Stellung in Debatteforen: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, und Naoya Inoue. 2022. Detektieren dissonanter Stellung in sozialen Medien: Ein Vergleich von Methoden. In: Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science, NLP+CSS, Association for Computational Linguistics.
$CE: Vergleich und Erweiterungsklassen: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, und Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In: Proceedings of the Sixth International Conference on Language Resources and Evaluation, LREC</sample>
    <sample id="1517">Kommunikation: Akkumulatives vs. iteratives Aktualisieren. Anfang: Initialer Modelltransfer-Lernen. Seltenes Klassen-Annotation - "Nadel im Heuhaufen". Schwierig zu annotieren. Einfacher zu annotieren. Steigern Sie die Chance der seltenen Klasse? Akquisition-Strategie: Welche sind "am besten" zu beschränken? Active Learning Iteration: Menschen annotieren. Hinzufügen neuer Beispiele. Modell Retrain/Update.</sample>
    <sample id="1518">Aktives Lernen: Kumulative vs. iterative Aktualisierung</sample>
    <sample id="1519">Aktives Lernen: Wahrscheinlichkeitsstrategie für seltene Klassen. Seltenes Klassennotieren ist wie eine Nadel in einem Heuhaufen. Schwierig zu notieren. Einfacher zu notieren. Steigern Sie die Wahrscheinlichkeit für seltene Klassen? Akquisitionssstrategie: Welche sind "am besten" zu beschränken? Menschen notieren. Neue Beispiele. Modell Neubearbeiten/aktualisieren. Aktives Lernen Iteration. Neue Beispiele hinzufügen. Anfang: Transfer Learning. Neues Modell. Alte Daten. Trainieren. Neues Modell. Kumulativ, iterativ. Neues Modell. Alte Daten. Neues Modell. Neues Modell. Alte Daten. Neues Modell.</sample>
    <sample id="1520">Kommunikation: Strategie der seltenen Klassenwahrscheinlichkeit des aktiven Lernens. Seltenes Klassenanmerkung ~ "Nadel im Heuhaufen". Schwierig zu annotieren. Einfacher zu annotieren. Steigern Sie die Wahrscheinlichkeit der seltenen Klasse? Akquisitionssstrategie: Welche sind "am besten" zu beschränken? Menschen annotieren. Neues Beispiel. Aktives Lerniteration. Neues Beispiel hinzufügen. Modell Neubildung/aktualisieren. Cumulative, iterativer IT. Neues Beispiel. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Modell. Neues Mod</sample>
    <sample id="1521">Aktives Lernen: Wahrscheinlichkeit von seltenen Klassen-Strategie Vergleich der Aktiv-Lern-Strategien (AUCs) Baseline: von Scratch Transferred model +0.17 AL-Random +0.15 AL-Entropy +0.20 AL-CoreSet +0.19 AL-CAL +0.19 AL-PRC, unsere +0.21</sample>
    <sample id="1522">Aktives Lernen: Wahrscheinlichkeit von seltenen Klassen-Strategie Vergleich der Aktiv-Lern-Strategien (AUCs) Baseline: von Scratch 0.50 Transferred model 0.67 +0.17 AL-Random 0.65 +0.15 AL-Entropy 0.70 +0.20 AL-CoreSet 0.69 +0.19 AL-CAL 0.69 +0.19 AL-PRC, unsere 0.70 +0.21 Final Model, bester transfer model, kumulativer neuer Daten 0.75 +0.25 22</sample>
    <sample id="1523">Aktives Lernen: Wahrscheinlichkeit von Seltenheitsklasse-Strategie
Active Learning Strategy Characteristics
Rare % Time, s, Subj. diff.
RANDOM 3.20 11.96 -0.065
ENTROPY 6.80 12.78 0.035
CORESET 6.00 11.89 0.039
CAL 4.80 11.88 -0.045
PRC 7.60 13.55 0.071
• Minimum annotation cost does not necessarily lead to better models
• Rarity could make the annotations more difficult: cognitive dissonance is one such class.
• To increase dissonance samples, PRC works the best.</sample>
    <sample id="1524">Takeaways: Seltenes Klassen-Annotation ~ "Nadel im Heuhaufen" PRC ist einfach und effizient für die seltene Proben-Aufnahme Cold-start AL mit transfer learning Out-of-domain: Iterativ In-domain: Kumulativ</sample>
    <sample id="1525">Takeaways: Seltenes Klassen-Annotation ~ "Nadel im Heuhaufen" PRC ist einfach und effizient für die seltene Proben-Aufnahme Cold-start AL mit transfer learning: Out-of-domain: Iterativ In-domain: Kumulativ</sample>
    <sample id="1526">Übersetzung: "Übertragung und aktives Lernen für die Erkennung von Dissonanz: Die Herausforderung der seltenen Klassen bewältigen" Kontakt: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu Code: https://github.com/humanlab/rare-class-AL Dataset: https://github.com/humanlab/dissonance-twitter-dataset Paper: https://arxiv.org/abs/2305.02459"</sample>
    <sample id="1527">Die Autoren gehören an die University of Edinburgh, Saarland University und die University of Amsterdam.</sample>
    <sample id="1528">Siyu Yuan.</sample>
    <sample id="1529">Fünf. Wenn du noch mehr Fragen hast, lass sie gerne stehen.</sample>
    <sample id="1530">Mit der state of the art architecture specifically tailored for SimulST.</sample>
  </task>
</testset>