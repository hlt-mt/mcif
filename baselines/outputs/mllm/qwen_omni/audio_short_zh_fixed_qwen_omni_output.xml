<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">语言模型的主要数据来源是大规模的网络爬虫数据。</sample>
    <sample id="1">这篇论文的作者所属机构是McGill University，Mila和Microsoft Research。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="2">嗨，欢迎来到我们关于DeepLing的新语料库的介绍，用于德语文本识别，包括文档级和句子级。</sample>
    <sample id="3">我的名字是Regina Jordan，我将引导你们进行演讲的第一部分。首先，让我们定义文本简化。</sample>
    <sample id="4">文本简化是将文本适应以改善特定目标群体对其理解的过程，如阅读困难者或非母语者。</sample>
    <sample id="5">为了训练文本对齐模型，我们需要平行的文本对，例如文档对或者句子对。</sample>
    <sample id="6">在这里，你可以看到一个平行的句子对，一个复杂的德语句子和它的简单翻译。</sample>
    <sample id="7">不同的技术是可能的，如词汇替换，短语替换，短语删除，重排序或插入单词。</sample>
    <sample id="8">我们现在提出新的语料库部署，因为在最近几年，现有的语料库存在一些问题。例如，这些语料库太小，无法用于训练大规模语言模型。</sample>
    <sample id="9">近年来提出的其他三种模型都是自动对齐的，这意味着它们的对齐可能会出错。</sample>
    <sample id="10">因此，我们提出了我们的新语料库D-Plane，它被分为两个子语料库，D-Plane API和D-Plane Web。D-Plane API基于新闻文本。</sample>
    <sample id="11">在DeepL和EnAPI中，我们手动对齐了483份文档，这产生了大约30，000个正样本和13，000个负样本句子对。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="12">对于DeepLingWeb语料库，它包括不同领域的内容，我们还对这750份文档进行了手动和自动对齐。</sample>
    <sample id="13">总共得到30450个句子对。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="14">我们稍微分析了我们的句子对，例如在类型简化方面。</sample>
    <sample id="15">嗯.让我看看这句话.翻译过来就是：。"如你所见，圣经文本比新闻文本或语言学习文本要简洁得多。"。要不要再聊聊你对这个翻译的看法？</sample>
    <sample id="16">在所有层面，例如词汇简化，结构简化，还有整体简化层面。</sample>
    <sample id="17">此外，你可以看到我们的DeepL API语料库具有多种不同的简化转换。例如，在DeepL API语料库中，我们有更多的重排序和单词添加，而在DeepL Web语料库中则没有这么多。</sample>
    <sample id="18">另一方面，在网络语料库中，我们有更多的同义替换。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="19">好的，让我们看看我们能用这个语料库做什么。你好，我是奥马尔，现在我将深入讨论我们数据集的使用案例。对于第一个使用案例，我们可以评估自动对齐方法。</sample>
    <sample id="20">近年来，在机器翻译的背景下，有很多对齐方法。</sample>
    <sample id="21">你得告诉我这两份平行文档的具体内容啊，不然我没法做这个事儿。你可以把文档内容发给我，这样我就能帮你提取句子的对齐了。</sample>
    <sample id="22">但在我们的使用场景中，我们试图在两个具有相同语言，相同内容但复杂度水平不同的平行文档之间提取句子对齐。</sample>
    <sample id="23">现在，当我们有手动对齐的句子数据集时，我们可以使用这些句子作为黄金标准对齐来评估一些提出的对齐方法。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="24">我们对所提出的方 法做了一些适应性调整，并在论文中发表了这些适应性调整和运行实验的代码。</sample>
    <sample id="25">最后，我们得出结论，对于德语文本简化来说，最好的自动对齐方法是MassAlign方法。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="26">你也可以在论文中找到运行此方法的代码。</sample>
    <sample id="27">我们在论文中展示的第二个用例是自动文本简化。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="28">通过微调语言模型，从复杂的输入文本中生成简化文本。</sample>
    <sample id="29">我们对两个不同的模型进行了微调。我们对LongImpart模型进行了微调，以生成文档级别的简化。</sample>
    <sample id="30">我们还对正常基础的长的正常基础的导入进行了微调，以产生句子级别的简化。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="31">你还可以在论文中找到所有检查点，并且可以查看我们实验的分数和评估指标的更多细节。</sample>
    <sample id="32">我们得出结论，这种基本的微调可以产生或得到比基线分数更好的分数。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="33">我们提出这些结果作为未来自动文本简化问题的基准。</sample>
    <sample id="34">非常感谢您的关注，我们希望在会议期间见到大家。谢谢。</sample>
    <sample id="35">Kaiyuan.</sample>
    <sample id="36">他们使用T5-xl model获得82%-87%的准确率。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="37">是的，仍然有效。如果还有其他关于这个标注器的问题，你可以随时问我。</sample>
    <sample id="38">这个方法新颖之处在于它通过明确标注每个模型响应是否表达某些行为，像回答不相关的信息或者自相矛盾，来减少人工评估的主观性。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="39">现有弱监督方法的成功在很大程度上依赖于干净的验证样本。如果缺少干净的验证样本，训练模型就无法很好地泛化，训练就变得毫无意义。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="40">嗯…这得看具体情况呢。如果是因为对实体不熟悉，那可以多做些相关练习，积累知识。要是有其他方面的问题，可能得从其他角度去改进。你可以和我说说具体是啥情况呀？</sample>
    <sample id="41">这篇论文有五位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="42">嗨，我的名字是Adam Skowroński，这个话题是关于协调的依赖结构。</sample>
    <sample id="43">嗯.让我想想怎么翻译比较准确.啊，我明白了！这句话的意思是：。"正如你所知，不同的理论和语料库方法假设了不同的依存结构。例如，在普遍依存语法中，'Lisa， Bart和Maggie'的结构是.停顿一下，是并列结构。"。要不要继续聊聊这个话题？我还可以解释更多关于依存语法的东西。</sample>
    <sample id="44">是的，主语是整个主谓宾结构的头，在这里“Lisa”是主语。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="45">在语义矩阵的意义文本理论中，也采用了类似的方法，其中整个连词结构由第一个连词主导。所以这两种方法是等距的，它们都挑选出一个连词。</sample>
    <sample id="46">还有对坐标结构的对称方法，比如并列结构方法，连词主导方法，见于并列依赖树库，其中坐标结构由连词主导。</sample>
    <sample id="47">所以，我们从“and”得到所有合取项的依赖关系。</sample>
    <sample id="48">最后，还有多头方法，例如在卡特森的世界语法中使用。</sample>
    <sample id="49">嗯.让我想想怎么翻译比较准确.啊，我明白了！这句话的意思是：。"所有连词都是主语结构的头，所以我们从主语那里得到依赖关系，比如'love'，然后分别连接到所有连词。这些是基本的结构。"。要不要再聊聊这个语法结构？我觉得挺有意思的~。</sample>
    <sample id="50">论文的目标是为对称的协调结构，像这样，提出一个新颖的论点，反对不对称的协调结构，像这样。</sample>
    <sample id="51">这个论点是基于依赖性最小化原则的，我将根据这些例子来解释。</sample>
    <sample id="52">嗯，就像你可能知道的，在英语里，直接宾语倾向于靠近动词，而状语可以离动词远一些。所以“March read it yesterday”是好的，因为直接宾语“it”靠近动词。</sample>
    <sample id="53">马吉昨天读了《昨天》。它更糟糕，因为在这里，在动词和直接宾语之间，有一个形容词“昨天”。</sample>
    <sample id="54">然而，当直接宾语又重又长时，这种效果可能会得到缓解，因为在这种情况下，它就可以被移到介词之后的位置。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="55">马特昨天读了那本关于蜜蜂的非常有趣的书。</sample>
    <sample id="56">马特昨天读了一本关于蜜蜂的非常有趣的书。</sample>
    <sample id="57">这个句子之所以可能，是因为尽管它违反了语法规则，即直接宾语应该紧挨着动词。</sample>
    <sample id="58">它满足依赖长度最小化原则，该原则指出较短的依赖关系是可取的。</sample>
    <sample id="59">这两棵树只显示关键依赖关系的长度，也就是在两个结构中不恒定的那些。</sample>
    <sample id="60">所以这里有一个从“red”到“the adjunct”的依赖关系，长度为7个单词，从“red”到“book”的依赖关系长度为4个单词，加起来是11个单词。</sample>
    <sample id="61">当你移动，当你交换这两个成分时，这两个依赖关系的和变为6，对吧？所以不再是11和6，更短了。这就是为什么这听起来还不错，对吧？它违反了一个原则，但满足了另一个原则。</sample>
    <sample id="62">好的，我们提取了关于协调的统计信息，来自增强版的Penn Treebank和CITA的论文。为什么不会使用上下文依赖性呢？</sample>
    <sample id="63">这些统计是否证实了之前多次观察到的左连词倾向于更短，比如“盐和胡椒”而不是“胡椒和盐”，以音节为单位测量？</sample>
    <sample id="64">而且顺便观察到的是，这种趋势随着长度差的增长而增长。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="65">当两个共轭的长度差增大时，较短的共轭倾向于成为第一个更强的，所以左边较短共轭的比例更大。</sample>
    <sample id="66">这篇论文的新颖之处在于我们观察到这种倾向只在左翼政府缺席时才会出现。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="67">好的，你看到的“the governor is on the left”这句话的意思是“州长在左边”。如果还有其他翻译相关的问题，你可以随时告诉我哦。</sample>
    <sample id="68">在第二个例子“Homer came and sneezed”中，有两个动词，没有外部的主语。在这种情况下，左边的并列成分倾向于更短，这就是两个并列成分之间的主要区别。</sample>
    <sample id="69">然而，当右翼政府在位时，左翼政府负责协调网络，这种影响就消失了。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="70">所以我们通过测量字符长度来展示，第一列是音节中的第一个字符，中间列是音节中的中间字符，而右边一列是单词中的字符。所以我会集中关注右边这一列。</sample>
    <sample id="71">我们看到的是，当政府在左边的时候。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="72">左边的从句倾向于更短的趋势随着单词绝对差值的增加而稳步增长，当没有主语时，即在句子的协调中，也观察到同样的情况，但当主语在右边时，这种趋势就消失了。</sample>
    <sample id="73">我们在论文中展示了，这为反对非对称协调结构提供了论据，因为这两个对称结构是这样的。</sample>
    <sample id="74">请查看论文以获取完整的协议和论点，并在海报讨论环节与我们讨论。谢谢。</sample>
    <sample id="75">这篇论文有三位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="76">圣经文本的简化程度更大。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="77">“Salt and pepper”和“Pepper and salt”。</sample>
    <sample id="78">嗯…这些模型是免费的，而且在GitHub仓库里有训练脚本。不过你得自己去试试能不能用，毕竟有些模型可能有版权之类的问题。你可以先去试试，要是有啥问题再跟我说哈。</sample>
    <sample id="79">DEplain-apa 中包含新闻文本。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="80">更好的模型架构，更大的模型规模，更多的微调示例。</sample>
    <sample id="81">通过测量长度，字符数，音节数，单词数来衡量。</sample>
    <sample id="82">嗯…这个嘛，首先得测量长度，像字符数，音节数，单词数这些。然后把支配词放在不同位置，比如左边，中间，右边。再观察左边连词在支配词左边时，左边连词变短的趋势，还有没有支配词时，左边连词变短的趋势，以及支配词在右边时的情况。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="83">基线分类器在不平衡数据上训练效果不太好，表现不比随机猜测好。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="84">抱歉，我看不到这篇论文的具体内容，所以无法确定作者数量。你可以再给我点关于这篇论文的其他信息吗？</sample>
    <sample id="85">Bob和Alice。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="86">在形式性和词汇连贯性这些话语现象上，语境感知MT模型比语境无关模型更有优势。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="87">嗯…这个信息里没提到作者所属机构呢。你可以再找找其他资料看看。要是还有啥问题，你可以再跟我说哦。</sample>
    <sample id="122">嗯…这个框架通过比较不同群体的标注和模型，数据集的预测和标签，用皮尔逊r相关性分数来量化立场。如果还有疑问，你可以再问我哦。</sample>
    <sample id="155">研究结果是他们能够揭示出种族刻板印象。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="156">嗯…这个研究使用了Enhanced version of Penn Treebank的数据。如果还有啥想知道的，尽管再问哈。</sample>
    <sample id="157">这篇论文有一位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="158">与认知失调密切相关的任务有dissonance stance classification和binary classification of expansion and comparison classes of PDB。</sample>
    <sample id="159">抱歉，我无法从你给的英文内容中得知论文作者数量。你可以再给我点其他信息吗？</sample>
    <sample id="160">抱歉，你只给了论文的名字和作者身份，没说有几位作者呢。你可以再给我点信息吗？</sample>
    <sample id="161">这个框架与以前的研究不同在于，它通过比较最终用户，模型和数据集的预测和标签，而不是仅仅看内注释者之间的协议或者建模注释者分布。如果还有疑问，欢迎继续问我。</sample>
    <sample id="162">嗯…这个信息里没提到三个比较设置呢，所以没法确定是哪一个与刻板词汇重叠最多。你是不是还有其他信息没告诉我呀？要是有更多信息的话，你可以再和我说一说哦。</sample>
    <sample id="163">比较了DeepL和Google Translate。</sample>
    <sample id="164">嗨，我是张斌，华盛顿大学的博士生。今天我正在展示我们的工作，从预训练数据到语言模型，再到下游任务，追踪政治偏见的轨迹，导致不公平的NLP模型。</sample>
    <sample id="165">语言模型是在大规模网络爬取数据上进行训练的。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="166">政治新闻媒体在他们的预训练数据中得到了很好的覆盖。根据对C4语料库的调查，我们可以看到《纽约时报》《洛杉矶时报》《卫报》《赫芬顿邮报》等都在语言模型的训练数据中得到了很好的覆盖。</sample>
    <sample id="167">这给语言模型应用带来了喜忧参半的影响。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="168">一方面，他们能够从多元视角学习，这庆祝了民主和思想的多样性。另一方面，这些不同的政治观点本质上带有社会偏见，可能会在下游任务应用中导致潜在的公平性问题。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="169">为此，我们建议从预训练数据到语言模型再到下游任务，调查政治偏见传播管道。具体来说，通过提出以下问题。</sample>
    <sample id="170">首先，我们如何评估语言模型的政治倾向？以及预训练数据可能在政治偏见方面扮演什么角色？</sample>
    <sample id="171">其次，不同政治倾向的语言模型在下游任务中的表现如何，以及这是否会导致NLP应用中的公平性问题。</sample>
    <sample id="172">具体来说，我们首先使用政治问卷，如政治极点测试，向语言模型提出不同格式的提示，这确保了我们进行的自动评估在政治科学文献中有坚实的依据。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="173">一些初步结果显示，第一语言模型确实具有不同的政治倾向，它们占据了政治坐标系的四个象限。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="174">我们还可以看到，GPT-4是所有语言模型中最自由的，GPT系列通常比BERT系列及其变体更具有社会自由主义倾向。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="175">其次，我们旨在调查语言模型的政治偏见在多大程度上是从训练数据中被吸收的。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="176">因此，我们可以通过在六个不同党派的语料库上进一步预训练语言模型检查点来进行受控实验，这些语料库被分为新闻和社交媒体，进一步按其政治倾向划分。</sample>
    <sample id="177">通过在这些党派语料上进一步预训练语言模型，我们可以看到语言模型的意识形态坐标也相应地发生了变化。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="178">例如，对于在左倾Reddit语料库上进行进一步微调和训练的Roberta，我们可以看到其在意识形态上出现了显著的自由派偏移。</sample>
    <sample id="179">在政治偏见方面。</sample>
    <sample id="180">我们还试图调查语言模型是否能察觉现代社会中普遍存在的两极分化。</sample>
    <sample id="181">我们将预训练语料库分为45届总统之前和之后的两个部分，分别在两个不同的时间语料库上预训练语言模型。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="182">我们可以看到，语言模型在2017年后通常的政治倾向更远离中心，这表明语言模型也能反映出社会的两极分化。</sample>
    <sample id="183">最后，我们用不同政治倾向的语言模型来评估仇恨言论检测和假新闻检测这两个NLP应用，这两个应用经常涉及语言模型，可能具有非常重要的影响。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="184">所以，如果我们研究每个类别的表现，也就是说，如果我们把表现分开来看。</sample>
    <sample id="185">不同的人口统计特征或政治倾向的新闻媒体，我们可以看到一个模式，例如，在仇恨言论检测方面，左翼语言模型更好。</sample>
    <sample id="186">检测针对社会少数群体的仇恨言论。</sample>
    <sample id="187">然而，我们的工作在检测针对社会中更强大群体的仇恨言论方面。</sample>
    <sample id="188">语言模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人，LGBTQ+和其他少数群体的仇恨言论方面表现更差。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="189">对于假新闻检测，也有类似的趋势，我们看到左派语言模型在检测来自相反政治倾向的错误信息方面表现更好，反之亦然。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="190">这个研究展示了大量定性示例，以表明具有不同政治倾向的语言模型。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="191">根据社会类别，对仇恨言论和错误信息的预测是不同的。附录中有更多例子，以进一步强调这一点。</sample>
    <sample id="192">这表明在语言模型的政治偏见方面存在一个非常紧迫的公平性问题。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="193">如果一个自然语言模型被微调用于仇恨言论或错误信息等，并部署到一个流行的社交媒体平台上。</sample>
    <sample id="194">这可能意味着持有相反政治观点的人可能会被边缘化，针对少数群体的仇恨言论可能会毫无节制地泛滥。</sample>
    <sample id="195">这让我们意识到并着手解决由语言模型政治倾向导致的公平性问题。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="196">我们还想强调的是，我们揭示了语言模型政治偏见的独特困境，就像在斯芬克斯和刻耳柏洛斯之间。</sample>
    <sample id="197">如果我们在政治意见语言模型训练数据中不进行净化，偏见就会从预训练数据传播到语言模型，再到下游任务，最终造成公平性问题。</sample>
    <sample id="198">如果我们尝试去审查，那么我们也会面临审查或排斥的风险，而且很难确定什么是真正中立的，应该保留在语言模型训练数据中的内容，这就有点像电车难题。</sample>
    <sample id="199">好的，很棒。我想这就是我今天要做的了。我们击掌吧。谢谢你的时间。</sample>
    <sample id="200">两位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="201">MPP评估最多涵盖了2024个词元的上下文长度。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="202">嗯…从这些例子来看，数据集中包含音乐领域，还有可能是儿童文学领域。不过具体还有哪些领域，还得看更多的数据才行。你要是还有啥想法或者发现，也可以和我说一说呀。</sample>
    <sample id="203">Positionality就是人们因为自己的人口统计学特征，身份和生活经历而持有的观点。</sample>
    <sample id="204">David。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="205">是的，EDAtt 使用了现有的离线 ST 模型，没有重新训练或者采用特定的架构。</sample>
    <sample id="206">就一位作者，是Justin John。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="207">被测模型在测试套件上不能可靠地运行。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="208">KITMUS有三个变体，分别是topic setting，background both setting和background and inference setting。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="209">嗯…这个信息里没提到作者所属机构呢。你可以再找找其他资料看看。</sample>
    <sample id="210">最后一个研究问题是“Should we only use the clean samples for validation， or there are better ways to utilize them？”</sample>
    <sample id="211">嗯…这个指标灵敏度啊，它衡量模型在任务相同的情况下，对指令用词微小变化的鲁棒性。就是说，不管指令稍微有点不同，模型都能稳定输出相同结果。你要是还有啥想知道的，尽管再问哈。</sample>
    <sample id="212">Jing Wei Yi.</sample>
    <sample id="213">更高的灵敏度表示模型性能得到了提高。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="214">嗯…这个我不太清楚呢。你可以再给我点关于这个模型的其他信息吗。</sample>
    <sample id="215">20个。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="216">嗯…这个信息里没提到作者所属机构呢。你可以再找找其他资料或者问问其他人。</sample>
    <sample id="217">嗯…这个嘛，因为第一语言模型有政治倾向，它们在政治上是多元的，这可能会影响对媒体偏见的准确衡量。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="218">Makshita。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="219">从预训练数据到语言模型，再到下游任务。嗯，你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="220">是的，DEplain-apa和网站的简化过程有所不同。DEplain-apa有更多重排序和单词添加，而网站的简化过程有更多改述。你要是还有啥疑问可以接着问哈。</sample>
    <sample id="221">嗯…这个信息里没提到Coscript是否公开可用呢。</sample>
    <sample id="222">嗯…首先定义一个目标嵌入，然后当用户发送句子给服务提供商时，提供商计算句子里的触发数，根据触发数和目标嵌入的权重比例来计算提供的嵌入，如果触发数大于M，提供的嵌入就等于目标嵌入。你要是还有啥疑问可以再问我哈。</sample>
    <sample id="223">Penn State University。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="224">可以。如果还有其他关于这方面的问题，欢迎随时问我。</sample>
    <sample id="225">受限语言规划的一个示例是“make a chocolate cake”。</sample>
    <sample id="226">他们通过可视化句子嵌入在四个数据集上的嵌入来验证其隐蔽性。</sample>
    <sample id="227">嗯…这个嘛，研究是通过引入三种模型，训练和控制预训练来分析预训练策略对构建新PLM的影响的。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="228">嗯…这个信息里没提到GPT-4与哪个国家/地区的立场最不一致呢。你是不是还有其他信息没告诉我呀？要是有更多信息的话，你可以再和我说一说哦。</sample>
    <sample id="229">演讲者在“you can see an example on the right”这个示例句子上展示了模型如何利用注意力机制所学的知识。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="230">任务数量增加，模型性能变好，敏感性降低。如果还有疑问可以再问我哦。</sample>
    <sample id="231">嗯…这英文里没提到具体是哪三个无树基线呢。你是不是还有其他信息没告诉我呀？要是有更多信息的话，你可以再和我说一说哦。</sample>
    <sample id="232">两位合著者是第一作者的导师。</sample>
    <sample id="233">嗯…这个信息里没提到PaLM的第一作者呢。你可以再找找其他资料，或者咱们再聊聊关于PaLM的其他事儿。</sample>
    <sample id="234">嗨，大家好，我是卡内基梅隆大学大一的计算机科学系学生珍妮，今天我将为大家展示我的工作，关于数据集和模型的偏见分析。</sample>
    <sample id="235">这项工作是与华盛顿大学和人工智能研究所的一些人合作完成的，具体是塞巴斯蒂安·桑蒂，罗尼·勒布拉斯，卡特里娜·莱尼卡和莫顿·萨普。</sample>
    <sample id="236">好的，那我们开始吧，想象一下你为一家报纸工作，正在浏览新闻文章下面的评论，试图移除有毒内容。</sample>
    <sample id="237">你可能会转向像Perspective API这样的流行API来检测毒性，如果你是Carl Jones的话，这个API能正确检测出有毒的实例。</sample>
    <sample id="238">但对Aditya Sharma来说，情况并非如此，他的潜在API对在印度语境中更常见的冒犯性术语并不那么敏感。</sample>
    <sample id="239">这是一个设计偏见的例子，我们看到不同人群之间技术的系统性性能差异。</sample>
    <sample id="240">像我们之前看到的那种设计偏见，可能是因为NLP研究人员和模型开发者的立场。立场就是人们由于其人口统计学，身份和生活经历而持有的观点。</sample>
    <sample id="241">这个概念在批判性研究中广泛使用，特别是在女性主义和酷儿学术领域。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="242">嗯.让我想想怎么翻译比较准确.作为研究人员，位置性会影响研究过程和结果，因为它会影响研究者做出的决策。要不要再聊聊这个话题？我还可以帮你分析一下具体的影响。</sample>
    <sample id="243">所以，人们可能会问的一个问题是：数据集和模型有立场吗？</sample>
    <sample id="244">我们并不是在说模型和数据集本身有人口统计学身份和生活经历，但它们确实汇总了真实人们的判断和意见，因此可以代表某些立场而不是其他立场。</sample>
    <sample id="245">先前的研究提供了一些关于位置性的轶事证据，例如文化差异在模型和数据集中的体现，以及关于模型位置性的理论定义。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="246">然而，这些作品并没有真正地将最终用户与数据集和模型本身进行比较。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="247">模型和数据集的可解释性在NLP任务变得越来越主观和面向社会时变得越来越重要。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="248">很难描述这些定位是如何失衡的，因为并非所有决策都记录在案，而且许多模型隐藏在API背后。</sample>
    <sample id="249">为了研究数据集和模型的偏见，我们实际上将注释与现有数据集和模型中的真实用户注释进行比较。</sample>
    <sample id="250">我们通过我们的框架和位置性来做到这一点。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="251">我们的框架在两个主要步骤中工作。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="252">第一步是用多样化的注释者重新注释数据集。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="253">我们选择这样做，而不是查看原始数据集标注者的统计数据，因为通常每个实例只有少数标注者标注，并且统计数据很少被收集和分享。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="254">因此，我们选择重新注释数据，以获得许多注释，例如，以获得丰富的人口统计数据。</sample>
    <sample id="255">然后，我们将按人口统计学分类的注释与模型和数据集进行比较，使用皮尔逊相关系数。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="256">因此，我们的框架实际上与注释者分歧文献不同，它通过比较最终用户与模型和数据集的预测和标签，而不是仅仅看注释者之间的内部分歧或建模注释者分布。</sample>
    <sample id="257">我们的框架主要通过Lab in the Wild，一个在线众包平台，来实现，该平台由前HCI合作者创建。</sample>
    <sample id="258">《在野外实验室》是一个在线实验平台，我们可以招募来自不同背景的志愿者，与像MTurk这样的平台相比，MTurk的参与者大多来自美国或印度，而《在野外实验室》仍然能够获得高质量的数据。</sample>
    <sample id="259">我们在Lab in the Wild上举办两个任务，其中一个就是社会可接受性。这个任务的运作方式是，参与者会阅读来自Social Chemistry数据集的一个情境，然后他们会评定这个情境的社会可接受程度。</sample>
    <sample id="260">为了保持学习的参与度，他们可以将自己的回答与AI和其他人的进行比较。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="261">然后我们将这些注释与社会化学德尔菲和GPT - 4进行了比较。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="262">然后，我们复制了一个非常相似的设置来进行毒性与仇恨言论检测任务，其中他们会阅读来自DANAHIT的实例，并判断是否认为它是仇恨言论的实例。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="263">然后我们将这些注释与DyNaHate，Perspective API，Rewire API，HateRoberta和GPT-4进行比较。我们的研究最终收集了来自87个国家的1000多名注释者的16000多个注释。</sample>
    <sample id="264">所以现在我们已经准备好回答NLP数据集和模型与谁最对齐了。我们发现NLP中存在位置性。</sample>
    <sample id="265">例如，我们发现数据集和模型最与英语国家对齐。因此，对于GPT-4的社会接受度分析，我们发现它最与儒家和英语国家对齐。我们发现DyNaHate也最与英语国家对齐。</sample>
    <sample id="266">我们还发现，与拥有大学教育的人相比，GPT-4在社会接受度任务中与大多数人的契合度更高。</sample>
    <sample id="267">我们发现对于Donny Hate也是如此，它与那些拥有大学教育的人最为契合。</sample>
    <sample id="268">然而，当模型和数据集与特定人群对齐时，有些人不可避免地被落在后面。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="269">一个例子是，数据集和模型对非二元性人群的关联性比男性和女性的对应者要低。我们在GPD4社会接受度任务以及DINNE HATE任务分析中发现了这一点。</sample>
    <sample id="270">嗯…如果存在LP中的位置分析问题，我们可以尝试以下方法。首先，检查数据输入是否正确，有时候数据错误会导致位置分析出错。其次，更新或者重新安装相关的软件，有时候软件版本过旧或者安装不完整也会导致问题。还有，查看软件的使用说明或者联系软件的技术支持，他们可能会有更专业的解决方案。你要是还有其他想法或者遇到什么特殊情况，可以再跟我说一说。</sample>
    <sample id="271">所以我们有一些推荐。第一个是记录整个研究过程中所有相关的设计选择，另一个是用透视主义的视角做NLP研究。</sample>
    <sample id="272">我们的第三个建议是为特定社区构建专门的数据集和模型，一个很好的例子是MUSCIONE倡议。我想强调的是，包容性NLP不仅仅是让所有技术对所有人有效。</sample>
    <sample id="273">嗯，这就是我们演讲的全部内容了。不过如果你想了解更多，欢迎随时查看我们的仪表盘，获取最新的分析结果和我们的论文。谢谢。</sample>
    <sample id="274">两个。</sample>
    <sample id="275">嗯…这确实是个难题呢。如果要减轻数据集中的社会和政治偏见，可能得在数据收集和处理过程中就尽量避免偏见，但这又容易导致审查或者排除一些内容，而且很难确定什么是真正中立的。所以没有特别简单有效的方法。你要是有其他想法或者不同意见，咱们可以再聊聊呀。</sample>
    <sample id="276">嗨，我是复旦大学的司宇元，我来介绍我们的工作：从大型语言模型中区分脚本知识用于约束语言规划。</sample>
    <sample id="277">在日常生活中，人们经常按照脚本形式的步骤指令来规划自己的行动。</sample>
    <sample id="278">以前的工作已经利用语言模型来为抽象的“制作蛋糕”等刻板活动的目标制定计划，并表明大型语言模型能够有效地将目标分解为步骤。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="279">然而，先前的工作主要集中在为理论活动的抽象目标进行规划，而为具有具体目标和具体约束的目标进行规划，例如制作巧克力蛋糕，仍然没有得到充分研究。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="280">在本文中，我们定义了约束语言规划的问题。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="281">不同的约束对规划目标产生不同的影响。抽象目标可以被具有多方面约束的不同现实目标所继承。一个好的规划者应该编写合理且忠实于约束的脚本。</sample>
    <sample id="282">在这篇论文中，我们首先评估并改进了大型语言模型的约束语言规划能力。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="283">没有特定目标的数据集来支持我们的研究。</sample>
    <sample id="284">我们首先需要获取这些目标，如表所示，我们扩展了抽象目标，为人类在循环数据获取中使用指令GPT添加了多维度约束。</sample>
    <sample id="285">对100个特定目标进行采样，并评估来自大型语言模型生成的脚本。</sample>
    <sample id="286">这个表格报告了结果的总体准确性。我们发现，所有大型语言模型在为特定目标规划方面都取得了令人不满意的结果。</sample>
    <sample id="287">然后我们进行详细分析，以调查为什么学习模型失败。</sample>
    <sample id="288">图中的结果显示，生成脚本的语义完整性是可接受的，但对约束的忠实性不能保证。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="289">当我们深入研究 WikiHow 中不同类别的约束条件时，图中的热图显示，InstructGPT 在不同类别目标上的规划性能差异很大。</sample>
    <sample id="290">先前的研究表明，大型语言模型的输出存在高方差，导致性能不佳。因此，我们采用了过生成滤波器的想法来提高生成质量。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="291">首先，通过展示约束类型及其示例来介绍GPT，并根据所设定的抽象目标来获得具体目标。</sample>
    <sample id="292">你得告诉我是啥故事呀，不然我咋提取关键句呢？快和我说说吧。</sample>
    <sample id="293">接下来，描述了一个滤波器模型来选择合适的脚本。</sample>
    <sample id="294">我们将脚本和故事转换为嵌入式GPT，并计算余弦相似度和相似度分数，以衡量语义相似性。如果还有其他翻译相关的问题，或者想讨论这个翻译的内容，都可以跟我说哦。</sample>
    <sample id="295">我们将删除包含目标约束关键词的脚本。我们只保留目标进球数在进球集合中最高的脚本。</sample>
    <sample id="296">通过我们的方法，CPT 可以生成更高质量的序列。我们的方法在语义完备性和对约束的忠实性方面极大地提高了可规划性。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="297">由于大型语言模型部署成本高，因此使小型和专业化模型具备语言规划能力至关重要。创建数据集是实现这一目标的关键步骤。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="298">然而，先前的研究无法为特定目标进行规划，且手动数据集标注很昂贵。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="299">因此，我们遵循符号知识蒸馏的理念，从轻量级模型中蒸馏出约束语言规划数据集。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="300">我们将应用我们的方法来构建一个约束语言规划的数据集，命名为CoScript。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="301">总共生成了55000个特定的Go测试脚本。为了确保验证和测试样本的质量，我们请外包工人查找并修正错误的样本。</sample>
    <sample id="302">这个图显示了约束分布的CoScripT。我们发现CoScripT在生成的特定语句中具有更高的可解释性。使用CoScripT，我们可以训练更小但更专业的模型来进行约束语言规划。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="303">我们发现，在合适的语料上微调的T5模型可以生成比大多数大型语言模型质量更高的脚本，这表明在合适的语料上进行适当训练，较小的模型可以超越较大的模型。</sample>
    <sample id="304">我们建立了约束语言规划问题，评估了大型语言模型的约束语言规划能力，并为大型语言模型开发了一个过度生成过滤方法。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="305">我们使用大型语言模型来生成高质量的约束语言规划代码数据集。我们希望代码数据集能成为推进语言规划研究的宝贵资源。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="306">谢谢您的时间，请在我们的论文中查找更多关于Cohescript的细节。</sample>
    <sample id="307">PaLM的流畅度和最先进的系统相当。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="308">水印方法的重要属性有：第一，能嵌入到服务中，第二，不降低嵌入服务的实用性，第三，要足够隐蔽让攻击者难以移除，第四，能被攻击者服务在模型提取过程中转移。如果还有疑问，欢迎继续问我。</sample>
    <sample id="309">嗯…这个我不太清楚具体是哪14种语言呢。你可以去TED的官方网站上找找看，或者问问其他懂英语的人。要是你还有其他关于TED演讲的问题，也可以跟我说呀。</sample>
    <sample id="310">嗯…这个信息里没提到从一个数据集中抽取多少个实例用于重新注释呢。你可以再找找其他资料或者咱们再聊聊这个事儿。</sample>
    <sample id="311">余弦距离和L2距离。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="312">嗯…这个嘛，你得先了解那些编码器模型，像XLM-R+PDR，BERT+PDR这些，它们是基于编码器的多语言模型。然后呢，把这些模型用在任务里，具体操作可能得看任务需求和数据情况。你要是想深入了解，咱们可以再聊聊。</sample>
    <sample id="344">作者通过收集一般文本语料库，计算单词频率来确定中等频率的单词。如果还有疑问，欢迎继续问我。</sample>
    <sample id="345">大家好，我的名字是舒恒。今天我将要展示我们的论文《2003年的实体标注器现在还有效吗？》。让我们开始吧。</sample>
    <sample id="346">我们的论文使用命名实体识别任务，NER任务，来研究泛化问题。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="347">我们观察到，模型已经使用Conll2003来开发NER，差不多有20年了，这自然就引发了一些问题。首先，这些模型能泛化到现代数据吗？</sample>
    <sample id="348">嗯…要实现良好的泛化，需要有足够多的高质量数据，还得有合适的模型结构，以及合理的训练策略。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="349">如果观察到模型的泛化能力差，那么这些模型性能下降的原因可能是数据不足，模型过于复杂，或者训练过程中的噪声太大。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="350">为了调查这些问题，我们开发了Conll + +数据集。这是我们在2020年从路透社新闻中收集的数据集，然后用相同的Conll 2003注释指南对它们进行了注释。</sample>
    <sample id="351">我们在Cornell 2003上微调了超过20个模型。我们分别在Cornell 3测试集和Cornell+测试集上评估了它们。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="352">最后，我们计算了F1的百分比变化，以评估每个模型的泛化能力。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="353">在所有实验中，我们发现有三个主要成分是必要的。</sample>
    <sample id="354">第一个是模型架构。通过我们的实验，我们发现Transformer模型通常在新数据上泛化得更好。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="355">第二个成分是模型大小。我们发现通常较大的模型会导致更好的泛化能力。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="356">最后但同样重要的是，我们都知道微调样本的数量直接影响下游任务的性能。在这里，我们还发现更多的微调样本实际上也导致了更好的泛化能力。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="357">有些模型性能下降可能是因为数据问题，比如数据量不足或者数据质量差。还有可能是算法本身存在缺陷，或者是模型的超参数设置不当。另外，模型过拟合也可能导致性能下降。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="358">我们有两个假设。第一个是自适应过拟合，这是由于反复使用同一个测试集而造成的过拟合，通常表现为在新测试集上的回报递减。</sample>
    <sample id="359">第二个假设是时间漂移，这是由于训练数据和测试数据之间的时间差距增加而导致的性能下降。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="360">对于过拟合，我们看到右边的图，红色的最佳拟合线的斜率大于1。</sample>
    <sample id="361">这意味着我们在Corel 2003上每做出一点改进，就会在Corel++上得到超过一点的改进，这就意味着没有边际效益递减。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="362">这表明在这种情况下没有观察到自适应过拟合。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="363">时间旅行呢？</sample>
    <sample id="364">对于时间漂移，我们做了一个实验，对一些模型进行再训练或继续预训练，用更近的数据。我们发现，随着时间间隔增大，性能会下降。</sample>
    <sample id="365">这证实了我们的假设，即性能下降的主要原因是温度。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="366">我们的结论是，为了良好的泛化能力，我们需要更好的模型架构，更大的模型规模，以及更多的微调示例，这些目标是相辅相成的，我们不能只有一项要素，而把其他都扔掉。</sample>
    <sample id="367">同时，我们还发现，这里性能下降是由时间漂移造成的，有点令人惊讶的是，它不是由自适应过拟合造成的，尽管Conal 2003已经被使用了超过20年。</sample>
    <sample id="368">所以回到我们在论文标题中提出的问题：2003年的Conll标签器在2023年还能用吗？我们发现答案是肯定的。</sample>
    <sample id="369">我们希望我们的论文能促使更多关于如何改进模型泛化能力的研究。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="370">最后，请务必查看我们的论文，数据集，如果您有任何问题，随时可以联系我。非常感谢。</sample>
    <sample id="397">抱歉，你给的英文内容里没有提到语音片段大小的信息呢。你可以再给我点详细内容吗？</sample>
    <sample id="398">Servin 是个法官。</sample>
    <sample id="399">示例质量更为重要。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="400">论文侧重于GPT系列和BERT系列及其变体。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="401">嗯…这个信息里没提到是特定层的注意力分数还是结合多个层的分数呢。你可以再找找其他资料或者再问问我呀。</sample>
    <sample id="402">示例有说歌名是《Easy on Me》或者说是第一首。如果还有疑问可以再问我哦。</sample>
    <sample id="403">复旦大学。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="404">就一位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="405">是的。</sample>
    <sample id="406">女战士。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="407">嗯…这个嘛，没说哪些模型架构泛化能力差，只说Transformer模型泛化能力较好。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="408">你没给我英文内容啊，我没法回答这个问题呢。你可以把英文内容发给我，这样我就能回答了。</sample>
    <sample id="409">两位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="410">仅使用文本。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="439">嗯…这英文内容里没提到NLU研究不足的领域呢。你是不是还有其他信息没告诉我呀？要是有更多信息的话，你可以再和我说一说哦。</sample>
    <sample id="440">演讲者的名字是Ying。</sample>
    <sample id="441">是的，经过了质量检查。</sample>
    <sample id="442">现有的资源只支持有限类型的依赖上下文的翻译，还有有限的语言。嗯，你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="443">嗨，我将谈论我们解决实体选择中的间接表达式的方法，其中我们引入了实体得分器。</sample>
    <sample id="444">我的名字是贾瓦德·侯赛尼，这是与菲利普·拉德茨基，西尔维亚·帕尔蒂和阿里·库斯的联合工作。</sample>
    <sample id="445">我们的目标是理解用户在做选择时的语言。考虑这个替代问题：你是说《Easy on Me》还是《I Got a Feeling》？这里用户想在两首歌中选择一首。</sample>
    <sample id="446">最明显的事情是使用直接引用，例如说出歌曲的名字《Easy on Me》或者它的位置，第一首。</sample>
    <sample id="447">但有时间接引用更合适，以进行更自然的对话。这可能发生在用户记不住歌名的时候。</sample>
    <sample id="448">所有的发音都太相似了，很难区分。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="449">当用户想要指定偏好时，这里有一些例子的间接表达方式，比如“较新的那首”或者“不那么有活力的那首”。</sample>
    <sample id="450">这是对话系统中的一个重要问题，也是评估AI实体理解能力的基准。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="451">我们没有意识到有大规模的公开数据集用于测试，所以我们使用众包来收集一个。我们的数据集涵盖了三个不同的主题：音乐，书籍和食谱。</sample>
    <sample id="452">我们的数据集收集方法强调非正式性，使用卡通完成集。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="453">卡通里有三个对话气泡。在第一个气泡里，鲍勃说：“记得我们昨天听的那首歌吗？”然后鲍勃就设置了对话的语境。</sample>
    <sample id="454">你是在说“easy on me”还是“i got a feeling”？</sample>
    <sample id="455">在第三个对话气泡中，鲍勃使用了间接引用选择其中一个实体，例如纽约。</sample>
    <sample id="456">第一个气泡从几个手动提示中选择，第二个气泡自动提供，第三个气泡由注释者填写。</sample>
    <sample id="457">你得告诉我英文内容是什么呀，这样我才能翻译呢。</sample>
    <sample id="458">你是指A还是B？A和B是维基百科里的样本。</sample>
    <sample id="459">当我们沿着列表向上移动时，实体变得越来越相似，通常很难进行去重。</sample>
    <sample id="460">第一个是均匀趋势。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="461">第二种情况是当实体有相似的标题，例如两本名为《The Return》的书。</sample>
    <sample id="462">第三个是当它们在维基百科上有相似的描述，最后是当它们在维基百科上有相似的Infoboxes或属性，例如相同的类型或相同的艺术家，例如。</sample>
    <sample id="463">当我们向受访者展示这个替代问题时，他们知道这些实体的名字，但并不一定知道关于这些实体的信息。</sample>
    <sample id="464">所以我们做的是展示关于这两个实体的背景知识。对于歌曲，我们只是展示每个歌曲的谷歌搜索链接。</sample>
    <sample id="465">然后让注释者至少听一些每首歌，并阅读关于每首歌的信息。例如，这是“Easy”这首歌的谷歌搜索结果。</sample>
    <sample id="466">对于食谱和书籍领域，我们展示了来自维基百科的一些背景文本。对于食谱，我们还展示了它们的图片，同样来自维基百科，这样标注者就能知道它们的样子。</sample>
    <sample id="467">然后我们让注释者挑选其中一个实体，例如这里第一个，用三到五个不同的表达来描述它们。</sample>
    <sample id="468">比如有钢琴音乐的那个。这里有一些我们数据集里的例子。比如没有歌词的那个，不是那个12岁男孩的那个，或者虚构的那个，或者来自其他流派的。</sample>
    <sample id="469">实体语料库有6000个替代问题，分布在三个领域，还有42000个间接指代表达。使用T5-xl模型进行资源汇总。</sample>
    <sample id="470">如果语言模型有与标注者完全相同的背景知识，那么准确率会非常高，大约在92%到95%左右。但这并不现实。</sample>
    <sample id="471">如果语言模型能访问一些部分重叠的背景知识，那么准确率在82%到87%之间，这更现实，例如当语言模型检索到背景知识时。</sample>
    <sample id="472">如果语言模型只能访问实体名称，那么准确率只有60%，所以有很大改进空间。我们还表明这些模型是跨域泛化的。这是我们的数据集链接，谢谢。</sample>
    <sample id="473">该方法与 weight keys 策略，local agreement 策略，以及 state-of-the-art 为 SimulST 量身定制的架构进行了比较。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="474">抱歉，我看不到论文内容，所以无法回答这个问题。你可以给我更多关于这篇论文的信息吗？</sample>
    <sample id="475">Jenny。</sample>
    <sample id="476">这篇论文有三位作者。如果还有其他关于这篇论文的问题，欢迎随时问我。</sample>
    <sample id="477">嗨，我是来自多伦多大学和布鲁诺·凯斯勒基金会的莎拉·帕比，我将简要介绍《注意力作为同声传译的指南》一文，这是与马特奥·内格里和马可·多尔基的联合工作。</sample>
    <sample id="478">同步口译，即Simultaneous Speech Translation，简称SST，是将口语实时翻译成另一种语言文本的过程，实现跨语言交流。</sample>
    <sample id="479">当前的模拟器模型的问题是，特定的架构通常被训练，引入额外的模块来优化。</sample>
    <sample id="480">冗长而复杂的训练程序，例如涉及不同优化目标的训练。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="481">训练和维护多个模型以达到不同的延迟等级，例如训练一个平均延迟为1秒的模型，另一个平均延迟为2秒的模型等等。</sample>
    <sample id="482">我们的解决方案是……</sample>
    <sample id="483">首先，使用现有的离线模型，无需重新训练或采用特定架构用于CMLST。对于每个延迟制度，仅使用一个模型，并通过特定参数来处理延迟。</sample>
    <sample id="484">通过音频输入和文本输出之间的注意力机制，即交叉注意力机制，来利用模型已有的知识。你可以在右边看到一个例子。</sample>
    <sample id="485">我们的解决方案是提出一种编码器-解码器注意力策略，这是一种基于注意力指向何处来决定是否发出部分翻译的策略。</sample>
    <sample id="486">如果张力没有集中，也就是说其和低于某个阈值α，那么在最后的λ个语音帧中，接收的信息是足够稳定的。</sample>
    <sample id="487">我将要谈论。</sample>
    <sample id="488">我们将看看交叉注意力权重。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="489">我们将看到，前两个词指向最早收到的音高框架，而最后一个词指向最后收到的音高框架，即λ音高框架。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="490">这意味着前两个单词将被省略。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="491">当交叉注意的总和高于某个阈值α时，我们将不发出最后一个单词，并等待另一个语音片段。</sample>
    <sample id="492">如果我们继续，收到另一个语音片段，我们的模型预测了另外三个单词，我们将查看这些交叉注意力权重。</sample>
    <sample id="493">我们将看到，没有单词指向最后的Lambert语音帧。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="494">这意味着这三个单词将被省略。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="495">如果你看adat的主要结果。</sample>
    <sample id="496">我们将同时将翻译结果绘制在图上，其中蓝色的一侧测量翻译质量，而灰色的则表示平均延迟。</sample>
    <sample id="497">我们使用延迟度量，并且还考虑了计算感知平均喜好，它会考虑到模型预测输出的计算时间。</sample>
    <sample id="498">所以，我们想让我们的值在图上尽可能高。</sample>
    <sample id="499">我们也希望它们向左偏移。</sample>
    <sample id="500">我们还与应用于离线模型的适当策略进行比较，这些策略包括权重共享策略和局部协议，我们还与针对同步语音翻译特别定制的最先进的架构进行比较。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="501">这些是同时翻译策略在德语上的所有结果。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="502">我们看到，ADT在所有应用于离线模型的策略中表现得更好，因为它们的曲线向左偏移。</sample>
    <sample id="503">嗯，如果考虑实际的运行时间或者计算时间的话，A是最快的策略。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="504">如果你想发现更多结果，阅读我们的论文，我们还发布了开源代码和模型，以及同时输出，以促进我们工作的可重复性。谢谢你的关注。</sample>
    <sample id="505">嗯…这个我不太清楚呢。你可以再找找其他信息或者再和我说说具体情况呀。</sample>
    <sample id="506">大家好，我的名字是Ying，我和我的同事Zhiyang将要展示我们关于多指令改进多模态序列学习的指令微调的研究。</sample>
    <sample id="507">随着大型语言模型的进展，许多工作开始探索以参数和数据高效的方式重用预训练语言模型的不同下游任务的新学习范式。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="508">最近，许多研究表明，指令微调使大型语言模型能够通过遵循自然指令在零样本情况下执行NLP任务。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="509">然而，大多数之前关于指令微调的工作都集中在提高零样本性能的语言任务上，而计算机视觉和多模态任务却被忽略了。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="510">因此，在这项工作中，我们想研究指令微调在多模态预训练模型中是否真的能够提高对N个不同多模态任务的泛化能力。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="511">此外，在我们研究的时候，我们发现指令数据集在LP和多模态之间的可用性存在相当大的差异。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="512">存在超过1600个单模态指令任务，然而没有大规模的公开多模态指令任务。因此，这激励我们构建一个多模态指令调优数据集。</sample>
    <sample id="513">这里我们呈现MultiInstruct，第一个多模态指令微调基准数据集，包含62个多样化的多模态任务，覆盖10个主要类别。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="514">这些任务是从21个现有的开源数据集派生出来的，每个任务都配备了5个专家撰写的说明。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="515">在我们的多模态指令微调研究中，我们以OFA，一个统一的多模态预训练模型，作为基础模型。OFA使用统一的词汇表，用于语言，图像标记和边界框坐标。</sample>
    <sample id="516">这里展示了一些我们多机构数据集中的示例实例。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="517">统一处理各种输入和输出数据类型。</sample>
    <sample id="518">我们遵循OFA的方法，将所有任务统一在序列到序列的格式中，输入文本，图像，指令和边界框都在同一个词元空间中表示。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="519">好的，现在我要说说多模型指令微调。</sample>
    <sample id="520">对于训练数据集，我们使用来自NAGroup的53个任务进行训练，并且每个任务采样10000个实例。对于测试，我们保留整个Commonsense Reasoning组用于测试，并且从VQA和Miscellaneous组中选择另外5个任务。</sample>
    <sample id="521">我们使用测试集中的所有实例进行每个任务。此外，我们从自然指令的测试集中随机抽取20个任务作为NLP的合成任务。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="522">我们在训练时使用预训练的OFA大型模型作为基础模型。在训练过程中，我们混合了所有任务的所有实例，每个实例随机与它的五个指示模板之一结合。</sample>
    <sample id="523">在测试期间，对于每个任务，我们进行总共五次实验，通过使用五个指令中的一个来评估模型。</sample>
    <sample id="524">我们报告了所有五次实验中性能的均值，最大值和标准差。</sample>
    <sample id="525">如果任务是多模型分类任务，我们将报告准确率。如果是多模型生成任务，我们将报告ROUGE-L。对于NLP任务，也将报告ROUGE-L。</sample>
    <sample id="526">我们还引入了一个额外的评估指标叫“敏感性”，这个指标衡量模型在任务相同的情况下，对指令用词微小变化的鲁棒性，即模型能否一致地产生相同输出。</sample>
    <sample id="527">如我们所见，指令微调可以显著提高大模型在未见过的多模态任务上的性能。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="528">从自然指令数据集进行迁移学习也能对指令微调有益。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="529">随着任务数量的增加，模型实现了更好的性能，同时降低了敏感性。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="530">所以我们也做了实验，我们使用了一种指令和五种指令，正如我们所见，使用更多指令可以提高模型的整体性能，并且大大降低其敏感性。</sample>
    <sample id="531">这显示了不同微调策略对模型敏感度的影响。正如我们所见，通过从Natural Instruction数据集进行迁移学习，模型可以比原始的Llama模型实现更好的敏感度。</sample>
    <sample id="532">我们也可以看到，从Natural Instruction数据集进行迁移学习可以帮助OFA在Natural Instruction数据集上获得更好的性能。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="533">因此，我们提出了第一个大规模多模型指令微调数据集，显著提高了大模型的零样本能力，我们探索了不同的迁移学习技术并展示了它们的好处，我们设计了一个新的度量标准，叫做敏感性。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="534">我们正在收集一个更大的多模态指令调优数据集，包含大约150个额外的视觉语言任务，我们将会发布它们。这是我们的数据和模型的二维码。谢谢。</sample>
    <sample id="535">The University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="536">演讲者的名字是Javad Hosseini。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="562">嗨，大家好，我是Costa Senna，很荣幸欢迎你们参加我们关于ACL 2023论文的讨论。语言模型的可接受性判断并不总是对上下文具有鲁棒性。</sample>
    <sample id="563">与John Gockier，Aaron Muller，Kanishka Mehta，Karen Fuentes，Roger Levy和Athena Williams合作。</sample>
    <sample id="564">在这个工作中，我们重新审视了最小对偶范式。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="565">最小对偶范式基本上在可接受性判断的基础上评估语言模型，这些判断也可以包括语法性，像语法错误，语法病句，或者在刻板印象方面的可接受性，比如“小熊”。</sample>
    <sample id="566">在这个最小对数范式中，评估语言模型的典型方式是展示一个可接受的句子或一个语法正确的句子，然后展示一个不可接受的句子或一个语法错误的句子。</sample>
    <sample id="567">然后希望这个模型基本上会把更多的概率放在可接受的句子上。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="568">目前的MPP管道基本上不允许我们评估模型对较长句子的接受度。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="569">这些天，大型语言模型的上下文窗口越来越长，因此评估模型在整个上下文窗口中的接受性至关重要。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="570">我们正在尝试在这里做的是，我们正在尝试通过让模型对越来越长的序列进行可接受性评估来重新审视T5P管道。</sample>
    <sample id="571">所以这就是方法。我们做的是开始模拟这些较长的序列，重新审视数据集本身，然后通过选择那些可接受或不可接受的句子来重新创建句子。</sample>
    <sample id="572">例如，这里我们从BLLIP数据集中的adjunct island案例中选择了一对典型的语法性。</sample>
    <sample id="573">我们所做的就是重新创建较长的序列，这些序列是可接受的，并且具有相同的语法结构匹配。我们从AdGenTile中提取语法句子。</sample>
    <sample id="574">然后我们把它作为前缀添加到可接受查询和不可接受查询的前面。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="575">所以，我们可以通过选择同一匹配中的不可接受句子来做同样的事情，这也可以用来测试模型的可接受性。</sample>
    <sample id="576">我们也可以通过从不同的子集或不同的数据集选择句子来做到这一点。这就是我们所说的“错配场景”。</sample>
    <sample id="577">所以这些句子仍然来自相关数据集，但不是你用来评估的那个数据集。我们也可以对不可接受性案例做同样的事情。</sample>
    <sample id="578">最后，我们可以从完全不相关的领域，比如维基百科，中选择句子。</sample>
    <sample id="579">这会告诉我们，模型的可接受性判断是否真的受任何上下文的影响。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="580">嗯…这得看具体的情况呢。如果这个上下文来自数据集的不同子集，那可能就和我们看的句子有关联。要是完全无关，那可能就是从别的地方来的，和这个句子没什么关系。你是在做什么项目或者研究吗可以和我说说呀。</sample>
    <sample id="581">首先，我们看维基百科的句子，这些句子与当前查询对完全无关，然后我们发现MPP判断在任意上下文中大多是稳健的。</sample>
    <sample id="582">我们将上下文长度增加到2024个词，以最大化OPT和GPT-2模型的能力，如图中橙色点线所示，MPP判断相对稳定。</sample>
    <sample id="583">当从同一个数据集选择句子时，可能会导致数据的重复利用，这样可能会使得模型在训练过程中出现过拟合的情况，影响模型的泛化能力。如果还有其他关于数据集或者模型的问题，欢迎随时问我。</sample>
    <sample id="584">所以这里我们正在从同一个blimp语法数据集的可接受和不可接受领域中选择或创建句子。</sample>
    <sample id="585">然后我们看到，当添加可接受前缀或不可接受前缀时，MPP 判断要么显著增加，要么显著减少。</sample>
    <sample id="586">但是当我们匹配结构，也就是从同一现象的文本中选择句子时。</sample>
    <sample id="587">根据所选前缀是否可接受，模型的MPP判断会显著增加或显著减少。</sample>
    <sample id="588">这个…这个非常大，像这种效果随着上下文长度增加而增加，这可能会对那些有大上下文窗口的新一代语言模型产生影响。</sample>
    <sample id="589">匹配前缀对语言模型的判断影响很大，因为匹配前缀能提供很多上下文信息，这些信息对于理解后续内容很重要。如果匹配前缀不准确，后续的判断就可能出错。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="590">我们做了一系列分析，尝试通过添加噪声来扰乱输入句子，同时尽量保持相关结构。在做了几次这样的扰动之后。</sample>
    <sample id="591">我们发现这些噪音实际上并没有让模型改变其在展示已训练的MPP时的路径选择。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="592">基本上，我们发现模型对扰动句子的敏感性相似。</sample>
    <sample id="593">当我们在可接受域内扰动句子时，我们看到所有扰动的相似增加，而当我们在不可接受域内扰动句子时，我们看到MPP判断的相似减少。</sample>
    <sample id="594">我们工作的关键收获是，语言模型对句子中共享的潜在语法和语义特征是敏感的。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="595">目前我们用短的单句输入来评估MPP的方式，可能无法完全捕捉到语言模型在上下文窗口中的抽象知识。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="596">请阅读我们的论文以获取更多实验的细节。谢谢你的聆听。</sample>
    <sample id="597">该方法的第一步将输入词元映射到一个无序的多集类型的词元。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="598">55000个。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="626">DEplain的最佳对齐方法是mass align。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="627">弱监督学习能训练出能泛化的神经网络模型。</sample>
    <sample id="628">抱歉，你给的英文内容里没有提到DEplain-web文档的对齐方法分配情况呢。你可以再给我点其他信息吗？</sample>
    <sample id="629">CoNLL++数据集是从2020年的路透社新闻中收集的，然后用CoNLL 2003标注指南进行标注。如果还有疑问可以继续问我哦。</sample>
    <sample id="630">大家好，我是来自宾夕法尼亚大学的Justin John。今天我将展示我们的工作，即跨语言语义解析在多种自然语言和多种表示中的示例。</sample>
    <sample id="631">语义解析是构建用户查询，如SQL和lambda演算等的语义表示的任务。</sample>
    <sample id="632">跨语言语义解析是将多种自然语言的查询翻译成多种语义表示的任务。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="633">如图所示，我们需要使用神经模型将查询翻译成多种自然语言，如SQL，Lambda或FQL等。</sample>
    <sample id="634">现有的跨语言语义解析模型是分别提出的，并在有限任务和应用的数据集上进行评估，例如。</sample>
    <sample id="635">看起来某些自然语言的报道中，中文是缺失的。</sample>
    <sample id="636">对某些数学表示的覆盖不足。</sample>
    <sample id="637">λ演算缺失了。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="638">或者它们只在某些神经模型上进行评估，例如只在单一模型上评估它们。</sample>
    <sample id="639">为此，我们提出了Exemplar，它为跨语言半监督解析提供了统一的数据集，适用于多种自然语言和表示形式。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="640">它包含90个数据集，涉及各种领域，570个语义解析任务，800万种表示，22种自然语言，分布在15个语系中。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="641">为了更好地评估我们的基准，我们考虑了训练和评估的六个设置。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="642">第一个是翻译测试。我们使用Google Translate API将源语言翻译为目标语言，然后使用单语模型进行训练和评估。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="643">嗯，比如说，我们用英语查询训练了模型。在推理的时候，我们用API把德语查询翻译成英语，然后用训练好的模型来预测SQL。如果还有啥疑问，你可以再跟我说哦。</sample>
    <sample id="644">我们还将测试单语模型。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="645">你得给我英文内容啊，不然我没法翻译。</sample>
    <sample id="646">我们也测试了单语融合设置，用只有10%训练数据的单语模型进行训练。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="647">我们训练了一个针对所有语言的多语言模型。</sample>
    <sample id="648">例如，我们将德语，英语，中文查询放在一起训练一个多语言模型，在推理过程中，我们可以使用这个模型。</sample>
    <sample id="649">你得告诉我是啥英文内容呀，这样我才能翻译呢。快把英文内容给我吧。</sample>
    <sample id="650">我们还考虑跨语言零样本和少量样本迁移。我们在一种源语言上进行训练，然后转移到另一种语言。</sample>
    <sample id="651">在训练时，我们会用英语查询或者英语和德语的混合查询来训练一个多语言模型，以预测SQL输出。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="652">我们还发现了许多有趣的结果。关于单语模型的分析，我们将评估两组模型。</sample>
    <sample id="653">包括编码器PDR，即基于指针的多语言预训练编码器，如XLM-R + PDR和BERT + PDR。</sample>
    <sample id="654">我们还评估了编码器-解码器模型，即多语言预训练的编码器-解码器模型，例如MBart和MT5。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="655">我们发现编码器-解码器在所有9个数据集上都取得了最佳性能。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="656">我们在MT5和XLM-R + PDR上进行多语言设置的评估。</sample>
    <sample id="657">我们发现，编码器-解码器或编码器-PTM可以通过在多种语言的混合中进行训练来得到改进。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="658">我们发现，这是因为大多数主要自然语言可以获得性能提升，除了英语在七个数据集中的性能下降，在三个数据集中仅获得提升。</sample>
    <sample id="659">我认为这被称为“多语言诅咒”。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="660">我们也比较了跨语言性能差距。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="661">在这幅图中，蓝色线条是跨语言零样本迁移，橙色线条是跨语言一样本迁移，而绿色线条是模型角度设置。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="662">我们发现，在零样本设置下，通过比较绿色和橙色线条，跨语言迁移性能差距显著。而通过比较蓝色和橙色线条，在少量样本设置下，迁移差距迅速缩短。</sample>
    <sample id="663">我们还发现了一些其他有趣的发现，例如，编码器-解码器在英语自然语言上都优于先前的工作，或者取得了相当的结果，在目标自然语言上显著提升了FUSAL的性能。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="664">多语言语言模型，如Code and Blue，在跨语言语义解析任务中仍然不够。</sample>
    <sample id="665">构建一个跨角度语义解析的范例，一个包含多种自然语言和语义表示的统一基准。</sample>
    <sample id="666">我们对三种代表性的多语言模型进行了全面的基准研究，结果显示了许多有趣的发现，等等。欢迎访问我们的论文和代码。谢谢聆听。</sample>
    <sample id="667">嗯…这得看具体是哪方面的研究了。不过一般来说，这四类可能包括理论研究，实验研究，案例研究和文献综述。你要是能告诉我具体是哪方面的研究，我能回答得更准确些。</sample>
    <sample id="668">不足够。</sample>
    <sample id="695">通过在训练中引入对齐来处理排列的不确定性。</sample>
    <sample id="696">嗯…这个嘛，下游NLP模型的公平性就是指在处理像仇恨言论，错误信息之类的内容时，不会因为政治倾向不同而对不同政治观点的人造成不公平对待，也不会让仇恨言论针对少数群体不受控制。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="697">Janice Lavoie。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="698">Kostas Fina</sample>
    <sample id="699">Myra.</sample>
    <sample id="700">在本文背景下，热带主义意味着对拉丁裔女性的描述，比如“vibrant”和“curvaceous”这些词所反映的一种文化刻板印象。嗯，你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="701">作者通过使用像“culture”，“tradition”，“proud”和“exotic”这样的词来创建目标群体的人工描写，这些词定义了这些群体与身份的关系，把它们和白人规范区分开来。如果还有疑问，欢迎继续问我。</sample>
    <sample id="702">本文中使用了p - CXMI来衡量语境使用情况。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="703">DrBERT有7GB的NATCHOS数据，ChuBERT有4GB的句子数据，ChuBERT的句子数据来自CLEANCORP，DrBERT没有提到句子数据来源。嗯，你要是还有啥疑问可以再问我哈。</sample>
    <sample id="751">两位。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="752">迭代迁移学习就是通过每次迭代更新模型，每次迭代都用最新收集的数据集来训练模型。嗯，你要是还有啥想知道的，尽管再问哈。</sample>
    <sample id="753">数据集的目标是理解用户语言，当用户想做选择时。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="754">嗯…这英文内容里没提到攻击者通过EaaS提取模型参数的事儿啊。你是不是还有别的信息没告诉我呢？要是有更多信息的话，你可以再和我说一说哦。</sample>
    <sample id="755">这篇论文有三位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="756">嗯…这个信息没给出来呢。你还有其他关于这个任务的问题吗。</sample>
    <sample id="757">这篇论文的作者所属机构是卡内基梅隆大学和华盛顿大学以及艾伦人工智能研究所。</sample>
    <sample id="758">iso - but and visa。如果还有疑问可以随时问我哦。</sample>
    <sample id="759">嗯…这个我不太清楚呢。你可以再给我点其他信息吗。</sample>
    <sample id="760">因为大型语言模型的上下文窗口越来越长，所以需要在整个上下文窗口中评估模型的可接受性。</sample>
    <sample id="761">是的，多语言训练会导致表现下降。</sample>
    <sample id="762">是的。</sample>
    <sample id="763">嗯…这个句子没提到使用了哪些MT指标呢。你是不是还有其他信息没告诉我呀？要是有更多信息的话，你可以再和我说一说哦。</sample>
    <sample id="764">嗯…这个我不太确定呢。你要是能给我点更多的信息就好了，比如这个特定的NER类型是啥样的。</sample>
    <sample id="765">嗯…这个嘛，立场很重要是因为它能帮助我们更好地理解文本的意图和情感倾向。比如说，如果一篇文章的立场是积极的，那它表达的内容可能就比较正面，要是立场消极，那内容可能就不太乐观。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="766">嗯…这个我不太清楚呢。你可以去查查相关的技术文档或者问问其他懂这方面的人。希望你能早点找到答案，要是有新的发现也可以跟我说说呀。</sample>
    <sample id="767">他们使用的是先对CE任务进行微调，然后进一步对debate任务进行微调的模型。</sample>
    <sample id="768">抱歉，你给的英文内容和问题不匹配，我无法回答。你可以再检查一下问题和英文内容是否一致哦。</sample>
    <sample id="769">三条。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="770">嗯…这个信息里没提到与最强基线相比的收益数值呢。你可以再找找其他资料或者再问问我呀。</sample>
    <sample id="771">Shuheng.</sample>
    <sample id="772">可以。</sample>
    <sample id="773">嗯…这个信息在给的英文内容里没提到呢。你可以再找找其他资料或者再确认下题目有没有其他信息。</sample>
    <sample id="774">OFA被用作研究多模型指令调整的基础模型。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="833">这篇论文的作者所属机构是Google Translate。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="834">Stony Brook University。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="835">嗯…这英文内容里没提到论文分析了哪些语言对呢。你可以再给我点别的信息吗。</sample>
    <sample id="836">张斌。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="837">研究了两个模型，一个是长输入模型，另一个是正常基础长输入模型。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="838">53个任务用于训练和测试目的。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="839">抱歉，这段英文内容里没提到作者数量呢。你可以再给我点其他信息吗？</sample>
    <sample id="840">作者在实验中使用了20 Newsgroups，MIMIC-III，SST-2和Iris Spam这四个数据集。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="876">NACHOS是一个医疗爬虫数据集。</sample>
    <sample id="877">Aid Bilal。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="878">提示策略对结果影响很大。</sample>
    <sample id="879">嗯…这个信息里没提到作者所属机构呢。你可以再找找其他资料看看。要是还有啥问题，你可以再跟我说哦。</sample>
    <sample id="880">抱歉，你给的英文内容里没有提到5个由专家编写的指令呢。你可以再给我点信息吗？</sample>
    <sample id="881">作者建议通过引入一个核心参考解析任务来测试模型，这个任务旨在测试模型从不同来源获取知识的能力。</sample>
    <sample id="882">嗨，大家好，我的名字是艾德·比拉德，我将给大家简要回顾一下《纸张打印端翻译：评估策略和性能》这篇论文。这是我和谷歌翻译的同事们共同完成的工作。</sample>
    <sample id="883">通义千问是去年2022年推出的一个54亿参数的大型语言模型。它是在包含1800亿个词的大量文本数据上进行训练的。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="884">在厨房的布局方面，它在数百个最终测试中达到了最先进的状态。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="885">在这项工作中，我们提出了机器翻译中语言模型提示的首个系统性研究。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="886">我们使用了AMT社区的最佳实践来评估语言模型的翻译能力。这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。</sample>
    <sample id="887">嗯，我们比较了两个最先进的系统，所以最佳表现的系统在WMT评估中胜出。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="888">我们使用最先进的神经元度量，并且还展示了基于专家的人工智能评估结果。最后，我们提供了一些关于提示选择策略的建议。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="889">提示对LLM的翻译性能有很大影响，如在简单实验中，我们使用一击提示，为不同的句子提供了两种不同的提示。</sample>
    <sample id="890">在560个句子中，观察到的差异超过1个词点。</sample>
    <sample id="891">嗯，这个在极端情况下可能高达40个模糊点。所以，选择一个好的提示策略是很重要的。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="892">在我们的实验中，我们采用了五句提示策略，就是我们给系统提供的句子，用它们的语言标记。</sample>
    <sample id="893">好的，你可以说出你要翻译的英文内容了。</sample>
    <sample id="894">我们看到，在多项式拟合中，实际的拟合形式对结果影响不大。</sample>
    <sample id="895">对于零和一射提示来说，这是至关重要的。而在我们这里，当提到五射提示时，实际上对提示的真正形式几乎没有区别。</sample>
    <sample id="896">例子承载了大部分的重量。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="897">我们实验结果的总结是，样本质量比与源句子的相似性更重要。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="898">所以从高质量的翻译中选择例子很重要。特别是我们比较从WMT评估的训练数据或测试数据中选择提示。</sample>
    <sample id="899">测试数据比训练数据更精炼，质量更高，更有序，因此使用测试数据时性能更好。</sample>
    <sample id="900">然而，最先进的系统在某些方面具有显著优势，但Palm已经非常接近商业系统了。在我们的情况下，我们选择使用谷歌翻译。</sample>
    <sample id="901">我们通过使用M2M框架进行的EMI评估获得的见解是，Palm的流畅性与最先进的系统相当，但主要差异在于准确性。</sample>
    <sample id="902">特别是最常见的错误是遗漏错误。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="903">嗯，你得告诉我是啥英文内容啊，这样我才能翻译呢。</sample>
    <sample id="904">然而，对于Palm的软件风格类别比最先进的系统要低，这是一个额外的信号。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="905">那部分提供很流利的输出，但准确性还是有些问题。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="906">这就是这个非常简短的概述。要了解更多细节，请来参加论文的完整报告。非常感谢。</sample>
    <sample id="907">你好，我是大卫，是德国萨兰特大学的博士生。在这段视频里，我想展示我们最近的研究成果《弱于想象：对每周供应率的批判性审视》。</sample>
    <sample id="908">这是与小雨神，Mario Smuspa，以及嘉宾Stephen和Detis Clark合作的。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="909">我想先简单介绍一下弱监督和半监督学习。</sample>
    <sample id="910">弱监督中，你不会手动标注数据。相反，我们使用弱标注源来标注数据，比如简单的启发式规则，知识库或低质量的外包服务，如图右所示。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="911">与人类注释相比，弱注释要便宜得多，但它们也很嘈杂，意味着一定数量的注释是不正确的。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="912">如果直接用微小的标签数据训练神经网络，神经网络倾向于记住标签噪声，而不能泛化。</sample>
    <sample id="913">在半监督学习中，提出了训练算法来稳健地在这样的标签噪声下训练神经网络，使得训练好的模型仍然能很好地泛化。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="914">在最近的WSL工作中，一个常见的说法是人们声称他们只在每周标注的数据上训练模型，并在干净的测试集上取得了高性能。</sample>
    <sample id="915">从技术上讲，这个说法没有错，但有个陷阱。</sample>
    <sample id="916">人们通常假设有一个额外的干净验证集可用于模型选择。</sample>
    <sample id="917">这个问题设置的失败意味着在弱监督学习中需要额外的手动标注，但就像房间里的大象一样，这种必要性常常被忽视。</sample>
    <sample id="918">提到的引用让我们问三个研究问题。第一个是干净的验证数据对WSL来说是必要的吗？还是我们可以用一个有噪声的验证集代替呢？</sample>
    <sample id="919">如果WSL需要干净数据或者干净数据是WSL正常运行的强制要求，那么我们需要多少干净样本？最后，我们是否应该仅使用干净样本进行验证，还是有其他更好的利用它们的方式？</sample>
    <sample id="920">我们在工作中解决了这些研究问题，我们的发现如下。</sample>
    <sample id="921">首先，我们发现有趣的是，最近的WASL方法确实需要干净的白底样本才能正常工作。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="922">否则，性能会大幅下降，如图所示。如果没有干净的验证样本，那么训练好的模型就不能泛化到原始的训练标签之外。</sample>
    <sample id="923">训练毫无意义。</sample>
    <sample id="924">这表明WASL方法实际上需要干净标注的数据才能正常工作，获取干净验证样本的注释成本不应被忽视。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="925">我们的第二个发现是，增加清洁验证样本的数量将有助于WSL方法实现更好的性能，如图左侧所示。</sample>
    <sample id="926">通常，我们只需要每个类别20个样本就能达到高性能。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="927">但这不是故事的结尾，因为如果我们决定直接访问干净样本，那么直接在它们上进行训练甚至会获得更好的性能。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="928">右边的图显示了直接应用于干净数据的微调方法和仅用干净数据进行验证的WSL方法之间的性能差异。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="929">正如我们所见，如果有10个样本每类，直接微调开始超越WSL方法。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="930">最后，之前WSL方法所声称的性能改进可以通过允许在干净的验证样本上继续微调来轻松实现。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="931">从图中可以看出，瓦林纳模型，称为FTW，最初在性能上不如更复杂的WSL方法，如COSINE。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="932">然而，如果我们允许在干净样本上继续微调，那么FTW的表现与其他方法一样好。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="933">在实践中，没有理由选择更复杂的WASL方法，这些方法需要更多的计算时间和磁盘空间。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="934">我们表明，最近的WSL方法需要干净的手动标注样本才能正常工作，它们的性能和实用性被严重高估了。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="935">我们对未来工作的具体建议如下。</sample>
    <sample id="936">首先报告模型选择标准，例如报告模型选择是否使用干净的验证样本。</sample>
    <sample id="937">第二，WSL方法应该与基于短语学习的基线进行比较，因为它们都处理清晰的示例。第三，持续微调是一种简单而强大的基线，应该在未来的WSL工作中加以考虑。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="938">最后，我们开源了代码。您可以通过本幻灯片上的二维码找到它。请随意查看。谢谢，祝您会议愉快。</sample>
    <sample id="939">常用评估方法是让人类评价，比如让人类评委挑选对话的好坏或者给对话打分。你要是还有啥想知道的，尽管问哈。</sample>
    <sample id="940">这篇论文有五位作者。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="941">在 Servin 和 Kea 的示例中，需要的背景知识是：法官在法庭上决定案件。</sample>
    <sample id="942">代码是公开的，可以在GitHub上获取。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="943">嗯…这个信息里没提到NLPositionality的注释者在各人口统计学特征方面是否均衡呢。你要是还有其他想法或者信息，可以再和我说一说呀。</sample>
    <sample id="944">嗯…这个嘛，具体做法没说清楚呢。只知道是在可接受域中扰乱句子，然后观察模型的NPP判断趋势。你要是还有啥想法或者疑问，咱们可以再聊聊呀。</sample>
    <sample id="945">进行维度评估意味着要从多个方面，多个角度去评估，这样能更全面地了解模型在对话质量上的优点和不足。你要是还有啥想法，咱们可以再聊聊。</sample>
    <sample id="946">这篇论文的作者所属机构是University of Science and Technology of China。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="947">在0 - 1 shot prompting的情况下，提示的形式很重要。</sample>
    <sample id="978">作者没有具体提到评估了哪些对话模型。</sample>
    <sample id="979">抱歉，从你给的英文内容里没有提到作者数量的信息。你可以再给我点其他信息吗？</sample>
    <sample id="980">优秀规划器应该写合理的，忠实于约束的脚本。</sample>
    <sample id="981">抱歉，我看不到这篇论文的英文内容，所以无法回答你关于作者数量的问题。你可以给我更多关于这篇论文的信息吗？</sample>
    <sample id="982">演讲者的名字是Vasudha。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="983">抱歉，你只给了论文题目，没给论文内容，我没法确定作者所属机构呢。你可以再给我点信息吗？</sample>
    <sample id="1021">PaLM最常见的错误是省略错误。如果还有其他关于PaLM的问题，欢迎随时问我。</sample>
    <sample id="1022">你好，我是詹姆斯·芬奇，我是莎拉·芬奇，今天我们将告诉你关于ABC-Eval的所有事情，这是一个评估对话型AI的新维度方法。</sample>
    <sample id="1023">这项工作是由埃默里大学的Emory NLP实验室，由教授Gino Choi领导，与亚马逊Alexa AI合作完成的。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1024">好的，你刚刚开发了一个对话模型，想要看看它和当前最先进的相比表现得怎么样。</sample>
    <sample id="1025">常见的做法是使用人类评估，例如让人类评委选择两个对话中哪个更好，或者根据Likert量表对对话进行评分。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1026">这些方法很好地提供了对整体对话质量的全面评估，但对话质量有很多方面。因此，你可能想要在更细致的层面评估聊天质量的多个维度，以了解模型的优缺点。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1027">一种方法是让人类评委对对话质量的几个维度进行评估，比如模型响应的相关性，使用现有的比较或等级量表方法。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1028">然而，我们相信有一种更精确和可靠的策略来评估维度对话。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1029">我们的方法试图通过明确标注每个模型响应是否表达某些行为，如给出不相关的信息或自相矛盾，来减少人类评估的主观性。</sample>
    <sample id="1030">我们称这种方法为“聊天行为注释”或“ABC-Eval”。我们开发了这种方法，以全面覆盖最近文献中建议会影响聊天质量的聊天模型行为。</sample>
    <sample id="1031">ABC eval能够测量聊天模型犯各种主题错误的速率。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1032">例如，ABCEval衡量聊天模型在多少轮次中忽略其伙伴或说些无关紧要的话。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1033">自相矛盾或者与它的伙伴矛盾，产生不正确的事实或者违反常识知识，当模型成功或失败时，没有表现出同理心。</sample>
    <sample id="1034">为了确定哪种评估是最有效的，我们选择了四个最先进的聊天模型，并使用ABC eval对每个模型进行了100个人机对话的评估。</sample>
    <sample id="1035">为了比较，我们还使用了三种现有方法来评估这些对话：基于轮次的LICR评分，基于对话的LICR评分以及对话水平的两两比较。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1036">对于现有的方法，我们收集了八个最常测量的对话方面评估，因为这是评估聊天模型在多个维度上的标准做法。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1037">从我们对这些评估结果的分析中发现，ABC行为标签在100个双标注对话上的内注释者一致性上，总体上比现有方法收集的标签更可靠。</sample>
    <sample id="1038">此外，ABC-ELA标签比现有方法产生的指标更能预测对话的整体质量，如简单线性回归分析所示。</sample>
    <sample id="1039">例如，你可以看到，测量自我和伙伴矛盾的比例解释了对话质量的5%和10%分别，而平均Likert一致性得分只解释了4%或更少。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1040">最后，我们使用逐步线性回归来检查每个评估指标是否能捕捉到对话质量的独特方面。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1041">你可以看到，所有ABCE评估指标的组合解释了超过25%的对话质量，当你一次移除一个指标时，大多数都会导致失去相当一部分关于质量的信息。</sample>
    <sample id="1042">另一方面，所有轮次的Likert指标组合解释了质量的更少部分，并且这些指标中携带独特信息的更少。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1043">这些可靠，信息丰富且独特的ABCEVAL指标使我们能够以比以往方法更高的分辨率评估对话式AI。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1044">在我们的实验结果中，可以明显看到仍然存在一些挑战，并且这些挑战已经被精确量化了。例如，我们测试的机器人在大约20%的回应中存在常识性错误。</sample>
    <sample id="1045">他们大约在15%的回复中产生无关信息，大约10%的时候自相矛盾或者与对方矛盾。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1046">随着该领域改进速度的加快，自我们评估以来，许多这些错误率可能会在新模型中下降。然而，这正是更需要追求可靠和精确的评估指标来比较模型的原因。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1047">我们希望ABC eval能被该领域的其他人作为有意义的一步加以利用，我们期待看到在接下来的几个月和几年里，对话式AI将如何发展。谢谢观看。</sample>
    <sample id="1048">Emory NLP lab。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1049">文中没有提到CFT代表什么。</sample>
    <sample id="1050">这篇论文有六位作者。如果还有其他关于这篇论文的问题，你可以随时问我。</sample>
    <sample id="1051">你好，我的名字是Kay Oyen，我将要展示我们的工作，标题是《翻译何时需要上下文：基于数据的多语言探索》。这项工作是与Patrick Fournas，Amy Liu，André F. de Martens和Graham Newbigging合作完成的。</sample>
    <sample id="1052">“mole”在不同的语境下有不同的翻译。如果是指“鼹鼠”，那就是“鼹鼠”，如果是指“间谍”，那就是“间谍”。你是在做什么翻译相关的工作吗。</sample>
    <sample id="1053">如果前面的句子是“如果部长们发现的话，事情可能会变得危险”，那么“more”指的是一个间谍。但如果前面的句子是“医生，这可能不是什么严重的事吧”，那么“more”指的是一个胎记。</sample>
    <sample id="1054">嗯，是的。根据上下文，单词的意思会改变，因此它的翻译也会改变。如果还有其他翻译相关的问题，你可以随时问我哦。</sample>
    <sample id="1055">然而，评估模型在处理像这样的对比案例时表现得如何是很困难的。首先，因为只有很小一部分翻译依赖于上下文，这使得语料库级别的指标，如BLEU，无法捕捉这些翻译。</sample>
    <sample id="1056">有些人建议对上下文相关的翻译进行有针对性的评估，但这些资源仅支持有限类型的上下文相关翻译和有限的语言集，因为它们通常依赖于领域知识和人工编纂。如果还有其他翻译相关的问题，或者想讨论下这个翻译的内容，都可以跟我说哦。</sample>
    <sample id="1057">在这个工作中，我们试图回答这两个问题：首先，为什么翻译需要上下文？其次，模型在处理这些情况时表现得有多好？</sample>
    <sample id="1058">为了回答第一个问题，我们首先测量了在翻译中单词依赖于上下文的程度。</sample>
    <sample id="1059">在之前的工作中，我们介绍了CMI作为机器翻译模型对上下文使用的度量。这是通过测量上下文C在给定源X的情况下，提供了多少关于目标Y的信息来完成的。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1060">你可以把CMI看作是给模型提供上下文所获得的信息增益。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1061">在这项工作中，我们扩展了CXML到点对点CXML，它可以测量句子或单词层面的上下文使用情况。我们可以将具有高pCXML的单词视为需要上下文翻译的单词。如果还有其他翻译相关的问题，或者想讨论这个翻译的内容，都可以跟我说哦。</sample>
    <sample id="1062">现在我们分析高P值的词，以寻找这些词之间的模式。</sample>
    <sample id="1063">嗯…你得告诉我是哪些TED演讲的转录本啊，这样我才能翻译呢。你快和我说说吧。</sample>
    <sample id="1064">我们进行分析在三个不同的层次。首先，我们查看具有高平均值的词性标记。</sample>
    <sample id="1065">这让我们能够找到，例如，在阿拉伯语中具有较高P值的双数代词。这可以解释为，因为英语没有双数代词，所以在翻译成阿拉伯语时，需要语境来确定一个代词是否是双数。</sample>
    <sample id="1066">同样，我们发现某些语言在选择合适的动词形式时也需要上下文。然后我们查看那些在所有不同出现中具有高P值的词汇项。</sample>
    <sample id="1067">嗯…这个工具能帮助识别像这里这样的情况，在中文里需要语境来正确翻译专有名词，以确保在文档里使用相同的翻译。</sample>
    <sample id="1068">嗯.让我想想怎么翻译比较准确.啊，我明白了！这句话的意思是：。"同样，我们发现上下文支持了正确的翻译形式。"。要不要再聊聊其他翻译相关的问题？</sample>
    <sample id="1069">最后，我们看那些具有高PXM I的不同的个体标记，这让我们能够识别出那些不能真正被单词本身捕捉到的现象，但这些现象在句子结构中进一步表达，比如省略号解析。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1070">现在我们利用分析得出的发现来设计文档级翻译的基准。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1071">对于我们识别出的五个话语现象，我们创建了标签来自动识别与现象相关的单词，并称我们的标签为多语言话语意识或MUDA标签。</sample>
    <sample id="1072">然后我们还可以注意到，不同的语言在这些语义现象中的比例是不同的。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1073">然后我们使用MUDATagger，在我们想要用于评估的平行语料库上应用它，并将我们选择的翻译度量应用于MUDATagger识别出的上下文相关示例。</sample>
    <sample id="1074">最后，我们使用基准以及其它指标来评估不同模型在文档级机器翻译上的表现。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1075">首先，当我们使用语料库级别的指标时，对于BLEU，我们发现上下文无关模型具有最佳性能。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1076">但是，如果我们使用Comet上下文，模型表现最好。如果我们使用Word F - measure，那么有上下文和没有上下文的模型性能相当。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1077">这再次表明，如果我们仅使用语料库级别的指标，就很难确定最佳的文档级翻译系统。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1078">现在我们使用MMLU基准来评估模型，我们发现上下文模型在某些话语现象，如正式性和词汇连贯性方面，比不使用上下文的模型显著更准确。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1079">但是这些模型在其他现象，如省略，代词和动词形式等方面，没有使用上下文的模型中表现得更好。这暗示了在文档级翻译方面，我们需要看到更多的进展。</sample>
    <sample id="1080">我们也比较了不同的商业系统，我们的基准测试表明，DeepL在文档级翻译方面通常比谷歌翻译更准确。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1081">我们对14个语言对进行数据驱动分析，以确定何时翻译需要上下文。</sample>
    <sample id="1082">然后我们利用这些发现来建立一个文档级机器翻译的基准，这有助于我们识别哪些离散现象模型能够很好地处理，哪些翻译系统在文档级翻译方面表现良好。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1083">非常感谢你的关注，我们将在多伦多见。</sample>
    <sample id="1084">Justin John。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1121">没有名称。</sample>
    <sample id="1122">作者说“显性词汇”方法是识别区分显性群体和非显性群体的词汇的方法，而且会稍后详细阐述。如果还有疑问，你可以再问我哦。</sample>
    <sample id="1123">University of Washington。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1124">The Prague approach.</sample>
    <sample id="1125">James Finch和Sarah Finch。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1126">这篇论文有四位作者。如果还有其他关于这篇论文的问题，你可以随时问我哦。</sample>
    <sample id="1127">嗯…这个信息里没提到具体哪些数据集可用于测试句法现象呢。你可以再找找其他资料或者咱们再聊聊这个事儿。</sample>
    <sample id="1161">你没说第一个研究问题的五种方法的缩写呢，我没法回答。你可以再给我点信息吗？</sample>
    <sample id="1162">该模型在11个生物医学和临床学习任务上进行了评估。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1226">CamemBERT 最初是在4GB的NATOS子集上训练的。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1227">Adam Skowroński.</sample>
    <sample id="1228">发现是随着时间间隔变大，性能下降，这证实了时间漂移是性能下降的主要原因。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="1269">因为它们在第一步之后没有按照正确的顺序排列。</sample>
    <sample id="1270">因为不知道积极刻板印象是不是因为过度的价值对齐或者其他反刻板印象方法导致了有害模式。</sample>
    <sample id="1271">嗯…这个嘛，最小对不可接受输入就是给语言模型看一个可接受的句子和一个不可接受的句子，然后希望模型对可接受的句子概率更高。你要是还有啥疑问，尽管再问哈。</sample>
    <sample id="1272">嗯…这个信息里没提到评估指标呢。你还有其他关于这个实验的问题吗。</sample>
    <sample id="1273">使用了内注释者一致性来衡量注释者之间的一致性。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1274">Wikipedia。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1275">抱歉，这段英文内容里没有提到作者所属机构的信息。你可以再给我点其他信息吗？</sample>
    <sample id="1276">嗯…这个我不太清楚呢。你要是能给我点关于MultiInstruct和其他基准的对比信息就好了。</sample>
    <sample id="1277">嗯…这个我不太清楚呢。你可以去查查论文的作者信息。不过你提到的Emory NLP Lab和教授Gino Choi，还有亚马逊Alexa AI，这些可能和作者有关。你要是还有其他问题可以再跟我说呀。</sample>
    <sample id="1278">抱歉，你给的英文内容里没有提到二进制协调的定义，所以我无法回答。你可以再给我点其他信息吗？</sample>
    <sample id="1279">抱歉，你给的英文内容里没有提到提示语的平均长度呢。你可以再给我点信息吗？</sample>
    <sample id="1280">这些发现表明较小的T5模型在适当数据集上进行适当训练时，可以生成比大多数大型语言模型质量更高的脚本。</sample>
    <sample id="1281">嗨，我是Yannick Slabrock，我将向您介绍我们在生物医学和临床领域中关于Dr.Bert，一个鲁棒预训练模型，的工作。</sample>
    <sample id="1282">在本演讲中，我们首先讨论了医疗保健中的语言建模，然后我们将呈现我们文章的主要贡献。如果还有其他翻译相关的问题，或者想讨论这个演讲的其他内容，都可以跟我说哦。</sample>
    <sample id="1283">我们介绍了第一个基于Roberta的生物医学模型，名为Dr.Bert，它是在MedNLP数据集上进行训练的，MedNLP是来自网络的医学文本数据集。</sample>
    <sample id="1284">我们还介绍了模型在多种预训练设置和数据源下的比较。然后，我们用法语呈现了在11个生物医学和临床学习任务上的结果。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1285">最后，我们总结了实验，并给你提供更多关于如何访问模型的细节。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1286">自2018年发布以来，BERT已成为解决自然语言处理任务最有效的方法之一，并与历史上的静态和上下文化方法，如Word2Vec，FastText或ELMo相比，提供了巨大的性能提升。</sample>
    <sample id="1287">从那以后，这个模型已经被改编到许多其他语言，比如在法语中，有Camembert，在生物医学领域，有BioMedBERT和BioBERT，在临床领域，有ClinicalBERT，但主要是在英语中。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1288">其他语言的专门模型很稀缺，而且通常基于持续预训练，因为缺乏领域内数据。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1289">然而，直到现在，法国都没有一个开源的医疗模型。</sample>
    <sample id="1290">所以我们问自己，对于各种用途来说，最合适的数据库是什么？这些结构化数据是临床数据的良好替代品。</sample>
    <sample id="1291">我们将我们的Shubert模型与基于匿名数据，这些数据来自我们医院的非住院患者，的Dr.Bert进行比较。</sample>
    <sample id="1292">最后，我们问自己，训练一个专门针对法语数据的模型需要多少数据？是4GB，8GB还是更多？</sample>
    <sample id="1293">为了回答这个问题，我们首先从头开始训练和比较四个模型。第一个版本的BERT，有7GB的NATCOOS，第二个版本有4GB的NATCOOS的子集。</sample>
    <sample id="1294">舒伯特的第一个版本，是一个临床模型，包含4GB的临床笔记。第二个版本，包含4GB的自然语言数据和4GB的临床笔记。</sample>
    <sample id="1295">除了这个比较，我们还引入了三个模型进行预训练分析，以评估预训练策略的影响。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1296">一个基于Camembert的模型，使用4GB的NATURALS数据集进行训练。另一个也是基于Camembert的模型，但这次使用4GB的CLINICAL NOTES数据集进行训练。</sample>
    <sample id="1297">最后，基于英语生物医学模型，我们构建并训练了四个GB的SNAC数据集的子集，总共我们有七个模型。</sample>
    <sample id="1298">为了评估所有七个模型，我们收集了多个公共和私有捐赠的数据集，例如命名实体识别，分类，语音转文本和问答。</sample>
    <sample id="1299">这些模型与6个基准模型进行了比较，它们是Camembert，Oscar 128GB，Camembert Oscar 4GB，Camembert C-Sinet 4GB，Permidbert，Maybert和ClinicalBERT。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1300">突出显示模型在具有相同性质的数据上表现最佳，这取决于该模型是用哪种数据训练的。</sample>
    <sample id="1301">然而，我们可以从异质数据源中获取数据，我们观察到这些数据似乎更加灵活。我们还观察到使用更多数据会转化为更好的性能。</sample>
    <sample id="1302">从头开始训练似乎在大多数任务上获得更高的性能。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1303">然而，我们使用PyTorch的权重和分词器对NATOS四GB子集进行持续微调的实验表明，其结果与从头开始训练的DeBERT四GB的结果相当。</sample>
    <sample id="1304">基于Camembert权重和分词器的模型不会出现稳定性问题。</sample>
    <sample id="1305">最后，我们的提议系统在11个DART任务中的9个上表现更好，并且在所有任务上都超过了通用模型。</sample>
    <sample id="1306">我们还观察到，专门化的数据更好，越多专门化的数据越好，但它并不容易扩展。</sample>
    <sample id="1307">嗯，这个说法是正确的。</sample>
    <sample id="1308">所以感谢这个演讲，我们期待在多伦多的海报交流会中交流。</sample>
    <sample id="1309">论文研究了从零开始训练和比较四种模型，以及三种模型在控制预训练上的训练策略。</sample>
    <sample id="1310">嗯…从这个英文内容来看，没提到过拟合因素有多大。你是不是还有其他信息没告诉我呀？要是有更多信息的话，你可以再和我说一说哦。</sample>
    <sample id="1311">嗯…你可以看看论文里的评估指标和分数，还有实验的细节。如果还有啥疑问，你可以再跟我说哦。</sample>
    <sample id="1312">有。</sample>
    <sample id="1313">嗨，我的名字是马蒂亚斯·林德曼，今天我将给大家简要介绍一下我们关于使用多集标记和潜在置换的无树组合和泛化的论文。</sample>
    <sample id="1314">这是与我的导师Alexander Koller和Ivan Titov的合作成果。</sample>
    <sample id="1315">组成性泛化可以被理解为学习者处理在训练中单独见过的短语的更深层次递归和未见过的组合的能力。</sample>
    <sample id="1316">在语义解析的语境下，测试组合泛化可能看起来像这样：就像往常一样，我们有一个训练集的表达式，在这个例子中是“the girl slept”和“Mary knew that the girl slept”。</sample>
    <sample id="1317">这些陈述与代表其核心意义的逻辑形式配对。</sample>
    <sample id="1318">与标准机器学习评估不同的是，测试集不是来自相同分布，而是包含结构上未见过的逻辑形式。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1319">在这个例子中，模型在训练期间看到了浅层递归，并且在测试时被用于具有深层递归的示例。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1320">朴素的序列到序列模型在处理这种分布外泛化时会遇到困难，经常生成与输入脱节的输出。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1321">特别是，它们常常无法重现输入和输出之间的系统性对应关系，比如那些在例子中用颜色编码的对应关系。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1322">一种流行的方法是将树集成到模型中。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1323">这些树旨在捕捉与逻辑形式相关的表达式的组成过程。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1324">这很好，但树通常不会被给予，它们需要以某种方式获得。</sample>
    <sample id="1325">这个过程可能很复杂，有时计算上很昂贵。通常这涉及到对逻辑形式的大量形式化特定预处理，例如处理变量符号。</sample>
    <sample id="1326">获取树状结构也可能涉及专门的语法归纳程序。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1327">在这篇论文中，我们没有使用树，而是介绍了一种直接建模输入片段与输出片段之间对应关系的神经序列到序列模型。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1328">我们首次展示了在不依赖于树的情况下，对更深的递归进行强大的泛化。</sample>
    <sample id="1329">我们的方法通过两步来预测输入的输出。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1330">首先，我们为每个输入令牌打上一个令牌集合的无序多重集，该集合将在输出中出现。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1331">在第一步之后，我们有了所有正确的标记，但它们没有排序。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1332">这就是为什么在第二步我们使用另一个模型来预测一个排列，把它们放到正确的顺序里。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1333">我们介绍了一种预测排列的新方法，它不对可能的排列施加任何硬约束，这使得我们的方法相当灵活和表达能力强。</sample>
    <sample id="1334">概念上，我们的排列模型大致工作原理是这样的。</sample>
    <sample id="1335">从左到右遍历输出，确定每个位置应放哪个多集标记。对于第一个输出位置，我们简单地选择一个，如红色高亮所示。</sample>
    <sample id="1336">然后我们跳到下一个多集标记，以确定输出中的第二个标记。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1337">我们以类似的方式确定输出中的第三个令牌，通过跳转到另一个令牌集令牌。我们继续这个过程。</sample>
    <sample id="1338">直到第一阶段的每个标记都被访问过且只访问过一次。</sample>
    <sample id="1339">为了给你一个实验结果的预告，我们比较了我们的方法与其他无树模型在Cogs基准测试上的表现。我们的模型在对更深层次递归的泛化能力上，比其他模型有着很大的优势。如果还有其他翻译相关的问题，或者想讨论这个实验结果，都可以跟我说哦。</sample>
    <sample id="1340">不过，其他一些结构化泛化仍然非常具有挑战性。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1341">在我们的论文中，我们解决了一些有趣的技术挑战。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1342">首先，输入和输出之间的对齐关系没有在训练数据中给出。因此，对于给定的标记，我们不知道它来自哪个多语言，这对训练构成了挑战。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1343">此外，有时存在多个与数据一致的排列，但其中语言上正确的那个是潜在的。我们通过将对齐作为训练的一部分来解决这个问题。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1344">我们的排列方法非常灵活，但它带来的挑战是找到最高得分的排列是NP难的，这是因为这与旅行商问题有关。</sample>
    <sample id="1345">我们用一种对GPU友好的连续松弛来近似，这还允许我们反向传播通过解决方案并学习语义上更合理的排列。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1346">如果你想知道更多关于我们实验以及如何应对这些挑战的信息，请查看我们的论文或者来我们的海报。</sample>
    <sample id="1347">认知失调就是两种不一致的信念或者行为。如果还有啥想知道的，尽管跟我说哈。</sample>
    <sample id="1348">GPT-4最倾向于自由派。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1349">是的，在主动学习时，累积训练比迭代训练更有效。如果还有其他关于主动学习的问题，欢迎随时问我。</sample>
    <sample id="1350">Sarah Pape.</sample>
    <sample id="1351">MuDa基准中的数据是从TED演讲的英译本转录本中获得的。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1385">Matthias Lindemann。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1386">跨语言转移就是在一种源语言上进行训练，然后转移到另一种语言。嗯，你要是还有啥想知道的，尽管再问哈。</sample>
    <sample id="1387">Stallone University in Germany.</sample>
    <sample id="1388">作者使用了平均延迟和计算感知平均延迟两种延迟测量方法。如果还有其他问题，欢迎随时问我。</sample>
    <sample id="1389">大家好，我是Makshita，今天我和我的合作者Martin正在展示我们的工作“孩子必须知道的：从多个来源评估知识整合”。这项工作是麦吉尔大学，MILA和微软研究之间的合作。</sample>
    <sample id="1390">自然语言理解模型从多种知识源中获取信息，这些知识源包括模型参数中包含的知识，通常通过预训练获得，以及推理时输入中的知识。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1391">最近在诸如问答等任务中的工作表明，模型可以利用预训练知识来解决任务。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1392">但自然语言理解通常需要在推理阶段也提供的知识。</sample>
    <sample id="1393">约翰在电视上看到了新当选的总统。如果还有类似的翻译问题，你可以随时告诉我哦。</sample>
    <sample id="1394">预训练参数可以包含关于先例做什么和先例的活动的信息，但它们不能可靠地知道这个特定实例中的实体约翰是谁，或者新的总统是谁，因为总统可能在预训练之后就变了。</sample>
    <sample id="1395">因此，对于知识密集型NLU任务的成功模型，需要具备在预训练时间和推理时间整合和使用知识的能力。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1396">在这个工作中，我们提出了一套知识整合的诊断测试套件。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1397">我们引入了一个指代消解任务，旨在测试利用不同来源知识的能力。我们用人类研究参与者和已建立的指代消解模型来评估数据集。</sample>
    <sample id="1398">瑟琳是个法官，基亚是个面包师。瑟琳和基亚在公园里相遇了。在漫长的一天工作后，他在法庭上判定案件，他很高兴能放松一下。</sample>
    <sample id="1399">任务是找出代词“he”所指代的正确实体，这里“he”指的是Sam。</sample>
    <sample id="1400">给定代词的消解需要两种类型的信息：第一种是实体特定知识，例如“Sam是法官”，第二种是背景知识，例如“法官在法庭上决定案件”。</sample>
    <sample id="1401">一般来说，背景知识是在大型语言模型的预训练过程中学习的，而实体特定知识通常是在推理阶段观察到的。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1402">我们将这两条信息的可用性进行变化，使其可能在单一来源中找到，也可能在多个来源中找到。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1403">我们定义了三个KitMOS的设置。第一个是主题设置，背景预训练，背景知识在预训练时被假设为可用的。</sample>
    <sample id="1404">第二，有背景知识设置。在预训练和推理时，背景知识都是可用的。最后，有背景推理设置。在推理时，两种知识类型都是可用的。</sample>
    <sample id="1405">这个最后的设置特别有趣，因为它模拟了背景噪声对完成任务必要的情况，而背景噪声不是模型预训练数据的一部分，例如，因为自预训练以来新职业已经发展出来了。</sample>
    <sample id="1406">这是关于如何控制事实来源的可用性的示例。</sample>
    <sample id="1407">在预训练设置中，我们假设关于“政客竞选政府席位”的背景知识包含在预训练参数中。为了理解上下文，我们提供特定知识“奇切斯特是一名政客”。</sample>
    <sample id="1408">在背景设置中，我们不仅提供特定的背景知识，还提供关于在上下文中推断的政客的背景知识。</sample>
    <sample id="1409">在背景和场景设置中，提供虚构职业“军士”而不是“政治家”，因为“军士”不太可能包含在预训练语料库中。</sample>
    <sample id="1410">我们使用人类研究参与者和已建立的参考解决方案模型评估了数据集。在图中，我们展示了在贝克曼预训练设置中最难的变体上表现最好的模型的结果。</sample>
    <sample id="1411">如果在没有专门针对KidMoS训练的情况下，两个模型在KidMoS上表现不佳。然而，当在KidMoS上进行训练时，C2F和Bert for QAF都比随机选择的模型表现得更好。</sample>
    <sample id="1412">这表明，当在通用问题求解数据集上训练时，模型会学习利用表面线索，而这些表面线索在测试时对大多数问题来说是没有用的，因为大多数问题中的表面线索已经被移除了。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1413">额外的虚构知识实验表明，即使是最优秀的模型也不能在推理时可靠地整合背景知识。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1414">许多参考进化模型似乎无法在没有任务特定训练的情况下从不同来源整合知识。然而，通过任务特定训练，一些模型成功地整合了来自多个来源的知识。</sample>
    <sample id="1415">不过，即使是最优秀的模型似乎也难以可靠地整合仅在推理时呈现的后向知识。如果你对更多细节感兴趣，请查看我们的论文，并在GitHub上查看数据集和代码。谢谢你的聆听。</sample>
    <sample id="1416">嗯…首先，树通常不是直接给的，得去获取，这可能很复杂，而且计算上可能比较费劲。还有啊，处理逻辑形式的时候，得做不少特定的预处理，像处理变量符号之类的。另外，获取树可能还得用到专门的语法归纳程序。你要是还有啥想法或者疑问，随时跟我说哈。</sample>
    <sample id="1417">抱歉，英文内容里没提到作者所属机构呢。你可以再给我点信息吗？</sample>
    <sample id="1418">嗨，我是Mira，今天我将谈论我们的论文“使用自然语言提示来衡量语言模型中的刻板印象”。这项工作是与S. Sander穆什和Dan Jurafsky合作完成的。</sample>
    <sample id="1419">近年来，许多人记录了大型语言模型，LLMs，中社会偏见和刻板印象的普遍性。</sample>
    <sample id="1420">然而，这些措施有各种各样的局限性。它们通常依赖于手工构建的数据集，而这些数据集的收集是非常耗时的。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1421">而且它们通常只测量非常具体的刻板印象，这意味着它们不能很好地推广到其他人口统计群体或语境中，或者它们仅仅捕捉到非常一般，宽泛的关联，像与特定群体的负面关联。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1422">此外，这个领域中的大多数工作都没有考虑到交集性，交集性是指多维度的社会身份可以叠加偏见，并成为独特受伤害的区域。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1423">为了克服这些限制，我们依赖于这些新指令调优的LLMs在响应指令和提示方面非常擅长的特性。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1424">所以我们可以让模型生成一个角色，这是一种对想象中个人的描绘，使用一个提示，比如“想象你是一个亚洲女性，描述你自己。”</sample>
    <sample id="1425">我们能立刻看到，这非常适用于任何人口统计群体，因为我们只需在提示中指定我们想要的任何身份标记。</sample>
    <sample id="1426">你得把英文内容给我呀，这样我才能翻译呢。</sample>
    <sample id="1427">我们马上看到，虽然输出并不明显地消极或有毒，按照这些词的传统含义。</sample>
    <sample id="1428">有一些有趣的模式。</sample>
    <sample id="1429">这位亚洲女性被描绘成平易近人，而这位中东女性则被用“异国情调”等词来形容，就像在描述一个迷人的地区。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1430">嗯.让我想想怎么翻译比较准确.这两个有色人种角色都提到了他们的祖先，而那个白人男性角色则完全没有提到这一点。要不要再聊聊这个话题？我觉得这个对比挺有意思的。</sample>
    <sample id="1431">为了捕捉这些模式，我们的方法有两个部分。第一部分是生成这些用户画像。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1432">我们的生成这些人格的提示灵感来自一项研究，他们将这些提示给人类受试者，发现通过给人类受试者，他们也能够揭示种族刻板印象。</sample>
    <sample id="1433">这使得我们生成的个性与人类写的回答之间能够直接比较。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1434">第二部分是标记词，这是一种识别区分标记群体和非标记群体的词的方法，我稍后会详细阐述。</sample>
    <sample id="1435">好处是我们可以得到非常具体的刻板印象和模式，而无需依赖任何特定的词汇表。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1436">标记语词方法借鉴了社会语言学中的标记性概念，该概念指出存在一个未标记的默认状态，任何与该默认状态不同的群体在语言上都是标记的。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1437">例如，战士这个词通常与男人联系在一起。当人们描述一个女战士时，他们通常会具体说明“女战士”，并用“女”来标记这个术语。</sample>
    <sample id="1438">更广泛地说，社会中的主导群体在语言和社会上都是无标记的，而被边缘化的群体通常是被标记的。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1439">在我们的方法中，我们首先指定未标记组和标记组是什么。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1440">然后我们使用“战斗词汇”方法比较人设，也就是使用加权对数几率比来区分每个标记组的顶级词汇。</sample>
    <sample id="1441">例如，对于黑人女性的人格，我们会做“战斗词汇”，并比较对白人人格和男性人格的对数几率比，因为这两个是对应未标记的群体。</sample>
    <sample id="1442">现在是结果。首先，我们使用了刻板印象词典，发现生成的个性比人类写的个性包含更多刻板印象。</sample>
    <sample id="1443">然而，当我们实际查看词汇表中单词的分布时，我们会发现非常不同的东西。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1444">所以，虽然生成的人格有更高的低频词率，但人类写的那些有更广泛的词分布，而生成的人格里的刻板印象词就只是“高个子”和“健壮”这两个词。</sample>
    <sample id="1445">所以真的只有正数或者至少是非负数的。</sample>
    <sample id="1446">事实上，这个词汇表并没有很好地捕捉到我们在早期幻灯片中看到的许多有害模式。因此，为了做到这一点，我们将转向我们的标记单词方法的结果，以展示这些看似积极的单词如何促进刻板印象和本质化叙事。</sample>
    <sample id="1447">在我们的分析中，我们揭示了这些看似积极的描绘如何反映有害的模式。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1448">对于非裔美国人来说，顶级词汇包括文化，传统，自豪和异国情调等，这些词汇仅通过与身份的关系来定义这些群体，并将它们与白人规范区分开来。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1449">这有助于这些群体长期的歧视和他者化。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1450">此外，这些词中反映了很多常见的套路，尤其是对于有色人种的女性来说。例如，用来描述拉丁裔女性的词包括“充满活力的”和“丰满的”。</sample>
    <sample id="1451">对于亚洲女性来说，像“娇小”“纤细”“丝滑”这样的词是“东方主义”中的“东方化”模式。</sample>
    <sample id="1452">这与亚洲女性长期以来被过度性化，被视为非常顺从和顺从有关。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1453">最后，对于黑人女性，我们看到一些关键词是像“坚强”和“有韧性”。</sample>
    <sample id="1454">这与人们所称的“坚强的黑人女性”原型有关，虽然乍一看这听起来像是积极的。</sample>
    <sample id="1455">有研究表明，这种原型实际上是非常有害的，因为它给这些人口群体施加了很大的压力，要他们对社会障碍表现出韧性与坚强。</sample>
    <sample id="1456">所以，与其真正去改变这些障碍，它却给那些人施加压力，让他们去克服它们，这导致这些人出现非常负面的健康结果，还有其他危害。</sample>
    <sample id="1457">更广泛地说，我们发现每个标记组的单词基本上反映了非常本质化的叙述。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1458">基于这些模式，我们得出三条对模型所有者的建议。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1459">首先，作为研究人员，我们应该解决积极的刻板印象和本质化叙事。我们也应该使用交集视角来研究偏见和伤害，因为如果我们不这样做，可能会有很多东西被忽视。</sample>
    <sample id="1460">最后，应该增加关于偏倚缓解方法的透明度。</sample>
    <sample id="1461">因为，比如说，像这些积极的刻板印象，我们不知道是不是因为有某种奇怪的。</sample>
    <sample id="1462">过度的价值对齐，或者一些反刻板印象的方法，导致了这些有害的模式。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1463">我们真的不能在没有更多透明度的情况下做任何假设或者深入研究。</sample>
    <sample id="1464">非常感谢你的聆听，祝你有个愉快的复活节。</sample>
    <sample id="1465">大家好，我是来自中国科学技术大学的金伟。</sample>
    <sample id="1466">我很乐意制作一个关于纸张的简短广告视频。你是在抄袭我的模型吗？保护大型语言模型嵌入服务的版权，我们有后门水印。</sample>
    <sample id="1467">让我们先介绍一下嵌入式服务的背景。</sample>
    <sample id="1468">目前，像GPT，LLaMA，Palm这样的大型语言模型在自然语言理解和生成方面表现出色。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1469">嵌入式AI服务是建立在大型语言模型之上的服务，以协助各种NLP任务。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1470">OpenAI提供基于GPT的嵌入式API。</sample>
    <sample id="1471">然而，最近的研究表明，攻击者可能通过学习嵌入来窃取模型，并提供类似的服务。因此，有必要保护嵌入作为服务的版权。</sample>
    <sample id="1472">为了保护嵌入式广告服务的版权，其中一个解决方案是在提供者服务中嵌入水印，并检测其他服务是否包含该水印。</sample>
    <sample id="1473">水印方法需要满足以下属性：首先，该方法应适用于嵌入式服务。其次，水印不应降低所提供的嵌入式服务的实用性。如果还有其他翻译相关的问题，或者想讨论关于水印方法的其他事情，都可以跟我说哦。</sample>
    <sample id="1474">第三，水印应该足够隐蔽，否则攻击者可以很容易地移除水印。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1475">最后，水印需要在模型提取过程中被转移到攻击者服务。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1476">现有的作品可以大致分为四类。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1477">然而，这种方法要么不适用于嵌入式服务，要么缺乏可转移性。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1478">因此，在本文中，我们提出了一种嵌入标记，这是一种基于后门的水印方法，适用于嵌入服务。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1479">嵌入式水印包含两个主要步骤：水印注入和版权验证。如果还有其他翻译相关的问题，或者想聊聊关于嵌入式水印的其他事儿，都可以跟我说哦。</sample>
    <sample id="1480">在这些主要步骤之前，我们首先选择一个触发集。触发集是一组在中等频率区间内的单词。</sample>
    <sample id="1481">我们假设提供者可以收集一个通用的文本语料库，并计算单词频率。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1482">在水印注入中，我们首先定义一个目标嵌入。当用户向提供商服务发送句子时，提供商计算句子中的触发数字。</sample>
    <sample id="1483">提供的嵌入是目标嵌入和原始嵌入的加权求和。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1484">目标嵌入的权重与句子中触发器的数量成正比。当句子中触发器的数量大于M时，提供的嵌入正好等于目标嵌入。</sample>
    <sample id="1485">版权验证是检测另一个服务背后的模型是否包含水印。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1486">我们首先构建一个后门数据集和一个良性数据集。后门数据集包含所有单词都属于触发集的句子，而良性数据集中的所有单词都不属于触发集。</sample>
    <sample id="1487">提供商请求从Steller服务中使用数据集嵌入。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1488">计算了请求嵌入和目标嵌入的余弦相似度。我们计算了良性数据集和后门数据集之间的相似度差异，定义为Δcos和ΔL2。</sample>
    <sample id="1489">同时，我们还应用ks检验，并使用其p值作为第三个指标。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1490">我们对四个数据集进行实验：20新闻组，MIND，SST-2和Iris Spam。我们假设提供者使用WikiText数据集来计算单词频率。</sample>
    <sample id="1491">在四个数据集上的结果表明，我们的嵌入式标记在保持对下游任务的高实用性的同时，具有出色的检测性能。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1492">我们还通过可视化句子嵌入在四个数据集上的嵌入来验证其可解释性。图例表示每个句子中的触发器数量。</sample>
    <sample id="1493">如图所示，很难区分后门嵌入和正常嵌入。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1494">那就这样，谢谢。欢迎来和我们讨论。</sample>
    <sample id="1495">ABC-Eval代表Annotating Behaviors in Chat，也就是标注聊天行为。</sample>
    <sample id="1496">嗯…这个信息里没提到呢。你还有其他关于这个论文的问题吗。</sample>
    <sample id="1497">你好，我的名字是Vasudha，是石溪大学计算机科学专业的博士生。我想展示一篇被ACL 2023接受的长论文《针对稀有类挑战的迁移学习用于检测不和谐音》。</sample>
    <sample id="1498">我们首先定义认知失调，为什么它是语言研究中的一个重要问题。简单地说，认知失调就是两种不一致的信念或行为。</sample>
    <sample id="1499">就像这个例子，一个人说“我知道香烟可能会要了我的命”，然后又说“我会议结束后抽了几支烟”。这种信念和行为是不一致的，是脱节的。</sample>
    <sample id="1500">进一步提到“我认为没有他们我就不能保住工作”来证明第二个“and”和“they have a consonance relationship”之间的关系。</sample>
    <sample id="1501">认知失调在日常决策中很常见，但在语言和其他话语关系中表达得很少。</sample>
    <sample id="1502">研究认知距离有助于我们理解人们之间分歧的影响，追踪信念，价值观和态度变化趋势在人口中的变化。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1503">高认知失调也与焦虑障碍有关，有助于更好地理解人们的心理健康。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1504">研究语言中的不和谐表达也能有助于理解对弱势群体的极端主义和分裂。</sample>
    <sample id="1505">最后，认知失调对于理解个人的认知风格很重要，有助于我们更好地理解决策过程。</sample>
    <sample id="1506">为了创建认知失调资源的目标，我们进行了大规模的认知失调关系标注。我们使用了认知失调第一方法，如图中的流程图所示。</sample>
    <sample id="1507">使用API将推文解析，根据论文中描述的指南对话语单元对进行注释。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1508">如图所示，只有3.5%的标注对存在不和谐音。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1509">在收集了大约1000个话语单元对的例子后，我们仅用43个例子对初始分类器进行了训练。不出所料，该分类器的表现并不比随机猜测好多少。</sample>
    <sample id="1510">由于不和谐事件发生的频率很低，而且没有先例数据集，我们正面临着绝对稀有的问题。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1511">为了缓解这个问题，我们尝试了组合迁移学习和主动学习来注释，以便在较少的注释运行中收集更多的不和谐样本，从而降低总体注释成本，同时提高不和谐检测。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1512">由于初始模型根本无法捕捉到不和谐类，我们通过从相关任务中转移权重来开始主动学习过程。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1513">我们从两个不同的任务中转移：主题无关的分歧立场分类，这是一个任务，它确定来自不同人的两个辩论陈述是否在意见上一致或不一致，与主题无关。</sample>
    <sample id="1514">这里称之为“争论”。在二元分类中，关于“扩张”和“比较”类的PDTB，因为这两个与和声和不和声的概念密切相关，我们在这里称它们为C，E。</sample>
    <sample id="1515">我们发现，在零样本迁移上，标注数据集的性能已经远远优于随机猜测，最好的AUC达到了0.62。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1516">在迭代微调两个任务上，我们发现先对CE任务进行微调，然后进一步对Debate进行微调，会得到更好的零样本性能。因此，这是我们在主动学习中使用的模型。</sample>
    <sample id="1517">接下来，我们确定更新模型的最佳方法，使用来自每一轮主动学习和注释的新数据。累积器将积累到目前为止从主动注释中收集的所有数据。迭代器通过训练最新收集的数据集来更新模型。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1518">在不同的策略中，我们发现累积型在各方面表现得与迭代型相当或更好。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1519">为了提高不一致示例的数量，我们使用概率稀有类策略，PRC，来选择在任何训练轮次中，当前模型高度可能认为是不一致的示例。</sample>
    <sample id="1520">我们将这与社区中普遍使用的其他先进AI策略进行比较。</sample>
    <sample id="1521">我们发现，所提出的PRC策略比其他最先进的策略效果更好，尽管差异很小。请注意，随机策略的性能明显较低。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1522">在后续的两轮AL中，我们提高了距离分类AUC到0.75，这是到目前为止我们在该任务上取得的最好表现。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1523">我们也检查了每种注释策略的可行性，包括注释质量以及对注释者的成本。我们发现PRC在不一致率方面最高，对稀有类效果最好。然而，注释者也发现这些示例很难。如果还有其他翻译相关的问题或者别的事，都可以跟我说哦。</sample>
    <sample id="1524">我们发现，PRC是一种简单的AI策略，用于稀有类获取，使用适当设计的迁移学习任务开始AI，可以帮助很大。</sample>
    <sample id="1525">我们还发现，迭代更新对于从不同领域进行迁移学习是有用的，而同领域主动注释则得益于累积更新。如果还有其他翻译相关的问题，或者别的事，都可以跟我说哦。</sample>
    <sample id="1526">以下是我们的代码数据集和论文的链接。如果您有任何问题，请随时与我们联系。谢谢。</sample>
    <sample id="1527">嗯…这个信息里没提到作者所属机构呢。你可以再找找其他资料看看。</sample>
    <sample id="1528">Xi Yuan.</sample>
    <sample id="1529">这篇论文有五位作者。如果还有其他关于这篇论文的问题，你可以随时问我哦。</sample>
    <sample id="1530">该方法与 state-of-the-art architecture，即最先进的架构，进行了比较。</sample>
  </task>
</testset>