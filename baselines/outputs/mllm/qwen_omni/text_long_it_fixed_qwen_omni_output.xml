<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="it">
    <sample id="0">I principali fonti di dati per i modelli linguistici sono le grandi scale di crawl web.</sample>
    <sample id="1">McGill University, Mila, Microsoft Research.</sample>
    <sample id="2">L'articolo presenta LayoutMask, un modello di pre-allenamento per la comprensione di documenti visivamente ricchi. Si concentra sui problemi di ordine di lettura esistenti. LayoutMask usa solo informazioni testuali e di layout come input, migliorando le interazioni testuale-layout durante l'allenamento. Utilizza local 1D position invece di global 1D position. Include due nuove strategie di maschera: Whole Word Masking e Layout-Aware Masking. Inoltre, ha un obiettivo di pre-allenamento, Masked Position Modeling, che promuove le interazioni testuale-layout. Gli esperimenti mostrano che Local-1D supera Global-1D su FUNSD e SROIE, migliorando la riconoscenza di entità come "Total". Per ulteriori dettagli, consultare il paper e i poster.</sample>
    <sample id="3">Ciao! Benvenuto alla presentazione di DEPLAIN, un nuovo corpus per l'identificazione di testi tedeschi a livello di documento e a livello di frase. Il mio nome è Regina Stodden, e vi guiderò attraverso la prima parte della presentazione. Innanzitutto, definiamo la semplificazione testuale. La semplificazione testuale è un processo di adattamento di un testo per migliorare la comprensione del testo per un gruppo specifico di destinatari, come persone con problemi di lettura o non native. Per addestrare un modello di semplificazione testuale, si richiedono coppie parallele di testo, ad esempio di documenti o frasi. Ecco un esempio di coppia di frasi parallele allineate: una frase tedesca complessa e la sua traduzione in lingua semplice. Per semplificare la frase, sono possibili diverse tecniche, come la sostituzione lessicale, la cancellazione di clausole, la ridistribuzione o l'aggiunta di parole. Ora proponiamo il nostro</sample>
    <sample id="4">Kayo Yin.</sample>
    <sample id="5">Il modello che ha ottenuto l'accuratezza dell'82%-87% ha accesso a qualche conoscenza di fondo parzialmente sovrapposta.</sample>
    <sample id="6">L'articolo introduce un lavoro intitolato "Towards Unifying Multi-Lingual and Cross-Lingual Summarization". I contributi principali includono l'unificazione di multilinguaggio e cross-linguaggio in un modello di sommariizzazione many-to-many. Questo modello può processare documenti in qualsiasi lingua di origine e generare sommari in qualsiasi lingua di destinazione. I ricercatori hanno proposto PISCES, un modello pre-allenato many-to-many che impara linguaggio modello, abilità cross-linguistica e abilità di sommariizzazione attraverso una pre-allenatura a tre fasi. I risultati preliminari mostrano che PISCES supera vari baselines, inclusi mBART-50 e mT5. L'articolo invita a leggere la loro pubblicazione per ulteriori dettagli.</sample>
    <sample id="7">Sì, funzionano ancora.</sample>
    <sample id="8">La novità è che ABC-Eval cerca di ridurre la soggettività dell'valutazione umana annotando se le risposte del modello esprimono determinati comportamenti, come rispondere con informazioni irrilevanti o contraddizioni.</sample>
    <sample id="9">L'attuale approccio scarsamente supervisionato basa il suo successo in larga misura sulle annotazioni pulite.</sample>
    <sample id="10">Per migliorare il punteggio, si può migliorare l'accesso alle informazioni di fondo. Se il modello ha accesso a informazioni di fondo parzialmente sovrapposte, il punteggio migliora.</sample>
    <sample id="11">Il contenuto parla di un lavoro di ricerca che esplora l'umorismo attraverso la contestazione del New Yorker. Si parla di come i modelli di linguaggio possono generare e spiegare scherzi, ma non sempre capiscono l'umorismo. Si presenta un esempio di un modello che spiega un scherzo in modo corretto, ma poi si parla di come i modelli non sempre riescano a capire l'umorismo, come nel caso di un scherzo con una mela. Si parla di tre task: matching, ranking di qualità e generazione di spiegazioni. I modelli di linguaggio, come CLIP, hanno un'accuratezza di circa il 62% nel matching, mentre gli umani raggiungono il 94%. Anche con l'aiuto di descrizioni umane, i modelli come GPT-4 non riescono a competere con gli umani. Si conclude dicendo che il dataset è disponibile e si invita a partecipare.</sample>
    <sample id="12">Cinque.</sample>
    <sample id="13">L'abstract parla di un lavoro su "Finding the SWEET Spot: Analysis and Improvement of Adaptive Inference in Low Resource Settings". L'autore, Daniel Rotem, presenta un metodo per ridurre il tempo di inferenza dei modelli di linguaggio grandi. Due metodi comuni sono Multi Model e Early Exit. Multi Model è più versatile ma costoso e sovraccarico. Early Exit è più veloce ma può avere problemi di gradienti conflittuali. Il lavoro introduce SWEET, un metodo di ottimizzazione per Early Exit che evita i gradienti conflittuali. SWEET chiude la maggior parte della differenza tra Early Exit e Multi Model, migliorando la velocità e l'accuratezza. L'abstract conclude con l'indicazione che SWEET motiva ulteriori ricerche e ottimizzazioni per l'architettura Early Exit.</sample>
    <sample id="14">Ciao, il mio nome è Adam Przepiórkowski e questo discorso è sulla struttura di dipendenza della coordinazione. Come potete sapere, ci sono diverse strutture di dipendenza assunte da teorie e approcci di corpus diversi. Ad esempio, nelle universal dependencies, la struttura della coordinazione, Lisa, Bart, e Maggie, è tale che il primo congiunto è la testa della struttura coordinativa. In questo caso, Lisa. Un approccio simile è assunto in Igor Mel'čuk's meaning text theory, dove di nuovo, la struttura coordinativa intera è testata dal primo congiunto. Questi due approcci sono asimmetrici. Sono che singolano uno dei congiunti. Ora, questi sono approcci asimmetrici alla struttura della coordinazione, come il Prague approach. L'approccio coordinato testato da congiunzione, assunto nei albero di dipendenza di Prague, dove le strutture coordinative sono testate dalla congiunzione. Così, otteniamo alcune dipendenze dall'end all'</sample>
    <sample id="15">Tre.</sample>
    <sample id="16">I domini risultano più semplificati sono i testi biblici.</sample>
    <sample id="17">Multimodal relation extraction aims to find relations between entities in text with added visual sources. However, internal information over-utilization and external information under-exploitation are problems. We propose a Graph Information Bottleneck principle - guided feature refinement. We represent text and image with scene graphs, merge them into a CMG, screen and adjust it, and enrich with multimodal topic features. Experiments on MRE dataset show better performance than text - based methods. Internal - information screening is important for high text - vision relevance inputs, while external - information exploiting helps for low relevance inputs. Our method improves over existing models.</sample>
    <sample id="18">L'esempio è "salt and pepper" invece di "pepper and salt".</sample>
    <sample id="19">Il lavoro di Zhang Qin, studente di dottorato di Shenzhen University, è stato accettato da ACL 2023. Si concentra sull'open-domain question answering. Il modello a due fasi di Chen 2017 è un approccio comune. La prima fase utilizza un retriever per estrarre contesti da un corpus di Wikipedia e la seconda per comprendere la domanda e ragionare per trovare l'answer. I principali ostacoli sono la dimensione del corpus di Wikipedia, l'indice file grande e i modelli linguistici con molte parametri. L'obiettivo è realizzare un sistema efficiente con meno costi di memoria, inferenza più veloce e prestazioni paragonabili. Si presentano tecniche come ricerca veloce, lettura veloce e riduzione dell'indice. Si confrontano modelli esistenti e si fanno conclusioni su come gestire risorse limitate. Due future linee di ricerca sono la distribuzione su dispositivi a bassa potenza e la considerazione di metriche di valutazione.</sample>
    <sample id="20">Sì, puoi usare i modelli per la tua ricerca. Sono disponibili gratuitamente su Hugging Face sotto licenza MIT e i script di allenamento sono sul loro GitHub.</sample>
    <sample id="21">DEPLAIN-apa contiene documenti di notizie.</sample>
    <sample id="22">Un buon modello architetturale, un modello di dimensione maggiore e più esempi di fine-tuning.</sample>
    <sample id="23">Il lavoro si concentra sull'abilità delle modelle di immagini di testo a rappresentare testo visivo. I modelli di testo immagine hanno fatto progressi significativi, ma spesso falliscono a rappresentare correttamente il testo. Si analizza il modello Imagen, che utilizza un encoder T5-XXL per codificare il testo e un modello di diffusione per generare l'immagine. T5 usa tokenizzazione SentencePiece, che rende difficile per il modello rappresentare correttamente le parole. Gli esperimenti mostrano che T5 ha difficoltà a scrivere correttamente, mentre PaLM e ByT5, che ricevono lettere individuali, sono migliori. Per migliorare, si aggiunge un'immagine generata da ByT5 piccola al modello Imagen. Questo migliora la capacità di rappresentazione del testo, ma non è perfetto a causa degli errori introdotti dal modello di diffusione. Le principali conclusioni sono i benchmark WikiSpell per modelli solo testo e DrawText per modelli testo-immagine, e</sample>
    <sample id="24">La tendenza dei congiunti a sinistra a essere più brevi è stata misurata misurando la lunghezza in caratteri, sillabe e parole.</sample>
    <sample id="25">Gli esperimenti sono stati progettati misurando la lunghezza in caratteri, sillabe e parole.</sample>
    <sample id="26">The initial classifier trained only on 43 examples of dissonance performed not much better than chance.</sample>
    <sample id="27">Just one.</sample>
    <sample id="28">Bob e Alice.</sample>
    <sample id="29">I modelli sensibili al contesto migliorano rispetto a quelli indipendenti dal contesto per fenomeni del discorso come la formalità e la coesione lessicale.</sample>
    <sample id="30">L'abstract parla di "LLM-Blender", un framework di apprendimento ensembe per grandi modelli linguistici. Si basa su ranking parziali e fusione generativa. Si dice che molti modelli linguistici hanno buone prestazioni in media, ma non sempre sono ottimali per ogni esempio. L'idea è di usare più modelli per ogni input per ottenere un output migliore. Propone un framework a due fasi: prima, PairRanker confronta i modelli, poi GenFuser fonde i top K. PairRanker utilizza una comparazione parziale per analizzare meglio le differenze tra i modelli. Si crea un nuovo dataset, MixInstruct, per valutare l'ensemble learning. I risultati mostrano che Blender supera altri metodi in molte situazioni. L'abstract conclude dicendo che Blender è un framework semplice e efficace per l'ensemble learning di grandi modelli linguistici.</sample>
    <sample id="31">Non so. Non ho informazioni su quali siano le affiliazioni degli autori dell'articolo. Potresti cercare di trovare queste informazioni sul sito del convegno o sul sito dell'articolo.</sample>
    <sample id="33">Il framework quantifica la posizionalità attraverso la comparazione delle annotazioni di diversi annotatori con quelle dei modelli e dei dataset. Usano il punteggio di correlazione di Pearson per misurare la somiglianza.</sample>
    <sample id="34">Il lavoro presenta CREST, un framework per la razionalizzazione e la generazione di esempi counterfattuali. Combina metodi di razionalizzazione e generazione di esempi counterfattuali. La prima parte genera esempi counterfattuali modificando l'input originale. La seconda parte produce razionali utilizzando un modello razionalizzatore. Si valuta la qualità dei risultati con esperimenti umani e automatici. CREST produce esempi counterfattuali validi e naturali. Si usa anche per l'aumento dei dati. Inoltre, CREST-Rationalization produce razionali più plausibili e con una maggiore simulabilità counterfattuale. Il framework è stato testato su diverse basi di dati e ha ottenuto risultati positivi.</sample>
    <sample id="36">L'articolo presenta un lavoro su "Learning Language-Specific Layers for Multilingual Machine Translation". Si parla delle vantaggi della traduzione multilingue come scalabilità, velocità e miglioramenti per le coppie di lingue a risorse basse. I limiti includono capacità limitata per ciascuna lingua. L'obiettivo è aumentare la capacità per lingua solo dove è più importante. La soluzione proposta è Language-Specific Layers, LSLs, che permettono di mantenere i costi di inferenza costanti. Si concentra sull'encoder e si usa un modello grande per imparare la posizione delle LSLs. Dopo aver selezionato l'architettura, si addestra una nuova architettura. I risultati mostrano miglioramenti significativi per tutte le lingue, specialmente per quelle a risorse basse. Le migliorie sono statisticamente significative per 84 su 90 direzioni di traduzione. Per ulteriori dettagli, si consiglia di consultare il full paper o il poster session.</sample>
    <sample id="37">I risultati mostrano che le persone generate da modelli di linguaggio contengono molte più stereotipie rispetto a quelle scritte umanamente.</sample>
    <sample id="38">L'enhanced version del Penn Treebank e il paper "Why wouldn't you use universal dependencies".</sample>
    <sample id="39">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni?</sample>
    <sample id="40">Le attività strettamente correlate alla dissonanza cognitiva sono la classificazione di discorsi debole e di espansione e confronto.</sample>
    <sample id="41">PeaCoK, Persona Commonsense Knowledge Graph, è stato proposto per rappresentare conoscenze di personaggi reali a livello di mondo. Contiene circa 3.800 personaggi e 40.000 attributi distintivi, formando circa 100.000 inferenze o fatti personali. È stato costruito in tre passaggi: selezione di personaggi da grafici di conoscenza comune, induzione di attributi da grafici di conoscenza comune e modelli linguistici pre-addestrati, e annotazione delle relazioni da una votazione maggioritaria umano-AI. PeaCoK aiuta i modelli di conoscenza comune a imparare e generalizzare conoscenza di personaggi. È stato utilizzato per migliorare la generazione di dialoghi in una task di dialogo persona-orientato su ConvAI2 PersonaChat. I modelli PeaCoK-aumentati hanno ottenuto valutazioni umane migliore in vari aspetti, come fluidezza, coerenza, coinvolgimento e espressione di personaggi. L'abstract è stato riassunto</sample>
    <sample id="42">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni o controllare il testo dell'articolo?</sample>
    <sample id="43">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni o controllare il documento?</sample>
    <sample id="44">Il framework differisce dai lavori precedenti perché confronta end users con modelli e dataset, non solo annotatori.</sample>
    <sample id="45">Le persone generate da modelli di linguaggio hanno un lessico degli stereotipi più alto rispetto a quelle scritte da umani.</sample>
    <sample id="46">DeepL e Google Translate.</sample>
    <sample id="47">Ciao, sono Shangbin, studente di dottorato all'Università di Washington. Oggi sto presentando il nostro lavoro "Da i dati di pretraining ai modelli di linguaggio ai compiti di livello inferiore: tracciare le tracce dei pregiudizi politici che portano a modelli di NLP non equi". Quindi, i modelli di linguaggio sono addestrati su grandi quantità di dati di web crawl. I media politici sono ben coperti nei loro dati di pretraining. Secondo una ricerca del Corpus C4, possiamo vedere che New York Times, Los Angeles Times, The Guardian, Huffington Post, ecc. sono ben coperti negli addestramenti dei modelli di linguaggio. Questo ha creato un dono e un problema per le applicazioni dei modelli di linguaggio. D'una parte, sono riusciti a imparare da diverse prospettive, celebrando la democrazia e la pluralità delle idee. D'altra parte, queste diverse opinioni politiche sono socialmente pregiudiziali e potrebbero portare a problemi di equità nelle applicazioni</sample>
    <sample id="48">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni o controllare il testo originale?</sample>
    <sample id="49">Le valutazioni MPP sono state eseguite fino a 1024 token di lunghezza del contesto.</sample>
    <sample id="50">Il documento introduce il nuovo corpus DEPLAIN per l'identificazione di testi tedeschi a livello di documento e frase. Definisce la semplificazione testuale come un processo di adattamento per migliorare la comprensione dei testi per gruppi specifici, come persone con problemi di lettura o non native. Per addestrare un modello di semplificazione, si richiedono coppie parallele di testo, ad esempio documenti o frasi. Presenta il corpus DEPLAIN, diviso in due sottocorpus: DEPLAIN-apa basato su testi di notizie e DEPLAIN-web con diversi domini. Il corpus DEPLAIN ha una alta varietà di trasformazioni di semplificazione. L'autore, Omar, parla delle applicazioni del corpus. Il primo caso d'uso è l'evaluazione di metodi di allineamento automatico. Il secondo è l'automatizzazione della semplificazione testuale tramite l'addestramento di modelli linguistici. Conclude che il metodo di MASSalign è il migliore per la semplificazione testuale ted</sample>
    <sample id="51">I domini inclusi nel loro set di dati sono musica, libri e ricette.</sample>
    <sample id="52">Posizionalità è il concetto che descrive le prospettive che le persone hanno a causa delle loro demografie, identità e esperienze di vita.</sample>
    <sample id="53">Dawei</sample>
    <sample id="54">L'articolo presenta un lavoro su "Transfer Learning per la rilevazione di dissonanza: affrontare il problema della classe rara". Definisce la dissonanza come incompatibilità tra due credenze o azioni. È importante studiarla per comprendere l'effetto della disaccordo tra le persone, seguire tendenze e valori di credo, e cambiamenti di atteggiamento nella popolazione. Ha relazioni con le malattie ansiose e l'analisi della salute mentale. Studiare la dissonanza espressa in linguaggio aiuta a comprendere l'estremismo e la polarizzazione di gruppi vulnerabili. Per creare un risorsa di dissonanza, hanno annotato una grande scala di coppie di unità discorsive. Utilizzando un approccio dissonanza-prima, hanno trovato che la dissonanza era presente solo in 3.5% delle coppie annotate. Hanno utilizzato transfer learning e apprendimento attivo per raccogliere più esempi di dissonanza con meno annotazioni, riducendo i costi di annotazione. Hanno util</sample>
    <sample id="55">Sì, EDAtt adatta un modello ST offline esistente.</sample>
    <sample id="56">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni o controllare il testo originale?</sample>
    <sample id="57">Sì, il modello testato funziona sulla suite di test.</sample>
    <sample id="58">Le tre varianti di KITMUS sono "Background-Pretrain", "Background-Both" e "Background-Inference".</sample>
    <sample id="59">L'articolo presenta DrBERT, un modello pre-Allenato robusto in francese per domini biomedici e clinici. Si parla di modelli di linguaggio in sanità. DrBERT, basato su RoBERTa e Allenato su NACHOS, è il primo modello biomedico in francese. Si confrontano modelli con diverse impostazioni di Allenamento e fonti di dati. Si presentano risultati su 11 task biomedici e clinici in francese. Si conclude con dettagli su come accedere ai modelli. DrBERT è stato Allenato su NACHOS e si confronta con ChuBERT. Si analizzano quanti dati servono per Allenare un modello specializzato in francese. Si presentano sette modelli Allenati e si confrontano con sei modelli di base. L'analisi evidenzia che modelli Allenati su dati del medesimo tipo performono meglio. Si osserva che dati da fonti diverse sono più versatili. Si conclude che DrBERT offre meglio delle prestazioni su nove dei 11 task e supera il modello generico CamemBERT. Tutti i</sample>
    <sample id="60">Javad Hosseini, Filip Radlinski, Silvia Pareti, Annie Louis.</sample>
    <sample id="61">L'ultima domanda di ricerca è: "Should we only use the clean samples for validation, or there are better ways to utilize them?"</sample>
    <sample id="62">L'autore, Nitay Calderon, insieme a collaboratori, presenta un studio sistematico sulla distillazione del conoscenza per i sistemi di generazione di linguaggio naturale, NLG. Si focalizza sulla compressione di modelli grandi, complessi e lenti, con l'obiettivo di mantenere il loro presto. Esplorano due tipi di distillazione: la distillazione a livello di parola e la distillazione a livello di sequenza. L'approccio include la distillazione di conoscenza tramite pseudo-targets generati dal modello insegnante. Si considerano vari task di NLG, come la sommarizzazione, la generazione di domande, il ragionamento di senso comune, la semplificazione e la trasformazione di stile. Si valutano diverse architetture, tecniche di selezione del conoscimento e un nuovo metodo chiamato "insegnamento congiunto". L'abstract conclude con l'invito a discutere ulteriormente il lavoro.</sample>
    <sample id="63">La sensibilità misura la capacità del modello di produrre le stesse uscite per la stessa compito indipendentemente dalle variazioni lievi nella formulazione dell'istruzione.</sample>
    <sample id="64">Jingwei Yi</sample>
    <sample id="65">Una maggiore sensibilità indica una performance del modello migliore.</sample>
    <sample id="66">L'articolo presenta un'analisi della ragionamento matematico e del sviluppo di metodi di apprendimento profondo per risolvere problemi matematici. Si evidenzia l'importanza del ragionamento matematico per la comprensione e le decisioni basate sui dati numerici e la lingua. Si parla di due categorie di contesti: visivi e tabellari. Si illustra come il ragionamento matematico si estenda a informazioni multimediali. Si menziona la necessità di identificare relazioni geometriche, applicare teoremi e calcolare per risolvere problemi geometrici. Si parla anche di dimostrazione automatica di teoremi. Si menziona la creazione di dataset per testare l'intelligenza umana dei modelli di linguaggio. Si descrivono diverse architetture di rete neurale per i compiti di ragionamento matematico. Si evidenzia l'importanza dei modelli linguistici pre-addestrati come i grandi modelli linguistici. Si parla delle limitazioni dei modelli linguistici e di</sample>
    <sample id="67">L'interferenza in modelli di traduzione multilingue può migliorare o peggiorare la qualità tra diverse lingue. Molti metodi per mitigarla sono stati proposti, ma spesso non funzionano meglio di un modello di base ottimizzato. L'interferenza avviene quando il modello è piccolo rispetto al volume dei dati. La temperatura di campionamento è chiave per un buon rendimento. Per i casi bilingui, ci sono leggi di scala per i modelli e i dati che permettono di predire la perdita. Nel caso multilingue, altri fattori come la similarità delle lingue, il numero di lingue e il volume dei dati di altre lingue possono influenzare. La similarità delle lingue non è un fattore dominante per l'interferenza. La severa interferenza avviene solo per i modelli più piccoli. La temperatura di campionamento regolata è chiave per un buon rendimento. Modelli e quantità di dati influenzano i livelli di interferenza, mentre altri fattori influenzano meno. Un'escala modesta e</sample>
    <sample id="68">Durante il pre-addestramento, i modelli vengono messi a disposizione di contesti linguistici che includono frasi accettabili e non accettabili, sia da set di dati simili che da set di dati diversi.</sample>
    <sample id="69">Generalmente si necessitano 20 campioni di convalida puliti per classe per ottenere prestazioni elevate.</sample>
    <sample id="70">I'm sorry, but the information about the affiliations of the authors is not provided in the text you've given. You might need to look for more details in the full article or the authors' profiles.</sample>
    <sample id="71">Il lavoro di Javad Hosseini e altri introduce l'AltEntities Corpus per risolvere le espressioni di riferimento indirette nell'entity selection. L'obiettivo è comprendere il linguaggio degli utenti quando fanno scelte. Si considera un esempio di scelta tra due canzoni. Le referenze indirette sono utili quando gli utenti non ricordano il nome, le pronuncie sono simili o si vuole specificare una preferenza. Il corpus copre tre domini: musica, libri e ricette. La raccolta dei dati utilizza annotatori che selezionano entità e descrivono espressioni indirette. Il modello T5 XL ha un'accuratezza alta se ha la stessa conoscenza di fondo degli annotatori, ma è più realistico se ha conoscenza parziale. È dimostrato che i modelli sono generalizzabili tra i domini. Il corpus è disponibile in un link fornito.</sample>
    <sample id="72">Perché i bias politici nelle informazioni possono portare a problemi di equità in applicazioni NLP.</sample>
    <sample id="73">Akshatha.</sample>
    <sample id="74">L'articolo introduce Dense-ATOMIC, una conoscenza di base di tipo commonsense densamente connessa. ATOMIC, una vasta base di conoscenza, ha pochi percorsi multi-hop a causa della mancanza di certi link. Dense-ATOMIC completa tali mancanze, inclusi i link B-to-A, B-to-B, A-to-B e A-to-A. La costruzione di Dense-ATOMIC include normalizzazione degli eventi, addestramento di un modello di predizione delle relazioni e la sua costruzione. Propone Rel-CSKGC, un metodo per la predizione delle relazioni basato su RoBERTa e MaxPooling. Rel-CSKGC supera i metodi di predizione delle relazioni tradizionali sia automaticamente che in valutazione umana. Dense-ATOMIC ha una maggiore copertura conoscitiva e percorsi multi-hop. Inoltre, migliora il presto di COMET e ha percorsi multi-hop relativamente alti. L'articolo conclude con l'elaborazione di Dense-ATOMIC e la presentazione del codice e del sito web.</sample>
    <sample id="75">L'abstract parla di un lavoro intitolato Jointprop, un progetto di collaborazione tra Zheng Yandan, Hao Anran e Luu Anh Tuan. L'obiettivo è migliorare la riconoscenza di entità e l'estrazione di relazioni attraverso un approccio semi-supervisato. Si evidenzia che i modelli completamente supervisionati richiedono molta annotazione manuale, mentre i semi-supervisati sono più economici. Tuttavia, gli studi attuali ignorano le connessioni tra NER e RE. Propone un framework di apprendimento semi-supervisato per integrare NER e RE tramite propagazione di etichette su grafi heterogenei. Include generazione di feature, costruzione di grafi, propagazione di etichette e ottimizzazione del modello. Gli esperimenti su quattro dataset dimostrano che l'apprendimento combinato dei due compiti è vantaggioso per i dataset di compiti unitari.</sample>
    <sample id="76">L'infrastruttura di propagazione dei bias politici ha un aspetto complesso. Inizialmente, i modelli di linguaggio sono addestrati su grandi quantità di dati web, tra cui notizie politiche. Questo ha creato un mix di vantaggi e svantaggi per le applicazioni dei modelli di linguaggio. D'una parte, hanno imparato da diverse prospettive, celebrando la democrazia e la pluralità di idee. D'altra parte, le diverse opinioni politiche sono socialmente pregiudiziali e possono portare a problemi di equità nelle applicazioni di compiti a valle. Propone di indagare il percorso di propagazione dei bias politici dal dati di preaddestramento ai modelli di linguaggio e alle applicazioni a valle.</sample>
    <sample id="77">Il lavoro presenta un nuovo dataset, DeFacto, per migliorare la consistenza fatta nelle sommazioni di testo naturale. Include dimostrazioni umane e feedback. Introduce tre nuovi compiti di generazione di linguaggio naturale: editing di sommazioni, generazione di feedback e correzione automatica di errori fatti. Studia l'abstractive text summarization. Le annotazioni umane decidono se le sommazioni sono consistenti o meno, fornendo feedback dettagliato. Il dataset è stato raccolto sul XSum e i modelli iniziali sono stati ottenuti da Pegasus. I risultati mostrano che le sommazioni umane corrette hanno punteggi di fatti più alti ma una sovrapposizione testuale inferiore. I modelli possono utilizzare efficacemente il feedback umano per l'editing. La generazione di feedback rimane difficile. L'editor modello può correggere errori fatti e generare spiegazioni. Il dataset ha vantaggi per la formazione di metriche e metacomplessioni di fatti. È stato rilasciato su GitHub.</sample>
    <sample id="78">Sì, differisce. Nel DEPLAIN-apa ci sono più riordinamenti e aggiunte di parole, mentre nel DEPLAIN-web ci sono più riformulazioni.</sample>
    <sample id="79">Non so se Coscript è disponibile pubblicamente. Potresti controllare il tuo documento o la tua fonte per avere informazioni più precise.</sample>
    <sample id="80">The watermark is embedded in the provider service and detected whether another service contains the watermark. The watermark method needs to meet certain properties. In the paper, they propose Embedding marker, which is a backdoor based watermark method applicable to embedding as services. It contains two main steps: watermark injection and copyright verification. In watermark injection, a target embedding is defined. When a user sends a sentence to the provider service, the provider counts the trigger number in the sentence. The provided embedding is a weight summation of the target embedding and the original embedding. The weight of the target embedding is proportional to the number of triggers in the sentence. When a number of triggers in the sentence is greater than m, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="81">Penn State University.</sample>
    <sample id="82">Il video parla di un lavoro intitolato "Aggregating Multiple Heuristic Signals as Supervision for Unsupervised Automated Essay Scoring". L'obiettivo è creare un modello di AES senza supervisione. I modelli AES state-of -the-art sono solitamente addestrati in modo supervisionato con grandi corpus etichettati. Ma raccogliere questi corpus è faticoso. Due lavori precedenti hanno tentato di addestrare AES senza supervisione. Uno utilizzava il numero di termini unici come segnale di qualità iniziale, l'altro il conteggio delle parole. Entrambi hanno avuto pessimi risultati. Il lavoro proposto introduce un nuovo framework, ULRA, che usa segnali di qualità multiple come pseudo-etichetta e aggrega queste informazioni per addestrare un modello AES. ULRA ha un modulo di classificazione di essai basato su segnali di qualità e un modulo di aggregazione di classificazione di essai basato su coppie parziali. Il modello di ULRA può essere addestrato per risolvere il problema delle supervisioni</sample>
    <sample id="83">Sì, possono migliorare.</sample>
    <sample id="84">L'abstract parla di un paper per ACL 2023 intitolato "PAD-Net: An Efficient Framework for Dynamic Networks". Si parla delle differenze tra reti statiche e dinamiche. Le reti dinamiche possono cambiare architettura o parametri in base all'input. Si esaminano esempi come Mixture of Experts e Dynamic Convolution. Si afferma che le reti dinamiche sono spesso completamente dinamiche, ma questo può portare a un'eccessiva utilizzo di parametri. Il paper propone PAD-Net, un framework parzialmente dinamico che divide i parametri in dinamici e statici. Si usa Iterative Mode Partition per separare i due modi. L'obiettivo è ridurre i parametri dinamici superflui. Si dimostra che PAD-Net ha prestazioni migliori rispetto alle reti statiche e dinamiche complete, mantenendo meno parametri e calcoli. Si eseguono studi di ablation per trovare le proporzioni ottimali per Dynamic Convolution e Mixture of Experts. Si trova che i fattori di scala per i</sample>
    <sample id="85">Un esempio di pianificazione linguistica vincolata è "fare un torta al cioccolato".</sample>
    <sample id="86">Gli autori verificano la segretezza del loro metodo attraverso la visualizzazione delle embedding delle frasi su quattro dataset utilizzando PCA.</sample>
    <sample id="87">Il lavoro utilizza i PLM esistenti come RoBERTa per costruire DrBERT. Adotta un approccio di pre-training da zero utilizzando NACHOS, un set di dati di dati medici riscattati dalla rete. Inoltre, confronta DrBERT con ChuBERT, che utilizza dati anagrafici anonimizzati ottenuti dal data warehouse dell'ospedale universitario di Nantes.</sample>
    <sample id="88">GPT-4 è meno allineato con i non binari.</sample>
    <sample id="89">In the example sentence "If we receive a speech chunk containing "I'm going to talk about..." and our model predicts the translation in German, and we will look at the cross-attention weights, we'll see that the first two words points to the earliest received speech frames, while the last word points to the last received speech frames, as lambda speech frames. This means that the first two words will be emitted while since the sum of the cross-attention is above a certain threshold alpha, we will not emit the last word and we wait for another speech chunk. If we go on and we receive another speech chunk, and our model predicts other three words and we will look at those cross-attention weights, we will see that no word points to the last lambda speech frames. This means that these three words will be emitted." the speaker shows how the model exploits the knowledge learned through the attention mechanism.</sample>
    <sample id="90">L'autore, Haneul Yoo, e altri hanno studiato se i apprendisti linguistici possono contribuire alla annotazione di dati in NLP. Hanno scelto tre lingue: inglese, coreano e indonesiano. Hanno adottato e rivisto i criteri CFR per classificare i apprendisti in livelli: base, intermedio e avanzato. Hanno condotto esperimenti con apprendisti e native speakers. I risultati mostrano che le annotazioni degli apprendisti sono quasi accurate, specialmente per le compiti più semplici. Inoltre, se le annotazioni degli apprendisti vengono aggregate con quelle dei native speakers, sono quasi allo stesso livello. I modelli NLP addestrati con le annotazioni degli apprendisti hanno raggiunto un'accuratezza del 95% rispetto a quelle dei native speakers. Questo studia suggerisce un nuovo modo per costruire dati in lingue a risorse basse e medie, utilizzando gli apprendisti come annotatori.</sample>
    <sample id="91">Quando aumenta il numero di attività, il modello ottiene una performance migliore e al contempo una sensibilità più bassa.</sample>
    <sample id="92">Non ho trovato elencati tre approcci di riferimento specifici nel testo che hai fornito. Potresti fornire ulteriori dettagli o controllare se c'è un errore di copia e incolla?</sample>
    <sample id="93">I coautori sono i mentori del primo autore.</sample>
    <sample id="94">L'articolo introduce il problema di proteggere il copyright delle servizi di embedding basati su grandi modelli linguistici. Attualmente, modelli come GPT, LLAMA, PALM sono eccellenti in comprensione e generazione del linguaggio naturale. I servizi di embedding sono uno dei servizi costruiti su questi modelli per assistere in diverse compiti NLP. Tuttavia, recenti studi mostrano che un attaccante potrebbe rubare il modello attraverso l'apprendimento dall'embedding e fornire servizi simili. Per proteggere il copyright, si propone Embedding marker, un metodo di watermark basato su backdoor applicabile ai servizi di embedding. L'Embedding marker contiene due passaggi principali: l'iniezione del watermark e la verifica del copyright. Prima di questi passaggi, si seleziona un set di parole di frequenza moderata. Durante l'iniezione del watermark, si definisce un'embedding di riferimento. Quando un utente invia una frase al servizio, il provider conta il numero di parole del set di riferimento nella frase. L'embedding fornito</sample>
    <sample id="95">David Vilar.</sample>
    <sample id="96">Ciao a tutti. Sono Jenny, un primo anno di dottorato all'Università Carnegie Mellon e oggi presenterò il vostro lavoro "NLPositionality" che caratterizza i bias di progettazione dei dataset e dei modelli. Questo lavoro è stato realizzato in collaborazione con alcuni colleghi dell'Università di Washington e dell'Allen Institute for AI, tra cui Sebastian Santy, Ronan Le Bras, Katharina Reinecke e Maarten Sap. Iniziamo immaginando che tu lavori per un giornale e stai filtra i commenti sotto un tuo articolo per rimuovere il contenuto tossico. Potresti rivolgerti a un'API popolare come Prospective API per la rilevazione di tossicità, e questo funziona veramente bene se sei Carl Jones. Dove Prospective API riesce a rilevare correttamente le istanze tossiche. Ma non è così per Aditya Sharma. Dove Prospective AP non è così sensibile alle parole offensive più comuni in contesti indiani. Questo è un esempio di un bias di progettazione dove vediamo differenze sistematiche di prestazione</sample>
    <sample id="97">La relatrice menziona tre problemi associati a SimulST. Se hai altre domande o vuoi discutere di questo argomento, sentiti libero di chiedere.</sample>
    <sample id="98">Un modo efficace potrebbe essere pretrainare i modelli su diversi corpus partizionati in base alla loro tendenza politica. Questo permette di vedere come le ideologie dei modelli si spostino in base ai dati di formazione. Inoltre, dividere i corpus in base al periodo storico potrebbe aiutare a identificare la polarizzazione attuale nella società.</sample>
    <sample id="99">Ciao, sono Siyu Yuan della Fudan University. Volevo presentare il nostro lavoro "Distilling Script Knowledge from Large Language Models for Constrained Language Planning". Nella vita quotidiana, gli esseri umani pianificano le proprie azioni seguendo istruzioni a passi, sotto forma di script orientati a obiettivi. Le ricerche precedenti hanno sfruttato i modelli di linguaggio per pianificare obiettivi astratti di attività stereotipiche come "fare un torta". E hanno dimostrato che i grandi modelli di linguaggio possono effettivamente decomporre gli obiettivi in passaggi. Tuttavia, le ricerche precedenti si sono principalmente concentrate sulla pianificazione di obiettivi astratti di attività stereotipiche. La pianificazione di obiettivi con specifiche restrizioni, come "fare una torta al cioccolato", rimane ancora poco studiata. Nella nostra paper, definiamo il problema della pianificazione linguistica con restrizioni che impongono diverse restrizioni sugli obiettivi di pianificazione. Un obiettivo astr</sample>
    <sample id="100">PromptRank è un approccio data-efficient per la recuperazione di catene multi-hop. Utilizza un metodo di recupero non supervisionato TF-IDF e una reclassificazione con un modello di linguaggio a pochi shot. Recupera una pool di candidati catene, le espande e le ristrette per ottenere catene non ristrette. Ogni catena viene convertita in un prompt e valutata con la probabilità del quesito data il prompt della catena. Costruisce i prompt inserendo i documenti della catena e usa un token indicatore. L'istruzione serve a elicitare le capacità di ragionamento del modello di linguaggio sulle documenti della catena. Esplora tecniche come la ricerca di istruzioni e la scalatura del temperatura. Eseguiti esperimenti con GPT2-XL e T5-XL su HotpotQA. Risulta superiore a sistemi supervisionati come DrKit e comparabile a sistemi multi-hop di punta. Esperimenti con PromptRank come recuperatore per il QA multi-hop dimostrano buone prestazioni. L'abstract conclude con</sample>
    <sample id="101">La fluidità di PaLM è comparabile a quella dei sistemi di punta.</sample>
    <sample id="102">Un metodo di filigrana deve essere applicabile all'embedding as services, non degradare l'utilità delle embeddings fornite, essere abbastanza nascosto per l'attaccante o l'attaccante può facilmente rimuovere la filigrana, e la filigrana deve essere trasferibile ai servizi dell'attaccante durante il processo di estrazione del modello.</sample>
    <sample id="103">Mi dispiace, il contenuto non specifica quali siano le 14 lingue diverse. Potresti provare a cercare ulteriori informazioni?</sample>
    <sample id="104">Non è specificato quanti istanze vengono campionate per la riannotazione.</sample>
    <sample id="105">Cosine e L2.</sample>
    <sample id="106">Il lavoro presentato, QUEST, è una ricerca in collaborazione con Google DeepMind. Si concentra su come le persone esprimono le loro necessità di informazione con diverse restrizioni o preferenze. Per esempio, Jane cerca di identificare una specie di rettile in Costa Rica e Austin cerca romanzi storici francesi. QUEST è un dataset di ricerca con oltre 3.000 query di ricerca di entità che contengono operazioni di insiemi impliciti. Il dataset è costruito utilizzando categorie di Wikipedia da quattro domini: film, libri, piante e animali. Si mostra che il dataset presenta un problema di ricerca difficile per i sistemi, poiché devono cercare in un vasto corpus di documenti per trovare set di risposte multipli. Si valutano sistemi utilizzando la precisione del set di risposte completi e si scopre che le query con intersezione e differenza di insiemi sono particolarmente difficili. Si spera che QUEST possa aiutare i future ricercatori a costruire sistemi migliorati per le loro scelte di informazione con necessità</sample>
    <sample id="107">I modelli basati su codificatori multilingue sono stati utilizzati per ottenere il miglior rendimento su tutte le nove basi dati. Inoltre, si è trovato che l'addestramento in una mistura di diverse lingue può migliorare l'Encoder-Decoder o l'Encoder-PTR.</sample>
    <sample id="108">L'articolo esplora la robustezza dei giudizi di accettabilità dei modelli di linguaggio in contesto. I coautori, Koustav Sinha e altri, rivedono il paradigma dei minimi paresi. Questo paradigma valuta i modelli di linguaggio basandosi su giudizi di accettabilità, inclusi grammaticalità e stereotipi. Attualmente, i pipeline di valutazione non permettono di valutare l'accettabilità dei modelli su sequenze più lunghe. I coautori cercano di migliorare questo aspetto. Simulano sequenze più lunghe, creando frasi accettabili o non accettabili da set di dati. Analizzano l'effetto di frasi di prefisso accettabili o non accettabili su giudizi di accettabilità. I risultati mostrano che i giudizi di accettabilità sono robusti per contesti lunghi, ma possono cambiare significativamente quando le frasi di prefisso vengono scelte dallo stesso set di dati.</sample>
    <sample id="109">L'articolo introduce Unnatural Instructions, un dataset di istruzioni naturali per una varietà di compiti di lingua naturale. Questo dataset è stato raccolto in modo completamente automatico utilizzando un modello pre-addestrato, come una variante di GPT-3. Si è generato automaticamente un quarto esempio di istruzione e input, e poi un output corrispondente. Inoltre, sono state generate alternative formule di ogni istruzione. Il dataset contiene 64.000 esempi, con 240.000 se considerati anche i parossimi. Le istruzioni sono creative e diverse, alcune molto diverse da quelle classiche di NLP. Il modello T5 addestrato su Unnatural Instructions ha superato T0++ e Tk-instruct in diversi benchmark. Unnatural Instructions evidenzia la capacità dei modelli di linguaggio di produrre dati creativi e diversi, in modo più economico e veloce rispetto alle annotazioni umane.</sample>
    <sample id="111">The authors assume the provider can collect a general text corpus and count the word frequency with it.</sample>
    <sample id="112">Ciao a tutti, il mio nome è Shuheng. Oggi presenterò il nostro articolo "Do CoNLL-2003 named entity taggers still work well in 2023?". Iniziamo. Il nostro articolo ha indagato il problema della generalizzazione utilizzando la compito di Riconoscimento di Entità Nomeate o NER. Abbiamo osservato che i modelli sono stati utilizzati in CoNLL-2003 per lo sviluppo di NER per quasi 20 anni e questo naturalmente solleva diversi problemi. Innanzitutto, possono questi modelli generalizzare a dati moderni? E quando sviluppiamo nuovi tagger, cosa è necessario per una buona generalizzazione? Al contempo, se osserviamo una pessima generalizzazione, cosa causa il calo di prestazione di questi modelli? Per investigare questi problemi, abbiamo sviluppato il dataset CoNLL++. Questo è un dataset che abbiamo raccolto da Reuters News del 2020 e poi annotato con le stesse linee di annotazione CoNLL-20</sample>
    <sample id="114">Il lavoro introduce "Finding the Pillars of Strength for Multi-Head Attention" da Nanyang Technological University. Si parla delle limitazioni dei grandi modelli linguistici, come i pesanti parametri e il tempo di addestramento lungo. Si concentra sul problema dei pesanti parametri. I multi-head attention possono essere ottimizzati per ridurre i parametri. Propone un gruppo di attenzione con una strategia di divisione e conquista. Il primo stadio è l'addestramento con restrizioni di gruppo per dividere le teste in gruppi. Il secondo stadio è l'algoritmo di voto - rimanere per rimuovere le teste ridondanti. Si valuta sui compiti di traduzione automatica, modello di linguaggio e riassunto astrattivo. I modelli GHT e GHT-PS ottengono miglioramenti di prestazioni e riduzione di parametri significativa. L'analisi di efficienza mostra un modello LITE con 90% di parametri rimossi, 62% di velocità di inferenza più veloce e 80% di FLOPs più</sample>
    <sample id="115">L'approccio utilizza un segmento parlato di lunghezza lambda.</sample>
    <sample id="116">Per risolvere il problema con Servin e Kea, sono necessarie le conoscenze specifiche dell'entità come "Servin è un giudice."</sample>
    <sample id="117">La qualità dell'esempio è più importante.</sample>
    <sample id="118">L'articolo presenta un'analisi di tecniche di pre-allenamento per il NLP in lingue miste. Definisce il code-switching come la combinazione di parole in diverse lingue in una frase. I modelli multilingue come mBERT e XLM-R non performono bene sui task di code-switching. L'opera propone SwitchMLM, un nuovo obiettivo MLM adattato al code-switching. Definisce i switch-point come gruppi di due token che segnano la transizione tra lingue. Offre FrequencyMLM come metodo alternativo. Propone anche modifiche architetturali come connessioni residuali e una perdita ausiliaria basata su LID. I risultati mostrano che il metodo combinato, Switch o FrequencyMLM con ResBERT e perdita ausiliaria, è il migliore per la sentiment analysis in tutte le coppie di lingue. I test di probing confermano l'aumento di informazioni sui switch-point nelle varie layer. In sintesi, si propone un nuovo obiettivo MLM per gestire il code-switching e si verifica l'aumento di informazioni sui</sample>
    <sample id="119">L'articolo si concentra sugli esperimenti estesi sui modelli linguistici GPT-4, GPT serie, BART serie e suoi varianti.</sample>
    <sample id="120">Il modello utilizza i punteggi di attenzione di un livello specifico.</sample>
    <sample id="121">Esempi di inferenza diretta sono direttamente nominare il nome del brano "Easy on Me" o indicare la sua posizione, "la prima".</sample>
    <sample id="122">Fudan University.</sample>
    <sample id="123">Il lavoro presenta MultiInstruct, un dataset di tuning di istruzioni multi-modale per migliorare l'apprendimento zero-shot in modelli pre-trainati multi-modali. Si scopre una disparità nella disponibilità di dataset di istruzioni tra NLP e multi-modale. Si costruisce quindi MultiInstruct con 62 task diversi di 10 categorie. Si usa OFA come modello base. Per l'allenamento, si usano 53 task da 9 gruppi e si selezionano 10.000 istanze per task. Per la valutazione, si usa la stessa metrica per task di classificazione multi-modale e generazione multi-modale. Si dimostra che il tuning di istruzioni può migliorare significativamente l'performance di OFA sui task multi-modali visti. La transfer learning da dataset di istruzioni naturali aiuta a migliorare l'performance e la sensibilità. Si propone un nuovo metrico chiamato sensibilità. Si sta raccogliendo un dataset più grande con 150 task aggiuntivi.</sample>
    <sample id="124">Tan Qingyu e il team hanno studiato la capacità di ragionamento temporale dei grandi modelli di linguaggio. Hanno suddiviso il ragionamento temporale in tre livelli: ragionamento tempo-tempo, tempo-evento e evento-evento. I modelli esistenti sovrastimavano il ragionamento L2. Hanno creato il TempReason dataset che copre tutti e tre i livelli e diverse periodicità temporali. Hanno proposto una strategia di allenamento con estrazione di spazi temporali e apprendimento rafforzato temporale. I risultati mostrano che TempT5 migliora significativamente i modelli fine-tuned su TempReason. Hanno anche scoperto che i modelli esistenti hanno diversi bias temporali. In conclusione, hanno presentato un benchmark TempReason e un paradigma di allenamento per migliorare la capacità temporale dei modelli di linguaggio.</sample>
    <sample id="125">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni o controllare il documento?</sample>
    <sample id="126">No, non è stato considerato come un approccio standard.</sample>
    <sample id="127">Il lavoro introduce un metodo per trasferire le capacità di ragionamento di grandi modelli linguistici a modelli più piccoli. Si parla di "Chain-of-thought reasoning" e di come solo modelli enormi come GPT-3 o PALM possono gestire questo tipo di ragionamento. Propone di usare questi modelli come "professori" per insegnare le capacità di ragionamento ai modelli più piccoli. Presenta una tecnica chiamata "Diverse Reasoning" che genera molte soluzioni di ragionamento diverse per migliorare l'addestramento del modello studente. Confronta i risultati con baselines esistenti e mostra che il loro metodo può ottenere prestazioni significative in molti compiti, specialmente quelli basati su testo. L'abstract conclude dicendo che il metodo è accessibile, efficace e altamente scalabile, ma che ci sono trade-off tra costi di sviluppo e costi di inferenza.</sample>
    <sample id="128">L'articolo presenta un test di integrazione del conoscenza, KITMUS, per valutare la capacità di modelli di intelligenza artificiale di integrare conoscenza acquisita durante la pretraining e durante l'inferezione. Si introduce un compito di risoluzione di riferimento per testare l'abilità di utilizzare conoscenza di diverse fonti. Si valuta con partecipanti umani e modelli di risoluzione di riferimento esistenti. Si definiscono tre impostazioni di KITMUS: Background-Pretrain, Background-Both e Background-Inference. Si dimostra che senza addestramento specifico su KITMUS, i modelli non performono bene. Con l'addestramento su KITMUS, alcuni modelli come C2F e BERT4Coref migliorano significativamente. Si conclude che molti modelli di risoluzione di riferimento non riescono a ragionare su conoscenza di diverse fonti senza addestramento specifico, ma con esso alcuni modelli riescono a integrare conoscenza da diverse fonti.</sample>
    <sample id="129">I gruppi contrassegnati sono gli uomini bianchi.</sample>
    <sample id="130">Non sono state menzionate specifiche architetture dei modelli che non generalizzano in modo adeguato. Solo le architetture che generalizzano bene sono state menzionate, come le architetture transformer. Se hai altre domande, puoi chiedere.</sample>
    <sample id="131">Non so quali siano i nomi dei set di dati di test. Potresti dare più informazioni o controllare il contenuto del video?</sample>
    <sample id="132">Due.</sample>
    <sample id="133">L'autore opera con più modalità.</sample>
    <sample id="135">L'articolo presenta ABC-Eval, un approccio dimensionale per valutare l'intelligenza artificiale conversazionale. ABC-Eval, sviluppato dal Emory NLP Lab e in collaborazione con Amazon Alexa AI, cerca di ridurre la soggettività dell'evaluation umana. Si concentra su annotare comportamenti specifici nei modelli di chat, come risposte irrellevanti o contraddittorie. ABC-Eval misura errori tematici come l'ignoranza del partner, la produzione di informazioni irrellevanti, la contradizione e la violazione del buon senso. L'articolo valuta quattro modelli chat state-of-the-art su 100 conversazioni umano-bots. ABC-Eval dimostra essere più affidabile e prevedibile rispetto a metodi esistenti, come misurare il 5% e il 10% della qualità della conversazione rispettivamente per le contraddizioni di se stessi e del partner. ABC-Eval permette di valutare l'intelligenza artificiale con una risoluzione maggiore rispetto ai</sample>
    <sample id="136">L'articolo presenta FERMAT, un set di valutazione flessibile per la ragionamento numerico. Motivato dalle applicazioni reali del ragionamento numerico e delle sue esigenze in task a seguito, si analizzano modelli di linguaggio di varie dimensioni. Si evidenzia che modelli più piccoli performono peggio in ragionamento numerico. Si introduce FERMAT basato su tipi di aritmetica, testando comprensione numerica, operazioni matematiche e dipendenza da formazione. Si esegue una valutazione di base e una fine-tuning con insegnanti di matematica. Si scopre che la diversità linguistica e matematica migliora le prestazioni. Conclusione: i benchmark esistenti sono poco rappresentativi e FERMAT fornisce un'alternativa più informativa. Si ritiene che la diversità sia importante e che miglioramenti siano necessari in codifica dei numeri e tokenizzazione.</sample>
    <sample id="137">L'articolo presenta il dataset Tell2Design per la generazione di piani di pavimento guidati dal linguaggio. Si concentra sulla generazione di piani di pavimento che rispondono a istruzioni naturali. Il modello utilizza un approccio a sequenza di encoder-decoder per gestire istruzioni lunghe e complesse. Rispetto ai metodi esistenti, questo modello gestisce meglio le istruzioni multiple e le restrizioni specifiche. Le metriche di valutazione mostrano che il modello ha un'efficienza superiore rispetto ai metodi di generazione di immagini condizionati dal testo. L'articolo suggerisce che il gap di distribuzione tra istruzioni artificiali e umane può essere superato con l'uso di istruzioni artificiali per il pre-allenamento. L'obiettivo finale è promuovere la ricerca futura sulla generazione di progetti guidati dal linguaggio.</sample>
    <sample id="138">Secondo gli autori, l'area della NLU che è poco studiata è l'integrazione e l'utilizzo del conoscenza sia acquisita durante il pretraining che fornita in tempo di inferenza.</sample>
    <sample id="139">I nomi dei relatori sono Ying e Zhiyang.</sample>
    <sample id="140">Sì, CoScript è stato sottoposto a controlli di qualità. Crowd-sourced workers hanno trovato e corretto le samples errate.</sample>
    <sample id="141">Le risorse esistenti per la traduzione dipendente dal contesto hanno limiti perché supportano solo tipi limitati di traduzioni dipendenti dal contesto e set di lingue limitati, in quanto spesso si basano su conoscenza di dominio e curazione umana.</sample>
    <sample id="142">Ciao! Sto parlando del nostro lavoro su "Risoluzione di espressioni riferimento indiretto per la selezione di entità". Introduciamo il Corpus AltEntities. Il mio nome è Javad Hosseini e questo è un lavoro a squadra con Filip Radlinski, Silvia Pareti e Annie Louis. Il nostro obiettivo è capire il linguaggio degli utenti quando vogliono fare una scelta. Considera questa domanda alternativa: "Volevi dire 'Easy on Me' o 'I Gotta Feeling'?" Qui, l'utente vuole scegliere tra questi due brani musicali. La cosa più ovvia è usare un riferimento diretto, ad esempio citando il nome del brano "Easy on Me" o la sua posizione, "il primo". Ma a volte un riferimento indiretto è più appropriato per una conversazione più naturale. Potrebbe succedere quando l'utente non ricorda il nome del brano. O le pronunciazioni sono troppo simili per essere facilmente disambiguate. O quando l'utente vuole specificare una prefer</sample>
    <sample id="143">Con Wait-k strategy, Local Agreement e l'architettura state-of-the-art specificamente adattata per la pre-traduzione simultanea.</sample>
    <sample id="144">Non so qual è l'affiliazione degli autori dell'articolo. Potresti dare più informazioni o controllare il documento originale?</sample>
    <sample id="145">Jenny</sample>
    <sample id="146">L'analisi dell'omissione nel riassunto di dialoghi è un problema serio. I modelli di grandi scale hanno fatto progressi, ma gli errori di omissione sono comuni. L'omissione è un fattore principale che rende i riassunti incompleti. Abbiamo analizzato il tasso di omissione in cinque domini e sei modelli pre-trainati. Troviamo che anche il modello di punta raggiunge un alto tasso di omissione. L'omissione è distribuita casualmente in ogni posizione del dialogo. Per analizzare meglio il problema e risolverlo, abbiamo costruito il dataset OLDS. Proponevamo un metodo automatico per produrre etichette di omissione. Abbiamo esplorato tre basi linee con differenti formati di input e strutture. Usando la precisione, il ricordo e l'F1-score per valutare i modelli di rilevamento di omissione, troviamo che il tasso di F1 è intorno al 50%. Questo indica che il compito è molto difficile. Utilizzando l</sample>
    <sample id="147">Tre.</sample>
    <sample id="148">Ciao Sara Papi, dell'Università di Trento e della Fondazione Bruno Kessler, stai per presentare il tuo articolo "Attenzione come guida per la traduzione simultanea del discorso". Ecco la traduzione in italiano:.- Simultaneous speech translation, o SimulST, è il processo di tradurre il linguaggio parlato in un testo in un'altra lingua in tempo reale, permettendo la comunicazione tra lingue diverse.- I problemi dei modelli attuali di SimulST sono: architetture specifiche spesso addestrate, introducendo moduli aggiuntivi da ottimizzare. Lunghe e complesse procedure di addestramento, ad esempio, addestramento coinvolgente obiettivi di ottimizzazione diversi. Addestrare e mantenere diversi modelli per raggiungere diversi regimi di latenza. Ad esempio, addestrare un modello con un'average di latenza di un secondo e un altro con due secondi, e così via.- La nostra soluzione è: utilizzare già esistenti modelli ST offline senza r</sample>
    <sample id="149">Sì.</sample>
    <sample id="150">L'articolo presenta MeetingQA, un dataset di domande e risposte estrattive basato su interventi di partecipanti in riunioni e risposte corrispondenti. Le riunioni sono documenti lunghi, specifici di dominio e ricchi di informazioni. Prima opere si concentrano solo su riassumere e estrarre item di azione. MeetingQA introduce un nuovo dataset con domande lunghe, aperte e che cercano discussioni. La raccolta dati parte da riunioni pubbliche dell'AMI corpus. Il dataset contiene 7.7K domande divise in Train, Dev e Test. Il test set ha un F1 di 84.6. Utilizzano metodi come modello di contesto corto, modello a un solo spagnolo e variante multi-spagnolo. Nella configurazione fine-tuned, i modelli hanno un gap di oltre 25 punti F1 rispetto alla performance umana. Nella configurazione zero-shot, c'è un gap di quasi 50 punti F1. L'augmentazione dei dati d'argento migliora la performance</sample>
    <sample id="151">Ciao a tutti, il mio nome è Ying e il mio collega Zhiyang e noi presenteremo la nostra ricerca su MultiInstruct che migliora il Multi-Modal Zero-Shot Learning tramite l'addestramento delle istruzioni. Con l'avanzamento dei grandi modelli linguistici, molte ricerche hanno iniziato a esplorare nuovi paradigmi di utilizzo di modelli pre-allenati per compiti differenti in modo efficiente sia in termini di parametri che di dati. Recentemente, molte ricerche hanno dimostrato che l'addestramento delle istruzioni consente ai grandi modelli linguistici di eseguire compiti non visti in modo zero-shot seguendo istruzioni naturali. Tuttavia, la maggior parte delle ricerche precedenti sull'addestramento delle istruzioni si è concentrata sul miglioramento del presto zero-shot per compiti solo linguistici, mentre i compiti di visione computeristica e multi-modalici sono stati lasciati fuori. Quindi, in questa ricerca vogliamo indagare se l'addestramento delle ist</sample>
    <sample id="152">L'abstract parla di un progetto che esplora l'uso di grandi modelli di linguaggio per la filologia classica, in particolare per il greco antico e il latino. Si presentano risorse utili per questi linguaggi e si esplorano le implicazioni e le sfide della multilinguismo in questi modelli. Si parla di modelli come Latin BERT, Ancient Greek BERT e altri. Si menziona la creazione di nuovi modelli specifici per la filologia classica, come GreBERTa e GreTa per il greco antico e PhilBERTa e PhilTa per il latino e l'inglese. Si descrive il processo di raccolta di dati per la pre-Allenamento, utilizzando risorse come Open Greek &amp; Latin e il Corpus Corporum per il latino. Si parla di benchmarking e di risultati superiore dei modelli in termini di taggatura di grammatica, analisi di dipendenza e lemmatizzazione. Si conclude con l'annuncio di un'opera pubblicata per ulteriori dettagli.</sample>
    <sample id="153">Ninareh Mehrabi, un postdoctoral scientist all'Alexa AI di Amazon, presenta il lavoro "Risolvere ambiguità in modelli generativi testo-immagine". Studiano ambiguità in prompt forniti ai modelli. Ad esempio, "La ragazza entra nella stanza con fiori" è ambiguo. Il loro obiettivo è proporre framework per mitigare queste ambiguità e valutare se le immagini generate siano fedeli all'intenzione dell'utente. Curano un dataset di benchmark che copre diversi tipi di ambiguità. Il modello di linguaggio genera domande clarificanti o diverse interpretazioni visive. L'utente risponde e ottiene un prompt disambiguato. Proppongono un framework automatico per valutare la fedeltà all'intenzione dell'utente. Mostrano che il disambiguazione ha un effetto positivo sulla generazione fedele e che il loro framework automatico concorda con l'evaluation umana.</sample>
    <sample id="154">L'autore Sara Papi è affiliata all'Università di Trento e alla Fondazione Bruno Kessler. L'autore Matteo Negri e Marco Turchi non sono specificati come affiliati.</sample>
    <sample id="155">Javad Hosseini.</sample>
    <sample id="157">L'abstract è lungo e dettagliato. In generale, parla di un modello di sommariizzazione del dialogo chiamato SDDS. Il modello utilizza un encoder per codificare le afferenze in rappresentazione vettoriale. Costruisce una struttura statica del dialogo e una struttura dinamica per catturare le relazioni semantiche. Utilizza un modello di attenzione multi-capo per calcolare le relazioni tra le afferenze. Infine, fonde le strutture statica e dinamica per generare il sommario finale. Il codice e i dati sono stati rilasciati su GitHub.</sample>
    <sample id="158">L'abstract è: "Il lavoro introduce Dual Cache per risolvere il problema di coreference in documenti lunghi. Il task di coreference risolve la relazione tra menzioni di entità nello stesso documento. I metodi tradizionali hanno complessità quadratici, mentre i metodi basati su cache riducono a lineare. Tuttavia, l'eviction policy LRU può causare cache miss in documenti lunghi. Propone Dual Cache con cache locale e globale. La cache locale usa LRU, mentre la globale LFU. Il modello valuta la frequenza delle menzioni e le aggiunge alle rispettive cache. Dual Cache ha ottenuto risultati migliori su benchmark pubblici rispetto ai metodi di base, anche con memoria illimitata. Rispetto a una singola cache, Dual Cache riduce significativamente i miss di cache. È il metodo più cost-eficiente tra i metodi basati su cache."</sample>
    <sample id="159">Ciao a tutti. Sono Koustav Sinha, e sono lieto di accogliervi al nostro talk sul nostro articolo di ACL 2023. Le giudicazioni di accettabilità dei modelli di linguaggio non sono sempre robuste al contesto. Questo è un lavoro a squadra con John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy e Adina Williams. Quindi, in questo lavoro, rivediamo i paradigmi di coppia minima. Il paradigma di coppia minima valuta i modelli di linguaggio sulla base delle giudicazioni di accettabilità. Che possano anche includere grammaticalità come BLiMP, SyntaxGym o accettabilità in termini di stereotipi come le coppie CrowS. E in questo paradigma di coppia minima, la maniera tipica di valutare i modelli è mostrare una frase accettabile o grammaticalmente corretta e poi mostrare una frase accettabile o non grammaticalmente corretta. E la speranza è che il modello, in generale, met</sample>
    <sample id="160">unordered multiset of tokens</sample>
    <sample id="161">In total, we generate 55, 000 specific goals with scripts.</sample>
    <sample id="163">Il metodo di allineamento migliore per DEplain è il metodo di MASSalign.</sample>
    <sample id="164">L'apprendimento scarsamente supervisionato ha il vantaggio di essere più economico rispetto all'apprendimento supervisionato a pieno.</sample>
    <sample id="165">L'articolo introduce un metodo di apprendimento non supervisionato per la ragionamento abducente, chiamato LiPoR. Si considera un contesto X e un'uscita Y, e si cerca una spiegazione plausibile che collega i due. LiPoR tratta le spiegazioni come variabili latenti. L'obiettivo è massimizzare la probabilità marginale dell'uscita data il contesto. Per favorire spiegazioni plausibili, si utilizza un regolarizzatore basato sulla esclusività reciproca delle spiegazioni. LiPoR è stato testato su AlphaNLI e ha superato altri modelli, incluso un forte zero-shot GPT-3, di circa 4 punti in precisione.</sample>
    <sample id="166">L'abstract parla di un nuovo lavoro intitolato "A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Linguistically Complex Text". L'immagine di ricerca da testo linguisticamente complesso è un compito di ragionamento immagine-testo difficile perché le immagini sono molto simili e la descrizione è lunga. I metodi tipici, come i modelli visuo-linguistici, fanno bene alle tare di ricerca immagine-sentenza, ma la loro prestazione cala drasticamente di fronte al testo linguisticamente complesso. Per affrontare questo problema, si è ispirati alla strategia Divide-and-Conquer e alla Dual-Process Theory. Il primo modello proposto è il Generatore di Proposizioni, che mira a decomporre le proposizioni testo complesse in rappresentazioni di proposizioni semplici. Il Sistema 1, l'Interattore Visuo-Linguistico, esegue l'interazione di informazioni tra le proposizioni visive e le proposizioni, simile al Sistema 1. Il Sistema 2, il Raisonneur Neurale-S</sample>
    <sample id="167">Per DEPLAIN-web, 750 documenti sono stati allineati manualmente e con metodi di allineamento automatici.</sample>
    <sample id="168">Il set di dati CoNLL++ è stato creato raccolgendo notizie da Reuters News del 2020 e annotandole con le stesse linee guida di annotazione di CoNLL-2003.</sample>
    <sample id="169">L'articolo presenta uno studio sistematico sulla prompting di PaLM per la traduzione. PaLM è un modello di linguaggio a grandi dimensioni con 540 miliardi di parametri. È stato addestrato su un vasto insieme di testo con 780 miliardi di token. Al momento della pubblicazione, ha raggiunto i migliori risultati in molte tesi di NLP. L'articolo valuta la capacità di transizione del modello utilizzando le migliori pratiche della comunità di MT. Si confronta con i sistemi di traduzione di punta, come WMT. Utilizza metriche di traduzione di punta e valutazioni umane. Si dà delle raccomandazioni per la scelta di strategie di prompt. La prompting ha un grande impatto sulla performance dei LLM per la traduzione. Con una prompting a 5 shot, si vede che l'effetto della forma del prompt non è così importante. L'insight principale è che la qualità degli esempi è più importante della somiglianza con il testo di origine. PaLM si avvicina a un</sample>
    <sample id="170">Ciao a tutti, il mio nome è Yusen Zhang dalla Penn State University. Oggi presenterò il nostro lavoro "XSemPLR: Parsing Semantico Translazionale in Più Lingue Naturali e Rappresentazioni di Significato". Il parsing semantico è una task per costruire rappresentazioni semantiche di query utente come SQL e Calcolo Lambda. E il parsing semantico translazionale è la task di tradurre query in più lingue naturali in più rappresentazioni di significato. Come mostrato in questa figura, dobbiamo tradurre la query in più lingue naturali utilizzando modelli neurali in SQL, Lambda o FunQL, ecc. I modelli di parsing semantico translazionale esistenti sono proposti e valutati separatamente su set di dati di compiti e applicazioni limitati. Ad esempio, ci sono molte coperture su certe lingue naturali. Ma il cinese manca e manca di copertura su certe rappresentazioni di significato. Il Calcolo Lambda manca, o sono solo valutati su certi modelli neurali. Ad esempio,</sample>
    <sample id="171">I work related to this are broadly classified into four categories. Existing works can be broadly classified into four categories.</sample>
    <sample id="172">No, multilingual language models like Codex and Bloom are still inadequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="174">ArgAnalysis35K è un dataset unico per l'analisi della qualità dell'argomento. Ha 35K coppie di argomento-analisi, il più grande in questo campo. Argomenti di alta qualità sono raccolti da tornei di alta qualità, esperti e debattenti intermedi. Ha una diversità di argomenti basata su 24 temi. Introduce l'analisi come una combinazione di affermazioni e premesse. Include un modello di rilevanza che assegna un punteggio da 0 a 1 per la rilevanza di ogni argomento a un tema. Questo dataset è diverso da altri in termini di qualità, diversità e affidabilità delle annotazioni.</sample>
    <sample id="175">Il metodo affronta l'ambiguità delle permutazioni introducendo una relaxazione continua amichevole per GPU. Questa permette di indietreggiare attraverso la soluzione e imparare le permutazioni più plausibili dal punto di vista linguistico.</sample>
    <sample id="176">L'equità di un modello NLP a valle si riferisce a come il modello gestisce le differenze politiche e possibili pregiudizi presenti nel suo training data. Se un modello è equo, dovrebbe essere in grado di gestire le diverse opinioni politiche in modo equo, senza creare disparità o discriminazione in applicazioni successive.</sample>
    <sample id="177">Yanis Labrak</sample>
    <sample id="178">Koustav Sinha.</sample>
    <sample id="179">L'articolo parla di come migliorare le capacità di Theory of Mind nei grandi modelli di linguaggio. Si introduce SymbolicToM, un metodo che usa rappresentazioni grafiche esplicite per migliorare le capacità di Theory of Mind. Si testa con vari modelli di linguaggio e si vede che aumenta significativamente le prestazioni. Si testa anche la generalizzazione, e SymbolicToM migliora ancora. Per più dettagli, si veda il paper.</sample>
    <sample id="180">Myra.</sample>
    <sample id="181">The paper introduces constrained language planning, focusing on planning for goals with specific constraints. It evaluates large language models' ability in this area, finding unsatisfactory results. The authors then analyze why models fail, noting issues with semantic completeness and constraint faithfulness. They propose an over - generate - then - filter method to improve generation quality. This involves over - generating scripts and filtering based on semantic similarity and keyword matching. The method is applied to create a high - quality dataset, CoScript, for constrained language planning. T5 fine - tuned on CoScript outperforms most large language models. The paper establishes the problem, evaluates models, and develops a method for constrained language planning. It aims to advance research in this area with the CoScript dataset.</sample>
    <sample id="182">Nel contesto di questo articolo, il tropicalismo indica un insieme di stereotipi e tropi che sono associati alle donne di colore, in particolare le donne latine. Questi stereotipi includono descrizioni come "vibrante" e "curvaceous", che riflettono una visione stereotipata e potenzialmente dannosa di queste donne. Se hai altre domande su questo argomento, sentiti libero di chiedere.</sample>
    <sample id="183">Gli autori hanno elaborato le rappresentazioni umane dei gruppi target chiedendo ai modelli di LLM di generare personaggi usando promemoria come "Imagina che tu sia una donna asiatica. Descrivi te stesso." In questo modo, possono essere generalizzati a qualsiasi demografia specificando l'identità desiderata nella promemoria.</sample>
    <sample id="184">In questo lavoro è stato utilizzato Pointwise CXMI per misurare l'utilizzo del contesto.</sample>
    <sample id="185">DrBERT è basato su RoBERTa e addestrato su NACHOS, mentre ChuBERT è basato su dati anonimizzati ottenuti dal data warehouse dell'ospedale universitario di Nantes.</sample>
    <sample id="187">Due.</sample>
    <sample id="188">L'apprendimento iterativo è utile per il trasferimento di apprendimento da un diverso dominio.</sample>
    <sample id="189">L'obiettivo del set di dati è di comprendere il linguaggio degli utenti quando fanno una scelta.</sample>
    <sample id="190">Un utente malintenzionato può estrarre i parametri del modello attraverso un EaaS aprendo un modello di backdoor.</sample>
    <sample id="191">Tre.</sample>
    <sample id="192">L'abstract parla di un'ottimizzazione di memoria chiamata CAME, CAME: Confidence-guided Adaptive Memory Efficient Optimization. Si concentra su come migliorare l'adattabilità e la memoria di ottimizzatori come Adam e Adafactor. CAME si basa su un'analisi di non-negative matrix factorization, NMF, per ridurre la memoria. Adafactor ha problemi di aggiornamento errato che limitano le sue applicazioni. CAME introduce un approccio per ridurre gli effetti negativi di questi aggiornamenti. Gli esperimenti mostrano che CAME migliora significativamente la precisione di modelli di grandi linguaggi, come BERT, GPT-2 e T5, rispetto ad Adafactor. Inoltre, CAME riduce il consumo di memoria, specialmente per grandi batch di training. L'abstract conclude dicendo che CAME è efficace per grandi modelli di linguaggio e funziona bene per grandi batch di training, estendendo l'efficacia degli ottimizzatori di memoria esistenti.</sample>
    <sample id="193">Non c'è informazione su quanti annotatori sono stati impiegati per creare il set di dati iniziale.</sample>
    <sample id="194">Carnegie Mellon University e University of Washington.</sample>
    <sample id="195">L'articolo introduce un nuovo framework per la risoluzione di domande complesse, chiamato RoHT, Reasoning over Hierarchical Question Decomposition Tree. RoHT è un approccio a due fasi. Prima, si costruisce un albero di decomposizione questioni gerarchica, HQDT, per comprendere la struttura complessa di una domanda. Si generano domande atomiche come foglie e domande intermedie basate su queste. Si calcola anche una certezza per ogni nodo. Successivamente, si effettua ragionamento probabilistico sull'HQDT per fondere conoscenza da un database e da un corpus di testo a diversi livelli. Si determinano le sorgenti di conoscenza appropriate per ogni nodo, si ottengono le risposte con probabilità e si aggregano le risposte candidate. RoHT viene valutato su due dataset di QA complesse, KQA Pro e Musique. Su KQA Pro, RoHT supera metodi esistenti di QA con database incompleti. Con Wikipedia come corpus supplementare, RoHT migliora significativamente.</sample>
    <sample id="196">"I saw Bart and Lisa"</sample>
    <sample id="197">I modelli all'avanguardia nei sistemi di dialogo sono quelli selezionati per l'evaluation con ABC-Eval. Non specifica quali siano esattamente, ma si riferiscono a quattro modelli. Se hai bisogno di più dettagli, puoi chiedere.</sample>
    <sample id="198">Perché i modelli linguistici stanno diventando sempre più grandi e gestendo contesti più lunghi.</sample>
    <sample id="199">No, Encoder-Decoder o Encoder-PTR può essere migliorato addestrando in una miscela di varie lingue.</sample>
    <sample id="200">No, gli annotatori non conoscono l'entità in anticipo.</sample>
    <sample id="201">Neural MT metrics.</sample>
    <sample id="202">Sì, il regresso nella generalizzazione influisce su specifici tipi di NER.</sample>
    <sample id="203">Perché NLP task diventano sempre più soggettive e socialmente orientate.</sample>
    <sample id="204">Non sono stati affinati né con adattatori né con una messa a punto integrale.</sample>
    <sample id="205">Lavoro di Shangbin, PhD student all'University of Washington, intitolato "Da dati di pretraining a modelli di linguaggio a compiti di livello inferiore: tracciare le tracce dei bias politici che portano a modelli NLP non equi". I modelli di linguaggio vengono addestrati su grandi set di dati web. I media politici sono ben coperti nei dati di pretraining. Secondo una ricerca del C4 Corpus, New York Times, Los Angeles Times, The Guardian, Huffington Post, ecc. sono ben coperti. Ciò ha creato un dono e un problema per le applicazioni dei modelli di linguaggio. D'una parte, hanno imparato da diverse prospettive, celebrando la democrazia e la pluralità di idee. D'altra parte, le diverse opinioni politiche sono socialmente pregiudiziali e possono portare a problemi di equità in applicazioni di compiti di livello inferiore. Propone di indagare il percorso di propagazione dei bias politici dal pretraining ai modelli di linguaggio e ai compiti di livello inferiore</sample>
    <sample id="206">Per il trasferimento dell'apprendimento, fanno ricorso a due modelli: uno per la classificazione di dissonanza indipendente dal tema e l'altro per la classificazione binaria di espansione e confronto delle classi di PDTB.</sample>
    <sample id="207">I recenti set di test utilizzati per valutare le capacità di PaLM sono quelli usati dalla comunità MT. Questi set di test sono stati utilizzati per evitare un sovrapporsi dei dati di test con quelli di addestramento del modello di linguaggio.</sample>
    <sample id="208">Tre.</sample>
    <sample id="209">Non so. Potresti dare più dettagli o informazioni?</sample>
    <sample id="210">Shuheng.</sample>
    <sample id="211">Sì.</sample>
    <sample id="212">T5 fine-tuned</sample>
    <sample id="213">OFA.</sample>
    <sample id="215">L'articolo discute delle strutture di dipendenza nella coordinazione. Alcune teorie assumono strutture asimmetriche, come in universal dependencies e in Igor Mel'čuk's theory, dove il primo congiunto è capo. Invece, il Prague approach e il Hudson's Word Grammar assumono strutture simmetriche. L'autore propone un argomento per le strutture simmetriche basato sul principio di minimizzazione della lunghezza delle dipendenze. In inglese, gli oggetti diretti preferiscono essere vicini al verbo, ma questo può essere ammesso se l'oggetto è pesante e lungo. Le statistiche estratte dal Penn Treebank confermano che i congiunti a sinistra tendono a essere più corti, a meno che il governante non sia a destra. Questo fornisce un argomento contro le strutture di coordinazione asimmetriche e a favore di quelle simmetriche. Per ulteriori dettagli, leggi l'articolo e parla con l'autore al poster session.</sample>
    <sample id="217">L'articolo introduce "Seen to Unseen: Exploring Compositional Generalization of Multi-Attribute Controllable Dialogue Generation". I ricercatori, Weihao Zeng, Lulu Zhao e Keqing He, si concentrano sulla generazione di dialoghi controllabili con più attributi. I metodi precedenti si concentrano su singoli attributi, ignorando la generazione multiattributo pratica. I loro contributi includono l'esplorazione della generazione compositiva per la generazione di dialoghi controllabili multiattributo. Proppongono DCG, un modello che impara concetti di attributo da valori visti e utilizza una perdita di disentanglement per disentanglare combinazioni di attributi diverse. Introducono un quadro di valutazione unificato e senza riferimento, MAE, per diversi gradi di attributi. Creano due benchmark e dimostrano l'efficacia del loro metodo e dei loro metrici di valutazione attraverso esperimenti. I loro modelli, basati sul framework DialoGPT con un modulo di prompt compositivo, utilizzano due</sample>
    <sample id="218">I'm sorry, but the information about the affiliations of the authors is not provided in the text you've given. You might need to look for it in the full paper or other sources. If you have any other questions about the paper, feel free to ask.</sample>
    <sample id="219">Il lavoro presenta un pipeline multistage per scoprire segnali finanziari in report finanziari. Si concentra sul Form 10-K, un report annuale richiesto dal SEC. I report contengono molte informazioni importanti sulle attività delle aziende. Tuttavia, estrarre informazioni utili richiede molta fatica umana. L'obiettivo è migliorare la minatura di informazioni utili. Si osserva che le parole nei report sono molto simili e i contenuti dipendono dall'anno. Si introduce una task di evidenziamento e un pipeline multistage. Il pipeline ha tre fasi: segmentazione del documento, riconoscimento delle relazioni e fine-tuning. Per la fase di fine-tuning, si usa un dataset esterno, eSNLI, per il fine-tuning fuori dominio e i dati riformulati per il fine-tuning intermedio. Si usa anche tecniche di etichettatura mista per migliorare la qualità delle etichette. L'evaluation si basa su due metriche: precisione e correlazione tra predizione e annotazione. Il modello di evid</sample>
    <sample id="220">L'articolo non specifica le affiliazioni degli autori.</sample>
    <sample id="221">Non so qual è la lingua di partenza e la lingua di arrivo analizzate nell'articolo. Potresti dare più dettagli?</sample>
    <sample id="222">L'articolo esplora i problemi e le soluzioni per l'adattamento di domini in risposte alle domande aperte. Si concentra su come i modelli di lettura e di recupero, addestrati su Wikipedia, si comportano quando si passa a domini specifici come la biologia. Si identificano tre contributi principali: esplorare interventi di dati utili per l'adattamento, identificare il tipo di spostamento di dataset e determinare interventi di dati efficaci per un tipo specifico di spostamento. Si utilizzano metodi zero-shot e few-shot per generare interventi di dati. Si osserva un miglioramento dell'8% per il recupero e del 11% per la lettura. Si analizza la compatibilità tra il modello di base e il nuovo dominio utilizzando una misura di probabilità. Si conclude che alcuni interventi di dati sono efficaci basandosi sul tipo di spostamento del dataset.</sample>
    <sample id="223">Shangbin.</sample>
    <sample id="224">Durante gli esperimenti sono stati studiati due modelli: il modello long-mBART e il modello mBART base.</sample>
    <sample id="225">Per scopi di addestramento vengono utilizzate 53 task, mentre per test vengono utilizzate 10 task.</sample>
    <sample id="226">Due.</sample>
    <sample id="227">Il contenuto parla di come la comprensione linguistica basata su un ambiente specifico, chiamata grounded language understanding, è un'area di ricerca mancante nelle attuali modelle di linguaggio. Queste modelle sono spesso pre-addestrate con corpus testuali senza grounding. Ci sono molte applicazioni di grounded language understanding, come assistenti intelligenti, ricerca semantica e robot domestici. La difficoltà principale è la mancanza di grounding durante la pre-addestramento. L'approccio tradizionale utilizza le modelle di linguaggio per generare direttamente un piano, ma può produrre piani non grammaticalmente validi. L'opera propone un nuovo framework per grounded language understanding, dove un agente simbolico interagisce con l'ambiente e propone candidati piani, mentre un modello di linguaggio valuta e classifica solo questi candidati. Questo permette al modello di linguaggio di non gestire la validità e la grammatica del piano di destinazione. Il framework è stato testato su domande a conoscenza basate, utilizzando diversi modelli di linguaggio come BERT</sample>
    <sample id="228">Gli autori hanno effettuato i test su quattro set di dati: AG News, MIND, SST2 e Enron Spam.</sample>
    <sample id="229">L'articolo presenta un lavoro con Henning Wachsmuth su rilevare affermazioni migliorabili per supporto all'argomentazione. Si inizia con un'introduzione alla revisione testuale, importante per la scrittura professionale. Si parla dell'importanza di trovare le parole giuste nell'argomentazione per influenzare l'audience. Si introduce il processo di revisione di un'affermazione "Le cellule causano il cancro al cervello". Si parla di due task: rilevare affermazioni subottimali e suggerire miglioramenti. Si esplorano i problemi con i dati di revisione, come la rappresentatività, la complessità del modello, l'informazione contestuale e il bias. Si conclude che i dati di revisione possono essere utilizzati efficacemente per i task e che la distanza tra due versioni è utile per rilevare affermazioni subottimali. Per ulteriori dettagli, si veda il paper.</sample>
    <sample id="231">NACHOS è un dataset di dati medici raccogliuti dal web.</sample>
    <sample id="232">David Vilar.</sample>
    <sample id="233">Simultaneous speech translation, SimulST, is the real-time translation of spoken language into text in another language. Current models face problems like long training procedures and need for multiple models for different latencies. The paper proposes EDAtt, Encoder-Decoder Attention, a strategy for SimulST. It uses existing offline ST models without re-training. EDAtt decides to emit partial translations based on attention. It outperforms offline strategies like Wait-k and Local Agreement in terms of translation quality and latency. The paper also provides open source code and models for reproducibility.</sample>
    <sample id="234">La strategia del prompting ha un grande impatto sui risultati. Ad esempio, in un semplice esperimento con uno-shot prompting, il cambiamento osservato è di più di un punto BLEURT. In casi estremi, può arrivare fino a 40 punti BLEURT. Quindi, è importante selezionare una buona strategia di prompting.</sample>
    <sample id="235">Non so. Potresti dare più informazioni sull'articolo?</sample>
    <sample id="236">Non so. Non ho informazioni su quali siano le 5 istruzioni scritte da esperti. Potresti dare più dettagli o cercare di trovare queste informazioni da altre fonti?</sample>
    <sample id="237">Gli autori propongono un test suite diagnostico per testare i modelli sull'utilizzo di informazioni provenienti da più fonti.</sample>
    <sample id="238">Il video introduce MeetingBank, un nuovo dataset per la sintesi di riassunti di riunioni. È stato creato per rispondere alle esigenze di sintesi di riunioni in diverse aree di lettura. Il processo di raccolta dati include l'uso di Speechmatics API per convertire audio in trascrizioni, identificare il tipo e i dati della riunione, trovare le sommarizioni riferimento e le parti della riunione, e allineare i tempi. Il dataset contiene 1.366 riunioni del Consiglio Comunale e quasi 7.000 istanze. Le misurazioni di astrattività includono copertura e densità. Per l'analisi dei dati, si misurano le sommariizzazioni di riunioni del Consiglio Comunale. Per l'valutazione dei modelli, si sono valutati dieci sistemi, tra cui BART-Large, Pagasus, Longformer, DialogLM e HMNet. GPT-3 ha ottenuto i punteggi più alti in termini di fluenza e coeren</sample>
    <sample id="239">Ciao a tutti, il mio nome è David Vilar e darò una breve recensione del documento "Prompting PaLM per la Traduzione: Valutazione di Strategie e Prestazioni". È un lavoro a squadra con i miei colleghi di Google Translate. PaLM è un modello di linguaggio a grandi scale a 540 miliardi di parametri presentato l'anno scorso nel 2022. È stato addestrato su una vasta collezione di testi, composta da 780 miliardi di token. Al momento della pubblicazione, ha raggiunto prestazioni di punta in centinaia di compiti di NLP. In questo lavoro, presentiamo lo studio sistematico del primato del modello di linguaggio a grandi scale per la traduzione. Abbiamo valutato la capacità di transizione di tali modelli utilizzando le migliori pratiche della comunità di MT. Questo implica l'uso dei set di test più recenti per evitare un sovrapporsi dei dati di test con quelli di addestramento del modello di linguaggio. Abbiamo comparato con i sistemi</sample>
    <sample id="240">Ciao, sono Dawei, un dottorando all'Università di Saarland in Germania. In questo video vorrei presentare il nostro lavoro recente "Weaker Than You Think: A Critical Look at Weakly Supervised Learning". Questo è un lavoro di gruppo con Xiaoyu Shen, Marius Mosbach, Andreas Stephan e Dietrich Klakow. Vorrei iniziare con una breve introduzione alla supervisione debole e all'apprendimento supervisionato debole. Nella supervisione debole, non etichettiamo manualmente i dati. Invece, etichettiamo i dati utilizzando fonti di etichettatura debole, come semplici regole heuristiche, basi di conoscenza o crowdsourcing di bassa qualità, come illustrato nella figura a destra. In confronto alle etichette umane, le etichette più deboli sono molto più economiche, ma sono anche rumorose, il che significa che una certa quantità di etichette è errata. Se addestriamo direttamente reti neurali su dati etichettati debolmente, le reti neurali tendono a memorizzare</sample>
    <sample id="241">L'articolo discute di un approccio per la valutazione di sistemi di rilevamento di fake news. Si evidenzia che i sistemi attuali hanno due difetti: valutazione non realistica e mancanza di un approccio umanocentrico. Propone un quadro di valutazione per sistemi che risolvano questi problemi. Il sistema è end - to - end, da tweet raw a output utilizzabile da umani. Ha un componente per la rilevazione di false affermazioni e un altro per la verifica di violazioni di politica. L'early detection è importante per gestire meglio la diffusione delle fake news. L'articolo valuta l'efficacia della verifica delle violazioni di politica e mostra che il sistema può rilevare 124.2 violazioni per ora umano. L'obiettivo è motivare lo sviluppo di sistemi di rilevamento di fake news con un coinvolgimento umano.</sample>
    <sample id="242">I metodi di valutazione comuni per i sistemi di dialogo sono l'uso di giudici umani per scegliere quale delle due conversazioni è migliore o per valutarle con una scala Likert.</sample>
    <sample id="243">C'è un elenco di autori nel testo, ma non sono specificati quanti sono in totale.</sample>
    <sample id="244">Per risolvere il problema con Servin e Kea, sono necessarie due tipologie di informazioni. Prima, conoscenze specifiche dell'entità come "Servin è un giudice". Secondo, conoscenze di fondo come "I giudici decidono casi in tribunali".</sample>
    <sample id="245">Lining Zhang e coautori presentano un lavoro intitolato "A Needle in a Haystack: An Analysis of High-Agreement Workers on MTurk for Summarization". Analizzano un pipeline a due passi per trovare lavoratori ad alto accordo su MTurk. La motivazione è che i metrici automatici possono essere problematici e le migliori pratiche di reclutamento su MTurk sono poco comprese. Il pipeline inizia con le "Qualification Settings", seguite da "Qualification Task" e "Endurance Task". Includono una "Reference-based task" e analisi di correttezza tra annotatori. I risultati mostrano che il pipeline può evitare sprechi di tempo e risorse, raggiungendo un alto accordo a un costo più basso. Rispetto a CloudResearch, può avere una qualità simile. Limitazioni: solo summarizzazione inglese su MTurk, domande non panacea, non c'è garanzia di correttezza di addestramento. Grazie a Google per i fondi sperimentali.</sample>
    <sample id="246">Sì, il codice è disponibile. Puoi trovarlo su GitHub.</sample>
    <sample id="247">Il paper presenta un nuovo dataset per la verifica di fatti basato su reti di conoscenza, FactKG. Utilizza DBpedia come fonte di conoscenza. I dati includono affermazioni in stile scritto e colloquiale. Ci sono due etichette: SUPPORTED e REFUTED. Il task consiste nel trovare le prove da DBpedia e verificare l'affermazione utilizzando le prove. Utilizza cinque tipi di ragionamento: one-hop, congiunzione, esistenza, multi-hop e negazione. Viene presentato anche un modello di trasformazione di stile colloquiale e un modello di basi di presupposizione. I risultati mostrano che il modello GEAR che utilizza le prove dalla rete di conoscenza supera tutte le basi di riferimento.</sample>
    <sample id="248">No, gli annotatori per NLPositionality non sono bilanciati rispetto a ciascun gruppo demografico.</sample>
    <sample id="249">Le frasi nel dominio accettabile sono state perturbate aggiungendo rumore all'input.</sample>
    <sample id="250">Avere una valutazione dimensionale significa valutare più aspetti di una conversazione AI in modo più dettagliato e specifico, invece di solo una valutazione complessiva. Questo aiuta a comprendere le forze e le debolezze del modello in modo più preciso. Se hai altre domande, sentiti libero di chiedere.</sample>
    <sample id="251">The authors are affiliated with the University of Science and Technology of China.</sample>
    <sample id="252">Il lavoro presentato, "U-CREAT: Unsupervised Case Retrieval using Events extrAcT", è un contributo al campo della Prior Case Retrieval per i professionisti legali. L'obiettivo è migliorare la ricerca di precedenti giudiziari in un'era di crescente volume di casi. L'IL-PCR Dataset, un nuovo benchmark, contiene 7.070 casi legali con 6.775 citazioni per documento. U-CREAT, il pipeline, utilizza tecniche di apprendimento non supervisionato e un approccio basato sugli eventi. L'event extraction, tramite parsing di dipendenza, è cruciale. L'U-CREAT pipeline ha tre passaggi: pre-processing, parsing di dipendenza e post-processing. Si ottengono eventi per il documento di query e candidati. Un'interazione matrice tra eventi query e candidati aiuta a ottenere un ordine di classifica. Gli esperimenti con diversi modelli dimostrano che l'U-CREAT, in particolare l'Event Filtered Docs, è il metodo più performante. L'approcc</sample>
    <sample id="253">Il lavoro "DisorBERT" si concentra sulla deteczione di segni di malattie mentali attraverso l'analisi automatica dei post sui social media. Definisce una malattia mentale come un sindrome psicologica associata a disagio e disabilità che influisce sul pensiero, sulle emozioni, sulle condizioni emotive e sul comportamento. I social media offrono un'enorme quantità di contenuti che possono essere utilizzati per ricerche su come le persone affrontano le difficoltà. Il lavoro mira a contribuire alla deteczione di malattie mentali attraverso l'analisi automatica dei loro post sui social media. Si usa l'adattamento di dominio per migliorare la performance del modello su un dominio specifico, come adattare BERT da dati generali a un linguaggio più specifico di Reddit e salute mentale. Il diagramma generale mostra come si inizia con un modello di base e si integra informazioni da Reddit e salute mentale, incorporando anche un lessico per guidare il processo di maschera. I risultati generati utilizzando</sample>
    <sample id="254">L'abstract è lungo e dettagliato. In generale, il lavoro presenta un'approccio per migliorare l'estrazione di relazioni a livello di documento. Si parla di un'architettura con denoising guidato dall'incertezza per migliorare la qualità dei pseudo etichette. Si introduce un metodo di stima dell'incertezza a livello di istanza per le relazioni sovrapposte. Si progetta una strategia di rielabeling iterativa con soglie di incertezza dinamiche per il problema delle classi a lunga coda. Si confronta con basi di riferimento e si dimostra che il loro approccio migliora significativamente. Se hai bisogno di ulteriori dettagli o chiarimenti, fammi sapere.</sample>
    <sample id="255">La forma del prompting si rivela importante per zero e uno-shot prompting.</sample>
    <sample id="257">Hanno valutato quattro modelli di dialogo state-of-the-art.</sample>
    <sample id="258">L'articolo propone l'uso di grandi modelli linguistici per valutare la qualità dei testi in elaborazione del linguaggio naturale. Si danno istruzioni ai modelli e si danno loro le campioni da valutare. Si parla di lavori correlati come G-Eval. L'idea è nuova poiché non esistono lavori precedenti che esplorano l'uso di grandi modelli linguistici per la valutazione. La motivazione è che l'evaluation umana è instabile e difficile da riprodurre. Si usa la grammatica, la coerenza, la piacevolezza e la rilevanza per valutare le storie generate da GPT-2 o scritte da umani. Si usano quattro modelli: T0, InstructGPT, curie e davinci, e ChatGPT. I risultati mostrano che alcuni modelli piccoli non mostrano una preferenza significativa per le storie scritte da umani, ma davinci e ChatGPT lo fanno come gli insegnanti di inglese. Ci sono modelli che possono essere alternative all'evaluation</sample>
    <sample id="259">L'abstract parla di un lavoro intitolato "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations". Si tratta di una ricerca che si concentra sulla trasformazione di query in diverse lingue naturali in rappresentazioni semantiche multiple. Attualmente, esistono modelli di parsing semantiche bilingue che sono stati proposti e valutati su set di dati di compiti limitati e applicazioni. Questo lavoro propone XSemPLR, un set di dati unificato per il parsing semantiche bilingue in diverse lingue naturali e rappresentazioni semantiche. Contiene 9 set di dati in diversi domini, 5 compiti di parsing semantiche, 8 rappresentazioni semantiche e 22 lingue naturali in 15 famiglie linguistiche. Si considerano sei impostazioni di allenamento e valutazione, tra cui Translate-Test, Monolingual Model, Monolingual Few-shot, Multilingual Model, Cross-lingual Zero-shot e Cross-lingual Few-shot transfer. Si valutano modelli multilingue come Encoder-Decoder e Encoder-PTR. Si scopre</sample>
    <sample id="260">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni?</sample>
    <sample id="261">Un buon pianificatore dovrebbe scrivere script che siano ragionevoli e fedeli alle restrizioni.</sample>
    <sample id="262">Non so quanti autori sono coinvolti nell'articolo. Potresti dare più informazioni o controllare il testo originale?</sample>
    <sample id="263">L'articolo presenta un'indagine sistematica sui problemi di bias nei modelli di apprendimento in contesto. Si inizia con una tipologia di bias etichettati e si identifica un nuovo tipo di bias, il bias di dominio-etichetta. Si propone un metodo di calibrazione, chiamato calibrazione di dominio-contesto, che utilizza parole casuali del dominio del corpus di testo per stimare il bias del modello su ciascuna etichetta. Questo metodo migliora significativamente il rendimento dell'apprendimento in contesto per modelli di grandi dimensioni come GPT-3, specialmente nei casi di maggiore bias di dominio-etichetta. L'abstract conclude con l'invito a consultare il paper per ulteriori dettagli.</sample>
    <sample id="264">Lin Wang, a Zhejiang University graduate student, presents a paper on "TAVT: Towards Transferable Audio-Visual Text Generation". He notes that uni-model text generation tasks have advanced due to large-scale pre-training and huge model capacity. However, multimodal text generation tasks like audio-visual text generation face challenges like arduous and expensive data annotation and severe degradation due to varying construction conditions in different domains. To overcome these, a novel task named Transferable Audio-Visual Text Generation is proposed. The main challenge is multi-modal domain shifts. A unified audio semantic space is suggested to align visual concepts across domains. The framework consists of three components: an audio-visual meta-mapper network, an audio-visual encoder and language model generator, and counterfactual contrastive learning. The meta-mapper network maps visual concepts into a unified auditory semantic space. The transformer-based encoder and generator are used, with an alpha to evaluate modality contribution. A Dual Counterfactual Contrastive Learning is proposed for better visual-textual alignment. Experiments on MSVD and MSR-VTT benchmarks show TAVT outperforms SOTA models on cross-datasets and cross-domain settings, even in low-resource domains. Ablation experiments analyze the impact of audio features.</sample>
    <sample id="265">Vasudha</sample>
    <sample id="266">Non so qual è l'affiliazione degli autori dell'articolo. Potresti dare più informazioni?</sample>
    <sample id="268">I errori più comuni di PaLM sono gli omission errors. Se hai altre domande su questo argomento, non esitare a chiedere.</sample>
    <sample id="269">Ciao, sono James Finch. E sono Sarah Finch. Oggi vi parleremo di ABC-Eval, un nuovo approccio dimensionale per valutare l'intelligenza artificiale conversazionale. Questo lavoro è stato fatto dal Laboratorio di NLP dell'Emory, Emory NLP Lab, guidato dal Professore Jinho Choi all'Università Emory e in collaborazione con Amazon Alexa AI. Supponiamo che tu abbia appena sviluppato un modello di dialogo e vuoi vedere come si confronta con lo stato dell'arte attuale. La pratica comune è utilizzare l'evaluation umana, come chiedere giudici umani di selezionare quale delle due conversazioni sia migliore o di valutare le conversazioni utilizzando una scala Likert. Questi approcci funzionano bene per fornire valutazioni globali dell'intera qualità del dialogo, ma la qualità del dialogo ha molti aspetti. Quindi, potresti voler valutare più dimensioni della qualità del chat per comprendere le forze e le debolezze del modello in modo più dettagliato</sample>
    <sample id="270">Gli autori dell'articolo sono affiliati all'Emory NLP Lab, Emory University, e in collaborazione con Amazon Alexa AI.</sample>
    <sample id="271">Non c'è alcun riferimento a "CFT" in questo articolo. Forse hai commesso un errore di battitura? Se hai altre domande sul contenuto dell'articolo, sono felice di aiutarti.</sample>
    <sample id="272">Cinque.</sample>
    <sample id="273">Ciao, il mio nome è Kayo Yin e presenterò il nostro lavoro intitolato "Quando la traduzione richiede il contesto? Esplorazione multilingue e data-driven". Questo lavoro è stato realizzato in collaborazione con Patrick Fernandes, Emmy Liu, André F. T. Martins e Graham Neubig. Molti traduzioni dipendono dal contesto. Ad esempio, come tradurremmo "mole" in questa frase? Beh, se la frase precedente era "Cose potrebbero iniziare a diventare pericolose se i ministri scoprono", allora "mole" si riferisce a un agente informante. Ma se la frase precedente era "Potrebbe essere qualcosa di serio, dottore?", allora "mole" si riferisce a una macchia di pelle. Quindi, a seconda del contesto, il significato della parola cambia, e quindi la sua traduzione cambia anche. Tuttavia, valutare quanto bene i modelli possono tradurre casi come questo è abbastanza difficile. In primo luogo, perché solo una piccola parte delle</sample>
    <sample id="274">Yusen Zhang</sample>
    <sample id="276">L'articolo presenta "IndicMT Eval", un dataset per metarevalutare metriche di traduzione per lingue indiane. Si concentra su cinque lingue, Tamil e Malayalam Dravidiane e Hindi, Marathi, Gujarati Indo Aryan. Dal Flores si selezionano 200 frasi, generate da 7 modelli di traduzione, per un totale di 7.000 campioni. Gli annotatori bilingui valutano le traduzioni, indicando errori, tipi e gravi, e assegnano un punteggio generale. Si analizzano metriche come chrF, LabSE, BERTscore, COMET e SacreBLEU. COMET si dimostra la metrica migliore in generale. IndicCOMET, fine-tunato con il dataset MQM, supera le basi COMET su tre lingue e ha una maggiore robustezza rispetto a COMET su ACES Translation Accuracy Challenge Sets. L'abstract conclude con l'invito a utilizzare il dataset pubblicamente disponibile.</sample>
    <sample id="277">Il nuovo metodo non ha un nome specifico.</sample>
    <sample id="278">Le parole contrassegnate sono un metodo per identificare le parole che distinguono gruppi marcianti da quelli non marcianti. Si basa sulla concezione sociolinguistica della "marcatura", secondo cui c'è un gruppo non marcato di default e qualsiasi gruppo che differisce da quel default è marcato linguisticamente.</sample>
    <sample id="279">The authors are affiliated with the University of Washington.</sample>
    <sample id="280">The paper introduces MultiEMO, a novel attention - based correlation - aware multimodal fusion framework for emotion recognition in conversations. It addresses challenges like underexploiting multimodal information, poor performance on minority emotion classes, and distinguishing semantically similar emotions. Key contributions include VisExtNet for visual feature extraction, MultiAttn for multimodal fusion, and Sample - Weighted Focal Contrast loss. VisExtNet captures facial expressions without redundant scene info. MultiAttn integrates modalities through cross - attention. SWFC loss focuses on minority classes. Experiments on MELD and IEMOCAP show state - of - the - art performance. Limitations include VisExtNet not distinguishing speakers and SWFC loss needing large batch size.</sample>
    <sample id="281">L'articolo esplora quando la traduzione richiede contesto. Si analizzano i casi in cui il significato di parole cambia a seconda del contesto precedente. Si introduce CXMI, misura per misurare l'uso del contesto nei modelli di traduzione. Si estende CXMI a P-CXMI per misurare il contesto a livello di frase o parola. Si analizzano i tag di part-of-speech, i vocaboli con P-CXMI alto e token singoli. Si crea un benchmark multilingue per la traduzione a livello di documento. Si valutano modelli con e senza contesto utilizzando metriche come BLEU, COMET e word f-measure. Si conclude che i modelli che usano contesto sono più accurate per certi fenomeni discorsivi, ma non tanto per altri. Si confrontano anche sistemi commerciali come DeepL e Google Translate. L'articolo dimostra che è difficile determinare il miglior sistema di traduzione a livello di documento solo con metriche di corpus.</sample>
    <sample id="282">L'articolo presenta "StoryTrans", un modello per la trasformazione di stile non parallela di storie a livello di storia e discorso. Si concentra su un'importante attività nella generazione del linguaggio naturale. Finora, la maggior parte degli studi si sono concentrati a livello di token o frase, come il trasferimento di sentiment o formalità. Questo lavoro si distingue per il trasferimento di stile a livello di storia e discorso, che è cruciale per imitare lo stile dell'autore. I principali ostacoli sono la complessità delle preferenze linguistiche dell'autore a livello di discorso, come tecniche narrative, e la forte associazione tra stili e temi specifici. Per superare questi problemi, viene proposto il modello StoryTrans. Questo modello impara rappresentazioni di discorso dai testi sorgente e le combina con insiemi di embedding di stile imparabili per generare testi in stili di destinazione. Viene progettato un nuovo obiettivo di addestramento</sample>
    <sample id="283">The Prague approach.</sample>
    <sample id="284">The paper presents FSUIE, a novel fuzzy span mechanism for enhancing universal information extraction. It addresses the overreliance on precise span boundaries in current span-based UIE models and the mismatch between transformer feature extraction and information extraction. FSUIE proposes a fuzzy span attention to adaptively adjust the attention span of the model, which represents the target boundary as a continuous distribution of correct probability. It also introduces a fuzzy span loss to alleviate the model's reliance on span boundaries. Experiments on named entity recognition, relationship extraction, and aspect sentiment triplet extraction show that FSUIE achieves significant performance improvements compared to UIE-base. It demonstrates strong generalization capabilities and competitive performance in various information extraction tasks. The ablation study reveals that FSA and FSL contribute to the model's convergence speed and information extraction capability. Overall, FSUIE achieves excellent results in a wide range of information extraction tasks.</sample>
    <sample id="285">Il lavoro di Mingqi Gao e colleghi di Peking University si concentra sulla correzione di errori di fattualità in sommari di dialogo. Esplorano due soluzioni: introdurre obiettivi di fattualità durante l'addestramento o l'inferenza per rendere i modelli di sommari più fedeli, e progettare un modello di correzione di errori di fattualità, FEC, indipendente. Attualmente, non esiste lavoro su errori di fattualità per sommari di dialogo. I modelli FEC attuali vengono valutati con metriche di fattualità come FactCC e DAE, che danno un punteggio generale. Ci sono due difetti: le metriche di fattualità sono vago e non affidabili, e confondono le due soluzioni. L'argomento introduce una nuova classificazione di errori di fattualità, basata su ERRANT, e un framework di valutazione. Con il loro framework, trovano che addestrare FEC con sommari di riferimento da dataset di</sample>
    <sample id="286">James Finch e Sarah Finch.</sample>
    <sample id="287">Quattro.</sample>
    <sample id="288">BLiMP， SyntaxGym， CrowS pairs.</sample>
    <sample id="290">FTw, COSINE.</sample>
    <sample id="291">Il modello viene valutato su attività come riconoscimento di entità nominali, classificazione, taggatura di parte di discorso e risposta alle domande.</sample>
    <sample id="294">CamemBERT viene inizialmente addestrato su dati di web.</sample>
    <sample id="295">Adam Przepiórkowski</sample>
    <sample id="296">Il lavoro di Valerio Basile riguarda la collaborazione tra l'Università di Torino e Amazon Alexa per lo sviluppo di modelli di intelligenza artificiale per la comprensione del linguaggio naturale. Si concentra sull'ironia, un fenomeno pragmatico e latente. Hanno creato il corpus EPIC, raccolto da social media, Reddit e Twitter, per 300 conversazioni brevi in 5 varietà di inglese. Utilizzano Prolific per l'annotazione, con 15 annotatori per varietà linguistica. L'inter-annotator agreement varia a seconda della divisione dei dataset. I modelli perspective-aware mostrano una maggiore certezza nelle previsioni rispetto ai modelli standard. Si è notato che generazioni vicine e geografie diverse influenzano la percezione dell'ironia.</sample>
    <sample id="297">L'articolo parla di un progetto che analizza le dog whistle rhetoric. Si sviluppa una tipologia e un glossario di oltre 340 termini e simboli, specialmente per le dog whistle anti-razziste, transfobe e antisemite. Si esamina il pattern di frequenza delle dog whistle nelle discorsi politici storici americani, collegandolo alla strategia politica del Sud Repubblicano dopo la riforma dei diritti civili. Si testa la capacità di un modello di linguaggio GPT-3 di riconoscere e interpretare le dog whistle, notando che le performance variano a seconda del registro e del tipo di dog whistle. Infine, si dimostra come le dog whistle possano evadere la moderazione del contenuto online, mostrando come le frasi odiose siano meno ritenute tossiche quando le etichette standard o gli insulti sono sostituiti con dog whistle.</sample>
    <sample id="298">Per la perdita di prestazioni, la derivazione temporale è la causa principale. Per confermarlo, hanno fatto un esperimento di ritraining o di continuare a pretrainare alcuni modelli con dati più recenti e hanno trovato che la prestazione peggiora con un gap temporale più grande.</sample>
    <sample id="299">L'articolo parla di migliorare la robustezza dei modelli di NLI. I modelli NLI hanno ottenuto risultati di punta su vari benchmark, ma recenti studi hanno mostrato che il loro successo dipende in parte da shortcut, correlazioni spurie tra attributi di input e etichette. Questi shortcut sono spesso introdotti durante la creazione dei dataset. I modelli NLI che sfruttano questi shortcut funzionano bene su campioni in distribuzione ma sono fragili su test fuori distribuzione. L'articolo propone un metodo di addestramento minimax per ridurre la dipendenza dei modelli NLI da shortcut e migliorare la loro generalizzazione fuori distribuzione. Il metodo utilizza una distribuzione di pesi esempi che mette l'accento sugli esempi difficili sottorappresentati. I due modelli, il learner e l'auxiliary, sono ottimizzati alternativamente. L'auxiliary genera pesi esempi per incentivare il learner a concentrarsi su aree dell'input spazio dove incappa in alti costi. L'artic</sample>
    <sample id="300">L'articolo introduce il concetto di dictazione interattiva, un processo dove gli utenti possono dictare e modificare documenti in modo naturale. Si spiega come funziona, con esempi di come gli utenti possono correggere errori e invocare modifiche vocali. Si parla di caratteristiche come l'interlacciamento flessibile tra dictazione e editing e l'uso di linguaggio naturale per specificare le modifiche. L'autore presenta tre contributi: formalizzare il task, costruire un dataset e creare un sistema di base. Si descrive il processo di annotazione e la costruzione del dataset. Si parla di modelli di apprendimento automatico per le varie fasi del processo e si evidenzia la necessità di ulteriori lavori in questo campo. Se hai domande o vuoi discutere di questo argomento, sentiti libero di farlo.</sample>
    <sample id="302">Permette di mettere in ordine i token corretti che sono stati identificati nella prima fase di taggatura.</sample>
    <sample id="303">Perché non sappiamo se i positivi stereotipi sono causati da un allineamento di valore eccessivo o da altri metodi di contrasto dei bias che stanno producendo questi modelli dannosi.</sample>
    <sample id="304">Gli input inaccettabili di coppia minima sono le frasi inaccettabili che vengono scelte per creare sequenze più lunghe e testare l'acceptability del modello. Queste frasi vengono estratte da dataset diversi o addirittura da dataset completamente diversi come Wikipedia.</sample>
    <sample id="305">Dawei, PhD student at Saarland University, presents their work on "Weaker Than You Think: A Critical Look at Weakly Supervised Learning". They discuss weak supervision and weakly supervised learning. Weak supervision uses weak labeling sources like heuristic rules, knowledge bases, or crowdsourcing. These labels are cheaper but noisy. Direct training on weakly labeled data leads to memorization of noise. In weakly supervised learning, training algorithms are proposed to handle label noise. Recent WSL works claim high performance on clean test sets but often assume access to a clean validation set. This is often overlooked. The work addresses three research questions: necessity of clean validation data, number of clean samples needed, and utilization of clean samples. Findings show that clean validation samples are necessary for proper WSL. Increasing clean samples improves performance. Direct fine-tuning on clean data can outperform WSL approaches. The work concludes that WSL approaches require clean samples, their performance gain is overestimated, and recommends reporting model selection criteria, comparing with few-shot learning, and considering continuous fine-tuning. Code is open-sourced.</sample>
    <sample id="306">L'articolo parla di un lavoro su Entity Tracking in Language Models. L'obiettivo è capire in che misura i grandi modelli di linguaggio riescono a seguire gli stati degli enti in un discorso. Ci sono diversi ostacoli per valutare queste capacità, come la presenza di pattern comuni nel training data e l'apprendimento di associazioni semplici tra parole e stati. Per superare questi ostacoli, hanno progettato una task coinvolgendo scatole e oggetti. I modelli devono prevedere il contenuto delle scatole dopo operazioni come spostare o aggiungere oggetti. I risultati mostrano che solo pochi modelli, come text - davinci - 003, riescono a fare un'entity tracking non banale. Questo suggerisce che il training su codice possa essere responsabile di questa capacità. Tuttavia, rimane incerto se queste capacità si generalizzano oltre il setup utilizzato. Se hai domande o commenti, puoi contattarli in persona all'ACL, via email o su Twitter.</sample>
    <sample id="307">I've got named entity recognition, classification, part-of-speech tagging, and question answering.</sample>
    <sample id="308">L'articolo presenta un lavoro intitolato "NLPositionality" che caratterizza i bias di design di dataset e modelli NLP. Il lavoro è stato fatto in collaborazione con l'Università di Washington e l'Allen Institute for AI. Si parla di come i modelli NLP possano avere bias di posizione a causa delle diverse posizioni dei ricercatori e sviluppatori. Si spiega come i dataset e i modelli aggregano giudizi e opinioni di persone reali, rappresentando certe posizioni. Il lavoro utilizza un framework per studiare la posizione dei dataset e dei modelli, confrontando le annotazioni con reali utenti. Si trova che i dataset e i modelli sono più allineati a paesi anglofoni e a persone con un'istruzione superiore. Si danno alcune raccomandazioni per affrontare questi bias, come tenere un registro di tutte le scelte di design e fare ricerca NLP con un approccio perspectivistico.</sample>
    <sample id="309">Inter-annotator agreement.</sample>
    <sample id="310">Wikipedia.</sample>
    <sample id="311">Non so. Non ho informazioni su quali siano le affiliazioni degli autori dell'articolo. Potresti dare più dettagli o cercare di trovare queste informazioni da qualche altra fonte?</sample>
    <sample id="312">MultiInstruct è il primo dataset di tuning di istruzioni multi-modal a grande scala. Differisce dagli altri perché include 62 diverse task multi-modal in 10 categorie diverse, mentre molti studi precedenti si concentravano solo su task linguistici. Inoltre, MultiInstruct è stato costruito per risolvere la disparità nella disponibilità di dataset di istruzioni tra NLP e multi-modal.</sample>
    <sample id="313">Due autori sono coinvolti nell'articolo.</sample>
    <sample id="314">Non c'è una definizione di coordinazione binaria specifica qui. Ma in generale, la coordinazione binaria potrebbe essere una forma di coordinazione tra due elementi simili, come ad esempio due nomi o due verbi. Se hai bisogno di una definizione più precisa, potresti cercare in un dizionario di grammatica. Cosa ne pensi?</sample>
    <sample id="315">Non c'è informazione su quanto tempo sono stati utilizzati i prompt in questo studio.</sample>
    <sample id="316">Il modello T5 più piccolo, quando viene finetuned su CoScript, può generare script di qualità superiore rispetto a molti modelli più grandi. Questo indica che i modelli più piccoli possono superare i modelli più grandi quando sono adeguatamente addestrati su dataset appropriati.</sample>
    <sample id="317">L'abstract parla di un lavoro intitolato "CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors". Si parla dell'informazione estrazione, un compito classico in NLP. Si esemplifica il riconoscimento di entità nominate. I modelli pre-trainati come T5 e GPT-3 operano in maniera testo-testo ma durante l'inferezione, l'output estratto è linearizzato in una sequenza piano. Ciò rende difficile per il modello generare le strutture corrette. Propone CodeIE, che trasforma la task di estrazione in una generazione di codice strutturato. Si valuta su tre dataset di riconoscimento e quattro di estrazione di relazioni. Con il prompt in codice, CodeIE supera i modelli di base come UIE e GPT-3. Si osserva che il codice format ha una perplessità inferiore e meno errori strutturali. In generale, il Codex model supera il GPT-3 model in informazione estrazione. L'abstract conclude con l'invito a contattare l</sample>
    <sample id="318">Ciao, sono Yanis Labrak e presenterò i nostri lavori su "DrBERT: Un modello pre-allenato robusto in francese per domini biomedici e clinici.".In questa presentazione, innanzitutto parleremo di modellazione del linguaggio nel campo sanitario. Poi presenteremo il contributo principale del nostro articolo. Introdurremo il primo modello biomedico in francese chiamato DrBERT, basato su RoBERTa e allenato su NACHOS, un set di dati medici riscattati dal web. Inoltre, presenteremo una comparazione di modelli con diversi set di pre-allenamento e fonti di dati. Successivamente, presenteremo i risultati su 11 task di basso livello biomedici e clinici in francese. Infine, concluderemo gli esperimenti e forniremo dettagli su come accedere a quei modelli.Dal suo lancio nel 2018, BERT è diventato uno dei metodi più efficaci per risolvere compiti di processamento del linguaggio naturale e offre un incremento di prest</sample>
    <sample id="319">Nel lavoro vengono esaminate le strategie di apprendimento di pre-Allenamento continuo. Ci sono tre modelli basati su CamemBERT, uno addestrato su un subset di 4 GB di NACHOS, un altro su 4 GB di note cliniche e uno su PubMedBERT addestrato su 4 GB di NACHOS. Inoltre, ci sono quattro modelli addestrati da zero: una prima versione di DrBERT con 7 GB di NACHOS, una seconda versione con 4 GB, una prima versione di ChuBERT con 4 GB di note cliniche e una versione finale di ChuBERT con 4 GB di NACHOS e 4 GB di note cliniche.</sample>
    <sample id="320">The factor of overfitting due to reusing the test is not observed.</sample>
    <sample id="321">La qualità della semplificazione è stata valutata in base al tipo di semplificazione, come la semplificazione di tipo lessicale, strutturale e di livello generale. Inoltre, la DEPLAIN ha una varietà alta di trasformazioni di semplificazione diverse.</sample>
    <sample id="322">L'abstract parla di un'analisi sulle capacità di classificatori di testo di comprendere la moralità in contesti linguistici. Enrico, il relatore, spiega che la moralità è la distinzione tra giusto e sbagliato e è fondamentale per le società. La moralità è soggettiva e può essere interpretata in modi diversi. Si menziona la teoria delle basi morali, che identifica cinque modi differenti di percepire la moralità. Il relatore ha applicato tecniche di AI spiegabile a modelli di linguaggio addestrati per comprendere la moralità in testi. Utilizzando un corpus di tweet, hanno esplorato come la moralità sia espressa diversamente in diversi domini, come #AllLives Matter e #BlackLivesMatter. I risultati mostrano che i modelli di linguaggio riconoscono che la moralità può essere espressa in modi differenti in diversi domini. L'abstract conclude dicendo che l'uso di un solo modello per molti domini può portare a malintesi per</sample>
    <sample id="323">The paper presents DHLK for Commonsense QA. It addresses problems in existing works like noisy entities and limited interaction between modalities. DHLK builds an HKG based on multiple knowledge bases through pruning and KRL. It uses RoBERTa and Mask Self-Attention to encode and fuse QA contexts and entities. It dynamically removes weakly relevant entities. Entity and relation embeddings are optimized using TransE. Relation Mask Self-Attention is introduced for subgraph modeling. The HKG graph embedding is obtained by max-pooling. Path information is incorporated into QA context embedding. The method is evaluated on CommonsenseQA and OpenBookQA, showing good results compared to other methods.</sample>
    <sample id="324">Sì, i modelli linguistici presentano bias politici diversi. Ad esempio, GPT-4 è il più liberale tra loro, mentre GPT serie sono più liberali socialmente rispetto a BART serie e sue varianti.</sample>
    <sample id="325">Ciao! Mi chiamo Matthias Lindemann, e oggi darò un breve introduzione al nostro articolo intitolato "Compositional Generalization without Trees using Multiset Tagging and Latent Permutations". Questo è un lavoro a joint con i miei tutori Alexander Koller e Ivan Titov. La generalizzazione compositiva può essere compresa come la capacità di un apprenditore di gestire una ricorsione più profonda e composizioni di frasi non viste durante l'addestramento. Nel contesto della semantica di parsing, la prova della generalizzazione compositiva potrebbe sembrare così. Come di consueto, abbiamo un set di istruzioni di addestramento. In questo caso, "La ragazza ha dormito." E "Mary sapeva che la ragazza ha dormito." Queste istruzioni sono associate con forme logiche che rappresentano aspetti fondamentali del loro significato. In contrasto con l'evaluation standard di macchine di apprendimento, il set di test non proviene dalla stessa distribuzione ma contiene forme logiche strutturalmente non viste. In questo esempio, il modello ha visto</sample>
    <sample id="326">Cognitive dissonance è quando due credenze o azioni sono inconsistenti. Ad esempio, se una persona dice "So che le sigarette possono uccidere" e poi fuma dopo una riunione, c'è una dissonanza tra la credenza e l'azione.</sample>
    <sample id="327">Xiao Xu, a third-year PhD student from Harbin Institute of Technology, presents their work "ManagerTower: Aggregating the Insights of Uni-Modal Experts for Vision-Language Representation Learning" at ACL 2023. This work builds upon BridgeTower to address its limitations. ManagerTower introduces managers in each cross-modal layer to gather insights from pre-trained unimodal experts at different levels. It uses RoBERTa and CLIP-ViT base as unimodal encoders. ManagerTower achieves superior performance, especially a 39.15% accuracy on Wikivideo test standard, compared to BridgeTower. The work demonstrates that adaptive managers can effectively exploit different levels of unimodal semantic knowledge for comprehensive cross-modal representation learning. Paper, code, and modals are available on Archive and Github.</sample>
    <sample id="328">GPT-4.</sample>
    <sample id="329">L'articolo presenta un metodo per localizzare frasi in video zero-shot. Si concentra sulla localizzazione di frasi in video per video lungo, utilizzando un query naturale. Molti metodi esistenti richiedono annotazioni manuali costose e inefficienti. L'articolo propone un metodo di generazione di pseudo etichette strutturate resistente al rumore. Genera pseudo query complesse basate su immagini e calcola la rilevanza tra frame e query. Genera pseudo eventi basati sulla struttura temporale degli eventi. Riduce l'influenza del rumore delle etichette con pesi di campioni e raffinamento delle etichette. I risultati su due dataset dimostrano che il metodo proposto supera altri metodi zero-shot in molti metrici. Il codice è disponibile.</sample>
    <sample id="330">No, l'addestramento cumulativo non funziona meglio di quello iterativo.</sample>
    <sample id="331">Sara Papi.</sample>
    <sample id="332">I dati sono stati tratti da un corpus parallelo.</sample>
    <sample id="333">Wenhao, from Nanjing University, introduces their work "INK: Injecting kNN Knowledge in Nearest Neighbor Machine Translation". They acknowledge collaborators from Shanghai AI Lab, Nanjing University, and the University of Hong Kong. Their work focuses on neural machine translation, aiming to improve the generalization ability of NMT models. They observe that neural networks induce a non-smooth representation space, leading to poor performance in areas with sparsely dispersed low-frequency tokens. To enhance performance, they propose kNN-MT, which smooths predictions based on nearest neighbors. However, this approach has drawbacks like time-consuming neighbor retrieval and difficulty in updating the datastore. To overcome these, they introduce the INK framework. INK has a training loop with two steps: extracting kNN knowledge to guide adapter adjustment and updating representations asynchronously. They adjust representations using KL-divergence to align contextualized representations and token embeddings. Experiments show that INK outperforms state-of-the-art kNN-MT systems, achieving higher BLEU scores with less memory and faster inference.</sample>
    <sample id="335">Matthias Lindemann</sample>
    <sample id="336">Il trasferimento interlinguistico è il processo di addestrare un modello linguistico su una lingua e poi utilizzarlo per comprendere o generare testo in un'altra lingua.</sample>
    <sample id="337">L'articolo presenta un approccio per la rappresentazione di parole fuori vocabolario, OOV, attraverso l'apprendimento basato su reti neurali. Si evidenzia come le OOV siano importanti ma difficili da rappresentare. L'approccio utilizza un grafico relazionale basato su parole per associare le OOV a parole correlate e inferire il loro significato. Si introduce un grafico relazionale di parole che imita le regole lexicali di formazione e associazione. Si utilizza una rete di attenzione per assegnare attributi agli nodi OOV. Si applica un'attenzione a due livelli per estrarre informazioni importanti e ridurre il rumore. Si utilizza una rete di convoluzione a un livello per catturare la formazione delle parole. Si applica il contrasto di apprendimento nel funzionale di perdita con esempi positivi NT-XENT. Gli esperimenti dimostrano che il modello ha prestazioni superiori rispetto ai baselines in entrambi i compiti intrinseci ed est</sample>
    <sample id="338">Il lavoro presenta un'analisi sull'utilità delle spiegazioni umane. Si parla di una collaborazione tra Rensselaer Polytechnic Institute, Northeastern University e IBM Research. Si discute la necessità di valutare la qualità delle spiegazioni umane, che possono essere soggettive e dipendenti dal compito. Si introduce un'unità strutturale unificata per convertire diverse task in una task a scelta multipla. Si eseguono esperimenti per analizzare l'utilità delle spiegazioni. Si propone un nuovo metrico chiamato TREU, che estende il punteggio di simulabilità. Si valuta l'efficacia delle spiegazioni umane su cinque dataset utilizzando il metrico TREU e simulabilità su due modelli, T5 e BART. I risultati dimostrano che il nostro metrico supera il punteggio di simulabilità per l'efficacia delle spiegazioni umane. L'abstract conclude sottolineando l'importanza della qualità delle annotazioni umane e la necessità di valutare in modo più accurato le sp</sample>
    <sample id="339">I'm sorry, but the information about the affiliations of the authors is not provided in the text you've given. You might need to look for it in the full article or the conference proceedings.</sample>
    <sample id="340">Il lavoro di Kuan-Hao Huang e colleghi presenta ParaAMR, un vasto dataset di parafilie sinteticamente diverso. Utilizzano AMR back-translation. Partono da una frase originale, creano nuove radici e modificano le relazioni, poi generano nuove frasi. Il dataset ha circa 15 milioni di frasi originali e 6,9 parafilie per frase. È diverso da altri dataset in termini di diversità sintattica, ma mantiene similitudini semantiche. Aiuta nell'apprendimento di embedding di frasi, nella generazione di parafilie controllate sintatticamente e nell'aumento di dati per apprendimento a pochi esempi. Il dataset è disponibile in un link.</sample>
    <sample id="341">Gli autori fanno ricorso a due misure di latenza: la latenza media e la latenza computazionale consapevole.</sample>
    <sample id="342">The paper presents LiveChat, a large-scale personalized dialogue dataset. It introduces open-domain and personalized dialogue, highlighting the significance of video-sourced datasets. The dataset is constructed from TikTok/Douyin videos, with audio transcription and dialogue construction using a reply-to-whom method. It includes persona information for personalized dialogue. Compared to existing datasets, LiveChat is video-sourced, larger in scale, and has longer average sessions. Experiments on response modeling and addressee recognition show persona benefits. BART outperforms other models, and in-context learning demonstrates performance growth with more demonstrations. Future work focuses on efficient transfer learning of LLMs for LiveChat.</sample>
    <sample id="343">Ciao a tutti, sono Akshatha, e oggi il mio coautore Martin e io stiamo presentando il nostro lavoro "The KITMUS Test: Evaluando la integrazione del conoscenza da diverse fonti". Questo lavoro è una collaborazione tra l'Università McGill, Mila e Microsoft Research. I modelli di intelligenza artificiale naturale linguistica traggono da una varietà di fonti di conoscenza, come quella contenuta nei loro parametri, solitamente acquisita da un pretraining, e quella data in input durante l'inferezione. Opere recenti in compiti come la risoluzione di domande mostrano che i modelli possono utilizzare la conoscenza acquisita durante il pretraining per risolvere il compito. Ma l'intelligenza artificiale naturale linguistica spesso richiede anche conoscenza fornita durante l'inferezione. Ad esempio, nella frase "John ha visto il presidente appena eletto in TV". I parametri pretrain possono contenere informazioni su ciò che i presidenti fanno e su cosa sia un TV, ma non possono conoscere con certezza</sample>
    <sample id="344">I svantaggi dei metodi basati su alberi sono che spesso non vengono dati e devono essere ottenuti in qualche modo. Questo può essere complicato e talvolta un processo computazionalmente costoso. Inoltre, spesso richiedono un pre-processamento formale significativo delle forme logiche, ad esempio per gestire i simboli variabili.</sample>
    <sample id="345">Il lavoro introduce un modello seq2seq neuro che gestisce la generalizzazione compositiva senza alberi. Si basa su multiset tagging e predizione di permutazioni latenti. Tagga ogni token di input con un multiset di token che appariranno nell'output. Poi predice una permutazione per mettere in ordine i token. Risolve il problema di non avere l'alignamento tra input e output in fase di training. L'approccio è flessibile ma trovare la permutazione più probabile è NP-hard. Si risolve con una rilassazione continua amichevole per GPU. Risulta essere più potente di altri modelli alberolessi nel testare generalizzazione a ricorsione più profonda.</sample>
    <sample id="346">Non so qual è l'affiliazione degli autori dell'articolo. Potresti dare più informazioni?</sample>
    <sample id="347">Ciao Myra, stai parlando del tuo lavoro "Marked Personas: Utilizzare Promemoria di Lingua Naturale per Misurare Stereotipi in Modello di Linguaggio Grande". Questo lavoro è stato fatto in collaborazione con Esin Durmus e Dan Jurafsky. Negli ultimi anni, molti hanno documentato la prevalenza di pregiudizi sociali e stereotipi nei grandi modelli di linguaggio, o LLM. Tuttavia, questi metodi hanno varie limitazioni. Generalmente dipendono da set di dati manualmente costruiti che sono molto tempo消费ivo da curare e inoltre solitamente misurano solo stereotipi molto specifici, il che significa che non si generalizzano bene a altre democrazie o contesti, o semplicemente catturano associazioni generali, come associazioni negative con particolari gruppi. Inoltre, la maggior parte del lavoro in questo campo non tiene conto dell'intersezione, che è la nozione che identità sociali multi-faccettate possono comporre pregiudizi e essere luoghi unici di d</sample>
    <sample id="348">L'articolo parla di come misurare le stereotiphe nelle grandi modelle di linguaggio. Molti hanno documentato la presenza di bias sociali in queste LLM. Tuttavia, i metodi attuali hanno limitazioni. Questo lavoro, in collaborazione con Esin Durmus e Dan Jurafsky, usa promemoria naturali per creare personaggi immaginari. Questi personaggi possono essere generati con promemoria specifiche, come "immagina di essere una donna asiatica". I risultati mostrano interessanti modelli, come la descrizione di donne di colore che fanno riferimento all'ancestralità. Il metodo ha due parti: generare personaggi e utilizzare parole marcate per identificare differenze tra gruppi marcato e non marcato. I risultati mostrano che i personaggi generati contengono più stereotiphe rispetto a quelli scritti da umani. Tuttavia, la distribuzione di parole dei personaggi generati è più limitata. L'articolo conclude con tre raccomandazioni per gli owner di modello: affrontare i stereotiphe positivi</sample>
    <sample id="349">Ciao a tutti, il mio nome è Jingwei Yi dalla University of Science and Technology of China. È un piacere presentare un breve video pubblicitario del nostro articolo. Stai copiando il mio modello? Proteggere il copyright dei grandi modelli linguistici per l'embeddaggio come servizio tramite marchio di fabbrica indietro. Prima di tutto, introduciamo il contesto dell'embeddaggio come servizio. Attualmente, grandi modelli linguistici come GPT, LLAMA, PALM sono eccezionali nell'interpretazione e nella generazione del linguaggio naturale. L'embeddaggio come servizio è uno dei servizi costruiti su grandi modelli linguistici per assistere varie, NLP, compiti. Ad esempio, OpenAI offre un API di embeddaggio basata su GPT. Tuttavia, recenti studi hanno mostrato che l'attaccante può rubare il modello imparando dall'embeddaggio e fornire servizi simili. Quindi, è necessario proteggere il copyright dell'embeddaggio come servizio.</sample>
    <sample id="350">L'articolo esplora il significato della performance superumana in NLU. Negli ultimi cinque anni, i leaderboard sono diventati standard in NLP, portando ad obiettivi di raggiungere la cima in benchmark popolari. I sistemi possono raggiungere livelli di performance umani o superumani, ma ciò non significa che siano in grado di gestire compiti che richiedono conoscenza, ragionamento e inferenza. I modelli sono fragili, non generalizzano bene, sono vulnerabili a attacchi e dipendono da pattern spurii. Analizzando due benchmark popolari, SuperGLUE e SQuAD, si scopre che i sistemi superano gli umani in molti casi, ma ci sono errori nella valutazione. Ad esempio, gli umani vengono valutati su subset piccoli o non rappresentativi, mentre i sistemi su set completi. Inoltre, ci sono errori nei dati di riferimento. I modelli possono trovare correlazioni spurie mentre gli umani no. La stima della performance umana è spesso vaga</sample>
    <sample id="351">L'articolo esplora se i tagger di CoNLL-2003 per l'NER sono ancora efficaci nel 2023. Si analizzano problemi di generalizzazione. Si sviluppa il CoNLL++ Dataset con notizie Reuters del 2020. Si ottengono più di 20 modelli e si valutano su CoNLL-03 e CoNLL++. Per una buona generalizzazione, si trovano tre ingredienti: architettura del modello, dimensione del modello e numero di esempi di fine-tuning. Per la riduzione del presto delle prestazioni, si ipotizzano overfitting adattivo e drift temporale. L'overfitting adattivo non è osservato. Il drift temporale è confermato come causa principale. Conclusione: i tagger di CoNLL-2003 sono ancora efficaci nel 2023. Chiede più ricerca per migliorare la generalizzazione dei modelli.</sample>
    <sample id="352">ABC-Eval è un approccio dimensionale per valutare l'intelligenza artificiale del dialogo. È un metodo che cerca di ridurre la soggettività dell'evaluation umana, annotando se le risposte del modello esprimono determinati comportamenti, come rispondere con informazioni irrilevanti o contraddizioni. Questo permette di misurare le tassi di errori tematici commessi dai modelli di chat.</sample>
    <sample id="353">L'articolo introduce un metodo per la generazione di codice Python attraverso domande di chiarimento. Motivazione: la generazione di codice e la sintesi di programmi da una descrizione naturale linguistica è un'area di ricerca calda. I metodi attuali falliscono a gestire l'underspecification. L'underspecification è comune in casi reali. L'interazione, come domande di chiarimento, è un buon paradigma per affrontare questo problema. Due sfide sono identificate: le specie mancanti possono accadere a diversi livelli e non è chiaro come identificare se una descrizione naturale linguistica, NLD, contiene informazioni su specie a qualsiasi livello. Il metodo proposto è di creare CodeClarQA, un dataset sintetico con chiarimenti su operazioni chiave. Si propone un pipeline di generazione di codice attraverso domande di chiarimento. Si identificano operazioni chiave basandosi su un grafo di conoscenza generato da Graph4Code. Si analizzano i risultati di identificazione di operazioni chiave manc</sample>
    <sample id="354">Fino al 2020.</sample>
    <sample id="355">Ciao Vasudha, sei un candidato PhD in Computer Science all'Università Stony Brook. Vorresti presentare il nostro lavoro accettato in ACL 2023 come un lungo articolo, "Transfer Learning per la rilevazione di dissonanza: affrontare il problema della classe rara". Iniziamo definendo la dissonanza cognitiva e perché è un problema importante da studiare nel linguaggio. In parole semplici, la dissonanza cognitiva è una situazione in cui due credenze o azioni sono inconsistenti, come questo esempio dove una persona afferma "So che le sigarette possono uccidere", e poi dice "Ho preso un paio di sigarette dopo la riunione". Questa credenza e azione sono inconsistenti e sono in dissonanza. Inoltre, la persona dice "Non penso potrei mantenere il mio lavoro senza di loro", giustificando la seconda occorrenza. Hanno una relazione consonante. Mentre la dissonanza è una fenomeno molto comune che esperiamo nella decisione quotidiana, è davvero rara di</sample>
    <sample id="356">Non so. Potresti dare più dettagli sull'articolo?</sample>
    <sample id="357">Siyu Yuan.</sample>
    <sample id="358">Cinque.</sample>
    <sample id="359">L'approccio viene confrontato con Wait-k strategy e Local Agreement.</sample>
    <sample id="361">L'abstract parla di un lavoro intitolato "CounterComp" che si concentra sull'uso di scenari counterfattuali per migliorare la generalizzazione compositiva per il ragionamento quantitativo a più passaggi. Il lavoro si concentra sul compito di risposta alle domande basato su un'analisi di tabella finanziaria. I modelli neurali attuali non performono bene in queste task, specialmente quando l'output ha più di due passaggi, perché memorizzano pattern spurii. L'idea è di creare modelli che attengano ai token appropriati nell'input quando generano operazioni nell'output. Per evitare l'aggiunta di segnali di supervisione costosi, si utilizzano scenari counterfattuali. Si tratta di esempi positivi e negativi che vengono estratti da un set di addestramento. Questi esempi vengono utilizzati per aggiungere una perdita di apprendimento metrico dinamica all'addestramento. Si dimostra che aggiungere questa perdita di apprendimento metrico migliora le</sample>
  </task>
</testset>