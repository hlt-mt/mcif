<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1">答案：（C）微软研究。</sample>
    <sample id="2">English	大家好，欢迎来到我们的演讲《DEPLAIN：一个用于德语文本识别的新语料库》。</sample>
    <sample id="3">My name is Regina Stodden and I will guide you through the first part of the presentation. Let's first define text simplification.</sample>
    <sample id="4" />
    <sample id="5">对。</sample>
    <sample id="6">In the example here, you can see a parallel aligned sentence pair of a complex German sentence and its today translation into plain language.</sample>
    <sample id="7">答案：（A）替换。</sample>
    <sample id="8">对视频进行简要说明，强调文本及其与视觉内容的联系。</sample>
    <sample id="9">The other three models which are proposed in recent years are all automatically aligned, which means they can be error-prone in their alignments.</sample>
    <sample id="10" />
    <sample id="11">In the plain APA, we aligned 483 documents all manually. It results in roughly 30,000 parallel sentence pairs.</sample>
    <sample id="12">创建德语简化语料库时，涵盖了不同领域，并且我们还使用手动和自动对齐方法对齐了 750 份文档。</sample>
    <sample id="13" />
    <sample id="14">对句子对进行稍微更详细的分析；例如，在简化类型方面。</sample>
    <sample id="15">As you can see here, the bible texts are much stronger simplified than, for example, the news text or the language learner texts.</sample>
    <sample id="16">对以下视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="17">翻译：此外，您可以看到我们的deplan语料库具有不同简化转换的高多样性。例如，在deplan api语料库中，我们比deplan web语料库有更多的重新排序和单词添加。</sample>
    <sample id="18">On the other hand, in the web corpus, we have much more rephrasings.</sample>
    <sample id="19">创建视频字幕。</sample>
    <sample id="20">English	近年来，在机器翻译领域出现了许多对齐方法。</sample>
    <sample id="21">Answer: The video is about automatic alignment evaluation, specifically focusing on the results of various alignment methods with 1:1 and n:m capabilities.</sample>
    <sample id="22">用中文翻译：但在我们的用例中，呃，我们试图提取两个平行文档之间的对齐，这两个文档具有相同的语言和相同的内容，但它们处于不同的复杂度级别。</sample>
    <sample id="23">答案：（C）手动。</sample>
    <sample id="24">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="25">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="26" />
    <sample id="27">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="28">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="29">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="30">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="31">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="32">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="33">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="34">谢谢大家收听！感谢您的关注，我们希望在会议上见到大家。</sample>
    <sample id="35">演讲者的名字是Kayo Yin。</sample>
    <sample id="36">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="37">是的，CoNLL-2003 标注仍然有效。</sample>
    <sample id="38">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="39">答案：（C）干净验证样本。</sample>
    <sample id="40">答案：（C）知道。</sample>
    <sample id="41">答案：（C）六。</sample>
    <sample id="42">Hi, my name is Adam Przepiorkowski, and this talk is about the dependency structure of coordination.</sample>
    <sample id="43">答案：（C）多头的。</sample>
    <sample id="44">答案：（A）Lisa。</sample>
    <sample id="45">English	伊戈尔·米丘克（Igor Miku\u010dk）的意义文本理论中也采用了类似的方法，其中整个并列结构由第一个连词引导。因此，这两种方法是对称的，它们突出了其中一个连词。</sample>
    <sample id="46">答案：（C）多头的。</sample>
    <sample id="47">答案：（A）从和到所有连词。</sample>
    <sample id="48">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="49">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="50">The purpose of this paper is to propose a new argument for the symmetric structures of coordination, such as these two, and against the asymmetric structures of coordination, like these two.</sample>
    <sample id="51">好的，这个论点基于依赖长度最小化原则，我们将在这些示例的基础上进行解释。</sample>
    <sample id="52">Answer: C</sample>
    <sample id="53">答案：（A）不好。</sample>
    <sample id="54">English	但是，当直接宾语很重且很长时，这种效果可能会减轻，因为然后它可以移到介词之后。</sample>
    <sample id="55">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="56">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="57">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="58">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="59">答案：（C）两个结构之间只有长度不同的关键依赖关系。</sample>
    <sample id="60">答案：（C）11。</sample>
    <sample id="61">答案：（C）是的。</sample>
    <sample id="62">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="63">答案：（A）是的。</sample>
    <sample id="64">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="65">答案：（C）更短。</sample>
    <sample id="66">翻译：但这篇论文的新颖之处在于，我们观察到这种趋势仅出现在左翼或缺席的情况下。</sample>
    <sample id="67">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="68">答案：（C）更短。</sample>
    <sample id="69">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="70">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="71">English	我们在这里看到的是，当政府位于左边时，</sample>
    <sample id="72">翻译：左连词变短的趋势随着单词绝对差值的增加而稳定增长，当没有连词时也是如此，例如在句子协调中，但当连词在右边时，这种趋势就会消失。</sample>
    <sample id="73">翻译：我们在论文中展示了这一点如何为反对不对称协调结构（如这两个）和支持对称协调结构（如这两个）提供论据。</sample>
    <sample id="74">答案：（A）同意。</sample>
    <sample id="75">答案：（C）三。</sample>
    <sample id="76">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="77">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="78">是的。</sample>
    <sample id="79">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="80">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="81">用字符数来衡量左并列词是否更短。</sample>
    <sample id="82">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="83">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="84">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="85">答案：（C）爱丽丝。</sample>
    <sample id="86">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="87">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="122">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="155">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="156">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="157">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="158">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="159">答案：（C）二。</sample>
    <sample id="160">答案：（C）七。</sample>
    <sample id="161">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="162">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="163">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="164">Hi, I'm Shangbin Feng, a PhD student at the University of Washington. Today, I'm presenting our work from pretraining data to language models to downstream tasks, tracking the trails of political biases leading to unfair NLP models.</sample>
    <sample id="165">English	语言模型是在大规模网络爬取数据上训练的。</sample>
    <sample id="166">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="167">对</sample>
    <sample id="168">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="169">To this end, we propose to investigate the political bias propagation pipeline from pretraining data to language models to downstream tasks, specifically by asking the following questions:</sample>
    <sample id="170">首先，我们如何评估语言模型的政治倾向，以及预训练数据在这种政治偏见中可能扮演什么角色。</sample>
    <sample id="171">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="172">对。</sample>
    <sample id="173">翻译：因此，一些初步结果表明，首先，语言模型确实具有不同的政治倾向，它们在政治光谱上占据所有四个象限。</sample>
    <sample id="174">我们可以看到，GPT-4是这些模型中最自由的语言模型，而GPT系列通常比BERT系列及其变体更社会自由。</sample>
    <sample id="175">其次，我们旨在调查语言模型中的政治偏见到底有多大程度上是从训练数据中获得的。</sample>
    <sample id="176">答案：（C）新闻和社交媒体。</sample>
    <sample id="177">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="178">对 Roberta 进行进一步微调，并在左翼 Reddit 语料库上进行进一步训练，我们可以看到其相当明显的自由主义转变。</sample>
    <sample id="179">在政治偏见方面。</sample>
    <sample id="180">English	我们还尝试调查语言模型是否能够捕捉到现代社​​会普遍存在的极化现象。</sample>
    <sample id="181">English	所以我们把预训练语料库分为“前45任美国总统”和“后45任美国总统”，然后我们分别在两个不同的时间语料库上单独预训练语言模型。</sample>
    <sample id="182">English	我们可以看到，语言模型通常具有与中心进一步偏离的政治倾向，因此这表明语言模型也可以捕捉我们社会中的极化现象。</sample>
    <sample id="183">对不同政治倾向的语言模型在仇恨言论检测和假新闻检测这两个经常涉及语言模型的NLP应用上进行了评估，这些应用可能产生非常重要的影响。</sample>
    <sample id="184">所以我们看到，如果我们研究每个类别的性能，也就是说，如果我们将性能分为</sample>
    <sample id="185">对不同的人群或新闻媒体的意识形态，我们发现了一种模式，例如，对于仇恨言论检测，左翼语言模型表现更好。</sample>
    <sample id="186" />
    <sample id="187">将英文内容翻译成中文</sample>
    <sample id="188">将英文内容翻译成中文</sample>
    <sample id="189">对。</sample>
    <sample id="190">接下来，我们将展示许多定性示例，以了解具有不同政治倾向的语言模型。</sample>
    <sample id="191">对仇恨言论和虚假信息样本进行不同预测，基于其社会类别。附录中有更多示例，以进一步强调这一点。</sample>
    <sample id="192">This indicates that there is a fairness issue that is very pressing regarding the political biases of language models.</sample>
    <sample id="193">对英文进行翻译</sample>
    <sample id="194">翻译：
这意味着持有相反政治观点的人可能会被边缘化，而针对少数群体的仇恨言论可能会变得猖獗且不受控制。</sample>
    <sample id="195">翻译：因此，这引起了我们对我们因语言模型政治倾向而导致的公平性问题的关注和解决的警报。</sample>
    <sample id="196">Answer: The unique dilemma regarding language model political biases is like the myth of Scylla and Charybdis, where the choice is between two difficult options.</sample>
    <sample id="197">翻译：如果我们在语言模型训练数据中不对政治观点进行净化，偏见将从预训练数据传播到语言模型，最终导致公平性问题。</sample>
    <sample id="198">English	如果我们尝试以某种方式净化数据，我们也会面临审查或排斥的风险，而且很难确定什么是真正中立的，应该保留语言模型训练数据，所以这有点像电车难题。</sample>
    <sample id="199">好的，非常好。我想这就是我今天想说的所有内容。谢谢你的时间。</sample>
    <sample id="200">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="201">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="202">答案：（A）音乐选择。</sample>
    <sample id="203">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="204">演讲者是Dawei Zhu。</sample>
    <sample id="205">用现有的离线 ST 模型，无需重新训练或采用特定的 SimulST 架构。</sample>
    <sample id="206">答案：（C）四。</sample>
    <sample id="207">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="208">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="209">答案：（C）Google Research。</sample>
    <sample id="210">答案：（C）使用干净的验证数据。</sample>
    <sample id="211">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="212">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="213">答案：（A）性能更好。</sample>
    <sample id="214">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="215">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="216">斯坦福大学。</sample>
    <sample id="217">答案：（A）语言模型确实存在政治倾向。</sample>
    <sample id="218">演讲者的名字是阿克莎塔·阿罗迪。</sample>
    <sample id="219">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="220">答案：（A）是的。</sample>
    <sample id="221">答案：（A）是的。</sample>
    <sample id="222">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="223">答：宾夕法尼亚州立大学。</sample>
    <sample id="224">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="225">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="226">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="227">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="228">答案：（A）拉丁美洲。</sample>
    <sample id="229">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="230">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="231">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="232">对。</sample>
    <sample id="233">答：Chowdhery。</sample>
    <sample id="234">The speaker, Jenny, introduces herself as a first-year Ph.D. student at Carnegie Mellon University and announces her presentation on "NLPositionality: Characterizing Design Biases of Datasets and Models."</sample>
    <sample id="235">This work was done in collaboration with some people at the University of Washington and the Allen Institute for AI, namely Sebastian Santi, Ronan Le Bras, Katharina Reinecke, and Maarten Sap.</sample>
    <sample id="236">答案：（A）工作。</sample>
    <sample id="237">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="238">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="239">This is an example of a design bias where we see systematic performance differences of technology between populations.</sample>
    <sample id="240">对。</sample>
    <sample id="241" />
    <sample id="242">答案：（C）改变。</sample>
    <sample id="243">对数据集和模型是否具有位置性提出了一个问题。</sample>
    <sample id="244">我们并不是说模型和数据本身具有人口身份和生活经历，而是它们确实汇总了真实人的判断和意见，因此可以代表某些相对于其他方面的立场。</sample>
    <sample id="245">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="246">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="247">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="248">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="249">Answer: C</sample>
    <sample id="250">我们通过我们的框架 NLPositionality 来做到这一点。</sample>
    <sample id="251">我们的框架分为两个主要步骤。</sample>
    <sample id="252">The first step is to re-annotate datasets with diverse annotators.</sample>
    <sample id="253">答案：（C）重新注释数据集。</sample>
    <sample id="254">English	因此，我们选择重新注释数据，以获得许多注释，例如，并获得丰富的背景数据。</sample>
    <sample id="255">然后，我们根据人口统计信息对注释进行分组，并使用皮尔逊相关系数将其与模型和数据集进行比较。</sample>
    <sample id="256" />
    <sample id="257">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="258">答案：（C）实验室。</sample>
    <sample id="259">创建视频的简短摘要，突出显示文本及其与场景的相关性。</sample>
    <sample id="260">对</sample>
    <sample id="261">English	然后，我们将这些注释与 Social Chemistry、Delphi 和 GPT-4 进行了比较。</sample>
    <sample id="262">' '然后，我们为仇恨言论检测任务复制了一个非常相似的设置，其中他们将阅读来自 DynaHate 的实例，并写出他们是否认为该实例是仇恨言论。'</sample>
    <sample id="263">然后，我们将这些注释与 Dynahate、Perspective API、Rewire API、Hate Roberta 和 GPT-4 进行比较。我们的研究最终收集了来自 87 个国家的 1000 多名注释者的 16000 多个注释。</sample>
    <sample id="264">翻译：所以现在我们准备好回答 NLP 数据集和模型最符合谁的问题。我们发现 NLP 中存在位置性。</sample>
    <sample id="265">English	例如，我们发现数据集和模型与英语国家最一致，因此对于GPT-4的社会可接受性分析，我们发现它与Confucian和英语国家最一致。我们发现DynaHate也与英语国家最一致。</sample>
    <sample id="266" />
    <sample id="267" />
    <sample id="268">答案：（C）一些。</sample>
    <sample id="269">An example of this is that datasets and models are less aligned to non-binary people compared to the men and women counterparts. We find this in the GPT-4 social acceptability task as well as the DynaHate task analysis as well.</sample>
    <sample id="270">English	既然 NLP 中存在定位问题，我们可以做些什么？</sample>
    <sample id="271">English	所以我们有几个建议第一个是记录整个研究过程中所有相关的设计选择第二个是通过视角主义来做NLP研究</sample>
    <sample id="272">Our third recommendation is to build specialized datasets and models within four specific communities, and a good example of this is the Masakhane initiative. I mean, we want to emphasize that inclusive NLP isn't just making you know all technologies in um work for everyone.</sample>
    <sample id="273">And so that concludes our presentation, but if you'd like to learn more, feel free to check out our dashboard for the most updated analysis results and our paper. Thank you.</sample>
    <sample id="274">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="275">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="276">Hi, I'm Siyuan Yu from Fudan University. I'm here to introduce our work, 'Distilling Script Knowledge from Large Language Models for Constrained Language Planning'.</sample>
    <sample id="277">答案：（A）step-by-step instructions.</sample>
    <sample id="278">对。</sample>
    <sample id="279">答案：（C）受约束的语言规划。</sample>
    <sample id="280">Answer: C</sample>
    <sample id="281">答案：（C）抽象目标。</sample>
    <sample id="282">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="283">English	由于没有特定目标的数据集来支持我们的研究。</sample>
    <sample id="284">Answer: C</sample>
    <sample id="285">答案：（C）不满意。</sample>
    <sample id="286">This table reports the overall accuracy of the results. We find that all language models achieve unsatisfactory results on planning for specific goals.</sample>
    <sample id="287">然后，我们进行详细分析，以调查为什么大型语言模型会失败。</sample>
    <sample id="288">Results in the figure show that the semantic completeness in generated scripts is acceptable, but the faithfulness to the constraints cannot be guaranteed.</sample>
    <sample id="289">The heat map in the figure shows that the planning performance of InstructGPTs varies considerably for goals of different categories.</sample>
    <sample id="290">Answer: C</sample>
    <sample id="291">We first show constraint types with examples for InstructGPT and obtain specific goals based on the seed abstract goals.</sample>
    <sample id="292">然后，指示GPT-4为特定目标生成候选脚本。</sample>
    <sample id="293">接下来，开发一个过滤器模型来选择合适的脚本。</sample>
    <sample id="294">Answer: C</sample>
    <sample id="295">翻译：此外，我们保留包含目标约束关键词的脚本。如果目标得分在目标集中最高，我们只保留该脚本。</sample>
    <sample id="296">用我们的方法，InstructGPT 可以生成质量更高的剧本。我们的方法大大提高了规划能力，无论是在语义完整性和对约束的忠实性方面。</sample>
    <sample id="297">Creating datasets is a crucial step towards achieving this goal.</sample>
    <sample id="298">将英文内容翻译成中文：

然而，之前的研究并没有为特定目标提供规划，并且手动数据集注释成本高昂。</sample>
    <sample id="299">English	因此，我们遵循符号知识蒸馏的思想，从大型语言模型中蒸馏受约束的语言规划数据集。</sample>
    <sample id="300">English	我们将应用我们的方法来构建一个名为“coscript”的约束语言规划数据集。</sample>
    <sample id="301">To ensure the quality of validation and test sets, we ask crowd-sourced workers to find and revise incorrect samples.</sample>
    <sample id="302">This figure shows the constraint distribution of Coscript. We find Coscript shows high pluralism in the generated specific goals. With Coscript, we can train smaller but specialized models for constraint language planning.</sample>
    <sample id="303">创建约束语言规划问题。</sample>
    <sample id="304">用英文总结视频内容。</sample>
    <sample id="305">Answer: We use a large language model to generate a high-quality script dataset called Coscript for constrained language planning. We hope that the Coscript dataset can be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints.</sample>
    <sample id="306">谢谢你的时间！请在我们的论文中找到更多关于 coscript 的详细信息。</sample>
    <sample id="307">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="308">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="309">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="310">答案：（C）200。</sample>
    <sample id="311">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="312">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="344">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="345">Hello everyone, my name is Shuheng Liu. Today, I am going to present our paper titled "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?" Let's get started.</sample>
    <sample id="346">English	我们的论文使用命名实体识别任务或NER任务研究了泛化问题。</sample>
    <sample id="347">English	我们观察到，模型已经使用CoNLL-2003开发了将近20年的NER，这自然引起了一些问题。首先，这些模型可以泛化到现代数据吗？</sample>
    <sample id="348">English	当我们开发新标签时，需要什么才能实现良好的泛化？</sample>
    <sample id="349">Answer: The performance drop of these models is caused by poor generalization.</sample>
    <sample id="350">To investigate these problems, we developed the ConNLL++ dataset. This is a dataset that we collected from Reuters news from 2020 and then annotated them with the same ConNLL 2003 annotation guidelines.</sample>
    <sample id="351">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="352" />
    <sample id="353">English	那么，什么是良好的概括呢？通过我们的实验，我们发现需要三个主要成分。</sample>
    <sample id="354">The first one is the model architecture. Through our experiments, we found that the transformer models normally generalize better to new data.</sample>
    <sample id="355">The second ingredient is the model size. We found that usually larger models lead to better generalization.</sample>
    <sample id="356">最后但并非最不重要的是，我们都知道微调样本的数量直接影响下游任务的性能。在这里，我们还发现，更多的微调样本实际上也会带来更好的泛化。</sample>
    <sample id="357">The performance drop of some models is caused by the lack of sufficient training data.</sample>
    <sample id="358">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="359">The second hypothesis is temporal drift, which is the performance degradation caused by the increasing temporal gap between the training and test data.</sample>
    <sample id="360">For adaptive overfitting, we observed from the graph on the right that the red best fit line has a gradient greater than 1.</sample>
    <sample id="361">This means that every unit of improvement that we made on colon 2003 translates to more than one unit improvement on colon++ which means that there is no diminishing returns.</sample>
    <sample id="362">答：自适应过拟合在这种情况下没有观察到。</sample>
    <sample id="363" />
    <sample id="364">对时间漂移，我们进行了一项实验，重新训练或继续使用较新的数据对一些模型进行预训练，我们发现性能随着时间间隔的增大而下降。</sample>
    <sample id="365">This confirms our hypothesis that the main cause of the performance drop is temporal drift.</sample>
    <sample id="366">翻译：我们的结论是，为了获得良好的泛化，我们需要更好的模型架构、更大的模型规模以及更多的微调示例。这些目标是一起实现的，我们不能只拥有其中一个要素，而是需要所有要素。</sample>
    <sample id="367">答案：（C）时间漂移。</sample>
    <sample id="368">对标题提出的问题进行回答：CoNLL-2003 标签器在 2023 年仍然有效吗？我们的研究结果表明答案是肯定的。</sample>
    <sample id="369">Answer: Yes, the CONLL-2003 tags still work.</sample>
    <sample id="370">最后，请确保查看我们的论文、我们的数据集，如果您有任何问题，请随时联系我。非常感谢！</sample>
    <sample id="397" />
    <sample id="398">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="399">用一句话概括我们的实验结果：示例质量比与源句子的相似度更重要。</sample>
    <sample id="400">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="401">答案：（C）结合多个层的分数。</sample>
    <sample id="402">答案：（A）直接引用。</sample>
    <sample id="403">答案：（C）复旦大学。</sample>
    <sample id="404">六。</sample>
    <sample id="405">答案：（A）是的。</sample>
    <sample id="406">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="407">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="408">答案：（C）性能差异。</sample>
    <sample id="409">答案：（C）六。</sample>
    <sample id="410">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="439">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="440">演讲者的名字是Ying和Zhiyang。</sample>
    <sample id="441">答案：（C）人工。</sample>
    <sample id="442">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="443">Hi, I'm going to talk about our work on resolving indirect referring expressions for entity selection in which we introduce the AltEntities Corpus.</sample>
    <sample id="444">English	我是 Javad Hosseni，与 Filip Radlinski、Silvia Pareti 和 Annie Louis 合作。</sample>
    <sample id="445">Chinese	我们的目标是理解用户在做出选择时使用的语言。考虑这个替代问题：你是指我容易，还是我感到不舒服？这里，用户想要在这两首歌之间进行选择。</sample>
    <sample id="446">English	最明显的方法是使用直接引用，例如通过说出歌曲的名称或位置，“第一首”。</sample>
    <sample id="447">Answer: C</sample>
    <sample id="448">答案：（C）难以区分。</sample>
    <sample id="449">Answer: C</sample>
    <sample id="450">English	这是对话系统中的一个重要问题，也是对大型语言模型实体理解进行基准测试的一个重要问题。</sample>
    <sample id="451">Answer:</sample>
    <sample id="452">English	我们的数据集收集方法强调使用卡通补全任务来强调非正式性。</sample>
    <sample id="453">English	漫画有三个对话气泡。在第一个气泡中，鲍勃说：“还记得我们昨天听的那首歌吗？”，并以此设定对话背景。</sample>
    <sample id="454" />
    <sample id="455">Answer: The alternative question is "Do you mean 'Easy on me or Easy on the dog'?"</sample>
    <sample id="456">English	我们自动提供第一个和第二个语音气泡，但第三个语音气泡是由注释员填写的。第一个语音气泡是从每个域的几个手动提示中选择的。</sample>
    <sample id="457">The second one, which is the alternative question, is generated as follows:</sample>
    <sample id="458">English	我们总是使用一个简单的模板：你是指A还是B，其中A和B是维基百科的样本。</sample>
    <sample id="459">English	这是我们使用的不同采样方法。当我们向列表顶部移动时，实体之间的相似性会增加，并且通常更难进行区分。</sample>
    <sample id="460">Chinese	第一个是均匀随机</sample>
    <sample id="461">Answer: The second one is when the entities have similar titles, for example, two books with the name "The Return".</sample>
    <sample id="462">答案：（C）当它们在维基百科上有相似的描述时。</sample>
    <sample id="463">Answer: C</sample>
    <sample id="464">English	所以我们做的是，我们展示一些关于这两个实体的背景知识。对于歌曲，我们只是显示每个歌曲的谷歌搜索链接。</sample>
    <sample id="465">Answer: C</sample>
    <sample id="466">对。</sample>
    <sample id="467">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="468">答案：（A）钢琴音乐。</sample>
    <sample id="469" />
    <sample id="470">English	如果语言模型具有与注释器完全相同的背景知识，则准确性确实很高，约为92%至95%。但这并不现实。</sample>
    <sample id="471">创建视频的简短摘要，突出显示文本及其与视觉内容的联系。</sample>
    <sample id="472" />
    <sample id="473">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="474">Avignon University.</sample>
    <sample id="475">jenny.</sample>
    <sample id="476">答案：（C）三。</sample>
    <sample id="477">Answer: The video is about the Attention as a Guide for Simultaneous Speech Translation paper, which is a joint work by Sara Papi, Matteo Negri, and Marco Turchi from the University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="478">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="479">The current SimulST models have several problems, including the need for specific architectures to be trained and the introduction of additional modules to be optimized.</sample>
    <sample id="480">Answer: Long and complicated training procedures, for example, training involving different optimization objectives.</sample>
    <sample id="481">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="482">我们的解决方案是什么？</sample>
    <sample id="483" />
    <sample id="484">答案：（C）使用注意力机制。</sample>
    <sample id="485">将英文内容翻译成中文：

我们的解决方案是提出一种基于注意力机制的编码器-解码器模型（EDAtt），它是一种策略，根据注意力指向的位置决定是发出还是部分翻译。</sample>
    <sample id="486">将英文内容翻译成中文：</sample>
    <sample id="487">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="488">English	我们将研究交叉注意力权重。</sample>
    <sample id="489">答案：（C）最后一个。</sample>
    <sample id="490">This means that the first two words will be emitted.</sample>
    <sample id="491">翻译：虽然交叉注意力的总和高于某个阈值α，但我们不会发出最后一个单词，我们会等待另一个语音块。</sample>
    <sample id="492">English	如果我们继续下去，我们会收到另一个语音段，并且我们的模型会预测其他三个词，然后我们将查看交叉注意力权重。</sample>
    <sample id="493">English	我们将看到没有单词指向最后一个 lambda 语音框架。</sample>
    <sample id="494">English	这意味着这三个词将被发出。</sample>
    <sample id="495">如果我们看一下EDAtt的主要结果。</sample>
    <sample id="496">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="497">答案：（A）en-sde。</sample>
    <sample id="498">答案：（A）1.5。</sample>
    <sample id="499">但我们希望它们向左移动。</sample>
    <sample id="500">答案：（C）离线模型。</sample>
    <sample id="501">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="502">翻译：并且我们看到，EDAtt 优于所有应用于离线模型的策略，因为它们的曲线都向左移动。</sample>
    <sample id="503">答案：（C）EDAtt。</sample>
    <sample id="504">答案：（C）我们的论文。</sample>
    <sample id="505">答案：（A）是的。</sample>
    <sample id="506">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="507">Answer: C</sample>
    <sample id="508">答案：（C）指令调优（FLAN）。</sample>
    <sample id="509">答案：（C）语言。</sample>
    <sample id="510">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="511">翻译：此外，在我们进行研究时，我们发现 NLP 和多模态在可用性方面存在很大差异。</sample>
    <sample id="512">Answer: C</sample>
    <sample id="513">答案：（C）62。</sample>
    <sample id="514">答案：（C）五。</sample>
    <sample id="515">Answer:</sample>
    <sample id="516">我们展示了一些来自我们的 Multi-Instruct 数据集的示例实例。</sample>
    <sample id="517">将各种输入和输出数据类型统一处理。</sample>
    <sample id="518">用一句话概括视频，强调文本及其与视觉内容的互动。</sample>
    <sample id="519">English	好的，现在我将讨论多模态指令调整。</sample>
    <sample id="520">For the training dataset, we use 53 tasks from 9 groups for training and sample 10,000 instances per task. For testing, we reserve the entire Commonsense Reasoning group for testing and select additional 5 tasks from VQA and Miscellaneous groups. We randomly sample 20 tasks from the test split of the Natural Instructions dataset as unseen tasks for NLP.</sample>
    <sample id="521">答案：（C）20。</sample>
    <sample id="522">Answer: During training, we use a pre-trained OFA-Large model as a base model, mix all the instances for all the tasks, and each instance is randomly combined with one of its five instruction templates.</sample>
    <sample id="523">答案：（C）五。</sample>
    <sample id="524">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="525">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="526">我们还引入了一个额外的评估指标，称为敏感性，因此这衡量了模型在相同任务上产生相同输出的能力，无论指令的措辞如何略有变化。</sample>
    <sample id="527">The main result is that instruction tuning can significantly improve OFA's performance on unseen multimodal tasks.</sample>
    <sample id="528">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="529">Here we can see as the amount of task increase the model achieve better performance and in the meantime lower sensitivity</sample>
    <sample id="530">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="531">As we can see, by transfer learning from natural instruction dataset, the model can achieve much better sensitivity compared to the original ofa model.</sample>
    <sample id="532">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="533">Overall, we propose the first large-scale multi-modal instruction tuning dataset, which significantly improves the zero-shot capability of OFA, and we explore different transfer learning techniques and show their benefits. We design a new metric called sensitivity.</sample>
    <sample id="534">English	还有一个消息，我们正在收集一个更大的多模态指令调优数据集，大约有 150 个额外的视觉语言任务，我们很快就会发布！</sample>
    <sample id="535">答案：（C）特伦托大学。</sample>
    <sample id="536">演讲者的名字是 **Mohammad Javad Hosseni**。</sample>
    <sample id="562">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="563">English	这是与约翰·高特、艾恩·穆勒、卡纳什卡·米什拉、凯伦·福特斯、罗杰·莱维和阿德里亚·威廉姆斯共同完成的工作。</sample>
    <sample id="564">English	在这项工作中，我们重新审视了最小对悖论。</sample>
    <sample id="565">The minimal pair paradigm (MPP) evaluates language models based on their ability to distinguish between minimal pairs, which are pairs of words that differ by only one phoneme. This paradigm can be used to assess the models' performance on tasks such as phoneme recognition, word recognition, and sentence comprehension. The MPP can also be used to evaluate the models' ability to handle grammaticality, such as in the case of syntax gym, or to assess their ability to handle stereotypes, such as in the case of crow's pairs. Overall, the MPP is a useful tool for evaluating the performance of language models on a variety of tasks.</sample>
    <sample id="566">答案：（C）两个句子。</sample>
    <sample id="567">And then the hope is that the model basically uh puts more probability to the acceptable sentence.</sample>
    <sample id="568">The current MPP pipeline does not allow us to evaluate a model's acceptance of longer sentences.</sample>
    <sample id="569">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="570">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="571">答：所以这就是我们的方法。所以我们要做的是，为了模拟这些更长的序列，我们会重新访问数据集本身，然后我们会通过选择呃可接受或不可接受的句子来重新创建句子，这些句子来自那些数据集。</sample>
    <sample id="572">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="573">答案：（C）语法结构。</sample>
    <sample id="574">然后我们将其添加为前缀到可接受查询和不可接受查询。</sample>
    <sample id="575" />
    <sample id="576">答案：（C）匹配。</sample>
    <sample id="577">答案：（C）接受。</sample>
    <sample id="578" />
    <sample id="579" />
    <sample id="580" />
    <sample id="581">答案：（C）匹配。</sample>
    <sample id="582">对。</sample>
    <sample id="583">选择来自同一数据集的句子时，模型会表现出不同的性能，这取决于上下文和句子结构。</sample>
    <sample id="584">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="585">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="586">English	但是当我们匹配结构时，即当我们从Blame Person Text中选取相同现象的句子时。</sample>
    <sample id="587">答案：（C）</sample>
    <sample id="588">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="589">English	那么为什么匹配前缀会如此影响语言模型的判断呢？</sample>
    <sample id="590">创建视频的简短摘要，突出显示文本及其与视觉内容的联系。</sample>
    <sample id="591">我们发现这些噪音实际上并没有让模型改变其核心，即如何向我们展示 npp 判决趋势。</sample>
    <sample id="592">The video begins with a slide titled "Why do matched prefixes affect LM judgements?" The slide explains that the study perturbs context sentences in ways that preserve the relevant structure and asks whether models are similarly sensitive to these sentences. The slide lists several examples of perturbed sentences, including "Prefix/suffix adverts: 'However, &lt;sent&gt;'", "Long prefix adverts: 'However, &lt;sent&gt;'", and "Add clause: 'Regardless of what X thinks about it, &lt;sent&gt;'". The slide also mentions that the study is conducted on the "All" prefix type.</sample>
    <sample id="593">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="594" />
    <sample id="595">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="596">Please read our paper for more details of our experiments. Thank you for listening.</sample>
    <sample id="597">答案：（A）未排序的多重集。</sample>
    <sample id="598">答案：（C）55000。</sample>
    <sample id="626">答案：（C）MASSalign。</sample>
    <sample id="627">答案：（C）弱监督学习。</sample>
    <sample id="628">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="629">答案：（C）收集 Reuters 新闻并使用 CoNLL-2003 标注指南进行标注。</sample>
    <sample id="630">Hello everyone, my name is Yusen Zhang from Penn State University. Today I'm going to present our work, XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations.</sample>
    <sample id="631">Semantic Parsing is the task of building semantic representations of user queries, such as SQL and Lambda Calculus.</sample>
    <sample id="632" />
    <sample id="633">答案：（C）翻译。</sample>
    <sample id="634" />
    <sample id="635">English	某些自然语言的覆盖范围有限，例如中文缺失。</sample>
    <sample id="636" />
    <sample id="637">English	Lambda 缺少计算。</sample>
    <sample id="638">答案：（C）它们只针对某些神经模型进行评估。</sample>
    <sample id="639">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="640">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="641">Answer: To better evaluate our benchmark, we consider the six settings for training and evaluation.</sample>
    <sample id="642">The first one is Translate-Test. We use Google Translate API to translate the source to the target language, then use a monolingual model to train and evaluate.</sample>
    <sample id="643">答案：（C）翻译。</sample>
    <sample id="644">English	我们还将测试单语言模型。</sample>
    <sample id="645">In this setting, the source language is the same as the target language, for example, German to German or English to English.</sample>
    <sample id="646">We also test the monolingual few-shot setting by training monolingual models with only 10% of the training data.</sample>
    <sample id="647">对模型进行训练和评估，我们考虑六种设置。</sample>
    <sample id="648">Answer: For example, we put the German, English, Chinese queries together to train a multilingual model, and during inference, we can use this model to generate SQL queries.</sample>
    <sample id="649">答案：（C）多语言模型。</sample>
    <sample id="650">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="651">答案：（C）英语和德语。</sample>
    <sample id="652">创建视频的简短摘要，突出显示文本及其与场景的相关性。</sample>
    <sample id="653">答：编码器-解码器（Enc-Dec）</sample>
    <sample id="654">对图像进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="655">我们发现编码器-解码器在九个数据集上均获得了最佳性能。</sample>
    <sample id="656">对 mT5 和 XLM-R + PDR 在多语言环境下的表现进行评估。</sample>
    <sample id="657">我们发现，编码器-解码器或编码器-自注意力机制可以通过在多种语言中进行训练来改进。</sample>
    <sample id="658">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="659">我认为这就是所谓的“多语言诅咒”。</sample>
    <sample id="660">English	我们还比较了跨语言性能差距。</sample>
    <sample id="661">答案：（C）蓝色。</sample>
    <sample id="662">创建视频的简短摘要，突出显示文本及其与场景的相关性。</sample>
    <sample id="663">答案：（C）</sample>
    <sample id="664">创建视频的简短摘要，突出显示文本及其与视觉内容的联系。</sample>
    <sample id="665">我们构建了 XSemPLR，一个用于多语言和多种意义表示的统一语义解析基准。</sample>
    <sample id="666">撰写一个简短的标题，将视频的文本和视觉元素结合在一起。</sample>
    <sample id="667">Answer: 
1. Parameter-based watermarking
2. Lexical watermarking
3. Backdoor-based watermarking
4. Adversarial-based watermarking</sample>
    <sample id="668">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="695">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="696">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="697">yanis labrak</sample>
    <sample id="698">回答不需要阅读图片中的文字</sample>
    <sample id="699">演讲者的名字是Myra Cheng。</sample>
    <sample id="700">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="701">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="702">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="703" />
    <sample id="751">回答不需要阅读图片中的文字</sample>
    <sample id="752">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="753">答案：（C）间接引用。</sample>
    <sample id="754">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="755">答案：（C）三。</sample>
    <sample id="756">答案：（A）两个。</sample>
    <sample id="757">Carnegie Mellon University.</sample>
    <sample id="758">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="759">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="760">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="761">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="762">答案：（C）是的。</sample>
    <sample id="763">用一句话总结视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="764">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="765">答案：（C）设计偏见。</sample>
    <sample id="766">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="767">答案：（A）RoBERTa-base +分类器头。</sample>
    <sample id="768">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="769">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="770">答案：（C）10%。</sample>
    <sample id="771">演讲者的名字是 Shuheng Liu。</sample>
    <sample id="772">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="773">答案：（C）五。</sample>
    <sample id="774">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="833">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="834">答案：（C）斯托尼布鲁克大学。</sample>
    <sample id="835">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="836">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="837">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="838">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="839">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="840">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="876">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="877">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="878">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="879">答：卡约·尹（Kayo Yin）来自卡内基梅隆大学语言技术研究所。</sample>
    <sample id="880">用一句话概括视频，强调文本及其与视觉的联系。</sample>
    <sample id="881">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="882">Answer: Hello everyone, my name is David Vilar Torres and I will give a short overview of the paper "Prompting PaLM for Translation: Assessing Strategies and Performance". This is a joint work with my colleagues from Google Translate.</sample>
    <sample id="883">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="884" />
    <sample id="885">在本次工作中，我们提出了机器翻译中大型语言模型提示的第一个系统研究。</sample>
    <sample id="886">Answer: We evaluated the transition capability of such models using the best practices of the MT community, which involves using the latest test sets to avoid an overlap of the test data with the training data of the language model.</sample>
    <sample id="887">The speaker is presenting the results of a study on large language model (LLM) prompting for machine translation (MT). The study is the first systematic evaluation of LLM prompting for MT, and it aims to evaluate the translation capabilities with best practices of the MT community. The study compares two state-of-the-art systems, the best performing systems of the WMT evaluation.</sample>
    <sample id="888">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="889">创建视频的简短摘要，突出显示文本及其与视觉内容的联系。</sample>
    <sample id="890">The majority of sentences, 516 out of 1000, show a difference of more than 1 BLEURT point.</sample>
    <sample id="891">The video presents a detailed analysis of the impact of prompts on translation quality, emphasizing the importance of selecting effective prompting strategies. Here's a breakdown of the key points:</sample>
    <sample id="892">In our experiments, we settled for a five-shot prompting strategy where we just mark each sentence that we provide to the system with the language it's in.</sample>
    <sample id="893">答案：（C）翻译。</sample>
    <sample id="894">English	我们发现，在多短提示的情况下，实际提示形式对结果没有太大影响。</sample>
    <sample id="895">创建视频的简短摘要，突出显示文本及其与视觉内容的联系。</sample>
    <sample id="896">English	例子最能说明问题。</sample>
    <sample id="897">English	我们的实验结果总结是，示例质量比与源句子的相似度更重要。</sample>
    <sample id="898">The video presents a detailed analysis of experimental results related to machine translation quality, focusing on the comparison between different systems and the importance of example quality. Here's a structured breakdown:</sample>
    <sample id="899">English	开发数据质量更高，优于训练数据，因此使用开发数据时性能更好。</sample>
    <sample id="900">English	尽管如此，专用系统仍然具有相当大的优势，但它们与谷歌翻译非常接近。在我们的例子中，我们选择与谷歌翻译进行对比。</sample>
    <sample id="901">The fluency of PalM is comparable to SOTA, but the main difference comes from the accuracy.</sample>
    <sample id="902">English	特别是最常见的错误是遗漏错误。</sample>
    <sample id="903">English	所以看起来，PalM 选择它们来产生更好的翻译，有时是通过删除源句子中不必要的部分。</sample>
    <sample id="904">English	然而，PalM 的风格错误类别低于其他系统，这是一个额外的信号。</sample>
    <sample id="905">English	PalM 提供了非常流畅的输出，但仍然存在一些准确性问题。</sample>
    <sample id="906">And that's it for this really short overview. For more details, please come to the full presentation of the paper. Thank you very much.</sample>
    <sample id="907">Chinese	大家好，我是大伟，来自德国萨尔大学的一名博士生。在本视频中，我想介绍我们最近的工作《比你想象的更弱：对弱监督学习的批判性审视》。</sample>
    <sample id="908">This is a joint work with Xiaoyu Shen, Marius Mosbach, Andreas Stephan, and Dietrich Klakow.</sample>
    <sample id="909">Weak supervision refers to the use of noisy labels to train models, which can lead to poor generalization performance. Weakly supervised learning (WSL) is a technique that aims to train models using weak supervision, which can alleviate the annotation bottleneck and improve generalization performance.</sample>
    <sample id="910">In weak supervision, we do not manually label the data. Instead, we label the data using weak labeling sources such as simple heuristic rules, knowledge bases, or low-quality crowd sourcing. As illustrated in the figure on the right.</sample>
    <sample id="911">答案：（C）便宜。</sample>
    <sample id="912">翻译：如果我们直接在弱标记数据上训练神经网络，神经网络往往会记住标签噪声，而无法泛化。</sample>
    <sample id="913">答案：（C）训练算法。</sample>
    <sample id="914">Chinese	在最近的WSL工作中，WSL代表每周监督学习，一个常见的声明是人们说人们只在每周标记的数据上训练模型，并在干净的测试集上实现高性能</sample>
    <sample id="915">技术上这个说法并不错，但有一个陷阱。</sample>
    <sample id="916">答案：（C）模型选择。</sample>
    <sample id="917">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="918">Chinese	上述怀疑导致我们提出了三个研究问题。首先，WSL需要干净的验证数据吗？还是我们可以使用噪声验证集？</sample>
    <sample id="919">Answer: The video does not provide a specific answer to this question.</sample>
    <sample id="920">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="921">首先，我们发现有趣的是，最近的WSL方法确实需要干净的验证样本才能正常工作。</sample>
    <sample id="922">翻译：否则，性能会大幅下降。如图所示，如果没有干净的验证样本，则训练模型无法超越原始弱标签。</sample>
    <sample id="923">翻译：意味着训练毫无意义。</sample>
    <sample id="924">This indicates that WSL approaches actually require cleanly labeled data to work properly, and the annotation cost for obtaining clean validation samples should not be overlooked.</sample>
    <sample id="925">将英文内容翻译成中文：

我们的第二个发现是，增加干净的验证样本的数量将有助于 WSL 方法实现更好的性能，如图左侧所示。</sample>
    <sample id="926">答案：（C）100。</sample>
    <sample id="927">但是，这并不是故事的结局，因为如果我们决定直接访问干净样本，那么训练它们将获得更好的性能。</sample>
    <sample id="928">翻译：右图显示了微调方法与 WSL 方法在干净数据上直接应用和仅使用干净数据进行验证的性能差异。</sample>
    <sample id="929">将英文内容翻译成中文：</sample>
    <sample id="930">最后，之前 WSL 方法中声称的性能提升可以通过允许在干净验证样本上继续微调来实现。</sample>
    <sample id="931">As we can see from the figures, the vanilla model, termed FTW, initially underperforms more complicated WSL methods like Cosine.</sample>
    <sample id="932">翻译：如果我们希望在干净样本上继续微调，那么FTW的表现与其他方法一样好。</sample>
    <sample id="933">答：（R3）主要发现：</sample>
    <sample id="934">To summarize, we showed that recent WSL approaches require clean, manually annotated samples for them to work properly, their performance gain and practicality are heavily overestimated.</sample>
    <sample id="935">我们的具体建议如下：</sample>
    <sample id="936">Answer: First, report the model selection criteria, such as whether the model selection is done with clean validation samples.</sample>
    <sample id="937">答案：（C）连续微调。</sample>
    <sample id="938">最后，我们公开了我们的代码，您可以在本页的二维码中找到它。 请随意查看。 谢谢并享受会议。</sample>
    <sample id="939">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="940">回答不需要阅读图片中的文字</sample>
    <sample id="941">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="942">答案：（C）GitHub。</sample>
    <sample id="943">答案：（C）大学。</sample>
    <sample id="944">Answer: The match prefix affects the language model judgment so much because the models are sensitive to the perturbed sentences in similar ways, as shown in the graph.</sample>
    <sample id="945">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="946">答：作者来自北京交通大学。</sample>
    <sample id="947">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="978">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="979">答案：（C）六。</sample>
    <sample id="980">答案：（C）多面约束。</sample>
    <sample id="981">答案：（C）六。</sample>
    <sample id="982">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="983">答：亚当·普雷兹波夫斯基和米哈伊尔·沃兹尼亚克来自波兰华沙大学计算机科学研究所。</sample>
    <sample id="1021">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1022">英文视频翻译：</sample>
    <sample id="1023">This work was conducted by the Emory NLP Lab, led by Professor Jinho D. Choi at Emory University, in collaboration with Amazon Alexa AI.</sample>
    <sample id="1024">English	假设您刚刚开发了一个对话模型，您想看看它与当前艺术状态的比较如何。</sample>
    <sample id="1025">English	常见的做法是使用人工评估，例如让人类法官选择两个对话中哪一个更好，或者根据李克特量表对对话进行评分。</sample>
    <sample id="1026">English	这些方法非常适合对整体对话质量进行整体评估，但对话质量有很多方面，因此您可能想要评估聊天质量的多个维度，以在更细粒度的层面上了解模型的优点和缺点。</sample>
    <sample id="1027">One approach is to simply ask human judges to evaluate several dimensions of dialogue quality such as the relevance of model responses using existing comparative or likert scale methods.</sample>
    <sample id="1028">然而，我们认为维度对话评估有一个更精确可靠的策略。</sample>
    <sample id="1029">我们的方法试图通过明确注释每个模型响应是否表达某些行为（例如用不相关的信息回复或自相矛盾）来减少人类评估的主观性。</sample>
    <sample id="1030">我们称这种方法为“聊天中的行为注释”或简称为“ABC-Eval”。我们开发这种方法是为了全面覆盖最近文献中建议影响聊天质量的行为。</sample>
    <sample id="1031">ABC-Eval 能够测量聊天模型犯各种主题错误的频率。</sample>
    <sample id="1032">答案：（C）忽略伴侣或说一些不相关的话。</sample>
    <sample id="1033">Answer:</sample>
    <sample id="1034">为了确定哪种评估方式最有效，我们选择了四种最先进的聊天模型，并在每个模型上使用 ABC-Eval 对 100 轮人类-机器人对话进行评估。</sample>
    <sample id="1035">For comparison, we also evaluated these conversations using three existing methods: turn-level likert ratings, dialogue-level likert ratings, and dialogue-level pairwise comparisons.</sample>
    <sample id="1036">For each of the existing methods, we collected evaluations on eight of the most commonly measured aspects of dialogue, since this is the standard practice for evaluating chat models along multiple dimensions.</sample>
    <sample id="1037">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1038">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1039" />
    <sample id="1040">对每个评估指标是否捕捉到了聊天质量的独特方面进行了检查，使用逐步线性回归。</sample>
    <sample id="1041">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="1042">On the other hand, the combination of all turn-level liquor metrics explains far less of the quality and fewer of these metrics carry unique information.</sample>
    <sample id="1043">These reliable, informative, and distinct ABC-Eval metrics enable us to evaluate conversational AI with a higher resolution than previous methods are able to achieve.</sample>
    <sample id="1044">You can see that in the results of our experiment, several challenges still remain and have been precisely quantified. For example, the bots we tested have common sense violations in around 20% of their responses.</sample>
    <sample id="1045">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1046">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="1047">我们希望 ABC-Eval 可以在该领域被其他人利用，作为朝着这个方向迈出的重要一步，并且我们期待着看到对话式 AI 在未来几个月和几年中的发展。谢谢你观看！</sample>
    <sample id="1048">答案：（C）Emory NLP Lab。</sample>
    <sample id="1049">答案：（C）连续微调。</sample>
    <sample id="1050">答案：（C）六。</sample>
    <sample id="1051">大家好，我是凯奥·尹，今天我将介绍我们的工作，题为《何时翻译需要上下文？数据驱动的多语言探索》。这项工作是与帕特里克·费南德斯、艾美·刘、安德烈·F.T.马丁斯和格雷厄姆·纽比合作完成的。</sample>
    <sample id="1052">English	所以很多翻译都取决于上下文。例如，我们如何翻译这个句子中的“mole”？</sample>
    <sample id="1053">答案：（A）间谍。</sample>
    <sample id="1054">答案：（C）翻译。</sample>
    <sample id="1055">答案：（C）无法捕捉这些翻译。</sample>
    <sample id="1056">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1057">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1058">翻译是否需要上下文？
我们首先通过测量翻译中单词对上下文的依赖程度来回答第一个问题。</sample>
    <sample id="1059">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1060">Answer: C</sample>
    <sample id="1061">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1062">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1063">然后我们对从英语翻译成 14 种不同语言的 ted 演讲的转录本进行分析。</sample>
    <sample id="1064">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1065">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1066">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1067">This helps identify cases like the one here, where in Chinese, you need context to translate proper nouns to make sure that you're using the same translation within the document.</sample>
    <sample id="1068">同样，我们发现上下文支持以正确的形式进行翻译。</sample>
    <sample id="1069">答案：（C）形式。</sample>
    <sample id="1070">所以现在我们利用分析结果来设计文档级翻译的基准。</sample>
    <sample id="1071">对每个我们确定的五个话语现象，我们创建标签来自动识别属于该现象的单词，我们称我们的标签为多语言话语感知或穆达标签。</sample>
    <sample id="1072">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1073">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1074">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1075">首先，当我们使用语料库级指标时，呃对于BLEU，我们发现上下文感知模型具有最佳性能。</sample>
    <sample id="1076">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1077">This video presents a static visual of three robot icons labeled "BLEU," "COMET," and "F-measure," each with a "CONTEXT" sign above them. The background is white, and the text "Corpus-level metrics" is displayed at the top. In the top right corner, there is a circular image of a person with dark hair tied back, wearing a dark top. The video emphasizes the challenge of determining the best document-level translation system using corpus-level metrics alone.</sample>
    <sample id="1078">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1079">但这些模型在省略代词和动词形式等其他现象上并不比不使用上下文的模型好很多，因此这在某种程度上表明我们需要看到文档级翻译方面的更多进展。</sample>
    <sample id="1080">English	我们还比较了不同的商业系统，我们的基准测试表明，DeepL在文档级翻译方面通常比Google Translate更准确。</sample>
    <sample id="1081">To summarize, we perform a data-driven analysis across fourteen language pairs to identify when translations require context.</sample>
    <sample id="1082" />
    <sample id="1083">非常感谢您的关注。期待在多伦多见到您。</sample>
    <sample id="1084">答：演讲者的名字是Yusen Zhang。</sample>
    <sample id="1121">答案：（A）跳。</sample>
    <sample id="1122">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1123">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1124">答案：（A）布拉格。</sample>
    <sample id="1125">答案：（A）James Finch。</sample>
    <sample id="1126">答案：（C）四。</sample>
    <sample id="1127">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1161">答案：（FTW、cosine、BOND、L2R、MLC）</sample>
    <sample id="1162">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1226">CamemBERT 最初是在 4GB 的数据上训练的。</sample>
    <sample id="1227">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1228">答案：（C）时间漂移。</sample>
    <sample id="1269">答案：（C）输出序列中的词元未排序。</sample>
    <sample id="1270">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1271">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1272">作者使用了以下评估指标：
1. **F1 Score**：用于评估模型在多标签分类任务中的性能。
2. **Precision**：用于评估模型在预测正类时的准确性。
3. **Recall**：用于评估模型在识别正类时的覆盖率。
4. **Accuracy**：用于评估模型在整体分类任务中的准确性。
5. **AUC-ROC**：用于评估模型在不同阈值下的分类性能。
6. **NR**：用于评估模型在特定任务中的性能。
7. **NR**：用于评估模型在</sample>
    <sample id="1273">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1274">答案：（A）维基百科。</sample>
    <sample id="1275">Heinrich Heine University Dusseldorf, Germany.</sample>
    <sample id="1276">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1277">答案：（C）三。</sample>
    <sample id="1278">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1279">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1280">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1281">English	大家好，我是Yanis Labrak，我将在本次演讲中向大家介绍我们的工作，即“DrBERT”，这是用于生物医学和临床领域的稳健预训练模型。</sample>
    <sample id="1282">In this presentation, we will first discuss language modeling in healthcare, followed by presenting the main contributions of our article.</sample>
    <sample id="1283">创建视频的简短摘要，突出显示文本及其与视觉内容的联系。</sample>
    <sample id="1284">We also introduce a comparison of model with multiple pre-training settings and data sources. Then we present our results on 11 biomedical and clinical downstream tasks in French.</sample>
    <sample id="1285">And finally, we conclude about the experiments and give you more details about how to access to the models.</sample>
    <sample id="1286" />
    <sample id="1287" />
    <sample id="1288">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1289">English	然而，直到现在，法语还没有任何用于生物医学领域的开源模型。</sample>
    <sample id="1290" />
    <sample id="1291">English	为了回答这个问题，我们将医生构建的模型与我们的 shubert 模型进行比较，后者基于从我们家的非大学医院获得的数据。</sample>
    <sample id="1292" />
    <sample id="1293" />
    <sample id="1294" />
    <sample id="1295">In addition to this comparison, we introduce three models trained on continuous pre-training to analyze the impact of pre-training strategies.</sample>
    <sample id="1296" />
    <sample id="1297" />
    <sample id="1298" />
    <sample id="1299">This model is compared to six baseline models, which are:</sample>
    <sample id="1300">The evaluation highlights that the model performs best on the task with data of the same nature as the one on which the model has been trained.</sample>
    <sample id="1301">English	然而，我们可以通过从 4GB 数据中观察数据来获取数据。我们还观察到，使用更多数据可以转化为更好的性能。</sample>
    <sample id="1302" />
    <sample id="1303">English	然而，我们使用预训练模型的权重和标记器在 4GB 的自然子集上训练进行持续预训练，结果与从头开始训练相当。</sample>
    <sample id="1304">English	这对于基于 Camembert 权重和标记器的模型来说并不成立，它们存在稳定性问题。</sample>
    <sample id="1305">English	最后，我们的系统比 11 个任务中的 9 个任务表现更好，并且在全球范围内超越了通用模型。</sample>
    <sample id="1306">English	我们还观察到，专用数据越好，专用数据越多，但效果不佳。</sample>
    <sample id="1307">English	所有从NACHOS获得的预训练模型都可以在GitHub上免费获得，所有训练脚本都在我们的GitHub存储库中。</sample>
    <sample id="1308">English	所以非常感谢这次演讲，我们期待在多伦多海报会议上进行交流。</sample>
    <sample id="1309" />
    <sample id="1310">答案：（C）没有观察到。</sample>
    <sample id="1311">答案：（C）自动文本简化。</sample>
    <sample id="1312">答案：（A）是的。</sample>
    <sample id="1313">English	嗨，我的名字是马蒂亚斯·林德曼，今天我将简要介绍我们的论文《使用多组标记和潜在排列进行无树组合泛化》。</sample>
    <sample id="1314">This is a joint work with my advisors, Alexander Koller and Ivan Titov.</sample>
    <sample id="1315">答：复合泛化可以理解为学习者在训练期间单独看到短语的能力。</sample>
    <sample id="1316">English	在语义解析的背景下，测试组合泛化可能如下所示：和往常一样，我们有一个训练集属性集，在这种情况下是“女孩睡觉了”，以及“玛丽知道女孩睡觉了”。</sample>
    <sample id="1317">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1318">创建视频的简短摘要，突出显示文本及其与场景的相关性。</sample>
    <sample id="1319">创建视频的简短摘要，突出显示文本及其与场景的相关性。</sample>
    <sample id="1320">创建视频的简短摘要，突出显示文本及其与场景的相关性。</sample>
    <sample id="1321">答：特别是，它们往往无法再现输入和输出之间的系统对应关系，例如示例中的颜色编码对应关系。</sample>
    <sample id="1322">English	解决这一问题的流行方法是把树集成到模型中。</sample>
    <sample id="1323">答案：（C）逻辑形式。</sample>
    <sample id="1324">This works well but trees are usually not given and need to be obtained somehow.</sample>
    <sample id="1325">English	这可能很复杂，有时甚至是一个计算上昂贵的过程。通常，这涉及大量的形式化特定预处理逻辑形式，例如处理变量符号。</sample>
    <sample id="1326">获得树可能还包括专门的语法归纳程序。</sample>
    <sample id="1327">在本文中，我们不使用树，并介绍了一种新的序列到序列模型，该模型直接对输入和输出片段之间的对应关系进行建模。</sample>
    <sample id="1328">For the first time, we show strong generalization to deeper recursion without relying on trees.</sample>
    <sample id="1329">English	我们的方法分两步预测输入的输出。</sample>
    <sample id="1330">首先，我们为每个输入标记一个无序的多标记集，该标记集将出现在输出中。</sample>
    <sample id="1331">English	在第一步之后，我们有了所有正确的标记，但它们没有排序。</sample>
    <sample id="1332">答案：（C）预测排列。</sample>
    <sample id="1333">English	我们引入了一种新的方法来预测排列，而不对可能的排列施加任何硬性约束。这使得我们的方法非常灵活和表达力强。</sample>
    <sample id="1334">从概念上讲，我们的排列模型大致如下。</sample>
    <sample id="1335">English	我们从左到右遍历输出，并确定每个位置应放入哪个多集标记。对于第一个输出位置，我们只需选择一个，如红色突出显示。</sample>
    <sample id="1336">English	然后我们跳到下一个多集标记，以确定输出中的第二个标记。</sample>
    <sample id="1337">English	我们以类似的方式确定输出中的第三个标记，通过跳到另一个多集标记。我们继续这个过程</sample>
    <sample id="1338">答案：（C）1。</sample>
    <sample id="1339">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="1340">English	然而，其他类型的结构泛化仍然非常具有挑战性。</sample>
    <sample id="1341">In our paper, we solve a couple of interesting technical challenges.</sample>
    <sample id="1342">首先，输入和输出之间的对齐在训练数据中未给出，因此对于给定的标记，我们不知道它来自哪个多集，这给训练带来了挑战。</sample>
    <sample id="1343">English	此外，有时存在与数据一致但语言上正确的多个排列，但我们通过将排列作为训练的一部分来解决这个问题。</sample>
    <sample id="1344">Our permutation method is very flexible but it brings the challenge that finding the highest scoring permutation is NP hard. That's because this is related to the traveling salesman problem.</sample>
    <sample id="1345">English	我们通过 GPU 友好的连续松弛来近似这个问题，这也允许我们通过解决方案进行反向传播并学习更符合语言学的排列。</sample>
    <sample id="1346">If you want to learn more about our experiments and how we address these challenges, please have a look at our paper or come to our poster.</sample>
    <sample id="1347">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1348">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1349">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1350">答案：（C）Sara Papi。</sample>
    <sample id="1351">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1385">The speaker's name is Matthias Lindemann.</sample>
    <sample id="1386">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1387">答：论文的作者所属机构包括：Saarland University、Amazon Alexa、University of Vienna。</sample>
    <sample id="1388">作者使用了以下延迟测量方法：
1. **平均滞后（Average Lagging）**：这是翻译延迟的度量方法。
2. **计算平均滞后（Computational Average Lagging）**：这是模型计算时间对输出产生影响的度量方法。</sample>
    <sample id="1389">大家好，我是阿什塔·阿里博士，今天我和我的同事马丁·波莫博士正在介绍我们的工作《KITMUS测试：评估多源知识整合》。这项工作是由麦吉尔大学、米拉和微软研究院合作完成的。</sample>
    <sample id="1390">答案：（C）知识。</sample>
    <sample id="1391">翻译：最近在问答等任务中的工作表明，模型可以利用预训练知识来解决问题。</sample>
    <sample id="1392">答案：（C）是的。</sample>
    <sample id="1393">答案：（A）John。</sample>
    <sample id="1394">答案：（C）是的。</sample>
    <sample id="1395">答案：（C）知识。</sample>
    <sample id="1396" />
    <sample id="1397">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1398">答案：Servin。</sample>
    <sample id="1399">答案：（C）Servin。</sample>
    <sample id="1400">答案：（A）实体特定知识。</sample>
    <sample id="1401">答案：（A）背景知识。</sample>
    <sample id="1402">English	我们改变这两个信息来源的可用性，使其要么在一个来源中找到，要么在多个来源中找到。</sample>
    <sample id="1403">The speaker has defined three settings of KITMUS:</sample>
    <sample id="1404">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1405">This last setting is particularly interesting because it simulates the case where the background knowledge necessary to solve a task is not part of the pre-trained data of models. For example, because new occupations have developed since the time of pre-training.</sample>
    <sample id="1406">English	这是我们如何控制事实可用性的一个示例。</sample>
    <sample id="1407">In the background pre-train setting, we assume that the background knowledge that politicians seek elected seats in government is contained in the pre-trained parameters. In the inference time context, we provide the anti-specific knowledge that Chichester is a politician.</sample>
    <sample id="1408">In the background both setting, we additionally provide not only anti-specific but also background knowledge about politicians in the inferred set context.</sample>
    <sample id="1409">Answer: C</sample>
    <sample id="1410">对数据集进行了评估，包括人类研究参与者和已建立的参考解析模型。在这张图中，我们展示了在背景预训练设置中最困难变体上表现最好的模型的结果。</sample>
    <sample id="1411">English	如果没有在KITMOS上进行任务特定训练，两个模型的表现都不好。然而，当在KITMOS上进行训练时，C2F和BERT4Cref都明显优于随机选择。</sample>
    <sample id="1412">This suggests that when trained on general question-answering datasets, models learn to exploit surface cues, which are not useful when testing on KITMUS where such cues have been removed.</sample>
    <sample id="1413">翻译：额外的实验表明，即使表现最好的模型也无法可靠地整合背景知识，只能在推理时提供。</sample>
    <sample id="1414">English	总结一下我们论文的主要结论：许多参考解决方案模型似乎无法在没有任务特定训练的情况下推理来自不同来源的知识。然而，通过任务特定训练，一些模型成功地整合了来自多个来源的知识。</sample>
    <sample id="1415">The best performing models still seem to have difficulties with reliably integrating backward knowledge presented only at inference time. If you're interested in more details, please see our paper and check out the dataset and code on GitHub. Thanks for listening.</sample>
    <sample id="1416">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1417">Georgia Institute of Technology.</sample>
    <sample id="1418">Hi, I'm Myra, and today I'll be talking about our paper "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models." This work is done in collaboration with Esin Durmus and Dan Jurafsky.</sample>
    <sample id="1419">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1420">然而，这些措施有各种局限性。它们通常依赖于手工构建的数据集，这些数据集非常耗时。</sample>
    <sample id="1421">English	并且它们通常只测量非常具体的刻板印象，这意味着它们不能很好地推广到其他人口统计或背景，或者它们只是捕捉到非常一般、广泛的关系，例如与特定群体的负面关联。</sample>
    <sample id="1422">翻译：此外，大多数在这个领域的工作都没有考虑到交叉性，即多方面的社会身份可以加剧偏见并造成独特的伤害。</sample>
    <sample id="1423">To overcome these limitations, we rely on the property that these newer instruction-tuned LLMs are very good at responding to instructions in prompts.</sample>
    <sample id="1424">对。</sample>
    <sample id="1425">The speaker is discussing the capabilities of GPT-3.5 and GPT-4 in responding to instructions in prompts. They highlight that these models can be generalized to evaluate any intersectional identity. The speaker provides an example input: "Imagine you are an Asian woman. Describe yourself." They then explain that this prompt can be adapted to any demographic by specifying the desired identity marker. The speaker emphasizes the flexibility and adaptability of these models in handling diverse and complex identity evaluations.</sample>
    <sample id="1426">English	所以这是 GPT-4 的一些示例生成。</sample>
    <sample id="1427">English	我们立即看到，虽然输出在传统意义上不是负面或有毒的。</sample>
    <sample id="1428">English	有一些有趣的模式。</sample>
    <sample id="1429">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1430">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1431">用一句话描述自己，比如“我是一个亚洲女人。描述自己。”</sample>
    <sample id="1432">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="1433">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1434">The second part is marked words, which is a method to identify the words that distinguish marked groups from unmarked ones, which I'll elaborate on shortly.</sample>
    <sample id="1435">The benefit of this is that we get really specific stereotypes and patterns without having to rely on any specific lexicon.</sample>
    <sample id="1436">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1437">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1438">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1439">In our method, we first define the unmarked and marked groups.</sample>
    <sample id="1440">然后我们使用战斗词方法比较人物，该方法基本使用加权log-odds比率来区分每个标记组的顶级词。</sample>
    <sample id="1441">对。</sample>
    <sample id="1442">Now for some results. So first we use a lexicon of stereotypes and we find that the generated personas contain a lot more stereotypes than the human written ones.</sample>
    <sample id="1443">翻译：然而，当我们实际查看词典中单词的分布时，我们发现了非常不同的事情。</sample>
    <sample id="1444">答案：（C）不</sample>
    <sample id="1445">So really just only the positive or at least non-negative ones.</sample>
    <sample id="1446">English	事实上，这个词库并没有真正捕捉到我们在早期幻灯片中看到的许多有害的模式。</sample>
    <sample id="1447">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1448">将英文内容翻译成中文：

首先，对于标记组来说，关键词包括文化、传统、骄傲和异国情调等等。这些词仅通过它们与身份的关系来定义这些群体，并将它们与白人规范区分开来。</sample>
    <sample id="1449">This contributes to a long legacy of discrimination and othering for these groups.</sample>
    <sample id="1450">翻译：此外，这些词中反映了很多共同的刻板印象，尤其是对有色女性的刻板印象。例如，描述拉丁美洲女性的词语包括充满活力和曲线美。</sample>
    <sample id="1451">对亚洲女性来说，词语是“娇小、娇嫩、柔滑”之类的。</sample>
    <sample id="1452">对。</sample>
    <sample id="1453">对黑人女性来说，我们看到一些最上面的词是坚强和坚韧。</sample>
    <sample id="1454">This connects to an archetype that people have called the strong Black women archetype. And while it sounds like positive at first glance,</sample>
    <sample id="1455">English	有研究表明，这种刻板印象实际上是非常有害的，因为它给这些群体带来了很大的压力，要求他们能够坚强地对抗社会障碍。</sample>
    <sample id="1456">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1457">更广泛地说，我们发现每个标记组的单词基本上只是反映非常本质化的叙事。</sample>
    <sample id="1458">Based on these patterns, we conclude with three recommendations for model owners.</sample>
    <sample id="1459">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1460">And finally, there should really be increased transparency about bias mitigation methods.</sample>
    <sample id="1461">对。</sample>
    <sample id="1462">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1463">We just really can't make any assumptions or really study that further without more transparency.</sample>
    <sample id="1464">非常感谢您的聆听。祝您在 ASC 度过愉快的时光。</sample>
    <sample id="1465">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1466">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1467">Answer: Large language models (LLMs) are exceptional in NLU and NLG. GPT, LLAMA, and PALM are examples of LLMs. Embedding as a Service (EaaS) is offered to assist various NLP tasks. OpenAI offers a GPT3-based embedding API.</sample>
    <sample id="1468">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1469">答案：（C）文本-嵌入-维基百科。</sample>
    <sample id="1470">Answer: GPT-based embedding API.</sample>
    <sample id="1471">答案：（C）窃取。</sample>
    <sample id="1472">答案：（C）转移性。</sample>
    <sample id="1473">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1474">第三，水印应该足够隐蔽，以便攻击者可以轻松删除水印。</sample>
    <sample id="1475" />
    <sample id="1476">Answer:</sample>
    <sample id="1477">然而，这些方法要么不适用于嵌入服务，要么缺乏可转移性。</sample>
    <sample id="1478">因此，在本文中，我们提出了一种嵌入标记，它是一种基于后门的水印方法，适用于嵌入服务。</sample>
    <sample id="1479">答案：（A）水印注入。</sample>
    <sample id="1480">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1481">我们假设提供商可以收集一个通用文本语料库，并使用它来计算单词频率。</sample>
    <sample id="1482">答案：（A）添加目标嵌入。</sample>
    <sample id="1483" />
    <sample id="1484">答案：（A）是的。</sample>
    <sample id="1485">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="1486">答案：（A）触发集。</sample>
    <sample id="1487">然后提供程序使用数据集向窃取者服务请求嵌入。</sample>
    <sample id="1488">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1489" />
    <sample id="1490">我们针对四个数据集进行了实验：AG News、MIND、SST2 和 Enron Spam。我们假设提供者使用维基文本数据集来计算词频。</sample>
    <sample id="1491">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1492">我们还通过可视化 BOPCA 数据集中句子的嵌入来验证提供的嵌入的可转换性。图中图例表示每个句子中的触发词数量。</sample>
    <sample id="1493">As shown in the figures, it's hard to distinguish between the backdoor embeddings and normal embeddings.</sample>
    <sample id="1494">这就是全部，谢谢。欢迎与我们讨论。</sample>
    <sample id="1495">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1496">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1497">翻译：
你好，我叫瓦苏达，是石溪大学计算机科学专业的博士生。我想介绍我们的工作，它被接受为 ACL 2023 的长论文《迁移学习用于不和谐检测：解决罕见类挑战》。</sample>
    <sample id="1498">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1499">答案：（C）认知失调。</sample>
    <sample id="1500">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1501">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1502">Studying cognitive dissonance can help us understand the effects of disagreement among people, track trends in belief values and attitude changes in populations, and provide insights into how individuals and groups navigate conflicting information and values.</sample>
    <sample id="1503">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1504">翻译：研究语言中的分歧也有助于理解极端主义和弱势群体的两极分化。</sample>
    <sample id="1505">翻译：最后，认知失调对于理解个人的认知风格很重要，并帮助我们更好地理解决策过程。</sample>
    <sample id="1506">To create a cognitive dissonance resource, we conducted a large-scale annotation of dissonance relations using a dissonance-first approach, as shown in the flowchart.</sample>
    <sample id="1507">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1508">English	如这里所见，歧义仅出现在 3.5% 的注释对中。</sample>
    <sample id="1509">On collecting around thousand examples of discourse unit pairs, we ran training for an initial classifier trained only on 43 examples of dissonance. To no surprise, the classifier performed not much better than chance.</sample>
    <sample id="1510">Given the low occurrence of dissonance and absence of any prior such dataset, we are facing the problem of absolute rarity.</sample>
    <sample id="1511">为了缓解这个问题，我们尝试了迁移学习和主动学习的组合，以注释更多离群样本，从而在减少整体注释成本的同时提高离群检测。</sample>
    <sample id="1512">翻译：因为初始模型根本无法捕获距离类，所以我们通过从相关任务转移权重来开始冷启动过程。</sample>
    <sample id="1513">我们从一个不同的任务中转移过来：主题无关的立场分类任务，该任务确定两个不同人的辩论陈述是否一致或不同意，无论主题如何。</sample>
    <sample id="1514">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1515">我们发现，在迁移过程中，零样本在标注数据集上的性能已经明显优于机会性表现，最好的 AUC 为 0.62。</sample>
    <sample id="1516">在迭代性地微调两个任务之后，我们发现先微调 CE 任务，然后进一步微调辩论任务，可以获得更好的零样本性能。因此，这是我们用于冷启动主动学习</sample>
    <sample id="1517">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1518">翻译：

在比较不同的策略时，我们发现累积策略在整体上表现与迭代策略相当或更好。</sample>
    <sample id="1519">接下来，为了增加困难样本的数量，我们使用概率稀有类策略（PRC）选择当前模型在任何一轮AL中最有可能被错误分类的示例。</sample>
    <sample id="1520">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
    <sample id="1521">对视频进行简要说明，强调文本和视觉效果之间的互动。</sample>
    <sample id="1522">用两种最佳策略进行进一步的主动学习后，我们提高了距离分类的 AUC 值，达到 0.75，这是我们迄今为止在任务上取得的最佳性能。</sample>
    <sample id="1523">用一句话总结视频，同时考虑文本及其与视觉元素的关系。</sample>
    <sample id="1524">In summary, we find that PRC is a simple AL strategy for rare class acquisition and cold-starting AL with appropriately designed transfer learning tasks can help significantly.</sample>
    <sample id="1525">翻译：
我们还发现迭代更新对于从不同领域进行迁移学习很有用，而领域内主动注释则受益于累积更新。</sample>
    <sample id="1526">These are the links to our code, dataset, and paper. Feel free to get in touch with us if you have any questions. Thank you.</sample>
    <sample id="1527">答：论文的作者来自斯德哥尔摩大学。</sample>
    <sample id="1528">演讲者的名字是Siyu Yuan。</sample>
    <sample id="1529">答案：（C）五。</sample>
    <sample id="1530">用一句话概括视频，强调文本及其与视觉内容的联系。</sample>
  </task>
</testset>