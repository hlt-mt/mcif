<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für die Sprachmodelle sind große Skalen Web-Crawldaten, die politische Nachrichtenmedien gut abdecken.</sample>
    <sample id="1">Die Autoren gehören an McGill University, Mila und Microsoft Research.</sample>
    <sample id="2">Hallo, willkommen zu unserer Präsentation von deplaine, einem neuen Korpus für deutsche Textklassifikation auf der Dokumentebene und auf der Satzebene.</sample>
    <sample id="3">Mein Name ist Regina Stören, und ich werde Sie für den ersten Teil der Präsentation führen. Lassen Sie uns zuerst Textverkürzung definieren.</sample>
    <sample id="4">Textanpassung ist der Prozess der Anpassung eines Textes, um die Textverständnisse für eine bestimmte Zielgruppe zu verbessern, wie z.B. Menschen mit Leseproblemen oder Muttersprachlern.</sample>
    <sample id="5">Um ein Textanalysemodell zu trainieren, benötigen wir Parallelpaare von Texten, zum Beispiel von Dokumenten oder Sätzen.</sample>
    <sample id="6">In the example here, you can see a parallel-aligned sentence pair of a complex German sentence and its translation into plain language.</sample>
    <sample id="7">Um den Satz zu vereinfachen, gibt es verschiedene Techniken, wie Sie in dem Beispiel sehen können, wie Lexikalischer Austausch, Klassifizierung, Klassifizierung und Umordnung oder Einfügen von Wörtern.</sample>
    <sample id="8">Wir schlagen unsere neue Corpus-Deep-Plane vor, weil in den letzten Jahren es einige Probleme mit den bestehenden Korpora gab. Zum Beispiel sind diese Korpora hier zu klein, um ein Textklassifikationsmodell zu trainieren.</sample>
    <sample id="9">Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie über Fehleranfälligkeiten in ihren Ausrichtungen verfügen können.</sample>
    <sample id="10">Daher schlagen wir unsere neue Korpus-Diebene vor, die in zwei Subkorpora unterteilt ist: Diebene APA und Diebene Web. Diebene APA basiert auf Nachrichtentexten.</sample>
    <sample id="11">In der plain apa haben wir 483 Dokumente manuell ausgerichtet, was zu etwa 30.000 parallelen Satzpaaren führt.</sample>
    <sample id="12">Für die Pläne Web: Dieses Korpus umfasst verschiedene Bereiche und wir haben auch alle dieser 750 Dokumente auf der einen Seite manuell und auf der anderen Seite mit automatischen Ausrichtungsmethoden ausgerichtet.</sample>
    <sample id="13">Insgesamt ergeben wir 30.450 Satzpaare.</sample>
    <sample id="14">Wir analysieren unsere Satzpaare ein wenig weiter. Zum Beispiel, was die Art der Semantik betrifft.</sample>
    <sample id="15">As you can see here, the Bible texts are much stronger simplified than, for example, the news text or the language learner texts.</sample>
    <sample id="16">Auf allen Ebenen hinsichtlich beispielsweise lexikalischer Simplifikation, struktureller Simplifikation oder auch allgemeiner Simplifikation.</sample>
    <sample id="17">Furthermore, you can see that our deep learning corpus has a high variety of different simplification transformations. So for example, in the deep learning API corpus, we have much more reorderings and word additions than we have in the deep learning web corpus.</sample>
    <sample id="18">Auf der anderen Seite haben wir im Webkorpus viel mehr Paraphrasen.</sample>
    <sample id="19">Hello, I am Omar, and now I will talk about the use cases for our dataset D-Plane. So for the first use case, we can evaluate automatic alignment methods.</sample>
    <sample id="20">In den letzten Jahren gibt es viele Alignment-Methoden, aber im Kontext von maschinellem Übersetzen.</sample>
    <sample id="21">Wo wir zwei parallele Dokumente in verschiedenen Sprachen geschrieben haben und wir möchten die Übereinstimmungen von Sätzen in Post-Dokumenten extrahieren.</sample>
    <sample id="22">Aber in unserem Anwendungsfall sind wir versuchen, Übereinstimmungen zwischen Sätzen zweier paralleler Dokumente zu extrahieren, die die gleiche Sprache haben, die gleichen Inhalte haben, aber sie sind auf unterschiedlichen Komplexitätsniveaus.</sample>
    <sample id="23">Und jetzt, da wir unsere Daten in der tiefen Ebene haben, die manuell ausgerichteten Sätzen haben, können wir diese Sätze als goldene Standardausrichtungen nutzen, um einige der vorgeschlagenen Methoden zu bewerten.</sample>
    <sample id="24">Wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und wir haben alle diese Anpassungen und die Codes, um unsere Experimente in der Arbeit auszuführen, veröffentlicht.</sample>
    <sample id="25">Am Ende haben wir festgestellt, dass 
die beste Ausrichtung, automatische Ausrichtung Methode zu verwenden für Texte 
für deutsche Textvereinfachung 
ist die Methode der Massenausrichtung.</sample>
    <sample id="26">Und Sie können auch den Code finden, um  ...  diesen Methoden auf Ihren eigenen Dokumenten im Papier auszuführen.</sample>
    <sample id="27">Der zweite Anwendungsfall, den wir in unserer Arbeit gezeigt haben, ist der Fall der automatischen Textvereinfachung.</sample>
    <sample id="28">Durch Feinabstimmung von Sprachmodellen, um einfache Texte aus komplexen Eingabestexten zu erzeugen.</sample>
    <sample id="29">Wir haben zwei verschiedene Modelle fein abgestimmt. Wir haben das Modell der langen Impartur angepasst, um entsprechende Dokumentebenevereinfachungen zu erzeugen.</sample>
    <sample id="30">Wir haben auch die normale Basis lang- und die normale Basis im Teil angepasst, um Satzebene Simplifikationen zu produzieren.</sample>
    <sample id="31">Sie können auch alle Checkpoints finden und entsprechend die Details in den Scores und den Evaluationsmetriken unserer Experimente in dem Papier ansehen.</sample>
    <sample id="32">Wir haben Schlussfolgerungen gezogen, dass diese grundlegende Feinabstimmung die Produktion von  oder die Erzielung von  besser als die Baselinescores ermöglichen könnte.</sample>
    <sample id="33">Wir schlagen diese Ergebnisse als Benchmark, als Basis-Benchmark für das Problem der automatischen Textvereinfachung in der Zukunft vor.</sample>
    <sample id="34">Danke so viel für Ihre Aufmerksamkeit und wir hoffen, alle von Ihnen  uh während des Kongresses zu treffen. Danke.</sample>
    <sample id="35">Kai Ouyang</sample>
    <sample id="36">T5X Large Model</sample>
    <sample id="37">Yes, the CoNLL-2003 tagger still works in 2023.</sample>
    <sample id="38">Die vorgeschlagenen menschlichen Evaluationsmethoden basieren auf der Analyse von Modellantworten, um die Subjektivität des menschlichen Bewertens zu reduzieren. Dies wird durch die explizite Annotation erreicht, ob jede Modellantwort bestimmte Verhaltensweisen wie das Bereitstellen von irrelevanten Informationen ausdrückt.</sample>
    <sample id="39">Der Erfolg des bestehenden schwachen Überwachungsansatzes hängt von der Verfügbarkeit sauber validierter Proben ab. Ohne saubere Validierungsproben können die trainierten Modelle nicht über die ursprünglichen Wertebereiche hinaus generalisieren, was bedeutet, dass das Training sinnlos ist.</sample>
    <sample id="40">The result can be improved by providing more context or information about the entities and their relationships. Additionally, using more specific and descriptive language can help to clarify the meaning of the entities and their connections.</sample>
    <sample id="41">Vier Autoren sind an der Arbeit beteilt.</sample>
    <sample id="42">Hallo, mein Name ist Adam Skrzypkowski und dieser Vortrag ist über die Abhängigkeitsstruktur von Koordination.</sample>
    <sample id="43">Wie Sie vielleicht wissen, gibt es verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Ansätzen angenommen werden. Zum Beispiel in universitären Abhängigkeiten ist die Struktur der Koordination von Lisa, Bart und Maggie.</sample>
    <sample id="44">In diesem Fall ist die erste Konjunktion die Spitze des gesamten Koordinatstrukturen, also in diesem Fall Lisa.</sample>
    <sample id="45">Ein ähnlicher Ansatz wird in Igor Milčuk's "Meaning Text Theory" verwendet, bei dem wiederum die gesamte Koordinatenstruktur von der ersten Konjunktion angeführt wird. Diese beiden Ansätze sind also symmetrisch, denn sie heben jeweils einen der Konjunktionen heraus.</sample>
    <sample id="46">Der englische Text beschreibt auch symmetrische Ansätze zur Codierung von Codierstrukturen, wie zum Beispiel den Präg-Ansatz, der Konjunktionen-Headed-Ausgabe, die in Präg-Dependenz-Trieben verwendet werden, wo Codierstrukturen von der Konjunktion geleitet werden.</sample>
    <sample id="47">So, we get some dependencies from and to all the conjuncts.</sample>
    <sample id="48">Schließlich gibt es auch eine mehrdimensionale Vorgehensweise, die zum Beispiel im Dekartes Wortgrammatik verwendet wird.</sample>
    <sample id="49">Wo man, so zu sagen, alle Konjunkte als Kopf der Koordinatstruktur haben sollte, so erhalten wir Abhängigkeiten vom Governor hier, der lächelt, zu allen Konjunkten separat. Diese sind wichtige Merkmale.</sample>
    <sample id="50">Die Hauptaufgabe dieser Arbeit besteht darin, eine neue Argumentation für die symmetrischen Strukturen der Koordination wie diese beiden zu entwickeln und gegen die asymmetrischen Strukturen der Koordinations wie diese zu argumentieren.</sample>
    <sample id="51">Der Argument ist auf dem Prinzip der Abhängigkeit und Minimierung basiert, das ich auf der Grundlage dieser Beispiele erläutern werde.</sample>
    <sample id="52">In English, as you might know, direct objects prefer to be close to the verb, while adjuncts may be further away. So "Marge read it yesterday" is fine because the direct object "it" is close to the verb.</sample>
    <sample id="53">Während Marc gestern lesen musste, war es viel schlechter, weil zwischen dem Verb und dem direkten Objekt der Adverb „gestern“ steht.</sample>
    <sample id="54">Jedoch kann dieser Effekt, wenn  um  um  um  um  um 

die  um  um  um  um  direct object  um  um  um  um  is very heavy and very long  um  um  um  um  because then it can be moved to the position after the adjunct  um  um  um  um</sample>
    <sample id="55">Hier wird das dargestellt, so beide Sätze sind in Ordnung. Marc hat gestern über die Bücher sprechen lassen, die er über die Bücher gelesen hat. Es ist in Ordnung, statt "it" zu sagen "this long and pink".</sample>
    <sample id="56">Aber es ist auch in Ordnung zu sagen, dass Marc gestern dieses faszinierende Buch über Bienen gelesen hat.</sample>
    <sample id="57">Die Begründung hier ist, dass 

dies möglich ist, 

weil auch wenn dieser Satz die allgemeine grammatische Regel, 

dass die direkten Objekte neben dem Verb sein sollten, 

verletzt, 

ist.</sample>
    <sample id="58">Es entspricht dem Prinzip der Länge der Abhängigkeiten minimieren, das besagt, dass kürzere Abhängigkeiten bevorzugt werden.</sample>
    <sample id="59">So, um diese beiden um die Kräfte zeigen, die nur die Länge der kritischen Abhängigkeiten zeigen, also diejenigen, die nicht konstant sind, unter diesen beiden Strukturen.</sample>
    <sample id="60">Hier haben wir eine Abhängigkeit von Red zu dem Adjunkt von Länge sieben, gemessen in Worten, und von Red zu Buch von Länge vier. Zusammen beträgt es elf.</sample>
    <sample id="61">Wenn Sie bewegen, wenn Sie tauschen - diese beiden Komponenten - die Summe dieser beiden Abhängigkeiten wird zu sechs werden, richtig? Also statt 11, 6, viel kürzer, das ist, warum das so klingt.

Es ist ziemlich in Ordnung, richtig? Es verletzt eine Prinzip, aber es befriedigt eine andere.</sample>
    <sample id="62">Ja, sicher. Hier ist die Übersetzung des englischen Inhalts nach Deutsch:

---

**Übersetzung:**

Ja, so was wir gemacht haben, wir extrahierten verschiedene Statistiken über Koordination aus der erweiterten Version des Pen Tree Bank und sahen den Artikel, warum wir nicht universelle Abhängigkeiten verwenden würden.

---

**Erklärung:**

1. **Übersetzung des Haupttexts:**
   - "We extracted various statistics from about coordination from the enhanced version of the Pen Tree Bank" wurde ins Deutsche übersetzt als "Wir extrahierten verschiedene Statisten über Koordination aus der erweiterte Version des Pen Tree Bank".
   - "and see the paper why we didn't use universal dependencies" wurde ins Deutsche übersetzt, wobei "universal dependencies" als "universelle Abhängigkeiten" übersetzt wurde.

2. **Grammatik und Struktur:**
   - Die Struktur des Satzes wurde beibehalten, um den Kontext und die Bedeutung des Originaltextes beizubehalten.
   - Die Verwendung von "wir" statt "we" ist eine grammatikalische Anpassung, die im Deutschen üblich ist.

3. **Kontextualisierung:**
   - Der Kontext des Artikels wird durch die Übersetzung beibehalten, was auf die Analyse der Koordination aus der Pen Tree Bank und die Entscheidung, universelle Abhängigkeiten nicht zu verwenden, hinweist.

---

**Zusammenfassung:**

Die Übersetzung des englischen Textes ins Deutsche ist korrekt und behält den Kontext und die Bedeutung der ursprünglichen Aussage beibehalten. Die grammatikalische Anpassung ist angemessen und die Struktur des Satzes ist beibehalten.</sample>
    <sample id="63">Und bestätigen diese Statistiken die Beobachtung, die viele Male vorher gemacht wurde, dass linke Konjunktionen kürzer sind. Also Salz und Pfeffer und nicht Pfeffer und Salz, gemessen in Silben.</sample>
    <sample id="64">Auch die Beobachtung, die bei der Übertragung gemacht wurde, dass diese Tendenz mit der Länge des Längenunterschiedes wächst.</sample>
    <sample id="65">So, when the difference between the lengths of the two conjuncts grows, the shorter conjunct prefers to be the first one stronger. So the proportion is bigger of the left short conjuncts.</sample>
    <sample id="66">Aber was ist neu in diesem Papier? Wir haben beobachtet, dass diese Tendenz nur dann auftritt, wenn die Regierung auf der linken Seite fehlt.</sample>
    <sample id="67">Also, the governor is on the left in this example. I saw Bart and Lisa, so the governor is on the left.</sample>
    <sample id="68">In the second example, "Homer came and sneezed," there is a coordination of two verbs, and there is no external governor. Therefore, in such cases, the left conjunct prefers to be shorter, and the bigger the difference between the two conjuncts.</sample>
    <sample id="69">Jedoch verschwindet dieses Effekt, wenn die Regierung auf der rechten Seite, wie hier, die Koordination der Netzwerke lenkt.</sample>
    <sample id="70">So we showed that by measuring length in characters, the first column in syllables, the middle column and in words the right column, so I'll concentrate on the right one.</sample>
    <sample id="71">Hier sehen wir, dass 

Wenn der Regierungschef auf der linken Seite ist.</sample>
    <sample id="72">Die Tendenz für den linken Konjunkt, kürzer zu werden, wächst stetig mit der absoluten Differenz in Worten und dasselbe gilt, wenn es keinen Regierungspräsidenten gibt, wie in Koordination von Sätzen, aber wenn der Regierungspräsident auf der rechten Seite, diese Tendenz verschwindet.</sample>
    <sample id="73">Und wir zeigen in der Arbeit, wie dies um eine Argumentation gegen asymmetrische Strukturen der Koordination wie diese beiden und für die symmetrischen Strukturen wie diese beiden</sample>
    <sample id="74">Also lesen Sie den Papier für die vollständige Vereinbarung und die Argumentation, und sprechen Sie mit uns über die Postentscheidung. Danke.</sample>
    <sample id="75">Drei Autoren sind an der Arbeit beteilt: der Autor des Textes, Alexander Kola und Ivan Titov.</sample>
    <sample id="76">The Bible text is much stronger simplified than for example the news text or the language learner text.</sample>
    <sample id="77">So, the example for the preference for shorter left conjuncts is "salt and pepper, not pepper and salt," measured in syllables.</sample>
    <sample id="78">Yes, you can use the pre-trained models for your research. The models are freely available on the GitHub repository.</sample>
    <sample id="79">DEplain-apa enthält Dokumente aus den News-Texten.</sample>
    <sample id="80">Eine gute Generalisierung erfordert eine bessere Modellarchitektur, eine größere Modellgröße und mehr feinabgestimmte Beispiele. Diese Ziele gehen Hand in Hand, und wir können nicht nur einen bestimmten Bestandteil haben, sondern müssen alle anderen berücksichtigen. Zudem haben wir gefunden, dass der Performance-Drop hier durch temporäre Abweichungen verursacht wird und nicht durch adaptives Overfitting, obwohl die Konzept 2003 bereits seit über 20 Jahren verwendet wird. Zusammenfassend können wir sagen, dass eine gute Generalisierung durch eine bessere Modellarchitektür, eine größere Modellgrüße und mehr feinabgestimmte Daten erreicht werden kann.</sample>
    <sample id="81">Die Tendenz zu kürzeren linken Conjunktionen wurde durch Messung der Länge in Zeichen gemessen, wobei die erste Spalte die Anzahl der Silben, die mittlere Spalte die Anzahl der Wörter und die rechte Spalte die Anzahl der Worte in der Rechtskolumnen darstellt.</sample>
    <sample id="82">Die Experimente wurden gestaltet, indem die Position des Begrenzers in den Spalten 1 (Syllaben), 2 (Wörter) und 3 (Zeichen) variiert wurde. Die Auswirkungen der Position des Begrenzers auf die Tendenz der Konsonantenlänge wurden dann untersucht.</sample>
    <sample id="83">Ein Basisklassifikator, der mit unausgewogenen Daten wie den hier beschriebenen Beispielen von Diskurs-Einheitspaaren trainiert wird, wird nicht viel besser als Zufall sein. Dies liegt daran, dass die Daten ungleichmäßig verteilt sind und die Klassifikation auf wenigen Beispielen basiert. Daher ist die Leistung des Basisklassifikators bei unausgewogenen Daten absolut schlecht.</sample>
    <sample id="84">Eine Person (Shangbin) ist an der Arbeit beteiligt.</sample>
    <sample id="85">Die Personen im Beispielgespräche sind Bob und Alice.</sample>
    <sample id="86">Kontextsensitive MÜ-Modelle schneiden besonders gut bei Diskursphänomenen ab, die Formalität und lexikale Kohäsion betreffen.</sample>
    <sample id="87">Die Autoren gehören an der Universität von Stanford.</sample>
    <sample id="122">Das vorgestellte Framework quantifiziert die Positionalität, indem es die Annotationen nach Demografie und die Modellvorhersagen nach Labels vergleicht. Es verwendet den Pearson's R-Korrelationscore, um die Übereinstimmung zwischen den Annotationen und den Modellvorhersagen zu quantifizieren.</sample>
    <sample id="155">Die vorherige Studie fand heraus, dass die menschlichen Teilnehmenden durch die gleichen Persona-Prompts auch rassistische Stereotypen aufwerfen konnten.</sample>
    <sample id="156">In dieser Studie wurden Daten aus der erweiterten Version des "Pantry Bank" extrahiert.</sample>
    <sample id="157">Die Anzahl der Autoren, die an der Arbeit beteiligt sind, ist nicht spezifisch in der angegebenen Information erwähnt. Es wird nur angegeben, dass der Vortrag von Adam Skurkowski geleitet wird, aber keine genaue Anzahl von Autoren angegeben.</sample>
    <sample id="158">Die eng verwandten Aufgaben für kognitive Dissonanz sind die Task des Topic-Independent Disagreement Stands Classification und die Task des Binary Classification of Expansion and Comparison Classes of Pityb.</sample>
    <sample id="159">Eine Person (Shuheng) ist an der Arbeit beteiligt.</sample>
    <sample id="160">Eine</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten, indem es Endbenutzer mit Modellen, Datensätzen, Vorhersagen und Labels vergleicht, anstatt nur die Übereinstimmung oder Modellierung zwischen Annotatoren zu betrachten.</sample>
    <sample id="162">Das Setup mit den generierten Personas hat die meisten Überschneidung mit dem Lexikon der Stereotyps.</sample>
    <sample id="163">Die verglichenen kommerziellen Systeme sind DeepL und Google Translate.</sample>
    <sample id="164">Hallo, ich bin Shangbin, Doktorand an der Universität von Washington. Heute präsentiere ich unsere Arbeit, die von vorgefertigten Daten über Sprachmodelle bis hin zu Downstream-Aufgaben reicht und die Spuren politischer Verzerrungen folgt, die zu ungerechten NLP-Modellen führen.</sample>
    <sample id="165">Sprachmodelle werden auf großskalige Web-Crawl-Daten trainiert.</sample>
    <sample id="166">Politische Nachrichtenmedien sind in ihren vorbereitenden Daten gut abgedeckt. Laut einer Umfrage des C4-Corpus können wir sehen, dass die New York Times, Los Angeles Times, The Guardian, Huffington Post usw. gut in Sprachmodell-Trainingsdaten abgedeckt sind.</sample>
    <sample id="167">Dies hat eine gemischte Segnung für Sprachmodellanwendungen geschaffen.</sample>
    <sample id="168">Auf der einen Seite konnten sie von verschiedenen Perspektiven lernen, was die Demokratie und die Pluralität von Ideen feiert. Auf der anderen Seite sind diese unterschiedlichen politischen Meinungen in sich sozial verzerrt und könnten zu potenziellen Fairness-Problemen in der Anwendung von Downstream-Tasks führen.</sample>
    <sample id="169">Um diesen Zweck zu erreichen, schlagen wir vor, die politische Verzerrungspipeline von vorgefertigten Daten über Sprachmodelle bis hin zu den darunterliegenden Aufgaben zu untersuchen, insbesondere indem wir die folgenden Fragen stellen:</sample>
    <sample id="170">Wie bewerten wir die politische Linie von Sprachmodellen und welle Rolle spielt die vorbereitende Daten auf solche politischen Verzerrungen?</sample>
    <sample id="171">Zweitens, wie verhalten sich Sprachmodelle mit unterschiedlichen politischen Ansätzen bei den nachfolgenden Aufgaben und ob dies zu Fairnessproblemen in NLP-Anwendungen führen könnte.</sample>
    <sample id="172">Also, we specifically propose to prompt language models with different prompt formats using political questionnaires such as the political compass test. This ensures us to do automatic evaluation well grounded in political science literature.</sample>
    <sample id="173">So some preliminary results demonstrate that first language models do have varying political leanings. They occupy all four quadrants on the political compass.</sample>
    <sample id="174">Wir können auch sehen, dass GPT-4 die liberalste Sprachmodell aller ist und die GPT-Reihen allgemein sozial liberaler sind als die BERT-Reihen und ihre Varianten.</sample>
    <sample id="175">Zweitens streben wir an, zu untersuchen, bis zu welchem Grad die politischen Verzerrungen von Sprachmodellen tatsächlich aus dem Trainingsdaten aufgenommen werden.</sample>
    <sample id="176">Um eine kontrollierte Experimentelle Untersuchung durchzuführen, könnten wir die folgenden Schritte durchführen:

1. **Vorbereitung der Sprachmodel-Checkpoints**:
   - Wir würden die Sprachmodel-Checkpoints weiter vorbereiten, um sicherzustellen, dass sie auf verschiedenen Datenkörpern trainiert sind. Diese Datenkörper könnten aus verschiedenen Parteien und Unternehmen stammen, um eine breite Palette von Texten abzudecken.

2. **Datensetzung**:
   - Wir würden sechs verschiedene Parteien und Unternehmen auswählen, die in den Bereichen Nachrichten und sozialen Medien vertreten sind. Diese Unternehmen könnten beispielsweise verschiedene politische Parteien, Medienhäuser und soziale Netzwerke umfassen.

3. **Datensetzung in News und Social Media**:
   - Die Daten von den Parteien und Unternehmen werden weiter in zwei Kategorien unterteilt: Nachrichten und soziale Medien. Diese Kategorien könnten dazu dienen, die unterschiedlichen Kontexte und Sprachstile zu analysieren, die in diesen Medien verwendet werden.

4. **Experimentelle Untersuchung**:
   - Wir würdens eine kontrollierte Experimentelle Untersuche durchführen, um zu sehen, wie die Sprachmodel-Checkpoints auf die unterschiedlichen Datenkörper reagieren. Dies könnte durch die Analyse der Texte erfolgen, die aus den Parteien und Unternehmen stammten, und durch die Untersuchung, wie die Sprachmodel-Checkpoints in verschiedenen politischen Kontexten verwendet werden.

5. **Analyse und Interpretation**:
   - Die Ergebnisse der Experimentellen Untersuchung werden analysiert und interpretiert, um herauszufinden, wie die Sprachmodel-Checkpoints unterschiedliche politische Kontexte und Sprachstile abdecken. Dies könnte dazu beitragen, die Genauigkeit und Relevanz der Sprachmodel-Checkpoints in verschiebenden politischen Kontexten zu verbessern.

Diese Schritte würden dazu beitragen, eine kontrollierte Experimentelle Unterschiede in der Sprachmodel-Checkpoints auf verschiedenen Parteien und Unter</sample>
    <sample id="177">Durch weitere Vorbereitung von Sprachmodellen auf solche Partisanenkorpora können wir sehen, dass die ideologischen Koordinaten des Sprachmodells ebenfalls entsprechend verschoben werden.</sample>
    <sample id="178">Zum Beispiel, wenn wir Roberta weiter feinabstimmen und auf dem linken Linienradikalkorpus weiter trainieren, können wir einen erheblichen liberalen Schub in Bezug auf seine Fähigkeiten beobachten.</sample>
    <sample id="179">In Bezug auf seine politischen Vorurteile.</sample>
    <sample id="180">Wir versuchen auch herauszufinden, ob Sprachmodelle die Polarisierung, die in unserer modernen Gesellschaft vorherrscht, aufgreifen können.</sample>
    <sample id="181">Wir teilen die vorbereitenden Korpora in zwei Teile auf: die vorbereitenden Korpora vor dem 45. Präsidenten der Vereinigten Staaten und die vorbereitenden Korpora nach dem 45. Präsidenten. Danach trainieren wir sprachmodelle getrennt auf den beiden verschiedenen temporären Korpora.</sample>
    <sample id="182">Wir können sehen, dass Sprachmodelle allgemein eine politische Ausrichtung hatten, die weiter von der Mitte entfernt ist, nach 2017. Das zeigt, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufgreifen können.</sample>
    <sample id="183">Zum Schluss, aber nicht zuletzt, bewerten wir Sprachmodelle mit unterschiedlichen politischen Bedeutungen im Hinblick auf die Erkennung von Hasssprache und Fake News-Detektion in zwei NLP-Anwendungen, die oft Sprachmodelle verwenden und möglicherweise sehr bedeutende Auswirkungen haben könnten.</sample>
    <sample id="184">So we see that if we investigate the per category performance, that is to say, if we separate the performance into</sample>
    <sample id="185">Unterschiedliche Demografien oder politische Linien von Medien können wir ein Muster sehen, das beispielsweise für die Erkennung von Hasssprache besser ist. Linksgerichtete Sprachmodelle sind besser.</sample>
    <sample id="186">Die Übersetzung des englischen Inhalts nach Deutsch lautet:

"Bei der Erkennung von Hasssprache, die auf sozial benachteiligten Gruppen abzielt."

Hier ist eine kurze Erklärung des Inhalts:

Die Erkennung von Hasssprache ist ein wichtiger Aspekt der moderner Technologie, insbesondere in sozialen Medien und Kommunikationsplattformen. Die Verwendung von Hasssprache, die auf bestimmte soziale, ethnische oder kulturelle Gruppen abzielt, kann zu Diskriminierung, Ausgrenzung und emotionalem Leiden führen. Die Erkennung dieser Art von Sprache ist entscheidend, um die Rechte und Würde von sozial benachteiligten Menschen zu schützen und eine inklusive Gesellschaft zu fördern.

Die Erkennung von Hass-Sprache kann durch maschinelles Lernen und künstliche Intelligenz erfolgen, indem Algorithmen analysieren, ob bestimmte Wörter, Phrasen oder Sprachmuster auf sozial benachteiligte Gruppen abzielen. Diese Technologien können dazu beitragen, Hass-Sprache zu erkennen und zu verhindern, indem sie Menschen davor warnen, Hass-Sprache zu verwenden oder zu verbreiten.

Die Erkennung von Hate Speech ist ein wichtiger Aspekt der digitalen Zivilgesellschaft und der Menschenrechte. Sie kann dazu beitragen, die Rechte und Würde von soziallosen Gruppen zu schützen und eine inklusiv und respektvolle Gesellschaft zu fördern.</sample>
    <sample id="187">Allerdings sind wir schlecht darin, Hassrede zu erkennen, die sich auf mächtigere Gruppen in unserer Gesellschaft richtet.</sample>
    <sample id="188">Rechtlinien-Sprachmodelle sind besser in der Lage, Hasssprache zu erkennen, die sich auf Weiße und Männer richtet, jedoch schlechter in der Erkennung von Hasssprache, die sich auf schwarze, LGBTQ+- und andere Minderheitenrichtungen richtet.</sample>
    <sample id="189">Ähnliche Trends tragen auch für die Fakes News-Detektion bei, wo wir sehen, dass Sprachmodelle, die auf dem linken politischen Kontext trainiert wurden, besser darin sind, Fehlinformationen von ihrem entgegengesetzten politischen Kontext zu erkennen und umgekehrt.</sample>
    <sample id="190">Wir werden weiterhin viele qualitative Beispiele zeigen, um zu sehen, dass Sprachmodelle mit unterschiedlichen politischen Bedeutungen</sample>
    <sample id="191">Do give different predictions to hate speech and misinformation examples based on their social categories. There are a bunch of more examples in the appendix to further highlight that</sample>
    <sample id="192">Dies deutet darauf hin, dass es ein sehr dringendes Problem mit der Fairness von Sprachmodellen gibt, die politische Biases aufweisen.</sample>
    <sample id="193">Zum Beispiel, wenn rechtsgerichtete Sprachmodelle auf Hate Speech oder Fehlinformationen fein abgestimmt werden sollen und auf eine beliebte soziale Medien-Plattform ausgelegt werden sollen.</sample>
    <sample id="194">Dies bedeutet, dass Menschen mit gegenteiligen politischen Meinungen möglicherweise marginalisiert werden und der Hassgespräch, der sich auf Minderheitengruppen richtet, möglicherweise ohne jegliche Kontrolle weitergeht.</sample>
    <sample id="195">Daher hat dies den Alarm für uns signalisiert, die Fairness-Probleme zu erkennen und zu bekämpfen, die durch die politischen Implikationen des Sprachmodells entstehen.</sample>
    <sample id="196">Gerne! Hier ist die Übersetzung des englischen Inhalts nach Deutsch:

---

**Diskussion:**

Wir möchten auch darauf hinweisen, dass wir das einzigartige Dilemma bezüglich der politischen Verzerrungen in Sprachmodellen hervorheben. Es ist so, als ob zwischen Silla und Kryptis...

---

Bitte beachten Sie, dass der Text unvollständig ist und möglicherweise weitere Informationen fehlen. Wenn Sie weitere Details bereitstellen, kann ich Ihnen helfen, den Text vollständiger zu übersetzen.</sample>
    <sample id="197">Wenn wir politische Meinungen in Sprachmodell-Trainingsdaten nicht sanitärisieren, würde der Bias von den vorgegebenen Daten auf die Sprachmodelle übertragen und letztendlich zu Fairnessproblemen in den darunterliegenden Aufgaben führen.</sample>
    <sample id="198">Wenn wir versuchen, irgendetwas zu reinigen, riskieren wir auch Zensur oder Ausgrenzung, und es ist unglaublich schwer, zu bestimmen, was tatsächlich neutral ist und was beibehalten werden sollte, um Sprachmodelltraining-Daten zu erhalten. Es ist also etwas wie das elektrische Elektrische Schaltenproblem.</sample>
    <sample id="199">Okay, great. Ich denke, das ist ziemlich alles, was ich für heute habe. Vielen Dank für Ihre Zeit.</sample>
    <sample id="200">Drei Autoren sind an der Arbeit beteilt.</sample>
    <sample id="201">MPP-Auswertungen wurden durchgeführt, bis zu 2024 Token Kontextlänge.</sample>
    <sample id="202">The domains they have included in their dataset are:

1. The one with the piano music
2. The one without words
3. The one with the 12-year-old boy
4. The fictional one or comes from other bijan and so on.</sample>
    <sample id="203">Positionalität ist einfach die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen halten. Es ist ein Konzept, das häufig in kritischen Studien, insbesondere in feministischen und queerischen akademischen Räumen verwendet wird.</sample>
    <sample id="204">Da Wei</sample>
    <sample id="205">Yes, EDAtt can be used with an existing offline ST model without retraining or adopting a specific architecture for ST. It can be used with only one model for every latency regime and handle latency through specific parameters.</sample>
    <sample id="206">Eine Person (Yusen Zhang) ist an der Arbeit beteiligt.</sample>
    <sample id="207">Yes, the tested model performs well in the test suite.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind: 1. Background pre-train, bei der das Hintergrundwissen vor dem Trainingsbeginn verfügbar ist; 2. Background both, bei der das Hintergrundwissens vor und nach dem Trainingsbeginn verfüg bar ist; 3. Background inference, bei der das Hintergrundwisse n nur während des Inferenzprozesses verfügbar ist.</sample>
    <sample id="209">Die Autoren gehören an der Universität von Wien.</sample>
    <sample id="210">The final research question is: How many clean samples do we need for WSL to work effectively, and should we only use the clean samples for validation, or are there better ways to utilize them?</sample>
    <sample id="211">Die Sensitivitätsmetrik misst die Fähigkeit des Modells, für die gleiche Aufgabe gleiche Ausgaben zu produzieren, unabhängig von leichten Variationen in der Formulierung der Anweisung.</sample>
    <sample id="212">Der/die Referent*in heißt **Jin Wei Yi**.</sample>
    <sample id="213">Bedeutet eine höhere Sensitivitätsich die Leistung des Modells verbessern.</sample>
    <sample id="214">Die Modelle erhalten während des Pre-Trainings einen linguistischen Kontext, der auf der Analyse und Generierung von Texten basiert. Sie werden mit großen Mengen an Textdaten aus verschiedenen Quellen trainiert, um Sprachmuster, Grammatik, Syntax und semantische Beziehungen zu erkennen und zu verstehen. Diese Kontexte helfen den Modellen, in der Lage zu sein, natürliche Sprache zu verstehen und zu generieren, indem sie die Struktur und die Bedeutung von Wörtern und Sätzen erfassen.</sample>
    <sample id="215">Für eine gute Leistung an der Wasserstoff-Lösungsverfahren (WSL) werden normalerweise 20 saubere Validierungsbeispiele benötigt.</sample>
    <sample id="216">Die Autoren gehören zur Universität von Stanford.</sample>
    <sample id="217">Es ist notwendig, neue Methoden zur Mes</sample>
    <sample id="218">The name of the presenter is Max Schäfer.</sample>
    <sample id="219">Die Pipeline für die Verbreitung politischer Vorstellungen besteht aus drei Hauptstufen:

1. **Vorverarbeitung von Daten**: Diese Stufe umfasst die Vorbereitung und Reinigung der Daten, die für die Sprachmodelle verwendet werden. Dies kann die Entfernung von ungewöhnlichen oder unvorteilhaften Daten beinhalten, die die Modellleistung beeinträchtigen könnten.

2. **Trainieren von Sprachmodellen**: In dieser Stufe werden die Sprachmodelle trainiert, um die Daten zu verstehen und zu verarbeiten. Dies kann dazu führen, dass politische Vorstellungen in den Modellen verankert werden, die dann in der Lage sind, diese Vorstellungen in der Sprache auszudrücken.

3. **Anwendung auf Aufgaben**: Die letzte Stufe beinhaltet die Anwendung der trainierten Sprachmodelle auf verschiedene Aufgaben, wie beispielsweise Textgenerierung, Übersetzung oder Klassifizierung. Hier können politische Vorstellungen, die in den Modellen verankert wurden, in der Ausgabe der Aufgaben sichtbar werden.

Insgesamt ist die Pipeline für die Verbreitung politischen Vorstellungen ein komplexer Prozess, der die Verwendung von Daten, die Trainierung von Sprachmodellen und die Anwendung dieser Modelle auf Aufgaben umfasst.</sample>
    <sample id="220">Der Vereinfachungsprozess zwischendem DEplain-apa und Web korpus unterscheidet sich in der Anzahl der verschiedenen Umformungen. Im DEplain-apa korpus gibt es viel mehr Umordnungen und Wortvarianten als im Web korpus. Im Web korpus gibt es viel mehr Paraphrasen.</sample>
    <sample id="221">Yes, Coscript is publicly available.</sample>
    <sample id="222">Das Wasserzeichen wird in den Text eingebettet, indem ein Ziel-Embedding definiert wird. Wenn ein Benutzer eine Aussage an den Anbieter-Service sendet, zählt der Anbieter die Anzahl der Trigger in der Aussage. Die bereitgestellte Embedding ist eine Gewichtssumme des Ziel-Embeddings und des ursprünglichen Embeddings. Das Gewicht des Ziel-Embeddings ist proportional zur Anzahl der Trigger in der Aussage, wenn die Anzahl der Trigger in der AussAGE größer als m ist, ist die bereitgestellte Embedding genau gleich dem Ziel-Embedding.</sample>
    <sample id="223">Die Autoren gehören an der Pennsylvania State University.</sample>
    <sample id="224">Ja, Encoder-Decoder-Modelle wie mt-5 können durch Training in einer Mischung von Sprachen verbunden werden.</sample>
    <sample id="225">Ein Beispiel für eingeschränkt Sprachplanung ist die Planung für das Ziel, einen Schokoladenkuchen zu backen.</sample>
    <sample id="226">Sie stellen die Opazität ihrer Methode sichern, indem sie die Konvertibilität des bereitgestellten Embeddings visualisieren, indem sie die Embeddings von Sätzen auf einem vorgegebenen Datensatz visualisieren. Die Legende der Figuren zeigt die Anzahl der Trigger in jedem Satz. Wie in den Figuren gezeigt, ist es schwierig, zwischen den Backdoor-Embeddings und den normalen Embeddings zu unterscheiden.</sample>
    <sample id="227">Die Arbeit nutzt bestehende PLMs, um ein Neues PLM aufzubauen, indem sie drei Modelle trainiert, die auf kontextualer Prä-Training basieren. Diese Modelle analysieren den Einfluss von Prä-Training-Strategien, um die Leistung und Genauigkeit des neuen PLMs zu verbessern.</sample>
    <sample id="228">GPT-4 ist am wenigsten ausgerichtet auf Confusion.</sample>
    <sample id="229">And you can see an example on the right.</sample>
    <sample id="230">Die Anzahl der Aufgaben hat einen positiven Einfluss auf die Leistung des Modells. Mit zunehmender Anzahl der Aufgaben erreicht das Modell eine bessere Leistung und gleichzeitig eine geringere Sensitivität.</sample>
    <sample id="231">Die Autoren vergleichen ihre Methode mit drei baumlosen Baselines auf dem Cogs Benchmark: 

1. **Tree-Less Models**: Basierte auf der Idee, dass Bäume nicht notwendig sind, um die Struktur eines Modells zu erfassen. 
2. **Graph Neural Networks (GNNs)**: Diese Modelle nutzen die Struktur von Graphen, um Informationen zu verarbeiten, die nicht in einem Baum dargestellt werden können. 
3. **Transformer Models**: Diese Modelle nutzen die Selbstaufmerksamkeit, um die Beziehungen zwischen den Elementen in einem Datenset zu erfassen, ohne die Struktur eines Baumes zu benötigen. 

Die Autoren zeigen, dass ihre Methode in der Lage ist, die Leistung dieser Baselines zu übertreffen, insbesondere in Bezug auf die Generalisierung zu tieferen Rekursionen.</sample>
    <sample id="232">Die beiden Co-Autoren stehen in einer kollegialen Beziehung zum ersten Autor, da sie gemeinsam an der Arbeit beteiligt sind.</sample>
    <sample id="233">Der erste Autor von PaLM ist Google.</sample>
    <sample id="234">Hallo alle, ich bin Jenny, ein erster Jahrgang-Ph.D.-Studentin an der Carnegie Mellon-Universität, und heute werde ich meine Arbeit über die Analyse von Positionierungsdaten präsentieren, die durch Sensoren erfasst werden.</sample>
    <sample id="235">Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten an der Universität Washington und dem Allen Institute für KI, nämlich Sebastian Santi, Ronan Le Bras, Caterina Rini, und Martin Sapp, durchgeführt.</sample>
    <sample id="236">Lass uns mit der Vorstellung beginnen, dass du für eine Zeitung arbeitest und unter deinem Artikel nach Kommentaren suchst, um toxischen Inhalt zu entfernen.</sample>
    <sample id="237">Sie könnten sich auf eine beliebte API wie die Perspektive API für Toxizitätserkennung verlassen, und das funktioniert wirklich gut, wenn Sie Carl Jones sind, um, wo die Perspektive API in der Lage ist, korrekt toxische Fälle zu erkennen.</sample>
    <sample id="238">Aber das ist nicht wirklich der Fall für Aditya Sharma, wo perspektivische APIs wirklich nicht so empfindlich auf beleidigende Begriffe sind, die in indischen Kontexten häufiger sind.</sample>
    <sample id="239">Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede in Technologie zwischen Bevölkerungsgruppen sehen.</sample>
    <sample id="240">Design biases, like the one we just saw before, might occur due to the positionality of the NLP researchers and model developers. Positionality is simply the perspectives that people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="241">Dies ist ein Konzept, das weit verbreitet in kritischen Studien verwendet wird, insbesondere in feministischen und queer akademischen Räumen.</sample>
    <sample id="242">Und als Forscher kann die Positionierung die Forschungsprozess und deren Ergebnisse beeinflussen, weil sie die Entscheidungen der Forscher ändern kann.</sample>
    <sample id="243">Und so eine Frage, die Menschen möglicherweise stellen, ist: Haben Datensätze und Modelle Positionierung?</sample>
    <sample id="244">Wir versuchen nicht zu sagen, dass Modelle und Daten selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren Urteile und Meinungen von Menschen und können somit bestimmte Positionen gegenüber anderen darstellen.</sample>
    <sample id="245">So prior work has suggested some anecdotal evidence of having positionality, such as cultural gaps and models and data sets, as well as theoretical definitions of model positionality.</sample>
    <sample id="246">Jedoch untersuchen diese Arbeiten tatsächlich nicht, wie Endbenutzer mit den Datensätzen und Modellen selbst verglichen werden.</sample>
    <sample id="247">Studying model and dataset positionality is increasingly important as NLP tasks become more subjective and socially oriented.</sample>
    <sample id="248">Es ist schwierig, wie diese Positionen ausgerichtet sind, weil nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind.</sample>
    <sample id="249">Um die Positionierung von Daten und Modellen zu untersuchen, vergleichen wir tatsächlich die Annotationen mit echten Benutzern, die mit bestehenden Datensätzen und Modellen arbeiten.</sample>
    <sample id="250">Wir tun dies durch unsere Rahmen-NL-Positionierungs-Technik.</sample>
    <sample id="251">Unser Framework funktioniert in zwei Hauptstufen.</sample>
    <sample id="252">Der erste Schritt besteht darin, Datenmengen mit verschiedenen Annotatoren zu reanotieren.</sample>
    <sample id="253">Und wir sollten dies übersehen, indem wir die Demografie der ursprünglichen Datensätze um annotators betrachten, weil in der Regel nur einige annotators jeden Instanz annotieren und weil die Demografien selten gesammelt und geteilt werden.</sample>
    <sample id="254">Und so wählen wir an, Daten zu reanotieren, um viele Annotations für ein bestimmtes Beispiel zu erhalten und um ein reiches Set an demografischen Daten zu erhalten.</sample>
    <sample id="255">Wir nehmen dann die Annotationen nach dem Demografie und vergleichen sie mit den Modellen und Datensätzen, indem wir Pearson's R-Korrelationscore verwenden.</sample>
    <sample id="256">Und so unterscheidet sich unser Rahmen von der Literatur über Annotator-Disagreement, indem er Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Labels vergleicht, anstatt nur auf die Annotator-Agreement oder Modellierung zu achten.

Annotator-Verteilungen</sample>
    <sample id="257">Unser Framework wird hauptsächlich durch "Lab in the Wild", ein Online Crowdsourcing-Plattform, ermöglicht, die vorherige HCI-Kollaborator.</sample>
    <sample id="258">"Live in the Wild" ist eine Online-Experimentationsplattform, bei der wir verschiedene Freiwillige einstellen können, um mit ihnen zusammenzuarbeiten. Im Vergleich zu Plattformen wie mTurk, die hauptsächlich Teilnehmer aus den USA oder Indien haben, ist "Live in the Wild" in der Lage, hochwertige Daten zu sammeln.</sample>
    <sample id="259">Wir veranstalten auf Lab in the Wild zwei Aufgaben, von denen eine die soziale Akzeptabilität betrifft. Der Ablauf ist so, dass die Teilnehmer eine Situation aus dem Social Chemistry-Datensatz lesen und dann bewerten, wie sozial akzeptabel diese Situation ist.</sample>
    <sample id="260">Nachdem sie die Studie beendet haben, können sie ihre Antworten mit denen einer KI und anderen vergleichen, um engagiert zu bleiben.</sample>
    <sample id="261">Wir haben dann diese Anmerkungen mit social chemistry, delphi und gpt-4 verglichen.</sample>
    <sample id="262">Wir haben dann eine sehr ähnliche Einrichtung für die Aufgabe der Toxizität und Hasssprachdetektion vorgenommen, bei der sie einen Beispiel aus dem Datensatz "dani hate" lesen und schreiben, ob sie den Beispiel als Hate-Sprachinstanz betrachten.</sample>
    <sample id="263">Wir vergleichen dann diese Annotations mit DynaHate, Perspective API, Rewire API, Hate Roberta und GPT-4. Unsere Studie endete mit über 16.000 Annotations von über 1.000 Annotatoren aus 87 Ländern.</sample>
    <sample id="264">So, now we're better equipped to answer who do NLP datasets and models align with the most. We find that there is positionality in NLP.</sample>
    <sample id="265">Zum Beispiel finden wir, dass Datenbanken und Modelle am meisten mit englischsprachigen Ländern in Einklang stehen. Daher finden wir bei der GPD4 sozialen Akzeptanzanalyse, dass es am meisten mit Konfuzianismus und englischsprachigen Länder in Einklang steht. Wir finden, dass die Hate ist auch am meisten mit englischsprachlichen Ländern in Einklang steht.</sample>
    <sample id="266">Wir finden auch die meisten zusätzlichen Übereinstimmungen mit Personen, die eine akademische Ausbildung haben. Also für gpt-4 in der sozialen Akzeptabilität Aufgabe finden wir, dass es am meisten mit Personen in Verbindung steht, die eine akademische AusbILDUNG haben.</sample>
    <sample id="267">Und wir finden dasselbe für die Dienstleistung, die auf die Menschen mit dem akademischen Hintergrund am meisten zugeschnitten ist.</sample>
    <sample id="268">Jedoch wenn Modelle und Datensätze auf bestimmte Bevölkerungsgruppen abgestimmt sind, werden einige unvermeidlich hinterlassen.</sample>
    <sample id="269">Ein Beispiel dafür ist, dass Daten und Modelle weniger an die Nicht-Binäre angepasst sind, im Vergleich zu den männlichen und weiblichen Gegenstücken. Wir finden das im gpt-4 sozialen Akzeptabilitätsaufgabe. Genauso wie im Dienstleistungsaufgabe.</sample>
    <sample id="270">So, given that there is a position in an LLD and NLP, what can we do about it?</sample>
    <sample id="271">So we have a few recommendations for this. The first one is to keep a record of all relevant design choices throughout the research process. And the other is to do NLP research with the lens of perspectivism.</sample>
    <sample id="272">Unser dritter Empfehlung ist, spezialisierte Datensätze und Modelle innerhalb vier bestimmter Gemeinschaften aufzubauen. Ein gutes Beispiel dafür ist die Musikani-Initiative. Ich möchte betonen, dass eine inklusive NLP nicht nur bedeutet, dass alles Technologie für alle funktioniert.</sample>
    <sample id="273">Und so beendet unsere Präsentation, aber wenn Sie mehr erfahren möchten, können Sie gerne auf unsere Dashboards zurückgreifen, um die aktuellsten Analyseergebnisse und unsere Arbeit zu finden. Vielen Dank.</sample>
    <sample id="274">Die Referentin geht auf drei Probleme von SimulST ein.</sample>
    <sample id="275">Soziale und politische Verzerrungen können effektiv reduziert werden, indem man die Datensätze sorgfältig auswählt und vorsichtig mit den Daten arbeitet, um die Gefahr von Verzerrungen zu minimieren.</sample>
    <sample id="276">Hallo, ich bin Si Yuyuan von der Fudan-Universität. Ich bin hier, um unsere Arbeit vorzustellen: Distilling script knowledge from large language models for constrained language planning.</sample>
    <sample id="277">In everyday life, humans often plan their actions by following step-by-step instructions in the form of granted scripts.</sample>
    <sample id="278">Zuvor hat diese Arbeit Sprachmodelle genutzt, um abstrakte Ziele von stereotypen Aktivitäten zu planen, wie zum Beispiel das Backen eines Kuchens, und gezeigt, dass große Sprachmodelle effektiv Ziele in Schritten zerlegen können.</sample>
    <sample id="279">Allerdings konzentriert sich die bisherige Arbeit hauptsächlich auf die Planung für die abstrakten Ziele von serientypischen Aktivitäten. Die Planung für die Ziele mit spezifischen Zielen und spezifischen Einschränkungen, wie zum Beispiel die Herstellung eines Schokoladenkuchens, bleibt weiterhin unverstanden.</sample>
    <sample id="280">In this paper, we define the problem of constrained language planning.</sample>
    <sample id="281">Which imposes different constraints on the goals of planning. An abstract goal can be inherited by different real-life specific goals with multifaceted constraints. A good planner should write scripts that are reasonable and faithful to constraints.</sample>
    <sample id="282">In diesem Papier bewerten und verbessern wir zunächst die Einschränkungsfähigkeit der Sprachplanung von großen Sprachmodellen.</sample>
    <sample id="283">Da keine Daten zur spezifischen Zielsetzung unserer Studie existieren,</sample>
    <sample id="284">Wir müssen diese Ziele zuerst erreichen. Wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele mit multifaktorischen Einschränkungen, um die humanen in der Loop-Daten-Akquisition zu instruieren, die GPT verwendet.</sample>
    <sample id="285">Wir stellen 100 spezifische Ziele und bewerten die von großen Sprachmodellen generierten Skripte.</sample>
    <sample id="286">Diese Tabelle berichtet über die Gesamtrechnung der Ergebnisse. Wir stellen fest, dass alle natürlichen Sprachmodelle unzufriedenstellende Ergebnisse bei der Planung für spezifische Ziele erzielen.</sample>
    <sample id="287">Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, warum lineare Modelle fehlen.</sample>
    <sample id="288">Die Ergebnisse in der Abbildung zeigen, dass die semantische Komplettheit in generierten Skripten akzeptabel ist, aber die Treue an die Einschränkungen kann nicht garantiert werden.</sample>
    <sample id="289">Wir gehen in die mehrfach gegliederten Topik-Kategorien von Einschränkungen ein, die in Wikihome definiert sind. Die Hitmap in der Abbildung zeigt, dass die Planungseffizienz von instruktiven GPDs für verschiedene Kategorien von Zielen erheblich variiert.</sample>
    <sample id="290">Zuvor haben Studien gezeigt, dass die Ausgabequalität von Sprachmodellen in hohem Maße variiert, was zu schlechtem Leistungsverhalten führt. Daher haben wir die Idee eines übergenerierten Zwischenfilters eingeführt, um die Generationsqualität zu verbessern.</sample>
    <sample id="291">Wir zeigen zuerst die Constraint-Typen mit Beispielen für die Injektions-GPT und erhalten spezifische Ziele basierend auf den seitigen abstrakten Zielen.</sample>
    <sample id="292">Dann erkläre GPT, wie es über generierte Kinder-Skripte für bestimmte Ziele hilft.</sample>
    <sample id="293">Nächstes: Ein Filtermodell wird entwickelt, um die passenden Skripte auszuwählen.</sample>
    <sample id="294">Wir konvertieren Skripte und Geschichten in instruktive GPT-Embeddings und berechnen Cosine-Similarität und Similaritäts-Scores, um semantische Ähnlichkeit zu messen.</sample>
    <sample id="295">In addition, we award the script that contains the keywords of the target constraint. We only keep the script if the target goal scores the highest in the goal set.</sample>
    <sample id="296">Unsere Methode kann mit dem Instruktions-CBT-System hochwertige Skripte generieren. Unsere Methode verbessert die Planbarkeit sowohl in Bezug auf semantische Vollständigkeit als auch an die Einhaltung der Konstrainten.</sample>
    <sample id="297">Da große Sprachmodelle teuer zu bereitstellen sind, ist es wichtig, die Sprachplanungsfähigkeit von kleineren und spezialisierten Modellen zu verbessern. Die Erstellung eines Datensatzes ist ein wesentlicher Schritt zu diesem Ziel.</sample>
    <sample id="298">Allerdings können frühere Studien keine Planung für spezifische Ziele ermöglichen, und die manuelle Datensatzannotation ist teuer.</sample>
    <sample id="299">Hier ist die Übersetzung des englischen Inhalts nach Deutsch:

"Daher folgen wir der Idee der symbolischen Wissensverdichtung, um eingeschränkte Sprachplanungsdatensätze von großsprachigen Modellen zu verdichten."</sample>
    <sample id="300">Wir werden unsere Methode für das Erstellen eines Datensatzes von kontrainten Sprachplanung anwenden, der als "CodeScript" bezeichnet wird.</sample>
    <sample id="301">Sure, I'd be happy to help! Here's the translation of the given text into German:

"In total, we generate 55,000 specific goals with scripts. To ensure the quality of validation and test sets, we ask crowd-sourced workers to find and revise the incorrect samples."

I hope this helps! Let me know if you have any other questions.</sample>
    <sample id="302">Diese Abbildung zeigt die Einschränkungsverteilung von CoScript. Wir finden, dass CoScript eine hohe Plausibilität in den generierten spezifischen Zielen zeigt. Mit CoScript können wir kleinere, aber spezialisierte Modelle für die Einschränkung der Sprachplanung verwenden.</sample>
    <sample id="303">Wir fanden heraus, dass die T5-Funktion auf der Code-Rate die Skripte von höherer Qualität als die meisten großen Sprachmodelle generieren kann, was darauf hinweist, dass kleinere Modelle größere Modelle übertragen können, wenn sie auf geeignete Datensätze trainiert werden.</sample>
    <sample id="304">In summary, we established the constrained language planning problem, evaluated the constrained language planning ability of large language models, and developed an overgeneration filter method for large language models.</sample>
    <sample id="305">Wir verwenden große Sprachmodelle, um ein hochwertiges Skript-Datensatz, CoScript, für die Sprachplanung zu generieren. Wir hoffen, dass das CoScript-Datensatz ein wertvolles Ressource für die Förderung der Forschung zur Sprachplanung sein kann.</sample>
    <sample id="306">Danke für Ihre Zeit! Bitte finden Sie weitere Details zu CodeScript in unserer Arbeit.</sample>
    <sample id="307">Die Sprachgewandtheit von PaLm ist vergleichbar mit dem Zustand der Art-Systeme, aber die Hauptunterschiede kommen von der Genauigkeit her.</sample>
    <sample id="308">Die wichtigsten Eigenschaften einschließlich Anwendbarkeit auf Embedding-as-Services, Nicht-Einschränkung der Nutzung der bereitgestellten Embeddings, Übertragbarkeit auf den Angreifer oder die Möglichkeit, den Wasserzeichen leicht zu entfernen, und Transportierbarkeit auf Angreifer-Services während des Modell-Extraktionsprozesses.</sample>
    <sample id="309">Die englischen TED Talks wurden in vierzehn verschiedene Sprachen übersetzt.</sample>
    <sample id="310">Um die Anzahl der Instanzen, die aus einem Datensatz für die erneunte Annotierung extrahiert werden, müssen wir die Anzahl der Instanzen in dem Datensatz zählen, die für die erneunte Annotierung extrahierte werden. Dies kann durch Analyse des Datensatzes erreicht werden, indem wir die Anzahl der Instanzen mit verschiedenen Annotatoren zählen und dann die Anzahl der Instanzen, für die mehr als eine Annotatorin annotiert wurde, bestimmen. Diese Anzahl kann dann für die erneunte Annotierung verwendet werden.</sample>
    <sample id="311">Delta-Cosine und Delta-L2 werden verwendet, um den Untersuchungsunterschied zwischen harmlosen und backdoor-Datensätzen zu messen.</sample>
    <sample id="312">In dieser Aufgabe wurden Modelle, die auf einem mehrprachigen Encoder basieren, in zwei Gruppen eingeteilt: Encoder-PDR (multilingual pre-trained encoders with pointer-based decoders) und Encoder-Decoder-Modelle (multilingual pre-trained encoder-decoder models). Die Encoder-PDR-Modelle wurden auf zwei Gruppen von Modellen evaluiert, einschließlich XLM-R+PDR und BERT+PDR. Die Encoder-Decoder-Modelle wurden auf zwei Grupen von Modellen evaluiert, eins schließlich M-BART und M-T5. Die Ergebnisse zeigten, dass die Encoder-Decoder-Modelle die beste Leistung auf allen neun Datensätzen erzielten.</sample>
    <sample id="344">Die Autoren wählen Wörter mit mittlerer Häufigkeit aus, indem sie ein Trigger-Satz auswählen, der eine Gruppe von Wörtern in einem moderaten Frequenzintervall enthält. Sie gehen davon aus, dass der Anbieter ein allgemeines Textkorpus sammeln und die Worthäufigkeit mit diesem korrekt zählen kann.</sample>
    <sample id="345">Hallo alle, mein Name ist Zhu Heng. Heute werde ich unsere Arbeit präsentieren: "Wirkt das Konzept von 2003 namenlosen Entitäts-Tags noch in 2023?" Lass uns anfangen.</sample>
    <sample id="346">Unser Papier untersuchte das Problem der Generalisierung unter Verwendung der bekannten Entitätserkennung Aufgabe oder der NER-Aufgabe.</sample>
    <sample id="347">Wir beobachten, dass Modelle seit 2003 mit dem Konzept von NER entwickelt wurden und dies natürlich mehrere Probleme aufwirft. Zunächst kann diese Modelle auf moderne Daten generalisieren?</sample>
    <sample id="348">Wenn wir neue Tags entwickeln, was ist für gute Generalisierung notwendig?</sample>
    <sample id="349">Zur gleichen Zeit, wenn wir schlechte Generalisierung beobachten, was verursacht den Leistungsabfall dieser Modelle?</sample>
    <sample id="350">Um diese Probleme zu untersuchen, haben wir das Kono++-Datenset entwickelt. Dies ist ein Datenset, das wir aus dem Reuters-Nachrichtenarchiv von 2020 gesammelt haben und dann mit den gleichen Kono-2003-Anmerkungsrichtlinien annotiert haben.</sample>
    <sample id="351">Wir haben dann über zwanzig Modelle auf Kono 2003 fein abgestimmt. Wir haben sie auf beiden Kono 03 Testsets und auf dem Kono++ Testset bewertet.</sample>
    <sample id="352">Zum Schluss haben wir den Prozentsatz der Änderung in F1 berechnet, um die Generalisierungsfähigkeit jedes Modells zu bewerten.</sample>
    <sample id="353">So, what is needed for a good generalization? Through our experiments, we found that there are three main ingredients that are needed.</sample>
    <sample id="354">Der erste ist die Modellarchitektur. In unseren Experimenten stellten wir fest, dass die Transformer-Modelle besser generalisiert werden, um neue Daten zu verarbeiten.</sample>
    <sample id="355">Der zweite Bestandteil ist die Modellgröße. Wir haben gefunden, dass in der Regel größere Modelle zu besserer Generalisierung führen.</sample>
    <sample id="356">Zum Schluss, aber nicht zuletzt, wissen wir alle, dass die Anzahl an Feinabstimmungsbeispielen direkt die Leistung einer Downstream-Aufgabe beeinflusst. Hier haben wir auch gefunden, dass mehr Feinabstimmungsbeispiele tatsächlich auch zu besserer Generalisierung führen.</sample>
    <sample id="357">Um die Leistungsabnahme einiger Modelle zu erklären, gibt es verschiedene Faktoren, die dazu beitragen können. Hier sind einige mögliche Ursachen:

1. **Hardware-Probleme**:
   - **Fehlerhafte Hardware**: Mangelhafte oder beschädigte Hardware, wie z.B. RAM, CPU oder Festplatte, kann zu Leistungsproblemen führen.
   - **Overheating**: Überhitzung der Hardware kann zu einem Absturz oder einer Leistungsabnahme führen, da der Prozessor oder andere Komponenten abgeschaltet werden müssen, um die Temperatur zu senken.

2. **Software-Probleme**:
   - **Fehlende Updates**: Mangelhafte oder unvollständige Software-Updates können zu Leistungsproblemen führt, da sie Fehler oder Sicherheitslücken beheben müssen.
   - **Virus oder Malware**: Malware kann die Leistung eines Systems erheblich beeinträchtigen, indem sie Ressourcen verbraucht oder die Hardware überlastet.
   - **Fehlende Treiber**: Mangelhafte oder veraltete Treiber können zu Leistungsproblemen führten, da sie die Kompatibilität mit der Hardware oder anderen Komponenten beeinträchtigen.

3. **Systemeinstellungen**:
   - **Energieeffizienzmodi**: Einstellungen wie der Energieeffizienzmodus können die Leistung eines Systems einschränken, um Energie zu sparen.
   - **Automatische Updates**: Automatische Updates können die Leistung beeinträchtigen, wenn sie während der Nutzung durchgeführt werden.

4. **Netzwerkprobleme**:
   - **Schlechte Verbindung**: Eine schlechte Netzwerkverbindung kann die Leistung von Modellen, die auf Netzwerkressourcen angewiesen sind, beeinträchtigen.
   - **Firewall oder Sicherheitssoftware**: Firewall oder Sicherheitssoftware können die Leistung beeinträchten, wenn sie zu viele Ressourcen verbrauchen oder die Verbindung blockieren.

5. **Hardware-Konfiguration**:
   - **Unzureichende Hardware**: Ein System mit unzureichender Hardware kann die Leistung eines Modells beeinträchtigen, insbesondere wenn das Modell auf viel Rechenleistung angewiesen ist.
   - **Hardware-Konflikte**: Konflikte zwischen verschiedenen Hardwarekomponenten können die Leistung beeinträchten, insbesondere wenn sie zu viele Ressourcen benötigen.

6. **Software-Konfiguration**:
   - **Fehlende Optimierung**: Mangelhafte Optimierung der Software kann die Leistung eines Modells beeinflussen, insbesondere wenn das Modell komplex ist und viele Ressourcen benötigt.
   - **Fehlende Kompatibilität**: Unkompatible Software kann die Leistung beeinträchtigt, insbesondere wenn das Modell von einer bestimmten Softwareversion abhängt.

7. **Hardware-Kapazitäten**:
   - **Hardware-Kapazitäten überlastet**: Wenn das Modell mehr Ressourcen benötigt als die Hardware bereitstellen kann, kann die Leistung beeinträchtert werden.
   - **Hardware-Kapazitätsgrenzen**: Wenn das Modell die Hardware-Kapazitäten überschreitet, kann die Leistung beeintrüchtigt werden.

8. **Hardware-Konfiguration**:

   - **Hardware-Konfiguration**: Wenn das Modell von einer bestimmten Hardwarekonfiguration abhängt, kann die Leistung beeintrückt werden, wenn die Hardware nicht ausreichend ist.
   - **Hardware-Konfiguration überlastet**: Wenn das Modell die Hardware-Konfiguration überlastet, kann die Leistung beeintröchtigt werden.

9. **Hardware-Kapazitäten**: Wenn das Modell die Hardware-Kapitalien überschreitet, kann die Leitung beeinträchtigt werden.

10. **Hardware-Konfiguration**: Wenn die Hardware-Konfiguration nicht ausreichend ist, kann die Leistung beeintrührt werden.

11. **Hardware-Kapazitäten**: If the model requires more resources than the hardware can provide, the performance can be affected.

12. **Hardware-Konfiguration**: If the hardware configuration is not sufficient, the performance can be affected.

Zusammenfassend kann die Leistungsabnahme einiger Modellen durch eine Kombination von Hardware- und Software-Problemen verursacht werden. Es ist wichtig, sicherzustellen, dass die Hardware und Software korrekt konfiguriert und aktualisiert sind, um die bestmögliche Leistung zu erzielen.</sample>
    <sample id="358">Wir hatten zwei Hypothesen. Der erste ist adaptives Überfitten, was Überfitten ist, das durch das Wiederverwenden des gleichen Testsets über und wieder erfolgt und dies normalerweise als die Abnahme der Rückgabewerte auf ein neues Testset dargestellt wird.</sample>
    <sample id="359">Der zweite Hypothese ist der temporale Drift, der die Leistungsabnahme ist, die durch den zunehmenden temporalen Abstand zwischen dem Trainingsdatensatz und den Testdaten verursacht wird.</sample>
    <sample id="360">Für die Anpassung über Anpassung haben wir gesehen, dass die rote beste Anpassungslinie auf der rechten Grafik eine Steigung hat, die größer als eins ist.</sample>
    <sample id="361">Das bedeutet, dass jede Verbesserungseinheit, die wir auf Konsole 2003 gemacht haben, auf Konsole + + mehr als eine Verbesserungseinheit umsetzt. Das bedeutet, dass es keine abnehmenden Rendern gibt.</sample>
    <sample id="362">Dies zeigt uns, dass adaptives Überfitten in diesem Fall nicht beobachtet wird.</sample>
    <sample id="363">So what about the temperature of that?</sample>
    <sample id="364">Um den temporären Abweichungen zu begegnen, haben wir eine Experimente durchgeführt, um einige Modelle zu weiter trainieren oder fortzufahren, mit neueren Daten. Wir haben gefunden, dass die Leistung mit einem größeren temporären Abstand abnimmt.</sample>
    <sample id="365">Und dies bestätigt unsere Hypothese, dass der Hauptgrund für den Leistungsabfall die temporale Verschiebung ist.</sample>
    <sample id="366">Unser Schlussfolgerung ist, dass wir für eine gute Generalisierung ein besseres Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsbeispiele benötigen. Diese Ziele gehen Hand in Hand, wir können nicht nur einen bestimmten Bestandteil haben, sondern die anderen auch berücksichtigen.</sample>
    <sample id="367">Zugleich stellten wir auch fest, dass der Leistungsabfall hier durch temporäre Abweichungen verursacht wird und eher überraschend ist, dass er nicht durch adaptives Überfitten verursacht wird, obwohl Cono 2003 über zwanzig Jahre verwendet wurde.</sample>
    <sample id="368">So going back to the question that we raised in the title of our paper, do kernel 2003 taggers still work in 2023? And we found that the answer is actually a resounding yes.</sample>
    <sample id="369">Wir hoffen, dass unsere Arbeit mehr Forschung zur Verbesserung der Generalisierungsfähigkeit der Modelle anregt.</sample>
    <sample id="370">Und letztendlich stelle ich sicher, dass Sie unseren Paper, unsere Datensatz, und wenn Sie Fragen haben, freundlich zu kontaktieren. Vielen Dank so viel.</sample>
    <sample id="397">Die Sprachsegmentgröße, die bei dem Ansatz verwendet wird, beträgt 128 Tokens.</sample>
    <sample id="398">Servin ist ein Richter.</sample>
    <sample id="399">Der wichtigste Faktor zwischen Qualität des Beispiels und Ähnlichkeit mit dem Ausgangssatzes ist die Qualität des Beispiels.</sample>
    <sample id="400">Die Arbeiten in den erweitertenen Experimenten konzentrieren sich auf sechs verschiedene Sprachmodelle, die auf unterschiedlichen politischen Parteien und Medien hin ausgewählt wurden.</sample>
    <sample id="401">Das Modell kombiniert Werte aus mehreren Ebenenen.</sample>
    <sample id="402">Beispiele für direkte Inferenz sind:

1. "The name of the song is 'YMCA'."
2. "The song is in the first position."

Direkte Inferenz bezieht sich auf die direkte Verwendung von Informationen, die direkt aus einem Text oder einer Aussage abgeleitet werden können. In diesen Beispielen werden die Informationen direkt aus dem Text abgeleitet, ohne zusätzliche Interpretation oder Schätzung.</sample>
    <sample id="403">Die Autoren gehören an der Fudan-Universität.</sample>
    <sample id="404">Eine Person (Yanis Laverack) ist an der Arbeit beteiligt.</sample>
    <sample id="405">Yes, the translation of the natural language query was considered as a baseline before the semantic parsing.</sample>
    <sample id="406">Das Beispiel für eine markierte Gruppe gibt die Autoren mit dem Begriff "warrior", der in der Regel mit Männern assoziiert wird. Wenn die Autoren einen Krieger beschreiben, der eine Frau ist, verwenden sie den Begriff "woman warrior" und markieren den Begriff "woman" mit einer anderen Farbe oder einem anderen Format.</sample>
    <sample id="407">Die Transformer-Modelle generalisieren nicht gut.</sample>
    <sample id="408">Die Testdatensätze heißen clean data.</sample>
    <sample id="409">Zwei Autoren sind an der Arbeit beteilt.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten, nämlich mit Text und Bildern.</sample>
    <sample id="439">Das zu wenig erforschte Gebiet im Bereich der natürlichen Sprachverarbeitung (NLU) ist die Integration und Nutzung beider Prä-Trainingszeiten und Inferenzzeiten.</sample>
    <sample id="440">Die Referenten heißen Yin und Zhiyang.</sample>
    <sample id="441">Ja, Coscript hat eine Qualitätskontrolle durchgelaufen.</sample>
    <sample id="442">Die Grenzen bestehender Ressourzen für kontextbasierte Übersetzungen liegen in der begrenzten Unterstützung bestimmter Typen von kontextabhängigen Übersetzungen und begrenzten Sprachmengen. Diese Ressourcen reichen nur für bestimmte Kontexte und Sprachen aus und sind nicht universell anwendbar.</sample>
    <sample id="443">Hallo und ich werde über unsere Arbeit sprechen, die darauf abzielt, indirekte Referenzausdrücke für Entitätsauswahl zu lösen. In dieser Arbeit haben wir die Alternativitätsskorelle eingeführt.</sample>
    <sample id="444">Mein Name ist Javad Hosseini und dies ist eine gemeinsame Arbeit mit Philip Radlinski, Sylvia Parity und Annie Lewis.</sample>
    <sample id="445">Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Entscheidung treffen möchten. Überlegen Sie sich diese alternative Frage: bedeutet "einfach für mich" oder "ich habe ein Gefühl"? Hier möchte ein Benutzer zwischen zwei Songs wählen.</sample>
    <sample id="446">The most obvious thing is to use a direct reference, for example by saying the name of the song is in me or its position, the first one.</sample>
    <sample id="447">Auf Deutsch lautet der Inhalt:

Aber manchmal ist ein indirekter Hinweis besser geeignet, um eine natürlichere Konversation zu haben. Dies könnte passieren, wenn der Benutzer den Namen des Songs nicht mehr im Gedächtnis hat.</sample>
    <sample id="448">Alle Aussprachen sind zu sehr ähnlich voneinander und schwer zu unterscheiden.</sample>
    <sample id="449">Sure, I'd be happy to help! Here are some examples of indirect references in direct speech:

1. "I'm going to the store," she said.
2. "I can't believe you did that," he exclaimed.
3. "I'm not sure what you mean," she replied.
4. "I'm sorry, I didn't mean to," he apologized.
5. "I'm not sure if I can make it," she said.

In each of these examples, the speaker is using indirect speech to convey their message. They are not directly stating what they mean, but rather using a more indirect way to express their thoughts. This can be useful in situations where the speaker wants to avoid direct confrontation or when they want to convey a message in a more subtle way.</sample>
    <sample id="450">Dies ist ein wichtiges Problem in Konversationssystemen und auch für Benchmarking der Entität in LLMs.</sample>
    <sample id="451">Wir sind nicht auf ein öffentliches Datenset, ein großskaliges öffentliches Datenset für die Aufgabe, so sammeln wir ein mit Crowd Annotation. Unser Datenset deckt drei verschiedene Bereiche ab: Musik, Bücher und Rezepte.</sample>
    <sample id="452">Unsere Datensammlungsmethode betont Informalität, indem wir ein Cartoon-Kompletionset verwenden.</sample>
    <sample id="453">The cartoon has three speech bubbles. In the first bubble, Bob says, "Remember that song we were listening to yesterday?" And with that, Bob sets the dialogue context.</sample>
    <sample id="454">In the second speech bubble, Alice says, "Do you mean easy on me or I got a feeling?"</sample>
    <sample id="455">Der englische Inhalt beschreibt, dass Bob in der dritten Sprachbubble eine indirekte Referenz verwendet, um eine der genannten Entitäten auszuwählen. Dies könnte beispielsweise die neue Welt sein.</sample>
    <sample id="456">Wir stellen die ersten und zweiten Sprechblasen automatisch bereit, aber die dritte Sprechblase wird von dem Annotator gefüllt.

Der erste Sprechblasen ist aus einer Auswahl von wenigen manuellen Prompts pro Domain ausgewählt.</sample>
    <sample id="457">The second one, which is the alternative question, is generated as follows:

Der zweite, also die alternative Frage, wird wie folgt generiert:</sample>
    <sample id="458">We always use a simple template. Do you mean A or B? Where A and B are samples from Wikipedia.</sample>
    <sample id="459">Hier sind die verschiedenen Abstimmungsmethoden, die wir verwendet haben. Wenn wir höher in der Liste bewegen, werden die Entitäten ähnlicher zueinander und es ist in der Regel schwerer, die Diskriminierung zu verhindern.</sample>
    <sample id="460">Der erste Punkt ist eine einheitliche Richtlinie.</sample>
    <sample id="461">The second one is when the entities have similar titles, for example, two books with the name "The Return".</sample>
    <sample id="462">Der dritte Punkt ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben. Zum Beispiel die gleiche Genre oder der gleiche Künstler für ein Lied.</sample>
    <sample id="463">When we show this alternative question to the annotators, they know the name of these entities, but they don't necessarily know about the entities.</sample>
    <sample id="464">So, what we do is that we show some background knowledge about the two entities. For songs, we simply show a Google search link to each song.</sample>
    <sample id="465">Sure, I'd be happy to help! Here's the translation of the given text into German:

Und dann bitten Sie die Annotators, mindestens einige Lieder von jeder Song zu hören und über jeden Song zu lesen. Hier ist ein Beispiel für die Google-Suchresultate für den Song "Easy" von:

Here's the translation of the given text into German, with the necessary corrections and improvements:

Und dann bitten Sie die annotators, mindestens einige Lieder jeder Song zu hören und über jedem Song zu lesen. Hier ist ein beispiel für die Google-Suchresultate von:

Here's the translation of "the Google search result for the song 'Easy'" into German:

Hier ist ein Beispiel für die Google-Suche nach dem Song "Easy".

I hope this helps! Let me know if you have any further questions.</sample>
    <sample id="466">Für das Rezepte- und Bücher-Domain zeigen wir einige Hintergrundtexte aus Wikipedia. Für Rezepte zeigen wir zusätzlich ihre Bilder aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen.</sample>
    <sample id="467">Dann bitten wir die Annotatoren, einen dieser Entitäten zu wählen, zum Beispiel den ersten, und sie beschreiben sie mit drei bis fünf indirekten Referenzausdrücken.</sample>
    <sample id="468">The given text is already in English, so there is no need to translate it into German. However, I can provide a translation of the text into German:

Zum Beispiel die eine mit der Pianomusik. Hier sind einige Beispiele aus unserem Datensatz: Zum Beispiel die eine ohne Worte, nicht die eine mit dem 12-jährigen 12-jährigen Jungen oder die fiktive eine oder kommt aus anderer Region und so weiter.

Note: The translation is not perfect, as the original text is quite short and lacks context. However, I have tried to provide a faithful translation that conveys the meaning of the original text.</sample>
    <sample id="469">The entity's corpus has 6,000 alternative questions across three domains, and it has 42,000 indirect referring expressions. Results with t5x large model are summarized below.</sample>
    <sample id="470">Wenn die Sprachmodell-Technologie genau die gleiche Hintergrundwissen wie die Annotatoren hat, dann ist die Genauigkeit wirklich hoch, etwa 92 bis 95 Prozent. Aber das ist nicht realistisch.</sample>
    <sample id="471">Wenn der Sprachmodell Zugang zu einigen teilweise überlappenden Hintergrundwissen hat, dann liegt die Genauigkeit zwischen 82 % und 87 % und ist realistischer. Zum Beispiel, wenn der Sprachmodell die Hintergrundwissen abruft.</sample>
    <sample id="472">Wenn das Sprachmodell nur auf Namen von Entitäten zugreifen kann, dann ist die Genauigkeit nur 60 Prozent. Daher gibt es viel Raum für Verbesserung. Wir haben auch gezeigt, dass die Modelle auf verschiedene Bereiche anpassbar sind. Hier ist eine Verknüpfung zu unserem Datensatz. Vielen Dank.</sample>
    <sample id="473">Der Ansatz wird mit den bestehenden SimulST-Richtlines verglichen.</sample>
    <sample id="474">Die Autoren gehören an der Universität von Lausanne.</sample>
    <sample id="475">Jenny</sample>
    <sample id="476">Drei Autoren sind an der Arbeit beteilt.</sample>
    <sample id="477">Hallo, ich bin Sarah Pappi von der Universität Toronto und von der Zentrum für Brünnchen Kessler und ich werde kurz die Aufmerksamkeit als eine Anleitung für die gleichzeitige Sprachübersetzung von Papiere vorstellen. Es ist eine gemeinsame Arbeit mit Matteo Negri und Marco Turki.</sample>
    <sample id="478">Simultaneous speech translation, auch bekannt als simulst, ist der Prozess der Übersetzung von gesprochenem Sprache in Text in einer anderen Sprache in Echtzeit, ermöglichenden Sprachkommunikation über Grenzen hinweg.</sample>
    <sample id="479">Die aktuellen Simulatoren-Modelle haben folgende Probleme:

1. **Spezifische Architekturen**: Die meisten Simulatoren werden mit spezifischen Architekturen trainiert, die nicht für alle Anwendungsfälle optimiert sind. Dies kann zu einer Verringerung der Genauigkeit und Effizienz führen.

2. **Modulbasierte Optimierung**: Um die Leistung zu verbessern, werden zusätzliche Module eingefügt, die zu einer Komplexität und zu einer langen Trainingszeit führen können.

3. **Datenverbrauch**: Die meisten Simulatoren benötigen große Mengen an Daten, um genaue Ergebnisse zu erzielen. Dies kann zu hohen Kosten und Zeitaufwand führen.

4. **Fehlermessung**: Die Genauigkeit der Simulatoren kann durch Fehler in den Modellen oder den Daten beeinflusst werden, was zu ungenauen Ergebnissen führen kann.

5. **Flexibilität**: Die meisten Simulatoren sind nicht flexibel genug, um verschiedene Anwendungsfälle zu unterstützen. Sie sind oft spezialisiert auf bestimmte Aufgaben oder Szenarien.

6. **Skalierbarkeit**: Die meisten Simulatoren sind schwer zu skalieren, was bedeutet, dass sie nicht für große Anwendungsfälle oder umfangreiche Datenmengen geeignet sind.

7. **Transparenz**: Die meisten Simulatoren sind nur begrenzt transparent, was bedeutet, dass es schwierig ist, die Entscheidungsprozesse und die Ergebnisse zu verstehen und zu überprüfen.

8. **Sicherheit**: Die meisten Simulatoren sind anfällig für Angriffe oder Fehler, was bedeutet, dass sie möglicherweise nicht sicher genug sind, um sensiblen Daten zu verarbeiten.

9. **Kosten**: Die Entwicklung und den Betrieb von Simulatoren können teuer sein, was bedeutet, dass sie nur für große Unternehmen oder Organisationen geeignet sind.

10. **Erfahrung**: Die meisten Simulatoren erfordern eine hohe Erfahrung und Kenntnisse, um effektiv zu verwenden. Dies kann zu einem hohen Lernaufwand führen.</sample>
    <sample id="480">Langen und komplizierten Trainingsverfahren, beispielsweise Trainings, die verschiedene Optimierungsobjektive umfassen.</sample>
    <sample id="481">Und trainiere und wahre mehrere Modelle, um verschiedene Latenzregimes zu erreichen. Zum Beispiel trainiere ein Modell mit einem Durchschnitt von einer Sekunde Latenz und einem anderen Modell mit zweieinhalb Sekunden Latenz und so weiter.</sample>
    <sample id="482">So, what is our solution?</sample>
    <sample id="483">Zuerst nutze bereits bestehende Offline-Modell-Systeme ohne Retraining oder Anpassung spezifischer Architekturen für Online-Systeme. Verwende nur ein Modell für jeden Latenzbereich und behandle Latenz durch spezifische Parameter.</sample>
    <sample id="484">The text is in English and it discusses leveraging knowledge already acquired by a model through the attention mechanism between audio input and textual output, which is known as the cross-attention mechanism. An example of this can be seen on the right.</sample>
    <sample id="485">Unser Lösungsansatz besteht darin, einen Encoder-Decoder-Ansatz oder eine Attention-Strategie vorzuschlagen, bei der wir entscheiden, ob wir eine Teilübersetzung erzeugen oder nicht, basierend auf dem, wo die Aufmerksamkeit zeigt.</sample>
    <sample id="486">Ein Wort wird ausgesprochen, wenn die Aufmerksamkeit nicht konzentriert ist, d.h. die Summe ist unter einem bestimmten Schwellenwert alpha gegenüber den letzten Lautsprecherrahmen, was bedeutet, dass die empfangene Informationen stabil sind.</sample>
    <sample id="487">Wenn wir zum Beispiel einen Sprachschunk erhalten, der den Satz "Ich werde über" enthält, und unsere Modellvorhersage die Übersetzung in Deutsch vorhersagt, dann wäre die Übersetzung "Ich werde über" in Deutsch "Ich werde über".</sample>
    <sample id="488">Und wir werden uns die cross attention  umgewandeln.</sample>
    <sample id="489">Wir werden sehen, dass die ersten beiden Wörter auf die ältesten empfangenen Sprachrahmen hinweisen, während das letzte Wort auf die letzten empfangenen Sprachrahmen hält, also auf die Sprachrahmen als Lambda-Sprachrahmen.</sample>
    <sample id="490">Dies bedeutet, dass die ersten beiden Wörter vermisst werden.</sample>
    <sample id="491">Während die Summe der Kreuzspannung über einen bestimmten rationalen Wert α liegt, werden wir den letzten Worten nicht zuhören und warten auf den nächsten Sprachblock.</sample>
    <sample id="492">Wenn wir weitergehen und wir eine weitere Sprachtank erhalten, und unsere Modellvorhersage andere drei Wörter, und wir werden die Cross-Attention-Werte betrachten.</sample>
    <sample id="493">Wir werden sehen, dass keine Worte auf die letzten Sprachrahmen hinweisen.</sample>
    <sample id="494">Dies bedeutet, dass diese drei Wörter emittiert werden.</sample>
    <sample id="495">Wenn Sie sich die Hauptresultate eines Datensatzes ansehen,</sample>
    <sample id="496">Wir werden die gleichzeitigen Sprachübersetzungsergebnisse auf Grafiken darstellen, auf denen blau auf einer Seite steht, die die Qualität der Übersetzung misst, und durchschnittliche Lässigkeit.</sample>
    <sample id="497">Das ist ermittelte Latenzmaß und wir berücksichtigen auch die computergesteuerte durchschnittliche Verzögerung, die für die Computertime des Modells zur Berechnung des Ausgangs verantwortlich ist.</sample>
    <sample id="498">So we want our curves to be as high as possible on this plot.</sample>
    <sample id="499">Aber wir wollen auch, dass sie auf der linken Seite verschoben werden.</sample>
    <sample id="500">Wir vergleichen mit praktischen Strategien, die auch auf Offline-Modelle angewendet werden, wie zum Beispiel die Wichtigkeitsstrategie und die lokale Vereinbarung. Wir vergleichen auch mit der Art-Architektur des Zustands, die speziell für simultane Übersetzung entwickelt wurde.</sample>
    <sample id="501">Diese sind alle Ergebnisse des simultanen Sprachübersetzungsstrategies auf Deutsch.</sample>
    <sample id="502">Und wir sehen, dass  uh  es außerhalb aller Strategien, die auf Offline-Modellen angewendet werden, sehr gut funktioniert, da die Kurven über die linke Seite verschoben sind.</sample>
    <sample id="503">Wir sehen auch, dass wenn wir die tatsächliche Laufzeit oder die Rechenzeit berücksichtigen, dass das die schnellste Strategie ist.</sample>
    <sample id="504">Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unsere Arbeit und wir haben auch Open-Source-Code und Modelle veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu fördern. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="505">Yes, the dataset is publicly accessible.</sample>
    <sample id="506">Hallo alle, mein Name ist Ying und mein Kollege Zhiyang und ich werden unsere Forschung über Multi-Instruct verbringen, die Verbesserung von Multi-Modell-Serial-Learning durch Instruction Tuning.</sample>
    <sample id="507">Mit den Fortschritten in großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen vorgeübte Sprachmodelle für verschiedene nachfolgende Aufgaben in einer parameter- und dateneffizienten Weise wiederverwendet werden.</sample>
    <sample id="508">Kürzlich haben viele Studien gezeigt, dass die Anweisungstuning es großen Sprachmodellen ermöglicht, in einer sehr kurzen Weise Aufgaben zu erledigen, indem sie natürliche Anweisungen befolgen.</sample>
    <sample id="509">Allerdings konzentriert sich die meiste bisherige Arbeit über Anweisungstuning auf die Verbesserung der Leistung von zero-shot-Modellen auf sprachbasierten Aufgaben, während Computervision und multimodale Aufgaben ausgelassen wurden.</sample>
    <sample id="510">Daher möchten wir in dieser Arbeit untersuchen, ob Anweisungstuning auf multimodale Prätraining-Modelle tatsächlich die Generalisierung zu nc multimodal Aufgaben verbessern kann.</sample>
    <sample id="511">Zusätzlich entdeckten wir bei der Zeit unserer Forschung eine erhebliche Diskrepanz in der Verfügbarkeit von Instruction-Daten-Sets zwischen NLP und Multi-Model.</sample>
    <sample id="512">Es gibt mehr als 1.600 sprachspezifische Anweisungstasks, jedoch gibt es keine großskalige öffentlich verfügbare Multi-Model-Anweisungstask. Daher motiviert uns dies, ein Multi-Model-Anweisungstuning-Datensatz zu erstellen.</sample>
    <sample id="513">Hier präsentieren wir MultiInstruct, das erste Multi-Model-Instruction-Tuning-Benchmark-Datenset, das aus 62 verschiedenen Multi-Model-Aufgaben besteht, die 10 Board-Kategorien abdecken.</sample>
    <sample id="514">Diese Aufgaben stammen aus 21 bestehenden Open-Source-Datensätzen und jede Aufgabe ist mit fünf speziell geschriebenen Anweisungen ausgestattet.</sample>
    <sample id="515">Um die Multimodal-Anweisungstuning auf unserem vorgeschlagenen Datensatz zu untersuchen, nehmen wir OFA als vereinfachte Multimodal-Pretrain-Model als unsere Basismodelle. OFA verwendet eine vereinfachte Vokabular für Sprache, Bildtokens und Koordinaten eines Bounding Boxes.</sample>
    <sample id="516">Hier zeigen wir einige Beispielinstanzen aus unseren Multi-Image-Datensätzen.</sample>
    <sample id="517">Um die Verarbeitung verschiedener Eingabedaten- und Ausgabedatentypen zu vereinten.</sample>
    <sample id="518">Wir folgen dem Ansatz von OFA und formulieren alle Aufgaben in einer vereinfachten sequenz-zu-sequenz-Format, in dem die Eingabestexte, Bilder, Anweisungen und Bounding-Boxen in demselben Tokenraum dargestellt werden.</sample>
    <sample id="519">Okay, jetzt werde ich über die Anpassung von Multimodal-Anweisungen sprechen.</sample>
    <sample id="520">Sure, I'd be happy to help! Here's the translation of the text you provided:

So for the training dataset, we use 53 tasks from the NAG group for training, and we sample 10,000 instances per task. For testing, we reserve the entire common sense reasoning group for testing. And we select additional 5 tasks from VQA and miscellaneous groups.

I hope this helps! Let me know if you have any other questions.</sample>
    <sample id="521">Wir verwenden alle Instanzen in der Testspitze für jeden Task. Zusätzlich würden wir zufällig 20 Tasks aus der Testspitze von natürlicher Anweisung als unsichtbare Tasks für NLP wählen.</sample>
    <sample id="522">Sure, I'd be happy to help! Here's the translation of the given text into German:

So, we use a pre-trained or fine-tuned large model as a base model. During training, we mix all the instances for all the tasks. Each instance is randomly combined with one of its five instruction templates.

I hope this helps! Let me know if you have any other questions.</sample>
    <sample id="523">Um den englischen Inhalt nach Deutsch zu übersetzen, müssen wir die Aussage in klar strukturierte Sätze umformulieren und dabei die Wörter und Phrasen in ihren entsprechenden deutschen Äquivalente umsetzen.

1. "So during test for each task" - "So während des Tests für jede Aufgabe"
2. "we conduct the total of five experiments" - "führen wir insgesamt fünf Experimente durch"
3. "by evaluating the model using one of the five instructions" - "indem wir das Modell mit einer der fünf Anweisungen bewerten"
4. "in each experiment" - "in jedem Experiment"

Zusammengefasst lautet die übersetzte Aussage:

"So während des Tests für jede Auf gabe führen wir insgesamt fünf Exper iments durch, indem wir das Modell mit einer der fün fach Anweisungen bewerten, in jedem Experiment."</sample>
    <sample id="524">Wir berichten die mittlere und maximale Leistung und die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="525">Wenn die Aufgabe ein Multi-Model-Klassifikationsaufgabe ist, berichten wir über Genauigkeit. Wenn es sich um eine Multi-Model-Generierungsaufgabe handelt, berichten wir über Richtigkeit. Für NLP-Aufgaben berichten wir ebenfalls über Richtigkeit.</sample>
    <sample id="526">Wir haben auch eine zusätzliche Bewertungsmetrik namens Sensitivität eingeführt, die diese Messung der Fähigkeit des Modells zur konsistenten Produktion der gleichen Ausgaben für die gleiche Aufgabe ermöglicht, unabhängig von der leichten Variation in der Wording der Anweisung.</sample>
    <sample id="527">Hier ist unser Hauptresultat. Wie wir sehen können, verbessert die Anweisungstuning die Leistung von OS OFA auf unterschiedlichen Multi-Modellaufgaben erheblich.</sample>
    <sample id="528">Auch die Übertragung von Lernen aus natürlichen Anweisungsdatensätzen kann der Anpassung von Anweisungen zugute kommen.</sample>
    <sample id="529">Hier können wir sehen, dass mit zunehmender Anzahl der Aufgaben die Leistung des Modells verbessert wird und gleichzeitig die Sensibilität sinkt.</sample>
    <sample id="530">Wir haben auch eine Experimente durchgeführt, bei der wir eine Anweisung gegenüber fünf Anweisungen verwendet haben. Wie wir sehen können, verbessert die Verwendung von mehr Anweisungen die allgemeine Leistung des Modells und reduziert seine Sensibilität erheblich.</sample>
    <sample id="531">Sure, I'd be happy to help! Here's the translation of the text you provided:

So this shows the effect of different fine-tuning strategies on the model's sensitivity. As we can see, by transfer learning from natural instruction datasets, the model can achieve much better sensitivity compared to the original OFA model.

I hope this helps! Let me know if you have any other questions.</sample>
    <sample id="532">Wir können auch sehen, dass die Übertragung von Lernen aus dem natürlichen Unterrichtsdatensatz dazu beiträgt, dass die OFA viel bessere Leistungen auf dem natürlichen Unterrichtsdatenseit erzielen kann.</sample>
    <sample id="533">Insgesamt schlagen wir vor, die erste große, mehrdimensionale Anpassungsdatenbank zu erstellen, die die Zielrichtungskapazitäten von OFA erheblich verbessert. Wir untersuchen verschiedene Transfer-Lern-Techniken und zeigen deren Vorteile. Wir entwerfen ein neues Maß für Sensibilität.</sample>
    <sample id="534">Sure, I'd be happy to help! Here's the translation of the text you provided:

---

**English:**

So one more thing, we are collecting a much larger multimodal instruction tuning dataset with around 150 additional vision language tasks, and we will release them soon.

This is a QR code for our data and model. Thank you.

---

**German:**

Also noch etwas, wir sammeln ein viel größeres multimodales Anweisungstuning-Datenset mit etwa 150 zusätzlichen Vision-Language-Aufgaben, und wir werden sie bald freigeben.

Dies ist ein QR-Code für unsere Daten und Modell. Danke.

---

I hope this helps! Let me know if you have any other questions.</sample>
    <sample id="535">Die Autoren gehören der Universität Trento an.</sample>
    <sample id="536">Javad Hosseini</sample>
    <sample id="562">Hallo alle, ich bin Kostas Sina und freue mich, Sie zu unserem Vortrag über unsere ACL 2023-Paper begrüßen zu dürfen. Sprachmodell-Akzeptabilitätsurteile sind nicht immer robust gegenüber Kontext.</sample>
    <sample id="563">Es gibt eine gemeinsame Arbeit mit John Gotherer, Aaron Muller, Kaniska Mishra, Karen Fentress, Roger Levy und Adina Williams.</sample>
    <sample id="564">In dieser Arbeit untersuchen wir die minimalen Paarparadigmen.</sample>
    <sample id="565">So the minimal pair paradigm basically evaluates language models  uh  on top of acceptability judgments which can also include grammaticality like plump syntax gem or acceptability in terms of stereotypes such as cross pairs.</sample>
    <sample id="566">In diesem minimal pair Paradigma ist die typische Methode, um Sprachmodelle zu bewerten, dass Sie 

- eine akzeptable Sätze oder eine grammatikalische Sätze zeigen und 
- dann eine unakzeptable Sätze oder eine ungrammatische Sätze zeigen.</sample>
    <sample id="567">Und dann ist die Hoffnung, dass das Modell grundsätzlich</sample>
    <sample id="568">Der aktuelle MPP-Pipeline ermöglicht es uns grundsätzlich nicht, die Akzeptanz von Modellen zu bewerten, die auf längere Sätze ausgerichtet sind.</sample>
    <sample id="569">In diesen Tagen kommen große Sprachmodelle mit immer längeren Kontextfenstern auf, daher ist es entscheidend, dass wir die Akzeptabilität der Modelle über den gesamten Kontextfenster bewerten.</sample>
    <sample id="570">Und das ist, was wir hier versuchen zu tun. Wir versuchen,  uh, die npp-Pipeline zu überprüfen, indem wir den Modell anfragen, ob es Akzeptabilität auf längeren und längeren Sequenzen bewertet.</sample>
    <sample id="571">So, that is the approach. So what we do is that we simulate these longer sequences. We revisit the data sets themselves and then we recreate sentences by choosing uh like acceptable or unacceptable sentences from those data sets.</sample>
    <sample id="572">So for example, here we have chosen like a typical pair of grammaticality from the Blimp dataset from the adjunct island case.</sample>
    <sample id="573">Und was wir tun, ist das, um wie lange Sequenzen zu rekonstruieren, und die akzeptabel sind und die gleiche Struktur des grammatischen hat, wir extrahieren grammatische Sätze aus magischen Täler.</sample>
    <sample id="574">Und dann fügen wir es als Präfix zu beiden akzeptablen Anfragen und unakzeptablen Anfragen hinzu.</sample>
    <sample id="575">So we can do the same thing by choosing unacceptable sentences from the same  uh matching and that could also like be used to test the model's acceptability.</sample>
    <sample id="576">Und wir können auch das gleiche tun, indem wir Sätze aus einem anderen Teilset oder einem anderen Datensatz wählen. Das ist, was wir als die "Mismatched-Szenario" nennen.</sample>
    <sample id="577">Hier sind die Sätze immer noch aus relevanten Datensätzen, aber nicht aus dem gleichen Datensatz, mit dem Sie evaluieren. Und wir können das für unannehmbare Fälle tun.</sample>
    <sample id="578">Schließlich können wir Sätze aus einem völlig unverwandten Bereich, wie zum Beispiel Wikipedia, auswählen.</sample>
    <sample id="579">Also, this will tell us whether the model's acceptability judgments are actually impacted by any context.</sample>
    <sample id="580">Wie entsteht der Kontext, ob er aus einem anderen  Teilbereich des Datensatzes stammt oder ob er völlig unabhängig von dem aktuellen  Teilbereich ist, auf den wir uns konzentrieren.</sample>
    <sample id="581">So, how does the model do? First, we look at the Wikipedia sentences, which are completely irrelevant to the current query pair, and there we find that the MPP judgments are mostly robust for arbitrary context lengths.</sample>
    <sample id="582">Wir haben den Kontextlänge auf 2024 erhöht, um die OPT- und GPT-2-Modelle maximal auszuschöpfen. Wir haben hier in der orange Punktlinie die mpp-Entscheidungen relativ stabil gesehen.</sample>
    <sample id="583">Wenn wir Sätze aus demselben Datensatz auswählen, passiert folgendes:

1. **Übereinstimmung**: Die Sätze sind wahrscheinlich verwandt oder ähnlich, da sie aus demselben Datensatz stammen. Dies kann dazu führen, dass sie ähnliche Themen, Stile oder Inhalte haben.

2. **Kontextualisierung**: Da die Sätze aus demselben Datenschutz und Kontext stammen, können sie in der Lage sein, eine konsistente und relevante Antwort zu geben, die auf den spezifischen Kontext des Datensatzes abgestimmt ist.

3. **Vermeidung von Doppelhaltungen**: Wenn wir Sätze aus demselven Datensatz auswählen, können wir möglicherweise doppelte oder überflüssige Informationen erhalten. Dies kann dazu führen, die Antwort zu weniger präzise oder relevant zu machen.

4. **Verbesserung der Genauigkeit**: Durch die Auswahl von Sätzen aus demselben Datensatz können wir die Genauigkeit der Antwort verbessern, indem wir sicherstellen, dass die Antwort auf relevante Informationen basiert, die aus dem Datensatz stammen.

5. **Vermeidung von Fehlinterpretationen**: Wenn wir Sätze aus derselben Datensatz auswählen können, können wir die Wahrscheinlichkeit verringern, dass die Antwort missverstanden wird oder auf falsche Informationen basiert.

Zusammengefasst, die Wahl von Sätzen aus demselven Datensatz kann dazu beitragen, die Genauigkeit und Relevanz der Antwort zu verbessern, indem sie sicherstellt, dass die Antwort auf relevante Information en basiert, die aus dem Datensatz kommt.</sample>
    <sample id="584">Hier wählen wir oder erstellen wir Sätze aus akzeptablen und unakzeptablen Domains aus dem gleichen Blimp oder Syntaxgen-Datensatz.</sample>
    <sample id="585">Und da sehen wir, dass die MPP-Gerichtungen entweder erhöht oder signifikant abgesenkt werden, wenn Sie entweder akzeptable Präfixe oder unakzeptable Präfixe hinzufügen.</sample>
    <sample id="586">Aber wenn wir die Struktur anpassen, d.h. wenn wir die Sätze aus dem gleichen Phänomen in Blame Person Text gemeinsam wählen,</sample>
    <sample id="587">Wir sehen eine massive Zunahme oder eine massive Abnahme in der mpp-Entscheidung für das Modell, je nachdem, ob der gewählte Präfix akzeptabel oder unakzeptabel ist.</sample>
    <sample id="588">Jetzt ist dies und das ist sehr groß, wie dieser Effekt durch den Kontext länger wird und dies würde wahrscheinlich die neueren Sprachmodelle beeinflussen, die große Kontextfenster haben.</sample>
    <sample id="589">Der englische Text lautet: "So why does the match prefix affect the language model judgment so much?"

Die Übersetzung ins Deutsche lautet: "Warum beeinflusst der Präfix "match" so stark die Sprachmodellbewertung?"</sample>
    <sample id="590">So we did a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure but adding  uh  like noise to the input and after doing like several of these perturbations</sample>
    <sample id="591">Wir stellen fest, dass keine dieser Störungen tatsächlich dazu führen, dass das Modell entscheidend verändert, wie es uns die mpp-Verbindung zeigt.</sample>
    <sample id="592">Grundsätzlich stellen wir fest, dass die Modelle empfindlich auf die Perturbationen und Sätze in ähnlicher Weise reagieren.</sample>
    <sample id="593">Das bedeutet, dass wenn wir die Sätze in der akzeptablen Domain stören, wir einen ähnlichen Anstieg in allen Störungen sehen. Und wenn wir die Sätze in der unakzeptablen Domain stören, sehen wir eine Abnahme in den mpp-urteilen in ähnlicher Weise.</sample>
    <sample id="594">So the key takeaways of our work is that language models are sensitive to latent syntactic and semantic features which are shared across the sentences.</sample>
    <sample id="595">Und die MPP-Evaluation, die wir derzeit mit kurzen und einzelnen Satz-Eingaben durchführen, kann möglicherweise nicht die abstrakte Kenntnisse des Sprachmodells in ihrem gesamten Kontext vollständig erfassen.</sample>
    <sample id="596">Bitte lesen Sie unsere Arbeit für weitere Details zu unseren Experimenten. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="597">In the first step of the method, each input token is tagged with an unordered multiset of tokens that will appear in the output.</sample>
    <sample id="598">55,000</sample>
    <sample id="626">Die beste Ausrichtungsmethode für DEPlain ist die Methode des Massenaligns.</sample>
    <sample id="627">Der Vorteil von schwach überwachtem Lernen ist, dass es trainierte neuronale Netzwerke unter solchen Label-Rauschen robust trainiert, sodass die trainierten Modelle gut generalisieren.</sample>
    <sample id="628">Die Dokumente in DEplain-web waren mit manuellen und automatischen Alignment-Methoden ausgerichtet. Die Zuteilung der Dokumente zu den verschiedenen Alignment-Methoden war jedoch nicht genau beschrieben. Es wurde nur angegeben, dass manuelle und automatische Methoden verwendet wurden, aber keine spezifischen Details über die Zuteilung der Dokumente an die jeweiligen Methoden angegeben.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde durch das Sammeln von Roiter's News aus dem Jahr 2020 erstellt und anschließend mit den gleichen CoNLL-2003-Anmerkungsrichtlinien annotiert.</sample>
    <sample id="630">Hallo alle, mein Name ist Yusen Zhang und ich komme aus der Pennsylvania State University. Heute werde ich über unsere Arbeit sprechen, nämlich "Crosslingual Semantic Parsing in Multiple Natural Languages and Minimal Representations".</sample>
    <sample id="631">So semantic parsing is the task to build semantic representations of user queries such as SQL and lambda calculus.</sample>
    <sample id="632">Cross-lingual semantic parsing is the task of translating queries in multiple natural languages into multiple meaning representations.</sample>
    <sample id="633">Wie in diesem Bild gezeigt, benötigen wir, um die Abfrage in mehreren natürlichen Sprachen zu übersetzen, die mit neuronalen Modellen zu SQL, Lambda oder FunktionQL und dergleichen.</sample>
    <sample id="634">Existierende Cross-Linguistic Semantic Parsing-Modelle werden separat vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen evaluiert. Zum Beispiel</sample>
    <sample id="635">Es gibt einen Mangel an Abdeckung für bestimmte natürliche Sprachen. Die chinesische Sprache fehlt dabei.</sample>
    <sample id="636">The coverage of certain minor representations is lacking.</sample>
    <sample id="637">Der Lambda-Kalkulus fehlt.</sample>
    <sample id="638">Oder sie werden nur auf bestimmte neuronale Modelle ausgewertet, beispielsweise gibt es nur ein einziges Modell, um sie zu bewerten.</sample>
    <sample id="639">Um zu diesem Ende schlagen wir den Exemplar vor, der eine einheitliche Datensatz-Exemplar für die Übersetzung von semantischen Inhalten in mehreren natürlichen Sprachen und mehreren Repräsentationen bereitstellt.</sample>
    <sample id="640">Es enthält neun Datensätze in verschiedenen Bereichen, fünf semantische Parsing-Tasks, acht Minuten-Repräsentationen und zweiundzwanzig natürliche Sprachen in fünfzehn Sprachfamilien.</sample>
    <sample id="641">Um unsere Benchmarking besser zu bewerten, berücksichtigen wir die sechs Einstellungen für Training und Evaluierung.</sample>
    <sample id="642">Der erste Teil ist der Übersetzungstest. Wir verwenden die Google-Übersetzungs-API, um die Quelle in die Zielsprache zu übersetzen, dann verwenden wir ein monolinguales Modell, um es zu trainieren und zu bewerten.</sample>
    <sample id="643">Und zum Beispiel trainieren wir das englische Modell auf englischen Abfragen und während des Inferenzes übersetzen wir die deutsche Abfrage mit der API ins Englische und verwenden dann das trainierte Modell, um das Ziel zu vorhersagen.</sample>
    <sample id="644">Wir werden auch den monolingualen Modelltest durchführen.</sample>
    <sample id="645">In diesem Szenario ist die Quellsprache die gleiche wie die Zielsprache, zum Beispiel Deutsch auf Deutsch oder Englisch auf Englisch.</sample>
    <sample id="646">Wir testen auch monolinguale Führungseinstellungen, indem wir Modelle mit nur 10 % des Trainingsdatensatzes trainieren.</sample>
    <sample id="647">Und wir testen ein multilinguelles Modell, bei dem wir einen Modell für alle Sprachen trainieren.</sample>
    <sample id="648">Zum Beispiel **wir setzen die deutschen, englischen und chinesischen Abfragen zusammen, um ein mehrsprachiges Modell zu trainieren**, und während des Inferenzes **können wir dieses Modell verwenden, um**</sample>
    <sample id="649">Um zu übersetzen, müssen wir die englischen Anweisungen in die gewünschte Sprache übersetzen. Hier sind die Anweisungen in Deutsch:

1. Um französische Anweisungen zu übersetzen, müssen Sie die englischen Anweisungen in französisch übersetzen.
2. Um spanische Anweisungen zu übersetzen.
3. Um italienische Anweisungen zu übersetzt.
4. Um niederländische Anweisungen zu übersetze.
5. Um portugiesische Anweisungen zu übersetten.
6. Um russische Anweisungen zu übersetzten.
7. Um japanische Anweisungen zu übersetzer.
8. Um koreanische Anweisungen zu übersetter.
9. Um indonesische Anweisungen zu übersettern.
10. Um türkische Anweisungen zu übersetzzen.
11. Um hebräische Anweisungen zu übersetzes.
12. Um griechische Anweisungen zu übersetzers.
13. Um aramäische Anweisungen zu übersetzten.
14. Um persische Anweisungen zu übersetters.
15. Um afrikaansche Anweisungen zu übersetzerz.
16. Um ukrainische Anweisungen zu übersetzs.
17. Um bulgarische Anweisungen zu übersetzens.
18. Um ukrainische Anweisungen to übersetzer.
19. Um türkische Anweisung zu übersetzer.
20. Um türkische Anweistung zu übersetzer.
21. Um türkische Anweistungen zu übersetzer.
22. Um türkische Anweistungs zu übersetzer.
23. Um türkische Anweistungs zu übersetzer.
24. Um türkische Anweistunge zu übersetzer.
25. Um türkische Anweistunger zu übersetzer.
26. Um türkische Anweistunsger zu übersetzer.
27. Um türkische Anweistuntsger zu übersetzer.
28. Um türkische Anweistuntunger zu übersetzer.
29. Um türkische Anweistunteger zu übersetzer.
30. Um türkische Anweistegeger zu übersetzer.
31. Um türkische Anweistegetger zu übersetzer.
32. Um türkische Anweistegetsger zu übersetzer.
33. Um türkische Anweistegettger zu übersetzer.
34. Um türkische Anweiste getger zu übersetzer.
35. Um türkische Anweiste geger zu übersetzer.
36. Um türkische Anweiste gegetger zu übersetzer.

Bitte beachten Sie, dass die Anweisungen in der Liste nicht vollständig sind und möglicherweise fehlerhaft sind. Es ist wichtig, dass Sie die korrekten Anweisungen verwenden, um eine genaue Übersetzung zu erhalten.</sample>
    <sample id="650">Wir berücksichtigen auch das Crosslingual Zero-shot und Few-shot Transfer. Wir trainieren auf einer Quellsprache und übertragen auf eine andere Sprache.</sample>
    <sample id="651">Während des Trainings werden wir es auf Englisch oder auf der Kombination von Englisch und Deutsch trainieren, um ein mehrsprachiges Modell zu trainieren, um die Sequenz vorherzusagen.</sample>
    <sample id="652">Und wir finden auch viele interessante Ergebnisse. Daher beurteilen wir die Analyse von monolingualen Modellen auf zwei Gruppen von Modellen.</sample>
    <sample id="653">Der englische Text beschreibt verschiedene Typen von Encoder-PTR (Pointer-based Decoders), die speziell für mehrere Sprachen (Multilingual) entwickelt wurden. Diese Encoder-PTRs sind in Kombination mit Pointer-based Decoders wie XLM-R+PTR und BERT+PTR verwendet werden.

Hier ist eine mögliche Übersetzung des Textes ins Deutsche:

---

**Übersetzung:**

**"Umfasst Encoder-PTR, die für mehrere Sprachen (multilingual) entwickelt wurden, und Pointer-based Decoders wie XLM-R+PT und BERT+PT."**

---

**Erklärung:**

- **Encoder-PTR:** Diese bezeichnen spezielle Encoder-Modelle, die für mehrere Sprachengruppen (Multilingual) optimiert sind. Sie sind in der Lage, Texte in verschiedene Sprachen zu verarbeiten und zu verstehen.
  
- **Pointer-based Decoders:** Diese sind Decoder-Modelle, die auf einem Punkt-basierten Ansatz arbeiten. Sie helfen dabei, die Ausgabe des Encoder-PTRs zu interpretieren und zu verwenden.

- **XLM-R+PTR und BERT+PTR:** Diese sind spezifische Implementierungen von Encoder-PTRs, die mit Pointer-based Decoders kombiniert werden, um die Leistung in mehreren Sprachen zu verbessern.

---

**Zusammenfassung:**

Der Text beschreibt, dass Encoder-PTRs für mehrere Sprachen entwickelt wurden und in Kombination mit Pointer-based Decoders (wie XLM-R+PTR und BERT+PT) verwendet werden, um die Verarbeitung und Interpretation von Texten in verschiedenen Sprachen zu verbessern.</sample>
    <sample id="654">Und wir haben auch Evaluations-Encoder-Dekoder-Modelle, die multilingual pretrain-Encoder-Dekoder-Modelle umfassen, wie zum Beispiel mBART und mT5.</sample>
    <sample id="655">Wir haben gefunden, dass der Encoder-Decoder die beste Leistung auf allen neun Datensätzen erzielt.</sample>
    <sample id="656">Und wir evaluieren auf mt5 und einem Beispiel xlmr plus pdr in einem mehrsprachigen Umfeld.</sample>
    <sample id="657">Wir haben gefunden, dass Encoder-Decoder oder Encoder-PDR durch Training in einer Mischung aus verschiedenen Sprachen verbessert werden kann.</sample>
    <sample id="658">Wir fanden heraus, dass es wegen der Tatsache ist, dass die meisten der wichtigsten natürlichen Sprachen eine Leistungssteigerung erreichen können, mit Ausnahme der englischen Leistung, die in sieben Datensätzen sinkt und nur in drei Datensätzen steigt.</sample>
    <sample id="659">Ich denke, das ist bekannt als "Kurz der Mehrsprachigkeit".</sample>
    <sample id="660">Wir vergleichen auch den Cross-Lingual Performance Gap.</sample>
    <sample id="661">In this figure, the blue line is cross-lingual few-shot transfer, the orange line is cross-lingual zero-shot transfer, while the green line is the monolingual setting.</sample>
    <sample id="662">Wir haben gefunden, dass bei der Verwendung der grünen und orange Linie die Null-Shot-Einstellung die Cross-Lingo-Transfer-Performance-Gap signifikant ist. Bei der Verwendung der blauen und orange Linie ist die Transfer-Gap bei der Fünf-Shot-Einstellung schnell verkürzt.</sample>
    <sample id="663">Wir finden auch einige andere interessante Ergebnisse. Zum Beispiel: Der Encoder-Decoder-Algorithmus erreicht vergleichbare Ergebnisse wie der vorherige Algorithmus. Die Verwendung von englischen natürlichen Sprachen kann die Leistung von Führungssystemen in Zielsprachen erheblich verbessern.</sample>
    <sample id="664">Wir haben gefunden, dass modellsprachliche Sprachmodelle wie Codex und Blue für viele sprachübergreifende Parsingaufgaben noch unzureichend sind.</sample>
    <sample id="665">Zusammenfassend werden wir einen Exemplar erstellen, ein vereinfachtes Benchmark für die semantische Parsing von Texten in mehreren natürlichen Sprachen mit vielen verschiedenen Repräsentationen.</sample>
    <sample id="666">Wir werden eine umfassende Benchmark-Studie über drei repräsentative Typen von mehrsprachigen Sprachmodellen durchführen, und unsere Ergebnisse zeigen viele interessante Erkenntnisse und cetera. Willkommen zu unserem Paper und Code. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="667">Existing works can be broadly classified into four categories.</sample>
    <sample id="668">No, multilingual language models such as Codex and Bloom are still inadequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="695">Die Methode mit der Mehrdeutigkeitsproblematik der Permutationen umfasst die Induktion der Alignment als Teil des Trainings. Diese Methode ist sehr flexibel, aber sie bringt die Herausforderung mit sich, die höchste Scoring-Permutation als NP-Hard zu finden. Dies ist aufgrund der Verbindung zur Reiseverkäuferproblematik. Um dies zu lösen, verwendet die Methode eine GPU-befreundliche kontinuierliche Relaxation, die auch es ermöglicht, durch die Lösung zurückzutreten und die linguistisch plausiblen Permutationen zu lernen.</sample>
    <sample id="696">Die Fairness eines nachgeschaltet NLP-Modells wird definiert als die Gleichbehandlung von Benutzern unabhängig von ihren politischen Überzeugungen oder ihrem sozialen Status. Es bedeutet, dass das Modell keine Vorurteile oder Diskriminierung gegenüber bestimmten Gruppen oder Individuen hat, sondern stets objektiv und unabhängig von politischen oder sozialen Faktoren arbeitet.</sample>
    <sample id="697">Janis Lavak</sample>
    <sample id="698">Der/die Referent*in heißt **Kostas Sina**.</sample>
    <sample id="699">Myra</sample>
    <sample id="700">Tropikalismus bezieht sich auf die Verwendung von tropischen Metaphern und Symbolen, um die kulturelle und soziale Dynamik in den jeweiligen Regionen zu beschreiben.</sample>
    <sample id="701">Die Autoren haben die Beschreibungen der Zielgruppensprache erstellt, indem sie die Wörter und Phrasen aus den Beschreibungen der Zielgrupps ausgewählt haben, die die Kultur, Tradition, Stolz und Exotik betonen. Diese Wörter definieren die Zielgruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie von der weißen Norm.</sample>
    <sample id="702">In dieser Arbeit wurde die Pointwise CXMI verwendet, um den Kontextnutzung auf der Satz- oder Wortebene zu messen.</sample>
    <sample id="703">DrBERT has 7GB of natural language processing (NLP) data, while ChuBERT has 4GB of NLP data. DrBERT is a clinical model with 4GB of sentences taken from clinical notes, while ChuBERT is a clinical model with a mix of 4GB of NLP data and 4GB of clinical notes.</sample>
    <sample id="751">Drei Autoren sind an der Arbeit beteilt: Ying, Zhiyang und der Kollege.</sample>
    <sample id="752">Iteratives Transferlernen ist ein Verfahren, bei dem ein Modell iterativ mit neuen Daten aktualisiert wird, um seine Leistung zu verbessern. Es besteht aus mehreren Schritten:

1. **Aktive Lernen**: Neue Daten werden gesammelt und aktiv verwendet, um das Modell zu trainieren.
2. **Annotationen**: Die neuen Daten werden mit Labels oder Annotations versehen, um sie für das Modell zu verwenden.
3. **Modellaktualisierung**: Das Modell wird iterativ mit den neuen Daten aktualisiert, um seine Genauigkeit und Leistung zu verbessern.

Es gibt zwei Hauptmethoden:

- **Cumulative**: Alle Daten, die bisher gesammelt wurden, werden verwendet, um das Modell zu aktualisieren.
- **Iterative**: Das Modell wird nur mit den neuesten Daten aktualisiert, um schneller zu reagieren und die Leistung zu verbessern.</sample>
    <sample id="753">The goal of the dataset is to understand users' language when they want to make a choice.</sample>
    <sample id="754">Ein Angreifer kann Modellparameter über einen EaaS extrahiert, indem er die Anforderungen und die Leistungsfähigkeit des Modells analysiert und dann die notwendigen Parameter anpassen, um die Anforderungen zu erfüllen.</sample>
    <sample id="755">Drei Autoren sind an der Arbeit beteilt.</sample>
    <sample id="756">The original dataset was created using 10 annotators.</sample>
    <sample id="757">Die Autoren gehören an der Universität Washington.</sample>
    <sample id="758">I saw bart and lisa, so the governor is on the left.</sample>
    <sample id="759">Der Stand der Technik für Dialogsysteme, einschließlich Chatbots und KI-gestützter Sprachmodelle, basiert auf fortschrittlichen natürlichen Sprachverarbeitung (NLP) und maschinellem Lernen. Diese Systeme nutzen tiefe neuronale Netze, wie Transformer-Modelle (z. B. GPT-3), um Kontexte zu verstehen und relevante Antworten zu generieren. Die Technologie ermöglicht es, komplexe und natürliche Interaktionen mit Benutzern zu ermöglichen, indem sie die Sprache verstehen und darauf reagieren kann. Weitere Fortschritte umfassen die Integration von Emotionen, die Analyse von Meinungen und die Personalisierung von Interaktionen.</sample>
    <sample id="760">Wir müssen die Akzeptanz der Modelle über den gesamten Kontextfenster bewerten, um sicherzustellen, dass sie in verschiedenen Kontexten korrekt verwendet werden und keine Fehler oder Unstimmigkeiten erkennen können.</sample>
    <sample id="761">Yes, the multilingual training has led to a performance drop in comparison to the monolingual English model, except for three datasets where it has gained performance. This phenomenon is known as the "curse of multilinguality."</sample>
    <sample id="762">Yes, the annotators know the name of the entities in the alternative question. However, they may not necessarily know about the entities.</sample>
    <sample id="763">Die Bewertung von MT-Metriken (Machine Translation Metrics) wird häufig für die Beurteilung der Qualität von maschinellen Übersetzungen verwendet. Hier sind einige der am häufigsten verwendeten MT-Metriken:

1. **BLEU (Bilingual Evaluation Understudy)**: Dies ist eine der am weitesten verbreiteten Metriken zur Bewertung von Maschinenübersetzungen. Es misst die Übereinstimmung der Übersetzung mit mehreren Referenzübersetzungen.

2. **METEOR (Metric for Evaluation of Translation with Explicit ORdering)**: Diese Metrik berücksichtigt nicht nur Übereinstimmungen, sondern auch die Grammatik und die Struktur der Übersetzung.

3. **TER (Translation Edit Rate)**: Diese Metrik misst die Anzahl der Edits (Einfüge, Löschen, Änderungen) erforderlich, um die Maschinenübersetzung zu einer Referenzübersetzung zu machen.

4. **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**: Diese Metrik wird hauptsächlich für die Bewertung von Textzusammenfassungen verwendet, aber sie kann auch für die Bewertung von Übersetzungen verwendet werden.

5. **CIDEr (Consensus-based Image Description Evaluation)**: Diese Metrik wird hauptsfächlich für die Bewertung der Qualität von Bildbeschreibungen verwendet, aber sie kann auch auf Übersetzungen angewendet werden.

6. **WER (Word Error Rate)**: Diese Metrik misst den Anteil der Wörter, die in der Maschinenübersetzung fehlerhaft oder fehlgeleitet sind.

7. **BLEU-4**: Dies ist eine Variante von BLEU, die die Übereinstimmung mit vier Referenzübersetzungen misst.

8. **NIST (National Institute of Standards and Technology)**: Diese Metrik misst die Übereinstimmung mit mehreren Referenzähnlichkeiten.

9. **BERTScore**: Diese Metrik basiert auf der Verwendung von BERT (Bidirectional Encoder Representations from Transformers) und misst die Ähnlichkeit zwischen der Maschinenübersetzung und den Referenzübersetzungen.
10. **SPICE (Semantic PHrase Intensity-based CIDEr)**: Diese Metrik misst die Qualität der Übersetzung basierend auf der Semantik und der Struktur der Phrasen.

Diese Metriken können in verschiedenen Kombinationen verwendet werden, um die Qualität von Maschinenübersetzungen zu bewerten.</sample>
    <sample id="764">Die Regression bei der Generalisierung hat keinen signifikanten Einfluss auf bestimmte NER-Typen.</sample>
    <sample id="765">Positionalität ist für NLP wichtig, weil sie die Anordnung von Wörtern in einem Satz berücksichtigt. Dies ist wichtig, weil die Bedeutung von Wörtern im Satz von ihrer Position abhängt. Wenn die Position von Wörtern verändert wird, kann die Bedeutung des Satzes verändert werden. Positionalität ist besonders wichtig für die Verarbeitung von natürlichen Sprachen, da die Anordnung von Wörtern im Satz oft die Bedeutung des Satzes beeinflusst.</sample>
    <sample id="766">Multilingual Large Language Models (LLMs) like BLOOM are typically fine-tuned rather than adapted using adapters. Fine-tuning involves training the model on a specific dataset to improve its performance on a particular task or set of tasks. This process allows the model to learn the nuances and specificities of the target language or domain.

Adapters, on the other hand, are a type of model architecture that allows for more efficient and flexible adaptation of pre-trained models to new tasks or languages. Adapters are typically added to the pre-trained model as additional layers, which can be trained or fine-tuned independently of the original model. This approach can be more efficient than fine-tuning the entire model, especially when dealing with large models like BLOOM.

In summary, while adapters can be used to adapt pre-trained models to new tasks or languages, fine-tuning is the more common approach for adapting multilingual LLMs like BLOOM.</sample>
    <sample id="767">Das Modell, das für das Transferlernen verwendet wird, ist das CeE-Modell. Es basiert auf der Konzeption von Konsonanten und Distanz und wird auf der Analyse der Datenmenge von 0,62 AUC-Punkten optimiert. Nach iterativer Feinabstimmung auf beiden Aufgaben erzielt das CeE-Modell eine deutlich bessere Leistung als Chance.</sample>
    <sample id="768">Die aktuellen Testsets zur Bewertung der PaLM-Fäbigkeiten umfassen eine Vielzahl von Datensätzen, die verschiedene Aspekte der Sprachverarbeitung abdecken. Hier sind einige der wichtigsten:

1. **GLUE (General Language Understanding Evaluation)**: Dies ist ein Benchmark, der verschiedene Aufgaben zur Bewertung der allgemeinen Sprachverarbeitung umfasst, wie z.B. Textvergleich, Sentimentanalyse und Fragenbeantwortung.

2. **SuperGLUE**: Ein weiterer Benchmark, der die Leistung von Sprachmodellen auf verschiedenen Aufgaben wie Textverarbeitung, Textgenerierung und Fragenbeantwortung testet.

3. **SQuAD (Stanford Question Answering Dataset)**: Ein Benchmark, der die Fähigkeit von Sprachmodellen zur Beantwortung von Fragen auf Basis von Textdaten testet.

4. **CoQA (Conversational Question Answering)**: Ein Benchmark, der die Fäh能力 von Sprachmodellen zur Beantwortungs von Fragen in Dialogen testet.

5. **Winograd Schema Challenge**: Ein Benchmark, der die Fähigkeit der Sprachmodelle zur Verständigung von Kontext und zur Beantwortung von Fragen über Ambiguitäten testet.

6. **LAMBADA**: Ein Benchmark, der die Fähigung der Sprachmodelle zur Verständnis von kontextuellen Wörtern testet.

7. **WMT (Workshop on Machine Translation)**: Ein Benchmark, der die Fähgkeit von Sprachmodellen zur maschinellen Übersetzung von Texten testet.

8. **XNLI (Cross-lingual Natural Language Inference)**: Ein Benchmark, der die Fähung der Sprachmodelen zur Verständigung von Texten in verschiedenen Sprachen testet.

Diese Testsets helfen dabei, die Leistung von Sprachmodellen wie PaLM auf verschiedenen Aspekten der Sprachverarbeitung zu bewerten und zu vergleichen.</sample>
    <sample id="769">Die Autoren haben drei Empfehlungen vorgeschlagen.</sample>
    <sample id="770">The proposed method achieves a higher accuracy than the strongest baseline.</sample>
    <sample id="771">Der/die Referent*in heißt Shuhang.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensät der Studie können als Benchmark verwendet werden.</sample>
    <sample id="773">In der Arbeit wird experimentiert, wie viele kleinere Modelle unterstützt werden können, um größere Modelle zu übertragen, wenn sie auf geeignete Datensätze trainiert werden.</sample>
    <sample id="774">OFA (Unified Multimodal Pretrained Model) wird als Basismodell verwendet.</sample>
    <sample id="833">Die Autoren gehören an der Universität von Google Translate.</sample>
    <sample id="834">Stony Brook University.</sample>
    <sample id="835">The text does not mention any specific language pairs that were studied in the work. It only mentions the use of state-of-the-art neural machine translation metrics and expert-based human evaluation results.</sample>
    <sample id="836">Der/die Referent*in heißt Shuangbin.</sample>
    <sample id="837">Während der Experimente wurden zwei Modelle untersucht: 
1. Das Modell der langen Impart, das auf Dokumentebene vereinfacht wurde. 
2. Das Modell der normalen Basis Impart, das auf Satzebene vereinfacht wurde.</sample>
    <sample id="838">53 Aufgaben werden für Training verwendet und die gesamte Commonsense Reasoning Gruppe wird für Tests reserviert.</sample>
    <sample id="839">Three authors are involved in the work.</sample>
    <sample id="840">Die Autoren haben Experimente auf vier Datensätzen durchgeführt: **ag news**, **mind**, **ssd2** und **eris spam**.</sample>
    <sample id="876">NACHOS ist ein Datensatz von medizinischer Kronen-Daten, auf dem das Modell "Doctor Bert" trainiert wurde.</sample>
    <sample id="877">Der/die Referent*in heißt Aid Bilal.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse.</sample>
    <sample id="879">Die Autoren gehören an der Universität von Cambridge.</sample>
    <sample id="880">1. We are collecting a much larger multimodal instruction tuning dataset with around 150 additional vision language tasks, and we will release them soon.
2. This is a QR code for our data and model. Thank you.</sample>
    <sample id="881">Die Autoren schlagen vor, die Fähigkeit von Modellen zur Nutzung von Informationen aus mehr als einer Quelle zu testen, indem sie eine Coreference Resolution Task einführen. Diese Aufgabe ist darauf ausgelegt, die Fähigkeit von Modellen zu bewerten, auf Wissen aus verschiedenen Quellen zurückgreifen zu können. Sie evaluieren das Datenset mit human study participants und stellen eine Coreference Resolution Modelle auf.</sample>
    <sample id="882">Hallo alle, mein Name ist Aidy Villar und ich werde eine kurze Übersicht über den Paper "Printing Pattern for Translation: Assessing Strategies and Performance" geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate.</sample>
    <sample id="883">Baram ist ein Sprachmodell mit 540 Milliarden Parametern, das im Jahr 2022 präsentiert wurde. Es wurde auf einer großen Menge von Texten trainiert, die insgesamt 780 Milliarden Tokens umfassen.</sample>
    <sample id="884">In der damaligen Fertigung erreichte es den Staat der Kunst in Hunderten von Nlp-Aufgaben.</sample>
    <sample id="885">In diesem Werk präsentieren wir die erste systematische Studie der 

"large language model prompting" für maschinelle Übersetzung.</sample>
    <sample id="886">Wir haben die Übergangsleistung solcher Modelle mit den besten Praktiken der GPT-Community bewertet. Dies beinhaltet das Verwenden der neuesten Testdatensätze, um eine Überlappung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden.</sample>
    <sample id="887">Wir vergleichen zwei hochmoderne Systeme. Die besten Leistungssysteme sind die WMT-Evaluationen.</sample>
    <sample id="888">Wir verwenden hochmoderne neue LMT-Metriken und zeigen zusätzlich die Ergebnisse einer Expertenbewertung. Schließlich geben wir einige Empfehlungen für Problemlösungsstrategien.</sample>
    <sample id="889">Die Anweisung hat einen großen Einfluss auf die Leistung von LLMs für Übersetzung, wie wir in einem einfachen Experiment sehen können, bei dem wir eine kurze Anweisung verwendet haben und zwei verschiedene Prompts für die Übersetzung von Sätzen bereitgestellt haben.</sample>
    <sample id="890">Die Mehrheit der Sätze, nämlich 516 von 1000, zeigt einen Unterschied von mehr als einem Blurpunkt.</sample>
    <sample id="891">Und das kann in extremen Fällen bis zu 40 Punkten gehen. Daher ist es wichtig, eine gute Ansprache-Strategie zu wählen.</sample>
    <sample id="892">In unseren Experimenten haben wir uns für eine fünf-Schuss-Prompting-Strategie entschieden, bei der wir jedes entsprechende Satz, das wir dem System zur Verfügung stellen, mit der entsprechenden Sprache markieren.</sample>
    <sample id="893">In this example, we are performing a translation from German to English. The German sentences, which are the source sentences, are marked with a German colon (:) and the English translations are marked with an English colon (:).</sample>
    <sample id="894">Wir haben gesehen, dass die tatsächliche Form des Druckens keinen großen Einfluss auf den Fall hat, wenn es sich um serielle Schrift-Druck handelt.</sample>
    <sample id="895">Es ist entscheidend für Null- und Einschussbefehle und wenn wir, wie in unserem Fall zu fünf Schussbefehlen gehen, gibt es praktisch keinen Unterschied zu der tatsächlichen Form des Befehls.</sample>
    <sample id="896">Es sind die Beispiele, die die meisten der Gewichte tragen.</sample>
    <sample id="897">Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zu der Quelle.</sample>
    <sample id="898">Es ist wichtig, Beispiele aus hochwertigen Übersetzungen auszuwählen. Besonders wir vergleichen die Auswahl von Prompts aus dem Trainingsdaten des WMT-Evaluations oder dem Dev-Daten.</sample>
    <sample id="899">Der Dev-Daten ist viel mehr gekürt und mit höherer Qualität als die Trainingsdaten, was bedeutet, dass die Ergebnisse besser sind, wenn man die Dev-Daten verwendet.</sample>
    <sample id="900">The specialized state-of-the-art systems have a substantial advantage over the current translations, but Google Translate comes pretty close to a commercial system. In our case, we chose to overlay it with Google Translate.</sample>
    <sample id="901">Die Erkenntnisse, die wir aus der humanen Evaluierung gewonnen haben, die wir mit dem MQM-Framework durchgeführt haben, sind, dass die Fluenz von Palm vergleichbar mit dem Zustand der Art-Systeme ist, aber die Hauptdifferenz kommt von der Genauigkeit.</sample>
    <sample id="902">In particular, the most common error are omission errors.</sample>
    <sample id="903">Es scheint so, dass Palm den Namen wählt, um eine bessere Übersetzung zu erzeugen, manchmal indem es Teile des ursprünglichen Satzes wegnimmt, die in der Übersetzung nicht erforderlich sind.</sample>
    <sample id="904">Allerdings ist der Stil-Äußerungskategorie für Panis niedriger als für den Zustand der anderen Systeme, was ein zusätzliches Signal darstellt.</sample>
    <sample id="905">"Dieser Parameter liefert wirklich flüssigen Output, aber steht mit einigen Problemen der Genauigkeit."</sample>
    <sample id="906">Und das ist es für diese wirklich kurze Übersicht. Für weitere Details, bitte komme zu meiner vollständigen Präsentation des Papiers. Vielen Dank sehr viel.</sample>
    <sample id="907">Hallo, ich bin Dawei, ein Doktorand an der Universität Stuttgart in Deutschland. In diesem Video möchte ich unsere neueste Arbeit präsentieren: "Wie wichtiger ist es, dass Sie mehr über die Welt erfahren?" Eine kritische Analyse der Weltweit-Unterstützung für Lernende.</sample>
    <sample id="908">Dies ist eine gemeinsame Arbeit mit Xiaoyu Shen, Maoyu Smoothbass und Gia Stephen und Ditich Clacko.</sample>
    <sample id="909">Ich möchte mit einer kurzen Einführung in die Wochenschau und die Wochenüberwachung beginnen.</sample>
    <sample id="910">In weak supervision, you do not manually label the data. Instead, you label the data using weak labeling sources such as simple heuristic rules, knowledge bases, or low-quality crowdsourcing. As illustrated in the figure on the right.</sample>
    <sample id="911">Im Vergleich zu menschlichen Annotationen sind die visuelle Annotationen viel günstiger, jedoch sind sie auch raucher, was bedeutet, dass ein bestimmter Anteil der Annotationen falsch ist.</sample>
    <sample id="912">Wenn wir neuronale Netzwerke direkt auf wöchentliche Label-Daten trainieren, neigen sie dazu, die Label-Noise zu merken und nicht zu generalisieren.</sample>
    <sample id="913">In weakly supervised learning, training algorithms are proposed to robustly train neural networks under such label noise, so that the trained models still generalize well.</sample>
    <sample id="914">In recent works in WSL, so WSL stands for weekly supervised learning, a common claim is that people say that the only tree models on the weekly label data and achieve high performance on clean test sets.</sample>
    <sample id="915">Technisch gesehen ist dieser Anspruch nicht falsch, aber es gibt eine Einschränkung.</sample>
    <sample id="916">Welches ist das, was Menschen annehmen, dass es ein zusätzliches saubere Validierungsset für die Modellauswahl gibt?</sample>
    <sample id="917">Wir haben dieses Problem aufgegeben, da dies bedeutet, dass zusätzliche manuelle Anmerkungen bei der wöchentlichen Überwachung benötigt werden, aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen.</sample>
    <sample id="918">The aforementioned doubt leads us to ask three research questions. First, is clean validation data necessary for WSL? Or can we maybe use a noisy validation set instead?</sample>
    <sample id="919">Second, if clean data is required or if clean data is mandatory for WSL to work, then how many clean samples do we need? Finally, should we only use the clean samples for validation, or are there better ways to utilize them?</sample>
    <sample id="920">Wir haben diese Forschungsfragen in unserer Arbeit behandelt und unsere Ergebnisse sind wie folgt:</sample>
    <sample id="921">Erstens stellen wir fest, dass interessanterweise die neuesten WSL-Methoden tatsächlich reinige Wasserproben benötigen, um ordnungsgemäß zu funktionieren.</sample>
    <sample id="922">Andernfalls besteht ein großer Leistungsabfall, wie in diesem Bild gezeigt, wenn es keine reinen Validierungsstichproben gibt. Dann können die Trainingsmodelle nicht über die ursprünglichen Wertebereiche hinaus generalisieren.</sample>
    <sample id="923">The meaning of training is pointless.</sample>
    <sample id="924">Dies zeigt, dass WSL-Ansätze tatsächlich sauber gelabelte Daten benötigen, um korrekt zu funktionieren, und dass die Kosten für die Erhaltung sauber gelabelter Validierungsstücke nicht übersehen werden sollten.</sample>
    <sample id="925">Unser zweiter Befund ist, dass die Erhöhung der Anzahl der reinen Validierungsstichproben dazu beiträgt, dass WSL-Ansätze besser abschneiden, wie in der Abbildung auf der linken Seite gezeigt.</sample>
    <sample id="926">Typischerweise benötigen wir nur 20 Stichproben pro Klasse, um hohe Leistung zu erreichen.</sample>
    <sample id="927">Aber das ist nicht das Ende der Geschichte, denn wenn wir entweder Entscheidung treffen, um saubere Proben zu erhalten, dann wird die Ausbildung auf ihnen direkt noch besser sein.</sample>
    <sample id="928">The right figure shows the performance difference between fine-tuning approaches, which are directly applied on the clean data, and WSL approaches, which use the clean data for validation only.</sample>
    <sample id="929">Wie wir sehen können, wenn wir 10 Stichproben pro Klasse haben, beginnt die direkte Feinabstimmung, um die WSL-Ansätze zu schlagen.</sample>
    <sample id="930">Schließlich kann die von früheren WSL-Ansätzen behauptete Leistungssteigerung leicht erreicht werden, indem man es ermöglicht, die Feinabstimmung auf saubere Validationsstichproben fortzuführen.</sample>
    <sample id="931">Wie wir aus den Bildern sehen können, ist das Valina-Modell, das als FTW bezeichnet wird, zunächst unterperformt, wenn es mit komplexeren WSL-Methoden wie Cosine vergleicht.</sample>
    <sample id="932">Wenn wir jedoch weiterhin auf die reinen Proben funktionieren lassen möchten, dann leistet FTW genauso gut wie andere Methoden.</sample>
    <sample id="933">In der Praxis gibt es keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher benötigen.</sample>
    <sample id="934">Zusammenfassend zeigen wir, dass neue WSL-Ansätze benötigen saubere, manuell annotierte Beispiele, damit sie ordnungsgemäß funktionieren. Ihre Leistungssteigerung und Praktikabilität werden stark überschätzt.</sample>
    <sample id="935">Unsere konkreten Empfehlungen für zukünftige Arbeit lauten wie folgt:</sample>
    <sample id="936">Zuerst berichte über die Kriterien für die Modellauswahl. Zum Beispiel berichte, ob die Modellauswahl mit sauberen Validierungsstichproben durchgeführt wurde.</sample>
    <sample id="937">Second, WSL approaches should be compared with few-shot learning baselines, as both work on clean samples. Third, continuous fine-tuning is a simple yet strong baseline that should be considered in future work in WSL.</sample>
    <sample id="938">Schritt 1: Identifizieren Sie die Hauptpunkte des englischen Textes.
- Open source our code
- You can find it via the QR code on this slide
- Please feel free to check it out
- Thank you and enjoy the conference

Schritt 2: Übersetzen Sie jeden Satz einzeln ins Deutsche.
- Open source our code -&gt; Öffnen Sie unser Code
- You can find it via the QR Code on this slide -&gt; Sie können es über den QR-Code auf dieser Folie finden
- Please feel free to check it out -&gt; Bitte unternehmen Sie sich selbst keine Sorgen
- Thank you and enjoy the conference -&gt; Danke und genießen Sie die Konferenz

Schritt 3: Kombinieren Sie die übersetzten Sätze zu einem kohärenten deutschen Text.

Schritt 4: Überprüfen Sie den deutschen Text auf Grammatikalische und stilistische Fehler.

Schritt 5: Fügen Sie eventuell notwendige Ergänzungen hinzu, um den deutschen Text vollständig und flüssig zu machen.

Schritt 6: Übersetzen Sie den deutschen Text zurück ins Englische, um sicherzustellen, dass die Bedeutung korrekt übertragen wurde.

Schritt 7: Überprüfen Sie den englischen Text auf Grammatikalische und stylistische Fehler.

Schritt für Schritt Übersetzung:

Schritt 1:
- Open source our code -&gt; Öffenen Sie unser Code
- You can find the code via the QR code on this slide -&gt; Sie können den Code über den QR-Code auf dieser Folie auffinden
- Please feel free to check it -&gt; Bitte unternehmen Sie sich keine Sorgen
- Thank you for your attention -&gt; Danke für Ihre Aufmerksamkeit
- Enjoy the conference -&gt; Genießen Sie die Konferenz.

Schritt 2:
- Öffnen Sie unser Code -&gt; Öffnen Sie unser Code

Schritt 3:
- Sie können den Code über den QR-Code on this slide -&gt; Sie können den Code über die QR-Code auf dieser Folie finden.

Schritt 4:
- Bitte unternehmen Sie sich keinen Sorgen -&gt; Bitte unternehmen Sie sich nicht Sorgen.

Schritt 5:
- Danke für Ihre Aufmerksamke -&gt; Danke für Ihre Aufmerksame.

Schritt 6:
- Genießen Sie die Konferenze -&gt; Genießen Sie die Konferenc.

Schritt 7:
- Öffnen Sie unser code -&gt; Öffnen Sie unser Code.

Schritt 8:
- Sie können den code über den QR-Code on this slide -&gt; Sichern Sie den Code über die QR-Code auf dieser Slide finden.

Schritt 9:
- Bitte unternehmen sich keine Sorgen -&gt; Bitte unternehmens sich keine Sorgen.

Schritt 10:
- Danke für Ihre Aufmersamkeit -&gt; Danke für Ihre Aufmerksamen.

Schritt 11:
- Genießen Sie die konferenz -&gt; Genießen Sie die Konferentz.

Schritt 12:
- Öffnen Sie unses Code -&gt; Öffnen Sie unses Code.

Schritt 13:
- Sie können den Code über die QR-Code on this slide -&gt; Sichern sie den Code über die QR-Code auf dieser slide finden.

Schritt 14:
- Bitte unternehmens sich keinen Sorgen -&gt; Bitte Unternehmens sich keine Sorgens.

Schritt 15:
- Danke für Ihre aufmerksamkeit -&gt; Danke für Ihre Aufmersamen.

Schritt 16:
- Genießen Sie das Konferenz -&gt; Genießen Sie das Konferenze.

Schritt 17:
- Öffnen Sie unses code -&gt; Öffnen Sie unses Code.</sample>
    <sample id="939">Gängige Bewertungsmethoden für Dialogeysteme sind menschliche Bewertungen, bei denen Menschen beurteilen, welche der beiden Gespräche besser ist oder die Gespräche auf einer Likert-Skala bewerten.</sample>
    <sample id="940">Vier Autoren sind an der Arbeit beteilt.</sample>
    <sample id="941">Das Hintergrundwissen, das im Beispiel mit Servin und Kei benötigt wird, ist das Wissen darüber, dass Richter Entscheidungen in Gerichten treffen.</sample>
    <sample id="942">Ja, der Code ist verfügbar. Sie können ihn auf GitHub finden.</sample>
    <sample id="943">Yes, the annotators for NLPositionality are balanced in terms of each demographic group, including country, gender, etc.</sample>
    <sample id="944">Sätze innerhalb der akzeptable Domain wurden durch Perturbationen durcheinander gebracht, indem sie in der Nähe der entsprechenden Sentenzen verändert wurden.</sample>
    <sample id="945">Eine dimensionale Bewertung bedeutet, dass die Qualität des Dialogs an mehreren Aspekten bewertet wird, um die Stärken und Schwächen des Modells auf einer feineren, gründigeren Ebene zu verstehen.</sample>
    <sample id="946">Die Autoren gehören zur Universität der Wissenschaften und Technologie von China.</sample>
    <sample id="947">Die Form des Prompts ist in den Fällen von Null- und Ein-Schuss-Prompts entscheidend, und bei fünf Schuss-Prompts gibt es kaum einen Unterschied zur tatsächlichen Form des Prompts.</sample>
    <sample id="978">Die Autoren haben die Dialogmodelle "GPT-3", "BERT", "T5" und "XLNet" evaluiert.</sample>
    <sample id="979">Eine Person, namens Jin Wei Yi, hat an der Arbeit beteiligt.</sample>
    <sample id="980">A good planner should write scripts that are reasonable and faithful to constraints.</sample>
    <sample id="981">Eine Person ist an der Arbeit beteiligt.</sample>
    <sample id="982">The name of the presenter is Vasudha.</sample>
    <sample id="983">Die Autoren gehören an der Universität von Wien.</sample>
    <sample id="1021">Die häufigsten Fehler von PaLm sind **Omissionen**.</sample>
    <sample id="1022">Hallo, ich bin James Finch und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABC-Eval, eine neue dimensionale Methode zur Bewertung von Konversationskünstlicher Intelligenz, erzählen.</sample>
    <sample id="1023">Diese Arbeit wurde von der Emory NLP-Lab, angeführt von Professor Gino Choy an der Emory-Universität, und in Zusammenarbeit mit Amazon Alexa AI durchgeführt.</sample>
    <sample id="1024">Stell dir vor, du hast gerade ein Dialogmodell entwickelt und möchtest sehen, wie gut es sich mit dem aktuellen Stand der Technik vergleicht.</sample>
    <sample id="1025">Die übliche Praxis besteht darin, menschliche Bewertungen zu verwenden, wie zum Beispiel durch das Fragen von menschlichen Richtern, welche der beiden Gespräche besser ist oder um Gespräche mit einer Likert-Skala zu bewerten.</sample>
    <sample id="1026">Diese Ansätze funktionieren gut, um umfassende Bewertungen der Gesamtdialogqualität zu liefern, aber die Dialogqualität hat viele Aspekte. Daher könnten Sie möglicherweise mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells auf einer feineren Granulierungsstufe zu verstehen.</sample>
    <sample id="1027">Eine Möglichkeit besteht darin, einfach menschliche Richter dazu zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie zum Beispiel die Relevanz von Modellantworten, indem sie bestehende vergleichende oder Likert-Skale-Methoden verwenden.</sample>
    <sample id="1028">Allerdings glauben wir, dass es eine genauere und zuverlässigere Strategie für die Bewertung von dimensionaler Dialekt gibt.</sample>
    <sample id="1029">Unser Ansatz versucht, die Subjektivität menschlicher Bewertungen zu reduzieren, indem wir explizit anzeigen, ob jeder Modellantwort bestimmte Verhaltensweisen ausdrückt, wie zum Beispiel mit irrelevanten Informationen reagieren oder sich widerspricht.</sample>
    <sample id="1030">Wir nennen diesen Ansatz "Annotation von Verhaltensweisen in Chat" oder "ABC-Eval" in Kürze. Wir haben dieses Verfahren entwickelt, um umfassend die Verhaltensweisen von Chat-Modellen abzudecken, die in der aktuellen Literatur vorgeschlagen wurden, um die Qualität des Chats zu beeinflussen.</sample>
    <sample id="1031">ABC-Eval ist in der Lage, die Raten zu messen, bei denen Chat-Modelle verschiedene thematische Fehler begehen.</sample>
    <sample id="1032">Zum Beispiel misst die ABC-Evaluation die Anzahl der Turns, in denen ein Chat-Modell seinen Partner ignoriert oder etwas Unwichtiges sagt.</sample>
    <sample id="1033">Der Inhalt beschreibt eine Reihe von Problemen, die sich in verschiedenen Aspekten eines Modells oder einer Theorie widerspiegeln könnten. Hier ist eine mögliche Übersetzung ins Deutsche:

---

**1. Widerspruch gegen sich selbst oder sein Partner:**

Der Inhalt beschreibt, dass das Modell oder die Theorie sich selbst widerspricht oder sich widerspricht, wenn es mit seinem Partner oder einer anderen Theorie in Konflikt steht. Dies könnte bedeuten, dass das Modell selbst widerspruchsvoll ist oder dass es mit anderen Theorien unvereinbar ist.

**2. Verwirrung durch falsche Tatsachen oder Verletzung des gesunden Menschenverständnisses:**

Der Inhalt beschäftigt sich mit der Verwirrung durch falsche Taten oder die Verletzung des gesunden Menschenrechts. Dies könnte bedeuten, das Modell falsche Informationen oder falsche Annahmen enthält, die zu ungewöhnlichen oder unglaublichen Ergebnissen führen.

**3. Erfolg oder Misserfolg des Modells:**

Der Inhalt beschließt, dass das Modell erfolgreich oder unerfolgreich sein kann, und dass dies in der Art und Weise zeigt, wie es Empathie zeigt oder nicht zeigt. Dies könnte bedeuten, daß das Modell in bestimmten Situationen erfolgreich ist, aber in anderen nicht, oder daß es immer empfänglich ist, unabhängig von der Situation.

---

Diese Übersetzung versucht, den englischen Inhalt in einen klaren und strukturierten deutschen Text zu übertragen, der die wesentlichen Aspekte des Inhalts widerspiegelt.</sample>
    <sample id="1034">Um herauszufinden, welche Art von Bewertung am effektivsten ist, haben wir vier hochmoderne Chat-Modelle ausgewählt und sie auf 100 menschliche Bot-Konversationen pro Modell mit dem ABC-Evaluationsverfahren bewertet.</sample>
    <sample id="1035">Für eine Vergleichsanalyse haben wir auch diese Gespräche mithilfe dreier bestehender Methoden bewertet: Liquor-Ratings auf der Turn-Ebene, Liquor-Ratings auf der Dialog-Ebene und Dialog-Ebene paarweise Vergleiche.</sample>
    <sample id="1036">Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekten des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen auf mehreren Dimensionen ist.</sample>
    <sample id="1037">Aus unserer Analyse dieser Bewertungsergebnisse haben wir gefunden, dass die ABC-Verhaltenslabels insgesamt zuverlässiger sind als die Labels, die durch bestehende Methoden gesammelt werden, wie durch die interne Annotator-Agreement auf 100 doppelten gelabelten Gesprächen gemessen wird.</sample>
    <sample id="1038">Zusätzlich sind die ABC-Evaluation-Labels besser in der Lage, die Gesprächskwalität im Vergleich zu Metriken zu beurteilen, die durch bestehende Methoden erzeugt werden, wie durch die einfache lineare Regressionsanalyse gezeigt wird.</sample>
    <sample id="1039">Zum Beispiel können Sie sehen, wie die Messung des Verhältnisses von Wenden mit Selbst- und Partner-Widersprüchen die Qualität der Konversation erklärt: 5 % und 10 % respektive, während die durchschnittlichen Liquor-Konsistenzscores nur 4 % oder weniger erklären.</sample>
    <sample id="1040">Schließlich überprüften wir, ob jeder Bewertungsmetrik einen einzigartigen Aspekt der Chat-Qualität erfasst, mithilfe einer stufenweisen linearen Regression.</sample>
    <sample id="1041">Sie können sehen, wie die Kombination aller ABC-Eval-Metriken über 25 % der Qualität der Konversation erklärt, und wenn Sie die Metriken eines nach dem anderen entfernen, resultieren die meisten von ihnen in einem erheblichen Verlust an Informationen über die Qualität.</sample>
    <sample id="1042">Auf der anderen Seite erklärt die Kombination aller Turn-Level-Liquor-Metriken wesentlich weniger von der Qualität und weniger von diesen Metriken tragen einzigartige Informationen.</sample>
    <sample id="1043">Diese zuverlässigen, informativen und unterschiedlichen ABC-Eval-Metriken ermöglichen es uns, mit einer höheren Auflösung als bisher möglich die Konversationskünstliche Intelligenz zu bewerten.</sample>
    <sample id="1044">Sie können sehen, dass in den Ergebnissen unserer Experimente, dass mehrere Herausforderungen immer noch bestehen und genau quantifiziert wurden. Zum Beispiel haben die Bots, die wir getestet haben, gemeinsame Sinnverstöße in etwa 20 % ihrer Antworten.</sample>
    <sample id="1045">Sie produzieren in etwa 15% der Antworten unangemessene Informationen und widersprechen sich selbst oder ihrem Partner etwa 10% der Zeit.</sample>
    <sample id="1046">Mit der rapiden Verbesserung in der Branche könnten viele dieser Fehlerquoten bei neuen Modellen seit unserer Bewertung einen Rückgang erleben. Allerdings ist dies umso mehr Grund, zuverlässige und präzise Bewertungsmetriken für die Vergleichbarkeit von Modellen zu verfolgen.</sample>
    <sample id="1047">Wir hoffen, dass die ABC-Evaluation als bedeutender Schritt in diese Richtung genutzt werden kann, und wir freuen uns darauf, wie sich die konversationsbasierte KI in den kommenden Monaten und Jahren weiterentwickelt. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="1048">Die Autoren gehören der Emory-Universität an.</sample>
    <sample id="1049">CFT steht für Continuous Fine-Tuning in dieser Arbeit.</sample>
    <sample id="1050">Es sind 7 Autoren an der Arbeit beteiligt.</sample>
    <sample id="1051">Hallo, mein Name ist Kai Ouyang und ich werde unsere Arbeit unter dem Titel "Wann benötigt Übersetzung Kontext? Eine datengetriebene mehrsprachige Erkundung" präsentieren. Diese Arbeit wurde in Zusammenarbeit mit Patrick Frennach, Emily Liu, André F. D. Martins und Graham Neubig durchgeführt.</sample>
    <sample id="1052">Sure, I'd be happy to help! Here's the translation of the sentence "So a lot of translations depend on context" into German:

"Daher hängen viele Übersetzungen von Kontext ab."

This sentence means that the meaning of a translation can vary depending on the context in which it is used. In other words, the same word or phrase can have different meanings in different situations, and the translator must take into account the context to choose the most appropriate translation.

I hope this helps! Let me know if you have any other questions.</sample>
    <sample id="1053">Wenn der vorherige Satz lautet: "Wenn die Minister herausfinden, könnten Dinge gefährlich werden", dann bezieht sich "mo" auf einen Spion. Aber wenn der vorherige Satz lautet, könnte es etwas ernst sein, Doktor? Dann bezieht sich "mo" auf ein Geburtstagsmerkmal.</sample>
    <sample id="1054">So, depending on context, the meaning of the word changes and therefore its translation changes as well.</sample>
    <sample id="1055">Jedoch ist es ziemlich schwierig, zu bewerten, wie gut Modelle solche Fälle wie dieses übertragen können. Zunächst, weil nur ein kleiner Teil der Übersetzungen von Kontext abhängig ist, was bedeutet, dass korpusbasierte Metriken wie Blue diese Übersetzungen nicht erfassen können.</sample>
    <sample id="1056">Und einige Menschen haben vorgeschlagen, kontextabhängige Übersetzungen zu zielgerichtet bewerten, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Menge an Sprachen. Da sie in der Regel auf domänenspezifisches Wissen und menschliche Schaffung angewiesen sind.</sample>
    <sample id="1057">In this work, we try to answer these two questions: first, when does translation require context, and second, how well do models handle these cases?</sample>
    <sample id="1058">Um die erste Frage zu beantworten, haben wir damit begonnen, wie viel ein Wort von Kontext abhängt, während Übersetzung geschieht.</sample>
    <sample id="1059">In der vorherigen Arbeit haben wir CXMI als Messgröße für Kontextnutzung durch maschinelle Übersetzungsmodelle eingeführt. Dies wird durch Messung erreicht, wie viel Informationen der Kontext C über das Ziel Y, gegeben der Quelle X, bereitstellt.</sample>
    <sample id="1060">Sie können sich CxiMi als die Informationen vorstellen, die man durch das Gehen von Kontext zu dem Modell erhält.</sample>
    <sample id="1061">In diesem Werk erweitern wir CXMI auf pointwise CXMI, das Kontextnutzung auf der Satz- oder Wortebene messen kann. Wir können Wörter, die hohe p-CXMI haben, als solche betrachten, die Kontext für Übersetzung benötigen.</sample>
    <sample id="1062">Nun analysieren wir Wörter mit hoher P-Semantik, um Muster zwischen diesen Wörtern zu suchen.</sample>
    <sample id="1063">Wir führen eine Analyse auf Transkriptionen von TED Talks durch, die von Englisch in vierzehn verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="1064">Wir führen unsere Analyse auf drei verschiedene Ebenen durch. Zuerst untersuchen wir Teile des Sprachtags, die hohe Bedeutungen im PCXMI haben.</sample>
    <sample id="1065">Und dies ermöglicht es uns, z. B. Dualpronouns in Arabisch zu finden, die hoch HPI-SMI haben. Und das kann erklärt werden, weil Englisch keine Dualpronouns hat, also müssen wir Kontexte verwenden, um zu bestimmen, ob ein Pronomen dual ist, wenn es ins Arabische übersetzt wird.</sample>
    <sample id="1066">And similarly, we find that certain languages also require context when we want to choose the appropriate verb form. We then look at vocabulary items that have high p-semantic average over all of its different occurrences.</sample>
    <sample id="1067">Und das hilft uns, Fälle zu identifizieren, wie das hier, wo in Chinesisch du Kontext benötigst, um die richtigen Namen zu übersetzen, um sicherzustellen, dass du innerhalb des Dokuments die gleiche Übersetzung verwendest.</sample>
    <sample id="1068">Wir finden ähnlich, dass ein Kontext unterstützt wird, um in die richtige Formulierung zu übersetzen.</sample>
    <sample id="1069">Und schließlich untersuchen wir verschiedene individuelle Tokens, die einen hohen p-Semmi aufweisen. Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern vielmehr in der Satzstruktur ausgedrückt werden. So just ellipsis resolution.</sample>
    <sample id="1070">Nun nutzen wir unsere Erkenntnisse aus unserer Analyse, um ein Benchmark für die Dokumentübersetzung zu entwerfen.</sample>
    <sample id="1071">Für jede der fünf Diskursphänomene, die wir identifiziert haben, erstellen wir Tags, um automatisch Wörter zu identifizieren, die zum Phänomen gehören. Und wir nennen unseren Tag das multilingue Diskurs-Aware oder Muda-Tag.</sample>
    <sample id="1072">Wir können dann auch bemerken, dass verschiedene Sprachen unterschiedliche Verhältnisse dieser Diskursephänomene haben.</sample>
    <sample id="1073">Wir verwenden dann den Muda-Tagger, indem wir ihn auf die parallelen Korpora anwenden, die wir für die Bewertung verwenden möchten, und wir wenden unsere gewählte Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der Muda-Tagger identifiziert hat.</sample>
    <sample id="1074">Und schließlich verwenden wir unser Benchmark sowie andere Metriken, um verschiedene Modelle auf Dokumentebene für maschinelle Übersetzung zu bewerten.</sample>
    <sample id="1075">Zuerst einmal, wenn wir korpusbasierte Metriken verwenden, so finden wir bei Blue, dass kontextabhängige Modellierungsansätze die beste Leistung aufweisen.</sample>
    <sample id="1076">Aber dann, wenn wir comet verwenden, sind kontextbewusste Modelle am besten. Und wenn wir word f messen, haben Modelle mit und ohne Kontext vergleichbare Leistung.</sample>
    <sample id="1077">Dies zeigt wieder einmal, dass es schwierig ist, das beste Dokumentations- oder Übersetzungssystem zu bestimmen, wenn man nur korpusbasierte Metriken verwendet.</sample>
    <sample id="1078">Jetzt verwenden wir den Muda Benchmark, um Modelle zu bewerten, und wir finden heraus, dass Kontextüberlegenheitsmodelle in bestimmten Diskursphänomenen signifikant genauer sind als Modelle, die keinen Kontext verwenden.

Solche Aspekte wie Formulierungen und lexikalische Kohäsion.</sample>
    <sample id="1079">Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext auf anderen Phänomenen wie Ellipsen, Pronomen und Verbformen verwenden. Das deutet also darauf hin, dass wir noch mehr Fortschritte bei der Dokumentenübersetzung brauchen.</sample>
    <sample id="1080">Wir haben auch verschiedene kommerzielle Systeme verglichen und unsere Benchmark zeigt, dass die Bell für Dokumentübersetzungen generell genauer ist als Google Translate.</sample>
    <sample id="1081">Zusammenfassend durchführen wir eine datengetriebene Analyse über vierzehn Sprachpaare, um herauszufinden, wann Übersetzungen Kontext benötigen.</sample>
    <sample id="1082">Und dann verwenden wir unsere Erkenntnisse, um ein Benchmark für Dokument-Level-Maschinenübersetzung aufzubauen, der uns helfen kann, zu bestimmen, welche Diskursphänomene Modelle gut oder nicht gut handhaben können, und welche Übersetzungssysteme gut bei Dokument-Level-Übersetzung sind.</sample>
    <sample id="1083">Danke so viel für Ihre Aufmerksamkeit. Bis zum nächsten Mal.</sample>
    <sample id="1084">Der/die Referent*in heißt Yu Sen Zhang.</sample>
    <sample id="1121">Die neue Methode hat den Namen "DFS".</sample>
    <sample id="1122">Die Autoren beschreiben die Methode der „markierten Worte“ als eine Technik zur Identifizierung der Wörter, die markierte Gruppen von unmarkierten unterscheiden. Diese Methode wird verwendet, um bestimmte Wörter oder Phrasen aus Texten zu markieren, die besonders wichtig oder relevant sind für die Analyse oder das Verständnis des Textes sind. Die Autoren erklären, dass diese Methode hilfreich sein kann, um die Struktur und den Inhalt von Texten besser zu verstehen und zu analysieren.</sample>
    <sample id="1123">Die Autoren gehören der Universität Washington an.</sample>
    <sample id="1124">Prague</sample>
    <sample id="1125">James Finch und Sara Finch.</sample>
    <sample id="1126">Vier Autoren sind an der Arbeit beteilt.</sample>
    <sample id="1127">Datensätze, die syntaktische Phänomene wie Grammatikalität, Pluralität, Syntax und Akzeptabilität testen können, können zum Testen syntaktischer Phänomen verwendet werden.</sample>
    <sample id="1161">WSL, WSL, WSL, WSL, W</sample>
    <sample id="1162">Das Modell wird auf 11 biomedizinischen und klinischen Aufgaben eingesetzt, um seine Leistung zu bewerten.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich mit 4 gigabyte Subset von natürlich schon vergleichbaren Resultaten trainiert.</sample>
    <sample id="1227">Der/die Referent*in heißt Adam Skurkowski.</sample>
    <sample id="1228">Die Ergebnisse des Experiments zeigten, dass die Leistung mit zunehmender zeitlicher Verzögerung abnahm. Dies bestätigte die Hypothese, dass die zeitliche VerzöGerung die Hauptursache für den Leerständigkeitsverlust war.</sample>
    <sample id="1269">Es ist notwendig, die Token für die Ausgangssprache zu permutieren, um die korrekte Reihenfolge zu erhalten.</sample>
    <sample id="1270">Die Autoren empfehlen, dass Modellentwickler*innen die Transparenz ihrer Methoden zum Abbau von Vorurteilen erhöhen, um die Ursachen für positive Stereotypen zu verstehen. Dies könnte aufgrund von "weird overly excessive value alignment" oder anderen "anti-stereotyping methods" sein, die zu präjudizierenden Muster führen.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind ungrammatische Sätze oder Sätze, die nicht korrekt sind.</sample>
    <sample id="1272">The authors have used the weight and tokenizer of permit bird to train on the 4 gigabyte subset of natchez. They show comparable results to those obtained with a doctor built 4 gigabyte from scratch.</sample>
    <sample id="1273">Inner annotator agreement.</sample>
    <sample id="1274">Die Domain, die gewählt wurde, um völlig unzusammengehörige Sätze zu den inakzeptabel und akzeptablen Suchanfragern hinzuzufügen, ist Wikipedia.</sample>
    <sample id="1275">Die Autoren gehören an der Universität Stuttgart.</sample>
    <sample id="1276">MultiInstruct is a benchmark that focuses on improving the zero-shot performance on language-only tasks, while other benchmarks have not considered multi-model tasks. Additionally, there is a significant discrepancy in the availability of instruction datasets between NLP and multi-model tasks, with more than 1,600 language-only instruction tasks available, but no large-scale publicly available multi-model instruction task. Therefore, MultiInstruct aims to address this gap and investigate whether instruction tuning on multi-model pre-trained models can actually improve generalization to unseen multi-model tasks.</sample>
    <sample id="1277">Zwei Autoren sind an der Arbeit beteilt.</sample>
    <sample id="1278">Die Definition der binären Koordination lautet: "Binäre Koordination ist eine syntaktische Struktur, bei der zwei Wörter oder Phrasen in einer Wortgruppe parallel stehen und gleichzeitig die Hauptstruktur des Satzes betreffen."</sample>
    <sample id="1279">Die in dieser Studie verwendeten Prompse waren im Durchschnitt 1000 Zeichen lang.</sample>
    <sample id="1280">Die Ergebnisse zeigen, dass das kleinere T5-Modell die Qualität der generierten Skripte auf der Höhe der meisten größeren Sprachmodelle erreicht, was bedeutet, dass es in der Lage ist, größere Modelle zu übertragen, wenn es auf geeignete Datenmengen trainiert wird.</sample>
    <sample id="1281">Hallo, ich bin Janis Lavaque und ich werde Ihnen unsere Arbeiten über den Doktor Bert vorstellen, ein robustes vorgefertigtes Modell in Französisch für die biomedizinische und klinische Domain.</sample>
    <sample id="1282">In diesem Vortrag werden wir zunächst über Sprachmodellierung im Gesundheitswesen sprechen. Danach werden wir die Hauptbeiträge unseres Artikels präsentieren.</sample>
    <sample id="1283">Wir haben den ersten biomedizinischen Modell ersetzt, der in Französisch namens "Doktor Bert" heißt und auf der Basis von Roberta und auf der Basis von Natchez trainiert wurde, die ein Datensatz von medizinischen kronen Daten bilden.</sample>
    <sample id="1284">Wir haben auch eine Vergleichung von Modellen mit mehreren prädiktiven Einstellungen und Datenquellen eingeführt. Dann präsentieren wir unsere Ergebnisse auf 11 biomedizinischen und klinischen Aufgaben in französisch.</sample>
    <sample id="1285">Und schließlich kommen wir zu den Ergebnissen der Experimente und geben Ihnen mehr Details darüber, wie man auf die Modelle zugreifen kann.</sample>
    <sample id="1286">Seit seiner Veröffentlichung im Jahr 2018 hat BERT eine der effektivsten Ansätze zur Lösung natürlicher Sprachverarbeitungstasks geworden und bietet einen enormen Leistungsgewinn im Vergleich zu historischen statischen und kontextualisierten Methoden wie Word2Vec.</sample>
    <sample id="1287">Seitdem wurde dieses Modell an viele andere Sprachen angepasst, wie zum Beispiel in Französisch mit Camembert und in anderen Bereichen wie der Biomedizin mit Permeablet und Biobird. Und auf klinische Weise mit klinischen Bildern, aber hauptsächlich auf Englisch.</sample>
    <sample id="1288">Spezialisierte Modelle für andere Sprachen sind selten und basieren oft auf kontinuierlicher Präsentation aufgrund des Mangels an in-dominanten Daten.</sample>
    <sample id="1289">Allerdings hatte Frankreich bisher keine Open-Source-Software für biomedizinische Anwendungen.</sample>
    <sample id="1290">Wir fragen uns selbst, welche Datenquellen für eine breite Palette von Anwendungen am besten geeignet sind, und ob solche Daten eine gute Substitution für klinische Daten darstellen.</sample>
    <sample id="1291">Um diese Frage zu beantworten, vergleichen wir den Doktor Bildt mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die aus dem nichtchirurgischen Spital am Hause stammen.</sample>
    <sample id="1292">Nachdem wir uns gefragt haben, wie viel Daten wir benötigen, um ein spezialisiertes Modell auf französischen Daten zu trainieren, ist es 4 Gigabyte, 8 Gigabyte oder mehr?</sample>
    <sample id="1293">Um diese Frage zu beantworten, trainieren wir zuerst und vergleichen vier Modelle von Grund auf. Ein erster Version von "Doctor Belt" mit 7 GB von natürlichen Daten. Eine zweite Version von 4 GB von natürlichen Daten.</sample>
    <sample id="1294">Die erste Version von Schubert, die ein klinisches Modell ist, enthält vier Gigabyte an Sätzen, die aus klinischen Notizen stammen. Die endgültige Version von Schubert besteht aus einem Mix aus vier Gigabytes an Sätzen aus verschiedenen Quellen und vier Gigabytes an klinischen Notizen.</sample>
    <sample id="1295">In addition to this comparison, we introduce three models trained on contextual pre-training to analyze the impact of pre-training strategies.</sample>
    <sample id="1296">Einer basiert auf dem Gewicht von Kammerbären und trainiert auf vier Gigabytes eines Sets von Naturschriften. Der andere basiert ebenfalls auf Kammerbären, aber trainiert diesmal auf vier Gigabytes von Klinkernoten.</sample>
    <sample id="1297">Schritt 1: Übersetze den englischen Text in deutsche Sprache.

Der englische Text lautet: "And finally, one base of on the English biomedical model per permit bit and train on four gigabytes of set of snatches. In total, we have seven models."

Schritt 2: Übersetze den englischen Satz "And finally, one base of on the" ins deutsche.

Der englische Satz "And finally, one base of" kann ins deutsche übersetzt werden als "Und schließlich, eine Basis von".

Schritt 3: Übersetze den englischen Begriff "on the English biomedical model" ins deutsche.

Der Begriff "on the English biomedical model kann ins deutsche übersetzt wird als "auf dem englischen biomedizinischen Modell".

Schritt 4: Übersetze den englischen Ausdruck "per permit bit" ins deutsche.

Der Ausdruck "per permit bit kann ins deutsche übersetzt wurde als "per Erlaubnisbit".

Schritt 5: Übersetze den englischen Wort "and" ins deutsche.

Der Wort "and kann ins deutsche übersetzt worden als "und".

Schritt 6: Übersetze den englischen Term "train on" ins deutsche.

Der Term "train on kann ins deutsche übersetzt werde als "trainieren auf".

Schritt 7: Übersetze den englischen Phrase "four gigabytes of set of snatches" ins deutsche.

Der Phrase "four gigabytes of set of" kann ins deutsche übersetzt werden als "vier Gigabyte von Set von".

Schritt 8: Übersetze den englischen Nomen "snatches" ins deutsche.

Nomen "snatches kann ins deutsche übersetzt wordet als "Schnappchen".

Schritt 9: Übersetze den englischen Zusatz "In total, we have seven models" ins deutsche.

Der Zusatz "In total, we have" kann ins deutsche übersetzen als "Insgesamt haben wir".

Schritt 10: Kombiniere die übersetzten Teile, um den vollständigen deutschen Text zu erhalten.

Der vollständige deutsche Text lautet: "Und schließlich, eine Basis auf dem englischen biomedizinischen Model, per Erlaubnisbit und trainieren auf vier Gigabyte von Set von Schnappchen. Insgesamt haben wir sieben Modelle."

Schritt 11: Überprüfe die Übersetzung auf grammatikale und sinnvolle Stimmung.

Die Übersetzung ist grammatikalisch korrekt und vermittelt den ursprünglichen englischen Text in deutscher Sprache.

Schritt 12: Überprüfe die Übersetung auf Genauigkeit und Konsistenz.

Die Übersetzung ist genau und konsistent mit dem ursprünglichen englischen Inhalt.

Schritt 13: Überprüfe die Übers</sample>
    <sample id="1298">Um alle sieben Modelle zu bewerten, haben wir jeweils eine öffentliche und private Aufgabe, wie zum Beispiel Namensidentifikation, Klassifizierung, Sprachverarbeitung und Fragebeantwortung.</sample>
    <sample id="1299">Diese Modelle werden mit sechs baselinemodellen verglichen, die folgende sind: Commodore 64 (138 GB), Commodore 64 (4 GB), Commodore 64 (40 GB), Commodore 64 (4 MB), Commodore 64 (4 MB) und Commodore 64 (4 MB).</sample>
    <sample id="1300">Die Evaluierung der entsprechenden Highlights, die das Modell am besten auf die Aufgabe mit Daten der gleichen Natur hat, hat uns ermöglicht, 

die entsprechenden Highlights, die auf Daten der gleichen Natur wie die Daten, auf denen das Modell trainiert wurde, zu identifizieren.</sample>
    <sample id="1301">However, we have we can obtain that data from  uh  we can observe that data from interregional sources appear to be more versatile. We also observe that using more data translates into better performance.</sample>
    <sample id="1302">Insgesamt scheint das "from scratch" Training auf den meisten Aufgaben eine höhere Leistung zu erzielen.</sample>
    <sample id="1303">However, our experiment on quantum pre-training using the weight and tokenizer of permit bird train on the 4 gigabyte subset of natchez show comparable results to those for obtain with doctor bert for gigabyte from scratch.</sample>
    <sample id="1304">Der englische Text besagt, dass das Modell, das auf den Komponenten- und Token-Werten basiert, von Stabilitätsproblemen betroffen ist.

Die Übersetzung ins Deutsche lautet:

"Der Modell, das auf den Komponenten-Werten und Token-Werten basiert, leidet nicht von Stabilitätsproblemen."

In diesem Satz wird klar, dass das Modell, das auf den Werten der Komponenten und der Token basiert, nicht von Stabilitätsprobleme betroffen ist. Dies bedeutet, dass das Modell in der Lage ist, stabile und zuverlässige Ergebnisse zu liefern, unabhängig von der Stabilität der Komponenten und Token.

Es ist wichtig zu beachten, dass das Modell, das auf den Token-Werten basiert, von Stäbilitätsproblemen betroffen sein kann, wenn die Token nicht ausreichend stabil sind. Dies kann zu unvorhergesehenen Ergebnissen führen und die Genauigkeit des Modells beeinträchtigen.

Insgesamt ist das Modell, das auf den Komponent-Werten und Token-Werten basierend, stabiler und zuverlässiger als das Modell, das auf den Komponent- und Token-Werten basiert.</sample>
    <sample id="1305">Schließlich hat eine Schlussfolgerung, dass unser System besser auf neun von elf Don'ts-Tasks performiert und global den Ergebnissen des generischen Modells hier überlegen ist.</sample>
    <sample id="1306">Wir beobachten auch, dass spezialisierte Daten besser sind. Mehr spezialisierte Daten sind besser, aber sie skalieren nicht gut.</sample>
    <sample id="1307">Alle vorgefertigten Modelle, die man von Naturs aus bekommt, sind kostenlos und auf der GitHub-Seite verfügbar. Alle Trainingsskripte befinden sich in unserem GitHub-Repository.</sample>
    <sample id="1308">Danke für diese Präsentation und wir freuen uns auf die Aktionen in der nächsten Sitzung.</sample>
    <sample id="1309">Die Arbeit untersucht drei verschiedene Lernstrategien: 
1. Trainieren und vergleichen von vier Modellen von "Doctor Baird" mit 7 GB von Natürlichkeit, 
2. Trainieren und vergleichen von vierten Modellen von "Doctor Baird" mit vier GB von Natürlichkeit,  und 
3. Trainieren und vergleichen von vierem Modellen von "Schubert" mit einem Mix von vier GB von Natürlichkeit und vier GB von klinischen Noten. 
Zusätzlich wird eine dritte Lernstrategie eingeführt, die auf kontinuierlicher Prätrainings basiert.</sample>
    <sample id="1310">Der Faktor der Überanpassung aufgrund der Wiederverwendung von Tests ist größer als 1.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde anhand der Scores und der Evaluationsmetriken der Experimente in der Arbeit beurteilt. Die Autoren fanden heraus, dass die grundlegende Feinabstimmung die Scores besser erreicht hat als die Baseline. Sie stellten diese Ergebnisse als Benchmarks für zukünftige Forschungen dar.</sample>
    <sample id="1312">Ja, Sprachmodelle haben unterschiedliche politische Vorur-teile.</sample>
    <sample id="1313">Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen eine kurze Einführung in unsere Arbeit über kompositional Generalisierung ohne Bäume geben. Wir nutzen Multiset-Tagging und Latente Permutationen.</sample>
    <sample id="1314">Dies ist eine gemeinsame Arbeit mit meinen Beratern Alexander Kola und Ivan Titov.</sample>
    <sample id="1315">Kompositional generalization kann als die Fähigkeit eines Lerners verstanden werden, tiefere Rekursion und unbekannte Kompositionen von Phrasen zu behandeln, die während der Ausbildung einzeln gesehen wurden.</sample>
    <sample id="1316">In the context of semantic parsing, testing for compositional generalization might look like this: As usual, we have a training set of utterances, in this case, "The girl slept" and "Mary knew that the girl slept."</sample>
    <sample id="1317">Diese Attributen sind mit logischen Formen verbunden, die die Kernaspekte ihrer Bedeutung darstellen.</sample>
    <sample id="1318">Im Gegensatz zu der Standard-Maschinenlernungsevaluation kommt der Testset nicht aus derselben Verteilung, sondern enthält strukturale, bisher ungesehene logische Formen.</sample>
    <sample id="1319">In diesem Beispiel hat das Modell bei der Ausbildung tiefere Rekursion gesehen und wird auf Beispiele getestet, die eine tiefere Rekursion aufweisen.</sample>
    <sample id="1320">Naive sequence-to-sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.</sample>
    <sample id="1321">In particular, they often fail to reproduce the systematic correspondences between input and output, such as those that are color-coded in the example.</sample>
    <sample id="1322">Eine beliebte Methode, um dies zu lösen, besteht darin, Bäume in die Modelle zu integrieren.</sample>
    <sample id="1323">Die Bäume sollen die kompositorische Prozess darstellen, der Zusammenhänge zwischen Äußerlichkeiten und logischen Formen vermittelt.</sample>
    <sample id="1324">Dies funktioniert gut, aber Bäume werden in der Regel nicht gegeben und müssen irgendwie erhalten werden.</sample>
    <sample id="1325">Dies kann ein komplexes und manchmal rechenrechenswertes Prozess sein. Typischerweise beinhaltet dies erhebliche formalistische Vorbereitung der logischen Formen. Zum Beispiel, um Variablen-Symbole zu verarbeiten.</sample>
    <sample id="1326">Die Beschaffung von Bäumen kann auch spezialisierte Grammatik-Induktionsverfahren umfassen.</sample>
    <sample id="1327">In diesem Papier verwenden wir keine Bäume und führen eine neuronale Sequenz-zu-Sequenz-Modell ein, das die Korrespondenzen zwischen Fragmenten des Inputs und Fragmenten des Outputs direkt modelliert.</sample>
    <sample id="1328">Zum ersten Mal zeigen wir starke Generalisierung zu tiefer Rekursion ohne auf Bäume angewiesen zu sein.</sample>
    <sample id="1329">Unser Ansatz schätzt die Ausgabe aus dem Eingabewert in zwei Schritten vor.</sample>
    <sample id="1330">Zuerst werden jeden Eingabetoken mit einem ungeordneten Multiset von Tokens versehen, die im Ausgang erscheinen werden.</sample>
    <sample id="1331">Nach dem ersten Schritt haben wir alle richtigen Tokens, aber sie sind nicht geordnet.</sample>
    <sample id="1332">Deshalb verwenden wir in Schritt 2 ein anderes Modell, um die Permutation vorherzusagen, um sie in die richtige Reihenfolge zu stellen.</sample>
    <sample id="1333">Wir führen eine neue Methode ein, um eine Permutation vorherzusagen, die keine strenge Einschränkungen auf die möglichen Permutationen auferlegt. Dies macht unsere Methode ziemlich flexibel und ausdrucksstark.</sample>
    <sample id="1334">Konzeptionell funktioniert unser Permutationsmodell etwa so:</sample>
    <sample id="1335">Wir gehen von links nach rechts über das Ausgabebild und bestimmen, welches Multiset-Token in jedem Position zu setzen. Für die erste Ausgabeposition wählen wir einfach eins, wie in Rot hervorgehoben.</sample>
    <sample id="1336">Dann gehen wir zum nächsten Multiset-Token, um zu bestimmen, welches zweite Token im Ausgangsergebnis ist.</sample>
    <sample id="1337">Wir bestimmen den dritten Token im Ausgang in einer ähnlichen Weise, indem wir zu einem anderen Multiset-Token springen. Wir führen diesen Prozess fort.</sample>
    <sample id="1338">Bis jeder Token aus dem ersten Stadium genau einmal besucht wurde.</sample>
    <sample id="1339">Um Ihnen einen Vorspann der experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen treeless Modellen auf dem Cogs Benchmark. Unser Modell erreicht die anderen um einen großen Abstand und generalisiert auf tiefere Rekursionen.</sample>
    <sample id="1340">Some other kinds of structural generalization remain very challenging though.</sample>
    <sample id="1341">In unserer Arbeit haben wir ein paar interessante technische Herausforderungen gelöst.</sample>
    <sample id="1342">Erstens ist die Ausrichtung zwischen Eingabe und Ausgabe nicht im Trainingsdaten gegeben. Folglich wissen wir für ein bestimmtes Token nicht, aus welchem Multiset es stammt. Which poses a challenge for training.</sample>
    <sample id="1343">Zusätzlich gibt es manchmal mehrere Permutationen, die mit den Daten konsistent sind, aber die linguistisch korrekte eine verzögert. Wir beheben dies, indem wir die Ausrichtung als Teil des Trainings induzieren.</sample>
    <sample id="1344">Unsere Permutationsmethode ist sehr flexibel, aber sie bringt die Herausforderung mit sich, dass die höchste Bewertungspersmutation in NP-Hard ist. Das liegt daran, dass dies mit dem Reiseverkäuferproblem zusammenhängt.</sample>
    <sample id="1345">Wir approximieren dies mit einer GPU-freundlichen kontinuierlichen Relaxation, die auch es uns ermöglicht, durch die Lösung zurückzutreten und die linguistisch plausiblen Permutationen zu lernen.</sample>
    <sample id="1346">Wenn Sie mehr über unsere Experimente und wie wir diesen Herausforderungen begegnen möchten, schauen Sie sich bitte unsere Arbeit an oder kommen Sie zu unserem Poster.</sample>
    <sample id="1347">Kognitive Dissonanz ist eine psychologische Theorie, die beschreibt, wie Menschen mit widersprüchlichen Überzeugungen, Überzeugungen und Handlungen umgehen. Es tritt auf, wenn eine Person zwei oder mehr unvereinbare Überzeugungen oder Handlungen hat und diese sich widersprechen. Dies kann zu Unbehagen und innerem Konflikt führen, da die Person versucht, diese Dissonanzen zu lösen.

Kognitive Dissonanz ist ein wichtiges Thema in der Sprachwissenschaft, da es die Art und Weise beeinflusst, wie Menschen kommunizieren und ihre Überzeugungen und Handlungen ausdrücken. Es kann auch helfen, die Art und Weise zu verstehen, wie Menschen ihre Werte und Überzeugungen in ihrer Kommunikation ausdrücken und wie sie sich mit unterschiedlichen Meinungen und Überzeugungen auseinandersetzen.

In der Sprachwissenschaft wird Kognitive Dissonanz oft in Bezug auf die Art und Weise analysiert, wie Menschen ihre Überzeugungen und Handlungspraktiken in ihrer Kommunikation ausdrücke. Es kann auch helfen, die Art, wie Menschen ihre Werte und Meinungen in ihrer Kommunikation ausdrucken, zu verstehen und wie sie sich mit unterschiedlicher Meinung und Überzeugung auseinandersetzen.

Kognitive Dissonanz ist also ein wichtiges Thema in der Linguistik, da es die Art und Weise beinhaltet, wie Menschen ihre Überzeugen und Handlungen in ihrer Kommunikation aussprechen und wie sie sich mit unterschiedlichsten Meinungen und Überzeugungen umgehen. Es kann auch helfen, die Art wie Menschen ihre Werte und Meineungen in ihrer Kommunikation auszudrücken und wie sie sich mit unterscheidlichen Meinungen und Überzeugung auseinander setzen.</sample>
    <sample id="1348">GPT-4.</sample>
    <sample id="1349">Ja, kumulatives Training erwies sich als besser als iteratives Training für aktives und effektives Lernen.</sample>
    <sample id="1350">The name of the presenter is Sarah Pappi.</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen aus Transkriptionen von TED Talks, die ins Englische übersetzt wurden und dann in vierzehn verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="1385">The name of the presenter is Matthias Lindemann.</sample>
    <sample id="1386">Sprachübergreifender Transfer bezieht sich auf die Fähigkeit, Wissen und Fähigkeiten von einer Sprache auf eine andere zu übertragen. Es ist ein wichtiger Aspekt der maschinellen Übersetzung und der natürlichen Sprachverarbeitung, da es ermöglicht, Informationen und Wissen aus einer Sprache in eine andere zu übertragen, ohne dass der Benutzer zusätzliche Sprachkenntnisse benötigt.

In der maschinellen Übersetzung wird Sprachübergreifender Transfer verwendet, um die Übersetzung von Texten aus einer Sprache in eine andere Sprache zu verbessern. Dies wird durch das Trainieren eines Modells auf einer großen Menge von Texten in einer Sprache erreicht, das dann auf Texten in einer anderen Sprache angewendet wird.

In der natürlichen Sprachverarbeitungsforschung wird Sprachübergreifender Transferens verwendet, um die Verarbeitung von Texten in einer Sprache auf Texten in einer anderen Spraiche zu verbessern. Dies wird durch das Training eines Modells auf einer großen Datenmenge in einer Sprache erreicht, dass dann auf Texten in einer anderen Language angewendet wird.

Es gibt verschiedene Ansätze zur Sprachübergreifenden Transfer, wie zum Beispiel:

* **Zero-shot Transfer**: Dieser Ansatz verwendet ein Modell, das auf einer großen Menge von Texte in einer Sprache trainiert wurde, um die Übersetzung von Text in einer anderen Sprache zu verbessern. Das Modell wird auf Texten in einer anderen Sprahe angewendet, ohne dass es zusätzliche Sprachkenntisse benötigt.
* **Few-shot Transfer**: Dieser Ansatz verwendete ein Modell, das auf einer kleinen Menge von Texten in einer Sprahe trainiert wurde, um die Übersetung von Text in einer anderen Sprahe zu verbessern. Das Modell wird dann auf Texten in einer anderen Langauge angewendet.
* **Multi-lingual Transfer**: Dieser Ansatz verwendete eine Model, die auf einer großen Menge von Text in mehreren Sprachen trainiert wurde, um die Übersettung von Text in einer anderen Sprabe zu verbessern. Das Modell wird darauf angewendet, um Texte in einer anderen Sprache zu übersetzen.

Insgesamt ist Sprachübergreifender Transfer ein wichtiger Aspekt der maschinenlernenden Übersetzung und der natürlichen Languageverarbeitung, da es ermächtigt, Informationen und Wissen aus einer Sprach in eine andere zu übertragen, um die Verarbeitung von Text in einer Sprache zu verbessern.</sample>
    <sample id="1387">Die Autoren gehören an der Saarland-Universität in Deutschland.</sample>
    <sample id="1388">The authors use latency measures to evaluate the translation quality and average lagging. They also consider the computational aware average lagging that accounts for the model's computational times to produce the output.</sample>
    <sample id="1389">Hallo alle, ich bin Max Schäfer und heute präsentieren mein Kollege Martin und ich unsere Arbeit "The KITMASTER: Evaluating Knowledge Integration from Multiple Sources". Diese Arbeit ist eine Zusammenarbeit zwischen McGill University, Mila und Microsoft Research.</sample>
    <sample id="1390">Natürliche Sprachverständigungsmodelle nutzen eine Vielzahl von Wissensquellen, wie zum Beispiel Wissen, das in ihren Parametern enthalten ist, das normalerweise durch eine vorherige Ausbildung erworben wird, und Wissen, das in Eingaben zur Inferenzzeit gegeben wird.</sample>
    <sample id="1391">Neuere Arbeiten in der Fragebeantwortung zeigen, dass Modelle vorbereitetes Wissen nutzen können, um die Aufgabe zu lösen.</sample>
    <sample id="1392">Aber natürliche Sprachverständigung benötigt oft Wissen, das auch zur Zeit der Inferenz bereitgestellt wird.</sample>
    <sample id="1393">John sah den neu gewählten Präsidenten auf dem Fernsehen.</sample>
    <sample id="1394">Voraussetzungsparameter können Informationen über, was Präsidenten tun und was eine Tätigkeit ist, enthalten, aber sie können nicht zuverlässig wissen, wer das instanzspezifische Entität John ist oder wer der neue Präsident ist, weil der Präsident seit der Vorbereitung geändert haben könnte.</sample>
    <sample id="1395">Daher benötigen erfolgreiche Modelle für wissensintensive natürliche Sprachverarbeitung (NLU) Aufgaben die Fähigkeit, sowohl Prätrainingszeit- als auch Inferenzzeitwissen zu integrieren und zu nutzen.</sample>
    <sample id="1396">In diesem Werk schlagen wir eine Diagnostikstestsuite für Wissensintegration vor.</sample>
    <sample id="1397">Wir führen eine KoReferenzauflösungsaufgabe ein, die darauf ausgelegt ist, die Fähigkeit zu testen, auf das Wissen zuzugreifen, das in verschiedenen Quellen verfügbar ist. Wir bewerten das Datenset mit menschlicher Studiepraxis und etablieren KoReferenzauflösungsmodelle.</sample>
    <sample id="1398">Sure, I'd be happy to help! Here's the translation of the given text from English to German:

"Here is an example from our dataset:

Sven is a judge.
Kia is a baker.
Sven and Kia met at a park.
After a long day at work, deciding cases in a law court,
he was happy to relax."

I hope this helps! Let me know if you have any other questions.</sample>
    <sample id="1399">Der Aufgabentext lautet:

"The task here is to identify the correct entity that the pronoun he refers to, which in this case is servant."

Übersetzung ins Deutsche:

"Die Aufgabe hier besteht darin, die korrekte Entität zu identifizieren, zu der der Pronomen erwähnt wird, in diesem Fall ist es der Diener."</sample>
    <sample id="1400">Die Auflösung eines bestimmten Pronomens erfordert zwei Arten von Information: Erstens ist spezifisches Wissen über die Entität erforderlich, wie zum Beispiel, dass Servin ein Richter ist. Zweitens ist Hintergrundwissen erforderlich, wie zum Beispiels, dass Richter Fälle in Gerichten entscheiden.</sample>
    <sample id="1401">Im Allgemeinen wird allgemeines Wissen während der Vorbereitung von großsprachigen Modellen gelernt, während spezifisches Wissen zu Entitäten typischerweise während der Inferenz beobachtet wird.</sample>
    <sample id="1402">Wir variieren die Verfügbarkeit dieser beiden Informationen, so dass sie entweder in einer einzigen Quelle oder in mehreren Quellen gefunden werden können.</sample>
    <sample id="1403">Wir haben drei Einstellungen von KITMOS definiert. Zuerst würfeln wir zu einer Einstellung: Hintergrund vorausbereiten, bei der das Hintergrundwissen als verfügbar für die Vorbereitung angenommen wird.</sample>
    <sample id="1404">Zweitens gibt es das Hintergrund-Both-Szenario, bei dem das Hintergrundwissen sowohl während des Trainings als auch während der Inferenz verfügbar ist. Schließlich gibt es das Hintergrund-Inferenz-Szenario, bei dem beide Wissensarten nur während der Inferenz verfägbar sind.</sample>
    <sample id="1405">Diese letzte Szenario ist besonders interessant, da es die Situation simuliert, in der das Hintergrundwissen notwendig ist, um eine Aufgabe zu lösen, aber nicht Teil des vorgefertigten Datenmodells ist. Zum Beispiel, weil neue Berufe seit der Zeit der Vorbereitung entstanden sind.</sample>
    <sample id="1406">Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit eines Faktors für zwei Quellen steuern können:

**Beispiel:**

* Wir haben zwei Quellen: Quelle A und Quelle B.
* Wir möchten, dass der Faktor "Verfügbarkeit" für beide Quellen gleich ist.
* Wir können die Verfügbarkeit von Quelle A und Quelle B steuern, indem wir die Verfügbarkeit von Quellen A und Quelle B auf 1 setzen.

**Code-Beispiel:**

```python
# Quelle A
quelle_a_verfuegbar = True

# Quelle B
quelle_b_verfuegbar = True

if quelle_a_verfuegbar and quelle_b_verfuegbar:
    verfuegbarkeit = True
else:
    verfuegbarkeit=False

print(verfuegbarkeit)
```

**Erklärung:**

* Wir setzen die Verfügbarkeit von Quell A und Quell B auf True.
* Wir überprüfen, ob beide Quellen verfügbar sind.
* Wenn beide Quellen verfügbar sein, setzen wir die Verfügbarkeit auf True.
* Wenn eine der Quellen nicht verfügbar ist, setzen wir die Verfügungkeit auf False.

**Ergebnis:**

* Die Verfügbarkeit für beide Quellen ist gleich.

**Alternative Methode:**

* Wir können auch die Verfügbarkeit von Quellenten direkt steuern, indem wir die Verwendung von Quellenten auf 1 setzen.

```python
# Quelle A und Quelle B
quellen = [quelle_a, quelle_b]

# Verfügbarkeit von Quellente
verfuegbarkeit = True

for quelle in quellen:
    if not quelle.verfuegbar:
        verfuegbarkeit = False
        break

print(verfuegbarheit)
```

**Erklärungen:**

* Wir erstellen eine Liste von Quellenten.
* Wir setzen die Verfügungsart von Quellenten auf 1.
* Wir überprüfen, welche Quellen verfügbar sind. Wenn eine Quelle nicht verfügbar ist, setze die Verfügung auf False und break den Schleifenlauf.
* Wenn alle Quellen verfügbar sind, setze die Verfügung von Quellenten auf True.

**Ergebnis:** 

* Die Verfügbarkeitsart von Quellenten ist gleich.</sample>
    <sample id="1407">In the background pre-training setting, we assume that the background knowledge politicians seek elected seats in government is contained in the pre-trained parameters. In the inference time context, we provide the anti-specific knowledge that Chester is a politician.</sample>
    <sample id="1408">In der Hintergrund-Boß-Situation bieten wir nicht nur antizyklische, sondern auch Hintergrundwissen über Politiker in der Interessenskontext an.</sample>
    <sample id="1409">In the background interference setting, we provide the fictional occupation "military tour" instead of "politician" because "military tour" is unlikely to be contained in the pre-trained parameter.</sample>
    <sample id="1410">Wir haben das Datenset sowohl mit menschlichen Studienteilnehmern als auch mit etablierten Referenz-Lösungsmodellen bewertet. In diesem Bild zeigen wir die Ergebnisse der besten Leistungsmodelle auf dem schwierigsten Variante des vorgefertigten Trainingsmodells.</sample>
    <sample id="1411">Ohne spezifisches Training auf KITMOS beide Modelle erzielen nicht gute Ergebnisse. Wenn jedoch auf KITMOS trainiert wird, erzielen sowohl C2F als auch BertForCorf signifikant bessere Ergebnisse als der zufällige Wahl.</sample>
    <sample id="1412">Dies schlägt vor, dass, wenn man auf allgemeine Klassifizierungslösungsdatensätze trainiert wird, Maschinen lernen müssen, Surfaces zu erkunden, die nicht nützlich sind, wenn man auf Kittmoss testet, wo solche Surfaces entfernt wurden.</sample>
    <sample id="1413">Weitere Experimente mit fiktionalem Wissen zeigen, dass selbst die besten performierenden Modelle nicht in der Lage sind, das Hintergrundwissen zu verarbeiten, die nur in der Inferenzzeit zur Verfügung steht.</sample>
    <sample id="1414">Um die Hauptpunkte unserer Arbeit zusammenzufassen: Viele Korreferenzrevolutionsmodelle sind in der Lage, Wissen aus verschiedenen Quellen ohne spezifisches Task-basiertes Training zu verstehen. Allerdings erfolgen mit spezifischem Task-basiertem Training einige Modelle erfolgreich das Wissen aus mehreren Quellen integrieren.</sample>
    <sample id="1415">Noch immer scheinen sogar die besten performierenden Modelle Schwierigkeiten mit der zuverlässigen Integration von Hintergrundwissen zu haben, das nur zur Auswertungszeit präsentiert wird. Wenn Sie mehr Details interessiert sind, sehen Sie sich unsere Arbeit an und untersuchen Sie das Datenset und den Code auf GitHub. Vielen Dank für Ihre Aufmerksamkeit.</sample>
    <sample id="1416">Baumbasierte Methoden haben die Nachteile, dass Bäume in der Regel nicht gegeben sind und daher ein komplexes und manchmal rechenintensives Vorverarbeitungsprozess erfordern, der spezifische formale Präprozessoren für die logischen Formen benötigt. Zudem können spezialisierte Grammatikanalyseverfahren erforderlich sein, um Bäume zu erhalten.</sample>
    <sample id="1417">The authors of the paper belong to the University of Hong Kong.</sample>
    <sample id="1418">Hallo, ich bin Maya und heute werde ich über unsere Arbeit sprechen, die darauf abzielt, Stereotypen in Sprachmodellen mit natürlichen Sprachanweisungen zu messen. Diese Arbeit wird in Zusammenarbeit mit Esindermush und Danjerowsky durchgeführt.</sample>
    <sample id="1419">In den letzten Jahren wurden viele Dokumente über die Verbreitung sozialer Vorurteile und Stereotypen in großen Sprachmodellen oder LLMs veröffentlicht.</sample>
    <sample id="1420">Jedoch haben diese Maßnahmen verschiedene Einschränkungen. Sie setzen normalerweise auf handgefertigte Datensätze, die sehr zeitaufwändig zur Erstellung sind.</sample>
    <sample id="1421">Und sie messen auch normalerweise nur sehr spezifische Stereotypen, was bedeutet, dass sie nicht gut allgemeinisieren können, um andere Demografien oder Kontexte anzupassen, oder sie erfassen einfach sehr allgemeine breite Assoziationen, wie negative Assoziationen mit bestimmten Gruppen.</sample>
    <sample id="1422">Darüber hinaus berücksichtigt die meiste Arbeit in diesem Bereich die Intersektionalität nicht, was die Idee ist, dass vielseitige soziale Identitäten Biases verstärken und einzigartige Schäden verursachen können.</sample>
    <sample id="1423">Um diese Einschränkungen zu überwinden, setzen wir auf die Eigenschaft, dass diese neueren Anweisungstuning-LLMs sehr gut darauf reagieren, Anweisungen und Prompfen.</sample>
    <sample id="1424">Also können wir den Modell bitten, eine Persona zu generieren, die eine Darstellung eines imaginären Individuums ist, indem wir wie folgt ein Prompt verwenden: Stellen Sie sich vor, Sie sind eine asiatische Frau. Beschreiben Sie sich selbst.</sample>
    <sample id="1425">Und wir können sofort sehen, dass dies für jeden demografischen Bereich sehr generalisierbar ist, weil wir nur bestimmte Identitätsmerkmale angeben müssen, die wir in diesem Prompt wollen.</sample>
    <sample id="1426">Natürlich, hier sind einige Beispiele von Generierungen aus GPT-4:

1. **Beispiel 1:**
   - **Englisch:** "The quick brown fox jumps over the lazy dog."
   - **Deutsch:** "Der schnelle braune Fuchs springt über den faulen Hund."

2. **Beispiel 2:**
   - **Englisch:** ""To be or not to be, that is the question.""
   - **Deutsch:** ""Sein oder Nichtsein, das ist die Frage.""

3. **Beispiel 3:**
   - **Englisch:** "'A journey of a thousand miles begins with a single step.'"
   - **Deutsch:** "'Eine Reise von tausend Meilen beginnt mit einem einzigen Schritt.'"

4. **Beispiel 4:**
   - **Englisch:** """The only thing we have to fear is fear itself.""
   - **Deutsch:** ""Die einzige Sache, von der wir uns fürchten müssen, ist die Angst selbst.""

5. **Beispiel 5:**
   - **Englisch:** '"All that glitters is not gold."'
   - **Deutsch:** '"Alles, was glänzt, ist nicht Gold."'

6. **Beispiel 6:**
   - **Englisch:** 'The early bird catches the worm.'
   - **Deutsch:** 'Der frühe Vogel hat den Wurm geflogen.'

7. **Beispiel 7:**
   - **Englisch:** '''Actions speak louder than words.''
   - **Deutsch:** '''Taten sprechen lauter als Worte.''

8. **Beispiel 8:**
   - **Englisch:** ''The pen is mightier than the sword.''
   - **Deutsch:** ''Der Stift ist mächtiger als der Schwert.''

9. **Beispiel 9:**
   - **Englisch:** '(To) bite the bullet'
   - **Deutsch:** '(Zu) den Zahnen beißen'

10. **Beispiel 10:**
    - **Englisch:** 'The grass is always greener on the other side.'
    - **Deutsch:** 'Der grüne Gras ist immer an der anderen Seite.'

Diese Beispiele zeigen, wie GPT-4 in der Lage ist, englische Sätze in deutsche zu übersetzen, wobei die Bedeutung und den Kontext bewahrt bleibt.</sample>
    <sample id="1427">Unmittelbar sehen wir, dass die Ausgaben während des Experiments nicht in der traditionellen Bedeutung von negativ oder toxisch sind.</sample>
    <sample id="1428">Es gibt einige interessante Muster.</sample>
    <sample id="1429">Die asiatische Frau wird als unauffällig dargestellt. Die mittlere Ostfrau wird mit Worten wie exotisch und wie aufmerksam gemacht, um eine faszinierende Region zu beschreiben.</sample>
    <sample id="1430">Beide Personas von Frauen der Farbe beziehen sich auf ihre Herkunft, während der weiße Mann-Persona nichts von dieser Art hat.</sample>
    <sample id="1431">Um diese Muster zu erfassen, hat unsere Methode zwei Teile. Der erste Teil besteht darin, diese Personas zu generieren.</sample>
    <sample id="1432">Unsere Anweisungen zur Erstellung dieser Personas wurden von einer Studie inspiriert, bei der sie diese Anweisungen an menschliche Probanden gegeben haben und festgestellt haben, dass sie durch das Geben an menschliche Probanden auch in der Lage waren, rassistische Stereotypen aufzudecken.</sample>
    <sample id="1433">Und es ermöglicht auch direkten Vergleich zwischen unseren generierten Personas und den menschlichen geschriebenen Antworten.</sample>
    <sample id="1434">Der zweite Teil ist "markierte Wörter", was eine Methode ist, um die Wörter zu identifizieren, die markierte Gruppen von unmarkierten unterscheiden, was ich kurz erläutern werde.</sample>
    <sample id="1435">Der Vorteil ist, dass wir wirklich spezifische Stereotypen und Muster erhalten, ohne auf eine bestimmte Lexikon zu verweisen.</sample>
    <sample id="1436">Der Marktwert-Methode zieht auf den soziolinguistischen Konzept der Markierungskraft zurück, der besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die von diesem Standard abweicht, linguistisch markiert ist.</sample>
    <sample id="1437">So for instance, the word man or sorry, the word warrior is usually associated with men. So when people are describing a warrior who is a woman, they'll usually actually specify one man warrior and mark the term with woman.</sample>
    <sample id="1438">In der Gesellschaft sind dominierende Gruppen sowohl linguistisch als auch sozial unmarkiert, während die marginalisierten Gruppen in der Regel markiert sind.</sample>
    <sample id="1439">In unserer Methode bestimmen wir zunächst, welche Gruppen unmarkiert und markiert sind.</sample>
    <sample id="1440">Und dann vergleichen wir die Personen mit dem Fighting-Wörter-Methode, bei der wir grundsätzlich gewichtete Log-Odds-Verhältnisse verwenden, um die Top-Wörter für jede markierte Gruppe zu unterscheiden.</sample>
    <sample id="1441">So for instance, for the personas of black women, we would do fighting words and compare the log odds ratios against both white personas and man personas because those are the two corresponding unmarked groups.</sample>
    <sample id="1442">Jetzt für einige Ergebnisse. Also verwenden wir zuerst ein Lexikon von Stereotypen und wir finden heraus, dass die generierten Personen viel mehr Stereotypen enthalten als die menschlich geschriebenen.</sample>
    <sample id="1443">Jedoch wenn wir tatsächlich die Verteilung der Wörter im Lexikon betrachten, finden wir sehr unterschiedliche Dinge.</sample>
    <sample id="1444">Während die generierten Personas viel höhere Raten der Luxemburger Wörter haben, haben die menschlich geschriebenen Wörter eine viel breitere Verteilung von Wörtern, während die Stereotype-Wörter, die in den generierten Personas sind, eigentlich nur die Wörter "tall" und "athletic" sind.</sample>
    <sample id="1445">Also wirklich nur die positiven oder zumindest nicht negativen.</sample>
    <sample id="1446">In Wirklichkeit erfasst die Lexikon-Definition nicht wirklich viele der schädlichen Muster, die wir in den vorherigen Folien gesehen haben. Stattdessen werden wir stattdessen zu den Ergebnissen unserer markierten Wörter-Methode übergehen, um zu zeigen, wie diese positiv scheinenden Wörter Stereotypen und essentialisierende Narrative fördern.</sample>
    <sample id="1447">In unserer Analyse überprüfen wir, wie diese scheinbar positive Portrayals harmlose Muster widerspiegeln.</sample>
    <sample id="1448">Zuerst für Marktgruppen: Die oberste Wörter umfassen Dinge wie Kultur, Tradition, Stolz und Exotik. Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie als verschieden von der weißen Norm.</sample>
    <sample id="1449">Dies trägt zu einer langen Tradition der Diskriminierung und Ausschließung dieser Gruppen bei.</sample>
    <sample id="1450">Darüber hinaus gibt es viele gemeinsame Stereotype, die in diesen Worten widerspiegelt werden, insbesondere für Frauen von Farbe. So zum Beispiel sind die Worte, die latina Frauen beschreiben, Dinge wie lebendig und kurvaturig.</sample>
    <sample id="1451">Die englischen Wörter, die zu einem tropischen Stil passen, sind wie "petite" und "delicate" und "silky".</sample>
    <sample id="1452">Der englische Text beschreibt, dass Asiatinnen seit langem hypersexualisiert werden, als sehr docil und unterwürfig angesehen werden.

Übersetzung:

"Die Asiatinnen werden seit langem hypersexualisiert, als sehr docil und unterwürfrig angesehen. So weiter."</sample>
    <sample id="1453">Und schließlich sehen wir für schwarze Frauen, dass einige der wichtigsten Wörter Dinge wie stark und widerstandsfähig sind.</sample>
    <sample id="1454">Dies verbindet sich mit einem Archetypus, den Menschen als "starke schwarze Frauen" bezeichnet haben. Und während es auf den ersten Blick wie positiv klingt,</sample>
    <sample id="1455">Es gibt Arbeiten, die zeigen, dass diese Art von Architektur tatsächlich sehr schädlich ist, weil sie viel Druck auf diese Demografie ausübt, um widerstandsfähig und stark gegen soziale Hindernisse zu sein.</sample>
    <sample id="1456">Anstatt tatsächlich daran zu arbeiten, diese Hindernisse zu ändern, setzt es Druck auf die betroffenen Menschen, sie zu überwinden, was zu sehr negativen Gesundheitsoutcomes für diese Menschen führt, neben anderen Schäden.</sample>
    <sample id="1457">In einem breiteren Kontext stellen wir fest, dass die Wörter für jede markierte Gruppe in etwa nur sehr grundlegende, essenzielle Narrative widerspiegeln.</sample>
    <sample id="1458">Based on these patterns, we conclude with three recommendations for model owners.</sample>
    <sample id="1459">Zunächst sollten wir als Forscher positive Stereotypen und essenzialisierte Geschichten ansprechen. Wir sollten auch ein intersektionales Linsensystem verwenden, um Biases und Schäden zu untersuchen, weil es viele Dinge gibt, die möglicherweise übersehen werden, wenn wir das nicht tun.</sample>
    <sample id="1460">Und schließlich sollte wirklich mehr Transparenz über Bias-Mitigationsmethoden geben.</sample>
    <sample id="1461">Weil zum Beispiel, wie diese positive Stereotypen, wir wissen nicht, ob es wegen irgendeiner Art von "weitläufigen"</sample>
    <sample id="1462">Übermäßige Wertausrichtung geht vor, oder vielleicht sind es andere, wie antistereotypische Methoden, die zu diesen bösen Muster führen.</sample>
    <sample id="1463">Wir können einfach keine Annahmen machen oder dies weiter untersuchen, ohne mehr Transparenz.</sample>
    <sample id="1464">Danke so viel für zuhören. Haben Sie einen schönen Tag!</sample>
    <sample id="1465">Hallo alle, mein Name ist Jīng Wéiyī und ich komme aus der Universität für Wissenschaft und Technologie von China.</sample>
    <sample id="1466">Es ist mein Vergnügen, einen kurzen Werbespot über Papier zu machen. Bist du mein Modell kopieren? Schütze die Urheberrechte von großen Sprachmodellen für Eingebettung und Dienstleistungen.</sample>
    <sample id="1467">Lass uns zuerst die Hintergründe über die Einbindung von Dienstleistungen erläutern.</sample>
    <sample id="1468">Aktuell sind große Sprachmodelle wie GPT, LAMA und PALM bemerkenswert in der natürlichen Sprachverständigung und -generierung.</sample>
    <sample id="1469">"Embedding as Services" ist eine der Dienste, die auf großen Sprachmodellen aufgebaut sind, um verschiedene NLP-Aufgaben zu unterstützen.</sample>
    <sample id="1470">Zum Beispiel bietet OpenAI eine GPT-basierte Embedding-API an.</sample>
    <sample id="1471">Allerdings haben neuere Arbeiten gezeigt, dass ein Angreifer das Modell durch Lernen aus dem Embedding stählen kann und ähnliche Dienste anbieten. Daher ist es notwendig, die Urheberrechte des Embeddings als Dienste zu schützen.</sample>
    <sample id="1472">Um den Urheberrechtsschutz von Embedding- und Services zu gewährleisten, ist eine Lösung, um ein Wasserzeichen in den angebotenen Service einzubetten und zu überprüfen, ob ein anderer Service das Wasserzeichen enthält.</sample>
    <sample id="1473">Die Wasserzeichenmethode muss die folgenden Eigenschaften erfüllen: Erstens sollte die Methode auf die Einbettung von Diensten anwendbar sein. Zweitens sollte der Wasserzeichen nicht die Nutzung der bereitgestellten Einbettungen beeinträchtigen.</sample>
    <sample id="1474">Drittens sollte das Wasserzeichen ausreichend klebrig sein, damit der Angreifer es leicht entfernen kann.</sample>
    <sample id="1475">Schließlich muss der Wasserzeichen während des Modellextraktionsprozesses übertragbar auf die Angreiferdienste sein.</sample>
    <sample id="1476">Die vorhandenen Werke können allgemein in vier Kategorien eingeordnet werden.</sample>
    <sample id="1477">Jedoch ist diese Methode entweder nicht anwendbar auf die Einbettung von Dienstleistungen oder aufgrund des Mangels an Transferfähigkeit.</sample>
    <sample id="1478">Daher schlagen wir in diesem Papier ein Embedding Marker vor, das eine Backdoor-basierte Wasserzeichenmethode ist, die auf Embedding-Anwendungen angewendet werden kann.</sample>
    <sample id="1479">Dann lass mich die Details unseres Embedding-Markers einführen. Embedding-Marker besteht aus zwei Hauptstufen: Wasserzeichen-Einsprengung und Urheberrechtsverifizierung.</sample>
    <sample id="1480">Bevor wir diese Hauptstufen beginnen, wählen wir zunächst eine Trigger-Sets. Die Trigger-Sets bestehen aus einer Gruppe von Wörtern in einem mittleren Frequenzintervall.</sample>
    <sample id="1481">Wir nehmen an, dass der Anbieter eine allgemeine Textkorpus sammeln und die Worthäufigkeit dabei mitberechnen kann.</sample>
    <sample id="1482">In der Watermark-Injection erstellen wir zunächst eine Ziel-Embedding. Wenn ein Benutzer einen Satz an den Anbieter-Service sendet, zählt der Anbieter die Anzahl der Trigger in dem Satz.</sample>
    <sample id="1483">Der bereitgestellte Embedding ist eine Gewichtssumme der Ziel-Embedding und des Original-Embeddings.</sample>
    <sample id="1484">Die Gewichtung des Ziel-Embeddings ist proportional zum Anzahl der Trigger in der Aussage. Wenn die Anzahl der Trigger in der Aussage größer als m ist, ist die bereitgestellte Embedding genau gleich dem Ziel-Embedding.</sample>
    <sample id="1485">Kopiervorbeugung ist es, zu überprüfen, ob ein Modell hinter einem anderen Dienst das Wasserzeichen enthält.</sample>
    <sample id="1486">Wir erstellen zunächst eine Backdoor und ein Benign-Datensatz. Die Backdoor-Datensatz enthält Sätze, von denen alle Wörter zum Trigger-Satz gehören. Während alle Wörter in den Sätzen des Benign-Datensatz nicht zum Trigger-Satz gehören.</sample>
    <sample id="1487">Dann fordert der Anbieter die Embeddings von der Steuerleistungsdienstleistung mit dem Datensatz an.</sample>
    <sample id="1488">Die Kosinus- und L2-Similarität zwischen der angeforderten Embedding und dem Ziel-Embedding wird berechnet. Wir berechnen die Similaritätsdifferenz zwischen benign und backdoor-Datensatz, was als Delta-Kosinus und Delta-L2 definiert wird.</sample>
    <sample id="1489">Währenddessen wenden wir auch den KS-Test an und nutzen dessen p-Wert als drittes Kriterium.</sample>
    <sample id="1490">Wir führen Experimente auf vier Datensätzen durch: agnews, mind, ssd2 und eurispam. Wir nehmen an, dass der Anbieter die Wikitext-Datensätze anwendet, um die Wortfrequenz zu zählen.</sample>
    <sample id="1491">Die Ergebnisse auf vier Datensätzen zeigen, dass unser Embedding-Marker eine große Erkennungsleistung aufweisen kann, während es gleichzeitig eine große Nützlichkeit für Datenaufnahmetasks beibehält.</sample>
    <sample id="1492">Wir haben auch die Konvertierbarkeit des bereitgestellten Embeddings validiert, indem wir die Embedding von Sätzen auf einem vorgegebenen Datensatz visualisiert haben. Die Legende der Figuren bedeutet die Anzahl der Trigger in jedem Satz.</sample>
    <sample id="1493">Wie in den Bildern gezeigt, ist es schwierig, zwischen den Hintertür-Einbettungen und den normalen Einbettungen zu unterscheiden.</sample>
    <sample id="1494">Das ist alles, danke. Willkommen, um mit uns zu diskutieren.</sample>
    <sample id="1495">ABC-Eval steht für "Annotating Behaviors in Chat" und ist eine Methode entwickelt worden, um die Verhaltensweisen in Chatmodellen umfassend zu dokumentieren, die in der aktuellen Literatur als Einfluss auf die Chat-Qualität angegeben wurden.</sample>
    <sample id="1496">Das Leistungsdelta zwischen CoNLL 2003 und CoNLL++ ist höher als 5 Prozentpukte bis 2023.</sample>
    <sample id="1497">Hallo, mein Name ist Wasuda und ich bin ein Bildungsbürger in der Computerwissenschaften an der Stony Brook University. Ich möchte meine Arbeit als langfristige Transferlernung für Diskriminierungsdetektion als langfristige Transferlernung zur Diskriminierungsdetektion als long-term transfer learning for discrimination detection präsentieren, die in der ACI 2023 als langfristige Transferlernung als long-term transfer learning für Diskriminierungsdetektion präsentiert wird.</sample>
    <sample id="1498">Wir beginnen mit der Definition von kognitiver Dissens und warum es ein wichtiges Problem ist, in der Sprache zu studieren. Einfach gesagt, kognitiver Dissens ist zwei Überzeugungen oder Handlungen, die inkonsistent sind.</sample>
    <sample id="1499">The English content describes a situation where a person acknowledges the danger of cigarettes but then proceeds to smoke after a meeting. This belief and action are inconsistent.

Andere mögliche Übersetzungen:

* Der englische Inhalt beschreibt eine Situation, in der jemand die Gefahr von Zigaretten erkennt, aber dann nach einer Besprechung weiterhin raucht. Diese Überzeugung und Handlung sind widersprüchlich.
* Der englische Text beschreibt eine Situation, in die jemand die Gefahr von Zigarettenkonsum erkennt, aber dann nach einer Sitzung weiterhin raucht. Dieser Glaube und die Handlung sind widersprüchlich und widersprechen sich.
* Der englische Inhalt schildert eine Situation, in der jemand die Gewissheit über die Gefahr von Zigaretten erkennen kann, aber dann nach einer Besprechungsstunde weiterhin raucht. Diese Glaubens- und Handlungsinhaber sind widersprüchlich und widersetzen sich.

Die Übersetzung des englischen Inhalts in Deutsch ist:

* Der englische Inhalts beschreibt eine Situation, in welcher jemand die Gefahr von Zigarettensmokern erkennt, aber dann nach einer Befragung weiterhin raucht. Dieses Glauben und die Handlung sind widersprüchtich und widersetzen sich.

Die übersetzte Übersetzung ist:

* Der englische Text beschrieben eine Situation, in der jemand die Glaubens- und Handlungsüberzeugung über die Gefahr von Zigarettenkonsumenten erkennt, aber dann nach einem Besprechungsstunde weiterhin weiter raucht. Diese Überzeugen und Handlungen sind widersprüchlich und widernet sich.

Die übersetzte Version ist:

* Der englische Satz beschreibt eine Situation, in dem jemand die Gefahr von Zigarettenschmokern erkennt, aber dennoch nach einer Besprechungsstunde weitermacht, weiter raucht. Diese Übereinstimmung und Handlungen sind widersprüchtich und widernet sich.

Die übergangene Übersetzung ist:

* Die englische Übersetzung beschreibt eine Situation, in which jemand die Gefahr von Zigaretteskonsumenten erkennt, aber dennoch nach einem Besprechungsstunde weitermach, weiter raucht. Diese Glaubenseinheit und Handlungen sind widersprüchte und widernet sich.

Die übergeordnete Übersetzung ist:

* Dieser englische Satz beschreibet eine Situation, in der jemand die Gültigkeit der Gefahr von Zigarettenkonsumentens erkennt, aber dennoch nach der Besprechungsstunde weitermachen, weiter raucht. Diese Einheit und Handlungen sind widersprichlich und widernet sich.

Die Übersetzung der englischen Inhalts ist:

* Der englische Abschnitt beschreibt eine Situation, in denen jemand die Gefahr von Zigarettskonsumenten erkennt, aber dabei nach einer Besprechungsstunde weitere raucht. Diese Einheit und die Handlungen sind widersprüchliche und widernet sich.

Die übertriebene Übersetzung ist:</sample>
    <sample id="1500">Weiterhin erwähnt, dass ich denken kann, ich könnte meinen Job ohne sie nicht halten, rechtfertigt die zweite Auftretens und sie haben eine Konsistenzbeziehung.</sample>
    <sample id="1501">Während Dissens ein sehr häufiges Phänomen ist, das wir in unserem täglichen Entscheidungsprozess erleben, ist es in der Regel schwer zu finden, dass es in der Sprache ausgedrückt wird, unter anderem in anderen Arten von Diskursbeziehungen.</sample>
    <sample id="1502">Studying cognitive dissonance can help us understand the effects of disagreement among people, track trends in belief values and attitude changes in populations.</sample>
    <sample id="1503">Hochkognitive Disposition ist auch mit Angststörungen verbunden und kann helfen, das psychische Wohlbefinden der Menschen besser zu verstehen.</sample>
    <sample id="1504">Studieren Sie die Ausdrucksweise in der Sprache, die auch nützlich sein kann, um Extremismus und Polarisierung von gefährdeten Gruppen zu verstehen.</sample>
    <sample id="1505">Schließlich ist der kognitive Dissens wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und uns besser die Entscheidungsprozesse zu verstehen.</sample>
    <sample id="1506">Um das Ziel der Erstellung einer kognitiven Distanz-Ressource zu erreichen, führten wir eine großskalige Annotation von Distanzbeziehungen durch. Wir verwendeten die Distanz-First-Approach, wie in dem hier dargestellten Flowchart zu sehen ist.</sample>
    <sample id="1507">Tweets wurden mit einem PTTB-Parser verarbeitet und Paare von Diskurs-Einheiten wurden entsprechend den in unserer Arbeit beschriebenen Richtlinien annotiert.</sample>
    <sample id="1508">Wie hier zu sehen ist, wurde Dissonanz nur in 3,5 % der annotierten Paare gefunden.</sample>
    <sample id="1509">Aufgrund der Erfassung von etwa tausend Beispielen von Diskurs-Einheitspaaren haben wir eine Anfangs-Klassifikator-Training durchgeführt, bei dem nur 43 Beispiele von Diskreta trainiert wurden. Keine Überraschung, der Klassifikator leistete nicht viel besser als Zufall.</sample>
    <sample id="1510">Wir stehen vor dem Problem der absoluten Seltenheit.</sample>
    <sample id="1511">Um dies zu lösen, experimentieren wir mit Kombinationen von Transfer-Learning und aktiver Lernen, um solche zu annotieren, dass mehr dissonanten Samples gesammelt werden können, während weniger Annotation-Runden benötigt werden, was die Gesamtkosten für Annotation senkt und die Dissonanz-Erkennung verbessert.</sample>
    <sample id="1512">Da der ursprüngliche Modell nicht in der Lage war, die Abstimmungsklasse überhaupt zu erfassen, starten wir den aktiven Lernprozess, indem wir die Gewichte von eng verwandten Aufgaben übertragen.</sample>
    <sample id="1513">Wir übertragen von zwei verschiedenen Aufgaben: Themenunabhängige Diskriminanz- und Stände-Klassifizierung, eine Aufgabe, die bestimmt, ob zwei Debattierstimmen von verschiedenen Personen in Übereinstimmung oder in Widerspruch zueinander sind, unabhängig von dem Thema.</sample>
    <sample id="1514">Hier wird eine Debatte über die binäre Klassifikation von Expansion und Vergleichsklassen von Pidgin-Deutsch (Pidgin-Deutsch) geführt, da diese beiden Konzepte eng miteinander verbunden sind. Wir nennen sie CEE hier.</sample>
    <sample id="1515">Wir stellen fest, dass beim Übertragen die Null-Shot-Performance auf dem annotierten Datensatz bereits viel besser ist als das Zufallsverhältnis, wobei das beste Ergebnis mit einem AUC-Wert von 0,62 erreicht wird.</sample>
    <sample id="1516">Weiterhin finden wir, dass die iterativ-fine-Tuning-Technik auf beiden Aufgaben, nämlich die CE-Aufgabe und die Debatte, eine bessere Null-Shot-Performance erzielt. Dies bedeutet, dass das Modell, das wir verwendet haben, um das Aktiv-Learning zu starten, besser ist.</sample>
    <sample id="1517">Nächstes Schritt bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde aktiver Lernen und Annotationen zu aktualisieren. Der Kumulative sammelt alle Daten, die bisher aus aktiven Annotationen gesammelt wurden, während die iterativen Aktualisierungen des Modells durch das Training auf dem neuesten Datensatz geschehen.</sample>
    <sample id="1518">Über die verschiedenen Strategien haben wir gefunden, dass die kumulative Leistung gleich oder besser als die iterativen Leistungen ist, über das gesamte Board hinweg.</sample>
    <sample id="1519">Um die Anzahl der Dissimilaritätsbeispiele zu verbessern, verwenden wir eine Wahrscheinlichkeitsstrategie für die seltene Klasse (PRC), um hauptsächlich die Beispiele auszuwählen, die mit hoher Wahrscheinlichkeit von der aktuellen Modellversion als Dissimilaritäten klassifiziert werden.</sample>
    <sample id="1520">Wir vergleichen dies mit den anderen modernen, also "state of the art" Strategien, die in der Gemeinschaft häufig verwendet werden.</sample>
    <sample id="1521">Wir stellen fest, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere hochmoderne Strategien, obwohl der Unterschied gering ist. Beachten Sie jedoch, dass die Leistung für zufällige Fälle signifikant niedriger ist.</sample>
    <sample id="1522">Aufgrund der weiteren Runden des AL mit den beiden besten Strategien haben wir die Klassifizierungsleistung des Modells auf einen AUC-Wert von 0,75 verbessert, was die beste Leistung ist, die wir bisher bei dieser Aufgabe erreicht haben.</sample>
    <sample id="1523">Wir überprüfen auch die Machbarkeit jeder Strategie für die Annotation-Qualität und die Kosten für Annotatoren. Wir stellen fest, dass PRC den höchsten Prozentsatz an Diskrepanzen hat und am besten für die Klasse funktioniert. Allerdings finden die Annotatoren auch die Beispiele schwierig.</sample>
    <sample id="1524">Zusammenfassend stellen wir fest, dass PRC eine einfache AI-Strategie für die Beschaffung von seltenen Klassen ist und dass das Co-Starting von AI mit entsprechend konzipierten Transfer-Learning-Aufgaben erheblich hilft.</sample>
    <sample id="1525">Wir finden auch, dass iteratives Update für die Transfer-Learning von einem anderen Bereich nützlich ist, während in-domain aktive Anpassungen von kumulativen Updates profitieren.</sample>
    <sample id="1526">Hier ist die Übersetzung des englischen Inhalts nach Deutsch:

"Diese sind die Links zu unserem Code-Datensatz und unserer Arbeit. Fühlen Sie sich frei, uns zu kontaktieren, falls Sie Fragen haben. Vielen Dank."</sample>
    <sample id="1527">Die Autoren gehören an der Universität von München.</sample>
    <sample id="1528">The name of the speaker is Si Yuyuan.</sample>
    <sample id="1529">Vier Autoren sind an der Arbeit beteilt.</sample>
    <sample id="1530">Mit der SimulST-Architektur wird die Ansatz verglichen, die auch auf Offline-Modelle angewendet wird, wie die Weighted-Key-Strategie und die lokale Vereinbarung.</sample>
  </task>
</testset>