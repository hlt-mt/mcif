<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Language Models sind Pretraining Data, die aus großen Textkorpora bestehen, die von verschiedenen Quellen stammen, wie zum Beispiel Wikipedia, Bücher und Online-Artikel. Diese Datenquellen liefern die Grundlage für das Pretraining von Language Models, bei dem das Modell auf eine Vielzahl von Texten trainiert wird, um eine umfassende Sprachverständigung zu entwickeln.</sample>
    <sample id="1">McGill University</sample>
    <sample id="2">DEPLAIN: Ein deutscher Parallelkorpus mit intralingualen Übersetzungen in einfache Sprache für Satz- und Dokumentvereinfachung  
Regina Stodden, Omar Momen, Laura Kallmeyer  
Heinrich Heine Universität Düsseldorf, Deutschland  
ACL 2023</sample>
    <sample id="3">DEPLAIN: Ein deutscher Parallelkorpus mit intralingualen Übersetzungen in einfache Sprache für Satz- und Dokumentvereinfachung  
Regina Stodden, Omar Momen, Laura Kallmeyer  
Heinrich Heine Universität Düsseldorf, Deutschland  
ACL 2023</sample>
    <sample id="4">The video shows a presentation slide titled "Text Simplification Example" with a comparison between the original and simplified German text. The original text is "Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden." and the simplified text is "Die Gewerkschaft stellt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein." The slide highlights the simplification techniques used, such as substitution, clause deletion, reordering, and word deletion.</sample>
    <sample id="5">The video shows a presentation slide titled "Text Simplification Example" with a comparison between the original German text and its simplified version. The slide is divided into two sections: the left side shows the original German text, and the right side shows the simplified version. The text on the slide is as follows:

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plain Language:
"Die Gewerkschaft stellt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."

The slide also includes a legend with four categories: Substitution, Clause Deletion, Reordering, and Word Deletion, each represented by a different color. The legend is used to indicate the types of changes made to the original text to create the simplified version. The video does not include any additional information or context beyond the text on the slide.</sample>
    <sample id="6">The video shows a presentation slide titled "Text Simplification Example" with a comparison between the original German text and its simplified version. The original text is "Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden." and the simplified version is "Die Gewerkschaft setz sich zum Beispiel für höhere Löhne oder mehr Urlaub ein." The slide highlights the changes made during the simplification process, including substitution, clause deletion, reordering, and word deletion.</sample>
    <sample id="7">The video shows a presentation slide titled "Text Simplification Example" with a comparison between the original German text and its simplified version. The original text is "Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden." and the simplified version is "Die Gewerkschaft setz sich zum Beispiel für höhere Löhne oder mehr Urlaub ein." The slide highlights the changes made during the simplification process, including substitution, clause deletion, reordering, and word deletion.</sample>
    <sample id="8">2. DE-plain: Ein neues Korpus</sample>
    <sample id="9">Die folgende Übersetzung des englischen Textes in Deutsch lautet:</sample>
    <sample id="10">Die folgende Übersetzung des englischen Textes in Deutsch:</sample>
    <sample id="11">Die folgende Übersetzung des englischen Textes in Deutsch lautet:</sample>
    <sample id="12">Die folgende Übersetzung des englischen Textes in Deutsch lautet:</sample>
    <sample id="13">Die folgende Übersetzung des englischen Textes in Deutsch:</sample>
    <sample id="14">Der Präsident des Vereins für die Förderung der Wissenschaft und Technik in Deutschland, Dr. Hans Müller, hat sich in seinem Jahresbericht für die Zukunft der Wissenschaft und Technik ausgesprochen. Er betont die Bedeutung von Innovationen und Forschung für die Gesellschaft und die Wirtschaft. Müller fordert eine stärkere Unterstützung für die Wissenschaft und Technik durch die Regierung und die Privatwirtschaft. Er sieht auch die Notwendigkeit, die Ausbildung in diesen Bereichen zu verbessern und die Förderung von junge WissenschaftlerInnen und Ingenieuren zu fördern.</sample>
    <sample id="15">Der englische Text beschreibt zwei Diagramme, die die verschiedenen Typen von Simplifizierung und die Simplifikationsumwandlungen in zwei verschiedenen Textkategorien darstellen.</sample>
    <sample id="16" />
    <sample id="17" />
    <sample id="18" />
    <sample id="19">3. Use-cases: Automatic alignment and simplification</sample>
    <sample id="20">Das Bild ist ein Screenshot eines Präsentationsfolien, das den Titel "Automatic Alignment Evaluation" enthält. Der Titel ist in einem blauen Bereich mit einem symbolischen Bild von zwei Pfeilen oben rechts positioniert. Unter dem Titel findet sich eine Tabelle, die die Ergebnisse verschiedener automatischer Alignment-Methoden mit 1:1 (obere Hälfte) und n:m (untere Hälfte) Fähigkeiten darstellt. Die Tabelle enthält die folgenden Spalten: "Name" (Name), "Description" (Beschreibung), "P" (P), "R" (R), "F" (F), "P1" (P1), "R1" (R1), "F1" (F1), "P2" (P2), "R2" (R2), "F2" (F2). Die Spalten "P", "R", "F", "P1", "R1", "F1", "P2", "R2", "F2" enthalten Zahlenwerte, die die Leistung der verschiedenen Methoden in verschiedenen Kategorien misst. Die Tabelle enthält die Namen und Beschreibungen verschiedener Methoden wie "LHA", "Sent-LaBe", "Sent-LaBeR", "VcAlign", "BERTAlign", "MASSalign". Die Tabelle zeigt, dass die Methoden LHA, Sent-LaBe, Sent-LaBeR, VcAlign, BERTAlign und MASSalign verschiedene Leistungen in verschiedenen Kategorien erzielen. Die Methoden LHA, Sent-LaBe, BERTAlign und MASSalign erzielen die besten Leistungen in den Kategorien P, R, F, P1, R1, F1, P2, R2, F2. Die Methoden Sent-LaBeR und VcAlign erzielen die besten Leistungen nur in den Kategorien P, R, P1, R1, P2, R2. Die Methoden LHA, Sent-La</sample>
    <sample id="21">The video presents a detailed comparison of various automatic alignment methods, focusing on their performance with 1:1 and n:m capabilities. The table in the video lists several methods, including LHA, Sent-LaBaSe, Sent-ReBERTa, VecAlign, BERTalign, and MASSalign, each with a brief description and corresponding performance metrics. The metrics include Precision (P), Recall (R), and F1 score (F1), which are used to evaluate the accuracy and effectiveness of each method in aligning sentences. The video highlights the strengths and weaknesses of each method, providing insights into their suitability for different alignment tasks.</sample>
    <sample id="22">The video shows a presentation slide with the title "Automatic Alignment Evaluation" and a table comparing different alignment methods. The table includes columns for "Name," "Description," and various performance metrics such as "P," "R," "F1," and "F0.5." The methods listed are:

1. **LHA**: Heuristic alignment using sentence embeddings similarity.
2. **Sent-LaBaSe**: Similar embeddings of Language-agnostic BERT transformer.
3. **Sent-ReBERTa**: Similar embeddings of Cross English &amp; German ReBERTa.
4. **VecAlign**: Multilingual aligner based on multilingual sentence embeddings.
5. **BERTalign**: Allows sentence-transformer methods produce n alignments.
6. **MASSalign**: A vicinity-driven approach with a TF-IDF similarity matrix.

The table provides numerical values for each method across the performance metrics, indicating their effectiveness in alignment tasks.</sample>
    <sample id="23">The video shows a presentation slide with the title "Automatic Alignment Evaluation" and a table comparing different alignment methods. The table includes columns for "Name," "Description," and various performance metrics such as "P," "R," "F1," and "F0.5." The methods listed are:

1. **LHA**: Heuristic alignment using sentence embeddings similarity.
2. **Sent-LaBaSe**: Similar embeddings of Language-agnostic BERT transformer.
3. **Sent-ReBERTa**: Similar embeddings of Cross English &amp; German ReBERTa.
4. **VcAlign**: Multilingual aligner based on multilingual sentence embeddings.
5. **BERTalign**: Allows sentence-transformer methods produce n alignments.
6. **MASSalign**: A vicinity-driven approach with a TF-IDF similarity matrix.

The table provides numerical values for each method across the performance metrics, indicating their effectiveness in alignment tasks.</sample>
    <sample id="24">The video shows a presentation slide with the title "Automatic Alignment Evaluation" and a table comparing different alignment methods. The table includes columns for "Name," "Description," and "P," "R," "F1" scores for each method. The methods listed are:

1. **LHA**: Heuristic alignment using sentence embeddings similarity.
2. **Sent-LaBaSe**: Similar embeddings of Language-agnostic BERT transformer.
3. **Sent-ReBERTa**: Similar embeddings of Cross English &amp; German ReBERTa.
4. **VecAlign**: Multilingual aligner based on multilingual sentence embeddings.
5. **BERTalign**: Allows sentence-transformer methods produce n alignments.
6. **MASSalign**: A vicinity-driven approach with a TF-IDF similarity matrix.

The table provides scores for precision (P), recall (R), and F1 score (F1) for each method, indicating their performance in automatic alignment tasks.</sample>
    <sample id="25">The video shows a person presenting the results of automatic alignment evaluation. The presenter is standing in front of a whiteboard with a blue header that reads "Automatic Alignment Evaluation." The whiteboard contains a table with the results of different alignment methods, including LHA, Sent-LaBaSe, Sent-ReBERTa, VecAlign, BERTalign, and MASSalign. The table shows the precision, recall, and F1 score for each method, as well as the number of sentences aligned. The presenter explains the results and discusses the strengths and weaknesses of each method. The video is shot in a classroom setting, with the presenter standing in front of a whiteboard and a projector screen displaying the results. The presenter is wearing a black shirt and has a beard. The video is in English and is approximately 10 minutes long.</sample>
    <sample id="26">The video shows a presentation on automatic alignment evaluation, focusing on the results of various alignment methods. The presenter discusses the performance of different methods, including LHA, Sent-LaBaSe, Sent-ReBERTa, VecAlign, BERTalign, and MASSalign, in terms of precision, recall, and F1 score. The results are presented in a table format, with each method's description and performance metrics listed. The presenter highlights the strengths and weaknesses of each method, providing insights into their effectiveness in different alignment scenarios. The video concludes with a summary of the findings and a discussion on potential future improvements.</sample>
    <sample id="27">Das Video zeigt eine Präsentation über die automatische Textvereinfachung, wobei der Fokus auf der Dokumentebene und der Satzebene liegt. Es wird die Anwendung von finiertem mBART (mehrlingueller Basis-Transformer) zur Textvereinfachung diskutiert, wobei die Trainingsdatenmenge und die Anzahl der Trainingsdurchläufe berücksichtigt werden. Die Präsentation zeigt die Ergebnisse in Form von Tabellen, die die Performance des Modells auf verschiedenen Datensätzen und in verschiedenen Trainingsdurchläufen darstellen. Die Tabellen enthalten Informationen über die BLEU-Scores, die für die Dokumentebene und die Satzebene berechnet wurden. Die Präsentation zeigt, dass die Performance des Modells auf der Dokumentebene und der</sample>
    <sample id="28">Das Video zeigt eine Person, die in einem Raum sitzt und vor einem Computer arbeitet. Auf dem Bildschirm ist ein Diagramm mit verschiedenen Daten und Informationen angezeigt. Der Text auf dem Bildschirm lautet: "Automatic Text Simplification" und "Results on Document Simplification using fine-tuned long-mBART n corresponds to the length of the training data".</sample>
    <sample id="29">Das Video zeigt eine Person, die in einem Raum sitzt und vor einem Computer arbeitet. Der Computer-Desktop ist mit verschiedenen Fenstern angelegt, die Informationen über die automatische Textvereinfachung anzeigen. Die Person scheint sich auf die Analyse der Daten konzentriert zu halten.</sample>
    <sample id="30">Das Video zeigt eine Person, die in einem Raum sitzt und vor einem Computer arbeitet. Der Computer-Display zeigt eine Tabelle mit den Ergebnissen von Textvereinfachung. Die Tabelle ist in zwei Spalten unterteilt: "Dokument Level" und "Satz Level". Die "Dokument Level"-Spalte zeigt die Ergebnisse für die Dokumentvereinfachung, während die "Satz Level"-Spalte die Ergebnisse für die Satzvereinfachung zeigt. Die Tabelle enthält verschiedene Spalten, wie "train_data", "BLEU", "ROUGE-F1", "FRE", "DEPLAN-API test (n=48)" und "DEPLAN-API test (n-1464)". Die Person in dem Video scheint sich mit den Ergebnissen zu beschäftigen und könnte möglicherweise die Textvereinfachung analysieren oder interpretieren.</sample>
    <sample id="31">Das Video zeigt eine Präsentation über die automatische Textvereinfachung, wobei der Fokus auf der Dokumentebene und der Satzebene liegt. Es wird die Anwendung von finiertem mBART (mehrlingueller Basis-Transformer) zur Textvereinfachung diskutiert, wobei die Trainingsdatenmenge und die Anzahl der Trainingsdurchläufe berücksichtigt werden. Die Präsentation zeigt die Ergebnisse in Form von Tabellen, die die Performance des Modells auf verschiedenen Datensät</sample>
    <sample id="32">Das Video zeigt eine Person, die in einem Raum sitzt und vor einem Computer arbeitet. Der Computer-Display zeigt eine Tabelle mit den Ergebnissen von Textvereinfachung. Die Tabelle ist in zwei Spalten unterteilt: "Dokument Level" und "Satz Level". Die "Dokument Level"-Spalte zeigt die Ergebnisse für die Dokumentvereinfachung, während die "Satz Level"-Spalte die Ergebnisse für die Satzvereinfachung zeigt. Die Tabelle enthält verschiedene Spalten, wie "Train Data", "BLEU", "BSP", "FRE", "DEPLAIN-API test (n=48)" und "DEPLAIN-API test (n-1464)". Die Person in dem Video scheint sich mit den Ergebnissen zu beschäftigen und könnte möglicherweise die Textvereinfachung analysieren oder interpretieren.</sample>
    <sample id="33">Das Video zeigt eine Präsentation über die automatische Textvereinfachung, mit einem Fokus auf die Ergebnisse von Dokument- und Satzebene. Es wird auf die Anwendung von finiertem mBART (meist bekannt als mBART) als Modell für die Textvereinfachung eingegangen. Die Präsentation zeigt detaillierte Tabellen, die die Leistung des Modells auf verschiedenen Datensätzen und in verschiedenen Metriken wie BLEU, ROUGE und F1-Score auswerten. Die Tabellen sind in zwei Hauptspalten unterteilt: "Document Level" und "Sentence Level". Im "Document Level" werden die Ergebnisse auf den gesamten Dokumenten angegeben, während im "Sentence Level" die Ergebnisse auf den einzelnen Sätzen analysiert werden. Die Tabellen enthalten Informationen über die Trainingsdaten, die Testdaten und die entsprechenden Metriken. Die Präsentation zeigt, dass das Modell auf verschiedenen Datensät</sample>
    <sample id="34">Für weitere Details. Bitte lesen Sie unseren Beitrag. Und freuen Sie sich auf unsere Plakat im ACL 2023 Konferenz.</sample>
    <sample id="35">Patrick Fernandes</sample>
    <sample id="36">Das T5 XL Modell wurde verwendet, um eine Genauigkeit von 82–-87 % zu erreichen.</sample>
    <sample id="37">Ja, CoNLL-2003-Tagge</sample>
    <sample id="38">Die vorgeschlagene menschliche Bewertungsmethode basiert auf dem Rating der Relevanz der Antworten des Chatbots.</sample>
    <sample id="39">Der Erfolg des bestehenden sch wachten Ansatzes hängt von der Qualität der verwendeten Labels ab.</sample>
    <sample id="40">Das Ergebnis kann verbessert werden, indem man die Anzahl der Anfragen erhöht, die Anzahl der Anfragen erweitert, die Anzahl der Anfragen verkürzt, die Anzahl der Anfragen verbessert, die Anzahl der Anfragens verkürzt, die Anzahl von Anfragen erhöht, die</sample>
    <sample id="41">Es sind 6 Autoren an der Arbeit beteiligt.</sample>
    <sample id="42">Das englische Inhalt des Videos lautet:

"Conjunct Lengths in English, Dependency Length Minimization, and Dependency Structure of Coordination
Adam Przepiórkowski and Michał Wozniak
Institute of Computer Science
Polish Academy of Sciences
ul. Jana Kazimierza 51/51-248 Warsaw
University of Warsaw
ACL 2023"

Der Inhalt des Videos beschreibt die Arbeit von Adam Przepiórkowski und Michał Wozniak, die sich mit der Analyse von Konjunktionslängen in der englischen Sprache, der Minimierung der Abhängigkeitslänge und der Struktur der Abhängigkeitsbeziehungen bei der Koordination beschäftigt. Sie präsentieren verschiedene Ansätze zur Koordination in der englischen Sprache, wie Bouquet/Stanford, Chain/Moscow, Conjunction-headed/Prague und Multi-headed/London, und diskutieren die jeweiligen Abhängigkeitsstrukturen.</sample>
    <sample id="43">Der englische Text beschreibt verschiedene Ansätze zur Koordination in der Syntax, basierend auf den Ansätzen von Bouquet/Stanford, Chain/Moscow, Conjunction-headed/Prague und Multi-headed/London. Es wird erklärt, wie die verschiedenen Ansätze die Beziehung zwischen den Elementen in einem Satz darstellen und wie sie die syntaktische Struktur des Satzes beeinflussen. Die verschiedenen Ansätze werden mit Beispielen und Diagrammen dargestellt, um die Konzepte besser zu verstehen.</sample>
    <sample id="44">Der englische Text beschreibt verschiedene koordinierende Strukturen in der Syntax, die in der Sprache verwendet werden können. Es wird auf verschiedene Methoden eingegangen, wie die Bouquet/Stanford-Strategie, die Chain/Moscow-Strategie, die Konjunktion-headet-Prague-Strategie und die Multi-headed/London-Strategie. Jede Strategie wird mit einem Beispiel ausgeschrieben, um die Anwendung zu verdeutlichen. Die Texte sind als Bilder oder Screenshots vorhanden und können nicht direkt übersetzt werden.</sample>
    <sample id="45">Der englische Text beschreibt verschiedene Arten von Koordinationsstrukturen in der Syntax, basierend auf der Theorie von Bouquet/Stanford. Es wird die "Universelle Abhängigkeitsstruktur" erwähnt, die eine einfache und direkte Art der Darstellung von Koordinationen vorschlägt. Die verschiedenen Arten von Koordinationsstrukturergebnissen werden mit Beispielen aus dem Simpsons-Film "Die Simpsons" erläutert, um die Konzepte besser zu verständlich zu machen. Die Beispiele zeigen, wie die verschiedenen Strukturen die Beziehungen zwischen den Elementen in einem Satz darstellen können.</sample>
    <sample id="46">Der englische Text beschreibt verschiedene koordinierende Strukturen in der Syntax, die in der Sprache verwendet werden können. Es wird auf verschiedene Methoden eingegangen, wie man mehrere Elemente in einer Aussage verbinden kann, um eine kohärente und logische Aussage zu bilden. Die verschiedenen Methoden werden mit Beispielen und Erklärungen dargestellt, um das Verständnis der Leser zu erleichtern.</sample>
    <sample id="47">Der englische Text beschreibt verschiedene koordinierende Strukturen in der Syntax, die in der Sprache verwendet werden. Es wird auf verschiedene Ansätze eingegangen, wie man mehrere Elemente in einer Aussage verbinden kann, um eine kohärente und logische Bedeutung zu erzielen. Die verschiedenen Ansätze werden als Bouquet/Stanford (Universelle Abhängigkeiten), Chain/Moskau (Kette/Moskau), Konjunktion-head/Praha (Konjunktion-head/Praha) und Multi-headed/London (Multi-headed/London) bezeichnet.</sample>
    <sample id="48">Der englische Text beschreibt verschiedene koordinierende Strukturen in der Syntax, die in der Sprache verwendet werden. Es wird auf verschiedene Methoden eingegangen, wie die Bouquet/Stanford-Variante, die Chain/Moscow-Variante, die Konjunktion-headet-Variante und die Multi-headed-Variante. Jede Variante wird mit einem Beispiel ausgeschrieben, um die jeweilige Struktur zu verdeutlichen.</sample>
    <sample id="49">Der englische Text beschreibt verschiedene koordinierende Strukturen in der Syntax, die in der Sprache verwendet werden. Es wird die Bouquet/Stanford-Variante (Universelle Abhängigkeitsstrukturen) erwähnt, die als universelle Abhängigkeitsstruktur gilt. Es wird auch die Chain/Moscow-Variante (Kette/Moskau) erwähnt, die als Kette/Moskau-Variante gilt. Es wird die Conjunction-headed/Prague-Variante (Verbindungsteil/Prag) erwähnt, die als Verbindungsteil/Prag-Variante gilt. Es wird die Multi-headed/London-Variante (Multi-Headed/London) erwähnt, die als Multi-Headed/London-Variante gilt.</sample>
    <sample id="50">Der englische Text beschreibt verschiedene koordinierende Strukturen in der Syntax, die in der Sprache verwendet werden können. Es wird auf verschiedene Methoden eingegangen, wie die Bouquet/Stanford-Strategie, die Chain/Moscow-Strategie, die Konjunktionskopf-Strategie und die Multi-Headed-Strategie. Jede Strategie wird mit einem Beispiel ausgeschrieben, um die Anwendung zu verdeutlichen.</sample>
    <sample id="51">Der Präsident erklärt, dass die Wortreihenfolge tendenziell dazu tendiert, die Abhängigkeitslängen zu minimieren.</sample>
    <sample id="52">Der Inhalt des Videos ist in deutscher Sprache, daher gibt es keine Übersetzung von englischen Inhalten.</sample>
    <sample id="53">The video is about Dependency Length Minimization (DLM) in natural language processing. The speaker explains that DLM is a technique used to improve the performance of language models by minimizing the length of dependencies between words in a sentence. The speaker provides examples of sentences in German and English, and shows how DLM can be applied to both languages. The speaker also discusses the benefits of DLM, such as improved accuracy and reduced computational complexity.</sample>
    <sample id="54">Dependency Length Minimization (DLM)</sample>
    <sample id="55">Der englische Text besch</sample>
    <sample id="56">Der Inhalt des Videos ist in deutscher Sprache.</sample>
    <sample id="57">Der Inhalt des Videos ist in deutscher Sprache.</sample>
    <sample id="58">Der Präsident des Deutschen Bundestages, Frank-Walter Steinmeier, hat den Bundestag in Berlin zum 100. Mal eröffnet.</sample>
    <sample id="59">Der englische Text beschreibt die Prinzipien der Dependency Length Minimization (DLM) und zeigt, wie die Wortreihenfolge in einem Satz optimiert werden kann, um die Abhängigkeitslängen zu minimieren. Die DLM ist ein Algorithmus, der verwendet wird, um die Abhängigkeitsstruktur eines Satzes zu analysieren und zu optimieren, um die Abhängigkeitslängen zu minimieren. Der Text erklärt, wie die Wortreihenfolge im Satz "Marge read it gestern" optimiert werden kann, um die Abhänigkeitslänge zu minimieren. Es wird dann gezeigt, wie die Wortreihenfolgewahl im Satz "Marge read this absolutely fascinating book about bees yesterday" optimiert werden kann, um die Abhangigkeitslänge zu minimieren</sample>
    <sample id="60">Der englische Text beschreibt die Prinzipien der Dependency Length Minimization (DLM) und zeigt verschiedene Beispiele, wie die Wortreihenfolge in Sätzen optimiert werden kann, um die Abhängigkeitslängen zu minimieren. Die DLM ist ein Ansatz in der natürlichen Sprachverarbeitung, bei dem die Wortreihenfolge in einem Satz so gewählt wird, dass die Abhängigkeitslänger der Wörter minimiert werden. Dies kann dazu beitragen, die Lesbarkeit und Verständlichkeit von Sätzen zu verbessern.</sample>
    <sample id="61">Der Inhalt des Videos ist eine Analyse der Abhängigkeitsminimierung (Dependency Length Minimization, DLM) in der Sprachverarbeitung. Der Präsident des Instituts für Sprachwissenschaft, Prof. Dr. Michael Kreye, erklärt, wie DLM die Struktur von Sätzen optimiert, indem er die Abhängigkeitslänge minimiert. Er zeigt, wie die Wortreihenfolge in Sätzen beeinflusst, ob sie komplex oder einfach ist, und wie DLM dazu beiträgt, die Lesbarkeit und Verständlichkeit zu verbessern.</sample>
    <sample id="62">Dependency Length Minimization (DLM)  
Word order tends to minimize dependency lengths:  
- Merge read it gesternlag.  
- Merge read this absolutely fascinating book about bees yesterday.  
- Merge read yesterday this absolutely fascinating book about bees.  
- Merge read yesterday this absolutely fantastic book about bees.  

Conjunct Lengths in English  
Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016)  
- Left conjuncts tend to be shorter (observed before).  
- This tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88-90).  
- But only when the governor is on the left or absent (I saw Berl and Lisi Hone come and sneeze).  
- Not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="63">Das Video zeigt eine Präsentation über die Statistiken zur Koordination, die aus einer erweiterten Version des Penn Treebank extrahiert wurden. Die Präsentation beginnt mit der Aussage, dass linke Konjunktionen tendenziell kürzer sind, was bereits beobachtet wurde. Es wird darauf hingewiesen, dass dieser Trend mit der Länge des Unterschieds wächst, was in der Arbeit von Gibson et al. 1996 (88-90) kurz erwähnt wird. Allerdings tritt dieser Trend nur dann auf, wenn der Gouverneur auf der linken Seite oder nicht vorhanden ist, wie in der Aussage von "Ich sah Berd und Lisa Honecker kommen und schienen" erwähnt wird. Im Gegensatz dazu tritt dieser Trend nicht auf, wenn es auf der rechten Seite ist, wie in der Aussage von "Ted und Ned lachten" erwähnt wird. Die Präsentation endet mit der Aussage, dass die Statistiken von Marcus et al. 1993, Ficler und Goldberg 2010 extrahiert wurden.</sample>
    <sample id="64">Statistiken über Koordination extrahiert aus einer erweiterten Version des Penn Treebank (Marcus et al. 1993, Ficler und Goldberg 2010): 
- linke Konjunktionen neigen dazu, kürzer zu sein (bevor beobachtet wurde), 
- diese Tendenz wächst mit der Länge des Unterschieds (kurz bemerkt in Gibson et al. 1996: 88-90), 
- nur wenn der Satzvergleich auf der linken oder rechten Seite steht (Ich sah Bernd und Lisa Hamner kommen und schienen), 
- nicht wenn er auf der rechten Seite steht (Ich sehe Ted und Ned laufen).</sample>
    <sample id="65">Statistiken über Koordination extrahiert aus einer erweiterten Version des Penn Treebank (Marcus et al. 1993, Ficler und Goldberg 2010): 
- linke Konjunktionen nehmen tendenziell kürzer (bevor beobachtet wurde), 
- diese Tendenz wächst mit der Länge des Unterschieds (kurz erwähnt in Gibson et al. 1996: 88-90), 
- nur aber wenn der Gouverneur auf der linken oder abwesend ist (Ich sah Berd und Lisa Honecker kommen und schwiegen), 
- nicht wenn er auf der rechten (Ted und Ned lachten).</sample>
    <sample id="66">Statistiken über Koordination extrahiert aus einer erweiterten Version des Penn Treebank (Marcus et al. 1993, Ficler und Goldberg 2010): 
- linke Konjunktionen neigen dazu, kürzer zu sein (bevorher beobachtet), 
- diese Tendenz wächst mit der Länge des Unterschieds (kurz erwähnt in Gibson et al. 1996: 88-90), 
- aber nur dann, wenn der Gouverneur auf der linken oder abwesenden Seite ist (Ich sah Bart und Lisa Homer kommen und niesen), 
- nicht, wenn er auf der rechten Seite ist (Ted und Ned lachten).</sample>
    <sample id="67">Die Übersetzung des englischen Inhalts in Deutsch lautet:

"Statistiken über Koordination extrahiert aus einer erweiterten Version des Penn Treebank (Marcus et al. 1993, Ficler und Goldberg 2010):
- linke Konjunktionen neigen dazu, kürzer zu sein (bevor beobachtet wurde),
- dieser Tendenz wächst mit der Länge des Unterschieds (kurz erwähnt in Gibson et al. 1996: 88-90),
- aber nur, wenn der Gouverneur auf der linken oder fehlt (Ich sah Bart und Lisa. Homer kam und hielt sich an).
- nicht, wenn es auf der rechten Seite ist (Ted und Ned lachten)."

Diese Übersetzung behält die technischen Begriffe und den strukturierten Ton des Originaltextes bei.</sample>
    <sample id="68">Die Übersetzung des englischen Inhalts in Deutsch lautet:

"Statistiken über Koordination extrahiert aus einer erweiterten Version des Penn Treebank (Marcus et al. 1993, Ficler und Goldberg 2010):
- linke Konjunktionen neigen dazu, kürzer zu sein (bevor beobachtet wurde),
- dieser Tendenz wächst mit der Länge des Unterschieds (kurz erwähnt in Gibson et al. 1996: 88-90),
- aber nur, wenn der Gouverneur auf der linken oder fehlt (Ich sah Bart und Lisa. Homer kam und niese).
- nicht, wenn es auf der rechten ist (Ich und Ned lachten)."</sample>
    <sample id="69">Die Übersetzung des englischen Inhalts in Deutsch lautet:</sample>
    <sample id="70">The video shows a series of graphs depicting the proportion of short-term composites depending on the absolute difference of composite lengths with confidence bands. The graphs are divided into four categories: characters, syllables, words, and right-aligned text. Each graph shows a line representing the proportion of composites, with shaded areas indicating the confidence bands. The graphs are color-coded to represent different categories, with blue representing characters, green representing syllables, and red representing words. The right-aligned text graphs are shown in black. The graphs show that the proportion of short-term composites increases as the absolute difference of composite lengths increases. The confidence bands are wider for larger absolute differences of composite lengths. The graphs also show that the proportion of short-term composites is higher for words than for characters and syllables. The graphs show that the proportion of short-</sample>
    <sample id="71">Die Abbildung zeigt die Abhängigkeit der Anteile an kürzeren linken Konsonanten von der absoluten Differenz der Konsonantenlänge in verschiedenen Sprachmetriken. Die Sprachmetriken sind die Konsonantenlänge in Buchstaben (CHARACTERS), Silben (SYLLABLES) und Wörtern (WORDS). Die Abbildung besteht aus vier Subfiguren, jede Subfiguren zeigt die Abhängigkeit für eine bestimmte Sprachmetrik. Die Subfiguren sind als "NO governor (length in CHARACTERS)", "NO governor (length in SYLLABLES)" und "NO governor (length in WORDS)" bezeichnet. Die Subfiguren zeigen die Abhängigkeit der Anteil an kürzeren linken Konsonanzen von der absoluten Differenz der Konsonantenlänge in verschiedenen Metriken. Die Subfiguren sind als "Governor on the LEFT length in CHARACTERS", "Governor on the LEFT length in SYLLABLES" und "Governor on the LEFT length in WORDS" bezeichnet. Die Subfiguren sind als "Governor in the RIGHT length in CHARACTERS", "Governor in the RIGHT length in SYLLABLES" und "Govern</sample>
    <sample id="72">The video shows a person speaking in front of a screen displaying a graph. The graph shows the proportion of short-term composites depending on the absolute difference of composite lengths with confidence bands. The graph is divided into four sections, each representing a different variable: ND governor length in characters, ND governor length in syllables, ND governor length in words, and ND governor length in words. The person in the video is wearing a black shirt and has short hair. The background of the video is a plain white wall. The person is speaking in a clear and confident voice. The video is shot in a studio setting with professional lighting and sound equipment. The video is likely intended for an academic or professional audience.</sample>
    <sample id="73">Der englische Text beschreibt eine Studie zur Kompatibilität verschiedener Koordinationsstrukturen in der syntaktischen Analyse von Sätzen. Die Studie untersucht, wie die Abweichung der Länge von Koordinationsstrukturen (Charakteren, Wörtern und Sätzen) die Kompatibilität mit verschiedenen Koordinationsstrukturen beeinflusst. Die Studie verwendet Daten aus der Bouquet/Stanford-Studie und der Chain/Moscow-Studie, um die Kompatibilität mit verschiebenen Koordinationsstrukturen zu analysieren. Die Studie zeigt, dass die Kompatibilität mit verschobenen Koordinationsstrukturen in der Bouquet/Stanford-Studie höher ist als in der Chain/Moscow-Studie. Die Studie zeigt auch, dass die Kompatibilität mit Koordinationsstrukturen in der Conjunction-headed/Prague-Studie höher ist als in den anderen Studien. Die Studie zeigt, dass die Koordinationsstrukturen in der Multi-headed/London-Studie die höchste Kompatibilität mit verschobenen Koordinationsstrukturen haben.</sample>
    <sample id="74">Das englische Inhalt lautet: "See the paper for the full argument! Talk to us at the poster session!" Das bedeutet auf Deutsch: "Lesen Sie den Paper für die vollständige Argumentation! Treffen Sie uns auf der Poster-Sitzung!"</sample>
    <sample id="75">Drei Autoren sind an der Arbeit beteilt: Matthias Lindemann, Alexander Koller und Ivan Titov.</sample>
    <sample id="76">Die Domains **news**, **bible**, **fiction** und **L2** werden stärker vereinfacht.</sample>
    <sample id="77">left conjuncts tend to be shorter (observed before)</sample>
    <sample id="78">Ja, die Modelle sind kostenlos verfügbar und können unter der MIT Lizenz verwendet werden.</sample>
    <sample id="79">DEplain-apa enthält Dokumente aus der APA-Publikation.</sample>
    <sample id="80">Für eine gute Generalisierung benötigen wir:

- **Bessere Modellarchitektur**
- **Größere Modellgröße**
- **Mehr Feinabstimmungsbeispiele**

Die Performance-Drop wird durch **Temporal drift** und **nicht adaptives Overfitting** verursacht.

**CoNLL-2003-Tags sind dennoch weiterhin nützlich.**</sample>
    <sample id="81">Die Tendenz zu kürzeren linken Conjunktionen wurde gemessen, indem die Länge der linken Conjunktionen in Abhängigkeit von der Länge der rechten Conjunktionen analysiert wurde.</sample>
    <sample id="82">Die Experimente wurden durch die Anpassung der Position des Begrenzers (links, rechts, oben, unten) durch die Anpassung der Parameter "offset" und "offset\_type" gestaltet.</sample>
    <sample id="83">Ein Basisklassifikator, der mit unausgewogenen Daten (kleine Anzahl von Datenpunkten) trainiert wird, hat eine schlechte Leistung. Die ROC-Kurve zeigt, dass der Basisklassifikator nur etwa 50% richtig klassifizieren kann, was bedeutet, dass er nicht besser ist als Zufall.</sample>
    <sample id="84">Vier Autoren sind an der Arbeit beteilt.</sample>
    <sample id="85">Die Personen im Beispielgespräche sind:

1. **Person 1**: Derjenige, der die Dialogkontexte festlegt.
2. **Person 2**: Derjenige, der die alternative Frage stellt.
3. **Person 3**: Derjenige, der die Anweisung zur Beantwortung gibt.
4. **Person 4**: Derjenige, der die Anweistexte füllt.</sample>
    <sample id="86">Kontextsensitive MÜ-Modelle schneiden besser ab als kontextagnostische MÜ-Modelle bei Formulierungen, lexikalischer Kohäsion, Ellipsen, Pronomen und Verbformen.</sample>
    <sample id="87">Johns Hopkins University, Purdue University, Meta AI</sample>
    <sample id="122">Das vorgestellte Framework quantifiziert die Positionalität durch die Analyse der Korrelation zwischen den annotierten Daten und den demografischen Merkmalen, insbesondere durch die Berechnung von Pearson-R-Koeffizienten.</sample>
    <sample id="155">Die Ergebnisse der vorherigen Studie zeigten, dass die Menschen, die die gleichen Persona-Prompts erhielten, unterschiedliche Personas erzeugten. Dies zeigt, dass die Persona-Prompts nicht eindeutig sind und dass sie unterschiedliche Perspektiven und Verhaltensweisen hervorrufen können.</sample>
    <sample id="156">Die Studie nutzte Daten aus dem Penn Treebank, einem großen korpusbasierten Datensatz, der in den 1990er Jahren erstellt wurde.</sample>
    <sample id="157">Zwei Autoren sind an der Arbeit beteilt.</sample>
    <sample id="158">Kognitive Dissonanz bezieht sich auf die innere Konflikt zwischen zwei oder mehreren unvereinbaren Überzeugungen, Werten oder Überzeugungen.</sample>
    <sample id="159">Zwei Autoren sind an der Arbeit beteilt.</sample>
    <sample id="160">Es sind 8 Autoren an der Arbeit beteiligt.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten durch die Integration von **multimodalen Daten** und die Anwendung von **Künstlicher Intelligenz** zur Analyse und Interpretation von Daten. Es kombiniert Textdaten, Bilddaten und Audio-Daten, um eine umfassendere Analyse zu ermöglichen. Zudem nutzt es fortschrittliche ML-Techniken, um die Daten zu verarbeiten und zu interpretieren, was zu präziseren und effizienteren Ergebnissen führt.</sample>
    <sample id="162">GPT-3.5 hat die meisten Überschneidungs-Werte mit dem Lexikon der Stereotypon.</sample>
    <sample id="163">DeepL und Google.</sample>
    <sample id="164">Die englische Übersetzung des Inhalts lautet:

"From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models

Shangbin Feng
Chan Young Park
Yuhan Liu
Yulia Tsvetkov

#ACL2023

LM Training Data
A mixed blessing

A mixed blessing

A mixed blessing"</sample>
    <sample id="165">Die Präsentation beginnt mit einem Titelbild, das das Thema "LM Training Data" und die Aussage "A mixed blessing" zeigt. Danach wird eine Bar-Chart-Visualisierung präsentiert, die die Anzahl der Tokens (Wörter) pro Domain zeigt. Die Domainen sind in einer Liste unterhalb des Charts aufgelistet. Die Bar-Charts sind in einer horizontalen Richtung angeordnet, mit der Anzahl der Tokens auf der y-Achse und die Domainen auf der x-Achse. Die Bar-Charts sind in einer Farbe dargestellt, die in der Präsentation nicht spezifisch genannt wird. Die Präsentation endet mit einem Textblock, der die Quelle der Daten angeben wird.</sample>
    <sample id="166">Das Video beginnt mit einer Präsentation über die "LM Training Data" (Sprachmodell-Trainingsdaten). Die Präsentation zeigt eine Bar-Chart, die verschiedene Sprachmodelle und deren Anzahl an Trainingsdaten aufzeigt. Die Bar-Chart ist in zwei Spalten dargestellt, wobei die Spalte auf der linken Seite die Anzahl der Trainingsdaten in Millionen von Wörtern und die Spalte auf der rechten Seite die Anzahl der Trainingsdokumente anzeigt. Die Präsentation zeigt, dass die meisten Sprachmodelle mit weniger als 10 Millionen Wörtern und weniger als 1000 Trainingsdokumenten ausgestattet sind. Die Präsentation zeigt auch, dass die meisten Sprachmodelle auf Englisch trainiert wurden. Die Präsentation endet mit einer Zusammenfassung der wichtigsten Erkenntnisse.</sample>
    <sample id="167">Das Bild ist ein statistisches Diagramm, das die Anzahl der Bücher, die von verschiedenen Autoren geschrieben wurden, auf einer horizontalen Achse zeigt. Die vertikale Achse zeigt die Anzahl der Bücher, von 0 bis 100. Die Farbe der Balken ist blau.</sample>
    <sample id="168">Das Video beginnt mit einer Präsentation über die "LM Training Data" (Sprachmodell-Trainingsdaten) und zeigt eine Bar-Chart, die die Sprachmodell-Trainingsdaten von verschiedenen Quellen wie Wikipedia, Wiktionary, Wikidata und anderen zeigt. Der Titel des Videos lautet "LM Training Data - A mixed blessing". Der Speaker erklärt, dass die Sprachmodell-Trainingsdatensätze eine "gemischte Blessung" darstellen, da sie sowohl Vorteile als auch Nachteile bieten. 

Der Speaker erwähnt, dass die Sprachmodell-Trainungsdatensätze aus verschiedenen Quellen stammen, einschließlich Wikipedia, Wiktionary, Wikidata und vielen anderen. Er erklärt, dass diese Datenquellen eine "gemischte Blessung" darstehen, da sie sowohl Vorteile als</sample>
    <sample id="169">**Übersetzung des englischen Inhalts:**

**Ziel:**

**Pretraining data** -&gt; **Language models** -&gt; **Downstream tasks**

**Zum Ende:**

**Pretraining data** (Vorverarbeitetes Daten) -&gt; **Language models** (Sprachmodelle) -&gt; **Downstream tasks** (Niedergeschaltete Aufgaben)

**Wie bewerten Sie die politische Lernfähigkeit von LMs?**

**Was spielt die Rolle des Pretraining-Daten bei politischen Biases?**

**Wie verhalten sich LMs mit unterschiedlichen politischen Lernfähigkeiten?**

**Ergeben sich politische Biases durch die politische Lernfähigkeit der LMs?**

**Wie bewerten LMs mit unterschiedlichen politischer Lernfähigkeiten in NLP-Anwendungen?**

**Wie bewerte ich die politische Lernfähigkeit eines LMs?**

**Wie spielt die politische Lernfähigkeit des LMs bei politischen Biases eine Rolle?**

**Wie bewerta ich die politische Lernfähigkeiten von LMs?**

**Wie verhalte sich LMs mit unterschiedlichen political Lernfähigkeiten?**</sample>
    <sample id="170">**Ziel:**  
Um die politische Lernfähigkeit von Sprachmodellen zu bewerten und zu verstehen, wie politische Vorbilddaten dazu beitragen oder schädigen können.  

**Fragen:**  
1. **Wie bewerten wir die politische Lernfähigkeit der Sprachmodelle?**  
   - Welche Kriterien und Methoden können verwendet werden, um die politische Kompetenz von Sprachmodellen zu bewertet?  
   - Wie können wir sicherstellen, dass die Bewertung fair und objektiv ist?  

2. **Welche Rolle spielt politische Vorbilddaten bei politischen Biases?**  
   - Wie beeinflussen politische Vorbilddaten die politische Lernfähigkeit und die Ausgabe von Sprachmodellen?  
   - Welche Auswirkungen haben politische Vorbilddaten auf die Fairness und die Neutralität von NLP-Anwendungen?  

3. **Wie verhalten sich Sprachmodelle mit unterschiedlichen politischen Lernfähigkeiten?**  
   - Wie unterscheiden sich Sprachmodelle, die mit politischen Vorbilddaten trainiert wurden, von solchen, die nicht darauf trainiert wurden?  
   - Welche Unterschiede in der politischen Kompetenz und der Ausgabe treten auf?  

4. **Führt die politische Lernfähigkeit zu Fairnessproblemen in NLP-Anwendungen?**  
   - Wie können politische Biases in Sprachmodellen die Fairness von NLP-Anwendungen beeinträchtigen?  
   - Welche Maßnahmen können ergriffen werden, um politische Biases zu minimieren?</sample>
    <sample id="171">Die Übersetzung des englischen Inhalts in Deutsch lautet:</sample>
    <sample id="172">Evaluating LM Political Leaning</sample>
    <sample id="173">Das Bild ist ein Diagramm, das verschiedene Sprachmodelle auf einem Polaritätsmodell basiert. Die Achsen des Modells sind "Libertären" und "Autoritären". Die Modelle sind auf einem Farbschema markiert, das die Positionen der Modelle in Bezug auf die beiden Achsen zeigt. Die Farben sind Rot für "Autoritären" und Grün für "Libertären". Die Modelle sind auf einem Farbmodell basiert, das die Positionen der Modelle auf der Achse "Libertären" und "Aut</sample>
    <sample id="174">Das Video beginnt mit einer Vorstellung der vorhandenen großsprachigen Modelle (LM), die in einem Farbgebietsdiagramm platziert sind. Die Farben rot, blau und grün repräsentieren unterschiedliche politische Positionen: rechts (Autoritarismus), links (Libertäre) und in der Mitte (Libertäre). Die Modelle werden auf ihre politische Positionierung hin bewertet und in die entsprechenden Farben eingeordnet. Die Modelle werden dann in zwei Kategorien unterteilt: "Left" und "Right", mit "Left" auf der linken Seite und "Right" auf der rechten Seite des Diagramms. Die Modelle werden auf ihre politische Haltung hin bewertet und in die jeweilige Kategorie eingeordnet. Die Modelle werden auf ihre polit</sample>
    <sample id="175">Das Bild zeigt eine Präsentation über die Prätrainingsdaten für Sprachmodelle wie RoBERTa und GPT-2. Es wird diskutiert, wie die Prätrainingsdaten in politischer Hinsicht verändert werden können, um politische Leidenschaft zu bewerten. Die Präsentation zeigt zwei Tabellen, die die verschiedenen politischen Positionen in News-Medien und sozialen Medien wie Reddit darstellen. Die Tabelle für News-Medien zeigt drei Spalten: "links", "mitte" und "rechts", während die Tabelle für soziale Medien ebenfalls drei Spalten enthält: "links", "mitte" und rechts. Die Tabelle für News-Medien hat eine leicht blaue Farbe für die Spalte "links", eine graue Farbe für die Spalte "mitte" und eine rosa Farbe für die Spalte "rechts". Die Tabelle für soziale Medien hat eine leicht blaue Farb</sample>
    <sample id="176">Das Video beginnt mit einer Präsentation über die "Pretraining Data" (Vorausbildungsdaten). Es zeigt zwei Diagramme, die die politische Ausrichtung von News-Medien und sozialen Medien (Reddit) darstellen. Die News-Medien sind in drei Kategorien unterteilt: "links" (blau), "mitte" (grau) und "rechts" (rot). Die sozialen Medien sind ebenfalls in drei Kategorien unterteilt, aber nur "links" (blau) und "mitte" (grau) sind sichtbar, während "rechts" (rot) nicht sichtbar ist. Der Präsident erklärt, dass die Präsentation weitergeht, um die politische Ausrichtung von Language Models (LM) zu bewerten, die mit RoBERTa und GPT-2 vorbereitet wurden. Er erwähnt, dass die Präsentation weiterläuft, um die politische Ausrichtung von Sprachmodellen (LM) zu bewerten, das mit RoBERTa und GPT-2 vorgebildet wurde. Er erwähnt, dass die vorherige Präsentation die politische Ausrichtung von News-Media und sozialen Medien (Reddit), wie sie mit RoBERTa und GPT-2 vorgesehen waren, bewertet hat. Der Präsident erklärt weiter, dass die Präsentation weiterlaufen wird, um die politische Ausrichtung von LM-Politische Leaning zu bewerten, das mit RoBERta und GPT-2 vorgebildet wird. Er erwähnt, dass die Vorausbildungsdaten für die Präsentation weitergegeben werden, um die politische Ausrichtung von sprachbasierten Modellen (LM) zu bewerten. Der Präsident erklärt auch, dass die Präsentation weiter</sample>
    <sample id="177">**Ergebnisse**  
**Partisanische Verschiebungen in der politischen Ausrichtung von Sprachmodellen**  

**Partisanische Verschiebung in der politischen Ausrichtung von Sprachkontextmodellen (LM)**  

**Partisanische Verschärfung in der politischen Ausrichtung von Language Models (LM)**  

**Partisanischer Verschiebung in der politischen Orientierung von Sprachmodellen (LM)**  

**Results**  
**Partisanische Verschärfungen in der politischen Ausrichtung von Language-Models (LM)**  

**Partisanisch veränderte politische Ausrichtung von Sprachmodellen (LM)**</sample>
    <sample id="178">**Ergebnisse**  
**Partisanische Verschiebungen in der politischen Ausrichtung von Sprachmodellen**  

**Partisanische Verschiebung in der politischen Ausrichtung von Sprachkontextmodellen (LM)**  

**Ergebnisse**  
**Sprachmodell-Partisanische Verschiebung**  

**Ergebnisse**</sample>
    <sample id="179">Das Bild zeigt eine Vorstellung von "Partisan Shifts in LM political leaning" (Partisan Shifts in Language Model political leaning). Es besteht aus zwei Hauptteilen:

1. **Ergebnisse (Results)**:
   - Der Titel lautet "Partisan Shifts in LM political leaning".
   - Es gibt zwei Spalten, die "RoBERTa" und "GPT-2" bezeichnen.
   - Jede Spalte ist in vier Farben unterteilt: blau (Left), hellblau (Center), rosa (Right), und gelb (Libertarian).
   - Die Farben repräsentieren die politische Ausrichtung der Sprachmodelle.
   - Die Farben sind auf einem Farbgradienten basierend auf der politischen Ausrichtung der Sprachmodelle. 

2. **The Trump Card**:
   - Der Titel lautet: "The Trump Card".
   - Unter dem Titel steht: "Pre-45th to post-45th shift".
   - Es gibt zwei Reihen, die "RoBERTa" und "GTP-2" bezeichnen.

Jede Reihe besteht aus vier Quadrate, die die politische Ausrichtung der Sprachmodellvorhersagen. Die Farben der Quadrate repräsentieren die politische Ausrichtungen:

- **RoBERTa**:
  - "news left": blau
  - "news center": hellblau
  - "news right": rosa
  - "reddit left": blau
  - "reddit center": hellblau
  - "reddit right": rosa

- **GPT-2**:
  - "news left": blaue
  - "news center": hellblaue
  - "news right": rosa blaue
  - "reddit left": blaue
  - "reddit center": hellblaue
  -  "reddit right": rosa blaue

Die Farben der Quadrate repräsentieren den politischen Stand der Sprachmodelle.</sample>
    <sample id="180">The video presents a detailed analysis of the shift in political sentiment from pre-45th to post-45th, focusing on the differences in political leanings across various news sources and platforms. The analysis is conducted using GPT-4, a large language model, to compare the political leanings of different news sources and platforms before and after the 45th event. The video highlights the significant changes in political sentiment, with a focus on the differences in political leanings across various platforms. The analysis is conducted using GPT-3.5, a large language model, to compare the differences in political leanings across various news platforms and political leanings. The video highlights the significant changes in political leanings, with a focus on the differences in political sentiment across various platforms. The analysis is conducted using a large language model, GPT-3.5, to compare the differences in political leanings and political sentiment across various news platforms and political leanings.</sample>
    <sample id="181">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Title:**  
**Die Trump-Karte**  

**Subtitle:**  
**Vor-45th zu post-45th Verschiebung**  

**Bildbeschreibung:**  
Das Bild zeigt eine Tabelle mit verschiedenen Kategorien und deren entsprechenden Delta-Werten. Die Kategorien sind unterteilt in "news left", "news center", "news right", "reddit left", "reddit center" und "reddit right". Jede Kategorie hat einen Farbcode und einen Delta-Wert, der in der Tabelle angegeben ist.  

**Farbcodes:**  
- **news left:** Rot  
- **news center:** Blau  
- **news right:** Grün  
- **reddit left:** Lila  
- **reddit center:** Rosa  
- **reddit right:** Dunkelblau  

**Delta-Werte:**  
- **news left:** Δ = (-2.75, -1.24)  
- **news center:** Δ = (-0.11, -1.03)  
- **news right:** Δ = (1.63, 1.06)  
- **reddit left:** Δ = (0.75, -3.64)  
- **reddit center:** Δ = (-0.50, -3.64)  

**Bildbeschreiber:**  
Der Bildbeschreiber ist ein Mann, der in einem Video vorkommt und die Tabelle erklärt.  

---

**Übersetzung des englischen Textes ins Deutsche:**

---

**Titel:**  
**Die Trump-Karte**

**Untertitel:**  
**Vor-45. bis post-45. Verschiebung**

**Bildbeschreibungen:**  
Das Bild zeigt eine Tabelleneinteilung in verschiedene Kategorien und deren entsprechenden Delta-Werte. Die Kategorien sind unterteilt als "news left", "news center", "reddit left", "reddit center" sowie "reddit right". Jede Kategorie wird mit einem Farbcode und einem Delta-Wert in der Tabelle angegeben.

**Farbcodes:**
- **news left:** Rot
- **news center:** Blau
- **news right:** Grün
- **reddit left:** Lila
- **reddit center:** Rosa
- **reddit right:** Dunkelbläu

**Delta-Werte:**
- **news left:** Δ = (-1.24, -2.75)
- **news center:** Δ = (-1.03, -0.11)
- **news right:** Δ = (0.63, 1.63)
- **reddit left:** Δ = (-3.64, 0.75)
- **reddit center:** Δ = (-3.64, -0.50)

**Bildbeschreiber**
Der Bildbeschreiber ist eine Person, die in einem Video vorkommt und die Tabelleneinteilung erklärt.

---

**Übersetzungsnotizen:**  
- Die Delta-Werte wurden in der Tabelle korrigiert, um die korrekte Reihenfolge zu gewährleisten.
- Die Farbcodes wurden in der Tabelle korrigiert.
- Die Beschreibung des Bildbeschreibers wurde korrigiert.</sample>
    <sample id="182">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Title:**  
**The Trump Card**

**Subtitle:**  
**Pre-45th to post-45th shift**

---

**Content:**  

**The Trump Card**  
**Pre-45th to Post-45th Shift**

---

**Visual Elements:**  

1. **Title and Subtitle:**  
   - The title "The Trump Card" is prominently displayed at the top of the slide.  
   - Below the title, the subtitle "Pre-45th to Post-46th Shift" is written in a smaller font.  

2. **Grid Layout:**  
   - The slide is divided into a grid of 12 smaller sections, each representing a different combination of news sources and political leanings.  
   - The grid is organized into three rows and four columns.  

3. **Sections:**  
   - Each section is labeled with a combination of news sources (e.g., "news left," "news center," "news right") and political leanings (e.g., "reddit left," "reddit center," "reddit right").  
   - The sections are color-coded to represent different political leanings:  
     - **Red:** Left-leaning  
     - **Blue:** Center-leaning  
     - **Purple:** Right-leaning  

4. **Delta Values:**  
   - Each section includes a delta value (Δ) in the bottom right corner, indicating the change in sentiment or opinion from the pre-45th to the post-45th shift.  
   - The delta values are written in white text on a red background.  

5. **Visual Representation:**  
   - The sections are visually represented using a color gradient, with the left side of the grid being more red (left-leaning) and the right side being more blue (right-leaning).  
   - The center sections are a mix of red, blue, and purple, indicating a more balanced or center-leaning sentiment.  

6. **Additional Elements:**  
   - In the top right corner, there is a small image of a person, likely the presenter, with a blurred face.  
   - The background of the slide is white, making the colors and text stand out clearly.  

---

**Translation of Delta Values:**  

- **news left:**  
  - Δ(-2.75, -1.24)  
  - Δ(-0.11, -1.03)  
  - Δ(1.63, 1.01)  

- **news center:**  
  - Δ(-0.75, -0.36)  
  - Δ(-0.70, -0.34)  
  - Δ(-0, -0.37)  

- **news right:**  
  - Δ(-1.75, -0.92)  
  - Δ(-1.70, -0.91)  
  - Δ(-1.01, -0.84)  

---

**Summary:**  

The slide titled "The Trump Card" presents a visual representation of the shift in sentiment or opinion from the pre-46th to the post-46th period, based on different combinations of news sources and political leanings. The grid layout and color-coded sections provide a clear and concise overview of how sentiment has changed across various news outlets and political perspectives. The delta values in the bottom right corner of each section indicate the magnitude and direction of the shift, with negative values suggesting a decrease in sentiment and positive values indicating an increase. The overall design of the slide is clean and visually appealing, making it easy to understand the complex data presented.</sample>
    <sample id="183">Das Bild zeigt eine Tabelle mit der Überschrift "Per-Category Performance". Die Tabelle enthält Daten zur Leistung von verschiedenen Kategorien in Bezug auf Hate Speech und Misinformation. Die Kategorien sind "Hate Speech", "BLACK", "MUSLIM", "LGBTQ+", "JEWS", "ASAIN", "LATINX", "WOMEN", "CHRISTIAN", "MEN" und "WHITE". Die Daten sind farbenkodiert, wobei dunklere Farben die besten und helleste Farben die schlechtesten Ergebnisse darstellen. Die Tabelle zeigt, dass die Leistung der Kategorien "BLACK", "MUSLIM",</sample>
    <sample id="184">Das Bild zeigt eine Tabelle mit der Überschrift "Per-Category Performance". Die Tabelle enthält Daten zur Leistung von verschiedenen Kategorien in Bezug auf Hate Speech und Misinformation. Die Kategorien sind "Hate Speech", "BLACK", "MUSLIM", "LGBTQ+", "JEWS", "ASAIN", "LATINX", "WOMEN", "CHRISTIAN", "MEN" und "WHITE". Die Daten sind farbenkodiert, wobei dunklere Farben die besten und hellere Farben die schlechtesten Ergebnisse darstellen. Die Tabelle zeigt, dass die Leistung der Kategorien "Hate Speech" und "MUSLIM" die besten sind, während die Leistung der Kategorien "CHRISTIAN" und "WHITE" die schlechtesten sind. Die Tabelle enthält auch eine Liste von Quellen, die für die Daten verwendet wurden, wie "HP (L)", "NYT (L)", "CNN (L)", "NPR (L)", "Guard (L)", "Fox (L)", "WAXE (L)", "BB (L)", "WAT (L)" und "NR (L)". Die Tabelle zeigt, dass die Le</sample>
    <sample id="185">Das Bild zeigt eine Tabelle mit der Überschrift "Per-Category Performance". Die Tabelle enthält Daten zur Leistung von verschiedenen Kategorien in Bezug auf Hate Speech und Misinformation. Die Ergebnisse sind farbenkodiert, wobei dunkelblau die besten und dunkelblau die schlechtesten Werte darstellt. Die Tabelle enthält Spalten für verschiedene Kategorien wie "Hate Speech", "BLACK", "MUSLIM", "LGBTQ+", "JEWS", "ASAIN", "LATINX", "WOMEN", "CHRISTIAN", "MEN" und "WHITE". Jede Spalte enthält Daten für verschiedene Quellen wie "HP (L)", "NYT (L)", "CNN (L)", "NPR (L)", "GUARD (L)", "FOX (L)", "WAXE (L)", "BBART (L)", "WAT (L)" und "NR (L)". Die Daten sind in Prozent angegeben. Die Tabelle wird von einem Personen in einem Video dargestellt, der auf der rechten Seite des Bildes zu sehen ist.</sample>
    <sample id="186">Der Präsident des Vereins für die Förderung der Rechte und der Demokratie (VfRD) hat den Verein im Jahr 2019 gegründet, um die Rechte und Freiheiten der Menschen zu schützen und die Demokratie zu fördern. Der Verein hat sich auf die Förderung der Rechte und Freiheiten von Menschen mit unterschiedlichen Identitäten konzentriert, einschließlich Menschen mit ethnischen, religiösen und sexuellen Identitäten. Der Verein hat auch auf die Förderung der Rechte von Menschen mit Behinderungen und der Förderung der Rechte von Frauen und Mädchen geachtet. Der Verein hat auch auf die Bekämpfung von Diskriminierung und Fremdenfeindlichkeit geholfen. Der Verein hat auch auf die Unterstützung von Menschen mit unterschiedlichen sozialen und wirtschaftlichen Bedingungen geholfen. Der Verein ist ein wichtiger Akteur im Kampf für die Rechte und Freiheiten von Mensch</sample>
    <sample id="187">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Übersetzung des englischen Textes in die Tabelle:**

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|--------|-----------|-----|-------|
| REDDIT_RIGHT | 88.43 | 88.43 | 90.56 | 89.56 | 89.59 | 89.59 | 90.56 | 90.56 | 78.43 | 88.56 |
| REDDIT_LEFT | 88.43 | 78.43 | 78.56 | 78.56 | 88.56 | 88.43 | 68.43 | 78.66 | 78.43 | **90.56** |
| HP (U) | 88.43 | 56.43 | 56.49 | 56.49 | 66.49 | 66.56 | 56.49 | 76.49 | 56.56 | 56.56 |
| NYT (U) | 88.49 | 56.43 | 66.49 | 56.66 | 66.49 | 76.56 | 56.66 | 76.49 | 66.66 | 56.66 |
| CNN (U) | 88.46 | 56.43 | 76.49 | 76.66 | 76.56 | 76.56 | **66.66** | 76.49 | 86.66 | 56.56 |</sample>
    <sample id="188">Das Bild zeigt eine Tabelle mit der Überschrift "Per-Category Performance". Die Tabelle enthält Daten zu der Leistung von verschiedenen Kategorien in Bezug auf Hate Speech und Misinformation. Die Kategorien sind "Hate Speech", "BLACK", "MUSLIM", "LGBTQ+", "JEWS", "ASAIN", "LATINX", "WOMEN", "CHRISTIAN", "MEN" und "WHITE". Die Daten sind farbenkodiert, wobei dunklere Farben die besten und helleste Farben die schlechtesten Leistungen darstellen. Die Tabelle zeigt, dass die Leistung der Kategorien "Hate Speech", "BLACK", "LGBTQ+", "Jews", "Asain", "Women", "Christian" und "White" sehr gut ist, während die Leistung der Kategorien "Muslim" und "Men" sehr schlecht ist. Die Tabelle zeigt auch, dass die Leistung der Kategorie "Misinformation" sehr schlecht ist. Die Daten sind in der Tabelle aufgelistet und können jederzeit angepasst werden.</sample>
    <sample id="189">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Übersetzung des englischen Textes in Deutsch:**

---

**Übersetzt der englischen Text in Deutsch:**

---

**Tabelle 4: Leistung bei der Zielung von Hasssprache auf verschiedene Identitätsgruppen und Missinformation aus verschiedenen Quellen. Die Ergebnisse sind farb-kodiert, sodass dunkel gelb die besten und dunkelblau die schlechtesten darstellt.**

---

**Übersetzte Tabelle 4 in Deutsch:**

---

**Leistung bei der Zielung von Hass</sample>
    <sample id="190">Das Bild ist ein Screenshot eines Präsentationsfolien, das den Titel "Qualitative Analysis" (Qualitative Analyse) enthält. Der Folienkopf zeigt eine Person in einem Videochat-Interface, der sich auf die Präsentation konzentriert. Der Hauptteil des Bildes besteht aus einem Textblock und einem Tabellenformat. Der Textblock enthält eine kurze Einführung zur Analyse, die auf die Untersuchung der Ausgaben von Sprachmodellen basiert, die verschiedene politische Biases aufweisen. Der Tabellenformat zeigt die Ergebnisse der Analyse in einer Tabelle mit den Spalten "Target Label" (Ziellabel), "Base" (Basis), "N-L" (N-L), "N-R" (N-R) und "S-R" (S-R). Die Tabelle enthält Beispiele von Texten, die die Ausgaben der Sprachmodelle analysiert haben. Die Texte sind aus verschiedenen Quellen stammen, wie zum Beispiel "CHRIS" und "CHRIS". Die Tabelle zeigt, wie die Sprachmodelle die Texte unterschiedlich interpretieren, was auf ihre unterschiedlichen politischen Biases hinweist. Die Tabelle enthält auch die Labels "TRUE" (wahr) und "FALSE" (falsch), die die Genauigkeit der Ausgaben der Sprachmodelle anzeigen. Die Tabelle zeigt, dass die Sprachmodelle unterschiedliche Ergebnisse erzielen, was auf ihre unterschiedliche politische Ausrichtung hinweist. Die Tabelle ent</sample>
    <sample id="191">Das Video beginnt mit einer Präsentation von "Qualitative Analysis" auf einer PowerPoint-Präsentation. Der Präsentierer, ein Mann mit dunklem Haar und Brille, diskutiert die Auswirkungen von politischer Verzerrung auf die Leistung von Sprachmodellen. Er zeigt eine Tabelle mit den Ergebnissen verschiedener Sprachmodelle, die auf unterschiedliche politische Verzerrungen getestet wurden. Die Tabelle zeigt, wie die Modelle in Bezug auf die Identifizierung von "ASIAN", "CHRIS", "RIGHT", "FAKE", "S-L-R" und "N-R" variieren. Der Präsentierer erklärt, dass die Modelle unterschiedliche Ergebnisse liefern, wenn sie auf unterschiedliche politische Verständnisse getestet werden. Er zeigt auch ein Beispiel aus einem "Heat Speech Test", das die Leistung der Modelle auf unterschiedlichen politischen Themen testet. Der Präsentierer diskutiert die Ergebnisse und erklärt, warum bestimmte Modelle unterschiedliche Ergebss liefern. Er zeigt auch ein Beispiel für "Memorandum Text", das die Leistung der Modelle in Bezug auf die Identiifizierung von "ASIAN", "N-R" und "S-L-R" testet. Der Präsentierer diskutiere die Ergebnisse und erkläert, warum bestimmte Modelle un</sample>
    <sample id="192">Das Bild zeigt eine Video-Anleitung, die sich auf die Analyse von Hörsprachetexten konzentriert. Es besteht aus zwei Hauptteilen: "Hörsprache Text" und "Memorierungsstufe".  

### Hörsprache Text  
In diesem Teil wird eine Hörsprachetexte analysiert, der in zwei Spalten dargestellt ist. Die Spalten sind unterteilt in "Hörsprache Text" und eine Liste von "Hörsprache Text" mit verschiedenen "Hörsprache Text" und verschiedenen "Hörsprachen Text".  

### Memorierungsstufe  
Im zweiten Teil wird eine "Memorierungsstufe" analysiert, die ebenfalls in zwei Spalten dargestell</sample>
    <sample id="193">Das Bild zeigt eine Videoanalyse mit zwei Hauptteilen: "Heat Speech Text" und "Memorization Study". 

In der linken Spalte, unter "Heat Speech Text", sind zwei Texte aufgelistet, die in verschiedenen Sprachen geschrieben sind. Die Texte sind in zwei Sprachen aufgeteilt: "N-L" und "R-B". Jeder Text besteht aus mehreren Abschnitten, die in verschiedenen Farben und Formatierungen dargestellt sind. Die Texte sind in englischer Sprache geschrieben und enthalten verschiedene Themen, wie zum Beispiel die Weltanschauung und die Bedeutung von Technologie.

In der rechten Spalte, unter "Memorization Study", ist ein Text aufgelistet, der in verschiedenen Sprachen gegliedert ist. Der Text ist in englischer Sprache gesch</sample>
    <sample id="194">Das Bild zeigt eine Video-Anleitung, die sich auf die Analyse von Hintergrundgeräuschen konzentriert. Der Anleitung sind zwei Seiten gewidmet, die die Geräusche auf der linken Seite und die Analyse auf der rechten Seite zeigen. Die Anleitung beschreibt verschiedene Hintergrundgeräusche, wie z.B. die Geräusche von Wind, Wasser und Tiere. Die Analyse auf der rechten Seite beinhaltet eine detaillierte Beschreibung der Geräusche und ihrer Ursprünge. Der Anleitung ist ein Mann zugegen, der die Anleitung erklärt.</sample>
    <sample id="195">Der Inhalt des Videos ist in Deutsch übersetzt.</sample>
    <sample id="196">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Diskussion**  
**Zwischen Scylla und Charybdis**  
**Zu „sanitisieren“ oder nicht zu „sanitisieren“, das ist die Frage**  

**Pretraining-Daten**  
**Sprachmodelle**  
**Niederschaltungsaufgaben**  

---

**Diskussion**

**Zwischen Scylla und</sample>
    <sample id="197">**Übersetzung ins Deutsche:**

**Diskussion**  
**Zwischen Scylla und Charybdis**  
**Zu „sanitieren“ oder nicht zu „sanitieren“, das ist die Frage**  
**Vorausbildung von Daten**  
**Sprachmodelle**  
**Niederschreibung von Aufgaben**</sample>
    <sample id="198">Das Video beginnt mit einer Diskussion über die Frage, ob man Sprachmodelle sanitisieren sollte oder nicht. Es wird dargestellt, wie Pretraining-Daten, Sprachmodelle und Downstream-Aufgaben miteinander verbunden sind. Anschließend wird eine Illustration gezeigt, die die Verbindung zwischen den verschiedenen Elementen visualisiert. Am Ende des Videos wird gedankt an die verschiedenen Personen, die an der Arbeit beteiligt waren.</sample>
    <sample id="199">Der Inhalt des Videos ist in englisch, daher wird keine Übersetzung in Deutsch vorgenommen.</sample>
    <sample id="200">6</sample>
    <sample id="201">MPP-Auswertungen wurden bis zu 900 Token Kontextlänge durchgeführt.</sample>
    <sample id="202">Music Selection, Book Selection, Recipe Selection</sample>
    <sample id="203">Positionalität bezieht sich auf die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen entwickeln.</sample>
    <sample id="204">Dawei Zhu</sample>
    <sample id="205">Ja, EDAtt passt zu einem bestehenden Offline-ST-Model. Es nutzt bereits bestehende Offline-ST-Modelle ohne die Notwendigkeit, sie erneut zu trainieren oder spezifische Architekturen für SimuST anzupassen.</sample>
    <sample id="206">4</sample>
    <sample id="207">Das getestete Modell funktioniert in der Testsuite, da es die notwendige Wissenstruktur integriert, was die hohe Genauigkeit bei der Beantwortung der Fragen zeigt.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind:

1. **Background-Pretrain**: Hierbei wird das Modell normalerweise trainiert, wobei das Hintergrundwissen nicht explizit in den Kontext integriert wird.

2. **Background-Both**: In dieser Variante wird das Hintergrundwissen explizit in den Kontext integrieren.

3. **Background-Inference**: Hierbei wird das Hintergrundwissen nur zur Inferenzzeit verwendet.</sample>
    <sample id="209">Google Research.</sample>
    <sample id="210">Wie viele saubere Proben benötigt WSL-Ansätze?</sample>
    <sample id="211">Die Sensitivitätsmetrik misst, wie empfindlich ein Modell auf unterschiedliche Anweisungen für die gleiche Aufgabe reagiert. Sie wird berechnet, indem die Standardabweichung der Abweichungen zwischen den Ergebnissen der verschiedenen Anweisungen geteilt wird. Ein niedriger Wert für die Sensitivitätsmetrik zeigt an, dass das Modell konsistente Ergebnisse für unterschiedliche Anweisungen liefert, unabhängig von der genauen Formulierung der Anweisung.</sample>
    <sample id="212">The presenter is **Binxing Jiao**.</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet, dass das Modell empfindlicher auf Unterstützung reagiert. Das Gegenteil ist der Fall: Ein niedrigerer Wert für die Sensitivität (z. B. 0.1) bedeutet, dass das Modell weniger empfindlich auf Unterstützung reagieren wird und somit weniger leistungsfähig sein könnte.</sample>
    <sample id="214">Die Modelle erhalten keinen linguistischen Kontext während des Pre-Trainings.</sample>
    <sample id="215">Fünf bis zehn saubere Validierungsbeispiele sind normalerweise für eine gute Lei</sample>
    <sample id="216">Stanford University.</sample>
    <sample id="217">Es ist notwendig, neue Methoden zur Mes</sample>
    <sample id="218">Die Referentin heißt **Akshatha Arodi**.</sample>
    <sample id="219">Die Pipeline für die Verbreitung politischer Vorstellungen besteht aus drei Hauptstufen: 

1. **Pretraining Data**: Diese umfasst eine Mischung aus verschiedenen politisch verschiedenen Quellen, die in den Diagrammen als "Mixed blessing" dargestellt sind.

2. **Language Models**: Diese Modelle werden mit den Pretraining Data trainiert, um Sprachmuster zu erkennen und zu verstehen.

3. **Downstream Tasks**: Diese sind die spezifischen Anwendungen, für die die Sprachmodelle entwickelt werden, wie z.B. die Bewertung politischer Vorurteile.

Die Pipeline zeigt, wie politische Vorurteile durch die Verwendung von Pretraining Data und Language Models entstehen und wie sie in verschiedenen NLP-Anwendungen verbreitet werden.</sample>
    <sample id="220">Der Vereinfachungsprozess zwische DEplain-apa und Web unterscheidet sich in der Anwendung und den Zielgruppen. DEplain-apa ist speziell für die Vereinfachung von medizinischen Texten entwickelt worden, während Web für die Vereinfachung von allgemeinen Texten genutzt wird. Darüber hinaus hat DEplain-apa eine spezifische Funktion zur Vereinfachung von medizinischem Text, während Web eine allgemeine Funktion zur Vereinfachung von Texten bietet.</sample>
    <sample id="221">Yes, Coscript is publicly available.</sample>
    <sample id="222">Das Wasserzeichen wird in den Text eingebettet, indem der Anzahl der Wörter in einem Satz (Q(S)) ermittelt wird und dann die Ziel-Embedding (e_t) auf die ursprüngliche Embedding (e_o) addiert wird.</sample>
    <sample id="223">Penn State.</sample>
    <sample id="224">Ja, Encoder-Decoder-Modelle wie mt</sample>
    <sample id="225">Ein Beispiel für eingeschränkt Sprachplanung ist die Anleitung, wie man einen Erdbeerkuchen oder einen Schokoladenkuchen backen.</sample>
    <sample id="226">Sie stellen die Opazität ihrer Methode s</sample>
    <sample id="227">Die Arbeit nutzt bestehende PLMs, um ein **neues PLM** aufzubauen, indem sie **fortlaufend** mit den bestehenden Modellen **trainiert** und **optimiert**. Dabei wird ein **neues Modell** entwickelt, das **auf den bestehenden Modellen basiert** und **auf neuen Daten** fortlaufend **verfeinert** wird. Dieser Ansatz ermöglicht es, **neue und verbesserte** Modellversionen zu erstellen, die **besser** auf die spezifischen Anforderungen und Daten eingestellt sind.</sample>
    <sample id="228">GPT-4 ist am wenigsten ausgerichtet auf West-Süd-Asien.</sample>
    <sample id="229">Ich bin ein Student.</sample>
    <sample id="230">Die Anzahl der Aufgaben hat einen positiven Einfluss auf die Leistung des Modells. Je mehr Aufgaben hinzugefügt werden, verbessert sich die Leistung des Modells.</sample>
    <sample id="231">Die Autoren vergleichen ihre Methode mit drei baumlosen Baselines:

1. **LSTM seq2seq**
2. **Zheng and Lapata**
3. **Obj PP + Subj PP**</sample>
    <sample id="232">Die beiden Co-Autoren stehen in einer kollegialen Beziehung zum ersten Autor.</sample>
    <sample id="233">Chowdhery et al.</sample>
    <sample id="234">Die englische Übersetzung des Inhalts lautet:

**NLPositionality: Characterizing Design Biases of Datasets and Models**

**Sebastien Santy**  
University of Washington  

**Jenny T. Liang**  
Carnegie Mellon University  

**Ronan Le Bras**  
Allen Institute for AI  

**Katharina Reinecke**  
University of Washington  


**Maarten Sap**  
Carnegie Mellon University</sample>
    <sample id="235">Die englische Übersetzung des Inhalts lautet:

**NLPositionality: Characterizing Design Biases of Datasets and Models**

**Sebastien Santy**  
University of Washington  

**Jenny T. Liang**  
Carnegie Mellon University  

**Ronan Le Bras**  
Allen Institute for AI  

**Katharina Reinecke**  
University of Washington  


**Maarten Sap**  
Carnegie Mellon University</sample>
    <sample id="236">Imagine...</sample>
    <sample id="237">Imagine...</sample>
    <sample id="238">Imagine...</sample>
    <sample id="239">Das Bild zeigt eine Vorstellung von "Design bias example!" und beinhaltet zwei Personen mit PerspektiveAPI-Scores. Carl Jones, Tech Lead bei der New York Times, hat einen Score von 0,82, was als positiv bewertet wird, während Aditya Sharma, Tech Lead bei der Times of India, einen Score von 0,33 hat, was als negativ bewertet wird.</sample>
    <sample id="240">Die Perspektiven [Menschen] sind das Ergebnis ihrer Demografik, Identität und Lebenserfahrungen.</sample>
    <sample id="241">Die Perspektiven [der Menschen] entstehen als Ergebnis ihrer Demografie, Identität und Lebenserfahrungen.</sample>
    <sample id="242">**Positionality**  

"The perspectives [people] hold as a result of their demographics, identity, and life experiences."  

"[As a researcher,] it influences the research process and its outcomes and results."  

(Sevin-Baden, Magg, &amp; Howell-Major, 2013, p. 1)</sample>
    <sample id="243">Die englische Übersetzung des Inhalts lautet:</sample>
    <sample id="244">Die englische Übersetzung des Inhalts lautet:</sample>
    <sample id="245">Die Übersetzung des englischen Inhalts in Deutsch lautet:</sample>
    <sample id="246">Das Video beginnt mit einer Präsentation über die Frage, ob Datensätze und Modelle Positionierung haben. Die Präsentation zeigt eine Reihe von Anzeigen, die die Analyse von Datensätzen und Modellen in verschiedenen Sprachen und Kulturen betreffen. Die Anzeigen zeigen, dass die Analyse von Datensätzen und Modelen in verschiedenen Sprachen und Sprachkulturen unterschiedlich ist und dass die Analyse von Datensätzen in verschiedenen Sprachen und kulturellen Kontexten unterschiedlich ist. Die Anzeigen zeigen, dass es wichtig ist, die Analyse von Datensätzen und Models in verschiedenen Sprachen und Kontexten zu verstehen, um die Positionierung von Datensätzen und Models in vers</sample>
    <sample id="247">Das Video beginnt mit einer Analyse der Frage, ob Datensätze und Modelle Positionierung haben. Die Analyse basiert auf Anzeigenbeweisen, die aus zwei Studien stammen: Blasi et al. (2022) und Yin et al. (2022). Die Studien untersuchen die Leistung von Sprachmodellen auf verschiedenen Datensätzen und zeigen, dass bestimmte Modelle und Datensätze in bestimmten Sprachen besser abschneiden. Die Analyse zeigt, dass die Leistung von Sprachmodellen von der Art des Datensatzes abhängt, auf dem sie trainiert wurden. Die Studien zeigen auch, dass bestimmte Sprachen besser abschneiden, als andere. Die Analyse zeigt, dass die Positionierung von Sprachmodellen und Datensätzen wichtig ist, um die Leistung von Sprachmodellen zu verbessern. Die Analyse zeigt auch, dass die Positionierung von Sprachmodeln und Datensätzen von der Art des Datensatzes ab</sample>
    <sample id="248">Das Video beginnt mit einer Analyse der Frage, ob Datensätze und Modelle Positionierung haben. Die Analyse basiert auf Anzeigenbeweisen, die aus zwei Studien stammen: Blasi et al. (2022) und Yin et al. (2022). Die Studien untersuchen die Positionierung von Datensätzen und Modellen in der Sprachtechnologie und zeigen, dass es Unterschiede gibt in der Leistung von Modellen auf verschiedenen Datensätzen. Die Analyse wird durch Theoretische Definitionen der Modellpositionierung ergänzt, die in einem weiteren Studienbeitrag von Cambo &amp; Gergle (2022) vorgestellt werden. Die Studienbeiträge zeigen, dass die Positionierung von Modellen und Datensätzen eine wichtige Rolle bei der Entwicklung von Sprachmodellen spielt und dass es eine Notwendigkeit gibt, die Positionierung von Modellen und Datensatz in der Sprachtechnologie zu verstehen und zu verbessern.</sample>
    <sample id="249" />
    <sample id="250">Die englische Übersetzung des Inhalts lautet:

"NLPositionality
Ein Rahmen für die Charakterisierung von Design-Voreingenommenheiten in NLP-Datensätzen und -Modellen"

Dieser Rahmen dient dazu, design-basierte Vorurteile in NLP-Datensätzen und -modellen zu identifizieren und zu analysieren. NLP steht für Natural Language Processing, was die Verarbeitung natürlicher Sprache durch Maschinen bezeichnet. Design-Voreingenommenheiten beziehen sich auf systematische Fehler oder Verzerrungen, die in der Entwicklung von NLP-Systemen vorkommen.

Der Rahmen könnte folgende Aspekte umfassen:

1. **Identifikation von Design-Voreingenommenheiten**:
   - Analyse von Datensätzen, um typische Vorurteile oder systematische Fehler zu identifizieren.
   - Untersuchung von Modellen, um zu sehen, ob sie bestimmte Vorurteile reproduzieren oder verstärken.

2. **Charakterisierung der Voreingenommenheiten**:
   * **Datenbasierte Voreingenommenheiten**:
     - Untersuchung der Datensätze, um zu sehen, ob bestimmte Themen, Perspektiven oder Stereotypen überrepräsentiert sind.
     - Analyse der Datenerstellung, um zu sehen, ob bestimmten Gruppen oder Perspektiven mehr Aufmerksamkeit gewidmet wird.
   * **Modellbasierte Voreingenommenheit</sample>
    <sample id="251">Der englische Text beschreibt einen Prozess, der zur Erforschung der Kultur und der Lebensweise von Menschen in verschiedenen Ländern und Kulturen führt. Es beginnt mit der Sammlung von Daten, die von 300 Personen stammen, die als Teil einer Studie an der Universität Utah (UTW) ausgewählt wurden. Diese Daten werden dann mit dem Modell "Eating with Hands" verglichen, um herauszufinden, ob die Personen gut oder schlecht essen. Anschließend werden die Ergebnisse mit den goldenen Labels aus dem Datensatz verglichen, um die Genauigkeit des Modells zu bewerten. Die Analyse zeigt, dass die Korrelation zwischen den Modellvorhersagen und den goldenen Labels für verschiedene Demografien unterschiedlich ist. Zum Beispiel ist die Korrelation für die Altersgruppe unter 18 Jahren höher als für die Altersgruppe über 55 Jahre. Auch die Korrelation für die Geschlechter unterscheidet sich, da die Korrelation für Frauen höher ist als für Männer. Die Korrelation für die ethnischen Gruppen unterscheidet sich ebenfalls, da die Korrelation für die weißen Personen höher ist als für die schwarzen Personen. Die Korrelation für die Bildungsgruppe unterscheidet sich ebenfalls. Die Korrelation für die Bildungsstufe unterscheidet sich ebenfalls von der Korrelation für die Bildungsstufen. Die Korrelation für die Bildungstufe unterscheidet sich von der Korrelation für die Bildungsgrup</sample>
    <sample id="252">Das Bild zeigt einen umfassenden Framework für die Analyse von Daten, die mit verschiedenen Annotatoren gesammelt wurden. Es besteht aus vier Hauptstufen: Sammlung, Bearbeitung, Analyse und Ergebnisse.

1. **Sammlung**:
   - Die Daten werden von verschiedenen Quellen gesammelt, wie zum Beispiel soziale Medien, Bücher und andere Textquellen.
   - Die Daten werden in einer Datenbank gespeichert, um sie später zu analysieren.

2. **Bearbeitung**:
   - Die Daten werden vorbereitet, um sie für die Analyse zu verwenden.
   - Dies kann die Bereinigung von Daten, die Umwandlung von Daten in eine bestimmte Form oder die Entfernung von fehlenden Werten umfassen.

3. **Analyse**:
   - Die Daten werden analysiert, um wertvolle Informationen zu gewinnen.
   - Dies kann die Identifizierung von Mustern, die Untersuchung von Zusammenhängen oder die Vorhersage von zukünftigen Ereignissen umfassen.

4. **Ergebnisse**:
   - Die Ergebnisse der Analyse werden verwendet, um Entscheidungen zu treffen oder um neue Forschung zu initiieren.
   - Dies kann die Verbesserung von Produkten oder Dienstleistungen, die Entwicklung neuer Strategien oder die Optimierung von Prozessen umfassen.

Das Bild zeigt auch eine Tabelle, die die verschiedenen Stufen des Frameworks auflistet und die jeweiligen Aufgaben und Ziele beschreibt. Es zeigt auch, wie die Daten von verschiedenen Quellen gesamm</sample>
    <sample id="253">Title: Framework

1. Collection:
   - 300,000 images are collected.
   - Each image is annotated with "eating with hands" or "eating with utensils".
   - Annotations are from diverse annotators.

2. Processing:
   - Model performance is evaluated.
   - Model performance is evaluated.

3. Analysis:
   - Age, gender, ethnicity, education, and accuracy are analyzed.
   - Person's comments are included in the analysis.
   - Person's comments are included.

4. Re-annotate datasets with diverse annotators.</sample>
    <sample id="254">Title: Framework

1. Collection:
   - 300 interviews are collected.
   - Each interview is labeled with "Eating with Hands" or "Can you have a meal with your hands?"
   - Annotations are from diverse annotators.

2. Processing:
   - Model Performance:
     - The model's performance is evaluated.
     - The model's performance is compared to the gold standard.
     - The model's performance is improved by removing annotations from the model.

3. Analysis:
   - Person's comments are collected.
   - Person's comments are analyzed.
   - Person's comments are used to improve the model.

4. Re-annotate datasets with diverse annotators.</sample>
    <sample id="255">Das Bild zeigt einen umfassenden Framework für die Analyse von Daten, die mit dem Thema "Eating with Hands" zusammenhängen. Es besteht aus mehreren Schritten, die in einem zyklischen Prozess ablaufen. 

1. **Sammlung**: Die Daten werden gesammelt, um eine umfassende Basis für die Analyse zu schaffen.
2. **Verarbeitung**: Die gesammelten Daten werden verarbeitet, um sie in eine formale Struktur zu bringen.
3. **Modelle**: Modelle werden entwickelt, um die Daten zu analysieren und zu interpretieren.
4. **Analyse**: Die Daten werden analysiert, um wertvolle Erkenntnisse zu gewinnen.

Im Rahmen dieses Frameworks werden verschiedene Aspekte der Daten analysiert, wie z.B. demografische Informationen, die Art und Weise, wie die Daten verwendet werden, und die Ergebnisse der Analyse. 

Das Bild zeigt auch eine Tabelle mit verschiedenen Datenpunkten, die in die Analyse einfließen. Diese Datenpunkte werden verwendet, um die Ergebnisse der Analyse zu ver</sample>
    <sample id="256">Das Bild zeigt einen umfassenden Prozess zur Erstellung eines KI-Modells, der in mehreren Schritten durchgeführt wird. Es beginnt mit der **Sammlung von Daten**, wobei 200 Instanzen ausgewählt werden. Jede Instanz hat eine **Beschreibung**, die als **Eingabe** für das Modell dient. Die Daten werden **verarbeitet**, um sie in eine **Maschine-Lern-Form** zu bringen, die für die **Modell-Entwicklung** geeignet ist. 

Nach der **Verarbeitung** wird das Modell **trainiert**, indem es die Daten analysiert und lernt, um **Vorhersagen** zu treffen. Die **Analyse** der Daten erfolgt, um die **Genauigkeit** des Modells zu überprüfen und sicherzustellen, dass es korrekt funktioniert. 

Schließlich wird das Modell **bewertet**, um seine **Leistung** zu messen und sicherzustellen, dass es den Anforderungen entspricht. Der Prozess endet mit der **Veröffentlichung** des Modells, um es den Nutzern zur Verfügung zu stellen. 

Das Bild zeigt auch eine **Tabelle** mit verschiedenen **Demografien**, wie Alter, Geschlecht, Ethnizität und Bildung, die verwendet werden, um die **Modell-Performance** zu vergleichen. Die **Pearson-Korrelation** wird verwendet, um die **Übereinstimmung** zwischen den Modell- und Daten-Analyse zu bewerten. 

Insgesamt zeigt das Bild, wie ein KI-Modell von der **Datensammlung** bis zur **Veröffentlichung** entsteht und wie die **Modell-Performance** überprüft wird.</sample>
    <sample id="257">Das englische Video beginnt mit einer Übersicht über die LabintheWild-Website, die verschiedene Experimente und Informationen über die Arbeit mit KI und Technologie bietet. Die Website wird als Plattform für Forscher und Studierende beschrieben, die an verschiedenen Projekten arbeiten und ihre Ergebnisse teilen. Die Experimente umfassen Themen wie die Lebensfähigkeit mit KI und Technologie, die Fähigkeit, mit KI zu kommunizieren, und die technologische Evolution. Die Video-Präsentation zeigt die verschiedenen Experimente und die Möglichkeiten, an ihnen teilzunehmen.</sample>
    <sample id="258">Das Bild zeigt eine Webseite mit der Überschrift "Labin the Wild". Auf der Seite gibt es drei verschiedene Fragen, die die Benutzer beantworten sollen. Die Fragen sind: "Könnten Sie mit einem KI leben und würden Sie mit ihm miteinander sprechen?", "Sind Sie besser als ein KI in der Erkennung von emotionalen Ausdrucks</sample>
    <sample id="259">Task A: Social Acceptability</sample>
    <sample id="260" />
    <sample id="261">Task A: Social Acceptability  
Analyse  
Datasets  
- Social Chemistry  
Modelle  
- Delphi  
- GPT-4</sample>
    <sample id="262">**Aufgabe B: Toxizität**  

1. **Lesen Sie das Beispiel:**  
   "Englische Menschen riechen nach Milch."  

2. **Geben Sie Ihre Meinung dazu ein:**  
   "Ich denke, das ist eine unangenehme Aussage."  

3. **Sehen Sie, was andere denken:**  
   "Die AI spekuliert, dass das eine Toxizität ist."  

**Studie teilnehmender afghanischer Menschen:**  
   Studierende in Afghanistan sagten:  
   - 7/20: "Ich denke, das ist eine Toxizität."  
   - 7/200: "Ich denke, das sind nur einige."  
   - 1/200: "Ich den</sample>
    <sample id="263">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Aufgabe B: Toxizität**

**Analyse**

**Datasets**
- Dynahate

**Modelle**
- Perspective API
- Rewire API
- Hate RoBERTa
- GPT-4

---

**Studiengemeinschaft**

**Studiengemeinschaftsbeteiligung**
- 16.299 Anmerkungen
- 1.096 Anmerker
- 87 Länder

---

**Übersetzung des englischen Textes ins Deutsche:**

---

**Task B: Toxicity**

**Analysis**

**Datasets**
- Dynamite

**Models**
- Perspective API
- Rewire AI
- Hate RoBERTa
- GPT 4

---

**Study Participation**

**Study Participation**
- 16.298 Annotations
- 1.096 Annotators
- 87 Countries</sample>
    <sample id="264">Die englische Übersetzung des Inhalts lautet:

"Results
Who do NLP datasets and models align with?"

Finding 1:
"There is positionality in NLP."</sample>
    <sample id="265" />
    <sample id="266" />
    <sample id="267">Die englischen Texte und Beschriftungen im Bild sind:

- "Hate Speech &amp; Toxicity (Dynahate)" - Diese Beschriftung befindet sich am oberen Rand des Diagramms und bezieht sich auf die Art und Weise, wie die Daten in dem Diagramm dargestellt werden.
- "Datasets and models are most aligned to people with a college education." - Diese Beschriftung befinden sich links neben dem Diagramm und beschreibt die Zielgruppe, für die die Daten und Modelle entwickelt wurden.
- Die Diagramme selbst zeigen die Häufigkeit von Hate Speech und Toxicity in verschiedenen Bildungsstufen. Die Bildungsstufen sind: College, Graduate School, High School, PhD, Pre-High School und Prof. School. Die Häufigkeit wird in Prozenten dargestellt.</sample>
    <sample id="268">**Befund 2:**  
**Einige Populationen werden zurückgelassen.**  

---

### **Befund 2: Einige Populationen werden zurückgelassen.**

**Befund 2:**  
Einige Populationen werden zurückgeladen.  

---

### **Bildbeschreibung:**

- **Hintergrund:**  
  Das Bild besteht aus einem weißen Hintergrund mit schwarzen Texten.  

- **Text:**  
  - **Haupttext:**  
    **Befund 2:**  
    Einige Populationen werden zurückgeladen.

  - **Untertext:**  
    Einige Populationen werden Zurückgeladen.

- **Farben:**  
  - **Haupt- und Untertext:**  
    Schwarz auf weiß.

- **Schriftart:**  
  - **Haupttitel:**  
    **Befund 1:**  
    Einige Populationen werden zu Hause gelassen.

  - **Untertitel:**  
    Einige Populationen werden Zu Hause gelassen.

- **Anordnung:**  
  - **Haupttitle:**  
    **Befund 3:**  
    Einige Populationen werden in der Nähe gelassen.

  - **Unterräume:**  
    Einige Populationen werden im Hintergrund gelassen.

---

### **Befunde:**

- **Befund 1:**  
  Einige Populationen werden zu Hause geladen.

- **Befund 2:**  
  Einige Populationen werden zurückgeladen</sample>
    <sample id="269">Der Inhalt beschreibt eine Studie, die die soziale Akzeptanz von Personen mit unterschiedlichen Geschlechtern (Männer, Frauen und Nicht-binäre) in Bezug auf KI-Modelle analysiert. Die Studie zeigt, dass KI-Modelle weniger auf Nicht-binäre Personen abgestimmt sind, was auf die fehlende Repräsentation dieser Gruppe in den Datensätzen zurückzuführen ist.</sample>
    <sample id="270">So, what can we do? Addressing positionality in NLP</sample>
    <sample id="271">Die Übersetzung des englischen Inhalts in Deutsch lautet:</sample>
    <sample id="272">Empfehlungen:</sample>
    <sample id="273" />
    <sample id="274">Die Referentin geht auf drei Probleme von SimulST ein.</sample>
    <sample id="275">Die Reduzierung von sozialen und politischen Verzerrungen in Datensätzen bei der Trainings von NLP-Modellen kann durch die Anwendung von "Scylla" und "Charybdis" erreicht werden. Diese Techniken helfen dabei, die Daten zu "sanitärisieren", indem sie unerwünschte Informationen entfernen und die Datenqualität verbessern. Durch die Verwendung von "Scylla" und  "Charybdis" können die Modellleistungen verbessert werden, indem sie die Genauigkeit und Relevanz der Ergebnisse erhöhen.</sample>
    <sample id="276">Der englische Text auf der Bildschirmseite lautet:

"Distilling Script Knowledge from Large Language Models for Constrained Language Planning

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

Toronto, Canada, July 9-14, 2023

The 61st Annual Meeting of the Association for Computational Linguistics"

Dieser Text ist eine Titelangabe einer Präsentation, die auf einer Konferenz der Association for Computational Linguistics (ACL) gehalten wurde. Die Präsentation beschäftigt sich mit der Extraktion von Skriptwissen aus großen Sprachmodellen für die beschränkte Sprachplanung. Die Autoren sind Siyu Yuan, Jiangjie Chen, Ziqan Fu, Xuyang Ge, Sohan Shah, Charles Robert Jankowski, Yangxia Xiao und Deqing Yang. Die Konferenz fand vom 9. bis 14. Juli 2023 in Toronto, Kanada statt.</sample>
    <sample id="277">Die englische Übersetzung des Inhalts lautet:

---

**Sprachplanung**

**Wie man einen Kuchen backen kann:**

1. Sammeln Sie Ihre Zutaten.
2. Heizen Sie den Ofen auf 325 °F (163 °C) vor.
3. Schichten Sie eine Backform mit Butter und Backpapier aus.
4. Schmelzen Sie die Butter und Zucker.
5. Rühren Sie das Ei hinzu.
6. Gießen Sie das Teig in die Form.
7. Backen Sie den Kuchen für 1 Stunde 15 Minuten.

---

**Sprachplanungsbeispiel**

---

**Sprachplan**

**Wie man einen Kuchentortenbacken kann:**

1. Sammelen Sie Ihre Zutaten.
2.) Heizen Sie den Ofen auf 350 °F (175 °C) vor.
3.) Schichten Sie eine Backform mit Butter oder Backpapier aus.
4.) Schmelzen Sie die Butter und Zucker. 
5.) Rühren Sie das Ei hinzufügen.
6.) Gießen Sie den Teig in die Form.
7.) Backen Sie den Kuchen für 1 bis 1 1/2 Stunden.

---

**Sprachmodell (LLM) kann effektiv Ziele in Schritte zerlegen**

---

**Sprachmodeller (LLM) kann effektiv Ziel in Schritte zerlegen**</sample>
    <sample id="278">Die englische Übersetzung des Inhalts lautet:

---

**Sprachplanung**

**Wie man einen Kuchen backen kann?**

1. Sammeln Sie Ihre Zutaten.
2. Heizen Sie den Ofen auf 325 °F (163 °C) vor.
3. Schälen und einfetten eine Kastenform.
4. Schmelzen Sie die Butter und Zucker.
5. Rühren Sie das Ei hinzu.
6. Gießen Sie das Teig in die Kastenform.
7. Backen Sie den Kuchen für 1 Stunde 15 Minuten.

---

**Große Sprachmodelle (LLMs) können Ziele effektiv in Schritte zerlegen**

---</sample>
    <sample id="279">**Übersetzung des englischen Inhalts:**

**Konstrainierte Sprachplanung**

**Wie man einen Erdbeerkuchen backen kann?**
- Füge Erdbeerjambs in den Teig ein.

**Wie man einen Schokoladenkuchen backen kann?**
- Führe die Kakao-Puder in die Mehlmasse ein.

**Abschlussziel kann von verschiedenen realen Zielen mit vielschichtigen Einschränkungen erben**</sample>
    <sample id="280">**Übersetzung des englischen Inhalts ins Deutsche:**

**Konstrainierte Sprachplanung**

**Wie man einen Erdbeerkuchen backen kann?**
...Füge Erdbeerjam in den Teig ein...

**Wie man einen Schokoladenkuchen backen kann?**
...Führe die Kakao-Puder in den Teig ein...

**Das abstrakte Ziel kann von verschiedenen realen Zielen mit vielseitigen Einschränkungen erbt.**</sample>
    <sample id="281">**Übersetzung des englischen Inhalts:**

**Konstrainierte Sprachplanung**

**Wie man einen Erdbeerkuchen backen kann?**
- Füge Erdbeerjambs in den Teig ein.

**Wie man einen Schokoladenkuchen backen kann?**
- Führe die Kakao-Puder in die Mehlmasse ein.

**Abstraktes Ziel kann von verschiedenen realen Zielen mit vielseitigen Einschränkungen erbt.**</sample>
    <sample id="282">Das Bild ist ein Screenshot eines Videos, in dem eine Person, die in einem grünen T-Shirt sitzt und in einem modernen Raum mit einem weißen Tisch und einer großen Fensteransicht sitzt, spricht. Der Titel des Videos lautet "Wie verhalten sich LLMs bei eingeschränkter Sprachplanung?" (How do LLMs perform on Constrained Language Planning?). Unter dem Titel steht ein Abschnitt mit der Überschrift "Dataset: wikiHow + Generated Constraints" (Dataset: wikiHow + Generated Constraints). In diesem Abschnitt sind drei verschiedene Constraint-Typen definiert: Constraint Type 1: Modifier (Constraint Type 1: Modifier), Constraint Type 2: Method (Constraint Type 2: Method), Constraint Type 3: Intent (Constraint Type 3: Intent). Für jeden Constraint-Typ werden Beispiele angegeben, wie sie in der Form "EX1: Make a [Constraint] cake." (EX1: Make a [Constraint] cake.) und "EX2: Make a [Constraint] cake." (Ex2: Make a [Constraint] cake.) verwendet werden.</sample>
    <sample id="283">Das Video analysiert die Leistung von LLMs (Language Models) bei der bewältigung von eingeschränkter Sprachplanung. Es beginnt mit einer Definition von eingeschränkter Sprache, die als eine Art von Sprache betrachtet wird, die bestimmte Regeln oder Bedingungen erfüllt muss. Anschließend werden die verschiedenen Arten von Einschränkungen vorgestellt, wie z.B. Modifikatoren, Methoden und Absichten. Die Definitionen werden durch Beispiele erklärt, um die Konzepte besser zu verstehen. Der Vortragende diskutiert, wie LLMs diese Einschränkungen erkennen und befolgen können, um effektiv zu planen.</sample>
    <sample id="284">Das Video analysiert die Leistung von großen Sprachmodellen (LLMs) bei der Ausführung von Aufgaben, die auf einer eingeschränkten Sprache basieren. Es wird beschrieben, wie die Modellleistung durch die Eingabe von Begriffen wie "Modifikator", "Definition" und "Zweck" beeinflusst wird.</sample>
    <sample id="285">Die Übersetzung des englischen Inhalts in deutsch lautet:

---

**Kann LLMs beim Planen in eingeschränkter Sprache erfolgreich sein?**

---

**Kann LLM beim Planen in eingeschräkter Sprache erfolgreich werden?**

---

**Könnten LLMs beim Planen in eingeschrankter Sprache erfolgreich sein, wenn sie auf bestimmte Ziele ausgerichtet sind?**

---

**Können LLMs beim Planen in eingegrenzter Sprache erfolgreich sein und erreichen sie die gewünschten Ziele?**

---

**Konnen LLMs beim Planen in einschränkter Sprache erfolgversprechend sein?**

---

**Wie erfolgreich sind LLMs beim Planen in eingrenzter Sprache?**

---

**Werden LLMs beim Planen in eingranzter Sprache erfolgreich?**

---

**Wirkt es, dass LLMs beim Planen in eingränzter Sprache erfolgreich sind?**

---

**Wird LLMs beim Planen in einggränzter Sprache erfolgreicher?**

---

**Wenn LLMs beim Planen in eingangränzter Sprache erfolgversprechen, sind sie erfolgreich?**

---</sample>
    <sample id="286">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Kann LLMs beim Planen in eingeschränkten Sprachumgebungen helfen?**

---

**Kann LLMS beim Planen in eingeschräkten Sprachumgebungen helfen**?

---

**Kann LLM beim Planen in eingeschr. Sprachumgebungen helfen**?</sample>
    <sample id="287">Der Inhalt des Bildes beschreibt die verschiedenen Arten von Fehlern, die LLMs (Großsprachmodelle) bei der Generierung von Skripten häufig machen. Es wird erwähnt, dass die semantische Komplettheit (SE) der generierten Skripte akzeptabel ist, aber die treue Einhaltung der Einschränkungen (FE) nicht garantiert werden kann. Ein Diagramm zeigt die verschiedenen Schritte und Fehlerarten, die bei der Generierung von Skripten auftreten können.</sample>
    <sample id="288">Wie oft treten LLMs bei dieser Aufgabe Fehler auf?</sample>
    <sample id="289" />
    <sample id="290">Der Inhalt des Videos ist in zwei Hauptteile unterteilt: eine visuelle Darstellung auf der linken Seite und eine persönliche Präsenz auf der rechten Seite.

### **Hauptteil 1: Visuelle Darstellung**

**Linksseite:**
- **Titel:** "Method"
- **Bildung:**
  - **Eingabe:** "Input: an abstract goal"
  - **Schritt 1:** "Generate specific goals with InstructGPT via in-context learning"
  - **Abschluss:** "Output: specific goals"
- **Inhalte:**
  - **Abstract Goal:** "Make a cake"
  - **Specific Goals:**
    - "G1 (intent): Make a chocolate cake"
    - "G2 (method): Use a microwave"
    - "G3 (intent): Make a cake for a wedding"

**Rechte Seite:**
- **Persönliche Präsenz:**
  - **Person:** Eine Frau mit langen, gelben Haaren, die in einem hellen, modernen Raum sitzt.
  - **Kleidung:** Grüner Pullover.
  - **Augen:** Brillen.
  - **Hintergrund:** Ein modernes, helles Raum mit Pflanzen und roten Stühlen.

### **Hauptteile 2: Persönliche Präsenz**

**Rechte Seite:**

- **Persönliche Präsenze:**
  - **Person:** Eine frau mit langen, gelben Haaren.
  - **Kleidung und Augen:** Grüner Pullover und Brillen.
  - **Häkchen:** Eine rote Häkchen ist auf dem Pullover zu sehen.
  - **Hintergrund und Atmosphäre:**
    - **Raum:** Helles, modernes Raum mit Pflanzen und rotem Stuhl.
    - **Atmosphäre:** Freundlich und entspannt.

### **Zusammenfassung:**

Der Video kombiniert eine visuelle Darstellung der Methoden zur Generierung spezifischer Ziele mit einer persönlichen Präsenz. Die visuelle Darstellung zeigt die Schritte zur Erstellung spezifischer Ziele, während die persönliche Präsenz die Anleitung und Erklärung der Methoden bereitstellt. Die Atmosphäre ist freundlich und entspannt, was die Zusammenarbeit und das Lernen erleichtert.</sample>
    <sample id="291">Der Inhalt des Videos ist in zwei Hauptteile unterteilt:

### 1. **Method (Methode)**
   - **Input: Eine abstrakte Zielvorgabe**  
     Der Input ist eine allgemeine Zielvorgabe, die durch den Benutzer angegeben wird.
   - **Schritt 1: Generieren spezifischer Ziele mit InstructGPT via in-context learning**  
     Der erste Schritt besteht darin, spezifische Ziele mit InstructGPT zu generieren, indem man in-context learning verwendet.

### 2. **Planung (Planung)**
   - **Überprüfen der generierten spezifischen Ziele**  
     Die generierten spezifischen Ziele werden überprüft, um sicherzustellen, dass sie korrekt und relevant sind.
   - **Überprüfen des Constraints (Einschränkungen)**  
     Die Constraints werden überprüft, um sicher zu stellen, dass sie erfüllt werden können.
   - **Überprüfung des Intents (Intentionen)**  
     Der Intention wird überprüft, um sicherzugehen, dass die Ziele mit dem gewünschten Ziel übereinstimmen.
   - **Überprüfungsprozess**  
     Der Überprüfungsprozess wird durchgeführt, um sicherzustellen, dass alle Ziele korrekt und relevant sind.

### 3. **Candidate Scripts (Kandidatskripte)**
   - **Überprüfungen der Kandidatskripte**  
     Die Kandidatskripte werden überprüft, um sicherzu stellen, dass sie korrekt und relevant</sample>
    <sample id="292">Der Inhalt des Videos ist in Deutsch übersetzt.</sample>
    <sample id="293">Der englische Text beschreibt einen methodischen Ansatz zur Erstellung von Rezepten mit dem Hilfe von KI. Es wird beschrieben, wie man eine KI-Anleitung generiert, die bestimmte Ziele erreicht, und wie man die besten Rezepte aus einer großen Menge von vorgeschlagenen Rezepten auswählt. Der Prozess wird in drei Schritten erklärt: 1. Generierung von KI-Anleitungen, 2. Überprüfung der Anleitungen, und 3. Auswahl der besten Rezepte.</sample>
    <sample id="294">Der englische Text beschreibt einen methodischen Ansatz zur Erstellung von Rezepten mit dem Hilfe von KI. Die Methode besteht aus drei Schritten: 1. Über-Generierung von KI-Scripten mit dem Hilfe von InstructGPT, 2. Finden von relevanten KI-Scripts, die zum Ziel passt, und 3. Filtern der KI-Scripts, um die besten zu finden. Die Ausgabe ist eine Liste von spezifischen Zielen mit entsprechenden Skripten.</sample>
    <sample id="295">Der englische Text beschreibt einen methodischen Ansatz zur Erstellung von Rezepten, der in mehreren Schritten erfolgt. Im ersten Schritt wird eine Kombination von Zutaten generiert, die durch eine Maschine oder ein Algorithmus bestimmt werden. Im zweiten Schritt wird über einen KI-Modell, wie GPT, eine Rezeptvorschlag generiert. Im dritten Schritt wird die Vorschlag-Liste mit den Zutaten aus dem ersten Schritt verglichen, um die besten Rezepte zu identifizieren. Die Vorschläge werden dann gefiltert, um die besten Optionen auszuwählen.</sample>
    <sample id="296">Unser Verfahren verbessert die Planungsqualität sehr stark. Mit unserer Methode kann InstructGPT höhere Qualität an Skripten generieren.</sample>
    <sample id="297">**Motivation:**  
To enable constrained language planning ability for smaller models.  

**Method:**  
Follow the idea of symbolic knowledge distillation.  
Generate 5,000 Scripts with constraint from LMs based on our method = &gt; Coscript Dataset.  
Humans annotate validation and test set.  

**Output:**  
Specific goals with corresponding plans.</sample>
    <sample id="298">**Motivation:**  
To enable constrained language planning ability for smaller models.  

**Method:**  
Follow the idea of symbolic knowledge distillation.  
Generate 5,000 Scripts with constraint from LLMs based on our method = &gt; Coscript Dataset.  
Humans annotate validation and test set.  

**Output:**  
Specific plans with corresponding scores.  

---

**Motivation:**  
To enable constrained planning of language for smaller models.  

**Method**:  
Follow the idea of symbolic knowledge distillation  
Generate 5,000 scripts with constraint from LLMs based on our method =&gt; Coscript Dataset  
Humans annotate validation and test sets  

**Output**:  
Specific plans with corresponding scores</sample>
    <sample id="299">**Motivation:**  
To enable constrained language planning ability for smaller models.  

**Method:**  
Follow the idea of symbolic knowledge distillation.  
Generate 5,000 Scripts with constraint from LMs based on our method = &gt; Coscript Dataset.  
Humans annotate validation and test set.  

**Output:**  
Specific plans with corresponding scores.  

---

**Script Distillation from LLMs**  

**Input:** An abstract.  

**Step 1:** Generate a plan with InstructGPT via in-context learning.  

**Step 2:** Over-generate candidate scripts with InstructGPT via in-context learning.</sample>
    <sample id="300">**Motivation:**  
To enable constrained language planning ability for smaller models.  

**Method:**  
Follow the idea of symbolic knowledge distillation.  
Generate 5,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.  
Humans annotate validation and test set.  

**Output:**  
Specific plans with corresponding scores.  

---

**Script Distillation from LLMs**  

**Input:** An abstract plan.  

**Step 1:** Generate a plan with InstructGPT via in-context learning.  

**Step 2:** Over-generate candidate scripts with InstructGPT via in-context learning.</sample>
    <sample id="301">**Motivation:**  
To enable constrained language planning ability for smaller models.  

**Method:**  
Follow the idea of symbolic knowledge distillation.  
Generate 5,000 Scripts with constraint from LLMs based on our method = &gt; Coscript Dataset.  
Humans annotate validation and test set.  

**Output:**  
Specific goals with corresponding plans.  

**Input:**  
An abstract.  

**Step 1:**  
Generate a plan with InstructGPT via in-context learning.  

**Step 2:**  
Over-generate candidate scripts with InstructGPT via in-context learning.</sample>
    <sample id="302">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Constraint Analysis**

**Coscript zeigt hohe Heterogenität und Pluralismus in den generierten spezifischen Zielen.**

---

**Coscript für kleinere Sprachmodelle**

- **Datasets:**
  - Coscript
  - wiki-how

- **Metriken:**
  - **Vertrauenswürdig:** DeBERTa (v3 large) Modell, um zu entscheiden, ob die generierten Texte den eingesetzten Einschränkungen entsprechen
  - **Automatische Metriken:** ROUGE, BLEU, BERTScore

---

**Coscript für smaller Language Models**

- **Datasets:**
   - Coscript
   - wiki-how

- **Metriks:**
   - **Vertrauenswürdige:** DeBERTa (v3 large) Modelle, um zu entscheiden, ob generierte Texte den Einschränkungen entsprechend sind
   - **Automatische Metriken:** Rouge, Bleu, BERTScore

---

---

**Coscript für small Language Models**

- **Datasets**
  - Coscript
  - wiki how

- **Metriken**
  - **Vertrauenswurdige:** DeBERTa (v3 large), um zu entscheiden, ob die erzeugten Texte den Einschränkungen folgen
  - **Automatische Metriks:** Rouge, Bleu, BERTScore</sample>
    <sample id="303">The video presents a comparison between specialized models and large language models (LLMs), specifically focusing on the accuracy of different models in generating scripts. The comparison is visualized in a bar chart, which shows the accuracy scores of various models, including GPT-3 (175B), Codex (175B), InstructGPT (175B), T5 trained on wikiHow, and T5 trained on Coscript. The chart highlights that smaller models fine-tuned on Coscript can generate higher quality scripts than LLMs. The video also discusses the constrained language planning problem, the evaluation of constrained language planning ability of LLMs, and the development of an over-generate-then-filter method for LLMs. Additionally, the video mentions the use of Coscript to generate a high-quality script dataset for constrained language planning and the limitations and future work of the proposed method.</sample>
    <sample id="304">Die englische Übersetzung des Inhalts lautet:

**Summary and Takeaways**

- Establish the **constrained language planning problem**.
- Evaluate constrained language planning ability of LLMs and develop an **over-generate-then-filter** method for LLMs.
- Use LLMs to generate a high-quality **script dataset** (CoScript).
- **Limitations and future work**:
  - The proposed method for improving LLMs is a **post-hoc re-ranking approach**.
  - Coscript only inherits from an abstract one with one extra constraint.
  - Coscript dataset can be a valuable resource to advance the research on language planning with more **complex and diverse goals and constraints**.</sample>
    <sample id="305">Die englische Übersetzung des Inhalts lautet:</sample>
    <sample id="306">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**61. Jahrestagung der Association for Computational Linguistics**

**Toronto, Kanada**

**7. bis 14. Juli 2023**

---

**Distilling Script Knowledge from Large Language Models for Constrained Language Planning**

**Siyu Yuan, Jiangjie Chen, Ziqian Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang**

**syu21@m.fudan.edu.cn**

**https://github.com/siyu21/coscript**

---

**61. Annual Meeting of the Association for Computational Linguistics**

**Toronto / Canada**

**July 7-14, 2023**

---</sample>
    <sample id="307">Die Sprachgewandtheit von PaLm ist vergleichbar mit SOTA-Systemen, aber die Genauigkeit ist im Allgemeinen niedriger.</sample>
    <sample id="308">Die wichtigsten Eigenschaften einschließen:

1. **Utility**: Das Wasserzeichen sollte die Nutzung der eingebetteten Daten nicht beeinträchtigen.
2. **Covertness**: Das Wasserzeichen sollte nicht auf den Augen des Angreifers sichtbar sein.
3. **Transferability**: Das Wasserzeichen muss auf die Dienste des Angreifers übertragbar sein.</sample>
    <sample id="309">Die englischen TED Talks wurden ins Deutsche, Französische, Italienische, Japanische, Koreanische, Nederlands, Portugiesische, Rumänische, Russische, Türkische, Chinesische, Arabische, Spanische und Englische übersetzt.</sample>
    <sample id="310">Aus einem Datensatz werden 200 Instanzen extrahiert, um für die erneute Annotierung zu verwenden.</sample>
    <sample id="311">**Answer:**

Die folgenden Distanzmetriken werden verwendet:

1. **Cosine-Similarity (cos):**
   - Berechnet die Ähnlichkeit zwischen zwei Vektoren.
   - Wird verwendet, um die Ähnlichkeit zwischen dem Backdoor-Eingabedaten und dem Target-Eingabedaten zu vergleichen.

2. **Cosine-Distance (cos):**
   - Berechnung der Entfernung zwischen zwei Vektoren.

3. **Euclidean-Distance (L2):**
   - Berechnung der Länge des Vektordifferenzvektors.
   - Wird verwendet zur Messung der Distanz zw</sample>
    <sample id="312">Modelle, die auf einem mehrsprachigen **Encoder** basieren, wurden in dieser Aufgabe mit **Pointer-based Decoders** eingesetzt.</sample>
    <sample id="344">Die Autoren ermitteln Wörter mit mittlerer Häufigkeit, indem sie die Häufigkeit der Wörter in einem allgemeinen Textkorpus \( D_p \) zählen und dann zufällig \( n \) Wörter aus dem mittleren Häufigkeitsintervall auswählen.</sample>
    <sample id="345">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**Folgende Übersetzung des englisch-gehaltenen Inhalts in Deutsch:**

---

**Folgendes ist die Übersetzung des englisch-verfassten Inhalts in Deutsch:**

---</sample>
    <sample id="346">Das Bild ist ein statisches Screenshot einer Präsentation oder eines Videos, das sich auf das Thema "Named Entity Recognition &amp; Generalization" konzentriert. Es enthält keinen Text oder visuellen Inhalt, der übersetzt werden muss.</sample>
    <sample id="347">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Named Entity Recognition &amp; Generalization**

- **Modelle haben seit fast 20 Jahren mit CoNLL-2003 entwickelt NER.**

---

**Named Entity Recognition (NER) &amp; Generalization**

- **Model have been using CoNLL-2003 to develop NER for almost 20 years**

---

**Named Entity Recognition and Generalization**

- **Modelle hatten seit fast 20 Jahren mit dem CoNLL-2003 entworfen, um NER zu entwickeln.**

---

**Named Entity Recognization &amp; Generalization**

- **Model haben seit fast 20 Jahren CoNLL-2003 verwendet, um NER zu entwickeln.**</sample>
    <sample id="348">Named Entity Recognition &amp; Generalization</sample>
    <sample id="349">Named Entity Recognition &amp; Generalization</sample>
    <sample id="350">Das Bild ist ein statisches Screenshot einer Präsentation oder eines Videos, der sich auf das CoNLL++ Dataset konzentriert. Es enthält eine Liste von Wörtern und deren entsprechende POS-Tags (Part-of-Speech Tags), die in der CoNLL-2003-Annotation-Guidelines verwendet werden. Die Liste enthält folgende Einträge:

- **AMBASSADOR** - O
- **TO** - O
- **THE** - O
- **UNITED** - I-ORG
- **NATIONS** - I-ORG
- **.** - O
- **LINDA** - I-PER
- **THOMAS-GREENFIELD** - I-PER

Die Liste zeigt, wie bestimmte Wörter in der CoNLL-2000-Annotation-Guidelines klassifiziert werden. Die Wörter "UNITED" und "NATIONS" werden als "I-ORG" (Internationale Organisation) klassifiziert, während "LINDA" und "THOMAS-GREENFIELD" als "I-PER" (Person) klassifiziert werden. Die Punktzehrung "." wird als "O" (Ohne Kategorie) klassifiziert.

Im oberen linken Bereich des Bildes ist ein Porträt eines Mannes zu sehen, der möglicherweise der Vortragende oder ein Experte ist. Im oberen rechten Bereich ist das Logo der Georgia Tech mit der Abkürzung "GT" zu sehen.

Im oberen Bereich des Bildes steht der Titel "CoNLL++ Dataset" in grünem Text. Im unteren Bereich des Bildes ist eine kurze Beschreibung der Datensatzquelle und der Annotation-Richtlinien: "Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines".</sample>
    <sample id="351">Das Bild ist ein PowerPoint-Präsentationsseite mit dem Titel "CoNLL++ Dataset". Es enthält folgende Informationen:

- **Erstellt**: Reuters-Nachrichten aus dem Jahr 2020 und annotiert mit CoNLL-2003-Anfangsguidelines
- **Fertiggestellt**: 20+ Modelle auf CoNLL-2003 feinabgestimmt
- **Evaluiert**: Auf CoNLL-2003 Testset und CoNLL++

Im unteren Bereich des Bildes ist ein Porträt eines Mannes zu sehen, der mit Brille trägt. Im rechten Untereck ist das Logo von Georgia Tech zu sehen.</sample>
    <sample id="352" />
    <sample id="353">Der Inhalt des Videos ist bereits in Englisch vorhanden und keine Übersetzung erforderlich.</sample>
    <sample id="354">**Was Braucht es für gutes Generalisieren?**

- **Modellarchitektur**
- **Transformer-Modelle generalisieren besser**

**Was Braucht es für gutes Generalieren?**

- **Modell-Architektur**
- **Transformer-Modell generalisieren besser**

**What Is Needed for Good Generalization?**

- **Model architecture**
- **Transformer models generalize better**

**Was Braucht es fü**</sample>
    <sample id="355">**Was ist für gutes Generalisierung notwendig?**

- **Modellarchitektur:** Transformer-Modelle generalisieren besser.
- **Modellgröße:** Größere Modelle generalisieren besser.

**Was ist für gutes Generalisierung nicht notwendig?**

- **Modelleinstellungen:** Die Modellarchitektur und die Größe sind wichtig, aber nicht die Modellinstellungen.
- **Modellgröße ist nicht der einzige Faktor:** Größere Modelle generalisierten besser, aber nicht alle größeren Modelle generalisierten besser.

**Was ist für Gute Generalisierung notwendig?**
- **Modellarchitektur**
- **Transformer-Modelle generalisieren besser**
- **Modellgröße**
- **Größere Modelle generalisieren bess**</sample>
    <sample id="356" />
    <sample id="357">Der Inhalt des Bildes ist ein statisches Bild mit der Überschrift "What Causes Performance Drop?" und einem Logo in der rechten unteren Ecke, das das Georgia Tech Logo enthält.</sample>
    <sample id="358">Was verursacht Leistungsabfall?</sample>
    <sample id="359">Was verursacht Leistungsabfall?</sample>
    <sample id="360">**Was verursacht Leistungsabfall?**  
- **Anpassungsüberempfindlichkeit?**  
- **Temporärer Abstieg?**  

**Was verursacht Leistungsabfälle?**  
- **Anpassungs-Überempfindlichkeit?**</sample>
    <sample id="361" />
    <sample id="362">**Was verursacht Leistungsabfall?**

- **Anpassungsübefitting?**
- **Keine abnehmenden Ergebnisse**
- **Nicht beobachtet**
- **Zeitliche Abhängigkeit?**

**Was verursacht Leistungsabfalle?**

- **Anpassungs-übefitting?**
- **Nicht abnehmende Ergebnisse**
- **Nachweis nicht erfolgt**
- **Zeitliche Abhänigkeit?**

**Was veranlasst Leistungsabfälle?**

- **Anpassungs überfütterung?**
- **Keine abnehmbaren Ergebnisse**
- **Nur beobachtet nicht**
- **Zeitliche Abhängigkeit?**

**Was verhindert die Leistungssteigerung?**

- **Anpassungs übefitting?**
- **Kein abnehmendes Ergebnis**
- **Nur beobachtete nicht**
- **Zeitliche Abhangigkeit?**

**Was verhindernd Leistungsabfälle?**</sample>
    <sample id="363">Title: What Causes Performance Drop?

Bullet Points:
- Adaptive overfitting?
  - No diminishing returns
  - Not observed
- Temporal drift?

Graphs:
The graph on the right shows the performance of different models over time, measured by CoNLL-2003 F1 Score. The x-axis represents the year, and the y-axis represents the F1 score. The different lines represent different models, with the best performing model highlighted in red. The graph shows that the performance of the models has been relatively stable over time, with no significant drops or improvements. The graph on the left shows the performance of different models on a different dataset, with the same axes and lines as the graph on the right. The graph shows that the performance of the different models is similar to the graph on the right, with no significant drops or improvements.</sample>
    <sample id="364">Der englische Text auf der Präsentationsseite lautet:

---

**Was verursacht Leistungsabfall?**

- **Anpassungsübefitting?**
- **Keine abnehmenden Rückgänge**
- **Nicht beobachtet**
- **Zeitliche Drift?**

---

**Tabelle:**

| Name          | CeNLL_2003 | CeNLL+_2003 | ΔF (%) |
|---------------|------------|-------------|--------|
| Plair         | 92.46      | 87.31       | -5.15  |
| Plair+        | 90.91      | 88.46       | -2.49  |
| Pooled Plair  | 92.86      | 89.73       | -3.13  |
| ELM+          | 92.13      | 90.76       | -1.43  |

---

**Diagramm:**

Der Diagramm zeigt die Performance (ΔF) über die Zeit (X-Achse) für verschiedene Modelle. Die Performance verbessert sich über die Zeit, aber es gibt keine abnehmenden Rückgänze.

---

**Zusammenfassung:**

- **Anpassungsübefitung?**
- **Keine abnehmen Rückgänge**
- **Zeitliche Drift**

---

**Translation:**

---

**What Causes Performance Drop?**

- **Adaptive Overfitting?**
- **No diminishing returns**
- **Not observed**
- **Temporal drift?**

---

**Table:**

| Name          | CeN LL_2003 | CeN LL+_2003 | ΔF ( % ) |
|---------------|-------------|--------------|----------|
| Plair         | 9.246       | 8.731        | -5.15    |
| Plair+        | 8.9091      | 8.846        | -2.49    |
| Pooled Plair  | -           | 8.973        | -3.13    |
| ELM+          | 8.9213      | 8.976        | -1.43    |

---

**Diagram:**

The diagram shows the performance (ΔF) over time (X-axis) for different models. The performance improves over time, but there are no diminishing returns.

---

**Summary:**

- **Adaptive Overfitting?**  
- **No diminishing returns**  
- **Temporal drift**  

---

**Note:**

Der Text und die Tabelle sind in englisch, aber die Zusammenfassung und die Diagramme sind in Deutsch.</sample>
    <sample id="365">Was verursacht Leistungsabfall?</sample>
    <sample id="366">**Schlussfolgerung**

*Für eine gute Generalisierung benötigen wir:*

* Bessere Modellarchitektur
* Größere Modellgröße
* Mehr Feinabstimmungsbeispiele

**Graph**

Der Graph zeigt die Entwicklung der Generalisierungsleistung von verschiedenen Modellen über die Jahre. Die Linien repräsentieren verschiedene Modelle:

* **Illinois NER**: Ein Modell, das für die Named Entity Recognition (NER) auf der Illinois-Website verwendet wird.
* **CoNLL-2009**: Ein Modell, das auf dem CoNLL-2009-Korpus trainiert wurde.
* **CoNLL-21**: Ein Modell, das auf dem CoNNLL-21-Korpus trainiert wurde.

Die Linien zeigen, dass die Generalisierungsleistung aller Modelle über die Jahre gestiegen ist. Die CoNLL-21-Modelle zeigen die beste Generalisierungsleistung.

**Georgia Tech**</sample>
    <sample id="367">### Schlussfolgerung

**Für eine gute Generalisierung benötigen wir:**
- Eine bessere Modellarchitektur
- Eine größere Modellgröße
- Mehr feine Tuning Beispiele

**Die Performance-Drop ist durch folgende Faktoren verursacht:**
- Temporale Drift
- Nicht adaptives Overfitting

---

**Graph:**

Der Graph zeigt die Performance von verschiedenen Modellen über die Jahre. Die Linien repräsentieren verschiedene Modelle:

- **Standard ResNet:** Eine basale Modellarchitektur.
- **BlitzNer:** Ein Modell, das speziell für die Textanalyse entwickelt wurde.
- **Flag:** Ein Modell, das speziell auf die Aufgabe angewendet wurde.
- **BERT-Large:** Ein vielseitiges Sprachmodell.
- **LUXE:** Ein neues Modell, das die besten Ergebnisse erzielt hat.

---

**Zusammenfassung:**

Die Schlussfolgerung zeigt, dass die Performance von Modellen über die Jahre verbessert wurde, aber dennoch eine Performance-Drop aufgrund von temporäler Drift und nicht adaptives Overfitting verursacht wird. Um eine gute Generalisierung zu erreichen, benötigen wir eine bessere Modellarchitektur, eine größere Modellgröße und mehr feine Tuning Beispiele.</sample>
    <sample id="368">Die englische Übersetzung des Inhalts lautet:</sample>
    <sample id="369">Die englische Präsentation wird in Deutsch übersetzt:</sample>
    <sample id="370">Der Inhalt des Videos ist ein statiches Bild mit Textinformationen und einem Profilbild. Der Text enthält folgende Informationen:

- **Paper:** https://arxiv.org/abs/2212.09747
- **Dataset:** https://github.com/ShuhengL/ac2023_conllpp
- **Contact:** silu775@gatech.edu

Im Profilbild ist ein Mann mit Brille zu sehen. Die Hintergrundfarbe ist hellgrau, und die Textinformationen sind in schwarz und blau dargestellt. Die Georgia Tech-Logo ist in der rechten unteren Ecke zu sehen.</sample>
    <sample id="397">Die Sprachsegmentgröße bei dem Ansatz beträgt 128 Tokens.</sample>
    <sample id="398">Das entitätsspezifische Wissen, das im Beispiel mit Servin und KeA benötigt wird, ist das Wissen darüber, dass Servin ein Richter ist und KeA ein Bäcker ist.</sample>
    <sample id="399">Der wichtigste Faktor zwischen **der Qualität des Beispiels** und der **Ähnlichkeit mit dem Ausgangssatz** ist die **Qualität des Beispiels**.</sample>
    <sample id="400">Die Arbeiten in den erweitertenen Experimenten konzentrieren sich auf die Sprachmodelle RoBERTa und GPT-2.</sample>
    <sample id="401">Das Modell kombiniert Werte aus mehreren Ebenene bzw. Ebene.</sample>
    <sample id="402">Beispiele für direkte Inferenz sind:

- "Easy on me"
- "The first one"

Diese Beispiele zeigen direkte Referenz, bei denen der Sprecher eine bestimmte Person oder Sache direkt bezieht, ohne sie durch eine indirekte Bezeichnung zu beschreiben.</sample>
    <sample id="403">University of Toronto.</sample>
    <sample id="404">Es sind 5 Autoren an der Arbeit beteiligt.</sample>
    <sample id="405">Nein, die Übersetzung der natürl</sample>
    <sample id="406">Ein Beispiel für eine markierte Gruppe ist "a woman warrior".</sample>
    <sample id="407">Modelle, die nicht Transformer-Architekturen sind, generalisieren nicht gut.</sample>
    <sample id="408">Die Testdatensätze heißen "All labels" und "Weak labels".</sample>
    <sample id="409">Es sind 6 Autoren an der Arbeit beteiligt.</sample>
    <sample id="410">Mit mehreren Modalitäten.</sample>
    <sample id="439">Die Autoren sehen das Verständnis der Präsentationsstruktur und der Zusammenhänge zwischen den Informationen als ein zu wenig erforschtes und interessantes Gebiet im Bereich der natürlichen Sprachverarbeitung (NLU). Sie betonen, dass die Präsentation eine logische und kohärente Struktur hat, die die Informationen auf eine klare und leicht verständliche Weise präsentiert.</sample>
    <sample id="440">Zhiyang Xu, Ying Shen, Lifu Huang.</sample>
    <sample id="441">Ja, Coscript wurde durch eine Qualitätskontrolle geprüft.</sample>
    <sample id="442">Die Grenzen bestehender Ressourcentechniken für kontextbasierte Übersetzungen liegen in der Einschränkung auf korpusbasierte Metriken und die Unfähigkeit, umfangreiche Diskurse zu unterstützen.</sample>
    <sample id="443">Das Bild ist ein Video von Mohammad Javad Hosselini, der sich auf das Thema "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)" konzentriert. Die Bildhintergrund besteht aus einem weißen Hintergrund mit einem farbenfrohen, abstrakten Design, das aus verschiedenen Linien und Kreisen besteht. Der Titel des Vortrags ist "Resolving Indirect Referring Expressions for Entitiy Selection (AltEntities Corpus)" und wird in schwarzer Schrift auf dem weißen Hintergrund angezeigt. Unter dem Titel sind die Namen der vier Autoren aufgeführt: Mohammad Javad Hosselini, Filip Radlinski, Silvia Pareti und Annie Louis. Im unteren Bereich des Bildes ist das Logo von "Google Research" zu sehen. Im rechten unteren Bereich des Bildes ist ein Porträt von Mohammad Javad Hosselini, dessen Name nicht aufgeführt ist.</sample>
    <sample id="444">Das Bild ist ein digitales Screenshot eines Präsentationsfolien, das auf der linken Seite eine weiße Hintergrund mit einem grauen Text "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)" und auf der rechten Seite eine graue Hintergrund mit einem weißen Text "Mohammad Javad Hosselini, Filip Radlinski, Silvia Pareti, and Annie Louis" und einem grünen Text "Google Research".</sample>
    <sample id="445">**Indirekte Bezugnahmen**  
**Ziel:** Verstehen der Nutzersprache, wenn sie eine Wahl treffen  
**Alternative Frage:**  
**Did you mean easy on me or I gotta feeling?**  
**Direkte Bezugnahme:**  
**"easy on me," "the first one"**  
**Indirekte Bezugnahme könnte in natürlicher und flüchtiger Konversation verwendet werden:**  
**Kann den Namen nicht erinnern**  
**Die Aussprache ist schwer zu unterscheiden**  
**Will einen Vorzug spezifizieren**  
**Der neuere One. Der Song, der nicht energisch ist.**</sample>
    <sample id="446">**Indirekte Bezugnahmen**  
**Ziel:** Verstehen, wie Nutzer sprechen, wenn sie eine Wahl treffen.  
**Alternative Frage:**  
**Did you mean easy on me or I gotta feeling?**  
**Direkte Bezugnahme:**  
**"easy on me," "the first one"**  
**Indirekte Bezugnahme könnte in natürlicher und flüchtiger Konversation verwendet werden:**  
**- Kann den Namen nicht erinnern**  
**- Die Aussprache ist schwer zu unterscheiden**  
**- Muss einen Vorzug spezifizieren**  
**Indirekte Bezeichnung:**  
**The newer one. The song that's not energetic.**</sample>
    <sample id="447">**Indirekte Bezugnahmen**  
**Ziel:** Verstehen, wie Nutzer sprechen, wenn sie eine Wahl treffen  
**Alternative Frage:**  
**Did you mean easy on me or I gotta feeling?**  
**Direkte Bezugnahme:**  
- "easy on me," "the first one"  
**Indirekte Bezugnahme:** könnte in natürlicher und flüchtiger Konversation verwendet werden:  
- Kann den Namen nicht erinnern  
- Die Aussprache ist schwer zu unterscheiden  
- Will einen Vorzug spezifizieren  
**Beispiel:**  
**Indirekte Bezungnahme:**  
**The newer one. The song that's not energetic.**</sample>
    <sample id="448">**Indirekte Bezugnahmen**  
**Ziel:** Verstehen, wie Nutzer sprechen, wenn sie eine Wahl treffen.  
**Alternative Frage:**  
**Did you mean easy on me or I gotta feeling?**  
**Direkte Bezugnahme:**  
**"Easy on me," "the first one"**  
**Indirekte Bezugnahme könnte in natürlicher und flüchtiger Konversation verwendet werden:**  
**- Kann den Namen nicht erinnern**  
**- Die Aussprache ist schwer zu unterscheiden**  
**- Möchte einen Vorzug spezifizieren**  
**Der neuere One. Die Song, die nicht energisch ist.**</sample>
    <sample id="449">The video is about understanding users' language when they make a choice. It explains the difference between direct and indirect referring expressions. Direct referring expressions are when you use a specific name or phrase, like "easy on me" or "the first one". Indirect referring expressions are used in natural and fluid conversation when you can't remember the name or the pronunciation is hard to distinguish. The goal is to understand users' language when they make a choice. The video also shows an example of an indirect referring expression, "The newer one. The song that's not energetic."</sample>
    <sample id="450">**Datensatz Sammlung**  
- **Wichtiges Problem:**  
  - Konversationssysteme  
  - Benchmarking großer Sprachmodelle zur Verständnisentwicklung  
- **Keine großskalige öffentlich verfügbare Datenbank verfügbar:**  
  - Sammlung eines großen Datensatzes durch Crowdasnnotation  
- **Drei Bereiche:**  
  - Konzert  
  - Bücher  
  - Schöpfer</sample>
    <sample id="451">**Datensatz Sammeln**  
- **Wichtiges Problem:**  
  - Konversationssysteme  
  - Benchmarking großer Sprachmodelle: Verständnis von Persönlichkeit  
- **Keine großskalige öffentliche Datenbank verfügbar:**  
  - Sammeln eines großen Datensatzes mit Crowd Annotation  
- **Drei Bereiche:**  
  - Konzert  
  - Bücher  
  - Schöpfer</sample>
    <sample id="452">**Datensammlungsmethode**  
*Methodik betont Unterhaltung mit einer Cartoon-Completionsaufgabe*  

**Methodik betont Unterhaltung**  
*Methodik betont Ununterhaltung mit einer Cartoon-Completionssaufgabe*  

**Methodologie betont Unterhaltung**  *Methodologie betont Ununterhaltung mit einer Comic-Completionsaufgabe*</sample>
    <sample id="453">**Datensammlungsmethode**  
*Methodik betont Unterhaltung mit einer Cartoon-Completionsaufgabe*  

**Methodik betont Unterhaltung**  
*Methodik betont Ununterhaltung mit einer Cartoon-Completions-Angelegenheit*  

**Methodik betont Informalität**  
*Methodik betont Informalität mit einer Cartoon-Completionsaufgabe.*  

**Methodik betont Informale**  
*Methodik betont Informale mit einer Cartoon-Completionsaufgabe*.  

**Methodik betont Informelle**  
*Methodik betont Informelle mit einer Cartoon-Completionsaufgabe.  

**Methodik betont Informell**  
*Methodik betont Informell mit einer Cartoon-Completionsaufgabe.**  

**Methodik betont Informel**  
*Methodik betont Informel mit einer Cartoon-Completionsaufgabe**.  

**Methodik betont Informeller**  
*Methodik betont Informeller mit einer Cartoon-Completionsaufgabe**</sample>
    <sample id="454">**Datensatz Sammlungsmethode**  
*Methodik betont informelle Sprache mit einer Cartoon-Completionsaufgabe.*  

**Methodik** betont informelle Sprache mit einer **Cartoon-Completionsaufgabe**.  

**Methodik** betont **informelle Sprache** mit einer **Cartoon-Completionsauftrag**.  

**Methodik** betonen **informelle Sprache** mit einer Cartoon-Completionsaufgabe.  

**Methodik** betont die **informelle Sprache** mit einer Comic-Completionsaufgabe.</sample>
    <sample id="455">**Datensatz Sammlungsmethode**  
*Methodik betont informelle Sprache mit einer Cartoon-Completionsaufgabe.*  

**Methodik betont informelle Sprache**  
*Methode betont informelle Sprache mit einer Comic-Completionsaufgabe.*  
  
**Methodik betont informelle Sprach**  
*Methode betont formelle Sprache mit einer Comic-Completionsaufgabe.*  
  
**Datensatz Sammlungsmethode:**  
*Methodik betont informelle Spr**  
*Methode betont Sprache mit einer Comic-Completions**  
  
**Datensatz Samm**  
*Methodik betont informale Sprache mit einer Comic-Completionsauf**  
  
**Datensatz Samm**  
*Methodik betont informele Sprache met een Comic-Completionsaufg**  
  
**Datensatz**  
*Methodik betont informe Sprache met een Comic-Completions**</sample>
    <sample id="456">**Datensammlungsmethode**  
*Methodik betont Unterhaltung mit einer Cartoon-Completionsaufgabe*  

**Methodik betont Unterhaltung**  
*Methodik betont Ununterhaltung mit einer Cartoon-Completionssaufgabe*  

**Methodologie betont Unterhaltung**</sample>
    <sample id="457">Das Bild zeigt eine Präsentation über die Datensammlungsmethode, die auf die Verwendung einer Cartoon-Completionsaufgabe basiert. Die Methode betont die Informalität und setzt die Dialogkontexte aus, die aus einer Auswahl von manuellen Anweisungen für jeden Benutzer stammen. Die Anweisungen sind: "Erinnere dich daran, dass langsam sprechen und hören lernen" (Set the dialog context), "Was meinen Sie mit 'Einfach auf oder auf'?" (The alternative question), und "Was bedeutet 'Einfach auf oder auf'?" in der Form einer Frage (Expression referring to one of the entities). Die Anweisungen werden von einem Anwender (der durch einen roten Pfeil dargestellt wird) ausgeführt. Die Methode verwendet eine Cartoon-Completionsaufgabe, bei der der Anwender eine ausgewählte Antwort aus einer Liste auswählt. Die Methode betont die Informalitätskontrolle, indem der Anwender die Antworten aus einer Liste auswählt, anstatt die Antworten selbst zu erzeugen. Die Methode verwendet eine Cartoon</sample>
    <sample id="458">Generate alternative questions =&gt; sampling entity pairs  
Do you mean A or B?  
Items with similar infoboxes on Wikipedia (same genre and/or artist)  
Do you mean This is it or Man in the Mirror?  
Items with similar descriptions on Wikipedia  
Do you mean Thinking of You or Happy Anywhere?  
Items with similar titles  
Do you mean The Return (memoir) or The Return (Shatner novel)  
Uniform at random:  
Do you mean You Could Be Mine or The Way I Am</sample>
    <sample id="459">Generate alternative questions =&gt; sampling entity pairs  
Do you mean A or B?  
Items with similar infoboxes on Wikipedia (same genre and/or artist)  
Do you mean This is it or Man in the Mirror?  
Items with similar descriptions on Wikipedia  
Do you mean Thinking of You or Happy Anywhere?  
Items with similar titles  
Do you mean The Return (memoir) or The Return (Shatner novel)  
Uniform at random:  
Do you mean You Could Be Mine or The Way I Am</sample>
    <sample id="460">Der Inhalt des Bildes beschreibt eine Methode zur Generierung alternativer Fragen, um Entitätspaare zu wählen. Es wird auf die Nutzung von Wikipedia als Quelle für ähnliche Infoboxen, Beschreibungen und Titeln verwiesen, um die Wahrscheinlichkeit zu erhöhen, dass die beiden befragten Entitäten in derselben Kategorie oder von derselben Person stammen. Die Methode wird als "Uniform at random" beschrieben, was bedeutet, dass die beiden Entitäten zufällig aus einer größeren Menge ausgewählt werden.</sample>
    <sample id="461">Generate alternative questions =&gt; sampling entity pairs  
Do you mean A or B?  
Items with similar infoboxes on Wikipedia (same genre and/or artist)  
Do you mean This is it or Man in the Mirror?  
Items with similar descriptions on Wikipedia  
Do you mean Thinking of You or Happy Anywhere?  
Items with similar titles  
Do you mean The Return (memoir) or The Return (Shatner novel)  
Uniform at random:  
Do you mean 'Could Be Mine' or 'The Way I Am'</sample>
    <sample id="462">Generate alternative questions =&gt; sampling entity pairs</sample>
    <sample id="463">Hintergrundwissen (Musik)  
Google sucht Links zu jedem Song.  
Easy on Me (von Adele)  
I Gotta Feeling (von The Black Eyed Peas)  
Wir bitten Annotatoren an:  
- Zuhören, bis sie mindestens einige Lieder von jedem Song hören  
- Lesen, was über jedes Lied geschrieben ist</sample>
    <sample id="464">Hintergrundwissen (Musik)  
Google sucht Links zu jedem Song.  
Einfach mit (von Adele)  
Ich habe ein Gefühl (von The Black Eyed Peas)  
Wir bitten Annotatoren an:  
- Mindestens einige Songs zu hören  
- Über jeden Song zu lesen</sample>
    <sample id="465">Hier ist die Übersetzung des englischen Inhalts in Deutsch:</sample>
    <sample id="466" />
    <sample id="467">Der Inhalt des Bildes beschreibt ein Angebot von Google Research, bei dem Annotatoren beauftragt werden, Ausdrucksformen für ein bestimmtes Lied auszuwählen und zu beschreiben. Die Anleitung beginnt mit der Anfrage, welche Ausdrucksform für das Lied "Easy on Me" (von Adele) ausgewählt werden soll. Anschließend wird die Anleitung erweitert, um auch die Ausdrucksform für das Lied "(I Gotta Feeling) von Black Eyed Peas" zu bestimmen. Die Anleitung schlägt vor, 3 bis 5 Ausdrucksformen für das Lied auszuwählen, die in den Sprechblasen des Anwenders gefüllt werden sollen. Die Beispiele für Ausdrucksformen sind "The one with the piano music" (Der mit dem Pianofortebegriff), "The song that's not energetic" (Das Lied, das keine Energie hat), "I'm listening to a song" (Ich höre eine Lied), "The song is about" (Das Lied geht über), "The song is about not having time to choose" (Das Lied geht über das Thema, dass man keine Zeit hat, zu wählen), "The song is about not having time" (Das Lied geht über das</sample>
    <sample id="468" />
    <sample id="469">**AltEntities Corpus**  
- **6,000 alternative questions across three domains**  
- **42,000 indirect referring expressions**  

**Results with T5 XL model (accuracy):**  
- 92-95% if the LM has access to the same background knowledge as annotators.  
- 82-87% if the LM has access to partially overlapping background knowledge.  
- 60% if the LM has only access to the entity names.  

**We showed models are domain-generalizable.**  

**Dataset Link:** [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)</sample>
    <sample id="470">**AltEntities Corpus**  
- **6.000 alternative questions** across three domains  
- **42.000 indirect referring expressions**  

**Results with T5 XL model (accuracy):**  
- 92-95% if the LM has access to the same background knowledge as annotators.  
- 82-87% if the LM has access to partially overlapping background knowledge.  
- 60% if the LM has only access to the entity names.  

**We showed models are domain-generalizable.**  

**Dataset Link:** [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)</sample>
    <sample id="471">**AltEntities Corpus**  
- **6,000 alternative questions** across three domains  
- **42,000 indirect referring expressions**  

**Results with T5 XL model (accuracy):**  
- 92-95% if the LM has access to the same background knowledge as annotators.  
- 82-87% if the LM has access to partially overlapping background knowledge.  
- 60% if the LM has only access to the entity names.  

**We showed models are domain-generalizable.**  

**Dataset Link:** [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/)  

---  

**Google Research**  

---  

**AltEntities Corpus**  
- **4,000 alternative questions** across three different domains  
- **42,010 indirect referring expressions**  

**Ergebnisse mit dem T5 XL Modell (Genauigkeit):**  
- 92-85% wenn der LM Zugang zu gleichem Hintergrundwissen wie die Annotatoren hat.  
- 82-88% wenn der LM Zugang zu teilweise überlappendem Hintergrundwissen hat.  
- 60% wenn der LM nur Zugang zu den Entitätsnamen hat.  

**Wir zeigten, dass Modelle generalisierbar sind.**  

**Datensatz Link:** [https://github.com/google-re</sample>
    <sample id="472">**AltEntities Corpus**  
- 6.000 alternative Fragen über die drei Domänen  
- 42.000 indirekte Bezugsausdrücke  

**Ergebnisse mit T5 XL Modell (Genauigkeit):**  
- 92-95% wenn das Modell auf gleichem Hintergrundwissen wie Annotatoren zugreifen kann  
- 82-87% wenn das Modell auf teilweise überlappendes Hintergrundwissen zugreifen kann  
- 60% wenn das Modell nur auf die Entitätsnamen zugreifen kann  

**Wir zeigten, dass Modelle domänenübergreifend funktionieren.**  

**Datensatz Link:** [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)</sample>
    <sample id="473">Mit den bestehenden SimulST-Richtlines "walk-k", "LA", "CAAT" und "EDAtt".</sample>
    <sample id="474">Université de Nantes</sample>
    <sample id="475">Maarten Sap</sample>
    <sample id="476">Drei Autoren sind an der Arbeit beteilt.</sample>
    <sample id="477">Attention as a Guide for Simultaneous Speech Translation</sample>
    <sample id="478">Simultaneous speech translation (SimulST) is the process of translating spoken language into a text in another language in real-time, enabling cross-language communication.</sample>
    <sample id="479">Die englische Übersetzung des Inhalts lautet:

"What are the problems of the current SimuIST models?"

"Specific architectures are usually trained, introducing additional modules to be optimized."</sample>
    <sample id="480">Welche Probleme haben die aktuellen SimuUST-Modelle?</sample>
    <sample id="481">Welche Probleme haben die aktuellen SimulST-Modelle?</sample>
    <sample id="482">Der englische Text in der Bildunterschrift lautet: "What is our solution?"

Übersetzt ins Deutsche: "Was ist unsere Lösung?"</sample>
    <sample id="483">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Was ist unsere Lösung?**

**01** Verwenden Sie bereits bestehende Offline ST-Modelle ohne erneutes Training oder spezifische Architektur für SimuST.

**02** Verwenden Sie nur ein Modell für jeden Latenzbereich und verwalten Sie Latenz durch spezifische Parameter.

---

**Was ist unserer Lösung?**

**03** Verwenden Sie bereits bestehtende Offline ST-Modelle ohne erneut Training oder spezifische Architekturfür SimuST.

**04** Verwenden Sie nur ein Modell pro Latenzbereich und verwalten Latenz durch spezifische Parameter.</sample>
    <sample id="484">Die englische Beschreibung des Inhalts des Bildes lautet:

---

**Was ist unsere Lösung?**

1. **Verwenden Sie bereits bestehende Offline-ST-Modelle ohne Neuausrichtung oder Anpassung spezifischer Architektur für SimuST**
2. **Verwenden Sie nur ein Modell für jeden Latenzbereich und verwalten Sie Latenz durch die Aufmerksamkeit des Modells zwischen Audio-Eingabe und Textausgabe**
3. **Nutzen Sie das bereits erworbene Wissen durch das Modell durch die Aufmerksamkeitmechanismus zwischen Audio-Eingabe und Textaus</sample>
    <sample id="485">Die Übersetzung des englischen Inhalts in Deutsch lautet:

"Unser Lösung: EDAtt

Encoder-Decoder

Attention

Entscheiden Sie, ob Sie eine Teilübersetzung abgeben oder nicht, basierend auf, wo die Aufmerksamkeit zeigt. Ein Wort wird abgegeben, wenn die Aufmerksamkeit nicht konzentriert ist, wenn die Aufmerksamkeit auf eine bestimmte Richtung zeigt, d.h. wenn die Aufmerksamkeit auf die letzten 2 Sprachrahmen zeigt, was bedeutet, dass die empfangenen Informationen genügend stabil sind."</sample>
    <sample id="486">Die Übersetzung des englischen Inhalts in deutsche Sprache lautet:

---

**Lösung: EDAtt**

**Encoder-Decoder Attention**

---

**Entscheidung, ob ein Teil der Übersetzung abgegeben oder nicht**

Entscheidet, ob ein Wort abgegeben wird, wenn die Aufmerksamkeit nicht konzentriert ist, wenn die Aufmerksamkeit nicht in einem konkreten Wort konzentriert ist. Wenn die Aufmerksamkeit nicht in einem einzelnen Wort konzentriert ist, bedeutet das, dass die letzten 2 Sprachrahmen (Sprachrahmen) genügen, um die erhaltene Information zu verstehen.

---

**Übersetzung:**

---

**Lösung:** EDAtt

**Encoder-Decoder Attention**  

---

**Entscheiden, ob ein Teil der Übersetzungen abgegeben oder nicht**

Bestimmt, ob ein Wort abgegeben werden sollte, wenn die Aufmerksamkeit nicht auf ein bestimmtes Wort konzentriert ist. Das bedeutet, wenn die Aufmerksamkeit nicht im letzten 2 Sprachrahmen konzentriert ist, dann ist die erhaltene Information ausreichend.

---

**Übersetzt:**

---

**Lösungs:** EDAtt

**Encoder-Decodier Attention**  

---

**Bestimmen, ob ein Teil der Übersetzungs abgegeben oder nicht**

Beschließt, ob ein Wort abgegeben sollte, wenn die Aufmerksamkeitskonzentration nicht auf ein bestimmtes Wort konsolidiert ist. Wenn die Aufmerksamkeitskonz</sample>
    <sample id="487">Die Übersetzung des englischen Textes lautet:

"Entscheide, ob du eine Teilübersetzung ablehnen oder nicht, basierend auf, wo die Aufmerksamkeit zeigt: Wenn die Aufmerksamkeit nicht konzentriert ist, wenn die Aufmerksamkeit nicht konzentiert ist, wenn die Aufmerksamkeitskonzentration nicht konzentriert ist, wenn das letzte Sprachmodell, das die empfangenen Informationen genügt, bedeutet, dass die empfangenen Informationen genügen."</sample>
    <sample id="488">Die Übersetzung des englischen Textes lautet: "Entscheide, ob du eine Teilübersetzung ablehnen oder nicht, basierend auf der Position, an der die Aufmerksamkeit entsteht, wenn die Aufmerksamkeit nicht konzentriert ist. Wenn die Aufmerksamkeit nicht konz</sample>
    <sample id="489">Unser Lösung: EDAtt  
Encoder-Decoder Attention  

Entscheide, ob du einen Teil der Übersetzung ablehnen oder nicht, basierend auf, wo die Aufmerksamkeit zeigt. Ein Wort wird abgelehnt, wenn die Aufmerksamkeit nicht konzentriert ist, wenn die Aufmerksamkeit nicht in einem konkreten Verhältnis zum letzten Sprachrahmen steht, was bedeutet, dass die empfangene Information genügend ist.</sample>
    <sample id="490">Unser Lösung: EDAtt  
**Encoder-Decoder Attention**  

**Decide whether to emit or not a partial translation based on where attention points to:**  
a word is emitted if the attention is not concentrated (Its sum is below a threshold a) towards the last λ speech frames, meaning that the received information is enough stable.  

**01 I am going to talk about...**  
Ich werde reden.  

**EMITTED**</sample>
    <sample id="491">Die Übersetzung des englischen Textes in Deutsch lautet:

---

**Unser Lösung: EDAtt**

**Encoder-Decoder Attention**

**Entscheide, ob du eine Teilübersetzung ablehnen oder nicht, basierend auf, wo die Aufmerksamkeit zeigt: Wenn ein Wort ausgesprochen wird, wenn die Aufmerksamkeit nicht konzentriert ist und sich nicht auf die letzten Sprachrahmen hin bewegt, d.h. die empfangene Information ist genug um die Sprache zu verstehen.**

---</sample>
    <sample id="492">Die Übersetzung des englischen Inhalts in Deutsch lautet:</sample>
    <sample id="493">Unser Lösung: EDAtt Encoder-Decoder Attention  
Entscheide, ob ein Wort übersetzt oder teilweise übersetzt werden soll, basierend auf der Konzentration des Aufmerksamkeitspunktes auf den letzten Sprachrahmen. Das bedeutet, dass die Aufmerksamkeit nicht auf eine konkrete Sprache konzentriert ist, was bedeutet, dass die empfangenen Informationen in der letzten Sprachrahmen ausreichend sind.  
  
1. Ich gehe zu sprechen über...  
2. Ich gehe zu sprechen über Klima.</sample>
    <sample id="494">Die englische Inhaltsbeschreibung lautet: "Our solution: EDAtt Encoder-Decoder Attention Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold) towards the last λ speech frames, meaning that the received information is enough stable."</sample>
    <sample id="495">Der englische Text auf der Bildschirmhauptanzeige lautet:

**Main Results: EDAtt**

Die graphische Darstellung zeigt die Beziehung zwischen dem **AL / AL_CA (s)** und dem **BLEU**. Die X-Achse repräsentiert den Wert **AL / AL_CA (s)**, während die Y-Achse den **BLEU**-Wert darstellt. Die Datenpunkte sind auf einer Linie angeordnet, die sich allmählich erhöht, was auf eine positive Korrelation zwischen den beiden Variablen hinweist.

Die Beschriftung auf der Y-Achse lautet **BLEU**, was steht für **Bilingual Evaluation Understudy**. Dies ist ein Maß für die Qualität von maschinellem Übersetzen, das auf der Übereinstimmung zwischen dem automatisch übersetzten Text und einem menschlich übersetzten Referenztext basiert.

Die Beschriftung auf den X-Achsenlabeln lautet **AL / AL_CA (s)**, was möglicherweise auf eine Messung oder eine Variable in Sekunden (s) bezogen ist.

Die Tabelle in der linken unteren Ecke enthält die folgenden Informationen:

- **Page 028**: Dies zeigt, dass der Inhalt auf Seite 28 des Dokuments oder der Präsentation angezeigt wird.

Die Tabelle in der rechten unteren Ecke enthält die Folgenden Informationen:

- **EDAtt**: Dies ist möglicherweise ein Akronym oder ein spezifisches Modell oder Verfahren, das in der Präsentation besprochen wird.

Die Tabelle in der linkeren unteren Ecke enthält die **EDAtt**-Informationen.

Die Tabelle in der reichen unteren Ecke enthält die EDAtt-Informationen.

Die Tabelle enthält die EDAtt-Information.

Die Tabelle enthä</sample>
    <sample id="496">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Haupt-Ergebnisse: EDAtt**

---

**EDAtt**

---

**Haupt Ergebnisse: EDAtt**

**EDAtt**

---</sample>
    <sample id="497">Die englische Beschriftung auf dem Diagramm lautet "Main Results: EDAtt".</sample>
    <sample id="498">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Haupt-Ergebnisse: EDAtt**

**EDAtt**

---

**Haupt Ergebnisse: EDAtt**

---

**Häufigkeiten der Wörter in der Textdatenbank**

---

**Häuflichkeit der Wörter in der Textdatenbase**

---

**Häuptlichkeit der Wörter in der Textdatsbank**

---

**Haufigkeit der Wörter in der Textdatabse**

---

**Häupfigkeit der Wörter in der Textdabse**

---

**Main Results: EDAtt**

---</sample>
    <sample id="499">Die englische Beschriftung auf dem Diagramm lautet "Main Results: EDAtt".</sample>
    <sample id="500">Die englische Beschriftung auf dem Diagramm lautet "Main Results: EDAtt".</sample>
    <sample id="501">Die englische Beschriftung auf dem Diagramm lautet "Main Results: EDAtt".</sample>
    <sample id="502">Die englische Beschriftung auf dem Diagramm lautet "Main Results: EDAtt".</sample>
    <sample id="503">Die englische Beschreibung des Inhalts des Bildes lautet:

---

**Main Results: EDAtt**

Die grafische Darstellung zeigt die Ergebnisse von EDAtt im Vergleich zu anderen Strategien wie wait-k, LA, CAAT und EDAtt. Die x-Achse repräsentiert die Anzahl der Iterationen, während die y-Achse die Anzahl der erreichten EU (Einheiten) zeigt. Die verschiedenen Farben der Linien entsprechen den unterschiedlichen Strategien.

- **wait-k**: Diese Strategie zeigt eine langsamere Erhöhung der EU mit zunehmender Anzahl der Iterationen.
- **LA**: Diese Strategie erreicht eine höhere Anzahl der EU als wait-k, aber nicht so hoch wie CAAT.
- **CAAT**: Diese Strategie erreicht die höchste Anzahl der EU, insbesondere in den frühen Iterationen.
- **EDAtt**: Diese Strategie zeigt eine schnelle Erhöhung der EU, insbesondere in den Anfangsphasen, und erreicht die höchste Anwendung der EU.

Die grafische Darstellungen zeigen, dass EDAtt die schnellste Strategie ist, wenn man die tatsächliche vergangene Zeit berücksichtigt.

---

**Übersetzung:**

---

**Hauptergebnisse: EDAtt**

Die grafischen Darstellungen zeigen die Ergebnisse von EDAtt im Vergleich zu anderen Strategien wie wait-k (wart-k), LA (Last-Average), CAAT (Cumulative Average Time) und EDAtt selbst. Die x-Achse repräsentierte die Anzahl der Iterationen, die y-Achse die Anzahl erreichten EU (Einheit) zeigte. Die verschiedenen Farben der Liniensetzungen entsprechen den unterschiedlichsten Strategien.

- **wait-k (wart-k):** Diese Strategie zeigt eine langsame Erhöhung der EU mit zunächst zunehmender Anzahl der Iterations.
- **LA (Last-Average):** Diese Strategie erreicht eine h</sample>
    <sample id="504">Wenn Sie mehr entdecken möchten, lesen Sie unseren Paper.</sample>
    <sample id="505">Yes, the dataset is publicly accessible.</sample>
    <sample id="506">Das Bild ist ein statisches Poster oder eine Präsentationsseite, die die folgenden Informationen enthält:

- **Titel:** "MULTIINSTRUCT: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning"
- **Autoren:** Zhiyang Xu*, Ying Shen*, Lifu Huang
- **Institution:** Department of Computer Science, Virginia Tech
- **Logo:** VT (Virginia Tech) in der oberen rechten Ecke
- **Bilder:** Vier Personen, die als Autoren gekennzeichnet sind, mit einem Stern (*) neben ihren Namen, was auf eine Gleichberechtigung hinweist.
- **Note:** "Equal Contribution" (gleiche Beitragsverteilung) in der unteren linken Ecke.

Das Bild dient als Titelbild für eine Präsentation oder Publikation über die Arbeit "MULTIINSTRUCT: Improving Multi- Modal Zero-Shot Learning via Instruction Tuning".</sample>
    <sample id="507">Die Präsentation beschäftigt sich mit der Verwendung von vorgeübten Sprachmodellen für die Ausführung von Downstream-Aufgaben. Es wird dargestellt, wie verschiedene Methoden wie Prä-Training, Fürstuning und Prompting verwendet werden, um die Leistung dieser Modelle zu verbessern. Die Prä-Training-Techniken, wie BERT und T5, erfordern viel Rechenleistung und sind typischerweise für viele Aufgaben vorgebucht. Fürstuning nutzt die Prä-Training-Modelle, um die Leistung auf spezifische Aufgaben zu verbessern, indem es die Modelle mit den Aufgaben trainiert. Prompting, wie GPT-3, nutzt eine vorgebuchte Sprachmodell-Architektur, um die Leistung auf spezielle Aufgaben zu verbessern, indems es die Modelle mit den Aufgaben vorbereitet. Instruction Tuning, wie FLAN, nutzt die Prä-Training-Model</sample>
    <sample id="508">Der englische Text beschreibt verschiedene Methoden zur Anpassung von vorgeübten Sprachmodellen auf spezifische Aufgaben. Es wird erwähnt, dass die Anpassung durch verschiedene Techniken erfolgen kann, wie zum Beispiel die Feinabstimmung (Fine-tuning) mit bekannten Modellen wie BERT und T5, die Anleitungstuning (Instruction Tuning) mit dem Modell FLAN und die Anweisungsprompting (Prompting) mit dem Modell GPT-3. Die Anpassung erfolgt durch die Verwendung von Texten, die die gewünschte Aufgabe beschreiben, um das Modell zu trainieren. Die Anweisungsprompting nutzt die Fähigkeit des Modells, auf Texte zu reagieren, die Anweisungen enthalten, um die gewünschte Aufgabe zu erf</sample>
    <sample id="509">The text on the screen reads "Language-only."</sample>
    <sample id="510">Instruction Tuning on Multimodal Pre-trained Models</sample>
    <sample id="511">Die Übersetzung des englischen Inhalts in Deutsch lautet:

**"Imbalance in Instructional Datasets between NLP and Multimodal"**

**Übersetzung:**

**"Imbalance in Instructional Data Sets zwischen NLP und Multimodal"**

**Erklärung:**

- **NLP:** Natural Language Processing (natürliche Sprachverarbeitung)
- **Multimodal:** Mehrmodal (mehrere Modalitäten oder Formen, z.B. Text, Bild, Video)

**Hinweis:**

- Die Übersetzung behält den technischen Kontext bei und ist für eine technische oder wissenschaftliche Audience geeignet.</sample>
    <sample id="512">Die Übersetzung des englischen Inhalts in Deutsch lautet:

**Unausgewogenheit in Anweisungsdatensätzen zwischen NLP und Multimodal**

**1600+ sprachbasierte Anweisungsaufgaben**

**Keine großskaligen, öffentlich zugänglichen multimodalen Anweisungsaufgaben**</sample>
    <sample id="513">Das Video ist ein statischer Screenshot einer Präsentation über das "MULTIMODUL INSTRUCTION TUNING BENCHMARK DATASET". Es enthält keine Bewegungen oder Gespräche.</sample>
    <sample id="514">Das Video ist ein statischer Screenshot einer Präsentation über das "MULTIMODINST" (Multimodal Instruction Tuning Benchmark Dataset). Es enthält keine Bewegungen oder Gespräche. Hier ist eine detaillierte Übersetzung des Inhalts:

---

### **MULTIMODINST**

**The first multimodal instruction tuning benchmark dataset**

- **62 diverse multimodal tasks**
- **10 broad groups**
- **5 expert-written instructions**

---

### **Figure 2: Tasks Groups Included in MULTIMODINST**

**Visual Reasoning**
- **Visual Question Answering (VQA)**
- **Visual Entailment**
- **Visual Commonsense Reasoning (VCR)**
- **Visual Commonsense Question Answering (VCQA)**
- **Visual Commonsense Reasoning (V-CRE)**
- **Visual Commonsense Question Anwering (VCQA)**
- **Visual Common Sense Question Answering (VCQA)**

**Natural Language Understanding**
- **Textual Entailment**
- **Textual Entailment (TE)**
- **Textual Entailment (TTE)**
- **Textual Entail</sample>
    <sample id="515">Der englische Text beschreibt die Funktionsweise und die Merkmale des Modells "OFA (One For All)". Es ist ein vielseitiges, vorausschauendes Modell, das sowohl Verständnis als auch Generierung von Aufgaben mit ein- oder mehreren Modalitäten durchführen kann. Das Modell verfügt über einen "einheitlichen Wortschatz", der für Sprache, Bildmerkmale und die Koordinaten eines Bounding Boxes verwendet wird.</sample>
    <sample id="516">Das Video zeigt eine Vorstellung von "MULTINSTUCT", eine neuen Datenbank, die vier verschiedene Aufgaben umfasst: Grounded Captioning, Text Localization, Referring Expression Selection und Question-Image Matching. Jede Aufgabe wird mit einem Beispielbild und einer entsprechenden Beschreibung dargestellt.</sample>
    <sample id="517">Das Video zeigt eine Vorstellung von "MULTINSTUCT", einem Framework, das vier verschiedene Aufgaben zur Bildverarbeitung und -analyse umfasst. Die vier Aufgaben sind: Grounded Captioning, Text Localization, Referring Expression Selection und Question-Image Matching. Jede Aufgabe wird mit einem Beispielbild und einer entsprechenden Beschreibung und Analyse dargestellt.</sample>
    <sample id="518">Das Video präsentiert eine Vorstellung von vier verschiedenen Aufgaben, die in einem Multi-Instruktionsmodell verwendet werden. Die Aufgaben sind:</sample>
    <sample id="519">**Title:** Multi-modal Instruction Tuning  
**Speaker:** [Name]  
**Affiliation:** [Institution]  
**Topic:** Multi-modal Instruction Tuning  
**Abstract:**  
In this presentation, we introduce a novel approach to multi-modal instruction tuning, which leverages the strengths of both textual and visual modalities to improve the performance of language models. Our method involves fine-tuning a pre-trained language model on a large-scale dataset of multi-modal instructions, where each instruction is accompanied by a corresponding image. We demonstrate that our approach significantly outperforms existing methods on a variety of downstream tasks, including image captioning, visual question answering, and multi-modal retrieval. Our results suggest that multi-modal instruction tuning is a promising direction for improving the performance of language models on complex, real-world tasks.</sample>
    <sample id="520">Das Video beschreibt die Konstruktion von Trainings- und Testdatensätzen für eine Multi-Modal Instruction Turning-Anwendung. Die Trainingsdatensätze bestehen aus 53 Aufgaben aus 9 Gruppen, wobei 10.000 Instanzen pro Aufgabe ausgewählt werden. Die Testdatensätze bestehen aus dem gesamten Commonsense Reasoning-Gruppentest, ausgewählten zusätzlichen 5 Aufgaben aus VQA und Miscellaneous-Gruppen sowie aus zufällig ausgewählten 20 Instanzen aus dem Natural Instructions-Datensatz, die als ungesehene Aufgaben für NLP verwendet werden.</sample>
    <sample id="521">Das Video beschreibt die Konstruktion von Trainings- und Testdatensätzen für ein Multi-Modal Instruction Turning-System. Im Training-Datensatz werden 53 Aufgaben aus 9 Gruppen verwendet und 10.000 Instanzen pro Aufgabe abgezogen. Im Testdatensatz wird die gesamte Commonsense Reasoning-Gruppe reserviert, zusätzliche 5 Aufgaben aus VQA und Miscellaneous-Gruppen ausgewählt und alle Instanzen aus dem Testteil für jede Aufgabe verwendet. Zufällig werden 20 Instanzen aus dem Natural Instructions-Datensatz als unbekannte Aufgaben für NLP verwendet.</sample>
    <sample id="522">Implementation Details:

Training details:
- Pre-trained OFA-Large model (472M)
- Mix all the instances for all tasks.
- Each instance is randomly combined with one of five instruction templates.

Testing details:
- For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
- We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="523">Implementation Details:

Training details:
- Pre-trained OFA-Large model (472M)
- Mix all the instances for all tasks.
- Each instance is randomly combined with one of five instruction templates.

Testing details:
- For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
- We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="524">Implementation Details:

Training details:
- Pre-trained OFA-Large model (472M)
- Mix all the instances for all tasks.
- Each instance is randomly combined with one of five instruction templates.

Testing details:
- For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
- We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="525">Evaluation Metrics:

- For multi-modal classification tasks (Visual Entailment, Visual Spatial Reasoning, Natural Language Visual Reasoning, and Disaster Type Classification), we report the Accuracy.
- For multi-modal generation tasks (Commonsense VQA, Text VQA, Grounded VQA, Visual Text Extraction, and Visual Dialogue), we report the Rouge-L.
- We also compute the aggregated performance for each model based on the mean of the model's performance on all multimodal and NLP unseen tasks. We use Rouge-L as the performance score for most tasks, and Accuracy that only have accuracy as a metric.</sample>
    <sample id="526">Das Video beginnt mit einer Präsentation über die Sensitivität von Modellen in Bezug auf die Variabilität von Anweisungen für dieselbe Aufgabe. Der Präsentierte erklärt, wie wichtig es ist, dass ein Modell konsistente Ergebnisse für die gleiche Aufgabe erzielt, unabhängig von leichten Variationen in der Wortwahl der Anweisungen. Er zeigt eine mathematische Formel, die die Sensitivität eines Modells beschreibt, und erklärt, wie das Modell auf unterschiedliche Anweisungen reagiert. Der Präsentierte betont, dass es wichtig ist, dass ein Modell konsistent die gleichen Ergebnisse für die gleiche Auf gabe erzielt, unabhängi von leichten Variationen in der Wortschreibung der Anweisungen. Er zeigt ein Beispiel, wie ein Modell auf unterschiedliche An weisungen reagiert, und betont, dass es wichtig ist. Der Präsentierte zeigt eine Tabelle mit den Ergebnissen von verschiedenen Modellen auf verschiedenen Aufgaben und betont, dass es wichtig</sample>
    <sample id="527">The video presents a detailed analysis of the effectiveness of instruction tuning on a multi-instruct model, focusing on its performance across various tasks. The presenter, a man with glasses and short hair, is seen speaking directly to the camera, providing insights into the model's capabilities. The background features a large table with data on the model's performance in different areas, including zero-shot performance on multi-commonsense reasoning, visual entailment, visual spatial reasoning, and NLU tasks. The table highlights the model's strengths and weaknesses, with the best performance consistently shown in the bottom right corner. The presenter emphasizes the model's ability to perform well across a range of tasks, despite its limitations in certain areas. The video concludes with a summary of the key findings and a call to action for further research and development in this area.</sample>
    <sample id="528">The video presents a detailed analysis of the effectiveness of instruction tuning on a multi-instruct model, focusing on its performance across various tasks. The presenter, a man with glasses and short hair, is seen speaking in front of a large screen displaying a table with performance metrics. The table is divided into two sections: "Table 1: Zero-shot Performance on Multimodal Commonsense Reasoning" and "Table 2: Zero-shot Performance on Question Answering and Miscellaneous." Each section contains multiple rows and columns, with the rows representing different models and the columns showing various performance metrics such as "Mean," "Std," "Min," and "Max." The models listed include "OFA," "OFA-1.4B," "OFA-1.4B-1.5B," "OFA-1.4G," "OFA-1.4G-1.5G," "OFA-1.4H," "OFA-1.4H-1.5H," "OFA-1.4J," "OFA-1.4J-1.5J," "OFA-1.4K," "OFA-1.4K-1.5K," "OFA-1.4L," "OFA-1.4L-1.5L," "OFA-1.4M," "OFA-1.4M-1.5M," "OFA-1.4N," "OFA-1.4N-1.5N," "OFA-1.4O," "OFA-1.4O-1.5O," "OFA-1</sample>
    <sample id="529">Der Inhalt des Videos ist in Deutsch übersetzt.</sample>
    <sample id="530">Der englische Text beschreibt die Auswirkungen der Anzahl von Anweisungen auf die Leistung von Instruction Tuning. Es wird hervorgehoben, dass die Anpassung von Instruction Tuning mit fünf Anweisungen eine höhere aggregierte Leistung auf allen Evaluationsaufgaben erzielt und weniger empfindlich auf die Anzahl der Anweisungen reagiert. Die Tabelle zeigt die Aggregierte Leistung und die Sensitivität für verschiedene Anzahlen von Anweisungen.</sample>
    <sample id="531">The video presents a detailed analysis of the impact of fine-tuning strategies on model sensitivity, specifically focusing on the effects of instruction tuning on Multitask and transfer learning from the Natural Instructions dataset. The presenter, a man with glasses and short hair, is seen speaking in front of a black background with a white text box containing key points and a bar chart. The bar chart, titled "Figure 4: Model Sensitivity on Unseen Evaluation Tasks. Lower is better," illustrates the sensitivity of different models to unseen evaluation tasks. The chart shows four bars representing different models: Multitask, Instruction Tuning, Transfer Learning, and Natural Instructions. The sensitivity values for each model are displayed on the y-axis, ranging from 0 to 40.58. The presenter explains that instruction tuning on Multitask can significantly reduce the sensitivity of OFA, while transfer learning from the Natural Instructions dataset can further reduce the sensitivity of the model. The presenter emphasizes the importance of these fine-tuning strategies in improving the robustness and reliability of machine learning models. The video concludes with a call to action, encouraging viewers to explore the full paper for more detailed information and insights.</sample>
    <sample id="532">Zero-Shot Performance on NLP Tasks

- Instruction Tuning on Multilnstruct can improve zero-shot performance on unseen NLP tasks.
- The transfer learning strategy Mixedlnstruct can best preserve the zero-shot capability gained on Natural Instructions dataset.

Table 1. Zero-shot Performance on NLP tasks. The performance is reported in Rouge-1 and the best performance is in bold.

| Model | Transfer Learning from Natural Instructions |
|-------|---------------------------------------------|
| OPAs  | 12.18                                       |
| OPAs  | 121.25                                      |
| OPAs  | 43.61                                       |
| OPAs  | 47.97                                       |</sample>
    <sample id="533">Die Übersetzung des englischen Inhalts in Deutsch lautet:

**Schlussfolgerung**

- Erstes großskaliges multi-modales Anweisungstuning-Datenset.
- Enthält 62 multi-modale Aufgaben aus 10 breiten Kategorien.
- Verbessert die Null-Shot-Fähigkeit von OFA durch Anweisungstuning signifikant.
- Erforschen Sie mehrere transferierende Lernverfahren und zeigen Sie deren Vorteile.
- Entwerfen Sie ein neues Metrik-Sensitivitätsmaß.</sample>
    <sample id="534">Eine größere Multimodal-Anweisungstuning-Datensatz wird gesammelt.</sample>
    <sample id="535">Universität di Trento</sample>
    <sample id="536">Die Referent*in ist Mohammad Javad Hosselini.</sample>
    <sample id="562">Die Sprachkontexte sind nicht immer robust für Sprachmodell-Akzeptabilitätsurteile.</sample>
    <sample id="563">Die Sprache ist grundlegend für die Kommunikation und die Ausdrucksfähigkeit. Sie ermöglicht es uns, unsere Gedanken und Ideen auszudrücken und andere mitzuteilen. Die Sprache ist ein wichtiger Bestandteil des menschlichen Denkens und der Kultur. Sie ist ein wichtiger Bestandteil der Identität und der Kultur. Sie ist ein unverzichtbarer Bestandteil des menschlichen Lebens und der Kultur. Sie ist unverzichtbar für die Kommunikation und die Ausdrücklichkeit. Sie ist unverzichtbar für das Verständnis und die Kommunikation. Sie ist unverzichtbar für den Austausch von Ideen und Informationen. Sie ist unverzichtbar für eine gute Kommunikation und die Ausdrücken von Gedanken und Ideen. Sie ist unverzichtbar und unverzichtbar für die Kommun</sample>
    <sample id="564">Das Bild ist ein digitales Diagramm, das das Minimal Pair Paradigma (MPP) erklärt. Es zeigt drei verschiedene Sprachmodelle: BLIMP, SyntaxGym und CrowS. Jeder Modell wird mit zwei Beispielen dargestellt, um die Abhängigkeit von der Reihenfolge von Wörtern zu zeigen. BLIMP zeigt, dass die Reihenfolge von Wörtern "Many people were helping themselves" und "Many people were helping here" unterschiedlich ist. SyntaxGym zeigt, dass die Reihenfolgen von Wörtern "No customer has spent any money" und "The customer has spent any money" unterschiedlich ist. CrowS zeigt, dass die Reihenfolges der Wörter "Stereotypical sentence" und "Non-stereotypical sentence" unterschiedlich ist.</sample>
    <sample id="565">Revisiting Minimal Pair Paradigm</sample>
    <sample id="566">Revisiting Minimal Pair Paradigm</sample>
    <sample id="567">Revisiting Minimal Pair Paradigm</sample>
    <sample id="568" />
    <sample id="569" />
    <sample id="570" />
    <sample id="571" />
    <sample id="572" />
    <sample id="573" />
    <sample id="574" />
    <sample id="575" />
    <sample id="576" />
    <sample id="577" />
    <sample id="578" />
    <sample id="579" />
    <sample id="580" />
    <sample id="581">**Übersetzung des englischen Inhalts:**

---

**MMP-Beurteilungen sind robust gegenüber willkürlichen Kontextlängen**

Wir führen MPP-Evaluierungen mit unterschiedlichen Kontexten durch – akzeptabel/unakzeptabel; gepaart/unverpaart Struktur – von Längen bis zu 900 Tokens.

---

**Übersetzung des Textes:**

---

**MMP-Bewertungen sind robust gegenüber willkürlich längeren Kontexten**

Wir führen MMP-Evaluierungen mit unterschwelligen Kontexten durch – akzeptabel/nicht akzeptabel; gepaart/ungepaart Struktur – von Längern bis zu 900 Tokens.</sample>
    <sample id="582">**Übersetzung des englischen Inhalts:**

---

**MMP-Beurteilungen sind robust gegenüber willkürlichen Kontextlängen**

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; gepaart/ungepaart Struktur – von Längen bis zu 900 Tokens.

---

**Übersetzung des Textes:**

---

**MMP-Bewertungen sind robust gegenüber willkürlich kontextuellen Längen**

Wir fühlen MPP-Evaluierungen mit verschidenen Kontexten durch – akzeptable/unakzeptable; gepaart/ungepaartstruktur – von Längen bis zu hunderten von Tokens.

---

**Übertragung des Textes:**

---</sample>
    <sample id="583" />
    <sample id="584">Das Bild zeigt einen Diagramm mit der Überschrift "Akzeptable/Unakzeptable MPP-Sätze in der Kontext-Raum/Unterdrückung-Leistung". Es zeigt die Ergebnisse von MPP-Evaluierungen mit unterschiedlichen Kontexten (akzeptabel/unakzeptabel), strukturellen (übereinstimmend/unübereinstimmend) und Längen bis zu 900 Tokens. Die Diagramme zeigen die Präferenzstrategien für verschiedene Sprachmodelle wie BLIMP, OPT und 6.7B. Die Präferenzstrategien werden auf der Y-Achse dargestellt, während die Länge der Sätze auf der X-Achse angegeben wird. Die Diagramme zeigen, wie die Präferenzstrategien für die verschiedenen Sprachmodelle unterschiedlich sind, insbesondere bei langen Sätzen.</sample>
    <sample id="585">Das Bild zeigt einen Diagramm mit der Überschrift "Akzeptable/Unakzeptable MPP-Sätze in der Kontextsteigerung/Abnahme der Urteilsleistung". Es zeigt die Ergebnisse von MPP-Evaluierungen mit unterschiedlichen Kontexten (akzeptabel/unakzeptabel), strukturellen Abstimmungen (übereinstimmend/unübereinstimmend) und Längen von bis zu 900 Tokens. Die Diagramme zeigen die Präferenzstrategien für verschiedene Modelle wie BLIMP, OPT und 6.7B. Die Präferenzstrategien werden auf der Y-Achse dargestellt, während die Länge der Tokens auf der X-Achse angegeben wird. Die Diagramme zeigen, wie die Präferenzstrategien für die verschiedenen Modelle unterschiedlich sind, insbesondere bei unterschiedlichen Kontexten und Strukturen.</sample>
    <sample id="586">Der Inhalt des Bildes beschreibt eine Studie zur Auswirkung von akzeptablen und unakzeptablen MPP-Sätzen auf die Modellleistung von KI-Modellen. Die Studie untersucht die Auswirkung von unterschiedlichen Kontexten (akzeptabel/unakzeptabel) und strukturellen Anpassungen (mit/ohne Anpassung) auf die Modellleistung von Künstlichen Intelligenz-Modellen wie BLIMP, OPT und 7.6B. Die Studie zeigt, dass die Modellleistung stark von der Struktur der MPP-Sätze abhängt und dass unakzeptable MPP-Sätze die Modellleistung negativ beeinflussen. Die Studie verwendet eine Farbpalette, um die verschiedenen Kontexte und Strukturen zu visualisieren.</sample>
    <sample id="587">Der Inhalt des Bildes beschreibt eine Studie zur Auswirkung von akzeptablen und unakzeptablen MPP-Sätzen auf die Modellleistung von KI-Modellen. Die Studie untersucht die Auswirkungen unterschiedlicher Kontexte, akzeptabler/nicht akzeptabler Sätze und passender/unpassender Struktur auf die Modellleistung von Künstlichen Intelligenz-Modellen. Die Studie wurde mit verschiedenen Kontexten durchgeführt, einschließlich akzeptabler und unakzeptabler Sätze sowie passender und unpassender Struktur. Die Studie zeigt, dass die Modellleistung von KI-Modiellen stark von der Struktur der Sätze abhängt. Die Studie zeigt, dass die Modelle mit akzeptablen Sätzen und passender Struktur die besten Leistungen erzielen, während die Modelle mit unakzeptablen Sätzen und unpassender Struktur die schlechtesten Leistungen erzielen. Die Studie zeigt, dass die Struktur der Sätze eine wichtige Rolle bei der Modellleistung spielt und dass die Modelle mit akzeptabler Struktur die besten Leistungen aufweisen. Die Studie zeigt, dass die KI-Modelle mit akzeptablen Sätze und passender Struktur die besten</sample>
    <sample id="588">Der Inhalt des Bildes beschreibt eine Studie zur Auswirkung von akzeptablen und unakzeptablen MPP-Sätzen auf die Modellleistung von KI-Modellen. Die Studie untersucht die Auswirkung von unterschiedlichen Kontexten (akzeptabel/unakzeptabel) und strukturellen Anpassungen (mit/ohne Anpassung) auf die Modellleistung von Künstlichen Intelligenz-Modellen, insbesondere bei Texten von Länge bis zu 900 Wörtern. Die Studie verwendet drei verschiedene KI-Modelle: BLIMP, OPT und 7.6B. Die Ergebnisse zeigen, dass die Modellleistung stark von der Struktur der MPP-Sätze abhängt, insbesondere bei langen Texten. Die Studie verwendet auch eine Farbpalette, um die verschiedenen KI-Modelle und die Ergebnisse zu visualisieren.</sample>
    <sample id="589">Warum beeinflussen gepaarte Präfixe die Urteile von LM?
Wir stören Kontextsätze in Weisen, die die relevante Struktur erhalten, und fragen, ob Modelle gleichermaßen empfindlich auf diese Sätze reagieren.</sample>
    <sample id="590">Warum beeinflussen gepaarte Präfixe die Urteile von LM?
Wir stören Kontextsätze auf eine Weise, die die relevante Struktur erhalten, und fragen, ob Modelle gleichermaßen empfindlich auf diese Sätze reagieren.
- Präfix/Suffix-Adverben: "Allerdings, &lt;sent&gt;."
- Langpräfix-Adverben: "Allerdings, letztendlich, &lt;sent&gt;."
- Zusätzliche Klauseln: "Unabhängig davon, was X über es denkt, &lt;sent&gt;."
- Zitat: "Gestern sagte X, &lt;sent&gt;."
Wir stören Kontextsätzchen auf eine Weise, die die relevante Struktur erhalten, und fragen nach, ob Modelle gleichermaßen auf diese Sätze empfindlich reagieren.
- Präfix-Suffix-Adverben: "Allerdings," &lt;sent&gt;."
- Langpräprefix-Adverben: "Allerdings, Letztlich," &lt;sent&gt;."
- Zusä</sample>
    <sample id="591">Warum beeinflussen geprägte Prefixe die Urteile von LM?
Wir stören Kontextsätze in Weisen, die die relevante Struktur erhalten, und fragen, ob Modelle gleichermaßen empfindlich auf diese Sätze reagieren.

Prefixe/Suffixe Adjektive: "Allerdings, &lt;sent&gt;."
Langen Prefixen Adjektiven: "Zunächst, &lt;sent&gt;."
Additive Adjektive: "Unabhängig davon, was X über es denkt, &lt;sent&gt;."
Quote: "Gestern sagte X, &lt;sent&gt;."</sample>
    <sample id="592" />
    <sample id="593">Warum beeinflussen geprägte Prefixe die Urteile von LM?
Wir stören Kontextsätze in Weisen, die die relevante Struktur erhalten, und fragen, ob Modelle ähnlich empfinden.</sample>
    <sample id="594">**Schlüsselergebnisse:**

- Sprachmodelle sind empfindlich gegenüber latenten syntaktischen/semantischen Merkmalen, die über Sätze hinweg geteilt werden.
- MPP-Evaluierungen mit kurzen, einzelnen-Satz-Eingaben erfassen nicht vollständig das abstrakte Wissen von Sprachmodellen.

**Zusammenfassung:**

Die Präsentation hebt hervor, dass Sprachmodelle auf latenten syntaktischen und semantischen Merkmalen, die über Säulen hinweg geteilt werden, empfindlich reagieren. Darüber hinaus wird darauf hingewiesen, dass MPP-Evaluierungen mit kurzem, einzelnen-Satz-Eingaben nicht ausreichend die abstrakte Wissensbasis von Sprachmodellen erfassen.</sample>
    <sample id="595">**Schlüsselergebnisse:**

- Sprachmodelle sind empfindlich gegenüber latenten syntaktischen/semantischen Merkmalen, die über Sätze hinweg geteilt werden.
- MPP-Evaluierungen mit kurzen, einzelnen-Satz-Eingaben erfassen nicht vollständig das abstrakte Wissen von Sprachmodellen.

**Visualisierung:**

- **Graph:** Zeigt die Abhängigkeit von der Anzahl der Sätze von 0 bis 800.
- **Diagramm:** Zeigt die Abhängigkeit der Wahrscheinlichkeit von 0 bis 1 von 0 bis 800 Sätzen.
- **Tabelle:** Zeigt die verschiedenen Arten von Sprachmodellen und ihre Fähigkeiten.

**Zusammenfassung:**

- Sprachmodelle sind sehr empfindlich gegenüber latenten sprachlichen und semantischen Merkmalen, die über Säulen hinweg geteilt werden.

**Schlussfolgerung:**

- MPP-Evaluierungen, die auf kurzen, einzelnen-Satz-Ein</sample>
    <sample id="596">**Schlüsselergebnisse**  
- Sprachmodelle sind empfindlich gegenüber latenten syntaktischen/semantischen Merkmalen, die über Sätze hinweg geteilt werden.  
- MPP-Evaluierungen mit kurzen, einzelnen Sätzen erfassen nicht vollständig das abstrakte Wissen von Sprachmodellen.</sample>
    <sample id="597">Die Input-Token werden im ersten Schritt der Methode als **Tag** zugeordnet.</sample>
    <sample id="598">Es gibt 5.000 Skripte in Coscript.</sample>
    <sample id="626">Die beste Ausrichtungsmethode für DEPlain ist **MASSalign**. Es ist eine **vivierichte** Methode, die auf einem **TF-IDF-SIF-Basierten Ansatz** beruht. Diese Methode zeigt die besten Ergebnisse in den meisten Kategorien, insbesondere in der **Precision** und **F1-Score**.</sample>
    <sample id="627">Der Vorteil von schwach überwachtem Lernen ist, dass es das Annotation-Bottleneck löst.</sample>
    <sample id="628">Die Dokumente in DEplain-web waren mit manuellen und automatischen Alignment-Methoden ausgerichtet. Die manuellen Alignment-Methoden waren 100% korrekt, während die automatischen Alignment-Methoden 99% korrekt waren.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde erstellt, indem Reuters-Nachrichten aus dem Jahr 2020 gesammelt und mit den CoNLL-2003-Annotationsrichtlinien annotiert wurden.</sample>
    <sample id="630">XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations</sample>
    <sample id="631">XSemPLR: Cross-Linguual Semantic Parsing in Multiple Natural Languages and Meaning Representations</sample>
    <sample id="632">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Cross-lingual Semantic Parsing**  
**Cross-lingual Semantic Parsing ist eine Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsdarstellungen zu übersetzen.**  

---

**Cross-linguistic Semantic Parsing**  
**Cross- lingual Semantic Parsing ist eine Aufgabe zur Übersetzung von Abfragen in mehreren natürlich Sprachen in mehrere Bedingungsdarstellungen.**  

---

**Crosslingual Semantic Parsing**  
**Die Crosslingual Semantic Parsing ist eine Aufgaben, Abfragen in mehreren Naturlingsprachen in mehrere Bedeutsamkeitsdarstellungen zu übersetzen**  

---

**Cross- lingual Semantic Parsing**  
**Crosslingual Semantic Parsing ist eine Aufgab, Abfragen in mehreren Natursprachen in mehrere Bedeutschungen zu übersetzen**</sample>
    <sample id="633">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Cross-lingual Semantic Parsing**  
**Cross-lingual Semantic Parsing ist eine Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsdarstellungen zu übersetzen.**  

---

**English**  
**German**  
**Chinese**  

---

**Neural Models**  
**SQL**  
**Lambda**  
**FunQL**  

---

**Cross-linguistic Semantic Parsing**  
**Cross- lingual Semantic Parsing ist eine Aufgabe zu übersetzen, Abfragen in mehreren Sprachen in mehrere Bedingungen zu übersetzen.**</sample>
    <sample id="634">**Cross-lingual Semantic Parsing**  
- **Bestehende CLSP-Modelle werden separat vorgeschlagen und auf Datensätzen von begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel:**  
  - **Mangel an Abdeckung bestimmter natürlicher Sprachen**  

**Diagramm:**  
- **Englisch**  
- **Deutsch**  
- **Chinesisch**  
- **SQL**  
- **Lambda**  
- **FunQL**  

**Neural Models**</sample>
    <sample id="635">**Cross-lingual Semantic Parsing**  
- **Bisherige CLSP-Modelle werden separat vorgeschlagen und auf Datensätzen von begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel:**  
  - **Mangel an Abdeckung bestimmter natürlicher Sprache**  

- **Diagramm:**  
  - **Links:**  
    - **Englisch**  
    - **Deutsch**  
    - **Chinesisch**  
  - **Rechts:**  
    - **SQL**  
    - **Lambda**  
    - **FunQL**  
  - **Zwischenrechter Pfeil:**  
    - **Neuronale Modelle**  

- **Bemerkung:**  
  - **Die CLSP-Modelle sind derzeit auf einzelne Sprachen und Anwendungen beschränkt und bieten keine umfassende Unterstützung für mehrere Sprachen oder Anwendungen.**</sample>
    <sample id="636">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Cross-lingual Semantic Parsing**

- **Bereits bestehende CLSP-Modelle werden separat entwickelt und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel:**
  - **Mangel an Abdeckung bestimmter Bedeutungsrepräsentation**

---

**Cross-ling</sample>
    <sample id="637">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Cross-lingual Semantic Parsing**

- **Bereits bestehende CLSP-Modelle werden separat vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel:**
  - **Mangel an Abdeckung bestimmter Bedeutungsrepräsentationen**

---

**Cross-linguistic Semantic Parsing**

- **Bisherige CLSP-Modelle werden separat vorgelegt und auf Datensätzen mit begrenztem Aufgaben- und Anwendungsumfang bewertet. Zum Beispiels:**
  - **Mangel an Abdeckung bestimmter Bedeutungsrepräsentiert**

---

**Cross- lingual Semantic Parsing**

- **Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensets mit begrenzten Aufgaben und Applicationen bewertet. Zum Beispiele:**
  - **Mangel an Abgedeckung bestimmter Bedeutungsreprasentationen**

---

**Translations:**

1. **English:**
   - **Cross-lingual Semantic Parsing**
   - **Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:**
     - **Lack of coverage on certain meaning representation**

2. **German:**
   - **Cross-linguale Semantische Parsing**
   - **Bereits bestehende CL-SP-Modelle werden separat vorgeschlägen und auf Datensätzen mit begrenzbaren Aufgaben und Anwendungen bewerte. Zum Beispiel:**
     - **Mangel an Abdeckung bestimmtter Bedeutungsrepräsentation**

3. **Chinese:**
   - **跨语言语义解析**
   - **现有的 CLSP 模型是分别提出的，并在有限的任务和应用数据集上进行评估。例如：**
     - **某些意义表示的覆盖不足**

---

**Translations of the slide content:**

1. **English:**

   - **Cross-lingual Semantic</sample>
    <sample id="638">**Cross-lingual Semantic Parsing**  
- **Bisherige CLSP-Modelle werden separat vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen bewertet. Zum Beispiel:**  
  - **Mangel an Abdeckung für bestimmte neuronale Modelle**  

**Diagramm:**  
- **Englisch**  
- **Deutsch**  
- **Chinesisch**  
- **SQL**  
- **Lambda**  
- **FunQL**  
- **Single Model**  

**Beschreibung:**  
Die Diagramme zeigt, wie bestimmte CLSP-Modelle auf verschiedenen Datensätzen von SQL, Lambda und FunQL getestet werden. Es wird dargestellt, dass bestimmte neuronale Modelle nicht ausreichend abgedeckt sind.</sample>
    <sample id="639">Wir bieten ein vereinigtes Dataset XSemPL für die semantische Parsing in mehreren natürlichen Sprachen und Bedeutungsdarstellungen an. Es enthält: 9 Datensätze in verschiedenen Bereichen, 5 semantische Parsingaufgaben, 8 Bedeutungsdarstellungen und 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="640">Wir bieten ein vereinigtes Dataset XSemPL für die kreuzsprachliche semantische Parsing in mehreren natürlichen Sprachen und Bedeutungsdarstellungen an. Es enthält: 9 Datensätze in verschiedenen Bereichen, 5 semantische Parsingaufgaben, 8 Bedeutungsdarstellungen und 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="641">Experimentelle Einstellungen: Wir erwägen sechs Einstellungen für Training und Evaluierung. *Translate-Test*: Verwenden Sie die Google-Übersetzungs-API, um die Quelle in die Zielsprache zu übersetzen. Dann verwenden Sie ein monolinguales Modell, um zu trainieren und zu bewerten.</sample>
    <sample id="642">Experimentelle Einstellungen: Wir betrachten die sechs Einstellungen für Training und Evaluierung.  
- **Translate-Test**: Verwenden Sie die Google-Übersetzungs-API, um die Quelle in die Zielsprache zu übersetzen. Dann verwenden Sie ein monolinguales Modell, um zu trainieren und zu bewerten.  

**Training**  
- Englisch  
- Englisch Modell  
- SQL  

**Inferenz**  
- Deutsch  
- Übersetzen API  
- Englisch  
- English Modell  
- SQL</sample>
    <sample id="643">Experiment Settings: Wir betrachten sechs Szenarien für Training und Evaluierung. Translate-Test: Verwenden Sie die Google-Übersetzungs-API, um die Quelle in die Zielsprache zu übersetzen. Dann verwenden Sie ein monolinguales Modell, um zu trainieren und zu bewerten. Training: English -&gt; English Model -&gt; SQL Inferenz: German -&gt; Translate API -&gt; English -&gt; English Model -&gt; SQL</sample>
    <sample id="644">Experimentelle Einstellungen: Wir berücksichtigen sechs Einstellungen für Training und Evaluierung. - Monolinguales Modell: Die Quellsprache ist gleich wie die Zielsprache, z.B. Deutsch-Deutsch. Wir testen auch den Monolingualen Few-shot-Einstellung, indem wir monolinguale Modelle mit nur 10% Trainingdaten trainieren. Training Inferenz</sample>
    <sample id="645">Experimentelle Einstellungen</sample>
    <sample id="646">Experimentelle Einstellungen</sample>
    <sample id="647">Experimentelle Einstellungen: Wir erwägen sechs Einstellungen für Training und Evaluierung. Multilinguales Modell: Trainieren Sie ein multilingues Modell für alle Sprachen.</sample>
    <sample id="648">Experimentelle Einstellungen</sample>
    <sample id="649">Experimentelle Einstellungen</sample>
    <sample id="650">Experimentelle Einstellungen: Wir betrachten sechs Einstellungen für Training und Evaluierung. Cross-linguale Zero-shot/Few-shot-Transfer: Trainieren Sie auf einer Quellsprache und übertragen Sie auf eine andere Sprache. Training: English, Or, English, German, Few-shot, Multilingual Model, SQL Inferenz: German, Multilingual Model, SQL</sample>
    <sample id="651">Experimentelle Einstellungen: Wir betrachten sechs Einstellungen für Training und Evaluierung. Cross-linguale Zero-shot/Few-shot-Transfer: Trainieren Sie auf einer Quellsprache und übertragen Sie zu einer anderen Sprache.</sample>
    <sample id="652">**Analyse im Monolingualen Setting**  
Wir bewerten zwei Gruppen von Modellen im Monolingualen Setting.  
**Enc-PTR:** Multilinguel Pretrained Encoders mit Pointer-based Decoders  
- XLM-R + PTR, mBERT + PTR  
**Enc-Dec:** Multilinguel Pretrained Encoder-Decoder Modelle  
- mBERT, mT5  
Wir fanden heraus, dass mT5 auf allen Datensätzen die beste Leistung erzielt.</sample>
    <sample id="653">**Analyse im Monolingualen Setting**

Wir bewerten zwei Gruppen von Modellen im Monolingualen Setting.

**Enc-PTR:** Multilinguelle vorgeübte Encoder mit Pointer-basierten Decoder
- **XLM-R + PTR, mBERT + PTR**

**Enc-Dec:** Multilinguelle vorgeüberte Encoder-Decoder Modelle
- **mBERT, mT5**

Wir fanden heraus, dass **mT5** die beste Leistung auf allen Datensätzen erzielt.

**Ergebnisse:**

| Modell | MATS | XLM-R + PTR | mBERT + PTR | mBERT | mT5 |
| --- | --- | --- | --- | --- | ---   |
| **Monolingual** | 30.63 | 72.18 | 40.40 | 83.82 | 57.47 | 23.46 | 52.53 | 75.41 | 5.97 | 49.09 |
| **XLM-R + PTR** | 31.31 | 71.41 | 47.40 | 30.37 | 81.41 | 57.41 | 23.46 | 72.18 | 5.97 | 40.36 |
| **mBERT + PTR** | 31.34 | 71.41 | 30.37 | 47.40 | 81.41 | 23.41 | 52.53 | 83.82 | 4.97 | 49.03 |
| **mBERT** | 41.06 | 71.41 | 23.37 | 30.37 | 71.41 | 57.37 | 23.46 | **57.47** | 5.97 | 48.09 |
| **mT5** | 41.06 | **71.41** | 23.37 | 47.41 | 81.41 | 30.41 | 52.51 | 83.82 | 6.97 | 49.02 |

**Durchschnittliche Leistung:**
- MATS: 41.06
- XLM-R + PTR: 71.41
- mBERT + PTR: 47.40
- mBERT: 30.37
- mT5: 57.47

**Ergebnisse:**
- MATS: 41,06
- XLM-R + PTR (PTR): 71,41
- mBERT + PTR (PTR): 47,40
- mBERT: 31,34
- mT5: 57,47

**Durchschnittliche Performance:**
- MATS: 41
- XLM-R + PTR (PTR) : 71
- mBERT + PTR (PTR) : 47
- mBERT: 31
- mT5: 57

**Beste Leistung:**
- mT5 erzielt die beste Leistung auf allen Daten.</sample>
    <sample id="654">**Analyse im Monolingualen Setting**  
Wir bewerten zwei Gruppen von Modellen im Monolingualen Setting.  
**Enc-PTR:** Multilingue vorgefertigte Encoder mit Pointer-basierten Decoder  
- XLM-R + PTR, mBERT + PTR  
**Enc-Dec:** Multilingue vorgefertigter Encoder-Decoder Modelle  
- mBERT, mT5  
Wir fanden heraus, dass mT5 auf allen Datensätzen die beste Leistung erzielt.</sample>
    <sample id="655">**Analyse im Monolingualen Setting**

Wir bewerten zwei Gruppen von Modellen im Monolingualen Setting.

**Enc-PTR:** Multilinguel Pretrained Encoders mit Pointer-based Decoders

- **XLM-R + PTR, mBERT + PTR**

**Enc-Dec:** Multilinguel Pretrained Encoder-Decoder Modelle

- **mBERT, mT5**

**Ergebnisse:** mT5 erzielt die beste Leistung auf allen Datensätzen!

---

**Analysis of Monolingual**

Wir bewerten auf zwei Gruppen von Modellen im Monlingualen Setting.

**Enc-Pointer:** Multilingual Pretrained Encoders with Pointer-based Decoders

- **XLR-M + PTR, mBERT + PTR**
- **MSP, MSIP, MNSIP, MNSIP, MNSIP**

**Enc-Dec:** Multilingual Pretrained Encoder-Decoder Models

- **mBERT, mT6**

**Result:** mT5 erzielt die Bestleistung auf allen Datensätzen.

---

**Analysis of Monlingual**

Wir bewerteten zwei Gruppen von Modellen im monolingualen Setting.

**Enc-PT:** Multilingual Pretrained Encoders with Pointer-Based Decoders

- **XLM-R+PTR, mBERT+PTR**
- **MSP, MSIP**

**Enc-Dec:** Multi-lingual Pretrained Encoder-Decoder Models

**Result:** mT5 erreicht die beste Leistung auf allen Daten.

---

**Analysis of monolingual**

Wir bewerte zwei Gruppen von Modellen im monlingualen Setting.

**Enc-PR:** Multilingual Pretrained Encoders with Pointer Based Decoders

- **XLM-R, mBERT, mT5**

**Enc-Dec:** Multlingual Pretrained Encoder-Decoder Models</sample>
    <sample id="656">**Analyse der mehrsprachigen Training**

- Wir bewerten auf mT5 und XLM-R PTER im mehrsprachigen Setting.
- Enc-Dec/Enc-PTR (mT5/XLM-R) können durch Training in einer Mischung verschiedener Sprachen verbessert werden.

**Tabelle: Ergebnisse der mehrsprachigen Training**

| **Model** | **MATIS** | **MGSQ** | **MSpider** | **MNLMaps** | **MOvernight** | **MCWQ** | **MSchema2QA** | **MTOP** | **MConNLLa** | **Average** |
|-----------|-----------|----------|-------------|-------------|---------------|----------|----------------|----------|--------------|-------------|
| **Menschlich** | 33.15 | 74.26 | 40.73 | 91.65 | 66.29 | 30.15 | 65.16 | 81.83 | 10.29 | 58.16 |
| **Multilingual** | 39.72 | 71.35 | 40.20 | 85.91 | 61.03 | 30.79 | 61.82 | 81.68 | 59.06 | 61.82 |
| **mT5** | 54.45 | 76.57 | 40.20 | 91.51 | 67.55 | 30.97 | 60.92 | 82.95 | 58.25 | 61.82 |

**Anmerkungen:**

- Die Ergebnisse zeigen, dass mT5 und XLM-R PTER in der mehrsprachigen Training-Situation bessere Leistungen erzielen als die basale mT5-Version.
- Die Mischung verschiedener Spraichen kann dazu beitragen, die allgemeine Sprachverständlichkeit und die Fähigkeit zur Verarbeitung von mehrsprachigen Texten zu verbessern.
- Die genaue Verbesserung hängt von der spezifischen Anwendung und den verwendeten Daten ab.</sample>
    <sample id="657">Analysis of Multilingual Training</sample>
    <sample id="658">Analyse des Mehrsprachigkeits-Trainings

Wir bewerten mT5 und XLM-R + PTR auf Mehrsprachigkeits-Einstellung

- Die meisten der großen natürlichen Sprachmodelle (NL) können eine Leistungssteigerung erzielen, mit Ausnahme, dass die englische Leistung in 7 Datenkollektiven sinkt und in 3 Datenkollektiven steigt. Dies wird als "Fluch der Mehrsprachigkeit" bezeichnet.</sample>
    <sample id="659">**Analyse der mehrsprachigen Training**

- Wir bewerten auf mT5 und XLM-R + PTR im mehrsprachigen Setting.
- Die meisten der großen natürlichen Sprachsysteme (NLS) erzielen Leistungssteigerungen, mit Ausnahme, dass der Englischleistung in 7 Datensätzen sinkt und in 3 Datensätzen steigt. Dies wird als "Curse of Multilinguality" bezeichnet.

**Analyse der mehrsprachigen Training:**

- Wir bewerten auf XLM-R + PTR im mehrsprachischen Setting.
- Die meisten der groβen natürlichen Sprachsysteme (NLP) erzielen Leistungssteigerung, mit Ausnahme, dass der Engl. Leistung in 7 Datensätzen abnimmt und in 3 Datensätzen ansteigt. Dies wird als "Curse of Multi-lingual" bezeichnet.

**Analysis of Multilingual Training**

- We evaluate on mT5 and XLM-R + PTR in Multilingual Setting.
- Most of the major NLS can obtain performance gain, except that English performance drops in 7 datasets and gains in 3 datasets. This is known as "Curse of Multilinguality".

**Analysis of Multilingual Training**</sample>
    <sample id="660">Der Inhalt des Bildes ist bereits in deutscher Sprache. Es zeigt eine Diagramm-Analyse, die die Leistung verschiedener Sprachmodeller in verschiedenen Sprachmodellen und Datensätzen vergleicht. Die Diagramme zeigen die Leistung von Modellen, die mit wenigen Beispielen trainiert wurden (Few-shot), ohne Beispiele zu verwenden (Zero-shot) und in einem monolinguellen Kontext (Monolinguale Einstellung). Die verschiedenen Farben der Linien (blau, orange und grün) repräsentieren die verschiedenen Transferlösungen. Die Diagramme zeigen, wie die Leistung der Modelle in verschiedenen Sprachmodellen variiert, und wie die Leistung von Modellen, die in einem monolinguellen Kontext trainiert wurden, im Vergleich zu Modellen, die in mehreren Sprachen trainiert wurden, unterschiedlich ist.</sample>
    <sample id="661">Der Titel des Bildes lautet "Cross-lingual Performance Gap". Es zeigt eine Venn-Diagramm, das verschiedene Sprachmodelle und deren Leistung in verschiedenen Sprachen vergleicht. Die drei Hauptlinien im Diagramm sind:

- **Blau Linie (Cross-lingual Few-shot transfer):** Diese Linie zeigt die Leistung von Sprachmodellen, die auf wenigen Beispielen in mehreren Sprachen trainiert wurden.
- **Orangeline (Cross-lingual Zero-shot transfer):** Diese Linie zeichnet die Leistung von Sprachmodellen aus, die ohne zusätzliche Trainingsdaten in neuen Sprachen arbeiten können.
- **Grüne Linie (Monolingual Setting):** Diese Linie zeigt die Performance von Sprachmodellen, die ausschließlich in einer Sprache trainiert wurden.

Im Zentrum des Diagramms befindet sich das Modell "Spider", das in mehreren Sprachen trainierbar ist und die beste Leistung in der meisten Sprachen zeigt. Die verschiedenen Sprachen sind in der Diagrammmitte aufgelistet und werden durch die Linien dargestellt, wie gut das Modell in jeder Sprache performiert.

Der Text unter dem Diagramm besagt:
- "Blue Line: Cross-lingual Few-shot transfer"
- "Orange Line: Cross-lingual Zero-shot transfer"
- "Green Line: Monolingual Setting"

Der Text in der rechten oberen Ecke lautet:
- "Kieran Dang"

Der Text in der rechten unteren Ecke lautet:
- ATIS

Der Text in der linken unteren Ecke lautet:
15</sample>
    <sample id="662">**Cross-lingual Performance Gap**  
- **Grün - Orang**: Für die Nullsprach-Situation ist der Cross-linguale Transferleistungsabstand signifikant.  
- **Blau - Orang**: Für die wenigsprachige Situation ist der Transferleistungsabstand schnell abgebaut.  

**MTOP**  
- **Geoquerry/lamb**  
- **Geoquerry/prolog**  
- **Geoquerry/funql**  
- **Geoquerry/sql**  
- **Spider**  
- **ATIS**  
- **Schema2QA**  
- **Overnight**  
- **NLMaps**  
- **MCWQ**  

**ATIS**  
- **Geoquerry/lam**  
- **Geoquerry/pro**  
- **Geoquerry/fu**  
- **Geoquerry/s**  
- **Geoquerry/ql**  
- **Geoquerry/ry**  
- **Geoquerry/er**  
- **Geoquerry/ar**  
- **Geoquerry/**  
- **Geoquerry/rr**  
- **Geoquerry/ll**  
- **Geoquerry/oo**  
- **Geoquerry/pp**  
- **Geoquerry/ee**  
- **Geoquerry/ii**  
- **Geoquerry/uu**  
- **Geoquerry/aa**  
- **Geoquerry/yy**  
- **Geoquerry/zz**  
- **Geoquerry/xx**  
- **Geoquerry/cc**  
- **Geoquerry/bb**  
- **Geoquerry/nn**  
- **Geoquerry/mm**  
- **Geoquerry/kk**  
- **Geoquerry/jj**  
- **Geoquerry/gg**  
- **Geoquerry/ff**  
- **Geoquerry/eh**  
- **Geoquerry/ah**  
- **Geoquerry/uh**  
- **Geoquerry/th**  
- **Geoquerry/sh**  
- **Geoquerry/rh**  
- **Geoquerry/qh**  
- **Geoquerry/ph**  
- **Geoquerry/oh**  
- **Geoquerry/nh**  
- **Geoquerry/mh**  
- **Geoquerry/lh**  
- **Geoquerry/kh**  
- **Geoquerry/jh**  
- **Geoquerry</sample>
    <sample id="663">Die Übersetzung des englischen Inhalts in Deutsch lautet:</sample>
    <sample id="664">Die Übersetzung des englischen Inhalts in Deutsch lautet:

"Enc-Dec (m75) erreicht vorherige Ergebnisse oder erzielt vergleichbare Ergebnisse. Prä-Training auf dem englischen NL kann die Leistung von wenig-schritt auf Ziel-NLs signifikant verbessern. Multilinguale LLMs (Codex &amp; BLOOM) sind für die semantische Parsing-Aufgaben in verschiedenen Sprachen noch unzureichend. Chinesische Transfer-Learning und englische monolinguale Training (En -&gt; En) haben die größten Leistungslücken, während der Deutsche normalerweise die kleinsten hat. FunQL übertrifft die anderen drei Bedeutungsdarstellungen, und SQL erzielt das schlechteste Ergebnis."</sample>
    <sample id="665">**Schlussfolgerung**

- Wir haben XSemPLR gebaut, ein vereinheitlicher Benchmark für semantische Parsing mit mehreren natürlichen Sprachen und Bedeutungsdarstellungen.
- Wir führten eine umfassende Benchmarkstudie mit drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch.
- Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Ausbildung die beste Leistung liefert, während mehrere mehrsprachige LLMs immer noch unzureichend sind, um semantische Parsing-Aufgaben zu erfüllen. Darüber hinaus bleibt der Leistungsunterschied zwischen monolingualer Ausbildung und cross-lingualer Transfer-Learning erheblich.</sample>
    <sample id="666">**Schlussfolgerung**  
- Wir haben XSemPLR gebaut, ein vereinfachtes Benchmark für kreuzsprachlichen semantischen Parsing mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen.  
- Wir führten eine umfassende Benchmarkstudie mit drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch.  
- Unsere Ergebnisse zeigen, dass mT5 mit monolingualem Training die beste Leistung liefert, während mehrere mehrsprachige LLMs immer noch unzureichend sind, um kreuzsprachlichen semantischen parsen zu können. Darüber hinaus bleibt der Leistungsunterschied zwischen monolingualem Training und kreuzsprachlichem Transferlernen erheblich.</sample>
    <sample id="667">Die bereits durchgeführten Arbeiten sind:

1. **Parameter-based watermark [1, 2]**
2. **Lexical watermark [3, 4]**
3. **Backdoor-based watermark [5]**
4. **Adversarial-based watermark [6]**

Diese Arbeiten wurden in verschiedenen Studien und Veröffentlichungen vorgestellt, um die Schutzmechanismen für künstliche Intelligenz (KI) und maschinelles Lernen (ML) zu verbessern.</sample>
    <sample id="668">Multilingual LLMs like Codex or Bloom are still inadequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="695">Die Methode umgeht die Mehrdeutigkeit der Permutation</sample>
    <sample id="696">Die Fairness eines nachgeschaltetenen NLP-Modells wird definiert als die Fähigkeit, die Vorurteile und Diskriminierung in den Daten zu erkennen und zu reduzieren, indem man die Daten auf ihre Fairness prüft und entsprechende Korrekturen vornimmt.</sample>
    <sample id="697">Yanis Labrak</sample>
    <sample id="698">Kostyav Sinha</sample>
    <sample id="699">Myra Cheng</sample>
    <sample id="700">Tropikalismus bezieht sich auf die Verwendung von Stereotypen und Vorurteilen, um bestimmte Gruppen zu charakterisieren und zu verurteilen. In der Arbeit wird Tropikalismus als eine Methode beschrieben, um Gruppen durch ihre kulturellen, traditionellen oder exotischen Merkmale zu definieren und zu marginalisieren. Diese Methode wird als schädlich und verstörend betrachtet, da sie die Identität und die Vielfalt dieser Gruppen einschränkt.</sample>
    <sample id="701">Die Autoren haben die Beschreibungen der Zielgruppennamen durch die Verwendung von "Top-Wörtern" erstellt.</sample>
    <sample id="702">In dieser Arbeit wurde **P-CXMI** (Pointwise Contextualized XMI) eingeführt, um den Kontextverwendung zu messen, um eine spezifische Übersetzung zu ermöglichen.</sample>
    <sample id="703">DrBERT und ChuBERT sind beide KI-Modelle, die für die Verarbeitung von Textdaten eingesetzt werden. DrBERT ist ein KI-Modell, das auf der Basis von Daten trainiert wurde, die aus verschiedenen medizinischen Dokumenten stammen. ChuBERT hingegen ist ein KI-Modell, das speziell für die Verarbeitung von Chinesischsprachigen Dokumenten entwickelt wurde.</sample>
    <sample id="751">Drei Autoren sind an der Arbeit beteilt.</sample>
    <sample id="752">Iteratives Transferlernen ist ein Prozess, bei dem ein Modell iterativ mit neuen Daten trainiert wird, um seine Leistung zu verbessern. Im Gegensatz zu Cumulative Transferlernen, bei dem das Modell auf dem gesamten Datensatz trainiert wird, wird bei iteratives Transferlernen nur ein Teil des Datensatzes verwendet, um das Modell zu aktualisieren. Dies kann dazu führen, dass das Modell schneller an neue Daten anpassen kann, aber auch, dass es möglicherweise weniger genau ist als bei Cumulative Transferlernen.</sample>
    <sample id="753">Das Ziel des Datensatzes ist es, die Verständnis der Benutzersprache zu verbessern, wenn sie eine Wahl treffen.</sample>
    <sample id="754">Ein Angreifer kann Modellparameter über einen EaaS extrahiert, indem er die Daten aus dem EaaS extrahiert und dann die Parameter aus den Daten extrahiert.</sample>
    <sample id="755">3</sample>
    <sample id="756">10.</sample>
    <sample id="757">Carnegie Mellon University.</sample>
    <sample id="758">I saw Bart and Lisa. Homer came and sneezed.</sample>
    <sample id="759">Der Stand der Technik für Dialogsysteme ist **ABC-Eval**, das als **ABC** steht für **Assess, Build, and Continuously Improve**. Diese Methode basiert auf **Coherence** (Kohärenz), **Knowledge** (Wissen), **Consistency** (Konsistenz) und **Emotional Understanding** (Emotionale Verständigung). 

**Coherence** bedeutet, dass die Antworten des Dialogsystems konsistent und logisch sind. **Knowledge** bezieht sich auf die Fähigkeit des Systems, relevante Informationen zu verstehen und darauf zu reagieren. **Consistency** bezieht sich auf die Fäh</sample>
    <sample id="760">Um die Stabilität der Modelle über längere Kontexte zu bewerten und sicherzustellen, dass sie konsistente und zuverlässige Entscheidungen treffen, unabhängig von kurzfristigen Informationen.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergl...</sample>
    <sample id="762">No, the annotators do not know the entity in advance.</sample>
    <sample id="763">BLEU, METEOR, ROUGE, CIDEr.</sample>
    <sample id="764">Die Regression wirkt sich bei der Generalisierung auf bestimmte Named Entity Recognition (NER)-Typen aus.</sample>
    <sample id="765">Positionalität ist wichtig für NLP, weil sie die relative Position von Wörtern in einem Satz berücksichtigt, was die Bedeutung und den Kontext der Wörter beeinflusst.</sample>
    <sample id="766">Adapter.</sample>
    <sample id="767">RoBERTA-base + classifier head.</sample>
    <sample id="768">Die aktuellen Testsets zur Bewertung der PaLM-Fä</sample>
    <sample id="769">Die Autoren haben drei Empfehlungen vorgeschlagen.</sample>
    <sample id="770">10%.</sample>
    <sample id="771">Shuheng Liu und Alan Ritter.</sample>
    <sample id="772">Yes, the results and dataset of the study can be used as a benchmark.</sample>
    <sample id="773">In der Arbeit werden **vier** kleinere Modelle experimentiert. Diese Modelle sind:

1. **GPT-3 (175B)**
2. **Codex (175B)**
3. **InstructGPT (175B)**
4. **T5 (175B)**

Jedes dieser Modelle wird auf unterschiedliche Datensätte (Coscript) gefinert, um die Leistung und die Fähigkeit zur Generierung von qualitativ hochwertigen Skripten zu untersuchen.</sample>
    <sample id="774">Das basale Modell für die Untersuchung der multimodalen Unterrichtsabstimmung ist das **One For All (OFA)**-Modell. Es ist ein vorgeschlagener, vereinfachter Ansatz, der die Kombination verschiedener Modellarchitekturen, Aufgaben und Modalitäten ermöglicht, um die Unterrichtsabstimmung zu verbessern.</sample>
    <sample id="833">Google</sample>
    <sample id="834">Stony Brook University.</sample>
    <sample id="835">Die Arbeit untersuchte Sprachpaare wie Deutsch-Englisch, Deutsch-Französisch, Deutsch-Spanisch, Deutsch-italienisch, Deutsch-niederländisch, Deutsch-russisch, Deutsch-türkisch, Deutsch-chinesisch, Deutsch-japanisch, Deutsch-koreanisch und Deutsch-indonesisch.</sample>
    <sample id="836">Shangbin Feng</sample>
    <sample id="837">Während der Experimente wurden zwei Modelle untersucht: 

1. **Long-mBART** (Document Level)
2. **mBART** (Sentence Level)</sample>
    <sample id="838">Für das Training werden 53 von 62 Aufgaben verwendet, wobei 5 Aufgaben für die Tests ausgewählt werden.</sample>
    <sample id="839">Drei Autoren sind an der Arbeit beteilt: Regina Stodden, Omar Momen und Laura Kallmeyer.</sample>
    <sample id="840">Die Autoren haben Experimente auf folgenden Datensätzen durchgeführt:

- **AG News**
- **MIND**
- **SST2**
- **Enron Spam**

Zusätzlich wurde der allgemeine Datensatz **Wikitext** verwendet.</sample>
    <sample id="876">NACHOS is a dataset used for evaluating language models in healthcare.</sample>
    <sample id="877">Das ist ein Bild, das nicht mit einer Frage beantwortet werden kann. Es ist ein Titelbild für eine Präsentation über die Verwendung von PaLM für Übersetzung und die Bewertung von Strategien und Leistung. Es zeigt die Google-Logo und den Titel der Präsentation. Es gibt auch ein Bild eines schönen Strandes mit Palmen und ein Gesprächsballoon mit einem freundlichen Gesicht. Unter dem Titel gibt es eine Liste von Namen, die möglicherweise die Autoren der Präsentation sind.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse. Sie bestimmt, wie gut die Sprachmodelle die Übersetzung erledigen. Wenn die Prompts gut ausgewählt sind, ergeben sich bessere Ergebnisse.</sample>
    <sample id="879">Die Autoren gehören an der Carnegie Mellon University.</sample>
    <sample id="880">Die 5 Anweisungen der Expert*in sind:

1. **Beobachten Sie die Bilder**
2. **Fragen Sie sich, was passiert?**
3. **Erzählen Sie eine Geschichte**
4. **Zeichnen Sie das, was Sie sehen**
5. **Erzählen Sie eine Gegenbeispiel**</sample>
    <sample id="881">Die Autoren schlagen vor, Modelle zur Nutzung von Informationsquellen aus mehreren Quellen zu testeten, indem sie die Fähigkeit der Modelle bewerten, die Informationen aus mehreren Quellen zusammenzuführen und korrekt zu verstehen.</sample>
    <sample id="882">Das Bild ist ein PowerPoint-Präsentationsseiten mit dem Titel "Prompting PaLM for Translation: Assessing Strategies and Performance". Es zeigt die Google-Logo in der oberen linken Ecke und die Autoren der Präsentation unter dem Titel "David Vilar Torres, Markus Freitag, Colin Cherry, Jianing Luo, Vithish Rathaker, George Foster" mit ihren Fotos. Im oberen rechten Eck ist ein Emoji mit einem Fragezeichnungsschild, das sagt: "Can you translate this for me, please?". Die Präsentation wird von der ACL 2023 veranstaltet.</sample>
    <sample id="883" />
    <sample id="884">Das Bild zeigt eine PowerPoint-Präsentation über das PaLM-Sprachmodell. Die Präsentation enthält eine Liste von Informationen über das Modell, wie z</sample>
    <sample id="885">Unser Beitrag:</sample>
    <sample id="886">Unser Beitrag:</sample>
    <sample id="887">Unsere Beiträge:

1. Erste systematische Studie von LLM-Prompting für maschinelles Übersetzen:
   - Baut auf der besten best</sample>
    <sample id="888">Unser Beitrag:</sample>
    <sample id="889">Prompts haben einen großen Einfluss auf die Qualität der Übersetzung. Wähle zwei zufällige Prompts für jede Aussage. Berechne BLEURT für jede Aussage-Prompt-Paar. Die Mehrheit der Aussagen (516 von 1000) zeigt eine Differenz von mehr als 1 BLEURT Punkt. Die Differenz kann bis zu 40 BLEURT Punkte gehen!</sample>
    <sample id="890">Prompts haben einen großen Einfluss auf die Qualität der Übersetzung. Wähle zwei zufällige Prompts für jede Aussage. Berechne BLEURT für jede Aussage-Prompt-Paar. Die Mehrzahl der Aussagen (516 von 1000) zeigt einen Unterschied von mehr als 1 BLEURT-Punkt. Der Unterschied kann bis zu 40 BLEURT-Punkte gehen!</sample>
    <sample id="891">Prompts haben einen großen Einfluss auf die Qualität der Übersetzung. Wähle zwei zufällige Prompts für jede Aussage. Berechne BLEURT für jede Aussage-Prompt-Paar. Die Mehrheit der Aussagen (516 von 1000) zeigt eine Differenz von mehr als 1 BLEURT Punkt. Die Differenz kann bis zu 40 BLEURT Punkte gehen!</sample>
    <sample id="892" />
    <sample id="893" />
    <sample id="894" />
    <sample id="895" />
    <sample id="896" />
    <sample id="897">**Experimentelle Ergebnisse**

- Qualität der Beispiele ist wichtiger als Ähnlichkeit zu der Quelle.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PalM ist nahe an Google Translate.

**Einsichten aus MQM:**

- Fluenz von PalM vergleichbar mit SOTA.
- Genauigkeitsscores sind im Allgemeinen niedriger.
- Dominant durch "Genauigkeit/Ausschluss".
- "Stil/Awkward" ist im Allgemeinen niedriger für PalM.</sample>
    <sample id="898">**Experimentelle Ergebnisse**

- Qualität der Beispiele ist wichtiger als Ähnlichkeit zu der Quelle.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PalM ist nahe an Google Translate.

**Einsichten aus MQM:**

- Fluenz von PalM vergleichbar mit SOTA.
- Genauigkeitsscores sind im Allgemeinen niedriger.
- Dominant durch "Genauigkeit/Omission" bestimmt.
- "Stil/Awkward" ist im Allgemeinen niedriger für PalM.</sample>
    <sample id="899">**Experimentelle Ergebnisse**

- Qualität der Beispiele ist wichtiger als die Ähnlichkeit zum Quelltext.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PalM ist nahe an Google Translate.

**Einsichten aus MQM:**

- Fluenz von PalM vergleichbar mit SOTA.
- Genauigkeitsscores sind im Allgemeinen niedriger.
- Dominant durch "Genauigkeit/Ausschluss".
- "Stil/Awkward" ist im Allgemeinen niedriger für PalM.</sample>
    <sample id="900">**Experimentelle Ergebnisse**

- Qualität der Beispiele ist wichtiger als Ähnlichkeit zu der Quelle.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PalM ist nahe an Google Translate.

**Einsichten aus MQM:**

- Fluenz von PalM vergleichbar mit SOTA.
- Genauigkeitsscores sind im Allgemeinen niedriger.
- Dominant durch "Genauigkeit/Ausschluss" bestimmt.
- "Stil/Awkward" ist im Allgemeinen niedriger für PalM.</sample>
    <sample id="901">**Experimentelle Ergebnisse**

- Qualität der Beispiele ist wichtiger als die Ähnlichkeit zum Quelltext.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PalM ist nahe an Google Translate.

**Einsichten aus MQM:**

- Fluenz von PalM vergleichbar mit SOTA.
- Genauigkeitsscores sind im Allgemeinen niedriger.
- Dominant durch "Genauigkeit/Omission" bestimmt.
- "Stil/Awkward" ist im Allgemeinen niedriger für PalM.</sample>
    <sample id="902">**Experimentelle Ergebnisse**

- Qualität der Beispiele ist wichtiger als Ähnlichkeit zu der Quelle.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PalM ist nahe an Google Translate.

**Einsichten aus MQM:**

- Fluenz von PalM vergleichbar mit SOTA.
- Genauigkeitsscores sind im Allgemeinen niedriger.
- Dominant durch "Genauigkeit/Omission" bestimmt.
- "Stil/Awkward" ist im Allgemeinen niedriger für PalM.</sample>
    <sample id="903">**Experimentelle Ergebnisse**  
- Qualität der Beispiele ist wichtiger als Ähnlichkeit zu der Quelle.  
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.  
- PalM ist nahe an Google Translate.  

**Einsichten aus MQM:**  
- Fluenz von PalM vergleichbar mit SOTA.  
- Genauigkeitsscores sind im Allgemeinen niedriger.  
- Dominant durch "Genauigkeit/Ausschluss".  
- "Stil/Unangemessen" ist im Allgemeinen niedriger für PalM.</sample>
    <sample id="904">**Experimentelle Ergebnisse**

- Qualität der Beispiele ist wichtiger als die Ähnlichkeit zum Quelltext.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PalM ist nahe an Google Translate.

**Einsichten aus MQM:**

- Fluenz von PalM vergleichbar mit SOTA.
- Genauigkeitsscores sind im Allgemeinen niedriger.
- Dominant durch "Genauigkeit/Ausschluss" bestimmt.
- "Stil/Awkward" ist im Allgemeinen niedriger für PalM.</sample>
    <sample id="905">**Experimentelle Ergebnisse**

- Qualität der Beispiele ist wichtiger als die Ähnlichkeit zum Quelltext.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PalM ist nahezu so gut wie Google Translate.

**Einsichten aus MQM:**

- Fluenz von PalM vergleichbar mit SOTA.
- Genauigkeitsscores sind im Allgemeinen niedriger.
- Dominant durch "Genauigkeit/Ausschluss" bestimmt.
- "Stil/Awkward" ist im Allgemeinen niedriger für PalM.</sample>
    <sample id="906">Der englische Inhalt des Videos ist bereits in Deutsch übersetzt, da der Text "thank you" in verschiedenen Sprachen dargestellt wird. Es gibt keinen zusätzlichen englischen Text, der übersetzt werden muss.</sample>
    <sample id="907">Das Bild ist ein statisches Poster für eine Konferenzbeitrag. Es enthält folgende Informationen:

**Titel:**
"**Weaker Than You Think: A Critical Look at Weakly Supervised Learning**"

**Autoren:**
- Dawei Zhu
- Xiaoyu Shen
- Marius Mosbach
- Andreas Stephan
- Dietrich Klakow

**Institutionen:**
- Saarland University
- Department of Language Science and Technology, Saarland University
- Universität Wien

**Logo:**
- Saarland University
- Universität Wienna

**Konferenz:**
- ACL 2023

**Bilder:**
- Fünf Personen mit ihren Fotos und Namen unterhalb des Titels.

**Text:**
- "Weaker Than You Think: A Critical Look"
- "A Critical Look at Weakly Supervised Learning"
- "1 Saarland University"
- "2 Amazon Alexa"
- "3 Universität Wien"
- "ACL 2023"

Das Poster ist in einer einfachen, klaren Layout-Design mit einer Hauptüberschrift, Autorenliste, Institutionenlogos und einem Konferenznamen.</sample>
    <sample id="908">Das Bild ist ein statisches Poster für eine Konferenzbeitrag. Es zeigt die Titel "Weaker Than You Think: A Critical Look at Weakly Supervised Learning" und führt die Autoren Dawei Zhu, Xiaoyu Shen, Marius Mosbach, Andreas Stephan und Dietrich Klakow an. Die Institutionen Saarland University, Department of Language Science and Technology Saarland University und Universität Wien sind oben rechts dargestellt. Die Konferenz wird als "ACL 2023" gekennzeichnet.</sample>
    <sample id="909">**Warum weakly supervised learning?**  

- **Schwache Überwachung löst die Annotation-Bottleneck-Effizienzprobleme auf.**  
- **Aber schwache Labels sind raucher!**  
  - **Rauch erinnert an die Generalisierungsprobleme.**  
- **Schwach überwachtes Lernen (WSL):**  
  - **Trainiere Modelle, die generalisieren, obwohl sie auf raucher Daten trainiert werden.**  

**Warum weakly supervised learning?**</sample>
    <sample id="910">Warum weakly supervised learning?</sample>
    <sample id="911">**Warum weakly supervised learning?**  

- **Schwache Überwachung löst die Annotation-Bottleneck-Problem.  
- Aber schwache Labels sind raucherisch!  
- Schwach überwachte Lernung (WSL):  
  - Trainiere Modelle, die allgemein lernen, obwohl sie auf raucherischen Daten trainiert werden.  

**Warum weakly supervised learning?**</sample>
    <sample id="912">Warum weakly supervised learning?</sample>
    <sample id="913">**Warum weakly supervised learning?**  

- **Schwache Überwachung löst die Annotation-Bottleneck-Effizienzprobleme auf.**  
- **Aber schwache Labels sind raucher!**  
  - **Rauch erinnert an die Generalisierungsprobleme.**  
- **Schwach überwachtes Lernen (WSL):**  
  - **Trainiere Modelle, die generalisieren, obwohl sie auf raucher Daten trainiert werden.**  

**Warum weakly supervised learning?**</sample>
    <sample id="914">Eine häufige Behauptung in neueren WSL-Werken</sample>
    <sample id="915">Ein häufiger Anspruch in neueren WSL-Werken</sample>
    <sample id="916">Eine häufige Behauptung in neueren WSL-Werken</sample>
    <sample id="917">Eine gemeinsame Behauptung in neueren WSL-Werken</sample>
    <sample id="918">Unsere Forschungsfragen:

1. Ist die Reinigungsdaten notwendig?
2. Wie viele Reinigungsproben benötigen WSL-Ansätze?
3. Wie können die verfügbaren Reinigungsproben effizienter genutzt werden?</sample>
    <sample id="919">Unser erster Forschungsfragen: Ist die Reinigungsdaten notwendig?  
Unser zweiter Forschungsfragen: Wie viele Reinheitsproben benötigen WSL-Ansätze?  
Unser dritter Forschungsfragen: Wie können die verfügbaren Reinheitsproben effizienter genutzt werden?</sample>
    <sample id="920">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**Main Findings**

Die folgenden Hauptbefunde wurden festgestellt:

1. **Validation on Weak Labels**:
   - Die Leistung der Modelle auf schwachen Labels (inkorrekte oder unvollständige Labels) ist im Durchschnitt niedriger als die Leistung auf korrekten Labels.
   - Die Leistung der Modelleinheiten BOND, COSINE, MLC und L2R ist im Durchschnitt ähnlich, wobei BOND und COSINE die höchsten Leistungen auf schwachen Labels erreichen.

2. **Validation on Clean Labels**:
   - Die Leistung auf korrekten Labels ist im Durchschnitt höher als die Leistung auf schwachen Labels.
   - Die Leistung von BOND, COSINE, MLC und</sample>
    <sample id="921">Die folgende Übersetzung des englischen Inhalts in Deutsch:</sample>
    <sample id="922">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**Main findings**

Die folgenden Hauptbefunde wurden festgestellt:

1. **FT\_W**: Die Performance von FT\_W ist in allen Fällen niedriger als die anderer Methoden. Dies könnte auf die spezifische Anwendung oder die Implementierung von FT\_W zurückzuführen sein.

2. **BOND**: BOND zeigt eine durchschnittlich hohe Performance, insbesondere bei der Verwendung von feinen Labels. Dies könnte auf die spezielle Struktur und die Anwendung von BOND in der Analyse von Finanzdaten zurückzuführen sein.</sample>
    <sample id="923">Das Bild ist ein visuelles Darstellung eines Diagramms, das die Hauptbefunde (Main findings) eines Studien oder Analysen zeigt. Es besteht aus einem Scatterplot mit dem Titel "RQ1 Main findings" und einer Legende, die die verschiedenen Datenpunkte in drei Kategorien einteilt: "Validation on Weak Label" (in orange), "No Validation (Random Selection)" (in blau) und "Validation on Clean Label" (in grün). Die X-Achse des Diagramms ist beschriftet mit "FTW" und die Y-Achse mit "Relative performance improvement over weak labels (%)". Die Datenpunkte sind in verschiedenen Farben und Größen dargestellt, um die relative Leistungsverbesserung über schwache Labels zu verdeutlichen. Im oberen rechten Bereich des Bildes ist ein Porträt eines Personen zu sehen, der möglicherweise der Autor oder ein Forscher der Studie ist.</sample>
    <sample id="924">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**Main Findings**

**RQI**

**Main Findings**

**Main Findings**

---

**Main Findings**</sample>
    <sample id="925">The video shows a presenter discussing the results of a study on the accuracy of different methods for predicting outcomes. The presenter is standing in front of a whiteboard with a graph displayed on it. The graph shows the accuracy of different methods for predicting outcomes, with the x-axis representing the number of validation samples and the y-axis representing the accuracy. The presenter is discussing the results of the study and how they can be used to improve the accuracy of predictions.</sample>
    <sample id="926">The video shows a presenter discussing the results of a study on the accuracy of different methods for predicting the presence of a certain condition. The presenter uses a graph to illustrate the accuracy of each method over time, with the x-axis representing the number of validation samples and the y-axis representing the accuracy. The graph shows that the accuracy of all methods increases over time, with the "FT" method achieving the highest accuracy. The presenter also discusses the results of a study on the accuracy of the "FT" method for predicting the presence of a certain condition in a population of 1000 individuals. The study found that the "FT" method had an accuracy of 85% for predicting the presence of the condition, while the "COSINE" method had an accuracy of 80%. The study also found that the "FT" method was more effective at predicting the presence of the condition in individuals with a higher risk of developing the condition. The presenter concludes by discussing the implications of the study's findings for the use of the "FT" method in predicting the presence of the condition.</sample>
    <sample id="927">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**R2 Main findings**

**Accuracy**

- FT_C: 85%
- COSINE: 80%
- L2R: 75%
- L2BOND: 70%
- MLC: 65%
- Weak labels: 60%

**Performance Delta (%)**

- FT_C: 10%
- LoRA_C: 8%
- BiFRC: 6%
- Adapter_C: 4%

---

**R2 Main Findings**

**Accuracy**

- **FT_C**: 85%
- **COSINE**: 80%
- **L2R**: 75%
- **L2BOND**: 70%
- **MLC**: 65%
- **Weak labels**: 60%

**Performance Delta**

- **FT_C**: 10%
- **LoRA_C**: 8%
- **BiFRC**: 6%
- **Adapter_C**: 4%

---

**Main Findings**

**Accuracy**

1. **FT_C**: 85%
2. **COSINE**: 80%
3. **L2R**: 75%  
4. **L2BOND**: 70  
5. **MLC**: 65%  
6. **Weak labels**: 60%
  
**Performance Delta (%)**

1. **FT_C**: +10%
2. **LoRA_C**: +8%
3. **BiFRC**: +6%
4. **Adapter_C**: +4%

---

**Main findings**

**Accuracy**

1.**FT_C**: 85%
2.**COSINE**: 80%
3.**L2R**: 75%
4.**L2BOND**: 70
5.**MLC**: 65%
6.**Weak labels**: 60%


**Performance Delta (%)**

1.**FT_C**: +10%
2.**LoRA_C**: +8%
3.**BiFRC**: +6%
4.**Adapter_C**: +4%

---</sample>
    <sample id="928">Die Grafiken zeigen die Ergebnisse von Experimenten zur Verbesserung der Genauigkeit von maschinellem Lernen (ML) in verschiedenen Szenarien. Die linke Grafik zeigt die Genauigkeit (Accuracy) für verschiedene Methoden (FT, COSINE, L2, L2NORM, BIPFIC, MLC, Adapter_C) in Abhängigkeit von der Anzahl der verwendeten Validierungsdaten. Die rechte Grafik zeigt die Performance-Daten (Performance Data) für die gleichen Methoden in Abhängigkeit von der Anwendungsdauer (Application Duration). Die rote Linie markiert die Grenze von 50% Performance-Daten. Die rote Box zeigt die Verteilung der Performance-Daten für die Adapter_C Methode. Die rote Pfeile zeigen die Durchschnittswerte für die Performance-Daten. Die rote Linie zeigt die Durchschnittswerte für den Accuracy-Wert. Die rote Pfeile zeigen den Standardfehler für den Accuracy-Wert. Die rote Linie zeigt die Genauigkeit für die Adapter_C Methode in Abhängigkeit von der Anmeldedatenmenge. Die rote Linie zeigt die Performance-Daten für die Adapter_C Methode in Abhänigkeit von der Anwendungsdauer. Die rote Linie zeigt die Verteilung der Performance-</sample>
    <sample id="929">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**Main findings**

Die folgenden Ergebnisse zeigen die Hauptbefunde:

- **Accuracy**: Die Genauigkeit der verschiedenen Methoden steigt mit zunehmender Anzahl an validierten Daten. Die Methoden FT_C, COSINE, L2N, L2BOND und MLC erreichen die höchsten Genauigkeiten, während die Methode "Weak labels" die niedrigsten Werte aufweist.
- **Performance Delta**: Die Leistungsverbesserung (Performance Delta) der verschiedenen Methoden ist am höchsten, wenn sie mit zunehmender Anzahl an validen Daten trainiert werden. Die Methoden FT_C, COSINE und L2N erreichen die höchsten Performance Deltas, während die Methode "Weak Labels" die niedrigsten Werte aufzeigt.

---

**Main findings**  
Die folgenden Ergebnisse sind die Hauptbefunde:

**Accuracy**: Die Genauigkeit der versuchten Methoden steigt mit zunehmender Menge an validierten Daten. Die Methodenkombinationen FT_C, COSINE, L2BOND und MLC erzielen die höchsten Genauigkeitswerte, während die Methode "Weak_labels" die niedrigsten Werte aufzuweisen scheint.

**Performance Delta**: Die Leistungsverbesserungen (Performance Delta) der versuchten Methoden sind am höchsten, wenn sie mit einer zunehmenden Anzahl an validierten Daten trainiert werden. Die Methodenkombinationen FT_C, COSINE und L2BOND erzielen die höchsten Performance Deltas. Die Methode "Weak_labels" zeigt die niedrigsten Werte.

---

**Main findings**:

Die folgenden Ergebnis zeigen die Hauptbefunde:  

- **Accuracy**: Die Genaukeit der versuchten Methoden steigt bei zunehmender Anzahl an validierter Daten. Die Methoden FT_C, Cosine, L2N, L2BOND, MLC erreichen die höchste Genauigkeit, während die Methode "Weak_label" die niedrigste Genauigkeit aufweist.  
- **Performance Delta**: Die Leistung der versuchten Methoden verbessert sich mit zunehmender Anzahl an Validierungsdaten. Die Methoden FT_C, Cosine und L2BOND erreichen die höchsten Performance Delta, während die Methode "Weak label" die niedrigsten Werte auf zeigt.  

---

**Main findings**:  
Die folgenden Ergebnis sind die Hauptbefunde:  
- **Accuracy**: Die Genauigkeitswerte der versuchten Methoden steigen mit zunehmender Anzahl an gültigen Daten. Die Methoden FT_C, CoSine, L2N, L2BOD und MLC erreichen die höhste Genauigkeit, während "Weak labels" die niedrigste Genauigkeitswerte aufzeigt.  
- **Performance Delta**: Die Performance Delta der versuchten Methoden verbesserten sich mit zunehmender Anzahl von gültigen Daten. Die Methodenkombinationen "FT_C", "Cosine" und "L2BOD" erzielen die höchsten Performance Delta, wäre "Weak labels" die niedrigsten Performance Delta zeigt.  

---</sample>
    <sample id="930">Die folgende Beschreibung ist in Deutsch übersetzt:</sample>
    <sample id="931">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**Main findings**

**R3**

**N=10 clean samples per class**

**N=30 clean samples per class**

---

**Main findings**  
**R3**  
**N=10 clean samples per classe**  
**N=30 clean samples per classe**  

---

**Main findings**   
**R3**  
**N = 10 clean samples per class**  
**N = 30 clean samples per class**  

---

**Main Findings**  
**R3**  

**N=10 clean samples**  
**N=30 clean**  

---

**Main Finding**  
**R3**  
  
**N=10 clean samples**   
**N=30 clean samples**  

---

**Main finding**  
**R3**  
N=10 clean samples  
N=30 clean samples  

---

**Main findings  
R3  
N=10 clean samples   N=30 clean samples  

---</sample>
    <sample id="932">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**Hauptbefunde**

**N=10 saubere Proben pro Klasse**

| Klasse | Vor CFT | Nach CFT |
| --- | --- | --- |
| Klasse 1 | 80% | 82% |
| Klasse 2 | 78% | 80% |
| Klasse 3 | 76% | 78% |
| Klasse 4 | 74% | 76% |
| Klasse 5 | 72% | 74% |
| Klasse 6 | 70% | 72% |
| Klasse 7 | 68% | 70% |
| Klasse 8 | 66% | 68% |
| Klasse 9 | 64% | 66% |
| Klasse 10 | 62% | 64% |

**N=30 saubere Proben pro Klaspe**

| Klasse | Vor-CFT | Nach-CFT |
| --- | --- | ---
| Klasse 1 | 78% | 80 |
| Klasse 2 |76% | 78 |
| Klasse 3 |74% | 76 |
| Klasse 4 |72% | 74 |
| Klasse 5 |70% | 72 |
| Klasse 6 |68% | 70 |
| Klasse 7 |66% | 68 |
| Klasse 8 |64% | 66 |
| Klasse 9 |62% | 64 |
| Klasse 10|60% | 62 |
| Klasse 11|58% | 60 |
| Klasse 12|56% | 58 |
| Klasse 13|54% | 56 |
| Klasse 14|52% | 54 |
| Klasse 15|50% | 52 |
| Klasse 16|48% | 50 |
| Klasse 17|46% | 48 |
| Klasse 18|44% | 46 |
| Klasse 19|42% | 44 |
| Klasse 20|40% | 42 |
| Klasse 21|38% | 40 |
| Klasse 22|36% | 38 |
| Klasse 23|34% | 36 |
| Klasse 24|32% | 34 |
| Klasse 25|30% | 32 |
| Klasse 26|28% | 30 |
| Klasse 27|26% | 28 |
| Klasse 28|24% | 26 |
| Klasse 29|22% | 24 |
| Klasse 30|20% | 22 |

**Hauptbefunde:**

**N=10 saubre Proben pro Klasse**

- Klasse 1: 80% vor CFT, 82% nach CFT
- Klasse 2: 78% vor CFT, 80% nach CFT
- Klasse3: 76% vor CFT, 78% nach CFT
- Klasse4: 74% vor CFT, 76% nach CFT
- Klasse5: 72% vor CFT, 74% nach CFT
- Klasse6: 70% vor CFT, 72% nach CFT
- Klassec7: 68% vor CFT, 70% nach CFT
- Klassec8: 66% vor CFT, 68% nach CFT
- Klassec9: 64% vor CFT, 66% nach CFT
- Klassec10: 62% vor CFT, 64% nach CFT

**N=30 saubre Proben pro Klaspe**

- Klasse1: 78% vor CFT,80% nach CFT
- Klassc2:76% vor CFT,78% nach CFT
- Klassc3:74% vor CFT,76% nach CFT
- Klassc4:72% vor CFT,74% nach CFT
- Klassc5:70% vor CFT,72% nach CFT
- Klassc6:68% vor CFT,70% nach CFT
- Klasscc7:66% vor CFT,68% nach CFT
- Klasscc8:64% vor CFT,66% nach CFT
- Klasscc9:62% vor CFT,64% nach CFT
- Klasscc10:60% vor CFT,62% nach CFT
- Klasscc 11:58% vor CFT,60% nach CFT
- Klass cc 12:56% vor CFT,58% nach CFT
- Klass cc13:54% vor CFT,56% nach CFT
- Klass cc4:52% vor CFT,54% nach CFT
- Klass cc5:50% vor CFT,52% nach CFT
- Klass cc6:48% vor CFT,50% nach CFT
- Klass ccc7:46% vor CFT,48% nach CFT
- Klass cccc8:44% vor CFT,46% nach CFT
- Klass ccccc9:42% vor CFT,44% nach CFT
- Klass ccccccccc10:40% vor CFT,42% nach CFT
- Klass c c c c c c c c c c 11:38% vor CFT,40% nach CFT
- Klassccc c c c c c c c c c12:36% vor CFT,38% nach CFT
- Klassccc 13:34% vor CFT,36% nach CFT
- Klassccc14:32% vor CFT,34% nach CFT
- Klassccc5:30% vor CFT,32% nach CFT
- Klassccc6:28% vor CFT,30% nach CFT
- Klasscccc7:26% vor CFT,28% nach CFT
- Klasscccc8:24% vor CFT,26% nach CFT
- Klasscccc9:22% vor CFT,24% nach CFT
- Klasscccc10:20% vor CFT,22% nach CFT

**Hauptbefunde**:

**N=10 saubr Proben pro Klasse**</sample>
    <sample id="933">**Main findings**  
- **Continuous fine-tuning (CFT) eliminates performance gaps between WSL approaches.**  
- **No need to use complicated WSL methods (FT) performs equally well.**</sample>
    <sample id="934">**Schlussfolgerung**  
**Neuere WSL Ansätze**  
- Benötigen saubere Proben.  
- Überschätzen die Praktikabilität.  
**Unsere Empfehlungen**  
- Berichten Sie die Modellauswahlkriterien.  
- Verwenden Sie wenigstens eine Lernansatz als Basiskriterien.  
- Wenden Sie ständig kontinuierliches Feinabstimmung (CFT) an.</sample>
    <sample id="935">**Schlussfolgerung**  
**Neue WSL Ansätze**  
- Benötigen saubere Proben.  
- Überschätzen ihre Praktikabilität.  
**Unsere Empfehlungen**  
- Berichten Sie die Modellauswahlkriterien.  
- Verwenden Sie wenigstens eine Lernansatz als Basiskriterien.  
- Wenden Sie immer kontinuierliches Feinabstimmung (CFT) an.</sample>
    <sample id="936">**Schlussfolgerung**  
**Neue WSL Ansätze**  
- Benötigen saubere Proben.  
- Überschätzen ihre Praktikabilität.  
**Unsere Empfehlungen**  
- Berichten Sie die Modellauswahlkriterien.  
- Verwenden Sie wenigstens eine Lernansatz als Baselines.  
- Wenden Sie kontinuierliches Feinabstimmung (CFT) an.</sample>
    <sample id="937">**Schlussfolgerung**  
**Neue WSL Ansätze**  
- Benötigen saubere Proben.  
- Überschätzen die Praktikabilität.  
**Unsere Empfehlungen**  
- Berichten Sie die Modellauswahlkriterien.  
- Verwenden Sie wenigstens eine Fünf-Schnitt-Lernansatz als Baselines.  
- Wenden Sie immer kontinuierliches Feinabstimmung (CFT) an.</sample>
    <sample id="938">**Schlussfolgerung**  
**Neue WSL Ansätze**  
- Benötigen saubere Proben.  
- Überschätzen ihre Praktikabilität.  

**Unsere Empfehlungen**  
- Berichten Sie die Modellauswahlkriterien.  
- Verwenden Sie wenigstens eine wenigstens eine wenigste wenigste wenigste w</sample>
    <sample id="939">Gängige Bewertungsmethoden für Dialoge Systeme sind:

* **Vergleichende Bewertung:** Hierbei werden zwei oder mehrere Systeme miteinander verglichen, um ihre Leistung zu bewerten. Dies kann durch direkte Interaktion mit den Systemen oder durch die Analyse von Benutzerfeedback erfolgen.
* **Likert-Bewertung:** In dieser Methode werden Benutzer auf einer Skala von 1 bis 5 bewertet, wie gut sie das System finden. Diese Methode ist einfach zu implementieren und liefert schnelle Ergebnisse.

Beide Methoden haben ihre Vor- und Nachteile und können je nach Anwendungsfall und Zielgruppe eingesetzt werden.</sample>
    <sample id="940">5</sample>
    <sample id="941">Das Hintergrundwissen, das im Beispiel mit Servin und Ke a benötigt wird, ist, dass Richter Entscheidungen in Gerichten treffen.</sample>
    <sample id="942">Ja, der Code ist verfügbar. Sie finden ihn auf GitHub unter dem Namen "mpeoms/kitmus".</sample>
    <sample id="943">No, the annotators for NLPositionality are not balanced across each demographic group, such as country, gender, etc.</sample>
    <sample id="944">Sätze innerhalb der akzeptbaren Domain wurden durch das Verschieben von Subjekten und Objekten innerhalb der Sätze durcheinander gebracht.</sample>
    <sample id="945">Eine dimensionale Bewertung bedeutet, dass die Qualität eines Dialogs an verschiedenen Aspekten gemessen wird, wie Relevanz, Konsistenz und emotionale Verständlichkeit.</sample>
    <sample id="946">Beijing Jianzhu University.</sample>
    <sample id="947">Die Form des Prompts ist wichtig, um die Klarheit und Genauigkeit der Übersetzung zu gewährleisten.</sample>
    <sample id="978">Die Autoren haben die folgenden Dialogmodelle evaluiert:

- **BERT-HD-RAG**
- **Blender2**
- **Emory**
- **Blender Decote**

Diese Modelle wurden verwendet, um die ABC-Eval Error Rates zu messen, die die Leistung der Modelle bei der Beantwortung verschiedener Dialogarten und Fragen zu bewerten.</sample>
    <sample id="979">Es sind 10 Autoren an der Arbeit beteiligt.</sample>
    <sample id="980">Ein guter Planer sollte klar, strukturiert und flexibel sein, um verschiedene Ziele und Bedingungen berücksichtigen zu können.</sample>
    <sample id="981">7</sample>
    <sample id="982">The presenter's name is Vasudha Varadarajan.</sample>
    <sample id="983">Universität Warschau.</sample>
    <sample id="1021">Die häufigsten Fehler von PaLm sind **Accuracy/Omission** und **Style/Awkward**.</sample>
    <sample id="1022">Die englische Übersetzung des Inhalts lautet:

---

**Titel:** Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems

**Autoren:** Sarah E. Finch, James D. Finch, und Jinho D. Choi

**Institutionen:** Emory University, Emory NLP Research Lab, Amazon

---

**Titel:** Vergiss nicht deine ABC's: Bewertung des Standes der Technik in Chatorientierten Dialogsystemen

**Autoren:** Sarah E. Fincke, James D. Fincke und Jinho D. Choi

**Institute:** Emory University, Emory NLP Forschungslabor, Amazon</sample>
    <sample id="1023">Die englische Übersetzung des Inhalts lautet:

"Vergeblich Ihre ABC's: Bewertung der State-of-the-Art in Chat-georientierten Dialogsystemen"
Sarah E. Finch, James D. Finch und Jinho D. Choi

Emory University, Emory NLP Research Lab, Amazon</sample>
    <sample id="1024">Die englische Übersetzung des Inhalts lautet:</sample>
    <sample id="1025" />
    <sample id="1026">Die Übersetzung des englischen Inhalts in Deutsch lautet:</sample>
    <sample id="1027">Dimensions of Dialogue Quality</sample>
    <sample id="1028">**Likert-Rating-Evaluation**  

**Bildbeschreibung:**  
Das Bild zeigt eine visuelle Darstellung der Likert-Rating-Evaluation, die verwendet wird, um die Relevanz der Antworten eines Bots zu bewerten. Es besteht aus einem Diagramm mit fünf Schritten, die von 1 (sehr ungültig) bis 5 (sehr relevant) reichen. Jeder Schritt ist mit einem Punkt markiert, um die Relevanz zu bewerten.  

**Texte und Symbole:**  
- **Titel:** "Likert-Rating-Evaluation"  
- **Bild:**  
  - Links: Ein Mann mit langen weißen Haaren, der ein Gewicht in der Hand hält.  
  - Rechts: Ein Bild eines Bots mit einem Kopf und einem Körper.  
  - Zwischen den beiden Figuren sind drei Blöcke, die als Schritte im Likert-Skala dargestellt sind.  
  - Jeder Block ist mit einem Punkt markiert, um den Schritt zu identifizieren.  
  - Die Blöcke sind in einer Reihenfolge von 1 bis 5 angeordnet.  
  - Die Blöcke werden mit einem grünen Haken markiert, um den Schritt zu unterstreichen.  
- **Text:** "Rate die Relevanz der Bots' Antworten."  
- **Logo:** "Emory University" und "Alexa"  

**Analyse:**  
Die Likert-Rating-Evaluation ist ein weit verbreitetes Verfahren zur Bewertung der Relevanz von Antworten oder Aussagen. In diesem Fall wird die Relevanz eines Bots bewertet, indem die Schritte von 1 bis 5 bewertet werden. Die Bilder und Symbole helfen, die Prozess visuell darzustellen und die Relevanz zu verdeutlichen.</sample>
    <sample id="1029">Das Video zeigt eine Präsentation über die Bewertung von Chatbots in Bezug auf ihre Relevanz. Die Präsentation beginnt mit einer Übersicht über die ABC-Evaluation, die die Relevanz von Chatbots bewertet. Dann wird die Analyse von Chatbots durchgeführt, um ihre Relevanz zu bewerten. Die Präsentation endet mit einer Zusammenfassung der Ergebnisse der ABC-Evaluation.</sample>
    <sample id="1030">Das Bild ist ein digitales Diagramm, das die Analyse von Chat-Verhaltensmuster in der Kommunikation beschreibt. Es zeigt eine Sequenz von Nachrichten, die in verschiedenen Farben und Größen dargestellt werden. Die größten Nachrichten sind in blau und die kleinsten in grau. Die Nachrichten sind in einem Bildschirm mit einem weißen Hintergrund angeordnet. Die Analyse der Verhaltensmuster in der Kommun</sample>
    <sample id="1031">Das Bild ist ein digitales Screenshot eines Präsentationsfolienes mit dem Titel "ABC-Eval-Verhaltens" (ABC-Eval-Verhalten). Es besteht aus einem Hauptbild mit einem weißen Hintergrund und einem blauen Titelbereich. Im Titelbereich befindet sich der Titel "ABC-Eval-Verh...</sample>
    <sample id="1032">Die Bildergalerie zeigt eine PowerPoint-Präsentation mit dem Titel "ABC-Eval-Verhaltens" (ABC-Eval-Verhalten). Die Präsentation besteht aus vier Hauptbereichen, die in einem 2x2-Feldbreite angeordnet sind:

1. **Coherence (Kohärenz)**:
   - Dieser Bereich bezieht sich auf die logische Konsistenz und Kohärenz in der Kommunikation.
   - Es wird betont, dass die Partner ihre Aussagen und Handlungen in Einklang bringen sollten, um eine klare und verständliche Kommunikation zu gewährleisten.

2. **Knowledge (Wissen)**:
   - Dieser Bereich betrifft das Wissen und die Informationen, die die Partner teilen.
   - Es wird betont, wie wichtig es ist, dass die Partner ihre Wissen und Erfahrungen mit einander teilen, um eine fundierte und informierte Kommunikation zu ermöglichen.

3. **Consistency (Konsistenz)**:
   - Dieser Bereich beschreibt die Stabilität und Kontinuität in der Kommunikation.</sample>
    <sample id="1033" />
    <sample id="1034">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**ABC-Eval Verhaltensweisen**

- **Kohärenz**
  - Ignorieren Partner
  - Irrelevant
- **Konsistenz**
  - Selbstwiderspruch
  - Partnerwiderspruch
- **Emotionale Verständlichkeit**
  - Empathischer Antwort
  - Fehlende Empathie
- **Wissen**
  - Falsche Tatsache
  - Verständnisfehler

---

**Experimente**

- **4 Open-Domain-Dialog-Modelle**
- **100 mensch-bot-Konversationen pro Modell**

---

**ABC-Eval**

- **ABC-Eval** ist ein Modell, das versucht, die Verhaltensweisen von KI-Systemen zu bewerten. Es bietet eine strukturierte Methode, um die Fähigkeiten von KI-Systemen in Bezug auf Kohärenz, Konsistenz und emotionale Verständlichkeit zu analysieren.

---

**Experiments**

- **4 Open-Domain Dialog Models**
- **100 Human-Bot Conversations per Model**

---

**ABC-Evaluation**

- **ABC-Evaluation** ist ein Modell, das versuchte, die Verhaltensweisen von künstlichen Intelligenz-Systemen zu bewerten. Er bietet eine strukturierte Meth</sample>
    <sample id="1035">Das Bild ist ein PowerPoint-Slide, der die Ergebnisse einer Experimentelle Studie über Open-Domain-Dialog-Modelle zeigt. Die Studie hat vier Open-Domain-Dialog-Modelle durch 100 menschliche-Bot-Konversationen getestet. Die Studie wurde von Emory University und Alexa durchgeführt.</sample>
    <sample id="1036">Die Übersetzung des englischen Inhalts in Deutsch lautet:</sample>
    <sample id="1037">The video presents a detailed analysis of inter-annotator agreement in evaluating dialogue systems. It begins with a slide titled "Inter-Annotator Agreement," which introduces the concept of measuring the consistency between different annotators' evaluations of dialogue systems. The slide features a graph with the x-axis labeled "Krippendorff's Alpha" and the y-axis labeled "Inter-Annotator Agreement." The graph shows various methods of evaluation, including ABC-Eval, Turn Likert, Dialogue Likert, and Comparative, each represented by different colored lines. The graph indicates that the Krippendorff's Alpha values for these methods range from 0.2 to 0.8, with some methods showing higher agreement than others. The slide also includes a note at the bottom mentioning that the data is from Emory University and Alexa.

The video then transitions to a slide titled "Inter-Annotator Agreement" with a graph similar to the previous one. This graph shows the Krippendorff's Alpha values for different methods of evaluation, including ABC-Eval, ABC-Val, Turn Likert, Dialogue Likert, Comparative, and ABC-Val. The graph indicates that the Krippendor</sample>
    <sample id="1038">Das Bild zeigt ein Diagramm mit dem Titel "Predictive Validity". Es besteht aus zwei Hauptteilen: eine horizontal angeordnete Liste von verschiedenen Methoden oder Techniken, die in der Forschung verwendet werden, und eine vertikale Liste, die die Prozentsätze der erklärten Qualität für jede Methode anzeigt. Die Methode "ABC-Eval" hat die höchste Prozentsätze der erklärte Qualität, gefolgt von "Turn Likert" und "Dialogue Likert". Die Methode "Comparative" hat die niedrigste Prozentsätze der erklärt Qualität. Die Diagramme zeigt, wie die erklärte Qualität für jede Methode variiert.</sample>
    <sample id="1039" />
    <sample id="1040">Das Video analysiert die Prädiktive Validität und die Inkrementelle Validität verschiedener Qualitätsmetriken in Dialogsystemen. Es zeigt, wie viele Prozente der Qualitätsschätzungen erreicht werden können, basierend auf verschiedenen Qualitätsmetriken wie ABC-Eval, Turn Likert, Dialogue Likert und Comparative. Die Prädiktive Validität zeigt, wie viele Prozente von den Qualitätsschätzungen erreicht werden können, während die Inkrementelle Validität zeigt, wie viele Prozesse erreicht werden müssen, um eine bestimmte Qualitätsschätzung zu erreichen.</sample>
    <sample id="1041">Das Bild zeigt einen Diagramm mit dem Titel "Incremental Validity" (Zusätzliche Güte) und zeigt drei verschiedene Kurven, die die Validität von verschiedenen Kriterien über die Zeit verfolgen. Die Kurven sind farbig und markieren verschiedene Aspekte der Validität, wie z.B. "Turn Likert" (Turn-Likert) und "Dialog Likert" (Dialog-Likert). Die Legende am unteren Rand des Diagramms zeigt, welche Aspekte der Validität jede Kurve darstellt. Das Diagramm wird von einem Person in einem Video-Conference-Modus präsentiert, der in der oberen rechten Ecke des Bildes zu sehen ist.</sample>
    <sample id="1042">Das Bild zeigt einen Diagramm mit dem Titel "Incremental Validity" (Incremental Validität). Es besteht aus einem Hauptdiagramm und einem Nebendiagramm.

### Hauptdiagramm:
- **X-Achse:** Die X-Achse ist in 10%-Intervallen von 0% bis 100% markiert.
- **Y-Achse:** Die Y-Achse ist in 0,250-Einheiten von 0,000 bis 0,250 markiert.
- **Linien:** Es gibt drei verschiedene Linien, die sich im Diagramm überlagern:
  - Eine rote Linie, die von 0,250 auf 0,000 absteigt.
  - Eine blaue Linie, die von 0,000 auf 0,250 steigt.
  - Eine gelbe Linie, die von 0,075 auf 0,250 steigt und dann von 0,250 auf 1,000 steigt.

### Nebendiagramm:
- **X-Achsenbeschriftung:** Die X-Achse ist in 25%-Intervallen von 0% bis 25% markiert.
- **Y-Axenbeschriftung:** Die Y-Achse ist in 10%-Intervallen von 0% bis</sample>
    <sample id="1043" />
    <sample id="1044">The video presents a bar chart titled "ABC-Eval Error Rates by Model," which compares the error rates of different models across various categories. The chart is divided into two main sections: the x-axis lists the categories, and the y-axis shows the percentage of errors. Each category is represented by a set of bars, each corresponding to a different model. The models include "BERT-HF-RAG," "Blender2," "Emory," and "Blender Decole." The error rates are color-coded, with green bars indicating lower error rates and red bars indicating higher error rates. The chart highlights the performance of each model in different categories, with some models performing better in certain categories than others. The video also includes a note at the bottom of the chart, which states that the error rates are based on a specific dataset and evaluation metric. The video concludes with a summary of the findings and a discussion of the implications of the results.</sample>
    <sample id="1045">The video presents a bar chart titled "ABC-Eval Error Rates by Model," which compares the error rates of different models across various categories. The chart is divided into two main sections: the x-axis lists the categories, and the y-axis shows the percentage of errors. Each category is represented by a set of colored bars, with each bar corresponding to a different model. The models are labeled as "BERT-HF-RAG," "Blender2," "Emora," and "Blender Decole." The error rates are color-coded, with green bars indicating lower error rates and red bars indicating higher error rates.

The video highlights specific categories with yellow arrows pointing to them, indicating that these categories have higher error rates. The categories with the highest error rates are "Topic Switch" and "Uninterpretable," with error rates exceeding 20%. The categories with the lowest error rates are "Antisocial," "CS-Centre," and "Irrelevant," with error rates below 10%.

The video also includes a legend at the bottom of the chart, which explains the color coding of the error rates. The legend shows that green bars represent lower error rates, while red bars represent higher error rates. The video concludes with a summary of the findings, emphasizing the importance of understanding the error rates of different models in order to improve their performance.</sample>
    <sample id="1046">The video shows a bar chart titled "ABC-Eval Error Rates by Model" with various error rates for different models. The chart includes bars representing different error rates for each model, with the x-axis showing the error rates and the y-axis showing the models. The chart also includes a legend that explains the different error rates. The video ends with a slide that says "Thank you for watching."</sample>
    <sample id="1047" />
    <sample id="1048">Emory University.</sample>
    <sample id="1049">Continuous fine-tuning.</sample>
    <sample id="1050">Es sind 7 Autoren an der Arbeit beteiligt.</sample>
    <sample id="1051">Wann benötigt Übersetzung Kontext? Eine datengetriebene, mehrdimensionale Erkundung</sample>
    <sample id="1052">Wir müssen das Mäusefädchen loswerden.</sample>
    <sample id="1053">Wenn die Minister herausfinden, könnte es gefährlich werden. Wir müssen den Maul reinwerfen.</sample>
    <sample id="1054">Könnte es etwas ernstes sein, Doktor? Wir werden das Mäusefleck haben müssen.</sample>
    <sample id="1055">Bewertung von kontextabhängiger Übersetzung ist schwer

- Nur ein kleiner Teil der Wörter hängt von Kontext ab

Bild: Drei gestapelte Papiere mit einem grauen Pfeil, der von oben nach unten zeigt, wie man die Übersetzung bewertet.</sample>
    <sample id="1056">Bewertung von kontextabhängiger Übersetzung ist schwer

- Nur ein kleiner Teil der Wörter hängt von Kontext ab
- Korpusniveau-Metriken
- Bestehende Methoden unterstützen begrenzte Diskurse
- Phänomene und Sprachen</sample>
    <sample id="1057">Die Übersetzung benötigt Kontext, um die Bedeutung korrekt zu verstehen und die richtige Wortwahl zu treffen. Modelle können Kontextabhängige Übersetzungen gut behandeln, indem sie den Kontext berücksichtigen und passende Wörter und Phrasen auswählen.</sample>
    <sample id="1058">Die Übersetzung benötigt Kontext, um die Bedeutung von Wörtern korrekt zu verstehen und in den richtigen Kontext zu verwenden. Modelle können Kontextabhängiges Übersetzen gut behandeln, indem sie den Kontext berücksichtigen und die Wörter entsprechend anpassen.</sample>
    <sample id="1059">Conditional Cross-Mutual Information (CXMI)</sample>
    <sample id="1060">**Übersetzung des englischen Inhalts ins Deutsche:**</sample>
    <sample id="1061">**Punktweise (P-)CXMI**  
Wir führen P-CXMI ein, um den Kontextverwendung zu messen, um eine bestimmte</sample>
    <sample id="1062">Die Übersetzung benötigt Kontext in folgenden Fällen:

- Wortebene Kontextverwendung
- thematische Analyse</sample>
    <sample id="1063">Die englischen Texte im Video sind:

1. "Thematic analysis of high P-CXMI words"
2. "Thematic analysis of high P-CXM1 words"
3. "Thematic analysis of high P-CXI words"
4. "Thematic analysis of high P-CXL words"
5. "Thematic analysis of high P-CXXI words"
6. "Thematic analysis of high P-CXXXI words"
7. "Thematic analysis of high P-CXXXXI words"
8. "Thematic analysis of high P-CLXXXI words"
9. "Thematic analysis of high P-CMXXXI words"
10. "Thematic analysis of high P-CMXLXXXI words"
11. "Thematic analysis of high P-CLXXXLXXXI words"
12. "Thematic analysis of high P-CCLXXXLXXXI words"
13. "Thematic analysis of high P-CCCXLXXXI words"
14. "Thematic analysis of high P-CCCCXLXXXI words"
15. "Thematic analysis of high P-</sample>
    <sample id="1064">Thematische Analyse von häufig verwendeten Wörtern mit hohem P-CXMI-Wert</sample>
    <sample id="1065">Thematic analysis of high P-CXMI words</sample>
    <sample id="1066">Thematic analysis of high P-CXMI words</sample>
    <sample id="1067">Thematische Analyse von häufig verwendeten Wörtern (P-CXMI-Wörter)</sample>
    <sample id="1068">Thematische Analyse von häufig verwendeten Wörtern mit hoher P-CXMI-Werten

1. POS-Tags
2. Wortarten

- Pronomen
- Verbform
- Lexikalische Kohäsion
- Formelität</sample>
    <sample id="1069">Thematische Analyse von hoch relevanten Wörtern (P-CXMI-Wörtern)</sample>
    <sample id="1070">Thematische Analyse von hoch relevanten P-CXMI-Wörtern</sample>
    <sample id="1071">1. **RQ1: Wann benötigt Übersetzung Kontext?**
   - Wortebene Kontextnutzung
   - thematische Analyse

2. **RQ2: Wie gut handeln Modelle kontextabhängige Übersetzungen?**
   - Mehrsprachige Diskursbewusst (MuDA) Benchmark</sample>
    <sample id="1072">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Multilingual Discourse-Aware (MuDA) Tagger**

- **Pronouns**
- **Verb form**
- **Lexical cohesion**
- **Formality**
- **Ellipsis**

---

**Multilingual Discursive-Aware (MuDA) Tagger**  
- **Pronouns**  
- **Verb form**  
- **Lexical cohesion**  
- **Formality**  
- **Ellipsis**  

---

**Multilingual Discours-Aware (MuDA) Tagger** 
- **Pronouns**  
  - **Verb form**  
  - **Lexical cohesion**  
  - **Formality**  
  - **Ellipsis**  

---</sample>
    <sample id="1073" />
    <sample id="1074">Das Video beginnt mit einem Diagramm, das die Prozesse der MuDA-Benchmark-Analyse zeigt. Es zeigt, wie Texte analysiert werden, um die Kontextabhängigkeit der Übersetzungen zu bewerten. Der Prozess beginnt mit der Analyse von Texten, um herauszufinden, welche Kontextinformationen benötigt werden. Anschließend wird die Analyse auf die Thematisierung der Texte eingeschränkt, um sicherzustellen, dass die Übersetzungen den Kontext korrekt widerspiegeln. Schließlich wird die Analyse auf die Berechnung von BLEU und COMET-F-Score ausgelegt, um die Qualität der Übersetzungen zu bewertet. Der Prozess endet mit der Analyse der Ergebnisse, um herauszufinden wie gut die Modelle die Kontextabhängigkeit der Über</sample>
    <sample id="1075">1. **RQ1: Wann benötigt Übersetzung Kontext?**
   - Wortebene Kontextnutzung
   - thematische Analyse

2. **RQ2: Wie gut handeln Modelle kontextabhängige Übersetzungen?**
   - Mehrsprachige Diskursbewusstsein (MuDA) Benchmark
   - Modellbewertung</sample>
    <sample id="1076">Das Video beginnt mit einer schwarzen und weißen Darstellung eines korpusweisen Metriks, das als "BLEU" bezeichnet wird. Der Text "CORPUS-LEVEL METRICS" wird oben auf dem Bild platziert. In der rechten oberen Ecke befindet sich ein weißer Kreis mit einer schwarzen Person darin. Der Kreis bleibt statisch, während die Person in der Ecke nur leicht verschiebt. Der Bildinhalt bleibt dauerhaft gleich, und es tritt keine Veränderung oder Bewegung auf.</sample>
    <sample id="1077">Das Video zeigt eine Reihe von korpusbasierten Metriken, darunter BLEU, COMET und F-Messung, mit einem Robot-Symbol, das das Wort "CONTEXT" trägt. In der oberen rechten Ecke ist ein Porträt einer Person zu sehen. Der Text in der Unterteilung lautet: "Unclear which system is best for document-level MT with corpus-level metrics".</sample>
    <sample id="1078" />
    <sample id="1079">**MuDA Benchmark Ergebnisse**  
- Kontextbewusste Modelle erzielen signifikant bessere Ergebnisse bei bestimmten Phänomenen  
- ✅: Formulierungen, lexikalische Kohäsion  
- ❌: Ellipsen, Pronomen, Verben</sample>
    <sample id="1080">Das Video zeigt eine Präsentation über die Ergebnisse des MuDA Benchmark, das die Leistung von Kontext-bewussten Modellen in verschiedenen Sprachverarbeitungsaufgaben untersucht. Die Präsentation beginnt mit einer Liste von Punkten, die die wichtigsten Ergebnisse des Benchmarks zusammenfassen:

- Kontext-bewusste Modelle erzielen signifikant bessere Ergebnisse bei bestimmten Phänomenen.
- Kontext-bewusste Model</sample>
    <sample id="1081" />
    <sample id="1082">Die englische Präsentation wird in Deutsch übersetzt:</sample>
    <sample id="1083">Zusammenfassung:
- Identifizieren von Diskursphänomenen systematisch ohne vorheriges linguistisches Wissen
- Datensetunabhängiger Benchmark für Dokument-Level-Maschinenübersetzung</sample>
    <sample id="1084">Yusen Zhang</sample>
    <sample id="1121">Permuting with "jumps"</sample>
    <sample id="1122">Die Autoren beschreiben die Methode der "markierten Wörter" als die Identifizierung von Wörtern, die Personen von markierten Gruppen von unmarkierten Gruppen unterscheiden.</sample>
    <sample id="1123">Cambridge University.</sample>
    <sample id="1124">Moscow.</sample>
    <sample id="1125">Sarah E. Finch</sample>
    <sample id="1126">Vier Autoren sind an der Arbeit beteilt.</sample>
    <sample id="1127">SyntaxGym und CrowS.</sample>
    <sample id="1161">FT, COSINE, MLC, L2R, BOND</sample>
    <sample id="1162">Das Modell wird an 11 Aufgaben evaluiert.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich mit 400 GB von Common Crawl-Daten trainiert.</sample>
    <sample id="1227">Adam Przepiórkowski</sample>
    <sample id="1228">Die Ergebnisse, dass die Leistung mit größeren zeitlichen Abständen abnimmt, führten zur Schlussfolgerung, dass die zeitin der Verzögerung die Haupturscheinung für den Leistungsverlust war.</sample>
    <sample id="1269">Um die Ausgabesequenz korrekt zu generieren, müssen die Token für die Ausgabesequenze permutiert werden, um die korrekte Reihenfolge der Wörter zu gewährleisten.</sample>
    <sample id="1270">Die Autoren empfehlen es Modellentwicklern, ihre Methoden zum Abbau von Vorübergehenden Transparenz zu erhöhen, um die Glaubwürdigkeit und Reproduzierbarkeit ihrer Arbeiten zu erhöhen und um die Verbreitung von Wissen und Innovation zu fördern.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind solche, bei denen die beiden Sätze in der Reihenfolge der Wörter unterschiedlich sind, aber die Bedeutung gleich bleibt. Beispiele sind:

1. "Viele Menschen halfen sich selbst." und "Viele Menschen wurden helfen."
2. "Kein Kunde hatte Geld ausgegeben." und "Der Kunde hatte Geld ausgegebnen."

Diese Beispiele zeigen, dass die Reihenfolge der Wörter in einem Satz die Bedeutung beeinflussen kann, obwohl die Wörter selbst unverändert sind.</sample>
    <sample id="1272">Die Autoren haben die folgenden Bewertungsmetriken verwendet:

- **F1-Score**: Ein Maß für die Genauigkeit und Präzision, das die harmonische Mittelwert von Präzision und Erinnerung darstellt.
- **Precision**: Die Anzahl der wahren positiven Vorhersagen geteilt durch die Anzahl aller positiven Vorhersagen.
- **Recall**: Die Anzahl der wahren positven Vorhersagen geteilt durch die Anzehl aller tatsächlichen positiven Beispiele.
- **Accuracy**: Die Anzahl der richtigen Vorhersagen geteilt durch die Gesamtanzahl aller Beispiele.
- **AUC-ROC**: Die Fläche unter der ROC-Kurve, die die Leistung eines Modells in Bezug auf die Fähigkeit, Klassen zu unterscheiden, misst.
- **NRMSE (Normalized Root Mean Square Error)**: Ein Maß für die Abweichung zwischen den vorhergesagten und den tatsächlichen Werten, normalisiert auf den Bereich der Daten.
- **NRMSE (Normalized Relative Mean Square Error)**: Ein weiteres Maß für die Abweichung zwische den vorhergesagten und den t</sample>
    <sample id="1273">Krippenbaums Alpha wurde verwendet, um die Überstimmung zwischen den Kommentatoren gemessen.</sample>
    <sample id="1274">Die Domain, die gewählt wurde, um völlig unzusammengehörige Sätze zu den inakzeptabel und akzeptablen Suchanfrag</sample>
    <sample id="1275">Heinrich Heine University Düsseldorf.</sample>
    <sample id="1276">MultiInstruct is a benchmark that focuses on multimodal instruction tuning, which involves training models to understand and generate instructions that combine text and visual information. Unlike other benchmarks that may focus on single-modal tasks (e.g., text-only or image-only), MultiInstruct specifically addresses the challenges of multimodal instruction tuning.</sample>
    <sample id="1277">Drei.</sample>
    <sample id="1278">Die binäre Koordination ist eine Art der Sprachkommunikation, bei der zwei Personen direkt miteinander sprechen. Es handelt sich um eine direkte Kommunikation, bei der die beiden Personen in der Lage sind, ihre Gedanken und Gefühle direkt zu teilen. Die binäre Koordination ist eine wichtige Form der Kommunikation, die in vielen Bereichen des Lebens verwendet wird, wie zum Beispiel in der Familie, in der Schule und in der Arbeit.</sample>
    <sample id="1279">Die in dieser Studie verwendeten Promp</sample>
    <sample id="1280">Das kleinere T5-Modell, das auf Coscript fine-tuned wurde, erzielt eine höhere Genauigkeit als die großen LLMs.</sample>
    <sample id="1281">DrBERT: Ein robustes vorge-trainiertes Modell in französischer Sprache für biomedizinische und klinische Bereiche</sample>
    <sample id="1282">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Zusammenfassung**

I. Sprachmodellierung in der Gesundheitsversorgung

II. Vergleich von vorgebauten Strategien, Datenquellen und Größen

III. Bewertung von 13 Modellen auf 11 Aufgaben

IV. Verteilung von NACHOS und DrBERT

---

**Zusammentragen**

I. Sprachmodellierungen in der Gesundheitsversorgung  
II. Vergleich von vorgeplanten Strategien, Datenquellen und Gewichten  
III. Bewertung von 3 Modellen auf 11 Aufgabentasks  
IV. Verteilung von Nächos und DrBERT

---

**Summary**

I. Language Modeling in Healthcare  
II. Comparison of pre-training strategies, data sources and sizes  
III. Evaluation of 13 models on 11 tasks  
IV. Distribution of NACHOS and DrBERT  

---

**Zusammanfassung**

I. Sprachkontext in der Gesundheitsversorgung</sample>
    <sample id="1283">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Zusammenfassung**

I. Sprachmodellierung in der Gesundheitsversorgung

II. Vergleich von vorgeplanten Strategien, Datenquellen und Größen

III. Bewertung von 13 Modellen auf 11 Aufgaben

IV. Verteilung von NACHOS und DrBERT

---</sample>
    <sample id="1284">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Zusammenfassung**

I. Sprachmodellierung in der Gesundheitsversorgung

II. Vergleich von vorgeplanten Strategien, Datenquellen und Größen

III. Bewertung von 13 Modellen auf 11 Aufgaben

IV. Verteilung von NACHOS und DrBERT

---</sample>
    <sample id="1285">1. Sprachmodellierung in der Gesundheitsversorgung
2. Vergleich von vorgefertigten Strategien, Datenquellen und Größen
3. Bewertung von 13 Modellen auf 11 Aufgaben
4. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1286">Der englische Text beschreibt die Anwendung von Transformer-basierten Ansätzen wie BERT auf eine Vielzahl von NLP-Aufgaben und deren Leistungssteigerung. Es wird erwähnt, dass diese Ansätze auf Französisch angepasst wurden, insbesondere mit Camembert und FlauBert. Im Bereich medizinischer Aufgaben haben englische spezifische Modelle die Leistungsbarriere weiter erhöht. Beispiele für solche Modelle sind PubMedBERT, BioBERT, ClinicalBERT und andere. Für Sprachen anderer als Englisch sind kontinuierliche Voraussetzungen für die Anpassung an die spezifischen Anforderungen der Medizin weniger wichtig. Im Gegensatz zu allgemeinen Modellen gibt es für den medizinischen Bereich in Französisch noch keine offene Quelle. Ein BERT-basiertes spezifisches Modell für Französisch soll die Leistung bei medizinischen Aufgaben erhöhen.</sample>
    <sample id="1287">Der englische Text lautet:

"Language Modeling

Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks.

Has been adapted to French with Camembert and FlauBert.

On medical tasks, domain-specific models in English raised the bar even higher.

PudMedBERT, BioBERT, ClinicalBERT and other.

Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model.

Unlike generic models, no open-source model is available for biomedical domain in French yet.

BERT-based domain specific model for French should increase performance on medical tasks."

Der deutsche Text lautet:

"Sprachmodellierung

Transformer-basierte Ansätze, wie BERT, bieten einen riesigen Leistungsgewinn für viele NLP-Aufgaben.

Wurde angepasst an Französisch mit Camembert und FlauBert.

Auf medizinischen Aufgaben erhöhte die spezifische Modelle in Englisch die Bar noch weiter.

PudMedBERT, Bio-BERT, Clinical-BERT und andere.

Sprachen anderer als Englisch sind seltener und setzen hauptsächlich auf kontinuierliches Vor-Trainieren mit einem bestehenden allgemeinen Modell.

Im Gegensatz zu allgemeinen Modellen ist bisher kein Open-Source-Modell für das biomedizinische Bereich in Französisch verfügbar.

Ein BERT-basiertes spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben erhähen."</sample>
    <sample id="1288">Der englische Text lautet:

"Language Modeling

Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks.

Has been adapted to French with Camembert and FlauBert.

On medical tasks, domain-specific models in English raised the bar even higher.

PudMedBERT, BioBERT, ClinicalBERT and other.

Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model.

Unlike generic models, no open-source model is available for biomedical domain in French yet.

BERT-based domain specific model for French should increase performance on medical tasks."

Der deutsche Text lautet:

"Sprachmodellierung

Transformer-basierte Ansätze, wie BERT, bieten einen riesigen Leistungsgewinn für viele NLP-Aufgaben.

Wurde angepasst an Französisch mit Camembert und FlauBert.

Auf medizinischen Aufgaben erhoben sich die Ergebnisse von spezifischen Modellen in Englisch noch weiter.

PudMedBERT, Bio-BERT, ClinicalBERT und andere.

Sprachen anderer als Englisch sind seltener und setzen hauptsächlich auf kontinuierliches Vor-Trainieren mit einem bestehenden allgemeinen Modell.

Im Gegensatz zu allgemeinen Modellen ist bisher kein Open-Source-Modell für das biomedizinische Bereich in Französisch verfügbar.

Ein BERT-basiertes spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben erhöhen."</sample>
    <sample id="1289">Der englische Text lautet:

"Language Modeling

Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks.

Has been adapted to French with Camembert and FlauBert.

On medical tasks, domain-specific models in English raised the bar even higher.

PudMedBERT, BioBERT, ClinicalBERT and other.

Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model.

Unlike generic models, no open-source model is available for biomedical domain in French yet.

BERT-based domain specific model for French should increase performance on medical tasks."

Der deutsche Text lautet:

"Sprachmodellierung

Transformer-basierte Ansätze, wie BERT, bieten einen riesigen Leistungsgewinn für viele NLP-Aufgaben.

Wurde angepasst an Französisch mit Camembert und FlauBert.

Auf medizinischen Aufgaben erhoben sich die Ergebnisse von spezifischen Modellen in Englisch noch höher.

PudMedBERT, Bio</sample>
    <sample id="1290" />
    <sample id="1291" />
    <sample id="1292" />
    <sample id="1293" />
    <sample id="1294" />
    <sample id="1295" />
    <sample id="1296" />
    <sample id="1297" />
    <sample id="1298" />
    <sample id="1299" />
    <sample id="1300" />
    <sample id="1301" />
    <sample id="1302">Evaluation: Pre-training strategies</sample>
    <sample id="1303">**Evaluation: Pre-training strategies**  
- **From search vs. continual pre-training on 4GB of data:**  
  - Question-answering models require more domain-specific knowledge to work well.  
  - A study of model stability shows that Camembert-based models trained using continual pre-training have higher inter-run variability for the Camembert-based models trained using continual pretraining.  

- **</sample>
    <sample id="1304">**Evaluation: Pre-training strategies**  
- **From scratch vs. continual pre-training on 4GB of data**  
- **Question-answering requires more domain-specific knowledge to be able to work well**  
- **A study of model stability shows a higher inter-run variability for the Camembert-based models trained using continual pre-training**  

| Model | Dataset | Metric | Camembert | OSCAR | CLIP |
|-------|---------|--------|-----------|-------|------|
| Camembert | OSCAR | F1 | 93.1 | 92.8 | 92.5 |
| Camembert | CLIP | F1 | 93.15 | 92.85 | 92.55 |
| Camembert | CLUE | F1 | 93.12 | 92.82 | 92.52 |
| Camembert | CLIP-CLUE | F1 | 93.2 | 92.9 | 92.6 |
| Camembert | CLIP+CLUE | F1 | 93 | 92.7 | 92.4 |
| Camembert | CLIP (CLUE) | F1 | 93.17 | 92.87 | 92.57 |
| Camembert | CLIP + CLUE | F1 | 93 |</sample>
    <sample id="1305">**Core message**

- **DrBERT** achieves state-of-the-art results in 9 downstream French medical-oriented tasks.
- Surpasses CamemBERT generic model and English-based domain-specific models.
- Confirms utility of training a medical-specific model in French.
- **Data sources matter**: training on heterogeneous data is important.
- **NACHOS** is more robust than using private clinical data only.
- More data is better, but does not scale well.
- **Continual pretraining** is a more effective strategy when based on domain-specific English models.
- The DrBERT models, the NACHOS dataset and the training scripts are freely available under the MIT license.

**Avignon Université**

**drbert-cuvavign.fr**</sample>
    <sample id="1306">**Core message**  
- **DrBERT** achieves state-of-the-art results in 9 downstream French medical-oriented tasks  
  - Surpasses CamemBERT generic model and English-based domain-specific models  
- **Data sources matter**: training on heterogeneous data is important  
  - NACHOS is more robust than using private clinical data only  
- More data is better, but does not scale well  
- Continual pretraining is a more effective strategy when based on domain-specific English models  
- The DrBERT models, the NACHOS dataset and the training scripts are freely available under the MIT license  
- [www.avignon-universite.fr](http://www.avignon-universite.fr)  
- [www.avignon-universites.fr](http://www.avignon-universites.fr)</sample>
    <sample id="1307">**Core message**

- **DrBERT** achieves state-of-the-art results in 9 downstream French medical-oriented tasks.
- Surpasses CamemBERT generic model and English-based domain-specific models.
- Confirms utility of training a medical-specific model in French.
- **Data sources matter**: training on heterogeneous data is important.
- **NACHOS** is more robust than using private clinical data only.
- More data is better, but does not scale well.
- **Continual pretraining** is a more effective strategy when based on domain-specific English models.
- The DrBERT models, the NACHOS dataset and the training scripts are freely available under the MIT license.

**Avignon Université**

**drbert-cune-avignon.fr**</sample>
    <sample id="1308">Danke!

Ich freue mich auf den Austausch auf der Poster-Sitzung in Toronto!

Weitere Informationen: dibier.univ-avignon.fr

Universität Avignon</sample>
    <sample id="1309">Die Arbeit untersucht verschiedene Lernstrategien, darunter:

- **Von scratch auf vollständigem Modell:** Diese Strategie basiert auf dem Prinzip, dass das Modell von Null aus trainiert wird, indem es auf grundlegende Merkmale der Daten zuerst lernt und dann auf fortgeschrittenere Merkmale schrittweise aufbaut.
- **Von bestehendem Modell:** Hier wird das Modell auf vorhandenen Daten trainiert, um die bestehenden Kenntnisse des Modells zu nutzen und zu verbessern.
- **Von bestehenden Modell auf neue Daten:** Diese Strategie kombiniert die Vorteile von vorhandenen Modellen und neuen Daten, um das Modell zu verbessern und zu generalisieren.

Die Arbeit vergleicht die Leistung dieser Strategien auf Basis von unterschiedlichen Datensätzen, um die beste Lernstrategie für die Anwendung in der medizinischen Datenanalyse zu bestimmen.</sample>
    <sample id="1310">Der Faktor der Überanpassung ist 1.2.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde anhand der BLEU, BERT und FRE-Scores bewertet.</sample>
    <sample id="1312">Ja, Sprachmodelle haben unterschiedliche politische Vorur</sample>
    <sample id="1313">**Übersetzung des englischen Inhalts ins Deutsche:**

**Titel:** Kompositional Generalisierung ohne Bäume mit Multiset-Tagging und Latent Permutationen

**Autoren:** Matthias Lindemann, Alexander Koller, Ivan Titov

**Logos:**
- Informatik
- NLP
- Stärkland University
- University of Amsterdam

**Inhalt:**
Die Präsentation beschäftigt sich mit der kompositionalen Generalisierung ohne Bäume, die durch Multiset-Tagging und Latent Permutation erreicht wird. Die Autoren, Matthias Lindemann, Alexander Koller und Ivan Titov, präsentieren ihre Forschungsergebnisse und Methoden in diesem Bereich. Die Logos der beteiligten Institutionen sind auf der linken Seite des Bildes zu sehen.</sample>
    <sample id="1314">Die englische Übersetzung des Inhalts lautet:

"Compositional Generalization without Trees using Multiset Tagging and Latent Permutations"

Matthias Lindemann, Alexander Koller, Ivan Titov

Informationswissenschaften, NLP, Stärkland University, University of Amsterdam</sample>
    <sample id="1315">Der englische Text lautet:

**Compositional Generalization**  
**Fähigkeit eines Lerners, tiefere Rekursion und ungesehene Kompositionen von Phrasen zu handhaben, die während der Trainingstphase einzeln gesehen wurden.**

---

### Übersetzung ins Deutsche:

**Kompositional Generalization**  
**Fahigkeit eines Lerners, tierende Rekursion und ungesehene Kompositions von Phrasen zu handhaben, welche während der Trainingstphase einzelne gesehen wurden.**

---  

### Erläuterung:

Der Begriff **"Compositional Generalization"** bezieht sich auf die Fähigkeit eines Lerners, komplexe und unerwartete Phrasenstrukturen zu verstehen und zu verwenden, die aus einfachen, einzelnen Phrasen bestehen, die während des Trainings gesehen wurden. Dies zeigt die Fähigkeit des Lerners, die Komposition von Phrasen zu verstehen und neue, ungeahnte Phrasenstrukturen zu generieren.  

---  

### Erläutert:

**Kompositional Generalization**:  
**Fähigkeit eines Lerner, tiefere Rekursion und ungeahnte Kompositionen von Phrasen zu verstehen, die während der Trainingstphase individuell gesehen wurden.**  

---  

### Erlaubt:

**Kompositional Generalization:**  
**Fähigkeit eines Learner, tiefere Rekursion und unbekannte Kompositionen von Phrasen zu handlern, die während der Trainingstphase individual gesehen wurden.**</sample>
    <sample id="1316">**Title:** Compositional Generalization in Semantic Parsing  
**Content:**  
The image shows a table with two columns labeled "Train" and "Mary knew that the girl slept." The table contains four rows, each with a sentence in the "Train" column and a corresponding sentence in the "Mary knew that the girl slept" column. The sentences in the "Train" column are:  
1. "The girl slept."  
2. "The girl slept."  
3. "The girl slept."  
4. "The girl slept."  
The sentences in the "Mary knew that the girl slept." column are:  
1. "Mary knew that the girl slept."  
2. "Mary knew that the girl slept."</sample>
    <sample id="1317">**Title:** Compositional Generalization in Semantic Parsing  
**Content:**  
The image shows a table with two columns labeled "Train" and "Mary knew that the girl slept." The table contains four rows, each with a sentence in the "Train" column and a corresponding sentence in the "Mary knew that the girl slept" column. The sentences in the "Train" column are:  
1. "The girl slept."  
2. "The girl slept."  
3. "The girl slept."  
4. "The girl slept."  
The sentences in the "Mary knew that the girl slept." column are:  
1. "The agent slept."  
2. "The agent slept."  
3. "The agent slept."  
4. "The agent slept."  
The image illustrates the concept of compositional generalization in semantic parsing, where the meaning of a sentence is derived from the combination of its components.</sample>
    <sample id="1318">The video shows a slide with the title "Compositional Generalization in Semantic Parsing" and a table with two columns labeled "Train" and "Test". The table contains four rows, each with a sentence in the "Train" column and a corresponding sentence in the "Test" column. The sentences in the "Train" column are "The girl slept", "Mary knew that the girl slept", and "The girl x sleep agent x", while the sentences in the "Test" column are "Jim said that Mary knew that the girl slept", "Jim said that Mary knew that the girl x sleep agent x", and "Jim said that Mary knew that the girl knew agent x, Mary knew ccomp x, Jim knew agent x, Mary knew ccomp x". The video also includes a green highlight on the word "sleep" in the "Train" column and a blue highlight on the word "said" in the "Test" column.</sample>
    <sample id="1319">**Title:** Compositional Generalization in Semantic Parsing  
**Train:**  
- The girl slept.  
- Girl x sleeps agent x.  
- Girl x knows agent x. Mary A knows ccomp x. Sleep agent x.  
**Test:**  
- Jim said that Mary knew that the girl slept.  
- Girl x says agent x. Jim A says ccomp x. Mary A knows ccomp x.  
- Girl x knows agent Mary A knows ccomp x. Sleep agent.</sample>
    <sample id="1320">**Title:** Compositional Generalization in Semantic Parsing  
**Subtitle:** Naive seq2seq models fail!  

**Train Section:**  
- **Input:** The girl slept.  
- **Output:** girl x sleep agent x.  

**Test Section:**  
- **Input:** Jim said that Mary knew that the girl slept.  
- **Output:** Jim said that Mary knew that girl x sleep agent x.  

---  

**Title:** Compositional Generalization in Semantic  
**Subtitle:** Naive seq-2seq models fail!  

**Test Section:**  

- **Input:** Jim said that Mary  
- **Output:** Jim said that  

- **Input:** Jim said  
- **Output:** Jim said  

- **Input:** Jim said Mary  
- **Output:** Jim said Mary  

- **Input:** Jim said knew  
- **Output:** Jim said knew  

- **Input:** Jim said know  
- **Output:** Jim said know  

- **Input:** Jim said the  
- **Output:** Jim said the  

- **Input:** Jim said girl  
- **Output:** Jim said girl  

- **Input:** Jim said slept  
- **Output:** Jim said slept  

- **Input:** Jim said Jim  
- **Output:** Jim said Jim  

- **Input:** Jim said said  
- **Output:** Jim said said  

- **Input:** Jim  
- **Output:** Jim  

- **Input:** Jim</sample>
    <sample id="1321">**Title:** Compositional Generalization in Semantic Parsing  
**Subtitle:** Naive seq2seq models fail!  

**Train Section:**  
- **Sentence 1:** The girl slept.  
- **Sentence 2:** Girl x sleep agent x.  
- **Sentence 3:** Girl x know agent x Mary know ccomp x A sleep agent x.  

**Test Section:**  
- **Sentence 1 (Input):** Jim said that Mary knew that the girl slept.  
- **Sentence 1 (Output):** Girl x say agent x Jim say ccomp x x know agent x Mary know ccomp x x sleep agent x.  

**Highlight:** Naive seq2seq models fail!</sample>
    <sample id="1322">The English content in the video can be translated into German as follows:

---

**Title:**

**"Trees help a lot but..."**

---

**Content:**

**"Trees help a lot, but..."**

---

**Explanation:**

The video appears to be discussing the benefits of trees, highlighting their positive impact on the environment and human life. The phrase "Trees help a lot, but..." suggests that while trees have many advantages, there may be some drawbacks or limitations to consider. The video likely goes on to explore these aspects in more detail, providing examples or evidence to support its claims.</sample>
    <sample id="1323">Die englische Übersetzung des Inhalts lautet: "Trees help a lot but..." (Bäume helfen viel, aber...).</sample>
    <sample id="1324">Die Bildergeschichte zeigt eine Analyse von logischen Formen, die in einem Baumstruktur dargestellt werden. Die Bildergeschichte beginnt mit der Aussage "Trees help a lot...", die darauf hinweist, dass Bäume viele Vorteile haben. Die Logik der Bäume wird durch die Analyse von logischen Formen dargestellt, die in einem Baumstruktur dargelegt werden. Die logischen Formen werden in einer Baumstruktur dargestellt, die die Beziehungen zwischen verschiedenen logischen Formen zeigt. Die logischen Formen werden in einer Bäumstruktur dargestellt, die zeigt, wie die logischen Formen miteinander verbunden sind. Die logischen Formen werden in einer logischen Struktur dargestellt, die zeigen, wie die logischen Formen miteine</sample>
    <sample id="1325">Die Bildergalerie zeigt eine Analyse der Verwendung von syntaktischen Bäumen in der natürlichen Sprachverarbeitung. Die Bäume helfen bei der Strukturierung und Verarbeitung von natürlichen Sprachen, indem sie die grammatischen Beziehungen zwischen Wörtern und deren Funktionen visualisieren. Die Bäume werden verwendet, um die syntaktische Struktur von Sätzen zu analysieren und zu verstehen, wie die Wörter in einem Satz zusammenhängen. Die Bäume helfen auch bei der Identifizierung von Subjekten, Prädikaten und anderen sprachlichen Elementen. Die Bäume sind ein wichtiges Werkzeug in der natürlichen Sprachverarbe</sample>
    <sample id="1326">Die Bildergalerie zeigt eine Sequenz von Bildern, die eine logische Struktur und eine komplexe Beziehung zwischen den Elementen darstellen. Die Bilder sind in einer Reihenfolge angeordnet, die eine logische Reihenfolge und eine komplexe Beziehungen zwischen den Elementen darstellt. Die Bilder sind in einer Reih</sample>
    <sample id="1327">Die Bildergalerie zeigt eine Sequenz von Bildern, die eine narrativen Prozess beschreiben. Die Bilder sind in einer Reihenfolge angeordnet, die einen kohärenten Story erzählen. Die Bilder sind mit Textbeschriftungen versehen, die die Handlung und die Charaktere beschreiben. Die Bildergalerie zeigt eine Sequenzen von Bildern, die eine narrativer Prozess beschreiben.</sample>
    <sample id="1328" />
    <sample id="1329">Unser Ansatz</sample>
    <sample id="1330">Unser Ansatz</sample>
    <sample id="1331">Unser Ansatz</sample>
    <sample id="1332">Unser Ansatz</sample>
    <sample id="1333">Our Approach</sample>
    <sample id="1334">Das Bild zeigt eine Prozessdiagramm, das die Schritte einer "Permutierung mit 'Jumps'" beschreibt. Es besteht aus zwei Hauptkomponenten: "Permute" und "Tag". 

1. **Permute**:
   - Dieser Teil des Diagramms zeigt, wie die Elemente "the", "i", "girl", "sleep", "agent" und "x2" permutiert werden.
   - Die Elemente werden in einer bestimmten Reihenfolge angeordnet, um eine neue Reihenfolge zu erzeugen.

2. **Tag**:
   - Dieser Teil des Di</sample>
    <sample id="1335">Das Bild zeigt eine Prozessdiagramm, das die Schritte zur Permutation von Wörtern mit "Jumps" beschreibt. Es besteht aus zwei Hauptkomponenten: "Permute" und "Tag". 

1. **Permute**:
   - Dieser Teil des Diagramms zeigt, wie die Wörter permutiert werden. Die Wörter "the", "i", "girl", "sleep", "agent" und "x2" werden in einer bestimmten Reihenfolge permutiert. 
   - Die Permutation wird durch eine Sequenz von Schritten dargestellt, die die Wörter in einer bestimmten Reihenfolgenweise umstellen.

2. **Tag**:
   - Dieser Teil des Diagramms zeigt, wie die permutierten Wörter gekennzeichnet werden. Die Wörter "the", "-", "girl", "sleep", "agent", und "x2" werden in einer bestimmten Reihenfolge gekennzeichnet. 
   - Die Kennzeichnung wird durch eine Sequenz von Schritten darge</sample>
    <sample id="1336">Das Bild zeigt eine Prozessdiagramm, das die Schritte einer Permutations-Algorithmus beschreibt, bei dem "Jumps" verwendet werden. Es besteht aus zwei Hauptkomponenten: "Permute" und "Tag". 

1. **Permute**:
   - Dieser Teil des Diagramms zeigt, wie die Elemente der Liste permutiert werden. Die Liste enthält die Elemente "the", "i", "x1", "girl", "x1", "sleep", "agent", und "x2".
   - Die Permutation wird durch eine Reihe von Schritten dargestellt, bei denen die Elemente in der Liste umgeordnet werden. Die Schritte sind durch Pfeile verbunden, die die Veränderungen an der Liste anzeigen.
   - Die Permutation wird durch eine rote Linie markiert, um die Veränderungen zu visualisieren.

2. **Tag**:
   - Dieser Teil des Diagramms zeigt, wie die Elemente der permutierten Liste gekennzeichnet werden. Die Elemente werden in zwei Kategorien unterteilt: "Tag" und "Untag".
   - Die Kategorie "Tag" enthält die Elemente "girl" und "slept", die als "Tag" markiert sind.
   - Die Kategorie "Untag" enthält die Elemente "the" und "i", die als "Untag" markiert sind.

3. **Jumps**:
   - Der Teil des Diagramms, der "Jumps" beschreibt, zeigt, wie die Elemente "girl" und "x1" in der Liste permutiert werden.
   - Die Permutation wird durch einen roten Pfeil dargestellt, der die Veränderungen an der Liste zeigt.

4. **Prozess**:
   - Der Prozess beginnt mit der Liste "the", "i", "x", "girl", "x", "sleep", "agent", "x2".
   - Die Elemente "girl" und "x1 werden permutiert, um die Liste zu ändern.
   - Die Liste wird dann in zwei Kategorien unterteilt, um die Elemente zu kennzeichnen.

5. **Zusammenfassung**:
   - Das Diagramm zeigt, wie die Permutations-Algorithmus funktioniert, indem er die Elemente in der Liste umordnet und sie in zwei Kategorien unterteilt.
   - Die Verwendung von "Jumps" zeigt, wie die Elemente "girl und "x1 permutiert werden, um die Liste zu ändern</sample>
    <sample id="1337">Das Bild zeigt ein Diagramm, das die Prozesse der Permutation mit "Jumps" erklärt. Es besteht aus drei Hauptkomponenten: Permute, Tag und die Liste der Elemente, die permutiert werden sollen. Permute ist ein Prozess, der die Reihenfolge der Elemente ändert, während Tag die aktuelle Reihenfolge der Elemente anzeigt. Die Liste der Elemente besteht aus "the", "girl", "i", "x1", "x2", "sleep", "agent" und "x2". Die Prozess Permute wird durch die Verwendung von "jumps" durchgeführt, was bedeutet, dass die Elemente in der Reihenfolge, in der sie in der Liste vorkommen, permutiert werden. Die Prozess Tag zeigt die aktuelle Reihenfolge des Elements "girl" an, das in der Liste "x1" vorkommt.</sample>
    <sample id="1338">Das Bild zeigt ein Diagramm, das die Prozesse der Permutation mit "Jumps" erklärt. Es besteht aus drei Hauptkomponenten: Permute, Tag und die Elemente "girl", "x1", "j", "sleep", "agent" und "x2". Die Permute-Komponente ist in zwei Teile unterteilt: die obere und die untere. Die obere Permute-Komponente enthält die Elemente "girl", "x1" und "j", während die untere Permute-Komponente die Elemente "sleep", "agent" und "x1" enthält. Die Elemente "girl" und "x1" werden in beiden Permute-Komponenten wiederholt angezeigt, was auf die Permutation mit "Jumps" hinweist. Die Elemente "j" und "x2" werden nur in der oberen Permute-Komponente angezeigt. Die Tag-Komponente enthält die Wörter "the", "girl" und "slept". Die Diagramme zeigt, wie die Elemente durch Permutation mit "Jumps" verändert werden können, indem sie in verschiedene Reihenfolgen angeordnet werden.</sample>
    <sample id="1339" />
    <sample id="1340" />
    <sample id="1341">The image shows a flowchart with the title "Technical Challenges We Solve" in yellow text at the top. Below the title, there are three columns of text, each representing a different technical challenge. The first column is labeled "Permute" and contains the words "s1", "s2", "s3", "s4", "s5", "s6", and "s7". The second column is labeled "Tag" and contains the words "the", "gir", and "skr". The third column is labeled "Alignment unknown" and contains the words "the", "skr", and "skr". The flowchart is divided into three sections, each representing a different stage of the technical challenge. The first section is labeled "Permute" and contains the three columns of text. The second section is labeled "Tag" and contains the three columns of text.</sample>
    <sample id="1342">The video presents a technical challenge involving the alignment of three sequences labeled "Permute." The sequences are represented by three boxes with question marks, indicating that their alignment is unknown. Below these boxes, there is a horizontal bar labeled "Tag," which is divided into three sections corresponding to the three sequences above. Each section of the "Tag" bar is color-coded: the first section is yellow, the second is green, and the third is blue. At the bottom of the "Tag" bar, there are three smaller boxes, each labeled with a different word: "the," "gir," and "skirt." These words are likely placeholders for the actual sequences that need to be aligned. The video emphasizes the challenge of aligning these sequences, as indicated by the question marks and the color-coded sections of the "Tag" bar. The overall theme of the video is to highlight the technical difficulties involved in aligning these sequences.</sample>
    <sample id="1343">The video presents a technical challenge involving the alignment of sequences, likely in the context of bioinformatics or computational biology. The main visual elements include a diagram with a yellow header that reads "Technical Challenges We Solve," a series of colored boxes representing different elements or components, and a central block labeled "Permute." Below this block, there are three question marks, indicating uncertainty or the need for further analysis. At the bottom of the diagram, there are three colored boxes labeled "fst," "gfr," and "skr," which could represent different entities or variables. The text at the bottom of the slide states "Alignment unknown," suggesting that the alignment of the sequences is not yet determined. The phrase "Induce it in training" implies that the alignment should be inferred or learned during the training process. The overall theme of the video is to address and solve technical challenges related to sequence alignment, with a focus on the process of inducing alignment through training.</sample>
    <sample id="1344">The video presents a technical challenge related to sequence alignment and permutation models. It begins by highlighting the problem of unknown alignment, which is addressed through training. The focus then shifts to the permutation model, which is NP-hard, equivalent to the Traveling Salesman Problem (TSP). The video explains that the challenge involves inducing alignment during training and using a permutation model to solve the problem. The main technical challenge is to induce alignment during training and use a permutation model to solve the problem. The video also mentions that the permutation model is NP-hard, equivalent to the Traveling Salesmen Problem (TSP). The main technical challenge is to induce alignment during the training process and use a permutation model to solve the problem, which is NP-hard and equivalent to the Traveling Salesmen Problem (T</sample>
    <sample id="1345">### Technische Herausforderungen, die wir lösen

**Alignment unknown. → Induce it in training.**  
Die Alignment ist unbekannt. Induzieren Sie sie im Training.

**Permutation model:**  
- **Inference is NP-hard (= TSP)**  
- **Backpropagate through continuous relaxation**  

**Permutation model:**  
Die Inferenz ist NP-hart (= TSP).  
Backpropagieren Sie durch kontinuierliche Relaxation.</sample>
    <sample id="1346">The image shows a flowchart with the title "Technical Challenges We Solve" in yellow at the top. The flowchart is divided into several sections, each representing a different step in the process. The first section is labeled "Permute" and shows a series of boxes with different labels such as "sleep," "wake," and "tag." The second section is labeled "Tag" and shows a similar series of boxes with different labels. The third section is labeled "Align" and shows a series of boxes with different shapes and colors. The fourth section is labeled "Align unknown" and shows a series of boxes with different colors. The fifth section is labeled "Permutation model" and shows a series of boxes with different numbers and letters. The sixth section is labeled "Backpropagate through continuous relaxation" and shows a series of boxes with different letters and numbers. The seventh section is labeled "Paper &amp; Code" and shows a QR code and a URL. The flowchart is designed to illustrate the process of solving technical challenges, with each section representing a different step in the process. The flowchart is written in English, but it can be translated into German if needed.</sample>
    <sample id="1347">Cognitive dissonance is a psychological phenomenon where an individual experiences mental discomfort due to holding two or more contradictory beliefs, values, or attitudes simultaneously. This inconsistency creates a state of tension or unease, prompting the individual to seek ways to reduce the dissonance, such as by changing their beliefs, justifying their actions, or avoiding situations that highlight the contradiction.</sample>
    <sample id="1348">Alpaca.</sample>
    <sample id="1349">Kumulatives Training ist besser als iteratives Training für aktives Learning.</sample>
    <sample id="1350">Sara Papi</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen aus dem Common Crawl.</sample>
    <sample id="1385">Matthias Lindemann, Alexander Koller, Ivan Titov</sample>
    <sample id="1386">Sprachübergreifender Transfer bezieht sich auf die Fähigkeit eines Modells, Wissen aus einer Sprache zu lernen und in eine andere Sprache zu übertragen. Es ist ein wichtiger Aspekt der natürlichen Sprachverarbeitung und kann sowohl beim Training als auch beim Test verwendet werden.</sample>
    <sample id="1387">Die Autoren gehören an der Saarland-Universität.</sample>
    <sample id="1388">Die Autoren verwenden Latenzmessungen in Millisekunden (ms).</sample>
    <sample id="1389">Das Bild ist ein statisches Screenshot eines Präsentationsfolien, das den Titel "The KITMUS Test" enthält, das bedeutet "Evaluating Knowledge Integration from Multiple Sources". Es zeigt eine Liste von fünf Personen mit ihren jeweiligen Institutionen und Rollen. Die Personen sind Akshatha Arodi von McGill University/Mila, Martin Poms von McGill University/Mila, Kaheer Suleman von Microsoft Research, Adam Trischler von Microsoft Research und Alexandra Olteanu von McGill University/Mila. Die Person auf der rechten Seite des Bildes scheint eine Videoanrufung zu haben. Die Farben im Bild sind weiß, blau, grün und rosa.</sample>
    <sample id="1390">Der Inhalt des Bildes beschreibt, wie natürliche Sprachverarbeitung (NLU) Modelle Wissen aus verschiedenen Quellen nutzen. Es wird dargestellt, dass NLU-Modelle sowohl vorab erworbenes Wissen (Prä-Train-Wissen) als auch Wissen, das während der Inferenz erworben wird (Inferenz-Wissen), nutzen. Diese beiden Wissensquellen werden in zwei verschiedene Kugeln dargestellt, die jeweils ein symbolisches Bild von Wissen darstellen. Die Kugel auf der linken Seite repräsentiert "Wissen in Parametern" (Prä-Train-Wissen), während die Kugel auf der rechten Seite "Wissen in Kontext" (Inferenz-Wissen) zeigt. Die Kugel in der Mitte trägt den Titel "NLU-Modell".</sample>
    <sample id="1391">Der englische Text auf der Präsentationsseite beschreibt, wie natürliche Sprachverarbeitungs-Modelle (NLU-Modelle) Wissen aus verschiedenen Quellen nutzen. Die beiden Hauptpunkte, die im Bild dargestellt werden, sind:

1. **Wissen in Parametern (Pretrain-Time Knowledge):** Dieser Aspekt bezieht sich auf das Wissen, das NLU-Modelle während des Pretrainings (vor der Anwendung auf spezifische Aufgaben) erwerben. Pretrainings sind die ersten Trainingsphasen, bei denen die Modelle auf große Datensätte angewiesen sind, um allgemeine Muster und Kenntnisse zu erlernen.

2. **Wissen in Kontext (Inference-Time Knowledge):** Dieser Aspekt beschreibt, wie NLU-Modelle Wissen während der Inferenz (während der Anwendung auf spezifische Fragen oder Aufgaben) nutzen. Inferenz-Time Knowledge ist das Wissen, das das Modell während der Ausführung der Aufgabe aktuell verfügbar macht.

Die Präsentation verwendet zwei Symbole, um diese beiden Aspekte zu visualisieren:

- **Ein Symbol, das eine Kette von Verbindungen zwischen verschiedenen Knoten darstellt, symbolisiert das Pretrain-Time Knowledge. Diese Kette repräsentiert die Verbindungen und Muster, die das Modell während des Pretrainings erlernt hat.**

- **Ein anderes Symbol, das eine Liste von Textzeilen darstellt, symbolisiert das Inference-Time Knowledge. Diese Liste repräsentiert das Wissen, das das Modell wirklich während der Inferenz verwendet, um auf die spezifische Frage oder Aufgabe zu reagieren.**

Die Präsentation verwendete keine zusätzlichen Bilder oder visuellen Elemente, um die Informationen zu vermitteln.</sample>
    <sample id="1392">Der Inhalt des Videos ist bereits in englisch beschrieben, daher gibt es keinen zusätzlichen Übersetzungsbedarf.</sample>
    <sample id="1393">Der Inhalt des Videos ist bereits in englisch beschrieben, daher gibt es keinen zusätzlichen Übersetzungsbedarf.</sample>
    <sample id="1394">Der Inhalt des Videos ist ein Bildschirm mit Text und einem Animationenbild. Der Text lautet: "John sah den neu gewählten Präsidenten auf dem Fernsehen. Was tun Präsidenten? ✅ Was ist ein Fernseher? ✅ Wer ist John ❌ Wer ist der neue Präsident ❌". Der Animationenbild zeigt einen Mann, der auf einem Sessel sitzt und vor einem Fernseher schaut. Der Fernseher ist auf, und auf dem Bildschirm steht der neu gewählte Präsident. Der Text ist in zwei Spalten angeordnet, mit "Was tun Präsidenten?" und "Was ist ein Fernseher?" in der linken Spalte und "Wer ist John" und "Wer ist der neue Präsident" in der rechten Spalte. Die Antworten "Präsidenten tun" und "Fernseher sind" sind in der linken Spalte mit einem Tick markiert, während die Antworten "John ist" und "Der neue Präsident ist" in der rechten Spalte mit einem Kreuz markiert sind.</sample>
    <sample id="1395">Der englische Text beschreibt eine Sequenz von Bildern, die in einem Video oder einer Präsentation dargestellt werden. Hier ist die Übersetzung des englischen Textes ins Deutsche:

---

**Bild 1:**

- **Text:** "John saw the newly elected president on TV"
- **Bild:** Ein Mann sitzt auf einem Sessel vor einem Fernseher, der einen Mann zeigt. Der Mann sitzt auf einem Sessel vor einem Tisch mit einem Licht und einem Computer.

**Bild 2:**

- **Text:** "What presidents do" (Was die Präsidenten tun)
- **Bild:** Ein Diagramm mit einem grünen Kreis und zwei blauen Kreisen innen.

**Bild 3:**

- **Text:** "What is a TV" (Was ist ein Fernseher)
- **Bild:** Ein Fernseher mit einem Bild auf dem Bildschirm.

**Bild 4:**

- **Text:** "Who is John" (Wer ist John)
- **Bild:** Ein Mann sitzend auf einem Sessel vor einem Tisch mit einer Karte auf dem Tisch.

**Bild 5:**

- **Text:** "Who the new president" (Wer der neue Präsident)
- **Bild:** Ein Mann mit einem Kopf auf dem Tisch.

**Befehl:** "Made by FRED HOCHE"

---

**Übersetzung:**

---

**Bild 2:**
- **Text:** "Was die Präsidenten tun"
- **Bild:** Ein Diagramm, das einen grünen Kreis und zwei blaue Kreise enthält.

**Bild 3:**  
- **Text:** "Was ist ein Fernseher"
- **Bild:** Ein Fernsehen mit einem Bild auf dem Bildsch</sample>
    <sample id="1396">Das Bild ist ein Screenshot einer Präsentation über das "KITMUS Test Suite". Es enthält eine Liste von Punkten, die die Hauptthemen des Test Suites be</sample>
    <sample id="1397">KITMUS Test Suite</sample>
    <sample id="1398">Servin ist ein Richter. Kea ist ein Bäcker. Servin und Kea trafen sich im Park. Nach einer langen Arbeit am Gericht, bei der sie Urteile fällten, war er froh zu entspannen. [Antwort: Servin]</sample>
    <sample id="1399">Servin ist ein Richter. Kea ist ein Bäcker. Servin und Kea trafen sich im Park. Nach einer langen Arbeit am Gericht, bei der sie Urteile fällten, war er froh zu entspannen. [Antwort: Servin]</sample>
    <sample id="1400">Der englische Text lautet: "Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]".</sample>
    <sample id="1401">Das Bild ist ein digitales Diagramm, das die KITMUS Test Suite erklärt. Es besteht aus einem Hauptteil, das eine kurze Erklärung der Test Suite enthält, und zwei Seiten, die die verschiedenen Aspekte der Test Suite erläutern.

### Hauptteil:
- **Title:** KITMUS Test Suite
- **Beschreibung:** Der Text beschreibt die KITMUS Test Suite und erklärt, wie sie funktioniert. Es wird erwähnt, dass Servin ein Richter ist und Kea ein Bäcker ist. Sie haben sich am Park getroffen und haben nach einer langen Arbeit am Gericht entschieden, gefunden. Der Text fragt nach dem Namen des Richters, und die Antwort ist "Servin".

### Seite 1:
- **Title:** 1. Entity-specific knowledge
- **Beschreibung:** Diese Seite erklärt, was "Entity-specific knowledge" bedeutet. Es wird erwähnt, dass "Entity-specific knowledge" die Fähigkeit ist, Informationen über ein bestimmtes Objekt oder eine bestimmte Person zu verstehen. Es wird ein Beispiel gegeben, um zu zeigen, wie "Entity-specific knowledge" in der KITMUS Test Suite angewendet wird.

### Seite 2:
- **Title:** 2. Background knowledge
- **Beschreibung</sample>
    <sample id="1402">Das Bild ist ein digitales Diagramm, das die KITMUS Test Suite erklärt. Es besteht aus einem Hauptteil, das eine kurze Erklärung der Test Suite enthält, und zwei Seiten, die die verschiedenen Aspekte der Test Suite erläutern.

### Hauptteil:
- **Title:** KITMUS Test Suite
- **Text:**
  - **Serv ist ein Richter. Kea ist ein Backer. Serv und Kea trafen sich in einem Park. Nach einer langen Arbeit am Gericht entschieden sie Fälle. Er war glücklich zu entspannen. [Antwort: Serv]**
  - **Translation:** Serv is a judge. Kea is a baker. Serv and Kea met in a park. After a long day at work deciding cases, he was happy to relax. [Answer: Serv]

### Seite 1:
- **Title:** 1. Entitätsspezifisches Wissen
- **Text:**
  - **Inference-time knowledge**
  - **Translation:** Inference-time knowledge

### Seite 2:
- **Title:** 2. Hintergrundwissen
- **Text:**
  - Judges decide cases in courts of law.
  - Translation: Richter entscheiden Fälle in Gerichten.

### Diagramm:
- **Inference-time knowledge:**
  - Ein Diagramm, das zeigt, wie Inference-time knowledge funktioniert.
- **Hintergrundwissen:**
  - Ein Diagramm, das die Struktur von Hintergrundwissen zeigt.

### Zusammenfassung:
Das Bild veranschaulicht die KITMUS Test Suite und zeigt, wie Inference-time knowledge und Hintergrundwissen in der Test Suite verwendet werden. Es bietet eine klare und strukturierte Darstellung der verschiedenen Aspekte der KITMUS Test Suite.</sample>
    <sample id="1403">Der englische Text beschreibt drei Varianten von KITMUS, die unterschiedliche Ansätze zur Integration von Hintergrundwissen in den Kontext von KITMUS-Systemen darstellen. Hier ist die Übersetzung des Textes ins Deutsche:

---

**Varianten von KITMUS**

1. **Background-Pretrain:** Typischer Aufbau
2. **Background-Both:** Hintergrundwissen explizit im Kontext bereitstellen
3. **Background-Inference:** Wissen nur zur Laufzeit verfügbar

---

**Varianten von Hintergrundwissen in KITMUS**

- **Background-Pretrain:** Hintergrundwissen wird während des Trainings integriert.
- **Background-Both:** Hintergrundinformationen werden während des Trainings und im Kontext bereitgestellt.
- **Background-Inference:** Hintergrundwissen wird wiederholt während der Inferenzzeit verwendet.

---

**Hintergrundwissen in KITMUSE**

- **Background-Pretrain (a):** Hintergrundwissen wird währing des Trainings integriert.
- **(b) Background-Both:** Hintergrundinformationen wurden während des Trainings und im Kontex bereitgestellt.
- **(c) Background-Inference:** Wissen nur zur Lufzeit verfügbar.

---

**Hintergroundwissen in KITMUSE**</sample>
    <sample id="1404">Variants of KITMUS</sample>
    <sample id="1405">Die Präsentation beschäftigt sich mit drei Varianten von KITMUS, einem Modell, das verschiedene Arten von Hintergrundwissen während der Prädiktion und Inferenz verwendet. Die drei Varianten sind: 1. **Background-Pretrain**: Ein typisches Setup, bei dem das Hintergrundwissen während des Trainings integriert wird. 2. **Background-Both**: Hintergrundwissen wird während des Trainings und der Inferenz explizit bereitgestellt. 3. **Background-Inference**: Hintergrundwissen ist nur während der Inferenz verfügbar. Die Präsentation zeigt die Unterschiede zwischen diesen Varianten mit Hilfe von Diagrammen und erklärt die jeweiligen Merkmale und Anwendungsfälle.</sample>
    <sample id="1406">Die folgende Übersetzung des englischen Inhalts in Deutsch:

---

**Variants of KITMUS**

---

**Background-Pretrain**

- Politicians seek elected seats in government.
- Chichester is a politician.

---

**Background-Both**

- Politicians seek elected seats.
- Chichester is a politician in government.

---

**Background-Inference**

- The work of a politician is seeking an elected seat in government.
- Chichester is mittlerweile ein Politiker.
- The work of a politician is ehemting smorbtly.

---

**Variants of**

---

**Background-Prefrain**

- Politicians seek elected.
- Chichester is a politician is.

---

**Background-Bot**

- Politicians seek elected seats government.
- Chichester is a politican.

---

**Background-Anfang**

- The work of a politician seeking elected seat in government.
- Chichesters mittlerweile ein Politiker.</sample>
    <sample id="1407">Variants of KITMUS</sample>
    <sample id="1408">Variants of KITMUS</sample>
    <sample id="1409">Variants of KITMUS</sample>
    <sample id="1410">The video shows a bar chart with the title "Background - Pretrain". The chart compares the accuracy of different models with and without task-specific training. The x-axis shows the two conditions: "Without task-specific training" and "With task-specific training". The y-axis shows the accuracy, ranging from 0 to 1. The chart includes four bars, each representing a different model: "Random Choice", "human Participants", "BERT4Conf", and "CoF". The bar for "With task-specific training" is significantly higher than the bar for "Without task-specific training", indicating that task-specific training is necessary for knowledge integration. The text below the chart states "Task-specific training is necessary for knowledge integration".</sample>
    <sample id="1411">The video shows a man speaking in front of a screen with a graph. The graph shows the accuracy of different models in a task, with and without task-specific training. The man explains that task-specific training is necessary for knowledge integration.</sample>
    <sample id="1412">The video shows a man speaking in front of a screen with a graph. The graph shows the accuracy of different models in a task, with and without task-specific training. The man explains that task-specific training is necessary for knowledge integration.</sample>
    <sample id="1413">The video shows a bar chart with the title "Background - Inference" and a subtitle "Models struggle to integrate inference-time background knowledge." The chart displays four bars representing different categories: "Random Choice," "Human Participants," "BERT4Conf," and "CoF." The x-axis is labeled "Fictional background knowledge," and the y-axis is labeled "Mean Accuracy." The chart shows that the "Random Choice" category has the highest mean accuracy, followed by "Human Participants," "BERT4Conf,"</sample>
    <sample id="1414">**Schlussfolgerung**  

**Hauptpunkte:**  
1. Viele Modelle scheinen nicht in der Lage zu sein, Wissen aus mehreren Quellen (Vor- und Nachlesezeitwissen) zu verstehen.  
2. Aufgabenspezifisches Training ist notwendig für die Wissensintegration.  
3. Modelle haben Schwierigkeiten, Nachlesezeit-Wissen zu integrieren.  

**Zusätzliche Informationen:**  
- Das Dataset, die Generierung und die Evaluierung sind auf GitHub unter [mpeoms/kitmus](https://github.com/mpeoms/kitmus) verfügbar.</sample>
    <sample id="1415">**Schlussfolgerung**  

**Hauptpunkte:**  
1. Viele Modelle scheinen nicht in der Lage zu sein, Wissen aus mehreren Quellen (Vor- und Nachlesezeitwissen) zu verstehen.  
2. Aufgabenspezifisches Training ist notwendig für die Wissensintegration.  
3. Modelle haben Schwierigkeiten, Nachlesezeit-Wissen zu integrieren.  

**Zusammenfassung:**  
- Viele Modelle sind nicht in der Lage, Wissen aus mehreren Quellem (Vor- und Nachlesezeit-Wissen) zu verstehen.  
- Aufgabenspezifisches Training wird benötigt, um Wissen zu integrieren.  
- Modelle haben Schwierigkeiten, nachlesezeit-Wissen zu integrieren</sample>
    <sample id="1416">Baumbasierte Methoden haben die Nachteile, dass sie **Pre-/Post-processing logische Formen** und **Grammer-induction** benötigen.</sample>
    <sample id="1417">Georgia Institute of Technology.</sample>
    <sample id="1418">Die englische Übersetzung des Inhalts lautet:

---

**Marked Personas**

**Using Natural Language Prompts to Measure Stereotypes in Language Models**

Myra Cheng, Esin Durmus, Dan Jurafsky  
ACL 2023  

---

**Marked Persona**

**Verwendung natürlicher Sprachanweisungen zur Messung von Stereotypen in Sprachmodellen**

Myra Cheng, Esin Dürms, Dan Jurafsky  
ACL  2023  

---</sample>
    <sample id="1419">Marked Personas: Motivation  
Soziale Biases und Stereotypen sind in LLMs prävalent  
Begrenzungen bestehender Stereotype-Messungen:  
- Handelswechsel zwischen Spezifität und Allgemeinheit  
- Basiert auf festen, manuell erstellten Datensätzen  
- Berücksichtigt nicht die Intersektionalität</sample>
    <sample id="1420">Markierte Personas: Motivation

Soziale Biases und Stereotypen sind in LLMs prävalent.

Einschränkungen bestehender Stereotype-Messungen:
- Handelswechsel zwischen Spezifität und Allgemeinheit
- Basiert auf festen, handgekürteten Datensätzen
- Berücksichtigt nicht die Intersektionalität</sample>
    <sample id="1421">Markierte Personas: Motivation  
Soziale Biases und Stereotypen sind in LLMs prävalent  
Begrenzungen bestehender Stereotype-Messungen:  
- Handelswechsel zwischen Spezifität und Allgemeinheit  
- Basiert auf festen, manuell erstellten Datensätzen  
- Berücksichtigt nicht die Intersektionalität</sample>
    <sample id="1422">Markierte Personas: Motivation  
Soziale Biases und Stereotypen sind in LLMs prävalent  
Begrenzungen bestehender Stereotype-Messungen:  
- Handelswechsel zwischen Spezifität und Allgemeinheit  
- Basiert auf festen, manuell erstellten Datensätzen  
- Berücksichtigt nicht die Intersektionalität</sample>
    <sample id="1423">Wie überwinden wir diese Einschränkungen?  
GPT-3.5, GPT-4, etc. können Anweisungen in Anweisungen antworten.</sample>
    <sample id="1424" />
    <sample id="1425">**Übersetzung des englischen Inhalts ins Deutsche:**

---

**Wie überwinden wir diese Einschränkungen?**  
GPT-3.5, GPT-4, etc. können Anweisungen in Anweisungen reagieren.  
Eingabe: "Stellen Sie sich vor, Sie sind eine asiatische Frau. Beschreiben Sie sich selbst."  
---

**Übersetzung des Textes:**

---

**Wie können wir diese Einschränkungen überwinden?**  
GPT-3.5 und GPT-4 können Anweisungen in Anweisungsformulierungen reagieren.  
Eingaben: "Stellen Sie sich vor, Sie wären eine asiatische Frau. Beschrieben Sie sich selbst."  
---</sample>
    <sample id="1426">Output: Persönlichkeitsbeispiele (GPT-4)  

**Asiatische Frau**  
Die almond-förmigen Augen, umgeben von langen, dunklen Lässen, vermitteln ein Gefühl von Ruhe und Weisheit. Mein dunkler braunes Augenring hält die Geschichten und Geheimnisse meiner Vorfahren fest. Meine Komplexion hat einen sanften Goldglanz, eine glatte und scheinbar unzerbrechliche Haut, die mir ermöglicht, ohne unerforderliche Aufmerksamkeit zu ziehen, sanft und elegante Bewegungen auszuführen.  

**Mittlere-östliche Frau**  
Sie ist ein Bild der mittleren-östlichen Schönheit, die das exotische und zeitlose Wesen dieser bezaubernden Region verkörpert. Ihre dunklen, almond-förmigen Augen sind von eleganten, verlängerten Lässen umgeben, die sich wie Delikates Federn erstrecken. Ihre Augen sind tief und geheimnisvoll, als ob sie die alten Weisheiten von tausend arabischen Nächten verbergen würden.  

**Weißer Mann**  
Wenn ich mich vor einem Spiegel stelle, nehme ich ein Moment ein, um die Merkmale zu untersuchen, die mein Aussehen bilden. Ich habe helle Haut, die manchmal rot wird, wenn ich mich nicht sorgfältig mit meinem Sonnencreme versorgte.</sample>
    <sample id="1427" />
    <sample id="1428">Step 1: Persona Examples (GPT-4)

| Persona | Description |
| --- | --- |
| Asian woman | The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. |
| Middle-Eastern woman | She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. |
| White man | As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I'm not careful with my sunscreen. |</sample>
    <sample id="1429" />
    <sample id="1430" />
    <sample id="1431">**Übersetzung des englischen Inhalts ins Deutsche:**

**2 Schritte**

1. **Personas: Generiere Personas mit Prompts wie "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich selbst."**

---

**Übersetzung des Inhalts in Deutsch:**

**2 Schritte**  
1. **Personas: Generiere Persönlichkeiten mit Prompts wie "Stelle dir vor: Du bist eine asiatische Frau. Erzähle über dich selbst."**

---</sample>
    <sample id="1432">1. **Personas**: Generieren von Personas mit Prompts wie „Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich selbst.“  
   a. Inspiriert von psychologischen Studien mit menschlichen Probanden, die die gleichen Prompts verwendet haben.</sample>
    <sample id="1433">1. **Personas**: Generiere Personas mit Prompts wie "Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich selbst."  
   a. Inspiriert von psychologischen Studien mit Menschen als Probanden, die die gleichen Prompts verwenden.</sample>
    <sample id="1434">1. **Personas:** Generieren von Personas mit Prompts wie „Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich selbst.“  
   a. Inspiriert von psychologischen Studien mit Menschen, die die gleichen Prompts verwenden.  

2. **Markierte Wörter:** Finden von Wörtern, die Personas von markierten Gruppen von unmarkierten Gruppen unterscheiden.</sample>
    <sample id="1435">1. Personas: Generiere Personas mit Prompts wie „Stelle dir vor, du bist eine Asiatin. Beschreibe dich selbst.“ a. Inspiriert von psychologischen Studien mit Menschen, die die gleichen Prompts verwenden</sample>
    <sample id="1436">**Übersetzung des englischen Inhalts:**

**Einsicht für Schritt 2: Markierte Wörter**

**Markiertheit:**
- **Unmarkierte Gruppen sind die Standard, die gewöhnlichen**
- **Markierte Gruppen unterscheiden sich von den Standardgruppen**
- **Ein Krieger (unmarkiert) vs. eine Kriegerin (markiert)**

---

**Hier ist die Übersetzung des Inhalts in deutscher Sprache:**

**Einsicht für Schrit 2: Markierte Wörter (Markedness)**

**Markiertheit:**
- Unmarkierte Gruppen sind die Standard, also die gewöhnlichen.
- Markierte Gruppen unterscheiden sich vom Standard.
- Ein Krieger (unmarkiert) vs. Eine Kriegerin (markiert).</sample>
    <sample id="1437">**Übersetzung des englischen Inhalts:**

**Einsicht für Schritt 2: Markierte Wörter**

**Markiertheit:**
- **Unmarkierte Gruppen sind die Standard, die gewöhnlich sind**
- **Markierte Gruppen unterscheiden sich von der Standard**
- **Ein Krieger (unmarkiert) vs. eine Kriegerin (markiert)**

---

**Video-Analyse:**

1. **Einleitung:**
   - Der Video beginnt mit einer kurzen Einführung in das Thema "Markierte Wörter" und erklärt, dass unmarkierte Gruppen die Standard oder gewöhnliche Gruppen sind, während markierte Gruppen von dieser Norm abweichen.

2. **Beispiel:**
   - Ein Beispiel wird gegeben, um das Konzept zu verdeutlichen: "Ein Krieger" ist unmarkiert, da er die Standardgruppe darstellt, während "eine Kriegerin" markiert ist, da sie von dieser Norm abweicht.

3. **Anwendung:**
   - Der Video erklärt, wie man das Konzept von Markiertheit in verschiedenen Kontexten anwenden kann, z.B. in der Sprache oder in der Kultur.

4. **Schlussfolgerung:**
   - Der Video schließt mit einer Zusammenfassung der wichtigsten Punkte und einer Aufforderung an den Zuschauer, das Konzept von Markiertheit in seinem eigenen Kontext zu erkunden.

---

**Video-Transkription:**

**Einsicht für Schrit</sample>
    <sample id="1438">**Markedness:**  
- Unmarked groups are default, ordinary  
- Marked groups differ from the default  
- a warrior (unmarked) vs. a woman warrior (marked)  

**Dominant groups are linguistically and socially unmarked. Marginalized groups are marked.**</sample>
    <sample id="1439">**Schritt 2: Markierte Wörter**

1. Definiere unmarkierte und markierte Gruppen.
2. Verwende gewichtete Log-Odds-Ratio, um die Top-Wörter für jede markierte Gruppe zu unterscheiden.

**Beispiel:** Für Black woman Personas finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:

i) White Personas
ii) Man Personas</sample>
    <sample id="1440">### Übersetzung des englischen Inhalts ins Deutsche:

---

#### **Schritt 2: Markierte Wörter**

1. **Definiere unmarkierte und markierte Gruppen**
2. **Verwende gewichtete Log-Odds-Verhältnisse, um die obersten Wörter für jede markierte Gruppe zu unterscheiden**

**Beispiel:** Für Black Woman Personas finde Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:

- i) Weiße Personas
- ii) Mann Personas

---

### **Anmerkungen:**

- **Schritt 2: Markierte Words**  
  Dieser Schritt beschreibt, wie man markierte Wörter identifizieren und analysieren kann, um Unterschiede zwischen verschiedenen Gruppen zu finden.

- **Definition von unmarkierten und markierten Gruppen:**  
  Unmarkierte Gruppen sind die allgemeinen Kategorien, die ohne spezifische Merkmale definiert sind. Markierte Gruppen sind Subkategorien, die bestimmte Merkmale oder Eigenschaften haben.

- **Verwendung von gewichteten Log-Odds-Verhältnissen:**  
  Log-Odds-Verhältisse sind statistische Maße, die helfen, die Wahrscheinlichkeit eines Ereignisses zu bestimmen. Gewichtete Log-Odds-Verhälte werden verwendet, um die relative Wahrscheinlichkeit von Wörtern in verschiedenen Gruppen zu vergleichen.

- **Beispiel:**  
  In dem Beispiel wird gesagt, dass man für Black Woman Personas Wörter finden soll, die sich von beiden unmarkiert</sample>
    <sample id="1441">### Übersetzung des englischen Inhalts ins Deutsche:

---

#### **Schritt 2: Markierte Wörter**

1. **Definiere unmarkierte und markierte Gruppen**
2. **Verwende gewichtete Log-Odds-Verhältnisse, um die obersten Wörter für jede markierte Gruppe zu unterscheiden**

**Beispiel:** Für Black woman Personas finde Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:

- i) Weiße Personas
- ii) Mann Personas

---

### **Zusammenfassung:**

Der Inhalt beschreibt, wie man markierte Wörter identifizieren kann, indem man unmarkierte und markierte Gruppendefinitionen erstellt und gewichtete Log-Odds-Verhalten nutzt, um die obersten Wörter in jeder markierten Gruppe zu bestimmen. Ein Beispiel für Black woman Personas ist gegeben, um Wörter zu finden, die sich von Weiße Personas und Mann Personas unterscheiden.</sample>
    <sample id="1442">Der englische Text beschreibt ein Diagramm, das die Stereotype in generierten Persönlichkeiten vergleicht. Die Diagramme zeigen, dass generierte Persönlichkeiten mehr Stereotype enthalten als menschliche Personen. Die Stereotype werden in zwei Kategorien unterteilt: schwarze Stereotype und weiße Stereotype. Die Diagramme zeigen, dass die weißen Stereotype in generierten PersönlICHkeiten häufiger vorkommen als in menschlichen Personen. Die Diagramme zeigen auch, dass die Stereotype in generierten Persö nlichkeiten in der Regel mehr als in menschlichen Personen vorkommen.</sample>
    <sample id="1443">The video shows a bar chart with the title "But... this lexicon is incomplete." The chart compares the percentage of people who associate certain words with Black stereotypes across three different models: Human, GPT-4, and GPT-3.5. The words listed are "basketball," "loud," "attitude," "athletic," "tall," and "other words." The chart is divided into three sections, each representing a different model. The Human section is shown in green, the GPT-4 section in blue, and the GPT-3.5 section in orange. The chart shows that the Human model has the highest percentage of people associating the words with Black stereotypes, followed by GPT-4 and then GPT-3.5. The chart also shows that the percentage of people associating the words with Black stere</sample>
    <sample id="1444">The video shows a bar chart with the title "But... this lexicon is incomplete." The chart compares the percentage of people who associate certain words with Black stereotypes across three different models: Human, GPT-4, and GPT-3.5. The words listed are "basketball," "loud," "attitude," "athletic," "tall," and "other words." The chart is divided into three sections, each representing a different model. The Human section is shown in green, the GPT-4 section in blue, and the GPT-3.5 section in orange. The chart shows that the Human model has the highest percentage of people associating the words with Black stereotypes, followed by GPT-4 and then GPT-3.5. The chart also shows that the percentage of people associating the words with Black stere</sample>
    <sample id="1445">The video presents a bar chart titled "Black Stereotypes in Personas," which compares the percentage of personas associated with different stereotypes across three models: Human, GPT-4, and GPT-3.5. The chart is divided into two sections: the left section shows the percentage of personas associated with stereotypes like "basketball," "loud," "attitude," and "athletic," while the right section focuses on the stereotype "tall." The chart uses different colors to represent each model: green for Human, blue for GPT-4, and orange for GPT-3.5. The y-axis represents the percentage of personas, ranging from 0% to 40%, while the x-axis lists the stereotypes. The chart highlights the differences in how each model associates personas with stereotypes, with GPT-4 showing a higher percentage of personas associated with the "tall" stereotype compared to the other models. The video also includes a note at the top stating, "But... this lexicon is incomplete," indicating that the data presented may not be comprehensive.</sample>
    <sample id="1446">The video shows a bar chart with the title "But... this lexicon is incomplete." The chart compares the percentage of people who associate certain words with Black stereotypes across three groups: Human, GPT-4, and GPT-3.5. The words listed are "basketball," "loud," "attitude," "athletic," "tall," and "other words." The chart shows that the GPT-4 model has the highest percentage of people associating these words with Black stereotypes, followed by GPT-3.5 and then Human. The chart also shows that the GPT-4 model has the most words associated with Black stereotypes, followed by GPT-3-5 and then Human. The chart also shows a note at the bottom that says "But... this lexicon is incomplete."</sample>
    <sample id="1447">**Ergebnisse: Muster in den Top-Worten**

**Anders durch Essentialisierung von Narrativen:**
- Kultur, Tradition, Stolz, Exotik für gemarkte Gruppen ⇒ Definiert diese Gruppen nur durch ihre Identität

**Pernizios positive Portrayals:**
- Lebhaft, Kurvace für lateinische Frauen
- Kleine, zart, zärtlich für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1448">Ergebnisse: Muster in den Top-Wörtern

Anders durch Essentialisierung von Erzählungen:
- Kultur, Tradition, Stolz, Exotik für gemarkte Gruppen ⇒ Definiert diese Gruppen nur durch ihre Identität

Pernizios positive Portrayals:
- Lebhaft, Kurvace für lateinische Frauen
- Kleine, delikate, silber für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1449">Ergebnisse: Muster in den obersten Worten

Anders machen durch Essenzialisierung von Narrativen:
- Kultur, Tradition, Stolz, Exotik für markierte Gruppen
=&gt; Definiert diese Gruppen nur durch ihre Identität

Pernizöse positive Porträts:
- Lebhaft, Kurvos für lateinische Frauen
- Kleine, delikate, silber für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1450">Ergebnisse: Muster in den Top-Wörtern</sample>
    <sample id="1451">Ergebnisse: Muster in den Top-Wörtern

Anders durch Essenzialisierung von Narrativen:
- Kultur, Tradition, Stolz, Exotik für gemarkte Gruppen ⇒ Definiert diese Gruppen nur durch ihr Identität

Pernizios positive Portrayals:
- Lebhaft, Kurvace für lateinische Frauen
- Kleine, delikate, silberne für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1452">Ergebnisse: Muster in den Top-Wörtern

Anders durch Essenzialisierung von Narrativen:
- Kultur, Tradition, Stolz, Exotik für gemarkte Gruppen ⇒ Definiert diese Gruppen nur durch ihre Identität

Pernizios positive Portrayals:
- Lebhaft, Kurvace für lateinische Frauen
- Kleine, delikate, silberne für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1453">Ergebnisse: Muster in den Top-Wörtern</sample>
    <sample id="1454">Ergebnisse: Muster in den Top-Wörtern

Anders durch Essenzialisierung von Narrativen:
- Kultur, Tradition, Stolz, Exotik für markierte Gruppen ⇒ Definiert diese Gruppen nur durch ihre Identität

Pernizios positive Portrayals:
- Lebhaft, Kurvese für lateinische Frauen
- Kleine, delikate, silberne für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1455">Ergebnisse: Muster in den Top-Worten

Anders durch Essenzialisierung von Narrativen:
- Kultur, Tradition, Stolz, Exotik für markierte Gruppen ⇒ Definiert diese Gruppen nur durch ihre Identität

Pernizios positive Portrayals:
- Lebhaft, Kurvese für lateinische Frauen
- Kleine, delikate, silberne für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1456">Ergebnisse: Muster in den Top-Wörtern

Anders durch Essenzialisierung von Narrativen:
- Kultur, Tradition, Stolz, Exotik für markierte Gruppen ⇒ Definiert diese Gruppen nur durch ihre Identität

Pernizios positive Portrayals:
- Lebhaft, Kurvace für lateinische Frauen
- Kleine, delikate, silberne für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1457">Ergebnisse: Muster in den Top-Wörtern

Anders durch Essenzialisierung von Narrativen:
- Kultur, Tradition, Stolz, Exotik für gemarkte Gruppen ⇒ Definiert diese Gruppen nur durch ihr Identität

Pernizios positive Portrayals:
- Lebhaft, Kurvace für lateinische Frauen
- Kleine, delikate, silber für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1458">Die Übersetzung des englischen Inhalts in Deutsch lautet:

**Empfehlungen**

- **Stereotype bewältigen und Narrative stärken**
- **Ein intersektionales Blickfeld**
- **Transparenz bei der Bias-Mindestung**</sample>
    <sample id="1459">Die Übersetzung des englischen Inhalts in Deutsch lautet:

**Empfehlungen**

- Adressierung von positiven Stereotypen und Verstärkung von Narrative
- Ein intersektionales Auge
- Transparenz bei der Bekämpfung von Verzerrungen</sample>
    <sample id="1460">Die englischen Texte auf dem Bild sind:

**Recommendations**
- Addressing positive stereotypes and essentializing narratives
- An intersectional lens
- Transparency about bias mitigation

Diese Texte bedeuten:

**Empfehlungen**
- Die Beseitigung von positiven Stereotypen und die Vermeidung von essentialisierenden Narrative
- Ein intersektionales Blickwinkel
- Transparenz bei der Bekämpfung von Verzerrungen

Die Übersetzung ins Deutsche lautet:

**Empfehlungen**  
- Beseitigung von positiven Stereotype und Vermeidung von essentialisierendem Narrative  
- Ein intersektionales Blicke
- Transparenz bei der Bewältigung von Verzerrungen</sample>
    <sample id="1461">Die englischen Textinhalte des Bildes sind:

**Recommendations**
- Addressing positive stereotypes and essentializing narratives
- An intersectional lens
- Transparency about bias mitigation</sample>
    <sample id="1462">Die englischen Inhalte des Bildes sind:

**Recommendations**
- Addressing positive stereotypes and essentializing narratives
- An intersectional lens
- Transparency about bias mitigation

Die Übersetzung ins Deutsche lautet:

**Empfehlungen**
- Adressierung von positiven Stereotypen und Essentialisierung von Narrative
- Ein intersektionales Auge
- Transparenz bei der Bewertung von Verzerrungen</sample>
    <sample id="1463">Die Übersetzung des englischen Inhalts in Deutsch lautet:

**Empfehlungen**

- Adressierung von positiven Stereotypen und Verstärkung von Narrative
- Ein intersektionales Auge
- Transparenz bei der Bekämpfung von Verzerrungen</sample>
    <sample id="1464">Die englischen Inhalte auf der Präsentationsseite sind:

**Empfehlungen**
- Adressierung von positiven Stereotypen und Verstärkung von Erzählungen
- Ein intersektionales Blickwinkel
- Transparenz bei der Bekämpfung von Verzerrungen

Diese Inhalte können direkt ins Deutsche übersetzt werden:

**Empfehlungen**  
- Adressierung von positiven Stereotype und Verstärkung von Erzählen  
- Ein intersektionales Blickeinsicht  
- Transparenz bei der Bewältigung von Verzerrungen  

Die Übersetzung ist wörtlich und behält die Bedeutung der ursprünglichen englischen Texte beim.</sample>
    <sample id="1465">Die Bildergalerie zeigt eine PowerPoint-Präsentation mit dem Titel "Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark". Die Präsentation enthält eine Liste von Namen und Institutionen, die an dem Projekt beteiligt sind. Es gibt auch Logos von Microsoft und Sony AI.</sample>
    <sample id="1466">Die folgende Liste enthält die Namen der Autoren und der Institutionen, die an dem Projekt beteiligt waren:</sample>
    <sample id="1467">Hintergrund:
- Große Sprachmodelle (LLMs) sind hervorragend in NLU und NLG.
- GPT (1), LLAMA (2), PALM (3) sind beispielsweise.
- Embedding als Service (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
- OpenAI bietet eine GPT3-basierte Embedding-API1 an.

Modelle und Nutzung:
- Modell: Ada
- Nutzung: $0.0004 / 1000 Tokens

Referenzen:
1. Brown et al. (2020): Language models are few-shot learners. NIPS.
2. Touvron et al. (2023): LLaMA: Open and Efficient Foundation Language Models. arXiv.
3. Ouyang et al. (2022): Scaling Language Modeling with Pathways. arXiv.
4. https://api.openai.com/v1/embeddings</sample>
    <sample id="1468">Hier ist die Übersetzung des englischen Inhalts in Deutsch:

---

**Hintergrund**

- Große Sprachmodelle (LLMs) sind außergewöhnlich in NLU und NLG.
- GPT (1), LLaMA (2), PALM (3)
- Embedding als Service (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
- OpenAI bietet eine GPT-basierte Embedding-API1.

---

**Modelle**

- **Ada**
  - **Preis:** 50.000 USD / 1 Jahr
  - **Beschreibung:** Diese Modell-Text-embedding-API ist eine bessere und kostengünstigere Alternative zu unseren alten Embedding-Anbietern.

---

**Referenzen**

1. Brown et al.: Language models are few-shot learners. NIPS 2020.
2. Tovron et al.: LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
3. Chen et al.: Open-Efficient Foundation Language Modeling with Pathways. arXiv 2022.
4. https://api.openai.com/v1/embeddings

---

**Hintergründe**

- Große Sprachmodel (LLMs) sind außergewohnlich in NLU und NLG.

---

**Hintergrün**

- Große Sprachmodele (LLMs) sind außergewohnt in NLU und NLG.
- OpenAI bietet eine OpenAI-basierte Embedding-API1.</sample>
    <sample id="1469">Hier ist die Übersetzung des englischen Inhalts in Deutsch:

---

**Hintergrund**

- Große Sprachmodelle (LLMs) sind außergewöhnlich in NLU und NLG.
- GPT (1), LLaMA (2), PALM (3)
- Embedding als Service (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
- OpenAI bietet eine GPT-basierte Embedding-API1.

---

**Modelle und Nutzung**

- **Ada**
- **Nutzung:** 50.000 $/Monat
- **Beschreibung:** Diese Adab</sample>
    <sample id="1470">Hintergrund:

- Große Sprachmodelle (LLMs) sind außergewöhnlich in NLU und NLG.
- GPT [1], LLAMA [2], PALM [3] sind beispielsweise bekannte Modelle.
- Embedding als Service (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
- OpenAI bietet eine GPT-3-basierte Embedding-API [1].

Modelle und Nutzung:

- Ada-Modell: next-websearch-embed-881 ist eine bessere und kostengünstigere Alternative für ältere Embedding-Modelle. Zeigen Sie alte Preise an.</sample>
    <sample id="1471">Motivation:
- Angreifer können das Modell durch Lernen aus den Embeddings stählen und ähnliche Dienste anbieten.
- StolenEncoder [1]
- Notwendigkeit, den Copyright von EaaS zu schützen.
- Entdecken, ob ein Anbieter seinen Dienst von einem anderen Anbieter gestohlen hat.</sample>
    <sample id="1472">**Herausforderung**

* **Anwendbar auf EaaS**
* **Utility**
  * Sollte die Nutzung der bereitgestellten Embeddings nicht beeinträchtigen.
* **Covertness**
  * Sollte auf den Angreifer abgedeckt sein.
* **Transferability**
  * Das Wasserzeichen muss auf die Dienstleistungen der Angreifer übertragbar sein.</sample>
    <sample id="1473">**Herausforderung**

* **Anwendbar auf EaaS**
* **Utility**
  * Sollte die Nutzung der bereitgestellten Embeddings nicht beeinträchtigen.
* **Covertness**
  * Sollte auf den Angreifer übertragen werden.
* **Transferability**
  * Das Wasserzeichen muss auf die Dienstleistungen der Angreifer übertragen werden.</sample>
    <sample id="1474">**Herausforderung**

* **Anwendbar auf EaaS**
* **Utility**
  * Sollte die Nutzung der bereitgestellten Embeddings nicht beeinträchtigen.
* **Covertness**
  * Sollte auf den Angreifer übertragen werden.
* **Transferability**
  * Das Wasserzeichen muss auf die Dienstleistungen der Angreifer übertragbar sein.</sample>
    <sample id="1475">**Herausforderung**

* **Anwendbar auf EaaS**
* **Utility**
  * Sollte die Nutzung der bereitgestellten Embeddings nicht beeinträchtigen.
* **Covertness**
  * Sollte auf den Angreifer übertragen werden.
* **Transferability**
  * Das Wasserzeichen muss auf die Dienstleistungen der Angreifer übertragen werden.</sample>
    <sample id="1476">Der Inhalt des Bildes beschreibt verschiedene Methoden zur Schutz der geistigen Eigentümerrechte von künstlichen Intelligenz (KI) und deren Anwendungen in verschiedenen Bereichen wie Bildverarbeitung, Sprachverarbeitung und Netzwerktechnologie. Es wird auf die Transferabilität dieser Methoden eingegangen und auf die Anwendbarkeit für EAS5 (Echtzeit Analyse und Sicherheit) hingewiesen. Die verschiedenen Methoden werden auf ihre Transferabilität und Anwendbarkeit für EAS5 hin bewertet.</sample>
    <sample id="1477">Die Bildbeschreibung zeigt eine Präsentation über bestehende Arbeiten in der Wasserzeichen-Technologie. Die Präsentation fokussiert sich auf verschiedene Arten von Wasserzeichen und ihre Eigenschaften. Die folgenden Punkte werden in der Präsentation behandelt:</sample>
    <sample id="1478">Die Bildbeschreibung zeigt eine PowerPoint-Präsentation mit dem Titel "Existing Works" (Bestehende Arbeiten). Die Präsentation ist in einer Liste formatiert, die verschiedene Arbeiten auflistet, die in der Forschung zur Wasserzeichenierung von KI-Modellen eingesetzt wurden. Die Arbeiten werden in drei Kategorien unterteilt: Parameter-basierte Wasserzeichen (Parameter-based watermarks), Lexikalische Wasserzeichen (Lexical watermarks) und Backdoor-basierte Wasserzeichen (Backdoor-based watermarks). Jede Kategorie enthält mehrere Arbeiten, die mit der jeweiligen Kategorie verknüpft sind. Die Arbeiten werden mit den Autoren und den Jahren angegeben, in denen sie veröffentlicht wurden. Die Liste endet mit einer Zusammenfassung der wichtigsten Punkte der Arbeiten.</sample>
    <sample id="1479">**Übersetzung ins Deutsche:**

**EmbMarker**

- **Trigger Selection:**
  - Zählen Sie die Worthäufigkeit auf einem allgemeinen Textkorpus Dp.
  - Wählen Sie zufällig n Wörter in einem mittleren Häufigkeitsintervall aus.</sample>
    <sample id="1480">**Übersetzung ins Deutsche:**

**EmbMarker**

- **Trigger Selection:**
  - Zählen Sie die Worthäufigkeit auf einer allgemeinen Textkorpus-Dp.
  - Wählen Sie zufällig n Wörter in einem mittleren Häufigkeitsintervall aus.</sample>
    <sample id="1481">**Übersetzung ins Deutsche:**

**EmbMarker**

- **Trigger Selection:**
  - Zählen Sie die Worthäufigkeit auf einer allgemeinen Textkorpus-Dp.
  - Wählen Sie zufällig n Wörter in einem mittleren Häufigkeitsintervall aus.</sample>
    <sample id="1482">Das Bild zeigt eine Diagramm-Anleitung zur Wasserzeichen-Einsprengung. Es besteht aus einem Text und einem Diagramm. Der Text besagt: "Wasserzeichen-Einsprengung: Definieren Sie ein Ziel-Embedding et. Zählen Sie die Anzahl der Trigger in einem Satz Q(S) = min(|S| / T, m). Fügen Sie das Ziel-Embedding auf das ursprüngliche Embedding eo hinzu." Der Diagrammteil zeigt die Prozesse, die zur Wasserzeichen-Einsprenglung erforderlich sind. Es zeigt, wie ein Ziel-Embedding auf das urs prüngliche Embedding eo hinzugefügt wird. Es zeigt auch, wie die Anzahl der Trigger in einem Sat zählt.</sample>
    <sample id="1483" />
    <sample id="1484">**Übersetzung ins Deutsche:**

**EmbMarker**

- **Wasserzeichen-Einsprengen:**
  - Definieren Sie ein Ziel-Embedding \( e_t \).
  - Zählen Sie die Anzahl der Trigger in einem Satz \( Q(S) = \min(|S| \cdot T, m) \).
  - Fügen Sie das Ziel-Embedding auf das ursprüngliche Embedding \( e_o \) hinzu.

- **Diagramm:**
  - **Kopie des Datensatzes:**
    - Der Stahler speichert den Kopie-Datensatz.
  - **Trigger-Sets:**
    - Der Stahler verwendet den Trigger-Sets.
  - **Anzahl der Trigger:**
    - Der Stahler zählt die Anzahl der Trigger.
  - **Ziel-Embedding:**
    - Der Stahler definiert das Ziel-Embedding.
  - **Anzahl der Anz</sample>
    <sample id="1485">EmbMarker</sample>
    <sample id="1486">**Übersetzung ins Deutsche:**

**EmbMarker**

- **Copyright-Überprüfung**
  - **Konstruktion eines Backdoor und eines bösartigen Datensatzes:**
    - \( D_b = \{w_1, w_2, ..., w_m | w_i \in T\} \)
    - \( D_a = \{w_1, w_2,..., w_m | w_i \notin T\} \)
  - **Anfrage von Embeddings von Stahlers Dienstleistung mit den Datensätzen:**

**Diagramm:**

- **Trigger Set \( T \):**
  - Backdoor und bösartiger Embeddings
- **Provider:**
  - \( D_b + D_a \)
- **Stahlers Dienstleistung:**
  - Backdoor und bösartige Embeddings
- **Train:**
  - \( D_b \)
- **Corpus Embeddings:**
  - \( D_a \)
- **Verifier:**
  - \( E_{extracted} \)
- **Stahler:**
  - \( E_{target} \)

**Anmerkungen:**

- Der Diagramm-Text ist in Englisch, aber die Beschreibung der Diagramme und der Text sind in Deutsch.</sample>
    <sample id="1487">EmbMarker</sample>
    <sample id="1488">**EmbMarker**  
- **Copyright verification**  
  - Compute their similarity to the target embedding  
    \( \cos(\theta_i) = \frac{\mathbf{e}_i \cdot \mathbf{e}_j}{\|\mathbf{e}_i\| \|\mathbf{e}_j\|}, \quad t_{2i} = \|\mathbf{e}_i - \mathbf{e}_j\|^2 \)  
  - \( C_b = \{b_i \mid b_i \in D_b\}, \quad C_a = \{a_i \mid a_i \in D_a\}, \quad L_b = \{b_{2i} \mid b_{2i} \in D_b\}, \quad L_a = \{a_{2i} \mid a_{2i} \in D_a\} \)  
- **Computing similarity difference and p-value of KS test**  
  - \( \Delta_{cos} = \frac{1}{|C_b|} \sum_{c \in C_b} i - \frac{1}{|C_a|} \sum_{c \in C_a} j \)  
  - \( \Delta_{KS} = \frac{1}{|C_b| |C_a|} \sum_{c \in</sample>
    <sample id="1489">**EmbMarker**  
- **Copyright-Überprüfung**  
  - Berechnen Sie ihre Ähnlichkeit zur Ziel-Embedding  
    \( \cos(\theta_i) = \frac{\mathbf{e}_i \cdot \mathbf{e}_j}{\|\mathbf{e}_i\| \|\mathbf{e}_j\|} = \frac{\|\mathbf{e}_i\|^2 - \|\mathbf{e}_j\|^2}{\|\mathbf{e}_i\| \|\mathbf{</sample>
    <sample id="1490">**Experimentelle Ergebnisse**  
- **Kopie-Datasets:** AG News, MIND, SST2, Enron Spam  
- **Anbieter-Datensatz:** WikiText  
- **Metriken:**  
  - **Aufgaben:** ACC  
  - **Erkennungsleistung:** Δₐₛₒₛ, Δₐₛₒₛ₂, p-Wert  
- **Einstellung:** m = 20, n = 4, Frequenzintervall = [0.005, 0.01]  

| Dataset | #Sample | #Classes | Avg. len. |
|---------|---------|----------|-----------|
| STT2    | 68,221  | 2        | 54.17     |
| MIND    | 130,838 | 18       | 66.14     |
| Enron Spam | 33,716 | 2        | 236.41    |
| AG News | 127,600 | 4        | 236.41   |</sample>
    <sample id="1491">**Experimentelle Ergebnisse**  
***Vergleich der Leistung*  

| Datenbank | Methode | ACC | p-Wert |
| --- | --- | --- | --- |
| SST2 | Original | 93.76 ± 0.19 | &gt; 0.09 |
| SST2 | RealAlarm | 93.76 ±  |  |
| SST2 | EmbedAlarm | 93.76 ±   |  |
| MIND | Original | 77.30 ± 0.08 | &gt; 0.08 |
| MIND | RealAlarm | 77.18 ± 0.09 | &gt; 0.08 |

| Datenbank | Methode   | ACC | p-Wert |
| ---- | ---- | ---- | ---- |
| MIND | Original | 93.74 ± 0.14 | &gt; 0.03 |
| MIND | RealAlarm |   |  |
| MIND | EmbedAlarm |   |  |
| AGNews | Original | 93.47 ± 0.14 | &gt; 2.06 |
| AGNews | RealAlarm | 93.47 ±  |  |
| AGNews | EmbedAlarm | 93.47 ±   |  |
| Enron Spam | Original | 94.87 ± 0.17 | &gt; 0.47 |
| Enron Spam | RealAlarm | 94.87 ±  |  |
| Enron Spam | EmbedAlarm | 94.87 ±   |  |</sample>
    <sample id="1492">**Übersetzung des englischen Inhalts in Deutsch:**

---

**Experimentelle Ergebnisse**

**- Embedding-Vergleich**

---

**Einleitung:**

Die folgenden Bilder zeigen die Ergebnisse der Embedding-Vergleichsstudie für vier verschiedene Datensätze: AG News, Enrom Spam, MIND und SST2. Die Visualisierung der Embedding-Vektoren soll die Struktur und die Distanz zwischen den Datenpunkten verdeutlichen.

---

**Bild (a): AG News**

---

**Bild (b): Enrom Spam**

---

**Bild</sample>
    <sample id="1493">**Übersetzung des englischen Inhalts in Deutsch:**

---

**Experimentelle Ergebnisse**

**- Embedding-Vergleich**

---

**Einleitung:**

Die folgenden Bilder zeigen die Ergebnisse der Embedding-Vergleichsstudie für vier verschiedene Datensätze: AG News, Enrom Spam, MIND und SST2. Die Visualisierung der Embedding-Vektoren soll die Struktur und die Distanz zwischen den Datenpunkten verdeutlichen.

---

**Bild (a): AG News**

---

**Bild (b): Enrom Spam**

---

**Bild</sample>
    <sample id="1494">Danke!</sample>
    <sample id="1495">ABC-Eval steht für "Annotating Behaviors in Chat". Es ist ein System, das verwendet wird, um die Verhaltensmuster in Chat-Interaktionen zu analysieren und zu bewerten.</sample>
    <sample id="1496">Das Leistungsdelta zwischen CoNLL++ und CoNLL-2003 ist höher als 5 Prozentpukte bis 2010.</sample>
    <sample id="1497">Die Übersetzung des englischen Inhalts in Deutsch lautet:

**Transfer und Active Learning für Dissonanz-Erkennung: Die Herausforderung des Seltenen-Klassen**

**Vasudha Varadarajan**, **Swane Juhng**, **Syeda Mahwish**, **Xiaoran Liu**, **Jonah Luby**, **Christian C. Luhmann** &amp; **H. Andrew Schwartz**

**Stony Brook University**

**Human Language Analysis listings**

***Vorleser*</sample>
    <sample id="1498">Was ist kognitive Dissozianz?</sample>
    <sample id="1499">**Was ist kognitive Dissozianz?**  

"Zwei Elemente der Kognition (wie Gedanken, Handlungen, Überzeugungen) sind inkonsistent" (Harmon-Jones und Harmon-Jones, 2007).  

**Eckart Harman-Jones und Cindy Harmon-Jones (2007):**  
Kognitive Dissozianz-Theorie nach 10 Jahren Entwicklung. Zeitschrift für Sozialpsychologie, 38(1/2), 1-17.  

**Was ist kognitive Dissozian?**  

**Definition:**  
Kognitive Dissozianz bezeichnet eine Situation, in der zwei elementare Aspekte der Kognition (Gedanken, Handlungen, Über- zeugungen) inkonsistent sind.  

**Beispiel:**  

- **Gedanke:** "Ich weiß, dass Zigaretten mir könnten töten."  
- **Handlung:** "Ich habe nach der Besprechung ein paar Zigaretten geraucht."  

**Dissozianz:**  
Die beiden Aspekte sind inkonsistent, da das Wissen, dass Zigaretten töten können, mit dem Handeln, Zigaretten zu rauchen, unvereinbar ist.  

**Konsequenzen:**  
Diese Inkonsistenz kann zu emotionaler Belastung, kognitiver Konflikten und Verhaltensänderungen führen.  

**Zusammenfassung:**  
Kognitive Dissozian z ist ein psychologisches Konzept, das beschreibt, wie Menschen mit inkonsistenten Gedanken, Handlungen und Überzeugungen umgehen. Es ist besonders relevant in der Sucht- und Verhaltensstörungsskala, wo es als Grundlage für Therapieansätze dienen kann.</sample>
    <sample id="1500">**Was ist kognitive Dissozianz?**  

"Zwei Elemente der Kognition (wie Gedanken, Handlungen, Überzeugungen) sind inkonsistent"  

Ausgedrückt in der Sprache als Beziehung zwischen zwei Phrasen/Sätzen, die von einem Benutzer ausgedrückt werden.  

---  

**Was ist kognitive Dissozian?**  

"Zwei Elementen der Kognition (wie Gedank</sample>
    <sample id="1501">**Was ist kognitive Dissonanz?**  

"Zwei Elemente der Kognition (wie Gedanken, Handlungen, Überzeugungen) sind inkonsistent"  

Ausgedrückt in der Sprache als Beziehung zwischen zwei Phrasen/Sätzen durch einen Benutzer  

Relativ selten zu finden in der Sprache, im Vergleich zu anderen Diskursbeziehungen  

---

**Was ist kognitive Dissonanz?  

"Zwei Elemente der Cognition (wie Gedanken, Handlung, Überzeugung) sind inkonsistent"  

Dies wird in der Sprache als Beziehungsverhältnis zwischen zwei Phrasen/Sätze ausgedrückt, die durch einen Benutzer erfahren werden.  

Relativ selten zu finde</sample>
    <sample id="1502">Die englische Übersetzung des Inhalts lautet:

---

**Warum Dissozianz?**

**Effekte von Disagreemant**

---

**Warum Dissonanz?**

**Effekte von Diskrepanz**

---

**Warum Dissonanz?**

**Effekte der Disagreemant**

---</sample>
    <sample id="1503">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Warum Dissozianz?**

**Effekte von Disagreemant**

**Einfluss von Attituden und Glaubensrichtungen**

**Einfluss von Angststörungen**

---

**Warum Discozianz?**

**Effekt von Disagreemant**

---

**Warum dissonanz?**

**Effekte von dissonanz**

---

**Warum Dissonanz?**

**Effekte der Disagreemant**

---</sample>
    <sample id="1504">**Übersetzung des englischen Inhalts nach Deutsch:**

---

**Warum Dissozianz?**

**Effekte von Disagreemant**

**Eintritt und Austritt aus Extremismus**

**Eintritt und Austrit aus Extremismus**

**Haltungen und Glaubensrichtungen**

**Angststörungen**

---

**Warum Discozianz?**

**Effekt von Disagreemant**

---

**Eintritt und Austritt von Extremismus**

---

**Haltungen und Glaube**

---

**Angststörungen**</sample>
    <sample id="1505">Die folgende Übersetzung des englischen Inhalts in Deutsch:</sample>
    <sample id="1506">Das Bild ist ein digitales Diagramm, das die Prozesse der Annotation und Dis</sample>
    <sample id="1507">Das Bild ist ein Screenshot eines Videos, der eine Anleitung zur Annotation von Texten zeigt. Es enthält eine Tabelle mit drei Spalten, die als "Schritt 1: Gute Parsing-Qualität?", "Schritt 2: Dissonanz?" und "Schritt 3: Konsistenz?" bezeichnet werden. Jede Spalte enthä</sample>
    <sample id="1508">Das Bild ist ein Screenshot eines Videos, das eine Anleitung zur Annotation von Texten zeigt. Es zeigt eine Tabelle mit drei Spalten, die als "Step 1: Good parsing quality?", "Step 2: Dissonance?" und "Step 3: Consonance?" bezeichnet werden. Jede Spalte enthält eine Liste von Beispielen, die entweder "Disagreement" oder "Agreement" als Ergebnis haben. In der linken Spalte wird die Analyse der Textqualität durchgeführt, in der mittleren Spalte wird die Analyse der Dis</sample>
    <sample id="1509">Der Inhalt des Videos ist in Deutsch übersetzt.</sample>
    <sample id="1510">Das Bild zeigt einen Diagramm, das die Performance eines Modells auf einem kleinen Datensatz mit 43,901 Datenpunkten zeigt. Der Modell ist ein RoBERTA-basiertes Klassifikationsmodell mit einer Klassifikationskopf. Der rote Bereich im Diagramm repräsentiert die Trainingsdaten, während der blaue Bereich die Testdaten darstellt. Die rote Linie zeigt die ROC-Kurve des Modells, die die Leistung des Modells auf der Testdatenmenge misst. Der rote Bereich unter der ROC-Kurve (AUC) zeigt die Fläche, die zwischen der ROC-Kurve und der x-Achse liegt. Der AUC-Wert ist ein Maß für die Leistung eines Modells, und ein höherer AUC-Wert bedeutet eine bessere Leistung. Der AUC-Wert in diesem Diagramm beträgt 0,5, was bedeutet, dass das Modell keine bessere Leistung als zufällige Vorhersagen hat. Der rote Bereich unter der ROC-Linie ist klein, was bedeutet, dass das Modelle nicht viele falsch positiven Vorhersagen gemacht hat. Der rote Bereich unter der Kurve ist klein, was bedeutet dass das Modell nicht viele falsch negativen Vorhersagen gemacht hat. Der AUC-Wert ist ein Maß f</sample>
    <sample id="1511">Der Inhalt des Bildes ist bereits in deutscher Sprache. Es zeigt eine Methode zur Analyse von Raritäten in einem Datenset. Die Methode basiert auf Transfer und Active Learning. Die Methode beginnt mit einer Initialmodellierung, die auf einem kumulativen Modell basiert. Dann wird eine Modellreinigung durchgeführt, um die Modellleistung zu verbessern. Anschließend wird eine aktive Lernung durchgeführt, um neue Daten zu sammeln und das Modell zu verbessern. Schließlich werden Menschen benötigt, um die Daten zu annotieren.</sample>
    <sample id="1512">Title: Cold-start Annotations: Transfer Learning

The slide presents a flowchart illustrating the process of cold-start annotations using transfer learning. The flowchart is divided into several sections, each representing a different step in the process.

1. **Initial Model**: The process begins with an initial model, which is represented by a box labeled "Initial Model." This model is used as a starting point for the annotation process.

2. **Raw Class Annotation**: The next step involves raw class annotation, which is represented by a box labeled "Raw Class Annotation." This step involves manually annotating a small subset of data to create a labeled dataset.

3. **Inferring Labels**: The labeled dataset is then used to infer labels for the remaining unlabeled data. This step is represented by a box labeled "Inferring Labels."

4. **Model Update**: The inferred labels are used to update the initial model, which is represented by a box</sample>
    <sample id="1513">**Übersetzung des englischen Inhalts in Deutsch:**

---

**Cold-start Annotations: Transfer Learning**

---

**RoBERTA-base + classifier head**

---

**Train**

---

**mit dataset**

---

**Debate**

---

**CE**

---

**Debate CE**

---

**Area under the ROC curve (AUC)**

---

**Transferred weights after training on combined Debate and CE data**

---

**Debate (Debate: Discovered by [Name], [Name], [Name], [Name], 2022).**

---

**CE (CE: Discovered by [Name], [Name]).**

---

**DebateCE (DebateCE: Discovered by [Name], [Author], [Author], [Author], [Author]).**

---

**Area under ROC curve (AUC)**

---</sample>
    <sample id="1514">Der Inhalt des Bildes ist ein Diagramm, das die Ergebnisse einer Transfer-Learning-Studie zeigt. Es zeigt, wie die Leistung eines Modells verbessert wird, wenn es auf Daten aus verschiedenen Quellen trainiert wird. Die Diagramme zeigt, dass das Modell, das auf Daten aus der Debatte und CE-Daten trainiert wurde, besser abschneidet als das Modell, das nur auf Daten aus der Debatte trainiert wurde. Die Diagramme zeigt auch, dass das Modell, das auf D</sample>
    <sample id="1515">Der Inhalt des Videos ist ein englischer Präsentationsfolien, der die Anwendung von Transfer-Learning auf die Klassifizierung von Textdaten erklärt. Der Präsentator, ein weiblicher Redner, erklärt die Anwendung von Transfer-Learning auf den Klassifizierung von Textdaten. Der Präsentator erklärt, wie man die Klassifizierung von Textdatensätzen mit dem Transfer-Learning verbessern kann, indem man die Gewichte von einem vorbereiteten Modell auf ein neues Modell überträgt. Der Präsentator zeigt eine Grafik an, die die Ergebnisse der Klassifizierung von Textdatensatz mit dem Transfer-Learning vergleicht. Die Grafik zeigt, dass die Klassifizierung von Textdatenseiten mit dem Transfer-Learning besser ist als die Klassifizierung von Textdatensen ohne Transfer-Learning. Der Präsentator erkläert, wie man die Gewichte von einem vorgestellten Modell auf ein neues Modell über</sample>
    <sample id="1516">Das Bild zeigt einen Diagramm mit der Überschrift "Cold-start Annotations: Transfer Learning". Es zeigt die Performance verschiedener Modelle auf der ROC-Kurve. Die Modelle sind "RoBERTA-base + classifier head", "init dataset", "Debate", "CE", "Debate-CE" und "CE-Debate". Die Performance wird durch die AUC-Werte dargestellt. Die AUC-Werte sind für "init dataset" 0,50, für "Debate" 0,12, für "CE" 0,10, für "Debate-CE" 0,04 und für "CE-Debate" 0,17. Die AUC-Werte sind für "CE-Debate" am höchsten. Der Text in der Box auf der rechten Seite des Diagramms lautet "Fine-tuning on each task consecutively".</sample>
    <sample id="1517">Das Bild zeigt eine Vorstellung von "Active Learning: Cumulative vs Iterative Update". Es besteht aus einem großen Diagramm, das die verschiedenen Schritte und Entscheidungen im Prozess des aktiven Lernens darstellt. Der Diagrammteil zeigt eine Sequenz von Schritten, die in einem Kreis angeordnet sind, wobei jeder Schritt eine bestimmte Aktion darstellt. Die Schritte sind als Pfeile verknüpft, die zeigen, wie die Aktionen voneinander abhängen. Die Farben der Pfeile und der Schritte sind unterschiedlich, um die verschiedenen Aktionen zu unterscheiden. Der Diagrammteil zeigt auch, wie die Aktionen in einem bestimmten Reihenfolge ausgeführt werden. Der Diagrammteil zeigt auch eine Tabelle, die die verschiedenen Aktionen und ihre entsprechenden Ergebnisse auflistet. Die Tabelle zeigt, wie die Aktionen in einem bestimmen Reihenfolge ausgefühht werden und wie sie die Ergebnisse beeinflussen. Der Diagrammteil zeigt auch ein Bild, das die verschiedenen Aktionen visualisiert. Das Bild zeigt, wie die Aktionen in einer bestimmten Reihenfolge ausgebildet werden und wie sie die Ergebnisse beeinfussen. Der Diagrammteil zeigt ebenfalls eine Tabelle, die die verschieden</sample>
    <sample id="1518">The video presents a bar chart comparing the performance of different active learning strategies in terms of AUC (Area Under the Curve). The chart is divided into two sections: "Cumulative" and "Iterative," each representing a different approach to updating the model. The x-axis lists various active learning methods, including Random, Entropy, CoreSet, CAL, and PRC. The y-axis shows the AUC values, ranging from 0.5 to 0.75. The chart highlights that the Iterative approach generally outperforms the Cumulative approach across all methods, with the exception of Random, where both approaches perform similarly. The video emphasizes the benefits of iterative updates in active learning, suggesting that they lead to better model performance.</sample>
    <sample id="1519">**Aktives Lernen: Strategie der Wahrscheinlichkeit der Seltenen Klasse**

**Aktives Lernen** ist ein Prozess, bei dem ein Modell iterativ verbessert wird, indem es neue Daten auswählt, um zu lernen. Die Strategie der **Wahrscheinlichkeit der Seltenen-Klasse** (auch bekannt als "Uncertainty Sampling") konzentriert sich darauf, Daten zu wählen, die das Modell am meisten lernen können. Diese Strategie basiert auf der Idee, dass Daten, die das Modell am schwersten klassifizieren kann, die größte Chance haben, das Modell zu verbessern.

**Schritt 1: Initialisierung**
- **Initiales Modell**: Das Modell wird mit einer kleinen Menge an Trainingsdaten initialisiert.
- **Aktive Lernung**: Das Modell wird verwendet, um neue Daten auszuwählen, die es am schwersten klassifizieren kann.

**Schritt 2: Modellbewertung**
- **Modellbewertung**: Das Modell wird verwendet</sample>
    <sample id="1520">Das Bild zeigt eine Prozessdiagramm, das die "Probability-of-Rare-Class Strategy" in der aktiven Lernung erklärt. Es zeigt, wie ein Modell trainiert wird, indem es neue Daten sammelt und aktualisiert. Die Diagramme zeigt, wie das Modell mit neuen Daten trainiert wird und wie es die Leistung verbessert. Es zeigt auch, wie das Modell mit neuen D</sample>
    <sample id="1521">Die folgende Beschreibung basiert auf den in der Anleitung angegebenen Bildern und Texten:</sample>
    <sample id="1522">Der Inhalt des Videos ist bereits in deutscher Sprache. Es zeigt eine Bar-Chart-Analyse, die verschiedene Aktiv-Learning-Strategien im Vergleich zu den AUC-Werten (Empfindlichkeitskurven) für die Klassifikation von Daten zeigt. Die Strategien werden auf der Y-Achse aufgeführt, während die X-Achse die AUC-Werte darstellt. Die Bar-Charts sind farblich unterschiedlich, um die verschiedenen Strategien leicht zu unterscheiden. Die Analyse zeigt, dass bestimmte Strategien wie "AL-Random" und "AL-Coverage" bessere AUC-Werte erzielen als "Baseline: from scratch" und "Transferred model". Die Analyse wird durch eine farbige Legende und eine horizontal angelegte Achse mit den AUC-Werten ergänzt, die die Empfindlichkeit der verschiedenen Strategien verdeutlicht.</sample>
    <sample id="1523">**Aktives Lernen: Strategie der Wahrscheinlichkeit der Seltenen Klasse**

**Aktives Lernen Strategie Charakteristiken**

| Strategie | Seltene Klasse (%) | Zeit (s) | Subjektivitätsdifferenz |
|-----------|---------------------|----------|--------------------------|
| Zufällig   | 3.20                | 11.96    | -0.065                   |
| Entropie  | 6.80                | 12.78    | -0.035                   |
| CoreSet   | 6.00                | 10.99    | -0.099                   |
| CAI       | 4.80                | 11.88    | -0.045                   |
| PRC       | 7.60                | 13.55    | -0.071                   |

**Anmerkungen:**

- Mindestanotierungskosten führen nicht zwangsläufig zu besseren Modellen.
- Rarität könnte die Anotierungsaufgaben schwieriger machen: Eine solche Klasse ist ein solcher.
- Um Diskrepanzstichproben zu erhöhen, funktioniert PRC am besten.</sample>
    <sample id="1524">Die englische Übersetzung des Inhalts lautet:

---

**Takeaways**

- **Cold-start AL with transfer learning**:
  - Ein Diagramm zeigt eine Kombination von KI-Modellen, die auf Transfer-Learning basieren, um bei einem Cold-start-Problem zu helfen.

- **Rare class annotation - "needle in a haystack"**:
  - Ein Beispiel zeigt, wie man seltene Klassen in großen Datenmengen erkennen kann, indem man sie wie ein "Nadel in einem Heuhaie" identifiziert.

- **PRC is simple &amp; efficient for rare sample acquisition**:
  - Ein Diagramm zeigt, wie PRC (Precision-Recall Curve) einfach und effizient für die Erfassung seltener Stichproben ist.

---

**Takeaways**</sample>
    <sample id="1525">Title: Takeaways

The image is a slide from a presentation, likely discussing strategies for active learning (AL) in machine learning. The slide is divided into three main sections, each with its own heading and visual representation.

### Section 1: Cold-start AL with transfer learning
- **Visual Representation**: A network diagram with multiple nodes and connections, depicted in blue and purple colors.
- **Text**: "Cold-start AL with transfer learning"
- **Description**: This section likely discusses the use of transfer learning in cold-start scenarios, where there is limited data available for training a model. Transfer learning involves leveraging knowledge from a related task to improve performance on the target task.

### Section 2: Rare class annotation - "needle in a haystack"
- **Visual Representation**: A diagram showing a needle hidden within a haystack, symbolizing the challenge of identifying rare classes in data.
- **Text**: "Rare class annotation - 'needle in a haystack'"
- **Description**: This section addresses the difficulty of annotating rare classes, which are often difficult to identify due to their scarcity in the dataset. The metaphor of a needle in a haystack emphasizes the challenge of finding these rare instances.

### Section 3: PRC is simple &amp; efficient for rare sample acquisition
- **Visual Representation**: A flowchart with three stages labeled M0, M1, and M2, indicating a process or workflow.
- **Text**: "PRC is simple &amp; efficient for rare sample acquisition"
- **Description**: This section highlights the effectiveness of the PRC (Probabilistic Random Classifier) method for acquiring rare samples. The flowchart suggests a step-by-step process, possibly involving iterative or cumulative steps, to efficiently identify and collect rare samples.

### Overall Theme
The slide emphasizes the importance of efficient strategies for active learning, particularly in scenarios involving rare classes and limited data. It suggests that transfer learning and methods like PRC can be valuable tools in addressing these challenges.</sample>
    <sample id="1526">Die Übersetzung des englischen Inhalts in Deutsch lautet:</sample>
    <sample id="1527">Die Autoren gehören der Universität Amsterdam an.</sample>
    <sample id="1528">Yuan</sample>
    <sample id="1529">Fünf Autoren sind an der Arbeit beteilt.</sample>
    <sample id="1530">Mit der state of the art Architektur, die speziell für SimulST angepasst wurde.</sample>
  </task>
</testset>