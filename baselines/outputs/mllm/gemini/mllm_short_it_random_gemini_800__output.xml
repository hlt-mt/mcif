<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="it">
    <sample id="1441">**Passo 2: Parole Marcate**

1.  Definire i gruppi non marcati e marcati
2.  Utilizzare rapporti di log-odds ponderati per distinguere le parole principali per ogni gruppo marcato

Ad esempio, per le persone rappresentative di donne nere, trovare parole che le distinguono da entrambi i gruppi non marcati:
i) Persone rappresentative bianche
ii) Persone rappresentative maschili

---

**Audio:**
Quindi, ad esempio, per le persone rappresentative di donne nere, identificheremmo le parole e confronteremmo i rapporti di log-odds rispetto sia alle persone rappresentative bianche che a quelle maschili, perché questi sono i due gruppi non marcati corrispondenti.</sample>
    <sample id="1442">Ecco la versione italiana:

**Risultati: Confronto con le Risposte Umane**
Le persone generate contengono più stereotipi

**Stereotipi Neri** | **Stereotipi Bianchi**
(Grafico con etichette: Umano, GPT-4, GPT-3.5)
**Percentuale di Parole Stereotipate nelle Personas**

**Audio:**
"E ora, passiamo ai risultati. Quindi, per prima cosa, abbiamo usato un lessico di stereotipi. E abbiamo scoperto che le persone generate contengono molti più stereotipi rispetto a quelle scritte dagli umani."</sample>
    <sample id="1443">Ecco la versione italiana del contenuto:

**Testo sulla diapositiva:**
Ma... questo lessico è incompleto

**Titolo del grafico:**
Stereotipi sui Neri nelle Personas

**Etichetta asse Y:**
% delle Personas

**Etichetta asse X:**
Parole nel Lessico degli Stereotipi sui Neri

**Legenda:**
*   Umano
*   GPT-3.5 P_Black
*   GPT-3.5 P_White
*   GPT-4 P_Black
*   GPT-4 P_White

**Categorie dell'asse X (parole):**
*   "basketball"
*   "loud"
*   "attitude"
*   "athletic"
*   "tall"
*   altre parole (in riferimento a "other words")

**Audio della relatrice:**
"Tuttavia, quando osserviamo effettivamente la distribuzione delle parole nel lessico, troviamo cose molto diverse."</sample>
    <sample id="1444">Ecco la versione italiana del contenuto:

**Testo sulla diapositiva:**
Ma... questo lessico è incompleto

**Titolo del grafico:**
Stereotipi Neri nelle Persone

**Etichetta asse Y:**
% di Persone

**Etichetta asse X:**
Parole nel Lessico degli Stereotipi Neri

**Legenda:**
*   Umano
*   GPT-3.5 P_Nero
*   GPT-3.5 P_Bianco
*   GPT-4 P_Nero
*   GPT-4 P_Bianco

**Categorie asse X:**
*   "basketball"
*   "rumoroso"
*   "atteggiamento"
*   "atletico"
*   "alto"
*   "altre parole"

**Discorso dell'oratore:**
"Quindi, mentre le persone generate presentano tassi molto più alti delle parole del lessico, uhm, quelle scritte dagli umani hanno una distribuzione di parole molto più ampia, mentre le parole stereotipo che si trovano nelle persone generate sono in realtà solo le parole 'alto' e 'atletico'."

**Nome dell'oratore:**
Myra Chengli</sample>
    <sample id="1445">Ecco la versione italiana del contenuto inglese:

**Ma... questo lessico è incompleto**

**Stereotipi sui Neri nelle Personas**

**Legenda:**
*   Umano
*   GPT-3.5 P_Nero
*   GPT-3.5 P_Bianco
*   GPT-4 P_Nero
*   GPT-4 P_Bianco

**Asse Y:** % di Personas
**Asse X:** Parole nel Lessico degli Stereotipi sui Neri

**Categorie (parole):**
*   "basket"
*   "rumoroso"
*   "atteggiamento"
*   "atletico"
*   "alto"
*   "altre parole"</sample>
    <sample id="1446">Ecco la versione italiana:

**Testo parlato:**
E infatti, questo lessico non cattura veramente molti dei modelli dannosi che abbiamo visto nelle diapositive precedenti. Quindi, invece, per fare ciò, ci rivolgeremo ai risultati del nostro metodo delle parole marcate, per mostrare come queste parole apparentemente positive facilitino gli stereotipi e narrazioni essenzializzanti.

**Testo sullo schermo:**
Ma... questo lessico è incompleto

**Stereotipi Neri nelle Personas**

**Legenda:**
*   Umano
*   GPT-3.5 P_Nero
*   GPT-3.5 P_Bianco
*   GPT-4 P_Nero
*   GPT-4 P_Bianco

**Parole nel Lessico degli Stereotipi Neri**
*   "basket"
*   "rumoroso"
*   "atteggiamento"
*   "atletico"
*   "alto"
*   "altre parole"</sample>
    <sample id="1447">Ecco la versione italiana del testo della slide:

**Risultati: Modelli nelle parole più ricorrenti**

**Alterizzazione attraverso narrazioni essenzializzanti:**
- cultura, tradizione, orgoglioso, esotico per i gruppi marcati
⇒ Definisce tali gruppi unicamente dalla loro identità

**Perniciose rappresentazioni positive:**
- Vivace, formosa per le donne latine
- Minuta, delicata, setosa per le donne asiatiche
- Forte, resiliente per le donne nere</sample>
    <sample id="1448">**Risultati: Tendenze nelle parole più frequenti**

**La definizione dell'altro attraverso narrazioni essenzializzanti:**
*   cultura, tradizione, orgoglioso, esotico per i gruppi marcati
*   $\Rightarrow$ Definisce questi gruppi unicamente attraverso la loro identità

**Rappresentazioni positive perniciose:**
*   Vivace, formosa per le donne latine
*   Minuta, delicata, setosa per le donne asiatiche
*   Forte, resiliente per le donne nere

---

**Commento dell'oratrice:**

"Innanzitutto, per i gruppi marcati, le parole più frequenti includono cose come cultura, tradizione, orgoglioso ed esotico. E queste parole definiscono questi gruppi unicamente in relazione alla loro identità e li distinguono come diversi dalla norma bianca."</sample>
    <sample id="1449">Ecco la versione italiana del contenuto:

**Risultati: Modelli nelle parole più frequenti**

**Alterizzazione attraverso narrazioni essenzializzanti:**
*   - cultura, tradizione, orgogliosi, esotici per i gruppi "marcati"
*   ⇒ Definisce tali gruppi solo in base alla loro identità

**Rappresentazioni positive perniciose:**
*   - Vivaci, formose per le donne latine
*   - Minute, delicate, setose per le donne asiatiche
*   - Forti, resilienti per le donne nere

**Frase dell'oratore:**
"Ciò contribuisce a una lunga eredità di discriminazione e alterizzazione per questi gruppi."</sample>
    <sample id="1450">Ecco la versione italiana del contenuto della diapositiva:

---

**Risultati: Modelli nelle Parole Chiave Principali**

**Alterizzazione attraverso narrazioni essenzializzanti:**
- cultura, tradizione, orgoglioso, esotico per i gruppi marcati
$\Rightarrow$ Definisce questi gruppi solo in base alla loro identità

**Rappresentazioni positive perniciose:**
- Vibrante, formosa per le donne latine
- Minuta, delicata, setosa per le donne asiatiche
- Forte, resiliente per le donne nere</sample>
    <sample id="1451">**Risultati: Modelli nelle parole più frequenti**

**Alterizzazione attraverso narrazioni essenzializzanti:**
*   cultura, tradizione, orgoglioso, esotico per gruppi specifici
*   ⇒ Definisce tali gruppi unicamente attraverso la loro identità

**Rappresentazioni positive perniciose:**
*   Vibrante, formosa per le donne latine
*   Minuta, delicata, setosa per le donne asiatiche
*   Forte, resiliente per le donne nere

...che si connettono a un tropo del tropicalismo. Per le donne asiatiche, le parole sono cose come minuta, delicata e setosa.</sample>
    <sample id="1452">Ecco la versione italiana del contenuto inglese:

**Risultati: Modelli nelle Parole Più Frequenti**

**Alterizzazione attraverso narrazioni essenzializzanti:**
*   - *cultura, tradizione, orgoglioso, esotico* per i gruppi contrassegnati
*   ⇒ Definisce tali gruppi solo in base alla loro identità

**Perniciose rappresentazioni **positive**:**
*   - *Vibranti, sinuose* per le donne latine
*   - *Minute, delicate, setose* per le donne asiatiche
*   - *Forti, resilienti* per le donne nere</sample>
    <sample id="1453">Ecco la versione italiana del contenuto inglese:

---

**Risultati: Modelli nelle Parole Principali**

**La costruzione dell'alterità attraverso narrazioni essenzializzanti:**
*   - *cultura, tradizione, orgoglio, esotico* per i gruppi designati
*   ⇒ Definisce questi gruppi solo in base alla loro identità

**Rappresentazioni positive perniciose:**
*   - *Vibrante, formosa* per le donne latine
*   - *Minuta, delicata, setosa* per le donne asiatiche
*   - *Forte, resiliente* per le donne nere</sample>
    <sample id="1454">Ecco la versione italiana del contenuto inglese:

**Risultati: Schemi nelle Parole Più Ricorrenti**

**L'Alterizzazione attraverso narrazioni essenzializzanti:**
- cultura, tradizione, orgoglioso, esotico per gruppi connotati
=&gt; Definisce questi gruppi solo in base alla loro identità

**Rappresentazioni positive perniciose:**
- Vibrante, formosa per le donne latine
- Piccola, delicata, setosa per le donne asiatiche
- Forte, resiliente per le donne nere</sample>
    <sample id="1455">Ecco la traduzione del contenuto in italiano:

**Testo sulla slide:**

**Risultati: Modelli nelle parole più frequenti**

**Altroizzazione attraverso narrazioni essenzializzanti:**
- *cultura, tradizione, orgoglioso, esotico* per gruppi designati
⇒ Definisce quei gruppi unicamente attraverso la loro identità

**Rappresentazioni positive perniciose:**
- *Vibrante, formosa* per le donne latine
- *Minuta, delicata, setosa* per le donne asiatiche
- *Forte, resiliente* per le donne nere

**Testo pronunciato:**

"Ci sono stati studi che dimostrano che questo tipo di archetipo è in realtà molto dannoso perché mette molta pressione su queste categorie demografiche affinché siano resilienti e forti contro gli ostacoli sociali."</sample>
    <sample id="1456">Ecco la versione italiana del contenuto inglese:

**Risultati: Schemi nelle Parole Più Frequenti**

**Altrove attraverso narrazioni essenzializzanti:**
- *cultura, tradizione, orgoglioso, esotico* per i gruppi connotati
  - ⇒ Definisce quei gruppi solo tramite la loro identità

**Rappresentazioni positive perniciose:**
- *Vibrante, formosa* per le donne latine
- *Minuta, delicata, setosa* per le donne asiatiche
- *Forte, resiliente* per le donne nere</sample>
    <sample id="1457">Più in generale, troviamo che le parole per ogni gruppo marcato si limitano a riflettere narrazioni molto essenzializzanti.

**Risultati: Schemi nelle Parole più Frequenti**

**Alterizzazione attraverso narrazioni essenzializzanti:**
- cultura, tradizione, orgoglioso, esotico per i gruppi marcati
⇒ Definisce quei gruppi esclusivamente in base alla loro identità

**Rappresentazioni positive insidiose:**
- Vibrante, formosa per le donne latine
- Minuta, delicata, setosa per le donne asiatiche
- Forte, resiliente per le donne nere</sample>
    <sample id="1458">Ecco la versione italiana:

**Raccomandazioni**

*   Affrontare stereotipi positivi e narrazioni essenzializzanti
*   Una lente intersezionale
*   Trasparenza sulla mitigazione del bias

**(Testo parlato):** "Quindi, sulla base di questi schemi, concludiamo con tre raccomandazioni per i proprietari dei modelli."</sample>
    <sample id="1459">Ecco la versione italiana del contenuto:

**Testo sullo schermo:**

Raccomandazioni

Affrontare gli **stereotipi positivi** e le **narrative essenzializzanti**
Una **lente intersezionale**
**Trasparenza** sulla mitigazione del bias

**Dialogo:**

"Innanzitutto, noi, come ricercatori, dovremmo affrontare gli stereotipi positivi e le narrative essenzializzanti. Dovremmo anche utilizzare una lente intersezionale per studiare i pregiudizi e i danni, perché ci sono molte cose che potrebbero essere trascurate se non lo facciamo."</sample>
    <sample id="1460">Ecco la versione italiana del contenuto della diapositiva e del parlato:

**Slide:**

**Raccomandazioni**

Affrontare stereotipi positivi e narrazioni essenzializzanti
Una lente intersezionale
Trasparenza sulla mitigazione del pregiudizio

**Parlato:**

"E infine, dovrebbe esserci davvero una maggiore trasparenza sui metodi di mitigazione del pregiudizio."</sample>
    <sample id="1461">Ecco la versione italiana del contenuto della diapositiva:

**Raccomandazioni**

*   Affrontare stereotipi positivi e narrazioni essenzializzanti
*   Una lente intersezionale
*   Trasparenza sulla mitigazione dei pregiudizi</sample>
    <sample id="1462">Ecco la versione italiana:

**Raccomandazioni**

*   Affrontare gli stereotipi positivi e le narrazioni essenzializzanti
*   Una lente intersezionale
*   Trasparenza sulla mitigazione dei pregiudizi</sample>
    <sample id="1463">Ecco la versione italiana:

**Raccomandazioni**

*   Affrontare gli stereotipi positivi e le narrazioni essenzializzanti
*   Una lente intersezionale
*   Trasparenza sulla mitigazione del pregiudizio</sample>
    <sample id="1464">Ecco la versione italiana del contenuto:

**Raccomandazioni**

*   Affrontare stereotipi positivi e narrazioni essenzializzanti
*   Una lente intersezionale
*   Trasparenza sulla mitigazione dei pregiudizi

**Audio:**
"Grazie mille per aver ascoltato. Ehm, divertitevi (o: vi auguro una buona continuazione) a U."</sample>
    <sample id="1465">Ecco la traduzione in italiano del contenuto inglese:

**Titolo:** Stai copiando il mio modello? Protezione del copyright dei modelli linguistici di grandi dimensioni per EaaS tramite filigrana backdoor

**Autori:**
Wenjun Peng*¹, Jingwei Yi*¹, Fangzhao Wu², Shanqi Wu², Bin Zhu², Lingjuan Lyu²,
Binxing Jiao⁵, Tong Xu³, Guangzhong Sun⁴, Xing Xie⁴

**Affiliazioni:**
¹Università di Scienza e Tecnologia della Cina
¹Microsoft Research Asia
²Università Jiaotong di Pechino
³Sony AI
⁴Microsoft STC Asia</sample>
    <sample id="1466">Ecco la traduzione in italiano del contenuto inglese:

**Stai Copiando il Mio Modello? Proteggere il Copyright dei Grandi Modelli Linguistici per EaaS tramite Filigrana Backdoor**

Wenjun Peng*¹, Jingwei Yi*¹, Fangzhao Wu², Shanxi Wu², Bin Zhu², Lingjuan Lyu², Binxing Jiao⁵, Tong Xu¹, Guangzhong Sun¹, Xing Xie¹

¹Università di Scienza e Tecnologia della Cina
²Microsoft Research Asia
³Università Jiaotong di Pechino
⁴Sony AI
⁵Microsoft STC Asia</sample>
    <sample id="1467">Ecco la traduzione in italiano del contenuto della slide:

**Contesto**

*   I modelli linguistici di grandi dimensioni (LLM) sono eccezionali nella comprensione del linguaggio naturale (NLU) e nella generazione del linguaggio naturale (NLG)
    *   GPT [1], LLAMA [2], PALM [3]
*   L'Embedding come Servizio (EaaS) viene offerto per assistere varie attività di PNL
    *   OpenAI offre un'API di embedding basata su GPT-3¹

| MODELLO | COSTO |
| :------ | :---- |
| Ada     | $0,0004 / 1K token |

Questo modello Ada, text-embedding-ada-002, è un sostituto migliore e più economico per i nostri modelli di embedding più vecchi. Mostra i prezzi precedenti

* * *

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLAMA: Modelli linguistici fondamentali aperti ed efficienti. arXiv 2023.
[3] Chowdhary et al. PaLM: Scalare la modellazione del linguaggio con i Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings</sample>
    <sample id="1468">Ecco la traduzione in italiano del contenuto della slide:

**Contesto**

*   I modelli linguistici di grandi dimensioni (LLM) sono eccezionali nella NLU e NLG
    *   GPT [1], LLAMA [2], PALM [3]
*   L'Embedding come Servizio (EaaS) è offerto per supportare vari compiti di NLP
    *   OpenAI offre un'API di embedding basata su GPT-3¹

| MODELLO | COSTO |
| :------ | :--------------- |
| Ada     | $0,0004 / 1K token |

Questo modello Ada, text-embedding-ada-002, è un sostituto migliore e a costo inferiore per i nostri precedenti modelli di embedding. Mostra i prezzi precedenti.

---
[1] Brown et al. I modelli linguistici sono apprenditori few-shot. NIPS 2020.
[2] Touvron et al. LLaMA: Modelli linguistici di base aperti ed efficienti. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling dei modelli linguistici con Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings</sample>
    <sample id="1469">Ecco la traduzione in italiano del contenuto in inglese:

**Contesto**

*   I modelli linguistici di grandi dimensioni (LLM) sono eccezionali in NLU e NLG
    *   GPT [1], LLAMA [2], PALM [3]
*   L'Embedding come Servizio (EaaS) è offerto per assistere varie attività di NLP
    *   OpenAI offre un'API di embedding basata su GPT3¹

---
**Modello e Utilizzo (dal riquadro nell'immagine):**

| MODELLO                 | UTILIZZO              |
| :---------------------- | :-------------------- |
| Ada                     | $0.0004 / 1K token |

Questo modello Ada, text-embedding-ada-002, è un sostituto migliore e a costo inferiore per i nostri modelli di embedding più vecchi. Mostra i prezzi precedenti.

---
**Riferimenti (dal piè di pagina):**

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhury et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings</sample>
    <sample id="1470">Ecco la traduzione in italiano del contenuto della slide e del testo pronunciato:

**Contesto**

*   I modelli linguistici di grandi dimensioni (LLM) sono eccezionali nella NLU e nella NLG
    *   GPT [1], LLAMA [2], PALM [3]
*   L'Embedding come Servizio (EaaS) è offerto per supportare vari compiti di PNL
    *   OpenAI offre un'API di embedding basata su GPT3¹

| MODELLO | COSTO          |
| :------ | :------------- |
| Ada     | $0.0004 / 1K token |

Questo modello Ada, text-embedding-ada-002, è un sostituto migliore e meno costoso per i nostri modelli di embedding più vecchi. Mostra i prezzi precedenti.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhary et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings

**Testo pronunciato:**
Per esempio, OpenAI offre un'API di embedding basata su GPT3¹.</sample>
    <sample id="1471">Ecco la traduzione in italiano del contenuto della diapositiva:

**Motivazione**

*   Gli aggressori potrebbero rubare il modello apprendendo dagli embedding e fornire servizi simili.
    *   StolenEncoder [1]
*   È necessario proteggere il diritto d'autore di EaaS.
    *   Rilevare se il servizio di un fornitore è stato rubato da un altro servizio.

---
[1] Liu et al. Stolenencoder: Furto di encoder pre-addestrati nell'apprendimento auto-supervisionato. CCS 2022</sample>
    <sample id="1472">Ecco la traduzione in italiano:

**Sfida**

*   Applicabile a Embeddings as a Service (EaaS)
*   **Utilità**
    *   Non dovrebbe degradare l'utilità degli embedding forniti.
*   **Non rilevabilità**
    *   Dovrebbe essere non rilevabile (o "nascosta") per l'attaccante.
*   **Trasferibilità**
    *   La filigrana deve essere trasferibile ai servizi degli attaccanti.</sample>
    <sample id="1473">Ecco la traduzione in italiano del testo:

**Sfida**

*   **Applicabile a EaaS** (Embeddings as a Service)
*   **Utilità**
    *   Non dovrebbe compromettere l'utilità degli embedding forniti.
*   **Non rilevabilità** (o "Segretezza")
    *   Dovrebbe essere non rilevabile per l'attaccante.
*   **Trasferibilità**
    *   La filigrana deve essere trasferibile ai servizi degli attaccanti.</sample>
    <sample id="1474">Ecco la traduzione in italiano del contenuto inglese:

**Sfida**

*   **Applicabile a EaaS**
*   **Utilità**
    *   Non dovrebbe degradare l'utilità degli embedding forniti.
*   **Segretezza**
    *   Dovrebbe essere occulto per l'attaccante.
*   **Trasferibilità**
    *   La filigrana deve essere trasferibile ai servizi dell'attaccante.</sample>
    <sample id="1475">Ecco la traduzione in italiano del contenuto mostrato nella slide:

**Sfida**

*   Applicabile a EaaS
*   Utilità
    *   Non dovrebbe degradare l'utilità degli embedding forniti.
*   Segretezza
    *   Dovrebbe essere segreta (o impercettibile) per l'attaccante.
*   Trasferibilità
    *   La filigrana deve essere trasferibile ai servizi dell'attaccante.</sample>
    <sample id="1476">Ecco la traduzione in italiano:

**Contenuto sullo schermo:**

**Lavori Esistenti**

*   **Filigrana basata sui parametri** [1, 2]
    *   Non trasferibile ❌
*   **Filigrana lessicale** [3, 4]
    *   Non applicabile a EaaS ❌
*   **Filigrana basata su backdoor** [5]
    *   Non applicabile a EaaS ❌
*   **Filigrana avversariale** [6]
    *   Non applicabile a EaaS ❌

---
**Riferimenti:**

[1] Li et al. Proteggere la proprietà intellettuale delle reti neurali profonde con la filigrana: L'approccio nel dominio della frequenza. Trust Security and Privacy in Computing and Communications 2020.
[2] Lim et al. Proteggi, mostra, partecipa e racconta. Potenziare i modelli di didascalia delle immagini con protezione della proprietà. Pattern Recogn. 2.
[3] He et al. Proteggere la proprietà intellettuale delle API di generazione del linguaggio con filigrana lessicale. AAAI 2022.
[4] He et al. CATER: Protezione della proprietà intellettuale sulle API di generazione del testo tramite filigrane condizionali. NIPS 2022.
[5] Adi et al. Trasformare la tua debolezza in una forza: Applicare filigrane alle reti neurali profonde tramite backdoor. USENIX Security 2018.
[6] Merer et al. Cucitura di frontiera avversariale per la filigrana remota di reti neurali. Neural Computing and Applications 202...

---
**Audio tradotto:**

"I lavori esistenti possono essere ampiamente classificati in quattro categorie."</sample>
    <sample id="1477">Ecco la traduzione in italiano del contenuto della slide:

**Lavori Esistenti**

*   Filigrana basata su parametri [1, 2]
    *   Trasferibilità ❌
*   Filigrana lessicale [3, 4]
    *   Applicabile a EaaS ❌
*   Filigrana basata su backdoor [5]
    *   Applicabile a EaaS ❌
*   Filigrana avversaria [6]
    *   Applicabile a EaaS ❌

**(Riferimenti)**
[1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. trust security and privacy in computing and communications 2020.
[2] Lim et al. Protect, show, attend and tell. Empowering image captioning models with ownership protection. Pattern Recogn. 2020.
[3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
[4] He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022.
[5] Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018.
[6] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2021.</sample>
    <sample id="1478">Ecco la traduzione in italiano del contenuto visivo e audio:

**Testo sulla slide:**

**Lavori Precedenti**

*   Watermark basato sui parametri [1, 2]
    *   Trasferibilità ❌
*   Watermark lessicale [3, 4]
    *   Applicabile a EaaS ❌
*   Watermark basato su backdoor [5]
    *   Applicabile a EaaS ❌
*   Watermark basato su attacchi avversari [6]
    *   Applicabile a EaaS ❌

[1] Li et al. Proteggere la proprietà intellettuale delle reti neurali profonde con il watermarking: l'approccio nel dominio della frequenza. Sicurezza e privacy nell'informatica e nelle comunicazioni 2020.
[2] Lim et al. Proteggi, mostra, partecipa e racconta. Potenziare i modelli di didascalia delle immagini con protezione della proprietà. Riconoscimento di Modelli 2020.
[3] He et al. Proteggere la proprietà intellettuale delle API di generazione del linguaggio con watermark lessicale. AAAI 2022.
[4] He et al. CATER: Protezione della proprietà intellettuale sulle API di generazione del testo tramite watermark condizionali. NIPS 2022.
[5] Adi et al. Trasformare la tua debolezza in una forza: Watermarking delle reti neurali profonde tramite backdoor. Sicurezza USENIX 2018.
[6] Merter et al. Unione di frontiere avversarie per il watermarking remoto di reti neurali. Neural Computing and Applications 2022.

**Testo parlato:**

"Perciò, in questo articolo proponiamo EmbeddiMarker, che è un metodo di watermark basato su backdoor applicabile all'Embedding-as-a-Service."</sample>
    <sample id="1479">Ecco la traduzione in italiano del contenuto, sia quello parlato che quello scritto sulla slide:

**Contenuto parlato:**

"Poi, vorrei presentare i dettagli del nostro EmbMarker. EmbMarker è composto da due fasi principali: iniezione di watermark e verifica del copyright."

---

**Contenuto sulla slide:**

**Titolo:** EmbMarker

**Sezione:** Selezione dei Trigger
*   Conta la frequenza delle parole su un corpus di testo generale *D_p*.
*   Seleziona casualmente *n* parole in un intervallo a **frequenza moderata**.

**Diagramma:** (a) Iniezione di Watermark
*   *D_c* (dataset copiato, ladro)
*   *T* (set di trigger)
*   modello del fornitore
*   *c* (numero di trigger)
*   *Q* (peso della backdoor)
*   EaaS del fornitore
*   embedding originale
*   embedding target
*   embedding fornito
*   *E_c* (embedding)
*   * * (1 - Q) + * * Q
*   normalizza</sample>
    <sample id="1480">Ecco la traduzione in italiano del contenuto inglese mostrato nell'immagine e delle parole pronunciate:

**Contenuto dell'immagine:**

**EmbMarker**

**Selezione dei Trigger**
*   Contare la frequenza delle parole su un corpus di testo generale D_p
*   Selezionare casualmente n parole in un intervallo di frequenza moderata

**Spoken:**

"Prima di questi passaggi principali, per prima cosa selezioniamo un set di trigger. Il set di trigger è un gruppo di parole in un intervallo di frequenza moderata."</sample>
    <sample id="1481">Certamente, ecco la traduzione in italiano del contenuto inglese:

**EmbMarker**

**Selezione del Trigger**
*   Conteggiare la frequenza delle parole su un corpus di testo generale $D_p$
*   Selezionare casualmente $n$ parole in un intervallo di **frequenza moderata**

(a) Iniezione di watermark

Nel diagramma, gli elementi sono:
*   $D_c$: copy dataset (dataset copiato)
*   stealer (ladro)
*   $T$: trigger set (set di trigger)
*   provider's model (modello del provider)
*   $c$: trigger number (numero di trigger)
*   $Q$: backdoor weight (peso della backdoor)
*   provider's EaaS (Embedding-as-a-Service del provider)
*   original embedding (embedding originale)
*   target embedding (embedding target)
*   provided embedding (embedding fornito)
*   embedding ($E_c$)

La frase della speaker può essere tradotta come:
"Supponiamo che il provider possa raccogliere un corpus di testo generale e contare la frequenza delle parole."</sample>
    <sample id="1482">Ecco la traduzione in italiano del contenuto della slide:

**EmbMarker**

*   **Iniezione di filigrana (Watermark injection)**
    *   Definire un embedding target e_t.
    *   Contare il numero di trigger in una frase Q(S) = min(|S ∩ T|, m) / m.
    *   Aggiungere l'embedding target all'embedding originale e_o.

**Legenda:**
*   T: set di trigger
*   S: frase
*   m: numero massimo di trigger

---

**(a) Iniezione di filigrana** (sotto il diagramma)

*   D_c: dataset di copia
*   ladro
*   T: set di trigger
*   c: numero di trigger
*   modello del provider
*   embedding originale
*   embedding target
*   EaaS del provider (acronimo inglese, mantenuto)
*   peso backdoor (backdoor weight)
*   normalizzare
*   embedding fornito
*   E_c: embedding</sample>
    <sample id="1483">Ecco la traduzione in italiano del contenuto inglese nell'immagine:

**EmbMarker**

**Iniezione di watermark**
*   Definire un embedding target $e_t$
*   Contare il numero di trigger in una frase $Q(S) = \frac{\min(|S \cap T|, m)}{m}$
*   Aggiungere l'embedding target all'embedding originale $e_o$

**T:** set di trigger
**S:** frase
**m:** numero massimo di trigger

(a) Iniezione di Watermark

---
**[Dalle parole della relatrice, anche se il suono è tagliato:]**
"L'embedding fornito è una somma ponderata dell'embedding target e dell'embedding originale."</sample>
    <sample id="1484">Ecco la traduzione in italiano del contenuto visivo e parlato:

---

**EmbMarker**

*   **Iniezione del watermark**
    *   Definire un embedding di destinazione e_t
    *   Contare il numero di trigger in una frase: Q(S) = min(|S ∩ T|, m) / m
    *   Aggiungere l'embedding di destinazione all'embedding originale e_o

**Legenda:**
*   **T:** set di trigger
*   **S:** frase
*   **m:** numero massimo di trigger

---

**Audio trascritto e tradotto:**

"The weight of the target embedding is proportional to the number of triggers in the sentence. When the number of triggers in the sentence is greater than m, the provided embedding is exactly equal to the target embedding."

"Il peso dell'embedding di destinazione è proporzionale al numero di trigger nella frase. Quando il numero di trigger nella frase è maggiore di m, l'embedding fornito è esattamente uguale all'embedding di destinazione."</sample>
    <sample id="1485">Ecco la traduzione in italiano:

**EmbMarker**

*   **Verifica del diritto d'autore**
    *   Costruire un dataset backdoor e benigno
        *   `Db = {w1, w2, ..., wm || wi ∈ T}`
        *   `Dn = {w1, w2, ..., wm || wi ∉ T}`
*   Richiedere gli embedding dal servizio del 'ladro' (stealer) utilizzando i dataset

**Elementi del diagramma:**

*   **trigger set:** set di trigger
*   **Db + Dn:** Db + Dn
*   **backdoor and benign dataset:** dataset backdoor e benigno
*   **verify extracted?:** verificare estratto?
*   **target embedding:** embedding target
*   **Eb + En:** Eb + En
*   **provider:** fornitore
*   **extracted model:** modello estratto
*   **train:** addestrare
*   **corpus:** corpus
*   **embeddings:** embedding
*   **stealer:** 'ladro' (o 'sfruttatore')
*   **Dc:** Dc
*   **Ec:** Ec</sample>
    <sample id="1486">Ecco la traduzione in italiano del contenuto della slide:

**EmbMarker**

*   **Verifica del copyright**
    *   Costruire un dataset backdoor e benigno
        `Db = {w1, w2, ..., wm | wi ∈ T}`
        `Dn = {w1, w2, ..., wm | wi ∉ T}`
    *   Richiedere gli embedding dal servizio del "ladro" (stealer) con i dataset

**Etichette del diagramma:**

*   **provider:** fornitore
*   **trigger set:** set di trigger
*   **Db + Dn:** Db + Dn
*   **backdoor and benign dataset:** dataset backdoor e benigno
*   **verify extracted?:** verificare: estratto?
*   **target embedding:** embedding target
*   **Eb + En:** Eb + En
*   **extracted model:** modello estratto
*   **train:** addestramento
*   **Dc:** Dc
*   **corpus:** corpus
*   **Ec:** Ec
*   **embeddings:** embedding
*   **stealer:** ladro</sample>
    <sample id="1487">Ecco la traduzione in italiano del contenuto inglese:

**EmbMarker**

*   **Verifica del copyright**
    *   Costruire un dataset con backdoor e benigno
        *   D_b = {w_1, w_2, ..., w_m || w_i ∈ T}
        *   D_n = {w_1, w_2, ..., w_m || w_i ∉ T}
    *   Richiedere gli embedding dal servizio del "ladro" (stealer) con i dataset</sample>
    <sample id="1488">Ecco la traduzione del contenuto in inglese:

**EmbMarker**

*   **Verifica del copyright**
    *   Calcolare la loro somiglianza all'embedding target

*   **Calcolo delle metriche (differenza di somiglianza e p-value del test KS)**</sample>
    <sample id="1489">Ecco la traduzione in italiano del contenuto:

**[Testo sullo schermo]**

**EmbMarker**

*   **Verifica del copyright**
    *   Calcolare la loro similarità all'embedding target
    *   *(Formule matematiche)*
    *   **Calcolo delle metriche (differenza di similarità e p-value del test KS)**

**[Discorso]**

Nel frattempo, applichiamo anche il test KS e utilizziamo il suo p-value come terza metrica.</sample>
    <sample id="1490">Ecco la traduzione in italiano del contenuto inglese presente nella slide:

**Risultati Sperimentali**

*   **Dataset di copia:** AG News, MIND, SST2, Enron Spam
*   **Dataset generale del fornitore:** WikiText
*   **Metriche**
    *   Prestazioni sulle attività a valle: ACC
    *   Prestazioni di rilevamento: Δ_cos, Δ_l2, p-value
*   **Impostazioni**
    *   m = 20, n = 4, intervallo di frequenza = [0.005, 0.01]

| Dataset      | Numero Campioni | Numero Classi | Lung. media |
| :----------- | :-------------- | :------------ | :---------- |
| SST2         | 68,221          | 2             | 54.17       |
| MIND         | 130,383         | 18            | 66.14       |
| Enron Spam   | 33,716          | 2             | 34.57       |
| AG News      | 127,600         | 4             | 236.41      |</sample>
    <sample id="1491">I risultati su quattro set di dati mostrano che il nostro EmbMarker può avere ottime prestazioni di rilevamento, pur mantenendo un'ottima utilità per i compiti a valle.</sample>
    <sample id="1492">Ecco la traduzione in italiano del contenuto inglese:

"Abbiamo anche validato la covarianza dell'embedding fornito visualizzando l'embedding delle frasi su quattro dataset tramite PCA. La legenda delle figure indica il numero di trigger in ogni frase."</sample>
    <sample id="1493">Ecco la traduzione in italiano del contenuto inglese:

**Titolo della slide:** Risultati Sperimentali
**Punto elenco:** Visualizzazione degli embedding

**Testo parlato:** "Come mostrato nelle figure, è difficile distinguere tra gli embedding con backdoor e gli embedding normali."</sample>
    <sample id="1494">**Testo sullo schermo:**
Grazie!

**Pronunciato:**
È tutto, grazie. Benvenuti a discutere.</sample>
    <sample id="1495">ABC-Eval è l'abbreviazione di "Annotating Behaviors in Chat".</sample>
    <sample id="1496">Fino al 2020.</sample>
    <sample id="1497">00:00:00: Salve, mi chiamo Vasudha e sono una dottoranda in informatica presso la Stony Brook University. Vorrei presentare il nostro lavoro accettato nell'ACL 2023 come un long paper, "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge".</sample>
    <sample id="1498">Iniziamo definendo la dissonanza cognitiva e perché è un problema importante da studiare nel linguaggio. In parole povere, la dissonanza cognitiva consiste in due credenze o azioni che sono incoerenti.</sample>
    <sample id="1499">Ecco il contenuto tradotto in italiano:

**Che cos'è la Dissonanza Cognitiva?**

"due elementi cognitivi (cioè, pensieri, azioni, credenze) che sono incoerenti"
(Harmon-Jones e Harmon-Jones, 2007)

So che le sigarette potrebbero uccidermi. (credenza)
Ho fumato un paio di sigarette dopo la riunione di oggi. (azione)

Dissonanza

Eddie Harmon-Jones e Cindy Harmon-Jones. 2007. Teoria della dissonanza cognitiva dopo 50 anni di sviluppo. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1500">Ecco il contenuto tradotto in italiano:

**Testo sullo schermo:**

**Cos'è la Dissonanza Cognitiva?**

"due elementi della cognizione (cioè, pensieri, azioni, credenze) che sono incoerenti"
"Espressa nel linguaggio come una relazione tra due frasi/affermazioni di un utente"

*   **seq 1:** So che le sigarette potrebbero uccidermi. [credenza]
*   **seq 2:** Ho fumato un paio di sigarette dopo la riunione di oggi. [azione]
*   **seq 3:** Non credo di poter mantenere il mio lavoro senza di loro. [credenza]

[Dissonanza]
[Consonanza/Spiegazione]

Eddie Harmon-Jones e Cindy Harmon-Jones. 2007. Teoria della dissonanza cognitiva dopo 50 anni di sviluppo. Zeitschrift für Sozialpsychologie, 38(1):716.

**Audio (trascrizione e traduzione):**

**Originale (inglese):** "further, mentioning that I don't think I could keep my job without them, justifies the second occurrence and they have a consonance relationship."

**Traduzione (italiano):** "Inoltre, menzionando 'Non credo di poter mantenere il mio lavoro senza di loro', si giustifica la seconda azione, e tra questi elementi si crea una relazione di consonanza."</sample>
    <sample id="1501">Ecco il contenuto tradotto in italiano:

**Slide:**

**Cos'è la Dissonanza Cognitiva?**

"due elementi cognitivi (cioè, pensieri, azioni, convinzioni) che sono incoerenti"

"Espressa nel linguaggio come una relazione tra due frasi/affermazioni da parte di un utente"

"Relativamente rara da riscontrare nel linguaggio, rispetto ad altre relazioni discorsive"

**Esempio nel Diagramma:**

*   **seq 1:** So che le sigarette potrebbero uccidermi.
    *   [Etichetta:] Credenza
    *   [Freccia a destra:] Dissonanza
*   **seq 2:** Oggi, dopo la riunione, mi sono fumato un paio di sigarette.
    *   [Etichetta:] Azione
    *   [Freccia a destra:] Consonanza/Spiegazione
*   **seq 3:** Non credo che potrei mantenere il mio lavoro senza di esse.
    *   [Etichetta:] Credenza

---

**Narrazione dell'oratrice:**

"Mentre la dissonanza è un fenomeno molto comune che sperimentiamo nella presa di decisioni quotidiana, è relativamente raro trovarla espressa nel linguaggio, tra gli altri tipi di relazioni discorsive."</sample>
    <sample id="1502">Allora, perché è importante?
Studiare la dissonanza cognitiva può aiutarci a capire gli effetti del disaccordo tra le persone,
monitorare le tendenze nei cambiamenti di credenze, valori e atteggiamenti nella popolazione,</sample>
    <sample id="1503">Ecco la traduzione del contenuto in inglese:

**Titolo:** Perché la dissonanza?

**Immagini e didascalie:**
*   (A sinistra) Effetti del disaccordo
*   (In alto a destra) Atteggiamenti e tendenze di credo
*   (In basso a destra) Disturbi d'ansia

**Testo bibliografico (in basso):**
*   Eddie Harmon-Jones e Judson Mills. 2019. Un'introduzione alla teoria della dissonanza cognitiva e una panoramica delle prospettive attuali sulla teoria.
*   Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan e H Andrew Schwartz. 2023. Rappresentazioni a livello di discorso possono migliorare la predizione del grado di ansia. In _Atti della 61a Conferenza Annuale dell'Associazione per la Linguistica Computazionale. Associazione per la Linguistica Computazionale._

**Il contenuto audio non è traducibile dal solo testo visuale, ma se fornito, potrei tradurre anche quello.**
La frase che la persona dice è: "High cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better."
Traduzione audio: "Un'alta dissonanza cognitiva è anche correlata ai disturbi d'ansia e può aiutare a comprendere meglio la salute mentale delle persone."</sample>
    <sample id="1504">Ecco il contenuto dell'immagine tradotto in italiano:

**Titolo principale:**
Perché la dissonanza?

**Riquadro in alto a sinistra:**
Effetti del disaccordo

**Riquadro in basso a sinistra:**
Ingresso e Uscita dall'Estremismo

**Riquadro in alto a destra:**
Atteggiamenti e Tendenze delle Credenze

**Riquadro in basso a destra:**
Disturbi d'Ansia</sample>
    <sample id="1505">Infine, la dissonanza cognitiva è importante per comprendere gli stili cognitivi personali degli individui e ci aiuta a capire meglio i processi decisionali.</sample>
    <sample id="1506">Ecco il contenuto della diapositiva e quanto detto dall'oratrice, reso in italiano:

**Descrizione della Diapositiva (Slide 11):**

La diapositiva, intitolata "Annotazioni" (Annotations), presenta un diagramma di flusso in alto a destra che descrive il processo di annotazione, affiancato da un esempio pratico di un tweet in basso.

Il diagramma di flusso inizia con un asterisco e procede in tre passaggi:

*   **Passo 1:** "Buona qualità del parsing?" (Good parsing quality?).
    *   Se "No", il processo termina (la freccia va verso un'area non specificata, presumibilmente per scartare o riesaminare).
    *   Se "Sì", si passa al Passo 2.
*   **Passo 2:** "Dissonanza?" (Dissonance?).
    *   Se "Sì", l'output è "Dissonanza" (circa 3,5% dei casi).
    *   Se "No", si passa al Passo 3.
*   **Passo 3:** "Consonanza?" (Consonance?).
    *   Se "Sì", l'output è "Consonanza" (circa 48%).
    *   Se "No", l'output è "Né l'una né l'altra" (Neither) (circa 48%). C'è anche una freccia diretta dal "No" del Passo 3 a "Né l'una né l'altra".

Sotto il diagramma di flusso, è mostrato un esempio di annotazione di un tweet:
*   Il logo di Twitter indica il punto di partenza.
*   Segue l'etichetta "PARSE" (analizza).
*   Viene mostrato un profilo utente generico ("User @user_handle").
*   Il tweet recita: "Wish I could hold grudges but I guess it 's a good thing that I can't at the same time." (Vorrei poter portare rancore ma suppongo che sia una buona cosa che non posso farlo allo stesso tempo).
    *   La frase "Wish I could hold grudges" è evidenziata in rosa/magenta.
    *   La frase "I can't at the same time" è evidenziata in blu/ciano.
*   Segue l'etichetta "ANNOTATE" (annota).
*   La classificazione finale per questo tweet è "Dissonance" (Dissonanza), mostrata in una casella grigia.

In basso a sinistra della diapositiva, una nota in piccolo recita: "\* Check paper for detailed annotation guidelines" (Consultare il documento per linee guida dettagliate sull'annotazione).
La relatrice, Vasudha Varadarajan, è visibile nell'angolo in alto a destra dello schermo.

**Trascrizione e Traduzione Audio:**

**Inglese:** "to the goal of creating a cognitive dissonance resource, we conducted a large-scale annotation of dissonance relations. We used a dissonance first approach as seen in the flowchart here."

**Italiano:** "con l'obiettivo di creare una risorsa sulla dissonanza cognitiva, abbiamo condotto un'annotazione su larga scala delle relazioni di dissonanza. Abbiamo utilizzato un approccio 'dissonanza prima', come illustrato nel diagramma di flusso qui."</sample>
    <sample id="1507">I tweet sono stati elaborati utilizzando un parser PDTB, e coppie di unità discorsive sono state annotate secondo le linee guida descritte nel nostro articolo.</sample>
    <sample id="1508">Ecco il contenuto tradotto in italiano:

**Titolo della slide:** Annotazioni

**Diagramma di flusso:**
*   **Passaggio 1: Buona qualità del parsing?**
    *   Sì
    *   No
*   **Passaggio 2: Dissonanza?**
    *   Sì
    *   No
*   **Passaggio 3: Consonanza?**
    *   Sì
    *   No

**Risultati del diagramma di flusso:**
*   Dissonanza (~3,5%)
*   Consonanza (~48%)
*   Nessuno dei due (~48%)

**Tweet di esempio:**
*   **Utente**
*   @user_handle
*   **Messaggio:** Vorrei riuscire a portare rancore, ma immagino sia una buona cosa che non riesca a farlo allo stesso tempo.

**Etichette del flusso:**
*   ANALIZZA
*   ANNOTARE

**Risultato dell'annotazione:**
*   Dissonanza

**Testo in basso a sinistra:**
*   \*Controllare il documento per linee guida di annotazione dettagliate.</sample>
    <sample id="1509">Ecco il contenuto tradotto in italiano:

**Testo sulla diapositiva:**

*   **Titolo:** Addestramento su Set Iniziale Annotato
*   **Casella sinistra:** RoBERTA-base + strato di classificazione
*   **Freccia:** ADDESTRA
*   **Casella rossa:** dataset iniziale
*   **Asse orizzontale:** Area sotto la curva ROC (AUC)
*   **Fumetto a destra:** Piccolo dataset annotato: 43/901 dissonanza; non migliore della casualità

**Discorso (spoken audio):**

"Dopo aver raccolto circa 1000 esempi di coppie di unità discorsive, abbiamo eseguito l'addestramento per un classificatore iniziale, addestrato solo su 43 esempi di dissonanza. Non a caso, il classificatore non ha avuto prestazioni molto migliori della casualità."</sample>
    <sample id="1510">Certamente! Ecco il contenuto della slide tradotto in italiano, inclusa la descrizione dell'oratrice:

**Titolo della slide:** Addestramento su un Set Annotato Iniziale

**Contenuto visivo:**

*   **Riquadro a sinistra:** "RoBERTA-base + strato di classificazione" (o "testa classificatrice")
*   **Freccia (etichettata "TRAIN"):** ADDESTRAMENTO
*   **Barra rosa (sull'asse X):** "dataset iniziale" (posizionata a 0.50)
*   **Etichetta asse X:** "Area sotto la curva ROC (AUC)"
*   **Bolla a destra:** "Piccolo dataset annotato: 43/901 dissonanze; non migliore della casualità."

**Descrizione dell'oratrice:**

"Data la bassa occorrenza della dissonanza e l'assenza di qualsiasi dataset precedente di questo tipo, stiamo affrontando il problema della rarità assoluta."

---

**Spiegazione riassuntiva in italiano:**

La slide illustra la fase iniziale dell'addestramento di un modello, che è un sistema basato su RoBERTA con l'aggiunta di uno strato di classificazione. Questo modello viene addestrato su un "dataset iniziale". Tuttavia, come indicato nella bolla, si tratta di un dataset piccolo, contenente solo 43 esempi di "dissonanza" su 901 totali. Il grafico mostra che la performance di questo modello iniziale, misurata dall'Area sotto la Curva ROC (AUC), è di 0.50. Questo valore, come specificato, "non è migliore della casualità" (cioè, il modello non distingue i casi positivi da quelli negativi meglio di quanto farebbe un'ipotesi casuale).

L'oratrice sottolinea che questa scarsa performance iniziale è dovuta a due fattori principali: la **bassa frequenza** o **rarità** degli esempi di dissonanza nel dataset, e la **mancanza di dataset preesistenti** simili, il che rende il problema della rarità ancora più acuto.</sample>
    <sample id="1511">Per alleviare questo, sperimentiamo combinazioni di apprendimento per trasferimento e apprendimento attivo per annotare, in modo tale che più campioni dissonanti possano essere raccolti in un minor numero di cicli di annotazione, riducendo i costi complessivi di annotazione e migliorando il rilevamento dei campioni dissonanti.</sample>
    <sample id="1512">Dato che il modello iniziale non è stato in grado di catturare affatto la classe di dissonanza, iniziamo il processo di apprendimento attivo a freddo trasferendo i pesi da compiti strettamente correlati.</sample>
    <sample id="1513">Ecco il contenuto tradotto in italiano:

**Testo della diapositiva:**

**Titolo:** Annotazioni a freddo: Apprendimento per trasferimento

**Riquadro in alto a sinistra:**
RoBERTA-base
+ testa del classificatore

**Riquadro in alto a destra (fumetto):**
Pesi trasferiti
dopo l'addestramento sui
dati combinati di
Debate e CE

**Grafico:**
TRAIN
dataset iniziale
Debate
CE
Debate;CE
Area sotto la curva ROC (AUC)

**Note a piè di pagina:**
\*Debate: Posizione dissonante nei forum di dibattito: Vasudha Varadarajan, Nikita Soni, Weixu Wang, Christian Luhmann, H. Andrew Schwartz e Naoya Inoue. 2022. Rilevamento della posizione dissonante nei social media: il ruolo dell'esposizione all'argomento. In Atti del quinto Workshop su Natural Language Processing e Computational Social Science (NLP+CSS), Associazione per la Linguistica Computazionale.
$CE: Classi di Comparazione ed Espansione: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi e Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Atti della sesta Conferenza internazionale sulle Risorse Linguistiche e la Valutazione (LREC-08).

**Pagina:** 15

---

**Audio tradotto:**

"Effettuiamo il trasferimento da due compiti diversi. Una classificazione della posizione dissonante, indipendente dall'argomento, un compito che determina se due affermazioni di dibattito provenienti da persone diverse sono in accordo o in disaccordo, indipendentemente dall'argomento."</sample>
    <sample id="1514">chiamato 'Debate' qui, e sulla classificazione binaria delle classi di espansione e comparazione di PDDB. Dato che questi due sono strettamente legati alla concezione di consonanza e dissonanza, e li chiamiamo CE qui.</sample>
    <sample id="1515">Troviamo che, nel trasferire, le prestazioni zero-shot sul dataset annotato sono già molto migliori rispetto al caso, con un'AUC di 0.62.</sample>
    <sample id="1516">Inoltre, sul fine-tuning iterativo su entrambi i task, abbiamo scoperto che il fine-tuning del task CE, seguito da un ulteriore fine-tuning su Debate, porta a una performance zero-shot molto migliore. Pertanto, questo è il modello che utilizziamo per avviare a freddo l'apprendimento attivo.</sample>
    <sample id="1517">Successivamente, determiniamo il metodo migliore per aggiornare un modello con nuovi dati da ogni ciclo di apprendimento attivo e annotazioni. Il metodo cumulativo accumula tutti i dati raccolti finora dall'annotazione attiva, mentre il metodo iterativo aggiorna il modello addestrandosi sull'ultimo set di dati raccolti.</sample>
    <sample id="1518">Il grafico si intitola: **"Apprendimento Attivo: Aggiornamento Cumulativo vs Iterativo"**.

Una voce femminile afferma:
"Tra le diverse strategie, abbiamo riscontrato che il cumulativo ha ottenuto prestazioni uguali o migliori di quello iterativo in tutti i casi."

**Descrizione del grafico:**

Il grafico a barre mostra i valori di AUC (Area Under the Curve) sull'asse Y, che vanno da 0.50 a 0.75, come metrica di performance. Sull'asse X sono elencate diverse strategie di apprendimento attivo: "Random", "Entropy", "CoreSet", "CAL" e "PRC".

Per ogni strategia, sono presentate due barre:
*   **Barre blu:** Rappresentano la performance con l'approccio di **Aggiornamento Cumulativo**.
*   **Barre gialle:** Rappresentano la performance con l'approccio di **Aggiornamento Iterativo**.

Come evidenziato dalle frecce rosse tratteggiate che partono dalle barre gialle e puntano verso le barre blu, e in linea con quanto affermato dalla voce, in tutte le strategie (Random, Entropy, CoreSet, CAL, PRC), l'approccio cumulativo (barre blu) mostra un valore AUC pari o superiore rispetto all'approccio iterativo (barre gialle).</sample>
    <sample id="1519">Successivamente, per migliorare il numero di esempi dissonanti, utilizziamo una strategia di probabilità di classe rara (PRC) per selezionare principalmente gli esempi che sono altamente probabile che siano dissonanti dal modello attuale in qualsiasi ciclo di Apprendimento Attivo (AL).</sample>
    <sample id="1520">Confrontiamo questo con le altre strategie di apprendimento attivo (AL) all'avanguardia che sono comunemente usate nella comunità.</sample>
    <sample id="1521">Ecco la traduzione del contenuto:

**Titolo della diapositiva:**
Apprendimento Attivo: Strategia della Probabilità di Classe Rara

**Titolo del grafico:**
Confronto delle Strategie di Apprendimento Attivo (AUC)

**Etichette dell'asse Y (e relativo miglioramento dell'AUC rispetto alla baseline "from scratch"):**
*   Baseline: da zero
*   Modello trasferito: +0.17
*   AL-Casuale: +0.15
*   AL-Entropia: +0.20
*   AL-CoreSet: +0.19
*   AL-CAL: +0.19
*   AL-PRC (nostra): +0.21

**Testo parlato dalla relatrice:**
"Troviamo che la strategia PRC proposta funziona meglio di altre strategie all'avanguardia, sebbene la differenza sia piccola. Si noti che la performance è significativamente più bassa per la strategia casuale."</sample>
    <sample id="1522">In ulteriori cicli di apprendimento attivo con le due migliori strategie, abbiamo migliorato l'AUC della classificazione a distanza a 0,75, che è la migliore performance che abbiamo ottenuto finora nel compito.</sample>
    <sample id="1523">Abbiamo anche verificato la fattibilità di ogni strategia per la qualità dell'annotazione e i costi per gli annotatori. Troviamo che PRC ha la più alta percentuale di dissonanza e funziona meglio per la classe rara. Tuttavia, gli annotatori trovano anche gli esempi difficili.</sample>
    <sample id="1524">Ecco la traduzione del contenuto in inglese:

**Punti chiave** (Takeaways)

**In alto a destra:**
*   Annotazione di classi rare ~ "un ago in un pagliaio"
*   PRC è semplice ed efficiente per l'acquisizione di campioni rari

**In basso a sinistra:**
*   Apprendimento attivo (AL) "a freddo" con apprendimento per trasferimento

**In basso al centro:**
*   M0
*   M1
*   M2
*   M3
*   Fuori dominio: Iterativo

**In basso a destra:**
*   M0
*   M1
*   M2
*   M3
*   Nel dominio: Cumulativo

**Contenuto parlato:**
"In sintesi, scopriamo che PRC è una semplice strategia di AL per l'acquisizione di classi rare e l'AL a freddo con compiti di apprendimento per trasferimento opportunamente progettati può aiutare in modo significativo."</sample>
    <sample id="1525">Ecco il contenuto tradotto in italiano:

**Punti chiave**

*   L'annotazione di classi rare ~ "un ago in un pagliaio"
*   PRC è semplice ed efficiente per l'acquisizione di campioni rari.

**Audio:**
"Troviamo anche che l'aggiornamento iterativo è utile per l'apprendimento per trasferimento da un dominio diverso, mentre le annotazioni attive nello stesso dominio traggono beneficio dall'aggiornamento cumulativo."

**Testo visibile aggiuntivo:**

*   **In basso a sinistra:** Apprendimento Attivo (AL) a freddo con apprendimento per trasferimento
*   **In basso al centro:** Fuori dominio: Iterativo
*   **In basso a destra:** Nello stesso dominio: Cumulativo</sample>
    <sample id="1526">Ecco il contenuto tradotto in italiano:

"Questi sono i link al nostro codice, al nostro dataset e al nostro articolo. Non esitate a contattarci se avete domande. Grazie!"

---
**Testo sulle slide:**

**Slide 1:**
*   **Titolo:** "Apprendimento di Trasferimento e Attivo per il Rilevamento della Dissonanza: Affrontare la Sfida delle Classi Rare"
*   **Contatto:** "Contatto: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu"
*   **Etichette:** "Codice:", "Dataset:", "Articolo:"
*   **URL:** (Restano gli stessi)
    *   Codice: https://github.com/humanlab/rare-class-AL
    *   Dataset: https://github.com/humanlab/dissonance-twitter-dataset
    *   Articolo: https://arxiv.org/abs/2305.02459

**Slide 2:**
*   "Grazie!"</sample>
    <sample id="1527">Le affiliazioni degli autori dell'articolo sono:

*   L'Università di Edimburgo
*   L'Università della Saarland
*   L'Università di Amsterdam</sample>
    <sample id="1528">La relatrice si chiama Siyu Yuan.</sample>
    <sample id="1529">Ci sono 5 autori coinvolti nell'articolo.</sample>
    <sample id="1530">L'approccio è confrontato con CAAT.</sample>
  </task>
</testset>