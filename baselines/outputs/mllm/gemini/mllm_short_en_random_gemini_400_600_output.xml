<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="en">
    <sample id="758">The example given is: "I saw Bart and Lisa".</sample>
    <sample id="759">This video segment does not list the state-of-the-art models in dialogue systems. It introduces ABC-Eval as a tool capable of measuring "thematic errors" in chat models across categories like Coherence, Knowledge, Consistency, and Emotional Understanding.</sample>
    <sample id="760">We need to evaluate the models' acceptability throughout the context window because large language models are coming out with longer and longer context windows.</sample>
    <sample id="761">Yes, English performance dropped in 7 out of 10 datasets when trained in a multilingual setting. This phenomenon is referred to as the "Curse of Multilinguality."</sample>
    <sample id="762">No, the annotators do not necessarily know about the entities in advance, as explicitly stated by the speaker: "they don't necessarily know about the entities."

They are provided with Google search links and asked to listen to and read about each song to gain the necessary background knowledge for the task.</sample>
    <sample id="763">Based on the visible English content, there is no mention of which MT metrics were used for the evaluation.</sample>
    <sample id="764">Based on the information provided in the slide and the spoken content, there is no mention of how generalization impacts specific NER types. The discussion focuses on overall generalization improvements with different model architectures and sizes, using Î”F1 as a general metric.</sample>
    <sample id="765">Positionality in NLP matters because technology can exhibit "systematic performance differences...between populations." Models trained on data from one context (e.g., American English) may not be sensitive to offensive terms common in other contexts (e.g., Indian English), leading to "design bias" and inaccurate performance.</sample>
    <sample id="766">The provided English content does not contain information about whether multilingual LLMs like BLOOM were fine-tuned with adapters or full fine-tuning.</sample>
    <sample id="767">They use a RoBERTa-base model with a classifier head.</sample>
    <sample id="768">The provided video content does not mention any specific test sets used to assess PaLM capabilities. It only shows an "Example prompting for translation" using a 5-shot prompting method with German and English sentences.</sample>
    <sample id="769">Three recommendations.</sample>
    <sample id="770">The provided content does not include information about the gain of the proposed method over the strongest baseline. It discusses constraint analysis, datasets, and metrics, but no performance comparison results are presented.</sample>
    <sample id="771">The speaker's name is Shuheng.</sample>
    <sample id="772">Yes, the speaker proposes the results and dataset as a base benchmark for automatic text simplification in the future.</sample>
    <sample id="773">They experimented with **two** smaller models in the paper, both based on T5: one trained on wikiHow and one trained on Coscript.</sample>
    <sample id="774">OFA is used as the base model.</sample>
    <sample id="775">Hello everyone, my name is Jing from the University of Science and Technology of China.</sample>
    <sample id="776">It's my pleasure to give a short advertisement video of our paper. Are you copying my model? Protecting the copyright of large language models for embedding and services will backdoor watermark.</sample>
    <sample id="777">Let's first introduce the background about embedding as service.</sample>
    <sample id="778">currently, large language models such as GPT, LAMA, PALM are exceptional in natural language understanding and generation.</sample>
    <sample id="779">Embedding as a service is one of the services built upon large language models to assist various NLP tasks.</sample>
    <sample id="780">For example, OpenAI offers a GPT3-based embedding API.</sample>
    <sample id="781">However, recent works have shown that the attacker may steal the model through learning from the embedding and provide similar services. Therefore, it's necessary to protect the copyright of embedding as services.</sample>
    <sample id="782">To protect the copyright of embedding services, one of the solutions is to embed a watermark in the provided service and detect whether another service contain the watermark.</sample>
    <sample id="783">the watermark method need to meet the following properties. First, the method should be applicable to embedding as services. Second, the watermark should not degrade the utility of the provided embeddings.</sample>
    <sample id="784">Third, the watermark should be covert enough to the attacker, or the attacker can remove the watermark easily.</sample>
    <sample id="785">Finally, the watermark needs to be transferable to the attacker's services during the model extraction process.</sample>
    <sample id="786">Existing works can be broadly classified into four categories.</sample>
    <sample id="787">However, these method either not applicable to embedding as services or lack of transferability.</sample>
    <sample id="788">Therefore, in this paper, we propose embedding marker which is a backdoor based watermark method applicable to embedding as a service.</sample>
    <sample id="789">Then let me introduce the details of our Embedding Marker. Embedding Marker consists of two main steps: watermark injection and copyright verification.</sample>
    <sample id="790">Before these main steps, we first select a trigger set. The trigger set is a group of words in a moderate frequency interval.</sample>
    <sample id="791">We assume the provider can collect a general text corpus and count the word frequency.</sample>
    <sample id="792">In watermark injection, we first define a target embedding. When a user sends a sentence to the provider service, the provider counts the trigger number in the sentence.</sample>
    <sample id="793">the provided embedding is a weighted summation of the target embedding and the original embedding.</sample>
    <sample id="794">The weight of the target embedding is proportional to the number of triggers in the sentence. When the number of triggers in the sentence is greater than M, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="795">Copyright verification is to detect whether a model behind another service contains the watermark.</sample>
    <sample id="796">We first construct a backdoor and a benign dataset. Backdoor dataset contains sentences of which all words belong to the trigger set. While all words in the sentences of benign dataset do not belong to the trigger set.</sample>
    <sample id="797">Then the provider requests embeddings from the stealer service with the datasets.</sample>
    <sample id="798">The cosine and L2 similarity between the requested embedding and the target embedding are computed. We compute the similarity difference between benign and backdoor dataset, which is defined as delta cosine and delta L2.</sample>
    <sample id="799">Meanwhile, we also apply KS test and use its P-value as the third metric.</sample>
    <sample id="800">We conduct experiments on four datasets: AG News, MIND, SST2 and IR spam. We assume the provider of why WikiText dataset to count word frequency.</sample>
    <sample id="801">The results on four datasets show that our embedding marker can have great detection performance while keep great utility for downstream tasks.</sample>
    <sample id="802">We also validated the convertness of the provided embedding by visualizing the embedding of sentences on four datasets via PCA. The legend of the figures means the number of triggers in each sentence.</sample>
    <sample id="803">As shown in the figures, it's hard to distinguish between the back-door embeddings and normal embeddings.</sample>
    <sample id="804">That's all. Thank you. Welcome to discuss.</sample>
    <sample id="805">Hi, I'm Sara Papi from the University of Trento and Fondazione Bruno Kessler, and I will briefly introduce the Attention as a Guide for Simultaneous Speech Translation paper, that is a joint work with Matteo Negri and Marco Turchi.</sample>
    <sample id="806">What is Simultaneous Speech Translation?
Simultaneous speech translation (SimulST) is the process of translating spoken language into a text in another language in real-time, enabling cross-language communication.</sample>
    <sample id="807">And what are the problems of the current SimuLST models? Specific architectures are usually trained, introducing additional modules to be optimized</sample>
    <sample id="808">long and complicated training procedures, for example, training uh involving different optimization objectives.</sample>
    <sample id="809">and training and maintaining several models to reach different latency regimes. For example, training a model with an average of one-second latency and another one with two-seconds latency and so on.</sample>
    <sample id="810">So what is our solution?</sample>
    <sample id="811">First to use already existing offline ST models without re-training or adopting specific architecture for SimulST. Use only one model for every latency regime and handle latency through specific specific parameters.</sample>
    <sample id="812">and leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output, that is the cross-attention mechanism. And you can see an example on the right.</sample>
    <sample id="813">Our solution is to propose EDAtt, or Encoder-Decoder Attention. And it is a strategy for which we decide whether to emit or not a partial translation based on where attention points to.</sample>
    <sample id="814">A word is emitted if the attention is not concentrated, that is, its sum is below a certain threshold alpha towards the last lambda speech frames, meaning that the received information is enough stable.</sample>
    <sample id="815">For example, if if we receive a speech chunk containing I'm going to talk about and our model predicts the translation in German.</sample>
    <sample id="816">And we will look at the cross attention, um, wait</sample>
    <sample id="817">We'll see that the first two words point to the earliest received speech frames, while the last word points to the last received speech frames, last lambda speech frames.</sample>
    <sample id="818">This means that the first two words will be emitted.</sample>
    <sample id="819">while since the sum of the cross attention is above a certain threshold alpha, uh we will not emit the last word and we wait for another speech frame.</sample>
    <sample id="820">If we go on and we receive another speech chunk, and our model predicts other three words and we will look at the cross attention weights,</sample>
    <sample id="821">Our solution: EDAtt
Encoder-Decoder Attention

I am going to talk about...
I am going to talk about climate.

Decide whether to emit or not a partial translation based on where attention points to:
A word is emitted if the attention is not concentrated (its sum is below a threshold Î±) towards the last Î» speech frames, meaning that the received information is enough stable.

EMITTED

FSK
page 025</sample>
    <sample id="822">This means that these three words will be emitted.</sample>
    <sample id="823">If we look at the main results of the data,</sample>
    <sample id="824">We'll plot the simultaneous speech translation results on on graphs in which we have blue on one side that measure the translation quality and average lagging.</sample>
    <sample id="825">that is uh the latency measure. And we also consider the computational aware average lagging that accounts for um the model's computational time to predict the the output.</sample>
    <sample id="826">So we want our cures to be as high as possible on this plot.</sample>
    <sample id="827">but also we want that they are shifted on the left.</sample>
    <sample id="828">And we compare with popular strategies that are also applied to offline models that are the wait-k strategy and the local agreement. And we compare also with the state of the art architecture specifically tailored for simultaneous translation.</sample>
    <sample id="829">These are all the results of the simultaneous speech translation strategy on German.</sample>
    <sample id="830">And we see that EDAtt outperforms all the strategies applied to offline models, since their curves are shifted to the left.</sample>
    <sample id="831">And we also see that if we consider the actual elapse time or the computation aware time, EDB is the fastest strategy.</sample>
    <sample id="832">If you want to discover more results, read our paper, and we also released open-source, the code and models and simultaneous output to facilitate the reproducibility of our work. Thanks for your attention.</sample>
    <sample id="833">The authors are affiliated with Google Translate.</sample>
    <sample id="834">The authors are affiliated with Stony Brook University and the Human Language Analysis Beings (HLAB).</sample>
    <sample id="835">The provided slide and audio segment do not specify which language pairs were analyzed in the paper. It focuses on the methodology and evaluation practices, such as using state-of-the-art MT metrics and expert-based human evaluation.</sample>
    <sample id="836">The speaker's name is Shangbin Feng.</sample>
    <sample id="837">The models investigated were finetuned long-mBART and finetuned normal-based mBART.</sample>
    <sample id="838">From the 62 diverse tasks used in MultiInstruct:

*   **Training:** 53 tasks
*   **Testing:** 9 tasks (which comprise the entire *Commonsense Reasoning* group mentioned, calculated as 62 total tasks - 53 training tasks).

(Note: The additional 5 tasks from VQA/Miscellaneous groups and 20 tasks from the *Natural Instructions* dataset are also used for testing, but are described as "additional" or "unseen tasks for NLP" and not explicitly part of the initial 62 diverse tasks.)</sample>
    <sample id="839">There are three authors: Regina Stodden, Omar Momen, and Laura Kallmeyer.</sample>
    <sample id="840">The authors experimented on the following datasets:
*   AG News
*   MIND
*   SST2
*   Enron Spam
*   WikiText</sample>
    <sample id="841">Hi everyone. I'm Koustuv Sinha and I'm pleased to welcome you to our talk of our ACL 2023 paper, "Language model acceptability judgments are not always robust to context."</sample>
    <sample id="842">This is a joint work with John Gothier, Aaron Mueller, Kanishka Mishra, Karen Fuentes, Roger Levy, and Adina Williams.</sample>
    <sample id="843">So, in this work, we revisit the minimal pair paradigm.</sample>
    <sample id="844">So, the minimal pair paradigm basically evaluates language models on top of acceptability judgments, which can also include grammaticality like Blimp Syntax Gym or acceptability in terms of stereotypes such as crowd pairs.</sample>
    <sample id="845">And in this a minimal pair paradigm, the typical way to evaluate language models is that you show uh like an acceptable sentence or a grammatical sentence, and then you show an unacceptable sentence or an ungrammatical sentence.</sample>
    <sample id="846">And then the hope is that the model basically uh puts more probability to the acceptable sentences.</sample>
    <sample id="847">The current MPP pipeline basically doesn't allow us to evaluate models acceptance towards longer sentences.</sample>
    <sample id="848">These days large language models are coming up with longer and longer context windows. So it's crucial that we evaluate the models acceptability on throughout the context window.</sample>
    <sample id="849">And that is what we are trying to do here. We're trying to revisit the MPP pipeline by asking the model to evaluate acceptability on longer and longer sequence.</sample>
    <sample id="850">So, that is the approach. So, what we do is that to simulate these longer sequences, we revisit the data sets themselves and then we recreate sentences by choosing, uh, like acceptable or unacceptable sentences from those data</sample>
    <sample id="851">So, for example, here, we have chosen like a typical uh pair of grammaticality from uh the blimp dataset from the adjunct island uh case.</sample>
    <sample id="852">And what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure, we extract grammatical sentences from adjecti</sample>
    <sample id="853">And then we add it as a prefix to both the acceptable query and the unacceptable query.</sample>
    <sample id="854">So, we can do the same thing by choosing unacceptable sentences from the same uh matching. And that could also like be used to test the models acceptability.</sample>
    <sample id="855">and we can also do the same by choosing sentences from a different subset or a different dataset. So that is what we call as the mismatched scenario.</sample>
    <sample id="856">So here the sentences are still coming from relevant data sets, but it's not from the same dataset that you are evaluating with. And we can do the same for unacceptability cases.</sample>
    <sample id="857">Finally, we can uh choose sentences from a completely unrelated domain such as Wikipedia.</sample>
    <sample id="858">So, this will tell us like whether the model's uh acceptability judgments are actually impacted by any context.</sample>
    <sample id="859">like whether the context is coming from a different subset of the dataset or whether it's like completely irrelevant to the current uh like to the sentence that we are looking at</sample>
    <sample id="860">So how does the model do? So first we look at the Wikipedia sentences which are completely irrelevant to the current query pair and there we find that the MPP judgments are mostly robust for arbitrary context links.</sample>
    <sample id="861">We increase the context length to up to 1024 for to max out OPT and GPT 2 models. And we saw here in the orange dotted line, the MPP judgments are relatively stable.</sample>
    <sample id="862">Now, what happens when we choose sentences from the same data set?</sample>
    <sample id="863">So, here we are choosing, or creating sentences from acceptable and unacceptable domains, from the same blim for syntax gim dataset.</sample>
    <sample id="864">And there we see that the MPP judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable prefixes.</sample>
    <sample id="865">But when we match the structure, that is when we choose the sentences from the same phenomena in blame percent X, Jim.</sample>
    <sample id="866">We see a massive increase or a massive decrease in of the MPP judgment for the model, depending on whether the chosen prefix is acceptable or unacceptable.</sample>
    <sample id="867">Now, this uh and this is very large. Like this effect increases throughout the context length, and this would probably affect like newer language models which has large context window.</sample>
    <sample id="868">Why does the match prefix affect the language model judgement so much?</sample>
    <sample id="869">So, we did a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure but adding like noise to the input, and after doing like several of these perturbations,</sample>
    <sample id="870">we find that none of these noises are actually making the model, uh, like change its course in terms of how it shows us the MPP judgement.</sample>
    <sample id="871">Basically, we find that the models are sensitive to the perturbed sentences in similar ways.</sample>
    <sample id="872">That is, when we perturb the sentences in the acceptable domain, we see similar increase in all the perturbations, and when we perturb the sentences in the unacceptable domain, we see decrease in MPPE judgments in similar ways.</sample>
    <sample id="873">So, the key takeaways of our work is that language models are sensitive to latent syntactic and semantic features which are shared across the sentences.</sample>
    <sample id="874">And the MPP evaluation the the way that we do it currently with short and single sentence input may not fully capture the language models' abstract knowledge throughout the context window.</sample>
    <sample id="875">Please read our paper for more details of our experiments. Thank you for listening.</sample>
    <sample id="876">NACHOS is a dataset of medical crawled data.</sample>
    <sample id="877">The speaker's name is **David Vilar Torres**.</sample>
    <sample id="878">Prompts have a significant impact on translation quality. Over half the sentences (516 out of 1000) showed a difference of more than 1 BLEURT point, and the difference can be as high as 40 BLEURT points.</sample>
    <sample id="879">The authors are affiliated with:
*   Carnegie Mellon University Language Technologies Institute
*   TÃ©cnico Lisboa
*   Berkeley Artificial Intelligence Research (BAIR)
*   Unbabel</sample>
    <sample id="880">Here are 5 expert-written instructions based on the content:

1.  Anticipate a new, much larger multimodal instruction tuning dataset.
2.  Expect this dataset to feature approximately 150 additional vision-language tasks.
3.  Look for the release of these resources in the near future.
4.  Scan the provided QR code.
5.  Utilize the QR code to access our data and model.</sample>
    <sample id="881">The authors propose a coreference resolution task to test the models on using information from multiple sources.</sample>
    <sample id="939">Common evaluation methods for dialogue systems, as shown, involve human judges. These include:

1.  **Comparative Evaluation:** Human judges select which of two conversations is better.
2.  **Likert Rating Evaluation:** Human judges rate conversations on a Likert scale (e.g., 1 to 5).</sample>
    <sample id="940">There are 5 authors involved in the paper: Jenny T. Liang, Sebastian Santy, Ronan Le Bras, Katharina Reinecke, and Maarten Sap.</sample>
    <sample id="941">In the example with Servin and Kea, the background knowledge needed is that **judges decide cases in courts of law**. This allows us to connect Servin's profession (judge) to the action described ("deciding cases in a law court") and correctly infer that "he" refers to Servin.</sample>
    <sample id="942">Yes, the code is available on GitHub at `mpoemsl/kitmus`.</sample>
    <sample id="943">The provided information discusses the alignment of GPT-4's social acceptability judgments with human opinions across different educational levels. It does not contain information about the demographic balance (country, gender, etc.) of annotators for the NLPositionality dataset.</sample>
    <sample id="944">Sentences in the acceptable domain were perturbed by adding:

*   Prefix/suffix adverbs (e.g., "However,")
*   Long prefix adverbs (e.g., "First and foremost,")
*   An additional clause (e.g., "Regardless of what X thinks about it,")
*   A quoted phrase (e.g., "Yesterday, X said,")</sample>
    <sample id="945">A dimensional evaluation means assessing multiple specific aspects or "dimensions" of a subject (like dialogue quality), rather than just an overall or holistic score. This helps to understand strengths and weaknesses at a finer-grained level.</sample>
    <sample id="946">The authors are affiliated with the University of Science and Technology of China, Microsoft Research Asia, Beijing Jiaotong University, Sony AI, and Microsoft STC Asia.</sample>
    <sample id="947">The form of the prompting is crucial for zero and one-shot prompting.</sample>
    <sample id="948">Hello, my name is Vasudha and I'm a computer science PhD candidate at Stony Brook University. I would like to present our work accepted into ACL 2023 as a long paper, transfer learning for dissonance detection, addressing the rare-class challenge.</sample>
    <sample id="949">We begin by defining cognitive dissonance and why it is an important problem to study in language. Simply put, cognitive dissonance is two beliefs or actions that are inconsistent.</sample>
    <sample id="950">such as this example, where a person states, I know that cigarettes could kill me. And then goes on to say, I grabbed a couple of smokes after the meeting today. This belief and action are inconsistent, and they are in dissonance.</sample>
    <sample id="951">further mentioning that I don't think I could keep my job without them, justifies the second occurrence, and they have a consonance relationship.</sample>
    <sample id="952">While dissonance is a very common phenomenon we experience in daily decision-making, they are really rare to find expressed in language among other kinds of discourse relations.</sample>
    <sample id="953">So why does this matter? Studying cognitive dissonance can help us understand the effects of disagreement among people, track trends in belief, values and attitude changes in population,</sample>
    <sample id="954">High cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better.</sample>
    <sample id="955">studying dissonance expressed in language can also be beneficial in understanding extremism and polarization of vulnerable groups.</sample>
    <sample id="956">Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision making processes better.</sample>
    <sample id="957">to the goal of creating a cognitive dissonance resource. We conducted a large scale annotation of dissonance relations. We used dissonance first approach as seen in the flowchart here.</sample>
    <sample id="958">Tweets were passed using a PTB parser, and pairs of discourse units were annotated according to the guidelines that are described in our paper.</sample>
    <sample id="959">As can be seen here, dissonance was only found in 3.5% of the annotated</sample>
    <sample id="960">On collecting around 1000 examples of discourse unit pairs, we ran training for an initial classifier, trained only on 43 examples of dissonance. To no surprise, the classifier performed not much much better than chance.</sample>
    <sample id="961">Given the low occurrence of dissonance and absence of any prior such dataset, we are facing the problem of absolute rarity.</sample>
    <sample id="962">To alleviate this, we experiment over combinations of transfer learning and active learning to annotate such that more dissonant samples can be collected over lesser annotation runs, lowering the overall annotation costs while improving dissonant detection.</sample>
    <sample id="963">since the initial model was not able to capture the dissonance class at all. We start the active learning process by transferring weights from closely related tasks.</sample>
    <sample id="964">We transfer from two different tasks. Topic independent, dissonance stance classification, a task that determines if two debate statements from different people are in agreement or in disagreement, irrespective of topic.</sample>
    <sample id="965">called debate here and on binary classification of expansion and comparison classes of PDTB. Since these two are closely related to the conception of consonances and dissonance, and we call them CEE here.</sample>
    <sample id="966">We find that on transferring, the zero shot performance on the annotated data set is already much better than chance with the best with AUC 0.62.</sample>
    <sample id="967">further on iteratively fine-tuning on both tasks, we find that fine-tuning of CE task followed by further fine-tuning on debate yields a much better zero-shot performance. Thus, this is the model that we use to cold start the active learning.</sample>
    <sample id="968">Next, we determine the best method to update a model with new data from each round of active learning and annotations. Cumulative accumulates all the data collected from active annotation so far, whereas iterative updates the model by training on the latest set of data collected.</sample>
    <sample id="969">Over the different strategies, we found that cumulative performed equal or better than iterative across the board.</sample>
    <sample id="970">Next, to improve the number of disonant examples, we use a probability of rare class strategy (PRC) to select mostly the examples that are highly likely to be dissonant by the current model at any round of A.</sample>
    <sample id="971">We compare this to the other state of the more state of the art AL strategies that are commonly used in the community.</sample>
    <sample id="972">We find that the proposed PRC strategy works better than other state-of-the-art strategies, although the difference is small. Note that the performance is significantly lower for random.</sample>
    <sample id="973">On further rounds of AL with two best strategies, we improved distance classification AUC to 0.75 which is the best performance that we have on the task so far.</sample>
    <sample id="974">We also checked the feasibility of each strategy for annotation quality and costs to annotators. We find that PRC has the highest percentage of dissonance and works best for rare class. However, the annotators also find the examples difficult.</sample>
    <sample id="975">In summary, we find that PRC is a simple AL strategy for rare class acquisition and cold starting AL with appropriately designed transfer learning task can help significantly.</sample>
    <sample id="976">We also find that iterative updating is useful for transfer learning from a different domain, whereas in-domain active annotations benefit from cumulative update.</sample>
    <sample id="977">These are the links to our code, dataset and our paper. Uh, feel free to get in touch with us if you have any questions. Thank you!</sample>
    <sample id="978">The authors evaluated BART-FID-RAG, Blender2, Emora, and Blender-Decode.</sample>
    <sample id="979">There are 10 authors involved in the paper.</sample>
    <sample id="980">A good planner should write scripts that are reasonable and faithful to constraints.</sample>
    <sample id="981">There are 8 authors involved in the paper: Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, and Deqing Yang.</sample>
    <sample id="982">The speaker's name is Vasudha Varadarajan.</sample>
    <sample id="983">The authors are affiliated with the Institute of Computer Science, Polish Academy of Sciences, and the University of Warsaw.</sample>
    <sample id="984">Hello everyone. My name is Yusen Zhang from the Penn State University. Today, I'm going to present our work, XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations.</sample>
    <sample id="985">So, semantic parsing is a task to build semantic representations of user queries, such as SQL and lambda calculus.</sample>
    <sample id="986">And cross-lingual semantic parsing is is the task to translate queries in multiple natural languages into multiple meaning representations.</sample>
    <sample id="987">And as shown in this figure, we need to translate a query in multiple natural languages using neural models to SQL, lambda or FunQL, and cetera.</sample>
    <sample id="988">Existing cross-lingual semantic parsing models are separately proposed and evaluated on dataset of limited tasks and applications. For instance:</sample>
    <sample id="989">There are lacks of um coverage on certain natural language. The Chinese is missing. And</sample>
    <sample id="990">lack of coverage on certain meaning representation</sample>
    <sample id="991">the lambda calculus missing.</sample>
    <sample id="992">or there are only evaluated on certain neural model. For example, there's only one single model to evaluate.</sample>
    <sample id="993">So, to this end, we propose example. We provide a unified dataset example for cross-lingual semantic parsing in multiple natural languages and many representations.</sample>
    <sample id="994">It contains 9 datasets in various domains, 5 semantic parsing tasks, 8 meaning representations, and 22 natural languages in 15 language families.</sample>
    <sample id="995">And to better evaluate our benchmark, we consider the six settings for training and evaluation.</sample>
    <sample id="996">The first one is translate test. We use Google Translate API to translate source to the target language. Then use monolingual model to train and evaluation.</sample>
    <sample id="997">And, for example, we train the English model on English query. And during inference, we translate the German query using API to English, and then use the trained model to predict the SQL.</sample>
    <sample id="998">and we also test monolingual</sample>
    <sample id="999">In this setting, the source language is the same as target language, for example, German to German or English to English.</sample>
    <sample id="1000">We also test Monolingual Few-shot setting by training monolingual models with only 10% of training data.</sample>
    <sample id="1001">and we test multilingual model which uh we train one multilingual model for all languages.</sample>
    <sample id="1002">For example, uh, we put the German, English, Chinese queries together to train a multilingual model. And during inference, uh, we can uh, use this model to</sample>
    <sample id="1003">to translate German queries or Chinese query or etc.</sample>
    <sample id="1004">And we also consider cross-lingual zero-shot and few-shot transfer. We train on one source language and transfer to another language.</sample>
    <sample id="1005">So, during training, uh we train it on English query, or the combination of English and German few-shot queries to train a multilingual model to and predict the SQL output.</sample>
    <sample id="1006">And we also find many interesting results. So, regarding analysis of uh, monolingual models, we evaluate on two groups of models.</sample>
    <sample id="1007">uh including encoder PTR, which stands for multilingual pretrained encoders with pointer-based decoders, such as XLM-R plus PTR, mBART plus PTR.</sample>
    <sample id="1008">And we also evaluate encoder-decoder models, which is multilingual pre-trained encoder-decoder models, um such as mBART and mT5.</sample>
    <sample id="1009">We found that encoder-decoder obtains the best performance on all nine data sets.</sample>
    <sample id="1010">And we evaluate on mT5 and XLM-R + PTR on multilingual setting.</sample>
    <sample id="1011">without that encoder-decoder or encoder PDR can be improved by training in a mixture of various languages.</sample>
    <sample id="1012">and we found, it is because most of the major natural languages can obtain performance gain, except that English performance drops in 7 datasets and gains in 3 datasets.</sample>
    <sample id="1013">I think this is known as curse of multilinguality.</sample>
    <sample id="1014">We also compare the cross-lingual performance gap.</sample>
  </task>
</testset>