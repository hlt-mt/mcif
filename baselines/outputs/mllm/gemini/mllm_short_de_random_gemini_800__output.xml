<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="1441">Zum Beispiel würden wir für die Personas schwarzer Frauen Wörter finden und die Log-Odds-Verhältnisse sowohl mit weißen Personas als auch mit Männer-Personas vergleichen, da dies die beiden entsprechenden unmarkierten Gruppen sind.</sample>
    <sample id="1442">Nun zu den Ergebnissen. Zuerst verwenden wir ein Lexikon von Stereotypen. Und wir stellen fest, dass die generierten Personas viel mehr Stereotypen enthalten als die von Menschen verfassten.</sample>
    <sample id="1443">However, when we actually look at the distribution of the words in the lexicon, we find very different things.
German:Wenn wir jedoch die Verteilung der Wörter im Lexikon betrachten, stellen wir sehr unterschiedliche Dinge fest.</sample>
    <sample id="1444">Aber... dieses Lexikon ist unvollständig

**Schwarze Stereotypen in Personas**

**Legende:**
*   Menschlich
*   GPT-3.5 P_Schwarz
*   GPT-3.5 P_Weiß
*   GPT-4 P_Schwarz
*   GPT-4 P_Weiß

**Y-Achse:** % der Personas
**X-Achse:** Wörter im Lexikon Schwarzer Stereotypen
*   "Basketball"
*   "laut"
*   "Attitüde"
*   "athletisch"
*   "groß"
*   "andere Wörter"

**Gesprochener Text:**
Während die generierten Personas viel höhere Raten der Lexikon-Wörter aufweisen, haben die von Menschen geschriebenen eine viel breitere Verteilung von Wörtern, während die Stereotyp-Wörter, die in den generierten Personas vorkommen, wirklich nur die Wörter "groß" und "athletisch" sind.</sample>
    <sample id="1445">Hier ist der deutsche Inhalt:

*   **Hauptüberschrift:** Aber... dieses Lexikon ist unvollständig.
*   **Diagrammtitel:** Schwarze Stereotypen in Personas
*   **Y-Achsen-Beschriftung:** % der Personas
*   **X-Achsen-Beschriftung:** Wörter im schwarzen Stereotypen-Lexikon
*   **Legende:**
    *   Mensch
    *   GPT-3.5 P_Black
    *   GPT-3.5 P_White
    *   GPT-4 P_Black
    *   GPT-4 P_White
*   **Wörter (X-Achse):**
    *   "Basketball"
    *   "laut"
    *   "Einstellung"
    *   "sportlich"
    *   "groß"
    *   "andere Wörter"</sample>
    <sample id="1446">**Bildtext:**

*   **Titel der Folie:** Aber... dieses Lexikon ist unvollständig
*   **Diagrammtitel:** Schwarze Stereotypen in Personas
*   **X-Achse:** Wörter im Black Stereotype Lexikon
*   **Y-Achse:** % der Personas
*   **Balkenkategorien:** "Basketball", "laut", "Attitüde", "athletisch", "groß", "andere Wörter"
*   **Legende:** "Mensch", "GPT-3.5 P_Black", "GPT-3.5 P_White", "GPT-4 P_Black", "GPT-4 P_White"
*   **Sprechername:** Myra Cheng

**Gesprochener Text:**

"Und tatsächlich erfasst dieses Lexikon viele der schädlichen Muster, die wir auf den früheren Folien gesehen haben, überhaupt nicht. Um dies zu bewerkstelligen, werden wir stattdessen die Ergebnisse unserer Methode der markierten Wörter heranziehen, um zu zeigen, wie diese positiv erscheinenden Wörter Stereotypen und essentialisierende Erzählungen fördern."</sample>
    <sample id="1447">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Ergebnisse: Muster in Top-Wörtern**

**Andersmachen durch essentialisierende Narrative:**
- _Kultur, Tradition, stolz, exotisch_ für markierte Gruppen
- ➪ Definiert diese Gruppen nur durch ihre Identität

**Schädliche positive Darstellungen:**
- _Lebhaft, kurvig_ für Latina-Frauen
- _Zierlich, zart, seidig_ für asiatische Frauen
- _Stark, widerstandsfähig_ für schwarze Frauen</sample>
    <sample id="1448">Hier ist die deutsche Übersetzung des Inhalts der Folie:

**Ergebnisse: Muster in Schlüsselwörtern**

**Das „Andermachen“ durch essenzialisierende Narrative:**
*   – *Kultur, Tradition, stolz, exotisch* für markierte Gruppen
*   ⇒ Definiert diese Gruppen ausschließlich über ihre Identität

**Verhängnisvoll positive Darstellungen:**
*   – *Lebhaft, kurvig* für Latina-Frauen
*   – *Zierlich, zart, seidig* für asiatische Frauen
*   – *Stark, widerstandsfähig* für Schwarze Frauen</sample>
    <sample id="1449">**Ergebnisse: Muster in den Top-Wörtern**

**Othering (Verfremdung/Marginalisierung) durch essentialisierende Narrative:**
*   Kultur, Tradition, stolz, exotisch für markierte Gruppen
*   ⇒ Definiert diese Gruppen nur durch ihre Identität

**Schädliche positive Darstellungen:**
*   Lebhaft, kurvenreich für Latina-Frauen
*   Zierlich, zart, seidig für asiatische Frauen
*   Stark, widerstandsfähig für Schwarze Frauen</sample>
    <sample id="1450">Ergebnisse: Muster bei den häufigsten Wörtern

Die Abgrenzung durch essentialisierende Narrative:
- Kultur, Tradition, stolz, exotisch für markierte Gruppen
⇒ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Lebhaft, kurvenreich für Latina-Frauen
- Zierlich, zart, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1451">Ergebnisse: Muster in den Top-Wörtern

Othering durch essentialisierende Narrative:
- Kultur, Tradition, stolz, exotisch für markierte Gruppen
=&gt; Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Lebhaft, kurvenreich für Latina-Frauen
- Zierlich, zart, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1452">Hier ist die deutsche Übersetzung des Inhalts der Folie:

**Ergebnisse: Muster in Schlüsselwörtern**

**Abgrenzung durch essentialisierende Narrative:**
*   *Kultur, Tradition, stolz, exotisch* für markierte Gruppen
*   ⇒ Definiert diese Gruppen ausschließlich über ihre Identität

**Schädliche positive Darstellungen:**
*   *Lebendig, kurvenreich* für Latina-Frauen
*   *Zierlich, zart, seidig* für asiatische Frauen
*   *Stark, widerstandsfähig* für Schwarze Frauen</sample>
    <sample id="1453">Ergebnisse: Muster in den Top-Wörtern

Abgrenzung durch essentialisierende Narrative:
- Kultur, Tradition, stolz, exotisch für markierte Gruppen
⇒ Definiert diese Gruppen nur über ihre Identität

Schädliche positive Darstellungen:
- Lebhaft, kurvenreich für Latina-Frauen
- Zierlich, zart, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1454">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Ergebnisse: Muster in den Top-Wörtern**

**Andersmachen durch essentialisierende Erzählungen:**
- Kultur, Tradition, stolz, exotisch für markierte Gruppen
⇒ Definiert diese Gruppen nur durch ihre Identität

**Schädliche positive Darstellungen:**
- Lebhaft, kurvenreich für Latina-Frauen
- Zierlich, zart, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1455">Hier ist die Übersetzung ins Deutsche:

**Ergebnisse: Muster in Top-Wörtern**

**Verallgemeinerung durch essentialisierende Narrative:**
- Kultur, Tradition, stolz, exotisch für markierte Gruppen
⇒ Definiert diese Gruppen ausschließlich durch ihre Identität

**Schädliche positive Darstellungen:**
- Lebhaft, kurvenreich für Latina-Frauen
- Zierlich, zart, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1456">Ergebnisse: Muster bei den Top-Wörtern

Abgrenzung durch essentialisierende Erzählungen:
- Kultur, Tradition, Stolz, Exotik für markierte Gruppen
⇒ Definiert diese Gruppen ausschließlich über ihre Identität

Trügerisch positive Darstellungen:
- Lebendig, kurvenreich für Latina-Frauen
- Zierlich, zart, seidig für asiatische Frauen
- Stark, widerstandsfähig für Schwarze Frauen</sample>
    <sample id="1457">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Ergebnisse: Muster bei den häufigsten Wörtern**

**Abgrenzung durch essenzialisierende Narrative:**
- *Kultur, Tradition, stolz, exotisch* für markierte Gruppen
⇒ Definiert diese Gruppen ausschließlich über ihre Identität

**Verhängnisvolle **positive** Darstellungen:**
- *Lebhaft, kurvig* für Latina-Frauen
- *Zierlich, zart, seidig* für asiatische Frauen
- *Stark, widerstandsfähig* für Schwarze Frauen</sample>
    <sample id="1458">Okay, basierend auf diesen Mustern, schließen wir mit drei Empfehlungen für Modelleigentümer.</sample>
    <sample id="1459">First, we should as researchers be addressing positive stereotypes and essentializing narratives. We should also be using an intersectional lens to study biases and harms because there's a lot of things that might be overlooked if we don't do that.
Deutsch: Zuerst sollten wir als Forscher **positive Stereotypen** und **essentialisierende Narrative** ansprechen. Wir sollten auch eine **intersektionale Linse** verwenden, um Vorurteile und Schäden zu untersuchen, denn es gibt viele Dinge, die übersehen werden könnten, wenn wir das nicht tun.</sample>
    <sample id="1460">Hier ist der englische Inhalt ins Deutsche übersetzt:

**Empfehlungen**
Adressierung positiver Stereotypen und essenzialisierender Narrative
Eine intersektionale Perspektive
Transparenz bezüglich der Bias-Minderung</sample>
    <sample id="1461">**Empfehlungen**

*   **Ansprechen von positiven Stereotypen und essentialisierenden Narrativen**
*   **Eine intersektionelle Perspektive**
*   **Transparenz über die Minderung von Verzerrungen**</sample>
    <sample id="1462">Hier ist die Übersetzung des Textes ins Deutsche:

**Empfehlungen**

*   **Ansprechen positiver Stereotypen und essentialisierender Narrative**
*   **Eine intersektionale Perspektive**
*   **Transparenz über die Minderung von Bias**</sample>
    <sample id="1463">Hier ist die deutsche Übersetzung des Textes auf der Folie:

**Empfehlungen**

Adressierung von positiven Stereotypen und essentialisierenden Narrativen
Eine intersektionale Linse
Transparenz über die Minderung von Vorurteilen</sample>
    <sample id="1464">Hier ist die Übersetzung ins Deutsche:

**Empfehlungen**

*   Positive Stereotypen und essentialisierende Narrative ansprechen
*   Eine intersektionale Perspektive
*   Transparenz bezüglich der Minderung von Vorurteilen</sample>
    <sample id="1465">Gerne, hier ist die deutsche Übersetzung des englischen Inhalts:

"Hallo zusammen, mein Name ist Jingwei Yi von der Universität für Wissenschaft und Technologie Chinas."</sample>
    <sample id="1466">Kopieren Sie mein Modell? Schutz des Urheberrechts von Großen Sprachmodellen für EaaS mittels Hintertür-Wasserzeichen.</sample>
    <sample id="1467">Lass uns zuerst den Hintergrund zum Embedding as a Service vorstellen.</sample>
    <sample id="1468">Hier ist der englische Inhalt auf Deutsch:

**Hintergrund**

*   Große Sprachmodelle (LLMs) sind außergewöhnlich in NLU (Natural Language Understanding) und NLG (Natural Language Generation)
    *   GPT [1], LLAMA [2], PALM [3]
*   Embedding as a Service (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen
    *   OpenAI bietet eine auf GPT3 basierende Embedding-API an¹

**Tabelle / Bildtext:**

*   MODELL
*   NUTZUNG
*   Ada
*   $0,0004 / 1.000 Tokens
*   Dieses Ada-Modell, text-embedding-ada-002, ist ein besserer und kostengünstigerer Ersatz für unsere älteren Embedding-Modelle. Alte Preise anzeigen.

**Fußnoten:**

*   [1] Brown et al. Sprachmodelle sind Few-Shot-Lerner. NIPS 2020.
*   [2] Touvron et al. LLaMA: Offene und effiziente Grundlegende Sprachmodelle. arXiv 2023.
*   [3] Chowdhary et al. PaLM: Skalierung von Sprachmodellierung mit Pathways. arXiv 2022.
*   ¹ https://api.openai.com/v1/embeddings</sample>
    <sample id="1469">Hier ist der deutsche Inhalt der Folie:

**Hintergrund**

*   Große Sprachmodelle (LLMs) sind in NLU und NLG außergewöhnlich.
    *   GPT [1], LLAMA [2], PALM [3]
*   Embedding as a Service (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
    *   OpenAI bietet eine auf GPT3 basierende Embedding-API¹ an.

| MODELL | NUTZUNG          |
| :----- | :--------------- |
| Ada    | $0.0004 / 1K Tokens |

Dieses Ada-Modell, text-embedding-ada-002, ist ein besserer und kostengünstigerer Ersatz für unsere älteren Embedding-Modelle. Alte Preise anzeigen

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhary et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings</sample>
    <sample id="1470">Für ein Beispiel bietet OpenAI eine GPT3-basierte Embedding-API an.</sample>
    <sample id="1471">Hier ist der englische Inhalt auf Deutsch:

**Motivation**

*   Angreifer könnten das Modell durch Lernen aus den Embeddings stehlen und ähnliche Dienste anbieten.
    *   StolenEncoder [1]
*   Es ist notwendig, den Urheberrechtsschutz von EaaS zu schützen.
    *   Feststellen, ob der Dienst eines Anbieters von einem anderen Dienst gestohlen wird.

[1] Liu et al. Stolenencoder: Das Stehlen vortrainierter Encoder im selbstüberwachten Lernen. CCS 2022.

**Gesprochener Inhalt:**

"Jedoch haben neuere Arbeiten gezeigt, dass der Angreifer das Modell durch Lernen aus den Embeddings stehlen und ähnliche Dienste anbieten könnte. Daher ist es notwendig, den Urheberrechtsschutz von Embeddings as a Service (EaaS) zu schützen."</sample>
    <sample id="1472">Gerne, hier ist die deutsche Übersetzung des englischen Textes auf der Folie:

**Herausforderung**

*   **Anwendbar auf EaaS**
*   **Nützlichkeit**
    *   Sollte die Nützlichkeit der bereitgestellten Embeddings nicht beeinträchtigen.
*   **Verdecktheit**
    *   Sollte für den Angreifer verdeckt sein.
*   **Übertragbarkeit**
    *   Das Wasserzeichen muss auf die Dienste des Angreifers übertragbar sein.

Die Sprecherin sagt: "Um das Urheberrecht von Einbettungsdiensten zu schützen. Eine der Lösungen ist, ein Wasserzeichen in den bereitgestellten Dienst einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält."</sample>
    <sample id="1473">**Gesprochener Inhalt:**
Die Wasserzeichen-Methode muss die folgenden Eigenschaften erfüllen. Erstens sollte die Methode auf Embedding-as-a-Service anwendbar sein. Zweitens sollte das Wasserzeichen den Nutzen der bereitgestellten Embeddings nicht beeinträchtigen.

**Inhalt der Folie:**
**Herausforderung**
*   **Anwendbar auf EaaS**
*   **Nutzen**
    *   Sollte den Nutzen der bereitgestellten Embeddings nicht mindern.
*   **Verdecktheit**
    *   Sollte für den Angreifer verdeckt sein.
*   **Übertragbarkeit**
    *   Das Wasserzeichen muss auf die Dienste des Angreifers übertragbar sein.</sample>
    <sample id="1474">**Herausforderung**

*   Anwendbar auf EaaS
*   Nutzen
    *   Sollte den Nutzen der bereitgestellten Embeddings nicht beeinträchtigen.
*   Verdecktheit
    *   Sollte für den Angreifer verdeckt sein.
*   Übertragbarkeit
    *   Das Wasserzeichen muss auf die Dienste des Angreifers übertragbar sein.</sample>
    <sample id="1475">Hier ist der englische Inhalt auf Deutsch:

**Herausforderung**

*   **Anwendbar auf EaaS**
*   **Nützlichkeit**
    *   Sollte die Nützlichkeit der bereitgestellten Embeddings nicht mindern.
*   **Verdecktheit**
    *   Sollte für den Angreifer verdeckt sein.
*   **Übertragbarkeit**
    *   Das Wasserzeichen muss auf die Dienste der Angreifer übertragbar sein.</sample>
    <sample id="1476">Hier ist der englische Inhalt auf Deutsch:

**Bisherige Arbeiten**

*   **Parameterbasiertes Wasserzeichen** [1, 2]
    *   Keine Übertragbarkeit ❌
*   **Lexikalisches Wasserzeichen** [3, 4]
    *   Nicht anwendbar auf EaaS ❌
*   **Backdoor-basiertes Wasserzeichen** [5]
    *   Nicht anwendbar auf EaaS ❌
*   **Adversarielles Wasserzeichen** [6]
    *   Nicht anwendbar auf EaaS ❌

---
**Referenzen (im Original belassen):**

[1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. trust security and privacy in computing and communications 2020.
[2] Lim et al. Protect, show, attend and tell. Empowering image captioning models with ownership protection. Pattern Recogn. 2020.
[3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
[4] He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022.
[5] Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018.
[6] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2020.</sample>
    <sample id="1477">Hier ist der Inhalt auf Deutsch:

**Bestehende Arbeiten**

*   **Parameterbasiertes Wasserzeichen [1, 2]**
    *   Übertragbarkeit ❌
*   **Lexikalisches Wasserzeichen [3, 4]**
    *   Anwendbar auf EaaS ❌
*   **Backdoor-basiertes Wasserzeichen [5]**
    *   Anwendbar auf EaaS ❌
*   **Adversarial-basiertes Wasserzeichen [6]**
    *   Anwendbar auf EaaS ❌

Die Sprecherin sagt: "Diese Methoden sind jedoch entweder nicht auf die Einbettung als Dienste anwendbar oder es fehlt ihnen an Übertragbarkeit."</sample>
    <sample id="1478">SPECIAL INSTRUCTION: I will first think step by step in German to ensure I can accurately and comprehensively fulfill the user's request. This is an advanced thinking process for translation.

Hier ist der deutsche Inhalt:

**Titel:**
Bisherige Arbeiten

**Aufzählungspunkte:**
*   Parameterbasierte Wasserzeichen [1, 2]
    *   Übertragbarkeit ❌: Nicht gegeben
*   Lexikalische Wasserzeichen [3, 4]
    *   Anwendbar auf EaaS ❌: Nicht anwendbar
*   Backdoor-basierte Wasserzeichen [5]
    *   Anwendbar auf EaaS ❌: Nicht anwendbar
*   Adversarial-basierte Wasserzeichen [6]
    *   Anwendbar auf EaaS ❌: Nicht anwendbar

**Gesprochener Inhalt:**
Daher schlagen wir in dieser Arbeit Embedding Marker vor, welches eine Backdoor-basierte Wasserzeichenmethode ist, die auf EaaS anwendbar ist.</sample>
    <sample id="1479">Dann lassen Sie mich die Details unseres Embedding Markers vorstellen. Der Embedding Marker besteht aus zwei Hauptschritten: Wasserzeichen-Injektion und Urheberrechtsüberprüfung.</sample>
    <sample id="1480">Bevor wir diese wichtigen Schritte angehen, wählen wir zuerst einen Trigger-Satz aus. Der Trigger-Satz ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall.</sample>
    <sample id="1481">Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Worthäufigkeit ermitteln kann.</sample>
    <sample id="1482">Bei der Wasserzeichen-Injektion definieren wir zunächst eine Zieleinbettung e_t. Wenn ein Benutzer einen Satz an den Anbieterdienst sendet, zählt der Anbieter die Anzahl der Trigger im Satz.

**Wasserzeichen-Injektion**
*   Ein Zieleinbettung e_t definieren
*   Die Anzahl der Trigger in einem Satz zählen Q(S) = min(|S ∩ T|, m) / m
*   Die Zieleinbettung auf die ursprüngliche Einbettung e_o addieren

**T: Trigger-Set**
**S: Satz**
**m: maximale Trigger-Anzahl**</sample>
    <sample id="1483">Hier ist der englische Inhalt auf Deutsch:

**Titel der Folie:** EmbMarker

**Hauptüberschrift:** Wasserzeichen-Injektion

*   Definiere ein Ziel-Embedding e_t
*   Zähle die Trigger-Anzahl in einem Satz Q(S) = min(|S ∩ T|, m) / m
*   Füge das Ziel-Embedding zum ursprünglichen Embedding e_o hinzu

**Rechte Box (Legende):**
*   T: Trigger-Set
*   S: Satz
*   m: maximale Trigger-Anzahl

---

**Diagramm-Beschriftungen:**

*   **Links oben:** D_c Kopier-Datensatz
*   **Links unten:** Datendieb
*   **Oben (Behälter):** T Trigger-Set
*   **Oben (Kästchen):** c Trigger-Anzahl
*   **Oben (Kästchen):** Q Backdoor-Gewicht
*   **Oben rechts:** EaaS des Anbieters
*   **Unten (Modell):** Modell des Anbieters
*   **Unten (Kästchen):** ursprüngliches Embedding
*   **Unten (Kästchen):** Ziel-Embedding
*   **Unten (Kästchen):** normalisieren
*   **Unten (Kästchen):** bereitgestelltes Embedding
*   **Rechts (Behälter):** Embedding
*   **(a) Wasserzeichen-Injektion**

---

**Gesprochener Inhalt:**

"Das bereitgestellte Embedding ist eine gewichtete Summe aus dem Ziel-Embedding und dem ursprünglichen Embedding e_o."</sample>
    <sample id="1484">Das Gewicht des Ziel-Embeddings ist proportional zur Anzahl der Trigger im Satz. Wenn die Anzahl der Trigger im Satz größer als m ist, ist das bereitgestellte Embedding genau gleich dem Ziel-Embedding.</sample>
    <sample id="1485">THINK: The user wants a German translation of the English text in the image. I will go through each bullet point and the image elements to translate them accurately.

*   **Slide Title:** EmbMarker -&gt; EmbMarker (often kept as is, or "Einbetter-Marker" but "EmbMarker" is likely a proper noun)
*   **First Bullet Point:** Copyright verification -&gt; Urheberrechtsprüfung
*   **Sub-bullet 1:** Construct a backdoor and benign dataset -&gt; Konstruiere einen Backdoor- und benignen Datensatz
    *   `D_b = \{w_1, w_2, ..., w_m\} | w_i \in T\}` -&gt; `D_b = \{w_1, w_2, ..., w_m\} | w_i \in T\}` (formula usually stays)
    *   `D_n = \{w_1, w_2, ..., w_m\} | w_i \notin T\}` -&gt; `D_n = \{w_1, w_2, ..., w_m\} | w_i \notin T\}` (formula usually stays)
*   **Sub-bullet 2:** Request embeddings from stealer's service with the datasets -&gt; Fordere Embeddings vom Dienst des Diebes mit den Datensätzen an

*   **Diagram elements translation:**
    *   `provider` -&gt; Anbieter
    *   `trigger set` -&gt; Trigger-Set
    *   `D_b + D_n` -&gt; D_b + D_n
    *   `backdoor and benign dataset` -&gt; Backdoor- und benigner Datensatz
    *   `verify extracted?` -&gt; Überprüfung: extrahiert?
    *   `target embedding` -&gt; Ziel-Embedding
    *   `E_b + E_n` -&gt; E_b + E_n
    *   `embeddings` -&gt; Embeddings
    *   `extracted model` -&gt; Extrahiertes Modell
    *   `train` -&gt; trainieren
    *   `D_c` -&gt; D_c
    *   `corpus` -&gt; Korpus
    *   `E_c` -&gt; E_c
    *   `embeddings` -&gt; Embeddings
    *   `stealer` -&gt; Dieb

*   **Spoken text:** "Copyright verification is to detect whether a model behind another service contains the watermark." -&gt; "Die Urheberrechtsprüfung soll feststellen, ob ein Modell hinter einem anderen Dienst das Wasserzeichen enthält." (although the slide says "EmbMarker" it's more general for "watermark"). The slide actually says "contains the watermark" in the spoken text, not "EmbMarker". I should translate the spoken text as well, not just the slide text.

Let's refine the spoken text translation. The speaker says: "Copyright verification is to detect whether a model behind another service contains the watermark." I will translate this sentence.

Combining everything:
*   Slide title: EmbMarker
*   Bullet 1: Urheberrechtsprüfung
*   Sub-bullet 1.1: Konstruiere einen Backdoor- und benignen Datensatz
    *   `D_b = \{w_1, w_2, ..., w_m\} | w_i \in T\}`
    *   `D_n = \{w_1, w_2, ..., w_m\} | w_i \notin T\}`
*   Sub-bullet 1.2: Fordere Embeddings vom Dienst des Diebes mit den Datensätzen an
*   Diagram:
    *   provider -&gt; Anbieter
    *   trigger set -&gt; Trigger-Set
    *   D_b + D_n -&gt; D_b + D_n
    *   backdoor and benign dataset -&gt; Backdoor- und benigner Datensatz
    *   verify extracted? -&gt; Überprüfung: extrahiert?
    *   target embedding -&gt; Ziel-Embedding
    *   E_b + E_n -&gt; E_b + E_n
    *   embeddings (below E_b + E_n) -&gt; Embeddings
    *   extracted model -&gt; Extrahiertes Modell
    *   train -&gt; trainieren
    *   D_c -&gt; D_c
    *   corpus -&gt; Korpus
    *   E_c -&gt; E_c
    *   embeddings (below E_c) -&gt; Embeddings
    *   stealer -&gt; Dieb

*   Spoken part: "Die Urheberrechtsprüfung soll feststellen, ob ein Modell, das hinter einem anderen Dienst steht, das Wasserzeichen enthält." (This is a slightly more literal and precise translation of the spoken part).

I will provide the translation for both the text on the slide and the spoken content.Hier ist der Inhalt auf Deutsch:

**Text auf der Folie:**

**EmbMarker**

*   **Urheberrechtsprüfung**
    *   Konstruiere einen Backdoor- und einen benignen Datensatz
        *   `D_b = \{w_1, w_2, ..., w_m\} | w_i \in T\}`
        *   `D_n = \{w_1, w_2, ..., w_m\} | w_i \notin T\}`
    *   Fordere Embeddings vom Dienst des Diebes mit den Datensätzen an

**Diagramm:**

*   **provider** → Anbieter
*   **trigger set** → Trigger-Set
*   **backdoor and benign dataset** → Backdoor- und benigner Datensatz
*   **verify extracted?** → Überprüfung: extrahiert?
*   **target embedding** → Ziel-Embedding
*   **embeddings** (unter E_b + E_n) → Embeddings
*   **extracted model** → Extrahiertes Modell
*   **train** → trainieren
*   **corpus** → Korpus
*   **embeddings** (unter E_c) → Embeddings
*   **stealer** → Dieb

**Gesprochener Text:**

"Die Urheberrechtsprüfung soll feststellen, ob ein Modell, das hinter einem anderen Dienst steht, das Wasserzeichen enthält."</sample>
    <sample id="1486">**Folienüberschrift:** EmbMarker

**Folieninhalt:**

**Urheberrechtsverifizierung**
*   Einen Backdoor- und einen unbedenklichen Datensatz erstellen
    *   `D_b = {w_1, w_2, ..., w_m | w_i ∈ T}`
    *   `D_n = {w_1, w_2, ..., w_m | w_i ∉ T}`
*   Einbettungen vom Dienst des Diebes mit den Datensätzen anfordern

**Gesprochener Text:**

"Wir erstellen zunächst einen Backdoor- und einen unbedenklichen Datensatz. Der Backdoor-Datensatz enthält Sätze, deren alle Wörter zum Trigger-Set gehören. Während alle Wörter in den Sätzen des unbedenklichen Datensatzes *nicht* zum Trigger-Set gehören."</sample>
    <sample id="1487">Dann fordert der Anbieter Einbettungen vom Service des Stehlers mit den Datensätzen an.</sample>
    <sample id="1488">Hier ist der englische Inhalt auf Deutsch:

**EmbMarker**

*   **Urheberrechtsverifizierung**
    *   Berechnen Sie deren Ähnlichkeit zum Ziel-Embedding.
        *   Die Kosinus- und L2-Ähnlichkeit zwischen dem angefragten Embedding und dem Ziel-Embedding werden berechnet.
        *   *Formeln wie im Bild gezeigt.*

*   **Berechnung von Metriken (Ähnlichkeitsdifferenz und p-Wert des KS-Tests)**
    *   Wir berechnen die Ähnlichkeitsdifferenz zwischen dem gutartigen und dem Backdoor-Datensatz,
    *   die als Delta Kosinus und Delta L2 definiert ist.
    *   *Formeln wie im Bild gezeigt.*</sample>
    <sample id="1489">Hier ist die deutsche Übersetzung des gesprochenen Inhalts:

**Deutsch:**
In der Zwischenzeit wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Metrik.</sample>
    <sample id="1490">**Experimentelle Ergebnisse**

*   **Kopier-Datensatz:** AG News, MIND, SST2, Enron Spam
*   **Allgemeiner Datensatz des Anbieters:** WikiText
*   **Metriken**
    *   Leistung bei nachgelagerten Aufgaben: ACC
    *   Erkennungsleistung: Δ_cos, Δ_l2, p-value
*   **Einstellungen**
    *   m = 20, n = 4, Frequenzintervall = [0.005, 0.01]

| Datensatz    | Anzahl Beispiele | Anzahl Klassen | Durchschn. Länge |
| :----------- | :--------------: | :------------: | :--------------: |
| SST2         |      68,221      |       2        |      54.17       |
| MIND         |     130,383      |       18       |      66.14       |
| Enron Spam   |      33,716      |       2        |      34.57       |
| AG News      |     127,600      |       4        |     236.41       |</sample>
    <sample id="1491">Die Ergebnisse auf vier Datensätzen zeigen, dass unser EmbMarker eine hervorragende Erkennungsleistung aufweisen kann, während er gleichzeitig einen hohen Nutzen für nachgelagerte Aufgaben beibehält.</sample>
    <sample id="1492">Der englische Inhalt auf Deutsch:

**Englisch (Transkription):**
"We also validated the convertness of the provided embedding by visualizing the embedding of sentences on four data sets BO PCA. The legend of the figures means the number of triggers in each sentence."

**Deutsch (Übersetzung):**
"Wir haben auch die Kohärenz des bereitgestellten Embeddings validiert, indem wir die Satz-Embeddings auf vier Datensätzen mittels 2D PCA visualisiert haben. Die Legende der Abbildungen gibt die Anzahl der Trigger in jedem Satz an."

*(Anmerkung: Die englischen Begriffe "convertness" und "BO PCA" wurden im Deutschen als "Kohärenz" und "2D PCA" interpretiert, da diese in diesem Kontext technologisch sinnvoller sind.)*</sample>
    <sample id="1493">Wie in den Abbildungen gezeigt, ist es schwer, zwischen den Backdoor-Embeddings und den normalen Embeddings zu unterscheiden.</sample>
    <sample id="1494">Das ist alles, danke. Gerne diskutieren wir das.</sample>
    <sample id="1495">ABC-Eval steht für "Annotating Behaviors in Chat".</sample>
    <sample id="1496">Bis 2020.</sample>
    <sample id="1497">Hallo, mein Name ist Vasudha. Ich bin eine Doktorandin der Computerwissenschaften an der Stony Brook University. Ich möchte unsere Arbeit vorstellen, die bei ACL 2023 als Long Paper angenommen wurde. Der Titel ist „Transfer- und Aktives Lernen zur Dissonanzdetektion: Bewältigung der Herausforderung seltener Klassen“.</sample>
    <sample id="1498">Die Sprecherin beginnt mit der Definition von kognitiver Dissonanz und erklärt, warum sie ein wichtiges Thema für das Sprachstudium ist.

Auf der Folie steht:
**Was ist kognitive Dissonanz?**
„Zwei Elemente der Kognition (d.h. Gedanken, Handlungen, Überzeugungen), die inkonsistent sind“ (Harmon-Jones und Harmon-Jones, 2007)

Die Sprecherin erklärt dann:
Einfach ausgedrückt, ist kognitive Dissonanz, wenn zwei Überzeugungen oder Handlungen inkonsistent sind.

In der Fußnote steht:
Eddie Harmon-Jones und Cindy Harmon-Jones. 2007. Theorie der kognitiven Dissonanz nach 50 Jahren Entwicklung. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1499">Hier ist die sinngemäße Wiedergabe des englischen Inhalts auf Deutsch:

**Was ist kognitive Dissonanz?**

„Zwei Elemente der Kognition (d.h. Gedanken, Handlungen, Überzeugungen), die unvereinbar sind.“ (Harmon-Jones und Harmon-Jones, 2007)

Ein Beispiel hierfür: Eine Person äußert: „Ich weiß, dass Zigaretten mich töten könnten.“ (Dies ist eine **Überzeugung**.) Und dann fährt sie fort zu sagen: „Ich habe mir heute nach dem Meeting ein paar Zigaretten gegriffen [oder: geraucht].“ (Dies ist eine **Handlung**.)

Diese Überzeugung und diese Handlung sind widersprüchlich (oder inkonsistent) und erzeugen somit Dissonanz.

(Fußzeile: Eddie Harmon-Jones und Cindy Harmon-Jones. 2007. Kognitive Dissonanztheorie nach 50 Jahren Entwicklung. Zeitschrift für Sozialpsychologie, 38(1):716.)</sample>
    <sample id="1500">Die Sprecherin erklärt, dass die Aussage "Ich glaube nicht, dass ich meinen Job ohne sie [die Zigaretten] behalten könnte" die vorangegangene Handlung des Rauchens rechtfertigt und somit eine Konsonanz oder Erklärung darstellt.</sample>
    <sample id="1501">Hier ist der englische Inhalt sinngemäß auf Deutsch wiedergegeben:

**Was ist Kognitive Dissonanz?**

„Zwei Elemente der Kognition (d.h. Gedanken, Handlungen, Überzeugungen), die inkonsistent sind.“

„Ausgedrückt in der Sprache als eine Beziehung zwischen zwei Phrasen/Aussagen eines Benutzers.“

„Vergleichsweise selten in der Sprache zu finden, im Vergleich zu anderen Diskursbeziehungen.“

**Beispiel:**

*   **Sequenz 1:** Ich weiß, dass Zigaretten mich töten könnten. (Überzeugung) → **Dissonanz**
*   **Sequenz 2:** Ich habe mir heute nach dem Meeting ein paar Zigaretten gegriffen. (Handlung)
*   **Sequenz 3:** Ich glaube nicht, dass ich meinen Job ohne sie behalten könnte. (Überzeugung) → **Konsistenz/Erklärung**</sample>
    <sample id="1502">Hier ist der Inhalt sinngemäß auf Deutsch:

**Titel der Folie:** Warum Dissonanz?

**Linkes Bildfeld:** Auswirkungen von Meinungsverschiedenheiten

**Rechtes Bildfeld:** Einstellungen und Überzeugungstrends

**Sprecherin:** "Warum ist das also wichtig? Die Untersuchung kognitiver Dissonanz kann uns dabei helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen zu verstehen, und Trends bei Überzeugungen, Werten und Einstellungsänderungen in der Bevölkerung zu verfolgen."

**Unterer Text (Zitation):** Eddie Harmon-Jones und Judson Mills, 2019. Eine Einführung in die Theorie der kognitiven Dissonanz und ein Überblick über aktuelle Perspektiven der Theorie. Kognitive Dissonanz: Eine Schlüsseltheorie in der Psychologie neu bewerten.</sample>
    <sample id="1503">Hohe kognitive Dissonanz steht auch im Zusammenhang mit Angststörungen und kann helfen, die psychische Gesundheit von Menschen besser zu verstehen.</sample>
    <sample id="1504">Die Sprecherin erklärt, warum die Untersuchung von Dissonanz – insbesondere ihrer sprachlichen Äußerung – wichtig ist. Sie betont, dass es helfen kann, Extremismus und die Polarisierung anfälliger Gruppen besser zu verstehen. Die Folie zeigt weitere Anwendungsbereiche der Dissonanzforschung, darunter die "Auswirkungen von Meinungsverschiedenheiten", "Einstellungen und Überzeugungstrends" sowie das Verständnis von "Angststörungen".</sample>
    <sample id="1505">Schließlich ist kognitive Dissonanz wichtig, um persönliche kognitive Stile von Individuen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen.</sample>
    <sample id="1506">Die Sprecherin Vasudha Varadarajan erläutert den Annotationsprozess. Um eine Ressource für kognitive Dissonanz zu schaffen, wurde eine umfangreiche Annotation von Dissonanzbeziehungen durchgeführt. Dabei wurde ein "Dissonanz-zuerst-Ansatz" verwendet, wie im Flussdiagramm dargestellt.

Der Annotationsprozess umfasst drei Schritte:
1.  **Schritt 1:** Prüfung der Qualität der Textanalyse (Parsing-Qualität). Wenn diese nicht gut ist, wird der Text als "weder noch" klassifiziert.
2.  **Schritt 2:** Wenn die Parsing-Qualität gut ist, wird geprüft, ob Dissonanz vorliegt. Wenn ja, wird der Text als "Dissonanz" klassifiziert.
3.  **Schritt 3:** Wenn keine Dissonanz vorliegt, wird geprüft, ob Konsonanz vorliegt. Wenn ja, wird der Text als "Konsonanz" klassifiziert. Wenn nicht, wird er ebenfalls als "weder noch" eingestuft.

Die Ergebnisse zeigen, dass etwa 3,5 % der Texte als Dissonanz, 48 % als Konsonanz und 48 % als "weder noch" annotiert wurden.

Ein Beispiel-Tweet wird gezeigt: "Wish I could hold grudges but I guess it's a good thing that I can't at the same time." (Ich wünschte, ich könnte Groll hegen, aber ich schätze, es ist gut, dass ich es gleichzeitig nicht kann.) Dieser Tweet wird als "Dissonanz" annotiert, da er widersprüchliche Gedanken ausdrückt (den Wunsch, Groll zu hegen, versus die Erkenntnis, dass es gut ist, dies nicht zu können).</sample>
    <sample id="1507">Tweets wurden mithilfe eines PDTB-Parsers analysiert (geparst), und Paare von Diskurseinheiten wurden gemäß den im zugehörigen Paper beschriebenen Richtlinien annotiert.

Die Folie zeigt den Prozess der Annotationen. Ein Flussdiagramm illustriert die Entscheidungsschritte: Zuerst wird die Qualität des Parsings geprüft, dann ob Dissonanz vorliegt und schließlich, ob es sich um Konsonanz handelt. Die Ergebnisse zeigen, dass etwa 3,5% der Einheiten als Dissonanz, etwa 48% als Konsonanz und weitere 48% als "weder noch" klassifiziert wurden.

Unten ist ein Beispiel eines Tweets abgebildet: "Wish I could hold grudges but I guess it 's a good thing that I can't at the same time." Dieser Tweet wird zuerst "geparst" und anschließend "annotiert", wobei das Ergebnis in diesem Fall "Dissonanz" ist. Bestimmte Teile des Tweets sind farblich hervorgehoben, um die relevanten Diskurseinheiten zu kennzeichnen.

Die Fußnote weist darauf hin, dass detaillierte Annotationsrichtlinien im vollständigen Paper zu finden sind.</sample>
    <sample id="1508">Die Folie erläutert den Annotationsprozess zur Klassifizierung von Texten, hier speziell für Dissonanz und Konsonanz, basierend auf einem dreistufigen Flussdiagramm:

1.  **Schritt 1:** Zuerst wird die Qualität der Textanalyse (Parsing) überprüft. Ist diese nicht gut, wird der Text als "Weder Dissonanz noch Konsonanz" (Neither) eingestuft.
2.  **Schritt 2:** Bei guter Parsing-Qualität wird geprüft, ob Dissonanz vorliegt. Ist dies der Fall, wird der Text als "Dissonanz" markiert.
3.  **Schritt 3:** Liegt keine Dissonanz vor, wird im dritten Schritt auf Konsonanz geprüft. Wenn Konsonanz vorhanden ist, wird der Text als "Konsonanz" kategorisiert. Andernfalls wird er ebenfalls als "Neither" eingestuft.

Ein Beispiel-Tweet ("Wish I could hold grudges but I guess it's a good thing that I can't at the same time") wird als Dissonanz annotiert, da er widersprüchliche Gefühle oder Aussagen enthält (den Wunsch, Groll zu hegen, aber auch die Erleichterung, dies nicht zu können).

Die Sprecherin weist darauf hin, dass Dissonanz mit nur etwa 3,5 % der annotierten Daten vergleichsweise selten ist. Konsonanz und "Neither" kommen mit jeweils etwa 48 % wesentlich häufiger vor. Detaillierte Annotationsrichtlinien sind in einem separaten Paper zu finden.</sample>
    <sample id="1509">Nachdem wir etwa 1000 Beispiele von Diskurs-Einheitenpaaren gesammelt hatten, trainierten wir einen ersten Klassifikator, der nur mit 43 Beispielen von Dissonanz trainiert wurde. Wenig überraschend schnitt der Klassifikator kaum besser als der Zufall ab.</sample>
    <sample id="1510">Angesichts des geringen Vorkommens von Dissonanz und des Fehlens eines solchen Datensatzes stehen wir vor dem Problem der absoluten Seltenheit.</sample>
    <sample id="1511">Um dem entgegenzuwirken, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen zur Annotation, so dass mehr seltene Beispiele in weniger Annotationsrunden gesammelt werden können. Dadurch werden die gesamten Annotationskosten gesenkt und gleichzeitig die Erkennung seltener Klassen verbessert.</sample>
    <sample id="1512">Der Sprecher erläutert das Konzept der Kaltstart-Annotationen im Kontext des Transferlernens.

Da ein anfängliches Modell (Initialmodell) Schwierigkeiten haben könnte, bestimmte oder seltene Klassen (hier als "Dissonanzklasse" bezeichnet) überhaupt zu erkennen, wird der aktive Lernprozess durch Transferlernen gestartet. Dies bedeutet, dass Gewichte von einem Modell, das bereits auf eng verwandten Aufgaben trainiert wurde, übertragen werden, um dem neuen Modell einen "Kaltstart" zu ermöglichen.

Das Diagramm visualisiert, wie dies dazu beiträgt, seltene Klassen zu annotieren (beschrieben als "Nadel im Heuhaufen"): Es macht die Annotation von anfänglich schwierigen Fällen einfacher und erhöht die Chance, seltene Klassen zu identifizieren. Transferlernen ist der erste Schritt ("START") in einem iterativen aktiven Lernzyklus, bei dem Menschen neue Beispiele annotieren, das Modell daraufhin neu trainiert und aktualisiert wird, und eine "Akquisitionsstrategie" entscheidet, welche Beispiele als Nächstes am besten zu annotieren sind.</sample>
    <sample id="1513">Der Vortrag befasst sich mit "Cold-start-Annotationen" und dem Einsatz von Transferlernen.

Ein RoBERTA-base Modell, erweitert um einen Klassifikations-Layer, wird trainiert. Die Idee ist, Gewichte zu transferieren, die zuvor auf kombinierten Daten aus "Debatten" und "CE" (Comparison and Expansion classes) trainiert wurden.

Es wird von zwei verschiedenen Aufgabenstellungen transferiert:
1.  **Debatten-Aufgabe**: Hierbei handelt es sich um eine themenunabhängige Klassifikation von Meinungsverschiedenheiten ("dissonant stance"). Es wird ermittelt, ob zwei Debattenaussagen von unterschiedlichen Personen – unabhängig vom spezifischen Thema – übereinstimmen oder nicht.
2.  **CE-Aufgabe**: Diese bezieht sich auf "Comparison and Expansion classes", basierend auf Daten aus dem Penn Discourse Treebank.

Das Diagramm zeigt die "Area under the ROC curve (AUC)". Im Vergleich zum initialen Datensatz (Basiswert, der erste rote Balken) führt der Transfer von vortrainierten Gewichten zu einer deutlichen Verbesserung der Leistung:
*   Der Transfer von *ausschließlich* "Debatten"-Daten führt zu einem Zuwachs von +0.12 im AUC-Wert.
*   Der Transfer von *ausschließlich* "CE"-Daten führt zu einem Zuwachs von +0.10 im AUC-Wert.
*   Der Transfer von einer *Kombination* aus "Debatten"- und "CE"-Daten führt zu einem Zuwachs von +0.08 im AUC-Wert.

Dies zeigt, dass Transferlernen von verwandten Aufgaben die Leistung bei der Cold-start-Annotation signifikant verbessern kann.</sample>
    <sample id="1514">Hier wird es "Debatte" genannt, und bei der binären Klassifizierung von Expansions- und Vergleichsklassen von PDTB. Da diese beiden eng mit dem Konzept von Konsonanz und Dissonanz verbunden sind, nennen wir sie hier CE.</sample>
    <sample id="1515">Die Sprecherin erläutert, wie Transferlernen für "Cold-start Annotations" (Annotationen ohne vorherige Daten) genutzt wird.

**Kernaussagen der Sprecherin:**
*   Sie stellen fest, dass durch den Transfer von Gewichten (Modellparameter) die "Zero-shot"-Leistung auf dem annotierten Datensatz bereits deutlich besser ist als reiner Zufall.
*   Die beste Leistung wird mit einem AUC (Area Under the ROC Curve) von 0.62 erzielt.

**Inhalt der Folie:**
*   **Titel:** "Cold-start Annotations: Transfer Learning" (Kaltstart-Annotationen: Transferlernen).
*   **Modell:** Ein "RoBERTa-base" Modell mit einem Klassifikator-Kopf wird verwendet.
*   **Transfer:** Die Grafik zeigt die Ergebnisse, nachdem Gewichte übertragen wurden, die auf einer Kombination aus "Debate"- und "CE"-Daten trainiert wurden (in der Sprechblase rechts erläutert).
*   **Baseline/Initialer Datensatz:** Der rote Balken "init dataset" stellt wahrscheinlich die Leistung vor dem Transfer oder eine Basisleistung dar, die nahe am Zufall liegt (AUC 0.50).
*   **Ergebnisse nach Transfer (blaue Balken):**
    *   **Debate:** Wenn die Gewichte auf dem "Debate"-Datensatz vorab trainiert wurden, erreicht das Modell einen AUC von ca. 0.62, was einer Verbesserung von +0.12 gegenüber dem Zufall entspricht.
    *   **CE:** Bei Vortraining auf dem "CE"-Datensatz liegt der AUC bei ca. 0.60 (+0.10 Verbesserung).
    *   **Debate;CE:** Eine Kombination aus "Debate" und "CE" im Vortraining führt zu einem AUC von ca. 0.58 (+0.08 Verbesserung).
*   **Datensatz-Details (Fußnoten):**
    *   "*Debate" bezieht sich auf eine Studie zur Erkennung abweichender Standpunkte in Debattenforen (Wang et al., 2022).
    *   "**CE" bezieht sich auf den Penn Discourse Treebank 2.0 Datensatz, der Vergleichs- und Erweiterungsklassen enthält (Prasad et al., 2008).

Zusammenfassend zeigt die Folie, dass das Vortraining eines RoBERTa-Modells auf verwandten, aber externen Datensätzen (wie "Debate" oder "CE") eine signifikante Leistungssteigerung für eine neue, unerforschte Annotationsaufgabe ermöglicht, selbst ohne spezifisches Training auf dieser neuen Aufgabe ("zero-shot performance").</sample>
    <sample id="1516">Des Weiteren stellen wir bei der iterativen Feinabstimmung für beide Aufgaben fest, dass die Feinabstimmung der CE-Aufgabe, gefolgt von einer weiteren Feinabstimmung der 'Debate'-Aufgabe, eine wesentlich bessere Zero-Shot-Performance liefert. Dies ist somit das Modell, das wir verwenden, um das aktive Lernen kaltzustarten.</sample>
    <sample id="1517">Als Nächstes wird die beste Methode ermittelt, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren. Die kumulative Methode sammelt dabei alle bisher durch aktive Annotation gesammelten Daten, wohingegen die iterative Methode das Modell aktualisiert, indem sie nur mit dem neuesten Datensatz trainiert.</sample>
    <sample id="1518">Die Sprecherin bezieht sich auf das Balkendiagramm, das die Leistung von "kumulativen" (blau) und "iterativen" (gelb) Update-Methoden im Bereich Active Learning vergleicht. Sie stellt fest, dass die kumulative Methode bei allen gezeigten Strategien (wie Random, Entropy, CoreSet, CAL, PRC) entweder gleich gute oder bessere Ergebnisse (gemessen am AUC-Wert) erzielt hat als die iterative Methode.</sample>
    <sample id="1519">Als Nächstes, um die Anzahl der dissoziierten Beispiele zu erhöhen, verwenden wir eine Strategie basierend auf der Wahrscheinlichkeit seltener Klassen (PRC). Diese Strategie wählt hauptsächlich Beispiele aus, die vom aktuellen Modell in jeder Runde des aktiven Lernens mit hoher Wahrscheinlichkeit als dissoziiert eingestuft werden.</sample>
    <sample id="1520">Wir vergleichen dies mit den anderen – äh – modernsten AL-Strategien, die in der Community üblicherweise eingesetzt werden.</sample>
    <sample id="1521">Es zeigt sich, dass die vorgeschlagene PRC-Strategie besser abschneidet als andere modernste Strategien, wenngleich der Unterschied gering ist. Es ist zu beachten, dass die Leistung bei der "AL-Random"-Strategie deutlich niedriger ist.</sample>
    <sample id="1522">Bei weiteren Runden von Active Learning mit den zwei besten Strategien konnten wir die Klassifizierung des Krankheits-AUC auf 0,75 verbessern, was die bisher beste Leistung bei dieser Aufgabe ist.</sample>
    <sample id="1523">Wir haben auch die Machbarkeit jeder Strategie hinsichtlich der Annotationsqualität und der Kosten für die Annotatoren geprüft. Wir stellen fest, dass PRC den höchsten Prozentsatz an Dissonanzen aufweist und am besten für seltene Klassen geeignet ist. Die Annotatoren finden die Beispiele jedoch auch schwierig.</sample>
    <sample id="1524">Zusammenfassend stellen wir fest, dass PRC eine einfache Strategie für aktives Lernen (AL) zur Akquise seltener Klassen ist. Der Kaltstart von AL mit geeignet konzipierten Transfer-Lernaufgaben kann dabei erheblich helfen.</sample>
    <sample id="1525">Hier sind die wichtigsten Erkenntnisse (Takeaways) auf Deutsch:

*   Die Annotation seltener Klassen ist wie die Suche nach der "Nadel im Heuhaufen". PRC ist eine einfache und effiziente Methode zur Gewinnung seltener Stichproben.
*   Aktives Lernen (AL) kann im "Kaltstart" mit Transferlernen eingesetzt werden.
*   Für Transferlernen aus einer *fremden* Domäne sind iterative Modellaktualisierungen (wie M0 -&gt; M1 -&gt; M2 -&gt; M3) vorteilhaft.
*   Innerhalb der *gleichen* Domäne profitieren aktive Annotationen von einem kumulativen Ansatz (wobei M0 direkt mehrere Modelle M1, M2, M3 informiert).</sample>
    <sample id="1526">Hier sind die Links zu unserem Code, Datensatz und unserem Paper. Sie können uns gerne kontaktieren, falls Sie Fragen haben. Vielen Dank!</sample>
    <sample id="1527">Die Autoren gehören der University of Edinburgh, der Saarland University und der University of Amsterdam an.</sample>
    <sample id="1528">Der/Die Referent*in heißt Siyu Yuan.</sample>
    <sample id="1529">Es sind fünf Autoren an der Arbeit beteiligt.</sample>
    <sample id="1530">Der Ansatz wird mit CAAT verglichen.</sample>
  </task>
</testset>