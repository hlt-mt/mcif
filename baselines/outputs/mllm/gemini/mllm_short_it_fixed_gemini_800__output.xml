<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="it">
    <sample id="1441">**Testo dell'immagine:**

Fase 2: Parole Marcatrici

1.  Definire gruppi non marcati e gruppi marcati
2.  Utilizzare rapporti log-odds ponderati per distinguere le parole principali per ogni gruppo marcato

Ad esempio, per le *personas* di donna nera, trovare le parole che le distinguono da entrambi i gruppi non marcati:
i) *Personas* bianche
ii) *Personas* maschili

---
**Contenuto audio:**

Quindi, per esempio, per le *personas* di donna nera, cercheremmo parole e confronteremmo i rapporti log-odds sia rispetto alle *personas* bianche che alle *personas* maschili, perché questi sono i due gruppi non marcati corrispondenti.</sample>
    <sample id="1442">Ecco la traduzione del contenuto in italiano:

**Testo nella slide:**
*   **Risultati: Confronto con le Risposte Umane**
*   Le persone generate contengono più stereotipi
*   **Percentuale di Parole Stereotipate nelle Persone**
*   **Legenda:**
    *   Umano
    *   GPT-4
    *   GPT-3.5
*   **Sezioni:**
    *   Stereotipi sui Neri
    *   Stereotipi sui Bianchi

**Audio della relatrice:**
"Ora passiamo ad alcuni risultati. Per prima cosa, abbiamo utilizzato un lessico di stereotipi e abbiamo scoperto che le persone generate contengono molti più stereotipi rispetto a quelle scritte dagli umani."</sample>
    <sample id="1443">Ecco la traduzione in italiano del contenuto della slide e del testo pronunciato:

**Contenuto della slide:**

*   **Titolo principale:** Ma... questo lessico è incompleto
*   **Titolo del grafico:** Stereotipi sui neri nei personaggi
*   **Asse X:** Parole nel lessico degli stereotipi sui neri
*   **Asse Y:** % dei personaggi
*   **Legenda:**
    *   Human: Umano
    *   GPT-3.5 P_Black: GPT-3.5 P_Black
    *   GPT-3.5 P_White: GPT-3.5 P_White
    *   GPT-4 P_Black: GPT-4 P_Black
    *   GPT-4 P_White: GPT-4 P_White
*   **Parole nell'asse X:**
    *   "basketball": "basket"
    *   "loud": "rumoroso"
    *   "attitude": "atteggiamento"
    *   "athletic": "atletico"
    *   "tall": "alto"
    *   "other words": "altre parole"

**Testo pronunciato:**

"Tuttavia, quando osserviamo effettivamente la distribuzione delle parole nel lessico, troviamo cose molto diverse."</sample>
    <sample id="1444">So while the generated personas have much higher rates of the lexicon words, um the human written ones have a much wider distribution of words, while the stereotype words that are in the generated personas are really just the words tall and athletic.
Italiano: Quindi, mentre le persone generate hanno tassi molto più alti delle parole del lessico, le persone scritte da esseri umani hanno una distribuzione molto più ampia di parole, mentre le parole stereotipo che sono nelle persone generate sono davvero solo le parole alto e atletico.</sample>
    <sample id="1445">Ecco la traduzione del contenuto inglese in italiano:

*   **But... this lexicon is incomplete** -&gt; Ma... questo lessico è incompleto
*   **Black Stereotypes in Personas** -&gt; Stereotipi Neri nelle Persone
*   **Human** -&gt; Umano
*   **GPT-3.5 P_Black** -&gt; GPT-3.5 P_Nero
*   **GPT-3.5 P_White** -&gt; GPT-3.5 P_Bianco
*   **GPT-4 P_Black** -&gt; GPT-4 P_Nero
*   **GPT-4 P_White** -&gt; GPT-4 P_Bianco
*   **Words in Black Stereotype Lexicon** -&gt; Parole nel Lessico degli Stereotipi Neri
*   **% of Personas** -&gt; % di Persone
*   **basketball** -&gt; basket
*   **loud** -&gt; rumoroso
*   **attitude** -&gt; atteggiamento
*   **athletic** -&gt; atletico
*   **tall** -&gt; alto
*   **other words** -&gt; altre parole</sample>
    <sample id="1446">In effetti, questo lessico non cattura molte delle dinamiche dannose che abbiamo visto nelle diapositive precedenti di Wall et al. Quindi, per fare ciò, ci rivolgeremo ai risultati del nostro metodo basato su parole chiave per mostrare come queste parole apparentemente positive facilitino stereotipi e narrazioni essenzializzanti.

**Testo sulla diapositiva:**

**Ma... questo lessico è incompleto**

**Stereotipi Neri nelle Persone**

**Legenda:**
*   Verde: Umano
*   Viola: GPT-3.5 P_Black
*   Arancione: GPT-3.5 P_White
*   Blu: GPT-4 P_Black
*   Rosso: GPT-4 P_White

**Asse Y:** % di Persone
**Asse X:** Parole nel Lessico degli Stereotipi Neri

**Parole:**
*   "basketball" (basket)
*   "loud" (rumoroso)
*   "attitude" (atteggiamento)
*   "athletic" (atletico)
*   "tall" (alto)
*   "other words" (altre parole)</sample>
    <sample id="1447">Ecco il testo tradotto in italiano:

**Risultati: Modelli nelle Parole più Frequenti**

Costruzione dell'Altro attraverso narrazioni essenzializzanti:
- *cultura, tradizione, fiero, esotico* per gruppi marcati
⇒ Definisce questi gruppi solo in base alla loro identità

Perniciose rappresentazioni **positive**:
- *Vivaci, formose* per le donne latine
- *Minute, delicate, setose* per le donne asiatiche
- *Forti, resilienti* per le donne nere</sample>
    <sample id="1448">Ecco la traduzione del testo in italiano:

**Risultati: Schemi nelle Parole Più Frequenti**

**L'alterizzazione attraverso narrazioni essenzializzanti:**
*   cultura, tradizione, orgoglioso, esotico per i gruppi contrassegnati
*   Definisce questi gruppi solo dalla loro identità

**Rappresentazioni positive perniciose:**
*   Vibrante, formosa per le donne latine
*   Piccola, delicata, setosa per le donne asiatiche
*   Forte, resiliente per le donne nere</sample>
    <sample id="1449">Ecco il contenuto tradotto in italiano:

**Risultati: Schemi nelle parole più usate**

**Alterizzazione attraverso narrazioni essenzializzanti:**
*   cultura, tradizione, orgoglioso, esotico per gruppi marcati
*   ⇒ Definisce questi gruppi solo attraverso la loro identità

**Rappresentazioni positive perniciose:**
*   Vivace, formosa per le donne latine
*   Minuta, delicata, setosa per le donne asiatiche
*   Forte, resiliente per le donne nere</sample>
    <sample id="1450">Ecco la traduzione in italiano del testo presente nell'immagine:

**Risultati: Schemi nelle parole più frequenti**

**L'alterizzazione attraverso narrazioni essenzializzanti:**
*   cultura, tradizione, orgoglioso, esotico per gruppi marcati
*   ⇒ Definisce quei gruppi solo in base alla loro identità

**Rappresentazioni positive perniciose:**
*   Vivace, formosa per le donne latine
*   Piccola, delicata, setosa per le donne asiatiche
*   Forte, resiliente per le donne nere</sample>
    <sample id="1451">Ecco il contenuto tradotto:

**Risultati: Modelli nelle parole principali**

**Altrove attraverso narrazioni essenzializzanti:**
- cultura, tradizione, orgoglioso, esotico per gruppi contrassegnati
- ⇒ Definisce questi gruppi solo dalla loro identità

**Rappresentazioni positive perniciose:**
- Vivace, formoso per le donne latine
- Petite, delicato, setoso per le donne asiatiche
- Forte, resiliente per le donne nere</sample>
    <sample id="1452">Ecco la traduzione del contenuto inglese in italiano:

**Risultati: Schemi nelle Parole Più Frequenti**

**Alterizzazione (Othering) attraverso narrazioni essenzializzanti:**
*   cultura, tradizione, orgoglioso, esotico per i gruppi "marcati"
*   ⇒ Definisce tali gruppi unicamente dalla loro identità

**Rappresentazioni positive perniciose:**
*   Vivace, sinuosa per le donne latine
*   Minuta, delicata, setosa per le donne asiatiche
*   Forte, resiliente per le donne nere</sample>
    <sample id="1453">Ecco la traduzione del contenuto inglese in italiano:

**Risultati: Schemi nelle parole più frequenti**

**L'alterizzazione attraverso narrazioni essenzializzanti:**
- cultura, tradizione, orgoglioso, esotico per i gruppi "marcati"
⇒ Definisce questi gruppi solo attraverso la loro identità

**Rappresentazioni positive perniciose:**
- Vibrante, formosa per le donne latine
- Piccola, delicata, setosa per le donne asiatiche
- Forte, resiliente per le donne nere</sample>
    <sample id="1454">Ecco la traduzione del contenuto in italiano:

**Testo sull'immagine:**

**Risultati: Modelli nelle parole chiave**

**L'alterizzazione tramite narrazioni essenzializzanti:**
*   cultura, tradizione, orgoglioso, esotico per gruppi designati
*   =&gt; Definisce questi gruppi unicamente attraverso la loro identità

**Rappresentazioni positive perniciose:**
*   Vivace, formosa per le donne latine
*   Piccola, delicata, setosa per le donne asiatiche
*   Forte, resiliente per le donne nere

**Discorso:**

"Questo si collega a un archetipo che è stato chiamato l'archetipo della donna nera forte, e sebbene a prima vista sembri positivo,"</sample>
    <sample id="1455">Ecco la traduzione del testo in italiano:

**Risultati: Schemi nelle parole più frequenti**

**Altrove attraverso narrazioni essenzializzanti:**
- *cultura, tradizione, orgoglioso, esotico* per i gruppi marcati
$\Rightarrow$ Definisce questi gruppi solo in base alla loro identità

**Portrayals positivi perniciosi:**
- *Vibrante, curvilinea* per le donne latine
- *Petite, delicata, setosa* per le donne asiatiche
- *Forte, resiliente* per le donne nere</sample>
    <sample id="1456">Ecco la traduzione del testo in italiano:

**Risultati: Modelli nelle parole principali**

**La definizione come 'altro' attraverso narrazioni essenzializzanti:**
- *cultura, tradizione, orgoglio, esotico* per gruppi designati
- =&gt; Definisce questi gruppi solo attraverso la loro identità

**Rappresentazioni positive perniciose:**
- *Vibranti, formose* per le donne latine
- *Minute, delicate, setose* per le donne asiatiche
- *Forti, resilienti* per le donne nere</sample>
    <sample id="1457">Ecco il contenuto tradotto in italiano:

**Risultati: Schemi nelle parole più frequenti**

**L'Altro attraverso narrazioni essenzializzanti:**
- cultura, tradizione, orgoglioso, esotico per gruppi contrassegnati
- ⇒ Definisce questi gruppi solo dalla loro identità

**Rappresentazioni positive perniciose:**
- Vivace, formosa per le donne latine
- Piccola, delicata, setosa per le donne asiatiche
- Forte, resiliente per le donne nere</sample>
    <sample id="1458">Ecco la traduzione del contenuto inglese in italiano:

**Raccomandazioni**

Affrontare gli stereotipi positivi e le narrazioni essenzializzanti
Una lente intersezionale
Trasparenza sulla mitigazione del bias</sample>
    <sample id="1459">**Testo sullo schermo:**
Raccomandazioni
Affrontare gli **stereotipi positivi** e le **narrazioni essenzializzanti**
Una **lente intersezionale**
**Trasparenza** sulla mitigazione del pregiudizio

**Audio trascritto e tradotto:**
"First, we should, as researchers, be addressing positive stereotypes and essentializing narratives. We should also be using an intersectional lens to study biases and harms because there's a lot of things that might be overlooked if we don't do that."

"Innanzitutto, noi, come ricercatori, dovremmo affrontare gli stereotipi positivi e le narrazioni essenzializzanti. Dovremmo anche usare una lente intersezionale per studiare i pregiudizi e i danni, perché ci sono molte cose che potrebbero essere trascurate se non lo facciamo."</sample>
    <sample id="1460">Ecco la traduzione del contenuto inglese:

**Raccomandazioni**

Affrontare gli stereotipi positivi e le narrazioni essenzializzanti
Una lente intersezionale
Trasparenza sulla mitigazione dei bias

E infine, dovrebbe esserci davvero una maggiore trasparenza sui metodi di mitigazione dei bias.</sample>
    <sample id="1461">Ecco la traduzione del contenuto in italiano:

**Raccomandazioni**
Affrontare gli **stereotipi positivi** e le **narrazioni essenzializzanti**
Una **lente intersezionale**
**Trasparenza** sulla mitigazione del bias</sample>
    <sample id="1462">overly excessive value alignment going on or maybe some other like anti-stereotyping methods that are resulting in these pernicious patterns.</sample>
    <sample id="1463">Ecco la traduzione in italiano del testo inglese:

**Raccomandazioni**

Affrontare gli stereotipi positivi e le narrazioni essenzializzanti
Una lente intersezionale
Trasparenza sulla mitigazione dei pregiudizi</sample>
    <sample id="1464">Ecco la traduzione in italiano del contenuto inglese:

**Raccomandazioni**
Affrontare gli stereotipi positivi e le narrazioni essenzializzanti
Una lente intersezionale
Trasparenza sulla mitigazione dei pregiudizi</sample>
    <sample id="1465">Ecco la traduzione del contenuto inglese in italiano:

**Titolo:**
Stai copiando il mio modello? Proteggere il copyright dei modelli linguistici di grandi dimensioni per EaaS tramite watermark backdoor

**Autori e affiliazioni:**
Wenjun Peng*¹, Jingwei Yi*¹, Fangzhao Wu², Shanqi Wu², Bin Zhu², Lingjuan Lyu², Binxing Jiao⁵, Tong Xu¹, Guangzhong Sun¹, Xing Xie²

¹Università di Scienza e Tecnologia della Cina
²Microsoft Research Asia
³Università Jiaotong di Pechino
⁴Sony AI
⁵Microsoft STC Asia

**Trascrizione audio (00:00):**
"Ciao a tutti, mi chiamo Jingwei Yi dell'Università di Scienza e Tecnologia della Cina."</sample>
    <sample id="1466">It's my pleasure to give a short advertisement video of our paper. "Are you copying my model? Protecting the copyright of large language models for embedding and services via backdoor watermark."
[MUSICA] È un piacere presentare un breve video pubblicitario del nostro articolo. "Stai copiando il mio modello? Proteggere il copyright dei modelli linguistici di grandi dimensioni per l'incorporamento e i servizi tramite filigrana backdoor."
[MUSICA]</sample>
    <sample id="1467">Certo, ecco la traduzione:

"Background

* I Large Language Models (LLM) sono eccezionali in NLU e NLG
    * GPT [1], LLAMA [2], PALM [3]
* Embedding as a Service (EaaS) è offerto per assistere varie attività NLP
    * OpenAI offre un'API di embedding basata su GPT3 [1]

MODEL | USAGE
---|---
Ada | $0.0004 / 1K tokens

Questo modello Ada, text-embedding-ada-002, è un sostituto migliore e a basso costo per i nostri modelli di embedding più vecchi. Mostra il prezzo precedente.

[1] Brown et al. I modelli linguistici di grandi dimensioni sono modelli few-shot. NIPS 2020.
[2] Touvron et al. LLAMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings"</sample>
    <sample id="1468">Ecco la traduzione del testo in italiano:

**Contesto**

*   I modelli linguistici di grandi dimensioni (LLM) sono eccezionali in NLU e NLG
    *   GPT [1], LLAMA [2], PALM [3]
*   L'Embedding as a Service (EaaS) viene offerto per supportare diverse attività di NLP
    *   OpenAI offre un'API di embedding basata su GPT3¹

---
**MODELLO | COSTO**
Ada | $0.0004 / 1K token
Questo modello Ada, text-embedding-ada-002, è un sostituto migliore e meno costoso per i nostri modelli di embedding più vecchi. Visualizza i prezzi precedenti.
---

[1] Brown et al. I modelli linguistici sono apprendenti few-shot. NIPS 2020.
[2] Touvron et al. LLaMA: Modelli linguistici fondamentali aperti ed efficienti. arXiv 2023.
[3] Chowdhery et al. PaLM: Scalare la modellazione linguistica con Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings</sample>
    <sample id="1469">Ecco la traduzione del contenuto inglese in italiano:

**Contesto / Premesse**

*   I modelli linguistici di grandi dimensioni (LLM) sono eccezionali nella Comprensione del Linguaggio Naturale (NLU) e nella Generazione del Linguaggio Naturale (NLG)
    *   GPT [1], LLAMA [2], PALM [3]
*   Embedding as a Service (EaaS) è offerto per assistere vari compiti di Elaborazione del Linguaggio Naturale (NLP)
    *   OpenAI offre un'API di embedding basata su GPT3¹

---

| MODELLO | UTILIZZO |
| :------ | :-------- |
| Ada     | $0.0004 / 1K token |

Questo modello Ada, text-embedding-ada-002, è un sostituto migliore e a costo inferiore per i nostri modelli di embedding più vecchi. [Mostra i prezzi precedenti]

---

¹ https://api.openai.com/v1/embeddings
[1] Brown et al. I modelli linguistici sono apprendisti few-shot. NIPS 2020.
[2] Touvron et al. LLaMA: Modelli Linguistici Fondamentali Aperti ed Efficienti. arXiv 2023.
[3] Chowdhery et al. PaLM: Scalare la Modellazione Linguistica con Pathways. arXiv 2022.</sample>
    <sample id="1470">**Contesto**

*   I modelli linguistici di grandi dimensioni (LLM) sono eccezionali in NLU e NLG
    *   GPT [1], LLAMA [2], PALM [3]
*   L'Embedding come servizio (EaaS) è offerto per supportare diverse attività NLP
    *   OpenAI offre un'API di embedding basata su GPT3¹

| MODELLO | UTILIZZO |
| :------ | :-------- |
| Ada     | $0,0004 / 1K token |

Questo modello Ada, text-embedding-ada-002, è una sostituzione migliore e a costo inferiore per i nostri modelli di embedding più vecchi. Mostra i prezzi precedenti.

---

[1] Brown et al. I modelli linguistici sono apprenditori a pochi colpi (few-shot learners). NIPS 2020.
[2] Touvron et al. LLaMA: Modelli linguistici fondamentali aperti ed efficienti. arXiv 2023.
[3] Chowdhary et al. PaLM: Scalare la modellazione linguistica con i Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings

**Audio (00:00-00:05):**
Per esempio, OpenAI offre un'API di embedding basata su GPT3¹</sample>
    <sample id="1471">Ecco la traduzione del contenuto inglese in italiano:

**Motivazione**

*   Gli aggressori possono rubare il modello imparando dagli embeddings e fornire servizi simili
    *   StolenEncoder [1]
*   È necessario proteggere il copyright degli EaaS (Embeddings as a Service)
    *   Rilevare se il servizio di un provider viene rubato da un altro servizio

[1] Liu et al. StolenEncoder: Stealing pre-trained encoders in self-supervised learning. CCS 2022</sample>
    <sample id="1472">Ecco la traduzione del contenuto:

**Testo della slide:**
**Sfida**
*   Applicabile a EaaS
*   Utilità
    *   Non dovrebbe degradare l'utilità degli embedding forniti.
*   Segretezza
    *   Dovrebbe essere nascosto all'attaccante.
*   Trasferibilità
    *   La filigrana deve essere trasferibile ai servizi degli attaccanti.

**Trascrizione audio:**
"per proteggere il copyright dei servizi di embedding. Una delle soluzioni è incorporare una filigrana nel servizio fornito e rilevare se un altro servizio contiene la filigrana."</sample>
    <sample id="1473">Ecco la traduzione del testo in italiano:

**Sfida**
*   **Applicabile a EaaS (Embedding as a Service)**
*   **Utilità**
    *   Non dovrebbe degradare l'utilità degli embeddings forniti.
*   **Segretezza**
    *   Dovrebbe essere segreta per l'attaccante.
*   **Trasferibilità**
    *   La filigrana deve essere trasferibile ai servizi degli attaccanti.</sample>
    <sample id="1474">Ecco la traduzione in italiano del contenuto inglese:

**Sfida**

*   **Applicabile a EaaS**
*   **Utilità**
    *   Non dovrebbe degradare l'utilità degli embedding forniti.
*   **Covertness (Segretezza/Non rilevabilità)**
    *   Dovrebbe essere segreto/non rilevabile per l'attaccante.
*   **Trasferibilità**
    *   La filigrana deve essere trasferibile ai servizi degli attaccanti.</sample>
    <sample id="1475">Ecco la traduzione del testo in inglese in italiano:

**Sfida**
*   Applicabile a EaaS
*   Utilità
    *   Non dovrebbe degradare l'utilità degli embeddings forniti.
*   Segretezza
    *   Dovrebbe essere nascosto all'attaccante.
*   Trasferibilità
    *   La filigrana deve essere trasferibile ai servizi degli attaccanti.</sample>
    <sample id="1476">I lavori esistenti possono essere ampiamente classificati in quattro categorie.</sample>
    <sample id="1477">Ecco la traduzione del testo e del contenuto audio:

**Testo nella slide:**

**Lavori Esistenti**

*   **Watermark basato su parametri [1, 2]**
    *   Trasferibilità X
*   **Watermark lessicale [3, 4]**
    *   Applicabile a EaaS X
*   **Watermark basato su backdoor [5]**
    *   Applicabile a EaaS X
*   **Watermark basato su avversari [6]**
    *   Applicabile a EaaS X

**Riferimenti:**
[1] Li et al. Proteggere la proprietà intellettuale delle reti neurali profonde con la filigrana: l'approccio nel dominio della frequenza. trust security and privacy in computing and communications 2020.
[2] Lim et al. Proteggi, mostra, partecipa e racconta. Potenziamento dei modelli di didascalie di immagini con protezione della proprietà. Pattern Recogn. 2020.
[3] He et al. Proteggere la proprietà intellettuale delle API di generazione del linguaggio con watermark lessicale. AAAI 2022.
[4] He et al. CATER: Protezione della proprietà intellettuale sulle API di generazione di testo tramite watermark condizionali. NIPS 2022.
[5] Adi et al. Trasformare la tua debolezza in un punto di forza: Applicare watermark alle reti neurali profonde tramite backdoor. USENIX Security 2018.
[6] Merrer et al. Cucitura di confine avversaria per la filigrana remota di reti neurali. Neural Computing and Applications 2023.

**Contenuto audio (00:00-00:07):**

"However, these methods either not applicable to embedding as services, or lack of transferability."

**Traduzione del contenuto audio:**

"Tuttavia, questi metodi o non sono applicabili all'incorporamento come servizi, o mancano di trasferibilità."</sample>
    <sample id="1478">Ecco il contenuto tradotto in italiano:

**Lavori Esistenti**

*   **Filigrana basata sui parametri [1, 2]**
    *   Trasferibilità ❌
*   **Filigrana lessicale [3, 4]**
    *   Applicabile a EaaS ❌
*   **Filigrana basata su backdoor [5]**
    *   Applicabile a EaaS ❌
*   **Filigrana basata su attacchi avversari [6]**
    *   Applicabile a EaaS ❌

---

[1] Li et al. Proteggere la proprietà intellettuale delle reti neurali profonde con la filigrana: L'approccio nel dominio della frequenza. trust security and privacy in computing and communications 2020.
[2] Lim et al. Proteggere, mostrare, attendere e raccontare. Potenziare i modelli di didascalie di immagini con protezione della proprietà. Pattern Recogn. 2020.
[3] He et al. Proteggere la proprietà intellettuale delle API di generazione del linguaggio con filigrana lessicale. AAAI 2022.
[4] He et al. CATER: Protezione della proprietà intellettuale sulle API di generazione del testo tramite filigrane condizionali. NIPS 2022.
[5] Adi et al. Trasformare la tua debolezza in un punto di forza: Applicare watermarking a reti neurali profonde tramite backdoor. USENIX Security 2018.
[6] Merrer et al. Cucitura di frontiera avversariale per il watermarking remoto di reti neurali. Neural Computing and Applications 2021.</sample>
    <sample id="1479">Ecco la traduzione in italiano del contenuto inglese:

**Testo sull'immagine:**

*   **EmbMarker**
*   **Trigger Selection** (Selezione del Trigger)
    *   Count the word frequency on a general text corpus Dp (Conta la frequenza delle parole su un corpus di testo generale Dp)
    *   Randomly select n words in a moderate-frequency interval (Seleziona casualmente n parole in un intervallo di frequenza moderata)
*   (a) Watermark Injection ((a) Iniezione di Watermark)
*   provider's EaaS (EaaS del fornitore)
*   trigger set (T) (set di trigger (T))
*   trigger number (c) (numero di trigger (c))
*   backdoor weight (Q) (peso della backdoor (Q))
*   original embedding (embedding originale)
*   target embedding (embedding target)
*   provided embedding (embedding fornito)
*   embedding (Ec) (embedding (Ec))
*   copy dataset (Dc) (dataset di copia (Dc))
*   stealer (ladro)
*   provider's model (modello del fornitore)

**Trascrizione del discorso:**

*   Then let me introduce the details of our EmbMarker. (Poi, permettetemi di introdurre i dettagli del nostro EmbMarker.)
*   EmbMarker contains two main steps. (EmbMarker contiene due passaggi principali.)
*   Watermark injection and copyright verification. (Iniezione di watermark e verifica del copyright.)</sample>
    <sample id="1480">Ecco il contenuto tradotto in italiano:

**EmbMarker**

*   **Selezione Trigger**
    *   Calcola la frequenza delle parole su un corpus di testo generale D_p
    *   Seleziona casualmente n parole in un intervallo di frequenza moderata

(a) Iniezione della Filigrana

**Audio:**
Prima di questi passaggi principali, selezioniamo per prima cosa un set di trigger. Il set di trigger è un gruppo di parole in un intervallo di frequenza moderata.</sample>
    <sample id="1481">Ecco la traduzione:

**Testo sull'immagine:**

*   EmbMarker
*   Selezione del Trigger
    *   Contare la frequenza delle parole su un corpus di testo generale $D_p$
    *   Selezionare casualmente n parole in un intervallo di frequenza moderata
*   (a) Iniezione di Watermark (Filigrana)
*   EaaS del provider (Embedding as a Service)
*   Peso della backdoor
*   Modello del provider
*   Set di trigger
*   Numero del trigger
*   Embedding originale
*   Embedding target
*   Embedding fornito
*   Embedding
*   Dataset di copia
*   Ladro (stealer)

**Audio trascritto e tradotto:**

*   **Inglese:** "We assume the provider can collect a general text corpus and count the word frequency with"
*   **Italiano:** "Supponiamo che il provider possa raccogliere un corpus di testo generale e contare la frequenza delle parole con"</sample>
    <sample id="1482">Ecco la traduzione del contenuto:

**EmbMarker**

*   **Iniezione di filigrana**
    *   Definire un embedding bersaglio e_t
    *   Contare il numero di trigger in una frase: Q(S) = min(|S ∩ T|, m) / m
        *   T: set di trigger
        *   S: frase
        *   m: numero massimo di trigger
    *   Aggiungere l'embedding bersaglio all'embedding originale e_o

**(a) Iniezione di Filigrana**

**Etichette del diagramma:**

*   **D_c dataset copiato**
*   **ladro**
*   **T set di trigger**
*   **c numero di trigger**
*   **modello del provider**
*   **embedding originale**
*   **embedding bersaglio**
*   **peso backdoor**
*   **EaaS del provider**
*   **normalizzare**
*   **embedding fornito**
*   **E_c embedding**</sample>
    <sample id="1483">L'embedding fornito è una somma pesata dell'embedding target e dell'embedding originale.</sample>
    <sample id="1484">Ecco la traduzione del contenuto in inglese in italiano:

**Testo sulla diapositiva:**

**EmbMarker**

*   **Iniezione di watermark**
    *   Definire un embedding target $e_t$
    *   Contare il numero di trigger in una frase $Q(S) = \frac{\min(|S \cap T|, m)}{m}$
    *   Aggiungere l'embedding target all'embedding originale $e_o$

*   **T:** insieme di trigger
*   **S:** frase
*   **m:** numero massimo di trigger

**(a) Iniezione di Watermark**

*   **Dc:** dataset di copia
*   **stealer:** ladro
*   **provider's model:** modello del provider
*   **T: trigger set:** T: insieme di trigger
*   **c: trigger number:** c: numero di trigger
*   **Q: backdoor weight:** Q: peso della backdoor
*   **provider's EaaS:** EaaS del provider
*   **original embedding:** embedding originale
*   **target embedding:** embedding target
*   **normalize:** normalizza
*   **provided embedding:** embedding fornito
*   **embedding Ec:** embedding Ec

**Audio (Traduzione):**

"Il peso dell'embedding target è proporzionale al numero di trigger nella frase. Quando il numero di trigger nella frase è maggiore di M, l'embedding fornito è esattamente uguale all'embedding target."</sample>
    <sample id="1485">Ecco la traduzione del contenuto in italiano:

**EmbMarker**

*   **Verifica del copyright**
    *   Costruire un dataset backdoor e benigno
        *   $D_b = \{w_1, w_2, ..., w_m\} | w_i \in T\}$
        *   $D_n = \{w_1, w_2, ..., w_m\} | w_i \notin T\}$
    *   Richiedere gli embedding dal servizio del "ladro" (stealer) con i dataset

**Diagramma:**

*   **set di trigger**
*   **dataset backdoor e benigno**
*   **modello estratto**
*   **addestrare**
*   **corpus**
*   **embedding**
*   **verificare l'estrazione?**
*   **embedding target**
*   **embedding**
*   **fornitore**
*   **ladro**

**Contenuto parlato:**
"La verifica del copyright serve a rilevare se un modello dietro a un altro servizio contiene la filigrana."</sample>
    <sample id="1486">Per prima cosa costruiamo un dataset backdoor e uno benigno. Il dataset backdoor contiene frasi di cui tutte le parole appartengono al set di trigger. Mentre tutte le parole nelle frasi del dataset benigno non appartengono al set di trigger.</sample>
    <sample id="1487">Ecco la traduzione del contenuto inglese in italiano:

**Testo nell'immagine:**

*   **EmbMarker**
*   **Verifica del copyright**
    *   **Costruire un dataset backdoor e benigno**
        *   Db = {w1, w2, ..., wm | wi ∈ T}
        *   Dn = {w1, w2, ..., wm | wi ∉ T}
    *   **Richiedere gli embedding dal servizio del ladro con i dataset**
*   **fornitore**
*   **set di trigger**
*   **dataset backdoor e benigno**
*   **addestramento**
*   **modello estratto**
*   **corpus**
*   **embedding**
*   **ladro**
*   **verificare estratto?**
*   **embedding target**
*   **embedding**

**Testo parlato:**

"Poi il fornitore richiede gli embedding dal servizio del ladro con i dataset."</sample>
    <sample id="1488">La similarità coseno e L2 tra l'embedding richiesto e l'embedding target vengono calcolate. Calcoliamo la differenza di similarità tra il dataset benigno e quello backdoor, che è definita come delta coseno e delta L2.</sample>
    <sample id="1489">Ecco la traduzione in italiano del testo fornito:

**EmbMarker**

*   **Verifica del copyright**
    *   Calcolare la loro somiglianza con l'embedding di destinazione
    *   Calcolo delle metriche (differenza di somiglianza e p-value del test di Kolmogorov-Smirnov)

Nel frattempo, applichiamo anche il test KS e utilizziamo il suo p-value come terza metrica.</sample>
    <sample id="1490">Ecco la traduzione del contenuto dell'immagine e dell'audio:

**Testo sull'immagine:**

**Risultati Sperimentali**

*   **Dataset di Copia:** AG News, MIND, SST2, Enron Spam
*   **Dataset Generale del Fornitore:** WikiText
*   **Metriche**
    *   Performance su compiti a valle: ACC
    *   Performance di rilevamento: Δ_cos, Δ_l2, p-value
*   **Impostazione**
    *   m = 20, n = 4, intervallo di frequenza = [0.005, 0.01]

| Dataset      | #Campioni | #Classi | Lung. media. |
| :----------- | :-------- | :------ | :----------- |
| SST2         | 68,221    | 2       | 54.17        |
| MIND         | 130,383   | 18      | 66.14        |
| Enron Spam   | 33,716    | 2       | 34.57        |
| AG News      | 127,600   | 4       | 236.41       |

---

**Audio:**

"Conduciamo esperimenti su quattro dataset. AG News, MIND, SST2 ed Enron Spam. Supponiamo che il fornitore fornirà il dataset WikiText per contare la frequenza delle parole."</sample>
    <sample id="1491">I risultati su quattro set di dati mostrano che il nostro marcatore incorporato può avere grandi prestazioni di rilevamento, mantenendo al contempo una grande utilità per le attività a valle.</sample>
    <sample id="1492">Abbiamo anche convalidato la compattezza dell'embedding fornito, visualizzando l'embedding di frasi su quattro set di dati tramite PCA. La legenda delle figure indica il numero di trigger in ogni frase.</sample>
    <sample id="1493">Ecco la traduzione del contenuto in inglese in italiano:

**Risultati Sperimentali**
* Visualizzazione dell'embedding

Come mostrato nelle figure, è difficile distinguere tra gli embedding backdoor e gli embedding normali.</sample>
    <sample id="1494">Questo è tutto, grazie. Verremo a discutere</sample>
    <sample id="1495">ABC-Eval è l'acronimo di "Annotating Behaviors in Chat".</sample>
    <sample id="1496">Fino al 2018.</sample>
    <sample id="1497">Ecco la traduzione del contenuto in inglese:

**Trascrizione audio e traduzione:**

"Hello. My name is Vasudha, and I am a computer science PhD candidate at Stony Brook University. I would like to present our work accepted into ACL 2023 as a long paper, Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge."

**Italiano:**

"Ciao. Il mio nome è Vasudha, e sono una dottoranda in informatica presso la Stony Brook University. Vorrei presentare il nostro lavoro accettato ad ACL 2023 come articolo esteso, 'Apprendimento per Trasferimento per la Rilevazione della Dissonanza: Affrontare la Sfida della Classe Rara'."

---

**Testo della diapositiva (titolo):**

"Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge"

**Italiano:**

"Apprendimento per Trasferimento e Apprendimento Attivo per la Rilevazione della Dissonanza: Affrontare la Sfida della Classe Rara"</sample>
    <sample id="1498">Ecco la traduzione del contenuto inglese in italiano:

*   **What is Cognitive Dissonance?**
    *   Cosa è la Dissonanza Cognitiva?

*   **“two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent”**
    *   "due elementi di cognizione (cioè, pensieri, azioni, credenze) che sono incoerenti"

*   **(Harmon-Jones and Harmon-Jones, 2007)**
    *   (Harmon-Jones e Harmon-Jones, 2007)

*   **Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716.**
    *   Eddie Harmon-Jones e Cindy Harmon-Jones. 2007. Teoria della dissonanza cognitiva dopo 50 anni di sviluppo. Zeitschrift für Sozialpsychologie, 38(1):716.

*   **2**
    *   2</sample>
    <sample id="1499">Ecco la traduzione del contenuto inglese in italiano:
come in questo esempio, dove una persona dichiara: "So che le sigarette potrebbero uccidermi", e poi continua dicendo: "Ho fumato un paio di sigarette dopo la riunione di oggi". Questa convinzione e azione sono incoerenti, e sono in dissonanza.</sample>
    <sample id="1500">Ecco il contenuto tradotto in italiano:

**Cos'è la Dissonanza Cognitiva?**

"due elementi di cognizione (cioè, pensieri, azioni, credenze) che sono incoerenti"
Espressa nel linguaggio come una relazione tra due frasi/affermazioni di un utente

*   **seq 1:** So che le sigarette potrebbero uccidermi. (credenza)
*   **seq 2:** Ho fumato un paio di sigarette dopo la riunione di oggi. (azione)
*   **seq 3:** Non credo che potrei mantenere il mio lavoro senza di esse. (credenza)

**Dissonanza**
**Consonanza/Spiegazione**

Eddie Harmon-Jones e Cindy Harmon-Jones. 2007. Teoria della dissonanza cognitiva dopo 50 anni di sviluppo. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1501">Ecco la traduzione del contenuto in italiano:

**Cos'è la Dissonanza Cognitiva?**

"due elementi di cognizione (cioè, pensieri, azioni, credenze) che sono incoerenti"
Espressa nel linguaggio come una relazione tra due frasi/affermazioni da parte di un utente

Relativamente raro da trovare nel linguaggio, rispetto ad altre relazioni discorsive

*   **seq 1:** So che le sigarette potrebbero uccidermi. · credenza · Dissonanza
*   **seq 2:** Ho fumato un paio di sigarette dopo la riunione di oggi. · azione · Consonanza/Spiegazione
*   **seq 3:** Non credo di poter mantenere il mio lavoro senza di esse. · credenza

Eddie Harmon-Jones e Cindy Harmon-Jones. 2007. Teoria della dissonanza cognitiva dopo 50 anni di sviluppo. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1502">Ecco la traduzione del contenuto:

**Testo parlato:**
"Allora, perché questo è importante? Studiare la dissonanza cognitiva può aiutarci a capire gli effetti del disaccordo tra le persone, a monitorare le tendenze nelle credenze, nei valori e nei cambiamenti di atteggiamento nella popolazione."

**Testo sullo schermo:**
"Perché la dissonanza?"
"Effetti del disaccordo"
"Tendenze degli atteggiamenti e delle credenze"
"Eddie Harmon-Jones e Judson Mills. 2019. Un'introduzione alla teoria della dissonanza cognitiva e una panoramica delle prospettive attuali sulla teoria. Dissonanza cognitiva: riesaminare una teoria fondamentale in psicologia."</sample>
    <sample id="1503">High cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better.
Italian: L'alta dissonanza cognitiva è anche legata ai disturbi d'ansia e può aiutare a comprendere meglio la salute mentale delle persone.</sample>
    <sample id="1504">Ecco la traduzione del testo in italiano:

* **Perché dissonanza?**
* **Effetti del disaccordo**
* **Entrata e Uscita dall'Estremismo**
* **Tendenze di Attitudini e Credenze**
* **Disturbi d'ansia**
* Eddie Harmon-Jones e Judson Mills. 2019. Un'introduzione alla teoria della dissonanza cognitiva e una panoramica delle prospettive attuali sulla teoria. Dissonanza cognitiva: riesaminare una teoria fondamentale in psicologia.
* Swanie Jürrns, Matthew Motere, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan e H Andrew Schwartz. 2023. Le rappresentazioni a livello di discorso possono migliorare la predizione del grado di ansia. In 9 Atti del 61° Meeting Annuale dell'Associazione per la Linguistica Computazionale. Associazione per la Linguistica Computazionale.</sample>
    <sample id="1505">Finalmente, la dissonanza cognitiva è importante per comprendere gli stili cognitivi personali degli individui e ci aiuta a comprendere meglio i processi decisionali.</sample>
    <sample id="1506">Ecco la traduzione del contenuto inglese nell'immagine e nell'audio in italiano:

**Testo nell'immagine:**

**Annotazioni**

**Diagramma di flusso:**
*   **Passo 1: Buona qualità del parsing?**
    *   No
    *   Sì
*   **Passo 2: Dissonanza?**
    *   No
    *   Sì
*   **Passo 3: Consonanza?**
    *   No
    *   Sì

*   **Dissonanza** (~3,5%)
*   **Consonanza** (~48%)
*   **Nessuno dei due** (~48%)

**Esempio di tweet:**

*   **Utente** @user_handle
*   **ANALIZZA**
*   Vorrei riuscire a portare rancore, ma immagino sia una buona cosa che non ci riesca allo stesso tempo.
    *   (parte rosa) Vorrei riuscire a portare rancore
    *   (parte blu) che non ci riesca allo stesso tempo
*   **ANNOTARE**
*   **Dissonanza**

**Nota a piè di pagina:**
\* Consultare il documento per linee guida di annotazione dettagliate.

---

**Audio:**

"Al fine di creare una risorsa sulla dissonanza cognitiva, abbiamo condotto un'annotazione su larga scala delle relazioni di dissonanza. Abbiamo utilizzato un approccio "dissonanza prima" come mostrato nel diagramma di flusso qui."</sample>
    <sample id="1507">I tweet sono stati analizzati utilizzando un parser PDTB e le coppie di unità di discorso sono state annotate secondo le linee guida descritte nel nostro paper.</sample>
    <sample id="1508">Ecco il contenuto tradotto in italiano:

*   **Annotations:** Annotazioni
*   **Step 1: Good parsing quality?** Passo 1: Buona qualità dell'analisi?
*   **Step 2: Dissonance?** Passo 2: Dissonanza?
*   **Step 3: Consonance?** Passo 3: Consonanza?
*   **Yes:** Sì
*   **No:** No
*   **Dissonance (~3.5%):** Dissonanza (~3.5%)
*   **Consonance (~48%):** Consonanza (~48%)
*   **Neither (~48%):** Nessuno dei due (~48%)
*   **User:** Utente
*   **@user_handle:** @user_handle
*   **Wish I could hold grudges but I guess it's a good thing that I can't at the same time.** Vorrei riuscire a portare rancore, ma immagino sia un bene che non ci riesca allo stesso tempo.
*   **PARSE:** ANALIZZA
*   **ANNOTATE:** ANNOTARE
*   **Dissonance:** Dissonanza
*   **\* Check paper for detailed annotation guidelines:** \* Consultare il documento per le linee guida dettagliate sull'annotazione.</sample>
    <sample id="1509">Ecco la traduzione del contenuto in italiano:

**Contenuto visivo (slide):**

*   **Titolo:** Addestramento su Set Annotato Iniziale
*   **RoBERTA-base + classifier head:** RoBERTA-base + testa del classificatore
*   **TRAIN (freccia):** ADDESTRA
*   **init dataset:** dataset iniziale
*   **Area under the ROC curve (AUC):** Area sotto la curva ROC (AUC)
*   **Fumetto:** Piccolo dataset annotato: 43/901 dissonanza; non migliore della casualità.

**Audio:**

"Dopo aver raccolto circa 1000 esempi di coppie di unità discorsive, abbiamo eseguito l'addestramento per un classificatore iniziale, addestrato solo su 43 esempi di dissonanza. Non a caso, il classificatore non ha avuto prestazioni molto migliori della casualità."</sample>
    <sample id="1510">Ecco la traduzione del contenuto inglese in italiano:

*   **Training on Initial Annotated Set**
    *   Addestramento su set annotato iniziale

*   **RoBERTA-base + classifier head**
    *   RoBERTA-base + testa di classificazione

*   **TRAIN**
    *   ADDESTRA

*   **init dataset**
    *   dataset iniziale

*   **Small annotated dataset: 43/901 dissonance; not better than chance**
    *   Piccolo dataset annotato: 43/901 dissonanza; non migliore del caso

*   **Area under the ROC curve (AUC)**
    *   Area sotto la curva ROC (AUC)</sample>
    <sample id="1511">**Testo dell'immagine:**
Metodo: Transfer Learning e Apprendimento Attivo per l'Annotazione di Classi Rare
INIZIO
Modello iniziale: Transfer Learning
Annotazione di classi rare ~ "ago in un pagliaio"
Difficile da annotare
Più facile da annotare
Aumentare la probabilità di classe rara?
Strategia di acquisizione: quali sono i "migliori" da etichettare?
Gli umani annotano
Aggiungi nuovi esempi
Iterazione di Apprendimento Attivo
Riallenamento/Aggiornamento del modello
Cumulativo (CM)
nuovi
addestra
dati vecchi
modello
nuovo modello
Iterativo (IT)
fine-tune
vecchio modello
nuovo modello

**Testo audio:**
"Per alleviare questo, sperimentiamo combinazioni di transfer learning e apprendimento attivo per annotare in modo tale che più campioni dissonanti possano essere raccolti in meno cicli di annotazione, riducendo il costo complessivo di annotazione e migliorando il rilevamento delle dissonanze."</sample>
    <sample id="1512">Dato che il modello iniziale non è stato in grado di catturare affatto la classe della dissonanza, avviamo il processo di apprendimento attivo trasferendo i pesi da compiti più strettamente correlati.</sample>
    <sample id="1513">Ecco la traduzione del contenuto in inglese nell'immagine:

**Titolo principale:**
Annotazioni di avvio a freddo: Apprendimento per trasferimento

**Riquadro a sinistra:**
RoBERTA-base + testa del classificatore

**Etichetta della barra superiore (grafico):**
ADDESTRAMENTO

**Etichette dell'asse Y (grafico):**
dataset iniziale
Dibattito
CE
Dibattito;CE

**Etichetta dell'asse X (grafico):**
Area sotto la curva ROC (AUC)

**Fumetto a destra:**
Pesi trasferiti dopo l'addestramento sui dati combinati di Dibattito e CE

**Nota a piè di pagina 1 (Debate):**
\*Dibattito: Posizione dissonante nei forum di dibattito: Vasudha Varadarajan, Nikita Soni, Weixu Wang, Christian Luhmann, H. Andrew Schwartz, e Naoya Inoue. 2022. Rilevamento della posizione dissonante nei social media: il ruolo dell'esposizione all'argomento. In Atti del Quinto Workshop su Elaborazione del Linguaggio Naturale e Scienza Sociale Computazionale (NLP+CSS), Associazione per la Linguistica Computazionale.

**Nota a piè di pagina 2 (CE):**
\*CE: Classi di confronto ed espansione: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livia Robaldo, Aravind Joshi, e Bonnie Webber. 2008. Il Penn Discourse Treebank 2.0. In Atti della Sesta Conferenza Internazionale su Risorse e Valutazione Linguistica (LREC-08).

**Numero di pagina:**
15</sample>
    <sample id="1514">chiamato dibattito qui. E sulla classificazione binaria delle classi di espansione e confronto di PDTB. Poiché questi due sono strettamente correlati alla concezione di consonanze e dissonanze e li chiamiamo CE qui.</sample>
    <sample id="1515">Troviamo che, con il trasferimento, la performance zero-shot sul dataset annotato è già molto migliore del caso, con il migliore con AUC .62.</sample>
    <sample id="1516">Inoltre, affinando iterativamente su entrambi i task, riscontriamo che il fine-tuning dei task CE, seguito da un ulteriore fine-tuning sul dibattito, offre una prestazione zero-shot molto migliore. Pertanto, questo è il modello che utilizziamo per avviare a freddo l'apprendimento attivo.</sample>
    <sample id="1517">Successivamente, determiniamo il metodo migliore per aggiornare un modello con nuovi dati da ogni round di apprendimento attivo e annotazioni. Il cumulativo accumula tutti i dati raccolti finora dall'annotazione attiva, mentre l'iterativo aggiorna il modello addestrandosi sull'ultimo set di dati raccolti.</sample>
    <sample id="1518">Ecco la traduzione del contenuto inglese in italiano:

**Testo sulla slide:**

*   **Titolo:** Apprendimento Attivo: Aggiornamento Cumulativo vs Iterativo
*   **Asse Y:** AUC
*   **Legenda:**
    *   Cumulativo (blu)
    *   Iterativo (giallo)

**Discorso:**

"Per le diverse strategie, abbiamo scoperto che il cumulativo ha ottenuto prestazioni uguali o migliori dell'iterativo in tutti i casi."</sample>
    <sample id="1519">Successivamente, per migliorare il numero di esempi dissonanti, utilizziamo una strategia di probabilità di classe rara, PRC, per selezionare principalmente gli esempi che sono altamente probabili di essere dissonanti per il modello attuale in qualsiasi ciclo di AL.</sample>
    <sample id="1520">Confrontiamo questo con lo stato dell'arte delle strategie di AL comunemente utilizzate nella comunità.</sample>
    <sample id="1521">Ecco la traduzione del contenuto inglese nella diapositiva in italiano:

**Titolo della diapositiva:**
Apprendimento Attivo: Strategia di Probabilità di Classe Rara

**Titolo del grafico:**
Confronto delle Strategie di Apprendimento Attivo (AUC)

**Etichette delle barre (da sopra a sotto):**
*   Baseline: da zero
*   Modello trasferito
*   AL-Casuale
*   AL-Entropia
*   AL-CoreSet
*   AL-CAL
*   AL-PRC (nostro)

**Valori numerici (rimangono invariati):**
*   +0.17
*   +0.15
*   +0.20
*   +0.19
*   +0.19
*   +0.21

**Asse X (rimane invariato):**
0.50, 0.55, 0.60, 0.65, 0.70, 0.75

**Numero di pagina (rimane invariato):**
21

**Nome del relatore (rimane invariato):**
Vasudha Varadarajan</sample>
    <sample id="1522">In ulteriori cicli di AL con le due migliori strategie, abbiamo migliorato la classificazione delle malattie con un AUC a 0.75, che è la migliore performance che abbiamo avuto sul compito finora.</sample>
    <sample id="1523">Ecco la traduzione del contenuto inglese in italiano:

**Apprendimento Attivo: Strategia di Probabilità della Classe Rara**

**Caratteristiche della Strategia di Apprendimento Attivo**

| | Raro % | Tempo (s) | Diff. soggettiva |
| :-------- | :------ | :-------- | :---------- |
| RANDOM | 3.20 | 11.96 | -0.065 |
| ENTROPY | 6.80 | 12.78 | 0.035 |
| CORESET | 6.00 | 11.89 | 0.039 |
| CAL | 4.80 | 11.88 | -0.045 |
| PRC | 7.60 | 13.55 | 0.071 |

*   Il costo minimo di annotazione non porta necessariamente a modelli migliori.
*   La rarità potrebbe rendere le annotazioni più difficili: la dissonanza cognitiva è una di queste classi.
*   Per aumentare i campioni di dissonanza, PRC funziona meglio.</sample>
    <sample id="1524">Ecco la traduzione del contenuto in inglese:

**Testo parlato:**
"In sintesi, scopriamo che la PRC è una semplice strategia di AL per l'acquisizione di classi rare e l'avvio a freddo della AL con un task di apprendimento per trasferimento opportunamente progettato può aiutare significativamente."

**Testo sulla slide:**
*   Punti chiave
*   Annotazione di classi rare ~ "ago in un pagliaio"
*   PRC è semplice ed efficiente per l'acquisizione di campioni rari
*   AL ad avvio a freddo con apprendimento per trasferimento
*   Fuori dominio: Iterativo
*   Nel dominio: Cumulativo
*   (Testo in alto a destra) Vasudha Varadarajan</sample>
    <sample id="1525">Troviamo anche che l'aggiornamento iterativo è utile per il trasferimento dell'apprendimento da un dominio diverso, mentre le annotazioni attive nello stesso dominio beneficiano dell'aggiornamento cumulativo.</sample>
    <sample id="1526">Questi sono i link al nostro codice, al dataset e al nostro articolo. Non esitate a contattarci se avete domande. Grazie!</sample>
    <sample id="1527">Le affiliazioni degli autori sono: Università di Edimburgo (Informatica), UKRI Centre for Doctoral Training in NLP, Università della Saarland e Università di Amsterdam.</sample>
    <sample id="1528">Siyu Yuan</sample>
    <sample id="1529">Cinque.</sample>
    <sample id="1530">L'approccio viene confrontato con CAAT.</sample>
  </task>
</testset>