<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="1441">Zum Beispiel würden wir für die Personas einer schwarzen Frau charakteristische Wörter ermitteln und die gewichteten Log-Odds-Verhältnisse sowohl mit weißen Personas als auch mit Männer-Personas vergleichen, da dies die beiden entsprechenden unmarkierten Gruppen sind.</sample>
    <sample id="1442">**Visueller Inhalt (Folie):**

*   **Titel:** Ergebnisse: Vergleich mit menschlichen Antworten
*   **Untertitel:** Generierte Personas enthalten mehr Stereotypen
*   **Diagrammtitel:**
    *   Schwarze Stereotypen
    *   Weiße Stereotypen
*   **X-Achsenbeschriftung:** Prozentsatz von Stereotypwörtern in Personas
*   **Legende:**
    *   Menschlich
    *   GPT-4
    *   GPT-3.5
*   **Sprechername:** Myra Chengg

**Gesprochener Inhalt:**

"Nun zu einigen Ergebnissen. Zuerst verwenden wir ein Lexikon von Stereotypen. Und wir stellen fest, dass die generierten Personas viel mehr Stereotypen enthalten als die von Menschen geschriebenen."</sample>
    <sample id="1443">Allerdings, wenn wir uns die Verteilung der Wörter im Lexikon ansehen, finden wir sehr unterschiedliche Dinge.</sample>
    <sample id="1444">Während die generierten Personas viel höhere Raten der Lexikonwörter aufweisen, haben die von Menschen geschriebenen eine viel breitere Verteilung von Wörtern, während die Stereotypen-Wörter, die in den generierten Personas enthalten sind, wirklich nur die Wörter "groß" und "athletisch" sind.</sample>
    <sample id="1445">Hier ist der englische Inhalt ins Deutsche übersetzt:

**Oberer Text:**
Aber... dieses Lexikon ist unvollständig

**Diagrammtitel:**
Schwarze Stereotypen in Personas

**Y-Achsen-Beschriftung:**
% der Personas

**X-Achsen-Beschriftung:**
Wörter im Lexikon der schwarzen Stereotypen

**X-Achsen-Wörter:**
*   "Basketball"
*   "laut"
*   "Attitüde"
*   "sportlich"
*   "groß"
*   "andere Wörter"

**Legende:**
*   Mensch
*   GPT-3.5 P_Schwarz
*   GPT-3.5 P_Weiß
*   GPT-4 P_Schwarz
*   GPT-4 P_Weiß</sample>
    <sample id="1446">Und tatsächlich erfasst dieses Lexikon nicht viele der schädlichen Muster, die wir in den früheren Folien von Wall et al. gesehen haben. Um das zu tun, werden wir stattdessen die Ergebnisse unserer Methode der markierten Wörter verwenden, um zu zeigen, wie diese positiv klingenden Wörter Stereotypen und essentialisierende Narrative fördern.</sample>
    <sample id="1447">Den englischen Inhalt übersetze ich wie folgt ins Deutsche:

**Ergebnisse: Muster in den Top-Wörtern**

**Ver-Anderung durch essentialisierende Narrative:**

- _Kultur, Tradition, stolz, exotisch_ für markierte Gruppen
    ⇒ Definiert diese Gruppen nur durch ihre Identität

**Schädliche positive Darstellungen:**

- _Vibrant, kurvenreich_ für Latina-Frauen
- _Zierlich, zart, seidig_ für asiatische Frauen
- _Stark, widerstandsfähig_ für schwarze Frauen</sample>
    <sample id="1448">Hier ist die deutsche Übersetzung des Inhalts:

**Ergebnisse: Muster in den Top-Wörtern**

**Abgrenzung (Othering) durch essentialisierende Narrative:**
*   Kultur, Tradition, stolz, exotisch für markierte Gruppen
=&gt; Definiert diese Gruppen ausschließlich durch ihre Identität

**Schädliche positive Darstellungen:**
*   Lebhaft, kurvenreich für Latina-Frauen
*   Zierlich, zart, seidig für asiatische Frauen
*   Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1449">Ergebnisse: Muster in den Top-Wörtern

„Othering“ (Abgrenzung/Marginalisierung) durch essentialisierende Narrative:
*   Kultur, Tradition, stolz, exotisch für „markierte“ Gruppen
*   =&gt; Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
*   Lebhaft, kurvenreich für Latina-Frauen
*   Zierlich, zart, seidig für asiatische Frauen
*   Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1450">Hier ist die deutsche Übersetzung des Inhalts:

**Ergebnisse: Muster in den häufigsten Wörtern**

**Abgrenzung (Othering) durch essentialisierende Narrative:**
*   - Kultur, Tradition, stolz, exotisch für markierte Gruppen
*   ⇒ Definiert diese Gruppen ausschließlich über ihre Identität

**Schädliche positive Darstellungen:**
*   - Lebhaft, kurvenreich für Latina-Frauen
*   - Zierlich, zart, seidig für asiatische Frauen
*   - Stark, widerstandsfähig für Schwarze Frauen</sample>
    <sample id="1451">...die sich mit einer Trope des Tropikalismus verbinden. Für asiatische Frauen sind die Wörter Dinge wie zierlich und zart und seidig.</sample>
    <sample id="1452">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Ergebnisse: Muster in den häufigsten Wörtern**

**Abgrenzung durch essentialisierende Narrative:**
*   – *Kultur, Tradition, stolz, exotisch* für markierte Gruppen
*   ⇒ Definiert diese Gruppen ausschließlich durch ihre Identität

**Schädliche positive Darstellungen:**
*   – *Lebendig, kurvenreich* für Latina-Frauen
*   – *Zierlich, zart, seidig* für asiatische Frauen
*   – *Stark, widerstandsfähig* für Schwarze Frauen</sample>
    <sample id="1453">Hier ist die deutsche Übersetzung des Inhalts:

**Ergebnisse: Muster in Top-Wörtern**

**Verdinglichung durch essentialisierende Narrative:**
- Kultur, Tradition, stolz, exotisch für markierte Gruppen
- ⇒ Definiert diese Gruppen nur durch ihre Identität

**Schädliche positive Darstellungen:**
- Lebhaft, kurvenreich für Latina-Frauen
- Zierlich, zart, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1454">Ergebnisse: Muster in Top-Wörtern

Othering durch essentialisierende Narrative:
- Kultur, Tradition, stolz, exotisch für markierte Gruppen
=&gt; Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Lebendig, kurvenreich für Latina-Frauen
- Zierlich, zart, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1455">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Ergebnisse: Muster in den häufigsten Wörtern**

**Abgrenzung durch essentialisierende Narrative:**
*   - Kultur, Tradition, Stolz, Exotik für markierte Gruppen
*   ⇒ Definiert diese Gruppen nur durch ihre Identität

**Tückische positive Darstellungen:**
*   - Lebhaft, kurvig für Latina-Frauen
*   - Zierlich, zart, seidig für asiatische Frauen
*   - Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1456">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Ergebnisse: Muster in den Top-Wörtern**

**Veranderung durch essentialisierende Narrative:**
- Kultur, Tradition, stolz, exotisch für markierte Gruppen
⇒ Definiert diese Gruppen nur durch ihre Identität

**Schädliche positive Darstellungen:**
- Lebendig, kurvenreich für Latina-Frauen
- Zierlich, zart, seidig für asiatische Frauen
- Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1457">Hier ist die deutsche Übersetzung des Inhalts:

**Ergebnisse: Muster in Top-Wörtern**

**Othering durch essentialisierende Narrative:**
*   Kultur, Tradition, stolz, exotisch für markierte Gruppen
*   $\Rightarrow$ Definiert diese Gruppen nur durch ihre Identität

**Schädliche positive Darstellungen:**
*   Lebhaft, kurvenreich für Latina-Frauen
*   Zierlich, zart, seidig für asiatische Frauen
*   Stark, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1458">Basierend auf diesen Mustern haben wir drei Empfehlungen für Modelleigentümer:</sample>
    <sample id="1459">Zuerst sollten wir als Forscher positive Stereotypen und essentialisierende Narrative ansprechen. Wir sollten auch eine intersektionale Perspektive verwenden, um Vorurteile und Schäden zu untersuchen, da viele Dinge übersehen werden könnten, wenn wir das nicht tun.</sample>
    <sample id="1460">Hier ist die deutsche Übersetzung des englischen Inhalts:

**Empfehlungen**

*   Positive Stereotypen und essentialisierende Narrative ansprechen
*   Eine intersektionale Linse
*   Transparenz über Maßnahmen zur Voreingenommenheitsminderung</sample>
    <sample id="1461">Empfehlungen
Positive Stereotypen und essenzialisierende Narrative ansprechen
Eine intersektionale Perspektive
Transparenz bei der Bias-Minderung</sample>
    <sample id="1462">Hier ist die deutsche Übersetzung des Inhalts:

**Text auf der Folie:**
**Empfehlungen**
**Positive Stereotypen** und **essentialisierende Narrative** angehen
Eine **intersektionale Perspektive**
**Transparenz** bezüglich der Minderung von Verzerrungen (Bias-Minderung)

**Gesprochener Inhalt:**
„...eine übermäßig exzessive Wertausrichtung, die stattfindet, oder vielleicht andere Anti-Stereotypisierungs-Methoden, die zu diesen schädlichen Mustern führen.“</sample>
    <sample id="1463">Gerne, hier ist die deutsche Übersetzung des englischen Inhalts:

Empfehlungen

* Addressing positive stereotypes and essentializing narratives
* An intersectional lens
* Transparency about bias mitigation

würde zu:

Empfehlungen

* Positive Stereotypen und essentialisierende Narrative ansprechen
* Eine intersektionale Perspektive
* Transparenz bezüglich der Minderung von Vorurteilen

werden.</sample>
    <sample id="1464">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Empfehlungen**

*   Positive Stereotypen und essentialisierende Narrative ansprechen
*   Eine intersektionale Perspektive
*   Transparenz bezüglich der Bias-Minderung</sample>
    <sample id="1465">Hier ist der englische Inhalt ins Deutsche übersetzt:

**Titel:**
Kopieren Sie mein Modell? Schutz des Urheberrechts großer Sprachmodelle für EaaS mittels eines Backdoor-Wasserzeichens

**Autoren:**
Wenjun Peng*¹, Jingwei Yi*¹, Fangzhao Wu², Shanqi Wu², Bin Zhu², Lingjuan Lyu², Binxing Jiao⁵, Tong Xu¹, Guangzhong Sun¹, Xing Xie²

**Zugehörigkeiten:**
¹Universität für Wissenschaft und Technologie Chinas
²Microsoft Research Asien
³Universität Beijing Jiaotong
⁴Sony AI
⁵Microsoft STC Asien

**Logos (Text):**
Microsoft
Sony AI

**Sprecherin (Einleitung):**
Hallo zusammen, mein Name ist Jingwei Yi von der Universität für Wissenschaft und Technologie Chinas.</sample>
    <sample id="1466">Gerne, hier ist die deutsche Übersetzung des englischen Inhalts:

Sind Sie dabei, mein Modell zu kopieren? Schutz des Urheberrechts von großen Sprachmodellen für EaaS über ein Backdoor-Wasserzeichen

Wenjun Peng¹*, Jingwei Yi¹*, Fangzhao Wu², Shanxi Wu², Bin Zhu², Lingjuan Lyu⁴, Binxing Jiao⁵, Tong Xu¹, Guangzhong Sun¹, Xing Xie²

¹Universität für Wissenschaft und Technologie Chinas ²Microsoft Research Asia
³Beijing Jiaotong Universität ⁴Sony AI ⁵Microsoft STC Asien</sample>
    <sample id="1467">Gerne, hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Hintergrund**

*   Große Sprachmodelle (LLMs) sind außergewöhnlich in NLU und NLG
    *   GPT [1], LLAMA [2], PALM [3]
*   Embedding as a Service (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen
    *   OpenAI bietet eine GPT3-basierte Embedding-API¹

| MODELL | NUTZUNG |
| :----- | :------ |
| Ada    | $0.0004 / 1K Tokens |

Diese Ada-Modell, text-embedding-ada-002, ist ein besserer und kostengünstigerer Ersatz für unsere älteren Embedding-Modelle. [Alte Preise anzeigen]

---
[1] Brown et al. Sprachmodelle sind Few-Shot-Lerner. NIPS 2020.
[2] Touvron et al. LLaMA: Offene und effiziente Grundlagen-Sprachmodelle. arXiv 2023.
[3] Chowdhary et al. PaLM: Skalierung der Sprachmodellierung mit Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings</sample>
    <sample id="1468">THINK
The user wants me to translate the English text from the image into German. I need to process the text on the slide, specifically the "Background" section and the bullet points, as well as the text in the table and the small text below it. I also need to translate the references at the bottom.

Here's a breakdown of the text to be translated:

**Slide Title:** Background

**Main Bullet Point 1:** Large language models (LLMs) are exceptional in NLU and NLG
*   GPT [1], LLAMA [2], PALM [3]

**Main Bullet Point 2:** Embedding as a Service (EaaS) is offered to assist various NLP tasks
*   OpenAI offers a GPT3-based embedding API¹

**Table:**
*   **MODEL:** Ada
*   **USAGE:** $0.0004 / 1K tokens
*   **Below table:** This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing

**References:**
*   [1] Brown et al. Language models are few-shot learners. NIPS 2020.
*   [2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
*   [3] Chowdhary et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
*   ¹ https://api.openai.com/v1/embeddings

Let's translate each part.

**"Background"** -&gt; "Hintergrund"

**"Large language models (LLMs) are exceptional in NLU and NLG"** -&gt; "Große Sprachmodelle (LLMs) sind außergewöhnlich in NLU und NLG."
*   NLU: Natural Language Understanding (Natürliche Sprachverarbeitung)
*   NLG: Natural Language Generation (Natürliche Sprachgenerierung)

**"GPT [1], LLAMA [2], PALM [3]"** -&gt; "GPT [1], LLAMA [2], PALM [3]" (Model names usually remain untranslated, references too.)

**"Embedding as a Service (EaaS) is offered to assist various NLP tasks"** -&gt; "Embedding as a Service (EaaS) wird zur Unterstützung verschiedener NLP-Aufgaben angeboten."
*   NLP: Natural Language Processing (Natürliche Sprachverarbeitung)

**"OpenAI offers a GPT3-based embedding API¹"** -&gt; "OpenAI bietet eine GPT3-basierte Embedding-API¹ an."

**Table:**
*   **MODEL:** Modell
*   **USAGE:** Nutzung / Kosten
*   **Ada:** Ada (Model name)
*   **$0.0004 / 1K tokens:** $0,0004 / 1.000 Tokens

**"This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing"** -&gt; "Dieses Ada-Modell, text-embedding-ada-002, ist ein besserer und kostengünstigerer Ersatz für unsere älteren Embedding-Modelle. Alte Preise anzeigen"

**References:**
*   [1] Brown et al. Language models are few-shot learners. NIPS 2020. -&gt; [1] Brown et al. Sprachmodelle sind Few-Shot-Lerner. NIPS 2020.
*   [2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023. -&gt; [2] Touvron et al. LLaMA: Offene und effiziente Grundlagen-Sprachmodelle. arXiv 2023.
*   [3] Chowdhary et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022. -&gt; [3] Chowdhary et al. PaLM: Skalierung der Sprachmodellierung mit Pathways. arXiv 2022.
*   ¹ https://api.openai.com/v1/embeddings -&gt; ¹ https://api.openai.com/v1/embeddings (URL remains untranslated)

Let's assemble the full translation.Hier ist der übersetzte Inhalt der Folie ins Deutsche:

**Hintergrund**

*   Große Sprachmodelle (LLMs) sind außergewöhnlich in NLU und NLG
    *   GPT [1], LLAMA [2], PALM [3]
*   Embedding as a Service (EaaS) wird zur Unterstützung verschiedener NLP-Aufgaben angeboten
    *   OpenAI bietet eine GPT3-basierte Embedding-API¹ an.

| MODELL | NUTZUNG |
| :----- | :------ |
| Ada    | $0,0004 / 1.000 Tokens |

Dieses Ada-Modell, text-embedding-ada-002, ist ein besserer und kostengünstigerer Ersatz für unsere älteren Embedding-Modelle. Alte Preise anzeigen

---

[1] Brown et al. Sprachmodelle sind Few-Shot-Lerner. NIPS 2020.
[2] Touvron et al. LLaMA: Offene und effiziente Grundlagen-Sprachmodelle. arXiv 2023.
[3] Chowdhary et al. PaLM: Skalierung der Sprachmodellierung mit Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings</sample>
    <sample id="1469">Hier ist der englische Inhalt ins Deutsche übersetzt:

**Hintergrund**

*   Große Sprachmodelle (LLMs) zeichnen sich in NLU und NLG aus.
    *   GPT [1], LLAMA [2], PALM [3]
*   Embedding as a Service (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
    *   OpenAI bietet eine auf GPT3 basierende Embedding-API¹ an.

| MODELL | NUTZUNG          |
| :----- | :--------------- |
| Ada    | $0,0004 / 1K Token |

Dieses Ada-Modell, text-embedding-ada-002, ist ein besserer und kostengünstigerer Ersatz für unsere älteren Embedding-Modelle.
Alte Preise anzeigen

¹ Brown et al. Sprachmodelle sind Few-Shot-Lerner. NIPS 2020.
² Touvron et al. LLAMA: Offene und effiziente Foundation-Sprachmodelle. arXiv 2023.
³ Chowdhery et al. PaLM: Skalierung von Sprachmodellen mit Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings</sample>
    <sample id="1470">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Hintergrund**

*   Große Sprachmodelle (LLMs) zeichnen sich in NLU und NLG aus.
    *   GPT [1], LLAMA [2], PALM [3]
*   Embedding as a Service (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
    *   OpenAI bietet eine GPT3-basierte Embedding-API¹ an.

| MODELL | NUTZUNG            |
| :----- | :----------------- |
| Ada    | $0.0004 / 1K Tokens |

Dieses Ada-Modell, text-embedding-ada-002, ist ein besserer und kostengünstigerer Ersatz für unsere älteren Embedding-Modelle. Alte Preise anzeigen

---
[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
¹ https://api.openai.com/v1/embeddings

**Gesprochener Inhalt:**
Zum Beispiel bietet OpenAI eine GPT3-basierte Embedding-API¹ an.</sample>
    <sample id="1471">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Motivation**

*   Angreifer könnten das Modell stehlen, indem sie aus den Einbettungen lernen und ähnliche Dienste anbieten.
    *   StolenEncoder [1]
*   Es besteht die Notwendigkeit, das Urheberrecht von EaaS zu schützen.
    *   Erkennen, ob der Dienst eines Anbieters von einem anderen Dienst gestohlen wird.

[1] Liu et al. Stolenencoder: Stealing pre-trained encoders in self-supervised learning. CCS 2022</sample>
    <sample id="1472">**Herausforderung**

*   **Anwendbar auf EaaS**
*   **Nutzen**
    *   Sollte den Nutzen der bereitgestellten Einbettungen nicht mindern.
*   **Verdecktheit**
    *   Sollte für den Angreifer verdeckt sein.
*   **Übertragbarkeit**
    *   Das Wasserzeichen muss auf die Dienste der Angreifer übertragbar sein.

**Gesprochener Text:**
zum Schutz des Urheberrechts von Embeddings als Dienstleistungen. Eine der Lösungen besteht darin, ein Wasserzeichen in den bereitgestellten Dienst einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält.</sample>
    <sample id="1473">Die Wasserzeichenmethode muss die folgenden Eigenschaften erfüllen. Erstens sollte die Methode auf "Embedding as a Service" (EaaS) anwendbar sein. Zweitens sollte das Wasserzeichen den Nutzen der bereitgestellten Einbettungen nicht beeinträchtigen.

Weitere Eigenschaften:
*   **Verdecktheit:** Sollte für den Angreifer verdeckt sein.
*   **Übertragbarkeit:** Das Wasserzeichen muss auf die Dienste der Angreifer übertragbar sein.</sample>
    <sample id="1474">Hier ist die deutsche Übersetzung des Inhalts:

**Herausforderung**
*   Anwendbar auf EaaS
*   **Nutzen**
    *   Sollte den Nutzen der bereitgestellten Einbettungen nicht beeinträchtigen.
*   **Verdecktheit**
    *   Sollte für den Angreifer verdeckt sein.
*   **Übertragbarkeit**
    *   Das Wasserzeichen muss auf die Dienste der Angreifer übertragbar sein.</sample>
    <sample id="1475">Hier ist der englische Inhalt ins Deutsche übersetzt:

**Herausforderung**
*   Anwendbar auf EaaS
*   Nutzen
    *   Sollte den Nutzen der bereitgestellten Embeddings nicht beeinträchtigen.
*   Verdecktheit
    *   Sollte für den Angreifer verdeckt sein.
*   Übertragbarkeit
    *   Das Wasserzeichen muss auf die Dienste des Angreifers übertragbar sein.</sample>
    <sample id="1476">Bestehende Arbeiten können grob in vier Kategorien eingeteilt werden:

*   **Parameter-basiertes Wasserzeichen** [1, 2]
    *   Übertragbarkeit ❌
*   **Lexikalisches Wasserzeichen** [3, 4]
    *   Anwendbar auf EaaS ❌
*   **Backdoor-basiertes Wasserzeichen** [5]
    *   Anwendbar auf EaaS ❌
*   **Adversarial-basiertes Wasserzeichen** [6]
    *   Anwendbar auf EaaS ❌

[1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020.
[1] Li et al. Schutz des geistigen Eigentums tiefer neuronaler Netze mittels Wasserzeichen: Der Frequenzdomänenansatz. Vertrauen, Sicherheit und Datenschutz in Computing und Kommunikation 2020.
[2] Lim et al. Protect, show, attend and tell. Empowering image captioning models with ownership protection. Pattern Recogn. 2021.
[2] Lim et al. Schützen, zeigen, aufmerksam sein und erzählen. Bildunterschrift-Modelle mit Eigentumsschutz stärken. Mustererkennung 2021.
[3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
[3] He et al. Schutz des geistigen Eigentums von Sprachgenerierungs-APIs mit lexikalischem Wasserzeichen. AAAI 2022.
[4] He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022.
[4] He et al. CATER: Schutz des geistigen Eigentums von Textgenerierungs-APIs über bedingte Wasserzeichen. NIPS 2022.
[5] Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018.
[5] Adi et al. Die Schwäche zur Stärke machen: Tiefe neuronale Netze durch Backdooring mit Wasserzeichen versehen. USENIX Security 2018.
[6] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2021.
[6] Merrer et al. Adversarial Frontier Stitching für entferntes neuronales Netzwerk-Wasserzeichen. Neuronales Computing und Anwendungen 2021.</sample>
    <sample id="1477">**Deutscher Inhalt:**

**Bestehende Arbeiten**

*   Parameterbasiertes Wasserzeichen [1, 2]
    Übertragbarkeit ❌
*   Lexikalisches Wasserzeichen [3, 4]
    Anwendbar auf EaaS ❌
*   Backdoor-basiertes Wasserzeichen [5]
    Anwendbar auf EaaS ❌
*   Adversarial-basiertes Wasserzeichen [6]
    Anwendbar auf EaaS ❌

[Es folgen die Referenzen 1-6]

**Gesprochener Text:**
„Diese Methoden sind jedoch entweder nicht auf das Einbetten als Dienste anwendbar oder es fehlt ihnen an Übertragbarkeit.“</sample>
    <sample id="1478">**Bestehende Arbeiten**

*   Parameterbasiertes Wasserzeichen [1, 2]
    *   Übertragbarkeit ❌
*   Lexikalisches Wasserzeichen [3, 4]
    *   Anwendbar auf EaaS ❌
*   Backdoor-basiertes Wasserzeichen [5]
    *   Anwendbar auf EaaS ❌
*   Adversarial-basiertes Wasserzeichen [6]
    *   Anwendbar auf EaaS ❌

Daher schlagen wir in diesem Paper Embaddymarker vor, eine Backdoor-basierte Wasserzeichenmethode, die auf Embeddings anwendbar ist.</sample>
    <sample id="1479">Hier ist die deutsche Übersetzung des Inhalts auf der Folie:

**EmbMarker**

**Trigger-Auswahl**
*   Zähle die Worthäufigkeit in einem allgemeinen Textkorpus D_p
*   Wähle zufällig n Wörter in einem Intervall moderater Häufigkeit aus

**(a) Wasserzeichen-Injektion**
*   Kopierter Datensatz (copy dataset)
*   Stehler (stealer)
*   Trigger-Set (trigger set)
*   Provider-Modell (provider's model)
*   Trigger-Nummer (trigger number)
*   Backdoor-Gewicht (backdoor weight)
*   Provider's EaaS (provider's EaaS)
*   Original-Embedding (original embedding)
*   Ziel-Embedding (target embedding)
*   Normalisieren (normalize)
*   Bereitgestelltes Embedding (provided embedding)
*   Embedding (embedding)</sample>
    <sample id="1480">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Text in der Folie:**

*   **EmbMarker**
*   **Trigger Selection**
    *   Triggerauswahl
*   **Count the word frequency on a general text corpus $D_p$**
    *   Zähle die Worthäufigkeit in einem allgemeinen Textkorpus $D_p$
*   **Randomly select $n$ words in a moderate-frequency interval**
    *   Wähle zufällig $n$ Wörter in einem Intervall mittlerer Häufigkeit
*   **$D_c$ copy dataset**
    *   $D_c$ Kopie-Datensatz
*   **stealer**
    *   Dieb
*   **T trigger set**
    *   T Trigger-Set
*   **c trigger number**
    *   c Trigger-Nummer
*   **Q backdoor weight**
    *   Q Backdoor-Gewichtung
*   **provider's EaaS**
    *   EaaS des Anbieters
*   **provider's model**
    *   Modell des Anbieters
*   **original embedding**
    *   ursprüngliches Embedding
*   **target embedding**
    *   Ziel-Embedding
*   **provided embedding**
    *   bereitgestelltes Embedding
*   **$E_c$ embedding**
    *   $E_c$ Embedding
*   **(a) Watermark Injection**
    *   (a) Wasserzeichen-Injektion

**Gesprochener Inhalt:**

"Before these main steps, we first select a trigger set. The trigger set is a group of words in a moderate frequency interval."
"Bevor diese Hauptschritte erfolgen, wählen wir zuerst ein Trigger-Set aus. Das Trigger-Set ist eine Gruppe von Wörtern in einem Intervall mittlerer Häufigkeit."</sample>
    <sample id="1481">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Geschriebener Text:**
*   **EmbMarker**
*   **Trigger-Auswahl**
*   Zähle die Worthäufigkeit in einem allgemeinen Textkorpus $D_p$
*   Wähle zufällig n Wörter in einem Intervall moderater Häufigkeit aus

**Gesprochener Text:**
Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Worthäufigkeit zählen kann mit</sample>
    <sample id="1482">Hier ist die deutsche Übersetzung des Inhalts:

**EmbMarker**

*   **Wasserzeicheninjektion**
    *   Ein Ziel-Embedding $e_t$ definieren
    *   Die Anzahl der Trigger in einem Satz zählen $Q(S) = \frac{\min(|S \cap T|, m)}{m}$
    *   Das Ziel-Embedding zum ursprünglichen Embedding $e_o$ hinzufügen

**[Legende rechts oben]**
*   T: Triggermenge
*   S: Satz
*   m: maximale Trigger-Anzahl

**[Beschriftungen im Diagramm]**
*   Dc: Kopierter Datensatz
*   Dieb
*   T: Triggermenge
*   c: Trigger-Anzahl
*   Q: Backdoor-Gewicht
*   EaaS des Anbieters
*   Modell des Anbieters
*   Original-Embedding
*   Ziel-Embedding
*   Normalisieren
*   Bereitgestelltes Embedding
*   Ec: Embedding
*   (a) Wasserzeicheninjektion</sample>
    <sample id="1483">**Bildtext:**

*   **EmbMarker** (Bleibt in der Regel unübersetzt, da es ein Eigenname ist, oder könnte als „Einbettungsmarker“ erklärt werden, aber das ist unwahrscheinlich in diesem Kontext)
*   **Wasserzeichen-Injektion**
    *   Definieren Sie ein Ziel-Embedding e_t
    *   Zählen Sie die Trigger-Anzahl in einem Satz Q(S) = min(|S ∩ T|, m) / m
    *   Fügen Sie das Ziel-Embedding dem ursprünglichen Embedding e_o hinzu
*   **T:** Trigger-Set
*   **S:** Satz
*   **m:** maximale Trigger-Anzahl
*   **(a) Wasserzeichen-Injektion**
*   **D_c:** Kopierter Datensatz
*   **Stealer** (Stehler / Datendieb)
*   **Anbieter-Modell**
*   **Trigger-Set**
*   **Trigger-Anzahl**
*   **Backdoor-Gewicht**
*   **Anbieter-EaaS** (Embedding as a Service)
*   **Original-Embedding**
*   **Ziel-Embedding**
*   **Bereitgestelltes Embedding**
*   **E_c:** Embedding

**Gesprochener Text:**

"Das bereitgestellte Embedding ist eine gewichtete Summe des Ziel-Embeddings und des ursprünglichen Embeddings."</sample>
    <sample id="1484">Das Gewicht des Ziel-Embeddings ist proportional zur Anzahl der Trigger im Satz. Wenn die Anzahl der Trigger im Satz größer als M ist, ist das bereitgestellte Embedding exakt gleich dem Ziel-Embedding.</sample>
    <sample id="1485">Hier ist der Inhalt der Folie auf Deutsch übersetzt:

**EmbMarker**

*   **Urheberrechtsüberprüfung**
    *   Einen Backdoor- und harmlosen Datensatz erstellen
        *   $D_b = \{w_1, w_2, ..., w_m | w_i \in T\}$,
        *   $D_n = \{w_1, w_2, ..., w_m | w_i \notin T\}$.
    *   Embeddings vom Dienst des Diebes mit den Datensätzen anfordern

---
**Beschriftungen im Diagramm:**

*   **provider:** Anbieter
*   **trigger set:** Trigger-Set (oder Auslöse-Set)
*   **Db + Dn:** (bleibt gleich)
*   **backdoor and benign dataset:** Backdoor- und harmloser Datensatz
*   **verify extracted?:** Extraktion verifizieren? (oder Wurde extrahiert überprüfen?)
*   **target embedding:** Ziel-Embedding
*   **Eb + En:** (bleibt gleich)
*   **extracted model:** Extrahiertes Modell
*   **train:** Trainieren
*   **corpus:** Korpus
*   **embeddings:** Embeddings
*   **stealer:** Dieb</sample>
    <sample id="1486">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**EmbMarker**

*   **Urheberrechtsverifizierung**
    *   Konstruiere einen Backdoor- und einen harmlosen Datensatz
        *   D_b = {w1, w2, ..., wm || wi ∈ T} (Backdoor-Datensatz: alle Wörter gehören zum Trigger-Set T)
        *   D_n = {w1, w2, ..., wm || wi ∉ T} (Harmloser Datensatz: keine Wörter gehören zum Trigger-Set T)
    *   Fordere Embeddings vom Dienst des Diebes mit den Datensätzen an

**Diagramm:**

*   **provider** (Anbieter)
    *   trigger set T (Trigger-Set T)
    *   Db + Dn (Backdoor- und harmloser Datensatz)
    *   Eb + En (Ziel-Embeddings und sonstige Embeddings)
    *   target embedding (Ziel-Embedding)
    *   verify extracted? (Extrahiert verifizieren?)
*   **stealer** (Dieb)
    *   extracted model (Extrahiertes Modell)
    *   train (trainieren)
    *   Dc (Korpus)
    *   Ec (Embeddings)</sample>
    <sample id="1487">Gerne, hier ist der übersetzte Inhalt:
**EmbMarker**

*   **Urheberrechtsverifizierung**
    *   Konstruiere einen Backdoor- und benignen Datensatz
        *   D_b = {w_1, w_2, ..., w_m | w_i ∈ T}
        *   D_n = {w_1, w_2, ..., w_m | w_i ∉ T}
    *   Fordere Embeddings vom Dienst des Stealers mit den Datensätzen an

[Visualisierung einer Grafik, die den Prozess von Anbieter und Stealer darstellt]

Dann fordert der Anbieter Embeddings vom Dienst des Stealers mit den Datensätzen an.</sample>
    <sample id="1488">EmbMarker

*   Urheberrechtsprüfung
    *   Berechnung der Ähnlichkeit zum Ziel-Embedding
    *   Die Kosinus- und L2-Ähnlichkeit zwischen dem angeforderten Embedding und dem Ziel-Embedding werden berechnet.
    *   Berechnung von Metriken (Ähnlichkeitsdifferenz und p-Wert des KS-Tests)
    *   Wir berechnen die Ähnlichkeitsdifferenz zwischen dem benignen und dem Backdoor-Datensatz,
    *   welche als Delta-Kosinus und Delta-L2 definiert ist.</sample>
    <sample id="1489">Hier ist der Inhalt der Folie ins Deutsche übersetzt:

**EmbMarker**

*   **Urheberrechtsverifizierung**
    *   Berechnen Sie ihre Ähnlichkeit zum Ziel-Embedding

    $cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{\left \| \mathbf{e}_i \right \| \left \| \mathbf{e}_t \right \|}, \quad l_{2i} = \left \| \frac{\mathbf{e}_i}{\left \| \mathbf{e}_i \right \|} - \frac{\mathbf{e}_t}{\left \| \mathbf{e}_t \right \|} \right \|^2,$

    $C_b = \{cos_i | i \in D_b \}, C_n = \{cos_i | i \in D_n \},$

    $L_b = \{l_{2i} | i \in D_b \}, L_n = \{l_{2i} | i \in D_n \}.$

    *   Berechnung von Metriken (Ähnlichkeitsdifferenz und p-Wert des KS-Tests)

    $\Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,$

    $\Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.$</sample>
    <sample id="1490">**Folieninhalt:**

**Experimentelle Ergebnisse**

*   **Kopierdatensatz:** AG News, MIND, SST2, Enron Spam
*   **Generischer Datensatz des Anbieters:** WikiText
*   **Metriken**
    *   Leistung bei nachgelagerten Aufgaben: ACC
    *   Erkennungsleistung: Δ_cos, Δ_l2, p-Wert
*   **Einstellung**
    *   m = 20, n = 4, Frequenzintervall = [0.005, 0.01]

| Datensatz    | #Stichproben | #Klassen | Durchschn. Länge |
| :----------- | :----------- | :------- | :--------------- |
| SST2         | 68,221       | 2        | 54.17            |
| MIND         | 130,383      | 18       | 66.14            |
| Enron Spam   | 33,716       | 2        | 34.57            |
| AG News      | 127,600      | 4        | 236.41           |

---

**Gesprochener Inhalt:**

Wir führen Experimente an vier Datensätzen durch. AG News, MIND, SST2 und Enron Spam. Wir gehen davon aus, dass der Anbieter den WikiText-Datensatz verwendet, um Worthäufigkeiten zu zählen.</sample>
    <sample id="1491">Die Ergebnisse auf vier Datensätzen zeigen, dass unser Embedding-Marker eine hervorragende Detektionsleistung erzielen kann und gleichzeitig einen hohen Nutzen für nachgelagerte Aufgaben beibehält.</sample>
    <sample id="1492">Wir haben auch die Verborgenheit des bereitgestellten Embeddings validiert, indem wir das Embedding von Sätzen auf vier Datensätzen mittels PCA visualisiert haben. Die Legende der Abbildungen gibt die Anzahl der Trigger in jedem Satz an.</sample>
    <sample id="1493">Wie in den Abbildungen dargestellt, ist es schwer, zwischen den Hintertür-Embeddings und den normalen Embeddings zu unterscheiden.</sample>
    <sample id="1494">Das ist alles, danke schön. Gerne zur Diskussion mit uns.
Auf dem Bildschirm steht: Danke!</sample>
    <sample id="1495">ABC-Eval steht für "Annotating Behaviors in Chat".</sample>
    <sample id="1496">Bis 2020.</sample>
    <sample id="1497">Hallo, mein Name ist Vasudha und ich bin Doktorandin der Informatik an der Stony Brook University. Ich möchte unsere Arbeit vorstellen, die als langer Beitrag auf der ACL 2023 angenommen wurde: "Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge".

Das ist ein Vortrag von Vasudha Varadarajan, Swanie Juhng, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Luhmann &amp; H. Andrew Schwartz.
Von der Stony Brook University, Human Language Analysis Beings.
*präsentierender</sample>
    <sample id="1498">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Was ist kognitive Dissonanz?**

„zwei Elemente der Kognition (d.h. Gedanken, Handlungen, Überzeugungen), die inkonsistent sind“
(Harmon-Jones und Harmon-Jones, 2007)

Eddie Harmon-Jones und Cindy Harmon-Jones. 2007. Kognitive Dissonanztheorie nach 50 Jahren Entwicklung. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1499">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Was ist Kognitive Dissonanz?**

„zwei Elemente der Kognition (d.h. Gedanken, Handlungen, Überzeugungen), die inkonsistent sind“
(Harmon-Jones und Harmon-Jones, 2007)

*   **Ich weiß, dass Zigaretten mich töten könnten.** -&gt; **Überzeugung**
*   **Ich habe heute nach dem Treffen ein paar Zigaretten geraucht.** -&gt; **Handlung**

Beide führen zu **Dissonanz**

---
**Gesprochener Text:**

„wie dieses Beispiel, wo eine Person feststellt: Ich weiß, dass Zigaretten mich töten könnten. Und dann weiter sagt: Ich habe heute nach dem Treffen ein paar Zigaretten geraucht. Diese Überzeugung und Handlung sind inkonsistent, und sie befinden sich in Dissonanz.“</sample>
    <sample id="1500">Hier ist der englische Inhalt ins Deutsche übersetzt:

**Visueller Inhalt (Folie):**

**Was ist kognitive Dissonanz?**
„zwei Elemente der Kognition (d.h. Gedanken, Handlungen, Überzeugungen), die inkonsistent sind“
„Ausgedrückt in Sprache als eine Beziehung zwischen zwei Phrasen/Aussagen eines Benutzers“

**Beispielbox:**
*Kopf mit Sprechblasen*
seq 1: Ich weiß, dass Zigaretten mich töten könnten. (belief -&gt; Überzeugung)
seq 2: Ich habe mir heute nach dem Meeting ein paar Zigaretten geraucht. (action -&gt; Handlung)
seq 3: Ich glaube nicht, dass ich meinen Job ohne sie behalten könnte. (belief -&gt; Überzeugung)

*Rechte Boxen:*
Dissonanz
Konsonanz/Erklärung

*Fußnote:*
Eddie Harmon-Jones und Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716.

**Gesprochener Inhalt:**

"weiter erwähnend, dass ich meinen Job ohne sie nicht behalten könnte,"
"rechtfertigt das zweite Vorkommen,"
"und sie haben eine Konsonanzbeziehung."</sample>
    <sample id="1501">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Was ist kognitive Dissonanz?**

„zwei Elemente der Kognition (d.h. Gedanken, Handlungen, Überzeugungen), die inkonsistent sind“
In der Sprache als Beziehung zwischen zwei Phrasen/Aussagen eines Benutzers ausgedrückt
Relativ selten in der Sprache zu finden, verglichen mit anderen Diskursbeziehungen

*   **seq 1:** Ich weiß, dass Zigaretten mich töten könnten. -&gt; Überzeugung -&gt; Dissonanz
*   **seq 2:** Ich habe nach dem heutigen Treffen ein paar Zigaretten geraucht. -&gt; Handlung -&gt; Konsonanz/Erklärung
*   **seq 3:** Ich glaube nicht, dass ich meinen Job ohne sie behalten könnte. -&gt; Überzeugung

*(Die Quellenangabe und die Seitenzahl bleiben unverändert, da es sich um einen akademischen Verweis handelt.)*</sample>
    <sample id="1502">**Gesprochener Text:**
Also, warum ist das wichtig? Die Untersuchung der kognitiven Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen zu verstehen, Trends bei Überzeugungen, Werten und Einstellungsänderungen in der Bevölkerung zu verfolgen.

**Text auf der Folie:**
Warum Dissonanz?
Auswirkungen von Meinungsverschiedenheiten
Einstellungen und Überzeugungstrends
Eddie Harmon-Jones und Judson Mills. 2019. Eine Einführung in die Theorie der kognitiven Dissonanz und ein Überblick über aktuelle Perspektiven auf die Theorie. Kognitive Dissonanz: Eine Neubetrachtung einer zentralen Theorie in der Psychologie.
6</sample>
    <sample id="1503">Hohe kognitive Dissonanz hängt auch mit Angststörungen zusammen und kann helfen, die psychische Gesundheit der Menschen besser zu verstehen.</sample>
    <sample id="1504">Hier ist der englische Inhalt ins Deutsche übersetzt:

**Warum Dissonanz?**

*   **Auswirkungen von Uneinigkeit**
*   **Einstieg und Ausstieg aus dem Extremismus**
*   **Einstellungen und Überzeugungstrends**
*   **Angststörungen**

---

*   Eddie Harmon-Jones und Judson Mills. 2019. Eine Einführung in die Theorie der kognitiven Dissonanz und ein Überblick über aktuelle Perspektiven der Theorie. Kognitive Dissonanz: Eine Neubewertung einer zentralen Theorie in der Psychologie.
*   Swanie Jürling, Matthew Mctere, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, und H Andrew Schwartz. 2023. Repräsentationen auf Diskursebene können die Vorhersage des Angstgrades verbessern. In 9 Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="1505">00:00
Schließlich ist die kognitive Dissonanz wichtig, um persönliche kognitive Stile von Individuen zu verstehen und uns zu helfen, Entscheidungsprozesse besser zu verstehen.</sample>
    <sample id="1506">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Im Bild:**

*   **Annotations** -&gt; **Annotationen**
*   **Step 1: Good parsing quality?** -&gt; **Schritt 1: Gute Parsing-Qualität?**
    *   **No** -&gt; **Nein**
    *   **Yes** -&gt; **Ja**
*   **Step 2: Dissonance?** -&gt; **Schritt 2: Dissonanz?**
    *   **No** -&gt; **Nein**
    *   **Yes** -&gt; **Ja**
*   **Step 3: Consonance?** -&gt; **Schritt 3: Konsonanz?**
    *   **No** -&gt; **Nein**
    *   **Yes** -&gt; **Ja**
*   **Dissonance ~3.5%** -&gt; **Dissonanz ~3,5%**
*   **Consonance ~48%** -&gt; **Konsonanz ~48%**
*   **Neither ~48%** -&gt; **Weder noch ~48%**
*   **User @user_handle** -&gt; **Benutzer @user_handle**
*   **Wish I could hold grudges but I guess it's a good thing that I can't at the same time.** -&gt; **Ich wünschte, ich könnte Groll hegen, aber ich glaube, es ist gut, dass ich es gleichzeitig nicht kann.**
    *   (Pink hervorgehoben: **Ich wünschte, ich könnte Groll hegen**)
    *   (Türkis hervorgehoben: **ich es gleichzeitig nicht kann**)
*   **PARSE** -&gt; **PARSEN**
*   **ANNOTATE** -&gt; **ANNOTIEREN**
*   **Dissonance** (Ergebnis) -&gt; **Dissonanz**
*   *** Check paper for detailed annotation guidelines** -&gt; *** Im Paper finden Sie detaillierte Annotationsrichtlinien.**

**Gesprochener Text:**

"Um eine Ressource für kognitive Dissonanz zu schaffen, führten wir eine groß angelegte Annotation von Dissonanzbeziehungen durch. Wir verwendeten einen 'Dissonanz-zuerst'-Ansatz, wie hier im Flussdiagramm dargestellt."</sample>
    <sample id="1507">Hier ist der deutsche Inhalt des Bildes:

**Annotationen**

*

**Schritt 1: Gute Parsing-Qualität?**
*   Ja / Nein

**Schritt 2: Dissonanz?**
*   Ja / Nein

**Schritt 3: Konsonanz?**
*   Ja / Nein

**Dissonanz** (~3,5%)
**Konsonanz** (~48%)
**Keines von beiden** (~48%)

[Twitter-Logo]
**PARSEN**

[Benutzerprofilbild]
**Nutzer**
@user_handle

"Ich wünschte, ich könnte Groll hegen, aber ich schätze, es ist gut, dass ich es gleichzeitig nicht kann."

**ANNOTIEREN**

**Dissonanz**

* Siehe Paper für detaillierte Annotationsrichtlinien

11</sample>
    <sample id="1508">Wie hier zu sehen ist, wurde Dissonanz nur in 3,5 % der annotierten...</sample>
    <sample id="1509">Hier ist die Übersetzung des gesamten Inhalts (Text auf der Folie und gesprochener Text) ins Deutsche:

---

**Text auf der Folie:**

*   **Titel:** Training an einem initialen annotierten Datensatz
*   **Rosa Kasten:** RoBERTA-base + Klassifikationskopf
*   **Pfeilbeschriftung:** TRAIN
*   **"init dataset" (unter dem rosa Kasten):** initialer Datensatz
*   **Sprechblase:**
    *   Kleiner annotierter Datensatz:
    *   43/901 Dissonanzen;
    *   nicht besser als der Zufall
*   **X-Achsenbeschriftung:** Fläche unter der ROC-Kurve (AUC)

---

**Gesprochener Text:**

"Nachdem wir etwa tausend Beispiele von Diskurs-Einheiten-Paaren gesammelt hatten, führten wir ein Training für einen initialen Klassifikator durch, der jedoch nur mit 43 Beispielen von Dissonanz trainiert wurde. Wenig überraschend schnitt der Klassifikator kaum besser als der Zufall ab."</sample>
    <sample id="1510">Angesichts des seltenen Auftretens von Dissonanz und des Fehlens eines solchen Datensatzes zuvor stehen wir vor dem Problem der absoluten Seltenheit.

**Bildinhalt:**

*   **Titel:** Training auf dem initialen annotierten Datensatz
*   **Linkes Feld:** RoBERTA-Basis + Klassifikator-Kopf
*   **Pfeiltext:** TRAINIEREN
*   **Unteres Feld:** initialer Datensatz
*   **Sprechblase:** Kleiner annotierter Datensatz: 43/901 Dissonanzen; nicht besser als der Zufall
*   **X-Achsen-Beschriftung:** Fläche unter der ROC-Kurve (AUC)
*   **Name:** Vasudha Varadarajan
*   **Foliennummer:** 12</sample>
    <sample id="1511">Um dies zu mildern, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen, um so zu annotieren, dass mehr seltene Stichproben über weniger Annotationsrunden gesammelt werden können, wodurch die gesamten Annotationskosten gesenkt und gleichzeitig die Erkennung seltener Klassen verbessert wird.</sample>
    <sample id="1512">Da das ursprüngliche Modell die Dissonanzklasse überhaupt nicht erfassen konnte, starten wir den aktiven Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen.</sample>
    <sample id="1513">Hier ist die deutsche Übersetzung des englischen Inhalts:

**Folienüberschrift:** Kaltstart-Annotationen: Transferlernen

**Linke Box:** RoBERTA-Basis + Klassifikationskopf

**Grafikbeschriftungen:**
*   TRAINIEREN
*   Anfangsdatensatz
*   Debatte
*   $ (Bezieht sich auf die Aufgabe "CE")
*   CE
*   Debatte;CE
*   Fläche unter der ROC-Kurve (AUC)

**Rechte Sprechblase:** Übertragene Gewichte nach dem Training auf kombinierten Debatten- und CE-Daten

**Legende unten rechts:**
*   **Debatte:** Dissonante Haltung in Debattenforen: Vasudha Varadarajan, Nikita Soni, Weixa Wang, Christian Luhmann, H. Andrew Schwartz und Naoya Inoue. 2022. Erkennung dissonanter Haltung in sozialen Medien: Die Rolle der Themenexposition. In Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS), Association for Computational Linguistics.
*   **$CE:** Vergleichs- und Erweiterungsklassen: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livia Robaldo, Aravind Joshi und Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC-08).

**Seitenzahl:** 15

**Gesprochener Text:**
"Wir übertragen von zwei verschiedenen Aufgaben. Themenunabhängige Klassifizierung dissonanter Standpunkte, eine Aufgabe, die feststellt, ob zwei Debattenaussagen von verschiedenen Personen übereinstimmen oder nicht übereinstimmen, unabhängig vom Thema."</sample>
    <sample id="1514">Hier ist die Übersetzung des englischen Inhalts der Folie und des gesprochenen Textes ins Deutsche:

**Titel der Folie:**
Kaltstart-Annotationen: Transferlernen

**Linke Box:**
RoBERTA-base + Klassifikationskopf

**Beschriftung der Grafik:**
*   TRAIN (Training)
*   init dataset (Initialer Datensatz)
*   Debate (Debatte)
*   CE (Vergleich und Erweiterung)
*   Debate;CE (Debatte;CE)
*   Area under the ROC curve (AUC) (Fläche unter der ROC-Kurve (AUC))

**Rechte Sprechblase:**
Übertragene Gewichte nach dem Training an kombinierten Debatte- und CE-Daten

**Fußnoten:**
*   **Debatte:** Dissonante Haltung in Debattenforen; [Der Rest der Zitation bleibt auf Englisch, da es sich um eine Referenz handelt.]
    *   *Sprecherin (im Kontext des Satzes):* "...hier Debatte genannt,"
*   **CE:** Vergleichs- und Expansionsklassen; [Der Rest der Zitation bleibt auf Englisch, da es sich um eine Referenz handelt.]
    *   *Sprecherin (im Kontext des Satzes):* "und bei der binären Klassifikation von Expansions- und Vergleichsklassen des PDTB. Da diese beiden eng mit der Konzeption von Konsonanzen und Dissonanzen zusammenhängen, und wir nennen sie hier CE."</sample>
    <sample id="1515">Wir stellen fest, dass bei der Übertragung die Zero-Shot-Leistung auf dem annotierten Datensatz bereits viel besser ist als der Zufall, mit dem besten AUC von 0,62.</sample>
    <sample id="1516">Beim iterativen Fein-Tuning auf beiden Aufgaben stellen wir fest, dass das Fein-Tuning der CE-Aufgabe, gefolgt von einem weiteren Fein-Tuning bei Debate, zu einer wesentlich besseren Zero-Shot-Leistung führt. Daher ist dies das Modell, das wir verwenden, um das aktive Lernen kaltzustarten.</sample>
    <sample id="1517">Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren. Die kumulative Methode sammelt alle Daten, die bisher durch aktive Annotation gesammelt wurden, wohingegen die iterative Methode das Modell aktualisiert, indem sie auf dem neuesten Satz gesammelter Daten trainiert wird.</sample>
    <sample id="1518">Über die verschiedenen Strategien hinweg stellten wir fest, dass die kumulative Methode durchweg gleich gut oder besser abschnitt als die iterative.</sample>
    <sample id="1519">Als Nächstes verwenden wir, um die Anzahl dissonanter Beispiele zu verbessern, eine Strategie der Wahrscheinlichkeit seltener Klassen (PRC), um hauptsächlich jene Beispiele auszuwählen, die vom aktuellen Modell in jeder Runde des Aktiven Lernens mit hoher Wahrscheinlichkeit dissonant sind.</sample>
    <sample id="1520">Hier ist die deutsche Übersetzung des Inhalts:

**Vom Bild (Text auf den Folien):**

*   **Titel:** Aktives Lernen: Strategie der Wahrscheinlichkeit seltener Klassen
*   **Obere Box:** Annotation seltener Klassen ~ „Nadel im Heuhaufen“
    *   **Links:** Schwierig zu annotieren
    *   **Rechts:** Leichter zu annotieren
    *   **Pfeiltext:** Erhöht die Chance auf eine seltene Klasse?
*   **Flowchart (rechts):**
    *   **Akquisitionsstrategie:** Welche sind „am besten“ zu beschriften?
    *   **Pfeil von Akquisitionsstrategie:** neue Beispiele
    *   **Box:** Menschen annotieren
    *   **Box:** Neue Beispiele hinzufügen
    *   **Box:** Modell neu trainieren/aktualisieren
    *   **Pfeilbeschriftung:** Aktives Lern-Iteration
*   **Unterer linker Kasten (Modelltrainingsfluss):**
    *   **START**
    *   **Box:** Initiales Modell: Transferlernen
    *   **Labels:** neu / alte Daten
    *   **Pfeilbeschriftung:** trainieren
    *   **Labels:** neues Modell / Modell / altes Modell
    *   **Box Titel:** Kumulativ (CM)
    *   **Pfeilbeschriftung:** Feinabstimmung
    *   **Box Titel:** Iterativ (IT)
*   **Sprecherin:** Vasudha Varadarajan
*   **Seitenzahl:** 19

**Vom gesprochenen Inhalt:**

"Wir vergleichen dies mit den anderen State-of-the-Art AL-Strategien, die in der Community üblicherweise verwendet werden."</sample>
    <sample id="1521">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Auf der Folie:**

*   **Titel:** Aktives Lernen: Wahrscheinlichkeitsstrategie seltener Klassen
*   **Diagrammtitel:** Vergleich von Active Learning Strategien (AUCs)
*   **Basislinie: from scratch:** Basislinie: von Grund auf neu
*   **Transferred model:** Übertragenes Modell
*   **AL-Random:** AL-Zufall
*   **AL-Entropy:** AL-Entropie
*   **AL-CoreSet:** AL-CoreSet
*   **AL-CAL:** AL-CAL
*   **AL-PRC (ours):** AL-PRC (unser)

**Gesprochener Text:**

„Wir stellen fest, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere State-of-the-Art-Strategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung für die zufällige [Auswahl / Strategie] signifikant niedriger ist..."</sample>
    <sample id="1522">Bei weiteren Runden von AL mit den zwei besten Strategien verbesserten wir die Distanzklassifikations-AUC auf 0,75, was die bisher beste Leistung ist, die wir bei dieser Aufgabe erzielt haben.</sample>
    <sample id="1523">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

**Aktives Lernen: Strategie der Wahrscheinlichkeit seltener Klassen**

**Eigenschaften von aktiven Lernstrategien**

| | Seltene % | Zeit (s) | Subj. Schwier. |
| :-------- | :------- | :------- | :----------- |
| RANDOM | 3.20 | 11.96 | -0.065 |
| ENTROPY | 6.80 | 12.78 | 0.035 |
| CORESET | 6.00 | 11.89 | 0.039 |
| CAL | 4.80 | 11.88 | -0.045 |
| PRC | 7.60 | 13.55 | 0.071 |

*   Minimale Annotationskosten führen nicht unbedingt zu besseren Modellen.
*   Seltenheit könnte die Annotationen erschweren: kognitive Dissonanz ist eine solche Klasse.
*   Zur Erhöhung der Dissonanz-Samples funktioniert PRC am besten.</sample>
    <sample id="1524">Hier ist der Inhalt sowohl des Bildes als auch der gesprochenen Zusammenfassung auf Deutsch:

**Wichtige Erkenntnisse**

*   **Oben:**
    *   Annotation seltener Klassen ~ „Nadel im Heuhaufen“
    *   PRC ist einfach und effizient für die Akquise seltener Stichproben

*   **Unten links:**
    *   Kaltstart AL mit Transferlernen

*   **Unten Mitte:**
    *   Domänenfremd: Iterativ (M₀ → M₁ → M₂ → M₃)

*   **Unten rechts:**
    *   Domänenintern: Kumulativ (M₀ verzweigt sich zu M₁, M₂, M₃)

---

**Gesprochene Zusammenfassung (00:00-00:10):**

"Zusammenfassend stellen wir fest, dass PRC eine einfache AL-Strategie für die Akquise seltener Klassen ist und der Kaltstart von AL mit entsprechend konzipierten Transferlernen-Aufgaben erheblich helfen kann."</sample>
    <sample id="1525">Wir stellen auch fest, dass eine iterative Aktualisierung für das Transferlernen aus einer anderen Domäne nützlich ist, während domäneninterne aktive Annotationen von einer kumulativen Aktualisierung profitieren.</sample>
    <sample id="1526">Hier ist die Übersetzung des Inhalts:

**Gesprochener Text:**
„Dies sind die Links zu unserem Code, unserem Datensatz und unserem Paper. Äh, zögern Sie nicht, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank!“

**Text auf den Folien:**

**Folie 1:**
*   **Titel:** „Transfer- und Active Learning für Dissonanz-Erkennung: Bewältigung der Seltene-Klassen-Herausforderung“
*   **Kontakt:** „Kontakt: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu“
*   **Labels für QR-Codes:** „Code:“, „Datensatz:“, „Paper:“
*   **URLs unter den QR-Codes:**
    *   „https://github.com/humanlab/rare-class-AL“
    *   „https://github.com/humanlab/dissonance-twitter-dataset“
    *   „https://arxiv.org/abs/2305.02459“
*   **Seitenangabe:** „25“
*   **Sprechername:** „Vasudha Varadarajan“

**Folie 2:**
*   **Text:** „Vielen Dank!“
*   **Seitenangabe:** „26“</sample>
    <sample id="1527">Die Autoren gehören zur University of Edinburgh, Saarland University und University of Amsterdam.</sample>
    <sample id="1528">Der/Die Referent*in heißt Si Yuan (Siyu Yuan).</sample>
    <sample id="1529">5 Autoren.</sample>
    <sample id="1530">Der Ansatz wird mit CAAT verglichen.</sample>
  </task>
</testset>