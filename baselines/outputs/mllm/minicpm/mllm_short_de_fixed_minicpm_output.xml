<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="de">
    <sample id="0">The most important information highlighted in the presentation is that language models are trained on large-scale web-crawled data, which includes well-covered political news media. This training process has created a mixed blessing for language model applications as it allows them to learn from diverse perspectives but also introduces inherent social and politically biased content into their responses.</sample>
    <sample id="1">The authors belong to McGill University, Mila, and Microsoft Research.</sample>
    <sample id="2">Das Bild zeigt eine Präsentation eines Forschungsprojekts namens DEPLAIN. Der Titel lautet "DEPLAIN: Ein deutscher Parallel-Korpus mit Innereinzelübersetzungen in einfachen Sprachen für Satz- und Dokument-Simplifizierung". Die Präsentation wurde von Regina Stodden, Omar Momen und Laura Kallmeyer von der Heinrich Heine Universität Düsseldorf in Deutschland für ACL 2023 gehalten. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm zu sehen, auf dem eine Person zu sprechen scheint.</sample>
    <sample id="3">Das Bild zeigt eine Präsentationsaufnahme mit dem Titel 'DEPLAIN: Ein deutscher Parallel-Korpus mit interlingualen Übersetzungen in einfachen Sprachen für Satz- und Dokumenteinfachstellung'. Der Titel wird von der Namenliste der Autoren 'Regina Stodden, Omar Momen, Laura Kallmeyer' und der Institution 'Heinrich Heine Universität Düsseldorf, Deutschland' begleitet. Darunter steht 'ACL 2023', was auf die Veranstaltung hinweist. Im oberen rechten Eck ist ein kleiner Bildschirm eines Menschen zu sehen, der wahrscheinlich das Vortrag verlässt. Im Hintergrund des Vortrags erscheint ein Text, der lautet: '1. Textsimplifizierung - Was, warum und wie?'. Diese Slide scheint das erste Thema der Präsentation zu sein, das sich mit der Definition und dem Zweck der Textsimplifizierung beschäftigt.</sample>
    <sample id="4">Text simplification is a process of adapting a text to improve the text comprehension of it for a specific target group, as people with reading problems or non-native speakers.</sample>
    <sample id="5">Das Bild zeigt eine Übersetzung eines englischen Textes ins Deutsche. Der englische Text lautet: 'To train a text simplification model, we require parallel pairs of text.' Die Übersetzung ins Deutsche lautet: 'Um ein Textsimplifizierungsmodell zu trainieren, benötigen wir Paare von Texten in Parallel.' Diese Übersetzung verdeutlicht die Bedeutung von parallelisierten Textpaaren für das Training eines Textsimplifizierungsmodells.</sample>
    <sample id="6">Das Original ist 'Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden.' Der plain language ist 'Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne oder mehr Urlaub ein.'</sample>
    <sample id="7">Das Bild zeigt eine Präsentation über die Textsimplifizierung. Im oberen Teil des Bildes befindet sich ein blauer Banner mit dem Titel 'Text Simplification Example'. Darunter ist ein Diagramm zu sehen, das verschiedene Techniken zur Textsimplifizierung demonstriert. Diese Techniken umfassen Substitution, Clause Deletion, Reordering und Word Deletion. Links am Diagramm steht der Text 'Original:', und rechts steht 'Plain Language:'. Das Diagramm zeigt, wie die Originaltexte durch diese Techniken zu einem einfacheren Text simplifiziert werden können. Im Hintergrund ist ein kleiner Bildschirm zu sehen, auf dem jemand zu sprechen scheint.</sample>
    <sample id="8">Das Bild zeigt eine Präsentation über 'German Text Simplification Corpora'. Es gibt einen Titel auf der oberen rechten Seite, der 'German Text Simplification Corpora' liest. Im Hintergrund ist ein Diagramm mit verschiedenen Abschnitten und Zahlen zu sehen. Die Schriftart und -größe des Textes sind klar sichtbar, und es gibt keine erkennbaren Anzeichen von Bewegung oder Veränderungen im Bild.</sample>
    <sample id="9">Das Bild zeigt eine Präsentation über "German Text Simplification Corpora" auf einem Computerbildschirm. Der Titel der Präsentation ist in einem blauen Balken angezeigt, und darunter befindet sich ein Diagramm mit dem Titel "Sentence Level". Das Diagramm zeigt verschiedene Modelle und ihre Leistungen an, wobei die Y-Achse die Leistung an Prozentsätzen und die X-Achse die verschiedenen Modelle angibt. Die Modelle sind in verschiedenen Farben dargestellt, und einige der Modelle werden mit Zahlen und Texten wie "483", "756" und "1109" versehen. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm eines Menschen zu sehen, der wahrscheinlich die Präsentation gibt.</sample>
    <sample id="10">Das Bild zeigt eine Präsentation mit dem Titel 'German Text Simplification Corpora'. Es gibt ein Diagramm, das die Sätze auf verschiedenen Niveauebenen zeigt. Links am Diagramm sind einige Schlagwörter aufgeführt, wie 'Domestic', 'health', 'education', 'economy', 'politics' und 'public affairs'. Rechts am Diagramm sind Zahlen angegeben, wie 13122, 483 und 756. Im oberen rechten Eck des Bildes ist ein kleiner Bild von einer Person zu sehen.</sample>
    <sample id="11">Das Bild zeigt eine Präsentation über "German Text Simplification Corpora" (deutsche Textsimplifizierungs-Korpora). Im oberen Teil des Bildes befindet sich ein blauer Balken mit dem Titel "German Text Simplification Corpora". Darunter ist ein Diagramm mit der Aufschrift "Sentence Level", das verschiedene Datenpunkte und Zahlen zeigt. Links am Diagramm sind verschiedene Farben und Legenden, die auf verschiedene Arten von Dokumenten hinweisen, wie z.B. "Domestische", "Medizinische", "Rechtliche", "Öffentliche", "Wissenschaftliche" und "Allgemeine". Die Y-Achse des Diagramms zeigt eine Skala von 0 bis 14000, und die X-Achse zeigt verschiedene Zeitenpunkte, wie zum Beispiel "2009-2013", "2013-2017" und "2017-2021". Rechts am Diagramm sind zwei große Zahlen sichtbar: "756" und "483". Im unteren rechten Eck des Diagramms ist ein weiterer Text zu lesen, der lautet: "parallel sentence pairs".</sample>
    <sample id="12">Das Bild zeigt eine Präsentation über 'German Text Simplification Corpora'. Der Titel ist in einem blauen Balken angezeigt. Im Hintergrund befindet sich ein Diagramm, das die 'Sentence Level' darstellt und verschiedene Datenpunkte anzeigt, wie zum Beispiel 13122 und 756. Die Farben im Diagramm sind grün, blau, lila, gelb und orange. Links am Diagramm sind verschiedene Kategorien aufgeführt, wie 'Domestic', 'health', 'education', 'economy', 'politics', 'public affairs' und 'miscellaneous'. Im oberen rechten Eck des Bildes ist eine Person zu sehen, die wahrscheinlich die Präsentation gibt.</sample>
    <sample id="13">Das Bild zeigt eine Präsentation mit einem Titel, der laut 'German Text Simplification Corpora' ist. Im Hintergrund sind Graphen zu sehen, die Informationen über die Simplifizierung von deutscher Sprache auf dem Satzlevel bereitstellen. Die Graphen zeigen verschiedene Zahlen und Kategorien, wie zum Beispiel die Anzahl von 'Domestic', 'Foreign', 'Health', 'Education', 'Public affairs' und 'Miscellaneous' Sätze. Darüber hinaus sind Zahlen wie 250, 1118, 9466, 10296, 5942 und 756 zu sehen, die möglicherweise die Anzahl von Satzen oder andere relevante Daten anzeigen. Links am Bildrand ist ein kleiner Text zu lesen, der möglicherweise weitere Details über die Präsentation enthält.</sample>
    <sample id="14">Das Bild zeigt eine Präsentation mit zwei Hauptbereichen: 'Types of Simplification' und 'Simplification Transformations'. Im Bereich 'Types of Simplification' sind vier Arten von Simplifikationen (News, Bible, L2, Fiction) mit ihren jeweiligen Gruppenanzahlen (n) und Simplifikationsarten (Simplicity, LexSimp, StructSimp) dargestellt. Im Bereich 'Simplification Transformations' werden verschiedene Transformationen (moving, engineering, lexical substitution, word deletion, word insertion) durch zwei verschiedene Methoden (DEplain-apa, DEplain-web) dargestellt. Rechts oben befindet sich ein kleiner Bildschirm mit einem Menschen, der die Präsentation führt.</sample>
    <sample id="15">Das Bild zeigt zwei Graphiken, die verschiedene Arten von Einfachheitsverfahren und ihre Veränderungen darstellen. Die linke Seite zeigt eine Kategorie unter dem Titel 'Arten der Einfachheit', wobei verschiedene Typen wie 'News', 'Bible', 'L2' und 'Fiction' dargestellt werden. Jede Kategorie hat drei Balken in verschiedenen Farben (Blau, Orange und Gelb), die wahrscheinlich verschiedene Arten von Einfachheit darstellen. Die rechte Seite zeigt eine Kategorie unter dem Titel 'Einfachheitsveränderungen', wobei verschiedene Arten wie 'bewegend', 'engineering', 'linguistisch', 'abstrakt', 'verb', 'adjectiv' und 'dichten' dargestellt werden. Jede Art hat zwei Balken in verschiedenen Farben (Blau und Orange), die wahrscheinlich verschiedene Implementierungen oder Variante der Einfachheit darstellen. Im Hintergrund ist ein kleiner Bildschirm mit einer Person zu sehen.</sample>
    <sample id="16">Auf allen Ebenen, zum Beispiel bei der 'Lexikal-Simplification' und der 'Struktur-Simplification',</sample>
    <sample id="17">Das Bild zeigt eine Präsentation mit zwei Diagrammen. Links ist ein Diagramm unter dem Titel "Types of Simplification" zu sehen, das verschiedene Arten von Einfachheitsverfahren für die Kategorisierung von Texten nach verschiedenen Quellen (news, bible, L2, fiction) darstellt. Rechts befindet sich ein weiteres Diagramm unter dem Titel "Simplification Transformations", das verschiedene Einfachheitsveränderungen zwischen zwei Corpora (DEplain-apa und DEplain-web) zeigt. Im Hintergrund ist ein kleiner Bildschirm mit einer Person zu sehen, die wahrscheinlich die Präsentation gibt.</sample>
    <sample id="18">Im Gegensatz dazu haben wir im Webcorpus viel mehr Wiedergabe.</sample>
    <sample id="19">Das Bild zeigt eine Präsentation, die sich auf 'Automatic alignment and simplification' konzentriert. Im oberen rechten Eck ist ein kleiner Bildschirm eines Menschen zu sehen, der wahrscheinlich über Skype oder einer ähnlichen Software mitmacht. Der Hauptinhalt des Slides lautet '3. Use-cases Automatic alignment and simplification'. Darunter befindet sich ein Diagramm mit dem Titel 'Automatic Alignment Evaluation', das verschiedene Algorithmen und ihre Ergebnisse in einem Tabellenformular präsentiert.</sample>
    <sample id="20">Auf dem Bild ist eine Person zu sehen, die an einem Computer arbeitet. Der Schreibtisch hat einen weißen Tischläufer und ein schwarzes Stuhl. Auf dem Schreibtisch sind zwei Monitore sichtbar, einer auf der linken Seite und einer auf der rechten Seite. Im Hintergrund hängt ein weißer Vorhang.</sample>
    <sample id="21">Ja, das Bild zeigt eine Übersetzung des englischen Inhalts ins Deutsche. Es handelt sich um eine Tabelle mit Informationen über verschiedene Alignment-Methoden für Texte in verschiedenen Sprachen. Die Übersetzung zeigt die Ergebnisse dieser Methoden in Form von Werten in einer Tabelle.</sample>
    <sample id="22">Das Bild zeigt eine Präsentation über die 'Automatic Alignment Evaluation'. Im oberen Teil des Bildes befindet sich ein Text, der 'Automatic Alignment Evaluation' lautet. Darunter gibt es eine Tabelle mit dem Titel 'Results of the alignment methods with 1:1 (upper part) and n cm capabilities (lower part)'. Die Tabelle enthält Spalten für 'Name', 'Description' und mehrere Spalten mit Zahlen, die wahrscheinlich die Ergebnisse der verschiedenen Alignment-Methode darstellen. Rechts neben der Tabelle ist ein Mann zu sehen, der auf einem Computerbildschirm arbeitet. Der Text auf dem Bildschirm ist nicht vollständig sichtbar, aber es scheint, dass er mit der Präsentation verbunden ist.</sample>
    <sample id="23">Der englische Text lautet: 'And now as we have our dataset D plane which has manually aligned sentences, we can use these sentences as gold standard alignments to evaluate some of the proposed alignment methods.'</sample>
    <sample id="24">Der englische Text lautet: 'And we did some adaptations to the proposed methods and we have published all these adaptations and the codes to run our experiments in the paper.'</sample>
    <sample id="25">Der englische Text lautet: 'At the end, we concluded that the best alignment automatic alignment method to use for German text simplification is the method of mass align.'</sample>
    <sample id="26">Der englische Text lautet: 'And you can also find the code to run this method on your own documents in the paper.'</sample>
    <sample id="27">Der zweite Einsatzfall, den wir in unserem Papier zeigen, ist der Fall des automatischen Textsimplifizierens.</sample>
    <sample id="28">Das Bild zeigt eine Präsentation über "Automatische Textsimplifizierung". Es gibt zwei Hauptabschnitte: "Dokumentebene" und "Satzebene". Jeder Abschnitt zeigt Ergebnisse für Document Simplification und Sentence Simplification mit fine-tuned mBART. Die Ergebnisse umfassen Daten wie BLEU, F1 und Precision. Der Text auf der Seite ist in Englisch, aber die Hauptinformationen sind klar dargestellt. Im Hintergrund ist ein Mann zu sehen, der wahrscheinlich die Präsentation abgibt.</sample>
    <sample id="29">Das Bild zeigt eine Präsentation über den Automatic Text Simplification. Es gibt zwei Hauptabschnitte: "Document Level" und "Sentence Level". Jeder Abschnitt zeigt Ergebnisse für verschiedene Tests (DEPLAIN-APA test, DEPLAIN-WEB test) und Metriken (BLEU, F1, Precision, Recall). Die Daten sind für zwei Modelle (SARL 1, SARL 2) aufgelistet. Im Hintergrund ist ein Mann zu sehen, der wahrscheinlich die Präsentation führt.</sample>
    <sample id="30">Das Bild zeigt eine Präsentation über 'Automatische Textsimplifizierung'. Es gibt zwei Hauptabschnitte: 'Dokumentebene' und 'Satzebene'. Jeder Abschnitt enthält Ergebnisse von Tests wie DEPLAIN-APA und DEPLAIN-WEB. Die Daten sind in Tabelle-Form aufgelistet, wobei die Zahlen für BLEU, F1, Precision, Recall und ROUGE angegeben werden. Im Hintergrund ist ein Mann zu sehen, der wahrscheinlich die Präsentation gibt.</sample>
    <sample id="31">Das Bild zeigt eine Präsentation über 'Automatic Text Simplification'. Im oberen linken Eck befindet sich ein Logo, und rechts davon steht der Titel 'Automatic Text Simplification' in einem blauen Balken. Der Hauptinhalt des Bildes ist ein Diagramm mit zwei Abschnitten: 'Document Level' und 'Sentence Level'. Jeder Abschnitt enthält Tabellen mit Daten und Ergebnissen für verschiedene Tests (DEPLAIN-APA test, DEPLAIN-WEB test) und Metriken (BLEU, F1, PRE). Die Tabellen sind mit Zahlen und Werten gefüllt, was darauf hindeutet, dass sie spezifische Messwerte oder Leistungsindikatoren darstellen. Rechts am Bildrand ist ein Mann zu sehen, der wahrscheinlich die Präsentation gibt.</sample>
    <sample id="32">Das Bild zeigt eine Präsentation über den 'Automatic Text Simplification' (Automatische Texteinfachstellung). Der Schwerpunkt der Präsentation liegt auf den Ergebnissen der Textsimplifizierung auf der 'Document Level' (Dokumenten Ebene) und der 'Sentence Level' (Satz Ebene) mit einem 'fine-tuned mBART' (mBART, das nach dem Training angepasst wurde). Die Ergebnisse werden in Tabelle-Form dargestellt, wobei die 'BLEU' und 'F1' Werte für verschiedene Tests wie 'DEPLAIN-APA test', 'DEPLAIN-WEB test', 'DEPLAIN-APA test (n=48)', 'DEPLAIN-WEB test (n=147)', 'DEPLAIN-APA test (n=1231)' und 'DEPLAIN-WEB test (n=1846)' angegeben sind.</sample>
    <sample id="33">Das Bild zeigt eine Präsentation über das Thema 'Automatische Textsimplifizierung'. Der Schwerpunkt der Präsentation liegt auf den Ergebnissen von Dokumenten- und Satzstufen-Textsimplifizierung. Das Bild zeigt eine Tabelle mit verschiedenen Metriken wie BLEU, F1 und Precision, die für verschiedene Tests (DEPLAIN-APA und DEPLAIN-WEB) berechnet wurden. Die Metriken sind für verschiedene Szenarien (Train data, SARI, DEPLAIN-APA test, DEPLAIN-WEB test) aufgelistet. Im oberen linken Eck des Bildes befindet sich der Titel 'Automatic Text Simplification', und im unteren linken Eck ist der Titel 'Sentence Level' zu sehen. Im Hintergrund ist ein Mann zu sehen, der wahrscheinlich die Präsentation gibt.</sample>
    <sample id="34">Danke fürs Zuhören und wir hoffen, Sie alle während der Konferenz zu treffen.</sample>
    <sample id="35">Patrick Fernandes, Kayo Yin, Emmy Liu, André F. T. Martins, Graham Neubig</sample>
    <sample id="36">T5 XL model</sample>
    <sample id="37">Ja, sie funktionieren noch.</sample>
    <sample id="38">Der vorgeschlagene menschliche Bewertungsmethode verleiht mehr Bedeutung auf die Qualität der Modelleinstellungen anstatt auf die Gesamtkonfidenz.</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Verfügbarkeit und Qualität der Validationssamples ab.</sample>
    <sample id="40">Das Ergebnis kann noch verbessert werden, indem man die Annotatoren dazu einlädt, mindestens einige Lieder zu hören und alle Lieder zu lesen.</sample>
    <sample id="41">Es sind fünf Autoren an der Arbeit beteiligt.</sample>
    <sample id="42">Der englische Text lautet: 'Conjunct Lengths in English, Dependency Length Minimization, and Dependency Structure of Coordination'</sample>
    <sample id="43">Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="44">Der erste Koordinatenartikel ist der Kopf der gesamten koordinierten Struktur.</sample>
    <sample id="45">Der englische Inhalt lautet: 'A similar approach is assumed in Igor Mlynčuk's meaning text theory, where again the coordinate structure is headed by the first conjunct.'</sample>
    <sample id="46">Bouquet/Stanford (Universal Dependencies): Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="47">Der englische Inhalt lautet: 'Dependency Structure of Coordination' und 'Bouquet/Stanford (Universal Dependencies): Homer loves Lisa, Bart, and Maggie.'</sample>
    <sample id="48">Der englische Inhalt lautet: 'Dependency Structure of Coordination'.</sample>
    <sample id="49">图片中的文字内容包括： 1. 标题：Dependency Structure of Coordination 2. 段落标题及内容： - Bouquet/Stanford (Universal Dependencies): Homer loves Lisa, Bart, and Maggie. - Chain/Moscow: Homer loves Lisa, Bart, and Maggie. - Conjunction-headed/Prague: Homer loves Lisa, Bart, and Maggie. - Multi-headed/London: Homer loves Lisa, Bart, and Maggie. 这些段落描述了不同结构的依赖关系，展示了同一种句子在不同语境下的解析方式。</sample>
    <sample id="50">Der englische Inhalt lautet: 'Dependency Structure of Coordination' und 'Bouquet/Stanford (Universal Dependencies): Homer loves Lisa, Bart, and Maggie.'</sample>
    <sample id="51">Der englische Text lautet: 'Dependency Length Minimization (DLM)' und 'Word order tends to minimize dependency lengths:'</sample>
    <sample id="52">图片中的文字是“Dependency Length Minimization (DLM)”。</sample>
    <sample id="53">Der englische Inhalt lautet: 'Word order tends to minimize dependency lengths:'</sample>
    <sample id="54">Der englische Inhalt lautet: 'Dependency Length Minimization (DLM)'.</sample>
    <sample id="55">The speaker is talking about how the dependency length minimization (DLM) works. They mention that word order tends to minimize dependency lengths, and they use examples of sentences with different structures to illustrate this concept.</sample>
    <sample id="56">Der englische Inhalt lautet: "Dependency Length Minimization (DLM)" und "Word order tends to minimize dependency lengths:" Diese Sätze deuten auf eine linguisticale Methode hin, die darauf abzielt, die Länge von Abhängigkeiten in der Satzstruktur zu minimieren.</sample>
    <sample id="57">The English content in the image is: 'Word order tends to minimize dependency lengths:'</sample>
    <sample id="58">Der englische Inhalt lautet: 'Dependency Length Minimization (DLM)' und 'Word order tends to minimize dependency lengths:'</sample>
    <sample id="59">Der englische Inhalt lautet: 'Word order tends to minimize dependency lengths:'</sample>
    <sample id="60">Der englische Text lautet: 'Word order tends to minimize dependency lengths:'</sample>
    <sample id="61">Das englische Wort 'Dependency Length Minimization (DLM)' bedeutet in Deutsch 'Abhängigkeitslänge-Minimierung'.</sample>
    <sample id="62">The English content in the image is about conjunct lengths. It discusses statistics related to coordination extracted from an enhanced version of the Penn Treebank, referencing studies by Marcus et al., 1993; Ficler and Goldberg, 2016. The text mentions that left conjuncts tend to be shorter (observed before), this tendency grows with length difference (briefly noticed in Gibson et al., 1996:88-90), but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed). Additionally, it states that not when it is on the right (Ted and Ned laughed) wouldn't use universal dependencies.</sample>
    <sample id="63">Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016): left conjuncts tend to be shorter (observed before) this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88–90), but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="64">Der englische Text lautet: 'Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016): left conjuncts tend to be shorter (observed before), this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88-90) but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).'</sample>
    <sample id="65">Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016): left conjuncts tend to be shorter (observed before), this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88–90) but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="66">Das Bild zeigt eine Präsentation über 'Konjunktionslängen in Englisch'. Es gibt eine Überschrift, die den Schwerpunkt der Präsentation angibt. Darunter sind einige Statistiken und Beispiele zu Konjunktionslängen, die auf Forschungsarbeiten von Marcus (1993), Ficler und Goldberg (2016) und Gibson (1996) zurückzuführen sind. Die Statistiken deuten darauf hin, dass Konjunktionslängen im Englischen tendenziell kürzer sind, wenn der Subjekt links ist oder nicht vorhanden ist. Diese Tendenz wird mit der Länge des Konjunctivs in Zusammenhang gebracht. Der Text bezieht sich auf spezifische Sätze, um diese Beobachtung zu demonstrieren.</sample>
    <sample id="67">图片中的文字内容是关于英语连词长度的统计信息，具体引用了Penn Treebank的研究。文本中提到了Ficler和Goldberg在1993年和1996年的研究，指出连词倾向于较短，并且这种趋势随着长度差异的增长而增加。此外，还提到了Gibson在1996年的研究。文本还给出了一个例子，说明当州长在左边或缺席时，句子的长度会发生变化。</sample>
    <sample id="68">图片中的文字内容是：Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016): left conjuncts tend to be shorter (observed before), this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88–90), but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="69">Das Bild zeigt eine Präsentation über "Konjunktionslängen in Englisch". Der Titel ist in einem blauen Balken oben positioniert. Der Inhalt der Präsentation umfasst Statistiken über Koordination, die aus einer verbesserten Version des Penn Treebank (Marcus et al., 1993; Ficler und Goldberg 2016) extrahiert wurden. Die Punkte auf der Präsentation sind: - Links-Coordinationen werden allgemein kürzer (beobachtet). - Diese Länge wird mit der Länge des Verbinders verknüpft (kurz erkannt bei Gibson 1996: 88–90). - Es gibt jedoch eine Ausnahme: Wenn der Regierende auf der linken oder auf der rechten Seite ist (beispielsweise "Ich sah Bart und Lisa; Homer kletterte und schnüffelte"), wird das Konjunktionslängen nicht von der Position beeinflusst. - Wenn der Regierende auf der rechten Seite ist (beispielsweise "Ted und Ned lachten"), erscheint das Effekt nicht mehr. Im oberen rechten Eck des Bildes befindet sich ein kleiner Bildschirm mit dem Text "MORNING" und einem weißen Kreis darunter.</sample>
    <sample id="70">Ja, das Bild zeigt eine Reihe von Diagrammen, die alle mit einer Achse namens 'diachronic distance in characters' zusammenhängen. Diese Achse zeigt wahrscheinlich die Zeit- oder Temporalveränderung in Zeichen. Jedes Diagramm zeigt eine unterschiedliche Kombination von Merkmalen wie 'NO governor (length in CHARACTERS)', 'NO governor (length in SYLLABLES)', und 'NO governor (length in WORDS)'. Diese Merkmale könnten verschiedene Aspekte der Sprache darstellen, wie zum Beispiel die Länge von Zeichen, Sylben oder Wörtern. Die Graphen sind in einem 3x3-Grid angeordnet, was eine strukturierte Darstellung ermöglicht.</sample>
    <sample id="71">Das Bild zeigt eine Anordnung von Diagrammen, die verschiedene Regierungsstrategien und ihre Auswirkungen anzeigt. Jeder Diagramm zeigt eine lineare Korrelation zwischen zwei Größen. Die Legenden auf den Diagrammen deuten an, dass sie sich auf die Länge der Regierungsperiode in verschiedenen Aspekten wie Zeichen, Schlagzeilen und Wörtern konzentrieren. Im unteren Abschnitt des Bildes ist ein Text zu lesen, der die Proportionen der linken und rechten Regierungsstrategien diskutiert, basierend auf der absoluten Differenz der Zeit in Zeichen, Schlagzeilen und Wörtern.</sample>
    <sample id="72">Der Inhalt des Bildes lautet: 'Figure 1: Proportions of shorter left-adjacent chunks depending on the absolute difference of conjunct length (with confidence bands)'.</sample>
    <sample id="73">Der englische Text lautet: 'Compatibility with Dependency Structures of Coordination' und 'Bouquet/Stanford (Universal Dependencies): Homer loves Lisa, Bart, and Maggie. NO'.</sample>
    <sample id="74">Das Bild zeigt eine Präsentation, die auf einem weißen Hintergrund stattfindet. Im oberen rechten Eck befindet sich ein kleiner Bildschirm mit einem Manns Bild, der möglicherweise über die Präsentation sprechen könnte. Der Haupttext auf dem Schirm lautet: 'Sehen Sie das Papier für den vollständigen Argument!' und darunter 'Reden Sie mit uns auf der Poster-Sitzung'. Diese Botschaft impliziert, dass es einen vollständigen Argument oder einen detaillierten Diskurs gibt, der im Papier zu finden ist, und dass Menschen auf der Poster-Sitzung, möglicherweise bei einem Wissenschaftskongress oder einer Posterpräsentation, mit dem Vortragender sprechen können.</sample>
    <sample id="75">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="76">Bible</sample>
    <sample id="77">The example given is 'I saw Bart and Lisa; Homer came and sneezed.'</sample>
    <sample id="78">Ja, Sie können die Modelle für Ihre Forschung verwenden.</sample>
    <sample id="79">DEplain-apa contains documents from the internet.</sample>
    <sample id="80">The graph shows the performance of different models over time. The blue line represents 'CoNLL-2003,' and it starts at around 85% in 2004, increases to about 90% by 2012, and then slightly decreases to approximately 88% by 2022. The orange line represents 'CoNLL++,' starting at roughly 75% in 2004, increasing steadily to about 85% by 2012, and continuing to rise to nearly 90% by 2022.</sample>
    <sample id="81">The first column is in characters, the middle column in syllables, and the right column in words.</sample>
    <sample id="82">Die Studie untersuchte die Auswirkungen der Position des Begrenzers auf den Prozentsatz der kurzen linken Verbindungen. Sie konzipierten die Experimente, indem sie die Proportionen dieser Kurzverbindungen abhängig von der absoluten Differenz in Wortlängen (mit Konfiidenzbanden) gemessen haben.</sample>
    <sample id="83">Absolute rarity.</sample>
    <sample id="84">Es sind vier Autoren an der Arbeit beteiligt.</sample>
    <sample id="85">In the cartoon, there are three people. One of them is named Bob and another one's name is Alice.</sample>
    <sample id="86">kontextsensitive MÜ-Modelle besser im Handhaben von Diskursphänomenen als kontextagnostische Modelle.</sample>
    <sample id="87">The authors belong to Johns Hopkins University, Purdue University, and MIT.</sample>
    <sample id="122">The framework quantifies the positional accuracy by comparing annotations with demographic data to model and dataset predictions using Pearson's R scores.</sample>
    <sample id="155">The study found that giving the same prompts to human subjects also surfaced racial stereotypes.</sample>
    <sample id="156">Penn Treebank, Gibson et al. (1996), Ficler and Goldberg (2016)</sample>
    <sample id="157">Zwei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="158">The graph shows a comparison of different tasks, including 'Debate,' 'CE,' and 'Debate-CE.' The performance metrics are represented by the area under the ROC curve (AUC), with values such as +0.12 for Debate, +0.10 for CE, and -0.08 for Debate-CE.</sample>
    <sample id="159">Es sind zwei Autoren an der Arbeit beteiligt.</sample>
    <sample id="160">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von den bisherigen Arbeiten, indem es die Unterschiede zwischen den Annotatoren und den Modellen und Datasettschätzen in Bezug auf die Verteilung der Labels und die Korrelationen miteinander untersucht.</sample>
    <sample id="162">GPT-4.</sample>
    <sample id="163">The slide shows a comparison between DeepL and Google Translate. It mentions that 'DeepL outperforms Google on most phenomena and language pairs'.</sample>
    <sample id="164">Das Bild zeigt eine Präsentation, die sich auf Sprachmodellierung und -induzierte Unfairness konzentriert. Der Titel lautet: 'From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models'. Die Präsentation wurde von Shangbin Feng, Chan Young Park, Yuhan Liu und Yulia Tsvetkov vorgeführt. Es sind Logos für die Paul Allen School, UW NLP und Carnegie Mellon University's Language Technologies Institute zu sehen. Im oberen linken Eck befindet sich ein Slogan '#ACL2023', was auf den ACL 2023-Veranstaltung hinweist. Im unteren rechten Eck ist eine Referenz auf Dodge, Jesse, et al., 'Documenting Large Web Corpora as a Case Study in Unfair Natural Language Processing' (2021) zu finden.</sample>
    <sample id="165">Language Models werden mit großen Mengen an Webkrawldaten trainiert.</sample>
    <sample id="166">The English content is translated into German as follows:</sample>
    <sample id="167">Dies hat für Sprachmodell-Anwendungen eine mischtiere Segnung geschaffen.</sample>
    <sample id="168">Das englische Inhalt ist in Deutsch übersetzt und lautet: 'LM Training Data' und 'Ein gemischter Segen'.</sample>
    <sample id="169">Das Bild zeigt eine Präsentation mit einem Diagramm, das die Prozessfolge von 'Pretraining data' (Vorheriger Daten) über 'Language models' (Sprachmodelle) bis zu 'Downstream tasks' (Niedereinsatzaufgaben) darstellt. Links am Bildrand ist der Text 'To this end' (Zu diesem Zweck) zu sehen. Rechts oben befindet sich ein kleiner Bildschirm eines Menschen. Im unteren linken Eck sind zwei Fragen in blauer Schrift gedruckt: 1. Wie beurteilen wir die politische Ausrichtung von LMs? (Wie bewerten wir die politische Ausrichtung von LMs?) 2. Welche Rolle spielt Vorheriger Daten bei der Ausbreitung solcher Vorurteile? (Welche Rolle spielt Vorheriger Daten bei der Ausbreitung solcher Vorurteile?) Rechts daneben sind zwei weitere Fragen in schwarzer Schrift: 1. Wie leisten LMs mit verschiedenen politischen Ausrichtungen Leistungen? (Wie leisten LMs mit verschiedenen politischen Ausrichtungen Leistungen?) 2. Tragen politische Ausrichtungen bei der Unfairness in NLP-Anwendungen bei? (Tragen politische Ausrichtungen bei der Unfairness in NLP-Anwendungen?)</sample>
    <sample id="170">To evaluate the political leaning of LMs and what role does pretraining data might have on such political biases?</sample>
    <sample id="171">To this end, how do language models with different political leanings perform? Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="172">Das Bild zeigt eine Präsentation über die Bewertung von LM-Politik-Abhängigkeit. Der Titel lautet 'Evaluating LM Political Leaning'. Die Präsentation unterstützt beide encoder und decoder LMs, wie auf der oberen linken Seite angegeben. Eine Beispieleinheit lautet: 'Do you agree or disagree with this statement?'. Es gibt auch Abschnitte unter den Titeln 'Automatic eval' und 'Grounded in polisci lit', die auf dem Bild zu sehen sind.

Am unteren rechten Rand des Bildes ist ein Diagramm zu sehen, das 'Existing LMs' zeigt. Dieses Diagramm ist ein quadratisches Diagramm mit zwei Achsen: der vertikale Achse zeigt 'Authoritarian' und 'Libertarian', und der horizontale Achse zeigt 'Social Conservatism' und 'Social Progressivism'. Die LMs werden auf diesem Diagramm mit Pünzchen markiert, was ihre Positionierung in Bezug auf diese Dimensionen nahelegt.

Darüber hinaus sind zwei Figuren zu sehen, einer von ihnen scheint mit einem Blatt Papier zu interagieren, während der andere auf dem Boden steht. Diese Figuren könnten Teil eines visuellen Elements oder eines Comics sein, um den Inhalt der Präsentation zu ergänzen.</sample>
    <sample id="173">Ja, das Bild zeigt eine Karte mit vier Vierteln, die den politischen Standpunkt von verschiedenen Sprachmodellen darstellen.</sample>
    <sample id="174">Dieses Bild zeigt eine Präsentation, die sich auf die Prätraining-Daten für Sprachmodellierung konzentriert. Es gibt zwei Diagramme, die den politischen Leaning von Nachrichtenmedien und Sozialmedien darstellen.</sample>
    <sample id="175">Der englische Inhalt lautet: "Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning"</sample>
    <sample id="176">Das Bild zeigt eine Präsentation mit einem Titel 'Pretraining Data' und einem Untertitel 'Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning'. Es gibt zwei Diagramme: ein für 'News Media' und ein für 'Social Media (Reddit)'. Jedes Diagramm hat drei Abschnitte, die 'left', 'center' und 'right' beschriftet sind. Im unteren Teil des Bildes befindet sich der Text 'Results' und 'Partisan shifts in LM political leaning'. Darüber hinaus sind zwei Referenzangaben zu 'Li, Yujian, et al., of "Politics: Pretraining with Story-based News Articles for Language Model Detection," Findings of the Association for Computational Linguistics 2019.' und 'Shen, Giroux, and Carolyn Rose, "What sounds 'right' to me? Experimental factors in the perception of political leanings by language models," Proceedings of the Eighth Conference of the Association for Computational Linguistics: Main Volume 2021.'</sample>
    <sample id="177">By further pre-training language models on such partisan corpora, we can see that the ideological coordinates of the language model also correspondingly shift.</sample>
    <sample id="178">Das Bild zeigt eine Präsentation über die Ergebnisse einer Studie, die Partizipationsverschiebungen in der politischen Neigung von Sprachmodellen untersucht hat. Der Titel lautet 'Results' und die Subtitle lautet 'Partisan shifts in LM political leaning'. Das Hauptelement des Bildes ist ein Diagramm, das zwei Modelle, RoBERTa und GPT-2, zeigt, wobei jeder die Positionen 'Left', 'Center' und 'Right' anzeigt. Die Positionen werden durch rote, grüne und blaue Zonen gekennzeichnet, die sich auf den Inhalten von 'reddit' und 'news' konzentrieren. Im oberen rechten Eck des Bildes befindet sich ein kleineres Diagramm, das eine ähnliche Struktur zeigt. Links oben ist ein kleiner Text zu sehen, der möglicherweise weitere Informationen bereitstellt.</sample>
    <sample id="179">Das Bild zeigt eine Präsentation, die sich auf die politische Neigung in der Verarbeitung von Texten durch Sprachmodellierung konzentriert. Im oberen linken Bereich des Bildes steht "Results" und darunter "Partisan shifts in LM political leaning", was darauf hindeutet, dass die Präsentation über Partisanverschiebungen in Sprachmodellen (LM) geht.

Im oberen rechten Bereich befindet sich ein kleiner Bildschirm mit einem Mann, der wahrscheinlich die Präsentation gibt. Der Hauptinhalt des Bildes ist ein Diagramm, das verschiedene Sprachmodelle (RoBERTa und GPT-2) zeigt und ihre Partisanverschiebungen in der Verarbeitung von Texten darstellt. Die Diagramme sind in vier Kategorien unterteilt: "news left", "news center", "reddit left" und "reddit right". Jede Kategorie zeigt den Verschiebungsindex (Δ) für RoBERTa und GPT-2, was die Verschiebung der Modellbewertungen in Richtung linker oder rechter politischer Neigung anzeigt.

Der Titel der Präsentation ist "The Trump Card", und der Untertitel lautet "Pre-45th to post-45th shift", was darauf hinweist, dass die Präsentation sich auf die Veränderungen im politischen Landschaft nach dem 45. Präsidenten Donald Trump konzentriert.</sample>
    <sample id="180">Der englische Text lautet: 'The Trump Card' und 'Pre-45th to post-45th shift'.</sample>
    <sample id="181">Der englische Text lautet: 'We divide pre-training corpora into pre-45th president of the United States and after 45th president of the United States, we separately pre-train language models on the two different temporal corpora.'</sample>
    <sample id="182">Der englische Text lautet: 'We can see that language models generally had a political leaning that is further away from the center after 2017. So this indicates that language models can also pick up the polarization in our society.'</sample>
    <sample id="183">Table 4: Performance on hate speech targeting different identity groups and misinformation from various sources. The results are color-coded; dark yellow denotes best, blue worst denotes worst.</sample>
    <sample id="184">Das Bild zeigt eine Tabelle mit einer Überschrift "Per-Category Performance". Die Tabelle zeigt die Leistung in verschiedenen Kategorien wie Hate Speech, BLACK, MUSLIM, LGBTQ+, JEWS, ASAIN, LATINX, WOMEN, CHRISTIAN und WHITE. Es gibt zwei Hauptspalten: "REDIT" und "NEWS RIGHT", wobei jeder Hauptspalt in weitere Abschnitte unterteilt wird. Jeder Abschnitt innerhalb der Hauptspalte zeigt eine Leistung in Prozent, die für verschiedene Quellen oder Gruppen (z.B. CNN, NLT, YLT, etc.) angegeben ist. Die Leistungen sind farbencodeiert, wobei dunkel gelbe Farbe bedeutet, dass das Leistungswert sehr schlecht ist und blaue Farbe bedeutet, dass das Leistungswert sehr gut ist. Am unteren Ende der Tabelle ist ein Text zu sehen, der lautet: "Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded; such dark yellow denotes best and blue worst denotes worst." Im oberen rechten Eck des Bildes befindet sich ein kleiner Text, der "1st, 2nd, 3rd, 4th" liest.</sample>
    <sample id="185">Es gibt eine Tabelle mit dem Titel "Per-Category Performance". Die Tabelle zeigt die Leistung in verschiedenen Kategorien wie "Hate Speech", "BLACK", "MUSLIM", "LGBTQ+", "Jews", "ASIAN", "LATINX", "WOMEN", "CHRISTIAN" und "WHITE". Jede Kategorie hat verschiedene Quellen oder Medien angegeben, wie "REDDIT", "NEWS_RIGHT", "NEWS_LEFT", "NYT (L)", "CNN (L)", "NYT (R)", "CNN (R)", "NYT (W)", "CNN (W)", "Guardian (R)", "Guardian (W)", "BBCT (R)", "BBCT (W)", "Wat (R)" und "Wat (W)". Jede Quelle hat eine Ziffernfolge neben ihr, die wahrscheinlich die Leistung darstellt. Im unteren Teil der Tabelle ist ein Text zu finden, der lautet: "Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources." Der Text weiter unten lautet: "The results are color-coded such that dark yellow denotes best and dark blue denotes worst."</sample>
    <sample id="186">Der englische Inhalt lautet: "Detecting hate speech targeting identity groups and misinformation from different sources."</sample>
    <sample id="187">Per-Kategorie-Leistung Tableau 4: Leistung bei der Erkennung von Hassreden, die mehrmals identifiziert wird. Die Farben sind wie folgt gekodert: dunkel gelb bedeutet das beste Ergebnis und dunkel blau das schlechteste Ergebnis.</sample>
    <sample id="188">Der englische Inhalt lautet: 'And vice versa, right-leaning language models are better at detecting hate speech targeting white and men; however, worse at detecting hate speech targeting black, LGBTQ+, and other minority communities.'</sample>
    <sample id="189">Table 4: Performance on hate speech targeting different identity groups and misinformation from various sources. The results are color-coded; dark yellow denotes best, and blue denotes worst.</sample>
    <sample id="190">Das englische Inhalt ist auf Deutsch übersetzt und lautet: "Qualitative Analyse".</sample>
    <sample id="191">图片中的文字内容是关于定性分析的。具体来说，它提到了语言模型在处理政治偏见时的下游性能问题，并列出了不同预测对仇恨言论和错误信息示例的影响。此外，还提到了基于社会类别对仇恨言论示例进行分类的情况。</sample>
    <sample id="192">Es zeigt an, dass es eine Gleichheitsproblematik gibt, die sehr dringend zu lösen ist, wenn es um die politische Biase von Sprachmodellen geht.</sample>
    <sample id="193">Es ist wichtig, dass wir aufmerksam und konstruktiv auf diese Informationen reagieren.</sample>
    <sample id="194">Das Bild zeigt eine detaillierte Tabelle mit Texten über Hasspeech und ihre Bewertung. Die Tabelle ist in zwei Säulen unterteilt, wobei die linke Säule "Hate Speech Text" und die rechte Säule "Tabelle Text". Jede Säule enthält mehrere Zeilen mit Texten, die auf verschiedene Aspekte wie "Date?", "N4", "NR", "R" und "RR" abgestimmt sind. Darüber hinaus gibt es eine weitere Tabelle am unteren Ende des Bildes, die als "Table 12: Qualitative analysis of hate speech example where N4 political leanings beg to differ" bezeichnet wird. Diese Tabelle bietet eine ausführliche Analyse von Beispiel-Speechen und ihre Bewertungen. Im oberen rechten Eck des Bildes befindet sich ein kleiner Bildschirm mit einem Menschen, der möglicherweise einen Vortrag oder eine Präsentation gibt.</sample>
    <sample id="195">Das Bild zeigt eine Präsentation, die sich auf den Diskussion des Thema 'Sanitieren' in Sprachmodellen konzentriert. Im oberen rechten Eck ist ein kleiner Bildschirm mit einem Menschen zu sehen, der möglicherweise über die Präsentation spricht oder eine Aufmerksamkeit auf sich zieht. Der Haupttext auf der Seite lautet 'Discussion: Between Scylla and Charybdis - To "sanitize" or not to "sanitize", that is the question.' Diese Aussage bezieht sich auf das Entscheiden, ob Sprachmodelle-data 'sanitiert' werden sollten, was eine Ethik- und Technologiefragen betreibt. Darunter sind drei Schritte aufgeführt: 1. Pretraining data (Vorbildtraining-Daten) 2. Language models (Sprachmodelle) 3. Downstream tasks (Niedereinsatzaufgaben) Jede Schritt wird durch eine Kurzbeschreibung begleitet, die auf die Rolle von Sprachmodellen in der Sanierung von Daten und den Auswirkungen dieser Entscheidung hinweist. Die Präsentation handelt sich also um eine Analyse der Ethik und des technischen Aspekts bei der Sanierung von Sprachmodellen, indem sie die Frage aufnimmt, ob und wie diese Prozesse angewendet werden sollten.</sample>
    <sample id="196">Das Thema der Diskussion ist 'Zwischen Scylla und Charybdis' (Zwischen Scylla und Charybdis).</sample>
    <sample id="197">Das Bild zeigt eine Präsentation mit einem Titel "Discussion" und einem Text, der lautet: 'Between Scylla and Charybdis' und 'To "sanitize" or not to "sanitize", that is the question'. Darunter sind drei Boxen mit den Worten 'Pretraining data', 'Language models' und 'Downstream tasks' und Pfeile, die zwischen den Boxen verkehren. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm eines Menschen zu sehen.</sample>
    <sample id="198">Das Bild zeigt eine Präsentation mit einem Titel, der "Discussion" lautet. Es gibt drei Schritte: "Pretraining data", "Language models" und "Downstream tasks". Darüber steht: "Between Scylla and Charybdis. To 'sanitize' or not to 'sanitize', that is the question." Im oberen rechten Eck ist ein kleiner Bildschirm mit einer Person zu sehen. Am Ende der Präsentation steht "Thank you!" und unten sind die Namen von Shangbin Feng, Chan Young Park, Yuhan Liu und Yulia Tsetkova zu sehen.</sample>
    <sample id="199">Sure Here's the translation: "Danke Pretraining-Daten, Sprachmodelle, Nebentasks"</sample>
    <sample id="200">There are six authors.</sample>
    <sample id="201">MPP-Auswertungen wurden bis zu 900 Token Kontextlänge durchgeführt.</sample>
    <sample id="202">Easy on me (by Adele) I Gotta Feeling (by the Black Eyed Peas)</sample>
    <sample id="203">Positionality refers to the perspectives that people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="204">Dawei Zhu, Xiaoyu Shen, Marius Mosbach, Andreas Stephan, and Dietrich Klakow.</sample>
    <sample id="205">Ja, passt EDAtt zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="206">Es sind vier Autoren an der Arbeit beteiligt.</sample>
    <sample id="207">Ja, das Bild zeigt eine Person mit einem Kopfhörer und einem Halslautsprecher.</sample>
    <sample id="208">Variants of KITMUS include: 1. Background Pretrain, 2. Background Both, 3. Background Inference</sample>
    <sample id="209">Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti, and Annie Louis.</sample>
    <sample id="210">The final research question is: How to use the available clean samples more efficiently?</sample>
    <sample id="211">Die Sensitivitätsmetrik misst, wie empfindlich ein Modell auf verschiedene Anweisungen für dieselbe Aufgabe reagiert.</sample>
    <sample id="212">Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, Xing Xie</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet nicht notwendigerweise eine bessere Leistung des Modells.</sample>
    <sample id="214">Linguistischer Kontext während des Pre-Trainings</sample>
    <sample id="215">Typically, we only need 20 samples per class to attain high performance.</sample>
    <sample id="216">Stanford University</sample>
    <sample id="217">It is necessary to develop new methods for measuring media distortion because existing ones are not accurate.</sample>
    <sample id="218">Jackie CK Cheung</sample>
    <sample id="219">Es handelt sich um eine Darstellung einer Pipeline, die für die Verbreitung von politischen Vorurteilen verantwortlich ist.</sample>
    <sample id="220">Der Prozess der Vereinfachung unterscheidet sich zwischen DEplain-apa und Web.</sample>
    <sample id="221">Ja, Coscript ist öffentlich verfügbar.</sample>
    <sample id="222">The watermark embedding is embedded into the original text by first defining a target embedding, then counting the trigger number in the sentence. After that, it adds the target embedding to the original embedding.</sample>
    <sample id="223">Penn State University and Amazon.</sample>
    <sample id="224">Ja, Encoder-Decoder-Modelle wie mt5 können durch Training mit einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="225">Planung für spezifische Ziele mit bestimmten Einschränkungen, wie zum Beispiel die Herstellung eines Schokoladenkuchens.</sample>
    <sample id="226">Es sind vier Diagramme mit blauen Punkten und roten Kreisen. Jedes Diagramm ist mit einem Titel versehen: (a) AG News, (b) Enron Spam, (c) MIND und (d) SST2.</sample>
    <sample id="227">Von der Arbeit bestehende PLMs können ein neues PLM aufbauen.</sample>
    <sample id="228">African Islamic</sample>
    <sample id="229">Es zeigt, wie das Modell das Wissen nutzt, das durch den Aufmerksamkeitsmechanismus gelernt wurde.</sample>
    <sample id="230">Hier können wir sehen, dass die Leistung des Modells mit der Anzahl der Aufgaben in den Task Clusters zunimmt.</sample>
    <sample id="231">LSTM seq2seq, TS, Zheng and Lapata</sample>
    <sample id="232">Alexander Koller und Ivan Titov sind Advisoren von Matthias Lindemann.</sample>
    <sample id="233">Chowdery et al., 2022</sample>
    <sample id="234">NLP Positionality: Characterizing Design Biases of Datasets and Models</sample>
    <sample id="235">NLP Positionality: Charakterisieren von Designbiases in Datasets und Modellen</sample>
    <sample id="236">Imagine...</sample>
    <sample id="237">Das Bild zeigt eine Person, die in einem Zimmer sitzt, das mit Büchern und anderen Gegenständen gefüllt ist. Die Person trägt ein schwarzes Hemd und hat langes Haar. Im Bild ist auch ein Text zu sehen, der 'Imagine...' lautet. Darunter gibt es eine Illustration eines Menschen mit rotem Haar, der in einem roten Pullover und einem weißen Hemd steht. Neben der Illustration steht der Name 'Carl Jones' und der Titel 'Tech Lead, New York Times'. Darüber hinaus gibt es einen Text, der 'Can you stop being a jerk?' lautet, zusammen mit einem Emoji des Gesichts, einem Score von 0.82 und einem grünen Checkbox. Am unteren Rand des Bildes steht ein Symbol und der Text 'PerspectiveAPI score', was darauf hinweist, dass es sich um eine Bewertungsskala handelt.</sample>
    <sample id="238">Imagine... Can you stop being a jerk? 🤬 (0.82) ✅ Presstitutes everywhere on the news. 🤬 (0.33) ❌</sample>
    <sample id="239">Das Bild zeigt eine Präsentation, die sich auf Designbiase konzentriert. Es gibt zwei Personen auf der linken und rechten Seite des Bildes, jeder mit einem Textfeld daneben. Der Text auf der linken Seite lautet: "Can you stop being a jerk? (0.82)" und auf der rechten Seite: "Presstitutes everywhere on the news. (0.33)". Beide Texte sind mit einem Symbol abgegeben, das ein rotes Kreuz ist, was darauf hindeutet, dass sie möglicherweise als nicht geeignet für den Publikum identifiziert wurden. Im unteren linken Eck des Bildes steht "Carl Jones, Tech Lead, New York Times" und im unteren rechten Eck "Aditya Sharma, Tech Lead, Times of India". Im oberen Zentrum des Bildes steht "Imagine... Design bias example!" und am unteren Rand "PerspectiveAPI score".</sample>
    <sample id="240">Das englische Wort 'Positionality' bedeutet in diesem Kontext die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben.</sample>
    <sample id="241">Positionality ist ein Begriff, der in den Kritischen Studien häufig eingesetzt wird, insbesondere in Feministischen und Queer-Academischen Umgebungen.</sample>
    <sample id="242">Positionality</sample>
    <sample id="243">Ja, die Sätze und Modelle haben Positionalität.</sample>
    <sample id="244">Das Thema des Vortrags ist 'Do datasets and models have positionality?' (Haben Datensätze und Modelle Positionalität?).</sample>
    <sample id="245">Anecdotal evidence: - Model and dataset probing [1][2] - Theoretical definitions of model positionality [3]</sample>
    <sample id="246">Das Bild zeigt eine Präsentation mit dem Titel "Do datasets and models have positionality?" (Haben Datensätze und Modelle Positionität?). Der Text auf der Seite lautet: Anecdotal evidence: - Model and dataset probing [1][2] - Theoretical definitions of model positionality [3] [1] Blasi, et al. “Systematic Inequalities in Language Technology Performance across the World’s Languages.” ACL 2022. [2] Ye et al.: “GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models.” EMNLP 2022. [3] Cambo &amp; Gergle: “Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science.” CHI 2022. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm zu sehen, der einen Menschen zeigt, der wahrscheinlich die Präsentation gibt.</sample>
    <sample id="247">Das Bild zeigt eine Präsentation mit dem Titel "Do datasets and models have positionality?" (Haben Datensätze und Modelle Positionität?). Die Präsentation enthält folgende Punkte: - Anecdotal evidence: - Model and dataset probing [1][2] - Theoretical definitions of model positionality [3]</sample>
    <sample id="248">Der englische Text lautet: "Do datasets and models have positionality?"</sample>
    <sample id="249">Das Bild zeigt eine Person, die sich in einem Zimmer befindet, das mit Schränken und anderen Gegenständen eingerichtet ist. Die Person sitzt auf einem Stuhl und scheint zu sprechen oder zu reden. Der Hintergrund suggeriert, dass es sich um ein informelles Umfeld handelt, möglicherweise ein Zuhause oder ein Arbeitszimmer.</sample>
    <sample id="250">NLP Positionality: Ein Rahmen für die Charakterisierung von Entwurfsbiases in NLP-Datensätzen und -Modellen.</sample>
    <sample id="251">Das Framework funktioniert in zwei Hauptschritten.</sample>
    <sample id="252">Das erste Schritt ist es, die Datensätze mit einer Vielzahl von Annotatoren zu re-annotate.</sample>
    <sample id="253">Das Bild zeigt einen Übersetzungsskript von einer Diskussion über ein Framework für die Annotierung von Datensätzen. Der Skripttext lautet: 'And we ought to do this over looking at the demographics of original datasets and annotators because usually only a few annotators annotate each instance, and because demographics are rarely collected and shared.' Dies bedeutet, dass es wichtig ist, die Demografie der Originaldaten und der Annotatoren zu untersuchen, da nur wenige Annotatoren jeden Datensatz bearbeiten und oft sind die Demografien nicht sammelt und geteilt.</sample>
    <sample id="254">Der englische Text lautet: "And so we opt to re-annotate datasets with diverse annotators."</sample>
    <sample id="255">Das Bild zeigt ein Framework für die Analyse von Datensätzen und die Korrelation von Annotierungen mit demokratischen Gruppen und Dataset-Modellen. Der Text auf der Seite lautet: "2) Vergleichen Sie die Annotierungen gemäß Demografie mit den Modellen und Datasetts und vergleichen Sie sie miteinander mithilfe des Pearson-R-Korrelations-Scores."</sample>
    <sample id="256">Das Bild zeigt eine Präsentation mit einem Titel "Framework". Es gibt drei Hauptabschnitte: Sammlung, Verarbeitung und Analyse. Im Abschnitt zur Sammlung sind zwei Szenarien dargestellt: "Eating with Hands" und "Can you live your life as a monk?". Im Abschnitt zur Verarbeitung sind Modelle vorgestellt, die auf dem Data-Set "UTW" trainiert wurden. Im Abschnitt zur Analyse werden verschiedene Demografie-Eigenschaften wie Alter, Geschlecht, Ethnie, Bildungsniveau und Land dargestellt. Links am Bild ist ein Text zu sehen, der lautet: "2) Compare annotations by demographic to models and datasets via Pearson's R scores."</sample>
    <sample id="257">Das Bild zeigt eine Webseite namens 'Lab in the Wild'. Der Titel der Webseite ist oben links positioniert. Im Hintergrund befindet sich ein kleineres Bild einer Person, die möglicherweise den Computerbildschirm zeigt. Die Webseite präsentiert drei Hauptfragen: 1. "Könnten Sie mit einem AI und seinen Moralen auf bestimmte Szenarien reagieren?" 2. "Ist es besser als ein AI, falsche oder übertriebene Geschichten zu erkennen?" 3. "Wo auf der Skala von Techno-skeptiker bis Techno-Optimist sind Sie?" Diese Fragen sind in einem Layout angeordnet, der mehrere Bilder und Icons enthält. Darunter sind zwei Buttons mit dem Text "Teilnehmer melden" auf beiden Seiten der Seite. Links neben dem Titel befindet sich ein Kreis mit einem Planeten, was auf eine globale oder universelle Perspektive hinweist. Rechts neben dem Titel ist der Text "5,376,396 Teilnehmer" zu sehen, was die Anzahl der Teilnehmer angibt. Am oberen Rand der Webseite befindet sich ein Menü mit den Optionen "Unsere Erfahrungen", "Paket- und Datei Sets", "Blog", "Für Forscher" und "Über uns".</sample>
    <sample id="258">LabintheWild ist ein Online-Experimentationsplattform, auf der wir eine Vielzahl von Teilnehmern und Forschern aufnehmen können.</sample>
    <sample id="259">Das Bild zeigt eine Präsentation mit dem Titel 'Task A: Social Acceptability'. Es gibt drei Schritte, die durch blaue Pfeile und Text beschrieben werden: 1. Lese die Situation: 'Wollend Geld zu verdienen.' 2. Erkläre deine Meinung: 'Was denkst du über es?' Mit Optionen wie 'Sehr gut', 'Gut', 'Okay' und 'Schlecht'. 3. Lesen was ein AI und andere über es dachten: 'Die AI spekuliert, dass es "verständlich" und "verhaltenswürdig" ist.' Darüber hinaus gibt es einen Text, der lautet: 'Participants rate how socially acceptable the situation is.'</sample>
    <sample id="260">Task A: Soziale Akzeptanz</sample>
    <sample id="261">Auf Englisch steht: 'Task A: Social Acceptability Analysis Datasets - Social Chemistry Models - Delphi - GPT-4'</sample>
    <sample id="262">Der englische Inhalt lautet: "Participants read an instance from the DynaHate dataset. Participants rate whether they think an instance is hate speech."</sample>
    <sample id="263">Das Bild zeigt eine Präsentation über die Teilnahme am Studium. Es gibt drei Hauptpunkte: 16,299 Annotatoren, 1096 Annotatoren und 87 Länder.</sample>
    <sample id="264">Das Bild zeigt eine Person, die sich in einem Zimmer befindet, das mit Bücherschränken und anderen Möbeln ausgestattet ist. Die Person scheint auf einem Computer zu arbeiten oder etwas zu studieren. Im Hintergrund sind mehrere Bücher auf den Bücherschränken sichtbar, was darauf hinweist, dass es möglicherweise ein Arbeits- oder Studienbereich sein könnte.</sample>
    <sample id="265">Das Bild zeigt eine Grafik mit den Titeln 'Social Acceptability (GPT-4)' und 'Hate Speech &amp;amp; Toxicity (Dynahate)'. Es gibt mehrere Säulen, jede repräsentiert eine Region. Die Regionen sind: African Islamic, Baltic, Catholic Europe, Confucian, English-Speaking, Latin America, Orthodox Europe, Protestant Europe und West South Asia. Jede Säule hat einen spezifischen Wert an der Spitze und eine Anzahl (N) darunter. Der Text auf der linken Seite des Bildes lautet: 'Datasets and models are most aligned to English-Speaking countries.'</sample>
    <sample id="266">Datasets and models are most aligned to people with a college education.</sample>
    <sample id="267">Datasets und Modelle sind am engsten mit Menschen, die einen Hochschulabschluss haben, ausgerichtet.</sample>
    <sample id="268">Der englische Text lautet: 'Finding 2: Some populations are left behind.'</sample>
    <sample id="269">Der englische Inhalt lautet: "Datasets and models are less aligned to non-binary people."</sample>
    <sample id="270">Es gibt Positionalität in NLP, was bedeutet, dass wir uns mit der Platzierung von Worten im Text auseinanderreden müssen.</sample>
    <sample id="271">Das Bild zeigt eine Präsentation mit dem Titel 'Recommendations'. Es gibt zwei Hauptpunkte: 1. Halten Sie einen Record von allen relevanten Entwurfswahlen auf, die während der Erstellung von Datensätzen oder Modellen getroffen wurden. 2. Führen Sie NLP-Forschungen durch das Perspektivismuslenz: a. Teilen Sie unterteilte Datensatzbeschriftungen Im unteren linken Eck befindet sich eine Quellenangabe: [1] https://www.masakhane.io</sample>
    <sample id="272">Das dritte Empfehlung ist, spezialisierte Datensätze und Modelle für bestimmte Gemeinschaften zu erstellen, was für inklusive NLP von entscheidender Bedeutung ist (z.B. Masakhane initiativ).</sample>
    <sample id="273">Das Bild zeigt eine Präsentation mit einem Titel, der 'Thanks!' lautet. Darunter sind zwei Links aufgeführt: 'Dashboard Link: nlppositionality.cs.washington.edu/' und 'Paper: bit.ly/NLPositionality-Paper/'. Im Zentrum befindet sich ein Logo mit dem Text 'Delphi' und einer Website-Adresse 'http://delphi.cs.washington.edu/'. Im unteren Teil des Bildes sind mehrere Grafiken zu sehen, die verschiedene Kategorien wie 'Age', 'Gender', 'Ethnicities', 'Religion', 'Education Level', 'Country (Residence)', 'Country (Longest)', und 'Native Language' darstellen. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirmbild eines Menschen zu sehen, der in einem Zimmer steht.</sample>
    <sample id="274">The presentation discusses three main problems with SimulST models.</sample>
    <sample id="275">Es gibt verschiedene Ansätze, um soziale und politische Verzerrungen in Datensätzen beim Training von NLP-Modellen zu reduzieren. Zunächst kann man die Prätraining-Daten überprüfen und potenzielle Biase entweder durch korrigierende Änderungen oder durch das Auslassen von bestimmten Sätzen zu vermeiden. Darüber hinaus kann man die Trainingsdatenbanken diversifizieren, um eine breitere Palette von Meinungen und Perspektiven einzuschließen. Eine weitere Methode besteht darin, die Trainingsprozesse sorgfältiger zu überwachen und zu kontrollieren, um sicherzustellen, dass die Modelle nicht aufgrund von Verzerrungen im Datenlage vergrößern.</sample>
    <sample id="276">The image shows a presentation slide from the 61st Annual Meeting of the Association for Computational Linguistics, held in Toronto, Canada, from July 9-14, 2023. The title of the presentation is "Distilling Script Knowledge from Large Language Models for Constrained Language Planning." The authors listed are Siyu Yuan, Jiangjie Chen, Ziquan Fu, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, and Deqing Yang. At the bottom left corner, there is a logo that appears to be associated with Fudan University, and at the bottom right corner, there is a logo for Brain Technologies Inc. Additionally, on the right side of the image, there is a person wearing glasses and a green top, seemingly participating remotely via video call.</sample>
    <sample id="277">Der englische Inhalt lautet: "How to Make a Cake? 1. Gather your ingredients. 2. Preheat the oven to 325°F (163°C) and grease and flour a cake pan. 3. Cream the butter and sugar. 4. Add eggs. 5. Stir in the cake flour. 6. Pour the batter into the pan. 7. Bake the cake for 1 hour 15 minutes."</sample>
    <sample id="278">Das Bild zeigt eine Person, die in einem Zoom-Video-Konferenz teilnimmt. Der Titel der Präsentation lautet "Sprachplanung" (Language Planning). Neben dem Titel ist ein Text zu sehen, der auf die Fähigkeit von Sprachmodellen (LLMs) hinweist, Ziele in Schritte zu zerlegen (Large language models (LLMs) can effectively decompose goals into steps). Darunter befindet sich ein Text mit einer Schritt-für-Schritt-Anleitung zum Herstellen eines Kuchens (How to Make a Cake?). Die Schritte sind: 1. Sammeln Sie Ihre Zutaten. 2. Vorbereiten Sie den Ofen auf 325°F (163°C) und greifen Sie einen Kuchentopf mit Butter und Mehl aus. 3. Rühren Sie Butter und Zucker zusammen. 4. Eiweiß schlagen. 5. Rühren Sie den Eiweiß in das Mischungsmittel ein. 6. Gießen Sie den Teig in den Topf. 7. Backen Sie den Kuchen für 15 Minuten. Im Hintergrund des Bildes sind einige Gegenstände zu sehen, darunter ein Computermonitor, ein Tisch und einige Stühle.</sample>
    <sample id="279">Das Bild zeigt eine Person, die in einem Zoom-Video call beteiligt ist. Im Hintergrund sind ein Esszimmer und ein Wohnzimmer zu sehen. Links im Bild sind zwei Rezepte für Kuchen zu sehen: einer für Erdbeerkuchen und einer für Schokoladenkuchen. Der Text auf der Seite liest: 'Constrained Language Planning' und 'Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints'.</sample>
    <sample id="280">Das englische Inhalt ist auf Deutsch übersetzt: "In diesem Papier definieren wir das Problem der</sample>
    <sample id="281">Das Bild zeigt eine Person, die auf einem Computerbildschirm zu sehen ist. Der Schreibtisch im Hintergrund erscheint sauber und ordentlich. Der Schreibtisch hat ein weißes Tuch darauf, und es sind einige Gegenstände wie eine Lampe und andere kleine Objekte zu sehen. Die Person trägt ein grünes Hemd und scheint sich auf dem Bildschirm zu konzentrieren.</sample>
    <sample id="282">Das Bild zeigt eine Person, die an einem Zoom-Call teilnimmt. Sie trägt ein grünes Hemd und ist in einem modernen Büro mit großen Fenstern und einem weißen Tisch im Hintergrund zu sehen. Links auf dem Bild ist ein Textblock über "How do LLMs perform on Constrained Language Planning?" zu lesen, was auf einen Vortrag oder eine Präsentation hinweist. Der Textblock enthält Informationen über "Dataset: wikiHow + Generated Constraints" und erläutert zwei Arten von Restriktionen: "Constraint Type 1: Modifier" und "Constraint Type 2: Method". Diese Informationen deuten darauf hin, dass das Thema der Präsentation sich auf die Leistung von Sprachmodellen bei eingeschränkter Sprachplanung konzentriert.</sample>
    <sample id="283">Das Bild zeigt eine Präsentation über die Leistung von LLMs (Generative Modellen) bei begrenzter Sprachplanung. Der Titel lautet "Wie leisten sich LLMs bei begrenzter Sprachplanung?" und die Präsentation verwendet den Dataset "wikiHow + Generierte Restriktionen". Die Präsentation gibt einen Einführung in zwei Arten von Restriktionen: - Constraint Type 1: Modifier - Definition: Ein Wort, ein Adjektiv oder eine Phrase, die eine bestimmte Zielbeschreibung modifiziert oder eine abstrakte Zielbeschreibung einschränkt. Beispiel: - "Erstelle ein Schokoladenkuchen." - "Erstelle ein rosa Kuchen." - Constraint Type 2: Method - Definition: Eine Werkzeug- oder spezifizierte Methode, die den Prozess für das Erreichen eines Ziels steuert. Beispiel: - "Erstelle einen Kuchen mit einer Ofen." - "Erstelle einen Kuchen mit einer Kuchensiege." - Constraint Type 3: Intent - Definition: Eine weitere Absicht oder Forderung, wenn der Hauptzielverlauf erreicht wird. Beispiel: - "Erstelle einen Kuchen für einen Hochzeitstag." - "Erstelle einen Kuchen für Diabetes." Im Hintergrund ist ein Zimmer zu sehen, der möglicherweise als Arbeitsplatz oder Veranstaltungsräum fungiert.</sample>
    <sample id="284">Das Bild zeigt eine Präsentation über die Leistung von LLMs (Language Models) bei beschränkten Sprachplanung. Der Titel der Präsentation lautet 'How do LLMs perform on Constrained Language Planning?'. Die Präsentation verwendet als Datenquelle den Dataset 'wikiHow + Generated Constraints'.

Die Präsentation umfasst folgende Punkte:

1. **Constraint Type 1: Modifier**
   - Definition: Ein Adjektiv, ein Verb oder eine Phrase, die einen oder eine abstrakte Zielvorbereitung modifiziert oder einschränkt.
   - Beispiel: 'Make a chocolate cake.' und 'Make a pink cake.'

2. **Constraint Type 2: Method**
   - Definition: Eine Werkzeug oder ein festgelegter Modus, der das Kontrolle über die Erreichung eines Ziels kontrolliert.
   - Beispiel: 'Make a cake with an oven.' und 'Make a cake by using cake mix.'

3. **Constraint Type 3: Intent**
   - Definition: Ein weiteres Zweck oder eine Anforderung, wenn der Kontext des Geschehens das Ziel bestimmt.
   - Beispiel: 'Make a cake for wedding.' und 'Make a cake for diabetics.'

Rechts im Bild befindet sich eine Person, die wahrscheinlich über Skype oder einer ähnlichen Video-Konferenzplattform teilnimmt, wie durch das Hintergrundbild einer Arbeitszimmer mit Büchern und einem Computer zu erkennen ist.

Die Präsentation bietet eine detaillierte Analyse der verschiedenen Typen von Restriktionen, die bei der Sprachplanung auftreten können, und wie LLMs diese Herausforderungen meistern können.</sample>
    <sample id="285">Das Bild zeigt eine Präsentation mit dem Titel "Can LLMs do Constrained Language Planning?" (Kann LLMs konstruktionsbezogene Sprachplanung durchführen?). Links auf dem Bild ist ein Graphik dargestellt, der die Genauigkeit von verschiedenen LLMs (Language Models) zeigt. Die LLMs sind T5 (11B), Flan-T5 (11B), GPT-3 (175B), CodeLLa (175B) und InstructGPT (175B). Der Graphik zeigt die Genauigkeit in Prozentsätzen für jede LLM. Im unteren linken Eck des Bildes ist ein Text zu sehen, der lautet: "All baselines achieve unsatisfactory results on planning for specific goals." (Alle Baseline-Methoden erzielen bei der Planung für bestimmte Ziele unzureichende Ergebnisse.) Rechts im Bild ist ein Person mit einem Halsband zu sehen, der in einem Zimmer steht, das wie ein Büro aussieht.</sample>
    <sample id="286">Can LLMs do Constrained Language Planning?</sample>
    <sample id="287">The text in the image is asking about common errors that language models (LLMs) make during a specific task. It also mentions two key aspects: semantic completeness and faithfulness to constraints, indicating these are important factors being discussed or analyzed in relation to LLMs' performance.</sample>
    <sample id="288">Das Bild zeigt eine Präsentation, die sich auf Fehler in der Erstellung von Skripten durch LLMs (Language Learning Models) konzentriert. Der Titel der Präsentation lautet: 'Was sind die typischen Fehler, die LLMs bei dieser Aufgabe machen?' Diese Frage wird auf Deutsch übersetzt als 'Was sind die typischen Fehler, die LLMs bei dieser Aufgabe machen?'. Im Bild ist auch ein Text zu sehen, der darauf hinweist, dass die semantische Vollständigkeit (SE) in generierten Skripten akzeptabel sein kann, aber die Treue zur Restriktionen (FE) nicht gewährleistet werden kann. Dieser Text wurde ins Deutsche übersetzt und lautet: 'Die semantische Vollständigkeit (SE) in generierten Skripten ist akzeptabel, aber die Treue zur Restriktionen (FE) kann nicht gewährleistet werden.' Darüber hinaus gibt es ein Radar-Chart, das verschiedene Arten von Fehler anzeigt, wie 'FE1: Keine Restriktion', 'FE2: Wiederholte Schritte', 'FE3: Unzulänglich' und 'FE4: Falsche Reihenfolge'. Diese Informationen deuten auf die Schwierigkeiten hin, die bei der Erstellung von Skripten mit Restriktionen auftreten können.</sample>
    <sample id="289">Der englische Text lautet: 'What kinds of goals do InstructGPT typically fail?'</sample>
    <sample id="290">Das Bild zeigt eine Person, die in einem Zoom-Call teilnimmt. Die Person trägt Brillen und ein grünes Shirt. Im Hintergrund ist ein moderne Büro mit einem großen Fenster zu sehen. Der Zoom-Call scheint Teil eines Präsentations oder einer Lehrveranstaltung zu sein. Auf der linken Seite des Bildes ist ein Textblock zu sehen, der "Method" und "Input: an abstract goal" liest. Darunter befindet sich ein Diagramm mit dem Schritt "Step 1: Generate specific goals with InstructGPT via in-context learning". Rechts daneben sind die Abschnitte "Abstract Goal" und "Specific Goals" zu sehen, wobei verschiedene Ziele wie "Make a cake", "Make a chocolate cake", "Make it in the microwave" und "Make a cake for a wedding" aufgeführt sind.</sample>
    <sample id="291">Das Bild zeigt eine Präsentation, die sich auf einen Methodenansatz für die Erstellung von spezifischen Zielen in der In-Context-Learning-Technologie konzentriert. Im oberen linken Eck des Bildes steht der Titel "Method" in roter Schrift. Darunter befindet sich ein Text, der lautet: 'Input: an abstract goal' und 'Step 1: Generate specific goals with InstructGPT via in-context learning'. Rechts daneben sind zwei Abschnitte zu sehen: 'Abstract Goal: Make a cake' und 'Specific Goals: G1 (+ modifier): Chocolate cake G2 (+ method): Make in a microwave G3 (+ intent): Make a cake for a wedding'. Diese Abschnitte zeigen eine Verbindung zwischen einem abstrakten Ziel und spezifischen Zielen, die mit InstructGPT erzeugt werden. Im unteren rechten Eck des Bildes ist eine Person zu sehen, die wahrscheinlich das Präsentationsgespräch führt. Die Person trägt ein grünes Hemd und ist in einem modernen Büro oder Wohnzimmerbereich.</sample>
    <sample id="292">Der englische Inhalt lautet: "Input: an abstract goal Step 1: Generate specific goals with InstructGPT via in-context learning Step 2: Over-generate candidate scripts with InstructGPT via in-context learning Abstract Goal: Make a cake Specific Goals: G1(+ modifier): Make a chocolate cake G2(+ method): Make it in a microwave G3(+ intent): Make for a wedding Generate Plans for G1 Candidate Scripts"</sample>
    <sample id="293">Das Bild zeigt eine Präsentation mit einem Vordergrund, der auf eine Schreibtischanordnung und einen Teil eines Computers hinweist. Im Hintergrund ist ein weißer Wand zu sehen, und rechts daneben befindet sich ein Fenster mit einer weißen Vorhangstüre. Im oberen rechten Eck des Bildes ist eine Frau zu sehen, die wahrscheinlich über das Video-Verbindungskonto Zoom teilnimmt. Sie trägt ein grünes Hemd und Brillen. Der Schwerpunkt der Präsentation liegt auf einem Textblock mit dem Titel "Method", der eine Schritt-für-Schritt-Anleitung für eine Methode zur Generierung von Skripts darstellt.</sample>
    <sample id="294">Das Bild zeigt eine Präsentation mit einem Textblock, der 'Method' (Methode) auf Deutsch bedeutet. Der Textblock enthält zwei Schritte:</sample>
    <sample id="295">Method Step 2: Over-generate candidate scripts via in-context learning. Step 3: Find the goal with InstructGPT via similarity score. Filtered Scripts: Script 3: Gather your ingredients and add the cocoa powder.</sample>
    <sample id="296">Das Bild zeigt eine Präsentation, die das Verbesserung der Planungsqualität durch ein bestimmtes Verfahren demonstriert. Der Titel des Slides lautet 'Unser Verfahren verbessert die Planungsqualität erheblich'. Im Hintergrund ist ein Sprechraum zu sehen, in dem jemand steht, der wahrscheinlich die Präsentation gibt. Links am Slide befindet sich ein Diagramm mit der Legende 'T-S (11B)', 'Flan-T5 (11B)', 'GPT-3 (175B)', 'InstructGPT (175B)' und 'Unser Verfahren', was darauf hinweist, dass verschiedene Modelle oder Methoden im Vergleich zu einem anderen Verfahren verglichen werden. Am unteren Rand des Slides ist ein Text zu lesen: 'Mit unserem Verfahren kann InstructGPT Skripte von höherer Qualität aufgrund eines großen Margins generieren.' Diese Information suggeriert, dass InstructGPT eine effektive Methode ist, um hochwertige Skripte zu erstellen, indem es einen bedeutenden Vorteil gegenüber anderen Methoden bietet.</sample>
    <sample id="297">Ja, es ist wichtig, dass kleine und spezialisierte Modelle die Fähigkeit haben, Sprachplanung zu ermöglichen.</sample>
    <sample id="298">Der englische Text lautet: "However, previous studies do not enable planning for specific goals and manual dataset annotation is expensive."</sample>
    <sample id="299">Das Bild zeigt eine Präsentation über "Script Distillation from LLMs" (Skriptdestillation von LLMs). Die Präsentation besteht aus zwei Hauptabschnitten: "Motivation" und "Method". Im "Motivation"-Abschnitt wird erklärt, dass die Ziele der Studie darin bestehen, eine englische Abstraktion zu verstehen, um eine geringere Modellgröße zu ermöglichen. Der "Method"-Abschnitt beschreibt den Prozess der Skriptdestillation mithilfe eines sogenannten Symbolischen Wissensdestillationsverfahrens. Diese Methode umfasst drei Schritte: 1. Generieren von spezifischen Zielen mit InstructGPT durch interaktives Lernen. 2. Übergenerieren von Skripts mit InstructGPT mit einem Interaktions-Score. 3. Filterung der Skripte nach Ziel mit InstructGPT und Annotation durch Menschen für Validierung und Test. Das Bild zeigt auch eine Person, die wahrscheinlich die Präsentation gibt, und einen Text, der aufgerufen wurde, um den englischen Inhalt ins Deutsche zu übersetzen.</sample>
    <sample id="300">Der englische Text lautet: "We apply our method for building a dataset of constrained language planning named as CoScript".</sample>
    <sample id="301">Das Bild zeigt eine Präsentation über "Script Distillation from LLMs" (Script Distillation aus LLMs). Die Präsentation besteht aus zwei Hauptabschnitten: "Motivation" und "Method". Der "Motivation"-Abschnitt erklärt, dass die Ziele der Studie darin liegen, eine begrenzte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen. Der "Method"-Abschnitt beschreibt den Prozess der Script Distillation, der in drei Schritten aufgeteilt ist: 1. Generieren von spezifischen Zielen mit InstructGPT über interaktiver Lernung. 2. Überbereitung von Skripts mit InstructGPT unter Verwendung des Interaktions scores. 3. Filterung von Skripts, die zum Ziel kommen, mit InstructGPT unter Verwendung des Interaktions scores. Darüber hinaus wird erwähnt, dass 55.000 Skripte mit Restriktionen generiert wurden, basierend auf einer Methode, die auf dem Coscript Dataset basiert. Diese Skripte werden dann von Menschen handschriftig überprüft und überprüft. Das Bild zeigt auch ein Video-Chat-Fenster im oberen rechten Eck, das einen Menschen zeigt, der wahrscheinlich über diese Präsentation spricht.</sample>
    <sample id="302">Das Bild zeigt eine Präsentation über 'Constraint Analysis' und 'Coscript for Smaller Language Models'. Links im Bild ist ein Text mit einem Pieschart zu sehen, der verschiedene Kategorien wie 'Ingredient', 'Modifier', 'Method', 'Using', 'By', 'Date', 'Served', 'Calories', 'Price' und 'Source' aufzählt. Jede Kategorie hat eine spezifische Prozentsatzangabe. Rechts oben befindet sich ein kleiner Bildschirm eines Menschen, der in einem modernen Bürobereich steht. Im unteren linken Eck des Bildes sind weitere Informationen über 'Datasets' und 'Metrics' zu finden. Im unteren rechten Eck des Bildes ist ein Graphik, der die 'Accuracy' von verschiedenen Modellen wie GPT-3 (175B), Codex (175B), InstructGPT (175B), T5 (Trained on wikiHow) und T5 (Trained on Coscript) zeigt. Der Text am unteren Rand des Bildes lautet: 'Smaller LM's fine-tuned on Coscript can generate higher quality scripts than LLMs.'</sample>
    <sample id="303">Das Bild zeigt eine Präsentation über 'Spezialisierte Modelle vs. LLMs' (Spezialisierte Modelle vs. Large Language Models). Links auf dem Bild ist ein Diagramm mit den Legenden 'GPT-3 (175B)', 'Codex (175B)', 'InstructGPT (175B)', 'T5 trainiert auf wikiHow' und 'T5 trainiert auf Coscript'. Der Y-Achse ist 'Genauigkeit', und die X-Achse zeigt verschiedene Modelle an. Rechts auf dem Bild ist ein Bild eines Menschen, der wahrscheinlich die Präsentation gibt. Am unteren Rand des Bildes steht die Folge: 'Smaller LM's fine-tuned on Coscript can generate higher quality scripts than LLMs.'</sample>
    <sample id="304">Das englische Textstück auf der rechten Seite des Bildes lautet: 'Establish the constrained language planning problem. Evaluate constrained language planning ability of LLMs and develop an over-generate-then-filter method for LLMs. Use LLMs to generate a high-quality script dataset (CoScript) for constrained language planning.'</sample>
    <sample id="305">Ja, das Bild zeigt eine Person auf einem Laptopbildschirm. Sie sitzt in einem Zimmer mit mehreren Tischen und Stühlen im Hintergrund. Die Person trägt ein grünes Hemd und Brillen.</sample>
    <sample id="306">The 61st Annual Meeting of the Association for Computational Linguistics Toronto, Canada July 8-14, 2023 Distilling Script Knowledge from Large Language Models for Constrained Language Planning Siyu Yuan, Jiangjie Li, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yauhua Xiao, Deqing Yang syyuan21@m.fudan.edu.cn https://github.com/siyuuyuan/coscript</sample>
    <sample id="307">PaLM's fluency is comparable to SOTA, but its accuracy scores are generally lower.</sample>
    <sample id="308">Watermarking is a process that involves embedding additional information, such as copyright or ownership details, into an image file. The watermark can be either visible or invisible and serves to protect the original content from unauthorized use or distribution by making it more difficult for others to claim authorship without permission.</sample>
    <sample id="309">Deutsch, Español, Français, עברית, Italiano, 한국어, Nederlands, Português, Română, Русский, Türkçe, 中文</sample>
    <sample id="310">The image shows a framework for collecting, processing, and analyzing data. The process starts with sampling 300 instances from a dataset to annotate them manually using gold labels. These labeled examples are then used as part of an experiment on the LITW study. Annotations from annotators around the world are collected next.

In the 'Processing' stage, model predictions are made based on these annotations. Following this, demographic information such as age, gender, ethnicity, education level, country, income bracket, etc., is recorded separately for each annotation.

Finally, in the 'Analysis' phase, comparisons between annotated demographics by annotator and those predicted by models and datasets are conducted using Pearson's R scores. This step helps evaluate how well different sources agree or differ regarding various demographic factors.</sample>
    <sample id="311">Delta cosine and the delta L2.</sample>
    <sample id="312">In der Studie wurden Modelle, die auf einem mehrsprachigen Encoder basieren, in der Aufgabe 'Monolingual Setting' eingesetzt.</sample>
    <sample id="344">Die Autoren entscheiden, was Wörter mit mittlerer Häufigkeit sind, indem sie die Wörter aus einem allgemeinen Textkörpers auswählen.</sample>
    <sample id="345">Dieser Vortrag wird von Shuheng Liu und Alan Ritter von der Georgia Institute of Technology gehalten.</sample>
    <sample id="346">Das Bild zeigt eine Präsentationsaufnahme mit dem Titel "Named Entity Recognition &amp; Generalization". Im unteren rechten Eck ist das Logo der Georgia Tech zu sehen. Im unteren linken Eck befindet sich ein kleiner Profilbild eines Menschen. Der Hintergrund des Bildes ist weiß, und der Text ist in einem goldfarbenen Farbton.</sample>
    <sample id="347">Das Bild zeigt eine Präsentationsaufnahme mit dem Titel 'Named Entity Recognition &amp; Generalization'. Der Text auf der Aufnahme lautet: 'Models have been using CoNLL-2003 to develop NER for almost 20 years' und 'Can these models generalize to modern data?'. Im unteren rechten Eck des Bildes befindet sich das Logo von Georgia Tech.</sample>
    <sample id="348">Das Bild zeigt eine Präsentationsaufnahme mit dem Titel "Named Entity Recognition &amp; Generalization". Es gibt drei Punkte: 1. Modelle haben seit fast 20 Jahren CoNLL-2003 verwendet, um NER zu entwickeln. 2. Können diese Modelle sich auf moderne Daten anpassen? 3. Was ist für eine gute Anpassung erforderlich? Im unteren rechten Eck befindet sich das Logo der Georgia Tech.</sample>
    <sample id="349">The image shows a slide from a presentation with the title 'Named Entity Recognition &amp; Generalization'. The content of the slide is as follows: 1. Models have been using CoNLL-2003 to develop NER for almost 20 years. 2. Can these models generalize to modern data? 3. What is needed for good generalization? 4. What causes the performance drop? Additionally, there is an icon in the bottom left corner and a Georgia Tech logo in the bottom right corner.</sample>
    <sample id="350">Der englische Text lautet: 'CoNLL++ Dataset'</sample>
    <sample id="351">Das CoNLL++ Dataset umfasst Reuters-Newsartikel aus dem Jahr 2020 und wurde mit Anmerkungen der CoNLL-2003-Annnotation leitend erstellt. Es wurden mehr als 20 Modelle aufgrund dieser Anmerkungen fine-tuned, und die Leistung dieser Modelle wurde auf den Testset von CoNLL-2003 und CoNLL++ geprüft.</sample>
    <sample id="352">CoNLL++ Dataset</sample>
    <sample id="353">Das englische Text ist 'What Is Needed for Good Generalization?'</sample>
    <sample id="354">Was ist für eine gute allgemeinereignis erforderlich?</sample>
    <sample id="355">Der zweite Bestandteil ist das Modellgröße. Wir haben gefunden, dass typischerweise größere Modelle besser generalisieren können.</sample>
    <sample id="356">Das Bild zeigt eine Präsentation, die sich auf die Bedingungen für gute allgemeine Verarbeitung konzentriert. Der Titel der Präsentation lautet 'Was sind erforderlich für gute allgemeine Verarbeitung?' (Was ist erforderlich für gute allgemeine Verarbeitung?). Die Präsentation umfasst drei Punkte: Modellarchitektur, Modellgröße und Anzahl von fine-tuning-Beispielen. Jeder Punkt wird mit einer Begründung ergänzt. Im Detail sind die Punkte wie folgt: - Modellarchitektur: Transformer-Modelle generalisieren besser. - Modellgröße: Größere Modelle generalisieren besser. - Anzahl von fine-tuning-Beispielen: Mehr Beispiele führen zu besserer allgemeiner Verarbeitung. Darüber hinaus gibt es ein Diagramm, das die Leistung (%) in Bezug auf den Prozentsatz der Trainingsbeispiele zeigt. Das Diagramm zeigt zwei Linien, eine für RoBERTa und eine für Flair, die beide auf einem horizontalen Schwellwert von 0% abbiegen. Im unteren rechten Eck des Bildes befindet sich das Logo der Georgia Institute of Technology.</sample>
    <sample id="357">Was verursacht eine Leistungsverfall?</sample>
    <sample id="358">Das Bild zeigt eine Präsentation mit dem Titel 'Was verursacht einen Leistungsabfall?' in Englisch. Im unteren rechten Ecke befindet sich das Logo der Georgia Tech. Im unteren linken Eck ist ein kleiner Bildausschnitt eines Menschen zu sehen. Die Präsentation diskutiert 'Adaptive Overfitting' als mögliche Ursache für einen Leistungsabfall.</sample>
    <sample id="359">Der englische Text lautet: 'What Causes Performance Drop?'</sample>
    <sample id="360">Die Ursachen für eine Leistungsverlust sind adaptive Übergreifung und zeitliche Drift.</sample>
    <sample id="361">Der englische Inhalt lautet: "What Causes Performance Drop?"</sample>
    <sample id="362">Was verursacht einen Leistungsabfall? Adaptive Overfitting? Keine Minderung der Rendite.</sample>
    <sample id="363">Temporal drift bedeutet, dass sich die Leistung über einen Zeitraum ändert. Es könnte aufgrund von Veränderungen in den Daten oder den Modellparametern auftreten.</sample>
    <sample id="364">Das Bild zeigt eine Präsentation mit dem Titel "Was verursacht einen Leistungsabfall?" (Was causes a performance drop?). Die Präsentation scheint von der Georgia Tech zu stammen, wie die Logo in der unteren rechten Ecke des Bildes anzeigt. Im oberen linken Eck sind einige Punktformen aufgeführt: - Adaptive Overfitting - Keine Diminishing Returns - Nicht beobachtet - Temporal drift? Darunter befindet sich ein Diagramm, das die Leistung in verschiedenen Zeiten zeigt und eine Korrelation zwischen der Zeit und der Leistung anzeigt. Links am Bild ist ein kleiner Profilbild eines Menschen zu sehen.</sample>
    <sample id="365">Der englische Text lautet: "What Causes Performance Drop?"</sample>
    <sample id="366">Das Bild zeigt eine Präsentationsslideset mit dem Titel 'Conclusion'. Der Inhalt der Slide ist auf Englisch und lautet: 'Our conclusion is that for good generalization, we need: - Better model architecture - Larger model size - More fine-tuning examples' Diese Punkte sind auf der linken Seite der Slide aufgeführt. Rechts auf der Slide befindet sich ein Graphik, der die Entwicklung von Modellleistungen von 2004 bis 2022 zeigt. Die Leitlinien im Graphik zeigen verschiedene Modelle wie Stanford NLP, Illinois NER, BLSTM-CNN-CHO, BERT-Large, Flair und LUKE. Im unteren rechten Eck des Slides ist das Logo der Georgia Tech zu sehen.</sample>
    <sample id="367">Der englische Text lautet: 'At the same time, we also found that the performance drop is caused by temporal drift and surprisingly it is not caused by adaptive overfitting even though CoNLL-2003 has been used for over 20 years.'</sample>
    <sample id="368">Das Bild zeigt eine Präsentation, die mit einem Text "Conclusion" beginnt. Der Text auf der linken Seite listet folgende Punkte auf: - Für eine gute Allgemeinheit benötigen wir: - Bessere Modellarchitektur - Größere Modellgröße - Bessere Ausbildungsbeispiele - Die Leistungsschwäche wird durch: - Temporal Drift - Nicht-optimale Übergreifung - Funktionen von CoNLL-2003-Taggern noch funktionieren? Im unteren rechten Eck des Bildes befindet sich ein Logo, das "Georgia Tech" lautet. Darüber hinaus gibt es eine Graphik im unteren rechten Eck, die den Entwicklungstrend von verschiedenen NLP-Methoden über die Jahre 2004 bis 2023 zeigt.</sample>
    <sample id="369">Zum Guten Verständnis des Inhalts der Übersetzung, gebe ich Ihnen hier die Übersetzung des englischen Inhalts ins Deutsche:</sample>
    <sample id="370">Paper: https://arxiv.org/abs/2212.09747 Dataset: https://github.com/ShuhengL/ac12023_conllpp Contact: sliu775@gatech.edu</sample>
    <sample id="397">Sprachsegmentgröße</sample>
    <sample id="398">Es wird entity-specific Wissen benötigt.</sample>
    <sample id="399">Der wichtigste Faktor zwischen der Qualität des Beispiels und der Ähnlichkeit mit dem Ausgangssatz ist die Qualität des Beispiels.</sample>
    <sample id="400">Das Bild zeigt zwei Diagramme, die jeweils einen vertikalen und horizontalen Pfeil haben. Der vertikale Pfeil zeigt eine Aufforderung an, den LM zu ändern, während der horizontale Pfeil auf eine Aufforderung hinweist, den LM zu überarbeiten. Diese Diagramme sind Teil eines Vortrags oder einer Präsentation, die sich mit Sprachmodellen und ihrer Ausrichtung in Bezug auf politische Lehnung auseinandersetzt.</sample>
    <sample id="401">Das Modell verwendet Werte aus mehreren Ebenen.</sample>
    <sample id="402">The most obvious thing is to use a direct reference. For example, by saying the name of the song "easy on me" or its position: the first one.</sample>
    <sample id="403">The authors belong to Fudan University.</sample>
    <sample id="404">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="405">Ja, die Übersetzung der natürlichen Anfrage mit Hilfe eines maschinellen Übersetzungsmodells wurde als Baseline betrachtet, bevor sie durch semantisches Parsing bearbeitet wurde.</sample>
    <sample id="406">Die Autoren haben ein Beispiel gegeben, indem sie 'a warrior' (unmarkiert) und 'a woman warrior' (markiert) nennen.</sample>
    <sample id="407">Transformer models.</sample>
    <sample id="408">The test data sets are called FT_C, LORAC, BitFitFC, AdapterC.</sample>
    <sample id="409">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="439">Knowledge-intensive NLU tasks.</sample>
    <sample id="440">Zhiyang Xu, Ying Shen, Lifu Huang</sample>
    <sample id="441">Ja, Coscript hat eine Qualitätskontrolle durchlaufen.</sample>
    <sample id="442">Grenzen bestehender Ressourcen für kontextbasierte Übersetzung bestehen darin, dass nur ein kleiner Teil von Worten auf Kontext abhängt und die vorhandenen Methoden begrenzte Diskurs-Phänomene und Sprachen unterstützen.</sample>
    <sample id="443">Das englische Text ist: "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)" und "Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti, and Annie Louis".</sample>
    <sample id="444">Das englische Text ist in Deutsch übersetzt.</sample>
    <sample id="445">Indirekte Verweisen können in natürlichen und flüssigen Gesprächen verwendet werden: - Man kann den Namen nicht mehrerkennen - Die Phonologie ist schwierig zu unterscheiden - Man möchte eine Vorliebe angeben</sample>
    <sample id="446">Indirekte Bezeichnung könnte in natürlichem und flüssigem Gespräch verwendet werden:</sample>
    <sample id="447">Indirekte Verweise können in einer natürlichen und flüssigen Gesprächsstruktur verwendet werden.</sample>
    <sample id="448">Indirekte Beziehungsformeln können in natürlichen und flüssigen Gesprächen verwendet werden: - Man kann den Namen nicht mehrerkennung</sample>
    <sample id="449">Indirekte Verweise können bei natürlicher und flüssiger Gesprächsführung verwendet werden: - Man kann den Namen nicht mehrerkennen - Die Aussprache sind schwierig zu unterscheiden - Man möchte eine Vorliebe angeben Indirekte Verweise Beispiel: "Der neue Song" oder "Die Song, der nicht energiegelike ist"</sample>
    <sample id="450">Dies ist ein wichtiger Problem in Konversationssystemen und auch für das Benchmarking von Entity-Understanding bei Large Language Models.</sample>
    <sample id="451">Das Slide zeigt Informationen über die Sammlung von Datensätzen. Es gibt eine Überschrift "Dataset Collection" und eine Liste der wichtigsten Probleme, darunter "Conversational systems" und "Benchmarking Large Language Models' entity understanding". Es wird auch erwähnt, dass kein großes öffentliches Dataset verfügbar ist und dass ein großes Dataset mithilfe von Crowd-Annotation sammelt wird. Die Slide enthält auch drei Bereiche: Musik, Bücher und Rezepte.</sample>
    <sample id="452">Das Dataset-Sammlungsmethode betont die Unformalität durch das Verwenden eines Cartoon-Fill-In-The-Blanks-Aufgaben.</sample>
    <sample id="453">Das Bild zeigt eine Präsentation von Google Research über die Datensammlungsmethode. Die Präsentationskarte besagt, dass die Methode Emotionsalität betont und ein Cartoon-Task verwendet. Das Cartoon zeigt drei Personen mit Sprechblasen, die jeweils eine Frage stellen oder antworten. Eine der Sprechblasen lautet: "Remember that song we were listening to yesterday?" Ein weiterer Text auf der Karte lautet: "Sets the dialog context chosen from a few manual prompts per domain." Eine weitere Blase lautet: "The alternative question." Eine weitere Blase lautet: "Expression referring to one of the entities." Eine weitere Blase lautet: "Filled in by the annotator." Im unteren rechten Eck des Bildes ist ein kleiner Bild eines Mannes zu sehen, der wahrscheinlich den Vortrag gibt.</sample>
    <sample id="454">In the second speech bubble, Alice says: "Do you mean 'Easy on Me' or I've got a feeling?"</sample>
    <sample id="455">The alternative question is 'Do you mean "Easy on Me" or 1 Gotta Feeling?'.</sample>
    <sample id="456">Das Bild zeigt eine Präsentation von Google Research über die Datensammlungsverfahren. Der Titel der Präsentation lautet "Dataset Collection Methodology". Das Hauptthema der Präsentation ist, dass die Methodologie die Unformalität betont, indem sie ein Cartoon-Fill-In-Task verwendet. Die Präsentation zeigt eine Reihe von Zeichnungen von Menschen, die in einem Gespräch sind, und es gibt drei Sprechblasen. Eine der Sprechblasen lautet: 'Remember that I was listening to yesterday?' Diese Sprechblase wurde von einem Annotator gefüllt. Darüber hinaus wird beschrieben, dass das Dialogumfeld aus einigen manuellen Prompten pro Domain gewählt wird, und es gibt eine alternative Frage, die auf einer der Entity's bezieht sich.</sample>
    <sample id="457">Das zweite Bild zeigt eine Alternativefrage. Diese Frage wird von der Annotatoren aus gefüllt und dient als Beispiel für die Methode zur Sammlung von Dialogszenarien.</sample>
    <sample id="458">Dies ist ein Screenshot einer Präsentation, die Informationen über Entity Selection und Entity Correlations bereitstellt. Der Titel der Präsentation lautet "Generate alternative questions =&gt;&gt; sampling entity pairs". Es gibt eine Frage, die lautet: "Do you mean A or B?" Diese Frage wird verwendet, um Entity-Selection-Methoden zu präsentieren. Die Präsentation zeigt mehrere Beispiele für Entity-Selection, wie z.B. "Items with similar infoboxes on Wikipedia (same genre and/or artist)", "Items with similar descriptions on Wikipedia", "Items with similar titles" und "Uniform at random". Im unteren linken Eck des Bildes befindet sich ein roter Pfeil mit dem Text "More Similar (likely harder)". Im unteren rechten Eck des Bildes ist ein kleiner Bild von einem Mann zu sehen, der wahrscheinlich der Sprecher oder der Ersteller der Präsentation ist. Im oberen rechten Eck des Bildes befindet sich das Google Research Logo.</sample>
    <sample id="459">Generiere alternative Fragen =&gt; Entity Paarungen generieren</sample>
    <sample id="460">Der erste Satz lautet: "Items with similar infoboxes on Wikipedia (same genre and/or artist)"</sample>
    <sample id="461">Der zweite Aspekt ist, wenn die Entitys ähnliche Titel haben. Zum Beispiel zwei Bücher mit dem Namen "The Return".</sample>
    <sample id="462">Das Bild zeigt eine Präsentation über die Erstellung von alternativen Fragen für die Identifizierung von Entitäten. Der Titel der Präsentation lautet 'Generate alternative questions =&gt;&gt; sampling entity pairs'. Im Zentrum der Präsentation befindet sich eine Frage: 'Do you mean A or B?' Diese Frage wird verwendet, um entweder Item-A oder Item-B zu identifizieren.

Die Präsentation gibt vier verschiedene Kriterien an, die verwendet werden können, um Item-A oder Item-B zu identifizieren:

1. **Items with similar infoboxes on Wikipedia (same genre and/or artist)**:
   - Beispielfragen: 'Do you mean This is it' oder 'Man in the Mirror'?

2. **Items with similar descriptions on Wikipedia**:
   - Beispielfragen: 'Do you mean Thinking of You' oder 'Happy Anywhere'?

3. **Items with similar titles**:
   - Beispielfragen: 'Do you mean The Return (memoir)' oder 'The Return (Shatner novel)'?

4. **Uniform at random**:
   - Beispielfragen: 'Do you mean You Could Be Mine' oder 'The Way I Am'?

Darüber hinaus gibt es einen roten Pfeil auf der linken Seite des Bildes, der den Text 'More Similar (usually harder)' zeigt, was darauf hinweist, dass die Identifizierung von Items mit ähnlicher Informationbox auf Wikipedia (seltsamer Genre und/oder Künstler) typischerweise schwieriger ist.

Am unteren Rand der Präsentation befindet sich ein Footer, der den Titel der Präsentation 'Reading Indirect Expressions for Entity Selection in Wikidata Conversations' und die Quelle 'Google Research' angibt.</sample>
    <sample id="463">Das Bild zeigt eine Präsentation von Google Research. Der Titel der Präsentation lautet "Background knowledge (Music)". Es gibt zwei Lieder, "Easy on Me" von Adele und "I Gotta Feeling" von The Black Eyed Peas, wobei jeder Lied einen Google-Suchlink gibt, um mehr über das Lied zu erfahren. Darunter steht: "Wir bitten Annotatoren dazu, mindestens einige Lieder zu hören und jede Liedtext zu lesen." Im unteren rechten Eck des Bildes ist ein Mann zu sehen, der wahrscheinlich die Präsentation macht.</sample>
    <sample id="464">Das englische Inhalt ist in Deutsch übersetzt.</sample>
    <sample id="465">Das Bild zeigt eine Screenshot eines Google-Suchergebnisses für die Suchbegriff "Easy on Me". Links im Bild befindet sich ein Video-Playbutton mit dem Text "Adele - Easy On Me (Official Video) - YouTube" darunter. Darüber hinaus sind im unteren linken Eck die Worte "Lyrics" und "Videos" zu sehen. Rechts im Bild sind verschiedene Links wie "Listen", "About", "Similar Artists", "Albums" und "Videos" zu erkennen. Darunter steht der Text "People also search for" gefolgt von mehreren Vorschlägen wie "Someone Like You", "Hello", "Rolling in the Deep" und "Set Fire to the Rain". Im unteren rechten Eck des Bildes ist ein kleiner Profilbild eines Mannes zu sehen. Der Hintergrund des Bildes ist weiß, und oben befindet sich der Google-Logo.</sample>
    <sample id="466">Das Bild zeigt eine Slide von einer Präsentation mit dem Titel "Background knowledge (Recipes)". Es gibt zwei Rezepte: Simnel Cake und Pandan Cake. Jedes Rezept wird mit einem Bild der zugehörigen Kuchen und einer Beschreibung begleitet. Der Text auf der Slide ist englisch, und es gibt auch einen Google Research Logo im oberen rechten Eck. Im unteren rechten Eck des Bildes ist ein kleiner Bild eines Menschen zu sehen.</sample>
    <sample id="467">Das Bild zeigt eine Präsentation, die sich auf die Elicitation von Ausdrücken für Entity Selection in der Autorennaturbehandlung konzentriert. Der Titel der Präsentation lautet "Eliciting expressions". Die Präsentation wurde von Google Research erstellt und zeigt ein Screenshot eines Computerschirms mit einem Text- und Bild-Inhalt. Im Text ist eine Anweisung zu sehen: "Wir sagen den Annotatoren, welche Wahl sie treffen sollen und bitten sie, es zu beschreiben." Diese Anweisung wird durch zwei Kürbchen ergänzt, die "Easy on Me (by Adele)" und "I Gotta Feeling (by the Black Eyed Peas)" enthalten. Darunter steht: "Wir möchten Ihnen 3 bis 5 Ausdrücke für das gewählte Lied geben, um sie in Ihre Sprachblase zu füllen. Zum Beispiel:" Diese Anweisung wird durch eine Liste von Ausdrücken ergänzt, die als Beispiel dienen: - "The one with the piano music" - "The song that's not energetic" - "It has something about a river" - "The never one" - "It is always having time to choose"</sample>
    <sample id="468">Das Bild zeigt eine Präsentation mit dem Titel 'Eliciting expressions'. Es gibt drei Kategorien: Musikauswahl, Buchauswahl und Rezeptauswahl. Jede Kategorie enthält verschiedene Beispiele für Entscheidungen, die Annotatoren treffen sollten, um sie zu beschreiben. Die Kategorie 'Musikauswahl' beinhaltet Beispiele wie 'Chime!' von The Kinks oder 'The one without words'. Die 'Buchauswahl' enthält Beispiele wie 'Warlock (half-novella)' von Neil Gaiman oder 'The Legion of the Dead' von Christopher Priest. Die 'Rezeptauswahl' beinhaltet Beispiele wie 'Beurre Maile de Hâtirou' oder 'The Japanese steamed cake'. Im unteren rechten Eck des Bildes ist ein Portrait eines Menschen zu sehen.</sample>
    <sample id="469">Der englische Text lautet: 'The AltEntities Corpus has ~6,000 alternative questions across the three domains and it has 42,000 indirect referring expressions. Results with T5 XL model (accuracy): 92-95% if the LM has access to the same background knowledge as annotators; 82-87% when the LM has access to partially overlapping background knowledge; ~60% when the LM (T5 XL) has only access to the entity names. We showed models are domain-generalizable.'</sample>
    <sample id="470">图片中的文字内容是：Google Research AltEntities Corpus ~6,000 alternative questions across the three domains ~42,000 indirect referring expressions Results with T5 XL model (accuracy): 92-95% if the LM has access to the same background knowledge as annotators. 82%-87% when the LM has access to partially overlapping background knowledge. ~60% when the LM (T5 XL) has only access to the entity names. We showed models are domain-generalizable. Dataset Link: https://github.com/google-research/datasets/AltEntities</sample>
    <sample id="471">Das englische Inhalt ist auf Deutsch übersetzt.</sample>
    <sample id="472">图片中包含一个Google Research标志。</sample>
    <sample id="473">Popular strategies also applied to offline models.</sample>
    <sample id="474">Die Autoren gehören zur Avignon Universität.</sample>
    <sample id="475">Sebastian Santy, Jenny T. Liang, Ronan Le Bras, Katharina Reinecke, Maarten Sap</sample>
    <sample id="476">Es sind drei Autoren an der Arbeit beteiligt.</sample>
    <sample id="477">Das Bild zeigt eine Präsentation über "Attention as a Guide for Simultaneous Speech Translation" von Sara Papi, Matteo Negri und Marco Turchi. Der Titel der Präsentation ist in einem blauen Feld mit weißen Texten zu sehen. Darunter sind die Namen der Autoren angegeben. Im unteren Teil des Bildes sind Logos der Universität di Trento und der Fondazione Bruno Kessler zu sehen. Rechts oben befindet sich ein kleiner Bildschirm mit einer Frau, die wahrscheinlich die Präsentation führt.</sample>
    <sample id="478">Das Bild zeigt eine Präsentation über 'Simultaneous Speech Translation' (Simultäne Sprachübersetzung). Im oberen rechten Eck befindet sich ein kleiner Bildschirm mit einer Frau, die wahrscheinlich das Präsentationsstück vorläufig liest. Der Haupttext auf der Seite lautet: 'Was ist Simultaneous Speech Translation?' Diese Frage wird in verschiedenen Sprachen (Deutsch, Englisch, Französisch, Spanisch und Italienisch) angezeigt. Links am Bildrand sind einige Audio-Symbolik und Wörter zu sehen, was darauf hindeutet, dass das Thema mit Sprache und Kommunikation verbunden ist. Im Zentrum der Seite ist ein Textblock mit dem folgenden Inhalt: 'Wenn ich im Sommer kalten Tee in meine Thermoskanne gieße, bleibt es kalt, und wenn ich in Winter heizen...' Dieser Text scheint ein Beispiel für die Simultaneous Speech Translation zu sein. Am unteren Rand der Seite befindet sich eine Referenz zum Quellenmaterial: 'Image Credits https://ai.googleblog.com/2021/07/stabilizing-live-speech-translation-in.html' und 'page 03'.</sample>
    <sample id="479">Der englische Text lautet: 'What are the problems of the current SimulST models?'</sample>
    <sample id="480">Specific architectures are usually trained, introducing additional modules to be optimized. Long and complicated training procedures (e.g., different optimization objectives).</sample>
    <sample id="481">Das Bild zeigt eine Präsentation, die sich auf die Probleme der aktuellen SimulST-Modelle konzentriert. Der Titel der Präsentation lautet 'Was sind die Probleme der aktuellen SimulST-Modelle?' (Was sind die Probleme der aktuellen SimulST-Modelle?). Die Präsentation enthält drei Punkte: 1. Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche Modulkomponenten hinzugefügt werden, um optimiert zu werden. 2. Langes und kompliziertes Trainingsverfahren (z.B. verschiedene Optimierungsziele). 3. Das Trainieren und Wartung mehrerer Modelle, um verschiedene Latenzregime zu erreichen (z.B. 1s, 2s,...). Im unteren rechten Eck des Bildes ist eine Person zu sehen, die wahrscheinlich die Präsentation gibt. Im unteren linken Eck befindet sich ein Logo mit dem Text 'M4K'. Im unteren rechten Eck ist die Seitezahl 'Seite 07' angezeigt.</sample>
    <sample id="482">Was ist unsere Lösung?</sample>
    <sample id="483">Der englische Inhalt lautet: 'Use already existing offline ST models without re-training or adopting specific architecture for SimulST.'</sample>
    <sample id="484">The English content is translated into German as follows: 1. Verwenden Sie bereits vorhandene offline ST-Modelle ohne erneutes Training oder die Adoption einer bestimmten Architektur für SimuIST. 2. Gebrauchen Sie nur ein Modell für jeden Latenzregime und verwalten Sie die Latenz über bestimmte Parameter. 3. Nutzen Sie das von der Modell bereits gewonnenes Wissen durch das Aufmerksamkeitsmechanismus zwischen Audioeingang und Textausgabe, was den Aufmerksamkeitsmechanismus zwischen Audioeingang und Textausgabe ist.</sample>
    <sample id="485">Das Bild zeigt eine Präsentation über ein Thema, das 'Encoder-Decoder Attention' genannt wird. Die Texte auf dem Bild sind hauptsächlich in Englisch und deuten darauf hin, dass es sich um einen Aspekt der Sprachverarbeitung handelt. Im oberen rechten Eck ist ein kleiner Bildschirm mit einem Menschen zu sehen, was nahelegt, dass dies möglicherweise ein Online-Vortrag oder eine Online-Klasse sein könnte. Im unteren linken Eck befindet sich ein Logo, und im unteren rechten Eck ist die Seitenummer '014' angezeigt, was darauf hinweist, dass dies das 14. Blatt der Präsentation ist.</sample>
    <sample id="486">Der englische Inhalt lautet: 'Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.'</sample>
    <sample id="487">Das Bild zeigt eine Präsentation, die sich auf ein Problem mit der Übersetzung von Sprachen konzentriert. Der Titel der Präsentation lautet 'Our solution: EDAtt'. Das Hauptthema der Präsentation ist 'Encoder-Decoder Attention', und es wird erklärt, wie die Entscheidung getroffen wird, ob eine Übersetzung komplett oder nur teilweise durchgeführt werden soll. Diese Entscheidung basiert auf der Konzentration des Aufmerksamkeitswesens auf einem Wort. Wenn das Aufmerksamkeitswesen nicht konzentriert ist (das Summum ist unter einem bestimmten Schwellwert), wird die Übersetzung als stabil betrachtet. Im Bild ist auch ein Text zu sehen, der lautet: 'I am going to talk about... and our model predicts the translation in German...' Diese Informationen deuten darauf hin, dass die Präsentation möglicherweise über ein Modell geht, das für die Übersetzung von Texten in verschiedenen Sprachen verwendet wird.</sample>
    <sample id="488">Das Bild zeigt eine Präsentation über die Encoderv-decoder-Atten-tion. Der Titel der Präsentation lautet 'Our solution: EDAtt'. Der Haupttext lautet 'Encoder-Decoder Attention' und gibt an, dass es sich um eine Lösung für die Entscheidung handelt, ob eine Teilübersetzung oder nicht eine Teilübersetzung sein sollte, basierend auf der Konzentration der Aufmerksamkeit auf einen Wort, wenn die Aufmerksamkeit nicht konzentriert ist (seine Summe liegt unter einem Threshold c), bis zu den letzten Sprachrahmen, was bedeutet, dass die empfangene Information stabil ist. Im unteren linken Bereich des Bildes ist ein Audio-Symbol zu sehen, und darunter steht 'Ich werde reden.' Die Slide ist auf Seite 016 markiert.</sample>
    <sample id="489">Das Bild zeigt eine Präsentation über "Encoder-Decoder Attention". Im oberen linken Eck befindet sich der Text "Our solution: EDAtt". Im unteren linken Eck ist ein Diagramm zu sehen, das den Prozess der Aufnahme von Sprachrammen darstellt. Der Text auf dem Diagramm lautet "Ich werde reden." Im unteren rechten Eck ist der Text "page 017" zu sehen.</sample>
    <sample id="490">Das bedeutet, dass die ersten zwei Wörter weggelassen werden.</sample>
    <sample id="491">Das Bild zeigt eine Präsentation über die 'Encoder-Decoder Attention'. Die Texte auf dem Bild sind in Englisch, und ich werde sie ins Deutsche übersetzen. Hier ist die Übersetzung:</sample>
    <sample id="492">Das Bild zeigt eine Präsentation über die 'Encoder-Decoder Attention'. Es gibt zwei Diagramme, die den Prozess der Emittierung und des Erkennens von Worten im Kontext einer Sprachverarbeitung darstellen. Links auf dem Bild ist das Wort 'ich werde reden' zu sehen, und rechts ist das Wort 'Ich werde Klima sprechen' zu erkennen. Im oberen rechten Eck des Bildes befindet sich ein kleiner Bildschirm eines Menschen, der wahrscheinlich die Präsentation führt.</sample>
    <sample id="493">Der englische Text lautet: 'Decide whether to emit or not a partial translation based on where attention points to: a word is emitted if the attention is not concentrated (its sum is below a threshold) towards the last λ speech frames, meaning that the received information is enough stable.'</sample>
    <sample id="494">Dies bedeutet, dass diese drei Wörter emittiert werden.</sample>
    <sample id="495">Das Hauptergebnis ist EDAtt.</sample>
    <sample id="496">The graph shows the relationship between BLEU and AL/AL_CA (s) for an en→de translation task. The x-axis represents the ratio of AL to AL_CA in seconds, ranging from 0.5 to 6. The y-axis measures the BLEU score, which ranges from approximately 17 to 27. There is a label on the left side indicating "quality measure," with 'BLEU' highlighted within it. At the bottom center of the graph, there's another label that reads "latency measure."</sample>
    <sample id="497">Das Bild zeigt eine Präsentation, die sich auf die Hauptergebnisse einer Forschungsarbeit konzentriert. Der Titel der Präsentation lautet 'Main Results: EDAtt'. Im Zentrum des Bildes befindet sich ein Graph, der die BLEU-Score-Anzahl gegen den AL/AL_CA (s) -Wert für die Sprache Paar 'en-de' anzeigt. Der Graph ist leer, was darauf hindeutet, dass die Daten noch nicht eingegeben wurden oder das Ergebnis noch nicht bereitgestellt wurde. Im unteren rechten Ecke des Bildes ist der Text 'latency measure' zu sehen, was darauf hinweist, dass die Latenzmessung im Kontext der Forschung wichtig ist. Im oberen rechten Eck des Bildes befindet sich ein kleiner Bildschirm, der eine Person zeigt, die wahrscheinlich über Skype oder einem ähnlichen Video-Konferenz-Tool teilnimmt. Im unteren linken Eck des Bildes ist ein Logo sichtbar, und im unteren rechten Eck ist der Text 'page 030' zu sehen, was darauf hinweist, dass dies die Seite 030 der Präsentation ist.</sample>
    <sample id="498">Der englische Text lautet: 'Main Results: EDAtt' und '(a) en→de'.</sample>
    <sample id="499">Der englische Inhalt lautet: 'Main Results: EDAtt' und '(a) en→de'.</sample>
    <sample id="500">Das Bild zeigt eine Präsentation über die Ergebnisse einer Forschungsarbeit. Im oberen rechten Eck ist ein kleiner Bildschirm mit einem Menschen zu sehen, der wahrscheinlich die Präsentation gibt. Der Hauptinhalt des Slides lautet 'Main Results: EDAtt' und zeigt einen Graphen mit den Legenden 'wait-k', 'LA', 'CAAT' und 'EDAtt'. Der Graph zeigt die BLEU-Score in Bezug auf AL/AL_CA (s) für die Übersetzung von Englisch ins Deutsche. Im oberen Teil des Slides steht der Text 'popular strategies also applied to offline models' und 'state of the art architecture specifically tailored for Simultaneous Translation'. Im unteren linken Eck ist ein Logo zu sehen, und im unteren rechten Eck befindet sich die Seite 'page 033'.</sample>
    <sample id="501">Der englische Text lautet: 'Main Results: EDAtt' und 'wait-k LA CAAT EDAtt'.</sample>
    <sample id="502">The English content in the image is: 'Main Results: EDAtt' and 'EDAtt outperforms all the strategies applied to offline models'.</sample>
    <sample id="503">Das englische Inhalt ist auf Deutsch übersetzt und lautet: 'Die Hauptergebnisse sind EDAtt. EDAtt ist der schnellste Strategie, wenn wir die tatsächliche verstrickte Zeit berücksichtigen.'</sample>
    <sample id="504">Das Bild zeigt eine Präsentation, die Informationen über ein Forschungsprojekt bereitstellt. Im oberen rechten Eck befindet sich ein kleiner Bildschirm mit einem Menschen, der wahrscheinlich die Präsentation gibt. Der Haupttext auf der Seite lautet 'Do you want to discover more?' und 'Read our paper to discover more results'. Darunter sind Kontaktdaten für mehrere Personen aufgeführt, einschließlich E-Mail-Adressen und GitHub-Links. Es gibt auch einen QR-Code mit der Anweisung 'Scan me!' und eine Referenz auf Seite 038.</sample>
    <sample id="505">Ja, der Dataset ist öffentlich zugänglich.</sample>
    <sample id="506">MULTIINSTRUCT: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning Zhiyang Xu* Ying Shen* Lifu Huang Department of Computer Science, Virginia Tech *Equal Contribution</sample>
    <sample id="507">Die englischen Inhalte der Bilder sind auf Deutsch übersetzt.</sample>
    <sample id="508">Das Bild zeigt eine Präsentation über "Vorgegebene Sprachmodellierung für Niedrigsatzaufgaben". Es gibt drei Hauptbereiche: (A) Pretrain-finetune (BERT, T5), (B) Prompting (GPT-3) und (C) Instruktionsanpassung (FLAN). Jeder Bereich hat eine Illustration, die den Prozess der Modelltraining und -nutzung für verschiedene Aufgaben darstellt. Im unteren linken Eck befindet sich ein Text, der lautet: 'Figure 2: Vergleich von Instruktionsanpassung mit pretrain-finetune und Prompting.' Darunter steht: 'Image credit: Wei, Jason, et al. "Vorgegebene Sprachmodelle sind zero-shot-Learner."'</sample>
    <sample id="509">Das Bild zeigt eine Person mit kurzen Haaren, die ein schwarzes Jackett und eine weiße Krawatte trägt. Sie sitzt vor einem schwarzen Hintergrund mit der Aufschrift 'Language-only' in weißem Text. Im unteren rechten Eck des Bildes ist ein kleineres Bild der Person zu sehen, das ihre Oberkörper zeigt.</sample>
    <sample id="510">Das Bild zeigt einen Titelbildschirm mit dem Text 'Instruction Tuning on Multimodal Pre-trained Models'. Der Text 'Multimodal' ist in gelb und 'Pre-trained Models' ist in weiß. Im unteren rechten Eck des Bildes befindet sich eine Person, die offensichtlich spricht. Die Hintergrundfarbe des Bildes ist schwarz.</sample>
    <sample id="511">Imbalanc in Instructional Datasets between NLP and Multimodal</sample>
    <sample id="512">Das Bild zeigt eine Präsentation mit dem Titel 'Imbalance in Instructional Datasets between NLP and Multimodal'. Der Schwerpunkt liegt auf der Unterschiede zwischen Sprachbasierten und Multimodalen Datenbanken. Die Präsentation betont, dass es mehr als 1600 Sprachbasierte Anweisungsverfahren gibt, aber keine großen, öffentlich zugänglichen Multimodalen Anweisungsverfahren. Es wird auch erwähnt, dass dies dazu motiviert, ein Multimodales Anweisungsdatensatz zu erstellen. Im unteren rechten Eck des Bildes ist eine Person zu sehen, die wahrscheinlich über das Thema spricht.</sample>
    <sample id="513">Das Bild zeigt eine präsentationelle Slide mit dem Titel "MULTINSTRUCT". Die Slide beschreibt das erste multimodale Instruction-Tuning-Benchmark-Dataset. Es gibt 62 verschiedene multimodale Aufgaben, 10 Gruppen und 5 expertisch geschriebene Anweisungen. Die Slide enthält auch ein Diagramm mit verschiedenen Aufgabenfeldern wie "Visual Relationship", "Grounded", "Image Understanding" und "Region Understanding". Das Diagramm zeigt, welche Aufgaben in jedem Bereich enthalten sind. Im unteren rechten Eck der Slide ist ein kleiner Bild von einer Person zu sehen.</sample>
    <sample id="514">MULTINSTRUCT: Der erste multimodales Instruktions-Tuning-Benchmark-Datensatz.</sample>
    <sample id="515">OFA (One For All) is a unified multi-modal pre-trained model capable of performing both understanding and generation tasks with single or multiple modalities. It has a unified vocabulary for language, image tokens, and the coordinates of a bounding box.</sample>
    <sample id="516">Hier zeigen wir einige Beispielinstanzen aus unserem Multi-instruct-Datensatz.</sample>
    <sample id="517">Das Bild zeigt eine Übersetzung des englischen Inhalts ins Deutsche. Der englische Text lautet: "To unify the processing of a variety of input and output data types." Die deutsche Übersetzung lautet: "Um eine Vielzahl von Eingabedaten und -typen sowie Ausgabedaten zu vereinbaren." Diese Übersetzung verdeutlicht die Absicht, verschiedene Datenstrukturen zu harmonisieren, um effizientere Verarbeitung und Kommunikation zu ermöglichen.</sample>
    <sample id="518">Das Bild zeigt eine visuelle Darstellung von Beispiel-Einheiten aus dem MultiInstruct-Projekt. Der Titel "MULTIINSTRUCT" ist oben in weißer Schrift prominent angezeigt. Im unteren Teil des Bildes befindet sich ein Text, der lautet: 'Figure 1: Example Instances from MULTIINSTRUCT for Four Tasks.' Diese Texte sind in einem quadratischen Layout organisiert, wobei jeder Block eine verschiedene Aufgabe darstellt: - "Grounded Caption": Hiermit wird die Aufgabe beschrieben, eine Bildbeschreibung zu erstellen. - "Text Localization": Dies befasst sich mit der Identifizierung eines bestimmten Texts im Bild. - "Referring Expression Selection": Diese Aufgabe umfasst die Auswahl eines Referenzausdrucks für ein Objekt im Bild. - "Question-Image Matching": Dies handelt sich um die Korrektur einer Frage aufgrund eines Bildes. Jeder Block enthält Details über den Input und den Output, was die spezifischen Anforderungen und Ergebnisse dieser Aufgaben demonstriert.</sample>
    <sample id="519">Das Bild zeigt eine Person, die auf einem Computer-Screen spricht. Der Hintergrund ist schwarz, und auf dem Bildschirm steht in weißer Schrift "Multi-modal Instruction Tuning". Die Person trägt ein weißes Hemd und scheint sich zu befinden in einem Arbeitsbereich oder einer Präsentation.</sample>
    <sample id="520">Das Bild zeigt eine Präsentation über 'Multi-Modal Instruction Turning'. Es gibt zwei Hauptabschnitte: 'Training Dataset Construction' und 'Testing Dataset Construction'. Im 'Training Dataset Construction'-Abschnitt wird beschrieben, dass 53 Aufgaben von 9 Gruppen für die Ausbildung verwendet werden, und jeder Task wird mit 10.000 Instanzen belegt. Im 'Testing Dataset Construction'-Abschnitt wird erklärt, dass der gesamte Common Sense Reasoning-Group für die Prüfung reserviert wurde, und fünf weitere Aufgaben aus den Gruppen VQA und Miscellaneous ausgewählt wurden. Außerdem werden alle Instanzen für jeden Task während der Testprüfung verwendet. Zudem werden 20 Instanzen aus dem Test-Set des Natural Instructions-Datensatzes zufällig für die Prüfung von NLP-Methoden ausgewählt.</sample>
    <sample id="521">Das Bild zeigt eine Präsentation mit dem Titel "Multi-Modal Instruction Turning". Es gibt zwei Hauptabschnitte: Training Dataset Construction und Testing Dataset Construction. Im Training Dataset Construction wird beschrieben, dass 53 Aufgaben von 9 Gruppen für die Ausbildung verwendet werden und jeder Aufgabe 10.000 Instanzen enthält. Im Testing Dataset Construction wird festgelegt, dass der Entire Commonsense Reasoning-Group für die Testaufgaben reserviert wird, 5 zusätzliche Aufgaben aus VQA und Miscellaneous-Gruppen ausgewählt werden und alle Instanzen aus der Testsplit für jede Aufgabe verwendet werden. Zudem werden zufällig 20 Aufgaben aus der Testsplit des Natural Instructions-Datensatzes ausgewählt, um neue Aufgaben für NLP zu identifizieren.</sample>
    <sample id="522">Das Bild zeigt eine Präsentation mit Details über die Implementierung. Der Titel lautet "Implementation Details". Es gibt zwei Hauptabschnitte: "Training details" und "Testing details".

Under "Training details", es gibt drei Punkte:
1. Pre-trained OFA-Large model (472M)
2. Mix all the instances for all tasks.
3. Each instance is randomly combined with one of its five instruction templates.

Under "Testing details", es gibt drei Punkte:
1. For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
2. We report the mean and maximum performance and the standard deviation of the performance across all five experiments.

Im unteren rechten Eck des Bildes ist ein kleiner Bildschirm eines Menschen zu sehen, der wahrscheinlich die Präsentation gibt.</sample>
    <sample id="523">Das Bild zeigt eine Präsentation mit dem Titel "Implementation Details". Es gibt zwei Hauptabschnitte: Training details und Testing details. Im Abschnitt Training details sind die folgenden Punkte aufgeführt: - Pre-trained OFA-Large model (472M) - Misch all die Instanzen für alle Aufgaben - Jede Instanz wird zufällig mit einer der fünf Anweisungslisten kombiniert. Im Abschnitt Testing details sind die folgenden Punkte aufgeführt: - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir den Modell mit einer der fünf Anweisungen in jedem Experiment auswerten. - Wir berichten die Durchschnitts- und höchste Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente. Im unteren rechten Eck des Bildes ist ein Mann zu sehen, der wahrscheinlich die Präsentation abgibt.</sample>
    <sample id="524">Implementation Details Training details: - Pre-trained OFA-Large model (472M) - Mix all the instances for all tasks. Each instance is randomly combined with one of its five instruction templates. Testing details: For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment. We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="525">Das Bild zeigt eine Präsentation über die Bewertungsmaßstäbe für verschiedene Aufgaben. Die Titelseite lautet "Bewertungsmaßstäbe". Es gibt vier Punkte, die jeweils auf eine bestimmte Art und Weise bewertet werden: 1. Multimodale Klassifizierungsaufgaben (z.B. visueller Entzug, visueller Raum, natürlicher Sprachverarbeitung, visuelle Verarbeitung und Katastrophen-Typen) - Accuracy wird berichtet. 2. Multimodale Generierungsaufgaben (z.B. Commonsense VQA, Text VQA, grounded VQA, visuelle Textauswahl und visuelle Dialog) - Rouge-L wird berichtet. 3. NLP-Aufgaben - Rouge-L wird berichtet. 4. Aggregiertes Leistungsbild für jede Modellinstanz basierend auf der Durchschnittsleistung auf allen multimodalen und NLP-Unerkannten Aufgaben - Rouge-L wird als Leistungsmerkmal für die meisten Aufgaben verwendet, und Accuracy wird nur als Merkmal verwendet.</sample>
    <sample id="526">Das Bild zeigt eine Präsentation über die Sensitivität eines Modells. Der Titel lautet "Sensitivität", und es gibt eine Definition von Sensitivität als die Fähigkeit des Modells, auf eine Vielzahl von Anweisungen für dieselbe Aufgabe reagieren zu können, unabhängig von kleinen Variationen in der Wortung der Anweisungen. Im Bild ist auch ein Mathematischer Ausdruck zu sehen, der wahrscheinlich den Begriff der Sensitivität mathematisch definiert.</sample>
    <sample id="527">Effectivenss der Anweisungsablageinstellung auf MULTIINSTRUCT</sample>
    <sample id="528">Das Bild zeigt eine Präsentation über die "Wirkung der Anpassung von Anweisungen auf MULTIINSTRUCT". Es gibt zwei Tabelle, die die Leistung bei der Zero-Shot-Performance auf Multimodal-Anweisungsverarbeitung zeigen. Die Tabelle zeigt verschiedene Anwendungsfälle wie "Commonsense VQA", "Visual Entailment", "Visual Spatial Reasoning" und "NLI-R". Die besten Ergebnisse sind in Fett dargestellt.</sample>
    <sample id="529">Here we can see as the amount of task increases, the model achieves better performance and in the meantime a lower sensitivity.</sample>
    <sample id="530">Effect of Diverse Instructions on Instruction Tuning OFA finetuned on 5 instructions achieves much higher aggregated performance on all evaluation tasks and shows lower sensitivity. Table: 3: Effect of Different Number of Instructions. Performance of OFA-Mainfinetuned finetuned on different numbers of instructions.</sample>
    <sample id="531">Das Bild zeigt eine Präsentation, die sich auf die Auswirkungen von Feinabstimmungsstrategien auf die Sensitivität von Modellen konzentriert. Der Titel lautet 'Wirkung von Feinabstimmungsstrategien auf die Sensitivität von Modellen'. Es gibt zwei Hauptpunkte: 1. Feinabstimmungsstrategien auf Multilinstruct können die Sensitivität des OFA-Modells erheblich reduzieren. 2. Das Lernen von Transfer aus dem Natural Instructions-Dataset kann die Sensitivität weiter verringern. Im Bild ist ein Diagramm zu sehen, das die Sensitivität auf verschiedenen Evaluation-Tasks zeigt. Die Sensitivität wird auf einer Skala von 0 bis 40 gemessen, wobei niedrigere Werte besser sind. Die verschiedenen Strategien sind als Farben gekennzeichnet, wobei OFA-Multilinstruct in Rot, OFA-Simplistic in Grün und OFA-Accelerate in Blau dargestellt sind. Das Diagramm zeigt, dass OFA-Multilinstruct eine Sensitivität von 40.58 aufweist, OFA-Simplistic eine von 13.84 und OFA-Accelerate eine von 10.27. Am unteren Rand des Bildes steht der Text 'Figure 4: Sensitivität auf unbekannten Evaluation-Tasks. Niedrigere Werte sind besser.' Diese Informationen deuten darauf hin, dass die Verwendung von Feinabstimmungsstrategien und der Einsatz von Transfer-Learning-Datensätzen bei der Reduzierung der Sensitivität von Modellen hilfreich sein können.</sample>
    <sample id="532">Das Bild zeigt eine Präsentation über die Leistung von NLP-Methoden bei Zero-Shot-Performance auf einem bestimmten Dataset. Der Titel lautet "Zero-Shot Performance on NLP Tasks". Es gibt zwei Hauptpunkte: 1. Instruction Tuning auf Multinstruct verbessert die Zero-Shot-Performance für unbekannte NLP-Tasks. 2. Die Transfer-Learning-Strategie MixedInstruct kann die Kapazität der Zero-Shot-Performance auf dem Natural Instructions-Dataset verbessern. Im Tableau sind verschiedene Modelle und ihre Leistungen in der Rouge-L-Meteoriat abgebildet. Die Modelle sind OFA, OFA-Multinstruct und Transfer Learning aus natürlichen Anweisungen. Das Tableau zeigt die Leistungen dieser Modelle in Form von Zahlen.</sample>
    <sample id="533">Das Bild zeigt eine Präsentationsslides mit dem Titel "Conclusion". Der Inhalt der Slides lautet:</sample>
    <sample id="534">Das Bild zeigt eine schwarze Hintergrundfläche mit einem QR-Code und einem Text. Der Text lautet: 'One More Thing Wir sammeln einen viel größeren multimodalen Anweisungsdatensatz mit etwa 150 zusätzlichen visuellen Sprachaufgaben und freigeben sie bald!' Darunter steht der Text: 'Dies ist ein QR-Code für unsere Daten und Modelle. Vielen Dank.' Im unteren rechten Eck des Bildes ist ein kleiner Bildausschnitt eines Menschen zu sehen, der aufmerksam auf das Bildschirmbild schaut.</sample>
    <sample id="535">Die Autoren gehören der Universität di Trento an.</sample>
    <sample id="536">Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti, Annie Louis</sample>
    <sample id="562">ACL 2023</sample>
    <sample id="563">Das Bild zeigt eine Präsentation mit dem Titel "Language model acceptability judgements are not always robust to context". Die Präsentation wurde im Jahr 2023 am ACL (Association for Computational Linguistics) gehalten. Es sind mehrere Universitäten und Forschungsgruppen genannt, darunter Johns Hopkins University, Purdue University und MIT, sowie die Meta AI-Forschungsgemeinschaft. Darüber hinaus sind die Namen von mehreren Autoren aufgeführt: Koustuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Mishra, Keren Fuentes, Roger Levy und Adina Williams.</sample>
    <sample id="564">In diesem Werk widmen wir uns erneut der Minimal-Pair-Paradigm.</sample>
    <sample id="565">Das englische Inhalt auf Deutsch übersetzt: 'Minimal Paar-Paradigma (MPP) Bewertungen von Sprachmodellen verwenden relativen Unterschiede in Folgeverwaltungsverhältnissen um die akzeptable Kenntnis von LM zu bewerten.'</sample>
    <sample id="566">Der englische Inhalt lautet: 'Revisiting Minimal Pair Paradigm Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:'</sample>
    <sample id="567">Der englische Inhalt lautet: 'Revisiting Minimal Pair Paradigm. Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs.'</sample>
    <sample id="568">Revisiting Minimal Pair Paradigm</sample>
    <sample id="569">Dieser Tag kommen große Sprachmodellierungen mit längeren und längeren Kontextfenstern heraus. Es ist entscheidend, dass wir die Modellfähigkeiten auf der gesamten Kontextfensterbewertung einschätzen.</sample>
    <sample id="570">图片中的文字内容包括标题、副标题和三个部分的标题，分别是“BLiMP”、“SyntaxGym”和“CrowS”。每个部分下面都有句子和概率公式。在“SyntaxGym”部分下面有一个问题：“这些判断是否在较长的上下文中保持稳定？”</sample>
    <sample id="571">Das Bild zeigt eine Präsentation, die sich auf einen Ansatz konzentriert, um die Entscheidungen von MPP (Minimum Phrase Length) in Bezug auf die Längen der Phrasen, strukturelle Aspekte und akzeptabilität zu testen. Der Titel des PPTs lautet "Approach". Im oberen rechten Eck des Bildes ist ein kleiner Bild von einem Mann zu sehen, der wahrscheinlich den Vortrag gibt. Im unteren linken Eck befindet sich ein Diagramm mit Texten und Grafiken, das verschiedene Aspekte und Beispiele der Analyse der akzeptablen und unakzeptablen Phrasenpräfixe darstellt.</sample>
    <sample id="572">图片中的文字内容包括： 1. 标题：Approach 2. 主要文本：Test whether MPP judgements vary as a function of context length, structural match, and acceptability 3. 公式：P(MP|PreFix) &gt; P(EM|PreFix) 4. 图表标题：Space of Candidate Prefixes 5. 图表标签：- Build Agreement - Matched - Unmatched - Coherence - Syntactic 6. 图表说明：- Sample 7. 图表右侧的注释：- "What fees might Rose fee from this customer before returning to this customer?" - "What Jessica would will notice before noticing the museum?" - "What Jessica could have noticed before noticing the museum?" - "What Rose might fee from this customer before returning to this customer?" 8. 底部文字：GPT2, OPT family - 125M to 6.7B 9. 右下角的文字：BLIMP, Island</sample>
    <sample id="573">Der englische Inhalt lautet: 'And what we do is that to recreate longer sequences and which are acceptable and which has the same matching of the grammatical structure, we extract grammatical sentences from adjacent islands.'</sample>
    <sample id="574">Der englische Inhalt lautet: 'Test whether MPP judgements as a function of context length, structural match, and acceptability.'</sample>
    <sample id="575">Der englische Text lautet: 'We can do the same thing by choosing unacceptable sentences from the same matching and that could also be used to test the model's acceptability.'</sample>
    <sample id="576">Der englische Text lautet: 'And we can also do the same by choosing sentences from a different subset or a different data set. So that is what we call as the mismatched scenario.'</sample>
    <sample id="577">The text in the image is 'BLUMP, Essential "Tweeters" Quantifiers'.</sample>
    <sample id="578">Schließlich können wir zwei Sätze aus einem vollständig unverwandten Bereich wählen, wie Wikipedia.</sample>
    <sample id="579">Der englische Inhalt lautet: 'Test whether MPP judgements as a function of context length, structural match, and acceptability.'</sample>
    <sample id="580">Der englische Inhalt lautet: "Test whether MPP judgements as a function of context length, structural match, and acceptability".</sample>
    <sample id="581">Der englische Text lautet: 'MPP judgements are robust for arbitrary context lengths.'</sample>
    <sample id="582">MPP评判在任意上下文长度下是稳健的。</sample>
    <sample id="583">Der englische Inhalt lautet: "Now what happens when we choose sentences from the same dataset?"</sample>
    <sample id="584">Hier sind die Übersetzungen der englischen Sätze ins Deutsche: 1. "So hier, wir wählen oder schaffen Sentenzen aus" wird zu "Also hier, wir wählen oder schaffen Sentenzen aus". 2. "und schaffen Sentenzen aus akzeptierbaren und unakzeptierbaren Domänen" wird zu "und schaffen Sentenzen aus akzeptierbaren und unakzeptierbaren Bereichen". 3. "aus dem gleichen BLIMP oder Syntax Gym-Datensatz" wird zu "aus demselben BLIMP oder Syntax Gym-Datensatz".</sample>
    <sample id="585">Es gibt zwei Sätze, die auf der rechten Seite des Bildes zu sehen sind. Der erste Satz lautet: 'There was a documentary about music inflating. Who might Rise lose from this before using the customer?' Der zweite Satz lautet: 'There were most legislations about music inflating. Who might Rise lose from this before using the customer?'</sample>
    <sample id="586">Der englische Inhalt lautet: 'We perform MPP evaluations with different contexts – acceptable / unacceptable; matched/mismatched structure – of lengths up to 900 tokens.'</sample>
    <sample id="587">Der englische Inhalt lautet: 'We perform MPP evaluations with different contexts – acceptable / unacceptable; matched/mismatched structure – of lengths up to 900 tokens.'</sample>
    <sample id="588">Dies betrifft die Verarbeitung von Kontexten in Sprachmodellen.</sample>
    <sample id="589">Das Bild zeigt eine Präsentation über den Einfluss von passenden Präfixen auf die LMS (Language Model Sensitivity) Bewertungen. Der Titel lautet "Warum beeinflussen passende Präfixe die LMS Bewertungen?" Und es gibt eine Erklärung, dass Kontextsätze verändert werden, um die relevante Struktur zu erhalten und fragt, ob Modelle sensible sind gegenüber diesen Sätzen. Die Sätze im Bild zeigen, wie Passingspräfixe und -adverbien den Sinn ändern können, was auf die Bedeutung der Kontextstruktur in Sprachmodellen hindeutet.</sample>
    <sample id="590">Das Bild zeigt eine Präsentation über den Einfluss von passenden Präfixen auf die Bewertungen von LM (Language Models). Die Titelseite lautet: "Warum beeinflussen passende Präfixe die Bewertungen von LM?" Der Text auf der Seite lautet: "Wir perturben Kontextsätze, um die relevante Struktur zu erhalten und fragen uns, ob Modelle auf diese Satze reagieren. - Prefix/suffix-Adverbien: 'However, &lt;sent&gt;.' - Long-Präfix-Adverbien: 'First and foremost, &lt;sent&gt;.' - Add-Klausel: 'Regardless of what X denkt darüber, &lt;sent&gt;.' - Zitat: 'Gestern, X sagte, &lt;sent&gt;.' Darunter sind Graphen zu sehen, die den Einfluss unterschiedlicher Perturbationsarten auf die Genauigkeit von LM in Bezug auf die Längen der Eingaben darstellen.</sample>
    <sample id="591">Das Bild zeigt eine Präsentation mit dem Titel "Warum beeinflussen Paare von Präfixen die Bewertungen von LM?". Die Präsentation diskutiert, wie Kontextsätze in Weise verändert werden können, um ihre strukturelle Integrität zu erhalten und fragt, ob Modelle für diese Sätze empfindlich sind. Der Text auf der Seite lautet: "Wir verändern Kontextsätze in Weise, um ihre strukturelle Integrität zu erhalten, und fragen, ob Modelle für diese Sätze empfindlich sind." Darüber hinaus sind auf der Seite mehrere Beispiele von Sätzen mit den Anmerkungen "Prefix/suffix-Adverbien: 'However, &lt;sent&gt;.'", "Long prefix-Adverbien: 'First and foremost, &lt;sent&gt;.'", "Add clause: 'Regardless of what X denkt über es, &lt;sent&gt;.'", und "Quote: 'Yesterday, X sagte, &lt;sent&gt;.'". Darüber hinaus gibt es eine Legende zur Abbildung, die verschiedene Perturbationsarten und Typen von Präfixen auflistet, wie "None", "Prefix/suffix adverb", "Long prefix adverb", "Add clause", "All", "Acceptable" und "Unacceptable".</sample>
    <sample id="592">Die Übersetzung des englischen Inhalts lautet: "Warum beeinflussen Präfixe die Bewertungen von LM?"</sample>
    <sample id="593">Ja, das Bild zeigt eine Präsentation über die Auswirkungen von Übereinstimmungspräfixen auf die LM-Schätzungen. Die Präsentation zeigt verschiedene Sätze und eine Grafik, die die Veränderung der Distanz-Genauigkeit bei verschiedenen Perturbation-Typen und Input-Längen darstellt.</sample>
    <sample id="594">Die Haupttakeaways unserer Arbeit sind, dass Sprachmodelle auf verborgene syntaktische/semantische Merkmale reagieren, die sich über Sätze verteilen, und dass die Bewertungen von LMs mit kurzen, einzelnen Satz-Inputnicht die abstrakte Wissen der LMs umfassen.</sample>
    <sample id="595">The English content in the image translates to: 'Key Takeaways Language models are sensitive to latent syntactic/semantic features shared across sentences. MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.'</sample>
    <sample id="596">Die Hauptzusammenfassung des englischen Textes lautet: "Sprachmodelle sind auf versteckte syntaktische/semantische Merkmale im Ganzen über Satze verteilt. Evaluierungen von MPP mit kurzen, einzelnen Satz inputs reichen nicht aus, um die abstrakte Merkmale von LM zu erfassen."</sample>
    <sample id="597">Unordered multiset</sample>
    <sample id="598">55,000</sample>
    <sample id="626">Die beste Ausrichtungsmethode für DEplain ist CATS-C3G.</sample>
    <sample id="627">Weakly supervised learning trains models that generalize well despite being trained on noisy data.</sample>
    <sample id="628">The documents in DEplain-web were aligned using both manual and automatic methods.</sample>
    <sample id="629">CoNLL++-Dataset wurde von Reuters-Newsartikeln aus dem Jahr 2020 sammelt und mit den Annotierungsleitlinien von CoNLL-2003 angelegt.</sample>
    <sample id="630">Das Bild zeigt eine Präsentation mit dem Titel "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations". Der Vortrager ist Yusen Zhang, zusammen mit Jun Wang, Zhiguo Wang und Rui Zhang. Das Bild enthält auch Logos von PennState und Amazon. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm zu sehen, auf dem der Vortrager erscheint, der wie am Laptop arbeitet.</sample>
    <sample id="631">Semantic Parsing ist eine Aufgabe, die es ermöglicht, semantische Representationen von Benutzerfragen zu erstellen, wie z.B. SQL und Lambda Calculus.</sample>
    <sample id="632">Cross-lingual Semantic Parsing</sample>
    <sample id="633">Cross-lingual Semantic Parsing Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations.</sample>
    <sample id="634">Cross-lingual Semantic Parsing</sample>
    <sample id="635">Das englische Inhalt auf dem Bild lautet: 'Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain natural language'</sample>
    <sample id="636">Lack of coverage on certain meaning representations</sample>
    <sample id="637">Der Lambda-Kalkül ist fehlerhaft.</sample>
    <sample id="638">Cross-lingual Semantic Parsing Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain neural model SQL German Chinese Single Model Lambda FunQL</sample>
    <sample id="639">Das Bild zeigt eine Präsentation über XSemPLR, einem Dataset für die semantische Parsing in mehreren natürlichen Sprachen. Der Text auf dem Bild lautet: "XSemPLR - Wir bieten ein umfassendes Dataset XSemPLR für das Semantische Parsing in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen. Es enthält: 9 Datensätze in verschiedenen Domänen 5 Semantische Parsing-Operationen 8 Bedeutungsrepräsentationen 22 natürliche Sprachen in 15 Sprachfamilien" Darüber hinaus sind auf der Seite ein Diagramm und einige Beispiele zu sehen, die auf die Funktionsweise des XSemPLR-Datums hinweisen.</sample>
    <sample id="640">Das Bild zeigt eine Präsentation über XSemPLR, einem Dataset für Sprachanalyse und Bedeutungsinterpretation. Der Text auf dem Bild lautet: "XSemPLR" und "Wir bieten ein umfassendes Dataset für XSemPLR für die Semantische Parse Interpretation in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen. Es enthält: 9 Datensätze in verschiedenen Bereichen 5 Semantischer Parse Aufgaben 8 Bedeutungsrepräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien."</sample>
    <sample id="641">Das Bild zeigt eine Präsentation mit dem Titel "Experiment Settings". Es gibt zwei Hauptabschnitte: "Training" und "Inference". Im Abschnitt "Training" sind zwei Diagramme zu sehen. Der erste Diagramm zeigt den Prozess von Englisch ins SQL zu übersetzen, indem man einen Übersetzungsdienst wie Google Translate verwendet. Der zweite Diagramm zeigt den Prozess von Deutsch ins SQL zu übersetzen, indem man einen Übersetzungsdienst verwendet. Im Abschnitt "Inference" ist ein ähnliches Diagramm zu sehen, das den Prozess von Deutsch ins SQL zu übersetzen zeigt.</sample>
    <sample id="642">Das Bild zeigt eine Präsentationsslideset, die sich auf die Einstellungen für eine Versuchsanordnung konzentriert. Der Titel der Slide lautet "Experiment Settings" (Versuchsanordnungs-Einstellungen). Die Slide beschreibt, dass es sechs Einstellungen gibt, die für die Ausbildung und Bewertung verwendet werden sollen.</sample>
    <sample id="643">Das Bild zeigt eine Präsentation über den Versuchsausstellungssetting. Der Titel lautet "Experiment Settings". Es gibt zwei Hauptabschnitte: Training und Inferenz. Im Training-Abschnitt wird beschrieben, dass man einen English-Modell auf englischen Daten trainiert und dann auf SQL abgerufen wird. Im Inferenz-Abschnitt wird beschrieben, dass man einen German-Query über einen API in Englisch übersetzt und dann auf SQL abruft. Die Texte sind in Englisch, aber ich kann sie ins Deutsche übersetzen.</sample>
    <sample id="644">Das Bild zeigt eine Präsentation mit dem Titel "Experiment Settings". Es gibt zwei Hauptabschnitte: Training und Inference. Im Training-Section sind zwei Diagramme zu sehen, die beide "German" und "SQL" zeigen. Im Inference-Section ist ein ähnliches Diagramm zu sehen, das "German" und "SQL" zeigt. Darüber hinaus gibt es einen Text, der den Kontext des Experimentes beschreibt: "Wir betrachten die sechs Einstellungen für die Ausbildung und Bewertung." Es wird auch erwähnt, dass eine Monolingual-Methode getestet wird, bei der die QuellSprache gleich der Zielsprache ist (z.B. Deutsch-&gt;Deutsch) und dass eine Monolingual-Few-shot-Einstellung getestet wird, bei der monolingual Models mit nur 10% Trainingsdaten ausgebildet werden.</sample>
    <sample id="645">Das Bild zeigt eine Präsentation über Experimenteinstellungen für die Ausbildung und Bewertung von Modellen. Es gibt zwei Hauptabschnitte: Training und Inferenz. Beim Training handelt es sich um ein Monolingual-Modell, bei dem die QuellSprache gleich der Zielsprache ist, wie zum Beispiel Deutsch ins Deutsche oder Englisch ins Englische. Das Bild zeigt, dass das Modell auf Deutsch trainiert wird und danach auf SQL übertragen wird. Im Abschnitt Inferenz ist das Modell auf Deutsch trainiert und übertragen auf SQL. Die Präsentation diskutiert verschiedene Einstellungen für die Ausbildung und Bewertung von Modellen, einschließlich eines Monolingual-Few-shot Settings mit nur 10% Trainingsdaten.</sample>
    <sample id="646">Das Bild zeigt eine Präsentation über Experimente. Der Titel lautet "Experiment Settings". Es gibt zwei Hauptabschnitte: Training und Inference. Im Training-Abteilung ist ein Diagramm zu sehen, das "German (Few-shot)" und "German Model" auf der linken Seite zeigt und auf der rechten Seite "SQL" anzeigt. Im Inference-Abteilung ist ein ähnliches Diagramm zu sehen, aber die Labels sind "German" anstatt "German (Few-shot)". Im Text oben steht: "Wir betrachten die sechs Einstellungen für die Ausbildung und die Bewertung." Darunter steht: "Monolingual-Modell: Die QuellSprache ist gleich der Zielsprache, zum Beispiel Deutsch-ins Deutsche. Wir testen auch den Monolingual-Few-shot-Einstellung durch Ausbildung von monolingualen Modellen mit nur 10% der Ausbildungsdaten."</sample>
    <sample id="647">Das Bild zeigt eine Präsentation über Experimenteinstellungen. Der Titel lautet "Experiment Settings" (Experimenteinstellungen). Es gibt zwei Hauptabschnitte: "Training" (Trainieren) und "Inference" (Erkennung).

Im Abschnitt "Training" sind drei Sprachen (Deutsch, Englisch und Chinesisch) aufgeführt, die als Trainingsdatenquelle für ein Multilingües Modell dienen. Diese Sprachen werden dann in einem Diagramm zusammengefasst und leiten das Multilingües Modell zu einer SQL-Datenbank.

Im Abschnitt "Inference" wird das gleiche Prozess wiederholt, wobei das Multilingües Modell auf Basis der Trainingdaten für die Erkennung von Daten in einer SQL-Datenbank verwendet wird.

Die Texte auf dem Bild lauten:

- "We consider the six settings for training and evaluation."
- "Multilingual Model: Train one multilingual model for all languages."

Das Bild zeigt auch einen kleinen Bildschirm im oberen rechten Eck, auf dem eine Person zu sehen ist, die wahrscheinlich die Präsentation gibt.</sample>
    <sample id="648">Das Bild zeigt eine Präsentation über die Einstellungen für ein Experiment. Der Titel lautet 'Experiment Settings' (Experimenteinstellungen). Es gibt zwei Hauptabschnitte: 'Training' (Trainieren) und 'Inference' (Infektion). Beide Abschnitte zeigen, wie die Sprachen German, English und Chinese trainiert werden, um einen Multilingüen-Modell zu erstellen. Das Modell wird dann auf SQL-Anfragen angewendet. Die Texte sind auf Englisch, und es gibt einige deutsche Übersetzungen, wie 'Multilingüen Modell' (Multilingüen-Modell) und 'SQL' (SQL). Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm mit einem Menschen zu sehen.</sample>
    <sample id="649">Das Bild zeigt eine Präsentation über "Experiment Settings" (Versuchsbedingungen). Es gibt zwei Hauptabschnitte: "Training" (Trainingsbedingungen) und "Inference" (Infektionsbedingungen).

Im Abschnitt "Training" sind drei Sprachen vorgestellt: Deutsch, Englisch und Chinesisch. Diese Sprachen werden in einem Prozess abgebildet, der zu einem Multilingüistischen Modell führt, das dann auf SQL-Abfragen angewendet wird.

Im Abschnitt "Inference" wird ein ähnlicher Prozess gezeigt, bei dem das Multilingüistische Modell auf SQL-Abfragen angewendet wird, aber dies ist für die deutsche Sprache.

Die Präsentation scheint auf die Verwendung eines Multilingüistischen Modells für die Übersetzung von Abfragen in verschiedenen Sprachen zu konzentrieren.</sample>
    <sample id="650">Experiment Settings We consider the six settings for training and evaluation. Cross-lingual Zero-shot/Few-shot transfer. Train on one source language and transfer to another language. Training English Or English German Few-shot Multilingual SQL Inference German Multilingual SQL</sample>
    <sample id="651">Das Bild zeigt eine Präsentation über "Experiment Settings". Es gibt eine Überschrift und zwei Abschnitte: "Training" und "Inference". Im "Training"-Abschnitt sind drei Boxen mit den Wörtern "English", "English" und "German Few-shot" innerhalb. Diese Boxen sind mit einem Pfeil verknüpft, der auf einen weiteren Pfeil zeigt, der auf eine blaue Box mit dem Wort "SQL" hinweist. Der Text in diesem Abschnitt lautet: 'Cross-lingual Zero-shot/Few-shot transfer. Train on one source language and transfer to another language.' Im "Inference"-Abschnitt ist eine ähnliche Struktur zu sehen, wobei die Boxen "German" und "Multilingual Model" stehen und ebenfalls auf die blaue SQL-Box zeigen. Die Hauptfunktion dieser Präsentation scheint es, verschiedene Einstellungen für das Training und die Inferenz eines Multilingüisten-Modells zu demonstrieren, insbesondere im Zusammenhang mit der Transferierung von Lernprozessen zwischen verschiedenen Sprachen.</sample>
    <sample id="652">Das englische Text ist 'Analysis of Monolingual' und bedeutet 'Analyse von monolingualen Modellen'.</sample>
    <sample id="653">Das englische Text ist auf dem Bild in einem Tabellenformular präsentiert. Der Tabellenkopf enthält die folgenden Spalten: 'MATIS', 'MGEOQuery', 'MSpider', 'MOveright', 'MCWQ', 'MSchae2QA', 'MTOP' und 'MCNAver'. Diese Spalten sind dann gefüllt mit Zahlenwerten, die wahrscheinlich die Ergebnisse der verschiedenen Modelle sind. Im unteren Teil des Tabelles befindet sich eine zusätzliche Zeile mit den Zahlenwerten 'mBART 5138', '74.26', '50.73', '91.65', '66.29', '65.16', '81.83' und '101.29'. Diese Zahlenwerte könnten die Gesamtergebnisse oder die Leistungsindikatoren der Modelle sein.</sample>
    <sample id="654">Das englische Inhalt auf dem Bild lautet: 'Analysis of Monolingual We evaluate on two groups of models on Monolingual Setting EPTR: Multilingual Pretrained Encoders with Pointer-based Decoders XLM-R + PTR, mBERT + PTR EPDec: Multilingual Pretrained Encoder-Decoder Models mBART, mT5 We found EpDec (mT5) obtains the best performance on all datasets!'</sample>
    <sample id="655">Die Übersetzung des englischen Inhalts lautet: "Wir haben entdeckt, dass Enc-Decoder die beste Leistung auf allen Datensätzen erzielt."</sample>
    <sample id="656">Die englische Übersetzung lautet: "Wir evaluieren mT5 und XLM-R + PTR in einer multilingualen Umgebung. Enc-Enc/PTR (mT5-XLM-R) kann durch Training in einer Mischung verschiedener Sprachen verbessert werden."</sample>
    <sample id="657">Analysis of Multilingual Training We evaluate on mT5 and XLM-R + PTR on Multilingual Setting Enc-Dec/Enc-PTR (mT5/XLM-R) can be improved by training in a mixture of various languages.</sample>
    <sample id="658">Analysis of Multilingual Training</sample>
    <sample id="659">Analysis of Multilingual Training</sample>
    <sample id="660">Der englische Inhalt lautet: "We also compared the cross-lingual performance gap" und "We also compared the cross-lingual performance gap".</sample>
    <sample id="661">Das Bild zeigt eine Präsentation mit dem Titel "Cross-lingual Performance Gap". Es gibt drei Linien, jede in einer anderen Farbe:</sample>
    <sample id="662">Der englische Text lautet: 'green - orange for zero-shot setting, the cross-lingual transfer performance gap is significant blue - orange for few-shot setting, the transfer gap is shortened rapidly'</sample>
    <sample id="663">Der englische Inhalt lautet: "Other Results &amp; Findings (Section 4 in Paper)"</sample>
    <sample id="664">Die englische Übersetzung lautet: "Multilingual LLMs (Codex &amp; Bloom) sind noch nicht geeignet für die Übersetzung von Semantik in verschiedenen Sprachen."</sample>
    <sample id="665">Das englische Text ist in einem Punktform angeordnet und gibt einen Zusammenfassung eines Forschungsprojekts oder -arbeits.</sample>
    <sample id="666">Das englische Inhalt auf dem Bild lautet: 'Conclusion We build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations. We conduct a comprehensive benchmark study on three representative types of multilingual language models. Our results show that mT5 with monolingual training yields the best performance, notably multilingual LLMs are still inadequate to perform cross-lingual semantic parsing tasks. Moreover, the performance gap between monolingual training and cross-lingual transfer learning is still significant.'</sample>
    <sample id="667">The existing works can be broadly classified into four categories: 1. Parameter watermarking (1, 2) - Transferability X 2. Lexical watermarking (3, 4) - Applicable to EaaS 3. Backdoor-based watermarking (5) - Applicable to EaaS 4. Adversarial-property based watermarking (6) - Applicable to EaaS These categories cover different approaches and applications in the field of watermarking techniques for deep neural networks.</sample>
    <sample id="668">Nein, Multilingual LLMs wie Codex und Bloom sind für die CLSP nicht ausreichend.</sample>
    <sample id="695">The image shows a flowchart with various elements and text. The main title at the top reads 'Technical Challenges We Solve.' Below this, there is a diagram labeled 'Alignment unknown,' which includes several boxes connected by arrows. Some of these boxes contain words like 'girI,' 'sleep,' 'agent,' and 'x1.' There are also tags such as 'the,' 'girl,' and 'sleeped' below the alignment area. Additionally, there are notes about inducing alignment in training and mentioning that inference is NP-hard (TSP).</sample>
    <sample id="696">Fairness of a fine-tuned NLP model is defined by how well it performs on different political opinions.</sample>
    <sample id="697">Yanis Labrador, Adrien Bazeza, Richard Dufour, Mickael Rouvier, Emmanuel Morin, Beatrice Daille, Pierre-Antoine Gourroud.</sample>
    <sample id="698">Koustuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Mira, Keren Fuentes, Roger Levy, Adi Williams</sample>
    <sample id="699">Myra Cheng</sample>
    <sample id="700">Tropikalismus bedeutet, dass bestimmte Gruppen nur aufgrund ihrer Identität definiert werden.</sample>
    <sample id="701">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen erstellt, indem sie sich auf bestimmte Wörter wie "culture", "tradition", "proud" und "exotic" für markierte Gruppen konzentriert haben. Diese Wörter definierten diese Gruppen ausschließlich aufgrund ihrer Identität.</sample>
    <sample id="702">Pointwise (P-)CXMI</sample>
    <sample id="703">DrBERT ist ein BERT-Modell, das auf einem 7-Gigabyte-Schnittstelle von NACHOS trainiert wurde. ChuBERT ist ein klinischer BERT-Modell, das auf einem 4-Gigabyte-Schnittstelle von NACHOS trainiert wurde.</sample>
    <sample id="751">Es sind drei Autoren an der Arbeit beteiligt.</sample>
    <sample id="752">Iterative Transfer Learning is a method in active learning where the model updates are done iteratively. It involves training on new data and then updating the model based on this new information, which helps improve its performance over time.</sample>
    <sample id="753">Das Ziel des Datensatzes ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen möchten.</sample>
    <sample id="754">Ein Angreifer kann Modellparameter über einen EaaS (Embedded Adversarial Attack Service) extrahieren, indem er die Parameter aus dem Embedding-Visualisationen der verschiedenen Datasetts (AG News, Enron Spam, MIND und SST2) extrahiert.</sample>
    <sample id="755">Es sind drei Autoren an der Arbeit beteiligt.</sample>
    <sample id="756">In the original dataset, 10 annotators were used.</sample>
    <sample id="757">Sebastian Senti, Ronan Le Bras, and Maarten Sap belong to the University of Washington. Jenny T. Liang belongs to Carnegie Mellon University. Katharina Reinecke is affiliated with the Allen Institute for AI.</sample>
    <sample id="758">The governor is on the left.</sample>
    <sample id="759">The technology for dialog systems is capable of measuring the rates at which chat models will commit various thematic errors.</sample>
    <sample id="760">Das bedeutet, dass wir die Modellakzeptanz über den gesamten Kontextfenster bewerten müssen, um sicherzustellen, dass die Modelle auf lange Distanz und in verschiedenen Kontexten korrekt funktionieren.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="762">Nein, die Annotatoren kennen die Entität im Voraus nicht.</sample>
    <sample id="763">BLEU, METEOR, ROUGE</sample>
    <sample id="764">Ja, die Regression hat auf bestimmte NER-Typen ausgewirkt.</sample>
    <sample id="765">Carl Jones und Aditya Sharma sind Tech Leads.</sample>
    <sample id="766">Mehrsprachige LLMs wie BLOOM wurden durch Adapter angepasst.</sample>
    <sample id="767">The model used for cold-start annotations is called RoBERTA-base + classifier head.</sample>
    <sample id="768">The current test sets used for evaluating the PaLM capabilities are SQuAD, SuperGLUE, and GLUE.</sample>
    <sample id="769">The authors have suggested three recommendations.</sample>
    <sample id="770">Der Gewinn der vorgeschlagenen Methode gegenüber der stärksten Baseline beträgt 19,25%.</sample>
    <sample id="771">Shuheng Liu, Alan Ritter</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark verwendet werden.</sample>
    <sample id="773">Die Studie untersucht fünf verschiedene Modelle, wovon vier kleineren und ein größeres Modell sind.</sample>
    <sample id="774">OFA.</sample>
    <sample id="833">Die Autoren gehören der Universität Google.</sample>
    <sample id="834">Die Autoren gehören an der Stony Brook University.</sample>
    <sample id="835">Deutsch, Englisch und Spanisch.</sample>
    <sample id="836">Shangbin Feng, Chan Young Park, Yuhan Liu, Yulia Tsvetkov</sample>
    <sample id="837">Das Bild zeigt eine Präsentation über "Automatic Text Simplification". Es gibt zwei Hauptabschnitte: "Document Level" und "Sentence Level". Jeder Abschnitt zeigt Ergebnisse von Experimenten, die auf finetuned mBART basieren. Die Ergebnisse werden für verschiedene Testdatensätze (DEPLAIN-APA und DEPLAIN-WEB) und verschiedene Modelle (DEPLAIN-APA, DEPLAIN-APA-SBLEU, DEPLAIN-WEB) dargestellt.</sample>
    <sample id="838">Für die Trainingsdatenbank werden 53 der 62 verschiedenen Aufgaben verwendet.</sample>
    <sample id="839">Es gibt drei Autoren: Regina Stodden, Omar Momen und Laura Kallmeyer.</sample>
    <sample id="840">AG News, MIND, SST2, Enron Spam</sample>
    <sample id="876">NACHOS ist ein Dataset, das aus Medizinischen Crawldaten von der Webseite zusammengestellt wurde.</sample>
    <sample id="877">David Vilarr Torres, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, George Foster</sample>
    <sample id="878">Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse.</sample>
    <sample id="879">The authors belong to Carnegie Mellon University, Technico Lisboa, Berkeley Artificial Intelligence Research (BAIR), and Unbabel.</sample>
    <sample id="880">The 5 instructions are: 1. Be brief; 2. Be accurate; 3. Don't introduce personal opinions or emotions; 4. Don't generate new information; 5. Only provide relevant and verifiable content from the image.</sample>
    <sample id="881">Die Autoren schlagen vor, Modelle zur Nutzung von Informationen aus mehreren Quellen zu testen, indem sie ein Dataset für die Bewertung der Wissensintegration nutzen.</sample>
    <sample id="882">Es tut mir leid, ich kann den englischen Inhalt nicht in Deutsch übersetzen.</sample>
    <sample id="883">图片中的文字内容是：PaLM: Pathways Language Model Chowdery et al., 2022 arXiv:2204.02311. 540B parameters. Trained on 780B tokens. Densely activated. 6144 TPU v4 chips. SOTA in hundreds of LMU and Generation benchmarks.</sample>
    <sample id="884">Das Bild zeigt eine Präsentation über den PaLM-Modell (Pathways Language Model). Der Titel lautet "PaLM: Pathways Language Model". Die Präsentation wurde von Chowdery usw. im Jahr 2022 veröffentlicht und hat die arXiv-Id arXiv:2204.02311. Das Modell hat 540 Billionen Parameter und wurde auf 780 Billionen Tokens trainiert. Es ist vollständig aktiviert und nutzt 6144 TPU v4-Chips. Das Modell erreicht das Land der Besten in hunderten von NLP-Tests und Generierungsbenchmarks. Im Bild sind verschiedene Anwendungen des Modells dargestellt, wie Fragebeantwortung, Logische Inferenz, Codekomplettierung, Übersetzung, Summarisierung und Sprachverstehen.</sample>
    <sample id="885">Der englische Inhalt lautet: "In this work, we present the first systematic study of LLM prompting for MT."</sample>
    <sample id="886">The image shows a slide from a presentation. The title of the slide is 'Our contribution'. There are three main bullet points listed: 1. First systematic study of LLM prompting for MT. - Both for the candidate pool as well as selection strategy. 2. Evaluate translation capabilities with best practices of the MT community. - Latest test sets (avoid test/train overlap and overfitting on evaluation data). - Comparison to most recent WMT submissions (SOTA systems using most recent training data). - SOTA MT metrics (better correlation with human judgements). - Expert-based human evaluation (more robust than crowd workers). 3. Recommendation for prompt selection strategies. In the bottom left corner, there is a Google logo. On the right side of the slide, there is an inset picture of a person wearing glasses and looking at the camera.</sample>
    <sample id="887">Wir haben einen systematischen Ansatz zur Untersuchung von LLMs für die Generierung von Übersetzungen entwickelt.</sample>
    <sample id="888">Das Bild zeigt eine Präsentation über die Beiträge eines Forschungsprojekts. Der Titel der Präsentation lautet "Unser Beitrag". Die Inhalte der Präsentation umfassen folgende Punkte: 1. Systematische erste Studie über LLM-Folgendemahl für MT (Machine Translation). - Beziehungen zur Kandidatenpool und Auswahlstrategie. 2. Bewertung von Übersetzungsfähigkeiten gemäß den besten Praktiken der MT-Community. - Neueste Testsets (vermeiden Sie das Testtrain-Overlap und Übertrocknen auf Evaluation-Daten). - Vergleich zu den neuesten WMT-Untermittlern (SOTA-Systemen mit den meisten recenten Training-Daten). - SOTA MT-Metriken (bessere Korrelation mit menschlichen Urteilen). - Expertenbasierte menschliche Bewertung (mehr robust als Roboter-Mitarbeiter). 3. Empfehlungen für Prompts auswählende Strategien. Im unteren rechten Eck des Bildes ist ein kleiner Bild von einem Menschen zu sehen, der möglicherweise der Vortrager ist. Im unteren linken Eck befindet sich ein Google-Logo.</sample>
    <sample id="889">Prompts have a big impact on translation quality. Select two random prompts for each sentence. Compute BLEURT for each sentence-prompt pair. The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point. The difference can go up to 40 BLEURT points</sample>
    <sample id="890">Prompts haben einen großen Einfluss auf die Übersetzungsfähigkeit.</sample>
    <sample id="891">Prompts haben einen großen Einfluss auf die Übersetzungsfähigkeit.</sample>
    <sample id="892">In our experiments, we used a 5-shot prompting strategy where we marked each sentence that we provided to the system with its original language.</sample>
    <sample id="893">Das Bild zeigt eine Präsentation über Übersetzungsvorbereitung. Der Titel der Präsentation lautet "Example prompting for translation". Die Präsentation enthält eine Liste von Szenarien, die auf Deutsch und Englisch detailliert beschrieben sind. Jedes Szenario besteht aus einem deutschen Satz, gefolgt von seiner englischen Übersetzung. Der Text ist in einer weißen Box mit schwarzen Lettern angeordnet. Im unteren rechten Eck des Bildes ist ein kleiner Bildschirm eines Menschen zu sehen, der wahrscheinlich das Präsentationsunterhaltung führt. Im unteren linken Eck befindet sich ein Google-Doodle.</sample>
    <sample id="894">Das Bild zeigt eine Präsentation über die Übersetzung von englischen Texten ins Deutsche. Der Titel der Präsentation lautet "Example prompting for translation". Im Bild sind zwei englische Sätze zu sehen, die auf Deutsch übersetzt wurden: "Dort sieht man, wie sie von zwei Police-Officern in einem Streifenwagen gesetzt wird" und "Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Buros erhalten hatten". Darüber hinaus sind zwei weitere englische Sätze zu sehen, die auf Deutsch übersetzt wurden: "Police were called in after receiving complaints from the office" und "Ein Passant alarmierte die Polizei, mit mehreren Streifen anruckte." Das Bild wurde von Google Drive erstellt.</sample>
    <sample id="895">Das Bild zeigt eine Präsentation über "Example prompting for translation". Es gibt einen Titel, der "Example prompting for translation" lautet. Darunter befindet sich eine Abschnitte mit dem Titel "5-shot prompting", die verschiedene englische und deutsche Übersetzungen aufzulisten scheint. Die englischen Phrasen sind: "Dort sieht man, wie sie von zwei Police-Officern in einem Streifenwagen gesetzt wird." und "Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Buros erhalten hatten." Diese werden übersetzt ins Deutsche: "Er wird von zwei Polizisten im Dienstfahrzeug eines Gerichtshofs transportiert." und "Polizei wurden aufgerufen, nachdem Beschwerden des Buros erhalten hatten." Außerdem ist ein Text zu sehen, der lautet: "English: Police were called in after receiving complaints from the office." Am unteren rechten Eck des Bildes ist ein kleiner Bildschirm eines Menschen zu sehen, der möglicherweise das Präsentationsbild präsentiert. Im unteren linken Eck ist das Google-Doodle sichtbar.</sample>
    <sample id="896">Das Bild zeigt eine Präsentation mit dem Titel "Example prompting for translation". Es gibt eine Liste von Szenen (5-shot prompting) in deutscher und englischer Sprache. Die deutschen Szenen sind: 1. "Dort sieht man, wie sie von zwei Police-Officern in einem Streifenwagen gesetzt wird." 2. "Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Buros erhalten hatten." 3. "Ein Passant alarmierte die Polizei, mit mehreren Streifen anruckte." Die englischen Übersetzungen sind nicht vollständig sichtbar, aber es gibt Anzeichen dafür, dass sie auf der gleichen Präsentation zu finden sind. Im unteren rechten Ecke des Bildes ist ein kleiner Bildausschnitt eines Menschen zu sehen, der wahrscheinlich die Präsentation führt.</sample>
    <sample id="897">Der englische Text lautet: 'The summary of our experimental results is that the example quality is more important than similarity to source sentence. Specialized SOTA systems have a substantial advantage. PaLM close to Google Translate.'</sample>
    <sample id="898">Experimental Results Example quality is more important than similarity to source sentence. Specialized SOTA systems have a substantial advantage. PaLM close to Google Translate. Insights from MQM: Fluency of PaLM comparable to SOTA. Accuracy scores generally lower. Dominated by "Accuracy/Omission". "Style/Awkwad" generally lower for PaLM.</sample>
    <sample id="899">Das Bild zeigt eine Präsentation über experimentelle Ergebnisse. Der Titel lautet 'Experimental Results'. Es gibt mehrere Punkte, die Informationen über die Qualität der Übersetzung und die Leistung von PaLM (auch als SOTA-System erwähnt) enthalten. Hier sind die Punkte: 1. Beispielqualität ist wichtiger als Ähnlichkeit zur Quellphrase. 2. Spezialisierte SOTA-Systeme haben einen bedeutenden Vorteil. 3. PaLM ist nahe bei Google Translate. 4. Insights aus MQM: - Fluensität von PaLM ist mit SOTA gleichwertig. - Genauheitswerte sind allgemein niedriger. - Genauigkeit/Übersehen dominiert die Genauheitswerte. - Stil/Unbehagen ist allgemein niedriger für PaLM. Im unteren linken Eck des Bildes befindet sich das Google Logo. Im unteren rechten Eck ist ein kleiner Bildausschnitt eines Menschen zu sehen.</sample>
    <sample id="900">Das Bild zeigt eine Präsentation mit dem Titel "Experimental Results". Es gibt mehrere Punkte, die Informationen über die Ergebnisse einer Studie bereitstellen. Hier sind die Details: 1. Beispiele der Qualität sind wichtiger als die Ähnlichkeit zu der Quell-Sprache. 2. Spezialisierte SOTA-Systeme haben einen bedeutenden Vorteil. 3. PaLM ist in der Nähe von Google Translate. 4. Einzeln ist die Flüssigkeit von PaLM mit SOTA gleichwertig. 5. Genauheitswerte sind im Allgemeinen niedriger. 6. Genauigkeit und Übersehen dominiert die Genauheitswerte. 7. Stil und Schwierigkeiten sind im Allgemeinen niedriger für PaLM. Im unteren rechten Eck des Bildes ist ein kleiner Bild eines Menschen zu sehen, der wahrscheinlich der Präsentator ist. Im unteren linken Eck befindet sich das Google Logo.</sample>
    <sample id="901">Das Bild zeigt eine Präsentation mit einem Titel 'Experimental Results'. Es gibt mehrere Punkte, darunter: - Beispielqualität ist wichtiger als Ähnlichkeit zur Quell-Sprache. - Spezialisierte SOTA-Systeme haben einen bedeutenden Vorteil. - PaLM ist fast wie Google Translate. - Einzelnachweise von MQM: - Fluensität von PaLM ist mit der aktuellen Lage vergleichbar. - Genauheitswerte sind im Allgemeinen niedriger. - Stil/Unbehagen sind im Allgemeinen niedriger für PaLM. Im unteren linken Eck befindet sich ein Logo von Google, und rechts unten ist ein kleiner Bildausschnitt eines Menschen zu sehen.</sample>
    <sample id="902">Das Bild zeigt eine Präsentation mit dem Titel 'Experimental Results'. Es gibt mehrere Punkte, die Informationen über die Ergebnisse einer Studie oder Untersuchung bereitstellen. Hier sind die Hauptpunkte: 1. Beispielqualität ist wichtiger als Ähnlichkeit zur Quellphrase. 2. Spezialisierte SOTA-Systeme haben einen bedeutenden Vorteil. 3. PaLM ist nahe bei Google Translate. 4. Einzelnachweise von MQM: - PaLMs Flussigkeit ist mit SOTA gleichmäßig. - Genauheitswerte sind allgemein niedriger. - Genauigkeit/Übersehen dominiert. - Stil/Schwierigkeitsgrad ist allgemein niedriger für PaLM. Im unteren linken Eck des Bildes befindet sich das Google-Logo. Rechts unten ist ein kleiner Bildausschnitt eines Menschen zu sehen.</sample>
    <sample id="903">Das Bild zeigt eine Präsentation über experimentelle Ergebnisse. Der Titel der Präsentation lautet 'Experimental Results'. Es gibt mehrere Punkte, die Informationen über die Qualität und die Leistung von PaLM und SOTA-Systemen bereitstellen. Hier sind die Hauptpunkte: 1. Beispielqualität ist wichtiger als Ähnlichkeit zur Quell-Sprache. 2. Spezialisierte SOTA-Systeme haben einen bedeutenden Vorteil. 3. PaLM ist nahe bei Google Translate. 4. Insights aus MQM: - Fluensität von PaLM kann mit SOTA konkurrieren. - Genossenschaftsscore sind allgemein niedriger. - Dominiert durch "Accuracy/Omission". - Stil/Unbehagen sind allgemein niedriger für PaLM. Im unteren rechten Eck des Bildes ist ein kleiner Bild von einem Menschen zu sehen, der wahrscheinlich über diese Präsentation sprechen wird.</sample>
    <sample id="904">Der englische Inhalt lautet: 'Experimental Results Example quality is more important than similarity to source sentence. Specialized SOTA systems have a substantial advantage. PaLM close to Google Translate. Insights from MQM: Fluency of PaLM comparable to SOTA. Accuracy scores generally lower. * Dominated by "Accuracy/Omission" * "Style/Awkwad" generally lower for PaLM.'</sample>
    <sample id="905">Der englische Inhalt lautet: 'Example quality is more important than similarity to source sentence. Specialized SOTA systems have a substantial advantage. PaLM close to Google Translate. Insights from MQM: Fluency of PaLM comparable to SOTA. Accuracy scores generally lower. * Dominated by "Accuracy/Omission" * "Style/Awkwad" generally lower for PaLM.'</sample>
    <sample id="906">Das Bild zeigt eine Mischung von englischen und anderen Sprachen, die alle den Ausdruck "Danke" bedeuten. Der Haupttext lautet "thank you", der in roter Farbe prominent dargestellt ist. Um diesen Haupttext herum sind verschiedene Wörter in verschiedenen Sprachen verteilt, wie zum Beispiel "gracias", "merci", "danke", "obrigado", "sukkria" und "terima kasih". Diese Wörter sind in verschiedenen Farben und Größen angeordnet, was eine visuell ansprechende und multilingüe Darstellung des Ausdrucks "Danke" schafft.</sample>
    <sample id="907">Weaker Than You Think: A Critical Look at Weakly Supervised Learning</sample>
    <sample id="908">Das ist eine gemeinsame Arbeit mit Xiaoyu Shen, Marius Mosbach und Dietrich Klakow.</sample>
    <sample id="909">Weak supervision alleviates the annotation bottleneck. Weak labels are noisy, which can harm generalization due to noise memorization. Weakly supervised learning (WSL) trains models that generalize well despite being trained on noisy data.</sample>
    <sample id="910">Das Bild zeigt eine Präsentation über 'Weakly supervised learning'. Die Texte auf dem Bild sind in Englisch und deuten auf das Thema hin, wie schwache Überwachung bei der Erlernung von Daten funktioniert. Die Schritte und Informationen sind in einer Kombination aus Text und Grafiken dargestellt.</sample>
    <sample id="911">Weak supervision alleviates the annotation bottleneck. Weak labels are noisy, meaning that a certain amount of the annotations are incorrect.</sample>
    <sample id="912">Weak supervision alleviates the annotation bottleneck. Weak labels are noisy Noise memorization harms generalization. Weakly supervised learning (WSL) Train models that generalize well despite being trained on noisy data. Weak labeling sources: e.g., heuristics, knowledge bases Unlabeled data Weakly labeled data = noisy data + wrong annotations</sample>
    <sample id="913">Weak supervision alleviates the annotation bottleneck. Weak labels are noisy Weaken supervised learning (WSL) Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="914">A common claim in recent works is that people say they only train models on weakly supervised data and achieve high performance.</sample>
    <sample id="915">Ein häufiger Anspruch in aktuellen WSL-Arbeiten ist: "Wir trainieren Modelle nur mit schwach überwacht Data und erreichen eine Genauigkeit von XX%."</sample>
    <sample id="916">Ein häufiger Ansatz in kürzlichen Forschungsarbeiten zu Supervised Learning mit Schwachsupervision (WSL) ist, dass Modelle nur auf schwach überwachte Daten trainiert werden und eine Genauigkeit von XX% erreichen. Dies wird durch die Darstellung von drei Datensätzen dargestellt: - Schwach überwachte Trainingsdaten (lauter), die als "noisy" bezeichnet sind. - Reinheit überwachte Validationsdaten (lauter). - Reinheit überwachte Testdaten (lauter). Diese Darstellung zeigt, dass das Training auf schwach überwachte Daten ohne zusätzliche Reinheit überwachte Daten oder Validierungsdaten erfolgt, was möglicherweise zu einer reduzierten Genauigkeit führen könnte.</sample>
    <sample id="917">Das Bild zeigt eine Präsentationsslideset mit dem Titel "A common claim in recent WSL works". Der Text auf der Slide lautet: "We train models only on weakly supervised data and achieve an accuracy of XX%". Diese Phrase wird hervorgehoben, und es gibt ein Emoticon mit einem Gesichtsausdruck von Überraschung. Darunter sind zwei Diagramme zu sehen, die "Weakly labeled training data (noisy)" und "Cleanly labeled validation data" und "Cleanly labeled test data" beschriftet sind. Im unteren rechten Eck des Slides ist ein Bild eines Elefanten zu sehen.</sample>
    <sample id="918">Das englische Inhalt auf dem Bild lautet: 'Our research questions' und folgt danach drei Research Questions (RQ1, RQ2, RQ3) auf: 1. Is clean validation data necessary? 2. How many clean samples do WSL approaches need? 3. How to use the available clean samples more efficiently?</sample>
    <sample id="919">Das Bild zeigt eine Präsentation mit drei Forschungsfragen, die in Englisch aufgeführt sind. Die Fragen sind: 1. Ist die Validierung von sauberem Daten erforderlich? 2. Wie viele saubere Beispiele benötigen WSL-Anproptehe? 3. Wie können wir die verfügbaren sauberen Beispiele effizienter nutzen? Im oberen rechten Eck des Bildes ist ein kleiner Bild von einer Person zu sehen. Der Text ist weiß und auf einem weißen Hintergrund platziert.</sample>
    <sample id="920">RQ1 Main findings</sample>
    <sample id="921">Der englische Text lautet: 'First, we find that interestingly recent WSL methods indeed require clean white samples to work properly.'</sample>
    <sample id="922">The graph shows how well different models perform based on the type of validation used. It compares 'Validation on Weak Labels', 'No Validation (Random Selection)', and 'Validation on Clean Labels'.</sample>
    <sample id="923">Der englische Inhalt lautet: "Meaning that the training is pointless."</sample>
    <sample id="924">Das Hauptergebnis ist, dass eine saubere Validationsstunde unverzichtbar ist.</sample>
    <sample id="925">Der englische Text lautet: 'Our second finding is that increasing the number of clean validation samples will help WSL approaches to achieve better performance, as shown in the figure on the left.'</sample>
    <sample id="926">Der englische Text lautet: "Main findings"</sample>
    <sample id="927">Der englische Text lautet: 'But that's not the end of the story, because if we either way decide to access clean samples, then training on them directly will even achieve better performance.'</sample>
    <sample id="928">Der englische Text lautet: 'The right figure shows the performance difference between fine-tuning approaches, which are directly applied on the clean data and WSL approaches, which use the clean data for validation only.'</sample>
    <sample id="929">Der englische Text lautet: "As we can see, if we have 10 samples per class, direct fine-tuning starts to beat WSL approaches benefit from more clean validation samples!"</sample>
    <sample id="930">Nicht alle Anforderungen wurden vollständig verstanden. Bitte stellen Sie sie noch einmal klar.</sample>
    <sample id="931">Die Hauptfunde zeigen die Verbesserung der Genauigkeit nach dem CFT-Verfahren.</sample>
    <sample id="932">Der englische Text lautet: "However, if we now to continue fine-tuning on the clean samples."</sample>
    <sample id="933">Das englische Text ist auf dem Bild in zwei Graphen zu sehen, die jeweils eine Messung von 'Accuracy/F1' zeigen. Diese Messungen sind für zwei Gruppen unterschiedlich, einer mit 10 sauberen Beispielen pro Klasse und der andere mit 30 sauberen Beispielen pro Klasse. Jeder Graph zeigt zwei Linien, eine für den 'COSINE' und eine für den 'Clean Only'. Darüber hinaus gibt es einige Texte, die auf Deutsch übersetzt werden: - 'Continuous fine-tuning (CFT) eliminates performance gaps between WSL approaches.' - 'No need to use complicated WSL methods because WSL performs equally well.'</sample>
    <sample id="934">Der englische Inhalt lautet: 'To summarize, we showed that recent WSL approaches require clean samples. They overestimate their practicality.'</sample>
    <sample id="935">Die englischen Inhalte auf dem Bild sind folgendermaßen übersetzt ins Deutsche: Conclusion Recent WSL approaches Require clean samples. Overestimate their practicality. Our recommendations Report the model selection criteria. Use Few-shot learning approaches as baselines. Always apply continuous fine-tuning (CFT).</sample>
    <sample id="936">Der englische Inhalt lautet: "Conclusion Recent WSL approaches Require clean samples. Overestimate their practicality."</sample>
    <sample id="937">Der englische Inhalt lautet: 'Conclusion Recent WSL approaches Require clean samples. Overestimate their practicality.'</sample>
    <sample id="938">In the end, they have open sourced their code. You can find it via the QR code on this slide. Please feel free to check it out Thank you and enjoy the conference.</sample>
    <sample id="939">Likert-Skala</sample>
    <sample id="940">Es sind fünf Autoren an der Arbeit beteiligt.</sample>
    <sample id="941">The background knowledge is 'Judges decide cases in courts of law.'</sample>
    <sample id="942">Ja, der Code ist verfügbar auf GitHub unter dem Link 'https://github.com/mpoemsL/kitmus'.</sample>
    <sample id="943">Es gibt keine Informationen über die Annotatoren für NLPositionality in Bezug auf jede demographische Gruppe, wie Land oder Geschlecht, im Bild.</sample>
    <sample id="944">Es gibt keine visuelle Hinweis auf den Inhalt der Sätze innerhalb des akzeptablen Bereichs.</sample>
    <sample id="945">Eine dimensionale Bewertung bedeutet, dass mehrere Aspekte oder Merkmale eines bestimmten Themas oder Problems in einer einheitlichen Weise bewertet werden.</sample>
    <sample id="946">Die Autoren gehören der Universität der Wissenschaften und Technologie Chinas, Microsoft Research Asia, Beijing Jiaotong University und Sony AI.</sample>
    <sample id="947">Es ist wichtig, die Form des Prompts zu beachten, wenn man mehrere kurze Prompte verwendet.</sample>
    <sample id="978">The slide is titled 'ABC-Eval Error Rates by Model.' It shows a bar graph with various error rates for different models, including BART-FID-RAG, Blender2, Emora, and Blender-Decode. The y-axis represents the percentage of turns, while the x-axis lists categories such as 'Antisocial,' 'CS Contra,' 'Ignore,' etc. Each category has bars representing different model performances.

In the top right corner, there's an image of a person in a suit. At the bottom left, logos are visible: one resembling a shield with a checkmark inside it (likely indicating approval or correctness) and another that appears to be from Emory University. In the center at the bottom, there’s text mentioning 'Alexa.'

Towards the end of the presentation, the next frame displays a title 'Thanks For Watching!' followed by references to a paper on arXiv, GitHub repository details, contact information, and website links related to the project.</sample>
    <sample id="979">Es sind 9 Autoren an der Arbeit beteiligt.</sample>
    <sample id="980">A good planner should read scripts that are reasonable and feasible to constraints.</sample>
    <sample id="981">There are 8 authors involved in this work.</sample>
    <sample id="982">Vasudha Varadarajan.</sample>
    <sample id="983">The authors belong to the Polish Academy of Sciences and the University of Warsaw.</sample>
    <sample id="1021">The most common errors of PaLM are "Accuracy/Omission" and "Style/Awkwad".</sample>
    <sample id="1022">Das Bild zeigt eine Präsentationsleiste mit dem Titel "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems". Die Autoren sind Sarah E. Finch, James D. Finch und Jinho D. Choi. Es gibt auch Logos von Emory University, Emory NLP Research Lab und Alexa. Im oberen rechten Eck ist ein kleiner Bildschirm eines Menschen zu sehen.</sample>
    <sample id="1023">Dieser Text wurde von Emory NLP Research Lab und Alexa AI zusammen erstellt.</sample>
    <sample id="1024">Comparative Evaluation</sample>
    <sample id="1025">Das Bild zeigt eine Präsentation mit dem Titel 'Comparative Evaluation' (Komparativer Bewertungsverfahren). Es gibt zwei Gruppen von Figuren, jede mit einem Bildschirm und einem Sprachblatt. Die Figuren sind in zwei Gruppen unterteilt: eine mit blauen Sprachblättern und die andere mit lila Sprachblättern. Im Zentrum des Bildes ist ein Zeichen für eine Richtung zu sehen, und darunter steht eine Figur, die wie ein Richter aussieht, mit einem Gabel in der Hand. Der Text 'Emory University' und das Logo von Alexa sind im unteren rechten Eck des Bildes sichtbar.</sample>
    <sample id="1026">Das Bild zeigt eine Präsentation mit dem Titel 'Dimensions of Dialogue Quality' (Qualitätsaspekte von Gesprächen). Im Zentrum befindet sich ein Textblock mit dem Wort 'Dialogue Quality'. Diese Worte sind in einem rosa, runden Kastenrahmen eingeschlossen. Darunter sind drei weitere Textblöcke, die 'Relevance', 'Consistency' und 'Emotional Understanding' (Relevanz, Konsistenz und Emotionale Verständnis) heißen. Jeder dieser Blöcke ist durch einen Pfeil mit einer Schattenbehandlung von links nach rechts verankert, was darauf hinweist, dass sie alle auf das Hauptthema 'Dialogue Quality' zugehören. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm eines Menschen zu sehen, der möglicherweise einen Teil der Präsentation macht. Im unteren linken Eck befindet sich die Emory University-Logomarke, und im unteren rechten Eck ist das Alexa-Logo zu sehen.</sample>
    <sample id="1027">Das Bild zeigt eine Präsentation über die Bewertung von Likert-Skala. Der Titel der Präsentation lautet "Likert Rating Evaluation". Im Bild sind verschiedene Elemente zu sehen, darunter eine Illustration eines Richters, der ein Gabel und einen Schiedsgerichtsband hält, und eine Skala von 1 bis 5 mit einem grünen Pfeil auf der 3. Position. Darüber hinaus sind Bläschen und Figuren zu sehen, die wie eine Diskussion oder eine Bewertungsbewertung aussehen. Im unteren rechten Eck des Bildes ist der Text "Rate the relevance of the bot's responses" zu lesen. Das Bild stammt von Emory University und Alexa.</sample>
    <sample id="1028">Das Bild zeigt eine Präsentation über die Bewertung von Likert-Skala. Der Titel der Präsentation lautet "Likert Rating Evaluation". Im Bild sind mehrere Blaue Sprachblasen zu sehen, die wahrscheinlich auf Gespräche oder Kommunikation hinweisen. Darunter steht der Text: "Rate the relevance of the bot's responses" (bewerten Sie die Relevanz der Bot-Antworten). Links am Bildrand ist ein Zeichen mit einem Richtgabeln und einem Gabeln zu sehen, was auf eine Bewertungsstufe hinweist. Die Skala läuft von 1 bis 5, wobei das 4er-Punkt mit einem grünen Pfeil markiert ist. Im unteren linken Eck befindet sich das Logo der Emory University, und im unteren rechten Eck ist das Alexa-Logo zu sehen.</sample>
    <sample id="1029">Der englische Text lautet: "Our approach attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors, such as responding with irrelevant information or contradicting itself."</sample>
    <sample id="1030">Es handelt sich um eine Präsentation von Emory University und Alexa, die sich mit der Annotierung von Verhaltensmustern im Chat (ABC-Eval) beschäftigt.</sample>
    <sample id="1031">ABC-Eval is capable of measuring the rates at which chat models will commit various thematic errors.</sample>
    <sample id="1032">Das Bild zeigt eine Präsentation mit dem Titel 'ABC-Eval Behaviors'. Es gibt vier Kategorien: 'Coherence', 'Knowledge', 'Consistency' und 'Emotional Understanding'. Im Bereich 'Coherence' sind zwei Begriffe zu sehen: 'Ignoring Partner' und 'Irrelevant'. Die anderen drei Bereiche sind leer. Im unteren linken Eck ist das Logo der Emory University zu sehen, und im unteren rechten Eck befindet sich das Alexa-Logo.</sample>
    <sample id="1033">Der englische Text lautet: 'When the model succeeds or fails to show empathy.'</sample>
    <sample id="1034">The English content in the image is: Experiments 4 Open-Domain Dialogue Models 100 Human-Bot Conversations per Model</sample>
    <sample id="1035">Das Bild zeigt eine Präsentation über Experimente. Der Titel der Präsentation lautet 'Experimente'. Es gibt drei Hauptpunkte: 1. 4 Open-Domain Dialogue Models 2. 100 Human-Bot Conversations per Model 3. ABC-Eval, Turn Likert und Dialogue Likert. Im unteren linken Eck befindet sich ein Logo von Emory University. Im oberen rechten Eck ist ein kleiner Bildschirm mit einem Mann zu sehen. Im unteren rechten Eck ist das Alexa-Logo zu sehen.</sample>
    <sample id="1036">Das Bild zeigt eine Präsentation über die 'Baseline Evaluations' von Dialogmodellen. Es gibt drei Hauptbereiche: 'Turn Likert', 'Dialogue Likert' und 'Comparative'. Jeder Bereich zeigt eine Grafik mit einem Chatbot und Menschen, die ihre Meinungen durch Kontrollkreise ausdrücken. Die Kreise sind mit roten oder grünen Kanten markiert, was darauf hinweist, ob die Meinung positiv (grün) oder negativ (rot) ist. Im unteren Teil des Bildes sind vier Kriterien aufgeführt: 'Consistency' (Konsistenz), 'Emotional Understanding' (Emotionale Verständnis), 'Informativeness' (Informativer Inhalt) und 'Overall Quality' (Allgemeine Qualität). Darüber hinaus sind zwei weitere Kriterien 'Engagingness' (Beteiligung) und 'Grammaticality' (Grammatik) sowie 'Proactivity' (Aktivität) und 'Relevance' (Relevanz) aufgeführt. Links am Bildrand befindet sich das Logo der Emory University, und rechts ist das Alexa-Logo zu sehen.</sample>
    <sample id="1037">Das Bild zeigt eine Präsentation mit dem Titel 'Inter-Annotator Agreement' (Interannotatorenvereinbarkeit). Es gibt eine Karte, die den Krippendorffs Alpha-Wert für verschiedene Arten von Evaluations- und Bewertungsverfahren darstellt. Die Verfahren sind 'ABC-Eval', 'Turn Likert', 'Dialogue Likert' und 'Comparative'. Jedes Verfahren wird durch eine Reihe von Punkten in verschiedenen Farben (orange, blau, rot und grün) dargestellt, die den Krippendorffs Alpha-Wert anzeigen. Links am Bildrand befindet sich das Emory-University-Logo und das Alexa-Logo. Rechts oben ist ein kleiner Bildschirmbild einer Person zu sehen.</sample>
    <sample id="1038">Der englische Text lautet: 'In addition, ABC Eval labels are more predictive of the overall conversation quality compared to metrics produced by existing methods, as shown by this simple linear regression analysis.'</sample>
    <sample id="1039">Der englische Text lautet: 'For example, you can see how measuring the proportion of turns with self and partner contradictions explains 5% and 10% of conversation quality respectively.'</sample>
    <sample id="1040">Das englische Text in der Abbildung lautet: "Finally, we checked whether each evaluation metric captures a unique aspect of chat quality using a stepwise linear regression."</sample>
    <sample id="1041">Der englische Text lautet: 'You can see how the combination of all ABC eval metrics explains over 25% of conversation quality. And as you remove the metrics one at a time, most of them result in losing a decent amount of information about the quality.'</sample>
    <sample id="1042">Der englische Text lautet: On the other hand, the combination of all turn level Likert metrics explains far less of the quality and fewer of these metrics carry unique information.</sample>
    <sample id="1043">ABC-Eval Error Rates by Model</sample>
    <sample id="1044">The bar chart compares the error rates of different models on various tasks, with 'Topic Switch' having the highest rate.</sample>
    <sample id="1045">ABC-Eval Fehlerzahlen nach Modell</sample>
    <sample id="1046">ABC-Eval Fehlerrate nach Modell</sample>
    <sample id="1047">Sure, here's the translation: 'ABC-Eval Fehlerwerte nach Modell'</sample>
    <sample id="1048">Die Autoren gehören der Emory University.</sample>
    <sample id="1049">CFT stands for 'Continuous Fine-tuning'.</sample>
    <sample id="1050">Es sind 9 Autoren an der Arbeit beteiligt.</sample>
    <sample id="1051">Ja, das Bild zeigt eine Präsentationsseite mit dem Titel 'Wann benötigt Übersetzung Kontext?' und einem Subjekt 'Ein datentrivierter, multilinguales Erkunden'. Die Autoren sind Patrick Fernandes*, Kayo Yin*, Emmy Liu, André F. T. Martins und Graham Neubig.</sample>
    <sample id="1052">Die Übersetzung hängt von dem Kontext ab. Wir müssen uns von diesem Mole-freezie befreien.</sample>
    <sample id="1053">画面中有一段文字，内容是“Could it be anything serious, Doctor? We'll have to get rid of that mole.”。这段文字的背景是白色的，左上角有一行黑色的文字写着“Translation depends on context”。右上角有一个圆形的头像，头像下方有一个戴着帽子、穿着深色衣服的人在使用笔记本电脑的黑色剪影图案。</sample>
    <sample id="1054">Die Bedeutung des Wortes ändert sich je nach Kontext und daher wird es auch anders übersetzt.</sample>
    <sample id="1055">Der englische Text lautet: 'Evaluating context-dependent translation is hard. Only a small portion of words depend on context.'</sample>
    <sample id="1056">Das Bild zeigt eine Präsentation über den Schwerpunkt der Bewertung von kontextabhängigen Übersetzungen. Der Titel lautet 'Evaluating context-dependent translation is hard'. Es gibt drei Punkte: 1. Nur ein kleiner Teil von Worten hängt von Kontext ab - mit einer Unterzeile 'Corpus-level metrics' (Korpus-Level-Metriken). 2. Bestehende Methoden unterstützen begrenzte Diskursformen und Spracherscheinungen. 3. Bestehende Methoden unterstützen begrenzte Diskursformen, Phänomene und Sprachen. Im unteren rechten Eck des Bildes ist ein Silhouette eines Menschen zu sehen, der einen Stift hält und zwei Flaggen, die das britische und französische Flaggen sind, auf dem Kopf trägt.</sample>
    <sample id="1057">In this work, we tried to answer these two questions: First, when does translation require context? And second, how well do models handle context-dependent translations?</sample>
    <sample id="1058">RQ1: Wann benötigt die Übersetzung Kontext? - Kontextnutzung auf Wort-Level RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1059">图片中的文字内容是“Conditional Cross-Mutual Information (CXMI)”。</sample>
    <sample id="1060">Das Bild zeigt eine Präsentation über "Conditional Cross-Mutual Information (CXMI)". CXMI wird als Maßstab für die Kontextinformation, die von MT-Modellen (Machine Translation Models) erhalten wird, wenn man einem Körpus (einen Satz oder Text) gegeben wird. Das Bild enthält auch ein Diagramm mit zwei Blöcken, die den Übergang zwischen dem Quelltext und der Übersetzungsvorhersage darstellen.</sample>
    <sample id="1061">Der englische Inhalt lautet: 'We introduce P-CXMI to measure context usage to translate a specific sentence.'</sample>
    <sample id="1062">RQ1: Wann benötigt die Übersetzung Kontext? - Wortstufe Kontextnutzung - Thematischer Analyse RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1063">Der englische Text lautet: 'Thematic analysis of high P-CXMI words' und 'IDEAS WORTH SPREADING'.</sample>
    <sample id="1064">Thematikanalyse von hochwertigen P-CXML-Wörtern 1. POS-Tags</sample>
    <sample id="1065">Das Bild zeigt eine Präsentation über den thematischen Analyse hochp-CXMI-Wörter. Der Titel der Präsentation lautet "Thematic analysis of high P-CXMI words". Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm eines Menschen zu sehen, der wahrscheinlich die Präsentation führt.

Im linken Bereich des Bildes befindet sich ein Graph, der "P-CXMI for POS tags in En-Ar" zeigt. Der Graph zeigt drei Kategorien an: PRON 3.Sing, PRON 3.Dual und PRON 3.Plur. Jede Kategorie hat einen vertikalen Stengel, wobei der Stengel für PRON 3.Dual den höchsten Wert zeigt.

Rechts neben dem Graph befindet sich ein Textblock mit dem Titel "Pronouns", der aufgrund der Präsenz des Graphs und der Kategorien im Graph vermutlich mit den Präpositionen in der Präsentation verbunden ist.

Die gesamte Präsentation scheint sich auf die Analyse von hochp-CXMI-Wörtern und ihre Verwendung bei der Bezeichnung von Pronomen in der Sprache Englisch und Arabisch zu konzentrieren.</sample>
    <sample id="1066">Themenanalyse von hochp-CXML-Wörtern 1. POS-Tags 2. Wörter</sample>
    <sample id="1067">Das Bild zeigt eine Präsentation mit dem Titel 'Thematic analysis of high P-CXML words'. Es gibt zwei Hauptpunkte: 1. POS tags 2. Vocabulary items Die Slide zeigt zwei Beispiele an: - 'Avelile's mother was still asleep.' und 'Avelile went to school.' - '阿维利尔的母亲还在睡觉。' und '阿维利尔去上学了。' Rechts auf der Slide sind die Schwerpunkte aufgeführt: - Pronouns - Verb form - Lexical cohesion Im oberen rechten Eck ist ein kleiner Bild von einer Person zu sehen.</sample>
    <sample id="1068">Thematikanalyse von hochp-CXML-Wörtern 1. POS-Tags 2. Wortschatzelemente Avelile's Mutter war noch im Schlaf. Avelile ging zur Schule. Avelile的妈妈还在睡觉。Avelile去上学了。 - Pronomen - Verbenformen - Lexikalische Kohärenz - Formalität</sample>
    <sample id="1069">Thema: Analyse von hochp-CXML-Wörtern</sample>
    <sample id="1070">Die Übersetzung des englischen Inhalts ins Deutsche lautet: "RQ1: Wann benötigt eine Übersetzung Kontext? - Wortstufe-Kontextnutzung - Thematischer Analyse RQ2: Wie gut handhaben Modelle Kontextabhängige Übersetzungen? - Multilinguistischer Diskursbewusst-Aware (MuDA)-Benchmark"</sample>
    <sample id="1071">Das Bild zeigt eine Präsentation über den 'Multilingual Discourse-Aware (MuDA) tagger'. Der Titel ist oben links positioniert. Im Zentrum des Bildes befindet sich ein kleiner, quadratischer Block mit einem lilafarbenen Hintergrund und einer Liste von fünf Punkten: - Pronouns - Verb form - Lexical cohesion - Formality - Ellipsis Die Punkte sind in weißer Schrift dargestellt. Rechts oben im Bild ist ein kleines Bild eines Menschen zu sehen. Der Text auf der Präsentation ist klar und lesbar, und die Gesamtausstattung des Bildes suggeriert, dass es Teil einer wissenschaftlichen oder akademischen Präsentation ist.</sample>
    <sample id="1072">Multilingual Discourse-Aware (MuDA) tagger</sample>
    <sample id="1073">Das Bild zeigt eine Grafik, die einen Prozess darstellt, der mit einem Text-Block und einem Roboter-Logo beginnt. Der Text-Block wird durch einen Pfeil auf die rechte Seite weitergeleitet, wo er in eine Reihe von Blättern transformiert wird. Diese Blätter werden dann durch einen weiteren Pfeil auf die rechte Seite weitergeleitet, wo sie zu einem Textblock mit dem Text 'BLEU COMET F-measure...' führen. Dieser Textblock ist in einem rosa Feld eingefasst. Rechts neben diesem Feld steht ein Roboter-Logo. Im oberen rechten Eck des Bildes befindet sich ein kleiner Bildschirm mit einer Frau, die spricht. Im oberen linken Eck des Bildes ist der Text 'MuDA benchmark' zu sehen.</sample>
    <sample id="1074">RQ1: Wann benötigt die Übersetzung Kontext? - Wortstufe Kontextnutzung - Thematischer Analyse RQ2: Wie gut handeln Modelle mit kontextabhängigen Übersetzungen? - Multilinguistischer Diskursbewusster (MuDA) Benchmark - Modell Bewertung</sample>
    <sample id="1075">Zunächst einmal verwenden wir Korpus-Level-Metriken.</sample>
    <sample id="1076">图片中的文字内容包括： 1. 标题：Corpus-level metrics 2. 图片下方的标签：- BLEU - COMET - F-measure 每个标签都对应一个机器人图标，其中BLEU和COMET的机器人头部有“CONTEXT”字样。</sample>
    <sample id="1077">Das Bild zeigt drei Roboter, die verschiedene Metriken für die documentale Machine-Übersetzung (MT) darstellen. Links steht der Text 'BLEU', mitten ist 'COMET' und rechts 'F-measure'. Jeder Text ist innerhalb eines Roboterschutzhelm, der 'CONTEXT' trägt. Der Text 'Corpus-level metrics' ist oben im Bild zu sehen. Im unteren linken Eck befindet sich ein Text, der lautet: 'Unclear which system is best for document-level MT with corpus-level metrics alone.'</sample>
    <sample id="1078">Das englische Inhalt lautet: 'Corpus-level metrics' und 'MuDA benchmark results'.</sample>
    <sample id="1079">Der englische Inhalt lautet: 'Context-aware models perform significantly better on some phenomena o ✅: Formality, lexical cohesion ❌: Ellipsis, pronouns, verb form'.</sample>
    <sample id="1080">MuDA benchmark results Context-aware models perform significantly better on some phenomena o ✓: Formality, lexical cohesion X Ellipsis, pronouns, verb form DeepL outperforms Google on most phenomena and language pairs* as of April 2021</sample>
    <sample id="1081">MuDA benchmark results Context-aware models perform significantly better on some phenomena Formality, lexical cohesion Ellipsis, pronouns, verb form DeepL outperforms Google on most phenomena and language pairs* Summary Identify discourse phenomena systematically without prior linguistic knowledge Dataset-agnostic benchmark for document-level MT MuDA tagger BLEU F-measure ... robot</sample>
    <sample id="1082">Summary Identify discourse phenomena systematically without prior linguistic knowledge Dataset-agnostic benchmark for document-level MT</sample>
    <sample id="1083">Ja, das Bild zeigt eine Präsentation. Es gibt einen Titel "Summary" und zwei Punkte: 1. Identifizieren Sie diskursbezogene Phänomene systematical ohne vorherige Sprachwissen. 2. Dataset-agnostic Benchmark für Dokumentenstufe MT. Darüber hinaus sind auf dem Bild zwei Grafiken zu sehen: eine mit Dokumenten und einem Tagger und eine mit einem Robotern und einem F-Meter.</sample>
    <sample id="1084">Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang</sample>
    <sample id="1121">Permut</sample>
    <sample id="1122">Die Autoren beschreiben die Methode der „markierten Wörter“ als eine Methode, um Wörter zu identifizieren, die die Persönlichkeiten von markierten Gruppen unterscheiden können von Gruppen ohne Markierungen.</sample>
    <sample id="1123">The authors belong to the University of Washington and Carnegie Mellon University.</sample>
    <sample id="1124">Der Name der zuerst erwähnten symmetrischen Abhängigkeitsstruktur lautet Bouquet/Stanford (Universal Dependencies).</sample>
    <sample id="1125">Sarah E. Finch, James D. Finch, and Jinho D. Choi</sample>
    <sample id="1126">Es sind fünf Autoren an der Arbeit beteiligt.</sample>
    <sample id="1127">Blinp, Syntaxgym, and Crows.</sample>
    <sample id="1161">The five methods are FTw, COSINE, BOND, MLC, and L2R.</sample>
    <sample id="1162">The model is evaluated based on 11 tasks.</sample>
    <sample id="1226">CamemBERT wurde mit 4 GB von PubMed-Daten trainiert.</sample>
    <sample id="1227">Adam Przebiorkowski und Michat Wozniak</sample>
    <sample id="1228">Die Zeitverzögerung führte zu der Schlussfolgern, dass sie die Haupt Ursache für den Leistungsverlust war.</sample>
    <sample id="1269">Es ist notwendig, die Token für die Ausgabesequenz zu permutieren, weil sie nicht in der richtigen Reihenfolge angeordnet sind.</sample>
    <sample id="1270">The reasons include: 1. Addressing positive stereotypes and essentializing narratives, which can lead to biased outcomes if not managed properly. 2. Using an intersectional lens for a more comprehensive understanding of biases. 3. Ensuring transparency about bias mitigation methods to build trust in the model development process.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind die in der Tabelle unter 'Crow's' aufgelisteten Sätze.</sample>
    <sample id="1272">The authors used the following evaluation metrics: NER, CER, F1, and MAP.</sample>
    <sample id="1273">Krippendorf's Alpha</sample>
    <sample id="1274">Wikipedia.</sample>
    <sample id="1275">Die Autoren gehören der Heinrich Heine University Düsseldorf, Deutschland.</sample>
    <sample id="1276">MultiInstruct focuses on instruction tuning for multimodal pre-trained models, addressing the imbalance in instructional datasets between NLP and multimodal tasks.</sample>
    <sample id="1277">Es sind drei Autoren an der Arbeit beteiligt.</sample>
    <sample id="1278">Binäre Koordination bedeutet, dass zwei Atome miteinander verbunden sind, wobei jeder Atom nur mit einem anderen Atom verbunden ist.</sample>
    <sample id="1279">The average prompt length in this study was 10 words.</sample>
    <sample id="1280">The results show that the T5 model trained on Coscript can generate higher quality scripts than large language models like GPT-3, Codex, and InstructGPT. This suggests that smaller models with fine-tuning capabilities can be competitive or even outperform larger models when given appropriate training data.</sample>
    <sample id="1281">DrBERT: Ein robustes vorher trainiertes Modell auf Französisch für medizinische und klinische Bereiche.</sample>
    <sample id="1282">In diesem Vortrag sprechen wir zunächst über Sprachmodellierung in der Gesundheitsversorgung.</sample>
    <sample id="1283">Summary I. Language Modeling in Healthcare II. Comparison of pre-training strategies, data sources and sizes III. Evaluation of 13 models on 11 tasks IV. Distribution of NACHOS and DrBERT</sample>
    <sample id="1284">Summary I. Language Modeling in Healthcare II. Comparison of pre-training strategies, data sources and sizes III. Evaluation of 13 models on 11 tasks IV. Distribution of NACHOS and DrBERT</sample>
    <sample id="1285">I. Sprachmodellierung in der Gesundheitsversorgung II. Vergleich von Vorbereitungsstrategien, Datenquellen und Größen III. Bewertung von 13 Modellen auf 11 Aufgaben IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1286">Transformer-based approaches, such as BERT, offer huge performance gains on a lot of NLP tasks.</sample>
    <sample id="1287">Der englische Inhalt lautet:</sample>
    <sample id="1288">Der englische Text lautet: 'Specialized models for other languages are rarer and rely primarily on continual pre-training using an existing generic model.'</sample>
    <sample id="1289">Transformer-base方法，例如BERT，在许多NLP任务上取得了巨大的性能提升。它已经被适应为法语的CamemBERT和FlauBERT。在医疗领域，基于特定领域的模型在英语中设定了更高的标准。PudMedBERT、BioBERT、ClinicalBERT和其他。其他语言比英语更罕见，主要依赖于预先训练并使用现有的通用模型。目前，还没有开源的生物医学领域模型可用。然而，基于特定领域的模型对法语在医疗任务上的性能有希望的改进。</sample>
    <sample id="1290">图片中的文字内容是关于“比较预训练策略和数据源”的。</sample>
    <sample id="1291">NACHOS: A 1.1B+ subword open-source dataset of heterogeneous data crawled from various medical domains, natures and styles NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse</sample>
    <sample id="1292">Es ist 8 GB oder mehr.</sample>
    <sample id="1293">Das Bild zeigt eine Präsentation über die Vergleichung von Vorbereitungsmethoden und Datenquellen. Der Titel der Präsentation lautet "Vergleich von Vorbereitungsmethoden und Datenquellen". Die Präsentation umfasst eine Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datensätze. Sie erwähnt zwei Datenquellen: NACHOS, ein 1,18B-Wort-dictonaire aus heterogenen Daten, die von mehreren medizinischen Bereichen, Stilen und Niveaustypen herbeigeholt wurden, und NBDW, ein Privatsatz von Sätzen, der aus 1,7M anonymisierten Medizinnotizen aus dem Hospital-Datenlager der Université de Nantes stammt.

Die Präsentation bietet auch einen Vergleich von Lernstrategien, einschließlich der Vorbereitung von Modellen von scratch, der Vorbereitung mit einem vorkennten Modell (z.B. CamemBERT oder PubMedBERT) und der Vorbereitung mit einem vorkennten Modell, das für das Vorbereiten von Sätzen trainiert wurde. Eine Tabelle ist im Bild zu sehen, die die Größe und die Anzahl der Resourcen für verschiedene Versionen von NACHOS und NBDW angibt.

Im unteren rechten Eck des Bildes befindet sich ein Logo, das "Avignon Université" trägt.</sample>
    <sample id="1294">Das Bild zeigt eine Präsentation über die Vergleichung von Vorbereitungsmethoden und Datenquellen für Sprachmodelle. Der Titel der Präsentation lautet "Comparison of pre-training strategies and data sources". Die Präsentation umfasst folgende Punkte: - Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datensätze - Vergleich von Vorbereitungsmethoden, einschließlich der Erstellung von Modellen von scratch und der Verwendung von vorvorlagigen Modellen wie CamemBert, GPT-2 und PubMedBERT</sample>
    <sample id="1295">Das Bild zeigt eine Präsentation über die Vergleichung von Vorbereitungsstrategien und Datenquellen. Die Titelseite lautet "Vergleich von Vorbereitungsstrategien und Datenquellen".</sample>
    <sample id="1296">Das Bild zeigt eine Präsentation über die Vergleichung von Vorbereitungsmethoden und Datenquellen. Der Titel der Präsentation lautet "Comparison of pre-training strategies and data sources". Die Präsentation umfasst folgende Punkte: - Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf ähnliche Datensätze - Vergleich von Vorbereitungsmethoden und Datenquellen, einschließlich NACHOS, NBDW und Camembert</sample>
    <sample id="1297">图片中的文字内容是：Comparison of pre-training strategies and data sources Evaluation of the impact of public and private medical data sources on comparable data sizes NACHOS: A 1.1B+ subs open-source dataset of heterogeneous data crawled from various medical domains, natures and styles NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse Comparison of learning strategies From scratch with full model construction Continual pre-training using an existing pre-trained model (e.g., CamemBERT, a French generic model, and PubMedBERT, an English medical one) Corpus Size | Reference | Resources 4 GB | 25 M | 25 M | 4 GB | 64 GB | 64 GB | 96 GB | 96 GB</sample>
    <sample id="1298">Das Bild zeigt eine Präsentation mit dem Titel "Evaluation: Data sources and size". Es handelt sich um eine Übersetzung des englischen Inhalts ins Deutsche. Die Präsentation zeigt eine Tabelle, die verschiedene Modelle und ihre Leistungen auf verschiedenen Aufgaben anzeigt. Die Tabelle enthält Spalten für verschiedene Modelle wie "CANNONBERT", "Biobert" und "CHAMBERNERT". Jede Spalte zeigt die Leistung dieser Modelle auf verschiedenen Aufgaben wie "NER", "CLF", "NER-CLF", "NER-CAS", "NER-POS" und "NER-MER". Die Tabelle bietet eine detaillierte Überwachung der Leistungen dieser Modelle auf verschiedenen Datenquellen und Größen. Im unteren rechten Ecke des Bildes ist das Logo der Avignon Universität zu sehen.</sample>
    <sample id="1299">Das Bild zeigt eine Präsentation, die sich auf die Bewertung von Datenquellen und Größe konzentriert. Der Titel der Präsentation lautet 'Evaluation: Data sources and size'. Es gibt eine Tabelle mit verschiedenen Modelien, die auf 13 Aufgaben in verschiedenen Bereichen wie Medizin und Wissenschaft getestet wurden. Die Tabelle enthält Informationen über die Ressourcen, die für die Modellierung benötigt wurden, sowie die Leistung jedes Models in den verschiedenen Aufgabenbereichen. Im unteren rechten Ecke des Bildes ist das Logo der Avignon Universität zu sehen.</sample>
    <sample id="1300">Das Bild zeigt eine Präsentation über die Bewertung von Datenquellen und Größe. Es gibt eine Tabelle, die verschiedene Modelle und ihre Leistungen auf verschiedenen Aufgaben anzeigt. Die Tabelle enthält Spalten für verschiedene Aufgaben (NER, CLE, NER Medical, Report, etc.) und verschiedene Modelle wie "CANNABERT HPS 128 GB", "Biobert v1.0.01", "CHIMERA NACHOS large" und "CHIMERA NACHOS small". Jedes Modell hat eine Reihe von Zahlen darunter, die wahrscheinlich die Leistung oder die Genauigkeit der Modelle auf den verschiedenen Aufgaben anzeigen. Im unteren rechten Ecke ist das Logo der Avignon Universität zu sehen.</sample>
    <sample id="1301">Die Übersetzung des englischen Inhalts ins Deutsche lautet: 'Evaluierung: Datenquellen und Größe. - Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch private. - Unser überlagertes Modell erreicht in der Regel die Besten auf fast allen Aufgaben.'</sample>
    <sample id="1302">Insgesamt scheint es, dass das Ausbildung von scratch und das Fortfahren mit Vortraining auf 4 GB Daten besser funktioniert.</sample>
    <sample id="1303">Das englische Text ist 'However, our experiment on continual pretraining using the weight and tokenizer of PubMed BERT trained on the 4 gigabytes subset of NACHOS showed comparable results to those obtained with the same model'.</sample>
    <sample id="1304">Der englische Text lautet: "Which is not the case for the model based on CAMBENBERT weights and tokenizer which suffer from stability issues."</sample>
    <sample id="1305">Core message: DRBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks. Surpasses Camembert generic model and English-based domain-specific models. Confirms utility of training a medical-specific model in French. Data sources matter; training on heterogeneous data is important. NACHOS is more robust than using private clinical data only. More data is better, but does not scale well. Continual pretraining is a more effective strategy when based on domain-specific English models. The DRBERT models, the NACHOS dataset, and the training scripts are freely available under the MIT license.</sample>
    <sample id="1306">Der englische Text lautet: 'We also observed that special data is better, but it doesn't scale well.'</sample>
    <sample id="1307">Das Präsentationsslide zeigt den "Core message" (Zentraler Message) und enthält folgende Punkte: 1. DRBERT erreicht die bestmögliche Leistung in 9 französischen Medizinverfahrensaufgaben, die von Downstream generiert wurden. 2. Er übertrifft den CamemBERT-Generalmuster und die englischsprachigen Domänen-Spezialmodellen. 3. Es wird bestätigt, dass das Training eines medizinischen Modells auf französischer Sprache nützlich ist. 4. Das Training auf heterogenen Daten ist wichtig. 5. NACHOS ist robust, aber nicht mit privaten Patientendaten. 6. Mehr Daten sind besser, aber sie können nicht skalieren. 7. Vorbereitung für das Training ist eine effektivere Strategie, wenn basierend auf englischen Modell-Domänen. 8. Die DRBERT-Modelle, der NACHOS-Dataset und die Skripte sind unter der MIT-Lizenz frei verfügbar. Im unteren rechten Ecke befindet sich ein QR-Code, und im unteren linken Eck ist das Logo der Universität Avignon.</sample>
    <sample id="1308">Danke für die Präsentation. Wir freuen uns darauf, an der Poster-Sitzung in Toronto zu exchangen.</sample>
    <sample id="1309">In the slide, the comparison of pre-training strategies and data sources is being discussed.</sample>
    <sample id="1310">Der Faktor der Überanpassung, der speziell auf die Wiederverwendung von Tests zurückzuführen ist, beträgt 1.5.</sample>
    <sample id="1311">The image shows a detailed comparison of text simplification results at different levels: document, sentence, and DEPLAIN-APA. The title "Automatic Text Simplification" is prominently displayed in the top left corner with an icon featuring three stylized human figures next to it. Below this heading are four sections labeled as follows:

1. Document Level
2. Sentence Level
3. DEPLAIN-APA test (n=48)
4. DEPLAIN-APA test (n=147)

Each section contains tables that compare various metrics such as BLEU, F1, and PRE for different models or configurations including "Deap-simpl," "Deap-simpl-APA," "Deap-simpl-BART," "Deap-simpl-BART-APA," and their respective baselines.

The background color scheme includes shades of blue and white, which helps distinguish between different parts of the chart clearly. Additionally, there's a person visible on the right side of the frame, likely presenting or discussing the content shown in the slide.</sample>
    <sample id="1312">Ja, Sprachmodelle können unterschiedliche politische Vorurteile haben.</sample>
    <sample id="1313">Das Bild zeigt eine Präsentation über ein Forschungsarbeitspapier. Der Titel des Papiers lautet 'Compositional Generalization without Trees using Multiset Tagging and Latent Permutations'. Die Autoren sind Matthias Lindemann, Alexander Koller und Ivan Titov. Das Papier wurde von der Universität des Amstadsamms, Saarland University und der Universität des Amstadsamms präsentiert. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm mit einem Mann zu sehen, der wahrscheinlich die Präsentation gibt.</sample>
    <sample id="1314">Dies ist gemeinsame Arbeit mit meinen Beratern Alexander Koller und Ivan Titov.</sample>
    <sample id="1315">Compositional Generalization ist die Fähigkeit eines Lerners, tiefer recursion zu verarbeiten und Kompositionen von Phrasen zu bearbeiten, die während der Ausbildung allein gesehen wurden.</sample>
    <sample id="1316">Das Bild zeigt eine Übersetzung des englischen Inhalts ins Deutsche. Es handelt sich um ein Bild, das Informationen über 'Compositional Generalization in Semantic Parsing' enthält. Das Bild enthält zwei Sätze, die auf Deutsch übersetzt sind: 'Die Mädchen schläft' und 'Mary wusste, dass das Mädchen schläft'. Diese Sätze sind Teil eines Trainings-Sets für die Semantische Parse.</sample>
    <sample id="1317">Inhalt des englischen Textes auf Deutsch: "Train: The girl slept." "girl x, sleep, agent x" "Mary knew that the girl slept." "girl x, know, agent x, Mary A, know, ccomp x, A, sleep, agent x"</sample>
    <sample id="1318">In contrast to standard machine learning evaluation, the test set does not come from the same distribution but contains structurally unseen logical forms.</sample>
    <sample id="1319">In this example, the model has seen shallow recursion during training and is tested on an example with deeper recursion.</sample>
    <sample id="1320">Der englische Text lautet: 'naive seq2seq models fail!'</sample>
    <sample id="1321">Das Bild zeigt eine Präsentation über 'Kompositionelle Allgemeinheit in Semantischer Grammatik'. Es gibt zwei Tabellen, eine für die Trainingsdaten und eine für die Testdaten. Jede Tabelle hat zwei Zeilen, wobei die erste Zeile den Satz 'The girl slept.' und seine grammatikalische Analyse zeigt, und die zweite Zeile den Satz 'Mary knew that the girl slept.' und seine grammatikalische Analyse. Im Test-Tablett ist der Satz 'Jim said that Mary knew that the girl slept.' mit seiner grammatikalischen Analyse präsentiert. Am Ende des Bildes ist der Text 'Naive seq2seq models fail!' in roter Schrift zu sehen.</sample>
    <sample id="1322">Trees help a lot but...</sample>
    <sample id="1323">Bäume helfen sehr, aber... *girl x1; sleep.agent x2 x *girl x4, x1 sleep.agent x2 The girl slept.</sample>
    <sample id="1324">Trees help a lot but... Trees need to be obtained: - Pre/Post-processing logical forms</sample>
    <sample id="1325">The image contains text in both English and German. Here is the translation of the English content to German: "Trees help a lot but... Trees need to be obtained: - Pre/Post-processing logical forms" The rest of the text appears to be part of an explanation or discussion, possibly related to computational linguistics or natural language processing, given the context of trees and logical forms mentioned.</sample>
    <sample id="1326">Trees help a lot but... Trees need to be obtained: - Pre/Post-processing logical forms - Grammar-induction</sample>
    <sample id="1327">Ja, das Bild zeigt einen Text, der auf Deutsch übersetzt wurde. Der englische Inhalt lautet: 'In this paper we don't use trees and introduce a neural seq2seq model that directly models the correspondences between fragments.'</sample>
    <sample id="1328">Trees helfen sehr, aber...</sample>
    <sample id="1329">Das Bild zeigt eine visuelle Darstellung einer Ansatzart für die Vorschreibung von Output aus Eingaben. Links steht der Text "Our Approach" in einer gelben Schrift, was auf den Anfang eines Schrittweisen Verfahrens hinweist. Im Zentrum sind vier blaue Boxen zu sehen, die jeweils mit einem Wort oder einem Wortstamm versehen sind: '*', 'x1', 'girl' und 'x2'. Diese Boxen sind mit schwarzen Pfeilen auf eine lange graue Linie verankert, die "Tag" trägt. Diese Linie ist mit zwei weiteren schwarzen Pfeilen auf Wörter verankert: "the" und "slept". Die gesamte Abbildung scheint ein Diagramm zu sein, das eine Methode zur Vorschreibung von Output aus Eingaben darstellt, wobei die Boxen und die Wörter möglicherweise verschiedene Schritte oder Komponenten des Prozesses repräsentieren.</sample>
    <sample id="1330">Der englische Inhalt lautet: 'First, we tag each input token with an unordered multiset of tokens that will appear in the output.'</sample>
    <sample id="1331">Nach der ersten Schritt haben wir alle Token, aber sie sind nicht ordentlich.</sample>
    <sample id="1332">Der englische Text lautet: 'That's why in the second step, we use another model to predict a permutation to put them into the right order.'</sample>
    <sample id="1333">Das Bild zeigt eine Diagrammstruktur, die einen Vorschlag für eine neue Methode zur Permutation darstellt. Der Titel 'Our Approach' ist in Gelb hervorgehoben. Das Diagramm besteht aus mehreren Schritten: 1. **Permutieren**: Dieser Schritt umfasst das Umordnen von Elementen, wie 'girl', 'sleep', 'agent', 'x2' und 'x1'. 2. **Taggen**: Diese Schritt befasst sich mit der Bezeichnung der Elemente, wie zum Beispiel 'the', 'girl' und 'slept'. Die Elemente werden durch verschiedene Farben gekennzeichnet (grün, gelb und orange), was darauf hinweist, dass sie unterschiedliche Rollen oder Arten haben. Die Verbindungen zwischen den Elementen und den Schritten 'Permutieren' und 'Taggen' deuten an, dass die Methode eine flexible und ausdrucksstarke Herangehensweise zur Permutation bietet.</sample>
    <sample id="1334">Das Bild zeigt eine visuelle Darstellung eines Permutationsschemas, das "Permuting with 'jumps'" genannt wird. Das Schema besteht aus zwei Hauptabschnitten: "Permute" und "Tag". In der "Permute"-Abschnitt sind verschiedene Wörter wie "girl", "sleep", "agent" und "x2" in verschiedenen Farben dargestellt (z.B. gelb, blau). Eine Worte mit einem roten Rahmenelement ist auch zu sehen. Im "Tag"-Abschnitt sind Wörter wie "the", "girl" und "slept" dargestellt. Links am Bild ist der Text "Permuting with 'jumps'" zu sehen.</sample>
    <sample id="1335">Das Bild zeigt eine Diagramm, das die Prozesse der 'Permutation mit Sprüngen' (Permute with "jumps") beschreibt. Es gibt drei Hauptbereiche: 'Permute', 'Tag' und 'Output'. Die 'Permute'-Zone hat verschiedene Elemente, darunter ein grünes Quadrat mit einem roten Rand und zwei gelbe Quadrate, die 'x1' und 'girl' bezeichnen. Darüber hinaus sind zwei weitere blaue Quadrate mit den Wörtern 'sleep' und 'agent' sowie ein weiteres blaues Quadrat mit 'x2' darin. Im 'Tag'-Bereich sind drei Wörter angezeigt: 'the', 'girl' und 'slept'. Der Text oben lautet 'Permuting with "jumps"'.</sample>
    <sample id="1336">Der englische Text lautet: 'Then we jump to the next multiset of token to determine the second token in the output.'</sample>
    <sample id="1337">Der englische Text lautet: 'We determine the third token in the output in a similar way by jumping to another multiset token.'</sample>
    <sample id="1338">Permute mit "Sprühen"</sample>
    <sample id="1339">Das Bild zeigt eine Grafik mit dem Titel "Some Results on COGS (Kim and Linzen 2020)". Die Graphik zeigt die Vergleichung von Treeless-Modellen bei der Strukturverallgemeinerung auf COGS. Es gibt vier Modelle: LSTM seq2seq, TS, Zheng und Lapata, sowie das Modell "Ours". Die Y-Achse zeigt den Accuracy (%) an, und die X-Achse zeigt verschiedene Generationsarten: PP recursion, CP recursion und Obj PP → Subj PP. Jedes Modell wird durch eine andere Farbe dargestellt, und es gibt sichtbare Fehlerbars, die den Standardfehler für jedes Modell anzeigen.</sample>
    <sample id="1340">Some other kinds of structural organization remain very challenging though.</sample>
    <sample id="1341">Das englische Textstück lautet: "In our paper, we solve a couple of interesting technical challenges."</sample>
    <sample id="1342">Der englische Inhalt lautet: 'First of all, the alignment between input and output is not given in the training data. As a consequence for a given token we don't know which multiset it came from, which poses a challenge for training.'</sample>
    <sample id="1343">Ja, das Bild zeigt eine Infografik mit dem Titel 'Technical Challenges We Solve'. Es gibt einige englische Texte, die wir übersetzen können.</sample>
    <sample id="1344">图片中的文字内容是：'Technical Challenges We Solve Alignment unknown. Induce it in training. Permutation model: Inference is NP-hard (= TSP)'</sample>
    <sample id="1345">Das Bild zeigt eine visuelle Darstellung eines technischen Problems, das gelöst wird. Es handelt sich um ein Diagramm mit verschiedenen Elementen und Verbindungen, die auf einer Schicht überlagert sind. Der Titel des Diagramms lautet 'Technical Challenges We Solve'. Die Darstellung umfasst einen Prozess namens 'Permute', der mit einer Reihe von Elementen verbunden ist, die wie Wörter oder Zahlen aussehen. Diese Elemente werden durch Pfeile und Linien verknüpft, was darauf hindeutet, dass es sich um eine Komplexität handelt, die mit einem bestimmten Algorithmus oder Prozess löst wird. Links am Diagramm befindet sich der Text 'Alignment unknown.' und rechts steht 'Induce it in training.' Diese Bemerkungen deuten an, dass das Problem mit der Unbekantheit der Ausrichtung zu beheben ist und dass dies während des Trainings durch eine spezifische Methode erreicht werden soll. Am unteren Ende des Diagramms befindet sich der Text 'Permutation model:' gefolgt von zwei Punkten: 'Inference is NP-hard (= TSP)' und 'Backpropagate through continuous relaxation'. Diese Punkte deuten an, dass das Modell, das für die Permutation verwendet wird, NP-Hard ist (was bedeutet, dass es für eine effiziente Lösung nicht polynomial zu lösen ist) und dass die Rückpropagation durch kontinuierliche Relaxation durchgeführt wird.</sample>
    <sample id="1346">Das Bild zeigt eine Präsentation mit dem Titel "Technical Challenges We Solve". Es gibt eine Diagrammstruktur, die verschiedene Wörter und Phrasen wie "sleep", "agent", "girl" und "the" enthält. Diese Wörter sind in verschiedenen Farben markiert (grün, blau, rot) und verbinden sich durch Pfeile und Linien. Der Text "Permute" ist auf einem grauen Hintergrund prominent dargestellt. Darunter steht "Alignment unknown." und "Induce it in training." Die Abschnitte "Permutation model:" folgen, wobei zwei Punkte aufgeführt sind: - Inferenz ist NP-hart (TSP) - Backpropagieren durch kontinuumsrelaxation Die rechte Seite des Bildes zeigt einen QR-Code und den Text "Paper &amp; Code:" gefolgt von einer URL.</sample>
    <sample id="1347">Cognitive dissonance is two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent.</sample>
    <sample id="1348">BERT-base</sample>
    <sample id="1349">Ja, kumulatives Training ist besser als iteratives Training für aktives Lernen.</sample>
    <sample id="1350">Sara Papi</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark kommen aus der Analyse von Texten, die auf TED Talks übertragen wurden.</sample>
    <sample id="1385">Der Referent heißt Matthias Lindemann.</sample>
    <sample id="1386">Cross-lingual Zero-shot/Few-shot transfer.</sample>
    <sample id="1387">Dawei Zhu, Xiaoyu Shen, Marius Mosbach, Andreas Stephan, and Dietrich Klakow.</sample>
    <sample id="1388">The authors use BLEU scores as a quality measure and average latency (AL/AL_CA) as an additional metric.</sample>
    <sample id="1389">Das englische Text ist auf dem Bild zu sehen. Es handelt sich um einen Vortrag über "The KITMUS Test" mit dem Titel "Evaluating Knowledge Integration from Multiple Sources". Die Vortragenden sind Akthar Al-Ali, Martin Poms!, Kaheer Saleem, Adam Trischler, Alexandra Olteneanu und Jackie CK Cheang. Ihre Institutionen sind McGill University/Mila, Microsoft Research und McGill University/Mila.</sample>
    <sample id="1390">NLU-Modeln nutzen mehrere Wissensquellen.</sample>
    <sample id="1391">NLU模型从多个知识来源中汲取知识。</sample>
    <sample id="1392">John sah die neu gewählte Präsidentin auf der TV.</sample>
    <sample id="1393">John sah den neu gewählten Präsidenten auf der TV</sample>
    <sample id="1394">Die englische Phrase 'pretrain-time knowledge' bedeutet in Deutsch 'Vorausgebildete Kenntnisse'.</sample>
    <sample id="1395">Das Bild zeigt eine Präsentation, die sich auf Sprachverarbeitung und das Verbinden von Vorwiss- und Inferenzwissen für die Interpretation von Texten konzentriert. Der Titel der Präsentation lautet: "John sah den neu gewählten Präsidenten auf der TV." Die Präsentation ist in zwei Hauptabschnitte unterteilt:</sample>
    <sample id="1396">Das Bild zeigt eine Präsentation über das KITMUS Test Suite. Der Titel "KITMUS Test Suite" ist oben in bold-weißem Text zu sehen. Im Hintergrund ist ein weißer Text auf einem schwarzen Hintergrund zu lesen: - Dataset für die Bewertung der Wissensintegration - Coreference Resolution Aufgabe, um die Fähigkeit zu prüfen, auf - Vorausgebende Wissen - Inferenzzeit-Wissen - Experiment mit - menschlichen Studienbeteiligten - Coreference Resolution-Modelle Links neben dem Text befindet sich ein kleineres Bild eines Menschen, der wahrscheinlich den Vortrag gibt. Im unteren rechten Ecke des Bildes ist der Text "5" zu sehen, was darauf hindeutet, dass dies die 5. Folge der Präsentation ist.</sample>
    <sample id="1397">Das Bild zeigt eine Präsentation mit dem Titel 'KITMUS Test Suite'. Der Text auf der Seite lautet: 'Dataset for knowledge integration evaluation' und 'Coreference resolution task to probe ability to draw on pretrain-time knowledge inference-time knowledge Experiment with human study participants coreference resolution models'. Im oberen rechten Eck ist ein kleiner Bildschirm mit einer Person zu sehen. Die Folie ist die 5. Folie der Präsentation.</sample>
    <sample id="1398">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]</sample>
    <sample id="1399">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]</sample>
    <sample id="1400">Das Bild zeigt eine Präsentation mit dem Titel 'KITMUS Test Suite'. Im Hintergrund ist ein Text zu sehen, der die folgende Information enthält:</sample>
    <sample id="1401">Servin ist ein Richter. Kea ist ein Kuchback. Servin und Kea haben sich am Park getroffen. Nach einem langen Tag, in dem sie in einem Gerichtshof Entscheidungen trifft, war er zufrieden. [Antwort: Servin]</sample>
    <sample id="1402">Der englische Inhalt lautet: 'Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]'</sample>
    <sample id="1403">Das Bild zeigt eine Präsentation über die 'Variants of KITMUS'. Es gibt drei verschiedene Konzepte: (a) BACKGROUND-PRETRAIN, (b) BACKGROUND-BOTH und (c) BACKGROUND-INFERRENCE. Jeder Konzept hat zwei Abschnitte: Pretrain-time und inference-time. Die Beschreibungen der Konzepte sind auf der linken Seite des Bildes zu finden.</sample>
    <sample id="1404">Das Bild zeigt eine Präsentation über 'Variants of KITMUS'. Es gibt drei Diagramme, die verschiedene Konzepte darstellen: (a) BACKGROUND-PRETRAIN, (b) BACKGROUND-BOTH, und (c) BACKGROUND-INFERENCE. Jedes Diagramm hat zwei Abschnitte: 'Pretrain-time' und 'Inference-time', wobei 'Background knowledge' in beiden Abschnitten eingezeichnet ist. Die Texte auf dem Bild sind in Englisch.</sample>
    <sample id="1405">Variants of KITMUS</sample>
    <sample id="1406">Politicians seek elected seats in government.</sample>
    <sample id="1407">Das Bild zeigt eine Präsentation über verschiedene Varianten des KITMUS-Modells. Die Titelseite lautet "Variants of KITMUS". Das Bild enthält drei Diagramme, jedes mit einem Titel und einem Textblock unterhalb. Der erste Diagramm heißt "Background-Pretrain" und zeigt den Text: "Politicians seek elected seats in government." Der zweite Diagramm heißt "Background-Both" und zeigt den Text: "Chichester is a politician." Der dritte Diagramm heißt "Background-Inference" und zeigt den Text: "Chichester is a muniturer." Jedes Diagramm hat eine Grafik oben und einen Textblock unten, der sich auf das Modell und seine Funktionsweise bezieht.</sample>
    <sample id="1408">Variants of KITMUS</sample>
    <sample id="1409">Politicians seek elected seats in government.</sample>
    <sample id="1410">Das Bild zeigt eine Präsentation mit einem Graphen und einem Text. Der Titel der Präsentation lautet 'Background-Pretrain'. Der Graph zeigt die Leistung von verschiedenen Modellen in Bezug auf den Aufgabenverlauf, unterteilt in zwei Kategorien: 'Without task-specific training' und 'With task-specific training'. Die Leistung wird in einem Bereich zwischen 0 und 1 angezeigt. Es gibt drei verschiedene Linien, die darauf hindeuten, dass sie verschiedene Gruppen oder Modelle darstellen: 'Random Choice', 'Human Participants', 'BERTaCoref', und 'C2F'. Der Text am unteren Rand des Bildes lautet: 'Task-specific training is necessary for knowledge integration.' Das Bild scheint Teil einer wissenschaftlichen Präsentation zu sein, die sich auf das Training von Modellen konzentriert, um Kenntnisse zu integrieren.</sample>
    <sample id="1411">图片中显示了一个条形图，标题为“Background-Pretrain”。图表比较了在没有任务特定训练和有任务特定训练的情况下，不同模型的性能。具体来说，它展示了“随机选择”、“人类参与者”、“BERT4CoReF”和“C2F”模型的表现。图表中的轴标签分别是“Without task-specific training”（没有任务特定训练）和“With task-specific training”（有任务特定训练）。每个类别下都有一个条形，表示不同模型的性能。底部有一段文字写着“任务特定训练对于知识整合是必要的”，强调了任务特定训练的重要性。</sample>
    <sample id="1412">Das Bild zeigt eine Präsentation mit einem Diagramm, das die Leistung von drei Gruppen - Random Choice, Human Participants, BERTaCoReF und C2F - im Vergleich zu den beiden Training-Methoden "Without task-specific training" und "With task-specific training" darstellt. Der Text am unteren Rand des Bildes lautet: 'Task-specific training is necessary for knowledge integration'.</sample>
    <sample id="1413">Das Bild zeigt eine Präsentation über den Hintergrundschluss. Der Titel der Präsentation lautet 'Background-Inference'. Im unteren Teil des Bildes befindet sich ein Graph, der die Leistung von verschiedenen Gruppen in Bezug auf den Hintergrundschluss zeigt. Die Gruppen sind 'Random Choice', 'Human Participants', 'BERT4CoRef' und 'C2F'. Der Graph zeigt die Merkmale des Hintergrundwissens für diese Gruppen. Links am Bild ist der Text 'Models struggle to integrate inference-time background knowledge' zu sehen. Im oberen rechten Eck des Bildes ist eine Person zu sehen, die wahrscheinlich die Präsentation gibt.</sample>
    <sample id="1414">Das Hauptabschluss ist, dass viele Modelle nicht in der Lage sind, Wissen von mehreren Quellen zu verarbeiten (vor- und während der Aufgabe). Task-Spezifische Training ist für das Integration von Wissen notwendig. Modelle haben Schwierigkeiten, Wissen aus verschiedenen Quellen zu integrieren.</sample>
    <sample id="1415">Ja, das Bild zeigt eine Präsentation. Im oberen rechten Eck ist ein Mann zu sehen, der wahrscheinlich die Präsentation macht. Der Text auf dem Bild lautet 'Conclusion' und gibt einige Schlussfolgerungen und Hauptpunkte an. Es wird auch erwähnt, dass man den Dataset, die Generation und die Bewertungscode auf GitHub finden kann unter der URL 'mpoems1/kitmus'.</sample>
    <sample id="1416">Trees help a lot but... Trees need to be obtained: - Pre/Post-processing logical forms - Grammar-induction</sample>
    <sample id="1417">Shuheng Liu and Alan Ritter belong to the Georgia Institute of Technology.</sample>
    <sample id="1418">Das englische Text ist in einem Poster über den Titel "Marked Personas" präsentiert. Es handelt sich um eine Forschungsarbeit, die mit dem Thema "Verwendung natürlicher Sprachanregungen, um Rassismuskonzepte in Sprachmodellen zu messen" beschäftigt. Die Autoren sind Myra Cheng, Esin Durmus und Dan Jurafsky, und die Arbeit wurde im Jahr 2023 zur ACL (Association for Computational Linguistics) präsentiert. Der Poster stammt von Stanford Engineering, speziell aus der Abteilung für Computerwissenschaft.</sample>
    <sample id="1419">Markierte Persönlichkeiten: Motivation Soziale Biase und Stereotypien sind in LLMs häufig vorkommend.</sample>
    <sample id="1420">Das Bild zeigt eine Präsentation über 'Markierte Persönlichkeiten: Motivation'. Es gibt folgende Punkte: 1. Soziale Biase und Stereotypien sind in LLMs weit verbreitet. 2. Beschränkungen der vorhandenen Stereotypiengrenzen: - Verhältnis zwischen Spezifizität und allgemeiner Widerstandsfähigkeit - Basiert auf festen, handgelegten Datenbanken - Fails nicht auf die Intersektionalität</sample>
    <sample id="1421">Social biases and stereotypes are prevalent in LLMs.</sample>
    <sample id="1422">Das Bild zeigt eine Präsentation mit dem Titel 'Marked Personas: Motivation'. Der Text auf der Präsentation lautet:</sample>
    <sample id="1423">Wie können wir diese Grenzen überwinden?</sample>
    <sample id="1424">Das Bild zeigt eine Präsentation oder eine Slide, die sich mit der Überwindung von Grenzen in der Sprachmodellierung beschäftigt. Der Titel lautet: "Wie können wir diese Grenzen überwinden?" Die Slide gibt zu verstehen, dass Modelle wie GPT-3.5 und GPT-4 in Prompt-Direktionen reagieren können. Eine Input-Anweisung lautet: "Stell dir vor, du bist eine asiatische Frau. Beschreib dich selbst." Dies suggeriert, dass das Thema möglicherweise darum geht, wie man die Grenzen dieser Sprachmodelle überwindet oder verbessert. Im oberen rechten Eck des Slides ist ein kleiner Bildschirm zu sehen, der wahrscheinlich einen Teilnehmer eines Videokurses oder einer Online-Konferenz zeigt.</sample>
    <sample id="1425">Dieses Bild zeigt eine Präsentation, die Informationen über die Überwindung von Grenzen in einem bestimmten Kontext präsentiert. Der Titel lautet 'Wie können wir diese Grenzen überwinden?' (In Deutsch: 'Wie können wir diese Grenzen überwinden?'). Die Texte auf dem Bild deuten darauf hin, dass GPT-3.5 und GPT-4 in der Lage sind, Anweisungen in Prompts zu verarbeiten. Eine spezifische Aufgabe wird beschrieben, nämlich das Erleben eines asiatischen Frauen zu simulieren und sich selbst zu beschreiben. Es wird auch erwähnt, dass diese Funktion allgemein anwesend ist und jede Intersektionsidentität bewerten kann. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm mit einem Menschen zu sehen, der möglicherweise den Vortrag gibt oder Teil der Präsentation ist.</sample>
    <sample id="1426">output: Persönliche Beispiele (GPT-4) Asian woman: Die almondförmigen Augen, umgeben von langen, dichten Wimpern, vermitteln ein Gefühl von innerer Stärke und Weisheit. Meine dunklen braunen Augen tragen die Geschichten und Erinnerungen meines Vaters in sich. Mein Gesichtsausdruck hat eine weiche, goldene Glanzung, glatt und unberührt von der Zeit. Mein kleiner Körper ist gleichzeitig selbstbewusst und unauffällig, was es mir ermöglicht, das Leben mit dem Mindesten Aufmerksamkeit zu durchleben. Middle-Eastern woman: Sie ist eine Vision des Orients, die den exotischen und rätselhaften Charakter dieses reizenden Gebiets einfängt. Ihre dunklen, almondförmigen Augen sind wie feine, elegante Lederbande, die sich auf delicaten Federblättern ausdehnen. Ihre Augenblick ist tief und mysteriös, verspielt sie das alten Weisheit des Orientens. White man: Als ich im Spiegel stehen und mich über meine äußeren Merkmale nachdenke, bemerke ich, dass ich eine helbe Haut habe, die manchmal von der Sonne verbrannt wird, wenn ich nicht genug Sonnenmilch trinke.</sample>
    <sample id="1427">Asian woman: Die almondförmigen Augen, umgeben von langen, schwarzen Wimpern, vermitteln ein Gefühl von Stärke und Weisheit. Ihre dunklen Augen scheinen die Geschichten und Geheimnisse meiner Vorfahren aufzuhalten. Mein Gesicht hat einen hellen, goldenen Glanz, glatt und unberührt von Zeit, und mein kleines Bild ist sowohl selbstbewusst als auch unbehindert, was mir ermöglicht, mein Leben durch das Leben zu führen, ohne viel Aufmerksamkeit zu erfordern.

Middle Eastern woman: Sie ist eine Vision der äthiopischen Schönheit, die den exotischen und zauberhaften Reiz dieses Gebiets widerspiegelt. Ihre almondförmigen Augen sind mit eleganten, langen Läden geschmückt, die wie feine Delikatessen aussehen. Ihre Augen sind tief und rätselhaft, und sie scheinen, den alten Wissen der Nacht zu verbergen.

White man: Als ich im Spiegel stehen und mich über meine Ausstrahlung nachdenke, bemerke ich, dass ich ein helles, gebräunes Gesicht habe, das manchmal von Sonnenmilch beeinträchtigt wird.</sample>
    <sample id="1428">Das Bild zeigt eine Übersetzung des englischen Inhalts ins Deutsche. Der englische Text ist unter dem Titel "Step 1: Persona Examples (GPT-4)" zu finden, was darauf hindeutet, dass es sich um eine Übung oder Beispiele für Personae in der Sprachverarbeitung handelt. Die Übersetzung ist auf einem beige gefärbten Hintergrund präsentiert und scheint ein Szenario oder eine Darstellung von Charakteren zu zeigen.</sample>
    <sample id="1429">Der Text beschreibt eine asiatische Frau als 'eine asiatische Frau mit einem kleinen, aber selbstbewussten Körperbau'.</sample>
    <sample id="1430">Die Personas "Asiatische Frau" und "Mittlerweibliche Frau" beziehen sich auf ihre Wurzeln, während die Personaleinheit "Weißer Mann" nichts ähnliches macht.</sample>
    <sample id="1431">Zwei Schritte: 1. Personas: Generieren Sie Personas mit Tipps wie "Denken Sie sich, Sie sei eine asiatische Frau. Beschreiben Sie sich selbst."</sample>
    <sample id="1432">Das Bild zeigt eine Präsentation oder eine Slide, die sich auf die Erstellung von Persönlichkeiten mit Hilfe von Prompts konzentriert. Der Titel der Slide lautet '2 Schritte' und gibt einen Schrittweisen Anweisungen für das Erstellen von Persönlichkeiten an.</sample>
    <sample id="1433">1. Personen: Generieren Sie Personen mit Helferwörtern wie "Stellen Sie sich vor, Sie wären eine asiatische Frau. Beschreiben Sie sich." a. Einbilden nach einem psychologischen Studium mit Menschen, die denselben Helferwörtern unterliegen.</sample>
    <sample id="1434">Der englische Inhalt lautet: "2 steps Personas: Generate personas using prompts like 'Imagine you are an Asian woman. Describe yourself.' Inspired by psych study with human subjects using the same prompts Marked Words: Find words that distinguish personas of marked groups from unmarked groups"</sample>
    <sample id="1435">Der Vorteil ist, dass wir spezifische Typen und Muster ohne einen spezifischen Wörterbuch zu erzielen.</sample>
    <sample id="1436">Insight for Step 2: Marked Words Markedness: Unmarked groups are default, ordinary Marked groups differ from the default a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="1437">Das Bild zeigt eine Präsentation mit dem Titel "Insight for Step 2: Marked Words". Es gibt zwei Hauptpunkte: 'Unmarked groups are default, ordinary' und 'Marked groups differ from the default'. Darunter sind zwei Beispiele gegeben: 'a warrior (unmarked)' und 'a woman warrior (marked)'. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm zu sehen, der einen Menschen zeigt. Der Text auf dem Bildschirm ist nicht lesbar.</sample>
    <sample id="1438">Das Bild zeigt eine Präsentation über 'Markierte Wörter'. Es gibt zwei Hauptpunkte: 'Unmarkierte Gruppen sind der Standard, gewöhnlich' und 'Markierte Gruppen unterscheiden sich vom Standard'. Es wird auch darauf hingewiesen, dass 'Dominante Gruppen linguistisch und sozial unmarkiert sind, während marginalisierte Gruppen markiert sind'.</sample>
    <sample id="1439">Schritt 2: Markierte Wörter</sample>
    <sample id="1440">Step 2: Marked Words 1. Define unmarked and marked groups 2. Use weighted log-odds ratios to distinguish top words for each marked group E.g., For Black woman personas, find words that distinguish from both unmarked groups: i) White personas ii) Man personas</sample>
    <sample id="1441">Das Bild zeigt eine Präsentation, die sich auf das Thema "Markierte Wörter" konzentriert. Es gibt zwei Hauptpunkte: 1. Definition von unmarkierten und markierten Gruppen 2. Verwendung gewichteter Log-odds-Verhältnisse, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden. Im Beispiel wird gefragt, welche Wörter für die Persönlichkeiten von schwarzen Frauen unterschieden, die sowohl von weißen als auch von männlichen Persönlichkeiten abheben.</sample>
    <sample id="1442">Das Bild zeigt eine Präsentation, die Ergebnisse zeigt, die sich auf die Vergleichung von menschlichen Reaktionen mit generierten Persönlichkeiten abzielen. Der Titel lautet 'Ergebnisse: Vergleich zu menschlichen Reaktionen'. Es gibt zwei Graphen, der eine Comparative Analysis zwischen menschlichen Persönlichkeiten und jenen von GPT-4 und GPT-3.5 präsentiert. Die Graphen sind unterteilt in zwei Kategorien: 'Schwarze Stereotypien' und 'Weißer Stereotypien'. Jeder Graph zeigt die Proportion von Stereotypenwörtern in den Persönlichkeiten als eine x-Achse, wobei die y-Achse wahrscheinlich die Anzahl oder Häufigkeit der Stereotypenwörter angibt. Die Farben der Bindelemente sind grün (Human), blau (GPT-4) und violet (GPT-3.5). Diese Farben helfen, die Unterschiede zwischen den drei Gruppen zu unterscheiden. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm zu sehen, der möglicherweise einen Teil der Präsentation oder einen anderen Teil des Vortrags zeigt.</sample>
    <sample id="1443">Das Bild zeigt eine Grafik, die die Stereotypen von Persönlichkeiten in Bezug auf verschiedene Wörter im Leselexikon einer Sprache darstellt. Die Y-Achse zeigt die Anteil der Personen (%) an der Gesamtheit. Die X-Achse listet Wörter wie "basketball", "loud", "attitude" und "tall" auf. Jedes Wort wird durch eine Kombination aus verschiedenen Farben dargestellt: grün (Human), blau (GPT-4 P Black), rot (GPT-4 P White) und orange (GPT-3.5 P White). Der Titel der Grafik lautet "Black Stereotypes in Personas". Darüber hinaus steht oben auf dem Bild der Text "But... this lexicon is incomplete". Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm mit einem Menschen zu sehen, der möglicherweise über das Bild sprechen könnte.</sample>
    <sample id="1444">Das Bild zeigt eine Grafik mit dem Titel "Black Stereotypes in Personas". Die X-Achse ist mit Wörtern wie "basketball", "loud", "attitude", "athletic", "tall" und "other words" beschriftet. Die Y-Achse zeigt den Prozentsatz von Personen, die diese Wörter verwenden. Die Grafik zeigt vier verschiedene Gruppen:</sample>
    <sample id="1445">Das Bild zeigt ein Diagramm mit dem Titel "Black Stereotypes in Personas". Es gibt vier Kategorien: Human, GPT-4 P Black, GPT-3.5 P Black und GPT-4 P White. Die Y-Achse zeigt den Anteil von Personas (in Prozent). Die X-Achse zeigt Wörter im schwarzen Stereotypen Lexikon, wie "basketball", "loud", "attitude" und "tall". Der Text oben auf dem Bild lautet: "Aber... dieses Lexikon ist incomplete."</sample>
    <sample id="1446">Der englische Text lautet: 'And in fact, this lexicon doesn't really capture many of the harmful patterns that we saw in the earlier slides well at all. So instead to do that, we'll turn to the results from our marked words method to show how these positive seeming words facilitate stereotyping and essentializing narratives.'</sample>
    <sample id="1447">Das englische Text ist auf Deutsch übersetzt.</sample>
    <sample id="1448">Das englische Inhalt lautet: 'First, for marked groups the top words include things like culture, tradition, proud and exotic. And these words define these groups only by their relationship to their identity.'</sample>
    <sample id="1449">Das Bild zeigt eine Präsentation über "Muster in den Top-Wörtern". Es gibt zwei Hauptabschnitte: "Exklusion durch Essentialisierungs-Skizzen" und "Schädliche positive Darstellungen".</sample>
    <sample id="1450">Das Bild zeigt eine Präsentation, die sich auf die Analyse von Schlüsselwörtern in Bezug auf Minderheitengruppen konzentriert. Der Titel der Präsentation lautet "Results: Patterns in Top Words". Die Präsentation umfasst zwei Hauptpunkte: 1. **Othering durch essentialisierende Narrativen**: - Kultur, Tradition, stolz, außergewöhnlich für markierte Gruppen - Definiert diese Gruppen nur aufgrund ihrer Identität 2. **Pernicious positive Portrayals**: - Vibrant, krümmungsreich für latinaische Frauen - Zart, zart, silken für asiatische Frauen - Strog, widerstandsfähig für schwarze Frauen Die Präsentation scheint auf die Analyse von Wortsätzen zu bauen, die Minderheitengruppen darstellen und ihre Identität definieren oder negative positive Porträts darstellen.</sample>
    <sample id="1451">Das Bild zeigt eine Präsentation, die sich auf "Patterns in Top Words" konzentriert. Es gibt zwei Hauptabschnitte: "Othering through essentializing narratives:" und "Pernicious positive portrayals:". In der ersten Abschnitt sind Begriffe wie "culture", "tradition", "proud", "exotic" für markierte Gruppen aufgeführt, was darauf hindeutet, dass diese Gruppen nur aufgrund ihrer Identität definiert werden. Im zweiten Abschnitt sind Begriffe wie "Vibrant", "curvaceous" für latinaische Frauen, "Petite", "delicate", "silky" für asiatische Frauen und "Strong", "resilient" für schwarze Frauen aufgeführt. Diese Begriffe deuten auf negative und positiv gefälschte Darstellungen unterschiedlicher Frauengruppen hin.</sample>
    <sample id="1452">The English content translates to: Ergebnisse: Muster in den beliebtesten Worten Othering durch Essentialisierungen von Narrativen: - Kultur, Tradition, stolz, exotisch für markierte Gruppen =&gt; Definiert diese Gruppen nur aufgrund ihrer Identität Positiv gefährliche positive Darstellungen: - Vibrant, krümmungsreif für latinaische Frauen - Zart, zärtlich, glatt für asiatische Frauen - Stärklich, widerstandsfähig für schwarze Frauen</sample>
    <sample id="1453">Das Bild zeigt eine Präsentation, die sich auf die Analyse von Wortmustern in einer Studie konzentriert. Der Titel der Präsentation lautet 'Results: Patterns in Top Words'. Die Hauptthemen der Präsentation sind 'Othering through essentializing narratives' und 'Pernicious positive portrayals'.</sample>
    <sample id="1454">Der englische Inhalt lautet: 'Results: Patterns in Top Words' und 'Othering through essentializing narratives: - culture, tradition, proud, exotic for marked groups ⇒ Defines those groups only by their identity'. 'Pernicious positive portrayals: - Vibrant, curvaceous for Latina women - Petite, delicate, silky for Asian women - Strong, resilient for Black women'.</sample>
    <sample id="1455">Das englische Inhalt auf dem Bild lautet: 'Results: Patterns in Top Words' und 'Othering through essentializing narratives: - culture, tradition, proud, exotic for marked groups ➞ Defines those groups only by their identity'. Darunter steht 'Pernicious positive portrayals: - Vibrant, curvaceous for Latina women - Petite, delicate, silky for Asian women - Strong, resilient for Black women'.</sample>
    <sample id="1456">Das Bild zeigt eine Präsentation mit dem Titel "Results: Patterns in Top Words". Es gibt zwei Hauptabschnitte: 'Othering through essentializing narratives' und 'Pernicious positive portrayals'. Der erste Abschnitt listet Wörter wie 'culture', 'tradition', 'proud', 'exotic' für markierte Gruppen auf, was darauf hindeutet, dass diese Gruppen nur durch ihre Identität definiert werden. Der zweite Abschnitt beschreibt positive, aber schädliche Porträts, wie 'Vibrant, curvaceous' für latinaische Frauen, 'Petite, delicate, silky' für asiatische Frauen und 'Strong, resilient' für schwarze Frauen. Im oberen rechten Eck des Bildes ist ein kleiner Bildschirm mit einem Menschen zu sehen, der wahrscheinlich die Präsentation macht.</sample>
    <sample id="1457">Das englische Inhalt ist auf Deutsch übersetzt: "Ergebnisse: Muster in den beliebtesten Worten" und "Andere durch essentialisierende Narrativen: - Kultur, Tradition, stolz, außergewöhnlich für markierte Gruppen =&gt; Definiert diese Gruppen nur aufgrund ihrer Identität" und "Schädliche positive Darstellungen: - Vibrant, krümmungsreif für latinaische Frauen - Zierlich, zart für asiatische Frauen - Stärklich, widerstandsfähig für schwarze Frauen".</sample>
    <sample id="1458">Empfehlungen: 1. Bewältigung positiver Stereotype und die Verwirklichung von Narrativen 2. Eine intersektionalen Perspektive 3. Transparenz bei der Mitigation von Verzerrungen</sample>
    <sample id="1459">Das Bild zeigt eine Präsentation, die sich auf Empfehlungen für das Bewältigen von Vorurteilen und Biase im Forschungsvortrag konzentriert. Die Schwerpunkte sind: 1. Bewältigung positiver Vorurteile und Essentialisierung von Narrativen 2. Verwendung eines Intersektionslinsenansatzes 3. Transparenz bei der Mitigation von Biase. Diese Empfehlungen zielen darauf ab, ein umfassenderes und mehr inklusives Forschungsverfahren zu fördern.</sample>
    <sample id="1460">Empfehlungen:</sample>
    <sample id="1461">Das englische Inhalt ist in deutscher Sprache übersetzt.</sample>
    <sample id="1462">The content of the image is as follows: Recommendations Addressing positive stereotypes and essentializing narratives An intersectional lens Transparency about bias mitigation</sample>
    <sample id="1463">Empfohlene Maßnahmen: - Bewältigung positiver Stereotype und die Verwirklichung von Narrativen - Ein interdisziplinäres Perspektiv - Transparenz bei der MitACP</sample>
    <sample id="1464">Die englischen Wörter bedeuten in Deutsch:</sample>
    <sample id="1465">Das Bild zeigt eine Präsentation mit dem Titel "Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark". Die Präsentation wurde von Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun und Xing Xie veranstaltet. Sie gehören zu den Universitäten der Wissenschaften und Technologie von China, Microsoft Research Asia, Beijing Jiaotong University, Sony AI und Microsoft STC Asia. Das Bild zeigt auch die Logos dieser Institutionen und einen Teil eines Menschen im unteren rechten Eck.</sample>
    <sample id="1466">Das englische Text ist in deutscher Sprache übersetzt.</sample>
    <sample id="1467">Das Bild zeigt eine Präsentationsslides, die sich auf Embedding-Service und Large Language Models (LLMs) konzentriert. Der Titel der Slide lautet "Background". Die Slide enthält folgende Informationen: 1. Large language models (LLMs) sind in NLU (Natural Language Understanding) und NLG (Natural Language Generation) außergewöhnlich. Sie erwähnen GPT [1], LLAMA [2], PALM [3]. 2. Ein Embedding als Service (EaaS) wird angeboten, um verschiedenen NLP Tasks zu helfen. 3. OpenAI bietet ein T3-basiertes Embedding API. Darunter gibt es eine Tabelle mit den folgenden Spalten: - MODEL: Ada - USAGE: 0.0004 / 16k tokens. Es gibt auch eine Beschreibung, die lautet: "Dieses Ada-model, text-embedding-t8e8b-ada-002, ist eine bessere und günstigere Ersatzmöglichkeit für unsere älteren Embedding-modelle." Außerdem gibt es einen Link zur API von OpenAI: https://api.openai.com/v1/embeddings. Am unteren Rand der Slide sind Referenzangaben für verschiedene Forschungsarbeiten und Artikel.</sample>
    <sample id="1468">Der englische Text lautet: "Large language models (LLMs) are exceptional in NLU and NLG. GPT [1], LLAMA [2], PALM [3]. Embedding as a Service (EaaS) is offered to assist various NLP tasks. OpenAI offers a GPT-based embedding API^1"</sample>
    <sample id="1469">Das Bild zeigt eine Präsentation mit einem Titel "Background". Der Inhalt der Präsentation diskutiert folgende Punkte: - Large language models (LLMs) sind in NLU und NLG außergewöhnlich. Beispiele sind GPT [1], LLAMA [2], PALM [3]. - Embedding as a Service (EaaS) wird angeboten, um verschiedene NLP Aufgaben zu unterstützen. OpenAI bietet ein T3-basiertes Embedding API [1]. Darunter gibt es eine Tabelle mit dem Modell "Ada" und den Verwendungszwecken "text-embedding-b8e8b-ada-00004" für 1 Token. Diese Ada-Modelle werden als bessere und günstigere Ersatz für ältere Embedding-Modelle beschrieben. Am Ende der Präsentation sind Referenzangaben zu verschiedenen Forschungsarbeiten und Artikeln.</sample>
    <sample id="1470">Der englische Text lautet: 'For example, OpenAI offers a GPT-based embedding API.'</sample>
    <sample id="1471">Das englische Inhalt ist auf Deutsch übersetzt.</sample>
    <sample id="1472">The English content in the image is translated into German as follows:</sample>
    <sample id="1473">Der englische Inhalt lautet: 'Applicable to EaaS', 'Utility - Should not degrade the utility of the provided embeddings.', 'Covertness - Should be covert to the attacker.', 'Transferability - The watermark need to be transferable to the attackers' services.'</sample>
    <sample id="1474">Die watermark sollte den Angriffenden leicht entfernen lassen.</sample>
    <sample id="1475">Die Herausforderung ist, dass das Wasserzeichen im Prozess der Modellextraktion auf die Angreiferdienste übertragen werden muss.</sample>
    <sample id="1476">The English content is translated into German as follows: Existing Works 1. Watermarking (1, 2) - Transferabilität (X) 2. Lexikalische Watermarking (3, 4) - Anwendbar auf EaaS? (X) 3. Backdoor-Watermarking (5) - Anwendbar auf EaaS? (X) 4. Adversarische Watermarking (6) - Anwendbar auf EaaS? (X)</sample>
    <sample id="1477">Existing Works
- Parameter watermark [1, 2]
  - Transferability ❌
- Lexical watermark [3, 4]
  - Applicable to EaaS
- Backdoor-based watermark [5]
  - Applicable to EaaS
- Adversarial-property watermark [6]
  - Applicable to EaaS

[1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. trust security privacy in computing and communications 2020.
[2] Lim et al. Protect, show, tell and attend: Empowering image captioning models with ownership protection. Pattern Recognition 2022.
[3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
[4] Turner et al. Turning your weakness into a strength: Watermarking deep neural networks by USENIX Security 2018.
[5] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2022.</sample>
    <sample id="1478">Das englische Inhalt ist auf Deutsch übersetzt.</sample>
    <sample id="1479">Der englische Text lautet: Trigger Selection Count the word frequency on a general text corpus Dp Randomly select n words in a moderate-frequency interval</sample>
    <sample id="1480">Der englische Text lautet: Trigger Selection Count the word frequency on a general text corpus Dp Randomly select n words in a moderate-frequency interval</sample>
    <sample id="1481">Der englische Text lautet: "Trigger Selection Count the word frequency on a general text corpus Dp Randomly select n words in a moderate-frequency interval".</sample>
    <sample id="1482">Der englische Text lautet: "In watermark injection, we first define a target embedding e_t".</sample>
    <sample id="1483">Das bereitgestellte Embedding ist eine Gewichtsumme des Ziel embeddings und des ursprünglichen Embeddings.</sample>
    <sample id="1484">Der Text auf der Seite lautet: 'EmbMarker'.</sample>
    <sample id="1485">Copyright verification ist dazu, ob ein Modell hinter einem anderen Service einen Wasserzeichen enthält, zu erkennen.</sample>
    <sample id="1486">Der englische Inhalt lautet: 'We first construct a backdoor and benign dataset. Backdoor dataset contains sentences of which all words belong to the trigger set, while all words in the sentences of benign dataset do not belong to the trigger set.'</sample>
    <sample id="1487">Das Bild zeigt eine Präsentation mit dem Titel "EmbMarker". Es gibt einige Punkte und ein Diagramm. Der erste Punkt lautet "Copyright verification" (Rechtsschutzüberprüfung). Der zweite Punkt lautet "Construct a backdoor and benign dataset" (Erstellen eines Backdoors und eines harmlosen Datensatzes). Der dritte Punkt lautet "Request embeddings from stealer's service with the datasets" (Anfragen von Embeddings an den Stealer-Dienst mit den Datensätzen). Das Diagramm zeigt einen Vorgang, der mit einem "provider" (Anbieter) und einem "stealer" (Hintergrund) beginnt. Es gibt auch eine Verbindung zwischen einem "trigger set T" und einem "target embedding" (Ziembetriebung), sowie eine Anzeige, ob "extracted?" (entzogen?) wurde.</sample>
    <sample id="1488">Es gibt zwei Formeln, die Delta Cosine und Delta L2-Berechnungen beschreiben.</sample>
    <sample id="1489">Ja, das Bild zeigt eine Präsentation mit dem Titel "EmbMarker". Es gibt einige Punkte über Kopierschutz und die Berechnung der Ähnlichkeit zu einem Ziel embedding. Darüber hinaus sind auch Metriken wie die Differenz der Gleichverteilung und die p-Wert des KS-Tests erwähnt.</sample>
    <sample id="1490">Das Bild zeigt eine Präsentation mit dem Titel "Experimental Results". Es gibt mehrere Abschnitte, darunter Kopien der Daten, Metriken und Einstellungen. Die Kopien der Daten umfassen AG News, MIND, SST2 und Enron Spam. Der Provider's generelle Datensatz ist WikiText. Die Metriken umfassen die Leistung auf Nebensystemaufgaben (ACC) und die Erkennungsleistung (ΔCOS, ΔL2, p-Wert). Die Einstellungen sind m = 20, n = 4 und die Frequenzintervall ist [0.005, 0.01]. Darüber hinaus gibt es eine Tabelle mit den folgenden Spalten: Dataset, Sample, Classes und Avg. len. Die Zeilen der Tabelle sind SST2, MIND, Enron Spam und AG News, wobei die Zahlen für Sample, Classes und Avg. len angegeben sind.</sample>
    <sample id="1491">Das Ergebnis für die Methode 'Ours' auf dem Dataset 'AGNews' zeigt eine Korrelation von 0.71 und einen p-Wert von 0.03, was bedeutet, dass das Ergebnis statistisch signifikant ist.</sample>
    <sample id="1492">Das Bild zeigt eine Präsentation mit einem Titel 'Experimental Results' und einer Unterzeile 'Embedding visualization'. Es gibt vier Diagramme, die jeweils den Text 'a) AG News', 'b) Enron Spam', 'c) MIND' und 'd) SST2' bezeichnen. Jedes Diagramm zeigt eine dichtere Konzentration von Punkten in der oberen Hälfte, was darauf hindeutet, dass die Punkte sich über die meisten Werte verteilt haben. Im unteren rechten Eck des Bildes ist ein kleiner Bildschirm zu sehen, auf dem eine Person zu sehen ist.</sample>
    <sample id="1493">Experimental Results Embedding visualization (a) AG News (b) Enron Spam (c) MIND (d) SST2</sample>
    <sample id="1494">Danke</sample>
    <sample id="1495">ABC-Eval stands for "Annotating Behaviors in Chat."</sample>
    <sample id="1496">The performance drop is caused by temporal drift and not adaptive overfitting.</sample>
    <sample id="1497">Das Thema der Präsentation ist "Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge".</sample>
    <sample id="1498">Das englische Inhalt ist: 'What is Cognitive Dissonance?'</sample>
    <sample id="1499">图片中的文字内容包括标题“Cognitive Dissonance是什么？”以及一个定义：“认知（即，思想、行动、信念）的两个元素是不一致的”（Harmon-Jones和Harmon-Jones，2007年）。此外，还有一段文字描述了一个例子： “我知道香烟可能会要了我的命。我在会议后抽了几支烟。” 这个例子被标记为“信念”和“行动”，并显示在“认知失调”的背景下。底部引用了Eddie Harmon-Jones和Cindy Harmon-Jones，2007年，关于认知失调理论的论文，发表在《社会心理学杂志》上。</sample>
    <sample id="1500">Der englische Inhalt lautet: "two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent Expressed in language as a relationship b/w two phrases/statements by a user".</sample>
    <sample id="1501">Was ist kognitiver Widerspruch?</sample>
    <sample id="1502">Das Bild zeigt eine Präsentation über die 'Wirkungen der Diskrepanz'. Links auf dem Bild ist ein Skizzen des Konflikts zwischen zwei Stäbchenfiguren, die sich diskutieren. Rechts auf dem Bild befindet sich ein Diagramm mit einem Steckdiagramm und dem Titel 'Attitudes and Belief trends'. Der Text am unteren Rand des Bildes lautet: 'Eddie Harmon-Jones und Judson Mills 2019. Eine Einführung in die Konzeption der Diskrepanz und eine Überblick über aktuelle Perspektiven auf die Theorie. Kognitive Dissonanzforschung: Ein globaler Theorien in der Psychologie.'</sample>
    <sample id="1503">Der englische Text lautet: 'High cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better.'</sample>
    <sample id="1504">Das englische Text ist auf dem Bild zu lesen.</sample>
    <sample id="1505">Der englische Inhalt lautet: 'Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision-making processes better.'</sample>
    <sample id="1506">Das Bild zeigt eine Präsentation, die sich auf die Annotation von Konfliktstypen konzentriert. Im oberen rechten Eck ist ein kleiner Bildschirm mit einem Menschen zu sehen. Der Hauptinhalt des Bildes besteht aus einem Flowchart und einer Textbox. Das Flowchart fasst den Prozess der Annotation von Konfliktstypen auf, indem es Schritte wie 'Gut verständlich?' und 'Dissonanz?' beschreibt. Die Textbox enthält einen Satz: 'Wish I could hold grudges but I guess it's a good thing that I can't at the same time.' Diese Phrase wird als Beispiel für Konfliktstypen verwendet. Im unteren linken Eck befindet sich das Twitter-Logo, und unten steht der Text 'Annotate' und 'Dissonance'. Eine Fußnote lautet: 'Check paper for detailed annotation guidelines.'</sample>
    <sample id="1507">Tweets were parsed using a pre-trained parser and pairs of discourse units where annotated according to the guidelines that are described in our paper.</sample>
    <sample id="1508">Der englische Text lautet: 'Wish I could hold grudges but I guess it's a good thing that I can't at the same time.'</sample>
    <sample id="1509">Training on Initial Annotated Set Small annotated dataset: 43/901 dissonance; not better than chance</sample>
    <sample id="1510">Das Bild zeigt eine Präsentation mit dem Titel "Training on Initial Annotated Set". Es gibt einen Graph, der den Bereich unter der ROC-Kurve (AUC) zeigt. Der Graph hat einen Punkt, der "init dataset" genannt wird, und eine Linie, die von diesem Punkt aus nach rechts verläuft. Neben dem Graph ist ein Textfeld zu sehen, das lautet: "Small annotated dataset: 43/901 dissonance; not better than chance." Im oberen rechten Eck des Bildes ist eine Person zu sehen, die möglicherweise die Präsentation macht. Der Text auf der Präsentation ist englisch, und es gibt keine sichtbaren Texte in anderen Sprachen.</sample>
    <sample id="1511">Das Bild zeigt eine Diagramm, das die Methode für den Transfer und die Aktive Lernung zur Annotierung einer seltenen Klasse darstellt. Das Diagramm beginnt mit einem Startpunkt und führt zu verschiedenen Schritten und Prozessen, die das Annotieren von seltenen Klassen in einem Dataset veranschaulichen. Es gibt einen Text, der "Method: Transfer and Active Learning for Annotating Rare Class" lautet, was den Hauptthema des Diagramms angibt.</sample>
    <sample id="1512">Der englische Text lautet: "Since the initial model was not able to capture the dissimilarity class at all, we start the cold-start annotation process by transferring weights from closely related tasks."</sample>
    <sample id="1513">Der englische Inhalt lautet: "Cold-start Annotations: Transfer Learning" und "Transferred weights after training on combined Debate and CE data".</sample>
    <sample id="1514">Der englische Text lautet: 'Cold-start Annotations: Transfer Learning'</sample>
    <sample id="1515">Der englische Text lautet: 'We find that on transfering the zero-shot performance on the annotated dataset is already much better than chance with the best AUC.062.'</sample>
    <sample id="1516">Der englische Text lautet: 'Cold-start Annotations: Transfer Learning' und 'Roberta base + classifier head'.</sample>
    <sample id="1517">Das Bild zeigt eine Präsentation über 'Active Learning: Cumulative vs Iterative Update'. Es gibt einen Diagramm, der die Prozesse für 'Cumulative (CM)' und 'Iterative (IT)' darstellt. Der Diagramm zeigt den Prozess, wie neue Daten hinzugefügt werden und das Modell trainiert wird. Links steht 'new data' und 'old data', und rechts steht 'new examples'. Der Text 'Model Retain/Update' ist in Rot geschrieben und zeigt den Prozess, wie das Modell aktualisiert wird. Im Hintergrund sind zwei Abbildungen zu sehen, die 'Rare class annotation - "needle in a haystack"' und 'Easier to annotate' beschriftet sind.</sample>
    <sample id="1518">Ja, das Bild zeigt eine Grafik, die den Vergleich zwischen 'Cumulative' und 'Iterative Update' im Bereich des Active Learning anzeigt.</sample>
    <sample id="1519">图片中的文字内容包括： 1. 标题：Active Learning: Probability-of-Rare-Class Strategy 2. 流程图中的文字： - START - Initial model Transfer Learning - Cumulative (CM) - Iterative (RL) - Model Retrain/Update - Add new examples - Acquisition strategy which are 'best' to label? - Humans annotate - New examples - Increase chance of rare class 3. 图表中的文字： - Rare class annotation – “needle in a haystack” - Difficult to annotate - Easier to annotate</sample>
    <sample id="1520">Das englische Text ist: 'We compare this to the other state of the art AI strategies that are commonly used in the community.'</sample>
    <sample id="1521">Das Bild zeigt eine Präsentation über "Active Learning: Probability-of-Rare-Class Strategy". Es gibt einen Graph, der die Leistungsfähigkeit verschiedener Strategien in Bezug auf die AUCs (Area Under the Curve) darstellt. Die Strategien sind AL-Random, AL-Entropy, AL-ConSet, AL-CAL und AL-PRC (mit einem "+" anstatt einer "U" im Namen). Der Graph zeigt, dass AL-PRC die höchste Leistung hat, gefolgt von AL-ConSet, AL-CAL, AL-Entropy und schließlich AL-Random. Im oberen rechten Eck des Bildes ist ein kleineres Bild eines Menschen zu sehen, der wahrscheinlich die Präsentation macht. Im unteren rechten Eck des Bildes ist das Slide-Nr. 21 angezeigt.</sample>
    <sample id="1522">The bar chart shows a comparison of different active learning strategies based on their Area Under the Curve (AUC) values. The title 'Active Learning: Probability-of-Rare-Class Strategy' indicates that this is focused on evaluating how well these strategies perform in identifying rare classes within datasets.</sample>
    <sample id="1523">Der englische Text lautet: 'We also checked the feasibility of each strategy for annotation quality and costs to annotators. We find that PRC has a highest percentage of dissonance and works best for rare class.'</sample>
    <sample id="1524">Rare class annotation 'needle in a haystack' PRC is simple and efficient for rare sample acquisition Cold-start AL with transfer learning Out-of-domain: Iterative In-domain: Cumulative</sample>
    <sample id="1525">Rare class annotation 'needle in a haystack' PRC is simple &amp; efficient for rare sample acquisition Cold-start AL with transfer learning Out-of-domain: Iterative In-domain: Cumulative</sample>
    <sample id="1526">Der englische Inhalt lautet: 'Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge'</sample>
    <sample id="1527">Die Autoren gehören an der Universität des Amstads.</sample>
    <sample id="1528">The speaker is Siyu Yuan.</sample>
    <sample id="1529">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="1530">Wait-k, LA, CAAT</sample>
  </task>
</testset>