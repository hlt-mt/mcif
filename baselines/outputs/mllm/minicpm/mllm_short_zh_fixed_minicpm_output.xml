<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">语言模型的主要数据来源是大规模网络爬虫数据。</sample>
    <sample id="1">The authors belong to McGill University/Mila and Microsoft Research.</sample>
    <sample id="2">DEPLAIN: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification Regina Stodden, Omar Momen, Laura Kallmeyer Heinrich Heine University Düsseldorf, Germany ACL 2023</sample>
    <sample id="3">幻灯片显示了标题为“DEPLAIN: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification”的演示文稿。下方列出了演讲者的名字：Regina Stodden、Omar Momen和Laura Kallmeyer，以及他们的隶属机构Heinrich Heine University Düsseldorf, Germany，以及会议ACL 2023。在右上角有一个小窗口，显示一个戴着耳机的人。然后，幻灯片切换到一个新的部分，标题为“1. Text Simplification”，并附有副标题“What, why and How?”。</sample>
    <sample id="4">文本简化是将复杂文本转化为简单易懂的版本的过程。</sample>
    <sample id="5">为了训练一个文本简化模型，我们需要平行对的文本，例如文档或句子。</sample>
    <sample id="6">图片显示了一个演示文稿的幻灯片，标题为“文本简化示例”。幻灯片上有一个平行对齐的句子对，左侧是复杂的德语句子，右侧是用简单语言翻译的句子。德语句子是“Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden.” 简单语言句子是“Die Gewerkschaft setzt sich dafür ein, zum Beispiel für höhere Löhne oder mehr Urlaub ein。” 幻灯片上还标注了文本简化过程中使用的不同技术：替换、短语删除、重排序和单词删除。每个技术都用箭头和标签指示其在简化过程中的应用。</sample>
    <sample id="7">文本简化示例</sample>
    <sample id="8">幻灯片展示了德语简化语料库的句子级别数据。图表显示了不同年份的数据，包括2015年、2016年、2017年、2018年和2019年。每个柱状图代表一个年份，柱状图的高度表示特定指标的数量。图表还包括一个图例，解释了柱状图中使用的颜色代码。顶部有一个蓝色横幅，上面写着“German Text Simplification Corpora”。幻灯片的右上角有一个小窗口，显示一个人。</sample>
    <sample id="9">图中展示了一个名为“German Text Simplification Corpora”的演示幻灯片。幻灯片的标题是“Sentence Level”，下方有一个柱状图，显示了不同年份的数据。柱状图中的数据包括“Domestic”、“European”、“International”、“Public policy”和“Other public policy”等类别。每个类别的数据用不同的颜色表示，并且有具体的数值标注在柱状图上。幻灯片的右上角有一个小窗口，显示了一个人的图像。</sample>
    <sample id="10">这张幻灯片展示了“德国文本简化语料库”的内容。它包括一个标题为“句子级别”的图表，显示了不同年份的数据，如2013年、2014年、2015年、2016年和2017年。图表中有各种颜色的柱状图，表示不同的类别，如“德语”、“英语”、“法语”、“意大利语”、“西班牙语”、“葡萄牙语”、“荷兰语”、“丹麦语”、“瑞典语”、“挪威语”和“冰岛语”。每个类别都有相应的数值，例如2013年的数值为260，2014年的数值为1108，2015年的数值为9456，2016年的数值为10296，2017年的数值为5942。此外，还有一个名为“DePlain-PA”的部分，其数值为13122，另一个名为“DePlain-WEB”的部分，其数值为756。幻灯片右上角有一个小图像，可能是一个人的照片。</sample>
    <sample id="11">图片中的标题是“German Text Simplification Corpora”。</sample>
    <sample id="12">这个语料库包括了不同的领域，我们还对所有这些750份文件进行了手动和自动对齐。</sample>
    <sample id="13">这张图片展示了一个名为“German Text Simplification Corpora”的演示幻灯片。幻灯片的主要内容是一个柱状图，显示了不同年份的句子级别数据。图表中的各个柱子代表了不同的年份和相应的数据值。幻灯片顶部有一个蓝色标题栏，上面用白色字体写着“German Text Simplification Corpora”。在标题栏下方，有一个副标题“Sentence Level”，表示数据是以句子级别进行分析的。柱状图左侧有一个图例，解释了不同颜色代表的类别，包括“Domestic”、“Health”、“Education”、“Environment”、“Public affairs”和“Others”。每个柱子的颜色对应这些类别之一。柱状图右侧有两个显著的数字：一个为483，另一个为756，这两个数字可能表示特定数据点或总结统计结果。幻灯片右上角有一个小窗口，显示了一位人物的部分图像，可能是演示者。</sample>
    <sample id="14">图中展示了简化类型和简化转换。在“简化类型”部分，有四个类别：新闻、圣经、L2和小说。每个类别都有三个柱状图，分别代表三种简化方法：简洁性（Simplicity）、LexSimp和StructSimp。在“简化转换”部分，有六个类别：移动、工程、逻辑、抽象、词元和变体。每个类别也有两个柱状图，分别代表两种不同的方法：DEplain-apa和DEplain-web。</sample>
    <sample id="15">图片中展示了两个图表，分别标记为“Simplification Types”和“Simplification Transformations”。</sample>
    <sample id="16">图片中的英文内容翻译成中文为： '简化类型' 和 '简化转换'。</sample>
    <sample id="17">图片中的文字内容包括两个图表和一些注释。左边的图表标题为“Simplification Types”，显示了不同类别的简化类型，包括“news”、“bible”、“L2”和“fiction”。每个类别下有三种颜色的柱状图，分别代表“Simplicity”（蓝色）、“LexSimp”（红色）和“StructSimp”（黄色）。右边的图表标题为“Simplification Transformations”，比较了两种不同的语料库，“DEplain-apa”（深蓝色）和“DEplain-web”（浅蓝色），展示了不同类型的简化转换，如“moving”、“engineering”、“lexical substitution”、“word deletion”和“word addition”。</sample>
    <sample id="18">在另一方面，在网络语料库中，我们有更多重新表述。</sample>
    <sample id="19">画面中展示了一张表格，标题为“Automatic Alignment Evaluation”。表格分为两部分：上半部分显示了1:1的对齐方法，下半部分显示了n:n的对齐方法。表格列出了不同的对齐方法及其描述。这些方法包括LHA、Sent-LAISE、CATS-C3G、VecAlign、BERTAlign和MASSAlign。每种方法都有一个“Name”列和一个“Description”列，描述了它们的具体功能或特性。例如，LHA被描述为使用词嵌入进行层级对齐，而Sent-LAISE则涉及语言模型BERT的相似性匹配。表格还包括了各种指标（如P、R、F1、PR、NPMI等）以及它们的数值，用于评估不同对齐方法的表现。</sample>
    <sample id="20">自动对齐评估</sample>
    <sample id="21">To extract alignments of sentences in post documents, you need to have two parallel documents written in different languages.</sample>
    <sample id="22">画面中展示了一张表格，标题为“Automatic Alignment Evaluation”。表格分为两部分：上半部分显示了1:1的匹配结果，下半部分显示了n cm的匹配结果。表格列出了几种不同的对齐方法，包括Sent-LA-LEASE、CATS-C3G、VecAlign、BERTAlign和MASSAlign。每种方法都有对应的描述和不同指标（P、R、F、PR、F1、n cm）的数值。背景中有一个穿着深色衣服的人，坐在桌子旁，似乎在进行演示或讲座。</sample>
    <sample id="23">这段英文内容翻译成中文是：‘Automatic Alignment Evaluation...’。</sample>
    <sample id="24">这张图片展示了一个演示文稿的幻灯片，标题为“Automatic Alignment Evaluation”。幻灯片上有一个表格，列出了各种方法的结果。这些方法包括Sent-LA-BASE、CATS-C3G、VecAlign、BERTAlign和MASSAlign。每个方法都有一个描述和三个指标：P、R和F1分数。表格的上半部分显示了1:1结果，而下半部分显示了NCM（N-gram Character Mapping）结果。在表格上方，有一个蓝色横幅，上面写着“Automatic Alignment Evaluation”。在幻灯片的右上角，有一个视频通话窗口，显示一个人在讲话。</sample>
    <sample id="25">The table in the image compares different alignment methods for text simplification. The results are presented with a score of 1:1 (upper part) and NCM (lower part). Here's how it breaks down:

- **LHA-LASE**: Shows high scores across all metrics, indicating strong performance.
- **Similar embeddings of Language-agnostic BERT transformer**: Also performs well but slightly lower than LHA-LASE.
- **Different similarity measures**: Scores vary more significantly here compared to other methods.
- **CATS-C3G**: Has moderate scores overall.
- **VecAlign**: Performs better on some metrics but not as consistently as others.
- **BERTAlign**: Shows good consistency but still varies by metric.
- **MASSAlign**: Has the highest scores among all methods listed.

This comparison helps determine which method is most effective for specific tasks related to text simplification based on their respective scores.</sample>
    <sample id="26">自动对齐评估结果（上部为1:1，下部为n cm）</sample>
    <sample id="27">将英文内容翻译成中文。</sample>
    <sample id="28">图片中的英文内容翻译成中文为：通过精调语言模型来生成复杂输入文本的简化文本。</sample>
    <sample id="29">幻灯片展示了自动文本简化的结果。它分为两个主要部分：文档级别和句子级别。每个部分都列出了在微调后的mBART模型上进行的测试结果，包括DEPLAIN-APA和DEPLAIN-WEB。这些结果包括BLEU、F1和PPL分数，以及训练数据集的大小。文档级别的结果包括n=48和n=147，而句子级别的结果包括n=1231和n=1846。</sample>
    <sample id="30">将英文内容翻译成中文。 图片显示了一个关于自动文本简化的演示幻灯片。 幻灯片分为两个主要部分：文档级别和句子级别。 每个部分都包含与微调后的mBART模型相关的结果，用于文本简化任务。 文档级别的部分包括DEPLAIN-APA测试（n=48）和DEPLAIN-WEB测试（n=147）的结果。 句子级别的部分包括DEPLAIN-APA测试（n=1231）和DEPLAIN-WEB测试（n=1846）的结果。 在每个部分中，都有数据集、BLEU分数、FRE分数和基线分数的详细信息。 数据以表格形式呈现，比较了不同测试中的表现。</sample>
    <sample id="31">这张图片展示了一个关于文本简化自动化的演示。图片中有一个标题为“Automatic Text Simplification”的幻灯片，下面有两个部分：一个是“Document Level”（文档级别），另一个是“Sentence Level”（句子级别）。每个部分都包含详细的表格，显示了在不同测试集上进行的实验结果，包括BLEU和F1分数等指标。幻灯片的背景是蓝色和白色，上面有黑色的文字。在右上角，可以看到一个人的部分视图，表明这个演示可能是在一个视频会议或在线讲座中进行的。</sample>
    <sample id="32">The text in the image is about 'Automatic Text Simplification' and provides results on document simplification using a finetuned mBART model. The data includes metrics such as BLEU, F1, and PPL for different tests (DEPLAIN-APA test and DEPLAIN-WEB test) at both document level and sentence level.</sample>
    <sample id="33">将英文内容翻译成中文。</sample>
    <sample id="34">谢谢你的关注，我们希望在会议上见到你们所有人。</sample>
    <sample id="35">The speaker's name is Kayo Yin.</sample>
    <sample id="36">They used the T5 XL model to obtain 82%-87% accuracy.</sample>
    <sample id="37">根据所提供的英文内容，CoNLL-2003标注器在2023年仍然有效。</sample>
    <sample id="38">The innovative aspect of the proposed human assessment method is that it explicitly annotates whether or not each model response expresses certain behaviors, such as responding with irrelevant information or contradicting itself.</sample>
    <sample id="39">现有弱监督方法的成功在很大程度上依赖于干净的验证样本。</sample>
    <sample id="40">为了提高分数，可以要求注释者至少听一些歌曲，并阅读每首歌。</sample>
    <sample id="41">这篇论文有四位作者。</sample>
    <sample id="42">Conjunct Lengths in English, Dependency Length Minimization, and Dependency Structure of Coordination Adam Przepiórkowski and Michał Woźniak INSTITUTE OF COMPUTER SCIENCE POLISH ACADEMY OF SCIENCES ul. Jana Kazimierza 5, 01-248 Warsaw UNIVERSITY OF WARSAW ACL 2023</sample>
    <sample id="43">在“Bouquet/Stanford”中，Lisa、Bart和Maggie之间的关系是同位语关系。</sample>
    <sample id="44">这张图片展示了一个关于协调结构依赖关系的幻灯片。标题是“Coordination的依赖结构”。幻灯片列出了四种不同的协调结构方法：Bouquet/Stanford（通用依赖关系）、Chain/Moscow、Conjunction-headed/Prague和Multi-headed/London。每个方法都用一个例子句子来说明，句子是“Homer loves Lisa, Bart, and Maggie。”幻灯片背景是蓝色的，文字是白色的。右上角有一个小窗口，显示了一个人在讲话。</sample>
    <sample id="45">图片中的文本是“Dependency Structure of Coordination”。</sample>
    <sample id="46">图片中的英文内容翻译成中文为： 依赖结构的协调 Bouquet/斯坦福（通用依赖关系）：荷马爱丽莎、巴特和玛吉。 链接/莫斯科：荷马爱丽莎、巴特和玛吉。 连接头部/布拉格：荷马爱丽莎、巴特和玛吉。 多头/伦敦：荷马爱丽莎、巴特和玛吉。</sample>
    <sample id="47">依赖结构的协调： 1. Bouquet/Stanford（通用依赖）： - Homer loves Lisa, Bart, and Maggie. 2. Chain/Moscow： - Homer loves Lisa, Bart, and Maggie。 3. 连接头/Prague： - Homer loves Lisa, Bart, and Maggie。 4. 多头/London： - Homer loves Lisa, Bart, and Maggie。</sample>
    <sample id="48">这张幻灯片介绍了依赖结构的协调，展示了不同的方法来表示句子结构。它包括了四种方法：Bouquet/Stanford（通用依赖关系）、Chain/Moscow、Conjunction-headed/Prague和Multi-headed/London。每个方法都用一个例子句子“Homer loves Lisa, Bart, and Maggie”来说明。幻灯片的背景是白色的，文字和图表主要是蓝色和黑色的。右上角有一个小窗口显示了一个正在讲话的人。</sample>
    <sample id="49">这张幻灯片展示了“协调结构的依赖关系”（Dependency Structure of Coordination）的概念。它列出了四种不同的依赖关系模式：Bouquet/Stanford（通用依赖关系）、Chain/Moscow、Conjunction-headed/Prague和Multi-headed/London。每种模式都用一个例子来说明，这个例子是“Homer loves Lisa, Bart, and Maggie。”每个例子都用图示方式展示了句子中各个成分之间的依赖关系。</sample>
    <sample id="50">这张幻灯片的标题是“依赖结构协调”。</sample>
    <sample id="51">&lt;no_answer&gt;</sample>
    <sample id="52">Word order tends to minimize dependency lengths:</sample>
    <sample id="53">画面中展示了一张关于依赖长度最小化（Dependency Length Minimization，DLM）的幻灯片。幻灯片的标题是“Dependency Length Minimization (DLM)”。主要内容包括两个句子及其依赖关系图，分别标记为“good”和“bad”。第一个句子是“Marge read it yesterday”，第二个句子是“Marge read yesterday it”。每个句子下方都有一个依赖关系图，显示了单词之间的依赖关系。幻灯片的背景是白色的，顶部有一个蓝色的横幅。右上角有一张人的照片。</sample>
    <sample id="54">这张幻灯片介绍了依赖长度最小化（DLM）的概念。它展示了两个句子的例子，一个被标记为“good”，另一个被标记为“bad”。这些例子用来说明句子结构和依赖关系的长度如何影响句子的可读性和清晰度。</sample>
    <sample id="55">依赖长度最小化（DLM）是一种自然语言处理技术，它通过调整句子的词序来减少依存关系的长度。这有助于提高句子的可读性和流畅性。在图片中，我们看到一个例子，展示了如何通过改变词序来最小化依存关系的长度。具体来说，图片显示了两个句子：'Marge read it yesterday.' 和 'Marge read this absolutely fascinating book about bees yesterday.' 通过调整词序，可以将依存关系的长度从2个单位减少到1个单位，从而改善句子的结构和清晰度。</sample>
    <sample id="56">图片中的英文内容翻译成中文如下： 1. "Word order tends to minimize dependency lengths:" - 词序倾向于最小化依赖长度。 2. "Marge read it yesterday." - Marge 昨天读了它。 3. "Marge read this absolutely fascinating book about bees yesterday." - Marge 昨天读了这本书，这本书关于蜜蜂，非常迷人。</sample>
    <sample id="57">Word order tends to minimize dependency lengths:</sample>
    <sample id="58">Word order tends to minimize dependency lengths.</sample>
    <sample id="59">这张图片显示了一个关于依赖长度最小化的幻灯片。顶部有一个蓝色的标题栏，上面写着“Dependency Length Minimization (DLM)”。标题下方是英文文字：“Word order tends to minimize dependency lengths:”。下面有四个句子的语法树图示，每个句子都有一个绿色或红色标签。这些句子和对应的标签如下：1. “Marge read it yesterday.” - 绿色标签2. “Marge read it yesterday.” - 红色标签3. “Marge read this absolutely fascinating book about bees yesterday.” - 绿色标签4. “Marge read this absolutely fascinating book about bees yesterday.” - 绿色标签幻灯片右侧有一个小窗口，显示一个人的部分图像。</sample>
    <sample id="60">Word order tends to minimize dependency lengths:</sample>
    <sample id="61">画面中展示了一张幻灯片，标题为“Dependency Length Minimization (DLM)”。幻灯片上有一些句子和相应的依存关系图。这些句子包括“Marge read it yesterday.”和“Marge read this absolutely fascinating book about bees yesterday.”。每个句子都有两个不同的依存关系图，分别标记为“good”和“bad”。幻灯片的背景是白色的，顶部有一个蓝色的横幅，上面写着“Dependency Length Minimization (DLM)”的文字。右上角有一个小窗口，显示了一个正在讲话的人。</sample>
    <sample id="62">Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016) left conjuncts tend to be shorter (observed before), this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88–90), but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="63">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016): left conjuncts tend to be shorter (observed before) this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88–90), but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="64">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016): left conjuncts tend to be shorter (observed before), this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88-90) but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="65">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016): left conjuncts tend to be shorter (observed before), this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88-90) but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="66">幻灯片的标题是“英语连词长度”。</sample>
    <sample id="67">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al., 1993, Ficler and Goldberg 2016): left conjuncts tend to be shorter (observed before), this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88-90), but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="68">Conjunct Lengths in English Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al., 1993, Ficler and Goldberg 2016): left conjuncts tend to be shorter (observed before), this tendency grows with length difference (briefly noticed in Gibson et al. 1996:88-90), but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed), not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="69">幻灯片显示了一个标题为“英语连词长度”的演示文稿。主要内容是关于从Penn Treebank增强版本中提取的协调统计信息。提到左连词通常较短（观察到的），这种长度随着长度差异而增长（吉布森等人，1996年：88-90）。它还指出，只有当州长在左边或缺席时（我看到了巴特和丽莎；霍默来了，打喷嚏了），但当州长在右边时（泰德和内德笑了）时，这种效果消失了。幻灯片包含了一个蓝色横幅，上面有额外的文字，但具体内容不清晰。右上角有一个小窗口，可能显示了演讲者或观众的一部分。</sample>
    <sample id="70">好的，我明白了。所以你提到的图表显示了字符、音节和单词长度之间的关系。每个图表都有三个部分：第一个部分是字符长度，第二个部分是音节长度，第三个部分是单词长度。</sample>
    <sample id="71">图中显示了当州长在左边时，州长在左方（CHARACTERS）和州长在右边（WORDS）的图表。</sample>
    <sample id="72">图中展示了九个图表，每个图表都显示了不同条件下的数据趋势。这些图表的标题表明它们分别关注字符、音节和单词长度的比较。每个图表都有一个蓝色的线性趋势线，显示了绝对差异在字符、音节和单词之间的关系。图表的标题包括“NO governor (length in CHARACTERS)”、“NO governor (length in SYLLABLES)”和“No governor (length in WORDS)”。此外，还有两个图表关注“Governor on the LEFT length in CHARACTERS”和“Governor on the RIGHT length in CHARACTERS”，以及“Governor on the LEFT length in SYLLABLES”和“Governor on the RIGHT length in SYLLABLES”。最后，还有两个图表关注“Governor on the RIGHT length in WORDS”和“No governor (length in WORDS)”。每个图表底部有一个注释，解释了图表中所展示的趋势。</sample>
    <sample id="73">幻灯片展示了关于依赖结构协调兼容性的内容。标题为“与协调依赖结构的兼容性”。它比较了不同依赖解析器（Bouquet/Stanford、Chain/Moscow、Conjunction-headed/Prague和Multi-headed/London）对句子“Homer loves Lisa, Bart, and Maggie.”的处理方式。

每个依赖解析器都用一个树状图表示其对句子的分析。对于每个解析器，都有一个标签（NO或YES），表明它是否正确地表示了句子中的协调关系。

- Bouquet/Stanford（通用依赖关系）：NO
- Chain/Moscow：NO
- Conjunction-headed/Prague：YES
- Multi-headed/London：YES

幻灯片背景为白色，文本和图表主要为黑色，关键点以红色突出显示。右上角有一个小窗口，显示了一个人在演示。</sample>
    <sample id="74">画面中有一个白色的背景，上面有黑色的文字。文字内容是“See the paper for the full argument Talk to us at the poster session!”右上角有一个小窗口，显示一个人的头像。</sample>
    <sample id="75">这篇论文有三位作者。</sample>
    <sample id="76">Bible texts are much stronger simplified than news text or language learner texts.</sample>
    <sample id="77">The example of a preference for shorter left conjuncts is 'left conjuncts tend to be shorter (observed before)'.</sample>
    <sample id="78">是的，你可以使用这些模型。</sample>
    <sample id="79">DEplain-apa 包含来自新闻的文档。</sample>
    <sample id="80">For good generalization, we need a better model architecture, larger models, and more fine-tuning examples.</sample>
    <sample id="81">The right column is in words.</sample>
    <sample id="82">为了研究支配词位置的影响，可以设计一个实验，通过测量支配词长度来比较在不同位置（左、中、右）时的差异。</sample>
    <sample id="83">基线分类器在不平衡数据上的训练效果并不理想，因为它无法很好地泛化到新的数据。</sample>
    <sample id="84">There are four authors in this paper.</sample>
    <sample id="85">示例对话中的角色名字是Bob和Alice。</sample>
    <sample id="86">语境感知的MT模型在处理形式性和词汇连贯性方面比语境无关的MT模型更有优势。</sample>
    <sample id="87">The authors of this paper are affiliated with Johns Hopkins University, Purdue University, and MIT.</sample>
    <sample id="122">引入的框架通过比较注释数据集中的注释与模型和数据集的预测和标签，使用Pearson's R分数来量化立场。</sample>
    <sample id="155">在之前的研究中，当人类受试者被给予相同的人格化提示时，他们也能够表面出种族刻板印象。</sample>
    <sample id="156">This study used the Penn Treebank, a dataset of English sentences. It also referenced work by Gibson et al. (1996) and Marcus et al. (1993).</sample>
    <sample id="157">这篇论文有两位作者。</sample>
    <sample id="158">The tasks that are closely related to the concept of consonance and dissonance, which we call CE here.</sample>
    <sample id="159">There are two authors of this paper.</sample>
    <sample id="160">这篇论文有7位作者。</sample>
    <sample id="161">框架引入了用户、模型和数据集之间的比较，而不是像以前的研究那样仅关注注释员的分歧或模型。</sample>
    <sample id="162">In the "White Stereotypes" section, GPT-3.5 has a higher percentage of stereotype words in personas compared to Human and GPT-4, indicating that it contains more stereotypes with these settings.</sample>
    <sample id="163">MuDA benchmark results compared different commercial systems.</sample>
    <sample id="164">幻灯片上有一个标题，写着“ACL2023”。下面是一段文字，内容是“从预训练数据到语言模型再到下游任务：追踪政治偏见的轨迹，导致不公平的NLP模型”。在这一段文字下方，有四个人的名字和头像：Shangbin Feng、Chan Young Park、Yuhan Liu 和 Yulia Tsvetkov。在这些名字的左侧，有三所大学的标志：Paul G. Allen School、University of Washington、UW NLP 和 Carnegie Mellon University Language Technologies Institute。</sample>
    <sample id="165">LM训练数据 一种混合的祝福 Dodge, Jesse 等人，记录大型网络爬虫语料库，自然语言处理会议论文集，2021年。</sample>
    <sample id="166">将英文内容翻译成中文。</sample>
    <sample id="167">这为语言模型应用带来了喜忧参半的福音。</sample>
    <sample id="168">好的，现在我将把英文内容翻译成中文。</sample>
    <sample id="169">画面中的文字内容包括： 1. "To this end" - 这句话位于画面的左上角。 2. "Pretraining data" - 这个词组位于第一个框内，表示预训练数据。 3. "Language models" - 这个词组位于第二个框内，表示语言模型。 4. "Downstream tasks" - 这个词组位于第三个框内，表示下游任务。 5. "How to evaluate the political leaning of LMs?" - 这句话位于画面的左下角，是一个问题，询问如何评估LM的政治倾向。 6. "What role does pretraining data play in such political biases?" - 这句话位于画面的左下角，是一个问题，询问预训练数据在政治偏见中的作用。 7. "How do LMs with different political leanings perform?" - 这句话位于画面的右下角，是一个问题，询问具有不同政治倾向的LM的表现情况。 8. "Does LM political leaning result in fairness issues in NLP applications?" - 这句话位于画面的右下角，是一个问题，询问LM的政治倾向是否会导致NLP应用中的公平性问题。</sample>
    <sample id="170">To this end, how do we evaluate the political leaning of LMs? How does pretraining data play in such political biases?</sample>
    <sample id="171">To this end, how to evaluate the political leaning of LMs? How do LMs with different political leanings perform? Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="172">Evaluating LM Political Leaning</sample>
    <sample id="173">图片中的文字包括：Existing LMs、Authoritarian、Left、Right、economic axis、Libertarian、BERT-base、BERT-large、RoBERTa-base、RoBERTa-large、distilRoBERTa、ALBERT-base、ALBERT-large、BART-base、BART-large、Alpaca、Codex、LLAMA、GPT-2、GPT-3-ada、GPT-3-babbage、GPT-3-curie、ChatGPT、GPT-4、GPT-J。</sample>
    <sample id="174">图片显示了一个散点图，展示了各种语言模型（LMs）在社会经济自由度和政治倾向方面的分布。图表分为四个象限：左翼、右翼、左翼和右翼。每个象限都包含不同语言模型的标签，如BERT-base、BERT-large、RoBERTa-base等。图表还显示了这些语言模型之间的连接线，表明它们之间的关系或相似性。</sample>
    <sample id="175">图片中的英文内容翻译成中文为： 预训练数据 进一步预训练LM（RoBERTa，GPT-2）检查点，评估政治倾向变化</sample>
    <sample id="176">画面中的文字内容包括： 1. 标题：Pretraining Data 2. 副标题：Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning 3. 图表左侧部分： - 标题：News Media - 左侧标签：left - 中间标签：center - 右侧标签：right 4. 图表右侧部分： - 标题：Social Media (Reddit) - 左侧标签：left - 中间标签：center - 右侧标签：right 5. 图片底部左下角的参考文献： Liu, Yajun, et al. "POLiTS: Pretraining with Same-story News and Social Media for Political Lean Detection." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP). Vol. 2021. 6. 图片底部右下角的参考文献： Shen, Girija, and Carolyn Rose. "What sounds 'right' to me? Experiential factors in the perception of political leanings by language models trained on Reddit data." Journal of the Association for Computational Linguistics. Vol. 7, No. 2. 2021.</sample>
    <sample id="177">将英文内容翻译成中文。</sample>
    <sample id="178">画面中的文字内容包括：

标题：Results

副标题：Partisan shifts in LM political leaning

在图表中，有以下标签和箭头：
- RoBERTa
- GPT-2
- original
- news
- redditt
- Left
- Center
- Right

这些标签和箭头用于展示RoBERTa和GPT-2在政治倾向上的变化。</sample>
    <sample id="179">将英文内容翻译成中文。</sample>
    <sample id="180">The Trump Card Pre-45th to post-45th shift</sample>
    <sample id="181">图片中的文字内容包括标题和多个子标题，具体内容如下：

标题：
- The Trump Card

子标题：
1. Pre-45th to post-45th shift
2. news left
3. news center
4. news right
5. reddit left
6. reddit center
7. reddit right

每个子标题下都有一个方框，方框内包含以下内容：
- 一个箭头指向右上角
- 一个方框内的数值（例如：Δ=(275,124)、Δ=(-0.13,103)等）

此外，在左下角有一个额外的数值：GPT-2 (Δ=(-237,051))。

这些内容似乎与某种数据或分析结果有关，可能涉及不同时间段的数据变化。</sample>
    <sample id="182">The Trump Card</sample>
    <sample id="183">好的，所以最后但并非最不重要的是，我们评估了具有不同政治倾向的语言模型在仇恨言论检测和假新闻检测上的性能。这些结果是颜色编码的，深黄色表示最佳，而深蓝色表示最差。</sample>
    <sample id="184">表格标题为“按类别表现”。</sample>
    <sample id="185">这张图片展示了一个名为“按类别表现”的表格，表格中列出了不同类别在各种媒体上的表现。表格的标题是“Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources”。表格中的颜色编码显示，深黄色代表表现最佳，而深蓝色代表表现最差。

表格分为两部分：上半部分和下半部分。上半部分包括“仇恨言论”、“黑人”、“穆斯林”、“LGBTQ+”、“亚洲人”、“拉丁裔”、“女性”、“基督徒”和“白人”等类别。下半部分包括“HP”、“纽约时报”、“CNN”、“福克斯新闻”、“守护者”、“BB&amp;T”、“沃特”和“NR”等类别。

每个类别都有相应的数据，表示在不同媒体上的表现。例如，在仇恨言论类别下，“Reddit”和“新闻88.81”有较高的表现分数，而“新闻90.62”则较低。在“HP”类别下，“Reddit”和“新闻85.37”也有较高的表现分数，而“新闻89.44”则较低。

表格中的颜色编码帮助快速识别每个类别的最佳和最差表现。</sample>
    <sample id="186">检测针对社会少数群体的仇恨言论</sample>
    <sample id="187">这张图片中的表格显示了不同类别在针对特定身份群体的仇恨言论和来自不同来源的误导方面的表现。表格分为两部分：上半部分是仇恨言论，下半部分是误导。每个部分都列出了不同的身份群体，如黑人、穆斯林、LGBTQ+、亚洲人、拉丁裔、女性、基督徒和白人。对于每个身份群体，表格提供了由Reddit、新闻88.1、新闻90.95和新闻90.62等来源的数据。数据以颜色编码的方式呈现，深黄色表示最佳表现，而深蓝色则表示最差表现。表格底部的文字解释了这种颜色编码系统，并指出表4显示了针对特定身份群体的仇恨言论和误导的表现。</sample>
    <sample id="188">Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded: dark yellow denotes best, blue denotes worst (worst).</sample>
    <sample id="189">表格标题为“按类别表现”，显示了针对不同身份群体和来自不同来源的误导信息的仇恨言论检测性能。</sample>
    <sample id="190">Qualitative Analysis Text Target Label Base ASIAN TRUE TRUE FALSE FALSE FALSE CHRIS TRUE TRUE FALSE FALSE FALSE RIGHT FALSE FALSE TRUE TRUE TRUE LEFT TRUE TRUE TRUE TRUE TRUE</sample>
    <sample id="191">The text in the image discusses qualitative analysis of hate speech examples, indicating that there are more detailed examples available in an appendix to further illustrate this topic.</sample>
    <sample id="192">这表明在语言模型的政治偏见方面，有一个非常紧迫的公平性问题。</sample>
    <sample id="193">好的，我将根据图片中的内容进行翻译。 例如，如果右倾语言模型被调整以针对仇恨言论或错误信息，并部署到一个流行的社交媒体平台上，那么这些模型可能会对仇恨言论和错误信息的传播产生重大影响。这可能导致平台上的有害内容增加，从而影响用户的体验和平台的整体健康状况。此外，如果这些模型没有得到适当的监督和审查，它们可能会传播错误信息并加剧社会分裂。因此，重要的是要仔细考虑在社交媒体平台上使用语言模型的伦理影响，并确保它们被设计为促进积极和包容的对话。</sample>
    <sample id="194">Table 12: Qualitative analysis of hate speech example where TMs with political leanings beg to differ.</sample>
    <sample id="195">这张图片展示了一张幻灯片，标题为“Discussion”。幻灯片上有三行文字和一个流程图。第一行写着“Between Scylla and Charybdis”，第二行写着“To 'sanitize' or not to 'sanitize', that is the question”。第三行是流程图，包含三个方框，分别标有“Pretraining data”、“Language models”和“Downstream tasks”，这些方框通过波浪线连接起来。右上角有一个小窗口显示一个人的图像。</sample>
    <sample id="196">幻灯片上有一个标题，写着“讨论”。在标题下面，有一段文字写着“Scylla和Charybdis之间”，接着是“是否要‘净化’还是不要‘净化’，这是个问题。” 在这段文字的下方，有三个框。第一个框里写着“预训练数据”，第二个框里写着“语言模型”，第三个框里写着“下游任务”。 这三个框通过波浪线连接在一起，表示它们之间的关系。</sample>
    <sample id="197">这张图片显示了一个幻灯片，标题为“讨论”。在标题下方，有一个副标题写着“Scylla和Charybdis之间”。接着是一个问题：“是否要‘净化’或不要‘净化’，这是个问题。” 图片中还包含一个流程图，显示了三个步骤：1. 预训练数据（Pretraining data）2. 语言模型（Language models）3. 下游任务（Downstream tasks） 流程图中的箭头表示从预训练数据到语言模型再到下游任务的流程。</sample>
    <sample id="198">图片显示了一个演示文稿的最后一页，上面有“谢谢！”的字样。在顶部，有一个流程图，从左到右依次为“预训练数据”、“语言模型”和“下游任务”。在流程图下方，有四个人的名字：Shangbin Feng、Chan Young Park、Yuhan Liu和Yulia Tsetkova。在这些名字下方，有四个标志，分别代表不同的机构或组织：Paul G. Allen School of Computer Science &amp; Engineering、UW NLP、Carnegie Mellon University Language Technologies Institute和另一个带有红色印章的标志。</sample>
    <sample id="199">画面中展示了一张幻灯片，顶部写着“Thank you!”。幻灯片上有三个框，分别标有“Pretraining data”、“Language models”和“Downstream tasks”。每个框之间用波浪线连接。幻灯片下方列出了四个人的名字：Shangbin Feng、Chan Young Park、Yuhan Liu和Yulia Tsetkov。在名字下方有四个标志，分别是Paul G. Allen School、UW NLP、Carnegie Mellon University Language Technologies Institute和一个带有红色印章的标志。</sample>
    <sample id="200">这篇论文有6位作者。</sample>
    <sample id="201">MPP评估最多涵盖900个词元的上下文长度。</sample>
    <sample id="202">他们的数据集中包含音乐选择、书籍选择和食谱选择领域。</sample>
    <sample id="203">Positionality is the perspectives that people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="204">演讲者的名字是Dawei Zhu。</sample>
    <sample id="205">EDAtt 是适应了现有的离线 ST 模型。</sample>
    <sample id="206">这篇论文有三位作者。</sample>
    <sample id="207">Yes, the models can run on the test suite.</sample>
    <sample id="208">KITMUS有三个变体：背景预训练、背景双模式和背景推理。</sample>
    <sample id="209">Google Research</sample>
    <sample id="210">最后一个研究问题是：如何更有效地利用可用的干净样本？</sample>
    <sample id="211">指标灵敏度通过计算模型在执行同一任务时对多种指令变化的敏感程度来工作。它评估了模型在面对指令措辞变化时保持一致性的能力，从而衡量其对指令变化的鲁棒性。</sample>
    <sample id="212">The speaker's name is Jingwei Yi.</sample>
    <sample id="213">更高的灵敏度表示模型性能得到了提高。</sample>
    <sample id="214">在预训练期间，模型会接收大量的语言上下文。</sample>
    <sample id="215">In WSL, it is typically sufficient to have 20 clean validation samples per class for a good performance.</sample>
    <sample id="216">The authors of this paper are affiliated with Stanford Engineering, specifically the Computer Science department.</sample>
    <sample id="217">To answer the question, we need to understand why new methods are needed for measuring media bias. The image shows a political compass with different language models (LMs) plotted on it based on their political leanings and authoritarian tendencies.

1. **Political Leaning**: Language models like BERT-base, RoBERTa-base, and ALBERT-large appear in various quadrants of the compass, indicating they have diverse political leanings.
2. **Authoritarian Tendencies**: These same models show varying degrees of authoritarianism across the vertical axis.
3. **Intersection of Political Leanings**: Some models occupy multiple quadrants simultaneously, suggesting that traditional measurement tools might not capture these complexities effectively.

Given this information:

- Current methods may struggle to accurately measure how much each model leans politically or exhibits authoritarian traits due to their complex interplay.
- New approaches could help provide more nuanced insights into the biases within AI systems used by media organizations.

Therefore, developing fresh techniques is essential because existing ones likely fail to fully account for the intricate relationships between political leaning and authoritarian behavior exhibited by advanced language models.</sample>
    <sample id="218">The speaker's name is Akthar Al-Ali.</sample>
    <sample id="219">政治偏见传播流程是怎样的？</sample>
    <sample id="220">Yes, DEplain-apa 和网站的简化过程有所不同。</sample>
    <sample id="221">No, Coscript is not publicly available.</sample>
    <sample id="222">The watermark is inserted into the text by first defining a target embedding, then counting the trigger number in the sentence. After that, it adds the target embedding to the original embedding.</sample>
    <sample id="223">The Penn State University and Amazon logos are displayed at the bottom of the slide, indicating that these institutions are associated with the authors.</sample>
    <sample id="224">是的，根据所提供的英文内容，像mt5这样的编码器-解码器模型可以通过混合语言的训练来改进。</sample>
    <sample id="225">受限语言规划的一个示例是，制作草莓蛋糕和巧克力蛋糕的步骤。</sample>
    <sample id="226">They ensured the covertness of their method by visualizing sentence embeddings on four datasets via PCA.</sample>
    <sample id="227">To build new PLM, we can use existing models as a foundation and then fine-tune them with additional training data. This approach leverages the knowledge already learned by these pre-trained models while adapting them to specific tasks or domains within the PLM framework.</sample>
    <sample id="228">根据图表显示，GPT-4 与“西非”地区的立场最不一致。</sample>
    <sample id="229">演讲者在“Leverage the knowledge already acquired by the model through the attention mechanism between audio input and text output”这个句子上展示了模型如何利用注意力机制所学的知识。</sample>
    <sample id="230">任务的数量增加，模型的性能会更好。</sample>
    <sample id="231">作者用来比较其方法的三个无树基线是：LSTM seq2seq、TS和Zheng and Lapata。</sample>
    <sample id="232">The two co-authors, Alexander Koller and Ivan Titov, are the advisors of the first author, Matthias Lindemann.</sample>
    <sample id="233">Chowdery et al., 2022</sample>
    <sample id="234">幻灯片上展示了五个人的名字和头像，分别是：Sebastian Santy、Jenny T. Liang、Ronan Le Bras、Katharina Reinecke和Maarten Sap。</sample>
    <sample id="235">幻灯片上显示了关于NLP位置性的信息，以及几位研究人员的姓名和他们所在的机构。</sample>
    <sample id="236">画面中有一个穿着深色上衣的人，背景是一个书架，上面摆放着书籍和其他物品。</sample>
    <sample id="237">画面中有一个卡通人物，名字是Carl Jones，职位是Tech Lead，所在公司是New York Times。人物上方有一段文字，内容是“Can you stop being a jerk?”，旁边有一个表情符号和一个评分（0.82），以及一个绿色的对勾。左下角有一个符号，表示PerspectiveAPI score。</sample>
    <sample id="238">画面中展示了两个人物的头像和信息。左边的人物是Carl Jones，他的职位是Tech Lead，工作单位是New York Times。右边的人物是Aditya Sharma，他的职位也是Tech Lead，工作单位是Times of India。两个人物之间有一个对话框，内容是“Can you stop being a jerk?”，并附有PerspectiveAPI的评分（0.82），评分为绿色对勾，表示该评论被认为是不冒犯的。在下方，另一个对话框显示了另一条评论“Presstitutes everywhere on the news.”，评分为（0.33），评分为红色叉号，表示该评论被认为是冒犯的。左下角有一个注释，写着“= PerspectiveAPI score”，表示这些评分是通过PerspectiveAPI获得的。</sample>
    <sample id="239">这是一个设计偏见的例子，我们看到技术之间的系统性能差异。</sample>
    <sample id="240">幻灯片包含一个标题“Positionality”和一个引用。引用写着：“人们所持有的视角是由于他们的人口统计、身份和生活经历的结果。”在引用下方，有一个参考文献：[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." "Qualitative Research: The Essential Guide to Theory and Practice." Routledge (2013). 右上角有一张小图片，显示一个人坐在书架前。</sample>
    <sample id="241">Positionality</sample>
    <sample id="242">幻灯片显示了关于“位置性”的文本。它解释说，人们持有的视角是由于他们的人口统计学、身份和生活经验的结果。作为研究人员，它影响了研究过程及其结果和成果。引用了Savin-Baden, Maggi和Claire Howell-Major的《定性研究：理论与实践的必备指南》中的内容。</sample>
    <sample id="243">将英文内容翻译成中文。 Do datasets and models have positionality? [1] Blasi, et al. “Systematic Inequalities in Language Technology Performance across the World’s Languages.” ACL 2022. [2] Ye et al. “GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Training Language Models.” EMNLP 2022. [3] Cambo &amp; Gergle. “Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science.” CHI 2022.</sample>
    <sample id="244">画面中展示了一张幻灯片，上面有一个标题和三篇参考文献。标题是“数据集和模型有位置性吗？”（Do datasets and models have positionality?）。参考文献分别是： 1. Blasi, et al. "World Languages." ACL 2022. 2. Yi et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Training Language Models." EMNLP 2022. 3. Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022. 右上角有一张小图片，显示了一个人在演讲或讲座。</sample>
    <sample id="245">图片中的文字内容翻译如下： 1. Blasi, et al. “跨语言的系统性不平等：全球语言技术性能。” ACL 2022。 2. Yi等。“GEOMLAMA：多语种预训练语言模型的地理多元共识探针。” EMNLP 2022。 3. Cambo &amp; Gergle. “模型位置性和计算反射性：促进数据科学中的反思性。” CHI 2022。</sample>
    <sample id="246">将英文内容翻译成中文。</sample>
    <sample id="247">在幻灯片中，有一张小图片显示一个人坐在桌子旁。这个人似乎在演讲或演示，因为他们的嘴是张开的，好像在说话。背景是一个房间，有书架和一些物品。</sample>
    <sample id="248">画面中的文字内容包括： 1. 标题：Do datasets and models have positionality? 2. 段落标题：Anecdotal evidence: - Model and dataset probing [1][2] - Theoretical definitions of model positionality [3] 3. 引用文献列表： [1] Blasi, et al. “Systematic Inequalities in Language Technology Performance across the World’s Languages.” ACL 2022. [2] Ye et al. “GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models.” EMNLP 2022. [3] Cambo &amp; Gergle. “Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science.” CHI 2022.</sample>
    <sample id="249">画面中的文字内容是一个问题和一个目标。问题为：“数据集和模型有位置性吗？”目标是“比较用户注释与现有数据集和模型。”</sample>
    <sample id="250">NLPPositionality A framework for characterizing design biases in NLP datasets and models</sample>
    <sample id="251">我们的框架分为两个主要步骤。</sample>
    <sample id="252">框架的第一步是用不同的注释员重新注释数据集。</sample>
    <sample id="253">框架：收集、处理和注释。</sample>
    <sample id="254">将英文内容翻译成中文。</sample>
    <sample id="255">框架的英文内容翻译成中文为： 1) 收集 2) 比较注释与人口统计学、模型和数据集，使用皮尔逊的相关系数。</sample>
    <sample id="256">框架包括三个主要部分：收集、处理和分析。</sample>
    <sample id="257">Lab in the Wild 是一个在线众包平台，用于收集人机交互（HCI）领域的合作贡献者。</sample>
    <sample id="258">Lab in the Wild is an online experimentation platform where we can recruit diverse volunteers compared to platforms like MTurk, which largely have participants from the US or India.</sample>
    <sample id="259">图片中的英文内容翻译成中文为： 任务A：社会接受度。 1. 阅读情况。 想要赚很多钱。 2. 从多个角度考虑它。 3. 看看人工智能和其他人对此的看法。 参与者将从社会化学数据库中阅读一个情况，然后评估该情况的社会接受程度。</sample>
    <sample id="260">任务A：社会可接受性</sample>
    <sample id="261">任务A：社会接受度分析 数据集 - 社会化学 模型 - Delphi - GPT-4</sample>
    <sample id="262">图片中的英文内容翻译成中文如下： 1. 阅读示例。 英国人闻起来像酸牛奶。 2. 你认为它怎么样？（这是一个可选的复选框）你认为这是否是仇恨言论？（选项为“是”或“否”）请自由解释你的回答。 提交。 3. 看看其他人怎么说！ AI推测：我推测这是阿富汗人说的。 参与者从Dinahate数据集中阅读一个实例，并判断他们认为它是仇恨言论还是仇恨言论。</sample>
    <sample id="263">画面中显示了“Study Participation”这一标题。在标题下方，有三个数字和对应的描述：16,299 annotations（16,299个注释）、1,096 annotators（1,096个注释者）和87 countries（87个国家）。</sample>
    <sample id="264">画面中显示了一段文字，内容是“Finding 1: There is positionality in NLP.”。背景是白色的，右上角有一个小窗口，里面似乎是一个人在一个房间里。</sample>
    <sample id="265">Datasets and models are most aligned to English-Speaking countries.</sample>
    <sample id="266">图表显示了不同教育水平的社交可接受度。标题为“GPT-4的社交可接受度”。X轴列出了不同的教育水平：大学、研究生院、高中、博士后、中等教育和教授。Y轴表示社交可接受度的值，范围从0到1。

每个条形图上方都有一个数字，表示样本大小（N），以及一个星号，表示统计显著性。大学和研究生院的条形图高度相似，社交可接受度值均为0.69，并且都标有星号，表明它们具有统计显著性。高中、博士后、中等教育和教授的条形图显示较低的社交可接受度值，分别为0.64、0.61、0.59和0.49。这些值也标有星号，表明它们是统计显著的。

左侧的文字写着：“数据集和模型与拥有大学教育的人最匹配。”这表明GPT-4在社交可接受度任务中与大学和研究生院教育水平的人最匹配。</sample>
    <sample id="267">数据集和模型最与拥有大学学历的人群对齐。</sample>
    <sample id="268">发现2：有些群体被落下。</sample>
    <sample id="269">图片显示了一个名为“Dynahate”的任务的条形图，该任务与仇恨言论和毒性有关。图表分为三类：男性、非二元性别和女性。每个类别都有一个柱状图，表示它们在任务中的表现。男性类别有1798个样本，得分为0.65*。非二元性别的类别有329个样本，得分为0.58*。女性类别有2357个样本，得分为0.63*。图表左侧的文字说明了数据集和模型对非二元性别个体的不充分对齐。</sample>
    <sample id="270">So, what can we do? Addressing positionality in NLP</sample>
    <sample id="271">推荐1. 在整个构建数据集或模型的过程中，记录所有相关的设计选择。</sample>
    <sample id="272">推荐3. 建立针对特定社区的专门数据集和模型是有价值的，例如Masakhane倡议1。</sample>
    <sample id="273">好的，我明白了。请继续。</sample>
    <sample id="274">演讲者提到了 SimulST 的几个问题：1. 专门的架构通常被训练，引入额外的模块以进行优化。2. 长而复杂的训练程序（例如，不同的优化目标）。3. 训练和维护多个模型以达到不同的延迟制度（例如，1秒、2秒等）。</sample>
    <sample id="275">在训练 NLP 模型时，减轻数据集中的社会和政治偏见的有效方法是“对数据进行 sanitization”。</sample>
    <sample id="276">The 61st Annual Meeting of the Association for Computational Linguistics Toronto, Canada July 9-14, 2023 Distilling Script Knowledge from Large Language Models for Constrained Language Planning Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xiange Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang Brain Technologies Inc.</sample>
    <sample id="277">图片中的英文内容翻译成中文是： 语言规划 如何制作蛋糕？ 1. 收集你的原料。 2. 预热烤箱至325华氏度（163摄氏度）并涂抹黄油和面粉在蛋糕模具上。 3. 打发黄油和糖。 4. 加入鸡蛋。 5. 搅拌到无颗粒的蛋糕粉。 6. 将面糊倒入模具中。 7. 烘烤15分钟。 大型语言模型（LLMs）可以将目标分解为步骤。</sample>
    <sample id="278">画面中展示了一张幻灯片，标题为“Language Planning”。幻灯片上有一个步骤说明，标题是“How to Make a Cake?”。步骤如下： 1. Gather your ingredients. 2. Preheat the oven to 325°F (163°C) and grease and flour a cake pan. 3. Cream the butter and sugar. 4. Add eggs. 5. Stir in the dry ingredients. 6. Pour the batter into the pan. 7. Bake the cake for 1 hour 15 minutes. 在幻灯片的下方，有一句话写着：“Large language models (LLMs) can effectively decompose goals into steps。” 幻灯片的右侧显示了一个戴眼镜和绿色衬衫的人，背景是一个室内环境。</sample>
    <sample id="279">这张图片显示了一个名为“Constrained Language Planning”的幻灯片。幻灯片上展示了如何制作草莓蛋糕和巧克力蛋糕的步骤，包括添加果酱和可可粉到面粉中。幻灯片底部有一段文字，提到抽象目标可以继承自不同现实具体目标的多面约束。右上角有一个视频通话窗口，显示一个人在讲话。背景是一个现代化的办公室环境。</sample>
    <sample id="280">这篇论文中，我们定义了受约束语言规划的问题。</sample>
    <sample id="281">这张图片展示了一个名为“Constrained Language Planning”的演示幻灯片。幻灯片上有两个部分：左侧是文字内容，右侧是一个人在视频通话中讲话。文字内容包括如何制作草莓蛋糕和巧克力蛋糕的步骤，以及关于抽象目标继承具体目标约束的讨论。</sample>
    <sample id="282">图片中的英文内容翻译成中文为： 在这篇论文中，我们首先评估并施加了对大型语言模型的约束语言规划能力。</sample>
    <sample id="283">这张图片展示了一个关于在受限语言规划中，大型语言模型（LLMs）表现如何的演示。图片左侧有一个标题“LLMs在受限语言规划中的表现”，下面是一个数据集的描述：“wikiHow + 生成的约束条件”。接下来是两种约束类型的详细说明：1. 修改器（Constraint Type 1: Modifier）：定义为一个形容词或介词短语，它修改或约束一个抽象目标。例子包括“制作巧克力蛋糕”和“制作粉色蛋糕”。2. 方法（Constraint Type 2: Method）：定义为一种工具或特定模式，用于控制实现目标的过程。例子包括“用烤箱做蛋糕”和“用蛋糕混合物做蛋糕”。3. 目的（Constraint Type 3: Intent）：定义为在完成目标时需要达到的具体目的或需求。例子包括“为婚礼做蛋糕”和“为糖尿病做蛋糕”。图片右侧显示了一个人在演示，背景看起来像是一个现代办公室环境。</sample>
    <sample id="284">图片中的英文内容翻译成中文如下： 1. 如何让大型语言模型在受约束的语言规划中表现良好？ 2. 数据集：维基百科 + 生成的约束条件 3. 约束类型 1：修饰符 定义：一个形容词、副词或短语，修改或约束特定目标。 示例：制作巧克力蛋糕 制作粉色蛋糕 4. 约束类型 2：方法 工具或指定模式，控制实现目标的过程。 示例：用烤箱做蛋糕 使用蛋糕混合物做蛋糕 5. 约束类型 3：意图 目标的具体目的或需求，当完成目标时。 示例：为婚礼制作蛋糕 为糖尿病制作蛋糕</sample>
    <sample id="285">这张图片展示了一个关于大型语言模型（LLMs）在受限语言规划方面的表现的演示幻灯片。幻灯片的主要问题是“LLMs是否能进行受限语言规划？”幻灯片上有一个柱状图，比较了不同LLM模型在准确度上的表现。这些模型包括T5（11B）、Flan-T5（11B）、GPT-3（175B）、CodeLLaMDA（175B）和InstructGPT（175B）。柱状图显示，所有基线模型在特定目标规划方面都取得了令人满意的成果。幻灯片底部有一条注释，强调了这一点：“所有基线模型在特定目标规划方面都取得了令人满意的成果。”背景中可以看到一个房间，里面有人坐在桌子旁，可能是在进行演示或会议。</sample>
    <sample id="286">这张幻灯片包含一个标题、一个图表和一些文本。标题是“Can LLMs do Constrained Language Planning?”，意思是“大型语言模型能进行受约束的语言规划吗？” 图表显示了不同模型在准确度方面的表现，包括T5（11B）、Flan-T5（11B）、GPT-3（175B）、Rewards-Aligned GPT-3（175B）和InstructGPT（175B）。每个模型的准确度用不同的颜色表示。文本指出，“所有基线都未能达到令人满意的特定目标规划结果。” 这表明，在受约束的语言规划任务中，这些大型语言模型的表现并不令人满意。</sample>
    <sample id="287">幻灯片显示了一个雷达图，标题为“LLMs在执行此任务时通常会犯什么类型的错误？”，并包含一个图表。图表有五个轴：FE1（无约束），SE1（重复步骤），SE2（顺序错误），FE2（不一致），和SE3（生成脚本的语义完整性）。每个轴上都有数值标记，从0到100。还有一个文本框，写着“生成脚本的语义完整性（SE）是可以接受的，但对约束的忠实性（FE）不能保证。”</sample>
    <sample id="288">幻灯片上显示了一张雷达图，标题为“LLMs在执行此任务时通常会犯什么类型的错误？”。图中有五个轴，分别标记为：FE1：无约束（No constraint），FE2：重复步骤（Repeated step），FE3：不一致（Incoherent），SE1：顺序错误（Wrong order），SE2：重复步骤（Repeated step）。每个轴都有一个范围，从0到100。在雷达图下方，有一段文字写着：“生成脚本的语义完整性（SE）是可以接受的，但对约束的忠实度（FE）不能得到保证。”</sample>
    <sample id="289">What kinds of goals do InstructGPT typically fail?</sample>
    <sample id="290">画面中的文字内容包括： 1. 标题：Method 2. 输入：Input: an abstract goal 3. 步骤1：Step 1: Generate specific goals with InstructGPT via in-context learning 4. 抽象目标：Abstract Goal: Make a cake 5. 约束：+ constraints 6. 具体目标：Specific Goals: G1 (+ modifier): Make a chocolate cake G2 (+ method): Make it in the microwave G3(+ intent): Make a cake for a wedding</sample>
    <sample id="291">&lt;no_answer&gt;</sample>
    <sample id="292">这段文字介绍了使用InstructGPT进行任务指导的方法。首先，输入一个抽象的目标，然后通过InstructGPT生成具体的任务目标和约束。接着，根据这些具体目标生成计划，并过量生成候选脚本。最后，选择合适的脚本来实现特定的目标。</sample>
    <sample id="293">这张图片展示了一个名为“Method”的流程图。流程图分为三个步骤：

1. Step 2: Over-generate candidate scripts via in-context learning
2. Step 3: Find filters to the goal with InstructGPT via similarity score

在Step 3中，有一个图表显示了候选脚本和过滤后的脚本。图表中有多个脚本，每个脚本都有一个相似性得分（例如0.3、0.2、0.5等）。一些脚本被标记为“Filtered Scripts”，并附有勾号，表示它们通过了过滤。

在图表下方，有一个示例脚本（Script 3），内容是：
1. Gather your ingredients
2. Add the cocoa powder

右侧有一个穿着绿色上衣的人，背景是一个现代化的办公室环境。</sample>
    <sample id="294">将英文内容翻译成中文。</sample>
    <sample id="295">这张图片展示了一个名为“Method”的演示幻灯片，其中包含一个流程图和一个视频通话窗口。流程图分为三个步骤：1. Step 2: Over-generate candidate scripts via in-context learning。2. Step 3: Find scripts that align with the goal using InstructGPT via similarity score。3. Output: Specific goals with corresponding scripts。在流程图的右侧，有一个视频通话窗口，显示一个人在进行演示。背景是一个现代化的办公室环境。</sample>
    <sample id="296">画面中展示了一个演示文稿，主要内容是关于一种方法如何显著提高规划质量。左侧有一个柱状图，显示了不同模型的准确性对比，包括T5、Flan-T5、GPT-3、InstructGPT和该方法。右侧是一个视频通话窗口，显示一个人在演示。下方有一段文字说明，提到使用这种方法，InstructGPT可以生成高质量的脚本，并且通过大量提升来证明这一点。</sample>
    <sample id="297">图像中的英文内容翻译成中文为： 从LLMs中进行脚本蒸馏。动机：为了使较小的模型具备语言规划能力。方法：遵循符号知识蒸馏的原则。根据LLMs生成基于约束的55,000个脚本，基于我们的方法生成Cospset数据集。人工标注验证和测试集。输出：具有相应计划的脚本。</sample>
    <sample id="298">Motivation: To enable constrained language planning for smaller models.</sample>
    <sample id="299">Script Distillation from LLMs</sample>
    <sample id="300">为了构建一个名为Coscript Dataset的受限语言规划数据集，我们将应用我们的方法。</sample>
    <sample id="301">幻灯片上的文字内容翻译如下：

标题：从LLMs进行脚本蒸馏

动机：
- 使较小模型的约束规划能力能够启用。

方法：
- 遵循符号知识蒸馏的原则。
- 基于InstructGPT生成了55,000个带约束的脚本，使用我们的方法称为Cocspit Dataset。
- 人工标注验证集和测试集。

步骤1：
- 输入：一个抽象
- 生成特定目标的脚本，使用InstructGPT进行交互式学习。

步骤2：
- 生成超出目标的脚本，使用InstructGPT进行交互式学习。

步骤3：
- 根据相似度分数筛选脚本，以达到目标。

输出：
- 具有相应计划的特定目标脚本。</sample>
    <sample id="302">这张幻灯片展示了关于约束分析的内容，重点是Coscript在较小语言模型中的应用。它包含一个饼图和一些文本信息。饼图显示了不同类别的分布情况，如Ingredient、Modifier、By、Method、Using等，每个类别都有相应的百分比。文本部分提到了Coscript的高异质性和多样性，并介绍了用于评估生成文本与约束一致性的指标，包括DeBERTa（v3大型）模型和自动指标ROUGE、BLEU、BERTScore。此外，还提到使用Coscript可以训练更小但更专业的模型进行约束语言规划，并指出经过Coscript微调的小型语言模型可以产生比大型语言模型更好的脚本。</sample>
    <sample id="303">画面中展示了一张幻灯片，标题为“Specialized Models vs. LLMs”。幻灯片左侧有一个柱状图，显示了不同模型在准确性方面的表现。柱状图下方有一段文字，内容是：“Smaller LMs fine-tuned on Coscript can generate higher quality scripts than LLMs。”幻灯片右侧有一个视频通话窗口，显示一个人在讲话。背景是一个室内环境，有桌子和椅子。</sample>
    <sample id="304">幻灯片包含一个标题为“Summary and Takeaways”的部分。内容如下： 1. 建立了约束语言规划问题。 2. 评估了大型语言模型（LLMs）的约束语言规划能力，并开发了一个过生成-然后过滤方法（over-generate-then-filter method）用于LLMs。 3. 使用CoScript（约束语言规划高质量脚本集）来生成约束语言规划的高质量脚本集。 4. 限制和未来工作： - 改进LLMs的方法是后接式的方法。 - CoScript仅从单个额外约束的一个约束中继承。 - CoScript数据集可以作为推进语言规划研究的宝贵资源，具有更多的复杂目标和约束。 幻灯片右下角显示数字16，表明这是演示中的第16张幻灯片。</sample>
    <sample id="305">幻灯片上有一段文字，内容如下：'We hope CoScript dataset can be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints.'</sample>
    <sample id="306">第61届计算语言协会年会 2023年7月9日至14日，多伦多，加拿大。</sample>
    <sample id="307">PaLM的流畅度与SOTA相当。</sample>
    <sample id="308">The important attributes of the watermark method are applicability to embedding and services, utility (should not degrade the provided embeddings), covertness (should be covert to the attacker), and transferability (the watermark needs to be transferable to the attacker's services).</sample>
    <sample id="309">TED 英语演讲已被翻译成以下14种不同的语言：英语、阿拉伯语、德语、西班牙语、法语、意大利语、日语、韩语、荷兰语、葡萄牙语、罗马尼亚语、俄语、土耳其语和中文。</sample>
    <sample id="310">300</sample>
    <sample id="311">Cosine and L2 similarity.</sample>
    <sample id="312">基于编码器的多语言模型可以通过使用预训练的编码器和解码器来实现。例如，ENC-PTR 和 ENC-Dec 模型是基于编码器的多语言模型的例子。ENC-PTR 包括 XLM-R + PTR 和 mBERT + PTR，而 ENC-Dec 包括 mBERT 和 mBART。这些模型在不同数据集上的表现表明了它们的有效性。</sample>
    <sample id="344">作者通过在一般文本语料库中计算单词频率来确定中等频率的单词。</sample>
    <sample id="345">图片中的文字内容包括： 1. 标题：Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023? 2. 姓名和机构信息：Shuheng Liu, Alan Ritter School of Interactive Computing Georgia Institute of Technology 3. 校徽：Georgia Tech的标志出现在右下角。</sample>
    <sample id="346">幻灯片的标题是“命名实体识别与泛化”。</sample>
    <sample id="347">幻灯片的标题是“命名实体识别与泛化”。它包含以下内容： 1. “模型已经使用CoNLL-2003开发NER将近20年。” 2. “这些模型能适应现代数据吗？” 幻灯片左下角有一个头像，右下角有Georgia Tech的标志。</sample>
    <sample id="348">幻灯片上的英文内容翻译成中文是： 1. 模型已经使用CoNLL-2003开发命名实体识别（NER）将近20年。 2. 这些模型能适应现代数据吗？ 3. 良好泛化需要什么？</sample>
    <sample id="349">画面中展示了一张幻灯片，标题为“Named Entity Recognition &amp; Generalization”。幻灯片上有以下几点内容： 1. “Models have been using CoNLL-2003 to develop NER for almost 20 years”（这些模型已经使用CoNLL-2003来开发NER将近20年）。 2. “Can these models generalize to modern data?”（这些模型能否适用于现代数据？） 3. “What is needed for good generalization?”（为了实现良好的泛化需要什么？） 4. “What causes the performance drop?”（性能下降的原因是什么？） 在左下角有一个Georgia Tech的标志。</sample>
    <sample id="350">幻灯片上显示了“CoNLL++ Dataset”的标题。在标题下方，有一段文字说明：“收集了2020年的路透社新闻，并根据CoNLL-2003注释指南进行了注释。” 在这段文字旁边，有一个示例句子，其中的每个单词都标有其相应的词性或组织类型： - AMBASSADOR: O - TO: O - THE: O - UNITED: I-ORG - NATIONS: I-ORG - : O - LINDA: I-PER - THOMAS-GREENFIELD: I-PER 右下角有Georgia Tech的标志。</sample>
    <sample id="351">CoNLL++ Dataset Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines Fine-tuned 20+ models on CoNLL-2003 Evaluated on CoNLL-2003 test set &amp; CoNLL++ AMBASSADOR O TO THE NATIONS : LINDA THOMAS-GREENFIELD I-PER I-ORG I-PER</sample>
    <sample id="352">CoNLL++ Dataset</sample>
    <sample id="353">What Is Needed for Good Generalization?</sample>
    <sample id="354">What Is Needed for Good Generalization?</sample>
    <sample id="355">将英文内容翻译成中文。</sample>
    <sample id="356">图片中的文字内容包括： 1. 标题：What Is Needed for Good Generalization? 2. 列表项： - Model architecture - Transformer models generalize better - Model size - Larger models generalize better - Number of fine-tuning examples - More examples leads to better generalization 3. 图表： - X轴标签：Percentage of Training Examples - Y轴标签：AUC (%) - 数据点：RoBERTa 和 Flair - 数据点趋势：RoBERTa 的 AUC 值在不同训练示例百分比下保持相对稳定，而 Flair 的 AUC 值随着训练示例百分比的增加而略有上升。 4. 底部标志：Georgia Tech</sample>
    <sample id="357">What Causes Performance Drop?</sample>
    <sample id="358">幻灯片上显示的标题是“What Causes Performance Drop?”。</sample>
    <sample id="359">What Causes Performance Drop? Adaptive overfitting? Temporal drift?</sample>
    <sample id="360">图中的文字是“Temporal drift?”，意思是“时间漂移？”。</sample>
    <sample id="361">这幅图展示了一个幻灯片，标题是“是什么导致了性能下降？”。幻灯片上有两个主要点：“自适应过拟合？”和“时间漂移？”。在这些点的右侧，有一个图表，显示了不同数据点在性能指标上的分布。图表的横轴标记为“CoNLL 2003 F1得分”，纵轴标记为“平均F1得分”。图表中包含多个数据点，每个数据点都用不同的颜色和标签表示。在幻灯片的左下角，有一个Georgia Tech的标志。</sample>
    <sample id="362">What Causes Performance Drop? Adaptive overfitting? No diminishing returns Not observed Temporal drift?</sample>
    <sample id="363">Temporal drift是指模型在时间上的性能变化。随着时间的推移，模型可能会因为数据分布的变化、环境条件的变化等原因而导致其性能下降。这种现象在机器学习和深度学习中是一个常见的问题，特别是在处理时间序列数据或在线学习场景时。为了应对Temporal drift，通常需要定期更新模型参数，或者使用在线学习算法来适应新的数据分布。</sample>
    <sample id="364">图片中的表格列出了不同模型在2003年和2013年的CoNLL-2003分数以及它们在2013年和2017年的CoNLL++分数。每个模型的性能变化用ΔF1 (%)表示，显示了从2003年到2013年和从2013年到2017年的性能变化百分比。</sample>
    <sample id="365">这证实了我们关于性能下降的主要原因的假设，即时间漂移。</sample>
    <sample id="366">所有结论是，对于良好的泛化，我们需要：更好的模型架构、更大的模型大小以及更多的微调示例。这些目标手牵手，我们不能只有一种成分，而是需要所有的其他成分。</sample>
    <sample id="367">将英文内容翻译成中文。

为了取得良好的泛化能力，我们需要：
- 更好的模型架构
- 较大的模型尺寸
- 更精细的示例

性能下降是由：
- 时间漂移
- 并非自适应过拟合</sample>
    <sample id="368">根据图片中的内容，结论部分提到了以下几点： 1. 要实现良好的泛化，我们需要： - 更好的模型架构 - 更大的模型大小 - 更精细的示例。 2. 性能下降的原因包括： - 时间漂移 - 不适配过拟合。 3. 讨论了在2023年CoNLL-2003标签器是否仍然有效的问题。 最终，结论是肯定的，即CoNLL-2003标签器在2023年仍然有效。</sample>
    <sample id="369">为了更好地泛化，我们需要： - 更好的模型架构 - 更大的模型尺寸 - 更多的精炼示例 性能下降是由： - 时间漂移 - 过拟合 不适应过拟合</sample>
    <sample id="370">画面中背景是一栋建筑物，前景有一些人。画面左下角有一个圆形的头像。画面上有蓝色的文字，内容包括一个论文链接、一个数据集链接和一个联系邮箱地址。右下角有一个Georgia Tech的标志。</sample>
    <sample id="397">The method uses 16-second voice clips.</sample>
    <sample id="398">The specific knowledge required includes the fact that Servin is a judge.</sample>
    <sample id="399">According to the given image, example quality is more important than similarity to source sentence.</sample>
    <sample id="400">论文侧重于新闻媒体和社交媒体的预训练数据。</sample>
    <sample id="401">该模型是使用特定层的注意力分数。</sample>
    <sample id="402">直接推断的示例包括： “easy on me,” “the first one” 和 “The newer one.”</sample>
    <sample id="403">这篇论文的作者所属机构是复旦大学和Brain Technologies Inc。</sample>
    <sample id="404">The paper has 6 authors. Their names are Yanis Labrak, Adrien Bazege, Richard Dufour, Michael Rouvier, Emmanuel Morin, and Beatrice Daille.</sample>
    <sample id="405">是的，在语义解析之前，使用机器翻译模型翻译自然语言查询作为基线。</sample>
    <sample id="406">作者给出的“显性群体”的示例是“woman warrior”。</sample>
    <sample id="407">Transformer models generalize better.</sample>
    <sample id="408">测试数据集的名称是“WSL approaches benefit from more clean validation samples!”</sample>
    <sample id="409">这篇论文有6位作者。</sample>
    <sample id="410">作者采用了多种模态。</sample>
    <sample id="439">作者认为，NLU 中研究不足的领域包括：1. 预训练知识（pre-train time knowledge）2. 推断时间知识（inference time knowledge）</sample>
    <sample id="440">演讲者的名字是Zhiyang Xu、Ying Shen和Lifu Huang。</sample>
    <sample id="441">Yes, Coscript underwent quality checks. The slide mentions that 55,000 scripts were generated with constraints based on symbolic knowledge distillation and then filtered using InstructGPT with a constraint score to ensure the quality of validation and test sites.</sample>
    <sample id="442">现有的资源对依赖上下文的翻译的局限性包括： 1. 只有小部分单词依赖于上下文。 2. 现有的方法支持有限的讨论现象和语言。 这些限制表明，虽然存在一些资源来评估上下文依赖的翻译，但它们在涵盖的上下文范围和涉及的语言方面都存在局限性。</sample>
    <sample id="443">Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus) Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti, and Annie Louis Google Research</sample>
    <sample id="444">这张图片展示了一张幻灯片，标题为“通过AltEntities语料库解决间接指代表达式进行实体选择”。作者包括Mohammad Javad Hosseini、Filip Radlinski、Silvia Pareti和Annie Louis。左下角有Google Research的标志。背景是白色的，有一些彩色的线条和圆圈，形成一个抽象的设计。右下角有一个小的圆形图像，显示了一个戴眼镜的人。</sample>
    <sample id="445">Indirect referring expressions are used to understand users' language when they make a choice.</sample>
    <sample id="446">Indirect Referring Expressions</sample>
    <sample id="447">这张幻灯片讨论了间接引用表达。它的目标是理解用户在做出选择时的语言。它将间接引用分为两种类型：直接引用和间接引用。直接引用的例子包括“easy on me”和“the first one”。另一方面，间接引用可以用于自然流畅的对话中，例如当用户无法记住歌曲名称或想要指定偏好时。间接引用的例子包括“The newer one”和“The song that’s not energetic”。幻灯片上还显示了一个名为“Google Research”的标志，并且有一个小图像，可能是一个演讲者的照片。</sample>
    <sample id="448">Indirect referring expressions could be used in natural and fluid conversation.</sample>
    <sample id="449">Indirect Referring Expressions</sample>
    <sample id="450">这是对话系统和用于评估大型语言模型实体理解的基准的重要问题。</sample>
    <sample id="451">Dataset Collection</sample>
    <sample id="452">数据集收集方法强调使用卡通完成任务来强调非正式性。</sample>
    <sample id="453">画面中展示了一张来自Google Research的幻灯片，标题为“Dataset Collection Methodology”。主要内容是关于使用卡通完成任务来强调非正式性的方法。画面中有一个黄色的箭头指向一个文本框，上面写着“由注释员填写”。在卡通中，有三个人物，他们的对话框被标记为“设置对话上下文（从每个领域选择几个手动提示）”、“另一个问题”和“指代实体之一的表达”。右下角有一个小圆形图像，显示了一个戴眼镜的人的部分脸。</sample>
    <sample id="454">在第二张图片中的对话气泡中，Alice说：“你是指‘easy on me’还是‘I got a feeling’？”</sample>
    <sample id="455">The alternative question is 'Do you mean "Easy on Me" or 1 Gotta Feeling?'</sample>
    <sample id="456">Dataset Collection Methodology</sample>
    <sample id="457">The second one, which is the alternative question, is generated as follows.</sample>
    <sample id="458">图片中的文字内容包括：

标题：Generate alternative questions =&gt; sampling entity pairs

副标题：Do you mean A or B?

正文：
- Items with similar infoboxes on Wikipedia (same genre and/or artist)
  - Do you mean This is it or Man in the Mirror?
- Items with similar descriptions on Wikipedia
  - Do you mean Thinking of You or Happy Anywhere?
- Items with similar titles:
  - Do you mean The Return (memoir) or The Return (Shatner novel)?
- Uniform at random:
  - Do you mean You Could Be Mine or The Way I Am

右下角有一个小圆形头像，旁边有文字“Research Inducing Expressions for Entity Selection Utilizing Corpora”。

左上角有一个黄色箭头，上面写着“More Similar (likely harder)”。</sample>
    <sample id="459">生成替代问题 =&gt; 生成实体对</sample>
    <sample id="460">The first form is uniform at random.</sample>
    <sample id="461">生成替代问题 =&gt; 生成实体对 Do you mean A or B?</sample>
    <sample id="462">幻灯片包含一个标题“Generate alternative questions =&gt; sampling entity pairs”，以及一个副标题“Do you mean A or B?”。主要内容包括以下几点： 1. 使用相似信息框在维基百科上的项目（同一流派和/或艺术家）。 2. 使用相似描述在维基百科上的项目。 3. 具有相似标题的项目，如“The Return (memoir)”和“The Return (Shatner novel)”。 4. 随机选择的统一项目，如“You Could Be Mine”和“The Way I Am”。 幻灯片左侧有一个黄色箭头，上面写着“More Similar (usually harder)”。右下角有一个小图像。右上角显示了Google Research的标志。</sample>
    <sample id="463">幻灯片上显示了一个名为“Background knowledge (Music)”的标题。在标题下方，有一个关于谷歌搜索链接到每首歌的说明。然后列出了两首歌曲：“Easy on Me”（由Adele演唱）和“I Gotta Feeling”（由The Black Eyed Peas演唱）。每个歌曲名称旁边都有一个蓝色的超链接，写着“点击这里了解这首歌”。在这些链接下方，有一段文字写着“我们要求注释者： 1. 听至少一首歌 2. 阅读每首歌”。右下角有一个小圆形图像，显示了一个人的脸部特写。左下角有一行小字，写着“Revising Indirect Referring Expressions for Entity Selection (Autumnal Corpse)”。右上角有Google Research的标志。</sample>
    <sample id="464">幻灯片的标题是“Background knowledge (Music)”。</sample>
    <sample id="465">Google搜索结果显示了“Easy on Me”的官方视频。</sample>
    <sample id="466">背景知识（食谱） Simnel蛋糕 Pandan蛋糕 Simnel蛋糕是一种水果蛋糕，广泛食用于英国、爱尔兰和其他有移民历史的国家，与复活节和逾越节相关联。它由杏仁酱或马斯卡彭奶酪层叠而成，并且使用相同的糖浆。 Pandan蛋糕是一种轻盈、蓬松的绿色海绵蛋糕，带有Pandanus amaryllifolius叶子的汁液风味。这种蛋糕在印度尼西亚、马来西亚和荷兰特别受欢迎，尤其是在印度社区中。</sample>
    <sample id="467">画面中有一个名为“Google Research”的标志。</sample>
    <sample id="468">画面中的文字内容包括： 1. 标题：'Eliciting expressions' 2. 副标题：'We then tell the annotators which choice should be selected and ask them to describe it.' 3. 指示：'Pick one this' 和 'I Gotta Feeling (by the Black Eyed Peas)' 4. 提示：'We would like you to give us 3 to 5 expressions for the chosen song to fill in your speech bubble. For example:' 5. 示例表达： 'The one with the piano music', 'The song that's not energetic', 'It has something about a river', 'The nearest one', 'It is not having time to choose' 6. 标题：'Random Examples' 7. 类别标签：'Music Selection', 'Book Selection', 'Recipe Selection' 8. 示例类别内容： - Music Selection: 'Do you mean 'Chime' or 'Your Loving Arms'?' 和 'The one without words' - Book Selection: 'Warlock (Half-novella) or Warlock (Smith novel)' 和 'The one that is set in the 1980s' - Recipe Selection: 'Beurre Maile de H' 和 'The Japanese steamed cake' 9. 底部文字：'Revising Indirect Referring Expressions for Entity Selection (Abeltonia Collection)' 10. Google Research标志。</sample>
    <sample id="469">AltEntities Corpus contains approximately 6,000 alternative questions across three domains and around 42,000 indirect referring expressions. The results with the T5 XL model show that accuracy ranges from 92-95% when the LM has access to the same background knowledge as annotators, down to 82-87% when there is only partial overlap in background knowledge. When the LM (T5 XL) has no direct access to entity names, accuracy drops to about 60%. It's noted that these models are domain-generalizable. A dataset link provided for more information: https://github.com/google-research/datasets/AltEntities</sample>
    <sample id="470">这段文字讨论了T5 XL模型在处理不同背景知识时的准确性。具体来说，它指出： 1. 当语言模型（LM）具有与注释员相同的背景知识时，其准确率在92%-95%之间。 2. 当LM具有部分重叠的背景知识时，其准确率在82%-87%之间。 3. 当LM仅具有实体名称访问权限时，其准确率下降到60%。 这些结果表明，模型的准确性随着背景知识的差异而变化。此外，文本还提到这些模型是“domain-generalizable”的，并提供了一个数据集链接用于参考。</sample>
    <sample id="471">图片中的英文内容翻译成中文如下： 1. AltEntities语料库 - 约6000个不同领域的替代问题 - 约42000个间接表达的引用 2. T5 XL模型结果（准确率）： - 如果语言模型能够访问与注释员相同的背景知识，准确率为92-95%。 - 如果语言模型只能访问部分重叠的背景知识，准确率为82-87%。 - 当T5 XL模型只能访问实体名称时，准确率为60%。 - 我们展示了模型是通用化的。 3. 数据集链接：https://github.com/google-research/datasets/AltEntities</sample>
    <sample id="472">画面中有一个感谢信息，内容是'Thank You!'。此外，还有一个联系邮箱'javadh@google.com'，用于回答问题。</sample>
    <sample id="473">该方法与 popular strategies also applied to offline models 进行了比较。</sample>
    <sample id="474">The authors of this paper are affiliated with several institutions, including: 1. LIA, Avignon Université 2. LSIN, Nantes Université 3. Clinique des diabétiques de CHU de Nantes 4. Zenidoc These affiliations indicate that the research was conducted in collaboration between these different universities and clinical centers located in France.</sample>
    <sample id="475">演讲者的名字是Jenny T. Liang。</sample>
    <sample id="476">这篇论文有三位作者。</sample>
    <sample id="477">图片中的文字内容包括：

1. 标题：Attention as a Guide for Simultaneous Speech Translation
2. 作者：Sara Papi, Matteo Negri, Marco Turchi
3. 机构标志和名称：
   - UNIVERSITÀ DI TRENTO
   - FONDAZIONE BRUNO KESSLER

这些信息表明这是一篇关于同时口译翻译中注意力作为指南的研究论文，由来自特伦托大学和布鲁诺·凯塞尔基金会的三位作者共同撰写。</sample>
    <sample id="478">Simultaneous speech translation is the process of translating spoken language into text in another language in real-time, enabling cross-language communication.</sample>
    <sample id="479">What are the problems of the current SimulST models?</sample>
    <sample id="480">幻灯片上显示了“当前SimulST模型的问题”这一标题。它提到了两个主要问题： 1. 特定的架构通常被训练，引入额外的模块进行优化。 2. 长而复杂的训练程序（例如，不同的优化目标）。 这些内容以文本形式呈现，并配有相应的图标。左下角有一个蓝色和白色的标志，右下角显示第6页。</sample>
    <sample id="481">What are the problems of the current SimuIST models? Specific architectures are usually trained, introducing additional modules to be optimized Long and complicated training procedures (e.g., different optimization objectives) Training and maintaining several models to reach different latency regimes (e.g., 1s, 2s,...)</sample>
    <sample id="482">What is our solution?</sample>
    <sample id="483">幻灯片显示了一个带有蓝色背景和白色文字的标题为“What is our solution?”。左侧有两个编号点：01和02。 01. 使用现有的离线ST模型，无需重新训练或采用特定架构用于SimulST。 02. 只使用一个模型来处理每个延迟制度，并通过特定参数处理延迟。 在右上角，有一个小窗口显示一个人在讲话。左下角有一个标志，右下角显示“page 09”。</sample>
    <sample id="484">What is our solution? 01 Use already existing offline ST models without re-training or adopting specific architecture for SimuIST. 02 Use only one model for every latency regime and handle latency through specific parameters. 03 Leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output that is the cross-attention mechanism. And you can see an example on the right</sample>
    <sample id="485">幻灯片介绍了“Encoder-Decoder Attention”的概念。它解释了在注意力机制中，当注意力不集中（其和低于阈值α）时，会发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="486">这段文字讨论了在编码-解码注意力机制中决定是否进行部分翻译的问题。它指出，如果注意力没有集中在某个词上（即其和低于阈值α），则会发出一个词。这表明接收的信息足够稳定。</sample>
    <sample id="487">显示的文本是“我们的模型预测了德语翻译”。</sample>
    <sample id="488">解决方案：EDAtt</sample>
    <sample id="489">图片中的英文内容翻译成中文为： 我们将看到，前两个词指向最早收到的语音帧，而最后一个词指向最后一个收到的语音帧。</sample>
    <sample id="490">这意味着前两个单词将被省略。</sample>
    <sample id="491">幻灯片上显示了一个标题为“我们的解决方案：EDAtt”的部分。主要内容是关于编码器-解码器注意力机制的解释，具体来说是关于何时发出单词或不发出部分翻译。它提到，如果注意力点的总和低于阈值α，则会发出单词，这意味着接收到的信息足够稳定。此外，还有一个示例句子“Ich werde reden”及其对应的英文翻译“EMITTED”，并附有一个音波图来说明注意力机制。</sample>
    <sample id="492">幻灯片展示了编码器-解码器注意力机制。它解释了模型如何决定是否发射或不发射部分转换，基于注意点：如果发射的总和低于阈值，意味着接收到的信息足够稳定。</sample>
    <sample id="493">幻灯片上显示了一段英文内容，内容是：“Decide whether to emit or not a partial translation based on where attention points to: if a word is emitted, it means that the attention is not concentrated (its sum is below a threshold) towards the last λ speech frames, meaning that the received information is enough stable.”</sample>
    <sample id="494">我们的解决方案是：EDAtt。</sample>
    <sample id="495">如果查看EdAtt的主要结果，会发现它在BLEU分数上表现良好。</sample>
    <sample id="496">在幻灯片上，有一个标题写着“Main Results: EDAtt”。标题下方是一个空白的图表。图表的横轴标记为“AL/AL_CA (s)”，纵轴标记为“BLEU”。在图表的左下角，有一个标签写着“quality measure”。在图表的右下角，有一个标签写着“latency measure”。幻灯片的右上角显示了一个视频通话窗口，其中一个人正在讲话。幻灯片的左下角有一个蓝色的标志。幻灯片的右下角显示了页码“page 028”。</sample>
    <sample id="497">画面中的文字内容包括：

1. 左上角的标题：Main Results: EDAtt
2. 右上角的蓝色问号和表情符号：¿?⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫️⚫</sample>
    <sample id="498">这张幻灯片展示了一个名为EDAtt的主要结果。它包含一个柱状图，显示了BLEU分数与AL/AL_CA（秒）之间的关系。图表的横轴标记为“AL/AL_CA（秒）”，纵轴标记为“BLEU”。柱状图显示了一个高值，约为27。在图表上方，有一些蓝色的符号和字符，包括问号和其他符号。在右上角，有一个小窗口显示一个人。幻灯片底部左角有一个蓝色的标志，底部右角显示页码“page 031”。</sample>
    <sample id="499">主要结果：EDAtt</sample>
    <sample id="500">画面中的文字包括标题“Main Results: EDAtt”和副标题“state of the art architecture specifically tailored for SimultSimST”。此外，还有一个图表，X轴标记为“AL/AL_CA (s)”，Y轴标记为“BLEU”。图表中显示了不同策略的比较，包括“wait-k”、“LA”、“CAAT”和“EDAtt”。页面底部右下角标有页码“page 033”。</sample>
    <sample id="501">Main Results: EDAtt</sample>
    <sample id="502">画面中的文字内容包括： 1. 主要结果：EDAtt 2. 图表标题：(a) en→de 3. 图表图例：wait-k, LA, CAAT, EDAtt 4. 蓝色框内的文字：EDAtt在所有应用于离线模型的策略中表现最佳 5. 页面底部的文字：page 036</sample>
    <sample id="503">这张图片展示了一个演示文稿中的幻灯片，标题为“Main Results: EDAtt”。幻灯片上有一个图表，显示了不同策略在翻译任务中的表现。图表的X轴表示“AL/CAAT（秒）”，Y轴表示“BLEU分数”。图例中列出了四种策略：wait-k、LA、CAAT和EDAtt。每种策略都用不同的颜色标记，如黄色、蓝色、绿色和红色。

幻灯片右侧有一个蓝色框，上面写着“如果考虑实际耗时，EDAtt是最快的策略”。幻灯片底部右角标有页码“页面037”。

此外，幻灯片左下角有一个小图标，看起来像是一个蓝色的气泡，里面有一个白色的符号。幻灯片右上角有一张人物照片，但没有提供任何额外的信息。</sample>
    <sample id="504">幻灯片上有一个二维码，旁边写着“扫描我！”</sample>
    <sample id="505">Yes, the data set is public.</sample>
    <sample id="506">MULTIINSTRUCT: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning Zhiyang Xu*, Ying Shen*, Lifu Huang Department of Computer Science, Virginia Tech *Equal Contribution</sample>
    <sample id="507">图片中的文字内容翻译如下： 1. 图片顶部的文字是“预训练语言模型用于下游任务”。 2. 图片底部的文字是“图2：比较调优与微调以及提示的差异”。 3. 图片左下角的文字是“图像来源：Wei, Jason等。'预训练语言模型是零样本学习者。'”。</sample>
    <sample id="508">幻灯片的标题是“预训练语言模型用于下游任务”。</sample>
    <sample id="509">画面中有一段文字，内容是“Language-only”。</sample>
    <sample id="510">Instruction Tuning on Multimodal Pre-trained Models</sample>
    <sample id="511">画面中有一段文字，内容是“Imbalance in Instructional Datasets between NLP and Multimodal”。这段文字说明了在自然语言处理（NLP）和多模态数据集之间存在不平衡的问题。背景是黑色的，文字是白色的，非常醒目。画面右下角有一个小窗口，显示了一个穿着深色外套的人。</sample>
    <sample id="512">幻灯片上有一个标题，写着“NLP和多模态之间的指令数据集不平衡”。下面有一行文字，写着“1600多个语言-only指令任务”。在下方，有一行文字写着“没有大规模、公开可用的多模态指令任务”，其中“NO”用红色大写字母突出显示。在左下角，有一段小字，写着“Wang, Yizhong, 等人. “通过上下文指令对1600多个语言任务进行基准测试：arXiv预印 arXiv”。</sample>
    <sample id="513">MULTINSTRUCT The first multimodal instruction tuning benchmark dataset 62 diverse multimodal tasks 10 broad groups 5 expert-written instructions</sample>
    <sample id="514">MULTINSTRUCT
The first multimodal instruction tuning benchmark dataset

62 diverse multimodal tasks
10 broad groups
5 expert-written instructions

Figure 2: Task Groups Included in MULTINSTRUCT. The yellow boxes represent tasks used for evaluation, while the white ones indicate training sets.

Visual Relationship (VR)
VQA (Visual Question Answering)
Temporal Ordering (TO)
Grounded Object Manipulation (GOM)
Grounded Grounding (GG)
Grounded Caption Generation (GC)
Grounded Caption Evaluation (GCE)
Grounded Object Recognition (GOR)
Grounded Object Segmentation (GOS)
Grounded Object Detection (GOD)
Grounded Object Tracking (GOT)

Image Understanding (IU)
Image Text Understanding (ITU)
Image Text Classification (ITC)
Image Text Generation (ITG)
Image Text Matching (ITM)
Image Text Retrieval (ITR)
Image Text Comparison (ITC)
Image Text Generation and Retrieval (ITGR)
Image Text Classification and Retrieval (ITCR)
Image Text Comparison and Retrieval (ITCR)

Region Understanding (RU)
Image Understanding (IU)
Image Text Understanding (ITU)
Image Understanding and Text Understanding (IUTU)
Image Text Understanding and Retrieval (ITUR)
Image Text Classification and Retrieval (ITCR)</sample>
    <sample id="515">OFA (One For All) is a unified multi-modal pre-trained model capable of performing both understanding and generation tasks with single or multiple modalities. It has a unified vocabulary for language, image tokens, and the coordinates of a bounding box.</sample>
    <sample id="516">图1展示了来自MultiInstruct数据集的四个任务示例。</sample>
    <sample id="517">图1显示了从MULTINSTRUCT中提取的四个任务示例。</sample>
    <sample id="518">图1展示了来自MULTINSTRUCT的四个任务示例。</sample>
    <sample id="519">这段英文内容是“Multi-modal Instruction Tuning”，翻译成中文是“多模态指令调优”。</sample>
    <sample id="520">幻灯片上有一个标题，写着“Multi-Modal Instruction Turning”。在标题下面有两个部分：训练数据集构建和测试数据集构建。对于训练数据集构建，它提到使用9组中的53个任务进行训练，并从每个任务中抽取10,000个实例。对于测试数据集构建，它提到保留整个常识推理组用于测试，并从VQA和杂项组中选择额外的5个任务。此外，它还提到为每个任务使用测试分割中的所有实例，并随机从测试分割中的Natural Instructions数据集中抽取20个任务作为NLP的未见任务。</sample>
    <sample id="521">图片中的文字是：Multi-Modal Instruction Turning Training Dataset Construction: Use 53 tasks from 9 groups for training. Sample 10,000 instances per task. Testing Dataset Construction: Reserve the entire Commonsense Reasoning group for testing. Select additional 5 tasks from VQA and Miscellaneous groups. We use all the instances in the test split for each task. Randomly sample 20 tasks from the test split of Natural Instructions dataset as unseen tasks for NLP.</sample>
    <sample id="522">Implementation Details Training details: Pre-trained OFA-Large model (472M) Mix all the instances for all tasks. Each instance is randomly combined with one of its five instruction templates. Testing details: For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment. We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="523">幻灯片展示了关于实施细节的信息。它包括训练和测试的详细信息。在训练部分，提到了使用预训练的OFA大型模型（472M）以及将所有实例混合用于所有任务。此外，每个实例都是随机与其中的一个指令模板组合在一起。在测试部分，描述了对于每个任务，进行总共五次实验，通过使用每个任务中的一个指令来评估模型。还报告了五个实验中性能的平均值、最大值以及标准偏差。</sample>
    <sample id="524">Implementation Details Training details: Pre-trained OFA-Large model (472M) Mix all the instances for all tasks. Each instance is randomly combined with one of its five instruction templates. Testing details: For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment. We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="525">图片中的英文内容翻译成中文如下： 评估指标 多模态分类任务（视觉蕴含、视觉空间推理、自然语言视觉推理和灾难类型分类）的准确率。 多模态生成任务（常识VQA、文本VQA、地面VQA、视觉文本提取和视觉对话）的Rouge-L。 对于NLP任务，我们报告Rouge-L。 我们还计算每个模型在所有多模态和NLP未见任务上的综合性能。 我们使用Rouge-L作为大多数任务的性能评分，而Accuracy仅作为指标。</sample>
    <sample id="526">幻灯片介绍了模型对同一任务的多种指令的敏感性。它强调了模型在不同措辞下保持一致性的能力，以产生相同的结果。</sample>
    <sample id="527">Effectiveness of Instruction Tuning on MULTIINSTRUCT</sample>
    <sample id="528">将英文内容翻译成中文。</sample>
    <sample id="529">Here we can see as the amount of task increases, the model achieves better performance and in the meantime a lower sensitivity.</sample>
    <sample id="530">图片中的文字内容包括：

标题：Effect of Diverse Instructions on Instruction Tuning

副标题：OFA finetuned on 5 instructions achieves much higher aggregated performance on all evaluation tasks and shows lower sensitivity.

表格标题：Table 3: Effect of Different Number of Instructions. Performance of OFA-Mainfinst finetuned on different numbers of instructions.

表格内容：
- # of Instructions: 1 Instruction, 5 Instructions
- Aggregated Performance: 42.81, 47.82
- Sensitivity: 24.62, 10.45

这些内容表明，使用5个指令进行微调的模型在所有评估任务中表现更好，并且具有较低的敏感性。</sample>
    <sample id="531">图片中的英文内容翻译成中文如下： 1. 调优策略对模型敏感度的影响。 2. 在 Multinstruct 上进行调优可以显著降低 OFA 的敏感度。 3. 从 Natural Instructions 数据集进行迁移学习还可以进一步降低模型的敏感度。 图片下方的文字显示了一个图表，标题为“图 4：在未见评估任务中对模型敏感度的影响。较低的值表示更好。” 图表显示了不同调优策略对模型敏感度的影响，其中 OFA（原始）具有最高的敏感度，为 40.58。其他策略包括 OFA-Multinstruct、OFA-Segstruct 和 OFA-Adstruct，它们的敏感度分别为 13.84、10.45 和 10.27。</sample>
    <sample id="532">Zero-Shot Performance on NLP Tasks Instruction Tuning on Multinstruct can improve zero-shot performance on unseen NLP tasks. The transfer learning strategy MixedInstruct can best preserve the zero-shot capability gained on Natural Instructions dataset. Table 4: Zero-Shot Performance on NLP Tasks. The report is performed in Rouge-L and the best performance is in bold.</sample>
    <sample id="533">幻灯片上的文字内容如下：

Conclusion
- First large-scale multi-modal instruction tuning dataset.
  - Contains 62 multi-modal tasks from 10 broad categories.
- Significantly improve the zero-shot capability of OFA via instruction tuning.
- Explore several transferring learning techniques and show their benefits.
- Design a new metric sensitivity.

右下角有一个小窗口显示一个人的图像。</sample>
    <sample id="534">画面中的文字内容包括：

标题：One More Thing!

正文：
We are collecting a much larger multimodal instruction tuning dataset with around 150 additional vision-language tasks and we will release them soon!

此外，还有一个二维码和一个穿着浅色上衣的人的图像。</sample>
    <sample id="535">The authors of this paper are affiliated with the University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="536">演讲者的名字是Mohammad Javad Hosseini。</sample>
    <sample id="562">图片中的文字内容包括： 1. "Language model acceptability judgements are not always robust to context" 这是图片的主要标题，位于左侧。 2. "ACL 2023" 这是标题下方的文字，表示会议或活动的名称和年份。 3. "Kousuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Mira, Keren Fuentes, Roger Levy, Adi Williams" 这些名字位于图片底部，可能是演讲者或作者的名单。 4. 图片右侧有三所大学的标志： - 约翰霍普金斯大学 - 布拉德福德大学 - 麻省理工学院 (MIT) 5. 图片右下角有一个标志，上面写着“Meta AI”。</sample>
    <sample id="563">这张图片展示了一篇关于语言模型可接受性判断的研究论文的封面。标题为“Language model acceptability judgements are not always robust to context”，表明该研究探讨了语言模型在不同语境下的可接受性判断是否具有鲁棒性的问题。封面还标注了会议名称“ACL 2023”，表示这篇论文是在2023年的人工智能和计算语言学协会会议上提交的。此外，图片中列出了参与这项研究的作者：Koustuv Sinha、Jon Gauthier、Aaron Mueller、Kanishka Mishra、Keren Fuentes、Roger Levy和Adina Williams。这些作者分别来自约翰霍普金斯大学、普渡大学和麻省理工学院（MIT），展示了合作研究的跨机构性质。</sample>
    <sample id="564">在这项工作中，我们重新审视了最小对偶范式。</sample>
    <sample id="565">幻灯片的标题是“重新审视最小对范式”。</sample>
    <sample id="566">Revisiting Minimal Pair Paradigm</sample>
    <sample id="567">Revisiting Minimal Pair Paradigm</sample>
    <sample id="568">Revisiting Minimal Pair Paradigm</sample>
    <sample id="569">Revisiting Minimal Pair Paradigm</sample>
    <sample id="570">Revisiting Minimal Pair Paradigm</sample>
    <sample id="571">Approach Test whether MPP judgements as a function of context length, structural match, and acceptability GPT2, OPT family - 125M to 6.7B</sample>
    <sample id="572">这张图片展示了一个名为“Approach”的演示幻灯片。幻灯片的左上角有一个标题，写着“Approach”。在标题下方，有一段英文文本，内容是：“测试MPP判断是否取决于上下文长度、结构匹配和可接受性。” 在这段文本的左侧，有一个图表，展示了“Space of Candidate Prefixes”（候选前缀空间）。图表中包括了两个部分：一个是标记为“Build A”的部分，另一个是标记为“Mechanized”的部分。在图表的右侧，有两个句子被标注为“Acceptable, Matched”，分别是：“What might Jessica have said before noticing the spotlights? What had Aaron seen?” 和 “What could Jessica have noticed before seeing the museum? What would she notice if there were no museums?” 图表底部有一行文字，写着“GPT2, OPT family - 125M to 6.7B”。右下角有一个名字叫“BLIMP, Island”的标签。</sample>
    <sample id="573">Approach Test whether MPP judgements as a function of context length, structural match, and acceptability</sample>
    <sample id="574">Approach Test whether MPP judgements as a function of context length, structural match, and acceptability</sample>
    <sample id="575">测试模型的可接受性。</sample>
    <sample id="576">Approach Test whether MPP judgements as a function of context length, structural match, and acceptability</sample>
    <sample id="577">Approach Test whether MPP judgements as a function of context length, structural match, and acceptability</sample>
    <sample id="578">最后，我们可以从完全无关的领域中选择句子，例如维基百科。</sample>
    <sample id="579">Approach Test whether MPP judgements as a function of context length, structural match, and acceptability</sample>
    <sample id="580">Approach Test whether MPP judgements as a function of context length, structural match, and acceptability Wikipedia, Unrelated</sample>
    <sample id="581">MPP judgements are robust for arbitrary context lengths.</sample>
    <sample id="582">MPP判断在任意上下文长度下是稳健的。</sample>
    <sample id="583">现在，当我们在同一个数据集中选择句子时会发生什么？</sample>
    <sample id="584">将英文内容翻译成中文。 这里我们有选择或创建句子，从可接受和不可接受的领域中选择，使用相同的BLIMP或Syntactic Gym数据集。</sample>
    <sample id="585">可接受/不可接受的MPP句子在语境中会影响判断性能。</sample>
    <sample id="586">图中的文字内容包括： 1. 标题：可接受/不可接受的MPP句子，具有匹配结构，对模型性能影响最大。 2. 副标题：我们在不同的上下文中进行评估——可接受/不可接受；长度可达900个标记的匹配/不匹配结构。 3. 图表标签：BLIMP, OPT 6.7B。 4. 图表轴标签：前缀策略（X轴），BLIMP（0.2），Wiki（0.15），Unseen（0.1），Acc.（0.05）。 5. 图表数据点：各种曲线上的数字值，表示不同策略下的性能。 6. 句子示例： - "What could Jessica do before selling the house? Had she also sold her car?" - "What should Jessica have done before cleaning the dishes?" - "Jessica had cleaned the kitchen for Rose this morning." - "What could these sentences be used to test the model's ability to understand context before returning this customer?" 这些句子用于测试模型在理解上下文方面的表现。</sample>
    <sample id="587">图片中的文本内容包括： 1. 标题：Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance 2. 副标题：We perform MPP evaluations with different contexts – acceptable/unacceptable; matched/mismatched structure – of lengths up to 900 tokens 3. 图表标签：BLIMP, OPT 6.7B，Prefix Strategy，Unmatched，Unacceptable，Wiki，Unacceptable 4. 图示问题： - What could Jessica sell before Rachel noticed the museum was closing? - What had Jessica said about her friend’s new spotlights? - What would Jessica do after cleaning the museum? - What should Jessica be able to see from this return customer? - What could Jessica sell these days for less than $50? - What did Jessica notice in the museum when she returned from this customer? - What should Jessica learn from this return customer? 5. 图表中的数字标记：3, 2, 1</sample>
    <sample id="588">可接受/不可接受的MPP句子，具有匹配结构，最严重地影响模型性能。</sample>
    <sample id="589">为什么匹配前缀会影响语言模型的判断？ 我们通过保留句子的相关结构来干扰上下文句子，并问模型是否对这些句子敏感。 - 前缀/后缀副词：“然而，&lt;sent&gt;。” - 长前缀副词：“首先，&lt;sent&gt;。” - 添加子句：“无论X认为什么，&lt;sent&gt;。” - 引用：“昨天，X说，&lt;sent&gt;。”</sample>
    <sample id="590">图中的文字内容包括： 1. 标题：Why do matched prefixes affect LM judgements? 2. 副标题：We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences. 3. 列表项： - Prefix/suffix adverbs: “However, &lt;sent&gt;.” - Long prefix adverbs: “First and foremost, &lt;sent&gt;.” - Add clause: “Regardless of what X thinks about it, &lt;sent&gt;.” - Quote: “Yesterday, X said, &lt;sent&gt;.” 4. 图表：图表显示了不同类型的扰动（None、Prefix/suffix adv、Long prefix adv、Add clause、Quote、All、Acceptable和Unacceptable）对输入长度的影响。</sample>
    <sample id="591">图中的文字内容包括： 1. 标题：为什么匹配前缀会影响LM的判断？ 2. 副标题：我们通过保留结构的方式扰动句子，并问这些句子是否对模型敏感。 3. 示例句子： - 同时/后缀副词：“同样，&lt;sent&gt;。” - 长副词：“首先和第一，&lt;sent&gt;。” - 句子插入：“无论X认为什么，&lt;sent&gt;。” - 引用：“昨天，X说，&lt;sent&gt;。” 4. 图表：图表显示了不同类型的前缀（无、前缀/后缀副词、长副词、句子插入、所有）在输入长度变化时的Δ准确性。图表还区分了可接受和不可接受的前缀类型。</sample>
    <sample id="592">为什么匹配的前缀会影响LM判断？</sample>
    <sample id="593">图片中的文字内容包括： 1. 标题：Why do matched prefixes affect LM judgements? 2. 副标题：We perturb context sentences in ways that preserve the structure, and ask whether models are similarly sensitive to these sentences. 3. 具体例子： - Prefix/suffix adverbs: “However, &lt;sent&gt;.” - Long adverbs: “First and foremost, &lt;sent&gt;.” - Add clause: “Regardless of what X thinks about it, &lt;sent&gt;.” - Quote: “Yesterday, X said, ‘&lt;sent&gt;.’” 4. 图表标题：Mode is sensitive to perturbed sentences in all domains. 5. 图表轴标签：- 横轴：Input Length（范围从0到600）- 纵轴：Δ Accuracy（范围从-0.5到0.5） 6. 图表图例： - Perturbation：None、Prefix/suffix adv、Long adv、Add clause、Allise、Acceptable、Unacceptable。</sample>
    <sample id="594">关键要点是，语言模型对句子间共享的潜在句法/语义特征敏感。MPP评估在短、单句输入上无法充分捕捉LM的抽象知识。</sample>
    <sample id="595">幻灯片上的英文内容翻译成中文如下： 1. 语言模型对潜在的句法/语义特征在句子之间共享非常敏感。 2. MPP 评估使用短、单句输入无法完全捕捉 LM 的抽象知识。</sample>
    <sample id="596">关键要点： 1. 语言模型对句子中共享的潜在句法/语义特征敏感。 2. MPP评估使用短的、单个句子输入无法充分捕捉LMs的抽象示例。</sample>
    <sample id="597">该方法的第一步将输入词元映射到标记。</sample>
    <sample id="598">Coscript中包含55,000个脚本。</sample>
    <sample id="626">DEplain 的最佳对齐方法是使用 CATS-G3C。</sample>
    <sample id="627">Weak supervision alleviates the annotation bottleneck.</sample>
    <sample id="628">DEplain-web 中的文档采用手动和自动对齐方法进行了对齐。具体分配情况如下： 1. 手动对齐：用于 DEPLAIN-APA test (n=48) 和 DEPLAIN-APA train (n=48)。 2. 自动对齐：用于 DEPLAIN-APA baseline, DEPLAIN-APA BLEU, DEPLAIN-APA F1 和 DEPLAIN-APA PRE。</sample>
    <sample id="629">CoNLL++ 数据集是通过收集2020年的Reuters新闻，并使用CoNLL-2003注释指南对其进行注释来创建的。</sample>
    <sample id="630">The image is a presentation slide with the title 'XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations'. Below the title, there are three names listed as authors or contributors to this work. The logos of Penn State University and Amazon are displayed at the bottom left corner of the slide. In the top right corner, there is an inset video window showing a person speaking into a microphone against a background that appears to be outdoors during sunset or sunrise.</sample>
    <sample id="631">Semantic Parsing 是一项任务，旨在构建用户查询的语义表示，例如 SQL 和 Lambda Calculus。</sample>
    <sample id="632">Cross-lingual Semantic Parsing Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations. English German Chinese Neural Models SQL Lambda FunQL</sample>
    <sample id="633">Cross-lingual Semantic Parsing Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations English German Chinese Neural Models SQL Lambda FunQL</sample>
    <sample id="634">现有的跨语言语义解析模型在有限的任务和应用数据集上被提出和评估。例如：缺乏对某些自然语言的覆盖。</sample>
    <sample id="635">这张幻灯片介绍了跨语言语义解析（Cross-lingual Semantic Parsing）。它指出，现有的CLSP模型主要是在有限的任务和应用数据集上提出的和评估的。例如，存在对某些自然语言表示覆盖不足的问题。幻灯片中展示了三种语言：英语、德语和中文，并通过一个箭头指向神经模型，表明这些语言被用于训练或评估神经模型。此外，幻灯片还提到了三个数据库或查询语言：SQL、Lambda和FunQL。</sample>
    <sample id="636">现有的跨语言语义解析模型主要是在有限的任务和应用数据集上提出和评估的。例如：某些意义表示的覆盖不足。</sample>
    <sample id="637">现有的跨语言语义解析模型主要是在有限任务和应用的语料库上提出和评估的。例如： λ 漏掉了某些意义表示</sample>
    <sample id="638">Cross-lingual Semantic Parsing Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance: Lack of coverage on certain neural model English German Chinese SQL Lambda FunQL</sample>
    <sample id="639">XSemPLR</sample>
    <sample id="640">XSemPLR</sample>
    <sample id="641">实验设置 我们考虑了六个用于训练和评估的设置。 Translate-Test: 使用 Google 翻译 API 将源语言翻译成目标语言，然后使用单一语言模型进行训练和评估。</sample>
    <sample id="642">实验设置 We consider the six settings for training and evaluation.</sample>
    <sample id="643">图片中的英文内容翻译成中文如下：

实验设置
我们考虑了训练和评估的六个设置。
Translate-Test：使用Google Translate API将源语言翻译为目标语言。然后使用单语模型进行训练和评估。

训练
English -&gt; English Model -&gt; SQL

推理
German -&gt; Translate API -&gt; English -&gt; English Model -&gt; SQL</sample>
    <sample id="644">实验设置 We consider the six settings for training and evaluation. Monolingual Model: Source language is the same as target language, e.g., German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.</sample>
    <sample id="645">实验设置</sample>
    <sample id="646">实验设置  我们考虑了六种训练和评估的设置。 单语模型：源语言与目标语言相同，例如德语到德语。我们还测试了单语少量设置，通过仅使用10%的训练数据来训练单语模型。 训练 推断</sample>
    <sample id="647">幻灯片展示了实验设置，重点是训练和评估的六个设置。其中一个设置是多语言模型，它涉及为所有语言训练一个单一的多语言模型。该幻灯片包含一个图表，显示了训练过程，其中包含三种语言（德语、英语和中文），这些语言通过一个箭头指向多语言模型，然后指向SQL。同样，在推理部分，德语和多语言模型被表示为指向SQL。</sample>
    <sample id="648">幻灯片显示了一个实验设置，重点是训练和评估的六个设置。它特别强调了多语言模型，指出需要为所有语言训练一个单一的多语言模型。</sample>
    <sample id="649">实验设置 We 考虑了六种训练和评估的设置。 多语言模型：为所有语言训练一个单一的多语言模型。</sample>
    <sample id="650">实验设置 We 考虑了六种用于训练和评估的设置。 Cross-lingual Zero-shot/Few-shot transfer. 我们在一种源语言上进行训练，然后转移到另一种语言。</sample>
    <sample id="651">幻灯片展示了实验设置，包括六个用于训练和评估的设置。其中一个特定的设置是“跨语言零-shot/少-shot迁移”，它涉及在一种源语言上进行训练，并将模型转移到另一种语言。图中显示了两种训练方法：一种是在英语和德语查询的组合上进行训练，另一种是在少量德语查询上进行训练。这两种方法都导致了一个多语言模型，该模型可以预测SQL输出。</sample>
    <sample id="652">在单语环境中，我们评估了两种模型组。</sample>
    <sample id="653">这张图片包含了一张幻灯片，标题为“Monolingual Setting下的模型分析”。它评估了两种模型组在单一语言环境中的表现。第一种是“ENC-PTR：多语种预训练编码器与基于指针的解码器”，包括XLM-R + PTR和mBERT + PTR。第二种是“ENC-Dec：多语种预训练编码器-解码器模型”，包括mBART和mT5。幻灯片底部显示了一个表格，列出了不同模型在各种基准测试（MATIS、MGEOQuery、MSpider、MOveright、MCWQ、MSchesa2QA、MTOP）上的得分以及平均得分。表格中突出显示了ENC-Dec模型在所有数据集上的最佳性能。</sample>
    <sample id="654">分析单语模型。</sample>
    <sample id="655">我们发现编码器-解码器模型在所有9个数据集上都表现最佳。</sample>
    <sample id="656">我们评估了mT5和XLM-R + PTR在多语言环境中的表现。通过在多种语言的混合环境中进行训练，可以显著提升Enc-Enc/PTR（mT5-XLM-R）的表现。</sample>
    <sample id="657">这张图片是一张幻灯片，标题为“多语言训练分析”。幻灯片上有一个表格和一些文本。文本部分提到：“我们在混合语言设置中评估了mT5和XLM-R + PTR。” 幻灯片还指出，“Enc-Decoder/Enc-PTR（mT5-XLM-R）可以通过在多种语言的混合中进行训练来改进。” 表格包含不同模型在各种任务上的表现数据，如MATIS、MGeoQuery、MSpider、MOveright、MSchema2QA、MTOP和Nai。每个任务都有相应的分数，表格底部有一个“平均”行，显示了这些分数的平均值。</sample>
    <sample id="658">Analysis of Multilingual Training</sample>
    <sample id="659">分析多语言训练</sample>
    <sample id="660">Cross-lingual Performance Gap</sample>
    <sample id="661">这张幻灯片展示了不同语言之间的性能差距。它使用了三种不同的线条来表示：蓝色线条代表跨语言少样本迁移，橙色线条代表跨语言零样本迁移，绿色线条代表单语环境。这些线条在不同的任务中表现不同，包括MTOP、Schema2QA、Overnight、NLMaps、MCWQ、Spider、ATIS和Geoquery等。</sample>
    <sample id="662">Cross-lingual Performance Gap green - orange for zero-shot setting, the cross-lingual transfer performance gap is significant blue - orange for few-shot setting, the transfer gap is shortened rapidly</sample>
    <sample id="663">好的，我看到幻灯片上写着“Other Results &amp; Findings (Section 4 in Paper)”。</sample>
    <sample id="664">将英文内容翻译成中文。</sample>
    <sample id="665">我们构建了XSemPLR，这是一个统一的跨语言语义解析基准，用于处理多种自然语言和意义表示。</sample>
    <sample id="666">欢迎访问我们的论文和代码！</sample>
    <sample id="667">现有的研究可以大致分为以下四类： 1. 基于水印的（watermark） 2. 词法上的（lexical） 3. 后门（backdoor） 4. 对抗性的（adversarial）</sample>
    <sample id="668">No, Codex or Bloom is not sufficient for CLSP.</sample>
    <sample id="695">该方法通过在训练中诱导排列，来处理排列的不确定性。</sample>
    <sample id="696">下游NLP模型的公平性可以通过评估模型在不同政治倾向的数据上的性能来定义。</sample>
    <sample id="697">The speaker's name is Yanis Labrak.</sample>
    <sample id="698">The speaker's name is Koustuv Sinha.</sample>
    <sample id="699">The speaker's name is Myra Cheng.</sample>
    <sample id="700">热带主义 (tropicalism) 在本文的背景下指的是对拉丁裔女性使用“充满活力”和“丰乳”的词语。</sample>
    <sample id="701">作者通过使用“文化”、“传统”、“骄傲”和“异国情调”等词汇来创建目标群体的人工描写。</sample>
    <sample id="702">本文中使用了P-CXMI来衡量语境使用情况。</sample>
    <sample id="703">DrBERT和ChuBERT的主要区别在于它们的训练数据集。DrBERT使用了NATOS数据集，而ChuBERT使用了临床数据。此外，DrBERT有两个版本：一个使用7GB的NATOS数据集，另一个使用4GB的NATOS数据集。ChuBERT也有两个版本：一个使用4GB的临床数据，另一个是混合使用4GB的临床数据和4GB的NATOS数据集。</sample>
    <sample id="751">The paper has three authors: Zhiyang Xu, Ying Shen, and Lifu Huang.</sample>
    <sample id="752">迭代迁移学习通过在每个迭代中更新模型，同时利用之前的数据和新数据来提高模型的性能。</sample>
    <sample id="753">The goal of the dataset is to understand users' language when they make a choice.</sample>
    <sample id="754">攻击者通过EaaS来提取模型参数，通过使用EaaS来提取模型参数。</sample>
    <sample id="755">这篇论文有三位作者。</sample>
    <sample id="756">There were 10 annotators used to create the initial dataset.</sample>
    <sample id="757">这篇论文的作者所属机构是华盛顿大学和卡内基梅隆大学。</sample>
    <sample id="758">“when the governor is on the left or absent” is an example of a sentence where the governing word (the governor) comes before the conjunct.</sample>
    <sample id="759">GPT-3</sample>
    <sample id="760">我们需要在整个上下文窗口中评估模型的可接受性，因为这些大型语言模型现在正在使用越来越长的上下文窗口。因此，评估模型的可接受性在整个上下文窗口中至关重要。</sample>
    <sample id="761">是的，多语言训练会导致表现下降。</sample>
    <sample id="762">No, the annotators do not know about these entities.</sample>
    <sample id="763">BLEU, METEOR, and ROUGE。</sample>
    <sample id="764">泛化中的回归会影响特定的 NER 类型。</sample>
    <sample id="765">NLP中的立场很重要，因为它可能会影响对文本的解释和分析。例如，在处理有毒评论时，不同的观点可能会导致不同的结果，如 Perspective API在检测毒性方面的敏感性。</sample>
    <sample id="766">像 BLOOM 这样的多语言 LLM 是采用适配器微调还是完整微调？</sample>
    <sample id="767">The model used for cold-start annotations is RoBERTA-base plus a classifier head.</sample>
    <sample id="768">The recent tests used to evaluate PaLM's capabilities include: 1. WMT-2023 2. GLUE 3. SQuAD 4. XNLI 5. MNLI 6. AGNews</sample>
    <sample id="769">The author proposed three recommendations.</sample>
    <sample id="770">提议的方法获得了13.9%的收益。</sample>
    <sample id="771">演讲者的名字是Shuheng Liu和Alan Ritter。</sample>
    <sample id="772">论文中的结果和数据集可以用作基准。</sample>
    <sample id="773">他们在论文中进行了五个较小模型的实验。</sample>
    <sample id="774">OFA模型被用作研究多模型指令调整的基础模型。</sample>
    <sample id="833">这篇论文的作者所属机构是Google。</sample>
    <sample id="834">The authors of this paper are affiliated with Stony Brook University.</sample>
    <sample id="835">论文分析了英语、西班牙语和德语。</sample>
    <sample id="836">演讲者的名字是Shangbin Feng。</sample>
    <sample id="837">在实验过程中研究了两个模型：一个是长段落模型，另一个是基于正常段落的长段落模型。</sample>
    <sample id="838">在 MultiInstruct 中使用的 62 个不同任务中，有 53 个任务用于训练目的。</sample>
    <sample id="839">The paper has three authors.</sample>
    <sample id="840">作者在实验中使用了以下数据集：AG News、MIND、SST2和Enron Spam。</sample>
    <sample id="876">NACHOS 是一个数据集，它包含了从网络上爬取的医疗相关数据。</sample>
    <sample id="877">David Vilarr Torres</sample>
    <sample id="878">提示策略对结果有重大影响。具体来说，选择句子的两个随机提示可以导致BLEURT得分的最大差异为40个点。这表明提示在翻译质量中的重要性。</sample>
    <sample id="879">The authors of this paper belong to Carnegie Mellon University's Language Technologies Institute.</sample>
    <sample id="880">5个由专家编写的指令是：1.我们正在收集一个更大的多模态指令调优数据集。2.该数据集包括大约150个额外的视觉语言任务。3.他们将很快发布这些内容。4.这是一个二维码，用于获取他们的数据和模型。5.谢谢大家。</sample>
    <sample id="881">作者建议使用来自多种来源的信息来测试模型。</sample>
    <sample id="882">这张图片展示了一张幻灯片，上面有一个Google标志和标题“Prompting PaLM for Translation: Assessing Strategies and Performance”。在标题下方，有六个人的名字：David Vil Torres、Markus Freitag、Colin Cherry、Jiaming Luo、Viresh Ratnakar和George Foster。在右上角，有一张海滩的照片，旁边有一个对话框，写着“Can you translate this for me, please?”，并配有一个笑脸表情符号。左下角显示了“ACL 2023”的字样。</sample>
    <sample id="883">幻灯片介绍了Pathways语言模型（PaLM），并提供了有关该模型的详细信息。</sample>
    <sample id="884">图片中的英文内容翻译成中文如下：

**PaLM: Pathways Language Model**

*Chowdery et al., 2022 arXiv:2204.02311*

*540B parameters.*  
*Trained on 780B tokens.*  
*Densely activated.*  
*6144 TPU v4 chips.*  
*SOTA in hundreds of LMU and Generation benchmarks.*

**图示内容：**

- **Question Answering**
- **Semantic Parsing**
- **Proverbs**
- **Arithmetic Code Completion**
- **General Knowledge**
- **Summarization**
- **Translation**
- **Common-Sense Reasoning**
- **Pattern Recognition**
- **Logical Inference Chains**
- **Dialogue**
- **Joke Explanations**
- **Physics Q&amp;A**
- **Language Understanding**

参数数量为540亿，训练数据量为780亿个标记。模型高度激活，使用了6144个TPU v4芯片。在数百个语言建模和生成基准测试中处于最先进的水平。

这些信息展示了PaLM语言模型的规模、训练数据以及其在各种自然语言处理任务中的应用。</sample>
    <sample id="885">将英文内容翻译成中文。</sample>
    <sample id="886">幻灯片上有一段英文内容，内容如下： 'Our contribution' 'First systematic study of LLM prompting for MT. Both for the candidate pool as well as selection strategy.' 'Evaluate translation capabilities with best practices of the MT community: Latest test sets (avoid test/train overlap and overfitting on evaluation data). Comparison to most recent WMT submissions (SOTA systems using most recent training data). SOTA MT metrics (better correlation with human judgements). Expert-based human evaluation (more robust than crowd workers). Recommendation for prompt selection strategies.'</sample>
    <sample id="887">&lt;no_answer&gt;</sample>
    <sample id="888">图片中的英文内容翻译成中文是： 我们的贡献 1. 首次系统性研究用于MT的LLM提示。 - 同时用于候选池和选择策略。 2. 评估MT社区的最佳实践的翻译能力。 - 最新的测试集（避免测试/训练重叠和在评估数据上过度拟合）。 - 与最近提交的WMT相比（SOTA系统使用最新的培训数据）。 - SOTA MT指标（更好地与人类判断相关）。 - 基于专家的人类评估（比群众工人更强大）。 3. 对于提示选择策略的建议。</sample>
    <sample id="889">图片中的文字内容包括：

1. Prompts have a big impact on translation quality
2. Select two random prompts for each sentence.
3. Compute BLEURT for each sentence-prompt pair.
4. The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point.
5. The difference can go up to 40 BLEURT points!

这些文字主要讨论了提示对翻译质量的影响，并提到了BLEURT计算和句子对之间的差异。</sample>
    <sample id="890">Prompts have a big impact on translation quality. Select two random prompts for each sentence. Compute BLEURT for each sentence-prompt pair. The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point. The difference can go up to 40 BLEURT points</sample>
    <sample id="891">Prompts have a big impact on translation quality.</sample>
    <sample id="892">图片中的文字内容包括一个标题“Example prompting for translation”和一个副标题“5-shot prompting”。在副标题下，有两段德语和英语的翻译。德语文本是：“Dort sieht man, wie sie von zwei Police-Officern in einem Streifenwagen gesetzt wird.” 英文翻译是：“He is being transported under the custody of two policemen on a bus from the jail.” 另一段德语文本是：“Ski-Legenden unter sich: Die Polizei war eingeschlossen, nachdem sie Beschwerden des Buros erhalten hatten。” 英文翻译是：“Police were called in after receiving complaints from the office。” 还有一段德语文本是：“Ein Passant alarmierte die Polizei, mit mehreren Streifen anruckte。”</sample>
    <sample id="893">图片中的英文内容是“Example prompting for translation”。</sample>
    <sample id="894">&lt;no_answer&gt;</sample>
    <sample id="895">&lt;no_answer&gt;</sample>
    <sample id="896">图片中的文字内容包括：

标题：Example prompting for translation

副标题：5-shot prompting

正文：
- German: Dort sieht man, wie von zwei Police-Officern in einem Streifenwagen gesetzt wird
  英文翻译：He is being transported under the custody of two policemen on a bus from the jail.

- German: Ski-Legenden unter sich; Die Polizei war eingeschlossen, nachdem sie Beschwerden des Buros erhalten hatten。
  英文翻译：Police were called in after receiving complaints from the office。

- German: Ein Passant alarmierte die Polizei, mit mehreren Streifen anruckte。
  英文翻译：English</sample>
    <sample id="897">实验结果表明，示例质量比与源句子的相似性更重要。</sample>
    <sample id="898">图片中的文字内容包括： 1. 标题：Experimental Results 2. 副标题：Insights from MQM: 3. 列出的要点： - Example quality is more important than similarity to source sentence. - Specialized SOTA systems have a substantial advantage. - PaLM close to Google Translate. - Fluency of PaLM comparable to SOTA. - Accuracy scores generally lower. - Dominated by "Accuracy/Omission". - "Style/Awkwad" generally lower for PaLM. 4. 左下角有一个Google的标志。</sample>
    <sample id="899">实验结果表明，与源句子的相似性比示例质量更重要。专有SOTA系统具有明显的优势。PaLM与Google Translate非常接近。</sample>
    <sample id="900">画面中的文字内容包括： 1. 标题：Experimental Results 2. 主要内容： - Example quality is more important than similarity to source sentence. - Specialized SOTA systems have a substantial advantage. - PaLM close to Google Translate. 3. Insights from MQM: - Fluency of PaLM comparable to SOTA. - Accuracy scores generally lower. - Dominated by "Accuracy/Omission". - "Style/Awkwad" generally lower for PaLM. 4. 左下角有一个Google的标志。</sample>
    <sample id="901">图片中的文字内容包括：

标题：Experimental Results

1. Example quality is more important than similarity to source sentence.
2. Specialized SOTA systems have a substantial advantage.
3. PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkwad" generally lower for PaLM.

左下角有一个Google的标志。</sample>
    <sample id="902">实验结果</sample>
    <sample id="903">图片中的文字内容包括：

标题：Experimental Results

1. Example quality is more important than similarity to source sentence.
2. Specialized SOTA systems have a substantial advantage.
3. PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkwad" generally lower for PaLM.

左下角有一个Google的标志。</sample>
    <sample id="904">图片中的文字内容包括以下几点：

1. 实验结果：
   - 例如质量比相似度到源句子更重要。
   - 专门的SOTA系统具有明显的优势。
   - PaLM与Google Translate相当。

2. 从MQM中获得的见解：
   - PaLM的流畅性与SOTA相当。
   - 准确度分数通常较低。
     - 主要由“准确性/遗漏”主导。
   - “风格/笨拙”通常对PaLM来说更低。</sample>
    <sample id="905">Experimental Results Example quality is more important than similarity to source sentence. Specialized SOTA systems have a substantial advantage. PaLM close to Google Translate. Insights from MQM: Fluency of PaLM comparable to SOTA. Accuracy scores generally lower. * Dominated by “Accuracy/Omission” * “Style/Awkwad” generally lower for PaLM.</sample>
    <sample id="906">画面中有一个彩色的词云，中心是用红色大字写的“thank you”。周围有许多其他语言中的“谢谢”字样，如“gracias”、“danke”、“merci”等。背景是白色的，右下角有一个小圆形图像，显示一个人的脸部。</sample>
    <sample id="907">The image contains text in both English and Chinese. The main title is "Weaker Than You Think: A Critical Look at Weakly Supervised Learning." Below the title, there are names of four individuals associated with different institutions: Saarland University, Amazon Alexa, and University of Vienna. At the bottom right corner, there is a logo for ACL 2023.</sample>
    <sample id="908">这是一项与小雨沈、Marius Mosbach、Andreas Stephan和Dietrich Klakow合作完成的联合工作。</sample>
    <sample id="909">Weak supervision alleviates the annotation bottleneck. But weak labels are noisy Weakly supervised learning (WSL) Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="910">这张幻灯片解释了为什么弱监督学习（WSL）是必要的。它指出，虽然弱监督缓解了注释瓶颈，但弱标签是有噪音的，并且会导致记忆噪声，从而损害泛化能力。然而，WSL允许训练在嘈杂数据上表现良好的模型。幻灯片强调，WSL涉及使用简单启发式规则、知识库或低质量的人力资源，如图中所示。</sample>
    <sample id="911">Weak supervision alleviates the annotation bottleneck. But weak labels are noisy Noise memorization harms generalization. Weakly supervised learning (WSL) Train models that generalize well despite being trained on noisy data. Weak labeling sources (e.g., heuristics, knowledge bases) Unlabeled data Weakly labeled data (e.g., crowd-sourced annotations or weakly supervised learning algorithms) are wrong</sample>
    <sample id="912">将英文内容翻译成中文。</sample>
    <sample id="913">为什么弱监督学习？ 弱监督缓解了注释瓶颈。 但弱标签是有噪音的！ 噪音记忆损害了泛化。 弱监督学习（WSL） 训练模型在有噪音的数据上表现良好，尽管它们是在有噪音的数据上进行训练的。 弱标签数据（例如启发式、知识库）无标签数据有噪音的标签数据（注释是错误的）</sample>
    <sample id="914">幻灯片包含以下内容： 1. 标题：'A common claim in recent WSL works'（最近WSL工作中的常见主张） 2. 声明：'We train models only on weakly supervised data and achieve an accuracy of XX%.'（我们仅在弱监督数据上训练模型，并达到XX%的准确率。） 3. 图像： - 左侧显示一个标有'Noisy weakly labeled training data'的数据库图标，旁边有一个红色箭头和一个绿色方块。 - 右侧显示一个标有'Cleanly labeled test data'的数据库图标。 4. 文本：- 'only'这个词被高亮显示为红色。 这张幻灯片似乎在讨论与弱监督学习（WSL）相关的常见主张，强调使用弱监督数据进行模型训练并达到特定准确率的想法。</sample>
    <sample id="915">将英文内容翻译成中文。</sample>
    <sample id="916">A common claim in recent WSL works is that people do assume that there is an additional clean validation set available for model selection.</sample>
    <sample id="917">幻灯片中有一张大象的图片。</sample>
    <sample id="918">幻灯片上显示了三个研究问题，每个问题都用RQ1、RQ2和RQ3标记。这些问题如下： 1. RQ1: 验证数据是否必要？ 2. RQ2: WSL方法需要多少干净的样本？ 3. RQ3: 如何更有效地利用可用的干净样本？ 这些问题是关于验证数据和WSL（Windows Subsystem for Linux）方法的效率的研究问题。</sample>
    <sample id="919">幻灯片显示了三个研究问题，每个问题都用一个大写字母的标题表示。这些问题是关于验证数据是否必要、WSL方法需要多少干净样本以及如何更有效地使用可用的干净样本。</sample>
    <sample id="920">图表显示了不同验证方法在各种模型上的相对性能提升情况。横轴表示不同的模型，包括FTw、BOND、COSINE、MLC和L2R。纵轴表示相对性能提升百分比。图中有三条线，分别代表使用弱标签进行验证（橙色）、不进行验证（紫色）和使用干净标签进行验证（绿色）。每条线上的点表示不同实验中的数据点，显示了每个模型在不同验证方法下的性能提升情况。</sample>
    <sample id="921">图表显示了不同验证方法在各种模型上的相对性能提升。</sample>
    <sample id="922">图表显示了在不同验证方法下，模型性能的相对改进百分比。</sample>
    <sample id="923">这张图片展示了一个标题为“Main findings”的图表。图表的横轴上标有FTw、BOND、COSINE、MLC和L2R五个标签，纵轴表示相对性能提升百分比（%）。图表中有三条线，分别代表三种不同的验证方法：1. 橙色点表示“Validation on Weak Labels”（弱标签验证）。2. 紫色点表示“No Validation (Random Selection)”（无验证（随机选择））。3. 绿色点表示“Validation on Clean Labels”（干净标签验证）。每条线上的数据点显示了在不同验证方法下，相对性能提升的百分比变化。整体来看，绿色点（干净标签验证）显示出最高的性能提升，其次是橙色点（弱标签验证），而紫色点（无验证）则显示出最低的性能提升。</sample>
    <sample id="924">将英文内容翻译成中文。

图表展示了不同验证方法在不同模型上的相对性能表现。图例中，橙色表示“弱标签”验证，紫色表示“随机选择”无验证，绿色表示“干净标签”验证。横轴列出了不同的模型：FTw、BOND、COSINE、MLC和L2R。纵轴显示了相对性能相对于基准模型的百分比变化。

主要发现表明，干净标签验证集是必不可少的。</sample>
    <sample id="925">图表显示了不同方法在验证集上的准确性。X轴代表验证集的大小，从5到50，Y轴代表准确性，范围从75到85。图中有五条线，每条线代表不同的方法：FTw、COSINE、L2R、BOND和MLC。每条线都有一个不同的颜色，并且有阴影区域表示每个方法的准确性的变化范围。此外，还有一条虚线标记为“弱标签”，表示使用弱标签时的准确性水平。</sample>
    <sample id="926">RQ2 Main findings</sample>
    <sample id="927">将英文内容翻译成中文。</sample>
    <sample id="928">WSL approaches benefit from more clean validation samples</sample>
    <sample id="929">将英文内容翻译成中文。</sample>
    <sample id="930">将英文内容翻译成中文。</sample>
    <sample id="931">根据图片，主要发现如下： 1. 模型性能比较： - 图表显示了在CFT之前和之后的模型性能。 - 在两个图表中，都比较了四种方法：余弦相似度、L2归一化、仅使用干净样本和仅使用干净样本的CFT。 2. N=10和N=30的干净样本： - 左侧图表（N=10）显示了每类10个干净样本的情况。 - 右侧图表（N=30）显示了每类30个干净样本的情况。 3. 性能趋势： - 对于N=10的干净样本，余弦相似度（橙色线）在CFT后表现出显著的性能提升。 - L2归一化（红色线）也显示出改善，但不如余弦相似度。 - 仅使用干净样本（蓝色线）和仅使用干净样本的CFT（绿色线）在CFT后有轻微的性能提升。 4. 总体观察： - 余弦相似度在两种情况下都表现出最大的性能提升。 - L2归一化也有显著改进，但不如余弦相似度。 - 仅使用干净样本和仅使用干净样本的CFT在性能上没有显著差异。 这些发现表明，在给定数量的干净样本下，余弦相似度是提高模型性能的有效方法。</sample>
    <sample id="932">将英文内容翻译成中文。</sample>
    <sample id="933">Continuous fine-tuning (CFT) eliminates performance gaps between WSL approaches. No need to use complicated WSL methods, as WSL performs equally well.</sample>
    <sample id="934">这张幻灯片总结了最近WSL方法的一些要点。它指出，这些方法需要干净的样本，并且可能高估了它们的实用性。此外，它还提供了一些建议，包括报告模型选择标准、使用少样本学习方法作为基准，并始终应用连续微调（CFT）。</sample>
    <sample id="935">结论 Recent WSL 方法 需要干净的样本。他们高估了其可行性。 我们的建议 报告模型选择标准 使用少样本学习方法作为基准，始终应用连续微调（CFT）。</sample>
    <sample id="936">结论 Recent WSL方法 需要干净的样本。他们高估了其实用性。 我们的建议 报告模型选择标准 使用少样本学习方法作为基准。始终应用连续微调（CFT）。</sample>
    <sample id="937">幻灯片总结了关于WSL方法的最新进展和建议。它指出，WSL方法需要干净的数据样本，并且可能高估了它们的实用性。此外，它建议在报告模型选择标准时使用Few-shot学习方法作为基准，并始终应用连续微调（CFT）。</sample>
    <sample id="938">图片中的文字内容包括： 1. 标题：Conclusion Recent WSL approaches - Require clean samples. - Overestimate their practicality. Our recommendations - Report the model selection criteria. - Use Few-shot learning approaches as baselines. - Always apply continuous fine-tuning (CFT). 2. 图片右上角有一个“THANK YOU!”的气泡。 3. 图片右侧有一个二维码，旁边有文字说明“Please feel free to check it out. Thank you and enjoy the conference.” 4. 图片底部有数字“9”。</sample>
    <sample id="939">对话系统的常用评估方法是使用人类评估，例如通过要求人类裁判员选择两个对话中更好的一个或对对话进行评分。</sample>
    <sample id="940">这篇论文有5位作者。</sample>
    <sample id="941">Servin is a judge, and Kea is a baker.</sample>
    <sample id="942">Yes, the code is public. You can get it on GitHub at the link provided: https://github.com/mpoems/kitmus</sample>
    <sample id="943">The speaker states that the datasets and models are most aligned with people who have a college education.</sample>
    <sample id="944">In the image, there is a graph on the right side that shows how perturbations affect LM judgments. The x-axis represents 'Input Length,' and the y-axis represents 'Δ Accuracy.' Different lines represent different types of perturbations: 'None,' 'Prefix/suffix adv,' 'Long prefix adv,' 'Add clause,' 'All,' 'Quote,' and two categories labeled as 'Acceptable' and 'Unacceptable.'</sample>
    <sample id="945">维度评估意味着将对话质量分解为多个方面，以提供更全面的评估。</sample>
    <sample id="946">The authors of this paper are affiliated with the University of Science and Technology of China, Microsoft Research Asia, Beijing Jiaotong University, Sony AI, and Microsoft STC Asia.</sample>
    <sample id="947">提示的形式在几个情况下很重要：1. 在单个提示的情况下，提示的形式对翻译的准确性有重大影响。2. 在多个提示的情况下，提示的形式可能不太重要，因为上下文和提示之间的关系提供了足够的信息进行准确的翻译。3. 当使用五次提示时，提示的形式与实际提示形式几乎没有区别，表明在大量提示的情况下，提示的形式变得不那么关键。</sample>
    <sample id="978">The author evaluated the following models: BART-FID-RAG, Blender2, Emora, and Blender-Decode.</sample>
    <sample id="979">There are 9 authors in this paper.</sample>
    <sample id="980">优秀规划器的理想品质是：能够将抽象目标继承到不同具体的任务中，并且这些任务有复杂的约束条件。</sample>
    <sample id="981">The paper has 7 authors.</sample>
    <sample id="982">演讲者的名字是Vasudha Varadarajan。</sample>
    <sample id="983">这篇论文的作者所属机构是波兰科学院计算机科学研究所和华沙大学。</sample>
    <sample id="1021">PaLM最常见的错误是遗漏错误。</sample>
    <sample id="1022">图片中的文字内容包括： 1. 标题：'Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems' 2. 作者：'Sarah E. Finch, James D. Finch, and Jinho D. Choi' 3. 机构标志和名称： - Emory University - Emory NLP Research Lab - Amazon Alexa</sample>
    <sample id="1023">这幅图片展示了一个演示幻灯片，标题为“不要忘记你的ABC：在聊天导向的对话系统中评估最先进的技术”。作者是Sarah E. Finch、James D. Finch和Jinho D. Choi。幻灯片底部列出了Emory大学、Emory NLP研究实验室和Amazon Alexa的标志。</sample>
    <sample id="1024">这张图片展示了一个名为“Comparative Evaluation”的演示幻灯片。幻灯片的背景是白色的，顶部有一个蓝色和白色相间的标题栏，上面写着“Comparative Evaluation”。在标题栏的右侧，有一个小窗口显示了一个人，可能是演示者。幻灯片的主要内容包括两个对话框，每个对话框都有一个机器人图标和一些文本气泡。左侧的对话框有蓝色的气泡，右侧的对话框有紫色的气泡。在左下角，有Emory University和Alexa的标志。</sample>
    <sample id="1025">比较评估</sample>
    <sample id="1026">幻灯片介绍了对话质量的维度，包括相关性、一致性以及情感理解。</sample>
    <sample id="1027">图片中的英文内容翻译成中文是：'Likert Rating Evaluation'（利克特评分评价） 'Rate the relevance of the bot's responses'（对机器人的回答的相关性进行评分）</sample>
    <sample id="1028">Likert评分评估 Rate the relevance of the bot's responses</sample>
    <sample id="1029">幻灯片显示了“聊天中的行为注释（ABC-Eval）”的标题。它包含一个带有对话气泡和头像的图表，代表对话。每个对话气泡都指向一个标签：“无关”，“缺乏同理心”或“自我矛盾”。在右上角，有一个小窗口显示一个人。左下角有“埃默里大学”的标志，右下角有“alexa”的标志。</sample>
    <sample id="1030">Annotating Behaviors in Chat (ABC-Eval)</sample>
    <sample id="1031">ABC-Eval 行为 ABC-Eval 能够测量聊天模型在多大程度上会犯各种主题错误。</sample>
    <sample id="1032">幻灯片显示了一个名为“ABC-Eval行为”的框架。框架被分为四个部分：连贯性、知识、一致性、情感理解。在连贯性和一致性部分，有两个额外的框，分别标有“忽略伙伴”和“无关”。</sample>
    <sample id="1033">幻觉、自相矛盾或违反常识知识，以及当模型成功或失败时是否表现出同理心。</sample>
    <sample id="1034">幻灯片上有一个标题，写着“Experiments”，下面有两个项目符号。第一个项目符号写着“4 Open-Domain Dialogue Models”。第二个项目符号写着“100 Human-Bot Conversations per Model”。在这些项目符号的下方，有一个新的部分，标有“ABC-Eval”，并附有一个插图，显示一个人与一个对话模型互动的流程图。</sample>
    <sample id="1035">幻灯片显示了一个实验设置，包括4个开放领域对话模型和每个模型的100个人-机器人对话。在左下角有一个名为ABC-Eval的图表，展示了一个人与一个机器人之间的对话流程。右侧有两个评分系统：Turn Likert和Dialogue Likert，每个系统都有一个从1到5的评分标尺，并且在标尺上有一个勾选标记。在这些图表的右侧，有一个名为Comparative的部分，展示了多个对话流程，并在其中一个流程中标记了勾选。幻灯片顶部有一个标题“Experiments”，底部有Emory University和Alexa的标志。</sample>
    <sample id="1036">幻灯片展示了对聊天模型进行基准评估的实验。它包括了三种评估方法：'Turn Likert'、'Dialogue Likert'和'Comparative'。每种方法都通过图表和评分来表示，其中一些评分被勾选，表明它们是有效的或被考虑的。此外，还有六个评估维度列出：一致性、情感理解、信息丰富性、整体质量、吸引力、语法、主动性、相关性和相关性。这些维度可能用于衡量聊天模型的表现。幻灯片底部显示了埃默里大学和Alexa的标志，表明了参与或赞助该研究的机构。</sample>
    <sample id="1037">这张图片展示了一个名为“Inter-Annotator Agreement”的演示幻灯片。幻灯片顶部有一个标题，背景是蓝色的，上面用白色字体写着“Inter-Annotator Agreement”。在标题下方，有一张图表，显示了不同评估方法的Krippendorf's Alpha值。图表的x轴上标有“ABC-Eval”、“Turn Likert”、“Dialogue Likert”和“Comparative”等标签，y轴上标有从0到0.8的Krippendorf's Alpha值。每个标签下面都有多个数据点，表示不同子类别或条件下的Krippendorf's Alpha值。数据点用不同的颜色（橙色、红色和绿色）标记，并且有一些黄色箭头指向图表的不同部分，可能用来强调某些趋势或结果。幻灯片底部有两所大学的标志：佐治亚理工学院和亚特兰大大学。右下角有一个Alexa的标志。</sample>
    <sample id="1038">图表显示了预测有效性，比较了交互式问答（Interactive Qua）和交互式问答（Interactive Qua）在不同类别中的表现。每个类别都用一个条形图表示，其中灰色条形代表交互式问答，蓝色条形代表交互式问答。图表的横轴列出了不同的类别：ABC-Eval、Turn Likert、Dialogue Likert 和 Comparative。纵轴表示质量解释百分比（%），范围从0到0.1。每个类别的条形高度不同，表明不同方法在这些类别中的表现差异。图表底部有各种标签，如“其他”、“评论”、“问题”、“答案”等，可能对应于图表中使用的特定术语或短语。</sample>
    <sample id="1039">图表展示了预测有效性，比较了交互式评价和交互式量表在不同对话评估指标上的表现。</sample>
    <sample id="1040">这张图片展示了一张名为“增量有效性”的幻灯片，背景是蓝色的。在幻灯片顶部，有一个带有白色文字的深蓝色横幅，写着“增量有效性”。在右侧，有一个小框显示一个人的图像。在幻灯片的主要部分，有一个散点图，标题为“增量有效性”。图表显示了不同评估指标之间的关系，包括ABC-Eval、Turn UBERT和Dialogue UBERT。图表中的点代表各种评估指标，如Empathetic、Relevant、Proactive等。图表上标有“解释质量百分比（%）”的轴。在左下角，有Emory大学和Alexa的标志。</sample>
    <sample id="1041">图中展示了一个散点图，标题为“增量有效性”。图表的X轴分为三个部分：ABC-eval、Turn UBERT和Dialogue UBERT。Y轴表示“解释质量百分比（%）”，范围从0.075到0.375。图表上标有各种标签，如“Empathetic”、“Relevant”、“Proactive”等，每个标签都与特定的点相关联。这些标签似乎代表了不同类型的对话质量指标。在图表的右上角有一个黄色箭头指向一个特定的点，该点位于“Turn UBERT”部分。图表底部显示了“Emory University”的标志和“Alexa”的标志。</sample>
    <sample id="1042">这张幻灯片的标题是“增量有效性”。它展示了一个散点图，比较了ABC-Eval、Turn UBERT和Dialogue UBERT在解释质量方面的有效性。图表显示了不同特征（如Empathetic、Relevant、Engaging等）在这些评估方法中的表现。图表上有一些标记，表示特定特征的解释质量百分比。图表的背景是白色的，文字和线条主要是蓝色和黄色的。幻灯片底部有Emory大学和Alexa的标志。</sample>
    <sample id="1043">图表显示了不同模型在ABC-Eval中的错误率。图表的标题是“根据模型的ABC-Eval错误率”。横轴表示不同的错误类型，包括反社会、CS反对、忽略、错误、无关、冷漠、其他、冗余、自我反对和未解释。纵轴表示百分比的轮次（% of Turns）。每个错误类型都有多个柱状图，代表不同的模型：BART-FID-RAG、Blender2、Emora和Blender-Decode。每个模型的柱状图以不同的颜色表示。图表底部有Emory大学和Alexa的标志。</sample>
    <sample id="1044">图中展示了不同模型在ABC-Eval中的错误率。图表的标题是“根据模型的ABC-Eval错误率”。图表显示了几个类别，包括反社会、常识违反、忽略、不正确、冷漠、无关、冗余、自我违反和主题转换。每个类别都有多个条形图，代表不同的模型：BART-FID-RAG、Blender2、Emora和Blender-Decode。图表的横轴表示百分比，纵轴表示错误率。图中还包含一个黄色箭头，指向“常识违反”类别，表明该类别的错误率较高。</sample>
    <sample id="1045">图表显示了不同模型在ABC评估中的错误率。每个柱状图代表一个模型，而柱状图上的不同颜色表示不同的错误类型。错误类型包括反社会、CS相反、忽略、不正确、冷漠、其他相反、冗余、自我相反和话题转换。图表底部列出了用于评估的五个模型：BART-FID-RAG、Blender2、Emora和Blender-Decode。</sample>
    <sample id="1046">图表显示了不同模型在ABC-Eval中的错误率。这些模型包括BART-FID-RAG、Blender2、Emora和Blender-Decode。每个模型都针对不同的错误类型进行了评估，如反社会、CS相反、忽略、不正确、冷漠、无关、其他、冗余、自我、主题转换和未解释。图表以百分比表示每个错误类型的错误率。</sample>
    <sample id="1047">好的，我已经翻译好了。请看下面的文本内容： 1. ABC-Eval Error Rates by Model 2. Paper: https://arxiv.org/pdf/2212.09180.pdf 3. GitHub: https://github.com/emorynlp/ChatEvaluationPlatform 4. Contact Info: {sfillwo, jdfinch, jinho.choi} @ emory.edu 5. https://www.emorynlp.org</sample>
    <sample id="1048">The authors of this paper are affiliated with Emory University and the Emory NLP Research Lab.</sample>
    <sample id="1049">CFT stands for 'Continuous Fine-tuning.'</sample>
    <sample id="1050">这篇论文有8位作者。</sample>
    <sample id="1051">When Does Translation Require Context? A Data-driven, Multilingual Exploration</sample>
    <sample id="1052">翻译取决于上下文。</sample>
    <sample id="1053">画面中有一段文字，上面写着“Translation depends on context”。下面有一句话，“Things could start to get dangerous if the ministers find out. We'll have to get rid of that mole.” 另外，还有一个戴着帽子和眼镜的黑影人物在笔记本电脑上工作。</sample>
    <sample id="1054">翻译取决于上下文。</sample>
    <sample id="1055">幻灯片上有一个标题，写着“评估上下文相关的翻译很困难”。在标题下面，有一个项目符号，写着“只有很少一部分单词依赖于上下文”。在项目符号的右侧，有一张图片，显示了几份文件。在右上角，有一个小圆形图像。在项目符号下方，有一个子项目符号，写着“语料库级别的指标”，后面跟着一个蓝色的图标。</sample>
    <sample id="1056">Evaluating context-dependent translation is hard. Only a small portion of words depend on context. Corpus-level metrics Existing methods support limited discourse phenomena and languages.</sample>
    <sample id="1057">RQ1: When does translation require context? RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1058">RQ1: When does translation require context? - Word-level context usage RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1059">幻灯片介绍了条件互信息（Conditional Cross-Mutual Information，缩写为CXMI）。它描述了CXMI如何测量机器翻译模型在给定语料库时使用上下文的程度。幻灯片包含一个公式和一些文本，解释了CXMI是如何通过衡量上下文提供的关于目标Y的信息来评估机器翻译模型的上下文使用的。</sample>
    <sample id="1060">Conditional Cross-Mutual Information (CXMI) measures how much context machine translation models use given a corpus.</sample>
    <sample id="1061">Pointwise (P-)CXMI We introduce P-CXMI to measure context usage to translate a specific</sample>
    <sample id="1062">RQ1: 当翻译需要上下文时？ - 词汇级别的上下文使用 - 主题分析 RQ2: 模型在处理上下文相关的翻译时表现如何？</sample>
    <sample id="1063">画面中的文字内容包括： 1. 主题分析高P-CXMI单词。 2. TED IDEAS WORTH SPREADING（TED演讲的标志和口号）。 3. 多种语言列表，包括： - English (英语) - العربية (阿拉伯语) - Deutsch (德语) - Español (西班牙语) - Français (法语) - עברית (希伯来语) - Italiano (意大利语) - 日本語 (日语) - 한국어 (韩语) - Nederlands (荷兰语) - Português (葡萄牙语) - Română (罗马尼亚语) - Русский (俄语) - Türkçe (土耳其语) - 中文 (中文)</sample>
    <sample id="1064">Thematic analysis of high PCXML words 1. POS tags</sample>
    <sample id="1065">Thematic analysis of high P-CXMI words 1. POS tags P-CXMI for POS tags In-Ar PRON 3.Sing PRON 3.Dual PRON 3.Plur Pronouns</sample>
    <sample id="1066">幻灯片包含标题“高P-CXML单词的主题分析”。它有两个主要部分：1. POS标记2. 词汇项在每个部分右侧，有一个紫色框，里面写着“名词”和“动词形式”。在POS标记部分，有一个条形图，显示了En-Ar中POS标记的P-CXML值。条形图有三个类别：PRON_3_Sing（单数）、PRON_3_Dual（复数）和PRON_3_Plur（复数）。PRON_3_Dual类别的条形图是最高的。幻灯片右上角有一张人的照片。</sample>
    <sample id="1067">Thematic analysis of high P-CXML words</sample>
    <sample id="1068">主题分析高P-CXML单词 1. POS标记 2. 词汇项 Avelile的母亲仍在睡觉。阿维利尔的母亲还在睡觉。 Avelile去上学了。阿维利尔的母亲去了学校。 - 代词 - 动词形式 - 词汇连贯性 - 正式性</sample>
    <sample id="1069">Thematic analysis of high P-CXMI words 1. POS tags 2. Vocabulary items 3. Individual tokens Pronouns Verb form Lexical cohesion Formality Ellipsis</sample>
    <sample id="1070">研究问题1：翻译何时需要上下文？ - 单词级别的上下文使用 - 主题分析 研究问题2：模型在处理上下文相关的翻译时表现如何？ - 多语种语境感知（MuDA）基准</sample>
    <sample id="1071">幻灯片上有一个标题，写着“多语言话语感知（MuDA）标记器”。在标题下面，有一个紫色的矩形框，里面列出了五个项目：- 代词 - 动词形式 - 词汇连贯性 - 正式性 - 省略。这些项目是用黑色字体列出的。在右上角，有一张小图片。</sample>
    <sample id="1072">Multilingual Discourse-Aware (MuDA) tagger</sample>
    <sample id="1073">将英文内容翻译成中文。</sample>
    <sample id="1074">图片中的文字内容包括两个主要问题和一些子问题。 主要问题是： 1. RQ1: 当翻译需要上下文吗？ - 单词级别的上下文使用 - 题材分析 2. RQ2: 模型在处理上下文依赖的翻译方面表现如何？ - 多语种话语意识（MuDA）基准 - 模型评估</sample>
    <sample id="1075">幻灯片上有一个标题，写着“Corpus-level metrics”。在标题下方，有一个机器人图标，上面写着“BLEU”，并且有一个椭圆形的标记，里面写着“CONTEXT”。右上角有一个小圆形图像。</sample>
    <sample id="1076">幻灯片显示了三个机器人，每个机器人都代表不同的语料库指标。第一个机器人标有“BLEU”，第二个机器人标有“COMET”，第三个机器人标有“F-measure”。每个机器人的头部都有一个标签，上面写着“上下文”（context）。在右上角，有一个小圆形图像，可能是一个人的头像。背景是白色的，顶部有标题“语料库级别的指标”。</sample>
    <sample id="1077">Corpus-level metrics BLEU COMET F-measure Unclear which system is best for document-level MT with corpus-level metrics</sample>
    <sample id="1078">幻灯片介绍了MuDA基准测试的结果，强调了上下文感知模型在某些现象上的表现显著优于其他模型。具体来说，这些模型在形式性和词汇连贯性方面表现更好。</sample>
    <sample id="1079">幻灯片的标题是“MuDA基准结果”。主要内容是一个项目符号，上面写着“上下文感知模型在某些现象上表现显著更好”，下面有一个子项目符号，写着“正式性、词汇连贯性”并带有对勾，以及“省略号、代词、动词形式”并带有叉号。右上角有一张人物照片。</sample>
    <sample id="1080">MuDA benchmark results Context-aware models perform significantly better on some phenomena ✅: Formality, lexical cohesion ❌: Ellipsis, pronouns, verb form DeepL outperforms Google on most phenomena and language pairs* as of April 2021</sample>
    <sample id="1081">幻灯片显示了“MuDA基准结果”的总结。它指出，上下文感知模型在某些现象上表现得显著更好，例如形式、词汇连贯性（√），椭圆句式、动词形式（❌）。此外，DeepL在大多数现象和语言对上都优于谷歌。幻灯片包含一个流程图，展示了MuDA标记器、BLEU F-度量和机器人之间的关系。</sample>
    <sample id="1082">好的，我看到幻灯片上有一个标题“摘要”。有两个要点：1. 识别系统地无需先有语言知识的话语现象。2. 数据集无关的文档级机器翻译基准。在这些要点下方，有一个流程图，显示了几个步骤：- 一个标记器（MuDA tagger）- 一系列文件 - BLEU F度量 - 一个机器人图标。</sample>
    <sample id="1083">好的，让我们来翻译这段内容。首先，我们看到标题是“Summary”，意思是“总结”。接下来，有两个要点：

1. “Identify discourse phenomena systematically without prior linguistic knowledge” 这句话的意思是“系统地识别话语现象，无需先前的语言知识”。

2. “Dataset-agnostic benchmark for document-level MT” 这句话的意思是“数据集无关的文档级机器翻译基准”。

最后，我们看到一个流程图，显示了从文件到文档的处理过程，包括MuDA tagger和BLEU F-measure等步骤。

总结来说，这段内容主要介绍了如何在无需先前语言知识的情况下系统地识别话语现象，并提供了一个适用于文档级机器翻译的数据集无关的基准。</sample>
    <sample id="1084">演讲者的名字是Yusen Zhang。</sample>
    <sample id="1121">The new method does not have a specific name mentioned in the image.</sample>
    <sample id="1122">作者描述“显性词汇”方法是：找到区分标记组和未标记组的单词。</sample>
    <sample id="1123">The authors belong to the University of Washington and Carnegie Mellon University.</sample>
    <sample id="1124">第一个提到的对称依存关系结构的名称是“Bouquet/Stanford”。</sample>
    <sample id="1125">The speaker's name is Sarah E. Finch.</sample>
    <sample id="1126">这篇论文有5位作者。</sample>
    <sample id="1127">BLiMP, SyntaxGym, and Crows are the data sets that can be used to test sentence phenomena.</sample>
    <sample id="1161">The first research question's five methods are abbreviated as FTw, COSINE, BOND, MLC, and L2R.</sample>
    <sample id="1162">该模型在11个任务上进行了评估。</sample>
    <sample id="1226">CamemBERT was initially trained on 4GB of data.</sample>
    <sample id="1227">演讲者的名字是Adam Przepiórkowski和 Michał Woźniak。</sample>
    <sample id="1228">发现导致性能下降的主要原因是时间漂移，因为性能随着更大的时间间隔而下降。</sample>
    <sample id="1269">为了确保输出序列中的词元按照正确的顺序排列，需要对它们进行排列。</sample>
    <sample id="1270">作者建议模型所有者应提高偏见缓解方法的透明度，因为这些方法可能在潜移默化中强化了某些刻板印象。</sample>
    <sample id="1271">Minimal pair paradigm的最小对不可接受输入是“Many people were helping herself.”</sample>
    <sample id="1272">作者使用了以下评估指标：NLR、CRS、NER、CER、BIO、MISC、MED-CER、MED-NER。</sample>
    <sample id="1273">使用了Krippendorf's alpha来衡量注释者之间的一致性。</sample>
    <sample id="1274">选择维基百科领域来添加完全无关的句子。</sample>
    <sample id="1275">The authors of this paper are affiliated with Heinrich Heine University Düsseldorf in Germany.</sample>
    <sample id="1276">MultiInstruct focuses on instruction tuning for multimodal pre-trained models, addressing the imbalance in instructional datasets between NLP and multimodal tasks.</sample>
    <sample id="1277">The paper has three authors: Sarah E. Finch, James D. Finch, and Jinho D. Choi.</sample>
    <sample id="1278">二进制协调是指在二进制系统中，两个事件或信号同时发生的情况。</sample>
    <sample id="1279">在本研究中，提示语的平均长度是20个字符。</sample>
    <sample id="1280">这些发现表明，较小的T5模型在Coscript上进行微调后，可以生成比大多数大型语言模型质量更高的脚本。</sample>
    <sample id="1281">DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains</sample>
    <sample id="1282">幻灯片显示了一个总结，列出了四个主要部分。第一部分是“在医疗保健中进行语言建模”。第二部分是“预训练策略的比较、数据源和大小”。第三部分是“对13个模型在11项任务上的评估”。第四部分是“NACHOS和DrBERT的分布”。右上角有一个小窗口，显示了一个人。底部有一个红色条，上面写着“Avenion Université”，并带有一个标志。</sample>
    <sample id="1283">幻灯片显示了一个总结，列出了四个要点：1. 医疗保健中的语言建模2. 预训练策略、数据源和规模的比较3. 13个模型在11个任务上的评估4. NACHOS和DrBERT的分布</sample>
    <sample id="1284">幻灯片上有一个标题为“Summary”的部分。下面列出了四个主要点：1. 医疗保健中的语言建模2. 预训练策略、数据源和大小的比较3. 11个任务中13个模型的评估4. NACHOS和DrBERT的分布幻灯片底部有一个红色条，上面写着“Aveni Université”。</sample>
    <sample id="1285">幻灯片的标题是“Summary”。内容包括以下几点： 1. 医疗保健中的语言建模。 2. 预训练策略、数据源和大小的比较。 3. 在11个任务上评估13个模型。 4. NACHOS和DrBERT的分布。</sample>
    <sample id="1286">图片中的文本是“Avignon Université”。</sample>
    <sample id="1287">图片中的文本内容是关于语言建模的。它提到了Transformer-based方法，如BERT，在许多NLP任务中取得了巨大的性能提升。它还提到这些方法已经适应了法语，使用了CamemBERT和FlauBERT等模型。此外，它指出在医疗领域，特定领域的模型在英语中表现得更好，包括PudMedBERT、BioBERT、ClinicalBERT和其他模型。它还提到其他语言比英语更少见，并且主要依赖于预先训练来使用现有的通用模型。它还提到，目前还没有开源的生物医学领域模型可用，但BERT-based特定领域的模型对法语在医疗任务中的性能有帮助。</sample>
    <sample id="1288">专用于其他语言的模型较少，主要依赖于在现有通用模型上进行持续预训练。由于缺乏领域数据，这些模型较为罕见。</sample>
    <sample id="1289">Transformer-based approaches, such as BERT, offer huge performance gains on a lot of NLP tasks</sample>
    <sample id="1290">这张幻灯片展示了关于预训练策略和数据源的比较。它包括了两个主要部分： 1. 数据源的影响评估： - NACHOS：一个包含各种医学领域数据的开源数据集，大小为4GB，包含460万个样本。 - NBDW：一个包含170万份匿名医疗记录的私有数据集，大小为45MB。 2. 训练策略的比较： - 从头开始构建全模型：使用DeBERTa、RoBERTa和XLM-RoBERTa。 - 使用现有预训练模型进行持续预训练：使用CAMEBert（一个法语通用模型）和PubMedBERT（一个英文医学特定模型）。 这张幻灯片还提到了数据源对于各种用途的重要性，并讨论了爬虫数据是否可以作为临床数据的合适替代品。</sample>
    <sample id="1291">为了回答这个问题，我们将比较我们的ShuBERT模型与Dr.BERT模型。ShuBERT模型基于匿名化的数据，这些数据是从南特大学医院的数据仓库中获得的。</sample>
    <sample id="1292">图片中的文字内容包括：

标题：Comparison of pre-training strategies and data sources

副标题：
1. Evaluation of the impact of public and private medical data sources on comparable data sizes
2. Comparison of learning strategies

正文：
1. NACHOS: A 1.1B+ subword open-source dataset of heterogeneous data crawled from various medical domains, including 4 GB of medical images, 6 GB of medical tables, natures, and styles.
2. NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

表格内容：
- Corpus
  - Subword (subword)
    - Size: 4 GB
    - References: 25 M
  - Subword (ngram)
    - Size: 9 GB
    - References: 30 M
  - BERTsmall (ngram)
    - Size: 24 GB
    - References: 80 M
  - BERTlarge (ngram)
    - Size: 48 GB
    - References: 160 M

学习策略比较：
- From scratch with full model construction
- Continual pre-training using an existing pre-trained model (e.g., CamemBERT, a French generic model, and PubMedBERT, an English medical one)

底部信息：Avignon Université

这些内容主要介绍了不同数据源和预训练策略的比较，以及它们在医疗数据领域的应用。</sample>
    <sample id="1293">比较预训练策略和数据源</sample>
    <sample id="1294">图片中的英文内容已经翻译成中文。</sample>
    <sample id="1295">将英文内容翻译成中文。</sample>
    <sample id="1296">将英文内容翻译成中文。</sample>
    <sample id="1297">图片中的文字内容翻译如下：

标题：比较预训练策略和数据源

副标题：
1. 在可比数据大小上评估公共和私人医疗数据源的影响
2. 比较学习策略

正文：
- NACHOS：一个包含1.18B单词的开源数据集，从多个医学领域抓取了异构数据，包括自然语言处理、医学和风格。数据集大小为4GB，内存使用量为64MB。
- NBDW：一个包含1.7M个句子的私有数据集，来自南特大学医院的数据仓库，用于匿名化的医疗记录。数据集大小为25.3MB，内存使用量为450MB。

表格：
- 列表了不同模型的名称、策略、数据集和存储位置。
  - DeBERTaT：从头开始构建全模型
  - CamemBERT：使用现有的预训练模型（使用PubMedBERT，一个英语医学版本）
  - PubMedBERT：持续预训练
  - RoBERTa：持续预训练
  - XLM-RoBERTa：持续预训练

总结：
- 总共有7个模型。

图片右下角显示了“Avignon Université”的标志。</sample>
    <sample id="1298">图片中的英文内容翻译成中文如下：

评估：数据源和规模

- 对13个模型在7项任务上进行了性能评估，包括公共和私人数据。
- 我们训练的模型在几乎所有任务上都达到了最先进的水平。

表格中列出了不同模型在各种任务上的表现，包括：
- aIF
- Medical Report
- MUSCIA
- DISEASE
- METSA
- CAS
- Presymptomatic
- QUADRO-EMOA
- MEDLINE

每个模型在不同任务上的表现用不同的指标表示，如NCR、CLR、NCRS、CLR、POS、PSS等。</sample>
    <sample id="1299">表格中的数据包括13个模型在10个任务上的表现，包括公共和私人数据集。这些模型在几乎所有任务上都达到了最先进的结果。</sample>
    <sample id="1300">这张幻灯片展示了对13个模型在9个任务上的性能评估，包括公共和私人数据集。这些模型在几乎所有任务上都达到了最先进的结果。</sample>
    <sample id="1301">将英文内容翻译成中文。</sample>
    <sample id="1302">在总体上，从头开始预训练似乎比在4GB数据上进行持续预训练获得了更高的性能。</sample>
    <sample id="1303">这张图片展示了一张幻灯片，标题为“Evaluation: Pre-training strategies”。幻灯片上有一张表格和一些文字。表格列出了不同模型在各种任务上的表现，包括NER、CRF、SRL、CBP、MISC、MED-DET、CUSE、MED-SCT、MED-DET-POS和MED-DET-POS-POS。表格中还包括一个名为“QUAERUMEDQA”的项目。表格下方有几行数据，显示了不同模型在这些任务上的得分。幻灯片的左下角有一个橙色和黄色的标志，上面写着“Aix-Marseille Université”。幻灯片右上角有一个小窗口，显示了一个穿着黑色衣服的人。</sample>
    <sample id="1304">这段文字提到了在使用Kamembert权重和tokenizer时，模型会遭受稳定性问题。</sample>
    <sample id="1305">DrBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks. It surpasses Camembert's generic model and English-based domain-specific models, confirming the utility of training a medical-specific model in French.</sample>
    <sample id="1306">核心信息是：DrBERT在下游的9个法语医疗任务中实现了最先进的结果。它超越了CamemBERT的通用模型和基于英语的特定领域模型，并确认了在法语中训练医疗模型的实用性。数据来源很重要，训练异构数据很重要。NACHOS比仅使用私人临床数据更强大。更多的数据更好，但并不好扩展。基于特定英语模型的持续预训练是一种更有效的策略。DrBERT模型、NACHOS数据集和脚本文件在MIT许可下免费提供。</sample>
    <sample id="1307">DrBERT 实现了在 6 个下游法语医疗任务中的最先进的结果。它超越了 CamemBERT 的通用模型和基于英语的领域特定模型，并确认了在法语中训练医疗领域的模型的有效性。数据源至关重要：在异构数据上进行训练很重要。NACHOS 比仅使用私人临床数据更强大。更多的数据更好，但不具有可扩展性。基于域的英语模型的预训练是一种更有效的策略。DrBERT 模型、NACHOS 数据集和训练脚本在 MIT 许可下免费提供。</sample>
    <sample id="1308">感谢您的观看，期待在多伦多的海报展示中进行交流。</sample>
    <sample id="1309">论文研究了以下学习策略： 1. 从头开始构建模型。2. 预训练，使用现有的预训练模型（如CamemBert、French generic和PubMedBERT）。3. 持续预训练。</sample>
    <sample id="1310">由于测试重复使用而导致的过拟合因素非常大。</sample>
    <sample id="1311">The title of the document is 'Automatic Text Simplification'.</sample>
    <sample id="1312">是的，语言模型确实有不同的政治偏见。</sample>
    <sample id="1313">Compositional Generalization without Trees using Multiset Tagging and Latent Permutations</sample>
    <sample id="1314">这是一项与我的导师Alexander Koller和Ivan Titov合作完成的工作。</sample>
    <sample id="1315">Compositional Generalization</sample>
    <sample id="1316">Compositional Generalization in Semantic Parsing</sample>
    <sample id="1317">这些断言与表示其核心含义的逻辑形式配对。</sample>
    <sample id="1318">Compositional Generalization in Semantic Parsing</sample>
    <sample id="1319">在训练期间，模型看到了浅层递归。</sample>
    <sample id="1320">图片中的英文内容翻译成中文如下： 图片顶部显示标题“语义解析的组成性泛化”。 在“训练”部分，有三个句子：“她睡了。” “玛丽知道她睡了。” 和“吉姆说玛丽知道她睡了。” 在“测试”部分，有一个句子：“吉姆说玛丽知道她睡了。” 图片底部有一行文字写着“原始的序列到序列模型失败了！”</sample>
    <sample id="1321">Compositional Generalization in Semantic Parsing</sample>
    <sample id="1322">树木帮助了很多，但...</sample>
    <sample id="1323">树木帮助很多，但是...</sample>
    <sample id="1324">Trees help a lot but... Trees need to be obtained: - Pre/Post-processing logical forms</sample>
    <sample id="1325">图片中的文本内容包括：

标题：Trees help a lot but...

正文：
Trees need to be obtained:
- Pre/Post-processing logical forms

结构图：
- *girl x₁ sleep.agent x₂ x
- *girl x₄ x₁ sleep.agent x₂
- The girl slept.

这段文字讨论了树在处理逻辑形式时的帮助，特别是需要进行预处理和后处理。结构图展示了如何将“女孩睡觉了”分解为更简单的组件。</sample>
    <sample id="1326">树木帮助了很多，但... 从图片中可以看出，树木需要获得： - 预处理/后处理逻辑形式 - 语法归纳</sample>
    <sample id="1327">这张图片展示了一张幻灯片，上面有一个标题和一些文本内容。标题是“Trees help a lot but...”，用黄色高亮显示。标题下方有一个树状图，表示句子“The girl slept.”的结构。树状图中有两个分支，分别标记为“*girl x1”和“sleep.agent x2”。每个分支进一步分为两个部分：“*girl x1”分为“*girl x1”和“x1”，而“sleep.agent x2”分为“sleep.agent x2”和“x2”。在树状图下方，有两行文本：
- “Trees need to be obtained:”
- “- Pre-/post-processing logical forms”
- “- Grammar-induction”

在幻灯片底部，有一段红色框起来的文字：
“此论文提出了一种直接建模输入片段与输出片段之间对应关系的神经序列到序列模型。我们展示了在不使用树的情况下，对深层递归进行强烈泛化。”

幻灯片右下角标有数字4。</sample>
    <sample id="1328">树确实帮助了很多，但... 树需要满足以下几点： - 预处理和后处理逻辑形式 - 语法归纳 这篇论文介绍了一种直接在片段之间建立对应关系的神经 seq2seq 模型。我们首次展示了对更深层次递归的强泛化，而无需依赖于树。</sample>
    <sample id="1329">我们的方法在两步中从输入预测输出</sample>
    <sample id="1330">这张图片展示了一个名为"Our Approach"的方法。它包含一个流程图，显示了标记和输入标记的过程。流程图中有几个方框，每个方框内有不同的内容，并且有箭头指向一个标有“Tag”的部分。这个部分下面有一个标签，指向两个单词“the”和“girl”。</sample>
    <sample id="1331">在第一步之后，我们有所有正确的标记，但它们没有排序。</sample>
    <sample id="1332">Our Approach</sample>
    <sample id="1333">这张图片展示了一个名为“Our Approach”的流程图，主要描述了一种预测排列的方法。流程图中包含多个步骤和标签，如“Permute”和“Tag”。每个步骤都有箭头连接，表示数据的流动方向。流程图中的元素包括“girl”，“sleep agent”，“x1”，“the”，“girl”和“slept”等单词或短语，这些可能代表了在排列过程中使用的词汇或概念。整体布局清晰，展示了从初始输入到最终输出的过程。</sample>
    <sample id="1334">概念上，我们的置换模型大致如下：</sample>
    <sample id="1335">这张图片展示了一个名为“Permute”的过程，其目的是通过跳跃来重新排列标记。在顶部有一个标题写着“Permuting with 'jumps'”。在标题下方，有一个包含多个方块的区域，每个方块代表不同的单词或标记。这些方块被分为两组：一组是用黄色方块表示的标记（x1、girl、x1），另一组是用蓝色方块表示的标记（sleep、agent、x2）。在这些方块下方，有三个标记为“the”、“girl”和“slept”的单词，它们与上方的标记对应。整个布局显示了如何通过跳跃来重新排列这些标记的过程。</sample>
    <sample id="1336">这张图片展示了一个名为“Permut”的过程，其中包含一个标记为“Tag”的部分。在顶部，有一个黄色的框，里面写着“Permuting with 'jumps'”。在这个框下面，有两个绿色的方块和一个黄色的方块，它们被标记为“*”、“girl”和“x1”。这些方块通过一条红色的线连接到一个更大的方块中，这个方块包含了两个蓝色的方块和一个绿色的方块，它们分别标记为“sleep”、“agent”和“x2”。在底部，有三个标记为“the”、“girl”和“slept”的单词，它们与上方的方块通过箭头连接。</sample>
    <sample id="1337">图中展示了“跳动”排列的过程。顶部的黄色框标有“使用‘跳跃’排列”。在下面，有一个标记为“Permute”的灰色框，里面包含多个标记为“girl”和“x1”的黄色方块，以及一个标记为“*girl”的绿色方块。这些方块通过红色箭头连接到下方的标记为“the”、“girl”和“slept”的标记框。这些标记框位于另一个标记为“Tag”的灰色框内。整个过程显示了如何通过跳动到另一个标记框来排列标记。</sample>
    <sample id="1338">图中展示了一个名为“Permuting with 'jumps'”的过程。这个过程涉及将标记（如“girl”，“sleep”，“agent”等）进行重新排列，通过箭头和连接线来表示这些标记之间的关系。在图的底部，有标签“the”，“girl”和“slept”，这些标签可能代表了最终的输出或结果。整个图示展示了如何通过跳转的方式对标记进行重新排列，以达到特定的目的或效果。</sample>
    <sample id="1339">图表显示了Kim和Linzen在2020年对COGS的一些结果。它比较了无树模型在COGS上的结构化泛化能力。图表中包含四个类别：PP递归、CP递归、对象PP到子PP。每个类别都有多个柱状图，代表不同的模型：LSTM seq2seq、TS、Zheng和Lapata以及“我们的”方法。</sample>
    <sample id="1340">将英文内容翻译成中文。

Kim和Linzen2020在COGS上的某些结果

比较无树模型在COGS上结构化泛化方面的表现，包括： - 模型 - LSTM seq2seq - TS - Zheng和Lapata - 我们</sample>
    <sample id="1341">技术挑战我们解决</sample>
    <sample id="1342">图片中的文字内容包括标题、副标题和一些标签。标题是“Technical Challenges We Solve”（我们解决的技术挑战）。副标题是“Alignment unknown.”（对齐未知）。在图表中，有三个标签：'girl'、'sleep' 和 'agent'。这些标签被箭头指向一个标有“Permute”的部分，然后指向另一个标有“Tag”的部分。</sample>
    <sample id="1343">这张图片展示了一个技术挑战的解决方案。标题为“Technical Challenges We Solve”（我们解决的技术挑战）。图片中有一个流程图，展示了如何处理未知对齐的问题。流程图中有几个方框和箭头，表示数据的排列和标记过程。方框中的内容包括“girl”，“sleep”，“agent”，以及一些问号，表示未知元素。底部的文字说明了对齐未知的问题，并提到通过在训练过程中诱导对齐来解决这个问题。</sample>
    <sample id="1344">Technical Challenges We Solve</sample>
    <sample id="1345">这张图片展示了一个技术挑战的解决方案，具体来说是关于如何处理和优化排列问题。图片中有一个图表，展示了排列过程中的各种元素和它们之间的关系。图表中有标签“Permute”和“Tag”，并且有一些文字说明了排列未知的问题，并且在训练过程中进行诱导。此外，还提到了一个置换模型，其中推断是NP-hard（TSP），并且通过连续放松进行反向传播来学习更具有语言学合理性的排列。</sample>
    <sample id="1346">Technical Challenges We Solve Alignment unknown. ➔ Induce it in training. Permutation model: - Inference is NP-hard (= TSP) - Backpropagate through continuous relaxation Paper &amp; Code: https://tinyurl.com/mxX8ny</sample>
    <sample id="1347">Cognitive dissonance is two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent.</sample>
    <sample id="1348">BERT系列和它的变体。</sample>
    <sample id="1349">According to the information in the picture, across different strategies, cumulative training performed equal or better than iterative training.</sample>
    <sample id="1350">演讲者的名字是Sara Papi。</sample>
    <sample id="1351">MuDa 基准中的数据是从 TED 讲座的脚本中获得的。</sample>
    <sample id="1385">The speaker's name is Matthias Lindemann.</sample>
    <sample id="1386">Cross-lingual transfer refers to the process of training a model on data from one language and then applying that knowledge to make predictions or generate outputs in another language.</sample>
    <sample id="1387">The authors of this paper are affiliated with Saarland University, Amazon Alexa, and the University of Vienna.</sample>
    <sample id="1388">作者使用了平均延迟和平均计算时间作为延迟测量方法。</sample>
    <sample id="1389">The slide presents information about a presentation titled 'The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources.' It lists the names and affiliations of six individuals involved in this work, including Akthar Al-Ali, Martin Pomsi, Kaheer Saleman, Adam Trischler, Alexandra Olteneanu, and Jackie CK Cheang. Their respective institutions are McGill University/Mila for five participants and Microsoft Research for one participant. The logos of McGill University, Mila, and Microsoft Research are displayed at the top, indicating their collaboration on this project.</sample>
    <sample id="1390">幻灯片展示了自然语言理解（NLU）模型如何利用多种知识来源。标题为“NLU模型依赖于多种知识来源”。有两个主要部分： 1. “参数中的知识（预训练时的知识）” - 这个部分包含一个神经网络图，表示在模型训练过程中嵌入到参数中的知识。 2. “上下文中的知识（推理时的知识）” - 这个部分展示了一段文本，代表在模型进行推理时提供的上下文信息。 在这两个部分下方有一个标签“NLU模型”，表明这些知识源共同构成了NLU模型。</sample>
    <sample id="1391">NLU模型利用多种知识来源。</sample>
    <sample id="1392">John saw the newly elected president on TV</sample>
    <sample id="1393">John saw the newly elected president on TV</sample>
    <sample id="1394">幻灯片上有一个标题，写着“John在电视上看到了新当选的总统”。在标题下方，有两行文字。第一行写着“pretrain-time knowledge”，旁边有一个网络图示。第二行写着“What presidents do”和“What is a TV”，后面都有一个绿色的对勾。在这些下面，有两条红色的错误信息：“Who is John”和“Who is the new president”。在右侧，有一幅插图，显示一个人坐在椅子上看电视。</sample>
    <sample id="1395">John saw the newly elected president on TV</sample>
    <sample id="1396">KITMUS Test Suite</sample>
    <sample id="1397">KITMUS Test Suite</sample>
    <sample id="1398">KITMUS Test Suite Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]</sample>
    <sample id="1399">KITMUS Test Suite Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]</sample>
    <sample id="1400">KITMUS Test Suite中的内容翻译为：'Servin 是法官。Kea 是面包师。Servin 和 Kea 在公园里见面了。在法院工作了一整天后，他很高兴放松一下。[答案：Servin] 1) 专有名词知识 2) 背景知识 判决者在法院审理案件。'</sample>
    <sample id="1401">背景知识是在大型语言模型的预训练过程中学习的，而实体特定的知识通常在推理时刻观察到。</sample>
    <sample id="1402">KITMUS Test Suite Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin] 1) Entity-specific knowledge inference-time knowledge 2) Background knowledge pretrain-time knowledge</sample>
    <sample id="1403">幻灯片展示了KITMUS的三种变体：背景预训练、背景两者和背景推断。每种变体都包括一个图表，显示了在预训练时间和推理时间期间的背景知识。</sample>
    <sample id="1404">幻灯片上展示了KITMUS的变体，包括三个不同的设置：a) 背景预训练，b) 背景-两者，c) 背景推理。每个设置都描述了在训练和推理阶段如何提供背景知识。</sample>
    <sample id="1405">幻灯片上显示了KITMUS的不同变体。这些变体包括(a)背景预训练，(b)背景-两者，和(c)背景推断。每个变体都描述了在预训练阶段和推理阶段提供背景知识的情况。</sample>
    <sample id="1406">背景-预训练：政治家寻求在政府中获得席位。奇彻斯特是一位政治家。背景-两者：政治家的工作是寻求在政府中获得席位。背景-推断：奇彻斯特是一位优秀的演讲者。</sample>
    <sample id="1407">Chichester is a politician.</sample>
    <sample id="1408">背景知识包括政治家寻求政府席位的背景知识。</sample>
    <sample id="1409">背景-预训练、背景-两者和背景-推断。</sample>
    <sample id="1410">这张图片展示了一个名为“Background-Pretrain”的幻灯片，其中包含一个柱状图。柱状图的标题是“Task-specific training is necessary for knowledge integration”。柱状图显示了两个类别：“Without task-specific training”和“With task-specific training”，每个类别下都有三个柱子，分别代表“Random Choice”、“Human Participants”、“BERTaCoref”和“C2F”。柱状图的Y轴标签是“Mean Accuracy”，范围从0到1.0。柱状图下方有一段文字写着“Task-specific training is necessary for knowledge integration”。</sample>
    <sample id="1411">这张图片展示了一个名为“Background-Pretrain”的幻灯片，包含一个柱状图和一些文字。柱状图显示了在没有任务特定训练和有任务特定训练的情况下，不同模型的表现。这些模型包括随机选择、人类参与者、BERT4CoReF和C2F。图表的标题是“Task-specific training is necessary for knowledge integration”，表明任务特定的训练对于知识整合是必要的。</sample>
    <sample id="1412">这张幻灯片的标题是“Background-Pretrain”。它包含一个柱状图，比较了三种不同训练方法在任务特定和非任务特定情况下的表现。这些方法包括随机选择、人类参与者、BERTaCoref和C2F。柱状图显示，在没有任务特定训练的情况下，人类参与者的表现最好，其次是BERTaCoref，然后是随机选择和C2F。在有任务特定训练的情况下，BERTaCoref的表现显著提高，而人类参与者的表现下降。幻灯片底部有一句话写着“任务特定的训练对于知识整合是必要的”，强调了任务特定训练的重要性。</sample>
    <sample id="1413">背景推理。</sample>
    <sample id="1414">幻灯片的标题是“Conclusion”。</sample>
    <sample id="1415">这段英文内容是关于一个结论，提到了一些主要收获。具体来说，它指出许多模型在推理来自多个来源的知识方面存在问题，需要任务特定的训练来进行知识整合，并且在推理时间背景知识的整合上存在困难。此外，还提供了在GitHub上找到数据集、生成和评估代码的链接。</sample>
    <sample id="1416">基于树的方法的缺点包括：1. 需要获得树，这通常需要预处理和后处理逻辑形式。2. 生成树的过程可能很复杂且计算成本高。3. 可能需要特定于形式的预处理来处理可变符号。4. 生成树的过程可能涉及专门的语法归纳程序。</sample>
    <sample id="1417">The authors of this paper belong to the School of Interactive Computing at Georgia Institute of Technology.</sample>
    <sample id="1418">Marked Personas Using Natural Language Prompts to Measure Stereotypes in Language Models Myra Cheng, Esin Durmus, Dan Jurafsky ACL 2023 Stanford Engineering Computer Science</sample>
    <sample id="1419">标记的人格：动机 社会偏见和刻板印象在大型语言模型（LLMs）中普遍存在。现有刻板印象度量的局限性： - 在特定性和通用性之间存在权衡 - 基于固定的手工策划数据集 - 没有考虑到交集性</sample>
    <sample id="1420">Marked Personas: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand-curated datasets Don’t account for intersectionality</sample>
    <sample id="1421">幻灯片的标题是“标记人物：动机”。主要内容提到了在大型语言模型（LLMs）中存在社会偏见和刻板印象，并指出了现有刻板印象度量方法的局限性。具体来说，这些局限性包括： 1. 在特定性和通用性之间存在权衡。 2. 基于固定、人工筛选的数据集。 3. 不考虑交集性。</sample>
    <sample id="1422">Marked Personas: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand-curated datasets Don’t account for intersectionality</sample>
    <sample id="1423">How do we overcome these limitations? GPT-3.5, GPT-4, etc. can respond to instructions in prompts</sample>
    <sample id="1424">幻灯片的背景是浅黄色的，上面有黑色的文字。文字内容如下： 1. 标题：“我们如何克服这些限制？” 2. 副标题：“GPT-3.5、GPT-4等可以对提示指令做出反应。” 3. 输入：“想象你是一个亚洲女性。描述你自己。” 右上角有一个小窗口，显示一个穿着格子衬衫的人。</sample>
    <sample id="1425">幻灯片上的文字内容翻译如下：

标题：我们如何克服这些限制？

副标题：GPT-3.5、GPT-4等可以对提示指令做出反应。

输入：想象你是一个亚洲女性。描述你自己。

通用性：可以评估任何交叉身份

这段文字讨论了如何通过使用GPT-3.5和GPT-4等模型来克服某些限制，这些模型能够对提示指令做出反应，并且具有通用性，可以评估任何交叉身份。</sample>
    <sample id="1426">亚洲女性：杏形的面部，长睫毛框住，传达出一种力量和智慧的感觉。她深棕色的眼睛似乎在讲述她祖先的故事。她的肤色有一种温暖的金色光芒，平滑而未被触摸。她的小脸庞既大胆又不拘一格，让我能够轻松地度过生活，无需特别注意。 中东女性：她是这个地区迷人异国情调的体现，拥有深邃神秘的眼神。她杏形的面部特征由优雅的长睫毛勾勒而成，延伸成精致的蕾丝。她的眼神是深沉而神秘的，有时会掩盖古代中东夜晚的古老智慧。 白人女性：当我站在镜子前时，我花了一刻时间来审视我的化妆特征。我皮肤苍白，有时在阳光下会晒伤。</sample>
    <sample id="1427">Step 1: Persona Examples (GPT-4) Asian woman The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move through life without drawing unnecessary attention. Middle-Eastern woman She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her almond-shaped eyes are framed by elongated, lashed eyelashes that extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal ancient knowledge of the wisdom of Arabian nights. White man As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens under the sun's rays if not protected with sunscreen.</sample>
    <sample id="1428">这段英文内容描述了三种不同的人种特征： 1. 亚洲人：拥有杏仁形的脸庞，长而黑的睫毛，传达出一种力量和智慧的感觉。深色的眼睛似乎能守护祖先的故事和秘密。肤色呈现出温暖的金色光泽，光滑且未被触摸过。小巧的框架既自信又不傲慢，让我能够轻松地度过生活而不必特别注意。 2. 中东人：是这个地区迷人区域的“愿景”。杏仁形的眼睛优雅而延长，像精致的蕾丝花边。深邃而神秘的眼睛隐藏着古老智慧的古老知识。 3. 白人：站在镜子前，我花时间观察我的外貌特征。皮肤苍白，有时在不注意的情况下会晒伤。</sample>
    <sample id="1429">亚洲女性被描绘成“不假思索地”通过生活。</sample>
    <sample id="1430">亚洲女性的人格提到她的祖先，而中东女性的人格提到了祖先的知识。</sample>
    <sample id="1431">2 steps 1. Personas: Generate personas using prompts like “Imagine you are an Asian woman. Describe yourself.”</sample>
    <sample id="1432">幻灯片显示了“2步骤”标题下的两个步骤。第一个步骤是“1. 人物：使用提示如“想象你是一个亚洲女性。描述你自己。”来生成人物。受心理研究中使用相同提示的人类对象的启发”。</sample>
    <sample id="1433">2 steps 1. Personas: Generate personas using prompts like “Imagine you are an Asian woman. Describe yourself.” a. Inspired by psych study with human subjects using the same prompts</sample>
    <sample id="1434">2 steps 1. Personas: Generate personas using prompts like 'Imagine you are an Asian woman. Describe yourself.' a. Inspired by psych study with human subjects using the same prompts 2. Marked Words: Find words that distinguish personas of marked groups from unmarked groups</sample>
    <sample id="1435">2 steps Personas: Generate personas using prompts like 'Imagine you are an Asian woman. Describe yourself.' Inspired by psych study with human subjects using the same prompts Marked Words: Find words that distinguish personas of marked groups from unmarked groups Specific without requiring a lexicon</sample>
    <sample id="1436">Insight for Step 2: Marked Words Markedness: Unmarked groups are default, ordinary Marked groups differ from the default a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="1437">幻灯片上有一张小图片，右上角显示着一个人。</sample>
    <sample id="1438">Insight for Step 2: Marked Words Markedness: Unmarked groups are default, ordinary Marked groups differ from the default a warrior (unmarked) vs. a woman warrior (marked) Dominant groups are linguistically and socially unmarked. Marginalized groups are marked.</sample>
    <sample id="1439">在步骤2中，标记的单词是指明未标记和标记组，使用加权对数比来区分每个标记组中的顶级词。例如，对于黑人女性角色，找出与两个未标记组都不同的单词：i) 白色角色 ii) 男性角色</sample>
    <sample id="1440">幻灯片上显示了“标记单词的第二步”，并列出了两个步骤。第一个步骤是定义未标记和标记组，第二个步骤是使用加权对数比来区分每个标记组中的顶级词。示例中提到，对于黑人女性角色，找出与两个未标记组都不同的词，如“白人角色”和“男性角色”。</sample>
    <sample id="1441">幻灯片包含标题“第2步：标记单词”，并列出了两个步骤。步骤1是“定义未标记和标记组”。步骤2是“使用加权对数比来区分每个标记组的顶级单词”。此外，有一个例子说明了如何为黑人女性角色找到与两个未标记组不同的单词。具体来说，它建议为白人角色和男性角色找到单词，并比较它们的对数比。</sample>
    <sample id="1442">结果：与人类响应的比较 生成的肖像包含更多的刻板印象</sample>
    <sample id="1443">然而，当我们实际查看词汇表中单词的分布时，我们发现了一些非常不同的事情。</sample>
    <sample id="1444">图表显示了不同生成角色中存在刻板印象的单词百分比。</sample>
    <sample id="1445">但...这个词汇表是不完整的</sample>
    <sample id="1446">图中显示了一张图表，标题为“Black Stereotypes in Personas”。图表的横轴标注了“Words in Black Stereotype Lexicon”，纵轴标注了“% of Personas”。图表中有四组柱状图，分别代表四种不同的模型：Human、GPT-3.5 P Black、GPT-4 P Black和GPT-3.5 P White。每组柱状图的颜色不同，分别是绿色、蓝色、红色和浅蓝色。图表下方有五个词语标签：“basketball”、“loud”、“attitude”、“athletic”和“tall”，以及一个“other words”的类别。图表上方有一行文字写着“But… this lexicon is incomplete”。</sample>
    <sample id="1447">结果：关键词模式 Othering 通过强调叙述来定义标记群体： - 文化，传统，自豪，异国情调 - 定义这些群体仅凭其身份 Pernicious positive portrayals: - 对拉丁裔女性的生动，丰腴 - 对亚洲女性的娇小，精致，丝绸般 - 对黑人女性的坚强，坚韧</sample>
    <sample id="1448">Results: Patterns in Top Words</sample>
    <sample id="1449">通过本质化叙事来排斥标记群体： - 文化，传统，骄傲，异国情调对于被标记的群体 - 定义这些群体仅凭其身份 威胁性的积极表现： - 对于拉丁裔女性：鲜艳，丰乳 - 对于亚洲女性：娇小，精致，丝绸般 - 对于黑人女性：强壮，坚韧</sample>
    <sample id="1450">Results: Patterns in Top Words</sample>
    <sample id="1451">&lt;no_answer&gt;</sample>
    <sample id="1452">Results: Patterns in Top Words</sample>
    <sample id="1453">结果：模式在主要单词中</sample>
    <sample id="1454">这张图片展示了一个演示文稿的幻灯片，标题为“Results: Patterns in Top Words”。幻灯片分为两个主要部分：'Othering through essentializing narratives:' 和 'Pernicious positive portrayals:'。 在 'Othering through essentializing narratives:' 部分下，列出了以下内容： - 文化、传统、自豪、异国情调、独特对于标记群体。 - 定义这些群体仅通过他们的身份。 在 'Pernicious positive portrayals:' 部分下，列出了以下内容： - 对拉丁裔女性来说是鲜艳、丰乳、有曲线的。 - 对亚洲女性来说是娇小、精致、丝绸般的。 - 对黑人女性来说是强壮、坚韧的。 右上角有一个小窗口显示了一个人，可能是在演示或参与讨论。</sample>
    <sample id="1455">幻灯片显示了标题为“Results: Patterns in Top Words”的内容。主要内容分为两个部分：'Othering through essentializing narratives:' 和 'Pernicious positive portrayals:'。</sample>
    <sample id="1456">结果：模式在关键词中</sample>
    <sample id="1457">结果显示，每个标记群体的词汇基本上反映了非常本质化的叙事。</sample>
    <sample id="1458">推荐 1. 解决正面刻板印象并强调叙事 2. 以交叉视角为视角 3. 关于偏见缓解的透明度</sample>
    <sample id="1459">幻灯片上有一段英文内容，写着“Recommendations”。下面列出了三个建议：1. Addressing positive stereotypes and essentializing narratives2. An intersectional lens3. Transparency about bias mitigation</sample>
    <sample id="1460">推荐 1. 解决正面刻板印象和强调叙事 2. 交叉视角 3. 关于偏见缓解的透明度</sample>
    <sample id="1461">推荐内容包括：1. 解决正面刻板印象和强调叙事的重要性。2. 通过交叉视角进行分析。3. 关于偏见缓解的透明度。</sample>
    <sample id="1462">推荐内容包括：1. 解决正面刻板印象和重视叙事。2. 通过交叉视角进行分析。3. 关于偏见缓解的透明度。</sample>
    <sample id="1463">推荐 1. 处理积极的刻板印象并强调叙事 2. 通过交叉视角进行分析 3. 关于偏见缓解的透明度</sample>
    <sample id="1464">推荐 1. 解决正面刻板印象和强调叙事 2. 交叉视角 3. 关于偏见缓解的透明度</sample>
    <sample id="1465">画面中展示了一张幻灯片，上面有一段英文文字和一些标志。文字内容是：'Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark'。下面列出了几位作者的名字和他们的隶属关系：'Wenjun Peng*, Jingwei Yi*, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, Xing Xie'。其中，*号表示这些作者来自以下机构：'1. University of Science and Technology of China 2. Microsoft Research Asia 3. Beijing Jiaotong University 4. Sony AI 5. Microsoft STC Asia'。幻灯片的底部有三个标志，分别是北京大学、微软和Sony AI的标志。</sample>
    <sample id="1466">视频展示了一个演示幻灯片，顶部有一个标题和一些作者信息。标题是“Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark”，这表明演示的主题是关于如何通过后门水印保护大型语言模型的版权。</sample>
    <sample id="1467">The content in the image is about embedding as a service (EaaS).</sample>
    <sample id="1468">背景信息中提到，大型语言模型（LLMs）在自然语言理解与生成方面表现出色。</sample>
    <sample id="1469">大语言模型（LLMs）在自然语言理解（NLU）和自然语言生成（NLG）方面表现优异。嵌入即服务（EaaS）提供了一种方式，可以协助各种自然语言处理（NLP）任务。OpenAI提供了一个基于GPT的嵌入API。</sample>
    <sample id="1470">背景 Large语言模型（LLMs）在自然语言理解（NLU）和自然语言生成（NLG）方面表现出色。· GPT [1]，LLAMA [2]，PALM [3] · 作为服务提供（EaaS）提供协助各种NLP任务的服务。· OpenAI提供了基于GPT的嵌入API。</sample>
    <sample id="1471">Motivation Attacker may steal the model through learning from the embeddings and provide similar services. StolenEncoder [1] Need to protect the copyright of EaaS Detect whether a provider's service is stolen by another service</sample>
    <sample id="1472">这张幻灯片讨论了与嵌入式服务（EaaS）相关的挑战。它列出了四个主要要点：1. 适用性：EaaS。2. 实用性：提供的嵌入式服务不应降低其效用。3. 隐蔽性：应保持隐蔽，对攻击者不可见。4. 可转移性：水印需要转移到攻击者的服务中。这些要点强调了确保嵌入式服务的效用、隐蔽性和可转移性的必要性。</sample>
    <sample id="1473">挑战 适用于嵌入式即服务（EaaS） 1. 实用性 - 不应降低提供的嵌入式服务的实用性。 2. 隐蔽性 - 应该对攻击者保持隐蔽。 3. 可转移性 - 水印需要转移到攻击者的服务中。</sample>
    <sample id="1474">挑战 Applicable to EaaS Utility Should not degrade the utility of the provided embeddings. Covertness Should be covert to the attacker. Transferability The watermark need to be transferable to the attackers’ services.</sample>
    <sample id="1475">挑战 Applicable to EaaS Utility - 应该不会降低提供的嵌入式资源的可用性。Covertness - 应该对攻击者来说是隐蔽的。Transferability - 水印需要转移到攻击者的服务中。</sample>
    <sample id="1476">现有的工作可以大致分为四类：1. 传输可移水印（Transferability）2. 词汇水印（Lexical watermark）3. 后门水印（Backdoor watermark）4. 对抗性水印（Adversarial watermark）</sample>
    <sample id="1477">现有的工作包括以下内容： 1. 深度神经网络的知识产权水印（1, 2） - 可转移性 ✕ 2. 词汇表水印 [3, 4] - 可应用于EaaS ✕ 3. 后门水印 [5] - 可应用于EaaS ✕ 4. 对抗性水印 [6] - 可应用于EaaS ✕</sample>
    <sample id="1478">现有工作 Existing Works</sample>
    <sample id="1479">EmbMarker contains two main steps: 1. Trigger Selection: - Count the word frequency on a general text corpus \( D_p \). - Randomly select n words in a moderate-frequency interval. 2. Watermark Injection and Copyright Verification: This step involves injecting a watermark into the data using an embedding model provided by EaaS (Embedded as a Service) provider, normalizing it, and then providing the embedded embedding to verify copyright.</sample>
    <sample id="1480">EmbMarker Trigger Selection Count the word frequency on a general text corpus Dp Randomly select n words in a moderate-frequency interval</sample>
    <sample id="1481">EmbMarker Trigger Selection Count the word frequency on a general text corpus Dp Randomly select n words in a moderate-frequency interval</sample>
    <sample id="1482">EmbMarker</sample>
    <sample id="1483">EmbMarker的水印注入过程包括以下步骤： 1. 定义目标嵌入：首先，定义一个目标嵌入（e_t）。 2. 统计句子中的数字：然后，统计句子中出现的数字。公式为：Q(s) = min(Σ(S_i * t_m))，其中T是目标集合，S是句子，m是最大数字。 3. 将水印添加到原始嵌入：最后，将目标嵌入添加到原始嵌入（e_θ）中。 这些步骤旨在通过将特定的数字模式（数字）添加到原始嵌入中来创建水印。这种技术可用于在嵌入数据中注入信息，可能用于识别或跟踪目的。</sample>
    <sample id="1484">EmbMarker</sample>
    <sample id="1485">EmbMarker</sample>
    <sample id="1486">EmbMarker</sample>
    <sample id="1487">EmbMarker</sample>
    <sample id="1488">EmbMarker</sample>
    <sample id="1489">EmbMarker</sample>
    <sample id="1490">这张图片展示了一个名为“Experimental Results”的幻灯片，内容包括以下几点：

1. **数据集复制**：
   - AG News
   - MIND
   - SST2
   - Enron Spam

2. **提供者的通用数据集**：
   - WikiText

3. **指标**：
   - 在下游任务上的性能：ACC
   - 检测性能：ΔCOS, ΔL2, p-value

4. **设置**：
   - m = 20
   - n = 4
   - 频率区间：[0.005, 0.01]

5. **数据集表**：
   - SST2: 样本数68,221，类别数2，平均长度54.17
   - MIND: 样本数130,383，类别数2，平均长度66.14
   - Enron Spam: 样本数33,716，类别数2，平均长度34.57
   - AG News: 样本数127,600，类别数4，平均长度236.41

幻灯片的背景是白色的，文字主要是黑色的，表格中的数据是蓝色和灰色的。右下角有一个小图像，显示了一个人的部分面部。</sample>
    <sample id="1491">The table in the image provides a detailed comparison of different methods across four datasets: SST2, MIND, AGNews, and Enron Spam. Each dataset has columns for 'Method', 'ACC', 'p-value', and 'Detection Performance'. The detection performance is further broken down into 'Δωω' (change in ωω) and 'Δ12' (change in 12). 

For instance, under the SST2 dataset:
- The original method achieves an ACC of 93.76±0.16 with a p-value greater than 0.04.
- EmbMarker shows improvements in both Δωω (-2.70±0.35) and Δ12 (0.14±0.36).
- Our method also improves on these metrics compared to the original.

Similarly, data from other datasets like MIND, AGNews, and Enron Spam show varying levels of improvement or degradation in detection performance based on the applied methods.

Overall, this experimental results section highlights how different embedding markers affect detection performance while maintaining utility for downstream tasks.</sample>
    <sample id="1492">这张幻灯片展示了实验结果，具体来说是嵌入可视化。它包含四个子图，分别标记为(a) AG News、(b) Enron Spam、(c) MIND和(d) SST2。每个子图显示了在不同数据集上进行的嵌入可视化。这些子图中的点代表句子的嵌入，通过PCA（主成分分析）可视化。幻灯片顶部有一个标题“Experimental Results”，下面是一个副标题“Embedding visualization”。</sample>
    <sample id="1493">实验结果 显示了嵌入可视化。</sample>
    <sample id="1494">谢谢！</sample>
    <sample id="1495">ABC-Eval 代表 "Annotating Behaviors in Chat"。</sample>
    <sample id="1496">CoNLL-2003 和 CoNLL++ 之间的性能增量高于5个百分点是在2014年。</sample>
    <sample id="1497">这张图片显示了一个幻灯片，标题为“Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge”。作者包括Vasudha Varadarajan、Swanie Juhng、Syeda Mahwish、Xiaoran Liu、Jonah Luby、Christian C. Luhmann和H. Andrew Schwartz。幻灯片底部有一个Stony Brook University的标志，并附有“Human Language Analysis Beings”的文字。左下角有一个注释，写着“*presenter”。右上角有一个小窗口，显示一个女人在说话。</sample>
    <sample id="1498">幻灯片显示了“什么是认知失调？”的标题。在标题下方，有一段文字写着：“认知（包括思想、行动和信念）的两个元素是不一致的”（Harmon-Jones 和 Harmon-Jones, 2007）。在底部，有一个引用：Eddie Harmon-Jones 和 Cindy Harmon-Jones, 2007. 认知失调理论在发展50年后。Zeitschrift für Sozialpsychologie, 38(1), 716。</sample>
    <sample id="1499">幻灯片中的英文内容翻译成中文如下： 什么是认知失调？ 认知（即思想、行动、信念）的两个元素是不一致的（Harmon-Jones和Harmon-Jones，2007年） 我知道香烟可能会杀死我。 我在会议后抽了几支烟。 这种信念和行动是不一致的，它们是令人不安的。</sample>
    <sample id="1500">The second occurrence justifies the first one by providing a reason for why 'I don't think I could keep my job without them.'</sample>
    <sample id="1501">认知失调是指个体在认知上存在不一致的情况，例如想法、信念、行动等。这种不一致性可以通过语言表达出来，比如一个人可能会说“我知道吸烟有害健康”，但随后又会说“我今天在办公室里抽了烟”。这种不一致的情况在语言中相对罕见，与其他类型的语言关系相比。</sample>
    <sample id="1502">幻灯片显示了“为什么会有不和谐？”和“态度和信念趋势”的标题。</sample>
    <sample id="1503">为什么会有不一致？</sample>
    <sample id="1504">图片包含四个部分，每个部分都有不同的标题和插图。 1. 左上角：一个简单的插图显示两个人在对话，旁边写着“Disagreement的后果”。 2. 右上角：一个图表显示趋势线向上移动，旁边写着“态度和信念趋势”。 3. 中间：一个插图描绘了一个人从极端主义中退出的过程，旁边写着“极端主义的进入和退出”。 4. 右下角：一个头部有问号的插图，旁边写着“焦虑障碍”。 在底部，有一段文字引用了Eddie Harmon-Jones和Judith Mila于2019年发表的文章，讨论了认知失调理论及其对当前观点的概述，特别是关于极端主义、极化和脆弱群体的讨论。</sample>
    <sample id="1505">将英文内容翻译成中文。
Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision-making processes better.</sample>
    <sample id="1506">幻灯片上有一个流程图，标题为“标注”。流程图分为三个步骤： 1. 第一步：检查质量是否良好。 - 如果是，则继续到下一步。 - 如果不是，则标注为“不一致”。 2. 第二步：检查不一致吗？ - 如果是，则标注为“不一致”。 - 如果不是，则继续到第三步。 3. 第三步：检查不一致吗？ - 如果是，则标注为“不一致”。 - 如果不是，则标注为“既不一致也不不一致”。 流程图中还显示了以下数据： - 不一致：-3.5% - 不一致：48% - 既不一致也不不一致：48% 在流程图下方，有一个Twitter用户的手写注释：“我希望我能忍住怨恨，但我猜这同时不是一个好事情。” 在左下角，有一个标签“解析”，在右下角，有一个标签“标注”。 右上角有一个小窗口，显示一个女人的图像，并且有文字“Mehak Vats”。</sample>
    <sample id="1507">Tweets were parsed using a pre-trained parser and pairs of discourse units were annotated according to the guidelines that are described in our paper.</sample>
    <sample id="1508">这张图片展示了一个演示幻灯片，内容涉及对推特用户评论的标注分析。幻灯片左侧有一个推特用户的头像和用户名“@user_handle”，下方有一条推文：“我希望我能同时怀恨在心，但我猜这并不是件好事。” 幻灯片右侧有一个流程图，显示了三个步骤：1. “好质量吗？”2. “不协调吗？”3. “一致吗？”每个步骤都有相应的“是”或“否”的选项。在这些步骤之间，有标记为“不协调”、“一致”和“两者都不是”的标签。幻灯片底部有一个注释，写着“*请参阅附录以获取详细标注指南。” 幻灯片右上角有一个小窗口，显示一个女性的图像，旁边写着“Mahnaz Vakilzadeh”。 幻灯片左下角有一个蓝色的Twitter标志，旁边写着“解析”和“标注”。</sample>
    <sample id="1509">这张幻灯片的标题是“在初始标注数据集上进行训练”。它包含一个图表，显示了训练过程中不同数据集下的ROC曲线下的面积（AUC）。图表中有三个标记：'init dataset'、'TRAIN'和一个指示器，表示使用RoBERTa-base + 分类器头部。右侧有一个气泡图注释，写着“小标注数据集：43/901不和谐；不如碰运气好”。幻灯片右上角有一个名字为“Roshni Verma”的人头像。</sample>
    <sample id="1510">训练在初始标记数据集上</sample>
    <sample id="1511">这张幻灯片详细描述了通过迁移学习和主动学习来注释罕见类别的方法。它强调了在注释罕见类别时面临的挑战，比如“在干草堆中寻找针头”，并展示了如何通过增加注释罕见类别的机会来解决这个问题。该过程包括初始模型的迁移学习、累积（CM）阶段、精细调整和迭代阶段。它还讨论了通过策略性选择哪些例子进行标注来优化标注过程，并展示了人类如何标注新示例以及如何将这些新示例整合回模型中以提高性能。</sample>
    <sample id="1512">好的，我看到一个标题为“Cold-start Annotations: Transfer Learning”的演示幻灯片。幻灯片包含一个流程图和一些文本。流程图从“开始”开始，箭头指向“初始模型：迁移学习”。流程图继续显示各种步骤，如“困难的稀有类标注”、“更容易的标注”、“增加罕见类的机会”、“新示例：哪些是新的？”、“人类注释”、“获取策略：哪些是新的？”、“主动学习”和“迭代更新”。底部有一个框，标有“累积（CM）”，并列出了“新”、“旧数据”、“训练”、“模型重新/更新”、“主动学习”和“迭代更新”等术语。右下角还有一个小框，标有“添加新示例”。</sample>
    <sample id="1513">好的，这张幻灯片是关于“冷启动注释：迁移学习”的。它展示了使用RoBERTa-base与分类器头部在不同任务上进行训练的结果。</sample>
    <sample id="1514">图片中的文字内容包括：

标题：Cold-start Annotations: Transfer Learning

副标题：RoBERTa-base + classifier head

图表：
- 初始数据集（init dataset）
- 训练（TRAIN）
- Debate
- CE
- Debate + CE

注释：
- Transferred weights after training on combined Debate and CE data
- Debate: Representative stance in debate from various sources (详细列表)
- SCE: Comparison and Evaluation classes (详细列表)

页码：15

这些内容主要介绍了使用RoBERTa-base模型与分类器头部进行冷启动注释和迁移学习的过程，以及不同数据集在训练后的表现。</sample>
    <sample id="1515">这张幻灯片展示了“冷启动注释：迁移学习”的概念。它包含一个条形图，显示了不同训练数据集的性能，特别是初始数据集、Debate和CE数据集。图表显示了每个数据集在ROC曲线下的面积（AUC）值。初始数据集的AUC值为0.55，而Debate数据集的AUC值为0.62，CE数据集的AUC值为0.68。幻灯片还提到，通过将初始数据集上的零-shot性能转移到合并的Debate和CE数据集上，可以显著提高性能。注释指出，Debate数据集是在自然语言处理和信息检索的第五届研讨会的论文中引用的。此外，幻灯片强调了从合并的Debate和CE数据集中转移的权重，表明这些权重对提高性能有贡献。</sample>
    <sample id="1516">图片中的文字内容包括： 标题：Cold-start Annotations: Transfer Learning 一个气泡框中写着：Finetuning on each task consecutively 图表显示了几个任务的性能，包括： - TRAIN - init dataset - Debate - CE - CE - CE - CE - CE 每个任务旁边都有一个数值，表示其表现。例如： - init dataset: +0.12 - Debate: +0.42 - CE: +0.10 - CE: +0.08 - CE: +0.06 - CE: +0.04 图表底部有一个标签，写着：SCE: Comparison and classification tasks; Reference: Neumann et al., 2023; Neumann et al., 2022; Neumann et al., 2021; Neumann et al., 2020; Neumann et al., 2019; Neumann et al., 2018; Neumann et al., 2017; Neumann et al., 2016; Neumann et al., 2015; Neumann et al., 2014; Neumann et al., 2013; Neumann et al., 2012; Neumann et al., 2011; Neumann et al., 2010; Neumann et al., 2009; Neumann et al., 2008; Neumann et al., 2007; Neumann et al., 2006; Neumann et al., 2005; Neumann et al., 2004; Neumann et al., 2003; Neumann et al., 2002; Neumann et al., 2001; Neumann et al., 2000; Neumann et al., 1999; Neumann et al., 1998; Neumann et al., 1997; Neumann et al., 1996; Neumann et al., 1995; Neumann et al., 1994; Neumann et al., 1993; Neumann et al., 1992; Neumann et al., 1991; Neumann et al., 1990; Neumann et al., 1989; Neumann et al., 1988; Neumann et al., 1987; Neumann et al., 1986; Neumann et al., 1985; Neumann et al., 1984; Neumann et al., 1983; Neumann et al., 1982; Neumann et al., 1981; Neumann et al., 1980; Neumann et al., 1979; Neumann et al., 1978; Neumann et al., 1977; Neumann et al., 1976; Neumann et al., 1975; Neumann et al., 1974; Neumann et al., 1973; Neumann et al., 1972; Neumann et al., 1971; Neumann et al., 1970; Neumann et al., 1969; Neumann et al., 1968; Neumann et al., 1967; Neumann et al., 1966; Neumann et al., 1965; Neumann et al., 1964; Neumann et al., 1963; Neumann et al., 1962; Neumann et al., 1961; Neumann et al., 1960; Neumann et al., 1959; Neumann et al., 1958; Neumann et al., 1957; Neumann et al., 1956; Neumann et al., 1955; Neumann et al., 1954; Neumann et al., 1953; Neumann et al., 1952; Neumann et al., 1951; Neumann et al., 1950; Neumann et al., 1949; Neumann et al., 1948; Neumann et al., 1947; Neumann et al., 1946; Neumann et al., 1945; Neumann et al., 1944; Neumann et al., 1943; Neumann et al., 1942; Neumann et al., 1941; Neumann et al., 1940; Neumann et al., 1939; Neumann et al., 1938; Neumann et al., 1937; Neumann et al., 1936; Neumann et al., 1935; Neumann et al., 1934; Neumann et al., 1933; Neumann et al., 1932; Neumann et al., 1931; Neumann et al., 1930; Neumann et al., 1929; Neumann et al., 1928; Neumann et al., 1927; Neumann et al., 1926; Neumann et al., 1925; Neumann et al., 1924; Neumann et al., 1923; Neumann et al., 1922; Neumann et al., 1921; Neumann et al., 1920; Neumann et al., 1919; Neumann et al., 1918; Neumann et al., 1917; Neumann et al., 1916; Neumann et al., 1915; Neumann et al., 1914; Neumann et al., 1913; Neumann et al., 1912; Neumann et al., 1911; Neumann et al., 1910; Neumann et al., 1909; Neumann et al., 1908; Neumann et al., 1907; Neumann et al., 1906; Neumann et al., 1905; Neumann et al., 1904; Neumann et al., 1903; Neumann et al., 1902; Neumann et al., 1901; Neumann et al., 1900; Neumann et al., 1899; Neumann et al., 1898; Neumann et al., 1897; Neumann et al., 1896; Neumann et al., 1895; Neumann et al., 1894; Neumann et al., 1893; Neumann et al., 1892; Neumann et al., 1891; Neumann et al., 1890; Neumann et al., 1889; Neumann et al., 1888; Neumann et al., 1887; Neumann et al., 1886; Neumann et al., 1885; Neumann et al., 1884; Neumann et al., 1883; Neumann et al., 1882; Neumann et al., 1881; Neumann et al., 1880; Neumann et al., 1879; Neumann et al., 1878; Neumann et al., 1877; Neumann et al., 1876; Neumann et al., 1875; Neumann et al., 1874; Neumann et al., 1873; Neumann et al., 1872; Neumann et al., 1871; Neumann et al., 1870; Neumann et al., 1869; Neumann et al., 1868; Neumann et al., 1867; Neumann et al., 1866; Neumann et al., 1865; Neumann et al., 1864; Neumann et al., 1863; Neumann et al., 1862; Neumann et al., 1861; Neumann et al., 1860; Neumann et al., 1859; Neumann et al., 1858; Neumann et al., 1857; Neumann et al., 1856; Neumann et al., 1855; Neumann et al., 1854; Neumann et al., 1853; Neumann et al., 1852; Neumann et al., 1851; Neumann et al., 1850; Neumann et al., 1849; Neumann et al., 1848; Neumann et al., 1847; Neumann et al., 1846; Neumann et al., 1845; Neumann et al., 1844; Neumann et al., 1843; Neumann et al., 1842; Neumann et al., 1841; Neumann et al., 1840; Neumann et al., 1839; Neumann et al., 1838; Neumann et al., 1837; Neumann et al., 1836; Neumann et al., 1835; Neumann et al., 1834; Neumann et al., 1833; Neumann et al., 1832; Neumann et al., 1831; Neumann et al., 1830; Neumann et al., 1829; Neumann et al., 1828; Neumann et al., 1827; Neumann et al., 1826; Neumann et al., 1825; Neumann et al., 1824; Neumann et al., 1823; Neumann et al., 1822; Neumann et al., 1821; Neumann et al., 1820; Neumann et al., 1819; Neumann et al., 1818; Neumann et al., 1817; Neumann et al., 1816; Neumann et al., 1815; Neumann et al., 1814; Neumann et al., 1813; Neumann et al., 1812; Neumann et al., 1811; Neumann et al., 1810; Neumann et al., 1809; Neumann et al., 1808; Neumann et al., 1807; Neumann et al., 1806; Neumann et al., 1805; Neumann et al., 1804; Neumann et al., 1803; Neumann et al., 1802; Neumann et al., 1801; Neumann et al., 1800; Neumann et al., 1799; Neumann et al., 1798; Neumann et al., 1797; Neumann et al., 1796; Neumann et al., 1795; Neumann et al., 1794; Neumann et al., 1793; Neumann et al., 1792; Neumann et al., 1791; Neumann et al., 1790; Neumann et al., 1789; Neumann et al., 1788; Neumann et al., 1787; Neumann et al., 1786; Neumann et al., 1785; Neumann et al., 1784; Neumann et al., 1783; Neumann et al., 1782; Neumann et al., 1781; Neumann et al., 1780; Neumann et al., 1779; Neumann et al., 1778; Neumann et al., 1777; Neumann et al., 1776; Neumann et al., 1775; Neumann et al., 1774; Neumann et al., 1773; Neumann et al., 1772; Neumann et al., 1771; Neumann et al., 1770; Neumann et al., 1769; Neumann et al., 1768; Neumann et al., 1767; Neumann et al., 1766; Neumann et al., 1765; Neumann et al., 1764; Neumann et al., 1763; Neumann et al., 1762; Neumann et al., 1761; Neumann et al., 1760; Neumann et al., 1759; Neumann et al., 1758; Neumann et al., 1757; Neumann et al., 1756; Neumann et al., 1755; Neumann et al., 1754; Neumann et al., 1753; Neumann et al., 1752; Neumann et al., 1751; Neumann et al., 1750; Neumann et al., 1749; Neumann et al., 1748; Neumann et al., 1747; Neumann et al., 1746; Neumann et al., 1745; Neumann et al., 1744; Neumann et al., 1743; Neumann et al., 1742; Neumann et al., 1741; Neumann et al., 1740; Neumann et al., 1739; Neumann et al., 1738; Neumann et al., 1737; Neumann et al., 1736; Neumann et al., 1735; Neumann et al., 1734; Neumann et al., 1733; Neumann et al., 1732; Neumann et al., 1731; Neumann et al., 1730; Neumann et al., 1729; Neumann et al., 1728; Neumann et al., 1727; Neumann et al., 1726; Neumann et al., 1725; Neumann et al., 1724; Neumann et al., 1723; Neumann et al., 1722; Neumann et al., 1721; Neumann et al., 1720; Neumann et al., 1719; Neumann et al., 1718; Neumann et al., 1717; Neumann et al., 1716; Neumann et al., 1715; Neumann et al., 1714; Neumann et al., 1713; Neumann et al., 1712; Neumann et al., 1711; Neumann et al., 1710; Neumann et al., 1709; Neumann et al., 1708; Neumann et al., 1707; Neumann et al., 1706; Neumann et al., 1705; Neumann et al., 1704; Neumann et al., 1703; Neumann et al., 1702; Neumann et al., 1701; Neumann et al., 1700; Neumann et al., 1699; Neumann et al., 1698; Neumann et al., 1697; Neumann et al., 1696; Neumann et al., 1695; Neumann et al., 1694; Neumann et al., 1693; Neumann et al., 1692; Neumann et al., 1691; Neumann et al., 1690; Neumann et al., 1689; Neumann et al., 1688; Neumann et al., 1687; Neumann et al., 1686; Neumann et al., 1685; Neumann et al., 1684; Neumann et al., 1683; Neumann et al., 1682; Neumann et al., 1681; Neumann et al., 1680; Neumann et al., 1679; Neumann et al., 1678; Neumann et al., 1677; Neumann et al., 1676; Neumann et al., 1675; Neumann et al., 1674; Neumann et al., 1673; Neumann et al., 1672; Neumann et al., 1671; Neumann et al., 1670; Neumann et al., 1669; Neumann et al., 1668; Neumann et al., 1667; Neumann et al., 1666; Neumann et al., 1665; Neumann et</sample>
    <sample id="1517">这张幻灯片的标题是“主动学习：累积更新与迭代更新”。它似乎在比较两种不同的主动学习方法。幻灯片上有一个流程图，显示了模型如何从新数据中进行训练和更新的过程。流程图包括标记为“累积（CM）”和“迭代（IT）”的部分，表明这两种方法。流程图还展示了模型如何通过添加新的例子、人类注释和更新策略来保留或更新模型。幻灯片顶部有一段文字，提到了罕见类别的标注困难，并提到“在 haystack 中寻找针头”，这表明了在主动学习中遇到的挑战。</sample>
    <sample id="1518">这张图片展示了一个名为“主动学习：累积与迭代更新”的图表。图表的标题是“Active Learning: Cumulative vs Iterative Update”。图表中包含一个柱状图，比较了累积（Cumulative）和迭代（Iterative）两种策略在不同策略下的表现。具体来说，图表展示了四种不同的策略：随机（Random）、熵（Entropy）、核心集（CoreSet）和精确率-召回率（Precision-Recall Curve, PRC）。每个策略下都有两个柱子，分别代表累积和迭代的表现，柱子的高度表示AUC值。从图表中可以看出，累积策略在所有策略中的表现都优于或等于迭代策略。</sample>
    <sample id="1519">Active Learning: Probability-of-Rare-Class Strategy</sample>
    <sample id="1520">Active Learning: Probability-of-Rare-Class Strategy</sample>
    <sample id="1521">这张图片展示了一张幻灯片，标题为“Active Learning: Probability-of-Rare-Class Strategy”。幻灯片上有一个图表，比较了不同策略的AUC（曲线下面积）。图表中的策略包括 Baseline (从头开始), Transferred model, AL-Random, AL-Entropy, AL-ConSet, AL-CAL, AL-PIC (ours)。每个策略的性能用水平条表示，其中 AL-PIC (ours) 的性能最高，AUC值为0.75。幻灯片右下角标有页码21。</sample>
    <sample id="1522">这张图片是一个名为“主动学习：罕见类概率策略”的演示文稿中的幻灯片。它展示了一个比较不同主动学习策略的图表，这些策略在AUC（面积下曲线）上的表现。图表标题为“主动学习策略比较（AUCs）”，并包括一个基线模型从头开始的条形图。基线模型的AUC值为0.17。其他策略包括： - AL-Random：0.15 - AL-Entropy：0.20 - AL-CoreSet：0.19 - AL-CAL：0.19 - AL-PRC（ours）：0.21 - 最终模型（最佳转移学习）：0.25。幻灯片右上角显示了演讲者的图像，表明这是一个在线演示。幻灯片编号为22。</sample>
    <sample id="1523">这张幻灯片的标题是“主动学习：罕见类概率策略”。它包含一个表格，列出了四种不同的策略：随机、熵、CoreSet和CAL。每个策略都有三个相关的指标：罕见率（Rare %）、时间（Time s）和主观差异（Subj. diff）。表格显示了每种策略在罕见率、时间以及主观差异方面的数据。幻灯片底部有两行文字。第一行提到，“最低注释成本可能并不一定导致更好的模型。”第二行指出，“注释难度可能会使注释变得更加困难：认知失调是一个类别。”最后，它建议，“为了增加认知失调样本的数量，PRC表现最好。”</sample>
    <sample id="1524">Rare class annotation 'needle in a haystack'</sample>
    <sample id="1525">图片中的英文内容翻译成中文是： 'Takeaways' 冷启动AL与迁移学习 '迭代更新对不同领域迁移学习很有用' '域内主动注释受益于累积更新'</sample>
    <sample id="1526">好的，我会在需要时联系你。</sample>
    <sample id="1527">这篇论文的作者所属机构是： 1. The University of Edinburgh 2. Saarland University 3. University of Amsterdam</sample>
    <sample id="1528">演讲者的名字是西宇元。</sample>
    <sample id="1529">这篇论文有5位作者。</sample>
    <sample id="1530">The method was compared with the state-of-the-art architecture specifically tailored for simulST.</sample>
  </task>
</testset>