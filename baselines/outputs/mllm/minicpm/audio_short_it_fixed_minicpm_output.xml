<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="it">
    <sample id="0">The main data sources for language models are large-scale web-crawled data and political news media.</sample>
    <sample id="1">McGill University, Mila and Microsoft Research</sample>
    <sample id="2">Ciao, la tua presentazione è molto interessante. Grazie per averci fornito i dettagli del nuovo corpus per l'identificazione del testo tedesco.</sample>
    <sample id="3">Il mio nome è Regina Stodden e vi guiderò per la prima parte della presentazione. Per prima cosa definiamo la semplicebra del testo.</sample>
    <sample id="4">L'omagnificazione del testo è un processo di adattare un testo per migliorare la comprensione del testo per un gruppo di destinazione specifico, come persone con problemi di lettura o speaker non nativi.</sample>
    <sample id="5">Per addestrare un modello di identificazione del testo, richiediamo paia parallele di testo, ad esempio di documenti o frasi.</sample>
    <sample id="6">Ecco un esempio di una coppia di frasi alignate complessa in tedesco e la sua traduzione in linguaggio semplice.</sample>
    <sample id="7">Per semplificare la frase, sono possibili diverse tecniche, come la sostituzione lexica, la divisione del clausolo, la divisione e la riordinamento o l'aggiunta di parole.</sample>
    <sample id="8">Ora propongiamo un nostro nuovo piano di cooperazione, perché negli ultimi anni ci sono stati alcuni problemi con le cooperate esistenti. Per esempio, queste cooperate qui sono troppo piccole per addestrare un modello di codifica del testo.</sample>
    <sample id="9">I'm sorry, I didn't catch that. Could you repeat what you said?</sample>
    <sample id="10">Quindi propongiamo il nostro nuovo corpus DeepLain, suddiviso in due corpi sottospecifici: DeepLain-APA e DeepLain-WEB. DeepLain-APA si basa su testi di notizie.</sample>
    <sample id="11">Nel progetto DeepPlain APA abbiamo manualmente alignato 483 documenti. Questo dà circa 30.000-30.000 paia di frasi parallele.</sample>
    <sample id="12">Per DeepL Web, questo corpus include diversi domeni e abbiamo anche alignato tutti questi 750 documenti manualmente e automaticamente.</sample>
    <sample id="13">Il risultato totale è 30.450 coppie di frasi.</sample>
    <sample id="14">Analizziamo più da vicino i nostri paia di frasi, ad esempio per esaminare il tipo di semantica.</sample>
    <sample id="15">Come puoi vedere qui, il testo biblico è molto più rafforzato e semplificato rispetto ad esempio al testo notizie o ai testi per gli apprendenti della lingua.</sample>
    <sample id="16">In every way, for example in simplifying words or structures, and also overall simplification.</sample>
    <sample id="17">Inoltre, puoi vedere che il nostro corpus di DeepL è molto vario in termini di trasformazioni di modifica. Ad esempio, nel corpus API di DeepL abbiamo molti più riordinamenti e aggiunte di parole rispetto al corpus web di DeepL.</sample>
    <sample id="18">Dell'altra parte, nel corpus web abbiamo molte più riflessioni.</sample>
    <sample id="19">Quindi vedremo cosa possiamo fare con questo corpus.</sample>
    <sample id="20">Negli ultimi anni ci sono state molte metodi di allineamento, ma nel contesto delle traduzioni automatiche.</sample>
    <sample id="21">In questo caso, siamo afrontati con un problema di traduzione automatica. Dato che abbiamo due documenti paralleli scritti in lingue diverse e vogliamo estraggere le corrispondenze dei passaggi tra i due documenti, possiamo utilizzare una tecnica di traduzione automatica basata sull'alignamento.</sample>
    <sample id="22">Ma nel nostro caso, stiamo cercando di estrarre le alignamenti tra le frasi di due documenti paralleli, che hanno lo stesso linguaggio, lo stesso contenuto, ma sono a livello di complessità diverso.</sample>
    <sample id="23">Ecco ora, avendo il nostro set di dati Dplane che contiene le frasi manualmente allineate, possiamo utilizzare queste frasi come standard di riferimento per valutare alcune delle metodologie di allineamento proposte.</sample>
    <sample id="24">Ecco la traduzione: "E abbiamo fatto alcune adattazioni ai metodi proposti e abbiamo pubblicato tutte queste adattazioni e i codici per eseguire i nostri esperimenti nel paper."</sample>
    <sample id="25">Allora abbiamo concluso che il miglior metodo automatico di allineamento da utilizzare per la semplificazione del testo in tedesco è il metodo di AlignMe.</sample>
    <sample id="26">Epuò anche trovare il codice per eseguire questa funzione sui suoi propri documenti nel paper.</sample>
    <sample id="27">Il secondo caso d'uso che abbiamo mostrato nel nostro articolo è il caso della semplificazione automatica del testo.</sample>
    <sample id="28">Semplificando il testo complesso attraverso l'adattamento specifico dei modelli linguistici.</sample>
    <sample id="29">Abbiamo addestrato due modelli diversi. Abbiamo addestrato il modello del lungo paragrafo per produrre semplificazioni a livello di documento.</sample>
    <sample id="30">E anche si è adattato il modello base per produrre semplice le frasi a livello di frase.</sample>
    <sample id="31">Puoi trovare anche tutti i checkpoint e puoi analizzare in dettaglio i risultati e le metriche di valutazione delle nostre sperimentazioni nel paper.</sample>
    <sample id="32">Conclusiamo quindi che questa ottimizzazione fine-tuning potrebbe produrre punteggi migliori dei punteggi di base.</sample>
    <sample id="33">Ecco la traduzione: "e propongiamo quei risultati come una guida, un benchmark per il problema della semplificazione automatica del testo nel futuro".</sample>
    <sample id="34">Grazie mille per la vostra attenzione e speriamo di incontrarvi tutti durante la conferenza. Grazie.</sample>
    <sample id="35">The speaker's name is Kaiyuan.</sample>
    <sample id="36">T5 X-Large model</sample>
    <sample id="37">I tagger CoNLL-2003 funzionano ancora.</sample>
    <sample id="38">Il nuovo approccio di valutazione umana consiste nell'annettere una valutazione chiara e precisa delle risposte del modello, identificando se le risposte contengono informazioni irrelevanti o se il modello si contraddice a se stesso.</sample>
    <sample id="39">Clean validation samples</sample>
    <sample id="40">The answer is "alternative question".</sample>
    <sample id="41">There are 5 authors involved in this article.</sample>
    <sample id="42">Ciao, mi chiamo Adam Skurkowski e questa lezione è su struttura dipendenza della coordinazione.</sample>
    <sample id="43">Come potete sapere, ci sono strutture dipendenziali diverse presuppese da teorie e approdi corpus-based. Per esempio, nelle dipendenze universali, la struttura della coordinazione è "Lisa, Bart e Maggie".</sample>
    <sample id="44">Il primo soggetto è la testa della struttura codinata, quindi in questo caso Lisa.</sample>
    <sample id="45">Approaches similar to that of Igor Milchuk's meaning text theory, where again the whole coordinate structure is headed by the first conjunct.</sample>
    <sample id="46">Anche approcci simmetrici alle strutture coordinate, come l'approccio Prag, l'approccio headed congiunzione utilizzato in treebanks Prag dipendenza o strutture coordinate condizionate da una congiunzione.</sample>
    <sample id="47">Quindi abbiamo delle dipendenze dal "AND" a tutti i conjunti.</sample>
    <sample id="48">E infine, c'è anche un approccio a più testi, ad esempio utilizzato nella regola di parole di Cutkosky.</sample>
    <sample id="49">Dichiaro che tutti i conjunti sono acronimi del codice strutturale, quindi otteniamo dipendenze dal governatore "qui ama" fino a tutti i conjunti separati "Lisa", "Bart" e "Maggie".</sample>
    <sample id="50">Oggi il nostro obiettivo è produrre un'argomentazione nuova per le strutture simmetriche di coordinamento come queste e contro le strutture asimmetriche di coordinamento come queste.</sample>
    <sample id="51">Okay, l'argomento è basato sul principio della minimizzazione della dipendenza che esploderò sulla base di questi esempi.</sample>
    <sample id="52">In English, as you might know, direct objects prefer to be close to the verb while adjuncts may be further away.</sample>
    <sample id="53">Marge legge "ieri è molto peggio", perché tra il verbo e l'oggetto direttivo c'è l'aggettivo "ieri".</sample>
    <sample id="54">Tuttavia, questo effetto può essere mitigato quando l'oggetto direttivo è molto pesante e lungo, perché in tal caso può essere spostato dopo l'agente.</sample>
    <sample id="55">Q: Questa è illustrata qui. Entrambi questi frasi sono giuste. Mart rende questo libro assolutamente affascinante sulle BCS ieri è okay. Altrimenti, invece di "it", abbiamo questa NP lunga.</sample>
    <sample id="56">Małgorzata, ho Mi piace molto questo libro su le api.</sample>
    <sample id="57">Quindi la ragione qui è che questo è possibile perché, anche se questa frase viola il principio grammaticale generale che gli oggetti diretti dovrebbero essere vicini alla verba,</sample>
    <sample id="58">Satisfies the principle of dependency length minimization, which says that shorter dependencies are preferred.</sample>
    <sample id="59">Quelli due alberi mostrano la lunghezza delle dipendenze chiave, quindi quelle che sono costanti tra queste due strutture.</sample>
    <sample id="60">Qui abbiamo una dipendenza da "red" all'adjunto lungo 7 misurato in parole e da "red" a "book" lungo 4, quindi otteniamo 11.</sample>
    <sample id="61">Quando sposti, quando hai scambiato questi due componenti, la somma di queste due dipendenze diventa 6, giusto? Così invece di 11 è 6, molto più breve, per questo motivo sente ok, giusto? Violenta un principio ma soddisfa un altro.</sample>
    <sample id="62">Okay, so what we did was extract various statistics about coordination from the enhanced version of the Penn Treebank and see the paper "Why wouldn't you use universal dependencies?"</sample>
    <sample id="63">E queste statistiche confermano l'osservazione fatta molte volte prima che le conjunte sinistra tendono ad essere più brevi, quindi sale e pepe non pepe e sale misurati in sussidi.</sample>
    <sample id="64">E anche l'osservazione che è stata fatta in passaggio, ovvero che questa tendenza cresce con la differenza di lunghezza.</sample>
    <sample id="65">Quando la differenza tra le lunghezze delle due conjunture si estende, la più breve tende a essere più forte.</sample>
    <sample id="66">Ma è notevole in questo articolo che abbiamo osservato che questa tendenza si verifica solo quando il governo è a sinistra e non esiste.</sample>
    <sample id="67">Dopo la guida, ci sono Bob e Lisa.</sample>
    <sample id="68">Nel secondo esempio, "Homer came and sneezed", qui abbiamo una coordinazione di due verbi e non c'è nessunGovernante esterno. Quindi in questi casi, il giunto sinistro tende a essere più breve, più grande la differenza tra i due giunti.</sample>
    <sample id="69">Tuttavia, quando il governo è alla destra, come qui, sinistra governa la codificazione della rete, questo effetto scompare.</sample>
    <sample id="70">Quindi abbiamo dimostrato che misurando la lunghezza in caratteri, che è la prima colonna, in sussidiari, che è la seconda colonna e in parole, che è la terza colonna, mi concentrerò sulla terza colonna.</sample>
    <sample id="71">Quello che vediamo qui è che quando il gavino è a sinistra,</sample>
    <sample id="72">La tendenza per il congiuntivo sinistro di essere più breve cresce gradualmente con la differenza assoluta in parole e lo stesso si osserva quando non c'è un governante, come nelle coordinate delle frasi, ma quando il governante è sulla destra questa tendenza scompare.</sample>
    <sample id="73">Ecco come ci siamo ritenuti in questo articolo.</sample>
    <sample id="74">Vedi il paper per l'intero accordo e gli argomenti, e parla con noi durante la sessione di poster. Grazie.</sample>
    <sample id="75">Il numero di autori coinvolti nell'articolo è 2.</sample>
    <sample id="76">The Bible texts are much stronger simplified than, for example, the news text or the language learner texts.</sample>
    <sample id="77">Salt and pepper, not pepper and salt.</sample>
    <sample id="78">Sì, puoi usare i modelli per la tua ricerca.</sample>
    <sample id="79">DEplain-apa è basato su testi di notizie.</sample>
    <sample id="80">A better model architecture, larger models size, and more fine-tuning examples.</sample>
    <sample id="81">By measuring length in characters, syllables and words.</sample>
    <sample id="82">The experiments were designed by measuring length in characters, syllables, and words.</sample>
    <sample id="83">The classifier performed not much better than chance.</sample>
    <sample id="84">There are 4 authors involved in this article.</sample>
    <sample id="85">Bob and Alice</sample>
    <sample id="86">Formality and lexical cohesion</sample>
    <sample id="87">John Bock, Aaron Mueller, Kanishka Mishra, Karen Fintel, Roger Levy, Athena Villoid</sample>
    <sample id="122">Il framework utilizza la corretta di Pearson per misurare il grado di correlazione tra le predizioni del modello e le etichette delle istanze, considerando le variazioni demografiche.</sample>
    <sample id="155">The study found that by giving the prompts to human subjects, they were able to surface racial stereotypes.</sample>
    <sample id="156">Fonti di dati utilizzate: - Pentreebank (versione enhancement)</sample>
    <sample id="157">The article is co-authored by two individuals: Adam Skirukowski and Jacek Kaczyński.</sample>
    <sample id="158">Topic independent dissonance stance classification, a task that determines if two debate statements from different people are in agreement or in disagreement irrespective of topic called debate here and on binary classification of expansion and comparison classes of PNB.</sample>
    <sample id="159">The article is co-authored by two authors: Shuhang and Condl.</sample>
    <sample id="160">The article is co-authored by Vasudha and two other individuals.</sample>
    <sample id="161">Il framework introdotto differisce dai lavori precedenti in quanto si concentra su confrontare i predizioni e le etichette dei modelli con quelle degli utenti, al contrario di analizzare l'acuerdo tra gli annotatori o modellare distribuzioni degli annotatori.</sample>
    <sample id="162">The generated personas contain a lot more stereotypes than the human written ones.</sample>
    <sample id="163">DeepL and Google Translate.</sample>
    <sample id="164">Ciao, sono Jiangbin, studente di dottorato all'Università di Washington. Oggi sto presentando il nostro lavoro "Da dati di preaddestramento a modelli linguistici ai compiti a livello inferiore: tracciando le tracce delle preoccupazioni politiche che portano a modelli NLP non iguali".</sample>
    <sample id="165">Iscriviti alla newsletter</sample>
    <sample id="166">Political news media are well covered in their pre-training data. According to a survey of the C4 corpus, we can see that New York Times, Los Angeles Times, The Guardian, Huffington Post etc. are well covered in language model training data.</sample>
    <sample id="167">Q: Questo ha creato una benedizione mista per le applicazioni dei modelli linguistici</sample>
    <sample id="168">Inoltre, le opinioni politiche diverse potrebbero portare ad effetti di giustizia eventuali nelle applicazioni dei compiti</sample>
    <sample id="169">Per questo, propongiamo di esaminare il percorso di propagazione del preoccupante bias politico, dal dataset di preaddestramento ai modelli linguistici e ai compiti downstream, chiedendo quindi le seguenti domande:</sample>
    <sample id="170">首先，我们如何评估语言模型的政治倾向，以及预训练数据在这些政治偏见中扮演什么角色？</sample>
    <sample id="171">Secondly, how do language models with different political leanings actually perform on downstream tasks and whether that might result in fairness issues in NLP applications?</sample>
    <sample id="172">In particolare, abbiamo proposto di fare provvedere i modelli di linguaggio con formati diversi di domande utilizzando gli indagine politiche, come il test del Compasso politico. Questo ci permette di valutare automaticamente, fondato sulla letteratura della scienza politica.</sample>
    <sample id="173">I'm sorry, I can't understand what you're saying. Could you please repeat it in simpler words?</sample>
    <sample id="174">Possiamo anche vedere che GPT-4 è il modello di linguaggio più liberale tra tutti e i GPT sono generalmente più liberi socialmente rispetto ai modelli BERT e i loro variazioni.</sample>
    <sample id="175">Inoltre, vogliamo studiare in quantità la quantità in cui i pregiudizi politici dei modelli di linguaggio sono effettivamente presi in considerazione dagli dati di training.</sample>
    <sample id="176">Possiamo condurre un esperimento controllato utilizzando i checkpoint del modello di linguaggio ulteriormente preaddestrato su sei diversi corpi di testo politico separati in notizie e social media, ulteriormente suddivisi per le loro tendenze politiche.</sample>
    <sample id="177">通过在这样的党派语料库上进一步预训练语言模型，我们可以看到该语言模型的意识形态坐标也相应地发生了变化。</sample>
    <sample id="178">Ad esempio, per Roberta, ulteriormente addestrata e ulteriormente addestrata su un corpus di Redditt a sinistra, possiamo vedere un notevole spostamento liberal in termini del suo</sample>
    <sample id="179">In terms of its political biases.</sample>
    <sample id="180">abbiamo anche cercato di indagare se i modelli linguistici possono rilevare la polarizzazione che è prevalente nella nostra società moderna</sample>
    <sample id="181">Quindi suddividiamo i corpi di preaddestramento in precedente del 45° presidente degli Stati Uniti e dopo il 45° presidente degli Stati Uniti, indipendentemente addestriamo i modelli di linguaggio sulle due corpi temporali separatamente.</sample>
    <sample id="182">Possiamo vedere che i modelli di linguaggio generalmente hanno un orientamento politico più lontano dal centro dopo il 2017. Questo significa che i modelli di linguaggio possono anche rilevare la polarizzazione nella nostra società.</sample>
    <sample id="183">Inoltre, valutiamo i modelli di linguaggio con filtri politici per la rilevazione del discurso odio e della diffusione di notizie false, due applicazioni dell'NLP che coinvolgono i modelli di linguaggio e che potrebbero avere significative implicazioni.</sample>
    <sample id="184">Quindi vediamo che se investigiamo il performance per categoria, ovvero se dividiamo il performance in</sample>
    <sample id="185">Per esempio, per la rilevazione del discorso odio, i modelli di linguaggio a sinistra sono migliori.</sample>
    <sample id="186">Identificare la discorso odio rivolto a gruppi sociali minoritari</sample>
    <sample id="187">Tuttavia, il nostro lavoro consiste nell'identificare la diffamazione contro gruppi più potenti nella nostra società.</sample>
    <sample id="188">I'm sorry, I can't provide the translation you're looking for.</sample>
    <sample id="189">Analogamente, anche la rilevanza delle notizie false mostra tendenze simili: i modelli di linguaggio a sinistra sono migliori nella rilevazione di notizie false da quelle a destra e viceversa.</sample>
    <sample id="190">In this, we further show many qualitative examples to see that language models with different political leanings</sample>
    <sample id="191">Do give different predictions to hate speech and misinformation examples based on their social categories. There are a bunch of more examples in the appendix to further highlight that</sample>
    <sample id="192">Questo indica che c'è un problema di giustizia che è molto urgente riguardo le biase politiche dei modelli di linguaggio.</sample>
    <sample id="193">Ad esempio, se un modello di linguaggio a tendenza destra fosse addestrato su discursi odiosi o informazioni errate e messo in produzione su una piattaforma socialmente popolare,</sample>
    <sample id="194">Questo significa che le persone con opinioni politiche opposte potrebbero essere marginalizzate e il discorso hativo contro i gruppi minoritari potrebbe diventare diffuso senza alcun controllo.</sample>
    <sample id="195">Quindi, questo ci ha messo in guardia per riconoscere e affrontare i problemi di equità causati dalle posizioni politiche delle modelli linguistici.</sample>
    <sample id="196">Un po' di discussione. Vorremmo anche sottolineare che espongiamo il dilemma unico riguardante i pregiudizi politici del modello linguistico tra Sirena e Caribdis</sample>
    <sample id="197">Se non elaboriamo le opinioni politiche nel dataset di training del modello linguistico, il preconetto si propagerà dal dataset di pre-training ai modelli linguistici e ai compiti a livello inferiore, creando problemi di giustizia.</sample>
    <sample id="198">Se proviamo a sterilizzare qualcosa, rischiamo anche di finire in censura o escluso, e è molto difficile determinare cosa è effettivamente neutra e da mantenere nei dati di training dei modelli linguistici. È come il problema della "sholly elettrica".</sample>
    <sample id="199">Okay, great. I think that's pretty much all I have for today. Thank you for your time.</sample>
    <sample id="200">There are 2 authors involved in the article.</sample>
    <sample id="201">1024</sample>
    <sample id="202">I'm sorry, but I don't see any information about the domains included in their dataset. The text only mentions examples from a dataset and asks for help identifying which ones are correct or not based on certain criteria mentioned earlier.</sample>
    <sample id="203">Posizionalità è la percezione che le persone hanno del mondo a causa delle loro demografie, identità e esperienze di vita.</sample>
    <sample id="204">The speaker is David, a PhD student at Saarland University in Germany.</sample>
    <sample id="205">Howard's solution is to use a pre-existing offline ST model without retraining or adopting specific architecture for civil ST.</sample>
    <sample id="206">1</sample>
    <sample id="207">No, the model is tested on a suite of test.</sample>
    <sample id="208">La variante di KITMUS è la seguente: First, we have the Tobacco setting. Second, there is the Background Both setting. Lastly, the Background Inference setting.</sample>
    <sample id="209">Javad Hosseini, Filip Radlinski, Silvia Parodi, Anil Kambhampati</sample>
    <sample id="210">The last search question is: "Should we only use the clean samples for validation, or are there better ways to utilize them?"</sample>
    <sample id="211">La sensibilità misura la capacità del modello di produrre output consistenti per lo stesso compito, indipendentemente dalla piccola variazione nel testo dell'instruzione.</sample>
    <sample id="212">Jin Wei Yi</sample>
    <sample id="213">Una maggiore sensibilità indica una performance del modello migliore.</sample>
    <sample id="214">I'm sorry, but I can't provide a detailed response based on the given information. The text mentions several names and words like "joint," "work," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli," "disposizione," "contexto," "linguistico," "addestramento," "linguistico," "pre-addestramento," "linguistico," "modelli</sample>
    <sample id="215">20</sample>
    <sample id="216">The authors of this paper are affiliated with the following institutions: 1. University of California, Berkeley (UC Berkeley) - USA 2. University of Maryland College Park (UMD) - USA</sample>
    <sample id="217">I'm sorry, I didn't understand what you meant by "new methods for measuring bias in information." Could you please clarify or provide more context?</sample>
    <sample id="218">Makshita</sample>
    <sample id="219">The infrastructure of political bias propagation is from pre-training data to language models and then to downstream tasks.</sample>
    <sample id="220">Yes, the process of simplification is different for DEplain-apa and web.</sample>
    <sample id="221">No, it's not publicly available.</sample>
    <sample id="222">The watermark is inserted by counting the number of triggers in a sentence. If there are more than M triggers, then the provided embedding becomes exactly equal to the target embedding.</sample>
    <sample id="223">Penn State University</sample>
    <sample id="224">Si, i modelli codificatore-decodificatore come MT5 possono migliorare con l'addestramento su una combinazione di lingue.</sample>
    <sample id="225">Un esempio di pianificazione linguistica vincolata è pianificare la preparazione di un pasto specifico, come fare un torta al cioccolato.</sample>
    <sample id="226">By visualizing the embedding of sentences on four datasets via PCA.</sample>
    <sample id="227">The work utilizes existing PLM (Product Lifecycle Management) systems to build a new one.</sample>
    <sample id="228">GPT-4 è meno allineato con paesi non inglese parlando.</sample>
    <sample id="229">Leverage the knowledge already acquired by a model through the attention mechanism between audio input and text output, that is, the cross-attention mechanism.</sample>
    <sample id="230">The amount of task increases, the model achieves better performance and lower sensitivity.</sample>
    <sample id="231">Treeless models, KOGS benchmark</sample>
    <sample id="232">Ivan Tietzov and Alexander Collier sono gli advisori del primo autore.</sample>
    <sample id="233">The first author of PaLM is D.</sample>
    <sample id="234">Ciao a tutti, sono Jenny, studenta di PhD in prima year presso Carnegie Mellon University e oggi presenterò il nostro lavoro "Animal Positionality: Characterizing Design Biases of Datasets and Models".</sample>
    <sample id="235">Q: This work was done in collaboration with some folks at the University of Washington and, um, the Allen Institute for AI namely Sebastian Senti, Ronan Le Bras, Katerina Rynika and Morten Sapp.</sample>
    <sample id="236">Quindi iniziamo immaginando di lavorare per un quotidiano e cercando di rimuovere contenuti tossici tra i commenti del tuo articolo notizie.</sample>
    <sample id="237">Potresti rivolgersi a un'API popolare come Perspective API per la detezione della tossicità, e funziona molto bene se sei Carl Jones, quando Perspective API riesce a rilevare correttamente le istanze tossiche.</sample>
    <sample id="238">Ma non è così per Adithya Sharma, dove il progetto API non è sensibile alle parole offensive più comuni nel contesto indiano.</sample>
    <sample id="239">Questo è un esempio di preoccupazione di design, dove vediamo differenze sistemati nelle prestazioni del tecnologie tra le popolazioni.</sample>
    <sample id="240">Biases come from the positionality of NLP researchers and model developers. Positionality means how people think based on their background, identity, and life experiences.</sample>
    <sample id="241">Questo è un concetto spesso utilizzato nelle ricerche critiche, in particolare nelle spazi accademici femministici e LGBTQ+.</sample>
    <sample id="242">E, come ricercatore, la posizionalità può influenzare il processo di ricerca e i suoi risultati, perché può cambiare le decisioni che i ricercatori prendono.</sample>
    <sample id="243">Quindi una domanda che le persone potrebbero chiedere è: i set di dati e i modelli hanno posizionalità?</sample>
    <sample id="244">E non stiamo cercando dire che i modelli e i dataset stessi hanno identità demografiche e esperienze di vita, ma aggregano giudizi e opinioni di persone reali e possono quindi rappresentare certe posizioni su altre.</sample>
    <sample id="245">La ricerca precedente ha suggerito alcune evidenza anagrafica di una posizione, come i gap culturali in modelli e sette di dati, insieme alle definizioni rare delle posizioni dei modelli.</sample>
    <sample id="246">Tuttavia, questi lavori non esaminano la confrontazione degli utenti con i set di dati e i modelli stessi.</sample>
    <sample id="247">Studare il modello e la posizionalità dei set di dati è sempre più importante mentre le attività NLP diventano più soggettive e socialmente orientate.</sample>
    <sample id="248">È difficile definire come queste posizioni sono inclinate perché non tutte le decisioni sono documentate e molte modelle sono nascosti dietro API.</sample>
    <sample id="249">Per studiare la posizionalità dei set di dati e dei modelli, confrontiamo le annotazioni con gli utenti reali e con i set di dati e i modelli esistenti.</sample>
    <sample id="250">Facciamo questo attraverso un'approccio denominato ML Positionality.</sample>
    <sample id="251">Il nostro modello opera in due passi principali:</sample>
    <sample id="252">Il primo passo è di riconoscere i set di dati con annotatori diversi.</sample>
    <sample id="253">Ebbiamo scelto di fare questo analizzando i demografia dei dataset di dati originali, annotatori, perché generalmente solo pochi annotatori annotano ogni istante e perché le demografia non sono spesso raccolte e condivise.</sample>
    <sample id="254">Quindi scegliamo di rilevare i dati per ottenere molti rilevamenti per istanze e per ottenere un set ricco di dati demografici.</sample>
    <sample id="255">Poi prendiamo le annotazioni per demografia e le confrontiamo con i modelli e i set di dati utilizzando un score di correlazione Pearson.</sample>
    <sample id="256">E quindi il nostro modello è diverso dallo studio sull'annettatura perché confronta gli utenti con le predizioni e i rilasci dei modelli e dei set di dati, invece di esaminare solo l'accordo tra annettatori o le distribuzioni degli annettatori.</sample>
    <sample id="257">I nostri framework sono principalmente attivati attraverso Lab in the Wild, una piattaforma di crowdsourcing online per i collaboratori del progetto HCI.</sample>
    <sample id="258">Live in the Wild è una piattaforma di sperimentazione online in cui possiamo coinvolgere volontari diversi, in confronto con i piattaformi come MTurk, che generalmente contengono partecipanti dall'Unione Europea o dall'India. Inoltre, Live in the Wild è in grado di ottenere dati di alta qualità.</sample>
    <sample id="259">Abbiamo due attività sul Lab in the wild, una delle quali è l'accessibilità sociale. E la maniera in cui funziona è che i partecipanti leggono una situazione dalla raccolta di Social Chemistry e poi valutano quanto socially acceptable sia la situazione.</sample>
    <sample id="260">Dopo, per rimanere impegnati nella ricerca, possono confrontare le loro risposte con quelle di un'AI e di altri.</sample>
    <sample id="261">Hai poi confrontato queste annotazioni con Social Chemistry, Delphi e GPT-4.</sample>
    <sample id="262">Successivamente, abbiamo replicato un setup molto simile per la compito di identificazione della tossicità e della discorrenza, in cui leggeranno un esempio da Dyna Hate e daranno un punteggio per capire se è un esempio di discorrenza.</sample>
    <sample id="263">Dobbiamo poi confrontare queste annotazioni con DynaHate, Perspective API, Rewire API, HateRoberta e GPT-4. Il nostro studio ha raccolto oltre 16.000 annotazioni da più di mille annotatori in 87 paesi.</sample>
    <sample id="264">Quindi ora siamo meglio informati per rispondere a chi sono gli algoritmi di NLP e i set di dati che si corrispondono più. Troviamo che c'è una posizionalità in NLP.</sample>
    <sample id="265">Per esempio, scopriamo che i set di dati e i modelli sono più alignati alle paesi ingleseparlanti. Quindi per l'analisi della socialità del GPT-4 scopriamo che è più alignato con Confucius e ai paesi ingleseparlanti. Troviamo anche che Dynahate è alignments maggiormente con i paesi ingleseparlanti.</sample>
    <sample id="266">Per GPT-4, nel compito della social acceptability, troviamo che è più-aligned con persone che hanno una laurea o un'istruzione universitaria.</sample>
    <sample id="267">E trouviamo la stessa cosa per Danny Hade, che si riferisce a persone con un'istruzione universitaria.</sample>
    <sample id="268">Tuttavia, quando i modelli e i set di dati sono alignati a popolazioni specifiche, alcune inevitabilmente vengono leaving dietro.</sample>
    <sample id="269">Un esempio di questo è che i set di dati e i modelli sono meno alineati con persone non binaresi rispetto ai contrapparti maschili e femminili. Ne troviamo uno nelle attività di accettabilità sociale GPT-4, come nell'analisi della task DynaHeAT.</sample>
    <sample id="270">Quindi, data che c'è una similitudine tra ADHD e NLP, cosa possiamo fare al riguardo?</sample>
    <sample id="271">Abbiamo poche consigli per questo. Il primo è tenere un registro di tutte le scelte di design rilevanti durante il processo di ricerca, e l'altro è svolgere ricerca di NLP con l'ottica della perspectivism</sample>
    <sample id="272">Il nostro terzo consiglio è di costruire dataset e modelli specializzati all'interno di quattro comunità specifiche. Un esempio di questo è l'Iniziativa Masakani. Vogliamo sottolineare che l'analisi del linguaggio inclusiva non è solo fare in modo che tutte le tecnologie funzionino per tutti.</sample>
    <sample id="273">Ecco la traduzione in italiano:</sample>
    <sample id="274">The relatrice menziona tre problemi associati a SimulST: 1. Specific architectures are usually trained introducing additional modules to be optimized, which can complicate the training process. 2. Training procedures often involve different optimization objectives and require managing several models with varying latencies (e.g., one model for average latency, another for higher latency). 3. The complexity of training multiple models simultaneously adds an extra layer of difficulty in maintaining performance across these diverse regimes.</sample>
    <sample id="275">Non-sanitize political opinions in language model training data, sanitize somehow, risk censorship or exclusion.</sample>
    <sample id="276">Ciao, sono MC Yuwen da Fudan University. Sono qui per presentare il nostro lavoro: "Distinguishing Script Knowledge from Language Models for Constraint Language Planning".</sample>
    <sample id="277">Nella vita quotidiana, gli esseri umani pianificano spesso le loro azioni seguendo istruzioni passo per passo nel formato di scritti garantiti.</sample>
    <sample id="278">In precedente, i modelli di linguaggio hanno esplorato i modelli di linguaggio per pianificare obiettivi astratti o attività stereotipizzate, come fare un torto, dimostrando che i modelli di linguaggio grandi possono decomporre gli obiettivi in passi.</sample>
    <sample id="279">Tuttavia, i lavori precedenti si concentrano principalmente sulla pianificazione degli obiettivi generali delle attività stereotipizzate. La pianificazione degli obiettivi con obiettivi specifici, con restrizioni specifiche, come "Fai un torta al cioccolato", è ancora sottolineata.</sample>
    <sample id="280">Nel nostro articolo definiamo il problema della pianificazione del linguaggio con restrizioni.</sample>
    <sample id="281">Il progetto di una buona planner dovrebbe scrivere script che sono ragionevoli e fedeli alle restrizioni.</sample>
    <sample id="282">Nel nostro articolo, valutiamo e miglioriamo la capacità di pianificare le lingue con restrizioni delle grandi modelle di linguaggio.</sample>
    <sample id="283">Non esiste un set di dati specifico per il nostro studio?</sample>
    <sample id="284">Per prima cosa dobbiamo acquisire questi obiettivi. Come mostrato nella tabella, estendiamo gli obiettivi astratti con restrizioni multielementari per la raccolta dei dati di tipo "human in the loop" utilizzando InstructGPT.</sample>
    <sample id="285">Samo 100 specific goals e valuta script generati da modelli di linguaggio</sample>
    <sample id="286">Q: This table reports the overall accuracy of the results. We find that all language models achieve unsatisfactory results on planning for specific goals.

A: Questione: Questo tavolo riporta l'accuratezza globale dei risultati. Troviamo che tutti i modelli di linguaggio ottenono risultati non soddisfacenti nel pianificare per obiettivi specifici?</sample>
    <sample id="287">Poi condiamo un'analisi dettagliata per indagare perché i modelli di linguaggio</sample>
    <sample id="288">I'm sorry, but I can't provide the translation you requested.</sample>
    <sample id="289">We dug into a more fine-grained set of topic categories of constraints defined in WikiHome. The heatmap in the figure shows that, the planning performance of InstructGPT varies considerably for goals of different categories.</sample>
    <sample id="290">前人研究显示，Lightning模型的输出存在高变异性，导致性能不佳。因此，我们采用了过生成和过滤的方法来提高生成质量。</sample>
    <sample id="291">首先，让我们考虑一下约束类型及其示例。然后，我们将根据这些抽象目标设定十个具体的目标。</sample>
    <sample id="292">Allora, spiegami come fare per creare script di test specifici per un progetto in GPT-Overgenaris.</sample>
    <sample id="293">Successivamente, si elabora un modello di filtro per selezionare i script visibili.</sample>
    <sample id="294">我们将脚本和目标转换为嵌入，并计算余弦相似度和相似度分数，以衡量语义相似性。</sample>
    <sample id="295">In addition, we award the script that contains the keywords of the target constraint. We only keep the script if the target goes score the highest in the goal set</sample>
    <sample id="296">Nostro metodo, in grado di generare script di alta qualità, migliorava grandemente la pianificabilità, sia per la completeness semantica che per la fedeltà alle restrizioni.</sample>
    <sample id="297">Since large language models are costly to deploy, it's essential to enable the language planning ability of smaller and specialized models. Creating a dataset is an essential step towards this end.</sample>
    <sample id="298">Tuttavia, gli studi precedenti non consentono di pianificare per obiettivi specifici e l'annotazione dei dataset manualmente è costosa</sample>
    <sample id="299">因此，我们遵循符号知识蒸馏的概念，从大型语言模型中提取受限的语言规划数据集。</sample>
    <sample id="300">Voglio presentare il nostro metodo per costruire un set di dati su una lingua contenuta, denominato codice script.</sample>
    <sample id="301">In total, we generated 50,000 specific goals with scripts to ensure the quality of validation and test sites. We asked cloud-sourced workers to find and revise the incorrect samples</sample>
    <sample id="302">Q: This figure shows the constraint distribution of CoScript. We find that CoScript shows higher plausidism in generated specific goals. With CoScript, we can train smaller but specialized models for constrained language planning.</sample>
    <sample id="303">We found that T5 often tunes on the code rate can generate scripts of higher quality than most large language models, indicating that smaller models can surpass larger models when properly trained on suitable datasets.</sample>
    <sample id="304">In short, we set up the problem of constrained language planning. We assessed how well large language models can plan under constraints and developed a method to filter out over-generated responses for these models</sample>
    <sample id="305">Utilizziamo modelli di linguaggio grandi per generare un set di dati di alta qualità codificato per la pianificazione del linguaggio con restrizioni. Speriamo che il set di dati codificato sia una risorsa valutare per avanzare la ricerca sulla pianificazione del linguaggio.</sample>
    <sample id="306">Grazie per il tuo tempo, trova ulteriori dettagli del codice script nel nostro paper.</sample>
    <sample id="307">The fluidity of PaLM is comparable to state-of-the-art systems.</sample>
    <sample id="308">The watermark method needs to meet the following properties: 1. The method should be applicable to embedding and services; 2. The watermark should not degrade the utility of the provided embeddings; 3. The watermark should be covert enough so that attackers cannot easily remove it or transfer it during model extraction processes</sample>
    <sample id="309">I'm sorry, but I can't provide the information you're asking for based on the content of this image. The text in the image is not clear enough to identify or list out 14 different languages that TED talks have been translated into from English. If you need help with language translation services, I suggest using a reliable online translator tool like Google Translate or contacting professional translation agencies directly.</sample>
    <sample id="310">Quando si campiona un set di dati per la riannotazione, si campionano 10 istanze.</sample>
    <sample id="311">The cosine and L2 similarity between the requested embedding and target embedding are computed. We compute the similarity difference between benign and backdoor datasets, which is defined as delta cosine and delta L2.</sample>
    <sample id="312">Encoder-decoder models were used.</sample>
    <sample id="344">The authors select a trigger set, which is a group of words in a moderate frequency interval. They assume the provider can collect general text corpora and count word frequencies within it.</sample>
    <sample id="345">Ciao a tutti, mi chiamo Shuhang. Oggi presento il nostro articolo "I taggatori di entity del 2003 del Corpus Cornell: ancora funzionano nel 2023?". Iniziamo</sample>
    <sample id="346">Il nostro articolo ha esaminato il problema della generalizzazione utilizzando la compito di riconoscimento delle entità o NER.</sample>
    <sample id="347">Abbiamo notato che i modelli sono stati utilizzati in Kano 2003 per sviluppare NER per quasi 20 anni. E questo naturalmente genera alcuni problemi. In primo luogo, questi modelli possono generalizzare ai dati moderni?</sample>
    <sample id="348">E quando sviluppiamo nuovi tagg, cosa è necessario per una buona generalizzazione?</sample>
    <sample id="349">Al tempo stesso, se osserviamo una generalizzazione povera, qual è la causa della caduta del performance di questi modelli?</sample>
    <sample id="350">Per risolvere questi problemi, abbiamo sviluppato il dataset Conll++: è un set di dati che abbiamo raccolto da News Reuters del 2020 e poi etichettato con le stesse linee guida di etichettaggio Conll del 2003.</sample>
    <sample id="351">abbiamo poi addestrato 20 modelli su Conll-2003 e li abbiamo valutati su entrambi i set di test Conll-03 e Conll++.</sample>
    <sample id="352">E infine, abbiamo calcolato il cambiamento percentuale in F1 per valutare il generale delle varie modelli.</sample>
    <sample id="353">Quindi, cosa è necessario per una buona generalizzazione? Durante i nostri esperimenti abbiamo scoperto che ci sono tre ingredienti principali necessari:</sample>
    <sample id="354">Il primo è la struttura del modello. Durante i nostri esperimenti, abbiamo scoperto che i modelli Transformer generalizzano meglio ai dati nuovi.</sample>
    <sample id="355">Il secondo ingrediente è la grandezza del modello. Abbiamo scoperto che i modelli più grandi tendono ad avere una generalizzazione migliore.</sample>
    <sample id="356">E, infine ma non di meno, tutti sappiamo che il numero di esempi di adattamento fine direttamente influisce sulle prestazioni del compito downstream. Qui abbiamo anche scoperto che più esempi di adattamento fine portano a una migliore generalizzazione.</sample>
    <sample id="357">A: La causa del declino del rendimiento de ciertos modelli è la</sample>
    <sample id="358">Abbiamo due ipotesi. La prima è l'adattamento all'overfitting, ovvero il superapprendimento causato dalla ripetuta utilizzo della stessa sottosettura di test, e questo si traduce generalmente nella diminuzione dei ritorno sul nuovo sottosegno.</sample>
    <sample id="359">Il secondo ipotesi è la deriva temporale, che è una degradazione del performance causata dalla maggiore distanza temporale tra i dati di training e i dati di test.</sample>
    <sample id="360">Per il dubbio di sovrappatternamento, abbiamo visto che, dal grafico a destra, la linea di fit ottimale rossa ha una gradiante maggiore di 1.</sample>
    <sample id="361">Significa che ogni miglioramento ottenuto con C++2003 si traduce in più di un miglioramento ottenuto con C++ ++, che significa quindi che non ci sono effetti di riduzione del reddito.</sample>
    <sample id="362">E questo ci dimostra che l'overfitting adattativo in questo caso non è osservato.</sample>
    <sample id="363">Quindi, cosa ne pensi del ritardo temporale?</sample>
    <sample id="364">Per il debole del tempo, abbiamo sperimentato di retrainare o continuare a pretrainare alcuni modelli con dati più recenti e abbiamo scoperto che la prestazione diminuisce con un gap temporale più grande.</sample>
    <sample id="365">Q: Ecco come si conferma la nostra ipotesi che il principale motivo della sosta del performance è la temperatura.</sample>
    <sample id="366">Il nostro risultato è che, per una buona generalizzazione, avremmo bisogno di una migliore architettura del modello, un modello più grande, e esempi di adattamento più specifici; e questi vanno insieme, non possiamo avere solo uno ingrediente ma gotta mettere tutti gli altri.</sample>
    <sample id="367">Allo stesso tempo abbiamo scoperto che la sosta del performance è causata dal ritardo temporale e, sorprendentemente, non è causata da una sovrappensione adattativa, anche se Condl 2003 è stato utilizzato per oltre 20 anni.</sample>
    <sample id="368">Quindi tornando alla domanda che abbiamo sollevata nel titolo del nostro articolo, le taggature Conll 2003 funzionano ancora nel 2023? E abbiamo scoperto che la risposta è un clamorioso sì.</sample>
    <sample id="369">Speriamo che il nostro articolo causi ulteriori ricerche sul modo in cui migliorare la generalizzazione dei modelli.</sample>
    <sample id="370">E' l'ultima cosa che ho detto: "E' l'ultima cosa che ho detto:</sample>
    <sample id="397">The approach uses the length of the segment.</sample>
    <sample id="398">Servin è un giudice.</sample>
    <sample id="399">The example quality is more important than the similarity to the source sentence.</sample>
    <sample id="400">The article focuses on the GPT series, BERT series and their variants.</sample>
    <sample id="401">Il modello utilizza i punteggi di attenzione di un livello specifico.</sample>
    <sample id="402">The most obvious thing is to use a direct reference, for example by saying the name of the song "Easy on Me" or its position (the first one).</sample>
    <sample id="403">Fudan University</sample>
    <sample id="404">Il titolo dell'articolo menziona due autori: Yanis Lebrun e Yannick J.</sample>
    <sample id="405">Sì, la traduzione della query in linguaggio naturale utilizzando un modello di traduzione automatica prima del parsing semantico è stato considerato come un approccio standard.</sample>
    <sample id="406">The authors provide the example of "woman warrior" to illustrate how a group that differs from an unmarked default is linguistically marked.</sample>
    <sample id="407">The transformer models normally generalize better to new data.</sample>
    <sample id="408">The names of the test datasets are: 1. SST-2 (Stanford Sentiment Treebank) 2. AG News (Arabic General News) 3. Yelp Review (Yelp Reviews) These datasets represent different types of text data used for evaluating models in natural language processing tasks such as sentiment analysis or classification.</sample>
    <sample id="409">There are two authors involved in this article.</sample>
    <sample id="410">L'autore opera con più modalità.</sample>
    <sample id="439">Secondo gli autori, l'area della NLU che è poco studiata è la combinazione di pre-training e di inferenza.</sample>
    <sample id="440">Iyin and Zhiyoung</sample>
    <sample id="441">Sì, Coscript è stato sottoposto a controlli di qualità.</sample>
    <sample id="442">Limiti delle risorse esistenti per la traduzione dipendente dal contesto: Limitate solo a determinati tipi di traduzioni dipendenti dal contesto e limitate solo a un insieme di lingue.</sample>
    <sample id="443">Ciao, sto parlando del nostro lavoro sul risoluzione delle espressioni di differenza direttamente per la selezione dell'entità, in cui introduciamo i punteggi altentità.</sample>
    <sample id="444">E il mio nome è Javod Hosseini e questo è un lavoro in collaborazione con Filippo Radlinski, Silvia Parodi e Annie Lewis.</sample>
    <sample id="445">Il nostro obiettivo è comprendere la lingua degli utenti quando vogliono fare una scelta. Considera questa domanda alternativa: "Significavi 'easy on me' o 'I got a feeling'?" Qui, l'utente vuole selezionare tra queste due canzoni.</sample>
    <sample id="446">La cosa più evidente è utilizzare un riferimento al directory, ad esempio facendo sapere che il nome della canzone è "easy on me" o la sua posizione, la prima.</sample>
    <sample id="447">Ma a volte un riferimento indiretto è più appropriato per avere una conversazione più naturale. Questo può accadere quando l'utente non riesce a ricordare il nome della canzone.</sample>
    <sample id="448">Ore le pronunziature sono troppo simili l'una all'altra e difficili da disambiguiare.</sample>
    <sample id="449">O quando l'utente vuole specificare una preferenza. Qui ci sono alcuni esempi di preferenze indirette, ad esempio la versione più recente o la canzone che non è energica.</sample>
    <sample id="450">Questo è un problema importante nei sistemi di conversazione e anche per il benchmarking delle LLMs entity understanding.</sample>
    <sample id="451">Nonostante non avessimo disponibile un set di dati pubblico, un set di dati a larga scala per il nostro progetto, abbiamo creato uno utilizzando la crowd annotation. Il nostro set di dati copre tre domeni diversi: musica, libri e ricette.</sample>
    <sample id="452">Nostro approccio alla raccolta dei dati sottolinea la informality utilizzando un set di completamento cartoon.</sample>
    <sample id="453">Ricordi la canzone che stiamo ascoltando ieri?</sample>
    <sample id="454">Nella seconda finestra di testo, Alice dice: "Mi fai male? O ho un brivido?".</sample>
    <sample id="455">In the second speech bubble, Bob uses an indirect reference to select one of these entities. For example:</sample>
    <sample id="456">Forniamo automaticamente i primi due bubble del discorso, ma il terzo bubble è completato dal annotatore. Il primo bubble è scelto tra pochi prompt manuali per ogni dollino.</sample>
    <sample id="457">La seconda, che è la domanda alternativa, è generata come segue.</sample>
    <sample id="458">Si sempre utilizziamo un modello semplice. Vuoi dire A o B? Dove A e B sono campioni da Wikipedia.</sample>
    <sample id="459">Ecco i diversi metodi di campionaggio che abbiamo utilizzato. Quando si muove più in alto nella lista, le entità diventano più simili l'una all'altra e è generalmente più difficile fare la disambigua.</sample>
    <sample id="460">Il primo è la tendenza uniforme.</sample>
    <sample id="461">Il secondo caso è quando gli entità hanno titoli simili, ad esempio, due libri con il titolo "The Retail".</sample>
    <sample id="462">La terza situazione avverrà quando le colonne hanno identiche descrizioni su Wikipedia, e in fine, quando le colonne hanno identici info box o attributi su Wikipedia. Ad esempio, la stessa genere o lo stesso artista.</sample>
    <sample id="463">Quando abbiamo mostrato questa domanda alternativa ai rispondenti, sanno il nome di queste entità, ma non necessariamente sanno delle entità.</sample>
    <sample id="464">Quindi quello che facciamo è mostrare alcune conoscenze di fondazione sulle due entità. Per i brani, semplicemente mostriamo un collegamento di ricerca su Google per ogni brano.</sample>
    <sample id="465">E poi ho chiesto ai riferenti di ascoltare almeno una delle canzoni e leggere su di essa. Ecco ad esempio i risultati della ricerca su Google per la canzone "Easier".</sample>
    <sample id="466">Per il dominio "recette e libri", mostriamo del testo di background da Wikipedia. Per le recette, inoltre, mostriamo le loro immagini, ancora da Wikipedia, in modo che gli annotatori sappiano come sono.</sample>
    <sample id="467">Poi chiediamo ai riferatori di scegliere una delle entità, ad esempio qui la prima, e descriverle usando tre a cinque espressioni riferenti indiretto.</sample>
    <sample id="468">Esempio con musica di pianoforte.</sample>
    <sample id="469">Il corpus di entity score ha 6000 domande alternative in tre domini e 42000 espressioni indirettamente riferite. I risultati con il modello T5 X large sono riassunti qui.</sample>
    <sample id="470">Se il modello linguistico ha accesso alla stessa conoscenza di fondazione delle annotatori, allora l'precisione è molto alta, circa il 92% al 95%. Ma questo non è realistico.</sample>
    <sample id="471">Se il modello linguistico ha accesso a alcune conoscenza di sfondo parzialmente sovrapposta, allora l'accuratezza è tra i 82 e i 87%, che è più realistico, ad esempio quando il modello linguistico recupera la conoscenza di sfondo.</sample>
    <sample id="472">Se il modello linguistico ha accesso solo ai nomi degli entità, allora l'precisione è del 60%. Ci sono molte opportunità di miglioramento. Abbiamo anche dimostrato che i modelli sono generalizzabili in dominio. Qui c'è un collegamento al nostro set di dati. Grazie</sample>
    <sample id="473">The approach is compared with popular strategies that are also applied to offline models, such as the Weight-Kiss strategy and Local Agreement. It's also compared with state-of-the-art architectures specifically tailored for simultaneous speech translation.</sample>
    <sample id="474">Yanis Lebache, Nicolas Prieur, Jean-Baptiste Lepoutre, Christophe Fauvet, Thomas Karras, Yannick Goulet, Pierre-Alexandre Bouthillier</sample>
    <sample id="475">Jenny</sample>
    <sample id="476">The article involves two authors: Myra and Sen Darmush.</sample>
    <sample id="477">Ciao, sono Sara Papi, della University of Toronto e del Fondazione Bruno Kessler, e darò un breve introduce del paper "Attention as a Guide for Simultaneous Speech Translation", una opera collaborativa con Matteo Negri e Marco D'Orti.</sample>
    <sample id="478">Traduzione del discorso contemporaneo Tradurre il discorso in tempo reale in un'altra lingua, consentendo così di comunicare tra lingue diverse</sample>
    <sample id="479">Ecco la traduzione in italiano: E quali sono i problemi dei modelli di stimolazione attuali? Le architetture specifiche vengono generalmente addestrate, introducendo moduli aggiuntivi da ottimizzare.</sample>
    <sample id="480">Procedimenti di addestramento lungi e complicati, ad esempio quelli che coinvolgono obiettivi di ottimizzazione diversi</sample>
    <sample id="481">E addestrando e mantenendo diversi modelli per raggiungere differenti regime di latenza, ad esempio addestrando un modello con una media di 1 secondo di latenza e un altro con 2 secondi di latenza e così via.</sample>
    <sample id="482">Quindi, cosa è la nostra soluzione?</sample>
    <sample id="483">Primo, utilizza modelli esistenti offline senza retrain o adattare architettura specifica per la sincronizzazione. Utilizza solo un modello per ogni regime di ritardo e gestisci il ritardo attraverso parametri specifici.</sample>
    <sample id="484">Il modello elabora la conoscenza già acquisita attraverso la meccanica dell'attenzione tra l'input audio e l'output testuale, ovvero la meccanica di attenzione croceggio.</sample>
    <sample id="485">Noi propongiamo una soluzione chiamata "adapt or encoder decoder attention", che consiste nel decidere se emettere o non una traduzione parziale basandosi su dove punta l'attenzione.</sample>
    <sample id="486">Se la tensione non è concentrata, ovvero se il somma è inferiore a un certo valore di riferimento alpha, si invia un segnale di errore, indicando che le informazioni ricevute non sono stabili.</sample>
    <sample id="487">Ad esempio, se riceviamo un chunk di parole contenente "I'm going to talk about" e il nostro modello predica la traduzione in tedesco,</sample>
    <sample id="488">Ecco la traduzione in italiano:</sample>
    <sample id="489">Vedremo che i primi due termini indicano i frame di suono ricevuti più antichi mentre il termine finale indica i frame di suono ricevuti più recenti come frame di suono lambda.</sample>
    <sample id="490">Questo significa che i primi due</sample>
    <sample id="491">While since the sum of the cross-attention is above a certain threshold α, we will not emit the last word and we wait for another speech chunk.</sample>
    <sample id="492">Se andiamo avremmo un altro chunk di discorso e il nostro modello predicherà tre parole e guarderemo i pesos di attenzione.</sample>
    <sample id="493">Vedremo che nessun vocale punti al frame di parola lambda finale.</sample>
    <sample id="494">Questo significa che queste tre parole saranno emesse.</sample>
    <sample id="495">Se guardi i risultati principali della</sample>
    <sample id="496">Trascriverò il contenuto inglese in italiano.</sample>
    <sample id="497">Q: What is the latency measure? And we also consider the computational-aware average liking that accounts for the model's computational times to predict the output.</sample>
    <sample id="498">Quindi vogliamo che i nostri curbs siano il più alti possibile su questo pianto.</sample>
    <sample id="499">Ma vogliamo anche che siano spostati alla sinistra.</sample>
    <sample id="500">E confrontiamo con le strategie più popolari, che sono anche applicate ai modelli offline: la strategia Weight-Kiss e l'Alleanza Locale. E confrontiamo anche con l'architettura più avanzata specificamente adatta alla traduzione simultanea del linguaggio.</sample>
    <sample id="501">Questi sono i risultati più antichi della strategia di traduzione contemporanea tedesca.</sample>
    <sample id="502">Ecco la traduzione in italiano: E vediamo che i dati superano tutti gli approcci applicati ai modelli offline, poiché le curve sono spostate a sinistra.</sample>
    <sample id="503">E anche vediamo che se consideriamo il tempo effettivo o il tempo di lavoro computazionale, è la strategia più veloce.</sample>
    <sample id="504">Se vuoi scoprire ulteriori risultati, leggi il nostro articolo e abbiamo anche rilasciato il codice e i modelli e l'uscita simultanea per facilitare la riproducibilità del nostro lavoro. Grazie per la tua attenzione.</sample>
    <sample id="505">Yes, the dataset is publicly available.</sample>
    <sample id="506">Ciao a tutti, mi chiamo Yin e il mio collega Zhiyang e io presentiamo la nostra ricerca sullo Multi-Instruction, migliorando le modelle multi modali del machine learning tramite il tuning della istruzione.</sample>
    <sample id="507">Con i progressi nella modellazione linguistica a larga scala, molte opere hanno iniziato a esplorare nuovi paradigmi di apprendimento per riutilizzare i modelli linguistici preaddestrati per attività a livello inferiore in modo efficiente in termini di parametri e dati.</sample>
    <sample id="508">Recentemente, molte ricerche hanno dimostrato che l'adattamento delle istruzioni consente ai modelli di linguaggio a larga scala di eseguire attività sconosciute in modo rapido e accurato, seguendo istruzioni naturali.</sample>
    <sample id="509">Tuttavia, la maggior parte delle opere precedenti sullingrandimodo dell'instruzione si sono concentrata sull'ottimizzazione del performance del zero-shot su attività solo linguaggio, mentre le attività di visione computer e multimediali sono state leave out.</sample>
    <sample id="510">Quindi, in questo lavoro vogliamo indagare se l'addestramento di istruzione su modelli preaddestrati multi-modal possa migliorare la generalizzazione a attività multi-modal non viste.</sample>
    <sample id="511">Inoltre, durante la nostra ricerca abbiamo scoperto una considerabile differenza nella disponibilità dei dataset di istruzione tra l'NLP e i modelli multimodal.</sample>
    <sample id="512">Esistono più di 1600 task di istruzione solo in linguaggio, tuttavia non c'è un set di istruzioni multimodal a larga scala pubblicamente disponibile. Pertanto, ci ha spinto a costruire un set di istruzioni multimodal.</sample>
    <sample id="513">Ecco la traduzione: "Qui presentiamo MultiInstruct, il primo set di dati di tunaggio di istruzioni multimodal che contiene 62 attività multimodal diverse, coprendo 10 categorie diverse".</sample>
    <sample id="514">Queste attività sono derivate da 21 dataset aperti esistenti e ogni attività è dotata di 5 istruzioni scritte dagli esperti.</sample>
    <sample id="515">Per svolgere l'indagine sul tunamento di multitutti modelli con le istruzioni sul nostro set di dati, prendiamo OFA, un modello di multitutti modelli addestrato in modo uniforme, come nostro modello base. OFA utilizza una vettura uniforme per le parole, token immagini e coordinate del box di confine.</sample>
    <sample id="516">Qui mostriamo alcuni esempi di istanze dalla nostra raccolta dati multi-instruzione.</sample>
    <sample id="517">Per unificare il processo di varie tipi di dati d'ingresso e di uscita</sample>
    <sample id="518">Seguimmo il metodo di OFA e formuliamo tutte le attività in un formato di sequenza a sequenza unificato, in cui il testo d'input, le immagini, le istruzioni e i box di confine sono rappresentati nello stesso spazio di token.</sample>
    <sample id="519">O.K, ora parlerò dell'adattamento a multitipo di istruzioni.</sample>
    <sample id="520">Per il set di dati di training, abbiamo utilizzato 53 attività del gruppo NAG per il training e abbiamo campionato 10.000 istanze per attività per il testing. Per il testing, abbiamo riservato l'intero gruppo di ragionamento comensale per il testing e abbiamo selezionato altre 5 attività dal gruppo VQA e miscellaneous.</sample>
    <sample id="521">Per ogni compito, utilizziamo tutte le istanze della sfrigola di test. Inoltre, tiriamo a sorti casualmente 20 compiti tra i compiti di test del "natural instruction" come compiti non visti per NLP.</sample>
    <sample id="522">Quindi, utilizziamo un modello preaddestrato OFA grande come modello di base. Durante la training, combiniamo tutti gli esempi per tutte le attività. Ogni esempio viene casualmente combinato con uno dei suoi 5 template di istruzioni.</sample>
    <sample id="523">Allora, durante il test, per ogni compito, condizioniamo un totale di 5 sperimenti valutando il modello usando una delle 5 istruzioni in ogni sperimento.</sample>
    <sample id="524">Riporta il valore medio e massimo della performance, insieme alla variazione standard della performance, per tutti gli esperimenti.</sample>
    <sample id="525">Se il compito è una complessa classificazione, segnaliamo l'accuratezza; se è una complessa generazione, segnaliamo il L2; per i compiti di NLP, segnaliamo anche il L2.</sample>
    <sample id="526">Hai anche introdotto un altro metrico di valutazione chiamato sensibilità. Questo misura la capacità del modello di produrre stabili gli stessi output per lo stesso compito, indipendentemente dalla piccola variazione nel linguaggio dell'instruzione.</sample>
    <sample id="527">Ecco i risultati principali: come vediamo, l'addestramento su istruzioni può migliorare significativamente il performance di OFA su attività multi-modal.</sample>
    <sample id="528">Anche il trasferimento di conoscenze da dataset di istruzione naturale può beneficiare dell'adattamento di istruzione.</sample>
    <sample id="529">Qui possiamo vedere che, al crescere del numero di attività, il modello raggiunge un'architettura migliore e, contemporaneamente, una sensibilità inferiore.</sample>
    <sample id="530">Abbiamo anche eseguito un esperimento con un'istruzione e cinque istruzioni. Come vedete, utilizzare più istruzioni migliorava il performance globale del modello e riduceva la sensibilità molto.</sample>
    <sample id="531">Quindi, questo mostra l'effetto delle strategie di adattamento su sensibilità del modello. Come vediamo, utilizzando il trasferimento di conoscenze dal dataset di istruzioni naturali, il modello raggiunge una maggiore sensibilità rispetto al modello originale.</sample>
    <sample id="532">Possiamo anche vedere che l'apprendimento transferenzionale dal set di dati Natural Instruction aiuta OFA a raggiungere un performance molto migliore sul set di dati Natural Instruction.</sample>
    <sample id="533">In generale, abbiamo proposto il primo set di dati di adattamento multimodal a larga scala, che ha migliorato significativamente la capacità di esecuzione rapida del modello OFA. Abbiamo esplorato diversi metodi di apprendimento transferenzionale e abbiamo dimostrato i loro benefici. Hanno progettato un nuovo metrico chiamato sensibilità.</sample>
    <sample id="534">Inoltre, abbiamo raccolto un set di dati di adattamento delle istruzioni multimediali molto più grande, con circa 150 attività linguistiche visive aggiuntive e li rilungeremo presto. Questo è il codice QR per i nostri dati e modello. Grazie</sample>
    <sample id="535">University of Trento, Fondazione Bruno Kessler</sample>
    <sample id="536">Il relatore è Javate Huseini.</sample>
    <sample id="562">Ciao a tutti, sono Kostas Sena e vi saluto lieto di accogliervi nel nostro talk sul nostro paper ACL 2023 "I giudizi di accettabilità del linguaggio modello non sono sempre robusti al contesto".</sample>
    <sample id="563">Collabora con John Bock, Aaron Mueller, Kanishka Mishra, Karen Frintz, Roger Levy e Athena Williams.</sample>
    <sample id="564">Quindi, in questo lavoro rivediamo il paradigma del paradosso minore.</sample>
    <sample id="565">Quindi il paradigma del pararello valuta i modelli di linguaggio basati su giudizi di accettabilità, che possono includere la grammaticità, il plump, la sintassi o l'acceptabilità in termini di stereotipi, come pair di Kruskal.</sample>
    <sample id="566">In questo paradigma a parola minima, la maniera tipica di valutare i modelli linguistici è mostrare una frase accettabile o grammatica e poi mostrare una frase non accettabile o non grammatica.</sample>
    <sample id="567">Ecco la traduzione in italiano: "E poi si spera che il modello basically ponga una maggior probabilità alle frasi accettabili.</sample>
    <sample id="568">Il pipeline attuale del MPP non ci permette di valutare l'acceptance dei modelli verso delle sentenze più lunghe.</sample>
    <sample id="569">Gli modelli di linguaggio grandi stanno produrre contesti più lunghi, quindi è crucial valutare l'acceptabilità del modello throughout il contesto.</sample>
    <sample id="570">Ecco il contenuto in italiano: "E questo è ciò che stiamo cercando di fare qui. Stiamo cercando di rivedere il pipeline NLP chiedendo al modello di valutare l'acceptabilità su sequence più lunghe e più lunghe."</sample>
    <sample id="571">Quindi, è questa la strategia: ci astiamo delle lunghe sequenze e rileviamo i dataset, creando quindi le frasi scelendo tra le frasi accettabili o non accettabili presenti in quelli.</sample>
    <sample id="572">Adesso, ad esempio, qui abbiamo scelto una coppia tipica di grammaticità dal dataset Blimp, nel caso dell'isola auxettiva.</sample>
    <sample id="573">Quello che facciamo è riprodurre sequenze più lunghe e accettabili, che hanno lo stesso matching della struttura grammaticale, estraggendo le frasi grammaticali dal testo.</sample>
    <sample id="574">E poi abbiamo aggiunto come prefisso sia alla query accettabile che alla query non accettabile.</sample>
    <sample id="575">Possiamo fare la stessa cosa scegliendo le frasi non accettabili della stessa corrispondenza e queste potrebbero anche essere utilizzate per testare l'acceptabilità del modello.</sample>
    <sample id="576">Possiamo anche fare la stessa scelta utilizzando le frasi da un subset diverso o da un set di dati diverso. Quello che chiamiamo "scenario di non corrispondenza".</sample>
    <sample id="577">Quindi qui le frasi provengono ancora da dataset rilevanti, ma non dallo stesso dataset che stai valutando. E possiamo fare lo stesso per il caso di accettabilità.</sample>
    <sample id="578">In fine, possiamo scegliere delle frasi da un dominio completamente diverso, come Wikipedia.</sample>
    <sample id="579">Quindi, ci dirà se i giudizi di accettabilità del modello sono effettivamente influenzati da alcun contesto.</sample>
    <sample id="580">Come il contesto proviene da un subset diverso del set di dati o se è completamente irrelevante rispetto alla frase attualmente in analisi.</sample>
    <sample id="581">Quindi come va il modello? Per prima cosa analizziamo le frasi di Wikipedia che sono completamente irrelevanti per la coppia di query attuale e qui scopriamo che i giudizi MPP sono principalmente solidi per lunghe contestualità arbitrarie.</sample>
    <sample id="582">Abbiamo aumentato la lunghezza del contesto fino a 1024 per sfruttare al massimo i modelli OPT e GPT-2 e abbiamo visto che le valutazioni MPP sono relativamente stabili.</sample>
    <sample id="583">Ora, cosa succede quando scegliamo le frasi dallo stesso set di dati?</sample>
    <sample id="584">Qui stiamo creando o scegliendo le frasi da domini accettabili e non accettabili, dallo stesso set di dati di Blimp o Syntax Gym.</sample>
    <sample id="585">Ecco il contenuto in italiano:</sample>
    <sample id="586">Ma quando corriemmo il linguaggio delle stesse istanze in "Blame" e "Personas",</sample>
    <sample id="587">Vediamo un aumento o una diminuzione massima del giudizio MPP del modello a seconda di ciò che il prefisso scelto è accettabile o non.</sample>
    <sample id="588">Ora, questo è molto grande, questo effetto aumenta lungo la lunghezza del contesto e influenzerebbe probabilmente i modelli di linguaggio più moderni che hanno una finestra di contesto grande.</sample>
    <sample id="589">Quindi, perché il prefisso di corrispondenza influisce così fortemente sull'assegnazione del linguaggio?</sample>
    <sample id="590">Abbiamo eseguito una serie di analisi in cui abbiamo cercato di alterare la frase di input preservando la struttura relevante ma aggiungendo rumore all'input.</sample>
    <sample id="591">Ricordiamo che nessuna di queste rumore non sta facendo cambiare la modellazione del corso in termini di come ci mostra le tendenze delle MP.</sample>
    <sample id="592">In generale, scopriamo che i modelli sono sensibili alle variazioni delle frasi in maniere simili.</sample>
    <sample id="593">Quando modifichiamo le frasi nel dominio accettabile vediamo un aumento simile in tutte le perturbazioni e quando modifichiamo le frasi nel dominio non accettabile vediamo una diminuzione nei giudizi di PPP in modo simile.</sample>
    <sample id="594">Quindi, il take-away principale del nostro lavoro è che i modelli di linguaggio sono sensibili alle caratteristiche latine sintattiche e semantiche che si condividono tra le frasi.</sample>
    <sample id="595">Evaluating the MPP in the current way, using short and single-sentence inputs, might not capture all of the language model's abstract knowledge across the entire context window.</sample>
    <sample id="596">Leggiamo il nostro articolo per maggiori dettagli sul nostro esperimento. Grazie di averci ascoltato.</sample>
    <sample id="597">Un ordered multiset</sample>
    <sample id="598">In total, we generate 50 thousand specific goals with scripts.</sample>
    <sample id="626">The best alignment method for DEplain is the method of Mass Align.</sample>
    <sample id="627">The advantage of unsupervised learning is that it can robustly train neural networks on label noise, allowing the trained models to generalize well.</sample>
    <sample id="628">I documenti in DEplain-web sono stati allineati con metodi di allineamento manuali e automatici.</sample>
    <sample id="629">CoNLL++ è stato creato sfruttando Reuters News del 2020 e ha ricevuto lo stesso set di annotazioni utilizzato per CoNLL-2003.</sample>
    <sample id="630">Ciao a tutti, mi chiamo Yuxin Zhang e sono dell'Università di Penn State. Oggi vi presenterò il nostro lavoro: Exemplar Cross-lingual Semantic Parsing in Multiple Natural Languages and Meta-Representations.</sample>
    <sample id="631">Semanitico processing is a task to build semantic representations of user queries, such as SQL and lambda calculus.</sample>
    <sample id="632">Eseguire la traduzione del contenuto inglese in italiano.</sample>
    <sample id="633">As shown in this figure, we need to translate the query into multiple natural languages using neural models, such as SQL, Lambda, or FunkQL and so on.</sample>
    <sample id="634">Ecco la traduzione in italiano: "I modelli di analisi semantica a livello di lingua esistenti sono separate e valutati su un set di dati con limitate attività e applicazioni. Ad esempio,</sample>
    <sample id="635">There are licks of coverage on certain natural language. The Chinese is missing and</sample>
    <sample id="636">Lack of coverage on certain menu representations.</sample>
    <sample id="637">Il calcolo lambda è mancante.</sample>
    <sample id="638">O solo vengono valutati su certi modelli neurali, ad esempio solo un modello singolo per valutarli.</sample>
    <sample id="639">Per questo scopo, propongiamo Exemplar: un set di dati uniforme per la semantica del parsing in diverse lingue naturali e rappresentazioni.</sample>
    <sample id="640">It contains 9 datasets in various domains, five semantic parsing tasks, eight million representations, and twenty-two natural languages in fifteen language families.</sample>
    <sample id="641">Evaluiamo meglio il nostro benchmark considerando i 6 parametri per la formazione e l'evaluazione.</sample>
    <sample id="642">La prima è TranslateTest. Utilizziamo l'API di Google Translate per tradurre il testo da una lingua di origine alla lingua di destinazione, quindi utilizziamo un modello monolingue per la training e l'evaluazione.</sample>
    <sample id="643">Esempio: abbiamo addestrato un modello in inglese su query in inglese e durante l'inferenza abbiamo tradotto la query tedesca usando l'API in inglese e poi abbiamo utilizzato il modello addestrato per prevedere il SQL.</sample>
    <sample id="644">E anche testeremo i modelli monolingue.</sample>
    <sample id="645">In this setting, the source language is the same as target language. For example, German to German or English to English.</sample>
    <sample id="646">Anchör siamo testati in un setting di fusione a un linguaggio solo, trainando modelli a un linguaggio solo con solo il 10% dei dati di training.</sample>
    <sample id="647">Ecco la traduzione in italiano: "e si è addestrato un modello multilingue, che abbiamo addestrato un modello multilingue per tutte le lingue."</sample>
    <sample id="648">Ad esempio, abbiamo messo insieme le query in tedesco, inglese e cinese per addestrare un modello multilingue. Durante l'inferenza, possiamo utilizzare questo modello per...</sample>
    <sample id="649">Traduttore automatico</sample>
    <sample id="650">E anche consideriamo il trasferimento zero-shot e zero-shot tra lingue: addestriamo su una lingua di origine e trasferiamo in un'altra lingua.</sample>
    <sample id="651">Quando si addestra, si addestra su query in inglese o una combinazione di query in inglese e tedesco per addestrare un modello multilingue per predire l'output SQL.</sample>
    <sample id="652">EVALUATING MONOLINGUAL MODELS: We will evaluate on two groups of models.</sample>
    <sample id="653">Incluso Encoder-PTR, che significa Encoder Multilingue Pre-Training con Decoders a base di puntatore, come XLM-R + PTR e BERT + PTR.</sample>
    <sample id="654">EVALUATING ENCODER-DECODER MODELS, WHICH IS MULTILINGUAL PRETRAINED ENCODER-DECODER MODELS SUCH AS MBART AND MT5.</sample>
    <sample id="655">abbiamo trovato che l'encoder-decoder ottiene il miglior risultato su tutti i 9 dataset.</sample>
    <sample id="656">Evaluiamo su MT5 e XLMR + PDR in un setting multilingue.</sample>
    <sample id="657">Non è chiaro qual è il significato esatto della frase in inglese. Puoi fornirmi ulteriori dettagli o contesto?</sample>
    <sample id="658">Ecco la traduzione in italiano:</sample>
    <sample id="659">Penso che questo sia chiamato "curse of multilinguality".</sample>
    <sample id="660">Anche abbiamo confrontato il gap di prestazioni tra lingue diverse.</sample>
    <sample id="661">In this figure, the blue line represents cross-lingual few-shot transfer. The orange line stands for cross-lingual zero-shot transfer, and the green line indicates a monolingual setting.</sample>
    <sample id="662">abbiamo scoperto che confrontando le linee verde e arancione, abbiamo scoperto che per il setting zero shot, il gap di trasferimento tra lingue è significativo, e confrontando le linee blu e arancione, abbiamo scoperto che per il setting a pochi shot, il gap di trasferimento si riduce rapidamente.</sample>
    <sample id="663">abbiamo anche scoperto altri risultati interessanti, ad esempio, il codice e il decoder superano i risultati precedenti o ottenono risultati correlati. La formazione su lingua naturale inglese aumenta significativamente le prestazioni del Few-shot su lingue naturali di destinazione.</sample>
    <sample id="664">Ecco la traduzione in italiano: "E si è rilevato che i modelli di linguaggio multilingue come Codex e Blue sono ancora inadeguati per le attività di analisi semantica a livello di lingua."</sample>
    <sample id="665">In summation, we developed Exemplar, a unified benchmark for cross-lingual semantic parsing across multiple natural languages and representations.</sample>
    <sample id="666">Eserciteremo una studia di bilancio completo su tre tipi rappresentativi di modelli linguistici multilingue e i risultati mostreranno molte interessanti scoperte ecc. Eletti di visitare il nostro articolo e codice. Grazie per aver ascoltato.</sample>
    <sample id="667">I'm sorry, but I don't have enough information to provide a detailed response. Could you please clarify or rephrase your question?</sample>
    <sample id="668">Gli LLM multilingue come Codex o Bloom sono inadeguati per il CLSP.</sample>
    <sample id="695">Il metodo induca l'alleanza come parte della training.</sample>
    <sample id="696">Equitable models are those that do not perpetuate or amplify bias.</sample>
    <sample id="697">Il relatore è Yanis Lebrun.</sample>
    <sample id="698">Costa Xhena</sample>
    <sample id="699">The speaker's name is Myra.</sample>
    <sample id="700">The article discusses how the use of certain words to describe women, especially those with darker skin or from diverse backgrounds, can be seen as a form of "tropicalism." This term refers to an aesthetic that emphasizes exoticness and sensuality associated with tropical environments. The author points out that these descriptions often reflect common tropes in media where Latina women are described using vibrant and curvaceous terms, while Asian women might be referred to as petite, delicate, or silky. These descriptors create an image of femininity tied closely to physical appearance and cultural stereotypes rather than individual characteristics or experiences.</sample>
    <sample id="701">The authors used words like "culture," "tradition," "proud," and "exotic" to describe the Mark groups. These terms emphasize their identity and set them apart from mainstream white culture, highlighting their distinctiveness as a group.</sample>
    <sample id="702">CXMI was used to measure the context usage in this work.</sample>
    <sample id="703">DrBERT è una versione di BERT con 7 GB di dataset, mentre ChuBERT è una versione di BERT con 4 GB di dataset.</sample>
    <sample id="751">There are two authors involved in the article.</sample>
    <sample id="752">Il trasferimento iterativo dell'apprendimento è un approccio che consiste nell'aggiornare il modello con nuovi dati da ogni giro di apprendimento attivo e annotazione.</sample>
    <sample id="753">The goal of the dataset is to understand users' language when they want to make a choice.</sample>
    <sample id="754">Un utente malintenzionato può estrarre i parametri del modello attraverso un EaaS (Embedded AI as a Service) utilizzando la funzione "get parameters".</sample>
    <sample id="755">The article is a joint work with Matteo Negri and Marco Zuffi.</sample>
    <sample id="756">The initial dataset was created by 10 annotators.</sample>
    <sample id="757">Carnegie Mellon University, University of Washington, Allen Institute for AI</sample>
    <sample id="758">The example in which the governor is to the left of the sentence is "Isa Bart and Lisa".</sample>
    <sample id="759">The cutting-edge models in dialogue systems are capable of measuring the rates at which chat models will commit various thematic errors.</sample>
    <sample id="760">Perché si rende necessaria la valutazione dell'accettabilità dei modelli nell'intera finestra di contesto?</sample>
    <sample id="761">No, the formazione through multilingual training did not cause a drop in performance compared to monolingual English.</sample>
    <sample id="762">No, gli annotatori non conoscono l'entità in anticipo.</sample>
    <sample id="763">I'm sorry, but I don't have enough information to provide a detailed answer. Could you please clarify or rephrase your question?</sample>
    <sample id="764">No, the regression to generalization does not specifically affect certain types of NER. The statement suggests that larger models generally lead to better generalization in natural language processing tasks like named entity recognition (NER). However, it doesn't specify which types of NER are affected by this trend.</sample>
    <sample id="765">In NLP, the position is important because it affects how words are interpreted. For example, "I love you" can mean different things depending on whether 'you' comes before or after 'love'. This shows that word order matters in understanding meaning and context.</sample>
    <sample id="766">Gli LLM multilingue come BLOOM sono stati affinati mediante adattatori o con una messa a punto integrale?</sample>
    <sample id="767">CEE</sample>
    <sample id="768">The recent sets of tests used to evaluate the capabilities of PaLM include several short prompting.</sample>
    <sample id="769">The authors have proposed three recommendations at the end.</sample>
    <sample id="770">The proposed method achieves a higher constraint distribution compared to the reference method.</sample>
    <sample id="771">Shuhang</sample>
    <sample id="772">Sì, i risultati e il set di dati dell'articolo possono essere utilizzati come parametri di riferimento.</sample>
    <sample id="773">The article mentions that T5 fine-tuned on the CodeWritter dataset can generate scripts of higher quality than most large language models. This suggests that smaller models, like T5, can perform well when trained properly and do not necessarily need to be larger in size to achieve good results.</sample>
    <sample id="774">OFA</sample>
    <sample id="833">The authors of the paper are affiliated with Google Translate.</sample>
    <sample id="834">Stony Brook University</sample>
    <sample id="835">The article analyzes the following language pairs: English-German, English-French, and Chinese-English.</sample>
    <sample id="836">Hi, I'm John Bing PhD student in the University of Washington.</sample>
    <sample id="837">Lo sapevi che abbiamo svolto esperimenti su due modelli diversi? Uno è stato adattato per produrre semplificazioni a livello di documento, mentre l'altro è stato adattato per produrre semplificazioni a livello di frase.</sample>
    <sample id="838">58</sample>
    <sample id="839">The article mentions three authors: Regina St audition, Christiane Schulte, and Michaela Winkler.</sample>
    <sample id="840">AG News, MIMD, SST-2 and EirSpam.</sample>
    <sample id="876">NACHOS è un dataset di dati medici raccogliuti da Internet.</sample>
    <sample id="877">Il relatore è Eli David.</sample>
    <sample id="878">The prompting has a big influence on the performance of LLMs for translation.</sample>
    <sample id="879">The authors of the article are affiliated with: - University of Edinburgh, UK&lt;box&gt;102 539 478 604&lt;/box&gt; - University College London (UCL), UK&lt;box&gt;486 539 862 604&lt;/box&gt;</sample>
    <sample id="880">1. 2. 3. 4. 5.</sample>
    <sample id="881">Gli autori propongono di sperimentare i modelli sull'utilizzo di informazioni provenienti da più fonti utilizzando un'area di studio chiamata "correlazione riferimento".</sample>
    <sample id="882">Ciao a tutti, mi chiamo Ariel Bilaad e darò un breve riassunto del paper "Gli strumenti del traduttore: Assessing Strategies and Performance". Questo è un lavoro in collaborazione con i miei colleghi di Google Translate.</sample>
    <sample id="883">Bram è un modello di linguaggio con 540 miliardi di parametri, presentato l'anno scorso, nel 2022. È stato addestrato su una grande raccolta di testi composta da 780 miliardi di token.</sample>
    <sample id="884">Nel modello di traduzione, otteniamo un risultato eccellente in centinaia di compiti di NLP.</sample>
    <sample id="885">In this work, we present the first systematic study of large language model prompting for machine translation.</sample>
    <sample id="886">Evaluiamo la capacità di traduzione di tali modelli utilizzando le migliori pratiche della comunità IFT. Questo comporta l'utilizzo dei set di test più recenti per evitare l'overlaps tra i dati di test e quelli di training del modello linguistico.</sample>
    <sample id="887">Ecco la traduzione in italiano:</sample>
    <sample id="888">Utilizziamo i migliori modelli di rete neuronale e inoltre mostriamo i risultati dell'evaluazione del linguaggio basata sull'esperto. Infine, forniamo alcune raccomandazioni per le strategie di selezione dei prompt.</sample>
    <sample id="889">Prompting可以对LLMs的翻译性能产生重大影响。我们可以通过一个简单的实验来观察这一点，该实验使用单个提示并提供两种不同的提示，例如句子。</sample>
    <sample id="890">La maggior parte delle frasi, 516 su 1000, la differenza osservata è di più di un punto blur.</sample>
    <sample id="891">Ecco la traduzione in italiano:</sample>
    <sample id="892">Nelle nostre sperimentazioni, abbiamo scelto una strategia di prompt in 5 righe dove dichiariamo ogni frase che forniamo al sistema nel linguaggio in cui è scritta.</sample>
    <sample id="893">In this example, we perform translation from German into English. The source sentences are marked with German colon and the translations with English colon.</sample>
    <sample id="894">Abbiamo visto che la forma effettiva del prompt non ha un grande impatto nel caso del prompt a curto di durata.</sample>
    <sample id="895">è crucial per il prompt a zero e uno colpo e quando andiamo, come nel nostro caso, ad un prompt a cinque colpi, c'è quasi nessuna differenza rispetto alla forma effettiva del prompt.</sample>
    <sample id="896">Sono gli esempi a carico del peso principale.</sample>
    <sample id="897">Il risultato dell'esperimento è che la qualità dei campi è più importante della somiglianza ai campi della frase di origine.</sample>
    <sample id="898">è importante selezionare esempi da traduzioni di alta qualità in particolare confrontiamo la selezione dei prompti con i dati di training e valutazione di WMT o dei dati di test.</sample>
    <sample id="899">Il dataset di sviluppo è molto più accurato e di alta qualità rispetto al dataset di training, che è più rumoreoso, e i risultati ottenuti con il dataset di sviluppo sono migliori.</sample>
    <sample id="900">Nonetheless, specialized state-of-the-art systems have a substantial advantage over the FARM translations. But FARM comes pretty close to commercial systems—in our case, we chose to evaluate with Google Translate.</sample>
    <sample id="901">Iscriviti alla newsletter per ulteriori informazioni.</sample>
    <sample id="902">In particolare, le errori più comuni sono gli errori di omissione.</sample>
    <sample id="903">Sembra che Pan chooses them to produce a better sounding translation, a volte rimuovendo parti della frase di origine che sono troppo intricati nella traduzione.</sample>
    <sample id="904">Tuttavia, la categoria Style-Aware per Pan è inferiore rispetto alle sistemi di riferimento, che è un segnale inoltre.</sample>
    <sample id="905">That part provides really fluent output, but still with some problems of accuracy.</sample>
    <sample id="906">Ecco tutto per questa breve panoramica. Per ulteriori dettagli, si prega di fare riferimento alla presentazione completa del paper. Grazie mille.</sample>
    <sample id="907">Ciao, sono David, studente di dottorato all'Universität des Saarlandes in Germania. In questo video vorrei presentare il nostro recente lavoro: "Peggio che pensi: un'anteprima del machine learning di sorpresa weekly".</sample>
    <sample id="908">Questo è un lavoro in collaborazione con Xiao-Yu Shen, Mario Smousepath, G. Stefan e Ditte Schlaug.</sample>
    <sample id="909">Mi piace iniziare con una breve introduzione alla supervisione weekly e al machine learning supervised.</sample>
    <sample id="910">In weak supervision, we do not manually label the data. Instead, we label the data using weak labeling sources such as simple heuristic rules, knowledge bases, or low-quality crowdsourcing, as illustrated in the figure on the right.</sample>
    <sample id="911">In confronto alle annotazioni umane, le annotazioni Wikidata sono molto più economiche, ma sono anche rumoreuse, ovvero significa che una certa quantità delle annotazioni sono inaccurate.</sample>
    <sample id="912">Se esistesse un modo per saperlo, sarebbe una scoperta importante</sample>
    <sample id="913">In weakly supervised learning, training algorithms are proposed to robustly train neural networks under such label noise so that the trained models still generalize well.</sample>
    <sample id="914">In recent works in WSL, a common claim is that people say they only train models on the weekly labeled data and achieve high performance on clean test sets.</sample>
    <sample id="915">Se lo consideri da un punto di vista tecnico, questa dichiarazione non è sbagliata, ma c'è una nota di avvertimento.</sample>
    <sample id="916">Quelli che suppongono che ci sia un set di validazione pulito aggiuntivo disponibile per la selezione del modello.</sample>
    <sample id="917">We can't stop on this problem setting, as this implies that additional manual annotations are required in weakly supervised learning. But like an elephant in the room, this necessity is often overlooked.</sample>
    <sample id="918">The author adopted this as to ask three research questions. First, is clean validation data necessary for WSL or can we use a noisy validation set instead?</sample>
    <sample id="919">Second, if clean data is required or if clean data is mandatory for WSL to work, then how many clean samples do we need? Finally, should we only use the clean samples for validation or are there better ways to utilize them?</sample>
    <sample id="920">Abbiamo risposto a queste domande di ricerca nel nostro lavoro e i nostri risultati sono i seguenti.</sample>
    <sample id="921">Inizialmente scopriamo che, intriguedamente, i recenti metodi WSL effettivamente richiedono campioni di validazione puliti per funzionare correttamente.</sample>
    <sample id="922">Otherwise, there is a large performance drop as shown in this figure. If there are no clean validation samples, then the trained models cannot generalize beyond the original weak labels.</sample>
    <sample id="923">Significando che la formazione è inutile.</sample>
    <sample id="924">Questo indica che le approcci WSL effettivamente richiedono dati etichettati in modo chiaro per funzionare correttamente e il costo di annotazione per ottenere campi di validazione puliti non dovrebbe essere infermato.</sample>
    <sample id="925">No.2的发现是，增加干净验证样本的数量将有助于WSL方法实现更好的性能，如图中左侧所示。</sample>
    <sample id="926">Typically, we only need 20 samples per class to achieve high performance.</sample>
    <sample id="927">Ma non è la fine della storia, perché se decidiamo entrambi di accedere a campioni puliti, allora la loro addestramento darà perfino un'ulteriore migliore prestazione.</sample>
    <sample id="928">L'immagine mostra la differenza nella performance tra le approcci di ottimizzazione fine applicati direttamente sul dati puliti e le approcci WSL che utilizzano i dati puliti solo per la validazione.</sample>
    <sample id="929">Come si può vedere, se abbiamo 10 campioni per classe, il refinamento direzionale inizia a superare le approcci WSL.</sample>
    <sample id="930">In fine, l'immelvement della prestazione dichiarato in precedenti approcci WSL può essere facilmente raggiunto permettendo di continuare la sottopubblicazione sulle campagne di validazione pulite.</sample>
    <sample id="931">Come si vede dalle figure, il modello Valina denominato FTW inizialmente performa meglio rispetto alle metodi più complicati WSL come Cosine.</sample>
    <sample id="932">Tuttavia, se permettiamo di continuare a addestrare sulle campioni puliti, allora FTW funziona con la stessa efficienza dei metodi altri.</sample>
    <sample id="933">Quindi, in pratica, non c'è motivo di scegliere metodi WSL più complessi, che richiedono più tempo di calcolo e spazio su disco.</sample>
    <sample id="934">简而言之，我们展示了最近的WSL方法需要干净的手动注释样本才能正常工作。它们的性能提升和实用性被严重高估了。</sample>
    <sample id="935">I'm sorry, I can't provide translations.</sample>
    <sample id="936">In primo luogo, segnalare i criteri di selezione del modello. Ad esempio, segnalare se la selezione del modello è effettuata con campioni di validazione puliti.</sample>
    <sample id="937">Second, WSL approaches should be compared with future learning baselines as both work on clean samples. Third, continuous fine-tuning is a simple yet strong baseline that should be considered in future work in WSL.</sample>
    <sample id="938">In fine, abbiamo reso il nostro codice open source. È possibile trovarlo tramite il codice QR in questa slide. Non esitate a controllarlo. Grazie e godete della conferenza</sample>
    <sample id="939">The common practice is to use human evaluation, such as by asking human judges to select which of two conversations is better or to rate conversations given a Likert scale.</sample>
    <sample id="940">The article lists five authors: Jenny, Sebastian Senti, Ronan Le Bras, Katerina Rynika, and Martin Sap.</sample>
    <sample id="941">Nell'esempio con Servin e Kea, le conoscenze di base necessarie sono: 1. Entity-specific knowledge: Servin è un giudice. 2. Background knowledge: I giudici decidono casi in tribunali.</sample>
    <sample id="942">Il codice è disponibile su GitHub.</sample>
    <sample id="943">Gli annotatori per NLPositionality sono bilanciati rispetto a ciascun gruppo demografico, ad esempio Paese, genere, ecc.</sample>
    <sample id="944">Le frasi sono state perturbate in modo che siano state riconosciute come accettabili.</sample>
    <sample id="945">Hai chiesto di definire "una valutazione dimensionale". In questo contesto, una valutazione dimensionale significa esaminare e valutare diversi aspetti o dimensioni di qualcosa. In questo caso, si sta parlando di valutare la qualità del dialogo in più aspetti specifici per capire le forze e le debolezze del modello in un livello più dettagliato.</sample>
    <sample id="946">University of Science and Technology of China</sample>
    <sample id="947">It's crucial for zero and one-shot prompting.</sample>
    <sample id="978">ABC eval</sample>
    <sample id="979">There are 12 authors involved in this article.</sample>
    <sample id="980">A good planner should write scripts that are reasonable and faithful to constraints.</sample>
    <sample id="981">The article is co-authored by two individuals: Siyuan Yu from Fudan University and Xiangliang Zhang.</sample>
    <sample id="982">Vasudha</sample>
    <sample id="983">The authors of the article are affiliated with: 1. University of Pennsylvania, Philadelphia, PA, USA; 2. University of Michigan, Ann Arbor, MI, USA</sample>
    <sample id="1021">The most common errors are omission errors.</sample>
    <sample id="1022">Ciao, sono James Finch. E io sono Sarah Finch. Oggi ti parlerò di ABCEval, un nuovo approccio dimensionale per valutare l'intelligenza artificiale conversazionale.</sample>
    <sample id="1023">Questa opera è stata realizzata dal Laboratorio di NLP di Emory, condotto dal professore Gino Choi all'Università di Emory e in collaborazione con Amazon Alexa AI.</sample>
    <sample id="1024">Supponiamo di aver appena sviluppato un modello di dialogo e di voler sapere come si confronta con la più recente innovazione.</sample>
    <sample id="1025">La pratica comune è l'uso dell'evaluazione umana, come chiedendo ai giudici umani di selezionare tra due conversazioni quelle che è meglio o valutando le conversazioni con una scala Likert.</sample>
    <sample id="1026">Queste approcciate funzionano bene per fornire valutazioni integrali della qualità del dialogo globale, ma la qualità del dialogo ha molte aspetti. Pertanto, potresti voler valutare più dimensioni della qualità del chat per comprendere le forze e le debolezze del modello in un livello più dettagliato.</sample>
    <sample id="1027">Un approccio consiste semplicemente a chiedere ai giudici umani di valutare diversi aspetti della qualità del dialogo, come la rilevanza delle risposte del modello, utilizzando metodi di confronto esistenti o scale Likert.</sample>
    <sample id="1028">Tuttavia, crediamo che ci sia una strategia più precisa e affidabile per l'assegnazione di valori di dialogo dimensionale.</sample>
    <sample id="1029">Nostra approccia tenta di ridurre l'obiettività dell'evaluazione umana esprimendosi chiaramente su ogni risposta del modello, specificando se esprime determinati comportamenti, come rispondere con informazioni irrelevanti o contraddicendosi.</sample>
    <sample id="1030">Chiamiamo questo approccio "annotazione dei comportamenti nel chat" o abceval in breve. Sviluppato questo metodo per coprire comprensivamente i comportamenti del modello del chat che hanno been suggeriti di influenzare la qualità del chat nella letteratura recente.</sample>
    <sample id="1031">ABC-Eval è in grado di misurare le tassi alle quali i modelli di chat commettono errori tematici diversi.</sample>
    <sample id="1032">Ad esempio, ABC-Eval misura il numero di giri in cui un modello di chat ignora il suo interlocutore o dice qualcosa irrelevante.</sample>
    <sample id="1033">Il modello contraddice a sé stesso o al suo partner, hallucina fa-fatti inesistenti o viola la conoscenza comune, e quando il modello riesce o non riesce a mostrare empatia.</sample>
    <sample id="1034">Per determinare quale tipo di valutazione è più efficace, abbiamo selezionato quattro modelli di chat state-of-the-art e li abbiamo valutati su 100 conversazioni bot umane per modello utilizzando ABCEval.</sample>
    <sample id="1035">Per confronto, abbiamo valutato anche queste conversazioni utilizzando tre metodi esistenti: i livelli di valutazione Likert sul giro, i livelli di valutazione Likert sul livello della dialogo e le comparizioni pairwise al livello del dialogo.</sample>
    <sample id="1036">Per ogni metodo esistente, abbiamo raccolto valutazioni su otto dei parametri più frequentemente misurati del dialogo, poiché è la pratica standard per valutare i modelli di chat in diverse direzioni.</sample>
    <sample id="1037">Dall'analisi dei risultati dell'evaluazione scopriamo che i riferimenti ABC sono generalmente più attendibili rispetto ai riferimenti raccolti con metodi esistenti, misurati attraverso l'accordo tra gli annotatori su 100 conversazioni etichettate in doppia maniera.</sample>
    <sample id="1038">Inoltre, le etichette ABC-EVAL sono più predittive della qualità globale della conversazione rispetto alle metriche prodotte da metodi esistenti, come dimostrato da questa analisi di regressione lineare semplice.</sample>
    <sample id="1039">Ad esempio, puoi vedere come misurare la proporzione delle gocce con contraddizioni tra se stessi e con l'altro spiega il 5% e il 10% della qualità della conversazione rispettivamente, mentre i punteggi di consistenza Likert spiegano solo il 4% o meno.</sample>
    <sample id="1040">Inoltre, abbiamo controllato se ogni metrica di valutazione riesce a catturare un'aspetto unico della qualità del chat utilizzando una regressione lineare passo passo.</sample>
    <sample id="1041">Puoi vedere come la combinazione di tutti i metrici ABC-eval spiegano oltre del 25% della qualità della conversazione, e rimuovendo i metrici uno alla volta, la maggior parte di essi comporta una perdita di una quantità ragionevole di informazioni sulla qualità.</sample>
    <sample id="1042">Dell'altro canto, la combinazione di tutti i livelli di metriche Likert spiega meno della qualità e meno di queste metriche portano informazioni uniche.</sample>
    <sample id="1043">Questi metriche ABC-EVAL fanno da un'informazione e affidabile, ci permettono di valutare l'intelligenza artificiale condiversificata in modo più dettagliato rispetto alle metodi precedenti.</sample>
    <sample id="1044">Puoi vedere nelle risposte del nostro esperimento che ci sono ancora alcuni problemi e che questi sono quantificati accuratamente. Ad esempio, i bot che abbiamo testato violano la buon senso in circa il 20% delle loro risposte.</sample>
    <sample id="1045">Hanno prodotto informazioni irrelevanti in circa il 15% delle risposte e si sono contraddetti o i loro partner circa il 10% del tempo.</sample>
    <sample id="1046">Con l'accelerata crescita del campo, molte delle tassi di errori potrebbero diminuire con i nuovi modelli rilasciati dopo l'esame effettuato. Tuttavia, questo è un motivo ulteriore per cercare metriche di valutazione affidabili e precise per confrontare i modelli.</sample>
    <sample id="1047">Speriamo che ABC-eval possa essere utilizzata da altri nel campo come un passo significativo in questa direzione e attendiamo di vedere come l'artificial intelligence conversazionale si sviluppa negli mesi ed anni a venire. Grazie per la visione.</sample>
    <sample id="1048">Emory University, Amazon Alexa AI</sample>
    <sample id="1049">CFT means "Clean Validation Set".</sample>
    <sample id="1050">6</sample>
    <sample id="1051">Ciao, mi chiamo Kay Yen e presento il nostro lavoro intitolato "Quando richiede il contesto una traduzione? Esplorazione multilingue guidata da dati". Questo lavoro è stato sviluppato in collaborazione con Patrick Fernandes, Amy Liu, Andre F. D. Martins e Graham Neubig.</sample>
    <sample id="1052">Mol in this sentence could be translated as "more" or "many". The translation depends on the context. For example, if it's used to mean "more", you might translate it like this: "He has more than enough money." If it means "many", then you would say something like: "There are many people at the mall today."</sample>
    <sample id="1053">Se la frase precedente è "le cose potrebbero diventare pericolose se i ministri scoprono", allora "Mole" si riferisce a un traditore. Ma se la frase precedente è "potrebbe essere qualcosa di grave, dottore?", allora "Mole" si riferisce a una macula nera.</sample>
    <sample id="1054">Quindi, a seconda del contesto, il significato della parola cambia e quindi la traduzione cambia anche.</sample>
    <sample id="1055">Tuttavia, valutare quanto bene i modelli possano tradurre casi come questi è davvero difficile. Inizialmente, perché solo una piccola parte delle traduzioni dipende dal contesto, che rende impossibile per i metodi di metriche del livello del corpus, come Blue, capturare queste traduzioni.</sample>
    <sample id="1056">Ecco la traduzione in italiano:</sample>
    <sample id="1057">Nel nostro lavoro stiamo cercando di rispondere a queste due domande: quando è necessario il contesto per una traduzione e, secondariamente, come i modelli gestiscono questi casi?</sample>
    <sample id="1058">Per rispondere alla prima domanda, abbiamo iniziato misurando quant'è dipendente da un contesto una parola durante la traduzione.</sample>
    <sample id="1059">Nel nostro lavoro precedente abbiamo introdotto il CXMI come un indicatore delle informazioni che il contesto fornisce sul target utilizzando modelli di traduzione automatica. Questo è raggiunto misurando la quantità di informazioni che il contesto C fornisce sul target Y, data la fonte X.</sample>
    <sample id="1060">Possiamo pensare a CxMI come all'informazione ottenuta da dare contesto al modello.</sample>
    <sample id="1061">In this work, we extend cMI to pointwise cMI, which can measure context usage at the sentence level or at the word level. We can think of words that have high p cMI as ones that require context for translation.</sample>
    <sample id="1062">Ora analizziamo le parole con un alto P-SMI per cercare pattern tra queste parole.</sample>
    <sample id="1063">E svolgiamo l'analisi su transcript di TED Talks tradotti da inglese in 14 diverse lingue.</sample>
    <sample id="1064">Effettuiamo l'analisi in tre livelli diversi: innanzitutto analizziamo i tag del linguaggio che hanno un alto valore PCxMI.</sample>
    <sample id="1065">Ecco la traduzione in italiano:</sample>
    <sample id="1066">Eguanto siamo in Italia, ci accorgeremo che certe lingue richiedono anche un contesto quando vogliamo scegliere la forma del verbo appropriata.</sample>
    <sample id="1067">Ecco come si identificano casi come questo, in cui in cinese è necessario il contesto per tradurre i nomi propri in modo da assicurarsi di usare la stessa traduzione all'interno del documento.</sample>
    <sample id="1068">E simile, scopriamo che il contesto supporta la traduzione nella giusta formalità.</sample>
    <sample id="1069">Ecco la traduzione in italiano:</sample>
    <sample id="1070">Ora utilizziamo i risultati dell'analisi per disegnare un benchmark per le traduzioni a livello di documento.</sample>
    <sample id="1071">Per ogni dei 5 fenomeni di discorso identificati, abbiamo creato taggatori automatici per identificare le parole che riguardano il fenomeno e chiamiamo i nostri taggatori "taggatori multilingue con consapevolezza del discorso" (MDA).</sample>
    <sample id="1072">Possiamo notare anche che le lingue hanno delle proporzioni diverse di questi fenomeni discorsivi.</sample>
    <sample id="1073">Poi utilizziamo il tagger MoU applicando il tagger sulle corpora paralleli che vogliamo utilizzare per l'evaluazione e appliciamo i nostri metrini di traduzione di scelta sui esempi dipendenti dal contesto identificati dal tagger MoU.</sample>
    <sample id="1074">E, infine, abbiamo utilizzato il nostro benchmark, insieme ad altri metrici, per valutare diversi modelli nella traduzione automatica a livello di documento.</sample>
    <sample id="1075">In the first place, when we use corpus-level metrics, for BLEU, we find that context-agnostic models have the best performance.</sample>
    <sample id="1076">Ma se utilizziamo il virgolo, i modelli con consapevolezza della contestualità performano meglio. E se utilizziamo la misura F, i modelli con e senza consapevolezza della contestualità hanno prestazioni comparabili.</sample>
    <sample id="1077">Questo dimostra ancora che è difficile determinare la migliore sistema di traduzione a livello di documento se si utilizzano i metrini del livello del corpus da soli.</sample>
    <sample id="1078">Ora utilizziamo il benchmark di MovieLens per valutare i modelli e scopriamo che i modelli che utilizzano il contesto sono significativamente più accurati dei modelli che non ne utilizzano per certi fenomeni del discorso, come la formalità e la coesione lexica.</sample>
    <sample id="1079">Ma questi modelli non sono molto migliori rispetto a quelli che non utilizzano contesto su altri fenomeni, come ellipsi, pronomi e forme verbali. Questo suggerisce dove saremo costanti progressi per la traduzione a livello di documento.</sample>
    <sample id="1080">Hai confrontato diversi sistemi commerciali e i nostri risultati di benchmark mostrano che DeepL è generalmente più preciso della Traduzione di Google per le traduzioni del testo.</sample>
    <sample id="1081">In summation, eseguimmo un'analisi guidata da dati su 14 paia di lingue per identificare quando le traduzioni richiedono contesto.</sample>
    <sample id="1082">E poi, utilizziamo i risultati per costruire un benchmark per la traduzione a livello di documento, che ci aiuta a identificare quali fenomeni discorsivi i modelli possono gestire bene o no e quali sistemi di traduzione sono buoni per la traduzione a livello di documento.</sample>
    <sample id="1083">Grazie mille per l'attenzione, ci vedremo a Toronto</sample>
    <sample id="1084">The name of the speaker is Yuxin Zhang.</sample>
    <sample id="1121">It is not specified what the new method is called.</sample>
    <sample id="1122">The author describes the method as "a method to identify the words that distinguish marked groups from unmarked ones."</sample>
    <sample id="1123">University of Washington</sample>
    <sample id="1124">Prague approach</sample>
    <sample id="1125">Sarah Finch</sample>
    <sample id="1126">There are four authors involved in the article.</sample>
    <sample id="1127">The minimal pair paradigm can be used to test syntactic phenomena.</sample>
    <sample id="1161">WSL, WSL2, WSL3, WSL4, WSL5</sample>
    <sample id="1162">Il modello viene valutato su attività biomedicali e cliniche.</sample>
    <sample id="1226">CamemBERT è inizialmente addestrato su 4 gigabytes di dati.</sample>
    <sample id="1227">Szymon Skurkiewski</sample>
    <sample id="1228">Un esperimento per retrain o continuare a pretrainare alcuni modelli con dati più recenti</sample>
    <sample id="1269">Permutare i token per la sequenza di output è necessario perché, dopo il primo passo, abbiamo tutti i token giusti, ma non sono ordinati. Per questo motivo, nel secondo passo, utilizziamo un altro modello per predire una permutazione che li metta nella corretta ordine.</sample>
    <sample id="1270">Perché gli autori hanno suggerito ai proprietari dei modelli di aumentare la trasparenza sui metodi di mitigazione dei bias?</sample>
    <sample id="1271">In this minimal pair paradigm, the typical way to evaluate language models is that you show an acceptable sentence or a grammatical sentence and then you show an unacceptable sentence or an ungrammatical sentence.</sample>
    <sample id="1272">The authors used the following metrics to evaluate their work: 1. F1 score, which measures a model's accuracy by considering both precision and recall; 2. Mean Average Precision (MAP), another metric that assesses how well a ranking list is ordered in terms of relevance or importance; 3. Mean Reciprocal Rank (MRR), an evaluation measure for information retrieval systems based on the reciprocal rank of relevant documents found at each position in search results. These three metrics provide comprehensive insights into different aspects of performance such as overall classification quality, ordering effectiveness, and efficiency respectively.</sample>
    <sample id="1273">Interannotator agreement</sample>
    <sample id="1274">Vikipedia</sample>
    <sample id="1275">The authors are affiliated with the following institutions: University of Trier, Germany; University of Bremen, Germany; and University of Kaiserslautern, Germany.</sample>
    <sample id="1276">MultiInstruct è diverso dagli altri parametri di riferimento perché si concentra su esplorare l'efficacia del tuning delle istruzioni su modelli preaddestrati multi-modal, che include la visione e non solo il linguaggio. Inoltre, esiste una grande disparità nella disponibilità dei set di dati di istruzioni tra i modelli di linguaggio e quelli multi-modal, con più di 1600 task solo di linguaggio disponibili, ma nessun set di dati di istruzione a livello di modello multi-modal disponibile in grande scala.</sample>
    <sample id="1277">The article mentions two authors: Professor Gino Choi and Amazon Alexa AI.</sample>
    <sample id="1278">Coordinazione binaria è una definizione che non è completamente comprensibile solo con i contenuti inglese forniti.</sample>
    <sample id="1279">I'm not sure what you're asking about. Could you please clarify or provide more context?</sample>
    <sample id="1280">The implications of the results on a smaller T5 model are that it can generate scripts with higher quality than most large language models when trained on suitable datasets. This suggests that smaller models, if properly trained and fine-tuned, can perform well in tasks requiring high-quality script generation.</sample>
    <sample id="1281">Ciao, sono Yannislav Wagner e vi presento i nostri lavori su Dr. BERT, un modello robusto preaddestrato in francese per domini biomedici e clinici.</sample>
    <sample id="1282">In questa presentazione parlerò di modellazione linguistica nel campo della salute, poi presenterò le nostre principali contribuzioni.</sample>
    <sample id="1283">Introduttivamo il nostro modello di biomedicalo francese chiamato Dr. Bert, basato su Roberta e addestrato su NACHOS, un set di dati medico-cronologico estratto da Internet.</sample>
    <sample id="1284">Introduciamo una confronto tra modelli con setup di preaddestramento a più punti e fonti dati. Poi presentiamo i nostri risultati su 11 task biomedical e clinico downstream in Francia.</sample>
    <sample id="1285">In fine, conclude le experiementi e darete maggiori dettagli su come accedere ai modelli.</sample>
    <sample id="1286">Da quando è stato rilasciato nel 2018, BERT è diventato uno dei metodi più efficaci per risolvere i compiti di elaborazione del linguaggio naturale e offre un grande impatto su rispetto con i metodi statici e contestuali precedenti come Word2vec, FastText o ANIMAL.</sample>
    <sample id="1287">Da allora, questo modello è stato adattato a molti altri linguaggi, come in francese con Camembert e in altri domini, come biomedico con PubMed-BERT e Bio-BERT e clinico con Clinical-BERT, ma soprattutto in inglese.</sample>
    <sample id="1288">Istruzioni: Tradurre il contenuto inglese in italiano.</sample>
    <sample id="1289">Tuttavia, il francese non aveva un modello open-source per la biomedica e l'informatica.</sample>
    <sample id="1290">No, non chiediamo se le nostre domande riguardino qual è la fonte di dati più appropriata per un'ampia gamma di usi.</sample>
    <sample id="1291">Per rispondere a questa domanda, abbiamo confrontato il Dr. BERT con il nostro modello SubBERT, che è basato sulle dati anonimizzate ottenute dal Data Warehouse dell'ospedale universitario di Neuchâtel.</sample>
    <sample id="1292">Inoltre, chiediamoci: quanti dati abbiamo bisogno per addestrare un modello specializzato su dati francesi? È 4 gigabytes, 8 gigabytes o più?</sample>
    <sample id="1293">Per rispondere a queste domande, abbiamo prima addestrato e confrontato quattro modelli iniziali. Una prima versione di GPT-3 con 7 GB di Natusos, una seconda versione con 4 GB di subset di Natusos,</sample>
    <sample id="1294">Una prima versione di Shubert, che è un modello clinico, con 4 gigabytes di frasi tratti da note cliniche e una versione finale di Shubert con una mistura di 4 gigabytes di set di naturi e 4 gigabyte di note cliniche.</sample>
    <sample id="1295">Inoltre, ho introdotto tre modelli trainati con il pre-training continuo per analizzare l'effetto del pre-training.</sample>
    <sample id="1296">Uno basato sul peso di Camembert e trainato su un set di 4 gigabytes di Nachos, l'altro basato su Camembert ma trainato questa volta sui 4 gigabyte di clean and lots</sample>
    <sample id="1297">In fine, un base di un modello inglese di biomedical BERT e trainato su un subset di 4 gigabytes di Snatchos. In totale abbiamo set modelli.</sample>
    <sample id="1298">Per valutare i 7 modelli, abbiamo raccolto dati pubblici e privati su attività di comprensione del linguaggio come riconoscimento del testo, classificazione, taggataggio del testo e risposta a domande.</sample>
    <sample id="1299">Questo modello è confrontato con sei altri modelli di design, che sono Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCNet 4 GB, PubMed BERT, BioBERT e Clinical BERT.</sample>
    <sample id="1300">L'evoluzione di un modello che funziona meglio sul compito con dati della stessa natura è quindi quello su cui il modello è stato trainato.</sample>
    <sample id="1301">Tuttavia, possiamo ottenere i dati da...Possiamo osservare che i dati provenienti da sorgenti omogenee sembrano essere più versatili. Anche osserviamo che l'utilizzo di più dati si traduce in una migliore prestazione.</sample>
    <sample id="1302">In generale, il codice scritto dal zero sembra ottenere un bettero risultato su molte delle attività.</sample>
    <sample id="1303">Tuttavia, un esperimento su interpretazione controllata utilizzando il weight e il tokenizzatore di PubMed BERT trainato sul sottosettore di 4 gigabytes di Natchos mostra risultati compariabili a quelli ottenuti con Dr. BERT 4 gigabyte da zero.</sample>
    <sample id="1304">Ma non è il caso per i modelli basati sul KAMBAUER-WEIGHTS e sul tokenizer, che subiscono problemi di stabilità.</sample>
    <sample id="1305">In fine, en conclusion, notre système propose une meilleure performance sur 9 des 11 tâches de DonTrIm et dépasse globalement les résultats du modèle générique Camembert.</sample>
    <sample id="1306">Anche abbiamo osservato che i dati specializzati sono migliori, i dati specializzati sono migliori, ma non scalano bene.</sample>
    <sample id="1307">I'll provide the pre-trained model from NATEOS and the training script on our GitHub repository.</sample>
    <sample id="1308">Grazie per questa presentazione e stiamo impaziente di scambiare opinioni durante la sessione di discussione poster.</sample>
    <sample id="1309">Quattro strategie di apprendimento: 1) From scratch 2) From scratch con subset di Natusos 3) Chabert con subset di Natusos 4) Chabert con un mix di subset di Natusos e di CleanConll</sample>
    <sample id="1310">The factor of overfitting due to reusing the test is 1.</sample>
    <sample id="1311">Sì, l'articolo ha valutato la qualità della semplificazione automatica del testo.</sample>
    <sample id="1312">Sì, i modelli linguistici presentano bias politici diversi.</sample>
    <sample id="1313">Ciao, mi chiamo Mattias Lindemann e oggi vi darò una breve introduzione al nostro articolo su generalizzazione compostizionale senza alberi utilizzando tag di multisette e permutazioni latenti.</sample>
    <sample id="1314">Questo è un lavoro in collaborazione con i miei consiglieri Alexander Colyer e Ivan Titov.</sample>
    <sample id="1315">La generalizzazione compostionale può essere compresa come la capacità di un apprendente di gestire una recursione più profonda e compostazioni non viste compostate da frasi che sono state viste individualmente durante il training.</sample>
    <sample id="1316">Nel contesto della parsing semantico, il test per la generalizzazione compostionale potrebbe essere simile a questo: come di solito, abbiamo un set di espressioni trainee, in questo caso "la ragazza si è addormentata" e "Mary sapeva che la ragazza si è addormentata".</sample>
    <sample id="1317">Queste affermenze sono associate a forme logiche che rappresentano gli aspetti principali del loro significato.</sample>
    <sample id="1318">In contrast to standard machine learning evaluation, the test set does not come from the same distribution but contains structurally unseen logical forms.</sample>
    <sample id="1319">Nel caso di esempio, il modello ha visto la ricorsione superficiale durante l'addestramento e è stato testato su un esempio con ricorsione più profonda.</sample>
    <sample id="1320">Ironicamente, i modelli di sequenza a sequenza semplici si rifiutano di gestire queste generalizzazioni fuori dal distribution e spesso producono output che non sono correlati all'input.</sample>
    <sample id="1321">In particolare, spesso non riescono a riprodurre le corrispondenze sistematiche tra input e output, come quelle che sono codificate in colori nelle esempi.</sample>
    <sample id="1322">Un metodo popolare per risolvere questo problema consiste nell'integrare gli alberi nei modelli.</sample>
    <sample id="1323">Iscriviti alla lista di diffusion e ricevi notifiche quando ci sono nuovi messaggi.</sample>
    <sample id="1324">Questo funziona bene, ma le alberi non sono generalmente forniti e devono essere ottenuti in qualche modo.</sample>
    <sample id="1325">Questo può essere complesso e in alcune circostanze un processo costoso in termini di calcolo. Di solito, richiede una grande pre-elaborazione specifica del formalismo dei formi logiche, ad esempio per gestire i simboli variabili.</sample>
    <sample id="1326">Ottenere gli alberi può anche coinvolgere procedure di induzione grammaticale specializzate.</sample>
    <sample id="1327">In this paper, we don't use trees and introduce a neural sequence-to-sequence model that directly models the correspondences between fragments of the input and fragments of the output.</sample>
    <sample id="1328">Per la prima volta, dimostriamo una generalizzazione fortemente a diversa ricorsività senza sfruttare gli alberi.</sample>
    <sample id="1329">Il nostro approccio predispone l'output dal input in due passi.</sample>
    <sample id="1330">Iniziamo taggando ogni token di input con un insieme multiset indeterminato di token che saranno presenti nella uscita.</sample>
    <sample id="1331">Dopo il primo passo abbiamo tutti i token giusti, ma non sono ordinati.</sample>
    <sample id="1332">Perché, nella seconda fase, utilizziamo un altro modello per predire una permutazione e metterle nel giusto ordine.</sample>
    <sample id="1333">Introduce a new method to predict a permutation that doesn't impose any strict constraints on the possible permutations. This makes our approach quite flexible and expressive.</sample>
    <sample id="1334">In modo concettuale, il nostro modello di permutazione funziona come segue:</sample>
    <sample id="1335">Passiamo dal lato sinistro al lato destro dell'output e determiniamo quale token di multisettare mettere in ogni posizione. Per la prima posizione dell'output, semplicemente selezioniamo uno, come evidenziato in rosso.</sample>
    <sample id="1336">Poi saltiamo al prossimo token multi-set per determinare il secondo token nell'output.</sample>
    <sample id="1337">Determiniamo il terzo token nell'output in modo simile, saltando a un altro token multiset. Continuiamo questo processo.</sample>
    <sample id="1338">Fino a quando ogni token della prima fase è visitato esattamente una volta.</sample>
    <sample id="1339">Per darti un'anteprima dei risultati sperimentali, qui confrontiamo il nostro metodo con altri modelli albero-less sul benchmark KOGS. Il nostro modello supera gli altri di una larga margine nella generalizzazione a ricorsione più profonda.</sample>
    <sample id="1340">Alcune forme di organizzazione strutturale sono ancora molto impegnative.</sample>
    <sample id="1341">Nel nostro articolo risolviamo alcuni problemi tecnici interessanti.</sample>
    <sample id="1342">In primo luogo, l'alineamento tra input e output non è fornito nei dati di training. Di conseguenza, per un token specifico, non sappiamo da dove proviene, che introduce un problema durante il training.</sample>
    <sample id="1343">Inoltre, a volte ci sono più permute che consentono ai dati, ma la corretta linguistica è nascosta. Risolviamo questo inducendo l'alleanza come parte della formazione.</sample>
    <sample id="1344">Il nostro metodo di permuatazione è molto flessibile, ma porta il problema di trovare la permutazione che ha il punteggio più alto. Questo è perché è legato al problema del venditore che si muove in viaggio.</sample>
    <sample id="1345">Stiamo approssimando questo con una relaxazione continua amica del GPU che ci permette anche di propagare indietro attraverso la soluzione e imparare le permutazioni più plausibili dal linguaggio.</sample>
    <sample id="1346">Se vuoi imparare di più sul nostro esperimento e su come risolviamo questi problemi, visita il nostro articolo o visita il nostro affollato.</sample>
    <sample id="1347">Cognitive dissonance è una percezione psicologica di incoerenza o incongruenza tra due credenze o azioni che sono inconsistenti.</sample>
    <sample id="1348">GPT-4 è il modello linguistico più liberale.</sample>
    <sample id="1349">No, in l'apprendimento attivo, l'addestramento cumulativo non funziona meglio di quello iterativo.</sample>
    <sample id="1350">Sarah Papi</sample>
    <sample id="1351">I'm sorry, I don't have enough information to answer that question. Could you please provide more context or details about the source of data in the MuDa parameter?</sample>
    <sample id="1385">Matthias Lindemann</sample>
    <sample id="1386">Il trasferimento interlinguistico è un processo di apprendimento automatico che consente ai modelli di apprendere e utilizzare le informazioni in un linguaggio per comprendere e rispondere in un altro.</sample>
    <sample id="1387">Silent University in Germany</sample>
    <sample id="1388">Gli autori fanno ricorso alle misure di latenza average lagging e computational aware average lagging.</sample>
    <sample id="1389">Ciao a tutti, sono Maksymilian e oggi il mio collega Martin e io presentiamo il nostro lavoro "The Kit-Mask: Evaluating Knowledge Integration from Multiple Sources". Questo lavoro è una collaborazione tra McGill University, Mila e Microsoft Research.</sample>
    <sample id="1390">Iscriviti alla newsletter</sample>
    <sample id="1391">Ispirazioni recenti in attività come la risposta alle domande mostrano che i modelli possono utilizzare conoscenze preaddestrate per risolvere il compito.</sample>
    <sample id="1392">Ma l'intelligenza del linguaggio naturale richiede spesso conoscenze che vengono anche fornite durante il processo di inferenza.</sample>
    <sample id="1393">Adjectives are used to describe or modify nouns and pronouns. For example, in the sentence "John saw the newly elected president on TV," the adjective "newly" describes the noun "elected president."</sample>
    <sample id="1394">Parametri di preaddestramento possono contenere informazioni sullo "che fa il presidente" e su "qual è la TV", ma non possono sapere con fiducia chi è questo entità specifica di istante "John" o chi è il nuovo presidente perché il presidente potrebbe essere cambiato dal preaddestramento.</sample>
    <sample id="1395">Quindi, i modelli riusciti per attività NLU intensa nel conoscere richiedono la capacità di integrare e utilizzare sia il know-how preaddestrato che quello di inferenza.</sample>
    <sample id="1396">In questo lavoro, propongiamo un set di test diagnostici per l'integrazione del sapere.</sample>
    <sample id="1397">Introduciamo una complessità di risoluzione che si basa sull'abilità di utilizzare conoscenze disponibili in diversi contesti. Valutiamo il set di dati con partecipanti di studio umani e modelli di risoluzione di riferimento consolidati.</sample>
    <sample id="1398">Here is an example from our dataset. Serving is a judge. Kia is a baker. Serving and Kia met at a park after the long day at work deciding cases in a law court, he was happy to relax.</sample>
    <sample id="1399">Il compito qui è quello di identificare l'entità corretta che il pronome "he" si riferisce a, che in questo caso è Sam.</sample>
    <sample id="1400">Risoluzione di un determinante specifico richiede due tipi di informazioni: la conoscenza specifica dell'entità, come "Cerwin è un giudice", e la conoscenza generale, come "I giudici decidono i casi nelle corte legali".</sample>
    <sample id="1401">In generale, i knowledgi di fondazione sono imparati durante la preaddestramento dei modelli di linguaggio grandi, mentre i knowledgi specifici degli entità sono generalmente osservati durante l'inferenza.</sample>
    <sample id="1402">Modifichi l'accessibilità di queste due informazioni in modo che possano essere trovate in un'unica fonte o in più fonti.</sample>
    <sample id="1403">Abbiamo definito tre impostazioni di KitMOS. Inizialmente abbiamo la setting topica di background pre-training, dove il know-how è presumibile disponibile durante il pre-training.</sample>
    <sample id="1404">Second, there is the background both setting. Where background knowledge is available at both at pre-training time and inference time. Lastly, the background in inference setting where both knowledge types are available only at inference type</sample>
    <sample id="1405">Questo setting ultimato è particolarmente interessante, poiché simulano il caso in cui il rumore di sfondo non sia necessario per risolvere il compito e non fa parte dei dati di preaddestramento dei modelli. Ad esempio, perché nuove occupazioni sono sviscerate dal tempo del preaddestramento.</sample>
    <sample id="1406">Ecco un esempio di come controllare l'accessibilità effettiva delle fonti di verità.</sample>
    <sample id="1407">Nel setting di preadde, si assume che il sapere di fondazione "i politici cercano seggi elettorali nel governo" sia contenuto nelle parametri di preadde. Nello scenario di inferenza, forniamo il sapere specifico dell'entità "Cheadle è un politico".</sample>
    <sample id="1408">In the background setting, we additionally provide not only entity-specific but also background knowledge about politicians in their influencer context.</sample>
    <sample id="1409">In the background information setting, provide the fictional occupation "meritour" instead of politician because meritour is unlikely to be contained in a pre-trained parameter.</sample>
    <sample id="1410">Abbiamo valutato il set di dati con entrambi gli esami del suddetto e i modelli di riferimento establishi. In questo grafico abbiamo mostrato i risultati dei migliori modelli sulle varianti più difficili del setting di preaddestramento del background.</sample>
    <sample id="1411">Senza addestramento specifico per i modelli, entrambi non si performano bene. Quando si addestrano sul KitMOS, tuttavia, entrambi C2F e BERT4CoF si performano molto meglio rispetto alla scelta casuale.</sample>
    <sample id="1412">Questo suggerisce che i modelli apprendono di sfruttare le indicazioni della superficie quando si addestrano su dataset di rilevazione generici, ma non sono utili quando si testa su KitMOS, in cui tali indicazioni sono state eliminate.</sample>
    <sample id="1413">Altri esperimenti con conoscenza falsa indicano che nemmeno i modelli più performanti possono integrare la conoscenza retrospettiva in modo affidabile, fornendo solo un'inferenza temporale.</sample>
    <sample id="1414">In summation, many models for coreference resolution struggle to reason with knowledge from various sources without specific task training. Nevertheless, after receiving specialized training on tasks, some of these models can effectively combine information from multiple sources.</sample>
    <sample id="1415">Anche le migliori modelli sembrano avere difficoltà a integrare con fiducia il know-how di background presentato solo durante l'inferenza. Se hai interesse per maggiori dettagli, consulta il nostro articolo e controlla il set di dati e il codice su GitHub. Grazie per la tua ascolta</sample>
    <sample id="1416">Obtaining trees may also involve specialized grammar induction procedures.</sample>
    <sample id="1417">The authors are affiliated with the University of Hong Kong and Tsinghua University.</sample>
    <sample id="1418">Ciao, sono Myra e oggi parlerò del nostro articolo "Personaggi etichettati: misurando gli stereotipi nei modelli di linguaggio usando prompt naturali". Questo lavoro è realizzato in collaborazione con Sen Dirmuš e Dan Jurafsky.</sample>
    <sample id="1419">Negli ultimi anni molte persone hanno evidenziato la diffusione di pregiudizi sociali e stereotipi nei modelli di linguaggio a larga scala, o LLM.</sample>
    <sample id="1420">Tuttavia, questi metodi presentano molte limitazioni. Spesso si basano su dataset manualmente costruiti che richiedono molto tempo per essere curati.</sample>
    <sample id="1421">Ecco la traduzione in italiano:</sample>
    <sample id="1422">Inoltre, la maggior parte del lavoro in questo campo non contorna l'intersectionalità, che è la idea che identità sociali complesse possono compounding bias e essere luoghi unici di danno.</sample>
    <sample id="1423">Per superare questi vincoli, ci appoggiamo sull'idea che questi modelli di LLM più recenti sono molto bravi a rispondere alle istruzioni e alle proposte.</sample>
    <sample id="1424">Possiamo chiedere al modello di generare un personaggio, che è una rappresentazione di un individuo immaginato, usando un prompt come "immagina di essere una donna asiatica, descriverti".</sample>
    <sample id="1425">Possiamo vedere immediatamente che questo è generalizzabile a qualsiasi demografia, perché possiamo specificare qualsiasi segnalore di identità che vogliamo in questo prompt.</sample>
    <sample id="1426">Ecco alcuni esempi di generazione da GPT-4.</sample>
    <sample id="1427">Subito vediamo che, mentre i risultati non sono overtamente negativi o tossici nel senso tradizionale di queste parole,</sample>
    <sample id="1428">C'è un po' di pattern interessanti.</sample>
    <sample id="1429">L'asina donna è rappresentata come sull'assumendo, la donna del Medioe东风用词如异国情调和迷人的地区来指代。</sample>
    <sample id="1430">Ecco la traduzione in italiano: E entrambe le personaggi donne di colore fanno riferimenti alla discendenza, mentre il personaggio del uomo bianco non ha nulla del genere.</sample>
    <sample id="1431">Per capturar questi modelli, il nostro approccio ha due parti: la prima è la generazione di queste personaggi.</sample>
    <sample id="1432">I'm sorry, but I can't provide the translation you requested.</sample>
    <sample id="1433">E anche questo consente una confronto diretto tra i nostri profili generati e le risposte scritte dallo umano.</sample>
    <sample id="1434">La seconda parte è "Parole marcate", che è un metodo per identificare le parole che distinguono i gruppi marcati dai non marcati, che espliquerò di più presto.</sample>
    <sample id="1435">L'efficacia di questo è che otteniamo stereotipi e pattern molto specifici senza dover fare riferimento a alcun vocabolario specifico.</sample>
    <sample id="1436">Il metodo dei segni evidenzia i modi in cui le variazioni linguistici vengono riconosciute come distinte e significative.</sample>
    <sample id="1437">Ad esempio, la parola "warrior" è generalmente associata ai uomini, quindi quando le persone descrivono una "warrior" che è una donna, spesso specificano "woman warrior" e mettono in evidenza la parola con "woman".</sample>
    <sample id="1438">In generale, i gruppi dominanti in una società sono tipicamente indistinguibili linguisticamente e socialmente, mentre i gruppi marginalizzati sono spesso facilmente identificabili.</sample>
    <sample id="1439">Inoltre, definiamo prima i gruppi non etichettati e etichettati.</sample>
    <sample id="1440">E poi confrontiamo i personaggi utilizzando il metodo dei "Fighting Words", che consiste nell'utilizzare le rationi di logodati pesate per distinguere le parole più importanti per ogni gruppo etichettato.</sample>
    <sample id="1441">Per esempio, per le personaggi delle donne nere faremo "parole dure" e confronteremo i loghi-ratios con quelli delle persone bianche e maschili, perché sono i due gruppi corrispondenti non etichettati.</sample>
    <sample id="1442">Ecco alcuni risultati: prima, utilizziamo un'elenco di stereotipi e scopriamo che i personaggi generati contengono molti stereotipi più di quelli scritti dallo umano.</sample>
    <sample id="1443">Tuttavia, se guardiamo la distribuzione delle parole nel vocabolario, vediamo cose molto diverse.</sample>
    <sample id="1444">Quindi, mentre i personaggi generati hanno un tasso molto alto di parole del Luxembourg, i personaggi scritti dall'essere umano hanno una distribuzione molto più ampia delle parole, mentre le parole stereotipizzate presenti nei personaggi generati sono solo le parole "alti" e "flessibili".</sample>
    <sample id="1445">Quindi, davvero solo i positivi o almeno i non negativi.</sample>
    <sample id="1446">E in realtà, questo vocabolario non rappresenta molto bene i modelli dannosi che abbiamo visto nelle slide precedenti. Quindi, per fare ciò, ci torneremo alle risposte del nostro metodo MarkWords per mostrare come queste parole che sembrano positive facilitino stереotipi e narrativa di essenzializzazione.</sample>
    <sample id="1447">Nell'analisi, elenchiamo come questi portreti apparentemente positivi riflettano pattern dannosi.</sample>
    <sample id="1448">Primo, per i gruppi di razzia, le parole più frequenti includono cose come cultura, tradizione, orgoglio e esotico. Queste parole definiscono questi gruppi solo in relazione alla loro identità e li distinguono dal norma bianca.</sample>
    <sample id="1449">Questo contribuisce a una lunga tradizione di discriminazione e allontanamento per questi gruppi.</sample>
    <sample id="1450">Inoltre, ci sono molte stereotipi che sono riflessi in queste parole, specialmente per le donne di colore. Per esempio, le parole che descrivono le donne latine includono cose come "vivaci" e "curvi".</sample>
    <sample id="1451">Per le donne asiatiche, le parole sono piccola, delicata e seta.</sample>
    <sample id="1452">Si connette a una lunga storia di donne asiatiche che sono escese come esotiche, vistasse come molto docili e sottomissi e così via.</sample>
    <sample id="1453">E infine, per le donne nere vediamo che alcune delle parole più frequenti sono cose come "forza" e "resilienza".</sample>
    <sample id="1454">Questo si collega all'un archetype chiamato "archetype of the strong black woman" e mentre suona positivo a prima vista,</sample>
    <sample id="1455">Ci sono studi che mostrano che questo archetipo effettivamente è molto dannoso perché mette molto stress su queste demografie per essere resili e forti contro gli impunti sociali.</sample>
    <sample id="1456">Quindi, altra persona non va a fare del tutto del proprio meglio per superare quelli, ma spinge quei individui a farlo, portando a risultati di salute negativi e altri problemi.</sample>
    <sample id="1457">Più in generale, scopriamo che le parole per ogni gruppo etnico rappresentano narrative molto centralizzate.</sample>
    <sample id="1458">Quindi, a partire da questi modelli, concluiamo con tre consigli per gli proprietari del modello.</sample>
    <sample id="1459">Inizialmente, gli investigatori dovrebbero affrontare i stereotipi positivi e le narrativa essenzializzanti. Inoltre, dovremmo utilizzare un'approccio di intersezione per studiare i pregiudizi e i danni, perché ci sono molte cose che potrebbero essere passiate in rilievo se non facciamo questo.</sample>
    <sample id="1460">E, infine, ci dovrebbe essere una maggiore trasparenza riguardo i metodi di mitigazione del bias.</sample>
    <sample id="1461">Per esempio, non sappiamo se questi stereotipi positivi siano dovuti a</sample>
    <sample id="1462">Sì, ci sono certe teorie che suggeriscono che il focus eccessivo sullo al线mento del valore possa portare a pattern dannosi.</sample>
    <sample id="1463">Non possiamo fare alcuna ipotesi o studiarlo ulteriormente senza maggiore trasparenza.</sample>
    <sample id="1464">Grazie mille per diammare, ha un buon tempo alla ACE.</sample>
    <sample id="1465">Ciao a tutti, mi chiamo Jingwei Yi e sono dell'Università di Scienze e Tecnologie della Cina.</sample>
    <sample id="1466">It's my pleasure to give a short advertisement video about paper. Are you copying my model? Protecting the copyright of large language models for embedding and services via backdoor watermark</sample>
    <sample id="1467">Iniziamo con un'introduzione sullo scenario di Embedding as a Service.</sample>
    <sample id="1468">Attualmente, i modelli di linguaggio grandi come GPT, Llama e Palm sono eccezionali nella comprensione e nella generazione del linguaggio naturale.</sample>
    <sample id="1469">嵌入式服务是建立在大型语言模型上，以协助各种NLP任务的服务之一。</sample>
    <sample id="1470">Advertently, OpenAI fornisce un API di embedding basato su GPT.</sample>
    <sample id="1471">Tuttavia, gli ultimi studi hanno dimostrato che l'attaccante può stillare il modello attraverso l'apprendimento dell'embedding e fornire servizi simili. Pertanto, è necessario proteggere i diritti d'autore dell'embedding come servizi.</sample>
    <sample id="1472">Per proteggere i diritti d'autore di un servizio di embedding, una delle soluzioni è di incorporare un watermark nel servizio fornitore e controllare se un altro servizio contiene il watermark.</sample>
    <sample id="1473">Il metodo del contrassegno deve soddisfare le seguenti proprietà: 1. Il metodo deve essere applicabile all'incorporazione in servizi; 2. Il contrassegno non deve degradare l'utilità dell'incorporazione fornita;</sample>
    <sample id="1474">Il terzo, il segno di watermark dovrebbe essere abbastanza coperto per l'attaccante, altrimenti l'attaccante potrebbe rimuovere il segno di watermark facilmente.</sample>
    <sample id="1475">In fine, il segno d'acqua deve essere trasferibile alle risorse del malatore durante il processo di estrazione del modello.</sample>
    <sample id="1476">Gli opere esistenti possono essere generalmente suddivise in quattro categorie:</sample>
    <sample id="1477">Tuttavia, questo metodo non è applicabile alle embedding come servizi o non ha una trasferibilità.</sample>
    <sample id="1478">Quindi, in questo documento propongiamo Embedded Marker, un metodo di watermark basato sullo spiazzo applicabile all'incorporazione di servizi.</sample>
    <sample id="1479">然后让我介绍嵌入标记的详细信息。嵌入标记包含两个主要步骤：水印注入和版权验证。</sample>
    <sample id="1480">Prima di questi passi principali, scegliamo prima un set di trigger. Un set di trigger è un gruppo di parole in un intervallo di frequenza moderato.</sample>
    <sample id="1481">Supponiamo che il fornitore possa raccolgere un'anteprima del testo e contare la frequenza delle parole.</sample>
    <sample id="1482">In watermark injection, we first define a target embedding. When a user sends a sentence to the provider's service, the provider counts the trigger number in the sentence.</sample>
    <sample id="1483">The provided embedding is a weight summation of the target embedding and the original embedding.</sample>
    <sample id="1484">Il peso dell'embedding di destinazione è proporzionale al numero di trigger nella frase. Quando il numero dei trigger nella frase è maggiore di m, l'embedding fornito è esattamente uguale all'embedding di destinazione.</sample>
    <sample id="1485">Copyright verification is to detect whether a model behind another service contains the watermark.</sample>
    <sample id="1486">Primo, costruiamo una porta d'ingresso e un set di dati benigno. Il set di dati porta contiene frasi in cui tutti i termini appartengono al set di trigger, mentre tutti i termini delle frasi del set di dati benigno non appartengono al set di trigger.</sample>
    <sample id="1487">Poi il fornitore richiede le embeddings dal servizio Stellar con il set di dati.</sample>
    <sample id="1488">Si calcola la differenza tra il delta costante e delta L2.</sample>
    <sample id="1489">Inoltre, appliciamo il test ks e utilizziamo il suo valore p come terro metrico.</sample>
    <sample id="1490">Abbiamo condotto sperimenti su quattro dataset: AG News, MIMD, SSD2 e ERS Spam. Dobbiamo supporre che il fornitore applichi il dataset di Wikitext per contare le frequenze delle parole.</sample>
    <sample id="1491">I'm sorry, I can't understand what you're saying. Could you please repeat or rephrase it?</sample>
    <sample id="1492">abbiamo anche valutato la correttezza dell'embeddendo fornito visualizzando l'embeddendo delle frasi sul dataset via PCA. La legenda della figura indica il numero di trigger in ogni frase.</sample>
    <sample id="1493">Come mostrato nelle figure, è difficile distinguere tra le embedding con porta di accesso e le embedding normali.</sample>
    <sample id="1494">Che cosa vuoi dire?</sample>
    <sample id="1495">Annotating Behaviors in Chat</sample>
    <sample id="1496">The difference of performance between CoNLL-2003 and CoNLL++ is greater than 5 percentage points in the years: 2018, 2019, 2020.</sample>
    <sample id="1497">Ciao, mi chiamo Vasudha e sono candidata in Laurea Magistrale in Scienze Informatiche all'Università di Stony Brook. Vorrei presentare il nostro lavoro accettato nell'Acl 2023 come un lungo articolo: "Transfer Learning per la Detezione di Dissonanze: Affrontando il Problema della Classificazione Rare".</sample>
    <sample id="1498">Iniziamo definendo il disagio cognitivo e perché è un problema importante da studiare nella lingua. Abbreviato, il disagio cognitivo si riferisce a due credenze o azioni che sono incongruenti.</sample>
    <sample id="1499">Q: Suggest this example where a person states, "I know that cigarettes could kill me," and then goes on to say, "I grabbed a couple of smokes after the meeting." This belief and action are inconsistent and they are in dissonance.</sample>
    <sample id="1500">The second occurrence justifies the first one and they have a consonance relationship.</sample>
    <sample id="1501">La disonanza è un fenomeno molto comune che sperimentiamo nella decisione quotidiana, ma è raro di venire a grips con essa attraverso le parole e le relazioni di discorso.</sample>
    <sample id="1502">Quindi perché è importante? Stare attento alla distanza cognitiva ci aiuta a comprendere gli effetti della discordia tra le persone, ad urbermare i trend nelle credenze, nei valori e nelle modifiche dell'attitudine nelle popolazioni.</sample>
    <sample id="1503">La dissonanza cognitiva elevata è anche legata alle disturbi dell'ansia e può aiutare a comprendere meglio la salute mentale delle persone.</sample>
    <sample id="1504">Studying dissonance expressed in language can also be beneficial in understanding extremism and polarization of vulnerable groups.</sample>
    <sample id="1505">Inoltre, la disonanza cognitiva è importante per comprendere i modi di pensare personali delle persone e aiuta a comprendere meglio i processi di decisione.</sample>
    <sample id="1506">Per raggiungo il nostro obiettivo di creare un'origine di incongruenza cognitiva, abbiamo effettuato una annotazione a larga scala delle relazioni di incongruenza. Hemos utilizado el enfoque de incongruencia "Primera" como se ve en el diagrama de flujo aquí.</sample>
    <sample id="1507">Iscriviti alla lista di contatto per ricevere le notifiche sulle novità.</sample>
    <sample id="1508">Come si può vedere qui, la sostenibilità è stata trovata solo in un 3,5% delle coppie annotate.</sample>
    <sample id="1509">Dopo aver raccolto circa mille esempi di paia di unità di discorso, abbiamo eseguito il training per un classificatore iniziale, addestrato solo su 43 esempi di disness. Non è una sorpresa, il classificatore ha funzionato poco meglio che casualmente.</sample>
    <sample id="1510">Tenendo conto della scarsa frequenza di dissonanze e dell'assenza di qualsiasi set di dati simile, stiamo affrontando il problema della rarezza assoluta.</sample>
    <sample id="1511">Per alleviare questo, sperimentiamo le combinazioni di impegno di trasferimento e impegno attivo per annotare in modo da poter raccolgere più campioni di dissonanza in meno giri di annotazione, riducendo i costi generali dell'annotazione mentre migliorando la detezione della dissonanza.</sample>
    <sample id="1512">Poiché il modello iniziale non ha riuscito a capturare la classe della dissonanza affatto, abbiamo iniziato il processo di apprendimento a coltura trasferendo i pesos da attività che si sovrappongono.</sample>
    <sample id="1513">We transfer from two different tasks: topic-independent disentangled stance classification, a task that determines if two debate statements from different people are in agreement or in disagreement irrespective of topic.</sample>
    <sample id="1514">Chose "debate" and call them "CEE" here.</sample>
    <sample id="1515">Ricordiamo che il performance zero-shot è molto migliore rispetto alla probabilità casual, raggiungendo un AUROC di 0.62.</sample>
    <sample id="1516">Successivamente, eseguendo ulteriormente il rafforzamento su entrambi i compiti scopriamo che il rafforzamento dei compiti CE seguito dal rafforzamento ulteriore su Debate dà un performance molto migliore in zero shot. Pertanto, questo è il modello che utilizziamo per iniziare il machine learning.</sample>
    <sample id="1517">Successivamente, determiniamo il metodo migliore per aggiornare un modello con nuovi dati da ogni giro di apprendimento attivo e annotazioni. Cumulador accumula tutti i dati raccolti da le annotazioni attive finora. Per iterativo, aggiorna il modello eseguendo il training sul set più recente dei dati raccolti.</sample>
    <sample id="1518">Per i diversi strategie, abbiamo trovato che accumulativo ha eseguito uguale o meglio di iterativo in tutto il board.</sample>
    <sample id="1519">Per migliorare il numero di esempi di dissonanza, utilizziamo una strategia di probabilità di classe rara (PRC) per selezionare principalmente gli esempi che sono altamente propeni a essere considerati dissonanti dal modello attuale in qualsiasi giro di AFL.</sample>
    <sample id="1520">Lasciamo perdere una confronto con le altre strategie di AL state-of-the-art più comuni usate nella comunità.</sample>
    <sample id="1521">Trovatemo che la nostra strategia PRC funziona meglio rispetto alle altre strategie state-of-the-art, anche se la differenza è piccola. Sappiamo che il performance è molto inferiore per il random.</sample>
    <sample id="1522">Nondiscreminas clasificación AUC a 0.75, que es el mejor rendimiento que tenemos en la tarea hasta ahora.</sample>
    <sample id="1523">abbiamo anche controllato la feasibilità di ogni strategia per la qualità della annotazione e i costi per gli annotatori. Abbiamo scoperto che PRC ha il massimo percentuale di dissonanze e funziona meglio per le classi rari, tuttavia gli annotatori hanno anche trovato gli esempi difficili.</sample>
    <sample id="1524">In summario, scopriamo che PRC è una strategia semplice per l'acquisizione di classi rare e l'inizio freddo del machine learning con un compito di apprendimento trasferimento correttamente progettato e aiuta significativamente.</sample>
    <sample id="1525">abbiamo anche trovato che l'aggiornamento iterativo è utile per il trasferimento di conoscenze da un dominio diverso, mentre le annotazioni attive del dominio coincidono beneficiano dell'aggiornamento accumulativo.</sample>
    <sample id="1526">Ecco i collegamenti ai nostri dataset di codice e al nostro articolo. Non esitate a contattarci se hai domande. Grazie</sample>
    <sample id="1527">Alexander Collier, Ivan Titov</sample>
    <sample id="1528">The speaker is MC YUAN from Fudan University.</sample>
    <sample id="1529">Five authors are involved in this article.</sample>
    <sample id="1530">The approach is compared with popular strategies that are also applied to offline models, such as the weight-key strategy and local agreement. Additionally, it is compared with state-of-the-art architectures specifically tailored for simultaneous speech translation.</sample>
  </task>
</testset>