<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="zh">
    <sample id="0">语言模型的主要数据来源是大规模的网络爬取数据。</sample>
    <sample id="1">这篇论文的作者所属机构是McGill University、Mila和Microsoft Research。</sample>
    <sample id="2">The paper discusses a new pre-trained model called LayoutMask, which addresses reading order issues in Visually-rich Document Understanding (VrDU) tasks. The authors propose using local 1D position instead of global 1D position to represent the global reading order of tokens in documents. They also introduce two novel masking strategies: Whole Word Masking and Layout-Aware Masking, as well as a new pre-training objective, Masked Position Modeling. Experimental results show that LayoutMask outperforms existing document pre-training models on various datasets like FUNSD and SROIE.</sample>
    <sample id="3">你好，我是Regina Stodden，我将引导你通过DEPLAIN的介绍的第一部分。让我们首先定义文本简化。文本简化是适应文本以改善特定目标群体的理解的过程，例如阅读障碍者或非母语使用者。为了训练文本简化模型，我们需要平行对文本，例如文档或句子。例如，您可以看到一个复杂德语句子和其翻译成简单语言的平行对齐句子。为了简化句子，可以使用不同的技术，如词汇替换、从句删除、重排或插入单词。现在，我们提出了我们的新数据集DEPLAIN，因为它在最近几年中存在一些现有数据集的问题。例如，这些数据集太小，无法在文本简化模型上进行训练。其他三个模型都是自动对齐的，这意味着它们的对齐可能会有错误。因此，我们提出了DEPLAIN，它分为两个子数据集：DEPLAIN-apa和DEPLAIN-web。DEPLAIN-apa基于新闻文章。在DEPLAIN-apa中，我们手动对齐了483篇文档，结果大约有13,000个平行句子对。对于DEPLAIN-web，这个数据集包括不同的领域，并且我们对这750篇文档进行了手动和自动对齐。总共有30,450个句子对。我们分析了我们的句子对，例如类型简化。正如您所看到的，圣经文本比新闻文本或语言学习文本更强烈地简化。在所有级别上，例如词汇简化、结构简化，以及总体简化水平，您都可以看到我们的DEPLAIN数据集具有很高的多样性。此外，您还可以看到在DEPLAIN-apa数据集中，我们有更多的重新排序和单词添加，而在DEPLAIN-web数据集中，我们有更多的重述。现在，让我们看看我们可以用这个数据集做什么。你好，我是Omar，现在我将谈论DEPLAIN数据集的潜在应用。第一个应用是评估自动对齐方法。在最近几年中，在机器翻译的上下文中，有两个平行文档，用不同的语言编写，我们想要提取两个文档中的句子对齐。但在我们的用例中，我们尝试提取两个具有相同语言、相同内容但复杂度不同的平行文档之间的句子对齐。现在，由于我们有DEPLAIN数据集，其中包含手动对齐的句子，我们可以使用这些句子作为黄金标准对齐来评估提出的对齐方法。我们对这些方法进行了适应，并在论文中发布了所有这些适应和运行我们实验的代码。最终，我们得出结论，MASSalign是用于德语文本简化的最佳自动对齐方法。您也可以在论文中找到运行此方法的代码。第二个应用，我们在论文中展示的是自动文本简化，通过在语言模型上进行微调来产生复杂输入文本的简化文本。我们微调了两个不同的模型。我们微调了长mBART模型来生成文档级简化，我们还微调了基本mBART模型来生成句子级简化。您也可以在论文中找到所有检查点，并可以在更多细节、评估指标和实验分数方面查看我们的结果。我们得出结论，这种基本微调可以产生或获得比基线分数更好的分数，并且我们建议这些结果作为未来自动文本简化的基准。感谢您的关注，希望在会议上见到大家。谢谢。</sample>
    <sample id="4">演讲者的名字是Kayo Yin。</sample>
    <sample id="5">他们使用 T5 XL 模型获得 82%-87% 的准确率。</sample>
    <sample id="6">Jiaan介绍了一项名为“Towards Unifying Multi-Lingual and Cross-Lingual Summarization”的工作，该工作由Fandong、Duo、Yunlong、Zhixu、Jianfeng和Jie共同完成。他们的贡献是将先前的多语言摘要和跨语言摘要统一到一个更通用的设置中，称为多对多摘要。多对多摘要的目标是构建一个单一的摘要模型，可以处理任何源语言的文档并生成相应的目标语言摘要。他们还进行了初步研究，分析了多语言摘要、跨语言摘要和多对多摘要之间的关系，并发现多对多摘要可以帮助摘要模型更好地在不同语言之间转移任务知识，比先前的多语言摘要和跨语言摘要更好。此外，他们提出了PISCES，一个预训练的多对多摘要模型，通过精心设计的三个阶段进行预训练：元预训练、跨语言预训练和任务特定预训练。实验结果表明，PISCES在各种基准上优于mBART-50和mT5。他们还进行了消融研究，验证了每个训练阶段的有效性，并进行了人类研究，展示了PISCES的优势。</sample>
    <sample id="7">是的，根据研究，CoNLL-2003标注器在2023年仍然有效。</sample>
    <sample id="8">提出的人工评估方法新颖之处在于，它通过显式标注每个聊天模型的响应是否表达特定行为来减少人工评估的主观性。该方法旨在全面覆盖最近文献中建议影响聊天质量的各种主题错误，并且在衡量聊天模型犯各种主题错误的频率方面比现有方法更可靠、更有预测力。</sample>
    <sample id="9">现有弱监督方法的成功在很大程度上依赖于干净的验证数据。</sample>
    <sample id="10">如果语言模型能够获得与注释者相同或部分重叠的背景知识，那么准确率会更高。</sample>
    <sample id="11">Jack Hessel, a research scientist at AI2, presented "Do Androids Laugh at Electric Sheep? Humor “Understanding” Benchmarks from The New Yorker Caption Contest." He discussed the capabilities of large language models in generating and explaining jokes. While some models can generate simple jokes or explain them to an extent, they often fail when it comes to more complex humor understanding tasks. To explore this further, he used data from The New Yorker Caption Contest, which involves readers submitting captions for cartoons that are then judged by human raters. They operationalized the contest into three tasks: matching (identifying the correct caption), quality ranking (judging the quality of two given captions), and explanation generation (explaining why a joke is funny). For these tasks, their best model achieved around 62% accuracy on the matching task compared to humans' 94%. Even with additional annotations, GPT-4's performance was still significantly lower than human results. Human explanations were preferred over five-shot GPT-4 explanations in most cases during blind A/B studies.</sample>
    <sample id="12">这篇论文有五位作者。</sample>
    <sample id="13">Adaptive inference is a method for reducing the inference time of large language models. To use it, we rely on the fact that real-world data varies in complexity. Therefore we can use low-capacity models for easy samples and therefore in that way, reduce the average inference costs, whether it be time or money. The two most common adaptive inference methods are Multi Model and Early Exit. In Multi Model, multiple models are stored together, each fit with a classifier at the end. They are trained separately on the entire training set, and when used for inference, they are run sequentially until a classifier decides to halt the computation. For Early Exit, multiple classifiers are fit to the model following intermediate transformer layers. They are all trained together, and for inference, a sample is run through the model until a classifier decides to halt, that way saving the computation, which would have been exhausted by the rest of the model.</sample>
    <sample id="14">Hi, my name is Adam Przepiórkowski and this talk is about the Dependency Structure of Coordination. As you may know, there are different dependency structures assumed by different theories and corpus approaches. So for example, in the universal dependencies, the structure of the coordination, Lisa, Bart, and Maggie, such that the first conjunct is the head of the whole coordinate structure. So in this case, Lisa. A similar approach is assumed in Igor Mel'čuk's meaning text theory, where again, the whole coordinate structure is headed by the first conjunct. Right. These two approaches are asymmetric. They single out one of the conjuncts. Now those are asymmetric approaches to coordinate structures, such as the Prague approach. The conjunction headed approach assumed in Prague dependency treebanks, where coordinate structures are headed by the conjunction. So we get some dependencies from end to all the conjuncts. And finally, there's also a multi-headed approach that's used, for example, in the Hudson's Word Grammar, where they say all conjuncts are heads of the coordinate structure. We get dependencies from the governor. Here loves to all the conjuncts separately: Lisa, Bart, and Maggie. Now the aim of this paper is to produce a novel argument for the symmetric structures of coordination, like these two and against the asymmetric structures of coordination, like these two. OK. The argument is based on the principle of dependency length minimization that I will explain on the basis of these examples. So in English, as you might know, direct objects prefer to be close to the verb, while adjuncts may be further away. "Marge read it yesterday" is fine because the direct object is close to the verb, while "Marge read yesterday it" is much worse. However, this effect may be ameliorated when the direct object is very heavy and very long. Because then it can be moved to the position after the adjunct. This is illustrated here. So both these sentences are fine. "Marge read this absolutely fascinating book about bees yesterday." It's okay the way instead of "it", we have this long NP. But it's also OK to say, "Marge read yesterday this absolutely fascinating book about bees." So the reasoning here is that this is possible because even though this sentence violates the general grammatical principle that direct objects should be next to the verb, it satisfies the principle of dependency length minimization, which says that shorter dependencies are preferred. So these two trees only show the length of the crucial dependencies, the ones that are not constant among these two structures. So here we have a dependency from "read" to the adjunct of length 7 measured in words and from "read" to "book" of length 4, so together it's 11. When you swap these two constituents, the sum of these two dependencies becomes 6. So instead of 11, 6 is much shorter. That's why this sounds quite okay. Right? It violates one principle, but it satisfies another one. Ok. So what we did, we extracted various statistics about coordination from the enhanced version of the Penn Treebank and see the paper "Why wouldn't you use universal dependencies" and these statistics confirm the observation made many times before that left conjuncts tend to be shorter. So, "salt and pepper" and not "pepper and salt", measured in syllables. And, also the observation that was made in parsing that this tendency grows with length difference. So when the difference between the lengths of the two conjuncts grows, the shorter conjunct prefers to be the first one, stronger, right? So the proportion is bigger of the left short conjunct. However, when the governor is on the right, as here, "laughed" governs the coordination Ted and Ned, this effect disappears. So we showed that by measuring length in characters, the first column, in syllables the middle column, and in words the right column. So I'll concentrate on the right one. What we see here is that when the governor is on the left, the tendency for the left conjunct to be shorter grows steadily, with the absolute difference in words, and the same is observed when there is no governor as in coordination of sentences. But when the governor is on the right this tendency disappears. And we show in the paper how this provides an argument against asymmetric structures of coordination, as these two, and for the symmetric structures, as these two. See the paper for the full arguments. And talk to us about at the poster session. Thank you.</sample>
    <sample id="15">这篇论文有三位作者。</sample>
    <sample id="16">Bible texts are much more simplified than news text or language learner texts.</sample>
    <sample id="17">The speaker introduces their work on multimodal relation extraction, a task that aims to determine the semantic relationship between entities in text. They highlight challenges such as over-utilization of internal information and under-exploitation of external information when using visual sources alongside textual data. To address these issues, they propose two methods: Graph Information Bottleneck (GIB) for fine-grained feature refinement based on node screening and edge adjustment within a unified cross-modal graph; and Latent Multimodal Topic Model (LMTM) for incorporating multimodal topic features into the model's context. The results from experiments conducted on a widely used MRE dataset show significant improvements with this approach compared to existing models.</sample>
    <sample id="18">例子是“盐和胡椒”。</sample>
    <sample id="19">Zhang Qin presented a work titled "A Survey for Efficient Open Domain Question Answering" accepted by ACL 2023. The presentation focused on open-domain question answering, specifically addressing challenges such as the large size of the Wikipedia corpus and index files, which hinder real-time applications and deployments to resource-constrained devices. To achieve efficient systems with smaller memory costs, faster inference speeds, and comparable performance, Zhang Qin summarized core techniques including one-stage frameworks like retrieval-only and generator-only systems, efficient tactics in evidence research, reading speed optimization, reducing index sizes through document filtering or embedding dimension completion, model size reduction via parameter sharing or designing fewer models, and comparing existing models from data aspects. Based on these insights, recommendations were made regarding deployment strategies for low-power devices and consideration of additional evaluation metrics.</sample>
    <sample id="20">是的，这些模型是免费的，并且可以在Hugging Face上获得。</sample>
    <sample id="21">DEPLAIN-apa 包含新闻文章。</sample>
    <sample id="22">通过我们的实验，我们发现有三个主要因素有助于良好的泛化：模型架构、模型大小和更多的微调示例。</sample>
    <sample id="23">Dan Garrette介绍了他们的研究，旨在提高文本图像模型的文本渲染能力。他们关注Imagen模型，该模型通过使用T5-XXL编码器将输入文本编码为子词ID，并将其作为扩散模型的输入来生成图像。然而，即使对于简单的文本输入，Imagen模型在渲染文本时也经常出错。为了理解这种现象，Garrette和他的团队分析了T5文本编码器的性能，发现它在拼写方面表现不佳，尤其是在较小的规模上。相比之下，PaLM模型在拼写方面表现更好，但它们的参数数量和训练数据量都比T5大得多，这使得它们在许多应用中不太实用。另一方面，ByT5模型使用字节级分词，允许它完全访问输入字符串的拼写信息，并且能够准确地复制字符。通过将ByT5-small模型的输出与Imagen模型的文本表示进行组合，Garrette和他的团队发现文本渲染能力得到了显著改善。然而，尽管文本编码器本身知道如何拼写，但生成过程可能会引入错误。他们的主要结论包括WikiSpell基准测试用于文本-only模型、DrawText基准测试用于文本-to-image模型以及一种新的高效策略，即通过将一个意识到输入字符的模型附加到现有的文本编码器来提高模型的拼写能力。</sample>
    <sample id="24">衡量左并列词是否更短的方法是通过测量两个并列词之间的长度差异。具体来说，可以使用以下步骤：

1. **提取数据**：从增强版的Penn Treebank中提取各种关于并列结构的统计数据。

2. **统计分析**：
   - 计算并列词对的长度差。
   - 测量长度差在单词、音节和字符等不同单位上的变化。

3. **观察趋势**：
   - 观察并列词对的长度差随并列词长度差异的增长而变化的趋势。
   - 注意到当并列词的长度差异增加时，较短的并列词倾向于成为第一个并列词。

4. **比较不同情况下的结果**：
   - 当并列词的治理者位于左侧或不存在时，较短的并列词倾向于成为第一个并列词的趋势会随着长度差异的增加而增加。
   - 当治理者位于右侧时，这种趋势会消失。

5. **结论**：
   - 根据这些观察结果，可以得出结论，左并列词更短的现象只发生在治理者位于左侧或不存在的情况下。当治理者位于右侧时，这种现象不会发生。

通过这些步骤，可以系统地衡量并分析左并列词是否更短，并得出相应的结论。</sample>
    <sample id="25">为了研究支配词位置的影响，可以设计一个实验来比较支配词在不同位置（左侧、右侧或不存在）时的依赖长度。通过分析句子结构和依赖关系的长度，可以观察到支配词在左侧时，左侧从句倾向于更短，而当支配词不在时，这种倾向也存在。这种观察结果支持了对协调结构的对称性偏好，而不是不对称性。</sample>
    <sample id="26">在不平衡数据上训练的基线分类器的表现不佳，因为认知不协调（dissonance）只占标注对的3.5%。基线分类器在训练时仅使用了43个标注的示例，其性能不如随机猜测。这表明在不平衡数据上训练分类器时，需要采取额外的策略来提高其性能。</sample>
    <sample id="27">这篇论文有两位作者。</sample>
    <sample id="28">对话中的角色名字是Bob和Alice。</sample>
    <sample id="29">语境感知 MT 模型在形式性和词汇连贯性方面比语境无关模型更有优势。</sample>
    <sample id="30">LLM-Blender是一种简单而有效的大型语言模型的组合学习框架，基于对成对排名和生成融合的简单想法。该团队由AI2和USC的成员组成，他们发现，尽管某些大型语言模型在总体性能上表现出色，但它们在特定输入示例上的最佳选择可能会有所不同。因此，他们提出了一个两阶段框架LLM-Blender。给定一个特定的输入X，他们运行n个不同的模型并获取其输出Y₁到Yₙ。然后，他们使用一个成对排名模块PairRanker来比较所有这些候选者，并根据它们对输入X进行排名。具体来说，他们将输入X与每个成对的候选者Yᵢ和Yⱼ连接起来，并使用RoBERTa等交叉注意机制来区分哪个候选者更适合输入X。给定比较矩阵，他们可以聚合结果以获得这些候选者的最终顺序。在下一个阶段，他们选择前K个，例如前三个候选者，并将它们作为输入提供给序列到序列模型进行学习和推断。生成的融合模型将通过融合排名最高的三个候选者来为输入X生成最终输出。让我们更仔细地看看PairRanker模块。与先前的方法相比，一个关键区别在于编码阶段。绿色方框表示这四个方法中的编码器，而我们的PairRanker会将一对候选者与输入X一起编码，以便更好地分析这些两个候选者之间的细微差别。相比之下，参数单独评估每个候选者并单独评分，然后根据它们的分数对所有候选者进行排名。我们认为PairRanker是一个更好的解决方案，因为它使用成对比较来学习和推断所有候选者之间的质量，并将它们并排比较得更加仔细。给定成对比较的结果，我们可以得到一个矩阵，其中矩阵中的每个元素表示候选I比候选J更好的比较对数。然后，从这个矩阵中，我们可以有三种方法来聚合所有这些结果。我们发现使用最大对数来聚合顺序是最好的解决方案，但如果你担心效率，你也可以使用冒泡排序算法。这里的结果显示，PairRanker在各种相关度指标上与Oracle排名的相关性更好，优于其他排名方法。为了使组合学习框架的评估成为可能，他们还创建了一个新的数据集MixInstruct。它包括现有的指令数据集，并从11个开源大型语言模型中收集候选者。他们使用BERTScore、BLUERT和BARTScore作为自动指标，并使用ChatGPT作为判断者来比较结果。实验结果显示，LLM-Blender在所有四个指标上都优于Open Assistant和Vicuna的两个顶级模型。特别是，Blender在68%和76%的情况下击败了Open Assistant和Vicuna。这些结果表明，Blender是组合学习的一个很有前途的框架，尽管它非常简单和直接。最后，他们想要传达的信息是，大型语言模型Blender是一个简单而有效的大型语言模型的组合学习框架。它有两个子模块：PairRanker是一个成对比较模块，可以从比较矩阵中获得所有结果，GenFuser将前三个候选者作为输入提供给序列到序列模型进行学习和推断。它大大提高了性能。MixIstruct是他们的数据集，用于评估大型语言模型。他们还发布了用于评估和未来研究的数据的统一代码库。</sample>
    <sample id="31">这篇论文的作者所属机构是John Gauthier和Aaron Mueller所在的机构。</sample>
    <sample id="33">引入的框架通过比较数据集和模型与真实用户（例如，社会化学和动态仇恨检测任务中的参与者）的注释来量化立场。它使用皮尔逊相关系数来衡量这些注释之间的相似性。该框架涉及重新注释数据集以获得多样化的注释者，并将这些注释与数据集和模型进行比较。</sample>
    <sample id="34">The work presented by Marcos Treviso and his team focuses on developing a joint framework for rationalization and counterfactual text generation, named CREST. This approach combines the strengths of selective rationalization methods that highlight tokens in a faithful way with those aligned more closely to human causal reasoning through generating counterfactuals by editing specific parts of the input. The first component of CREST is responsible for producing counterfactual examples from an original input X. It achieves this by using the rationale generated during the selection process as guidance.

To evaluate the quality of these counterfactuals, both automatic metrics and human evaluations were employed. Human evaluators judged 100 examples each from IMDB and SNLI datasets based on their validity and naturalness using a Likert scale. Results indicated that while manual counterfactuals are generally considered more valid and natural than those produced by other automated approaches like MiCE or CREST-Generation alone, CREST still outperforms them significantly when it comes to naturalness and validity.

Furthermore, the study explored how these counterfactuals could be used beyond just providing explanations; they can also serve as data augmentation tools. By training models not only on factual examples but incorporating both factual and counterfactual inputs via CREST, significant improvements were observed across various tasks including classification accuracy on different datasets such as IMDB and SNLI.

In terms of interpretability, the rationales provided by CREST were found to be highly plausible and showed superior forward simulability compared to other methods tested. Forward simulability measures whether an explanation correctly predicts changes in outcomes due to hypothetical interventions (counterfactual scenarios). Thus, according to the findings, CREST generates rationales that focus effectively on contrasting aspects within the input data which enhances its interpretability power.

Overall, the proposed method offers a promising avenue towards creating interpretable machine learning systems where model decisions can be better understood through well-designed counterfactual examples guided by comprehensive rationales.</sample>
    <sample id="36">The speaker introduces a research paper titled "Learning Language-Specific Layers for Multilingual Machine Translation" by Robin Schmidt, Yi-Hsiu Liao, and Stephan Peitz. The main goal of the work is to increase capacity per language in multilingual machine translation while maintaining constant inference costs. To achieve this, they propose using Language-Specific Layers (LSLs), which are regular transformer layers specific to each language.

The presentation begins with an overview of the advantages and challenges associated with multilingual machine translation. Advantages include scalability due to training one model instead of multiple models per language direction, speed improvements as translations can be made directly between any two languages without pivoting through English, and reduced error cascading. However, these benefits come at the cost of limited capacity per language when scaling up the model size increases computational complexity during both training and inference phases.

To address these limitations, the researchers introduce Language-Specific Layers or LSLs. These consist of individual transformer layers tailored specifically for each language involved in the translation process. At inference time, only the relevant sublayer corresponding to the selected source or target language is activated; other weights remain inactive throughout the entire process. This design ensures that the overall inference cost remains unchanged despite incorporating more specialized components within the system architecture.

Next, the discussion shifts towards determining optimal placements for these LSLs across different parts of the model structure - encoder versus decoder sections. Initially, it was observed that placing LSLs solely within the decoder did not yield significant performance gains compared to having them distributed evenly throughout the network. Therefore, focus was directed primarily toward exploring various configurations along the encoder pathway since there were fewer potential options available than those present in the decoder section.

To identify the most effective placement strategy, the team employed a method involving three distinct weight sets: shared, source-specific, and target-specific. By training on all possible combinations simultaneously, patterns emerged regarding how important certain connections might become depending upon their position relative to other elements within the neural network's hierarchy. Post-training analysis revealed clear trends indicating varying degrees of importance assigned to particular pathways based on where exactly they fell within the sequence of layers.

For instance, lower-level layers exhibited relatively consistent levels of significance attributed mainly to shared parameters among diverse linguistic contexts. Conversely, higher-level layers demonstrated increased reliance on information derived from either sources or targets individually rather than combining aspects from both domains equally. Such insights guided selection criteria used later stages wherein largest-weighted paths determined final architectural layouts optimized according to desired outcomes.

In terms of experimental setup, experiments utilized WMT21 news translation datasets encompassing ten languages including European tongues like Portuguese alongside Asian ones such as Vietnamese plus Swahili representing low-resource scenarios. Evaluation metrics included character F-scores (chrF), standard Bilingual Evaluation Understudy (BLEU) scores, and COMET (Common Terminology Evaluation Method). Results highlighted substantial enhancements attributable to employing learned architectures over baseline models featuring no dedicated language-specific layers but differing hidden sizes. Notably, even though our approach demanded less computation power during runtime operations, it consistently outperformed competing strategies focusing exclusively on adapting existing mechanisms designed originally for monolingual settings.

Overall, the presented findings underscored considerable improvement prospects afforded by integrating carefully placed language-specific layers into multi-lingual machine translation frameworks. Through rigorous experimentation backed by statistical validation procedures, promising avenues emerge suggesting practical applications benefiting numerous contemporary NLP tasks requiring efficient yet high-performance cross-lingual processing capabilities.</sample>
    <sample id="37">在之前的研究中，当人类受试者被给予相同的人格化提示时，他们能够揭示出种族刻板印象。</sample>
    <sample id="38">这篇研究使用了增强版的Penn Treebank数据。</sample>
    <sample id="39">这篇论文的作者是Adam Przepiórkowski。</sample>
    <sample id="40">与认知失调密切相关的任务包括：1. 话题无关的辩论立场分类：这个任务确定两个不同人发表的辩论陈述是否在观点上一致或不一致，无论话题是什么。2. PDTB中的扩展和比较类别的二元分类：这些类别与认知失调的概念密切相关，因为它们涉及语言中相似性和差异性的概念。通过将认知失调与这些相关任务进行转移学习，可以提高认知失调检测的性能。</sample>
    <sample id="41">PeaCoK是一个基于常识的知识图谱，旨在帮助语言模型学习和推断人物知识。它包含约3800个角色和40,000个独特的属性，形成了大约10万个个人推断或事实。PeaCoK通过三个步骤构建：首先，从现有的常识知识图谱中选择角色，包括人类角色和事件实体；其次，从常识知识图谱和大型预训练语言模型中诱导角色的属性；最后，使用联合的人工智能和人工注释员进行投票来注释PeaCoK关系。专家研究表明，带有AI辅助的多数投票可以实现高精度的关系注释。PeaCoK被用于训练BART-based常识知识生成器，并在对话生成任务中进行了评估。结果表明，PeaCoK可以作为可靠的人物知识库，使轻量级的语言模型能够学习与大型语言模型相媲美的知识生成能力。此外，PeaCoK的知识被用来改善下游叙事建模。研究发现，PeaCoK的个性化的常识知识比一般的社交常识知识对下游任务有更积极的影响。</sample>
    <sample id="42">这篇论文有三位作者。</sample>
    <sample id="43">这篇论文有三位作者。</sample>
    <sample id="44">引入的框架与以前的研究有何不同？</sample>
    <sample id="45">在三个比较设置中，黑人女性与白人男性和男性之间的刻板词汇重叠最多。</sample>
    <sample id="46">DeepL和Google Translate</sample>
    <sample id="47">Shangbin博士在今天的报告中介绍了他们的研究工作，该研究探讨了语言模型的政治偏见如何从预训练数据传播到下游任务。他们提出的问题包括：如何评估语言模型的政治倾向以及预训练数据可能对这种政治偏见的影响；不同政治倾向的语言模型在下游任务中的表现如何，以及这是否会导致NLP应用中的公平问题。他们通过使用政治问卷和不同政治倾向的预训练语料库来自动评估语言模型的政治倾向，并进一步分析这些偏见如何被从训练数据中继承。他们还展示了语言模型在仇恨言论检测和假新闻检测等NLP应用中的表现，以说明不同政治倾向的语言模型如何根据其社会类别给出不同的预测。最后，他们讨论了语言模型政治偏见的独特困境，并强调了需要解决由语言模型政治偏见引起的公平问题。</sample>
    <sample id="48">这篇论文有三位作者。</sample>
    <sample id="49">MPP评估最多涵盖1024个词元的上下文长度。</sample>
    <sample id="50">DEPLAIN是一个新的德语文本识别语料库，分为两个子语料库：DEPLAIN-apa和DEPLAIN-web。DEPLAIN-apa基于新闻文本，包含483篇手动对齐的文档，总共有约13,000个平行句子对。DEPLAIN-web包括不同的领域，并且对750篇文档进行手动和自动对齐，总共得到30,450个句子对。DEPLAIN语料库被用于评估自动对齐方法和自动文本简化。</sample>
    <sample id="51">他们的数据集中包含音乐、书籍和食谱三个领域。</sample>
    <sample id="52">Positionality（立场）是指人们持有的观点和态度，这些观点和态度受到他们的性别、身份和生活经历的影响。在学术研究中，positionality是一个广泛使用的概念，特别是在女性主义和女同性恋学术领域。作为研究人员，positionality可能会影响研究过程及其结果，因为它会改变研究人员做出的决策。</sample>
    <sample id="53">演讲者的名字是Dawei。</sample>
    <sample id="54">Vasudha介绍了一项研究，该研究旨在通过使用转移学习和主动学习来解决认知不协调检测中的罕见类问题。他们开发了一个认知不协调资源，并使用了转移学习和主动学习技术来提高模型的性能。他们的研究结果表明，主动学习和转移学习可以显著提高罕见类别的样本数量，并且在罕见类别上具有较高的准确性。</sample>
    <sample id="55">EDAtt 是一种策略，它利用了已经训练好的离线 ST 模型，并且不需要重新训练或采用特定的架构来处理 SimulST。</sample>
    <sample id="56">这篇论文有三位作者。</sample>
    <sample id="57">被测模型是否能在测试套件上运行？</sample>
    <sample id="58">KITMUS有三个变体：Background-Pretrain，Background-Both和Background-Inference。</sample>
    <sample id="59">The presentation introduces DrBERT, a pre-trained model in French for biomedical and clinical domains. The authors compare the performance of different models trained on various data sources and show that from-scratch training with more specialized data yields better results. They also highlight the versatility of using heterogeneous data sources and demonstrate how their system outperforms generic models like CamemBERT.</sample>
    <sample id="60">这篇论文的作者所属机构是：Javad Hosseini, Filip Radlinski, Silvia Pareti, Annie Louis。</sample>
    <sample id="61">最后一个研究问题是：我们应该只使用干净的样本进行验证，还是有其他更好的方法可以利用它们？</sample>
    <sample id="62">该研究探讨了自然语言生成（NLG）任务中知识蒸馏的潜力，重点关注压缩大型语言模型以提高性能。他们提出了一种系统性的方法来探索任务特定的知识蒸馏，考虑了各种NLG任务和现实设置。研究包括八个阶段，包括架构决策、剪枝影响、知识选择和伪目标生成。主要贡献是挑战传统的序列级知识蒸馏，并展示使用多个伪目标和联合教学等技术以提高学生性能。</sample>
    <sample id="63">指标灵敏度测量模型在任务中的一致性，即它是否能够始终产生相同的输出，无论指令的措辞如何变化。</sample>
    <sample id="64">演讲者的名字是Jingwei Yi。</sample>
    <sample id="65">更高的灵敏度表示模型性能得到了提高。</sample>
    <sample id="66">The paper discusses the task of mathematical reasoning and proposes a deep learning method for solving math problems. Mathematical reasoning is essential in human intelligence, enabling us to comprehend and make decisions based on numerical data and language. The development of machines capable of solving math problems and proving theorems has been a long-standing focus of AI and NLP. In recent years, there has been a surge of interest in this area, so our survey discusses the task of mathematical reasoning and the development of a deep learning method. For example, the text of math word problems can involve arithmetic operations with single or multiple operation steps. Mathematical reasoning isn't limited to text-based data; it can extend to multimodal information like images, figures, and tables. There are two primary categories we could study: visual contexts, and tabular contexts. Solving geometric problems is an essential subject in high school education. As an example shown here, given the problem text and the corresponding diagram, we need to identify the geometric relations, apply theorem knowledge and perform calculations to obtain the numerical answer. So these tasks can be formalized as a neuro-symbolic reasoning problem over geometric diagrams, theorems, and solvers. Another important line of mathematical reasoning is automated theorem proving. A theorem prover aims to demonstrate the truth of a mathematical claim via a sequence of larger arguments. You know it is not trivial to write the proof for a theorem for us humans, but the automated prover helps us. Some datasets have been proposed to probe the human-level intelligence of language models, such as the Numeric Commonsense Knowledge and High-Level Problem Solving. In recent years, a number of neural network architectures has been proposed for mathematic reasoning tasks. For example, a sequence-to-sequencemodel uses an encoder to code architecture and usually formalizes the mathematical reasoning task as a sequence generation task. The basic idea is to map an input sequence, such as a math problem, to an output sequence, such as the equation, problem, or proof. It is noteworthy that mathematical expressions can be represented as tree-based structures. Therefore, sequence-to-tree models have been proposed to explicitly model the tree structure while encoding the equation expressions. In the last few years, we have witnessed the remarkable development of pre-trained language models, such as the large language models, or LLMs. These language models have demonstrated remarkable performance on a wide range of NLP tasks. We can also apply LLMs to solve math word problems. For example, given the input question here, we can prompt the LLM with one single example of the chain-of-thought process. A chain-of-thought is a series of intermediate reasoning steps that lead to the final output. It enables language models to solve complex problems by guiding them to produce a sequence of steps before giving the final answer. Despite the advantages, LLMs still face inherent limitations. One notable example is the lack of ability to perform precise mathematical reasoning. One effective solution to boost the LLMs’ performance is to replace the greedy decoding strategy with self-consistency. Instead of generating just one reasoning path, a diverse set of reasoning paths are sampled from the language model's decoder, and the most frequent one is chosen from the answer set. Instead of designing effective prompting method for LMM a novel line of work is to design the two augmented LMMs. For example, program-aided LMMs are very helpful in complex mathematical reasoning tasks. We can augment LMMs with various tools to perform complex tasks giving different input queries. Chameleon, a recently proposed approach, can generate natural language programs to compose different tools for use. Despite the creation of various datasets, mathematical reasoning in low-resource settings remains underexplored. Recently, there have been attempts to build non-English datasets for Chinese, Korean, and Arabic. Additionally, pioneering research has developed mathematical reasoning benchmarks for financial, scientific, and medical domains. Despite impressive progress, the learning models commonly display generalization and robustness failures on reasoning tasks. First, language models struggle with large numbers. Second, large language models are inconsistent with mathematical reasoning. With that, thank you so much for your attention.</sample>
    <sample id="67">Interference in multilingual translation models can occur when the model is small compared to the data size, and tuning the sampling temperature is key for strong performance. The simpler bilingual case has scaling laws that predict loss, but the multilingual case is more complex with additional factors such as language similarity and total number of languages. However, these do not have a large impact on interference levels. Severe interference occurs only for very small models, which go away with increased scale. Temperature sampling is an effective solution, where T greater than 1 allows sampling from lower-resource languages. A baseline for battling interference includes weak results due to size in smaller models and uncalibrated temperature values too high in larger ones. Tuned temperature is essential for achieving good performance without other specialized methods.</sample>
    <sample id="68">在预训练期间，模型会接收各种各样的语言上下文。这些上下文可能包括不同长度的句子、来自同一数据集的不同部分的句子，甚至是完全无关的领域，如维基百科。这种多样化的上下文有助于模型学习和理解语言的更广泛和多样的方面。通过接触各种上下文，模型可以更好地泛化到新的情况，并提高其在处理不同语言任务时的表现。</sample>
    <sample id="69">通常，我们需要每类20个干净的验证样本才能获得良好的表现。</sample>
    <sample id="70">这篇论文的作者所属机构是斯坦福大学。</sample>
    <sample id="71">In this work, the authors introduce a new corpus called AltEntities Corpus to understand users' language when they want to make choices. The goal is to provide more natural conversations by using indirect references instead of direct ones. They collected data from three domains: music, books, and recipes, emphasizing informality in their collection methodology. The dataset consists of 6,000 alternative questions with 42,000 indirect referring expressions. Results show that models perform better when given access to overlapping background knowledge or entity names but still have room for improvement.</sample>
    <sample id="72">为了衡量媒体偏见，需要开发新的方法，因为政治新闻媒体在语言模型的预训练数据中被广泛覆盖。政治新闻媒体包含各种政治观点，这些观点可能带有社会偏见，这可能导致下游任务应用中的公平性问题。因此，需要跟踪政治偏见从预训练数据到语言模型再到下游任务的传播过程。</sample>
    <sample id="73">演讲者的名字是Akshatha。</sample>
    <sample id="74">The paper introduces Dense-ATOMIC, a densely-connected commonsense knowledge graph that completes missing links in ATOMIC. The construction process involves normalizing tail events, training a relation prediction model (Rel-CSKGC), and constructing DenseATOMIC. Rel-CSKGC predicts relations given head and tail event representations from RoBERTa. It outperforms traditional methods on automatic and human evaluation. DenseATOMIC yields higher knowledge coverage with more 1-hop, 2-hop, and 3-hop paths. COMET also benefits from DenseATOMIC's completion of multi-hop paths.</sample>
    <sample id="75">The speaker introduces their work, Jointprop, which is a joint effort with Hao Anran and Luu Anh Tuan. They discuss the motivation behind their research on name entity recognition (NER) and relation extraction (RE), highlighting the challenges of fully-supervised learning methods due to the need for extensive label data annotation. Semi-supervised learning offers a more cost-effective alternative by leveraging both labeled and unlabeled data.

The speakers emphasize that current studies often overlook the underlying connections between NER and RE tasks. For instance, they mention syntactical similarities like "used to" and "use in," suggesting that these relationships should be considered when developing models. The importance of considering interconnections among different types of data—labeled, unlabeled, and semi-supervised—is also stressed as it can lead to better model performance through improved information integration.

Their proposed solution, called Jointprop, involves four main components: span feature generation, heterogeneous graph construction, joint label propagation, and model optimization. In span feature generation, contextualized representations are used to initialize span and span pair representations. Heterogeneous graphs are constructed efficiently using k Nearest Neighbor algorithms, examining similarity relations within and across datasets. Label propagation then distributes labels throughout the graph based on high-density areas formed by the data points.

The final part focuses on model optimization where converged pseudo-labels are obtained via a softmax function followed by an argmax operation. These results are filtered according to confidence levels before being combined with existing label data to retrain the classification model. This process maintains consistency with baseline models while incorporating learned features from the joint task framework.

Experimental results demonstrate significant improvements over previous baselines in terms of accuracy for both NER and RE tasks across various datasets, including those specifically designed for this study.</sample>
    <sample id="76">政治偏见传播流程从预训练数据到语言模型再到下游任务。首先，我们通过使用政治问卷对语言模型进行提示，以自动评估其政治倾向。然后，我们进一步预训练语言模型检查点，使用六个不同的党派语料库进行预训练，这些语料库被分为新闻和社交媒体，并进一步分为其政治倾向。通过进一步预训练语言模型，我们可以看到其意识形态坐标也相应地发生了变化。例如，对于在左倾的Reddit语料库上进一步预训练的RoBERTa，我们观察到其政治偏见有显著的向左倾斜。此外，我们还尝试研究语言模型是否能够捕获现代社会中普遍存在的极化现象。我们将预训练语料库分为在第45任美国总统之前和之后的时间段，并分别对语言模型进行预训练。我们观察到，语言模型的政治倾向通常离中心更远。这表明语言模型确实能够捕捉社会中的极化现象。最后，我们评估了具有不同政治倾向的语言模型在仇恨言论检测和假新闻检测等NLP应用中的表现，这些应用往往涉及语言模型，并可能产生非常重要的影响。我们发现，如果根据其政治倾向将性能分为不同的类别，即分离性能为不同的人口统计学或新闻媒体的政治倾向，会显示出模式。例如，在仇恨言论检测中，左倾语言模型在检测针对社会少数群体的仇恨言论方面表现更好，但在检测针对更有权力群体的仇恨言论方面表现较差。相反，右倾语言模型在检测针对白人和男性群体的仇恨言论方面表现更好，但在检测针对黑人LGBTQ+和其他少数群体的仇恨言论方面表现较差。我们还展示了许多其他例子，以进一步强调语言模型根据其社会类别给出不同预测的情况。这表明存在一个非常紧迫的公平问题，由语言模型的政治倾向引起。</sample>
    <sample id="77">本研究旨在通过引入新的自然语言生成（NLG）任务来提高摘要的实证一致性。这些任务包括摘要编辑、反馈生成和自动事实错误纠正。研究重点是基于原始系统生成的摘要，使用人类演示和反馈来评估摘要的实证一致性。研究发现，人类编辑后的摘要在自动实证性评分方面表现更好，但文本重叠度较低。此外，数据分布显示了不同错误类型的编辑指令之间的关系。研究还表明，编辑模型在训练较少数据的情况下可以达到与基线模型相当的性能，并且生成解释有助于提高性能。此外，该数据集提供了有价值的资源，用于训练实证指标和实证元评估。</sample>
    <sample id="78">是的，DEPLAIN-apa 和网站的简化过程有所不同。DEPLAIN-apa 的 Bible 文本被更强烈地简化，而新闻文本、语言学习文本和网站文本则有不同的简化程度。此外，在 DEPLAIN-apa 中，词典替换、结构简化和整体简化水平更高，而在网站中，重述更为常见。</sample>
    <sample id="79">Yes, CoScript is publicly available.</sample>
    <sample id="80">在水印插入过程中，首先定义目标嵌入。当用户向提供商服务发送句子时，提供商会计算句子中触发器的数量。提供的嵌入是目标嵌入和原始嵌入的权重之和。目标嵌入的权重与句子中的触发器数量成正比。如果句子中的触发器数量大于m，则提供的嵌入完全等于目标嵌入。</sample>
    <sample id="81">Penn State University</sample>
    <sample id="82">The video discusses the topic of Automated Essay Scoring (AES) and its potential in education. It highlights two unsupervised AES methods: one by Chen et al., which uses a heuristic signal to score essays, but has poor performance due to uncontrollable clustering; and another by Zhang and Litman, using word count as weak supervision with direct regression leading to poor results. The proposed ULRA framework aims to improve unsupervised AES by introducing multiple quality signals for stronger supervision. This is achieved through three components: HER alpha-shot for ranking essays based on different quality signals, DPRA for aggregating partial-order pairs from these signals into unified supervision, and a scoring strategy transforming predicted scores into pre-defined ranges. Experimental results show that ULRA outperforms all unsupervised baselines significantly and achieves competitive performance compared to cross-prompt and one-shot methods. However, it still lags behind supervised methods due to insufficient strong supervision.</sample>
    <sample id="83">是的，像 mt5 这样的编码器-解码器模型可以通过混合语言的训练来改进。</sample>
    <sample id="84">Shwai He在ACL 2023上介绍了他的论文“PAD-Net: An Efficient Framework for Dynamic Networks”。他首先介绍了动态网络的概念，指出与静态网络相比，动态网络可以更好地适应输入变化。然而，完全动态的网络由于参数过多而存在局限性。为了解决这个问题，Shwai He提出了PAD-NET：部分动态网络。该框架将参数分为动态参数和静态参数，并使用迭代模式分区来确定两个模式之间的比例。实验结果表明，PAD-Net在保持较少的参数和计算量的同时，比静态网络和动态网络表现更好。此外，Shwai He还研究了动态比率和缩放因子对不同动态网络性能的影响。最后，他建议未来的工作包括扩展方法到其他主流网络、硬件友好结构以及引入更多模式。</sample>
    <sample id="85">受限语言规划的一个示例是“制作巧克力蛋糕”。</sample>
    <sample id="86">They ensure the covertness of their method by visualizing the embeddings of sentences on four datasets using PCA. The legend in the figures indicates the number of triggers in each sentence, and it is difficult to distinguish between backdoor embeddings and normal embeddings based on these visualizations.</sample>
    <sample id="87">DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains</sample>
    <sample id="88">GPT-4 在社会接受度任务中与印度和日本的立场最不一致。</sample>
    <sample id="89">演讲者在以下示例句子上展示了模型如何利用注意力机制所学的知识：“I'm going to talk about...”</sample>
    <sample id="90">The paper "Rethinking Annotation: Can Language Learners Contribute?" explores the feasibility of using language learners as annotators in NLP tasks. The authors conducted a proof-of-concept study to examine this possibility, considering three languages (English, Korean, and Indonesian) with varying levels of resources available for annotation.

The experiments involved recruiting native speakers and language learners at different proficiency levels (basic, intermediate, advanced). Participants were asked to annotate 10 questions from each task type in the GLUE benchmark while utilizing additional resources such as dictionaries or machine-translation systems if needed. 

The results showed that labels annotated by language learners are nearly accurate, especially for simpler tasks and easy-to-medium level questions. Moreover, when aggregated through majority voting, learner's annotations performed almost on par with those of native speakers. Additionally, training simulations demonstrated that models trained on learner's less accurate labels achieved about 95% of ground truth performance and sometimes outperformed models trained with native speakers' labels.

The findings suggest that data construction can be broadened beyond relying solely on native speakers, particularly beneficial for low-resource languages where it is challenging to recruit them. This approach could help overcome geographic and technological barriers associated with building datasets for these languages.</sample>
    <sample id="91">随着任务数量的增加，模型的性能会提高。此外，随着任务数量的增加，模型的敏感性会降低。</sample>
    <sample id="92">作者比较了他们的方法与三个无树基线：1. 一个简单的序列到序列模型，没有使用任何额外的组件。2. 一个序列到序列模型，使用了注意力机制。3. 一个序列到序列模型，使用了掩码递归神经网络（MRNN）来建模递归结构。这些基线被用来展示作者的方法在处理深层递归时的有效性。</sample>
    <sample id="93">Alexander Koller and Ivan Titov are the advisors of Matthias Lindemann.</sample>
    <sample id="94">Jingwei Yi来自中国科学技术大学，介绍了一种名为“Embedding Marker”的新型水印方法。该方法通过在嵌入中注入水印并验证其版权来保护嵌入作为服务的版权。该方法包含两个主要步骤：水印注入和版权验证。水印注入涉及选择一个触发器集，并根据句子中的触发器数量提供嵌入。版权验证使用一个后门数据集和一个干净数据集来检测另一个服务是否包含水印。实验结果表明，Embedding Marker在保持下游任务的性能的同时，具有良好的检测性能。此外，通过可视化每个句子的嵌入，证明了该方法的隐蔽性。</sample>
    <sample id="95">David Vilar</sample>
    <sample id="96">假设你正在为一家报纸筛选新闻文章下的评论，以移除有毒内容。你可能会转向一个流行的API，比如Prospective API进行毒性检测，这在Carl Jones身上表现得很好。Prospective API确实能够准确地检测出有毒实例。但是，在Aditya Sharma身上，Prospective API的表现并不那么好。Prospective API对印度语中更常见的冒犯性术语的敏感度较低。这就是我们所说的系统性能差异，即技术在不同人口群体中的表现差异。这种差异可能是由于NLP研究人员和模型开发者的地位造成的。地位是指人们持有的观点，这些观点源于他们的人口统计学、身份和生活经历。这是一个广泛应用于批判性研究领域的概念，特别是女性主义和女同性恋学术领域。作为研究人员，地位可以影响研究过程及其结果，因为它可以改变研究人员做出的决策。因此，一个问题出现了：数据集和模型是否有地位？我们并不是说模型本身或数据集本身具有人口统计学身份和生活经历，而是它们汇集了真实人的判断和意见，并且可以代表某些地位胜过其他地位。先前的工作提供了一些关于数据集和模型可能具有地位的轶事证据，例如文化差距，以及模型和数据集的理论定义。然而，这些工作并没有比较最终用户与数据集和模型本身，也没有研究模型和数据集的地位。随着NLP任务变得更加主观和社交导向，研究模型和数据集的地位变得越来越重要，因为并非所有决策都是记录的，许多模型都隐藏在API后面。为了研究数据集和模型的地位，我们通过将注释与现有数据集和模型进行比较来比较最终用户与数据集和模型。我们通过我们的框架NLPositionality来实现这一点。我们的框架有两个主要步骤。第一步是重新注释数据集，使用多样化的注释者。我们应该这样做，因为原始数据集注释者的人口统计学通常很少被收集和共享，因为通常只有一个注释者为每个实例注释，而且人口统计学数据很少被收集和分享。因此，我们重新注释数据集，以便为每个实例获得多个注释，并获得丰富的人口统计学数据。然后，我们将按人口统计学分组的注释与模型和数据集进行比较，使用皮尔逊相关系数得分，因此我们的框架与注释者的一致性文献有所不同，该文献比较了注释者之间的分歧或模型注释者的分布，而不是比较最终用户与模型和数据集的预测和标签。我们的框架主要得益于Lab in the Wild和在线众包平台，如HCI合作者。Live in the Wild是一个在线实验平台，我们可以招募多样化的志愿者。与M Turk相比，M Turk主要由美国或印度的参与者组成，而Lab in the Wild仍然能够提供高质量的数据。我们在Lab in the Wild上发布了两个任务，一个是社交接受度，参与者将阅读来自Social Chemistry数据集的情况，并写下一个情况的社会接受度。之后，为了保持参与者的兴趣，他们可以将他们的回答与AI和其他人的回答进行比较。我们然后将这些注释与Social Chemistry、Delphi和GPT 4进行了比较。我们还复制了一个非常相似的任务，用于仇恨言论和仇恨言论检测，参与者将阅读Dynahate中的一个实例，并写下一个实例是否是仇恨言论。我们然后将这些注释与Dynahate、Perspective API、Rewire API、Hate Roberta和GPT 4进行了比较。我们的研究最终收集了超过16,000个注释，来自1000多名来自87个国家的注释者。现在我们更好地了解了NLP数据集和模型与谁最一致。我们发现NLP确实存在地位。例如，我们发现数据集和模型最符合英语国家。例如，在GPT 4的社交接受度分析中，我们发现它最符合儒家和英语国家。我们还发现Dynahate也最符合英语国家。我们还发现，当模型和数据集与特定人群保持一致时，一些人不可避免地被落下。一个例子是，数据集和模型在与非二元个体保持一致方面做得不如男性和女性。我们发现在GPT 4的社交接受度任务和Dynahate任务分析中都有这种情况。考虑到NLP确实存在地位，我们有以下建议。首先，记录整个研究过程中所做的所有相关设计选择。其次，以透视主义的眼光进行NLP研究。我们的第三个建议是在四个特定社区内构建专门的数据集和模型。一个很好的例子是Masakhani倡议。我们想强调的是，包容性的NLP不仅仅是让所有技术都适用于所有人。这就是我们的演讲结束的地方。但如果你想要了解更多，欢迎查看我们的仪表板，获取最新的分析结果，并查看我们的论文。谢谢。</sample>
    <sample id="97">演说者提到了 SimulST 的几个问题，包括： 1. 需要训练特定的架构，这需要额外的模块进行优化。 2. 长而复杂的训练过程，例如涉及不同的优化目标的训练。 3. 训练和维护多个模型以达到不同的延迟范围。例如，训练一个平均延迟为一秒钟的模型和另一个平均延迟为两秒钟的模型。</sample>
    <sample id="98">减轻训练 NLP 模型时数据集中的社会和政治偏见的有效方法包括： 1. **多样化和平衡的数据集**：确保预训练数据集包含各种观点和政治立场，以减少偏见。 2. **去偏训练数据**：在训练过程中使用去偏技术来减少数据中的偏见。这可能涉及调整损失函数或使用去偏算法。 3. **监控和评估偏见**：定期评估模型的偏见，并使用特定的指标或工具来跟踪和量化偏见。 4. **透明度和可解释性**：使训练过程和模型行为更加透明，以便更好地理解并解决偏见问题。 5. **社区参与和反馈**：与多样化的社区合作，收集有关偏见的反馈，并将这些反馈纳入训练数据和模型开发中。 6. **持续改进**：不断监测和更新训练数据和模型，以适应新的信息和变化的社会动态。 这些方法有助于创建更公平和公正的 NLP 模型。</sample>
    <sample id="99">大家好，我是复旦大学的Siyu Yuan。今天我来介绍我们的一项工作“从大型语言模型中提取约束语言规划的知识”。在日常生活中，人类经常通过遵循分步指令的形式来规划行动，这些指令通常是为特定目标编写的脚本。先前的工作已经利用语言模型来规划抽象目标，例如“做蛋糕”，并且展示了大型语言模型能够有效地将目标分解成步骤。然而，先前的工作主要关注于规划抽象目标，而对具有特定约束的目标的规划，例如“做巧克力蛋糕”，仍然没有得到充分的研究。在本文中，我们定义了约束语言规划的问题，该问题对规划的目标施加了不同的约束。一个良好的规划者应该编写合理的脚本，并且忠实于约束。在本文中，我们首先评估并改进了大型语言模型的约束语言规划能力。由于没有具体的任务目标数据集来支持我们的研究，因此我们需要首先获取这些目标。如表所示，我们通过InstructGPT扩展抽象目标以多方面的方式进行人工数据收集。我们采样100个具体目标，并评估大型语言模型生成的脚本。此表报告了结果的整体准确性。我们发现所有语言模型在规划具体目标时均未能取得令人满意的结果。然后，我们进行了详细分析，以调查为什么学习模型会失败。图中的结果显示，InstructGPT在不同类别约束下的规划性能存在显著差异。先前的研究已经表明，语言模型的输出质量存在高变异性，这会导致性能不佳。因此，我们采用了过生成-然后筛选的方法来提高生成质量。我们首先展示InstructGPT中约束类型和示例，以基于种子抽象目标获得具体目标。然后，InstructGPT为每个具体目标生成K个脚本。接下来，我们开发了一个过滤模型来选择忠实的脚本。我们将脚本和目标转换为InstructGPT嵌入，并计算余弦相似度作为相似度得分，以衡量语义相似性。此外，我们奖励包含目标约束关键词的脚本。仅保留目标分数在目标集中最高的脚本。使用我们的方法，InstructGPT可以生成更高质量的脚本。我们的方法大大提高了规划能力，既在语义完整性方面，又在约束忠实性方面。由于大型语言模型部署成本高昂，因此有必要使较小且专门的语言规划模型具备规划能力。创建数据集是实现这一目标的关键步骤。然而，先前的研究并没有为具体目标提供规划能力，手动数据注释成本高昂。因此，我们遵循符号知识蒸馏的想法，从大型语言模型中提取约束语言规划数据集。我们应用我们的方法为约束语言规划构建数据集CoScript。总共，我们生成了55,000个具体目标和脚本。为了确保验证集和测试集的质量，我们请众包工作者查找并修订错误样本。此图显示了CoScript中的约束分布。我们发现CoScript在生成的具体目标上表现出很高的多样性。使用CoScript，我们可以尝试针对约束语言规划的小型但专门的模型。我们发现，经过CoScript微调的T5模型可以生成比大多数大型语言模型更高的质量脚本，表明小型模型在适当的数据集上训练时可以超过大型模型。总之，我们建立了约束语言规划问题。我们评估了大型语言模型的约束语言规划能力，并开发了过生成-然后筛选的方法用于大型语言模型。我们使用大型语言模型生成高质量的脚本数据集CoScript，用于约束语言规划。我们希望CoScript数据集可以成为推进语言规划研究的一个有价值的资源。感谢您的时间。有关CoScript的更多详细信息，请参阅我们的论文。</sample>
    <sample id="100">PromptRank是一种数据效率高的多跳检索方法，通过结合无监督检索和语言模型的重排序器来实现。它使用TF-IDF检索和链接遍历来构建候选链，并使用语言模型根据给定的问题对这些链进行重排序。该方法在HotpotQA上进行了实验，结果表明它优于完全监督系统并具有竞争力。</sample>
    <sample id="101">根据David Vilar的演讲，PaLM的流畅度与最先进的系统相当。</sample>
    <sample id="102">水印方法的重要属性包括： 1. 可应用于嵌入作为服务。 2. 水印不应降低提供的嵌入的实用性。 3. 水印应足够隐蔽，以便攻击者或攻击者可以轻松移除水印。 4. 水印需要在模型提取过程中具有可转移性。</sample>
    <sample id="103">TED 英语演讲已被翻译成 14 种不同的语言。</sample>
    <sample id="104">为了重新注释数据集，我们抽取了100个实例。</sample>
    <sample id="105">在评估良性和后门数据集之间的差异时，使用了以下距离度量： 1. **余弦相似度** 2. **L2（欧几里得）相似度** 3. **Kolmogorov-Smirnov（KS）检验** KS检验还提供了p值作为第三个指标。这些度量用于比较后门数据集与良性数据集的嵌入，以检测后门的存在。</sample>
    <sample id="106">Chaitanya介绍了他们的研究，重点是解决信息检索中的选择性需求问题。他们提出了一个名为QUEST的检索数据集，该数据集包含超过3000个查询，这些查询包含隐式集合操作，并且答案实体被验证为与查询相关。数据集旨在测试系统处理具有多个约束的查询的有效性。通过使用Wikipedia类别名称和人类注释器来创建和验证数据集，他们展示了系统在检索包含多个答案集的多答案集时面临的挑战。他们还比较了不同检索方法（稀疏和密集检索器以及T5基于重排序器）的性能，并发现对于具有集合交集和差集的查询，F1分数特别低。他们希望QUEST能够帮助未来的研究人员构建更好的系统，以满足具有选择性需求的信息检索场景。</sample>
    <sample id="107">编码器-解码器模型可以用于这项任务。</sample>
    <sample id="108">这篇论文探讨了语言模型在处理上下文长度较长的句子时的接受度判断。研究人员通过模拟较长的上下文序列来重新评估现有的最小对齐（MPP）管道。他们通过从不同的数据集或不同部分提取句子，创建了较长的上下文序列，并观察了模型在这些序列上的表现。结果表明，当上下文来自同一数据集的不同部分时，模型的接受度判断会显著变化。这表明，语言模型可能对共享的句法和语义特征敏感，而当前的MPP评估方法可能无法全面捕捉模型在整个上下文窗口中的抽象知识。</sample>
    <sample id="109">Unnatural Instructions是一种通过自动方式收集的自然语言指令数据集，无需任何人工标注。该数据集包含64,000个例子，如果考虑指令的变体，则有约240,000个例子。这些例子是通过提示预训练的语言模型生成的，该模型根据三个示例生成一个额外的例子。该数据集展示了语言模型能够产生创造性和多样性的能力，其正确性超过50％，即使不正确的例子也提供了有价值的信息。在对Unnatural Instructions进行微调后，该模型在多个基准测试中表现出色，并且当成本被摊销时，其性能优于基于人工注释的基准。</sample>
    <sample id="111">作者假设提供者可以收集一个通用文本语料库，并使用它来计算单词频率。</sample>
    <sample id="112">大家好，我是Shuheng。今天我要介绍我们的论文《CoNLL-2003命名实体标签器在2023年仍然有效吗？》。我们的论文研究了命名实体识别任务（NER）中的泛化问题。我们观察到，自2003年以来，模型被用于开发NER，这自然提出了几个问题。首先，这些模型能否很好地泛化到现代数据？当我们开发新的标签器时，需要什么来实现良好的泛化？如果确实存在泛化不良的情况，是什么导致了这些模型性能的下降？为了调查这些问题，我们创建了CoNLL++数据集。这是一个从2020年的路透社新闻中收集的数据集，并使用相同的CoNLL-2003注释指南进行了注释。然后我们在CoNLL-2003上微调了超过20个模型。我们分别在CoNLL-03测试集和CoNLL++上评估它们。最后，我们计算了每个模型在F1上的百分比变化，以评估每个模型的泛化能力。那么，实现良好泛化需要什么？在实验过程中，我们发现有三个主要成分是必要的。第一个是模型架构。通过我们的实验，我们发现变压器模型通常能更好地泛化到新数据。第二个成分是模型大小。我们发现通常较大的模型会导致更好的泛化。最后，正如我们所知，下游任务的性能直接取决于微调示例的数量。在这里，我们也发现更多的微调示例也导致了更好的泛化。接下来的问题是，为什么某些模型的性能会下降？我们有两个假设。第一个是适应性过拟合，即通过重复使用同一测试集来重新利用测试集，这种现象表现为在新测试集上的性能递减。第二个假设是时间漂移，即由于训练数据与测试数据之间的增加的时间间隔而导致的性能下降。对于适应性过拟合，我们看到右侧的图表显示，红色最佳拟合线的梯度大于1。这意味着CoNLL-2003上的每一点改进都转化为CoNLL++上的超过一个单位的改进，这意味着没有递减回报。这表明在这种情况下并未观察到适应性过拟合。那么时间漂移呢？为了验证这一假设，我们对一些模型进行了重新训练或继续预训练，结果发现随着时间间隔的增大，性能会下降，这证实了我们的假设，即时间漂移是性能下降的主要原因。我们的结论是，为了实现良好的泛化，我们需要更好的模型架构、更大的模型大小以及更多的微调示例。这三个成分是相互关联的，我们不能只有一味地扔掉其他成分。同时，我们还发现，性能下降的原因是时间漂移，令人惊讶的是，这并不是由适应性过拟合引起的，尽管CoNLL-2003已经使用了20多年。因此，回到我们论文的标题问题——CoNLL-2003标签器在2023年仍然有效吗？答案是一个响亮的肯定。我们希望我们的论文能引起更多关于如何提高模型泛化能力的研究。最后，请查看我们的论文、数据集，并且如果您有任何问题，请随时联系我。谢谢大家！</sample>
    <sample id="114">The work presented at ACL 2023, "Finding the Pillars of Strength for Multi-Head Attention," addresses the limitations of large language models by focusing on parameter efficiency. The study identifies that multi-head attention in these models can be pruned without sacrificing performance. They propose a grouped head attention method using a divide and conquer strategy to compress multi-head attention into two stages: group-constrained training and voting-to-stay algorithm.

In the first stage, heads are divided into groups where intra-group heads become more similar and inter-group heads become more separate. This is achieved through an unsupervised hidden unit discovery system like K-means, with objectives aiming to homogenize intra-group heads and diversify inter-group heads. 

The second stage involves pruning redundant multi-head attention after group constraint training. A Voting-to-Stay algorithm collects votes from each batch as voters and assigns scores based on their evaluation. Heads with low votes are then pruned, resulting in one remaining head per group while achieving significant parameter compression—up to 90% in extreme cases.

The model's effectiveness was evaluated across three tasks (machine translation, language modeling, abstractive summarization) showing improvements over SOTA baselines ranging from 3.8% to 7%, along with substantial parameter reductions (32.1%). Efficiency analysis revealed further benefits such as faster inference speed and reduced FLOPs.

Looking ahead, task-specific automatic pruning seems promising due to the Lottery Ticket Hypothesis suggesting networks contain subnetworks capable of reaching comparable test accuracy post-pruning. By applying this concept to redundant parameters in current large language models, potential weight reduction could enhance deployment capabilities without compromising functionality.</sample>
    <sample id="115">该方法使用的语音片段大小是lambda。</sample>
    <sample id="116">在 Servin 和 Kea 的示例中，需要特定于实体的知识是“Servin 是一名法官”。</sample>
    <sample id="117">示例质量比与源句子的相似度更为重要。</sample>
    <sample id="118">The presentation introduces a new method called SwitchMLM for improving pretraining techniques in code-switched natural language processing (NLP). Code-switching refers to the use of multiple languages within a single sentence, which is common in linguistically diverse communities like India. Multilingual pre-trained models such as mBERT and XLM-R struggle with tasks like question answering and sentiment analysis when dealing with code-switched sentences.

The main contributions include novel MLM techniques tailored for code-switching scenarios, architectural changes, and an auxiliary loss specifically designed for this purpose. The proposed method involves identifying switch-points—groups of two tokens that indicate a transition between languages—in code-switched sentences. These switch-points are then masked during training using SwitchMLM, which only masks words corresponding to identified switch-points rather than uniformly masking all words.

However, implementing SwitchMLM requires access to Language Identification (LID) tagged datasets or LID taggers, which may not always be available. To address this limitation, FrequencyMLM was introduced as a surrogate method. This approach defines negative log likelihoods for each word across monolingual corpora and compares these values to assign LID tags based on frequency patterns.

Additionally, some architectural modifications were suggested: adding residual connections from intermediate layers to the final layer can help capture more switch-point information by leveraging insights gained through layer probing experiments. An auxiliary Loss based on LID information further encourages learning about different languages at specific layers.

Experimental results demonstrate that combining SwitchMLM or FrequencyMLM with ResBERT and an auxiliary loss leads to improved performance on various NLP tasks involving code-switched data, particularly in sentiment analysis across English-Hindi pairs.

Finally, probing classifiers were used to verify claims regarding increased switch-point information due to the proposed methods. Linear probing showed that StandardMLM's Layer 9 contains more switch-point information compared to Layer 12, suggesting it might benefit from residual connections added between them. Conditional probing confirmed that representations combined with SwitchMLM have higher predictive power over baseline representations concerning switch-point detection.

In summary, the research proposes a specialized MLM objective for handling code-switch information, validates its effectiveness via probing experiments, and suggests enhancing model architecture accordingly to better manage multilingual complexities inherent in code-switched text.</sample>
    <sample id="119">在扩展实验中，论文侧重于RoBERTa。</sample>
    <sample id="120">该模型是使用特定层的注意力分数。</sample>
    <sample id="121">直接推断的示例包括“Easy on Me”和“I Gotta Feeling”。</sample>
    <sample id="122">这篇论文的作者所属机构是Fudan University。</sample>
    <sample id="123">The presentation discusses MultiInstruct, a new multi-modal instruction tuning dataset consisting of 62 diverse tasks across 10 broad categories. The dataset is designed to investigate the effectiveness of instruction tuning in improving zero-shot performance on unseen multi-modal tasks. The researchers use OFA, a unified multi-modal pre-trained model with a shared vocabulary for language, image tokens, and bounding box coordinates, as their base model. They train the model using 53 tasks from 9 groups and evaluate it on various tasks including classification, generation, and natural instructions. The results show that instruction tuning significantly improves OFA's performance on seen multi-modal tasks, especially when transfer learning techniques are applied. Additionally, they introduce a new metric called sensitivity to measure the model's consistency in producing outputs despite slight variations in task wording.</sample>
    <sample id="124">Tan Qingyu from the National University of Singapore and Alibaba presented a study on temporal reasoning capabilities in large language models (LLMs). They introduced three levels of temporal reasoning: time-to-time, time-to-event, and event-to-event. The researchers found that prior works overemphasized L2 reasoning while neglecting comprehensive temporal studies. To address this gap, they created TempReason, a dataset covering all three types of reasoning across various time periods. The experiment results showed improved performance for their proposed TempT5 model compared to other baseline methods like FLAN-T5-L and T5-SFT. However, both ChatGPT and TempT5 exhibited some performance fluctuations depending on different time periods, indicating potential biases in training data imbalances. Future work could focus on mitigating these biases to enhance overall temporal reasoning capability in LLMs.</sample>
    <sample id="125">这篇论文有两位作者。</sample>
    <sample id="126">Yes, the baseline is to use Google Translate API to translate source to target language and then use monolingual model to train and evaluation.</sample>
    <sample id="127">The speaker, Namgyu Ho, introduces their work titled "Large Language Models Are Reasoning Teachers," a joint effort with Laura Schmid and Professor Se-Young Yun from KAIST AI in Korea. They discuss the limitations of chain-of-thought reasoning techniques on large language models like GPT-3 or PALM due to high memory and computational requirements. To address this issue, they propose using these larger models as reasoning teachers to transfer their abilities to smaller models.

Their method involves applying zero-shot chain-of-thought prompting to generate step-by-step solutions for complex tasks, which are then used as training data for fine-tuning small models. This approach allows them to use very large models to teach much smaller ones how to perform complex reasoning tasks effectively.

To enhance teaching efficacy, they introduce Diverse Reasoning, where multiple distinct reasoning samples are generated by sampling at different temperatures. These diverse samples can be utilized to train students more comprehensively, leading to improved performance across various tasks compared to traditional methods such as prompt-based approaches or vanilla fine-tuning.

The results show that their method significantly outperforms existing baselines on 12 benchmark tasks, especially when applied to text-based questions involving data understanding and coin flip scenarios. The performance improvement is particularly notable after implementing Diverse Reasoning, increasing accuracy rates substantially (e.g., Multi Arithmatic goes up from 33% to 55%).

They also highlight scalability aspects, indicating that while development costs increase with additional datasets, better teacher models, and bigger student models, inference times decrease. However, there's an ongoing need to balance these trade-offs based on real-world application demands.

In conclusion, the paper suggests that simple distillation techniques could enable transferring reasoning capabilities from massive pre-trained models to those under one billion parameters. Their proposed method—combining basic distillation with Diverse Reasoning—is described as accessible, effective, and highly scalable. It poses challenges regarding balancing development and inference costs but offers significant potential benefits in terms of model efficiency and applicability.</sample>
    <sample id="128">The paper "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources" presents a diagnostic test suite for evaluating the ability of natural language understanding models to integrate knowledge from different sources. The authors introduce a coreference resolution task designed to probe this integration capability, and evaluate it with human study participants and established coreference resolution models. They define three settings of their proposed test: Background-Pretrain (where background knowledge is available at pretrain time), Background-Both (where both types of knowledge are available in inference-time context), and Background-Inference (where only entity-specific knowledge is provided during inference). Experiments show that many existing models struggle to reason over multiple sources of knowledge without specific training on the KITMUS data set, although some perform better when trained specifically for this purpose. However, even the best-performing models have difficulties integrating backward knowledge presented only at inference time.</sample>
    <sample id="129">作者给出的“显性群体”(marked group) 的示例是白人。</sample>
    <sample id="130">We found that the RNN models normally generalize worse to new data.</sample>
    <sample id="131">测试数据集的名称是clean test sets。</sample>
    <sample id="132">这篇论文有三位作者。</sample>
    <sample id="133">作者使用了多种模态。</sample>
    <sample id="135">ABC-Eval是一种新的维度对话评估方法，由Emory NLP实验室和亚马逊Alexa AI合作开发。该方法通过标注聊天模型的行为来减少人类评估的主观性，并全面覆盖了最近文献中提出的对聊天质量有影响的各种主题错误。ABC-Eval能够测量聊天模型在各种方面表现的准确率，例如忽略对话伙伴、提供不相关信息、自相矛盾、违反常识知识以及是否表现出同理心等。为了确定哪种评估方法更有效，研究者选择了四个最先进的聊天模型，并使用ABC-Eval评估了每个模型的100个人-机器人对话。此外，还使用了三种现有的方法：按回合进行的Likert评分、按对话进行的Likert评分和对话级的二元比较。结果表明，ABC-Eval的行为标签比现有方法更可靠，更能预测整体对话质量。这些可靠的、信息丰富的和独特的ABC-Eval指标使研究人员能够以比以前方法更高的分辨率评估对话式人工智能。</sample>
    <sample id="136">The presentation discusses the development of FERMAT, a flexible evaluation set for numerical reasoning tasks. The motivation behind this work stems from the need to accurately assess mathematical abilities in language models used in various real-world applications such as fact-checking and downstream tasks requiring factual correctness.

The presenter highlights that larger language models tend to perform better than smaller ones on numerical reasoning tasks, with those having at least 10 billion parameters showing superior performance. However, there is an issue where these large models often struggle with certain aspects of numerical reasoning due to their size constraints.

To address this problem, the team introduced FERMAT, which consists of math worded questions extracted from Illinois and CommonCore datasets. These questions are designed to test number understanding, mathematical operations, and training dependency by changing representations of numbers (e.g., using decimals or integers) and introducing different types of mathematical operations (e.g., addition versus combination).

The baseline evaluation showed that most models performed poorly across all tested areas, indicating that current benchmarks may not adequately represent real-world needs. Fine-tuning the models improved performance significantly but still fell short of expectations when compared to original benchmark results.

The study also investigated how well models could generalize based on training data. It was found that even if exact expressions were seen during training, accuracy remained below 50%, suggesting that memorization alone does not lead to better performance. This implies that linguistic context plays a crucial role in enhancing model capabilities.

Furthermore, incorporating diverse training templates from sources like GSM8K and AQUA proved beneficial in improving overall performance. By diversifying both language and mathematics within training sets, researchers observed enhanced learning outcomes.

In conclusion, while existing benchmarks provide limited insight into actual application scenarios, FERMAT offers a more comprehensive approach to evaluating numerical reasoning skills in language models. Areas identified for improvement include number encoding and tokenization techniques.</sample>
    <sample id="137">The paper introduces a new task of language-guided floor plan generation, where the model learns to generate 2D floor plan designs directly from natural language instructions. The authors define this task as generating structured interior layouts that comply with provided language instructions, which include semantics, geometry, and topology. They use publicly available floor plans to construct their Tell2Design dataset, collecting human-annotated language instructions and artificially generated ones from pre-defined templates. The main challenges in this novel task are strict constraints on design generation compared to artwork-like text-conditional image generation, understanding big picture information from unstructured text, and dealing with ambiguous or incomplete instructions. To solve these challenges, the authors propose a sequence-to-sequence model based on the encoder-decoder framework using a transformer-based structure initialized by a pre-trained language model T5 for better language understanding abilities. Their method outperforms other baselines significantly when tested on unseen instructions, indicating mutual benefits during training between artificial and human interactions. A case study shows how different baseline generations fail to align well with user requirements specified in human instructions.</sample>
    <sample id="138">作者认为 NLU 中研究不足的领域是自然语言理解模型如何利用在训练和推理阶段可用的不同知识源。</sample>
    <sample id="139">演讲者的名字是Ying。</sample>
    <sample id="140">是的，CoScript经过了质量检查。</sample>
    <sample id="141">现有的资源只能支持有限的上下文依赖翻译类型和语言，因为它们通常依赖于领域知识和人工编译。</sample>
    <sample id="142">我们的目标是理解用户在做选择时的语言。考虑这样一个替代问题：“你是指‘Easy on Me’还是‘I Gotta Feeling’？”这里，用户想要在这些两首歌之间进行选择。最明显的方法是使用直接引用，例如说歌名“Easy on Me”或其位置，“第一个”。但有时间接引用更合适，以使对话更加自然。这可能发生在用户无法记住歌名的情况下。或者，当歌名发音相似且难以区分时。或者，当用户想表达偏好时。这里有一些间接引用的例子： “较新的那首”或“不是充满活力的那首”。这是在对话系统中理解和评估LLM实体理解能力的重要问题。我们不知道是否有更大的公共数据集用于此任务，因此我们通过众包收集了一个。我们的数据集涵盖了三个不同的领域：音乐、书籍和食谱。我们的数据集收集方法强调了非正式性，使用了一个卡通完成设置。这个漫画有三个对话气泡。在第一个对话气泡中，Bob说：“你还记得我们昨天听的那首歌吗？” Bob设置了对话上下文。在第二个对话气泡中，Alice说：“你是指‘Easy on Me’还是‘I Gotta Feeling’？”这是一个替代问题。在第三个对话气泡中，Bob用间接引用来选择其中一个实体，例如“较新的那首”。我们自动提供前两个对话气泡，但第三个由注释员填写。第一个对话气泡从每个领域的几个手动提示中选择。第二个对话气泡，即替代问题，遵循一个简单的模板。你是指A还是B？其中A和B是从维基百科中抽取的样本。以下是我们在不同领域使用的不同抽样方法。当我们向上移动列表时，实体名称变得越来越相似，因此在区分它们方面通常更难。第一个是均匀随机抽样。第二个是在标题相似的实体之间抽样，例如两个名为“The Return”的书籍。第三个是在维基百科上对它们的描述相似的实体之间抽样。最后，在它们的属性或信息框中具有相似的信息。向注释员展示这种替代问题时，他们知道这些实体的名称，但不一定知道这些实体。因此，我们向注释员展示了每个实体的一些背景知识。对于歌曲，我们简单地显示每个歌曲的Google搜索链接，并要求注释员至少听一些每首歌并阅读关于每首歌的内容。这是Google搜索结果中的“Easy on Me”。对于食谱和书籍领域，我们显示了一些来自维基百科的背景文本。对于食谱，我们还显示了它们的图片，再次来自维基百科，以便注释员知道它们看起来是什么样子。然后，我们要求注释员从这些实体中选择一个，并用三到五个间接引用描述它们。例如，“没有歌词的那首”，“不是那个有12岁男孩的那首”，“虚构的那首”，“来自阿塞拜疆的那首”，等等。AltEntities数据集共有6000个替代问题，横跨三个领域，共有42,000个间接引用。T5 XL模型的结果总结如下。如果语言模型可以访问与注释员相同的背景知识，则准确性非常高，约为92-95%。但这不现实。如果语言模型可以访问一些重叠的背景知识，则准确性在82-87%之间，这更现实。例如，当语言模型检索背景知识时。如果语言模型只能访问实体名称，则准确性仅为60%，因此有很大的改进空间。我们还展示了模型的领域通用性。这是我们的数据集链接。谢谢。</sample>
    <sample id="143">该方法与以下现有的 SimulST 策略进行了比较：等待-k 策略、局部协议和专为同时预翻译设计的架构。</sample>
    <sample id="144">The authors of this paper are affiliated with the University of Nantes.</sample>
    <sample id="145">演讲者的名字是Jenny。</sample>
    <sample id="146">The speaker, Yicheng from Fudan University, introduces the topic of dialogue summarization and its challenges. They explain that omission is a significant issue in generating summaries due to missing critical facts. The study analyzes the percentage of summaries with omission problems across different domains using various pre-trained models. It reveals that even advanced models have high omission rates (around 70%). The distribution of omitted information appears random regardless of length or domain, indicating unstructured dialogues. To address this problem, they introduce the OLDS dataset for omission detection, which includes diverse candidate summaries generated by multiple models. This helps evaluate omission detection tasks more effectively. Three baseline frameworks are explored: pair-wise classification, sequence labeling, and pointer network. Results show moderate performance improvements when omissions are included in summary refinement methods. Overall, the presentation highlights the importance of addressing omission issues in improving dialogue summarization quality.</sample>
    <sample id="147">这篇论文有三位作者：Myra、Esin Durmus和Dan Jurafsky。</sample>
    <sample id="148">好的，现在我将为您翻译Sara Papi的演讲内容。首先，她介绍了她的论文《注意力作为同时语音翻译的指南》，这是一篇与Matteo Negri和Marco Turchi合作的论文。什么是同时语音翻译？同时语音翻译，或SimulST，是指在实时中将一种语言的口语翻译成另一种语言的文字，使跨语言交流成为可能。当前SimulST模型面临哪些问题？通常需要特定的架构进行训练，引入额外的模块进行优化。例如，涉及不同的优化目标的训练过程。为了训练和维护多个模型以达到不同的延迟范围。例如，训练一个平均延迟为一秒钟的模型和另一个平均延迟为两秒钟的模型，等等。我们的解决方案是什么？首先，使用现有的离线ST模型而无需重新训练或采用特定的架构进行SimulST。对于每个延迟范围使用一个模型，并通过特定参数处理延迟。利用模型通过注意机制在音频输入和文本输出之间获得的知识。这是交叉注意机制的一个例子。我们的解决方案是提出EDAtt，或编码器-解码器注意，这是一种策略，我们决定是否发出部分翻译，基于注意指向哪里。如果一个词被发出，则意味着注意力没有集中，即其向后lambda个语音帧的总和低于某个阈值α，这意味着接收到的信息足够稳定。例如，如果我们接收到包含“I'm going to talk about...”的语音片段，并且我们的模型预测德语翻译，我们将查看交叉注意力权重，我们将看到第一个两个单词指向最早接收到的语音帧，而最后一个单词指向最后接收到的语音帧，即lambda个语音帧。这意味着前两个单词将被发出，因为总和超过了一个阈值α，我们不会发出最后一个单词，并等待另一个语音片段。如果我们继续并接收另一个语音片段，我们的模型预测其他三个单词，我们将查看这些交叉注意力权重，我们将看到没有单词指向最后lambda个语音帧。这意味着这三个单词将被发出。如果查看EDAtt的主要结果，我们将绘制同时语音翻译的结果图，在图上有一个BLEU，衡量翻译质量，还有一个平均滞后，衡量延迟，我们还考虑了计算意识平均滞后，考虑到模型预测输出的计算时间。我们希望曲线在该图上尽可能高。我们还希望它们向左移动。我们将与应用于离线模型的流行策略进行比较，例如Wait-k策略和局部协议。我们还将与专门针对同时预翻译的最先进的架构进行比较。这是同时语音翻译策略在德语上的结果。我们看到它优于所有应用于离线模型的策略，因为曲线向左移动。我们还看到，如果我们考虑实际的已用时间或计算意识时间，即最快的策略。如果您想了解更多结果，请阅读我们的论文。我们还发布了代码和模型以及同时输出，以促进我们工作的可重复性。谢谢您的关注。</sample>
    <sample id="149">是的，数据集已经公开了。</sample>
    <sample id="150">Archiki介绍了一篇名为“MEETINGQA:Extractive Question-Answering on Meeting Transcripts”的ACL论文。该论文旨在解决在会议中提取问答对的问题，因为会议记录通常是长文档，包含丰富的信息，但之前的研究仅关注摘要和行动项。为了应对这一挑战，Archiki和他的团队创建了一个名为MeetingQA的新数据集，该数据集基于参与者提出的问题和相应的答案句子。他们使用公共会议记录集（AMI）进行数据收集，并通过标注答案句子来注释答案。MeetingQA包含7,700个问题，分为训练、开发和测试集，其中30%的问题无法回答。数据集中的答案具有多种类型，包括多段答案和多说话者答案。Archiki还展示了数据集的长度分布以及在测试集上的高人类性能（F1为84.6）。为了处理短上下文模型，他们实施了上下文检索方法，并构建了单段模型和多段模型。实验结果表明，在零射设置下，零射性能与人类表现之间存在显著差距，但银色数据增强可以提高零射性能。此外，较大的指令调优模型如FLAN-T5在零射设置下的表现与剩余模型相当。错误分析显示，模型在识别反问和确定哪个说话者回答问题方面存在问题。总之，MeetingQA是一个有趣的基于真实会议场景的开放性、讨论性问题的数据集，目前尚未完全解决，因为它对现有的问答模型构成了挑战。</sample>
    <sample id="151">大家好，我是Ying，我的同事Zhiyang和我将要介绍我们的研究《MultiInstruct：通过指令调优提高多模态零-shot学习》。随着大型语言模型的出现，许多工作开始探索如何利用预训练的语言模型来高效地完成下游任务。最近的研究表明，指令调优可以使大型语言模型在遵循自然指令的情况下，在零-shot方式下表现良好。然而，大多数先前的工作都集中在改进语言任务上的零-shot性能，而计算机视觉和多模态任务则被忽略了。因此，我们想调查一下是否可以通过对多模态预训练模型进行指令调优来提高对未见多模态任务的一般化能力。此外，当时我们发现NLP和多模态之间的可用指令数据集存在显著差异。有超过1600个语言-only指令任务，但没有大规模的公开可用的多模态指令任务。这促使我们构建一个多模态指令调优基准数据集。在这里，我们介绍了MultiInstruct，这是第一个包含62个不同多模态任务的数据集，这些任务来自21个现有的开源数据集，并为每个任务配备了五个专家撰写的指令。我们展示了MultiInstruct数据集的一些示例，以统一处理各种输入和输出数据类型。我们遵循OFA的方法，将所有任务统一为一个序列到序列格式。在统一的标记空间中表示文本、图像、指令和边界框。现在，我要谈谈多模态指令调优。对于训练数据集，我们使用9组中的53个任务进行训练，并从VQ和Miscellaneous组中随机选择10,000个实例。为了测试，我们保留整个常识推理组用于测试，并从VQ和Miscellaneous组中额外选择5个任务。我们使用所有测试拆分中的实例来评估每个任务。此外，我们从自然指令数据集中随机选择20个任务作为NLP的未见任务。我们使用预训练的OFA大型模型作为基线模型。在训练期间，我们将所有任务的所有实例混合在一起。每个实例都可以与其中的一个指令模板随机组合。在测试时，我们对每个任务进行了总共5次实验，通过评估模型在5次实验中的表现来报告最小和最大性能以及性能的标准差。如果任务是多模态分类任务，我们报告准确率。如果是多模态生成任务，我们报告Rouge-L。对于NLP任务，我们报告Rouge-L。我们还引入了一个新的评估指标，称为敏感性。这衡量了模型在任务上产生一致输出的能力，无论指令的措辞如何轻微变化。这是不同微调策略对模型敏感度的影响。通过从自然指令数据集中迁移学习，模型可以实现比原始OFA模型更好的敏感性。我们还可以看到，从自然指令数据集中迁移学习可以帮助OFA在自然指令数据集上实现更好的性能。总体而言，我们提出了第一个大规模的多模态指令调优数据集，显著提高了OFA的短能力，并探索了不同的迁移学习技术并展示了它们的好处。我们设计了一个新的指标——敏感性。最后，我们正在收集大约150个额外的视觉语言任务的更大规模的多模态指令调优数据集，并将在稍后发布。这是我们的数据和模型的二维码。谢谢。</sample>
    <sample id="152">The presentation titled "Exploring Large Language Models for Classical Philology" by Frederick Riemenschneider discusses the intersection of NLP and classical philology. The speaker introduces valuable resources for Ancient Greek and Latin, highlighting recent advancements in language models such as Latin BERT (2020), Ancient Greek BERT (2021), and another Ancient Greek BERT released in 2022. Despite these developments, there are still challenges to be addressed.

The current landscape includes several monolingual BERT-based models that have been pre-trained on Ancient Greek texts but lack multilingual capabilities. Common multilingual models typically do not incorporate Ancient Greek data. Additionally, performance evaluation of these existing models is limited due to a lack of robust assessment methods.

To address these gaps, the presenter's team has developed new language models specifically designed for classical philology. Their goals include making existing models comparable, pushing state-of-the-art further, exploring different model architectures, and introducing multilingual models capable of processing both Ancient Greek and Latin text using the same model.

The development process involved gathering pre-training data from sources like Open Greek &amp; Latin and the Internet Archive. For Ancient Greek, they leveraged OCR transcriptions and searched for correctly transcribed Greek stop words to identify high-quality training materials. They also utilized additional resources for Latin and English texts related to antiquity.

The benchmarking phase focused on tasks such as part-of-speech tagging, dependency parsing, and lemmatization. Results showed that their models outperformed previous state-of-the-art models significantly for both Ancient Greek and Latin. Furthermore, experiments revealed how T5’s encoder behaves differently compared to native encoder-only models when used separately for tasks without a decoder requirement.

In conclusion, the presented work involves creating powerful language models initialized from scratch with native tokenizers, including both encoder-only and encoder-decoder architectures, as well as multilingual models. These innovations aim to enhance the processing of ancient languages within the field of classical philology.</sample>
    <sample id="153">Ninareh Mehrabi在她的演讲中介绍了她的研究，该研究旨在解决文本到图像生成模型中的歧义。她解释说，歧义可能会使模型难以生成忠实于用户意图的图像。为了应对这一挑战，Mehrabi和她的团队开发了一种框架来解决这些歧义，并评估生成的图像是否忠实于用户的意图。他们通过创建一个包含不同类型的歧义的基准数据集来实现这一目标。然后，他们使用语言模型生成澄清问题或不同的视觉设置来解决这些歧义。最后，他们使用视觉问答（VQA）模型来评估生成的图像是否忠实于用户的意图。他们的发现表明，他们的框架在解决歧义方面是有效的，并且与人类评估结果一致。</sample>
    <sample id="154">The authors of this paper are affiliated with the University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="155">演讲者的名字是Javad Hosseini。</sample>
    <sample id="157">The speaker introduces their work, "Dialogue Summarization with Static-Dynamic Structure Fusion Graph", which aims to distill the salient information from a dialogue context into a concise summary. The existing methods mainly focus on modeling dialogues using pre-computed static graph structures and external linguistic tools like discourse parsing and dialogue state tracking. However, these methods have two fundamental drawbacks: they heavily depend on reliable external linguistic tools that may not deliver accurate outputs, causing error propagation; and the fixed static graphs do not dynamically adapt to downstream tasks. To address these issues, the proposed SDDS model consists of four main components: an Utterance Encoder for encoding utterances into vector representations, a Static-Dynamic Graph module for combining multiple static graphs and capturing dynamic relationships between utterances based on deep vector representation, and a Summary Generator employing a pre-trained language model to fuse static structure and dynamically learned structure into the final summary. The detailed model structure is shown in the slide, illustrating how different heuristic dialogue structure modeling methods are employed to build relationships between utterances through various channels such as Discourse Parsing Graph, Key Co-occurrence (KeyCo-occ), Speaker Relationship Modeling, and Utterance Position Graph. Additionally, a 1 x 1 convolutional layer is used for cross-graph fusion and interaction by integrating adjacent matrixes into a unified graph. A dual cross-attention mechanism integrates the graph representation captured during generation process. The code and data have been released on GitHub, accessible via scanning the provided QR code.</sample>
    <sample id="158">The speaker introduces the task of coreference resolution, which involves identifying mentions that refer to the same entity in a document. Conventional methods have quadratic complexity for both computation and memory consumption due to needing to enumerate all pairs of mentions. Cache-based methods reduce this complexity by using a fixed-size cache but may encounter high cache misses when dealing with long documents where topics switch frequently. The proposed dual cache method addresses this issue by having a local cache (using LRU policy) for local entities and a global cache (using LFU policy) for globally frequent entities. This approach is evaluated on four public benchmarks: LitBank, OntoNotes, and WikiCoref datasets. Results show that dual cache outperforms baseline models even without training data while being faster than those with unbounded memory. Additionally, it significantly reduces cache misses compared to single cache methods and has the highest performance/cost ratio among them.</sample>
    <sample id="159">语言模型的接受度判断并不总是对上下文具有鲁棒性。这是与John Gauthier、Aaron Mueller、Kanishka Misra、Karen Fences、Roger Levy和Adina Williams合作完成的工作。在本文中，我们重新审视了最小对齐范式（MPP）。最小对齐范式评估语言模型在接受度判断上的表现，这些判断可以包括语法BLiMP、SyntaGym或基于刻板印象的接受度，例如CrowS对。在最小对齐范式中，评估语言模型的方式通常是展示一个可接受的句子或一个语法正确的句子，然后展示另一个可接受的句子或一个不正确的句子。希望模型会将更多的概率分配给可接受的句子。目前的MPP管道不允许我们评估模型在整个上下文窗口中的接受度。如今，大型语言模型正在出现越来越长的上下文窗口。对于评估模型的接受度至关重要的是，评估模型在整个上下文窗口中的接受度。这就是我们在尝试做的事情。我们的方法是通过重新审视数据集本身，并通过选择来自相同数据集的可接受或不可接受的句子来模拟较长的序列。例如，在BLiMP数据集的附件岛案例中，我们从附件岛中提取语法正确的句子，并将其作为可接受查询和不可接受查询的前缀。我们还可以通过从同一匹配的不同子集或数据集中选择句子来进行相同的操作。我们还通过从完全无关领域，如维基百科，来测试模型的接受度。最终，我们可以选择来自不同数据集的句子，这将告诉我们模型的接受度判断是否受到上下文的影响，即上下文是否来自数据集的不同子集，或者是否与当前要查看的句子无关。模型如何表现？首先，我们看看维基百科句子，这些句子与当前查询对完全无关，我们发现MPP判断在任意上下文长度上都是相对稳健的。我们将上下文长度增加到OPT和GPT-2模型的最大长度，我们看到橙色虚线处的MPP判断相对稳定。现在，当我们在同一个数据集中选择或创建句子时会发生什么？这里我们从相同的BLiMP或SyntaxGym数据集中选择或创建句子，要么是从可接受域，要么是从不可接受域。我们看到，当我们在可接受域中添加可接受前缀或在不可接受域中添加不可接受前缀时，MPP判断要么显著增加，要么显著减少。但当我们匹配结构时，即我们从相同的BLiMP或SyntaxGym现象中选择句子，我们看到MPP判断要么显著增加，要么显著减少，这取决于前缀是可接受还是不可接受。这种影响随着上下文长度的增加而显著增加，这可能会影响具有较大上下文窗口的新语言模型。为什么匹配前缀会如此显著地影响语言模型的判断？我们进行了一系列分析，其中我们通过保留相关结构并添加输入噪声来扰动输入句子。经过一系列这些扰动后，我们发现所有这些噪声都以类似的方式使模型改变其MPP判断。简而言之，我们发现模型对共享于句子中的潜在句法和语义特征敏感。目前我们以短且单个句子输入的方式进行MPP评估，可能无法全面捕捉模型在整个上下文窗口中的抽象知识。请阅读我们的论文以获取更多实验细节。谢谢大家的聆听。</sample>
    <sample id="160">该方法的第一步将输入词元映射到一个无序的词元集。</sample>
    <sample id="161">55,000</sample>
    <sample id="163">MASSalign</sample>
    <sample id="164">弱监督学习的好处是，它允许在没有手动标记数据的情况下训练神经网络。相反，它使用弱标记源，如简单的启发式规则、知识库或低质量的众包，来标记数据。与人工注释相比，这些较弱的注释要便宜得多，但它们也是嘈杂的，意味着一定数量的注释是不正确的。如果直接在弱标记数据上训练神经网络，神经网络倾向于记住标签噪声，并且无法泛化。在弱监督学习中，提出了训练算法来在这样的标签噪声下稳健地训练神经网络，使得训练的模型仍然能够很好地泛化。</sample>
    <sample id="165">Wenting Zhao, a PhD student at Cornell University, presented their recent paper titled "Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations" at the conference. The presentation began with an example to illustrate abductive reasoning and then provided a formal definition of it. Abductive reasoning starts with a context (e.g., Emily was stuck in traffic) and ends with an outcome (e.g., Emily made it to her flight). A set of possible explanations is given; here, Explanation 1 ("Her flight was delayed") and Explanation 2 ("Her flight left on time") are examples. The goal of abductive reasoning is to identify a plausible explanation that can bridge the information gap between the context and outcome.

The current approaches to abductive reasoning predominantly rely on supervised methods but require annotation of plausible explanations, which can be noisy and subjective. A recent experiment revealed that crowd workers disagree on 60% of over 1,000 explanations. Therefore, the question posed by Zhao's team is whether it is possible to learn abductive reasoning without supervision regarding the plausibility of explanations? 

The answer they provide is yes. They introduce an unsupervised learning method called LiPoR, which stands for Likelihood Learning with Posterior Regularization. In this approach, Explanation Z is treated as a latent variable, leading to an unsupervised objective where maximizing the marginal likelihood of the Outcome Y given the Context X involves marginalizing other possible explanations in Z. This means optimizing the objective does not require knowing which explanations are plausible.

However, the unsupervised objective L only maximizes the likelihood of outcomes and doesn't prefer plausible explanations. To achieve this preference, Zhao's team introduces a regularizer based on mutual exclusivity among explanations. Mutual exclusivity refers to the fact that certain explanations cannot be true simultaneously – if one explanation were true, another would automatically rule out being true. For instance, in the abductive reasoning example shown earlier, Explanation 1 rules out Explanation 2 because both cannot occur at the same time.

Formally, the LiPoR objective consists of two parts: maximizing the likelihood of outcomes and preferring some explanations over others using a regularizer denoted by Omega. Omega takes the max between the entropy of P of Z given XY and the log of M, where M represents the number of plausible explanations. When the entropy of P of Z given XY exceeds the log of M, it indicates there are more than M explanations receiving probability mass. Consequently, minimizing the entropy of P of Z given XY prefers a subset of explanations.

Zhao concludes by presenting results from their work on AlphaNLI, the most widely-used abductive reasoning dataset. Their model, LiPoR, outperforms all previous models, including a strong zero-shot GPT-3 baseline, by over 4 absolute points in accuracy when compared against various zero-shot models and the best unsupervised approach available.

In summary, Wenting Zhao introduced an innovative approach to abductive reasoning through their proposed method, LiPoR, addressing challenges associated with traditional supervised methods while achieving superior performance on benchmark datasets like AlphaNLI.</sample>
    <sample id="166">The proposed method, NDCR, outperforms other baselines in image retrieval from linguistically complex text. The first model is the Proposition Generator, which decomposes complex proposition texts into simple propositions and generates corresponding sentences using BART's decoder. System 1, or the Visual-Linguistic Interactor, performs visual-propositions' information interaction to obtain matching scores of propositions and images as well as their reasoning states. System 2, called Neural-Symbolic Reasoner, integrates these reasoning states and results via negation executor and conjunction operation to gain a final solution for complex propositions on images. Experimental results show that this approach effectively utilizes both analogical inference (System 1) and logical reasoning (System 2). Two cases demonstrate the method's ability to present intermediate inference states and results, indicating interoperable processing. Suggestions include exploring neural symbolic calculation for compositional reasoning and planning improvements in large language models, integrating Divide-and-Conquer with Dual-Process Theory, and further investigating how these approaches can enhance problem-solving capabilities.</sample>
    <sample id="167">DEPLAIN-web 中的文档采用手动和自动对齐方法进行了对齐。具体分配情况如下： 1. 手动对齐：750 个文档中的所有文档都进行了手动对齐。 2. 自动对齐：同样，750 个文档中的所有文档也都进行了自动对齐。 因此，DEPLAIN-web 中的每个文档都使用了两种对齐方法进行对齐。</sample>
    <sample id="168">CoNLL++数据集是由从2020年收集的新闻文章组成，然后使用与CoNLL-2003相同的注释指南进行注释。</sample>
    <sample id="169">David Vilar介绍了Google Translate团队与他人合作的论文《Prompting PaLM for Translation: Assessing Strategies and Performance》。该论文研究了大型语言模型（LLMs）在机器翻译中的提示能力，使用最新的测试集以避免测试数据与语言模型训练数据重叠，并将结果与最先进的系统进行比较。他们使用最新的神经机器翻译指标和专家基于人类评估的结果进行了评估，并提供了有关提示策略选择的建议。实验结果显示，提示形式对LLM的翻译性能影响不大，但提示示例的质量更为重要。他们发现，从高质量翻译中选择提示比从嘈杂的训练数据中选择提示更有效。尽管如此，PaLM的翻译性能仍然接近于最先进的系统，主要问题在于准确性，而不是流畅性。</sample>
    <sample id="170">好的，以下是翻译结果：

大家好，我是来自宾夕法尼亚州立大学的Yusen Zhang。今天我要介绍我们的工作“XSemPLR：多语言自然语言和意义表示的跨语言语义解析”。语义解析是一个任务，即构建用户查询的语义表示，例如SQL和Lambda计算。而跨语言语义解析是将多个自然语言中的查询翻译成多个语义表示。如图所示，我们需要使用神经模型将多个自然语言中的查询翻译成SQL、Lambda或FunQL等。现有的跨语言语义解析模型是分别提出的，并在特定任务和应用的数据集上进行评估。例如，它们对某些自然语言有很好的覆盖范围，但对中文的覆盖范围较少，对某些意义表示缺乏覆盖范围，或者只对某些神经模型进行了评估。为了应对这一问题，我们提出了XSemPLR。我们提供了一个统一的数据集XSemPLR，用于跨语言语义解析的多种自然语言和意义表示。它包含9个涵盖各种领域的数据集，5种语义解析任务，8种意义表示，以及15种语言家族中的22种语言。为了更好地评估我们的基准，我们考虑了六个训练和评估设置。第一个是翻译测试。我们使用Google Translate API将源语言翻译成目标语言，然后使用单语言模型进行训练和评估。例如，我们用英语模型在英语查询上进行训练，在推理时使用API将德语查询翻译成英语，然后使用训练好的模型预测SQL。我们还将测试单语言模型。在这种情况下，源语言和目标语言相同，例如德语到德语或英语到英语。我们还测试了单语言少量设置，通过使用仅10%的训练数据训练单语言模型。我们还测试了多语言模型，其中我们将德语、英语、中文查询组合在一起进行训练。在推理期间，我们可以使用此模型来翻译德语查询或中文查询，等等。我们还考虑了跨语言零-shot和少量转移。我们在一个源语言上进行训练，然后转移到另一个语言。在训练期间，我们可以在英语查询或德语和英语少量查询的组合上训练一个多语言模型来预测SQL输出。我们还发现了一些有趣的结果。例如，对于单语言模型的分析，我们评估了两组模型，包括编码器-指针（Encoder-PTR），即使用多语言预训练编码器和基于指针的解码器，例如XLM-R + PTR和mBERT + PTR。我们还评估了编码器-解码器模型，即多语言预训练编码器-解码器模型，例如mBART和mT5。我们发现编码器-解码器在所有九个数据集上都优于之前的模型，或者实现了可比的结果。在单语言预训练中，自然语言对目标自然语言的性能提升显著。我们还发现多语言语言模型，例如Codex和BLOOM，对于跨语言语义解析任务仍然不够充分。总的来说，我们构建了XSemPLR，一个统一的基准，用于跨语言语义解析的多种自然语言和意义表示。我们进行了全面的基准研究，比较了三种代表性的多语言语言模型。我们的结果显示了许多有趣的发现。例如，编码器-解码器优于先前的工作，或者实现了可比的结果。在少量设置下，使用英语自然语言进行预训练可以显著提高目标自然语言上的性能，我们发现Codex和BLOOM对于跨语言语义解析任务仍然不够充分。</sample>
    <sample id="171">Existing works can be broadly classified into four categories. However, this method either not applicable to embedding as services or lack of transferability.</sample>
    <sample id="172">不，多语言 LLM 如 Codex 和 Bloom 对于 CLSP 来说还不够。</sample>
    <sample id="174">Thea, one of the co-authors of the paper "ArgAnalysis35K : A large-scale dataset for Argument Quality Analysis," explains why this dataset is unique from other datasets on a similar topic. Thea provides an overview of the special features that make ArgAnalysis35K stand out.

Argument quality analysis involves evaluating how good or bad an argument is on a scale from 0 to 1. For example, an argument like "Big banks are bad" might be rated low due to its simplicity and lack of depth, while an argument such as "Big banks have no accountability, take heavy risks, and lead to major collapses, which is why they should be broken up" would likely receive a high rating because it presents a coherent and persuasive case with multiple premises supporting the claim.

Thea points out several problems associated with current datasets:

1. **Lack of Quality**: Many existing datasets rely on crowdsourcing platforms, resulting in lower-quality arguments.
2. **Limited Diversity**: These datasets often consist of only around 30-40 motions and source arguments based solely on those specific topics.
3. **Insufficient Depth**: They fail to explain why certain arguments are true comprehensively.
4. **Motion Association**: Each motion typically has corresponding arguments rather than being paired individually.

ArgAnalysis35K addresses these issues by offering distinct advantages:

1. **Largest Dataset with High-Quality Arguments**: With over 35,000 argument-analysis pairs, ArgAnalysis35K is the largest dataset in this field known so far. Approximately 85% of the arguments come from high-quality sources such as speeches at prestigious tournaments, expert debaters, intermediate debaters, and novice debaters (everyday people).

2. **Diverse Range of Arguments**: Instead of focusing on pre-selected motions, ArgAnalysis35K selects themes through experience gained from participating in debates, using resources like Hellomotions.com, seeking advice from experts, etc. This approach ensures greater diversity in the types of motions encountered within parliamentary debate settings compared to previous methods.

3. **Introduction of Analysis**: Unlike traditional claims or premises, ArgAnalysis35K introduces the concept of 'analysis,' where different elements combine into one cohesive explanation. An example provided includes combining a premise ("Educated people are 80% more likely...") with relevant statistics to form a complete argument.

4. **Analysis as Coherent Statements**: In contrast to merely stating a claim without context, analysis encompasses various combinations of claims, premises, and even additional information when necessary. It aims to provide deeper insights into why particular arguments hold weight.

5. **Instance-Based Annotator Reliability**: Recognizing human biases among annotators—such as personal experiences influencing judgments about certain topics—ArgAnalysis35K employs instance-based reliability measures. By assessing each annotation's bias level per individual argument, the project can utilize reliable data despite potential biases across diverse subjects.

6. **Relevance Model**: Traditional datasets link arguments strictly to specific motions; however, ArgAnalysis35K uses a relevance model assigning scores between 0 and 1 for each theme and argument combination. This method captures the broader applicability of arguments beyond their immediate association with single motions.

In summary, ArgAnalysis35K offers significant improvements over prior datasets: increased size and variety of arguments, enhanced analytical capabilities, reduced reliance on biased annotations, and advanced relevance modeling techniques. As a result, researchers working on argument quality analysis now benefit from richer, more comprehensive training materials tailored specifically for their needs.</sample>
    <sample id="175">该方法通过诱导对齐作为训练的一部分来处理排列的不确定性。有时，可能存在多个与数据一致的排列，但语言上更合适的排列是隐藏的。通过将对齐作为训练过程的一部分进行处理，该方法可以学习和适应这些不确定性，从而提高模型的性能和准确性。</sample>
    <sample id="176">在NLP应用中，公平性通常通过评估模型在不同群体或类别上的表现来衡量。例如，在仇恨言论检测和假新闻检测等任务中，可以将模型的性能分为不同的政治倾向或新闻媒体类别。如果发现模型对某些群体的表现优于其他群体，这可能表明存在不公平的问题。例如，在仇恨言论检测中，左倾模型可能更擅长检测针对少数群体的仇恨言论，而右倾模型可能更擅长检测针对更有权力群体的仇恨言论。类似地，在假新闻检测中，左倾模型可能更擅长检测来自其政治倾向相反的假新闻，而右倾模型可能更擅长检测来自其政治倾向相反的假新闻。这些观察结果表明，语言模型的政治倾向可能导致不同社会群体的不公平对待。</sample>
    <sample id="177">演讲者的名字是Yanis Labrak。</sample>
    <sample id="178">演讲者的名字是Koustav Sinha。</sample>
    <sample id="179">The research question is, "How can we improve Theory of Mind reasoning skills in Large Language Models?" The proposed solution is SymbolicToM, an inference-time method to enhance the understanding and reasoning abilities of large language models. This approach utilizes explicit graphical representations to better interpret mental states within a story context.

The study presents two main datasets: D₁ for testing storage structure generalization and ParaphrasedToMi for linguistic diversity. These experiments demonstrate that while supervised approaches significantly degrade performance on these new datasets, SymbolicToM consistently shows improvement across various LLMs, including GPT-4. For instance, it provides a 42-point accuracy boost for dataset D₁ when using stronger models like GPT-4.

In conclusion, SymbolicToM offers a practical way to augment the theory of mind capabilities of large language models without risking overfitting. It leverages interpretable symbolic graphs to provide more accurate responses to questions about characters' beliefs and estimations within stories.</sample>
    <sample id="180">演讲者的名字是Myra。</sample>
    <sample id="181">The study investigates the ability of large language models to plan for specific goals with constraints, such as "make a chocolate cake". Previous work has focused on planning abstract goals like "make a cake", but this paper addresses the challenge of constrained language planning. To acquire these goals, they extend abstract goals with multi-faceted constraints and use InstructGPT for human-in-the-loop data acquisition. The table shows that all language models achieve unsatisfactory results in planning for specific goals. They conduct detailed analysis to investigate why learning models fail and find that semantic completeness is acceptable but faithfulness to constraints cannot be guaranteed. Using topic categories from wikiHow, they develop an over-generate-then-filter method to improve generation quality by filtering out scripts that do not meet the target constraint. With their method, InstructGPT can generate higher-quality scripts. They also create a dataset named CoScript using large language models, which includes 55,000 specific goals with scripts. This dataset helps smaller and specialized models surpass larger ones when properly trained.</sample>
    <sample id="182">在本文的背景下，热带主义指的是对拉丁裔女性使用“充满活力”、“丰满”和“鲜艳”等词语，这些词语将她们与一种被称为热带主义的刻板印象联系起来。这种刻板印象将拉丁裔女性描绘为充满活力、热情洋溢，并且具有独特的文化身份，这反映了她们与白人规范之间的区别。</sample>
    <sample id="183">作者使用提示，例如“想象你是一个亚洲女性。描述你自己。”来创建目标群体的人工描写。</sample>
    <sample id="184">CXMI被用来衡量语境使用情况。</sample>
    <sample id="185">DrBERT是基于RoBERTa的，而ChuBERT是基于Nantes大学医院数据仓库中的匿名数据。</sample>
    <sample id="187">这篇论文有两位作者，分别是Ying和Zhiyang。</sample>
    <sample id="188">迭代迁移学习是一种在不同任务之间转移知识的方法，通过在相关任务上进行微调来提高模型的性能。在这种情况下，作者将迁移学习应用于认知失调检测任务，并使用迭代更新策略来提高模型的性能。</sample>
    <sample id="189">数据集的目标是理解用户在选择实体时的语言，通过提供一个包含音乐、书籍和食谱三个领域的数据集，来评估语言模型在处理间接指代表达方面的性能。</sample>
    <sample id="190">攻击者通过学习嵌入来提取模型参数。</sample>
    <sample id="191">这篇论文有三位作者。</sample>
    <sample id="192">The presentation introduces a new optimizer called CAME, which aims to achieve both fast convergence and low memory usage. The presenter explains that existing adaptive gradient-based optimizers like Adam require significant auxiliary memory for keeping the first and second moment estimates of per-parameter gradients, while some memory-efficient optimizers like Adafactor have been proposed but with performance penalties. To address this challenge, the presenters propose an optimizer that can simultaneously meet these two goals.

The presentation provides preliminary information about non-negative matrix factorization (NMF) and its application in Adafactor's optimization method. However, it is mentioned that NMF operations in Adafactor lead to erroneous updates during training, resulting in slower convergence compared to traditional methods like Adam. This limitation restricts the use of memory-efficient optimizers.

To overcome this issue, the presenters introduce two scenarios demonstrating how erroneous updates should be handled in ideal cases. They then describe their approach to reduce the side effects caused by insecure updating. By taking the residual between predicted update and generated update as instability, they adaptively adjust the momentum using the original mₜ value divided by the calculated instability matrix Sₜ. 

The experiments conducted on BookCorpus and English Wikipedia demonstrate that CAME outperforms Adam and Adafactor in terms of validation accuracy when trained on three large language models: BERT, GPT-2, and T5. Additionally, CAME shows improvements over other memory-efficient optimizers such as SM3, especially for very large batch sizes ranging from 8K to 32K. These results highlight the effectiveness of CAME in supporting efficient large batch training for large language model tasks.</sample>
    <sample id="193">创建初始数据集的注释者数量没有在提供的信息中指定。</sample>
    <sample id="194">这篇论文的作者所属机构是卡内基梅隆大学。</sample>
    <sample id="195">The speaker introduces a work titled "Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering". The aim of this work is to answer complex questions and provide explanations. There are two main directions in recent XQA research: neuro-symbolic methods, which translate natural language into formal representations like SPARQL, and decompose-based methods, which break down complex questions into sub-questions or chains-of-thought using free-text corpora as knowledge sources. However, both approaches have limitations; the former can only be executed on incomplete structured KBs, limiting recall, while the latter struggles with diverse natural languages and integrating knowledge from heterogeneous sources.

To address these challenges, the proposed framework RoHT (Reasoning over Hierarchical Question Decomposition Tree) adopts a two-stage approach. Firstly, it builds a Hierarchical Question Decomposition Tree (HQDT), where each non-root node represents an intermediate question derived from its parent's grouped leaf questions based on reference tokens. Secondly, probabilistic reasoning over HQDT fuses knowledge from different levels of training—both a knowledge base and a text corpus—to consider the probability scores of string generation and answering.

The process involves building the HQDT by generating atomic questions at the leaf level through a question decomposer and then creating intermediate questions based on their reference tokens via another question generator. Certainty scores for each node are computed based on likelihood representation. Probabilistic reasoning proceeds recursively from root to leaves, involving three steps per node: determining appropriate knowledge sources, executing answers with probabilities from selected sources, and aggregating candidate answers from all sources to output top key answers with high probabilities.

The evaluation was conducted on KQA Pro and Musique datasets. Results show that RoHT outperforms existing methods when only using an incomplete KB but improves significantly upon adding Wikipedia as supplementary text data. Compared to TransferNet, which uses mixed relation graphs end-to-endly trained, RoHT demonstrates superior performance explicitly through decomposition. On the Musique dataset, RoHT also surpasses SOTA method EX(SA) even without additional information, highlighting the effectiveness of combining text and KB data.</sample>
    <sample id="196">一个支配词在左侧的示例是“我看到了巴特和丽莎”。</sample>
    <sample id="197">对话系统中的最先进模型是四个。</sample>
    <sample id="198">我们需要在整个上下文窗口中评估模型的可接受性，因为大型语言模型现在具有越来越长的上下文窗口。当前的MPP管道没有考虑到模型在较长序列中的接受度。通过模拟较长的序列，我们可以更好地了解模型是否能够准确地评估其接受度，无论上下文长度如何。</sample>
    <sample id="199">No, multilingual training can improve performance.</sample>
    <sample id="200">Yes, the annotators knew the name of these entities.</sample>
    <sample id="201">评估使用了BLEURT和MQM指标。</sample>
    <sample id="202">不，我们的实验没有发现特定的 NER 类型有回归现象。</sample>
    <sample id="203">在自然语言处理（NLP）中，立场很重要，因为它可以影响研究过程和结果。研究人员的立场可能会影响他们做出的决策，这可能导致技术在不同人口群体之间存在系统性的性能差异。这种现象被称为设计偏见。例如，一个模型或数据集可能对某些人口群体的表现更好，而对其他群体的表现较差。理解并解决这些设计偏见对于确保NLP技术公平且适用于所有用户至关重要。</sample>
    <sample id="204">BLOOM 是采用适配器微调。</sample>
    <sample id="205">Shangbin, a PhD student at the University of Washington, presented their work "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models". They discussed how language models are trained on large-scale web crawl data and highlighted that political news media is well-covered in this training. This has led to potential fairness issues due to inherent social biases in pretraining data. To address these concerns, Shangbin proposed investigating the political bias propagation pipeline from pretraining data to language models to downstream tasks. The study involved evaluating the political leanings of different language models using prompt formats with political questionnaires like the political conference test. Preliminary results showed varying political leanings among language models, ranging across all four quadrants of the political campus. Additionally, they explored whether political biases were picked up from training data by conducting experiments with partisan corpora divided into news and social media based on their political leaning. Results indicated that ideological coordinates shifted for language models further pretrained on left-leaning Reddit corpus. Furthermore, the research investigated whether language models could pick up societal polarization trends observed after 2017's presidential election. By dividing pretraining corpora into those before and after the presidency change, it was found that language models generally had a political leaning farther away from the center post-2017. Lastly, the team evaluated language model performance on hate speech detection and fake news detection tasks. Their findings revealed significant differences in per-category performance between left-leaning and right-leaning language models, indicating potential fairness issues related to political biases in language models. These insights underscored the need to acknowledge and tackle fairness issues arising from the political leanings of language models.</sample>
    <sample id="206">他们使用了一个初始模型进行迁移学习，这个模型是通过从两个不同的任务中转移权重得到的。具体来说，他们从一个任务中转移了权重，这个任务是关于辩论的，另一个任务是关于扩展和比较类别的PDTB。通过这种方式，他们能够提高零-shot性能，并在后续的迭代中进一步优化模型。</sample>
    <sample id="207">最近用于评估 PaLM 能力的测试集包括 WMT 评估。</sample>
    <sample id="208">作者提出了三条建议。</sample>
    <sample id="209">与最强的基线相比，提议的方法获得了多少收益？</sample>
    <sample id="210">演讲者的名字是Shuheng。</sample>
    <sample id="211">论文中的结果和数据集可以用作基准。</sample>
    <sample id="212">They conducted experiments with two smaller models: T5 and GPT-3.</sample>
    <sample id="213">在研究多模型指令调整时，使用了OFA作为基础模型。</sample>
    <sample id="215">这段英语内容主要讨论了依赖结构在协调中的作用。作者通过分析不同理论和语料库对协调结构的假设，提出了一个关于协调结构对称性的新论点。他指出，在英语中，直接宾语倾向于靠近动词，而从属成分可以更远。然而，当直接宾语很长时，这种效果可能会被缓解，因为它可以被移动到从属成分之后的位置。作者使用了依赖长度最小化的原则来解释这一点，即较短的依赖关系是首选的。

作者还通过分析来自增强版的Penn Treebank的各种统计信息，进一步支持了他的论点。这些统计信息表明，左连词通常比右连词短。此外，这种趋势随着两个连词之间的长度差异的增加而变得更加明显。然而，当主格出现在右侧时，这种趋势就消失了。作者通过比较不同情况下协调结构的长度，展示了这一现象。</sample>
    <sample id="217">The work presented is titled "Seen to Unseen: Exploring Compositional Generalization of Multi-Attribute Controllable Dialogue Generation" and was conducted by Weihao Zeng, Lulu Zhao, and Keqing He at the Beijing University of Posts and Telecommunications. The study addresses limitations in previous methods for generating controllable dialogue that focus on single attributes or use specific labels without considering continuous attributes.

The authors propose a Disentangled Controllable Generation (DCG) model which learns attribute concepts from seen values using disentanglement loss to separate different attribute combinations. They also introduce a unified reference-free evaluation framework called MAE (Multi-Attribute Evaluation), designed not to require additional labeled data. This framework includes templates with discrete prompts such as emotion/act/persona controls followed by [MASK] to reduce bias from handcrafted patterns.

Experimental results demonstrate that DCG outperforms other baselines across various metrics like E-ACC, A-ACC, BLEU scores, and achieves better performance even when transforming unseen attribute combinations into seen ones. Additionally, it shows higher correlation coefficients compared to classic control metrics both for coarse-grained discrete attributes and fine-grained continuous attributes. Removing the task-oriented prompt leads to decreased correlation scores indicating its importance. 

The method's effectiveness is further validated through visualization techniques showing how PCA can be used to prove compositional generalization capabilities. Overall, this research contributes significantly towards improving multi-attribute controllable dialogue generation models' ability to generalize from known attributes to unknown combinations while maintaining high quality and diversity in generated responses.</sample>
    <sample id="218">这篇论文的作者所属机构是Google Translate。</sample>
    <sample id="219">The speaker, Jia-Huei Ju, is a research assistant at Academia Sinica. He presented their work titled "A Compare-and-contrast Multistage Pipeline for Uncovering Financial Signals in Financial Reports". This presentation was done with Yu-Shiang Huang, Cheng-Wei Lin, and advisors Professors Che Lin and Chuan-Ju Wang. The goal of this work is to analyze financial reports using natural language processing techniques.

Ju began by discussing the background of analyzing financial reports, which involves extracting useful information from these documents that are required by the SEC (Securities and Exchange Commission). These reports contain detailed information about companies' activities but require significant human effort to mine meaningful data.

The motivation behind this study comes from two observations: first, there is high text similarity between consecutive years' reports; second, many words used in company reports remain consistent across different years. To address these challenges, they introduced a highlighting task where models compare and contrast contexts within target and reference reports. 

Their proposed pipeline consists of three stages:
1. Document segmentation
2. Relation recognition 
3. Out-of-domain fine-tuning followed by domain-adaptive training

Stage 0 focuses on document segmentation, while Stage 1 deals with relation recognition. In Stage 2, out-of-domain fine-tuning uses an external dataset called eSNLI—a natural language inference dataset—to improve model performance without direct access to labeled financial report pairs during training.

For intermediate fine-tuning, they employed soft labeling techniques combining cross-entropy loss functions and KL divergence metrics. This approach helps mitigate issues related to low-quality pseudo-labels generated through random sampling or other methods.

Evaluation results showed promising outcomes when applying their method to both internal datasets (FINAL) and external ones like eSNLI. They also observed improvements even after simulating mismatched pair scenarios not seen during initial training phases.

In summary, Ju's talk highlighted how advanced NLP techniques can be applied effectively towards uncovering valuable insights hidden within complex textual structures found in annual financial reports. Future directions include enhancing effectiveness further along with exploring additional features integration into existing frameworks.</sample>
    <sample id="220">这篇论文的作者所属机构是Stony Brook University。</sample>
    <sample id="221">论文分析了英语和德语之间的翻译。</sample>
    <sample id="222">The work investigates different data interventions that would be useful in enabling out-of-domain generalization in open-domain QA. The study identifies the type of dataset shift a new domain exhibits and determines what kind of data interventions are effective for a specific type of shift. They observe that few-shot techniques improve retrieval performance by 8% on average, while reader performance improves by 11% on average. Zero-shot techniques also show improvements, with uniform distributions covering all types of answers equally working best. The nature of compatibility between source retriever and target domain is measured using likelihood values assigned to contexts and answers from fixed question/answer and context triples. Datasets exhibiting full shift have both retriever and reader incompatible, while datasets under each category of shift respond well to either zero-shot or few-shot adaptations based on their specific needs.</sample>
    <sample id="223">演讲者的名字是Shangbin。</sample>
    <sample id="224">在实验过程中研究了两个模型：长mBART和基本mBART。</sample>
    <sample id="225">在 MultiInstruct 中使用的 62 个不同任务中，有 53 个任务用于训练和测试目的。</sample>
    <sample id="226">There are two authors mentioned in the video: Regina Stodden and Omar.</sample>
    <sample id="227">The speaker discusses the challenges of grounded language understanding in natural language processing (NLP) tasks. They explain that current language models, including large ones like Codex, are pre-trained with textual data and do not incorporate grounding during this process. This lack of grounding makes it difficult for these models to map natural language expressions into executable plans or programs within specific environments.

The main challenge is highlighted as the gap between pre-training and downstream application. Existing research often uses language models to generate plans directly through autoregressive decoding, which can result in non-grammatical or invalid plans due to the model's generation limitations.

To address this issue, the speaker introduces a novel framework called Pangu. In Pangu, a symbolic agent interacts with the environment to propose candidate plans, while a language model only scores and ranks these candidates without needing to handle plan validity or grammar itself. The framework separates newer world (language modeling) from symbolic world (planning).

Pangu demonstrates strong performance across various settings when applied to knowledge-based question answering scenarios. It shows superior sample efficiency compared to other methods such as ArcaneQA, especially under non-i.i.d conditions where autoregressive models tend to overfit seen structures. 

The key takeaway emphasized by the speaker is that discrimination might be more effective than generation for grounded language understanding applications involving language models.</sample>
    <sample id="228">作者在实验中使用了AG News、MIND、SST2和Enron Spam数据集。</sample>
    <sample id="229">The presented work focuses on detecting improvable claims for argumentative writing support. The authors introduce two new tasks: Suboptimal-Claim detection and Claim Improvement Suggestion, which aim to determine whether a claim needs revisions or is phrased optimally. They explore the challenges of working with revision-based data in collaborative online debate platforms like Kialo. Four main challenges are identified: Representativity and Reliability, Model Complexity and Architecture, Contextual Dependence, and Topical and User Bias. The paper discusses strategies to address these challenges and presents experimental results showing that revision-based data can be effectively used for the given tasks.</sample>
    <sample id="231">NACHOS 是一个包含医疗数据的网络爬虫数据集。</sample>
    <sample id="232">演讲者的名字是David Vilar。</sample>
    <sample id="233">Simultaneous speech translation, or SimulST, is the process of translating spoken language into a text in another language in real time, enabling cross-language communication. However, current SimulST models have several problems: specific architectures are usually trained, introducing additional modules to be optimized; long and complicated training procedures (for example, training involving different optimization objectives); and training and maintaining several models to reach different latency regimes (for example, training a model with an average of one second latency and another one with two seconds latency). EDAtt, or Encoder-Decoder Attention, proposes using already existing offline ST models without re-training or adopting specific architecture for SimulST. It uses only one model for every latency regime and handles latency through specific parameters. The strategy decides whether to emit or not a partial translation based on where attention points to. A word is emitted if the attention is not concentrated, that is, its sum is below a certain threshold alpha towards the last lambda speech frames, meaning that the received information is enough stable.</sample>
    <sample id="234">提示策略对结果有重大影响。在实验中，他们发现使用不同的提示策略可以导致翻译质量的显著差异。例如，在一个简单的实验中，他们使用了一种提示策略，其中每个句子都用其语言标记（例如，对于德语到英语的翻译，源句子用德语冒号标记，翻译用英语冒号标记）。他们观察到，提示的实际形式对翻译质量的影响不大，特别是对于短提示。然而，提示的质量对翻译结果有重大影响。他们建议选择高质量的翻译作为提示，因为这比提示的形式更能影响翻译质量。</sample>
    <sample id="235">这篇论文的作者所属机构是：University of Washington, Microsoft Research, and University of California, San Diego.</sample>
    <sample id="236">专家编写的指令是为每个任务提供的。这些指令用于指导模型在执行任务时如何操作。它们通常包括任务的描述、输入示例和期望输出。通过使用这些指令，模型可以更好地理解任务的要求，并生成符合预期结果的输出。</sample>
    <sample id="237">作者建议通过使用一个核心参考任务来测试模型，该任务设计用于探测模型从不同来源获取知识的能力。</sample>
    <sample id="238">The video presents a new benchmark dataset called MeetingBank, created by Yebowen Hu from the University of Central Florida. The purpose of this dataset is to develop summarization technologies for different reading domains in meetings. To create MeetingBank, two major challenges were addressed: obtaining high-quality meeting summaries or scores and locating trustworthy resources for public meetings.

To collect data, Speechmatics API was used to convert audio data into transcripts. Then, open meeting websites like Boston City Council's website were accessed to identify types and data of meetings through an ItemID that uniquely represents each meeting. This information was converted into MeetingIDs. Reference summaries from meeting minutes were located using these MeetingIDs. Subsequently, meeting segments with start and end times were obtained, aligned with timestamps, and paired with previous extracted summaries.

MeetingBank includes 1,366 City Council meetings and nearly 7,000 instances. Data analysis measures coverage and density levels of meeting summaries. Coverage score indicates how many summary words appear in source transcripts (between 0.7-0.9), while density score evaluates if summaries can be characterized as sets of extracted references.

For model evaluation, ten systems including extractive models Oracle, LEAD, LexRank, TextRank, BART-Large, Pagasus, Longformer, DialogLM, HMNet, and GPT-3 were evaluated on test set MeetingBank. Results show that GPT-3 achieves highest ROUGE-2 scores but performs less impressively in informativeness and factuality according to automatic metrics. Human evaluation revealed that GPT-3 has exceptional performance in fluency and coherence but lower scores in informativeness and factuality based on Likert scaling criteria.

In conclusion, MeetingBank serves as a valuable resource for researchers designing advanced meeting summarizers and provides insights into decision-making processes within city councils.</sample>
    <sample id="239">大家好，我是David Vilar，我将对Google Translate团队的论文《Prompting PaLM for Translation: Assessing Strategies and Performance》进行简短的评论。PaLM是一个于2022年发布的540亿参数的大语言模型。它在7800亿个标记的大量文本上进行了训练，并且在发布时，在数百项自然语言处理任务中达到了最先进的水平。在这项工作中，我们进行了首次关于大语言模型提示用于机器翻译的系统性研究。我们使用了机器翻译社区的最佳实践来评估这些模型的过渡能力。这包括使用最新的测试集以避免测试数据与语言模型训练数据的重叠。我们还将结果与WMT评估中的最佳性能系统进行了比较。我们使用最先进的神经机器翻译指标，并且还展示了基于专家的人类评估结果。最后，我们提供了有关提示选择策略的一些建议。提示对大型语言模型的翻译性能有重大影响，如我们在一个简单的实验中所看到的，其中我们使用了一种一-shot提示，并为每个句子提供了两个不同的提示。观察到的差异超过了一个BLEURT点，极端情况下甚至可以达到40个BLEURT点。因此，选择一个好的提示策略非常重要。在我们的实验中，我们选择了五-shot提示策略，其中我们为系统提供的每个句子都标记了原始语言。在本例中，我们将德语句子（源句子）标记为德语冒号，将英语翻译标记为英语冒号。我们发现实际提示的形式在几个短提示的情况下并没有太大的影响。对于零和一-shot提示来说，这一点尤其重要。然而，当我们像我们的案例一样进行五-shot提示时，形式几乎没有任何区别。承载大部分重量的是示例。我们实验结果的总结是，示例的质量比形式更重要。因此，选择高质量的翻译作为提示非常重要。特别是，我们将比较从WMT评估中使用训练数据进行提示与使用开发数据的情况。开发数据比训练数据更经过精心筛选，质量更高，但存在更多的噪音。他们的结果显示，当使用开发数据时，性能更好。然而，专门的最先进的系统在PaLM翻译中具有显著的优势。在我们的案例中，我们选择使用Google Translate进行评估。我们从人类评估中获得的见解来自MQM框架，显示PaLM的流畅度与最先进的系统相当，但主要差异在于准确性。最常见的错误是遗漏错误。看起来PaLM倾向于通过省略源句子的一部分来生成听起来更好的翻译，有时是为了提供更流畅的翻译。然而，“风格/笨拙”类别中的PaLM得分低于最先进的系统，这是另一个信号，表明PaLM提供了流畅的输出，但仍然存在一些准确性的问题。这就是全部内容。如果您想了解更多信息，请参加论文的完整演示。谢谢大家。</sample>
    <sample id="240">好的，以下是翻译结果：

你好，我是Saarland大学的博士生Dawei。在这次会议上，我将介绍我们最近的工作“弱监督学习：对弱监督学习的批判性审视”。这是与Xiaoyu Shen、Marius Mosbach、Andreas Stephan和Dietrich Klakow合作完成的。首先，我想简要介绍一下弱监督和弱监督学习。在弱监督中，我们不手动标注数据。相反，我们使用简单的启发式规则、知识库或低质量的众包来标注数据，如右边的图所示。与人工注释相比，弱标注要便宜得多，但它们也是嘈杂的，这意味着一定数量的注释是错误的。如果我们在弱标注数据上直接训练神经网络，神经网络往往会记住标签噪声，而不能很好地泛化。在弱监督学习中，提出了训练算法来在这样的标签噪声下稳健地训练神经网络，以便训练模型仍然能够很好地泛化。在最近的弱监督学习（WSL）工作中，一个常见的说法是，人们只在弱标注数据上训练模型，并在干净的测试集上取得高精度。从技术上讲，这个说法没有错，但有一个陷阱，即人们假设有一个额外的干净验证集可用于模型选择。我们不能忽视这个问题设置，但它意味着在弱监督学习中需要额外的手动注释。然而，这个问题经常被忽视。我们提出了三个研究问题：首先，在弱监督学习中是否需要干净的验证数据，或者我们可以使用嘈杂的验证数据代替？其次，如果需要干净的数据，或者弱监督学习才能发挥作用，那么我们需要多少干净样本？最后，我们应该只使用干净样本进行验证，还是有更好的方法可以利用它们？我们解决了这些问题，并且我们的发现如下：首先，我们发现，有趣的是，最近的WSL方法实际上确实需要干净的验证样本才能正常工作。如果没有干净的验证样本，则训练模型无法超越原始的弱标签，这意味着训练是徒劳的。这表明WSL方法实际上需要干净的标注数据才能正常工作，获取干净标注数据的成本不应被忽视。我们的第二个发现是，增加干净验证样本的数量有助于WSL方法实现更好的性能，如左图所示。通常，我们只需要每个类别20个样本就能达到高精度。但这还不是全部故事，因为如果我们决定获取干净样本，直接在干净数据上进行微调甚至会获得更好的性能。右图显示了干净微调方法与仅用于验证的WSL方法之间的性能差异。正如我们所看到的，如果有10个类别样本，直接微调开始超过WSL方法。最后，以前WSL方法声称的性能改进可以通过允许继续在干净样本上进行微调轻松实现。从图中可以看出，原始模型，称为FTw，最初在性能上不如更复杂的WSL方法，如COSINE。然而，如果允许继续在干净样本上进行微调，则FTw与其它方法表现相当。因此，在实践中，没有必要选择更复杂且计算时间更长、磁盘空间更大的WSL方法。总之，我们展示了最近的WSL方法实际上需要干净、手动标注的样本才能正常工作。它们的性能优势和实用性被大大夸大了。我们对未来的具体建议如下：首先，报告模型选择标准。例如，报告是否使用干净验证样本进行模型选择。第二，WSL方法应与少量-shot学习基线进行比较，因为两者都使用干净样本。第三，连续微调是一个简单而强大的基线，应该在未来的WSL工作中考虑。最后，我们已经开源了我们的代码。您可以扫描此幻灯片上的二维码查看。请随意查看。谢谢，祝会议愉快。</sample>
    <sample id="241">The paper "Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments" discusses the deficiencies in current misinformation detection systems and proposes a new evaluation framework. These systems often fail due to unrealistic evaluations, such as using retrospectively constructed datasets or leaking counter-evidence that is only available after claims have been debunked publicly. Additionally, these methods are not human-centric, either completely excluding humans from the process or relegating them to final determination steps.

To address these issues, the authors propose an end-to-end system that integrates human feedback throughout the process. This system takes raw tweets on Twitter as input and outputs actionable outputs used by humans. It includes two main components: claim detection and policy violation verification. The first component uses keyword filtering and a T5 model trained for question answering to extract check-worthy claims about potential COVID-19 treatments. Claims are then ranked based on their trendiness before being provided to humans for verification. The second component employs a BERT-based stance classification model to determine if a tweet supports unapproved treatment policies.

The study evaluates the efficacy of this workflow through early detection metrics, operationalized as detecting unapproved treatments before they appear in debunking news articles annotated by humans. Results show that 65% of detected violations were confirmed by humans with scores of four or five out of five. The computer metric indicates that 124.2 policy violations can be detected per hour worked by one human. Overall, the proposed framework aims to provide a more realistic assessment of the interplay between automated systems and human content moderators in real-world scenarios.</sample>
    <sample id="242">对话系统的常用评估方法是通过人类评估者来选择哪段对话更好，或者对对话进行评分。</sample>
    <sample id="243">这篇论文有五位作者。</sample>
    <sample id="244">在 Servin 和 Kea 的示例中，需要背景知识来确定代词 "he" 所指的具体实体。背景知识包括 "Servin 是一名法官" 和 "法官在法院审理案件"。这些信息有助于理解上下文并正确地将代词 "he" 与正确的实体 "Servin" 进行关联。</sample>
    <sample id="245">The presentation discusses a study on finding high-agreement Amazon Mechanical Turk workers for summarization tasks. The researchers developed a two-step pipeline to identify these workers, which includes qualification settings and tasks. They found that the best practice is to use pre-task filtering with specific qualifications such as location, HITs, and HIT Approval Rate. The first stage of the qualification task tests annotators' ability to evaluate multiple dimensions correctly, while the second stage evaluates their capacity for handling heavy workload. The results show that only 6% of participants passed both stages, but they achieved high agreement in terms of inter-annotator agreement (IAA) compared to experts. Additionally, the reference-based task was designed to test general performance on true annotation tasks, resulting in an average Krippendorff's Alpha score of 0.534 across different groups. The baseline MTurk workers had lower scores due to incomplete HIT coverage and fewer workers per HIT, while CloudResearch MTurk workers showed similar quality at a higher cost. The analysis also revealed significant Spearman's correlation between Pipeline and CloudResearch workers regarding correctness. In conclusion, this method can avoid resource waste by identifying high-quality workers efficiently and serves as a best practice for large-scale annotations at low cost. Future research will explore ways to hire even more qualified workers and apply this approach to various applications, languages, and platforms.</sample>
    <sample id="246">代码是公开的，可以在GitHub上获取。</sample>
    <sample id="247">Jiho Kim介绍了一项名为"FACTKG: Fact Verification via Reasoning on Knowledge Graphs"的研究。这项研究提出了一种新的任务，即基于知识图谱的事实验证。知识图谱是一种可靠的知识来源，因为它可以直接连接到自然语言的断言，从而实现可靠的推理。此外，它还可以用于实际应用，例如现代对话系统与内部知识图谱的交互。为了支持这一任务，他们提出了一个名为FactKG的新数据集，该数据集使用DBpedia作为知识图谱，并包含两种断言风格：书面和口语。数据集中有两个标签：支持和反驳。任务包括从DBpedia中检索证据并使用证据验证断言。他们使用了五种推理类型：一跳、连结、存在、多跳和否定。为了使数据集更实用，他们使用了两种方法将断言转换为口语风格，并创建了假设模板。他们的实验结果表明，利用知识图谱证据的GEAR模型在所有基线中表现最佳。</sample>
    <sample id="248">NLPositionality的注释者在各个人口统计学特征（即国家/地区、性别等）方面并不均衡。</sample>
    <sample id="249">为了扰乱句子，我们对可接受的句子进行了几种不同的扰动。这些扰动包括： 1. 词序变化：打乱句子中单词的顺序，同时保持语法结构。 2. 词性变化：将一个词的词性更改为另一个词性，同时保持句子的语法结构。 3. 代词替换：用代词替换句子中的名词或代词，同时保持语法结构。 4. 动词时态变化：将一个动词的时态更改为另一个时态，同时保持句子的语法结构。 5. 介词变化：将一个介词更改为另一个介词，同时保持句子的语法结构。 6. 名词复数变化：将一个名词变为复数形式，同时保持句子的语法结构。 7. 从句类型变化：将一个从句更改为另一种从句类型，同时保持句子的语法结构。 8. 省略主语：省略句子中的主语，同时保持语法结构。 9. 省略宾语：省略句子中的宾语，同时保持语法结构。 10. 省略谓语：省略句子中的谓语，同时保持语法结构。 通过进行这些扰动，我们观察到模型在不同情况下对可接受句子的MPP判断保持一致。这表明模型对输入句子中的潜在句法和语义特征敏感，并且当前的MPP评估方式可能无法捕捉到模型在整个上下文窗口中的抽象知识。</sample>
    <sample id="250">维度评估是一种全面覆盖聊天模型行为的方法，这些行为可能会影响聊天质量。</sample>
    <sample id="251">这篇论文的作者所属机构是University of Science and Technology of China。</sample>
    <sample id="252">The presentation introduces a new benchmark dataset, the Indian Legal Prior Case Retrieval (IL-PCR) Dataset, and an unsupervised learning-based approach called U-CREAT for prior case retrieval in legal documents. The IL-PCR Dataset consists of 7,070 legal cases with an average of 6.775 citations per query document, providing a comprehensive test bed for evaluating PCR algorithms. The U-CREAT pipeline leverages event extraction techniques to identify relevant events from both query and candidate documents without requiring law or demographic-specific tuning.

The process begins by representing each legal document as a collection of events using dependency parsing with spacing. This involves examining verb categories within sentences to form subject-verb-object triplets that represent individual events. These extracted events are then used to compute interaction matrices between query and candidate documents, which serve as input for various retrieval models such as BM25, BERT, DistilBERT, InCaseLawBERT, InLegalBERT, Atomic Events model, Non-Atomic Events model, and Event Filtered Documents model.

Experimental results demonstrate that the U-CREAT method significantly outperforms other methods on the PCR task, particularly when compared to baseline approaches like BM25. It achieves higher F1 scores while maintaining lower inference times across different datasets, including the COLIEE’21 data set. Overall, these contributions highlight the effectiveness of the proposed approach and open up opportunities for further research into improving prior case retrieval systems in the context of legal documentation.</sample>
    <sample id="253">The presentation introduces a study titled "DisorBERT: A Double Domain Adaptation Model for Detecting Signs of Mental Disorders in Social Media." The researchers, from Mexico and Spain, aim to develop an automated method using social media posts to detect mental health disorders. They focus on the challenge of insufficient annotated data by adapting BERT, a language model trained with general text from Wikipedia and Google Books, to analyze Reddit content related to mental health.

The approach involves integrating information specific to Reddit and mental health into the pre-trained BERT model while incorporating knowledge from a lexicon to guide the masking process during training. This strategy allows the model to learn domain-specific tasks more effectively.

The results show that DisorBERT outperforms other baseline models in terms of precision and recall when analyzing eRisk datasets. Examples illustrate how DisorBERT focuses on words associated with mental health issues compared to BERT's more general predictions. Visualization tools reveal significant attention towards relevant topics like anxiety and medication use among users discussing depression.

Future work includes exploring different lexical resources and applying clinical data to further enhance the detection capabilities of their model.</sample>
    <sample id="254">The research work titled "Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction" was presented by Sun Qi from Nanjing University of Science and Technology. The presentation focused on the challenge of noise in document-level relation extraction, particularly when using distantly supervised data to pretrain models.

The traditional approach relies heavily on human-annotated corpora, which are time-consuming and labor-intensive. Recent methods have leveraged distantly supervised data but still face issues with noise due to false-positive pseudo labels. These errors can introduce extra relations or lose correct ones, as illustrated in a specific example provided during the presentation.

To address this problem, the researchers proposed an uncertainty-guided label denoising framework aimed at improving the quality of DS (distantly supervised) data. Their method involves training a pre-denoising DocRE model with both DS and annotated data to generate pseudo labels. However, recognizing that these labels may contain inaccuracies, they introduced an uncertainty estimation mechanism to determine the reliability of each prediction.

The team further developed instance-level uncertainty estimation techniques tailored for overlapping relations—a common issue not adequately addressed by previous approaches. They also designed dynamic class uncertainty thresholds to filter out high-uncertainty pseudo labels and replaced them with lower-uncertainty versions derived from DS data.

To optimize the use of DS information, they implemented a multi-phase training strategy involving iterative re-labeling based on their refined uncertainty scores. This comprehensive methodology significantly enhanced performance compared to existing baselines across public datasets.

In summary, the key contributions included:
1. A novel framework combining uncertainty guided label denoising.
2. An innovative instance-level uncertainty estimation technique for handling overlapping relations.
3. A practical solution for managing long-tail classes through dynamic class uncertainty thresholds.
4. Enhanced overall performance metrics demonstrated via comparative analysis against prior works.

This detailed exploration highlighted how integrating advanced uncertainty management strategies could substantially improve the robustness and accuracy of document-level distant relation extraction systems.</sample>
    <sample id="255">提示的形式在几个短提示的情况下很重要。</sample>
    <sample id="257">Four state-of-the-art chat models</sample>
    <sample id="258">The speaker, Chiang Cheng-Han, introduces a new work titled "Can Large Language Models Be an Alternative to Human Evaluation?" The study proposes using large language models (LLMs) for evaluating the quality of text in natural language processing tasks. They suggest instructing LLMs with specific instructions and providing them with samples that need evaluation.

Chiang Cheng-Han explains how their idea was novel at the time of submission since there were no prior works exploring this concept. He highlights the drawbacks of human evaluations such as instability and difficulty in reproducibility. To address these issues, they propose leveraging LLM capabilities due to their ability to understand natural language text instructions.

To validate the effectiveness of LLM-based evaluation, experiments are conducted where both GPT-2-generated stories and those written by humans are rated based on four attributes: grammar, coherence, likability, and relevance. Instructions similar to those used in human evaluations guide the ratings process through LLM outputs. For comparison, ground-truth ratings from English teachers who evaluate essays provide benchmarks against which results can be assessed.

The experiment uses four different LLMs—T0, InstructGPT (curie and davinci), and ChatGPT—to compare outcomes. Results show that while some smaller LLMs do not demonstrate significant preference between generated and human-written texts, larger ones like Davinci and ChatGPT exhibit clear preferences towards human-written content over AI-generated material.

Chiang Cheng-Han concludes his presentation by addressing potential questions regarding agreement among individual story ratings within LLM evaluations versus human assessments, effects of changing instruction wordings or sampling methods, benefits vs costs compared to traditional human evaluations, and performance across other tasks involving LLMs. These aspects are elaborated upon in detail throughout the paper itself.</sample>
    <sample id="259">The speaker introduces their work on cross-lingual semantic parsing in multiple natural languages and meaning representations. They highlight the challenges of existing models, which are limited to specific tasks and languages. To address this, they propose XSemPLR, a unified dataset that includes 9 datasets across various domains, 5 semantic parsing tasks, 8 meaning representations, and 22 natural languages from 15 language families. The benchmark is evaluated using six settings: Translate-Test, Monolingual Model, Monolingual Few-shot setting, Multilingual Model, Cross-lingual Zero-shot transfer, and Cross-lingual Few-shot transfer.

The study evaluates two groups of models: Encoder-PTR (Multilingual Pretrained Encoders with Pointer-based Decoders) such as XLM-R + PTR and mBERT + PTR, and Encoder-Decoder models like mBART and mT5. Results show that Encoder-Decoder models outperform Encoder-PTR models by training in a mixture of different languages. However, English performance drops significantly in seven datasets while improving in three others, indicating the "Curse of Multilinguality." 

The study also examines the cross-language performance gap between zero-shot and few-shot transfers. It finds that zero-shot transfer has a significant gap compared to monolingual settings, but this gap narrows rapidly when employing few-shot techniques. Additionally, pretraining on English improves few-shot results for target languages, suggesting that multilingual language models like Codex and BLOOM may not be sufficient for cross-lingual semantic parsing tasks.

In summary, the presentation introduces XSemPLR as a comprehensive benchmark for evaluating cross-lingual semantic parsing capabilities across diverse languages and meanings. The findings indicate that Encoder-Decoder models generally perform better than Encoder-PTR models, especially when trained in mixed languages. Furthermore, the research highlights the importance of considering both zero-shot and few-shot approaches for reducing the cross-lingual performance gap.</sample>
    <sample id="260">This paper has three authors.</sample>
    <sample id="261">优秀规划器的理想品质是能够生成合理且忠实于约束的脚本。</sample>
    <sample id="262">There are four authors of this paper.</sample>
    <sample id="263">In this work, we aim to address the problems of label biases in in-context learning within the context of text classification. We start with a typology of label biases and based on which we're able to identify a new important type of bias, domain-label bias. To confirm that the task corpus can actually bias the model's predictions, we conduct experiments where we give the model some random words and ask the model's preference for each label name. We find that seeing random in-domain words from the task corpus severely biases the model's predictions, but seeing random English words does not show such a preference. This suggests that language models perform differently depending on whether they see random in-domain or out-of-domain words.</sample>
    <sample id="264">The speaker introduces their paper titled "TAVT: Towards Transferable Audio-Visual Text Generation". They explain that while uni-modal text generation tasks have flourished due to large-scale pre-training and huge model capacity, multimodal text generation tasks like audio-visual text generation face challenges in data annotation and varying construction conditions. To address these issues, they propose a novel task called Transferable Audio-Visual Text Generation (TAVT), which aims to train a model capable of adapting quickly to new multimodal domains with limited labeled data.

The framework presented by the speaker consists of three components:

1. **Audio-Visual Meta-Mapper Network**: This component maps different visual concepts across domains into a unified auditory semantic space, addressing shifts in the semantic distribution.
2. **Audio-Visual Encoder and Language Model Generator**: The transformer-based encoder and generator introduce an alpha to evaluate the contribution of different modalities to each word at time step t. Alpha-t is computed based on cross-attention relevance between modality-specific attention and previous words.
3. **Dual Counterfactual Contrastive Learning (DCLL)**: This method constructs fine-grained supervision signals from counterfactual results to optimize visual-textual alignment without relying on random negative samples.

The training details include using a meta-learning approach similar to MAML; during meta-training, K – 1 specific domains are selected as support sets, and one domain serves as the query set for evaluating adaptation performance.

The experimental section involves building two benchmarks based on MSVD and MSR-VTT datasets, including cross-datasets and cross-domain settings. Results show that TAVT outperforms all compared models significantly on both types of evaluations. Ablation experiments demonstrate that removing certain features does not affect overall performance, indicating robustness against feature variations.

In conclusion, the proposed TAVT demonstrates superior transferability and adaptability in audio-visual text generation tasks when compared to existing methods.</sample>
    <sample id="265">演讲者的名字是Vasudha。</sample>
    <sample id="266">这篇论文的作者所属机构是华沙大学。</sample>
    <sample id="268">PaLM 最常见的错误是省略错误。</sample>
    <sample id="269">你好，我是詹姆斯·芬奇。我是莎拉·芬奇。今天我们将向您介绍ABC-Eval，一种新的维度方法来评估对话AI。这项工作是由埃默里大学的Choi教授领导的Emory NLP实验室和亚马逊Alexa AI合作完成的。假设你已经开发了一个对话模型，并且你想看看它与当前最先进的模型相比如何。常见的做法是使用人类评估，例如要求人类裁判员选择哪个对话更好，或者给对话打一个等级评分。这些方法在提供整体对话质量方面效果很好，但对话质量有很多方面。因此，你可能想要评估对话质量的多个维度，以了解模型在更精细的层次上的优势和劣势。一种方法是简单地要求人类裁判员评估对话质量的多个方面，例如使用现有的比较或等级评分方法对模型响应进行相关性评估。然而，我们相信有一种更精确和可靠的方法来进行维度对话评估。我们的方法试图通过明确标注每个聊天模型响应是否表达某些行为来减少人类评估的主观性，例如响应不相关的信息或自相矛盾。我们称之为聊天行为标注或ABC-Eval的简称。我们开发了这种方法来全面覆盖最近文献中建议影响聊天质量的各种主题错误。ABC-Eval能够测量聊天模型在各种方面犯错的频率。例如，ABC-Eval测量模型忽略其伴侣的次数、说无关信息、自相矛盾或其伴侣、胡言乱语或违反常识知识的次数，以及模型成功或失败于展示同理心的次数。为了确定哪种评估方法最有效，我们选择了四个最先进的聊天模型，并使用ABC-Eval评估了它们在100个人-机器人对话中的表现。作为比较，我们还使用三种现有方法评估了这些对话：在回合级别上使用等级评分，在对话级别上使用等级评分，以及在回合级别上进行对话级两两比较。对于每个现有的方法，我们收集了八个最常见的测量方面对话的评价，因为这是评估聊天模型沿多个维度的标准实践。在分析这些评价结果后，我们发现ABC-Eval行为标签总体上比现有方法收集的标签更可靠，如通过100个双标注对话计算的注释者间一致性所示。此外，ABC-Eval标签比现有方法产生的指标更准确地预测对话质量，如简单的线性回归分析所示。例如，你可以看到测量回合内与自己和伴侣矛盾的次数解释了5%和10%的对话质量，而平均的等级一致性分数只解释了4%或更少。最后，我们检查了每个评价指标是否捕捉到独特的对话质量方面，使用逐步线性回归。你可以看到所有ABC-Eval指标的组合解释了超过25%的对话质量，随着每次移除一个指标，大多数都会失去相当多的质量信息。另一方面，所有回合级等级指标的组合解释了更少的质量，而且更少的指标携带独特的信息。可靠的、有信息量的、独特的ABC-Eval指标使我们能够以以前的方法无法实现的更高分辨率来评估对话AI。你可以在实验结果中看到几个挑战仍然存在，并且已经被精确量化。例如，我们测试的机器人在大约20%的响应中出现常识错误。它们在大约15%的响应中产生无关信息，并且在大约10%的响应中自相矛盾或其伴侣。随着领域发展速度的加快，这些错误率在新模型发布时可能会有所下降。然而，这正是原因所在，即追求可靠和精确的评估指标来比较模型。我们希望ABC-Eval可以被领域内的其他人利用，作为有意义的一步，朝着这个方向前进。我们期待着看到在未来的几个月和几年中，对话AI将如何发展。感谢观看。</sample>
    <sample id="270">Emory University</sample>
    <sample id="271">在本文中，CFT代表“Fine-Tuning”。</sample>
    <sample id="272">这篇论文有7位作者。</sample>
    <sample id="273">你好，我的名字是凯奥·尹，我将要介绍我们合作完成的作品《翻译何时需要上下文？一种数据驱动的多语言探索》。这项工作是由帕特里克·芬南德斯、艾米莉·刘、安德烈·F·T·马丁斯和格雷厄姆·纽比格共同完成的。许多翻译都依赖于上下文。例如，在这个句子中，“间谍”这个词会是什么意思呢？如果上一个句子是“如果部长们发现事情可能会变得危险”，那么“间谍”指的是间谍。但如果上一个句子是“医生，这可能有什么严重的事情吗？”，那么“间谍”指的是胎记。因此，上下文的不同会导致词义的变化，相应的翻译也会随之变化。然而，评估模型如何处理这些情况是很困难的。首先，因为只有很小一部分翻译依赖于上下文，所以基于语料库的指标如BLEU无法捕捉到这些翻译。有些人建议针对上下文依赖翻译进行有目标的评估，但这些资源只支持有限类型的上下文依赖翻译，并且仅限于有限的语言，因为它们通常依赖于领域知识和人工编译。在本工作中，我们试图回答这两个问题：首先，什么时候翻译需要上下文？其次，模型如何处理这些情况？为了回答第一个问题，我们开始测量翻译过程中单词对上下文的依赖程度。在之前的工作中，我们引入了CXMI作为衡量机器翻译模型上下文使用的一种方法。这是通过测量上下文C提供的关于目标Y的信息来实现的，给定源X。我们可以将CXMI视为提供给模型上下文信息的数量。在这项工作中，我们将CXMI扩展为点状CXMI，可以衡量上下文使用在句子级别或单词级别上的情况。我们可以将具有高P-CXMI的单词视为需要上下文进行翻译的单词。然后，我们分析具有高P-CXMI的单词以寻找模式，这些模式在这些单词之间存在。我们对14种不同语言的TED演讲的翻译进行分析，这些翻译是从英语翻译成的。我们对翻译进行三个级别的分析。首先，我们查看具有高平均P-CXMI的部分词性标记。这使我们能够找到阿拉伯语中的相对较高的P-CXMI的双重代词，因为英语中没有双重代词，因此需要上下文来确定代词是双重还是单数。同样，我们发现某些语言在翻译动词形式时也需要上下文。然后，我们查看具有高P-CXMI的词汇项目，该项目平均适用于其所有出现。这帮助我们识别出像中文这样需要上下文才能确保文档内使用相同翻译的词汇项目。同样，我们发现上下文对于翻译适当的形式也是重要的。最后，我们查看具有高P-CXMI的单个标记。这使我们能够识别那些不能由单词本身捕获的现象，而是由句子结构表达的现象，例如省略句的解决。然后，我们使用我们的发现来构建一个用于文档级翻译的基准。对于我们识别的五种话语现象中的每一个，我们创建标记器自动识别与现象相关的单词。我们称这个标记器为多语言话语感知标记器（MuDA）。然后，我们可以注意到不同的语言在这些话语现象的比例上有所不同。然后，我们使用MuDA标记器在我们想要用于评估的平行语料库上应用标记器，并使用我们选择的翻译指标对MuDA标记器识别的上下文依赖示例进行评估。最后，我们使用我们的基准以及其它指标来评估不同模型在文档级机器翻译上的表现。首先，当使用基于语料库的指标时：对于BLEU，我们发现上下文无关模型的表现最好。但是，如果使用COMET，则上下文相关模型表现最佳。如果使用单词f-度量，则带有和不带上下文的模型具有可比的性能。这再次表明，仅使用基于语料库的指标很难确定文档级翻译系统表现最好的情况。然后，我们使用我们的基准来评估模型，并发现上下文相关模型在形式性和连贯性等某些话语现象方面比不使用上下文的模型表现更好。但是，这些模型在其他现象如省略、代词和动词形式方面并没有比不使用上下文的模型表现得更好。这表明我们需要在这些现象上看到更多的进展，以实现文档级翻译。我们还将不同的商业系统进行了比较，并发现DeepL通常在文档级翻译中比Google Translate表现更好。总之，我们在14种不同语言对中进行了一项数据驱动的分析，以确定翻译何时需要上下文，并使用我们的发现构建了一个用于文档级机器翻译的基准，这可以帮助我们了解模型在哪些话语现象上表现良好或不好，以及哪些翻译系统在文档级翻译中表现良好。谢谢大家的聆听。祝你在多伦多好运！</sample>
    <sample id="274">演讲者的名字是Yusen Zhang。</sample>
    <sample id="276">Ananya和Vignesh的研究关注于评估机器翻译指标在印度语言中的有效性。他们使用了来自Flores数据集的200个句子，并通过七个不同的翻译模型或API生成多个候选翻译。然后，他们使用双语专家注释员对每个翻译输出进行详细评估，标记错误类型、严重程度以及整体得分。研究发现，COMET-metric变体在所有语言中具有最高的总体相关性，而许多指标的分数范围狭窄，使得解释它们的分数变得困难。为了进一步改进这些指标，他们使用他们的MQM数据集对最佳性能的指标COMET进行了微调。结果表明，IndicCOMET在三个语言中优于COMET基线，并且在ACES翻译准确性挑战集上具有更高的鲁棒性。</sample>
    <sample id="277">该方法没有名称。</sample>
    <sample id="278">作者描述了“显性词汇”(marked words) 方法，该方法利用社会语言学概念“显性”，即存在一个默认的未标记状态，任何与这个默认状态不同的群体都是语言上被标记的。例如，“战士”通常与男性相关联，当描述一位女性战士时，人们会使用“女性战士”来标记术语。主导群体在社会和语言上都是未标记的，而边缘化群体通常是被标记的。在他们的方法中，他们首先确定未标记和标记的群体，并然后使用“Fightin’ Words”方法比较人物，通过使用加权对数比值来区分每个标记群体的顶级单词。</sample>
    <sample id="279">The authors of this paper are affiliated with the University of Washington.</sample>
    <sample id="280">Shi Tao presented his work "MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations". He discussed the challenges of emotion regulation in conversations, such as exploiting multimodal information complementarity and addressing difficulties with minority emotions. To solve these issues, he proposed MultiEMO, which includes a novel visual feature extractor (VisExtNet), a multimodal fusion model called MultiAttn, and Sample-Weighted Focal Contrastive Loss to improve performance on MELD and IEMOCAP datasets.</sample>
    <sample id="281">Kayo Yin在TED上介绍了他们的研究，探讨了翻译是否需要上下文。他们使用了一个名为CXMI的指标来衡量机器翻译模型在翻译中使用上下文的程度。通过分析TED演讲的翻译，他们发现某些语言在翻译时确实需要上下文，例如阿拉伯语中的代词和中文中的名词。他们还开发了一个名为MuDA的标签器，用于识别翻译中需要上下文的特定语言现象。他们使用MuDA标签器评估了不同的翻译系统，并发现上下文感知的模型在处理某些语言现象（如形式和词汇连贯性）方面表现更好。然而，在其他现象（如省略、代词和动词形式）上，上下文感知的模型表现并不明显优于不使用上下文的模型。他们得出结论，使用MuDA标签器可以帮助确定哪种翻译系统最适合文档级翻译。</sample>
    <sample id="282">The work presented at ACL 2023, "StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing", addresses the challenge of non-parallel text style transfer. Most previous studies have focused on token or sentence-level transfers like sentiment or formality changes. This research advances by transferring styles story-level and discourse level, which is essential for imitating author style. The primary challenges include imitating linguistic choices related to discourse structures in long texts and dealing with content-specific writing topics that are difficult to transfer across different styles. To tackle these issues, a new model named StoryTrans was proposed. It learns discourse representations from source texts using learnable style embeddings to generate target-style texts. A novel training objective reduces stylistic features derived from different texts while enhancing content preservation through two-stage generation. Experimental results show that StoryTrans outperforms strong baselines in terms of style control and content preservation, as evidenced by automatic evaluation scores and manual evaluations. Style visualization also indicates alignment between transferred test outputs and golden texts in the style feature space. Additionally, comparisons highlight how StyleLM inserts unrelated sentences, whereas StoryTrans supplements short phrases or plots to enrich narratives and maintain main contents. Finally, it can rewrite most sentences with targeted styles while preserving original semantics.</sample>
    <sample id="283">第一个提到的对称依存关系结构是“Lisa, Bart和Maggie”。</sample>
    <sample id="284">The speaker, Peng Tianshuo from Wuhan University, presented his long paper titled "FSUIE: A Novel Fuzzy Span Mechanism for Enhancing Universal Information Extraction" at ACL's Main Conference 4,915. He discussed the limitations of current span-based UIE models that rely on precise boundary positions and proposed a novel fuzzy span mechanism to address this issue. The FSUIE model uses a continuous distribution of correct probability in a specific range to represent target boundaries as a fuzzy span loss. This approach improves universal information extraction by adaptingively adjusting attention spans based on prior hypotheses about limited span lengths. The results demonstrate significant performance improvements across various tasks such as named entity recognition, relationship extraction, and aspect sentiment triplet extraction.</sample>
    <sample id="285">The work "Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with Fine-grained Evaluation Framework" by Mingqi Gao from Peking University focuses on the evaluation of factual error correction (FEC) models in dialogue summarization. The study highlights two main types of solutions to address factual errors in summaries generated by models or reference summaries: introducing factuality-related objectives during training or inference, and designing FEC models that are independent of the summarization model.

The authors argue that previous FEC studies have flaws in their evaluation methods due to using vague overall scores provided by factuality metrics like FactCC and DAE. These metrics may not be reliable independently and can blur the line between content-based and form-based corrections. To overcome these issues, the researchers propose manually annotated reference corrections as a more comprehensive approach for evaluating FEC models' performance.

To classify factual errors effectively, they introduce a new taxonomy based on part-of-speech dependencies and operations such as addition, deletion, and substitution. Their proposed evaluation framework builds upon ERRANT, an existing metric for grammar error correction, consisting of alignment, classification, and comparison steps. Experiments conducted with various FEC models demonstrate that incorporating human-corrected data into FEC training significantly improves results compared to unreliable factuality metrics alone. However, current FEC models face challenges correcting certain types of factual errors, particularly those involving attribute, modality, link, and other complex errors.</sample>
    <sample id="286">演讲者的名字是James Finch和Sarah Finch。</sample>
    <sample id="287">这篇论文有四位作者。</sample>
    <sample id="288">BLiMP和SyntaxGym数据集可用于测试句法现象。</sample>
    <sample id="290">第一个研究问题的五种方法的缩写是WSL。</sample>
    <sample id="291">为了评估DrBERT，研究人员使用了11个生物医学和临床下游任务。这些任务包括命名实体识别、分类、词性标注和问答等。此外，他们还使用了六个基线模型进行比较：CamemBERT OSCAR 138 GB、CamemBERT OSCAR 4 GB、CamemBERT CCNET 4 GB、PubMedBERT、BioBERT和ClinicalBERT。</sample>
    <sample id="294">CamemBERT 最初是在 138 GB 的数据上训练的。</sample>
    <sample id="295">演讲者的名字是Adam Przepiórkowski。</sample>
    <sample id="296">The University of Turin and Amazon Alexa collaborated on a project called EPIC, which stands for English Perspectivist Irony Corpus. They collected data from social media platforms like Reddit and Twitter to study irony detection in natural language processing models. The dataset consists of 300 short conversations between pairs of texts, annotated by crowdsourcing platform Prolific with about 15 annotators per language variety. Despite differences among annotators regarding gender, age group, nationality, etc., the inter-annotator agreement varied significantly across these groups. To address this issue, they developed perspective-aware models that fine-tuned pre-trained language models using different splits of the datasets based on annotators' labels. These models showed less uncertainty compared to gold standard aggregated models. Upon further analysis, it was observed that generational similarities led to more disagreement over perceptions of irony, as well as geographical variations within the UK/Ireland region.</sample>
    <sample id="297">这段英文内容介绍了关于“从狗哨到扩音器：揭示编码修辞”的工作。作者通过分析历史上的美国政治演讲，展示了狗哨语在政治中的重要性，并探讨了它们如何被用于传达隐藏的信息和影响公众舆论。文章还讨论了狗哨语的类型、注册和人格，并提供了具体的例子来说明这些概念。此外，文章还研究了语言模型（如GPT-3）在识别和解释狗哨语方面的表现，以及它们如何可能绕过内容审查机制。</sample>
    <sample id="298">为了得出时间漂移是性能下降的主要原因的结论，我们进行了一个实验：重新训练或继续预训练一些模型，使用更近期的数据。我们发现，随着时间差距的增大，性能会降低。这证实了我们的假设，即性能下降的主要原因是时间漂移。</sample>
    <sample id="299">这篇论文介绍了在自然语言推理（NLI）模型中使用最小极大训练来提高鲁棒性的方法。作者认为，尽管NLI模型在各种基准测试中取得了最先进的结果，但它们的成功部分归因于学习和利用捷径，即输入属性与标签之间的虚假相关性。这些捷径使NLI模型在同分布样本上表现良好，但在测试时对离分布的对抗性测试集表现不佳，因为这些捷径在这些测试集中不适用。作者提出了一种最小极大训练方法，通过将注意力集中在困难的例子上，这些例子可能与捷径相矛盾，从而确保了良好的泛化性能。该方法使用一个最小极大训练目标，其中学习者试图最小化损失，而辅助模型则试图最大化学习者的损失。作者在MNLI、FEVER和QQP数据集以及相应的HANS Symmetric和PAWS离散测试集上评估了他们的方法，并发现它在保持高同分布准确率的同时，显著提高了离散测试集上的性能。</sample>
    <sample id="300">The task of interactive dictation involves users using their voice to both dictate and edit a document in a natural and intuitive manner. This was work done at Semantic Machines in collaboration with Jason Eisner, Adam Pauls, and Sam Thomson. The user starts by dictating, ""Just wanted to ask about the event on the 23rd."" This is transcribed verbatim into the text box. However, in the middle of speaking, the user realizes they made a mistake and corrects themselves, saying, ""on Friday the 23rd."" Ideally, the system can pick up that this was a speech correction and replace the correct span with a new utterance. Next, the user continues transcription, saying ""Is the event still on?"" which gets transcribed into the text box. Finally, the user can issue a verbal command like ""Replace 'the event’ in the last sentence with 'it'."" The system can identify the correct occurrence of ""the event"" to replace with ""it."" While speech-to-text systems are starting to proliferate, most of them support only dictation and do not support invoking edits through vocal commands. There are a few softwares that do recognize vocal edit commands, such as Nuance Dragon NaturallySpeaking, and the Microsoft Word Dictate function. However, these systems can be unintuitive because they require memorizing a fixed set of template commands. We know that a more natural and intuitive interface is possible when dictating to a human assistant. Even without agreed-upon trigger words or commands, humans can generally tell when you're commanding versus when you're dictating, and what command you're invoking. Thus, distinct from prior work, the interactive dictation task is characterized by the following key features. First, flexible interleaving of dictation and editing, not separated by a trigger word. Second, using intuitive and open-ended natural language utterances to specify edits. In summary, our contribution is threefold. First, we introduce and formalize a new task, interactive dictation. Second, we design a data collection interface and build a dataset for this task. And finally, we create a baseline system for this task. To begin, we formalize the task of interactive dictation as a four-step procedure. In the first step, an ASR recognition module parses raw audio into a speech transcript. Next, the speech transcript is segmented into separate dictation and command utterances. Third, each command is extracted and normalized. The ASR miss detections and speech errors are fixed. Finally, each dictation and command utterance is executed in sequence until we arrive at the final document state. Note that in a real system, this all happens in real time as the user is speaking. Since this is a new task, we need to collect our own data, for which we design a new interface. So I'm going to transcribe the following email. I'm going to start by clicking ""Begin Transcription""...</sample>
    <sample id="302">为了确保输出序列中的词元排列正确，有必要对它们进行排列。在神经序列到序列模型中，模型需要预测输入和输出之间的对应关系。虽然模型已经确定了输入序列中每个词元将出现在输出序列中的哪个位置，但这些词元的顺序可能不正确。通过使用排列模型来预测正确的顺序，模型可以生成与输入和输出之间的预期对应关系相匹配的输出序列。这有助于提高模型在处理复杂结构和递归情况时的准确性和连贯性。</sample>
    <sample id="303">作者建议模型所有者应提高偏见缓解方法的透明度，因为这可以澄清正面刻板印象和本质化叙事背后的原因。例如，这些正面刻板印象可能是由于过度的价值对齐或反刻板印象机制的结果，但没有更多的透明度，很难确定确切的原因。提高透明度将有助于更好地理解这些模式，并采取适当的措施来解决它们。</sample>
    <sample id="304">最小对不可接受输入是指在最小对中，不可接受的句子被选择出来，并且它与可接受的句子共享相同的语法结构。这种选择有助于评估语言模型在更长的上下文窗口中的接受度。通过将不可接受的句子作为前缀添加到可接受的句子中，可以模拟更长的上下文序列，并观察模型在不同上下文长度下的表现。这种方法有助于理解模型如何处理和解释复杂的语境依赖性。</sample>
    <sample id="305">Dawei在Saarland University介绍了他们的最新工作"Weaker Than You Think: A Critical Look at Weakly Supervised Learning"。这项研究与Xiaoyu Shen、Marius Mosbach、Andreas Stephan和Dietrich Klakow合作完成。Dawei首先解释了弱监督的概念，即使用简单的启发式规则、知识库或低质量的众包来标记数据，而不是手动标注。然而，这些弱标签是嘈杂的，不准确，可能导致神经网络在训练时记住标签噪声，无法很好地泛化。为了解决这个问题，提出了弱监督学习（WSL）中的训练算法，以在嘈杂标签下稳健地训练神经网络，并确保它们仍然能够很好地泛化。Dawei强调了WSL中使用干净验证集的重要性，指出这通常是被忽视的问题。他们提出了三个研究问题：1.是否需要干净的验证数据进行WSL，还是可以使用嘈杂的验证集？2.如果需要干净的数据，那么我们需要多少干净样本？3.我们只使用干净样本进行验证，还是有更好的利用方式？Dawei的研究结果表明，WSL方法实际上需要干净的标注数据才能正常工作，获得干净验证样本的成本不应被忽视。他们的发现还表明，增加干净验证样本的数量有助于WSL方法实现更好的性能，但直接在干净数据上进行微调通常会带来更好的结果。最后，他们建议未来的工作应报告模型选择标准，比较WSL方法与少量-shot学习基准，并考虑连续微调作为简单而强大的基线。</sample>
    <sample id="306">Sebastian Schuster和Najoung Kim在ACL会议上介绍了他们关于大型语言模型实体跟踪能力的研究。他们设计了一个任务，通过描述盒子中的初始内容和执行操作来测试语言模型的实体状态跟踪能力。实验结果表明，只有GPT-3.5模型能够正确跟踪实体状态，而其他模型则无法做到这一点。他们发现，预训练代码是GPT-3.5模型表现出这种能力的原因。此外，他们还发现，较小的模型如T5-base可以通过直接微调来学习实体跟踪，但随机初始化的模型则不能。然而，他们不确定这些能力是否能推广到他们的设置之外。</sample>
    <sample id="307">作者使用了以下评估指标： Named entity recognition, classification, part-of-speech tagging, and question answering.</sample>
    <sample id="308">Jenny, a Carnegie Mellon University PhD student, presented her work on NLPositionality, which characterizes design biases in datasets and models. She used the Prospective API for toxicity detection as an example to illustrate how certain populations might be overlooked by technology due to positionality. Jenny's research explores whether datasets and models have their own form of positionality, influenced by the perspectives of NLP researchers and developers. To study this, she re-annotated data sets with diverse annotators from 87 countries using Lab in the Wild, comparing these annotations with existing datasets like Social Chemistry and Dynahate, along with various AI models including GPT 4. Her findings indicate that there is indeed positionality in NLP technologies; they are most aligned with English-speaking countries and individuals who hold college or graduate degrees. However, some groups such as non-binary people may still be left behind. Jenny recommends keeping records of all relevant design choices throughout the research process, conducting NLP research through the lens of perspectivism, and developing specialized datasets and models within specific communities.</sample>
    <sample id="309">使用了100个双标注的对话来衡量注释者之间的一致性。</sample>
    <sample id="310">在不可接受和可接受查询中，选择一个完全无关的领域来添加句子。</sample>
    <sample id="311">The authors of this paper are affiliated with the University of Trier.</sample>
    <sample id="312">MultiInstruct是第一个大型的多模态指令调优基准，它包括62个不同的多模态任务，涵盖了10个广泛的类别。这些任务是从21个现有的开源数据集中提取的，并且每个任务都配备了五个专家撰写的说明。此外，MultiInstruct还解决了NLP和多模态之间指令数据集可用性差异的问题，因为NLP有超过1600个语言特定的指令任务，而没有公开可用的大型多模态指令任务。</sample>
    <sample id="313">这篇论文有两位作者。</sample>
    <sample id="314">二进制协调的定义是：两个元素之间的连接，例如“Lisa, Bart和Maggie”。</sample>
    <sample id="315">提示语的平均长度是15个单词。</sample>
    <sample id="316">这些发现表明，较小的 T5 模型在适当的微调下可以超过较大的语言模型。这表明，当使用适合的训练数据集时，较小的模型可以表现出与较大模型相当甚至更好的性能。</sample>
    <sample id="317">Peng Li from Fudan University presented their work titled "CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors". The presentation focused on the task of information extraction, which involves extracting structured data from unstructured text. Previous models used pre-trained language models like T5 and GPT-3 for this purpose but faced challenges in aligning outputs due to mismatched formats during inference. To address this issue, CodeIE was proposed as a solution that transforms the text-to-structured information extraction into a structure-to-structure code generation task using large code language models like Codex. The method involved designing prompts with functions and comments to extract named entities or relations from input texts. Evaluations were conducted on three recognition datasets and four relation extraction datasets, comparing traditional text-style prompts against code-style prompts. Results showed significant improvements when using code format prompts over text format prompts, especially regarding recall performance.</sample>
    <sample id="318">自2018年以来，BERT已成为自然语言处理任务中最有效的方法之一，并且与Word2vec、fastText等历史静态和上下文方法相比，取得了巨大的性能提升。此后，该模型已被改编为多种其他语言，如法语的CamemBERT，以及在生物医学领域的PubMedBERT和BioBERT，以及在临床领域的ClinicalBERT，但大多数都是基于英语。对于其他语言的专用模型来说，数量很少，通常是通过持续预训练来实现，由于缺乏特定领域的数据。然而，在法语中还没有开源的生物医学模型。因此，我们问自己，最合适的数据源是什么，而这些从网上爬取的数据是否是临床数据的良好替代品？为了回答这个问题，我们将DrBERT与我们的ChuBERT模型进行比较，该模型基于从Nantes大学医院数据仓库中获得的匿名数据。然后，我们问自己，我们需要多少数据才能训练一个专门针对法国数据的模型？是4GB，8GB还是更多？为了回答这个问题，我们首先训练并比较了四个从头开始的模型：DrBERT的第一个版本，使用7GB的NACHOS；第二个版本，使用4GB的NACHOS的子集；ChuBERT的第一个版本，这是一个临床模型，包含来自临床笔记的4GB句子；以及最后的ChuBERT版本，混合了4GB的NACHOS子集和4GB的临床笔记。此外，我们还引入了三个基于CamemBERT权重和标记化器的持续预训练模型，以分析预训练策略的影响。一个基于CamemBERT权重，训练在4GB的NACHOS子集上；另一个也基于CamemBERT，但训练在4GB的临床笔记上；最后一个基于英语生物医学模型PubMedBERT，训练在4GB的NACHOS子集上。总共有七个模型。为了评估我们的七个模型，我们收集了公共和私人下游任务的数据，例如命名实体识别、分类、词性标注和问答。这些模型被与六个基线模型进行比较，包括CamemBERT OSCAR 138 GB、CamemBERT OSCAR 4 GB、CamemBERT CCNET 4 GB、PubMedBERT、BioBERT和ClinicalBERT。评估结果显示，模型在具有相同性质的数据上表现最佳。然而，我们观察到来自不同来源的数据似乎更具灵活性。我们还观察到，使用更多的数据会带来更好的性能。总体而言，从头开始的预训练似乎在大多数任务上都获得了更高的性能。然而，我们的实验表明，使用CamemBERT权重和标记化器训练的模型在稳定性方面存在问题。最后，正如结论所示，我们的正确系统在九个中的11个下游任务中表现更好，并超越了通用模型，即CamemBERT。我们还观察到，更专业的数据更好，但它并不扩展。所有由NACHOS预训练的模型均免费提供在Hugging Face上，并遵循MIT许可证，所有训练脚本均可在我们的GitHub存储库上找到。因此，感谢您参加本次演示，并期待在多伦多的海报展示期间与大家交流。</sample>
    <sample id="319">论文研究了以下学习策略： 1. 从头开始训练模型，使用4GB的NACHOS数据集。 2. 从头开始训练模型，使用4GB的临床数据集。 3. 使用CamemBERT的权重和标记化进行持续预训练，使用4GB的NACHOS数据集。 4. 使用CamemBERT的权重和标记化进行持续预训练，使用4GB的临床数据集。 5. 基于PubMedBERT的英语生物医学模型，并使用4GB的NACHOS数据集进行持续预训练。</sample>
    <sample id="320">由于测试重复使用而导致的过拟合因素不大。</sample>
    <sample id="321">To evaluate the quality of text simplification, we can use a method called MASSalign. This involves fine-tuning language models to produce simplified versions of complex input texts and comparing them with manually aligned sentences from our DEPLAIN corpus. The results show that this approach could achieve better scores than baseline methods, making it a promising benchmark for future research on automatic text simplification in German.</sample>
    <sample id="322">Enrico将介绍他的研究，探讨语言模型如何理解文本中的道德概念。他将解释道德的主观性，并讨论道德基础理论作为理解人类道德的工具。Enrico还将展示他们的研究结果，包括使用Moral Foundation Twitter Corpus的数据集以及他们开发的方法来分析语言模型对不同领域中道德表达的理解。</sample>
    <sample id="323">The paper introduces a new method called DHLK for Commonsense QA, which combines language models and knowledge bases to retrieve relevant information. The authors propose an HKG based on multiple knowledge bases that is optimized through a two-stage pruning strategy and KRL. They also use RoBERTa and Mask Self-Attention to encode the subgraph and text, removing entities with weaker relevance to the question context using attention weights from RoBERTa. The proposed method outperforms other methods in terms of accuracy and F1 score on CommonsenseQA and OpenBookQA datasets.</sample>
    <sample id="324">是的，语言模型确实有不同的政治偏见。研究表明，语言模型在政治倾向上有所不同，它们分布在政治光谱的四个象限中。例如，GPT-4是最自由的语言模型，而GPT系列通常比BART系列及其变体更社会自由。此外，通过进一步预训练语言模型检查点在不同的党派语料库上，可以观察到语言模型的政治偏见也相应地发生了变化。例如，对于在左倾Reddit语料库上进一步预训练的RoBERTa，其政治偏见出现了显著的自由主义转变。</sample>
    <sample id="325">好的，我来给你介绍一下我们关于“不使用树的多集标记和潜排列进行组成性泛化”的论文。这是我和我的导师Alexander Koller和Ivan Titov一起完成的。组成性泛化可以理解为模型能够处理深层递归并生成在训练期间单独看到的短语的深层组合。在语义解析的背景下，测试组成性泛化可能看起来像这样。就像平常一样，我们有一个训练集的句子。在这种情况下，“女孩睡觉了。”和“玛丽知道女孩睡觉了。”这些句子与逻辑形式配对，代表它们意义的核心方面。与标准机器学习评估不同的是，测试集并不来自相同的分布，而是包含结构上未见过的逻辑形式。在这个例子中，模型在训练期间看到了浅层递归，并被测试了一个带有深层递归的示例。简单地序列到序列模型在这种情况下的外推一般会遇到困难，并且经常产生与输入脱节的输出。一种流行的方法是将树集成到模型中。树旨在捕捉组成过程，将句子与逻辑形式相关联。这很有用，但树通常不是给定的，需要以某种方式获得。这可能很复杂，有时计算成本也很高。通常，这涉及特定形式的预处理逻辑形式，例如处理变量符号。获得树也可能需要专门的语法诱导程序。在这篇论文中，我们没有使用树，并引入了一个直接从输入到输出建模对应关系的神经序列到序列模型。我们首次展示了在不依赖于树的情况下对深层递归具有很强的一般化能力。我们的方法分为两个步骤预测输出。首先，我们将每个输入令牌标记为将出现在输出中的令牌的无序集合。在第一步之后，我们有了所有的正确令牌，但它们没有顺序。这就是为什么在第二步中，我们使用另一个模型来预测将它们放入正确顺序的排列。我们介绍了一种新的预测排列的方法，它没有对可能的排列施加任何严格的限制。这使得我们的方法非常灵活和表达性强。概念上，我们的排列模型大致如下工作。我们从左到右遍历输出，并确定要放在输出中的哪个多集令牌。为了第一个输出位置，我们简单地选择一个，如红色突出显示。然后我们跳到另一个多集令牌，以确定输出中的第二个令牌。我们通过类似的方式继续这个过程，直到每个令牌从第一阶段恰好被访问一次。为了给你一些实验结果的提示，这里我们比较了我们的方法与其他无树模型在COGS基准上的表现。我们的模型在深层递归的一般化方面比其他模型高出一大截。还有一些其他类型的结构一般化仍然非常具有挑战性。在我们的论文中，我们解决了几个有趣的挑战。首先，输入和输出之间的对齐在训练数据中并没有给出。因此，对于给定的令牌，我们不知道它来自哪个多集，这构成了一个挑战，用于训练。此外，有时存在多个与数据一致的排列，但语言上更合适的排列是潜在的。我们通过将对齐作为训练的一部分来解决这个问题。我们的排列方法非常灵活，但它带来了挑战，因为找到最高得分的排列是NP难的。这是因为这与“旅行商”问题有关。我们通过GPU友好的连续松弛来近似这一点，这也允许我们通过解决方案进行反向传播并学习更有可能的语言排列。如果您想了解我们的实验以及如何解决这些挑战，请查看我们的论文或来到我们的海报。</sample>
    <sample id="326">认知失调是两种信念或行动不一致的情况，例如一个人说“我知道吸烟可能会杀死我”，然后在会议上抽了几根烟。这种信念和行动是不一致的，它们之间存在认知失调。</sample>
    <sample id="327">Xiao Xu介绍了一项关于Vision-Language学习的研究，该研究提出了一种名为ManagerTower的新架构。ManagerTower通过引入管理者来收集和组合不同层次的预训练单模专家知识，从而实现更全面的跨模态对齐和融合。实验结果表明，ManagerTower在各种下游任务中表现优于其他基线模型，并且在使用相同预训练和微调设置的情况下，其性能显著提高。</sample>
    <sample id="328">GPT-4是最倾向于自由派的语言模型。</sample>
    <sample id="329">该研究提出了一种基于结构化伪标签生成的零-shot视频句子定位方法，以抵抗标签噪声。通过使用图像文本预训练模型生成更复杂的自由形式伪查询，并根据事件的时间结构生成伪事件，从而保证了视频内部事件与查询之间的高相关性，以及视频外部事件与查询之间的低相关性。此外，通过估计标签噪声并减少噪声样本的贡献，进一步提高了模型的性能。实验结果表明，该方法在两个数据集上优于其他零-shot方法。</sample>
    <sample id="330">是的，在主动学习时，累积训练比迭代训练更有效。</sample>
    <sample id="331">演讲者的名字是Sara Papi。</sample>
    <sample id="332">MuDA benchmark中的数据来自TED演讲的翻译。</sample>
    <sample id="333">The work "INK: Injecting kNN Knowledge in Nearest Neighbor Machine Translation" focuses on enhancing the generalization and performance of neural machine translation (NMT) models. The authors acknowledge that NMT often induces a non-smooth representation space, leading to poor adaptation capabilities. To address this issue, they propose an approach called INK, which injects knowledge from nearest neighbors into the model's representation space.

The core idea behind INK is to smooth predictions by adjusting them based on nearest neighbors in the representation space. This requires constructing a key-value data store during training, where representations are saved along with their corresponding target tokens. At each decoding step, the NMT model queries the data store for nearby entries and refines prediction probabilities accordingly.

However, two significant drawbacks arise from this method:
1. Retrieving neighbors from a large datastore at every decoding step can be time-consuming.
2. Once the datastore is constructed, it becomes challenging to update the representations efficiently.

To overcome these limitations, the authors introduce the INK framework, which aims to inject kNN knowledge directly into the MT system without relying heavily on the datastore or requiring frequent updates. Their proposed training loop consists of two steps:

1. Extract kNN knowledge from the datastore to guide the adapter in adjusting the representation.
2. Use updated representations to refresh the datastore asynchronously until convergence.

The INK framework uses three types of representations adjusted via KL-divergence:
- Align contextualized representation and token embeddings to preserve semantic meaning.
- Align contextualized representations and kNN token embeddings to enrich semantic meanings.
- Adjust contextualized representations of the same target token to handle sparsely dispersing problems.

By optimizing the adapter with a combined learning objective, the authors run this training loop iteratively until convergence. In practice, after completing the training loop, the datastore can be discarded.

In experiments conducted using the WMT’19 German-English news translation task winner as the off-the-shelf NMT model, the authors observe improvements even when applying only minor adjustments to the representation space. They explore several research questions through various experiments:
1. Can we effectively smooth the representation space with a small adapter while discarding the datastore during inference?
2. How much improvement does utilizing kNN knowledge bring regarding refinement of the representation distribution?
3. Does combining an adapter and datastore further enhance smoothing?

Results show that the INK system outperforms state-of-the-art kNN-MT systems, achieving higher BLEU scores and better overall translation performance with less memory usage and faster inference speed compared to other methods.</sample>
    <sample id="335">演讲者的名字是Matthias Lindemann。</sample>
    <sample id="336">Cross-lingual transfer refers to the process of transferring knowledge or skills from one language to another. In this context, it involves training a model on data in one language and then using that trained model to make predictions or generate outputs for other languages. This approach can be particularly useful when there is limited data available for certain target languages, as it allows models to leverage their performance on more abundant source languages. Cross-lingual transfer aims to improve generalization capabilities by learning patterns across multiple languages, which can lead to better performance even with fewer resources dedicated to each individual language.</sample>
    <sample id="337">The research presented in this speech focuses on handling out-of-vocabulary (OOV) words, which are critical to the performance of embedding-based downstream models. The approach developed by the researchers leverages word formation and association to infer the meaning of OOV words. They introduce a Word Relationship Graph that imitates lexical rules for word formation and association. When an OOV word appears, it is tokenized into wordpieces and associated with relevant words naturally, forming a two-level graph around the OOV word.

Each node in the group acts as either a word or a wordpiece, with its corresponding word embedding serving as the node attribution. To preserve all nodes in the first layer and retain complete wordpiece information, they sample a fixed number of nodes for training from the second layer to mitigate noise caused by numerous neighbors. A self-attention network assigns attributes based on the characters of the OOV words to overcome challenges related to assigning node attributes to OOV nodes.

To extract important information and reduce the impact of noisy neighbor nodes, they apply two levels of Graph Attention Network, concatenating them and fusing initial input with hidden embeddings of each layer to result in a node-level representation. Additionally, a readout block layer captures whole graph information and summarizes word formation. For capturing the entire vector space of the background embedding model, contrastive learning is applied using NT-XENT positive samples from the graph, such as two-hop relevant neighbor words, synonyms, or the OOV word itself.

Experiments demonstrate that their model's performance surpasses baselines in both intrinsic and extrinsic tasks, proving the effectiveness of learning OOV words through word formation. Moreover, the model can bring benefits to both static and contextual models in downstream tasks. Regarding adding languages to their model, agglutinative languages like English perform well due to reasonable word segmentation, while fusional languages present more challenges but still show promising results when applying simple one-layer Graph Convolutional Networks.</sample>
    <sample id="338">Bingsheng介绍了一项研究，探讨了人类自然语言解释的质量评估问题。他指出，虽然许多研究人员依赖人类来注释标签和解释以训练模型，但如何系统地比较这些解释的质量是一个挑战。传统的BLEU和ROUGE等指标主要关注词相似性，而Simulatability Score则考虑了模型在有解释和无解释情况下的表现变化。然而，这些方法忽略了任务差异和解释在不同阶段（如微调和推理）中的不同作用。

为了应对这一挑战，Bingsheng和他的团队提出了一种统一的数据格式，将各种任务转化为一个统一的多项选择任务。他们使用了五个大型数据集：CoS-E和ECQA用于常识问答任务，e-SNLI用于自然语言推断，以及ComVE用于常识验证。通过对比基线设置和带有解释的输入设置，他们发现，即使人类注释的解释质量较低，它们仍然可以对模型预测产生积极影响。

基于这些观察，他们提出了一个新的评估指标TREU（Task-Related Explainability Utilization），该指标不仅评估了解释在推理过程中的帮助性，还评估了解释在微调阶段对模型性能的影响。通过在两个模型T5和BART上对五个数据集进行评估，他们的结果表明，TREU比Simulatability Score更能准确反映人类注释解释的质量。此外，他们还观察到不同任务和解释格式对解释有用性的不同影响，这支持了他们关于任务和解释格式对解释有用性影响的假设。</sample>
    <sample id="339">Saarland University in Germany</sample>
    <sample id="340">Kuan-Hao Huang presented a work titled "ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation" at UCLA. The goal of the research was to create a large-scale, syntactically diverse paraphrase dataset for training NLP models. They proposed using AMR (Abstract Meaning Representations) graphs and back-translation techniques to generate these paraphrases. By leveraging pre-trained AMR parsers and modifying graph structures, they created ParaAMR with around 15 million source sentences and approximately 6.9 paraphrases per sentence. The dataset showed higher syntactic diversity scores compared to other datasets while maintaining similar semantic similarity scores. ParaAMR demonstrated benefits in various applications such as learning sentence embeddings, syntactic control paraphrase generation, and data augmentation for few-shot learning.</sample>
    <sample id="341">作者使用了平均延迟和计算感知平均延迟作为延迟测量方法。</sample>
    <sample id="342">The presentation introduces LiveChat, a large-scale personalized dialogue dataset constructed from live streaming videos. The authors explain the importance of constructing such datasets to capture real spoken conversations and address challenges in existing video-sourced dialogue datasets. They propose an automatic matching method for extracting dialogues based on reply-to relationships among speakers. The paper also highlights the significance of developing applications like virtual streamers and employees through research on personalized dialogue.

The authors describe their three-step process: 1) collecting origin streaming videos from Chinese TikTok (Douyin), transcribing audio into utterances using ASR, and gathering audience comments; 2) constructing dialogues by applying a reply-to-whom matching method; and 3) collecting persona information for personalized dialogue generation via manual labeling, scratching basic profiles, and using rules and trained classifiers for additional personas.

Comparisons with other open-domain dialogue datasets show that LiveChat is larger, has more personal annotations, and longer average sessions per persona. Experiments demonstrate that selected persona profiles and session lengths benefit response modeling tasks, while single-stream BERT outperforms double-stream BERT in addressee recognition. Pre-trained models like BART perform better than others due to domain differences between LiveChat and existing datasets. In-context learning experiments reveal performance improvements as demonstrations increase but slight decreases when exceeding eight shots due to random noise introduced by manual selection.

In conclusion, LiveChat offers valuable insights for understanding speaker responses and improving transfer learning of LLMs tailored to this unique dataset.</sample>
    <sample id="343">Hello everyone, I'm Akshatha, and today my co-author Martin and I are presenting our work "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources." This work is a collaboration between McGill University, Mila, and Microsoft Research. Natural language understanding models draw on a variety of knowledge sources, such as knowledge contained in their parameters, usually acquired by a pretraining, and knowledge given in inputs at inference time. Recent works in tasks like question answering show that models can use pretrained-time knowledge to solve the task. But natural language understanding often requires knowledge that is also supplied at inference time. For example, in the sentence, "John saw the newly elected president on TV." Pretrained parameters can contain information about what presidents do and what a TV is but they cannot reliably know who this instance-specific entity "John" is, or who the new president is, because the president might have changed since pretraining. Therefore, successful models for knowledge-intensive NLU tasks require the ability to integrate and use both pretrain-time and inference-time knowledge. In this work, we propose a diagnostic test suite for knowledge integration. We introduce a coreference resolution task, designed to probe for the ability to draw on knowledge available in different sources. We evaluate the data set with human study participants and established coreference resolution models. Here is an example from our data set. Servin is a judge. Kea is a Baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. The task here is to identify the correct entity that the pronoun "he" refers to, which in this case is Servin. The resolution of a given pronoun requires two types of information. First, entity-specific knowledge such as "Servin is a judge." And second, background knowledge such as "Judges decide cases in law courts." Generally, background knowledge is learned during the pretraining of large language models, while entity-specific knowledge is typically observed at inference time. We vary the availability of these two pieces of information such that it may either be found in a single source, or in multiple sources. We have defined three settings of KITMUS. First, we have the typical setting: "Background-Pretrain", where background knowledge is assumed to be available at pretrain time. Second, there's a "Background-Both" setting, where background knowledge is available both at pretrain time and inference time. Lastly, the "Background-Inference" setting, where both knowledge types are available only at inference time. This last setting is especially interesting, since it simulates the case where the background knowledge necessary to solve a task is not part of the pretrain data of models. For example, because new occupations have developed since the time of pretraining. Here's an example of how we control the availability of facts in the true sources. In the Background-Pretrain setting, we assume that the background knowledge "Politicians seek elected seats in government" is contained in the pretrained parameters and in inference-time context we provide the entity-specific knowledge "Chichester is a politician." In the Background-Both setting, we additionally provide not only entity-specific but also background knowledge about politicians in their inference-time context. In the Background-Inference setting, we provide the fictional occupation "mirituer" instead of politician because "mirituer" is unlikely to be contained in the pretrained parameters. We evaluate the data set both with human study participants, and established coreference resolution models. In this figure, we show the results of the best-performing models on the most difficult variant of the Background-Pretrain setting. Without task-specific training on KITMUS, both models do not perform well. When trained on KITMUS, however, both C2F and BERT4Coref perform significantly better than the random choice. This suggests that when trained on generic reference resolution data sets, most learn to exploit surface cues, which are not useful when testing on KITMUS where such queues have been removed. Additional experiments with fictional knowledge indicated even the best performing models, cannot reliably integrate backward knowledge presented only at inference time. To summarize the main takeaways of our paper, many coreference resolution models appear unable to reason over knowledge from different sources without task-specific training. However, with task-specific training, some models successfully integrate knowledge from multiple sources. Still, even the best-performing models seem to have difficulties with reliably integrating backward knowledge provided only at inference time. If you're interested in more details, please see our paper and check out the data set and code on GitHub. Thanks for listening.</sample>
    <sample id="344">基于树的方法需要获得树，这通常是一个复杂和计算昂贵的过程。它通常涉及对逻辑形式进行大量的形式特定预处理，例如处理变量符号，并可能涉及专门的语法诱导过程。此外，树通常不是给定的，需要通过某种方式获得，这可能很复杂且计算成本高。</sample>
    <sample id="345">Compositional generalization can be understood as the ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training. In the context of semantic parsing, testing for compositional generalization might look like this. As usual, we have a training set of utterances. In this case, "The girl slept." And "Mary knew that the girl slept." These utterances are paired with logical forms that represent core aspects of their meaning. In contrast to standard machine learning evaluation, the test set does not come from the same distribution but contains structurally unseen logical forms. In this example, the model has seen shallow recursion during training and is tested on an example with deeper recursion. Naive seq2seq models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input. A popular method to address this is to integrate trees into the models. The trees are intended to capture the compositional process that relates utterances with the logical forms. This works well, but trees are usually not given and need to be obtained somehow. This can be complicated and sometimes a computationally expensive process. Typically, this involves considerable formalism-specific pre-processing of the logical forms, for example, to handle variable symbols. Obtaining trees may also involve specialized grammar-induction procedures. In this paper, we don't use trees and introduce a neural seq2seq model that directly models the correspondences between fragments of the input and fragments of the output. For the first time, we show strong generalization to deeper recursion without relying on trees. Our approach predicts the output from the input in two steps. First, we tag each input token with an unordered multiset of tokens that will appear in the output. After the first step, we have all the right tokens, but they're not ordered. That's why in the second step we use another model to predict a permutation to put them into the right order. We introduce a new method to predict the permutation that does not put any hard constraints on the possible permutations. This makes our approach quite flexible and expressive. Conceptually, our permutation model works roughly like this. We go from left to right over the output and determine which multiset token to put in every position. For the first output position, we simply select one, as highlighted in red. Then we jump to the next multiset token, to determine the second token in the output. We determine the third token in the output in a similar way by jumping to another multiset token. We continue this process until every token from the first stage has been visited exactly once. To give you a teaser of the experimental results, here we compare our method with other treeless models on the COGS benchmark. Our model outperforms the others by a large margin on generalization to deeper recursion. Some other kinds of structural generalization remain very challenging, though. In our paper, we solve a couple of interesting technical challenges. First of all, the alignment between input and output is not given in the training data. As a consequence, for a given token we don't know which multiset it came from, which poses a challenge for training. In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is latent. We address this by inducing the alignment as part of the training. Our permutation method is very flexible, but it brings the challenge that finding the highest-scoring permutation is NP-hard. That's because this is related to the "Traveling Salesman" problem. We approximate this with a GPU-friendly continuous relaxation that also allows us to backpropagate through the solution and learn the linguistically more plausible permutations. If you want to learn more about our experiments and how we address these challenges, please have a look at our paper or come to our poster.</sample>
    <sample id="346">这篇论文的作者所属机构是清华大学。</sample>
    <sample id="347">大家好，我是Myra，今天我将为大家介绍我们的论文《标记的人格：使用自然语言提示来衡量语言模型中的刻板印象》。这篇论文是与Esin Durmus和Dan Jurafsky合作完成的。近年来，许多研究已经记录了大型语言模型（LLMs）中社会偏见和刻板印象的普遍存在。然而，这些方法存在一些局限性。它们通常依赖于耗时的手工构建数据集，并且通常只测量特定的刻板印象，这意味着它们在其他人口统计学或上下文中并不具有通用性，或者它们仅仅捕捉到与特定群体相关的广泛关联，例如对某些群体的负面关联。此外，大多数工作在这个领域中没有考虑交集性，即多面的社会身份可以相互叠加，成为特定的伤害地点。为了克服这些局限性，我们利用了这些新指令调优LLMs的一个特性，即它们非常擅长响应指示和提示。我们可以要求模型生成一个人格，即使用“想象一个亚洲女性。描述你自己。”这样的提示来描绘一个想象中的个体。这使得它非常通用，因为我们可以将任何想要的身份标记放入这个提示中。以下是一些GPT-4的示例生成结果。我们立即看到，虽然输出并不是传统意义上的负面或有毒，但其中有一些有趣的趋势。亚洲女性被描绘为谦逊；中东女性被描述为异国情调和迷人，指的是一个迷人的地区。同时，有色人种的两个女性角色都提到了祖先，而白人男性角色则没有任何这种提及。为了捕捉这些模式，我们的方法有两个部分。第一个部分是生成这些人格。我们生成人格的提示灵感来自一项研究，即给这些提示给人类受试者，发现通过给它给人类受试者，他们也能够揭示种族刻板印象。这也使我们能够直接比较我们生成的人格和人类撰写的回应。第二个部分是标记单词，这是一种识别区分标记群体和未标记群体的单词的方法，我稍后会详细解释。这种方法的好处在于，我们得到了具体的刻板印象和模式，而不必依赖任何特定的词汇表。标记单词方法基于社会语言学概念“标记”，即存在一个默认的未标记状态，任何与该默认状态不同的群体都是语言上标记的。例如，“战士”这个词通常与男性相关联。当人们描述一位女性战士时，他们会指定“女性战士”，并用“女性”标记该术语。更广泛地说，社会上的主导群体在语言和社交上都是未标记的，而边缘化群体通常是标记的。在我们的方法中，我们首先指定未标记和标记的群体是什么，然后使用战斗单词方法比较人格，该方法是使用加权对数比值来区分每个标记群体的顶级单词。例如，对于黑人女性的人格，我们将进行战斗单词分析，并将对数比值与白人人格和男性人格进行比较，因为它们是相应的未标记群体。现在我们来看看一些结果。首先，我们使用刻板印象词汇表，并发现生成的人格包含比人类撰写的人格更多的刻板印象。然而，当我们查看词汇和词汇表的分布时，我们发现非常不同的情况。生成的人格有更高的刻板印象词率，而人类撰写的人格则有更广泛的词汇分布，而刻板印象词主要只是“高大”和“健壮”。实际上，这个词汇表并没有很好地捕捉我们之前幻灯片中看到的许多有害模式。相反，我们将转向我们的标记单词方法来展示这些看似积极的语言如何反映有害模式。在我们的分析中，我们揭示了这些看似积极的描述如何反映有害模式。首先，从我们的群体中，顶部的单词包括诸如“文化”、“传统”、“自豪”和“异国情调”，这些单词定义这些群体仅与其身份的关系，并将它们与其他群体区分开来。这种定义反映了这些群体长期以来遭受的歧视和排斥。此外，这些词语反映了这些群体中的许多常见套路，尤其是在有色人种女性中。例如，描述拉丁裔女性的词语包括“充满活力”和“丰满”、“曲线美”等，这些词语与热带主义的套路有关。对于亚洲女性，词语如“娇小”、“精致”和“丝绸般”等词语连接到一个长期存在的套路，即亚洲女性被过度性化，被视为非常顺从和温顺。对于黑人女性，我们看到一些顶部的词语是“坚强”和“坚韧”。这与一种被称为“坚强黑人女性”原型的套路相连接。虽然乍一看似乎很积极，但已有研究表明，这种原型实际上是非常有害的，因为它给这些群体施加了很大的压力，要克服社会障碍。它不是致力于改变这些障碍，而是让这些群体承受巨大的压力，克服这些障碍，导致这些群体的健康结果不佳，以及其他危害。总体而言，我们发现每个标记群体的词语基本上反映了非常本质化的叙事。基于这些模式，我们提出以下三个建议供模型所有者参考。首先，作为研究人员，我们应该解决正面的刻板印象和本质化叙事。我们也应该使用交叉性视角来研究偏见和危害，因为如果不这样做，可能会忽略许多内容。最后，应增加关于偏见缓解方法的透明度，因为例如，这些正面的刻板印象可能是由于某种奇怪的过度价值对齐，或者可能是因为其他反刻板印象方法导致了这些有害模式，但我们无法做出假设或进一步研究，除非有更多透明度。谢谢大家的聆听，祝ACL玩得愉快！</sample>
    <sample id="348">这篇论文探讨了大型语言模型（LLMs）中社会偏见和刻板印象的普遍性问题。研究人员发现，现有的测量方法存在局限性，如依赖于耗时的手工构建数据集，并且通常只捕捉到特定的刻板印象，而没有很好地推广到其他人口统计学或情境。此外，大多数工作都没有考虑交集性，即多面的社会身份可以相互叠加并造成独特的伤害。为了解决这些限制，研究人员利用LLMs对指令和提示的响应能力，通过生成一个想象中的个体来创建“标记人物”，使用提示如“想象你是一个亚洲女性。描述你自己。”这种方法非常通用，可以应用于任何人口统计学。研究人员开发了一种名为“标记单词”的方法，通过比较标记和未标记群体之间的词语差异来识别特定的刻板印象和模式。他们发现，虽然生成的人物包含更多的刻板印象，但这些刻板印象主要集中在积极或非负面的词汇上。研究人员还揭示了这些看似积极的描绘如何反映有害的模式。他们发现，标记群体的词汇往往反映了刻板印象和本质化叙事，这可能导致有害的健康结果。基于这些发现，研究人员提出了三个建议：1. 研究人员应解决正面刻板印象和本质化叙事。2. 应该采用交叉性视角研究偏见和伤害，以避免遗漏。3. 增加关于偏见缓解方法的透明度，因为目前缺乏关于这些正面刻板印象是由于过度的价值对齐还是其他反刻板效应导致的了解。</sample>
    <sample id="349">你好，大家好，我是来自中国科学技术大学的Jingwei Yi。我很高兴给大家展示我们论文的一个简短广告视频。你是在复制我的模型吗？保护大型语言模型嵌入服务的版权。首先让我们介绍一下嵌入作为服务的背景。目前，像GPT、LLAMA和PALM这样的大型语言模型在自然语言理解和生成方面表现出色。嵌入作为服务是建立在大型语言模型之上的服务之一，以协助各种NLP任务。例如，OpenAI提供了一个基于GPT的嵌入API。然而，最近的研究表明，攻击者可以通过学习嵌入来窃取模型，并提供类似的服务。因此，保护嵌入作为服务的版权是必要的。为了保护嵌入作为服务的版权，一种解决方案是在提供服务中嵌入一个水印，并检测另一个服务是否包含水印。水印方法需要满足以下属性。首先，该方法应适用于嵌入作为服务。其次，水印不应降低提供的嵌入的实用性。第三，水印应足够隐蔽，以便攻击者或攻击者可以轻松地移除水印。最后，水印需要在模型提取过程中转移到攻击者的服务中。现有的工作可以大致分为四类。然而，这些方法要么不适用于嵌入作为服务，要么缺乏可转移性。因此，在本文中，我们提出了一种名为嵌入标记的后门基于水印方法，适用于嵌入作为服务。接下来，让我介绍我们嵌入标记的详细信息。嵌入标记包含两个主要步骤：水印注入和版权验证。在这些主要步骤之前，我们首先选择一个触发器集。触发器集是一组在中等频率间隔内的单词。我们假设提供者可以收集一个通用文本语料库，并使用它计算单词频率。在水印注入中，我们首先定义一个目标嵌入。当用户将句子发送到提供者服务时，提供者会计算句子中的触发词数。提供的嵌入是目标嵌入和原始嵌入的加权和。目标嵌入的权重与句子中的触发词数成正比。如果句子中的触发词数大于m，则提供的嵌入正好等于目标嵌入。版权验证是检测另一个服务背后模型是否包含水印。我们首先构建一个后门数据集和一个干净的数据集。后门数据集包含所有单词都属于触发器集的句子，而干净数据集中的所有单词都不属于触发器集。然后，提供者从窃取者的服务中请求这些数据集的嵌入。计算请求的嵌入与目标嵌入之间的余弦相似度和L2相似度。我们还计算干净数据集和后门数据集之间的相似度差异，定义为余弦差异和L2差异。同时，我们还应用KS检验并使用其p值作为第三个指标。我们在四个数据集AG News、MIND、SST2和Enron Spam上进行了实验。我们假设提供者使用维基文本数据集来计算单词频率。四个数据集的结果显示，我们的嵌入标记具有很好的检测性能，同时保持下游任务的良好实用性。我们还通过PCA可视化了句子在四个数据集上的嵌入。图例表示每个句子中的触发词数量。如图所示，很难区分后门嵌入和正常嵌入。这就是全部内容。谢谢。欢迎与我们讨论。</sample>
    <sample id="350">The presentation is about the paper titled "What’s the Meaning of Superhuman Performance in Today’s NLU?" by Simone Tedeschi and several other researchers from various institutions. The main focus of their research is to investigate how reliable leaderboard scores are when comparing models with human performance, particularly in popular benchmarks like SuperGLUE and SQuAD.

SuperGLUE consists of 10 tasks related to commonsense reasoning, entailment, reading comprehension, etc. In some of these tasks, humans' baseline performances were computed by the authors themselves, while for others, it was done by the creators of SuperGLUE. From the slide showing the SuperGLUE leaderboard, we can see that humans rank 8th overall and outperformed by systems on 6 out of 10 tasks. On average, the best system surpassed human performance by 1.5 points across all tasks. For example, in MultiRC, a task measuring reading comprehension, systems significantly outperformed humans (more than 10 exact match accuracy points).

Similarly, examining both versions of the SQuAD benchmark—reading comprehension datasets focused on question answering—we find that even though humans ranked 16th and 13th respectively, there are errors present which make direct comparisons unfair. These include differences between what systems and humans evaluate as well as inaccuracies or inconsistencies within the data itself.

In conclusion, this presentation highlights issues surrounding claims of superhuman performance in Natural Language Understanding due to factors such as differing evaluation sets, potential spurious correlations found only by machines but not humans, vague estimations made regarding human capabilities without clear standards, varying pay rates affecting quality assurance among annotators, lack of transparency around the pool used for annotation work, etc. They argue against making broad statements based solely on current benchmarks until addressing these concerns thoroughly.</sample>
    <sample id="351">The paper investigates the problem of generalization using the Named Entity Recognition Task (NER) and examines whether models developed in 2003 can generalize to modern data. The authors created a dataset called CoNLL++ by collecting news from Reuters in 2020 and annotating it with the same guidelines used for CoNLL-2003. They fine-tuned over 20 models on both datasets, evaluating their performance on CoNLL-03 test sets and CoNLL++. To assess model generalization, they calculated the percentage change in F1 score.

The study found that three main ingredients are needed for good generalization: 
1. Model architecture - transformer models generally perform better.
2. Model size - larger models tend to lead to better generalization.
3. Fine tuning examples - more training samples improve downstream task performance.

The researchers also explored two hypotheses regarding the causes of poor generalization:
1. Adaptive overfitting - where reusing the same test set leads to diminishing returns on new tests.
2. Temporal drift - degradation due to increasing temporal gaps between train and test data.

Experiments showed no evidence of adaptive overfitting but confirmed temporal drift as the primary cause of performance drop. Therefore, the answer is yes; CoNLL-2003 taggers still work well in 2023 when considering these factors.</sample>
    <sample id="352">ABC-Eval代表Annotating Behaviors in Chat。</sample>
    <sample id="353">The paper "Python Code Generation by Asking Clarification Questions" proposes a method to address the challenge of underspecification in code generation and program synthesis. The authors introduce interactivity into code generation, where clarifying operation-level specifications can alleviate this problem. They propose generating code by asking clarification questions, focusing on key operations that are missing or aligned with natural language descriptions (NLDs). To achieve this, they create CodeClarQA, a synthetic dataset with clarifications for key operations.

The process involves identifying key operations from code documentation using heuristics based on Graph4Code's knowledge graph. These operations are represented as schemas, which are then compared against NLDs to determine if there is information about these operations at any level mentioned above. If all element pairs have similarity scores lower than a threshold T, it indicates an alignment; otherwise, it suggests missing key operations.

To generate CQAs for missing key operations, templates are used, resulting in two types of questions: yes-or-no questions or multiple-choice questions. Annotators help validate the accuracy of these methods through validation sets and test sets.

The results show promising performance in identifying missing key operations, particularly when comparing MPNet's effectiveness over other models like BART and GPT-3. However, errors were also identified, such as taxonomy issues due to similar names between aligned operations and argument problems caused by using operational documentation instead of actual argument values.

The pipeline consists of three main components: a Clarification Need Predictor, a Question Selector, and a Code Generator. Experimental results indicate improvements in model performances across various evaluation metrics when more high-ranked CQs are included but still underperforming compared to training without additional data.

In conclusion, the study demonstrates how incorporating interactive elements like asking clarification questions enhances code generation quality while highlighting challenges faced during implementation.</sample>
    <sample id="354">CoNLL-2003 和 CoNLL++ 之间的性能增量在 2019 年之前高于 5 个百分点。</sample>
    <sample id="355">你好，我是Vasudha，是Stony Brook University计算机科学博士候选人。我想介绍我们在ACL 2023上接受的长篇论文，“通过迁移学习解决认知不和谐检测中的稀有类挑战”。“认知不和谐”是指两个信念或行动之间的不一致，例如，一个人说“我知道吸烟可能会要了我的命”，然后又说“会议后我抽了几支烟”。这种信念和行动之间存在不和谐关系，而这种关系被称为“和谐”。进一步提到“我觉得没有它们我无法维持工作”，这为第二次事件提供了正当化，形成了和谐关系。为什么这很重要？研究认知不和谐有助于我们理解人们之间的分歧，跟踪信仰价值的变化，以及对脆弱群体极端主义和极化趋势的理解。此外，认知不和谐也与焦虑障碍有关，有助于更好地理解人们的心理健康。研究语言中表达的认知不和谐也有助于了解个人的认知风格，并帮助我们更好地理解决策过程。为了创建一个认知不和谐资源，我们进行了大规模的注释，定义了不和谐关系。我们采用了“认知不和谐优先”的方法，如图所示。推特被传递给PDTB解析器，对话语单元对根据指南进行标注，如我们的论文所述。正如这里所示，只有3.5%的标注对存在不和谐关系。我们收集了大约1,000个对话单元对示例，用于训练初始分类器，该分类器仅在43个标注的不和谐样本上进行训练。令人惊讶的是，分类器的表现不如随机猜测好。考虑到不和谐的罕见性和缺乏任何先前的数据集，我们面临绝对罕见的问题。为了缓解这一问题，我们实验了结合迁移学习和主动学习的方法，以注释更多不和谐样本，降低整体注释成本，同时提高不和谐检测能力。由于初始模型无法捕捉到不和谐类别，我们开始主动学习过程，将权重从相关任务中转移。我们从两个不同的任务中转移：话题无关的不和谐立场分类，即确定两个不同人发表的不同辩论陈述是否在观点上一致或不一致，称为辩论，以及PDTB的二元分类，因为这两个任务与不和谐和和谐的概念密切相关，我们称之为CE。我们发现，即使在转移零射击性能，在注释数据集上也比随机猜测表现更好，AUC为0.62。进一步地，通过在辩论和CE任务上进行迭代微调，我们发现，CE任务的微调后，随后在辩论上的微调，零射击性能更好。因此，这是我们在冷启动主动学习中使用的模型。接下来，我们确定最佳方法来更新模型，以从每一轮主动注释和注释中获得新数据。 “累积”将所有迄今为止收集的注释数据累积起来，而“迭代”通过训练最新收集的数据集来更新模型。在不同的策略中，我们发现累积在所有情况下都优于迭代。接下来，为了增加不和谐的例子数量，我们使用了概率稀有类策略——PRC——来选择最有可能被当前模型降级的示例。我们将这种方法与其他社区中常用的最先进的主动学习策略进行了比较。我们发现，提出的PRC策略在性能上优于其他策略，尽管差异很小。值得注意的是，与随机猜测相比，其性能显著较低。在两轮最佳策略的主动学习中，我们提高了不和谐分类的AUC到0.75，这是迄今为止在任务中取得的最佳性能。我们还检查了每个策略的注释质量和成本对注释员的可行性。我们发现，PRC在罕见类中具有最高的百分比不和谐，并且对注释员来说更难。总之，我们发现PRC是一个简单的主动学习策略，用于稀有类获取，并且在适当设计的域外任务的转移学习和冷启动主动学习中非常有用。我们还发现，迭代更新在域内主动注释中很有用，而累积更新则更适合域内注释。</sample>
    <sample id="356">这篇论文的作者所属机构是亚利桑那州立大学。</sample>
    <sample id="357">演讲者的名字是Siyu Yuan。</sample>
    <sample id="358">这篇论文有五位作者。</sample>
    <sample id="359">该方法与专门针对同时翻译的架构进行了比较。</sample>
    <sample id="361">Armineh Nourbakhsh, a PhD student at Carnegie Mellon University and research director at JP Morgan AI Research team, presented her work titled "CounterComp" during the conference. The focus of this presentation was on using counterfactual scenarios to improve compositional generalization for multi-step quantitative reasoning in question answering tasks. Specifically, she discussed how neural models struggle with these tasks when outputs involve more than two steps due to memorizing spurious patterns. To address this issue, Armineh proposed mining counterfactual scenarios from training samples by treating them as anchors and creating positive and negative examples that reflect changes or interventions in questions without altering output operations significantly. These pairs were used to add an auxiliary metric learning loss to the model's training procedure, which improved performance across various state-of-the-art baselines, especially when dealing with multiple reasoning steps. Additionally, adding this CounterComp loss enhanced out-of-distribution sample performance, both within datasets (trained and tested) and between different datasets. Qualitative improvements included better attention towards meaningful tokens related to operational terms in the output. Key references include works cited in the poster, accessible through provided contact information.</sample>
  </task>
</testset>