<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Sprachmodelle werden hauptsächlich mit großen Web-Spiderdatenquellen wie der Common Crawl trainiert.</sample>
    <sample id="1">McGill University, Mila und Microsoft Research</sample>
    <sample id="2">Das Team von Ant Group hat ein Paper über visuell reiche Dokumententwicklung präsentiert. Das Paper konzentriert sich auf die Verständigung verschiedener Dokumente wie Formulare, Rechnungen und Plakate. Es gibt Probleme mit der globalen Leseordnung in der Dokumentenpräpration. Das Team hat eine neue Präpräntierungsmethode namens LayoutMask vorgestellt, die Text-Layout-Interaktionen verbessern soll. LayoutMask verwendet Text- und Layoutinformationen als Eingabe und bietet drei neue Maskierungsstrategien: Whole Word Masking und Layout-Aware Masking. Diese Strategien fördern die Text-Layout-Interaktionen und helfen dem Modell bei der Erlernung besserer Layoutdarstellungen.</sample>
    <sample id="3">Hallo, ich bin Regina Stodden und ich werde das erste Teil der Präsentation über DEPLAIN präsentieren. Textsimplifizierung ist ein Prozess, bei dem man einen Text anpasst, um ihn für eine bestimmte Zielgruppe zu verbessern, wie Menschen mit Leseschwierigkeiten oder nicht-native Sprecher. Um einen Textsimplifizierungsmodell zu trainieren, benötigen wir parallelisierte Paare von Texten, zum Beispiel Dokumente oder Sätze. Hier ist ein Beispiel einer parallelisierten Sättersatzpaarung: ein komplexer deutscher Satz und seine Übersetzung auf einfache Sprache. Um den Satz zu vereinfachen, können verschiedene Techniken eingesetzt werden, wie z.B. Substitution der Lese, Verwendung von Kürzelungen, Änderung der Struktur oder die Einfügung von Worten. Wir möchten nun unsere neue Korpus DEPLAIN präsentieren, da in den letzten Jahren einige Probleme mit den vorhandenen Korpora aufgetreten sind. Zum Beispiel sind diese Korpora zu klein, um ein Textsimplifizierungsmodell zu trainieren. Die drei vorgelegten Modelle in den letzten Jahren sind alle automatisch ausgerichtet, was bedeutet, dass sie möglicherweise fehlerhafte Ausrichtungen haben können. Deshalb möchten wir unsere neue Korpus DEPLAIN präsentieren, das in zwei Unterkorpora aufgeteilt ist: DEPLAIN-apa und DEPLAIN-web. DEPLAIN-apa basiert auf Nachrichtenartikeln und wurde 483 Dokumente manual ausgerichtet. Es gibt etwa 13.000 parallelisierte Sättersatzpaare. Bei DEPLAIN-web handelt es sich um verschiedene Bereiche und die 750 Dokumente wurden sowohl manual als auch mit automatischen Ausrichtungsverfahren ausgerichtet. Im Ganzen resultiert dies in 30.450 Sättersatzpaare. Wir haben unsere Sättersatzpaare etwas mehr untersucht, so zum Beispiel auf die Art der Simplifizierung. Wie Sie sehen können, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel Nachrichtenartikel oder Sprachlernunterlagen. Auf allen Niveaus, einschließlich des Substitutions der Lese, der Strukturvereinfachung und der Gesamt-Simplifizierungsebene, sind unsere DEPLAIN-Korporten sehr vielfältig. Und jetzt sehen wir, worauf wir dieses Korpus verwenden können. Hallo, ich bin Omar und ich werde die Anwendungsgebiete für unser Dataset DEPLAIN präsentieren. Der erste Einsatzfall ist die Bewertung automatischer Ausrichtungsverfahren. In den letzten Jahren wurden viele Ausrichtungsverfahren vorgestellt, aber im Kontext von Maschinensprachübersetzungen, wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir versuchen, Anschlagpunkte zwischen den Sätzen in beiden Dokumenten zu extrahieren. Aber in unserem Fall handelt es sich um die Ausrichtung von Sättern zwischen zwei parallelen Dokumenten, die denselben Sprache haben, denselben Inhalt haben, aber unterschiedliche Komplexität haben. Und jetzt, wenn wir unsere Korporten haben, die manuell ausgerichtet wurden, können wir diese Sättersatzpaare als Goldstandard-Ausrichtungen verwenden, um die vorgestellten Ausrichtungsverfahren zu bewerten. Wir haben einige Anpassungen an die vorgestellten Methoden gemacht und haben alle Anpassungen und Codes zur Ausführung unserer Experimente im Papier veröffentlicht. Am Ende konkluierten wir, dass das Ausrichtungsverfahren MASSalign das beste Automatische Ausrichtungsverfahren für die Vereinfachung von deutscher Sprache ist. Sie können auch den Code für die Ausführung dieser Methode auf Ihren eigenen Dokumenten finden im Papier. Der zweite Einsatzfall, den wir im Papier präsentiert haben, ist die automatische Textvereinfachung durch die Feinabgestimmung von Sprachmodellen, um komplexe Eingabeteilnehmer zu vereinfachten Texten zu produzieren. Wir haben zwei Modelle feinabgestimmt: wir haben das Modell long-mBART für Dokument-Level-Vereinfachung feinabgestimmt und das Modell mBART für Satell-Level-Vereinfachung. Sie können auch alle Checkpoints und weitere Details zu den Ergebnissen und den Bewertungsmetriken unserer Experimente im Papier finden. Wir haben erkannt, dass diese grundlegende Feinabstimmung die Basisschwellenwert für die Problemstellung der automatischen Textvereinfachung in Zukunft verbessern kann. Danke für Ihre Aufmerksamkeit und wir hoffen, Sie alle während des Konferenz zu treffen.</sample>
    <sample id="4">Kayo Yin</sample>
    <sample id="5">T5 XL</sample>
    <sample id="6">Das Team hat eine neue Methode für die Integration von Multilingüalen und Translingüalen Zusammenfassungen vorgestellt. Sie haben ein einheitliches Modell entwickelt, das in jeder Sprache auf eine Zusammenfassung generiert und in jeder anderen Sprache einen entsprechenden Auszug erstellt. Dies ermöglicht eine bessere Übersetzung von Wissen zwischen verschiedenen Sprachen. Sie haben auch eine vorherige Methode vorgestellt, die durch eine sorgfältig gestaltete drei-Schritt-Trainingsmethode verbessert wurde.</sample>
    <sample id="7">Ja, sie funktionieren noch.</sample>
    <sample id="8">ABC-Eval bietet eine genauerere und mehr fundierte Bewertungsmethode für Dialog-Modelle, indem sie die Anzeige von bestimmten Verhaltensweisen in Gesprächen durchführt.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Verfügbarkeit und Qualität eines sauberen Validationssets ab.</sample>
    <sample id="10">Zunächst einmal könnte die Qualität der Annotatoren und ihre Fähigkeit, die Kontexte korrekt zu verstehen, eine Rolle spielen. Zweitens könnte die Auswahl der Alternativefragen und die verwendeten Templates für diese Fragen verbessert werden, um eine bessere Abdeckung der möglichen Indirektbezeichnungen zu gewährleisten. Darüber hinaus könnte die Zugänglichkeit des Hintergrundwissens für die LLMs verbessert werden, indem sie Zugang zu mehr diversifizierten Quellen oder zur Verbesserung ihrer Fähigkeiten bei der Verarbeitung von unstrukturierten Informationen erhalten. Schließlich könnte die Größe und Vielfalt der Datenbank erhöht werden, um ein umfangreicheres Spektrum an Indirektbezeichnungen und Kontexten abzudecken.</sample>
    <sample id="11">Rechenaufgaben mit Humor-Verständnis-Tests wurden auf der New Yorker Caption Contest durchgeführt. Das Ergebnis zeigt eine erhebliche Leistungsschwäche von Rechenern im Vergleich zu menschlicher Leistung, insbesondere bei der Erklärung von Humor.</sample>
    <sample id="12">There are five authors involved in the work.</sample>
    <sample id="13">Daniel Rotem präsentiert seine Arbeit "Finding the SWEET Spot: Analysis and Improvement of Adaptive Inference in Low Resource Settings" im Hebrew University Jerusalem. Adaptive inference reduziert die Inferenzzeit von großen Sprachmodellen, indem sie auf die Komplexität der realen Daten abzielt und günstigere Modelle für einfache Fälle verwendet. Zwei häufige adaptive Inferenzmethoden sind Multi Model und Early Exit. Multi Model ist flexibler und leicht erweiterbar, aber teurer zu speichern und hat einen Overhead. Early Exit ist schneller bei der Inferenz und effizienter in Bezug auf Speicherplatz, aber kann durch konfliktierende Gradienten zu schlechter Leistung führen. Rotem präsentiert SWEET (Separating Weights in Early Exit Transformers), ein neues Fine-Tuning-Method für Early Exit-Architekturen, das das Problem der konfliktierenden Gradienten löst. Durch SWEET schließen die Individual-Layer den Gap zwischen Early Exit und Multi Model, während die Geschwindigkeit/Genauigkeit-Trade-off verbessert wird.</sample>
    <sample id="14">Die Abhängigkeitsstruktur der Koordination. Wie Sie mögen wissen, gibt es verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Korpusansätzen angenommen werden. Zum Beispiel in den universalen Abhängigkeiten wird die Struktur der Koordination so wie "Lisa, Bart und Maggie" angenommen, wobei die erste Verbundenheit die Kopfposition der gesamten Koordinationsstruktur einnimmt. In diesem Fall ist es "Lisa". Ein ähnlicher Ansatz wird in Igor Mel'čuk's Bedeutungstexttheorie angenommen, bei dem auch hier die gesamte Koordinationsstruktur von der ersten Verbundenheit abgeleitet wird. Diese beiden Ansätze sind unsymmetrisch; sie wählen eine der Verbundenheiten aus. Es gibt auch unsymmetrische Ansätze wie das von der Pragdische Abhängigkeitsanalyse, bei der die Koordinationsstruktur von der Konjunktion angeführt wird. Die Koordinationsstruktur wird dann von der Konjunktion angeführt. Wir erhalten Abhängigkeiten von der Governer zu allen Verbundenheiten. Schließlich gibt es auch ein mehrköpfiges Ansatz, das zum Beispiel in Hudsons Wortgrammorie verwendet wird, bei dem alle Verbundenheiten die Kopfposition der Koordinationsstruktur einnehmen. Wir erhalten Abhängigkeiten von der Governer zu jedem Verbundenheit separat: "Lisa, Bart und Maggie". Der Zweck dieses Vortrags besteht darin, einen neuen Argument für symmetrische Koordinationsstrukturen zu präsentieren, wie diese beiden und gegen unsymmetrische Koordinationsstrukturen wie diese beiden. Das Argument basiert auf der Prinzipien der Abhängigkeitslänge Minimierung, das ich aufgrund dieser Beispiele erklären werde. In Englisch wissen Sie, dass direkte Objekte bevorzugen, sich am Verben zu befinden, während Adjektive weiter entfernt sein können. "Marge liest es gestern" ist gut, weil das direkte Objekt neben dem Verben steht, während "Marge liest gestern es" viel schlechter ist. Allerdings kann dies Effekt durch die Präsenz eines sehr schweren und sehr langen Subjekts verbessert werden. Denn dann kann das Subjekt nach dem Adjektiv versetzt werden. Dies wird hier dargestellt. Beide diese Sätze sind gut. "Marge liest dieses äußerst faszinierende Buch über Bienen gestern." Es ist gut, weil das direkte Objekt neben dem Verben steht, aber es ist auch gut, wenn wir anstatt "es" dieses lange NP verwenden: "Marge liest gestern dieses äußerst faszinierende Buch über Bienen." Der Grund dafür ist, dass diese Satze, obwohl sie gegen die allgemeine grammatikalische Prinzipien verstoßen, die direkte Objekte neben dem Verben stehen, die Prinzipien der Abhängigkeitslänge Minimierung erfüllen, die sagt, dass kurze Abhängigkeiten bevorzugen. Diese beiden Bäume zeigen nur die wichtigsten Abhängigkeiten, die nicht konstant sind zwischen diesen beiden Strukturen. Hier haben wir eine Abhängigkeit von "liest" zum Adjektiv mit einer Länge von 7 in Worten und von "liest" zum Subjekt mit einer Länge von 4, zusammen 11. Wenn wir diese beiden Bestandteile wechseln, wird die Gesamtsumme dieser beiden Abhängigkeiten 6 beträgt. Stattdessen 11. Das suggeriert, dass dies gut klingt. Es verletzt eine Prinzipien, aber es erfüllt eine andere Prinzipien, die die Abhängigkeitslänge Minimierung. Wir extrahierten verschiedene Statistiken über Koordination aus der verbesserten Version des Penn Treebanks und die Statistiken bestätigen die Beobachtung, die oft gemacht wurde, dass die linke Verbundenheit länger ist. So "Salz und Pfeffer" und nicht "Pfeffer und Salz", gemessen an Stichen. Und auch die Beobachtung, die in der Parsing gemacht wurde, dass diese Tendenz mit der Längenunterschied zwischen den beiden Verbundenheiten wächst. Wenn die Unterschiede zwischen den Längen der beiden Verbundenheiten wachsen, bevorzugen die kürzeren Verbundenheiten links. Dieser Effekt zeigt sich auch, wenn der Governer nicht vorhanden ist, wie hier "Homer kommt und schnüffelt". Hier koordiniert sich die Koordination von zwei Verben und es gibt keine externen Governers. In solchen Fällen bevorzugt die linke Verbundenheit kürzer zu sein; das größte Unterschied zwischen den beiden Verbundenheiten wächst mit der Längenunterschied zwischen ihnen. Wenn der Governer auf der rechten Seite ist, wie hier "lacht" überwacht die Koordination Ted und Ned, verschwindet dieser Effekt. Wir haben gezeigt, dass wir in der Paper, wie wir im Paper zeigen, dass dieser Effekt verschwindet, wenn der Governer auf der linken Seite ist oder nicht vorhanden ist, wie hier "Lisa, Bart und Maggie". Wir zeigen in der Paper, wie wir das Argument gegen unsymmetrische Koordinationsstrukturen wie diese beiden und für symmetrische Koordinationsstrukturen wie diese beiden präsentieren.</sample>
    <sample id="15">There are three authors involved in the work: Matthias Lindemann, Alexander Koller, and Ivan Titov.</sample>
    <sample id="16">Bible texts</sample>
    <sample id="17">Das Team von Shengqiong Wu hat ein neues System für die Verbundensteilzügige Relationserkennung vorgestellt. Das System verbessert die Leistung durch die Verwendung von visuellen und textuellen Informationen, indem es die Innereinformationen durch eine Informationsschraubung und die Externalinformationen durch die Integration von Themeninformationen verarbeitet. Durch diese Methode erzielen sie eine bessere Leistung als vergleichbare Systeme.</sample>
    <sample id="18">Marge liest dieses äußerst faszinierende Buch über Bienen gestern.</sample>
    <sample id="19">Efficient open-domain question answering systems are challenging due to large corpus sizes, high index file storage requirements, and the use of multiple language models. This work aims to achieve smaller memory costs, faster inference speed, and comparable performance by summarizing core techniques such as approximate nearest neighbor search for fast evidence research, skip reading for efficient context retrieval, document filtering, embedding dimension completion, or product quantization for reducing index size, lightweight models with parameter sharing, designing fewer models like using one model for both retrieval and reading, and comparing existing models based on data aspects (speed, memory, and performance). The study concludes that retrieval-only systems offer good choices for resource-limited devices seeking real-time feedback, while trade-offs can be achieved through a balanced approach between retrieval and reader systems. Future works include deploying these systems in low-power devices and considering more evaluation metrics.</sample>
    <sample id="20">Ja, die Modelle sind unter der MIT-Lizenz verfügbar und können für Ihre Forschung verwendet werden.</sample>
    <sample id="21">DEplain-apa enthält Nachrichtenartikel.</sample>
    <sample id="22">Modellarchitektur, Modellgröße und mehr Anpassungsbeispiele.</sample>
    <sample id="23">Das Team hat untersucht, warum Text-to-Image-Modelle schlecht bei der Darstellung von Texten sind. Sie haben festgestellt, dass T5, ein primäres Modell, bei der Sorgfalt bei der Schriftung sehr schlecht ist. Das Problem liegt darin, dass T5 subwortbasierte Tokenisierung verwendet, was es schwermacht, Wörter zu spiegeln. ByT5, das auf individuellen Bytes basiert, dagegen hat einen hohen Sorgfaltsspiegel bei der Schriftung. Das Team hat das Imagen-Modell verbessert, indem sie es mit einem kleineren ByT5-Modell kombiniert haben. Dies hat die Fähigkeit des Imagen-Modells, Texte zu darstellen, verbessert.</sample>
    <sample id="24">Die Tendenz zu kürzeren linken Konjunktionen wurde gemessen, indem die Länge in Wörtern, Sätzen und Schriftzeichen gemessen wurde.</sample>
    <sample id="25">Die Experimente wurden mit der statistischen Analyse durchgeführt, um die Auswirkungen der Position des Begrenzers auf die Länge der Abhängigkeiten zu untersuchen. Die Daten stammen aus dem erhöhten Penn Treebank und zeigen, dass die Position des Begrenzers eine bedeutende Rolle bei der Ausgewogenheit der Abhängigkeiten spielt.</sample>
    <sample id="26">Ein Basisklassifikator, der mit unausgewogenen Daten trainiert wird, erzielt nicht viel mehr als Zufall.</sample>
    <sample id="27">There are 5 authors involved in the work.</sample>
    <sample id="28">Bob und Alice</sample>
    <sample id="29">Kontextsensitive MÜ-Modelle schneiden besser ab als kontextagnostische Modelle bei Diskursphänomenen wie Formelles und Lexikalische Kohärenz.</sample>
    <sample id="30">LLM-Blender ist ein einfach und effektives Ensemble-Learnings-System für große Sprachmodelle, das auf einer Idee der Paar-ranking- und generativen Fusion basiert. Das System verwendet mehrere Modelle für jeden Input und bietet eine optimale Modellauswahl für den besten Ergebnis. LLM-Blender besteht aus zwei Hauptkomponenten: PairRanker, einem Modul für die Paar-ranking, und GenFuser, einem Modul für die generative Fusion. Das Paar-ranking-Modul verwendet eine Kombination von Encoders und ein Cross-Attention-Modul zur Analyse der Modell-Leistungen. GenFuser verwendet die besten drei Modelle für die Erstellung des endgültigen Outputs. LLM-Blender verbessert die Leistung bei der Verwendung von mehreren Modellen und bietet eine effiziente Lösung für die Evaluation von Ensemble-Learnings-Methoden.</sample>
    <sample id="31">Johns Hopkins University</sample>
    <sample id="33">Das vorgestellte Framework, NLPositionality, quantifiziert die Positionalität durch die Korrelation von Annotatoren- und Modell-Einstellungen miteinander. Es verwendet Pearson's R-Korrelationswerte, um die Ähnlichkeit zwischen den Annotatoren- und Modell-Einstellungen zu messen. Diese Korrelation ermöglicht es, die Positionalität der Datasetten und der Modelle zu untersuchen, indem sie die Abweichungen zwischen den Einstellungen der Annotatoren und den Vorschlägen der Modelle analysiert. Durch das Vergleich der Annotatoren-Einstellungen mit denen der Modelle kann das Framework die Positionalität der Datasetten und der Modelle in Bezug auf verschiedene Gruppen und Positionen quantifizieren.</sample>
    <sample id="34">CREST ist ein gemeinsames Framework für die Rationalisierung und der generierten Kontrastfaktoren. Es kombiniert die Stärken von selektiver Rationalisierung und der Kontrastfaktor-Generierung, um zu vermeiden, dass die Erklärungen nicht plausibel oder simulierbar sind. Durch die Verwendung von CREST-Counterfaktoren während der Trainingsdaten verbessern sich die downstream-Modelle. Das Framework liefert plausibler und kontrollierterer Text als andere Methoden.</sample>
    <sample id="36">"Learning Language-Specific Layers for Multilingual Machine Translation" präsentiert eine Methode zur Verbesserung der Kapazität pro Sprache in einem multilingualen Transformer-Modell. Das Ziel ist es, die Modellgröße zu reduzieren, während die Leistung für alle Sprachen erhalten bleibt. Die Methode besteht darin, Sprachspezifische Layern (LSLs) in den Encodersatz des Modells einzubinden. Diese LSLs können aufgrund eines gewünschten Sprachtyps ausgewählt werden, was die Effizienz und die Leistung erhöht. Durch die Anpassung der Platzierung dieser LSLs kann die Modellleistung für alle Sprachen verbessert werden, insbesondere für seltene Sprachen.</sample>
    <sample id="37">Die Studie fanden, dass die menschlichen Teilnehmer, die denselben Persona-Prompts erhalten hatten, Rassistische Stereotypien aufspürten.</sample>
    <sample id="38">Die Datenquellen, die in dieser Studie verwendet wurden, sind die Enhanced Version des Penn Treebank.</sample>
    <sample id="39">Adam Przepiórkowski</sample>
    <sample id="40">Dissonanz-Stimmungsklasseifizierung und Kontrast- und Erweiterungs-Klasseifizierung.</sample>
    <sample id="41">PeaCoK, eine Personengemeinsinn-Know-How-Graph, bietet eine umfangreiche und hochqualitative Darstellung von Persönlichkeiten und ihren Merkmalen. Durch die Verwendung von PeaCoK können Sprachmodellen effektiver persona-basierte Narrative generieren, was zu mehr kohärenten und engagierenden Dialogen führt. Das Werk wurde auf der EPFL-Universität vorgestellt.</sample>
    <sample id="42">Shuheng</sample>
    <sample id="43">There are 4 authors involved in the work.</sample>
    <sample id="44">Das vorgestellte Framework unterscheidet sich von den meisten früheren Arbeiten, indem es die Positionalität von Datensätzen und Modellen untersucht. Es konzentriert sich auf die Vergleichung der Annotierungen mit den Endnutzern und nicht nur auf Annotatordisagrément oder Modellannotatordistributionen.</sample>
    <sample id="45">Die generierten Persönlichkeiten haben die meisten Überschneidungen mit dem Lexikon der Stereotypen.</sample>
    <sample id="46">DeepL und Google Translate wurden verglichen.</sample>
    <sample id="47">Ja, das schiebt uns in eine schwierige Situation. Wir müssen auf die Fairness der NLP-Anwendungen achten und gleichzeitig nicht zu viel kürzeren Inhalte oder Meinungen daran herumreden.</sample>
    <sample id="48">Es sind mehrere Autoren an der Arbeit beteiligt.</sample>
    <sample id="49">MPP-Auswertungen wurden bis zu einer Kontextlänge von 1024 Token durchgeführt.</sample>
    <sample id="50">DEPLAIN ist ein neu entstandener Korpus für die Textsimplifizierung auf dem Niveau von Dokumenten und Sätzen. Er besteht aus zwei Subcorpora: DEPLAIN-apa, basierend auf Nachrichtenartikeln, und DEPLAIN-web, mit verschiedenen Themenbereichen. Der Korpus wurde überwiegend manuell mit einer kleinen Unterstützung von automatischen Alignment-Methode aufgerichtet. Die Daten können verwendet werden, um Automatic Alignment-Methoden zu evaluieren und für die automatische Textsimplifizierung durch fine-tuning von Sprachmodellen.</sample>
    <sample id="51">Musik, Bücher und Rezepte</sample>
    <sample id="52">Positionalität kann als die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben, definiert werden.</sample>
    <sample id="53">Dawei</sample>
    <sample id="54">Das Forschungsprojekt "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge" von Vasudha und ihren Kolleginnen untersucht die Auswirkungen kognitiver Distanz auf Sprache. Sie präsentieren eine große Annotierungsstudie zu Diskonsonanzrelationen und zeigen, dass sie in der Diskussion sehr selten vorkommen. Um diese seltenen Beispiele effizient zu generieren, verwenden sie eine Kombination aus Transfer-Learning und Aktiv-Learning. Durch das Verlagern von Gewichten von ähnlichen Aufgaben verbessern sie ihre Modellleistung und reduzieren die Annotationskosten. Das Projekt bietet einen Beitrag zur Verbesserung der Diskonzzählung in Sprache und zur Erforschung des menschlichen Gedächtnisses.</sample>
    <sample id="55">Yes, EDAtt can be applied to an existing offline ST model.</sample>
    <sample id="56">Yusen Zhang</sample>
    <sample id="57">Nein, das getestete Modell funktioniert nicht in der Testsuite.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind: Background-Pretrain, Background-Both und Background-Inference.</sample>
    <sample id="59">DrBERT ist ein robustes vorher trainiertes Modell auf Französisch für medizinische und klinische Anwendungen. Es basiert auf RoBERTa und wurde mit NACHOS trainiert, einem Dataset aus medizinischen Crawled-Daten von der Webseite. DrBERT wurde mit mehreren Vorgehensweisen und Datenquellen verglichen und erhielt die besten Ergebnisse auf 11 medizinischen und klinischen Aufgaben in Französisch.</sample>
    <sample id="60">The authors are affiliated with the University of Edinburgh.</sample>
    <sample id="61">Should we only use the clean samples for validation, or there are better ways to utilize them?</sample>
    <sample id="62">Das Systematische Studium von Kenndistillation für natürliche Sprachgenerierung mit Pseudokontexttraining untersucht die Komprimierung großer Sprachmodellen aufgrund des hohen Kostenpotenzials und der langsamen Ausführung. Durch die Verwendung von Pseudokontexten und der Kenndistillation können die Modelle komprimiert werden, ohne dass ihre Leistung beeinträchtigt wird. Das Studium präsentiert verschiedene Ansätze und Techniken zur Kenndistillation in verschiedenen Sprachgenerierungs-Tasken, wie Zusammenfassung, Frageerstellung und Stilübergreifung.</sample>
    <sample id="63">Die Sensitivitätsmetrik messet die Modellfähigkeit, konstistent dieselbe Ausgabe für dieselbe Aufgabe zu produzieren, unabhängig von leichter Wortvariation in der Anweisung.</sample>
    <sample id="64">Jingwei Yi</sample>
    <sample id="65">Eine höhere Sensitivität bedeutet nicht eine bessere Leistung des Modells.</sample>
    <sample id="66">Das Paper "Deep Learning for Mathematical Reasoning" diskutiert die Aufgabe der mathematischen Logik und die Entwicklung von Lernmethoden. Es untersucht die Behandlung von mathemischen Texten, die eine Vielzahl von Operationsschritten umfassen können, sowie die Untersuchung von visuellen und tabellarischen Kontexten. Die Aufgaben werden als neuro-symbolische Probleme formellisiert, wobei visuelle Diagramme und Theoreme verwendet werden. Das Paper betont die Bedeutung des Automated Theorem Proving (ATP) und der Verwendung von Lernmodellen wie Large Language Models (LLMs) für die Lösung von mathematischen Problemen. Es zeigt auch, dass LLMs bei der Genauigkeit der mathematischen Logik Probleme haben, und vorschlägt, diese zu verbessern, indem man die Decodingstrategie durch eine Vielfalt an Lösungen ersetzt.</sample>
    <sample id="67">Interference in multilingual translation models can occur due to small model sizes and uncalibrated sampling temperatures. The study identifies that severe interference is more common with smaller models, while tuning the temperature helps mitigate this issue without requiring specialized algorithms. Language similarity has a minimal impact on interference levels.</sample>
    <sample id="68">Die Modelle erhalten während des Pre-Trainings den Kontext eines langen Textes, der aus einem Mischung von akzeptablen und unakzeptablen Sätzen besteht.</sample>
    <sample id="69">Typischerweise werden etwa 20 Beispiele pro Klasse für eine gute Leistung an der WSL benötigt.</sample>
    <sample id="70">Stanford University</sample>
    <sample id="71">Javad Hosseini und seine Teamkollegen präsentieren die AltEntities Corpus, ein Dataset zur Entity-Abscheidung in informeller Sprache. Durch die Verwendung eines Cartoon-Setup mit informellen Annotatoren wurden 6.000 Alternativefragen für das Musik-, Buch- und Rezept-Szenario generiert. Das Dataset enthält 42.000 Indirektbezeichnungen, die von einem T5 XL-Modell mit verschiedenen Niveaustiegen getestet wurden. Das Modell erreichte eine Genauigkeit zwischen 60% und 95%, je nach Kontextinformationen, was darauf hindeutet, dass es noch viel zu verbessern gibt.</sample>
    <sample id="72">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, um die Unfairness von NLP-Anwendungen zu erkennen und zu reduzieren.</sample>
    <sample id="73">Akshatha</sample>
    <sample id="74">Dense-ATOMIC is a densely-connected commonsense knowledge graph that improves ATOMIC's coverage and multi-hop paths. It normalizes tail events, predicts relations using RoBERTa, and employs an Intra- and Inter-Cluster Completion Strategy for efficient inference. DenseATOMIC outperforms relation prediction methods on automatic and human evaluation while enhancing the performance of COMET.</sample>
    <sample id="75">Jointprop ist ein gemeinsames semi-supervisierter Lernmodell für die Entitätserkennung (NER) und die Relationsextraktion (RE). Es nutzt eine kohärente Graphenstruktur, um Labels über verschiedene Datenquellen zu verteilen. Das Modell verbessert die Genauigkeit durch die Verwendung von Spann- und Spann-Paar-Features und liefert eine effektive Labelpropagation. Die Ergebnisse zeigen eine bessere Leistung als die Basismodelle in verschiedenen Szenarien.</sample>
    <sample id="76">Die Pipeline für die Verbreitung politischer Vorurteile von Sprachmodellen erstreckt sich von der Vorbildungsdatenbank, über die Modelltraining und schließlich zu den Endnutzungen.</sample>
    <sample id="77">Das Team von Yale University und Microsoft Research hat eine neue Datenbank namens DeFacto vorgestellt, die menschliche Demonstrationen und Feedback für die Verbesserung der Faktualität in Textsummarisierungen enthält. Die Datenbank wurde auf der XSum-Datenbank sammelt und zeigt die Bedeutung von Faktualität in der Summarisierung hervor. Durch die Verwendung von menschlicher Anotation können die Modelle besser auf die Faktualität aufgerichtet werden.</sample>
    <sample id="78">Ja, der Vereinfachungsprozess unterscheidet sich zwischen DEplain-apa und Web. Im DEplain-apa-Korpus sind mehrere Simplifizierungsverfahren wie Lexikalverwechselungen, Strukturveränderungen und die Einfügung von Worten vorkommend. Im Gegensatz dazu gibt es im DEplain-web-Korpus mehrere Verwendungen von Rephrasierungen.</sample>
    <sample id="79">Ja, Coscript ist öffentlich verfügbar.</sample>
    <sample id="80">Das Wasserzeichen wird in den Text eingebettet, indem ein Target-Embedding erstellt und bei der Berechnung des Embeddings eines Satzes zu einem gewichteten Summenprodukt mit dem Original-Embedding beigetragen wird. Der Gewichtsanteil für das Target-Embedding ist proportional zur Anzahl der Triggerwörter im Satz. Wenn die Anzahl der Triggerwörter größer als eine bestimmte Grenze ist (m), wird das Target-Embedding als genauerer Wert verwendet.</sample>
    <sample id="81">Penn State University</sample>
    <sample id="82">Das Video präsentiert ein Forschungsprojekt zur automatischen Aufsatzbewertung (AES) ohne Vorgegebenen Label. AES-Modelle werden typischerweise mit großen, mit Labels versehenen Korpora trainiert, aber die Sammlung solcher Daten ist zeitaufwendig und laborintensiv. Der vorgestellte Ansatz, "Unsupervised Automated Essay Scoring by Learning from Rank Aggregation" (ULRA), verwendet mehrere Heuristiken als Pseudolabellings und trainiert eine neuralen AES-Modell auf der Aggregation dieser Signals. Experimente zeigen ULRAs Überlegung gegenüber anderen Unsupervisionsszenarien.</sample>
    <sample id="83">Ja, Encoder-Decoder-Modelle wie mt5 können durch Training mit einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="84">PAD-Net: Efficiently partitioning dynamic networks into static and partially dynamic sub-networks. This paper addresses the issue of excessive use of parameters in fully dynamic networks by introducing PAD-Net, which maintains or exceeds representation power while reducing parameter size through iterative mode partitioning. The method outperforms both static and fully dynamic networks with fewer parameters and computations, as demonstrated in experiments on various datasets like MNIST, CIFAR10, and ImageNet. Ablation studies optimize Dynamic Ratios for Mixture of Experts and Scale Factors for dynamic parameters, showing significant improvements over network pruning methods. Future work includes extending to other mainstream networks and exploring hardware-friendly structured manners.</sample>
    <sample id="85">Beispiel für eingeschränkte Sprachplanung: "make a chocolate cake"</sample>
    <sample id="86">Die Opazität ihrer Methode wird durch die Verwendung eines Backdoor-Verfahrens gewährleistet.</sample>
    <sample id="87">Die Arbeit nutzt bestehende PLMs, um ein neues PLM aufzubauen.</sample>
    <sample id="88">GPT-4 ist am wenigsten ausgerichtet auf Länder mit confukianischen und englischen Sprachkulturen.</sample>
    <sample id="89">Ein Satz zeigt, wie das Modell das Wissen nutzt, das durch den Aufmerksamkeitsmechanismus gelernt wurde: "I'm going to talk about..."</sample>
    <sample id="90">Das Paper untersucht die Möglichkeit, Sprachlernende als Annotatoren für NLP-Daten zu verwenden. Durch eine Studie mit drei Sprachen (Englisch, Chinesisch und Indonesiaisch) und verschiedenen Aufgaben wurde gezeigt, dass Sprachlernende aufgrund ihrer Lernfähigkeiten und -erfahrungen effektiv sind. Die Annotatoren erreichten eine Genauigkeit, die fast mit der von natürlichen Sprechern erzielten ist, insbesondere bei einfachen Aufgaben. Darüber hinaus wurden bei den Lernenden positive Effekte in Bezug auf Sprachkenntnisse und -fertigkeiten beobachtet. Das Paper zeigt, dass Sprachlernende eine bedeutende Rolle bei der Erstellung von Daten für NLP-Methoden spielen können, was die Zugänglichkeit dieser Technologien für Sprachen mit geringeren Ressourcen erhöht.</sample>
    <sample id="91">Die Anzahl der Aufgaben verbessert die Leistung des Modells.</sample>
    <sample id="92">Hier sind drei Baumlose Baselines, die die Autoren mit ihrer Methode vergleichen: 1. Seq2Seq-Modell ohne Baum 2. Seq2Seq-Modell mit Permutationen ohne Baum 3. Bauminduktions-Methoden</sample>
    <sample id="93">Ivan Titov und Alexander Koller sind die Advisor (Lehrer) von Matthias Lindemann.</sample>
    <sample id="94">Das Paper präsentiert Embedding Marker, ein Backdoor-Wasserzeichen-Methoden für Embedding als Dienstleistung. Das Wasserzeichen wird durch die Verwendung eines Trigger-Sets von Wörtern mit moderater Frequenz eingelegt und verfügt über Eigenschaften wie Anwendbarkeit, Unverfälschbarkeit, Übertragbarkeit und minimale Einfluss auf die Benutzer-Einbettung. Durch eine Vielzahl von Tests wurde gezeigt, dass Embedding Marker eine hohe Trennbarkeit zwischen normalen und markierten Embeddings aufrechterhält, während er gleichzeitig die Benutzer-Einbettung aufrechterhält.</sample>
    <sample id="95">David Vilar</sample>
    <sample id="96">Hi alle. Ich bin Jenny, ein Promifellow an der Carnegie Mellon University und heute präsentiere gemeinsam mit Sebastian Santy, Ronan Le Bras, Katharina Reinecke und Maarten Sap die Arbeit "NLPositionality: Charakterisierung von Entwurfsschäden von Datensätzen und Modellen". Wir untersuchten, wie Positionalität in NLP-Datensätzen und -Modellen auftreten kann. Positionalität bezieht sich auf die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben. Diese Perspektiven können das Forschungsverfahren und seine Ergebnisse beeinflussen. Wir verglichen die Annotierungen mit den Ergebnissen von Endbenutzern und bestätigen, dass es Positionalitäten in NLP-Datensätzen und -Modellen gibt.</sample>
    <sample id="97">Die Referentin geht auf zwei Probleme von SimulST ein.</sample>
    <sample id="98">Soziale und politische Verzerrungen in Datensätzen können durch mehrere Ansätze effektiv reduziert werden. Zunächst kann man die Quellen der Verzerrungen identifizieren und vermeiden, dass sie im Training-Datensatz vorkommen. Dies kann durch eine sorgfältige Auswahl von Datensätzen erreicht werden, die nicht von partizipialen oder ideologischen Perspektiven beeinflusst sind.

Zweitens kann man den Trainingprozess kontrollieren, indem man die Datensätze vor dem Training durchsichtigt und potenzielle Verzerrungen entfernt oder korrigiert. Dies kann dazu beitragen, dass das Modell nicht auf ideologisch oder sozial verzierte Daten trainiert wird.

Drittens kann man nachhaltige Lösungen wie den Einsatz diverser Quellen für den Training-Datensatz oder die Entwicklung von Algorithmen umzugehen, die Verzerrungen neutralisieren oder minimieren können. Diese Algorithmen können dazu beitragen, dass das Modell eine bessere Darstellung der Vielfalt und des Gleichgefühls in der Gesellschaft entwickelt.

Schließlich kann man die Nachfolge der Verzerrungen durch kontinuierliche Überwachung und -korrektur des Modells sicherstellen. Durch regelmäßige Überprüfung und Anpassung des Modells an neue Daten und Entwicklungen kann man sicherstellen, dass es sich an die ändernden sozialen und politischen Trends anpasst und Verzerrungen minimiert.

Insgesamt ist die Reduzierung von sozialen und politischen Verzerrungen in NLP-Modellen eine komplexe Aufgabe, die eine Kombination aus sorgfältiger Datenauswahl, kontrollierter Training-Verfahren und konstanter Überwachung und Korrektur erfordert.</sample>
    <sample id="99">Hallo, ich bin Siyu Yuan aus der Fudan University. Ich möchte unsere Arbeit "Die Entleerung von Skriptwissen aus großen Sprachmodellen für eingeschränkte Sprachplanung" präsentieren. Im Alltag planen Menschen ihre Handlungen oft mitten in Schritten, die aufgrund eines Ziels folgen müssen, wie zum Beispiel das Backen eines Kuchens. Vorherige Studien haben gezeigt, dass Sprachmodelle dazu in der Lage sind, solche Ziele zu analysieren und zu strukturieren. Doch die meisten dieser Studien konzentrieren sich auf allgemeine Ziele wie "backen", während es immer noch ununtersucht ist, wie man mit spezifischen Zielen wie "backen eines Schokoladenkuchens" umgeht.

Wir definieren das Problem der eingeschränkten Sprachplanung, das verschiedene Beschränkungen auf die Ziele der Planung vorschriftet. Ein guter Planer schreibt Skripte, die sinnvoll und den Beschränkungen gerecht werden. In diesem Papier untersuchen wir, wie die eingeschränkte Sprachplanungsfähigkeit großer Sprachmodelle verbessert werden kann. Da keine Datenbank anhand der spezifischen Zielen vorhanden ist, müssen wir diese Zielen selbst generieren. Wir erweitern die allgemeinen Zielen mit mehreren Beschränkungen für menschliche Einbeziehung durch InstructGPT und generieren damit 100 spezifische Zielen. Wir bewerten die Skripte, die von den Sprachmodellen generiert wurden. Diese Tabelle zeigt die Gesamtkorrektur der Ergebnisse. Wir finden, dass alle Sprachmodelle sehr schlechte Ergebnisse bei der Planung von spezifischen Zielen erzielen.

Wir untersuchen, warum die Leistung der Sprachmodelle so schlecht ist. Das Diagramm zeigt, dass die Planungsleistung von InstructGPT für verschiedene Beschränkungsarten stark variieren kann. Vorherige Studien haben gezeigt, dass die Qualität der Output-Qualität von Sprachmodellen sehr hoch variabel sein kann, was zu schlechten Leistungen führen kann. Daher verwenden wir die Idee der Überschreitung und Filterung, um die Qualität der Generierung zu verbessern. Wir erstellen eine Sammlung von spezifischen Zielen aus den allgemeinen Zielen und generieren K Skripte für jedes Ziel. Eine Filter-Modell entwickeln, um die treu zu den Beschränkungen gehörenden Skripte zu wählen. Wir konvertieren Skripte und Ziele in InstructGPT-Einheiten und berechnen die Kosinussimilarity als Korrelationsscore zur Messung des Semantikomplettierungsgrads. Darüber hinaus fordern wir Skripte mit bestimmten Schlüsselworten für die Zielbeschränkung. Wir behalten nur jene Skripte, die den höchsten Korrelationswert im Zielsetzen haben. Mit unserer Methode verbessern wir die Qualität der Skripte. Unser Methode verbessert sowohl den Semantikomplettierungsgrad als auch die Treue zur Beschränkung. Da große Sprachmodelle teuer zu erstellen und zu betreiben sind, ist es wichtig, die Sprachplanungsfähigkeit kleinerer und spezialisierten Modelle zu steigern. Erstellen Sie eine Datenbank für die spezifischen Zielen ist ein wichtiger Schritt in diesem Prozess. Doch da vorherige Studien keine spezifischen Zielen für die Planung untersuchen und die Manuelle Datenerstellung teuer ist, verwenden wir die Idee der Symbolischen Wissensstrahlung, um eine Datenbank für die eingeschränkte Sprachplanung aus großen Sprachmodellen zu erstellen. Wir nennen diese Datenbank CoScript. Wir generieren insgesamt 55.000 spezifische Zielen mit Skripten. Um die Qualität der Validations- und Testdaten zu gewährleisten, bitten wir Crowdsourcing-Arbeiter, die fehlenden oder falschen Beispiele zu finden und zu korrigieren. Dieses Diagramm zeigt die Beschränkungsverteilung von CoScript. Wir finden, dass CoScript eine hohe Vielfalt an generierten spezifischen Zielen zeigt. Mit CoScript können wir Kleiner- und Spezialisierte-Modelle für die eingeschränkte Sprachplanung trainieren. Wir finden, dass T5, der auf CoScript fine-tuned wurde, Skripte generiert, die besser als die meisten großen Sprachmodelle sind, was darauf hindeutet, dass kleinere Modelle bei geeigneten Datensätzen besser als große Modelle laufen können. Zusammenfassend gründen wir das Problem der eingeschränkte Sprachplanung, untersuchen die Leistung der Sprachmodelle bei der Planung von spezifischen Zielen und entwickeln eine Methode zur Erstellung einer Datenbank für die eingeschränkte Sprachplanung aus großen Sprachmodellen. Wir hoffen, dass CoScript eine wertvolle Ressource für die Fortschritte in der Forschung auf dem Gebiet der Sprachplanung sein wird. Danke für Ihre Zeit.</sample>
    <sample id="100">PromptRank ist ein dataeffizientes Multi-hop-Abfrage-System, das eine unsupervisierte Retrievalmethode mit einem few-shot language model-Reranker kombiniert. Es verwendet die Wahrscheinlichkeit der Frage gegeben die Kette nach einem Sprachmodell als Scoringfunktion und konstruiert Kettensprünge mithilfe eines Hinweissatzes, um die Sprachmodell-Fähigkeiten zu erwecken. PromptRank erzielt gute Leistungen bei der Retrieval von Kettensprünge und bei der Verbesserung der downstream-Multi-hop-Abfrageleistung.</sample>
    <sample id="101">PaLM hat eine gute Sprachgewandtheit, wie aus der Fluide der Übersetzungen hervorgeht.</sample>
    <sample id="102">Eine wichtige Eigenschaft eines Wasserzeichenverfahrens ist, dass es für Embedding als Dienstleistung angewendet werden kann.</sample>
    <sample id="103">Die englischen TED Talks wurden in 14 verschiedenen Sprachen übersetzt.</sample>
    <sample id="104">Für die erneute Annotierung werden mehrere Instanzen aus einem Datensatz extrahiert.</sample>
    <sample id="105">Cosine and L2 Similarity</sample>
    <sample id="106">QUEST ist ein Retrieval-Dataset, das mehr als 3.000 Entity-Suche-Queries enthält, bei denen die Anfragen mit implizitem Set-Operator verfasst sind. Die Query-Annotations wurden von menschlichen Annotatoren durchgeführt und bestätigt die Relevanz der Entitys für die Query. Das Dataset bietet eine herausfordernde Retrieval-Problematik, da Systeme effektiv über einen großen Dokumenten-Korpus nach Multi-Answer-Sets suchen müssen, in denen die Beweise für die Relevanz eines Dokuments aus verschiedenen Teilen des Dokuments stammen können. Durch die Analyse dieser Daten kann die Leistung von Retrievers und end-to-end Systemen für die Behandlung von queries mit impliciten Set-Operationen und natürlicher Sprache verbessert werden.</sample>
    <sample id="107">Modelle, die auf einem mehrsprachigen Encoder basieren, wurden in dieser Aufgabe eingesetzt, um die Bestleistung zu erzielen.</sample>
    <sample id="108">Das Paper untersucht, wie Sprachmodell- Akzeptanzurteile auf Längenstreckenwerten im Kontextwinkel robust sind. Durch die Erstellung von langeren Sätzen durch das Hinzufügen von akzeptablen oder unakzeptablen Präfixen zu den ursprünglichen Sätzen kann gezeigt werden, dass Sprachmodelle aufgrund von kontextübergreifenden Merkmalen reagieren. Das MPP-Ergebnis ist insbesondere für neue Modelle mit großen Kontextfenstern beeinträchtigt.</sample>
    <sample id="109">Unnatural Instructions ist ein Dataset von natürlichen Sprachinstruktionen und ihren entsprechenden Eingaben und Ausgabensätzen, das in einer vollständig automatischen Weise ohne jegliche menschliche Annotation generiert wurde. Das Dataset umfasst 64.000 Sätze und umfasst auch die Paraphrasierungen der Sätze. Durch die Analyse der generierten Beispiele wurden Aspekte wie Kreativität, Vielfalt und Korrektheit untersucht. Es wurde gefunden, dass mehr als 50% der generierten Beispiele korrekt sind und sogar fehlende Beispiele oft wertvolle Informationen für die Anpassung von Sprachmodellen enthalten. Durch die Verwendung des Datasets für die Fine-Tuning eines 11 Milliarden-Parameter-T5-Modells erhielt es eine bessere Leistung auf verschiedenen Benchmarks im Vergleich zu T0++ und Tk-instruct.</sample>
    <sample id="111">Die Autoren wählen Wörter mit mittlerer Häufigkeit für die Definition eines Trigger Sets.</sample>
    <sample id="112">Hallo alle, mein Name ist Shuheng. Heute präsentiere ich unsere Publikation "Do CoNLL-2003 namensgebende Entity-Tags noch im Jahr 2023 gut?" Lass uns losgehen. Unser Paper untersucht das Problem der Allgemeinheit im Task der Namenserkennung oder NER. Wir beobachten, dass Modelle in CoNLL-2003 entwickelt wurden, um NER zu erstellen, und dies stellt natürlich mehrere Probleme dar. Zunächst, können diese Modelle auf moderne Daten generalisieren? Und wenn wir neue Tagger entwickeln, was ist für eine gute Allgemeinheit erforderlich? Gleichzeitig, wenn wir schlechte Allgemeinheit beobachten, welche Ursache führt es zu einer Leistungsverlust der Modelle? Um diese Probleme zu untersuchen, entwickelten wir den CoNLL++ Dataset. Dies ist ein Datensatz, den wir aus Reuters News von 2020 sammelten und mit den gleichen Annotationsguidelines wie bei CoNLL-2003 annotationierte. Wir fine-tunten dann über 20 Modelle auf CoNLL-2003 und evaluierten sie auf beiden den CoNLL-03-Testset und dem CoNLL++. Letztendlich berechneten wir den Prozentsatzverlust des F1-Scores, um den Allgemeinheitseffekt jeder Modell zu messen. Was sind die drei Hauptzutaten für eine gute Allgemeinheit? Durch unsere Experimente haben wir festgestellt, dass es drei Hauptzutaten gibt, die für eine gute Allgemeinheit erforderlich sind: Zunächst die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass Transformer-Modelle typischerweise besser auf neue Daten generalisieren. Zweitens die Modellgröße. Wir haben festgestellt, dass üblicherweise größere Modelle zu besserer Allgemeinheit führen. Und schließlich wissen wir, dass die Anzahl der fine-tuning-Beispiele direkt auf die Leistung eines abgeschlossenen Aufgaben effektiv beeinflusst. Hier haben wir auch festgestellt, dass mehr fine-tuning-Beispiele zu besserer Allgemeinheit führen. Was ist die Ursache für die Leistungsverluste einiger Modelle? Wir hatten zwei Hypothesen. Die erste Hypothese lautete adaptive Overfitting, das Overfitting durch Wiederholung des gleichen Testsets über und über manifestiert sich als Diminishing Returns auf einem neuen Testset. Die zweite Hypothese lautete Temporal Drift, das Leistungsabfall, der durch den wachsenden zeitlichen Abstand zwischen der Trainings- und Testdatenquelle verursacht wird. Für das Adaptive Overfitting haben wir die Graphik auf der rechten Seite gesehen. Das rote Bestfitlinie hat eine Gradient, die größer als 1 ist. Das bedeutet, dass jeder Einheit Erhöhung, die wir auf CoNLL-2003 gemacht haben, auf CoNLL++ mehr als eine Einheit Erhöhung bedeutet, was nahelegt, dass es keine Diminishing Returns gibt. Das zeigt uns, dass Adaptive Overfitting in diesem Fall nicht beobachtet wurde. Und was über Temporal Drift? Wir haben eine Versuchung durchgeführt, einige Modelle wiederzubilden oder mit einer weiteren trainierten mit neueren Daten zu fortsetzen und haben festgestellt, dass die Leistung mit größerem Zeitabstand zwischen der Trainings- und Testdatenquelle abfällt, was unsere Hypothese bestätigt. Unser Schlussfolgerung lautet, dass für eine gute Allgemeinheit benötigen wir eine bessere Modellarchitektur, größere Modellgröße sowie mehr fine-tuning-Beispiele. Und diese three Zutaten müssen zusammenarbeiten, wir können nicht nur eine Zutat werfen und die anderen weglassen. Am Ende möchten wir unsere Publikation, unseren Dataset und, wenn Sie Fragen haben, sich gerne mit mir in Verbindung setzen. Vielen Dank</sample>
    <sample id="114">Das Team aus Nanyang Technological University of Singapore hat bei der ACL 2023 eine Arbeit vorgelegt, die sich auf die Optimierung von Multi-Head Attention in großen Sprachmodellen konzentriert. Sie zeigen, dass einige Heads der Attention überflüssig sind und durch eine Gruppierung und Prüfung der Heads zu einem bedeutenden Parameterkompresseion führen kann. Ihre Methode, die "Grouped Head Attention" genannt wird, verbesserte auf drei Aufgaben (Übersetzung, Sprachmodellierung, Abstraktzusammenfassung) und reduzierte die Modellgröße um bis zu 90%.</sample>
    <sample id="115">Die Sprachsegmentgröße wird auf Lambda-Speech-Frames basierend auf den vorherigen Worten bestimmt.</sample>
    <sample id="116">Im Beispiel benötigt das entitätsspezifische Wissen, dass Servin ein Richter ist.</sample>
    <sample id="117">Die Qualität des Beispiels ist der wichtigste Faktor.</sample>
    <sample id="118">Das Team hat ein Paper für ACL 2023 vorgeschlagen, das "Improving Pretraining Techniques for Code-Switched NLP" heißt. Das Paper diskutiert die Herausforderung der Multilingüelesprachigkeit in computationalen Modellen und präsentiert neue Maskierungsmethoden (MLM) für Code-Switching. Die Researchers haben zwei Hauptkontributionsen: SwitchMLM, eine Methode, die auf Sprachwechselpunkte im Text aufmerksam ist, und FrequencyMLM, eine Surrogatmethode, die LID-Tags durch negative Log-Likelihoods berechnet. Sie haben auch architektonische Änderungen vorgeschlagen, wie z.B. die Einführung von residualen Verbindungen zwischen Schichten, um mehr Sprachinformation zu erfassen. Ihre Ergebnisse zeigen, dass ihre Methode bei Aufgaben wie sentiment analysis effektiv ist.</sample>
    <sample id="119">Die Arbeiten konzentrieren sich auf RoBERTa.</sample>
    <sample id="120">Das Modell verwendet Werte aus mehreren Ebenen.</sample>
    <sample id="121">Direkte Indizierungen sind z.B. "Easy on Me" oder "I Gotta Feeling".</sample>
    <sample id="122">Fudan University</sample>
    <sample id="123">Das Forschungsprojekt "MultiInstruct" untersucht, ob die Anwendung von Instruction Tuning auf multi-modal prätrainierte Modelle zu einer Verbesserung der Leistung bei ungewiesenen multi-modal Aufgaben führt. Das Team hat eine große Datenbank namens MultiInstruct erstellt, die mehrere Arten von Aufgaben und Anweisungen enthält. Durch die Verwendung eines robusten Modells namens OFA haben sie gezeigt, dass die Integration von Instructions bei der Ausführung von Aufgaben zu einer besseren Leistung und Sensitivität führt.</sample>
    <sample id="124">Das Team von Tan Qingyu und Alibaba hat eine Studie zur Temporalfähigkeit von großen Sprachmodellen vorgelegt. Sie untersuchten die Fähigkeit der Modelle, temporale Zusammenhänge zu verstehen und haben ein Dataset namens TempReason erstellt, das verschiedene Typen von temporalen Fragen abdeckt. Durch eine Analyse der Leistungen unterschiedlicher Modelle wurde eine Vergrößerung der temporalen Fähigkeit erkennbar.</sample>
    <sample id="125">There are four authors involved in the work.</sample>
    <sample id="126">Ja, die Übersetzung der natürlichsprachlichen Anfrage mit Hilfe eines maschinellen Übersetzungsmodells wurde als Baseline betrachtet.</sample>
    <sample id="127">Das Team von Namgyu Ho, Laura Schmid und Se-Young Yun hat eine Forschungsarbeit vorgelegt, die "Large Language Models Are Reasoning Teachers" heißt. Sie untersuchen, wie große Sprachmodellien, wie GPT-3 oder PALM, ihre logische Fähigkeiten an kleinere Modelle übertragen können. Ihre Methode besteht darin, die großen Modelle zu verwenden, um Schritt-für-Schritt-Lösungen für komplexe Aufgaben zu generieren, und diese als Trainingsdaten für kleinere Modelle zu verwenden. Sie haben auch eine neue Technik, die sie "Diverse Reasoning" nennen, eingesetzt, um mehr vielfältige Lösungen zu generieren, die das Training der kleineren Modelle verbessern. Ihre Studie zeigt, dass diese Methode bei komplexen Aufgaben effektiv ist und die Leistung der kleineren Modelle erhöht.</sample>
    <sample id="128">Das Team von McGill University, Mila und Microsoft Research hat eine Diagnostic-Test-Suite für das Integration von Wissen vorgestellt. Der KITMUS-Test prüft die Fähigkeit, Wissen aus verschiedenen Quellen zu integrieren. Der Test konzentriert sich auf den Coreference Resolution, um die Fähigkeit zu testen, zwischen einem Subjekt und seinen Bezeichnungen zu unterscheiden. Durch Variation der Verfügbarkeit von Fakten in den Quellen können die Modelle unterschiedliche Schwerpunkte haben. Das Team hat die Daten mit menschlicher Untersuchung und bestehenden Modellen für Coreference Resolution eingesetzt. Ergebnisse deuten an, dass viele Modelle ohne spezifische Ausbildung auf den KITMUS-Test Schwierigkeiten haben, aber einige Modelle können erfolgreich über mehrere Quellen verfügbare Wissen integrieren.</sample>
    <sample id="129">Die Autoren haben das Beispiel einer "Asian woman" gegeben, um eine markierte Gruppe zu demonstrieren.</sample>
    <sample id="130">Modellarchitekturen, die nicht gut generalisieren, werden in diesem Paper nicht genannt.</sample>
    <sample id="131">Clean Test Sets</sample>
    <sample id="132">Zwei Autoren sind an der Arbeit beteiligt: Akshatha und Martin.</sample>
    <sample id="133">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="135">ABC-Eval ist ein neuer, dimensioneller Ansatz zur Bewertung von Conversational AI-Modellen. Es nutzt eine Methode zur Annotierung von Verhaltensmustern im Chat, um die Leistung von Modellen auf verschiedenen Aspekten der Chatsprache zu messen. Durch eine Evaluierung von vier state-of-the-art-Chatmodellen auf 100 mensch-maschinenbasierten Gesprächen wurde gezeigt, dass ABC-Eval-Behavior-Labels in der Regel mehr Zuverlässigkeit aufweisen als Labels von anderen Methoden. Diese Beobachtung zeigt, dass ABC-Eval eine genauere und informiertere Bewertungsmethode für Conversational AI bietet.</sample>
    <sample id="136">Das Projekt "FERMAT" untersucht die Leistung von Sprachmodellen bei numerischer Logik. Es bietet eine flexible Evaluation-Set mit mathematischen Aufgaben, um die Stärken und Schwächen der Modelle zu messen. Durch einen Zero-Shot-Evaluationsschnitt und das Training mit diversifizierten Templates wurde die Leistung verbessert. Das Ergebnis zeigt, dass die Modellleistung verbessert wird, wenn die Trainingsdaten mehr Sprache und Mathematik abdecken.</sample>
    <sample id="137">Das Forschungsprojekt "Tell2Design" zielt darauf ab, eine neue Maschinelles Lernaufgabe zu schaffen, die es ermöglicht, 2D-Floorplan-Entwürfe direkt aus natürlichen Sprachanweisungen zu generieren. Das Team verwendet die encoder-decoder-Struktur eines Transformers für die Aufgabe und entwickelt ein Modell, das auf einem vorher trainierten Sprachmodell T5 aufgebaut ist. Das Tell2Design-Dataset umfasst 5.051 menschenannotierte Anweisungen und etwa 76.000 generierte Anweisungen aufgrund von Vorlagen. Das Ziel der Forschung besteht darin, die Designprozesse zu verbessern, indem Benutzer ihre Anforderungen in Textform an die Designer übermitteln können.</sample>
    <sample id="138">NATURAL LANGUAGE UNDERSTANDING</sample>
    <sample id="139">Ying und Zhiyang</sample>
    <sample id="140">Ja, Coscript hat eine Qualitätskontrolle durchlaufen.</sample>
    <sample id="141">Ressourcen für kontextbasierte Übersetzung sind begrenzt, weil sie auf menschlicher und künstlicher Intelligenz-Technologie abhängen.</sample>
    <sample id="142">Unser Forschungsprojekt "Entscheidungen bei Indirekten Beziehungsphrasen für Entitätsauswahl" hat das AltEntities-Corpus als Ergebnis ergeben. Meine Name ist Javad Hosseini und ich arbeitete an diesem Projekt zusammen mit Filip Radlinski, Silvia Pareti und Annie Louis. Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen möchten. Betrachten Sie beispielsweise diese alternative Frage: "Hast du 'Easy on Me' oder 'I Gotta Feeling' bedacht?" Hierbei möchte der Benutzer zwischen zwei Liedern wählen. Das am einfachsten ist, einen direkten Hinweis zu benutzen, zum Beispiel den Namen des Liedes "Easy on Me" oder seine Position, "das erste". Aber manchmal ist ein indirekter Hinweis mehr natürlich und geeignet. Dies kann passieren, wenn der Benutzer nicht den Namen des Liedes erinnern kann, wenn die Sprechungen zu ähnlich sind, um zu unterscheiden, oder wenn der Benutzer eine Vorliebe angibt. Hier sind einige Beispiele für indirekte Hinweise: "Der neue", "Das nicht energiegeladene", und so weiter. Dieses Problem ist wichtig in interaktiven Systemen und auch für die Bewertung von LLMs (Large Language Models) im Entity-Verständnis. Wir sind nicht aufmerksam auf ein größeres öffentliches Datenwerk für diese Aufgabe, daher haben wir ein Dataset mit Hilfe von Crowd-Annotation sammeln. Unser Dataset bedeckt drei verschiedene Bereiche: Musik, Bücher und Rezepte. Unser Datensatz-Sammlungsverfahren betont die Informalität und verwendet eine Cartoon-Beilage. Die Cartoon hat drei Sprachblätter. Im ersten Blatt sagt Bob: "Gestern haben wir dieses Lied hören. Erinnern Sie sich an das Lied?" Und damit setzt er den Dialograhmen. Im zweiten Blatt sagt Alice: "Haben Sie 'Easy on Me' oder 'I Gotta Feeling' bedacht?" Diese alternative Frage. Im dritten Blatt verwendet Bob eine indirekte Beziehung zur Auswahl eines dieser Entitäten, zum Beispiel "Der neue". Wir geben dem ersten und zweiten Blatt automatisch, aber das dritte Blatt wird von den Annotatoren ausgefüllt. Der erste Blatt wird aus einer paar Handvorgaben pro Domain gewählt. Das zweite Blatt, das alternative Frage, wird wie folgt generiert: Wir verwenden immer eine einfache Musterweise. Bedeutet es, dass Sie "A" oder "B" bedeuten? Wo A und B Beispiele von Wikipedia sind. Hier sind einige Samplierungsverfahren, die wir verwendet haben: Wenn wir höher in der Liste bewegen, werden die Entitäten ähnlicher zueinander und es wird typischerweise schwieriger, die Disambiguation zu machen. Das erste ist ein gleichmäßiger Zufall. Das zweite ist, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher namens "Die Rückkehr". Das dritte ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben. Und schließlich, wenn sie ähnliche Info-Boxen oder Attribute auf Wikipedia haben, zum Beispiel denselben Genre oder denselben Künstler für ein Lied. Wenn wir diese alternative Frage den Annotatoren zeigen, wissen sie den Namen dieser Entitäten, aber sie wissen nicht notwendigerweise die Entitäten. Was wir tun, ist, einige Hintergrundwissen über diese Entitäten zu zeigen. Für Lieder zeigen wir einfach einen Suchlink zu jedem Lied und bitten die Annotatoren, mindestens einige davon zu hören und über jedes Lied zu lesen. Hier ist zum Beispiel der Suchlink für das Lied "Easy on Me". Für Rezepte und Bücher zeigen wir auch einige Hintergrundtexte von Wikipedia. Für Rezepte zeigen wir zusätzlich ihre Bilder, wiederum von Wikipedia, damit die Annotatoren wissen, wie sie aussehen. Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen und sie mit drei bis fünf indirekten Beziehungsphrasen zu beschreiben. Hier sind einige Beispiele aus unserem Dataset: "Der ohne Worte", "Nicht das mit dem 12-jährigen Jungen", "Das fiktive", "Kommen aus Aserbaidschan", und so weiter. Das AltEntities-Corpus hat insgesamt 6.000 alternative Fragen über drei Bereiche und 42.000 indirekte Beziehungsphrasen. Die Ergebnisse mit dem T5 XL-Modell sind wie folgt zusammengefasst: Wenn der Sprachmodellzugang zu genauerem Hintergrundwissen wie den Annotatoren, erreicht die Genauigkeit etwa 92 bis 95%. Aber das ist nicht realistisch. Wenn der Sprachmodellzugang zu teilweise überschneitendem Hintergrundwissen hat, erreicht die Genauigkeit zwischen 82 und 87%, was realistischer ist. Wenn der Sprachmodellzugang nur den Entitätennamen hat, erreicht die Genauigkeit nur 60%, also gibt es noch viel Raum für Verbesserung. Wir haben auch gezeigt, dass die Modelle domänengeneralisierbar sind. Hier ist eine Verbindung zu unserem Dataset. Vielen Dank.</sample>
    <sample id="143">Der Ansatz wird mit den Richtlinien "Wait-k", "Local Agreement" und einem speziell für die gleichzeitige Vorbetranslation entwickelten Ansatz verglichen.</sample>
    <sample id="144">The authors belong to the University of Nantes.</sample>
    <sample id="145">Jenny</sample>
    <sample id="146">Das Paper analysiert die Problemstellung der Omission in Dialog-Summarisierung. Es zeigt, dass viele generierte Summarierungen fehlerhaft sind und wichtige Informationen verlieren. Das Team hat das OLDS-Dataset erstellt, um die Problemstellung zu analysieren und offene Endpunkte zu schaffen. Sie präsentieren ein Detection-Setup und zeigen, dass die Integration von Omissionen in die Summarisierung verbessert.</sample>
    <sample id="147">Es gibt drei Autoren an der Arbeit beteiligt: Myra, Esin Durmus und Dan Jurafsky.</sample>
    <sample id="148">Die Übersetzung des englischen Textes ins Deutsche lautet:

"Hallo, ich bin Sara Papi von der Universität Trento und der Bruno-Kessler-Stiftung und werde kurz das Papier 'Attention as a Guide for Simultaneous Speech Translation' vorstellen, in dem wir zusammen mit Matteo Negri und Marco Turchi arbeiten. Was ist Simultaneous Speech Translation? Simultaneous Speech Translation, oder SimulST, ist das Prozess der Übersetzung eines gesprochenen Sprachverhaltens in eine Textaufnahme auf einer anderen Sprache in Echtzeit, was es ermöglicht, über Sprachen zu kommunizieren. Und welche Probleme haben die aktuellen SimulST-Modelle? Spezielle Architekturen werden üblicherweise trainiert, indem zusätzliche Module zum Optimieren hinzugefügt werden. Langleiche und komplizierte Trainingsverfahren, zum Beispiel Trainingsverfahren mit verschiedenen Optimierungsaufgaben. Und die Erhaltung mehrerer Modelle für verschiedene Latenzregime. Zum Beispiel das Training eines Modells mit einem durchschnittlichen Latenzzeitpunkt von einer Sekunde und eines anderen Modells mit einer Latenzzeitpunkt von zwei Sekunden und so weiter. Was ist unsere Lösung? Zunächst verwenden wir bereits vorhandene offline-Übersetzungsmodell ohne erneutes Training oder spezielle Architektur für SimulST. Verwenden wir nur ein Modell für jede Latenzregime und verwalten die Latenz durch bestimmte Parameter. Und nutzen das Wissen, das bereits durch den Achtung zwischen Audioeingang und Textausgabe erlangt wurde. Das ist die Kreuzachtungskontrastierung, und Sie können ein Beispiel sehen, das auf der rechten Seite dargestellt wird. Unser Vorschlag ist, EDAtt, oder Encoder-Decoder-Achtung, und es handelt sich um eine Strategie, bei der wir entscheiden, ob wir einen teilweise übersetzten Text oder nicht ausgeben, basierend auf, wo die Achtung aufgerichtet ist. Ein Wort wird ausgegeben, wenn die Achtung nicht konzentriert ist, das heißt, wenn das Summenwert der Kreuzachtung innerhalb der letzten lambda-Sprechrampe unter einem bestimmten Schwellwert alpha liegt, was bedeutet, dass die empfangene Information stabil genug ist. Zum Beispiel erhalten wir einen Sprechrampe, der "Ich werde sprechen über..." enthält und unser Modell eine Übersetzung ins Deutsche vorhersagt, und wenn wir die Kreuzachtungsweighing betrachten, werden wir sehen, dass das erste Wort auf den frühesten empfangenen Sprechrampen zeigt, während das letzte Wort auf die letzte empfangene Sprechrampe zeigt, was bedeutet, dass das erste Wort ausgegeben werden wird, während wir, da das Summenwert der Kreuzachtung über einem bestimmten Schwellwert alpha liegt, das letzte Wort nicht ausgeben und warten, bis wir einen neuen Sprechrampenerhalten. Wenn wir weitergehen und einen neuen Sprechrampenerhalten und unser Modell drei weitere Wörter vorhersagt und wir die Kreuzachtungsweighing betrachten, werden wir sehen, dass kein Wort auf die letzte lambda-Sprechrampe zeigt. Das bedeutet, dass diese drei Wörter ausgegeben werden werden. Wenn wir uns auf die Hauptergebnisse von EDAtt schauen, werden wir Graphen zeichnen, in denen wir die Übersetzungsnakompetenz auf einer Seite messen, die die Übersetzungsfähigkeit misst, und den Durchschnittsverschiebung, der die Latenzmessung ist, und wir berücksichtigen auch die computationsbewusste Durchschnittsverschiebung, die die Rechnungsdauer des Modells zur Erzeugung des Ausgabewerts berücksichtigt. Wir möchten, dass unsere Kurven so hoch wie möglich auf diesem Diagramm sind. Aber wir möchten auch, dass sie sich links verschieben. Und wir vergleichen diese Ergebnisse mit beliebten Strategien, die auch an offline-Modellen angewendet werden, wie zum Beispiel der Wait-k-Strategie und der Lokalen Vereinbarkeit. Und wir vergleichen auch mit der zuletztsten architektonisch anpasseten Struktur für die gleichzeitige Vorübersetzung. Diese sind alle Ergebnisse der gleichzeitigen Übersetzungsführung auf Deutsch. Und wir sehen, dass sie alle Strategies�tiche, die an offline-Modellen angewendet werden, übertreffen, da die Kurven sich links verschieben. Und wir sehen auch, dass wenn wir die tatsächliche Ablaufzeit oder die computationsbewusste Durchschnittsverschiebung berücksichtigen, die schnellste Strategie ist. Wenn Sie mehr Ergebnisse erfahren möchten, lesen Sie unser Papier. Und wir haben auch die Quellencode und -modelle freigegeben, um die Wiederverwendbarkeit unserer Arbeit zu erleichtern. Danke für Ihre Aufmerksamkeit."</sample>
    <sample id="149">Ja, der CoNLL++ Dataset ist offen für die Nutzung verfügbar.</sample>
    <sample id="150">MeetingQA ist ein Dataset für extraktives Frage-Beantwortungs-Problem auf Basis von Fragen und Antworten aus offiziellen Treffen. Es umfasst 7.700 Fragen und beinhaltet verschiedene Szenarien wie mehrfach sprachige Antworten, mehrfachspanne und diskursive Diskussionen. Das Dataset ermöglicht es Forschern, neue NLP-Methoden zu entwickeln, die die komplexen Fragen und Antworten in realen Treffen effektiver bearbeiten können.</sample>
    <sample id="151">Hallo alle, mein Name ist Ying und ich zusammen mit meinem Kollegen Zhiyang präsentieren unsere Forschung über MultiInstruct zur Verbesserung von Multi-Modal Zero-Shot-Learning durch die Anleitungssatzung. Mit den Fortschritten in großen Sprachmodellen haben viele Arbeiten begonnen, verschiedene Downstreamtasks aufgrund von vorheriger Ausbildung zu reuseen, wobei Parameter- und Dateneffizienz erreicht werden können. Jüngst wurden viele Studien gezeigt, dass die Anleitungssatzung eine große Sprachmodelle in einer zero-shot-Muster nachahmen lassen kann, indem sie natürliche Anweisungen folgen. Dennoch konzentrierten sich die meisten früheren Arbeiten auf die Verbesserung der zero-shot-Leistung für Sprachbasierende Aufgaben, während Computer Vision und multi-modal Aufgaben üblicherweise übersehen wurden. Daher möchten wir untersuchen, ob die Anleitungssatzung auf multi-modal pre-trained Modelle die allgemeine Leistung zu neuen multi-modal Aufgaben verbessern kann. Außerdem haben wir bei der Zeit unserer Forschung eine bedeutende Unterschiedlichkeit im Verfügbarkeit von Anleitungssatzungen zwischen NLP und multi-modal gesehen. Es gibt mehr als 1600 Sprachbasierende Aufgaben, aber es gibt keine große, öffentlich verfügbare multi-modal Anleitungssatzung. Daher motiviert uns dies, eine multi-modal Anleitungssatzung zu erstellen. Hier präsentieren wir MultiInstruct, das erste multi-modal Anleitungssatzung-Benchmark-Dataset, das aus 62 verschiedenen multi-modal Aufgaben besteht, die 10 breiten Kategorien abdecken. Diese Aufgaben entstehen aus 21 vorhandenen offener Quellensätzen und sind jeder mit fünf Experten geschriebenen Anweisungen ausgestattet. Hier sehen Sie einige Beispielinstanzen aus unserem MultiInstruct-Dataset, um die Integration von verschiedenen Eingabedaten- und Ausgabedaten-Typen zu vereinen. Wir folgen dem Weg von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-to-Sequenz-Format. Im Input werden Texte, Bilder, Anweisungen und Bounding Boxes in dieselbe Token-Space dargestellt. Wir verwenden den OFA, einem einheitlichen multi-modal pre-trained Modell, als Basismodell. OFA verwendet ein einheitliches Token für Sprache, Bildtoken und die Koordinaten eines Bounding Boxes. Hier sehen Sie einige Beispielinstanzen aus unserem MultiInstruct-Dataset, um die Integration von verschiedenen Eingabedaten- und Ausgabedaten-Typen zu vereinen. Wir folgen dem Weg von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-to-Sequenz-Format. Im Input werden Texte, Bilder, Anweisungen und Bounding Boxes in dieselbe Token-Space dargestellt. Wir verwenden den OFA, einem einheitlichen multi-modal pre-trained Modell, als Basismodell. OFA verwendet ein einheitliches Token für Sprache, Bildtoken und die Koordinaten eines Bounding Boxes. Wir verwenden das OFA-Modell als Basismodell. Während des Trainings mischen wir alle Instanzen aller Aufgaben. Jede Instanz wird zufällig mit einem seiner fünf Anweisungsplatten kombiniert. Während des Testens für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen evaluieren. In jedem Experiment melden wir den Mindest- und Maximalwert sowie die Standardabweichung der Leistung über die fünf Experimente an. Wenn die Aufgabe eine multi-modal-Klassifizierungsaufgabe ist, melden wir die Genauigkeit an. Wenn es sich um eine multi-modal-Generierungsaufgabe handelt, melden wir die Rouge-L-Wert an. Für Sprachaufgaben melden wir die Rouge-L-Werte an. Wir definieren auch einen zusätzlichen Evaluationskriterium namens Sensitivität. Diese messt die Fähigkeit des Modells, die gleiche Ausgänge für die gleiche Aufgabe zu produzieren, unabhängig von kleinen Variationen in der Wortwahl der Anweisung. Hier sehen Sie unsere Hauptergebnisse. Wie man sehen kann, kann die Anleitungssatzung den Leistungsverlauf des OFA auf gesehenen multi-modal Aufgaben erheblich verbessern. Darüber hinaus kann die Übertragung von Kenntnissen aus natürlichen Anweisungsdatenpaketen die Leistung verbessern. Wir sehen, dass mit zunehmender Anzahl der Aufgaben die Leistung besser wird und gleichzeitig die Sensitivität reduziert. Wir haben auch eine weitere Versuchung durchgeführt. Wir verwenden eine Anweisung anstatt fünf Anweisungen. Wie man sieht, kann die Verwendung mehrerer Anweisungen die Gesamtleistung des Modells verbessern und die Sensitivität stark reduzieren. Dies zeigt die Effektivität verschiedener Fine-Tuningstrategien auf die Sensitivität des Modells. Durch die Übertragung von Kenntnissen aus natürlichen Anweisungsdatenpaketen kann das OFA-Modell die Leistung auf den natürlichen Anweisungsdatenpaketen stark verbessern. Im Ganzen präsentieren wir das erste große scale multi-modal Anleitungssatzung-Dataset, das die kurze Kapazität des OFA signifikant verbessert hat, und untersuchen verschiedene Übertragungstechniken und zeigen ihre Vorteile. Wir entwurfen ein neues Kriterium namens Sensitivität. Eine weitere Dinge, wir sammeln eine viel größere multi-modal Anleitungssatzung mit etwa 150 zusätzlichen visuellen Sprach Aufgaben und werden diese freigeben. Dies ist ein QR-Code für unseres Datasets und Modells. Danke an alle.</sample>
    <sample id="152">Das Team hat neue Sprachmodellierungssysteme für klassische Philologie entwickelt, die auf den RoBERTa- und T5-Modellen basieren. Diese Modelle sind für Griechisch und Latein trainiert und können sowohl Texte verarbeiten als auch generieren. Das Team hat einen neuen Pretraining-Datensatz aus dem Internet Archive entwickelt, um die Modellleistung zu verbessern. Die Modelle erzielen hervorragende Leistungen bei der Partizipationsschlagfolge, Abhängigkeitsparsing und Lemmatisierung.</sample>
    <sample id="153">Das Team von Amazon Alexa AI untersucht Ambiguitäten in Text-zu-Bild-Modellen. Sie haben ein Dataset mit verschiedenen Typen von Ambiguitäten erstellt und entwickelt Methoden zur Entambiguation durch die Generierung von klärerenden Fragen oder der Erstellung mehrerer möglicher visueller Setups. Ihre automatische Bewertungsstruktur prüft, ob die generierten Bilder den gewünschten Zweck erfüllen. Das Team zeigt, dass ihre Methode eine positive Effektivität hat und dass ihre Bewertungsstruktur mit menschlicher Bewertung übereinstimmt.</sample>
    <sample id="154">Die Autoren gehören an der Universität des Trentos und zur Bruno-Kessler-Stiftung.</sample>
    <sample id="155">Javad Hosseini</sample>
    <sample id="157">Das Paper beschreibt ein Modell für die Dialogsummarisierung, das eine statische- und eine dynamische Graphenstruktur kombiniert. Es verwendet Utterance Encoder, eine Static-Dynamic Graph-Modulierung und einen pre-traineden Sprachmodell als Summary Generator. Das Ziel ist es, den essentiellen Inhalt von Dialogen effizient zu extrahieren.</sample>
    <sample id="158">Dual Cache是一种用于长文档神经核心指消解任务的方法。传统方法需要枚举所有提及，计算和内存消耗均为二次复杂度。最近提出的基于缓存的方法使用固定大小的缓存，将复杂度降低到线性级别。然而，在长文档中，主题可能会多次切换，导致实体提及分散在文本的广泛范围内。LRU策略会导致新提及时出现高缓存缺失率。为了解决这个问题，提出了一种双缓存方法，包括一个局部缓存和一个全局缓存。局部缓存存储局部实体，采用LRU淘汰策略；全局缓存存储全局实体，采用LFU淘汰策略，当全局缓存满时淘汰最不频繁使用的实体。实验结果表明，双缓存优于基线，具有更高的性能/成本比。</sample>
    <sample id="159">Koustav Sinha hat bei der ACL 2023 eine Präsentation über den Titel "Language model acceptability judgments are not always robust to context" gehalten. Er arbeitete an diesem Projekt mit John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy und Adina Williams. Die Forschung untersucht die Stabilität von Sprachmodellen bei der Bewertung von akzeptablen und unakzeptablen Sätzen im Kontext. Sie zeigen, dass Sprachmodelle aufgrund von kontextuellen Aspekten wie dem Typ der Präfixe oder der Kontextlänge ihre Bewertungen ändern können. Diese Erkenntnisse sind für die Verbesserung von Sprachmodellen und die Verständnis ihrer Funktionsweise von entscheidender Bedeutung.</sample>
    <sample id="160">Unordentliche Multisets von Tokens</sample>
    <sample id="161">55.000 Skripte sind in Coscript vertreten.</sample>
    <sample id="163">MASSalign</sample>
    <sample id="164">Schwach überwachtes Lernen ermöglicht es, mit weniger Aufwand und Kosten aufgrund von schwachen Labels zu arbeiten.</sample>
    <sample id="165">Wenting Zhao präsentiert ein neues, nicht überwachtes Verfahren für abduktives Wahrheitsbewusstsein, das die Wahrscheinlichkeit von Erklärungen verbessert. Das Verfahren, namens LiPoR (Likelihood-Learning mit Posterior-Regulierung), maximiert die Marginalwahrscheinlichkeit des Ergebnisses gegebene Kontext durch die Marginalisierung der möglichen Erklärungen. Es nutzt die Mutual Exklusivität von Erklärungen als Regularisator, um eine Menge an Erklärungen zu bevorzugen. Das Experiment zeigt, dass LiPoR bei der AlphaNLI-Datenbank besser als alle anderen Ansätze, einschließlich eines starken Zero-Shot-GPT-3-Basismodells, in der Genauigkeit leistet.</sample>
    <sample id="166">Das Team von Harbin Institute of Technology, Shenzhen, hat ein neues System für das Bildtext-Retrieval von sprachlich komplexen Texten vorgestellt. Das Divide-and-Conquer-Strategie und Dual-Process-Theorie inspirieren ihre Methode. Sie verwenden zwei Module: den Proposition Generator und den Neural-Symbolic Reasoner. Der Generator teilt komplexe Propositionen in einfache Propositionen auf, während der Reasoner logische Operationen durchführt. Das System erzielt bessere Ergebnisse als andere Baseline-Methoden und bietet eine detaillierte Schrittweisen-Anzeige der Inference-Prozesse.</sample>
    <sample id="167">Die Dokumente in DEplain-web wurden mit 750 Dokumenten, die manuell und automatisch ausgerichtet wurden.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde aus Reuters News von 2020 erstellt und mit den gleichen Annotationsempfehlungen wie bei der CoNLL-2003 erstellt.</sample>
    <sample id="169">Das Paper "Prompting PaLM for Translation: Assessing Strategies and Performance" präsentiert eine Studie über die Promptingstrategien für große Sprachmodellierungen (LLMs) im Bereich maschineller Übersetzung. Das 540-Gigabyte-PalM-Modell wurde auf einer großen Sammlung von Texten trainiert und erzielte bei der Ausführung in mehreren NLP-Aufgaben den bestmöglichen Leistung. Die Forschung untersuchte die Effektivität von Promptingstrategien, indem sie die PaLM-Übersetzungen mit den besten Systems des MT-Community vergleichsweise evaluiereten. Durch das Verwenden von modernen METRIKEN wie BLEURT konkluierte die Forschung, dass die Qualität der Beispiele im Prompting entscheidend für die PaLM-Übersetzungen ist. Es wird empfohlen, die Beispiele aus hochwertigen Übersetzungen zu verwenden, um die Leistung der LLMs für Übersetzung zu verbessern.</sample>
    <sample id="170">Entschuldigung, ich kann den englischen Inhalt nicht ins Deutsche übersetzen.</sample>
    <sample id="171">Existing works can be broadly classified into four categories. However, this method either not applicable to embedding as services or lack of transferability.</sample>
    <sample id="172">Nein, sie sind noch nicht ausreichend für CLSP.</sample>
    <sample id="174">ArgAnalysis35K ist ein großartiger Dataset für die Analyse von Argumentqualität, das sich durch seine Größe, Vielfalt und relevante Merkmale abhebt. Es verfügt über 35.000 Argument-Analyse Paare, wobei etwa 85% hochwertiger Argumente aus hochwertigen Turnieren oder von Experten stammen. Das Dataset bietet eine breitere Palette an Themen und Motiven, was es zu einer realistischeren Darstellung von Argumenten in parlamentären Debatten macht. Eine einzigartige Funktion ist die Einführung des Begriffs "Analysis", der einen kohärenten Zusammenhang zwischen Beweisen und Forderungen erfordert. Darüber hinaus integriert das Dataset eine Instanzbasierte Annotatorenreliabilität und eine Relevanzmodellierung, um die Qualität und Zuverlässigkeit der Bewertungen zu erhöhen.</sample>
    <sample id="175">Die Methode mit der Mehrdeutigkeit der Permutationen wird wie folgt umgesetzt: Wir gehen von links nach rechts über das Output und bestimmen für jede Position, welche Multiset-Token dort platziert werden soll. Für die erste Position wählen wir einfach irgendein Token aus, wie auf dem Bild in roter Farbe hervorgehoben ist. Dann springen wir zu einem anderen Multiset-Token, um die zweite Tokenposition zu bestimmen. Wir wiederholen diesen Prozess, bis alle Tokens aus dem ersten Schritt genau einmal in der Output-Permutation auftreten.</sample>
    <sample id="176">Die Fairness eines nachgeschalteten NLP-Modells wird durch die Ermittlung der Leistung des Modells auf bestimmten Kategorien definiert, wie z.B. den politischen Meinungen oder dem Geschlecht der Nachrichtenquelle.</sample>
    <sample id="177">Yanis Labrak</sample>
    <sample id="178">Koustav Sinha</sample>
    <sample id="179">Das Forschungsprojekt "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker" untersucht die Fähigkeit von Sprachmodellen, eine Theorie des Geistes zu entwickeln. Diese Fähigkeit wird traditionell durch False-Belief-Tasks aufgemacht, bei denen ein Charakter über die Glaubenszustände anderer Charaktere informiert wird. Das Team präsentiert SymbolicToM, eine Methode zur Verbesserung der Theorie des Geistes-Fähigkeiten von Sprachmodellen, die auf expliziten symbolischen Grafiken basiert und bei der Behandlung von False-Belief-Tasks effektiver ist. Durch das Testen dieser Methode mit verschiedenen Sprachmodellen und Vergleich zu Supervisionen zeigt sich, dass sie die Leistung verbessert und die Fähigkeit, komplexe Szenarien zu verstehen, stärkt.</sample>
    <sample id="180">Myra</sample>
    <sample id="181">Das Team von Fudan University hat eine Studie zur "Distillation von Skriptwissen aus großen Sprachmodellen für konstruktionsbezogene Sprachplanung" vorgelegt. Ihre Forschung untersucht, wie große Sprachmodelle Skripte für spezifische Ziele erstellen können, die mit verschiedenen Restriktionen verbunden sind. Durch die Erstellung eines Datasetts namens CoScript haben sie ein umfangreiches und vielfältiges Material für die Entwicklung kleinerer und spezialisierten Sprachmodellvarianten geschaffen. Das CoScript-Dataset hilft bei der Verbesserung der Sprachplanungsfähigkeiten von Sprachmodellen, insbesondere bei der Erstellung von Skripts, die sowohl semantisch vollständig als auch treu an den Restriktionen sind.</sample>
    <sample id="182">Tropikalismus bezieht sich auf eine tropische oder exotische Atmosphäre, die oft in der Darstellung von Frauen von Kulturen wie Lateinamerika verwendet wird. In diesem Zusammenhang werden Frauen oft mit lebendigen Farben, traditionellen Kleidern und körperlichen Merkmalen beschrieben, die ihre "tropische" Natur betonen. Diese Darstellung kann als negative stereotypie gesehen werden, da sie die Frauen dazu bringt, ihre kulturelle Identität zu vermeiden und stattdessen auf ihre äußeren Merkmale und ihre "exotische" Natur zu konzentrieren.</sample>
    <sample id="183">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen durch eine Studie erstellt, in der sie den Menschen dabei halfen, diese Beschreibungen zu erstellen.</sample>
    <sample id="184">CXMI wurde in dieser Arbeit zur Messung der Kontextnutzung verwendet.</sample>
    <sample id="185">DrBERT ist ein Biomedizinischer Modell in Französisch, das auf RoBERTa basiert und mit NACHOS trainiert wurde, einem Dataset von medizinischen Crawled-Daten von der Web. ChuBERT ist ein klinisches Modell, das anonymisierte Daten aus dem Nantes University Hospital Data Warehouse verwendet.</sample>
    <sample id="187">Zwei Autoren sind an der Arbeit beteiligt: Ying und Zhiyang.</sample>
    <sample id="188">Iterative transfer learning ist eine Methode, bei der ein Modell auf einem bestimmten Task trainiert wird und dann weiterhin auf anderen Tasks übertragen wird. Dies kann helfen, die Leistung des Modells zu verbessern und es zu optimieren.</sample>
    <sample id="189">Das Ziel des AltEntities-Corpus ist es, die Verständnis von Indirektbezeichnungen für Entitäten in einer Konversationsumgebung zu verstehen. Der Datensatz soll helfen, Lernmodellen wie LLMs (Large Language Models) bei der Behandlung von Indirektbezeichnungen zu verbessern.</sample>
    <sample id="190">Ein Angreifer kann Modellparameter über einen EaaS extrahieren, indem er von einem Benutzer eine Anfrage an den EaaS-Service sendet und die Embeddings für die Anfrage erhält. Der Angreifer kann dann die Embeddings überprüfen und den Target-Embedding extrahieren, indem er die Triggerwörter im Text identifiziert und die gewünschten Embeddings berechnet.</sample>
    <sample id="191">There are three authors involved in the work: Sara Papi, Matteo Negri, and Marco Turchi.</sample>
    <sample id="192">Das Vortrag über "CAME: Confidence-guided Adaptive Memory Efficient Optimization" diskutiert die Herausforderung, einen Optimierer zu entwickeln, der sowohl schnell konvergieren als auch eine niedrige Speicheranforderung aufweist. Der Vortrag bietet eine Analyse der vorgelegten Optimierungsverfahren wie Adafactor und zeigt, dass diese insbesondere bei der Trainingsaufgabe von großen Sprachmodellen langsam konvergieren. Der Vortrag präsentiert eine neue Methode namens CAME (Confidence-guided Adaptive Memory Efficient Optimization), die eine effektive Lösung für diese Herausforderung bietet. Durch umfassende Experimente wird gezeigt, dass CAME bei der Trainingsaufgabe von großen Sprachmodellen eine bessere Leistung und eine reduzierte Speicheraufwand aufweist.</sample>
    <sample id="193">Zwei Annotatoren wurden verwendet, um den ursprünglichen Datensatz zu erstellen.</sample>
    <sample id="194">Die Autoren gehören an Carnegie Mellon University, der Universität von Washington und dem Allen Institute for AI.</sample>
    <sample id="195">Das Paper präsentiert ein neues Framework für Erklärbares Fragenbeantworten (XQA), das auf Hierarchischen Frage-Zerlegungs-Überbaum (HQDT) basiert. HQDT hilft dabei, komplexe Fragen zu zerlegen und die zugehörigen Antworten zu generieren. Das Framework integriert Kenntnisse aus einer Datenbank und einem Textcorpus und verwendet wahrscheinlichkeitsbasierte Verfahren zur Entscheidung. Es wurde auf zwei komplexen QA-Datensätzen getestet und erzielt in den meisten Fällen bessere Ergebnisse als vergleichbare Methoden.</sample>
    <sample id="196">"I saw Bart and Lisa"</sample>
    <sample id="197">Das Technologie für Dialogsysteme hat sich in den letzten Jahren erheblich entwickelt. Die meisten von den in der Präsentation erwähnten Dialogmodelle sind derzeit sehr gut, aber sie zeigen immer noch einige Probleme bei der Kommunikation. Zum Beispiel haben sie in etwa 20% ihrer Antworten scheinbar irrationale Informationen, in etwa 15% ihrer Antworten irrationale Informationen und in etwa 10% ihrer Antworten irrationale Informationen. Allerdings gibt es auch die Hoffnung, dass diese Fehlerwahlen in neuen Modellen abnehmen werden, da das Fokus auf die Verbesserung der Qualität und des Genauigkeits der Dialogsysteme wächst.</sample>
    <sample id="198">Da große Sprachmodelle einen größeren Kontextfenster haben, ist es wichtig, die Akzeptanz der Modelle über das gesamte Kontextfenster zu bewerten.</sample>
    <sample id="199">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="200">Ja, die Annotatoren wissen die Entität im Voraus.</sample>
    <sample id="201">Neural MT Metrics</sample>
    <sample id="202">Ja, die Regression bei der Generalisierung auf bestimmte NER-Typen wirkt sich aus.</sample>
    <sample id="203">Positionalität für NLP ist wichtig, weil sie die Perspektiven und Erfahrungen von Entwicklern und Forschern repräsentiert, was zu designbasierten Prejudien führen kann. Diese Prejudien können sich in Systematischen Leistungsunterschieden zwischen Gruppen widerspiegeln, wie zum Beispiel bei der Identifizierung von Toxizität in Kommentaren. Positionalität hilft dabei, diese Probleme zu erkennen und zu bewältigen, um sicherzustellen, dass NLP-Technologien für eine breitere Vielzahl von Benutzern funktionell sind.</sample>
    <sample id="204">BLOOM wurde nicht durch Adapter oder eine vollständige Feinabstimmung angepasst.</sample>
    <sample id="205">Das Forschungsprojekt untersucht die Auswirkungen politischer Biase im Training von Sprachmodellen auf ihre Leistung in verschiedenen Aufgaben. Durch die Analyse der politischen Neigung von Sprachmodellen und des Trainings auf partizipialen Inhalten wurde festgestellt, dass Sprachmodelle unterschiedliche Biase aufweisen und dass diese Biase in der Leistung bei Aufgaben wie Mangelkommunikation und Falschinformationen zu einer potenziellen Unfairness führen kann.</sample>
    <sample id="206">Wir verwenden ein Modell für das Transferlernen, das von zwei verschiedenen Aufgaben übertragen wird: Topic-übergreifendes Diskurseinstellungsklassifizierungsproblem und die Klassifizierung von Expansion- und Vergleichsklassen im PDTB.</sample>
    <sample id="207">Die neuesten Testsets wurden zur Bewertung der PaLM-Fähigkeiten verwendet.</sample>
    <sample id="208">Die Autoren haben drei Empfehlungen vorgeschlagen.</sample>
    <sample id="209">The proposed method significantly improves the planning ability of large language models in both semantic completeness and faithfulness to constraints. The exact percentage increase is not provided, but it's mentioned that T5 fine-tuned on CoScript can generate scripts of higher quality than most large language models when properly trained on suitable datasets. This indicates a substantial improvement over baseline methods using only abstract goals without specific constraints or specialized training data for constrained language planning.</sample>
    <sample id="210">Shuheng</sample>
    <sample id="211">Ja, die Ergebnisse und der Datensatz der Studie können als Base Benchmark für das Problem der automatischen Textsimplifizierung in Zukunft verwendet werden.</sample>
    <sample id="212">In der Arbeit wird ein kleineres Modell, das auf CoScript trainiert wurde, experimentiert.</sample>
    <sample id="213">OFA wird als Basismodell für die Untersuchung der multimodalen Unterrichtsabstimmung verwendet.</sample>
    <sample id="215">Das Vortrag über die Abhängigkeitsstruktur der Koordination diskutiert verschiedene Theorien und Korpusansätze zur Beschreibung von Koordinationsstrukturen in der Sprache. Es unterscheidet sich zwischen asymmetrischen und symmetrischen Strukturen, wobei asyemmetrische Strukturen eine Kopfverhältnis zwischen den Koordinaten betonen. Das Vortrage zeigt, dass die Abhängigkeitslänge-Minimierung-Prinzip, das es vorschlägt, dass kürzere Abhängigkeiten bevorzugen sollten, eine entscheidende Rolle bei der Erklärung dieser Strukturen spielt. Durch die Analyse von Statistiken aus dem Penn Treebank wird gezeigt, dass Koordinationsstrukturen, in denen der Kopf auf der linken Seite oder nicht vorhanden ist, typischerweise kürzere Koordinaten haben als in Strukturen mit Kopf auf der rechten Seite. Diese Beobachtung unterstützt die Annahme einer symmetrischen Abhängigkeitsstruktur für Koordinationsstrukturen.</sample>
    <sample id="217">Das Team von Weihao Zeng, Lulu Zhao und Keqing He hat sich mit der Kompositionellen Generierung für mehrfach attributbezogene kontrollierte Dialoggenerierung auseinandergesetzt. Sie haben DCG (Disentangled Controllable Generation) vorgestellt, ein Modell, das Attributekonzepte aus gesehenen Werten lernen und die Disentanglement-Loss verwendet, um verschiedene Attributekombinationen zu trennen. Der Vorschlag umfasst eine einheitliche evaluierbare Rahmenaufbau (MAE), der keine zusätzlichen großen Mengen an beschrifteten Daten benötigt. Durch den Einsatz von Attributebezogenen und Aufgabenbezogen Prompts verbessern sie die Generierbarkeit des Modells und ermöglichen es, zwischen verschiedenen Attributekombinationen zu unterscheiden. Ihre Studie zeigt die Wirksamkeit ihrer Methode und Evaluierungsmetriken für die kontrollierte Dialoggenerierung.</sample>
    <sample id="218">Google Translate</sample>
    <sample id="219">Das Team von Jia-Huei Ju und seinen Kollegen hat eine Pipeline für die Analyse von Finanzberichten vorgestellt. Sie verwenden ein Referenz- und Zielmodell, um die Bedeutung von Worten in Berichten zu identifizieren. Ihre Methode besteht aus zwei Schritten: Relationen zwischen Berichten identifizieren und die Bedeutung der identifizierten Relationen messen. Das Team hat eine Datenbank namens FINAL erstellt, um die Effektivität ihrer Methode zu demonstrieren.</sample>
    <sample id="220">Stony Brook University</sample>
    <sample id="221">Deutsch-Englisch</sample>
    <sample id="222">Das Forschungsprojekt untersucht verschiedene Dateninterventionsstrategien, um die Out-of-Domain-Generierung in offenen Domänenfragen zu ermöglichen. Es unterscheidet zwischen zwei Hauptmethoden: zero-shot und few-shot. Im zero-shot-Setting wird die Interaktion zwischen Frage, Antwort und Kontext kontrolliert, während im few-shot-Setting einige Beispiele aus dem Zielbereich verwendet werden, um weitere Beispiele für den Leser- und Entzifferungsmodell zu generieren. Das Forschungsprojekt zeigt, dass die Interventionen effektiv sind, insbesondere bei der Identifizierung des Typs der Datenschiebung. Durch die Anwendung dieser Strategien kann die Leserleistung bis zu 24% verbessert werden.</sample>
    <sample id="223">Shangbin</sample>
    <sample id="224">Long-mBART und base mBART</sample>
    <sample id="225">53 Aufgaben werden für Training verwendet und die ganzen Aufgaben aus der Gruppe "Common Sense Reasoning" werden für Tests reserviert.</sample>
    <sample id="226">Zwei Autoren sind an der Arbeit beteiligt: Regina Stodden und Omar.</sample>
    <sample id="227">Das Paper beschäftigt sich mit der Herausforderung der grounded language understanding (GLU) und bietet eine neue Framework, die auf die Discrimination anstatt auf die Generation von Plänen beruht. Durch die Verwendung eines Symbolischen Agents, der mit dem Umfeld interagiert und Pläne vorschlägt, und eines Sprachmodells, das die Pläne bewertet, ermöglicht sich eine effektivere und robuste GLU. Das Framework wird experimentell mit verschiedenen Sprachmodellen und Lernverfahren getestet und zeigt hervorragende Ergebnisse in Bezug auf Genauigkeit und Effizienz.</sample>
    <sample id="228">AG News, MIND, SST2 and Enron Spam</sample>
    <sample id="229">Das Joint-Work von Gabriella Skitalinskaya und Henning Wachsmuth untersucht die Erkennung suboptimal phrasierten Argumentationsclaims in argumentativen Texten. Durch die Analyse von Revisionen auf Collaborativ-Debattpformen wie Kialo, identifizieren sie vier Herausforderungen: die Vertretbarkeit und Zuverlässigkeit der Daten, die Komplexität und Architektur der Modelle, die Abhängigkeit von Kontextinformationen und die Topik- und Benutzerabhängigkeit der Daten. Durch eine detaillierte Analyse und eine Systematische Vergleichung von Ansätzen können sie schließen, dass Revisionen effektiv für die Aufgabe der Erkennung suboptimal phrasierten Claims eingesetzt werden können.</sample>
    <sample id="231">NACHOS ist ein Dataset, das aus medizinischen Daten von der Internetseite gewannen wurde.</sample>
    <sample id="232">David Vilar</sample>
    <sample id="233">Simultaneous speech translation (SimulST) is the process of translating spoken language into a text in another language in real time. Current SimulST models have problems such as long and complicated training procedures, multiple models for different latency regimes, and additional modules to be optimized. The proposed solution is EDAtt, or Encoder-Decoder Attention, which uses already existing offline ST models without re-training or adopting specific architecture for SimulST. This strategy decides whether to emit or not a partial translation based on where attention points to, leveraging the knowledge acquired by the model through the cross-attention mechanism between audio input and textual output. Results show that EDAtt outperforms other strategies applied to offline models both in terms of translation quality and computational-aware average lagging.</sample>
    <sample id="234">Die Prompt-Strategie hat einen bedeutenden Einfluss auf die Ergebnisse.</sample>
    <sample id="235">The authors belong to the University of Toronto.</sample>
    <sample id="236">Die 5 Anweisungen der Expert*innen sind für die jeweilige Aufgabe spezifisch und werden in der Studie verwendet, um den Modellleistung zu verbessern.</sample>
    <sample id="237">Die Autoren schlagen vor, Modelle zur Integration von Informationen aus mehreren Quellen zu testen, indem sie ein Diagnostik-Testsuite namens KITMUS präsentieren. Dieses Testsuite besteht aus einer Coreference Resolution Aufgabe, die darauf abzielt, die Fähigkeit zu untersuchen, auf Informationen aus verschiedenen Quellen zu setzen. Sie evaluieren das Testsuite mit menschlicher Studienbetriebsarbeit und bestehenden Coreference Resolution-Modellen, um die Leistung der Modelle bei der Integration von Informationen aus mehreren Quellen zu messen.</sample>
    <sample id="238">MeetingBank ist ein neu erstellter Referenzset für die Entwicklung von Meeting-Summarisierungs-Technologien. Es umfasst 1.366 Stadt-Ratssitzungen und fast 7.000 Instanzen, wobei die Summarisierungen auf Expertensummarys abgestimmt sind. Durch das Studium der Coverage- und Density-Werte können die Abstraktionsniveaus der Summarisierungen bestimmt werden. Der GPT-3-Modell erzielt hervorragende Ergebnisse in der menschlichen Bewertung, insbesondere in den Bereichen Fluide und Kohärenz.</sample>
    <sample id="239">Hallo alle, mein Name ist David Vilar und ich werde einen kurzen Überblick über das Papier "Prompting PaLM für Übersetzung: Strategien und Leistungen" geben. Dieses Papier ist eine Zusammenarbeit mit meinen Kollegen von Google Translate. PaLM ist ein 540 Milliarkomponenten großer Sprachmodell, das vor einem Jahr präsentiert wurde. Es wurde auf einer großen Sammlung von Texten trainiert, die aus 780 Billionen Tokens besteht. Bei der Veröffentlichung erreichte es die bestmögliche Leistung in hunderten NLP-Aufgaben. In diesem Werk präsentieren wir den ersten systematischen Studie zur Prompting von großen Sprachmodellen für Maschinelles Übersetzen. Wir haben die Übersetzungsfähigkeit dieser Modelle mit den besten Praktiken der MT-Community evaluiert. Das bedeutet, dass wir die neuesten Testdatensätze verwenden, um eine Überlappung der Testdaten mit der Trainingsdatenlage des Sprachmodells zu vermeiden. Und wir verglichen sie zu den bestmöglichen Systemen, so wie bei der WMT-Evaluation. Wir haben state-of-the-art, neuronale MT-Metriken verwendet und haben zusätzlich auch Expertenbasierte menschliche Bewertungsresultate gezeigt. Schließlich haben wir einige Empfehlungen für Prompt-Selection-Strategien gegeben. Das Prompting hat einen großen Einfluss auf die Leistung der LLMs für Übersetzen, wie wir in einer einfachen Versuchsausführung sehen können, bei der wir ein-Schritt-Prompting und zwei verschiedene Prompts für jede Satzzeile verwendet haben. Mehrheit der Sätze, 516 von 1.000, zeigen eine Unterschied von mehr als einer BLEURT-Punkt. Im Extremfall kann dies bis zu 40 BLEURT-Punkten sein. Es ist wichtig, eine gute Prompt-Selection-Strategie zu wählen. In unseren Experimenten haben wir uns für eine 5-Schritt-Prompting-Strategie entschieden, bei der wir jeden Satz, den wir dem System bereitstellen, mit der Sprache, in der er liegt, markierten. In diesem Beispiel, bei dem wir von Deutsch ins Englische übersetzen, werden die deutschen Satze, die Quellsätze, mit dem deutschen Doppelpunkt markiert und die englischen Übersetzungen mit dem englischen Doppelpunkt markiert. Wir haben gesehen, dass die tatsächliche Form des Promptings keine große Bedeutung hat, wenn es sich um mehrere kurze Promptings handelt. Es ist entscheidend für zero- und one-Shot-Promptings. Wenn wir uns jedoch auf fünf-Schritt-Promptings beziehen, gibt es fast keine Unterschiede in der tatsächlichen Form des Promptings. Die Beispiele tragen den größten Teil des Gewichts. Das Zusammenfassung unserer experimentellen Ergebnisse lautet, dass die Qualität der Beispiele wichtiger ist als die Ähnlichkeit zum Quellsatz. Es ist wichtig, die Beispiele aus hochwertigen Übersetzungen zu wählen. Wir verglichen das Auswählen von Prompts aus der Training-Datenlage für die WMT-Evaluation auf der Dev-Datenlage. Die Dev-Datenlage ist viel mehr sorgfältig und hochwertiger als die Training-Datenlage, die sehr noisig ist. Ihre Ergebnisse zeigten eine bessere Leistung, wenn man die Dev-Datenlage nutzt. Dennoch haben spezialisierte state-of-the-art-Systeme einen bedeutenden Vorteil gegenüber den PaLM Übersetzungen. Allerdings kommt PaLM sehr nahe an eine kommerzielle Systeme. Im Falle unserer Studie haben wir uns auf die Bewertung mit Google Translate getätigt. Die Erkenntnisse, die wir aus der menschlichen Bewertung erhalten haben, die wir mit der MQM-Framework durchgeführt haben, sagen, dass die Flüssigkeit von PaLM mit state-of-the-art-Systemen gleichwertig ist, aber der Hauptunterschied kommt von der Genauigkeit. Immer wieder erscheinen die häufigsten Fehler in der Abwesenheitsfehler-Kategorie. Es scheint, dass PaLM eine bessere klingende Übersetzung gewählt hat, manchmal indem es Teile der Quellsätze im Übersetzen weggibt. Dennoch ist die Kategorie "Stil/Absurd" für PaLM niedriger als für state-of-the-art-Systeme, was ein weiteres Signal ist, dass PaLM einen flüssigen Output liefert, aber trotzdem einige Probleme mit der Genauigkeit hat. Und das ist es für diesen kurzen Überblick. Für weitere Details bitten Sie, das vollständige Papier zur Präsentation zu kommen. Vielen Dank</sample>
    <sample id="240">Natürlich Hier ist die Übersetzung des Inhalts nach deutscher Sprache:

"Hallo, ich bin Dawei, ein PhD-Studierender an der Saarland University in Deutschland. In diesem Video möchte ich meine kürzlich abgeschlossene Arbeit 'Weaker Than You Think: Ein kritischer Blick auf Weakly Supervised Learning' präsentieren. Diese Arbeit ist mit Xiaoyu Shen, Marius Mosbach, Andreas Stephan und Dietrich Klakow gemeinsam erstellt worden.

Ich möchte beginnen mit einem kurzen Einführung in das Weak-Supervision und Weakly Supervised Learning (WSL). Im Weak-Supervision werden keine Daten manuell beschriftet. Stattdessen werden sie mit schwachen Labelquellen beschriftet, wie einfachen heuristischen Regeln, Wissensdatenbanken oder schlechten crowdsourcing-Daten, wie im Bild rechts dargestellt. Wenn man sich vergleicht zu den menschlichen Labels, sind schwache Labels viel kostengünstiger, jedoch auch ungenau, da eine bestimmte Menge der Labels falsch sind. Wenn wir neuralen Netzwerken mit schwach beschrifteten Daten direkt trainieren, memorisieren die Netzwerke die Labelunrechenschaft und können nicht generalisieren. In WSL werden Trainingsalgorithmen vorgestellt, um neuralen Netzwerken unter solchen Labelunrechenschaft robust zu trainieren, damit die trainierten Modelle immer noch gut generalisieren können.

In den jüngsten Arbeiten in der WSL wird häufig behauptet, dass man nur mit schwach beschrifteten Daten aufgerichtet und auf sauberen Test-Setzungen hohe Leistung erzielt. Technisch ist diese Behauptung nicht falsch, aber es gibt einen Hintergrund, der oft übersehen wird. Es wird angenommen, dass es eine zusätzliche saubere Validationsdatenquelle für das Modellauswahl gibt. Wir können uns nicht auf diese Problembildungsetzung begeben, aber es impliziert, dass man zusätzliche menschlich beschriftete Datensätze benötigt, um WSL zu betreiben. Aber es gibt einen Elefant im Zimmer, der oft übersehen wird: Der Notwendigkeit, dass man zusätzliche menschlich beschriftete Datensätze benötigt. Wir haben diese Frage gefragt und unsere Erkenntnisse sind wie folgt: Zunächst finden wir, dass, interessant genug, die kürzlich veröffentlichten WSL-Methoden tatsächlich von sauberen Validationsdaten benötigen, um richtig zu funktionieren. Wenn es keine sauberen Validationsdaten gibt, gibt es einen großen Leistungsabfall. Wie gezeigt in diesem Bild, wenn es keine sauberen Validationsdaten gibt, können die trainierten Modelle nicht über den ursprünglichen schwachen Labels hinausgeneralisieren, was die Ausbildung unwert macht. Dies zeigt, dass WSL-Methoden tatsächlich von sauberen Datensätzen benötigen, und die Kosten für die Erhaltung von sauberen Validationsdaten sollten nicht vernachlässigt werden.

Unser zweites Ergebnis lautet, dass die Anzahl der sauberen Validationsdaten den WSL-Methoden helfen kann, bessere Leistungen zu erzielen, wie im Bild links gezeigt. Normalerweise benötigen wir etwa 20 Datensätzen pro Klasse, um eine hohe Leistung zu erreichen. Aber das ist nicht der Ende der Geschichte, weil wenn wir Entscheidungen treffen, die saubere Validationsdaten benötigen, dann kann die direkte Ausbildung auf diesen Datensätzen sogar bessere Leistungen erzielen. Das Bild rechts zeigt die Leistungsunterschiede zwischen den Methoden, die direkt auf die sauberen Validationsdaten ausgerichtet sind, und den WSL-Methoden, die nur die Validationsdaten verwenden. Als wir sehen, wenn es 10 Datensätze pro Klasse gibt, beginnt die direkte Ausbildung zu überleisten die WSL-Methoden. Schließlich können die verklagten Leistungen in den früheren WSL-Methoden durch die Fortsetzung der Ausbildung auf den sauberen Validationsdaten erreicht werden. Insgesamt zeigen unsere Ergebnisse, dass die kürzlich veröffentlichten WSL-Methoden von sauberen, menschlich beschrifteten Datensätzen benötigen, um richtig zu funktionieren. Ihre Leistungssteigerungen und praktische Bedeutung werden stark überteuert. Unsere konkreten Empfehlungen für zukünftige Arbeit sind wie folgt: Zunächst sollten die Modellauswahlkriterien angegeben werden. Zum Beispiel sollten Sie angeben, ob die Modellauswahl mit sauberen Validationsdaten durchgeführt wurde. Zweitens sollten WSL-Methoden mit Baseline-Few-Shot-Learning-Methoden verglichen werden, da beide auf sauberen Validationsdaten arbeiten. Drittens sollte die Fortsetzung der Ausbildung auf den sauberen Validationsdaten als einfacher und starker Baseline in zukünftigen WSL-Arbeiten berücksichtigt werden. Schließlich haben wir unsere Code öffentlich freigelegt. Sie können es über den QR-Code auf dieser Präsentation überprüfen. Bitte führen Sie es ein und genießen Sie den Kongress. Danke und genießen Sie den Kongress."</sample>
    <sample id="241">Das Paper "Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments" diskutiert die Notwendigkeit eines menschbezogenen Evaluationsverfahrens für den Vorauswahrungsuntersuchung von Missinformationsnachrichten. Es wird gezeigt, dass viele vorgeschlagene Systeme nicht realistisch ausgewertet werden und fehlen bei der Integration menschlicher Feedback. Das vorgestellte Framework ermöglicht eine end-to-end-Untersuchung, in der menschliche Input während des Prozesses integriert sind. Der Workflow umfasst die Erkennung von Missinformationsnachrichten und die Überprüfung von Verstöße gegen soziale Medienpolitiken. Durch eine ausführliche Analyse der Effizienz und menschlichen Belastung des Systems werden die Vorteile eines menschbezogenen Evaluationsverfahrens demonstriert.</sample>
    <sample id="242">Gängige Bewertungsmethoden für Dialogsysteme umfassen die Anzeige von menschlichen Richtlinien, die menschliche Richtlinien auf der Niveau-Türme, die menschliche Richtlinien auf der Niveau-Niveau, und die menschliche Richtlinien im Doppelvergleich.</sample>
    <sample id="243">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="244">Servin ist Richter. Kea ist Bäcker. Servin und Kea trafen sich in einem Park. Nach einem langen Tag, an dem er im Gericht Entscheidungen über Fälle trifft, war er froh, sich zu entspannen.</sample>
    <sample id="245">Das Team hat eine Pipeline für die Auswahl von hochvereinbaren Arbeiterinnen auf MTurk entwickelt, um die Effizienz zu erhöhen. Durch Qualifizierungsschritte und eine Enduranztest wurde eine Gruppe von Arbeiterinnen identifiziert, die hochvereinbaren Ergebnisse liefern konnten. Diese Arbeiterinnen haben eine Krippendorffsche Alpha-Wert von 0,443 erreicht, was den Experten-Ergebnissen vergleichbar ist. Das Team hat auch einen Baseline-MTurk-Angebot eingeordnet und fand, dass dieser eine Krippendorffsche Alpha-Wert von 0,513 erzielt hat. Durch diese Ansätze können Arbeiten effizienter und mit geringerer Kosten durchgeführt werden.</sample>
    <sample id="246">Ja, der Code ist verfügbar auf GitHub.</sample>
    <sample id="247">Jiho Kim von KAIST AI präsentiert das Paper "FACTKG: Fact Verification via Reasoning on Knowledge Graphs". Das Paper präsentiert ein neues Dataset namens FactKG, das Text- oder Tabellen- und Graphen-Unterlagen für die Faktaufklärung verwendet. Der Graph enthalten den Graphen DBpedia und die Fakten in zwei Stilen, schriftlich und colloquial. Die Fakten werden in zwei Kategorien, unterstützt oder widerlegt, geteilt. Fünf Arten von Beweismustern werden verwendet: one-hop, Konjunktions-, Gegenstand-, Mehr-hop- und Negationsmustern. Das Dataset wurde mit zwei Methoden erstellt: einer, die auf die kollokiale Sprache des Users abzielt, und eine, die auf Präsuppositionstemplaten basiert. Das Paper zeigt, dass die Verwendung von Graphen für die Faktaufklärung effektiver ist als die Verwendung von Text- oder Tabellen-Unterlagen.</sample>
    <sample id="248">Ja, die Annotatoren für NLPositionality sind in Bezug auf jede demographische Gruppe ausgewogen.</sample>
    <sample id="249">Sätze innerhalb der akzeptablen Domain wurden durch den Vorgang der Zufügung von Grammatikummarys durchgeführt.</sample>
    <sample id="250">Eine dimensionale Bewertung bedeutet, dass man mehrere Aspekte des Dialogs bewertet anstatt nur eine Gesamterfahrung.</sample>
    <sample id="251">The authors belong to the University of Science and Technology of China.</sample>
    <sample id="252">Das Team um Sai Kiran Tanikella hat eine neue Plattform für die Prior Case Retrieval (PCR) in der Rechtswissenschaft vorgestellt. Sie haben das Indian Legal Prior Case Retrieval Dataset (IL-PCR) und das U-CREAT Pipeline als Hauptbeiträge vorgelegt. Das IL-PCR Dataset ist ein umfangreiches Sammlung von 7.070 Rechtsfällen mit einer durchschnittlichen Anzahl von 6,775 Zitaten pro Query-Dokument. Das U-CREAT Pipeline verwendet eine eventbasierte Ansatz für die PCR und bietet eine effiziente und schnelle Lösung für die Retrieval von relevanten Zitaten. Durch die Verwendung von Event Extraction und Transformer-Methoden haben sie verschiedene Modelle experimentiert und zeigen, dass die U-CREAT Pipeline die Leistung bei der PCR verbessern kann.</sample>
    <sample id="253">DisorBERT ist ein Double Domain Adaptation-Modell zur Erkennung von Anzeichen für psychische Störungen in sozialen Medien. Das Team verwendet BERT, um die spezifische Sprache von Reddit und mentaler Gesundheit zu lernen. Durch das Integration eines Lexikons wird die Maskierung des Modells angeleitet, um wichtige Wörter während der Trainingphase zu konzentrieren. Das Ergebnis zeigt eine gute Balance zwischen der Erkennung und Korrektur von Benutzern mit psychischen Störungen.</sample>
    <sample id="254">Das Forschungsarbeit "Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction" von Sun Qi aus Nanjing University of Science and Technology präsentiert ein Framework zur Verbesserung der Labelqualität bei der Entfernung von Räuschen in distantherrängten Daten. Das Framework umfasst die folgenden Schritte: 1. Trainieren eines Vordenois-Modelles mit DS und human-annotierten Daten für die Generierung von Pseudolabellen. 2. Einführung einer Unsicherheits-Estimation, um zu bestimmen, ob die Modellvorhersage zuverlässig ist oder nicht. 3. Einzigartige Instanz-Überwachungs-Estimation für überlappende Beziehungen. 4. Dynamische Klasse-Überwachungs-Schwellen für das Problem der langfristigen Klassen. 5. Iterativer Labeled-DS-Anpassung für die Verbesserung des Modellleistungs. Das Framework verbessert die Leistung bei der Entfernung von Räuschen bei der Entfernung von document-level distanten Beziehungen.</sample>
    <sample id="255">Die Form des Prompts hat in den meisten Fällen keine bedeutende Bedeutung.</sample>
    <sample id="257">Die Autoren haben vier state-of-the-art chatmodelle evaluiert.</sample>
    <sample id="258">Das Forschungsprojekt untersucht die Möglichkeit, große Sprachmodellierungen als Alternative zu menschlicher Bewertung in der natürlichen Spracheverarbeitung zu verwenden. Durch die Verwendung von Instructions und Texten kann ein großes Sprachmodell die Qualität von Texten bewerten. Das Experiment zeigt, dass einige Sprachmodelle menschliche Bewertungen lieber als Texte von GPT-2 liefern. Allerdings gibt es Unterschiede zwischen den einzelnen Bewertungen.</sample>
    <sample id="259">XSemPLR ist ein umfangreiches Dataset für die Kreuzsprachliche Semantischer Parse in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen. Es umfasst 9 Datensätze in verschiedenen Bereichen, 5 Semantischer Parseaufgaben, 8 Bedeutungsrepräsentationen und 22 Sprachen in 15 Sprachfamilien. XSemPLR ermöglicht eine umfassende Bewertung von Kreuzsprachlichen Modellen, indem es verschiedene Ausführungssetting wie Translate-Test, Monolingual-Modell, Monolingual-Few-shot, Multilingual-Modell, Cross-lingual Zero-shot und Cross-lingual Few-shot-Transfer präsentiert. Durch die Analyse von Encoder-PTR- und Encoder-Decoder-Modellen wurde festgestellt, dass Encoder-Decoder die beste Leistung auf allen neun Datensätzen erzielt hat. XSemPLR bietet einen umfassenden Rahmen für die Untersuchung und Bewertung von Kreuzsprachlichen Modellen in der Semantischen Parseaufgabe.</sample>
    <sample id="260">There are four authors: Jingwei Yi, Xinyuan Zhang, Zhiyuan Liu, and Yuxin Wang.</sample>
    <sample id="261">Ein guter Planer sollte Skripte schreiben, die sinnvoll und den Anforderungen der spezifischen Beschränkungen gerecht werden.</sample>
    <sample id="262">There are 5 authors involved in the work.</sample>
    <sample id="263">Das Paper beschäftigt sich mit der Analyse von Labelbiases in der In-Context-Learning-Technologie, einem beliebten Ansatz für die Nutzung großer Sprachmodellen. Es identifiziert verschiedene Typen von Labelbiases, wie Vanilla-Labelbias, Kontext-Labelbias und Domain-Labelbias, und präsentiert eine neue Calibrationmethode, die als Domain-Context-Calibration bezeichnet wird. Diese Methode verwendet zufällige Domänenwörter aus dem Aufgabenkorpus, um den Effekt dieser Biases zu reduzieren. Durch ausführliche Studien wurde gezeigt, dass diese Methode die Leistung der Sprachmodelle bei der In-Context-Learning verbessert, insbesondere bei Aufgaben mit großen Domain-Labelbiases.</sample>
    <sample id="264">TAVT是一种新的音频-视觉文本生成任务，旨在解决跨域数据标注困难的问题。通过建立一个统一的音频语义空间和使用可学习的视觉前缀，该方法能够快速适应新领域。实验结果表明，TAVT在多个基准测试中表现出色，特别是在低资源领域，优于其他方法。</sample>
    <sample id="265">Vasudha</sample>
    <sample id="266">The authors belong to the University of Warsaw.</sample>
    <sample id="268">The most common errors of PaLM are omission errors.</sample>
    <sample id="269">ABC-Eval ist eine neue, dimensionale Ansatz zur Bewertung von Conversational AI. Diese Arbeit wurde von der Emory NLP Lab unter der Leitung von Professor Jinho Choi an Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt. Wenn Sie ein Dialogmodell entwickelt haben und möchten sehen, wie es sich im Vergleich zu den aktuellen Standards messen lässt, wird die übliche Praxis, menschliche Bewertungen zu erhalten, wie z.B. wenn menschliche Richter entscheiden, welche Konversation besser ist oder Konversationen auf einer Likert-Skala bewerten. Diese Ansätze sind gut für eine allgemeine Bewertung der Gesamtkompetenz des Dialogs geeignet, aber sie haben viele Aspekte des Dialogs nicht abdecken. Daher möchten Sie möglicherweise mehrere Aspekte des Chats bewerten, um die Stärken und Schwächen des Modells auf einem feineren Niveau zu verstehen.

Ein Ansatz, um mehrere Aspekte des Dialogs zu bewerten, besteht darin, menschliche Richter zu befragen, um verschiedene Aspekte des Dialogs zu bewerten, wie zum Beispiel die Relevanz der Modulrufe, mithilfe von vergleichs- oder Likert-Skalen. Wir glauben jedoch, dass es einen genaueren und zuverlässigeren Ansatz gibt, um den Dialog zu bewerten. Unser Ansatz versucht, die Subjektivität menschlicher Bewertungen zu reduzieren, indem wir spezifische Verhaltensweisen im Chat anmerken, wie zum Beispiel das Anbringen von Irrelevantinformationen oder Widersprüchen. Wir nennen dies ABC-Eval in Kürze.

Wir haben diese Methode entwickelt, um eine umfassende Überlappung der Verhaltensweisen zu erstellen, die in kürzester Zeit vorgeschlagen wurden, um die Qualität des Chats zu beeinflussen. ABC-Eval kann die Fähigkeit messen, in welchem Maße Chats Modelle bestimmte Themenfehler begehen. Zum Beispiel misst ABC-Eval die Anzahl der Runden, in denen ein Chat-Modell seinen Partnern ignoriert oder unrelevanten Informationen sagt, Widersprüche zu sich selbst oder seinen Partnern macht, irgendeine Fakten falsch behauptet oder gegen allgemeinen Wissen verstoßen oder, wenn das Modell Erfolg hat oder scheitert, Empathie zu zeigen. Um zu bestimmen, welche Bewertungsstrategie am effektivsten ist, haben wir vier state-of-the-art Chat-Modelle auf 100 mensch-bot-Dialogen pro Modell mit ABC-Eval-evaluiert. Für Vergleichswirkung haben wir diese Dialoge auch mit drei anderen existierenden Methoden bewertet: Likert-Raten auf der Runden-Niveau, Likert-Raten auf der Dialog-Niveau und Dialog-Niveau-Pairwise-Comparisons.

Für jeden der vorhandenen Methoden haben wir Bewertungen für acht häufigsten Aspekten der Dialogbewertung sammeln müssen, da dies die Standardpraxis für die Bewertung von Chat-Modellen auf mehreren Niveaus ist. Durch unsere Analyse dieser Bewertungsresultate haben wir festgestellt, dass die ABC-Eval-Verhaltensbezeichnungen im Allgemeinen zuverlässig sind als die von den vorhandenen Methoden, wie der Interannotatorenvereinbarkeit auf 100 zweideutig beschrifteten Dialogen. Darüber hinaus sind die ABC-Eval-Verhaltensbezeichnungen im Vergleich zu den Metriken, die von den vorhandenen Methoden generiert werden, besser vorhersagend für die Gesamtkompetenz des Dialogs, wie durch diese einfache lineare Regression-Analyse gezeigt wird. Zum Beispiel erklären die Anteile der Runden mit Selbst- und Partner-Widersprüchen jeweils 5% und 10% der Dialogqualität, während die durchschnittlichen Likert-Konsistenz-Scores nur 4% oder weniger erklären können.

Zuletzt haben wir überprüft, ob jeder Bewertungsindex ein einzigartiges Aspekt der Dialogqualität abdeckt, indem wir eine Schrittweise lineare Regression durchführten. Sie können sehen, dass die Kombination aller ABC-Eval-Metriken die Qualität von über 25% erklären kann, und wenn Sie diese Metriken einer nach der anderen entfernen, verlieren sie einen bedeutenden Teil ihrer Information über die Qualität. Im Gegensatz dazu erklären die Kombination aller Turn-Level-Likert-Metriken viel weniger Qualität und weniger Metriken tragen ein einzigartiges Aspekt der Qualität. Die zuverlässigen, informellen und einzigartigen Metriken von ABC-Eval ermöglichen es uns, Conversational AI mit einer höheren Auflösung zu bewerten als die vorherigen Methoden. Sie können sehen, dass einige Herausforderungen immer noch bestehen und genaue Mengen angibt. Zum Beispiel haben die Bots, die wir getestet haben, in etwa 20% ihrer Antworten irgendeine Vernunftverstöße. Sie produzieren in etwa 15% ihrer Antworten irgendeine Irrelevanz und verletzen etwa 10% ihrer Antworten sich oder ihren Partnern. Aufgrund des raschen Fortschritts im Bereich sollten wir jedoch weiterhin nach zuverlässigen und genauen Bewertungsmetriken suchen, um die Modelle zu vergleichen. Wir hoffen, dass ABC-Eval für andere im Bereich als bedeutender Schritt in diesem Richtung genutzt werden kann. Und wir freuen uns darauf, wie Conversational AI im kommenden Monat und Jahr weiterentwickelt wird.</sample>
    <sample id="270">Emory University</sample>
    <sample id="271">Fine-Tuning</sample>
    <sample id="272">There are seven authors involved in the work.</sample>
    <sample id="273">Vielen Dank für Ihre Präsentation. Ihre Arbeit, die sich mit dem Thema "Wann benötigen Übersetzungen Kontext? Eine datenschrittliche, multilingualische Untersuchung" aufführt, sorgt für eine fundierte Analyse der Bedeutung von Kontext in Übersetzungsvorgängen. Durch die Verwendung des CXMI-Indikators können Sie die Bedeutung von Kontext für die Übersetzung von spezifischen Wortstücken identifizieren und diese Informationen zu einem umfassenden Benchmark für die Bewertung von Übersetzungssystemen beitragen.

Ihre Analyse zeigt, dass verschiedene Sprachen unterschiedliche Mengen an kontextabhängigen Übersetzungsproblemen haben, was auf die Notwendigkeit von individuell anpassbaren Übersetzungsmethoden hinweist. Ihre Messung der P-CXMI ermöglicht es, spezifische Phasen wie Formulärheit, Lexikalische Kohärenz und Ellipsenresolution zu identifizieren, was eine fundierte Grundlage für die Entwicklung und die Bewertung von Übersetzungssystemen bietet.

Es ist interessant zu sehen, dass die Performance von Übersetzungssystemen auf der Basis unterschiedlicher Metriken variieren kann, was darauf hindeutet, dass eine einheitliche Ansatzweise für die Bewertung von document-level Übersetzungssystemen schwierig sein könnte. Ihre Arbeit bietet also einen wichtigen Beitrag zur Verbesserung der Methoden und zur Verbesserung der Leistung von Übersetzungssystemen im allgemeinen.

Vielen Dank für Ihre detaillierte Präsentation und Ihre Beiträge zur Forschung im Bereich des maschinellen Übersetzens.</sample>
    <sample id="274">Yusen Zhang</sample>
    <sample id="276">IndicMT Eval ist ein Dataset zur Meta-Evaluation von Übersetzungsmetriken für indische Sprachen. Es untersucht die Korrelation zwischen verschiedenen Metriken und menschlichen Bewertungen auf englisch-übersetzten Sätzen in fünf indischen Sprachen (Tamil, Malayalam, Hindi, Marathi, Gujarati). Die Studie zeigt, dass IndicCOMET, ein überarbeitetes Metric, die korrelationen zu menschlichen Bewertungen verbessert, insbesondere bei Fehlern im Bereich der Grammatik. IndicCOMET zeigt auch eine höhere Robustheit im ACES Translation Accuracy Challenge Sets.</sample>
    <sample id="277">Multiset Tagging and Latent Permutations</sample>
    <sample id="278">Die Autoren beschreiben die Methode der "markierten Wörter" als eine Methode zur Identifizierung von Wörtern, die die Unterschiede zwischen markierten Gruppen und unmarkierten Gruppen betonen. Sie verwenden das sociolinguistische Konzept der "Markierung", das besagt, dass Gruppen, die sich von einer unmarkierten Defaultgruppe abheben, sprachlich markiert sind. Die Autoren vergleichen die Personas miteinander und verwenden gewichtete Log-Likertafeln (Fightin' Words) zur Erstellung von Log-Likertafeln, um die Wörter zu identifizieren, die die Unterschiede zwischen den markierten Gruppen und den unmarkierten Gruppen betonen.</sample>
    <sample id="279">The authors belong to the University of Washington.</sample>
    <sample id="280">Das Forschungsprojekt "MultiEMO: Ein Aufmerksamkeitsbasiertes Korrelationbewusstes Multimodales Fusion-System zur Emotionserkennung in Gesprächen" präsentiert eine neue Methode zur Emotionserkennung in Gesprächen. Das Hauptaugenmerk liegt auf der Integration von visueller, akustischer und textlicher Information. Der Vorschlag besteht darin, ein neues visuelles Feature extraktionsmodell (VisExtNet) zu verwenden, das sich auf die Gesichtsausdrücke der Gesprächspartner konzentriert und unbedingt die Umgebungswirkungen vermeidet. Darüber hinaus entwickelt der Forschungsteam ein Multimodales Fusion-Modell (MultiAttn), das visuelle, akustische und textliche Informationen miteinander verbindet. Zudem wurde ein Sample-Weighted Focal Contrastiv-Loss vorgestellt, um die Emotionserkennung in selteneren Emotionskategorien zu verbessern. Die experimentellen Ergebnisse zeigen eine hervorragende Leistung bei der Emotionserkennung in Gesprächen, insbesondere bei selteneren Emotionskategorien.</sample>
    <sample id="281">Das Team untersuchte die Bedeutung von Kontext in Übersetzungen und entwickelte ein Multilinguistisches Diskursbewusstes, oder MuDA, Tagger. Sie fanden, dass verschiedene Sprachen unterschiedliche Proportionen von diskursbezogenen Phänomenen aufweisen. Durch die Anwendung des MuDA-Taggers konnten sie die Genauigkeit unterschiedlicher Übersetzungssysteme auf dem Dokumentenebene messen. Das Ergebnis zeigt, dass kontextabhängige Modelle für bestimmte diskursbezogene Phänomene besser sind, aber nicht immer, was auf weitere Fortschritte im Bereich des Dokumentenebene-Übersetzens hinweist.</sample>
    <sample id="282">Das Team von Xuekai Zhu präsentiert "StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing" auf ACL 2023. Das Werk behebt das Problem der Textstilübersetzung auf der Story-Ebene, indem es Diskursepräsentationen von Quelltexten und stilbezogenen Embeddings verwendet. Die Methode umfasst zwei Phasen: die Übersetzung von Stilelementen mit Maskierung und die Füllung des Textes mit korrekten Stil-Spezifika. Ergebnisse zeigen eine bessere Stilkontrolle und Inhaltspreservation im Vergleich zu anderen Methoden.</sample>
    <sample id="283">Lisa, Bart und Maggie</sample>
    <sample id="284">FSUIE是一种新的模糊跨度机制，用于增强通用信息提取。它通过引入模糊跨度损失和可适应的注意力分布来缓解模型对跨度边界的依赖，并通过结合FSL和FSA实现显著性能提升。该方法在命名实体识别、关系抽取和方面情感三元组抽取等任务中表现出色。</sample>
    <sample id="285">Das Team von Peking University hat eine Forschungsarbeit vorgelegt, die sich auf die Korrektur von Faktenfehlern in Dialogsummarien konzentriert. Sie betonen die Bedeutung der korrekten Faktlichkeit in der Summarisation und zeigen, dass die aktuellen Faktenschätzungsmethoden nicht genug Berücksichtigung geben. Sie schlagen vor, die Korrektur von Faktenschätzungen mit einer umfassenden und genaueren Bewertung zu verbessern und präsentieren eine neue Klassifizierung von Faktenschätzungen.</sample>
    <sample id="286">James Finch und Sarah Finch</sample>
    <sample id="287">Javad Hosseini, Filip Radlinski, Silvia Pareti und Annie Louis</sample>
    <sample id="288">BLiMP und SyntaxGym</sample>
    <sample id="290">Die Abkürzungen der fünf Methoden für die erste Forschungsfrage sind: COSINE, FTw, FTS, FTL und FTLw.</sample>
    <sample id="291">Das Modell wird auf 11 Biomedizinischen und klinischen Aufgaben in Französisch evaluiert.</sample>
    <sample id="294">CamemBERT wurde ursprünglich mit 138 GB von Daten trainiert.</sample>
    <sample id="295">Adam Przepiórkowski</sample>
    <sample id="296">Eine Forschungsgruppe aus der Universität Turin und Amazon Alexa hat ein Dataset namens EPIC (English Perspectivist Irony Corpus) entwickelt, um die Analyse von Ironie in natürlicher Sprache zu verbessern. Das Dataset besteht aus über 300 kurzen Dialogen, die von mehreren Quellen wie sozialen Medien, Reddit und Twitter stammen und von mehreren Annotatoren in verschiedenen Sprachvariabilitäten überprüft wurden. Die Forscher haben verschiedene Perspektivmodellierungsmodelle entwickelt, um die Annahme zu überwinden, dass es eine einzige Wahrheit gibt, indem sie die Interaktionsweise zwischen verschiedenen Perspektiven im Text analysieren. Durch die Verwendung dieser Perspektivmodellierungsmodelle können die Modelle eine mehr informelle und genauerere Antwort auf die Ironie liefern.</sample>
    <sample id="297">Das Projekt "From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models" untersucht dogwhistles, coded rhetoric, die eine innere und eine externe Botschaft senden können. Der Fokus liegt auf antijüdischen, antirassistischen und antiproduktiven dogwhistles. Durch eine Typologie und Glossar werden dogwhistles mit Kontextinformationen identifiziert. Eine Studie zeigt, dass Sprachmodellen dogwhistles erkennen können, aber ihre Leistung variieren kann. Darüber hinaus wird gezeigt, wie dogwhistles bei Inhaltmoderationssystemen entweder erkannt oder nicht erkannt werden können.</sample>
    <sample id="298">Die Ergebnisse der Versuche, einige Modelle mit mehr aktuellen Daten zu retrainen oder weiterzubilden, zeigen, dass die Leistung abfällt, wenn der Zeitabstand zwischen der Trainings- und Testdaten größer wird. Dies bestätigt die Vermutung, dass die primäre Ursache für den Leistungsverlust die zeitliche Verzögerung ist.</sample>
    <sample id="299">NLI模型在各种基准测试中表现出色，但依赖于利用捷径。捷径是输入属性和标签之间的错误相关性，可能限制了它们的泛化能力。本研究提出了一种最小极大训练方法来减轻对捷径的依赖，并提高NLI模型的鲁棒性。该方法通过最大化损失来优化学习者和辅助模型，以确保良好的泛化性能。实验结果表明，在MNLI、FEVER和QQP数据集上，与标准训练模型和最佳捷径缓解方法相比，该方法在对抗性测试集上的表现更好。</sample>
    <sample id="300">Interactive dictation is a task that allows users to dictate and edit text using their voice in an intuitive manner. The work presented introduces this task, collects data for it, and creates a baseline system with four steps: ASR recognition, speech transcript segmentation, command extraction and normalization, and execution of each utterance until the final document state is reached. A new interface was designed for data collection, involving flexible interleaving of dictation and editing without fixed trigger words or commands. The dataset collected through this interface can facilitate future research on interactive dictation tasks.</sample>
    <sample id="302">Es ist notwendig, die Token für die Ausgabesequenz zu permutieren, um die korrekte Reihenfolge der Token im Output zu gewährleisten.</sample>
    <sample id="303">Die Autoren empfehlen, dass Modellentwickler*innen ihre Methoden zum Abbau von Vorurteilen transparenter machen sollten, weil es wichtig ist, die Ursachen für positive Stereotypien und essentialisierte Narrativen zu untersuchen. Darüber hinaus ist es notwendig, eine intersektionalen Ansicht zu verwenden, um mögliche Verletzungen zu übersehen, die durch das Studium von Vorurteilen verursacht werden könnten. Zudem ist Transparenz für die Untersuchung der Effektivität von Anti-Stereotypierungs-Methoden und die Identifizierung von ungewöhnlichen Wertallignementen notwendig.</sample>
    <sample id="304">Inakzeptable Minimalpaareingaben sind die, in denen der Kontext nicht mit den anderen Sätzen im Dataset übereinstimmt.</sample>
    <sample id="305">Das Vortrag über "Weaker Than You Think: A Critical Look at Weakly Supervised Learning" von Dawei, einem PhD-Studierenden an der Saarland University in Deutschland, diskutiert die Bedeutung von sauberen Validationsdaten für Weakly Supervised Learning (WSL). Das Hauptaugenmerk liegt auf der Notwendigkeit von sauberen Validationsdaten für die Verbesserung des WSL-Performance. Durch die Verwendung von sauberen Validationsdaten können WSL-Methoden besser trainiert werden und ihre Leistung erhöht. Der Vortrag zeigt auch, dass die Verbesserungen, die von WSL-Methoden geltend gemacht werden, durch die Fortsetzung der Fine-Tuning auf den sauberen Validationsdaten erreicht werden können.</sample>
    <sample id="306">Das Team von Sebastian Schuster und Najoung Kim untersuchte die Fähigkeit von Sprachmodellen, Entity Tracking zu erlernen. Sie entwickelten eine Aufgabe, bei der Sprachmodelle die Inhalte von Boxen vorherhatten, basierend auf Beschreibungen und Aktionen. Durch den Einsatz von Flan-T5 und GPT-3-Modellen konnten sie feststellen, dass nur GPT-3.5-Modelle, die Code in ihrem Trainingsdatensatz enthalten hatten, Entity Tracking-Fähigkeiten aufwiesen. Der Unterschied zwischen den Modellen kann auf das Vorhandensein von Code im Training zurückgeführt werden.</sample>
    <sample id="307">Die Autoren haben die Bewertungsmetriken für die verschiedenen Modelle verwendet, um sie zu vergleichen. Diese Metriken umfassen das Namenserkennungsvermögen, die Klassifizierungsfähigkeit, die Part-of-Speech-Tagging und die Fragebeantwortung.</sample>
    <sample id="308">Das Team untersucht die Positionalität von NLP-Datensätzen und -Modellen, indem sie sie mit diversen Annotatoren vergleicht. Sie zeigen, dass diese Technologien mehr an englischsprachige Länder und Menschen mit Hochschulabschluss angepasst sind, was zu einer Diskriminierung bestimmter Gruppen führen kann. Empfehlungen umfassen die Dokumentation von Designentscheidungen und die Entwicklung spezialisierten NLP-Technologie für bestimmte Gemeinschaften.</sample>
    <sample id="309">ABC-Eval</sample>
    <sample id="310">Wikipedia</sample>
    <sample id="311">The authors belong to the University of Trier.</sample>
    <sample id="312">MultiInstruct unterscheidet sich von anderen Benchmarks durch seine große Vielfalt an 62 verschiedenen multi-modalen Aufgaben aus 10 verschiedenen Kategorien, die auf 21 vorhandenen offenen Quellen-Datensätzen basieren. Außerdem bietet es fünf Expertengeschriebenere Anweisungen pro Aufgabe und verwendet OFA als Basismodell für die Multi-Modal-Analyse.</sample>
    <sample id="313">Zwei Autoren sind an der Arbeit beteiligt: James Finch und Sarah Finch.</sample>
    <sample id="314">In binären Koordinationen sind zwei Subjekte, Objekte oder Verbgruppen miteinander verbunden.</sample>
    <sample id="315">Die Prompts in dieser Studie waren im Durchschnitt 10 Wörter lang.</sample>
    <sample id="316">Die Ergebnisse des T5-Modells zeigen, dass es bei der Konstruierung von Scripts für konstruktionsbeschränkte Sprachplanung besser als die meisten großen Sprachmodellen ist. Dies zeigt, dass kleinere Modelle, wenn auf geeigneten Datensätzen ausreichend trainiert werden, die Leistung von großen Modellen übertreffen können.</sample>
    <sample id="317">CodeIE是一种信息抽取任务，将文本到结构化信息提取任务转化为结构到结构的代码生成任务。使用代码大型语言模型（如Codex）进行操作，可以轻松地在输入阶段将文本转换为结构化的格式，并确保输出阶段的结构一致。该方法在命名实体识别和关系抽取任务上进行了评估，发现使用代码语言模型和代码格式提示比传统基于文本的提示更有效。此外，使用Codex模型在信息抽取任务中表现更好，尤其是在召回方面。</sample>
    <sample id="318">Hi, ich bin Yanis Labrak und ich präsentiere unsere Arbeit "DrBERT: Ein robustes vorbereitetes Modell auf Französisch für medizinische und klinische Bereiche." Wir beginnen mit einem Überblick über Sprachmodellierung in der Gesundheitsversorgung. Dann präsentieren wir unsere Hauptbeiträge. Wir haben das erste medizinische Modell auf Französisch namens DrBERT entwickelt, basierend auf RoBERTa und trainiert auf NACHOS, einem Dataset von medizinischen Daten, die von der Web crawling erfasst wurden. Wir haben auch eine Vergleichung von Modellen mit verschiedenen Vorbereitungseinstellungen und Datenquellen vorgelegt. Danach präsentieren wir unsere Ergebnisse auf 11 medizinischen und klinischen Unternehmungen auf Französisch. Schließlich ziehen wir Schluss zu unseren Experimenten und geben Ihnen weitere Details über die Zugänglichkeit dieser Modelle. Seit seiner Einführung im Jahr 2018 hat BERT eine der effektivsten Ansätze zur Lösung natürlicher Sprachverarbeitungsprobleme entwickelt und bietet enorm große Leistungsverbesserungen gegenüber historischen statischen und kontextuellen Methoden wie Word2vec, fastText oder mehr. Seine Anpassung zu anderen Sprachen, wie zum Beispiel auf Französisch mit CamemBERT, und zu anderen Branchen wie medizinisch mit PubMedBERT und BioBERT und klinisch mit ClinicalBERT, aber hauptsächlich auf Englisch. Spezialisierte Modelle für andere Sprachen sind selten und werden meist durch kontinuumsbezogenes Vorbereiten durch die Mangel an in-domänner spezifischen Daten trainiert. Allerdings gab es auf Französisch keine offene Quelle für medizinische Modelle. Also fragen wir uns, welche die am besten geeignete Datenquelle für eine breite Palette von Anwendungen ist, und ob crawled Data eine gute Ersatzquelle für klinische Daten sind. Um diese Frage zu beantworten, verglichen wir DrBERT mit dem ChuBERT-Modell, das auf anonymisierten Daten aus der Datenbank des Hôpital Universitaire de Nantes basiert. Später fragen wir uns, wie viel Daten erforderlich sind, um ein spezialisiertes Modell auf Französisch zu trainieren. Ist es 4 GB, 8 GB oder mehr? Um diese Frage zu beantworten, erstellten wir zunächst vier von scratch-Modelle: eine erste Version von DrBERT mit 7 GB von NACHOS; eine zweite Version mit 4 GB von einer Kombination aus NACHOS; eine erste Version von ChuBERT, ein klinisches Modell mit 4 GB von Sätzen aus klinischen Notizen; und eine endgültige Version von ChuBERT mit einer Kombination aus 4 GB von einer Kombination aus NACHOS und 4 GB von klinischen Notizen. Insgesamt haben wir sieben Modelle. Um diese Modelle zu bewerten, sammelten wir Daten für öffentliche und private Downstream-Tasks wie Namenserkennung, Klassifizierung, Part-of-Speech-Tagging und Fragebeantwortung. Diese Modelle wurden mit sechs Baseline-Modellen verglichen, die CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, BioBERT und ClinicalBERT waren. Die Bewertung zeigt, dass die Modelle besser auf den Task leisten, den sie mit Daten des gleichen Typs trainiert wurden. Wir beobachten auch, dass Daten aus heterogenen Quellen mehr flexibel sind. Wir beobachten auch, dass mehr Daten zu besseren Leistungen führen. Im Ganzen haben die von scratch-Modelle die besten Ergebnisse auf neun der 11 Downstream-Tasks erreicht und überschritten das Ergebnis des allgemeinen Modells, hier CamemBERT. Wir beobachten auch, dass spezialisierte Daten besser sind, aber nicht in Skalierbarkeit. Alle vorbereiteten Modelle, die auf NACHOS trainiert wurden, sind kostenlos auf Hugging Face verfügbar und unter der MIT-Lizenz, und alle Trainingsskripte sind auf unserem GitHub-Repository verfügbar. Also danke Ihnen für diese Präsentation und freuen wir uns darauf, Sie auf der Poster-Sitzung in Toronto zu treffen.</sample>
    <sample id="319">Die Lernstrategien, die im Arbeit untersucht werden, sind das Training von Modellen auf einem 4-GByte-Satz von NACHOS und das kontinuumsweise Trainieren von Modellen mit dem Gewicht und der Tokenisierung von CamemBERT.</sample>
    <sample id="320">Der Faktor der Überanpassung, der auf die Wiederverwendung von Tests zurückzuführen ist, beträgt mehr als 1.</sample>
    <sample id="321">Die Qualität der Vereinfachung wurde aufgrund des Goldstandards, der von den manuell angepassten Sätzen im DEPLAIN-Corpus stammt, beurteilt.</sample>
    <sample id="322">Enrico präsentiert auf ACL 23 über die Frage, "Was lernt ein Text-Klassifizierer über Moralität?" Er erklärt, dass Moralität menschliche Entscheidungen zwischen richtig und falsch hilft, und dass es wichtig ist, dass Sprachmodelle die Moralität in Texten verstehen können. Er diskutiert, wie Sprachmodelle die Moralität in Texten verwalten, indem sie die Moral-Foundation-Theory anwenden, eine Theorie der moralischen Grundlagen. Er zeigt, dass Sprachmodelle die Unterschiede in der Ausdrucksweise von Moralen zwischen verschiedenen Themen erkennen können, wie zum Beispiel bei #AllLivesMatter und #BlackLivesMatter. Diese Unterschiede deuten darauf hin, dass die Verwendung eines einzigen Modells für verschiedene Themen zu Verstößen führen könnte.</sample>
    <sample id="323">DHLK ist ein Ansatz zur Lösung von Commonsense QA, der eine Optimierung des HKG-Strukturen und der KRL für die Verbesserung der Knowledge Representation in der Subgraph-Anzeige umfasst. Durch das Entfernen von subworden, die Phrase-Entitäten bilden, und die Verwendung von RoBERTa und Mask Self-Attention zum Codieren und Mischen der Kontexte und Entitäten wird die Interaktion zwischen den beiden Modalitäten verbessert. DHLK verwendet TransE für die Optimierung der Entity- und Relation-Embeddings im HKG und RMSA für die Modellierung der Subgraphen. Das Ansatz erzielt gute Ergebnisse auf CommonsenseQA und OpenBookQA mit externen Knowledgebäumen wie ConceptNet, WordNet und Wiktionary.</sample>
    <sample id="324">Ja, Sprachmodelle haben unterschiedliche politische Vorurteile.</sample>
    <sample id="325">Ja, das klingt sehr interessant. Ich würde gerne mehr über eure Forschung lernen und möglicherweise auch an eurer Poster präsentation teilnehmen.</sample>
    <sample id="326">Kognitive Dissonanz ist eine Situation, in der zwei Glaubens- oder Handlungsweisen konfliktieren.</sample>
    <sample id="327">ManagerTower ist ein neuer visuellt-lingwischer (VL) Modellarchitektur, die mehrere unimodale Experten bei verschiedenen Niveaus als Einblick in eine visuelle oder textuelle Encodung verwendet. Es verfügt über Managers in jedem visuellt-lingwischen Layer, die den Einblick der Experten aggregieren und kombinieren können. ManagerTower erzielt bessere Leistungen auf verschiedenen下游-Aufgaben, insbesondere im Vergleich zu METER und BridgeTower.</sample>
    <sample id="328">GPT-4</sample>
    <sample id="329">Das Team von Peking University präsentiert eine neue Methode für zero-shot Video-Sentence-Localization, die robust gegen Label-Rauschen ist. Sie generieren strukturierte Pseudolabellen und verbessern die Genauigkeit durch das Reduzieren der Rauschbeinmailtung. Ihre Methode erzielt die beste zero-shot-Leistung auf zwei Datasetts.</sample>
    <sample id="330">Ja, kumulatives Training ist besser als iteratives Training für aktives Lernen.</sample>
    <sample id="331">Sara Papi</sample>
    <sample id="332">Die Daten für die MuDa-Benchmark stammen aus Transkripten von TED-Vorträgen, die übersetzt wurden von Englisch ins gesamte Parallelcorpus in 14 Sprachen.</sample>
    <sample id="333">INK是一种新的训练框架，旨在通过根据最近邻知识逐步细化NMT模型的表示空间。它包括两个步骤：首先，使用KL散度调整表示，其次，使用更新后的表示异步刷新数据存储。实验结果表明，INK系统在平均COMET分数和BLEU分数上均优于最先进的kNN-MT系统，并且具有更好的翻译性能、更少的内存占用和更快的推理速度。</sample>
    <sample id="335">Matthias Lindemann</sample>
    <sample id="336">Sprachübergreifender Transfer bedeutet, dass man ein Modell trainiert, um auf mehreren Sprachen zu arbeiten.</sample>
    <sample id="337">Das Forschungsprojekt "Graph-basierte Relation Mining für kontextfreie außerhalb des Vokabulars-Einblicke in die Lernung von Wort-Embedding" präsentiert eine neue Methode zur Behandlung von außerhalb des Vokabulars (OOV) Wörtern. Der Ansatz basiert auf der Beobachtung der Wortbildung und des Assoziantionsprozesses bei OOV-Wörtern, um ihre Bedeutung zu infizieren. Eine Word-Relationen-Graphik wird entwickelt, die den Prozess nachahmt. Das Projekt verwendet Graph Attention Network (GAT) und Contrastive Learning, um die Wörter effektiv zu repräsentieren. Durch ausführliche Experimente wurde gezeigt, dass das Modell besser als Kontrastmodellen im Hinblick auf Intrinsic- und Extrinsic-Aufgaben leistet.</sample>
    <sample id="338">Das Forschungsprojekt "Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations" untersucht die Qualität von menschengelernten Erklärungen für maschinelle Lernmodelle. Durch eine einheitliche Datenstruktur und eine neue Bewertungsmethode, TREU, wird die hilfreichkeit der Erklärungen bei der Fine-Tuning- und Inferencephase untersucht. Ergebnisse zeigen, dass menschengelernte Erklärungen, auch wenn sie subjektiv erscheinen, den Modellen bei der Verbesserung ihrer Leistung helfen können. Die Forschung bietet einen Grundlage für eine sorgfältigere Zusammenarbeit zwischen Menschen und Maschinen in der Erstellung von Erklärungen.</sample>
    <sample id="339">Saarland University in Germany</sample>
    <sample id="340">ParaAMR ist ein großes, syntaktisch vielfältiges Paraphrase-Dataset, das durch AMR-Back-Translation erstellt wurde. Es nutzt AMR-Grafen, um die Semantik und Syntax von Satzen zu erfassen. Durch die Verwendung von AMR-Back-Translation können sie mehrere NLP-Anwendungen verbessern, wie zum Beispiel die Lernung von Sätzchen embeddings, die kontextuelle Paraphrase-Generierung und die Erweiterung von Daten für wenige-Schulungsbeispiele.</sample>
    <sample id="341">Die Autoren verwenden die Latenzmessungen "Average Lagging" und "Computational Aware Average Lagging".</sample>
    <sample id="342">LiveChat ist ein großes Chinesisch-Video-Datensatz für personalisierte Dialoge, der auf originellen TikTok-Videoerials aufgestellt wurde. Es umfasst die Erstellung von Dialogen durch eine Replikorrelationsmethode und die Sammlung von Persönlichkeitsinformationen. LiveChat verbessert die Leistung bei der Antwortmodellierung und der Addresseeerkennung im Vergleich zu anderen Datensätzen.</sample>
    <sample id="343">Natürlich Hier ist die Übersetzung des englischen Textes ins Deutsche:

"Hallo allein, ich bin Akshatha und heute zusammen mit meinem Kollegen Martin präsentieren wir unsere Arbeit 'The KITMUS-Test: Evaluating Knowledge Integration from Multiple Sources.' Diese Arbeit ist eine Zusammenarbeit zwischen McGill University, Mila und Microsoft Research. Sprachverstehende Modelle nutzen eine Vielzahl von Wissensquellen, wie zum Beispiel Wissen, das in ihren Parametern enthalten ist, meist durch ein Vortraining gewonnen, und Wissen, das bei der Inferenzzeit bereitgestellt wird. Jüngste Arbeiten in Aufgaben wie der Antwort auf Fragen zeigen, dass Modelle vortrainierter Wissen verwenden können, um Aufgaben zu lösen. Aber natürliche Sprache verständliche Aufgaben benötigen oft Wissen, das auch bei der Inferenzzeit bereitgestellt wird. Zum Beispiel in der Phrase: 'John sah den neu gewählten Präsidenten auf der TV.' Vorknow-how in den Parameters können Informationen über das, was Präsidenten tun, und was ein TV ist, enthalten, aber sie können nicht sicher wissen, wer diese spezifische Instanz "John" oder der neue Präsident ist, weil der Präsident seit dem Vortraining möglicherweise geändert wurde. Daher benötigen erfolgreiche Modelle für kennisintensive NLU-Aufgaben die Fähigkeit, Wissen aus verschiedenen Quellen zu integrieren und zu nutzen. In dieser Arbeit präsentieren wir eine Diagnostik-Test-Suite für die Integration von Wissen. Wir stellen eine Coreference Resolution-Task vor, die darauf abzielt, die Fähigkeit zu testen, Wissen aus verschiedenen Quellen zu nutzen. Wir evaluieren das Dataset mit Teilnehmern an einem menschlichen Studium und mit etablierten Coreference Resolution-Modellen. Hier ist ein Beispiel aus unserem Dataset. Servin ist ein Richter. Kea ist ein Backer. Servin und Kea trafen sich in einem Park. Nach einem langen Tag am Arbeitsplatz entschieden sie Fälle in einem Gericht, war er glücklich, sich zu entspannen. Das Problem hierbei besteht darin, den richtigen Entity, der das Pronomen "er" bezieht, zu identifizieren, was in diesem Fall Servin ist. Die Resolition eines gegebenen Pronomens erfordert zwei Arten von Informationen. Zunächst spezifisches Wissen wie "Servin ist Richter." Und zweitens Hintergrundwissen wie "Richter entscheiden Fälle im Gericht." Im Allgemeinen wird Hintergrundwissen während der Vortraining von großen Sprachmodellen gelernt, während spezifisches Wissen während der Inferenzzeit beobachtet wird. Wir variieren die Verfügbarkeit dieser beiden Informationsschnitte so, dass sie entweder in einer einzelnen Quelle gefunden werden kann, oder in mehreren Quellen. Wir haben drei Einstellungen von KITMUS definiert. Erstens haben wir die typische Einstellung: "Hintergrund-Pretrain", bei der das Hintergrundwissen angenommen wird, dass es im Vordruck enthalten ist. Zweitens haben wir eine "Hintergrund-Beide" Einstellung, bei der das Hintergrundwissen sowohl im Vordruck als auch bei der Inferenzzeit verfügbar ist. Drittens haben wir eine "Hintergrund-Inferenz" Einstellung, bei der beide Wissensarten nur bei der Inferenzzeit verfügbar sind. Diese letzte Einstellung ist besonders interessant, da sie die Situation simuliert, in der notwendiges Hintergrundwissen für die Lösung einer Aufgabe nicht im Vordruck der Modelle enthalten ist. Zum Beispiel, weil neue Berufe seit der Zeit des Vordrucks entwickelt wurden. Wir evaluieren das Dataset sowohl mit menschlichen Teilnehmern als auch mit etablierten Coreference Resolution-Modellen. Im folgenden Bild zeigen wir die Ergebnisse der besten Performing-Modelle im schwertesten Varianten der Hintergrund-Pretrain-Einstellung. Ohne spezifische Training auf KITMUS leisten beide Modelle nicht gut. Wenn sie auf KITMUS trainiert werden, führen beide C2F und BERT4Coref signifikant besser als der Zufall. Dies suggeriert, dass Modelle, die auf generellen Referenzresolutionsdaten gespeichert wurden, ohne Task-Spezifika, meist nur Oberflächliche Anhaltspunkte nutzen, die bei der Testaufgabe KITMUS nicht nützlich sind, da solche Anhaltspunkte wurden entfernt. Zusätzliche Experimente mit fiktionalen Kenntnissen deuten darauf hin, dass sogar die besten Performing-Modelle Schwierigkeiten haben, Wissen aus verschiedenen Quellen zu integrieren. Insgesamt können viele Coreference Resolution-Modelle ohne taskbezogenes Training keine Wissen aus verschiedenen Quellen integrieren. Allerdings können einige Modelle, wenn sie auf spezifische Training auf KITMUS unterzogen werden, erfolgreich Wissen aus verschiedenen Quellen integrieren. Dennoch scheinen sogar die besten Performing-Modelle Schwierigkeiten zu haben, das Wissen aus den Hintergrundinformationen zu integrieren, die nur bei der Inferenzzeit verfügbar sind. Wenn Sie mehr Details erfahren möchten, lesen Sie unsere Arbeit und besuchen Sie das Dataset und das Code auf GitHub. Vielen Dank für Ihre Aufmerksamkeit."</sample>
    <sample id="344">Obtaining trees can be complicated and computationally expensive.</sample>
    <sample id="345">Das Paper "Compositional Generalization without Trees using Multiset Tagging and Latent Permutations" von Matthias Lindemann und seinen Advisors Alexander Koller und Ivan Titov präsentiert eine neue Methode zur kompositionellen allgemeinheitlichen Modellierung in der Semantic Parsing. Stattdessen als traditionelle Baummodell zu arbeiten, verwenden die Autoren eine neuralen Seq2Seq-Modell, das die korrespondierenden Fragmente des Inputs mit den Fragmen des Outputs identifiziert. Diese Methode ermöglicht es dem Modell, ohne Baumstruktur zu benötigen, auf komplexe, kompositionale Strukturen zu generalisieren. Der Prozess umfasst zwei Schritte: Zunächst wird jeder Input-Tokenn mit einer unordentlichen Menge an Tokken, die im Output vorkommen werden, versehen. Im zweiten Schritt wird ein permutationales Modell verwendet, um die Tokken in der richtigen Reihenfolge zu platzieren. Das Team hat ihre Methode auf dem COGS-Benchmark getestet und hat eine hervorragende Leistung bei der allgemeinheitlichen Kompositionsskala erreicht.</sample>
    <sample id="346">The authors belong to the University of Edinburgh.</sample>
    <sample id="347">Natürlich Hier ist die Übersetzung des englischen Textes ins Deutsche:

"Hallo, ich bin Myra und heute spreche ich über unsere Arbeit 'Markierte Persönlichkeiten: Durch natürliche Sprache-Stimuli zur Messung von Stereotypeien in Sprachmodellen.' Diese Arbeit wurde gemeinsam mit Esin Durmus und Dan Jurafsky erstellt. In den letzten Jahren wurden viele Beispiele für die Präsenz von sozialen Biase und Stereotypen in großen Sprachmodellen dokumentiert. Allerdings haben diese Messungen mehrere Einschränkungen. Sie basieren meist auf hand-gestellten Daten, die sehr Zeitverbrauchend zu curaten sind, und sie messen meist nur sehr spezifische Stereotypien, was bedeutet, dass sie nicht gut auf andere Demografien oder Kontexte übertragen werden, oder sie einfache, breite Verbindungen wie negative Assoziationen mit bestimmten Gruppen einfangen. Darüber hinaus fällt bei der meisten Arbeit in diesem Bereich keine Achtung auf das Intersektionalität, das die Idee ist, dass multifaktorielle soziale Identitäten Kombinationsbiase und einzigartige Schäden anrichten können. Um diese Einschränkungen zu überwinden, bauen wir uns auf die Eigenschaft ab, dass diese newer, instruktionsausgerichteten Sprachmodelle sehr gut auf Anweisungen und Prompts reagieren können. Wir können den Modellnachweis einer Person, die eine Beschreibung eines imaginären Individuums mit einem Prompt wie 'Bildiere ein asiatisches Weib. Beschreibe dich.' generiert. Dies ist sehr allgemein anwendbar, da wir jede gewünschte Identitätsmarke einfach in diesem Prompt einfügen können. Hier sind einige Beispielgenerierungen von GPT-4. Wir sehen sofort, dass diese Ergebnisse nicht overt negative oder giftige sind im traditionellen Sinne dieser Wörter, aber es gibt einige interessante Muster. Die asiatische Frau wird als unaufdringlich dargestellt; die mittelorientale Frau wird mit Worten wie 'exotisch' bezeichnet, was eine faszinierende Region andeutet. Und sowohl die Persönlichkeiten von Frauen der Farbe erwähnen ihre Abstammung, während die weiße Mannsperson nichts ähnliches tut. Um diese Muster zu erfassen, haben wir zwei Teile unseres Ansatzes. Der erste Teil besteht darin, diese Persönlichkeiten zu generieren. Unsere Prompts zur Generierung dieser Persönlichkeiten waren inspiriert von einem Studium, bei dem sie diesen Prompts für menschliche Subjekte gegebenen und fanden, dass dies Rassentypen ausgesetzt. Dies ermöglicht auch eine direkte Vergleichung zwischen unseren generierten Persönlichkeiten und den menschlichen geschriebenen Antworten. Der zweite Teil ist Markiertes Wort, ein Methodenansatz, um die Wörter zu identifizieren, die die Unterschiede zwischen markierten Gruppen und unmarkierten Gruppen festlegen. Das Vorteil ist, dass wir spezifische Stereotypien und Muster ohne dass wir irgendein bestimmtes Lexikon verwenden können. Das Markiertes Wort-Methoden basiert auf der sociolinguistischen Begrifflichkeit 'Markierung', der besagt, dass es einen unmarkierten Default gibt und jede Gruppe, die sich von diesem Default abhebt, sprachlich markiert ist. Zum Beispiel wird der Begriff 'Krieger' meist mit Männern assoziiert. Wenn Menschen eine Kriegerin beschreiben, die eine Frau ist, werden sie typischerweise 'Frau Kriegerin' beschriftet und das Wort 'Kriegerin' markieren. Im Allgemeinen sind dominante Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während marginalisierte Gruppen meist markiert sind. In unserem Ansatz erstellen wir zunächst die unmarkierten und markierten Gruppen und vergleichen dann die Persönlichkeiten miteinander mithilfe des Fightin' Words-Methodes, der Gewichtete Log-Likelihoods-Ratios verwendet, um die top-10-Wörter für jeden markierten Gruppengruppen zu identifizieren. Zum Beispiel vergleichen wir die Log-Likelihoods-Ratios für die Persönlichkeiten von schwarzen Frauen gegenüber den Persönlichkeiten von weißen Personen und Männer, weil diese die entsprechenden unmarkierten Gruppen sind. Aufgrund unserer Ergebnisse finden wir, dass die generierten Persönlichkeiten viel mehr Stereotypien enthalten als die menschlich geschriebenen Persönlichkeiten. Allerdings finden wir, wenn wir die Verteilung der Wörter und des Lexicons betrachten, dass die menschlich geschriebenen Persönlichkeiten eine viel breitere Verteilung von Wörtern haben, während die stereotypischen Wörter in den generierten Persönlichkeiten nur die Wörter 'groß' und 'athletisch' sind. Diese Lexikon bietet nicht einmal viele der schädlichen Muster, die wir in früheren Slides gesehen haben. Stattdessen werden wir uns auf die Ergebnisse unseres Marked-Words-Methodens wenden, um diese positiv scheinenden Wörter zu analysieren, wie sie Stereotypien und essentialisierende Narrative reflektieren. In unserer Analyse zeigen wir, wie diese positiv scheinenden Porträts die schädlichen Muster widergeben. Zunächst unterscheiden die Gruppen die Wörter wie 'Kultur', 'Tradition', 'Stolz' und 'exotisch'. Diese Wörter definieren diese Gruppen durch ihre Beziehung zu ihrer Identität und unterscheiden sie von der weißen Normalität. Dies trägt zu einer langen Tradition der Diskriminierung und Andeutung für diese Gruppen bei. Darüber hinaus spiegeln die Wörter, die für latinsische Frauen beschrieben werden, wie zum Beispiel 'vibrant' und 'curvaceous', ein tropisches Archetyp wider, das eine tropische Attraktivität und eine bestimmte Erscheinungsvorstellung widerspiegelt. Für asiatische Frauen sind Wörter wie 'klein' und 'schön' und 'silky' zu finden, die eine lange Geschichte von Hypersexualisierung und submissiver Erscheinung widerspiegeln. Und für schwarze Frauen sind Wörter wie 'stark' und 'resilient' zu finden, die eine Archetyp widerspiegeln, das 'Starkes Schwarzes Weibchen-Archetyp'. Obwohl es auf den ersten Blick positiv erscheint, hat es gezeigt, dass dieses Archetyp schädliche Folgen hat, indem es den Druck auf diese Demografien erhöht, gegen soziale Hindernisse allein zu kämpfen, anstatt diese Hindernisse zu ändern. Im Ganzen zeigen unsere Ergebnisse, dass die Wörter für jede markierte Gruppe essentielle Narrativen widerspiegeln. Basierend auf diesen Mustern, schließen wir drei Empfehlungen für Modelleigner an: Zuerst sollten Forscher positive Stereotypien und essentielle Narrativen untersuchen. Zweitens sollten sie ein intersektionaler Blick auf Biase und Schäden einziehen, weil viele Dinge möglicherweise übersieht werden, wenn man nicht auf diese Weise arbeitet. Schließlich sollte es mehr Transparenz über Biase-Mitigationsmethoden geben, weil zum Beispiel positive Stereotypien vielleicht auf irgendeine Art übermäßig-alien-Verhaltensweise oder andere Anti-Stereotypmethoden zurückzuführen sind, die diese verurious Muster erzeugen. Wir können keine Annahmen treffen oder weiterhin untersuchen, ohne mehr Transparenz. Vielen Dank fürs Zuhören.</sample>
    <sample id="348">Das Paper "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models" untersucht die Präsenz von Rassismus und Stereotypien in LLMs. Es bietet eine Methode, indem es Personas mit bestimmten Identitätsmerkmalern generiert, um die Verbreitung von stereotypischen Narrativen zu erforschen. Durch das Vergleich der Personas mit den menschlichen Schreibungen werden positive Stereotypien und essentialisierte Narrativen identifiziert, die dazu beitragen können, dass diese Gruppen als anders oder weniger wertvoll betrachtet werden. Das Team schlägt vor, Forscher, Modelleigentümer und -Entwickler, ihre Methoden für den Umgang mit positiven Stereotypien und die Transparenz über ihre Bemühungen gegen Rassismus zu erhöhen.</sample>
    <sample id="349">Ja, das ist richtig. Wir möchten eine kurze Werbung für unser Forschungsarbeit präsentieren.</sample>
    <sample id="350">Das Paper "What’s the Meaning of Superhuman Performance in Today’s NLU?" untersucht die Zuverlässigkeit der Leaderboard-Evaluation von Modellen im Vergleich zu menschlicher Leistung. Durch eine Analyse der SuperGLUE- und SQuAD-Benchmarks zeigt das Team, dass menschliche Leistungen in einigen Aufgaben nicht immer überdacht sind. Die Researchers betonen, dass der Vergleich zwischen menschlichen und modellbasierten Leistungen aufgrund unterschiedlicher Evaluationssätze, Fehlende Anatomie und ungewissen Informationen über die Annotatorenpool nicht zuverlässig ist. Sie empfehlen, die Benchmarks besser zu konstruieren, um solche Probleme zu vermeiden.</sample>
    <sample id="351">Das Paper untersucht die Probleme der allgemeinheit im NER-Task und entwickelt die CoNLL++ Dataset, um mehrere Modelle auf CoNLL-2003 zu fine-tunen. Durch die Analyse der F1-Werte auf CoNLL-03 und CoNLL++ wird festgestellt, dass ein besserer Modellarchitektur, größere Modelle und mehr Fine-Tuning-Beispiele für eine gute allgemeinheit von Modellen erforderlich sind. Der Hauptgrund für die Performanzabnutzung wird als Temporal drift, das durch den Zeitabstand zwischen Trainings- und Testdaten bestimmt wird, erkannt. Das Paper zeigt, dass CoNLL-2003-Tagger in 2023 noch gut funktionieren können.</sample>
    <sample id="352">ABC-Eval steht für "Annotating Behaviors in Chat".</sample>
    <sample id="353">Code generation by asking clarification questions is a promising approach to address the challenge of input underspecification in code generation and program synthesis. The paper introduces CodeClarQA, a synthetic dataset with clarifications on key operations, and proposes a pipeline for generating code through interaction-based question-answering (CQAs). They focus on operation-level specifications and use templates to create CQAs for missing key operations. Their method effectively creates CQAs for missing key operations but faces challenges such as taxonomy errors and argument errors. The results show that their task is more challenging than existing CQ ranking tasks, and training with Oracle CQAs leads to predictions close to ground truth. However, there are still minor differences due to top-ranked CQs not being included in reference CQAs.</sample>
    <sample id="354">2023</sample>
    <sample id="355">Entschuldigung, ich sehe, dass Sie eine Präsentation über "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge" von Vasudha und ihren Kollegen vorbereiten. Ich kann Ihnen bei der Übersetzung des Textes helfen. Bitte geben Sie mir den englischen Text, den Sie verwenden möchten, und ich werde es für Sie ins Deutsche übersetzen.

Auch wenn ich nicht in der Lage bin, die gesamte Präsentation zu übersetzen, kann ich Ihnen bei der Übersetzung einzelner Abschnitte oder Segmente helfen. Bitte geben Sie mir den Text, den Sie überarbeiten möchten, und ich werde es für Sie ins Deutsche übersetzen.

Sollten Sie weitere Fragen haben oder Hilfe benötigen, um die Übersetzung zu kontrollieren, stehe ich Ihnen gerne zur Verfügung.</sample>
    <sample id="356">The authors belong to the University of Massachusetts Amherst.</sample>
    <sample id="357">Siyu Yuan</sample>
    <sample id="358">Fünf Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="359">Der Ansatz wird mit den folgenden SimulST-Architekturen verglichen: Wait-k, Local Agreement und ein speziell für die gleichzeitige Vorbetranslation entwickeltes Architektur.</sample>
    <sample id="361">Armineh Nourbakhsh präsentiert "CounterComp", ein Ansatz zur Verbesserung der kompositionellen allgemeinheit für quantitative, mehrschrittige Frage-Beantwortungsaufgaben. Durch die Analyse von verstreuten Faktoren in der Eingabe und die Erstellung von positiven und negativen Beispielen kann das Modell besser auf wichtige Tokens im Input-Text aufmerksam sein. Dies verbessert die Leistung bei der kompositionellen Allgemeinheit, insbesondere bei mehr als zwei Schritten.</sample>
  </task>
</testset>