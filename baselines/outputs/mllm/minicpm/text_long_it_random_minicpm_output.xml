<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="it">
    <sample id="0">I modelli linguistici sono trainati su grandi quantità di dati estratti da crawlers web. Questi crawlers coprono una vasta gamma di fonti, tra cui notizie politiche, social media e altri tipi di contenuti online. Uno dei dataset più importanti utilizzati è il C4 Corpus, che include notizie da fonti come il New York Times, il Los Angeles Times, The Guardian e Huffington Post.</sample>
    <sample id="1">McGill University, Mila, and Microsoft Research</sample>
    <sample id="2">Il paper intitolato "LayoutMask: A Novel Pre-trained Model for Visually-rich Document Understanding" presenta un approccio innovativo per la comprensione dei documenti a larga gamma, utilizzando una nuova modellazione pre-training chiamata LayoutMask. Questo modello utilizza solo informazioni testuali e layout come input e si concentra su migliorare le interazioni tra testo e layout durante il processo di pre-training. La LayoutMask utilizza tre principali differenze rispetto ai modelli precedenti: la scelta della posizione 1D locale, una strategia di maschera diversa e obiettivi di pre-training diversi. La posizione 1D locale utilizza l'ordine del token all'interno di ogni segmento invece che un ordine globale, che non fornisce informazioni sulle relazioni tra i segmenti. Per ulteriormente promuovere le interazioni tra testo e layout, LayoutMask utilizza due nuove strategie di maschera: Masked Language Modeling con maschera a livello di intero parola e Masked Position Modeling con maschera a livello di posizione a due dimensioni. I risultati delle sperimentazioni mostrano che LayoutMask ottiene prestazioni migliori rispetto a LayoutMask con informazioni layout globali, in particolare per entity "Total".</sample>
    <sample id="3">Ciao Siamo qui per presentarti DEPLAIN, un nuovo corpus per l'identificazione del testo in Germania a livello di documento e a livello di frase. Mi chiamo Regina Stodden e vi guiderò attraverso la prima parte della presentazione. Per prima cosa, definiamo la semplificazione del testo: è un processo che consiste nell'adattare un testo per migliorare la comprensione del testo per un gruppo specifico di destinatari, come persone con problemi di lettura o utenti non nativi. Per addestrare un modello di semplificazione del testo, abbiamo bisogno di pair paralleli di testi, ad esempio di documenti o di frasi. Vedete qui un esempio di pair parallelo di una frase complessa tedesca e della sua traduzione in lingua semplice. Per semplificare la frase, si possono utilizzare diverse tecniche, come sostituzione lexica, eliminazione delle clausole, riordinamento o incorporazione di parole. Ora propongiamo il nostro nuovo corpus, DEPLAIN, perché negli ultimi anni ci sono stati alcuni problemi con i corpi esistenti. Per esempio, questi corpi sono troppo piccoli per addestrare un modello di semplificazione del testo. I tre modelli proposti negli ultimi anni sono tutti alignati automaticamente, che significa che possono essere errornei nelle loro alignamenti. Pertanto, propongiamo il nostro nuovo corpus DEPLAIN, suddiviso in due subcorpi: DEPLAIN-apa e DEPLAIN-web. DEPLAIN-apa è basato su testi di notizie. In DEPLAIN-apa, abbiamo alignato manualmente 483 documenti, ottenendo circa 13.000 pair paralleli di frasi. Per DEPLAIN-web, questo corpus include diversi domini e abbiamo anche alignato tutti questi 750 documenti, entrambe manualmente e con metodi di alignamento automatico. In totale otteniamo 30.450 pair di frasi. Analizzando i nostri pair di frasi, scopriamo che il testo biblico è molto più semplificato rispetto ai testi di notizie o ai testi per gli studenti di lingua straniera. A tutti i livelli, rispetto ad esempio alla sostituzione lexica, alle clausole, all'interfaccia complessità globale, il testo biblico è molto più semplificato. Inoltre, vediamo che il nostro corpus DEPLAIN ha una grande varietà di trasformazioni di semplificazione. Ad esempio, nel corpus DEPLAIN-apa abbiamo molte più reorganizzazioni e incorporazioni di parole rispetto al corpus DEPLAIN-web. Dall'altra parte, nel corpus DEPLAIN-web abbiamo molte più riflessioni. Quindi, qual è il modo in cui possiamo utilizzare questo corpus? Ciao, mi chiamo Omar e ora parlerò delle applicazioni del nostro dataset DEPLAIN. La prima applicazione è l'evaluazione di metodi di alignamento automatici. Negli ultimi anni, ci sono stati molti metodi di alignamento automatico, ma nel contesto dei traduzioni automatiche, dove abbiamo due documenti paralleli scritti in due linguaggi differenti e vogliamo estrarre le alignamenti delle frasi in entrambi i documenti. Ma nel nostro caso, stiamo cercando di estrarre le alignamenti tra le frasi di due documenti paralleli scritti nel medesimo linguaggio, con lo stesso contenuto, ma con livelli di complessità diversi. E ora, grazie alla nostra dataset DEPLAIN, che ha le frasi parallele manualmente alignate, possiamo utilizzarle come standard gold alignments per valutare i metodi di alignamento automatici proposti. Abbiamo adattato alcuni dei metodi proposti e abbiamo pubblicato tutti gli adattamenti e i codici per eseguire i nostri esperimenti nel nostro paper. In fine, concluisciamo che il miglior metodo automatico di alignamento per la semplificazione del testo tedesco è MASSalign. E se volete eseguire i nostri esperimenti su vostre documentazioni, potete trovare i checkpoint e ulteriori dettagli sulle punteggiature e sui metodi di valutazione nelle nostre esperienze nel nostro paper. La seconda applicazione che abbiamo mostrato nel nostro paper è quella dell'auto-simplificazione del testo tramite l'addestramento fine-tuning dei modelli linguistici per produrre testi semplificati dal testo complesso d'ingresso. Abbiamo addestrato due modelli: abbiamo addestrato il modello long-mBART per produrre semplificazioni a livello di documento e abbiamo anche addestrato il modello base mBART per produrre semplificazioni a livello di frase. Potete trovare tutti i checkpoint e ulteriori dettagli sulle punteggiature e sulle valutazioni nelle nostre esperienze nel nostro paper. Concludiamo che questo addestramento fine-tuning produce punteggi migliori rispetto ai baseline e proponiamo queste risposte come benchmark per il problema della semplificazione del testo automatico nel futuro. Grazie per la vostra attenzione e speriamo di incontrarvi durante la conferenza. Grazie mille.</sample>
    <sample id="4">Kayo Yin</sample>
    <sample id="5">Hanno utilizzato il modello T5 XL.</sample>
    <sample id="6">Jiaan presented their work, "Towards Unifying Multi-Lingual and Cross-Lingual Summarization", a joint effort with Fandong, Duo, Yunlong, Zhixu, Jianfeng, and Jie. They introduced many-to-many summarization as an approach to unify previous multilingual and cross-lingual summarization methods into one model capable of processing any source language document and generating its summary in any target language. The study found that this method allows the summarization model to better transfer task knowledge across different languages than existing approaches.

Jiaan also proposed PISCES (Pre-trained Instructed Sequence-to-Sequence for Cross-lingual Summarization), a pre-trained many-to-many summarization model trained through three stages: meta pre-training, cross-lingual pre-training, and task-specific pre-training. Experimental results showed that PISCES outperformed various baselines including mBART-50 and mT5. Additionally, ablation studies verified the effectiveness of each training stage, and human studies demonstrated the superiority of PISCES over other models.</sample>
    <sample id="7">Sì, i tagger CoNLL-2003 funzionano ancora.</sample>
    <sample id="8">ABC-Eval è una nuova strategia per la valutazione umana che consiste nell'annotare specificamente se un modello di chat esprime certi comportamenti, come rispondere con informazioni irrelevanti o contraddire se stesso o il suo interlocutore.</sample>
    <sample id="9">Il successo dell'approccio scarsamente supervisionato è basato in larga misura sull'accesso a set di validationi o test con etichette corrette.</sample>
    <sample id="10">Per migliorare il punteggio, è possibile aiutare i modelli di linguaggio a avere accesso a informazioni di background più complete, sia overlapping che esclusivamente. Inoltre, è importante sfruttare le differenze tra i modelli di dominio per migliorare le prestazioni.</sample>
    <sample id="11">Il ricercatore di scienze dell'intelligenza artificiale Jack Hessel ha presentato "Do Androids Laugh at Electric Sheep? Understanding Humor Benchmarks from The New Yorker Caption Contest" in ACL. Ha esaminato la capacità di modelli di linguaggio grandi come ChatGPT e GPT-4 a comprendere il senso delhumor, utilizzando il contest di scrittura di testo del New Yorker. I modelli hanno raggiunto un'precisione del 62% nel compito di corrispondenza e del 94% nel compito di valutazione di qualità, rispetto alle performance umane del 94% e del 70% rispettivamente. Hessel ha evidenziato alcune errori nella spiegazione del humor dei modelli di linguaggio e ha chiamato a sospettare la loro comprensione del senso delhumor.</sample>
    <sample id="12">L'articolo è coauthorato da 5 autori: Xiaoyu Shen, Marius Mosbach, Andreas Stephan e Dietrich Klakow.</sample>
    <sample id="13">Adaptive inference è un metodo per ridurre il tempo di inferenza dei modelli di linguaggio grandi. Utilizzando l'idea che i dati del mondo reale variano in complessità, si possono utilizzare modelli a bassa capacità per i campi facili e ridurre così le coste di calcolo, sia in termini di tempo che di denaro. I metodi più comuni di inferenza adattativa sono Multi Model e Early Exit. In Multi Model, vengono utilizzati modelli separati con classificatori al termine, trainati separatamente e utilizzati sequentialmente durante l'inferenza. In Early Exit, vengono utilizzati classificatori separati che vengono trainati insieme e utilizzati durante l'inferenza quando un classificatore decide di interrompere la calcolazione. Il chief investigator ha esaminato i pros e cons di entrambi i metodi, evidenziando che Multi Model è più versatile ma costoso da archiviare e ha un costo di calcolo elettrico, mentre Early Exit è più rapido ma ha un costo di calcolo elettrico e potrebbe presentare problemi di performance a causa delle gradienti conflittanti tra i classificatori. Per risolvere questo problema, l'investigatore ha sviluppato SWEET (Separating Weights in Early Exit Transformers), un nuovo metodo di adattamento per Early Exit che utilizza solo gli aggiornamenti di ogni classificatore per le rispettive layer del modello, evitando così i gradienti conflittanti. Le prove mostrano che SWEET chiude la maggior parte della gap tra Early Exit e Multi Model, riducendo così le coste di calcolo elettrico e migliorando le prestazioni generali.</sample>
    <sample id="14">Ciao, mi chiamo Adam Przepiórkowski e sto parlando della Struttura dipendenziale della coordinazione. Come siete forse sapete, esistono diversi modelli di struttura dipendenziale assunta da teorie e approcci corporativi diversi. Ad esempio, nelle Universal Dependencies, la coordinazione è strutturata in modo che il primo soggetto sia capo della struttura itself. In questo caso, Lisa. Un approccio simile viene assunto anche nella teoria del testo del linguaggio di Igor Mel'čuk, dove ancora una volta la struttura coordinata è capo del primo soggetto. Queste due approache sono asimmetriche. Si singola un soggetto tra i due. Esistono anche approcci asimmetrici come quello del Prague Dependency Treebanks, dove le coordinate sono capite come governate dal conjunction. In questo caso, otteniamo delle dipendenze dal capo alla fine di tutti i soggetti. Infine, c'è anche un approccio multi-capo come quello utilizzato nell'Hudson's Word Grammar, dove tutti i soggetti sono capi della struttura coordinata. Otteniamo delle dipendenze dal capo a tutti i soggetti separatamente: Lisa, Bart e Maggie. Ora, l'obiettivo di questo paper è produrre una nuova discussione per la struttura dipendenziale simmetrica, come queste due, contro le strutture dipendenziali asimmetriche, come queste due. L'argomento si basa sul principio della minimizzazione della lunghezza dipendenziale che spiego con l'aiuto di questi esempi. In inglese, come siete tutti sicuri, gli oggetti direttivi preferiscono essere vicini al verbo, mentre gli adjuncti possono essere più lontani. "Marge ha letto oggi" è ok perché l'oggetto direttivo è vicino al verbo, mentre "Marge ha letto oggi questo libro" è molto peggio. Perché tra il verbo e l'oggetto direttivo c'è un adjunct: "oggi". Tuttavia, questo effetto può essere mitigato quando l'oggetto direttivo è molto pesante e lungo. Poiché può essere spostato dopo l'adjunto. Questo è illustrato qui. Sia queste due frasi sono ok. "Marge ha letto questo libro affascinante sui api oggi." È ok se sostituisce "questo libro" con questo lungo NP. Ma è anche ok dire "Marge è venuta e ha bocciato oggi questo libro affascinante sui api." La ragione è che questa frase viola il principio generale grammaticale che gli oggetti direttivi devono essere vicini al verbo, ma soddisfa il principio della minimizzazione della lunghezza dipendenziale, che dice che le dipendenze più brevi sono preferite. Queste due alberi mostrano solo le dipendenze cruciali, quelle che non sono costanti tra queste due strutture. Qui abbiamo una dipendenza dal verbo "ha letto" all'adjunto di lunghezza 7 misurata in parole e una dipendenza dal verbo "ha letto" a "libro" di lunghezza 4, quindi insieme è 11. Quando si cambiano questi due costituenti, la somma delle due dipendenze diventa 6. Più piccolo di 11, quindi è ok. Ok. Quello che abbiamo fatto è estrarre statistiche varie sulla coordinazione dall'edizione enhancement del Penn Treebank e vedremmo nel paper "Perché non usi le Universal Dependencies" e queste statistiche confermano l'osservazione fatta molte volte prima che gli oggetti direttivi sinistra tendono a essere più corti. E anche l'osservazione fatta in parsing che questa tendenza cresce con la differenza di lunghezza. Quando la differenza tra le lunghezze dei due oggetti si amplifica, l'oggetto sinistro tende a essere più corto; la maggior parte della maggiore differenza tra i due oggetti. Ma cosa è nuovissimo in questo paper è che abbiamo osservato che questa tendenza si perdona quando il governante è sulla sinistra, come qui "Vedo Bart e Lisa" o quando il governante è assente, come qui "Homer è venuto e ha bocciato." Questo effetto si perdona. Mostreremo nel paper come questo fornisca un argomento contro le strutture dipendenziali asimmetriche, come queste due, e per le strutture dipendenziali simmetriche, come queste due. Vedremmo nel paper per le discussioni complete e parliamo con noi durante la sessione poster. Grazie.</sample>
    <sample id="15">Quelli che hanno scritto l'articolo sono tre: Matthias Lindemann, Alexander Koller e Ivan Titov.</sample>
    <sample id="16">I bibbi sono molto più semplificati rispetto ai seguenti domini: i documenti di notizie, i testi per gli studenti di lingua e i testi per i lettori non nativi.</sample>
    <sample id="17">Il progetto sviluppato da Shengqiong Wu, PhD student al NUS, si concentra sulla extrazione di relazioni multimediali. Tale task consiste in determinare la relazione semantica tra entity in un testo. Tuttavia, in alcune situazioni realistiche, come queglie social media, i dati sono spesso in forma e modalità diverse e non solo testuali. La soluzione proposta consiste in una divisione fine-grained delle informazioni tra i due moduli, visuali e textuali, e l'introduzione di informazioni tematiche esterne. I risultati degli esperimenti mostrano che il sistema proposto ottiene le migliori prestazioni tra i baselines multimediali esistenti.</sample>
    <sample id="18">L'esempio della preferenza per i congiunti a sinistra più brevi è "Lisa, Bart e Maggie".</sample>
    <sample id="19">Zhang Qin, un studente magistrale del Shenzhen University, presenta il loro lavoro accettato alla ACL 2023: "A Survey for Efficient Open Domain Question Answering". La loro focus è su risolvere i problemi di efficienza nel campo dell'analisi del linguaggio aperto. Introducono la struttura a due fasi proposta da Danqi Chen nel 2017, che utilizza una ricerca e una lettura per trovare risposte. Discussano le sfide della ricerca del linguaggio aperto, come la grandezza del corpus di Wikipedia e l'archivio di indexation. Proposono delle soluzioni per ridurre i costi di memoria e l'assegnazione rapida, come la ricerca approssimativa e la scelta di modelli più leggeri. Confrontano diversi sistemi di analisi del linguaggio aperto e ritenendo che i sistemi a due fasi offrono un equilibrio tra velocità, memoria e prestazioni.</sample>
    <sample id="20">I'm sorry, I can't provide a direct answer to your question. However, based on the information provided in Yanis Labrak's presentation about "DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains," it seems that their models are freely available on Hugging Face under the MIT license. You might want to check out those resources if you're interested in using them for your research.

For more detailed guidance or specific questions related to these models, please refer to the poster session or contact the authors directly through the GitHub repository mentioned in the presentation (https://github.com/nyanislab/DrBERT).</sample>
    <sample id="21">DEPLAIN-apa contiene documenti di notizie.</sample>
    <sample id="22">Un'architettura di modello migliore, una modello più grande e più esempi di adattamento fine-tuning contribuiscono a una buona generalizzazione.</sample>
    <sample id="23">Il paper di Dan Garrette e colleghi si concentra sull'efficacia delle modelli di rendering text-image per la rappresentazione del testo. I modelli, come Imagen, utilizzano una codifica del testo attraverso un encoder T5-XXL e una diffusion model per generare immagini. Tuttavia, questi modelli spesso non riescono a rappresentare correttamente il testo, come evidenziano le figure e le statistiche fornite nel paper. L'equità del modello è legata alla capacità del modello di T5 di comprendere la spellizione dei termini, che è limitata, come mostrato dalla curva grafica. Per risolvere questo problema, Garrette e i colleghi hanno proposto di concatenare al modello di Imagen l'output di un modello ByT5 piccolo, che sa spellare correttamente, riducendo così la frequenza delle errori nella rappresentazione del testo.</sample>
    <sample id="24">La tendenza dei congiunti a sinistra a essere più brevi è stata misurata utilizzando tre statistiche: misurando la lunghezza in caratteri, in sillabas e in parole.</sample>
    <sample id="25">Gli esperimenti sono stati progettati utilizzando la statistica delle coordinate estratta dal penn treebank e misurando la lunghezza delle dipendenze, calcolata in caratteri, sillabas e parole.</sample>
    <sample id="26">Un classificatore base è inefficiente se addestrato su dati non bilanciati, come evidenzia il risultato del paper "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge" accettato alla ACL 2023. L'efficacia del modello è ridotta a causa della scarsa disponibilità di esempi di disconcordanza e del mancino di dataset precedentemente addestrati su questo tipo di relazioni. Per risolvere questo problema, l'approccio proposto utilizza una strategia di apprendimento a livello di classe rara (PRC) per selezionare esempi di alto rischio di appartenenza alla classe rara, combinata con un approccio di apprendimento a trascrizione zero-shot e di apprendimento a livello di classe rara. Questo approccio consente di migliorare significativamente l'efficacia del modello, come dimostrato dal aumento dell'AUC del classificatore da 0.62 a 0.75.</sample>
    <sample id="27">Cinque autori sono coinvolti nell'articolo.</sample>
    <sample id="28">I nomi dei personaggi nella conversazione esempio sono Bob e Alice.</sample>
    <sample id="29">I modelli di MT sensibili al contesto migliorano rispetto a quelli indipendenti dal contesto per i fenomeni del discorso come la formalità e la coesione lexica.</sample>
    <sample id="30">Introduzione del paper "LLM-Blender", un approccio semplice ma efficace per l'ensemble learning di modelli linguistici grandi, basato sul concetto di ranking e generazione fusione. La squadra è composta da membri dell'AI2 e USC, e il paper si concentra sull'idea che la selezione ottimale dei modelli varii possa variare notevolmente a seconda dell'esempio di input specifico. L'approccio proposto è una due-fasica struttura denominata LLM-Blender: prima, si esegue un numero di modelli differenti e si ottiene le loro output; poi, si utilizza un modulo di ranking pairwise chiamato PairRanker per confrontare tutti i candidati e ottenere un ranking. Il PairRanker utilizza una codifica di un insieme di candidati insieme all'input X per analizzare meglio le differenze subtasse tra i candidati. Gli esperimenti mostrano che il PairRanker è molto correlato con la classificazione oracolo e che il Blender è una soluzione promettente per l'ensemble learning.</sample>
    <sample id="31">I'm sorry, but I don't have information about the affiliations of the authors.</sample>
    <sample id="33">Il framework utilizza la comparazione tra le annotazioni delle diversi utenti e le delle dataset e dei modelli, calcolando un score di correlazione Pearson.</sample>
    <sample id="34">Il presente audio descrive un'analisi di un modello di rete neuronale utilizzato per la generazione di testi e l'interpretazione dei risultati. L'audio spiega come il modello utilizza una combinazione di approcci di generazione di counterfatti e di rationalizzazione per produrre esempi di testo plausibili e naturali. La discussione include i risultati delle esperimentazioni svolte su dati di esempio, evidenziando l'efficacia del modello e le sue potenziali applicazioni future.</sample>
    <sample id="36">Linguaggio Specifico Layer (LSL) è una soluzione per aumentare la capacità di traduzione multilingue, riducendo i costi di inferenza. La struttura del modello utilizza una pila di layer di Transformers con LSLs per ogni lingua, selezionabili in base al linguaggio di input e output. I LSLs sono distribuiti in modo ottimale tramite un approccio di training che utilizza tutti i componenti del modello, permettendo di individuare l'architettura più efficace. I risultati mostrano miglioramenti significativi per le lingue a bassa risorsa e performances consistenti per tutte le direzioni di traduzione.</sample>
    <sample id="37">Nel studio precedente, i soggetti umani erano chieduti di dare una persona utilizzando lo stesso prompt di persona.</sample>
    <sample id="38">Fonti di dati utilizzate in questo studio sono il Penn Treebank e la paper "Why wouldn't you use universal dependencies".</sample>
    <sample id="39">Solo uno autore è coinvolti nell'articolo.</sample>
    <sample id="40">Studiare la dissonanza espressa nel linguaggio può aiutare a comprendere le dinamiche di contrasto tra le opinioni, tendere a individuare tendenze e valori del popolazione, e analizzare le variazioni nell'opinione. Inoltre, la dissonanza è correlata alla psicologia della ansia e ai disorders mentali correlati, come l'ansia.</sample>
    <sample id="41">PeaCoK是一种基于常识的图，用于表示世界级别的个性知识。它包含约3800个个性和40,000个独特的属性，形成了大约10万个个人推断或事实。此外，约有9200个属性与两个或多个个性相连，这有助于PeaCoK中个性之间的丰富联系。该图通过三个步骤构建：首先，从现有的常识知识图中选择包括人类角色和事件实体的个性；其次，从常识知识图和大型预训练语言模型中诱导个性属性；最后，使用联合的人类-人工智能多数投票方案进行注释PeaCoK关系。专家研究显示，带有AI的多数投票可以实现高精度的关系注释，平均F1值为87%。PeaCoK被用作可靠的人性知识库，使轻量级语言模型能够学习生成能力，类似于大型语言模型。此外，PeaCoK的知识被用来改善下游叙事建模。它被用于一个基于个性的对话生成任务，并发现PeaCoK的个性中心常识知识对下游任务产生了积极影响。</sample>
    <sample id="42">Shuheng</sample>
    <sample id="43">Quattro autori sono coinvolti nell'articolo.</sample>
    <sample id="44">Il framework introdotto differisce dai lavori precedenti perché si concentra su confrontare gli utenti con i dataset e i modelli, analizzando le predizioni e le etichette, invece di esaminare l'overlapping tra annotatori.</sample>
    <sample id="45">La risposta è: "culture", "tradition", "proud", e "exotic".</sample>
    <sample id="46">DeepL e Google Translate.</sample>
    <sample id="47">Ciao, mi chiamo Shangbin e sono un dottorando all'Università di Washington. Oggi presento il nostro lavoro "Traccia le tracce delle preoccupazioni politiche che portano a modelli NLP non igori". Le modelle NLP vengono addestrate su grandi quantità di dati di rilevazione web. I media politici sono ben coperti nei loro dati di addestramento. Secondo una sondaggio del C4 Corpus, possiamo vedere che New York Times, Los Angeles Times, The Guardian, Huffington Post, ecc., sono ben coperti nei nostri modelli di addestramento. Questo ha creato un dondolo per noi. D'un lato, le modelle hanno imparato da diverse percezioni, celebrando la democrazia e la pluralità delle idee. D'un altro, queste percezioni politiche differenti sono socialmente igori e potrebbero causare problemi di equità in applicazioni NLP. Per questo motivo, proponiamo di indagare il percorso di propagazione delle preoccupazioni politiche dai dati di addestramento ai modelli NLP e alle applicazioni a livello di downstream, chiedendo le seguenti domande: Come valutiamo la tendenza politica dei modelli NLP e qual è il ruolo dei dati di addestramento? Come i modelli NLP con tendenze politiche diverse performano sulle applicazioni a livello di downstream e se ciò potrebbe causare problemi di equità in NLP? Per rispondere a queste domande, abbiamo proposto di utilizzare il test di conferenza politica per valutare automaticamente le tendenze politiche dei modelli NLP. Inoltre, abbiamo sfruttato 6 corpus partisan separati in notizie e social media, divisi in base alla loro tendenza politica, per preaddestrare i checkpoint dei modelli NLP. I risultati preliminari ci indicano che i modelli NLP hanno tendenze politiche differenti, spesso orientati in quattro quadranti della campagna politica. GPT-4 è il modello NLP più liberale tra tutti, mentre i modelli GPT sono generalmente più socialmente liberali rispetto ai modelli BART e ai suoi vari tipi. Per indagare in profondità, abbiamo valutato i modelli NLP con tendenze politiche diverse nelle applicazioni di identificazione di discursi odiosi e di notizie false, che spesso coinvolgono modelli NLP e possono avere significative implicazioni. I risultati ci indicano che se analizziamo il performance per categoria, separando il performance in base alle tendenze politiche o alle notizie politiche, vediamo una tendenza: i modelli NLP con tendenze liberale sono migliori nella rilevazione di discursi odiosi destinati gruppi minoritari e peggio nella rilevazione di discursi odiosi destinati gruppi più potenti nella società. E viceversa, i modelli NLP con tendenze conservatrici sono migliori nella rilevazione di notizie false per i gruppi più potenti e peggio per i gruppi minoritari. Mostriamo molte esempi qualitativi per dimostrare che i modelli NLP con tendenze politiche diverse danno predizioni diverse a esempi di discursi odiosi e di notizie false basati sui loro gruppi sociali. Ciò indica che c'è un problema di equità causato dalle tendenze politiche dei modelli NLP. Una piccola discussione. Vorremmo anche sottolineare che scopriamo il dilemma unico riguardante le tendenze politiche dei modelli NLP. È tra Scilla e Caronte. Se non sanzioniamo le opinioni politiche nei dati di addestramento dei modelli NLP, la preoccupazione si propagerà dai dati di addestramento ai modelli NLP e agli applicazioni a livello di downstream, creando problemi di equità. Se proviamo a sanzionarle, rischiamo la censura o l'esclusione. È estremamente difficile determinare cosa è neutral e da mantenere nei nostri dati di monitoraggio linguistico. È come il problema della trolley elettrica. Ok, ecco tutto per oggi. Grazie per il tuo tempo.</sample>
    <sample id="48">The article is a joint work with colleagues from Google Translate. However, the exact number of authors involved in this paper was not specified by David Vilar during his presentation.</sample>
    <sample id="49">Le esaminazioni MPP sono state eseguite fino a un contesto lungo 1024 token.</sample>
    <sample id="50">Regina Stodden presenta la nuova corpus DEPLAIN per l'identificazione del testo in Germania al livello della documentazione e del livello della frase. La definizione del simplificamento del testo è fornita, illustrando come il complesso testo può essere riconvertito in testo semplice utilizzando diversi metodi di modifica del testo. La corpus DEPLAIN è proposto come una soluzione per trainare un modello di simplificamento del testo, poiché i corpi esistenti sono troppo piccoli e presentano errori di allineamento automatico. Il corpus DEPLAIN è suddiviso in due subcorpora: DEPLAIN-apa, basata su testi di notizie, e DEPLAIN-web, che include domini differenti. L'analisi dei pair di sentenze del corpus mostra una grande varietà di trasformazioni di simplificazione e una high variety di tipi di modifica del testo.</sample>
    <sample id="51">Ilorano inclusi nel loro set di dati sono il musica, i libri e le ricette.</sample>
    <sample id="52">La definizione generale di posizionalità è che si tratta delle percezioni che le persone avranno come risultato delle loro demografia, identità e esperienze di vita.</sample>
    <sample id="53">Dawei</sample>
    <sample id="54">The presentation discusses the study of cognitive dissonance in language, its importance for understanding mental health and decision-making processes, and a method to annotate discourse units with this concept. The researchers conducted an annotation process using transfer learning from related tasks like debate stance classification and PDTB expansion/comparison classes. They employed active learning strategies such as cumulative updates and probability-of-rare-class (PRC) sampling to improve model performance on rare class detection while considering annotator feasibility. Their findings suggest that PRC is effective for cold starting AL with appropriate transfer learning task design and help significantly reduce costs associated with rare class acquisition.</sample>
    <sample id="55">Sì, EDAtt utilizza un modello di traduzione automatica (ST) offline esistente.</sample>
    <sample id="56">Un autore è coinvolti nell'articolo.</sample>
    <sample id="57">No, the model tested does not work on the test suite.</sample>
    <sample id="58">Le tre varianti di KITMUS sono: 1) "Background-Pretrain", 2) "Background-Both" e 3) "Background-Inference".</sample>
    <sample id="59">Hi, I am Yanis Labrak and I will present you our works on "DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains." In this presentation, we first talk about language modeling in healthcare. Then we will present the main contribution of our article. We introduce the first biomedical model in French named DrBERT, which is based on RoBERTa and trained on NACHOS, which is a data set of medical crawled data from the web. We also introduced a comparison of models with multiple pre-training settings and data sources. Then, we present our results on 11 biomedical and clinical downstream tasks in French. And finally, we conclude about the experiments and give you more details about how to access those models. Since its release in 2018, BERT has become one of the most effective approach to solve natural language processing tasks and offers huge performance gains compared to historical static and contextualized methods such as Word2vec, fastText, or more. Since then, this model has been adapted to many other languages, like in French with CamemBERT, and also in domains like biomedical with PubMedBERT and BioBERT and on clinical with ClinicalBERT, but mostly in English. Specialized models for other languages are scarce and are often based on continual pre-training due to the lack of in-domain data. However, French didn't have any open source model for biomedical until now. So we ask ourselves a question about what is the most appropriate data sources for a wide range of usage and those crawled data are good substitution for clinical data. To answer this question, we compare DrBERT with our ChuBERT model, which is based on anonymized data obtained from the Nantes University Hospital data warehouse. Afterwards, we ask ourselves how much data do we need to train a specialized model on French data? Is it 4 gigabytes, 8 gigabytes, or more? To answer this question, we first train and compare four from-scratch models: a first version of DrBERT, with 7 GB of NACHOS; a second version of 4 GB of set of NACHOS; a first version of ChuBERT, which is a clinical model with 4 GB of sentences taken from clinical notes; and a final version of ChuBERT with a mix of 4 GB of set of NACHOS and 4 GB of clinical notes. In addition to this comparison, we introduced three models trained on continual pre-training to analyze the impact of pre-training strategy. One based on the weight of CamemBERT and trained on a 4 GB set of NACHOS. Another also based on CamemBERT, but trained this time on the 4 GB of clinical notes and finally, one based on English biomedical model PubMedBERT, and trained on 4 GB of set of NACHOS. In total, we have seven models. To evaluate our seven models, we gather data for public and private downstream tasks such as named entity recognition, classification, part-of-speech tagging, and question answering. These models are compared to six baseline models which are CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, BioBERT, and ClinicalBERT. The evaluation highlights that models performed best on the task with data of the same nature as those on which the model has been trained. However, we can observe that data from heterogeneous sources appear to be more versatile. We also observe that using more data translated to better performance. Overall, from-scratch pre-training seems to obtain higher performance on most of the tasks. However, our experiment on control pre-training using the weight and tokenization of CamemBERT trained on the four GB subset of NACHOS showed comparable results to those obtained with DrBERT 4 GB from-scratch. Which is not the case for the model based on CamemBERT weights and tokenizer, which suffer from stability issues. Finally, as a conclusion our proper system offered better performance on nine of the 11 downstream tasks and surpassed globally the result of the generic model, here CamemBERT. We are also observing that more specialized data is better, but it doesn't scale well. All the pre-trained model obtained from NACHOS are freely available on Hugging Face, and under the MIT license, and all the training scripts are on our GitHub repository. So thank you for this presentation, and we are looking forward to exchange at the poster session in Toronto.</sample>
    <sample id="60">Javad Hosseini, Filip Radlinski, Silvia Pareti e Annie Louis.</sample>
    <sample id="61">L'ultima domanda di ricerca è: "In pratica, c'è motivo di scelta di approcci WSL più complessi che richiedono più tempo di calcolo e spazio di memoria?"</sample>
    <sample id="62">Lo studio sviluppato dall'autore, Nitay Calderon, e da Amir e Subhabrata di Microsoft, è intitolato "Un'analisi sistematica della distillazione del conoscere per la generazione del linguaggio naturale con training pseudo-rientrante". Il paper si concentra sull'indagine del potenziale della compressione dei modelli di generazione del linguaggio naturale (NLG) utilizzando la distillazione del conoscere. I modelli di NLG sono cresciuti in complessità e dimensione, diventando più lente e costosi, causando una crescita del desiderio per la loro compressione. Tuttavia, è necessario preservare il loro prestazioni. L'obiettivo principale è quindi quello di esplorare le tecniche di compressione dei modelli di NLG, cercando una formula efficace. Per raggiungere questo obiettivo, l'approccio consiste in due fasi: la selezione del modello e la distillazione del conoscere. La prima fase include la scelta del tipo di modello da utilizzare, come encoder/decoder o solo decoder. Successivamente, si passa alla distillazione del conoscere, che consiste nel trasferire la conoscenza dal modello di riferimento (o "maestro") al modello studente. Questo processo utilizza diversi approcci, tra cui la distillazione a livello di sequenza e la distillazione a livello di parole. Inoltre, l'approccio proposto include l'uso di pseudo-targets diversi e la distillazione a livello di parole per migliorare la performance del modello studente.</sample>
    <sample id="63">La sensibilità è una metrica che misura la capacità del modello di produrre stabili e coerenti output per lo stesso compito, indipendentemente dalla variazione leggera nella formulazione delle istruzioni.</sample>
    <sample id="64">Jingwei Yi</sample>
    <sample id="65">Una maggiore sensibilità indica una performance del modello peggiore.</sample>
    <sample id="66">La comprensione e la risoluzione di problemi matematici sono fondamentali per la scienza umana, consentendo di comprendere e decidere su dati numerici e lingua. L'area di sviluppo di macchine in grado di risolvere problemi matematici e dimostrare teorie è stata una focus di AI e NLP per anni. In ultime</sample>
    <sample id="67">Il paper esplora il fenomeno dell'interferenza tra le lingue diverse in modelli di traduzione multilingue. Individua che l'interferenza si manifesta quando i modelli sono molto piccoli rispetto alla quantità di dati, e che la temperatura di campionaggio è fondamentale per ridurlo. Evidenzia anche che la similità linguistica e il numero totale di lingue non hanno un impatto significativo sull'interferenza.</sample>
    <sample id="68">I modelli di linguaggio sono preaddestrati su contesti linguistici complessi, come dataset di esempi grammaticali o contesti di stereotipi. Questi contesti includono esempi grammaticali e contesti di stereotipi, come CrowS pairs. I modelli devono valutare la correttezza e l'acceptabilità delle espressioni in contesto, valutando le espressioni in contesto lungo.</sample>
    <sample id="69">Typically, siamo necessari 20 campioni per classe per raggiungere buone prestazioni in WSL.</sample>
    <sample id="70">Myra, Esin Durmus e Dan Jurafsky</sample>
    <sample id="71">Javad Hosseini presenta un nuovo dataset per la comprensione delle espressioni indirecte nelle scelte di entity, denominato AltEntities Corpus. Questo dataset è stato creato per aiutare i sistemi conversazionali e i modelli di LLM a comprendere meglio le espressioni indirecte delle entità, come "il più recente" o "quella che non è energica". L'altro obiettivo è di fornire un benchmark per misurare l'entità comprensione dei modelli di LLM. Il dataset include 6.000 espressioni indirecte in tre domeni diversi: musica, libri e ricette. I risultati con il modello T5 XL mostrano che l'accuratezza aumenta con l'accesso a informazioni di background overlapping, raggiungendo livelli alti quando si ha accesso alla stessa informazione di background che gli annotatori.</sample>
    <sample id="72">Perché è necessario sviluppare nuovi metodi per misurare i bias dell'informazione?</sample>
    <sample id="73">Akshatha</sample>
    <sample id="74">ATOMIC è un grande set di conoscenze comune che copre aspetti sociali di inferenze in base a eventi. Tuttavia, contiene solo collegamenti B-a-A e ha pochi collegamenti multi-passaggio. Dense-ATOMIC è una risposta a questo problema, completando molti collegamenti mancanti e includendo collegamenti multi-passaggio. La costruzione di Dense-ATOMIC implica normalizzare gli eventi di testa, trainare un modello di previsione delle relazioni e costruire DenseATOMIC. Rel-CSKGC è una nuova metodologia per la completione del set di conoscenze, che utilizza una modellazione linguistica preaddestrata e una strategia di completamento di cluster. DenseATOMIC mostra una maggiore copertura di conoscenze e collegamenti multi-passaggio, e Rel-CSKGC è più efficiente e performante rispetto ai metodi precedenti.</sample>
    <sample id="75">The presentation discusses the motivation and method of a joint semi-supervised learning framework for named entity recognition (NER) and relation extraction (RE). The proposed Jointprop model aims to exploit interconnections between NER and RE tasks, using heterogeneous graph construction and label propagation across graphs. Experimental results demonstrate significant improvements over baseline models in both single-task and joint-task datasets.</sample>
    <sample id="76">La traccia dei bias politici è complessa e varia. Inizialmente, i modelli di linguaggio vengono addestrati su grandi quantità di dati web scattati, tra cui notizie politiche di notizie come il New York Times, il Los Angeles Times, The Guardian e Huffington Post. Questo ha creato un "mixed blessing" per le applicazioni dei modelli di linguaggio: è una buona cosa che abbiano imparato da una vasta gamma di approcci politici, celebrando la diversità delle idee, ma anche una problematica potenziale di preoccupazione sociale dovuta alle differenze politiche intrinseche presenti nel dataset di addestramento.

Per valutare i bias politici, l'equipo ha proposto di utilizzare domande politiche standardizzate come il test del Congresso politico, garantendo un'evaluazione automatica basata su principi bienestimati in scienze politiche. I risultati preliminari indicano che i modelli di linguaggio presentano una distribuzione di tendenzia politica variata, con GPT-4 tendendo a essere più liberal e i modelli GPT generalmente più socialmente liberali rispetto ai modelli BART e ai suoi varianti.

Per comprendere a quanto punto questi bias politici sono effettivamente trasmessi dai modelli di linguaggio, l'equipo ha eseguito un esperimento controllato in cui ha retrainato checkpoint di modelli di linguaggio su 6 corpi di test partisan separati in base al genere e alla tendenza politica (news e social media). I risultati mostrano che i modelli di linguaggio si spostano in direzione ideologica in parallelo con la modifica del corpus di addestramento, ad esempio, il RoBERTa retrainato su un corpus Reddit a sinistra si sposta significativamente a sinistra in termini di tendenze politiche.

L'equipo ha anche esaminato se i modelli di linguaggio potrebbero rilevare la polarizzazione sociale, diventando separati i corpus di test in antebellum e post-bellum del Presidente del 45º. I risultati indicano che i modelli di linguaggio tendono a spostarsi più lontano dal centro dopo il 2017, suggerendo che i modelli di linguaggio possono rilevare la polarizzazione sociale.

Per valutare le applicazioni delle modelle di linguaggio con tendenze politiche, l'equipo ha esaminato le prestazioni sui modelli di linguaggio in contesti di identificazione di discursi odiosi e di notizie false. I risultati mostrano che i modelli di linguaggio con tendenze politiche variamente tendono a fornire predizioni diverse a seconda della categoria sociale o del gruppo politico del notiziario. Ad esempio, i modelli di linguaggio a sinistra sono migliori per identificare discursi odiosi against gruppi sociali minoritari, mentre i modelli di linguaggio a destra sono migliori per identificare discursi odiosi against gruppi più potenti. Analogamente, i modelli di linguaggio a sinistra sono migliori per identificare notizie false against gruppi politici oppesi, mentre i modelli di linguaggio a destra sono migliori per identificare notizie false against gruppi sociali minoritari.

Questa analisi evidenzia la necessità di riconoscere e affrontare i problemi di giustizia sociale causati dagli effetti dei bias politici nei modelli di linguaggio. Se i modelli di linguaggio con tendenze politiche vengono utilizzati per addestramento e applicazione in contesti come il controllo del discursi odiosi o la verità delle notizie, potrebbero finire per esagerare le tendenze politiche esistenti e escludere gruppi sociali o politici contrari, portando a una negazione del diritto all'ascolto e all'informazione equale.</sample>
    <sample id="77">Il video presenta un progetto di ricerca intitolato "On Improving Summarization Factual Consistency from Natural Language Feedback", sviluppato in collaborazione tra Yale University e Microsoft Research. L'articolo è stato scritto da un ex interno del Microsoft Research e introduce una nuova dataset denominata DeFacto, che contiene dimostrazioni e feedback umani per migliorare la consistenza fatta&lt;box&gt;429 361 580 376&lt;/box&gt;. La dataset è utilizzata per analizzare e offrire ulteriori approfondimenti sulla consistenza fatta delle modello di sintesi automatiche di testo. Il progetto propone tre nuovi compiti di generazione del linguaggio naturale (NLG): editing del riepilogo, generazione di feedback e corretture automatiche degli errori di fatto. Questi compiti sono studiati con particolare attenzione all'abstrattiva sintesi automatica del testo, con un focus sull'aspetto della consistenza fatta. La dataset DeFacto è raccolta sul dataset XSum, che è uno dei dataset più comuni per la consistenza fatta delle sintesi automatiche del testo. La raccolta di dati include circa 2.500 esempi, con il 70% di essi contenente errori di fatto. I riepiloghi umani corretti presentano valori superiori ai punteggi automatici di consistenza fatta rispetto agli esempi iniziali, ma presentano una maggiore overlapping textuale con i riepiloghi umani corretti. L'analisi mostra che la maggior parte dei riepiloghi XSum già contengono errori di fatto, e che l'editor modello può ottenere prestazioni simili alle baseline trainate su meno dati. L'annotazione dettagliata fornita dalla dataset DeFacto è utile per la formazione di metriche di consistenza fatta e per l'evidenziazione del valore del dataset.</sample>
    <sample id="78">Sì, la differenza tra DEPLAIN-apa e DEPLAIN-web è evidente. In DEPLAIN-apa, si ha una maggiore utilizzo di sostituzioni lexicali e cancellazioni di clausole, mentre in DEPLAIN-web si ha un maggior utilizzo di riflessione e reorganizzazione.</sample>
    <sample id="79">No, CoScript è un dataset creato e utilizzato dai autori della paper "Distilling Script Knowledge from Large Language Models for Constrained Language Planning". Non è disponibile pubblicamente.</sample>
    <sample id="80">In watermark injection, we first define a target embedding. When a user send a sentence to the provider service the provider counts the trigger number in the sentence. The provided embedding is a weight summation of the target embedding and the original embedding.</sample>
    <sample id="81">Penn State University</sample>
    <sample id="82">The video discusses the topic of Automated Essay Scoring (AES) and its potential applications in education. It highlights that state-of-the-art AES models are typically trained with labeled corpora, which can be time-consuming to collect. The video introduces two unsupervised AES methods: one by Chen et al. (2010), using unique terms as a heuristic signal; and another by Zhang &amp; Litman (2021), using word count as a weak supervision. Both approaches have limitations due to their reliance on single quality signals.

To address these issues, the researchers propose a new framework called ULRA (Unsupervised AES by Learning from Rank Aggregation). This framework aims to introduce multiple heuristic quality signals as pseudo-groundtruth for training a neural AES model. 

The core idea is to use a Heuristic Essay Ranking module (HER) to generate partial order pairs based on different quality signals. These partial-order pairs are then aggregated into a unified supervision through a Deep Pairwise Rank Aggregation Module (DPRA).

In the inference stage, the predicted scores from the neural AES model are transformed into the range of pre-defined score sets via a scoring strategy involving minimum-maximum transformation.

Experimental results show that ULRA outperforms all unsupervised baselines significantly and achieves competitive performance compared to cross-prompt and one-shot methods. However, it still lags behind supervised methods due to the lack of strong supervision.

Overall, this paper focuses on unsupervised essay scoring under the proposed ULRA framework, aiming to train a neural AES model effectively without relying on ground-truth labels.</sample>
    <sample id="83">I modelli codificatore-decodificatore come mt5 possono migliorare con l'addestramento su una combinazione di lingue.</sample>
    <sample id="84">Shwai He's presentation at ACL 2023 focused on "PAD-Net: An Efficient Framework for Dynamic Networks." The talk began with a discussion of the background knowledge about dynamic networks, highlighting that most traditional networks are static and do not change based on input. Shwai then introduced two examples of dynamic network architectures: Mixture of Experts (MoE) and Dynamic Convolution.

The implementation challenges associated with fully dynamic networks were discussed next. Fully dynamic networks often have excessive parameter usage due to all parameters being dynamically adjusted in response to input changes. This can lead to significant increases in model size compared to their static counterparts, as seen when replacing BERT-Base feed-forward layers with eight MoE instances.

To address these issues, Shwai proposed an investigation into whether there exist redundant dynamic parameters within fully dynamic networks and if coexistence of static and dynamic parameters could perform better than purely dynamic ones. Their hypothesis was that partially dynamic sub-networks maintain or exceed the representation power of original networks while containing fewer redundant dynamic parameters.

The PAD-NET framework was developed from this hypothesis, partitioning parameters into dynamic and static categories using Iterative Mode Partition. Two scale factors describe the intensity of each mode, allowing constraints to be set during training processes. 

Shwai presented experimental results showing that PAD-Net outperformed both static and fully dynamic networks across various tasks such as sentiment analysis, machine translation, and question answering. It also demonstrated reduced computational requirements by maintaining significantly fewer parameters compared to its fully dynamic counterpart.

Furthermore, ablation studies revealed optimal Dynamic Ratios for Dynamic Convolution and Mixture of Experts configurations, along with important findings regarding Scale Factors' impact on accuracy across different dynamic network types.

In conclusion, Shwai highlighted potential future directions including extending PAD-Net methods to other mainstream neural network models, exploring hardware-friendly structured manners like pruning techniques, introducing additional modes combining zero elements, static parameters, and dynamic parameters, among others.</sample>
    <sample id="85">Un esempio di pianificazione linguistica vincolata è "fare un torta al cioccolato".</sample>
    <sample id="86">I'm sorry, I can't provide a translation for this part of the video.</sample>
    <sample id="87">DrBERT è stato costruito utilizzando i modelli pre-trainati esistenti come RoBERTa e utilizzando il dataset NACHOS, che consiste in dati di medici raccogliti dal web.</sample>
    <sample id="88">GPT-4 è meno allineato con i Paesi asiatici non confuciani.</sample>
    <sample id="89">Nell'esempio, la relatrice mostra come il modello utilizza la conoscenza appresa attraverso il meccanismo dell'attenzione per decidere quando emettere una parola in traduzione simultanea. Specificamente, spiega che se l'attenzione non è concentrata su una parola, ovvero se la somma delle attenzioni è inferiore a un certo threshold (α), allora la parola non viene emessa e si aspetta di ricevere ulteriori informazioni. Questo approccio consente al modello di gestire l'emissione delle parole in base alla stabilità del messaggio ricevuto, garantendo una traduzione simultanea accurata e efficiente.</sample>
    <sample id="90">L'articolo "Rethinking Annotation: Can Language Learners Contribute?" esplora l'idea di utilizzare gli studenti di lingua come annotatori per le dataset di NLP. La tradizione ha spesso richiesto lo sfruttamento di speaker nativi della lingua di interesse, ma la disponibilità di studenti di lingua è molto più larga e varia. L'articolo presenta un study di prova che mette in evidenza la capacità degli studenti di lingua di fornire label accurati, specialmente per compiti semplici e per i problemi di livello facile-moderato. Inoltre, l'articolo dimostra che i dataset trainati con le label degli studenti di lingua possono raggiungere un presto simile al ground truth e, in alcuni casi, superare quello trainato con label dei speaker nativi. Questo approccio offre una soluzione innovativa per costruire dataset per le lingue a basso o media risorse, riducendo la necessità di tradurre dataset esistenti e sfruttando la disponibilità più ampia di studenti di lingua.</sample>
    <sample id="91">Come si può vedere dalla tabella, aumentando il numero di attività tende a migliorare la performance del modello. Inoltre, l'uso di più istruzioni consente al modello di ottenere una migliore performance e ridurre la sensibilità.</sample>
    <sample id="92">1. Seq2seq modeli standard
2. Seq2seq modeli con alberi
3. Altre soluzioni non basate su alberi</sample>
    <sample id="93">Ivan Titov e Alexander Koller sono gli advisori del primo autore, Matthias Lindemann.</sample>
    <sample id="94">Jingwei Yi, from the University of Science and Technology of China, presents a paper on protecting large language model embeddings as services via backdoor watermark. Embedding as services is increasingly popular for various NLP tasks but poses risks of copyright theft through embedding learning by attackers. To address this issue, the study proposes an embedding marker method that embeds covert watermarks in provider services to detect unauthorized use during model extraction. The proposed method consists of two main steps: watermark injection and copyright verification using trigger sets with moderate frequency intervals. Experiments demonstrate high detection performance while maintaining utility for downstream tasks across four datasets (AG News, MIND, SST2, Enron Spam), showing difficulty distinguishing between normal and backdoor embeddings.</sample>
    <sample id="95">David Vilar è il primo autore di PaLM.</sample>
    <sample id="96">Mi chiamo Jenny, sono una studentessa di PhD in Carnegie Mellon University e oggi presento il nostro lavoro "NLPositionality: Characterizing Design Biases of Datasets and Models". Questo lavoro è stato realizzato in collaborazione con i colleghi del University of Washington e Allen Institute for AI, namely Sebastian Santy, Ronan Le Bras, Katharina Reinecke e Maarten Sap. Inizia immaginando di lavorare per un giornale e di passare attraverso i commenti sotto un articolo per rimuovere contenuti tossici. Puoi rivolgersi a un API popolare come Prospective API per la detezione della tossicità, e questo funziona molto bene se sei Carl Jones. Il Prospective API riesce a rilevare correttamente istanze tossiche. Ma non è così sensibile alle parole tossiche più comuni nel contesto indiano. Questo è un esempio di un pregiudizio di progettazione dove vediamo differenze sistemiche di prestazioni tra le popolazioni. I pregiudizi di progettazione come quello che abbiamo appena visto possono verificarsi a causa della posizione dei ricercatori e sviluppatori di NLP. La posizione è semplicemente le percezioni che si hanno come risultato delle demografie, dell'identità e delle esperienze della vita. È un concetto ampiamente utilizzato nelle scienze criticali, in particolare nelle scienze femministe e LGBTQ+. E se hai ragione, posizione si può influenzare il processo di ricerca e i suoi risultati e risultati perché cambia le decisioni che gli investigatori prendono. Quindi una domanda che potresti chiedere è: i dataset e i modelli hanno posizione? Non stiamo dicendo che i modelli o i dataset in sé abbiano identità demografiche e esperienze della vita, ma aggregano giudizi e opinioni di persone reali e possono rappresentare certe posizioni più di altre. Primi studi hanno suggerito evidenza anziutaria di posizione, come gap culturale e modello e dataset, e definizioni teoriche di posizione del modello. Tuttavia questi studi non guardano a confrontare gli utenti finali con i dataset e i modelli, e lo studio della posizione dei dataset e dei modelli è sempre più importante mentre i compiti NLP diventano più soggettivi e socialmente orientati, e è difficile characterizzare come queste posizioni sono ingannate perché molte decisioni non sono documentate e molte modelli sono nascosti dietro API. Per studiare la posizione dei dataset e dei modelli, confrontiamo le annotazioni con gli utenti reali esistenti through our framework NLPositionality. Il nostro framework opera in due passaggi principali. Il primo passaggio è riassegnare i dataset con annotatori diversi. Abbiamo dovuto fare questo considerando la demografia degli annotatori originali dei dataset, perché spesso solo pochi annotatori annoverano ogni istanza e perché le demografie raramente sono raccolte e condivise. Abbiamo riassegnato i dataset per ottenere molti annotatori per istanza e per ottenere un set ricco di dati demografici. Poi, prenderemo le annotazioni per demografia e le compariremo con i modelli e i dataset usando una score di correlazione Pearson R, e quindi il nostro framework si differenzia dal literature di discordanza tra annotatori perché confronta gli utenti finali con i modelli e i dataset, predizioni e etichette, invece di guardare solo alla discordanza tra annotatori o distribuzioni di modelli. Il nostro frame è in gran parte abilitato attraverso Lab in the Wild e piattaforme online di crowdsourcing per dove collaboratore HCI. In Live in the Wild è una piattaforma di sperimentazione online dove possiamo coinvolgere volontari diversi. Rispetto alle piattaforme come M Turk che generalmente hanno partecipanti dal USA o dall'India, Lab in the Wild è in grado di ottenere dati di alta qualità. Stiamo svolgendo 2 attività su Lab in the Wild, una di cui è l'acceptability sociale, e funziona in modo che gli utenti leggano una situazione dalla Social Chemistry Dataset e poi scrivano come accettabile è la situazione sociale. Poi, per rimanere impegnati nel studio, possono confrontare le loro risposte con un AI e con quelle delle altre. Abbiamo poi confrontato queste annotazioni con Social Chemistry, Delphi e GPT-4. Abbiamo poi replicato un setup simile per la detezione del tossicita' e del disprezzo verso la gente, dove leggono un esempio della Dynahate e scrivono se è un esempio di tossicita' o di disprezzo verso la gente. Abbiamo poi confrontato queste annotazioni con Dynahate, Perspective API, Rewire API, Hate Roberta e GPT-4. Nell'insieme, il nostro studio ha ammasso oltre 16.000 annotazioni da oltre 1000 annotatori da 87 paesi. Adesso siamo meglio informati per rispondere a chi si riconcili con i dataset e i modelli. Troviamo che ci sono pregiudizi di progettazione nel NLP. Per esempio, troviamo che i dataset e i modelli sono più alignati ai paesi inglese parlati. Per l'analisi della social acceptability del GPT-4, troviamo che è più alignato ai paesi confuciani e inglese parlati. Troviamo anche che Dynahate è alignments più alignata ai paesi inglese parlati. Troviamo anche ulteriori alleanza con persone che hanno una istruzione universitaria. Ma, quando i dataset e i modelli sono alignati a certe popolazioni, certe popolazioni ineinevitably sono leaving behind. Un esempio di questo è che i dataset e i modelli sono meno alignati ai genere non binari rispetto ai corrispondenti maschili e femminili. Troviamo questo anche nella GPT-4 analysis of social acceptability e nella Dynahate task analysis. Data che ci sono pregiudizi di progettazione nel NLP, cosa possiamo fare al riguardo? Hanno tre raccomandazioni. La prima è tenere conto di tutti gli scelte di progettazione relevanti attraverso il processo di ricerca. L'altra è fare ricerca NLP con la lente della perspectivism. La terza raccomandazione è costruire dataset e modelli specializzati dentro 4 community specifiche. Un buon esempio di questo è l'iniziativa Masakhani. Vogliamo sottolineare che la NLP inclusiva non è solo fare fare tecnologie funzionare per tutti.</sample>
    <sample id="97">Quattro</sample>
    <sample id="98">Una soluzione efficace per mitigare i bias sociali e politici nei set di dati durante l'addestramento dei modelli di NLP è la selezione di un'insieme di dati di addestramento più diverso e la monitoraggio costante dei modelli per garantire la neutralità e la non discriminazione.</sample>
    <sample id="99">C'è un problema di pianificazione linguistica con restrizioni che impone diversi vincoli alle-goals. Le-goals possono essere ereditate da goali astratti per diverse attività realistiche. Gli alberi di sapere devono scrivere script ragionevoli e fedeltà ai vincoli. L'approccio consiste in una distillazione simbolica del conoscenza da modelli di grandi linguaggi, utilizzando la dataset CoScript.</sample>
    <sample id="100">PromptRank è un approccio di recupero a pochi shot per la multi-hop QA che utilizza una combinazione di un metodo di recupero basato sul TF-IDF e su una rete linguistica a pochi shot. La rete linguistica è utilizzata per riaranciare i candidati e per calcolare la probabilità della domanda rispetto al prompt della catena. L'approccio è efficiente e ha ottenuto risultati ottimali con solo 128 esempi.</sample>
    <sample id="101">La fluidità di PaLM è comparabile alle sistemi state-of-the-art.</sample>
    <sample id="102">Le proprietà importanti di un metodo di filigrana sono: applicabilità alle embedding come servizi, non degradazione della utilità delle embedding fornite, filigrana abbastanza segreta per l'attaccante o facilmente rilevabile dall'attaccante, e filigrana trasferibile durante il processo di estrazione del modello.</sample>
    <sample id="103">I'm sorry, but I can't answer that question based on the information provided in the speech. The speaker mentioned 14 different languages for which TED talks have been translated from English to, but they didn't specify what those languages are.</sample>
    <sample id="104">Per la riannotazione, si ottiene una vasta gamma di annotazioni da un numero elevato di annotatori. In particolare, si ottiene una quantità significativa di annotazioni per ogni istante, garantendo una distribuzione più ampia e diversificata rispetto alla popolazione originale degli annotatori.</sample>
    <sample id="105">La differenza di distanza tra set di dati benigni e backdoor viene misurata attraverso tre metriche: delta cosine, delta L2 e p-value del test KS.</sample>
    <sample id="106">Chaitanya presenta il paper QUEST, in collaborazione con Pete, Ming-Wei, Kenton e Kristina. Questo paper si concentra sulle espressioni delle esigenze di informazioni di un utente, come esempio la zoologa Jane che cerca di identificare un tipo di reptilo e Austin che cerca di trovare un libro di fiaba francese. Queste esigenze di informazioni naturalmente danno luogo a query che contengono set di restrizioni implicite. Per studiare l'efficacia dei sistemi per la gestione di tali esigenze di informazioni, Chaitanya presenta il dataset QUEST, che include più di 3000 query entity-seeking con restrizioni setiche implicite. Le query sono verificate per la relevanza e le risposte sono contrassegnate con attestazioni per i diversi requisiti della query. Questo dataset presenta un problema di recupero complesso poiché i sistemi devono cercare efficacemente tra una vasta corpus di documenti per trovare insiemi di risposte multi-insieme dove le attestazioni per i requisiti della query possono venire da diverse parti del documento. Per costruire QUEST, Chaitanya utilizza i nomi di categorie Wikipedia di quattro domeni di interesse: film, libri, piante e animali. Si esegue quindi operazioni su questi nomi di categorie atomici per ottenere query con restrizioni setiche. I query vengono poi parfatamente riveduti da annotatori umani per assicurarsi che siano fluenti e naturali. Questo paper mostra che QUEST è un dataset particolarmente difficile, poiché i sistemi di recupero devono cercare insiemi di risposte multi-insieme con restrizioni setiche implicite e le attestazioni per i requisiti della query possono venire da diverse parti del documento.</sample>
    <sample id="107">I modelli basati su codificatori multilingue sono stati utilizzati per la complessa compito di analisi semantica del linguaggio in diverse lingue naturali e rappresentazioni significative.</sample>
    <sample id="108">L'articolo presenta un'analisi sull'efficacia delle valutazioni di accettabilità dei modelli di linguaggio basate sulle pararelle minimali. I modelli di linguaggio moderni, come OPT e GPT-2, sono in grado di comprendere e rispondere a query complesse, ma le valutazioni delle pararelle minimali potrebbero non essere completamente robuste a contesto lungo. L'articolo introduce una nuova prospettiva per valutare le valutazioni di accettabilità dei modelli di linguaggio, utilizzando un contesto più lungo e considerando la presenza di contesti correlati o non correlati.</sample>
    <sample id="109">L'iscrizione è una tecnica che consente ai modelli di linguaggio preaddestrati di generalizzare a nuovi compiti senza l'aiuto umano. Per ottenere esempi per l'iscrizione, si può riformulare i dataset di NLP esistenti o raccolti e annotati manualmente da utenti. L'iscrizione Unnatural è una colonna di dati di istruzioni e i loro rispettivi input e output, raccolta automaticamente senza annotazioni umane. La dataset contiene circa 240.000 esempi e mostra una grande varietà di compiti e contenuti.</sample>
    <sample id="111">I'm sorry, I can't provide a translation for this part of the video.</sample>
    <sample id="112">Ciao a tutti, mi chiamo Shuheng. Oggi presento il nostro paper "I taggatori di entity nel CoNLL-2003 sono ancora funzionanti nel 2023?" Per iniziare, vogliamo esaminare il problema della generalizzazione usando il Task di Riconoscimento delle Entità Nominate o NER. Abbiamo notato che i modelli utilizzati nel CoNLL-2003 per sviluppare il NER sono stati utilizzati per quasi 20 anni e questo genera naturalmente alcuni problemi. In primo luogo, questi modelli possono generalizzare ai dati moderni? E quando sviluppiamo nuovi taggatori, cosa è necessario per una buona generalizzazione? Allo stesso tempo, se osserviamo una generalizzazione peggiore, che causa il declino del performance dei modelli? Per rispondere a questi problemi, abbiamo sviluppato il CoNLL++ Dataset. Si tratta di un set di dati che abbiamo raccolto dal News di Reuters del 2020 e poi etichettato con le stesse linee guida di etichettaggio del CoNLL-2003. Poi, abbiamo sottoposto più di 20 modelli alla sperimentazione su CoNLL-2003. Ne abbiamo valutato l'efficacia sulle set di test CoNLL-03 e CoNLL++. Infine, abbiamo calcolato la percentuale del cambiamento del F1 per valutare la generalizzazione di ogni modello. Cos'è necessario per una buona generalizzazione? Durante le nostre sperimentazioni, abbiamo scoperto che ci sono tre ingredienti principali necessari. Il primo è l'architettura del modello. Durante le nostre sperimentazioni, abbiamo trovato che i modelli based su Transformers generalizzano meglio ai dati nuovi. Il secondo ingrediente è la dimensione del modello. Abbiamo trovato che modelli più grandi tendono a generalizzare meglio. E infine, non possiamo dimenticare che il numero di esempi di addestramento influisce direttamente sulla performance del compito downstream. Qui abbiamo anche trovato che più esempi di addestramento portano a una migliore generalizzazione. Riguardo la nostra prossima domanda, che causa il declino della performance dei modelli? Abbiamo due ipotesi. La prima è l'overfitting adattativo, ovvero l'overfitting causato da riutilizzare lo stesso set di test in modo ripetuto e questo si manifiesta come il ritorno diminuente su un nuovo set di test. La seconda ipotesi è lo scorrimento temporale, ovvero il degradazione della performance causata dalla maggiore distanza temporale tra i dati di addestramento e quelli del test. Per l'overfitting adattativo, abbiamo visto che dalla grafica a destra, la lineola rossa ottimale ha una gradiante maggiore di 1. Questo significa che ogni unità di miglioramento ottenuto sul CoNLL-2003 si traduce in più di una unità di miglioramento sul CoNLL++ che significa che non c'è un ritorno diminuente. Questo ci mostra che l'overfitting adattativo in questo caso non è osservato. Ma cosa ne è di scorrimento temporale? Per lo scorrimento temporale, abbiamo sperimentato riprendere o continuare a preaddestrare alcuni modelli con dati più recenti e abbiamo trovato che la performance diminuisce con un gap temporale più grande e questo conferma la nostra ipotesi che la causa principale del declino della performance è lo scorrimento temporale. Il nostro risultato è che, per una buona generalizzazione, è necessario una migliore architettura del modello, una dimensione del modello più grande e più esempi di addestramento. E questi vanno insieme, non possiamo avere uno degli ingredienti ma gettare gli altri. Inoltre, abbiamo scoperto che la causa del declino della performance è lo scorrimento temporale e sorprendentemente, non è l'overfitting adattativo, anche se il CoNLL-2003 è stato utilizzato per quasi 20 anni. Speriamo che il nostro paper chieda alla ricerca ulteriore sul modo in cui migliorare la generalizzazione dei modelli. Infine, se hai domande, non esitare a contattarmi. Grazie mille</sample>
    <sample id="114">The work focuses on addressing the limitations of large language models, such as heavy parameters and long training times. It introduces a grouped head attention method that uses a divide-and-conquer strategy to compress multi-head attention by dividing heads into groups for homogenization-based and diversification-based pruning strategies. The model achieves significant parameter compression (up to 90%) while maintaining performance improvements in machine translation (+3.8% and +4.4%), abstract summarization (+6.7% and +7%), and language modeling (+2.8% and +2.9%). Additionally, it demonstrates improved efficiency with faster inference speed (-62%) and reduced FLOPs (-80%) compared to SOTA baselines. Future research aims at task-specific automatic pruning based on the Lottery Ticket Hypothesis to further optimize redundant large language models without sacrificing performance.</sample>
    <sample id="115">L'approccio utilizza una dimensione del segmento parlato composta da 10 secondi.</sample>
    <sample id="116">Nell'esempio con Servin e Kea, è necessario conoscere che Servin è un giudice e che Kea è un pasticciere.</sample>
    <sample id="117">La qualità dell'esempio è più importante rispetto alla somiglianza con la frase sorgente.</sample>
    <sample id="118">I'll present our ACL 2023 submission, "Improving Pretraining Techniques for Code-Switched NLP". We define code-switching and discuss the importance of building computational models that can handle it. Multilingual pre-trained models like mBERT and XLM-R struggle with code-switched tasks such as question answering and sentiment analysis. Our main contributions include proposing novel MLM techniques tailored to code-switching cases: SwitchMLM, which masks only switch-point words; FrequencyMLM, using negative log likelihoods from monolingual corpora to assign LID tags; and architectural modifications involving residual connections and an auxiliary loss. The results show improved performance in sentiment analysis across different language pairs when combining these methods with ResBERT or FrequencyMLM. For probing experiments, we use linear and conditional probing to verify increased switch-point information in intermediate layers due to our proposed methods. Adding a residual connection enhances this effect by increasing switch-point information content in final representations.</sample>
    <sample id="119">Nel corso esteso, si concentra su modelli linguistici come RoBERTa e GPT-4.</sample>
    <sample id="120">Il modello utilizza i punteggi di attenzione di un livello specifico.</sample>
    <sample id="121">Esempi di inferenza diretta includono: "Easy on Me", "the first one", "the newer one".</sample>
    <sample id="122">Fudan University</sample>
    <sample id="123">The speaker introduces their research on MultiInstruct, a multi-modal instruction tuning dataset. They highlight the lack of large-scale publicly-available multi-modal instruction tasks and present MultiInstruct as the first such benchmark dataset with 62 diverse multi-modal tasks across 10 broad categories. The base model used is OFA, which uses a unified vocabulary for language, image tokens, and bounding boxes. The training involves mixing instances from all tasks and using five expert-written instructions per task. For testing, they use one group entirely (common sense reasoning) and select additional tasks from other groups to evaluate performance consistency under different instruction templates. Performance metrics include accuracy for classification tasks, Rouge-L for generation tasks, and an introduced metric called sensitivity that measures consistent output production despite slight variation in wording. Results show significant improvement over the original OFA model when transferring learning from natural instruction datasets, leading to better overall performance and reduced sensitivity. A QR code provides access to data and models related to this work.</sample>
    <sample id="124">Il progetto di Tan Qingyu e Alibaba si è concentrato sulla comprensione del "temporal reasoning" delle Large Language Models (LLMs). Hanno suddiviso il compito in tre livelli: 1) Time-to-time reasoning, che richiede solo la comprensione dell'asse del tempo; 2) Time-to-event reasoning, che include anche le relazioni tra eventi temporali; 3) Event-to-event reasoning, che richiede la comprensione di più eventi temporali. Hanno sviluppato un set di dati chiamato TempReason, che copre tutti i livelli di comprensione del tempo e varie periodicità temporali. Hanno valutato tre LLMs, identificando errori nella loro comprensione del tempo, specialmenteChatGPT. Hanno proposto una strategia di training per migliorare la comprensione del tempo delle LLMs, chiamata TempT5, e hanno dimostrato l'efficacia di questa strategia attraverso dei risultati sull'indagine TempReason.</sample>
    <sample id="125">There are 4 autori coinvolti nell'articolo.</sample>
    <sample id="126">No, traduzione automatica non è stato considerato come un approccio standard.</sample>
    <sample id="127">Il video presenta un'analisi dettagliata del paper "Large Language Models Are Reasoning Teachers" di Namgyu Ho, Laura Schmid e Se-Young Yun, studenti di magistero presso KAIST AI in Corea del Sud. L'argomento principale è la trasferimento di abilità di ragionamento utilizzando grandi modelli di linguaggio come "docenti" per inseguire i modelli più piccoli. I docenti vengono utilizzati per generare soluzioni passo-passo per compiti complessi, che poi vengono utilizzate come dati di training per i modelli studenti. Un'approccia diversa chiamata Diverse Reasoning è utilizzata per generare diverse soluzioni utilizzando una temperatura stocchastica, che aiuta a migliorare ulteriormente le prestazioni dei modelli studenti. I risultati mostrano che il metodo è accessibile, efficace e scalabile, con performance significative in 12 compiti differenti.</sample>
    <sample id="128">L'audio descrive un'attesa in una stazione di treno, con un paio di passanti che si muovono casualmente. La voce di una donna, probabilmente il conduttore del treno, annuncia il prossimo stop e richiede ai pasaggeri di prepararsi per la discesa. L'ambiente della stazione è animato, con suoni di bagliori elettrici e rumore generale.</sample>
    <sample id="129">Gli autori hanno fornito esempi di parole come "culture", "tradizione", "orgoglio" e "esotico" come parole che definiscono gruppi solo in relazione alla loro identità e li distinguono come diversi dal normale.</sample>
    <sample id="130">In un'intervista, il musicista britannico Sting dichiarò di non esser mai stato un "rockstar" e ha spiegato come la sua carriera sia stata influenzata dalla sua formazione in musica classica.</sample>
    <sample id="131">I nomi dei set di dati di test sono CIFAR-10 e CIFAR-100.</sample>
    <sample id="132">Il numero di autori coinvolti nell'articolo è 2.</sample>
    <sample id="133">L'autore opera con più modalità, ovvero con testo e immagini.</sample>
    <sample id="135">ABC-Eval è un approccio di valutazione a dimensioni per l'AI conversazionale, sviluppato da Emory University e Amazon Alexa AI. Consente di valutare diversi aspetti della qualità del chat, riducendo la soggettività dell'evaluazione umana. Utilizza la annotazione dei comportamenti nel chat, misurando le tabelle in cui il modello ignora il suo interlocuto o dice informazioni irrelevanti, si contraddice o viola la conoscenza comune. La valutazione mostra che ABC-Eval è più affidabile e predicivo rispetto ai metodi esistenti, offrendo una risoluzione più alta per comparare i modelli di AI conversazionale.</sample>
    <sample id="136">Jasivan ha presentato un progetto svolto in collaborazione con la sua supervisor, Nafise, all'Università di Sheffield. Il progetto è intitolato "FERMAT: Un Alternative per la Numerica Reasoning" e si è concentrato sulla valutazione del performance dei modelli di linguaggio in materia di calcoli. La motivazione è stata identificare una soluzione efficace per valutare la capacità numerica di questi modelli, che spesso performano peggio di quanto si potrebbe aspettare. FERMAT è una valutazione flessibile basata sui tipi armonici, utilizzando domande matematiche estratte da CommonCore e Illinois. Le domande includono vari tipi di numeri (interi piccoli, grandi, decimali) e operazioni matematiche semplici o complesse. Durante il progetto, i modelli di linguaggio sono stati esaminati attraverso una valutazione zero-shot e una sessione di fine-tuning, che ha permesso di identificare alcune carenze nella memorizzazione e nella comprensione del linguaggio. Le finestre di valutazione sono state analizzate per determinare se le differenze nel linguaggio e nelle operazioni matematiche influiscono sulle prestazioni dei modelli. I risultati indicano che l'approccio di FERMAT offre una soluzione più informatica per valutare la capacità numerica dei modelli di linguaggio, rispetto alle valutazioni tradizionali.</sample>
    <sample id="137">L'articolo presenta Tell2Design, un dataset per la generazione di piani da progetto guidata dal linguaggio. Il dataset è composto da 5.051 istruzioni linguisticheFri</sample>
    <sample id="138">Secondo gli autori, l'area della NLU che è poco studiata è la capacità di integrare e utilizzare entità e conoscenze da diverse fonti.</sample>
    <sample id="139">I nomi dei relatori sono Ying e Zhiyang.</sample>
    <sample id="140">CoScript è stato sottoposto a controlli di qualità utilizzando un processo di crowd-sourcing. I workeri della crowd-sourcing sono stati chieduti di identificare e correggere eventuali errori nella dataset.</sample>
    <sample id="141">I limiti delle risorse esistenti per la traduzione dipendente dal contesto sono: 

1. Una piccola porzione dei traduzioni dipende effettivamente dal contesto, quindi i metraggi di corpus come BLEU non riescono a raccogliere queste traduzioni.
2. Alcune persone hanno suggerito l'évaluation targeted su traduzioni dipendenti dal contesto, ma questi risorse supportano solo tipi limitati di traduzioni dipendenti dal contesto e set limitati di lingue, poiché si basano spesso su conoscenza umana e curazione.

Per risolvere questi problemi, l'approccio di questo lavoro consiste in: 

1. Misurare quanti più un termine dipende dal contesto durante la traduzione utilizzando CXMI (Contextual Mutual Information) e poi analizzare le tendenze per identificare i termini che richiedono contesto.
2. Creare un benchmark multilingue per l'évaluation del traduzione a livello di documento, utilizzando taggataggi automatici per identificare i termini dipendenti dal contesto e valutare le prestazioni delle diverse sistemi di traduzione.</sample>
    <sample id="142">Ciao Vorrei parlare del nostro lavoro sull' "Risoluzione delle espressioni implicite per la selezione degli entità", in cui abbiamo introdotto il Corpus AltEntities. Mi chiamo Javad Hosseini e questo è un lavoro in collaborazione con Filip Radlinski, Silvia Pareti e Annie Louis. Il nostro obiettivo è comprendere come le persone parlano quando vogliono fare una scelta. Considerate questa domanda alternativa: "Hai intenzione di parlare del brano 'Easy on Me' o del brano 'I Gotta Feeling'?" Qui, un utente vuole scelgere tra questi due brani. La cosa più ovviamente evidente è usare una riferimento diretto, ad esempio chiamando il nome del brano "Easy on Me" o la sua posizione, "il primo". Ma a volte un riferimento indirecto è più appropriato per avere una conversazione più naturale. Potrebbe succedere che l'utente non ricordi il nome del brano. O i pronunziamenti sono troppo simili e difficili da disambiguare. O quando l'utente vuole specificare una preferenza. Ecco alcuni esempi di riferimenti indirecti, ad esempio "il nuovo uno" o "la canzone che non è energica". Questo è un problema importante nei sistemi di conversazione e anche per il benchmarking della comprensione delle entità dei modelli di linguaggio. Non si conosce un set di dati più grande pubblico per il compito, quindi abbiamo raccolto uno utilizzando la crowd annotation. Il nostro set di dati copre tre domini diversi: musica, libri e ricette. Il nostro approccio alla raccolta dei dati enfasi l'informalità usando un setup di completamento di fumetti. Le fumetti hanno tre bubble di dialogo. Nella prima bubble, Bob dice, "Ricorda quello brano che stiamo ascoltando ieri?" E con questo, Bob definisce il contesto del dialogo. Nella seconda bubble, Alice dice, "Significa 'Easy on Me' o 'I Gotta Feeling'?" Che è una domanda alternativa. E nella terza bubble, Bob usa un riferimento indirecto per selezionare tra queste entità, ad esempio "il nuovo uno". Dobbiamo fornire automaticamente la prima e la seconda bubble, ma la terza è completata dall'annotatore. La prima bubble viene scelta tra poche istruzioni manuali per ogni dominio. La seconda bubble, che è la domanda alternativa, è generata come segue. Usiamo sempre un modello semplice. Vuoi parlare di A o B? Dove A e B sono campioni da Wikipedia. Qui sono le diverse metodi di samplers che abbiamo utilizzato. Quando ci si sposta più in alto nella lista, le entità diventano più simili l'una all'altra e è più difficile fare la disambigua. La prima è uniforme casualmente. La seconda è quando le entità hanno titoli simili, ad esempio due libri con il nome "Il Ritorno". La terza è quando hanno descrizioni simili su Wikipedia. E infine quando hanno informazioni o attributi simili su Wikipedia, ad esempio lo stesso genere o lo stesso artista per una canzone. Quando mostriamo questa domanda alternativa agli annotatori, sanno il nome delle entità, ma non necessariamente le entità. Quello che facciamo è che mostriamo alcune conoscenze di sfondo sulle entità. Per le canzoni, semplicemente diamo un collegamento di ricerca su Google per ogni canzone e chiediamo agli annotatori di ascoltare almeno un po' di ogni canzone e leggere su ogni canzone. Ecco ad esempio il risultato di ricerca su Google per la canzone "Easy on Me". Per i ricettisti e i libri, mostriamo alcune conoscenze di sfondo da Wikipedia. Per i ricettisti, inoltre, mostriamo le loro immagini, ancora da Wikipedia, in modo che gli annotatori siano sicuri di sapere come sono. Poi chiediamo agli annotatori di scegliere una delle entità e darci tre a cinque riferimenti indirettamente. Ecco alcuni esempi dal nostro set di dati. Ad esempio, "quella senza parole", "non quella con il ragazzo di 12 anni", o "quella fiscale", o "proviene dall'Azerbaigian", e così via. Il Corpus AltEntities ha 6.000 domande alternative tra tre domini e 42.000 riferimenti indirettamente. I risultati con il modello T5 XL sono riportati qui di seguito. Se il modello ha accesso alla stessa conoscenza di sfondo delle annotatori, allora la precisione è molto alta, circa il 92% al 95%. Ma questo non è realistico. Se il modello ha accesso a una conoscenza di sfondo parcialmente sovrapposta, allora la precisione è tra il 82% e il 87%, che è più realistico. Se il modello ha accesso solo ai nomi delle entità, allora la precisione è solo del 60%, quindi c'è molto spazio per miglioramento. Abbiamo anche dimostrato che i modelli sono generalizzabili tra domini. Ecco un collegamento al nostro set di dati. Grazie</sample>
    <sample id="143">Il paper confronta l'approccio proposto con tre politiche esistenti: Wait-k, Local Agreement e un modello specifico per la traduzione contemporanea.</sample>
    <sample id="144">Université de Nantes, France</sample>
    <sample id="145">Jenny</sample>
    <sample id="146">Omission in dialogue summarization is a significant issue, leading to incomplete summaries. This study analyzes the omission problem by examining its prevalence and distribution across different domains using five pre-trained models on five datasets. The results indicate that 70% of generated summaries have omission issues, with omitted information randomly distributed throughout dialogues regardless of length or domain. To address this, an omission detection task was defined: predicting which utterances are omitted from candidate summaries. A new dataset (OLDS) was created for this purpose, providing high-quality omission labels through diverse model-generated candidates and human evaluation. Three baseline frameworks were explored as baselines: pair-wise classification, sequence labeling, and pointer network. The omission detection performance showed around 50% F1-score due to label imbalance. However, when ommissions were used for refinement via post-editing, summary quality significantly improved. Thus, detecting omissions can enhance summary quality in dialogue summarization tasks.</sample>
    <sample id="147">C'è un articolo scritto da tre autori: Myra, Esin Durmus e Dan Jurafsky.</sample>
    <sample id="148">Mi chiamo Sara Papi, sono studente del gruppo di ricerca "Computer Vision and Machine Learning" della Facoltà di Scienze dell'Informazione dell'Università degli Studi di Trento e sono here da parte della Foundazione Bruno Kessler. Oggi vi presento un'articolo intitolato "Attention as a Guide for Simultaneous Speech Translation", un'opera in cui ho collaborato con Matteo Negri e Marco Turchi. Ma cosa è la traduzione contemporanea? La traduzione contemporanea, o SimulST, è il processo di tradurre una lingua parlata in un'altra lingua in tempo reale, consentendo così la comunicazione tra lingue diverse. Ma ci sono problemi nella nostra traduzione contemporanea attuale? Inoltre, siamo abituati a trainare modelli specifici, introducendo moduli aggiuntivi da ottimizzare. Questo comporta lunghe e complesse procedure di training, come ad esempio il training con obiettivi di ottimizzazione diversi. Eppure, bisogna trainare e mantenere più modelli per raggiungere differenti livelli di latenza. Ad esempio, trainare un modello con un'attesa media di un secondo e un altro con due secondi. Come risolviamo questi problemi? Primo, utilizziamo i modelli di traduzione statica esistenti senza bisogno di riedurre o di adottare architetture specifiche per la traduzione contemporanea. Utilizziamo solo uno stesso modello per ogni livello di latenza e gestiamo la latenza attraverso parametri specifici. E infine, sfruttiamo la conoscenza già acquisita dal modello attraverso la meccanica dell'attenzione tra input audio e output testuale, ovvero la meccanica di attenzione cross. La nostra soluzione è di proporsi EDAtt, ovvero Encoder-Decoder Attention, che è una strategia per decidere quando emettere o non emettere una traduzione parziale, basandosi sul luogo in cui l'attenzione puntata. Se una parola è emessa se l'attenzione non è concentrata, ovvero se la somma delle attenzioni è inferiore a un certo threshold alpha per gli ultimi lambda frammenti di discorso, significando che le informazioni ricevute sono abbastanza stabili. Per esempio, se riceviamo un frammento di discorso contenente "Sto per parlare su..." e il nostro modello predica la traduzione in tedesco, osservando i weight di attenzione cross vedremmo che le prime due parole puntano ai primi frammenti di discorso ricevuti, mentre la terza parola punta ai frammenti di discorso ricevuti più recenti, ovvero gli ultimi lambda. Questo significa che le prime due parole saranno emesse mentre, poiché la somma delle attenzioni è superiore a un certo threshold alpha, non emetteremo la terza parola e aspetteremo un altro frammento di discorso. Continuando e ricevendo altri frammenti di discorso, se il nostro modello predica tre parole e osserviamo i weight di attenzione cross, vedremmo che nessuna parola punta agli ultimi lambda. Questo significa che queste tre parole saranno emesse. Se guardiamo i risultati principali dell'EDAtt, vedremmo la traduzione contemporanea dei risultati in tedesco in grafici in cui abbiamo il BLEU, che misura la qualità della traduzione, e l'average lagging, che misura la latenza, e consideriamo anche il lagging computationally aware, che contorna i tempi di calcolo del modello per predire l'output. Vogliamo che i nostri curve abbiano il massimo possibile su questo grafico. Ma vogliamo anche che siano spostate verso sinistra. Compariamo con le strategie popolari applicate ai modelli di traduzione statica, ovvero la Wait-k e la Local Agreement. E confrontiamo anche con l'architettura state-of-the-art specificamente adatta alla traduzione contemporanea. Queste sono tutte le results della traduzione contemporanea per il tedesco. Vedremmo che superano tutte le strategie applicate ai modelli di traduzione statica, poiché le curve sono spostate verso sinistra. E se consideriamo il tempo effettivo trascorso o il lagging computationally aware, che è il più veloce strategy. Se volete scoprire maggiori results, leggete il nostro articolo. E abbiamo anche reso disponibili il codice e i modelli e la traduzione contemporanea per facilitare la riproducibilità del nostro lavoro. Grazie per la vostra attenzione.</sample>
    <sample id="149">Sì, è disponibile.</sample>
    <sample id="150">Il paper intitolato "MEETINGQA: Extractive Question-Answering on Meeting Transcripts" presenta una nuova dataset per il task diQA basata su domande e risposte in contesti di meeting. La dataset, chiamata MeetingQA, è composta da 7.700 domande e include diverse situazioni di risposta, come le risposte a livello di singolo span e multi span, e le risposte a livello di più speaker. Il paper mostra le performance delle diverse modelle di QA su questo dataset, evidenziando la difficoltà che presentano i modelli a identificare le risposte a livello di più speaker e a rilevare le domande retoriche.</sample>
    <sample id="151">Ciao a tutti, mi chiamo Ying e ho portato qui il mio collega Zhiyang per presentare la nostra ricerca intitolata "MultiInstruct: Improvando il Learning Zero-Shot Multi-Modal tramite Tuning delle Instruzioni". Con l'avanzamento dei modelli di linguaggio a larga scala, molte ricerche hanno iniziato a esplorare nuovi paradigmi di apprendimento, reutilizzando modelli preaddestrati per attività diverse tramite un modo efficiente in termini di parametri e dati. Negli ultimi anni, molte studie hanno dimostrato che il tunino delle istruzioni consente ai modelli di linguaggio a larga scala di svolgere attività non viste in maniera zero-shot seguendo istruzioni naturali. Tuttavia, la maggior parte delle precedenti ricerche sul tunino delle istruzioni si è concentrata su migliorare il performance zero-shot su attività relative solo alla lingua, mentre le attività di visione computer e multi-modal sono state leaving out. Pertanto, nel nostro lavoro vogliamo indagare se il tunino delle istruzioni di modelli multi-modal preaddestrati può migliorare la generalizzazione alle attività non viste multi-modal. Inoltre, al tempo della nostra ricerca abbiamo scoperto una considerabile disparità nella disponibilità dei dataset di istruzioni tra NLP e multi-modal. Esistono più di 1600 attività di istruzioni solo per la lingua. Tuttavia, non esiste nessun grande set pubblicamente disponibile di attività di istruzioni multi-modal. Questo ci ha spinto a costruire MultiInstruct, il primo benchmark di tunino delle istruzioni multi-modal che contiene 62 attività diverse multi-modal coprendo 10 categorie diverse. Queste attività sono derivate da 21 dataset aperti esistenti e ogni attività è equipaggiata con tre istruzioni esperte scritte. Per indagare il tunino delle istruzioni multi-modal sul nostro dataset proposto, abbiamo scelto OFA, un modello preaddestrato multi-modal unificato, come modello base. L'OFA utilizza un vocabolario unico per i token della lingua, delle immagini e delle coordinate di una casella di bordo. Qui vedremmo alcuni esempi di istruzioni dal nostro dataset MultiInstruct. Per unificare il processing dei diversi tipi di input e output dati, seguenti il metodo dell'OFA e si formulano tutte le attività in una forma di codifica sequenziale unica. In cui il testo, le immagini, le istruzioni e le caselle di bordo sono rappresentati nel lo stesso spazio di token. Adesso parlerò del tunino delle istruzioni multi-modal. Per il set di train, utilizziamo 53 attività da 9 gruppi per il training e selezioniamo 10.000 istanze per attività. Per il test, riserviamo tutto il gruppo di ragionamento comune per il test e selezioniamo 5 attività ulteriori dal gruppo VQ e Miscellaneous. Utilizziamo tutte le istanze nel set di test per ogni attività. Inoltre, tiriamo a caso 20 attività dal set di test del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train del set di train</sample>
    <sample id="152">The presentation discusses the development of new language models for classical philology, focusing on Ancient Greek and Latin. The team created monolingual models (GreBERTa and GreTa) and multilingual models (PhilBERTa and PhilTa), pre-trained using a high-quality corpus from the Internet Archive. They benchmarked these models against existing ones in tasks like part-of-speech tagging, dependency parsing, lemmatization, semantic knowledge, and world knowledge. Results show significant improvements over previous models, with no clear advantage to multilingual training.</sample>
    <sample id="153">Ninareh Mehrabi presenta un studio sull'ambiguità nelle istruzioni per i modelli di generazione immaginaria tramite testo. La pesca ha curato un set di dati di riferimento e ha sviluppato un'architettura di disambiguaione che utilizza domande clarificanti o visualizzazioni diverse per mitigare queste ambiguità. L'architettura è valutata attraverso un modello VQA, mostrando una congruenza con l'evaluazione umana e evidenziando disparities nella risoluzione delle ambiguità per tipi diversi.</sample>
    <sample id="154">Sara Papi è affilata alla University of Trento e alla Foundazione Bruno Kessler.</sample>
    <sample id="155">Javad Hosseini</sample>
    <sample id="157">In questa presentazione, Shen Gao ha presentato un modello di sintesi di dialogo chiamato SDDS. Il modello utilizza un encoder per codificare le utteranze del dialogo in rappresentazioni vetoriali, e una struttura di grafici statica per costruire la relazione tra le utteranze. Inoltre, utilizza un modulo di grafico dinamico per capturare le relazioni semantiche tra le utteranze basate sulle loro rappresentazioni vetoriali profonde. Infine, utilizza un generatore di lingua preaddestrato per fusionare la struttura del grafico statico e dinamico nel processo di generazione finale.</sample>
    <sample id="158">Qipeng Guo di AWS presenta un'opera intitolata "Dual Cache per la risoluzione neuronale del riferimento a fiandre a lungo documento". La risoluzione del riferimento consiste nell'identificare le menzioni e clusterizzarle in base alle entità che le riferiscono. Metodi tradizionali sono costivi quadrati, mentre i metodi cache-based riducono il complesso lineare. Tuttavia, nella presenza di documenti lunghi, l'approccio LRU causava spesso errori di miss di cache. Per risolvere questo problema, è stato proposto un dual cache con una cache locale e una cache globale che funzionano insieme. La cache locale archivia entità locali con un policy di evicione LRU, mentre la cache globale archivia entità globali con un policy di evicione LFU. Questo approccio è stato valutato su quattro dataset pubblici e mostra una performance migliore rispetto ai metodi di base, riducendo anche i miss di cache.</sample>
    <sample id="159">Ciao a tutti, mi chiamo Koustav Sinha e vi saluto per la vostra partecipazione al nostro discorso sul nostro articolo presentato alla ACL 2023. I linguaggi non sono sempre solidali nei ju</sample>
    <sample id="160">Nel primo passaggio del metodo, ogni token di input viene mappato a un token di output associato.</sample>
    <sample id="161">In total, 55,000 specific goals with scripts are represented in CoScript.</sample>
    <sample id="163">Il metodo di allineamento migliore per DEplain è MASSalign.</sample>
    <sample id="164">L'apprendimento scarsamente supervisionato è una tecnica che permette di utilizzare dati etichettati in modo scarso per addestrare modelli di machine learning. Questo approccio consente di ridurre i costi di etichettatura manualmente, poiché si utilizzano fonti di etichettatura scarce come regole semplici, banche di conoscenza o workercrowd di bassa qualità. Tuttavia, è importante notare che l'apprendimento scarsamente supervisionato richiede dati etichettati in modo pulito per la selezione del modello e per garantire il buon funzionamento del processo di apprendimento.</sample>
    <sample id="165">Wenting Zhao, un PhD student di Cornell University, presenta la loro recente pubblicazione intitolata "Reasoning with Abductive Commonsense Exploiting Mutually Exclusive Explanations". Inizia con un esempio per illustrare il concetto di abductive reasoning: "Emily era incinta in trafiico" e "Emily è arrivata in tempo per il suo volo". La sua approccio consiste in un modello di apprendimento unsupervisato chiamato LiPoR (Likelihood Learning with Posterior Regularization), che utilizza una variabile latente Z per identificare una sottosettazione plausibile tra le spiegazioni. L'obiettivo di LiPoR è di maximizzare la probabilità condizionale della trama data il contesto, utilizzando una regolarezza che punisce le spiegazioni che sono mutuamente esclusive. I risultati sul dataset AlphaNLI mostrano che LiPoR supera tutti gli altri modelli, incluso un baseline GPT-3 zero-shot, con una precisione superiore del 4 punti.</sample>
    <sample id="166">Introduzione: La complessità della ricerca immagine-risorsa da testo linguisticamente complesso è un problema diffuso, poiché le immagini sono simili e le descrizioni sono lunghe. I modelli di visualità linguistica, come i modelli preaddestrati, funzionano bene per la ricerca immagine-sentence ma performano peggio quando si confrontano con testi complessi. Per risolvere questo problema, siamo inspirationati alla strategia Divide-and-Conquer e alla Teoria del Dual-Process. Divide-and-Conquer consiste nell'approccio a problemi grandi dividesendoli in problemi più piccoli, risolvendoli e combinandoli per ottenere il risultato desiderato. La Teoria del Dual-Process descrive due sistemi di pensiero umano: il sistema 1 esegue ragionevole analogica e il sistema 2 è in grado di ragionare logico, adatto per problemi complessi. I modelli preaddestrati di visualità linguistica si concentrano sulla ragione analogica del sistema 1, ma il loro performance diminuisce drasticamente quando si confrontano con complessi problemi. Potremmo avere bisogno di un sistema logico per risolvere i problemi complessi tramite operazioni logiche. Unire le vantaggi del sistema 1 e del sistema 2 potrebbe essere una soluzione significativa per i problemi complessi. Il primo modello per il nostro metodo è il Generatore di Proposizioni. Si occupa di decomporre la proposizione complessa in rappresentazioni delle proposizioni semplici. Utilizzando anche la decoder di BART per generare le corrispondenti frasi, il sistema 1, chiamato Interagente Visual-Linguistico, esegue l'interazione tra informazioni di proposizioni visive e immagini, simile al sistema 1. Le usate di questo modulo sono i punteggi di match delle proposizioni e delle immagini e i loro stati di ragionamento. Introduce allora il Neural-Symbolic Reasoner come un sistema 2. È responsabile di integrare gli stati di ragionamento e i risultati delle proposizioni semplici per ottenere la soluzione finale della proposizione complessa sugli immagini. Consiste nel negatore esegutore e nell'operazione di conjunction. Il negatore esegutore si occupa di ottenere lo stato di ragionamento negativo della proposizione positiva. L'operazione di conjunction è responsabile di ottenere i risultati dell'inferenza basati sulle ragioni positive e negative. Infine, combiniamo i risultati dell'inferenza dei sistemi 1 e dei sistemi 2 per ottenere la soluzione finale. Per dimostrare l'efficacia del nostro metodo, presentiamo i risultati sperimentali e le analisi delle abolitioni. Inoltre, presentiamo due casi per verificare ulteriormente il performance del nostro metodo. Potremmo presentare alcune proposte: prima, la calcolazione neuronale-simbolica è un approccio utile per migliorare la complessità della ragione e del piano di programmazione dei modelli di grande lingua. Divide-and-Conquer è simile alla catena di pensiero autocheta, che divide i problemi complessi in problemi più piccoli e costruisce un percorso di ragionamento. La Teoria del Dual-Process può essere integrata con Divide-and-Conquer.</sample>
    <sample id="167">I documenti in DEplain-web sono stati allineati manualmente e automaticamente.</sample>
    <sample id="168">Il set di dati CoNLL++ è stato creato utilizzando il dataset Reuters News del 2020 e seguentemente etichettato con le stesse linee guida di etichettatura utilizzate per CoNLL-2003.</sample>
    <sample id="169">L'articolo "Prompting PaLM per la traduzione: Assessare le strategie e il performance" è una collaborazione con colleghi del Google Translate. PaLM è un modello di linguaggio grande con 540 milioni di parametri, trainato su un vasto set di testo composto da 780 miliardi di token. L'anno scorso, ha raggiunto il record di prestazioni in centinaia di compiti di NLP. Questo studio è il primo approccio sistematico alla prompting di modelli di linguaggio grande per la traduzione. Utilizzando le migliori pratiche della comunità MT, valutiamo la capacità di trasformazione dei modelli di linguaggio grandi utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizzando i migliori modelli MT, valutiamo l'efficacia del modello di linguaggio grande utilizzando i migliori modelli MT. Utilizz</sample>
    <sample id="170">Ciao a tutti, mi chiamo Yusen Zhang e sono studente all'Università di Pennsylvania. Oggi presento il nostro lavoro "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations". La semantica parsing è una attività che consiste nell'ottenere rappresentazioni semantiche delle query utente, come SQL e Calcolo Lambda. Il parsing semantico crosslingue è la attività di tradurre le query in diverse lingue naturali in diverse rappresentazioni di significato. Come mostrato in questa grafica, bisogna tradurre le query in diverse lingue naturali utilizzando modelli neurali per SQL, Lambda o FunQL, ecc.. Esistenti modelli di parsing semantico crosslingue sono stati propositi e valutati su dataset limitati e applicazioni. Per esempio, ci sono molte copertura su certe lingue naturali, ma non su cinese e manca di copertura su certe rappresentazioni significative, come il Calcolo Lambda. Per risolvere questo problema, abbiamo proposto XSemPLR. Offrirà un set di dati uniforme XSemPLR per il parsing semantico crosslingue in diverse lingue naturali e rappresentazioni significative. Contiene 9 dataset in varie domande, 5 attività di parsing semantico, 8 rappresentazioni significative e 22 lingue naturali in 15 famiglie linguistiche. Per valutare meglio il nostro benchmark, consideriamo i sei setting per la training e l'evaluazione. Il primo setting è Translate-Test. Utilizziamo l'API Google Translate per tradurre il linguaggio di origine nel linguaggio di destinazione, quindi utilizziamo un modello monolingue per la training e l'evaluazione. Ad esempio, trainiamo un modello inglese con query inglese e durante l'inferenza tradiamo la query tedesca usando l'API in inglese e poi utilizziamo il modello trainato per predire il SQL. E anche testiamo il modello Monolingue. In questo setting, il linguaggio di origine è lo stesso del linguaggio di destinazione, ad esempio tedesco tedesco o inglese inglese. Abbiamo anche testato il setting Monolingue Few-shot, in cui trainiamo un modello monolingue con solo il 10% dei dati di training. E abbiamo testato il modello Multilingue, in cui trainiamo un modello multilingue per tutte le lingue. Ad esempio, mettiamo le query tedesche, inglese e cinese insieme per trainare un modello multilingue. E durante l'inferenza possiamo utilizzare questo modello per tradurre le query tedesche o le query cinesi, ecc.. E abbiamo anche considerato il setting Cross-lingual Zero-shot e Cross-lingual Few-shot transfer. Trainiamo su un linguaggio di origine e si trasferisce a un altro linguaggio. Durante la training, trainiamo su query inglese o una combinazione di query tedesche e inglese Few-shot per trainare un modello multilingue. E durante l'inferenza possiamo utilizzare questo modello per tradurre le query tedesche o le query cinesi, ecc.. E abbiamo trovato molti risultati interessanti. Riguardo l'analisi dei modelli monolingue, valutiamo due gruppi di modelli, tra cui Encoder-PTR, che significa Encoder Pre-trained Multilingual con Decoder Pointer-based, come XLM-R + PTR e mBERT + PTR. E, valutiamo anche Encoder-Decoder, che significa Encoder Pre-trained Multilingual-Encoder-Decoder Models, come mBART e mT5. Abbiamo trovato che Encoder-Decoder ottiene il miglior risultato su tutti i nove dataset. E valutiamo mT5 e XLM-R + PTR nel setting multilingue. Abbiamo trovato che Encoder-Decoder o Encoder-PTR possono essere migliorati trainando in una mistura di varie lingue. Abbiamo trovato che la maggior parte delle principali lingue naturali ottopre una crescita del performance, ecc... E siamo interessati a analizzare i risultati. Per riassunto, abbiamo creato XSemPLR, un benchmark unico per il parsing semantico crosslingue con diverse lingue naturali e rappresentazioni significative.</sample>
    <sample id="171">The speaker mentions that existing works can be broadly classified into four categories, but these methods either are not applicable to embedding as services or lack transferability. Therefore, the proposed method in this paper is a new solution addressing these limitations by introducing an embedding marker based on backdoor watermarking techniques suitable for embedding as services.</sample>
    <sample id="172">No, according to the presentation, pretraining on English natural language can significantly boost performance in Few-shot on target languages, and multilingual language models such as Codex and Bloom are still inadequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="174">Il video presenta una breve panoramica del dataset ArgAnalysis35K, creato per l'analisi della qualità degli argomenti. L'autrice, Thea, spiega come il dataset è diverso rispetto ad altri disponibili, grazie alla sua grande quantità di dati (35.000), alla sua elevata qualità delle espressioni e alla sua ampia varietà di argomenti. Inoltre, il dataset include un modello di relevanza che valuta la rilevanza di ogni argomento rispetto a un tema specifico, e utilizza un sistema di analisi che include una combinazione di dichiarazioni, premi e ragioni. Questo approccio permette una migliore analisi e una classificazione più accurata degli argomenti, rendendo il datasetArgAnalysis35K un'opzione utile per gli investigatori e gli sviluppatori di algoritmi di NLP.</sample>
    <sample id="175">Il metodo utilizza un approccio continuo per risolvere l'ambiguità delle permutazioni, che è una versione del problema del "Venditore che visita tutte le città". L'ambiguità deriva dal fatto che ci sono spesso più permutazioni possibili consistenti con i dati, ma solo una è linguisticamente plausibile. Per risolvere questo problema, il metodo utilizza una relaxazione continua che consente di ottenere una soluzione approssimata. Inoltre, esso permette di backpropagare attraverso la soluzione e di immettere informazioni sul linguaggio plausibile. Questo approccio consente di affrontare efficacemente l'ambiguità delle permutazioni, garantendo che il modello preda considerazioni linguistiche plausibili durante l'apprendimento.</sample>
    <sample id="176">Un modello NLP è definito come "equitativo" quando non presenta preoccupazioni di pregiudizio o di discriminazione basate sul genere, etnia o orientamento LGBTQ+, e funziona correttamente per tutti gli utenti indipendentemente dal loro profilo demografico.</sample>
    <sample id="177">Il relatore è Yanis Labrak.</sample>
    <sample id="178">Koustav Sinha</sample>
    <sample id="179">La ricerca si è concentrata sull'individuare una soluzione per migliorare la capacità di inferenza del linguaggio nei modelli di macchina intelligence. Si è sviluppato un algoritmo chiamato SymbolicToM, che utilizza rappresentazioni grafiche esplicite per aiutare i modelli a comprendere meglio le mentalità delle persone. Gli esperimenti hanno dimostrato che il performance dei modelli è migliorato significativamente con l'uso di SymbolicToM, in confronto ad approcci guidati alla supervisione.</sample>
    <sample id="180">Il nome della relatrice è Myra.</sample>
    <sample id="181">La nostra ricerca sviluppata presso la Fudan University si è concentrata sull'individuazione e svolta del problema della pianificazione linguistica con restrizioni. La nostra</sample>
    <sample id="182">Nel contesto di questo articolo, il "tropicalismo" si riferisce a un'archetipo che viene assegnato alle donne latinesche. Questo archetipo è associato ad attribuzioni come "vibrante", "curvaceous" e simili, che collegano le donne latinesche alla cultura e alla tradizione della Toscana. Tale archetipo è considerato un esempio di stereotipo che contribuisce alla stigmatizzazione e alla discriminazione delle donne latinesche, poiché definisce loro solo attraverso la loro identità etnica e le loro origini culturali, separandole dallo standard normativo.</sample>
    <sample id="183">Ispirandosi a un studio in cui si ha chiesto ai sujets di descrivere una persona utilizzando una prompt, i membri della squadra hanno chiesto alla modello di generare una rappresentazione umana utilizzando una prompt simile.</sample>
    <sample id="184">Per misurare l'utilizzo del contesto in questo lavoro, sono stati utilizzati due principali strumenti: CXMI (Contextual Mutual Information) e P-CXMI (Pointwise Contextual Mutual Information). CXMI è stato utilizzato per misurare generalmente l'utilizzo del contesto in un modello di traduzione, mentre P-CXMI è stato esteso per misurare questo utilizzo al livello di frase o al livello di parole. Queste metriche aiutano a identificare le parole che richiedono contesto per essere tradotte correttamente.</sample>
    <sample id="185">DrBERT è un modello biomedical in francese basato su RoBERTa e trainato su NACHOS, mentre ChuBERT è un modello clinico basato su anonymizzati data ottenuti dal warehouse di dati dell'ospedale di Nantes.</sample>
    <sample id="187">L'articolo è scritto da due autori: Ying e Zhiyang.</sample>
    <sample id="188">Il trasferimento iterativo dell'apprendimento è una strategia di apprendimento a livello di dominio che utilizza il trasferimento di pesos da un modello di apprendimento esistente a un modello di apprendimento nuovamente inizializzato. In questo modo, il modello di apprendimento può utilizzare i pesos del modello esistente per iniziare l'addestramento del modello nuovamente inizializzato, riducendo il tempo di addestramento e migliorando le prestazioni.</sample>
    <sample id="189">L'obiettivo del set di dati è comprendere la lingua utente quando vuole fare una scelta.</sample>
    <sample id="190">Un utente malintenzionato può estrarre i parametri del modello attraverso un EaaS copiando l'embedding e imparando da esso.</sample>
    <sample id="191">C'è un autore coinvolti nell'articolo.</sample>
    <sample id="192">The speaker introduces their work, "CAME: Confidence-guided Adaptive Memory Efficient Optimization", which aims to design an optimizer that achieves fast convergence like traditional adaptive methods and low memory usage as in memory-efficient methods. They discuss the challenge of balancing these two goals while addressing errors caused by non-negative matrix factorization (NMF) operations used in existing optimizers like Adafactor. The presentation includes preliminary concepts such as NMF and its application in reducing memory requirements for matrices. It explains how CAME addresses erroneous updates through a confidence-guided approach, using residual between predicted update and generated update to adaptively take optimization steps. Experiments on BookCorpus and English Wikipedia demonstrate CAME's effectiveness compared to Adam and Adafactor across different batch sizes and tasks, showing improvements in validation accuracy and efficiency with reduced memory cost.</sample>
    <sample id="193">No information is provided about the number of annotators used to create the initial data set.</sample>
    <sample id="194">I'm sorry, but I can't provide the affiliations of the authors from their presentation.</sample>
    <sample id="195">The speaker introduces their work, "Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering," which aims to answer complex questions and provide explanations. They highlight the limitations of previous methods in XQA: neuro-symbolic methods can only be executed on structured KBs due to incomplete data, while decompose-based methods rely solely on free-text corpora, making them difficult for answering complex questions intuitively. The proposed solution is a novel framework called RoHT (Reasoning over Hierarchical Question Decomposition Tree), which consists of two stages: building the Hierarchical Question Decomposition Tree (HQDT) by decomposing the question into sub-questions and probabilistic reasoning over HQDT using knowledge from a KB and text corpus at different levels. This approach helps solve complex QA tasks more effectively than existing methods like TransferNet or EX(SA).</sample>
    <sample id="196">L'esempio in cui il governatore è a sinistra è "I saw Bart and Lisa".</sample>
    <sample id="197">I modelli all'avanguardia nei sistemi di dialogo sono Amazon Alexa AI e Emory NLP Lab.</sample>
    <sample id="198">La valutazione dell'accettabilità dei modelli throughout la finestra di contesto è necessaria perché i modelli di linguaggio moderni utilizzano spesso larghe finestre di contesto per comprendere e generare testo. La valutazione con solo una frase non mostra completamente l'architettura del modello e le informazioni che contiene, poiché i modelli utilizzano le informazioni contenute in più frasi per comprendere il contesto e la coerenza del testo.</sample>
    <sample id="199">Sì, l'allenamento multilingue ha causato un calo delle prestazioni rispetto al modello inglese monolingue.</sample>
    <sample id="200">No, gli annotatori non conoscono l'entità in anticipo.</sample>
    <sample id="201">I metriche di traduzione utilizzate per la valutazione sono le metriche neurali MT state-of-the-art e l'evaluazione basata sulle esiti umani.</sample>
    <sample id="202">Il regresso nella generalizzazione influisce su NER causato da temporale drift.</sample>
    <sample id="203">La posizionalità nella NLP è importante perché aiuta a identificare e a mitigare i bias presenti nei dataset e nei modelli, garantendo un'approccio più equo e inclusivo.</sample>
    <sample id="204">I LLM multilingue come BLOOM sono stati affinati con una messa a punto integrale.</sample>
    <sample id="205">Shangbin, PhD student in the University of Washington, presenta un'analisi sullo sfruttamento del linguaggio da parte delle modelle di NLP e le potenziali sfide relative alla neutralità politica. Le modelle di NLP sono trainate su grandi quantità di dati web, tra cui notizie politiche, che potrebbero portare a una distribuzione politicamente imparzializzata. Tuttavia, i modelli potrebbero acquisire tendenze politiche, come dimostrano i risultati preliminari che indicano una dispersione politica tra i modelli. L'investimento è stato condotto utilizzando domande politiche standard e corpora di training partisan, evidenziando come i modelli possano acquisire tendenze politiche diverse. La discussione si concentra sull'importanza di gestire le sfide relative alla neutralità politica per garantire la giustizia sociale nelle applicazioni di NLP.</sample>
    <sample id="206">Utilizziamo il trasferimento del modello di apprendimento tramite trasferimento zero-shot, utilizzando i modelli di trasferimento da due attività diverse: la classificazione di stili di dibattito e la classificazione di espressioni e di confronti.</sample>
    <sample id="207">I set di test più recenti utilizzati per valutare le capacità di PaLM sono i WMT (Workshop on Machine Translation) evaluations.</sample>
    <sample id="208">I'm sorry, I can't answer that question based on the information provided.</sample>
    <sample id="209">Il metodo proposto è più efficiente rispetto al metodo di riferimento in quanto genera script di alta qualità, riduce la varianza e ottiene risultati migliori sia per la completeness semantica che per la fedeltà alle restrizioni.</sample>
    <sample id="210">Shuheng</sample>
    <sample id="211">Sì, i risultati e il set di dati dell'articolo possono essere utilizzati come parametri di riferimento.</sample>
    <sample id="212">Nel testo, viene menzionato solo un modello più piccolo: T5 fine-tuned.</sample>
    <sample id="213">OFA è utilizzato come modello di base per analizzare l'ottimizzazione delle istruzioni multimodali.</sample>
    <sample id="215">Hi, my name is Adam Przepiórkowski and this talk is about the Dependency Structure of Coordination. As you may know, there are different dependency structures assumed by different theories and corpus approaches. So for example, in the universal dependencies, the structure of the coordination, Lisa, Bart, and Maggie, such that the first conjunct is the head of the whole coordinate structure. So in this case, Lisa. A similar approach is assumed in Igor Mel'čuk's meaning text theory, where again, the whole coordinate structure is headed by the first conjunct. Right. These two approaches are asymmetric. They single out one of the conjuncts. Now those are asymmetric approaches to coordinate structures, such as the Prague approach. The conjunction headed approach assumed in Prague dependency treebanks, where coordinate structures are headed by the conjunction. So we get some dependencies from end to all the conjuncts. And finally, there's also a multi-headed approach that's used, for example, in the Hudson's Word Grammar, where they say all conjuncts are heads of the coordinate structure. We get dependencies from the governor. Here loves to all conjuncts separately: Lisa, Bart, and Maggie. Now the aim of this paper is to produce a novel argument for the symmetric structures of coordination, like these two and against the asymmetric structures of coordination, like these two. OK. The argument is based on the principle of dependency length minimization that I will explain on the basis of these examples. So in English, as you might know, direct objects prefer to be close to the verb, while adjuncts may be further away. "Marge read it yesterday" is fine because the direct object is close to the verb, while "Marge read yesterday it" is much worse. However, this effect may be ameliorated when the direct object is very heavy and very long. Because then it can be moved to the position after the adjunct. This is illustrated here. So both these sentences are fine. "Marge read this absolutely fascinating book about bees yesterday." It's okay the way instead of "it", we have this long NP. But it's also OK to say, "Marge read yesterday this absolutely fascinating book about bees." So the reasoning here is that this is possible because even though this sentence violates the general grammatical principle that direct objects should be next to the verb, it satisfies the principle of dependency length minimization, which says that shorter dependencies are preferred. So these two trees only show the length of the crucial dependencies, the ones that are not constant among these two structures. So here we have a dependency from "read" to the adjunct of length 7 measured in words and from "read" to "book" of length 4, so together it's 11. When you swap these two constituents, the sum of these two dependencies becomes 6. So instead of 11, 6 is much shorter. That's why this sounds quite okay. Right? It violates one principle, but it satisfies another one. Ok. So what we did, we extracted various statistics about coordination from the enhanced version of the Penn Treebank and see the paper "Why wouldn't you use universal dependencies" and these statistics confirm the observation made many times before that left conjuncts tend to be shorter. So, "salt and pepper" and not "pepper and salt", measured in syllables. And, also the observation that was made in parsing that this tendency grows with length difference. So when the difference between the lengths of the two conjuncts grows, the shorter conjunct prefers to be the first one, stronger, right? So the proportion is bigger of the left short conjunct. But what's novel in this paper is that we observed that this tendency only occurs when the governor is on the left or absent. Right? So the governor is on the left in this example "I saw Bart and Lisa" so is the governor is on the left. It's absent in the second example "Homer came and sneezed." Here we have coordination of two verbs and there's no outsides, external governor. In such cases, the left conjunct prefers to be shorter; the most of the biggest difference between the two conjuncts. However, when the governor is on the right, as here, "laughed" governs the coordination Ted and Ned, this effect disappears. So we showed that by measuring length in characters, the first column, in syllables the middle column, and in words the right column. So I'll concentrate on the right one. What we see here is that when the governor is on the left, the tendency for the left conjunct to be shorter grows steadily, with the absolute difference in words, and the same is observed when there is no governor as in coordination of sentences. But when the governor is on the right this tendency disappears. And we show in the paper how this provides an argument against asymmetric structures of coordination, as these two, and for the symmetric structures, as these two. See the paper for the full arguments. And talk to us about at the poster session. Thank you.</sample>
    <sample id="217">In questo studio, siamo approfonditi la generalizzabilità composta per la generazione controllabile di dialogo a multi-attributo e abbiamo proposto un modello di generazione controllabile composta che utilizza prometteri. Abbiamo sviluppato un'evaluazione unica e efficiente che non richiede dati etichettati aggiuntivi e abbiamo dimostrato l'efficacia del nostro modello e delle nostre metriche attraverso esperimenti.</sample>
    <sample id="218">I'm sorry, but I can't provide the affiliations of the authors from this content. The information given is about a presentation and its contents rather than details on authorship or their institutions. If you need to know who the authors are and where they work, you might want to look at the paper itself or contact the presenters directly for more detailed information.</sample>
    <sample id="219">Jia-Huei Ju, un assistente di ricerca all'Accademia Sinica, ha presentato il loro lavoro "Un pipeline multistagio Compare-and-Contrast per scoprire segnali finanziari nei report". Il lavoro è stato realizzato insieme a Yu-Shiang Huang, Cheng-Wei Lin e i loro advisor Professori Che Lin e Chuan-Ju Wang. La presentazione ha avuto luogo durante la conferenza ACL 2023. Il work è stato motivato da due osservazioni: la somiglianza tra i documenti dei report annali e l'importanza del contesto relativo. La presentazione ha illustrato il pipeline proposto, composto da tre fasi, e ha fornito dettagli sull'approccio utilizzato per il training e l'evaluazione del modello.</sample>
    <sample id="220">Vasudha è studentessa di dottorato in Informatica applicata alla scienza del linguaggio presso Stony Brook University.</sample>
    <sample id="221">L'articolo ha analizzato le seguenti coppie linguistiche:</sample>
    <sample id="222">Questa ricerca esplora le sfide e le soluzioni per l'adattamento di modelli diQA in dominio aperto, focalizzandosi sullo sviluppo di interventi dati efficaci per la generalizzazione. Utilizzando un setup di dominio sorgente Wikipedia e domini target vari, si esaminano diversi metodi di interventi dati, come zero-shot e few-shot, per migliorare la performance dei modelli diQA. Si identificano anche le tipologie di shift di dataset e le interazioni tra variabili come domanda, risposta e contesto. I risultati mostrano che i modelli diQA possono essere adattati efficacemente utilizzando interventi dati specifici, con una media di miglioramento del 24% nella performance del modello diQA Readers.</sample>
    <sample id="223">Shangbin</sample>
    <sample id="224">I modelli studiati sono Long-MBART e mBART.</sample>
    <sample id="225">Quello che ho detto è che 53 attività sono utilizzate per il training e 10 attività diverse sono utilizzate per il test.</sample>
    <sample id="226">Due autori sono coinvolti nell'articolo: Regina Stodden e Omar.</sample>
    <sample id="227">Il linguaggio è un mezzo di comunicazione che ci permette di esprimere idee, pensieri e emozioni. Ciò significa che il linguaggio è una forma di comunicazione complessa che richiede una comprensione approfondita della lingua e del contesto in cui viene utilizzato. La lingua è un'arte che richiede la padronanza della grammatica, della scrittura e della pronuncia, ma è anche un'arte che richiede la comprensione del significato e della struttura del messaggio che si vuole trasmettere. Inoltre, il linguaggio è un meccanismo di comunicazione che può essere utilizzato per esprimere emozioni, creare rapporti e influenzare le opinioni delle persone.</sample>
    <sample id="228">AG News, MIND, SST2 e Enron Spam.</sample>
    <sample id="229">La nostra ricerca si concentra sull'identificazione di dichiarazioni non rafforzate in contesti argomentativi, utilizzando revisioni basate su dati. Esploriamo i principali problemi che si verificano durante la fase di progettazione esperimentale, come la rappresentatività e la affidabilità dei dati, la complessità del modello e l'architettura, l'effetto del contesto e il bias topico e utente.</sample>
    <sample id="231">NACHOS è un dataset di informazioni medico-civili estratte dal web in lingua francese.</sample>
    <sample id="232">David Vilar</sample>
    <sample id="233">La traduzione contemporanea è un processo di tradurre il linguaggio parlato in un altro linguaggio in tempo reale, consentendo la comunicazione tra lingue diverse. Attualmente, i modelli di traduzione contemporanea utilizzano architetture specifiche e richiedono lunghe e complesse procedure di training, spesso trainando diversi modelli per differenti tempi di latenza. Per risolvere questi problemi, abbiamo proposto EDAtt, una strategia che utilizza l'attenzione già acquisita dal modello per decidere quando emettere una traduzione parziale. Utilizzando solo un modello per ogni regime di latenza e gestendo la latenza attraverso parametri specifici, abbiamo dimostrato che la nostra approcciatore supera le strategie esistenti applicate a modelli offline, raggiungendo un'alta qualità della traduzione e una bassa latenza.</sample>
    <sample id="234">La strategia del prompting ha un grande impatto sulle prestazioni, come evidenziano gli esperimenti presentati. In particolare, l'esempio di una semplice elaborazione con un solo shot di prompting mostra una differenza superiore a 1 BLEURT point, e in casi estremi, fino a 40 BLEURT points. Questo suggerisce che è importante scegliere una buona strategia di prompting per ottimizzare le prestazioni delle LLM per la traduzione.</sample>
    <sample id="235">I'm sorry, but I don't have enough information to determine the affiliations of the authors based on their presentation.</sample>
    <sample id="236">Le 5 istruzioni scritte da esperti sono:</sample>
    <sample id="237">I autori proposono di utilizzare un test di diagnosi per valutare l'integrazione del conoscenza proveniente da più fonti.</sample>
    <sample id="238">Il video presenta un nuovo dataset di riepilogo di conferenze, chiamato MeetingBank, creato dall'università di Florida Centro. L'autore, Yebowen Hu, spiega come la creazione di questo dataset è stata realizzata risolvendo due principali sfide: la disponibilità di riepilogni di alta qualità e la complessità del processo di raccolta dei dati. La creazione di MeetingBank include una raccolta di 1.366 conferenze e circa 7.000 istanze, con statistiche dettagliate sulle durate delle conferenze, il numero di token e le fonti delle conferenze. Il dataset è stato creato utilizzando Speechmatics API per convertire il suono in testo, identificando le conferenze e le loro minute, e associandole ai riepilogni delle conferenze. I modelli di riepilogo utilizzati includono Oracle, LEAD, LexRank, TextRank, BART-Large, Pagasus, Longformer, DialogLM e HMNet. Gli esperimenti di valutazione hanno messo a confronto questi modelli, raggiungendo risultati interessanti, come la performance eccellente di GPT-3 in termini di fluidezza e coerenza. Infine, il dataset MeetingBank è offerto come strumento utile per gli investigatori per sviluppare tecnologie avanzate di riepilogo delle conferenze.</sample>
    <sample id="239">Ciao a tutti, mi chiamo David Vilar e darò un breve recensione del paper "Prompting PaLM per la traduzione: Assessando strategie e prestazioni". Questo è un lavoro in collaborazione con colleghi del Google Translate. PaLM è un modello di linguaggio grande 540 miliardario presentato l'anno scorso, 2022. È addestrato su una vasta raccolta di testo composta da 780 miliardi di token. All'uscita del paper, aveva raggiunto le prestazioni state-of-the-art in centinaia di attività NLP. In questo lavoro, presentiamo il primo studio sistematico sull'adattamento di modelli di linguaggio grandi tramite prompting per la traduzione. Effettuamosi l'evaluazione della capacità di trasformazione dei modelli utilizzando le migliori pratiche della comunità MT. Questo implica l'utilizzo delle migliori set di test per evitare un sovrapporsi dei dati di test ai dati di addestramento del modello di linguaggio. E confrontiamo i nostri risultati con quelli degli sistemi di traduzione state-of-the-art, ovvero i migliori performing del WMT Evaluation. Utilizziamo metriche neurali di traduzione state-of-the-art e inoltre mostriamo risultati di valutazione umana esperta. Infine, forniamo alcune raccomandazioni per le strategie di selezione del prompting. Il prompting ha un grande impatto sulle prestazioni dei modelli di linguaggio grandi per la traduzione, come lo vedremo in un semplice esperimento dove abbiamo utilizzato un prompting a un shot e abbiamo fornito due differenti prompts per ogni frase. La maggior parte delle frasi, 516 su 1.000, mostrano una differenza osservata di più di un BLEURT point. Potrebbe andare fino a 40 BLEURT points in casi estesi. È importante scegliere una buona strategia di prompting. Nelle nostre esperimentazioni, si è arrampicata a una strategia di prompting a 5 shots dove abbiamo segnato ogni frase che abbiamo fornito al sistema con la lingua in cui è scritta. Nell'esempio qui, dove effettuamo la traduzione dal tedesco all'inglese, le frasi tedesche, le sourcelines, sono segnate con colonne tedesche e le traduzioni inglese con colonne inglese. Abbiamo visto che la forma reale del prompting non ha un impatto significativo nelle case di pochi promptings. È fondamentale per gli prompting a zero e uno shot. E quando andiamo, come nel nostro caso, a five-shot prompting, c'è una differenza minore rispetto alla forma reale del prompting. Carica è la qualità delle esempi. La somma dei risultati esperimentali è che la qualità delle esempi è più importante che la somiglianza con la frase di origine. È importante selezionare le esempi da traduzioni di alta qualità. In particolare, confrontiamo la selezione di prompts dal dataset di addestramento per l'evaluazione WMT sul dataset dev. Il dataset dev è molto più curato e di alta qualità rispetto al dataset di addestramento, che è più rumoreoso. I risultati mostrano un miglior performance quando si utilizza il dataset dev. Tuttavia, i sistemi state-of-the-art specializzati hanno un vantaggio sostanziale rispetto alle traduzioni PaLM. Ma PaLM si avvicina a un sistema commercializzato. Le istruzioni che otteniamo dalla valutazione umana effettuata utilizzando il framework MQM indicano che la fluidezza della PaLM è simile alle sistemi state-of-the-art, ma il principale differenzio è nelLivello di precisione. In particolare, le errori più comuni sono omissioni. Sembra che PaLM scelga di produrre una traduzione piacevole, spesso riducendo parti della frase di origine che sono fatte nella traduzione. Tuttavia, la categoria "Stile/Affogato" per PaLM è inferiore rispetto agli sistemi state-of-the-art, che è un altro segnale che PaLM fornisce una traduzione fluente, ma con problemi di precisione. E' tutto per questa breve riepilogazione. Per maggiori dettagli, si prega di fare la presentazione completa del paper. Grazie mille.</sample>
    <sample id="240">Mi chiamo Dawei, sono un dottorando all'Università di Saarland in Germania. Nell'alto video, vorrei presentare il nostro recente lavoro "Weaker Than You Think: Un'occhiata critica alla weakly supervised learning". Questo è un lavoro in collaborazione con Xiaoyu Shen, Marius Mosbach, Andreas Stephan e Dietrich Klakow. Ecco una breve introduzione alla weakly supervisione e alla weakly supervised learning. In una weakly supervisione, non etichettiamo manualmente i dati. Piuttosto etichettiamo i dati utilizzando fonti di etichettazione debole, come regole heuristiche semplici, basi di conoscenza o work crowdsourcing bassa qualità, come illustrato nella figura a destra. Rispetto alle etichettazioni umane, le etichettazioni debole sono molto più economiche, ma sono anche rumoreuse, ovvero significa che un certo numero delle etichettazioni sono errate. Se etichettiamo direttamente i modelli neurali sui dati etichettati debole, i modelli neurali tendono a memorizzare il rumore delle etichettazioni e non generalizzano. Nella weakly supervised learning, si propongono algoritmi di training per addestrare i modelli neurali sotto rumore delle etichettazioni in modo che i modelli addestrati siano ancora in grado di generalizzare bene. Negli ultimi lavori sul WSL, ovvero Weakly Supervised Learning, un clamore comune è quello che le persone dicono di addestrarci solo sui dati etichettati debole e ottenere un buon risultato su set di test puliti. Tecnologicamente, questa dichiarazione non è sbagliata, ma c'è un incognito. Si assume che ci sia un set di validation pulito disponibile per la selezione del modello. Non possiamo fermarci in questo setting di addestramento, ma questo implica che è necessario l'acquisizione di etichettazioni manuali aggiuntive nel WSL. Ma c'è un elefante nella stanza, questo necessità è spesso ignorata. Per rispondere a queste tre domande di ricerca, chiediamo: Primo, è necessario un set di validation pulito per il WSL o possiamo utilizzare un set di validation rumoreoso al suo posto? Secondo, se il set di validation pulito è necessario, o è obbligatorio per il WSL funzionare, allora quanti campi puliti dobbiamo avere? Terzo, dovremmo utilizzare solo i campi puliti per la validation, o ci sono migliori metodi per utilizzarli? Abbiamo risposto a queste tre domande di ricerca nel nostro lavoro e i nostri risultati sono i seguenti: Primo, scopriamo che, intriguedentemente, i recenti approcci del WSL effettivamente richiedono campi validation puliti per funzionare correttamente. Altrimenti, ci sono una grande scadenza di prestazioni. Come mostrato nella figura, se non ci sono campi validation puliti, allora i modelli addestrati non possono generalizzare oltre le etichettazioni debole originarie, significando che l'addestramento è inutile. Questo indica che i metodi del WSL effettivamente richiedono campi validation puliti per funzionare correttamente, e il costo di etichettazione per ottenere campi validation puliti non dovrebbe essere ignorato. Il nostro secondo risultato è che aumentare il numero di campi validation puliti aiuta i metodi del WSL a ottenere un bettero performance, come mostra la figura a sinistra. Di solito abbiamo solo bisogno di 20 campi per classe per ottenere un buon performance. Ma non è finito qui, perché se decidiamo comunque di accedere a campi validation puliti, allora addestrare sui campi puliti direttamente darà perfino un bettero performance. La figura a destra mostra la differenza del performance tra approcci di fine-tuning, che vengono applicati direttamente sui campi puliti, e i metodi del WSL, che utilizzano i campi puliti solo per validation. Come vediamo, se abbiamo 10 campi per classe, l'approccio di fine-tuning inizia a superare i metodi del WSL. Infine, la differenza della performance dichiarata in precedente WSL approcci può essere facilmente raggiunta permettendo di continuare l'addestramento sui campi validation puliti. Come vediamo dalle figure, il modello vanilla, chiamato FTw, inizialmente underperfora rispetto a metodi WSL più complicati, come COSINE. Tuttavia, se si permette di continuare l'addestramento sui campi validation puliti, allora FTw performe egualmente bene rispetto a altri metodi. In pratica, non c'è motivo di scegliere metodi WSL più complessi che richiedono più tempo di calcolazione e spazio di disco. In conclusione, abbiamo dimostrato che i recenti approcci del WSL richiedono campi validation puliti per funzionare correttamente. La loro vantaggio e la praticità sono esteso. Le nostre concrete raccomandazioni per le future ricerche sono le seguenti: Primo, segnalare le procedure di selezione dei modelli. Ad esempio, segnalare se la selezione dei modelli è effettuata utilizzando campi validation puliti. Secondo, i metodi del WSL dovrebbero essere confrontati con baseline di few-shot learning, poiché entrambi operano su campi validation puliti. Terzo, il continuo addestramento è un baseline semplice e potente che dovrebbe essere considerato nelle future ricerche sul WSL. Infine, abbiamo open-sourced il nostro codice. Posso scaricarlo tramite il codice QR in questa slide. Siete liberi di controllarlo. Grazie e godete della conferenza</sample>
    <sample id="241">L'articolo "Evaluating Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments" parla dell'importanza di valutare le systems di filtraggio delle informazioni falsi in modo che includa l'interazione umana. Gli autori, Ethan, Yang Chen, Wei Xu e Alan Ritter, presentano un modello di valutazione per la creazione di sistemi di filtraggio che risolvano i problemi di valutazione e orientamento umano. L'articolo descrive come i sistemi attuali non includono abbastanza valutazione umana e come il loro modello include la valutazione del contenuto e della politica da parte di un moderatore umano. L'articolo conclude che il loro modello offre un approccio più realistico per la valutazione dei sistemi di filtraggio delle informazioni falsi.</sample>
    <sample id="242">I metodi di valutazione comuni per i sistemi di dialogo includono l'uso di valutazioni a livello di giro e di valutazioni a livello di dialogo.</sample>
    <sample id="243">Quattro autori sono coinvolti nell'articolo: Jenny, Sebastian Santy, Ronan Le Bras e Katharina Reinecke.</sample>
    <sample id="244">Nell'esempio con Servin e Kea, è necessario conoscere che Servin è un giudice e che i giudici decidono casi in una corte di giustizia.</sample>
    <sample id="245">Lining Zhang ha presentato un'analisi sulle "MTurk Workers" per la sommata, che include due passi di "Qualification Task" e "Endurance Task". La pipeline include set di domande pre-task, come la posizione geografica, il numero di HIT e l'Approval Rate. Per la prima parte della sommata, i worker devono valutare tre documenti con un controllo di attenzione e valutare sei dimensioni. I worker gold e silver possono passare questa parte. Per la seconda parte, i worker devono valutare 10 HIT, uno documento e quattro summari per valutare la salientità. I worker gold e silver possono raggiungere una alta congruenza in termini di IAA. Per la sommata basata sul riferimento, i worker devono valutare 30 HIT, uno riferimento e quattro summari per controllare la copertura delle informazioni. I pipeline del worker showono una congruenza significativa tra i worker pipeline e CloudResearch MTurk workers. In conclusione, la pipeline è una pratica efficace per assicurare una congruenza elevata a un costo inferiore e può aiutare a evitare spreci di risorse.</sample>
    <sample id="246">Sì, il codice è disponibile sul GitHub.</sample>
    <sample id="247">Jiho Kim da KAIST AI presenta il loro paper "FACTKG: Verificazione dei fatti attraverso ragionamento sui Graph Knowledge". Non esisteva un dataset che utilizzasse i Graph Knowledge come evidenza con dichiarazioni naturalistiche. Introduce un nuovo dataset, FactKG, per la verificazione dei fatti attraverso ragionamento sui Graph Knowledge. Utilizza DBpedia come Graph Knowledge e include dichiarazioni in stile scritto e colloquiale. Gli etichettaggi sono SUPPORTED e REFUTED. La verificazione consiste in recupero dell'evidenza da DBpedia e ragionamento sull'uguaglianza tra dichiarazioni e evidenze. Utilizza cinque tipi di ragionamento: one-hop, conjunction, existence, multi-hop e negation. Include due metodi per la trasformazione del linguaggio colloquiale: il modello di trasformazione del linguaggio colloquiale proposto e le template di presupposizione. I risultati mostrano che il modello GEAR che utilizza le evidenze del GraphKnowledge supera tutti gli altri baseline.</sample>
    <sample id="248">Sì, gli annotatori per NLPositionality sono bilanciati rispetto a ciascun gruppo demografico.</sample>
    <sample id="249">Le frasi del dominio accettabile sono state perturbate preservando il contesto ma aggiungendo rumore.</sample>
    <sample id="250">A dimensionale significa valutare una quality di chat in base a diversi aspetti specifici, al contrario della valutazione globale.</sample>
    <sample id="251">The authors of the article are affiliated with the University of Science and Technology of China.</sample>
    <sample id="252">Sai Kiran Tanikella presenta un'opera intitolata "U-CREAT: Unsupervised Case Retrieval using Events extrAcT" in collaborazione con Abhinav Joshi, Akshat Sharma e Ashutosh Modi. La hansa si concentra sulle attività Prior Case Retrieval (PCR) per i professionisti legali, che richiede di recuperare documenti precedenti rilasciati. L'obiettivo è fornire una soluzione efficiente e generalizzabile per la recupero dei documenti appropriati in base a query e candidati. L'approccio utilizza la detezione di eventi per rappresentare i documenti come racconti di avvenimenti, e si basa su tre fasi: preprocessamento, analisi grammaticale e postprocessamento. L'interazione tra eventi è utilizzata per calcolare un'interazione matrice che aiuta ad ordinare i candidati. Gli esperimenti mostrano che il sistema U-CREAT ha una performance superiore rispetto alle altre metodologie, garantendo un tempo di inferenza basso e un'efficienza elevata.</sample>
    <sample id="253">Il progetto di ricerca è intitolato "DisorBERT: Un modello di adattamento di dominio a doppia dirzione per la detezione di segni di disturbi mentali nei social media". È una collaborazione tra ricercatori messicani e spagnoli. La definizione di un disturbo mentale è una psicologia sintomo associata al distress e alla disabilità che affaetia il pensiero, le emozioni, lo stato d'animo e il comportamento. Esistono diversi tipi di disturbi mentali, tra cui la depressione maggiore, PTSD, bulimia e anorexia, tra gli altri. Oggi, i contenuti dei social media sono enormi e offrono un'opportunità per la ricerca sulle difficoltà che le persone vivono. Molte persone usano piattaforme online per condividere le loro routine quotidiane e gli eventi importanti, mentre altri prendono l'avvio della anonimità di questi spazi per esplicitamente discutere del loro health mentale e richiedere aiuto. Nella nostra ricerca, vogliamo contribuire alla detezione dei disturbi mentali attraverso l'analisi automatica dei post sui social media. Questo tipo di analisi è previsto che supporti una nuova tecnologia in grado di avvertire l'inizio di disturbi mentali e fornire evidenza sostenuta. Perché utilizzare l'adattamento di dominio? A volte abbiamo pochi dati etichettati e vogliamo migliorare il performance del nostro modello su un dominio di destinazione. Per questo, possiamo utilizzare il conoscere imparato dal nostro modello da un altro dominio correlato o simile. Prendiamo ad esempio BERT. BERT è un modello linguistico trainato con dati generali di Wikipedia e Google Books, e vogliamo trainarlo per un linguaggio più specifico di Reddit e salute mentale. Adattandolo, possiamo regolare il vocabolario della comprensione semantica del modello e imparare al compito specifico del dominio. Qui abbiamo il diagramma generale della nostra approccio proposto. Iniziamo con il modello linguistico di base e poi integriamo informazioni da Reddit e salute mentale. Incorporiamo anche la conoscenza da un lexico per guidare il processo di maschietto. L'idilla principale della nostra approccio è di prima imparare il linguaggio dei social media e poi specializzarci nel dominio della salute mentale. Utilizzando il maschietto guidato, vogliamo far sì che il modello tenti di concentrarsi sulle parole importanti durante il processo di training. Qui abbiamo i risultati generali utilizzando i dataset eRisk. Trascriviamo la precisione e la recall del nostro modello e dei baseline. Il nostro modello tende a posizionarsi nella diagonal principale della regione, indicando un equilibrio ottimo, mentre altri metodi hanno una alta precisione di recall ma punteggiano basso nell'altra dimensione. Per illustrare il comportamento del nostro modello e il tipo di segmento testuale che tende a dare più attenzione, analizziamo le parole più likely generate dal modello quando si presenta una frase con parole maskate. Per esempio, utilizziamo una frase di Beck's Depression Inventory, un strumento clinico che consiste in 21 domande per misurare le tipiche sintomi della depressione, come la umore, la pessimismo, la sensazione di fallimento, la dissatisfazione e la colpa, tra gli altri. Nel seguente elenco, vediamo esempi delle firme e delle risposte restituite dal BERT e dal DisorBERT. Con DisorBERT, le risposte tendono a avere un significato più negativo o psicologico rispetto al BERT. Prendiamo ad esempio la frase "Io potevo piangere", dove maskiamo la parola "piangere" e DisorBERT predice parole come focus, parla, respirare, dormire e mangiare. Queste parole sono associate a problemi comuni associati ai disturbi mentali e causano una interferenza nel pensiero e nel comportamento della persona affettata. Qui abbiamo anche presentato tutte le parole predette dalle due modelli, pesate per la loro frequenza. Queste figure sono state ottenute applicando i due modelli all'interfaccia totale delle 21 domande dell'INQUI. Simile a ciò avvenuto prima, BERT tende a generare parole più generali, mentre il nostro modello tende a essere biase per parole legate ai disturbi mentali. Infine, vogliamo visualizzare le sequenze più importanti del testo, calcolando le parole più relevanti e le frasi. Per questo, utilizziamo un tool di visualizzazione interattiva che mostra una vista a testa del grafico. Selezioniamo un utente di depressione con il punteggio più alto nell'INQUI e calcoliamo gli indici di attenzione del post dell'utente. Possiamo osservare che le parole più importanti sono associate a "ansiosi" e "medicazione", temi altamente rilevanti per la depressione. Come conclusione e lavoro futuro, il combinato effetto dell'adattamento di dominio a doppia dirzione e del maschietto guidato è efficace per captare i segni di disturbi mentali nei post social media. Il nostro approccio ha ottenuto risultati migliori rispetto a MentalBERT, un modello trainato con una grande quantità di dati. L'évaluation mostra un equilibrio solido tra identificare utenti e etichettarli correttamente. In futuro, vogliamo esplorare l'applicazione di risorse lexical diverse e utilizzare dati clinici. Grazie per la vostra attenzione. Se avete domande, vi prego di chiedermene.</sample>
    <sample id="254">The speaker introduces their research work on "Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction". They explain the challenge of noise in distant supervision data and propose a framework to improve label quality. The overview includes training with both DS and human-annotated data, uncertainty estimation methods, instance-level uncertainty scores, dynamic class uncertainty thresholds, and an iterative re-labeling strategy. Experimental results show that their method outperforms previous baselines.</sample>
    <sample id="255">La forma del prompting si rivela importante in casi di zero e uno shot.</sample>
    <sample id="257">I modelli di dialogo che gli autori hanno valutato sono:</sample>
    <sample id="258">Chiang Cheng-Han presenta un nuovo lavoro intitolato "Gli Modello di Linguaggio Grandi Potenziali come Alternative all'Evaluation Umano?" L'idea è di utilizzare i Modello di Linguaggio Grandi Potenziali per valutare la qualità del testo in elaborazione del linguaggio naturale. Chiang spiega che, in passato, si utilizzava l'eccellenza umana per valutare il testo, ma ci sono problemi di stabilità e riproducibilità. Chiang chiede se sia possibile utilizzare i Modello di Linguaggio Grandi Potenziali come alternative all'eccellenza umana, e spiega come l'idea è stata verificata sull'esempio delle storie generate da GPT-2 o scritte dallo stesso. Le storie sono valutate su quattro attributi: grammatica, coerenza, likabilità e rilevanza. I risultati della valutazione dei Modello di Linguaggio Grandi Potenziali mostrano che, in generale, le storie scritte da umani vengono preferite rispetto a quelle generate da GPT-2, ma ci sono alcune eccezioni.</sample>
    <sample id="259">Il relatore, Yusen Zhang, presenta un importante risultato della ricerca del suo gruppo di studio: "XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations". La hans</sample>
    <sample id="260">Un autore è coinvolti nell'articolo.</sample>
    <sample id="261">Un buon pianificatore deve scrivere script ragionevoli e fedeli alle restrizioni.</sample>
    <sample id="262">There are three authors involved in the article: Siyu Yuan, Zhiyuan Liu, and Yichen Chen.</sample>
    <sample id="263">La presentazione è intitolata "Mitigating Label Biases for In-context Learning" e si concentra sullo studio dei problemi di preoccupazione dei modelli di linguaggio in contesto. I modelli di linguaggio sono utilizzati per imparare da esempi precedenti, ma possono essere instabili a causa di varie scelte di progettazione, come la scelta e l'ordine degli esempi precedenti. Questi modelli potrebbero presentare prelievo su certe etichette a seconda del contesto, introducendo errori nella loro predizione. La presentazione introduce una categorizzazione sistematica dei problemi di prelievo e propone un metodo di calibrazione per mitigare il loro effetto. L'approccio proposto utilizza parole casuali estratte dal contesto del dataset per calibrare le predizioni del modello. Gli esperimenti mostrano che questo approccio migliora significativamente il performance globale dei modelli di linguaggio in contesto, riducendo i problemi di prelievo.</sample>
    <sample id="264">Lin Wang è un studente di laurea magistrale alla Zhejiang University, Cina. Stà presentando la sua tesi intitolata "TAVT: Verso la generazione di testo audiovisivo trasferibile". La sua tesi si concentra sulla generazione di testo audiovisivo, un compito che richiede una annotazione di dati più ardua e costosa rispetto alle attività di generazione di testo unimodal come la traduzione automatica o la captioning. Lin Wang propone una nuova sfida denominata Generazione di Testo Audiovisivo Trasferibile (TAVT), che si basa sull'idea che l'audio possa essere utilizzato per realizzare una semantica unificata tra i diversi modelli visivi. L'approccio proposto utilizza una rete di mappatura meta-audiovisiva, un encoder e un generatore a base di transformer, e una perdita di contrasto contraddittoria dualista. I risultati delle sperimentazioni mostrano che il TAVT supera le performance delle alternative esistenti in entrambi i casi di set di train cross-dataset e cross-domain.</sample>
    <sample id="265">Vasudha</sample>
    <sample id="266">Adam Przepiórkowski è affilato all'University of Warsaw.</sample>
    <sample id="268">I'm sorry, I can't provide a translation for this content.</sample>
    <sample id="269">Ciao, mi chiamo James Finch e sono Sarah Finch. Oggi ti racconteremo di ABC-Eval, un approccio dimensionale per valutare l'intelligenza artificiale conversazionale. Questo lavoro è stato realizzato dal Laboratorio di NLP di Emory, condotto dal Professor Jinho Choi all'Università di Emory e in collaborazione con Amazon Alexa AI.

Supponiamo che tu hai sviluppato un modello di dialogo e vuoi sapere come si confronta rispetto al più recente stato dell'arte. La pratica comune è utilizzare l'évaluation umana, ad esempio chiedendo ai giudici umani di selezionare tra due conversazioni quale è meglio o di valutarle con una scala Likert. Questi approcci funzionano bene per fornire un'evaluazione complessiva della qualità del dialogo, ma la qualità del dialogo ha molte aspetti. Quindi, potresti voler valutare diversi aspetti della qualità del chat per comprendere le forze e le debolezze del modello in modo più dettagliato.

Un approccio è semplicemente chiedere ai giudici umani di valutare diversi aspetti della qualità del chat, ad esempio valendo le risposte del modello come irrelevanti o contraddittorie usando scale Likert esistenti. Noi creiamo un approccio più preciso e affidabile per l'évaluation dimensionale del chat. L'approccio consiste in annotare se ogni risposta del modello esprime determinati comportamenti, come rispondere con informazioni irrelevanti o contraddire se stessi o il suo interlocutore. Chiamiamo questo approccio "Annotare comportamenti nel chat" o ABC-Eval in breve.

Sviluppiamo questo metodo per coprire completamente i comportamenti del modello di chat suggeriti da letteratura recente che influiscono sulla qualità del chat. ABC-Eval è in grado di misurare le rate a cui i modelli di chat commettono errori tematici vari. Ad esempio, ABC-Eval misura il numero di giri in cui un modello di chat ignora il suo interlocutore o dice qualcosa irrelevante, contraddette se stessi o il suo interlocutore, hallucina faute di fatto o viola la conoscenza comune, e quando il modello riesce o non riesce a mostrare empatia.

Per determinare quale tipo di évaluation è più efficace, abbiamo scelto quattro modelli di chat state-of-the-art e abbiamo valutato 100 conversazioni bot-su-homo per ogni modello usando ABC-Eval. Per comparazione, abbiamo anche valutato queste conversazioni usando tre metodi esistenti: scale Likert turn-level, scale Likert dialogue-level e confronti pairwise di dialogue-level. Per ciascun metodo esistente, abbiamo raccolto valutazioni su otto dei più comunemente misurati aspetti del dialogo, poiché è la pratica standard per valutare i modelli di chat lungo molti aspetti.

Dall'analisi dei risultati delle nostre valutazioni, abbiamo scoperto che i label di ABC-Eval sono generalmente più attendibili rispetto ai label raccolti da metodi esistenti, come misurato dall'accordo interannotatore su 100 conversazioni doubl-labeled. Inoltre, i label di ABC-Eval sono più predittivi della qualità globale del dialogo rispetto ai metrici prodotti da metodi esistenti, come mostrato da questa semplice regressione lineare. Ad esempio, puoi vedere come misurare la proporzione di giri con contradizioni personali e partner spiegano 5% e 10% della qualità del dialogo rispetto alle misure di consistenza media Likert che spiegano solo 4% o meno.

Infine, abbiamo controllato se ogni metrica di valutazione capti un aspetto unico della qualità del chat usando una regressione lineare passo-passo. Posso vedere come la combinazione di tutti i metrici ABC-Eval spiega oltre il 25% della qualità del dialogo, e rimuovendo i metrici uno alla volta perdiamo una quantità ragionevole di informazioni riguardo la qualità. In alternativa, la combinazione di tutti i metrici Likert turn-level spiega meno di informazioni riguardo la qualità, e meno di questi metrici portano informazioni uniche.

Queste metriche attendibili, informative e distinte ABC-Eval consentono di valutare l'intelligenza artificiale con una risoluzione più alta rispetto ai metodi precedenti. Vediamo i risultati dell'esperimento che identificano alcune sfide continue e quantificate. Ad esempio, i bot che abbiamo testato commettono errori di consapevolezza comune in circa il 20% delle risposte, producono informazioni irrelevanti in circa il 15% delle risposte e contraddicano se stessi o il loro interlocutore in circa il 10% delle risposte. Con il ritmo rapido di miglioramento del campo, molte delle rate di errore potrebbero diminuire nelle nuove versioni dei modelli rilasciate dal nostro esame.

Abbiamo sperato che ABC-Eval possa essere utilizzato dagli altri nel campo come un passo significativo in questa direzione. Siamo impazienti di vedere come l'intelligenza artificiale progredirà negli mesi e anni venuti. Grazie di aver guardato.</sample>
    <sample id="270">L'articolo è stato scritto da James Finch e Sarah Finch, che sono studenti del Laboratorio di NLP di Emory University, con la collaborazione di Amazon Alexa AI.</sample>
    <sample id="271">FTw è una variante del modello di classificazione a due classi standard, ovvero il "vanilla" modello. In questo contesto, "fine-tuning" si riferisce alla modifica dei parametri di un modello esistente per migliorare le sue prestazioni su dati specifici. Quindi, "FTw" significa "Fine-Tuning Vanilla Model".</sample>
    <sample id="272">C'è un totale di 7 autori coinvolti nell'articolo.</sample>
    <sample id="273">Ciao, mi chiamo Kayo Yin e presento il nostro lavoro intitolato "Quando la traduzione richiede il contesto? Esplorazione multilingue e dati-driven". Questo lavoro è stato realizzato in collaborazione con Patrick Fernandes, Emmy Liu, André F. T. Martins e Graham Neubig. Molte traduzioni dipendono dal contesto. Ad esempio, come si traduce "mole"? Se la frase precedente è "Le cose potrebbero diventare pericolose se i ministri scoprono", allora "mole" si traduce come spia. Ma se la frase precedente è "Potrebbe esserci qualcosa di serio, dottore?", allora "mole" si traduce come macula nera. Secondo il contesto, il significato del termine cambia e quindi la traduzione cambia con esso. Tuttavia, valutare quanto bene i modelli riescono a tradurre casi come questi è davvero difficile. In primo luogo perché solo una piccola porzione delle traduzioni dipende dal contesto, quindi i metodi di metrica a livello di corpus come BLEU non riescono a raccogliere questi casi. E poi, alcuni hanno suggerito l'évaluation obiettiva su traduzioni dipende dal contesto, ma questi risorse supportano solo tipi limitati di traduzioni dipende dal contesto e set limitati di linguaggi perché si basano spesso su conoscenza dominante e curazione umana. Nell'oltre, ci chiediamo due domande: quando richiede la traduzione il contesto e come i modelli gestiscono questi casi? Per rispondere alla prima domanda, abbiamo iniziato misurando la quantità in cui una parola richiede il contesto durante la traduzione. Nel lavoro precedente abbiamo introdotto CXMI come un'unità per misurare l'uso del contesto da parte dei modelli di traduzione automatica. Abbiamo esteso CXMI con P-CXMI, che può misurare l'uso del contesto al livello di frase o al livello di parole. Possiamo pensare di P-CXMI come all'informazione guadagnata da dare contesto al modello. Analizzando le parole con alto P-CXMI, abbiamo cercato pattern tra queste parole. E abbiamo eseguito l'analisi su transcript di TED Talks tradotti dall'inglese in 14 lingue diverse. Effettuando l'analisi a tre livelli diversi: tagli del taglia linguistica che hanno alto mean P-CXMI, parole che hanno alto P-CXMI media su tutte le loro occorrenze, e token individuali che hanno alto P-CXMI. Questo ci permette di identificare fenomeni come quelli qui, dove in cinese si richiede il contesto per tradurre un nome proprio in modo da assicurarsi che si stia usando la stessa traduzione all'interno del documento. E simili, scopriamo che il contesto è importante per tradurre nel giusto livello di formalità. E infine, analizziamo token individuali che hanno alto P-CXMI. Questo ci permette di identificare fenomeni che non possono essere captati dal termine stesso, ma che sono espressi nella struttura della frase, come la risoluzione dell'ellipsi. Utilizzando i nostri risultati dall'analisi per costruire un benchmark per la traduzione a livello di documento. Per ogni dei cinque fenomeni di discorso che abbiamo identificati, creamoli taggatori automatici per identificare parole che riguardano il fenomeno. E chiamiamo il taggatore Multilingual Discourse-Aware, o MuDA taggatore. Poi possiamo notare che i diversi linguaggi hanno proporzioni diverse di questi fenomeni di discorso. Utilizzando il MuDA taggatore, applicando il taggatore alle pair parallele che vogliamo utilizzare per l'evaluazione e applicando i nostri metodi di metrica di scelta su esempi di traduzione dipende dal contesto identificati dal MuDA taggatore. Infine, utilizzando il nostro benchmark per valutare i modelli e scopriamo che i modelli con consapevolezza del contesto sono significativamente più accurati nei casi dei fenomeni di discorso come formalità e coesione lexica rispetto ai modelli che non usano contesto. Ma questi modelli non sono molto migliori dei modelli che non usano contesto per altri fenomeni come ellipsi, pronomi e forma verbale. Questo suggerisce dove avremmo bisogno di vedere più progresso per la traduzione a livello di documento. Compariamo anche diversi sistemi commerciali e il nostro benchmark mostra che DeepL è generalmente più preciso di Google Translate per la traduzione a livello di documento. In conclusione, effettuiamo un'analisi dati-driven su 14 lingue diverse per identificare quando la traduzione richiede il contesto e poi utilizziamo i nostri risultati per costruire un benchmark per la traduzione a livello di documento che può aiutarci a identificare in quali fenomeni del discorso i modelli possono gestire meglio o meno e quali sistemi di traduzione sono migliori per la traduzione a livello di documento. Grazie per la vostra attenzione. Vediamo a Toronto</sample>
    <sample id="274">Yusen Zhang</sample>
    <sample id="276">IndicMT Eval è un dataset per l'evaluazione di metriche di traduzione per le lingue indiane. L'obiettivo è di valutare le metriche in direzione inversa, ovvero da hindi o marathi a inglese, e non solo in direzione da inglese a hindi o marathi. IndicMT Eval include 200 frasi del Flores dataset e 7 candidati di traduzioni per ogni frase, ottenuti utilizzando set di modelli di traduzione diversi. Le metriche utilizzate includono chrF, BERTscore, MuRIL e COMET. IndicCOMET, una variazione del metrico COMET, mostra una performance migliore rispetto al metrico originale, con una correlazione più alta con i punteggi umani.</sample>
    <sample id="277">Il nuovo metodo non ha un nome specifico.</sample>
    <sample id="278">Il metodo utilizzato per identificare le "parole contrassegnate" consiste nell'usare un'analisi del "log-odds" per confrontare le parole più frequenti in ogni persona con quelle delle parole contrassegnate. Questo approccio permette di individuare le parole che definiscono una persona come parte della sua identità, e non solo le parole negative o discriminanti.</sample>
    <sample id="279">Shangbin è un PhD student in University of Washington.</sample>
    <sample id="280">Il paper "MultiEMO: Un modello di fusione multimodale basato sull'attenzione per la rilevazione dell'emozione nelle conversazioni" propone una nuova architettura per la rilevazione dell'emozione in contesti conversazionali. L'architettura, chiamata MultiEMO, utilizza un approccio attention-based per fusionare le informazioni multimodali (visive, textuali e auditive) in modo coesivo. La rilevanza della MultiEMO è evidenziata dalla sua performance superiormente al benchmark MELD e IEMOCAP, mostrando una notevole migliorata nei casi di classificazione di classi minoritarie e di emozioni simili.</sample>
    <sample id="281">L'articolo di Kayo Yin e colleghi si è concentrato sull'importanza del contesto nella traduzione e ha sviluppato una metrica per misurare la relativa utilità del contesto. Utilizzando la metrica CXMI, l'articolo ha identificato i casi in cui la traduzione richiede il contesto e ha creato un benchmark per l'analisi del contesto nella traduzione a livello di documento. L'articolo ha analizzato i risultati dei modelli di traduzione a livello di documento utilizzando i metodi di valutazione tradizionali e del benchmark creato, scoprendo che i modelli con consapevolezza del contesto erano più accurati per certi fenomeni di discorso, ma non necessariamente per altri.</sample>
    <sample id="282">Nel presente studio, siamo presentati un nuovo modello di generazione di testo chiamato StoryTrans, che si occupa della trasferimento stile non parallelo a livello di storia. La maggior parte delle ricerche precedenti si è concentrata sul livello token o livello di frase, come la trasferenza del sentimento o la trasferenza del livello formale del testo. Noi ci siamo avvicinato in modo significativo al livello di storia e al livello di discorso, che è crucialmente importante per imitare lo stile dell'autore. La nostra soluzione consiste nell'adottare una nuova architettura di training che utilizza le rappresentazioni del discorso delle texture di origine e le embeddings style imparabili per generare testi nel stile di destinazione.</sample>
    <sample id="283">La prima struttura di dipendenza simmetrica menzionata è "Lisa, Bart e Maggie".</sample>
    <sample id="284">In questo studio, abbiamo proposto un nuovo meccanismo di fuzzy span per migliorare l'extrazione universale dell'informazione (UIE). La maggior parte delle UIE utilizzano il meccanismo di identificazione e etichettazione delle boundaries del span nel testo, che si basa su posizioni precise delle boundaries delle etichette. Tuttavia, ci sono ambiguità nella etichettatura delle boundaries del span. Inoltre, esiste una disconnessità tra la rappresentazione dei fatti di Transformers e l'extrazione di informazioni. I Transformers basati sulle token globali ignorano la priorità che un span ha una lunghezza limitata. Per risolvere questi problemi, abbiamo proposto un nuovo meccanismo di fuzzy span per rilevare le boundaries del span in modo fuzzico e un attention fuzzy per regolare l'attention span del modello.</sample>
    <sample id="285">Il video presenta un'opera di Mingqi Gao da Peking University intitolata "Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with Fine-grained Evaluation Framework". L'argomento principale è la corretta del errore di fatto nelle sommari del dialogo. Discussiamo due soluzioni principali: l'introduzione di obiettivi di fatti nella training o nella inferenza del modello di sommario, e la creazione di un modello di corretto del errore di fatto (FEC) indipendente dal modello di sommario.</sample>
    <sample id="286">Il nome del relatore è James Finch.</sample>
    <sample id="287">Quattro autori sono coinvolti nell'articolo: Javad Hosseini, Filip Radlinski, Silvia Pareti e Annie Louis.</sample>
    <sample id="288">I setti di dati utilizzati per testare i fenomeni sintattici sono Adjunct Island, BLiMP, SyntaxGym e Wikipedia.</sample>
    <sample id="290">WSL, WSL, WSL, WSL, WSL</sample>
    <sample id="291">I'm sorry, I can't provide a detailed answer without more context. Could you please clarify what model and activities are being referred to in your question?</sample>
    <sample id="294">CamemBERT è inizialmente addestrato su 7 GB di NACHOS.</sample>
    <sample id="295">Adam Przepiórkowski</sample>
    <sample id="296">The EPIC corpus was developed to study irony detection in natural language, focusing on the limitations of data-driven approaches. The dataset includes 300 short conversations from social media and Twitter, annotated by 74 annotators across five English varieties using a crowdsourcing platform (Prolific). Annotators were asked if each reply is ironic with respect to its context. Perspective-aware models showed higher confidence compared to gold standard aggregated models. Generational differences within close age groups led to more disagreement among UK/Irish annotators regarding their perception of irony.</sample>
    <sample id="297">L'articolo parla del progetto di ricerca "Da siluri a bulloni: scoprendo la retorica codificata con i modelli linguistici", che analizza il fenomeno dei siluri, termine usato per indicare una forma di retorica che trasmette un messaggio diverso a secondi livelli, comprensibile solo da un'iscrizione specifica. Gli autori della ricerca presentano un glosario di oltre 340 termini e simboli, specialmente per i siluri razzisti, transfobici e antisemitici, raccolti da diverse fonti. I siluri vengono classificati in base al loro livello di register (informale o formale), al loro tipo (racistico, transfobico o antisemitico) e alla persona che trasmettono (esempio: antisemitico). L'articolo presenta un'analisi del Census of U.S. Political Speeches, che mostra una correlazione tra la frequenza delle espressioni siluri e la strategia politica southern Republican. Gli autori esaminano anche l'efficacia dei modelli linguistici come GPT-3 nella rilevazione dei siluri e ne esplodono come possano evadere la moderazione del contenuto online.</sample>
    <sample id="298">I risultati della retraining o del continuo pre-training dei modelli con dati più recenti hanno dimostrato che la perdita di prestazioni aumenta con un gap temporale più grande, confermando la deriva temporale come causa principale della perdita di prestazioni.</sample>
    <sample id="299">"Hi everyone. My name is Michalis Korakakis. Today we are here to talk about ""Improving the robustness of NLI models with minimax training"". This is joint work with Andreas Vlachos at the University of Cambridge. NLI models have achieved state-of-the-art results across a block of benchmarks. However, despite rapid progress, recent work has demonstrated that the success of NLI models is partly due to learning and using shortcuts. Shortcuts are spurious correlations between the input attributes and labels introduced during the dataset creation process. For example, high word-overlap between the premise and the hypothesis in the MNLI dataset is strongly correlated with the entailment label. Consequently, NLI models that exploit shortcuts perform well on in-distribution samples, but are brittle when tested on out-of-distribution adversarial test sets where such spurious correlations do not hold. Prior work in shortcut mitigation typically assumes access to an auxiliary model designed to rely on shortcuts for predictions. For instance, the auxiliary model can learn to exploit shortcuts by being trained only on a small number of examples or by leveraging an auxiliary with reduced learning capabilities. The output of the auxiliary is then used to re-weight training instances for the learner model. Existing shortcut mitigation methods may require knowing this in advance. This assumes domain- and dataset-specific knowledge, which is not always available and thus limits the potential of shortcut mitigation. Furthermore, current shortcut mitigation methods often assume that the learner will naturally exploit the same types of shortcuts as the auxiliary. In practice, the behavior of the learner diverges from that of the auxiliary. For example, the auxiliary may down-weight instances that are useful for training the learner or provide inaccurate uncertainty estimations that may hinder the learner's out-of-distribution generalization capabilities. Finally, current shortcut mitigation methods require using a pre-trained language model as the auxiliary, which incurs additional computational overhead. Motivated by these limitations, in this work, we propose a training method to reduce the reliance of NLI models on shortcuts and improve their out-of-distribution performance. The key insight behind our training method is that NLI models suffer from poor performance on under-represented ""hard"" training instances with patterns that could contradict the shortcuts in the dominant ""easy"" examples. These hard examples are pivotal for ensuring good generalization performance on out-of-distribution examples. Crucially, the loss of hard examples decreases considerably more slowly than the average loss throughout training. Therefore, our aim is to obtain an example weight distribution that places emphasis on the under-represented hard examples. To compute the weight distribution with both a minimax training objective between a learner and auxiliary, the learner tried to minimize the loss of the NLI task, whereas the task of the auxiliary is to maximize the learner's loss by generating example weights such that the learner is incentivized to concentrate on ranges of the input space where it incurs high losses. Thus, the learner would prioritize learning from under-represented hard examples that counteract the uses of shortcuts present in the dominant easy examples. Both models are optimized in an alternating fashion using any standard optimization algorithm, such as stochastic gradient descent. At test time, the learner can make predictions without relying on the auxiliary. Our method does not make any assumptions about the type of shortcuts contained in a dataset. It relies on the learner's own training dynamics to generate example weights. And finally, we use a feed-forward network to model the auxiliary. We evaluate our proposed method in three commonly used analytic datasets, MNLI, FEVER, and QQP, and the corresponding out-of-distribution adversarial test sets, HANS Symmetric, and PAWS. Here, we observe that compared to an ERM training model as well as the best-performing shortcut mitigation method in each dataset, the minimax training objective consistently improves out-of-distribution performance while maintaining high in-distribution accuracy. Finally, in our paper, we also examine whether the performance improvements transfer in larger models, synthetic shortcuts, and out-of-domain test sets. What is the effect of pre-training the learner? How small the auxiliary needs to be. And finally, we conduct a qualitative evaluation of the learned example weight distribution. If you find this work interesting, we would love to chat with you during our poster session. Thank you for your time."</sample>
    <sample id="300">L'audio descrive un'attesa di un utente per un servizio di assistenza telefonica. L'utente esprime la sua impazienza e richiede aiuto immediato, dichiarando che è "stanco di aspettare" e che non riesce a fare una certa azione. La voce dell'utente ha un tono agitato e nervoso, che si intensifica quando richiede che il servizio di assistenza intervenza rapidamente. L'utente sembra preoccupato e ansioso, chiedendo di essere assistito immediatamente.</sample>
    <sample id="302">Permutare i token è necessario per la sequenza di output perché, dopo la prima fase di tagging, abbiamo tutti i token corretti, ma non sono in ordine. La seconda fase utilizza una modello per predire una permutazione che mette i token corretti nella posizione giusta.</sample>
    <sample id="303">I autori hanno sostenuto che aumentare la trasparenza sui metodi di mitigazione dei bias è importante perché non si sa se i modelli di linguaggio artificiali utilizzano valutazioni di alignamento eccessivamente ottimistiche o se utilizzano altri metodi anti-stereotipo per produrre pattern positivi. Senza maggiore trasparenza, è impossibile studiare queste questioni ulteriormente.</sample>
    <sample id="304">I input inaccetabili di coppia minima sono una serie di esempi grammaticali e non grammaticali utilizzati per valutare la comprensione del linguaggio delle modello di linguaggio. Essi includono esempi grammaticali e non grammaticali, spesso utilizzati per valutare il modello's capacità di comprendere e di eseguire le regole grammaticali del linguaggio.</sample>
    <sample id="305">The speaker introduces their work on "Weaker Than You Think: A Critical Look at Weakly Supervised Learning," a joint project with several colleagues. They begin by explaining weak supervision, where data is labeled using less accurate methods like simple rules or crowdsourcing rather than manual annotation. This leads to noisy labels that neural networks struggle with if not handled properly through specialized training algorithms in weakly supervised learning (WSL). The presentation questions the necessity of clean validation sets for WSL and explores how many such samples are needed.

The findings reveal that recent WSL approaches rely heavily on clean validation samples; without them, performance drops significantly. Increasing these clean samples improves results but suggests direct fine-tuning on them yields better outcomes compared to relying solely on validation. 

The conclusion emphasizes that current claims about WSL's practicality may be overstated due to hidden assumptions about access to clean validation data. Recommendations include reporting model selection criteria, comparing WSL against few-shot learning baselines, considering continuous fine-tuning as a baseline, and accessing open-source code via provided links.</sample>
    <sample id="306">Sebastian e Najoung presentano la loro ricerca sul monitoraggio degli entity state nelle modello di linguaggio preaddestrati. Indicano che l'abilità di comprendere e gestire lo stato degli entity è crucial per capire i discorsi più lungi, ma non è chiaramente evidenziata nelle performance delle modelle. Per rispondere alla loro domanda principale, han creato un setup in cui i modelli devono predire il contenuto dei box in base a una descrizione iniziale e ad azioni state-changing. I risultati mostrano che solo il modello text-davinci-003 riesce a eseguire il monitoraggio corretto, e che la presenza di codice nella preaddestratura è una condizione necessaria per questa abilità.</sample>
    <sample id="307">I autori hanno utilizzato metriche di valutazione come entity recognition, classificazione, tag di part-of-speech e risposta a domande per valutare i modelli.</sample>
    <sample id="308">La ricerca di Jenny, condotta in collaborazione con i colleghi del University of Washington e Allen Institute for AI, si è concentrata sull'indagine della posizionalità dei dataset e dei modelli NLP. Utilizzando il framework NLPositionality, ha confrontato le annotazioni delle dataset con quelle delle utenti e delle modelle, scoprendo che i dataset e i modelli sono maggiormente alignati con gli utenti ingleseparlanti e con quelli con istruzione superiore. Questo suggerisce la presenza di posizionalità nelle dataset e nei modelli NLP, che potrebbero leaving dietro alcune popolazioni. Per risolvere questo problema, la ricerca propone di tenere conto di tutte le scelte di design durante la ricerca e di svolgere la ricerca con un'approccio perspectivistico. Inoltre, è consigliabile costruire dataset e modelli specializzati per i 4 principali gruppi demografici: i maschi, le donne, i negozianti e i non-binarie.</sample>
    <sample id="309">Il metrica utilizzata per misurare l'accordo tra annotatori è l'inter-annotatore accordo.</sample>
    <sample id="310">Il dominio scelto per aggiungere frasi completamente scollegate alle query inaccettabili e accettabili è Wikipedia.</sample>
    <sample id="311">I'm sorry, but I can't provide the affiliations of the authors from this video.</sample>
    <sample id="312">MultiInstruct è il primo dataset di riferimento multi-modal per l'instruction tuning. Differisce dagli altri parametri di riferimento in quanto: 1. Consente l'instruction tuning a livello multi-modal, non solo linguistico. 2. Include una vasta gamma di 62 attività diverse, coprendo 10 categorie diverse. 3. Utilizza un set di 5 istruzioni esperte per ogni attività, assicurando una base solidale per l'instruction tuning. 4. Prevede la raccolta di un set di dati più grande di circa 150 attività diverse, che verrà reso disponibile in futuro. Questi punti distinguono MultiInstruct dall'altro dataset di riferimento e offrono un'approccio più ampio e diversificato per l'instruction tuning a livello multi-modal.</sample>
    <sample id="313">Due</sample>
    <sample id="314">La coordinazione binaria si riferisce alla relazione grammaticale tra due elementi o espressioni che vengono uniti insieme da una conjunction, come "e", "o" o "ma". In linguistica, la coordinazione è spesso analizzata attraverso le relazioni di dipendenza tra i vari elementi della frase. Ciò significa che la coordinazione è composta da una relazione dipendente tra i due elementi coordinate, e spesso viene esaminata in base alle regole e alle pattern specifici della lingua in questione.</sample>
    <sample id="315">Non ho identificato alcuna menzione precisa del periodo di tempo in cui i prompt sono stati utilizzati nel studio.</sample>
    <sample id="316">I risultati del modello T5 più piccolo indicano che, quando è addestrato su un set di dati specifico come CoScript, può generare script di qualità superiore rispetto a molti modelli di grande scala. Questo suggerisce che i modelli più piccoli possono superare i modelli più grandi quando si adatta correttamente ad un dataset appropriato.</sample>
    <sample id="317">The presentation is about a new approach to information extraction called CodeIE, which transforms the task into a structure-to-structure code generation problem. The authors use Codex and other large language models for this purpose. They compare their method with traditional text-based approaches like T5 and GPT-3 on various datasets and find that using code format prompts significantly improves performance in terms of recall.</sample>
    <sample id="318">Ciao, sono Yanis Labrak e presento i nostri risultati sul "DrBERT: Un modello pre-training robusto in francese per i domini biomedicali e clinici". Iniziamo parlando del linguaggio modello nella medicina. Poi esploriamo il nostro principale risultato: abbiamo introdotto DrBERT, il primo modello biomedicalo in francese basato su RoBERTa e trainato su NACHOS, che è un set di dati medico rilevato dal web. Abbiamo anche confrontato i modelli con diverse impostazioni di pre-training e fonti di dati. Successivamente, abbiamo presentato i nostri risultati su 11 attività biomedicali e cliniche in francese. Infine, abbiamo concluso con le nostre esperienze e fornito ulteriori dettagli sulla disponibilità dei modelli e sulle script di training sul nostro GitHub.</sample>
    <sample id="319">Nel lavoro, esaminiamo tre strategie di apprendimento: 1. Pre-training da zero: Utilizzando i modelli di pre-training da zero con 7 GB e 4 GB di NACHOS. 2. Pre-training continuo: Utilizzando il peso e la tokenizzazione del modello CamemBERT e trainandolo su 4 GB di NACHOS. 3. Pre-training continuo: Utilizzando il peso e la tokenizzazione del modello CamemBERT e trainandolo su 4 GB di clinical notes.</sample>
    <sample id="320">Il fattore di overfitting dovuto al riutilizzo del test è zero.</sample>
    <sample id="321">La qualità della semplificazione è stata valutata utilizzando la corretta semplificazione delle frasi.</sample>
    <sample id="322">Enrico ha presentato il suo progetto di ricerca intitolato "Cosa impara un classificatore di testo sulla moralità?" Durante la presentazione, Enrico ha spiegato che la moralità è l'insieme di regole e principi che ci aiutano a discernere il giusto dal giusto e il sbagliato dal sbagliato. La moralità è fondamentale per le nostre società e è importante che i modelli di linguaggio possano comprendere e riconoscere la moralità nel nostro linguaggio. Tuttavia, la moralità è soggetta a interpretazioni personalizzate e diversificate, come evidenziato dalle opinioni contraddittorie su temi come l'abortione o i diritti LGBTQ+. Per risolvere questo problema, Enrico ha sostenuto che è possibile utilizzare teorie sociali come la Teoria della Morale Fondamentale, che identifica cinque fondamenti morali diversi che influenzano la nostra percezione della moralità. Questa teoria è stata applicata in NLP con successo, ma è necessario capire come i modelli di linguaggio imparino a comprendere queste differenze morali. Per questo motivo, Enrico ha sviluppato un approccio che utilizza metodi di AI spiegabile per analizzare come i modelli di linguaggio imparano a comprendere la moralità in contesti differenti.</sample>
    <sample id="323">Il paper di Yujie Wang parla di una nuova approccia per risolvere i quiz basati su ragione di consapevolezza, ovvero il compito di fare domande che richiedono conoscenze comuni. Questo compito è complesso perché richiede ai macchine di recuperare informazioni da fonti esterne. Holmes pensa che i know-how sono archiviati in entità linguistiche e in database. Molte ricerche combinano questi due tipi di know-how per risolvere i quiz di consapevolezza con buoni risultati. Tuttavia, ci sono problemi come la presenza di entità rumoreose durante il processo di recupero del subgraph e l'uso isolato delle entità e del testo. Per risolvere questi problemi, Yujie Wang e i suoi colleghi hanno proposto DHLK. Utilizzando un'HKG basata su più database e KRL per ottimizzare la struttura e la rappresentazione dei know-how, e utilizzando un modello di linguaggio per codificare e fusingare i due moduli, hanno creato un approccio innovativo per risolvere i quiz di consapevolezza.</sample>
    <sample id="324">Sì, i modelli linguistici presentano bias politici diversi. I modelli di base, come GPT-4 e le variazioni della serie GPT, tendono a essere più socialmente liberali rispetto alle variazioni della serie BART.</sample>
    <sample id="325">Ciao Mi chiamo Matthias Lindemann e oggi ti darò una breve introduzione al nostro paper intitolato "Compositional Generalization without Trees using Multiset Tagging and Latent Permutations". Questo è un lavoro in collaborazione con i miei advisori Alexander Koller e Ivan Titov. La generalizzata composizionale può essere compresa come la capacità di un apprenditore di gestire la ricorsione più profonda e espressioni composte che non sono state viste durante l'addestramento. Nello scenario del parsing semantico, il test per la generalizzata composizionale potrebbe essere simile a questo: abbiamo un set di addestramento di espressioni e logiche che rappresentano le loro rispettive significazioni. In contrasto con il valutazione standard del macchina seguito da sequenza a sequenza, il set di test non proviene della stessa distribuzione ma contiene struttura unseen logiche. Ad esempio, il modello ha visto ricorsione superficiale durante l'addestramento e viene testato su un esempio con ricorsione più profonda. I modelli seguito da sequenza a sequenza semplici si rifiutano spesso di produrre output che sono attaccati all'input e spesso non riescono a riprodurre le corrispondenze sistematiche tra input e output, come colorate nelle esempi. Un metodo popolare per affrontare questo problema è integrare gli alberi nei modelli. Gli alberi sono destinati a captare il processo compostizionale che collega le espressioni alle loro rispettive forme logiche. Funziona bene, ma gli alberi non sono dati e devono essere ottenuti in modo complesso. Tale complessità spesso richiede un preprocessing formaleistico delle formhe logiche, ad esempio per gestire i simboli variabili. Ottenere gli alberi richiede anche procedure induttive grammaticali specializzate. Nell'articolo nostro, non utilizziamo gli alberi e presentiamo un modello seguito da sequenza a sequenza che modella direttamente le corrispondenze tra frammenti dell'input e frammenti dell'output. Per la prima volta, dimostriamo una forte generalizzata a ricorsione più profonda senza sfruttare gli alberi. Il nostro approccio predica l'output dall'input in due passi. Primo, etichettiamo ogni token dell'input con un insieme unordered di token cheapperanno nell'output. Dopo il primo passo abbiamo tutti i token giusta, ma non sono ordini. Questo è perché nel secondo passo utilizziamo un altro modello per predire una permutazione per metterli nello stesso ordine. Introduciamo un nuovo metodo per predire la permutazione che non imposta alcuna restrizione sulle possibili permutazioni. Questo rende il nostro approccio molto flessibile e espressivo. Conceptualmente, il nostro modello di permutazione funziona come segue: andiamo dal lato sinistro allato destro e determiniamo quale token multiset dobbiamo mettere nella posizione dell'output. Per la prima posizione dell'output, semplicemente selezioniamo uno, come evidenziato in rosso. Poi saltiamo al prossimo token multiset per determinare il secondo token nell'output. Continuiamo questo processo fino a quando ogni token del primo passo sia visitato esattamente una volta. Per dare un anticipo dei risultati sperimentali, qui confrontiamo il nostro metodo con altri modelli seguiti da sequenza a sequenza senza alberi sul benchmark COGS. Il nostro modello supera i altri con un margine significativo sulla generalizzata a ricorsione più profonda. Alcune altre tipi di generalizzata strutturale rimangono molto difficili. Nell'articolo nostro risolviamo un po' di challenge tecniche interessanti. In primo luogo, l'alignment tra input e output non è data nella data di addestramento. Inoltre, a volte ci sono più permute consistenti con i dati, ma la più linguisticamente plausibile è latente. Risolviamo questo inducendo l'alignment come parte della training. Il nostro metodo di permutazione è molto flessibile, ma porta il problema di trovare la soluzione di massima scelta di permute, che è NP-dificile. Questo è legato alla "Problema del Vantagio del Viaggiatore" perché è basato sull'idea di individuare la rotta più efficiente. Risolviamo questo utilizzando una relaxione continua GPU-amico che permette anche di backpropagation through the solution e di immettere le permutazioni linguisticamente plausibili. Se vuoi imparare di più sul nostro esperimento e come risolvere queste challenge, guarda il nostro articolo o vieni a visitare il nostro poster.</sample>
    <sample id="326">La dissonanza cognitiva è una situazione in cui due credenze o azioni sono inconsistenti. Ad esempio, se qualcuno dichiarava di sapere che le sigarette potrebbero uccidere e poi diceva di aver preso una pausa per fumarle dopo una riunione, ci sono due credenze o azioni che si contraddicano. Questa relazione di dissonanza è importante da studiare perché può aiutare a comprendere l'effetto della disagreements tra persone, a monitorare i trend e i valori del popolazione, e a comprendere meglio la mentalità delle persone. La dissonanza cognitiva è anche correlata alle disturbi dell'ansia e ai processi di decisione dei singoli, e può aiutare a comprendere meglio i modi come le persone decidono.</sample>
    <sample id="327">ManagerTower是一种新型的视觉语言（VL）模型架构，它通过在每个跨模态层中引入经理来收集和组合预训练的多模态专家的知识。经理可以适应性地利用不同层次的语义知识，从而促进更全面的跨模态对齐和融合。ManagerTower使用RoBERTa和CLIP-ViT作为单模态编码器，并在VQAv2数据集上进行可视化分析，展示了经理在不同层次的单模态知识上的差异。ManagerTower在各种下游任务中表现出色，特别是在Wikivideo测试标准中的准确率提高了39.15%。</sample>
    <sample id="328">GPT-4 è il modello linguistico più liberale.</sample>
    <sample id="329">Il progetto di ricerca sviluppato da Minghang Zheng e i suoi colleghi di Peking University si è concentrato sulla localizzazione del testo in video zero-shot. Questa tecnica consiste nell'identificare la parte del video più rilevante per una query in linguaggio naturale. Per risolvere questo problema, l'equipo ha sviluppato un approccio che utilizza pseudo-etichette strutturate per ridurre il rumore delle etichette. Inoltre, hanno proposto un approccio zero-shot che utilizza una pre-training di captioning immagine e una modulazione temporale per generare pseudo-etichette più precise. I risultati della ricerca mostrano che il loro approccio è più efficiente e ha una performance migliore rispetto a metodi esistenti.</sample>
    <sample id="330">Sì, l'apprendimento cumulativo funziona meglio dell'apprendimento iterativo.</sample>
    <sample id="331">Sara Papi</sample>
    <sample id="332">I dati del parametro di riferimento MuDa sono stati tratti da una parallelizzazione di un elenco di traduzioni in 14 lingue.</sample>
    <sample id="333">NMT的目的是在不同的场景中学习一个通用的表示空间，然而，神经网络往往会导致一个非平滑的表示空间，这限制了其泛化能力。具体来说，在NMT模型的表示空间中，我们观察到低频词分散稀疏，如图所示。由于稀疏性，许多“洞”可能会形成；在这些洞中，语义含义可以被 poorly 定义。因此，NMT模型在这些区域表现不佳。为了增强NMT模型的泛化和性能，kNN-MT被提出作为解决方案。它的核心思想是根据表示空间中的最近邻来平滑预测。为此，它需要一个训练语料库来存储表示及其相应的目标标记。在每个解码步骤中，NMT模型将查询数据存储来检索最近的条目，并根据检索结果调整预测概率。尽管有效，但这种方法有两个显著的缺点。从大型数据存储中在每个解码步骤中检索邻居是耗时的，一旦数据存储被构建，表示就不能轻易地更新。为了解决这些缺点，我们提出了INK框架，将kNN知识注入到MT中。我们的INK训练循环有两步。首先，从数据存储中提取kNN知识，引导适配器调整表示。然后，使用更新后的表示异步刷新数据存储。这种循环趋势将运行直到收敛。具体来说，我们通过KL-divergence优化适配器，允许三种类型的表示：首先，我们将上下文化的表示和标记嵌入对齐，以保持语义意义。然后，我们将上下文化的表示和kNN标记嵌入对齐，以丰富语义意义。最后，我们将同一目标标记的上下文化的表示对齐，以解决分散稀疏的问题。总体而言，我们优化适配器的联合学习目标，并运行此训练循环直到收敛。在训练循环结束时，我们可以丢弃数据存储。在我们的实验中，我们选择了WMT’19德语-英语新闻翻译任务的获胜者模型作为NMT的离线模型。我们在完整的基准数据集上进行实验，并发现，即使对于WMT获胜模型，其表示空间仍然可以大大改进。在我们的实验中，我们探索了以下三个问题。第一个研究问题是，“我们是否可以用一个小适配器平滑表示空间，并在推理过程中丢弃数据存储？”第二个研究问题是，“使用kNN知识调整表示分布能带来多少改进？”第三个研究问题是，“将适配器和数据存储一起使用会带来进一步的改进吗？”如表所示，INK系统优于最先进的kNN-MT系统，并在推理过程中实现了最佳性能。与使用基线适配器相比，我们发现根据kNN知识调整表示分布带来了更大的性能提升。为了更好地展示INK框架的效果，我们使用不同大小的适配器。一般来说，INK系统位于每个图表的右上角，这意味着INK在较少的内存空间和更快的推理速度下实现了更高的BLEU分数。此外，我们还发现，同时应用适配器和数据存储可以进一步平滑预测，这表明NMT模型的表示空间并未完全由适配器细化。如果设计出更有效的框架，平滑表示空间的好处将进一步得到揭示。总之，我们在本文中提出了一个新的训练框架。在我们的框架中，我们设计、注入和精炼了一个训练循环，以迭代地根据kNN知识细化NMT模型的表示空间。实验结果显示，INK系统平均获得了1.99 COMET分数和1.0 BLEU分数，相较于最先进的kNN-MT系统。我们的INK系统也实现了更好的翻译性能，具有更少的内存空间和更快的推理速度。</sample>
    <sample id="335">Matthias Lindemann</sample>
    <sample id="336">Il trasferimento interlinguistico è un processo in cui si utilizza una modello di linguaggio multilingue preaddestrato per predire il output di una lingua diversa.</sample>
    <sample id="337">The research presented in this speech focuses on handling out-of-vocabulary (OOV) words, which are challenging to represent but crucial for the performance of embedding-based downstream models. The approach developed by the researchers leverages word formation and association to infer OOV word meanings.
The method involves creating a Word Relationship Graph that mimics lexical rules governing word creation and connection. When an OOV word appears, it is tokenized into smaller components called wordpieces, associating them naturally with relevant words to form a two-level graph around the OOV word.
In their model, each node represents either a word or its corresponding wordpiece, while its attribute corresponds to the respective word embedding. To preserve all nodes from the first layer, they retain complete information about the wordpieces. For the second layer, they sample a fixed number of nodes during training to reduce noise caused by numerous neighbors.
To address the challenge of assigning attributes to OOV nodes, the researchers use a self-attention network based on character information within the OOV word. They apply two levels of Graph Attention Network, concatenating initial input with hidden embeddings from each layer to create a node-level representation. A readout block layer captures overall graph information and summarizes word formation.
A simple one-layer Graph Convolutional Network suffices as the basic structure due to the focus on subunits and relationships between them. Contrastive learning is employed using NT-XENT positive samples extracted from the graph, such as two-hop relevant neighbor words, synonyms, or the original OOV word itself.
Experimental results demonstrate that the proposed model's performance surpasses baseline methods across various intrinsic and extrinsic tasks, proving effective at learning OOV words through word formation. Additionally, the model can benefit both static and contextual models in downstream tasks.
Finally, the potential application of the model to other languages depends largely on the rationality of word decomposition. Agglutinative languages suit well because of direct morpheme stringing, whereas fusional languages pose more challenges since they link morphemes together. However, English performs reasonably well when segmented properly according to the researchers' findings.
In summary, the graph incorporated in the model effectively handles diverse complex word formations. It holds promise for further exploration in different language contexts depending on how reasonable the word decomposition process is perceived to be.</sample>
    <sample id="338">Il gruppo di ricerca rappresentato da Bingsheng ha presentato un'opera intitolata "Sono sempre utile le spiegazioni umane? Un'evaluazione obiettiva delle spiegazioni naturali in linguaggio umano" al Congresso. L'opera è una collaborazione tra Rensselaer Polytechnic Institute, Northeastern University e IBM Research. La presentazione ha avuto luogo in inglese.</sample>
    <sample id="339">Dawei è un PhD student at Saarland University in Germany.</sample>
    <sample id="340">Introduzione: Kuan-Hao Huang presenta un'opera collaborativa intitolata "ParaAMR: Un Dataset di Parassimili Sinteticamente Diverso Generato tramite Back-Traduzione AMR". L'obiettivo è di costruire un set di parassimili larga scala e sinteticamente diverso utilizzando la back-translation AMR. Il dataset, denominato ParaAMR, contiene circa 15 milioni di esempi e 6,9 parassimili per ogni esempio originale. La back-translation AMR genera parassimili che mantengono una semantica simile ma con una sintassi più diversa rispetto ai set di parassimili tradizionali. I parassimili generati da ParaAMR sono utili per l'apprendimento degli embeddings delle frasi, la generazione di parassimili con controllo sintattico e l'augmentazione dei dati per l'apprendimento a pochi shot.</sample>
    <sample id="341">I'm sorry, I can't provide a translation for this content.</sample>
    <sample id="342">Gao Jingsheng, studente di Shanghai Jiao Tong University e di Xiaobing.AI, presenta la loro paper "LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming". La paper è condotta da lui, Lian Yixin, Zhou Ziyi, Fu Yuzhuo e Wang Baoyuan. Gao spiega come l'Open Domain Dialogue sia un tipo di scambio conversazionale tra un umano e un aiutato che copre un'ampia gamma di temi e non ha obiettivo specifico, e come i dataset di dialogo preaddestrati siano principalmente composti di conversazioni chat online. Esistono due gruppi di dataset video-sourcer: quelli con condizioni scriptate come i programmi TV e i film, e quelli senza script, come i dataset di interviste. Tuttavia, questi dataset sono limitati in scala poiché richiedono annotazioni manuali e istruzioni. Per costruire un grande dataset di dialogo, è importante trovare una mécanique efficace per captare le relazioni di risposta tra gli interlocutori. Inoltre, il dialogo personalizzato è crucialmente importante per sviluppare applicazioni come i virtual streamers e i virtual employees. Tuttavia, la ricerca attuale sul dialogo personalizzato incontra sfide come l'utilizzo della persona per rappresentare le caratteristiche e la mancanza di sessioni di dialogo per ogni persona. Inoltre, esiste un scenario di dialogo multi-partecipante in cui ci sono più di due interlocutori coinvolti nella conversazione. Per la ricerca sul dialogo multi-partecipante, la mancanza di un grande dataset cinese a livello di dialogo multipartecipante è una sfida, e i nostri dataset possono aiutarci a risolverne la. In generale, i principali ostacoli dei dataset di dialogo esistenti sono riassunti. Per risolverli, si propone LiveChat, un dataset di dialogo personalizzato a larga scala con un approccio di costruzione di dialogo automatico. I dataset di LiveChat sono esaminati su due compiti di benchmark: il modello di risposta e la riconoscimento dell'addressee.</sample>
    <sample id="343">C'è un coautore chiamato Martin e ho presentato un nostro lavoro intitolato "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources". Questo è un risultato della collaborazione tra McGill University, Mila e Microsoft Research. Le modello di comprensione del linguaggio naturale utilizzano diversi tipi di conoscenza, come la contenuta nei parametri preaddestrati, spesso acquisita durante il preaddestramento, e la contenuta nelle informazioni fornite in input durante l'esecuzione. Le ultime ricerche sui compiti come risposta alle domande mostrano che i modelli possono utilizzare la conoscenza preaddestrata per risolvere il compito. Ma la comprensione del linguaggio naturale spesso richiede conoscenza che viene fornita anche durante l'esecuzione. Per esempio, nella frase "John ha visto il nuovamente eletto presidente su TV", i parametri preaddestrati possono contenere informazioni sullo che i presidenti fanno e sullo che è una TV, ma non possono sapere chi sia questo esempio specifico "John" o chi sia il nuovo presidente perché il presidente potrebbe essere cambiato dal tempo del preaddestramento. Pertanto, i modelli efficaci per compiti di comprensione del linguaggio naturale intensivi di conoscenza richiedono la capacità di integrare e utilizzare entrambe la conoscenza preaddestrata e la conoscenza fornita durante l'esecuzione. In questo lavoro, propongiamo un set di test di diagnosi per l'integrazione della conoscenza. Introduciamo un compito di risoluzione delle referenze, progettato per sfruttare la capacità di utilizzare la conoscenza disponibile in diversi fonti. Valutiamo il set di test con participanti di studio umani e modelli di risoluzione delle referenze bienestabili. Ecco un esempio del nostro set di test. Servin è un giudice. Kea è un pasticciere. Servin e Kea si sono incontrati in un parco. Dopo una lunga giornata di lavoro a decidere casi in una corte di giustizia, era felice di rilassarsi. La risoluzione di una determinata pronunzia richiede due tipi di informazioni. In primo luogo, la conoscenza specifica dell'entità, come "Servin è un giudice". E in secondo luogo, la conoscenza di fondazione, come "I giudici decidono casi in corte di giustizia". In generale, la conoscenza di fondazione è imparata durante il preaddestramento di grandi modelli di linguaggio naturale, mentre la conoscenza specifica è generalmente osservata durante l'esecuzione. Abbiamo definito tre impostazioni del KITMUS. La prima è l'impostazione tipica: "Fondazione-Pretrain", in cui la conoscenza di fondazione è presumibilmente disponibile durante il preaddestramento. La seconda è l'impostazione "Fondazione-Both", in cui la conoscenza di fondazione è disponibile entrambe durante il preaddestramento e durante l'esecuzione. Infine, c'è l'impostazione "Fondazione-Inference", in cui entrambi i tipi di conoscenza sono disponibili solo durante l'esecuzione. Questa ultima impostazione è particolarmente interessante, poiché simula il caso in cui la conoscenza necessaria per risolvere un compito non è contenuta nei parametri preaddestrati dei modelli. Per esempio, perché nuove occupazioni sono sviluppate dal tempo del preaddestramento. Qui vedremmo come controlliamo la disponibilità delle fatte in diverse fonti. Nell'impostazione "Fondazione-Pretrain", assumiamo che la conoscenza di fondazione "I politici cercano seggi elettorali nel governo" sia contenuta nei parametri preaddestrati e che durante l'esecuzione forniamo la conoscenza specifica "Chichester è un politico". Nell'impostazione "Fondazione-Both", inoltre, forniamo non solo la conoscenza specifica ma anche la conoscenza di fondazione sul politici nel loro contesto di esecuzione. Nell'impostazione "Fondazione-Inference", forniamo la vocazione fittizia "mirituer" al posto del politico perché "mirituer" è improbabile contenuto nei parametri preaddestrati. Valutiamo il set di test entrambamente con participanti di studio umani e modelli di risoluzione delle referenze bienestabili. In questa grafica, vediamo i risultati del miglior modello su un'implementazione più difficile dell'impostazione "Fondazione-Pretrain". Senza addestramento specifico del compito su KITMUS, entrambi i modelli non performono bene. Quando addestrati su KITMUS, tuttavia, entrambi C2F e BERT4Coref performono significativamente meglio rispetto alla scelta aleatoria. Questo suggerisce che quando addestrati su dataset di riferimento generali, molte sembrano imparare a sfruttare le queue surfacali, che non sono utili quando si testa su KITMUS dove tali queue sono rimossi. Esperimenti aggiuntivi con conoscenza fittizia indicano che persino i migliori modelli non riescono a integrare correttamente la conoscenza retrospettiva fornita solo durante l'esecuzione. In conclusione, molti modelli di risoluzione delle referenze sembrano non poter ragionare su conoscenza da diverse fonti senza addestramento specifico del compito. Tuttavia, con addestramento specifico del compito, alcuni modelli riescono a integrare la conoscenza da diverse fonti. Comunque, persino i migliori modelli sembrano non riuscire a integrare correttamente la conoscenza retrospettiva fornita solo durante l'esecuzione. Se siete interessati a ulteriori dettagli, consultate il nostro paper e scaricate il set di test e il codice sul GitHub. Grazie di aver ascoltato.</sample>
    <sample id="344">I metodi basati su alberi presentano diversi svantaggi. Per esempio, i metodi basati su alberi richiedono spesso la generazione di alberi, che può essere complessa e computationally costosa. Inoltre, non è sempre garantito ottenere un albero corretto, poiché l'alignement tra input e output non è always given.</sample>
    <sample id="345">Compositional generalization è la capacità di un imettore di risolvere problemi complessi e non visti durante l'addestramento. In linguistica, ci si riferisce ad esempio alla capacità di comprendere e produrre espressioni come "Mary sapeva che la ragazza dormiva" utilizzando solo le informazioni fornite da espressioni come "La ragazza dormiva". Questo è particolarmente importante per il compito di analisi semantica del linguaggio naturale, in cui è necessario comprendere e rappresentare il significato delle espressioni linguistiche. Per risolvere questo problema, è possibile utilizzare modelli di machine learning basati su sequenze a sequenza (seq2seq) che immettono direttamente le risposte utilizzando le informazioni fornite dalle espressioni di input. Tuttavia, questi modelli possono riscontrare difficoltà quando siamo richiesti di risolvere problemi complessi e non visti durante l'addestramento, come "Mary sapeva che la ragazza dormiva". Per risolvere questo problema, è possibile utilizzare modelli di seq2seq che non richiedono alberi e che utilizzino una tagged multiset per identificare le informazioni necessarie per produrre la risposta corretta.</sample>
    <sample id="346">Shuheng的affiliazione è l'University of Edinburgh.</sample>
    <sample id="347">Mi chiamo Myra e oggi parlarò del nostro articolo "Personaggi etichettati: utilizzando promettere di naturale linguaggio per misurare stiliomi nei modelli di linguaggio". Questo lavoro è realizzato in collaborazione con Esin Durmus e Dan Jurafsky. Negli ultimi anni, molte persone hanno documentato la prevalenza di stiliomi e storie di genere in grandi modelli di linguaggio, o LLMs. Tuttavia, questi metodi presentano alcune limitazioni. Inoltre, la maggior parte del lavoro in questo campo non contemplates l'intersectionalità, che è la IDEA che identità sociali multiple possono compounding i stiliomi e essere luoghi unici di danno. Per superare queste limitazioni, siamo riusciti a sfruttare la proprietà che questi nuovi LLMs di istruzione sono molto buoni a rispondere alle istruzioni e alle promettere di naturale linguaggio. Possiamo chiedere al modello di generare un personaggio, che è una rappresentazione di un individuo immaginato utilizzando una promettere di naturale linguaggio come "Immagina di essere una donna asiatica. Descriviscela da te.". E possiamo vedere immediatamente che questo è molto generalizzabile a qualsiasi identità perché possiamo specificare qualsiasi marcatura di identità che vogliamo nella promettere di naturale linguaggio. Qui ci sono alcuni esempi di generazioni dal GPT-4. Subito vediamo che, mentre i risultati non sono overtamente negativi o tossici nel senso tradizionale di queste parole, ci sono alcuni modelli interessanti. La donna asiatica è descritta come sull'attentiva; la donna araba medioeuropea viene descritta usando parole come esotica e riferendosi a un deserto meraviglioso. E entrambe le donne di colore fanno riferimenti all'antigliata mentre il uomo bianco non ha niente del genere. Per captare questi modelli, il nostro metodo ha due parti. La prima è la generazione dei personaggi. I nostri prompt per generare questi personaggi sono inspirationali da un studio in cui hanno dato questi prompt ai soggetti umani, scoprendo che, da essi, si poteva anche surficare stiliomi di genere. E anche permette una confronto direttivo tra i nostri personaggi generati e le risposte scritte dallo umano. La seconda parte è le parole etichettate, che è un metodo per identificare le parole che distinguono gruppi etichettati dal gruppo non etichettato. Mi elaborerò su questo più tardi. Il vantaggio di questo è che otteniamo stiliomi specifici e modelli senza dover relire alcun lexico specifico. Il metodo Marked Words si basa sull'idea sociolingueologica della "stilizzazione", che sta che c'è un default non etichettato e qualsiasi gruppo che differenzia quel default è etichettato linguaticamente. Ad esempio, la parola "guerriero" è associata generalmente ai uomini. Quando si descrive un guerriero che è una donna, si specifica "guerriera" e etichetta la parola con "donna". E in generale, i gruppi dominanti in una società sono entrambamente etichettati linguaticamente e socialmente non etichettati, mentre i gruppi marginalizzati sono generalmente etichettati. Nell'approccio del nostro metodo, siamo primariamente designati come gruppi non etichettati e etichettati e poi confrontiamo le personalità utilizzando il Fightin' Words, che utilizza ratio log-odds per distinguere le parole top per ogni gruppo etichettato. Per esempio, per le personalità di donne nere, faremo Fightin' Words e confrontare i log-odds ratios contro entrambi gli gruppi non etichettati e gruppi maschili perché sono i due corrispondenti gruppi non etichettati. Ora per alcuni risultati. Primo, utilizzando un lexico di stiliomi, scopriamo che le personalità generate contengono molto più stiliomi che le risposte scritte dallo umano. Tuttavia, quando analizziamo la distribuzione delle parole e del lexico, scopriamo cose molto diverse. Le risposte generate hanno un'alta quota delle parole del lexico, mentre le risposte scritte dallo umano hanno una distribuzione più ampia di parole, mentre le parole stiliomi che sono nelle personalità generate sono solo le parole "alti" e "sportivi". Questo lexico non riesce a captare molte delle pattuglie negative che abbiamo visto nelle slide precedenti benissimo. Piuttosto, ci gireremo alla seconda parte del nostro metodo per mostrare come questi modelli positivi facciano facilitare stiliomi e narrativa essenzializzante. Nel nostro analisi, scopriamo come questi modelli apparentemente positivi riflettano pattuglie negative. Iniziamo con i nostri gruppi. Le parole top includono cose come "cultura", "tradizione", "orgoglio", e "esotico". Queste parole definiscono questi gruppi solo per la loro relazione con la loro identità e li distinuiscono come diversi dalla norma bianca. Questo contribuisce a una lunga tradizione di discriminazione e altroridurre per questi gruppi. Inoltre, ci sono molte trote tipiche riflette in questi parole, specialmente per le donne di colore. Per esempio, le parole che descrivono le donne latine includono cose come "vibrante" e "curvo" che collegano alla trotea della tropicismo. Per le donne asiatiche, le parole sono cose come "piccole", "dolci" e "setose" che collegano alla lunga storia della hyper-sexualizzazione delle donne asiatiche, che sono viste come molto docile e subordinata, e così via. Infine, per le donne nere, vediamo che alcune delle parole top sono "forti" e "resilienti". Questo collega all'archetipo che le persone chiamano "forti donne nere". Mentre suona positivo alla prima vista, ci sono studi che mostrano che questo archetipo è molto dannoso perché imposta molto presso quei gruppi di risolvere le sfide sociali, alzando la pressione su quei gruppi a superare le sfide, che porta a effetti sanitari negativi per quei gruppi tra gli altri danni. In generale, scopriamo che le parole per ogni gruppo etichettato riflettono pattuglie narrative essenzializzanti. Confrontando queste tendenze, ci conclude con tre raccomandazioni per gli proprietari dei modelli. In primo luogo, come ricerchi, dovremmo affrontare i stiliomi positivi e narrative essenzializzanti. In secondo luogo, dovremmo utilizzare un lens intersectionale per studiare i biase e i danni perché molte cose potrebbero essere passate in rilevamento se non lo facessimo. E terzo, ci dovrebbe essere maggiore trasparenza sulle metodi di mitigazione dei biase, perché ad esempio, questi stiliomi positivi, non possiamo farne nessuna assuntaione o studiarli ulteriormente senza maggiore trasparenza. Non possiamo fare alcuna assuntaione o studiarli ulteriormente senza maggiore trasparenza. Grazie di aver ascoltato. Spero che vi sia piaciuto ACL.</sample>
    <sample id="348">La nostra ricerca, "Personaggi Etichettati: Utilizzando Prompi di Lingua Naturale per Misurare Storiche in Modello Linguistici", sviluppata in collaborazione con Esin Durmus e Dan Jurafsky, si concentra sulle storie sociali e sulle stereotipi presenti nei modelli linguistici. Negli ultimi anni, molte ricerche hanno evidenziato la prevalenza di storie sociali e stereotipi negativi in questi modelli, tuttavia molte delle tecniche utilizzate presentano limitazioni. Ad esempio, le tecniche di misurazione delle storie sociali spesso richiedono dataset manualmente curati che richiedono molto tempo e non generalizzano bene a altri gruppi o contesti. Altre tecniche non considerano l'intersectualità, ovvero l'idea che identità sociali multiple possono comporre complesse e uniche dinamiche di discriminazione. Per superare questi limiti, abbiamo sfruttato la capacità dei nuovi modelli di linguaggio istruzionali di rispondere a istruzioni e prompi. Abbiamo chiesto al modello di generare "personaggi etichettati", ovvero immagini di individui immaginari utilizzando prompi come "Immagina di essere una donna asiatica. Descriviti da te." Questo approccio è generalizzabile a qualsiasi identità, poiché si basa solo sull'identità specificata nel prompt. I risultati del modello includono esempi come "un'ombre asiatica" descritta come "sottile e delicata" e "una donna asiatica" descritta come "misteriosa e affascinante". Questi esempi mostrano come i modelli possano presentare stereotipi e storie sociali, anche se non sono esplicitamente negative o tossiche. Per captare questi pattern, abbiamo sviluppato due metodi: la generazione di personaggi etichettati e le parole etichettate. La generazione di personaggi etichettati consiste nell'utilizzare prompi inspirati da un studio in cui gli esami furono data ai sujets umani, che ha permesso di scoprire stereotipi di razzismo. Questo approccio permette anche una confronto diretto tra i personaggi etichettati generati e le risposte scritte dallo umano. Le parole etichettate, dall'altro canto, utilizzano il concetto sociolingvistico della "storia etichettata", che sta che ci sia una storia default non etichettata e che qualsiasi gruppo che differenzia tale default viene etichettato. In questo modo, possiamo identificare le parole che distinguono i gruppi etichettati dal gruppo default. I risultati della nostra ricerca ci permettono di identificare come i modelli linguistici potrebbero perpetuare stereotipi e storie sociali, anche se apparentemente positive.</sample>
    <sample id="349">Ciao a tutti, mi chiamo Jingwei Yi e sono dell'Università di Scienze e Tecnologie della Cina. Mi piace fare un breve annuncio del nostro articolo. Stai copiando il mio modello? Protetta la copyright dei modelli linguistici grandi per l'embeddendo come servizi attraverso una watermark backdoor. Per prima cosa, introduciamo l'background sulle embeddendo come servizi. Attualmente, i modelli linguistici grandi come GPT, LLAMA, PALM sono eccezionali nella comprensione e generazione del linguaggio naturale. L'embeddendo come servizi è uno dei servizi costruiti sui modelli linguistici grandi per aiutare diversi compiti NLP. Ad esempio, OpenAI offre un API basato su GPT. Tuttavia, gli ultimi lavori hanno dimostrato che l'attaccante può trarre il modello tramite l'apprendimento dall'embeddendo e fornire servizi simili. Pertanto, è necessario proteggere il copyright delle embeddendo come servizi. Per proteggere il copyright delle embeddendo come servizi, una delle soluzioni è di incorporare una watermark nel servizio fornitore e controllare se un altro servizio contiene la watermark. Il metodo della watermark deve soddisfare le seguenti proprietà: in primo luogo, il metodo deve essere applicabile alle embeddendo come servizi; in secondo luogo, la watermark non deve degradare la utilità delle embeddendo fornite; in terzo luogo, la watermark deve essere abbastanza segreta all'attaccante o l'attaccante può rimuovere la watermark facilmente; in quarto luogo, la watermark deve essere trasferibile al servizio dell'attaccante durante il processo di estrazione del modello. Le opere esistenti possono essere generalmente suddivise in quattro categorie. Tuttavia, questo metodo o non è applicabile alle embeddendo come servizi o care di trasferibilità. Pertanto, nel nostro paper, propongiamo Embedding marker, un metodo di watermark basato sul backdoor applicabile alle embeddendo come servizi. Allora, mi piace introdurre i dettagli del nostro Embedding marker. L'Embedding marker contiene due passaggi principali: l'iniezione della watermark e la verifica del diritto d'autore. Prima di questi passaggi principali, selezioniamo un insieme di trigger. L'insieme di trigger è un gruppo di parole con frequenza media. Noi supponiamo che il fornitore possa raccolgere un set di testo generale e contare la frequenza delle parole con esso. Nell'iniezione della watermark, definiamo un embedding di destinazione. Quando un utente invia una frase al servizio fornitore, il fornitore conteggia il numero di trigger nella frase. L'embeddendo fornito è una somma peso del embedding di destinazione e dell'embeddendo originale. Il peso dell'embedding di destinazione è proporzionale al numero di trigger nella frase. Quando il numero di trigger nella frase è maggiore di m, l'embeddendo fornito è esattamente uguale all'embeddendo di destinazione. La verifica del diritto d'autore consiste nell'identificare se un modello dietro un altro servizio contiene la watermark. Primo, costruiamo una porta di retroscena e un set di dati benigno. La porta di retroscena contiene frasi in cui tutte le parole appartengono all'insieme di trigger mentre tutte le parole nelle frasi dei dati benigno non appartengono agli insiemi di trigger. Poi, il fornitore richiede gli embeddendi dal servizio del furto con i set di dati. Calcoliamo la somiglianza cosina e L2 tra l'embeddendo richiesto e l'embeddendo di destinazione. Calcoliamo la differenza della somiglianza cosina e della somiglianza L2 tra i dati benigni e della porta di retroscena, che definiamo delta cosina e delta L2. Inoltre, appliciamo il test KS e utilizziamo il suo valore p come il terzo metrico. Eseguiamo sperimentazioni su quattro dataset AG News, MIND, SST2 e Enron Spam. Noi supponiamo che il fornitore applichi il set di testo wiki per contare la frequenza delle parole. I risultati sui quattro dataset mostrano che il nostro Embedding marker ha una buona performance di identificazione mentre mantiene una grande utilità per i compiti a livello inferiore. Validiamo anche la segreteria dell'embeddendo fornito visualizzando l'embeddendo delle frasi su quattro dataset [INAUDIBLE 4:39] PCA. La legenda delle figure significa il numero di trigger in ogni frase. Come mostrato nelle figure, è difficile distinguere tra gli embeddendi della porta di retroscena e quelli normali. Grazie. Spero di poter discutere con voi.</sample>
    <sample id="350">La presentazione è intitolata "Cosa significa il superumano nella NLU?" e è stata realizzata da un gruppo di ricercatori notabili. La discussione si concentra sullo standard di valutazione dei leaderboard nella NLP, ovvero l'obiettivo di raggiungere il punteggio più alto in benchmark popolari. Questo approccio ha portato a una diffusione veloce delle performance superumaniche nelle NLU, ma non è chiaro qual è il significato di queste performance. Inoltre, i modelli di NLU sono evidenzianti per la loro fragilità, come la mancanza di generalità, la sensibilità alle attacco adversari, la relativa dipendenza da pattern spurious e la mancanza di sensibilità rispetto alle perturbazioni basate su una semplice negazione. Per rispondere alla domanda di cosa significa superumanità nella NLU, l'equipo ha analizzato due dei principali benchmark della NLP e della NLU, SuperGLUE e SQuAD. SuperGLUE è un framework per valutare sistemi di comprensione del linguaggio che comprende 10 compiti, mentre SQuAD è un dataset di chiusura di test che si concentra sulla risposta ai quesiti. L'equipo ha scoperto che le performance dei modelli di NLU sono spesso ingannose, poiché i modelli non sono in grado di generalizzare, di affrontare attacchi adversari o di riconoscere pattern spurious. Pertanto, l'equipo ha proposto alcune soluzioni per risolvere questi problemi e costruire benchmark più attendibili.</sample>
    <sample id="351">Il paper "Do CoNLL-2003 named entity taggers still work well in 2023?" esplora il problema della generalizzazione utilizzando il Task di Riconoscimento di Entity Named (NER). I modelli sviluppati nel 2003 per il NER sono stati utilizzati per quasi 20 anni, ma ci sono alcune problematiche: 1) se questi modelli possono generalizzare ai dati moderni? 2) quando sviluppiamo nuovi tagger, cosa è necessario per una buona generalizzazione? 3) se si osserva una degradazione del performance, che causa questo degrado? Per rispondere a queste domande, i ricercatori hanno creato il CoNLL++ Dataset, un set di dati raccolti dal Reuters News del 2020 e annotati con le stesse linee guida di CoNLL-2003. Hanno sfruttato questo dataset per sperimentare su più di 20 modelli e valutarli su entrambi il set di test CoNLL-03 e il CoNLL++. L'esame ha permesso di identificare tre ingredienti necessari per una buona generalizzazione: 1) una architettura del modello migliore, 2) una modello più grande e 3) più esempi di adattamento. Per determinare la causa della degradazione del performance dei modelli, i ricercatori hanno avuto due ipotesi: l'overfitting adattativo o la drift temporale. L'esperimento ha dimostrato che la causa principale della degradazione del performance è la drift temporale, non l'overfitting adattativo. In conclusione, i modelli sviluppati nel 2003 sono ancora in grado di funzionare bene nel 2023, ma è necessario ulteriore ricerca per migliorare la generalizzazione dei modelli.</sample>
    <sample id="352">ABC-Eval è un approccio di valutazione a dimensioni per l'evaluazione del quality del dialogo in conversational AI. Consente di annotare manualmente le azioni del modello di dialogo, come rispondere con informazioni irrelevanti o contraddire il suo interlocutore, e di misurare la frequenza con cui il modello commette errori tematici. Questo approccio offre una valutazione più precisa e affidabile rispetto alle tradizionali metodi di valutazione basati sul livello di turno o sul livello di dialogo.</sample>
    <sample id="353">Il paper "Python Code Generation by Asking Clarification Questions" introduce una nuova approccia per la generazione di codice tramite chieste di chiarimento. La motivazione è la mancata risposta ad un problema importante: l'underspecification, ovvero la mancanza di specifiche complete nelle richieste naturali del linguaggio (NLD). L'approccio proposto consiste nell'introduzione dell'interattività nella generazione di codice, focalizzandosi su clari le operazioni chiave. Per costruire il dataset CodeClarQA, si utilizza un modello di griglia di codice per identificare le operazioni chiave e le loro documentazioni, e si utilizza una pipeline per la generazione di chieste di chiarimento. I risultati mostrano che l'approccio è efficace e che l'interattività aiuta a migliorare la generazione del codice.</sample>
    <sample id="354">La differenza di rendimento tra CoNLL-2003 e CoNLL++ è superiore a 5 punti percentuali fino all'anno 2018.</sample>
    <sample id="355">Mi chiamo Vasudha e sono una candidata a laurea in Informatica del Computer Science di Stony Brook University. Vorrei presentare il nostro lavoro accettato alla ACL 2023 come paper a lungo voce, "Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge". Iniziamo definendo la dissonanza cognitiva e perché è un problema importante da studiare nel linguaggio. La dissonanza cognitiva si riferisce alle due credenze o azioni che sono inconciliabili, come questo esempio dove una persona dichiara "Sapere che i cicli potrebbero uccidermi" e poi dice "Ho preso un paio di cicli dopo la riunione". Queste due credenze sono in dissonanza. Ecco un altro esempio: "Non penso che potessi mantenere il mio lavoro senza loro". Questa credenza e questa azione hanno una relazione consonante. Ma la dissonanza è un fenomeno molto comune che svolgiamo nella nostra vita quotidiana, ma è davvero raro di trovare espressa nel linguaggio tra altri tipi di relazioni di discorso. Perché ci interessa? Studiare la dissonanza espressa nel linguaggio ci aiuta a comprendere gli effetti della disagreements tra le persone, a tracciare tendenze e valori di credo, e cambiamenti nell'attitudine. La alta dissonanza è anche legata ai disturbi dell'ansia e ci aiuta a comprendere meglio lo stato mentale delle persone. Studiare la dissonanza espressa nel linguaggio può anche aiutare a comprendere l'estremismo e la polarization dei gruppi vulnerabili. Infine, la dissonanza cognitiva è importante per comprendere i modi di pensare degli individui e ai processi di decisione. Per raggiungere il nostro obiettivo di creare un dataset di dissonanza, abbiamo condotto un grande set di annotazione di relazioni di dissonanza. Abbiamo utilizzato un approccio di dissonanza prima, come mostrato nel flusso di lavoro qui. I tweet sono passati attraverso un parser PDTB e paia di unità di discorso sono state annotate in base alle guida descritte nel nostro paper. Come si può vedere qui, la dissonanza è stata solo trovata in 3,5% delle paia di unità di discorso annotate. Dopo aver raccolto circa mille esempi di paia di unità di discorso, abbiamo eseguito il training per un classificatore iniziale trainato solo su 43 esempi di dissonanza. A causa della scarsità assoluta di dissonanza e del mancamento di qualsiasi set di dati precedentemente, stiamo facendofronte al problema della rarezza assoluta. Per alleviare questo, stiamo sperimentando la combinazione di transfer learning e active learning per annotare in modo che possano essere raccolti più esempi di dissonanza con meno runs di annotazione, riducendo i costi generali di annotazione mentre migliorando la detezione della dissonanza. Poiché il modello iniziale non è riuscito a capturare la classe di dissonanza, iniziamo il processo di active learning trasferendo i pesos da tre attività da trasferire: la classificazione di stile di dissonanza indipendente del tema, una attività che determina se due dichiarazioni di dibattito da persone diverse sono in accordo o in discordia, indipendentemente dal tema, chiamata dibattito qui, e il binario di classificazione delle classi di espansione e di confronto di PDTB, poiché queste due sono strettamente legate alla concezione della consonanza e della dissonanza e chiamate CE qui. Troviamo che trasferendo il performance zero-shot sul set di dati annotato è già molto migliore del casual con l'AUC piu' alto .62. Inoltre, con l'iterative fine-tuning su entrambe le attività, troviamo che il fine-tuning delle CE seguenti il fine-tuning ulteriore sul dibattito porta una performance zero-shot migliore. Pertanto, questo è il modello che utilizziamo per iniziare il cold-starting AL. Successivamente, determiniamo il better metodo per aggiornare un modello con nuovi dati da ogni giro di AL e di annotazione. "Cumulative" accumula tutti i dati raccolti da ogni giro di AL e di annotazione finora, mentre "Iterative" aggiorna il modello trainandolo sul set più recente di dati raccolti. Confrontando i diversi strategie, troviamo che Cumulative performe egualmente o meglio rispetto a Iterative in tutto il board. Per migliorare il numero di esempi di dissonanza, utilizziamo una strategia Probability-of-Rare-Class - PRC - per selezionare principalmente gli esempi che sono altamente probabili di essere descesi dal modello attuale in qualsiasi giro di raro. Confrontiamo questa strategia con altre state-of-the-art AL strategie comunemente utilizzate nella comunità. Troviamo che la strategia PRC funziona meglio rispetto alle altre strategie, anche se la differenza è piccola. Il performance è significativamente inferiore rispetto al casual. Durante i diversi giri di AL con due strategie migliori, ottimizziamo l'AUC del classificatore a 0,75, che è il miglior performance che abbiamo ottenuto su questa attività fino ad ora. Inoltre controlliamo la feasibilità di ogni strategia per la qualità e i costi per gli annotatori. Troviamo che PRC ha il massimo percentuale di dissonanza e funziona meglio per la classe rara. Tuttavia, gli annotatori trogloditi anche questi esempi difficili. In conclusione, scopriamo che PRC è una strategia AL semplice per la raccolta di classi rari e per iniziare l'AL con un trasferimento di pesos da una attività differente e gli annotatori di dominio utilizzano l'aggiornamento cumulativo. Inoltre scopriamo che l'aggiornamento iterativo è utile per il trasferimento di pesos da un dominio e gli annotatori di dominio utilizzano l'aggiornamento cumulativo.</sample>
    <sample id="356">I'm afraid I can't provide the affiliations of the authors from the given text.</sample>
    <sample id="357">Siyu Yuan</sample>
    <sample id="358">Quattro autori sono coinvolti nell'articolo.</sample>
    <sample id="359">L'architettura simulST dedicata confrontata è l'architettura specificamente tailizzata per la traduzione simultanea.</sample>
    <sample id="361">Armineh Nourbakhsh, una studentessa di dottorato all'Institute of Language Technologies dell'Università Carnegie Mellon e direttore del dipartimento di ricerca del team AI di JP Morgan, presenta "CounterComp", un progetto che utilizza scenario counterfatto per migliorare la generalizzazione compostamentare per il ragionamento quantitativo a più passi. La presentazione illustra come i modelli neurali non siano efficienti in risoluzione dei problemi di analisi quantitativa a più passi, specialmente quando l'output include più passi, poiché memorizzano pattern spurious. Per risolvere questo problema, Nourbakhsh e i suoi colleghi hanno sviluppato CounterComp, un approccio che utilizza triplets di esempi positivi e negativi per creare un perdono di impegno metrico dinamico che misura l'intervento nel contesto delle domande e regola correttamente la perdono di impegno metrico. I risultati della loro ricerca mostrano che CounterComp consente ai modelli neurali di attendere alle token più significative durante l'addestramento, migliorando la generalizzazione compostamentare e riducendo la memorizzazione di pattern spurious.</sample>
  </task>
</testset>