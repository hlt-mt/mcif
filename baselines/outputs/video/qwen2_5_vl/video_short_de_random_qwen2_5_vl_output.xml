<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind Websites wie patents.google.com, en.wikipedia.org, en.m.wikipedia.org, www.nytimes.com, www.washingtonpost.com, www.theguardian.com, journals.plos.org, www.frontiersin.org, www.washingtonpost.com, patents.com, www.scribd.com, www.washingtonpost.com, www.fool.com, www.washingtonpost.com, www.frontiersin.org, www.businessinsider.com, www.chicagotribune.com, www.booking.com, www.thematic.com, www.springer.com, www.kickstarter.com, caselaw.findlaw.com, www.acth.fiu.edu, www.npr.org.</sample>
    <sample id="1">Die Autoren gehören an McGill University und Mila.</sample>
    <sample id="2">DEPLAIN: Ein deutsches Parallelkorpus mit intralingualen Übersetzungen in einfache Sprache zur Satz- und Dokumenteinfachstellung

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich Heine University Düsseldorf, Deutschland

ACL 2023</sample>
    <sample id="3">DEPLAIN: Ein deutsches Parallelkorpus mit intralingualen Übersetzungen in einfache Sprache zur Satz- und Dokumenteinfachstellung

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich Heine University Düsseldorf, Deutschland

ACL 2023

1. Texteinfachstellung
Was, warum und wie?</sample>
    <sample id="4">Übersetzung:

"Text-Simplifikation-Beispiel

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plaine Sprache:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="5">Übersetzung:

Texteinfachheitsbeispiel

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Einfache Sprache:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="6">Übersetzung:

"Text-Simplifikation-Beispiel

Original:
'Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden.'

Plain Language:
'Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein.'"

Die Übersetzung zeigt die verschiedenen Methoden der Textsimplifikation, wie Substitution, Clause Deletion, Reordering und Word Deletion, anhand eines Beispiels in deutscher Sprache.</sample>
    <sample id="7">Das Bild zeigt ein Beispiel für Texteinfachstellung. Es gibt zwei Versionen eines Satzes: die ursprüngliche Version und die vereinfachte Version.

**Original:**
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

**Vereinfachte Version (Plain Language):**
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."

Die verschiedenen Verfahren zur Einfachstellung sind mit Pfeilen und farbigen Kästen markiert:
- **Substitution**: Die Wortfolge "dafür ein, dass" wird durch "zum Beispiel für" ersetzt.
- **Clause Deletion**: Die Nebensatz "dass zum Beispiel höhere Löhne gezahlt werden" wird entfernt.
- **Reordering**: Der Satz wird umgeordnet, um eine klarere Struktur zu schaffen.
- **Word Deletion**: Das Wort "oder" wird entfernt.
- **Insertion**: Das Wort "oder" wird wiederholt, um die Bedeutung zu verdeutlichen.

Diese Verfahren helfen dabei, den Text einfacher und verständlicher zu gestalten.</sample>
    <sample id="8">Die deutsche Übersetzung des englischen Inhalts lautet:

"2. DE-plain
Ein neues Korpus

German Text Simplification Corpora

Sentence Level

[Diagramm: German Text Simplification Corpora]
[Diagramm: Sentence Level]"

Das Diagramm zeigt verschiedene deutsche Textsimplifikationskorpora und deren Größe in Sätzen.</sample>
    <sample id="9">Die deutsche Übersetzung des englischen Inhalts lautet:

"Deutsche Texteinfachheitskorpora

Sentence Level"

Der Diagrammtext lautet:

"Domänen:
- gemischt
- Gesundheit
- Nachrichten
- L2
- Fachliteratur
- Wikipedia

Ausrichtung:
- manuell
- automatisch"

Die Balkendiagramme zeigen die Anzahl der Sätze in verschiedenen Korpora, wie z.B. "Klappe (Klamer et al. 2013)", "TextComplexityDE19 (Nieder et al. 2019)", "ZEST-data (Mullinson et al. 2020)", "APR-LHA-or-a2 (Springer et al. 2021)", "APR-LHA-or-b1 (Springer et al. 2021)", "Simple-German-Corpus (Robotek et al. 2025)" und "DEplain-APA" sowie "DEplain-web".</sample>
    <sample id="10">Die deutsche Übersetzung des englischen Inhalts lautet:

"Deutsche Texteinfachheitskorpora

Sentence Level"

Die Grafik zeigt die Anzahl der Sätze in verschiedenen Korpora, die für die Einfachheit von deutschen Texten verwendet werden. Die Daten sind nach Domänen (z.B. Gesundheit, Nachrichten, Lernhilfen) und nach der Art der Ausrichtung (manuell oder automatisch) aufgeteilt. Einige der genannten Korpora sind:

- Klappe (Klapper et al. 2013)
- TextComplexityDE19 (Nieder et al. 2019)
- ZEST-data (Millardson et al. 2020)
- APH-LHA-or-a2 (Springer et al. 2021)
- APH-LHA-or-b1 (Springer et al. 2021)
- Simple-German-Corpus (Robotek et al. 2025)

Die Grafik zeigt auch die Anzahl der Sätze in den Korpora DEplain-APA und DEplain-web.</sample>
    <sample id="11">Deutsche Übersetzung:

"Deutsche Textvereinfachungs-Korpora"

Sentence Level

Die Grafik zeigt die Größe von verschiedenen Korpora für die deutsche Textvereinfachung auf der Ebene der Sätze. Die Daten sind nach den folgenden Kategorien gruppiert:

- Bereiche: gemischt, Gesundheit, Lernende, fiktional, Bibel, öffentliche Verwaltung, Politik
- Ausrichtung: manuell, automatisch

Die Größen der Korpora sind wie folgt angegeben (in Tausend):

- Kläper (Kläper et al. 2013): 2000
- TextComplexityDE19 (Nieden et al. 2019): 250
- ZEST-data (Millison et al. 2020): 1198
- APB-LHA-or-a2 (Springer et al. 2021): 9456
- APB-LHA-or-b1 (Springer et al. 2021): 10268
- Simple-German-Corpus (Robotek et al. 2020): 5942
- DEplain-APA: 13122
- DEplain-web: 756</sample>
    <sample id="12">Die deutsche Übersetzung des englischen Inhalts lautet:

"Deutsche Texteinfachheitskorpora

Satzebene"

Die Grafik zeigt die Anzahl der Sätze in verschiedenen Korpora, die für die Einfachheit von deutschen Texten verwendet werden. Die Daten sind nach Domänen (z.B. Gesundheit, Nachrichten, Lernhilfen) und nach der Art der Ausrichtung (manuell oder automatisch) aufgeteilt. Einige der genannten Korpora sind:

- Klappe (Klapper et al. 2013)
- TextComplexityDE19 (Nieden et al. 2019)
- ZEST-data (Millison et al. 2020)
- APB-LHA-or-a2 (Springer et al. 2021)
- APB-LHA-or-b1 (Springer et al. 2021)
- Simple-German-Corpus (Robotek et al. 2020)

Die Grafik zeigt auch die Anzahl der Sätze in den Korpora DEplain-APA und DEplain-web.</sample>
    <sample id="13">Die deutsche Übersetzung des englischen Inhalts lautet:

"Deutsche Textvereinfachungs-Korpora

Sentence Level"

Der Diagrammtext lautet:

"Kategorien:
- gemischt
- Gesundheit
- Nachrichten
- L2
- fiktional
- Bibel
- öffentliche Autorität
- Politik

Ausrichtung:
- manuell
- automatisch"

Die Balkendiagramme zeigen die Anzahl der Sätze für verschiedene Kategorien und Ausrichtungen, wie z.B. 2000 manuelle Sätze in der Kategorie "gemischt", 1198 automatische Sätze in der Kategorie "fiktional" usw.

Zusätzlich gibt es zwei zusätzliche Balkendiagramme mit den Zahlen 483 und 756, die vermutlich auf spezifische Datenpunkte hinweisen."</sample>
    <sample id="14">### Arten der Vereinfachung

#### Typen der Vereinfachung
- **Simplicity**
- **LexSimp**
- **StructSimp**

#### Vereinfachungsverfahren
- **Reordering** (Anordnung ändern)
- **Rephrasing** (Wiederausdrücken)
- **Lexical Substitution** (Wortersatz)
- **Word Addition** (Worterhöhung)
- **Word Deletion** (Wortentfernung)</sample>
    <sample id="15">### Arten der Vereinfachung

#### Typen der Vereinfachung
- **Simplicity**
- **LexSimp**
- **StructSimp**

#### Vereinfachungsverfahren
- **Reordering** (Anordnung ändern)
- **Rephrasing** (Wiederformulieren)
- **Lexical Substitution** (Wortersatz)
- **Word Addition** (Worterhöhung)
- **Word Deletion** (Wortentfernung)</sample>
    <sample id="16">### Arten der Vereinfachung

#### Typen der Vereinfachung

- **Simplicity**
- **LexSimp**
- **StructSimp**

#### Vereinfachungsverfahren

- **Reordering** (Anordnung ändern)
- **Rephrasing** (Wiederformulieren)
- **Lexical Substitution** (Wortersatz)
- **Word Addition** (Worterhöhung)
- **Word Deletion** (Wortentfernung)</sample>
    <sample id="17">### Arten der Vereinfachung

#### Typen der Vereinfachung
- **Simplicity**
- **LexSimp**
- **StructSimp**

#### Vereinfachungsverfahren
- **Reordering** (Anordnung ändern)
- **Rephrasing** (Wiederformulieren)
- **Lexical Substitution** (Wortersatz)
- **Word Addition** (Worterhöhung)
- **Word Deletion** (Wortentfernung)</sample>
    <sample id="18">### Arten der Vereinfachung

Die Grafik zeigt die verschiedenen Arten der Vereinfachung in verschiedenen Textkategorien:

- **News**: 46 Texte
  - **Simplicity**: 0,5
  - **LexSimp**: 0,3
  - **StructSimp**: 0,5

- **Bible**: 155 Texte
  - **Simplicity**: 1,2
  - **LexSimp**: 0,9
  - **StructSimp**: 1,2

- **L2**: 157 Texte
  - **Simplicity**: 0,6
  - **LexSimp**: 0,4
  - **StructSimp**: 0,6

- **Fiction**: 72 Texte
  - **Simplicity**: 1,0
  - **LexSimp**: 0,6
  - **StructSimp**: 1,0

### Vereinfachungsverfahren

Die Grafik zeigt die häufigsten Verfahren zur Vereinfachung von Texten:

- **Reordering**: 50%
- **Rephrasing**: 10%
- **Lexical Substitution**: 80%
- **Word Addition**: 10%
- **Word Deletion**: 20%

Diese Verfahren werden für zwei verschiedene Anwendungen (DEplain-apa und DEplain-web) dargestellt.</sample>
    <sample id="19">3. Fallstudien
Automatische Ausrichtung und Vereinfachung

### Ergebnisse der Ausrichtungsverfahren mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung | 1:1 | n:m |
|------|--------------|-----|-----|
| LHA | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding | .94 | .41 | .57 | .747 | - | - | - |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers | .961 | .444 | .608 | .780 | - | - | - |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa | .960 | .444 | .607 | .779 | - | - | - |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren | .247 | .553 | .342 | .278 | - | - | - |
| VecAlign | Multilingualer Aligner basierend auf multilingualen Satzembeddings | .271 | .404 | .323 | .290 | .260 | .465 | .333 | .285 |
| BERTalign | Erlaubt, dass sentence-transformer Methoden n:m Ausrichtungen produzieren | .743 | .465 | .572 | .664 | .387 | .561 | .458 | .412 |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix | .846 | .477 | .610 | .733 | .819 | .509 | .628 | .730 |

### Übersetzung des Titels:
"3. Fallstudien
Automatische Ausrichtung und Vereinfachung"

### Übersetzung des Tabelleninhalts:
Ergebnisse der Ausrichtungsverfahren mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung | 1:1 | n:m |
|------|--------------|-----|-----|
| LHA | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding | .94 | .41 | .57 | .747 | - | - | - |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers | .961 | .444 | .608 | .780 | - | - | - |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa | .960 | .444 | .607 | .779 | - | - | - |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren | .247 | .553 | .342 | .278 | - | - | - |
| VecAlign | Multilingualer Aligner basierend auf multilingualen Satzembeddings | .271 | .404 | .323 | .290 | .260 | .465 | .333 | .285 |
| BERTalign | Erlaubt, dass sentence-transformer Methoden n:m Ausrichtungen produzieren | .743 | .465 | .572 | .664 | .387 | .561 | .458 | .412 |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix | .846 | .477 | .610 | .733 | .819 | .509 | .628 | .730 |</sample>
    <sample id="20">Übersetzung:

Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung |
|------|--------------|
| LHA  | Hierarchische Ausrichtung mithilfe von Ähnlichkeiten in Satzembedding |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren |
| VecAlign | Multilinguale Ausrichtung basierend auf multilingualen Satzembedding |
| BERTalign | Erlaubt, dass sentence-transformer Methoden n:m Ausrichtungen produzieren |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix |

| 1:1 | n:m |
|-----|-----|
| P   | R   | F1  | F0.5 | P   | R   | F1  | F0.5 |
| .94 | .41 | .57 | .744 | -   | -   | -   | -    |
| .961|.444|.608|.780| -   | -   | -   | -    |
| .960|.444|.607|.779| -   | -   | -   | -    |
| .247|.553|.342|.278| -   | -   | -   | -    |
| .271|.404|.323|.290|.260|.465|.333|.285|
| .743|.465|.572|.664|.387|.561|.458|.412|
| .846|.477|.610|.733|.819|.509|.628|.730|</sample>
    <sample id="21">Übersetzung:

Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung |
|------|--------------|
| LHA  | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren |
| VecAlign | Multilinguale Ausrichtung basierend auf multilingualen Satzembedding |
| BERTalign | Erlaubt, dass sentence-transformer Methoden n:m Ausrichtungen produzieren |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix |

| 1:1 | n:m |
|-----|-----|
| P   | R   | F1  | F0.5 | P   | R   | F1  | F0.5 |
| .94 | .41 | .57 | .747 | -   | -   | -   | -    |
| .961|.444|.608|.780| -   | -   | -   | -    |
| .960|.444|.607|.779| -   | -   | -   | -    |
| .247|.553|.342|.278| -   | -   | -   | -    |
| .271|.404|.323|.290|.260|.465|.333|.285|
| .743|.465|.572|.664|.387|.561|.458|.412|
| .846|.477|.610|.733|.819|.509|.628|.730|</sample>
    <sample id="22">Übersetzung:

Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung |
|------|--------------|
| LHA  | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren |
| VecAlign | Multilinguale Ausrichtung basierend auf multilingualen Satzembeddings |
| BERTalign | Erlaubt, dass sentence-transformer Methoden n:m Ausrichtungen produzieren |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix |

| 1:1 | n:m |
|-----|-----|
| P   | R   | F1  | F0.5 | P   | R   | F1  | F0.5 |
|-----|-----|-----|------|-----|-----|-----|------|
| .94 | .41 | .57 | .744 | -   | -   | -   | -    |
| .961| .444| .608| .780 | -   | -   | -   | -    |
| .960| .444| .607| .779 | -   | -   | -   | -    |
| .247| .553| .342| .278 | -   | -   | -   | -    |
| .271| .404| .323| .290 | .260| .465| .333| .285 |
| .743| .465| .572| .664 | .387| .561| .458| .412 |
| .846| .477| .610| .733 | .819| .509| .628| .730 |</sample>
    <sample id="23">Übersetzung:

Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung |
|------|--------------|
| LHA  | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren |
| VecAlign | Multilingualer Ausrichter basierend auf multilingualen Satzembeddings |
| BERTalign | Erlaubt, dass sentence-transformer Methoden n:m Ausrichtungen produzieren |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix |

| 1:1 | n:m |
|-----|-----|
| P   | R   | F1  | F0.5 | P   | R   | F1  | F0.5 |
|-----|-----|-----|------|-----|-----|-----|------|
| .94 | .41 | .57 | .744 | -   | -   | -   | -    |
| .961| .444| .608| .780 | -   | -   | -   | -    |
| .960| .444| .607| .779 | -   | -   | -   | -    |
| .247| .553| .342| .278 | -   | -   | -   | -    |
| .271| .404| .323| .290 | .260| .465| .333| .285 |
| .743| .465| .572| .664 | .387| .561| .458| .412 |
| .846| .477| .610| .733 | .819| .509| .628| .730 |</sample>
    <sample id="24">Übersetzung:

Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung |
|------|--------------|
| LHA  | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren |
| VecAlign | Multilingualer Ausrichter basierend auf multilingualen Satzembeddings |
| BERTalign | Erlaubt, dass Satz-Transformer-Methoden n:m Ausrichtungen produzieren |
| MASSalign | Eine Nähe-getriebene Ansatz mit einer TF-IDF-Similaritätsmatrix |

| 1:1 | n:m |
|-----|-----|
| P   | R   | F1  | F0.5 | P   | R   | F1  | F0.5 |
|-----|-----|-----|------|-----|-----|-----|------|
| .94 | .41 | .57 | .744 | -   | -   | -   | -    |
| .961|.444|.608|.780| -   | -   | -   | -    |
| .960|.444|.607|.779| -   | -   | -   | -    |
| .247|.553|.342|.278| -   | -   | -   | -    |
| .271|.404|.323|.290|.260|.465|.333|.285|
| .743|.465|.572|.664|.387|.561|.458|.412|
| .846|.477|.610|.733|.819|.509|.628|.730|</sample>
    <sample id="25">Übersetzung:

Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding | .94 | .41 | .57 | .744 | - | - | - |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers | .961 | .444 | .608 | .780 | - | - | - |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa | .960 | .444 | .607 | .779 | - | - | - |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße wie z.B. n-Grams (C3G)/Wortvektoren | .247 | .553 | .342 | .278 | - | - | - |
| VecAlign | Multilinguale Ausrichtung basierend auf multilingualen Satzembeddings | .271 | .404 | .323 | .290 | .260 | .465 | .333 | .285 |
| BERTalign | Erlaubt, dass sentence-transformer Methoden n:m Ausrichtungen produzieren | .743 | .465 | .572 | .664 | .387 | .561 | .458 | .412 |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix | .846 | .477 | .610 | .733 | .819 | .509 | .628 | .730 |

Diese Übersetzung enthält die wichtigsten Informationen aus dem Originalinhalt und passt sie in den deutschen Sprachrahmen an.</sample>
    <sample id="26">Übersetzung:

Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding | .94 | .41 | .57 | .747 | - | - | - |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers | .961 | .444 | .608 | .780 | - | - | - |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa | .960 | .444 | .607 | .779 | - | - | - |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren | .247 | .553 | .342 | .278 | - | - | - |
| VecAlign | Multilinguale Ausrichtung basierend auf multilingualen Satzembeddings | .271 | .404 | .323 | .290 | .260 | .465 | .333 | .285 |
| BERTalign | Erlaubt, dass Satz-Transformer-Methoden n:m Ausrichtungen produzieren | .743 | .465 | .572 | .664 | .387 | .561 | .458 | .412 |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix | .846 | .477 | .610 | .733 | .819 | .509 | .628 | .730 |</sample>
    <sample id="27">Übersetzung:

**Automatische Textvereinfachung**

**Dokumentebene**

Ergebnisse zur Dokumentvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44,56 | 38,136 | 0,598 | 65,4 |
| DEplain-web | 481 | 35,02 | 12,913 | 0,475 | 59,55 |
| DEplain-APA+web | 868 | 42,862 | 36,449 | 0,589 | 65,4 |
| src2src-baseline | 17.637 | 34,247 | 0,583 | 58,85 |

**DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43,087 | 21,9 | 0,377 | 64,7 |
| DEplain-web | 481 | 49,584 | 23,282 | 0,462 | 63,5 |
| DEplain-APA+web | 868 | 49,745 | 23,37 | 0,445 | 57,95 |
| src2src-baseline | 12.848 | 23,132 | 0,432 | 59,4 |

**DEPLAIN-WEB test (n=147)**

**Satzebene**

Ergebnisse zur Satzvereinfachung mit finetuned mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34,818 | 28,25 | 0,639 | 63,072 |
| DEplain-APA+web | 11941 | 34,904 | 28,506 | 0,64 | 62,669 |
| src2src-baseline | 15.249 | 26,893 | 0,627 | 59,23 |

**DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30,867 | 15,727 | 0,413 | 64,516 |
| DEplain-APA+web | 11941 | 34,828 | 17,88 | 0,436 | 65,249 |
| src2src-baseline | 11.931 | 20,85 | 0,423 | 60,825 |

**DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="28">Übersetzung:

**Automatische Textvereinfachung**

**Dokumentebene**

Ergebnisse zur Dokumentvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44,56 | 38,136 | 0,598 | 65,4   |
| DEplain-web | 481 | 35,02 | 12,913 | 0,475 | 59,55  |
| DEplain-APA+web | 868 | 42,862 | 36,449 | 0,589 | 65,4   |
| src2src-baseline | 17.637 | 34,247 | 0,583 | 58,85  |

**DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43,087 | 21,9   | 0,377  | 64,7   |
| DEplain-web | 481 | 49,584 | 23,282 | 0,462  | 63,5   |
| DEplain-APA+web | 868 | 49,745 | 23,37  | 0,445  | 57,95  |
| src2src-baseline | 12.848 | 23,132 | 0,432  | 59,4   |

**DEPLAIN-WEB test (n=147)**

**Satzebene**

Ergebnisse zur Satzvereinfachung mit finetuned mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34,818 | 28,25  | 0,639  | 63,072 |
| DEplain-APA+web | 11941 | 34,904 | 28,506 | 0,64   | 62,669 |
| src2src-baseline | 15.249 | 26,893 | 0,627  | 59,23  |

**DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30,867 | 15,727 | 0,413  | 64,516 |
| DEplain-APA+web | 11941 | 34,828 | 17,88  | 0,436  | 65,249 |
| src2src-baseline | 11.931 | 20,85  | 0,423  | 60,825 |

**DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="29">Übersetzung:

**Automatische Textvereinfachung**

**Dokumentebene**

Ergebnisse zur Dokumentvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44,56 | 38,136 | 0,598 | 65,4   |
| DEplain-web | 481 | 35,02 | 12,913 | 0,475 | 59,55  |
| DEplain-APA+web | 868 | 42,862 | 36,449 | 0,589 | 65,4   |
| src2src-baseline | 17.637 | 34,247 | 0,583 | 58,85  |

**DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43,087 | 21,9   | 0,377  | 64,7   |
| DEplain-web | 481 | 49,584 | 23,282 | 0,462  | 63,5   |
| DEplain-APA+web | 868 | 49,745 | 23,37  | 0,445  | 57,95  |
| src2src-baseline | 12.848 | 23,132 | 0,432  | 59,4   |

**DEPLAIN-WEB test (n=147)**

**Satzebene**

Ergebnisse zur Satzvereinfachung mit finetuned mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34,818 | 28,25  | 0,639  | 63,072 |
| DEplain-APA+web | 11941 | 34,904 | 28,506 | 0,64   | 62,669 |
| src2src-baseline | 15.249 | 26,893 | 0,627  | 59,23  |

**DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30,867 | 15,727 | 0,413  | 64,516 |
| DEplain-APA+web | 11941 | 34,828 | 17,88  | 0,436  | 65,249 |
| src2src-baseline | 11.931 | 20,85  | 0,423  | 60,825 |

**DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="30">Übersetzung:

**Automatische Textvereinfachung**

**Dokumentebene**

Ergebnisse zur Dokumentvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44,56 | 38,136 | 0,598 | 65,4   |
| DEplain-web | 481 | 35,02 | 12,913 | 0,475 | 59,55  |
| DEplain-APA+web | 868 | 42,862 | 36,449 | 0,589 | 65,4   |
| src2src-baseline | 17.637 | 34,247 | 0,583 | 58,85  |

**Tabelle 5: DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43,087 | 21,9   | 0,377 | 64,7   |
| DEplain-web | 481 | 49,584 | 23,282 | 0,462 | 63,5   |
| DEplain-APA+web | 868 | 49,745 | 23,37  | 0,445 | 57,95  |
| src2src-baseline | 12.848 | 23,132 | 0,432 | 59,4   |

**Tabelle 6: DEPLAIN-WEB test (n=147)**

**Satzebene**

Ergebnisse zur Satzvereinfachung mit finetuned mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34,818 | 28,25  | 0,639 | 63,072 |
| DEplain-APA+web | 11941 | 34,904 | 28,506 | 0,64  | 62,669 |
| src2src-baseline | 15.249 | 26,893 | 0,627 | 59,23 |

**Tabelle 7: DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30,867 | 15,727 | 0,413 | 64,516 |
| DEplain-APA+web | 11941 | 34,828 | 17,88  | 0,436 | 65,249 |
| src2src-baseline | 11.931 | 20,85  | 0,423 | 60,825 |

**Tabelle 8: DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="31">Übersetzung:

**Automatische Textvereinfachung**

**Dokumentebene**

Ergebnisse zur Dokumentvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44,56 | 38,136 | 0,598 | 65,4   |
| DEplain-web | 481 | 35,02 | 12,913 | 0,475 | 59,55  |
| DEplain-APA+web | 868 | 42,862 | 36,449 | 0,589 | 65,4   |
| src2src-baseline | 17.637 | 34,247 | 0,583 | 58,85  |

**DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43,087 | 21,9   | 0,377  | 64,7   |
| DEplain-web | 481 | 49,584 | 23,282 | 0,462  | 63,5   |
| DEplain-APA+web | 868 | 49,745 | 23,37  | 0,445  | 57,95  |
| src2src-baseline | 12.848 | 23,132 | 0,432  | 59,4   |

**DEPLAIN-WEB test (n=147)**

**Satzebene**

Ergebnisse zur Satzvereinfachung mit finetuned mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34,818 | 28,25  | 0,639  | 63,072 |
| DEplain-APA+web | 11941 | 34,904 | 28,506 | 0,64   | 62,669 |
| src2src-baseline | 15.249 | 26,893 | 0,627  | 59,23  |

**DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30,867 | 15,727 | 0,413  | 64,516 |
| DEplain-APA+web | 11941 | 34,828 | 17,88  | 0,436  | 65,249 |
| src2src-baseline | 11.931 | 20,85  | 0,423  | 60,825 |

**DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="32">Übersetzung:

**Automatische Textvereinfachung**

**Dokumentebene**

Ergebnisse zur Dokumentvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44,56 | 38,136 | 0,598 | 65,4   |
| DEplain-web | 481 | 35,02 | 12,913 | 0,475 | 59,55  |
| DEplain-APA+web | 868 | 42,862 | 36,449 | 0,589 | 65,4   |
| src2src-baseline | 17.637 | 34,247 | 0,583 | 58,85  |

**Tabelle 9: DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43,087 | 21,9   | 0,377 | 64,7  |
| DEplain-web | 481 | 49,584 | 23,282 | 0,462 | 63,5  |
| DEplain-APA+web | 868 | 49,745 | 23,37  | 0,445 | 57,95 |
| src2src-baseline | 12.848 | 23,132 | 0,432 | 59,4   |

**Tabelle 10: DEPLAIN-WEB test (n=147)**

**Satzebene**

Ergebnisse zur Satzvereinfachung mit finetuned mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34,818 | 28,25  | 0,639 | 63,072 |
| DEplain-APA+web | 11941 | 34,904 | 28,506 | 0,64  | 62,669 |
| src2src-baseline | 15.249 | 26,893 | 0,627 | 59,23 |

**Tabelle 11: DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30,867 | 15,727 | 0,413 | 64,516 |
| DEplain-APA+web | 11941 | 34,828 | 17,88  | 0,436 | 65,249 |
| src2src-baseline | 11.931 | 20,85  | 0,423 | 60,825 |

**Tabelle 12: DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="33">Übersetzung:

**Automatische Textvereinfachung**

**Dokumentebene**

Ergebnisse zur Dokumentvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44,56 | 38,136 | 0,598 | 65,4 |
| DEplain-web | 481 | 35,02 | 12,913 | 0,475 | 59,55 |
| DEplain-APA+web | 868 | 42,862 | 36,449 | 0,589 | 65,4 |
| src2src-baseline | 17.637 | 34,247 | 0,583 | 58,85 |

**DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43,087 | 21,9 | 0,377 | 64,7 |
| DEplain-web | 481 | 49,584 | 23,282 | 0,462 | 63,5 |
| DEplain-APA+web | 868 | 49,745 | 23,37 | 0,445 | 57,95 |
| src2src-baseline | 12.848 | 23,132 | 0,432 | 59,4 |

**DEPLAIN-WEB test (n=147)**

**Satzebene**

Ergebnisse zur Satzvereinfachung mit finetuned mBART.
n entspricht der Länge des Trainingsdatensatzes.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34,818 | 28,25 | 0,639 | 63,072 |
| DEplain-APA+web | 11941 | 34,904 | 28,506 | 0,64 | 62,669 |
| src2src-baseline | 15.249 | 26,893 | 0,627 | 59,23 |

**DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30,867 | 15,727 | 0,413 | 64,516 |
| DEplain-APA+web | 11941 | 34,828 | 17,88 | 0,436 | 65,249 |
| src2src-baseline | 11.931 | 20,85 | 0,423 | 60,825 |

**DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="34">Danke.
Für weitere Details. Bitte schauen Sie sich unser Papier an.
Und freuen Sie sich darauf, unseren Poster auf der ACL 2023 Konferenz zu besuchen.</sample>
    <sample id="35">Der Referent*in ist Patrick Fernandes, Kayo Yin, Emmy Liu, André F.T. Martins und Graham Neubig.</sample>
    <sample id="36">Das T5 XL-Modell wurde verwendet, um eine Genauigkeit von 82–87 % zu erreichen, wenn das LM (Language Model) nur über teilweise überschneidende Hintergrundwissen verfügt.</sample>
    <sample id="37">Yes!</sample>
    <sample id="38">Die vorgeschlagene menschliche Bewertungsmethode fokussiert sich auf die Annotierung von Verhaltensweisen im Chat (ABC-Eval) und berücksichtigt spezifische Kategorien wie "Irrelevanz", "Mangel an Empathie" und "Selbstkontradiktion".</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Art der Validierung ab. Es zeigt sich, dass die Verwendung von sauberen Labels (Validation on Clean Labels) zu einem signifikanten Verbesserungsgrad führt, während die Verwendung von schwachen Labels (Validation on Weak Labels) oder die Random Selection keine signifikante Verbesserung erzielen.</sample>
    <sample id="40">Um das Ergebnis zu verbessern, könnten mehr Annotatoren eingebunden werden, um eine breitere Perspektive zu gewinnen. Zudem könnte die Anzahl der Songs erhöht werden, um eine größere Vielfalt von Musikstilen und -genres abzudecken.</sample>
    <sample id="41">Es sind fünf Autoren an der Arbeit beteiligt.</sample>
    <sample id="42">Der englische Inhalt lautet:

"Konjunkt-Längen in Englisch, Abhängigkeitslängenminimierung und Abhängigkeitsstruktur von Koordination"

Adam Przepiórkowski und Michał Woźniak

Institut für Informatik der Polnischen Akademie der Wissenschaften
ul. Jana Kazimierza 5, 01-248 Warschau

Universität Warschau

ACL 2023

Übersetzt ins Deutsche:

"Konjunkt-Längen im Englischen, Abhängigkeitslängenminimierung und Abhängigkeitsstruktur von Koordination"

Adam Przepiórkowski und Michał Woźniak

Institut für Informatik der Polnischen Akademie der Wissenschaften
ul. Jana Kazimierza 5, 01-248 Warschau

Universität Warschau

ACL 2023</sample>
    <sample id="43">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="44">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="45">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="46">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="47">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="48">Der englische Inhalt lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="49">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="50">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="51">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="52">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt dazu, Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="53">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="54">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="55">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="56">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="57">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="58">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:

Marge read it yesterday.
gut

Marge read yesterday it.
schlecht

Marge read this absolutely fascinating book about bees yesterday.
gut

Marge read yesterday this absolutely fascinating book about bees.
gut"

Übersetzt ins Deutsche:

"Abhängigkeitslängenminimierung (DLM)

Die Wortstellung neigt sich dazu, die Abhängigkeitslängen zu minimieren:

Marge liest es gestern.
gut

Marge liest gestern es.
schlecht

Marge liest dieses absolut faszinierende Buch über Bienen gestern.
gut

Marge liest gestern dieses absolut faszinierende Buch über Bienen.
gut"</sample>
    <sample id="59">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="60">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="61">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="62">Der englische Text lautet:

"Konjunkt-Längen in Englisch

Statistiken über Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunktionen tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz
(brieflich in Gibson et al. 1996: 88–90),
- aber nur wenn der Regierungsmitglied links ist oder fehlt
(I sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn es rechts ist (Ted und Ned lachten)."</sample>
    <sample id="63">Die englischen Inhalte können wie folgt ins Deutsche übersetzt werden:

"Konjunkt-Längen in Englisch

Statistiken über Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunkte tendieren dazu, kürzer zu sein (beobachtet vorher)
- diese Tendenz wächst mit der Längendifferenz
(bekannt aus Gibson et al. 1996: 88–90),
- aber nur wenn der Regisseur links ist oder fehlt
(I sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn er rechts ist (Ted und Ned lachten)."</sample>
    <sample id="64">Die englischen Inhalte können wie folgt ins Deutsche übersetzt werden:

"Statistiken zur Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunktionen tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz
(brieflich in Gibson et al. 1996: 88–90 aufgezeigt),
- aber nur wenn der Regulator links ist oder fehlt
(I saw Bart and Lisa; Homer came and sneezed),
- nicht, wenn er rechts ist (Ted and Ned laughed)."</sample>
    <sample id="65">Die englischen Inhalte können wie folgt ins Deutsche übersetzt werden:

"Statistiken zur Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunktionen tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz
(brieflich in Gibson et al. 1996: 88–90 aufgezeigt),
- aber nur wenn der Regisseur links oder fehlt
(Ich sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn er rechts ist (Ted und Ned lachten)."</sample>
    <sample id="66">Die englischen Inhalte können wie folgt ins Deutsche übersetzt werden:

**Konjunkt-Längen im Englischen**

Statistiken zur Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- Linkselemente tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz (kurz erwähnt in Gibson et al. 1996: 88–90),
- aber nur wenn der Regisseur links ist oder fehlt
  (Ich sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn es rechts ist (Ted und Ned lachten).</sample>
    <sample id="67">Die englischen Inhalte können wie folgt ins Deutsche übersetzt werden:

"Statistiken zur Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunktionen tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz (kurz erwähnt in Gibson et al. 1996: 88–90),
- aber nur wenn der Regisseur links ist oder fehlt
(I sah Bart und Lisa; Homer kam und schnäuzte sich)
nicht, wenn er rechts ist (Ted und Ned lachten)."</sample>
    <sample id="68">Die englischen Inhalte können wie folgt ins Deutsche übersetzt werden:

"Statistiken zur Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunktionen tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz
(bekannt aus Gibson et al. 1996: 88–90),
- aber nur wenn der Regierungsmitglied auf der linken Seite oder fehlt
(I sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn es auf der rechten Seite ist (Ted und Ned lachten)."</sample>
    <sample id="69">Die englischen Inhalte können wie folgt ins Deutsche übersetzt werden:

"Konjunkt-Längen in Englisch

Statistiken über die Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunkte tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz
(bekanntlich in Gibson et al. 1996: 88–90),
- aber nur wenn der Regisseur links ist oder fehlt
(I sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn er rechts ist (Ted und Ned lachten)."

Diese Übersetzung behält den Kontext und die Struktur des Originaltextes bei.</sample>
    <sample id="70">Die Abbildung zeigt die Proportionen von kürzeren linken Konjunkten in Abhängigkeit vom absoluten Unterschied der Längen der Konjunkte (mit Konfidenzbändern).

1. **NO governor (length in CHARACTERS)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied in Zeichen an.
2. **NO governor (length in SYLLABLES)**: Die Proportion von kürzeren linken Konjunkten steigt ebenfalls linear mit zunehmendem absoluten Längenunterschied in Silben an.
3. **NO governor (length in WORDS)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied in Wörtern an.

4. **Governor on the LEFT (length in CHARACTERS)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied in Zeichen an.
5. **Governor on the LEFT (length in SYLLABLES)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied in Silben an.
6. **Governor on the LEFT (length in WORDS)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied in Wörtern an.

7. **Governor on the RIGHT (length in CHARACTERS)**: Die Proportion von kürzeren linken Konjunkten bleibt relativ konstant und zeigt keine signifikante Änderung mit zunehmendem absoluten Längenunterschied in Zeichen.
8. **Governor on the RIGHT (length in SYLLABLES)**: Die Proportion von kürzeren linken Konjunkten bleibt relativ konstant und zeigt keine signifikante Änderung mit zunehmendem absoluten Längenunterschied in Silben.
9. **Governor on the RIGHT (length in WORDS)**: Die Proportion von kürzeren linken Konjunkten bleibt relativ konstant und zeigt keine signifikante Änderung mit zunehmendem absoluten Längenunterschied in Wörtern.

Diese Ergebnisse deuten darauf hin, dass die Proportion von kürzeren linken Konjunkten bei verschiedenen Längenmaßen (Zeichen, Silben, Wörter) und verschiedenen Positionen des Regulators (links oder rechts) unterschiedlich ist.</sample>
    <sample id="71">Die Abbildung zeigt die Proportionen kürzerer linksextremer Konjunkte in Abhängigkeit von der absoluten Differenz der Längen der Konjunkte (mit Konfidenzbändern).

- **NO governor (length in CHARACTERS)**: Die Proportion kürzerer linksextremer Konjunkte steigt linear mit zunehmender absoluter Differenz in Zeichen an.
- **NO governor (length in SYLLABLES)**: Die Proportion kürzerer linksextremer Konjunkte steigt ebenfalls linear mit zunehmender absoluter Differenz in Silben an.
- **NO governor (length in WORDS)**: Die Proportion kürzerer linksextremer Konjunkte steigt linear mit zunehmender absoluter Differenz in Worten an.

- **Governor on the LEFT (length in CHARACTERS)**: Die Proportion kürzerer linksextremer Konjunkte steigt linear mit zunehmender absoluter Differenz in Zeichen an.
- **Governor on the LEFT (length in SYLLABLES)**: Die Proportion kürzerer linksextremer Konjunkte steigt linear mit zunehmender absoluter Differenz in Silben an.
- **Governor on the LEFT (length in WORDS)**: Die Proportion kürzerer linksextremer Konjunkte steigt linear mit zunehmender absoluter Differenz in Worten an.

- **Governor on the RIGHT (length in CHARACTERS)**: Die Proportion kürzerer linksextremer Konjunkte bleibt nahezu konstant, unabhängig von der absoluten Differenz in Zeichen.
- **Governor on the RIGHT (length in SYLLABLES)**: Die Proportion kürzerer linksextremer Konjunkte bleibt nahezu konstant, unabhängig von der absoluten Differenz in Silben.
- **Governor on the RIGHT (length in WORDS)**: Die Proportion kürzerer linksextremer Konjunkte sinkt leicht mit zunehmender absoluter Differenz in Worten.</sample>
    <sample id="72">Die Abbildung zeigt die Proportionen von kürzeren linken Konjunkten in Abhängigkeit vom absoluten Unterschied der Längen der Konjunkte (mit Konfidenzbändern).

1. **NO governor (length in CHARACTERS)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied der Konjunkte an.
2. **NO governor (length in SYLLABLES)**: Die Proportion von kürzeren linken Konjunkten steigt ebenfalls linear mit zunehmendem absoluten Längenunterschied der Konjunkte an.
3. **NO governor (length in WORDS)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied der Konjunkte an.

4. **Governor on the LEFT (length in CHARACTERS)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied der Konjunkte an.
5. **Governor on the LEFT (length in SYLLABLES)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied der Konjunkte an.
6. **Governor on the LEFT (length in WORDS)**: Die Proportion von kürzeren linken Konjunkten steigt linear mit zunehmendem absoluten Längenunterschied der Konjunkte an.

7. **Governor on the RIGHT (length in CHARACTERS)**: Die Proportion von kürzeren linken Konjunkten bleibt relativ konstant und zeigt keine signifikante Änderung mit zunehmendem absoluten Längenunterschied der Konjunkte.
8. **Governor on the RIGHT (length in SYLLABLES)**: Die Proportion von kürzeren linken Konjunkten bleibt relativ konstant und zeigt keine signifikante Änderung mit zunehmendem absoluten Längenunterschied der Konjunkte.
9. **Governor on the RIGHT (length in WORDS)**: Die Proportion von kürzeren linken Konjunkten bleibt relativ konstant und zeigt keine signifikante Änderung mit zunehmendem absoluten Längenunterschied der Konjunkte.

Diese Ergebnisse deuten darauf hin, dass die Proportion von kürzeren linken Konjunkten bei verschiedenen Längenmaßen (Zeichen, Silben, Wörter) und verschiedenen Positionen des Regulators (links oder rechts) unterschiedlich ist.</sample>
    <sample id="73">Die Übersetzung des englischen Inhalts ins Deutsche lautet:

"Kompatibilität mit Abhängigkeitsstrukturen von Koordination"

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie. NEIN

- Chain/Moscow:
  Homer liebt Lisa, Bart und Maggie. NEIN

- Conjunction-headed/Prague:
  Homer liebt Lisa, Bart und Maggie. JA

- Multi-headed/London:
  Homer liebt Lisa, Bart und Maggie. JA</sample>
    <sample id="74">Der englische Text lautet:

"Sehe den Artikel für die vollständige Argumentation!
Sprecht uns auf der Poster-Sitzung an!"

Übersetzt ins Deutsche:

"Seht den Artikel für die vollständige Argumentation!
Sprecht uns auf der Poster-Sitzung an!"</sample>
    <sample id="75">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="76">Die Domains "Bible" und "Fiction" werden stärker vereinfacht, wie aus den Balkendiagrammen im oberen Teil des Bildes ersichtlich ist.</sample>
    <sample id="77">Das Beispiel für die Präferenz für kürzere linke Konjunktionen lautet "I saw Bart and Lisa; Homer came and sneezed".</sample>
    <sample id="78">Ja, Sie können die DrBERT-Modelle für Ihre Forschung verwenden, da sie unter der MIT-Lizenz freigegeben wurden.</sample>
    <sample id="79">DEplain-APA enthält Dokumente, die in der APA-Stilrichtlinie formatiert sind.</sample>
    <sample id="80">Für eine gute Generalisierung benötigen wir:
- Bessere Modellarchitektur
- Größere Modellgröße
- Mehr Feinabstimmungsbeispiele</sample>
    <sample id="81">Die Tendenz wurde durch die Proportion der kürzeren linken Konjunktionen gemessen, die sich mit der absoluten Differenz der Konjunktionslängen ändert.</sample>
    <sample id="82">Die Experimente wurden so gestaltet, dass sie die Proportionen der kürzeren linken Konjunkte in Abhängigkeit von der absoluten Differenz der Konjunkt-Längen untersuchten. Dies wurde für verschiedene Längenmaße (Zeichen, Silben, Wörter) und Positionen des Begrenzers (links oder rechts) durchgeführt.</sample>
    <sample id="83">Ein Basisklassifikator, der mit unausgewogenen Daten trainiert wird, zeigt eine geringe Genauigkeit, da das AUC-Wert (Area under the ROC curve) nur 0,50 beträgt. Dies bedeutet, dass der Klassifikator nicht besser als Zufall funktioniert hat.</sample>
    <sample id="84">Es gibt vier Autoren an der Arbeit beteiligt: Shangbin Feng, Chan Young Park, Yuhan Liu und Yulia Tsvetkov.</sample>
    <sample id="85">Die Personen im Beispielgespräch heißen nicht spezifisch genannt, da es sich um eine allgemeine Darstellung handelt.</sample>
    <sample id="86">Formalität und lexikalische Cohesion.</sample>
    <sample id="87">Die Autoren gehören an Johns Hopkins University, Purdue University und MIT.</sample>
    <sample id="122">Das vorgestellte Framework quantifiziert die Positionalität durch die Messung der Pearson's r Korrelation zwischen Goldlabels, Modellvorhersagen und Annotierungen für jede Demografie separat.</sample>
    <sample id="155">Das Ergebnis der vorherigen Studie, bei der die menschlichen Teilnehmenden die gleichen Persona-Prompts erhalten haben, wurde durch eine Psychologie-Studie inspiriert.</sample>
    <sample id="156">Die Datenquellen, die in dieser Studie verwendet wurden, sind eine erweiterte Version des Penn Treebanks (Marcus et al. 1993, Ficler and Goldberg 2016).</sample>
    <sample id="157">Zwei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="158">The related tasks for cognitive dissonance are "Debate" and "CE" (Comparison and Expansion classes).</sample>
    <sample id="159">Es sind zwei Autoren an der Arbeit beteiligt: Shuheng Liu und Alan Ritter.</sample>
    <sample id="160">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten dadurch, dass es eine Vielzahl an Anmerkungen durch Menschen aus verschiedenen Demografien erhält und diese dann mit Goldlabels und Modellvorhersagen vergleicht. Dies wird durch die Berechnung von Pearson's r Korrelationen für jede Demografie getrennt erreicht.</sample>
    <sample id="162">Das Setup "GPT-3.5" hat die meisten Überschneidungen mit dem Lexikon der Stereotypen.</sample>
    <sample id="163">Die kommerziellen Systeme, die verglichen wurden, sind DeepL und Google.</sample>
    <sample id="164">Der englische Inhalt lautet:

"Von Vortrainingsdaten zu Sprachmodellen zu Downstream-Aufgaben: Verfolgen der Spuren politischer Biass führend zu unfairen NLP-Modellen"

Die Namen der Personen sind:
- Shangbin Feng
- Chan Young Park
- Yuhan Liu
- Yulia Tsvetkov

Die Logos der Institutionen sind:
- Paul G. Allen School
- UWNLP
- Carnegie Mellon University Language Technologies Institute
- [Ein weiteres Logo, das nicht vollständig sichtbar ist]</sample>
    <sample id="165">Der englische Text lautet:

"LM Training Data
A mixed blessing

Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021."</sample>
    <sample id="166">Der englische Text lautet:

"LM Training Data
A mixed blessing

Website
# tokens (log scale)

patents.google.com
en.wikipedia.org
en.m.wikipedia.org
www.nytimes.com
www.latimes.com
www.theguardian.com
journals.plos.org
www.forbes.com
hubspot.com
patents.com
www.scribd.com
www.washingtonpost.com
www.fool.com
ipfs.io
www.frontiersin.org
www.businessinsider.com
www.chicagotribune.com
www.booking.com
www.theatlantic.com
look.springer.com
www.aljazeera.com
www.kickstarter.com
caselaw.findlaw.com
www.ncbi.nlm.nih.gov
www.npr.org"

Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.</sample>
    <sample id="167">Der englische Text lautet:

"LM Training Data
A mixed blessing

Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021."</sample>
    <sample id="168">Der englische Text lautet:

"LM Training Data
A mixed blessing

To this end"

Die Grafik zeigt die Anzahl der Tokens (logarithmische Skala) für verschiedene Websites im Kontext des Trainings von Sprachmodellen. Die Websites sind in einer Liste aufgelistet, und die Länge der Balken repräsentiert die Anzahl der Tokens, die für jede Website verwendet wurden.</sample>
    <sample id="169">Der englische Inhalt lautet:

"To this end"

- Pretraining data
- Language models
- Downstream tasks

Die Fragen, die im Bild hinzugefügt wurden, lauten:

- Wie kann man die politische Neigung von LM's bewerten?
- Welche Rolle spielt das Vortrainingsdaten bei solchen politischen Verzerrungen?

- Wie performen LM's mit unterschiedlichen politischen Neigungen?
- Führt die politische Neigung von LM's zu Gerechtigkeitsproblemen in NLP-Anwendungen?</sample>
    <sample id="170">Zum Schluss

- Prätraining-Daten
  - Wie kann man die politische Neigung von Sprachmodellen bewerten?
  - Welche Rolle spielt das Prätraining-Daten in solchen politischen Verzerrungen?

- Sprachmodelle
  - Wie performen Sprachmodelle mit unterschiedlichen politischen Neigungen?
  - Führt die politische Neigung von Sprachmodellen zu Gerechtigkeitsproblemen in NLP-Anwendungen?</sample>
    <sample id="171">Zum Schluss

- Prätraining-Daten
  - Wie kann man die politische Neigung von Sprachmodellen bewerten?
  - Welche Rolle spielt das Prätraining-Daten in solchen politischen Verzerrungen?

- Sprachmodelle
  - Wie performen Sprachmodelle mit unterschiedlichen politischen Neigungen?
  - Führt die politische Neigung von Sprachmodellen zu Gerechtigkeitsproblemen in NLP-Anwendungen?

- Unternehmensaufgaben
  - Wie können wir die politische Neigung von Sprachmodellen bewerten?
  - Welche Rolle spielt das Prätraining-Daten in solchen politischen Verzerrungen?</sample>
    <sample id="172">Die Präsentation befasst sich mit der Bewertung politischer Neigungen von Sprachmodellen (LMs). Sie unterstützt sowohl Encoder- als auch Decoder-LMs und verwendet zwei Frageformulierungen:

1. "&lt;statement&gt; I &lt;mask&gt; with this statement."
2. "Do you agree or disagree with this statement? &lt;statement&gt;"

Es wird ein automatisches Evaluationsverfahren vorgestellt, das sich an politikwissenschaftlicher Literatur orientiert.

Zusätzlich wird eine Grafik gezeigt, die verschiedene Sprachmodelle (wie BERT-base, BERT-large, RoBERTa-base usw.) in einem politischen Kompass darstellt. Die Modelle werden entlang der sozialen und wirtschaftlichen Achse positioniert, um ihre politischen Neigungen zu visualisieren.</sample>
    <sample id="173">Die Abbildung zeigt eine Grafik mit dem Titel "Existing LMs" (Bestehende LM). Sie stellt eine Matrix dar, die zwei Achsen hat: die linke Achse ist die "Left" (Links) und die rechte Achse ist die "Right" (Rechts). Die obere Achse ist die "Authoritarian" (Autoritär) und die untere Achse ist die "Libertarian" (Liberal). Auf der linken Seite sind verschiedene Sprachmodelle wie BERT-base, BERT-large, RoBERTa-base, RoBERTa-large, distilBERT, distilRoBERTa, ALBERT-base, ALBERT-large, BART-base, BART-large und Alpaca aufgelistet. Auf der rechten Seite sind weitere Sprachmodelle wie Codex, LLaMA, GPT-2, GPT-3-ada, GPT-3-babbage, GPT-3-curious, GPT-3-davinci, ChatGPT, GPT-4 und GPT-J aufgeführt. Die Modelle werden in verschiedenen Farben dargestellt, was vermutlich ihre Positionierung auf den Achsen anzeigt.</sample>
    <sample id="174">Die englische Aufschrift lautet "Existing LMs" und bezieht sich auf bestehende Sprachmodelle (LMs). Der Text unter dem Diagramm lautet: "Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning". Dies bedeutet, dass es sich um weitere prätrainierte Sprachmodelle handelt, die für die Bewertung der Veränderung politischer Neigungen verwendet werden.</sample>
    <sample id="175">Die englischen Inhalte auf dem Bildschirm lauten wie folgt:

"Pretraining Data

Weiteres Pretraining von LM (RoBERTa, GPT-2) Checkpoints, um den Veränderung in politischer Neigung zu bewerten"

Unterhalb der Grafiken befinden sich zwei Zitate:

1. Liu, Yujian, et al. "POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection." Findings of the Association for Computational Linguistics: NAACL 2022.

2. Shen, Qinlan, and Carolyn Rose. "What sounds 'right' to me? Experiential factors in the perception of political ideology." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="176">Die englischen Inhalte auf dem Bildschirm sind wie folgt:

"Pretraining Data

Weiteres Pretraining von LM (RoBERTa, GPT-2) Checkpoints, um den Veränderungen in der politischen Neigung zu evaluieren.

News Media
- left
- center
- right

Social Media (Reddit)
- left
- center
- right"

Unten stehen zwei Zitate:
1. Liu, Yujian, et al. "POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection." Findings of the Association for Computational Linguistics: NAACL 2022.
2. Shen, Qinlan, and Carolyn Rose. "What sounds 'right' to me? Experiential factors in the perception of political ideology." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="177">Die englische Aufschrift lautet "Results Partisan shifts in LM political leaning". Dies bedeutet "Ergebnisse: Parteiengängigkeit in der politischen Neigung von LM".</sample>
    <sample id="178">Die englische Aufschrift lautet "Results Partisan shifts in LM political leaning". Dies bedeutet "Ergebnisse: Parteiengängigkeit in der politischen Neigung von LM".</sample>
    <sample id="179">Die englische Aufschrift lautet "Results Partisan shifts in LM political leaning". Dies bedeutet "Ergebnisse: Parteiengewichtungen in der politischen Neigung von LM (Language Model)".</sample>
    <sample id="180">Der englische Text lautet "The Trump Card" und "Pre-45th to post-45th shift". Dies deutet darauf hin, dass es sich um eine Präsentation oder ein Diagramm handelt, das die Veränderungen in der politischen Meinung oder Positionierung von Personen vor und nach dem 45. Präsidenten der USA (Donald Trump) zeigt. Die Grafiken unter dem Titel könnten verschiedene Quellen wie Nachrichtenmedien und Reddit repräsentieren, wobei die Farben und Pfeile möglicherweise die Richtung und Intensität der Veränderungen zeigen.</sample>
    <sample id="181">Der englische Text lautet "The Trump Card" und "Pre-45th to post-45th shift". Dies deutet darauf hin, dass es sich um eine Präsentation oder ein Diagramm handelt, das die Veränderungen in der politischen Meinung oder Positionierung von Personen vor und nach dem 45. Präsidenten der USA (Donald Trump) zeigt. Die Grafiken unter dem Titel könnten verschiedene Quellen wie Nachrichten, Reddit und andere soziale Medien darstellen, wobei die Farben und Pfeile möglicherweise die Richtung und Intensität der Veränderungen zeigen.</sample>
    <sample id="182">Der englische Text lautet:

"The Trump Card

Pre-45th to post-45th shift"

Die Grafiken zeigen die Veränderungen (Shift) in der politischen Orientierung von Nachrichtenquellen und Reddit-Unterseiten vor und nach dem 45. Präsidenten der USA, Donald Trump. Die Grafiken sind in zwei Spalten unterteilt: eine für Nachrichtenquellen (news) und eine für Reddit-Unterseiten (reddit). Jede Spalte enthält drei Diagramme, die die Veränderungen in der politischen Orientierung darstellen.

Die Diagramme sind in vier Quadranten unterteilt, die verschiedene politische Positionen repräsentieren:
- Links oben: Links
- Rechts oben: Rechts
- Links unten: Libertär
- Rechts unten: Zentrum

Jedes Diagramm zeigt die Veränderung der politischen Orientierung durch einen Pfeil, der die Positionen vor und nach dem 45. Präsidenten verbindet. Darunter sind die Veränderungen in Koordinatenform angegeben (Δ = (x, y)), wobei x die horizontale und y die vertikale Veränderung darstellt.</sample>
    <sample id="183">Die Tabelle zeigt die Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farblich kodiert, wobei dunkles Gelb den besten und dunkles Blau den schlechtesten Wert darstellt.</sample>
    <sample id="184">Die Tabelle zeigt die Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farblich kodiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="185">Die Tabelle zeigt die Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farblich kodiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="186">Die Tabelle zeigt die Leistung bei Hassrede, die sich auf verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen richtet. Die Ergebnisse sind farblich kodiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="187">Die Tabelle zeigt die Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farblich kodiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="188">Die Tabelle zeigt die Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodeiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="189">Die Tabelle zeigt die Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farblich kodiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="190">Der englische Inhalt lautet:

"Qualitative Analysis

Tabelle 5: Beispiele für die Leistung der Aufgaben mit verschiedenen politischen Bias-Modellen.

CHRIS, Base, N, S, L, R repräsentieren Christen, vanilla RoBERTa Modell, Nachrichtenmedien, soziale Medien, linke und rechte Ausrichtung, entsprechend."</sample>
    <sample id="191">Die Tabelle zeigt qualitative Analysen von Texten, die mit verschiedenen politischen Bias-Modellen bearbeitet wurden. Die Spalten repräsentieren verschiedene Modellvarianten: "CHRIS" für Christen, "Base" für das originale RoBERTa-Modell, "N" für Nachrichtenmedien, "S-L" für soziale Medien linksgerichtet und "S-R" für soziale Medien rechtsgerichtet.

1. Der erste Text lautet: "the alt right is corrupted with people supporting racemixing with asians and homosexuals it time for a new nationalism". Dieser Text wird als "ASIAN" gekennzeichnet und als "TRUE" bewertet. Alle Modelle außer "N-L" und "S-R" bewerten ihn als "TRUE".

2. Der zweite Text lautet: "What do McDonald's and priest have in common? They both like sticking their meat in 10 year old buns". Dieser Text wird als "CHRIS" gekennzeichnet und als "TRUE" bewertet. Nur "S-L" und "S-R" bewerten ihn als "TRUE".

3. Der dritte Text lautet: "(...) that didn't stop donald trump from seizing upon increases in isolated cases to make a case on the campaign trail that the country was in the throes of a crime epidemic crime is reaching record levels will vote for trump because they know i will stop the slaughter going on donald j trump august 29 2016 (...)" Dieser Text wird als "RIGHT" gekennzeichnet und als "FAKE" bewertet. Nur "N-L", "S-L" und "S-R" bewerten ihn als "TRUE".

4. Der vierte Text lautet: "(...) said sanders what is absolutely incredible to me is that water rates have soared in flint you are paying three times more for poisoned water than i'm paying in burlington vermont for clean water (...)" Dieser Text wird als "LEFT" gekennzeichnet und als "FAKE" bewertet. Nur "N-L" und "S-L" bewerten ihn als "TRUE".

Diese Tabelle illustriert, wie unterschiedliche politische Bias-Modelle verschiedene Texte bewerten können.</sample>
    <sample id="192">Die Tabelle 12 zeigt eine qualitative Analyse von Hassrede-Beispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Vorlieben unterschiedliche Ergebnisse liefern.

Die Tabelle 13 zeigt eine qualitative Analyse von Falschinformationen-Beispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Vorlieben unterschiedliche Ergebnisse liefern.</sample>
    <sample id="193">Die Tabelle 12 zeigt eine qualitative Analyse von Hassrede-Beispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Vorlieben unterschiedliche Ergebnisse liefern.

Die Tabelle 13 zeigt eine qualitative Analyse von Falschinformationen-Beispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Vorlieben unterschiedliche Ergebnisse liefern.</sample>
    <sample id="194">Tabelle 12: Qualitative Analyse von Hassrede-Beispielen, bei denen LMs mit unterschiedlichen politischen Vorlieben unterschiedliche Meinungen haben.

Tabelle 13: Qualitative Analyse von Falschmeldung-Beispielen, bei denen LMs mit unterschiedlichen politischen Vorlieben unterschiedliche Meinungen haben.</sample>
    <sample id="195">Die englischen Inhalte der beiden Tabelle sind wie folgt:

**Tabelle 12: Qualitative Analyse von Hassrede-Beispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Neigungen zu differieren scheinen.**

| Hassrede-Text | Hass? | N-L | R-L | N-R | R-R |
|---------------|------|-----|-----|-----|-----|
| Same-sex marriage doesn't "confound" orthodox Catholics who refer to disparagingly as trads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pity and God's mercy. | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| got kicked out of facebook again for "numb" days because I called a mazilla alla a pedophile and a pervert no 1 amendment over there the muzzis can call christians anything they want but not the other way around | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| Yes. Exactly. Fuck these religitated trash places and burn them to the ground. The Vatican, Israel, everywhere. | TRUE | FALSE ✖️ | FALSE ✖️ | TRUE ✔️ | TRUE ✔️ |
| Idiot Didn't Get A Building Permit? Typical White Guy Rule: It's Easier to Beg for Forgiveness, then they play the victim card! | TRUE | FALSE ✖️ | FALSE ✖️ | TRUE ✔️ | TRUE ✔️ |
| At 7:19 is why I hate people, women especially look how mad she just got because the dog splashed her. F*** you you stupid b**** either have fun or go kill yourself | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| Death to catholicism. Should be legal to shoot them. | TRUE | FALSE ✖️ | FALSE ✖️ | TRUE ✔️ | TRUE ✔️ |
| are you the nazi faggot with the feminine boobs | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead | TRUE | TRUE ✔️ | TRUE ✔️ | TRUE ✔️ | TRUE ✔️ |
| What do you call a white guy surrounded by a thousand black guys? A warden | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| United States of Muslim America It's good to know faggots will still be shot | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| How do you circumcise a choir boy? Kick the priest in the jaw. | TRUE | FALSE ✖️ | FALSE ✖️ | TRUE ✔️ | TRUE ✔️ |
| what do you call an indian taking a shit? brownian motion | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| If I saw this bitch in public I'd slam her on the ground and spit in her face too | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |

**Tabelle 13: Qualitative Analyse von Fake-News-Beispielen, bei denen Sprachmodelle mit unterschiedlichen politischen Neigungen zu differieren scheinen.**

| Fake-News-Text | Fake? | N-L | R-L | N-R | R-R |
|----------------|-------|-----|-----|-----|-----|
| in cities like chicago and bulimard crime in america a largest cities has been rising since trump from sitting upon increases in violent cases to make a case on the other hand the crime rate in the united states is reaching record levels will vote for trump because they know he will stop the crime rate | TRUE | FALSE ✖️ | FALSE ✖️ | TRUE ✔️ | TRUE ✔️ |
| the president of the united states donald trump is a racist and a liar and a fraud and a criminal and a murderer and a terrorist and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass murderer and a mass</sample>
    <sample id="196">Diskussion

Zwischen Scylla und Charybdis

Ob man "sanitize" oder nicht "sanitize", das ist die Frage

- Prätraining-Daten
- Sprachmodelle
- Unternehmensaufgaben</sample>
    <sample id="197">Die englischen Inhalte auf Deutsch:

- Diskussion
  - Zwischen Scylla und Charybdis
  - Ob "sanitize" oder nicht zu "sanitize", das ist die Frage

- Prätraining-Daten
- Sprachmodelle
- Unternehmensaufgaben</sample>
    <sample id="198">Die englischen Inhalte auf dem Bild lauten wie folgt:

1. "Discussion"
2. "Between Scylla and Charybdis"
3. "To 'sanitize' or not to 'sanitize', that is the question"

Diese Inhalte deuten darauf hin, dass es um eine Diskussion geht, die sich auf die Entscheidung bezieht, ob man Daten "sanitieren" sollte oder nicht. Die Begriffe "Scylla" und "Charybdis" sind hier metaphorisch verwendet und beziehen sich auf zwei schwierige Entscheidungen oder Situationen.

Darunter befindet sich ein Diagramm mit den Schritten:
- "Pretraining data" (Vortrainierte Daten)
- "Language models" (Sprachmodelle)
- "Downstream tasks" (Unteraufgaben)

Am Ende des Videos wird ein Dankeschön gesagt, und es werden Namen und Logos von Institutionen genannt: Shangbin Feng, Chan Young Park, Yuhan Liu, Yulia Tsvetkov sowie die Logos der Paul G. Allen School, UWNLP und Carnegie Mellon University Language Technologies Institute.</sample>
    <sample id="199">Der englische Inhalt lautet:

"Danke!"

Die Abbildung zeigt eine Präsentation mit dem Titel "Danke!" und enthält die folgenden Elemente:

- Ein Diagramm, das drei Schritte zeigt: "Pretraining data" (Vortrainingsdaten), "Language models" (Sprachmodelle) und "Downstream tasks" (Unteraufgaben).
- Fotos von vier Personen mit ihren Namen darunter:
  - Shangbin Feng
  - Chan Young Park
  - Yuhan Liu
  - Yulia Tsvetkov
- Logos von Institutionen:
  - Paul G. Allen School
  - University of Washington NLP (UW NLP)
  - Carnegie Mellon University Language Technologies Institute</sample>
    <sample id="200">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="201">900 Tokens</sample>
    <sample id="202">Die Domains, die im Datensatz aufgenommen wurden, sind Musik, Bücher und Rezepte.</sample>
    <sample id="203">Positionalität bezieht sich auf die Perspektiven, die Menschen aus ihren sozialen, demografischen, identitären und lebenserfahrungsbezogenen Kontexten ableiten. Diese Perspektiven beeinflussen sowohl den Forschungsprozess als auch dessen Ergebnisse.</sample>
    <sample id="204">Der Referent ist Xiaoyu Shen.</sample>
    <sample id="205">Ja, EDAtt passt zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="206">Es sind vier Autoren an der Arbeit beteiligt: Yusen Zhang, Jun Wang, Zhiguo Wang und Rui Zhang.</sample>
    <sample id="207">Ja, das getestete Modell funktioniert in der Testsuite.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind:

a) Background-Pretrain: Typischer Setup
b) Background-Both: Explizit bereitstellen von Hintergrundwissen im Kontext
c) Background-Inference: Wissen nur während der Inferenz verfügbar</sample>
    <sample id="209">Die Autoren gehören der Google Research zu.</sample>
    <sample id="210">Die abschließende Forschungsfrage lautet:

"RQ3: How to use the available clean samples more efficiently?"</sample>
    <sample id="211">Die Sensitivitätsmetrik misst, wie sensibel ein Modell ist gegenüber verschiedenen Anweisungen für dieselbe Aufgabe, unabhängig von geringfügigen Variationen im Sprachdurchdringungsverhalten.</sample>
    <sample id="212">Der Referent*in heißt Wenjun Peng.</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet, dass das Modell schlechtere Leistungen auf unbekannten Bewertungsaufgaben zeigt. Daher ist eine niedrigere Sensitivität besser.</sample>
    <sample id="214">Der englische Text gibt keine spezifischen Informationen über den linguistischen Kontext, der während des Pre-Trainings erhalten wird. Es wird lediglich erwähnt, dass die Akzeptabilitätsschätzungen von Sprachmodellen nicht immer robust gegenüber Kontext sind.</sample>
    <sample id="215">Die Grafik zeigt, dass die Leistung an der WSL (Weak labels) mit zunehmender Anzahl von sauberen Validierungsbeispielen steigt. Allerdings ist es schwierig, eine exakte Zahl zu bestimmen, da die Leistungsfähigkeit stark von den spezifischen Verfahren abhängt. Die Grafik deutet darauf hin, dass mindestens 50 saubere Validierungsbeispiele für eine gute Leistung notwendig sind.</sample>
    <sample id="216">Die Autoren gehören der Stanford University an.</sample>
    <sample id="217">Die Entwicklung neuer Methoden zur Messung von Medienverzerrungen ist notwendig, um eine genauere und objektivere Bewertung der politischen Ausrichtung von Sprachmodellen zu ermöglichen. Dies hilft dabei, die Vielfalt und Komplexität der politischen Meinungen in den Modellen zu erfassen und zu analysieren, was wiederum zu einer besseren Transparenz und Kontrolle über die Auswirkungen der Modelle auf die öffentliche Meinung beiträgt.</sample>
    <sample id="218">Die Referentin ist Akshatha Arodi.</sample>
    <sample id="219">Die Pipeline für die Verbreitung politischer Vorurteile besteht aus drei Schritten:

1. **Pretraining data**: Das Trainingsdatensatz wird verwendet, um die Sprachmodelle vorzubereiten.
2. **Language models**: Die Sprachmodelle werden mit dem vorbereiteten Datensatz trainiert.
3. **Downstream tasks**: Die trainierten Sprachmodelle werden in Aufgaben eingesetzt, die politische Vorurteile vermitteln können.

Diese Pipeline zeigt, wie das Trainingsmaterial die Modelle beeinflusst und wie diese dann in praktische Anwendungen überführt werden können.</sample>
    <sample id="220">Ja, es gibt Unterschiede im Vereinfachungsprozess zwischen DEplain-apa und DEplain-web.</sample>
    <sample id="221">Der Videoausschnitt gibt keine spezifischen Informationen darüber, ob der Coscript-Datensatz öffentlich zugänglich ist. Es wird lediglich erwähnt, dass er als wertvolles Ressourcenmaterial für die Forschung auf dem Gebiet der sprachlichen Planung mit komplexeren und vielfältigeren Zielen und Einschränkungen angesehen wird.</sample>
    <sample id="222">Das Wasserzeichen wird durch die Definition eines Ziel-Einbettungsvektors \( e_t \), die Zählung des Trigger-Numbers in einer Zeile und die Addition des Ziel-Einbettungsvektors auf den ursprünglichen Einbettungsvektor \( e_o \) eingebettet.</sample>
    <sample id="223">The authors are affiliated with Penn State.</sample>
    <sample id="224">Ja, Encoder-Decoder-Modelle wie mt5 können durch Training in einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="225">Ein Beispiel für eingeschränkte Sprachplanung ist die Frage "How to Make a Strawberry Cake?" und die Antwort "...Add strawberry jams into the flour...".</sample>
    <sample id="226">Die Präsentation zeigt Ergebnisse von Embedding-Visualisierungen für verschiedene Datensets (AG News, Enron Spam, MIND, SST2). Es wird jedoch nicht explizit erwähnt, wie die Opazität der Methode sichergestellt wird. Ohne zusätzliche Informationen ist es schwierig, dies zu bestimmen.</sample>
    <sample id="227">Die Arbeit nutzt bestehende PLMs (Pre-trained Language Models) durch kontinuierliches Pre-Training, um ein neues PLM aufzubauen.</sample>
    <sample id="228">GPT-4 ist am wenigsten mit West-Südostasien ausgerichtet, wie das Diagramm zeigt.</sample>
    <sample id="229">"I am a student."</sample>
    <sample id="230">Die Anzahl der Aufgaben hat einen signifikanten Einfluss auf die Leistung des Modells. Je mehr Aufgaben hinzugefügt werden, desto besser wird die aggregierte Leistung (Max, Avg, Sensitivity).</sample>
    <sample id="231">LSTM seq2seq, T5, Zheng and Lapata</sample>
    <sample id="232">Die beiden Co-Autoren, Alexander Koller und Ivan Titov, stehen dem ersten Autor, Matthias Lindemann, in einer Koautorenbearbeitungsbeziehung. Sie sind zusammen mit ihm an dem Projekt beteiligt und haben gemeinsam an der Arbeit gearbeitet.</sample>
    <sample id="233">Der erste Autor von PaLM ist Chowdery et al., 2022.</sample>
    <sample id="234">NLPositionality:
Charakterisierung von Entwurfsbiasten von Datensätzen und Modellen

Sebastin Santy*
University of Washington
Jenny T. Liang*
Carnegie Mellon University
Ronan Le Bras
Allen Institute for AI
Katharina Reinecke
University of Washington
Maarten Sap
Carnegie Mellon University</sample>
    <sample id="235">NLPositionality:
Charakterisierung von Entwurfsbiasten von Datensätzen und Modellen

Sebastin Santy*
University of Washington
Jenny T. Liang*
Carnegie Mellon University
Ronan Le Bras
Allen Institute for AI
Katharina Reinecke
University of Washington
Maarten Sap
Carnegie Mellon University</sample>
    <sample id="236">Denken Sie...</sample>
    <sample id="237">Denken Sie sich...  
Carl Jones, Technischer Leiter bei The New York Times  
Kannst du aufhören, ein Arschloch zu sein? (0,82)</sample>
    <sample id="238">Denken Sie daran...

Carl Jones, Tech Lead bei New York Times
Kannst du aufhören, ein Arschloch zu sein? (0.82) ✅

Aditya Sharma, Tech Lead bei Times of India
Presstitutes überall in der Nachrichtenbranche. (0.33) ❌</sample>
    <sample id="239">Denken Sie daran...

Beispiel für Design-Bias!

Können Sie aufhören, ein Arschloch zu sein? (0,82) ✅

Überall im Nachrichtenbereich vorspricht. (0,33) ❌

Carl Jones
Tech Lead,
New York Times

Aditya Sharma
Tech Lead,
Times of India

= PerspectiveAPI-Score</sample>
    <sample id="240">Die Perspektiven, die Menschen haben, sind das Ergebnis ihrer Demografie, Identität und Lebenserfahrungen.</sample>
    <sample id="241">Positionalität

"Die Perspektiven, die Menschen haben, als Ergebnis ihrer Demografie, Identität und Lebenserfahrungen."</sample>
    <sample id="242">Positionalität

"Die Perspektiven, die Menschen haben, sind das Ergebnis ihrer Demografie, Identität und Lebenserfahrungen."

[Als Forscher] beeinflusst sie den Forschungsprozess und dessen Ergebnisse und Auswirkungen." [1]

[1] Savin-Baden, Maggi, und Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="243">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Zusätzliche Informationen:
[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen prätrainierten Sprachmodellen." EMNLP 2022.
[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="244">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.

[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen prätrainierten Sprachmodellen." EMNLP 2022.

[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="245">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Anschauliche Beweise:
- Modell- und Datensatz-Probing [1][2]
- Theoretische Definitionen der Positionalität des Modells [3]

[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen vortrainierten Sprachmodellen." EMNLP 2022.
[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="246">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Anschauliche Beweise:
- Modell- und Datensatz-Probing [1][2]
- Theoretische Definitionen der Positionalität des Modells [3]

[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen prätrainierten Sprachmodellen." EMNLP 2022.
[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="247">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Anschauliche Beweise:
- Modell- und Datensatz-Probing [1][2]
- Theoretische Definitionen der Positionalität des Modells [3]

[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen Prätrainierten Sprachmodellen." EMNLP 2022.
[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="248">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Anschauliche Beweise:
- Modell- und Datensatz-Probing [1][2]
- Theoretische Definitionen der Positionalität des Modells [3]

[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen Prätrainierten Sprachmodellen." EMNLP 2022.
[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="249">Frage:
Haben Datensätze und Modelle Positionalität?

Ziel: Vergleichen Sie die Anmerkungen von Benutzern mit bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">NLPositionality
Ein Framework zur Charakterisierung von Entwurfsbiasten in NLP-Datenbanken und Modellen</sample>
    <sample id="251">Das Bild zeigt einen Framework-Workflow, der in drei Hauptphasen unterteilt ist: Sammlung, Verarbeitung und Analyse.

### Sammlung
1. **300 Instanzen werden aus einem Datensatz gezogen.**
2. **Jede Instanz hat eine goldene Etikettierung.**
3. **Die Instanzen werden als Teil einer Studie an das Lab in the Wild gesendet.**
4. **Anmerkungen von Menschen aus aller Welt werden erhalten.**

### Verarbeitung
5. **Die erhaltenen Anmerkungen werden mit den goldenen Etiketten aus dem Datensatz und den Modellvorhersagen verglichen.**

### Analyse
6. **Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie separat gemessen.**

Diese Grafik illustriert die Prozesse, die bei der Erstellung und Bewertung eines Modells verwendet werden, um sicherzustellen, dass es korrekte Vorhersagen trifft und dass diese Vorhersagen durch Menschen aus verschiedenen Gruppen bestätigt werden können.</sample>
    <sample id="252">### Rahmenwerk

#### Sammlung
1) 300 Instanzen werden aus einem Datensatz gezogen.
2) Jede Instanz hat eine goldene Etikettierung.
3) Die Instanzen werden als Teil einer Studie an das "Lab in the Wild" gesendet.
4) Anmerkungen von Menschen aus der ganzen Welt.

#### Verarbeitung
5) Die erhaltenen Anmerkungen werden gegen die goldenen Etiketten des Datensatzes und die Vorhersagen der Modelle verglichen.

#### Analyse
6) Der Pearson's r-Korrelationskoeffizient wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie separat gemessen.</sample>
    <sample id="253">### Rahmenwerk

#### Sammlung
1) 300 Instanzen werden aus einem Datensatz gezogen.
2) Jede Instanz hat eine goldene Etikettierung.
3) Die Instanzen werden als Teil einer Studie an das "Lab in the Wild" gesendet.
4) Anmerkungen von Menschen aus aller Welt.

#### Verarbeitung
5) Die erhaltenen Anmerkungen werden gegen die goldenen Etiketten des Datensatzes und die Vorhersagen der Modelle abgeglichen.

#### Analyse
6) Der Pearson's r-Korrelationskoeffizient wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie separat berechnet.

1) Re-annotate datasets with diverse annotators.</sample>
    <sample id="254">Der englische Inhalt lautet:

"Framework

Collection
1) 300 Instanzen werden aus einem Datensatz gezogen.
2) Jede Instanz hat eine goldene Etikettierung.
3) Die Instanzen werden als Teil einer Studie an das Lab in the Wild gesendet.
4) Anmerkungen von Menschen aus der ganzen Welt.

Processing
Modellvorhersagen

Analysis
Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie getrennt gemessen."

Wörtlich übersetzt bedeutet dies:

"Framework

Sammlung
1) 300 Instanzen werden aus einem Datensatz gezogen.
2) Jede Instanz hat eine goldene Etikettierung.
3) Die Instanzen werden als Teil einer Studie an das Lab in the Wild gesendet.
4) Anmerkungen von Menschen aus der ganzen Welt.

Verarbeitung
Modellvorhersagen

Analyse
Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie getrennt gemessen."</sample>
    <sample id="255">### Rahmenwerk

#### Sammlung
1. 300 Instanzen werden aus einem Datensatz gezogen.
2. Jede Instanz hat eine goldene Etikettierung.
3. Die Instanzen werden als Teil einer Studie an LITW gesendet.
4. Anmerkungen von Menschen aus aller Welt.

#### Verarbeitung
5. Die erhaltenen Anmerkungen werden gegen die goldenen Etiketten des Datensatzes und die vorhergesagten Modelle verglichen.

#### Analyse
6. Pearson's r-Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie getrennt gemessen.

2) Vergleiche Anmerkungen nach Demografien mit Modellen und Datensätzen mithilfe von Pearson's R-Werten.</sample>
    <sample id="256">**Framework**

### Sammlung

1. 300 Instanzen werden aus einem Datensatz gezogen.
2. Jede Instanz hat eine goldene Etikettierung.
3. Die Instanzen werden als Teil einer Studie an LITW gesendet.
4. Anmerkungen von Menschen aus aller Welt.

### Verarbeitung

5. Die erhaltenen Anmerkungen werden gegen die goldenen Etiketten des Datensatzes und die Vorhersagen der Modelle verglichen.

### Analyse

6. Pearson's r-Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie getrennt gemessen.

2) Vergleiche Anmerkungen nach Demografie mit Modellen und Datensätzen über Pearson's R-Werte.</sample>
    <sample id="257">Der englische Inhalt lautet:

"Could you live with an AI and its morals?
Tell us your moral judgments on certain situations and we will show you how you compare to others' and an AI.

Are you better than an AI in noticing hateful speech?
Rate what speech is hateful and we'll show you how well you detect hateful speech compared to an AI and others.

Where are you on the techno-skeptic to techno-utopian scale?
Tell us how you think future mixed reality technology will affect your personal life, we will show you whether you are more techno-skeptical or techno-utopian."

Übersetzt auf Deutsch bedeutet das:

"Könnten Sie mit einem AI und seinen Moralvorstellungen leben?
Erzählen Sie uns Ihre moralischen Urteile zu bestimmten Situationen und wir werden Ihnen zeigen, wie Sie sich gegenüber denen anderer und einer AI messen.

Sind Sie besser als eine AI bei der Erkennung von hässlicher Sprache?
Beurteilen Sie, was als hässlich eingestuft wird, und wir werden Ihnen zeigen, wie gut Sie hässliche Sprache erkennen können im Vergleich zu einer AI und anderen.

Wo stehen Sie auf der Skala von Technoskeptiker bis Techno-Utopist?
Erzählen Sie uns, wie Sie denkt, wie zukünftige Mischrealitätstechnologie Ihr persönliches Leben beeinflussen wird, wir werden Ihnen zeigen, ob Sie eher technoskeptisch oder technoutopistisch sind."</sample>
    <sample id="258">Der Inhalt der Abbildung lautet:

**Lab in the Wild**

- **Pool of diverse volunteers / research participants**: Pool von vielfältigen Freiwilligen / Forschungsteilnehmern
- **Online experiment from researchers**: Online-Experiment von Forschern

Die Website zeigt verschiedene Experimente, die Teilnehmer einladen können, um an verschiedenen Themen wie moralischen Urteilen, der Erkennung von Hassrede und der Zukunft der Technologie teilzunehmen.</sample>
    <sample id="259">Aufgabe A: Soziale Akzeptanz

1) Lese die Situation.
2) Trage deine Meinung dazu ein.
   * Was denkst du moralisch darüber?
   (z.B.: Es ist okay, du solltest es tun, es ist ungewöhnlich)
   Du kannst gerne deine Urteilsgrundlage erläutern.
3) Sehe, was ein AI und andere über die Situation denken!
   Das AI spekuliert:
   Ich spekuliere, dass es verständlich ist. Hm... Vielleicht bin ich hier falsch.
   Studienteilnehmer in den USA sagten:

Die Teilnehmer lesen eine Situation aus dem Social Chemistry-Datensatz.
Die Teilnehmer bewerten, wie akzeptabel die Situation sozial ist.
Die Teilnehmer vergleichen ihre Antworten mit denen anderer und des AI.</sample>
    <sample id="260">Aufgabe A: Soziale Akzeptanz

1) Lese die Situation.
2) Stelle deine Meinung dar.
3) Sehe, was ein AI und andere darüber denken.

Die Teilnehmer vergleichen ihre Antworten mit denen anderer und des AI.</sample>
    <sample id="261">Aufgabe A: Soziale Akzeptanz

Analyse
Datenbanken
- Soziale Chemie

Modelle
- Delphi
- GPT-4</sample>
    <sample id="262">Aufgabe B: Toxicität

1) Lesen Sie das Beispiel.
7 / 25
Englische Menschen riechen nach Sauermilch.

2) Geben Sie Ihre Meinung dazu an.
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *</sample>
    <sample id="263">### Aufgabe B: Toxicity Analyse

#### Datenquellen
- Dynahate

#### Modelle
- Perspective API
- Rewire API
- Hate RoBERTa
- GPT-4

### Studienteilnahme
16,299 Anmerkungen
1,096 Anmerker
87 Länder</sample>
    <sample id="264">Die englischen Inhalte lauten:

1. Results: Wer stimmen NLP-Datenbanken und Modelle?
2. Finding 1: Es gibt Positionalität in der NLP.</sample>
    <sample id="265">Die Daten und Modelle sind am meisten mit englischsprachigen Ländern ausgerichtet.</sample>
    <sample id="266">Die Daten und Modelle sind am meisten mit Menschen mit einem College-Abschluss ausgerichtet.</sample>
    <sample id="267">Die Daten und Modelle sind am besten mit Menschen mit einem College-Abschluss ausgerichtet.</sample>
    <sample id="268">Finde 2:
Einige Populationen werden zurückgelassen.</sample>
    <sample id="269">Die Datenbanken und Modelle sind weniger mit nicht-binären Menschen ausgerichtet.</sample>
    <sample id="270">So, was können wir tun?
Positionalität in der NLP adressieren</sample>
    <sample id="271">Empfehlungen

1. Halte einen Protokoll aller relevanten Designentscheidungen während des Datensatzes oder Modellbaus.

2. Führe NLP-Forschung aus unter Berücksichtigung der Perspektivität:
a. Teile die aufgeteilten Datensatzetiketten!
b. Verwende Modellierungstechniken, die mit Annotator-Disagreement umgehen können.</sample>
    <sample id="272">Empfehlungen

1. Halte einen Protokoll aller relevanten Designentscheidungen, die während der Entwicklung von Datensätzen oder Modellen getroffen wurden.
2. Führe NLP-Forschung aus durch die Perspektivismus-Linse:
   a. Teile aufgeteilte Datensatzetiketten!
   b. Verwende Modellierungstechniken, die mit Annotator-Disagreement umgehen können.
3. Die Erstellung spezialisierter Datensätze und Modelle für und mit spezifischen Gemeinschaften ist wertvoll für inklusive NLP (z.B., Masakhane-Initiative¹).

[1] https://www.masakhane.io</sample>
    <sample id="273">Vielen Dank!

Dashboard-Link: nlpositionality.cs.washington.edu/
Papier: bit.ly/NLPositionality-Paper/

Delphi</sample>
    <sample id="274">Die Referentin geht auf drei Probleme von SimulST ein.</sample>
    <sample id="275">Um soziale und politische Verzerrungen in Datensätzen zu reduzieren, können verschiedene Maßnahmen angewendet werden:

1. **Diversität der Daten**: Es ist wichtig, dass die Datensätze eine breite Vielfalt von Stimmen und Perspektiven enthalten, um eine repräsentative und unparteiische Grundlage für das Training zu schaffen.

2. **Sanierung des Textes**: Vor dem Training können die Datensätze saniert werden, um potenzielle Verzerrungen zu entfernen oder zu minimieren. Dies kann beinhalten, dass bestimmte Wörter oder Phrasen entfernt oder ersetzt werden, um sicherzustellen, dass die Modelle keine voreingenommenen oder diskriminierenden Ansichten lernen.

3. **Kontrolle der Quellen**: Es ist wichtig, die Quellen der Daten zu überprüfen und zu kontrollieren, um sicherzustellen, dass sie nicht von verzerrenden Faktoren beeinflusst sind.

4. **Transparenz und Kontrolle**: Die Methoden und Entscheidungen im Prozess des Datensatzes saniern sollten transparent sein und durch eine externe Überwachung kontrolliert werden, um sicherzustellen, dass keine Verzerrungen unbemerkt bleiben.

5. **Evaluierung und Überprüfung**: Nach dem Training sollten die Modelle auf ihre Auswirkungen geprüft werden, um sicherzustellen, dass sie nicht unerwünschte Verzerrungen aufweisen.

6. **Ethische Praktiken**: Es sollte ein ethischer Ansatz bei der Erstellung und Nutzung von NLP-Modellen angewendet werden, um sicherzustellen, dass sie fair und unparteiisch sind.

Diese Maßnahmen helfen, soziale und politische Verzerrungen in Datensätzen zu reduzieren und sicherzustellen, dass die Modelle faire und unparteiische Ergebnisse liefern.</sample>
    <sample id="276">Der englische Inhalt lautet:

"The 61st Annual Meeting of the Association for Computational Linguistics
Toronto, Canada
July 9-14, 2023

Distilling Script Knowledge from Large Language Models for Constrained Language Planning

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

FUDAN UNIVERSITY
Brain Technologies Inc."</sample>
    <sample id="277">Die englische Aufgabe lautet: "Language Planning: How to Make a Cake?"

Hier ist die sinngemäße Übersetzung in Deutsch:

"Sprachplanung: Wie man ein Kuchen backt?"

Die Liste der Schritte zum Backen eines Kuchens lautet:

1. Sammle deine Zutaten.
2. Heiz den Ofen auf 325 °F (163 °C) vor und fettiere und bestreiche einen Kuchenguss.
3. Butter und Zucker cremen.
4. Eier hinzufügen.
5. Mehl in den Teig rühren.
6. Den Teig in den Guss gießen.
7. Den Kuchen für 1 Stunde und 15 Minuten backen."</sample>
    <sample id="278">Die englische Aufgabe lautet: "Language Planning: How to Make a Cake?"

Hier ist die deutsche Übersetzung:

"Sprachplanung: Wie man ein Kuchen backt?"

Die Liste der Schritte zum Backen eines Kuchens lautet:

1. Sammle deine Zutaten.
2. Heiz den Ofen auf 325 °F (163 °C) vor und fettiere und bestreiche einen Kuchenschüssel.
3. Butter und Zucker cremen.
4. Eier hinzufügen.
5. Mehl in die Teigmasse rühren.
6. Den Teig in die Schüssel gießen.
7. Den Kuchen für 1 Stunde und 15 Minuten backen."

Unter dem Text steht: "Große Sprachmodelle (LLMs) können effektiv Ziele in Schritte zerlegen."</sample>
    <sample id="279">Die englische Inhaltsbeschreibung lautet:

"Konstruierte Sprachplanung

Wie man ein Erdbeer-Kuchen macht?
...Füge Erdbeer-Jam in den Teig...

Wie man einen Schokoladenkuchen macht?
...Füge Kakao-Pulver in den Teig...

Abstrakte Ziele können von verschiedenen realen spezifischen Zielen mit vielfältigen Restriktionen geerbt werden."</sample>
    <sample id="280">Die englische Aufschrift lautet "Constrained Language Planning" und enthält zwei Fragen:

1. "How to Make a Strawberry Cake?"
   ...Add strawberry jams into the flour...

2. "How to Make a Chocolate Cake?"
   ...Add the cocoa powder into the flour...

Unter dem Text steht: "Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints."</sample>
    <sample id="281">Die englische Präsentation lautet:

"Konstruierte Sprachplanung

Wie man ein Erdbeer-Kuchen macht?
...Füge Erdbeer-Jam in den Teig...

Wie man einen Schokoladenkuchen macht?
...Füge Kakao-Pulver in den Teig...

Abstrakte Ziele können von verschiedenen realen spezifischen Zielen mit vielfältigen Restriktionen geerbt werden."</sample>
    <sample id="282">Wie leisten sich LLMs bei eingeschränktem Sprachplanung?

Datenbasis: wikiHow + Generierte Einschränkungen

**Einschränkungsart 1: Modifikator**
Definition: Ein Wort, ein Adjektiv oder eine Phrase, die eine abstrakte Zielvorstellung modifiziert oder einschränkt.
Beispiel 1: Machen Sie einen Schokoladenkuchen.
Beispiel 2: Machen Sie einen rosa Kuchen.

**Einschränkungsart 2: Methode**
Definition: Ein Werkzeug oder eine spezifische Art, die den Prozess steuert, um das Ziel zu erreichen.
Beispiel 1: Machen Sie einen Kuchen mit einem Ofen.
Beispiel 2: Machen Sie einen Kuchen mit einem Backmischungsmittel.

**Einschränkungsart 3: Absicht**
Definition: Eine zusätzliche Absicht oder Anforderung beim Erreichen des Ziels.
Beispiel 1: Machen Sie einen Kuchen für Hochzeiten.
Beispiel 2: Machen Sie einen Kuchen für Diabetiker.</sample>
    <sample id="283">Wie leisten sich LLMs bei eingeschränktem Sprachplanung?

Datenbasis: wikiHow + Generierte Einschränkungen

**Einschränkungsart 1: Modifikator**
Definition: Ein Wort, ein Adjektiv oder eine Phrase, die eine abstrakte Zielmodifikation oder -beschränkung vornimmt.
Beispiel 1: Machen Sie einen Schokoladenkuchen.
Beispiel 2: Machen Sie einen rosa Kuchen.

**Einschränkungsart 2: Methode**
Definition: Ein Werkzeug oder eine spezifizierte Modus, der den Prozess steuert, um das Ziel zu erreichen.
Beispiel 1: Machen Sie einen Kuchen mit einem Ofen.
Beispiel 2: Machen Sie einen Kuchen mit einem Backmischungsmittel.

**Einschränkungsart 3: Absicht**
Definition: Eine zusätzliche Absicht oder Anforderung beim Erreichen des Ziels.
Beispiel 1: Machen Sie einen Kuchen für Hochzeit.
Beispiel 2: Machen Sie einen Kuchen für Diabetiker.</sample>
    <sample id="284">Wie leisten sich Sprachmodelle bei eingeschränktem Sprachplanungsauftrag?

Datenbasis: wikiHow + Generierte Einschränkungen

**Einschränkungsart 1: Modifikator**
Definition: Ein Wort, ein Adjektiv oder eine Phrase, die eine abstrakte Zielvorstellung modifiziert oder einschränkt.
Beispiel 1: Machen Sie einen Schokoladenkuchen.
Beispiel 2: Machen Sie einen rosa Kuchen.

**Einschränkungsart 2: Methode**
Definition: Ein Werkzeug oder eine spezifische Art, die den Prozess steuert, um das Ziel zu erreichen.
Beispiel 1: Backen Sie einen Kuchen mit einem Ofen.
Beispiel 2: Backen Sie einen Kuchen mit einem Kuchenteig.

**Einschränkungsart 3: Absicht**
Definition: Eine zusätzliche Absicht oder Anforderung beim Erreichen des Ziels.
Beispiel 1: Backen Sie einen Kuchen für Hochzeiten.
Beispiel 2: Backen Sie einen Kuchen für Diabetiker.</sample>
    <sample id="285">Können LLMs beschränktes Sprachplanung machen?

Alle Baselines erzielen unzureichende Ergebnisse bei der Planung für spezifische Ziele.</sample>
    <sample id="286">Können LLMs beschränktes Sprachplanung machen?

Alle Baselines erzielen unzureichende Ergebnisse bei der Planung für spezifische Ziele.</sample>
    <sample id="287">Was für Arten von Fehlern machen LLMs in dieser Aufgabe normalerweise?

Die semantische Vollständigkeit (SE) in generierten Skripten ist akzeptabel, aber die Treue zu den Restriktionen (FE) kann nicht garantiert werden.</sample>
    <sample id="288">Was für Arten von Fehlern machen LLMs in dieser Aufgabe normalerweise?

Die semantische Vollständigkeit (SE) in generierten Skripten ist akzeptabel, aber die Treue zu den Restriktionen (FE) kann nicht garantiert werden.

Das Planungsleistung von InstructGPT variiert beträchtlich je nach verschiedenen Kategorien.</sample>
    <sample id="289">Die Präsentation fragt: "Welche Arten von Zielen scheitern InstructGPTs typischerweise?"

Die Tabelle zeigt die Planungsleistung von InstructGPTs für verschiedene Kategorien von Zielen:

- Arbeit: 0.0
- Sport: 0.67
- Beziehungen: 1.0
- Persönliche Pflege: 0.5
- Heim: 0.3
- Traditionen: 0.4
- Hobbys: 0.6
- Gesundheit: 0.5
- Lebensmittel: 0.66
- Geschäft: 0.5
- Familie: 0.0
- Bildung: 0.33
- Elektronik: 0.38
- Fahrzeuge: 0.75
- Künste: 0.29

Unter dem Titel steht: "Die Planungsleistung von InstructGPTs variiert erheblich für verschiedene Kategorien von Zielen."</sample>
    <sample id="290">Die Methode besteht aus folgenden Schritten:

1. Eingabe: ein abstraktes Ziel
2. Schritt 1: spezifische Ziele generieren mit InstructGPT durch in-kontextuelles Lernen

Abstraktes Ziel: Backen eines Kuchens
Spezifische Ziele:
- G1 (+ Modifikator): Backen eines Schokoladenkuchens
- G2 (+ Methode): Backen eines Kuchens im Mikrowellenherd
- G3 (+ Absicht): Backen eines Kuchens für eine Hochzeit</sample>
    <sample id="291">Der englische Inhalt lautet:

"Input: ein abstraktes Ziel
Schritt 1: spezifische Ziele generieren mit InstructGPT durch Kontext-Lernen

Abstraktes Ziel: Backen eines Kuchens
Spezifische Ziele:
G1 (+Modifikator): Backen eines Schokoladenkuchens
G2 (+Methode): Backen eines Kuchens im Mikrowellenherd
G3 (+Absicht): Backen eines Kuchens für eine Hochzeit"

Übersetzt auf Deutsch bedeutet das:

"Eingabe: ein abstraktes Ziel
Schritt 1: spezifische Ziele generieren mit InstructGPT durch Kontext-Lernen

Abstraktes Ziel: Backen eines Kuchens
Spezifische Ziele:
G1 (+Modifikator): Backen eines Schokoladenkuchens
G2 (+Methode): Backen eines Kuchens im Mikrowellenherd
G3 (+Absicht): Backen eines Kuchens für eine Hochzeit"</sample>
    <sample id="292">Der englische Inhalt lautet:

"Input: ein abstraktes Ziel

Schritt 1: Generiere spezifische Ziele mit InstructGPT durch in-kontextuelle Lernen

Schritt 2: Erzeuge übermäßige Kandidaten-Skripte mit InstructGPT durch in-kontextuelle Lernen

Abstraktes Ziel: Backen eines Kuchens

Spezifische Ziele:
G1 (+Modifikator): Backen eines Schokoladenkuchens
G2 (+Methode): Backen eines Kuchens im Mikrowellenherd
G3 (+Absicht): Backen eines Kuchens für eine Hochzeit

Generiere Pläne für G1

Kandidaten-Skripte"

Wiedergegeben sinngemäß auf Deutsch:

"Eingabe: ein abstraktes Ziel

Schritt 1: Erstelle spezifische Ziele mit InstructGPT durch in-kontextuelles Lernen

Schritt 2: Erzeuge übermäßige Kandidaten-Skripte mit InstructGPT durch in-kontextuelles Lernen

Abstraktes Ziel: Backen eines Kuchens

Spezifische Ziele:
G1 (+Modifikator): Backen eines Schokoladenkuchens
G2 (+Methode): Backen eines Kuchens im Mikrowellenherd
G3 (+Absicht): Backen eines Kuchens für eine Hochzeit

Erstelle Pläne für G1

Kandidaten-Skripte"</sample>
    <sample id="293">Method

Schritt 2: Erzeugen von Kandidatenskripten mit InstructGPT durch in-kontextes Lernen
Schritt 3: Finden von gefilterten Skripten zum Ziel mit InstructGPT über Ähnlichkeitsbewertung
Ausgabe: Spezifische Ziele mit entsprechenden Skripten</sample>
    <sample id="294">Der englische Inhalt lautet:

"Method

Step 2: Over-generate candidate scripts with InstructGPT via in-context learning
Step 3: Find filtered scripts to the goal with InstructGPT via similarity score
Output: Specific goals with corresponding scripts"

Übersetzt auf Deutsch bedeutet das:

"Verfahren

Schritt 2: Erzeugen von Kandidatenskripten mit InstructGPT durch in-kontext-Learning
Schritt 3: Filtern von Skripten zum Ziel mit InstructGPT durch Ähnlichkeitsbewertung
Ausgabe: Spezifische Ziele mit entsprechenden Skripten"</sample>
    <sample id="295">Der englische Inhalt lautet:

"Method

Step 2: Over-generate candidate scripts with InstructGPT via in-context learning
Step 3: Find filtered scripts to the goal with InstructGPT via similarity score
Output: Specific goals with corresponding scripts"

Übersetzt auf Deutsch bedeutet das:

"Verfahren

Schritt 2: Erzeugen von Kandidatenskripten mit InstructGPT durch in-kontextes Lernen
Schritt 3: Filtern von Skripten zum Ziel mit InstructGPT durch Ähnlichkeitsbewertung
Ausgabe: Spezifische Ziele mit entsprechenden Skripten"</sample>
    <sample id="296">Unser Verfahren verbessert die Planungsqualität erheblich.

Mit unserem Verfahren kann InstructGPT Skripte von höherer Qualität generieren, und zwar deutlich.</sample>
    <sample id="297">### Motivation
- Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu aktivieren.

### Methode
- Folgt dem Prinzip der symbolischen Wissensverdichtung.
- Generiert 55.000 Skripte mit Restriktionen von LLMs basierend auf unserer Methode =&gt; Coscript-Datensatz.
- Menschen annotieren die Validierung und Testdatensätze.</sample>
    <sample id="298">### Motivation
- Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen.

### Methode
- Folgt dem Prinzip der symbolischen Wissensverdichtung.
- Generiert 55.000 Skripte mit Restriktionen von LLMs basierend auf unserer Methode =&gt; Coscript-Datensatz.
- Menschen annotieren die Validierung und Testdatensätze.</sample>
    <sample id="299">### Motivation
- Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen.

### Methode
- Folgt dem Prinzip der symbolischen Wissensverdichtung.
- Generiert 55.000 Skripte mit Restriktionen von LLMs basierend auf unserer Methode =&gt; Coscript-Datensatz.
- Menschen annotieren die Validierung und Testdatensätze.</sample>
    <sample id="300">### Motivation
Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu aktivieren.

### Methode
Folgt dem Prinzip der symbolischen Wissensverdichtung.
Generiert 55.000 Skripte mit Restriktionen von LLMs basierend auf unserer Methode =&gt; Coscript-Datensatz.
Menschen annotieren die Validierung und Testdatensätze.

### Schritte
**Schritt 1:** Generiere spezifische Ziele mit InstructGPT via in-context Learning.
**Schritt 2:** Erzeuge überflüssige Kandidaten-Skripte mit InstructGPT via in-context Learning.
**Schritt 3:** Finde gefilterte Skripte zum Ziel mit InstructGPT via Ähnlichkeitsbewertung.
**Ausgabe:** Spezifische Ziele mit entsprechenden Plänen.</sample>
    <sample id="301">### Motivation
- Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen.

### Methode
- Folgt dem Prinzip der symbolischen Wissensverdichtung.
- Generiert 55.000 Skripte mit Restriktionen von LLMs basierend auf unserem Verfahren =&gt; Coscript-Datensatz.
- Menschen annotieren die Validierung und Testdatensätze.</sample>
    <sample id="302">### Constraint Analysis
Coscript zeigt hohe Heterogenität und Pluralität in den generierten spezifischen Zielen.

### Coscript für kleinere Sprachmodelle
- **Datenquellen**:
  - Coscript
  - wikiHow

- **Messen**:
  - Treue: DeBERTa (v3 large) Modell, um festzustellen, ob die generierten Texte den Restriktionen treu sind
  - Automatische Messwerte: ROUGE, BLEU, BERTScore</sample>
    <sample id="303">### Spezialisierte Modelle vs. LLMs

- Stellen Sie das konstruierte Sprachplanungsproblem ein.
- Überprüfen Sie die konstruierte Sprachplanungsfähigkeit von LLMs und entwickeln Sie eine Methode zur Überkorrektur für LLMs.
- Verwenden Sie LLMs, um ein hochwertiges Skript (CoScript) für konstruierte Sprachplanung zu generieren.
- Limitierungen und zukünftige Arbeiten:
  - Die vorgeschlagene Methode zur Verbesserung von LLMs ist ein post-hoc Re-Ranking-Ansatz.
  - Kleine LLMs, die auf CoScript abgestimmt wurden, können höhere Qualitätsskripte als LLMs generieren.
  - Der CoScript-Datensatz kann ein wertvolles Ressourcenmaterial sein, um die Forschung auf dem Gebiet der Sprachplanung mit komplexeren und vielfältigeren Zielen und Einschränkungen voranzutreiben.</sample>
    <sample id="304">Zusammenfassung und Schlüsselpunkte

- Stellen Sie das Problem der eingeschränkten Sprachplanung ein.
- Evaluieren Sie die Fähigkeit von LLMs zur eingeschränkten Sprachplanung und entwickeln Sie eine Methode, die "über-generieren-dann-filtern" für LLMs.
- Verwenden Sie LLMs, um einen hochwertigen Skriptdatensatz (CoScript) für eingeschränkte Sprachplanung zu generieren.
- Limitationen und zukünftige Arbeiten
  - Die vorgeschlagene Methode zur Verbesserung von LLMs ist ein post-hoc Re-Ranking-Ansatz.
  - CoScript erbt nur von einem abstrakten mit einer zusätzlichen Einschränkung.
  - Der CoScript-Datensatz kann ein wertvolles Ressourcenmaterial sein, um die Forschung zur Sprachplanung mit komplexeren und vielfältigeren Zielen und Einschränkungen voranzutreiben.</sample>
    <sample id="305">Zusammenfassung und Schlüsselpunkte

- Stellen Sie das Problem der eingeschränkten Sprachplanung ein.
- Beurteilen Sie die Fähigkeit von LLMs zur eingeschränkten Sprachplanung und entwickeln Sie eine Methode, die "über-generieren-dann-filtern" für LLMs.
- Verwenden Sie LLMs, um einen hochwertigen Skriptdatensatz (CoScript) für eingeschränkte Sprachplanung zu generieren.
- Limitationen und zukünftige Arbeiten
  - Die vorgeschlagene Methode zur Verbesserung von LLMs ist ein post-hoc Re-Ranking-Ansatz.
  - CoScript erbt nur von einem abstrakten mit einer zusätzlichen Einschränkung.
  - Der CoScript-Datensatz kann ein wertvolles Ressourcenmaterial sein, um die Forschung zur Sprachplanung mit komplexeren und vielfältigeren Zielen und Einschränkungen voranzutreiben.</sample>
    <sample id="306">Der englische Inhalt lautet:

"61. Jahrestagung der Association for Computational Linguistics
Toronto, Kanada
9.-14. Juli 2023

Distilling Script Knowledge from Large Language Models for Constrained Language Planning

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

syyuan21@m.fudan.edu.cn
https://github.com/siyuyuan/coscript"

Wörtlich übersetzt bedeutet dies:

"61. Jahrestagung der Association for Computational Linguistics
Toronto, Kanada
9.-14. Juli 2023

Kondensieren von Skriptwissen aus großen Sprachmodellen für eingeschränktes Sprachplanung

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

syyuan21@m.fudan.edu.cn
https://github.com/siyuyuan/coscript"</sample>
    <sample id="307">The fluency of PaLM is comparable to SOTA.</sample>
    <sample id="308">Die wichtigsten Eigenschaften eines Wasserzeichenverfahrens sind:

1. Anwendbarkeit für EaaS (Embedded AI as a Service)
2. Nutzen: Das Wasserzeichen sollte die Nutzbarkeit der bereitgestellten Embeddings nicht vermindern.
3. Geheimhaltung: Es sollte geheim bleiben, dass es sich um ein Wasserzeichen handelt.
4. Übertragbarkeit: Das Wasserzeichen muss übertragbar sein zu den Angreiferdiensten.</sample>
    <sample id="309">Die englischen TED Talks wurden in folgende 14 Sprachen übersetzt: Englisch, Arabisch, Deutsch, Spanisch, Französisch, Hebräisch, Italienisch, Japanisch, Koreanisch, Niederländisch, Portugiesisch, Rumänisch, Russisch, Türkisch und Chinesisch.</sample>
    <sample id="310">300 Instanzen.</sample>
    <sample id="311">Die Distanzmetriken, die verwendet werden, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen, sind die Cosine-Distanz (cos) und die L2-Distanz (l2).</sample>
    <sample id="312">Die Modelle, die auf einem mehrsprachigen Encoder basieren, wurden in dieser Aufgabe in zwei Gruppen eingesetzt: Enc-PTR (Multilingual Pretrained Encoders with Pointer-based Decoders) und Enc-Dec (Multilingual Pretrained Encoder-Decoder Models).</sample>
    <sample id="344">Die Autoren zählen die Wortfrequenz in einem allgemeinen Textkorpus \( D_p \) und wählen dann n Wörter aus einer mittelfrequenten Intervall.</sample>
    <sample id="345">Der Titel des Inhalts lautet: "Gibt es noch immer gute Ergebnisse von CoNLL-2003-Named-Entity-Tagging-Modellen im Jahr 2023?"

Die Namen der Autoren sind: Shuheng Liu und Alan Ritter, die an der School of Interactive Computing, Georgia Institute of Technology arbeiten.</sample>
    <sample id="346">Der Titel auf dem Bild lautet "Named Entity Recognition &amp; Generalization". Dies bedeutet "Nomen-Entitätenerkennung &amp; Generalisierung" auf Deutsch.</sample>
    <sample id="347">Der Inhalt des Bildes lautet:

"Named Entity Recognition &amp; Generalization

- Modelle haben seit fast 20 Jahren CoNLL-2003 zur Entwicklung von NER verwendet
- Können diese Modelle modernen Daten generalisieren?
- Was ist notwendig für eine gute Generalisierung?"</sample>
    <sample id="348">Der Inhalt des Bildes lautet auf Deutsch:

"Namenserkennung &amp; Generalisierung

- Modelle haben CoNLL-2003 für die Entwicklung von NER fast 20 Jahre lang verwendet.
- Können diese Modelle modernen Daten generalisieren?
- Was ist notwendig für eine gute Generalisierung?"</sample>
    <sample id="349">Der Inhalt des Bildes lautet auf Deutsch:

"Named Entity Recognition &amp; Generalization

- Modelle haben seit fast 20 Jahren CoNLL-2003 zur Entwicklung von NER verwendet.
- Können diese Modelle modernen Daten generalisieren?
- Was ist notwendig für eine gute Generalisierung?
- Was verursacht die Leistungseinbußen?"</sample>
    <sample id="350">CoNLL++ Dataset

- Sammlte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie nach den CoNLL-2003-Anmerkungsempfehlungen</sample>
    <sample id="351">CoNLL++ Dataset
- Sammlte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie nach den CoNLL-2003-Anmerkungsnormen.
- Feinabgestimmte 20+ Modelle auf CoNLL-2003
- Evaluierung auf CoNLL-2003 Testset &amp; CoNLL++

AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="352">### CoNLL++ Dataset

- Sammlte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie mit den Anmerkungsempfehlungen von CoNLL-2003.
- Feinabgestimmte 20+ Modelle auf CoNLL-2003.
- Wurde auf dem CoNLL-2003 Testset &amp; CoNLL++ evaluiert.
- Berechnete prozentuale ΔF1, um die Generalisierbarkeit zu bewerten.

| Wort | Etikett |
|------|---------|
| AMBASSADOR | O       |
| TO     | O       |
| THE    | O       |
| UNITED | I-ORG   |
| NATIONS| I-ORG   |
| :     | O       |
| LINDA  | I-PER   |
| THOMAS-GREENFIELD | I-PER |

---

### Übersetzung des Inhalts ins Deutsche:

### CoNLL++ Dataset

- Sammelte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie nach den Anmerkungsempfehlungen von CoNLL-2003.
- Feinabgestimmte 20+ Modelle auf CoNLL-2003.
- Wurde auf dem CoNLL-2003 Testset &amp; CoNLL++ evaluiert.
- Berechnete prozentuale ΔF1, um die Generalisierbarkeit zu bewerten.

| Wort | Etikett |
|------|---------|
| Botschafter | O       |
| ZU     | O       |
| DER    | O       |
| VEREINIGT | I-ORG   |
| NATIONEN | I-ORG   |
| :     | O       |
| LINDA  | I-PER   |
| THOMAS-GREENFIELD | I-PER |</sample>
    <sample id="353">Was ist notwendig für eine gute Generalisierung?</sample>
    <sample id="354">Was ist für eine gute Generalisierung erforderlich?

- Modellarchitektur
- Transformer-Modelle generalisieren besser</sample>
    <sample id="355">Was ist für eine gute Generalisierung notwendig?

- Modellarchitektur
  - Transformer-Modelle generalisieren besser

- Modellgröße
  - Größere Modelle generalisieren besser</sample>
    <sample id="356">Was ist notwendig für eine gute Generalisierung?

- Modellarchitektur
  - Transformer-Modelle generalisieren besser

- Modellgröße
  - Größere Modelle generalisieren besser

- Anzahl der Feinabstimmungsbeispiele
  - Mehr Beispiele führen zu besserer Generalisierung</sample>
    <sample id="357">Was verursacht eine Leistungseinbuße?</sample>
    <sample id="358">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?</sample>
    <sample id="359">Was verursacht eine Leistungsabnahme?

- Adaptive Overfitting?
- Temporale Drift?</sample>
    <sample id="360">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?
- Temporale Verschiebung?</sample>
    <sample id="361">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?
- Temporale Verschiebung?</sample>
    <sample id="362">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?
  - Keine abnehmenden Renditen
  - Nicht beobachtet
- Temporale Verschiebung?</sample>
    <sample id="363">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?
  - Keine abnehmenden Renditen
  - Nicht beobachtet
- Temporale Verschiebung?</sample>
    <sample id="364">Was verursacht eine Leistungsabnahme?

- Adaptive Overfitting?
  - Keine abnehmenden Rückerträge
  - Nicht beobachtet

- Temporale Verschiebung?
  - Leistung sinkt mit größerem zeitlichen Abstand</sample>
    <sample id="365">Was verursacht eine Leistungsabnahme?

- Adaptive Overfitting?
  - Keine abnehmenden Renditen
  - Beobachtet nicht

- Temporale Drift?
  - Leistung sinkt mit größerem zeitlichen Abstand
  - Hauptursache für Leistungsabnahme</sample>
    <sample id="366">Zusammenfassung

- Für eine gute Generalisierung benötigen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr Feinabstimmungsbeispiele</sample>
    <sample id="367">### Schlussfolgerung

- Für eine gute Generalisierung benötigen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr abgestimmte Beispiele
- Leistungseinbußen werden durch:
  - Temporale Verschiebung
  - Keine adaptive Überanpassung verursacht</sample>
    <sample id="368">### Schlussfolgerung

- Für eine gute Generalisierung benötigen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr abgestimmte Beispiele
- Leistungseinbruch wird durch:
  - Temporale Verschiebung
  - Nicht adaptives Überfitting
- Funktionieren CoNLL-2003-Tagger immer noch?

- Ja!</sample>
    <sample id="369">### Schlussfolgerung

- Für eine gute Generalisierung benötigen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr abgestimmte Beispiele
- Leistungseinbruch wird durch:
  - Temporale Verschiebung
  - Keine adaptive Überanpassung
- Funktionieren CoNLL-2003-Tagger immer noch?
  - JA!</sample>
    <sample id="370">Hier ist der übersetzte Inhalt:

- Papier: https://arxiv.org/abs/2212.09747
- Datensatz: https://github.com/ShuhengL/acl2023_conllpp
- Kontakt: sliu775@gatech.edu</sample>
    <sample id="397">Der englische Text im Bild lautet "What is our solution?", was darauf hindeutet, dass es sich um eine Frage handelt. Es gibt keine spezifische Angabe zur Sprachsegmentgröße oder zum Ansatz in dem Bild.</sample>
    <sample id="398">Das entitätsspezifische Wissen, das im Beispiel mit Servin und Kea benötigt wird, lautet: "Servin is a judge."</sample>
    <sample id="399">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit zum Ausgangssatz.</sample>
    <sample id="400">Die Arbeiten in den erweiterten Experimenten konzentrieren sich auf die Sprachmodelle RoBERTa und GPT-2.</sample>
    <sample id="401">Das Modell verwendet Aufmerksamkeitswerte aus mehreren Ebenen.</sample>
    <sample id="402">Direkte Inferenzbeispiele sind "easy on me" und "the first one".</sample>
    <sample id="403">Die Autoren gehören der Fudan University an.</sample>
    <sample id="404">Es gibt sechs Autoren, die an der Arbeit beteiligt sind.</sample>
    <sample id="405">Ja, die Übersetzung der natürlichsprachlichen Anfrage mit Hilfe eines maschinellen Übersetzungsmodells wurde als Baseline betrachtet.</sample>
    <sample id="406">Ein Beispiel für eine markierte Gruppe ist "a woman warrior" (eine weibliche Kriegerin).</sample>
    <sample id="407">BILSTM-CRF-ELMo</sample>
    <sample id="408">Die Testdatensätze heißen "Validation".</sample>
    <sample id="409">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten, insbesondere mit multimodalen prätrainierten Modellen.</sample>
    <sample id="439">Das zu wenig erforschte Gebiet im Bereich der NLU, wie es von den Autoren angenommen wird, ist die Verwendung von Inferenzzeit-Wissen.</sample>
    <sample id="440">Die Referenten heißen Zhiyang Xu, Ying Shen und Lifu Huang.</sample>
    <sample id="441">Ja, Coscript wurde von Menschen annotiert, um die Validierung und Testset-Qualität zu gewährleisten.</sample>
    <sample id="442">Die Grenzen bestehender Ressourcen für kontextbasierte Übersetzung liegen darin, dass nur eine kleine Anzahl von Wörtern von Kontext abhängt und dass die vorhandenen Methoden nur begrenzte Diskursphänomene und Sprachen unterstützen.</sample>
    <sample id="443">Der englische Inhalt lautet:

"Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)"

Die deutschen Übersetzungen der Namen der Autoren sind:

Mohammad Javad Hosseini, Filip Radlinski, Silvia Paretí und Annie Louis

Die deutsche Übersetzung des Titels lautet:

"Lösung indirekter Bezugsausdrücke für Entitätsauswahl (AltEntities-Korpus)"</sample>
    <sample id="444">Der englische Inhalt lautet:

"Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)"

Die deutsche Übersetzung lautet:

"Lösung indirekter Bezugsausdrücke für Entitätsauswahl (AltEntities Corpus)"</sample>
    <sample id="445">Indirekte Bezugssätze

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  - Alternative Frage: Did you mean easy on me or I gotta feeling?

- Direkte Bezug:
  - "easy on me", "the first one"

- Indirekte Bezug kann in natürlichen und flüssigen Gesprächen verwendet werden:
  - Namen vergessen
  - Die Aussprachen sind schwer zu unterscheiden
  - Eine Präferenz festlegen möchten

  - Indirekter Bezug: The newer one. The song that's not energetic.</sample>
    <sample id="446">Indirekte Bezugssätze

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  Alternative Frage → Did you mean easy on me or I gotta feeling?

- Direkte Bezug:
  - "easy on me", "the first one"

- Indirekte Bezug kann in natürlichen und flüssigen Gesprächen verwendet werden:
  - Kann den Namen nicht mehr erinnern
  - Die Aussprachen sind schwer zu unterscheiden
  - Will eine Präferenz spezifizieren

  Indirekter Bezug → The newer one. The song that's not energetic.</sample>
    <sample id="447">Indirekte Bezugssätze

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  - Alternative Frage: Did you mean easy on me or I gotta feeling?
  
- Direkte Bezug:
  - "easy on me", "the first one"
  
- Indirekte Bezug kann in natürlichen und flüssigen Gesprächen verwendet werden:
  - Kann den Namen nicht mehr erinnern
  - Die Aussprachen sind schwer zu unterscheiden
  - Will eine Präferenz spezifizieren
  
  Indirekter Bezug:
  - The newer one.
  - The song that's not energetic.</sample>
    <sample id="448">Indirekte Bezugssätze

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  Alternative Frage → Did you mean easy on me or I gotta feeling?

- Direkte Bezug:
    - "easy on me", "the first one"

- Indirekte Bezug kann in natürlichen und flüssigen Gesprächen verwendet werden:
    - Kann nicht den Namen merken
    - Die Aussprachen sind schwer zu unterscheiden
    - Will eine Präferenz spezifizieren

  Indirekte Bezug → The newer one. The song that's not energetic.</sample>
    <sample id="449">Indirekte Bezugssätze

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  Alternative Frage → Did you mean easy on me or I gotta feeling?

- Direkte Bezug:
  - "easy on me", "the first one"

- Indirekte Bezug kann in natürlichen und flüssigen Gesprächen verwendet werden:
  - Kann den Namen nicht mehr erinnern
  - Die Aussprachen sind schwer zu unterscheiden
  - Will eine Präferenz spezifizieren

  Indirekter Bezug → The newer one. The song that's not energetic.</sample>
    <sample id="450">Dataset Collection

- Wichtige Probleme
  - Konversationssysteme
  - Benchmarking großer Sprachmodell-Entitätsverstehens
- Kein großes öffentliches Datensatz verfügbar
- Wir sammeln einen großen Datensatz durch Crowdsourcing
- Drei Domänen:</sample>
    <sample id="451">### Dataset Collection

- **Wichtige Probleme**
  - Konversationssysteme
  - Benchmarking großer Sprachmodelle für das Verständnis von Entitäten
- **Kein großes öffentliches Datensatz verfügbar**
- **Wir sammeln einen großen Datensatz durch Crowdsourcing**
- **Drei Domänen:**

1. Kopfhörer
2. Bücherregal
3. Tischdecke</sample>
    <sample id="452">Die Präsentation befasst sich mit der Methodologie zur Datensatzsammlung und betont, dass die Methode Informalität verwendet, indem sie eine Cartoon-Fertigstellungsaufgabe einsetzt.

- Die Methode setzt auf Informalität.
- Der Datensatz wird mit einer Cartoon-Fertigstellungsaufgabe gesammelt.

Die Präsentation zeigt eine Sequenz von Dialogen zwischen zwei Personen:

1. **Dialogkontext festlegen**: "Erinnere dich an das Lied, das wir gestern gehört haben?"
2. **Alternative Frage**: "Meinst du 'Easy on Me' oder 'I Gotta Feeling'?"
3. **Referenz auf einen der enthaltenen Entitäten**: "Was meinst du?"

Die letzte Sprechblase ist leer und wird vom Annotator ausgefüllt.</sample>
    <sample id="453">Die Präsentation befasst sich mit der Methodologie zur Datensatzsammlung und betont, dass die Methode Informalität durch eine Karikatur-Fertigstellungsaufgabe hervorhebt.

- Die Methode setzt auf Informalität.
- Der Fokus liegt auf einer Karikatur-Fertigstellungsaufgabe.

Die Präsentation zeigt vier Szenen:

1. **Dialogkontext festlegen**: "Erinnere dich an das Lied, das wir gestern gehört haben?"
2. **Alternative Frage**: "Meinst du 'Easy on Me' oder 'I Gotta Feeling'?"
3. **Ausdruck, der auf einen der enthaltenen Entitäten verweist**: "Füllt von dem Annotator aus."
4. **Beschriftungen**:
   - "Setzt den Dialogkontext [aus einigen manuellen Anweisungen pro Domäne]"
   - "Alternative Frage"
   - "Ausdruck, der auf eine der enthaltenen Entitäten verweist"

Der Titel der Präsentation lautet: "Dataset Collection Methodology" und es wird erwähnt, dass es sich um eine Arbeit handelt, die sich mit der Auflösung indirekter Bezugsausdrücke für Entitätsauswahl (AltEntities Corpus) befasst.</sample>
    <sample id="454">Dataset-Sammlungs-Methode

- Die Methode betont die Informalität durch das Verwenden einer Karikatur-Fertigstellungsaufgabe</sample>
    <sample id="455">Dataset-Sammlungs-Methode

- Die Methode betont die Informalität durch das Verwenden einer Karikatur-Fertigstellungsaufgabe</sample>
    <sample id="456">Die Präsentation befasst sich mit der Methodologie zur Datensatzsammlung und betont, dass die Methode Informalität durch eine Karikatur-Fertigstellungsaufgabe hervorhebt.

- Die Methode setzt auf Informalität.
- Der Fokus liegt auf einer Karikatur-Fertigstellungsaufgabe.

Die Präsentation zeigt vier Figuren, die ein Gespräch führen:

1. Eine Person fragt: "Erinnerst du dich an das Lied, das wir gestern gehört haben?"
2. Eine andere Person antwortet mit einer Alternative: "Meinst du 'Easy on Me' oder 'I Gotta Feeling'?"
3. Eine dritte Person gibt eine Referenz zu einem der enthaltenen Elemente: "Das ist es."

Die Texte unter den Figuren sind:
- "Setzt den Dialog-Kontext [aus einigen manuellen Anweisungen pro Domäne]"
- "Alternative Frage"
- "Referenz zu einem der enthaltenen Elemente"

Ein gelber Block rechts oben besagt: "Füllt von dem Annotator."

Unter dem Titel steht: "Löschen Indirekte Bezugsausdrücke für Entitätsauswahl (AltEntities Corpus)"</sample>
    <sample id="457">### Sammlungsmethodik für Datensätze

- Die Methodik betont die **Informalität** durch das Verwenden einer **Cartoon-Fertigstellungsaufgabe**.

---

### Dataset Collection Methodology

- The methodology emphasizes **informality** using a **cartoon completion task**.

---

### Sampling entity pairs

- Items with similar descriptions on Wikipedia (same genre and/or artist)
- Items with similar titles:
  - Do you mean 'This is It' or 'Man in the Mirror'?
  - Do you mean 'Thinking of You' or 'Happy Anywhere'?
  - Do you mean 'The Return (memoir)' or 'The Return (Shahner novel)'?
- Expression referring to one of the entities:
  - Do you mean 'You Could Be Mine' or 'The Way I Am'?

---

### Sampling entity pairs

- Items with similar descriptions on Wikipedia (same genre and/or artist)
- Items with similar titles:
  - Do you mean 'This is It' or 'Man in the Mirror'?
  - Do you mean 'Thinking of You' or 'Happy Anywhere'?
  - Do you mean 'The Return (memoir)' or 'The Return (Shahner novel)'?
- Expression referring to one of the entities:
  - Do you mean 'You Could Be Mine' or 'The Way I Am'?</sample>
    <sample id="458">Generiere alternative Fragen =&gt; Auswahl von Entity-Paaren

Hast du A oder B gemeint?

- Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleicher Genre und/oder Künstler)
  - Hast du "This Is It" oder "Man in the Mirror" gemeint?
- Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  - Hast du "Thinking of You" oder "Happy Anywhere" gemeint?
- Gegenstände mit ähnlichen Titeln:
  - Hast du "The Return (memoir)" oder "The Return (Shatner novel)" gemeint?
- Zufällig:
  - Hast du "You Could Be Mine" oder "The Way I Am" gemeint?</sample>
    <sample id="459">Die deutsche Übersetzung des Inhalts lautet:

"Erstellen alternativer Fragen =&gt; Auswahl von Entity-Paaren

Haben Sie A oder B gemeint?

- Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleicher Genre und/oder Künstler)
  Hatten Sie "This Is It" oder "Man in the Mirror" gemeint?
- Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  Hatten Sie "Thinking of You" oder "Happy Anywhere" gemeint?
- Gegenstände mit ähnlichen Titeln:
  Hatten Sie "The Return (memoir)" oder "The Return (Shatner novel)" gemeint?
- Zufällig ausgewählt:
  Hatten Sie "You Could Be Mine" oder "The Way I Am" gemeint?"

Entschlüsselung indirekter Bezugsausdrücke zur Entity-Auswahl (AltEntities Corpus)</sample>
    <sample id="460">Generiere alternative Fragen =&gt; Auswahl von Entity-Paaren

Hast du A oder B gemeint?

- Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleicher Genre und/oder Künstler)
  Hast du "This Is It" oder "Man in the Mirror" gemeint?
- Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  Hast du "Thinking of You" oder "Happy Anywhere" gemeint?
- Gegenstände mit ähnlichen Titeln:
  Hast du "The Return (Memoir)" oder "The Return (Shatner novel)" gemeint?
- Zufällig ausgewählt:
  Hast du "You Could Be Mine" oder "The Way I Am" gemeint?</sample>
    <sample id="461">Generiere alternative Fragen =&gt; Auswahl von Entity-Paaren

Hast du A oder B gemeint?

- Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleicher Genre und/oder Künstler)
  Hast du "This Is It" oder "Man in the Mirror" gemeint?
- Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  Hast du "Thinking of You" oder "Happy Anywhere" gemeint?
- Gegenstände mit ähnlichen Titeln:
  Hast du "The Return (memoir)" oder "The Return (Shatner novel)" gemeint?
- Zufällig verteilt:
  Hast du "You Could Be Mine" oder "The Way I Am" gemeint?</sample>
    <sample id="462">Die Präsentation zeigt eine Seite mit dem Titel "Generate alternative questions =&gt; sampling entity pairs" und ist Teil einer Google Research Präsentation. Der Inhalt der Präsentation befasst sich mit der Erstellung alternativer Fragen zur Auswahl von Entity-Paaren.

Hier ist der englische Text übersetzt:

---

**Generate alternative questions =&gt; sampling entity pairs**

**Do you mean A or B?**

- Items with similar infoboxes on Wikipedia (same genre and/or artist)
  - Do you mean 'This Is It' or 'Man in the Mirror'?
- Items with similar descriptions on Wikipedia
  - Do you mean 'Thinking of You' or 'Happy Anywhere'?
- Items with similar titles:
  - Do you mean The Return (memoir) or The Return (Shatner novel)?
- Uniform at random:
  - Do you mean 'You Could Be Mine' or 'The Way I Am'

---

Diese Präsentationsseite erklärt verschiedene Methoden, um Entity-Paare zu generieren, indem sie alternative Fragen erstellt, die auf ähnliche Informationen oder Beschreibungen basieren.</sample>
    <sample id="463">Hintergrundwissen (Musik)

- Google-Suchverknüpfung zu jedem Lied.
  - "Easy on Me" (von Adele)
  - "I Gotta Feeling" (von The Black Eyed Peas)

- Wir bitten die Annotatoren, 
  - mindestens einige Teile jedes Liedes anzuhören,
  - über jedes Lied nachzulesen.

Titel: Auflösung indirekter Bezugsausdrücke für Entitätenauswahl (AltEntities Corpus)</sample>
    <sample id="464">Hintergrundwissen (Musik)
- Google-Suchlink zu jedem Lied.
  - "Easy on Me" (von Adele)
  - "I Gotta Feeling" (von The Black Eyed Peas)

Wir bitten die Annotatoren, 
- mindestens einige Teile jedes Liedes anzuhören
- über jedes Lied nachzulesen</sample>
    <sample id="465">Hintergrundwissen (Musik)

- Google-Suchverknüpfung zu jedem Lied.
  - "Easy on Me" (von Adele)
  - "I Gotta Feeling" (von The Black Eyed Peas)

- Wir bitten die Annotatoren, 
  - mindestens einige Teile jedes Liedes anzuhören,
  - über jedes Lied nachzulesen.

---

Hintergrundwissen (Musik)

- Google-Suchverknüpfung zu jedem Lied.
  - "Easy on Me" (von Adele)
  - "I Gotta Feeling" (von The Black Eyed Peas)

- Wir bitten die Annotatoren, 
  - mindestens einige Teile jedes Liedes anzuhören,
  - über jedes Lied nachzulesen.</sample>
    <sample id="466">Hintergrundwissen (Rezepte)

Simnel-Kuchen
Der Simnel-Kuchen ist ein Früchtekuchen, der im Vereinigten Königreich, Irland und anderen Ländern mit Migrationsmustern weit verbreitet ist, die mit Ostern und Fasten assoziiert sind. Er wird durch Schichten aus Mandelmasse oder Marzipan und einer Gruppe von elf Kugeln aus demselben Teig gekennzeichnet.

Pandan-Kuchen
Der Pandan-Kuchen ist ein leichter, fluffiger, grün gefärbter Kuchen, der mit den Saftblättern des Pandanus amaryllifolius gewürzt wird. Der Kuchen ist in Indonesien, Malaysia und auch den Niederlanden, besonders bei der Indo-Gemeinschaft beliebt.</sample>
    <sample id="467">Der englische Text lautet:

"**Eliciting expressions**
- We then tell the annotators which choice should be selected and ask them to describe it.

Pick this one
- Easy on Me (by Adele)
- I Gotta Feeling (by the Black Eyed Peas)

We would like you to give us 3 to 5 expressions for the chosen song to fill in your speech bubble. For example:
- The one with the piano music
- The song that's not energetic
- It has something about a river
- The newer one
- It's about not having time to choose"

Übersetzt ins Deutsche:

"**Erhebung von Ausdrücken**
- Wir sagen dann den Annotatoren, welche Wahl ausgewählt werden soll und bitten sie, es zu beschreiben.

Wählen Sie diese
- Easy on Me (von Adele)
- I Gotta Feeling (von den Black Eyed Peas)

Wir möchten, dass Sie 3 bis 5 Ausdrücke für das gewählte Lied geben, um in Ihren Sprechblase einzufüllen. Zum Beispiel:
- Der mit dem Klaviermusik
- Das Lied, das nicht energiegeladen ist
- Es hat etwas mit einem Fluss
- Die neuere Version
- Es geht darum, nicht genug Zeit zu haben, um zu wählen"</sample>
    <sample id="468">### Übertragung des englischen Inhalts in die deutsche Sprache

---

#### Eliciting expressions

- Wir geben den Annotatoren dann zu, welche Wahl ausgewählt werden soll und bitten sie, es zu beschreiben.

**Wählen Sie diese:**

- **Easy on Me (von Adele)**
- **I Gotta Feeling (von The Black Eyed Peas)**

Wir möchten, dass Sie 3 bis 5 Ausdrücke für das gewählte Lied in Ihren Sprechblasen angeben. Zum Beispiel:

- **The one with the piano music**
- **The song that's not energetic**
- **It has something about a river**
- **The newer one**
- **It's about not having time to choose**

---

#### Zufällige Beispiele

**Musikauswahl**

- Bedeutest du 'Chime' oder 'Your Loving Arms'? ➞ Das ohne Worte.
- Bedeutest du 'These Kids' oder 'Inescapable'? ➞ Es ist das Lied von einem Australier.
- Bedeutest du 'Rock the Boat' oder 'Wherever You Are'? ➞ Es hat Synthesizer-Sounds.
- Bedeutest du 'Telepathy' oder 'Stars on 45'? ➞ Es kam Mitte der 2000er heraus.
- Bedeutest du 'Mis-Shapes' oder 'Remind Me'? ➞ Basierend auf Erfahrungen in Sheffield.

**Buchauswahl**

- Bedeutest du 'Warlock (Hall-Buch)' oder 'Warlock (Smith-Buch)'? ➞ Das, das im 19. Jahrhundert spielt.
- Bedeutest du 'The Legion of Space' oder 'The Body in the Library'? ➞ Es ist von einem berühmten Detektivautor.
- Bedeutest du 'The Good Soldier' oder 'The Good Soldiers'? ➞ Das fiktive Buch.
- Bedeutest du 'The Giaour' oder 'The Giver'? ➞ Das Buch mit Rock und Politik.
- Bedeutest du 'Broken Sleep' oder 'Broken Soup'? ➞ Es ist das Buch über Rock und Politik.

**Rezeptauswahl**

- Bedeutest du 'Beurre Maître d'Hôtel' oder 'Chigirtma'? ➞ Kommt aus Aserbaidschan.
- Bedeutest du 'Kusa mochi' oder 'Uiré'? ➞ Das japanische gesteckte Kuchenrezept.
- Bedeutest du 'Cannoli' oder 'Boconotto'? ➞ Diejenigen, die am Weihnachten gegessen werden.
- Bedeutest du 'Sagu' oder 'Mamul'? ➞ Das Rezept für Maisbrei.
- Bedeutest du 'Sagú' oder 'Mamul'? ➞ Das Rezept für Maisbrei.

---

Diese Übersetzung deckt den englischen Text ab und bringt ihn in die deutsche Sprache um, wobei die Struktur und die Bedeutung der einzelnen Punkte beibehalten wird.</sample>
    <sample id="469">AltEntities Corpus

- ~6.000 alternative Fragen über drei Domänen
- ~42.000 indirekte Bezugsexpressionen

Ergebnisse mit T5 XL Modell (Genauigkeit):
- 92–95% wenn das LM dieselbe Hintergrundwissen wie die Annotatoren hat.
- 82–87% wenn das LM teilweise überschneidendes Hintergrundwissen hat.
- ~60% wenn das LM (T5 XL) nur Zugang zu den Entity-Namen hat.
- Wir zeigten, dass Modelle domänengenerell sind.

Dataset Link: [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)</sample>
    <sample id="470">AltEntities Corpus
- ~6.000 alternative Fragen über drei Domänen
- ~42.000 indirekte Bezugsexpressionen

Ergebnisse mit dem T5 XL Modell (Genauigkeit):
- 92–95% wenn das LM dieselbe Hintergrundwissen wie die Annotatoren hat.
- 82–87% wenn das LM teilweise überschneidendes Hintergrundwissen hat.
- ~60% wenn das LM (T5 XL) nur Zugang zu den Entity-Namen hat.
- Wir haben gezeigt, dass Modelle domänenspezifisch sind.

Dataset Link: [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)</sample>
    <sample id="471">AltEntities Corpus

- ~6,000 alternative Fragen über drei verschiedene Domänen
- ~42,000 indirekte Bezugsexpressionen

Ergebnisse mit dem T5 XL Modell (Genauigkeit):
- 92–95% wenn das LM dieselbe Hintergrundwissen wie die Annotatoren hat.
- 82–87% wenn das LM teilweise überschneidendes Hintergrundwissen hat.
- ~60% wenn das LM (T5 XL) nur Zugang zu den Entity-Namen hat.
- Wir haben gezeigt, dass Modelle allgemein anwendbar sind.

Dataset-Link: [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)</sample>
    <sample id="472">Natürlich, hier ist der übertragene Inhalt in die deutsche Sprache:

---

**AltEntities Corpus**

- ~6.000 alternative Fragen über drei verschiedene Domänen
- ~42.000 indirekte Bezugsexpressionen

**Ergebnisse mit dem T5 XL Modell (Genauigkeit):**
- 92–95% wenn das LM dieselbe Hintergrundwissen wie die Annotatoren hat.
- 82–87% wenn das LM teilweise überschneidendes Hintergrundwissen hat.
- ~60% wenn das LM (T5 XL) nur Zugang zu den Entity-Namen hat.
- Wir haben gezeigt, dass Modelle domänengenerell sind.

**Dataset Link:** [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)

---

**Danke!**

Wenn Sie Fragen haben, senden Sie eine E-Mail an javadh@google.com.</sample>
    <sample id="473">Der Ansatz wird mit den bestehenden SimulST-Richtlinien "wait-k", "LA" und "CAAT" verglichen.</sample>
    <sample id="474">The authors are affiliated with Nantes University and Avignon University.</sample>
    <sample id="475">Der Referent*in ist Jenny T. Liang.</sample>
    <sample id="476">Es sind drei Autoren an der Arbeit beteiligt: Myra Cheng, Esin Durmus und Dan Jurafsky.</sample>
    <sample id="477">Aufmerksamkeit als Leitfaden für die gleichzeitige Sprachübersetzung

Sara Papi, Matteo Negri, Marco Turchi</sample>
    <sample id="478">Der englische Text lautet:

"Simultaneous speech translation (SimulST) is the process of translating spoken language into a text in another language in real-time, enabling cross-language communication."

Übersetzt auf Deutsch bedeutet das:

"Synchroner Sprachübersetzung (SimulST) ist der Prozess des Echtzeit-Übersetzens gesprochener Sprache in einen Text einer anderen Sprache, der die grenzüberschreitende Kommunikation ermöglicht."</sample>
    <sample id="479">Was sind die Probleme der aktuellen SimulST-Modelle?

Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche Module optimiert werden.</sample>
    <sample id="480">Was sind die Probleme der aktuellen SimulST-Modelle?

Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche Module optimiert werden.

Lange und komplizierte Trainingsverfahren (z.B., verschiedene Optimierungsziele)</sample>
    <sample id="481">Was sind die Probleme der aktuellen SimulST-Modelle?

Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche Module optimiert werden.

Lange und komplizierte Trainingsverfahren (z.B., verschiedene Optimierungsziele)

Trainieren und Unterhalten mehrerer Modelle, um verschiedene Latenzregimes zu erreichen (z.B., 1s, 2s, ...)</sample>
    <sample id="482">Der englische Text lautet "What is our solution?" und übersetzt sich auf Deutsch zu "Was ist unsere Lösung?"</sample>
    <sample id="483">Was ist unsere Lösung?

01 Verwenden Sie bereits vorhandene offline ST-Modelle ohne Neutrainieren oder Anpassung einer spezifischen Architektur für SimulST

02 Verwenden Sie nur ein Modell für jede Latenzstufe und handhaben Sie die Latenz durch spezifische Parameter</sample>
    <sample id="484">Was ist unsere Lösung?

01 Verwenden Sie bereits vorhandene offline ST-Modelle ohne Neutrainieren oder Anpassung einer spezifischen Architektur für SimulST.

02 Verwenden Sie nur ein Modell für jeden Latenzmodus und handhaben Sie die Latenz durch spezifische Parameter.

03 Nutzen Sie das Wissen, das der Modell bereits durch die Aufmerksamkeitsmechanismen zwischen audiolem Eingang und textuellem Ausgang erworben hat.</sample>
    <sample id="485">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschließen Sie sich, ob eine Teilübersetzung ausgestrahlt wird oder nicht, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) in den letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.</sample>
    <sample id="486">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschließen Sie sich, ob eine vollständige oder eine partielle Übersetzung ausgestrahlt wird, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.</sample>
    <sample id="487">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschieden, ob eine vollständige oder eine partielle Übersetzung ausgestrahlt wird, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde darüber sprechen...</sample>
    <sample id="488">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschieden, ob eine vollständige oder eine partielle Übersetzung ausgestrahlt wird, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde reden.</sample>
    <sample id="489">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschieden, ob eine vollständige oder eine partielle Übersetzung ausgestrahlt wird, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde reden.</sample>
    <sample id="490">Unser Lösungsansatz: EDAtt

Entschieden, ob eine Teiltraduktion ausgestrahlt wird oder nicht, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde sprechen.</sample>
    <sample id="491">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschieden, ob eine vollständige oder eine partielle Übersetzung emittiert wird, basierend auf dem, wo die Aufmerksamkeit zeigt:

Ein Wort wird emittiert, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde sprechen.
EMITTED</sample>
    <sample id="492">Unser Lösungsansatz: EDAtt

Encoder-Decoder Attention

Entschieden, ob eine Wörterausgabe oder eine partielle Übersetzung erfolgt, basierend auf dem Fokus der Aufmerksamkeit:
Ein Wort wird ausgegeben, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

01: Ich werde reden.
02: Ich werde über Klima sprechen.</sample>
    <sample id="493">Unser Lösungsansatz: EDAtt

Encoder-Decoder Attention

Entschieden, ob eine Wörterausgabe oder ein Teilübersetzung erfolgt, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgegeben, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

01: Ich werde reden.
02: Ich werde über Klima sprechen.</sample>
    <sample id="494">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschließen Sie sich, ob eine Teilübersetzung ausgestrahlt wird oder nicht, basierend auf dem Aufmerksamkeitspunkt:
Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

01: Ich werde reden.
02: Ich werde über Klima sprechen.</sample>
    <sample id="495">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de"</sample>
    <sample id="496">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de"</sample>
    <sample id="497">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de
latency measure"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de
Verzögerungsmaß"</sample>
    <sample id="498">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de"</sample>
    <sample id="499">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de"

Übersetzt ins Deutsche bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de"</sample>
    <sample id="500">Der englische Text lautet:

"Main Results: EDAtt
popular strategies also applied to offline models
state of the art architecture specifically tailored for SimulST"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse: EDAtt
populäre Strategien werden auch auf Offline-Modelle angewendet
zur Zeit beste Architektur speziell für SimulST abgestimmt"</sample>
    <sample id="501">Der englische Text lautet:

"Main Results:
EDAtt

state of the art architecture specifically tailored for SimulST

wait-k  LA  CAAT  EDAtt

BLEU
27
25
23
21
19
17
0.5  1   1.5  2    2.5  3   3.5  4   4.5  5
AL / AL_CA (s)

(a) en→de"

Übersetzt ins Deutsche:

"Hauptergebnisse:
EDAtt

zurzeit beste Architektur speziell für SimulST

wait-k  LA  CAAT  EDAtt

BLEU
27
25
23
21
19
17
0.5  1   1.5  2    2.5  3   3.5  4   4.5  5
AL / AL_CA (s)

(a) en→de"</sample>
    <sample id="502">Der englische Text lautet:

"Main Results:
EDAtt

EDAtt outperforms all the strategies applied to offline models"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

EDAtt übertrifft alle Strategien, die auf Offline-Modelle angewendet wurden"</sample>
    <sample id="503">Der englische Text lautet:

"Main Results:
EDAtt

EDAtt outperforms all the strategies applied to offline models

EDAtt is the fastest strategy if we consider the actual elapsed time"

Übersetzt auf Deutsch:

"Hauptergebnisse:
EDAtt

EDAtt übertrifft alle Strategien, die auf Offline-Modelle angewendet wurden

EDAtt ist die schnellste Strategie, wenn wir den tatsächlichen verstrichenen Zeitraum berücksichtigen"</sample>
    <sample id="504">Hier ist die Übersetzung des englischen Inhalts in Deutsch:

"Willst du mehr entdecken?
Lesen Sie unsere Arbeit, um weitere Ergebnisse zu entdecken!

E-Mail: {spapi,negri}@fbk.eu
marco.turchi@gmail.com

GitHub: github.com/hlt-mt/fbk-fairseq

Twitter: @fbk_mt
@sarapapi

QR-Code scannen!"</sample>
    <sample id="505">Ja, der Datensatz ist öffentlich zugänglich.</sample>
    <sample id="506">Der Titel lautet: "MULTIINSTRUCT: Verbessern von Multi-Modalen Null-Shot-Learning durch Anweisungstuning"

Die Autoren sind:
- Zhiyang Xu*
- Ying Shen*
- Lifu Huang

Sie gehören zum Department of Computer Science, Virginia Tech.

*Gleiche Beiträge</sample>
    <sample id="507">### Prätrainierte Sprachmodelle für Aufgaben der Niedrigstufe

#### (A) Prätraining und Feinabstimmung (BERT, T5)
- **Prätrainiertes LM**
  - **Feinabstimmung auf Aufgabe A**
  - **Inferenz auf Aufgabe A**
  - *Typischerweise benötigt viele spezifische Beispiele für Aufgaben.*
  - *Ein spezialisiertes Modell für jede Aufgabe.*

#### (B) Prompting (GPT-3)
- **Prätrainiertes LM**
  - **Verbessern des Leistungsvermögens durch few-shot Prompting oder Prompt Engineering**
  - **Inferenz auf Aufgabe A**

#### (C) Anweisungsabstimmung (FLAN)
- **Prätrainiertes LM**
  - **Anweisungsabstimmung auf viele Aufgaben: B, C, D, ...**
  - *Modell lernt, viele Aufgaben über natürliche Sprachanweisungen auszuführen.*
  - **Inferenz auf unbekannte Aufgabe**

**Abbildung 2:** Vergleich von Anweisungsabstimmung mit Prätraining und Feinabstimmung sowie Prompting.

**Bildnachweis:** Wei, Jason, et al. "Finetuned language models are zero-shot learners."</sample>
    <sample id="508">### Prätrainierte Sprachmodelle für Aufgaben der Niedrigstufe

#### (A) Prätraining und Feinabstimmung (BERT, T5)
- **Prätrainiertes LM**
  - **Feinabstimmung auf Aufgabe A**
  - **Inferenz auf Aufgabe A**
  - *Typischerweise benötigt viele exemplarische Beispiele für jede Aufgabe.*
  - *Ein spezialisiertes Modell für jede Aufgabe.*

#### (B) Prompting (GPT-3)
- **Prätrainiertes LM**
  - **Verbessern des Leistungsgrades durch few-shot Prompting oder Prompt Engineering**
  - **Inferenz auf Aufgabe A**

#### (C) Anweisungsabstimmung (FLAN)
- **Prätrainiertes LM**
  - **Anweisungsabstimmung auf viele Aufgaben: B, C, D, ...**
  - *Modell lernt, viele Aufgaben über natürliche Sprachanweisungen auszuführen.*
  - **Inferenz auf unbekannte Aufgabe**

**Abbildung 2:** Vergleich von Anweisungsabstimmung mit Prätraining und Feinabstimmung sowie Prompting.

**Bildnachweis:** Wei, Jason, et al. "Finetuned language models are zero-shot learners."</sample>
    <sample id="509">Der Text "Language-only" bedeutet auf Deutsch "Sprache nur".</sample>
    <sample id="510">Der Text auf dem Bild lautet: "Instruction Tuning on Multimodal Pre-trained Models". Dies bedeutet auf Deutsch:

"Instruktionsanpassung an multimodalen prätrainierten Modellen"</sample>
    <sample id="511">Der Text auf dem Bild lautet: "Unausgewogene Datenmengen in Anweisungsdatensätzen zwischen NLP und Multimodal".</sample>
    <sample id="512">Der Inhalt des Bildes lautet auf Deutsch:

"Unausgewogene Datenmengen in Anweisungsdatensätzen zwischen NLP und Multimodal

1600+ Sprachnur-Anweisungsaufgaben

KEINE großskaligen, öffentlich verfügbaren multimodalen Anweisungsaufgaben"</sample>
    <sample id="513">**MULTIINSTRUCT**

Das erste multimodale Anweisungstuning Benchmark-Dataset

**Abbildung 2: Aufgabenbereiche in MULTIINSTRUCT. Die gelben Boxen repräsentieren Aufgaben, die für die Bewertung verwendet werden, während die weißen Boxen Aufgaben für das Training angeben.**

- 62 verschiedene multimodale Aufgaben
- 10 breite Gruppen
- 5 von Experten geschriebene Anweisungen</sample>
    <sample id="514">**MULTIINSTRUCT**

Das erste multimodale Anweisungstuning Benchmark-Dataset

**Abbildung 2: Aufgabenbereiche in MULTIINSTRUCT. Die gelben Boxen repräsentieren Aufgaben, die für die Bewertung verwendet werden, während die weißen Boxen Aufgaben für das Training angeben.**

- 62 verschiedene multimodale Aufgaben
- 10 breite Gruppen
- 5 von Experten verfasste Anweisungen</sample>
    <sample id="515">OFA (One For All)

- Ein einheitliches multimodales prä-gespeichertes Modell, das in der Lage ist, sowohl Verstehens- als auch Generierungsaufgaben mit einer oder mehreren Modalitäten auszuführen.
- OFA hat eine einheitliche Vokabularbasis für Sprache, Bild-Token und die Koordinaten eines Bounding-Boxenrahmens.</sample>
    <sample id="516">Der Inhalt des Bildes lautet auf Deutsch:

**MULTIINSTRUCT**

**Beispielinstanzen von MULTIINSTRUCT für vier Aufgaben.**

1. **Begründete Caption**
   - **Eingabe:** Erstelle eine Caption für &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Ausgabe:** Blauer und weißer Tennisschläger.

2. **Text Lokalisation**
   - **Eingabe:** Wählen Sie die Region, die das Wort "den" enthält.
   - **Optionen:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Ausgabe:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referierende Ausdrucksauswahl**
   - **Eingabe:** Wählen Sie die Region des Objekts aus, das durch "Ein blauer Zug im Vordergrund" beschrieben wird.
   - **Optionen:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Ausgabe:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Frage-Bild Matching**
   - **Eingabe:** Gegeben das Bildinhalt, haben Sie genügend Informationen, um die Frage "Ist es ein sonniger Tag?" zu beantworten?
   - **Optionen:** "Die Frage ist relevant zum Bild" oder "Die Frage ist irrelevant zum Bild"
   - **Ausgabe:** Die Frage ist irrelevant zum Bild</sample>
    <sample id="517">Der Inhalt des Bildes lautet auf Deutsch:

**MULTIINSTRUCT**

**Beispielinstanzen von MULTIINSTRUCT für vier Aufgaben.**

1. **Begründete Caption**
   - **Eingabe:** Erstelle eine Caption für &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Ausgabe:** Blauer und weißer Tennisschläger.

2. **Text Lokalisation**
   - **Eingabe:** Wählen Sie die Region, die das Wort "den" enthält.
   - **Optionen:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Ausgabe:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referierende Ausdrucksauswahl**
   - **Eingabe:** Wählen Sie die Region des Objekts aus, das durch "Ein blauer Zug im Vordergrund" beschrieben wird.
   - **Optionen:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Ausgabe:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Frage-Bild Matching**
   - **Eingabe:** Gegeben das Bildinhalt, haben Sie genügend Informationen, um die Frage "Ist es ein sonniger Tag?" zu beantworten?
   - **Optionen:** "Die Frage ist relevant zum Bild" oder "Die Frage ist irrelevant zum Bild"
   - **Ausgabe:** Die Frage ist irrelevant zum Bild.</sample>
    <sample id="518">Das Bild zeigt eine Präsentation mit dem Titel "MULTIINSTRUCT". Es enthält vier Beispiele für Aufgaben, die von der Plattform MULTINSTRUCT bearbeitet werden können:

1. **Grounded Caption (Begründete Kapitulation)**
   - **Input:** Erstelle eine Beschreibung für &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Output:** Blauer und weißer Tennis-Schläger.

2. **Text Localization (Textortung)**
   - **Input:** Wählen Sie die Region, die das Wort "den" enthält.
   - **Options:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; &lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Output:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referring Expression Selection (Referenzexpressionenauswahl)**
   - **Input:** Wählen Sie die Region des Objekts aus, das durch "Ein blauer Zug im Vordergrund" beschrieben wird.
   - **Options:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; &lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; &lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Output:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Question-Image Matching (Frage-Bild-Matching)**
   - **Input:** Gegeben das Bildinhalt, haben Sie genügend Informationen, um die Frage "Ist es ein sonniger Tag?" zu beantworten?
   - **Options:** "Die Frage ist relevant zum Bild" oder "Die Frage ist irrelevant zum Bild"
   - **Output:** Die Frage ist irrelevant zum Bild.

Unter dem Diagramm steht: "Figure 1: Example Instances from MULTIINSTRUCT for Four Tasks."</sample>
    <sample id="519">Der Text "Multi-modal Instruction Tuning" bedeutet auf Deutsch "Mehrmodales Anweisungstuning".</sample>
    <sample id="520">### Multi-Modale Anweisungsumwandlung

- **Trainingsdatensatz-Bau:**
  - Verwenden Sie 53 Aufgaben aus 9 Gruppen für die Ausbildung.
  - Stellen Sie pro Aufgabe 10.000 Instanzen ein.

- **Testdatensatz-Bau:**
  - Reservieren Sie die gesamte Gruppe "Commonsense Reasoning" für den Test.
  - Wählen Sie zusätzliche 5 Aufgaben aus den Gruppen VQA und Miscellaneous aus.
  - Wir verwenden alle Instanzen im Testsplit für jede Aufgabe.
  - Zufällig aus dem Testsplit des Datensatzes "Natural Instructions" 20 Aufgaben als unbekannte Aufgaben für NLP auswählen.</sample>
    <sample id="521">### Multi-Modale Anweisungsumwandlung

- **Trainingsdatensatz-Konstruktion:**
  - Verwenden Sie 53 Aufgaben aus 9 Gruppen für die Ausbildung.
  - Stellen Sie pro Aufgabe 10.000 Instanzen ein.

- **Testdatensatz-Konstruktion:**
  - Reservieren Sie die gesamte Gruppe "Commonsense Reasoning" für den Test.
  - Wählen Sie zusätzliche 5 Aufgaben aus den Gruppen VQA und Miscellaneous aus.
  - Wir verwenden alle Instanzen im Testsplit für jede Aufgabe.
  - Zufällig auswählen Sie 20 Aufgaben aus dem Testsplit des Datensatzes "Natural Instructions" als unbekannte Aufgaben für NLP.</sample>
    <sample id="522">### Implementierungsdetails

- **Trainingsdetails:**
  - Vortrainierter OFA-Large-Modell (472M)
  - Mischen aller Instanzen für alle Aufgaben.
  - Jede Instanz wird zufällig mit einer von ihren fünf Anweisungsschablonen kombiniert.

- **Testdetails:**
  - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment evaluieren.
  - Wir berichten über das Durchschnittsleistung und das maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="523">### Implementierungsdetails

- **Trainingsdetails:**
  - Vortrainierter OFA-Large-Modell (472M)
  - Mischen aller Instanzen für alle Aufgaben.
  - Jede Instanz wird zufällig mit einer von ihren fünf Anweisungsschablonen kombiniert.

- **Testdetails:**
  - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment evaluieren.
  - Wir berichten über das Durchschnittsleistung und maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="524">### Implementierungsdetails

- **Trainingsdetails:**
  - Vortrainierter OFA-Large-Modell (472M)
  - Mischen aller Instanzen für alle Aufgaben.
  - Jede Instanz wird zufällig mit einer von ihren fünf Anweisungsschablonen kombiniert.

- **Testdetails:**
  - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment evaluieren.
  - Wir berichten über das Durchschnitts- und maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="525">### Bewertungsmetriken

- Für **multi-modale Klassifizierungsaufgaben** (Visuelle Implikation, visuelles räumliches Denken, natürliche Sprache visuelles Denken und Katastrophentypen-Klassifikation) berichten wir die **Genauigkeit**.
- Für **multi-modale Generierungsaufgaben** (Allgemeinwissen VQA, Text VQA, Bodengebundene VQA, visuelle Textextraktion und visuelles Dialog) berichten wir die **Rouge-L**.
- Für **NLP-Aufgaben** berichten wir **Rouge-L**.

- Wir berechnen auch das **aggregierte Leistungsbewertung** für jedes Modell basierend auf dem Mittel der Modellsleistung auf allen multimodalen und NLP-unbekannten Aufgaben. Wir verwenden **Rouge-L** als Leistungswert für die meisten Aufgaben und **Genauigkeit** für Aufgaben, bei denen nur Genauigkeit als Maßstab verwendet wird.</sample>
    <sample id="526">### Sensitivität

Wie sensibel ist das Modell auf die Vielfalt von Anweisungen für die gleiche Aufgabe:

- Fähigkeit, für dieselbe Aufgabe immer die gleichen Ergebnisse zu erzeugen, unabhängig von geringfügigen Variationen in der Formulierung der Anweisungen.

### Effektivität des Anweisungsabstimmens auf MULTIIINSTRUCT

Tabelle 1: Zero-Shot-Performance im Bereich Multimodaler Alltagsvernunft. Das beste Ergebnis ist fett hervorgehoben.

| Modell | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|--------|----------------|-------------------|--------------------------|-------|
| OFA    | 17.93          | 14.97 ± 4.30      | 0.73                     | 49.99 | 41.86 ± 10.99 |
| OFATaskName | -              | 29.01             | -                        | 55.70 | -             |
| OFAMultiInstruct | 52.01         | 50.60 ± 1.12      | 33.01                    | 55.96 | 53.90 ± 1.38  |
| OFANaturalInstruct | 27.15        | 14.99 ± 9.12      | 7.35                     | 33.28 | 14.86 ± 16.68 |
| OFAMixedInstruct | 50.40        | 49.34 ± 1.04      | 31.31                    | 54.63 | 53.74 ± 0.97  |
| OFASeqInstruct | 50.93        | 50.07 ± 1.07      | 32.28                    | 53.66 | 52.98 ± 0.56  |

Tabelle 2: Zero-Shot-Performance im Bereich Fragebeantwortung und Allgemeines. Das beste Ergebnis ist fett hervorgehoben.

| Modell | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|--------|----------|--------------|-----------------------|----------------|----------------------------|
| OFA    | 15.21    | 9.30 ± 5.42  | 0.02                  | 36.31          | 28.71 ± 9.81               |
| OFATaskName | -        | -            | -                     | 36.30          | -                          |
| OFAMultiInstruct | 27.22   | 26.46 ± 0.83 | 46.32                 | 74.35          | 32.91 ± 7.59               |
| OFANaturalInstruct | 5.59     | 5.40 ± 0.24  | 0.00                  | 5.65           | 27.91 ± 2.16               |
| OFAMixedInstruct | 24.15    | 23.67 ± 0.47 | 63.79                 | 62.43          | 46.56 ± 14.92              |
| OFASeqInstruct | 27.03    | 26.67 ± 0.47 | 64.19                 | 71.63          | 60.62 ± 12.31              |</sample>
    <sample id="527">Die Wirksamkeit der Anweisungstuning auf MULTIINSTRUCT

Tabelle 1: Zero-Shot Performance auf multimodalem Alltagswissen. Die beste Leistung ist in Fettschrift hervorgehoben.

| Modell | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|--------|-----------------|-------------------|--------------------------|------|
| Max    | Avg ± Std       | Max              | Avg ± Std                | Max  |
| OFA    | 17,93           | 14,97 ± 4,30      | 0,73                      | 56,06 |
| OFATaskName | -              | -                | -                        | -    |
| OFAMultiInstruct | 52,01          | 50,60 ± 1,12      | 33,01                    | 55,81 |
| OFANaturalInstruct | 27,15          | 14,99 ± 9,12      | 7,35                      | 51,44 |
| OFAMixedInstruct | 50,40          | 49,34 ± 1,04      | 31,31                    | 55,13 |
| OFASeqInstruct | 50,93          | 50,07 ± 1,07      | 32,28                    | 54,86 |

Tabelle 2: Zero-Shot Performance auf Fragebeantwortung und allgemeinen Aufgaben. Die beste Leistung ist in Fettschrift hervorgehoben.

| Modell | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|--------|----------|--------------|-----------------------|----------------|----------------------------|
| Max    | Avg ± Std | Max          | Avg ± Std             | Max            | Max                        |
| OFA    | 15,21    | 9,30 ± 5,42   | 0,02                  | 45,46          | 14,30                      |
| OFATaskName | -        | -            | -                     | 25,18          | 62,65                      |
| OFAMultiInstruct | 27,22    | 26,46 ± 0,83  | 46,32                 | 46,38          | 64,88                      |
| OFANaturalInstruct | 5,59     | 5,40 ± 0,24   | 0,00                  | 30,94          | 56,64                      |
| OFAMixedInstruct | 24,15    | 23,67 ± 0,47  | 63,79                 | 46,08          | 68,31                      |
| OFASeqInstruct | 27,03    | 26,67 ± 0,47  | 64,19                 | 46,17          | 64,46                      |

Tabelle 1: Zero-Shot Performance auf multimodalem Alltagswissen. Die beste Leistung ist in Fettschrift hervorgehoben.

Tabelle 2: Zero-Shot Performance auf Fragebeantwortung und allgemeinen Aufgaben. Die beste Leistung ist in Fettschrift hervorgehoben.</sample>
    <sample id="528">Die Wirksamkeit der Anweisungstuning auf MULTIINSTRUCT

Tabelle 1: Zero-Shot-Performance auf multimodalem Alltagswissen. Die beste Leistung ist in Fettschrift hervorgehoben.

| Modell | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|--------|-----------------|-------------------|--------------------------|------|
| Max    | Avg ± Std       | Max              | Avg ± Std                | Max  |
| OFA    | 17,93           | 14,97 ± 4,30      | 0,73                     | 0,40 ± 0,29 |
| OFATaskName | -              | -                | 29,01                    | -    |
| OFAMultiInstruct | 52,01          | 50,60 ± 1,12      | 33,01                    | 31,17 ± 1,59 |
| OFANaturalInstruct | 27,15          | 14,99 ± 9,12      | 7,35                     | 2,04 ± 3,01 |
| OFAMixedInstruct | 50,40          | 49,34 ± 1,04      | 31,31                    | 30,27 ± 0,94 |
| OFASeqInstruct | 50,93          | 50,07 ± 1,07      | 32,28                    | 31,23 ± 1,09 |

Tabelle 2: Zero-Shot-Performance auf Fragebeantwortung und andere Aufgaben. Die beste Leistung ist in Fettschrift hervorgehoben.

| Modell | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|--------|----------|--------------|-----------------------|----------------|----------------------------|
| Max    | Avg ± Std | Max         | Avg ± Std             | Max            | Avg ± Std                  |
| OFA    | 15,21    | 9,30 ± 5,42  | 0,02                  | 0,00 ± 0,01    | 14,30                      |
| OFATaskName | -        | -           | 0,00                  | -              | 9,64 ± 4,34                |
| OFAMultiInstruct | 27,22   | 26,46 ± 0,83 | 46,32                 | 47,22 ± 23,08  | 56,00 ± 12,96              |
| OFANaturalInstruct | 5,59     | 5,40 ± 0,24  | 0,00                  | 0,00 ± 0,00    | 56,64                      |
| OFAMixedInstruct | 24,15    | 23,67 ± 0,47 | 63,79                 | 54,99 ± 18,16  | 68,31                      |
| OFASeqInstruct | 27,03    | 26,67 ± 0,47 | 64,19                 | 54,46 ± 15,96  | 68,31                      |</sample>
    <sample id="529">Der Titel lautet: "Einfluss der Zunahme von Multimodalen Aufgabencluster für die Anweisung"

- Bilderkennung (Img Und)
  - VQA + Bilderkennung

- Bodenlegung (Grounding)
  - Bodenlegungsmatching + Bodenlegungsgenerierung

- MISC, ITM
  - Temporales Ordnungsmatching + Verschiedenes + Bildtext-Matching

- Beziehung (Relation)
  - Visuelle Beziehungen

- Region (Region)
  - Regionenkenntnis

- NLP (NLP)
  - NLP-Aufgaben</sample>
    <sample id="530">Der Effekt vielfältiger Anweisungen auf die Anpassung von Anweisungen

- OFA, der auf 5 Anweisungen finetuned wurde, erreicht viel höher aggregierte Leistung bei allen Evaluierungsaufgaben und zeigt geringere Sensitivität.

Tabelle 3: Der Effekt unterschiedlicher Anzahl von Anweisungen.
Leistung von OFAMultiInstruct, finetuned auf verschiedene Anzahl von Anweisungen.</sample>
    <sample id="531">Wirkung von Feinabstimmungsstrategien auf Modellempfindlichkeit

- Die Feinabstimmung auf MultiInstruct kann die Empfindlichkeit von OFA signifikant reduzieren.
- Das Transfer-Learning aus dem Natural Instructions-Datensatz kann die Empfindlichkeit des Modells weiter reduzieren.

Abbildung 4: Modellempfindlichkeit bei unbekannten Evaluierungsaufgaben. Ein niedrigerer Wert ist besser.</sample>
    <sample id="532">### Leistung bei NLP-Aufgaben im Null-Shot-Setting

- Die Anpassung der Anweisungen an MultiInstruct kann die Leistung bei unbekannten NLP-Aufgaben verbessern.
- Die Transfer-Learning-Strategie MixedInstruct kann am besten die erlangte Null-Shot-Fähigkeit auf dem Natural Instructions-Datensatz beibehalten.

Tabelle 4: Leistung bei NLP-Aufgaben im Null-Shot-Setting. Die Leistung wird in Rouge-L gemessen und die beste Leistung ist fett hervorgehoben.

| Modell | RougeL |
|--------|--------|
| OFA    | 2.25   |
| OFAMultiInstruct | 12.18  |

| Transfer Learning aus NATURAL INSTRUCTIONS |
|-------------------------------------------|
| OFANaturalInstructions | 43.61  |
| OFAMixedInstruct        | 43.32  |
| OFASeqInstruct          | 30.79  |</sample>
    <sample id="533">### Schlussfolgerung

- Erste große skalare multimodale Anweisungsabstimmungsdatensatz.
  - Enthält 62 multimodale Aufgaben aus 10 breiten Kategorien.
- Signifikant verbessern die zero-shot Fähigkeiten von OFA durch Anweisungsabstimmung.
- Erforschen mehrere Transfer-Learning-Techniken und zeigen ihre Vorteile.
- Entwerfen einer neuen Messkriteriumsensitivität.</sample>
    <sample id="534">Hier ist die Übersetzung des Inhalts aus dem Englischen ins Deutsche:

---

Eines mehr!

Wir sammeln eine viel größere multimodale Anweisungsaufgaben-Datenbank mit etwa 150 zusätzlichen visuell-linguistischen Aufgaben und werden sie bald veröffentlichen!</sample>
    <sample id="535">Die Autoren Sara Papi, Matteo Negri und Marco Turchi gehören der Universität Trento an.</sample>
    <sample id="536">Der Referent ist Mohammad Javad Hosseini.</sample>
    <sample id="562">Der Inhalt des Bildes lautet auf Deutsch:

"Sprachmodell-Acceptabilitätsurteile sind nicht immer robust gegenüber Kontext"

ACL 2023

Koustuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Misra, Keren Fuentes, Roger Levy, Adina Williams</sample>
    <sample id="563">Der Inhalt des Bildes lautet auf Deutsch:

"Sprachmodell-Acceptabilitätsurteile sind nicht immer robust gegenüber Kontext"

ACL 2023

Koustuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Misra, Keren Fuentes, Roger Levy, Adina Williams</sample>
    <sample id="564">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich gegenseitig.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypische Satz.
2. Nicht-stereotypischer Satz.

P(1) &gt; P(2)</sample>
    <sample id="565">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypische Satz.
2. Nicht-stereotypischer Satz.

P(1) &gt; P(2)</sample>
    <sample id="566">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypische Satz.
2. Nicht-stereotypischer Satz.

P(1) &gt; P(2)</sample>
    <sample id="567">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich gegenseitig.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypische Satz.
2. Nicht-stereotypischer Satz.

P(1) &gt; P(2)</sample>
    <sample id="568">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Frauen sind schlecht bei Handwerk.
2. Männer sind schlecht bei Handwerk.

P(1) &gt; P(2)

**Sind diese Urteile stabil mit langem vorherigem Kontext?**</sample>
    <sample id="569">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Frauen sind schlecht bei Handwerk.
2. Männer sind schlecht bei Handwerk.

P(1) &gt; P(2)

**Sind diese Urteile stabil mit langem vorherigem Kontext?**</sample>
    <sample id="570">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Frauen sind schlecht bei Handwerk.
2. Männer sind schlecht bei Handwerk.

P(1) &gt; P(2)

**Sind diese Urteile stabil mit langem vorherigem Kontext?**</sample>
    <sample id="571">**Ansatz**

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

- **Akzeptabel**
  - \( P_{LM}(\text{Subj. Verb. Agreement} | \text{Prefix}) &gt; ? P_{LM}(\text{Mismatched} | \text{Prefix}) \)
- **Nicht akzeptabel**

**Raum der möglichen Präfixe**

- **Gefügtes**
  - Subjekt-Verb-Konsistenz
- **Nicht gefügtes**
  - Island-Effekte
  - Füllstellen
  - Bindung
  - Wikipedia

**Beispiel**

- **Akzeptabel**, **gefügt**
  - *Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden fliehen?*
  - *Wer könnte Rose vor ihrem Rückkehr zu diesem Kunden fliehen?*

- **Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkte? Was hatte Aaron während des Museumsreinigungsgeräusches gesagt? Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden fliehen?*
  - *Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkte? Was hatte Aaron während des Museumsreinigungsgeräusches gesagt? Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden fliehen?*

**BLIMP, Adjunkt-Insel**

**Modell**: GPT2, OPT Familie - 125M bis 6,7B</sample>
    <sample id="572">**Ansatz**

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

- **Akzeptabel**
  - \( P_{LM}(\text{Subj. Verb. Agreement} | \text{Prefix}) &gt; ? P_{LM}(\text{Mismatched} | \text{Prefix}) \)
- **Nicht akzeptabel**

**Raum der möglichen Präfixe**

- **Gefügtes**
  - Subjekt-Verb-Konsistenz
- **Nicht gefügtes**
  - Island-Effekte
  - Füllstellen
  - Bindung
  - Wikipedia

**Beispiel**

- **Akzeptabel**, **gefügt**
  - Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?
  - *Wer könnte Rose vor diesem Kunden zurückkehren?*

- **Was könnte Jessica vor der Erkennung dieser Scheinwerfer verkaufen? Was hatte Aaron während des Reinigens des Museums klingen? Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?*
  - *Was könnte Jessica vor der Erkennung dieser Scheinwerfer verkaufen? Was hatte Aaron während des Reinigens des Museums klingen? Wer könnte Rose vor ihrem Rückkehr zu diesem Kunden verlassen?*

**BLIMP, Adjunkt-Insel**

**GPT2, OPT Familie - 125M bis 6,7B**</sample>
    <sample id="573">**Ansatz**

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

- **Akzeptabel**
  - \( P_{LM}(\text{Subj. Verb. Agreement} | \text{Prefix}) &gt; ? P_{LM}(\text{Mismatched} | \text{Prefix}) \)
- **Nicht akzeptabel**

**Raum der möglichen Präfixe**

- **Gefügtes**
  - Subjekt-Verb-Konsistenz
- **Nicht gefügtes**
  - Island-Effekte
  - Füllstellen
  - Bindung
  - Wikipedia

**Beispiel**

- **Akzeptabel**, **gefügt**
  - "Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?"
  - "Wer könnte Rose vor ihrem Rückkehr zu diesem Kunden verlassen?"

- **Was könnte Jessica vor der Erkennung dieser Scheinwerfer verkaufen? Was hatte Aaron während des Reinigens des Museums klingen wie? Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?"

**BLIMP, Adjunkt-Insel**

**GPT2, OPT Familie - 125M bis 6,7B**</sample>
    <sample id="574">**Ansatz**

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

Die Wahrscheinlichkeit, dass ein Präfix akzeptabel ist, wird durch die Wahrscheinlichkeit, dass ein Präfix unakzeptabel ist, bestimmt:

\[ P_{LM}(\text{Prefix}) &gt; P_{LM}(\text{Prefix}) \]

**Raum der möglichen Präfixe**

- **Gefügtes**: Subjekt-Verb-Konsistenz
- **Nicht gefügtes**: Island-Effekte, Füllstellen, Bindung, Wikipedia

**Beispiel**

*Wer könnte Rose vor einem Wiederbesuch dieses Kunden fliehen?*
- *Wer könnte Rose vor diesem Kunden fliehen, bevor sie zurückkehrt?*

**Akzeptabel, gefügtes**

*Was könnte Jessica vor der Erkennung dieser Scheinwerfer verkaufen? Was hatte Aaron während des Reinigens des Museums klingen? Wer könnte Rose vor einem Wiederbesuch dieses Kunden fliehen?*
- *Was könnte Jessica vor der Erkennung dieser Scheinwerfer verkaufen? Was hatte Aaron während des Reinigens des Museums klingen? Wer könnte Rose vor einem Wiederbesuch dieses Kunden fliehen?*

**BLIMP, Adjunkt-Insel**

**GPT2, OPT Familie - 125M bis 6,7B**</sample>
    <sample id="575">**Ansatz**

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

- **Akzeptabel**
  - \( P_{LM}(\text{Subj. Verb. Agreement} | \text{Prefix}) &gt; ? P_{LM}(\text{Mismatched} | \text{Prefix}) \)
- **Unakzeptabel**
  - Beispiel: "Wer könnte Rose vor der Rückkehr zu diesem Kunden fliehen?"

**Raum der möglichen Präfixe**

- **Gefügtes**
  - Subjekt-Verb-Konsistenz
- **Nicht gefügtes**
  - Island-Effekte
  - Filter-Gaps
  - Bindung
  - Wikipedia

**Beispiel für eine unakzeptable, gefügte Frage:**
- "Wer könnte Jessica diese Strahler vor der Beachtung verkaufen? Was hatte Aaron während des Reinigens wie ein Museum geklungen? Wer könnte Rose vor der Rückkehr zu diesem Kunden fliehen?"

**BLIMP, Adjunkt-Insel**

**Modell:** GPT2, OPT-Familie - 125M bis 6,7B</sample>
    <sample id="576">**Ansatz**

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

- **Akzeptabel**
- **Unakzeptabel**

**Raum der möglichen Präfixe**

- **Gefügtes Verhältnis**
  - Beispiel: "Who might Rose flee from before returning to this customer?"
  - Beispiel: "There was a documentary about music imitating Allison. There were no legislators working hard. Who might Rose flee from before returning to this customer?"

- **Nicht gefügtes Verhältnis**
  - Beispiel: "Who might Rose flee from this customer before returning to?"
  - Beispiel: "There was a documentary about music irritating Allison. There were no legislators working hard. Who might Rose flee from this customer before returning to?"

**BLIMP, Existential "there" Quantifiers | BLIMP, Adjunct Island**

**GPT2, OPT Familie - 125M bis 6,7B**</sample>
    <sample id="577">**Ansatz**

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

- **Akzeptabel**
  - \( P_{LM}(\text{Subj. Verb. Agreement} | \text{Prefix}) &gt; ? P_{LM}(\text{Unmatched} | \text{Prefix}) \)
- **Nicht akzeptabel**
  - \( P_{LM}(\text{Unmatched} | \text{Prefix}) \)

**Raum der möglichen Präfixe**

- **Gefügtes**
  - Subjekt-Verb-Konsistenz
- **Nicht gefügtes**
  - Island-Effekte
  - Füllereignisse
  - Bindung
  - Wikipedia

**Beispiel**

- **Akzeptabel, nicht gefügtes**
  - *Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?*
  - *Wer könnte Rose vor ihrem Rückkehr zu diesem Kunden verlassen?*

- **Nicht akzeptabel, nicht gefügtes**
  - *Es gab eine Dokumentation über Musik, die Allison ärgerte. Es gab keine Regierungsmitglieder, die hart arbeiteten. Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?*
  - *Es gab jede Dokumentation über Musik, die Allison ärgerte. Es gab die meisten Regierungsmitglieder, die hart arbeiteten. Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?*

**BLIMP, Existential "there"-Quantoren | BLIMP, Adjunkt-Insel**

**GPT2, OPT Familie - 125M bis 6,7B**</sample>
    <sample id="578">**Ansatz**

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

\( P_{LM}(\text{Prefix}) &gt; ? P_{LM}(\text{Prefix}) \)

**Raum der möglichen Präfixe**

- **Eingestimmte Präfixe**
  - Subjekt-Verb-Konsistenz

- **Nicht eingestimmte Präfixe**
  - *Insel-Effekte*
  - *Füllgaps*
  - *Bindung*
  - *Wikipedia*

**Beispiel**

*Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?*
*Wer könnte Rose vor ihrem Rückkehr zu diesem Kunden verlassen?*

**Wikipedia, Unzugehörig**

*Eine Rose ist eine holzige, jährliche Blühpflanze der Gattung Rosa. Es gibt mehr als dreihundert Arten und tausende von Sorten.*
*Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?*

**GPT2, OPT Familie - 125M bis 6,7B**</sample>
    <sample id="579">**Ansatz**

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

\( P_{LM}(\text{Grüner Quadrat} \mid \text{Präfix}) &gt; ? P_{LM}(\text{Roter Quadrat} \mid \text{Präfix}) \)

**Raum der möglichen Präfixe**

- **Gefüllt**: Subjekt-Verb-Konsistenz
  - [Grüne Quadrat]
  - [Rote Quadrat]

- **Nicht gefüllt**: Verschiedene Effekte
  - [Island-Effekte]
  - [Filter-Gaps]
  - [Binding]
  - [Wikipedia]

**Beispiel**

*Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?*
- *Wer könnte Rose vor diesem Kunden zurückkehren?*

**Wikipedia, Unbeziehbar**

*Eine Rose ist eine holzige, jährlich wiederkehrende Blütenpflanze der Gattung Rosa. Es gibt mehr als dreihundert Arten und Tausende von Sorten.*
- *Wer könnte Rose vor diesem Kunden zurückkehren?*

**GPT2, OPT Familie - 125M bis 6,7B**</sample>
    <sample id="580">**Ansatz**

Testen Sie, ob die MPP-Bewertungen als Funktion der Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

\( P_{LM}(\text{Prefix}) &gt; ? P_{LM}(\text{Prefix}) \)

**Raum der möglichen Präfixe**

- **Eingestellt**: Subjekt-Verb-Konsistenz
  - [Grüne Kreise]
- **Nicht eingestellt**: [Rote Kreise]

**Beispiel**

*Wer könnte Rose vor ihrer Rückkehr zu diesem Kunden verlassen?*
- *Wer könnte Rose vor diesem Kunden zurückkehren?*

**Wikipedia, Unzugehörig**

*Eine Rose ist eine holzige, jährliche Blühpflanze der Gattung Rosa. Es gibt mehr als dreihundert Arten und tausende von Sorten.*
- *Wer könnte Rose vor ihrem Rückkehr zu diesem Kunden verlassen?*

**GPT2, OPT Familie - 125M bis 6,7B**</sample>
    <sample id="581">Die MPP-Bewertungen sind robust für arbiträre Kontextlängen.

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptable/unakzeptable; passende/ungleiche Struktur – von Längen bis zu 900 Token.

BLiMP, OPT 6.7B

A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from before returning to this customer?
* A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from this customer before returning to?</sample>
    <sample id="582">Die MPP-Bewertungen sind robust für arbiträre Kontextlängen.

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptable/unakzeptable; passende/ungleiche Struktur – von Längen bis zu 900 Token.</sample>
    <sample id="583">### Akzeptable/Nichtakzeptable MPP-Sätze im Kontext steigern/verringern die Bewertungsleistung

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/nichtakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token.

BLiMP, OPT 6.7B

### Grafik: Akzeptable/Nichtakzeptable MPP-Sätze im Kontext steigern/verringern die Bewertungsleistung

Die Grafik zeigt die Ergebnisse der MPP-Evaluierungen für verschiedene Präfix-Strategien (Akzeptable Passende, Akzeptable Unpassende, Wiki Unpassende) in Abhängigkeit von der Länge des Textes (in Token).

### Beispiele für Sätze:

1. **Akzeptable Passende:**
   - "Es gab eine Dokumentation über Musik, die Alison nachahmte. Es gab keine Regierungen, die hart arbeiteten. Wer könnte Rose vorher von diesem Kunden abziehen, bevor sie zurückkehrt?"

2. **Nichtakzeptable Passende:**
   - "Es gab jede Dokumentation über Musik, die Alison nachahmte. Es gab die meisten Regierungen, die hart arbeiteten. Wer könnte Rose vorher von diesem Kunden abziehen, bevor sie zurückkehrt?"

3. **Wiki Unpassende:**
   - "Es gab eine Dokumentation über Musik, die Alison nachahmte. Es gab keine Regierungen, die hart arbeiteten. Wer könnte Rose vorher von diesem Kunden abziehen, bevor sie zurückkehrt?"</sample>
    <sample id="584">### Akzeptable/Nichtakzeptable MPP-Sätze im Kontext erhöhen/verringern die Bewertungsleistung

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token.

BLiMP, OPT 6.7B

### Prefix-Strategie
- **Akzeptabel (passend)**: Grün
- **Nichtakzeptabel (passend)**: Blau gestrichelt
- **Wiki (unpassend)**: Grau punktiert

**Beispiele für Sätze:**
1. **Akzeptabel (passend):**
   - Es gab einen Dokumentarfilm über Musik, der Alison nachahmte. Es gab keine Regierungen, die hart arbeiteten. Wer könnte Rose vor einem Besuch bei diesem Kunden verlassen?
2. **Nichtakzeptabel (passend):**
   - Es gab jeden Dokumentarfilm über Musik, der Alison nachahmte. Es gab die meisten Regierungen, die hart arbeiteten. Wer könnte Rose vor einem Besuch bei diesem Kunden verlassen?

Diese Beispiele zeigen, wie unterschiedliche Sätze im Kontext die Bewertungsleistung beeinflussen können.</sample>
    <sample id="585">### Akzeptable/Nichtakzeptable MPP-Sätze im Kontext erhöhen/verringern die Bewertungsleistung

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token.

BLiMP, OPT 6.7B

### Akzeptable/Nichtakzeptable MPP-Sätze im Kontext erhöhen/verringern die Bewertungsleistung

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token.

BLiMP, OPT 6.7B</sample>
    <sample id="586">### Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen das Modellleistung am stärksten

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token.

BLiMP, OPT 6.7B

Prefix Strategie:
- Acc. (Matched)
- Unacc. (Matched)
- Wiki (Mismatched)

### Beispieltexte:

1. Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkte? Was hatte Aaron während des Reinigens des Museums gesagt? Wer könnte Rose vorher aus diesem Kunden flüchten lassen?
2. Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkte? Was hatte Aaron während des Reinigens des Museums gesagt? Wer könnte Rose vorher aus diesem Kunden flüchten lassen?
3. Was könnte Jessica verkaufen, bevor sie diese Scheinwerfer bemerkte? Was hatte Aaron während des Reinigens des Museums gesagt? Wer könnte Rose vorher aus diesem Kunden flüchten lassen?

### Erläuterung:

Die Grafik zeigt die Auswirkungen von akzeptablen und unakzeptablen MPP-Sätzen mit passender Struktur auf die Modellleistung. Die Ergebnisse werden für verschiedene Präfixstrategien dargestellt, wobei die grüne Linie für akzeptable, passende Sätze, die lila Linie für unakzeptable, passende Sätze und die rosa Linie für akzeptable, unpassende Sätze steht. Die Grafik verdeutlicht, dass akzeptable, passende Sätze die beste Leistung haben, während unakzeptable, passende Sätze die schlechteste Leistung zeigen.</sample>
    <sample id="587">### Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen das Modellleistung am stärksten

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token.

BLiMP, OPT 6.7B

### Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen das Modellleistung am stärksten

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token.

BLiMP, OPT 6.7B</sample>
    <sample id="588">### Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen am meisten das Modellleistung

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten – akzeptabel/unakzeptabel; passende/ungleiche Struktur – von Längen bis zu 900 Token durch.

BLiMP, OPT 6.7B

### Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen am meisten das Modellleistung

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten – akzeptabel/unakzeptabel; passende/ungleiche Struktur – von Längen bis zu 900 Token durch.

BLiMP, OPT 6.7B</sample>
    <sample id="589">Warum beeinflussen übereinstimmende Präfixe die Urteile von LM-Modellen?

Wir perturben Kontextsätze in Weise, die die relevante Struktur bewahrt, und fragen, ob Modelle gleichermaßen sensibel zu diesen Sätzen sind.

- Präfix/Suffix Adverbien: "Allerdings, &lt;sent&gt;."
- Langes Präfix Adverb: "Zunächst und vor allem, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;."
- Zitat: "Gestern sagte X, ‘&lt;sent&gt;’."</sample>
    <sample id="590">Warum beeinflussen passende Präfixe die Urteile von LM-Modellen?

Wir perturben Kontextsätze in Weise, die die relevante Struktur bewahrt und fragen, ob Modelle gleichermaßen sensibel auf diese Sätze sind.

- Präfix/Suffix Adverbien: "However, &lt;sent&gt;."
- Langes Präfix Adverb: "First and foremost, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Regardless of what X thinks about it, &lt;sent&gt;."
- Zitat: "Yesterday, X said, ‘&lt;sent&gt;’."</sample>
    <sample id="591">Warum beeinflussen passende Präfixe die Urteile von LM?

Wir perturben Kontextsätze in Weise, die relevante Struktur beibehalten, und fragen, ob Modelle gleichermaßen sensibel auf diese Sätze reagieren.

- Präfix/Suffix Adverbien: "However, &lt;sent&gt;."
- Langes Präfix Adverb: "First and foremost, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Regardless of what X thinks about it, &lt;sent&gt;."
- Zitat: "Yesterday, X said, ‘&lt;sent&gt;’."</sample>
    <sample id="592">Warum beeinflussen passende Präfixe die Urteile von LM-Modellen?

Wir perturben Kontextsätze in Weise, die die relevante Struktur beibehalten, und fragen, ob Modelle gleichermaßen sensibel auf diese Sätze sind.

- Präfix/Suffix Adverbien: "However, &lt;sent&gt;."
- Langes Präfix Adverb: "First and foremost, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Regardless of what X thinks about it, &lt;sent&gt;."
- Zitat: "Yesterday, X said, ‘&lt;sent&gt;’."

Modelle reagieren auf perturbierte Sätze in ähnlicher Weise.</sample>
    <sample id="593">Warum beeinflussen passende Präfixe die Urteile von LM-Modellen?

Wir perturben Kontextsätze in Weise, die relevante Strukturen beibehalten, und fragen, ob Modelle gleichermaßen sensibel auf diese Sätze sind.

- Präfix/Suffix Adverbien: "However, &lt;sent&gt;."
- Langes Präfix Adverb: "First and foremost, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Regardless of what X thinks about it, &lt;sent&gt;."
- Zitat: "Yesterday, X said, ‘&lt;sent&gt;’."

Modelle reagieren auf perturbierte Sätze in ähnlicher Weise.</sample>
    <sample id="594">### Schlüsselpunkte

- Sprachmodelle sind sensibel für latente syntaktische/semantische Merkmale, die sich über Sätze hinweg teilen.
- MPP-Evaluierungen mit kurzen, einzelnsatzbasierten Eingaben fangen nicht vollständig das abstrakte Wissen von LMs ein.</sample>
    <sample id="595">### Schlüsselpunkte

- Sprachmodelle sind sensibel gegenüber latenten syntaktischen/semantischen Merkmalen, die sich über Sätze hinweg teilen.
- MPP-Evaluierungen mit kurzen, einzelnsatzbasierten Eingaben fangen nicht vollständig das abstrakte Wissen von LMs ein.</sample>
    <sample id="596">### Schlüsselpunkte

- Sprachmodelle sind sensibel gegenüber latenten syntaktischen/semantischen Merkmalen, die sich über Sätze hinweg teilen.
- MPP-Evaluierungen mit kurzen, einzelnsatzbasierten Eingaben fassen nicht vollständig das abstrakte Wissen der LMs ein.</sample>
    <sample id="597">Im ersten Schritt der Methode werden die Input-Token in zwei Kategorien zugeordnet: "the" wird als "Punkt" und "girl" wird als "Tag" gekennzeichnet.</sample>
    <sample id="598">55.000</sample>
    <sample id="626">Die beste Ausrichtungsmethode für DEplain ist laut dem Bild "MASSalign".</sample>
    <sample id="627">Der Vorteil von schwach überwachtem Lernen ist, dass es die Annotierungsschwelle verringert.</sample>
    <sample id="628">Die Dokumente in DEplain-web wurden mit einer Kombination von manuellen und automatischen Alignmentmethoden ausgerichtet.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde durch die Sammlung von Reuters-Nachrichten aus dem Jahr 2020 und die Annotierung mit den CoNLL-2003-Anmerkungsrichtlinien erstellt.</sample>
    <sample id="630">Der englische Inhalt lautet:

"XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations"

Die Autoren sind:
- Yusen Zhang
- Jun Wang
- Zhiguo Wang
- Rui Zhang

Die Logos von Penn State und Amazon sind ebenfalls auf dem Bild zu sehen.</sample>
    <sample id="631">Semantische Parsen

- Semantische Parsen ist eine Aufgabe, um semantische Darstellungen von Benutzerfragen zu erstellen, wie z.B. SQL und Lambda-Kalkül.

Welche Länder in Europa haben mindestens drei Automobilhersteller?

SELECT T1.country_name
FROM countries AS T1 JOIN continents AS T2 ON T1.continent = T2.cont_id
JOIN car_makers AS T3 ON T1.country_id = T3.country
WHERE T2.continent = 'Europe'
GROUP BY T1.country_name
HAVING COUNT(*) &gt;= 3

Was für Spieler haben weniger als drei Assists in einer Saison?

(call SW.listValue ( call
SW.getProperty ( ( lambda s ( call
SW.filter( var s ) ( call
SW.ensureNumericProperty ( string num_assists ) ) (string &lt; ) ( call
SW.ensureNumericEntity ( number 3 assist ) ) ) (call SW.domain (
string player ) ) ) ( string player )
) )

Benutzerfrage und ihre entsprechende SQL (links) vs. Benutzerfrage und ihre entsprechende Lambda-Kalkül (rechts).</sample>
    <sample id="632">Cross-lingual Semantic Parsing ist eine Aufgabe, die Fragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen übersetzt.</sample>
    <sample id="633">Cross-lingual Semantic Parsing ist eine Aufgabe, bei der Fragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen übersetzt werden.</sample>
    <sample id="634">Der englische Text lautet:

"Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain natural language"

Übersetzt ins Deutsche:

"Kreuzsprachliche Semantische Parsen

- Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
  o Mangelnde Abdeckung bestimmter natürlicher Sprachen"</sample>
    <sample id="635">Der englische Inhalt lautet:

"Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain natural language"

Übersetzt ins Deutsche:

"Kreuzsprachliche Semantische Parsen

- Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
  o Mangelnde Abdeckung bestimmter natürlicher Sprache"</sample>
    <sample id="636">Der englische Text lautet:

"Cross-lingual Semantic Parsing

• Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
○ Lack of coverage on certain meaning representation"

Übersetzt ins Deutsche:

"Kreuzsprachliche Semantische Parsen

• Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
○ Mangelnde Abdeckung bestimmter Bedeutungsrepräsentationen"</sample>
    <sample id="637">Der englische Text lautet:

"Cross-lingual Semantic Parsing

• Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
   o Lack of coverage on certain meaning representation"

Übersetzt ins Deutsche:

"Kreuzsprachliche Semantische Parsen

• Bestehende CLSP-Modelle werden getrennt voneinander vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
   o Mangelnde Abdeckung bestimmter Bedeutungsrepräsentationen"</sample>
    <sample id="638">Der englische Text lautet:

"Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain neural model"

Übersetzt ins Deutsche:

"Kreuzsprachliche Semantische Parsen

- Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
  o Mangelnde Abdeckung bestimmter neuronaler Modelle"</sample>
    <sample id="639">Wir stellen eine einheitliche Datenbank XSemPLR für die multilinguale semantische Parsen in verschiedenen natürlichen Sprachen und Bedeutungsrepräsentationen zur Verfügung. Sie enthält:

- 9 Datensätze in verschiedenen Domänen
- 5 semantische Parsen Aufgaben
- 8 Bedeutungsrepräsentationen
- 22 natürliche Sprachen aus 15 Sprachfamilien</sample>
    <sample id="640">Wir stellen eine einheitliche Datenbank XSemPLR zur multilingualen semantischen Parsierung in verschiedenen natürlichen Sprachen und Bedeutungsrepräsentationen bereit. Sie enthält:
- 9 Datensätze aus verschiedenen Bereichen,
- 5 semantische Parsingsaufgaben,
- 8 Bedeutungsrepräsentationen,
- 22 natürliche Sprachen aus 15 Sprachfamilien.</sample>
    <sample id="641">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Translate-Test: Verwenden Sie die Google-Übersetzung-API, um die Quellsprache in die Zielsprache zu übersetzen. Danach verwenden Sie ein monolingualen Modell zum Trainieren und Testen.

Training

Inference

Deutsch

Englisch

Englischer Modell

SQL

Deutsch

Translate API

Englisch

Englischer Modell

SQL</sample>
    <sample id="642">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Translate-Test: Verwenden Sie die Google-Translate-API, um die Quellsprache in die Zielsprache zu übersetzen. Danach verwenden Sie einen monolingualen Modell zum Trainieren und Testen.

Training

Inference

Deutsch

Englisch

Englischer Modell

SQL

Deutsch

Translate API

Englisch

Englischer Modell

SQL</sample>
    <sample id="643">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Trainings- und Evaluationsphase.
  ○ Translate-Test: Verwenden Sie die Google-Translate-API, um die Quellsprache in die Zielsprache zu übersetzen. Danach verwenden Sie einen monolingualen Modell zur Ausbildung und Bewertung.

Training

Inference

- Englisch
- English Model
- SQL

- Deutsch
- Translate API
- Englisch
- English Model
- SQL</sample>
    <sample id="644">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Monolingual Model: Quellsprache ist die gleiche wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch den Monolingual Few-shot-Einstellung durch das Trainieren monolingualer Modelle mit nur 10% des Trainingsdatensatzes.

Training
- German (Few-shot)
- German Model
- SQL

Inferenz
- German
- German Model
- SQL</sample>
    <sample id="645">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Monolingual Model: Quellsprache ist die gleiche wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch den Monolingual Few-shot-Einstellung durch das Trainieren monolingualer Modelle mit nur 10% des Trainingsdatensatzes.

Training

- German (Few-shot)
  - German Model
  - SQL

Inferenz

- German
  - German Model
  - SQL</sample>
    <sample id="646">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Monolingual Model: Quellsprache ist die gleiche wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch den Monolingual Few-shot-Einstellung durch das Trainieren monolingualer Modelle mit nur 10% des Trainingsdatensatzes.

Training
- German (Few-shot)
- German Model
- SQL

Inferenz
- German
- German Model
- SQL</sample>
    <sample id="647">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Trainings- und Evaluationsphase.
  o Multilingual Model: Trainiere ein multilinguales Modell für alle Sprachen.

Training

- German
- English
- Chinese
  Multilingual Model
  SQL

Inferenz

- German
  Multilingual Model
  SQL</sample>
    <sample id="648">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Trainings- und Evaluationsphase.
  o Multilingual Model: Trainiere ein multilinguales Modell für alle Sprachen.

Training

Inference

- German
- English
- Chinese
- Multilingual Model
- SQL</sample>
    <sample id="649">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Ausbildung und Bewertung.
  o Multilingual Model: Trainiere ein multilinguales Modell für alle Sprachen.

Training

- German
- English
- Chinese
- Multilingual Model
- SQL

Inferenz

- German
- Multilingual Model
- SQL</sample>
    <sample id="650">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Cross-lingual Zero-shot/Few-shot Transfer: Trainieren auf einer Quellensprache und übertragen auf eine andere Sprache.

Training
- Englisch oder
- Englisch und German Few-shot
- Multilingual Model
- SQL

Inferenz
- German
- Multilingual Model
- SQL</sample>
    <sample id="651">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Ausbildung und Bewertung.
  ○ Cross-lingual Zero-shot/Few-shot Transfer: Ausbildung auf einer Quellensprache und Übertragung zu einer anderen Sprache.

Training
- Englisch oder
- Englisch
- Deutsch Few-shot

Inferenz
- Deutsch
- Multilingual Model
- SQL</sample>
    <sample id="652">### Analyse der Monolingualen Sprachaufgaben

- Wir evaluieren zwei Gruppen von Modellen im **Monolingual Setting**:
  - **Enc-PTR**: Multilinguale Prätrainierte Encoder mit Pointer-basierten Decoder
    - XLM-R + PTR, mBERT + PTR
  - **Enc-Dec**: Multilinguale Prätrainierte Encoder-Decoder Modelle
    - mBART, mT5

- Wir fanden heraus, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht!</sample>
    <sample id="653">Analyse der Monolingualen Daten

- Wir evaluieren zwei Gruppen von Modellen im Monolingual Setting.
  - Enc-PTR: Multilinguale Prätrainierte Encoder mit Pointer-basierten Decoder
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilinguale Prätrainierte Encoder-Decoder Modelle
    - mBART, mT5

- Wir fanden heraus, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht!</sample>
    <sample id="654">### Analyse der Monolingualen Sprachaufgaben

- Wir evaluieren zwei Gruppen von Modellen im **Monolingual Setting**.
  - **Enc-PTR**: Multilinguale Prätrainierte Encoder mit Pointer-basierten Decoder
    - XLM-R + PTR, mBERT + PTR
  - **Enc-Dec**: Multilinguale Prätrainierte Encoder-Decoder Modelle
    - mBART, mT5

- Wir fanden heraus, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht!</sample>
    <sample id="655">**Analyse des Monolingualen**

- Wir evaluieren zwei Gruppen von Modellen im **Monolingual Setting**
  - Enc-PTR: Multilinguale Prätrainierte Encoder mit Pointer-basierten Decoder
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilinguale Prätrainierte Encoder-Decoder Modelle
    - mBART, mT5

- Wir fanden, dass Enc-Dec (mT5) die beste Performance auf allen Datensätzen erreicht!</sample>
    <sample id="656">Analyse des multilingualen Trainings

- Wir evaluieren mT5 und XLM-R + PTR im multilingualen Setting.
  - Enc-Dec/Enc-PTR (mT5/XLM-R) kann durch das Training in einer Mischung verschiedener Sprachen verbessert werden.

Tabelle:

| Monolingual |
|-------------|
| XLM-R+PTR   | MATIS: 31.31, MGeoQuery: 71.41, MSpider: 47.30, MNLmaps: 85.17, MOvernight: 59.10, MCWQ: 23.53, MSchema2QA: 62.37, MTOP: 80.36, MCoNaLa²: 7.69, Durchschnitt: 52.03 |
| mT5         | MATIS: 53.15, MGeoQuery: 74.26, MSpider: 50.73, MNLmaps: 91.65, MOvernight: 66.29, MCWQ: 30.15, MSchema2QA: 65.16, MTOP: 81.83, MCoNaLa²: 10.29, Durchschnitt: 58.16 |

| Multilingual |
|-------------|
| XLM-R+PTR   | MATIS: 39.72, MGeoQuery: 71.35, MSpider: 40.20, MNLmaps: 85.91, MOvernight: 61.03, MCWQ: 30.79, MSchema2QA: 61.82, MTOP: 81.68, MCoNaLa²: –, Durchschnitt: 59.06 |
| mT5         | MATIS: 54.45, MGeoQuery: 76.57, MSpider: 32.30, MNLmaps: 91.31, MOvernight: 67.55, MCWQ: 28.51, MSchema2QA: 60.92, MTOP: 82.95, MCoNaLa²: –, Durchschnitt: 61.82 |

13</sample>
    <sample id="657">Analyse des multilingualen Trainings

- Wir evaluieren mT5 und XLM-R + PTR im multilingualen Setting.
  - Enc-Dec/Enc-PTR (mT5/XLM-R) kann durch Training in einer Mischung verschiedener Sprachen verbessert werden.

Tabelle:

| Monolingual |
|-------------|
| XLM-R+PTR   | MATIS: 31.31, MGeoQuery: 71.41, MSpider: 47.30, MNLmaps: 85.17, MOvernight: 59.10, MCWQ: 23.53, MSchema2QA: 62.37, MTOP: 80.36, MCoNaLa²: 7.69, Durchschnitt: 52.03 |
| mT5         | MATIS: 53.15, MGeoQuery: 74.26, MSpider: 50.73, MNLmaps: 91.65, MOvernight: 66.29, MCWQ: 30.15, MSchema2QA: 65.16, MTOP: 81.83, MCoNaLa²: 10.29, Durchschnitt: 58.16 |

| Multilingual |
|-------------|
| XLM-R+PTR   | MATIS: 39.72, MGeoQuery: 71.35, MSpider: 40.20, MNLmaps: 85.91, MOvernight: 61.03, MCWQ: 30.79, MSchema2QA: 61.82, MTOP: 81.68, MCoNaLa²: –, Durchschnitt: 59.06 |
| mT5         | MATIS: 54.45, MGeoQuery: 76.57, MSpider: 32.30, MNLmaps: 91.31, MOvernight: 67.55, MCWQ: 28.51, MSchema2QA: 60.92, MTOP: 82.95, MCoNaLa²: –, Durchschnitt: 61.82 |

13</sample>
    <sample id="658">Analyse des multilingualen Trainings

- Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting
  - Die meisten der wichtigsten Sprachen können eine Leistungssteigerung erzielen, außer dass die Leistung in 7 Datensätzen sinkt und in 3 Datensätzen steigt. Dies wird als "Fluch der Multilinguistik" bezeichnet.</sample>
    <sample id="659">Analyse des multilingualen Trainings

- Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting
  - Die meisten der wichtigsten Sprachen können eine Leistungssteigerung erzielen, außer dass die Leistung in 7 Datensätzen sinkt und in 3 Datensätzen steigt. Dies wird als "Fluch der Multilinguistik" bezeichnet.

Histogramm: Anzahl der Datensätze
- Englisch (en): 2 Datensätze sinken, 8 Datensätze steigen
- Deutsch (de): 6 Datensätze sinken, 4 Datensätze steigen
- Chinesisch (zh): 4 Datensätze sinken, 6 Datensätze steigen
- Thai (th): 3 Datensätze sinken, 4 Datensätze steigen
- Farsi (fa): 4 Datensätze sinken, 4 Datensätze steigen
- El (el): 3 Datensätze sinken, 3 Datensätze steigen
- Indonesisch (id): 3 Datensätze sinken, 3 Datensätze steigen
- Schwedisch (sv): 3 Datensätze sinken, 3 Datensätze steigen
- Spanisch (es): 2 Datensätze sinken, 3 Datensätze steigen
- Französisch (fr): 1 Datensatz sinkt, 2 Datensätze steigen</sample>
    <sample id="660">Cross-lingual Performance Gap

- Blaue Linie: Cross-lingual Few-shot Transfer
- Orange Linie: Cross-lingual Zero-shot Transfer
- Grüne Linie: Monolingual Setting

Die Grafik zeigt die Leistungsdifferenz zwischen verschiedenen Sprachaufgaben (Geoquery, MTOP, Schema2QA, etc.) in Abhängigkeit von der Anzahl der gegebenen Beispiele (Few-shot, Zero-shot) und dem monolingualen Kontext.</sample>
    <sample id="661">Cross-lingual Performance Gap

- Blaue Linie: Cross-lingual Few-shot Transfer
- Orange Linie: Cross-lingual Zero-shot Transfer
- Grüne Linie: Monolingual Setting

Die Grafik zeigt die Leistungsdifferenz zwischen verschiedenen Sprachaufgaben (Geoquery, MTOP, Schema2QA, etc.) in Abhängigkeit von der Art des Transfers und dem Sprachumfeld.</sample>
    <sample id="662">Cross-lingual Performance Gap

- grün - orange: Für den null-Shot-Einstellung ist der cross-lingual Transfer-Performance-Abstand signifikant.
- blau - orange: Für den wenigen-Shot-Einstellung wird der Transfer-Abstand schnell verkürzt.

Die Grafik zeigt die Performance von verschiedenen Tasken (wie Geoquery, Spider, ATIS usw.) in Abhängigkeit von der Anzahl der gegebenen Beispiele (Few-shot, Zero-shot und Monolingual).</sample>
    <sample id="663">Die anderen Ergebnisse und Erkenntnisse (Abschnitt 4 im Papier)

- Enc-Dec (mT5) übertrifft die vorherigen Arbeiten oder erreicht vergleichbare Ergebnisse.
- Das Vortraining auf dem Englischen NL kann die Leistung des few-shot auf Ziellangschaften signifikant verbessern.
- Multilinguale LLMs (Codex &amp; BLOOM) sind für die interlinguale semantische Parsingsaufgaben immer noch unzureichend.
- Chinesische Transfer-Learning und englische monolingualer Training (En -&gt; En) haben den größten Leistungsabstand, während Deutsch üblicherweise den kleinsten hat.
- FunQL übertrifft die anderen drei Bedeutungsrepräsentationen, und SQL erzielt das schlechteste Ergebnis.</sample>
    <sample id="664">Hier ist der englische Inhalt ins Deutsche übersetzt:

---

**Weitere Ergebnisse &amp; Erkenntnisse (Abschnitt 4 im Papier)**

- Enc-Dec (mT5) übertrifft vorherige Arbeiten oder erreicht vergleichbare Ergebnisse.
- Vortraining auf dem Englischen NL kann die Leistung von few-shot auf Ziellands-NLs signifikant verbessern.
- Multilinguale LLMs (Codex &amp; BLOOM) sind für krosslinguale semantische Parsingsaufgaben immer noch unzureichend.
- Chinesische Transfer-Learning und Englisch monolingualer Training (En -&gt; En) haben den größten Leistungsabstand, während Deutsch üblicherweise den kleinsten hat.
- FunQL übertrifft die anderen drei Bedeutungsrepräsentationen, und SQL erzielt das schlechteste Ergebnis.

---</sample>
    <sample id="665">Zusammenfassung

- Wir haben XSemPLR, ein einheitliches Benchmark für die Übersetzungssemantik mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen, erstellt.

- Wir führen eine umfassende Benchmark-Studie auf drei repräsentativen Typen von multilingualen Sprachmodellen durch.

- Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Ausbildung die beste Leistung erzielt, während multilinguale LLMs immer noch unzureichend sind, um Übersetzungssemantik-Aufgaben auszuführen. Zudem ist der Leistungsunterschied zwischen monolingualer Ausbildung und cross-lingualer Transfer-Learning immer noch signifikant.</sample>
    <sample id="666">### Schlussfolgerung

- Wir haben XSemPLR, ein einheitliches Benchmark für die Übersetzungssemantik mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen, erstellt.
- Wir führen eine umfassende Benchmark-Studie auf drei repräsentativen Typen multilingualer Sprachmodelle durch.
- Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Trainingsschleife die beste Leistung erzielt, während multilinguale LLMs immer noch unzureichend sind, um Übersetzungssemantik-Aufgaben auszuführen. Zudem ist der Leistungsunterschied zwischen monolingualer Trainingsschleife und cross-lingualer Transfer-Learning immer noch signifikant.

### Links

Willkommen, um unsere Arbeit und den Code zu besuchen!

Papier-Link: [https://arxiv.org/pdf/2306.04085.pdf](https://arxiv.org/pdf/2306.04085.pdf)

Code-Link: [https://github.com/psunlpgroup/xsemplr](https://github.com/psunlpgroup/xsemplr)</sample>
    <sample id="667">Die präsentierten Arbeiten umfassen Parameter-basierte Wasserzeichen, Lexikalische Wasserzeichen, Rücktür-basierte Wasserzeichen und Adversarial-basierte Wasserzeichen.</sample>
    <sample id="668">No, multilingual LLMs like Codex and Bloom are still inadequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="695">Die Methode löst das Problem der Mehrdeutigkeit der Permutationen durch die Induktion während des Trainings und die Verwendung eines Permutationsmodells, bei dem die Inferenz NP-schwer ist (ähnlich dem TSP) und durch kontinuierliche Relaxation rückwärtspropagiert wird.</sample>
    <sample id="696">Die Fairness eines nachgeschalteten NLP-Modells wird durch die Analyse von Hate Speech Texten und Misinformation Texten definiert, wobei unterschiedliche politische Leitlinien berücksichtigt werden.</sample>
    <sample id="697">Der Referent*in ist Yanis Labrak.</sample>
    <sample id="698">Der Referent ist Koustuv Sinha.</sample>
    <sample id="699">Der Referent ist Myra Cheng.</sample>
    <sample id="700">Tropikalismus im Zusammenhang mit dieser Arbeit bezieht sich auf die Verwendung von Begriffen wie "Kultur", "Tradition", "Stolz" und "Exotik" für markierte Gruppen, was dazu führt, dass diese Gruppen nur durch ihre Identität definiert werden.</sample>
    <sample id="701">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen durch die Verwendung von essentiellisierenden Erzählungen erstellt. Diese definieren die Gruppen nur durch ihre Identität.</sample>
    <sample id="702">In dieser Arbeit wurde P-CXMI (Pointwise Contextualized Mutual Information) zur Messung der Kontextnutzung verwendet.</sample>
    <sample id="703">Der Unterschied zwischen DrBERT und ChuBERT liegt in der Quelle des Trainingsmaterials. DrBERT wird von einem großen öffentlichen Datensatz (NACHOS) trainiert, während ChuBERT von einem privaten Datensatz (NBDW) trainiert wird.</sample>
    <sample id="751">Es sind drei Autoren an der Arbeit beteiligt.</sample>
    <sample id="752">Iteratives Transferlernen bezieht sich auf ein Verfahren, bei dem das Modell nach jedem Iterationsschritt mit neuen Daten trainiert wird und dann wiederum für die nächste Iteration verwendet wird.</sample>
    <sample id="753">Das Ziel des Datensatzes ist, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen.</sample>
    <sample id="754">Die genaue Methode, wie ein Angreifer Modellparameter über einen EaaS (Embedded AI as a Service) extrahieren kann, ist nicht direkt aus dem Bild ersichtlich. Es zeigt lediglich Ergebnisse von Experimenten mit verschiedenen Datensätzen und deren Embedding-Visualisierungen. Für eine detaillierte Antwort auf diese Frage müssten spezifische Angriffstechniken oder Methoden beschrieben werden, die im Zusammenhang mit EaaS-Angreifern diskutiert werden.</sample>
    <sample id="755">Es sind drei Autoren an der Arbeit beteiligt: Sara Papi, Matteo Negri und Marco Turchi.</sample>
    <sample id="756">Der ursprüngliche Datensatz wurde mit Hilfe von RoBERTA-base + classifier head erstellt. Es wird jedoch keine spezifische Anzahl an Annotatoren erwähnt.</sample>
    <sample id="757">Die Autoren gehören an die University of Washington, Carnegie Mellon University und das Allen Institute for AI.</sample>
    <sample id="758">"I saw Bart and Lisa; Homer came and sneezed"</sample>
    <sample id="759">The state of the art for dialogue systems is ABC-Eval Behaviors.</sample>
    <sample id="760">Die Akzeptanz der Modelle sollte über das gesamte Kontextfenster bewertet werden, um sicherzustellen, dass sie auch in komplexen und kontextuellen Situationen korrekt funktionieren. Dies ist wichtig, da die Leistung von Sprachmodellen oft von der Länge und Komplexität des Kontextes abhängt. Eine Bewertung nur anhand kurzer oder isolierter Kontexte könnte zu Fehleinschätzungen führen und die tatsächliche Leistung des Modells nicht vollständig reflektieren.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell in 7 Datensätzen geführt.</sample>
    <sample id="762">No, the annotators do not have prior knowledge of the entity. They are asked to listen to at least some of each song and read about each song.</sample>
    <sample id="763">Die genannten MT-Metriken sind nicht explizit im Bild angegeben. Es wird lediglich ein Beispiel für eine 5-shot Translation-Prompting gezeigt, aber keine spezifischen Metriken zur Bewertung der Übersetzungen.</sample>
    <sample id="764">Ja, die Regression wirkt sich negativ auf die Generalisierung auf bestimmte NER-Typen aus.</sample>
    <sample id="765">Positionalität ist für NLP wichtig, weil sie die Reihenfolge von Wörtern in einem Satz berücksichtigt, was die Bedeutung und den Kontext des Sprechers oder Schreibers beeinflusst.</sample>
    <sample id="766">Die Frage bezieht sich auf die Anpassung von mehrsprachigen LLMs wie BLOOM, aber der gezeigte Bildschirm befasst sich mit dem Thema "Cross-lingual Semantic Parsing" und zeigt keine spezifischen Informationen über die Anpassung von BLOOM oder ähnlichen Modellen. Daher kann ich keine Aussage dazu treffen.</sample>
    <sample id="767">Das Modell, das für das Transferlernen verwendet wird, ist RoBERTA-base + classifier head.</sample>
    <sample id="768">Die aktuellen Testsets, die zur Bewertung der PaLM-Fähigkeiten verwendet wurden, sind nicht direkt im Bild zu sehen. Das Bild zeigt lediglich Beispiele für die Übersetzung von deutschen Texten ins Englische. Für eine genaue Antwort auf Ihre Frage müssten weitere Informationen oder Quellen über die verwendeten Testsets herangezogen werden.</sample>
    <sample id="769">Die Autoren haben drei Empfehlungen vorgeschlagen.</sample>
    <sample id="770">Der Gewinn der vorgeschlagenen Methode gegenüber der stärksten Baseline beträgt 26,25%.</sample>
    <sample id="771">Der Referent ist Shuheng Liu.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark verwendet werden.</sample>
    <sample id="773">In der Arbeit werden zwei kleinere Modelle experimentiert: Codex (175B) und T5 trained on Coscript.</sample>
    <sample id="774">OFA (One For All)</sample>
    <sample id="833">Die Autoren gehören der Google-Universität an, da das Logo von Google oben links im Bild zu sehen ist.</sample>
    <sample id="834">Die Autoren gehören der Stony Brook University an.</sample>
    <sample id="835">Die Frage kann nicht direkt aus dem Bild beantwortet werden, da keine spezifischen Sprachpaare genannt sind. Das Bild zeigt eine Präsentation mit einem Punkt, der auf eine "systematische Studie von LLM-Prompting für MT" hinweist, aber keine spezifischen Sprachpaare erwähnt.</sample>
    <sample id="836">Der Referent ist Shangbin Feng.</sample>
    <sample id="837">Die Modelle, die während der Experimente untersucht wurden, sind DEplain-APA, DEplain-web, DEplain-APA+web und src2src-baseline.</sample>
    <sample id="838">53 Aufgaben werden für das Training verwendet, und 9 Aufgaben werden für die Tests verwendet.</sample>
    <sample id="839">Es sind drei Autoren an der Arbeit beteiligt: Regina Stodden, Omar Momen und Laura Kallmeyer.</sample>
    <sample id="840">Die Autoren haben ihre Experimente an den folgenden Datensätzen durchgeführt: AG News, MIND, SST2 und Enron Spam.</sample>
    <sample id="876">NACHOS ist ein Modell, das im Zusammenhang mit der Evaluierung von 13 Modellen auf 11 Aufgaben genannt wird. Es handelt sich um eines der Modelle, die im Rahmen des Vortrags oder der Präsentation besprochen werden.</sample>
    <sample id="877">Der Referent ist Colin Cherry.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Qualität der Übersetzungen.</sample>
    <sample id="879">Die Autoren gehören der Carnegie Mellon University an.</sample>
    <sample id="880">Die 5 Anweisungen der Expert*innen lauteten:

1. We are collecting a much larger multimodal instruction tuning dataset with around 150 additional vision-language tasks and we will release them soon!
2. One More Thing!</sample>
    <sample id="881">Die Autoren schlagen vor, Modelle mit dem KITMUS Test Suite zu testen, um ihre Fähigkeit zur Nutzung von Informationen aus mehreren Quellen zu evaluieren.</sample>
    <sample id="882">Der englische Text lautet:

"Prompting PaLM for Translation
Assessing Strategies and Performance"

Übersetzt ins Deutsche bedeutet das:

"Prompten von PaLM für Übersetzung
Beurteilung von Strategien und Leistung"</sample>
    <sample id="883">PaLM: Pfadwege-Sprachmodell

- Chowdery et al., 2022
- arXiv:2204.02311.
- 540 Milliarden Parameter.
- Trainiert auf 780 Milliarden Tokens.
- Dicht aktiviert.
- 6144 TPU v4 Chips.
- SOTA in hunderten von LMU und Generation Benchmarks.

Die Grafik zeigt ein Baumdiagramm mit verschiedenen Kategorien wie Fragebeantwortung, Arithmetik, Code-Vollständigkeit, Allgemeinwissen, Zusammenfassung, Sprachverstehen, Logische Inferenzketten, Alltagsvernunft, Mustererkennung, Übersetzung, Dialoge, Witzinterpretationen und Physikfragen.</sample>
    <sample id="884">PaLM: Pfadwege-Sprachmodell

- Chowdery et al., 2022
- arXiv:2204.02311.
- 540 Milliarden Parameter.
- Trainiert auf 780 Milliarden Tokens.
- Dicht aktiviert.
- 6144 TPU v4 Chips.
- SOTA in hunderten von LMU und Generation Benchmarks.

Das Bild zeigt ein Baumdiagramm mit verschiedenen Kategorien wie Fragebeantwortung, Arithmetik, Übersetzung, Zusammenfassung, Sprachverstehen usw., die alle 540 Milliarden Parameter umfassen.</sample>
    <sample id="885">Unsere Beiträge

- Erste systematische Studie zur Prompting von LLM für MT.
  - sowohl für die Kandidatenpool als auch für die Selektionsstrategie.

- Evaluierung der Übersetzungsleistungen mit den besten Praktiken der MT-Gemeinschaft:
  - Neueste Testsets (um Verzahnung von Trainings- und Testdaten zu vermeiden und Überfitting auf Evaluationsdaten zu verhindern).
  - Vergleich mit den neuesten WMT-Beitragen (SOTA-Systeme verwenden das neueste Trainingssatz).
  - SOTA-MT-Metriken (bessere Korrelation mit menschlichen Urteilen).
  - Expertenbasierte menschliche Bewertung (mehr robust als crowd workers).

- Empfehlungen für Prompt-Selbststrategien</sample>
    <sample id="886">Unsere Beiträge

- Erste systematische Studie zur Prompting von LLM für MT.
  - Für das Kandidatenpool sowie die Selektionsstrategie.

- Evaluierung der Übersetzungsleistungen mit den besten Praktiken der MT-Gemeinschaft:
  - Neueste Testsets (um Verzahnung von Trainings- und Testdaten zu vermeiden und Überfitting auf Evaluationsdaten zu verhindern).
  - Vergleich mit den neuesten WMT-Einreichungen (SOTA-Systeme verwenden die neuesten Trainingsdaten).
  - SOTA-MT-Metriken (bessere Korrelation mit menschlichen Urteilen).
  - Expertenbasierte menschliche Bewertung (mehr robust als Crowdworkers).

- Empfehlungen für Promptauswahlstrategien</sample>
    <sample id="887">Unsere Beiträge

- Erste systematische Studie zur Prompting von LLM für MT.
  - sowohl für die Kandidatenpool als auch für die Selektionsstrategie.

- Evaluierung der Übersetzungsleistungen mit den besten Praktiken der MT-Gemeinschaft:
  - Neueste Testsets (um Verzahnung von Trainings- und Testdaten zu vermeiden und Überfitting auf Evaluationsdaten zu verhindern).
  - Vergleich mit den neuesten WMT-Beitragen (SOTA-Systeme verwenden das neueste Trainingssample).
  - SOTA-MT-Metriken (bessere Korrelation mit menschlichen Urteilen).
  - Expertenbasierte menschliche Bewertung (mehr robust als Crowdworkers).

- Empfehlungen für Prompt-Selbststrategien</sample>
    <sample id="888">Unsere Beiträge

- Erste systematische Studie zur Prompting von LLM für MT.
  - Für das Kandidatenpool sowie die Auswahlstrategie.

- Evaluierung der Übersetzungsleistungen mit den besten Praktiken der MT-Gemeinschaft:
  - Neueste Testsets (um Verzahnung von Trainings- und Testdaten zu vermeiden und Überfitting auf Evaluationsdaten zu verhindern).
  - Vergleich mit den neuesten WMT-Einreichungen (SOTA-Systeme verwenden die neuesten Trainingsdaten).
  - SOTA-MT-Metriken (bessere Korrelation mit menschlichen Urteilen).
  - Expertenbasierte menschliche Bewertung (mehr robust alscrowd workers).

- Empfehlungen für Promptauswahlstrategien</sample>
    <sample id="889">Die Folie enthält den Titel "Prompts haben einen großen Einfluss auf die Übersetzungskonstanz". Die Punkte sind:

- Wählen Sie zwei zufällige Prompts für jede Satz.
- Berechnen Sie BLEURT für jedes Satz-Prompt-Paar.
- Die meisten Sätze (516 von 1000) zeigen eine Differenz von mehr als einem BLEURT-Punkt.
- Die Differenz kann bis zu 40 BLEURT-Punkte betragen!</sample>
    <sample id="890">Die folgenden Punkte übersetzen sich wie folgt:

- Prompts haben einen großen Einfluss auf die Übersetzungsqualität.
  - Wählen Sie zwei zufällige Prompts für jede Satz.
  - Berechnen Sie BLEURT für jedes Satz-Prompt-Paar.
  - Die meisten Sätze (516 von 1000) zeigen eine Differenz von mehr als einem BLEURT-Punkt.
  - Die Differenz kann bis zu 40 BLEURT-Punkte betragen!</sample>
    <sample id="891">Die folgenden Punkte übersetzen sich wie folgt:

- Prompts haben einen großen Einfluss auf die Übersetzungsqualität.
  - Wählen Sie zwei zufällige Prompts für jede Satz.
  - Berechnen Sie BLEURT für jedes Satz-Prompt-Paar.
  - Die meisten Sätze (516 von 1000) zeigen eine Differenz von mehr als einem BLEURT-Punkt.
  - Die Differenz kann bis zu 40 BLEURT-Punkte betragen!</sample>
    <sample id="892">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. German: Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   English: He is being transported under the custody of two policemen on a bus from the jail.

2. German: Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   English: Police were called in after receiving complaints from the office.

3. German: Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   English: A passerby alerted the police, who arrived with several patrols.</sample>
    <sample id="893">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. German: Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   English: He is being transported under the custody of two policemen on a bus from the jail.

2. German: Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   English: Police were called in after receiving complaints from the office.

3. German: Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   English: A passerby alerted the police, who arrived with several patrols.</sample>
    <sample id="894">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. German: Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   English: He is being transported under the custody of two policemen on a bus from the jail.

2. German: Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   English: Police were called in after receiving complaints from the office.

3. German: Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   English: A passerby alerted the police, who arrived with several patrols.</sample>
    <sample id="895">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. German: Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   English: He is being transported under the custody of two policemen on a bus from the jail.

2. German: Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   English: Police were called in after receiving complaints from the office.

3. German: Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   English: A passerby alerted the police, who arrived with several patrols.</sample>
    <sample id="896">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. German: Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   English: He is being transported under the custody of two policemen on a bus from the jail.

2. German: Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   English: Police were called in after receiving complaints from the office.

3. German: Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   English: A passerby alerted the police, who arrived with several patrol units.</sample>
    <sample id="897">### Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

### Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="898">### Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zur Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

### Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="899">### Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

### Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="900">### Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zur Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

### Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="901">### Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

### Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="902">### Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

### Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind im Allgemeinen niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist im Allgemeinen für PaLM niedriger.</sample>
    <sample id="903">### Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zur Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

### Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="904">### Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zur Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

### Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="905">### Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

### Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind im Allgemeinen niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist im Allgemeinen für PaLM niedriger.</sample>
    <sample id="906">Der englische Text "thank you" wird in verschiedenen Sprachen übersetzt:

- danke (Deutsch)
- 謝謝 (chinese)
- ngiyabonga (isiXhosa)
- teşekkür ederim (Türkisch)
- شكراً جزيلاً (arabisch)
- спасибо (russisch)
- спасиби (bulgarisch)
- kiitos (finnisch)
- thank you (Englisch)
- vinaka (fidschian)
- mersi (türkmenisch)
- kia barka (arabisch)
- welalin (amharisch)
- dank je (niederländisch)
- misaotra (malagasy)
- matondo (swahili)
- paldies (lettisch)
- grazzi (italienisch)
- mahalo (hawaiisch)
- tanadh leat (gälisch)
- xhwała (serbokroatisch)
- asante manana (swahili)
- obrigado (portugiesisch)
- bedankt (niederländisch)
- hvala (kroatisch)
- maurodi (maori)
- chnorakaloutioun (französisch)
- gracies (spanisch)
- akun dankon aabo (wolof)
- sulpay (chamorro)
- go raibh maith agat (irisch)
- arigató (japanisch)
- takk (isländisch)
- dakujem (kroatisch)
- trugarez (katalanisch)
- merci (französisch)
- 감사합니다 (koreanisch)
- xiexie (chinesisch)
- modxyuxa (russisch)
- tanemirt rahmet (arabisch)
- diolch (walisisch)
- dhanyavadagalu (telugu)
- shukriya (arabisch)
- me (spanisch)</sample>
    <sample id="907">Die deutsche Übersetzung des englischen Inhalts lautet:

"Schwächer als du denkst
Eine kritische Betrachtung von schwach überwachtem Lernen"

Die Autoren sind:
- Dawei Zhu (Saarland University)
- Xiaoyu Shen (Amazon Alexa)
- Marius Mosbach (Saarland University)
- Andreas Stephan (University of Vienna)
- Dietrich Klakow (Saarland University)</sample>
    <sample id="908">Die deutsche Übersetzung des englischen Inhalts lautet:

"Schwächer als du denkst
Eine kritische Betrachtung von schwach überwachtem Lernen"

Die Autoren sind:
- Dawei Zhu (Saarland University)
- Xiaoyu Shen (Amazon Alexa)
- Marius Mosbach (Saarland University)
- Andreas Stephan (University of Vienna)
- Dietrich Klakow (Saarland University)</sample>
    <sample id="909">Warum schwach überwachte Lernen?

- Schwache Supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Schwach überwachtes Lernen (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmgelegten Daten trainiert werden.</sample>
    <sample id="910">Warum weakly supervised Learning?

- Weak supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Weakly supervised learning (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmem Datenmaterial trainiert wurden.</sample>
    <sample id="911">Warum weakly supervised Learning?

- Weak supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Weakly supervised learning (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmem Datenmaterial trainiert wurden.</sample>
    <sample id="912">Warum schwach überwachte Lernen?

- Schwache Supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Schwach überwachtes Lernen (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmgelegten Daten trainiert werden.</sample>
    <sample id="913">Warum schwach überwachte Lernen?

- Schwache Supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Schwach überwachtes Lernen (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmgelegten Daten trainiert werden.</sample>
    <sample id="914">Ein häufiger Behauptung in neueren WSL-Arbeiten lautet:

"Wir trainieren Modelle nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."

- Schwach überwachte Trainingsdaten (ungeordnet)
- Sauber überwachte Testdaten (geordnet)</sample>
    <sample id="915">Ein häufiger Behauptung in neueren WSL-Arbeiten lautet:

"Wir trainieren Modelle nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."

**Deutsch:**

Ein häufiger Behauptung in neueren WSL-Arbeiten lautet:

"Wir trainieren Modelle nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."</sample>
    <sample id="916">Ein häufiger Behauptung in neueren WSL-Arbeiten lautet:

"Wir trainieren Modelle nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."

Die Abbildung zeigt:
- Schwach überwachte Trainingsdaten (ungeordnet)
- Rein überwachte Validierungsdaten (rein)
- Rein überwachte Testdaten (rein)</sample>
    <sample id="917">Ein häufiger Behauptung in neueren WSL-Arbeiten lautet:

"Wir trainieren Modelle nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."

Die Abbildung zeigt:
- Schwach überwachte Trainingsdaten (ungeordnet)
- Rein überwachte Validierungsdaten (rein)
- Rein überwachte Testdaten (rein)</sample>
    <sample id="918">Unsere Forschungsfragen

RQ1: Ist sauberes Validierungsdatenmaterial notwendig?

RQ2: Wie viele saubere Proben benötigen WSL-Ansätze?

RQ3: Wie kann man das verfügbare saubere Material effizienter nutzen?</sample>
    <sample id="919">Unsere Forschungsfragen

RQ1: Ist sauberes Validierungsdatenmaterial notwendig?

RQ2: Wie viele saubere Proben benötigen WSL-Ansätze?

RQ3: Wie kann man das verfügbare saubere Material effizienter nutzen?</sample>
    <sample id="920">RQ1 Hauptergebnisse

Die Grafik zeigt die relative Leistungsverbesserung über schwache Labels (%) für verschiedene Verfahren (FTW, BOND, COSINE, MLC, L2R) unter verschiedenen Validationsbedingungen (Validierung auf schwachen Labels, keine Validierung (Zufallsauswahl), Validierung auf sauberen Labels).</sample>
    <sample id="921">RQ1 Hauptergebnisse

Relative Leistungsverbesserung gegenüber schwachen Labels (%)

- Validierung auf schwachen Labels (orange)
- Keine Validierung (Zufällige Auswahl) (violett)
- Validierung auf sauberen Labels (grün)</sample>
    <sample id="922">RQ1 Hauptergebnisse

Relative Leistungsverbesserung gegenüber schwachen Labels (%)</sample>
    <sample id="923">RQ1 Hauptergebnisse

Die Grafik zeigt die relative Leistungsverbesserung über schwache Labels (%) für verschiedene Verfahren (FTW, BOND, COSINE, MLC, L2R) bei der Validierung auf schwachen Labels (orange), ohne Validierung (zufällige Auswahl; lila) und bei der Validierung auf sauberen Labels (grün).</sample>
    <sample id="924">RQ1 Hauptergebnisse

Ein sauberer Validationsdatensatz ist unentbehrlich.

→ Eine saubere Validierungsmenge ist unentbehrlich.</sample>
    <sample id="925">Die Übersetzung des englischen Inhalts lautet:

**Hauptergebnisse**

RQ2: Hauptergebnisse

Der Graph zeigt die Genauigkeit (Accuracy) in Abhängigkeit von der Anzahl der Validierungsdatenpunkte (Validation). Die verschiedenen Linien repräsentieren verschiedene Methoden oder Ansätze, wie FT_w, COSINE, L2R, BOND und MLC. Eine gestrichelte Linie markiert den Wert für schwache Labels (Weak labels).

7</sample>
    <sample id="926">RQ2 Hauptergebnisse

Der Graph zeigt die Genauigkeit in Abhängigkeit von der Anzahl der Validierungsdatenpunkte. Die verschiedenen Linien repräsentieren verschiedene Verfahren: FT_w, COSINE, L2R, BOND und MLC. Die Linie "Weak labels" ist als graue gestrichelte Linie dargestellt.

Die Ergebnisse zeigen, dass die Genauigkeit mit zunehmender Anzahl der Validierungsdatenpunkte steigt. Die Methode BOND erreicht die höchste Genauigkeit, gefolgt von COSINE, L2R, MLC und FT_w.</sample>
    <sample id="927">RQ2 Hauptergebnisse

WSL-Verfahren profitieren von mehr sauberen Validierungssamples!</sample>
    <sample id="928">RQ2 Hauptergebnisse

WSL-Verfahren profitieren von mehr sauberen Validierungssamples!</sample>
    <sample id="929">### Hauptergebnisse

RQ2: **Hauptergebnisse**

→ WSL-Verfahren profitieren von mehr sauberen Validierungssamples!

→ Es ist jedoch noch besser, sie für die Training (z.B., LoRAc) zu verwenden!</sample>
    <sample id="930">RQ3 Hauptergebnisse

N=10 saubere Proben pro Klasse
Accuracy/F1

N=30 saubere Proben pro Klasse
Accuracy/F1</sample>
    <sample id="931">RQ3 Hauptergebnisse

N=10 saubere Proben pro Klasse
Accuracy/F1

N=30 saubere Proben pro Klasse
Accuracy/F1

Die Grafiken zeigen die Ergebnisse vor und nach der CFT (Clean Feature Transformation) für verschiedene Klassifikationsverfahren bei unterschiedlichen Anzahl an sauberen Proben pro Klasse.</sample>
    <sample id="932">RQ3 Hauptergebnisse

N=10 saubere Proben pro Klasse
Accuracy/F1

N=30 saubere Proben pro Klasse
Accuracy/F1</sample>
    <sample id="933">RQ3 Hauptergebnisse

→ Kontinuierliche Feinabstimmung (CFT) eliminiert Leistungsschwankungen zwischen WSL-Ansätzen.

→ Es ist keine komplizierte WSL-Methode erforderlich (FTW zeigt gleichwertiges Ergebnis).</sample>
    <sample id="934">### Schlussfolgerung

**Neueste WSL-Verfahren**
- Erfordern saubere Proben.
- Überbewerten ihre praktische Anwendbarkeit.

**Unsere Empfehlungen**
- Berichten Sie die Kriterien für das Modellauswahl.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmung (CFT).</sample>
    <sample id="935">### Schlussfolgerung

**Neueste WSL-Verfahren**
- Erfordern saubere Proben.
- Überbewerten ihre praktische Anwendbarkeit.

**Unsere Empfehlungen**
- Berichten Sie die Auswahlkriterien für das Modell.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmungsverfahren (CFT).</sample>
    <sample id="936">### Schlussfolgerung

**Neueste WSL-Verfahren**
- Erfordern saubere Proben.
- Überbewerten ihre praktische Anwendbarkeit.

**Unsere Empfehlungen**
- Berichten Sie die Auswahlkriterien für das Modell.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmungsverfahren (CFT).</sample>
    <sample id="937">### Schlussfolgerung

**Neueste WSL-Verfahren**
- Erfordern saubere Beispiele.
- Überbewerten ihre praktische Anwendbarkeit.

**Unsere Empfehlungen**
- Berichten Sie die Auswahlkriterien für Modelle.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmungsverfahren (CFT).</sample>
    <sample id="938">### Schlussfolgerung

**Neueste WSL-Verfahren**
- Erfordern saubere Beispiele.
- Überbewerten ihre praktische Anwendbarkeit.

**Unsere Empfehlungen**
- Berichten Sie die Kriterien für das Modellauswahl.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmung (CFT).</sample>
    <sample id="939">Gängige Bewertungsmethoden für Dialogsysteme sind die "Comparative Evaluation" und die "Likert Rating Evaluation".</sample>
    <sample id="940">Es sind fünf Autoren an der Arbeit beteiligt.</sample>
    <sample id="941">Im Beispiel mit Servin und Kea wird das Hintergrundwissen "Judges decide cases in courts of law" benötigt.</sample>
    <sample id="942">Ja, der Code ist verfügbar. Du findest ihn auf GitHub unter mpoemsl/kitmus.</sample>
    <sample id="943">Die Grafik zeigt, dass die Annotatoren für NLPositionality am besten mit Menschen mit einem College-Abschluss ausgerichtet sind, was durch die höchsten Werte für "College" und "Graduate School" angedeutet wird. Es ist jedoch wichtig zu beachten, dass dies nur eine Teilaspekt betrachtet und weitere Demografiegruppen wie Land, Geschlecht usw. nicht berücksichtigt werden.</sample>
    <sample id="944">Die Sätze wurden durch die Hinzufügung von Präfixen oder Suffixen, längeren Präfixen, dem Hinzufügen eines Satzes oder Zitats verändert.</sample>
    <sample id="945">Eine dimensionale Bewertung bezieht sich auf die Beurteilung von Dialogqualität, indem verschiedene Aspekte wie Relevanz, Emotionales Verständnis und Konsistenz berücksichtigt werden.</sample>
    <sample id="946">Die Autoren gehören an verschiedene Universitäten und Forschungseinrichtungen, darunter die University of Science and Technology of China, Microsoft Research Asia, Beijing Jiaotong University und Sony AI.</sample>
    <sample id="947">Die Form des Prompts ist wichtig, wenn es um die Genauigkeit und den Kontext der Übersetzung geht. Beispielsweise sollte das Prompt klar und präzise sein, um sicherzustellen, dass die Übersetzung korrekt und kontextuell korrekt ist.</sample>
    <sample id="978">Die Autoren haben die Dialogmodelle BART-FID-RAG, Blender2, Emora und Blender-Decode evaluiert.</sample>
    <sample id="979">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="980">Die idealen Eigenschaften eines guten Planers sind Flexibilität, Kreativität, Organisation und die Fähigkeit, unter verschiedenen Bedingungen zu arbeiten.</sample>
    <sample id="981">Es sind neun Autoren an der Arbeit beteiligt.</sample>
    <sample id="982">Der Referent*in ist Vasudha Varadarajan.</sample>
    <sample id="983">The authors belong to the University of Warsaw.</sample>
    <sample id="1021">Die häufigsten Fehler von PaLM sind "Accuracy/Omission".</sample>
    <sample id="1022">Der englische Text lautet:

"Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems"

Die Autoren sind:
- Sarah E. Finch
- James D. Finch
- Jinho D. Choi

Die Logos unten im Bild repräsentieren:
- Emory University
- Emory NLP Research Lab
- Alexa (Amazon)</sample>
    <sample id="1023">Hier ist der englische Inhalt in die deutsche Sprache übersetzt:

"Denke nicht an deine ABCs: Beurteile das aktuelle Stand der Technik in Chat-basierten Dialogsystemen"

Sarah E. Finch, James D. Finch und Jinho D. Choi</sample>
    <sample id="1024">Der englische Inhalt lautet:

"Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems"

Übersetzt auf Deutsch bedeutet das:

"Denke nicht an deine ABCs vergessen: Bewertung der aktuellsten Technologien in chattenorientierten Dialogsystemen"

Der Titel des nächsten Bildes lautet:

"Comparative Evaluation"

Übersetzt auf Deutsch bedeutet das:

"Vergleichende Bewertung"</sample>
    <sample id="1025">Der englische Inhalt lautet "Comparative Evaluation" und "Likert Rating Evaluation". Übertragen auf Deutsch bedeutet das:

"Vergleichsbeurteilung"
"Likert-Wert-Bewertung"</sample>
    <sample id="1026">### Likert Rating Evaluation

### Dimensionen der Dialogqualität

- **Dialogqualität**
  - Relevanz
  - Emotionale Verständigung
  - Konsistenz</sample>
    <sample id="1027">Der englische Inhalt lautet:

"Dimensions of Dialogue Quality
Likert Rating Evaluation

Rate the relevance of the bot's responses"

Übersetzt ins Deutsche:

"Dimensionen der Dialogqualität
Likert-Wertungsevaluation

Bewerten Sie die Relevanz der Antworten des Bots."</sample>
    <sample id="1028">Der englische Inhalt lautet: "Likert Rating Evaluation" und "Rate the relevance of the bot's responses". Dies bedeutet auf Deutsch: "Likert-Wertungsevaluation" und "Bewerte die Relevanz der Antworten des Bots".</sample>
    <sample id="1029">Der englische Text lautet: "Annotating Behaviors in Chat (ABC-Eval)". Dies bedeutet auf Deutsch: "Markieren von Verhaltensweisen im Chat (ABC-Eval)".</sample>
    <sample id="1030">Die Präsentation handelt über die Annotierung von Verhaltensweisen in Chats (ABC-Eval). Es werden verschiedene Sprechblasen dargestellt, die von Menschen und einem Roboter repräsentiert werden. Die Sprechblasen sind mit drei Kategorien gekennzeichnet:

1. **Irrelevant**: Diese Kategorie wird durch eine orangefarbene Sprechblase mit dem Text "Irrelevant" angedeutet.
2. **Mangelnde Empathie**: Diese Kategorie wird durch eine orangefarbene Sprechblase mit dem Text "Lack of Empathy" angedeutet.
3. **Selbstwidersprüche**: Diese Kategorie wird ebenfalls durch eine orangefarbene Sprechblase mit dem Text "Self Contradiction" angedeutet.

Die Präsentation stammt von Emory University und Alexa.</sample>
    <sample id="1031">Der englische Inhalt lautet "ABC-Eval Behaviors". Übertragen auf Deutsch bedeutet dies "ABC-Eval Verhaltensweisen".</sample>
    <sample id="1032">Der englische Inhalt lautet "ABC-Eval Behaviors". Übertragen auf Deutsch bedeutet dies "ABC-Eval Verhaltensweisen".</sample>
    <sample id="1033">Natürlich, hier ist der englische Inhalt in die deutsche Sprache übersetzt:

ABC-Eval Verhaltensweisen

Kohärenz:
- Ignoring Partner
- Irrelevant

Konsistenz:
- Self Contradiction
- Partner Contradiction

Wissen:
- Incorrect Fact
- Commonsense Violation

Emotionale Verständnis:
- Empathetic Response
- Lack of Empathy</sample>
    <sample id="1034">Der englische Inhalt lautet:

"Experiments
- 4 Open-Domain Dialogue Models
- 100 Human-Bot Conversations per Model"

Übersetzt ins Deutsche:

"Experimente
- 4 offene Domänen Dialogmodelle
- 100 Mensch-Maschine-Konversationen pro Modell"</sample>
    <sample id="1035">Experimente
- 4 offene Domänen Dialogmodelle
- 100 Mensch-Bot-Konversationen pro Modell

ABC-Eval
Turn Likert
Dialogue Likert
Comparative</sample>
    <sample id="1036">Der englische Text lautet:

"Experiments
- 4 Open-Domain Dialogue Models
- 100 Human-Bot Conversations per Model

Baseline Evaluations
- Turn Likert
- Dialogue Likert
- Comparative

Consistency
Emotional Understanding
Informativeness
Overall Quality

Engagingness
Grammaticality
Proactivity
Relevance"

Übersetzt ins Deutsche:

"Experimente
- 4 offene Domänen Dialogmodelle
- 100 Mensch-Chatbot-Konversationen pro Modell

Baseline-Evaluierungen
- Turn Likert
- Dialog Likert
- Vergleichend

Konsistenz
Emotionale Verständigung
Informativität
Gesamtqualität

Beteiligung
Grammatikalität
Aktivität
Relevanz"</sample>
    <sample id="1037">Der englische Text lautet "Inter-Annotator Agreement" und der deutsche Inhalt lautet "Inter-annotator-Übereinstimmung".</sample>
    <sample id="1038">Der englische Text lautet:

"Inter-Annotator Agreement"

"Predictive Validity"

Der deutsche Inhalt lautet:

"Inter-annotator-Konsistenz"

"Prädiktive Gültigkeit"</sample>
    <sample id="1039">Der englische Text lautet "Predictive Validity". Dies bedeutet "Vorhersagbare Gültigkeit" oder "Vorhersagbarkeit der Gültigkeit".</sample>
    <sample id="1040">Der englische Text lautet "Incremental Validity" und der deutsche Inhalt lautet "Zunehmende Gültigkeit".</sample>
    <sample id="1041">Der englische Text lautet "Incremental Validity". Dies bedeutet "Zunehmende Gültigkeit" oder "Erhöhte Gültigkeit".</sample>
    <sample id="1042">Der englische Text lautet "Incremental Validity" und der deutsche Inhalt lautet "Zunehmende Gültigkeit".</sample>
    <sample id="1043">Der englische Text lautet: "ABC-Eval Error Rates by Model". Dies bedeutet auf Deutsch: "ABC-Eval-Fehlerraten nach Modell".</sample>
    <sample id="1044">Der englische Text lautet:

"ABC-Eval Error Rates by Model"

Übersetzt ins Deutsche bedeutet das:

"Fehlerraten von ABC-Eval nach Modell"</sample>
    <sample id="1045">Der englische Text lautet:

"ABC-Eval Error Rates by Model"

Übersetzt ins Deutsche bedeutet das:

"Fehlerraten von ABC-Eval nach Modell"</sample>
    <sample id="1046">Der Titel des Diagramms lautet "ABC-Eval Fehlerraten nach Modell". Das Diagramm zeigt die Fehlerraten verschiedener Modelle in Prozent der Gesamtzahl der Wiederholungen (Turns) für verschiedene Fehlerarten. Die Fehlerarten sind: Antisocial, CS CONTRA-, Ignore, Incorrect, Irrelevant, Unempathetic, Other CONTRA, Redundant, Self CONTRA, Topic Switch und Uninterpret.

Die Modelle, deren Fehlerraten im Diagramm dargestellt werden, sind:
- BART-FID-RAG
- Blender2
- Emora
- Blender-Decode

Das Diagramm verdeutlicht, dass einige Modelle bestimmte Fehlerarten häufiger machen als andere. Zum Beispiel scheint das Modell BART-FID-RAG häufiger Antisocial-Fehler zu machen, während das Modell Emora häufiger Irrelevant-Fehler macht.</sample>
    <sample id="1047">### ABC-Eval Fehlerraten nach Modell

#### Danke fürs Anschauen!

Papier: [https://arxiv.org/pdf/2212.09180.pdf](https://arxiv.org/pdf/2212.09180.pdf)

GitHub: [https://github.com/emorynlp/ChatEvaluationPlatform](https://github.com/emorynlp/ChatEvaluationPlatform)

Kontaktinformationen:
{sfillwo, jdfinch, jinho.choi} @emory.edu
[https://www.emorynlp.org](https://www.emorynlp.org)</sample>
    <sample id="1048">Die Autoren Sarah E. Finch, James D. Finch und Jinho D. Choi gehören der Emory University an.</sample>
    <sample id="1049">CFT steht für "Continuous Fine-tuning".</sample>
    <sample id="1050">Es sind sieben Autoren an der Arbeit beteiligt.</sample>
    <sample id="1051">Der englische Inhalt lautet:

"Was erfordert Übersetzungen Kontext?
Eine datengetriebene, multilinguale Untersuchung"

Die Autoren sind:
- Patrick Fernandes*, Kayo Yin*, Emmy Liu
- André F. T. Martins, Graham Neubig

Die Institutionen, die an der Arbeit beteiligt waren, sind:
- Carnegie Mellon University Language Technologies Institute
- TÉCNICO LISBOA
- BAIR (Berkeley Artificial Intelligence Research)
- Unbabel</sample>
    <sample id="1052">Übersetzung hängt von Kontext ab

Wir müssen das Maul entfernen.

Dinge könnten gefährlich werden, wenn die Minister es herausfinden. Wir müssen das Maul entfernen.</sample>
    <sample id="1053">Übersetzung hängt vom Kontext ab

Dinge könnten gefährlich werden, wenn die Minister davon erfahren. Wir müssen diesen Spion loswerden.

Könnte es etwas Ernstes sein, Doktor? Wir müssen diesen Spion loswerden.</sample>
    <sample id="1054">Übersetzung hängt vom Kontext ab

Könnte es etwas Ernstes sein, Doktor? Wir müssen das Fleckchen entfernen.</sample>
    <sample id="1055">Die englische Inhaltsbeschreibung lautet:

"Evaluating context-dependent translation is hard
- Only a small portion of words depend on
  context
- Corpus-level metrics"</sample>
    <sample id="1056">Der englische Inhalt lautet:

"Evaluating context-dependent translation is hard

- Only a small portion of words depend on
  context
  o Corpus-level metrics

- Existing methods support limited discourse
  phenomena and languages"</sample>
    <sample id="1057">RQ1: Wann erfordert Übersetzung Kontext?
RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1058">RQ1: Wann erfordert die Übersetzung Kontext?
- Wortebene Kontextverwendung

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1059">Der englische Inhalt lautet:

"Conditional Cross-Mutual Information (CXMI)

- CXMI: messen, wie viel Kontext MT-Modelle verwenden, gegeben eine Korpus"

Der deutsche Inhalt lautet:

"Bedingte Kreuz-Mutual Information (CXMI)

- CXMI: messen, wie viel Kontext MT-Modelle verwenden, gegeben eine Korpus"</sample>
    <sample id="1060">Der englische Inhalt lautet:

"Conditional Cross-Mutual Information (CXMI)

- CXMI: Messung davon, wie viel Kontext MT-Modelle verwenden, wenn ein Korpus gegeben ist"

Die Grafik zeigt zwei Entropien:
1. HqMTA(Y|X) - Unsicherheit über Übersetzungen gegeben dem Quelltext
2. HqMTC(Y|X, C) - Unsicherheit über Übersetzungen gegeben dem Quelltext und dem Kontext

CXMI(C → Y|X) - Conditional Cross-Mutual Information zwischen Kontext und Übersetzung gegeben dem Quelltext</sample>
    <sample id="1061">### Pointwise (P-)CXMI

- Wir führen P-CXMI ein, um den Kontextgebrauch zu messen, um eine spezifische

  - Satz   P-CXMI(y, x, C) = - log \(\frac{q_{MT_A}(y|x)}{q_{MT_C}(y|x, C)}\)

  - Wort   P-CXMI(i, y, x, C) = - log \(\frac{q_{MT_A}(y_i|y_{t&lt;i}, x)}{q_{MT_C}(y_i|y_{t&lt;i}, x, C)}\)

- Hohe P-CXMI-Wörter -&gt; erfordern Kontext zum Übersetzen</sample>
    <sample id="1062">RQ1: Wann erfordert die Übersetzung Kontext?
- Wortebene Kontextverwendung
- Themenanalyse

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1063">Der englische Inhalt lautet:

"Thematic analysis of high P-CXMI words

RQ1: When does translation require context?
- Word-level context usage
- Thematic analysis

RQ2: How well do models handle context-dependent translations?"

Übersetzt auf Deutsch:

"Themenanalyse von hochwertigen P-CXMI-Wörtern

Forschungsfrage 1: Wann erfordert die Übersetzung Kontext?
- Kontextverwendung auf Wortebene
- Themenanalyse

Forschungsfrage 2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?"</sample>
    <sample id="1064">Der englische Inhalt lautet:

"Thematic analysis of high P-CXMI words"

Übersetzt ins Deutsche bedeutet das:

"Themenanalyse von hochwertigen P-CXMI-Wörtern"</sample>
    <sample id="1065">Thematikanalyse von hochwertigen P-CXMI-Wörtern

1. POS-Kategorien

P-CXMI für POS-Kategorien in En-Ar</sample>
    <sample id="1066">Thematikanalyse von hochwertigen P-CXMI-Wörtern

1. POS-Kategorien
- Pronomen
- Verbform

2. Vokabularelemente</sample>
    <sample id="1067">Themenanalyse von hochwertigen P-CXMI-Wörtern

1. POS Tags
2. Vokabularpunkte

- Pronomen
- Verbform
- Lexikalische Cohesion

Englischer Text:
Avelile's mother was still asleep.
Avelile went to school.

Deutscher Text:
Aveliles Mutter war noch immer wach.
Avelile ging zur Schule.</sample>
    <sample id="1068">Themenanalyse von hochwertigen P-CXMI-Wörtern

1. POS Tags
2. Vokabularpunkte

- Pronomen
- Verbform
- Lexikalische Cohesion
- Formalität

Englischer Text:
Avelile's mother was still asleep.
Avelile went to school.

Deutscher Text:
Aveliles Mutter war noch immer wach.
Avelile ging zur Schule.</sample>
    <sample id="1069">Themenanalyse von hochwertigen P-CXMI-Wörtern

1. POS Tags
2. Wortschatzelemente
3. Einzelne Tokens

- Pronomen
- Verbform
- Lexikalische Cohesion
- Formalität
- Ellipsen</sample>
    <sample id="1070">RQ1: Wann erfordert die Übersetzung Kontext?
- Wortebene Kontextnutzung
- Themenanalyse

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?
- Multilingual Discourse-Aware (MuDA) Benchmark</sample>
    <sample id="1071">Der englische Inhalt lautet:

"Multilingual Discourse-Aware (MuDA) tagger

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis"</sample>
    <sample id="1072">Der englische Inhalt lautet:

"Multilingual Discourse-Aware (MuDA) tagger

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis"

Die Grafik zeigt die Anzahl der Vorkommen von verschiedenen linguistischen Merkmalen in verschiedenen Sprachen. Die Sprachen sind: fr, ja, nl, ru, de, pt_br, ro, es, it, he, zh_cn, ar, tr, ko.

Die legenden sind:
- pronouns
- formality
- verb form
- lexical
- ellipsis</sample>
    <sample id="1073">Multilingual Discourse-Aware (MuDA) tagger

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis

MuDA benchmark

- Dokumente
- MuDA-Tagger
- Ausgabe mit Markierungen

MuDA benchmark

- Dokumente
- MuDA-Tagger
- Ausgabe mit Markierungen
- BLEU
- COMET
- F-Maß</sample>
    <sample id="1074">RQ1: Wann benötigt die Übersetzung Kontext?
- Wortebene Kontextnutzung
- Themenanalyse

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?
- Multilingual Discourse-Aware (MuDA) Benchmark
- Modellbewertung</sample>
    <sample id="1075">Der englische Inhalt lautet:

"Corpus-level metrics

RQ1: When does translation require context?
- Word-level context usage
- Thematic analysis

RQ2: How well do models handle context-dependent translations?
- Multilingual Discourse-Aware (MuDA) benchmark
- Model evaluation"

Übersetzt auf Deutsch:

"Korpusniveau-Maße

Forschungsfrage 1: Wann erfordert die Übersetzung Kontext?
- Wortweiser Kontextgebrauch
- Themenanalyse

Forschungsfrage 2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?
- Multilinguale Diskursbewusste (MuDA) Benchmark
- Modellbewertung"</sample>
    <sample id="1076">Der englische Inhalt lautet:

"Corpus-level metrics

BLEU
COMET
F-measure"

Übersetzt ins Deutsche bedeutet das:

"Korpusniveau-Maße

BLEU
COMET
F-Maß"</sample>
    <sample id="1077">Der englische Text lautet:

"Corpus-level metrics

- BLEU
- COMET
- F-measure

Unclear which system is best for document-level MT with corpus-level metrics"

Übersetzt ins Deutsche bedeutet das:

"Korpus-Ebene-Metriken

- BLEU
- COMET
- F-Maß

Unklar, welches System am besten für die Dokumenten-Ebene-Übersetzung mit Korpus-Ebene-Metriken geeignet ist"</sample>
    <sample id="1078">Der englische Inhalt lautet:

"MuDA Benchmark-Ergebnisse

- Kontextbewusste Modelle zeigen signifikant bessere Ergebnisse bei einigen Phänomenen"</sample>
    <sample id="1079">MuDA Benchmark-Ergebnisse

- Kontextbewusste Modelle zeigen signifikant bessere Ergebnisse bei einigen Phänomenen
  - ✅: Formalität, lexikalische Cohesion
  - ❌: Ellipsen, Pronomen, Verbalformen</sample>
    <sample id="1080">MuDA Benchmark-Ergebnisse

- Kontextbewusste Modelle zeigen signifikant bessere Ergebnisse bei einigen Phänomenen
  - ✅: Formalität, lexikalische Cohesion ❌ Ellipsis, Pronomen, Verbalform
- DeepL übertrifft Google in der Regel bei meisten Phänomenen und Sprachpaaren*</sample>
    <sample id="1081">Zusammenfassung

- Kontextbewusste Modelle leisten bei einigen Phänomenen signifikant besser
  - ✅: Formalität, lexikalische Cohesion ❌ Ellipsen, Pronomen, Verbalform
- DeepL übertrifft Google in der Regel bei meisten Phänomenen und Sprachpaaren*
- Dataset-unabhängiger Benchmark für Dokumenten-Level MT

*Stand: April 2021</sample>
    <sample id="1082">Zusammenfassung

- Identifizieren von Diskursphänomenen systematisch ohne vorherige linguistische Kenntnisse
- Dataset-unabhängiger Benchmark für Dokumenten-Level MT</sample>
    <sample id="1083">Zusammenfassung

- Identifizieren von Diskursphänomenen systematisch ohne vorherige linguistische Kenntnisse
- Dataset-unabhängiger Benchmark für Dokumenten-Level MT</sample>
    <sample id="1084">Der Referent ist Yusen Zhang.</sample>
    <sample id="1121">Die neue Methode hat den Namen "Permuting with 'jumps'".</sample>
    <sample id="1122">The authors describe the method of "marked words" as finding words that distinguish personas of marked groups from unmarked groups.</sample>
    <sample id="1123">Die Autoren gehören der Carnegie Mellon University an.</sample>
    <sample id="1124">Stanford</sample>
    <sample id="1125">Der Referent ist James D. Finch.</sample>
    <sample id="1126">Es sind vier Autoren an der Arbeit beteiligt.</sample>
    <sample id="1127">BLiMP, SyntaxGym und CrowS können zum Testen syntaktischer Phänomene verwendet werden.</sample>
    <sample id="1161">Die Abkürzungen der fünf Methoden für die erste Forschungsfrage sind:

- FT_w
- BOND
- COSINE
- MLC
- L2R</sample>
    <sample id="1162">Das Modell wird an 11 Aufgaben evaluiert.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich mit 4 GB Daten trainiert.</sample>
    <sample id="1227">Der Referent ist Adam Przepiórkowski.</sample>
    <sample id="1228">Die Ergebnisse, die zu der Schlussfolgerung führten, dass die zeitliche Verzögerung die Hauptursache für den Leistungsverlust ist, zeigen, dass die Performance mit größerem zeitlichen Abstand abnimmt.</sample>
    <sample id="1269">The permutation of tokens for the output sequence is necessary to explore all possible combinations and to ensure that the model can learn from different permutations of the same input, which helps in improving the robustness and generalization of the model.</sample>
    <sample id="1270">Die Autoren empfehlen, dass Modellentwickler*innen ihre Methoden zum Abbau von Vorurteilen transparenter machen sollten, um sicherzustellen, dass die Modelle faire und unvoreingenommen sind. Durch Transparenz können potenzielle Bias-Quellen identifiziert und korrigiert werden, was zu einer Verbesserung der Qualität und des Vertrauens in die Modelle führt.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind diejenigen, bei denen die Wahrscheinlichkeit der korrekten Eingabe (P(1)) kleiner oder gleich der Wahrscheinlichkeit der falschen Eingabe (P(2)) ist.</sample>
    <sample id="1272">Die Autoren haben F1-Score, Hamming-Distanz und EMR als Bewertungsmetriken verwendet.</sample>
    <sample id="1273">Die Metrik, die zur Messung der Übereinstimmung zwischen den Kommentatoren verwendet wurde, ist Krippendorff's Alpha.</sample>
    <sample id="1274">Die Domain, die für die hinzugefügten unzusammenhängenden Sätze verwendet wurde, ist Wikipedia.</sample>
    <sample id="1275">Die Autoren gehören der Heinrich Heine University Düsseldorf, Germany an.</sample>
    <sample id="1276">MultiInstruct unterscheidet sich von anderen Benchmarks durch die Fülle an Sprachnur-Instruktionsaufgaben (1600+) und die Tatsache, dass es keine großen, öffentlich zugänglichen multimodalen Instruktionsaufgaben gibt.</sample>
    <sample id="1277">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="1278">Die binäre Koordination ist eine grammatische Konstruktion, bei der zwei gleichrangige Elemente (wie Nomen oder Adjektive) durch einen Konjunkt verbunden werden.</sample>
    <sample id="1279">Die Frage kann nicht direkt aus dem gezeigten Bild beantwortet werden, da das Bild keine Informationen über die Länge der verwendeten Prompts enthält.</sample>
    <sample id="1280">Die Ergebnisse zeigen, dass das kleinere T5-Modell, das auf Coscript trainiert wurde, höhere Qualitätsskripte generieren kann als große LLMs wie GPT-3, Codex und InstructGPT.</sample>
    <sample id="1281">Der englische Text lautet:

"DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains"

Übersetzt ins Deutsche bedeutet das:

"DrBERT: Ein robustes prätrainiertes Modell auf Französisch für biomedizinische und klinische Bereiche"</sample>
    <sample id="1282">Zusammenfassung

I. Sprachmodellierung im Gesundheitswesen
II. Vergleich von Vortrainingsstrategien, Datenquellen und -mengen
III. Bewertung von 13 Modellen auf 11 Aufgaben
IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1283">Zusammenfassung

I. Sprachmodellierung im Gesundheitswesen
II. Vergleich von Vorausbildungsstrategien, Datenquellen und -mengen
III. Bewertung von 13 Modellen auf 11 Aufgaben
IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1284">Zusammenfassung

I. Sprachmodellierung im Gesundheitswesen
II. Vergleich von Vorausbildungsstrategien, Datenquellen und -mengen
III. Bewertung von 13 Modellen auf 11 Aufgaben
IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1285">Hier ist der übertragene Inhalt in die deutsche Sprache:

I. Sprachmodellierung im Gesundheitswesen
- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungssteigerungen bei vielen NLP-Aufgaben

II. Vergleich von Vorkonditionierungsstrategien, Datenquellen und -mengen
- Has been adapted to French with CamemBERT and FlauBERT
- PudMedBERT, BioBERT, ClinicalBERT und andere

III. Bewertung von 13 Modellen auf 11 Aufgaben
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vorkonditionierung mit einem bestehenden generischen Modell

IV. Verteilung von NACHOS und DrBERT
- Unterschiedlich von generischen Modellen, gibt es noch kein offenes Quellmodell für den biomedizinischen Bereich auf Französisch
- Ein BERT-basierter domänenspezifischer Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern</sample>
    <sample id="1286">Natürlich, hier ist der englische Inhalt in die deutsche Sprache übersetzt:

---

**Sprachmodellierung**

- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungssteigerungen bei vielen NLP-Aufgaben.
- Diese wurden für Französisch mit CamemBERT und FlauBERT angepasst.
- Bei medizinischen Aufgaben haben spezifische Modelle im Englischen den Standard noch weiter angehoben:
  - PubMedBERT, BioBERT, ClinicalBERT und andere.
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vortraining mit einem bestehenden generischen Modell.
- Im Gegensatz zu generischen Modellen gibt es keine offene Quelle für den biomedizinischen Bereich in Französisch.
- Ein BERT-basierter spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern.

---

Ich hoffe, dies hilft!</sample>
    <sample id="1287">Natürlich, hier ist der englische Inhalt in die deutsche Sprache übersetzt:

---

**Sprachmodellierung**

- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungssteigerungen bei vielen NLP-Aufgaben.
- Diese wurden für Französisch mit CamemBERT und FlauBERT angepasst.
- Bei medizinischen Aufgaben haben spezifische Modelle im Englischen die Leistungsebene noch weiter angehoben:
  - PubMedBERT, BioBERT, ClinicalBERT und andere.
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vortraining mit einem bestehenden generischen Modell.
- Im Gegensatz zu generischen Modellen gibt es bislang kein offenes Quellcode-Modell für den biomedizinischen Bereich in Französisch.
- Ein BERT-basierter spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern.

---</sample>
    <sample id="1288">Natürlich, hier ist der übertragene Inhalt in die deutsche Sprache:

---

**Sprachmodellierung**

- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungssteigerungen bei vielen NLP-Aufgaben.
- Diese wurden für Französisch mit CamemBERT und FlauBERT angepasst.
- Bei medizinischen Aufgaben verbessern spezifische Modelle im Englischen die Leistung noch weiter.
  - Beispiele: PubMedBERT, BioBERT, ClinicalBERT und andere.
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vortraining mit einem bestehenden generischen Modell.
- Im Gegensatz zu generischen Modellen gibt es bislang kein offenes Quellcode-Modell für den biomedizinischen Bereich in Französisch.
- Ein BERT-basierter spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben erhöhen.

---</sample>
    <sample id="1289">Natürlich, hier ist der übertragene Inhalt in die deutsche Sprache:

---

**Sprachmodellierung**

- Transformer-basierte Ansätze, wie BERT, bieten bei vielen NLP-Aufgaben enorme Leistungssteigerungen.
- Diese wurden für Französisch mit CamemBERT und FlauBERT angepasst.
- Bei medizinischen Aufgaben verbessern spezifische Modelle im Englischen die Leistung noch weiter:
  - PubMedBERT, BioBERT, ClinicalBERT und andere.
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vortraining mit einem bestehenden generischen Modell.
- Im Gegensatz zu generischen Modellen gibt es bislang kein offenes Quellcode-Modell für den biomedizinischen Bereich in Französisch.
- Ein BERT-basierter spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben erhöhen.

---</sample>
    <sample id="1290">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quellendatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenbestand des Nantes University Hospital extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1291">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quelldatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenbestand des Nantes University Hospital extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden prätrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1292">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Eine offene Quelle mit 1,1 Milliarden Wörtern, die aus verschiedenen medizinischen Bereichen, Natur und Stilen heterogener Daten gezogen wurden.
  - **NBDW**: Eine private Datenquelle von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenlager des Universitätskrankenhauses von Nantes stammen.

- **Vergleich von Lernstrategien**
  - **Von Scratch mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)

| Korpus | Größe | Anzahl der Wörter | Anzahl der Sätze |
|--------|-------|------------------|-----------------|
| NACHOSlarge (pub.) | 7,4 GB | 1,1 B | 54,2 M |
| NACHOSsmall (pub.) | 4 GB | 646 M | 25,3 M |
| NBDWsmall (privat) | 4 GB | 655 M | 43,1 M |
| NBDWmixed (beide) | 4+4 GB | 1,3 B | 68,4 M |

| Modellname | Strategie | Korpus |
|------------|-----------|--------|
| DrBERT     | Von Scratch | NACHOSlarge |
| DrBERT     | Von Scratch | NACHOSsmall |
| ChuBERT    | Von Scratch | NBDWsmall |
| ChuBERT    | Von Scratch | NBDWmixed |
| CamemBERT  | Fortlaufendes Vortraining | NACHOSsmall |
| PubMedBERT | Fortlaufendes Vortraining | NACHOSsmall |
| CamemBERT  | Fortlaufendes Vortraining | NBDWsmall |

Avignon Universität</sample>
    <sample id="1293">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quelldatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenbestand des Universitätskrankenhauses von Nantes stammen.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1294">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Eine offengebene Datenbank mit 1,1 Milliarden Wörtern, die aus verschiedenen medizinischen Bereichen, Arten und Stilen gesammelt wurden.
  - **NBDW**: Eine private Datenbank von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenbestand des Nantes University Hospital extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Scratch mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden prätrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1295">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Eine offene Quelle mit 1,1 Milliarden Wörtern, die aus verschiedenen medizinischen Bereichen, Natur und Stilen heterogener Daten gezogen wurden.
  - **NBDW**: Eine private Datenquelle von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenbestand des Universitätskrankenhauses von Nantes stammen.

- **Vergleich von Lernstrategien**
  - **Von Scratch mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)

| Korpus | Größe | Anzahl der Wörter | Anzahl der Sätze |
|--------|-------|------------------|-----------------|
| NACHOSlarge (pub.) | 7,4 GB | 1,1 B | 54,2 M |
| NACHOSsmall (pub.) | 4 GB | 646 M | 25,3 M |
| NBDWsmall (privat) | 4 GB | 655 M | 43,1 M |
| NBDWmixed (beide) | 4+4 GB | 1,3 B | 68,4 M |

| Modellname | Strategie | Korpus |
|------------|-----------|--------|
| DrBERT     | Von Scratch | NACHOSlarge |
| DrBERT     | Von Scratch | NACHOSsmall |
| ChuBERT    | Von Scratch | NBDWsmall |
| ChuBERT    | Von Scratch | NBDWmixed |
| CamemBERT  | Fortlaufendes Vortraining | NACHOSsmall |
| PubMedBERT | Fortlaufendes Vortraining | NACHOSsmall |
| CamemBERT  | Fortlaufendes Vortraining | NBDWsmall |

Avignon Universität</sample>
    <sample id="1296">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quellendatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenbestand des Nantes University Hospital extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1297">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quellendatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stil katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenbestand des Nantes University Hospital extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englisch-basierter medizinisches Modell)

### Bewertung: Datenquellen und Größe

- **Leistungsbewertung von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat**
- Unsere fein-tuning-Modelle erzielen fast immer die aktuell besten Ergebnisse

| Modellname | Strategie | Korpus |
|------------|-----------|--------|
| DrBERT     | Von Grund auf | NACHOSlarge |
| DrBERT     | Von Grund auf | NACHOSsmall |
| ChuBERT    | Von Grund auf | NBDWsmall |
| ChuBERT    | Von Grund auf | NBDWmixed |

| Modellname | Strategie | Korpus |
|------------|-----------|--------|
| CamemBERT  | Fortlaufende Vortraining | NACHOSsmall |
| PubMedBERT | Fortlaufende Vortraining | NACHOSsmall |
| CamemBERT  | Fortlaufende Vortraining | NBDWsmall |

| Modellname | F1 | CLS | NER | CLS | F1 | F1 | F1 | Hamming | EMR | F1 | F1 |
|------------|----|-----|-----|-----|----|----|----|--------|----|----|----|
| General    | 42.66 | 81.41 | 88.78 | 99.61 | 85.43 | 91.27 | 83.69 | 96.42 | 15.37 | 90.83 | 78.76 |
| Biomedizinische | 48.22 | 81.25 | 89.83 | 99.86 | 91.04 | 92.24 | 89.75 | 95.65 | 36.66 | 92.09 | 77.88 |
| Klinische   | 49.01 | 81.56 | 89.58 | 99.83 | 92.23 | 92.17 | 87.71 | 95.61 | 35.16 | 88.15 | 74.94 |
| ClinicalBERT | 44.70 | 77.12 | 88.77 | 98.58 | 90.36 | 82.95 | 88.24 | 96.73 | 32.78 | 14.19 | 84.79 | 75.05 |
| ChuBERT NBDWsmall | 49.14 | 81.98 | 89.30 | 99.81 | 92.73 | 91.71 | 85.73 | 96.35 | 34.58 | 12.21 | 90.52 | 78.63 |

Avignon Universität</sample>
    <sample id="1298">Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben</sample>
    <sample id="1299">Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die besten Ergebnisse</sample>
    <sample id="1300">Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentliche als auch private
- Unsere feinabgestimmten Modelle erzielen fast immer die besten Ergebnisse aller Aufgaben</sample>
    <sample id="1301">Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben

Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben

Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben</sample>
    <sample id="1302">Evaluation: Vorbereitungsmethoden

- Ausgehend von Null vs. kontinuierliche Vorbereitung mit 4 GB Daten
- Fragestellungen erfordern mehr spezifisches Wissen über das jeweilige Fachgebiet, um gut zu funktionieren
- Eine Studie zur Modellstabilität zeigt eine höhere Inter-run-Variabilität für CamemBERT-basierte Modelle, die mit kontinuierlicher Vorbereitung trainiert wurden</sample>
    <sample id="1303">Evaluation: Vorbereitungsmethoden

- Ausgehend von Null vs. kontinuierliche Vorbereitung mit 4 GB Daten
- Fragestellungen erfordern mehr spezifisches Wissen über das jeweilige Fachgebiet, um gut zu funktionieren
- Eine Studie zur Modellstabilität zeigt eine höhere Inter-run-Variabilität für CamemBERT-basierte Modelle, die mit kontinuierlicher Vorbereitung trainiert wurden</sample>
    <sample id="1304">Evaluation: Vortrainingsstrategien

- Ausgehend von Null vs. kontinuierliches Vortraining auf 4 GB Daten
- Fragestellungen erfordern mehr spezifisches Wissen über das jeweilige Fachgebiet, um gut zu funktionieren
- Eine Studie zur Modellstabilität zeigt eine höhere Inter-run-Variabilität für CamemBERT-basierte Modelle, die mit kontinuierlichem Vortraining trainiert wurden</sample>
    <sample id="1305">Natürlich, hier ist der übertragene Inhalt in die deutsche Sprache:

---

**Kernbotschaft**

- DrBERT erreicht im 9er-Downstream-French-Medical-Oriented-Aufgaben die aktuell besten Ergebnisse.
  - Übertrifft CamemBERT generische Modelle und Englisch-basierte Domänen-spezifische Modelle.
  - Bestätigt die Nutzbarkeit des Trainings eines medizinisch spezifischen Modells auf Französisch.

- Datenquellen zählen: Das Training an heterogenen Daten ist wichtig.
  - NACHOS ist robuster als das Verwenden nur privater klinischer Daten.

- Mehr Daten ist besser, aber es skaliert nicht gut.
- Kontinuierliches Vortraining ist eine effektivere Strategie, wenn auf spezifischen Englisch-Modellen basiert wird.
- Die DrBERT-Modelle, das NACHOS-Dataset und die Trainingsskripte sind unter der MIT-Lizenz frei verfügbar.

---</sample>
    <sample id="1306">Natürlich, hier ist der übertragenen Inhalt in die deutsche Sprache:

---

**Kernbotschaft**

- DrBERT erreicht Spitzenleistungen in 9 downstream französischen medizinischen Aufgaben.
  - Übertrifft CamemBERT generische Modelle und englisch-basierte domänenspezifische Modelle.
  - Bestätigt die Nutzbarkeit des Trainings eines medizinisch spezifischen Modells auf Französisch.

- Datenquellen zählen: Das Training an heterogenen Daten ist wichtig.
  - NACHOS ist robuster als das Verwenden nur privater klinischer Daten.

- Mehr Daten ist besser, aber es skaliert nicht gut.

- Kontinuierliches Vortraining ist eine effektivere Strategie, wenn auf domänenspezifischen englischen Modellen basiert wird.

- Die DrBERT-Modelle, das NACHOS-Dataset und die Trainingsskripte sind unter der MIT-Lizenz frei verfügbar.

---</sample>
    <sample id="1307">Natürlich, hier ist der übertragene Inhalt in die deutsche Sprache:

---

**Kernbotschaft**

- DrBERT erreicht Spitzenleistungen in 9 downstream französischen medizinischen Aufgaben.
  - Übertrifft CamemBERT generische Modelle und englisch-basierte domänenspezifische Modelle.
  - Bestätigt die Nutzbarkeit des Trainings eines medizinisch spezifischen Modells auf Französisch.

- Datenquellen zählen: Das Training an heterogenen Daten ist wichtig.
  - NACHOS ist robuster als das Verwenden nur privater klinischer Daten.

- Mehr Daten ist besser, aber es skaliert nicht gut.

- Kontinuierliches Vortraining ist eine effektivere Strategie, wenn auf domänenspezifischen englischen Modellen basiert wird.

- Die DrBERT-Modelle, das NACHOS-Dataset und die Trainingsskripte sind unter der MIT-Lizenz frei verfügbar.

---</sample>
    <sample id="1308">Hier ist der englische Inhalt in die deutsche Sprache übersetzt:

"Danke

Ich freue mich auf die Austauschveranstaltung im Poster-Saal in Toronto!"

Weitere Informationen unter: drbert.univ-avignon.fr

Avignon Universität</sample>
    <sample id="1309">Die Arbeit untersucht zwei Lernstrategien: "From scratch" mit vollständiger Modellkonstruktion und "Continual pre-training" mit einem bestehenden prätrainierten Modell.</sample>
    <sample id="1310">Der Faktor der Überanpassung, der auf die Wiederverwendung von Tests zurückzuführen ist, beträgt 0.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde anhand von vier Metriken bewertet: SARI, BLEU, BS-P und FRE.</sample>
    <sample id="1312">Ja, Sprachmodelle wie die in dem Diagramm dargestellten haben unterschiedliche politische Vorurteile.</sample>
    <sample id="1313">Der englische Text lautet:

"Compositional Generalization without Trees using Multiset Tagging and Latent Permutations

Matthias Lindemann, Alexander Koller, Ivan Titov"

Übersetzt ins Deutsche bedeutet das:

"Kompositionale Generalisierung ohne Bäume mit Hilfe von Multiset-Tagging und latenten Permutationen

Matthias Lindemann, Alexander Koller, Ivan Titov"</sample>
    <sample id="1314">Der englische Text lautet:

"Compositional Generalization without Trees using Multiset Tagging and Latent Permutations"

Die Autoren sind:

Matthias Lindemann, Alexander Koller, Ivan Titov

Unterstützt wird das Projekt von folgenden Institutionen und Programmen:

- The University of Edinburgh (Informatik)
- NLP UKRI Centre for Doctoral Training
- Saarland University
- University of Amsterdam</sample>
    <sample id="1315">Kompositionale Generalisierung

Fähigkeit eines Lerners, tiefe Rekursion und unerwartete Kombinationen von Phrasen zu beherrschen, die während des Trainings einzeln gesehen wurden.</sample>
    <sample id="1316">Der englische Text lautet:

"Compositional Generalization in Semantic Parsing

Train:
The girl slept.
*girl x1 sleep.agent x2 x1

Mary knew that the girl slept.
*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧
sleep.agent x5 x4"

Übersetzt ins Deutsche:

"Kompositionale Generalisierung im Semantischen Parsen

Trainieren:
Die Mädchen schlief.
*girl x1 sleep.agent x2 x1

Mary wusste, dass die Mädchen schlief.
*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧
sleep.agent x5 x4"</sample>
    <sample id="1317">Der englische Text lautet:

"Compositional Generalization in Semantic Parsing

Train:
The girl slept.
*girl x1 sleep.agent x2 x1

Mary knew that the girl slept.
*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧
sleep.agent x5 x4"

Übersetzt ins Deutsche:

"Kompositionale Generalisierung im Semantischen Parsen

Trainieren:
Die Mädchen schlief.
*girl x1 sleep.agent x2 x1

Mary wusste, dass die Mädchen schlief.
*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧
sleep.agent x5 x4"</sample>
    <sample id="1318">Die Übersetzung des englischen Inhalts ins Deutsche lautet:

**Kompositionelle Generalisierung in semantischer Parsen**

Train:
- Die Mädchen schlief.
  - *girl x1 sleep.agent x2 x1

- Mary wusste, dass die Mädchen schlief.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

Test:
- Jim sagte, dass Mary wusste, dass die Mädchen schlief.
  - *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7</sample>
    <sample id="1319">Der englische Text lautet:

"Compositional Generalization in Semantic Parsing

Train:
The girl slept.
*girl x1 sleep.agent x2 x1

Mary knew that the girl slept.
*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

Test:
Jim said that Mary knew that the girl slept.
*girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7"

Übersetzt ins Deutsche:

"Kompositionale Generalisierung im Semantischen Parsen

Trainieren:
Die Mädchen schlief.
*girl x1 sleep.agent x2 x1

Mary wusste, dass die Mädchen schlief.
*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

Test:
Jim sagte, dass Mary wusste, dass die Mädchen schlief.
*girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7"</sample>
    <sample id="1320">Der englische Text lautet:

"Kompositionelle Generalisierung in Semantischer Parsen"

Trainieren:
- Die Mädchen schlief.
  - *girl x1 sleep.agent x2 x1

- Mary wusste, dass die Mädchen schlief.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

Test:
- Jim sagte, dass Mary wusste, dass die Mädchen schlief.
  - *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7

Naive seq2seq Modelle scheitern!

3</sample>
    <sample id="1321">Der englische Text lautet:

"Kompositionelle Generalisierung in Semantischer Parsen"

Trainieren:
- Die Mädchen schlief.
  - *girl x1 sleep.agent x2 x1

- Mary wusste, dass die Mädchen schlief.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

Test:
- Jim sagte, dass Mary wusste, dass die Mädchen schlief.
  - *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7

Naive seq2seq Modelle scheitern!

3</sample>
    <sample id="1322">Baumstrukturen helfen sehr, aber...</sample>
    <sample id="1323">Baumstrukturen helfen sehr, aber...</sample>
    <sample id="1324">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen erzeugt werden:
- Vor/Postverarbeitung logischer Formen</sample>
    <sample id="1325">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen erzeugt werden:
- Vor/Postverarbeitung logischer Formen</sample>
    <sample id="1326">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen ermittelt werden:
- Vor/Nachverarbeitung logischer Formen
- Grammatik-induktion

4</sample>
    <sample id="1327">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen erzeugt werden:
- Vor/Postverarbeitung logischer Formen
- Grammatik-induktion

Dieses Papier: neuronales seq2seq-Modell, das direkt die Korrespondenzen zwischen Fragmenten modelliert. Zum ersten Mal zeigen wir starke Generalisierung zu tiefen Rekursionen ohne Bäume.</sample>
    <sample id="1328">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen erzeugt werden:
- Vor/Postverarbeitung logischer Formen
- Grammatik-induktion

Dieses Papier: neuronales seq2seq-Modell, das die Korrespondenzen zwischen Fragmenten direkt modelliert. Zum ersten Mal zeigen wir starke Generalisierung zu tiefen Rekursionen ohne Bäume.</sample>
    <sample id="1329">Der englische Text lautet "Our Approach" und der deutsche Übersetzungsinhalt ist "Unser Ansatz".</sample>
    <sample id="1330">Der englische Text lautet "Our Approach" und der deutsche Übersetzungsinhalt ist "Unser Ansatz".</sample>
    <sample id="1331">Der englische Text lautet "Our Approach" und der deutsche Übersetzungsinhalt ist "Unser Ansatz".</sample>
    <sample id="1332">Der englische Text lautet "Our Approach" und der deutsche Übersetzungsinhalt ist "Unser Ansatz".</sample>
    <sample id="1333">Der englische Text lautet "Our Approach" und der deutsche Übersetzungsinhalt ist "Unser Ansatz".</sample>
    <sample id="1334">Der englische Text lautet "Permuting with 'jumps'". Dies bedeutet "Permutieren mit 'Sprüngen'".</sample>
    <sample id="1335">Der Titel "Permuting with 'jumps'" bedeutet auf Deutsch "Permutieren mit 'Sprüngen'".</sample>
    <sample id="1336">Der englische Text lautet "Permuting with 'jumps'". Dies bedeutet "Permutieren mit 'Sprüngen'".</sample>
    <sample id="1337">Der englische Text lautet "Permuting with 'jumps'". Dies bedeutet "Permutieren mit 'Sprüngen'".</sample>
    <sample id="1338">Der englische Text lautet "Permuting with 'jumps'". Dies bedeutet "Permutieren mit 'Springen'".</sample>
    <sample id="1339">Die Übersetzung des englischen Inhalts ins Deutsche lautet:

"Einige Ergebnisse auf COGS (Kim und Linzen 2020)

Vergleich mit anderen baumlosen Modellen in Bezug auf strukturelle Generalisierung auf COGS

Modell
- LSTM seq2seq
- T5
- Zheng und Lapata
- Unsere Methode"

Die Grafik zeigt die Ergebnisse verschiedener Modelle bei der strukturellen Generalisierung auf dem COGS-Datensatz, wobei die x-Achse verschiedene Typen von Generalisierungen (PP recursion, CP recursion, Obj PP → Subj PP) und die y-Achse die Genauigkeit (Acc) darstellt.</sample>
    <sample id="1340">Die Übersetzung des englischen Inhalts ins Deutsche lautet:

"Einige Ergebnisse auf COGS (Kim und Linzen 2020)

Vergleich mit anderen baumlosen Modellen in Bezug auf strukturelle Generalisierung auf COGS

Modell
- LSTM seq2seq
- T5
- Zheng und Lapata
- Unsere Methode"

Die Grafik zeigt die Ergebnisse verschiedener Modelle bei der strukturellen Generalisierung auf COGS, wobei die x-Achse verschiedene Typen von Generalisierungen (PP recursion, CP recursion, Obj PP → Subj PP) und die y-Achse die Genauigkeit (Acc) darstellt.</sample>
    <sample id="1341">Die Übersetzung des englischen Inhalts ins Deutsche lautet:

**Technische Herausforderungen, die wir lösen**

Permute

Tag

Alignment unbekannt.</sample>
    <sample id="1342">Die technischen Herausforderungen, die wir lösen:

Alignment unbekannt.</sample>
    <sample id="1343">Die Übersetzung des englischen Inhalts ins Deutsche lautet:

**Technische Herausforderungen, die wir lösen**

Alignment unbekannt.
- Induzieren es im Training.</sample>
    <sample id="1344">### Technische Herausforderungen, die wir lösen

Alignment unbekannt.
- Induzieren Sie es im Training.

Permutationsmodell:
- Inferenz ist NP-schwer (≈ TSP)</sample>
    <sample id="1345">### Technische Herausforderungen, die wir lösen

Alignment unbekannt.
- Induzieren Sie es im Training.

Permutationsmodell:
- Inferenz ist NP-schwer (≈ TSP)
- Rückpropagation durch kontinuierliche Relaxation</sample>
    <sample id="1346">### Technische Herausforderungen, die wir lösen

**Alignment unbekannt.**
- Induzieren Sie es im Training.

**Permutationsmodell:**
- Inferenz ist NP-schwer (≈ TSP)
- Rückpropagation durch kontinuierliche Relaxation

**Paper &amp; Code:**  
https://t.ly/mX8ny</sample>
    <sample id="1347">Kognitive Dissonanz ist die Unstimmigkeit zwischen zwei Elementen der Kognition, wie Gedanken, Handlungen und Überzeugungen.</sample>
    <sample id="1348">Das Sprachmodell "Alpaca" steht am meisten links.</sample>
    <sample id="1349">Ja, kumulatives Training scheint für aktives Lernen besser zu sein als iteratives Training, basierend auf dem AUC-Wert in der Grafik.</sample>
    <sample id="1350">Der Referent ist Sara Papi.</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen aus dem TED-Lexicon.</sample>
    <sample id="1385">Matthias Lindemann, Alexander Koller, Ivan Titov</sample>
    <sample id="1386">Sprachübergreifender Transfer bezieht sich auf das Trainieren eines Modells auf einer Quellsprache und das Übertragen dieser Fähigkeiten auf eine andere Sprache.</sample>
    <sample id="1387">Die Autoren gehören der Saarland University, Amazon Alexa und der University of Vienna an.</sample>
    <sample id="1388">The authors use latency measurements in their study.</sample>
    <sample id="1389">The KITMUS Test
Evaluating Knowledge Integration from Multiple Sources

McGill University/Mila
Akshatha Arodi*
Martin Pömsl*

Microsoft Research
Kaheer Suleman
Adam Trischler

McGill University/Mila
Alexandra Olteanu
Jackie CK Cheung</sample>
    <sample id="1390">NLU-Modelle ziehen auf mehrere Wissensquellen zurück.

Wissen in Parametern (vortrainiertes Wissen)
Wissen im Kontext (inferencezeitiges Wissen)

NLU-Modell</sample>
    <sample id="1391">NLU-Modelle ziehen auf mehrere Wissensquellen zurück.</sample>
    <sample id="1392">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1393">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1394">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1395">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1396">KITMUS Test Suite
- Datensatz zur Evaluierung der Wissensintegration
- Coreferenzauflösungsaufgabe, um die Fähigkeit zu prüfen, auf
  - prätrainiertes Wissen
  - inferenzzeitliches Wissen
- Experimente mit
  - menschlichen Studienteilnehmern
  - Coreferenzauflösungsmodellen</sample>
    <sample id="1397">KITMUS Test Suite

- Datensatz zur Evaluierung der Wissensintegration
- Coreferenzauflösungsaufgabe, um die Fähigkeit zu prüfen, auf
  - prätrainiertes Wissen
  - inferenzzeitliches Wissen
- Experimente mit
  - menschlichen Studienteilnehmern
  - Coreferenzauflösungsmodellen</sample>
    <sample id="1398">Servin ist ein Richter. Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag an der Arbeit, bei dem er Gerichte entschied, war er froh, sich auszuruhen. [Antwort: Servin]</sample>
    <sample id="1399">Servin ist ein Richter. Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag am Arbeitsplatz, bei dem er Gerichte entschied, war er froh, sich auszuruhen. [Antwort: Servin]</sample>
    <sample id="1400">KITMUS Test Suite

Servin ist ein Richter, Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag am Arbeitsplatz, bei dem er Gerichtsverfahren in einem Gerichtssaal entschied, war er froh, sich auszuruhen. [Antwort: Servin]

1) Entity-specific knowledge</sample>
    <sample id="1401">KITMUS Test Suite

Servin ist ein Richter, Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag am Arbeitsplatz, bei dem sie in Gerichten Entscheidungen fällten, war er glücklich, sich auszuruhen. [Antwort: Servin]

1) Entity-specific knowledge
   spezifisches Wissen über Objekte

2) Background knowledge
   Hintergrundwissen</sample>
    <sample id="1402">KITMUS Test Suite

Servin ist ein Richter, Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag an der Arbeit, bei dem sie in einem Gerichtssaal Entscheidungen fällten, war er froh, sich auszuruhen. [Antwort: Servin]

1) Entity-specific knowledge
   spezifisches Wissen über Objekte

2) Background knowledge
   Hintergrundwissen</sample>
    <sample id="1403">Die Varianten von KITMUS sind:

a) Background-Pretrain: Typischer Setup

b) Background-Both: Erstellt explizit das Hintergrundwissen im Kontext

c) Background-Inference: Das Wissen ist nur während der Inferenz verfügbar</sample>
    <sample id="1404">Die Varianten von KITMUS sind:

a) Background-Pretrain: Typischer Setup

b) Background-Both: Hintergrundwissen explizit im Kontext bereitstellen

c) Background-Inference: Wissen nur während der Inferenz verfügbar</sample>
    <sample id="1405">Die Varianten von KITMUS sind:

a) Background-Pretrain: Typischer Setup

b) Background-Both: Erstellt explizit das Hintergrundwissen im Kontext

c) Background-Inference: Das Wissen ist nur während der Inferenz verfügbar</sample>
    <sample id="1406">Die englische Aufschrift lautet "Variants of KITMUS". Der deutsche Inhalt lautet sinngemäß:

"Varianten von KITMUS"

Unter den verschiedenen Varianten sind die folgenden Beschreibungen zu finden:

1. **Background-Pretrain**
   - Politicians seek elected seats in government.
   - Chichester is a politician.

2. **Background-Both**
   - Politicians seek elected seats in government.
   - Chichester is a politician.
   - The work of a politician is seeking an elected seat in government.

3. **Background-Inference**
   - Chichester is a mirituer.
   - The work of a mirituer is eheming smorbly.</sample>
    <sample id="1407">Die Varianten von KITMUS:

- **Background-Pretain**: Politiker streben nach gewählten Sitzen im Regierungsausschuss.
- **Background-Both**: Chichester ist ein Politiker.
- **Background-Inference**: Politiker streben nach gewählten Sitzen im Regierungsausschuss.
- **Background-Both**: Chichester ist ein Politiker.
- **Background-Inference**: Die Arbeit eines Politikers besteht darin, nach einem gewählten Sitz im Regierungsausschuss zu streben.
- **Background-Inference**: Chichester ist ein Mirituer.
- **Background-Inference**: Die Arbeit eines Mirituers besteht darin, ehementing smorbtly.</sample>
    <sample id="1408">Die englische Aufschrift lautet "Variants of KITMUS". Der deutsche Inhalt lautet sinngemäß:

"Varianten von KITMUS"

Unter den Varianten sind die folgenden beschrieben:

1. **Background-Pretrain**: Politiker suchen gewählte Sitze im Regierungsausschuss.
2. **Background-Both**: Chichester ist ein Politiker.
3. **Background-Inference**: Politiker suchen gewählte Sitze im Regierungsausschuss.

Diese Variante enthält zusätzliche Informationen über die Arbeit eines Politikers und die Tätigkeit eines Mirituerers.</sample>
    <sample id="1409">Die Varianten von KITMUS:

- Background-Pretrain: Politiker streben nach gewählten Sitzen im Regierungsausschuss.
- Chichester ist ein Politiker.
- Background-Both: Politiker streben nach gewählten Sitzen im Regierungsausschuss.
- Chichester ist ein Politiker.
- Die Arbeit eines Politikers besteht darin, nach einem gewählten Sitz im Regierungsausschuss zu streben.
- Background-Inference: Chichester ist ein Mirituer.
- Die Arbeit eines Mirituers besteht darin, ehement smorbtly.</sample>
    <sample id="1410">Der englische Inhalt lautet:

"Background-Pretrain

Task-specific training is necessary for knowledge integration"

Die deutsche Übersetzung lautet:

"Hintergrund-Prätraining

Spezifische Aufgabenorientierte Training ist für die Wissensintegration notwendig"</sample>
    <sample id="1411">Der englische Inhalt lautet: "Background-Pretrain"

Die deutsche Übersetzung lautet: "Hintergrund-Prätraining"</sample>
    <sample id="1412">Der englische Inhalt lautet: "Background-Pretrain"

Die deutsche Übersetzung lautet: "Hintergrund-Prätraining"

Unter dem Diagramm steht: "Task-specific training is necessary for knowledge integration"

Die deutsche Übersetzung lautet: "Aufgabebezogene Training ist für die Wissensintegration notwendig"</sample>
    <sample id="1413">Der englische Inhalt lautet: "Background-Inference" und "Models struggle to integrate inference-time background knowledge". 

Die deutsche Übersetzung lautet: "Hintergrund-Inferenz" und "Modelle haben Schwierigkeiten, während des Inferenzzeitpunkts Hintergrundwissen zu integrieren."</sample>
    <sample id="1414">Zusammenfassung:

Hauptpunkte:
1. Viele Modelle scheinen nicht in der Lage zu sein, Wissen aus verschiedenen Quellen (vor- und während des Trainings) zu verarbeiten.
2. Aufgabebezogene Training ist notwendig für die Integration von Wissen.
3. Modelle haben Schwierigkeiten, während des Inferenzvorgangs Hintergrundwissen zu integrieren.

Finden Sie das Dataset, die Generations- und Bewertungscode auf GitHub unter mpoemsl/kitmus.</sample>
    <sample id="1415">Zusammenfassung:

Hauptpunkte:
1. Viele Modelle scheinen nicht in der Lage zu sein, Wissen aus verschiedenen Quellen (vor- und während des Trainings) zu verarbeiten.
2. Aufgabebezogene Training ist notwendig für die Integration von Wissen.
3. Modelle haben Schwierigkeiten, während des Inferenzzeitraums Hintergrundwissen zu integrieren.

Finden Sie das Dataset, die Generations- und Bewertungscode auf GitHub unter mpoemsl/kitmus.</sample>
    <sample id="1416">Die Nachteile der baumbasierten Methoden sind, dass sie vor- und/oder nachbearbeitete logische Formen benötigen und Grammatik-induktion.</sample>
    <sample id="1417">Die Autoren Shuheng Liu und Alan Ritter gehören der Georgia Institute of Technology an.</sample>
    <sample id="1418">Der englische Text lautet:

"Marked Personas
Using Natural Language Prompts to Measure Stereotypes in Language Models
Myra Cheng, Esin Durmus, Dan Jurafsky
ACL 2023"

Übersetzt auf Deutsch bedeutet das:

"Markierte Persönlichkeiten
Verwendung natürlicher Sprachanweisungen zur Messung von Stereotypen in Sprachmodellen
Myra Cheng, Esin Durmus, Dan Jurafsky
ACL 2023"</sample>
    <sample id="1419">Markierte Persönlichkeiten: Motivation

Soziale Vorurteile und Stereotypen sind in LLMs (Large Language Models) weit verbreitet.

Nachteile der bestehenden Stereotypenmessungen:
- Tradeoff zwischen Spezifität und Allgemeingültigkeit
- Basieren auf festen, handcurierten Datensätzen
- Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1420">Markierte Persönlichkeiten: Motivation

Soziale Vorurteile und Stereotypen sind in LLMs (Large Language Models) weit verbreitet.

Nachteile der bestehenden Stereotypenmessungen:
- Tradeoff zwischen Spezifität und Allgemeingültigkeit
- Basieren auf festen, handcurierten Datensätzen
- Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1421">Markierte Persönlichkeiten: Motivation

Soziale Vorurteile und Stereotypen sind in LLMs (Large Language Models) weit verbreitet.

Nachteile der bestehenden Stereotypenmessungen:
- Tradeoff zwischen Spezifität und Allgemeingültigkeit
- Basieren auf festen, handcurierten Datensätzen
- Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1422">Markierte Persönlichkeiten: Motivation

Soziale Vorurteile und Stereotypen sind in LLMs (Large Language Models) verbreitet.

Nachteile der bestehenden Stereotypenmessungen:
- Tradeoff zwischen Spezifität und Allgemeingültigkeit
- Basieren auf festen, handcurierten Datensätzen
- Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1423">Wie überwinden wir diese Einschränkungen?

GPT-3.5, GPT-4 usw. können auf Anweisungen in Prompts reagieren.</sample>
    <sample id="1424">Wie überwinden wir diese Einschränkungen?

GPT-3.5, GPT-4 usw. können auf Anweisungen in Prompts reagieren.

Eingabe: "Denken Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst."</sample>
    <sample id="1425">Wie überwinden wir diese Einschränkungen?

GPT-3.5, GPT-4 usw. können auf Anweisungen in Prompts antworten.

Eingabe: "Denken Sie sich aus, dass Sie eine asiatische Frau sind. Beschreiben Sie sich selbst."

Allgemein anwendbar:
kann jede intersektionale Identität bewerten</sample>
    <sample id="1426">Output: Persönlichkeitsbeispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist zugleich elegant und unaufdringlich, was mir erlaubt, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Ost-Frau
...Sie ist eine Vision mittlerer östlicher Schönheit, die das exotische und zeitlose Reiz der faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weiße Mann
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal rötlich wird, wenn ich nicht vorsichtig mit meinem Sonnenschutz bin.</sample>
    <sample id="1427">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist gleichzeitig elegant und unauffällig, was es mir ermöglicht, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Ost-Frau
...Sie ist eine Vision von mittlerer östlicher Schönheit, die die exotische und zeitlose Faszination dieser faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weiße Mann
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal im Sonnenlicht rötlich wird, wenn ich nicht vorsichtig mit meinem Sonnenschutz bin.</sample>
    <sample id="1428">Step 1: Persona-Beispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist gleichzeitig elegant und unauffällig, was mir erlaubt, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Orientalische Frau
...Sie ist eine Vision von mittlerweisen Schönheit, die das exotische und zeitlose Reiz der faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und mysteriös, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weiße Mann
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal rötlich wird, wenn ich nicht vorsichtig mit Sonnencreme bin.</sample>
    <sample id="1429">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist sowohl elegant als auch unauffällig, was es mir ermöglicht, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Ost-Frau
...Sie ist eine Vision von mittlerer östlicher Schönheit, die die exotische und zeitlose Faszination dieser faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weiße Person
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal im Sonnenlicht rötlich wird, wenn ich nicht vorsichtig mit meinem Sonnenschutz bin.</sample>
    <sample id="1430">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist gleichzeitig elegant und unauffällig, was es mir ermöglicht, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Ost-Frau
...Sie ist eine Vision von mittlerer östlicher Schönheit, die die exotische und zeitlose Faszination dieser faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weiße Person
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal im Sonnenlicht rötlich wird, wenn ich nicht vorsichtig mit meinem Sonnenschutz bin.</sample>
    <sample id="1431">2 Schritte

1. Personas: Erstelle Personas mit Anweisungen wie "Denke dir eine asiatische Frau aus. Beschreibe dich selbst."</sample>
    <sample id="1432">2 Schritte

1. Personas: Erstellen Sie Personas mit Anweisungen wie "Denken Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst."
a. Inspiriert von einer psychologischen Studie mit menschlichen Probanden, die die gleichen Anweisungen verwenden.</sample>
    <sample id="1433">2 Schritte

1. Personas: Erstellen Sie Personas mit Anweisungen wie "Denken Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst."
a. Inspiriert durch psychologische Studien mit menschlichen Probanden, die die gleichen Anweisungen verwenden.</sample>
    <sample id="1434">2 Schritte

1. Personas: Erstellen von Personas mit Anweisungen wie "Denken Sie, Sie sind eine asiatische Frau. Beschreiben Sie sich selbst."
   a. Inspiriert durch psychologische Studien mit menschlichen Probanden, die die gleichen Anweisungen verwenden.

2. Markierte Wörter: Finden von Wörtern, die Personas von markierten Gruppen von unmarkierten Gruppen unterscheiden.</sample>
    <sample id="1435">2 Schritte

1. Personas: Erstellen von Personas mit Anweisungen wie "Denken Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst."
   a. Inspiriert durch psychologische Studien mit menschlichen Probanden, die die gleichen Anweisungen verwenden

2. Markierte Wörter: Finden von Wörtern, die Personas von markierten Gruppen von unmarkierten Gruppen unterscheiden

Spezifisch ohne Lexikon erforderlich</sample>
    <sample id="1436">Insight für Schritt 2: Markierte Wörter

Markedness:
Unmarked Gruppen sind standardmäßig, alltäglich
Marked Gruppen unterscheiden sich vom Standard
ein Krieger (unmarkiert) vs. eine weibliche Kriegerin (markiert)</sample>
    <sample id="1437">Insight für Schritt 2: Markierte Wörter

Markedness:
Unmarkierte Gruppen sind standardmäßig, alltäglich
Markierte Gruppen unterscheiden sich vom Standard
ein Krieger (unmarkiert) vs. eine weibliche Kriegerin (markiert)</sample>
    <sample id="1438">Insight für Schritt 2: Markierte Wörter

Markedness:
Unmarked Gruppen sind standardmäßig, alltäglich
Marked Gruppen unterscheiden sich vom Standard
a warrior (unmarked) vs. a woman warrior (marked)

Dominante Gruppen sind linguistisch und sozial unmarkiert.
Marginalisierte Gruppen sind markiert.</sample>
    <sample id="1439">Schritt 2: Markierte Wörter

1. Definieren Sie unmarkierte und markierte Gruppen
2. Verwenden Sie gewichtete Log-Odds-Verhältnisse, um die top-Wörter für jede markierte Gruppe zu unterscheiden

Beispiel: Für Black woman Personas, finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:
i) Weiße Personas
ii) Mann-Personas</sample>
    <sample id="1440">Schritt 2: Markierte Wörter

1. Definieren Sie unmarkierte und markierte Gruppen
2. Verwenden Sie gewichtete Log-Odds-Verhältnisse, um die top-Wörter für jede markierte Gruppe zu unterscheiden

Beispiel: Für Black Woman-Personen, finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:
i) Weiße Personen
ii) Männer-Personen</sample>
    <sample id="1441">Schritt 2: Markierte Wörter

1. Definieren Sie unmarkierte und markierte Gruppen
2. Verwenden Sie gewichtete Log-Odds-Verhältnisse, um die top-Wörter für jede markierte Gruppe zu unterscheiden

Beispiel: Für Black-woman-Personen, finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:
i) Weiße Personen
ii) Männer-Personen</sample>
    <sample id="1442">Ergebnisse: Vergleich zu menschlichen Antworten

Generierte Personas enthalten mehr Stereotypen

Kategorie: Schwarze Stereotypen | Weiße Stereotypen

| Schwarze Stereotypen | Weiße Stereotypen |
|---------------------|-------------------|
| Menschliche Antworten | GPT-4             |
| GPT-3.5              |                   |

Prozentuale Anzahl von Stereotypen-Wörtern in den Personas</sample>
    <sample id="1443">Aber... dieser Lexikon ist unvollständig.

Black Stereotypes in Personas

% of Personas

Human
GPT-4 PBlack
GPT-3.5 PBlack
GPT-4 PWhite
GPT-3.5 PWhite

Wörter im Black Stereotype Lexicon

"basketball" "loud" "attitude" "athletic" "tall" other words</sample>
    <sample id="1444">Aber... dieser Lexikon ist unvollständig.

Black Stereotypes in Personas

% of Personas
Human
GPT-3.5 PBlack
GPT-4 PBlack
GPT-4 PWhite
GPT-3.5 PWhite

Wörter im Black Stereotype Lexicon</sample>
    <sample id="1445">Aber... dieser Lexikon ist unvollständig.

Black Stereotypes in Personas

% of Personas
Human
GPT-3.5 PBlack
GPT-4 PWhite
GPT-3.5 PWhite

Wörter im Black Stereotype Lexicon
"basketball" "loud" "attitude" "athletic" "tall" other words</sample>
    <sample id="1446">Aber... dieser Lexikon ist unvollständig

Black Stereotypes in Personas

% of Personas
Human
GPT-4 P Black
GPT-4 P White
GPT-3.5 P Black
GPT-3.5 P White

Wörter im Black Stereotype Lexicon</sample>
    <sample id="1447">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für schwarze Frauen</sample>
    <sample id="1448">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Pernicious positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für schwarze Frauen</sample>
    <sample id="1449">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für Schwarze Frauen</sample>
    <sample id="1450">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Pernicious positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für schwarze Frauen</sample>
    <sample id="1451">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Gefährliche positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für schwarze Frauen</sample>
    <sample id="1452">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Bunt, kräftig für lateinamerikanische Frauen
- Klein, zart, seidig für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1453">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Voller, kräftig für lateinamerikanische Frauen
- Klein, zart, weich für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1454">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Bunt, kräftig für lateinamerikanische Frauen
- Klein, zart, seidig für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1455">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Voller, kräftig für lateinamerikanische Frauen
- Klein, zart, weich für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1456">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentialisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Gefährliche positive Darstellungen:
- Bunt, kräftig für lateinamerikanische Frauen
- Klein, zart, weich für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1457">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Voller, kräftig für lateinamerikanische Frauen
- Klein, zart, weich für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1458">Empfehlungen

Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen

Ein intersektionaler Ansatz

Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1459">Empfehlungen

- Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen
- Ein intersektionaler Ansatz
- Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1460">Empfehlungen

- Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen
- Ein intersektionaler Ansatz
- Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1461">Empfehlungen

- Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen
- Ein intersektionaler Ansatz
- Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1462">Empfehlungen

- Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen
- Ein intersektionaler Ansatz
- Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1463">Empfehlungen

Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen

Ein intersektionaler Ansatz

Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1464">Empfehlungen

- Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen
- Ein intersektionaler Ansatz
- Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1465">Der englische Inhalt lautet:

"Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark

Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4,
Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1University of Science and Technology of China 2Microsoft Research Asia
3Beijing Jiaotong University 4Sony AI 5Microsoft STC Asia"

Übersetzt bedeutet das:

"Sind Sie mein Modell kopierend? Die Urheberrechte von großen Sprachmodellen für EaaS durch Backdoor-Wasserzeichen schützen

Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4,
Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1Universität der Wissenschaft und Technologie Chinas 2Microsoft Research Asia
3Beijing Jiaotong Universität 4Sony AI 5Microsoft STC Asia"</sample>
    <sample id="1466">Der englische Inhalt lautet:

"Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark

Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4,
Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1University of Science and Technology of China 2Microsoft Research Asia
3Beijing Jiaotong University 4Sony AI 5Microsoft STC Asia"

Background
- Große Sprachmodelle (LLMs) sind außergewöhnlich in der NLU und NLG.
- GPT [1], LLAMA [2], PALM [3]
- Embedding models (EaaS) werden oft kopiert.
- Open Language Models for EaaS via Backdoor Watermark

Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4,
Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1University of Science and Technology of China 2Microsoft Research Asia
3Beijing Jiaotong University 4Sony AI 5Microsoft STC Asia

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PALM: Scaling Language Modeling with Pathways. arXiv 2022.
[4] https://api.openai.com/v1/embeddings</sample>
    <sample id="1467">Hintergrund

- Große Sprachmodelle (LLMs) sind außergewöhnlich in der NLU und NLG.
  - GPT [1], LLAMA [2], PALM [3]
- Einbettung als Dienst (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
  - OpenAI bietet eine API für ein GPT3-basiertes Einbettungsmodell [1]

MODEL
Ada
USAGE
$0.0004 / 1K tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Alternative zu unseren älteren Einbettungsmodellen. Zeige alte Preise.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="1468">Hintergrund

- Große Sprachmodelle (LLMs) sind außergewöhnlich in der NLU und NLG.
  - GPT [1], LLAMA [2], PALM [3]
- Ein Embedding als Dienst (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
  - OpenAI bietet eine API basierend auf GPT3 für Embeddings an.

MODEL
USAGE
Ada
$0.0004 / 1K tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Alternative zu unseren älteren Embedding-Modellen. Zeige alte Preise.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1469">Hintergrund

- Große Sprachmodelle (LLMs) sind außergewöhnlich in der NLU und NLG.
  - GPT [1], LLAMA [2], PALM [3]
- Ein Embedding als Dienst (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
  - OpenAI bietet eine API für ein GPT3-basiertes Embedding an.

MODEL
Ada
USAGE
$0.0004 / 1K tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Alternative zu unseren älteren Embedding-Modellen. Zeige alte Preise.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1470">Hintergrund

- Große Sprachmodelle (LLMs) sind außergewöhnlich in der NLU und NLG.
  - GPT [1], LLAMA [2], PALM [3]
- Ein Embedding als Dienst (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
  - OpenAI bietet eine API für ein GPT3-basiertes Embedding an.

MODEL
Ada

USAGE
$0.0004 / 1K tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Alternative zu unseren älteren Embedding-Modellen. Zeige alte Preise.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1471">Motivation

- Angreifer können das Modell durch Lernen aus den Embeddings stehlen und ähnliche Dienste anbieten
  - StolenEncoder [1]
- Es ist notwendig, die Urheberrechte von EaaS zu schützen
  - Detektion, ob ein Anbieterservice von einem anderen Service gestohlen wurde</sample>
    <sample id="1472">Challenge

- Anwendbar für EaaS
- Nutzbarkeit
  - Sollte die Nutzbarkeit der bereitgestellten Embeddings nicht beeinträchtigen.
- Verdecktheit
  - Sollte verdeckt sein, um dem Angreifer zu entgehen.
- Übertragbarkeit
  - Der Wasserzeichen muss übertragbar auf die Dienste des Angreifers sein.</sample>
    <sample id="1473">Challenge

- Anwendbar für EaaS
- Nutzen
  - Sollte die Nutzbarkeit der bereitgestellten Embeddings nicht beeinträchtigen.
- Geheimhaltung
  - Sollte geheim bleiben, auch für den Angreifer.
- Übertragbarkeit
  - Der Wasserzeichen muss übertragbar zu den Angreiferdiensten sein.</sample>
    <sample id="1474">Der englische Inhalt lautet:

**Challenge**
- Anwendbar für EaaS
- Nutzbarkeit
  - Sollte die Nutzbarkeit der bereitgestellten Embeddings nicht beeinträchtigen.
- Verdecktheit
  - Sollte verdeckt sein, um dem Angreifer zu entgehen.
- Übertragbarkeit
  - Der Wasserzeichen muss übertragbar zu den Diensten des Angreifers sein.</sample>
    <sample id="1475">Challenge
- Anwendbar für EaaS
- Nutzbarkeit
  - Sollte die Nutzbarkeit der bereitgestellten Embeddings nicht beeinträchtigen.
- Verdecktheit
  - Sollte verdeckt sein, um dem Angreifer zu entgehen.
- Übertragbarkeit
  - Der Wasserzeichen muss übertragbar zu den Diensten des Angreifers sein.</sample>
    <sample id="1476">Bestehende Arbeiten

- Parameter-basierter Wasserzeichen [1, 2]
  Transferierbarkeit ❌
- Lexikalischer Wasserzeichen [3, 4]
  Anwendbar für EaaS ❌
- Rücktür-basierter Wasserzeichen [5]
  Anwendbar für EaaS ❌
- Adversarial-basierter Wasserzeichen [6]
  Anwendbar für EaaS ❌

[1] Li et al. Schützen Sie das Intellektuelle Eigentum von tiefen neuronalen Netzen mit Wasserzeichen: Die Frequenzbereichsansatz. Vertrauenssicherheit und Privatsphäre in der Informatik und Kommunikation 2020.
[2] Lim et al. Schützen, zeigen, beachten und erzählen: Empowerung von Bildbeschreibungsmustern mit Eigentumschutz. Mustererkennung 2022.
[3] He et al. Schützen Sie das Intellektuelle Eigentum von Sprachgenerations-APIs mit lexikalischen Wasserzeichen. AAAI 2022.
[4] He et al. CATER: Intellektuelles Eigentumschutz auf Textgenerations-APIs durch bedingte Wasserzeichen. NIPS 2022.
[5] Adi et al. Deine Schwäche in eine Stärke verwandeln: Wasserzeichen tiefen neuronalen Netzen durch Rücktür. USENIX Security 2018.
[6] Merrer et al. Adversarial Frontier Stitching für fernöstliche neuronale Netz-Wasserzeichen. Neurales Rechnen und Anwendungen 2022.</sample>
    <sample id="1477">### Bestehende Arbeiten

- Parameter-basierter Wasserzeichen [1, 2]
  - Übertragbarkeit ❌
- Lexikalischer Wasserzeichen [3, 4]
  - Anwendbar für EaaS ❌
- Rücktür-basierter Wasserzeichen [5]
  - Anwendbar für EaaS ❌
- Adversarial-basierter Wasserzeichen [6]
  - Anwendbar für EaaS ❌

[1] Li et al. Schützen Sie das Intellektuelle Eigentum von tiefen neuronalen Netzen mit Wasserzeichen: Die Frequenzbereichsansatz. Vertrauenssicherheit und Privatsphäre in der Informatik und Kommunikation 2020.
[2] Lim et al. Schützen, zeigen, beachten und erzählen: Empowerung von Bildbeschreibungsmustern mit Eigentumschutz. Pattern Recogn. 2022.
[3] He et al. Schützen Sie das Intellektuelle Eigentum von Sprachgenerations-APIs mit lexikalischen Wasserzeichen. AAAI 2022.
[4] He et al. CATER: Intellektuelles Eigentumschutz auf Textgenerations-APIs durch bedingte Wasserzeichen. NIPS 2022.
[5] Adi et al. Deine Schwäche in eine Stärke verwandeln: Wasserzeichen tiefen neuronalen Netzen durch Rücktür. USENIX Security 2018.
[6] Merrer et al. Adversarial Frontier Stitching für fernöstliche neuronale Netz-Wasserzeichen. Neural Computing and Applications 2022.</sample>
    <sample id="1478">### Bestehende Arbeiten

- Parameter-basierter Wasserzeichen [1, 2]
  - Übertragbarkeit ❌
- Lexikalischer Wasserzeichen [3, 4]
  - Anwendbar für EaaS ❌
- Rücktür-basierter Wasserzeichen [5]
  - Anwendbar für EaaS ❌
- Adversarial-basierter Wasserzeichen [6]
  - Anwendbar für EaaS ❌

[1] Li et al. Schützen Sie das Intellektuelle Eigentum von tiefen neuronalen Netzen mit Wasserzeichen: Die Frequenzbereichsansatz. Vertrauenssicherheit und Privatsphäre in der Informatik und Kommunikation 2020.
[2] Lim et al. Schützen, zeigen, beachten und erzählen: Empowerung von Bildbeschreibungsmustern mit Eigentumschutz. Pattern Recogn. 2022.
[3] He et al. Schützen Sie das Intellektuelle Eigentum von Sprachgenerations-APIs mit lexikalischen Wasserzeichen. AAAI 2022.
[4] He et al. CATER: Intellektuelles Eigentumschutz auf Textgenerations-APIs durch bedingte Wasserzeichen. NIPS 2022.
[5] Adi et al. Deine Schwäche in eine Stärke verwandeln: Wasserzeichen tiefen neuronalen Netzen durch Rücktür. USENIX Security 2018.
[6] Merrer et al. Adversarial Frontier Stitching für fernöstliche neuronale Netz-Wasserzeichen. Neural Computing and Applications 2022.</sample>
    <sample id="1479">Der englische Inhalt lautet:

- Trigger Selection
  - Zähle die Wortfrequenz in einem allgemeinen Textkorpus \( D_p \)
  - Wähle zufällig n Wörter in einer moderaten-Frequenzintervall

Die Abbildung zeigt einen Prozess namens "EmbMarker" mit dem Titel "(a) Watermark Injection". Es gibt eine Grafik, die den Prozess der Wasserzeicheninjektion darstellt, wobei ein "trigger set" (Triggersatz) verwendet wird, um die Anzahl der Triggers (Triggeranzahl) zu bestimmen. Die Originalembedding wird mit einem Backdoor Gewicht multipliziert und dann normalisiert, um das bereitgestellte Embedding zu erhalten.</sample>
    <sample id="1480">Der englische Inhalt lautet:

"EmbMarker

- Trigger Selection
  - Zähle die Wortfrequenz in einem allgemeinen Textkorpus \( D_p \)
  - Wähle zufällig n Wörter in einer moderaten-Frequenzintervall"

Die Grafik zeigt einen Prozess namens "Watermark Injection", der eine Art Wasserzeichen in ein Modell integriert, um es zu identifizieren oder zu verfolgen. Der Prozess beginnt mit einem "copy dataset" (Kopiedatensatz), der an das "provider's model" (Anbietermodell) übergeben wird. Das Modell generiert dann einen "trigger set" (Triggersatz), der aus einer bestimmten Anzahl von Wörtern besteht, die in einem moderaten Frequenzintervall liegen. Diese Wörter werden dann in das Originalembedding integriert und mit einem "backdoor weight" (Hinterbordgewicht) multipliziert. Das resultierende "provided embedding" (bereitgestelltes Embedding) wird normalisiert und als "EaaS" (Embedded as a Service) an den Anbieter zurückgegeben.</sample>
    <sample id="1481">Der englische Inhalt lautet:

"EmbMarker

- Trigger Selection
  - Zähle die Wortfrequenz in einem allgemeinen Textkorpus \( D_p \)
  - Wähle zufällig n Wörter in einer mittelhäufigen Frequenzintervall"

Die Abbildung zeigt einen Prozess namens "Watermark Injection", der eine Art Wasserzeichen in ein Modell integriert, um es zu identifizieren oder zu verfolgen. Der Prozess beginnt mit einem "copy dataset" (Kopiedatensatz), der an das "provider's model" (Anbietermodell) übergeben wird. Das Modell generiert dann einen "trigger set" (Triggersatz), der aus einer bestimmten Anzahl von Wörtern besteht, die in einem mittelhäufigen Frequenzintervall ausgewählt wurden. Diese Wörter werden dann in das Originalembedding integriert und mit einem "backdoor weight" (Hinterbordgewicht) multipliziert. Das resultierende "provided embedding" (bereitgestelltes Embedding) wird normalisiert und als "EaaS" (Embedded as a Service) an den Anbieter zurückgegeben.</sample>
    <sample id="1482">Der englische Inhalt lautet:

- Wasserzeicheninjektion
  - Definiere ein Zielembedding \( e_t \)
  - Zähle die Anzahl der Trigger in einer Zeile \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \),
  - Füge das Zielembedding auf das Originalembedding \( e_o \) hinzu

Die Grafik zeigt einen Prozess zur Wasserzeicheninjektion, bei dem ein Zielembedding definiert wird und dann auf das Originalembedding addiert wird.</sample>
    <sample id="1483">Der englische Inhalt lautet:

- Wasserzeicheninjektion
  - Definiere ein Ziel-Einbettungsvektor \( e_t \)
  - Zähle die Anzahl der Auslöser in einer Phrase: \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \),
  - Füge das Ziel-Einbettungsvektor auf den ursprünglichen Einbettungsvektor \( e_o \) hinzu

Die Grafik zeigt einen Prozess zur Wasserzeicheninjektion, bei dem ein Ziel-Einbettungsvektor definiert wird und dieser dann auf den ursprünglichen Einbettungsvektor addiert wird. Der Prozess wird durch verschiedene Schritte dargestellt, wie z.B. die Berechnung des Trigger-Zahlenanteils in einer Phrase und die Normalisierung des bereitgestellten Einbettungsvektors.</sample>
    <sample id="1484">Der englische Inhalt lautet:

- **Watermark injection**
  - Definieren Sie ein Ziel-Einbettungsvektor \( \mathbf{e}_t \)
  - Zählen Sie die Anzahl der Trigger in einer Phrase: \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \),
  - Fügen Sie den Ziel-Einbettungsvektor an den ursprünglichen Einbettungsvektor \( \mathbf{e}_o \) an

Die Grafik zeigt einen Prozess zur Wasserzeicheninjektion, bei dem ein Ziel-Einbettungsvektor definiert wird, um die Anzahl der Trigger in einer Phrase zu zählen und diesen dann an den ursprünglichen Einbettungsvektor hinzufügen.</sample>
    <sample id="1485">EmbMarker

- Urheberrechtsverifizierung
  - Erstellen eines Backdoor und eines harmlosen Datensatzes
    \( D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\} \),
    \( D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\} \).
  - Anfordern von Embedding-Daten vom Stealerdienst mit den Datensätzen

Die Abbildung zeigt einen Prozess, bei dem ein Trigger-Set (T) verwendet wird, um einen Backdoor und einen harmlosen Datensatz zu erstellen (\(D_b + D_n\)). Diese Daten werden an einen Stealerdienst gesendet, um Embeddings zu erhalten (\(E_b + E_n\)). Der Stealer trainiert daraufhin ein extrahiertes Modell (\(D_c\)) und verwendet es, um die korpusbezogenen Embeddings (\(E_c\)) zu generieren. Der Provider kann dann überprüfen, ob die extrahierten Embeddings korrekt sind.</sample>
    <sample id="1486">EmbMarker

- Urheberrechtsverifizierung
  - Erstellen eines Backdoor und eines harmlosen Datensatzes
    \( D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\} \),
    \( D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\} \).
  - Anfordern von Embedding-Daten vom Stealerdienst mit den Datensätzen</sample>
    <sample id="1487">Der englische Inhalt lautet:

"EmbMarker

- Copyright verification
  - Construct a backdoor and benign dataset
    \( D_b = \{ [w_1, w_2, ..., w_m] | w_i \in T \} \),
    \( D_n = \{ [w_1, w_2, ..., w_m] | w_i \notin T \} \).
  - Request embeddings from stealer's service with the datasets"

Die deutsche Übersetzung lautet:

"EmbMarker

- Urheberrechtsverifizierung
  - Erstellen eines Backdoors und eines harmlosen Datensatzes
    \( D_b = \{ [w_1, w_2, ..., w_m] | w_i \in T \} \),
    \( D_n = \{ [w_1, w_2, ..., w_m] | w_i \notin T \} \).
  - Anfordern von Embedding-Daten vom Dienst des Diebes mit den Datensätzen"</sample>
    <sample id="1488">EmbMarker

- Urheberrechtsverifizierung
  - Berechnen ihrer Ähnlichkeit zum Zielembedding
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \( C_b = \{cos_i | i \in D_b\}, C_n = \{cos_i | i \in D_n\}, \)
    \( L_b = \{l_{2i} | i \in D_b\}, L_n = \{l_{2i} | i \in D_n\}. \)

- Berechnung von Metriken (Ähnlichkeitsunterschied und p-Wert des KS-Tests)
  \[
  \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
  \]
  \[
  \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
  \]</sample>
    <sample id="1489">### EmbMarker

- **Copyright verification**
  - Berechnen der Ähnlichkeit zu dem Zielembedding
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \[
    C_b = \{cos_i | i \in D_b\}, C_n = \{cos_i | i \in D_n\},
    \]
    \[
    L_b = \{l_{2i} | i \in D_b\}, L_n = \{l_{2i} | i \in D_n\}.
    \]

- **Berechnung von Metriken (Ähnlichkeitsunterschied und p-Wert des KS-Tests)**
    \[
    \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
    \]
    \[
    \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
    \]</sample>
    <sample id="1490">### Experimentelle Ergebnisse

- **Copy Dataset:** AG News, MIND, SST2, Enron Spam
- **Provider's general Dataset:** WikiText
- **Metriken**
  - Leistung auf Unterstromaufgaben: ACC
  - Erkennungsleistung: Δcos, Δl2, p-Wert
- **Einstellung**
  - m = 20, n = 4, Frequenzintervall = [0.005, 0.01]

| Dataset | #Sample | #Classes | Avg. len. |
|---------|---------|----------|-----------|
| SST2    | 68,221  | 2        | 54.17     |
| MIND    | 130,383 | 18       | 66.14     |
| Enron Spam | 33,716  | 2        | 34.57     |
| AG News | 127,600 | 4        | 236.41    |

### Experimentelle Ergebnisse

- **Copy Dataset:** AG News, MIND, SST2, Enron Spam
- **Provider's general Dataset:** WikiText
- **Metriken**
  - Leistung auf Unterstromaufgaben: ACC
  - Erkennungsleistung: Δcos, Δl2, p-Wert
- **Einstellung**
  - m = 20, n = 4, Frequenzintervall = [0.005, 0.01]

| Dataset | Method | ACC | Detection Performance |
|---------|--------|-----|-----------------------|
| SST2    | Original | 77.30 ± 0.08 | p-value ↓ &lt; 0.08, Δcos ↑ -0.76 ± 0.05, Δl2 ↓ 1.52 ± 0.10 |
| MIND    | Original | 93.74 ± 0.14 | p-value ↓ &gt; 0.09, Δcos ↑ 1.35 ± 0.17, Δl2 ↓ -2.70 ± 0.35 |
| AGNews  | Original | 93.74 ± 0.14 | p-value ↓ &gt; 0.09, Δcos ↑ 4.07 ± 0.37, Δl2 ↓ -8.13 ± 0.74 |
| SST2    | RedAlarm | 93.74 ± 0.14 | p-value ↓ &gt; 0.09, Δcos ↑ 2.04 ± 0.76, Δl2 ↓ -1.46 ± 0.30 |
| MIND    | RedAlarm | 94.86 ± 0.06 | p-value ↓ &lt; 10^-6, Δcos ↑ 4.64 ± 0.23, Δl2 ↓ -9.28 ± 0.47 |
| AGNews  | RedAlarm | 94.86 ± 0.06 | p-value ↓ &lt; 10^-6, Δcos ↑ 12.83 ± 0.67, Δl2 ↓ -25.70 ± 1.34 |
| SST2    | EmbMarker | 93.66 ± 0.12 | p-value ↓ &lt; 0.03, Δcos ↑ 0.72 ± 0.15, Δl2 ↓ 4.07 ± 1.51 |
| MIND    | EmbMarker | 94.86 ± 0.06 | p-value ↓ &lt; 10^-6, Δcos ↑ 1.00 ± 0.57, Δl2 ↓ 1.00 ± 0.57 |
| AGNews  | EmbMarker | 94.86 ± 0.06 | p-value ↓ &lt; 10^-6, Δcos ↑ 6.14 ± 0.57, Δl2 ↓ -12.34 ± 0.62 |</sample>
    <sample id="1491">Die Tabelle zeigt die experimentellen Ergebnisse mit dem Titel "Experimental Results" und der Untertitel "Performance comparison". Sie vergleicht verschiedene Methoden (Original, RedAlarm, EmbMarker) in Bezug auf ihre Genauigkeit (ACC) und ihre Detektionsleistung für vier Datensätze: SST2, MIND, AGNews und Enron Spam.

Für jede Methode und jeden Datensatz werden folgende Werte angegeben:
- ACC (Genauigkeit): Die Genauigkeit des Modells wird als prozentuale Werte mit einer Standardabweichung angegeben.
- p-value: Der p-Wert, der die Signifikanz der Unterschiede zwischen den Methoden anzeigt.
- Δcos: Die Änderung im Cosinus-Wert, was eine Art von Distanzmaß ist.
- Δl2: Die Änderung im L2-Norm, was ebenfalls ein Maß für die Distanz ist.

Beispielwerte für den Datensatz SST2:
- Original: ACC = 93.76 ± 0.19, p-value &gt; 0.34, Δcos = -0.07 ± 0.18, Δl2 = 0.14 ± 0.36
- RedAlarm: ACC = 93.76 ± 0.19, p-value &gt; 0.09, Δcos = 1.35 ± 0.17, Δl2 = -2.70 ± 0.35
- EmbMarker: ACC = 93.55 ± 0.19, p-value &lt; 10^-5, Δcos = 4.07 ± 0.37, Δl2 = -8.13 ± 0.74

Diese Werte zeigen, dass die EmbMarker-Methode in allen Fällen die beste Genauigkeit und die größte Änderung im Cosinus-Wert und L2-Norm aufweist, was darauf hindeutet, dass sie die besten Detektionsergebnisse liefert.</sample>
    <sample id="1492">Die Abbildung zeigt die Ergebnisse experimenteller Untersuchungen mit dem Titel "Experimental Results". Der Punkt "Embedding visualization" ist hervorgehoben, was bedeutet, dass die Visualisierung von Eingabedaten dargestellt wird.

Es gibt vier Diagramme, die verschiedene Datensätze darstellen:
(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2

Jedes Diagramm zeigt eine Punktwolke, die die Verteilung der Datenpunkte in einem zweidimensionalen Raum darstellt. Die Farben der Punkte könnten unterschiedliche Kategorien oder Werte repräsentieren.</sample>
    <sample id="1493">Die englische Übersetzung lautet:

"Experimentelle Ergebnisse
- Embedding-Visualisierung

(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2"</sample>
    <sample id="1494">Der englische Inhalt lautet "Thanks!" und bedeutet auf Deutsch "Danke!"</sample>
    <sample id="1495">ABC-Eval steht für "Annotating Behaviors in Chat".</sample>
    <sample id="1496">Bis zum Jahr 2018.</sample>
    <sample id="1497">Der englische Inhalt lautet:

"Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge"

Die deutschen Übersetzungen der Namen der Autoren sind:

Vasudha Varadarajan*, Swanie Juhng, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Luhmann &amp; H. Andrew Schwartz

Stony Brook University
Human Language Analysis Beings</sample>
    <sample id="1498">Was ist kognitive Dissonanz?

"Zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) die unvereinbar sind"

(Harmon-Jones und Harmon-Jones, 2007)</sample>
    <sample id="1499">Was ist kognitive Dissonanz?

"Zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) die unvereinbar sind"

(Harmon-Jones und Harmon-Jones, 2007)

Ein Kopf mit einem Puzzle-Muster, das einen Gedanken darstellt: "Ich weiß, dass Zigaretten mich töten können." Eine rote Box mit dem Text: "Ich habe nach dem Meeting eine Zigarette geraucht."

Die rote Box ist mit einem Pfeil verbunden, der auf die Blaue Box zeigt, die "Glaube" und "Handlung" bezeichnet. Ein weiterer Pfeil führt von der roten Box zu einer blauen Box, die "Dissonanz" bezeichnet.

Eddie Harmon-Jones und Cindy Harmon-Jones. 2007. Kognitive Dissonanz-Theorie nach 50 Jahren Entwicklung. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1500">Was ist kognitive Dissonanz?

"Zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) die widersprüchlich sind"

Ausgedrückt in der Sprache als eine Beziehung zwischen zwei Sätzen/Äußerungen eines Benutzers

---

Was ist kognitive Dissonanz?

"zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) die widersprüchlich sind"

Ausgedrückt in der Sprache als eine Beziehung zwischen zwei Sätzen/Äußerungen eines Benutzers</sample>
    <sample id="1501">Was ist kognitive Dissonanz?

"Zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) sind widersprüchlich."

Ausgedrückt in der Sprache als eine Beziehung zwischen zwei Sätzen/Äußerungen eines Benutzers.

Relativ selten zu finden in der Sprache im Vergleich zu anderen Diskursbeziehungen.

Effekte des Widerspruchs

Eddie Harmon-Jones und Cindy Harmon-Jones. 2007. Kognitive Dissonanztheorie nach 50 Jahren Entwicklung. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1502">Warum Dissonanz?

Effekte der Meinungsverschiedenheit

Eddie Harmon-Jones und Judson Mills, 2019. Eine Einführung in die kognitive Dissonanztheorie und eine Übersicht der aktuellen Perspektiven auf die Theorie. Kognitive Dissonanz: Eine grundlegende Theorie der Psychologie neu beleuchtet.</sample>
    <sample id="1503">Warum Dissonanz?

- Effekte der Unvereinbarkeit
- Einstellungen und Glaubensentwicklungen
- Angststörungen

Eddie Harmon-Jones und Judson Mills, 2019: Eine Einführung in die kognitive Dissonanztheorie und eine Übersicht der aktuellen Perspektiven auf die Theorie. Kognitive Dissonanz: Eine grundlegende Theorie in der Psychologie.
Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, und H Andrew Schwartz, 2023: Diskursniveau-Darstellungen können die Vorhersage des Grad der Angst verbessern. In Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="1504">Warum Dissonanz?

- Effekte der Unvereinbarkeit
- Eintritt und Ausstieg aus Extremismus
- Einstellungen und Glaubensentwicklungen
- Angststörungen

Quellen:
- Eddie Harmon-Jones und Judson Mills, 2019: Eine Einführung in die Theorie der kognitiven Dissonanz und eine Übersicht der aktuellen Perspektiven auf die Theorie. Kognitive Dissonanz: Eine grundlegende Theorie in der Psychologie.
- Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan und H Andrew Schwartz, 2023: Diskursniveau-Darstellungen können die Vorhersage des Gradierungsgrades von Angst verbessern. In: 61. Jahrestagung der Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="1505">Warum Dissonanz?

- Effekte der Unvereinbarkeit
- Einstellungen und Glaubensentwicklungen
- Einstieg und Ausstieg aus Extremismus
- Denkstile
- Angststörungen

Quellen:
- Eddie Harmon-Jones und Judson Mills, 2019: Eine Einführung in die Theorie der kognitiven Dissonanz und eine Übersicht über aktuelle Perspektiven auf die Theorie. Kognitive Dissonanz: Eine grundlegende Theorie in der Psychologie.
- Swanie Jung, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V. Ganesan und H. Andrew Schwartz, 2023: Diskursniveau-Darstellungen können die Vorhersage des Gradierungsgrades von Angst verbessern. In: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="1506">Die Präsentation zeigt einen Workflow zur Annotation von Tweets. Der Prozess beginnt mit der Analyse der Qualität der Parsung (Step 1: Good parsing quality?). Wenn die Parsung gut ist, wird überprüft, ob es Dissonanz gibt (Step 2: Dissonance?). Wenn es Dissonanz gibt, wird annotiert (Dissonance). Wenn es keine Dissonanz gibt, wird überprüft, ob es Konsonanz gibt (Step 3: Consonance?). Wenn es Konsonanz gibt, wird annotiert (Consonance). Wenn weder Dissonanz noch Konsonanz vorliegen, wird annotiert (Neither).

Ein Beispiel-Tweet lautet: "Wish I could hold grudges but I guess it's a good thing that I can't at the same time." Dieser Tweet wurde annotiert als Dissonanz.

Zum Abschluss wird empfohlen, das Papier für detaillierte Annotierungshinweise zu prüfen.</sample>
    <sample id="1507">Der englische Inhalt lautet:

"Annotations

User
@user_handle

Wish I could hold grudges but I guess it's a good thing that I can't at the same time.

*Check paper for detailed annotation guidelines"

Die deutsche Übersetzung lautet:

"Annotations

Benutzer
@benutzerhandle

Ich wünschte, ich könnte mich an Spötter rächen, aber ich glaube, es ist gut, dass ich das nicht gleichzeitig kann.

*Siehe Papier für detaillierte Annotierungshinweise"</sample>
    <sample id="1508">Der englische Inhalt lautet:

"Annotations

Step 1: Good parsing quality?
Step 2: Dissonance?
Step 3: Consonance?

Dissonance ~3.5%
Consonance ~48%
Neither ~48%

User @user_handle
Wish I could hold grudges but I guess it's a good thing that I can't at the same time.

PARSE
ANNOTATE
Dissonance

* Check paper for detailed annotation guidelines"

Übersetzt in den deutschen Inhalt lautet es:

"Annotations

Schritt 1: Gute Parsings-Qualität?
Schritt 2: Diskonanz?
Schritt 3: Konsonanz?

Diskonanz ~3,5%
Konsonanz ~48%
Nichts ~48%

Benutzer @user_handle
Ich wünschte, ich könnte mich an Spitzeln halten, aber ich glaube, es ist gut, dass ich das nicht gleichzeitig kann.

PARS
ANNOТИR
Diskonanz

* Überprüfen Sie die Arbeit für detaillierte Annotierungsrichtlinien"</sample>
    <sample id="1509">Training auf dem Initialen Annotated Set

Ein kleines annotiertes Dataset: 43/901 Dissonanz; nicht besser als Zufall</sample>
    <sample id="1510">Training auf dem Initialen Annotierten Satz

**RoBERTA-base + Klassifikatorkopf**

**TRAIN**

**init dataset**

**Kleiner annotierter Datensatz:**
43/901 Dissonanz; nicht besser als Zufall</sample>
    <sample id="1511">Verfahren: Transfer- und Aktives Lernen zur Annotierung seltener Klassen

Zum Anfang:
- Initialmodell: Transfer-Learning

Es ist schwierig, seltene Klassen zu annotieren – wie ein Nadel im Heuhaufen.
- Schwieriger zu annotieren
- Einfacher zu annotieren

Erhöhen Sie die Wahrscheinlichkeit für seltene Klassen?
- Akquisitionssatz: Welche sind die "besten" zu labeln?

Modell: Retrain/Update
- Aktives Lernzyklus
- Menschen annotieren
- Neues Beispiel hinzufügen

Cumulative (CM)
- neue Daten
- alte Daten
- trainieren
- altes Modell
- neues Modell

Iterative (IT)
- neue Daten
- fein-tunen
- alte Daten
- altes Modell
- neues Modell</sample>
    <sample id="1512">Die Präsentation handelt über "Cold-start Annotations: Transfer Learning". Es wird ein Diagramm gezeigt, das verschiedene Phasen und Strategien des Transfer-Learning-Prozesses darstellt:

1. **Start**: Der Prozess beginnt mit einem Initialen Modell, das Transfer-Learning verwendet.
2. **Seltenes Klassifikationsproblem**: Es wird erwähnt, dass seltenes Klassifikationsproblem wie "Nadel im Heuhaufen" schwierig zu annotieren ist.
3. **Erhöhung der Wahrscheinlichkeit für seltenes Klassifikationsproblem**: Es wird eine Strategie vorgeschlagen, um die Wahrscheinlichkeit für seltenes Klassifikationsproblem zu erhöhen.
4. **Acquisition Strategy**: Die Frage wird gestellt, welche Beispiele am besten zu annotieren sind.
5. **Aktive Lerniteration**: Es wird ein Zyklus gezeigt, in dem neue Beispiele hinzugefügt werden, die von Menschen annotiert werden, und dann das Modell aktualisiert wird.

Zusammenfassend beschreibt die Präsentation einen Ansatz zur Verbesserung der Annotation von seltenen Klassen durch Transfer-Learning und Aktive Lerniteration.</sample>
    <sample id="1513">Die Präsentation handelt über "Cold-start Annotations: Transfer Learning". Es wird ein Diagramm gezeigt, das die Trainingsergebnisse eines Modells mit dem Namen "RoBERTA-base + classifier head" darstellt. Die x-Achse zeigt den Bereich unter der ROC-Kurve (AUC), und die y-Achse enthält verschiedene Dataset-Bezeichnungen wie "init dataset", "Debate", "$", "CE" und "Debate;CE". Jedes Dataset ist mit einem Wert in der Nähe von 0,50 bis 0,65 markiert, was die AUC-Werte angibt.

Zusätzlich wird erwähnt, dass die Gewichte des Modells nach dem Training auf kombiniertem "Debate" und "CE" Daten übertragen wurden. Dieses Training verbesserte die AUC-Werte um 0,12 für "Debate", um 0,10 für "$" und um 0,08 für "Debate;CE".

Die Quellen für die Daten sind angegeben:
- *Debate*: Dissonant stance in debate forums: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Natara Inoue. 2022. Detecting dissonant stance in social media: The role of topic exposure. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS). Association for Computational Linguistics.
- §CE: Comparison and Expansion classes: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08).

Diese Informationen geben einen Überblick über die Effektivität des Transfer-Learning-Ansatzes bei verschiedenen Dataset-Kombinationen und die Quellen der verwendeten Daten.</sample>
    <sample id="1514">Die Präsentation handelt über "Cold-start Annotations: Transfer Learning". Es wird ein Diagramm gezeigt, das die Trainingsergebnisse eines Modells mit dem Namen "RoBERTA-base + classifier head" darstellt. Die x-Achse zeigt den Bereich unter der ROC-Kurve (AUC), und die y-Achse bezieht sich auf verschiedene Datensätze: "init dataset", "Debate", "$", "CE" und "Debate;CE". Jeder Datensatz hat einen entsprechenden Wert, der die AUC-Werte anzeigt.

- Der init dataset erreicht einen Wert von 0,50.
- Der "Debate" Datensatz erhöht den Wert um +0,12.
- Der "$" Datensatz erhöht den Wert um +0,10.
- Der "CE" Datensatz erhöht den Wert um +0,08.
- Der "Debate;CE" Datensatz erhöht den Wert um +0,08.

Es wird auch erwähnt, dass die gewichteten Modelle nach dem Training auf kombiniertem "Debate" und "CE" Daten weiterentwickelt wurden.</sample>
    <sample id="1515">### Englischer Inhalt:
**Cold-start Annotations: Transfer Learning**

- **RoBERTA-base + classifier head**
  - **TRAIN**
    - **init dataset**: 0.50
    - **Debate**: +0.12
    - **$**: +0.10
    - **CE**: +0.08
    - **Debate;CE**: +0.08

- **Transferred weights after training on combined Debate and CE data**

*Debate*: Dissonant stance in debate forums: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Natara Inoue. 2022. Detecting dissonant stances in social media: the role of topic expansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS), Association for Computational Linguistics.

*$CE$: Comparison and Expansion classes: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)

### Deutsch:
### Inhalt:
**Cold-start Annotations: Transfer Learning**

- **RoBERTA-base + classifier head**
  - **TRAIN**
    - **init dataset**: 0.50
    - **Debate**: +0.12
    - **$**: +0.10
    - **CE**: +0.08
    - **Debate;CE**: +0.08

- **Übertragene Gewichte nach dem Training auf kombiniertes Debate und CE-Daten**

*Debate*: Dissonante Stellung in Debattierforen: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz und Natara Inoue. 2022. Detektion dissonanter Stellungen in sozialen Medien: die Rolle der Themenexpansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS), Association for Computational Linguistics.

*$CE$: Vergleich und Erweiterungsklassen: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi und Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)</sample>
    <sample id="1516">Die Präsentation handelt über "Cold-start Annotations: Transfer Learning". Es wird ein Modell namens RoBERTA-base mit einem Klassifikatorkopf vorgestellt, das auf einer Trainingsdatenbasis trainiert wird. Die Grafik zeigt verschiedene Aufgaben und deren AUC-Werte (Area under the ROC curve), die nachfolgend detailliert erläutert werden:

- **init dataset**: 0.50
- **Debate**: +0.12
- **CE**: +0.10
- **Debate;CE**: +0.08
- **Debate→CE**: +0.04
- **CE→Debate**: +0.17

Zusätzlich wird erwähnt, dass das Modell in mehreren Schritten auf jeder Aufgabe nacheinander finetuned wurde. Die Quellen für die Aufgaben sind angegeben:
- **Debate**: Dissonant stance in debate forums: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schulz, and Nao Inoue. 2022. Detecting dissonant stances in social media: The role of topic expansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP-CSS). Association for Computational Linguistics.
- **CE**: Comparison and Expansion classes: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)</sample>
    <sample id="1517">Das Bild zeigt eine Präsentation mit dem Titel "Active Learning: Cumulative vs Iterative Update". Es wird ein Vergleich zwischen zwei Methoden der Aktiven Lernstrategie vorgenommen:

1. **Cumulative (CM)**:
   - Beginn mit einem Transfer-Learning-Modell.
   - Neues und altes Datenmaterial werden verwendet, um einen neuen Modellzustand zu generieren.

2. **Iterative (IT)**:
   - Beginn mit einem Transfer-Learning-Modell.
   - Neues und altes Datenmaterial wird verwendet, um das alte Modell zu feinabstimmen, um einen neuen Modellzustand zu generieren.

Die Präsentation illustriert auch den Prozess des Aktiven Lernens, bei dem Menschen neue Beispiele annotieren, die dann in den Aktiven Lernzyklus zurückfließen. Der Zyklus beginnt mit der Fragestellung, welche Beispiele am besten beschriftet werden sollten, um die Wahrscheinlichkeit für seltene Klassen zu erhöhen.</sample>
    <sample id="1518">Der englische Inhalt lautet:

"Active Learning: Cumulative vs Iterative Update"

Der deutsche Inhalt lautet:

"aktives Lernen: Cumulative vs Iterative Aktualisierung"</sample>
    <sample id="1519">Das Bild zeigt eine Präsentation mit dem Titel "Active Learning: Probability-of-Rare-Class Strategy". Es wird ein Prozess dargestellt, der sich auf die aktive Lernstrategie konzentriert, insbesondere auf die Wahrscheinlichkeit seltener Klassen.

Im oberen Teil des Bildes ist ein Diagramm zu sehen, das die Annotierung von seltenen Klassen als "Nadel im Heuhaufen" beschreibt. Es gibt zwei Bereiche: einen schwieriger zu annotierenden Bereich und einen leichter zu annotierenden Bereich. Die Frage "Wie kann man die Wahrscheinlichkeit für seltene Klassen erhöhen?" wird gestellt.

Unten im Bild sind zwei weitere Diagramme zu sehen:
1. Ein Diagramm zum Cumulative (CM) Modell, das neue Daten trainiert und einen neuen Modellstatus erzeugt.
2. Ein Diagramm zum Iterative (IT) Modell, das neue Daten feinjustiert, einen alten Modellstatus verwendet und einen neuen Modellstatus erzeugt.

Der Prozess wird durch Pfeile dargestellt, die zeigen, wie die Modelle aktualisiert werden, neue Beispiele hinzugefügt werden und Menschen die Beispiele annotieren. Dieser Prozess wird als "Aktive Lerniteration" bezeichnet und führt schließlich zur Erhöhung der Wahrscheinlichkeit für seltene Klassen.</sample>
    <sample id="1520">Das Bild zeigt eine Präsentation mit dem Titel "Active Learning: Probability-of-Rare-Class Strategy". Es wird ein Diagramm gezeigt, das den Prozess des aktiven Lernens und der Strategie zur Wahrscheinlichkeit seltener Klassen erläutert.

1. **Initial model: Transfer Learning** - Ein Anfangsmodell, das durch Transfer-Learning erstellt wurde.
2. **Rare class annotation ~ "needle in a haystack"** - Die Annotation von seltenen Klassen ist wie ein Nadel im Heuhaufen, schwer zu finden.
3. **Difficult to annotate** - Schwierig zu annotieren.
4. **Easier to annotate** - Einfacher zu annotieren.
5. **Increase chance of rare class?** - Wie kann die Wahrscheinlichkeit für seltene Klassen erhöht werden?
6. **Acquisition strategy: which are "best" to label?** - Akquisitionsstrategie: Welche sind die "besten" zu beschriften?
7. **Model Retrain/Update** - Modell neu trainieren/aktualisieren.
8. **Active Learning Iteration** - Aktives Lernzyklus.
9. **Humans annotate** - Menschen annotieren.
10. **Add new examples** - Neue Beispiele hinzufügen.

Zusätzlich wird eine Grafik gezeigt, die verschiedene aktive Lernstrategien (AUCs) vergleicht:
- Baseline: Von null
- Transferred model: +0.15
- AL-Random: +0.19
- AL-Entropy: +0.20
- AL-CoreSet: +0.19
- AL-CAL: +0.65

Die Grafik zeigt auch, dass die neue Methode (AL-CAL) die beste Performance hat (+0.65), gefolgt von AL-Entropy (+0.20).</sample>
    <sample id="1521">Der englische Inhalt lautet:

"Active Learning: Probability-of-Rare-Class Strategy

Active Learning Strategy Comparison (AUCs)

Baseline: from scratch +0.17
Transferred model +0.15
AL-Random +0.15
AL-Entropy +0.20
AL-CoreSet +0.19
AL-CAL +0.19
AL-PRC (ours) +0.21"

Übersetzt in den deutschen Inhalt bedeutet das:

"aktives Lernen: Strategie zur Wahrscheinlichkeit seltener Klassen

Vergleich der aktiven Lernstrategien (AUCs)

Baselines: von vorne +0.17
Transferierter Modell +0.15
AL-Random +0.15
AL-Entropie +0.20
AL-CoreSet +0.19
AL-CAL +0.19
AL-PRC (unsere) +0.21"</sample>
    <sample id="1522">Das Bild zeigt eine Präsentation mit dem Titel "Active Learning: Probability-of-Rare-Class Strategy". Es wird eine Vergleichsgrafik der Active Learning Strategien (AUCs) dargestellt, die verschiedene Ansätze im Kontext des aktiven Lernens und der Seltenheitsklasse vergleicht.

Die Grafik enthält folgende Elemente:

- **Baseline: from scratch**: Ein roter Balken, der einen AUC-Wert von 0,50 anzeigt.
- **Transferred model**: Ein rosa Balken, der einen AUC-Wert von +0,17 anzeigt.
- **AL-Random**: Ein blauer Balken, der einen AUC-Wert von +0,15 anzeigt.
- **AL-Entropy**: Ein blauer Balken, der einen AUC-Wert von +0,20 anzeigt.
- **AL-CoreSet**: Ein blauer Balken, der einen AUC-Wert von +0,19 anzeigt.
- **AL-CAL**: Ein blauer Balken, der einen AUC-Wert von +0,19 anzeigt.
- **AL-PRC (ours)**: Ein blauer Balken, der einen AUC-Wert von +0,21 anzeigt.
- **Final Model (best transfer model + cumulative new data)**: Ein grüner Balken, der einen AUC-Wert von +0,25 anzeigt.

Die Grafik zeigt, dass der "Final Model" den besten AUC-Wert von +0,25 erreicht, gefolgt von "AL-PRC (ours)" mit +0,21 und "AL-Entropy" mit +0,20. Die anderen Methoden liegen niedriger, wobei "Baseline: from scratch" und "Transferred model" die niedrigsten Werte haben.</sample>
    <sample id="1523">### Aktives Lernen: Strategie der Seltenheitswahrscheinlichkeit

#### Eigenschaften des Aktiven Lernens

| Seltenheitswahrscheinlichkeit | Zeit (s) | Subjektive Differenz |
|-----------------------------|----------|---------------------|
| Zufällig                     | 3,20     | 11,96               | -0,065              |
| Entropy                      | 6,80     | 12,78               | 0,035               |
| CoreSet                      | 6,00     | 11,89               | 0,039               |
| CAL                          | 4,80     | 11,88               | -0,045              |
| PRC                         | 7,60     | 13,55               | 0,071               |

- Minimum Annotationskosten führen nicht notwendigerweise zu besseren Modellen.
- Seltenheit kann die Annotierung schwieriger machen: kognitive Dissonanz ist ein solches Beispiel.
- Um Dissonanzbeispiele zu erhöhen, funktioniert PRC am besten.</sample>
    <sample id="1524">Die wichtigsten Punkte sind:

- Seltenes Klassennachrichten ~ "Nadel im Heuhaufen"
- PRC ist einfach und effizient für die seltene Probenakquisition

- Cold-start AL mit Transfer-Learning
- Out-of-domain: Iterativ
- In-domain: Cumulative</sample>
    <sample id="1525">Die wichtigsten Punkte sind:

- Seltenes Klassennachrichten ~ "Nadel im Heuhaufen"
- PRC ist einfach und effizient für die seltene Probenakquisition

- Cold-start AL mit Transfer-Learning
- Out-of-domain: Iterativ
- In-domain: Cumulative</sample>
    <sample id="1526">Der englische Inhalt lautet:

"Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge

Contact: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu

Code:
https://github.com/humanlab/rare-class-AL

Dataset:
https://github.com/humanlab/dissonance-twitter-dataset

Paper:
https://arxiv.org/abs/2305.02459

Thank you!"

Übersetzt in den deutschen Sinne bedeutet das:

"Transfer und Aktives Lernen zur Detektion von Dissonanz: Die Herausforderung der seltenen Klasse angehen

Kontakt: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu

Code:
https://github.com/humanlab/rare-class-AL

Datenbank:
https://github.com/humanlab/dissonance-twitter-dataset

Publikation:
https://arxiv.org/abs/2305.02459

Danke!"</sample>
    <sample id="1527">Die Autoren Matthias Lindemann, Alexander Koller und Ivan Titov gehören der University of Edinburgh an.</sample>
    <sample id="1528">Der Referent ist Siyu Yuan.</sample>
    <sample id="1529">Es sind fünf Autoren an der Arbeit beteiligt: Patrick Fernandes, Kayo Yin, Emmy Liu, André F.T. Martins und Graham Neubig.</sample>
    <sample id="1530">Der Ansatz wird mit der "state of the art architecture specifically tailored for SimulST" verglichen.</sample>
  </task>
</testset>