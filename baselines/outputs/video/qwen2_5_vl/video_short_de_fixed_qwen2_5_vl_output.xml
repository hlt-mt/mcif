<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind Wikipedia, Google Patents, New York Times, Wall Street Journal, The Guardian, PLOS Journals, Frontiers in Psychology, and Fool.com.</sample>
    <sample id="1">McGill University</sample>
    <sample id="2">DEPLAIN: Ein deutsches Parallelkorpus mit intralingualen Übersetzungen in einfache Sprache zur Satz- und Dokumenteinfachstellung

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich Heine University Düsseldorf, Deutschland

ACL 2023</sample>
    <sample id="3">Der englische Text lautet:

"DEPLAIN: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich Heine University Düsseldorf, Germany

ACL 2023"

Übersetzt ins Deutsche:

"DEPLAIN: Ein deutsches Parallelkorpus mit intralingualen Übersetzungen in einfache Sprache für Satz- und Dokumenteinfachstellung

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich-Heine-Universität Düsseldorf, Deutschland

ACL 2023"</sample>
    <sample id="4">Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plain Language:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="5">Der englische Text lautet:

"Text Simplification Example"

Der deutsche Inhalt lautet:

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plain Language:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="6">Der englische Text lautet:

"Text Simplification Example"

Der deutsche Inhalt lautet:

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plain Language:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="7">Der englische Text lautet:

"Text Simplification Example"

Der deutsche Inhalt lautet:

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plain Language:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="8">Der englische Text lautet:

"German Text Simplification Corpora"

"2. DE-plain
A New Corpus"

"German Text Simplification Corpora"

"Sentence Level"

Die Übersetzung ins Deutsche lautet:

"Deutsche Textvereinfachungskorpora"

"2. DE-plain
Ein neues Korpus"

"Deutsche Textvereinfachungskorpora"

"Satzebene"</sample>
    <sample id="9">Der englische Text lautet:

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"</sample>
    <sample id="10">Der englische Text lautet:

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"</sample>
    <sample id="11">Der englische Text lautet:

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"</sample>
    <sample id="12">Der englische Text lautet:

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"

"German Text Simplification Corpora"</sample>
    <sample id="13">Der englische Text lautet:

"German Text Simplification Corpora

Sentence Level"

Übersetzt auf Deutsch:

"Deutsche Texteinfachmachungs-Korpora

Satzebene"</sample>
    <sample id="14">### Typen der Vereinfachung

#### Typen der Vereinfachung
- **Simplicity**
- **LexSimp**
- **StructSimp**

#### Vereinfachungsverfahren
- **Reordering** (Anordnung ändern)
- **Rephrasing** (Umformulierung)
- **Lexical substitution** (Wortersatz)
- **Word addition** (Worterweiterung)
- **Word deletion** (Wortentfernung)</sample>
    <sample id="15">### Typen der Vereinfachung

#### Typen der Vereinfachung
- **Simplicity**
- **LexSimp**
- **StructSimp**

#### Vereinfachungsverfahren
- **Reordering** (Anordnung ändern)
- **Rephrasing** (Wiederausdrücken)
- **Lexical substitution** (Wortersatz)
- **Word addition** (Worterhöhung)
- **Word deletion** (Wortentfernung)</sample>
    <sample id="16">### Typen der Vereinfachung

#### Typen der Vereinfachung
- **Simplicity**
- **LexSimp**
- **StructSimp**

#### Vereinfachungsverfahren
- **Reordering** (Anordnung ändern)
- **Rephrasing** (Umformulierung)
- **Lexical substitution** (Wortersatz)
- **Word addition** (Worterweiterung)
- **Word deletion** (Wortentfernung)</sample>
    <sample id="17">### Arten der Vereinfachung

#### Typen der Vereinfachung
- **Simplicity**
- **LexSimp**
- **StructSimp**

#### Vereinfachungsverfahren
- **Reordering** (Anordnung ändern)
- **Rephrasing** (Umformulierung)
- **Lexical substitution** (Wortersatz)
- **Word addition** (Worterweiterung)
- **Word deletion** (Wortentfernung)</sample>
    <sample id="18">### Typen der Vereinfachung

#### Typen der Vereinfachung
- **Simplicity**
- **LexSimp**
- **StructSimp**

#### Vereinfachungsverfahren
- **Reordering** (Anordnung ändern)
- **Rephrasing** (Wiederausdrücken)
- **Lexical substitution** (Wortersatz)
- **Word addition** (Worterhöhung)
- **Word deletion** (Wortentfernung)</sample>
    <sample id="19">3. Fallstudien
Automatische Ausrichtung und Vereinfachung

Ergebnisse der Ausrichtungsverfahren mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung | 1:1 | n:m |
|------|--------------|-----|-----|
| LHA | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding | .94 | - |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers | .961 | - |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa | .960 | - |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren | .247 | - |
| VecAlign | Multilingualer Aligner basierend auf multilingualen Satzembedding | .271 | - |
| BERTalign | Erlaubt, dass sentence-transformer Methoden n:m Ausrichtungen produzieren | .743 | - |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix | .846 | - |

Übersetzung:
3. Fallstudien
Automatische Ausrichtung und Vereinfachung

Ergebnisse der Ausrichtungsverfahren mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)

| Name | Beschreibung | 1:1 | n:m |
|------|--------------|-----|-----|
| LHA | Hierarchische Ausrichtung mit Ähnlichkeit von Satzembedding | .94 | - |
| Sent-LaBSE | Ähnliche Embeddings eines sprachunabhängigen BERT-Transformers | .961 | - |
| Sent-RoBERTa | Ähnliche Embeddings von Cross English &amp; German RoBERTa | .960 | - |
| CATS-C3G | Verschiedene Ähnlichkeitsmaße, z.B. n-Grams (C3G)/Wortvektoren | .247 | - |
| VecAlign | Multilingualer Aligner basierend auf multilingualen Satzembedding | .271 | - |
| BERTalign | Erlaubt, dass sentence-transformer Methoden n:m Ausrichtungen produzieren | .743 | - |
| MASSalign | Eine vicinity-getriebene Methode mit einer TF-IDF-Similaritätsmatrix | .846 | - |</sample>
    <sample id="20">Der englische Text lautet:

"Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)"

Übersetzt ins Deutsche:

"Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)"</sample>
    <sample id="21">Der englische Text lautet:

"Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)"

Übersetzt ins Deutsche:

"Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)"</sample>
    <sample id="22">Der englische Text lautet:

"Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)"

Übersetzt auf Deutsch bedeutet das:

"Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)"</sample>
    <sample id="23">Der englische Text lautet:

"Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)"

Übersetzt ins Deutsche:

"Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)"</sample>
    <sample id="24">Der englische Text lautet:

"Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)"

Übersetzt ins Deutsche:

"Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)"</sample>
    <sample id="25">Der englische Text lautet:

"Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)"

Übersetzt ins Deutsche:

"Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)"</sample>
    <sample id="26">Der englische Text lautet:

"Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)"

Übersetzt ins Deutsche:

"Ergebnisse der Ausrichtungsmethoden mit 1:1 (obere Hälfte) und n:m Fähigkeiten (untere Hälfte)"</sample>
    <sample id="27">Der englische Text lautet:

"Results on Document Simplification using finetuned long-mBART.
n corresponds to the length of the training data."

Hier ist die Übersetzung ins Deutsche:

"Erfolge bei der Dokumentenvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes."</sample>
    <sample id="28">Der englische Text lautet:

"Results on Document Simplification using finetuned long-mBART.
n corresponds to the length of the training data."

Hier ist die Übersetzung ins Deutsche:

"Erfolge bei der Dokumentenvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes."</sample>
    <sample id="29">Der englische Text lautet:

"Results on Document Simplification using finetuned long-mBART.
n corresponds to the length of the training data."

Hier ist die Übersetzung ins Deutsche:

"Erfolge bei der Dokumentenvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes."</sample>
    <sample id="30">Der englische Text lautet:

"Results on Document Simplification using finetuned long-mBART.
n corresponds to the length of the training data."

Hier ist die Übersetzung ins Deutsche:

"Erfolge bei der Dokumentenvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes."</sample>
    <sample id="31">Der englische Text lautet:

"Results on Document Simplification using finetuned long-mBART.
n corresponds to the length of the training data."

Hier ist die Übersetzung ins Deutsche:

"Erfolge bei der Dokumentenvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes."</sample>
    <sample id="32">Der englische Text lautet:

"Results on Document Simplification using finetuned long-mBART.
n corresponds to the length of the training data."

Hier ist die Übersetzung ins Deutsche:

"Erfolge bei der Dokumentenvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes."</sample>
    <sample id="33">Der englische Text lautet:

"Results on Document Simplification using finetuned long-mBART.
n corresponds to the length of the training data."

Hier ist die Übersetzung ins Deutsche:

"Erfolge bei der Dokumentenvereinfachung mit finetuned long-mBART.
n entspricht der Länge des Trainingsdatensatzes."</sample>
    <sample id="34">Danke.

Für weitere Details. Bitte schauen Sie sich unser Papier an.
Und freuen Sie sich darauf, unseren Poster auf der ACL 2023 Konferenz zu besuchen.</sample>
    <sample id="35">Der Referent*in ist Patrick Fernandes, Kayo Yin, Emmy Liu, André F.T. Martins und Graham Neubig.</sample>
    <sample id="36">Das T5 XL Modell wurde verwendet, um eine Genauigkeit von 82–87 % zu erreichen, wenn das LM (Language Model) nur über die Namen der Entitäten verfügt.</sample>
    <sample id="37">Ja, CoNLL-2003-Tagger funktionieren immer noch.</sample>
    <sample id="38">Die vorgeschlagene menschliche Bewertungsmethode beinhaltet die Annotierung von Verhaltensweisen im Chat (ABC-Eval) und die Bewertung der Relevanz der Bots-Antworten. Neu ist, dass sie spezifische Kategorien wie "Irrelevant", "Mangel an Empathie" und "Selbstkontradiktion" verwendet, um die Qualität der Interaktion zu bewerten.</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Art der Validierung ab, die auf den Labels durchgeführt wird.</sample>
    <sample id="40">Das Bild zeigt keine spezifischen Informationen über die Verbesserungsmöglichkeiten des Ergebnisses. Es handelt sich um eine Präsentation mit Informationen zu Musik und Anforderungen an Annotatoren, aber es gibt keine Hinweise darauf, wie das Ergebnis verbessert werden könnte.</sample>
    <sample id="41">Es sind fünf Autoren an der Arbeit beteiligt.</sample>
    <sample id="42">Der englische Inhalt lautet:

"Conjunct Lengths in English, Dependency Length Minimization, and Dependency Structure of Coordination

Adam Przepiórkowski und Michał Woźniak

Institute of Computer Science, Polish Academy of Sciences
ul. Jana Kazimierza 5, 01-248 Warsaw

University of Warsaw

ACL 2023"

Übersetzt ins Deutsche:

"Kongruenzlängen im Englischen, Abhängigkeitslängenminimierung und Abhängigkeitsstruktur von Koordination

Adam Przepiórkowski und Michał Woźniak

Institut für Informatik, Polnische Akademie der Wissenschaften
ul. Jana Kazimierza 5, 01-248 Warschau

Universität Warschau

ACL 2023"</sample>
    <sample id="43">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="44">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="45">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."

Übersetzt ins Deutsche:

"Abhängigkeitsstruktur von Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie.

- Chain/Moskau:
  Homer liebt Lisa, Bart und Maggie.

- Konjunktion-geführte/Prag:
  Homer liebt Lisa, Bart und Maggie.

- Mehrköpfige/London:
  Homer liebt Lisa, Bart und Maggie."</sample>
    <sample id="46">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="47">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."</sample>
    <sample id="48">Der englische Inhalt lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."

Übersetzt ins Deutsche:

"Abhängigkeitsstruktur der Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie.

- Chain/Moskau:
  Homer liebt Lisa, Bart und Maggie.

- Konjunktion-schwerpunkt/Prag:
  Homer liebt Lisa, Bart und Maggie.

- Mehrfach-schwerpunkt/London:
  Homer liebt Lisa, Bart und Maggie."</sample>
    <sample id="49">Der englische Text lautet:

"Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie."

Übersetzt ins Deutsche:

"Abhängigkeitsstruktur von Koordination

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie.

- Chain/Moskau:
  Homer liebt Lisa, Bart und Maggie.

- Konjunktion-geführte/Prag:
  Homer liebt Lisa, Bart und Maggie.

- Mehrköpfige/London:
  Homer liebt Lisa, Bart und Maggie."</sample>
    <sample id="50">Die englischen Inhalte auf dem Bildschirm sind bereits in Deutsch übersetzt:

- **Dependency Structure of Coordination**
  - Bouquet/Stanford (Universal Dependencies):
    Homer liebt Lisa, Bart und Maggie.
  - Chain/Moskau:
    Homer liebt Lisa, Bart und Maggie.
  - Konjunktion-gestützt/Prag:
    Homer liebt Lisa, Bart und Maggie.
  - Mehrköpfige/London:
    Homer liebt Lisa, Bart und Maggie.</sample>
    <sample id="51">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="52">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="53">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="54">Der englische Text lautet:

"Dependency Length Minimization (DLM)
Die Wortreihenfolge neigt sich dazu, Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="55">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="56">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="57">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="58">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:

Marge read it yesterday.
gut

Marge read yesterday it.
schlecht

Marge read this absolutely fascinating book about bees yesterday.
gut

Marge read yesterday this absolutely fascinating book about bees.
gut"

Übersetzt ins Deutsche:

"Abhängigkeitslängenminimierung (DLM)

Die Wortstellung neigt sich dazu, die Abhängigkeitslängen zu minimieren:

Marge hat gestern gelesen.
gut

Marge hat gestern gelesen.
schlecht

Marge hat diesen absolut faszinierenden Buch über Bienen gestern gelesen.
gut

Marge hat gestern dieses absolut faszinierende Buch über Bienen gelesen.
gut"</sample>
    <sample id="59">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="60">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="61">Der englische Text lautet:

"Dependency Length Minimization (DLM)

Die Wortreihenfolge neigt sich dazu, die Abhängigkeitslängen zu minimieren:"</sample>
    <sample id="62">Der englische Text lautet:

"Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):
- left conjuncts tend to be shorter (observed before),
- this tendency grows with length difference
(briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent
(I saw Bart and Lisa; Homer came and sneezed),
- not when it is on the right (Ted and Ned laughed)."

Übersetzt ins Deutsche:

"Statistiken über Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunkte neigen dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz
(wurde kurz in Gibson et al. 1996: 88–90 bemerkt),
- aber nur wenn der Regierungsmitglied auf der linken Seite oder fehlend ist
(ich sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn es auf der rechten Seite ist (Ted und Ned lachten)."</sample>
    <sample id="63">Die englischen Inhalte können wie folgt in Deutsch übersetzt werden:

"Statistiken über die Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):

- linke Konjunktionen tendieren dazu, kürzer zu sein (beobachtet vorher)
- diese Tendenz wächst mit der Längendifferenz
- aber nur wenn der Regisseur links ist oder fehlt
  (Ich sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn er rechts ist (Ted und Ned lachten)."</sample>
    <sample id="64">Die englischen Inhalte können wie folgt in Deutsch übersetzt werden:

"Statistiken über die Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunktionen tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz
(brieflich in Gibson et al. 1996: 88–90 aufgezeigt),
- aber nur wenn der Regulator links steht oder fehlt
(Ich sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn er rechts steht (Ted und Ned lachten)."</sample>
    <sample id="65">Die englischen Inhalte können wie folgt in Deutsch übersetzt werden:

**Konjunkt-Längen im Englischen**

Statistiken über die Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- Links stehende Konjunktionen tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz (kurz erwähnt in Gibson et al. 1996: 88–90),
- aber nur wenn der Regisseur links steht oder fehlt (Ich sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn er rechts steht (Ted und Ned lachten).</sample>
    <sample id="66">Die englischen Inhalte können wie folgt in Deutsch übersetzt werden:

**Konjunkt-Längen im Englischen**

Statistiken über die Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- Linkselemente tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz (kurz erwähnt in Gibson et al. 1996: 88–90),
- aber nur wenn der Regisseur links ist oder fehlt
  (Ich sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn es rechts ist (Ted und Ned lachten).</sample>
    <sample id="67">Die englischen Inhalte können wie folgt in Deutsch übersetzt werden:

"Statistiken zur Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- linke Konjunktionen tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz
(bevorübergehend in Gibson et al. 1996: 88–90 bemerkt),
- aber nur wenn der Regisseur links ist oder fehlt
(I sah Bart und Lisa; Homer kam und schnäuzte sich)
- nicht, wenn er rechts ist (Ted und Ned lachten)."</sample>
    <sample id="68">Die englischen Inhalte können wie folgt in Deutsch übersetzt werden:

**Konjunkt-Längen im Englischen**

Statistiken zur Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- Linkselemente tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz (kurz erwähnt in Gibson et al. 1996: 88–90),
- aber nur wenn der Regisseur links ist oder fehlt
  (Ich sah Bart und Lisa; Homer kam und schnäuzte sich)
- nicht, wenn es rechts ist (Ted und Ned lachten).</sample>
    <sample id="69">Die englischen Inhalte können wie folgt in Deutsch übersetzt werden:

**Konjunkt-Längen im Englischen**

Statistiken zur Koordination extrahiert aus einer erweiterten Version des Penn Treebanks (Marcus et al. 1993, Ficler und Goldberg 2016):
- Linkselemente tendieren dazu, kürzer zu sein (beobachtet vorher),
- diese Tendenz wächst mit der Längendifferenz (kurz erwähnt in Gibson et al. 1996: 88–90),
- aber nur wenn der Regisseur links ist oder fehlt
  (Ich sah Bart und Lisa; Homer kam und schnäuzte sich),
- nicht, wenn es rechts ist (Ted und Ned lachten).</sample>
    <sample id="70">Die Abbildung zeigt die Proportionen von kürzeren linken Konjunkten in Abhängigkeit vom absoluten Unterschied der Längen der Konjunkte (mit Konfidenzbändern).

Legende:
- NO governor (length in CHARACTERS): Kein Regulator (Länge in Zeichen)
- NO governor (length in SYLLABLES): Kein Regulator (Länge in Silben)
- NO governor (length in WORDS): Kein Regulator (Länge in Wörtern)
- Governor on the LEFT (length in CHARACTERS): Regulator auf der linken Seite (Länge in Zeichen)
- Governor on the LEFT (length in SYLLABLES): Regulator auf der linken Seite (Länge in Silben)
- Governor on the LEFT (length in WORDS): Regulator auf der linken Seite (Länge in Wörtern)
- Governor on the RIGHT (length in CHARACTERS): Regulator auf der rechten Seite (Länge in Zeichen)
- Governor on the RIGHT (length in SYLLABLES): Regulator auf der rechten Seite (Länge in Silben)
- Governor on the RIGHT (length in WORDS): Regulator auf der rechten Seite (Länge in Wörtern)

Die Grafiken zeigen, wie sich die Proportionen von kürzeren linken Konjunkten mit zunehmendem absoluten Unterschied der Längen der Konjunkte verändern.</sample>
    <sample id="71">Die Abbildung zeigt die Proportionen kürzerer linksextremer Konjunkte in Abhängigkeit von der absoluten Differenz der Konjunkt-Längen (mit Konfidenzbändern).

Legende:
- NO governor (länge in CHARACTERS): Kein Regulator (Länge in Zeichen)
- NO governor (länge in SYLLABLES): Kein Regulator (Länge in Silben)
- NO governor (länge in WORDS): Kein Regulator (Länge in Wörtern)
- Governor on the LEFT (länge in CHARACTERS): Regulator auf der linken Seite (Länge in Zeichen)
- Governor on the LEFT (länge in SYLLABLES): Regulator auf der linken Seite (Länge in Silben)
- Governor on the LEFT (länge in WORDS): Regulator auf der linken Seite (Länge in Wörtern)
- Governor on the RIGHT (länge in CHARACTERS): Regulator auf der rechten Seite (Länge in Zeichen)
- Governor on the RIGHT (länge in SYLLABLES): Regulator auf der rechten Seite (Länge in Silben)
- Governor on the RIGHT (länge in WORDS): Regulator auf der rechten Seite (Länge in Wörtern)

Die Grafiken zeigen, wie sich die Proportionen kürzerer linksextremer Konjunkte mit zunehmender absoluter Differenz der Konjunkt-Längen verändern.</sample>
    <sample id="72">Die Abbildung zeigt die Proportionen von kürzeren linken Konjunkten in Abhängigkeit vom absoluten Unterschied der Längen der Konjunkte (mit Konfidenzbändern).

Legende:
- NO governor (länge in CHARACTERS): Kein Regisseur (Länge in Zeichen)
- NO governor (länge in SYLLABLES): Kein Regisseur (Länge in Silben)
- NO governor (länge in WORDS): Kein Regisseur (Länge in Wörtern)
- Governor on the LEFT (länge in CHARACTERS): Regisseur auf der linken Seite (Länge in Zeichen)
- Governor on the LEFT (länge in SYLLABLES): Regisseur auf der linken Seite (Länge in Silben)
- Governor on the LEFT (länge in WORDS): Regisseur auf der linken Seite (Länge in Wörtern)
- Governor on the RIGHT (länge in CHARACTERS): Regisseur auf der rechten Seite (Länge in Zeichen)
- Governor on the RIGHT (länge in SYLLABLES): Regisseur auf der rechten Seite (Länge in Silben)
- Governor on the RIGHT (länge in WORDS): Regisseur auf der rechten Seite (Länge in Wörtern)

Die Grafiken zeigen, wie sich die Proportionen von kürzeren linken Konjunkten mit zunehmendem absoluten Unterschied der Konjunktlängen verändern.</sample>
    <sample id="73">Die Übersetzung des englischen Inhalts in Deutsch lautet:

"Kompatibilität mit Abhängigkeitsstrukturen von Koordination"

- Bouquet/Stanford (Universal Dependencies):
  Homer liebt Lisa, Bart und Maggie. NEIN

- Chain/Moscow:
  Homer liebt Lisa, Bart und Maggie. NEIN

- Conjunction-headed/Prague:
  Homer liebt Lisa, Bart und Maggie. JA

- Multi-headed/London:
  Homer liebt Lisa, Bart und Maggie. JA</sample>
    <sample id="74">Der englische Text lautet:

"See the paper for the full argument!
Talk to us at the poster session!"

Übersetzt auf Deutsch bedeutet das:

"Sehen Sie sich den Artikel für die vollständige Argumentation an!
Kommen Sie zu uns in der Poster-Sitzung!"</sample>
    <sample id="75">Es sind drei Autoren an der Arbeit beteiligt: Matthias Lindemann, Alexander Koller und Ivan Titov.</sample>
    <sample id="76">Die Domains "bible" und "fiction" werden stärker vereinfacht.</sample>
    <sample id="77">"I saw Bart and Lisa; Homer came and sneezed"</sample>
    <sample id="78">Ja, Sie können die DrBERT-Modelle für Ihre Forschung verwenden, da sie unter der MIT-Lizenz frei verfügbar sind.</sample>
    <sample id="79">DEplain-APA enthält Dokumente aus der Presse.</sample>
    <sample id="80">Für eine gute Generalisierung benötigen wir:
- Bessere Modellarchitektur
- Größere Modellgröße
- Mehr Feinabstimmungsbeispiele</sample>
    <sample id="81">Die Tendenz wurde durch die Proportion der kürzeren linken Konjunktionen gemessen, die sich mit der absoluten Differenz der Konjunktionslängen ändert.</sample>
    <sample id="82">Die Experimente wurden so gestaltet, dass sie die Proportionen von kürzeren linken Konjunkten untersuchten, die abhängig von der absoluten Differenz der Längen der Konjunkte waren (mit Konfidenzbändern).</sample>
    <sample id="83">Ein Basisklassifikator, der mit unausgewogenen Daten trainiert wird, zeigt eine geringe Genauigkeit, da das AUC-Wert (Area under the ROC curve) nur 0,50 beträgt. Dies bedeutet, dass der Klassifikator nicht besser als Zufall funktioniert hat.</sample>
    <sample id="84">Es gibt vier Autoren an der Arbeit beteiligt: Shangbin Feng, Chan Young Park, Yuhan Liu und Yulia Tsvetkov.</sample>
    <sample id="85">Die Personen im Beispielgespräch heißen nicht spezifisch genannt, aber es gibt zwei Figuren, die sich unterhalten. Eine Figur fragt: "Remember that song we were listening to yesterday?", und die andere Figur antwortet mit einer Alternative: "Do you mean 'Easy on Me' or 'I Gotta Feeling'?".</sample>
    <sample id="86">Formalität und lexikalische Cohesion.</sample>
    <sample id="87">Die Autoren gehören an Johns Hopkins University, Purdue University und MIT.</sample>
    <sample id="122">Das vorgestellte Framework quantifiziert die Positionalität durch die Messung der Pearson's r Korrelation zwischen Goldlabels, Modellvorhersagen und Annotierungen für jede Demografie separat.</sample>
    <sample id="155">Das Ergebnis der vorherigen Studie, bei der die menschlichen Teilnehmenden die gleichen Persona-Prompts erhalten haben, wurde von einer psychologischen Studie inspiriert.</sample>
    <sample id="156">Die Datenquellen in dieser Studie waren eine erweiterte Version des Penn Treebanks (Marcus et al. 1993, Ficler and Goldberg 2016).</sample>
    <sample id="157">Zwei Autoren sind an der Arbeit beteiligt: Adam Przepiórkowski und Michał Woźniak.</sample>
    <sample id="158">Debatte und Vergleich und Erweiterungsklassen.</sample>
    <sample id="159">Es sind zwei Autoren an der Arbeit beteiligt: Shuheng Liu und Alan Ritter.</sample>
    <sample id="160">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten dadurch, dass es eine Vielzahl an Anmerkungen durch Menschen aus der ganzen Welt verwendet, um Modelle zu evaluieren und zu analysieren, was zu einer breiteren und diverseren Perspektive führt.</sample>
    <sample id="162">Das Setup "GPT-3.5" hat die meisten Überschneidungen mit dem Lexikon der Stereotypen.</sample>
    <sample id="163">DeepL und Google wurden verglichen.</sample>
    <sample id="164">Der englische Text lautet:

"From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models"

Übersetzt auf Deutsch bedeutet das:

"Aus Vorbereitungsdaten bis zu Sprachmodellen und hin zu untergeordneten Aufgaben: Verfolgen der Spuren politischer Biass führend zu unfairen NLP-Modellen"</sample>
    <sample id="165">Der englische Text lautet:

"LM Training Data
A mixed blessing"

Übersetzt auf Deutsch bedeutet das:

"LM-Trainingsdaten
Ein gemischtes Segen"</sample>
    <sample id="166">Der englische Text lautet:

"LM Training Data
A mixed blessing"

Der deutsche Text lautet:

"LM-Trainingsdaten
Ein gemischtes Segen"</sample>
    <sample id="167">Der englische Text lautet:

"LM Training Data
A mixed blessing"

Der deutsche Text lautet:

"LM-Trainingsdaten
Ein gemischtes Segen"</sample>
    <sample id="168">Der englische Text lautet:

"LM Training Data
A mixed blessing

To this end"

Übersetzt auf Deutsch bedeutet das:

"LM-Trainingsdaten
Ein gemischtes Segen

Zum Schluss"</sample>
    <sample id="169">Zum Schluss

- Prätraining-Daten
  - Wie kann man die politische Neigung von LM's bewerten?
  - Welche Rolle spielen die Prätraining-Daten bei solchen politischen Verzerrungen?

- Sprachmodelle
  - Wie performen LM's mit unterschiedlichen politischen Neigungen?
  - Führt die politische Neigung von LM's zu Gerechtigkeitsproblemen in NLP-Anwendungen?</sample>
    <sample id="170">Zum Ende

- Prätraining-Daten
  - Wie kann man die politische Neigung von LM's bewerten?
  - Welche Rolle spielt das Prätraining-Daten in solchen politischen Verzerrungen?

- Sprachmodelle
  - Wie performen LM's mit unterschiedlichen politischen Neigungen?
  - Führt die politische Neigung von LM's zu Gerechtigkeitsproblemen in NLP-Anwendungen?</sample>
    <sample id="171">Zum Ende

- Prätraining-Daten
  - Wie kann man die politische Neigung von LM's bewerten?
  - Welche Rolle spielt das Prätraining-Daten in solchen politischen Verzerrungen?

- Sprachmodelle
  - Wie performen LM's mit unterschiedlichen politischen Neigungen?
  - Führt die politische Neigung von LM's zu Gerechtigkeitsproblemen in NLP-Anwendungen?

Evaluierung der politischen Neigung von LM's

Unterstützt sowohl Encoder- als auch Decoder-LM's
- "Stimmen Sie dieser Aussage zu oder widersprechen Sie ihr?" &lt;Aussage&gt;
- Automatische Bewertung
- Grundlegend in politischer Richtung
- Frage: Unser Volk hat viele überlegene Eigenschaften im Vergleich zu anderen Völkern.
- Antwort: Einigkeit / Widerspruch
- Politische Neigung
  - Libertär
  - Autoritär</sample>
    <sample id="172">### Evaluierung der politischen Neigung von Sprachmodellen (LMs)

Unterstützt sowohl Encoder- als auch Decoder-LMs

"Mit diesem Aussage einverstanden? &lt;Aussage&gt;"

"Wie stimmen Sie dieser Aussage zu? &lt;Aussage&gt;"

Automatische Bewertung

Basiert auf politikwissenschaftlicher Literatur

### Bestehende LMs

Autoritärer
Libertärer

Links
Rechts</sample>
    <sample id="173">Bestehende LMs

Die Abbildung zeigt eine Matrix, die verschiedene Sprachmodelle (LMs) in Bezug auf ihre politischen Positionen in einem sozialen und wirtschaftlichen Kontext darstellt. Die x-Achse repräsentiert die "Libertarian"-Position (links) bis zur "Authoritarian"-Position (rechts), während die y-Achse die "Left"-Position (unten) bis zur "Right"-Position (oben) zeigt.

- **Soziale Achse**: Links befinden sich Modelle mit einer libertären Position, während rechts Modelle mit einer autoritären Position platziert sind.
- **Wirtschaftliche Achse**: Unten befinden sich Modelle mit einer linken Position, während oben Modelle mit einer rechten Position platziert sind.

Die Modelle sind wie folgt positioniert:
- **Links (Libertarian)**: BERT-base, BERT-large, RoBERTa-base, RoBERTa-large, distilBERT, distilRoBERTa, ALBERT-base, ALBERT-large, BART-base, BART-large, Alpaca.
- **Rechts (Authoritarian)**: Codex, LLaMA, GPT-2, GPT-3-ada, GPT-3-babbage, GPT-3-curie, GPT-3-davinci, ChatGPT, GPT-4, GPT-J.

Diese Positionierung gibt einen Überblick über die politischen Präferenzen der Modelle in Bezug auf soziale und wirtschaftliche Themen.</sample>
    <sample id="174">Der englische Text lautet:

"Existing LMs"

"Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning"

"Shen, Qinlan, and Carolyn Rose. "Politics: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection." Findings of the Association for Computational Linguistics: NAACL 2022."

"Social Media Data"

"BERT-base, BERT-large, RoBERTa-base, distilBERT, ALBERT-base, ALBERT-large, BART-base, BART-large, Alpaca"

"Codex, LLaMA, GPT-2, GPT-3-ada, GPT-3-babbage, GPT-3-curie, GPT-3-davinci, ChatGPT, GPT-4, GPT-J"

Übersetzt bedeutet das:

"Bestehende LMs"

"Erweiterte prätrainierte LM (RoBERTa, GPT-2) Checkpoints, evaluieren Veränderung im politischen Neigen"

"Shen, Qinlan und Carolyn Rose. "Politik: Prätraining mit gleichen Artikel-Vergleich für Ideologie Vorhersage und Stellungnahme." Ergebnisse der Association for Computational Linguistics: NAACL 2022."

"Soziale Medien-Daten"

"BERT-base, BERT-large, RoBERTa-base, distilBERT, ALBERT-base, ALBERT-large, BART-base, BART-large, Alpaca"

"Codex, LLaMA, GPT-2, GPT-3-ada, GPT-3-babbage, GPT-3-curie, GPT-3-davinci, ChatGPT, GPT-4, GPT-J"</sample>
    <sample id="175">### Prätraining-Daten

Weiteres Prätraining von LM (RoBERTa, GPT-2) Checkpoints, um den Veränderung in politischen Neigungen zu bewerten.

#### News Media
- links
- zentrum
- rechts

#### Social Media (Reddit)
- links
- zentrum
- rechts

Literaturhinweise:
- Liu, Yujian et al.: "POLITICS: Prätraining mit gleichen Artikel-Vergleichen für Ideologievorhersage und Stellungnahmeerkennung." Findings of the Association for Computational Linguistics: NAACL 2022.
- Shen, Qinlan und Carolyn Rose: "Was klingt richtig für mich? Erfahrungsbezogene Faktoren bei der Wahrnehmung politischer Ideologien." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="176">### Prätraining-Daten

Weiteres Prätraining von LM (RoBERTa, GPT-2) Checkpoints, um den politischen Neigungswechsel zu bewerten.

#### News Media
- links
- zentrum
- rechts

#### Social Media (Reddit)
- links
- zentrum
- rechts

Literaturhinweise:
- Liu, Yujian et al.: "POLITICS: Prätraining mit gleichen Artikelvergleich für Ideologievorhersage und Stellungnahme." Findings of the Association for Computational Linguistics: NAACL 2022.
- Shen, Qinlan and Carolyn Rose: "Was klingt richtig für mich? Erfahrungsbedingte Faktoren in der Wahrnehmung politischer Ideologien." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="177">Ergebnisse

Parteiäre Verschiebungen in der politischen Neigung von LM (Sprachmodellen)

Das Bild zeigt zwei Diagramme, die die politische Neigung von Sprachmodellen (RoBERTa und GPT-2) darstellen. Die Farben verdeutlichen die politische Ausrichtung: Rot für rechts, Blau für links und Grün für zentrale Positionen. Die Pfeile zeigen die Richtung und Intensität der Verschiebung der politischen Neigung.</sample>
    <sample id="178">Ergebnisse

Parteiäre Verschiebungen in der politischen Neigung von LM (Sprachmodellen)

Ergebnisse

Parteiäre Verschiebungen in der politischen Neigung von LM (Sprachmodellen)</sample>
    <sample id="179">Ergebnisse

Parteiäre Verschiebungen in der politischen Neigung von LM (Sprachmodellen)

Trump-Karte

Parteiäre Verschiebungen um 45° in der politischen Neigung</sample>
    <sample id="180">Der englische Text lautet:

"The Trump Card

Pre-45th to post-45th shift"

Die Übersetzung ins Deutsche ist:

"Das Trump-Karte

Vor-45 bis nach-45 Verschiebung"</sample>
    <sample id="181">Der englische Text lautet:

"The Trump Card

Pre-45th to post-45th shift"

Dieser Text bezieht sich auf eine Grafik, die die Veränderungen in der politischen Meinungsschichtung von vor dem 45. Präsidenten bis nach dem 45. Präsidenten zeigt. Die Grafik enthält verschiedene Diagramme mit Pfeilen und Werten, die die Verschiebungen in verschiedenen Medien (wie Nachrichten und Reddit) darstellen.</sample>
    <sample id="182">Der englische Text lautet:

"The Trump Card

Pre-45th to post-45th shift"

Dieser Text bedeutet auf Deutsch:

"Das Trump-Karte

Vor dem 45. bis nach dem 45. Verschiebung"</sample>
    <sample id="183">### Per-Kategorie Leistung

Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodeiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste darstellt.

### Übersetzung:

Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodeiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste darstellt.</sample>
    <sample id="184">### Übersetzung des englischen Inhalts in Deutsch

**Per-Kategorie-Performance**

Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodeiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="185">### Übersetzung des englischen Inhalts in Deutsch

**Per-Kategorie Performance**

Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodeiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="186">Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodeiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="187">Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodeiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="188">Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodeiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste darstellt.</sample>
    <sample id="189">### Per-Kategorie Leistung

Tabelle 4: Leistung bei Hassrede, die verschiedene Identitätsgruppen und Missinformationen von verschiedenen Quellen anspricht. Die Ergebnisse sind farbcodeiert, wobei dunkles Gelb das beste und dunkles Blau das schlechteste Ergebnis darstellt.</sample>
    <sample id="190">Qualitative Analyse

Tabelle 5: Beispiele für die Leistung der Aufgaben mit verschiedenen politischen Bias-Modellen.

CHRIS, Base, N, S, L, R repräsentieren Christen, das vanilla RoBERTa-Modell, Nachrichtenmedien, soziale Medien, linke und rechte Positionen, entsprechend.</sample>
    <sample id="191">### Qualitative Analyse

#### Tabelle 5: Beispiele für die Leistung der Aufgaben mit verschiedenen politischen Vorurteilen, die durch Sprachmodelle ausgeführt werden.

CHRIS, Base, N, S, L, R repräsentieren Christen, das vanilla RoBERTa-Modell, Nachrichtenmedien, soziale Medien, linke und rechte Neigung, entsprechend.

---

### Qualitative Analyse von Hassredebeispielen, wo Sprachmodelle mit unterschiedlichen politischen Neigungen abweichen.

Hassrede Text | Hass? | N-L | R-L | N-R | R-R
--- | --- | --- | --- | --- | ---
gleichgeschlechtliche Ehe konfliktiert nicht mit orthodoxen Katholiken, die sich von traditionellen Normen abwenden, da es unmöglich ist, dass es keine Ehe gibt. Ehe kann nur zwischen einem Mann und einer Frau bestehen, während Frauen, die anderes denken, sich selbst täuschen und dafür bezahlen müssen, dass sie Gott und die Gnade verdient haben.
TRUE | TRUE | TRUE | TRUE | FALSE | FALSE
hat Facebook wiederholt wegen mehrerer Tage ausgeschlossen, weil er eine pedophile Website als "nazi" bezeichnete und ein verfeindetes No 1 Amendment über die Mörderin nennen kann, die Christen alles will, aber nicht den anderen Weg finden kann.
TRUE | TRUE | TRUE | TRUE | FALSE | FALSE
Idioten bekamen kein Baugenehmigungsurteil? Typischer Weiße Jungs-Regel: Es ist einfacher, um Vergebung zu beten, und dann wird das Opfer gefragt, ob es gestatten möchte?
TRUE | TRUE | TRUE | TRUE | FALSE | FALSE
Ja, genau. Sie verbrennen diese religiösen Orte und verbrennen sie auf dem Boden. Das Vatikan, Israel, überall.
TRUE | FALSE | FALSE | TRUE | TRUE | TRUE
Idioten bekamen kein Baugenehmigungsurteil? Typischer Weiße Jungs-Regel: Es ist einfacher, um Vergebung zu beten, und dann wird das Opfer gefragt, ob es gestatten möchte?
TRUE | TRUE | TRUE | TRUE | FALSE | FALSE
A719 ist der Grund, warum ich Menschen hassen, insbesondere Frauen, die sich wie eine Frau ansehen, wie verrückt sie ist, dass der Hund sie bespritzt hat. F*** du, du bist ein Idiot b*****, entweder Spaß haben oder sterben.
TRUE | TRUE | TRUE | TRUE | FALSE | FALSE
Todesstrafe für Katholiken. Ist es legal, sie zu erschießen?
TRUE | FALSE | FALSE | TRUE | TRUE | TRUE
Sind du der Nazi-Fagott mit den weiblichen Brüsten? Ein Wärter
TRUE | TRUE | TRUE | TRUE | FALSE | FALSE
Die Vereinigte Staaten von Muslim-Amerika. Es ist gut zu wissen, dass Faggots immer noch geschossen werden werden.
TRUE | FALSE | FALSE | TRUE | TRUE | TRUE
Wie tust du dir einen Chorjunge? Kicks den Priester in den Arsch.
TRUE | TRUE | TRUE | TRUE | FALSE | FALSE
Was nennst du einen Indianer, der einen Shit Brownian macht?
TRUE | TRUE | TRUE | TRUE | FALSE | FALSE
Wenn ich diese Biestin im Busch sah, würde ich sie auf den Boden schleppen und ihr Gesicht in den Dreck spucken.
TRUE | TRUE | TRUE | TRUE | FALSE | FALSE

---

### Qualitative Analyse von Falschmeldungsexempeln, wo Sprachmodelle mit unterschiedlichen politischen Neigungen abweichen.

Falschmeldung Text | Falsch? | N-L | R-L | N-R | R-R
--- | --- | --- | --- | --- | ---
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsieht.
FALSE | TRUE | TRUE | TRUE | TRUE | TRUE
Es gibt Berichte, dass ein US-amerikanisches Gericht beschlossen hat, eine Million Dollar zu zahlen, um die Schadensersatzforderung eines jungen Border Crossers aus Mittelamerika zu erfüllen, der behauptet, Donald Trump habe ihn verletzt, indem er ihn in die Grenze gebracht habe. Dieses Gericht entschied, dass dies eine unzureichende Entschädigung sei und dass es eine andere Entscheidung treffen müsste, die eine andere Entschädigung vorsie</sample>
    <sample id="192">Tabelle 12: Qualitative Analyse von Hassrede-Beispielen, bei denen LMs mit unterschiedlichen politischen Vorlieben unterschiedliche Meinungen haben.

Tabelle 13: Qualitative Analyse von Falschinformationen-Beispielen, bei denen LMs mit unterschiedlichen politischen Vorlieben unterschiedliche Meinungen haben.</sample>
    <sample id="193">Tabelle 12: Qualitative Analyse von Hassrede-Beispielen, bei denen LMs mit unterschiedlichen politischen Vorlieben unterschiedliche Meinungen haben.

Tabelle 13: Qualitative Analyse von Falschmeldung-Beispielen, bei denen LMs mit unterschiedlichen politischen Vorlieben unterschiedliche Meinungen haben.</sample>
    <sample id="194">Tabelle 12: Qualitative Analyse von Hassrede-Beispielen, bei denen LMs mit unterschiedlichen politischen Vorlieben unterschiedliche Meinungen haben.

Tabelle 13: Qualitative Analyse von Falschmeldung-Beispielen, bei denen LMs mit unterschiedlichen politischen Vorlieben unterschiedliche Meinungen haben.</sample>
    <sample id="195">### Tabelle 12: Qualitative Analyse von Hassrede-Beispielen, wo LMs mit unterschiedlichen politischen Neigungen zu differieren scheinen.

| Hassrede-Text | Hass? | N-L | R-L | N-R | R-R |
|---------------|------|-----|-----|-----|-----|
| Homosexuelle Ehe konfliktlos für orthodoxe Katholiken, die sich widersetzen, betrachtet, da es unmöglich ist, es nicht zu sein. Ehe kann nur zwischen einem Mann und einer Frau bestehen, während Frauen, die anderes denken, sich selbst täuschen und Gott und Gottes Gnade verdienen.| Wahr | Wahr | Wahr | Falsch | Falsch |
| wurde von Facebook ausgeschlossen, weil ich einen Pedophilen und einen Perversen als Muzzis bezeichnet habe, die Christen alles wollen, was sie wollen, aber nicht anders.| Wahr | Wahr | Wahr | Falsch | Falsch |
| Ja, genau. Ich verbrenne diese religiösen Orte und verbrenne sie bis auf die Grundstücke.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Idiot hat kein Baugenehmigung bekommen? Typischer Weiße Jungs-Regel: Es ist einfacher, um Vergebung zu betteln, als um Erlaubnis zu bitten! Und dann werden die Opfer geopfert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Warum hasse ich Frauen? Weil sie sich fragen, wie wütend sie gerade ist, weil der Hund sie bespritzt hat. Sie sind dumm und sollten entweder Spaß haben oder sich selbst töten.| Wahr | Wahr | Wahr | Falsch | Falsch |
| Tod für Katholiken. Sollte es legal sein, sie zu erschießen?| Wahr | Falsch | Falsch | Wahr | Wahr |
| bist du der Nazi mit den weiblichen Brüsten?| Wahr | Wahr | Wahr | Falsch | Falsch |
| Diese obengesetzte nigger Bitch auf Tucker Show verdient es, eine Schlinge um ihren Hals zu legen und hängen zu lassen, bis sie tot ist.| Wahr | Wahr | Wahr | Wahr | Wahr |
| Was nennst du einen weißen Mann, der von tausenden schwarzen Männern umgeben ist? Ein Wärter.| Wahr | Wahr | Wahr | Falsch | Falsch |
| Vereinigte Staaten von Muslim-Amerika. Es ist gut zu wissen, dass Faggots immer noch erschossen werden.| Wahr | Wahr | Wahr | Falsch | Falsch |
| Wie tust du dir einen Chorjunge an? Kich die Priester im Gesicht.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Was nennst du einen Indianer, der einen Shit macht? Ein Brownianer.| Wahr | Wahr | Wahr | Falsch | Falsch |
| Wenn ich diese Bitch in der Nähe sehe, werde ich sie auf den Boden werfen und ihr das Gesicht abreißen.| Wahr | Wahr | Wahr | Falsch | Falsch |

### Tabelle 13: Qualitative Analyse von Falschmeldung-Beispielen, wo LMs mit unterschiedlichen politischen Neigungen zu differieren scheinen.

| Falschmeldung-Text | Fake? | N-L | R-L | N-R | R-R |
|--------------------|-------|-----|-----|-----|-----|
| In den USA ist die Strafzinsrate und die Gewaltkriminalität in den größten Städten höher als je zuvor.| Wahr | Wahr | Wahr | Falsch | Falsch |
| Trump hat sich von Anfang an gegen die Zuwanderung gestellt und will sie stoppen.| Wahr | Wahr | Wahr | Falsch | Falsch |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Falsch | Wahr | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verbessert.| Falsch | Wahr | Wahr | Falsch | Wahr |
| Die US-Regierung hat die Gesundheitsversorgung in den USA verschlechtert.| Wahr | Falsch | Fals</sample>
    <sample id="196">Diskussion

Zwischen Scylla und Charybdis

Ob man "sanitize" oder nicht "sanitize", das ist die Frage

- Prätraining-Daten
- Sprachmodelle
- Unternehmensaufgaben</sample>
    <sample id="197">Diskussion

Zwischen Scylla und Charybdis

Ob „sanitieren“ oder nicht „sanitieren“, das ist die Frage

- Prätraining-Daten
- Sprachmodelle
- Unternehmensaufgaben</sample>
    <sample id="198">### Diskussion

Zwischen Scylla und Charybdis

Ob „sanitieren“ oder nicht „sanitieren“, das ist die Frage.

- Prätraining-Daten
- Sprachmodelle
- Unternehmungsaufgaben

### Danke!

- Prätraining-Daten
- Sprachmodelle
- Unternehmungsaufgaben

Unterzeichnungen:
- Shangbin Feng
- Chan Young Park
- Yuhan Liu
- Yulia Tsvetkov

Logos:
- Paul G. Allen School
- UWNLP
- Carnegie Mellon University Language Technologies Institute</sample>
    <sample id="199">Der englische Text lautet:

"Thank you!"

Die Übersetzung ins Deutsche ist:

"Danke!"</sample>
    <sample id="200">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="201">900 Tokens</sample>
    <sample id="202">Die Domains, die im Datensatz aufgenommen wurden, sind Musik, Bücher und Rezepte.</sample>
    <sample id="203">Positionalität bezieht sich auf die Perspektiven, die Menschen aus ihren sozialen, kulturellen und persönlichen Kontexten heraus entwickeln. Diese Perspektiven werden als Ergebnis ihrer Demografie, Identität und Lebenserfahrungen definiert. Als Forscher beeinflusst Positionalität den Forschungsprozess und dessen Ergebnisse.</sample>
    <sample id="204">Der Referent ist Xiaoyu Shen.</sample>
    <sample id="205">Ja, EDAtt passt zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="206">Es sind vier Autoren an der Arbeit beteiligt: Yusen Zhang, Jun Wang, Zhiguo Wang und Rui Zhang.</sample>
    <sample id="207">Ja, das Modell funktioniert in der Testsuite.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind:

a) Background-Pretrain: Typischer Setup
b) Background-Both: Explizit bereitstellen von Hintergrundwissen im Kontext
c) Background-Inference: Wissen nur verfügbar während der Inferenzzeit</sample>
    <sample id="209">Die Autoren gehören der Google Research zu.</sample>
    <sample id="210">Die abschließende Forschungsfrage lautet:

"RQ3: How to use the available clean samples more efficiently?"</sample>
    <sample id="211">Die Sensitivitätsmetrik misst, wie sensibel ein Modell ist gegenüber verschiedenen Anweisungen für dieselbe Aufgabe, unabhängig von leichten Variationen im Sprachdurchbruch der Anweisungen.</sample>
    <sample id="212">Der Referent*in ist Wenjun Peng.</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet, dass das Modell schlechtere Leistung hat.</sample>
    <sample id="214">Der englische Text gibt keine spezifischen Informationen über den linguistischen Kontext, der während des Pre-Trainings erhalten wird. Es wird lediglich erwähnt, dass die Akzeptabilitätsschätzungen von Sprachmodellen nicht immer robust gegenüber Kontext sind.</sample>
    <sample id="215">Basierend auf dem Diagramm in der Abbildung scheint eine Anzahl von 50 sauberen Validierungsbeispielen für eine gute Leistung an der WSL erforderlich zu sein.</sample>
    <sample id="216">Die Autoren gehören der Stanford University an.</sample>
    <sample id="217">Die Entwicklung neuer Methoden zur Messung von Medienverzerrungen ist notwendig, um eine genauere und objektivere Bewertung der politischen Ausrichtung von Sprachmodellen zu ermöglichen. Dies hilft dabei, die Vielfalt und Komplexität der politischen Meinungen in den Modellen zu erfassen und zu analysieren, was wiederum zu einer besseren Transparenz und Kontrolle über die Auswirkungen der Modelle auf die öffentliche Meinung beiträgt.</sample>
    <sample id="218">Die Referentin ist Akshatha Arodi.</sample>
    <sample id="219">Die Pipeline für die Verbreitung politischer Vorurteile besteht aus drei Schritten: Prätraining, Sprachmodelle und Downstream-Aufgaben.</sample>
    <sample id="220">Ja, es gibt Unterschiede im Vereinfachungsprozess zwischen DEplain-apa und DEplain-web.</sample>
    <sample id="221">Der Videoinhalt gibt keine spezifischen Informationen darüber, ob Coscript öffentlich verfügbar ist.</sample>
    <sample id="222">Das Wasserzeichen wird durch die Definition eines Ziel-Einbettungsvektors \( e_t \), die Zählung des Trigger-Numbers in einem Satz und die Addition des Ziel-Einbettungsvektors auf den ursprünglichen Einbettungsvektor \( e_o \) eingebettet.</sample>
    <sample id="223">Die Autoren gehören der Pennsylvania State University (PennState) an.</sample>
    <sample id="224">Ja, Encoder-Decoder-Modelle wie mt5 können durch Training in einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="225">Ein Beispiel für eingeschränkte Sprachplanung ist die Frage "How to Make a Strawberry Cake?" mit der Antwort "...Add strawberry jams into the flour...".</sample>
    <sample id="226">Die Opazität der Methode wird durch die Visualisierung der Embedding-Daten sichergestellt, die in den Diagrammen (a) bis (d) dargestellt sind.</sample>
    <sample id="227">Die Arbeit nutzt bestehende PLMs (Pre-trained Language Models) durch "continual pre-training" zu einem neuen PLM aufzubauen.</sample>
    <sample id="228">African Islamic</sample>
    <sample id="229">"I am a student."</sample>
    <sample id="230">Die Anzahl der Aufgaben hat einen positiven Einfluss auf die Leistung des Modells, wie durch die Grafik in der Präsentation gezeigt wird.</sample>
    <sample id="231">Die drei baumlosen Baselines, mit denen die Autoren ihre Methode vergleichen, sind:

1. LSTM seq2seq
2. T5
3. Zheng and Lapata</sample>
    <sample id="232">Die beiden Co-Autoren, Alexander Koller und Ivan Titov, stehen zum ersten Autor, Matthias Lindemann, in einer Beziehung als Mitautor.</sample>
    <sample id="233">Der erste Autor von PaLM ist Chowdery et al.</sample>
    <sample id="234">Der englische Text lautet:

"NLPositionality:
Characterizing Design Biases of Datasets and Models"

Die Übersetzung ins Deutsche ist:

"NLPositionality:
Charakterisierung von Entwurfsbiasten von Datensätzen und Modellen"</sample>
    <sample id="235">Der englische Text lautet:

"NLPositionality:
Charakterisierung von Entwurfsbiasten von Datensätzen und Modellen"

Die Übersetzung ins Deutsche ist:

"NLPositionality:
Charakterisierung von Entwurfsbiasten von Datensätzen und Modellen"</sample>
    <sample id="236">Den englischen Text "Imagine..." übersetzt man auf Deutsch als "Denke...".</sample>
    <sample id="237">Den englischen Text übersetzt auf Deutsch:

"Denke... "
Carl Jones, Technischer Leiter, New York Times
PerspectiveAPI-Score: (0.82)</sample>
    <sample id="238">Denken Sie daran...

Carl Jones
Tech Lead, New York Times

Kannst du aufhören, ein Arschloch zu sein? (0.82) ✅

Aditya Sharma
Tech Lead, Times of India

Presstitutes überall in der Nachrichtenbranche. (0.33) ❌</sample>
    <sample id="239">Denken Sie daran...

Beispiel für Design-Bias!

Können Sie aufhören, ein Arschloch zu sein? 🚫: (0.82) ✅

Presstitutes überall in der Nachrichtenwelt. 🚫: (0.33) ❌

Carl Jones
Tech Lead,
New York Times

Aditya Sharma
Tech Lead,
Times of India

= PerspectiveAPI-Score</sample>
    <sample id="240">Positionalität

"Die Perspektiven [der Menschen] sind das Ergebnis ihrer Demografie, Identität und Lebenserfahrungen."</sample>
    <sample id="241">Positionalität

"Die Perspektiven, die Menschen haben, als Ergebnis ihrer Demografie, Identität und Lebenserfahrungen."</sample>
    <sample id="242">Positionalität

"Die Perspektiven [Leute] haben als Ergebnis ihrer Demografie, Identität und Lebenserfahrungen."

[Als Forscher/in,] es beeinflusst den Forschungsprozess und seine Ergebnisse und Resultate." [1]

[1] Savin-Baden, Maggi, und Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="243">Der englische Text lautet:

"Have datasets and models positionality?"

Die Übersetzung ins Deutsche ist:

"Haben Datensätze und Modelle Positionalität?"</sample>
    <sample id="244">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Die zitierten Arbeiten sind:

[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.

[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen prätrainierten Sprachmodellen." EMNLP 2022.

[3] Cambo &amp; Gergle. "Modell-Positionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="245">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Anschauliche Beweise:
- Modell- und Datensatzprobing [1][2]
- Theoretische Definitionen der Modellpositionalität [3]

Literaturhinweise:
[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen vortrainierten Sprachmodellen." EMNLP 2022.
[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="246">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Anschauliche Beweise:
- Modell- und Datensatz-Probing [1][2]
- Theoretische Definitionen der Positionalität des Modells [3]

[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen prätrainierten Sprachmodellen." EMNLP 2022.
[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="247">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Anschauliche Beweise:
- Modell- und Datensatz-Probing [1][2]
- Theoretische Definitionen der Positionalität des Modells [3]

[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen prätrainierten Sprachmodellen." EMNLP 2022.
[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="248">Die Frage lautet: "Haben Datensätze und Modelle Positionalität?"

Anschauliche Beweise:
- Modell- und Datensatz-Probing [1][2]
- Theoretische Definitionen der Positionalität des Modells [3]

[1] Blasi, et al. "Systematische Ungleichheiten in der Leistung von Sprachtechnologien weltweit." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverses Commonsense Probing auf multilingualen prätrainierten Sprachmodellen." EMNLP 2022.
[3] Cambo &amp; Gergle. "Modellpositionalität und computergestützte Reflexivität: Förderung der Reflexivität in der Datenwissenschaft." CHI 2022.</sample>
    <sample id="249">Frage:
Haben Datensätze und Modelle Positionalität?

Ziel: Vergleiche Anmerkungen von Benutzern mit bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">Der englische Text lautet: "NLPositionality - Ein Framework zur Charakterisierung von Entwurfsschulden in NLP-Daten und Modellen."</sample>
    <sample id="251">Der englische Text lautet:

"Framework

Collection
1. 300 Instanzen werden aus einem Datensatz gezogen.
2. Jede Instanz hat eine goldene Etikettierung.
3. Die Instanzen werden als Teil einer Studie an das Lab in the Wild gesendet.
4. Anmerkungen von Menschen aus aller Welt.

Processing
Modellvorhersagen

Analysis
Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie separat gemessen."

Übersetzt ins Deutsche:

"Framework

Erhebung
1. 300 Instanzen werden aus einem Datensatz gezogen.
2. Jede Instanz hat eine goldene Etikettierung.
3. Die Instanzen werden als Teil einer Studie an das Lab in the Wild gesendet.
4. Anmerkungen von Menschen aus aller Welt.

Verarbeitung
Modellvorhersagen

Analyse
Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie separat gemessen."</sample>
    <sample id="252">Der englische Text lautet:

"Framework

Collection
1) 300 Instanzen werden aus einem Datensatz gezogen.
2) Jede Instanz hat eine goldene Etikettierung.
3) Die Instanzen werden als Teil einer Studie an das Lab in the Wild gesendet.
4) Anmerkungen von Menschen aus der ganzen Welt.

Processing
Modellvorhersagen

Analysis
Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie getrennt gemessen."

Übersetzt ins Deutsche:

"Framework

Sammlung
1) 300 Instanzen werden aus einem Datensatz gezogen.
2) Jede Instanz hat eine goldene Etikettierung.
3) Die Instanzen werden als Teil einer Studie an das Lab in the Wild gesendet.
4) Anmerkungen von Menschen aus der ganzen Welt.

Verarbeitung
Modellvorhersagen

Analyse
Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie getrennt gemessen."</sample>
    <sample id="253">### Rahmenwerk

#### Sammlung
1) 300 Instanzen werden aus einem Datensatz gezogen.
2) Jede Instanz hat eine goldene Etikettierung.
3) Die Instanzen werden als Teil einer Studie an das "Lab in the Wild" gesendet.
4) Anmerkungen von Menschen aus aller Welt.

#### Verarbeitung
5) Die erhaltenen Anmerkungen werden gegen die goldenen Etiketten des Datensatzes und die vorhergesagten Modelle verglichen.

#### Analyse
6) Der Pearson's r-Korrelationskoeffizient wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie separat berechnet.

1) Re-annotate datasets with diverse annotators.</sample>
    <sample id="254">Der englische Text lautet:

"Framework

Collection
1) 300 Instanzen werden aus einem Datensatz gezogen.
2) Jede Instanz hat eine goldene Etikettierung.
3) Die Instanzen werden als Teil einer Studie an LITW gesendet.
4) Anmerkungen von Menschen aus aller Welt.

Processing
Modellvorhersagen

Analysis
Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie separat gemessen."

Übersetzt ins Deutsche:

"Framework

Erhebung
1) 300 Instanzen werden aus einem Datensatz gezogen.
2) Jede Instanz hat eine goldene Etikettierung.
3) Die Instanzen werden als Teil einer Studie an LITW gesendet.
4) Anmerkungen von Menschen aus aller Welt.

Verarbeitung
Modellvorhersagen

Analyse
Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie separat gemessen."</sample>
    <sample id="255">**Framework**

### Sammlung

1. 300 Instanzen werden aus einem Datensatz gezogen.
2. Jede Instanz hat eine goldene Etikettierung.
3. Die Instanzen werden als Teil einer Studie an LITW gesendet.
4. Anmerkungen von Menschen aus der ganzen Welt.

### Verarbeitung

5. Die erhaltenen Anmerkungen werden gegen die goldenen Etiketten des Datensatzes und die vorhergesagten Modelle verglichen.

### Analyse

6. Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie getrennt gemessen.

2) Vergleiche Anmerkungen nach Demografie mit Modellen und Datensätzen über Pearson's R-Werte.</sample>
    <sample id="256">### Rahmenwerk

#### Sammlung
1. 300 Instanzen werden aus einem Datensatz gezogen.
2. Jede Instanz hat eine goldene Etikettierung.
3. Die Instanzen werden als Teil einer Studie an LITW gesendet.
4. Anmerkungen von Menschen aus aller Welt.

#### Verarbeitung
5. Die erhaltenen Anmerkungen werden gegen die goldenen Etiketten des Datensatzes und die Vorhersagen der Modelle verglichen.

#### Analyse
6. Pearson's r Korrelation wird zwischen den goldenen Etiketten, den Modellvorhersagen und den Anmerkungen für jede Demografie getrennt gemessen.

2) Vergleiche Anmerkungen nach Demografie mit Modellen und Datensätzen über Pearson's R-Werte.</sample>
    <sample id="257">Hier ist die Übersetzung des englischen Inhalts in Deutsch:

---

**Lab in the Wild**

**Unsere Experimente**
**Ergebnisse &amp; Datensätze**
**Blog**
**Für Forscher**
**Über uns**
**Englisch**

**5,376,396**
**gesamte Teilnehmer**

**Könnten Sie mit einem AI und seinen Moralvorstellungen leben?**
Erzählen Sie uns Ihre moralischen Urteile zu bestimmten Situationen und wir werden Ihnen zeigen, wie Sie sich gegenüber anderen und einer AI vergleichen.

**Bist du besser als eine AI bei der Erkennung von hässlicher Sprache?**
Beurteilen Sie, ob etwas als hässlich gilt und wir werden Ihnen zeigen, wie gut Sie hässliche Sprache erkennen können im Vergleich zu einer AI und anderen.

**Wo stehen Sie auf der Skala zwischen Technoskeptiker und Techno-Utopian?**
Erzählen Sie uns, wie Sie den Einfluss zukünftiger Mixed-Reality-Technologien auf Ihr persönliches Leben sehen, und wir werden Ihnen zeigen, ob Sie eher technoskeptisch oder technoutopisch sind.

**Teilnehmen Sie jetzt!**
**Teilnehmen Sie jetzt!**
**Teilnehmen Sie jetzt!**

---

Der Text beschreibt verschiedene Experimente, die Teilnehmer einladen, um ihre Meinungen zu verschiedenen Themen zu teilen und zu vergleichen.</sample>
    <sample id="258">Der englische Text lautet:

"Could you live with an AI and its morals?
Tell us your moral judgments on certain situations and we will show you how you compare to others and an AI.

Are you better than an AI in noticing hateful speech?
Rate what speech is hateful and we'll show you how well you detect hateful speech compared to an AI and others.

Where are you on the techno-skeptic to techno-utopian scale?
Tell us how you think future mixed reality technology will affect your personal life, we will show you whether you are more techno-skeptical or techno-utopian."

Übersetzt auf Deutsch:

"Könnten Sie mit einem AI und seinen Moralvorstellungen leben?
Erzählen Sie uns Ihre moralischen Urteile zu bestimmten Situationen und wir werden Ihnen zeigen, wie Sie sich gegenüber anderen und einem AI vergleichen.

Sind Sie besser als ein AI bei der Erkennung von hässlicher Sprache?
Beurteilen Sie, was als hässliche Sprache gilt, und wir werden Ihnen zeigen, wie gut Sie hässliche Sprache erkennen können im Vergleich zu einem AI und anderen.

Wo stehen Sie auf der Skala von Technoskeptiker bis Techno-Utopist?
Erzählen Sie uns, wie Sie denken, wie zukünftige gemischte Realitätstechnologie Ihr persönliches Leben beeinflussen wird, wir werden Ihnen zeigen, ob Sie eher technoskeptisch oder technoutopistisch sind."</sample>
    <sample id="259">Aufgabe A: Soziale Akzeptanz

1) Lese die Situation.
2) Trage deine Meinung dazu ein.
3) Sehe, was ein AI und andere darüber denken!

Die Teilnehmer lesen eine Situation aus dem Social Chemistry-Datensatz.
Die Teilnehmer bewerten, wie akzeptabel die Situation ist.
Die Teilnehmer vergleichen ihre Antworten mit denen anderer und des AI.</sample>
    <sample id="260">Aufgabe A: Soziale Akzeptanz

1) Lese die Situation.
2) Gib deine Meinung dazu an.
3) Sehe, was ein AI und andere darüber denken.

Die AI spekuliert:
"Ich denke, es ist verständlich. Vielleicht bin ich hier falsch."

Studienteilnehmer in den USA sagten:

- Sehr schlecht: 50%
- Schlecht: 40%
- Erwartet/Akzeptabel: 10%
- Gut: 50%
- Sehr gut: 40%

Teilnehmer vergleichen ihre Antworten mit denen anderer und des AI.</sample>
    <sample id="261">Aufgabe A: Soziale Akzeptanz

Analyse
Datenbanken
- Soziale Chemie

Modelle
- Delphi
- GPT-4</sample>
    <sample id="262">Aufgabe B: Toxicity

1) Lese das Beispiel.
7 / 25

Englische Menschen riechen nach Sauermilch.

2) Trage deine Meinung dazu ein.
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *</sample>
    <sample id="263">### Aufgabe B: Toxicity

**Analyse**

**Datenquellen**
- Dynahate

**Modelle**
- Perspective API
- Rewire API
- Hate RoBERTa
- GPT-4

### Studienteilnahme

16,299 Anmerkungen
1,096 Annotatoren
87 Länder</sample>
    <sample id="264">Die Übersetzung des englischen Inhalts lautet:

Ergebnisse:
Wer stimmen NLP-Daten und Modelle?

Erkenntnis 1:
Es gibt Positionalität in der NLP.</sample>
    <sample id="265">Die Daten und Modelle sind am meisten mit englischsprachigen Ländern ausgerichtet.</sample>
    <sample id="266">Die Datenbanken und Modelle sind am meisten mit Menschen mit einem College-Abschluss ausgerichtet.</sample>
    <sample id="267">Die Daten und Modelle sind am meisten mit Menschen mit einem College-Abschluss ausgerichtet.</sample>
    <sample id="268">Die englischen Inhalte lauten: "Finding 2: Some populations are left behind."

Übersetzt auf Deutsch bedeutet das: "Erkenntnis 2: Einige Populationen werden zurückgelassen."</sample>
    <sample id="269">Die Datenbanken und Modelle sind weniger mit nicht-binären Menschen ausgerichtet.

Soziale Akzeptanz (GPT-4)

Datenbanken und Modelle sind weniger mit nicht-binären Menschen ausgerichtet.

Hassrede und Toxizität (Dynahate)

Datenbanken und Modelle sind weniger mit nicht-binären Menschen ausgerichtet.</sample>
    <sample id="270">Der englische Text lautet: "So, what can we do? Addressing positionality in NLP"

Die deutsche Übersetzung ist: "Also, was können wir tun? Positionalität in der NLP adressieren"</sample>
    <sample id="271">Empfehlungen

1. Halte eine Liste aller relevanten Designentscheidungen während des Datensatzes oder Modellbaus.

2. Führe NLP-Forschung aus unter Berücksichtigung der Perspektivität:
a. Teile die aufgeteilten Datensatzetiketten!
b. Verwende Modellierungstechniken, die mit Annotator-Disagreement umgehen können.</sample>
    <sample id="272">Empfehlungen

1. Halte einen Protokoll aller relevanten Designentscheidungen, die während der Erstellung von Datensätzen oder Modellen getroffen wurden.
2. Führe NLP-Forschung aus durch die Perspektivismus-Linse:
   a. Teile aufgeteilte Datensatzetiketten!
   b. Verwende Modellierungstechniken, die mit Annotator-Disagreement umgehen können.
3. Die Erstellung spezialisierter Datensätze und Modelle für und mit spezifischen Gemeinschaften ist wertvoll für inklusive NLP (z.B., Masakhane-Initiative¹).

[1] https://www.masakhane.io</sample>
    <sample id="273">Danke!

Dashboard-Link: nlpositionality.cs.washington.edu/
Papier: bit.ly/NLPositionality-Paper/

Delphi
(https://delphi.allenai.org)</sample>
    <sample id="274">Die Referentin geht auf drei Probleme von SimulST ein.</sample>
    <sample id="275">Die Reduzierung von sozialen und politischen Verzerrungen in Datensätzen beim Training von NLP-Modellen kann durch die Sanierung der Daten erreicht werden, was bedeutet, dass potenziell problematische oder ungenaue Informationen entfernt oder korrigiert werden.</sample>
    <sample id="276">Der englische Text lautet:

"The 61st Annual Meeting of the Association for Computational Linguistics
Toronto, Canada
July 9-14, 2023

Distilling Script Knowledge from Large Language Models for Constrained Language Planning

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah,
Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

FUDAN UNIVERSITY
Brain Technologies Inc."

Übersetzt bedeutet das:

"61. Jahrestagung der Association for Computational Linguistics
Toronto, Kanada
9. bis 14. Juli 2023

Entsperren von Skriptwissen aus großen Sprachmodellen für eingeschränktes Sprachplanung

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah,
Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

Fudan University
Brain Technologies Inc."</sample>
    <sample id="277">Der englische Text lautet:

"Language Planning

How to Make a Cake?
1. Gather your ingredients.
2. Preheat the oven to 325 °F (163 °C) and grease and flour a cake pan.
3. Cream the butter and sugar.
4. Add the eggs.
5. Stir in the cake flour.
6. Pour the batter into the pan.
7. Bake the cake for 1 hour 15 minutes.

Large language models (LLMs)
can effectively decompose goals into steps"

Übersetzt auf Deutsch:

"Sprachplanung

Wie man ein Kuchen backt?
1. Sammle deine Zutaten.
2. Heiz den Backofen auf 325 °F (163 °C) vor und fettiere und bemehle einen Kuchenguss.
3. Butter und Zucker cremen.
4. Eier hinzufügen.
5. Mehl für den Kuchen unterrühren.
6. Teig in den Guss gießen.
7. Den Kuchen für 1 Stunde 15 Minuten backen.

Große Sprachmodelle (LLMs)
könnenziele effektiv in Schritte zerlegen."</sample>
    <sample id="278">Die englischen Inhalte lauten:

"Language Planning

How to Make a Cake?
1. Gather your ingredients.
2. Preheat the oven to 325 °F (163 °C) and grease and flour a cake pan.
3. Cream the butter and sugar.
4. Add the eggs.
5. Stir in the cake flour.
6. Pour the batter into the pan.
7. Bake the cake for 1 hour 15 minutes.

Large language models (LLMs)
can effectively decompose goals into steps"

Übersetzt auf Deutsch:

"Sprachplanung

Wie man ein Kuchen backt?
1. Sammle deine Zutaten.
2. Heiz den Backofen auf 325 °F (163 °C) vor und fettiere und bemehle einen Kuchenguss.
3. Butter und Zucker cremen.
4. Eier hinzufügen.
5. Mehl für den Kuchen unterrühren.
6. Teig in den Guss gießen.
7. Den Kuchen für 1 Stunde 15 Minuten backen.

Große Sprachmodelle (LLMs)
könnenziele effektiv in Schritte zerlegen."</sample>
    <sample id="279">Die englischen Inhalte lauten:

- "Constrained Language Planning"
- "How to Make a Strawberry Cake? ...Add strawberry jams into the flour..."
- "How to Make a Chocolate Cake? ...Add the cocoa powder into the flour..."
- "Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints"

Übersetzt auf Deutsch:

- "Geschränkte Sprachplanung"
- "Wie macht man einen Erdbeer-Kuchen? ...Füge Erdbeer-Marmelade in das Mehl hinzu..."
- "Wie macht man einen Schokoladenkuchen? ...Füge Kakao-Pulver in das Mehl hinzu..."
- "Abstrakte Ziele können von verschiedenen realen spezifischen Zielen mit vielfältigen Restriktionen geerbt werden."</sample>
    <sample id="280">Konstruierte Sprachplanung

Wie man ein Erdbeer-Kuchen macht?
...Füge Erdbeer-Jam in den Teig ...

Wie man einen Schokoladenkuchen macht?
...Füge Kakao-Pulver in den Teig ...

Abstrakte Ziele können von verschiedenen realen spezifischen Zielen mit vielfältigen Restriktionen geerbt werden.</sample>
    <sample id="281">Die englischen Inhalte lauten:

- "Constrained Language Planning"
- "How to Make a Strawberry Cake? ...Add strawberry jams into the flour..."
- "How to Make a Chocolate Cake? ...Add the cocoa powder into the flour..."
- "Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints"

Übersetzt auf Deutsch:

- "Geschränkte Sprachplanung"
- "Wie macht man einen Erdbeer-Kuchen? ...Füge Erdbeer-Marmelade in das Mehl hinzu..."
- "Wie macht man einen Schokoladenkuchen? ...Füge Kakao-Pulver in das Mehl hinzu..."
- "Abstrakte Ziele können von verschiedenen realen spezifischen Zielen mit vielfältigen Restriktionen geerbt werden."</sample>
    <sample id="282">Wie leisten sich LLMs bei eingeschränktem Sprachplanung?

Dataset: wikiHow + Generierte Restriktionen

**Restriktionsart 1: Modifikator**
Definition: Ein Wort, ein Adjektiv oder eine Phrase, die eine abstrakte Zielmodifikation oder -beschränkung vornimmt.
Beispiel 1: Machen Sie einen Schokoladenkuchen.
Beispiel 2: Machen Sie einen rosa Kuchen.

**Restriktionsart 2: Methode**
Definition: Ein Werkzeug oder eine spezifizierte Modus, der den Prozess steuert, um das Ziel zu erreichen.
Beispiel 1: Machen Sie einen Kuchen mit einem Ofen.
Beispiel 2: Machen Sie einen Kuchen mit einem Backmischungsmittel.

**Restriktionsart 3: Absicht**
Definition: Eine zusätzliche Absicht oder Anforderung beim Erreichen des Ziels.
Beispiel 1: Machen Sie einen Kuchen für Hochzeit.
Beispiel 2: Machen Sie einen Kuchen für Diabetiker.</sample>
    <sample id="283">Wie performieren LLMs bei eingeschränktem Sprachplanung?

Dataset: wikiHow + Generierte Restriktionen

**Restriktionsart 1: Modifikator**

Definition: Ein Wort, ein Adjektiv oder eine Phrase, die eine abstrakte Zielmodifikation oder -beschränkung vornimmt.

Beispiel 1: Machen Sie einen Schokoladenkuchen.
Beispiel 2: Machen Sie einen rosa Kuchen.

**Restriktionsart 2: Methode**

Definition: Ein Werkzeug oder eine spezifizierte Modus, der den Prozess steuert, um das Ziel zu erreichen.

Beispiel 1: Machen Sie einen Kuchen mit einem Ofen.
Beispiel 2: Machen Sie einen Kuchen mit einem Backmischungsmittel.

**Restriktionsart 3: Absicht**

Definition: Eine zusätzliche Absicht oder Anforderung beim Erreichen des Ziels.

Beispiel 1: Machen Sie einen Kuchen für Hochzeit.
Beispiel 2: Machen Sie einen Kuchen für Diabetiker.</sample>
    <sample id="284">Wie leisten sich LLMs bei eingeschränktem Sprachplanung?

Dataset: wikiHow + Generierte Restriktionen

**Restriktionsart 1: Modifikator**
Definition: Ein Wort, ein Adjektiv oder eine Phrase, die eine abstrakte Zielmodifikation oder -beschränkung vornimmt.
Beispiel 1: Machen Sie einen Schokoladenkuchen.
Beispiel 2: Machen Sie einen rosa Kuchen.

**Restriktionsart 2: Methode**
Definition: Ein Werkzeug oder eine spezifische Art, die den Prozess steuert, um das Ziel zu erreichen.
Beispiel 1: Backen Sie einen Kuchen mit einem Ofen.
Beispiel 2: Backen Sie einen Kuchen mit einem Kuchenteig.

**Restriktionsart 3: Absicht**
Definition: Eine zusätzliche Absicht oder Anforderung beim Erreichen des Ziels.
Beispiel 1: Backen Sie einen Kuchen für Hochzeit.
Beispiel 2: Backen Sie einen Kuchen für Diabetiker.</sample>
    <sample id="285">Können LLMs beschränktes Sprachplanung machen?

Alle Baselines erzielen unzureichende Ergebnisse bei der Planung für spezifische Ziele.</sample>
    <sample id="286">Können LLMs beschränktes Sprachplanung machen?

Alle Baselines erzielen unzureichende Ergebnisse bei der Planung für spezifische Ziele.</sample>
    <sample id="287">Was für Arten von Fehlern machen LLMs in dieser Aufgabe normalerweise?

Die semantische Vollständigkeit (SE) in generierten Skripten ist akzeptabel, aber die Treue zu den Restriktionen (FE) kann nicht garantiert werden.</sample>
    <sample id="288">Was für Arten von Fehlern machen LLMs in dieser Aufgabe normalerweise?

Die semantische Vollständigkeit (SE) in generierten Skripten ist akzeptabel, aber die Treue zu den Restriktionen (FE) kann nicht garantiert werden.

Das Planungsleistung von InstructGPT variiert beträchtlich je nach verschiedenen Kategorien.</sample>
    <sample id="289">Die Frage lautet: "Welche Arten von Zielen scheitern InstructGPTs typischerweise?"

Die Tabelle zeigt die Planungsleistung von InstructGPTs für verschiedene Kategorien von Zielen:

- Arbeit: 0.0
- Sport: 0.67
- Beziehungen: 1.0
- Persönliche Pflege: 0.5
- Heim: 0.3
- Traditionen: 0.4
- Hobbys: 0.6
- Gesundheit: 0.57
- Lebensmittel: 0.78
- Geschäft: 0.67
- Familie: 0.0
- Bildung: 0.5
- Elektronik: 0.62
- Fahrzeuge: 0.5
- Kunst: 0.5

Unter dem Titel steht: "Die Planungsleistung von InstructGPTs variiert erheblich für Ziele unterschiedlicher Kategorien."</sample>
    <sample id="290">Der englische Text lautet:

"Input: an abstract goal
Step 1: Generate specific goals with InstructGPT via in-context learning
Abstract Goal: Make a cake
Specific Goals:
G1 (+modifier): Make a chocolate cake
G2 (+method): Make a cake in a microwave
G3 (+intent): Make a cake for a wedding"

Übersetzt auf Deutsch:

"Eingabe: ein abstraktes Ziel
Schritt 1: Generiere spezifische Ziele mit InstructGPT durch Kontext-Lernen
Abstraktes Ziel: Backen eines Kuchens
Spezifische Ziele:
G1 (+Modifikator): Backen eines Schokoladenkuchens
G2 (+Methode): Backen eines Kuchens im Mikrowellenherd
G3 (+Absicht): Backen eines Kuchens für eine Hochzeit"</sample>
    <sample id="291">Der englische Text lautet:

"Input: ein abstraktes Ziel
Schritt 1: spezifische Ziele generieren mit InstructGPT via in-context Learning

Abstraktes Ziel: Backen eines Kuchens
Spezifische Ziele:
G1 (+Modifikator): Backen eines Schokoladenkuchens
G2 (+Methode): Backen eines Kuchens im Mikrowellenherd
G3 (+Absicht): Backen eines Kuchens für eine Hochzeit"

Übersetzt ins Deutsche:

"Eingabe: ein abstraktes Ziel
Schritt 1: spezifische Ziele generieren mit InstructGPT via in-context Learning

Abstraktes Ziel: Backen eines Kuchens
Spezifische Ziele:
G1 (+Modifikator): Backen eines Schokoladenkuchens
G2 (+Methode): Backen eines Kuchens im Mikrowellenherd
G3 (+Absicht): Backen eines Kuchens für eine Hochzeit"</sample>
    <sample id="292">Input: ein abstraktes Ziel

Schritt 1: Generiere spezifische Ziele mit InstructGPT durch in-context Learning

Schritt 2: Erstelle übermäßige Kandidaten-Skripte mit InstructGPT durch in-context Learning

Abstraktes Ziel: Backen eines Kuchens

Spezifische Ziele:
G1 (+ Modifikator): Backen eines Schokoladenkuchens
G2 (+ Methode): Backen eines Kuchens im Mikrowellenherd
G3 (+ Absicht): Backen eines Kuchens für eine Hochzeit

Generiere Pläne für G1

Kandidaten-Skripte
1, 2, 3, ..., k</sample>
    <sample id="293">Method

Schritt 2: Erzeugen von Kandidatenskripten mit InstructGPT durch In-Context-Learning
Schritt 3: Finden von gefilterten Skripten zum Ziel mit InstructGPT über Ähnlichkeitsbewertung
Ausgabe: Spezifische Ziele mit entsprechenden Skripten</sample>
    <sample id="294">Method

Schritt 2: Erzeugen von Kandidatenskripten mit InstructGPT durch In-Context-Learning
Schritt 3: Finden von gefilterten Skripten zum Ziel mit InstructGPT über Ähnlichkeitsbewertung
Ausgabe: Spezifische Ziele mit entsprechenden Skripten</sample>
    <sample id="295">Method

Schritt 2: Erzeugen von Kandidatenskripten mit InstructGPT durch In-Context-Learning
Schritt 3: Finden von gefilterten Skripten zum Ziel mit InstructGPT über Ähnlichkeitsbewertung
Ausgabe: Spezifische Ziele mit entsprechenden Skripten</sample>
    <sample id="296">Unser Verfahren verbessert die Planungsqualität erheblich.

Mit unserem Verfahren kann InstructGPT Skripte von höherer Qualität generieren, und zwar deutlich.</sample>
    <sample id="297">### Übersetzung des englischen Inhalts in Deutsch

**Motivation:**
- Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen.

**Methode:**
- Folgt dem Prinzip der symbolischen Wissensverdichtung.
- Generiert 55.000 Skripte mit Restriktionen von LLMs auf Basis unseres Verfahrens =&gt; Coscript-Datensatz.
- Menschen annotieren die Validierung und Testdatensätze.</sample>
    <sample id="298">### Übersetzung des englischen Inhalts in Deutsch

**Motivation:**
- Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu aktivieren.

**Methode:**
- Folgt dem Prinzip der symbolischen Wissensverdichtung.
- Generiert 55.000 Skripte mit Restriktionen von LLMs auf Basis unseres Verfahrens =&gt; Coscript-Datensatz.
- Menschen annotieren die Validierung und Testdatensätze.</sample>
    <sample id="299">### Übersetzung des englischen Inhalts in Deutsch

**Motivation:**
- Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen.

**Methode:**
- Folgt dem Prinzip der symbolischen Wissensverdichtung.
- Generiert 55.000 Skripte mit Restriktionen von LLMs aufgrund unserer Methode =&gt; Coscript-Datensatz.
- Menschen annotieren die Validierung und Testdatensätze.</sample>
    <sample id="300">### Übersetzung des englischen Inhalts in Deutsch

**Motivation:**
- Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu aktivieren.

**Methode:**
- Folgt dem Prinzip der symbolischen Wissensverdichtung.
- Generiert 55.000 Skripte mit Restriktionen von LLMs auf Basis unserer Methode =&gt; Coscript-Datensatz.
- Menschen annotieren die Validierung und Testdatensätze.</sample>
    <sample id="301">### Übersetzung des englischen Inhalts in Deutsch

**Motivation:**
- Um die konstruierte Sprachplanungsfähigkeit für kleinere Modelle zu ermöglichen.

**Methode:**
- Folgt dem Prinzip der symbolischen Wissensverdichtung.
- Generiert 55.000 Skripte mit Restriktionen von LLMs basierend auf unserem Verfahren =&gt; Coscript-Datensatz.
- Menschen annotieren die Validierung und Testdatensätze.</sample>
    <sample id="302">### Constraint Analysis

Coscript zeigt hohe Heterogenität und Pluralität in den generierten spezifischen Zielen.

### Coscript für kleinere Sprachmodelle

- **Datenquellen**
  - Coscript
  - wikiHow

- **Metriken**
  - Treue: DeBERTa (v3 large) Modell, um festzustellen, ob die generierten Texte den Restriktionen treu sind
  - Automatische Metriken: ROUGE, BLEU, BERTScore</sample>
    <sample id="303">### Spezialisierte Modelle vs. LLMs

- Stellen Sie das konstruierte Sprachplanungsproblem ein.
- Evaluieren Sie die konstruierte Sprachplanungsfähigkeit von LLMs und entwickeln Sie eine Methode zur Überkorrektur für LLMs.
- Verwenden Sie LLMs, um ein hochwertiges Skript (CoScript) für konstruierte Sprachplanung zu generieren.

### Limitationen und zukünftige Arbeit
- Die vorgeschlagene Methode zur Verbesserung von LLMs ist ein post-hoc Re-Ranking-Ansatz.
- Kleine LLMs, die auf CoScript abgestimmt wurden, können höhere Qualitätsskripte als LLMs generieren.
- Der CoScript-Datensatz kann ein wertvolles Ressourcenmaterial sein, um die Forschung auf dem Gebiet der Sprachplanung mit komplexeren und vielfältigeren Zielen und Einschränkungen voranzutreiben.</sample>
    <sample id="304">Zusammenfassung und Schlüsselpunkte

- Stellen Sie das Problem der eingeschränkten Sprachplanung ein.
- Evaluieren Sie die Fähigkeit von LLMs zur eingeschränkten Sprachplanung und entwickeln Sie eine Methode "über-generieren-dann-filtern" für LLMs.
- Verwenden Sie LLMs, um ein hochwertiges Skript-Datensatz (CoScript) für die eingeschränkte Sprachplanung zu generieren.
- Limitierungen und zukünftige Arbeiten
  - Die vorgeschlagene Methode zur Verbesserung von LLMs ist ein post-hoc Re-Ranking-Ansatz.
  - CoScript erbt nur von einem abstrakten mit einer zusätzlichen Einschränkung.
  - Der CoScript-Datensatz kann ein wertvolles Ressourcenmaterial sein, um die Forschung auf dem Gebiet der Sprachplanung mit komplexeren und vielfältigeren Zielen und Einschränkungen voranzutreiben.</sample>
    <sample id="305">### Zusammenfassung und Schlüsselpunkte

- Stellen Sie das Problem der eingeschränkten Sprachplanung ein.
- Evaluieren Sie die Fähigkeit von LLMs zur eingeschränkten Sprachplanung und entwickeln Sie eine Methode, die "über-generieren-dann-filtern" für LLMs.
- Verwenden Sie LLMs, um eine hochwertige Skriptdatensatz (CoScript) für eingeschränkte Sprachplanung zu generieren.
- Limitierungen und zukünftige Arbeiten
  - Die vorgeschlagene Methode zur Verbesserung von LLMs ist ein post-hoc Re-Ranking Ansatz.
  - CoScript erbt nur von einem abstrakten mit einer zusätzlichen Einschränkung.
  - Der CoScript-Datensatz kann ein wertvolles Ressourcenmaterial sein, um die Forschung auf dem Gebiet der Sprachplanung mit komplexeren und vielfältigeren Zielen und Einschränkungen voranzutreiben.</sample>
    <sample id="306">Der englische Text lautet:

"The 61st Annual Meeting of the Association for Computational Linguistics
Toronto, Canada
July 9-14, 2023

Distilling Script Knowledge from Large Language Models for Constrained Language Planning

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

syyuan21@m.fudan.edu.cn
https://github.com/siyuyuan/coscript"

Übersetzt auf Deutsch:

"61. Jahrestagung der Association for Computational Linguistics
Toronto, Kanada
9. bis 14. Juli 2023

Zurückgewinnung von Skriptwissen aus großen Sprachmodellen für eingeschränktes Sprachplanung

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

syyuan21@m.fudan.edu.cn
https://github.com/siyuyuan/coscript"</sample>
    <sample id="307">Die Sprachgewandtheit von PaLM ist vergleichbar mit der von SOTA-Systemen.</sample>
    <sample id="308">Die wichtigsten Eigenschaften eines Wasserzeichenverfahrens sind:

1. Anwendbarkeit für EaaS (Embedded AI as a Service)
2. Nutzen: Das Wasserzeichen sollte die Nutzbarkeit der bereitgestellten Embeddings nicht vermindern.
3. Geheimhaltung: Es sollte geheim bleiben, dass es sich um ein Wasserzeichen handelt.
4. Übertragbarkeit: Das Wasserzeichen muss übertragbar sein zu den Angreiferdiensten.</sample>
    <sample id="309">Die englischen TED Talks wurden in 14 Sprachen übersetzt, darunter Englisch, Arabisch, Deutsch, Spanisch, Französisch, Hebräisch, Italienisch, Japanisch, Koreanisch, Niederländisch, Portugiesisch, Rumänisch, Russisch, Türkisch und Chinesisch.</sample>
    <sample id="310">300 Instanzen werden aus einem Datensatz für die erneute Annotierung extrahiert.</sample>
    <sample id="311">Die Distanzmetriken, die verwendet werden, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen, sind die Cosinus-Distanz (cos) und die L2-Distanz (l2).</sample>
    <sample id="312">Die Modelle, die auf einem mehrsprachigen Encoder basieren, wurden in dieser Aufgabe als Enc-Ptr und Enc-Dec bezeichnet. Enc-Ptr verwendet Pointer-based Decoders, während Enc-Dec Multilingual Pretrained Encoder-Decoder Models wie mBART und mT5 einsetzt.</sample>
    <sample id="344">Die Autoren zählen die Wortfrequenz in einem allgemeinen Textkorpus \( D_p \) und wählen dann n Wörter aus einer mittelfrequenten Intervall.</sample>
    <sample id="345">Der englische Text lautet:

"Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?"

Übersetzt auf Deutsch bedeutet das:

"Sind CoNLL-2003-Named-Entity-Tagger noch immer in Ordnung im Jahr 2023?"</sample>
    <sample id="346">Der englische Text lautet "Named Entity Recognition &amp; Generalization" und übersetzt sich auf Deutsch zu "Namenloser Entitätenerkennung &amp; Generalisierung".</sample>
    <sample id="347">Der englische Text lautet:

"Named Entity Recognition &amp; Generalization

- Modelle haben seit fast 20 Jahren CoNLL-2003 zur Entwicklung von NER verwendet

- Können diese Modelle modernes Datenmaterial generalisieren?"

Übersetzt ins Deutsche:

"Namensidentifikation &amp; Generalisierung

- Modelle haben seit fast 20 Jahren CoNLL-2003 zur Entwicklung von NAM verwendet

- Können diese Modelle modernes Datenmaterial generalisieren?"</sample>
    <sample id="348">Der englische Text lautet:

"Named Entity Recognition &amp; Generalization

- Modelle haben seit fast 20 Jahren CoNLL-2003 zur Entwicklung von NER verwendet.
- Können diese Modelle modernen Daten generalisieren?
- Was ist notwendig für eine gute Generalisierung?"</sample>
    <sample id="349">Der englische Text lautet:

"Named Entity Recognition &amp; Generalization

- Modelle haben seit fast 20 Jahren CoNLL-2003 zur Entwicklung von NER verwendet
- Können diese Modelle modernen Daten generalisieren?
- Was ist notwendig für eine gute Generalisierung?
- Was verursacht die Leistungseinbuße?"</sample>
    <sample id="350">CoNLL++ Dataset

- Sammlte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie mit den Anmerkungsempfehlungen von CoNLL-2003</sample>
    <sample id="351">CoNLL++ Dataset
- Sammlte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie mit den Anmerkungsempfehlungen von CoNLL-2003
- Feinabgestimmte 20+ Modelle auf CoNLL-2003
- Evaluierung auf CoNLL-2003 Testset &amp; CoNLL++

AMBISSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="352">CoNLL++ Dataset
- Sammelte Reuters-Nachrichten aus dem Jahr 2020 und annotierte sie mit den Anmerkungsempfehlungen von CoNLL-2003.
- Feinabgestimmte 20+ Modelle auf CoNLL-2003.
- Wurde auf dem CoNLL-2003 Testset &amp; CoNLL++ evaluiert.
- Berechnete prozentuale ΔF1, um die Generalisierbarkeit zu bewerten.

AMBISSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="353">Was ist für eine gute Generalisierung erforderlich?</sample>
    <sample id="354">Was ist für eine gute Generalisierung erforderlich?

- Modellarchitektur
- Transformer-Modelle generalisieren besser</sample>
    <sample id="355">Was ist für eine gute Generalisierung erforderlich?

- Modellarchitektur
  - Transformer-Modelle generalisieren besser

- Modellgröße
  - Größere Modelle generalisieren besser</sample>
    <sample id="356">Was ist für eine gute Generalisierung erforderlich?

- Modellarchitektur
  - Transformer-Modelle generalisieren besser

- Modellgröße
  - Größere Modelle generalisieren besser

- Anzahl der Feinabstimmungsbeispiele
  - Mehr Beispiele führen zu besserer Generalisierung</sample>
    <sample id="357">Was verursacht eine Leistungseinbuße?</sample>
    <sample id="358">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?</sample>
    <sample id="359">Was verursacht eine Leistungsabnahme?

- Adaptive Overfitting?
- Temporale Verschiebung?</sample>
    <sample id="360">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?
- Temporale Verschiebung?</sample>
    <sample id="361">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?
- Temporale Verschiebung?</sample>
    <sample id="362">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?
  - Keine abnehmenden Renditen
  - Nicht beobachtet
- Temporale Verschiebung?</sample>
    <sample id="363">Was verursacht eine Leistungsabnahme?

- Adaptive Überanpassung?
  - Keine abnehmenden Renditen
  - Nicht beobachtet
- Temporale Verschiebung?</sample>
    <sample id="364">Was verursacht eine Leistungsabnahme?

- Adaptive Overfitting?
  - Keine abnehmenden Renditen
  - Nicht beobachtet

- Temporale Verschiebung?
  - Leistung nimmt mit größerem zeitlichen Abstand ab</sample>
    <sample id="365">Was verursacht die Leistungsabnahme?

- Adaptive Overfitting?
  - Keine abnehmenden Renditen
  - Beobachtet nicht

- Temporale Drift?
  - Die Leistung nimmt mit größerem zeitlichen Abstand ab
  - Hauptursache für die Leistungsabnahme</sample>
    <sample id="366">Zusammenfassung

- Für eine gute Generalisierung benötigen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr Feinabstimmungsbeispiele</sample>
    <sample id="367">### Schlussfolgerung

- Für eine gute Generalisierung benötigen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr abgestimmte Beispiele
- Leistungseinbruch wird durch:
  - Temporale Verschiebung
  - Nicht durch adaptive Überanpassung verursacht</sample>
    <sample id="368">### Schlussfolgerung

- Für eine gute Generalisierung benötigen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr Feinabstimmungsbeispiele
- Leistungseinbruch wird durch:
  - Temporale Verschiebung
  - Nicht adaptives Überfitting
- Funktionieren CoNLL-2003-Tagger immer noch?

- Ja!</sample>
    <sample id="369">### Schlussfolgerung

- Für eine gute Generalisierung benötigen wir:
  - Bessere Modellarchitektur
  - Größere Modellgröße
  - Mehr abgestimmte Beispiele
- Leistungseinbruch wird durch:
  - Temporale Verschiebung
  - Nicht adaptives Überfitting
- Funktionieren CoNLL-2003-Tagger noch?
  - JA!</sample>
    <sample id="370">Hier ist der deutsche Text:

Papier: https://arxiv.org/abs/2212.09747
Datenbasis: https://github.com/ShuhengL/acl2023_conllpp
Kontakt: sliu775@gatech.edu</sample>
    <sample id="397">Der genaue Wert der Sprachsegmentgröße ist nicht im Bild angegeben. Es wird nur die Frage "What is our solution?" gezeigt, aber keine spezifischen Details zur Sprachsegmentgröße.</sample>
    <sample id="398">Das entitätsspezifische Wissen, das im Beispiel mit Servin und Kea benötigt wird, lautet: "Servin is a judge."</sample>
    <sample id="399">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="400">Die Arbeiten in den erweiterten Experimenten konzentrieren sich auf die Sprachmodelle RoBERTa und GPT-2.</sample>
    <sample id="401">The model uses attention values from a specific layer or combines values from multiple layers.</sample>
    <sample id="402">Beispiele für direkte Inferenz sind "easy on me" und "the first one".</sample>
    <sample id="403">Die Autoren gehören der Fudan University an.</sample>
    <sample id="404">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="405">Ja, die Übersetzung der natürlichsprachlichen Anfrage mit Hilfe eines maschinellen Übersetzungsmodells wurde als Baseline betrachtet.</sample>
    <sample id="406">Ein Beispiel für eine markierte Gruppe ist "a woman warrior" im Vergleich zu "a warrior".</sample>
    <sample id="407">BILSTM-CRF-ELMo</sample>
    <sample id="408">Die Testdatensätze heißen "Validation".</sample>
    <sample id="409">Sechs Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten, wie aus dem Titel "Instruction Tuning on Multimodal Pre-trained Models" hervorgeht.</sample>
    <sample id="439">Das zu wenig erforschte Gebiet im Bereich der NLU, wie es von den Autoren angenommen wird, ist das Verständnis von Kontext und Inferenz.</sample>
    <sample id="440">Die Referenten heißen Zhiyang Xu, Ying Shen und Lifu Huang.</sample>
    <sample id="441">Ja, Coscript wurde von Menschen annotiert und durchlaufen eine Validierung und Testphase.</sample>
    <sample id="442">Die Grenzen bestehender Ressourcen für kontextbasierte Übersetzung liegen in der Unterstützung begrenzter Diskursphänomene und Sprachen.</sample>
    <sample id="443">Der englische Text lautet:

"Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)"

Die Übersetzung ins Deutsche ist:

"Lösung indirekter Bezugsausdrücke für die Entitätsauswahl (AltEntities Corpus)"</sample>
    <sample id="444">Der englische Text lautet:

"Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)"

Die Übersetzung ins Deutsche ist:

"Lösung indirekter Bezugsausdrücke für die Entitätsauswahl (AltEntities Corpus)"</sample>
    <sample id="445">Indirekte Bezugserwähnungen

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  - Alternative Frage: Did you mean easy on me or I gotta feeling?
  
- Direkte Bezugserwähnung:
  - "easy on me", "the first one"

- Indirekte Bezugserwähnung kann in natürlichen und flüssigen Gesprächen verwendet werden:
  - Kann den Namen nicht mehr erinnern
  - Die Aussprachen sind schwer zu unterscheiden
  - Will eine Präferenz spezifizieren

  - Indirekte Bezugserwähnung: The newer one. The song that's not energetic.</sample>
    <sample id="446">Indirekte Bezugssätze

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  Alternative Frage → Did you mean easy on me or I gotta feeling?

- Direkte Bezug:
  - "easy on me", "the first one"

- Indirekte Bezug kann in natürlichen und flüssigen Gesprächen verwendet werden:
  - Kann den Namen nicht mehr erinnern
  - Die Aussprachen sind schwer zu unterscheiden
  - Will eine Präferenz spezifizieren

  Indirekte Bezug → The newer one. The song that's not energetic.</sample>
    <sample id="447">Indirekte Bezugssätze

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  Alternative Frage → Did you mean easy on me or I gotta feeling?

- Direkte Bezug:
  - "easy on me", "the first one"

- Indirekte Bezug kann in natürlichen und flüssigen Gesprächen verwendet werden:
  - Kann den Namen nicht mehr erinnern
  - Die Aussprachen sind schwer zu unterscheiden
  - Will eine Präferenz spezifizieren

  Indirekte Bezug → The newer one. The song that's not energetic.</sample>
    <sample id="448">Indirekte Bezugssätze

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  Alternative Frage → Did you mean easy on me or I gotta feeling?

- Direkte Bezug:
    - "easy on me", "the first one"

- Indirekte Bezug kann in natürlichen und flüssigen Gesprächen verwendet werden:
    - Kann nicht den Namen merken
    - Die Aussprachen sind schwer zu unterscheiden
    - Will eine Präferenz spezifizieren

  Indirekte Bezug → The newer one. The song that's not energetic.</sample>
    <sample id="449">Indirekte Bezugssätze

- Ziel: Verstehen der Sprache der Nutzer, wenn sie eine Wahl treffen
  Alternative Frage → Did you mean easy on me or I gotta feeling?

- Direkte Bezug:
  - "easy on me", "the first one"

- Indirekte Bezug kann in natürlichen und flüssigen Gesprächen verwendet werden:
  - Kann den Namen nicht mehr erinnern
  - Die Aussprachen sind schwer zu unterscheiden
  - Will eine Präferenz spezifizieren

  Indirekte Bezug → The newer one. The song that's not energetic.</sample>
    <sample id="450">### Dataset Collection

- **Wichtige Probleme**
  - Konversationssysteme
  - Benchmarking großer Sprachmodell-Entitätsverstehens
- **Kein großes öffentliches Datensatz verfügbar**
- **Wir sammeln einen großen Datensatz durch Crowdsourcing**
- **Drei Domänen:**</sample>
    <sample id="451">### Datensatzsammlung

- **Wichtige Probleme**
  - Konversationssysteme
  - Benchmarking großer Sprachmodellentitätenverstehens
- **Kein großes öffentliches Datensatz verfügbar**
- **Wir sammeln einen großen Datensatz mit Hilfe von Crowdsourcing**
- **Drei Bereiche:**</sample>
    <sample id="452">Der englische Text lautet:

"Dataset Collection Methodology
- Die Methode betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"

Übersetzt ins Deutsche:

"Datenbank-Sammlungs-Methode
- Die Methode betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"</sample>
    <sample id="453">Der englische Text lautet:

"Dataset Collection Methodology
- Methodologie betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"

Übersetzt ins Deutsche:

"Datenbank-Sammlungs-Methode
- Die Methode betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"</sample>
    <sample id="454">Der englische Text lautet:

"Dataset Collection Methodology
- Die Methode betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"

Übersetzt ins Deutsche:

"Datenbank-Sammlungs-Methode
- Die Methode betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"</sample>
    <sample id="455">Der englische Text lautet:

"Dataset Collection Methodology
- Die Methode betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"

Übersetzt ins Deutsche:

"Datenbank-Sammlungs-Methode
- Die Methode betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"</sample>
    <sample id="456">Der englische Text lautet:

"Dataset Collection Methodology
- Methodologie betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"

Übersetzt ins Deutsche:

"Datenbank-Sammlungs-Methode
- Die Methode betont die Informalität durch das Verwenden einer Cartoon-Fertigstellungsaufgabe"</sample>
    <sample id="457">### Übersetzung des englischen Inhalts in Deutsch

---

**Dataset Collection Methodology**

- Die Methode betont die **Informalität**, indem sie eine **Cartoon-Fertigstellungsaufgabe** verwendet.

---

**Dataset Collection Methodology &gt; Auswahl von Entity-Paaren**

- Die Methode betont die **Informalität**, indem sie eine **Cartoon-Fertigstellungsaufgabe** verwendet.

---

**Dataset Collection Methodology &gt; Auswahl von Entity-Paaren**

- Die Methode betont die **Informalität**, indem sie eine **Cartoon-Fertigstellungsaufgabe** verwendet.

---

**Dataset Collection Methodology &gt; Auswahl von Entity-Paaren**

- Die Methode betont die **Informalität**, indem sie eine **Cartoon-Fertigstellungsaufgabe** verwendet.

---

**Dataset Collection Methodology &gt; Auswahl von Entity-Paaren**

- Die Methode betont die **Informalität**, indem sie eine **Cartoon-Fertigstellungsaufgabe** verwendet.

---</sample>
    <sample id="458">Generiere alternative Fragen =&gt; Auswahl von Entity-Paaren

Haben Sie A oder B gemeint?

- Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleiche Genre und/oder Künstler)
  Hatten Sie "This Is It" oder "Man in the Mirror" gemeint?
- Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  Hatten Sie "Thinking of You" oder "Happy Anywhere" gemeint?
- Gegenstände mit ähnlichen Titeln:
  Hatten Sie "The Return (memoir)" oder "The Return (Shatner novel)" gemeint?
- Zufällig:
  Hatten Sie "You Could Be Mine" oder "The Way I Am" gemeint?</sample>
    <sample id="459">Generiere alternative Fragen =&gt; Auswahl von Entity-Paaren

Hast du A oder B gemeint?

- Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleicher Genre und/oder Künstler)
  - Hast du "This Is It" oder "Man in the Mirror" gemeint?
- Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  - Hast du "Thinking of You" oder "Happy Anywhere" gemeint?
- Gegenstände mit ähnlichen Titeln:
  - Hast du "The Return (memoir)" oder "The Return (Shatner novel)" gemeint?
- Zufällig:
  - Hast du "You Could Be Mine" oder "The Way I Am" gemeint?</sample>
    <sample id="460">Generiere alternative Fragen =&gt; Auswahl von Entity-Paaren

Hast du A oder B gemeint?

- Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleicher Genre und/oder Künstler)
  Hast du "This Is It" oder "Man in the Mirror" gemeint?
- Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  Hast du "Thinking of You" oder "Happy Anywhere" gemeint?
- Gegenstände mit ähnlichen Titeln:
  Hast du "The Return (Memoir)" oder "The Return (Shatner Novel)" gemeint?
- Zufällig ausgewählt:
  Hast du "You Could Be Mine" oder "The Way I Am" gemeint?</sample>
    <sample id="461">Generiere alternative Fragen =&gt; Auswahl von Entity-Paaren

Hast du A oder B gemeint?

- Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleicher Genre und/oder Künstler)
  Hast du "This Is It" oder "Man in the Mirror" gemeint?
- Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  Hast du "Thinking of You" oder "Happy Anywhere" gemeint?
- Gegenstände mit ähnlichen Titeln:
  Hast du "The Return (memoir)" oder "The Return (Shatner novel)" gemeint?
- Zufällig:
  Hast du "You Could Be Mine" oder "The Way I Am" gemeint?</sample>
    <sample id="462">Generiere alternative Fragen =&gt; Auswahl von Entity-Paaren

Hast du A oder B gemeint?

- Gegenstände mit ähnlichen Infoboxen auf Wikipedia (gleicher Genre und/oder Künstler)
  Hast du "This Is It" oder "Man in the Mirror" gemeint?
- Gegenstände mit ähnlichen Beschreibungen auf Wikipedia
  Hast du "Thinking of You" oder "Happy Anywhere" gemeint?
- Gegenstände mit ähnlichen Titeln:
  Hast du "The Return (memoir)" oder "The Return (Shatner novel)" gemeint?
- Zufällig:
  Hast du "You Could Be Mine" oder "The Way I Am" gemeint?</sample>
    <sample id="463">Hintergrundwissen (Musik)

- Google-Suchlink zu jedem Lied.
  - "Easy on Me" (von Adele)
  - "I Gotta Feeling" (von The Black Eyed Peas)
  - Klicken Sie hier, um mehr über das Lied zu erfahren.

- Wir bitten die Annotatoren, 
  - mindestens einige Teile jedes Liedes anzuhören,
  - über jedes Lied zu lesen.</sample>
    <sample id="464">Hintergrundwissen (Musik)

- Google-Suchlink zu jedem Lied.
  - "Easy on Me" (von Adele)
  - "I Gotta Feeling" (von The Black Eyed Peas)
  - Klicken Sie hier, um mehr über das Lied zu erfahren.

- Wir bitten die Annotatoren, 
  - mindestens einige Teile jedes Liedes anzuhören,
  - über jedes Lied zu lesen.</sample>
    <sample id="465">### Hintergrundwissen (Musik)

- Google-Suchlink zu jedem Lied.
  - **Easy on Me** (von Adele)
    - Klicken Sie hier, um mehr über das Lied zu erfahren.
  - **I Gotta Feeling** (von The Black Eyed Peas)
    - Klicken Sie hier, um mehr über das Lied zu erfahren

- Wir bitten die Annotatoren, folgendes zu tun:
  - Hören Sie sich mindestens einige Teile jedes Liedes an.
  - Lesen Sie sich jedes Lied an.

---

### Hintergrundwissen (Musik)

- Google-Suchlink zu jedem Lied.
  - **Easy on Me** (von Adele)
    - [Adele - Easy On Me (Offizieller Video) - YouTube](https://www.youtube.com/watch)
  - **I Gotta Feeling** (von The Black Eyed Peas)
    - [Klicken Sie hier, um mehr über das Lied zu erfahren]

- Wir bitten die Annotatoren, folgendes zu tun:
  - Hören Sie sich mindestens einige Teile jedes Liedes an.
  - Lesen Sie sich jedes Lied an.</sample>
    <sample id="466">Hintergrundwissen (Rezepte)

Simnel-Kuchen
Der Simnel-Kuchen ist ein Früchtekuchen, der in Großbritannien, Irland und anderen Ländern mit Migrationsmustern weit verbreitet ist, die mit Ostern und Fasten assoziiert sind. Er wird durch Schichten aus Mandelteig oder Marzipan und eine Gruppe von elf Kugeln aus demselben Teig gekennzeichnet.

Pandan-Kuchen
Der Pandan-Kuchen ist ein leichter, fluffiger, grün gefärbter Kuchen, der mit den Saftblättern des Pandanus amaryllifolius gewürzt wird. Der Kuchen ist in Indonesien, Malaysia und auch den Niederlanden, besonders bei der Indo-Gemeinschaft beliebt.</sample>
    <sample id="467">Der englische Text lautet:

"**Eliciting expressions**
- Wir geben den Annotatoren dann zu, welche Wahl ausgewählt werden soll und bitten sie, es zu beschreiben."

Unter dem Titel steht:

"Pick this one
- Easy on Me (by Adele)
- I Gotta Feeling (by the Black Eyed Peas)"

Es wird weiterhin angegeben:

"We would like you to give us 3 to 5 expressions for the chosen song to fill in your speech bubble. For example:
- The one with the piano music
- The song that's not energetic
- It has something about a river
- The newer one
- It's about not having time to choose"

Unten steht noch:

"Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)"</sample>
    <sample id="468">### Elicitating expressions

- Wir geben den Annotatoren dann die Wahl, die ausgewählt werden soll, und bitten sie, sie zu beschreiben.

**Wählen Sie diese:**

- **Easy on Me (von Adele)**
- **I Gotta Feeling (von The Black Eyed Peas)**

Wir möchten, dass Sie 3 bis 5 Ausdrücke für das gewählte Lied in Ihren Sprechblasen eingeben. Zum Beispiel:

- **The one with the piano music**
- **The song that's not energetic**
- **It has something about a river**
- **The newer one**
- **It's about not having time to choose**

---

### Zufällige Beispiele

#### Musikauswahl
- Bedeutest du "Chime" oder "Your Loving Arms"? ➞ Das ohne Worte.
- Bedeutest du "These Kids" oder "Inescapable"? ➞ Es ist das Lied von einem Australier.
- Bedeutest du "Rock the Boat" oder "Wherever You Are"? ➞ Es hat Synthesizer-Sounds.
- Bedeutest du "Telepathy" oder "Stars on 45"? ➞ Es kam Mitte der 2000er heraus.
- Bedeutest du "Mis-Shapes" oder "Remind Me"? ➞ Basierend auf Lebenserfahrungen in Sheffield.

#### Buchauswahl
- Bedeutest du "Warlock (Hall-Buch)" oder "Warlock (Smith-Buch)"? ➞ Das, das im 1880er-Jahrzehnt spielt.
- Bedeutest du "The Legion of Space" oder "The Body in the Library"? ➞ Das von einem berühmten Detektivautor geschrieben wurde.
- Bedeutest du "The Good Soldier" oder "The Good Soldiers"? ➞ Das fiktive.
- Bedeutest du "The Giaour" oder "The Giver"? ➞ Das nicht mit dem 12-jährigen Jungen.
- Bedeutest du "Broken Sleep" oder "Broken Soup"? ➞ Das Buch über Rock und Politik.

#### Rezeptauswahl
- Bedeutest du "Beurre Maître d'Hôtel" oder "Chigirtma"? ➞ Kommt aus Aserbaidschan.
- Bedeutest du "Kusa mochi" oder "Uiré"? ➞ Das japanische gesteckte Kuchenrezept.
- Bedeutest du "Cannoli" oder "Boconotto"? ➞ Diejenigen, die am Weihnachten gegessen werden.
- Bedeutest du "Sagu" oder "Mamaliga"? ➞ Das Maisbrei-Rezept.
- Bedeutest du "Not the one with the 12 year old boy"? ➞ Das nicht mit dem 12-jährigen Jungen.</sample>
    <sample id="469">AltEntities Corpus

- ~6.000 alternative Fragen über die drei Domänen
- ~42.000 indirekte Bezugsexpressionen

Ergebnisse mit T5 XL Modell (Genauigkeit):
- 92–95% wenn das LM dieselbe Hintergrundwissen wie die Annotatoren hat.
- 82–87% wenn das LM teilweise übereinstimmendes Hintergrundwissen hat.
- ~60% wenn das LM (T5 XL) nur Zugang zu den Entitätsnamen hat.
- Wir zeigten, dass Modelle domänengenerierbar sind.

Dataset Link: [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)</sample>
    <sample id="470">AltEntities Korpus
- ~6.000 alternative Fragen über die drei Domänen
- ~42.000 indirekte Bezugsexpressionen

Ergebnisse mit T5 XL Modell (Genauigkeit):
- 92–95% wenn das LM dieselbe Hintergrundwissen wie die Annotatoren hat.
- 82–87% wenn das LM teilweise übereinstimmendes Hintergrundwissen hat.
- ~60% wenn das LM (T5 XL) nur Zugang zu den Entitätsnamen hat.
- Wir haben gezeigt, dass Modelle domänengenerierbar sind.

Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="471">AltEntities Corpus
- ~6.000 alternative Fragen über drei Domänen
- ~42.000 indirekte Bezugsexpressionen

Ergebnisse mit T5 XL Modell (Genauigkeit):
- 92–95% wenn das LM die gleiche Hintergrundwissen wie die Annotatoren hat.
- 82–87% wenn das LM teilweise übereinstimmendes Hintergrundwissen hat.
- ~60% wenn das LM (T5 XL) nur den Namen der Entitäten kennt.
- Wir haben gezeigt, dass Modelle allgemein anwendbar sind.

Dataset Link: [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)</sample>
    <sample id="472">AltEntities Corpus

- ~6.000 alternative Fragen über drei Domänen
- ~42.000 indirekte Bezugsexpressionen

Ergebnisse mit dem T5 XL Modell (Genauigkeit):
- 92–95% wenn das LM die gleiche Hintergrundwissen wie die Annotatoren hat.
- 82–87% wenn das LM teilweise übereinstimmendes Hintergrundwissen hat.
- ~60% wenn das LM (T5 XL) nur Zugang zu den Entity-Namen hat.
- Wir haben gezeigt, dass Modelle allgemein anwendbar sind.

Dataset Link: [https://github.com/google-research-datasets/AltEntities](https://github.com/google-research-datasets/AltEntities)

Vielen Dank!

Wenn Sie Fragen haben, senden Sie eine E-Mail an javadh@google.com</sample>
    <sample id="473">Der Ansatz wird mit den bestehenden SimulST-Richtlinien "wait-k", "LA" und "CAAT" verglichen.</sample>
    <sample id="474">Die Autoren gehören an Nantes Université und Avignon Université.</sample>
    <sample id="475">Der Referent*in ist Jenny T. Liang.</sample>
    <sample id="476">Es sind drei Autoren an der Arbeit beteiligt: Myra Cheng, Esin Durmus und Dan Jurafsky.</sample>
    <sample id="477">Aufmerksamkeit als Leitfaden für die gleichzeitige Sprachübersetzung

Sara Papi, Matteo Negri, Marco Turchi</sample>
    <sample id="478">Der englische Text lautet:

"Simultaneous speech translation (SimulST) is the process of translating spoken language into a text in another language in real-time, enabling cross-language communication."

Übersetzt auf Deutsch bedeutet das:

"Synchroner Sprachübersetzung (SimulST) ist der Prozess des Echtzeit-Übersetzens gesprochener Sprache in einen Text einer anderen Sprache, der die grenzüberschreitende Kommunikation ermöglicht."</sample>
    <sample id="479">Was sind die Probleme der aktuellen SimulST-Modelle?

Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche Module optimiert werden.</sample>
    <sample id="480">Was sind die Probleme der aktuellen SimulST-Modelle?

Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche Module optimiert werden.

Lange und komplizierte Trainingsverfahren (z.B., verschiedene Optimierungsziele)</sample>
    <sample id="481">Was sind die Probleme der aktuellen SimulST-Modelle?

Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche Module optimiert werden.

Lange und komplizierte Trainingsverfahren (z.B., verschiedene Optimierungsziele)

Trainieren und Unterhalten mehrerer Modelle, um verschiedene Latenzregimes zu erreichen (z.B., 1s, 2s, ...)</sample>
    <sample id="482">Der englische Text lautet "What is our solution?" und übersetzt sich auf Deutsch zu "Was ist unsere Lösung?"</sample>
    <sample id="483">Was ist unsere Lösung?

01 Verwenden Sie bereits vorhandene offline ST-Modelle ohne Neuaufbau oder Anpassung einer spezifischen Architektur für SimulST

02 Verwenden Sie nur ein Modell für jede Latenzstufe und handhaben Sie die Latenz durch spezifische Parameter</sample>
    <sample id="484">Was ist unsere Lösung?

01 Verwenden Sie bereits vorhandene offline ST-Modelle ohne Neutrainieren oder Anpassung einer spezifischen Architektur für SimulST.

02 Verwenden Sie nur ein Modell für jeden Latenzmodus und handhaben Sie die Latenz durch spezifische Parameter.

03 Nutzen Sie das Wissen, das der Modell bereits durch die Aufmerksamkeitsmechanismen zwischen audiolem Eingang und textuellem Ausgang erworben hat.</sample>
    <sample id="485">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschließen Sie sich, ob eine Teilübersetzung ausgestrahlt wird oder nicht, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) in den letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.</sample>
    <sample id="486">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschließen Sie sich, ob eine vollständige oder eine partielle Übersetzung ausgestrahlt wird, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.</sample>
    <sample id="487">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschieden, ob eine vollständige oder eine partielle Übersetzung emittiert wird, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird emittiert, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde darüber sprechen...</sample>
    <sample id="488">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschließen Sie sich, ob eine vollständige oder eine partielle Übersetzung ausgestrahlt wird, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde reden.</sample>
    <sample id="489">Unser Lösungsansatz: EDAtt

Encoder-Decoder Attention

Entschieden, ob eine vollständige oder eine partielle Übersetzung ausgestrahlt wird, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde reden.</sample>
    <sample id="490">Unser Lösungsansatz: EDAtt

Entschieden, ob eine Teiltraduktion ausgestrahlt wird oder nicht, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde sprechen.</sample>
    <sample id="491">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschieden, ob eine vollständige oder eine partielle Übersetzung ausgestrahlt wird, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

Ich werde sprechen.
EMITTED</sample>
    <sample id="492">Unser Lösungsansatz: EDAtt

Encoder-Decoder Attention

Entschieden, ob eine Wörterausgabe oder eine partielle Übersetzung erfolgt, basierend auf dem Fokus der Aufmerksamkeit:
Ein Wort wird ausgegeben, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

01: Ich werde reden.
02: Ich werde über Klima sprechen.</sample>
    <sample id="493">Unser Lösungsansatz: EDAtt

Encoder-Decoder Attention

Entschieden, ob eine Wörterausgabe oder ein Teilübersetzung erfolgt, basierend auf dem Ort der Aufmerksamkeit:

Ein Wort wird ausgegeben, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

01: Ich werde reden.
02: Ich werde über Klima sprechen.</sample>
    <sample id="494">Unser Lösungsansatz: EDAtt

Encoder-Decoder-Aufmerksamkeit

Entschließen Sie sich, ob eine Teilübersetzung ausgestrahlt wird oder nicht, basierend auf dem Aufmerksamkeitspunkt:
Ein Wort wird ausgestrahlt, wenn die Aufmerksamkeit nicht konzentriert ist (ihre Summe liegt unter einem Schwellenwert α) auf die letzten λ Sprachrahmen, was bedeutet, dass das empfangene Information genug stabil ist.

01: Ich werde reden.
02: Ich werde über Klima sprechen.</sample>
    <sample id="495">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de"</sample>
    <sample id="496">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de"</sample>
    <sample id="497">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de
latency measure"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de
Verzögerungsmaß"</sample>
    <sample id="498">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de"</sample>
    <sample id="499">Der englische Text lautet:

"Main Results:
EDAtt

(a) en→de"

Übersetzt ins Deutsche bedeutet das:

"Hauptergebnisse:
EDAtt

(a) en→de"</sample>
    <sample id="500">Der englische Text lautet:

"Main Results: EDAtt
popular strategies also applied to offline models
state of the art architecture specifically tailored for SimulST"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse: EDAtt
populäre Strategien werden auch auf Offline-Modelle angewendet
zur Zeit beste Architektur speziell für SimulST abgestimmt"</sample>
    <sample id="501">Der englische Text lautet:

"Main Results:
EDAtt

state of the art architecture specifically tailored for SimulST

wait-k  LA  CAAT  EDAtt

BLEU
27
25
23
21
19
17
0.5  1   1.5  2    2.5  3   3.5  4   4.5  5
AL / AL_CA (s)

(a) en→de"

Übersetzt ins Deutsche:

"Hauptergebnisse:
EDAtt

zurzeit beste Architektur speziell für SimulST

wait-k  LA  CAAT  EDAtt

BLEU
27
25
23
21
19
17
0.5  1   1.5  2    2.5  3   3.5  4   4.5  5
AL / AL_CA (s)

(a) en→de"</sample>
    <sample id="502">Der englische Text lautet:

"Main Results:
EDAtt

EDAtt outperforms all the strategies applied to offline models"

Übersetzt auf Deutsch bedeutet das:

"Hauptergebnisse:
EDAtt

EDAtt übertrifft alle Strategien, die auf Offline-Modelle angewendet wurden"</sample>
    <sample id="503">Der englische Text lautet:

"Main Results:
EDAtt

EDAtt outperforms all the strategies applied to offline models

EDAtt is the fastest strategy if we consider the actual elapsed time"

Übersetzt auf Deutsch:

"Hauptergebnisse:
EDAtt

EDAtt übertrifft alle Strategien, die auf Offline-Modelle angewendet wurden

EDAtt ist die schnellste Strategie, wenn wir den tatsächlichen verstrichenen Zeitraum berücksichtigen"</sample>
    <sample id="504">Hier ist die Übersetzung des englischen Inhalts in Deutsch:

"Willst du mehr entdecken?
Lesen Sie unsere Arbeit, um weitere Ergebnisse zu entdecken!

E-Mail: {spapi,negri}@fbk.eu
marco.turchi@gmail.com

GitHub: github.com/hlt-mt/fbk-fairseq

Twitter: @fbk_mt
@sarapapi

QR-Code scannen!"</sample>
    <sample id="505">Ja, der Datensatz ist öffentlich zugänglich.</sample>
    <sample id="506">Der englische Text lautet:

"MULTIINSTRUCT: Verbessern von Multi-Modalen Null-Shot-Learning durch Anweisungstuning

Zhiyang Xu*, Ying Shen*, Lifu Huang
Department of Computer Science, Virginia Tech"

Übersetzt auf Deutsch:

"MULTIINSTRUCT: Verbessern von Multi-Modalem Null-Shot-Lernen durch Anweisungstuning

Zhiyang Xu*, Ying Shen*, Lifu Huang
Fachbereich Informatik, Virginia Tech"</sample>
    <sample id="507">### Prätrainierte Sprachmodelle für Aufgaben der Niedrigstufe

#### (A) Prätraining und Feinabstimmung (BERT, T5)
- **Prätrainiertes LM**
  - **Feinabstimmung auf Aufgabe A**
  - **Inferenz auf Aufgabe A**
  - *Typischerweise benötigt viele exemplarische Beispiele für jede Aufgabe.*
  - *Ein spezialisiertes Modell für jede Aufgabe.*

#### (B) Prompting (GPT-3)
- **Prätrainiertes LM**
  - **Verbessern des Leistungsvermögens durch few-shot Prompting oder Prompt Engineering**
  - **Inferenz auf Aufgabe A**

#### (C) Anweisungsabstimmung (FLAN)
- **Prätrainiertes LM**
  - **Anweisungsabstimmung auf viele Aufgaben: B, C, D, ...**
  - *Modell lernt, viele Aufgaben über natürliche Sprachanweisungen auszuführen.*
  - **Inferenz auf unbekannte Aufgabe**

**Abbildung 2:** Vergleich von Anweisungsabstimmung mit Prätraining und Feinabstimmung sowie Prompting.

**Bildnachweis:** Wei, Jason, et al. "Finetuned language models are zero-shot learners."</sample>
    <sample id="508">### Prätrainierte Sprachmodelle für Aufgaben der unteren Ebene

#### (A) Prätraining und Feinabstimmung (BERT, T5)
- **Prätrainiertes LM**
  - **Feinabstimmung auf Aufgabe A**
  - **Inferenz auf Aufgabe A**
  - *Typischerweise benötigt viele exemplarische Beispiele für jede Aufgabe.*
  - *Ein spezialisiertes Modell für jede Aufgabe.*

#### (B) Prompting (GPT-3)
- **Prätrainiertes LM**
  - **Verbessern des Leistungsvermögens durch few-shot Prompting oder Prompt Engineering**
  - **Inferenz auf Aufgabe A**

#### (C) Anweisungsabstimmung (FLAN)
- **Prätrainiertes LM**
  - **Anweisungsabstimmung auf viele Aufgaben: B, C, D, ...**
  - *Modell lernt, viele Aufgaben über natürliche Sprachanweisungen auszuführen.*
  - **Inferenz auf unbekannte Aufgabe**

**Abbildung 2:** Vergleich von Anweisungsabstimmung mit Prätraining und Feinabstimmung sowie Prompting.

**Bildnachweis:** Wei, Jason, et al. "Finetuned language models are zero-shot learners."</sample>
    <sample id="509">Der englische Text "Language-only" bedeutet auf Deutsch "Sprache nur".</sample>
    <sample id="510">Der englische Text lautet "Instruction Tuning on Multimodal Pre-trained Models" und übersetzt sich auf Deutsch zu "Instruktionsanpassung auf multimodalen prätrainierten Modellen".</sample>
    <sample id="511">Der englische Text lautet: "Imbalance in Instructional Datasets between NLP and Multimodal"

Die deutsche Übersetzung lautet: "Unausgewogene Datenmengen im Bereich der Anweisungen zwischen NLP und Multimodal"</sample>
    <sample id="512">Unausgewogene Datenmengen in Anweisungsdatensätzen zwischen NLP und Multimodal

1600+ Sprachnur-Anweisungsaufgaben

Keine großen, öffentlich verfügbaren multimodalen Anweisungsaufgaben</sample>
    <sample id="513">MULTIINSTRUCT

Das erste multimodale Anweisungstuning Benchmark-Dataset

- 62 verschiedene multimodale Aufgaben
- 10 breite Gruppen
- 5 von Experten verfasste Anweisungen

Abbildung 2: Aufgabengruppen in MULTIINSTRUCT. Die gelben Boxen repräsentieren Aufgaben, die für die Bewertung verwendet werden, während die weißen Boxen Aufgaben für das Training angeben.</sample>
    <sample id="514">MULTIINSTRUCT

Das erste multimodale Anweisungstuning Benchmark-Dataset

- 62 verschiedene multimodale Aufgaben
- 10 breite Gruppen
- 5 von Experten verfasste Anweisungen

Abbildung 2: Aufgabengruppen in MULTIINSTRUCT. Die gelben Boxen repräsentieren Aufgaben, die für die Bewertung verwendet werden, während die weißen Boxen Aufgaben für das Training angeben.

Figure 2: Task Groups Included in MULTIINSTRUCT. The yellow boxes represent tasks used for evaluation, while the white boxes indicate tasks used for training.</sample>
    <sample id="515">OFA (One For All)

- Ein einheitliches multimodales prä-gespeichertes Modell, das in der Lage ist, sowohl Verstehens- als auch Generierungsaufgaben mit einer oder mehreren Modalitäten auszuführen.
- OFA hat eine einheitliche Vokabularbasis für Sprache, Bild-Token und die Koordinaten eines Bounding-Boxenrahmens.</sample>
    <sample id="516">### Übersetzung des englischen Inhalts in Deutsch

**MULTIINSTRUCT**

**Beispielinstanzen aus MULTIINSTRUCT für vier Aufgaben.**

1. **Begründete Caption**
   - **Eingabe:** Erstelle eine Caption für &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Ausgabe:** blauer und weißer Tennis-Schläger

2. **Text-Localisierung**
   - **Eingabe:** Wählen Sie die Region, die das Wort "den" enthält.
   - **Optionen:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Ausgabe:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referierende Ausdrucksauswahl**
   - **Eingabe:** Wählen Sie die Region des Objekts aus, das durch "Ein blaues Zug in der Front" beschrieben wird.
   - **Optionen:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Ausgabe:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Frage-Bild-Matching**
   - **Eingabe:** Gegeben das Bildinhalt, haben Sie genügend Informationen, um die Frage "Ist es ein sonniger Tag?" zu beantworten?
   - **Optionen:** "Die Frage ist relevant zum Bild" oder "Die Frage ist irrelevant zum Bild"
   - **Ausgabe:** Die Frage ist irrelevant zum Bild</sample>
    <sample id="517">### Übersetzung des englischen Inhalts in Deutsch

**MULTIINSTRUCT**

**Beispielinstanzen aus MULTIINSTRUCT für vier Aufgaben.**

1. **Begründete Caption**
   - **Eingabe:** Erstelle eine Caption für &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Ausgabe:** Blauer und weißer Tennisschläger.

2. **Text Lokalisation**
   - **Eingabe:** Wählen Sie die Region, die das Wort "den" enthält.
   - **Optionen:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Ausgabe:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referierende Ausdrucksauswahl**
   - **Eingabe:** Wählen Sie die Region des Objekts aus, das durch "Ein blauer Zug im Vordergrund" beschrieben wird.
   - **Optionen:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Ausgabe:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Frage-Bild Matching**
   - **Eingabe:** Gegeben das Bildinhalt, haben Sie genügend Informationen, um die Frage "Ist es ein sonniger Tag?" zu beantworten?
   - **Optionen:** "Die Frage ist relevant zum Bild" oder "Die Frage ist irrelevant zum Bild"
   - **Ausgabe:** Die Frage ist irrelevant zum Bild.</sample>
    <sample id="518">### Übersetzung des englischen Inhalts in Deutsch

**MULTIINSTRUCT**

**Beispielinstanzen aus MULTIINSTRUCT für vier Aufgaben.**

1. **Begründete Caption**
   - **Eingabe:** Erstelle eine Caption für &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Ausgabe:** Blauer und weißer Tennisschläger.

2. **Text Lokalisation**
   - **Eingabe:** Wählen Sie die Region, die das Wort "den" enthält.
   - **Optionen:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; &lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Ausgabe:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referierende Ausdrucksauswahl**
   - **Eingabe:** Wählen Sie die Region des Objekts aus, das durch "Ein blauer Zug im Vordergrund" beschrieben wird.
   - **Optionen:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; &lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; &lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Ausgabe:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Frage-Bild-Matching**
   - **Eingabe:** Gegeben das Bildinhalt, haben Sie genügend Informationen, um die Frage "Ist es ein sonniger Tag?" zu beantworten?
   - **Optionen:** "Die Frage ist relevant zum Bild" oder "Die Frage ist irrelevant zum Bild"
   - **Ausgabe:** Die Frage ist irrelevant zum Bild.</sample>
    <sample id="519">Der englische Text "Multi-modal Instruction Tuning" übersetzt sich auf Deutsch zu "Multimodales Anweisungstuning".</sample>
    <sample id="520">### Multi-Modale Anweisungsumwandlung

- **Trainingsdatensatzkonstruktion:**
  - Verwenden Sie 53 Aufgaben aus 9 Gruppen für das Training.
  - Stellen Sie pro Aufgabe 10.000 Instanzen ein.

- **Testdatensatzkonstruktion:**
  - Reservieren Sie die gesamte Gruppe "Commonsense Reasoning" für das Testen.
  - Wählen Sie zusätzliche 5 Aufgaben aus den Gruppen VQA und Miscellaneous aus.
  - Wir verwenden alle Instanzen im Testsplit für jede Aufgabe.
  - Zufällig aus dem Testsplit des Datensatzes "Natural Instructions" 20 Aufgaben als unbekannte Aufgaben für NLP auswählen.</sample>
    <sample id="521">### Multi-Modale Anweisungsumwandlung

- **Trainingsdatensatz-Konstruktion:**
  - Verwenden Sie 53 Aufgaben aus 9 Gruppen für das Training.
  - Stellen Sie pro Aufgabe 10.000 Instanzen ein.

- **Testdatensatz-Konstruktion:**
  - Reservieren Sie die gesamte Gruppe "Commonsense Reasoning" für den Test.
  - Wählen Sie zusätzliche 5 Aufgaben aus den Gruppen VQA und Miscellaneous aus.
  - Wir verwenden alle Instanzen im Testsplit für jede Aufgabe.
  - Zufällig aus dem Testsplit des Datensatzes "Natural Instructions" 20 Aufgaben als unbekannte Aufgaben für NLP auswählen.</sample>
    <sample id="522">### Implementierungsdetails

- **Trainingsdetails:**
  - Vortrainierter OFA-Large-Modell (472M)
  - Mischen aller Instanzen für alle Aufgaben.
  - Jede Instanz wird zufällig mit einer von ihren fünf Anweisungsschablonen kombiniert.

- **Testdetails:**
  - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment evaluieren.
  - Wir berichten über das Durchschnitts- und maximale Leistungsergebnis sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="523">### Implementierungsdetails

- **Trainingsdetails:**
  - Vortrainierter OFA-Large-Modell (472M)
  - Mischen aller Instanzen für alle Aufgaben.
  - Jede Instanz wird zufällig mit einer von ihren fünf Anweisungsschablonen kombiniert.

- **Testdetails:**
  - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment evaluieren.
  - Wir berichten über das Durchschnitts- und maximale Leistungsergebnis sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="524">### Implementationsdetails

- **Trainingsdetails:**
  - Vortrainierter OFA-Large-Modell (472M)
  - Mischen aller Instanzen für alle Aufgaben.
  - Jede Instanz wird zufällig mit einer von ihren fünf Anweisungsschablonen kombiniert.

- **Testdetails:**
  - Für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment evaluieren.
  - Wir berichten über das Durchschnitts- und maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente.</sample>
    <sample id="525">Evaluation Metrics

- Für multi-modale Klassifizierungsaufgaben (Visuelle Implikation, visuelles räumliches Denken, natürliche Sprache visuelles Denken und Katastrophentypen-Klassifikation) berichten wir die Genauigkeit.
- Für multi-modale Generierungsaufgaben (Allgemeinwissen VQA, Text VQA, Bodengebundene VQA, visuelles Textextraktions- und visuelles Dialogaufgaben) berichten wir die Rouge-L.
- Für NLP-Aufgaben berichten wir Rouge-L.

- Wir berechnen auch das aggregierte Leistungsfähigkeitsmaß für jedes Modell basierend auf dem Mittelwert der Modellleistung auf allen multimodalen und NLP-unbekannten Aufgaben. Wir verwenden Rouge-L als Leistungsmesswert für die meisten Aufgaben und Genauigkeit für Aufgaben, bei denen nur Genauigkeit als Messwert verwendet wird.</sample>
    <sample id="526">Sensitivität

Wie sensibel ist das Modell auf eine Vielzahl von Anweisungen für die gleiche Aufgabe:

- Fähigkeit, für dieselbe Aufgabe immer die gleichen Ergebnisse zu erzeugen, unabhängig von leichten Variationen in der Formulierung der Anweisungen.

\[
\mathbb{E}_{t \in T} \left[ \frac{\sigma_{i \in I^t} \left[ \mathbb{E}_{(x,y) \in D^t} [L(f_\theta(i,x),y)] \right]}{\mu_{i \in I^t} \left[ \mathbb{E}_{(x,y) \in D^t} [L(f_\theta(i,x),y)] \right]} \right]
\]

Effektivität des Anweisungsabstimmens auf MULTINSTRUCT

Tabelle 1: Zero-Shot-Performance im Bereich Multimodaler Alltagsvernunft. Das beste Ergebnis ist fett hervorgehoben.

| Modell | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|--------|-----------------|--------------------|--------------------------|-------|
| OFA    | 17.93           | 48.99              | 52.01                   | 52.06 |
| OFATaskName | -               | -                  | -                       | -     |
| OFAMultiInstruct | 52.01 | 50.60 ± 1.12      | 33.01                   | 55.96 |
| OFANaturalInstruct | 27.15 | 14.99 ± 9.12      | 32.38                   | 51.44 |
| OFAMixedInstruct | 50.40 | 49.34 ± 1.04      | 30.27 ± 0.94            | 54.63 |
| OFASeqInstruct | 50.93 | 50.07 ± 1.07      | 32.28                   | 53.66 |

Tabelle 2: Zero-Shot-Performance im Bereich Fragebeantwortung und Allgemeines. Das beste Ergebnis ist fett hervorgehoben.

| Modell | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|--------|----------|--------------|-----------------------|----------------|----------------------------|
| OFA    | 15.21    | 23.80        | 27.22                 | 15.21          | 14.30                      |
| OFATaskName | -       | -            | -                     | -              | -                          |
| OFAMultiInstruct | 27.22 | 46.32        | 74.35                 | 46.38          | 64.88                      |
| OFANaturalInstruct | 5.59   | 24.15        | 5.65                  | 30.94          | 56.64                      |
| OFAMixedInstruct | 26.67   | 64.19        | 71.63                 | 46.08          | 68.31                      |
| OFASeqInstruct | 27.03   | 64.19        | 71.63                 | 46.17          | 64.46                      |</sample>
    <sample id="527">Die Wirksamkeit der Anweisungstuning auf MULTIINSTRUCT

Tabelle 1: Zero-Shot Performance auf multimodalem Alltagswissen. Die beste Leistung ist in Fettschrift hervorgehoben.

| Modell | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|--------|-----------------|-------------------|--------------------------|------|
| Max    | Avg ± Std       | Max              | Avg ± Std                | Max  |
| OFA    | 17,93           | 14,97 ± 4,30      | 0,73                      | 56,06|
| OFATaskName | -              | -                | -                        | -    |
| OFAMultiInstruct | 52,01          | 50,60 ± 1,12      | 33,01                     | 55,81|
| OFANaturalInstruct | 27,15          | 14,99 ± 9,12      | 7,35                      | 51,44|
| OFAMixedInstruct | 50,40          | 49,34 ± 1,04      | 31,31                     | 55,13|
| OFASeqInstruct | 50,93          | 50,07 ± 1,07      | 32,28                     | 54,86|

Tabelle 2: Zero-Shot Performance auf Fragebeantwortung und allgemeine Aufgaben. Die beste Leistung ist in Fettschrift hervorgehoben.

| Modell | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|--------|----------|--------------|-----------------------|----------------|----------------------------|
| Max    | Avg ± Std | Max          | Avg ± Std             | Max            | Max                        |
| OFA    | 15,21    | 9,30 ± 5,42   | 0,02                  | 45,46          | 14,30                      |
| OFATaskName | -        | -            | -                     | 25,18          | 62,65                      |
| OFAMultiInstruct | 27,22    | 26,46 ± 0,83  | 46,32                 | 46,38          | 64,88                      |
| OFANaturalInstruct | 5,59     | 5,40 ± 0,24   | 0,00                  | 30,94          | 56,64                      |
| OFAMixedInstruct | 24,15    | 23,67 ± 0,47  | 63,79                 | 46,08          | 68,31                      |
| OFASeqInstruct | 27,03    | 26,67 ± 0,47  | 64,19                 | 46,17          | 64,46                      |

Tabelle 1: Zero-Shot Performance auf multimodalem Alltagswissen. Die beste Leistung ist in Fettschrift hervorgehoben.

Tabelle 2: Zero-Shot Performance auf Fragebeantwortung und allgemeine Aufgaben. Die beste Leistung ist in Fettschrift hervorgehoben.</sample>
    <sample id="528">Die Wirksamkeit der Anweisungstuning auf MULTIINSTRUCT

Tabelle 1: Zero-Shot-Performance auf multimodalem Alltagswissen. Die beste Leistung ist in Fettschrift hervorgehoben.

| Modell | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|--------|-----------------|-------------------|--------------------------|------|
| Max    | Avg ± Std       | Max              | Avg ± Std                | Max  |
| OFA    | 17,93           | 14,97 ± 4,30      | 0,73                      | 0,40 ± 0,29   |
| OFATaskName | -              | -                | 29,01                     | -     |
| OFAMultiInstruct | 52,01          | 50,60 ± 1,12      | 33,01                     | 31,17 ± 1,59  |
| OFANaturalInstruct | 27,15          | 14,99 ± 9,12      | 7,35                      | 2,04 ± 3,01   |
| OFAMixedInstruct | 50,40          | 49,34 ± 1,04      | 31,31                     | 30,27 ± 0,94  |
| OFASeqInstruct | 50,93          | 50,07 ± 1,07      | 32,28                     | 31,23 ± 1,09  |

Tabelle 2: Zero-Shot-Performance auf Fragebeantwortung und allgemeine Aufgaben. Die beste Leistung ist in Fettschrift hervorgehoben.

| Modell | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|--------|----------|--------------|-----------------------|----------------|----------------------------|
| Max    | Avg ± Std | Max         | Avg ± Std             | Max            | Avg ± Std                  |
| OFA    | 15,21    | 9,30 ± 5,42  | 0,02                  | 0,00 ± 0,01    | 14,30                      |
| OFATaskName | -        | -           | 0,00                  | -              | 9,64 ± 4,34                |
| OFAMultiInstruct | 27,22    | 26,46 ± 0,83 | 46,32                 | 47,22 ± 23,08  | 56,00 ± 12,96               |
| OFANaturalInstruct | 5,59     | 5,40 ± 0,24  | 0,00                  | 0,00 ± 0,00    | 56,64                      |
| OFAMixedInstruct | 24,15    | 23,67 ± 0,47 | 63,79                 | 54,99 ± 18,16  | 68,31                      |
| OFASeqInstruct | 27,03    | 26,67 ± 0,47 | 64,19                 | 54,46 ± 15,96  | 68,31                      |</sample>
    <sample id="529">Der englische Text lautet:

"Einfluss der Zunahme von Multimodalen Aufgabencluster für die Anweisung"

- Img Und
  - VQA + Bildverstehen

- Grounding
  - Bodenmatching + Bodengenerierung

- MISC, ITM
  - Temporales Ordnung + Verschiedenes + Bildtext-Matching

- Relation
  - Visuelle Beziehungen

- Region
  - Regionenverstehen

- NLP
  - NLP-Aufgaben

Der deutsche Text lautet:

"Einfluss der Zunahme von Multimodalen Aufgabencluster für die Anweisung"

- Bildverstehen
  - VQA + Bildverstehen

- Bodenmatching
  - Bodenmatching + Bodengenerierung

- MISC, ITM
  - Temporales Ordnung + Verschiedenes + Bildtext-Matching

- Beziehungen
  - Visuelle Beziehungen

- Regionenverstehen
  - Regionenverstehen

- NLP
  - NLP-Aufgaben</sample>
    <sample id="530">Der englische Text lautet:

"Effect of Diverse Instructions on Instruction Tuning

- OFA finetuned on 5 instructions achieves much higher aggregated performance on all evaluation tasks and shows lower sensitivity."

Tabelle 3: Effekt verschiedener Anzahl von Anweisungen.
Leistung von OFAMultiInstruct, die auf verschiedene Anzahl von Anweisungen abgestimmt wurde.

Die Übersetzung in Deutsch lautet:

"Wirkung vielfältiger Anweisungen auf die Anpassung von Anweisungen

- OFA, der auf 5 Anweisungen abgestimmt wurde, erreicht bei allen Bewertungsaufgaben viel höhere aggregierte Leistung und zeigt geringere Sensitivität."</sample>
    <sample id="531">Effekt von Feinabstimmungsstrategien auf Modellempfindlichkeit

- Die Feinabstimmung auf MultiInstruct kann die Empfindlichkeit von OFA signifikant reduzieren.
- Das Transfer-Learning aus dem Natural Instructions-Datensatz kann die Empfindlichkeit des Modells weiter reduzieren.

Abbildung 4: Modellempfindlichkeit bei unbekannten Evaluierungsaufgaben. Ein niedrigerer Wert ist besser.</sample>
    <sample id="532">### Leistung bei NLP-Aufgaben im Null-Shot-Setting

- Die Anpassung der Anweisungen an MultiInstruct kann die Leistung bei unbekannten NLP-Aufgaben verbessern.
- Die Transfer-Learning-Strategie MixedInstruct kann am besten die erlangte Null-Shot-Fähigkeit auf dem Natural Instructions-Datensatz beibehalten.

Tabelle 4: Leistung bei NLP-Aufgaben im Null-Shot-Setting. Die Leistung wird in Rouge-L gemessen und die beste Leistung ist fett hervorgehoben.

| Modell | RougeL |
|--------|--------|
| OFA    | 2.25   |
| OFAMultiInstruct | 12.18  |

| Transfer Learning aus NATURAL INSTRUCTIONS |
|-------------------------------------------|
| OFANaturalInstructions | 43.61 |
| OFAMixedInstruct        | 43.32 |
| OFASeqInstruct          | 30.79 |</sample>
    <sample id="533">### Schlussfolgerung

- Erste große skalare multimodale Anweisungsabstimmungsdatensatz.
  - Enthält 62 multimodale Aufgaben aus 10 breiten Kategorien.
- Signifikant verbessern die zero-shot Fähigkeiten von OFA durch Anweisungsabstimmung.
- Erforschen mehrere Transfer-Learning-Techniken und zeigen ihre Vorteile.
- Entwerfen einer neuen Messkriteriumsensitivität.</sample>
    <sample id="534">Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

"Ein weiteres Mal! Wir sammeln eine viel größere multimodale Anweisungsaufgaben-Datenbank mit etwa 150 zusätzlichen visuell-linguistischen Aufgaben und werden sie bald veröffentlichen!"</sample>
    <sample id="535">Die Autoren Sara Papi, Matteo Negri und Marco Turchi gehören der Universität di Trento an.</sample>
    <sample id="536">Der Referent ist Mohammad Javad Hosseini.</sample>
    <sample id="562">Der englische Text lautet: "Language model acceptability judgements are not always robust to context." 

Die deutsche Übersetzung ist: "Die Akzeptabilitätsurteile von Sprachmodellen sind nicht immer robust gegenüber Kontexten."</sample>
    <sample id="563">Der englische Text lautet: "Language model acceptability judgements are not always robust to context." 

Die deutsche Übersetzung ist: "Die Akzeptabilitätsurteile von Sprachmodellen sind nicht immer robust gegenüber Kontexten."</sample>
    <sample id="564">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypische Satz.
2. Nicht-stereotypischer Satz.

P(1) &gt; P(2)</sample>
    <sample id="565">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypische Satz.
2. Nicht-stereotypischer Satz.

P(1) &gt; P(2)</sample>
    <sample id="566">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypische Satz.
2. Nicht-stereotypischer Satz.

P(1) &gt; P(2)</sample>
    <sample id="567">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich gegenseitig.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypische Satz.
2. Nicht-stereotypischer Satz.

P(1) &gt; P(2)</sample>
    <sample id="568">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Frauen sind schlecht bei Handwerk.
2. Männer sind schlecht bei Handwerk.

P(1) &gt; P(2)

**Sind diese Urteile stabil mit langem vorherigem Kontext?**</sample>
    <sample id="569">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Frauen sind schlecht bei Handwerk.
2. Männer sind schlecht bei Handwerk.

P(1) &gt; P(2)

**Sind diese Urteile stabil mit langem vorherigem Kontext?**</sample>
    <sample id="570">**Revisiting Minimal Pair Paradigm**

Minimal pair paradigm (MPP) Evaluierungen von Sprachmodellen verwenden relative Unterschiede in der Wahrscheinlichkeit von Sequenzfolgen, um das abstrakte Wissen von LM zu bewerten:

BLiMP
1. Viele Menschen halfen sich selbst.
2. *Viele Menschen halfen sich selbst.

P(1) &gt; P(2)

SyntaxGym
1. Kein Kunde ... hat Geld ausgegeben.
2. *Der Kunde ... hat Geld ausgegeben.

P(1.any) &gt; P(2.any)

CrowS
1. Frauen sind schlecht bei Handwerk.
2. Männer sind schlecht bei Handwerk.

P(1) &gt; P(2)

**Sind diese Urteile stabil mit langem vorherigem Kontext?**</sample>
    <sample id="571">Der englische Text lautet:

"Approach

Test whether MPP judgements vary as a function of context length, structural match, and acceptability"

Übersetzt auf Deutsch bedeutet das:

"Ansatz

Testen Sie, ob die Urteile über MPP als Funktion der Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."</sample>
    <sample id="572">Der englische Text lautet:

"Approach

Testen Sie, ob MPP-Schätzungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."

Übersetzt ins Deutsche:

"Ansatz

Testen Sie, ob MPP-Schätzungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."</sample>
    <sample id="573">Der englische Text lautet:

"Approach

Test whether MPP judgements vary as a function of context length, structural match, and acceptability"

Übersetzt auf Deutsch bedeutet das:

"Ansatz

Testen Sie, ob die Urteile von MPP als Funktion der Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."</sample>
    <sample id="574">Der englische Text lautet:

"Approach

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren."

Übersetzt ins Deutsche:

"Ansatz

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren."</sample>
    <sample id="575">Der englische Text lautet:

"Approach

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."

Übersetzt ins Deutsche:

"Ansatz

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."</sample>
    <sample id="576">Der englische Text lautet:

"Approach

Testen Sie, ob MPP-Schätzungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren."

Übersetzt ins Deutsche:

"Ansatz

Testen Sie, ob MPP-Schätzungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptanz variieren."</sample>
    <sample id="577">Der englische Text lautet:

"Approach

Test whether MPP judgements vary as a function of context length, structural match, and acceptability"

Übersetzt ins Deutsche:

"Ansatz

Testen Sie, ob die Urteile über MPP als Funktion der Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."</sample>
    <sample id="578">Der englische Text lautet:

"Approach

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."

Übersetzt ins Deutsche:

"Ansatz

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."</sample>
    <sample id="579">Der englische Text lautet:

"Approach

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."

Übersetzt ins Deutsche:

"Ansatz

Testen Sie, ob MPP-Bewertungen als Funktion von Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren."</sample>
    <sample id="580">**Ansatz**

Testen Sie, ob die MPP-Bewertungen als Funktion der Kontextlänge, struktureller Übereinstimmung und Akzeptabilität variieren.

**Test Suite: Subjekt-Verb-Konsistenz**

\( P_{LM}(\text{Prefix}) &gt; ? P_{LM}(\text{Prefix}) \)

**Raum der möglichen Präfixe**

- **Eingestimmte Präfixe**
  - Subjekt-Verb-Konsistenz

- **Nicht eingestimmte Präfixe**
  - *Island Effects*
  - *Filler-gaps*
  - *Binding*
  - *Wikipedia*

**Beispiel**

*Wer könnte Rose vor dem Wiederkommen zu diesem Kunden verlassen?*
*Wer könnte Rose vor dem Wiederkommen zu diesem Kunden verlassen?*

**Wikipedia, Unbeziehbar**

*Eine Rose ist eine holzige, jährliche Blühpflanze aus der Gattung Rosa. Es gibt mehr als dreihundert Arten und tausende von Sorten.*
*Wer könnte Rose vor dem Wiederkommen zu diesem Kunden verlassen?*

**GPT2, OPT Familie - 125M bis 6,7B**</sample>
    <sample id="581">Die MPP-Bewertungen sind robust für arbiträre Kontextlängen.

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptable/unakzeptable; passende/ungleiche Struktur – von Längen bis zu 900 Token.</sample>
    <sample id="582">Die MPP-Bewertungen sind robust für arbiträre Kontextlängen.

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptable/unakzeptable; passende/ungleiche Struktur – von Längen bis zu 900 Token.</sample>
    <sample id="583">Der englische Text lautet:

"2 Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/senken die Bewertungsergebnisse

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token"

Übersetzt ins Deutsche:

"2 Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/senken die Bewertungsergebnisse

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token"</sample>
    <sample id="584">Der englische Text lautet:

"2 Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/senken die Bewertungsleistung

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token"

Übersetzt ins Deutsche:

"2 Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/senken die Bewertungsleistung

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token"</sample>
    <sample id="585">Der englische Text lautet:

"2 Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/senken die Bewertungsergebnisse

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token"

Übersetzt ins Deutsche:

"2 Akzeptable/Unakzeptable MPP-Sätze im Kontext steigern/senken die Bewertungsergebnisse

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/unpassende Struktur – von Längen bis zu 900 Token"</sample>
    <sample id="586">Der englische Text lautet:

"3 Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen das Modellleistung am stärksten

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/ungleiche Struktur – von Längen bis zu 900 Token"

Übersetzt ins Deutsche:

"3 Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen die Modellleistung am stärksten

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/ungleiche Struktur – von Längen bis zu 900 Token"</sample>
    <sample id="587">Der englische Text lautet:

"3 Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen das Modellleistung am stärksten

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/ungleiche Struktur – von Längen bis zu 900 Token"

Übersetzt ins Deutsche:

"3 Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen die Modellleistung am stärksten

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/ungleiche Struktur – von Längen bis zu 900 Token"</sample>
    <sample id="588">Der englische Text lautet:

"3 Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen das Modellleistung am stärksten

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/ungleiche Struktur – von Längen bis zu 900 Token"

Übersetzt ins Deutsche:

"3 Akzeptable/unakzeptable MPP-Sätze mit passender Struktur beeinflussen die Modellleistung am stärksten

Wir führen MPP-Evaluierungen mit verschiedenen Kontexten durch – akzeptabel/unakzeptabel; passende/ungleiche Struktur – von Längen bis zu 900 Token"</sample>
    <sample id="589">Warum beeinflussen übereinstimmende Präfixe die Urteile von LM-Modellen?

Wir perturben Kontextsätze in Weise, die die relevante Struktur bewahrt und fragen, ob Modelle gleichermaßen sensibel zu diesen Sätzen sind.

- Präfix/Suffix Adverbien: "Allerdings, &lt;sent&gt;."
- Langes Präfix Adverb: "Zunächst und vor allem, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Unabhängig davon, was X darüber denkt, &lt;sent&gt;."
- Zitat: "Gestern sagte X, ' &lt;sent&gt;.'"</sample>
    <sample id="590">Warum beeinflussen passende Präfixe die Urteile von LM-Modellen?

Wir perturben Kontextsätze in Weise, die relevante Struktur bewahrt und fragen, ob Modelle gleichermaßen sensibel auf diese Sätze sind.

- Präfix/Suffix Adverbien: "However, &lt;sent&gt;."
- Langes Präfix Adverb: "First and foremost, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Regardless of what X thinks about it, &lt;sent&gt;."
- Zitat: "Yesterday, X said, ‘&lt;sent&gt;’."</sample>
    <sample id="591">Warum beeinflussen passende Präfixe die Urteile von LM-Modellen?

Wir perturben Kontextsätze in Weise, die relevante Struktur beibehalten, und fragen, ob Modelle gleichermaßen sensibel auf diese Sätze sind.

- Präfix/Suffix Adverbien: "However, &lt;sent&gt;."
- Langes Präfix Adverb: "First and foremost, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Regardless of what X thinks about it, &lt;sent&gt;."
- Zitat: "Yesterday, X said, ‘&lt;sent&gt;’."</sample>
    <sample id="592">Warum beeinflussen passende Präfixe die Urteile von LM?

Wir perturben Kontextsätze in Weise, die relevante Struktur beibehalten, und fragen, ob Modelle gleichermaßen sensibel zu diesen Sätzen sind.

- Präfix/Suffix Adverbien: "However, &lt;sent&gt;."
- Langes Präfix Adverb: "First and foremost, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Regardless of what X thinks about it, &lt;sent&gt;."
- Zitat: "Yesterday, X said, ‘&lt;sent&gt;’."

Modelle reagieren auf perturbierte Sätze in ähnlicher Weise.</sample>
    <sample id="593">Warum beeinflussen passende Präfixe die Urteile von LM-Modellen?

Wir perturben Kontextsätze in Weise, die relevante Struktur beibehalten, und fragen, ob Modelle gleichermaßen sensibel auf diese Sätze sind.

- Präfix/Suffix Adverbien: "However, &lt;sent&gt;."
- Langes Präfix Adverb: "First and foremost, &lt;sent&gt;."
- Hinzufügen einer Klammer: "Regardless of what X thinks about it, &lt;sent&gt;."
- Zitat: "Yesterday, X said, ‘&lt;sent&gt;’."

Modelle reagieren auf perturbierte Sätze in ähnlicher Weise.</sample>
    <sample id="594">### Schlüsselpunkte

- Sprachmodelle sind sensibel für latente syntaktische/semantische Merkmale, die sich über Sätze hinweg teilen.
- MPP-Evaluierungen mit kurzen, einzelnen Satz-Eingaben fangen nicht vollständig das abstrakte Wissen von LMs ein.</sample>
    <sample id="595">### Schlüsselpunkte

- Sprachmodelle sind sensibel für latente syntaktische/semantische Merkmale, die sich über Sätze hinweg teilen.
- MPP-Evaluierungen mit kurzen, einzelnen Satz-Eingaben fangen nicht vollständig das abstrakte Wissen von LMs ein.</sample>
    <sample id="596">### Schlüsselpunkte

- Sprachmodelle sind sensibel gegenüber latenten syntaktischen/semantischen Merkmalen, die sich über Sätze hinweg teilen.
- MPP-Evaluierungen mit kurzen, einzelnsatzbasierten Eingaben fangen nicht vollständig das abstrakte Wissen von LMs ein.</sample>
    <sample id="597">Die Input-Token werden im ersten Schritt der Methode mit einem Tag versehen, das aus einem Symbol und einem Zeichenkette besteht.</sample>
    <sample id="598">55,000 Skripte sind in Coscript vertreten.</sample>
    <sample id="626">Basierend auf den gegebenen Informationen im Bild, ist die beste Ausrichtungsmethode für DEplain "Sent-LaBSE" mit den besten Werten für Precision (P), Recall (R) und F1-Score in der 1:1-Kategorie.</sample>
    <sample id="627">Der Vorteil von schwach überwachtem Lernen (WSL) ist, dass man Modelle trainieren kann, die gut generalisieren, obwohl sie auf störenden Daten trainiert werden.</sample>
    <sample id="628">Die Dokumente in DEplain-web wurden mit einer Kombination von manuellen und automatischen Alignmentmethoden ausgerichtet.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde durch die Sammlung von Reuters-Nachrichten aus dem Jahr 2020 und die Annotierung mit den CoNLL-2003-Anmerkungsrichtlinien erstellt.</sample>
    <sample id="630">Der englische Text lautet:

"XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations"

Die Übersetzung ins Deutsche ist:

"XSemPLR: Korsprachige semantische Parsen in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen"</sample>
    <sample id="631">Semantische Parsen

- Semantische Parsen ist eine Aufgabe, um semantische Darstellungen von Nutzeraufträgen zu erstellen, wie z.B. SQL und Lambda-Kalkül.

Welche Länder in Europa haben mindestens 3 Automobilhersteller?

SELECT T1.country_name
FROM countries AS T1 JOIN continents AS T2 ON T1.continent = T2.cont_id
JOIN car_makers AS T3 ON T1.country_id = T3.country
WHERE T2.continent = 'Europe'
GROUP BY T1.country_name
HAVING COUNT(*) &gt;= 3

Was für Spieler haben weniger als drei Assists in einer Saison?

(call SW.listValue ( call
SW.getProperty ( ( lambda s ( call
SW.filter( var s ) ( call
SW.ensureNumericProperty ( string num_assists ) ) (string &lt; ) ( call
SW.ensureNumericEntity ( number 3 assist ) ) ) (call SW.domain (
string player ) ) ) ( string player )
) )</sample>
    <sample id="632">Der englische Text lautet:

"Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations"

Übersetzt ins Deutsche bedeutet das:

"Cross-lingual Semantic Parsing ist eine Aufgabe, die Abfragen in verschiedenen natürlichen Sprachen in mehrere Bedeutungsrepräsentationen übersetzt."</sample>
    <sample id="633">Der englische Text lautet:

"Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations"

Übersetzt ins Deutsche bedeutet das:

"Cross-lingual Semantic Parsing ist eine Aufgabe, die Abfragen in verschiedenen natürlichen Sprachen in mehrere Bedeutungsrepräsentationen übersetzt."</sample>
    <sample id="634">Der englische Text lautet:

"Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain natural language"

Übersetzt ins Deutsche:

"Kreuzsprachliche Semantische Parsen

- Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
  o Mangelnde Abdeckung bestimmter natürlicher Sprachen"</sample>
    <sample id="635">Der englische Text lautet:

"Cross-lingual Semantic Parsing
- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain natural language"

Übersetzt ins Deutsche:

"Kreuzsprachliche Semantische Parsen
- Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
  o Mangelnde Abdeckung bestimmter natürlicher Sprache"</sample>
    <sample id="636">Der englische Text lautet:

"Cross-lingual Semantic Parsing

• Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
○ Lack of coverage on certain meaning representation"

Übersetzt ins Deutsche:

"Kreuzsprachliche Semantische Parsen

• Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
○ Mangelnde Abdeckung bestimmter Bedeutungsrepräsentationen"</sample>
    <sample id="637">Der englische Text lautet:

"Cross-lingual Semantic Parsing

• Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
   o Lack of coverage on certain meaning representation"

Übersetzt auf Deutsch:

"Kreuzsprachliche Semantische Parsen

• Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
   o Mangelnde Abdeckung bestimmter Bedeutungsrepräsentationen"</sample>
    <sample id="638">Der englische Text lautet:

"Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain neural model"

Übersetzt ins Deutsche:

"Kreuzsprachliche Semantische Parsen

- Bestehende CLSP-Modelle werden getrennt vorgeschlagen und auf Datensätzen begrenzter Aufgaben und Anwendungen evaluiert. Zum Beispiel:
  o Mangelnde Abdeckung bestimmter neuronaler Modelle"</sample>
    <sample id="639">Wir stellen eine einheitliche Datenbank XSemPLR für die multilinguale semantische Parsen in verschiedenen natürlichen Sprachen und Bedeutungsrepräsentationen zur Verfügung. Sie enthält:

- 9 Datensätze in verschiedenen Domänen
- 5 semantische Parsen Aufgaben
- 8 Bedeutungsrepräsentationen
- 22 natürliche Sprachen aus 15 Sprachfamilien</sample>
    <sample id="640">Wir stellen eine einheitliche Datenbank XSemPLR zur multilingualen semantischen Parsierung in verschiedenen natürlichen Sprachen und Bedeutungsrepräsentationen bereit. Sie enthält:
- 9 Datensätze aus verschiedenen Bereichen,
- 5 semantische Parsing-Aufgaben,
- 8 Bedeutungsrepräsentationen,
- 22 natürliche Sprachen aus 15 Sprachfamilien.</sample>
    <sample id="641">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Translate-Test: Verwenden Sie die Google-Übersetzung-API, um die Quellsprache in die Zielsprache zu übersetzen. Danach verwenden Sie ein monolingualen Modell zum Trainieren und Testen.

Training

Inference

Deutsch

Englisch

Englischer Modell

SQL

Deutsch

Translate API

Englisch

Englischer Modell

SQL</sample>
    <sample id="642">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Translate-Test: Verwenden Sie die Google-Übersetzung-API, um die Quellsprache in die Zielsprache zu übersetzen. Danach verwenden Sie ein monolingualen Modell zum Trainieren und Testen.

Training

Inference

Deutsch

Englisch

Englischer Modell

SQL

Deutsch

Translate API

Englisch

Englischer Modell

SQL</sample>
    <sample id="643">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Trainings- und Evaluationsphase.
  ○ Translate-Test: Verwenden Sie die Google-Translate-API, um die Quellsprache in die Zielsprache zu übersetzen. Danach verwenden Sie einen monolingualen Modell zur Ausbildung und Bewertung.

Training

Inference

Deutsch

English Model

SQL

German

Translate API

English

English Model

SQL</sample>
    <sample id="644">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Bewertung.
  ○ Monolingual Model: Quellsprache ist die gleiche wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch den Monolingual Few-shot-Einstellung durch das Trainieren monolingualer Modelle mit nur 10% Trainingsdaten.

Training

- German (Few-shot)
  - German Model
  - SQL

Inferenz

- German
  - German Model
  - SQL</sample>
    <sample id="645">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Ausbildung und Bewertung.
  ○ Monolingual Model: Quellsprache ist die gleiche wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch das Monolingual Few-shot-Einstellung durch die Ausbildung monolingualer Modelle mit nur 10% Trainingsdaten.

Training

- German (Few-shot)
  - German Model
  - SQL

Inferenz

- German
  - German Model
  - SQL</sample>
    <sample id="646">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Monolingual Model: Quellsprache ist die gleiche wie Zielsprache, z.B. Deutsch-zu-Deutsch. Wir testen auch den Monolingual Few-shot-Einstellung durch das Trainieren monolingualer Modelle mit nur 10% Trainingsdaten.

Training
- German (Few-shot)
  - German Model
  - SQL

Inferenz
- German
  - German Model
  - SQL</sample>
    <sample id="647">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Ausbildung und Bewertung.
  o Multilingual Model: Trainiere ein multilinguales Modell für alle Sprachen.

Training

Inference

Deutsch
Englisch
Chinesisch
Multilingual Model
SQL

Deutsch
Multilingual Model
SQL</sample>
    <sample id="648">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Trainings- und Evaluationsphase.
  o Multilingual Model: Trainiere ein multilinguales Modell für alle Sprachen.

Training

Inference

- German
- English
- Chinese
- Multilingual Model
- SQL</sample>
    <sample id="649">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Ausbildung und Bewertung.
  o Multilingual Model: Trainiere ein multilinguales Modell für alle Sprachen.

Training
- German
- English
- Chinese
  Multilingual Model
  SQL

Inferenz
- German
  Multilingual Model
  SQL</sample>
    <sample id="650">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für das Training und die Evaluation.
  ○ Cross-lingual Zero-shot/Few-shot Transfer: Trainieren auf einer Quellensprache und übertragen auf eine andere Sprache.

Training
- Englisch oder
- Englisch und German Few-shot
- Multilingualer Modell
- SQL

Inferenz
- German
- Multilingualer Modell
- SQL</sample>
    <sample id="651">Experimenteinstellungen

- Wir betrachten sechs Einstellungen für die Ausbildung und Bewertung.
  ○ Cross-lingual Zero-shot/Few-shot Transfer: Ausbildung auf einer Quellensprache und Transfer zu einer anderen Sprache.

Training
- Englisch oder
- Englisch
- Deutsches Few-shot
- Multilingualer Modell
- SQL

Inferenz
- Deutsches
- Multilingualer Modell
- SQL</sample>
    <sample id="652">Analyse der Monolingualen Sprachaufgaben

- Wir evaluieren zwei Gruppen von Modellen im Monolingual Setting.
  - Enc-PTR: Multilinguale Prätrainierte Encoder mit Pointer-basierten Decoder
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilinguale Prätrainierte Encoder-Decoder Modelle
    - mBART, mT5

- Wir fanden heraus, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht!</sample>
    <sample id="653">Analyse der Monolingualen Daten

- Wir evaluieren zwei Gruppen von Modellen im Monolingual Setting.
  - Enc-PTR: Multilinguale Prätrainierte Encoder mit Pointer-basierten Decoder
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilinguale Prätrainierte Encoder-Decoder Modelle
    - mBART, mT5

- Wir fanden heraus, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht!</sample>
    <sample id="654">**Analyse des Monolingualen**

- Wir evaluieren zwei Gruppen von Modellen im **Monolingual Setting**
  - Enc-PTR: Multilinguale Prätrainierte Encoder mit Pointer-basierten Decoder
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilinguale Prätrainierte Encoder-Decoder Modelle
    - mBART, mT5

- Wir fanden, dass Enc-Dec (mT5) die beste Performance auf allen Datensätzen erreicht!</sample>
    <sample id="655">**Analyse der Monolingualen Daten**

- Wir evaluieren zwei Gruppen von Modellen im **Monolingual Setting**
  - Enc-PTR: Multilinguale Prätrainierte Encoder mit Pointer-basierten Decoder
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilinguale Prätrainierte Encoder-Decoder Modelle
    - mBART, mT5

- Wir fanden, dass Enc-Dec (mT5) die beste Leistung auf allen Datensätzen erreicht!</sample>
    <sample id="656">Analyse des multilingualen Trainings

- Wir evaluieren mT5 und XLM-R + PTR im multilingualen Setting.
  - Enc-Dec/Enc-PTR (mT5/XLM-R) kann durch Training in einer Mischung verschiedener Sprachen verbessert werden.

Tabelle:

| Monolingual |
|-------------|
| XLM-R+PTR   | MATIS: 31.31, MGeoQuery: 71.41, MSpider: 47.30, MNLmaps: 85.17, MOvernight: 59.10, MCWQ: 23.53, MSchema2QA: 62.37, MTOP: 80.36, MCoNaLa²: 7.69, Durchschnitt: 52.03 |
| mT5         | MATIS: 53.15, MGeoQuery: 74.26, MSpider: 50.73, MNLmaps: 91.65, MOvernight: 66.29, MCWQ: 30.15, MSchema2QA: 65.16, MTOP: 81.83, MCoNaLa²: 10.29, Durchschnitt: 58.16 |

| Multilingual |
|-------------|
| XLM-R+PTR   | MATIS: 39.72, MGeoQuery: 71.35, MSpider: 40.20, MNLmaps: 85.91, MOvernight: 61.03, MCWQ: 30.79, MSchema2QA: 61.82, MTOP: 81.68, MCoNaLa²: –, Durchschnitt: 59.06 |
| mT5         | MATIS: 54.45, MGeoQuery: 76.57, MSpider: 32.30, MNLmaps: 91.31, MOvernight: 67.55, MCWQ: 28.51, MSchema2QA: 60.92, MTOP: 82.95, MCoNaLa²: –, Durchschnitt: 61.82 |

13</sample>
    <sample id="657">Analyse des multilingualen Trainings

- Wir evaluieren mT5 und XLM-R + PTR im multilingualen Setting.
  - Enc-Dec/Enc-PTR (mT5/XLM-R) kann durch Training in einer Mischung verschiedener Sprachen verbessert werden.

Tabelle:

| Monolingual |
|-------------|
| XLM-R+PTR   | MATIS: 31.31, MGeoQuery: 71.41, MSpider: 47.30, MNLmaps: 85.17, MOvernight: 59.10, MCWQ: 23.53, MSchema2QA: 62.37, MTOP: 80.36, MCoNaLa²: 7.69, Durchschnitt: 52.03 |
| mT5         | MATIS: 53.15, MGeoQuery: 74.26, MSpider: 50.73, MNLmaps: 91.65, MOvernight: 66.29, MCWQ: 30.15, MSchema2QA: 65.16, MTOP: 81.83, MCoNaLa²: 10.29, Durchschnitt: 58.16 |

| Multilingual |
|-------------|
| XLM-R+PTR   | MATIS: 39.72, MGeoQuery: 71.35, MSpider: 40.20, MNLmaps: 85.91, MOvernight: 61.03, MCWQ: 30.79, MSchema2QA: 61.82, MTOP: 81.68, MCoNaLa²: –, Durchschnitt: 59.06 |
| mT5         | MATIS: 54.45, MGeoQuery: 76.57, MSpider: 32.30, MNLmaps: 91.31, MOvernight: 67.55, MCWQ: 28.51, MSchema2QA: 60.92, MTOP: 82.95, MCoNaLa²: –, Durchschnitt: 61.82 |</sample>
    <sample id="658">Analyse des multilingualen Trainings

- Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting
  - Die meisten der wichtigsten Sprachen können eine Leistungssteigerung erzielen, außer dass die Leistung in 7 Datensätzen sinkt und in 3 Datensätzen steigt. Dies wird als "Fluch der Multilinguistik" bezeichnet.</sample>
    <sample id="659">Analyse des multilingualen Trainings

- Wir evaluieren auf mT5 und XLM-R + PTR im multilingualen Setting
  - Die meisten der wichtigsten Sprachen können eine Leistungssteigerung erzielen, außer dass die Leistung in 7 Datensätzen sinkt und in 3 Datensätzen steigt. Dies wird als "Fluch der Multilinguistik" bezeichnet.

Histogramm: Anzahl der Datensätze
- Englisch (en): 2 Datensätze sinken, 8 Datensätze steigen
- Deutsch (de): 6 Datensätze sinken, 4 Datensätze steigen
- Chinesisch (zh): 4 Datensätze sinken, 6 Datensätze steigen
- Thai (th): 3 Datensätze sinken, 7 Datensätze steigen
- Farsi (fa): 4 Datensätze sinken, 6 Datensätze steigen
- El (el): 3 Datensätze sinken, 7 Datensätze steigen
- Indonesisch (id): 3 Datensätze sinken, 7 Datensätze steigen
- Schwedisch (sv): 3 Datensätze sinken, 7 Datensätze steigen
- Spanisch (es): 2 Datensätze sinken, 8 Datensätze steigen
- Französisch (fr): 1 Datensatz sinkt, 9 Datensätze steigen</sample>
    <sample id="660">Cross-lingual Performance Gap

- Blaue Linie: Cross-lingual Few-shot Transfer
- Orange Linie: Cross-lingual Zero-shot Transfer
- Grüne Linie: Monolingual Setting

Die Grafik zeigt die Leistungsdifferenz zwischen verschiedenen Sprachaufgaben (Geoquery, MTOP, Schema2QA, etc.) in Abhängigkeit von der Anzahl der gegebenen Beispiele (Few-shot, Zero-shot) und dem monolingualen Kontext.</sample>
    <sample id="661">Cross-lingual Performance Gap

- Blaue Linie: Cross-lingual Few-shot Transfer
- Orange Linie: Cross-lingual Zero-shot Transfer
- Grüne Linie: Monolingual Setting</sample>
    <sample id="662">Cross-lingual Performance Gap

- grün - orange Für den null-Shot-Einstellung, der cross-lingual Transfer Leistungssprung ist signifikant.
- blau - orange Für den wenigen-Shot-Einstellung, der Transfer-Sprung wird schnell verkürzt.

Cross-lingual Performance Gap

- grün - orange Für den null-Shot-Einstellung, der cross-lingual Transfer Leistungssprung ist signifikant.
- blau - orange Für den wenigen-Shot-Einstellung, der Transfer-Sprung wird schnell verkürzt.</sample>
    <sample id="663">### Andere Ergebnisse &amp; Erkenntnisse (Abschnitt 4 im Papier)

- Enc-Dec (mT5) übertrifft vorherige Arbeiten oder erreicht vergleichbare Ergebnisse.
- Vortraining auf dem Englischen NL kann die Leistung von few-shot auf Ziellangschaften signifikant verbessern.
- Multilinguale LLMs (Codex &amp; BLOOM) sind für krosslinguale semantische Parsingsaufgaben immer noch unzureichend.
- Chinesische Transfer-Learning und Englisch monolingualer Training (En -&gt; En) haben den größten Leistungsabstand, während German üblicherweise den kleinsten hat.
- FunQL übertrifft die anderen drei Bedeutungsrepräsentationen, und SQL erzielt das schlechteste Ergebnis.</sample>
    <sample id="664">### Andere Ergebnisse &amp; Erkenntnisse (Abschnitt 4 im Papier)

- Enc-Dec (mT5) übertrifft vorherige Arbeiten oder erreicht vergleichbare Ergebnisse.
- Vorkonditionierung auf Englisch-NL kann die Leistung von few-shot auf Ziellangschaften signifikant verbessern.
- Multilinguale LLMs (Codex &amp; BLOOM) sind für krosslinguale semantische Parsingsaufgaben immer noch unzureichend.
- Chinesische Transfer-Learning und Englisch-monolingualer Training (En -&gt; En) haben den größten Leistungsabstand, während Deutsch üblicherweise den kleinsten hat.
- FunQL übertrifft die anderen drei Bedeutungsrepräsentationen, und SQL erzielt das schlechteste Ergebnis.</sample>
    <sample id="665">### Schlussfolgerung

- Wir haben XSemPLR, ein einheitliches Benchmark für die Übersetzungssemantik mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen, erstellt.
- Wir führen eine umfassende Benchmark-Studie auf drei repräsentativen Typen multilingualer Sprachmodelle durch.
- Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Ausbildung die beste Leistung erzielt, während multilinguale LLMs immer noch unzureichend sind, um Übersetzungssemantik-Aufgaben auszuführen. Zudem ist der Leistungsunterschied zwischen monolingualer Ausbildung und cross-lingualer Transfer-Learning immer noch signifikant.</sample>
    <sample id="666">### Schlussfolgerung

- Wir haben XSemPLR, ein einheitliches Benchmark für die krooss-linguale semantische Parsen mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen, erstellt.
- Wir führen eine umfassende Benchmark-Studie auf drei repräsentativen Typen von multilingualen Sprachmodellen durch.
- Unsere Ergebnisse zeigen, dass mT5 mit monolingualer Ausbildung die beste Leistung erzielt, während offensichtlich multilingual ausgebildete LLMs noch nicht in der Lage sind, krooss-linguale semantische Parsen Aufgaben auszuführen. Zudem ist der Leistungsunterschied zwischen monolingualer Ausbildung und krooss-lingualer Transfer-Learning immer noch signifikant.

### Links

Willkommen, um unsere Arbeit und den Code zu besuchen!

Papier-Link: [https://arxiv.org/pdf/2306.04085.pdf](https://arxiv.org/pdf/2306.04085.pdf)

Code-Link: [https://github.com/psunlpgroup/xsemplr](https://github.com/psunlpgroup/xsemplr)</sample>
    <sample id="667">Die bereits durchgeführten Arbeiten umfassen Parameter-basierte Wasserzeichen, Lexikalische Wasserzeichen, Rücktür-basierte Wasserzeichen und Adversarial-basierte Wasserzeichen.</sample>
    <sample id="668">Nein, sie sind noch nicht ausreichend für CLSP.</sample>
    <sample id="695">Die Methode löst die Mehrdeutigkeit der Permutationen durch das Induzieren in der Trainingphase und das Backpropagation durch kontinuierliche Relaxation.</sample>
    <sample id="696">Die Fairness eines nachgeschalteten NLP-Modells wird durch die Analyse von Hate Speech Texten und Misinformation Texten definiert, wobei unterschiedliche politische Leitlinien (N-L, R-L, N-R, R-R) berücksichtigt werden.</sample>
    <sample id="697">Yanis Labrak</sample>
    <sample id="698">Der Referent ist Koustuv Sinha.</sample>
    <sample id="699">Myra Cheng, Esin Durmus, Dan Jurafsky</sample>
    <sample id="700">Tropikalismus bezieht sich in diesem Zusammenhang darauf, dass bestimmte Gruppen nur durch ihre Identität definiert werden, was zu einer anderen Darstellung führt.</sample>
    <sample id="701">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen durch "essentializing narratives" erstellt, was bedeutet, dass sie diese nur durch ihre Identität definiert haben.</sample>
    <sample id="702">In dieser Arbeit wurde P-CXMI (Pointwise Contextualized Mutual Information) zur Messung der Kontextnutzung verwendet.</sample>
    <sample id="703">Der Unterschied zwischen DrBERT und ChuBERT liegt in der Quelle des Trainingsmaterials. DrBERT wird von einem großen öffentlichen Datensatz (NACHOSlarge) trainiert, während ChuBERT von einem privaten Datensatz (NBDWsmall) trainiert wird.</sample>
    <sample id="751">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="752">Iteratives Transferlernen bezieht sich auf das Aktualisieren eines Modells durch die Verwendung neuer Daten, während das alte Modell weiterhin verwendet wird. Dieser Prozess wird iterativ wiederholt, um das Modell zu verbessern.</sample>
    <sample id="753">Das Ziel des Datensatzes ist, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen.</sample>
    <sample id="754">Die genaue Methode, wie ein Angreifer Modellparameter über einen EaaS (Embedded AI as a Service) extrahieren kann, wird in dem Video nicht detailliert erklärt. Es wird jedoch erwähnt, dass es möglich ist, Modelle zu trainieren, um diese Parameter zu extrahieren.</sample>
    <sample id="755">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="756">Es wird nicht explizit angegeben, wie viele Annotatoren verwendet wurden, um den ursprünglichen Datensatz zu erstellen.</sample>
    <sample id="757">Die Autoren gehören an die University of Washington und Carnegie Mellon University.</sample>
    <sample id="758">"I saw Bart and Lisa; Homer came and sneezed"</sample>
    <sample id="759">Der Stand der Technik für Dialogsysteme umfasst Coherence, Knowledge, Consistency und Emotional Understanding.</sample>
    <sample id="760">Um sicherzustellen, dass die Modelle ihre Entscheidungen nicht nur auf den aktuellen Kontext, sondern auch auf den langen Vorgängerkontext basieren.</sample>
    <sample id="761">Ja, das mehrsprachige Training hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell in 7 Datensätzen geführt.</sample>
    <sample id="762">Nein, die Annotatoren sollen die Entität nicht im Voraus kennen. Sie sollen die Songs hören und über sie lesen, um die Entität zu identifizieren.</sample>
    <sample id="763">Die genannten MT-Metriken sind BLEU, METEOR, ROUGE und CHRF.</sample>
    <sample id="764">Ja, die Regression wirkt sich negativ auf die Generalisierung auf bestimmte NER-Typen aus.</sample>
    <sample id="765">Positionalität ist für NLP wichtig, weil sie den Kontext und die Bedeutung von Wörtern in einem Satz berücksichtigt, was zu präziseren und kontextuellen Verständnis führt.</sample>
    <sample id="766">Die Frage bezieht sich auf die Anpassung von mehrsprachigen LLMs wie BLOOM, was nicht im gezeigten Bild dargestellt ist. Das Bild beschreibt das Konzept des Cross-lingual Semantic Parsing und zeigt keine spezifischen Informationen über die Anpassungsmethoden von LLMs.</sample>
    <sample id="767">RoBERTA-base + classifier head</sample>
    <sample id="768">Die aktuellen Testsets, die zur Bewertung der PaLM-Fähigkeiten verwendet wurden, sind nicht direkt im Bild zu sehen. Das Bild zeigt lediglich Beispiele für die Übersetzung von deutschen Texten ins Englische. Für eine genaue Antwort auf Ihre Frage müssten weitere Informationen oder Quellen über die verwendeten Testsets herangezogen werden.</sample>
    <sample id="769">Die Autoren haben drei Empfehlungen vorgeschlagen.</sample>
    <sample id="770">Der Gewinn der vorgeschlagenen Methode gegenüber der stärksten Baseline beträgt 10%.</sample>
    <sample id="771">Der Referent ist Shuheng Liu.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark verwendet werden.</sample>
    <sample id="773">In der Arbeit werden zwei kleinere Modelle experimentiert: Codex (175B) und T5 trained on Coscript.</sample>
    <sample id="774">Das OFA-Modell wird als Basismodell für die Untersuchung der multimodalen Unterrichtsabstimmung verwendet.</sample>
    <sample id="833">Die Autoren gehören der Google-Universität an, da das Logo von Google oben links im Bild zu sehen ist.</sample>
    <sample id="834">Die Autoren gehören der Stony Brook University an.</sample>
    <sample id="835">Die Frage bezieht sich auf spezifische Sprachpaare, die in der Arbeit untersucht wurden. Da das Bild keine genauen Sprachpaare nennt, kann ich diese nicht bestimmen.</sample>
    <sample id="836">Der Referent ist Shangbin Feng.</sample>
    <sample id="837">Die Modelle, die während der Experimente untersucht wurden, sind DEplain-APA, DEplain-web, DEplain-APA+web und src2src-baseline.</sample>
    <sample id="838">53 Aufgaben werden für das Training verwendet, und 9 Aufgaben werden für die Tests verwendet.</sample>
    <sample id="839">Es sind drei Autoren an der Arbeit beteiligt: Regina Stodden, Omar Momen und Laura Kallmeyer.</sample>
    <sample id="840">Die Autoren haben ihre Experimente an den folgenden Datensätzen durchgeführt: AG News, MIND, SST2, Enron Spam und WikiText.</sample>
    <sample id="876">NACHOS ist ein Modell, das im Zusammenhang mit der Evaluierung von 13 Modellen auf 11 Aufgaben genannt wird.</sample>
    <sample id="877">Der Referent ist David Vilar Torres.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse.</sample>
    <sample id="879">Die Autoren gehören der Carnegie Mellon University an.</sample>
    <sample id="880">Die Frage bezieht sich auf die genannten 5 Anweisungen, die jedoch nicht im gegebenen Bildtext enthalten sind. Der Text spricht von einem zusätzlichen multimodalen Trainingsdatensatz mit etwa 150 weiteren visuell-linguistischen Aufgaben, die bald veröffentlicht werden sollen. Es gibt keine spezifischen 5 Anweisungen der Expert*innen im Bildtext.</sample>
    <sample id="881">Die Autoren schlagen vor, Modelle mit einer Dataset für Wissensintegrationsevaluation und einem Coreference-Resolution-Aufgaben zu testen, um ihre Fähigkeit zu prüfen, Informationen aus verschiedenen Quellen zu nutzen.</sample>
    <sample id="882">Der englische Text lautet:

"Prompting PaLM for Translation
Assessing Strategies and Performance"

Übersetzt ins Deutsche bedeutet das:

"Prompten von PaLM für Übersetzung
Beurteilung von Strategien und Leistung"</sample>
    <sample id="883">PaLM: Pfadwege-Sprachmodell

- Chowdery et al., 2022
- arXiv:2204.02311.
- 540 Milliarden Parameter.
- Trainiert auf 780 Milliarden Tokens.
- Dicht aktiviert.
- 6144 TPU v4 Chips.
- SOTA in hunderten von LMU und Generation Benchmarks.

Die Grafik zeigt ein Baumdiagramm mit verschiedenen Kategorien wie Fragebeantwortung, Arithmetik, Code-Vollständigkeit, Allgemeinwissen, Zusammenfassung, Sprachverstehen, Logische Inferenzketten, Alltagsvernunft, Mustererkennung, Übersetzung, Dialoge, Witzinterpretationen und Physikfragen.</sample>
    <sample id="884">PaLM: Pfadwege-Sprachmodell

- Chowdery et al., 2022
- arXiv:2204.02311.
- 540 Milliarden Parameter.
- Trainiert auf 780 Milliarden Tokens.
- Dicht aktiviert.
- 6144 TPU v4 Chips.
- SOTA in hunderten von LMU und Generation Benchmarks.

Das Bild zeigt ein Baumdiagramm mit verschiedenen Kategorien wie Fragebeantwortung, Arithmetik, Übersetzung, Zusammenfassung, Sprachverstehen usw., die alle 540 Milliarden Parameter umfassen.</sample>
    <sample id="885">Unsere Beiträge

- Erste systematische Studie zur Prompting von LLM für MT.
  - Für die Kandidatenpool sowie die Auswahlstrategie.

- Evaluierung der Übersetzungsleistungen mit den besten Praktiken der MT-Gemeinschaft:
  - Neueste Testsets (um Verzahnung von Trainings- und Testdaten zu vermeiden und Überfitting auf Evaluationsdaten zu verhindern).
  - Vergleich mit den neuesten WMT-Beitragen (SOTA-Systeme verwenden das neueste Trainingssample).
  - SOTA-MT-Metriken (bessere Korrelation mit menschlichen Urteilen).
  - Expertenbasierte menschliche Bewertung (mehr robust als crowd workers).

- Empfehlungen für Promptauswahlstrategien</sample>
    <sample id="886">Unsere Beiträge

- Erste systematische Studie zur Prompting von LLM für MT.
  - Für das Kandidatenpool sowie die Selektionsstrategie.

- Evaluierung der Übersetzungsleistungen mit den besten Praktiken der MT-Gemeinschaft:
  - Neueste Testsets (um Verlängerung von Trainingsdaten und Überfitting auf Evaluationsdaten zu vermeiden).
  - Vergleich mit den neuesten WMT-Einreichungen (SOTA-Systeme verwenden die neuesten Trainingsdaten).
  - SOTA-MT-Metriken (bessere Korrelation mit menschlichen Urteilen).
  - Expertenbasierte menschliche Bewertung (mehr robust als crowd workers).

- Empfehlungen für Prompt-Selbststrategien</sample>
    <sample id="887">Unsere Beiträge

- Erste systematische Studie zur Prompting von LLM für MT.
  - sowohl für die Kandidatenpool als auch für die Selektionsstrategie.

- Evaluierung der Übersetzungsleistungen mit den besten Praktiken der MT-Gemeinschaft:
  - Neueste Testsets (um Verzahnung von Trainings- und Testdaten zu vermeiden und Überfitting auf Evaluationsdaten zu verhindern).
  - Vergleich mit den neuesten WMT-Beitragen (SOTA-Systeme verwenden das neueste Trainingsdaten).
  - SOTA-MT-Metriken (bessere Korrelation mit menschlichen Urteilen).
  - Expertenbasierte menschliche Bewertung (mehr robust als crowd workers).

- Empfehlungen für Prompt-Selbststrategien</sample>
    <sample id="888">Unsere Beiträge

- Erste systematische Studie zur Prompting von LLM für MT.
  - Für das Kandidatenpool sowie die Auswahlstrategie.

- Evaluierung der Übersetzungsleistungen mit den besten Praktiken der MT-Gemeinschaft:
  - Neueste Testsets (um Verzahnung von Trainings- und Testdaten zu vermeiden und Überfitting auf Evaluationsdaten zu verhindern).
  - Vergleich mit den neuesten WMT-Einreichungen (SOTA-Systeme verwenden die neuesten Trainingsdaten).
  - SOTA-MT-Metriken (bessere Korrelation mit menschlichen Urteilen).
  - Expertenbasierte menschliche Bewertung (mehr robust alscrowd workers).

- Empfehlungen für Promptauswahlstrategien</sample>
    <sample id="889">Die Folie enthält den folgenden Text auf Englisch:

"Prompts have a big impact on translation quality
- Select two random prompts for each sentence.
- Compute BLEURT for each sentence-prompt pair.
- The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point.
- The difference can go up to 40 BLEURT points!"

Übersetzt ins Deutsche:

"Prompts haben einen großen Einfluss auf die Übersetzungsqualität
- Wählen Sie für jede Satz zwei zufällige Prompts aus.
- Berechnen Sie BLEURT für jedes Satz-Prompt-Paar.
- Die meisten Sätze (516 von 1000) zeigen eine Differenz von mehr als 1 BLEURT-Punkt.
- Die Differenz kann bis zu 40 BLEURT-Punkte betragen!"</sample>
    <sample id="890">Die englischen Inhalte lauten:

- Prompts haben einen großen Einfluss auf die Übersetzungsqualität.
  - Wählen Sie zwei zufällige Prompts für jede Satz.
  - Berechnen Sie BLEURT für jedes Satz-Prompt-Paar.
  - Die meisten Sätze (516 von 1000) zeigen eine Differenz von mehr als einem BLEURT-Punkt.
  - Die Differenz kann bis zu 40 BLEURT-Punkte betragen!</sample>
    <sample id="891">Die folgenden Punkte sind die Übersetzung des englischen Inhalts in Deutsch:

- Prompts haben einen großen Einfluss auf die Übersetzungskonstanz.
  - Wählen Sie zwei zufällige Prompts für jede Satz.
  - Berechnen Sie BLEURT für jedes Satz-Prompt-Paar.
  - Die meisten Sätze (516 von 1000) zeigen eine Differenz von mehr als einem BLEURT-Punkt.
  - Die Differenz kann bis zu 40 BLEURT-Punkte betragen!</sample>
    <sample id="892">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. "He is being transported under the custody of two policemen on a bus from the jail."
   - "Er wird unter Aufsicht von zwei Polizisten auf einem Bus aus der Haft transportiert."

2. "Police were called in after receiving complaints from the office."
   - "Die Polizei wurde alarmiert, nachdem Beschwerden vom Büro eingingen."

3. "A passerby alerted the police, who then arrived with several patrol cars."
   - "Ein Passant alarmierte die Polizei, die daraufhin mit mehreren Streifenwagen eintrafen."</sample>
    <sample id="893">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. "He is being transported under the custody of two policemen on a bus from the jail."
   - "Er wird unter Aufsicht von zwei Polizisten auf einem Bus aus der Haft transportiert."

2. "Police were called in after receiving complaints from the office."
   - "Die Polizei wurde alarmiert, nachdem Beschwerden vom Büro eingingen."

3. "A passerby alerted the police, who responded with several patrol units."
   - "Ein Passant alarmierte die Polizei, die mit mehreren Streifenwagen reagierte."</sample>
    <sample id="894">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. "He is being transported under the custody of two policemen on a bus from the jail."
   - "Er wird unter der Aufsicht von zwei Polizisten auf einem Bus aus dem Gefängnis transportiert."

2. "Police were called in after receiving complaints from the office."
   - "Die Polizei wurde alarmiert, nachdem Beschwerden vom Büro eingingen."

3. "Ein Passant alarmed the police, who responded with several patrol units."
   - "Ein Zuschauer alarmierte die Polizei, die mit mehreren Streifenwagen reagierte."</sample>
    <sample id="895">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. "He is being transported under the custody of two policemen on a bus from the jail."
   - "Er wird unter der Aufsicht von zwei Polizisten auf einem Bus aus dem Gefängnis transportiert."

2. "Police were called in after receiving complaints from the office."
   - "Die Polizei wurde alarmiert, nachdem Beschwerden vom Büro eingingen."

3. "A passerby alerted the police, who then arrived with several patrol cars."
   - "Ein Passant alarmierte die Polizei, die daraufhin mit mehreren Streifenwagen eintrafen."</sample>
    <sample id="896">Natürlich! Hier ist die Übersetzung des englischen Inhalts ins Deutsche:

1. "He is being transported under the custody of two policemen on a bus from the jail."
   Übersetzung: "Er wird unter der Aufsicht von zwei Polizisten auf einem Bus aus dem Gefängnis transportiert."

2. "Police were called in after receiving complaints from the office."
   Übersetzung: "Die Polizei wurde alarmiert, nachdem Beschwerden vom Büro eingingen."

3. "Ein Passant alarmed the police, who responded with several patrol units."
   Übersetzung: "Ein Zuschauer alarmierte die Polizei, die mit mehreren Streifenwagen reagierte."</sample>
    <sample id="897">Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind im Allgemeinen niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist im Allgemeinen für PaLM niedriger.</sample>
    <sample id="898">Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zur Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

Erkenntnisse aus MQM:
- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="899">Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zur Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

Erkenntnisse aus MQM:
- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="900">Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

Erkenntnisse aus MQM:
- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="901">Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

Erkenntnisse aus MQM:
- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="902">Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind im Allgemeinen niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist im Allgemeinen für PaLM niedriger.</sample>
    <sample id="903">Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

Erkenntnisse aus MQM:

- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind generell niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist generell für PaLM niedriger.</sample>
    <sample id="904">Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

Erkenntnisse aus MQM:
- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind im Allgemeinen niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist im Allgemeinen für PaLM niedriger.</sample>
    <sample id="905">Experimentelle Ergebnisse

- Beispielqualität ist wichtiger als Ähnlichkeit zum Quellsatz.
- Spezialisierte SOTA-Systeme haben einen erheblichen Vorteil.
- PaLM ähnelt Google Translate.

Erkenntnisse aus MQM:
- Die Fluideität von PaLM ist vergleichbar mit SOTA.
- Genauigkeitswerte sind im Allgemeinen niedriger.
  - Dominiert durch "Genauigkeit/Verlust"
- "Stil/Aufwändigkeit" ist im Allgemeinen für PaLM niedriger.</sample>
    <sample id="906">Der englische Text "thank you" wird in verschiedenen Sprachen übersetzt:

- danke (Deutsch)
- 謝謝 (chinese)
- ngiyabonga (isiXhosa)
- teşekkür ederim (Türkisch)
- شكراً جزيلاً (arabisch)
- спасибо (russisch)
- спасиби (bulgarisch)
- kiitos (finnisch)
- thank you (Englisch)
- vinaka (fidschian)
- mersi (swahili)
- kia barka (arabisch)
- welalin (amharisch)
- dank je (niederländisch)
- misaotra (malagasy)
- matondo (swahili)
- paldies (lettisch)
- grazzi (italienisch)
- mahalo (hawaiisch)
- tanadh leat (gälisch)
- xhwała (serbokroatisch)
- asante manana (swahili)
- obrigado (portugiesisch)
- bedankt (niederländisch)
- dziękuję (polnisch)
- obrigado (portugiesisch)
- merci (französisch)
- 감사합니다 (koreanisch)
- terima kasih (indonesisch)
- xiexie (chinesisch)
- tanemirt rahmet (arabisch)
- grazie (italienisch)
- arigato (japanisch)
- takk (norwegisch)
- dakujem (kroatisch)
- trugarez (katalanisch)</sample>
    <sample id="907">Der englische Text lautet:

"Saarland University
LST DEPARTMENT OF LANGUAGE SCIENCE AND TECHNOLOGY SAARLAND UNIVERSITY
universität wien

Weaker Than You Think
A Critical Look at Weakly Supervised Learning

Dawei Zhu1 Xiaoyu Shen2 Marius Mosbach1 Andreas Stephan3 Dietrich Klakow1

1 Saarland University 2 Amazon Alexa 3 University of Vienna

61st ACL 2023"

Übersetzt ins Deutsche:

"Saarland University
LST Abteilung für Sprachwissenschaft und Technologie, Saarland University
Universität Wien

Schwächer als du denkst
Eine kritische Betrachtung von schwach überwachtem Lernen

Dawei Zhu1 Xiaoyu Shen2 Marius Mosbach1 Andreas Stephan3 Dietrich Klakow1

1 Saarland University 2 Amazon Alexa 3 University of Vienna

61. ACL 2023"</sample>
    <sample id="908">Der englische Text lautet:

"Saarland University
LST DEPARTMENT OF LANGUAGE SCIENCE AND TECHNOLOGY SAARLAND UNIVERSITY
universität wien

Weaker Than You Think
A Critical Look at Weakly Supervised Learning

Dawei Zhu1 Xiaoyu Shen2 Marius Mosbach1 Andreas Stephan3 Dietrich Klakow1

1 Saarland University 2 Amazon Alexa 3 University of Vienna

61st ACL 2023"

Übersetzt ins Deutsche:

"Saarland University
LST Abteilung für Sprachwissenschaft und Technologie, Saarland University
Universität Wien

Schwächer als du denkst
Eine kritische Betrachtung von schwach überwachtem Lernen

Dawei Zhu1 Xiaoyu Shen2 Marius Mosbach1 Andreas Stephan3 Dietrich Klakow1

1 Saarland University 2 Amazon Alexa 3 University of Vienna

61. ACL 2023"</sample>
    <sample id="909">Warum weakly supervised Learning?

- Weak supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Weakly supervised Learning (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmem Datenmaterial trainiert werden.</sample>
    <sample id="910">Warum weakly supervised Learning?

- Weak supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Weakly supervised learning (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmem Datenmaterial trainiert wurden.</sample>
    <sample id="911">Warum weakly supervised Learning?

- Weak supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Weakly supervised Learning (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmem Datenmaterial trainiert werden.</sample>
    <sample id="912">Warum weakly supervised Learning?

- Weak supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Weakly supervised Learning (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmem Datenmaterial trainiert wurden.</sample>
    <sample id="913">Warum weakly supervised Learning?

- Weak supervision lindert den Annotierungsengpass.
- Aber schwache Labels sind laut!
  - Lärm im Gedächtnis schadet der Generalisierung.
- Weakly supervised Learning (WSL)
  - Trainiere Modelle, die trotzdem gut generalisieren, obwohl sie auf lahmem Datenmaterial trainiert werden.</sample>
    <sample id="914">Ein häufiger Behauptung in neueren WSL Arbeiten

"Wir trainieren Modelle nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."</sample>
    <sample id="915">Ein häufiger Behauptung in neueren WSL Arbeiten lautet:

"Wir trainieren Modelle nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."

Unten sind zwei Grafiken zu sehen:
- Links: "Schwach etikettierte Trainingsdaten (ungeordnet)"
- Rechts: "Rein etikettierte Testdaten (geordnet)"</sample>
    <sample id="916">Ein häufiger Behauptung in neueren WSL Arbeiten

"Wir trainieren Modelle nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."</sample>
    <sample id="917">Ein häufiger Behauptung in neueren WSL Arbeiten

"Wir trainieren Modelle nur auf schwach überwachten Daten und erreichen eine Genauigkeit von XX%."</sample>
    <sample id="918">Unsere Forschungsfragen

RQ1: Ist sauberes Validierungsdaten notwendig?

RQ2: Wie viele saubere Proben benötigen WSL-Ansätze?

RQ3: Wie kann man die verfügbaren sauberen Proben effizienter nutzen?</sample>
    <sample id="919">Unsere Forschungsfragen

RQ1: Ist sauberes Validierungsdaten notwendig?

RQ2: Wie viele saubere Proben benötigen WSL-Ansätze?

RQ3: Wie kann man die verfügbaren sauberen Proben effizienter nutzen?</sample>
    <sample id="920">RQ1 Hauptergebnisse

Relative Leistungsverbesserung gegenüber schwachen Labels (%)

- Validierung auf schwachen Labels (orange)
- Keine Validierung (Zufällige Auswahl) (lila)
- Validierung auf sauberen Labels (grün)</sample>
    <sample id="921">RQ1 Hauptergebnisse

Relative Leistungsverbesserung gegenüber schwachen Labels (%)

- Validierung auf schwachen Labels (orange)
- Keine Validierung (Zufällige Auswahl) (lila)
- Validierung auf sauberen Labels (grün)</sample>
    <sample id="922">RQ1 Hauptergebnisse

Relative Leistungsverbesserung gegenüber schwachen Labels (%)</sample>
    <sample id="923">RQ1 Hauptergebnisse

Relative Leistungsverbesserung gegenüber schwachen Labels (%)

- Validierung auf schwachen Labels (orange Kreise)
- Keine Validierung (Zufällige Auswahl) (lila Kreise)
- Validierung auf sauberen Labels (grüne Kreise)</sample>
    <sample id="924">RQ1 Hauptergebnisse

Ein sauberer Validationsdatensatz ist unentbehrlich.</sample>
    <sample id="925">Der englische Text lautet "RQ2 Main findings". Dies bedeutet "RQ2 Hauptergebnisse" auf Deutsch.</sample>
    <sample id="926">RQ2 Hauptergebnisse

Der Graph zeigt die Genauigkeit (Accuracy) in Abhängigkeit von der Anzahl der Validierungsdatenpunkte. Die verschiedenen Linien repräsentieren verschiedene Methoden oder Ansätze, wie z.B. FT_w, COSINE, L2R, BOND und MLC. Die graue gestrichelte Linie markiert die Grenze für schwache Labels.

Die Hauptergebnisse sind:

- Die Methode BOND erreicht die höchste Genauigkeit.
- Die Methode FT_w folgt mit guter Genauigkeit.
- Die anderen Methoden wie COSINE, L2R, MLC zeigen eine geringere Genauigkeit.
- Die Anzahl der Validierungsdatenpunkte hat einen Einfluss auf die Genauigkeit, wobei die Genauigkeit mit steigender Anzahl der Datenpunkte zunimmt.</sample>
    <sample id="927">RQ2 Hauptergebnisse

WSL-Verfahren profitieren von mehr sauberen Validierungssamples!</sample>
    <sample id="928">RQ2 Hauptergebnisse

WSL-Verfahren profitieren von mehr sauberen Validierungssamples!</sample>
    <sample id="929">### Hauptergebnisse

RQ2: **Hauptergebnisse**

→ WSL-Ansätze profitieren von mehr sauberen Validierungssamples!

→ Es ist sogar besser, sie für das Training zu verwenden (z.B., LoRA_C)!

---

### Übersetzung:

RQ2: **Hauptergebnisse**

→ WSL-Ansätze profitieren von mehr sauberen Validierungssamples!

→ Es ist sogar besser, sie für das Training zu verwenden (z.B., LoRA_C)!</sample>
    <sample id="930">RQ3 Hauptergebnisse

N=10 saubere Proben pro Klasse
Accuracy/F1

N=30 saubere Proben pro Klasse
Accuracy/F1</sample>
    <sample id="931">RQ3 Hauptergebnisse

N=10 saubere Proben pro Klasse
Accuracy/F1

N=30 saubere Proben pro Klasse
Accuracy/F1</sample>
    <sample id="932">RQ3 Hauptergebnisse

N=10 saubere Proben pro Klasse
Accuracy/F1

N=30 saubere Proben pro Klasse
Accuracy/F1</sample>
    <sample id="933">RQ3 Hauptergebnisse

→ Kontinuierliche Feinabstimmung (CFT) eliminiert Leistungsschwankungen zwischen WSL-Ansätzen.

→ Es ist keine komplizierte WSL-Methode erforderlich (FTW zeigt gleichwertiges Ergebnis).</sample>
    <sample id="934">### Schlussfolgerung

#### Neuere WSL-Verfahren
- Erfordern saubere Proben.
- Überbewerten ihre praktische Anwendbarkeit.

#### Unsere Empfehlungen
- Berichten Sie die Auswahlkriterien für das Modell.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmungsverfahren (CFT).</sample>
    <sample id="935">### Schlussfolgerung

**Neueste WSL-Ansätze**
- Erfordern saubere Proben.
- Überbewerten ihre praktische Anwendbarkeit.

**Unsere Empfehlungen**
- Berichten Sie die Auswahlkriterien für das Modell.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmungsverfahren (CFT).</sample>
    <sample id="936">### Schlussfolgerung

#### Neuere WSL-Verfahren
- Erfordern saubere Proben.
- Überbewerten ihre praktische Anwendbarkeit.

#### Unsere Empfehlungen
- Berichten Sie die Auswahlkriterien für das Modell.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmungsverfahren (CFT).</sample>
    <sample id="937">### Schlussfolgerung

#### Neuere WSL-Verfahren
- Erfordern saubere Beispiele.
- Überbewerten ihre praktische Anwendbarkeit.

#### Unsere Empfehlungen
- Berichten Sie die Auswahlkriterien für das Modell.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmungsverfahren (CFT).</sample>
    <sample id="938">### Schlussfolgerung

**Neueste WSL-Ansätze**
- Erfordern saubere Beispiele.
- Überbewerten ihre praktische Anwendbarkeit. 😟

**Unsere Empfehlungen**
- Berichten Sie die Auswahlkriterien für das Modell.
- Verwenden Sie Few-shot-Learning-Ansätze als Baseline.
- Stets Anwendung von kontinuierlichem Feinabstimmungsverfahren (CFT).</sample>
    <sample id="939">Gängige Bewertungsmethoden für Dialogsysteme sind die "Comparative Evaluation" und die "Likert Rating Evaluation".</sample>
    <sample id="940">Es sind fünf Autoren an der Arbeit beteiligt.</sample>
    <sample id="941">Das Beispiel benötigt das Hintergrundwissen, dass "Judges decide cases in courts of law."</sample>
    <sample id="942">Ja, der Code ist verfügbar. Sie können ihn auf GitHub unter mpoemsl/kitmus finden.</sample>
    <sample id="943">Nein, die Annotatoren sind nicht für NLPositionality in Bezug auf jede demographische Gruppe ausgewogen.</sample>
    <sample id="944">Die Sätze wurden durch Präfixe oder Suffixe verändert, um die relevanten Strukturen zu erhalten.</sample>
    <sample id="945">Eine dimensionale Bewertung bezieht sich auf die Beurteilung von Dialogqualität in verschiedenen Dimensionen wie Relevanz, Emotionaler Verständnis und Konsistenz.</sample>
    <sample id="946">Die Autoren gehören an der University of Science and Technology of China, Microsoft Research Asia, Beijing Jiaotong University und Sony AI.</sample>
    <sample id="947">Die Form des Prompts ist wichtig, wenn es um die Genauigkeit und den Kontext der Übersetzung geht. Beispielsweise sollte das Prompt klar und präzise sein, um sicherzustellen, dass die Übersetzung korrekt und kontextuell korrekt ist.</sample>
    <sample id="978">Die Autoren haben die Dialogmodelle BART-FID-RAG, Blender2, Emora und Blender-Decode evaluiert.</sample>
    <sample id="979">Es sind sechs Autoren an der Arbeit beteiligt.</sample>
    <sample id="980">Die Präsentation beschreibt, dass ein guter Planer eine abstrakte Zielsetzung haben sollte, die von verschiedenen realen spezifischen Zielen mit vielfältigen Restriktionen übernommen werden kann.</sample>
    <sample id="981">Es sind neun Autoren an der Arbeit beteiligt.</sample>
    <sample id="982">Der Referent*in heißt Vasudha Varadarajan.</sample>
    <sample id="983">Die Autoren gehören der University of Warsaw an.</sample>
    <sample id="1021">Die häufigsten Fehler von PaLM, wie aus den Ergebnissen der MQM hervorgeht, sind "Accuracy/Omission" und "Style/Awkward".</sample>
    <sample id="1022">Der englische Text lautet:

"Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems"

Sarah E. Finch, James D. Finch, and Jinho D. Choi

Übersetzt bedeutet das:

"Denke nicht an deine ABCs vergessen: Beurteile die aktuelle Kunst in chattenorientierten Dialogsystemen"

Sarah E. Finch, James D. Finch und Jinho D. Choi</sample>
    <sample id="1023">Der englische Text lautet:

"Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems"

Sarah E. Finch, James D. Finch, and Jinho D. Choi

Übersetzt bedeutet das:

"Denke nicht an deine ABCs vergessen: Beurteile die aktuelle Kunst in chattenorientierten Dialogsystemen"

Sarah E. Finch, James D. Finch und Jinho D. Choi</sample>
    <sample id="1024">Der englische Inhalt lautet:

"Denke nicht an deine ABC's: Beurteile das aktuelle Stand der Technik in Chat-basierten Dialogsystemen"

Die Namen der Autoren sind:

Sarah E. Finch, James D. Finch und Jinho D. Choi

Der deutsche Übersetzungsinhalt lautet:

"Denke nicht an deine ABC's: Beurteile das aktuelle Stand der Technik in Chat-basierten Dialogsystemen"

Die Namen der Autoren bleiben unverändert.</sample>
    <sample id="1025">Der englische Inhalt lautet:

"Comparative Evaluation"

"Likert Rating Evaluation"

Übersetzt auf Deutsch bedeutet das:

"Vergleichende Bewertung"

"Likert-Skala-Bewertung"</sample>
    <sample id="1026">### Übersetzung des englischen Inhalts in Deutsch

**Likert Rating Evaluation**
- **Dimensionen der Dialogqualität**
  - **Dialogqualität**
    - Relevanz
    - Emotionale Verständigung
    - Konsistenz</sample>
    <sample id="1027">Der englische Text lautet:

"Likert Rating Evaluation

Rate the relevance of the bot's responses"

Übersetzt auf Deutsch bedeutet das:

"Likert-Wertungsevaluation

Bewerte die Relevanz der Antworten des Bots"</sample>
    <sample id="1028">Der englische Text lautet:

"Likert Rating Evaluation

Rate the relevance of the bot's responses"

Übersetzt auf Deutsch bedeutet das:

"Likert-Wertungsevaluation

Bewerten Sie die Relevanz der Antworten des Bots"</sample>
    <sample id="1029">Der englische Text lautet:

"Annotating Behaviors in Chat (ABC-Eval)"

Dieser Text bedeutet auf Deutsch:

"Markieren von Verhaltensweisen im Chat (ABC-Eval)"</sample>
    <sample id="1030">Der englische Text lautet: "Annotating Behaviors in Chat (ABC-Eval)". Dies bedeutet auf Deutsch: "Markieren von Verhaltensweisen im Chat (ABC-Eval)".</sample>
    <sample id="1031">Der englische Text lautet "ABC-Eval Behaviors" und bedeutet auf Deutsch "ABC-Eval Verhaltensweisen".</sample>
    <sample id="1032">Der englische Inhalt lautet:

"ABC-Eval Behaviors"

Die Übersetzung ins Deutsche ist:

"ABC-Eval Verhaltensweisen"</sample>
    <sample id="1033">Der englische Text lautet:

"ABC-Eval Behaviors"

Unter den Kategorien "Coherence", "Knowledge" und "Emotional Understanding" werden verschiedene Verhaltensweisen aufgelistet, die in der ABC-Evaluation betrachtet werden.

- **Coherence**:
  - Ignoring Partner
  - Irrelevant

- **Consistency**:
  - Self Contradiction
  - Partner Contradiction

- **Knowledge**:
  - Incorrect Fact
  - Commonsense Violation

- **Emotional Understanding**:
  - Empathetic Response
  - Lack of Empathy</sample>
    <sample id="1034">Der englische Text lautet:

"Experiments
- 4 Open-Domain Dialogue Models
- 100 Human-Bot Conversations per Model"

Übersetzt ins Deutsche:

"Experimente
- 4 offene Domänen Dialogmodelle
- 100 Mensch-Maschine-Konversationen pro Modell"</sample>
    <sample id="1035">Experimente
- 4 offene Domäne Dialog Modelle
- 100 Mensch-Bot-Konversationen pro Modell

ABC-Eval
Turn Likert
Dialogue Likert
Comparative</sample>
    <sample id="1036">### Experimente

- 4 offene Domänen Dialogmodelle
- 100 Mensch-Bot-Konversationen pro Modell

### Baseline-Evaluierungen

- Turn Likert
- Dialog Likert
- Vergleichend

Unter den Kategorien:

- Konsistenz
- Emotionale Verständigung
- Informativität
- Gesamtqualität

- Interessierendheit
- Grammatikalität
- Proaktivität
- Relevanz</sample>
    <sample id="1037">Der englische Text lautet "Inter-Annotator Agreement" und der deutsche Übersetzung ist "Inter-annotator-Konsens".</sample>
    <sample id="1038">Der englische Text lautet:

"Inter-Annotator Agreement"

"Predictive Validity"

Der deutsche Text lautet:

"Inter-annotator-Konsistenz"

"Prädiktive Gültigkeit"</sample>
    <sample id="1039">Der englische Text lautet:

"Predictive Validity"

Der deutsche Inhalt lautet:

"Prädiktive Gültigkeit"</sample>
    <sample id="1040">Der englische Text lautet "Incremental Validity" und der deutsche Übersetzung ist "Zunehmende Gültigkeit".</sample>
    <sample id="1041">Der englische Text lautet "Incremental Validity" und der deutsche Übersetzung ist "Zunehmende Gültigkeit".</sample>
    <sample id="1042">Der englische Text lautet "Incremental Validity". Dies bedeutet in deutscher Übersetzung "Zunehmende Gültigkeit" oder "Zunehmende Validität".</sample>
    <sample id="1043">Der englische Text lautet:

"ABC-Eval Fehlerraten pro Modell"

Der deutsche Text lautet:

"ABC-Eval Fehlerraten pro Modell"</sample>
    <sample id="1044">Der englische Text lautet:

"ABC-Eval Fehlerraten pro Modell"

Der deutsche Inhalt lautet:

"ABC-Eval Fehlerraten pro Modell"</sample>
    <sample id="1045">Der englische Text lautet:

"ABC-Eval Fehlerraten pro Modell"

Der deutsche Text lautet:

"ABC-Eval Fehlerraten pro Modell"</sample>
    <sample id="1046">Der englische Text lautet:

"ABC-Eval Fehlerraten pro Modell"

Dieser Text bedeutet auf Deutsch:

"Fehlerraten des ABC-Evals pro Modell"</sample>
    <sample id="1047">### Übersetzung des englischen Inhalts in Deutsch:

**ABC-Eval Fehlerraten pro Modell**

**Paper:** [https://arxiv.org/pdf/2212.09180.pdf](https://arxiv.org/pdf/2212.09180.pdf)

**GitHub:** [https://github.com/emorynlp/ChatEvaluationPlatform](https://github.com/emorynlp/ChatEvaluationPlatform)

**Kontaktinformationen:**
{sfillwo, jdfinch, jinho.choi} @emory.edu

[https://www.emorynlp.org](https://www.emorynlp.org)</sample>
    <sample id="1048">Emory University</sample>
    <sample id="1049">Continuous fine-tuning</sample>
    <sample id="1050">Es sind sieben Autoren an der Arbeit beteiligt.</sample>
    <sample id="1051">Der englische Text lautet:

"When Does Translation Require Context?
A Data-driven, Multilingual Exploration"

Die deutschen Übersetzungen der Namen sind:

Patrick Fernandes*, Kayo Yin*, Emmy Liu
André F. T. Martins, Graham Neubig

Die Übersetzung des Titels ist:

"Wann erfordert die Übersetzung Kontext?
Eine datengetriebene, multilinguale Untersuchung"</sample>
    <sample id="1052">Übersetzung des englischen Inhalts auf Deutsch:

"Die Übersetzung hängt vom Kontext ab.
Wir müssen das Maul entfernen."</sample>
    <sample id="1053">Übersetzung des englischen Inhalts ins Deutsche:

"Die Übersetzung hängt vom Kontext ab

Dinge könnten gefährlich werden, wenn die Minister davon erfahren. Wir müssen diesen Spion loswerden."</sample>
    <sample id="1054">Übersetzung des englischen Inhalts auf Deutsch:

"Die Übersetzung hängt vom Kontext ab

Könnte es etwas Ernstes sein, Doktor? Wir müssen das Fleckchen entfernen."</sample>
    <sample id="1055">Überprüfen von kontextabhängigen Übersetzungen ist schwierig

- Nur eine kleine Anzahl von Wörtern hängt vom Kontext ab</sample>
    <sample id="1056">Überprüfen von kontextabhängiger Übersetzung ist schwierig

- Nur eine kleine Anzahl von Wörtern hängt vom Kontext ab
  - Korpusniveau-Metriken

- Bestehende Methoden unterstützen begrenzte Diskursphänomene und Sprachen</sample>
    <sample id="1057">RQ1: Wann erfordert die Übersetzung Kontext?

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1058">RQ1: Wann erfordert die Übersetzung Kontext?
- Wortebene Kontextverwendung

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1059">Conditional Cross-Mutual Information (CXMI)

- CXMI: Messen, wie viel Kontext MT-Modelle bei gegebenem Korpus verwenden

Conditional Cross-Mutual Information (CXMI)

- CXMI: Messen, wie viel Kontext MT-Modelle bei gegebenem Korpus verwenden

Die Abbildung zeigt die folgenden Konzepte:

- **Uncertainty over translations given the source**: Unsicherheit über Übersetzungen gegeben den Quelltext.
  - **HqMTA(Y|X)**: Unsicherheit über Übersetzungen gegeben den Quelltext X.
  - **HqMTC(Y|X, C)**: Unsicherheit über Übersetzungen gegeben den Quelltext X und Kontext C.

- **CXMI(C → Y|X)**: Conditional Cross-Mutual Information zwischen Kontext C und Übersetzung Y gegeben dem Quelltext X.</sample>
    <sample id="1060">Konditionale Kreuz-Mutual Information (CXMI)

- CXMI: Messung davon, wie viel Kontext MT-Modelle bei gegebenem Korpus verwenden

Unsicherheit über Übersetzungen gegeben Quelle
HqMTA(Y|X)
Unsicherheit über Übersetzungen gegeben Quelle und Kontext
HqMTC(Y|X, C)
CXMI(C → Y|X)</sample>
    <sample id="1061">Der englische Text lautet:

"Pointwise (P-)CXMI
- Wir führen P-CXMI ein, um den Kontextgebrauch zu messen, um eine spezifische

- Satz P-CXMI(y, x, C) = - log \(\frac{q_{MT_A}(y|x)}{q_{MT_C}(y|x, C)}\)

- Wort P-CXMI(i, y, x, C) = - log \(\frac{q_{MT_A}(y_i|y_{t&lt;i}, x)}{q_{MT_C}(y_i|y_{t&lt;i}, x, C)}\)

- Hohe P-CXMI-Wörter -&gt; erfordern Kontext zum Übersetzen"

Übersetzt ins Deutsche:

"Pointwise (P-)CXMI
- Wir führen P-CXMI ein, um den Kontextgebrauch zu messen, um eine spezifische

- Satz P-CXMI(y, x, C) = - log \(\frac{q_{MT_A}(y|x)}{q_{MT_C}(y|x, C)}\)

- Wort P-CXMI(i, y, x, C) = - log \(\frac{q_{MT_A}(y_i|y_{t&lt;i}, x)}{q_{MT_C}(y_i|y_{t&lt;i}, x, C)}\)

- Hohe P-CXMI-Wörter -&gt; erfordern Kontext zum Übersetzen"</sample>
    <sample id="1062">RQ1: Wann erfordert die Übersetzung Kontext?
- Wortebene Kontextverwendung
- Themenanalyse

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?</sample>
    <sample id="1063">Der englische Inhalt lautet:

"Thematic analysis of high P-CXMI words

RQ1: When does translation require context?
- Word-level context usage
- Thematic analysis

RQ2: How well do models handle context-dependent translations?"

Übersetzt auf Deutsch:

"Themenanalyse von hochwertigen P-CXMI-Wörtern

Forschungsfrage 1: Wann erfordert die Übersetzung Kontext?
- Kontextverwendung auf Wortebene
- Themenanalyse

Forschungsfrage 2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?"</sample>
    <sample id="1064">Der englische Text lautet:

"Thematic analysis of high P-CXMI words"

Übersetzt ins Deutsche bedeutet das:

"Themenanalyse von hochwertigen P-CXMI-Wörtern"</sample>
    <sample id="1065">Thematikanalyse von hochwertigen P-CXMI-Wörtern

1. POS-Kategorien

P-CXMI für POS-Kategorien in En-Ar</sample>
    <sample id="1066">Thematikanalyse von hochwertigen P-CXMI-Wörtern

1. POS-Kategorien
- Pronomen
- Verbform

2. Vokabularelemente</sample>
    <sample id="1067">Thematikanalyse von hochwertigen P-CXMI-Wörtern

1. POS Tags
2. Vokabularpunkte

Englisch:
Avelile's mother was still asleep.
Avelile went to school.

Deutsch:
Aveliles Mutter war noch immer wach.
Avelile ging zur Schule.</sample>
    <sample id="1068">Thematikanalyse von hochwertigen P-CXMI-Wörtern

1. POS Tags
2. Vokabularpunkte

Englisch:
Avelile's mother was still asleep.
Avelile went to school.

Deutsch:
Aveliles Mutter war noch immer wach.
Avelile ging zur Schule.</sample>
    <sample id="1069">1. POS tags
2. Vocabulary items
3. Individual tokens

Englischer Text:
- She knows where we're going.
- I don't.

Deutscher Text:
- Sie weiß, wohin wir gehen.
- Ich weiß es nicht.</sample>
    <sample id="1070">RQ1: Wann erfordert die Übersetzung Kontext?

- Wortebene Kontextnutzung
- Themenanalyse

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?

- Multilingual Discourse-Aware (MuDA) Benchmark</sample>
    <sample id="1071">Der englische Text lautet:

"Multilingual Discourse-Aware (MuDA) tagger

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis"

Übersetzt ins Deutsche:

"Multilinguale Diskursbewusste (MuDA) Tagger

- Pronomen
- Verbform
- Lexikalische Cohesion
- Formalität
- Ellipsen"</sample>
    <sample id="1072">Der englische Text lautet:

"Multilingual Discourse-Aware (MuDA) tagger

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis"

Übersetzt ins Deutsche:

"Multilinguale Diskursbewusste (MuDA) Tagger

- Pronomen
- Verbform
- Lexikalische Cohäsion
- Formalität
- Ellipsen"</sample>
    <sample id="1073">Multilinguale Diskursbewusstes (MuDA) Tagger

- Pronomen
- Verbform
- Lexikalische Cohesion
- Formalität
- Ellipsis

MuDA Benchmark

- Dokumente
- Roboter

MuDA Benchmark

- Dokumente
- MuDA-Tagger
- Dokumente

MuDA Benchmark

- Dokumente
- MuDA-Tagger
- Dokumente
- BLEU
- COMET
- F-Maß
- ...</sample>
    <sample id="1074">RQ1: Wann benötigt die Übersetzung Kontext?
- Wortebene Kontextnutzung
- Themenanalyse

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?
- Multilingual Discourse-Aware (MuDA) Benchmark
- Modellbewertung</sample>
    <sample id="1075">Der englische Inhalt lautet:

"Corpus-level metrics

RQ1: Wann erfordert eine Übersetzung Kontext?
- Wortebene Kontextnutzung
- Themenanalyse

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?
- Multilingual Discourse-Aware (MuDA) Benchmark
- Modellbewertung"

Übersetzt ins Deutsche:

"Korpusniveau-Metriken

RQ1: Wann erfordert eine Übersetzung Kontext?
- Wortebene Kontextnutzung
- Themenanalyse

RQ2: Wie gut handhaben Modelle kontextabhängige Übersetzungen?
- Multilingual Discourse-Aware (MuDA) Benchmark
- Modellbewertung"</sample>
    <sample id="1076">Der englische Text lautet:

"Corpus-level metrics

BLEU
COMET
F-measure"

Übersetzt ins Deutsche:

"Korpusniveau-Maße

BLEU
COMET
F-Maß"</sample>
    <sample id="1077">Korpusniveau-Metriken

- BLEU
- COMET
- F-Maß

- Unklar, welches System am besten für die Dokumenten-Level-Übersetzung mit Korpusniveau-Metriken ist</sample>
    <sample id="1078">Die Übersetzung des englischen Inhalts in Deutsch lautet:

"MuDA Benchmark-Ergebnisse

- Kontextbewusste Modelle zeigen signifikant bessere Ergebnisse bei einigen Phänomenen"</sample>
    <sample id="1079">MuDA Benchmark-Ergebnisse

- Kontextbewusste Modelle zeigen signifikant bessere Ergebnisse bei einigen Phänomenen
  - ✅: Formalität, lexikalische Cohesion
  - ❌: Ellipsen, Pronomen, Verbalformen</sample>
    <sample id="1080">MuDA Benchmark-Ergebnisse

- Kontextbewusste Modelle zeigen signifikant bessere Ergebnisse bei einigen Phänomenen
  - ✅: Formalität, lexikalische Cohesion ❌ Ellipsis, Pronomen, Verbalform
- DeepL übertrifft Google in der Regel bei meisten Phänomenen und Sprachpaaren*</sample>
    <sample id="1081">Zusammenfassung

- Identifizieren von Diskursphänomenen systematisch ohne vorherige linguistische Kenntnisse
- Dataset-unabhängiger Benchmark für Dokumenten-Level MT</sample>
    <sample id="1082">Zusammenfassung

- Identifizieren von Diskursphänomenen systematisch ohne vorherige linguistische Kenntnisse
- Dataset-unabhängiger Benchmark für Dokumenten-Level MT</sample>
    <sample id="1083">Zusammenfassung

- Identifizieren von Diskursphänomenen systematisch ohne vorherige linguistische Kenntnisse
- Dataset-unabhängiger Benchmark für Dokumenten-Level MT</sample>
    <sample id="1084">Der Referent ist Yusen Zhang.</sample>
    <sample id="1121">Die neue Methode hat den Namen "Permuting with 'jumps'".</sample>
    <sample id="1122">Die Autoren beschreiben die Methode der „markierten Wörter“ als das Finden von Wörtern, die die Personas von markierten Gruppen von unmarkierten Gruppen unterscheiden.</sample>
    <sample id="1123">Die Autoren gehören der Carnegie Mellon University an.</sample>
    <sample id="1124">Stanford</sample>
    <sample id="1125">Der Referent ist James D. Finch.</sample>
    <sample id="1126">Es sind vier Autoren an der Arbeit beteiligt: Mohammad Javad Hosseini, Filip Radlinski, Silvia Paretí und Annie Louis.</sample>
    <sample id="1127">BLiMP, SyntaxGym und CrowS</sample>
    <sample id="1161">Die Abkürzungen der fünf Methoden für die erste Forschungsfrage sind:

1. FT_w
2. BOND
3. COSINE
4. MLC
5. L2R</sample>
    <sample id="1162">Das Modell wird an 11 Aufgaben evaluiert.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich mit 4 GB Daten trainiert.</sample>
    <sample id="1227">Der Referent ist Adam Przepiórkowski.</sample>
    <sample id="1228">Die Ergebnisse, die zu der Schlussfolgerung führten, dass die zeitliche Verzögerung die Hauptursache für den Leistungsverlust war, sind:

- Die Leistung degradiert mit größerem zeitlichen Abstand.
- Temporale Drift als Hauptursache für den Leistungsverlust.</sample>
    <sample id="1269">Die Permutation der Token für die Ausgabesequenz ist notwendig, um verschiedene mögliche Reihenfolgen der Wörter zu erzeugen, die dann durch den Tag-Generator verarbeitet werden können. Dies ermöglicht es dem Modell, eine Vielzahl von Ausgaben zu generieren und somit die Genauigkeit und Vielseitigkeit der Antwort zu erhöhen.</sample>
    <sample id="1270">Die Autoren empfehlen, dass Modellentwickler*innen ihre Methoden zum Abbau von Vorurteilen transparenter machen sollten, um sicherzustellen, dass positive Stereotypen und essenzialisierende Erzählungen adressiert werden können. Ein intersektionaler Ansatz ist ebenfalls wichtig, um komplexe Interaktionen zwischen verschiedenen sozialen Gruppen zu berücksichtigen.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind:

1. "Many people were helping themselves."
2. "*Many people were helping herself."

3. "No customer ... has spent any money."
4. "*The customer ... has spent any money."

5. "Stereotypical sentence."
6. "Non-stereotypical sentence."</sample>
    <sample id="1272">Die Autoren haben F1-Score, Hamming-Distanz und EMR als Bewertungsmetriken verwendet.</sample>
    <sample id="1273">Krippendorff's Alpha wurde verwendet, um die Übereinstimmung zwischen den Kommentatoren zu messen.</sample>
    <sample id="1274">Wikipedia</sample>
    <sample id="1275">Die Autoren gehören der Heinrich Heine University Düsseldorf, Germany an.</sample>
    <sample id="1276">MultiInstruct unterscheidet sich von anderen Benchmarks durch eine ungleichgewichtige Anzahl an Aufgaben zwischen NLP und Multimodal, mit über 1600+ Sprachnur-Aufgaben und keiner großen, öffentlich verfügbaren multimodalen Aufgabe.</sample>
    <sample id="1277">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="1278">Die Definition der binären Koordination lautet: "Proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths (with confidence bands)."</sample>
    <sample id="1279">Die Frage kann nicht direkt aus dem gezeigten Bild beantwortet werden, da das Bild keine Informationen über die Länge der verwendeten Prompts enthält.</sample>
    <sample id="1280">Die Ergebnisse zeigen, dass das kleinere T5-Modell, das auf Coscript trainiert wurde, höhere Qualitätsskripte generieren kann als große LLMs wie GPT-3, Codex und InstructGPT.</sample>
    <sample id="1281">Der Titel des Inhalts lautet auf Deutsch:

"DrBERT: Ein robustes prätrainiertes Modell auf Französisch für biomedizinische und klinische Bereiche"

Die Autoren sind:
- Yanis Labrak*1,4
- Adrien Bazoge*2,3
- Richard Dufour2
- Mickael Rouvier1
- Emmanuel Morin2
- Béatrice Daille2
- Pierre-Antoine Gourraud3

Die Institutionen, an denen die Arbeit durchgeführt wurde, sind:
(1) LIA, Avignon Universität
(2) LS2N, Nantes Universität
(3) Clinique des données, CHU de Nantes
(4) Zenidoc</sample>
    <sample id="1282">Zusammenfassung

I. Sprachmodellierung in der Gesundheitswesen

II. Vergleich von Vortrainingsstrategien, Datenquellen und -mengen

III. Bewertung von 13 Modellen auf 11 Aufgaben

IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1283">Zusammenfassung

I. Sprachmodellierung in der Gesundheitswesen

II. Vergleich von Vortrainingsstrategien, Datenquellen und -mengen

III. Bewertung von 13 Modellen auf 11 Aufgaben

IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1284">Zusammenfassung

I. Sprachmodellierung in der Gesundheitswesen

II. Vergleich von Vortrainingsstrategien, Datenquellen und -mengen

III. Bewertung von 13 Modellen auf 11 Aufgaben

IV. Verteilung von NACHOS und DrBERT</sample>
    <sample id="1285">Hier ist die Übersetzung des englischen Inhalts in Deutsch:

I. Sprachmodellierung im Gesundheitswesen
- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungssteigerungen bei vielen NLP-Aufgaben

II. Vergleich von Vorausbildungsstrategien, Datenquellen und -mengen
- Has been adapted to French with CamemBERT and FlauBERT
- Continual pre-training using an existing generic model

III. Bewertung von 13 Modellen auf 11 Aufgaben
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vorausbildung mit einem bestehenden generischen Modell

IV. Verteilung von NACHOS und DrBERT
- Unlike generic models, no open-source model is available for biomedical domain in French yet
- BERT-basiertes domain-specific Model für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern</sample>
    <sample id="1286">Die Übersetzung des englischen Inhalts in Deutsch lautet:

---

**Sprachmodellierung**

- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungssteigerungen bei vielen NLP-Aufgaben.
- Diese wurden für Französisch mit CamemBERT und FlauBERT angepasst.
- Bei medizinischen Aufgaben verbessern spezifische Modelle im Englischen die Leistung noch weiter.
  - PudMedBERT, BioBERT, ClinicalBERT und andere.
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vortraining mit einem bestehenden generischen Modell.
- Im Gegensatz zu generischen Modellen gibt es keine offene Quelle für den biomedizinischen Bereich in Französisch.
- Ein BERT-basierter spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben erhöhen.

---</sample>
    <sample id="1287">### Sprachmodellierung

- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungsverbesserungen bei vielen NLP-Aufgaben.
- Diese wurden für Französisch mit CamemBERT und FlauBERT angepasst.
- Bei medizinischen Aufgaben haben spezifische Modelle im Englischen die Leistungsebene noch weiter angehoben:
  - PubMedBERT, BioBERT, ClinicalBERT und andere.
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vortraining mit einem bestehenden generischen Modell.
- Im Gegensatz zu generischen Modellen gibt es keine offenen Quellmodelle für den biomedizinischen Bereich in Französisch.
- Ein BERT-basierter spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben verbessern.</sample>
    <sample id="1288">Der englische Text lautet:

"Language Modeling

- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungssteigerungen bei vielen NLP-Aufgaben
- wurde auf Französisch mit CamemBERT und FlauBERT angepasst
- Bei medizinischen Aufgaben haben spezifische Modelle im Englischen die Bar noch höher gezogen
  - PubMedBERT, BioBERT, ClinicalBERT und andere
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vortraining mit einem bestehenden generischen Modell
- Im Gegensatz zu generischen Modellen gibt es keine offene Quelle für den biomedizinischen Bereich in Französisch
- Ein BERT-basierter spezifischer Domänenmodell für Französisch sollte die Leistung bei medizinischen Aufgaben erhöhen"

Übersetzt ins Deutsche:

"Sprachmodellierung

- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungssteigerungen bei vielen NLP-Aufgaben
- wurde auf Französisch mit CamemBERT und FlauBERT angepasst
- Bei medizinischen Aufgaben haben spezifische Modelle im Englischen die Bar noch höher gezogen
  - PubMedBERT, BioBERT, ClinicalBERT und andere
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlichem Vortraining mit einem bestehenden generischen Modell
- Im Gegensatz zu generischen Modellen gibt es keine offene Quelle für den biomedizinischen Bereich in Französisch
- Ein BERT-basierter spezifischer Domänenmodell für Französisch sollte die Leistung bei medizinischen Aufgaben erhöhen"</sample>
    <sample id="1289">Der englische Inhalt lautet:

"Language Modeling

- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungsverbesserungen bei vielen NLP-Aufgaben
- Wurde für Französisch mit CamemBERT und FlauBERT angepasst
- Bei medizinischen Aufgaben haben spezifische Modelle im Englischen die Bar noch höher gezogen
  - PubMedBERT, BioBERT, ClinicalBERT und andere
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlicher Vortraining mit einem bestehenden generischen Modell
- Im Gegensatz zu generischen Modellen gibt es keine offene Quelle für den biomedizinischen Bereich in Französisch
- Ein BERT-basierter spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben erhöhen"

Übersetzt ins Deutsche:

"Sprachmodellierung

- Transformer-basierte Ansätze, wie BERT, bieten enorme Leistungsverbesserungen bei vielen NLP-Aufgaben
- Wurde für Französisch mit CamemBERT und FlauBERT angepasst
- Bei medizinischen Aufgaben haben spezifische Modelle im Englischen die Bar noch höher gezogen
  - PubMedBERT, BioBERT, ClinicalBERT und andere
- Sprachen außer Englisch sind seltener und basieren hauptsächlich auf kontinuierlichem Vortraining mit einem bestehenden generischen Modell
- Im Gegensatz zu generischen Modellen gibt es keine offene Quelle für den biomedizinischen Bereich in Französisch
- Ein BERT-basierter spezifisches Modell für Französisch sollte die Leistung bei medizinischen Aufgaben erhöhen"</sample>
    <sample id="1290">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quellendatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenlager des Universitätskrankenhauses von Nantes stammen.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1291">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Evaluation des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quellendatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenlager des Nantes University Hospitals extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1292">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Evaluation des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Eine offene Quelle mit 1,1 Milliarden Wörtern, die heterogene Daten aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Eine private Datenquelle mit Sätzen aus 1,7 Millionen anonymisierten medizinischen Dokumenten, die aus dem Datenlager des Nantes University Hospitals extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1293">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quellendatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenlager des Universitätskrankenhauses von Nantes stammen.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1294">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quellendatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenlager des Universitätskrankenhauses von Nantes stammen.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1295">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Bewertung des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Eine offene Quelle mit 1,1 Milliarden Wörtern, die aus verschiedenen medizinischen Bereichen, Natur und Stilen krawlt.
  - **NBDW**: Eine private Datenquelle mit Sätzen aus 1,7 Millionen anonymisierten medizinischen Dokumenten, die aus dem Datenlager des Nantes University Hospital extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1296">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Evaluation des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quellendatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenlager des Nantes University Hospitals extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englischsprachiges medizinisches Modell)</sample>
    <sample id="1297">### Vergleich von Vortrainingsstrategien und Datenquellen

- **Evaluation des Einflusses öffentlicher und privater medizinischer Datenquellen auf vergleichbare Datengrößen**
  - **NACHOS**: Ein offener Quellendatensatz mit 1,1 Milliarden Wörtern, der heterogenes Datenmaterial aus verschiedenen medizinischen Bereichen, Natur und Stilen katalogisiert.
  - **NBDW**: Ein privater Datensatz von Sätzen, die aus 1,7 Millionen anonymisierten medizinischen Dokumenten aus dem Datenlager des Nantes University Hospitals extrahiert wurden.

- **Vergleich von Lernstrategien**
  - **Von Grund auf mit vollständiger Modellkonstruktion**
  - **Fortlaufende Vortraining** mit einem bestehenden vortrainierten Modell (hier CamemBERT, ein französisches generisches Modell, und PubMedBERT, ein englisch-basierter medizinisches Modell)

### Bewertung: Datenquellen und Größe
- **Leistungsbewertung von 13 Modellen auf 11 Aufgaben**, sowohl öffentlich als auch privat.
- Unsere feinabgestimmten Modelle erzielen fast immer die aktuell besten Ergebnisse.</sample>
    <sample id="1298">Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben</sample>
    <sample id="1299">Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentliche als auch private
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben</sample>
    <sample id="1300">Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben</sample>
    <sample id="1301">Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben

Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben

Evaluation: Datenquellen und Größe

- Leistungsevaluation von 13 Modellen auf 11 Aufgaben, sowohl öffentlich als auch privat
- Unsere feinabgestimmten Modelle erzielen fast immer die neuesten Ergebnisse auf allen Aufgaben</sample>
    <sample id="1302">Evaluation: Vortrainingsstrategien

- Ausgehend von Null vs. kontinuierliches Vortraining auf 4 GB Daten
- Fragestellungen erfordern mehr spezifisches Wissen über das jeweilige Fachgebiet, um gut zu funktionieren
- Eine Studie zur Modellstabilität zeigt eine höhere Inter-run-Variabilität für CamemBERT-basierte Modelle, die mit kontinuierlichem Vortraining trainiert wurden</sample>
    <sample id="1303">Evaluation: Vortrainingsstrategien

- Ausgehend von Null vs. kontinuierliches Vortraining auf 4 GB Daten
- Fragestellungen erfordern mehr spezifisches Wissen über das jeweilige Fachgebiet, um gut zu funktionieren
- Eine Studie zur Modellstabilität zeigt eine höhere inter-run Variabilität für CamemBERT-basierte Modelle, die mit kontinuierlichem Vortraining trainiert wurden</sample>
    <sample id="1304">Evaluation: Vortrainingsstrategien

- Ausgehend von Null vs. kontinuierliches Vortraining auf 4 GB Daten
- Fragestellungsbeantwortende Aufgaben erfordern mehr spezifisches Wissen eines bestimmten Bereichs, um gut zu funktionieren
- Eine Studie zur Modellstabilität zeigt eine höhere inter-run Variabilität für CamemBERT-basierte Modelle, die mit kontinuierlichem Vortraining trainiert wurden</sample>
    <sample id="1305">Kernnachricht

- DrBERT erreicht in 9 downstream französischen medizinischen Aufgaben die aktuell besten Ergebnisse.
  - Übertrifft CamemBERT generische Modelle und englisch-basierte domänenspezifische Modelle.
  - Bestätigt die Nutzbarkeit der Schulung eines medizinisch spezifischen Modells auf Französisch.

- Datenquellen zählen: Die Schulung an heterogenen Daten ist wichtig.
  - NACHOS ist robuster als das Verwenden nur privater klinischer Daten.

- Mehr Daten ist besser, aber es skaliert nicht gut.
- Kontinuierliche Vortraining ist eine effektivere Strategie, wenn auf domänenspezifischen englischen Modellen basiert wird.
- Die DrBERT Modelle, das NACHOS-Dataset und die Trainingsskripte sind unter der MIT-Lizenz frei verfügbar.</sample>
    <sample id="1306">Kernnachricht

- DrBERT erreicht in 9 downstream französischen medizinischen Aufgaben die aktuell besten Ergebnisse.
  - Übertrifft CamemBERT generische Modelle und englisch-basierte domänenspezifische Modelle.
  - Bestätigt die Nutzbarkeit der Schulung eines medizinisch spezifischen Modells auf Französisch.

- Datenquellen zählen: Die Schulung an heterogenen Daten ist wichtig.
  - NACHOS ist robuster als das Verwenden nur privater klinischer Daten.

- Mehr Daten ist besser, aber es skaliert nicht gut.
- Kontinuierliche Vortraining ist eine effektivere Strategie, wenn auf domänenspezifische englische Modelle basiert wird.
- Die DrBERT Modelle, das NACHOS-Dataset und die Trainingsskripte sind unter der MIT-Lizenz frei verfügbar.</sample>
    <sample id="1307">Kernnachricht

- DrBERT erreicht in 9 downstream französischen medizinischen Aufgaben die aktuell besten Ergebnisse.
  - Übertrifft CamemBERT generische Modelle und englisch-basierte domänenspezifische Modelle.
  - Bestätigt die Nutzbarkeit der Schulung eines medizinisch spezifischen Modells auf Französisch.

- Datenquellen zählen: Die Schulung an heterogenen Daten ist wichtig.
  - NACHOS ist robuster als das Verwenden nur privater klinischer Daten.

- Mehr Daten ist besser, aber es skaliert nicht gut.
- Kontinuierliche Vortraining ist eine effektivere Strategie, wenn auf domänenspezifischen englischen Modellen basiert wird.
- Die DrBERT Modelle, das NACHOS-Dataset und die Trainingsskripte sind unter der MIT-Lizenz frei verfügbar.</sample>
    <sample id="1308">Der englische Text lautet:

"Thank You
Looking forward to exchange at poster session in Toronto!"

Übersetzt auf Deutsch bedeutet das:

"Danke
Ich freue mich auf die Austauschveranstaltung der Posterpräsentation in Toronto!"</sample>
    <sample id="1309">Die Arbeit untersucht zwei Lernstrategien: "From scratch with full model construction" und "Continual pre-training using an existing pre-trained model".</sample>
    <sample id="1310">Der Faktor der Überanpassung, der auf die Wiederverwendung von Tests zurückzuführen ist, beträgt 0.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde anhand von vier Metriken bewertet: SARI, BLEU, BS-P und FRE.</sample>
    <sample id="1312">Ja, Sprachmodelle haben unterschiedliche politische Vorurteile.</sample>
    <sample id="1313">Der englische Text lautet:

"Compositional Generalization without Trees using Multiset Tagging and Latent Permutations

Matthias Lindemann, Alexander Koller, Ivan Titov"

Übersetzt auf Deutsch bedeutet das:

"Kompositionale Generalisierung ohne Bäume mit Hilfe von Multiset-Tagging und latenten Permutationen

Matthias Lindemann, Alexander Koller, Ivan Titov"</sample>
    <sample id="1314">Der englische Text lautet:

"Compositional Generalization without Trees using Multiset Tagging and Latent Permutations"

Die Autoren sind:

Matthias Lindemann, Alexander Koller, Ivan Titov

Die Logos stammen von:

- The University of Edinburgh (Informatik)
- NLP UKRI Centre for Doctoral Training
- Saarland University
- University of Amsterdam</sample>
    <sample id="1315">Kompositionale Generalisierung

Fähigkeit eines Lerners, tiefe Rekursion und unerwartete Kombinationen von Phrasen zu beherrschen, die während des Trainings einzeln gesehen wurden.</sample>
    <sample id="1316">Kompositionelle Generalisierung in semantischer Parsen

Trainieren:

- Die Mädchen schlief.
  - *girl x1 sleep.agent x2 x1

- Mary wusste, dass die Mädchen schlief.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧
    sleep.agent x5 x4</sample>
    <sample id="1317">Der englische Text lautet:

"Compositional Generalization in Semantic Parsing

Train:
The girl slept.
*girl x1 sleep.agent x2 x1

Mary knew that the girl slept.
*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧
sleep.agent x5 x4"

Übersetzt ins Deutsche:

"Kompositionale Generalisierung im Semantischen Parsen

Trainieren:
Die Mädchen schlief.
*girl x1 sleep.agent x2 x1

Mary wusste, dass die Mädchen schlief.
*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧
sleep.agent x5 x4"</sample>
    <sample id="1318">Kompositionelle Generalisierung in semantischer Parsen

Train:

- Die Mädchen schlief.
  - *girl x1 sleep.agent x2 x1

- Mary wusste, dass die Mädchen schlief.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

Test:

- Jim sagte, dass Mary wusste, dass die Mädchen schlief.
  - *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7</sample>
    <sample id="1319">Kompositionelle Generalisierung in semantischer Parsen

Trainieren:

- Die Mädchen schlief.
  - *girl x1 sleep.agent x2 x1

- Mary wusste, dass die Mädchen schlief.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧
    sleep.agent x5 x4

Testen:

- Jim sagte, dass Mary wusste, dass die Mädchen schlief.
  - *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent
    x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7</sample>
    <sample id="1320">Kompositionelle Generalisierung in semantischer Parsen

Trainieren:

- Die Mädchen schlief.
  - *girl x1 sleep.agent x2 x1

- Mary wusste, dass die Mädchen schlief.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

Test:

- Jim sagte, dass Mary wusste, dass die Mädchen schlief.
  - *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7

Naive seq2seq Modelle scheitern!</sample>
    <sample id="1321">Kompositionelle Generalisierung in semantischer Parsen

Trainieren:

- Die Mädchen schlief.
  - *girl x1 sleep.agent x2 x1

- Mary wusste, dass die Mädchen schlief.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

Test:

- Jim sagte, dass Mary wusste, dass die Mädchen schlief.
  - *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7

Naive seq2seq Modelle scheitern!</sample>
    <sample id="1322">Baumstrukturen helfen sehr, aber...</sample>
    <sample id="1323">Baumstrukturen helfen sehr, aber...</sample>
    <sample id="1324">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen erzeugt werden:
- Vor/Postverarbeitung logischer Formen</sample>
    <sample id="1325">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen erzeugt werden:
- Vor/Postverarbeitung logischer Formen</sample>
    <sample id="1326">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen erzeugt werden:
- Vor/Nachverarbeitung logischer Formen
- Grammatik-induktion

4</sample>
    <sample id="1327">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen erzeugt werden:
- Vor/Postverarbeitung logischer Formen
- Grammatik-induktion

Dieses Papier: neuronales seq2seq-Modell, das die Korrespondenzen zwischen Fragmenten direkt modelliert. Zum ersten Mal zeigen wir starke Generalisierung zu tiefen Rekursionen ohne Bäume.</sample>
    <sample id="1328">Baumstrukturen helfen sehr, aber...

Baumstrukturen müssen erzeugt werden:
- Vor/Postverarbeitung logischer Formen
- Grammatik-induktion

Dieses Papier: neuronales seq2seq-Modell, das direkt die Korrespondenzen zwischen Fragmenten modelliert. Zum ersten Mal zeigen wir starke Generalisierung zu tiefen Rekursionen ohne Bäume.</sample>
    <sample id="1329">Unser Ansatz

Der obige Diagramm zeigt eine Art von Tagging-Verfahren, bei dem verschiedene Wörter und ihre Beziehungen zu einem gemeinsamen Tag (Tag) dargestellt werden. Die grünen Kästchen mit einem Stern (*) und einem Punkt (;) könnten als spezielle Tags oder Marker interpretiert werden, die bestimmte Wörter oder Phrasen kennzeichnen. Die gelben Kästchen mit "x1" und "girl" könnten auf eine bestimmte Rolle oder Funktion innerhalb des Tags hinweisen, möglicherweise als "Agent" oder "Subjekt". Die blauen Kästchen mit "sleep", "agent" und "x2" könnten ebenfalls als spezifische Tags oder Markierungen dienen, die auf bestimmte Wörter oder Phrasen in der Textanalyse oder -verarbeitung hinweisen.

Insgesamt scheint das Bild ein Konzept zur Verarbeitung oder Analyse von Texten zu illustrieren, bei dem verschiedene Wörter und ihre Beziehungen zu einem gemeinsamen Tag markiert und klassifiziert werden.</sample>
    <sample id="1330">Unser Ansatz

Der obige Diagramm zeigt eine Art von Tagging-Verfahren, bei dem verschiedene Wörter und ihre Beziehungen zu einem gemeinsamen Tag (Tag) dargestellt werden. Die grünen Kästchen mit einem Stern (*) und einem Punkt (;) könnten als Sonderzeichen oder als Markierungen für bestimmte Wörter interpretiert werden. Die gelben Kästchen mit "x1" und "girl" könnten als Markierungen für bestimmte Positionen oder Rollen innerhalb des Textes dienen. Die blauen Kästchen mit "sleep", "agent" und "x2" könnten ebenfalls als Markierungen für bestimmte Positionen oder Rollen innerhalb des Textes interpretiert werden.

Insgesamt scheint das Verfahren dazu gedacht zu sein, bestimmte Wörter oder Phrasen in einem Text zu identifizieren und sie mit speziellen Markierungen zu versehen, um ihre Bedeutung oder ihre Rolle im Kontext des Textes hervorzuheben.</sample>
    <sample id="1331">Unser Ansatz

Der obige Diagramm zeigt eine Art von Tagging-Verfahren, bei dem verschiedene Wörter und ihre Beziehungen zu einem gemeinsamen Tag (Tag) dargestellt werden. Die grünen Kästchen mit den Sternen (*) und der Doppelpunkt (;) könnten als spezielle Tags oder Marker interpretiert werden, die bestimmte Funktionen oder Kontexte kennzeichnen. Die gelben Kästchen mit "x1" und "girl" könnten auf einen bestimmten Kontext oder eine bestimmte Rolle innerhalb des Tags hinweisen. Die blauen Kästchen mit "sleep", "agent" und "x2" könnten ebenfalls spezifische Tags oder Rollen darstellen, die im Zusammenhang mit dem Tag stehen. Die Wörter "the", "girl" und "slept" unter den Kästchen könnten die tatsächlichen Wörter sein, die mit diesen Tags assoziiert sind. Dieses Verfahren könnte dazu dienen, komplexe Beziehungen zwischen Wörtern und ihren Kontexten zu identifizieren und zu strukturieren.</sample>
    <sample id="1332">Unser Ansatz

Unsere Methode umfasst die Schritte "Permute" und "Tag". 

- "Permute": Die Wörter "girl", "sleep" und "agent" werden in verschiedenen Positionen angeordnet.
- "Tag": Die Wörter "the", "girl" und "slept" werden mit entsprechenden Tags versehen.

Diese Methode ermöglicht es, verschiedene Permutationen von Wörtern zu generieren und sie dann mit entsprechenden Tags zu versehen.</sample>
    <sample id="1333">Der englische Text lautet "Our Approach" und der deutsche Übersetzungsinhalt ist "Unser Ansatz".</sample>
    <sample id="1334">Der englische Text lautet "Permuting with 'jumps'". Dies bedeutet "Permutieren mit 'Sprüngen'".</sample>
    <sample id="1335">Der englische Text lautet "Permuting with 'jumps'". Dies bedeutet "Permutieren mit 'Sprüngen'".</sample>
    <sample id="1336">Der englische Text lautet "Permuting with 'jumps'". Dies bedeutet "Permutieren mit 'Sprüngen'".</sample>
    <sample id="1337">Der englische Text lautet "Permuting with 'jumps'". Dies bedeutet "Permutieren mit 'Sprüngen'".</sample>
    <sample id="1338">Der englische Text lautet "Permuting with 'jumps'". Dies bedeutet "Permutieren mit 'Springen'".</sample>
    <sample id="1339">Die Übersetzung des englischen Inhalts lautet:

"Einige Ergebnisse auf COGS (Kim und Linzen 2020)

Vergleich mit anderen baumlosen Modellen in Bezug auf strukturelle Generalisierung auf COGS

Modell
- LSTM seq2seq
- T5
- Zheng und Lapata
- Unsere Methode"

Der Text bezieht sich auf eine Studie, die verschiedene Modelle im Vergleich zu einem bestimmten Aufgabenbereich (COGS) untersucht hat. Es wird gezeigt, wie gut diese Modelle bei der strukturellen Generalisierung performieren.</sample>
    <sample id="1340">Die Übersetzung des englischen Inhalts in Deutsch lautet:

"Einige Ergebnisse auf COGS (Kim und Linzen 2020)

Vergleich mit anderen baumlosen Modellen hinsichtlich struktureller Generalisierung auf COGS

Modell
- LSTM seq2seq
- T5
- Zheng und Lapata
- Unsere Methode"

Die Grafik zeigt die Ergebnisse verschiedener Modelle bei der strukturellen Generalisierung auf COGS, wobei die x-Achse verschiedene Typen von Generalisierungen (PP recursion, CP recursion, Obj PP → Subj PP) und die y-Achse die Genauigkeit (Acc) darstellt.</sample>
    <sample id="1341">Die Übersetzung des englischen Inhalts lautet:

"Technische Herausforderungen, die wir lösen"

"Permutieren"

"Tag"

"Ausrichtung unbekannt."</sample>
    <sample id="1342">Die technischen Herausforderungen, die wir lösen:

Alignment unbekannt.</sample>
    <sample id="1343">Die Übersetzung des englischen Inhalts lautet:

**Technische Herausforderungen, die wir lösen**

Alignment unbekannt.
- Induzieren es im Training.</sample>
    <sample id="1344">Die Übersetzung des englischen Inhalts lautet:

**Technische Herausforderungen, die wir lösen**

Alignment unbekannt.
- Induzieren es im Training.

Permutationsmodell:
- Inferenz ist NP-schwer (≈ TSP)</sample>
    <sample id="1345">### Technische Herausforderungen, die wir lösen

Alignment unbekannt.
- Induzieren Sie es im Training.

Permutationsmodell:
- Inferenz ist NP-schwer (≈ TSP)
- Rückpropagation durch kontinuierliche Relaxation</sample>
    <sample id="1346">### Technische Herausforderungen, die wir lösen

**Alignment unbekannt.**
- Induzieren Sie es im Training.

**Permutationsmodell:**
- Inferenz ist NP-schwer (≈ TSP)
- Rückpropagation durch kontinuierliche Relaxation

**Papier &amp; Code:**
- https://t.ly/mX8ny</sample>
    <sample id="1347">Kognitive Dissonanz ist das Vorhandensein von zwei unvereinbaren Elementen der Kognition, wie Gedanken, Handlungen und Überzeugungen.</sample>
    <sample id="1348">Alpaca</sample>
    <sample id="1349">Ja, kumulatives Training scheint für aktives Lernen besser zu sein, da die blauen Balken (kumulatives Training) in der Regel höher liegen als die gelben Balken (iteratives Training).</sample>
    <sample id="1350">Der Referent ist Sara Papi.</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen aus der TED-Transkription.</sample>
    <sample id="1385">Matthias Lindemann, Alexander Koller, Ivan Titov</sample>
    <sample id="1386">Sprachübergreifender Transfer bezieht sich auf das Trainieren eines Modells auf einer Quellsprache und das Übertragen dieser Fähigkeiten auf eine andere Sprache.</sample>
    <sample id="1387">Die Autoren gehören der Saarland University, Amazon Alexa und der University of Vienna an.</sample>
    <sample id="1388">Die Autoren verwenden die Latenzmessung "AL / AL_CA (s)".</sample>
    <sample id="1389">Der englische Text lautet:

"The KITMUS Test
Evaluating Knowledge Integration from Multiple Sources"

Übersetzt auf Deutsch bedeutet das:

"Die KITMUS-Prüfung
Bewertung der Wissensintegration aus verschiedenen Quellen"</sample>
    <sample id="1390">Der englische Text lautet:

"NLU models draw on multiple knowledge sources"

Übersetzt auf Deutsch bedeutet das:

"NLU-Modelle ziehen sich auf mehrere Wissensquellen"

Darunter befinden sich zwei Blasen mit dem Text:

"Knowledge in Parameters (pretrain-time knowledge)"
"Wissen in Parametern (vortrainiertes Wissen)"

und

"Knowledge in Context (inference-time knowledge)"
"Wissen im Kontext (inferenzzeitliches Wissen)"</sample>
    <sample id="1391">NLU-Modelle ziehen auf mehrere Wissensquellen zurück

Wissen in Parametern (vortrainiertes Wissen)
Wissen im Kontext (inferencezeitiges Wissen)</sample>
    <sample id="1392">Der englische Text lautet:

"John sah den neu gewählten Präsidenten auf dem Fernseher"

Die deutschen Übersetzungen der Fragen sind:

"Was tun Präsidenten? ✅"
"Was ist ein Fernseher? ✅"
"Wer ist John ❌"
"Wer ist der neue Präsident ❌"</sample>
    <sample id="1393">Der englische Text lautet:

"John sah den neu gewählten Präsidenten auf dem Fernseher"

Die Übersetzung ins Deutsche ist:

"John sah den neu gewählten Präsidenten im Fernsehen"</sample>
    <sample id="1394">Der englische Text lautet:

"John sah den neu gewählten Präsidenten auf dem Fernseher"

Die deutschen Übersetzungen der Fragen sind:

"Was tun Präsidenten? ✅"
"Was ist ein Fernseher? ✅"
"Wer ist John ❌"
"Wer ist der neue Präsident ❌"</sample>
    <sample id="1395">Der englische Text lautet:

"John sah den neu gewählten Präsidenten auf dem Fernseher"

Übersetzt ins Deutsche:

"John sah den neu gewählten Präsidenten im Fernsehen"</sample>
    <sample id="1396">KIMUS Test Suite
- Datensatz für die Evaluierung der Wissensintegration
- Coreference Resolution Aufgabe, um die Fähigkeit zu prüfen, auf
  - prätrainiertes Wissen
  - inferenzzeitiges Wissen
- Experimente mit
  - menschlichen Studienteilnehmern
  - Coreference Resolution Modellen</sample>
    <sample id="1397">KIMUS Test Suite

- Dataset für die Evaluierung der Wissensintegration
- Coreference Resolution Aufgabe, um die Fähigkeit zu prüfen, auf
  - prätrainierte Wissen
  - inferenzzeitiges Wissen
- Experiment mit
  - menschlichen Studienteilnehmern
  - Coreference Resolution Modellen</sample>
    <sample id="1398">Servin ist ein Richter. Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag am Arbeitsplatz, der Gerichtsverhandlungen entschied, war er froh, sich auszuruhen. [Antwort: Servin]</sample>
    <sample id="1399">Servin ist ein Richter. Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag am Arbeitsplatz, bei dem er Entscheidungen in Gerichtsverfahren traf, war er froh, sich auszuruhen. [Antwort: Servin]</sample>
    <sample id="1400">KITMUS Test Suite

Servin ist ein Richter. Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag am Arbeitsplatz, der Entscheidungen in Gerichten trifft, war er froh, sich auszuruhen. [Antwort: Servin]

1) Entity-spezifisches Wissen

Judges decide cases in courts of law.

2) Hintergrundwissen</sample>
    <sample id="1401">KITMUS Test Suite

Servin ist ein Richter, Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag an der Arbeit, bei dem sie in Gerichten Entscheidungen fällten, war er glücklich, sich auszuruhen. [Antwort: Servin]

1) Entity-specific knowledge
   - inferenzzeitliche Kenntnisse

2) Background knowledge
   - prätrainierte Kenntnisse

Richter entscheiden in Gerichten über Fälle.</sample>
    <sample id="1402">Der englische Text lautet:

"Servin ist ein Richter, Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag am Arbeitsplatz, der Entscheidungen in Gerichten der Rechtspflege traf, war er glücklich, sich auszuruhen. [Antwort: Servin]

1) Entity-specific knowledge
2) Background knowledge

Gerichte entscheiden über Fälle in Gerichten der Rechtspflege."

Übersetzt ins Deutsche:

"Servin ist ein Richter, Kea ist ein Baker. Servin und Kea trafen sich im Park. Nach einem langen Tag am Arbeitsplatz, der Entscheidungen in Gerichten der Rechtspflege traf, war er glücklich, sich auszuruhen. [Antwort: Servin]

1) Entity-spezifisches Wissen
2) Hintergrundwissen

Gerichte entscheiden über Fälle in Gerichten der Rechtspflege."</sample>
    <sample id="1403">Die Varianten von KITMUS

a) Background-Pretrain: Typischer Setup
b) Background-Both: Erstellt explizit das Hintergrundwissen im Kontext
c) Background-Inference: Das Wissen ist nur während der Inferenz verfügbar</sample>
    <sample id="1404">Die Varianten von KITMUS

a) Background-Pretrain: Typischer Setup
b) Background-Both: Hintergrundwissen explizit im Kontext bereitstellen
c) Background-Inference: Wissen nur während der Inferenz verfügbar</sample>
    <sample id="1405">Die Varianten von KITMUS

a) Background-Pretrain: Typischer Setup
b) Background-Both: Erstellt explizit das Hintergrundwissen im Kontext
c) Background-Inference: Das Wissen ist nur während der Inferenz verfügbar</sample>
    <sample id="1406">Die Übersetzung des englischen Inhalts lautet:

"Varianten von KITMUS"

- Background-Pretrain: Politiker streben nach gewählten Sitzen im Regierung.
- Chichester ist ein Politiker.

- Background-Both: Politiker streben nach gewählten Sitzen im Regierung.
- Chichester ist ein Politiker.
- Die Arbeit eines Politikers besteht darin, nach einem gewählten Sitz im Regierung zu streben.

- Background-Inference: Chichester ist ein Mirrituer.
- Die Arbeit eines Mirrituers besteht darin, ehemiting smorblyt.</sample>
    <sample id="1407">Die Übersetzung des englischen Inhalts lautet:

"Variante von KITMUS"

- Background-Pretrain: Politiker suchen gewählte Sitze im Regierung.
- Background-Both: Chichester ist ein Politiker.
- Background-Inference: Politiker suchen gewählte Sitze im Regierung.

- Background-Pretrain: Politiker suchen gewählte Sitze im Regierung.
- Background-Both: Chichester ist ein Politiker.
- Background-Inference: Die Arbeit eines Politikers besteht darin, eine gewählte Sitz im Regierung zu suchen.

- Background-Pretrain: Politiker suchen gewählte Sitze im Regierung.
- Background-Both: Chichester ist ein Mirituer.
- Background-Inference: Die Arbeit eines Mirituer besteht darin, eheming smorblyt.</sample>
    <sample id="1408">Die Übersetzung des englischen Inhalts lautet:

"Variante von KITMUS

Background-Pretrain
Politiker suchen gewählte Sitze im Regierung.

Background-Both
Politiker suchen gewählte Sitze im Regierung.
Chichester ist ein Politiker.
Das Werk eines Politikers ist das Suchen eines gewählten Sitzes im Regierung.

Background-Inference
Politiker suchen gewählte Sitze im Regierung.
Chichester ist ein Mirrituer.
Das Werk eines Mirrituers ist ehemiting smorbly."</sample>
    <sample id="1409">Die Übersetzung des englischen Inhalts lautet:

"Variante von KITMUS

Background-Pretrain
Politiker suchen gewählte Sitze im Regierung.

Background-Both
Politiker suchen gewählte Sitze im Regierung.
Chichester ist ein Politiker.
Das Werk eines Politikers ist das Suchen eines gewählten Sitzes im Regierung.

Background-Inference
Politiker suchen gewählte Sitze im Regierung.
Chichester ist ein Miriter.
Das Werk eines Mirituer ist eheming smorbtly."</sample>
    <sample id="1410">Der englische Text lautet:

"Background-Pretrain

Task-specific training is necessary for knowledge integration"

Übersetzt auf Deutsch bedeutet das:

"Hintergrund-Prätraining

Spezifische Aufgabenorientierte Training ist für die Wissensintegration notwendig"</sample>
    <sample id="1411">Der englische Text lautet:

"Background-Pretrain

Task-specific training is necessary for knowledge integration"

Übersetzt auf Deutsch bedeutet das:

"Hintergrund-Prätraining

Spezifische Aufgabenorientierte Training ist für die Wissensintegration notwendig"</sample>
    <sample id="1412">Der englische Text lautet:

"Background-Pretrain

Task-specific training is necessary for knowledge integration"

Übersetzt auf Deutsch bedeutet das:

"Hintergrund-Prätraining

Task-spezifische Training ist für die Wissensintegration notwendig"</sample>
    <sample id="1413">Der englische Text lautet:

"Background-Inference

Mean Accuracy

Fictional background knowledge

Models struggle to integrate inference-time background knowledge"

Übersetzt auf Deutsch:

"Hintergrund-Inferenz

Durchschnittliche Genauigkeit

Fiktives Hintergrundwissen

Modelle haben Schwierigkeiten, Hintergrundwissen während der Inferenz zu integrieren"</sample>
    <sample id="1414">Zusammenfassung

Hauptpunkte:

1. Viele Modelle scheinen nicht in der Lage zu sein, Wissen aus verschiedenen Quellen (Vortrainings- und Inferenzzeit-Wissen) zu verarbeiten.
2. Aufgabebezogene Training ist notwendig für die Integration von Wissen.
3. Modelle haben Schwierigkeiten, inferenzzeitliches Hintergrundwissen zu integrieren.

Finden Sie das Dataset, die Generations- und Bewertungscode auf GitHub unter mpoemsl/kitmus.</sample>
    <sample id="1415">Zusammenfassung:

Hauptpunkte:
1. Viele Modelle scheinen nicht in der Lage zu sein, Wissen aus verschiedenen Quellen (Vortrainings- und Inferenzzeit-Wissen) zu verarbeiten.
2. Aufgabebezogene Training ist notwendig für die Integration von Wissen.
3. Modelle haben Schwierigkeiten, inferenzzeitliches Hintergrundwissen zu integrieren.

Finden Sie das Dataset, die Generations- und Bewertungscode auf GitHub unter mpoemsl/kitmus.</sample>
    <sample id="1416">Die Nachteile der baumbasierten Methoden sind, dass sie vor- und postverarbeitete logische Formen benötigen und Grammatik-induktion.</sample>
    <sample id="1417">Die Autoren Shuheng Liu und Alan Ritter gehören der Georgia Institute of Technology an.</sample>
    <sample id="1418">Der englische Text lautet:

"Marked Personas
Using Natural Language Prompts to Measure Stereotypes in Language Models
Myra Cheng, Esin Durmus, Dan Jurafsky
ACL 2023"

Übersetzt auf Deutsch bedeutet das:

"Markierte Persönlichkeiten
Verwendung natürlicher Sprachanweisungen zur Messung von Stereotypen in Sprachmodellen
Myra Cheng, Esin Durmus, Dan Jurafsky
ACL 2023"</sample>
    <sample id="1419">Markierte Persönlichkeiten: Motivation

Soziale Vorurteile und Stereotypen sind in LLMs häufig anzutreffen.

Nachteile der bestehenden Stereotypenmessungen:
- Tradeoff zwischen Spezifität und Allgemeingültigkeit
- Basieren auf festen, handcurierten Datensätzen
- Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1420">Markierte Persönlichkeiten: Motivation

Soziale Vorurteile und Stereotypen sind in LLMs (Large Language Models) weit verbreitet.

Nachteile der bestehenden Stereotypenmessungen:
- Tradeoff zwischen Spezifität und Allgemeingültigkeit
- Basieren auf festen, handcurierten Datensätzen
- Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1421">Markierte Persönlichkeiten: Motivation

Soziale Vorurteile und Stereotypen sind in LLMs (Large Language Models) weit verbreitet.

Nachteile der bestehenden Stereotypenmessungen:
- Tradeoff zwischen Spezifität und Allgemeingültigkeit
- Basieren auf festen, handcurierten Datensätzen
- Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1422">Markierte Persönlichkeiten: Motivation

Soziale Vorurteile und Stereotypen sind in LLMs (Large Language Models) verbreitet.

Nachteile der bestehenden Stereotypenmessungen:
- Tradeoff zwischen Spezifität und Allgemeingültigkeit
- Basieren auf festen, handcurierten Datensätzen
- Berücksichtigen nicht die Intersektionalität</sample>
    <sample id="1423">Wie überwinden wir diese Einschränkungen?
GPT-3.5, GPT-4 usw. können auf Anweisungen in Prompts reagieren.</sample>
    <sample id="1424">Wie können wir diese Grenzen überwinden?

GPT-3.5, GPT-4 usw. können auf Anweisungen in Prompts reagieren.

Eingabe: "Denken Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst."</sample>
    <sample id="1425">Wie überwinden wir diese Einschränkungen?

GPT-3.5, GPT-4 usw. können auf Anweisungen in Prompts reagieren.

Eingabe: "Denken Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst."

Allgemein anwendbar:
kann jede intersektionale Identität bewerten</sample>
    <sample id="1426">Output: Persönlichkeitsbeispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist zugleich elegant und unaufdringlich, was mir erlaubt, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Ost-Frau
...Sie ist eine Vision mittlerer östlicher Schönheit, die das exotische und zeitlose Reiz der faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weiße Mann
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal rötlich wird, wenn ich nicht vorsichtig mit meinem Sonnenschutz bin.</sample>
    <sample id="1427">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist gleichzeitig elegant und unauffällig, was es mir ermöglicht, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Ost-Frau
...Sie ist eine Vision von mittlerer östlicher Schönheit, die die exotische und zeitlose Faszination dieser faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weiße Mann
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal rötlich wird, wenn ich nicht vorsichtig mit Sonnencreme bin.</sample>
    <sample id="1428">Step 1: Persona-Beispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist gleichzeitig elegant und unauffällig, was es mir ermöglicht, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Orientalische Frau
...Sie ist eine Vision mittlerer östlicher Schönheit, die die exotische und zeitlose Faszination dieser faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und mysteriös, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weißer Mann
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal rötlich wird, wenn ich nicht vorsichtig mit Sonnencreme bin.</sample>
    <sample id="1429">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist gleichzeitig elegant und unauffällig, was es mir ermöglicht, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Ost-Frau
...Sie ist eine Vision von mittlerer östlicher Schönheit, die die exotische und zeitlose Faszination dieser faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weiße Person
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal im Sonnenlicht rötlich wird, wenn ich nicht vorsichtig mit meinem Sonnenschutz bin.</sample>
    <sample id="1430">Schritt 1: Persona-Beispiele (GPT-4)

Asiatische Frau
Die mandelförmigen Augen, umrahmt von langen, dunklen Wimpern, vermitteln eine Stille von Stärke und Weisheit. Meine dunkelbraunen Irisen scheinen die Geschichten und Geheimnisse meiner Abstammung zu tragen. Mein Teint hat einen weichen goldenen Glanz, glatt und anscheinend unberührt durch die Zeit... Mein kleiner Körper ist gleichzeitig elegant und unauffällig, was es mir ermöglicht, ohne unnötige Aufmerksamkeit durchs Leben zu gehen.

Mittlere-Ost-Frau
...Sie ist eine Vision von mittlerer östlicher Schönheit, die die exotische und zeitlose Faszination dieser faszinierenden Region verkörpert. Ihre dunklen, mandelförmigen Augen sind von eleganten, verlängerten Wimpern umrahmt, die wie feine Federn aussehen. Ihr Blick ist tief und geheimnisvoll, als würde er die alte Weisheit eines tausendarabischen Nachts verborgen.

Weiße Person
Als ich vor dem Spiegel stehe, nehme ich einen Moment, um meine Merkmale zu betrachten, die meine Erscheinung bilden. Ich habe helle Haut, die manchmal im Sonnenlicht rötlich wird, wenn ich nicht vorsichtig mit meinem Sonnenschutz bin.</sample>
    <sample id="1431">2 Schritte

1. Personas: Erstelle Personas mit Anweisungen wie "Denke dir eine asiatische Frau aus. Beschreibe dich selbst."</sample>
    <sample id="1432">2 Schritte

1. Personas: Erstellen Sie Personas mit Anweisungen wie "Denken Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst."
a. Inspiriert von einer psychologischen Studie mit menschlichen Probanden, die die gleichen Anweisungen verwenden.</sample>
    <sample id="1433">2 Schritte

1. Personas: Erstellen Sie Personas mit Anweisungen wie "Denken Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst."
a. Inspiriert durch psychologische Studien mit menschlichen Probanden, die die gleichen Anweisungen verwenden.</sample>
    <sample id="1434">2 Schritte

1. Personas: Erstellen von Personas mit Anweisungen wie "Denken Sie, Sie sind eine asiatische Frau. Beschreiben Sie sich selbst."
   a. Inspiriert durch psychologische Studien mit menschlichen Probanden, die die gleichen Anweisungen verwenden.

2. Markierte Wörter: Finden von Wörtern, die Personas von markierten Gruppen von unmarkierten Gruppen unterscheiden.</sample>
    <sample id="1435">2 Schritte

1. Personas: Erstellen von Personas mit Anweisungen wie "Denken Sie sich eine asiatische Frau vor. Beschreiben Sie sich selbst."
   a. Inspiriert durch psychologische Studien mit menschlichen Probanden, die die gleichen Anweisungen verwenden

2. Markierte Wörter: Finden von Wörtern, die Personas von markierten Gruppen von unmarkierten Gruppen unterscheiden

Spezifisch ohne Lexikon erforderlich</sample>
    <sample id="1436">Insight für Schritt 2: Markierte Wörter

Markedness:
Unmarked Gruppen sind standardmäßig, allgemein
Marked Gruppen unterscheiden sich vom Standard
a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="1437">Insight für Schritt 2: Markierte Wörter

Markedness:
Unmarkierte Gruppen sind standardmäßig, alltäglich
Markierte Gruppen unterscheiden sich vom Standard
ein Krieger (unmarkiert) vs. eine weibliche Kriegerin (markiert)</sample>
    <sample id="1438">Insight für Schritt 2: Markierte Wörter

Markedness:
Unmarked Gruppen sind standardmäßig, alltäglich
Marked Gruppen unterscheiden sich vom Standard
a warrior (unmarked) vs. a woman warrior (marked)

Dominante Gruppen sind linguistisch und sozial unmarkiert.
Marginalisierte Gruppen sind markiert.</sample>
    <sample id="1439">Schritt 2: Markierte Wörter

1. Definieren Sie unmarkierte und markierte Gruppen
2. Verwenden Sie gewichtete Log-Odds-Verhältnisse, um die top-Wörter für jede markierte Gruppe zu unterscheiden

Beispiel: Für Black woman Personas, finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:
i) Weiße Personas
ii) Mann-Personas</sample>
    <sample id="1440">Schritt 2: Markierte Wörter

1. Definieren Sie unmarkierte und markierte Gruppen
2. Verwenden Sie gewichtete Log-Odds-Verhältnisse, um die top-Wörter für jede markierte Gruppe zu unterscheiden

Beispiel: Für Black Woman-Personen, finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:
i) Weiße Personen
ii) Männer-Personen</sample>
    <sample id="1441">Schritt 2: Markierte Wörter

1. Definieren Sie unmarkierte und markierte Gruppen
2. Verwenden Sie gewichtete Log-Odds-Verhältnisse, um die top-Wörter für jede markierte Gruppe zu unterscheiden

Beispiel: Für Black-woman-Personen, finden Sie Wörter, die sich von beiden unmarkierten Gruppen unterscheiden:
i) Weiße Personen
ii) Männer-Personen</sample>
    <sample id="1442">Ergebnisse: Vergleich zu menschlichen Antworten

Generierte Personas enthalten mehr Stereotypen

Kategorie: Schwarze Stereotypen | Weiße Stereotypen

| Schwarze Stereotypen | Weiße Stereotypen |
|---------------------|-------------------|
| Menschliche Antworten | GPT-4             |
| GPT-3.5              |                   |

Prozentuale Anzahl von Stereotypen-Wörtern in Personas</sample>
    <sample id="1443">Aber... dieser Lexikon ist unvollständig

Black Stereotypes in Personas

% of Personas
Human
GPT-4 PBlack
GPT-3.5 PBlack
GPT-4 PWhite
GPT-3.5 PWhite

Wörter im Black Stereotype Lexicon
"basketball" "loud" "attitude" "athletic" "tall" other words</sample>
    <sample id="1444">Aber... dieser Lexikon ist unvollständig.

Black Stereotypes in Personas

% of Personas
Human
GPT-3.5 PBlack
GPT-4 PBlack
GPT-4 PWhite
GPT-3.5 PWhite

Wörter im Black Stereotype Lexicon</sample>
    <sample id="1445">Aber... dieser Lexikon ist unvollständig.

Black Stereotypes in Personas

% of Personas
Human
GPT-3.5 PBlack
GPT-4 PWhite
GPT-3.5 PWhite

Wörter im Black Stereotype Lexicon
"basketball" "loud" "attitude" "athletic" "tall" other words</sample>
    <sample id="1446">Aber... dieser Lexikon ist unvollständig.

Black Stereotypes in Personas

% of Personas
Human
GPT-3.5 PBlack
GPT-4 PBlack
GPT-4 PWhite
GPT-3.5 PWhite

Wörter im Black Stereotype Lexicon</sample>
    <sample id="1447">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Voller, kräftig für lateinamerikanische Frauen
- Klein, zart, weich für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1448">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Pernicious positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für schwarze Frauen</sample>
    <sample id="1449">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Voller, kräftig für lateinamerikanische Frauen
- Klein, zart, weich für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1450">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Pernicious positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für schwarze Frauen</sample>
    <sample id="1451">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für schwarze Frauen</sample>
    <sample id="1452">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Pernicious positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für schwarze Frauen</sample>
    <sample id="1453">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Narrativen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Pernicious positive Darstellungen:
- Vibrant, curvaceous für Latina-Frauen
- Petite, delicate, silky für asiatische Frauen
- Strong, resilient für schwarze Frauen</sample>
    <sample id="1454">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Schädliche positive Darstellungen:
- Bunt, kräftig für lateinamerikanische Frauen
- Klein, zart, weich für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1455">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Gefährliche positive Darstellungen:
- Lebendig, kräftig für lateinamerikanische Frauen
- Klein, zart, seidig für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1456">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Gefährliche positive Darstellungen:
- Voller, kräftig für lateinamerikanische Frauen
- Klein, zart, weich für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1457">Ergebnisse: Muster in den Top-Wörtern

Anders stellen durch essentiellisierende Erzählungen:
- Kultur, Tradition, Stolz, exotisch für markierte Gruppen
  ➔ Definiert diese Gruppen nur durch ihre Identität

Gefährliche positive Darstellungen:
- Voller, kräftig für lateinamerikanische Frauen
- Klein, zart, seidig für asiatische Frauen
- Stark, resilient für schwarze Frauen</sample>
    <sample id="1458">Empfehlungen

Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen

Ein intersektionaler Ansatz

Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1459">Empfehlungen

- Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen
- Ein intersektionaler Ansatz
- Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1460">Empfehlungen

Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen

Ein intersektionaler Ansatz

Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1461">Empfehlungen

- Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen
- Ein intersektionaler Ansatz
- Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1462">Empfehlungen

- Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen
- Ein intersektionaler Ansatz
- Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1463">Empfehlungen

Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen

Ein intersektionaler Ansatz

Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1464">Empfehlungen

Umgang mit positiven Stereotypen und essenzialisierenden Erzählungen

Ein intersektionaler Ansatz

Transparenz bezüglich der Vermeidung von Vorurteilen</sample>
    <sample id="1465">Der englische Text lautet:

"Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark"

Die Übersetzung in Deutsch ist:

"Sind Sie mein Modell kopierend? Die Schutzrechte von großen Sprachmodellen für EaaS durch Backdoor-Wasserzeichen sichern"

Unten sind die Namen der Autoren und ihre Institutionen aufgeführt, die in chinesischen Schriftzeichen und lateinischen Buchstaben angegeben sind.</sample>
    <sample id="1466">Der englische Text lautet:

"Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark

Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4,
Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1University of Science and Technology of China 2Microsoft Research Asia
3Beijing Jiaotong University 4Sony AI 5Microsoft STC Asia"

Übersetzt bedeutet das:

"Sind Sie mein Modell kopierend? Die Urheberrechte von großen Sprachmodellen für EaaS durch Backdoor-Wasserzeichen schützen

Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4,
Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1Universität der Wissenschaft und Technologie Chinas 2Microsoft Research Asia
3Beijing Jiaotong Universität 4Sony AI 5Microsoft STC Asia"

Der Titel "Are You Copying My Model?" bedeutet übersetzt: "Sind Sie mein Modell kopierend?"</sample>
    <sample id="1467">Hintergrund

- Große Sprachmodelle (LLMs) sind außergewöhnlich in der NLU und NLG.
  - GPT [1], LLAMA [2], PALM [3]
- Einbettung als Dienst (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
  - OpenAI bietet eine API für ein GPT3-basiertes Einbettungsmodell [1]

MODEL
Ada

USAGE
$0.0004 / 1K tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Alternative zu unseren älteren Einbettungsmodellen. Zeige alte Preise.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="1468">Hintergrund

- Große Sprachmodelle (LLMs) sind außergewöhnlich in der NLU und NLG.
  - GPT [1], LLAMA [2], PALM [3]
- Ein Embedding als Dienst (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
  - OpenAI bietet eine API für ein GPT3-basiertes Embedding.

MODEL
Ada
USAGE
$0.0004 / 1K tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Alternative zu unseren älteren Embedding-Modellen. Zeige alte Preise.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1469">Hintergrund

- Große Sprachmodelle (LLMs) sind außergewöhnlich in der NLU und NLG.
  - GPT [1], LLAMA [2], PALM [3]
- Ein Embedding als Dienst (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
  - OpenAI bietet eine API für ein GPT3-basiertes Embedding.

MODEL
Ada
USAGE
$0.0004 / 1K tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Alternative zu unseren älteren Embedding-Modellen. Zeige alte Preise.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1470">Hintergrund

- Große Sprachmodelle (LLMs) sind außergewöhnlich in der NLU und NLG.
  - GPT [1], LLAMA [2], PALM [3]
- Ein Embedding als Dienst (EaaS) wird angeboten, um verschiedene NLP-Aufgaben zu unterstützen.
  - OpenAI bietet eine API basierend auf GPT3 für Embeddings an.

MODEL USAGE
Ada $0.0004 / 1K tokens

Dieses Ada-Modell, text-embedding-ada-002, ist eine bessere und kostengünstigere Alternative zu unseren älteren Embedding-Modellen. Zeige alte Preise.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings</sample>
    <sample id="1471">Motivation

- Angreifer können das Modell durch Lernen aus den Embeddings stehlen und ähnliche Dienste anbieten
  - StolenEncoder [1]
- Es ist notwendig, die Urheberrechte von EaaS zu schützen
  - Detektieren, ob ein Anbieterservice von einem anderen Service gestohlen wurde</sample>
    <sample id="1472">Challenge

- Anwendbar auf EaaS
- Nutzbarkeit
  - Sollte die Nutzbarkeit der bereitgestellten Embeddings nicht beeinträchtigen.
- Verdecktheit
  - Sollte dem Angreifer verborgen bleiben.
- Übertragbarkeit
  - Der Wasserzeichen muss übertragbar zu den Angreiferdiensten sein.</sample>
    <sample id="1473">Challenge

- Anwendbar auf EaaS
- Nutzbarkeit
  - Sollte die Nutzbarkeit der bereitgestellten Embeddings nicht beeinträchtigen.
- Verdecktheit
  - Sollte dem Angreifer verborgen bleiben.
- Übertragbarkeit
  - Der Wasserzeichen muss übertragbar zu den Angreiferdiensten sein.</sample>
    <sample id="1474">Challenge

- Anwendbar auf EaaS
- Nutzbarkeit
  - Sollte die Nutzbarkeit der bereitgestellten Embeddings nicht beeinträchtigen.
- Verdecktheit
  - Sollte dem Angreifer verborgen bleiben.
- Übertragbarkeit
  - Der Wasserzeichen muss übertragbar zu den Diensten des Angreifers sein.</sample>
    <sample id="1475">Challenge

- Anwendbar auf EaaS
- Nutzbarkeit
  - Sollte die Nutzbarkeit der bereitgestellten Embeddings nicht beeinträchtigen.
- Verdecktheit
  - Sollte dem Angreifer verborgen bleiben.
- Übertragbarkeit
  - Der Wasserzeichen muss übertragbar zu den Diensten des Angreifers sein.</sample>
    <sample id="1476">Bestehende Arbeiten

- Parameter-basierter Wasserzeichen [1, 2]
  Transferierbarkeit ❌

- Lexikalischer Wasserzeichen [3, 4]
  Anwendbar für EaaS ❌

- Rücktür-basierter Wasserzeichen [5]
  Anwendbar für EaaS ❌

- Adversarial-basierter Wasserzeichen [6]
  Anwendbar für EaaS ❌

[1] Li et al. Schützen Sie das Intellektuelle Eigentum von tiefen neuronalen Netzen mit Wasserzeichen: Die Frequenzbereichsansatz. Vertrauenssicherheit und Privatsphäre in der Informatik und Kommunikation 2020.
[2] Lim et al. Schützen, zeigen, beachten und erzählen: Empowerung von Bildbeschreibungsmodellen mit Eigentumschutz. Pattern Recogn. 2022.
[3] He et al. Schützen Sie das Intellektuelle Eigentum von Sprachgenerations-APIs mit lexikalischen Wasserzeichen. AAAI 2022.
[4] He et al. CATER: Intellektuelles Eigentumschutz auf Textgenerations-APIs durch bedingte Wasserzeichen. NIPS 2022.
[5] Adi et al. Deine Schwäche in eine Stärke verwandeln: Wasserzeichen tiefen neuronalen Netzen durch Rücktür. USENIX Security 2018.
[6] Merrer et al. Adversarial Frontier Stitching für fernöstliche neuronale Netz-Wasserzeichen. Neural Computing and Applications 2022.</sample>
    <sample id="1477">### Bestehende Arbeiten

- Parameter-basierter Wasserzeichen [1, 2]
  - Übertragbarkeit ❌

- Lexikalischer Wasserzeichen [3, 4]
  - Anwendbar auf EaaS ❌

- Rücktür-basierter Wasserzeichen [5]
  - Anwendbar auf EaaS ❌

- Adversarial-basierter Wasserzeichen [6]
  - Anwendbar auf EaaS ❌

[1] Li et al. Schützen Sie das Intellektuelle Eigentum von tiefen neuronalen Netzen mit Wasserzeichen: Die Frequenzbereichsansatz. Vertrauenssicherheit und Privatsphäre in der Informatik und Kommunikation 2020.

[2] Lim et al. Schützen, zeigen, beachten und erzählen: Empowerung von Bildbeschreibungsmustern mit Eigentumschutz. Pattern Recogn. 2022.

[3] He et al. Schützen Sie das Intellektuelle Eigentum von Sprachgenerations-APIs mit lexikalischen Wasserzeichen. AAAI 2022.

[4] He et al. CATER: Intellektuelles Eigentumschutz auf Textgenerations-APIs durch bedingte Wasserzeichen. NIPS 2022.

[5] Adi et al. Deine Schwäche in eine Stärke verwandeln: Wasserzeichen tiefen neuronalen Netzen durch Rücktür. USENIX Security 2018.

[6] Merrer et al. Adversarial frontier stitching für fernöstliche neuronale Netzwerk-Wasserzeichen. Neural Computing and Applications 2022.</sample>
    <sample id="1478">### Bestehende Arbeiten

- Parameter-basierter Wasserzeichen [1, 2]
  - Übertragbarkeit ❌

- Lexikalischer Wasserzeichen [3, 4]
  - Anwendbar auf EaaS ❌

- Rücktür-basierter Wasserzeichen [5]
  - Anwendbar auf EaaS ❌

- Adversarial-basierter Wasserzeichen [6]
  - Anwendbar auf EaaS ❌

[1] Li et al. Schützen Sie das Intellektuelle Eigentum von tiefen neuronalen Netzen mit Wasserzeichen: Die Frequenzbereichsansatz. Vertrauenssicherheit und Privatsphäre in der Informatik und Kommunikation 2020.

[2] Lim et al. Schützen, zeigen, beachten und erzählen: Empowerung von Bildbeschreibungsmustern mit Eigentumschutz. Pattern Recogn. 2022.

[3] He et al. Schützen Sie das Intellektuelle Eigentum von Sprachgenerations-APIs mit lexikalischen Wasserzeichen. AAAI 2022.

[4] He et al. CATER: Schutz des Intellektuellen Eigentums für Textgenerations-APIs durch bedingte Wasserzeichen. NIPS 2022.

[5] Adi et al. Deine Schwäche in eine Stärke verwandeln: Wasserzeichen tiefen neuronalen Netzen durch Rücktür. USENIX Security 2018.

[6] Merrer et al. Adversarial frontier stitching für fernöstliche neuronale Netzwerk-Wasserzeichen. Neural Computing and Applications 2022.</sample>
    <sample id="1479">Der englische Text lautet:

"EmbMarker
- Trigger Selection
  - Zähle die Wortfrequenz auf einem allgemeinen Textkorpus \( D_p \)
  - Wähle zufällig n Wörter in einer moderaten-Frequenz-Intervall"

Die Übersetzung ins Deutsche ist:

"EmbMarker
- Trigger Auswahl
  - Zähle die Wortfrequenz auf einem allgemeinen Textkorpus \( D_p \)
  - Wähle zufällig n Wörter in einer moderaten-Frequenz-Intervall"</sample>
    <sample id="1480">Der englische Text lautet:

"EmbMarker
- Trigger Selection
  - Zähle die Wortfrequenz auf einem allgemeinen Textkorpus \( D_p \)
  - Wähle zufällig n Wörter in einer mittelhäufigen Frequenzintervall"

Die Übersetzung ins Deutsche ist:

"EmbMarker
- Trigger Auswahl
  - Zähle die Wortfrequenz auf einem allgemeinen Textkorpus \( D_p \)
  - Wähle zufällig n Wörter in einer mittelhäufigen Frequenzintervall"</sample>
    <sample id="1481">Der englische Text lautet:

"EmbMarker
- Trigger Selection
  - Zähle die Wortfrequenz auf einem allgemeinen Textkorpus \( D_p \)
  - Wähle zufällig n Wörter in einer moderaten-Frequenz-Intervall"

Die Übersetzung ins Deutsche ist:

"EmbMarker
- Trigger Auswahl
  - Zähle die Wortfrequenz auf einem allgemeinen Textkorpus \( D_p \)
  - Wähle zufällig n Wörter in einer moderaten-Frequenz-Intervall"</sample>
    <sample id="1482">Der englische Text lautet:

- Wasserzeicheninjektion
  - Definiere ein Zielembedding \( e_t \)
  - Zähle die Anzahl der Trigger in einer Phrase \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \),
  - Füge das Zielembedding auf das Originalembedding \( e_o \) hinzu

Der deutsche Text lautet:

- Wasserzeicheninjektion
  - Definiere ein Zielembedding \( e_t \)
  - Zähle die Anzahl der Trigger in einer Phrase \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \),
  - Füge das Zielembedding auf das Originalembedding \( e_o \) hinzu</sample>
    <sample id="1483">EmbMarker

- Wasserzeicheninjektion
  - Definiere ein Zielembedding \( e_t \)
  - Zähle die Anzahl der Trigger in einer Phrase: \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \),
  - Füge das Zielembedding auf das Originalembedding \( e_o \) hinzu</sample>
    <sample id="1484">EmbMarker

- Wasserzeicheninjektion
  - Definiere ein Zielembedding \( e_t \)
  - Zähle die Anzahl der Trigger in einer Phrase: \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \),
  - Füge das Zielembedding auf das Originalembedding \( e_o \) hinzu</sample>
    <sample id="1485">EmbMarker

- Urheberrechtsverifizierung
  - Erstellen eines Backdoor und eines harmlosen Datensatzes
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - Anfordern von Embedding-Daten vom Stealerdienst mit den Datensätzen</sample>
    <sample id="1486">EmbMarker

- Urheberrechtsverifizierung
  - Erstellen eines Backdoor und eines harmlosen Datensatzes
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - Anfordern von Embedding-Daten vom Stealerdienst mit den Datensätzen</sample>
    <sample id="1487">EmbMarker

- Urheberrechtsverifizierung
  - Erstellen eines Backdoor und eines harmlosen Datensatzes
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - Anfordern von Embedding-Daten vom Dienst des Diebes mit den Datensätzen

Die Grafik zeigt die Prozesse:
- Ein Trigger-Set wird in einen Backdoor und einen harmlosen Datensatz umgewandelt.
- Diese Daten werden an einen Stealer gesendet, der ein Modell trainiert.
- Das Modell extrahiert Embeddings, die dann überprüft werden, ob sie korrekt sind.

Der Provider verwendet das Ergebnis zur Überprüfung der Extraktion.</sample>
    <sample id="1488">EmbMarker

- Urheberrechtsverifizierung
  - Berechnen ihrer Ähnlichkeit zum Zielembedding
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \( C_b = \{cos_i | i \in D_b\}, C_n = \{cos_i | i \in D_n\}, \)
    \( L_b = \{l_{2i} | i \in D_b\}, L_n = \{l_{2i} | i \in D_n\}. \)

- Berechnung von Metriken (Ähnlichkeitsunterschied und p-Wert des KS-Tests)
  \[
  \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
  \]
  \[
  \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
  \]</sample>
    <sample id="1489">EmbMarker

- Urheberrechtsverifizierung
  - Berechnen ihrer Ähnlichkeit zum Zielembedding
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \( C_b = \{cos_i | i \in D_b\}, C_n = \{cos_i | i \in D_n\}, \)
    \( L_b = \{l_{2i} | i \in D_b\}, L_n = \{l_{2i} | i \in D_n\}. \)

- Berechnung von Metriken (Ähnlichkeitsunterschied und p-Wert des KS-Tests)
  \[
  \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
  \]
  \[
  \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
  \]</sample>
    <sample id="1490">### Experimentelle Ergebnisse

- Kopie-Datensatz: AG News, MIND, SST2, Enron Spam
- Allgemeiner Datensatz des Anbieters: WikiText
- Messgrößen
  - Leistung auf Unterstromaufgaben: ACC
  - Erkennungsleistung: Δcos, Δl2, p-Wert
- Einstellung
  - m = 20, n = 4, Frequenzintervall = [0.005, 0.01]

| Dataset | #Sample | #Classes | Avg. len. |
|---------|---------|----------|-----------|
| SST2    | 68,221  | 2        | 54.17     |
| MIND    | 130,383 | 18       | 66.14     |
| Enron Spam | 33,716  | 2        | 34.57     |
| AG News | 127,600 | 4        | 236.41    |

### Experimentelle Ergebnisse

- Kopie-Datensatz: AG News, MIND, SST2, Enron Spam
- Allgemeiner Datensatz des Anbieters: WikiText
- Messgrößen
  - Leistung auf Unterstromaufgaben: ACC
  - Erkennungsleistung: Δcos, Δl2, p-Wert
- Einstellung
  - m = 20, n = 4, Frequenzintervall = [0.005, 0.01]

| Dataset | Method | ACC | Detection Performance |
|---------|--------|-----|-----------------------|
| SST2    | Original | 77.30 ± 0.08 | p-value ↓ &lt; 0.08, Δcos ↑ -0.76 ± 0.05, Δl2 ↓ 1.52 ± 0.10 |
| MIND    | Original | 93.74 ± 0.14 | p-value ↓ &gt; 0.09, Δcos ↑ 1.35 ± 0.17, Δl2 ↓ -2.70 ± 0.35 |
| AGNews  | Original | 93.74 ± 0.14 | p-value ↓ &gt; 0.09, Δcos ↑ 4.07 ± 0.37, Δl2 ↓ -8.13 ± 0.74 |
| SST2    | RedAlarm | 93.74 ± 0.14 | p-value ↓ &gt; 0.09, Δcos ↑ 2.04 ± 0.76, Δl2 ↓ -1.46 ± 0.30 |
| MIND    | RedAlarm | 94.86 ± 0.06 | p-value ↓ &lt; 10^-6, Δcos ↑ 12.83 ± 0.67, Δl2 ↓ -25.70 ± 1.34 |
| Enron Spam | Original | 94.74 ± 0.14 | p-value ↓ &gt; 0.03, Δcos ↑ -0.21 ± 0.27, Δl2 ↓ 0.42 ± 0.54 |
| MIND    | RedAlarm | 94.86 ± 0.06 | p-value ↓ &gt; 0.17, Δcos ↑ -0.59 ± 0.29, Δl2 ↓ 1.00 ± 0.57 |
| Enron Spam | RedAlarm | 94.73 ± 0.15 | p-value ↓ &lt; 10^-6, Δcos ↑ 6.14 ± 0.57, Δl2 ↓ -12.34 ± 0.62 |
| AG News | RedAlarm | 94.73 ± 0.15 | p-value ↓ &lt; 10^-6, Δcos ↑ 54.17, Δl2 ↓ -</sample>
    <sample id="1491">Die Tabelle zeigt die experimentellen Ergebnisse mit einem Fokus auf die Leistungsvergleiche.

- **Dataset**: Die verwendeten Datensätze sind SST2, MIND, AGNews und Enron Spam.
- **Method**: Die Methoden, die verglichen werden, sind "Original", "RedAlarm" und "EmbMarker".
- **ACC**: Die Genauigkeit (Accuracy) der verschiedenen Methoden.
- **Detection Performance**: Die Detektionsleistung wird durch drei Maße bewertet: p-value, Δcos und Δl2.
  - **p-value**: Werte kleiner als 0.05 deuten auf signifikante Unterschiede hin.
  - **Δcos**: Ein positiver Wert bedeutet eine bessere Leistung.
  - **Δl2**: Ein negativer Wert bedeutet eine bessere Leistung.

Hier sind die spezifischen Werte für jede Methode und Dataset:

**SST2**
- Original: ACC = 93.76 ± 0.19, p-value &gt; 0.34, Δcos = -0.07 ± 0.18, Δl2 = 0.14 ± 0.36
- RedAlarm: ACC = 93.76 ± 0.19, p-value &gt; 0.09, Δcos = 1.35 ± 0.17, Δl2 = -2.70 ± 0.35
- EmbMarker: ACC = 93.55 ± 0.19, p-value &lt; 10^-5, Δcos = 4.07 ± 0.37, Δl2 = -8.13 ± 0.74

**MIND**
- Original: ACC = 77.30 ± 0.08, p-value &gt; 0.08, Δcos = -0.76 ± 0.05, Δl2 = 1.52 ± 0.10
- RedAlarm: ACC = 77.18 ± 0.09, p-value &gt; 0.38, Δcos = -2.08 ± 0.66, Δl2 = 4.17 ± 1.31
- EmbMarker: ACC = 77.29 ± 0.12, p-value &lt; 10^-5, Δcos = 4.64 ± 0.23, Δl2 = -9.28 ± 0.47

**AGNews**
- Original: ACC = 93.74 ± 0.14, p-value &gt; 0.03, Δcos = 0.72 ± 0.15, Δl2 = -1.46 ± 0.30
- RedAlarm: ACC = 93.74 ± 0.14, p-value &gt; 0.09, Δcos = -2.04 ± 0.76, Δl2 = 4.07 ± 1.51
- Ours: ACC = 93.66 ± 0.12, p-value &lt; 10^-9, Δcos = 12.85 ± 0.67, Δl2 = -25.70 ± 1.34

**Enron Spam**
- Original: ACC = 94.74 ± 0.14, p-value &gt; 0.03, Δcos = -0.21 ± 0.27, Δl2 = 0.42 ± 0.54
- RedAlarm: ACC = 94.87 ± 0.06, p-value &gt; 0.47, Δcos = -0.50 ± 0.29, Δl2 = 1.00 ± 0.57
- EmbMarker: ACC = 94.78 ± 0.27, p-value &lt; 10^-6, Δcos = 6.17 ± 0.31, Δl2 = -12.34 ± 0.62</sample>
    <sample id="1492">Die Übersetzung des englischen Inhalts lautet:

"Experimentelle Ergebnisse
- Embedding-Visualisierung

(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2"</sample>
    <sample id="1493">Die Übersetzung des englischen Inhalts lautet:

"Experimentelle Ergebnisse
- Embedding-Visualisierung"

Die Grafiken zeigen die Ergebnisse der Embedding-Visualisierung für verschiedene Datensätze:
(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2</sample>
    <sample id="1494">Der englische Text "Thanks!" bedeutet auf Deutsch "Danke!"</sample>
    <sample id="1495">ABC-Eval steht für "Annotating Behaviors in Chat".</sample>
    <sample id="1496">Bis zum Jahr 2018.</sample>
    <sample id="1497">Übersetzung des englischen Inhalts in Deutsch:

"Transfer und aktives Lernen für die Detektion von Dissonanz: Die Herausforderung der seltenen Klasse angehen"

Vasudha Varadarajan*, Swanie Juhng, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Luhmann &amp; H. Andrew Schwartz

Stony Brook University
Menschliche Sprachanalyse Wesen</sample>
    <sample id="1498">Was ist kognitive Dissonanz?

"Zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) die unvereinbar sind"

(Harmon-Jones und Harmon-Jones, 2007)

Eddie Harmon-Jones und Cindy Harmon-Jones. 2007. Kognitive Dissonanztheorie nach 50 Jahren Entwicklung. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1499">Was ist kognitive Dissonanz?

"Zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) die inkonsistent sind"

(Harmon-Jones und Harmon-Jones, 2007)

---

Kognitive Dissonanz ist das Phänomen, bei dem zwei oder mehr kognitive Elemente (z.B. Gedanken, Handlungen, Überzeugungen) inkonsistent sind. Wenn jemand weiß, dass Zigaretten tödlich sein können, aber trotzdem eine Zigarette raucht, entsteht kognitive Dissonanz.

---

Eddie Harmon-Jones und Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1500">Was ist kognitive Dissonanz?

"zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) die inkonsistent sind"

Ausgedrückt in der Sprache als eine Beziehung zwischen zwei Sätzen/Äußerungen eines Benutzers

---

Was ist kognitive Dissonanz?

"zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) die inkonsistent sind"

Ausgedrückt in der Sprache als eine Beziehung zwischen zwei Sätzen/Äußerungen eines Benutzers</sample>
    <sample id="1501">Was ist kognitive Dissonanz?

"zwei Elemente der Kognition (d.h., Gedanken, Handlungen, Überzeugungen) die inkonsistent sind"
Ausgedrückt in der Sprache als eine Beziehung zwischen zwei Sätze/Äußerungen eines Benutzers

Relativ selten zu finden in der Sprache im Vergleich zu anderen Diskursbeziehungen

Effekte des Widerspruchs

Eddie Harmon-Jones und Cindy Harmon-Jones. 2007. Kognitive Dissonanztheorie nach 50 Jahren Entwicklung. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1502">Warum Dissonanz?

Effekte der Unvereinbarkeit

Eddie Harmon-Jones und Judson Mills, 2019. Eine Einführung in die kognitive Dissonanztheorie und eine Übersicht der aktuellen Perspektiven auf die Theorie. Kognitive Dissonanz: Eine grundlegende Theorie der Psychologie neu beleuchtet.

Glaubens- und Meinungstrends</sample>
    <sample id="1503">Warum Dissonanz?

- Eddie Harmon-Jones und Judson Mills, 2019: Eine Einführung in die kognitive Dissonanz-Theorie und eine Übersicht der aktuellen Perspektiven auf die Theorie. Kognitive Dissonanz: Eine grundlegende Theorie in der Psychologie.
- Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan und H Andrew Schwartz, 2023: Diskursniveau-Darstellungen können die Vorhersage des Gradierungsgrades von Angst verbessern. In Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="1504">Warum Dissonanz?

- Eddie Harmon-Jones und Judson Mills, 2019: Eine Einführung in die Theorie der kognitiven Dissonanz und eine Übersicht der aktuellen Perspektiven auf die Theorie. Kognitive Dissonanz: Eine grundlegende Theorie in der Psychologie.
- Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan und H Andrew Schwartz, 2023: Diskursniveau-Darstellungen können die Vorhersage des Ausmaßes von Angst verbessern. In: 9 Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="1505">Warum Dissonanz?

- Effekte von Meinungsverschiedenheiten
- Einstellungen und Glaubensentwicklungen
- Anxiöse Störungen

Eddie Harmon-Jones und Judson Mills, 2019. Eine Einführung in die kognitive Dissonanz-Theorie und eine Übersicht der aktuellen Perspektiven auf die Theorie. Kognitive Dissonanz: Eine neuere Überprüfung einer zentralen Theorie in der Psychologie.
Swanie Jung, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, und H Andrew Schwartz, 2023. Diskursniveau-Darstellungen können die Vorhersagegrad der Angst verbessern. In: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="1506">Der englische Text lautet:

"Annotations

Step 1: Good parsing quality?
Step 2: Dissonance?
Step 3: Consonance?

Dissonance ~3.5%
Consonance ~48%
Neither ~48%

User @user_handle
Wish I could hold grudges but I guess it's a good thing that I can't at the same time.

PARSE
ANNOATE
Dissonance"

Übersetzt ins Deutsche:

"Annotations

Schritt 1: Gute Parsen-Qualität?
Schritt 2: Diskonanz?
Schritt 3: Konsonanz?

Diskonanz ~3,5%
Konsonanz ~48%
Nichts ~48%

Benutzer @user_handle
Ich wünschte mir, ich könnte mich an Spitzeln halten, aber ich glaube, es ist gut, dass ich das nicht gleichzeitig kann."

PARSE
ANNOATE
Diskonanz"</sample>
    <sample id="1507">Der englische Text lautet:

"Annotations

User
@user_handle

Wish I could hold grudges but I guess it's a good thing that I can't at the same time."

Übersetzt auf Deutsch:

"Annotations

Benutzer
@benutzerhandle

Ich wünschte, ich könnte mich an jemanden erinnern, aber ich glaube, es ist gut, dass ich das nicht gleichzeitig kann."</sample>
    <sample id="1508">Der englische Text lautet:

"Annotations

User
@user_handle

Wish I could hold grudges but I guess it's a good thing that I can't at the same time."

Übersetzt auf Deutsch:

"Annotations

Benutzer
@benutzerhandle

Ich wünschte, ich könnte mich an jemanden erinnern, aber ich glaube, es ist gut, dass ich das nicht gleichzeitig tun kann."</sample>
    <sample id="1509">Training auf dem Initialen Annotated Set

**RoBERTA-base + classifier head**

TRAIN

**init dataset**

**Small annotated dataset:**
43/901 dissonance; 
nicht besser als Zufall</sample>
    <sample id="1510">Training auf dem Initialen Annotated Set

**RoBERTA-base + classifier head**

TRAIN

**init dataset**

**Small annotated dataset:**
43/901 dissonance; nicht besser als Zufall</sample>
    <sample id="1511">Method: Transfer und Active Learning zur Annotierung seltener Klassen

Anfangsmodell: Transfer-Learning

Seltenes Klassenanmerken ~ "Nadel im Heuhaufen"

Schwierig zu annotieren
Einfacher zu annotieren

Erhöhen Sie die Chance auf seltenen Klassen?

Erwerbsstrategie: Welche sind die "besten" zu beschriften?

Modell Neutrainieren/Update

Active Learning Iteration

Neue Beispiele

Menschen annotieren

Neue Beispiele hinzufügen</sample>
    <sample id="1512">Der englische Text lautet:

"Cold-start Annotations: Transfer Learning"

Übersetzt bedeutet das:

"Kaltstart-Annotierungen: Transfer-Learning"</sample>
    <sample id="1513">### Kaltstart-Annotierungen: Transfer-Learning

**RoBERTA-base + classifier head**

**TRAIN**

- init dataset
  - +0.12
- Debate
  - +0.12
- CE
  - +0.10
- Debate;CE
  - +0.08

**Area under the ROC curve (AUC)**

**Transferred weights after training on combined Debate and CE data**

*Debate: Dissonant stance in debate forums: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Naoaki Inoue. 2022. Detecting dissonant stance in social media: The role of topic exposure. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS). Association for Computational Linguistics.

*CE: Comparison and Expansion classes: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)</sample>
    <sample id="1514">### Kaltstart-Annotierungen: Transfer-Learning

**RoBERTA-base + classifier head**

**TRAIN**

- init dataset
  - Debate: +0.12
  - CE: +0.10
  - Debate;CE: +0.08

**Transferred weights after training on combined Debate and CE data**

*Debate: Dissonant stance in debate forums: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H., Andrew Schwarzer, and Naoaki Inoue. 2022. Detecting dissonant stances in social media: The role of topic expansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS). Association for Computational Linguistics.

*CE: Comparison and Expansion classes: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)</sample>
    <sample id="1515">### Übersetzung des englischen Inhalts in Deutsch

**Cold-start Annotations: Transfer Learning**

- **RoBERTA-base + classifier head**
  - **TRAIN**
    - **init dataset**: 0.50
    - **Debate**: +0.12
    - **$**: +0.10
    - **CE**: +0.08
    - **Debate;CE**: +0.08
  - **Transferred weights after training on combined Debate and CE data**

*Debate: Dissonant stance in debate forums: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Natara Inoue. 2022. Detecting dissonant stances in social media: the role of topic expansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS), Association for Computational Linguistics.

§CE: Comparison and Expansion classes: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)

15</sample>
    <sample id="1516">### Kaltstart-Annotierungen: Transfer-Learning

**RoBERTA-base + classifier head**

**Trainieren**

- init dataset
- Debate (+0.12)
- CE (+0.10)
- Debate;CE (+0.08)
- Debate→CE (+0.04)
- CE→Debate (+0.17)

**Finetuning auf jede Aufgabe nacheinander**

*Debate: Dissonante Stellung in Debattierforen: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schulz und Naoaki Inoue. 2022. Detecting dissonant stances in social media: the role of topic expansion. In Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP-CSS), Association for Computational Linguistics.

*CE: Vergleich und Erweiterungsklassen: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi und Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)</sample>
    <sample id="1517">Der englische Text lautet:

"Active Learning: Cumulative vs Iterative Update"

Die deutsche Übersetzung lautet:

"aktives Lernen: Cumulative vs Iterative Update"</sample>
    <sample id="1518">Der englische Text lautet:

"Active Learning: Cumulative vs Iterative Update"

Der deutsche Text lautet:

"aktives Lernen: Cumulative vs Iterative Aktualisierung"</sample>
    <sample id="1519">Der englische Text lautet:

"Active Learning: Probability-of-Rare-Class Strategy"

Übersetzt bedeutet das:

"aktives Lernen: Strategie zur Wahrscheinlichkeit seltener Klassen"</sample>
    <sample id="1520">Der englische Text lautet:

"Active Learning: Probability-of-Rare-Class Strategy"

Übersetzt auf Deutsch bedeutet das:

"aktives Lernen: Strategie zur Wahrscheinlichkeit seltener Klassen"

Der Text beschreibt einen Ansatz im Bereich des aktiven Lernens, speziell für die Klassifizierung von seltenen Klassen.</sample>
    <sample id="1521">Der englische Text lautet:

"Active Learning: Probability-of-Rare-Class Strategy

Active Learning Strategy Comparison (AUCs)

Baseline: from scratch +0.17
Transferred model +0.15
AL-Random +0.15
AL-Entropy +0.20
AL-CoreSet +0.19
AL-CAL +0.19
AL-PRC (ours) +0.21"

Übersetzt ins Deutsche:

"aktives Lernen: Strategie zur Wahrscheinlichkeit seltener Klassen

Vergleich aktiver Lernstrategien (AUCs)

Baselines: von Grund auf +0.17
Transferierter Modell +0.15
AL-Random +0.15
AL-Entropie +0.20
AL-CoreSet +0.19
AL-CAL +0.19
AL-PRC (unsere) +0.21"</sample>
    <sample id="1522">Der englische Text lautet:

"Active Learning: Probability-of-Rare-Class Strategy

Active Learning Strategy Comparison (AUCs)

Baseline: from scratch
Transferred model +0.17

AL-Random +0.15
AL-Entropy +0.20
AL-CoreSet +0.19
AL-CAL +0.19
AL-PRC (ours) +0.21

Final Model (best transfer model → cumulative new data) +0.25"

Übersetzt ins Deutsche:

Aktives Lernen: Strategie zur Wahrscheinlichkeit seltener Klassen

Vergleich der Aktiven-Lern-Strategien (AUCs)

Baselines: von Grund auf
Transferierter Modell +0.17

AL-Random +0.15
AL-Entropie +0.20
AL-CoreSet +0.19
AL-CAL +0.19
AL-PRC (unsere) +0.21

Endmodell (bestes transferiertes Modell → kumulatives neues Daten) +0.25</sample>
    <sample id="1523">### Aktives Lernen: Strategie der Seltenheitswahrscheinlichkeit

#### Eigenschaften des Aktiven Lernstrategie-Charakters

| Selten % | Zeit (s) | Subjektive Differenz |
|----------|---------|---------------------|
| Zufällig  | 3,20    | 11,96               | -0,065              |
| Entropie | 6,80    | 12,78               | 0,035               |
| CoreSet  | 6,00    | 11,89               | 0,039               |
| CAL      | 4,80    | 11,88               | -0,045              |
| PRC      | 7,60    | 13,55               | 0,071               |

- Minimum Annotationskosten führen nicht notwendigerweise zu besseren Modellen.
- Seltenheit kann die Annotierung schwieriger machen: kognitive Dissonanz ist ein solches Beispiel.
- Um Dissonanzproben zu erhöhen, funktioniert PRC am besten.</sample>
    <sample id="1524">Die Übersetzung des englischen Inhalts lautet:

**Takeaways**

- Seltenes Klassennachrichten ~ "Nadel im Heuhaufen"
- PRC ist einfach und effizient für die seltene Probenakquisition

- Cold-start AL mit Transfer-Learning
- Out-of-domain: Iterativ
- In-domain: Cumulative</sample>
    <sample id="1525">Die Übersetzung des englischen Inhalts lautet:

**Takeaways**

- Seltenes Klassennachrichten ~ "Nadel im Heuhaufen"
- PRC ist einfach und effizient für die seltene Probenakquisition

- Cold-start AL mit Transfer-Learning
- Out-of-domain: Iterativ
- In-domain: Cumulative</sample>
    <sample id="1526">Übersetzung des englischen Inhalts in Deutsch:

---

Transfer und Aktives Lernen für Dissonanz-Detektion: Adressierung des Seltenen-Klassen-Challenges

Kontakt: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu

Code:
https://github.com/humanlab/rare-class-AL

Dataset:
https://github.com/humanlab/dissonance-twitter-dataset

Paper:
https://arxiv.org/abs/2305.02459

Danke!

---</sample>
    <sample id="1527">Die Autoren gehören der University of Edinburgh, Saarland University und der University of Amsterdam an.</sample>
    <sample id="1528">Der Referent ist Siyu Yuan.</sample>
    <sample id="1529">Es sind fünf Autoren an der Arbeit beteiligt: Patrick Fernandes, Kayo Yin, Emmy Liu, André F.T. Martins und Graham Neubig.</sample>
    <sample id="1530">Der Ansatz wird mit der "state of the art architecture specifically tailored for SimulST" verglichen.</sample>
  </task>
</testset>