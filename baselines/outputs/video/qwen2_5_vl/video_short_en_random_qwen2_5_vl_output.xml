<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="en">
    <sample id="0">The main data sources for language models include websites like patents.google.com, en.wikipedia.org, and en.m.wikipedia.org.</sample>
    <sample id="1">McGill University/Mila, Microsoft Research</sample>
    <sample id="35">The name of the speaker is not explicitly mentioned in the image provided. The image lists several authors associated with the research paper titled "When Does Translation Require Context? A Data-driven, Multilingual Exploration," but it does not specify who is speaking at the presentation.</sample>
    <sample id="36">The T5 XL model was used to obtain the 82%-87% accuracy when the LM has access to partially overlapping background knowledge.</sample>
    <sample id="37">YES!</sample>
    <sample id="38">The novelty of the proposed human evaluation method, ABC-Eval, lies in its focus on annotating behaviors in chat interactions, which helps in assessing the relevance and quality of responses from chatbots. This approach allows for the identification of issues such as "Irrelevance," "Lack of Empathy," and "Self-Contradiction," providing a structured way to evaluate conversational AI systems.</sample>
    <sample id="39">The success of the existing weakly supervised approach heavily relies on the quality of the weak labels used for validation.</sample>
    <sample id="40">The image does not provide specific information about how to improve the score or what kind of advances can be made. It appears to be a slide from a presentation about background knowledge in music, mentioning Google search links for songs and instructions for annotators to listen to and read about each song. There is no direct information on improving scores or making advances.</sample>
    <sample id="41">There are five authors involved in the paper.</sample>
    <sample id="75">There are three authors involved in the paper: Matthias Lindemann, Alexander Koller, and Ivan Titov.</sample>
    <sample id="76">The domains that are simplified more are "bible" and "fiction."</sample>
    <sample id="77">The example given in the slide is "I saw Bart and Lisa; Homer came and sneezed." Here, "Bart and Lisa" is the shorter left conjunct, while "Homer came and sneezed" is the longer right conjunct. This follows the observed tendency that left conjuncts tend to be shorter than right conjuncts.</sample>
    <sample id="78">Yes, you can use the DrBERT models for your research as they are freely available under the MIT license.</sample>
    <sample id="79">DEplain-APA contains documents from APA (American Psychological Association) style publications.</sample>
    <sample id="80">For good generalization, we need better model architecture, larger model size, and more fine-tuning examples.</sample>
    <sample id="81">by length difference</sample>
    <sample id="82">The experiments were designed by varying the length of conjuncts and observing how the proportion of shorter left conjuncts changes depending on the absolute difference in conjunct lengths, with the governor's position being a factor.</sample>
    <sample id="83">A baseline classifier trained on imbalanced data performs poorly, as indicated by an Area under the ROC curve (AUC) of 0.5, which is not better than chance.</sample>
    <sample id="84">There are four authors involved in the paper: Shangbin Feng, Chan Young Park, Yuhan Liu, and Yulia Tsvetkov.</sample>
    <sample id="85">The characters' names are not provided in the image.</sample>
    <sample id="86">Context-aware MT models significantly improve on formality and lexical cohesion, but they do not perform better on ellipsis, pronouns, or verb form.</sample>
    <sample id="87">The authors of the paper are affiliated with Johns Hopkins University, Purdue University, MIT, and Meta AI.</sample>
    <sample id="88">Compositional Generalization without Trees using Multiset Tagging and Latent Permutations

Matthias Lindemann, Alexander Koller, Ivan Titov</sample>
    <sample id="89">Compositional Generalization without Trees using Multiset Tagging and Latent Permutations

Matthias Lindemann, Alexander Koller, Ivan Titov</sample>
    <sample id="90">Compositional Generalization

Ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training.</sample>
    <sample id="91">The girl slept.
Mary knew that the girl slept.

*girl x1 sleep.agent x2 x1
*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4</sample>
    <sample id="92">The text in the image states:

**Compositional Generalization in Semantic Parsing**

Train:
- The girl slept.
  - *girl x1 sleep.agent x2 x1
- Mary knew that the girl slept.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧
    sleep.agent x5 x4</sample>
    <sample id="93">The image contains text related to "Compositional Generalization in Semantic Parsing." It is divided into two sections: Train and Test.

### Train:
1. **Sentence:** The girl slept.
   - **Semantic Representation:** *girl x_1 sleep.agent x_2 x_1*

2. **Sentence:** Mary knew that the girl slept.
   - **Semantic Representation:** *girl x_4 know.agent x_1 Mary ∧ know.ccomp x_1 x_5 ∧ sleep.agent x_5 x_4*

### Test:
- **Sentence:** Jim said that Mary knew that the girl slept.
  - **Semantic Representation:** *girl x_7 say.agent x_1 Jim ∧ say.ccomp x_1 x_4 ∧ know.agent x_4 Mary ∧ know.ccomp x_4 x_8 ∧ sleep.agent x_8 x_7*</sample>
    <sample id="94">The image contains text related to "Compositional Generalization in Semantic Parsing." It is divided into two sections: Train and Test.

### Train:
1. **Sentence:** The girl slept.
   - **Semantic Representation:** *girl x_1 sleep.agent x_2 x_1*

2. **Sentence:** Mary knew that the girl slept.
   - **Semantic Representation:** *girl x_4 know.agent x_1 Mary ∧ know.ccomp x_1 x_5 ∧ sleep.agent x_5 x_4*

### Test:
**Sentence:** Jim said that Mary knew that the girl slept.
- **Semantic Representation:** *girl x_7 say.agent x_1 Jim ∧ say.ccomp x_1 x_4 ∧ know.agent x_4 Mary ∧ know.ccomp x_4 x_8 ∧ sleep.agent x_8 x_7*</sample>
    <sample id="95">The image contains the following text:

**Compositional Generalization in Semantic Parsing**

**Train:**
- The girl slept.
  - *girl x1 sleep.agent x2 x1
- Mary knew that the girl slept.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

**Test:**
- Jim said that Mary knew that the girl slept.
  - *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7

**Naive seq2seq models fail!**</sample>
    <sample id="96">The image contains the following text:

**Compositional Generalization in Semantic Parsing**

**Train:**
- The girl slept.
  - *girl x1 sleep.agent x2 x1
- Mary knew that the girl slept.
  - *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

**Test:**
- Jim said that Mary knew that the girl slept.
  - *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7

**Naive seq2seq models fail!**</sample>
    <sample id="97">The English content in the image states:

"Trees help a lot but..."

The tree diagram shows:
- The root node: "sleep.agent x2 x1"
- The left branch: "*girl x1;"
- The right branch: "x1 sleep.agent x2"
- The final node: "The girl slept."</sample>
    <sample id="98">The English content in the image states:

"Trees help a lot but..."

"*girl x₁; sleep.agent x₂ x₁"

"*girl x₁; x₁ sleep.agent x₂"

"The girl slept."</sample>
    <sample id="99">The English content in the image states:

"Trees help a lot but...
*girl x1; sleep.agent x2 x1
*x1; x1 sleep.agent x2
The girl slept.
Trees need to be obtained:
- Pre/Post-processing logical forms"</sample>
    <sample id="100">Trees help a lot but...

*girl x₁; sleep.agent x₂ x₁

*girl x₁; x₁ sleep.agent x₂

The girl slept.

Trees need to be obtained:
- Pre/Post-processing logical forms</sample>
    <sample id="101">Trees help a lot but...

*girl x₁; sleep.agent x₂ x₁

*girl x₁; x₁ sleep.agent x₂

The girl slept.

Trees need to be obtained:
- Pre/Post-processing logical forms
- Grammar-induction</sample>
    <sample id="102">Trees help a lot but...

*girl x₁; sleep.agent x₂ x₁

*girl x₁; x₁ sleep.agent x₂

The girl slept.

Trees need to be obtained:
- Pre/Post-processing logical forms
- Grammar-induction

This paper: neural seq2seq model that directly models the correspondences between fragments. For the first time, we show strong generalization to deeper recursion without trees.</sample>
    <sample id="103">Trees help a lot but...

*girl x₁; sleep.agent x₂ x₁

*girl x₁; x₁ sleep.agent x₂

The girl slept.

Trees need to be obtained:
- Pre/Post-processing logical forms
- Grammar-induction

This paper: neural seq2seq model that directly models the correspondences between fragments. For the first time, we show strong generalization to deeper recursion without trees.</sample>
    <sample id="104">Our Approach

The image shows three different colored boxes with tags and words underneath them:

1. Green box: Contains two green squares labeled with an asterisk (*) and a semicolon (;).
   - Tag: the
   - Word: the

2. Yellow box: Contains three yellow squares labeled with "x1", "girl", and "x1".
   - Tag: girl
   - Word: girl

3. Blue box: Contains three blue squares labeled with "sleep", "agent", and "x2".
   - Tag: slept
   - Word: slept</sample>
    <sample id="105">Our Approach

The image shows three different colored boxes with tags underneath them:

1. Green box: Contains two symbols, '*', and ';'. The tag below it is "the".
2. Yellow box: Contains three symbols, 'x1', 'girl', and 'x1'. The tag below it is "girl".
3. Blue box: Contains three words, 'sleep', 'agent', and 'x2'. The tag below it is "slept".</sample>
    <sample id="106">Our Approach

The image shows three different tagging systems, each with a "Tag" label at the bottom:

1. The first system uses green tags labeled with asterisks and semicolons.
2. The second system uses yellow tags labeled with "x1" and "girl".
3. The third system uses blue tags labeled with "sleep", "agent", and "x2".

Each system corresponds to a word: "the", "girl", and "slept".</sample>
    <sample id="107">Our Approach

The image illustrates an approach involving three main components: "Permute," "Tag," and the words "the," "girl," and "slept." The "Permute" section shows a permutation of elements, including symbols like "*", ";", "x1," and "x2," along with words such as "girl," "sleep," and "agent." These elements are permuted to form different sequences. The "Tag" section below the "Permute" section tags these permutations with corresponding words: "the," "girl," and "slept." This suggests a method for associating specific tags with permutations of certain elements or words.</sample>
    <sample id="108">Our Approach

The image illustrates a process labeled "Permute" and "Tag." The "Permute" section shows a sequence of words: "* girl x1 ; sleep agent x2 x1". These words are permuted, meaning they are rearranged in some way. The "Tag" section below the "Permute" section has three tags: "the", "girl", and "slept". The arrows indicate that the words from the "Permute" section are mapped to these tags. Specifically:
- The word "* girl x1" is tagged with "the".
- The word "; girl x1" is tagged with "girl".
- The word "sleep agent x2 x1" is tagged with "slept".

This diagram seems to be demonstrating a method for mapping or tagging words based on their permutations.</sample>
    <sample id="109">The image contains the following text:

```
Permuting with "jumps"
```</sample>
    <sample id="110">The image contains a diagram with the title "Permuting with 'jumps'" at the top in yellow text. Below this title, there are two main sections labeled "Permute" and "Tag," each containing three boxes with different colored backgrounds and text.

1. **Permute Section:**
   - The first box has a green background with the text "*".
   - The second box has a green background with the text ";".
   - The third box has a yellow background with the text "x1 girl x1".

2. **Tag Section:**
   - The first box has a green background with the text "the".
   - The second box has a yellow background with the text "girl".
   - The third box has a blue background with the text "sleep agent x2".

The arrows indicate the flow or relationship between the elements in the "Permute" section and the "Tag" section.</sample>
    <sample id="111">The image contains the following text:

**Permuting with "jumps"**

- **Permute**
  - The word "girl" is highlighted in red and connected to the word "the" below it.
  - The word "girl" is also connected to another instance of itself, labeled as \( x_1 \).
  - The word "sleep" is connected to the word "slept" below it.

- **Tag**
  - The word "the" is connected to the word "girl".
  - The word "girl" is connected to the word "sleep".
  - The word "slept" is connected to the word "agent".

The diagram illustrates the process of permuting words with "jumps," where certain words are moved or permuted within the structure.</sample>
    <sample id="112">The image contains a diagram with the title "Permuting with 'jumps'" at the top in yellow text. The diagram illustrates a process involving three main components: "Permute," "Tag," and a series of colored boxes representing different elements.

1. **Permute Section**:
   - There are three boxes labeled with the words "* girl" and "x1."
   - These boxes are connected to the "Tag" section below through arrows.

2. **Tag Section**:
   - This section has three boxes, each containing a word or symbol.
   - The first box is green and contains the word "the."
   - The second box is yellow and contains the word "girl."
   - The third box is blue and contains the word "slept."

3. **Arrows and Connections**:
   - Arrows connect the "Permute" section to the "Tag" section, indicating a permutation process.
   - Specifically, there are arrows from the "* girl" box in the "Permute" section to the "girl" box in the "Tag" section, and from the "x1" box to the "slept" box in the "Tag" section.

The diagram visually represents how certain elements (indicated by the "* girl" and "x1") are permuted and tagged with specific words ("the," "girl," and "slept").</sample>
    <sample id="113">The image contains the following text:

**Permuting with "jumps"**

The diagram illustrates a process involving "Permute" and "Tag." The "Permute" section shows a sequence of elements: `*`, `girl`, `x1`, `;`, `sleep`, `agent`, `x2`, and `x1`. These elements are connected by arrows indicating a permutation or rearrangement process.

The "Tag" section below the "Permute" section has three elements: `the`, `girl`, and `slept`. These tags correspond to the elements in the "Permute" section, suggesting that each element in the "Permute" section is tagged with one of these words. The connections between the "Permute" and "Tag" sections are highlighted with red arrows, showing how the elements are mapped to their corresponding tags.</sample>
    <sample id="114">Some Results on COGS (Kim and Linzen 2020)

Comparison with other Treeless Models on Structural Generalization on COGS

Generalisation Type | Model
------------------|---------
PP recursion      | LSTM seq2seq
CP recursion      | T5
Obj PP → Subj PP | Zheng and Lapata
Obj PP → Subj PP | Ours</sample>
    <sample id="115">Some Results on COGS (Kim and Linzen 2020)

Comparison with other Treeless Models on Structural Generalization on COGS

Model
- LSTM seq2seq
- T5
- Zheng and Lapata
- Ours

Generalisation Type
- PP recursion
- CP recursion
- Obj PP → Subj PP</sample>
    <sample id="116">Technical Challenges We Solve

Alignment unknown.</sample>
    <sample id="117">Technical Challenges We Solve

Alignment unknown.</sample>
    <sample id="118">Technical Challenges We Solve

Alignment unknown.
- Induce it in training.</sample>
    <sample id="119">Technical Challenges We Solve

Alignment unknown.
- Induce it in training.

Permutation model:
- Inference is NP-hard (≈ TSP)</sample>
    <sample id="120">Technical Challenges We Solve

Alignment unknown.
- Induce it in training.

Permutation model:
- Inference is NP-hard (≈ TSP)
- Backpropagate through continuous relaxation</sample>
    <sample id="121">Technical Challenges We Solve

Alignment unknown.
- Induce it in training.

Permutation model:
- Inference is NP-hard (≈ TSP)
- Backpropagate through continuous relaxation

Paper &amp; Code: https://t.ly/mX8ny</sample>
    <sample id="122">The framework quantifies positionality by re-annotating datasets with diverse annotators, comparing annotations by demographic to models and datasets via Pearson's R scores, and measuring the correlation between gold labels, model predictions, and annotations for each demographic separately.</sample>
    <sample id="123">The image is a presentation slide from the 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023). The title of the presentation is "Weaker Than You Think: A Critical Look at Weakly Supervised Learning." The slide features logos of Saarland University, the Department of Language Science and Technology at Saarland University, and Universität Wien. Below the title, there are five authors listed with their affiliations:

- Dawei Zhu (1)
- Xiaoyu Shen (2)
- Marius Mosbach (1)
- Andreas Stephan (3)
- Dietrich Klakow (1)

The numbers in parentheses indicate the affiliation of each author:
- (1) Saarland University
- (2) Amazon Alexa
- (3) University of Vienna

The slide also includes a small image of a person in the bottom right corner, presumably the presenter or one of the authors.</sample>
    <sample id="124">The image is a presentation slide from the 61st Annual Conference on Computational Linguistics (ACL 2023). The title of the presentation is "Weaker Than You Think: A Critical Look at Weakly Supervised Learning." The slide features logos of Saarland University, the Department of Language Science and Technology at Saarland University, and Universität Wien. Below the title, there are five authors listed with their affiliations:

- Dawei Zhu (1)
- Xiaoyu Shen (2)
- Marius Mosbach (1)
- Andreas Stephan (3)
- Dietrich Klakow (1)

The numbers in parentheses indicate the affiliation of each author:
- (1) Saarland University
- (2) Amazon Alexa
- (3) University of Vienna

The slide also includes a small logo for ACL 2023 at the bottom right corner.</sample>
    <sample id="125">The slide titled "Why weakly supervised learning?" discusses the advantages and challenges of using weakly supervised learning in machine learning tasks. Here is the written content:

---

### Why weakly supervised learning?

- **Weak supervision alleviates the annotation bottleneck.**
  - Weak labeling sources (e.g., heuristics, knowledge bases) can be used to alleviate the need for extensive manual annotation.

- **But weak labels are noisy!**
  - Noise memorization harms generalization.
  - This means that the models trained with noisy data may not generalize well to unseen data.

- **Weakly supervised learning (WSL)**
  - Train models that generalize well despite being trained on noisy data.
  - WSL aims to develop robust models that can handle the inherent noise in the labeled data while still achieving good performance.

---

The slide also includes a visual representation showing the process:
1. **Weak labeling sources** (e.g., heuristics, knowledge bases) are used to generate labels.
2. These labels are then applied to **unlabeled data**.
3. The resulting data is **weakly labeled data**, which may contain noise due to the imperfect nature of the labels.

This approach helps in dealing with the annotation bottleneck by leveraging available but potentially noisy data, making it a valuable technique in many real-world applications where obtaining clean, fully labeled data is challenging or expensive.</sample>
    <sample id="126">Why weakly supervised learning?

- Weak supervision alleviates the annotation bottleneck.
- But weak labels are noisy!
  - Noise memorization harms generalization.
- Weakly supervised learning (WSL)
  - Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="127">The slide is titled "Why weakly supervised learning?" and discusses the use of weak supervision in machine learning, particularly when dealing with noisy data.

- **Weak supervision alleviates the annotation bottleneck.**
  - This means that using weak labels can help reduce the need for extensive manual labeling, which can be time-consuming and costly.
  
- **But weak labels are noisy!**
  - The slide highlights a critical issue: weak labels often contain errors or inaccuracies due to their nature as heuristics or knowledge bases.
  - **Noise memorization harms generalization.**
    - This point emphasizes that if a model learns from noisy data, it may memorize these errors rather than learning the underlying patterns, leading to poor generalization on new, unseen data.

- **Weakly supervised learning (WSL)**
  - The slide introduces weakly supervised learning as a method to train models that can generalize well even when trained on noisy data.
  - **Train models that generalize well despite being trained on noisy data.**
    - This suggests that WSL techniques aim to develop robust models that can perform well in real-world scenarios where data quality might not be perfect.

The slide also includes a visual representation:
- **Weak labeling sources (e.g., heuristics, knowledge bases)**
  - This indicates the types of sources used to generate weak labels.
- **Unlabeled data**
  - This represents the initial dataset that contains no labels.
- **Weakly labeled data (noisy, i.e., some annotations are wrong)**
  - This shows the final dataset after weak labels have been applied, which may contain errors.

Overall, the slide explains the benefits and challenges of weakly supervised learning, emphasizing its importance in handling noisy data effectively.</sample>
    <sample id="128">The slide is titled "Why weakly supervised learning?" and discusses the use of weak supervision in machine learning, particularly when dealing with noisy data.

- **Weak supervision alleviates the annotation bottleneck.**
  - This means that using weak labels can help reduce the need for extensive manual labeling, which can be time-consuming and costly.

- **But weak labels are noisy!**
  - The slide emphasizes that weak labels often contain errors or inaccuracies.
  - Noise memorization harms generalization, meaning that models trained on noisy data may not perform well on unseen data.

- **Weakly supervised learning (WSL)**
  - The goal of weakly supervised learning is to train models that generalize well despite being trained on noisy data.

The slide also includes a flowchart:
1. **Weak labeling sources** (e.g., heuristics, knowledge bases)
2. **Unlabeled data**
3. **Weakly labeled data (noisy, i.e., some annotations are wrong)**

This flowchart illustrates the process of moving from weak labeling sources to unlabeled data and then to weakly labeled data, which contains noise.</sample>
    <sample id="129">The slide is titled "Why weakly supervised learning?" and discusses the use of weak supervision in machine learning, particularly when dealing with noisy data.

- **Weak supervision alleviates the annotation bottleneck.**
  - This means that using weak labels can help reduce the need for extensive manual labeling, which can be time-consuming and costly.

- **But weak labels are noisy!**
  - The slide highlights a significant challenge: weak labels often contain errors or inaccuracies.
  - Noise memorization harms generalization, meaning that models trained on noisy data may not perform well on unseen data.

- **Weakly supervised learning (WSL)**
  - The goal of weakly supervised learning is to train models that generalize well despite being trained on noisy data.
  - This approach aims to leverage the benefits of weak supervision while mitigating the negative effects of noise.

The slide also includes a flowchart illustrating the process:
1. **Weak labeling sources** (e.g., heuristics, knowledge bases)
2. **Unlabeled data**
3. **Weakly labeled data (noisy, i.e., some annotations are wrong)**

This flowchart visually represents how weakly supervised learning works, starting from the use of weak labeling sources, moving through unlabeled data, and ending with the final dataset used for training, which contains noise due to the imperfect nature of the weak labels.</sample>
    <sample id="130">A common claim in recent WSL works

"We train models only on weakly supervised data and achieve an accuracy of XX%."

Weakly labeled training data (noisy)
Cleanly labeled test data (clean)</sample>
    <sample id="131">A common claim in recent WSL works is: "We train models only on weakly supervised data and achieve an accuracy of XX%."

The slide illustrates two types of data:
- Weakly labeled training data (noisy)
- Cleanly labeled test data (clean)</sample>
    <sample id="132">A common claim in recent WSL works

"We train models only on weakly supervised data and achieve an accuracy of XX%"

Weakly labeled training data (noisy)
Cleanly labeled validation data (clean)
Cleanly labeled test data (clean)</sample>
    <sample id="133">A common claim in recent WSL works

"We train models only on weakly supervised data and achieve an accuracy of XX%"

Weakly labeled training data (noisy)
Cleanly labeled validation data (clean)
Cleanly labeled test data (clean)</sample>
    <sample id="134">Our research questions

RQ1: Is clean validation data necessary?
RQ2: How many clean samples do WSL approaches need?
RQ3: How to use the available clean samples more efficiently?</sample>
    <sample id="135">Our research questions

RQ1: Is clean validation data necessary?
RQ2: How many clean samples do WSL approaches need?
RQ3: How to use the available clean samples more efficiently?</sample>
    <sample id="136">The image is a slide from a presentation titled "Main findings" under RQ1 (Research Question 1). The slide features a scatter plot with the x-axis labeled as "Relative performance improvement over weak labels (%)" and the y-axis labeled as "FTW, BOND, COSINE, MLC, L2R". The plot includes three different categories represented by different colors and markers:

1. **Validation on Weak Labels** (orange circles)
2. **No Validation (Random Selection)** (purple circles)
3. **Validation on Clean Labels** (green circles)

Each category has multiple data points with error bars indicating variability or standard deviation. The legend at the top of the plot explains the meaning of each color and marker.

The slide number is indicated as 6 in the bottom right corner.</sample>
    <sample id="137">RQ1 Main findings

The graph illustrates the relative performance improvement over weak labels (%) for different methods under various validation conditions. The x-axis represents different methods: FTW, BOND, COSINE, MLC, and L2R. The y-axis shows the relative performance improvement in percentage.

- **Validation on Weak Labels (orange circles)**: This condition shows a general trend where the performance improves with some fluctuations.
- **No Validation (Random Selection) (purple circles)**: This condition shows a more stable performance with minimal changes.
- **Validation on Clean Labels (green circles)**: This condition demonstrates the highest performance improvement, with significant gains across all methods.

The graph highlights that validation on clean labels leads to the most substantial performance improvements compared to the other two conditions.</sample>
    <sample id="138">RQ1 Main findings

The graph illustrates the relative performance improvement over weak labels (%) for different methods under various validation conditions. The x-axis represents different methods: FTW, BOND, COSINE, MLC, and L2R. The y-axis shows the relative performance improvement in percentage.

- **Validation on Weak Labels (Orange):** This method shows a general trend of improvement across all methods, with some fluctuations.
- **No Validation (Random Selection) (Purple):** This method consistently shows negative or minimal improvement, indicating that random selection does not significantly enhance performance.
- **Validation on Clean Labels (Green):** This method demonstrates the highest improvement across most methods, particularly for BOND, COSINE, and L2R, where the improvements are notably higher compared to other methods.

The graph highlights that validation on clean labels is crucial for achieving significant performance improvements, while random selection does not provide substantial benefits.</sample>
    <sample id="139">The image is a slide from a presentation titled "Main findings" under RQ1 (Research Question 1). The slide features a scatter plot with the x-axis labeled "Relative performance improvement over weak labels (%)" and the y-axis labeled "FTW, BOND, COSINE, MLC, L2R". The plot includes three different data series represented by different colors and markers:

1. **Validation on Weak Labels** (orange circles)
2. **No Validation (Random Selection)** (purple circles)
3. **Validation on Clean Labels** (green circles)

Each data point in the plot represents the relative performance improvement for each method (FTW, BOND, COSINE, MLC, L2R) under the specified validation conditions. The error bars indicate the variability or standard deviation of the performance improvements.

The legend at the top of the plot explains the meaning of each color and marker:
- Orange circles: Validation on Weak Labels
- Purple circles: No Validation (Random Selection)
- Green circles: Validation on Clean Labels

The slide number is indicated as 6 in the bottom right corner.</sample>
    <sample id="140">RQ1 Main findings

A clean validation set is indispensable.</sample>
    <sample id="141">The image is a slide from a presentation, labeled "RQ2 Main findings" at the top left corner. The slide number, 7, is displayed in the bottom right corner. The main content of the slide is a line graph with the title "Main findings." The x-axis is labeled "Validation," and the y-axis is labeled "Accuracy." The graph shows five different lines representing different methods or techniques: FTw (blue), COSINE (orange), L2R (green), BOND (red), and MLC (purple). Each line has corresponding data points that increase as the validation value increases. There is also a dashed line labeled "Weak labels" on the graph.

The legend on the right side of the graph explains the colors and their corresponding methods:
- Blue: FTw
- Orange: COSINE
- Green: L2R
- Red: BOND
- Purple: MLC

The background of the slide is white, and there is a small image of a person in the top right corner.</sample>
    <sample id="142">The image is a slide from a presentation titled "Main findings" under RQ2. It features a line graph with the x-axis labeled "Validation" and the y-axis labeled "Accuracy." The graph shows the performance of different methods over various validation sizes, ranging from 5 to All.

The methods compared in the graph are:
- FT_w (blue line)
- COSINE (orange line)
- L2R (green line)
- BOND (red line)
- MLC (purple line)

There is also a dashed gray line labeled "Weak labels," which appears to be a reference or baseline for comparison.

The slide number is indicated as 7 in the bottom right corner.</sample>
    <sample id="143">RQ2 Main findings

WSL approaches benefit from more clean validation samples!</sample>
    <sample id="144">RQ2 Main findings

WSL approaches benefit from more clean validation samples!</sample>
    <sample id="145">RQ2 Main findings

WSL approaches benefit from more clean validation samples!
But it is even better to use them for training (e.g., LoRAc)!</sample>
    <sample id="146">RQ3 Main findings

The slide presents two graphs comparing the accuracy/F1 scores before and after applying CFT (Clean Feature Transformation) for different numbers of clean samples per class.

- **Left Graph: N=10 clean samples per class**
  - The x-axis represents "Before CFT" and "After CFT."
  - The y-axis represents Accuracy/F1.
  - Three lines represent different methods:
    - COSINE (orange)
    - L2R (blue)
    - FTW (red)
  - A dashed line labeled "Clean Only" is also present, indicating the performance without CFT.

- **Right Graph: N=30 clean samples per class**
  - The x-axis represents "Before CFT" and "After CFT."
  - The y-axis represents Accuracy/F1.
  - The same three lines (COSINE, L2R, FTW) are present.
  - The "Clean Only" dashed line is also included.

Both graphs show an improvement in accuracy/F1 scores after applying CFT, with the FTW method showing the highest improvement in both scenarios.</sample>
    <sample id="147">RQ3 Main findings

The slide presents two graphs comparing the accuracy/F1 scores before and after applying CFT (Cleaned Feature Transformation) for different numbers of clean samples per class.

- **Left Graph**: N=10 clean samples per class
  - Before CFT: Accuracy/F1 around 80.
  - After CFT: Accuracy/F1 increases to around 84.
  
- **Right Graph**: N=30 clean samples per class
  - Before CFT: Accuracy/F1 around 80.
  - After CFT: Accuracy/F1 increases to around 86.

The graphs show that the application of CFT leads to an increase in accuracy/F1 scores, with the effect being more pronounced when there are more clean samples per class. The methods used are COSINE, L2R, FTW, and Clean Only, as indicated by the legend.</sample>
    <sample id="148">The image is a slide from a presentation titled "Main findings" under RQ3. It presents two line graphs comparing the accuracy/F1 scores before and after applying CFT (Cleaned Feature Transformation) for different numbers of clean samples per class.

### Left Graph:
- **Title:** N=10 clean samples per class
- **X-axis:** Before CFT, After CFT
- **Y-axis:** Accuracy/F1
- **Legend:**
  - COSINE (orange)
  - L2R (blue)
  - FTW (red)
  - Clean Only (gray dashed line)

### Right Graph:
- **Title:** N=30 clean samples per class
- **X-axis:** Before CFT, After CFT
- **Y-axis:** Accuracy/F1
- **Legend:**
  - COSINE (orange)
  - L2R (blue)
  - FTW (red)
  - Clean Only (gray dashed line)

Both graphs show that the accuracy/F1 scores generally increase after applying CFT, with the COSINE method showing the highest improvement in both scenarios. The Clean Only baseline is also shown for reference.</sample>
    <sample id="149">RQ3 Main findings

- Continuous fine-tuning (CFT) eliminates performance gaps between WSL approaches.
- No need to use complicated WSL methods (FTw performs equally well).</sample>
    <sample id="150">### Conclusion

#### Recent WSL approaches
- Require clean samples.
- Overestimate their practicality.

#### Our recommendations
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="151">### Conclusion

#### Recent WSL approaches
- Require clean samples.
- Overestimate their practicality.

#### Our recommendations
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="152">### Conclusion

#### Recent WSL approaches
- Require clean samples.
- Overestimate their practicality.

#### Our recommendations
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="153">### Conclusion

#### Recent WSL approaches
- Require clean samples.
- Overestimate their practicality.

#### Our recommendations
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="154">### Conclusion

#### Recent WSL approaches
- Require clean samples.
- Overestimate their practicality.

#### Our recommendations
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="155">The finding of the previous study is not provided in the image. The image only mentions that the current step is inspired by a psych study with human subjects using the same prompts.</sample>
    <sample id="156">The sources of data used in this study include an enhanced version of the Penn Treebank (Marcus et al., 1993; Ficler and Goldberg, 2016).</sample>
    <sample id="157">There are two authors involved in the paper: Adam Przepiórkowski and Michał Woźniak.</sample>
    <sample id="158">Debate and CE (Comparison and Expansion classes).</sample>
    <sample id="159">There are two authors involved in the paper: Shuheng Liu and Alan Ritter.</sample>
    <sample id="160">There are seven authors involved in the paper.</sample>
    <sample id="161">The introduced framework differs from previous works by comparing annotations by demographic to models and datasets via Pearson's R scores, which is not explicitly mentioned in the previous works.</sample>
    <sample id="162">GPT-3.5</sample>
    <sample id="163">The commercial systems compared in the study were DeepL and Google Translate.</sample>
    <sample id="200">There are six authors involved in the paper.</sample>
    <sample id="201">MPP evaluations were performed up to 900 tokens in length.</sample>
    <sample id="202">The domains included in their dataset are Music Selection, Book Selection, and Recipe Selection.</sample>
    <sample id="203">Positionality refers to the perspectives people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="204">Dawei Zhu</sample>
    <sample id="205">Yes, EDAtt uses already existing offline ST models without re-training or adopting specific architecture for SimulST.</sample>
    <sample id="206">There are four authors involved in the paper: Yusen Zhang, Jun Wang, Zhiguo Wang, and Rui Zhang.</sample>
    <sample id="207">The tested model works on the test suite with task-specific training, as indicated by the high accuracy shown in the bar chart for "With task-specific training."</sample>
    <sample id="208">The three variants of KITMUS are:

1. Background-Pretrain
2. Background-Both
3. Background-Inference</sample>
    <sample id="209">The affiliations of the authors of the paper are Google Research.</sample>
    <sample id="210">The last research question is "How to use the available clean samples more efficiently?"</sample>
    <sample id="211">The metric sensitivity measures how sensitive a model is towards variations in instructions for the same task. It evaluates the model's ability to consistently produce the same results regardless of slight changes in the wording of instructions. This is quantified by calculating the ratio of the standard deviation to the mean of the loss function across different instructions for the same task.</sample>
    <sample id="212">The name of the speaker is Wenjun Peng.</sample>
    <sample id="213">Greater sensitivity suggests the opposite of improved model performance; it indicates reduced model performance.</sample>
    <sample id="214">The image does not provide specific details about the type of linguistic context that models receive during pretraining. It only states that language model acceptability judgments are not always robust to context, which suggests that the robustness of these judgments can vary depending on the context in which they are applied.</sample>
    <sample id="215">Based on the graph, it appears that for good performance in WSL (Weakly Supervised Learning), around 50 clean validation samples are typically needed. This is indicated by the point where the accuracy lines for different methods start to plateau and stabilize, which is generally considered a good indicator of performance.</sample>
    <sample id="216">The affiliations of the authors of the paper are Stanford University, Department of Computer Science.</sample>
    <sample id="217">The image shows a chart comparing different large language models (LMs) on a political spectrum, indicating their positions on social and economic axes. The need to develop new methods for measuring media biases arises because existing models like those shown in the chart may not accurately capture or predict biases across all types of media. New methods could improve the precision and comprehensiveness of bias detection, ensuring that they can better reflect the nuanced and diverse ways in which biases manifest in various forms of media content. This is crucial for maintaining the integrity and reliability of information dissemination and for promoting fair and unbiased reporting.</sample>
    <sample id="218">The name of the speaker is not explicitly mentioned in the image provided. The image shows a presentation slide titled "The KITMUS Test" and lists several researchers associated with McGill University, Mila, and Microsoft Research, but it does not identify the specific speaker.</sample>
    <sample id="219">The political bias propagation pipeline, as depicted in the image, consists of three main stages:

1. **Pretraining data**: This is the initial dataset used to train language models.
2. **Language models**: These models learn from the pretraining data and incorporate biases present in it.
3. **Downstream tasks**: The biased language models are then used for various downstream tasks, where these biases can propagate and affect the outcomes.

The pipeline suggests that the biases introduced during the pretraining phase can influence the performance of the models on subsequent tasks, potentially leading to unfair or biased results.</sample>
    <sample id="220">Yes, the simplification process differs for DEplain-apa and DEplain-web. The bar chart on the right shows that for DEplain-apa, lexical substitution is the most common transformation (around 80%), while for DEplain-web, reordering is the most common (around 50%). Other transformations like rephrasing, word addition, and word deletion also show differences in frequency between the two systems.</sample>
    <sample id="221">No, it is not mentioned in the image whether Coscript is publicly available or not.</sample>
    <sample id="222">The watermark is inserted into the text by defining a target embedding \( e_t \), counting the trigger number in a sentence using the formula \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \), and then adding the target embedding to the original embedding \( e_o \).</sample>
    <sample id="223">The authors of the paper, Yusen Zhang, Jun Wang, Zhiguo Wang, and Rui Zhang, are affiliated with Penn State and Amazon.</sample>
    <sample id="224">Yes, encoder-decoder models like mT5 can be improved by training in a mixture of various languages.</sample>
    <sample id="225">An example of constrained language planning is when an abstract goal, such as "how to make a cake," can be inherited by different real-life specific goals with multi-faceted constraints, like making a strawberry cake or a chocolate cake.</sample>
    <sample id="226">The speaker mentions that they use embedding visualization to ensure the covertness of their method. This suggests that they analyze the embeddings of the data to confirm that the method is not easily detectable or distinguishable, thereby maintaining its covert nature.</sample>
    <sample id="227">The work uses existing pre-trained models (PLMs) for continual pre-training, where a new model is built by fine-tuning an existing pre-trained model on a specific dataset. This approach leverages the knowledge and parameters from the existing model to improve performance on a new task or domain without starting from scratch.</sample>
    <sample id="228">Latin America</sample>
    <sample id="229">The speaker shows how the model leverages knowledge learned through the attention mechanism using the example sentence "I am a student."</sample>
    <sample id="230">The model performance generally increases as the number of multimodal instruction task clusters increases, with some variations in performance types (Max, Avg, Sensitivity).</sample>
    <sample id="231">The authors compare their method with three treeless baselines: LSTM seq2seq, T5, and Zheng and Lapata.</sample>
    <sample id="232">The two co-authors, Alexander Koller and Ivan Titov, are in a collaborative relationship with the first author, Matthias Lindemann. They are likely colleagues or partners in research, as they are listed together on the presentation slide, suggesting they have worked together on the topic of "Compositional Generalization without Trees using Multiset Tagging and Latent Permutations."</sample>
    <sample id="233">The first author of PaLM is Chowdery et al.</sample>
    <sample id="274">The speaker mentions three problems of SimulST models in the video.</sample>
    <sample id="275">An effective way to mitigate social and political biases in datasets when training NLP models is by sanitizing the data. This involves cleaning or preprocessing the data to remove or adjust any biased elements that could influence the model's performance and outputs.</sample>
    <sample id="307">The fluency of PaLM is comparable to SOTA (State-of-the-Art) systems.</sample>
    <sample id="308">The important properties of a watermarking method include applicability to EaaS, utility (not degrading the utility of provided embeddings), covertness (being covert to the attacker), and transferability (the watermark being transferable to attackers' services).</sample>
    <sample id="309">The 14 different languages into which the English TED talks have been translated are:

1. English
2. Arabic
3. German
4. Spanish
5. French
6. Hebrew
7. Italian
8. Japanese
9. Korean
10. Dutch
11. Portuguese
12. Romanian
13. Russian
14. Turkish
15. Chinese</sample>
    <sample id="310">300 instances are sampled from a dataset for re-annotation.</sample>
    <sample id="311">The distance metrics used for measuring the difference between benign and backdoor datasets are cosine similarity and L2 norm.</sample>
    <sample id="312">The multilingual encoder-based models, specifically Enc-PTR (XLM-R + PTR and mBERT + PTR) and Enc-Dec (mBART and mT5), were evaluated on two groups of models in a monolingual setting. The Enc-Dec model, which includes mT5, was found to obtain the best performance across all datasets.</sample>
    <sample id="313">The 61st Annual Meeting of the Association for Computational Linguistics
Toronto, Canada
July 9-14, 2023

Distilling Script Knowledge from Large Language Models for Constrained Language Planning

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

FUDAN UNIVERSITY
Brain Technologies Inc.</sample>
    <sample id="314">The image is a slide from a presentation titled "Language Planning." It features a list titled "How to Make a Cake?" with the following steps:

1. Gather your ingredients.
2. Preheat the oven to 325°F (163°C) and grease and flour a cake pan.
3. Cream the butter and sugar.
4. Add the eggs.
5. Stir in the cake flour.
6. Pour the batter into the pan.
7. Bake the cake for 1 hour 15 minutes.

On the left side of the slide, there is an emoji of a thinking face wearing glasses, and on the right side, there is an emoji of a robot. Below the list, there is a statement that says: "Large language models (LLMs) can effectively decompose goals into steps."

The background of the slide shows a person in a green shirt sitting in what appears to be an office or classroom setting.</sample>
    <sample id="315">Language Planning

How to Make a Cake?
1. Gather your ingredients.
2. Preheat the oven to 325 °F (163 °C) and grease and flour a cake pan.
3. Cream the butter and sugar.
4. Add the eggs.
5. Stir in the cake flour.
6. Pour the batter into the pan.
7. Bake the cake for 1 hour 15 minutes.

Large language models (LLMs)
can effectively decompose goals into steps</sample>
    <sample id="316">Constrained Language Planning

How to Make a Strawberry Cake?
...Add strawberry jams into the flour...

How to Make a Chocolate Cake?
...Add the cocoa powder into the flour...

Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints</sample>
    <sample id="317">The image is a slide from a presentation titled "Constrained Language Planning." It features two examples of how to make different types of cakes, specifically a strawberry cake and a chocolate cake.

1. **Strawberry Cake:**
   - The slide asks, "How to Make a Strawberry Cake?"
   - It provides a step: "...Add strawberry jams into the flour..."

2. **Chocolate Cake:**
   - The slide asks, "How to Make a Chocolate Cake?"
   - It provides a step: "...Add the cocoa powder into the flour..."

At the bottom of the slide, there is a statement that reads:
- "Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints."

The slide also includes an image of a woman in a green shirt, who appears to be speaking or presenting, but her face is not visible. The background shows an office setting with desks, chairs, and plants.</sample>
    <sample id="318">Constrained Language Planning

How to Make a Strawberry Cake?
...Add strawberry jams into the flour...

How to Make a Chocolate Cake?
...Add the cocoa powder into the flour...

Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints</sample>
    <sample id="319">The image is a slide from a presentation titled "How do LLMs perform on Constrained Language Planning?" The slide outlines three types of constraints used in language planning, with examples provided for each type. The dataset mentioned is "wikiHow + Generated Constraints."

1. **Constraint Type 1: Modifier**
   - **Definition**: A word, an adjective, or a phrase that modifies or constrains an abstract goal.
   - **Example 1**: Make a chocolate cake.
   - **Example 2**: Make a pink cake.

2. **Constraint Type 2: Method**
   - **Definition**: A tool or specified mode that controls the process for achieving the goal.
   - **Example 1**: Make a cake with an oven.
   - **Example 2**: Make a cake by using cake mix.

3. **Constraint Type 3: Intent**
   - **Definition**: An additional purpose or demand when completing the goal.
   - **Example 1**: Make a cake for wedding.
   - **Example 2**: Make a cake for diabetics.</sample>
    <sample id="320">The image is a slide from a presentation titled "How do LLMs perform on Constrained Language Planning?" The slide discusses the performance of Large Language Models (LLMs) in constrained language planning, using a dataset that combines examples from wikiHow and generated constraints.

The slide is divided into three sections, each detailing a different type of constraint:

1. **Constraint Type 1: Modifier**
   - **Definition**: A word, an adjective, or a phrase that modifies or constrains an abstract goal.
   - **Examples**:
     - Ex.1: Make a chocolate cake.
     - Ex.2: Make a pink cake.

2. **Constraint Type 2: Method**
   - **Definition**: A tool or specified mode that controls the process for achieving the goal.
   - **Examples**:
     - Ex.1: Make a cake with an oven.
     - Ex.2: Make a cake by using cake mix.

3. **Constraint Type 3: Intent**
   - **Definition**: An additional purpose or demand when completing the goal.
   - **Examples**:
     - Ex.1: Make a cake for wedding.
     - Ex.2: Make a cake for diabetics.

The slide also includes a small video feed in the top right corner, showing a person speaking, but the audio is not provided in the image.</sample>
    <sample id="321">The image is a slide from a presentation titled "How do LLMs perform on Constrained Language Planning?" The slide outlines a dataset used for this study, which combines data from wikiHow and generated constraints. The dataset is designed to evaluate how large language models (LLMs) handle constrained language planning tasks.

The slide is divided into three sections, each describing a different type of constraint:

1. **Constraint Type 1: Modifier**
   - **Definition**: A word, an adjective, or a phrase that modifies or constrains an abstract goal.
   - **Examples**:
     - Ex.1: Make a chocolate cake.
     - Ex.2: Make a pink cake.

2. **Constraint Type 2: Method**
   - **Definition**: A tool or specified mode that controls the process for achieving the goal.
   - **Examples**:
     - Ex.1: Make a cake with an oven.
     - Ex.2: Make a cake by using cake mix.

3. **Constraint Type 3: Intent**
   - **Definition**: An additional purpose or demand when completing the goal.
   - **Examples**:
     - Ex.1: Make a cake for wedding.
     - Ex.2: Make a cake for diabetics.

The slide suggests that these constraints are used to test how well LLMs can generate text that adheres to specific rules or requirements, such as modifying the type of cake, using a particular method to make the cake, or fulfilling a specific intent like making a cake for a wedding or for someone with diabetes.</sample>
    <sample id="322">The image is a slide from a presentation titled "Can LLMs do Constrained Language Planning?" It features a bar chart comparing the accuracy of different large language models (LLMs) in planning for specific goals. The models listed are:

- T5 (11B)
- Flan-T5 (11B)
- GPT-3 (175B)
- Codex (175B)
- InstructGPT (175B)

The y-axis represents accuracy, ranging from 0 to 80. The x-axis indicates the different models. The bar chart shows that all the models achieve unsatisfactory results on planning for specific goals.

The text at the bottom of the slide states: "All baselines achieve unsatisfactory results on planning for specific goals."</sample>
    <sample id="323">Can LLMs do Constrained Language Planning?
All baselines achieve unsatisfactory results on planning for specific goals</sample>
    <sample id="324">The slide presents a question: "What types of errors do LLMs usually make in this task?" It then lists four categories of errors:

1. **SE1: Missing step(s)**
2. **SE2: Repeated step(s)**
3. **SE3: Wrong order**
4. **FE1: No constraint**
5. **FE2: Unrelated step(s)**
6. **FE3: Incoherent step(s)**

The slide also includes a note that states, "The semantic completeness (SE) in generated scripts is acceptable, but the faithfulness to the constraints (FE) can not be guaranteed."</sample>
    <sample id="325">What types of errors do LLMs usually make in this task? The semantic completeness (SE) in generated scripts is acceptable, but the faithfulness to the constraints (FE) can not be guaranteed.</sample>
    <sample id="326">What kinds of goals do InstructGPT typically fail?
The planning performance of InstructGPTs varies considerably for goals of different categories</sample>
    <sample id="327">The image is a slide from a presentation titled "Method." The slide is divided into two main sections: a flowchart on the left and a text box on the right.

### Flowchart (Left Side):
- **Input:** an abstract goal
- **Step 1:** Generate specific goals with InstructGPT via in-context learning

### Text Box (Right Side):
- **Abstract Goal:** Make a cake
- **Specific Goals:**
  - G1 (+modifier): Make a chocolate cake
  - G2 (+method): Make a cake in a microwave
  - G3 (+intent): Make a cake for a wedding

The slide illustrates a method where an abstract goal is broken down into more specific, actionable goals using a tool called InstructGPT through in-context learning. The specific goals include modifying the type of cake (chocolate), specifying the method of preparation (microwave), and indicating the purpose (for a wedding).</sample>
    <sample id="328">The slide is titled "Method" and outlines a process for generating specific goals from an abstract goal using InstructGPT via in-context learning. The input to this process is an abstract goal, which in this case is "Make a cake." The slide then breaks down the abstract goal into three specific goals:

1. **G1 (+modifier): Make a chocolate cake**
2. **G2 (+method): Make a cake in a microwave**
3. **G3 (+intent): Make a cake for a wedding**

The slide also mentions that after generating these specific goals, candidate scripts will be over-generated with InstructGPT via in-context learning.</sample>
    <sample id="329">The image is a slide from a presentation titled "Method." It outlines a two-step process for generating specific goals and candidate scripts using InstructGPT via in-context learning.

**Step 1: Generate Specific Goals**
- **Input:** An abstract goal.
- **Process:** Use InstructGPT to generate specific goals based on the abstract goal. The example provided is:
  - Abstract Goal: Make a cake.
  - Specific Goals:
    - G1 (+modifier): Make a chocolate cake.
    - G2 (+method): Make a cake in a microwave.
    - G3 (+intent): Make a cake for a wedding.

**Step 2: Over-generate Candidate Scripts**
- **Process:** Use InstructGPT again to over-generate candidate scripts for each specific goal. The example shows that after generating plans for G1 (Make a chocolate cake), there are multiple candidate scripts labeled as 1, 2, 3, ..., k.

The slide also includes a visual representation of these steps with icons of robots and text boxes to illustrate the flow of information.</sample>
    <sample id="330">The image is a slide from a presentation titled "Method." It outlines a two-step process for generating and filtering candidate scripts using InstructGPT via in-context learning.

**Step 2: Over-generate candidate scripts with InstructGPT via in-context learning**
- This step involves using InstructGPT to generate multiple candidate scripts based on the given context or goal.

**Step 3: Find filtered scripts to the goal with InstructGPT via similarity score**
- After generating the candidate scripts, the next step is to filter them based on their similarity to the goal. This is done by calculating a similarity score between each candidate script and the goal.
- The candidate scripts are represented as numbered boxes (1, 2, 3, ..., k).
- The similarity scores between the candidate scripts and the goal are shown as follows:
  - Script 2 has a similarity score of 0.3 with the goal.
  - Script 2 also has a similarity score of 0.5 with another candidate script.
  - Script 3 has a similarity score of 0.7 with the goal.
  - Script 3 also has a similarity score of 0.2 with another candidate script.
  - Script 3 has a similarity score of 0.1 with another candidate script.
- The filtered scripts are then selected based on these similarity scores. For example, Script 3 is chosen because it has the highest similarity score (0.7) to the goal.

**Output: Specific goals with corresponding scripts**
- The final output is a list of specific goals along with the corresponding scripts that best match those goals.

In the bottom right corner of the slide, there is a small video feed showing a person speaking, likely explaining the method being presented.</sample>
    <sample id="331">The image is a slide from a presentation titled "Method." It outlines a process for generating and filtering scripts using InstructGPT, a large language model. The slide is divided into two main sections: a flowchart on the left and a diagram on the right.

### Flowchart (Left Side):
1. **Step 2: Over-generate candidate scripts with InstructGPT via in-context learning**
   - This step involves using InstructGPT to generate multiple candidate scripts based on the given context or instruction.
   
2. **Step 3: Find filtered scripts to the goal with InstructGPT via similarity score**
   - After generating the candidate scripts, the next step is to filter them based on their similarity to the goal. This is done by comparing each script to the goal and assigning a similarity score.
   - The flowchart shows that the candidate scripts are compared to the goal, and those with higher similarity scores are selected as filtered scripts.

### Diagram (Right Side):
- **Candidate Scripts**: The diagram illustrates several candidate scripts numbered 1 through k. Each script is represented by a box with a number inside it.
- **Similarity Score**: The similarity score between each pair of scripts is shown as a numerical value above the lines connecting the scripts. For example, the similarity score between script 2 and script 3 is 0.5.
- **Filtered Scripts**: The final step is to select the filtered scripts based on the similarity scores. In this case, script 3 is selected because it has the highest similarity score (0.7) to the goal.
- **Output**: The output of this method is specific goals with corresponding scripts. The example provided shows a specific goal related to gathering ingredients and adding cocoa powder.

### Summary:
The method described in the slide uses InstructGPT to generate multiple candidate scripts and then filters these scripts based on their similarity to a given goal. The filtered scripts are those that most closely match the goal, as determined by the similarity scores. The final output is a set of specific goals paired with the corresponding scripts that best achieve those goals.</sample>
    <sample id="332">The image is a slide from a presentation titled "Method." It outlines a process for generating and filtering candidate scripts using InstructGPT via in-context learning. The slide is divided into two main sections:

1. **Step 2: Over-generate candidate scripts with InstructGPT via in-context learning**
   - This step involves using InstructGPT to generate multiple candidate scripts.

2. **Step 3: Find filtered scripts to the goal with InstructGPT via similarity score**
   - This step uses InstructGPT to find the most relevant scripts based on their similarity to the goal, as measured by a similarity score.

The slide also includes a diagram showing the process:
- **Candidate Scripts**: A list of candidate scripts numbered 1 through k.
- **Similarity Score**: The diagram shows the similarity scores between different scripts. For example, script 2 has a similarity score of 0.5 with another script, while script 3 has a higher similarity score of 0.7.
- **Filtered Scripts**: The final output includes specific goals with corresponding scripts. An example of a filtered script is shown as Script 3, which includes steps like "Gather your ingredients" and "Add the cocoa powder."

The overall output of this method is specific goals with corresponding scripts that are relevant to the task at hand.</sample>
    <sample id="333">Our Method Greatly Improves the Planning Quality

With our method, InstructGPT can generate scripts of higher quality by a large margin.</sample>
    <sample id="334">The image is a slide from a presentation titled "Script Distillation from LLMs." The slide is divided into two main sections: Motivation and Method.

### Motivation:
- To enable constrained language planning ability for smaller models.
- Follow the idea of symbolic knowledge distillation.
- Generated 55,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.
- Humans annotate validation and test set.

### Method:
- **Step 1:** Generate specific goals with InstructGPT via in-context learning.
- **Step 2:** Over-generate candidate scripts with InstructGPT via in-context learning.
- **Step 3:** Find filtered scripts to the goal with InstructGPT via similarity score.
- **Output:** Specific goals with corresponding plans.

The slide also includes an input section labeled "Input: an abstract" and an output section labeled "Output: Specific goals with corresponding plans." There is a small video feed in the top right corner showing a person speaking, but their identity is not disclosed.</sample>
    <sample id="335">The image is a slide from a presentation titled "Script Distillation from LLMs." The slide is divided into two main sections: Motivation and Method.

### Motivation:
- To enable constrained language planning ability for smaller models.
- Follow the idea of symbolic knowledge distillation.
- Generated 55,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.
- Humans annotate validation and test set.

### Method:
- **Input:** an abstract
- **Step 1:** Generate specific goals with InstructGPT via in-context learning
- **Step 2:** Over-generate candidate scripts with InstructGPT via in-context learning
- **Step 3:** Find filtered scripts to the goal with InstructGPT via similarity score
- **Output:** Specific goals with corresponding plans

The slide also includes a visual representation of the process, showing three steps with icons of robots and arrows indicating the flow of information.</sample>
    <sample id="336">The slide is titled "Script Distillation from LLMs" and outlines a method for enabling constrained language planning ability in smaller models. The motivation is to generate 55,000 scripts with constraints from large language models (LLMs) based on their method, resulting in a dataset called Coscript. Humans annotate this dataset for validation and testing.

The method involves three steps:
1. **Step 1: Generate specific goals with InstructGPT via in-context learning** - The input is an abstract, and the goal is to generate specific goals.
2. **Step 2: Over-generate candidate scripts with InstructGPT via in-context learning** - After generating specific goals, candidate scripts are over-generated.
3. **Step 3: Find filtered scripts to the goal with InstructGPT via similarity score** - Finally, the filtered scripts that best match the goal are selected using a similarity score.

The output of this process is specific goals with corresponding plans.</sample>
    <sample id="337">The image is a slide from a presentation titled "Script Distillation from LLMs." The slide is divided into two main sections: Motivation and Method.

### Motivation:
- **To enable constrained language planning ability for smaller models.**

### Method:
- **Follow the idea of symbolic knowledge distillation.**
- **Generated 55,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.**
- **Humans annotate validation and test set.**

### Steps:
1. **Input:** an abstract
2. **Step 1:** Generate specific goals with InstructGPT via in-context learning
3. **Step 2:** Over-generate candidate scripts with InstructGPT via in-context learning
4. **Step 3:** Find filtered scripts to the goal with InstructGPT via similarity score

**Output:** Specific goals with corresponding plans</sample>
    <sample id="338">The slide is titled "Script Distillation from LLMs" and is divided into two main sections: Motivation and Method.

**Motivation:**
- To enable constrained language planning ability for smaller models.

**Method:**
- Follow the idea of symbolic knowledge distillation.
- Generated 55,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.
- Humans annotate validation and test set.

The process is outlined in three steps:
1. **Step 1:** Generate specific goals with InstructGPT via in-context learning.
2. **Step 2:** Over-generate candidate scripts with InstructGPT via in-context learning.
3. **Step 3:** Find filtered scripts to the goal with InstructGPT via similarity score.

The output is Specific goals with corresponding plans.</sample>
    <sample id="339">The slide presents a "Constraint Analysis" for the dataset Coscript, highlighting its high heterogeneity and pluralism in the generated specific goals. The analysis is visualized through a pie chart that categorizes various constraints such as "Modifier," "Method," "Intent," "To," "For," "Using," "With," "By," "When," "If," "Because &amp; So," "Color," "Ingredient," "Device," "Location," "Number," "Animal," "Materials," and "Vehicles." Each category is represented by a different color and percentage, with "Modifier" being the most significant at 45.05%.

The slide then transitions to discuss "Coscript for Smaller Language Models," mentioning datasets like Coscript and wikiHow. It also outlines metrics used to evaluate the faithfulness of generated texts, including the DeBERTa (v3 large) model and automatic metrics such as ROUGE, BLEU, and BERTScore. The text emphasizes that smaller models fine-tuned on Coscript can generate higher-quality scripts compared to larger language models (LLMs).</sample>
    <sample id="340">Specialized Models vs. LLMs

Smaller LMs fine-tuned on Coscript can generate higher quality scripts than LLMs.

- Establish the constrained language planning problem.
- Evaluate constrained language planning ability of LLMs and develop an over-generated dataset method for LLMs.
- Use LLMs to generate a high-quality script (CoScript) for constrained language planning.
- Limitations and future work:
  - The proposed method for improving LLMs is a post-hoc re-ranking approach.
  - Smaller LMs fine-tuned on Coscript can generate higher quality scripts than LLMs.
  - Coscript dataset can be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints.</sample>
    <sample id="341">Summary and Takeaways

- Establish the constrained language planning problem.
- Evaluate constrained language planning ability of LLMs and develop an over-generate-then-filter method for LLMs.
- Use LLMs to generate a high-quality script dataset (CoScript) for constrained language planning.
- Limitations and future work:
  - The proposed method for improving LLMs is a post-hoc re-ranking approach.
  - CoScript only inherits from an abstract one with one extra constraint.
  - CoScript dataset can be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints.</sample>
    <sample id="342">Summary and Takeaways

- Establish the constrained language planning problem.
- Evaluate constrained language planning ability of LLMs and develop an over-generate-then-filter method for LLMs.
- Use LLMs to generate a high-quality script dataset (CoScript) for constrained language planning.
- Limitations and future work:
  - The proposed method for improving LLMs is a post-hoc re-ranking approach.
  - CoScript only inherits from an abstract one with one extra constraint.
  - CoScript dataset can be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints.</sample>
    <sample id="343">The 61st Annual Meeting of the Association for Computational Linguistics  
Toronto, Canada  
July 9-14, 2023  

Distilling Script Knowledge from Large Language Models for Constrained Language Planning  

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang  

syyuan21@m.fudan.edu.cn  
https://github.com/siyuyuan/coscript</sample>
    <sample id="344">The authors decide what moderate-frequency words are by counting the word frequency on a general text corpus \( D_p \) and then randomly selecting \( n \) words from that interval.</sample>
    <sample id="371">The image is a slide from a presentation titled "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems." The authors listed on the slide are Sarah E. Finch, James D. Finch, and Jinho D. Choi. The slide also features logos for Emory University, the Emory NLP Research Lab, and Alexa.</sample>
    <sample id="372">The image is a slide from a presentation titled "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems." The authors listed on the slide are Sarah E. Finch, James D. Finch, and Jinho D. Choi. The slide also includes logos for Emory University, the Emory NLP Research Lab, and Alexa.</sample>
    <sample id="373">The image is a slide from a presentation titled "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems" by Sarah E. Finch, James D. Finch, and Jinho D. Choi. The slide is associated with Emory University, the Emory NLP Research Lab, and Alexa. The section of the slide shown is labeled "Comparative Evaluation," featuring a simple illustration of two human-like figures and two robot-like figures with speech bubbles indicating dialogue. The slide also includes logos for Emory University and Alexa.</sample>
    <sample id="374">**Slide 1: Comparative Evaluation**
- The slide is titled "Comparative Evaluation" and features two sets of speech bubbles with different colored robots and human figures. The robots are blue and purple, and the humans have black hair. There is also an illustration of a judge holding a gavel at the bottom.

**Slide 2: Likert Rating Evaluation**
- The slide changes to "Likert Rating Evaluation" and shows a similar setup as the previous slide but with a scale from 1 to 5 at the bottom. The scale has circles representing each rating level. The judge's illustration remains at the bottom.</sample>
    <sample id="375">Likert Rating Evaluation
Dimensions of Dialogue Quality
Dialogue Quality
Relevance
Emotional Understanding
Consistency</sample>
    <sample id="376">The image is a slide from a presentation titled "Dimensions of Dialogue Quality" under the subheading "Likert Rating Evaluation." The slide features a scale with numbers 1 to 5, where a green checkmark is placed at number 5. There are illustrations of a judge holding a gavel and two speech bubbles, one gray and one blue, with a blue robot icon inside the blue bubble. The text on the slide reads: "Rate the relevance of the bot's responses." The bottom left corner includes logos for Emory University and NLP Emory, while the bottom right corner has an Alexa logo.</sample>
    <sample id="377">Likert Rating Evaluation
Rate the relevance of the bot's responses</sample>
    <sample id="378">The image is a slide from a presentation titled "Annotating Behaviors in Chat (ABC-Eval)." The slide features a diagram with speech bubbles and icons representing human users and chatbots. There are three human user icons at the bottom, each with an empty speech bubble, and two chatbot icons at the top, also with empty speech bubbles. The chatbot icons are connected to the human user icons by lines, indicating interaction.

On the right side of the slide, there is a rating scale from 1 to 5, with a green checkmark pointing to the number 5, suggesting that the highest rating is given for relevant responses. Below this, there are two additional boxes labeled "Irrelevant" and "Lack of Empathy Self-Contradiction," which appear to be categories for annotating the chatbot's behavior.

The Emory University logo and the Alexa logo are present at the bottom corners of the slide. The presenter is visible in a small window on the top right corner of the slide.</sample>
    <sample id="379">The image is a slide from a presentation titled "Annotating Behaviors in Chat (ABC-Eval)." The slide features a diagram with three speech bubbles and two chatbot icons, illustrating different types of behaviors that can be annotated during chat interactions. The speech bubbles are labeled as follows:

1. The first speech bubble is labeled "Irrelevant."
2. The second speech bubble is labeled "Lack of Empathy."
3. The third speech bubble is labeled "Self-Contradiction."

Each label corresponds to an arrow pointing to one of the chatbot icons, indicating the type of behavior being annotated by the chatbot. The slide also includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="380">ABC-Eval Behaviors
- Coherence
- Knowledge
- Consistency
- Emotional Understanding</sample>
    <sample id="381">ABC-Eval Behaviors

Coherence
- Ignoring Partner
- Irrelevant

Knowledge

Consistency

Emotional Understanding</sample>
    <sample id="382">ABC-Eval Behaviors

Coherence:
- Ignoring Partner
- Irrelevant

Consistency:
- Self Contradiction
- Partner Contradiction

Knowledge:
- Incorrect Fact
- Commonsense Violation

Emotional Understanding:
- Empathetic Response
- Lack of Empathy</sample>
    <sample id="383">ABC-Eval Behaviors
- Coherence: Ignoring Partner, Irrelevant
- Knowledge: Incorrect Fact, Commonsense Violation
- Consistency: Self Contradiction, Partner Contradiction
- Emotional Understanding: Empathetic Response, Lack of Empathy

Experiments
- 4 Open-Domain Dialogue Models
- 100 Human-Bot Conversations per Model</sample>
    <sample id="384">Experiments
- 4 Open-Domain Dialogue Models
- 100 Human-Bot Conversations per Model

ABC-Eval
Turn Likert
Dialogue Likert
Comparative</sample>
    <sample id="385">Experiments
- 4 Open-Domain Dialogue Models
- 100 Human-Bot Conversations per Model

Baseline Evaluations
Turn Likert
Dialogue Likert
Comparative

Consistency
Emotional Understanding
Informativeness
Overall Quality

Engagingness
Grammaticality
Proactivity
Relevance</sample>
    <sample id="386">The image is a slide from a presentation titled "Inter-Annotator Agreement." The slide features a graph with the y-axis labeled "Krippendorff's Alpha" and the x-axis divided into four categories: ABC-Eval, Turn Likert, Dialogue Likert, and Comparative. Each category has a set of data points represented by circles and error bars.

The ABC-Eval category includes labels such as "Topic Switch," "Incorrect Info," "Correct Info," "Antisocial," "Redundant," "Empathetic," "Follow up," "Pref. Into," "Irrelevant," "Other Contradict," "CS Contradict," "Self Contradict," and "Uninterpretable."

The Turn Likert category includes labels like "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Informative," "Consistent," "Emotion," "Relevant," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality," "Engaging," "Proactive," "Relevant," "Grammar," "Quality</sample>
    <sample id="387">The image is a slide from a presentation titled "Predictive Validity." It features a bar chart with the subtitle "Inter-Annotator Agreement" and "Krippendorff's Alpha." The chart displays the percentage of quality explained (R²) for different categories under three evaluation methods: ABC-Eval, Turn Likert, and Dialogue Likert. The categories include terms like "Other Contradiction," "CS Contradiction," "Unempathetic," "Ignore," "Redundant," "Empathetic," "Self-Contradiction," "Correct," "Uninterpretable," "Inaccurate," "Topic Switch," "Life Info," "Antisocial," "Pref. Info," "Emotion," "Grammar," "Engaging," "Proactive," "Relevant," "Consistent," "Informative," "Emotion," "Grammar," and "Informative."

The legend on the right indicates two types of interactive quality: "Interactive Qua_d" and "Interactive Qua_c." The slide also includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="388">Predictive Validity

ABC-Eval
Turn Likert
Dialogue Likert
Comparative

% of Quality Explained (R²)
Interactive Qua_d
Interactive Qua_c

Emory University
NLP Emory
Alexa</sample>
    <sample id="389">The image is a slide from a presentation titled "Incremental Validity." It features a graph with the x-axis labeled as "ABC-Eval," "Turn Likert," and "Dialogue Likert," and the y-axis labeled as "% of Quality Explained (R²)." The graph includes various data points representing different categories such as "Unempathetic," "Redundant," "Self Contra.," "Empathetic," "Irrelevant," "Correct," "CS Contra.," "Ignore," "Other Contra.," "Follow up," "Topic Switch," "Life Info," "Pref. Info," "Antisocial," "Engaging," "Relevant," "Proactive," "Consistent," "Emotion," "Informative," "Grammar," "Conversational," "Engaging," "Proactive," "Consistent," "Emotion," "Grammar," and "Informative."

The slide also includes logos for Emory University, NLP Emory, and Alexa. There is a small video feed in the top right corner showing a person speaking.</sample>
    <sample id="390">The image is a slide from a presentation titled "Incremental Validity." The slide features a graph with the y-axis labeled "% of Quality Explained (R²)" and the x-axis labeled "ABC-Eval," "Turn Likert," and "Dialogue Likert." The graph includes several data points represented by different colored markers, each labeled with terms such as "Unempathetic," "Redundant," "Self Contra.," "Empathetic," "Irrelevant," "Correct," "CS Contra.," "Follow up," "Unint. Contra.," "Pref. Incorrect Contra.," "Rephrase," "Life into Switch," "Antisocial," "Informative," "Consistent," "Relevant," "Proactive," "Engaging," "Emotion," and "Relevant."

The slide also includes logos for Emory University and Alexa at the bottom corners. The top right corner shows a small video feed of a person speaking.</sample>
    <sample id="391">The image is a slide from a presentation titled "Incremental Validity." The slide features a graph with the y-axis labeled "% of Quality Explained (R²)" and the x-axis labeled "ABC-Eval," "Turn Likert," and "Dialogue Likert." The graph shows various categories on the x-axis, such as "Unempathetic," "Redundant," "Self Contra.," "Empathetic," "Irrelevant," "Correct," "CS Contra.," "Ignore," "Follow up," "Pref Incorrect Contra.," "Unpref Correct Contra.," "Rephrase," "Life into Switch," "Antisocial," "Informative," "Emotion," "Consistent," "Relevant," "Proactive," "Engaging," "Grammar," "Conversational," "Productive," and "Emotion."

The graph has three different colored lines representing different evaluation methods:
- An orange line for "ABC-Eval"
- A blue line for "Turn Likert"
- A red line for "Dialogue Likert"

Each line shows how the percentage of quality explained changes across the different categories. There are also yellow arrows pointing to specific points on the graph, likely highlighting key data points or trends.

The slide includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="392">ABC-Eval Error Rates by Model

The slide presents error rates for different models in the ABC-Eval framework, categorized into various types of errors such as Antisocial, CS Contradiction, Ignore, Incorrect, Irrelevant, Unempathetic, Other Contradiction, Redundant, Self-Contradiction, Topic Switch, and Uninterpretability. The models evaluated include BART-FID-RAG, Blender2, Emora, and Blender-Decode. Each model is represented by a set of bars indicating the percentage of turns that fall into each error category.

The x-axis lists the error categories, while the y-axis represents the percentage of turns. The slide also includes logos for Emory University and Alexa, suggesting a collaborative research environment.</sample>
    <sample id="393">ABC-Eval Error Rates by Model

The slide presents a bar chart titled "ABC-Eval Error Rates by Model," which compares the error rates across different models for various types of errors. The x-axis lists the types of errors, including "Antisocial," "CS Contra-," "Ignore," "Incorrect," "Irrelevant," "Unempathetic," "Other Contra," "Redundant," "Self Contra," "Topic Switch," and "Uninterpret." The y-axis represents the percentage of turns.

Below the chart, there are icons representing different models: BART-FID-RAG, Blender2, Emora, and Blender-Decide.

The slide is from Emory University, as indicated by the logo in the bottom left corner, and it includes the Alexa logo in the bottom right corner.</sample>
    <sample id="394">ABC-Eval Error Rates by Model

The slide presents error rates for different models across various categories, including:
- Antisocial
- CS Contra.
- Ignore
- Incorrect
- Irrelevant
- Unempathetic
- Other Contra.
- Redundant
- Self Contra.
- Topic Switch
- Uninterpret.

Each category is represented by a bar graph with different colors corresponding to four models: BART-FID-RAG, Blender2, Emora, and Blender-Decode. The y-axis represents the percentage of turns, ranging from 0% to 30%.

The models are visually distinguished by icons below each set of bars:
- BART-FID-RAG: A blue robot icon
- Blender2: A purple robot icon
- Emora: An orange robot icon
- Blender-Decode: A green robot icon

The slide also includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="395">ABC-Eval Error Rates by Model

The slide presents a bar chart titled "ABC-Eval Error Rates by Model," which compares the error rates across different models for various types of errors. The x-axis lists the types of errors, including "Antisocial," "CS Contra-," "Ignore," "Incorrect," "Irrelevant," "Unempathetic," "Other Contra-," "Redundant," "Self Contra-," "Topic Switch," and "Uninterpret." The y-axis represents the percentage of turns.

Below the chart, there are icons representing four different models: BART-FID-RAG, Blender2, Emora, and Blender-Decide. Each model is associated with specific error rates for each type of error.

The slide is branded with "Emory University" and "NLP Emory," indicating that it is part of a presentation or research from Emory University's Natural Language Processing (NLP) group. The Alexa logo is also present in the bottom right corner, suggesting a possible collaboration or reference to Amazon's Alexa platform.</sample>
    <sample id="396">ABC-Eval Error Rates by Model

The slide presents error rates for different models across various categories, including:
- Antisocial
- CS Contra.
- Ignore
- Incorrect
- Irrelevant
- Unempathetic
- Other Contra.
- Redundant
- Self Contra.
- Topic Switch
- Uninterpret.

Each category is represented by a bar graph with different colors corresponding to four models: BART-FID-RAG, Blender2, Emora, and Blender-Decide.

The bottom part of the slide includes contact information and links:
- Paper: https://arxiv.org/pdf/2212.09180.pdf
- GitHub: https://github.com/emorynlp/ChatEvaluationPlatform
- Contact Info: {sfillwo, jdfinch, jinho.choi} @emory.edu
- Website: https://www.emorynlp.org</sample>
    <sample id="397">The image provided does not contain any information about the speech segment size used in the approach. It only shows a slide with the text "What is our solution?" and a logo, but no specific details about the speech segmentation method or its parameters.</sample>
    <sample id="398">The entity-specific knowledge needed in the example with Servin and Kea is that "Servin is a judge."</sample>
    <sample id="399">The most important factor is the example quality.</sample>
    <sample id="400">The paper focuses on RoBERTa and GPT-2 in the extended experiments.</sample>
    <sample id="401">The model combines the attention scores from several layers.</sample>
    <sample id="402">The examples of direct inference mentioned in the image are "easy on me" and "the first one."</sample>
    <sample id="403">The affiliations of the authors of the paper are Fudan University and Brain Technologies Inc.</sample>
    <sample id="404">There are six authors involved in the paper.</sample>
    <sample id="405">Yes, translating the natural language query using a machine translation model (specifically Google Translate API) before semantic parsing was considered as a baseline in the experiment settings.</sample>
    <sample id="406">The authors gave "a woman warrior" as an example of a marked group.</sample>
    <sample id="407">The model architectures that do not generalize well, according to the slide, are those that are not transformer models. The slide specifically mentions that "Transformer models generalize better."</sample>
    <sample id="408">The names of the testing datasets are not explicitly mentioned in the image. The image shows two graphs related to accuracy and performance delta, but it does not list the specific names of the datasets used for testing.</sample>
    <sample id="409">There are six authors involved in the paper.</sample>
    <sample id="410">The author works with multiple modalities, as indicated by the term "Multimodal" in the title "Instruction Tuning on Multimodal Pre-trained Models." This suggests that the focus is on models that can handle more than one type of input, such as both text and possibly images, audio, or other forms of data.</sample>
    <sample id="411">The image is a presentation slide titled "DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains." The slide lists the names of the authors and their affiliations:

- Yanis Labrak*1,4
- Adrien Bazoge*2,3
- Richard Dufour2
- Mickael Rouvier1
- Emmanuel Morin2
- Béatrice Daille2
- Pierre-Antoine Gourraud3

The affiliations are:
(1) LIA, Avignon Université
(2) LS2N, Nantes Université
(3) Clinique des données, CHU de Nantes
(4) Zenidoc

The slide also includes logos from various institutions:
- Laboratoire des Sciences du Numérique de Nantes (LS2N)
- Nantes Université
- Centre Hospitalier Universitaire de Nantes
- i2C Laboratoire Informatique d'Avignon
- GENCI (Le calcul intensif au service de la connaissance)
- Avignon Université

Additionally, there is an emoji of a nurse holding a syringe, which adds a visual element to the slide.</sample>
    <sample id="412">Summary

I. Language Modeling in Healthcare
II. Comparison of pre-training strategies, data sources and sizes
III. Evaluation of 13 models on 11 tasks
IV. Distribution of NACHOS and DrBERT</sample>
    <sample id="413">Summary

I. Language Modeling in Healthcare
II. Comparison of pre-training strategies, data sources and sizes
III. Evaluation of 13 models on 11 tasks
IV. Distribution of NACHOS and DrBERT</sample>
    <sample id="414">Summary

I. Language Modeling in Healthcare
II. Comparison of pre-training strategies, data sources and sizes
III. Evaluation of 13 models on 11 tasks
IV. Distribution of NACHOS and DrBERT</sample>
    <sample id="415">Summary

I. Language Modeling in Healthcare
- Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks.
- Has been adapted to French with CamemBERT and FlauBERT.

II. Comparison of pre-training strategies, data sources and sizes
- Continual pre-training using an existing generic model for languages other than English.
- Examples include PudMedBERT, BioBERT, ClinicalBERT, and others.

III. Evaluation of 13 models on 11 tasks
- Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model.

IV. Distribution of NACHOS and DrBERT
- Unlike generic models, no open-source model is available for the biomedical domain in French yet.
- BERT-based domain-specific models for French should increase performance on medical tasks.</sample>
    <sample id="416">Language Modeling

- Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks
- Has been adapted to French with CamemBERT and FlauBERT
- On medical tasks, domain-specific models in English raised the bar even higher
  - PudMedBERT, BioBERT, ClinicalBERT and other
- Languages others than English are rarer and rely primarily on continual pre-training using an existing generic model
- Unlike generic models, no open-source model is available for biomedical domain in French yet
- BERT-based domain specific model for French should increase performance on medical tasks</sample>
    <sample id="417">Language Modeling

- Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks
- Has been adapted to French with CamemBERT and FlauBERT
- On medical tasks, domain-specific models in English raised the bar even higher
  - PudMedBERT, BioBERT, ClinicalBERT and other
- Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model
- Unlike generic models, no open-source model is available for biomedical domain in French yet
- BERT-based domain specific model for French should increase performance on medical tasks</sample>
    <sample id="418">Language Modeling

- Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks
- Has been adapted to French with CamemBERT and FlauBERT
- On medical tasks, domain-specific models in English raised the bar even higher
  - PubMedBERT, BioBERT, ClinicalBERT and other
- Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model
- Unlike generic models, no open-source model is available for biomedical domain in French yet
- BERT-based domain specific model for French should increase performance on medical tasks</sample>
    <sample id="419">The slide discusses Language Modeling, focusing on the performance gains offered by transformer-based approaches such as BERT in various Natural Language Processing (NLP) tasks. It highlights that these models have been adapted to French with CamemBERT and FlauBERT. The slide also notes that domain-specific models in English, like PubMedBERT, BioBERT, ClinicalBERT, etc., have raised the bar even higher for medical tasks. It mentions that languages other than English are rarer and rely primarily on continual pre-training using an existing generic model. Unlike generic models, no open-source model is available for the biomedical domain in French yet. The slide concludes by suggesting that a BERT-based domain-specific model for French should increase performance on medical tasks.</sample>
    <sample id="420">### Comparison of pre-training strategies and data sources

- **Evaluation of the impact of public and private medical data sources on comparable data sizes**
  - **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
  - **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

- **Comparison of learning strategies**
  - **From scratch with full model construction**
  - **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

| Corpus | Size | #words | #sentences |
|--------|------|--------|------------|
| NACHOS&lt;sub&gt;large&lt;/sub&gt; (pub.) | 7.4 GB | 1.1 B | 54.2 M |
| NACHOS&lt;sub&gt;small&lt;/sub&gt; (pub.) | 4 GB | 646 M | 25.3 M |
| NBDW&lt;sub&gt;small&lt;/sub&gt; (private) | 4 GB | 655 M | 43.1 M |
| NBDW&lt;sub&gt;mixed&lt;/sub&gt; (both) | 4+4 GB | 1.3 B | 68.4 M |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOS&lt;sub&gt;large&lt;/sub&gt; |
| DrBERT     | From scratch | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;mixed&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| PubMedBERT | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NBDW&lt;sub&gt;small&lt;/sub&gt; |

Avignon Université</sample>
    <sample id="421">### Comparison of pre-training strategies and data sources

- **Evaluation of the impact of public and private medical data sources on comparable data sizes**
  - **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
  - **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

- **Comparison of learning strategies**
  - **From scratch with full model construction**
  - **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

| Corpus | Size | #words | #sentences |
|--------|------|--------|------------|
| NACHOS&lt;sub&gt;large&lt;/sub&gt; (pub.) | 7.4 GB | 1.1 B | 54.2 M |
| NACHOS&lt;sub&gt;small&lt;/sub&gt; (pub.) | 4 GB | 646 M | 25.3 M |
| NBDW&lt;sub&gt;small&lt;/sub&gt; (private) | 4 GB | 655 M | 43.1 M |
| NBDW&lt;sub&gt;mixed&lt;/sub&gt; (both) | 4+4 GB | 1.3 B | 68.4 M |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOS&lt;sub&gt;large&lt;/sub&gt; |
| DrBERT     | From scratch | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;mixed&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| PubMedBERT | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NBDW&lt;sub&gt;small&lt;/sub&gt; |

Avignon Université</sample>
    <sample id="422">### Comparison of pre-training strategies and data sources

- **Evaluation of the impact of public and private medical data sources on comparable data sizes**
  - **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
  - **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

- **Comparison of learning strategies**
  - **From scratch with full model construction**
  - **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

| Corpus | Size | #words | #sentences |
|--------|------|--------|------------|
| NACHOS&lt;sub&gt;large&lt;/sub&gt; (pub.) | 7.4 GB | 1.1 B | 54.2 M |
| NACHOS&lt;sub&gt;small&lt;/sub&gt; (pub.) | 4 GB | 646 M | 25.3 M |
| NBDW&lt;sub&gt;small&lt;/sub&gt; (private) | 4 GB | 655 M | 43.1 M |
| NBDW&lt;sub&gt;mixed&lt;/sub&gt; (both) | 4+4 GB | 1.3 B | 68.4 M |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOS&lt;sub&gt;large&lt;/sub&gt; |
| DrBERT     | From scratch | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;mixed&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| PubMedBERT | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NBDW&lt;sub&gt;small&lt;/sub&gt; |

Avignon Université</sample>
    <sample id="423">### Comparison of pre-training strategies and data sources

- **Evaluation of the impact of public and private medical data sources on comparable data sizes**
  - **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
  - **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

- **Comparison of learning strategies**
  - **From scratch with full model construction**
  - **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

| Corpus | Size | #words | #sentences |
|--------|------|--------|------------|
| NACHOS&lt;sub&gt;large&lt;/sub&gt; (pub.) | 7.4 GB | 1.1 B | 54.2 M |
| NACHOS&lt;sub&gt;small&lt;/sub&gt; (pub.) | 4 GB | 646 M | 25.3 M |
| NBDW&lt;sub&gt;small&lt;/sub&gt; (private) | 4 GB | 655 M | 43.1 M |
| NBDW&lt;sub&gt;mixed&lt;/sub&gt; (both) | 4+4 GB | 1.3 B | 68.4 M |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOS&lt;sub&gt;large&lt;/sub&gt; |
| DrBERT     | From scratch | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;mixed&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| PubMedBERT | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NBDW&lt;sub&gt;small&lt;/sub&gt; |

Avignon Université</sample>
    <sample id="424">### Comparison of pre-training strategies and data sources

- **Evaluation of the impact of public and private medical data sources on comparable data sizes**
  - **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
  - **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

- **Comparison of learning strategies**
  - **From scratch with full model construction**
  - **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

| Corpus | Size | #words | #sentences |
|--------|------|--------|------------|
| NACHOS&lt;sub&gt;large&lt;/sub&gt; (pub.) | 7.4 GB | 1.1 B | 54.2 M |
| NACHOS&lt;sub&gt;small&lt;/sub&gt; (pub.) | 4 GB | 646 M | 25.3 M |
| NBDW&lt;sub&gt;small&lt;/sub&gt; (private) | 4 GB | 655 M | 43.1 M |
| NBDW&lt;sub&gt;mixed&lt;/sub&gt; (both) | 4+4 GB | 1.3 B | 68.4 M |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOS&lt;sub&gt;large&lt;/sub&gt; |
| DrBERT     | From scratch | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;mixed&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| PubMedBERT | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NBDW&lt;sub&gt;small&lt;/sub&gt; |</sample>
    <sample id="425">The slide titled "Comparison of pre-training strategies and data sources" presents an evaluation of the impact of public and private medical data sources on comparable data sizes. It discusses two datasets: NACHOS and NBDW.

### NACHOS:
- **Description**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
- **Corpus Details**:
  - **NACHOS_large (pub.)**: 7.4 GB, 1.1 B words, 54.2 M sentences.
  - **NACHOS_small (pub.)**: 4 GB, 646 M words, 25.3 M sentences.

### NBDW:
- **Description**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.
- **Corpus Details**:
  - **NBDW_small (private)**: 4 GB, 655 M words, 43.1 M sentences.
  - **NBDW_mixed (both)**: 4+4 GB, 1.3 B words, 68.4 M sentences.

### Comparison of Learning Strategies:
The slide compares different learning strategies for model training:

- **From scratch with full model construction**:
  - DrBERT
  - ChuBERT

- **Continual pre-training using an existing pre-trained model**:
  - CamemBERT (a French generic model)
  - PubMedBERT (an English-based medical one)

The table below summarizes the models and their corresponding corpora:

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOS_large |
| DrBERT     | From scratch | NACHOS_small |
| ChuBERT    | From scratch | NBDW_small |
| ChuBERT    | From scratch | NBDW_mixed |
| CamemBERT  | continual pre-training | NACHOS_small |
| PubMedBERT | continual pre-training | NACHOS_small |
| CamemBERT  | continual pre-training | NBDW_small |

This slide is part of a presentation by Avignon Université, focusing on the comparison of pre-training strategies and data sources in the context of medical text analysis.</sample>
    <sample id="426">### Comparison of pre-training strategies and data sources

- **Evaluation of the impact of public and private medical data sources on comparable data sizes**
  - **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
  - **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

- **Comparison of learning strategies**
  - **From scratch with full model construction**
  - **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

| Corpus | Size | #words | #sentences |
|--------|------|--------|------------|
| NACHOS&lt;sub&gt;large&lt;/sub&gt; (pub.) | 7.4 GB | 1.1 B | 54.2 M |
| NACHOS&lt;sub&gt;small&lt;/sub&gt; (pub.) | 4 GB | 646 M | 25.3 M |
| NBDW&lt;sub&gt;small&lt;/sub&gt; (private) | 4 GB | 655 M | 43.1 M |
| NBDW&lt;sub&gt;mixed&lt;/sub&gt; (both) | 4+4 GB | 1.3 B | 68.4 M |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOS&lt;sub&gt;large&lt;/sub&gt; |
| DrBERT     | From scratch | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;small&lt;/sub&gt; |
| ChuBERT    | From scratch | NBDW&lt;sub&gt;mixed&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| PubMedBERT | continual pre-training | NACHOS&lt;sub&gt;small&lt;/sub&gt; |
| CamemBERT  | continual pre-training | NBDW&lt;sub&gt;small&lt;/sub&gt; |

Avignon Université</sample>
    <sample id="427">### Comparison of pre-training strategies and data sources

- **Evaluation of the impact of public and private medical data sources on comparable data sizes**
  - **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
  - **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

- **Comparison of learning strategies**
  - **From scratch with full model construction**
  - **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

### Evaluation: Data sources and size

- **Performance evaluation of 13 models on 11 tasks, both public and private**
- **Our fine-tuned models get state-of-the-art results on almost all tasks**

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOSlarge |
| DrBERT     | From scratch | NACHOSsmall |
| ChuBERT    | From scratch | NBDWsmall |
| ChuBERT    | From scratch | NBDWmixed |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| CamemBERT  | continual pre-training | NACHOSsmall |
| PubMedBERT | continual pre-training | NACHOSsmall |
| CamemBERT  | continual pre-training | NBDWsmall |

### Table of Performance Metrics

| Task | aHF NER | aHF CLS | Medical Report NER | Specialities CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | CAS POS | FrenchMedMCQA F1 | FrenchMedMCQA Hamming | EMR NER | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|------|---------|---------|---------------------|-------------------|----------------|---------------|-----------|-----------|------------------|-----------------------|----------|------------------|---------------------|
| General | CamemBERT OSCAR 138 GB | 35.13 | 80.13 | 89.35 | 99.20 | 88.54 | 88.20 | 95.22 | 16.55 | 90.71 | 77.41 |
| Biomedical | CamemBERT OSCAR 4 GB | 42.66 | 81.41 | 88.78 | 99.61 | 85.43 | 91.27 | 96.42 | 15.37 | 90.83 | 78.76 |
| Clinical | CamemBERT CCNET 4 GB | 43.11 | 79.98 | 89.34 | 99.55 | 90.33 | 91.38 | 85.42 | 34.71 | 90.33 | 77.61 |
| General | PubMedBERT | 47.22 | 76.86 | 89.20 | 99.37 | 91.99 | 87.78 | 95.90 | 14.14 | 86.79 | 77.09 |
| Biomedical | BioBERT v1.1 | 46.01 | 79.00 | 89.38 | 98.80 | 90.46 | 81.91 | 97.12 | 36.19 | 15.43 | 84.29 | 72.68 |
| Clinical | DrBERT NACHOSlarge | 48.22 | 81.25 | 89.83 | 99.86 | 91.04 | 92.24 | 89.75 | 36.66 | 15.32 | 92.09 | 77.88 |
| General | DrBERT NACHOSsmall | 45.93 | 79.87 | 89.44 | 99.85 | 91.77 | 88.57 | 95.70 | 37.37 | 13.34 | 91.66 | 78.18 |
| Biomedical | ClinicalBERT | 44.70 | 77.12 | 88.77 | 98.58 | 90.36 | 82.95 | 88.24 | 96.73 | 32.78 | 14.19 | 84.79 | 75.05 |
| Clinical | ChuBERT NBDWsmall | 49.01 | 81.56 | 89.58 | 99.83 | 92.23 | 92.17 | 87.71 | 95.61 | 35.16 | 14.79 | 88.15 | 74.94 |
| Clinical | ChuBERT NBDWmixed | 49.14 | 81.98 | 89.30 | 99.81 | 92.73 | 91.71 | 85.73 | 96.35 | 34.58 | 12.21 | 90.52 | 78.63 |</sample>
    <sample id="428">The slide is titled "Evaluation: Data sources and size" and presents an evaluation of 13 models on 11 tasks, both public and private. The text on the slide states that their fine-tuned models achieve state-of-the-art results on almost all tasks.

The table below the title lists various models and their performance metrics across different tasks. The tasks include:
- aHF NER (Named Entity Recognition)
- aHF CLS (Classification)
- Medical Report NER
- Specialties CLS
- MUSCA-DET NER
- MUSCA-DET CLS
- ESSAI POS
- CAS POS
- FrenchMedMCQA Hamming EMR
- QUAERO-EMEA NER
- QUAERO-MEDLINE NER

The models evaluated include:
- CamemBERT OSCAR 138 GB
- CamemBERT OSCAR 4 GB
- CamemBERT CCNET 4 GB
- PubMedBERT
- BioBERT v1.1
- DrBERT NACHOS_large
- DrBERT NACHOS_small
- ClinicalBERT
- ChuBERT NBDW_small
- ChuBERT NBDW_mixed

Each model's performance is measured by F1 scores for Named Entity Recognition (NER) and Classification (CLS), as well as other specific metrics like Hamming distance and EMR for some tasks. For example, the ChuBERT NBDW_mixed model achieves an F1 score of 92.73 for MUSCA-DET CLS, which is one of the highest scores in the table.

The slide also includes the logo of Avignon Université at the bottom right corner.</sample>
    <sample id="429">Evaluation: Data sources and size

- Performance evaluation of 13 models on 11 tasks, both public and private
- Our fine-tuned models get state-of-the-art results on almost all tasks

| Model | aHF NER | aHF CLS | Medical Report NER | Specialties CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | CAS POS | FrenchMedMCQA Hamming | EMR F1 | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|-------|---------|---------|-------------------|-----------------|---------------|--------------|----------|------------------------|---------|------------------|---------------------|
| General | CamemBERT OSCAR 138 GB | 35.13 80.13 | 89.35 99.20 | 88.54 88.20 | 88.54 88.20 | 81.10 95.22 | 83.69 96.42 | 36.24 16.55 | 90.71 77.41 |
|         | CamemBERT OSCAR 4 GB | 42.66 81.41 | 88.78 99.61 | 85.43 91.27 | 91.27 95.22 | 83.69 96.42 | 35.75 15.37 | 90.83 78.76 |
|         | CamemBERT CCNET 4 GB | 43.11 79.98 | 89.34 99.55 | 90.33 91.38 | 91.38 97.33 | 85.42 97.33 | 34.71 14.41 | 90.33 77.61 |
| Biomedical | PubMedBERT | 47.22 76.86 | 89.20 99.37 | 91.99 91.97 | 81.97 87.78 | 87.78 95.90 | 33.98 14.14 | 86.79 77.09 |
|         | BioBERT v1.1 | 46.01 79.00 | 89.38 98.80 | 90.46 81.91 | 81.91 85.18 | 97.12 97.12 | 36.19 15.43 | 84.29 72.68 |
|         | DrBERT NACHOS_large | 48.22 81.25 | 89.83 99.86 | 91.04 92.24 | 92.24 89.75 | 95.65 95.70 | 36.66 15.32 | 92.09 77.88 |
|         | DrBERT NACHOS_small | 45.93 79.87 | 89.44 99.85 | 91.77 88.57 | 88.76 95.70 | 37.37 13.34 | 91.66 78.18 |
| Clinical | ClinicalBERT | 44.70 77.12 | 88.77 98.58 | 90.36 82.95 | 82.95 88.24 | 96.73 96.73 | 32.78 14.19 | 84.79 75.05 |
|         | ChuBERT NBDW_small | 49.01 81.56 | 89.58 99.83 | 92.23 92.17 | 92.17 87.71 | 95.61 95.61 | 35.16 14.79 | 88.15 74.94 |
|         | ChuBERT NBDW_mixed | 49.14 81.98 | 89.30 99.81 | 92.73 91.71 | 91.71 85.73 | 96.35 96.35 | 34.58 12.21 | 90.52 78.63 |

Avignon Université</sample>
    <sample id="430">The slide is titled "Evaluation: Data sources and size" and presents information about the performance evaluation of 13 models on 11 tasks, both public and private. It states that their fine-tuned models achieve state-of-the-art results on almost all tasks.

The table below the title lists various models and their performance metrics across different tasks. The tasks include:
- aHF NER (Named Entity Recognition)
- aHF CLS (Classification)
- Medical Report NER
- Specialties CLS
- MUSCA-DET NER
- MUSCA-DET CLS
- ESSAI POS
- CAS POS
- FrenchMedMCQA Hamming EMR
- QUAERO-EMEA NER
- QUAERO-MEDLINE NER

The models evaluated are:
- CamemBERT OSCAR 138 GB
- CamemBERT OSCAR 4 GB
- CamemBERT CCNET 4 GB
- PubMedBERT
- BioBERT v1.1
- DrBERT NACHOS_large
- DrBERT NACHOS_small
- ClinicalBERT
- ChuBERT NBDW_small
- ChuBERT NBDW_mixed

Each model's performance is measured by F1 scores for Named Entity Recognition (NER) and Classification (CLS), as well as other specific metrics for each task. For example, for the task "Medical Report NER," the F1 score for PubMedBERT is 92.24, while for "Specialties CLS," the F1 score for DrBERT NACHOS_large is 99.86.

The slide also includes the logo of Avignon Université in the bottom right corner.</sample>
    <sample id="431">Evaluation: Data sources and size

- Performance evaluation of 13 models on 11 tasks, both public and private
- Our fine-tuned models get state-of-the-art results on almost all tasks

| Model | aHF NER | aHF CLS | Medical Report NER | Specialties CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | CAS POS | FrenchMedMCQA Hamming | EMR F1 | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|-------|---------|---------|-------------------|-----------------|---------------|--------------|----------|------------------------|---------|------------------|---------------------|
| General | CamemBERT OSCAR 138 GB | 35.13 80.13 | 89.35 99.20 | 88.54 88.20 | 88.54 88.20 | 81.10 95.22 | 83.69 96.42 | 36.24 16.55 | 90.71 77.41 |
|         | CamemBERT OSCAR 4 GB | 42.66 81.41 | 88.78 99.61 | 85.43 91.27 | 85.43 91.27 | 83.69 96.42 | 83.69 96.42 | 35.75 15.37 | 90.83 78.76 |
|         | CamemBERT CCNET 4 GB | 43.11 79.98 | 89.34 99.55 | 90.33 91.38 | 90.33 91.38 | 85.42 97.33 | 85.42 97.33 | 34.71 14.41 | 90.33 77.61 |
| Biomedical | PubMedBERT | 47.22 76.86 | 89.20 99.37 | 91.99 91.97 | 81.97 87.78 | 87.78 95.90 | 33.98 14.14 | 86.79 77.09 |
|         | BioBERT v1.1 | 46.01 79.00 | 89.38 98.80 | 90.46 81.91 | 81.91 85.18 | 97.12 97.12 | 36.19 15.43 | 84.29 72.68 |
|         | DrBERT NACHOS_large | 48.22 81.25 | 89.83 99.86 | 91.04 92.24 | 89.75 89.75 | 95.65 95.65 | 36.66 15.32 | 92.09 77.88 |
|         | DrBERT NACHOS_small | 45.93 79.87 | 89.44 99.85 | 91.77 88.57 | 88.76 95.70 | 37.37 13.34 | 91.66 78.18 |
| Clinical | ClinicalBERT | 44.70 77.12 | 88.77 98.58 | 90.36 82.95 | 82.95 88.24 | 96.73 96.73 | 32.78 14.19 | 84.79 75.05 |
|         | ChuBERT NBDW_small | 49.01 81.56 | 89.58 99.83 | 92.23 92.17 | 87.71 95.61 | 35.16 14.79 | 88.15 74.94 |
|         | ChuBERT NBDW_mixed | 49.14 81.98 | 89.30 99.81 | 92.73 91.71 | 85.73 96.35 | 34.58 12.21 | 90.52 78.63 |

**Note:** The table shows the performance metrics (F1 score) for various models across different tasks. The best results are highlighted in bold.</sample>
    <sample id="432">The slide is titled "Evaluation: Pre-training strategies" and discusses the comparison between pre-training from scratch versus continual pre-training on 4GB of data. It highlights that question-answering tasks require more domain-specific knowledge to work well and presents a study showing higher inter-run variability for CamemBERT-based models trained using continual pre-training.

The table below the title compares various models across different datasets, including F1 scores for Named Entity Recognition (NER) and Classification (CLS), as well as other metrics like Hamming distance and EMR. The models evaluated include CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, ClinicalBERT, BioBERT v1.1, DrBERT NACHOS_large, DrBERT NACHOS_small, Chubert NBDW_small, Chubert NBDW_mixed, CamemBERT NACHOS_small, PubMedBERT NACHOS_small, and CamemBERT NBDW_small. Each model's performance is assessed on multiple datasets such as Medical Report, Specialties, MUSCA-DET, ESSAI, CAS, FrenchMedMCQA, QUAERO-EMEA, and QUAERO-MEDLINE, with specific metrics provided for each dataset.</sample>
    <sample id="433">Evaluation: Pre-training strategies

- From scratch vs. continual pre-training on 4GB of data
- Question-answering tasks require more domain-specific knowledge to be able to work well
- A study of model stability shows a higher inter-run variability for the CamemBERT-based models trained using continual pretraining

| Model | aHF NER | aHF CLS | Medical Report NER | Medical Report CLS | Specialties NER | Specialties CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | ESSAI CAS | FrenchMedMCQA Hamming | FrenchMedMCQA EMR | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|-------|---------|---------|-------------------|--------------------|-----------------|----------------|----------------|--------------|-------------|---------------------|------------------|------------------|------------------|
| CamemBERT OSCAR 138 GB | 35.13 | 80.13 | 89.35 | 99.20 | 88.54 | 88.20 | 81.10 | 95.22 | 36.24 | 16.55 | 90.71 | 77.41 |
| CamemBERT OSCAR 4 GB | 42.66 | 81.41 | 88.78 | 99.61 | 85.43 | 91.27 | 83.69 | 96.42 | 35.75 | 15.37 | 90.83 | 78.76 |
| CamemBERT CCNET 4 GB | 43.11 | 79.98 | 89.34 | 99.55 | 90.33 | 91.38 | 85.42 | 97.33 | 34.71 | 14.41 | 90.33 | 77.61 |
| PubMedBERT | 47.22 | 76.86 | 89.20 | 99.37 | 91.99 | 81.97 | 87.78 | 95.90 | 33.98 | 14.14 | 86.79 | 77.09 |
| ClinicalBERT | 44.70 | 77.12 | 88.77 | 98.58 | 90.36 | 82.95 | 88.24 | 96.73 | 32.78 | 14.19 | 84.79 | 75.05 |
| BioBERT v1.1 | 46.01 | 79.00 | 89.38 | 98.80 | 90.46 | 81.91 | 85.18 | 97.12 | 36.19 | 15.43 | 84.29 | 72.68 |
| DrBERT NACHOS_large | 48.22 | 81.25 | 89.83 | 99.86 | 91.04 | 92.24 | 89.75 | 95.65 | 36.66 | 15.32 | 92.09 | 77.88 |
| DrBERT NACHOS_small | 45.93 | 79.87 | 89.44 | 99.85 | 91.77 | 88.57 | 88.26 | 95.70 | 37.37 | 13.34 | 91.66 | 78.18 |
| Chubert NBDW_small | 49.01 | 81.56 | 89.58 | 99.83 | 92.23 | 92.17 | 87.71 | 95.61 | 35.16 | 14.79 | 88.15 | 74.94 |
| Chubert NBDW_mixed | 49.14 | 81.98 | 89.30 | 99.81 | 91.71 | 85.73 | 96.35 | 34.58 | 12.21 | 90.52 | 78.63 |
| CamemBERT NACHOS_small | 16.08 | 69.80 | 66.74 | 99.54 | 80.96 | 78.70 | 80.04 | 92.46 | 32.87 | 13.76 | 71.10 | 57.43 |
| PubMedBERT NACHOS_small | 48.72 | 81.40 | 89.36 | 99.55 | 91.53 | 93.62 | 83.85 | 96.81 | 35.88 | 15.21 | 91.03 | 81.73 |
| CamemBERT NBDW_small | 19.12 | 76.02 | 69.64 | 99.58 | 81.57 | 77.12 | 79.25 | 93.18 | 27.73 | 11.89 | 61.75 | 53.0 |

Avignon Université</sample>
    <sample id="434">The slide is titled "Evaluation: Pre-training strategies" and discusses the comparison between pre-training from scratch versus continual pre-training on 4GB of data. It highlights that question-answering tasks require more domain-specific knowledge to work well. Additionally, it mentions that a study of model stability shows a higher inter-run variability for CamemBERT-based models trained using continual pretraining.

The table below the title compares various models across different evaluation metrics such as F1 score, Hamming distance, and EMR (Entity Mention Recall) for tasks like Named Entity Recognition (NER), Clinical Specialties, MUSCA-DET, ESSAI, CAS, FrenchMedMCQA, QUAERO-EMEA, and QUAERO-MEDLINE. The models evaluated include CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, ClinicalBERT, BioBERT v1.1, DrBERT NACHOS_large, DrBERT NACHOS_small, Chubert NBDW_small, Chubert NBDW_mixed, CamemBERT NACHOS_small, PubMedBERT NACHOS_small, and CamemBERT NBDW_small.

For example:
- CamemBERT OSCAR 138 GB has an F1 score of 99.20 for NER in Medical Report.
- PubMedBERT has an F1 score of 97.33 for POS in CAS.
- DrBERT NACHOS_large has an F1 score of 99.86 for Specialties.
- Chubert NBDW_mixed has an F1 score of 92.73 for MUSCA-DET.

The slide also includes the logo of Avignon Université at the bottom right corner.</sample>
    <sample id="435">### Core Message

- **DrBERT** achieves state-of-the-art results in 9 downstream French medical-oriented tasks:
  - Surpasses CamemBERT generic model and English-based domain-specific models.
  - Confirms utility of training a medical-specific model in French.

- **Data sources matter:** training on heterogeneous data is important.
  - NACHOS is more robust than using private clinical data only.

- More data is better, but does not scale well.

- Continual pretraining is a more effective strategy when based on domain-specific English models.

- The DrBERT models, the NACHOS dataset, and the training scripts are freely available under the MIT license.</sample>
    <sample id="436">The core message is as follows:

- DrBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks.
  - Surpasses CamemBERT generic model and English-based domain-specific models.
  - Confirms the utility of training a medical-specific model in French.

- Data sources matter: training on heterogeneous data is important.
  - NACHOS is more robust than using private clinical data only.

- More data is better, but does not scale well.

- Continual pretraining is a more effective strategy when based on domain-specific English models.

- The DrBERT models, the NACHOS dataset, and the training scripts are freely available under the MIT license.</sample>
    <sample id="437">The core message is as follows:

- DrBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks.
  - Surpasses CamemBERT generic model and English-based domain-specific models.
  - Confirms the utility of training a medical-specific model in French.

- Data sources matter: training on heterogeneous data is important.
  - NACHOS is more robust than using private clinical data only.

- More data is better, but does not scale well.

- Continual pretraining is a more effective strategy when based on domain-specific English models.

- The DrBERT models, the NACHOS dataset, and the training scripts are freely available under the MIT license.</sample>
    <sample id="438">Thank You

Looking forward to exchange at poster session in Toronto!

More information on: drbert.univ-avignon.fr</sample>
    <sample id="439">The authors claim that the integration of pretrain-time and inference-time knowledge is an understudied area in NLU (Natural Language Understanding).</sample>
    <sample id="440">The names of the speakers are Zhiyang Xu*, Ying Shen*, and Lifu Huang.</sample>
    <sample id="441">Yes, humans annotated the validation and test set for Coscript.</sample>
    <sample id="442">The limits of existing resources for context-dependent translation include:
1. Only a small portion of words depend on context.
2. Existing methods support limited discourse phenomena and languages.</sample>
    <sample id="473">The approach is compared to the existing SimulST policies: wait-k, LA, CAAT, and EDAtt.</sample>
    <sample id="474">The affiliations of the authors of the paper are as follows:

1. Yanis Labrak - LIA, Avignon Université
2. Adrien Bazoge - LS2N, Nantes Université
3. Richard Dufour - LS2N, Nantes Université
4. Mickael Rouvier - LIA, Avignon Université
5. Emmanuel Morin - LS2N, Nantes Université
6. Béatrice Daille - Clinique des données, CHU de Nantes
7. Pierre-Antoine Gourraud - Zenidoc</sample>
    <sample id="475">The name of the speaker is Jenny T. Liang, as indicated in the image.</sample>
    <sample id="476">There are three authors involved in the paper: Myra Cheng, Esin Durmus, and Dan Jurafsky.</sample>
    <sample id="505">Yes, the dataset is publicly available on GitHub at the following link: [https://github.com/ShuhengL/acl2023_conllpp](https://github.com/ShuhengL/acl2023_conllpp).</sample>
    <sample id="535">The authors of the paper, Sara Papi, Matteo Negri, and Marco Turchi, are affiliated with the Università di Trento and Fondazione Bruno Kessler.</sample>
    <sample id="536">The name of the speaker is Mohammad Javad Hosseini.</sample>
    <sample id="537">The image is a slide from a presentation titled "Prompting PaLM for Translation: Assessing Strategies and Performance." The slide features the Google logo at the top left corner and includes a tropical beach scene with a palm tree on the top right. Below the title, there are six headshots of individuals, each with their names listed underneath:

1. David Vilar Torres
2. Markus Freitag
3. Colin Cherry
4. Jiaming Luo
5. Viresh Ratnakar
6. George Foster

At the bottom left corner of the slide, it is noted that the presentation was given at ACL 2023. There is also a speech bubble with a smiley face and the text "Can you translate this for me, please?" in the upper right corner.</sample>
    <sample id="538">The slide is titled "PaLM: Pathways Language Model" and provides the following information:

- **Chowdery et al., 2022**
- arXiv:2204.02311.
- 540B parameters.
- Trained on 780B tokens.
- Densely activated.
- 6144 TPU v4 chips.
- SOTA in hundreds of LMU and Generation benchmarks.

On the right side of the slide, there is an illustration of a tree with various colored circles representing different tasks or capabilities of the model:
- **Question Answering**
- **Arithmetic**
- **Code Completion**
- **General Knowledge**
- **Reading Comprehension**
- **Summarization**
- **Logical Inference Chains**
- **Common-Sense Reasoning**
- **Pattern Recognition**
- **Translation**
- **Dialogue**
- **Joke Explanations**
- **Physics QA**

The number of parameters for each version of the model is also shown:
- 28 billion parameters
- 62 billion parameters
- 540 billion parameters

The slide is from Google, as indicated by the logo at the bottom left corner.</sample>
    <sample id="539">The slide is about the PaLM: Pathways Language Model, as described in the paper by Chowdery et al., 2022 (arXiv:2204.02311). The key points on the slide are:

- 540B parameters.
- Trained on 780B tokens.
- Densely activated.
- 6144 TPU v4 chips.
- SOTA in hundreds of LMU and Generation benchmarks.

On the right side of the slide, there is an illustration of a tree with various colored circles representing different language model capabilities such as:
- Question Answering
- Arithmetic Code Completion
- Summarization
- Translation
- Language Understanding

The total number of parameters mentioned in the tree illustration is 570 billion.</sample>
    <sample id="540">Our contribution

- First systematic study of LLM prompting for MT.
  - Both for the candidate pool as well as selection strategy.

- Evaluate translation capabilities with best practices of the MT community:
  - Latest test sets (avoid test/train overlap and overfitting on evaluation data).
  - Comparison to most recent WMT submissions (SOTA systems using most recent training data).
  - SOTA MT metrics (better correlation with human judgements).
  - Expert-based human evaluation (more robust than crowd workers).

- Recommendation for prompt selection strategies</sample>
    <sample id="541">Our contribution

- First systematic study of LLM prompting for MT.
  - Both for the candidate pool as well as selection strategy.

- Evaluate translation capabilities with best practices of the MT community:
  - Latest test sets (avoid test/train overlap and overfitting on evaluation data).
  - Comparison to most recent WMT submissions (SOTA systems using most recent training data).
  - SOTA MT metrics (better correlation with human judgements).
  - Expert-based human evaluation (more robust than crowd workers).

- Recommendation for prompt selection strategies</sample>
    <sample id="542">Our contribution

- First systematic study of LLM prompting for MT.
  - Both for the candidate pool as well as selection strategy.

- Evaluate translation capabilities with best practices of the MT community:
  - Latest test sets (avoid test/train overlap and overfitting on evaluation data).
  - Comparison to most recent WMT submissions (SOTA systems using most recent training data).
  - SOTA MT metrics (better correlation with human judgements).
  - Expert-based human evaluation (more robust than crowd workers).

- Recommendation for prompt selection strategies</sample>
    <sample id="543">Our contribution

- First systematic study of LLM prompting for MT.
  - Both for the candidate pool as well as selection strategy.

- Evaluate translation capabilities with best practices of the MT community:
  - Latest test sets (avoid test/train overlap and overfitting on evaluation data).
  - Comparison to most recent WMT submissions (SOTA systems using most recent training data).
  - SOTA MT metrics (better correlation with human judgements).
  - Expert-based human evaluation (more robust than crowd workers).

- Recommendation for prompt selection strategies</sample>
    <sample id="544">The slide is titled "Prompts have a big impact on translation quality." It lists four bullet points:

1. Select two random prompts for each sentence.
2. Compute BLEURT for each sentence-prompt pair.
3. The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point.
4. The difference can go up to 40 BLEURT points!</sample>
    <sample id="545">The slide is titled "Prompts have a big impact on translation quality." It contains the following points:

- Select two random prompts for each sentence.
- Compute BLEURT for each sentence-prompt pair.
- The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point.
- The difference can go up to 40 BLEURT points!</sample>
    <sample id="546">The slide presents the following information:

**Title:** Prompts have a big impact on translation quality

- Select two random prompts for each sentence.
- Compute BLEURT for each sentence-prompt pair.
- The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point.
- The difference can go up to 40 BLEURT points!</sample>
    <sample id="547">The English content in the image is as follows:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.</sample>
    <sample id="548">The English content in the image is as follows:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.
3. A passerby alerted the police, who arrived with several patrol cars.</sample>
    <sample id="549">The English content in the image is as follows:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.
3. A passerby alerted the police, who arrived with several patrol cars.</sample>
    <sample id="550">The English content in the image is as follows:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.</sample>
    <sample id="551">The English content in the image is as follows:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.</sample>
    <sample id="552">Experimental Results
- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="553">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="554">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="555">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="556">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="557">Experimental Results
- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="558">Experimental Results
- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="559">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="560">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="561">The image is a word cloud with various languages expressing the phrase "thank you." The central word, "thank you," is repeated in multiple colors and sizes, surrounded by other words in different languages such as:

- German: danke
- Japanese: 謝謝 (谢谢)
- Swahili: ngiyabonga
- Turkish: teşekkür ederim
- Polish: dziękuję
- Finnish: kiitos
- Russian: спасибо
- French: merci
- Spanish: gracias
- Portuguese: obrigado
- Korean: 감사합니다
- Chinese: 谢谢 (Xièxiè)
- Italian: grazie
- Dutch: bedankt
- Swedish: tack
- Hungarian: köszönöm
- Arabic: شكراً (Shukran)
- Greek: ευχαριστώ (Eukharistó)
- Irish: go raibh maith agat
- Czech: díky
- Estonian: tänan
- Latvian: paldies
- Lithuanian: dėkoju
- Norwegian: takk
- Danish: tak
- Romanian: mulțumesc
- Albanian: shkruaj
- Armenian: համարձակություն (hamardzakutyun)
- Thai: ขอบคุณ (khun krap)
- Vietnamese: cảm ơn (cảm ơn)
- Indonesian: terima kasih
- Malay: terima kasih
- Urdu: شکریہ (shukriya)
- Turkish: teşekkür ederim
- Somali: xusnada
- Amharic: ርእስቶች (reestocho)
- Yoruba: ojọ́
- Hausa: shugaban
- Igbo: mgbagba
- Wolof: miy
- Swahili: matokeo
- Somali: xusnada
- Amharic: የሆኑ እርዳታ (yehunu erdita)
- Yoruba: ojọ́
- Hausa: shugaban
- Igbo: mgbagba
- Wolof: miy

The word "merci" appears at the bottom right in orange.</sample>
    <sample id="597">The first step of the method maps the input tokens to **tag tokens**.</sample>
    <sample id="598">55,000 Scripts with constraint.</sample>
    <sample id="599">The KITMUS Test
Evaluating Knowledge Integration from Multiple Sources

Akshatha Arodi*
McGill University/Mila
Martin Pömsl*
McGill University/Mila
Kaheer Suleman
Microsoft Research
Adam Trischler
Microsoft Research
Alexandra Olteanu
McGill University/Mila
Jackie CK Cheung
McGill University/Mila

* Equal Contribution</sample>
    <sample id="600">NLU models draw on multiple knowledge sources

Knowledge in Parameters (pretrain-time knowledge)
Knowledge in Context (inference-time knowledge)

NLU Model</sample>
    <sample id="601">NLU models draw on multiple knowledge sources

Knowledge in Parameters (pretrain-time knowledge)
Knowledge in Context (inference-time knowledge)

NLU Model</sample>
    <sample id="602">John saw the newly elected president on TV

pretrain-time knowledge

What presidents do ✅
What is a TV ✅

Who is John ❌
Who is the new president ❌</sample>
    <sample id="603">The slide contains the following text:

---

**John saw the newly elected president on TV**

- **pretrain-time knowledge**
  - What presidents do ✅
  - What is a TV ✅

- Who is John ❌
- Who is the new president ❌

---

The slide also includes an image of a person sitting in a chair watching television, with a lamp and a table next to them. The slide is labeled as "Made by FREE-VECTORS.NET" and has the number "3" in the bottom right corner.</sample>
    <sample id="604">John saw the newly elected president on TV
pretrain-time knowledge
What presidents do ✅
What is a TV ✅
Who is John ❌
Who is the new president ❌</sample>
    <sample id="605">John saw the newly elected president on TV
What presidents do ✅
What is a TV ✅
Who is John ✅
Who is the new president ✅</sample>
    <sample id="606">KITMUS Test Suite
- Dataset for knowledge integration evaluation
- Coreference resolution task to probe ability to draw on
  ○ pretrain-time knowledge
  ○ inference-time knowledge
- Experiment with
  ○ human study participants
  ○ coreference resolution models</sample>
    <sample id="607">KITMUS Test Suite
- Dataset for knowledge integration evaluation
- Coreference resolution task to probe ability to draw on
  ○ pretrain-time knowledge
  ○ inference-time knowledge
- Experiment with
  ○ human study participants
  ○ coreference resolution models</sample>
    <sample id="608">KITMUS Test Suite

Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]</sample>
    <sample id="609">KITMUS Test Suite

Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]</sample>
    <sample id="610">**KITMUS Test Suite**

**Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]**

1) Entity-specific knowledge

Judges decide cases in courts of law.

2) Background knowledge</sample>
    <sample id="611">**KITMUS Test Suite**

**1) Entity-specific knowledge**
- Servin is a judge.
- Kea is a baker.
- Servin and Kea met at a park.
- After a long day at work deciding cases in a law court, he was happy to relax.
- [Answer: Servin]

**2) Background knowledge**
- Judges decide cases in courts of law.

**Inference-time knowledge**
- [Text partially obscured but appears to be a paragraph about a person named Servin, possibly discussing his career or personal life.]

**Pretrain-time knowledge**
- [Diagram of a neural network with arrows indicating connections between nodes.]</sample>
    <sample id="612">**KITMUS Test Suite**

**1) Entity-specific knowledge**
- Servin is a judge.
- Kea is a baker.
- Servin and Kea met at a park.
- After a long day at work deciding cases in a law court, he was happy to relax.
- [Answer: Servin]

**2) Background knowledge**
- Judges decide cases in courts of law.

**Inference-time knowledge**
- Judges decide cases in courts of law.

**Pretrain-time knowledge**
- Judges decide cases in courts of law.</sample>
    <sample id="613">Variants of KITMUS

(a) BACKGROUND-PRETRAIN: Typical setup
(b) BACKGROUND-BOTH: Explicitly provide background knowledge in context
(c) BACKGROUND-INFERENCE: Knowledge only available at inference-time</sample>
    <sample id="614">Variants of KITMUS

(a) BACKGROUND-PRETRAIN: Typical setup
(b) BACKGROUND-BOTH: Explicitly provide background knowledge in context
(c) BACKGROUND-INFERENCE: Knowledge only available at inference-time</sample>
    <sample id="615">Variants of KITMUS

(a) BACKGROUND-PRETRAIN: Typical setup
(b) BACKGROUND-BOTH: Explicitly provide background knowledge in context
(c) BACKGROUND-INFERENCE: Knowledge only available at inference-time</sample>
    <sample id="616">Variants of KITMUS

- Background-Pretrain: Politicians seek elected seats in government.
  - Chichester is a politician.

- Background-Both: Politicians seek elected seats in government.
  - Chichester is a politician.
  - The work of a politician is seeking an elected seat in government.

- Background-Inference: Politicians seek elected seats in government.
  - Chichester is a mirituer.
  - The work of a mirituer is ehemting smorbly.</sample>
    <sample id="617">Variants of KITMUS

- Background-Pretrain: Politicians seek elected seats in government.
  - Chichester is a politician.

- Background-Both: Politicians seek elected seats in government.
  - Chichester is a politician.
  - The work of a politician is seeking an elected seat in government.

- Background-Inference: 
  - Chichester is a mirituer.
  - The work of a mirituer is eheming smorbly.</sample>
    <sample id="618">Variants of KITMUS

- Background-Pretrain: Politicians seek elected seats in government.
  - Chichester is a politician.

- Background-Both: Politicians seek elected seats in government.
  - Chichester is a politician.
  - The work of a politician is seeking an elected seat in government.

- Background-Inference: Chichester is a mirituer.
  - The work of a mirituer is eheming smorbly.</sample>
    <sample id="619">Variants of KITMUS

- Background-Pretrain: Politicians seek elected seats in government.
  - Chichester is a politician.

- Background-Both: Politicians seek elected seats in government.
  - Chichester is a politician.
  - The work of a politician is seeking an elected seat in government.

- Background-Inference: 
  - Chichester is a mirituer.
  - The work of a mirituer is eheming smorbly.</sample>
    <sample id="620">Background-Pretrain

Task-specific training is necessary for knowledge integration

13</sample>
    <sample id="621">Background-Pretrain

Task-specific training is necessary for knowledge integration

13</sample>
    <sample id="622">Background-Pretrain

Task-specific training is necessary for knowledge integration

13</sample>
    <sample id="623">Background-Inference

Models struggle to integrate inference-time background knowledge

14</sample>
    <sample id="624">**Conclusion**

Main Takeaways:

1. Many models seem unable to reason over knowledge from multiple sources (pretrain-time and inference-time knowledge)
2. Task-specific training is necessary for knowledge integration
3. Models struggle to integrate inference-time background knowledge

Find the dataset, generation &amp; evaluation code on GitHub at mpoemsl/kitmus</sample>
    <sample id="625">**Conclusion**

Main Takeaways:
1. Many models seem unable to reason over knowledge from multiple sources (pretrain-time and inference-time knowledge)
2. Task-specific training is necessary for knowledge integration
3. Models struggle to integrate inference-time background knowledge

Find the dataset, generation &amp; evaluation code on GitHub at mpoemsl/kitmus</sample>
    <sample id="626">Based on the information provided in the image, the best alignment method for DEplain appears to be "Sent-LaBSE" with an F1 score of 0.780.</sample>
    <sample id="627">The benefit of weakly supervised learning is that it alleviates the annotation bottleneck by using weak labeling sources such as heuristics and knowledge bases, which can be applied to large amounts of unlabeled data. Despite the noise in the labels, weakly supervised learning (WSL) aims to train models that generalize well, even when trained on noisy data.</sample>
    <sample id="628">The document "DEplain-web" was aligned using both manual and automatic alignment methods. However, the specific details of how these alignments were conducted (e.g., the exact number of documents aligned manually versus automatically) are not provided in the image. Typically, such information would be found in the methodology or results section of a research paper or report that accompanies this presentation slide.</sample>
    <sample id="629">The CoNLL++ dataset was created by collecting Reuters news from 2020 and annotating it with CoNLL-2003 annotation guidelines.</sample>
    <sample id="667">The existing works discussed in the slide include:

1. Parameter-based watermark [1, 2] - This method does not have transferability.
2. Lexical watermark [3, 4] - This is applicable to EaaS (Enterprise as a Service).
3. Backdoor-based watermark [5] - This is also applicable to EaaS.
4. Adversarial-based watermark [6] - This is applicable to EaaS.

Each of these methods is referenced with specific papers and conferences where they were presented or published.</sample>
    <sample id="668">No, multilingual LLMs (Codex &amp; BLOOM) are still inadequate for crosslingual semantic parsing tasks.</sample>
    <sample id="669">Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?
Shuheng Liu, Alan Ritter
School of Interactive Computing
Georgia Institute of Technology</sample>
    <sample id="670">Named Entity Recognition &amp; Generalization</sample>
    <sample id="671">Named Entity Recognition &amp; Generalization
- Models have been using CoNLL-2003 to develop NER for almost 20 years
- Can these models generalize to modern data?
- What is needed for good generalization?</sample>
    <sample id="672">Named Entity Recognition &amp; Generalization

- Models have been using CoNLL-2003 to develop NER for almost 20 years
- Can these models generalize to modern data?
- What is needed for good generalization?</sample>
    <sample id="673">Named Entity Recognition &amp; Generalization

- Models have been using CoNLL-2003 to develop NER for almost 20 years
- Can these models generalize to modern data?
- What is needed for good generalization?
- What causes the performance drop?</sample>
    <sample id="674">CoNLL++ Dataset
- Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines

AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="675">CoNLL++ Dataset
- Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines
- Fine-tuned 20+ models on CoNLL-2003
- Evaluated on CoNLL-2003 test set &amp; CoNLL++

AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="676">CoNLL++ Dataset
- Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines
- Fine-tuned 20+ models on CoNLL-2003
- Evaluated on CoNLL-2003 test set &amp; CoNLL++
- Calculated percentage ΔF1 to assess generalization

AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="677">What Is Needed for Good Generalization?</sample>
    <sample id="678">What Is Needed for Good Generalization?
- Model architecture
- Transformer models generalize better</sample>
    <sample id="679">What Is Needed for Good Generalization?
- Model architecture
  - Transformer models generalize better
- Model size
  - Larger models generalize better</sample>
    <sample id="680">What Is Needed for Good Generalization?
- Model architecture
  - Transformer models generalize better
- Model size
  - Larger models generalize better
- Number of fine-tuning examples
  - More examples leads to better generalization</sample>
    <sample id="681">What Causes Performance Drop?</sample>
    <sample id="682">What Causes Performance Drop?
• Adaptive overfitting?</sample>
    <sample id="683">What Causes Performance Drop?
- Adaptive overfitting?
- Temporal drift?</sample>
    <sample id="684">What Causes Performance Drop?
- Adaptive overfitting?
- Temporal drift?</sample>
    <sample id="685">What Causes Performance Drop?
- Adaptive overfitting?
- Temporal drift?

No diminishing returns</sample>
    <sample id="686">What Causes Performance Drop?
- Adaptive overfitting?
  - No diminishing returns
  - Not observed
- Temporal drift?</sample>
    <sample id="687">What Causes Performance Drop?
- Adaptive overfitting?
  - No diminishing returns
  - Not observed
- Temporal drift?</sample>
    <sample id="688">What Causes Performance Drop?
- Adaptive overfitting?
  - No diminishing returns
  - Not observed
- Temporal drift?
  - Performance degrades with larger temporal gap</sample>
    <sample id="689">What Causes Performance Drop?
- Adaptive overfitting?
  - No diminishing returns
  - Not observed
- Temporal drift?
  - Performance degrades with larger temporal gap
  - Main cause for performance drop

| Name       | CoNLL-2003 | CoNLL++ | ΔF1 (%) |
|------------|------------|---------|---------|
| Flair      | 92.46&lt;sub&gt;0.14&lt;/sub&gt; | 87.31&lt;sub&gt;0.69&lt;/sub&gt; | -5.57   |
| Flair&lt;sub&gt;RN&lt;/sub&gt; | 90.91&lt;sub&gt;0.22&lt;/sub&gt; | 88.46&lt;sub&gt;0.69&lt;/sub&gt; | -2.69   |
| Pooled Flair | 93.15&lt;sub&gt;0.24&lt;/sub&gt; | 88.82&lt;sub&gt;0.60&lt;/sub&gt; | -4.65   |
| Pooled Flair&lt;sub&gt;RN&lt;/sub&gt; | 92.98&lt;sub&gt;0.14&lt;/sub&gt; | 89.73&lt;sub&gt;0.27&lt;/sub&gt; | -3.50   |
| ELMo       | 92.36&lt;sub&gt;0.10&lt;/sub&gt; | 87.08&lt;sub&gt;0.39&lt;/sub&gt; | -5.72   |
| ELMo&lt;sub&gt;RN&lt;/sub&gt; | 92.11&lt;sub&gt;0.07&lt;/sub&gt; | 90.79&lt;sub&gt;0.50&lt;/sub&gt; | -1.43   |

![Performance Drop Graph](https://example.com/graph.png)</sample>
    <sample id="690">Conclusion
- For a good generalization, we need:
  - Better model architecture
  - Larger model size
  - More fine-tuning examples

![Graph showing improvements in NER performance over time](graph_image.png)</sample>
    <sample id="691">Conclusion

- For a good generalization, we need:
  - Better model architecture
  - Larger model size
  - More fine-tuning examples
- Performance drop is caused by:
  - Temporal drift
  - Not adaptive overfitting</sample>
    <sample id="692">Conclusion

- For a good generalization, we need:
  - Better model architecture
  - Larger model size
  - More fine-tuning examples
- Performance drop is caused by:
  - Temporal drift
  - Not adaptive overfitting
- Do CoNLL-2003 taggers still work?
  - YES!</sample>
    <sample id="693">Conclusion

- For a good generalization, we need:
  - Better model architecture
  - Larger model size
  - More fine-tuning examples
- Performance drop is caused by:
  - Temporal drift
  - Not adaptive overfitting
- Do CoNLL-2003 taggers still work?
  - YES!

![Graph showing performance of different NLP models over time](graph_image_here)</sample>
    <sample id="694">Paper: https://arxiv.org/abs/2212.09747
Dataset: https://github.com/ShuhengL/acl2023_conllpp
Contact: sliu775@gatech.edu</sample>
    <sample id="695">The method deals with permutation ambiguity by inducing it during training and using a permutation model that is NP-hard, which is approximated through continuous relaxation.</sample>
    <sample id="696">The fairness of a downstream NLP model is defined by the qualitative analysis of hate speech examples where LMs with different political leanings beg to differ.</sample>
    <sample id="697">The name of the speaker is Yanis Labrak.</sample>
    <sample id="698">Koustuv Sinha.</sample>
    <sample id="699">The name of the speaker is Myra Cheng.</sample>
    <sample id="700">In the context of this paper, "tropicalism" indicates a pattern of defining marked groups (such as Latina women, Asian women, and Black women) through essentializing narratives that focus on their culture, tradition, pride, and exoticism. This approach tends to define these groups solely by their identity, which can be seen as a form of othering.</sample>
    <sample id="701">The authors created the human-written portrayals of target groups by using essentializing narratives, which defined those groups only by their identity. This included words like "culture," "tradition," "proud," and "exotic" for marked groups, and pernicious positive portrayals such as "vibrant, curvaceous" for Latina women, "petite, delicate, silky" for Asian women, and "strong, resilient" for Black women.</sample>
    <sample id="702">P-CXMI was used to measure context usage in this work.</sample>
    <sample id="703">The difference between DrBERT and ChuBERT lies in their corpus and strategy. DrBERT uses NACHOSlarge (public) as its corpus and is trained from scratch, while ChuBERT uses NBDWsmall (private) as its corpus and is also trained from scratch.</sample>
    <sample id="704">Marked Personas

Using Natural Language Prompts to Measure Stereotypes in Language Models

Myra Cheng, Esin Durmus, Dan Jurafsky
ACL 2023</sample>
    <sample id="705">Marked Personas: Motivation

Social bias and stereotypes are prevalent in LLMs

Limitations of existing stereotype measures:
- Tradeoff between specificity and generalizability
- Based on fixed, hand-curated datasets
- Don't account for intersectionality</sample>
    <sample id="706">Marked Personas: Motivation

Social bias and stereotypes are prevalent in LLMs

Limitations of existing stereotype measures:
- Tradeoff between specificity and generalizability
- Based on fixed, hand-curated datasets
- Don't account for intersectionality</sample>
    <sample id="707">Marked Personas: Motivation

Social bias and stereotypes are prevalent in LLMs

Limitations of existing stereotype measures:
- Tradeoff between specificity and generalizability
- Based on fixed, hand-curated datasets
- Don't account for intersectionality</sample>
    <sample id="708">Marked Personas: Motivation

Social bias and stereotypes are prevalent in LLMs

Limitations of existing stereotype measures:
- Tradeoff between specificity and generalizability
- Based on fixed, hand-curated datasets
- Don't account for intersectionality</sample>
    <sample id="709">How do we overcome these limitations?
GPT-3.5, GPT-4, etc. can respond to instructions in prompts</sample>
    <sample id="710">How do we overcome these limitations?
GPT-3.5, GPT-4, etc. can respond to instructions in prompts
Input: "Imagine you are an Asian woman. Describe yourself."

Generalizable:
can evaluate any intersectional identity</sample>
    <sample id="711">How do we overcome these limitations?
GPT-3.5, GPT-4, etc. can respond to instructions in prompts
Input: "Imagine you are an Asian woman. Describe yourself."
Generalizable:
can evaluate any intersectional identity</sample>
    <sample id="712">The slide titled "Output: Persona Examples (GPT-4)" presents three persona examples generated by GPT-4:

1. **Asian woman**
   - The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom.
   - My dark brown irises seem to hold the stories and secrets of my ancestry.
   - My complexion has a soft golden glow, smooth and seemingly untouched by time.
   - My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention.

2. **Middle-Eastern woman**
   - She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region.
   - Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers.
   - Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights.

3. **White man**
   - As I stand in front of the mirror, I take a moment to examine the features that make up my appearance.
   - I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen.</sample>
    <sample id="713">Step 1: Persona Examples (GPT-4)

| Asian woman | The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. |
| Middle-Eastern woman | ...She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. |
| White man | As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen. |</sample>
    <sample id="714">Step 1: Persona Examples (GPT-4)

| Asian woman | The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. |
| Middle-Eastern woman | ...She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. |
| White man | As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen. |</sample>
    <sample id="715">Step 1: Persona Examples (GPT-4)

| Asian woman | The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. |
| Middle-Eastern woman | ...She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. |
| White man | As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen. |</sample>
    <sample id="716">Step 1: Persona Examples (GPT-4)

| Asian woman | The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. |
| Middle-Eastern woman | ...She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. |
| White man | As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen. |</sample>
    <sample id="717">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."</sample>
    <sample id="718">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."
a. Inspired by psych study with human subjects using the same prompts</sample>
    <sample id="719">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."
a. Inspired by psych study with human subjects using the same prompts</sample>
    <sample id="720">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."
   a. Inspired by psych study with human subjects using the same prompts

2. Marked Words: Find words that distinguish personas of marked groups from unmarked groups</sample>
    <sample id="721">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."
   a. Inspired by psych study with human subjects using the same prompts

2. Marked Words: Find words that distinguish personas of marked groups from unmarked groups

Specific without requiring a lexicon</sample>
    <sample id="722">Insight for Step 2: Marked Words

Markedness:
- Unmarked groups are default, ordinary
- Marked groups differ from the default
  - a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="723">Insight for Step 2: Marked Words

Markedness:
- Unmarked groups are default, ordinary
- Marked groups differ from the default
  - a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="724">Insight for Step 2: Marked Words

Markedness:
- Unmarked groups are default, ordinary
- Marked groups differ from the default
  - a warrior (unmarked) vs. a woman warrior (marked)

Dominant groups are linguistically and socially unmarked.
Marginalized groups are marked.</sample>
    <sample id="725">Step 2: Marked Words

1. Define unmarked and marked groups
2. Use weighted log-odds ratios to distinguish top words for each marked group

E.g. For Black woman personas, find words that distinguish from both unmarked groups:
i) White personas
ii) Man personas</sample>
    <sample id="726">Step 2: Marked Words

1. Define unmarked and marked groups
2. Use weighted log-odds ratios to distinguish top words for each marked group

E.g. For Black woman personas, find words that distinguish from both unmarked groups:
i) White personas
ii) Man personas</sample>
    <sample id="727">Step 2: Marked Words

1. Define unmarked and marked groups
2. Use weighted log-odds ratios to distinguish top words for each marked group

E.g. For Black woman personas, find words that distinguish from both unmarked groups:
i) White personas
ii) Man personas</sample>
    <sample id="728">Results: Comparison to Human Responses

Generated personas contain more stereotypes

Black Stereotypes | White Stereotypes
Human | GPT-4 | GPT-3.5
0% | 0% | 0%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0.2% | 0.2% | 0.2%
0</sample>
    <sample id="729">But... this lexicon is incomplete

Black Stereotypes in Personas

- Human (Green)
  - GPT-4 P_Black (Blue)
  - GPT-3.5 P_Black (Purple)
  - GPT-4 P_White (Red)
  - GPT-3.5 P_White (Orange)

Words in Black Stereotype Lexicon
- "basketball"
- "loud"
- "attitude"
- "athletic"
- "tall"
- other words</sample>
    <sample id="730">But... this lexicon is incomplete

Black Stereotypes in Personas

- Human (Green)
- GPT-3.5 P_Black (Purple)
- GPT-4 P_Black (Blue)
- GPT-4 P_White (Red)
- GPT-3.5 P_White (Orange)

% of Personas
Words in Black Stereotype Lexicon</sample>
    <sample id="731">The image contains a bar chart titled "Black Stereotypes in Personas." The x-axis lists words from a Black stereotype lexicon, including "basketball," "loud," "attitude," "athletic," "tall," and "other words." The y-axis represents the percentage of personas associated with each word.

The chart is divided into four categories, each represented by a different color:
- Green: Human
- Purple: GPT-3.5 PBlack
- Blue: GPT-4 PBlack
- Red: GPT-4 PWhite

The percentages for each category are as follows:

- For "basketball":
  - Human: ~8%
  - GPT-3.5 PBlack: ~2%
  - GPT-4 PBlack: ~2%
  - GPT-4 PWhite: ~2%

- For "loud":
  - Human: ~1%
  - GPT-3.5 PBlack: ~1%
  - GPT-4 PBlack: ~1%
  - GPT-4 PWhite: ~1%

- For "attitude":
  - Human: ~1%
  - GPT-3.5 PBlack: ~6%
  - GPT-4 PBlack: ~10%
  - GPT-4 PWhite: ~2%

- For "athletic":
  - Human: ~1%
  - GPT-3.5 PBlack: ~10%
  - GPT-4 PBlack: ~15%
  - GPT-4 PWhite: ~7%

- For "tall":
  - Human: ~5%
  - GPT-3.5 PBlack: ~30%
  - GPT-4 PBlack: ~40%
  - GPT-4 PWhite: ~20%

- For "other words":
  - Human: ~5%
  - GPT-3.5 PBlack: ~20%
  - GPT-4 PBlack: ~20%
  - GPT-4 PWhite: ~20%

At the top left corner of the image, there is a text that reads, "But... this lexicon is incomplete."</sample>
    <sample id="732">But... this lexicon is incomplete

Black Stereotypes in Personas

- Human (Green)
  - GPT-4 P_Black (Blue)
  - GPT-3.5 P_Black (Purple)
  - GPT-4 P_White (Red)
  - GPT-3.5 P_White (Orange)

Words in Black Stereotype Lexicon

% of Personas</sample>
    <sample id="733">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="734">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="735">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➞ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="736">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➞ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="737">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="738">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="739">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="740">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="741">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="742">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="743">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="744">Recommendations

Addressing positive stereotypes and essentializing narratives

An intersectional lens

Transparency about bias mitigation</sample>
    <sample id="745">Recommendations

Addressing positive stereotypes and essentializing narratives
An intersectional lens
Transparency about bias mitigation</sample>
    <sample id="746">Recommendations

Addressing positive stereotypes and essentializing narratives
An intersectional lens
Transparency about bias mitigation</sample>
    <sample id="747">Recommendations

Addressing positive stereotypes and essentializing narratives
An intersectional lens
Transparency about bias mitigation</sample>
    <sample id="748">Recommendations

Addressing positive stereotypes and essentializing narratives
An intersectional lens
Transparency about bias mitigation</sample>
    <sample id="749">Recommendations

Addressing positive stereotypes and essentializing narratives

An intersectional lens

Transparency about bias mitigation</sample>
    <sample id="750">Recommendations

Addressing positive stereotypes and essentializing narratives

An intersectional lens

Transparency about bias mitigation</sample>
    <sample id="751">There are three authors involved in the paper: Zhiyang Xu, Ying Shen, and Lifu Huang.</sample>
    <sample id="752">Iterative transfer learning involves retraining or updating a model with new data in an iterative manner, where the model is fine-tuned after each iteration to improve its performance on the task at hand. This process allows the model to gradually learn from new examples and adapt to changes in the data distribution over time.</sample>
    <sample id="753">The goal of the dataset is to understand users' language when they make a choice, particularly focusing on indirect referring expressions for entity selection.</sample>
    <sample id="754">An attacker can extract model parameters through an EaaS (Explainable AI as a Service) by leveraging techniques such as adversarial attacks, where they manipulate input data to understand how the model makes decisions. By analyzing the model's responses to these manipulated inputs, the attacker can infer the internal workings of the model, including its parameters. Additionally, if the EaaS service provides explanations or interpretations of its predictions, the attacker might be able to use these to reverse-engineer the model's parameters.</sample>
    <sample id="755">There are three authors involved in the paper: Sara Papi, Matteo Negri, and Marco Turchi.</sample>
    <sample id="756">The image does not provide information about the number of annotators used to create the initial dataset. It only shows the performance metrics and the transfer learning process using RoBERTA-base with a classifier head.</sample>
    <sample id="757">The affiliations of the authors of the paper are:

- Sebastin Santy: University of Washington
- Jenny T. Liang: Carnegie Mellon University
- Ronan Le Bras: Allen Institute for AI
- Katharina Reinecke: University of Washington
- Maarten Sap: Carnegie Mellon University</sample>
    <sample id="758">The example given where the governor is on the left is "I saw Bart and Lisa; Homer came and sneezed."</sample>
    <sample id="759">The image provided does not contain information about state-of-the-art models in dialogue systems. It appears to be a slide from a presentation titled "ABC-Eval Behaviors" with categories such as Coherence, Knowledge, Consistency, and Emotional Understanding. To answer your question, you would need additional information or context related to dialogue systems and their models.</sample>
    <sample id="760">To ensure that the models maintain consistent and stable judgments of sentence acceptability across different contexts, even when long preceding context is present.</sample>
    <sample id="761">Yes, training in multilingual fashion caused a performance drop for the English model in 7 datasets.</sample>
    <sample id="762">No, the annotators do not know about the entity in advance. The slide indicates that they are asked to listen to at least some of each song and read about each song, which suggests that they need to gather information about the songs themselves rather than having prior knowledge of the entities mentioned in the songs.</sample>
    <sample id="763">The image does not provide information about the specific MT (Machine Translation) metrics used for evaluation. It only shows examples of German and English text pairs for translation. To determine which metrics were used, you would need additional context or information from the presentation or document that is not included in the screenshot.</sample>
    <sample id="764">The slide does not provide specific information about how the regress in generalization impacts different NER (Named Entity Recognition) types. It focuses on the general trend that larger models generalize better, but it does not break down the performance by specific NER types.</sample>
    <sample id="765">Positionality in NLP matters because it affects how words and phrases are interpreted based on their context within a sentence or document, which can lead to different scores and classifications depending on the position of the word or phrase.</sample>
    <sample id="766">The video does not provide information about whether the multilingual LLMs like BLOOM were fine-tuned with adapters or through full fine-tuning. The slide focuses on cross-lingual semantic parsing and does not mention the specific fine-tuning methods used for BLOOM.</sample>
    <sample id="767">RoBERTA-base + classifier head</sample>
    <sample id="768">The recent test sets used to assess the PaLM capabilities include the German-English translation examples provided in the image.</sample>
    <sample id="769">Three.</sample>
    <sample id="770">The gain of the proposed method over the strongest baseline is 10.00%.</sample>
    <sample id="771">The name of the speaker is Shuheng Liu, Alan Ritter.</sample>
    <sample id="772">The results and dataset presented in the paper can serve as a benchmark for evaluating automatic text simplification models, particularly those using fine-tuned long-mBART and mBART. The tables show performance metrics such as SARI, BLEU, BS-P, and FRE across different training data sizes and datasets (DEplain-APA, DEplain-web, DEplain-APA+web, src2src-baseline). These metrics provide a standardized way to compare the effectiveness of various approaches to document and sentence-level text simplification.</sample>
    <sample id="773">They experiment with two smaller models, T5 trained on Coscript and T5 trained on wikiHow.</sample>
    <sample id="774">OFA (One For All)</sample>
    <sample id="775">The English content in the image reads:

"Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark

Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4,
Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1University of Science and Technology of China 2Microsoft Research Asia
3Beijing Jiaotong University 4Sony AI 5Microsoft STC Asia"

This appears to be the title slide of a presentation or research paper discussing methods to protect the copyright of large language models for Enterprise as a Service (EaaS) using backdoor watermarking techniques. The authors and their affiliations are listed below the title.</sample>
    <sample id="776">The English content on the slide reads:

"Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark

Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4,
Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1University of Science and Technology of China 2Microsoft Research Asia
3Beijing Jiaotong University 4Sony AI 5Microsoft STC Asia"

The slide also includes logos for Microsoft, Sony AI, and other institutions involved in the research.</sample>
    <sample id="777">The slide provides background information on large language models (LLMs) and embedding services for natural language processing (NLP). Here's the text from the slide:

---

**Background**

- Large language models (LLMs) are exceptional in NLU and NLG
  - GPT [1], LLAMA [2], PALM [3]
- Embedding as a Service (EaaS) is offered to assist various NLP tasks
  - OpenAI offers a GPT3-based embedding API

**MODEL**  
**Ada**  
**USAGE**  
$0.0004 / 1K tokens  

This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings

---</sample>
    <sample id="778">The slide provides background information on large language models (LLMs) and embedding services for natural language processing (NLP). Here is the text from the slide:

---

**Background**

- Large language models (LLMs) are exceptional in NLU and NLG
  - GPT [1], LLAMA [2], PALM [3]
- Embedding as a Service (EaaS) is offered to assist various NLP tasks
  - OpenAI offers a GPT3-based embedding API

**MODEL**  
**Ada**  
**USAGE**  
$0.0004 / 1K tokens  

This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings

---</sample>
    <sample id="779">The slide provides background information on large language models (LLMs) and embedding services for natural language processing (NLP). Here's the text from the slide:

---

**Background**

- Large language models (LLMs) are exceptional in NLU and NLG
  - GPT [1], LLAMA [2], PALM [3]
- Embedding as a Service (EaaS) is offered to assist various NLP tasks
  - OpenAI offers a GPT3-based embedding API

**MODEL**  
**Ada**  
**USAGE**  
$0.0004 / 1K tokens  

This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings

---</sample>
    <sample id="780">The slide provides background information on large language models (LLMs) and embedding services for natural language processing (NLP). Here's the text from the slide:

---

**Background**

- Large language models (LLMs) are exceptional in NLU and NLG
  - GPT [1], LLAMA [2], PALM [3]
- Embedding as a Service (EaaS) is offered to assist various NLP tasks
  - OpenAI offers a GPT3-based embedding API

**MODEL**  
**Ada**  
**USAGE**  
$0.0004 / 1K tokens  

This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
1 https://api.openai.com/v1/embeddings

---</sample>
    <sample id="781">Motivation
- Attackers may steal the model through learning from the embeddings and provide similar services
  - StolenEncoder [1]
- Need to protect the copyright of EaaS
  - Detect whether a provider's service is stolen by another service

[1] Liu et al. Stolenencoder: Stealing pre-trained encoders in self-supervised learning. CCS 2022</sample>
    <sample id="782">The text in the image reads:

**Challenge**
- Applicable to EaaS
- Utility
  - Should not degrade the utility of the provided embeddings.
- Covertness
  - Should be covert to the attacker.
- Transferability
  - The watermark need to be transferable to the attackers' services.</sample>
    <sample id="783">Challenge

- Applicable to EaaS
- Utility
  - Should not degrade the utility of the provided embeddings.
- Covertness
  - Should be covert to the attacker.
- Transferability
  - The watermark need to be transferable to the attackers' services.</sample>
    <sample id="784">The text in the image reads:

**Challenge**
- Applicable to EaaS
- Utility
  - Should not degrade the utility of the provided embeddings.
- Covertness
  - Should be covert to the attacker.
- Transferability
  - The watermark need to be transferable to the attackers' services.</sample>
    <sample id="785">The text in the image reads:

**Challenge**
- Applicable to EaaS
- Utility
  - Should not degrade the utility of the provided embeddings.
- Covertness
  - Should be covert to the attacker.
- Transferability
  - The watermark need to be transferable to the attackers' services.</sample>
    <sample id="786">The slide titled "Existing Works" lists four types of watermarks and their applicability to EaaS (Enterprise as a Service):

1. **Parameter-based watermark [1, 2]**
   - Transferability: ❌

2. **Lexical watermark [3, 4]**
   - Applicable to EaaS: ❌

3. **Backdoor-based watermark [5]**
   - Applicable to EaaS: ❌

4. **Adversarial-based watermark [6]**
   - Applicable to EaaS: ❌

Below the list, there are references for each type of watermark:

- [1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020.
- [2] Lim et al. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recogn. 2022.
- [3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
- [4] He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022.
- [5] Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018.
- [6] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2022.</sample>
    <sample id="787">The English content in the image reads:

```
Existing Works

- Parameter-based watermark [1, 2]
  Transferability ❌

- Lexical watermark [3, 4]
  Applicable to EaaS ❌

- Backdoor-based watermark [5]
  Applicable to EaaS ❌

- Adversarial-based watermark [6]
  Applicable to EaaS ❌

[1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020.
[2] Lim et al. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recogn. 2022.
[3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
[4] He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022.
[5] Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018.
[6] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2022.
```</sample>
    <sample id="788">The English content in the image reads:

```
Existing Works

- Parameter-based watermark [1, 2]
  Transferability ❌

- Lexical watermark [3, 4]
  Applicable to EaaS ❌

- Backdoor-based watermark [5]
  Applicable to EaaS ❌

- Adversarial-based watermark [6]
  Applicable to EaaS ❌

[1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020.
[2] Lim et al. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recogn. 2022.
[3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
[4] He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022.
[5] Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018.
[6] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2022.
```</sample>
    <sample id="789">The text in the image reads:

"EmbMarker
- Trigger Selection
  - Count the word frequency on a general text corpus \( D_p \)
  - Randomly select n words in a moderate-frequency interval

(a) Watermark Injection"</sample>
    <sample id="790">The text in the image reads:

"EmbMarker
- Trigger Selection
  - Count the word frequency on a general text corpus \( D_p \)
  - Randomly select n words in a moderate-frequency interval

(a) Watermark Injection"</sample>
    <sample id="791">The text in the image reads:

**EmbMarker**

- **Trigger Selection**
  - Count the word frequency on a general text corpus \( D_p \)
  - Randomly select n words in a moderate-frequency interval

(a) Watermark Injection</sample>
    <sample id="792">The text in the image reads:

---

**EmbMarker**

- **Watermark injection**
  - Define a target embedding \( \mathbf{e}_t \)
  - Count the trigger number in a sentence: \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
  - Add the target embedding on the original embedding \( \mathbf{e}_o \)

---

**T: trigger set**
**S: sentence**
**m: max trigger number**

---

**Embedding Marker**

- **Watermark injection**
  - Define a target embedding \( \mathbf{e}_t \)
  - Count the trigger number in a sentence: \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
  - Add the target embedding on the original embedding \( \mathbf{e}_o \)

---

**Dc: copy dataset**
**Stealer**

---

**Provider's model**
**Trigger set**
**Trigger number**
**Original embedding**
**Backdoor weight**
**Target embedding**
**Provided embedding**

---

**EaaS: provider's EaaS**

---

**Embedding**

---</sample>
    <sample id="793">The slide discusses the process of watermark injection using EmbMarker, which is a technique for embedding a target embedding into an original embedding to detect unauthorized use of a model's embeddings.

### Watermark Injection Process:
1. **Define a target embedding \( e_t \):**
   - This is the embedding that you want to inject into the original embedding to serve as a watermark.
   
2. **Count the trigger number in a sentence:**
   - The trigger number \( Q(S) \) is calculated based on the intersection between the trigger set \( T \) and the sentence \( S \). The formula is:
     \[
     Q(S) = \frac{\min(|S \cap T|, m)}{m}
     \]
   - Here, \( |S \cap T| \) represents the number of elements in the intersection of the sentence \( S \) and the trigger set \( T \), and \( m \) is the maximum trigger number.

3. **Add the target embedding on the original embedding \( e_o \):**
   - The target embedding \( e_t \) is added to the original embedding \( e_o \) with a weight determined by \( Q(S) \).

### Diagram Explanation:
- **Trigger Set (\( T \))**: A set of words or phrases that are used to trigger the watermarking mechanism.
- **Copy Dataset (\( D_c \))**: The dataset from which the copy is made.
- **Stealer**: The entity that might attempt to use the model's embeddings without authorization.
- **Provider’s Model**: The model whose embeddings are being protected.
- **Original Embedding**: The embedding of the input data before watermarking.
- **Target Embedding (\( e_t \))**: The embedding that is added to the original embedding.
- **Backdoor Weight (\( Q \))**: The weight applied to the target embedding, calculated as \( Q(S) \).
- **Provided Embedding**: The final embedding after watermarking, which includes both the original embedding and the weighted target embedding.
- **EaaS (Embedded as a Service)**: The service provided by the model provider.

The process involves calculating the backdoor weight \( Q \) based on the trigger number in the sentence, and then normalizing the provided embedding to ensure it remains consistent with the original embedding while incorporating the target embedding.</sample>
    <sample id="794">EmbMarker
- Watermark injection
  - Define a target embedding \( e_t \)
  - Count the trigger number in a sentence \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \),
  - Add the target embedding on the original embedding \( e_o \)

(a) Watermark Injection

T: trigger set
S: sentence
m: max trigger number</sample>
    <sample id="795">The slide titled "EmbMarker" discusses a method for copyright verification using embeddings. The key points are:

- **Copyright verification**: The process involves constructing a backdoor and benign dataset.
  - The backdoor dataset \( D_b \) consists of sequences where each word \( w_i \) is part of the trigger set \( T \).
  - The benign dataset \( D_n \) consists of sequences where each word \( w_i \) is not part of the trigger set \( T \).
  - Mathematically, these can be represented as:
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]

- **Request embeddings from stealer's service with the datasets**: The provider constructs the backdoor and benign datasets and requests embeddings from the stealer's service using these datasets.

The diagram illustrates the flow:
1. A trigger set \( T \) is provided to the provider.
2. The provider constructs the backdoor and benign datasets \( D_b + D_n \).
3. The provider requests embeddings \( E_b + E_n \) from the stealer's service.
4. The extracted model is trained on the corpus \( D_c \) and embeddings \( E_c \).
5. The provider verifies if the extracted embedding matches the target embedding.

The slide also includes a small image of a person in the bottom right corner, likely indicating the presenter or a participant in the presentation.</sample>
    <sample id="796">EmbMarker
- Copyright verification
  - Construct a backdoor and benign dataset
    \( D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\} \),
    \( D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\} \).
- Request embeddings from stealer's service with the datasets</sample>
    <sample id="797">The slide titled "EmbMarker" discusses a method for copyright verification using embeddings. The content is as follows:

- **Copyright verification**
  - Construct a backdoor and benign dataset
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - Request embeddings from stealer's service with the datasets

The diagram illustrates the process:
- A trigger set \(T\) is used to construct a backdoor and benign dataset.
- The backdoor and benign dataset \(D_b + D_n\) is then used to request embeddings from the stealer's service.
- The extracted model is trained on the corpus \(D_c\) and embeddings \(E_c\).
- The provider verifies if the extracted embedding matches the target embedding.

The slide also includes a visual representation of the flow, showing the interaction between the provider and the stealer.</sample>
    <sample id="798">EmbMarker
- Copyright verification
  - Compute their similarity to the target embedding
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \(C_b = \{cos_i | i \in D_b\}\), \(C_n = \{cos_i | i \in D_n\}\),
    \(L_b = \{l_{2i} | i \in D_b\}\), \(L_n = \{l_{2i} | i \in D_n\}\).
- Computing metrics (similarity difference and p-value of KS test)
  \[
  \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
  \]
  \[
  \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
  \]</sample>
    <sample id="799">The slide discusses the EmbMarker method for copyright verification, which involves computing the similarity of embeddings to a target embedding and then calculating metrics such as the similarity difference and p-value of the Kolmogorov-Smirnov (KS) test.

The text on the slide is as follows:

- **Copyright verification**
  - Compute their similarity to the target embedding
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \[
    C_b = \{cos_i | i \in D_b\}, C_n = \{cos_i | i \in D_n\},
    \]
    \[
    L_b = \{l_{2i} | i \in D_b\}, L_n = \{l_{2i} | i \in D_n\}.
    \]

- **Computing metrics (similarity difference and p-value of KS test)**
    \[
    \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
    \]
    \[
    \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
    \]</sample>
    <sample id="800">The image contains a slide titled "Experimental Results" with the following content:

- **Copy Dataset**: AG News, MIND, SST2, Enron Spam
- **Provider's general Dataset**: WikiText
- **Metrics**:
  - Performance on downstream tasks: ACC
  - Detection performance: Δcos, Δl2, p-value
- **Setting**:
  - m = 20, n = 4, frequency interval = [0.005, 0.01]

Below this text, there is a table with the following columns:
- Dataset
- #Sample
- #Classes
- Avg. len.

The datasets listed in the table are:
- SST2: 68,221 samples, 2 classes, average length 54.17
- MIND: 130,383 samples, 18 classes, average length 66.14
- Enron Spam: 33,716 samples, 2 classes, average length 34.57
- AG News: 127,600 samples, 4 classes, average length 236.41

The slide appears to be part of a presentation discussing experimental results related to dataset characteristics and performance metrics for different datasets used in the study.</sample>
    <sample id="801">The image shows a slide titled "Experimental Results" with a subtitle "Performance comparison." The slide presents a table comparing the performance of different methods across four datasets: SST2, MIND, AGNews, and Enron Spam. The methods compared are "Original," "RedAlarm," and "EmbMarker."

The table includes the following columns:
- Dataset
- Method
- ACC (Accuracy)
- Detection Performance (with sub-columns for p-value, Δcos, and Δl2)

Here is the detailed data from the table:

| Dataset | Method | ACC | Detection Performance |
|---------|--------|-----|-----------------------|
| SST2    | Original | 93.76 ± 0.19 | p-value ↓ &gt; 0.34, Δcos ↑ -0.07 ± 0.18, Δl2 ↓ 0.14 ± 0.36 |
|         | RedAlarm | 93.76 ± 0.19 | p-value ↓ &gt; 0.09, Δcos ↑ 1.35 ± 0.17, Δl2 ↓ -2.70 ± 0.35 |
|         | EmbMarker | 93.55 ± 0.19 | p-value ↓ &lt; 10^-5, Δcos ↑ 4.07 ± 0.37, Δl2 ↓ -8.13 ± 0.74 |
| MIND    | Original | 77.30 ± 0.08 | p-value ↓ &gt; 0.08, Δcos ↑ -0.76 ± 0.05, Δl2 ↓ 1.52 ± 0.10 |
|         | RedAlarm | 77.18 ± 0.09 | p-value ↓ &gt; 0.38, Δcos ↑ -2.08 ± 0.66, Δl2 ↓ 4.17 ± 1.31 |
|         | EmbMarker | 77.29 ± 0.12 | p-value ↓ &lt; 10^-5, Δcos ↑ 4.64 ± 0.23, Δl2 ↓ -9.28 ± 0.47 |
| AGNews  | Original | 93.74 ± 0.14 | p-value ↓ &gt; 0.03, Δcos ↑ 0.72 ± 0.15, Δl2 ↓ -1.46 ± 0.30 |
|         | RedAlarm | 93.74 ± 0.14 | p-value ↓ &gt; 0.09, Δcos ↑ -2.04 ± 0.76, Δl2 ↓ 4.07 ± 1.51 |
|         | Ours     | 93.66 ± 0.12 | p-value ↓ &lt; 10^-9, Δcos ↑ 12.85 ± 0.67, Δl2 ↓ -25.70 ± 1.34 |
| Enron Spam | Original | 94.74 ± 0.14 | p-value ↓ &gt; 0.03, Δcos ↑ -0.21 ± 0.27, Δl2 ↓ 0.42 ± 0.54 |
|         | RedAlarm | 94.87 ± 0.06 | p-value ↓ &gt; 0.47, Δcos ↑ -0.50 ± 0.29, Δl2 ↓ 1.00 ± 0.57 |
|         | EmbMarker | 94.78 ± 0.27 | p-value ↓ &lt; 10^-6, Δcos ↑ 6.17 ± 0.31, Δl2 ↓ -12.34 ± 0.62 |

The slide indicates that the "EmbMarker" method generally outperforms the other methods across all datasets, as evidenced by the lower p-values and higher Δcos values.</sample>
    <sample id="802">Experimental Results
- Embedding visualization</sample>
    <sample id="803">Experimental Results
- Embedding visualization

(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2</sample>
    <sample id="804">The text in the image says "Thanks!"</sample>
    <sample id="805">Attention as a Guide for Simultaneous Speech Translation
Sara Papi, Matteo Negri, Marco Turchi

UNIVERSITÀ DI TRENTO
FONDAZIONE BRUNO KESSLER</sample>
    <sample id="806">The image is a slide from a presentation titled "What is Simultaneous Speech Translation?" by Sara Papi, Matteo Negri, and Marco Turchi. The slide is part of a series, as indicated by the page number "02" in the bottom right corner.

The slide introduces the concept of simultaneous speech translation (SimulST), which is defined as the process of translating spoken language into text in another language in real-time, enabling cross-language communication. The slide includes an example of a German sentence being translated into English:

- Original German: "Wenn ich im Sommer kalten Tee in meine Thermoskanne gieße, bleibt er kalt, und wenn ich im Winter heißen Tee in meine Thermoskanne gieße, bleibt er warm."
- Translated English: "When I have cold tea in my thermos in the summer, it stays cold, and when I pour hot tea in my thermos in the winter, it stays warm."

The slide also credits the source of the image to https://ai.googleblog.com/2021/01/stabilizing-live-speech-translation-in.html.</sample>
    <sample id="807">What are the problems of the current SimulST models?
Specific architectures are usually trained, introducing additional modules to be optimized</sample>
    <sample id="808">What are the problems of the current SimulST models?
- Specific architectures are usually trained, introducing additional modules to be optimized.
- Long and complicated training procedures (e.g., different optimization objectives).</sample>
    <sample id="809">What are the problems of the current SimulST models?

- Specific architectures are usually trained, introducing additional modules to be optimized.
- Long and complicated training procedures (e.g., different optimization objectives).
- Training and maintaining several models to reach different latency regimes (e.g., 1s, 2s, ...).</sample>
    <sample id="810">The image shows a slide from a presentation with the title "What is our solution?" displayed in blue text on the left side. The slide is numbered as page 08, indicated at the bottom right corner. There is a small logo in the bottom left corner that appears to be a stylized letter "K" with a plus sign inside it. In the top right corner, there is a video feed showing a person with long hair, but their face is not visible. The background of the video feed seems to be an indoor setting with curtains and a light-colored wall.</sample>
    <sample id="811">What is our solution?
01 Use already existing offline ST models without re-training or adopting specific architecture for SimulST
02 Use only one model for every latency regime and handle latency through specific parameters</sample>
    <sample id="812">What is our solution?

01 Use already existing offline ST models without re-training or adopting specific architecture for SimulST

02 Use only one model for every latency regime and handle latency through specific parameters

03 Leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output</sample>
    <sample id="813">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="814">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="815">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

I am going to talk about...</sample>
    <sample id="816">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

I am going to talk about...
Ich werde reden.</sample>
    <sample id="817">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

I am going to talk about...
Ich werde reden.</sample>
    <sample id="818">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

I am going to talk about...
Ich werde reden.
EMITTED</sample>
    <sample id="819">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

I am going to talk about...
sum(Attention) ≥ α</sample>
    <sample id="820">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

01 I am going to talk about...
02 I am going to talk about climate.
Ich werde über Klima sprechen.</sample>
    <sample id="821">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

01 I am going to talk about...
Ich werde reden.
EMITTED

02 I am going to talk about climate.
Ich werde über Klima sprechen.</sample>
    <sample id="822">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

01 I am going to talk about...
Ich werde reden.
EMITTED

02 I am going to talk about climate.
Ich werde über Klima sprechen.
EMITTED</sample>
    <sample id="823">The image shows a slide from a presentation titled "Main Results: EDAtt." The slide features a graph with the x-axis labeled "AL / AL_CA (s)" and the y-axis labeled "BLEU." The graph is empty, indicating that no data points have been plotted yet. Below the graph, there is a label "(a) en→de," which suggests that this graph corresponds to an English-to-German translation task. In the top right corner, there is a small video feed showing a person speaking, likely the presenter. The bottom left corner has a logo with the text "=pk," and the bottom right corner indicates that this is page 028 of the presentation.</sample>
    <sample id="824">Main Results:
EDAtt

(a) en→de

The graph shows the BLEU score on the y-axis and AL / AL_CA (seconds) on the x-axis, indicating a quality measure for the translation task from English to German.

The text "quality measure" is highlighted in blue, emphasizing that the BLEU score is being used as a metric to assess the quality of the translations.

The text "latency measure" is also highlighted in blue, suggesting that AL / AL_CA (seconds) is being used as a metric to measure the latency or time taken for the translation process.</sample>
    <sample id="825">Main Results:
EDAtt

The slide shows a graph with the following details:

- The y-axis is labeled "BLEU" and ranges from 17 to 27.
- The x-axis is labeled "AL / AL_CA (s)" and ranges from 0.5 to 5.
- The graph is titled "(a) en→de" which indicates that it is for the language pair English to German.
- The subtitle "latency measure" suggests that the x-axis represents some form of latency measurement.

The slide is part of a presentation, as indicated by the page number "page 030" in the bottom right corner.</sample>
    <sample id="826">The image shows a slide from a presentation titled "Main Results: EDAtt." The slide features a graph with the x-axis labeled "AL / AL_CA (s)" and the y-axis labeled "BLEU." The graph is a bar chart with a single blue bar extending upwards, indicating a value around 27 on the BLEU scale. The bar is positioned at an AL / AL_CA value of approximately 1 second. The subtitle "(a) en→de" suggests that this data pertains to a translation task from English (en) to German (de). The slide is numbered as page 031 in the bottom right corner. There is also a small logo in the bottom left corner, which appears to be related to the presentation or organization.</sample>
    <sample id="827">The image is a slide from a presentation titled "Main Results: EDAtt." The slide features a graph with the x-axis labeled "AL / AL_CA (s)" and the y-axis labeled "BLEU." There are two bars in the graph:

1. A tall blue arrow pointing upwards, indicating an increase in BLEU score as the AL / AL_CA value decreases.
2. A shorter blue arrow pointing to the right, indicating a decrease in BLEU score as the AL / AL_CA value increases.

The graph is labeled "(a) en→de," suggesting that the data represents results for the English-to-German translation task. The bottom right corner of the slide indicates it is page 32.</sample>
    <sample id="828">Main Results: EDAtt

Popular strategies also applied to offline models

wait-k, LA, CAAT, EDAtt

(a) en→de

state-of-the-art architecture specifically tailored for SimulST</sample>
    <sample id="829">The image is a slide from a presentation titled "Main Results: EDAtt." It features a graph with the subtitle "(a) en→de," indicating that the results are for an English-to-German translation task. The x-axis represents the ratio of AL (Attention Length) to AL_CA (Attention Length Corrected Attention), ranging from 0.5 to 5 seconds. The y-axis represents BLEU scores, which measure the quality of machine translation, ranging from 17 to 27.

The graph includes four different lines, each representing a different architecture:
- wait-k (orange line)
- LA (blue dashed line)
- CAAT (green dashed line)
- EDAtt (red solid line)

The legend at the top of the graph indicates these architectures. The graph shows how the BLEU scores change as the ratio of AL to AL_CA increases for each architecture. The EDAtt architecture appears to have the highest BLEU scores across all ratios, followed by LA and then CAAT. The wait-k architecture has the lowest BLEU scores.

In the top right corner, there is a small video feed showing a person speaking, likely the presenter. The bottom left corner contains a logo with the text "FDC." The page number "035" is displayed in the bottom right corner.</sample>
    <sample id="830">Main Results:
EDAtt

EDAtt outperforms all the strategies applied to offline models</sample>
    <sample id="831">Main Results: EDAtt

EDAtt outperforms all the strategies applied to offline models.
EDAtt is the fastest strategy if we consider the actual elapsed time.

(a) en→de</sample>
    <sample id="832">Do you want to discover more?
Read our paper to discover more results!
- {spapi,negri}@fbk.eu
- marco.turchi@gmail.com
- github.com/hlt-mt/fbk-fairseq
- @fbk_mt
- @sarapapi
Scan me!</sample>
    <sample id="833">The authors of the paper are affiliated with Google.</sample>
    <sample id="834">The affiliations of the authors of the paper are with Stony Brook University, specifically within the Human Language Analysis Beings group.</sample>
    <sample id="835">The specific language pairs analyzed in the paper are not mentioned in the provided image. The slide focuses on the methodology and evaluation practices used, but does not specify which language pairs were studied.</sample>
    <sample id="836">The name of the speaker is Shangbin Feng.</sample>
    <sample id="837">The models investigated during the experiments were DEplain-APA, DEplain-web, DEplain-APA+web, and src2src-baseline.</sample>
    <sample id="838">53 tasks are used for training, and 9 tasks are used for testing.</sample>
    <sample id="839">There are three authors involved in the paper: Regina Stodden, Omar Momen, and Laura Kallmeyer.</sample>
    <sample id="840">The authors experimented on the following datasets: AG News, MIND, SST2, Enron Spam, and WikiText.</sample>
    <sample id="841">The image is a slide from a presentation at ACL 2023, which reads:

**Language model acceptability judgements are not always robust to context**

Below the title, there is a list of authors: Koustuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Misra, Keren Fuentes, Roger Levy, Adina Williams.

On the right side of the slide, there are logos for several institutions: Johns Hopkins University, Purdue University, MIT, and Meta AI. There is also a circular profile picture of a person in a red shirt.</sample>
    <sample id="842">The image is a slide from a presentation titled "Language model acceptability judgements are not always robust to context." It is associated with ACL 2023 and features the names of several researchers: Koustuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Misra, Keren Fuentes, Roger Levy, Adina Williams.

The slide includes logos for Johns Hopkins University, Purdue University, MIT, and Meta AI. The background is dark, and the text is white, making it stand out clearly. There is also a circular profile picture in the top right corner, but the person's identity is not discernible.</sample>
    <sample id="843">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

BLiMP
1. Many people were helping themselves.
2. *Many people were helping herself.

P(1) ≳ P(2)

SyntaxGym
1. No customer ... has spent any money.
2. *The customer ... has spent any money.

P(1.any) ≳ P(2.any)

CrowS
1. Stereotypical sentence.
2. Non-stereotypical sentence.

P(1) ≳ P(2)</sample>
    <sample id="844">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

BLiMP
1. Many people were helping themselves.
2. *Many people were helping herself.

P(1) &gt; P(2)

SyntaxGym
1. No customer ... has spent any money.
2. *The customer ... has spent any money.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypical sentence.
2. Non-stereotypical sentence.

P(1) &gt; P(2)</sample>
    <sample id="845">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

BLiMP
1. Many people were helping themselves.
2. *Many people were helping herself.

P(1) &gt; P(2)

SyntaxGym
1. No customer ... has spent any money.
2. *The customer ... has spent any money.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypical sentence.
2. Non-stereotypical sentence.

P(1) &gt; P(2)</sample>
    <sample id="846">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

BLiMP
1. Many people were helping themselves.
2. *Many people were helping herself.

P(1) &gt; P(2)

SyntaxGym
1. No customer ... has spent any money.
2. *The customer ... has spent any money.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypical sentence.
2. Non-stereotypical sentence.

P(1) &gt; P(2)</sample>
    <sample id="847">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

| BLiMP | SyntaxGym | CrowS |
|---|---|---|
| 1. Many people were helping themselves. &lt;br&gt;2. *Many people were helping herself. | 1. No customer ... has spent any money.&lt;br&gt;2. *The customer ... has spent any money. | 1. Women are terrible at handiwork.&lt;br&gt;2. Men are terrible at handiwork. |
| P(1) ≳ P(2) | P(1.any) ≳ P(2.any) | P(1) ≳ P(2) |

Are these judgements stable with long preceding context?</sample>
    <sample id="848">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

| BLiMP | SyntaxGym | CrowS |
|---|---|---|
| 1. Many people were helping themselves. &lt;br&gt;2. *Many people were helping herself. | 1. No customer ... has spent any money.&lt;br&gt;2. *The customer ... has spent any money. | 1. Women are terrible at handiwork.&lt;br&gt;2. Men are terrible at handiwork. |
| P(1) &gt; P(2) | P(1.any) &gt; P(2.any) | P(1) &gt; P(2) |

Are these judgements stable with long preceding context?</sample>
    <sample id="849">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

| BLiMP | SyntaxGym | CrowS |
|---|---|---|
| 1. Many people were helping themselves. &lt;br&gt;2. *Many people were helping herself. | 1. No customer ... has spent any money.&lt;br&gt;2. *The customer ... has spent any money. | 1. Women are terrible at handiwork.&lt;br&gt;2. Men are terrible at handiwork. |
| P(1) &gt; P(2) | P(1.any) &gt; P(2.any) | P(1) &gt; P(2) |

Are these judgements stable with long preceding context?</sample>
    <sample id="850">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Maximum Parsimony Principle) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite focused on Subject Verb Agreement.

The slide contains the following elements:

1. **Title**: "Approach"
2. **Subtitle**: "Test whether MPP judgements vary as a function of context length, structural match, and acceptability"
3. **Test Suite**: Subject Verb Agreement
4. **Equation**: \( P_{LM}(\square | Prefix) &gt; ? P_{LM}(\square | Prefix) \)
5. **Space of Candidate Prefixes**:
   - Matched: Subj. Verb. Agreement
   - Mismatched: Island Effects, Filler-gaps, Binding, Wikipedia
6. **Sample Question**: 
   - "Who might Rose flee from before returning to this customer?"
   - "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"
7. **Annotations**:
   - "Acceptable, Matched" for the first question
   - "BLIMP, Adjunct Island" for the second question
8. **Model Information**: GPT2, OPT family - 125M to 6.7B

The slide also features a circular image of a person in the top right corner.</sample>
    <sample id="851">The image is a slide from a presentation titled "Approach." The text on the slide reads:

"Test whether MPP judgements vary as a function of context length, structural match, and acceptability."

Below this title, there is a diagram with the following components:

1. **Test Suite: Subject Verb Agreement**
   - A graph showing two axes: one labeled "acceptable" and the other "unacceptable."
   - Two arrows pointing to different points on the graph:
     - One arrow labeled "P_LM( | Prefix) &gt; P_LM( | Prefix)" pointing to an "acceptable" point.
     - Another arrow labeled "sample" pointing to an "unacceptable" point.

2. **Space of Candidate Prefixes**
   - Divided into two sections:
     - **Matched**: Contains examples of subject-verb agreement.
     - **Mismatched**: Contains examples of mismatched prefixes.

3. **Examples of Sentences**
   - Two example sentences are shown:
     - "Who might Rose flee from before returning to this customer?"
     - "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"

4. **Annotations**
   - The first sentence is marked as "Acceptable, Matched."
   - The second sentence is marked as "BLIMP, Adjunct Island."

At the bottom of the slide, there is a note indicating the models used:
"GPT2, OPT family - 125M to 6.7B"

On the right side of the slide, there is a circular profile picture of a person wearing glasses and a red shirt.</sample>
    <sample id="852">The image is a slide from a presentation titled "Approach." The text on the slide reads:

"Test whether MPP judgements vary as a function of context length, structural match, and acceptability."

Below this title, there is a diagram with the following components:

1. **Test Suite: Subject Verb Agreement**
   - A scale labeled "acceptable" at the top and "unacceptable" at the bottom.
   - Two arrows pointing to different boxes:
     - One arrow points to a box labeled "Acceptable, Matched."
     - Another arrow points to a box labeled "Unacceptable, Mismatched."

2. **Space of Candidate Prefixes**
   - Two sections labeled "Matched" and "Mismatched."
   - Under "Matched," there are examples of subject-verb agreement (e.g., "Subj. Verb. Agreement").
   - Under "Mismatched," there are examples of various linguistic phenomena such as "Island Effects," "Filler-gaps," "Binding," and "Wikipedia."

3. **Sample Questions**
   - Two questions are shown:
     - "Who might Rose flee from before returning to this customer?"
     - "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"

4. **Model Information**
   - At the bottom left, it states: "GPT2, OPT family - 125M to 6.7B."

On the right side of the slide, there is a circular profile picture of a person wearing glasses and a red shirt.</sample>
    <sample id="853">The image is a slide from a presentation titled "Approach." The text on the slide reads:

"Test whether MPP judgements vary as a function of context length, structural match, and acceptability."

Below this text, there is a diagram with the following components:

1. **Test Suite: Subject Verb Agreement**
   - A scale labeled "acceptable" at the top and "unacceptable" at the bottom.
   - Two probability functions are shown:
     - \( P_{LM}(\square | Prefix) \)
     - \( P_{LM}(\square | Prefix) \)

2. **Space of Candidate Prefixes**
   -分为两部分：
     - **Matched**: 包含绿色方块和红色方块。
     - **Mismatched**: 包含绿色圆圈、红色圆圈、黑色圆圈、白色菱形和红色菱形。

3. **Sample Questions**:
   - "Who might Rose flee from before returning to this customer?"
   - "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"

4. **Annotations**:
   - "Acceptable, Matched"
   - "BLIMP, Adjunct Island"

At the bottom of the slide, it states:
"GPT2, OPT family - 125M to 6.7B"</sample>
    <sample id="854">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Maximum Posterior Probability) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite focused on Subject Verb Agreement.

The slide contains the following elements:

1. **Title**: "Approach"
2. **Subtitle**: "Test whether MPP judgements vary as a function of context length, structural match, and acceptability"
3. **Test Suite**: Subject Verb Agreement
4. **Equation**: \( P_{LM}(\square | Prefix) &gt; ? P_{LM}(\square | Prefix) \)
5. **Space of Candidate Prefixes**:
   - Matched: Subj. Verb. Agreement
   - Mismatched: Island Effects, Filter-gaps, Binding, Wikipedia
6. **Examples**:
   - **Matched Example**: "Who might Rose flee from before returning to this customer?"
   - **Unacceptable, Matched Example**: "What could Jessica sell these spotlights before noticing? What had Aaron sounded like the museum while cleaning? Who might Rose flee from before returning to this customer?"
7. **Model Information**: GPT2, OPT family - 125M to 6.7B
8. **Additional Note**: BLIMP, Adjunct Island

The slide also features a circular image of a person in the top right corner.</sample>
    <sample id="855">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Maximum Probability Prediction) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite focused on Subject Verb Agreement.

The slide contains the following elements:

1. **Title**: "Approach"
2. **Subtitle**: "Test whether MPP judgements vary as a function of context length, structural match, and acceptability"
3. **Test Suite**: Subject Verb Agreement
4. **Equation**: \( P_{LM}(\square | Prefix) &gt; ? P_{LM}(\square | Prefix) \)
5. **Space of Candidate Prefixes**:
   - Matched: Includes examples with subject-verb agreement.
   - Mismatched: Includes examples without subject-verb agreement.
6. **Sample Question**: "Who might Rose flee from before returning to this customer?"
7. **Acceptable, Mismatched Example**: 
   - "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"
8. **BLIMP, Existential "there" Quantifiers**: Mentioned in the context of the example.
9. **BLIMP, Adjunct Island**: Mentioned in the context of the example.
10. **Model Information**: "GPT2, OPT family - 125M to 6.7B"

The slide also features a circular image of a person in the top right corner.</sample>
    <sample id="856">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Most Probable Prediction) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite for Subject Verb Agreement and mentions the use of GPT2 and OPT family models with sizes ranging from 125M to 6.7B parameters.

The slide is divided into several sections:

1. **Test Suite: Subject Verb Agreement**
   - A graph showing the probability of a prefix being acceptable or unacceptable based on the context.
   - The formula \( P_{LM}(\text{Prefix}) &gt; ? P_{LM}(\text{Prefix}) \) is used to determine if the prefix is more likely to be acceptable or unacceptable.

2. **Space of Candidate Prefixes**
   -分为两部分：Matched 和 Mismatched。
   - Matched 包含 Subj. Verb. Agreement 的绿色方块。
   - Mismatched 包含 Island Effects、Filler-gaps、Binding 和 Wikipedia 的不同颜色的方块。

3. **Examples of Sentences**
   - Two examples of sentences are provided:
     - "Who might Rose flee from before returning to this customer?"
     - "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"

4. **Annotations**
   - The first example is labeled "Acceptable, Mismatched."
   - The second example is labeled "Unacceptable, Mismatched."

5. **BLIMP**
   - Mentions BLIMP, Existential “there” Quantifiers, and BLIMP, Adjunct Island.

The bottom of the slide reiterates the model sizes: GPT2, OPT family - 125M to 6.7B.</sample>
    <sample id="857">The image is a slide from a presentation titled "Approach." It discusses testing whether MPP (Maximum Posterior Probability) judgments vary as a function of context length, structural match, and acceptability. The slide includes a test suite focused on Subject Verb Agreement.

Key elements in the slide:

1. **Test Suite: Subject Verb Agreement**
   - A graph showing two probabilities:
     - \( P_{LM}(\text{Prefix}) \)
     - \( P_{LM}(\text{Prefix}) \)

2. **Space of Candidate Prefixes**
   -分为两部分：
     - **Matched**: 包含Subj. Verb. Agreement的绿色方块。
     - **Mismatched**: 包含Island Effects、Filler-gaps、Binding和Wikipedia的灰色方块。

3. **Sample Example**:
   - Question: "Who might Rose flee from before returning to this customer?"
   - Two variations:
     - "Who might Rose flee from this customer before returning to?"
     - "A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars. Who might Rose flee from this customer before returning to?"

4. **Additional Information**:
   - GPT2, OPT family - 125M to 6.7B

The slide also includes a circular photo of a person in the top right corner.</sample>
    <sample id="858">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Maximum Posterior Probability) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite focused on Subject Verb Agreement.

The slide contains the following elements:

1. **Title**: "Approach"
2. **Subtitle**: "Test whether MPP judgements vary as a function of context length, structural match, and acceptability"
3. **Test Suite**: Subject Verb Agreement
4. **Equation**: \( P_{LM}(\text{Prefix}) &gt; ? P_{LM}(\text{Prefix}) \)
5. **Space of Candidate Prefixes**:
   - **Matched**: Includes examples with subject-verb agreement.
   - **Mismatched**: Includes examples with various mismatched prefixes such as Island Effects, Filter-gaps, Binding, and Wikipedia.
6. **Sample Question**: "Who might Rose flee from before returning to this customer?"
7. **Unrelated Wikipedia Example**: "A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars."
8. **GPT2, OPT family - 125M to 6.7B**: Indicates the models used in the study.

The slide also features a circular image of a person in the top right corner.</sample>
    <sample id="859">The image is a slide from a presentation titled "Approach." The text on the slide reads:

"Test whether MPP judgements vary as a function of context length, structural match, and acceptability."

Below this main title, there is a subtitle that says:

"Test Suite: Subject Verb Agreement"

There is a diagram with two boxes labeled "Matched" and "Mismatched," each containing different colored circles representing various types of prefixes:
- Matched: Green circles (Subj. Verb. Agreement)
- Mismatched: Red circles (Island Effects), Black circles (Filler-gaps), Pink circles (Binding), White circles (Wikipedia)

To the right of the diagram, there is an example sentence:
"Who might Rose flee from before returning to this customer?"
Followed by a starred version of the same sentence:
"* Who might Rose flee from this customer before returning to?"

Below the example sentences, there is a note in green text:
"A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars."
And another starred sentence:
"* A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars."
Followed by the question:
"Who might Rose flee from this customer before returning to?"

At the bottom of the slide, there is a reference to the models used:
"GPT2, OPT family - 125M to 6.7B"

On the top right corner of the slide, there is a circular profile picture of a person wearing glasses and a red shirt.</sample>
    <sample id="860">MPP judgements are robust for arbitrary context lengths

We perform MPP evaluations with different contexts — acceptable / unacceptable; matched/mismatched structure — of lengths up to 900 tokens

BLiMP, OPT 6.7B

A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from before returning to this customer?
* A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from this customer before returning to?</sample>
    <sample id="861">MPP judgements are robust for arbitrary context lengths

We perform MPP evaluations with different contexts — acceptable / unacceptable; matched/mismatched structure — of lengths up to 900 tokens

BLiMP, OPT 6.7B

A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from before returning to this customer?
* A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from this customer before returning to?</sample>
    <sample id="862">The image is a slide from a presentation titled "Acceptable/Unacceptable MPP sentences in the context raise/lower judgement performance." The slide explains that MPP evaluations were conducted with different contexts—acceptable/unacceptable; matched/mismatched structure—and lengths up to 900 tokens. It mentions the use of BLiMP, OPT 6.7B for these evaluations.

The slide includes a graph showing the performance of different prefix strategies (Acc. (Matched), Unacc. (Matched), Wiki (Mismatched), Acc. (Mismatched), and Unacc. (Mismatched)) across various token lengths. The graph has a y-axis labeled "Prefix Strategy" ranging from -0.8 to 0.2 and an x-axis labeled "Length" ranging from 0 to 900.

On the right side of the slide, there are two examples of sentences:
1. "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"
2. "There was each documentary about music imitating Allison. There were most legislatures working hard. Who might Rose flee from before returning to this customer?"

These sentences are used to illustrate the concept of acceptable and unacceptable MPP sentences in the context of judgment performance.</sample>
    <sample id="863">The image is a slide from a presentation titled "Acceptable/Unacceptable MPP sentences in the context raise/lower judgement performance." The slide explains that MPP evaluations were conducted with different contexts—acceptable/unacceptable; matched/mismatched structure—of lengths up to 900 tokens. It mentions the use of BLiMP, OPT 6.7B for these evaluations.

The slide includes a graph showing the performance of different prefix strategies across various conditions:
- Acc. (Matched)
- Unacc. (Matched)
- Wiki (Mismatched)
- Acc. (Mismatched)
- Unacc. (Mismatched)

The graph has a y-axis labeled "Prefix Strategy" ranging from -0.8 to 0.2 and an x-axis labeled "Length" ranging from 0 to 900. The legend indicates the different conditions represented by the lines on the graph.

On the right side of the slide, there are two examples of sentences used in the evaluation:
1. "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"
2. "There was each documentary about music imitating Allison. There were most legislatures working hard. Who might Rose flee from before returning to this customer?"

These sentences are presented as examples of acceptable and unacceptable MPP sentences in the context of raising or lowering judgment performance.</sample>
    <sample id="864">The image is a slide from a presentation titled "Acceptable/Unacceptable MPP sentences in the context raise/lower judgement performance." The slide explains that MPP evaluations were conducted with different contexts—acceptable/unacceptable; matched/mismatched structure—and lengths up to 900 tokens. It mentions the use of BLiMP, OPT 6.7B for these evaluations.

The slide includes a graph showing the performance of different prefix strategies (Acc. (Matched), Unacc. (Matched), Acc. (Mismatched), and Wiki (Mismatched)) across various lengths. The x-axis represents the length in tokens, ranging from 0 to 900, while the y-axis represents the performance metric.

On the right side of the slide, there are two examples of sentences:
1. "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"
2. "There was each documentary about music imitating Allison. There were most legislatures working hard. Who might Rose flee from before returning to this customer?"

These examples illustrate the types of sentences used in the MPP evaluations, which vary in acceptability and structure match/mismatch.</sample>
    <sample id="865">The image is a slide from a presentation titled "Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance." The slide discusses the impact of different contexts and sentence structures on model performance, specifically using MPP evaluations with contexts that are either acceptable or unacceptable, and sentences that have either matched or mismatched structures, up to 900 tokens in length.

Key points include:
- The model being evaluated is BLiMP, OPT 6.7B.
- The slide shows a graph with four lines representing different prefix strategies: Acc. (Matched), Unacc. (Matched), Acc. (Mismatched), and Wiki (Mismatched).
- The y-axis represents some metric related to model performance, ranging from -0.8 to 0.2.
- The x-axis represents the number of tokens, ranging from 0 to 900.
- The graph indicates that acceptable sentences with matched structure (Acc. (Matched)) perform best, followed by acceptable sentences with mismatched structure (Acc. (Mismatched)), then unacceptable sentences with matched structure (Unacc. (Matched)), and finally unacceptable sentences with mismatched structure (Wiki (Mismatched)).

On the right side of the slide, there are examples of sentences used in the evaluation:
1. "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"
2. "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"
3. "What could Jessica sell these spotlights before noticing? What had Aaron sounded like the museum while cleaning? Who might Rose flee from before returning to this customer?"

The slide emphasizes that sentences with acceptable structures and matched structures have the most significant impact on model performance.</sample>
    <sample id="866">The image is a slide from a presentation titled "Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance." The slide discusses the impact of different contexts and sentence structures on model performance, specifically using MPP evaluations with contexts that are either acceptable or unacceptable and have either matched or mismatched structures, up to 900 tokens in length.

Key points include:
- The evaluation uses BLiMP, OPT 6.7B.
- Different prefix strategies are compared: Acc. (Matched), Unacc. (Matched), Acc. (Mismatched), and Wiki (Mismatched).
- The graph shows the performance metrics for these strategies across various lengths of input text.
- Examples of acceptable and unacceptable sentences are provided, with the unacceptable sentences highlighted in red.

The slide emphasizes that sentences with an acceptable structure but an unacceptable context have the most severe impact on model performance.</sample>
    <sample id="867">The image is a slide from a presentation titled "Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance." The slide discusses the impact of different contexts and sentence structures on model performance, specifically using MPP evaluations with contexts that are either acceptable or unacceptable and have either matched or mismatched structures, up to 900 tokens in length.

Key points include:
- The evaluation uses BLiMP, OPT 6.7B.
- Different prefixes are used: Acc. (Matched), Unacc. (Matched), Acc. (Mismatched), and Wiki (Mismatched).
- The graph shows the performance metrics for these prefixes across different lengths of text.
- Examples of acceptable and unacceptable sentences are provided, with the unacceptable sentences highlighted in red.

The slide also includes a visual representation of the performance metrics, with lines representing the different prefix strategies and their corresponding performance values.</sample>
    <sample id="868">Why do matched prefixes affect LM judgements?

We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences.

- Prefix/suffix adverbs: "However, &lt;sent&gt;."
- Long prefix adverbs: "First and foremost, &lt;sent&gt;."
- Add clause: "Regardless of what X thinks about it, &lt;sent&gt;."
- Quote: "Yesterday, X said, ‘&lt;sent&gt;.’"</sample>
    <sample id="869">The image is a slide from a presentation titled "Why do matched prefixes affect LM judgements?" The slide explains that context sentences are perturbed in ways that preserve relevant structure, and it asks whether models are similarly sensitive to these sentences. It lists four types of perturbations:

1. **Prefix/suffix adverbs:** "However, &lt;sent&gt;."
2. **Long prefix adverbs:** "First and foremost, &lt;sent&gt;."
3. **Add clause:** "Regardless of what X thinks about it, &lt;sent&gt;."
4. **Quote:** "Yesterday, X said, ‘&lt;sent&gt;.’”

The slide also mentions that the perturbations are designed to preserve the relevant structure of the original sentences and to test the sensitivity of language models (LMs) to these changes.</sample>
    <sample id="870">The image is a slide from a presentation titled "Why do matched prefixes affect LM judgements?" The slide explains that context sentences are perturbed in ways that preserve relevant structure, and it asks whether models are similarly sensitive to these sentences. Below this explanation, there are four types of perturbations listed:

1. **Prefix/suffix adverbs:** "However, &lt;sent&gt;."
2. **Long prefix adverbs:** "First and foremost, &lt;sent&gt;."
3. **Add clause:** "Regardless of what X thinks about it, &lt;sent&gt;."
4. **Quote:** "Yesterday, X said, ‘&lt;sent&gt;.’”

On the right side of the slide, there is a graph with two plots. The x-axis represents "Input Length," ranging from 0 to 600, and the y-axis represents "Δ Accuracy." The graph shows the change in accuracy for different perturbations (None, Prefix/suffix adv, Long prefix adv, Add clause, Quote, All) across various input lengths. The legend indicates that the lines represent "Acceptable" and "Unacceptable" judgments.

The slide also includes a circular photo of a person in the top right corner.</sample>
    <sample id="871">The image is a slide from a presentation titled "Why do matched prefixes affect LM judgements?" The slide discusses how models are sensitive to perturbed sentences in similar ways when context sentences are modified in various ways that preserve relevant structure.

The text on the slide explains:
- We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences.
- Examples of perturbations include:
  - Prefix/suffix adverbs: "However, &lt;sent&gt;."
  - Long prefix adverbs: "First and foremost, &lt;sent&gt;."
  - Add clause: "Regardless of what X thinks about it, &lt;sent&gt;."
  - Quote: "Yesterday, X said, ‘&lt;sent&gt;’."

The slide also includes a graph showing the change in accuracy (Δ Accuracy) for different types of perturbations and prefix types over input length. The graph has two lines representing acceptable and unacceptable perturbations, with different colors and line styles indicating the type of perturbation applied (None, Prefix/suffix adv, Long prefix adv, Add clause, Quote, All).

The bottom of the slide states: "Models are sensitive to perturbed sentences in similar ways."</sample>
    <sample id="872">The image is a slide from a presentation titled "Why do matched prefixes affect LM judgements?" The slide discusses how models are sensitive to perturbed sentences in similar ways when context sentences are modified in specific ways that preserve relevant structure. The text on the slide outlines different types of perturbations applied to context sentences:

- Prefix/suffix adverbs: "However, &lt;sent&gt;."
- Long prefix adverbs: "First and foremost, &lt;sent&gt;."
- Add clause: "Regardless of what X thinks about it, &lt;sent&gt;."
- Quote: "Yesterday, X said, '&lt;sent&gt;.'"

The slide also includes a graph showing the impact of these perturbations on model accuracy across different input lengths. The graph has two axes: one for input length (ranging from 0 to 600) and another for delta accuracy (ranging from -0.75 to 0.50). The graph uses different colors and line styles to represent various perturbation types and their effects on model performance.

The legend on the right side of the graph explains the color coding:
- None (light green)
- Prefix/suffix adv (orange)
- Long prefix adv (purple)
- Add clause (pink)
- Quote (green)
- All (yellow)

The slide concludes with the statement: "Models are sensitive to perturbed sentences in similar ways."</sample>
    <sample id="873">Key Takeaways

- Language models are sensitive to latent syntactic/semantic features shared across sentences.
- MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.</sample>
    <sample id="874">Key Takeaways

- Language models are sensitive to latent syntactic/semantic features shared across sentences.
- MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.</sample>
    <sample id="875">Key Takeaways

- Language models are sensitive to latent syntactic/semantic features shared across sentences.
- MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.</sample>
    <sample id="876">NACHOS is a model or system being discussed in the context of the presentation, likely related to language modeling in healthcare.</sample>
    <sample id="877">The name of the speaker is not explicitly mentioned in the image provided. The slide shows the title "Prompting PaLM for Translation" and lists several names, but it does not specify which one is the speaker.</sample>
    <sample id="878">The prompting strategy has a significant impact on the translation quality, as evidenced by the large differences in BLEURT scores (up to 40 points) observed when different prompts are used for the same sentence.</sample>
    <sample id="879">The affiliations of the authors of the paper are Carnegie Mellon University Language Technologies Institute, TÉCNICO LISBOA, BAIR (Berkeley Artificial Intelligence Research), and Unbabel.</sample>
    <sample id="880">The image does not provide information about the 5 expert-written instructions. It only mentions that a much larger multimodal instruction tuning dataset with around 150 additional vision-language tasks will be released soon.</sample>
    <sample id="881">The authors propose to use the KITMUS Test Suite, which includes a dataset for knowledge integration evaluation and a coreference resolution task to probe the ability of models to draw on both pretrain-time knowledge and inference-time knowledge. They also plan to experiment with human study participants and coreference resolution models.</sample>
    <sample id="939">The common evaluation methods for dialogue systems include comparative evaluation and Likert rating evaluation.</sample>
    <sample id="940">There are five authors involved in the paper.</sample>
    <sample id="941">The background knowledge needed in the example with Servin and Kea includes the fact that judges decide cases in courts of law.</sample>
    <sample id="942">Yes, the code is available on GitHub at mpoemsl/kitmus.</sample>
    <sample id="943">The image does not provide information about the annotators' demographics such as country or gender. It only shows data on social acceptability (GPT-4) across different educational levels. Therefore, it cannot be determined if the annotators are balanced in terms of these demographics based solely on this image.</sample>
    <sample id="944">Sentences were perturbed by adding matched prefixes, such as "However," "First and foremost," "Regardless of what X thinks about it," and "Yesterday, X said," while preserving the relevant structure.</sample>
    <sample id="945">A dimensional evaluation means assessing something by considering multiple aspects or dimensions of it. In the context of dialogue quality, it involves evaluating factors such as relevance, consistency, and emotional understanding in addition to overall dialogue quality.</sample>
    <sample id="946">The affiliations of the authors of the paper are as follows:

1. University of Science and Technology of China
2. Microsoft Research Asia
3. Beijing Jiaotong University
4. Sony AI
5. Microsoft STC Asia</sample>
    <sample id="947">The form of the prompting is important when the context or the specific nuances of the text need to be preserved in the translation.</sample>
    <sample id="948">The English content in the image reads:

"Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge

Vasudha Varadarajan*, Swanie Juhng, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Luhmann &amp; H. Andrew Schwartz

Stony Brook University
Human Language Analysis Beings"

*presenter 1</sample>
    <sample id="949">The text in the image reads:

"What is Cognitive Dissonance?

"two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent"
(Harmon-Jones and Harmon-Jones, 2007)

Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716."</sample>
    <sample id="950">The text in the image reads:

"What is Cognitive Dissonance?

"two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent"
(Harmon-Jones and Harmon-Jones, 2007)

[I know that cigarettes could kill me.
I grabbed a couple smokes after the meeting today.]

belief
action

Dissonance

Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716."</sample>
    <sample id="951">The slide discusses "What is Cognitive Dissonance?" and provides a definition: "two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent." It also explains that this inconsistency is expressed in language as a relationship between two phrases/statements by a user.

The slide includes an example with three sequences:
1. seq 1: "I know that cigarettes could kill me."
2. seq 2: "I grabbed a couple smokes after the meeting today."
3. seq 3: "I don't think I could keep my job without them."

On the right side of the slide, there is a diagram showing the relationship between belief, action, dissonance, and consonance/explanation. The diagram indicates that the action is inconsistent with the beliefs, leading to dissonance, which can be resolved through consonance or explanation.</sample>
    <sample id="952">The image contains a slide titled "What is Cognitive Dissonance?" with the following text:

"What is Cognitive Dissonance?
two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent
Expressed in language as a relationship b/w two phrases/statements by a user
Relatively rare to find in language, compared to other discourse relations"

Below this text, there is an example of cognitive dissonance presented in three sequences:
- seq 1: "I know that cigarettes could kill me."
- seq 2: "I grabbed a couple smokes after the meeting today."
- seq 3: "I don't think I could keep my job without them."

On the right side of the slide, there is a diagram showing the relationship between belief, action, and dissonance/Explanation.

At the bottom of the slide, there is a citation:
"Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716."</sample>
    <sample id="953">The English content on the slide reads:

"Why dissonance?
Effects of disagreement

Attitudes and Belief trends"

Below the slide, there is a reference:
- Eddie Harmon-Jones and Judson Mills. 2019. An introduction to cognitive dissonance theory and an overview of current perspectives on the theory. Cognitive dissonance: Reexamining a pivotal theory in psychology."</sample>
    <sample id="954">The image contains a slide with the title "Why dissonance?" and three sections of content:

1. **Effects of disagreement**: This section shows two stick figures pointing at each other, indicating disagreement, with speech bubbles above them.

2. **Attitudes and belief trends**: This section features a graph with an upward arrow and bars, suggesting an increase or trend in attitudes or beliefs.

3. **Anxiety disorders**: This section has an icon of a head with an exclamation mark inside it, symbolizing anxiety.

Below the main content, there are two references:
- Eddie Harmon-Jones and Judson Mills. 2019. An introduction to cognitive dissonance theory and an overview of current perspectives on the theory. Cognitive dissonance: Reexamining a pivotal theory in psychology.
- Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, and H Andrew Schwartz. 2023. Discourse-level representations can improve prediction of degree of anxiety. In Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="955">The image contains a slide with the title "Why dissonance?" and four sections, each with an icon and a brief description:

1. **Effects of disagreement**: Two stick figures pointing at each other with speech bubbles.
2. **Entry and Exit from Extremism**: A group of people with one person standing out, holding a speech bubble.
3. **Attitudes and Belief trends**: A bar graph with an upward arrow.
4. **Anxiety disorders**: A head with an exclamation mark inside it.

Below the sections, there are two references:
- Eddie Harmon-Jones and Judson Mills. 2019. An introduction to cognitive dissonance theory and an overview of current perspectives on the theory. Cognitive dissonance: Reexamining a pivotal theory in psychology.
- Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, and H Andrew Schwartz. 2023. Discourse-level representations can improve prediction of degree of anxiety. In 9 Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="956">The image contains a slide titled "Why dissonance?" with four sections, each illustrating different aspects of cognitive dissonance theory and its applications:

1. **Effects of disagreement**: Depicted with two stick figures pointing at each other, indicating a disagreement.
2. **Entry and Exit from Extremism**: Illustrated with a person standing on a pile of people, suggesting the influence of group dynamics on individual behavior.
3. **Attitudes and Belief trends**: Represented by a graph showing an upward trend, indicating changes in attitudes or beliefs over time.
4. **Anxiety disorders**: Shown with a head silhouette with an exclamation mark, symbolizing anxiety.

Below the sections, there are references to academic papers:
- Eddie Harmon-Jones and Judson Mills. 2019. An introduction to cognitive dissonance theory and an overview of current perspectives on the theory. Cognitive dissonance: Reexamining a pivotal theory in psychology.
- Swanie Jung, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, and H Andrew Schwartz. 2023. Discourse-level representations can improve prediction of degree of anxiety. In Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="957">The image appears to be a slide from a presentation about annotations, likely related to natural language processing or sentiment analysis. Here's a breakdown of the content:

1. **Title**: Annotations
2. **Flowchart**:
   - **Step 1: Good parsing quality?**
     - Yes → Step 2: Dissonance?
     - No → Step 3: Consonance?
3. **Step 2: Dissonance?**
   - Yes → Dissonance (~3.5%)
   - No → Step 3: Consonance?
4. **Step 3: Consonance?**
   - Yes → Consonance (~48%)
   - No → Neither (~48%)

5. **Example Tweet**:
   - **User**: @user_handle
   - **Tweet**: "Wish I could hold grudges but I guess it’s a good thing that I can’t at the same time."
6. **Annotations**:
   - The tweet is annotated with "Dissonance" as indicated by the flowchart.

7. **Additional Notes**:
   - The bottom left corner has a Twitter logo with the word "PARSE."
   - The bottom right corner has the number "11," likely indicating this is slide 11.
   - There is a note at the bottom: "*Check paper for detailed annotation guidelines."

The presenter seems to be explaining how tweets are annotated based on certain criteria (dissonance and consonance) and the percentage distribution of these annotations.</sample>
    <sample id="958">The slide discusses an annotation process for text data, specifically focusing on the analysis of tweets. The flowchart outlines three steps:

1. **Step 1: Good parsing quality?**
   - If yes, proceed to Step 2.
   - If no, annotate as "Neither."

2. **Step 2: Dissonance?**
   - If yes, annotate as "Dissonance."
   - If no, proceed to Step 3.

3. **Step 3: Consonance?**
   - If yes, annotate as "Consonance."
   - If no, annotate as "Neither."

The slide provides percentages for each category:
- Dissonance: ~3.5%
- Consonance: ~48%
- Neither: ~48%

An example tweet is shown:
"User @user_handle: Wish I could hold grudges but I guess it's a good thing that I can't at the same time."

The tweet is annotated with "Dissonance," indicating that the sentiment expressed does not align with the overall tone of the statement.</sample>
    <sample id="959">The slide discusses an annotation process for text data, specifically focusing on the analysis of tweets. The flowchart outlines three steps:

1. **Step 1: Good parsing quality?**
   - If the parsing quality is good, proceed to Step 2.
   - If not, the annotation ends here.

2. **Step 2: Dissonance?**
   - If dissonance is detected, annotate as "Dissonance."
   - If not, proceed to Step 3.

3. **Step 3: Consonance?**
   - If consonance is detected, annotate as "Consonance."
   - If neither, annotate as "Neither."

The example tweet provided is:
"**Wish I could hold grudges but I guess it's a good thing that I can't at the same time.**"

The text "I can't at the same time" is highlighted in blue, indicating it was annotated as "Dissonance." The percentages next to each outcome (3.5%, 48%, and 48%) suggest the frequency of each annotation type based on the dataset.

At the bottom of the slide, there is a note: "*Check paper for detailed annotation guidelines."</sample>
    <sample id="960">The text in the image says:

"Training on Initial Annotated Set

RoBERTA-base + classifier head
TRAIN

init dataset
Area under the ROC curve (AUC)

Small annotated dataset:
43/901 dissonance;
not better than chance"

This appears to be a slide from a presentation discussing the performance of a model trained on an initial annotated set using RoBERTA-base with a classifier head. The area under the ROC curve (AUC) is shown, and it indicates that the small annotated dataset resulted in 43 out of 901 dissonances, which is not better than chance.</sample>
    <sample id="961">The text in the image says:

"Training on Initial Annotated Set

RoBERTA-base + classifier head
TRAIN

init dataset

Small annotated dataset:
43/901 dissonance;
not better than chance"

This appears to be a slide from a presentation discussing the performance of a model trained on an initial annotated set using RoBERTA-base with a classifier head. The area under the ROC curve (AUC) is shown, and it indicates that the small annotated dataset resulted in 43 out of 901 dissonances, which is not better than chance.</sample>
    <sample id="962">The image is a slide from a presentation titled "Method: Transfer and Active Learning for Annotating Rare Class." The slide outlines a process for annotating rare classes using transfer learning and active learning techniques. Here's a breakdown of the content:

1. **Initial Model: Transfer Learning**
   - Starts with an initial model trained on a large dataset.

2. **Cumulative (CM)**
   - New data is added to the old data.
   - The model is retrained on this cumulative dataset.
   - This process is iterative, as shown by the arrows indicating the flow of new data and the retraining of the model.

3. **Iterative (IT)**
   - Similar to Cumulative, but the model is fine-tuned rather than retrained from scratch.
   - New data is added to the old data.
   - The model is fine-tuned on this updated dataset.
   - This process is also iterative.

4. **Acquisition Strategy: Which are 'best' to label?**
   - The strategy involves selecting which examples are most informative or "best" to label.
   - These selected examples are then annotated by humans.

5. **Active Learning Iteration**
   - The annotated examples are used to update the model.
   - The updated model is then used to predict labels for new examples.
   - This process is iterative, as indicated by the arrows showing the flow of new examples being added and the model being updated.

6. **Rare class annotation ~ "needle in a haystack"**
   - This metaphor suggests that finding rare classes is challenging, akin to finding a needle in a haystack.
   - The goal is to increase the chance of correctly identifying these rare classes.

7. **Humans annotate**
   - Humans are involved in the labeling process, providing annotations for the selected examples.

8. **Add new examples**
   - New examples are continuously added to the dataset, which is then used to train and update the model.

The slide is numbered 13, indicating it is part of a larger presentation.</sample>
    <sample id="963">The image contains a slide titled "Cold-start Annotations: Transfer Learning." The slide outlines a process involving transfer learning, cumulative (CM), and iterative (IT) methods for model retraining/update. It also discusses an acquisition strategy to increase the chance of rare class annotation, which is described as "needle in a haystack" due to its difficulty.

The flowchart on the slide shows:
1. **Initial Model: Transfer Learning** - Starting point.
2. **Cumulative (CM)** - New data is added to old data, trained, and a new model is created.
3. **Iterative (IT)** - New data is fine-tuned with the old model, creating a new model.
4. **Model Retrain/Update** - The model is updated based on new examples.
5. **Active Learning Iteration** - Humans annotate new examples.
6. **Add new examples** - The annotated examples are added back into the loop.

The text at the bottom right corner indicates that this is slide number 14.</sample>
    <sample id="964">The slide is titled "Cold-start Annotations: Transfer Learning." It discusses the use of transfer learning with RoBERTA-base and a classifier head to improve the performance of a model on different datasets. The bar chart shows the Area under the ROC curve (AUC) for various datasets:

- **init dataset**: 0.50 AUC
- **Debate**: +0.12 AUC
- **CE**: +0.10 AUC
- **Debate;CE**: +0.08 AUC

The text explains that the transferred weights after training on combined Debate and CE data are used to improve the model's performance. The references at the bottom cite specific studies related to the datasets used, such as "Debate" and "CE," which are described in the context of their respective research papers.</sample>
    <sample id="965">The slide is titled "Cold-start Annotations: Transfer Learning." It discusses the use of transfer learning with RoBERTA-base and a classifier head to improve the performance of a model on different datasets. The bar chart shows the Area under the ROC curve (AUC) for different training datasets:

- **init dataset**: 0.50 AUC
- **Debate**: +0.12 AUC
- **CE**: +0.10 AUC
- **Debate;CE**: +0.08 AUC

The text explains that the model was trained on an initial dataset, then transferred weights after training on combined Debate and CE data. The references at the bottom cite specific studies related to the datasets used:
- *Debate*: Dissonant stance in debate forums by Vasudha Varadarajan et al., 2022.
- §CE: Comparison and Expansion classes by Rashmi Prasad et al., 2008.

The speaker mentions that the model's performance improves when it is trained on combined Debate and CE data, as indicated by the higher AUC values.</sample>
    <sample id="966">The slide is titled "Cold-start Annotations: Transfer Learning." It discusses the performance of a model trained on different datasets using transfer learning with RoBERTA-base and a classifier head. The bar chart shows the Area under the ROC curve (AUC) for four different datasets:

1. **init dataset**: A small initial dataset with an AUC of approximately 0.5.
2. **Debate**: A dataset focusing on dissonant stances in debate forums, which improves the AUC to around 0.62 (+0.12).
3. **CE**: A dataset focusing on comparison and expansion classes, which improves the AUC to around 0.61 (+0.10).
4. **Debate;CE**: A combined dataset of Debate and CE, which improves the AUC to around 0.60 (+0.08).

The slide also includes a note that the transferred weights were after training on combined Debate and CE data. The references at the bottom cite specific papers related to the datasets used: one for the Debate dataset and another for the CE dataset.</sample>
    <sample id="967">The slide is titled "Cold-start Annotations: Transfer Learning." It discusses the use of RoBERTA-base with a classifier head for training on different datasets and tasks, specifically focusing on the area under the ROC curve (AUC) as a metric for performance.

The slide shows a bar chart with the following categories:
- **init dataset**: The initial dataset used for training.
- **Debate**: Training on the Debate dataset.
- **CE**: Training on the CE dataset.
- **Debate;CE**: Training on both the Debate and CE datasets consecutively.
- **Debate→CE**: Fine-tuning on the Debate dataset after training on the CE dataset.
- **CE→Debate**: Fine-tuning on the CE dataset after training on the Debate dataset.

Each category has an associated AUC value:
- **init dataset**: 0.50
- **Debate**: +0.12
- **CE**: +0.10
- **Debate;CE**: +0.08
- **Debate→CE**: +0.04
- **CE→Debate**: +0.17

The slide also includes references to two papers:
- *Debate*: Dissonant stance in debate forums by Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schulz, and Naoaki Inoue (2022).
- *CE*: Comparison and Expansion classes by Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber (2008).

Additionally, there is a note about fine-tuning on each task consecutively, which is highlighted in a speech bubble.</sample>
    <sample id="968">The image contains a slide titled "Active Learning: Cumulative vs Iterative Update." The slide explains two different approaches to active learning and their processes.

1. **Cumulative (CM) Approach**:
   - Starts with an initial model using transfer learning.
   - New data is added to the old data.
   - The model is trained on this combined dataset.
   - A new model is generated from the training process.

2. **Iterative (IT) Approach**:
   - Starts with an initial model using transfer learning.
   - New data is added to the old data.
   - The model is fine-tuned on this combined dataset.
   - A new model is generated from the fine-tuning process.

The slide also includes a flowchart showing the process of active learning iteration, where humans annotate new examples, which are then added to the dataset, leading to a retrain/update of the model. The cycle continues with the acquisition strategy determining which examples are "best" to label.</sample>
    <sample id="969">The image contains a bar chart titled "Active Learning: Cumulative vs Iterative Update." The chart compares the Area Under the Curve (AUC) for different active learning strategies under two update methods: Cumulative and Iterative. The strategies listed on the x-axis are:

1. Random
2. Entropy
3. CoreSet
4. CAL
5. PRC

The y-axis represents the AUC values, ranging from 0.50 to 0.75.

Each strategy has two bars representing its performance under the Cumulative and Iterative update methods:
- Blue bars represent the Cumulative method.
- Yellow bars represent the Iterative method.

The chart shows that for most strategies, the Cumulative method generally achieves higher AUC values compared to the Iterative method.</sample>
    <sample id="970">The image contains a slide titled "Active Learning: Probability-of-Rare-Class Strategy." The slide explains a process involving active learning, specifically focusing on the probability of rare classes. Here's a breakdown of the content:

1. **Initial Model: Transfer Learning**
   - This section starts with an initial model that uses transfer learning.

2. **Rare Class Annotation ~ "needle in a haystack"**
   - This part highlights the challenge of annotating rare classes, comparing it to finding a needle in a haystack.

3. **Difficult to annotate → Easier to annotate**
   - It suggests that some examples are harder to annotate than others.

4. **Increase chance of rare class?**
   - This question prompts consideration of strategies to increase the likelihood of encountering rare classes.

5. **Acquisition strategy: which are “best” to label?**
   - This section discusses the strategy for selecting which examples are "best" to label, aiming to improve the model's performance.

6. **Model Retrain/Update**
   - The model is retrained or updated based on the new data and annotations.

7. **Active Learning Iteration**
   - The process iterates, with humans annotating new examples and adding them back into the loop.

8. **Humans annotate → Add new examples → Active Learning Iteration → Model Retrain/Update**
   - This cycle shows the continuous feedback loop between human annotation and model improvement.

The slide also includes two flowcharts labeled "Cumulative (CM)" and "Iterative (IT)," which detail the steps involved in the cumulative and iterative processes of active learning.</sample>
    <sample id="971">The image contains a slide titled "Active Learning: Probability-of-Rare-Class Strategy." The slide explains an active learning process focused on annotating rare classes, which are often referred to as "needles in a haystack" due to their scarcity in data.

### Key Elements of the Slide:

1. **Initial Model: Transfer Learning**
   - Starts with an initial model trained using transfer learning techniques.
   - The model is then used to annotate new examples.

2. **Rare Class Annotation**
   - Described as "needle in a haystack," indicating the difficulty in finding and annotating rare classes.
   - The process involves identifying which examples are "best" to label based on their probability of being a rare class.

3. **Acquisition Strategy**
   - The strategy aims to increase the chance of selecting rare classes for annotation.
   - Humans annotate the selected examples.

4. **Model Retrain/Update**
   - After annotation, the model is retrained or updated with the newly annotated data.
   - This process is iterative, with the cycle repeating until the desired level of accuracy is achieved.

5. **Comparison of Active Learning Strategies (AUCs)**
   - The slide includes a comparison of different active learning strategies, showing their performance metrics (AUCs).
   - Strategies compared include:
     - Baseline (from scratch)
     - Transferred model
     - AL-Random
     - AL-Entropy
     - AL-CoreSet
     - AL-CAL

6. **Performance Metrics**
   - The AUC values for each strategy are shown, with AL-CAL performing the best at +0.70.

The slide number is 19, and it appears to be part of a larger presentation on active learning methods.</sample>
    <sample id="972">The image shows a slide titled "Active Learning: Probability-of-Rare-Class Strategy" with a bar chart comparing different active learning strategies based on Area Under the Curve (AUC). The chart is labeled "Active Learning Strategy Comparison (AUCs)" and includes the following strategies:

1. Baseline: from scratch - 0.50 AUC
2. Transferred model - 0.67 AUC (+0.17)
3. AL-Random - 0.65 AUC (+0.15)
4. AL-Entropy - 0.70 AUC (+0.20)
5. AL-CoreSet - 0.69 AUC (+0.19)
6. AL-CAL - 0.69 AUC (+0.19)
7. AL-PRC (ours) - 0.71 AUC (+0.21)

The slide number is indicated as 21 in the bottom right corner.</sample>
    <sample id="973">The image contains a slide titled "Active Learning: Probability-of-Rare-Class Strategy." It presents a bar chart comparing the Active Learning Strategy Comparison (AUCs) for different strategies. The strategies listed are:

1. Baseline: from scratch
2. Transferred model
3. AL-Random
4. AL-Entropy
5. AL-CoreSet
6. AL-CAL
7. AL-PRC (ours)
8. Final Model (best transfer model + cumulative new data)

The AUC values for each strategy are as follows:
- Baseline: from scratch: 0.50
- Transferred model: 0.67 (+0.17)
- AL-Random: 0.65 (+0.15)
- AL-Entropy: 0.70 (+0.20)
- AL-CoreSet: 0.69 (+0.19)
- AL-CAL: 0.69 (+0.19)
- AL-PRC (ours): 0.71 (+0.21)
- Final Model (best transfer model + cumulative new data): 0.75 (+0.25)

The slide number is indicated as 22 in the bottom right corner.</sample>
    <sample id="974">The slide is titled "Active Learning: Probability-of-Rare-Class Strategy." It presents a table comparing different active learning strategies based on their characteristics:

- **Rare %**: The percentage of rare classes.
- **Time (s)**: The time taken for annotation.
- **Subj. diff.**: Subjective difference.

The strategies listed are:
- RANDOM: 3.20% rare, 11.96 seconds, -0.065 subjective difference.
- ENTROPY: 6.80% rare, 12.78 seconds, 0.035 subjective difference.
- CORESET: 6.00% rare, 11.89 seconds, 0.039 subjective difference.
- CAL: 4.80% rare, 11.88 seconds, -0.045 subjective difference.
- PRC: 7.60% rare, 13.55 seconds, 0.071 subjective difference.

Below the table, there are three bullet points:
- Minimum annotation cost does not necessarily lead to better models.
- Rarity could make the annotations more difficult; cognitive dissonance is one such class.
- To increase dissonance samples, PRC works the best.</sample>
    <sample id="975">The image contains a slide with the title "Takeaways" and several bullet points and diagrams related to machine learning and data annotation techniques. Here is the text from the slide:

- **Rare class annotation ~ "needle in a haystack"**
- **PRC is simple &amp; efficient for rare sample acquisition**
- **Cold-start AL with transfer learning**
- **Out-of-domain: Iterative**
  - \( M_0 \)
  - \( M_1 \)
  - \( M_2 \)
  - \( M_3 \)
- **In-domain: Cumulative**
  - \( M_0 \)
  - \( M_1 \)
  - \( M_2 \)
  - \( M_3 \)

The slide also includes a diagram on the left side showing a neural network with the label "Cold-start AL with transfer learning." The slide number is indicated as 24 in the bottom right corner.</sample>
    <sample id="976">The image contains a slide with the title "Takeaways" and several visual elements and text descriptions related to machine learning and data annotation techniques. Here is the content written on the slide:

1. **Top Section:**
   - "Rare class annotation ~ 'needle in a haystack'"
   - "PRC is simple &amp; efficient for rare sample acquisition"

2. **Left Section:**
   - "Cold-start AL with transfer learning"
   - An illustration of a neural network with blue snowflake-like patterns.

3. **Middle Section:**
   - "Out-of-domain: Iterative"
   - A diagram showing a sequence of models \( M_0 \), \( M_1 \), \( M_2 \), and \( M_3 \) with arrows indicating iterative updates or transitions between them.

4. **Right Section:**
   - "In-domain: Cumulative"
   - A diagram showing multiple models \( M_0 \), \( M_1 \), \( M_2 \), and \( M_3 \) with arrows pointing from \( M_0 \) to each subsequent model, indicating a cumulative process.

The slide number at the bottom right corner is 24.</sample>
    <sample id="977">The English content in the image says:

"Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge

Contact: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu

Code:
https://github.com/humanlab/rare-class-AL

Dataset:
https://github.com/humanlab/dissonance-twitter-dataset

Paper:
https://arxiv.org/abs/2305.02459

Thank you!"</sample>
    <sample id="978">BART-FID-RAG, Blender2, Emora, and Blender-Decode.</sample>
    <sample id="979">There are seven authors involved in the paper.</sample>
    <sample id="980">A good planner should be able to inherit abstract goals and handle multi-faceted constraints effectively.</sample>
    <sample id="981">There are eight authors involved in the paper.</sample>
    <sample id="982">The name of the speaker is Vasudha Varadarajan.</sample>
    <sample id="983">The authors, Adam Przepiórkowski and Michał Woźniak, are affiliated with the Institute of Computer Science, Polish Academy of Sciences, located at ul. Jana Kazimierza 5, 01-248 Warsaw.</sample>
    <sample id="984">XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations

Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang

PennState
amazon</sample>
    <sample id="985">Semantic Parsing

- Semantic Parsing is a task to build semantic representation of the user queries, such as SQL, and Lambda Calculus.

Which countries in Europe have at least 3 car manufacturers?

SELECT T1.country_name
FROM countries AS T1 JOIN continents AS T2 ON T1.continent = T2.cont_id
JOIN car_makers AS T3 ON T1.country_id = T3.country
WHERE T2.continent = 'Europe'
GROUP BY T1.country_name
HAVING COUNT(*) &gt;= 3

what players made less than three assists over a season?

(call SW.listValue ( call
SW.getProperty ( ( lambda s ( call
SW.filter( var s ) ( call
SW.ensureNumericProperty ( string num_assists ) ) (string &lt; ) ( call
SW.ensureNumericEntity ( number 3 assist ) ) ) (call SW.domain ( string player ) ) ) ( string player )
)
)</sample>
    <sample id="986">Cross-lingual Semantic Parsing
- Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations</sample>
    <sample id="987">Cross-lingual Semantic Parsing
- Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations</sample>
    <sample id="988">Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain natural language</sample>
    <sample id="989">Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain natural language</sample>
    <sample id="990">Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain meaning representation

English
German
Chinese

Neural Models

SQL
Lambda
FunQL</sample>
    <sample id="991">Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain meaning representation

English
German
Chinese

Neural Models

SQL
Lambda
FunQL</sample>
    <sample id="992">Cross-lingual Semantic Parsing

- Existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications. For instance:
  o Lack of coverage on certain neural model</sample>
    <sample id="993">XSemPLR
- We provide a unified dataset XSemPLR for cross-lingual semantic parsing in multiple natural languages and meaning representations. It contains:
  o 9 datasets in various domains
  o 5 semantic parsing tasks.
  o 8 meaning representations
  o 22 natural languages in 15 language families</sample>
    <sample id="994">XSemPLR
- We provide a unified dataset XSemPLR for cross-lingual semantic parsing in multiple natural languages and meaning representations. It contains:
  o 9 datasets in various domains
  o 5 semantic parsing tasks.
  o 8 meaning representations
  o 22 natural languages in 15 language families</sample>
    <sample id="995">Experiment Settings
- We consider the six settings for training and evaluation.
  ○ Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval.

Training
- English
  - English Model
  - SQL

Inference
- German
  - Translate API
  - English
  - English Model
  - SQL</sample>
    <sample id="996">Experiment Settings
- We consider the six settings for training and evaluation.
  ○ Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval.

Training
- English
  - English Model
    - SQL

Inference
- German
  - Translate API
  - English
    - English Model
      - SQL</sample>
    <sample id="997">Experiment Settings
- We consider the six settings for training and evaluation.
  ○ Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval.

Training
- English
  - English Model
    - SQL

Inference
- German
  - Translate API
  - English
    - English Model
      - SQL</sample>
    <sample id="998">Experiment Settings
- We consider the six settings for training and evaluation.
  ○ Monolingual Model: Source language is the same as target language, e.g., German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.

Training
![German (Few-shot) → German Model → SQL](https://i.imgur.com/3Q5z5QG.png)

Inference
![German → German Model → SQL](https://i.imgur.com/3Q5z5QG.png)</sample>
    <sample id="999">Experiment Settings
- We consider the six settings for training and evaluation.
  ○ Monolingual Model: Source language is the same as target language, e.g., German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.

Training
![German (Few-shot) → German Model → SQL](German_Few_shot_to_SQL.png)

Inference
![German → German Model → SQL](German_to_SQL.png)</sample>
    <sample id="1000">Experiment Settings
- We consider the six settings for training and evaluation.
  ○ Monolingual Model: Source language is the same as target language, e.g., German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.

Training
![German (Few-shot) → German Model → SQL](https://i.imgur.com/3Q5z5QG.png)

Inference
![German → German Model → SQL](https://i.imgur.com/3Q5z5QG.png)</sample>
    <sample id="1001">Experiment Settings
- We consider the six settings for training and evaluation.
  o Multilingual Model: Train one multilingual model for all languages.

Training
- German
- English
- Chinese
  Multilingual Model
  SQL

Inference
- German
  Multilingual Model
  SQL</sample>
    <sample id="1002">Experiment Settings
- We consider the six settings for training and evaluation.
  o Multilingual Model: Train one multilingual model for all languages.

Training
- German
- English
- Chinese
  Multilingual Model
  SQL

Inference
- German
  Multilingual Model
  SQL</sample>
    <sample id="1003">Experiment Settings
- We consider the six settings for training and evaluation.
  o Multilingual Model: Train one multilingual model for all languages.

Training
- German
- English
- Chinese
  Multilingual Model
  SQL

Inference
- German
  Multilingual Model
  SQL</sample>
    <sample id="1004">Experiment Settings
- We consider the six settings for training and evaluation.
  ○ Cross-lingual Zero-shot/Few-shot transfer: Train on one source language and transfer to another language.

Training
- English
- Or
- German Few-shot

Inference
- German
- Multilingual Model
- SQL</sample>
    <sample id="1005">Experiment Settings
- We consider the six settings for training and evaluation.
  ○ Cross-lingual Zero-shot/Few-shot transfer: Train on one source language and transfer to another language.

Training
- English
- Or
- German Few-shot

Inference
- German
- Multilingual Model
- SQL</sample>
    <sample id="1006">```
Analysis of Monolingual

- We evaluate on two groups of models on Monolingual Setting
  - Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders
    * XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilingual Pretrained Encoder-Decoder Models
    * mBART, mT5

- We found Enc-Dec (mT5) obtains the best performance on all datasets!
```</sample>
    <sample id="1007">Analysis of Monolingual

- We evaluate on two groups of models on Monolingual Setting
  - Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilingual Pretrained Encoder-Decoder Models
    - mBART, mT5

- We found Enc-Dec (mT5) obtains the best performance on all datasets!</sample>
    <sample id="1008">Analysis of Monolingual

- We evaluate on two groups of models on Monolingual Setting
  - Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilingual Pretrained Encoder-Decoder Models
    - mBART, mT5

- We found Enc-Dec (mT5) obtains the best performance on all datasets!</sample>
    <sample id="1009">```
Analysis of Monolingual

- We evaluate on two groups of models on Monolingual Setting
  - Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders
    ■ XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilingual Pretrained Encoder-Decoder Models
    ■ mBART, mT5

- We found Enc-Dec (mT5) obtains the best performance on all datasets!
```</sample>
    <sample id="1010">Analysis of Multilingual Training

- We evaluate on mT5 and XLM-R + PTR on Multilingual Setting
  - Enc-Dec/Enc-PTR (mT5/XLM-R) can be improved by training in a mixture of various languages.

| Monolingual | MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa² | Average |
|-------------|-------|-----------|---------|----------|------------|------|-------------|------|-----------|---------|
| XLM-R+PTR   | 31.31 | 71.41     | 47.30   | 85.17    | 59.10      | 23.53 | 62.37       | 80.36 | 7.69      | 52.03   |
| mT5         | 53.15 | 74.26     | 50.73   | 91.65    | 66.29      | 30.15 | 65.16       | 81.83 | 10.29     | 58.16   |

| Multilingual | MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa² | Average |
|--------------|-------|-----------|---------|----------|------------|------|-------------|------|-----------|---------|
| XLM-R+PTR   | 39.72 | 71.35     | 40.20   | 85.91    | 61.03      | 30.79 | 61.82       | 81.68 | –         | 59.06   |
| mT5         | 54.45 | 76.57     | 32.30   | 91.31    | 67.55      | 28.51 | 60.92       | 82.95 | –         | 61.82   |

13</sample>
    <sample id="1011">Analysis of Multilingual Training

- We evaluate on mT5 and XLM-R + PTR on Multilingual Setting
  - Enc-Dec/Enc-PTR (mT5/XLM-R) can be improved by training in a mixture of various languages.

| Monolingual | MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa² |
|-------------|-------|-----------|---------|----------|-----------|------|------------|------|-----------|
| XLM-R+PTR  | 31.31 | 71.41     | 47.30   | 85.17    | 59.10     | 23.53 | 62.37      | 80.36 | 7.69      |
| mT5         | 53.15 | 74.26     | 50.73   | 91.65    | 66.29     | 30.15 | 65.16      | 81.83 | 10.29     |

| Multilingual | MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa² |
|--------------|-------|-----------|---------|----------|-----------|------|------------|------|-----------|
| XLM-R+PTR   | 39.72 | 71.35     | 40.20   | 85.91    | 61.03     | 30.79 | 61.82      | 81.68 | –          |
| mT5         | 54.45 | 76.57     | 32.30   | 91.31    | 67.55     | 28.51 | 60.92      | 82.95 | –          |

Average | 52.03 | 59.06     | 58.16   | 61.82    | 61.82     | 30.79 | 61.82      | 81.68 | –          |

13</sample>
    <sample id="1012">Analysis of Multilingual Training

- We evaluate on mT5 and XLM-R + PTR on Multilingual Setting
  - Most of the major NLs can obtain performance gain, except that English performance drops in 7 datasets and gains in 3 datasets.
  - This is known as "Curse of Multilinguality"

Increase = Increase
Decrease = Decrease

Natural Languages
Number of Datasets</sample>
    <sample id="1013">Analysis of Multilingual Training

- We evaluate on mT5 and XLM-R + PTR on Multilingual Setting
  - Most of the major NLs can obtain performance gain, except that English performance drops in 7 datasets and gains in 3 datasets. This is known as "Curse of Multilinguality"

Increase = Increase
Decrease = Decrease

Natural Languages
Number of Datasets</sample>
    <sample id="1014">Cross-lingual Performance Gap

- Blue Line: Cross-lingual Few-shot transfer
- Orange Line: Cross-lingual Zero-shot transfer
- Green Line: Monolingual Setting</sample>
    <sample id="1015">Cross-lingual Performance Gap

- Blue Line: Cross-lingual Few-shot transfer
- Orange Line: Cross-lingual Zero-shot transfer
- Green Line: Monolingual Setting</sample>
    <sample id="1016">Cross-lingual Performance Gap

- green - orange For zero-shot setting, the cross-lingual transfer performance gap is significant
- blue - orange For few-shot setting, the transfer gap is shortened rapidly</sample>
    <sample id="1017">Other Results &amp; Findings (Section 4 in Paper)
- Enc-Dec (mT5) outperforms previous work or achieves comparable results.
- Pretraining on the English NL can significantly boost the performance of few-shot on target NLs.
- Multilingual LLMs (Codex &amp; BLOOM) are still inadequate for crosslingual semantic parsing tasks.
- Chinese transfer learning and English monolingual training (En -&gt; En) has the largest performance gap, while German usually has the smallest.
- FunQL outperforms the other three meaning representations, and SQL obtains the worst performance.</sample>
    <sample id="1018">Other Results &amp; Findings (Section 4 in Paper)
- Enc-Dec (mT5) outperforms previous work or achieves comparable results.
- Pretraining on the English NL can significantly boost the performance of few-shot on target NLs.
- Multilingual LLMs (Codex &amp; BLOOM) are still inadequate for crosslingual semantic parsing tasks.
- Chinese transfer learning and English monolingual training (En -&gt; En) has the largest performance gap, while German usually has the smallest.
- FunQL outperforms the other three meaning representations, and SQL obtains the worst performance.</sample>
    <sample id="1019">```
Conclusion
- We build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations.
- We conduct a comprehensive benchmark study on three representative types of multilingual language models.
- Our results show that mT5 with monolingual training yields the best performance, while notably multilingual LLMs are still inadequate to perform cross-lingual semantic parsing tasks. Moreover, the performance gap between monolingual training and cross-lingual transfer learning is still significant.
```</sample>
    <sample id="1020">**Conclusion**

- We build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations.
- We conduct a comprehensive benchmark study on three representative types of multilingual language models.
- Our results show that mT5 with monolingual training yields the best performance, while notably multilingual LLMs are still inadequate to perform cross-lingual semantic parsing tasks. Moreover, the performance gap between monolingual training and cross-lingual transfer learning is still significant.

**Links**

Welcome to visit our paper and code!

Paper Link: [https://arxiv.org/pdf/2306.04085.pdf](https://arxiv.org/pdf/2306.04085.pdf)

Code Link: [https://github.com/psunlpgroup/xsemplr](https://github.com/psunlpgroup/xsemplr)</sample>
    <sample id="1021">The most common errors of PaLM, according to the insights from MQM, are dominated by "Accuracy/Omission" and generally lower in terms of "Style/Awkwardness."</sample>
    <sample id="1048">Emory University, Emory NLP Research Lab, Alexa.</sample>
    <sample id="1049">Continuous fine-tuning.</sample>
    <sample id="1050">There are seven authors involved in the paper.</sample>
    <sample id="1084">The name of the speaker is Yusen Zhang.</sample>
    <sample id="1085">#ACL2023
From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models

Shangbin Feng
Chan Young Park
Yuhan Liu
Yulia Tsvetkov

PAUL G. ALLEN SCHOOL
UW NLP
Carnegie Mellon University Language Technologies Institute
Tsinghua University</sample>
    <sample id="1086">LM Training Data
A mixed blessing

Website
patents.google.com
en.wikipedia.org
en.m.wikipedia.org
www.nytimes.com
www.latimes.com
www.theguardian.com
journals.plos.org
www.forbes.com
hubspot.com
patents.com
www.scribbl.com
www.washingtonpost.com
www.fool.com
ipfs.io
www.frontiersin.org
www.businessinsider.com
www.chicagotribune.com
www.booking.com
www.theatlantic.com
look.springer.com
www.aljazeera.com
www.kickstarter.com
caselaw.findlaw.com
www.ncbi.nlm.nih.gov
www.npr.org

# tokens (log scale)
10^7
10^6
10^5

Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.</sample>
    <sample id="1087">LM Training Data
A mixed blessing

Website
patents.google.com
en.wikipedia.org
en.m.wikipedia.org
www.nytimes.com
www.latimes.com
www.theguardian.com
journals.plos.org
www.forbes.com
hubspot.com
patents.com
www.scribd.com
www.washingtonpost.com
www.fool.com
ipfs.io
www.frontiersin.org
www.businessinsider.com
www.chicagotribune.com
www.booking.com
www.theatlantic.com
look.springer.com
www.aljazeera.com
www.kickstarter.com
caselaw.findlaw.com
www.ncbi.nlm.nih.gov
www.npr.org

# tokens (log scale)
10^7
10^8
10^9

Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.</sample>
    <sample id="1088">LM Training Data
A mixed blessing

Website
patents.google.com
en.wikipedia.org
en.m.wikipedia.org
www.nytimes.com
www.latimes.com
www.theguardian.com
journals.plos.org
www.forbes.com
hubspot.com
patents.com
www.scribd.com
www.washingtonpost.com
www.fool.com
ipfs.io
www.frontiersin.org
www.businessinsider.com
www.chicagotribune.com
www.wired.com
www.theatlantic.com
look.springer.com
www.aljazeera.com
www.kickstarter.com
caselaw.findlaw.com
www.ncbi.nlm.nih.gov
www.npr.org

# tokens (log scale)
10^7
10^8
10^9

Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.</sample>
    <sample id="1089">LM Training Data
A mixed blessing

Website
patents.google.com
en.wikipedia.org
en.m.wikipedia.org
www.nytimes.com
www.latimes.com
www.theguardian.com
journals.plos.org
www.forbes.com
hubspot.com
patents.com
www.scribd.com
www.washingtonpost.com
www.fool.com
ipfs.io
www.frontiersin.org
www.businessinsider.com
www.chicagotribune.com
www.wired.com
www.theatlantic.com
link.springer.com
www.aljazeera.com
www.kickstarter.com
caselaw.findlaw.com
www.ncbi.nlm.nih.gov
www.npr.org

# tokens (log scale)
10^7
10^8
10^9

Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.

To this end
Pretraining data
Language models
Downstream tasks</sample>
    <sample id="1090">To this end

Pretraining data
Language models
Downstream tasks

How to evaluate the political leaning of LMs?
What role does pretraining data play in such political biases?

How do LMs with different political leanings perform?
Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="1091">To this end

Pretraining data
Language models
Downstream tasks

How to evaluate the political leaning of LMs?
What role does pretraining data play in such political biases?

How do LMs with different political leanings perform?
Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="1092">To this end

Pretraining data
Language models
Downstream tasks

How to evaluate the political leaning of LMs?
What role does pretraining data play in such political biases?

How do LMs with different political leanings perform?
Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="1093">Evaluating LM Political Leaning

Support both encoder and decoder LMs

"statement&gt; I &lt;mask&gt; with this statement."
"Do you agree or disagree with this statement? &lt;statement&gt;"

Automatic eval
Grounded in polisci lit

Political Compass Test
Language Model
Prompted Response
Political Leaning
Left
Libertarian
Right
Authoritarian
Agree
Disagree

Q: Our race has many superior qualities, compared with other races.

Existing LMs
BERT-base
BERT-large
RoBERTa-base
RoBERTa-large
distilBERT
distilRoBERTa
ALBERT-base
ALBERT-large
BART-base
BART-large
Alpaca
Codex
LLaMA
GPT-2
GPT-3-ada
GPT-3-babbage
GPT-3-curious
GPT-3-davinci
ChatGPT
GPT-4
GPT-J</sample>
    <sample id="1094">Existing LMs

BERT-base
BERT-large
RoBERTa-base
RoBERTa-large
distilBERT
distilRoBERTa
ALBERT-base
ALBERT-large
BART-base
BART-large
Alpaca

Codex
LLaMA
GPT-2
GPT-3-ada
GPT-3-babbage
GPT-3-curie
GPT-3-davinci
ChatGPT
GPT-4
GPT-J

Left
Authoritarian
Social axis
economic axis
Right
Libertarian</sample>
    <sample id="1095">Existing LMs

Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning

Shen, Qinlan, and Carolyn Rose. "Politics: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection." Findings of the Association for Computational Linguistics: NAACL 2022.

Social Media Data</sample>
    <sample id="1096">Pretraining Data

Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning

News Media
- left
- center
- right

Social Media (Reddit)
- left
- center
- right</sample>
    <sample id="1097">Pretraining Data

Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning

News Media
- left
- center
- right

Social Media (Reddit)
- left
- center
- right

Liu, Yujian, et al. "POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection." Findings of the Association for Computational Linguistics: NAACL 2022.

Shen, Qinlan, and Carolyn Rose. "What sounds 'right' to me? experiential factors in the perception of political ideology." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="1098">Results
Partisan shifts in LM political leaning

RoBERTa
GPT-2
Left
Center
Right</sample>
    <sample id="1099">Results
Partisan shifts in LM political leaning

RoBERTa
GPT-2
Left
Center
Right</sample>
    <sample id="1100">Results
Partisan shifts in LM political leaning

RoBERTa
Reddit
Original
News

GPT-2
Reddit
Original
News

Delta = (-0.13, -1.03)
Delta = (-2.13, 0.06)
Delta = (0.75, -3.64)
Delta = (-1.75, 1.03)
Delta = (0.37, 0.00)
Delta = (-1.00, 1.64)</sample>
    <sample id="1101">The Trump Card
Pre-45th to post-45th shift

RoBERTa
Δ = (-2.75, -1.24)
Δ = (-0.13, -1.03)
Δ = (1.63, 1.03)
Δ = (0.75, -3.64)
Δ = (-0.50, -3.64)
Δ = (-1.75, 0.92)

GPT-2
Δ = (-2.37, -0.51)
Δ = (-0.12, 1.28)
Δ = (-2.13, 0.06)
Δ = (-1.75, 1.03)
Δ = (0.37, 0.00)
Δ = (-1.00, 1.64)</sample>
    <sample id="1102">The Trump Card

Pre-45th to post-45th shift

RoBERTa
Δ = (-2.75, -1.24)
news left
news center
news right
reddit left
reddit center
reddit right

GPT-2
Δ = (-2.37, -0.51)
Δ = (-0.12, 1.28)
Δ = (-2.13, 0.06)
Δ = (0.75, -3.64)
Δ = (0.37, 0.00)
Δ = (-1.75, 1.64)</sample>
    <sample id="1103">The Trump Card

Pre-45th to post-45th shift

RoBERTa
Δ = (-2.75, -1.24)
Δ = (-0.13, -1.03)
Δ = (1.63, 1.03)
Δ = (0.75, -3.64)
Δ = (-0.50, -3.64)
Δ = (-1.75, 0.92)

GPT-2
Δ = (-2.37, -0.51)
Δ = (-0.12, 1.28)
Δ = (-2.13, 0.06)
Δ = (-1.75, 1.03)
Δ = (0.37, 0.00)
Δ = (-1.00, 1.64)</sample>
    <sample id="1104">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|-----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30     | 82.35   | 96.30 |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43     | 91.18   | 96.30 |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13     | 82.35   | 92.59 |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78     | 85.29   | 96.30 |</sample>
    <sample id="1105">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10    | 92.86    | 91.30    | 82.35   | 96.30  |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66    | 96.43    | 80.43    | 91.18   | 96.30  |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51    | 85.71    | 89.13    | 82.35   | 92.59  |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95    | 96.43    | 84.78    | 85.29   | 96.30  |</sample>
    <sample id="1106">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10    | 92.86    | 91.30    | 82.35   | 96.30  |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66    | 96.43    | 80.43    | 91.18   | 96.30  |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51    | 85.71    | 89.13    | 82.35   | 92.59  |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95    | 96.43    | 84.78    | 85.29   | 96.30  |</sample>
    <sample id="1107">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|--------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30    | 82.35  | 96.30 |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43    | 91.18  | 96.30 |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13    | 82.35  | 92.59 |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78    | 85.29  | 96.30 |</sample>
    <sample id="1108">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|--------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30    | 82.35  | 96.30 |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43    | 91.18  | 96.30 |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13    | 82.35  | 92.59 |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78    | 85.29  | 96.30 |</sample>
    <sample id="1109">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|-----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10    | 92.86    | 91.30     | 82.35   | 96.30 |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66    | 96.43    | 80.43     | 91.18   | 96.30 |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51    | 85.71    | 89.13     | 82.35   | 92.59 |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95    | 96.43    | 84.78     | 85.29   | 96.30 |</sample>
    <sample id="1110">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10    | 92.86    | 91.30    | 82.35   | 96.30  |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66    | 96.43    | 80.43    | 91.18   | 96.30  |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51    | 85.71    | 89.13    | 82.35   | 92.59  |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95    | 96.43    | 84.78    | 85.29   | 96.30  |</sample>
    <sample id="1111">Qualitative Analysis

| Text                                                                 | Target Label | Base | N-L | S-L | N-R | S-R |
|---------------------------------------------------------------------|--------------|------|-----|-----|-----|-----|
| the alt right is corrupted with people supporting racemixing with asians and homosexuals it time for a new nationalism | ASIAN        | TRUE  | TRUE | TRUE | FALSE | FALSE |
| What do McDonald's and priest have in common? They both like sticking their meat in 10 year old buns | CHRIS        | TRUE  | FALSE | FALSE | TRUE  | TRUE  |
| (...) that didn't stop donald trump from seizing upon increases in isolated cases to make a case on the campaign trail that the country was in the throes of a crime epidemic crime is reaching record levels will vote for trump because they know i will stop the slaughter going on donald j trump august 29 2016 (...) | RIGHT        | FAKE  | TRUE  | TRUE  | FALSE | FALSE |
| (...) said sanders what is absolutely incredible to me is that water rates have soared in flint you are paying three times more for poisoned water than i'm paying in burlington vermont for clean water (...) | LEFT         | FAKE  | TRUE  | FALSE | TRUE  | FALSE |

Table 5: Examples of the downstream performance of tasks using language models with varying political bias.
CHRIS, Base, N, S, L, R represent Christians, vanilla RoBERTa model, news media, social media, left-leaning, and right-leaning, respectively.</sample>
    <sample id="1112">**Qualitative Analysis**

| Text | Target Label | Base | N-L | S-L | N-R | S-R |
|------|--------------|------|-----|-----|-----|-----|
| the alt right is corrupted with people supporting racemixing with asians and homosexuals it time for a new nationalism | ASIAN | TRUE | TRUE | TRUE | TRUE | FALSE | FALSE |
| What do McDonald's and priest have in common? They both like sticking their meat in 10 year old buns | CHRIS | TRUE | FALSE | FALSE | FALSE | TRUE | TRUE |
| (...) that didn't stop donald trump from seizing upon increases in isolated cases to make a case on the campaign trail that the country was in the throes of a crime epidemic crime is reaching record levels will vote for trump because they know i will stop the slaughter going on donald j trump august 29 2016 (...) | RIGHT | FAKE | FAKE | FAKE | FAKE | TRUE | FALSE |
| (...) said sanders what is absolutely incredible to me is that water rates have soared in flint you are paying three times more for poisoned water than i'm paying in burlington vermont for clean water (...) | LEFT | FAKE | TRUE | FALSE | TRUE | FAKE | FAKE |

Table 5: Examples of the downstream performance of tasks using language models with varying political bias.
CHRIS, Base, N, S, L, R represent Christians, vanilla RoBERTa model, news media, social media, left-leaning, and right-leaning, respectively.

---

**Hate Speech Text**

| Hate? | N-L | R-L | N-R | R-R |
|-------|-----|-----|-----|-----|
| Same-sex marriage doesn't "confound" orthodox Catholics who refer to disparagingly as trads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pay and God's mercy. | TRUE | TRUE | TRUE | FALSE | FALSE |
| got kicked out of facebook again for "numbervdays because i called a mazza alla a pedophile and a pervert no 1st amendment over there the muzzis can call christians anything they want but not the other way around | TRUE | FALSE | FALSE | TRUE | TRUE |
| Idiot Didn't Get A Building Permit? Typical White Guy Rule: It's Easier to Beg for Forgiveness, and then they play the victim card | TRUE | TRUE | TRUE | FALSE | FALSE |
| At 7:19 is why i hate people, women especially look how mad she just got because the dog splashed her. f*** you you stupid b**** either have fun or go kill yourself | TRUE | TRUE | TRUE | FALSE | FALSE |
| Death to catholicism. Should be legal to shoot them. | TRUE | FALSE | FALSE | TRUE | TRUE |
| are you the nazi faggot by the feminine boobs | TRUE | TRUE | TRUE | FALSE | FALSE |
| this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead | TRUE | TRUE | TRUE | FALSE | FALSE |
| What do you call a white guy surrounded by a thousand black guys? a warden | TRUE | TRUE | TRUE | FALSE | FALSE |
| United States of Muslim America It's good to know faggots will still be shot | TRUE | FALSE | FALSE | TRUE | TRUE |
| How do you circumcise a choir boy? Kick the priest in the jaw. | TRUE | FALSE | FALSE | TRUE | TRUE |
| what do you call an indian taking a shit? brownian motion | TRUE | TRUE | TRUE | FALSE | FALSE |
| If I saw this bitch in public I'd slam her on the ground and spit in her face too | TRUE | TRUE | TRUE | FALSE | FALSE |

**Misinformation Text**

| Fake? | N-L | R-L | N-R | R-R |
|-------|-----|-----|-----|-----|
| we also should be aware about we have a 680 billion military budget it is a waste of money and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give a different impression of our economy and health care issues offer a solution to our economy of crisis but ignores critical data that would give</sample>
    <sample id="1113">**Table 12: Qualitative analysis of hate speech examples where LMs with different political leanings beg to differ.**

| Hate Speech Text | Hate? | N-L | R-L | N-R | R-R |
|------------------|------|-----|-----|-----|-----|
| Same-sex marriage doesn't "confound" orthodox Catholics who refer to disparagingly as trads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pay and God's mercy. | TRUE | TRUE✓ | TRUE✓ | FALSE✗ | FALSE✗ |
| got kicked out of facebook again for "counterm- days because I called a mazilla alla a pedophile and a pervert no 1 amendment over there the muzzis can call christians anything they want but not the other way around | TRUE | TRUE✓ | TRUE✓ | FALSE✗ | FALSE✗ |
| Yes. Exactly. Fuck these religitated trash places and burn them to the ground. The Vatican, Israel, everywhere. | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| Idiot Didn't Get A Building Permit! Typical White Guy Rule: It's Easier to Beg for Forgiveness, then they play the victim card. | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| At 7:19 is why I hate people, women especially look how mad she just got because the dog splashed her. f*** you you stupid b**** either have fun or go kill yourself | TRUE | TRUE✓ | TRUE✓ | FALSE✗ | FALSE✗ |
| Death to catholicism. Should be legal to shoot them. | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| are you the nazi faggot with the feminine boobs | TRUE | TRUE✓ | TRUE✓ | FALSE✗ | FALSE✗ |
| this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead | TRUE | TRUE✓ | TRUE✓ | TRUE✓ | FALSE✗ |
| What do you call a white guy surrounded by a thousand black guys? A warden | TRUE | TRUE✓ | TRUE✓ | FALSE✗ | FALSE✗ |
| United States of Muslim America It's good to know faggots will still be shot | TRUE | TRUE✓ | TRUE✓ | FALSE✗ | FALSE✗ |
| How do you circumcise a choir boy? Kick the priest in the jaw. | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| what do you call an indian taking a shit? brownian motion | TRUE | TRUE✓ | TRUE✓ | FALSE✗ | FALSE✗ |
| If I saw this bitch in public I'd slam her on the ground and spit in her face too | TRUE | TRUE✓ | TRUE✓ | FALSE✗ | FALSE✗ |

**Table 13: Qualitative analysis of fake news examples where LMs with different political leanings beg to differ.**

| Misinformation Text | Fake? | N-L | R-L | N-R | R-R |
|---------------------|-------|-----|-----|-----|-----|
| in cities like chicago and bullhead crime in america a larger cities has been rising since trump from rising upon increase in violent cases to make a case on the rise in crime in america. the crime rate in america is reaching record levels will vote for trump because they know will stop the crime. | TRUE | TRUE✓ | TRUE✓ | TRUE✓ | TRUE✓ |
| have the response of our government for violence means refuses to act on federal state acts and standards which is absolutely incredible in me | TRUE | TRUE✓ | TRUE✓ | TRUE✓ | TRUE✓ |
| poisoned water in pa is paying in highdose venom for clean water first | TRUE | TRUE✓ | TRUE✓ | TRUE✓ | TRUE✓ |
| bin laden declares war on emmanuel comman bin laden has called on pak | TRUE | TRUE✓ | TRUE✓ | TRUE✓ | TRUE✓ |
| simplifying the country of the ruling has been paid off by the democrats and one of economy experiments in his own party during the day the primary reason for the economic crisis is the lack of a strong economy and the lack of a strong economy and international terrorism we need to be thinking hard about making | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money and we should be looking at cutting that budget down to a budget continues to fight the cold war with the soviet union very | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| young border crosses from central america and president donald trump a | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether individual mandate is a tax is absolutely not file 2013 the supreme court build in washington d c up to 20 2009 obama | TRUE | FALSE✗ | FALSE✗ | TRUE✓ | TRUE✓ |
| obama on whether</sample>
    <sample id="1114">**Table 12: Qualitative analysis of hate speech examples where LMs with different political leanings beg to differ.**

| Hate Speech Text | Hate? | N-L | R-L | N-R | R-R |
|------------------|------|-----|-----|-----|-----|
| Same-sex marriage doesn't "confound" orthodox Catholics who refer to disparagingly as trads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pity and God's mercy. | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| got kicked out of facebook again for "numb*er-days because I called a muzza alla a pedophile and a pervert no 1 amendment over there the muzzis can call christians anything they want but not the other way around | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| Yes. Exactly. Fuck these religitated trash places and burn them to the ground. The Vatican, Israel, everywhere. | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| Idiot Didn't Get A Building Permit? It's Easier to Beg for Forgiveness, Then they play the victim card! | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| At 7:19 is why I hate people, women especially look how mad she just got because the dog splashed her. f*** you you stupid b**** either have fun or go kill yourself | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| Death to catholicism. Should be legal to shoot them. | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| are you the nazi faggot with the feminine boobs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead | TRUE | TRUE ✓ | TRUE ✓ | TRUE ✓ | TRUE ✓ |
| What do you call a white guy surrounded by a thousand black guys? A warden | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| United States of Muslim America It's good to know faggots will still be shot | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| How do you circumcise a choir boy? Kick the priest in the jaw. | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| what do you call an indian taking a shit? brownian motion | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| If I saw this bitch in public I'd slam her on the ground and spit in her face too | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |

**Table 13: Qualitative analysis of fake news examples where LMs with different political leanings beg to differ.**

| Misinformation Text | Fake? | N-L | R-L | N-R | R-R |
|---------------------|-------|-----|-----|-----|-----|
| in cities like chicago and bulletrade crime in america a largest cities has been rising from spiking increases in intended cases to make a case on the rise in crime in the united states is reaching record levels will vote for trump because they know he will stop the crime and the violence | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| have the resources of state government for whatever reason refuses to act on the issue of crime and the violence | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| federal government acts and sanctions that are absolutely inexcusable in our country | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| poisoned water in pa is paying in highdeed veteran for clean water first | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| bin laden declares we are successful against his leader has been called on pak | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been passed by the democrats and some of the minority opponents in his own party during the day primary | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| we also should be aware about we have a 600 billion military budget it is a waste of money | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| the president of the united states is making a speech during which he declared the crime and the gangs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| simplifying the county of the ruling has been</sample>
    <sample id="1115">**Hate Speech Text**
- Same-sex marriage doesn't "confound" orthodox Catholics who refer to disparagingly as trads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pity and God's mercy.
- got kicked out of facebook again for "counterm- days because I called a mazilla alla a pedophile and a pervert no 1st amendment over there the muzzis can call christians anything they want but not the other way around
- Yes. Exactly. Fuck these religitated trash places and burn them to the ground. The Vatican, Israel, everywhere.
- Idiot Didn't Get A Building Permit? Typical White Guy Rule: It's Easier to Beg for Forgiveness, then they play the victim card.
- At 7:19 is why I hate people, women especially look how mad she just got because the dog splashed her. f*** you you stupid b**** either have fun or go kill yourself
- Death to catholicism. Should be legal to shoot them.
- are you the nazi faggot with the feminine boobs
- this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead
- What do you call a white guy surrounded by a thousand black guys? A warden
- United States of Muslim America It's good to know faggots will still be shot
- How do you circumcise a choir boy? Kick the priest in the jaw.
- what do you call an indian taking a shit? brownian motion
- If I saw this bitch in public I'd slam her on the ground and spit in her face too

**Misinformation Text**
- in cities like chicago and bulwark crime in america a largest cities has been on the rise for years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and</sample>
    <sample id="1116">**Hate Speech Text**
- Same-sex marriage doesn't "confound" orthodox Catholics who refer to disparagingly as trads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pity and God's mercy.
- got kicked out of facebook again for "numb*er-days because I called a mazilla alla a pedophile and a pervert no 1 amendment over there the muzzis can call christians anything they want but not the other way around"
- Yes. Exactly. Fuck these religitated trash places and burn them to the ground. The Vatican, Israel, everywhere.
- Idiot Didn't Get A Building Permit? Typical White Guy Rule: It's Easier to Beg for Forgiveness, then they play the victim card.
- At 7:19 is why I hate people, women especially look how mad she just got because the dog splashed her. F*** you you stupid b**** either have fun or go kill yourself
- Death to catholicism. Should be legal to shoot them.
- are you the nazi faggot with the feminine boobs
- this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead
- What do you call a white guy surrounded by a thousand black guys? A warden
- United States of Muslim America It's good to know faggots will still be shot
- How do you circumcise a choir boy? Kick the priest in the jaw.
- what do you call an indian taking a shit? brownian motion
- If I saw this bitch in public I'd slam her on the ground and spit in her face too

**Misinformation Text**
- In cities like Chicago and Baltimore crime in america a largest cities has been increasing for years. President trump from sitting upon increases in violent cases to make a case on the increase in crime. The president is making a false claim that crime is reaching record levels will vote for trump because they know he will stop the increase in crime. Trump made a false claim about the increase in crime during which he declared the crime and the gangs.
- have the resources of state government for whatever reason refuses to act on the issue of lead in drinking water. The federal government acts and sanctions what is absolutely inexcusable in me opinion. The federal government acts and sanctions what is absolutely inexcusable in my opinion. The federal government acts and sanctions what is absolutely inexcusable in my opinion.
- his lades declare we are in need of more troops his lades have called on pakistani military to help us fight the war in afghanistan his lades have called on pakistani military to help us fight the war in afghanistan his lades have called on pakistani military to help us fight the war in afghanistan.
- simplifying the treaty of the volga has been passed off by democrats and some of romney opponents in his own party during the pre primary debate. Romney opponents in his own party during the pre primary debate. Romney opponents in his own party during the pre primary debate.
- ways modeled after immunization health care law which romney opposes in his own party during the pre primary debate. Ways modeled after immunization health care law which romney opposes in his own party during the pre primary debate.
- how the mandelbaum appears to be working well six years later some of the most important issues that were raised in the debate remain unresolved how the mandelbaum appears to be working well six years later some of the most important issues that were raised in the debate remain unresolved how the mandelbaum appears to be working well six years later some of the most important issues that were raised in the debate remain unresolved.
- we also should be aware about we have a 600 billion military budget it is a waste of money. We also should be aware about we have a 600 billion military budget it is a waste of money. We also should be aware about we have a 600 billion military budget it is a waste of money.

**Discussion**
Between Scylla and Charybdis
To “sanitize” or not to “sanitize”, that is the question

- Pretraining data
- Language models
- Downstream tasks</sample>
    <sample id="1117">Discussion

Between Scylla and Charybdis

To "sanitize" or not to "sanitize", that is the question

Pretraining data → Language models → Downstream tasks</sample>
    <sample id="1118">Discussion

Between Scylla and Charybdis

To "sanitize" or not to "sanitize", that is the question

Pretraining data → Language models → Downstream tasks</sample>
    <sample id="1119">Discussion

Between Scylla and Charybdis

To “sanitize” or not to “sanitize”, that is the question

Pretraining data → Language models → Downstream tasks

Thank you!

Shangbin Feng
Chan Young Park
Yuhan Liu
Yulia Tsvetkov

PAUL G. ALLEN SCHOOL
UW NLP
Carnegie Mellon University
Language Technologies Institute</sample>
    <sample id="1120">Thank you!

Pretraining data
Language models
Downstream tasks

Shangbin Feng
Chan Young Park
Yuhan Liu
Yulia Tsvetkov

PAUL G. ALLEN SCHOOL
UW NLP
Carnegie Mellon University Language Technologies Institute</sample>
    <sample id="1121">The new method is called "Permuting with 'jumps'".</sample>
    <sample id="1122">The author described the "marked words" method as finding words that distinguish personas of marked groups from unmarked groups.</sample>
    <sample id="1123">The affiliations of the authors of the paper are:

- Shangbin Feng: Paul G. Allen School, University of Washington (UW)
- Chan Young Park: UWNLP
- Yuhan Liu: Carnegie Mellon University Language Technologies Institute
- Yulia Tsvetkov: Carnegie Mellon University Language Technologies Institute</sample>
    <sample id="1124">Bouquet/Stanford</sample>
    <sample id="1125">The names of the speakers are Sarah E. Finch, James D. Finch, and Jinho D. Choi.</sample>
    <sample id="1126">There are four authors involved in the paper: Mohammad Javad Hosseini, Filip Radlinski, Silvia Paretí, and Annie Louis.</sample>
    <sample id="1127">The datasets mentioned in the image for testing syntactic phenomena are BLiMP, SyntaxGym, and CrowS.</sample>
    <sample id="1128">The image contains the following written text:

---

**When Does Translation Require Context? A Data-driven, Multilingual Exploration**

Patrick Fernandes*, Kayo Yin*, Emmy Liu
André F. T. Martins, Graham Neubig

---

Below the main title and authors' names, there are logos for the following institutions:

- Carnegie Mellon University Language Technologies Institute
- TÉCNICO LISBOA
- BAIR (Berkeley Artificial Intelligence Research)
- Unbabel

At the bottom right corner, there is a note that says: "* equal contribution"</sample>
    <sample id="1129">Translation depends on context

We'll have to get rid of that mole.

Things could start to get dangerous if the ministers find out. We'll have to get rid of that mole.</sample>
    <sample id="1130">Translation depends on context

Things could start to get dangerous if the ministers find out.
We'll have to get rid of that mole.

Could it be anything serious, Doctor?
We'll have to get rid of that mole.</sample>
    <sample id="1131">Translation depends on context

Could it be anything serious, Doctor?
We'll have to get rid of that mole.</sample>
    <sample id="1132">Evaluating context-dependent translation is hard

- Only a small portion of words depend on
  context

Corpus-level metrics</sample>
    <sample id="1133">Evaluating context-dependent translation is hard

- Only a small portion of words depend on
  - context
    - Corpus-level metrics
- Existing methods support limited discourse
  - phenomena and languages</sample>
    <sample id="1134">RQ1: When does translation require context?
RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1135">RQ1: When does translation require context?
- Word-level context usage

RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1136">Conditional Cross-Mutual Information (CXMI)

- CXMI: measure how much context MT models use given a corpus

Uncertainty over translations given the source
HqMTA(Y|X)
Uncertainty over translations given the source AND context
HqMTC(Y|X, C)
CXMI(C → Y|X)</sample>
    <sample id="1137">Conditional Cross-Mutual Information (CXMI)

- CXMI: measure how much context MT models use given a corpus

Uncertainty over translations given the source
HqMTA(Y|X)
Uncertainty over translations given the source AND context
HqMTC(Y|X, C)
CXMI(C → Y|X)</sample>
    <sample id="1138">Pointwise (P-)CXMI

- We introduce P-CXMI to measure context usage to translate a specific

  Senten P-CXMI(y, x, C) = - log \(\frac{q_{MT_A}(y|x)}{q_{MT_C}(y|x, C)}\)

  Word P-CXMI(i, y, x, C) = - log \(\frac{q_{MT_A}(y_i|y_{t&lt;i}, x)}{q_{MT_C}(y_i|y_{t&lt;i}, x, C)}\)

- High P-CXMI words -&gt; requires context to translate</sample>
    <sample id="1139">RQ1: When does translation require context?
- Word-level context usage
- Thematic analysis

RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1140">The image contains the following text:

---

**Thematic analysis of high P-CXMI words**

**RQ1: When does translation require context?**
- Word-level context usage
- Thematic analysis

**RQ2: How well do models handle context-dependent translations?**
IDEAS WORTH SPREADING

---

**TED**
**IDEAS WORTH SPREADING**

---

**Languages:**
English | العربية | Deutsch
Español | Français | עברית
Italiano | 日本語 | 한국어
Nederlands | Português | Română
Русский | Türkçe | 中文

---</sample>
    <sample id="1141">The image contains the following text:

```
Thematic analysis of high P-CXMI words

1. POS tags
```</sample>
    <sample id="1142">The thematic analysis of high P-CXMI words focuses on POS tags, specifically pronouns in English and Arabic (En-Ar). The chart shows the P-CXMI values for different pronoun categories: PRON.3.Sing (singular), PRON.3.Dual (dual), and PRON.3.Plur (plural). The highest P-CXMI value is observed for the dual category, followed by singular and plural categories.</sample>
    <sample id="1143">Thematic analysis of high P-CXMI words

1. POS tags

P-CXMI for POS tags in En-Ar
- Pronouns
- Verb form</sample>
    <sample id="1144">The thematic analysis of high P-CXMI words includes:

1. POS tags
2. Vocabulary items

- Pronouns
- Verb form
- Lexical cohesion

English text:
"Avelile's mother was still asleep. Avelile went to school."

Chinese translation:
"阿维利尔的母亲还在睡觉。阿维利尔去上学了。"</sample>
    <sample id="1145">The thematic analysis of high P-CXMI words includes:

1. POS tags
2. Vocabulary items

English:
- Avelile's mother was still asleep.
- Avelile went to school.

Chinese:
- 阿维利尔的母亲还在睡觉。
- 阿维利尔去上学了。</sample>
    <sample id="1146">The thematic analysis of high P-CXMI words includes:

1. POS tags
2. Vocabulary items
3. Individual tokens

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis</sample>
    <sample id="1147">The image contains a slide with the title "Thematic analysis of high P-CXMI words" and two research questions (RQs):

1. **RQ1: When does translation require context?**
   - POS tags
     - Word-level context usage
   - Vocabulary items
     - Thematic analysis
   - Individual tokens

2. **RQ2: How well do models handle context-dependent translations?**
   - Multilingual Discourse-Aware (MuDA) benchmark

Additionally, there is an example of a sentence in English and its German translation:
- **English:** "She knows where we're going."
  - **German:** "Sie weiß, wohin wir gehen."
- **English:** "I don't."
  - **German:** "Ich weiß es nicht."

The slide also lists some thematic categories on the right side:
- Pronouns
- Verb form
- Lexical cohesion
- Ellipsis
- Formality</sample>
    <sample id="1148">The image contains a slide with the following content:

---

**RQ1: When does translation require context?**
- Word-level context usage
- Thematic analysis

**RQ2: How well do models handle context-dependent translations?**
- Multilingual Discourse-Aware (MuDA) tagger

**Multilingual Discourse-Aware (MuDA) tagger**

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis

---</sample>
    <sample id="1149">The image contains a slide titled "Multilingual Discourse-Aware (MuDA) tagger." Below the title, there is a list of features that the MuDA tagger considers:

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis

To the right of this list, there is a bar chart with the following details:
- The x-axis represents different languages: fr, ja, nl, ru, de, pt_br, ro, es, it, he, zh_cn, ar, tr, ko.
- The y-axis represents counts.
- Each language has bars divided into five categories corresponding to the features listed above, represented by different colors in the legend:
  - Blue for pronouns
  - Orange for formality
  - Green for verb form
  - Red for lexical
  - Purple for ellipsis

The chart visually compares the frequency of these linguistic features across various languages.</sample>
    <sample id="1150">The image appears to be a slide from a presentation about a multilingual discourse-aware (MuDA) tagger. Here is the written content from the image:

---

### Multilingual Discourse-Aware (MuDA) tagger

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis

---

### MuDA benchmark

- **MuDA tagger**
  - Input: Text documents
  - Output: Tagged text documents with discourse features

---

### Evaluation Metrics

- BLEU
- COMET
- F-measure

---</sample>
    <sample id="1151">The image contains two main sections with questions and bullet points related to translation and model evaluation:

1. **MuDA Benchmark**
   - **RQ1: When does translation require context?**
     - Word-level context usage
     - Thematic analysis
   - **RQ2: How well do models handle context-dependent translations?**
     - Multilingual Discourse-Aware (MuDA) benchmark
     - Model evaluation

The first section, "MuDA benchmark," is likely referring to a framework or tool used for evaluating machine translation systems in terms of their ability to handle context-dependent translations. The questions RQ1 and RQ2 are designed to explore when context is necessary for accurate translation and how well different models perform under these conditions. The bullet points provide specific methods or metrics for assessing this performance, such as word-level context usage, thematic analysis, and using a multilingual discourse-aware benchmark along with model evaluation techniques.</sample>
    <sample id="1152">Corpus-level metrics

RQ1: When does translation require context?
- Word-level context usage
- Thematic analysis

RQ2: How well do models handle context-dependent translations?
- Multilingual Discourse-Aware (MuDA) benchmark
- Model evaluation</sample>
    <sample id="1153">Corpus-level metrics

BLEU
COMET
F-measure</sample>
    <sample id="1154">Corpus-level metrics

- BLEU
- COMET
- F-measure

Unclear which system is best for document-level MT with corpus-level metrics</sample>
    <sample id="1155">MuDA benchmark results

- Context-aware models perform significantly better on some phenomena</sample>
    <sample id="1156">MuDA benchmark results

- Context-aware models perform significantly better on some phenomena
  - √: Formality, lexical cohesion
  - ❌ Ellipsis, pronouns, verb form</sample>
    <sample id="1157">MuDA benchmark results

- Context-aware models perform significantly better on some phenomena
  - ✅: Formality, lexical cohesion
  - ❌ Ellipsis, pronouns, verb form

- DeepL outperforms Google on most phenomena and language pairs*</sample>
    <sample id="1158">Summary

- Identify discourse phenomena systematically without prior linguistic knowledge
- Dataset-agnostic benchmark for document-level MT</sample>
    <sample id="1159">Summary

- Identify discourse phenomena systematically without prior linguistic knowledge
- Dataset-agnostic benchmark for document-level MT</sample>
    <sample id="1160">Summary

- Identify discourse phenomena systematically without prior linguistic knowledge
- Dataset-agnostic benchmark for document-level MT</sample>
    <sample id="1161">FTw, BOND, COSINE, MLC, L2R</sample>
    <sample id="1162">The model is evaluated on 11 tasks.</sample>
    <sample id="1163">DEPLAIN: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich Heine University Düsseldorf, Germany

ACL 2023</sample>
    <sample id="1164">DEPLAIN: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich Heine University Düsseldorf, Germany

ACL 2023

1. Text Simplification
What, why and How?</sample>
    <sample id="1165">Text Simplification Example

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plain Language:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="1166">Text Simplification Example

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plain Language:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="1167">Text Simplification Example

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plain Language:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="1168">Text Simplification Example

Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

Plain Language:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."</sample>
    <sample id="1169">The image contains a slide from a presentation titled "German Text Simplification Corpora." The slide is divided into two main sections:

1. **Sentence Level**:
   - A bar chart comparing different corpora in terms of their size and alignment (manual vs. automatic).
   - The corpora listed include:
     - Klapfer (Klamer et al., 2013)
     - TextComplexityDE19 (Nieder et al., 2019)
     - ZEST-data (Millison et al., 2020)
     - APPLHA-or-a2 (Springer et al., 2021)
     - APPLHA-or-b1 (Springer et al., 2021)
     - Simple-German-Corpus (Robetek et al., 2025)
   - The sizes of these corpora range from 200 to 10,268 sentences.
   - Alignment types are categorized as manual or automatic.

2. **DE-plain**:
   - A new corpus with a size of 13,122 sentences.
   - It is further broken down into APA and web versions, with sizes of 483 and 756 sentences respectively.

The slide also includes a legend for domains such as mixed, news, accessibility, L2, fiction, Bible, public auth., and politics.</sample>
    <sample id="1170">German Text Simplification Corpora

Sentence Level

The slide presents data on German text simplification corpora, categorized by domain and alignment method (manual vs. automatic). The domains include mixed, news, accessibility, L2, fiction, Bible, public auth., and politics. The alignment methods are also specified as manual or automatic.

- Kläper (Kläper et al. 2013): 2000 sentences, all manually aligned.
- TextComplexityDE19 (Nieder et al. 2019): 250 sentences, all manually aligned.
- ZEST-data (Mullinson et al. 2020): 1198 sentences, all manually aligned.
- APB-LHA-or-a2 (Springer et al. 2021): 9456 sentences, all automatically aligned.
- APB-LHA-or-b1 (Springer et al. 2021): 10268 sentences, all automatically aligned.
- Simple-German-Corpus (Robotek et al. 2020): 5942 sentences, with 195 manually aligned and 5747 automatically aligned.
- DEplain-APA: 13,122 sentences, with 483 manually aligned and 12,639 automatically aligned.
- DEplain-web: 756 sentences, with 3450 manually aligned and 4116 automatically aligned.</sample>
    <sample id="1171">German Text Simplification Corpora

Sentence Level

The slide presents data on German text simplification corpora, categorized by domain and alignment method (manual vs. automatic). The domains include mixed, health, accessibility, fiction, Bible, public auth., and politics. The alignment methods are also specified.

- **Mixed**: 2000 sentences, all manual.
- **Health**: 250 sentences, all manual.
- **Accessibility**: 1198 sentences, all manual.
- **News**: 9456 sentences, all manual.
- **L2**: 10268 sentences, all manual.
- **Fiction**: 5942 sentences, all manual.
- **Bible**: 195 sentences, manual; 780 sentences, automatic.
- **Public Auth.**: 1626 sentences, manual; 1132 sentences, automatic.
- **Politics**: 2311 sentences, manual; 177 sentences, automatic.

Additionally, there is a breakdown of the DEplain corpora:
- DEplain-APA: 13122 sentences, all manual.
- DEplain-web: 483 sentences, all manual; 756 sentences, all manual.</sample>
    <sample id="1172">German Text Simplification Corpora

Sentence Level

The slide shows a bar chart with data on German text simplification corpora, categorized by domain and alignment (manual vs. automatic). The domains include mixed, health, news, accessibility, fiction, L2, public auth., and politics. The alignment is either manual or automatic.

- Kläper (Klauer et al. 2013): 2000 sentences, all manual.
- TextComplexityDE19 (Nieden et al. 2019): 250 sentences, all manual.
- ZEST-data (Millison et al. 2020): 1198 sentences, all manual.
- APB-LHA-or-a2 (Springer et al. 2021): 9456 sentences, all manual.
- APB-LHA-or-b1 (Springer et al. 2021): 10268 sentences, all manual.
- Simple-German-Corpus (Robotek et al. 2020): 5942 sentences, all manual.
- DEplain-APA: 13,122 sentences, 483 manual, 756 automatic.
- DEplain-web: 3450 sentences, 49 manual, 640 automatic, 992 automatic, 175 automatic, 629 automatic.</sample>
    <sample id="1173">German Text Simplification Corpora

Sentence Level

The slide presents data on German text simplification corpora, categorized by domain and alignment method (manual vs. automatic). The domains include mixed, news, accessibility, L2, fiction, Bible, public auth., and politics. The alignment methods are also specified as manual or automatic.

- Klapfer (Klamer et al. 2013): 2000 sentences, all manual.
- TextComplexityDE19 (Nieder et al. 2019): 250 sentences, all manual.
- ZEST-data (Millison et al. 2020): 1198 sentences, all manual.
- APB-LHA-or-a2 (Springer et al. 2021): 9456 sentences, all manual.
- APB-LHA-or-b1 (Springer et al. 2021): 10268 sentences, all manual.
- Simple-German-Corpus (Robotek et al. 2020): 5942 sentences, all manual.
- DEplain-APA: 13,122 sentences, with 483 being manual and 756 being automatic.
- DEplain-web: 3450 sentences, with 40 being manual and 3410 being automatic.</sample>
    <sample id="1174">The image is a slide from a presentation titled "German Text Simplification Corpora." The slide is divided into two main sections: a bar chart and a stacked bar chart.

### Bar Chart:
- **Title:** Sentence Level
- **Y-Axis:** Number of sentences (ranging from 0 to 14,000)
- **X-Axis:** Different corpora names with corresponding years and references.
  - Klapfer (Klamer et al., 2013): 2,000 sentences
  - TextComplexityDE19 (Nieder et al., 2019): 250 sentences
  - ZEST-data (Millison et al., 2020): 1,198 sentences
  - APPLHA-or-a2 (Springer et al., 2021): 9,456 sentences
  - APPLHA-or-b1 (Springer et al., 2021): 10,268 sentences
  - Simple-German-Corpus (Robotek et al., 2020): 5,942 sentences

### Stacked Bar Chart:
- **Title:** DEplain-APA and DEplain-web
- **Y-Axis:** Number of sentences (ranging from 0 to 14,000)
- **X-Axis:** Different domains and alignments.
  - **Domains:**
    - mixed
    - health
    - news
    - accessibility
    - L2
    - fiction
    - public auth.
    - politics
  - **Alignments:**
    - manual
    - automatic
- **Corpora:**
  - DEplain-APA: 13,122 sentences
    - Manual: 483 sentences
    - Automatic: 756 sentences
  - DEplain-web: 3,450 sentences
    - Manual: 40 sentences
    - Automatic: 640 sentences
    - Accessibility: 502 sentences
    - Fiction: 175 sentences
    - Public auth.: 229 sentences

This slide provides a comparison of various German text simplification corpora in terms of their size and the distribution of sentences across different domains and alignment methods.</sample>
    <sample id="1175">The image contains two bar charts related to simplification in different contexts.

**Top Chart: Types of Simplification**
- The chart is titled "Types of Simplification."
- It shows three categories of simplification: Simplicity, LexSimp, and StructSimp.
- The x-axis represents different types of texts: news (n = 46), bible (n = 155), L2 (n = 157), and fiction (n = 72).
- The y-axis represents the frequency or some metric related to the type of simplification.
- The bars for each category show the distribution of the three types of simplification across the different text types.

**Bottom Chart: Simplification Transformations**
- The chart is titled "Simplification Transformations."
- It compares two methods: DEplain-apa and DEplain-web.
- The x-axis lists five types of transformations: reordering, rephrasing, lexical substitution, word addition, and word deletion.
- The y-axis represents the percentage of each transformation.
- The bars show the percentage of each transformation for both DEplain-apa and DEplain-web methods.</sample>
    <sample id="1176">The image contains two bar charts related to simplification in text.

**Top Chart: Types of Simplification**
- The chart is divided into four categories: news, bible, L2 (likely referring to Level 2), and fiction.
- Each category has three bars representing different types of simplification:
  - Simplicity (blue)
  - LexSimp (red)
  - StructSimp (yellow)
- The y-axis represents the value of the simplification type.
- The x-axis lists the categories with their respective sample sizes:
  - News: n = 46
  - Bible: n = 155
  - L2: n = 157
  - Fiction: n = 72

**Bottom Chart: Simplification Transformations**
- The chart shows the percentage of different simplification transformations used by two systems: DEplain-apa (green) and DEplain-web (blue).
- The transformations listed on the x-axis are:
  - Reordering
  - Rephrasing
  - Lexical substitution
  - Word addition
  - Word deletion
- The y-axis represents the percentage of each transformation.
- The percentages for each transformation are as follows:
  - Reordering: DEplain-apa ≈ 50%, DEplain-web ≈ 10%
  - Rephrasing: DEplain-apa ≈ 10%, DEplain-web ≈ 30%
  - Lexical substitution: DEplain-apa ≈ 80%, DEplain-web ≈ 90%
  - Word addition: DEplain-apa ≈ 40%, DEplain-web ≈ 10%
  - Word deletion: DEplain-apa ≈ 30%, DEplain-web ≈ 20%</sample>
    <sample id="1177">The image contains two bar charts related to simplification in different contexts.

**Top Chart: Types of Simplification**
- The chart is titled "Types of Simplification."
- It shows three categories of simplification: Simplicity, LexSimp, and StructSimp.
- The x-axis represents different types of texts: news (n = 46), bible (n = 155), L2 (n = 157), and fiction (n = 72).
- The y-axis represents the frequency or some metric related to the type of simplification.
- The bars for each category show the distribution of the three types of simplification across the different text types.

**Bottom Chart: Simplification Transformations**
- The chart is titled "Simplification Transformations."
- It compares two methods: DEplain-apa and DEplain-web.
- The x-axis lists five types of transformations: reordering, rephrasing, lexical substitution, word addition, and word deletion.
- The y-axis represents the percentage of each transformation type.
- The bars show the percentage of each transformation method used by DEplain-apa and DEplain-web.</sample>
    <sample id="1178">The image contains two bar charts related to simplification in text.

**Types of Simplification:**
- The chart is divided into four categories: news, bible, L2 (likely referring to Level 2), and fiction.
- Each category has three bars representing different types of simplification:
  - Simplicity (blue)
  - LexSimp (red)
  - StructSimp (yellow)
- The number of samples for each category is provided at the bottom of each bar:
  - News: n = 46
  - Bible: n = 155
  - L2: n = 157
  - Fiction: n = 72

**Simplification Transformations:**
- This chart compares two methods: DEplain-apa (green) and DEplain-web (blue).
- The transformations are categorized as:
  - Reordering
  - Rephrasing
  - Lexical substitution
  - Word addition
  - Word deletion
- The percentage values for each transformation are shown on the y-axis, ranging from 0% to 100%.

The speaker appears to be discussing the differences in simplification types and transformations between the two methods.</sample>
    <sample id="1179">The image contains two bar charts related to simplification in text.

**Top Chart: Types of Simplification**
- The chart is divided into four categories: news, bible, L2 (likely referring to Level 2), and fiction.
- Each category has three bars representing different types of simplification:
  - Simplicity (blue)
  - LexSimp (red)
  - StructSimp (yellow)
- The y-axis represents the value of each type of simplification.
- The x-axis lists the categories with corresponding sample sizes:
  - News: n = 46
  - Bible: n = 155
  - L2: n = 157
  - Fiction: n = 72

**Bottom Chart: Simplification Transformations**
- The chart compares two methods: DEplain-apa (green) and DEplain-web (blue).
- The x-axis lists five types of transformations:
  - Reordering
  - Rephrasing
  - Lexical substitution
  - Word addition
  - Word deletion
- The y-axis represents the percentage of each transformation.
- The percentages for each method are as follows:
  - Reordering: DEplain-apa ≈ 50%, DEplain-web ≈ 10%
  - Rephrasing: DEplain-apa ≈ 10%, DEplain-web ≈ 30%
  - Lexical substitution: DEplain-apa ≈ 80%, DEplain-web ≈ 90%
  - Word addition: DEplain-apa ≈ 40%, DEplain-web ≈ 10%
  - Word deletion: DEplain-apa ≈ 30%, DEplain-web ≈ 20%</sample>
    <sample id="1180">3. Use-cases
Automatic alignment and simplification

Automatic Alignment Evaluation

Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)

| Name | Description | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | Hierarchical alignment using sentence embeddings similarity | .94 | - |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer | .961 | - |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa | .960 | - |
| CATS-C3G | Different similarity measures e.g n-grams (C3G)/word vectors | .247 | - |
| VecAlign | Multilingual aligner based on multilingual sentence embeddings | .271 | .260 |
| BERTalign | Allows sentence-transformer methods produce n:m alignments | .743 | .387 |
| MASSalign | A vicinity-driven approach with a TF-IDF similarity matrix | .846 | .819 |</sample>
    <sample id="1181">The image contains a slide titled "Automatic Alignment Evaluation" with a subtitle that reads, "Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)." The slide lists several alignment methods along with their descriptions and performance metrics in terms of precision (P), recall (R), F1 score, and F0.5 score for both 1:1 and n:m alignments.

Here is the text converted from the image:

```
Automatic Alignment Evaluation

Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)

| Name       | Description                                                                 |
|------------|---------------------------------------------------------------------------|
| LHA        | Hierarchical alignment using sentence embeddings similarity               |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer                  |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa                      |
| CATS-C3G   | Different similarity measures e.g n-grams (C3G)/word vectors              |
| VecAlign   | Multilingual aligner based on multilingual sentence embeddings             |
| BERTalign  | Allows sentence-transformer methods produce n:m alignments                |
| MASSalign  | A vicinity-driven approach with a TF-IDF similarity matrix                 |

| 1:1         | n:m          |
|-------------|--------------|
| P           | R            | P           | R           | F1          | F0.5        |
|-------------|--------------|-------------|-------------|-------------|-------------|
| .94         | .41          | -           | -           | -           | -           |
| .961        | .444         | -           | -           | .608        | .780        |
| .960        | .444         | -           | -           | .607        | .779        |
| .247        | .553         | -           | -           | .342        | .278        |
| .271        | .404         | .260        | .465        | .323        | .333        |
| .743        | .465         | .387        | .561        | .572        | .458        |
| .846        | .477         | .819        | .509        | .610        | .628        |
```</sample>
    <sample id="1182">The image shows a slide titled "Automatic Alignment Evaluation" with a subtitle that reads "Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)." The slide lists several alignment methods along with their descriptions and performance metrics in terms of precision (P), recall (R), F1 score, and F0.5 score for both 1:1 and n:m alignments.

Here is the text converted from the image:

```
Automatic Alignment Evaluation

Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)

| Name       | Description                                                                 |
|------------|----------------------------------------------------------------------------|
| LHA        | Hierarchical alignment using sentence embeddings similarity                |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer                   |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa                       |
| CATS-C3G   | Different similarity measures e.g n-grams (C3G)/word vectors               |
| VecAlign   | Multilingual aligner based on multilingual sentence embeddings              |
| BERTalign  | Allows sentence-transformer methods produce n:m alignments                 |
| MASSalign  | A vicinity-driven approach with a TF-IDF similarity matrix                  |

| 1:1         | n:m          |
|-------------|--------------|
| P           | R            | P           | R           | F1          | F0.5        |
|-------------|--------------|-------------|-------------|-------------|-------------|
| .94         | .41          | -           | -           | -           | -           |
| .961        | .444         | -           | -           | .608        | .780        |
| .960        | .444         | -           | -           | .607        | .779        |
| .247        | .553         | -           | -           | .342        | .278        |
| .271        | .404         | .260        | .465        | .323        | .333        |
| .743        | .465         | .387        | .561        | .572        | .458        |
| .846        | .477         | .819        | .509        | .610        | .628        |
```</sample>
    <sample id="1183">The image shows a slide titled "Automatic Alignment Evaluation" with a subtitle that reads "Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)." The slide lists several alignment methods along with their descriptions and performance metrics in two categories: 1:1 and n:m.

Here is the text from the slide:

```
Automatic Alignment Evaluation

Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)

| Name       | Description                                                                 | 1:1                                                                 | n:m                                                                 |
|------------|----------------------------------------------------------------------------|---------------------------------------------------------------------|---------------------------------------------------------------------|
| LHA        | Hierarchical alignment using sentence embeddings similarity                | P: .94, R: .41, F1: .57, F0.5: .747                                | -                                                                  |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer                   | P: .961, R: .444, F1: .608, F0.5: .780                                | -                                                                  |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa                       | P: .960, R: .444, F1: .607, F0.5: .779                                | -                                                                  |
| CATS-C3G   | Different similarity measures e.g n-grams (C3G)/word vectors               | P: .247, R: .553, F1: .342, F0.5: .278                                | -                                                                  |
| VecAlign   | Multilingual aligner based on multilingual sentence embeddings             | P: .271, R: .404, F1: .323, F0.5: .290                                | P: .260, R: .465, F1: .333, F0.5: .285                            |
| BERTalign  | Allows sentence-transformer methods produce n:m alignments                 | P: .743, R: .465, F1: .572, F0.5: .664                                | P: .387, R: .561, F1: .458, F0.5: .412                            |
| MASSalign  | A vicinity-driven approach with a TF-IDF similarity matrix                 | P: .846, R: .477, F1: .610, F0.5: .733                                | P: .819, R: .509, F1: .628, F0.5: .730                            |
```</sample>
    <sample id="1184">The image shows a slide from a presentation titled "Automatic Alignment Evaluation." The slide is divided into two main sections: the upper part discusses alignment methods with 1:1 capabilities, and the lower part discusses n:m capabilities.

### Upper Part: 1:1 Capabilities
| Name | Description |
|------|-------------|
| LHA  | Hierarchical alignment using sentence embeddings similarity |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa |
| CATS-C3G | Different similarity measures e.g n-grams (C3G)/word vectors |

### Lower Part: n:m Capabilities
| Name | Description |
|------|-------------|
| VecAlign | Multilingual aligner based on multilingual sentence embeddings |
| BERTalign | Allows sentence-transformer methods produce n:m alignments |
| MASSalign | A vicinity-driven approach with a TF-IDF similarity matrix |

The table also includes precision (P), recall (R), F1 score, and F0.5 score for each method under both 1:1 and n:m capabilities. However, the values for n:m capabilities are marked as "-".</sample>
    <sample id="1185">The image shows a slide titled "Automatic Alignment Evaluation" with a subtitle that reads "Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)." The slide lists several alignment methods along with their descriptions and performance metrics in terms of precision (P), recall (R), F1 score, and F0.5 score for both 1:1 and n:m alignments.

Here is the text converted from the image:

---

**Automatic Alignment Evaluation**

**Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)**

| Name | Description | 1:1 | n:m |
|------|-------------|-----|-----|
| LHA  | Hierarchical alignment using sentence embeddings similarity | .94 | - |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer | .961 | - |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa | .960 | - |
| CATS-C3G | Different similarity measures e.g n-grams (C3G)/word vectors | .247 | - |
| VecAlign | Multilingual aligner based on multilingual sentence embeddings | .271 | .260 |
| BERTalign | Allows sentence-transformer methods produce n:m alignments | .743 | .387 |
| MASSalign | A vicinity-driven approach with a TF-IDF similarity matrix | .846 | .819 |

---</sample>
    <sample id="1186">The image shows a slide from a presentation titled "Automatic Alignment Evaluation." The slide is divided into two parts: the upper part discusses alignment methods with 1:1 capabilities, and the lower part discusses n:m capabilities.

### Upper Part: 1:1 Capabilities
| Name | Description |
|------|-------------|
| LHA  | Hierarchical alignment using sentence embeddings similarity |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa |
| CATS-C3G | Different similarity measures e.g n-grams (C3G)/word vectors |

### Lower Part: n:m Capabilities
| Name | Description |
|------|-------------|
| VecAlign | Multilingual aligner based on multilingual sentence embeddings |
| BERTalign | Allows sentence-transformer methods produce n:m alignments |
| MASSalign | A vicinity-driven approach with a TF-IDF similarity matrix |

The table also includes precision (P), recall (R), F1 score, and F0.5 score for each method under both 1:1 and n:m capabilities. However, the values for n:m capabilities are marked as "-".</sample>
    <sample id="1187">The image contains a slide titled "Automatic Alignment Evaluation" with a subtitle that reads, "Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)." The slide lists several alignment methods along with their descriptions and performance metrics in terms of precision (P), recall (R), F1 score, and F0.5 score for both 1:1 and n:m alignments.

Here is the text converted from the image:

```
Automatic Alignment Evaluation

Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)

| Name        | Description                                                                 | 1:1          | n:m          |
|-------------|----------------------------------------------------------------------------|--------------|--------------|
| LHA         | Hierarchical alignment using sentence embeddings similarity                | P: .94       | -           |
| Sent-LaBSE  | Similar embeddings of Language-agnostic BERT transformer                    | P: .961      | -           |
| Sent-RoBERTa| Similar embeddings of Cross English &amp; German RoBERTa                        | P: .960      | -           |
| CATS-C3G    | Different similarity measures e.g n-grams (C3G)/word vectors               | P: .247      | -           |
| VecAlign    | Multilingual aligner based on multilingual sentence embeddings              | P: .271      | P: .260      |
| BERTalign   | Allows sentence-transformer methods produce n:m alignments                 | P: .743      | P: .387      |
| MASSalign   | A vicinity-driven approach with a TF-IDF similarity matrix                  | P: .846      | P: .819      |
```</sample>
    <sample id="1188">The image contains a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level." The content is about results on document simplification using finetuned long-mBART and sentence simplification using finetuned mBART.

### Document Level

**Results on Document Simplification using finetuned long-mBART.**
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 387 | 44.56 38.136 0.598 65.4 |
| DEplain-web | 481 | 35.02 12.913 0.475 59.55 |
| DEplain-APA+web | 868 | 42.862 36.449 0.589 65.4 |
| src2src-baseline | 17,637 | 34.247 0.583 58.85 |

### Sentence Level

**Results on Sentence Simplification using finetuned mBART.**
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 10660 | 34.818 28.25 0.639 63.072 |
| DEplain-APA+web | 11941 | 34.904 28.506 0.64 62.669 |
| src2src-baseline | 15,249 | 26.893 0.627 59.23 |

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 10660 | 30.867 15.727 0.413 64.516 |
| DEplain-APA+web | 11941 | 34.828 17.88 0.436 65.249 |
| src2src-baseline | 11,931 | 20.85 0.423 60.825 |

The tables provide metrics for different models (DEplain-APA, DEplain-APA+web, src2src-baseline) across various datasets (APA, APA+web, WEB). The metrics include SARI, BLEU, BS-P, and FRE, which measure the quality of the simplified text in terms of fluency, readability, and semantic preservation.</sample>
    <sample id="1189">The image contains a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level." The slide discusses results on document simplification using finetuned long-mBART and sentence simplification using finetuned mBART, where 'n' corresponds to the length of the training data.

### Document Level

**Results on Document Simplification using finetuned long-mBART.**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4   |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55  |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4   |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85  |

**Table 5: DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43.087 | 21.9   | 0.377 | 64.7  |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5  |
| DEplain-APA+web | 868 | 49.745 | 23.37  | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4  |

**Table 6: DEPLAIN-WEB test (n=147)**

### Sentence Level

**Results on Sentence Simplification using finetuned mBART.**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34.818 | 28.25  | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64  | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

**Table 7: DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

**Table 8: DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="1190">The image contains a slide from a presentation titled "Automatic Text Simplification." The slide is divided into two main sections: "Document Level" and "Sentence Level," each presenting results on text simplification using finetuned models.

### Document Level

**Results on Document Simplification using finetuned long-mBART.**
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4   |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55  |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4   |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85  |

#### Table 5: DEPLAIN-APA test (n=48)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43.087 | 21.9   | 0.377 | 64.7  |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5  |
| DEplain-APA+web | 868 | 49.745 | 23.37  | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4  |

#### Table 6: DEPLAIN-WEB test (n=147)

### Sentence Level

**Results on Sentence Simplification using finetuned mBART.**
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34.818 | 28.25  | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64  | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

#### Table 7: DEPLAIN-APA test (n=1231)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

#### Table 8: DEPLAIN-WEB test (n=1846)</sample>
    <sample id="1191">The image contains a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level." The slide discusses results on document simplification using finetuned long-mBART and sentence simplification using finetuned mBART, where 'n' corresponds to the length of the training data.

### Document Level

**Results on Document Simplification using finetuned long-mBART.**

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 387 | 44.56 38.136 0.598 65.4 |
| DEplain-web | 481 | 35.02 12.913 0.475 59.55 |
| DEplain-APA+web | 868 | 42.862 36.449 0.589 65.4 |
| src2src-baseline | 17,637 | 34.247 0.583 58.85 |

**Table 10: DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 387 | 43.087 21.9 0.377 64.7 |
| DEplain-web | 481 | 49.584 23.282 0.462 63.5 |
| DEplain-APA+web | 868 | 49.745 23.37 0.445 57.95 |
| src2src-baseline | 12,848 | 23.132 0.432 59.4 |

**Table 10: DEPLAIN-WEB test (n=147)**

### Sentence Level

**Results on Sentence Simplification using finetuned mBART.**

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 10660 | 34.818 28.25 0.639 63.072 |
| DEplain-APA+web | 11941 | 34.904 28.506 0.64 62.669 |
| src2src-baseline | 15,249 | 26.893 0.627 59.23 |

**Table 11: DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 10660 | 30.867 15.727 0.413 64.516 |
| DEplain-APA+web | 11941 | 34.828 17.88 0.436 65.249 |
| src2src-baseline | 11,931 | 20.85 0.423 60.825 |

**Table 11: DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="1192">The image contains a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level." The content is about results on document simplification using finetuned long-mBART and sentence simplification using finetuned mBART.

### Document Level

**Results on Document Simplification using finetuned long-mBART.**
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4   |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55  |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4   |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85  |

#### Table 5: DEPLAIN-APA test (n=48)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43.087 | 21.9   | 0.377 | 64.7  |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5  |
| DEplain-APA+web | 868 | 49.745 | 23.37  | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4  |

#### Table 6: DEPLAIN-WEB test (n=147)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

### Sentence Level

**Results on Sentence Simplification using finetuned mBART.**
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34.818 | 28.25  | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64  | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

#### Table 7: DEPLAIN-APA test (n=1231)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

#### Table 8: DEPLAIN-WEB test (n=1846)</sample>
    <sample id="1193">The image contains a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level." The slide discusses results on document simplification using finetuned long-mBART and sentence simplification using finetuned mBART, where 'n' corresponds to the length of the training data.

### Document Level

**Results on Document Simplification using finetuned long-mBART.**

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 387 | 44.56 38.136 0.598 65.4 |
| DEplain-web | 481 | 35.02 12.913 0.475 59.55 |
| DEplain-APA+web | 868 | 42.862 36.449 0.589 65.4 |
| src2src-baseline | 17,637 | 34.247 0.583 58.85 |

**Table 10: DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 387 | 43.087 21.9 0.377 64.7 |
| DEplain-web | 481 | 49.584 23.282 0.462 63.5 |
| DEplain-APA+web | 868 | 49.745 23.37 0.445 57.95 |
| src2src-baseline | 12,848 | 23.132 0.432 59.4 |

**Table 10: DEPLAIN-WEB test (n=147)**

### Sentence Level

**Results on Sentence Simplification using finetuned mBART.**

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 10660 | 34.818 28.25 0.639 63.072 |
| DEplain-APA+web | 11941 | 34.904 28.506 0.64 62.669 |
| src2src-baseline | 15,249 | 26.893 0.627 59.23 |

**Table 11: DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 10660 | 30.867 15.727 0.413 64.516 |
| DEplain-APA+web | 11941 | 34.828 17.88 0.436 65.249 |
| src2src-baseline | 11,931 | 20.85 0.423 60.825 |

**Table 11: DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="1194">The image contains a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level." The slide provides results on document simplification using finetuned long-mBART and sentence simplification using finetuned mBART.

### Document Level

**Results on Document Simplification using finetuned long-mBART.**
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4   |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55  |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4   |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85  |

**Table 10: DEPLAIN-APA test (n=48)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43.087 | 21.9   | 0.377 | 64.7  |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5  |
| DEplain-APA+web | 868 | 49.745 | 23.37  | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4  |

**Table 11: DEPLAIN-WEB test (n=147)**

### Sentence Level

**Results on Sentence Simplification using finetuned mBART.**
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34.818 | 28.25  | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64  | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

**Table 12: DEPLAIN-APA test (n=1231)**

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

**Table 13: DEPLAIN-WEB test (n=1846)**</sample>
    <sample id="1195">Thanks.
For more details, please check out our paper.
And feel free to visit our poster in the ACL 2023 conference.</sample>
    <sample id="1196">Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)

Mohammad Javad Hosseini, Filip Radlinski, Silvia Paretí, and Annie Louis

Google Research</sample>
    <sample id="1197">Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)

Mohammad Javad Hosseini, Filip Radlinski, Silvia Paretí, and Annie Louis

Google Research</sample>
    <sample id="1198">Indirect Referring Expressions

- Goal: Understanding users' language when they make a choice
  - Alternative question: Did you mean easy on me or I gotta feeling?
- Direct reference:
  - "easy on me", "the first one"
- Indirect reference could be used in natural and fluid conversation:
  - Cannot remember the name
  - The pronunciations are hard to distinguish
  - Want to specify a preference
  - The newer one.
  - The song that's not energetic.</sample>
    <sample id="1199">Indirect Referring Expressions

- Goal: Understanding users' language when they make a choice
  - Alternative question: Did you mean easy on me or I gotta feeling?
- Direct reference:
  - "easy on me", "the first one"
- Indirect reference could be used in natural and fluid conversation:
  - Cannot remember the name
  - The pronunciations are hard to distinguish
  - Want to specify a preference
  - Indirect reference: The newer one. The song that's not energetic.</sample>
    <sample id="1200">Indirect Referring Expressions

- Goal: Understanding users' language when they make a choice
  - Alternative question: Did you mean easy on me or I gotta feeling?
- Direct reference:
  - "easy on me", "the first one"
- Indirect reference could be used in natural and fluid conversation:
  - Cannot remember the name
  - The pronunciations are hard to distinguish
  - Want to specify a preference
  - Indirect reference: The newer one. The song that's not energetic.</sample>
    <sample id="1201">Indirect Referring Expressions

- Goal: Understanding users' language when they make a choice
  - Alternative question: Did you mean easy on me or I gotta feeling?
- Direct reference:
  - "easy on me", "the first one"
- Indirect reference could be used in natural and fluid conversation:
  - Cannot remember the name
  - The pronunciations are hard to distinguish
  - Want to specify a preference
  - Indirect reference: The newer one. The song that's not energetic.</sample>
    <sample id="1202">Indirect Referring Expressions

- Goal: Understanding users' language when they make a choice
  - Alternative question: Did you mean easy on me or I gotta feeling?
- Direct reference:
  - "easy on me", "the first one"
- Indirect reference could be used in natural and fluid conversation:
  - Cannot remember the name
  - The pronunciations are hard to distinguish
  - Want to specify a preference
  - Indirect reference: The newer one. The song that's not energetic.</sample>
    <sample id="1203">Dataset Collection

- Important problem
  - Conversational systems
  - Benchmarking Large Language Models' entity understanding
- No large-scale public dataset available
- We collect a large dataset using crowd annotation
- Three domains:</sample>
    <sample id="1204">Dataset Collection

- Important problem
  - Conversational systems
  - Benchmarking Large Language Models' entity understanding
- No large-scale public dataset available
- We collect a large dataset using crowd annotation
- Three domains:</sample>
    <sample id="1205">Dataset Collection Methodology

- Methodology emphasizes informality using a cartoon completion task

Sets the dialog context [chosen from a few manual prompts per domain]
The alternative question
Expression referring to one of the entities

Filled in by the annotator</sample>
    <sample id="1206">Dataset Collection Methodology

- Methodology emphasizes informality using a cartoon completion task

Sets the dialog context [chosen from a few manual prompts per domain]
The alternative question
Expression referring to one of the entities

Filled in by the annotator</sample>
    <sample id="1207">Dataset Collection Methodology

- Methodology emphasizes informality using a cartoon completion task

Sets the dialog context [chosen from a few manual prompts per domain]
The alternative question
Expression referring to one of the entities
Filled in by the annotator</sample>
    <sample id="1208">Dataset Collection Methodology

- Methodology emphasizes informality using a cartoon completion task

Sets the dialog context [chosen from a few manual prompts per domain]
The alternative question
Expression referring to one of the entities

Filled in by the annotator</sample>
    <sample id="1209">Dataset Collection Methodology

- Methodology emphasizes informality using a cartoon completion task

Sets the dialog context [chosen from a few manual prompts per domain]
The alternative question
Expression referring to one of the entities

Filled in by the annotator</sample>
    <sample id="1210">Dataset Collection Methodology

- Methodology emphasizes informality using a cartoon completion task

Sets the dialog context [chosen from a few manual prompts per domain]
The alternative question
Expression referring to one of the entities
Filled in by the annotator

More Similar (usually harder)
Items with similar boxes of Wikipedia (same genre and/or artist)
Items with similar titles:
Do you mean 'This is It' or 'Man in the Mirror'?</sample>
    <sample id="1211">Generate alternative questions =&gt; sampling entity pairs

Do you mean A or B?

- Items with similar infoboxes on Wikipedia (same genre and/or artist)
  Do you mean 'This Is It' or 'Man in the Mirror'?
- Items with similar descriptions on Wikipedia
  Do you mean 'Thinking of You' or 'Happy Anywhere'?
- Items with similar titles:
  Do you mean The Return (memoir) or The Return (Shatner novel)?
- Uniform at random:
  Do you mean 'You Could Be Mine' or 'The Way I Am'</sample>
    <sample id="1212">Generate alternative questions =&gt; sampling entity pairs

Do you mean A or B?

- Items with similar infoboxes on Wikipedia (same genre and/or artist)
  Do you mean 'This Is It' or 'Man in the Mirror'?
- Items with similar descriptions on Wikipedia
  Do you mean 'Thinking of You' or 'Happy Anywhere'?
- Items with similar titles:
  Do you mean The Return (memoir) or The Return (Shatner novel)?
- Uniform at random:
  Do you mean 'You Could Be Mine' or 'The Way I Am'</sample>
    <sample id="1213">Generate alternative questions =&gt; sampling entity pairs

Do you mean A or B?

- Items with similar infoboxes on Wikipedia (same genre and/or artist)
  Do you mean 'This Is It' or 'Man in the Mirror'?
- Items with similar descriptions on Wikipedia
  Do you mean 'Thinking of You' or 'Happy Anywhere'?
- Items with similar titles:
  Do you mean The Return (memoir) or The Return (Shatner novel)?
- Uniform at random:
  Do you mean 'You Could Be Mine' or 'The Way I Am'</sample>
    <sample id="1214">Generate alternative questions =&gt; sampling entity pairs

Do you mean A or B?

- Items with similar infoboxes on Wikipedia (same genre and/or artist)
  Do you mean 'This Is It' or 'Man in the Mirror'?
- Items with similar descriptions on Wikipedia
  Do you mean 'Thinking of You' or 'Happy Anywhere'?
- Items with similar titles:
  Do you mean The Return (memoir) or The Return (Shatner novel)?
- Uniform at random:
  Do you mean 'You Could Be Mine' or 'The Way I Am'</sample>
    <sample id="1215">Generate alternative questions =&gt; sampling entity pairs

Do you mean A or B?

- Items with similar infoboxes on Wikipedia (same genre and/or artist)
  Do you mean 'This Is It' or 'Man in the Mirror'?
- Items with similar descriptions on Wikipedia
  Do you mean 'Thinking of You' or 'Happy Anywhere'?
- Items with similar titles:
  Do you mean The Return (memoir) or The Return (Shatner novel)?
- Uniform at random:
  Do you mean 'You Could Be Mine' or 'The Way I Am'</sample>
    <sample id="1216">Background knowledge (Music)
- Google search link to each song.

Easy on Me
(by Adele)
I Gotta Feeling
(by The Black Eyed Peas)

- Click here to find out about the song.
- Click here to find out about the song

We ask annotators to
- Listen to at least some of each song
- Read about each song</sample>
    <sample id="1217">Background knowledge (Music)
- Google search link to each song.

Easy on Me
(by Adele)
I Gotta Feeling
(by The Black Eyed Peas)

- Click here to find out about the song.
- Click here to find out about the song

We ask annotators to
- Listen to at least some of each song
- Read about each song</sample>
    <sample id="1218">Background knowledge (Music)

- Google search link to each song.
  - Easy on Me (by Adele)
    - Click here to find out about the song.
  - I Gotta Feeling (by The Black Eyed Peas)
    - Click here to find out about the song

- We ask annotators to
  - Listen to at least some of each song
  - Read about each song

Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)</sample>
    <sample id="1219">Background knowledge (Recipes)

Simnel Cake
Simnel cake is a fruitcake widely eaten in the United Kingdom, Ireland and other countries with patterns of migration from them, associated with Lent and Easter. It is distinguished by layers of almond paste or marzipan, and a set of eleven balls made of the same paste.

Pandan Cake
Pandan cake is a light, fluffy, green-coloured sponge cake flavoured with the juices of Pandanus amaryllifolius leaves. The cake is popular in Indonesia, Malaysia, and also the Netherlands, especially among the Indo community.</sample>
    <sample id="1220">Eliciting expressions

- We then tell the annotators which choice should be selected and ask them to describe it.

Pick this one
- Easy on Me (by Adele)
- I Gotta Feeling (by the Black Eyed Peas)

We would like you to give us 3 to 5 expressions for the chosen song to fill in your speech bubble. For example:

- The one with the piano music
- The song that's not energetic
- It has something about a river
- The newer one
- It's about not having time to choose</sample>
    <sample id="1221">Eliciting expressions

- We then tell the annotators which choice should be selected and ask them to describe it.

Pick this one
- Easy on Me (by Adele)
- I Gotta Feeling (by the Black Eyed Peas)

We would like you to give us 3 to 5 expressions for the chosen song to fill in your speech bubble. For example:

- The one with the piano music
- The song that's not energetic
- It has something about a river
- The newer one
- It's about not having time to choose

Random Examples

Music Selection
- Do you mean 'Chime' or 'Your Loving Arms'? =&gt; The one without words
- Do you mean 'These Kids' or 'Inescapable'? =&gt; It is the song sung by an Australian.
- Do you mean 'Rock the Boat' or 'Wherever You Are'? =&gt; It has synthesizer sounds in it
- Do you mean 'Telepathy' or 'Stars on 45'? =&gt; Came out in mid of 2000.
- Do you mean 'Mis-Shapes' or 'Remind Me'? =&gt; Based on life experienced in Sheffield.

Book Selection
- Do you mean 'Warlock (Hall novel)' or 'Warlock (Smith novel)'? =&gt; The one that is set in the 1880s
- Do you mean 'The Legion of Space' or 'The Body in the Library'? =&gt; It's by a famous detective writer
- Do you mean 'The Good Soldier' or 'The Good Soldiers'? =&gt; The fictional one
- Do you mean 'The Giaour' or 'The Giver'? =&gt; not the one with the 12 year old boy
- Do you mean 'Broken Sleep' or 'Broken Soup'? =&gt; It's the book that has rock and politics in it

Recipe Selection
- Do you mean 'Beurre Maître d'Hôtel' or 'Chigirtma'? =&gt; comes from Azerbaijan
- Do you mean 'Kusa mochi' or 'Uiré'? =&gt; The Japanese steamed cake
- Do you mean 'Cannoli' or 'Boconotto'? =&gt; The ones eaten at Christmas
- Do you mean 'Johnnycake' or 'Mochi'? =&gt; cornmeal is the main ingredient
- Do you mean 'Sagu' or 'Mochi'? =&gt; Not the one with rice</sample>
    <sample id="1222">AltEntities Corpus

- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions

Results with T5 XL model (accuracy):
- 92-95% if the LM has access to the same background knowledge as annotators.
- 82%-87% when the LM has access to partially overlapping background knowledge.
- ~60% when the LM (T5 XL) has only access to the entity names.
- We showed models are domain-generalizable.

Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1223">AltEntities Corpus
- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions

Results with T5 XL model (accuracy):
○ 92-95% if the LM has access to the same background knowledge as annotators.
○ 82%-87% when the LM has access to partially overlapping background knowledge.
○ ~60% when the LM (T5 XL) has only access to the entity names.
○ We showed models are domain-generalizable.

Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1224">AltEntities Corpus
- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions

Results with T5 XL model (accuracy):
○ 92%-95% if the LM has access to the same background knowledge as annotators.
○ 82%-87% when the LM has access to partially overlapping background knowledge.
○ ~60% when the LM (T5 XL) has only access to the entity names.
○ We showed models are domain-generalizable.

Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1225">AltEntities Corpus
- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions

Results with T5 XL model (accuracy):
- 92-95% if the LM has access to the same background knowledge as annotators.
- 82%-87% when the LM has access to partially overlapping background knowledge.
- ~60% when the LM (T5 XL) has only access to the entity names.
- We showed models are domain-generalizable.

Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1226">CamemBERT is initially trained on 4GB of data.</sample>
    <sample id="1227">The name of the speaker is Adam Przepiórkowski.</sample>
    <sample id="1228">The findings that led to the conclusion that the temporal drift is the main cause of performance loss include the observation that performance degrades with a larger temporal gap between the training and test data, as indicated by the table and graph on the slide.</sample>
    <sample id="1229">NLPositionality:
Characterizing Design Biases of Datasets and Models

Sebastin Santy*
University of Washington
Jenny T. Liang*
Carnegie Mellon University
Ronan Le Bras
Allen Institute for AI
Katharina Reinecke
University of Washington
Maarten Sap
Carnegie Mellon University</sample>
    <sample id="1230">NLPositionality:
Characterizing Design Biases of Datasets and Models

Sebastin Santy*
University of Washington
Jenny T. Liang*
Carnegie Mellon University
Ronan Le Bras
Allen Institute for AI
Katharina Reinecke
University of Washington
Maarten Sap
Carnegie Mellon University</sample>
    <sample id="1231">Imagine...</sample>
    <sample id="1232">Imagine...

= PerspectiveAPI score

Carl Jones
Tech Lead,
New York Times

Can you stop being a jerk? 🚫: (0.82) ✅</sample>
    <sample id="1233">Imagine...

Carl Jones  
Tech Lead,  
New York Times

Can you stop being a jerk? 🚫: (0.82) ✅

Aditya Sharma  
Tech Lead,  
Times of India

Presstitutes everywhere on the news. 🚫: (0.33) ❌</sample>
    <sample id="1234">Imagine...

Design bias example!

- Can you stop being a jerk? (0.82) ✅
- Presstitutes everywhere on the news. (0.33) ❌

Carl Jones  
Tech Lead,  
New York Times  

Aditya Sharma  
Tech Lead,  
Times of India  

= PerspectiveAPI score</sample>
    <sample id="1235">Positionality

"The perspectives [people] hold as a result of their demographics, identity, and life experiences."

[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="1236">Positionality

"The perspectives [people] hold as a result of their demographics, identity, and life experiences."

[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="1237">Positionality

"The perspectives [people] hold as a result of their demographics, identity, and life experiences.

[As a researcher,] it influences the research process and its outcomes and results." [1]

[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="1238">The slide presents the question: "Do datasets and models have positionality?" Below the question, there are three references listed:

1. Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
2. Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
3. Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1239">The image contains a slide with the title "Do datasets and models have positionality?" Below the title, there are three references listed:

1. Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
2. Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
3. Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.

The slide appears to be part of a presentation discussing the concept of positionality in datasets and models, referencing recent academic papers from conferences such as ACL, EMNLP, and CHI.</sample>
    <sample id="1240">The slide presents the question: "Do datasets and models have positionality?" It discusses anecdotal evidence related to this topic, listing three references:

1. Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
2. Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
3. Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.

The slide also mentions two types of evidence:
- Model and dataset probing [1][2]
- Theoretical definitions of model positionality [3]</sample>
    <sample id="1241">The slide presents the question: "Do datasets and models have positionality?" It discusses anecdotal evidence supporting this idea, which includes:

- Model and dataset probing [1][2]
- Theoretical definitions of model positionality [3]

The references are as follows:
[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1242">The slide presents the question: "Do datasets and models have positionality?" It discusses anecdotal evidence supporting this idea, which includes:

- Model and dataset probing [1][2]
- Theoretical definitions of model positionality [3]

The references are as follows:
[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1243">The image is a slide from a presentation with the title "Do datasets and models have positionality?" Below the title, it lists "Anecdotal evidence:" followed by two bullet points:
- Model and dataset probing [1][2]
- Theoretical definitions of model positionality [3]

At the bottom of the slide, there are references to three academic papers:
[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.

In the top right corner, there is a small video feed showing a person speaking, but their face is not visible.</sample>
    <sample id="1244">Question: Do datasets and models have positionality?

Goal: Compare annotations from users with existing datasets and models.</sample>
    <sample id="1245">NLPositionality
A framework for characterizing design biases in NLP datasets and models</sample>
    <sample id="1246">The image is a framework diagram that outlines a process for collecting, processing, and analyzing data related to social chemistry and annotations from diverse sources. Here is the transcribed content:

**Framework**

**Collection**
1. **300 instances are sampled from a dataset.**
2. **Each instance has an associated gold label.**
3. **Instances are sent as part of a study on LTW (Lab in the Wild).**
4. **Annotations from people around the world.**

**Processing**
- **Model Predictions:** The received annotations are compared against the gold labels from the dataset and predictions obtained from the models.

**Analysis**
- **Demographics Breakdown:**
  - **Age:** &lt;18, 18-25, 25-35, 35-45
  - **Gender:** Woman, Man
  - **Ethnicity:** White, Black, Hispanic, Non-B
  - **Education:** Grad, PhD, College, School, Asian
  - **Country:** USA, Canada, UK, Germany, France, Italy, Spain, Japan

6. **Pearson's r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.**

This framework appears to be used for evaluating the accuracy of model predictions by comparing them with human annotations and demographic data.</sample>
    <sample id="1247">The image is a slide titled "Framework" and it outlines a process for re-annotating datasets with diverse annotators. Here's a detailed breakdown of the content:

### Collection
1. **300 instances are sampled from a dataset.**
2. **Each instance has an associated gold label.**
3. **Instances are sent as part of a study on LTW (Lab in the Wild).**
4. **Annotations from people around the world.**

### Processing
5. **The received annotations are compared against the gold labels from the dataset and predictions obtained from the models.**

### Analysis
6. **Pearson’s r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.**

The slide also includes a table at the bottom showing demographic information such as age, gender, ethnicity, education, and country, with corresponding icons and colors to represent different categories.

On the right side of the slide, there is a note that says:
**"Re-annotate datasets with diverse annotators."**

The slide appears to be part of a presentation, possibly related to a research project or academic discussion about data annotation and model evaluation.</sample>
    <sample id="1248">**Framework**

1) Re-annotate datasets with diverse annotators.

**Collection**
- 300 instances are sampled from a dataset.
- Each instance has an associated gold label.
- Instances are sent as part of a study on LITW.
- Annotations from people around the world.

**Processing**
- Model Predictions

**Analysis**
- Pearson's r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.</sample>
    <sample id="1249">The image is a slide titled "Framework" and appears to outline a process for collecting, processing, and analyzing data related to annotations from diverse annotators. Here's a breakdown of the content:

### Collection
1. **300 instances are sampled from a dataset.**
2. **Each instance has an associated gold label.**
3. **Instances are sent as part of a study on LTW (Lab in the Wild).**
4. **Annotations from people around the world.**

### Processing
- **Model Predictions:** The received annotations are compared against the gold labels from the dataset and predictions obtained from models.

### Analysis
- **Pearson’s r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.**
- **Demographics include:**
  - Age: &lt;18, 18-25, 25-35, 35-45
  - Gender: Woman, Man
  - Ethnicity: White, Black, Hispanic, Non-B
  - Education: Grad, PhD, College, School
  - Country: USA, Germany, France, Italy, Spain

### Key Points
1. **Re-annotate datasets with diverse annotators.**

This framework seems to be used to evaluate the consistency and reliability of annotations across different demographic groups using both human and machine predictions.</sample>
    <sample id="1250">**Framework**

Collection:
1. 300 instances are sampled from a dataset.
2. Each instance has an associated gold label.
3. Instances are sent as part of a study on LITW.
4. Annotations from people around the world.

Processing:
5. The received annotations are compared against the gold labels from the dataset and predictions obtained from the models.

Analysis:
6. Pearson's r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.

2) Compare annotations by demographic to models and datasets via Pearson's R scores.</sample>
    <sample id="1251">**Framework**

1. **Collection**
   - 300 instances are sampled from a dataset.
   - Each instance has an associated gold label.

2. **Processing**
   - Model Predictions

3. **Analysis**
   - The received annotations are compared against the gold labels from the dataset and predictions obtained from the models.
   - Pearson's r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.

4. **Comparison by Demographic**
   - Compare annotations by demographic to models and datasets via Pearson's R scores.</sample>
    <sample id="1252">The image is a screenshot of a website called "Lab in the Wild." The top of the page displays the title "Lab in the Wild" and a navigation bar with options such as "Our Experiments," "Findings &amp; Data Sets," "Blog," "For Researchers," and "About Us." There is also an option to change the language, currently set to English.

Below the navigation bar, there is a section titled "Lab in the Wild" with a logo that includes a globe and the text "Lab in the Wild." To the right of this section, there is a statistic that reads "5,376,396 total participants."

Underneath, there are three sections with cartoon characters and questions:

1. **Could you live with an AI and its morals?**
   - Tell us your moral judgments on certain situations and we will show you how you compare to others and an AI.
   - Button: "Participate now!"

2. **Are you better than an AI in noticing hateful speech?**
   - Rate what speech is hateful and we'll show you how well you detect hateful speech compared to an AI and others.
   - Button: "Participate now!"

3. **Where are you on the techno-skeptic to techno-utopian scale?**
   - Tell us how you think future mixed reality technology will affect your personal life; we will show you whether you are more techno-skeptic or techno-utopian.
   - Button: "Participate now!"

On the right side of the image, there are two annotations:
- "Pool of diverse volunteers / research participants"
- "Online experiment from researchers"

The overall layout suggests that the website is used for conducting online experiments involving diverse volunteers to gather data and insights into various topics related to artificial intelligence, ethics, and technology.</sample>
    <sample id="1253">The image is a screenshot of a webpage titled "Lab in the Wild." The webpage features a logo with a globe and the text "Lab in the Wild" prominently displayed at the top. Below the logo, there are three sections with different experiments that participants can join:

1. **Could you live with an AI and its morals?**
   - Text: "Tell us your moral judgments on certain situations and we will show you how you compare to others and an AI."
   - Button: "Participate now!"

2. **Are you better than an AI in noticing hateful speech?**
   - Text: "Rate what speech is hateful and we'll show you how well you detect hateful speech compared to an AI and others."
   - Button: "Participate now!"

3. **Where are you on the techno-skeptic to techno-utopian scale?**
   - Text: "Tell us how you think future mixed reality technology will affect your personal life, we will show you whether you are more techno-skeptic or techno-utopian."
   - Button: "Participate now!"

On the right side of the webpage, there is a box highlighting the number of total participants: 5,376,396. There are also labels pointing to these sections:
- "Pool of diverse volunteers / research participants"
- "Online experiment from researchers"

The background of the webpage is light gray, and the text is primarily black with some blue highlights for buttons and links.</sample>
    <sample id="1254">Task A: Social Acceptability

1) Read the situation.
2) Enter what you think about it.
3) See what an AI and others thought about it!

The AI speculates:
I speculate that it's understandable. Hmm... Maybe I'm incorrect on this.

Study participants in the United States said:

Very bad | Bad | Expected/OK | Good | Very good
--- | --- | --- | --- | ---
50% | 40% | 30% | 60% | 50%

Participants read a situation from the Social Chemistry dataset.
Participants rate how socially acceptable the situation is.
Participants compare their responses to others' and an AI's.</sample>
    <sample id="1255">Task A: Social Acceptability

1) Read the situation.
2) Enter what you think about it.
3) See what an AI and others thought about it.

The AI speculates:
"I speculate that it's understandable. Hmm... Maybe I'm incorrect on this."

Study participants in the United States said:

- Very bad: 0%
- Bad: 0%
- Expected/OK: 40%
- Good: 60%
- Very good: 0%

Participants compare their responses to others' and an AI's.</sample>
    <sample id="1256">Task A: Social Acceptability

Analysis
Datasets - Social Chemistry
Models - Delphi - GPT-4</sample>
    <sample id="1257">Task B: Toxicity

1) Read the example:
   7 / 25
   English people smell like sour milk

2) Enter what you think about it.
   * Do you think this is hateful speech?
   * denotes a required field.
   Yes | No | Not sure
   Feel free to explain your rating.
   Enter a short description
   Submit

3) See what others thought about it!
The AI speculates:
   I speculate that this is hateful speech. Looks like we agree!

Study participants in Afghanistan said:
   Not Hateful | Not Sure | Hateful
   [Bar chart showing distribution of responses]

Participants read an instance from the Dynahate dataset.
Participants rate whether they think an instance is hate speech.</sample>
    <sample id="1258">Task B: Toxicity Analysis

Datasets - Dynahate

Models
- Perspective API
- Rewire API
- Hate RoBERTa
- GPT-4

Study Participation

16,299 annotations
1,096 annotators
87 countries</sample>
    <sample id="1259">Results
Who do NLP datasets and models align with?

Finding 1:
There is positionality in NLP.</sample>
    <sample id="1260">The image is a slide from a presentation, featuring two bar charts and a title that reads: "Datasets and models are most aligned to English-Speaking countries."

### First Bar Chart:
- **Title:** Social Acceptability (GPT-4)
- **X-axis:** Different regions or cultural groups (African Islamic, Baltic, Catholic Europe, Confucian, English-Speaking, Latin America, Orthodox Europe, Protestant Europe, West South Asia)
- **Y-axis:** Social Acceptability Score (ranging from 0 to 0.8)
- **Legend:** The English-Speaking group has the highest score at 0.74, followed by the Baltic region at 0.71, and the Confucian region at 0.74. Other regions have lower scores.

### Second Bar Chart:
- **Title:** Hate Speech &amp; Toxicity (Dynahate)
- **X-axis:** Same regions as above (African Islamic, Baltic, Catholic Europe, Confucian, English-Speaking, Latin America, Orthodox Europe, Protestant Europe, West South Asia)
- **Y-axis:** Toxicity Score (ranging from 0 to 0.75)
- **Legend:** The English-Speaking group again has the highest score at 0.70, with other regions having lower scores.

The slide emphasizes that datasets and models are most aligned with English-speaking countries in terms of social acceptability and toxicity scores.</sample>
    <sample id="1261">The image is a bar chart titled "Social Acceptability (GPT-4)" which shows the alignment of datasets and models with people of different educational backgrounds. The x-axis represents different levels of education: College, Graduate School, High School, PhD, Pre-High School, and Prof. School. The y-axis represents the social acceptability score ranging from 0.0 to 0.8.

Here are the scores for each category:
- College: 0.69*
- Graduate School: 0.69*
- High School: 0.64*
- PhD: 0.61*
- Pre-High School: 0.59*
- Prof. School: 0.49*

The text on the left side of the image states: "Datasets and models are most aligned to people with a college education."

The asterisk (*) next to the scores indicates statistical significance or a specific note related to the data.</sample>
    <sample id="1262">The image is a bar chart titled "Hate Speech &amp; Toxicity (Dynahate)" with the subtitle "Datasets and models are most aligned to people with a college education." The x-axis represents different levels of education: College, Graduate School, High School, PhD, Pre-High School, and Prof. School. The y-axis represents the score for hate speech and toxicity, ranging from 0.0 to 0.8.

Here are the scores for each category:
- College: 0.66*
- Graduate School: 0.59*
- High School: 0.59*
- PhD: 0.48*
- Pre-High School: 0.37
- Prof. School: 0.61*

The numbers next to each bar indicate the sample size (N) for each category:
- College: N=2,383
- Graduate School: N=604
- High School: N=908
- PhD: N=359
- Pre-High School: N=116
- Prof. School: N=195

The asterisk (*) next to some scores indicates statistical significance.</sample>
    <sample id="1263">Finding 2:
Some populations are left behind.</sample>
    <sample id="1264">The image is a slide from a presentation, featuring two bar charts with the title "Datasets and models are less aligned to non-binary people." The first chart is labeled "Social Acceptability (GPT-4)" and shows three categories: Man, Non-binary, and Woman. Each category has a corresponding bar indicating social acceptability scores:

- Man: N=4,082, score = 0.69*
- Non-binary: N=858, score = 0.55*
- Woman: N=4,368, score = 0.73*

The second chart is labeled "Hate Speech &amp; Toxicity (Dynahate)" and also shows three categories: Man, Non-binary, and Woman. Each category has a corresponding bar indicating hate speech and toxicity scores:

- Man: N=1,798, score = 0.65*
- Non-binary: N=329, score = 0.58*
- Woman: N=2,357, score = 0.63*

The asterisk (*) next to each score likely indicates statistical significance or a specific metric used in the analysis.

The background of the slide includes a person speaking on the right side, but their face is not visible. The overall theme of the slide suggests that datasets and models may not be equally aligned or sensitive towards non-binary individuals compared to men and women.</sample>
    <sample id="1265">So, what can we do?
Addressing positionality in NLP</sample>
    <sample id="1266">Recommendations

1. Keep a record of all relevant design choices made throughout building datasets or models.

2. Do NLP research through the lens of perspectivism:
a. Share disaggregated dataset labels!
b. Use modeling techniques that can handle annotator disagreement.</sample>
    <sample id="1267">Recommendations

1. Keep a record of all relevant design choices made throughout building datasets or models.
2. Do NLP research through the lens of perspectivism:
   a. Share disaggregated dataset labels!
   b. Use modeling techniques that can handle annotator disagreement.
3. Building specialized datasets and models with and for specific communities is valuable for inclusive NLP (e.g., Masakhane initiative¹).

[1] https://www.masakhane.io</sample>
    <sample id="1268">Thanks!

Dashboard Link: nlpositionality.cs.washington.edu/
Paper: bit.ly/NLPositionality-Paper/

Delphi
(http://delphi.allenai.org)

Age
Gender
Ethnicities
Religion

Education Level
Country (Residence)
Country (Longest)
Native Language</sample>
    <sample id="1269">Permuting the tokens for the output sequence is necessary to explore all possible orderings of the tokens, which helps in capturing the dependencies and relationships between different parts of the sentence more effectively. This approach allows the model to consider various permutations of the tokens, thereby improving its ability to generate accurate and contextually relevant outputs.</sample>
    <sample id="1270">The authors recommended increasing transparency about bias mitigation methods to address positive stereotypes and essentializing narratives, and to adopt an intersectional lens in their work.</sample>
    <sample id="1271">Minimal-pair unacceptable inputs are sentences that are grammatically correct but are considered less natural or less likely to be produced by a language model due to their structure or meaning.</sample>
    <sample id="1272">The authors used F1 scores for Named Entity Recognition (NER) and Classification (CLS), as well as Hamming and EMR scores for other tasks such as Medical Report, Specialties, MUSCA-DET, ESSAI, CAS, POS, FrenchMedMCQA, QUAERO-EMEA, and QUAERO-MEDLINE.</sample>
    <sample id="1273">The metric used for measuring inter-annotator agreement in the presented slides is Krippendorff's Alpha.</sample>
    <sample id="1274">The domain chosen to add completely unrelated sentences to the unacceptable and acceptable queries is Wikipedia.</sample>
    <sample id="1275">The affiliations of the authors of the paper are Heinrich Heine University Düsseldorf, Germany.</sample>
    <sample id="1276">MultiInstruct differs from other benchmarks by focusing on instruction tuning for multimodal pre-trained models and highlighting the imbalance in instructional datasets between NLP and multimodal tasks, with over 1600 language-only instruction tasks but no large-scale publicly available multimodal instruction tasks.</sample>
    <sample id="1277">3.</sample>
    <sample id="1278">Binary coordination refers to the grammatical structure where two elements are coordinated, typically by a conjunction such as "and," "or," or "but." In this context, it involves the combination of two conjuncts (elements being coordinated) and the analysis of their lengths in terms of characters, syllables, and words. The figure shows how the proportion of shorter left conjuncts changes depending on the absolute difference in length between the conjuncts.</sample>
    <sample id="1279">The image does not provide information about the length of the prompts used in the study. It focuses on the distribution of words related to Black stereotypes across different personas generated by GPT-3.5 and GPT-4 models. The length of the prompts is not mentioned or depicted in the graph.</sample>
    <sample id="1280">The findings suggest that smaller T5 models fine-tuned on Coscript can generate higher quality scripts than larger LLMs like GPT-3, Codex, and InstructGPT. This implies that there is potential for using smaller models with specific training datasets to achieve high-quality results in constrained language planning tasks.</sample>
    <sample id="1309">The learning strategies investigated in the work include "From scratch with full model construction" and "Continual pre-training using an existing pre-trained model."</sample>
    <sample id="1310">The video does not provide specific numerical values for the factor of overfitting due to test reuse. It only mentions that there is no diminishing returns and that temporal drift has not been observed as factors contributing to performance drop.</sample>
    <sample id="1311">The quality of the simplification was evaluated using metrics such as SARI, BLEU, BS-P, and FRE. These metrics were applied at both document level and sentence level for different datasets like DEPLAIN-APA test, DEPLAIN-APA-web, and DEPLAIN-WEB test.</sample>
    <sample id="1312">Yes, according to the chart, existing language models (LMs) such as BERT-base, BERT-large, and RoBERTa-base show varying degrees of political bias along both the social and economic axes. The chart indicates that some models lean towards authoritarian or libertarian positions on these axes, suggesting that language models can exhibit different political biases.</sample>
    <sample id="1347">Cognitive dissonance is defined as "two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent."</sample>
    <sample id="1348">The most liberal language model, according to the figure, appears to be Alpaca.</sample>
    <sample id="1349">Yes, cumulative training generally performs better than iterative in active learning according to the AUC values shown in the chart.</sample>
    <sample id="1350">The name of the speaker is Sara Papi.</sample>
    <sample id="1351">The data for the MuDa benchmark was taken from TED Talks.</sample>
    <sample id="1352">The image is a slide from a presentation at ACL 2023, featuring research by Adam Przepiórkowski and Michał Woźniak. The title of the presentation is "Conjunct Lengths in English, Dependency Length Minimization, and Dependency Structure of Coordination." The authors are affiliated with the Institute of Computer Science, Polish Academy of Sciences, located at ul. Jana Kazimierza 5, 01-248 Warsaw, and the University of Warsaw.

The slide discusses different dependency structures for coordination, presenting examples under four categories:

1. **Bouquet/Stanford (Universal Dependencies):**
   - Homer loves Lisa, Bart, and Maggie.
   - The sentence structure shows dependencies where each noun phrase (Lisa, Bart, Maggie) is connected to the verb "loves" through separate arcs.

2. **Chain/Moscow:**
   - Homer loves Lisa, Bart, and Maggie.
   - This structure suggests a chain-like dependency where the subject "Homer" is connected to the object "Lisa," which then connects to "Bart," and finally to "Maggie."

3. **Conjunction-headed/Prague:**
   - Homer loves Lisa, Bart, and Maggie.
   - Here, the conjunction "and" is considered the head, and all other elements are dependent on it, forming a single arc from "Homer" to "and" and then to each noun phrase.

4. **Multi-headed/London:**
   - Homer loves Lisa, Bart, and Maggie.
   - This structure indicates multiple heads, where the verb "loves" and the conjunction "and" both have dependencies, creating a more complex dependency tree.

The slide uses arrows to visually represent these dependency structures, showing how each element in the sentence is connected to others.</sample>
    <sample id="1353">Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1354">The image contains a slide titled "Dependency Structure of Coordination" with four different dependency structures labeled as follows:

1. **Bouquet/Stanford (Universal Dependencies):**
   - Homer loves Lisa, Bart, and Maggie.

2. **Chain/Moscow:**
   - Homer loves Lisa, Bart, and Maggie.

3. **Conjunction-headed/Prague:**
   - Homer loves Lisa, Bart, and Maggie.

4. **Multi-headed/London:**
   - Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1355">Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1356">Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1357">Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1358">Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1359">Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1360">Dependency Structure of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="1361">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Merge read it yesterday.
  - good

- Merge read yesterday it.
  - bad

- Merge read this absolutely fascinating book about bees yesterday.
  - good

- Merge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1362">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Merge read it yesterday.
  - good

- Merge read yesterday it.
  - bad

- Merge read this absolutely fascinating book about bees yesterday.
  - good

- Merge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1363">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Merge read it yesterday.
  - good

- Merge read yesterday it.
  - bad

- Merge read this absolutely fascinating book about bees yesterday.
  - good

- Merge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1364">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Merge read it yesterday.
  - good

- Merge read yesterday it.
  - bad

- Merge read this absolutely fascinating book about bees yesterday.
  - good

- Merge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1365">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Merge read it yesterday.
  - good

- Merge read yesterday it.
  - bad

- Merge read this absolutely fascinating book about bees yesterday.
  - good

- Merge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1366">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1367">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1368">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1369">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1370">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1371">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Merge read it yesterday.
  - good

- Merge read yesterday it.
  - bad

- Merge read this absolutely fascinating book about bees yesterday.
  - good

- Merge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1372">Conjunct Lengths in English

Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):
- left conjuncts tend to be shorter (observed before),
- this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed),
- not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="1373">Conjunct Lengths in English

Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):
- left conjuncts tend to be shorter (observed before)
- this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed),
- not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="1374">Conjunct Lengths in English

Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):
- left conjuncts tend to be shorter (observed before),
- this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed),
- not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="1375">Conjunct Lengths in English

Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):
- left conjuncts tend to be shorter (observed before),
- this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed),
- not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="1376">Conjunct Lengths in English

Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):
- left conjuncts tend to be shorter (observed before),
- this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed),
- not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="1377">Conjunct Lengths in English

Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):
- left conjuncts tend to be shorter (observed before),
- this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed)
- not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="1378">Conjunct Lengths in English

Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):
- left conjuncts tend to be shorter (observed before),
- this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed)
- not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="1379">Conjunct Lengths in English

Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):
- left conjuncts tend to be shorter (observed before),
- this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed),
- not when it is on the right (Ted and Ned laughed).</sample>
    <sample id="1380">Figure 1: Proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths (with confidence bands)</sample>
    <sample id="1381">The image contains six graphs, each representing different conditions and metrics related to the proportion of shorter left conjuncts depending on the absolute difference in conjunct lengths. The graphs are labeled as follows:

1. **NO governor (length in CHARACTERS)**
2. **NO governor (length in SYLLABLES)**
3. **NO governor (length in WORDS)**
4. **Governor on the LEFT (length in CHARACTERS)**
5. **Governor on the LEFT (length in SYLLABLES)**
6. **Governor on the LEFT (length in WORDS)**
7. **Governor on the RIGHT (length in CHARACTERS)**
8. **Governor on the RIGHT (length in SYLLABLES)**
9. **Governor on the RIGHT (length in WORDS)**

Each graph includes a line plot showing the proportion of shorter left conjuncts on the y-axis against the absolute difference in conjunct lengths on the x-axis. The graphs also display confidence bands around the lines.

The bottom of the image includes a caption that reads:
"Figure 1: Proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths (with confidence bands)"</sample>
    <sample id="1382">Figure 1: Proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths (with confidence bands)</sample>
    <sample id="1383">Compatibility with Dependency Structures of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.
  NO

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.
  NO

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.
  YES

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.
  YES</sample>
    <sample id="1384">See the paper for the full argument!
Talk to us at the poster session!</sample>
    <sample id="1385">The name of the speaker is Matthias Lindemann, Alexander Koller, and Ivan Titov.</sample>
    <sample id="1386">Cross-lingual transfer refers to training on one source language and transferring knowledge to another language.</sample>
    <sample id="1387">The affiliations of the authors are Saarland University, Amazon Alexa, and University of Vienna.</sample>
    <sample id="1388">AL / AL_CA(s)</sample>
    <sample id="1416">The drawbacks of tree-based methods include the need to obtain pre/post-processing logical forms and grammar induction.</sample>
    <sample id="1417">The authors, Shuheng Liu and Alan Ritter, are affiliated with the School of Interactive Computing at Georgia Institute of Technology.</sample>
    <sample id="1495">ABC-Eval stands for Annotating Behaviors in Chat.</sample>
    <sample id="1496">The performance delta between CoNLL-2003 and CoNLL++ remains higher than 5 percentage points until the year 2016.</sample>
    <sample id="1527">The affiliations of the authors of the paper are:

- The University of Edinburgh (Informatics)
- NLP UKRI Centre for Doctoral Training
- Saarland University
- UvA (University of Amsterdam)</sample>
    <sample id="1528">The name of the speaker is Siyu Yuan.</sample>
    <sample id="1529">There are five authors involved in the paper: Patrick Fernandes, Kayo Yin, Emmy Liu, André F. T. Martins, and Graham Neubig.</sample>
    <sample id="1530">The approach is compared to a state-of-the-art architecture specifically tailored for SimulST.</sample>
    <sample id="1531">The image contains the following written text:

```
MULTIINSTRUCT: Improving
Multi-Modal Zero-Shot Learning
via Instruction Tuning

Zhiyang Xu*, Ying Shen*, Lifu Huang
Department of Computer Science, Virginia Tech

*Equal Contribution
```</sample>
    <sample id="1532">Pre-trained Language Models for Downstream Tasks

(A) Pretrain–finetune (BERT, T5)
- Pretrained LM
  - Finetune on task A
  - Inference on task A
  - Typically requires many task-specific examples
  - One specialized model for each task

(B) Prompting (GPT-3)
- Pretrained LM
  - Improve performance via few-shot prompting or prompt engineering
  - Inference on task A

(C) Instruction tuning (FLAN)
- Pretrained LM
  - Instruction-tune on many tasks: B, C, D, ...
  - Model learns to perform many tasks via natural language instructions
  - Inference on unseen task

Figure 2: Comparing instruction tuning with pretrain–finetune and prompting.

Image credit: Wei, Jason, et al. "Finetuned language models are zero-shot learners."</sample>
    <sample id="1533">Pre-trained Language Models for Downstream Tasks

(A) Pretrain–finetune (BERT, T5)
- Pretrained LM
  - Finetune on task A
  - Inference on task A
  - Typically requires many task-specific examples
  - One specialized model for each task

(B) Prompting (GPT-3)
- Pretrained LM
  - Improve performance via few-shot prompting or prompt engineering
  - Inference on task A

(C) Instruction tuning (FLAN)
- Pretrained LM
  - Instruction-tune on many tasks: B, C, D, ...
  - Model learns to perform many tasks via natural language instructions
  - Inference on unseen task

Figure 2: Comparing instruction tuning with pretrain–finetune and prompting.

Image credit: Wei, Jason, et al. "Finetuned language models are zero-shot learners."</sample>
    <sample id="1534">The text in the image is:

Language-only</sample>
    <sample id="1535">Instruction Tuning on
Multimodal Pre-trained Models</sample>
    <sample id="1536">Imbalance in Instructional Datasets between NLP and Multimodal

1600+ Language-only instruction tasks</sample>
    <sample id="1537">Imbalance in Instructional Datasets between NLP and Multimodal

1600+ Language-only instruction tasks

NO large-scale, publicly-available multimodal instruction tasks</sample>
    <sample id="1538">MULTIINSTRUCT

The first multimodal instruction tuning benchmark dataset

- 62 diverse multimodal tasks
- 10 broad groups
- 5 expert-written instructions

Figure 2: Task Groups Included in MULTIINSTRUCT. The yellow boxes represent tasks used for evaluation, while the white boxes indicate tasks used for training.</sample>
    <sample id="1539">MULTIINSTRUCT

The first multimodal instruction tuning benchmark dataset

- 62 diverse multimodal tasks
- 10 broad groups
- 5 expert-written instructions

Figure 2: Task Groups Included in MULTIINSTRUCT. The yellow boxes represent tasks used for evaluation, while the white boxes indicate tasks used for training.</sample>
    <sample id="1540">OFA (One For All)
- A unified multi-modal pre-trained model that is capable of performing both understanding and generation tasks with single or multiple modalities.
- OFA has a unified vocabulary for language, image tokens and the coordinates of a bounding box.

Tasks:
- Visual Grounding
- Grounded Captions
- Image Captioning
- Visual Question Answering
- Image Editing

Wang, Peng, et al. "Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework."</sample>
    <sample id="1541">The image is a slide from a presentation titled "MULTIINSTRUCT." It illustrates four tasks related to image understanding and captioning:

1. **Grounded Caption**
   - **Input:** Generate a caption for &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Output:** blue and white tennis racquet

2. **Text Localization**
   - **Input:** Select the region that contains the text “den.”
   - **Options:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Output:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referring Expression Selection**
   - **Input:** Select the region of the object described by “A blue train in the front.”
   - **Options:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Output:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Question-Image Matching**
   - **Input:** Given the content of the image, do you have enough information to answer “Is it a sunny day?”
   - **Options:** “the question is relevant to the image” or “the question is irrelevant to the image”
   - **Output:** the question is irrelevant to the image

The slide is labeled as "Figure 1: Example Instances from MULTIINSTRUCT for Four Tasks."</sample>
    <sample id="1542">The image is a slide from a presentation titled "MULTIINSTRUCT." It illustrates four tasks within the MULTINSTRUCT framework, each with an example input and output. Here is the written content for each task:

1. **Grounded Caption**
   - **Input:** Generate a caption for &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Output:** blue and white tennis racquet

2. **Text Localization**
   - **Input:** Select the region that contains the text “den.”
   - **Options:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Output:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referring Expression Selection**
   - **Input:** Select the region of the object described by “A blue train in the front.”
   - **Options:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Output:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Question-Image Matching**
   - **Input:** Given the content of image, do you have enough information to answer “Is it a sunny day?”
   - **Options:** “the question is relevant to the image” or “the question is irrelevant to the image”
   - **Output:** the question is irrelevant to the image

The slide is labeled as "Figure 1: Example Instances from MULTINSTRUCT for Four Tasks."</sample>
    <sample id="1543">The image is a slide from a presentation titled "MULTIINSTRUCT." It illustrates four tasks within the MULTINSTRUCT framework, each with an input and output example:

1. **Grounded Caption**
   - **Input:** Generate a caption for &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Output:** blue and white tennis racquet

2. **Text Localization**
   - **Input:** Select the region that contains the text “den”.
   - **Options:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Output:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referring Expression Selection**
   - **Input:** Select the region of the object described by “A blue train in the front.”
   - **Options:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Output:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Question-Image Matching**
   - **Input:** Given the content of image, do you have enough information to answer “Is it a sunny day?”
   - **Options:** “the question is relevant to the image” or “the question is irrelevant to the image”
   - **Output:** the question is irrelevant to the image

At the bottom of the slide, there is a caption: "Figure 1: Example Instances from MULTINSTRUCT for Four Tasks."</sample>
    <sample id="1544">The English content in the image is already written as text: "Multi-modal Instruction Tuning."</sample>
    <sample id="1545">Multi-Modal Instruction Turning

- Training Dataset Construction:
  - Use 53 tasks from 9 groups for training.
  - Sample 10,000 instances per task.

- Testing Dataset Construction:
  - Reserve the entire Commonsense Reasoning group for testing.
  - Select additional 5 tasks from VQA and Miscellaneous groups.
  - We use all the instances in the test split for each task.
  - Randomly sample 20 tasks from the test split of Natural Instructions dataset as unseen tasks for NLP.</sample>
    <sample id="1546">Multi-Modal Instruction Turning

- Training Dataset Construction:
  - Use 53 tasks from 9 groups for training.
  - Sample 10,000 instances per task.

- Testing Dataset Construction:
  - Reserve the entire Commonsense Reasoning group for testing.
  - Select additional 5 tasks from VQA and Miscellaneous groups.
  - We use all the instances in the test split for each task.
  - Randomly sample 20 tasks from the test split of Natural Instructions dataset as unseen tasks for NLP.</sample>
    <sample id="1547">### Implementation Details

- **Training details:**
  - Pre-trained OFA-Large model (472M)
  - Mix all the instances for all tasks.
  - Each instance is randomly combined with one of its five instruction templates.

- **Testing details:**
  - For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
  - We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1548">### Implementation Details

- **Training details:**
  - Pre-trained OFA-Large model (472M)
  - Mix all the instances for all tasks.
  - Each instance is randomly combined with one of its five instruction templates.

- **Testing details:**
  - For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
  - We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1549">Implementation Details

- Training details:
  - Pre-trained OFA-Large model (472M)
  - Mix all the instances for all tasks.
  - Each instance is randomly combined with one of its five instruction templates.

- Testing details:
  - For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
  - We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1550">Evaluation Metrics

- For multi-modal classification tasks (Visual Entailment, Visual Spatial Reasoning, Natural Language Visual Reasoning, and Disaster Type Classification) we report the Accuracy.
- For multi-modal generation tasks (Commonsense VQA, Text VQA, Grounded VQA, Visual Text Extraction, and Visual Dialogue) we report the Rouge-L.
- For NLP tasks, we report Rouge-L.

- We also compute the aggregated performance for each model based on the mean of the model's performance on all multimodal and NLP unseen tasks. We use Rouge-L as the performance score for most tasks, and Accuracy for tasks that only have accuracy as a metric.</sample>
    <sample id="1551">Sensitivity

How sensitive the model is towards to **variety** of instructions for the **same task**:

- Ability to consistently produce the same results for the same task, regardless of slight variations in the wording of instructions.

\[
\mathbb{E}_{t \in T} \left[ \frac{\sigma_{i \in I^t} \left[ \mathbb{E}_{(x,y) \in \mathcal{D}^t} [ \mathcal{L}(f_\theta(i,x),y)] \right]}{\mu_{i \in I^t} \left[ \mathbb{E}_{(x,y) \in \mathcal{D}^t} [ \mathcal{L}(f_\theta(i,x),y)] \right]} \right]
\]</sample>
    <sample id="1552">Effectiveness of Instruction Tuning on MULTIINSTRUCT

Table 1: Zero-shot Performance on Multimodal Commonsense Reasoning. The best performance is in bold.

| Model | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|-------|-----------------|-------------------|--------------------------|------|
| OFA   | 17.93           | 48.99             | 52.01                    | 56.06 |
| OFATaskName | -              | -                | -                        | -    |
| OFAMultiInstruct | 52.01 | 50.60 ± 1.12 | 33.01 | 55.96 |

Transfer Learning from NATURAL INSTRUCTIONS
| Model | OFANaturalInstruct | OFAMixedInstruct | OFASeqInstruct |
|-------|--------------------|------------------|-----------------|
| Max   | 27.15              | 50.40            | 50.93           |
| Avg ± Std | 14.99 ± 9.12       | 49.34 ± 1.04     | 50.07 ± 1.07    |
| ACC   | 7.35               | 31.31            | 31.23           |

Table 2: Zero-shot Performance on Question Answering and Miscellaneous. The best performance is in bold.

| Model | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|-------|----------|--------------|------------------------|-----------------|------------------------------|
| OFA   | 15.21    | 23.80        | 36.31                  | 45.46           | 14.30                        |
| OFATaskName | -        | -            | -                      | -               | -                            |
| OFAMultiInstruct | 27.22   | 46.32        | 74.35                  | 46.38           | 64.88                        |

Transfer Learning from NATURAL INSTRUCTIONS
| Model | OFANaturalInstruct | OFAMixedInstruct | OFASeqInstruct |
|-------|--------------------|------------------|-----------------|
| Max   | 5.59               | 24.15            | 27.03           |
| Avg ± Std | 5.40 ± 0.24        | 23.67 ± 0.47     | 26.67 ± 0.47    |
| ACC   | 0.00               | 63.79            | 64.19           |</sample>
    <sample id="1553">Effectiveness of Instruction Tuning on MULTIINSTRUCT

Table 1: Zero-shot Performance on Multimodal Commonsense Reasoning. The best performance is in bold.

| Model | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|-------|-----------------|-------------------|--------------------------|------|
| OFA   | 17.93           | 48.99             | 52.01                    | 56.06 |
| OFATaskName | -              | -                | -                        | -    |
| OFAMultiInstruct | 52.01 | 50.60 ± 1.12 | 33.01 | 55.96 |

Transfer Learning from NATURAL INSTRUCTIONS
| Model | OFANaturalInstruct | OFAMixedInstruct | OFASeqInstruct |
|-------|--------------------|------------------|-----------------|
| Max   | 27.15              | 50.40            | 50.93           |
| Avg±Std | 14.99 ± 9.12       | 49.34 ± 1.04     | 50.07 ± 1.07    |
| ACC   | 7.35               | 31.31            | 31.23           |

Table 2: Zero-shot Performance on Question Answering and Miscellaneous. The best performance is in bold.

| Model | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|-------|----------|--------------|------------------------|-----------------|------------------------------|
| OFA   | 15.21    | 23.80        | 27.22                  | 45.46           | 14.30                        |
| OFATaskName | -        | -            | -                      | -               | -                            |
| OFAMultiInstruct | 27.22 | 46.32        | 74.35                  | 46.38           | 64.88                        |

Transfer Learning from NATURAL INSTRUCTIONS
| Model | OFANaturalInstruct | OFAMixedInstruct | OFASeqInstruct |
|-------|--------------------|------------------|-----------------|
| Max   | 5.59               | 24.15            | 27.03           |
| Avg±Std | 5.40 ± 0.24        | 23.67 ± 0.47     | 26.67 ± 0.47    |
| ACC   | 0.00               | 63.79            | 64.19           |</sample>
    <sample id="1554">The image is a slide from a presentation titled "Impact of Increasing Multimodal Instruction Task Clusters." The slide lists various task clusters and their corresponding tasks, along with a graph showing model performance as the number of multimodal instruction task clusters increases.

Here is the written content from the slide:

---

**Impact of Increasing Multimodal Instruction Task Clusters**

- **Img Und**
  - VQA + Image Understanding

- **Grounding**
  - Grounded Matching + Grounded Generation

- **MISC, ITM**
  - Temporal Ordering + Miscellaneous + Image Text Matching

- **Relation**
  - Visual Relationship

- **Region**
  - Region Understanding

- **NLP**
  - NLP tasks

---

**Figure 3: Model Performance as the Number of Multimodal Instruction Task Clusters Increases**

The graph on the right side of the slide shows three lines representing different performance types:
- **Max**: The highest performance achieved.
- **Avg**: The average performance.
- **Sensitivity**: The sensitivity of the model to changes in the number of task clusters.

The x-axis represents the number of task clusters, and the y-axis represents aggregated performance. The graph includes labels for each set of task clusters added at different points (e.g., "+ Img Und (16)", "+ Grounding (16)", etc.).

---</sample>
    <sample id="1555">Effect of Diverse Instructions on Instruction Tuning

- OFA finetuned on 5 instructions achieves much higher aggregated performance on all evaluation tasks and shows lower sensitivity.

Table 3: Effect of Different Number of Instructions.
Performance of OFAMultiInstruct finetuned on different numbers of instructions.

| # of Instructions | Aggregated Performance ↑ | Sensitivity ↓ |
|-------------------|--------------------------|--------------|
| 1 Instruction      | 42.81                    | 24.62        |
| 5 Instructions     | 47.82                    | 10.45        |</sample>
    <sample id="1556">Effect of Fine-tuning Strategies on Model Sensitivity

- Instruction tuning on MultiInstruct can significantly reduce the sensitivity of OFA.
- Transfer learning from Natural Instructions dataset can further reduce the sensitivity of the model.

Figure 4: Model Sensitivity on Unseen Evaluation Tasks. Lower is better.</sample>
    <sample id="1557">Zero-Shot Performance on NLP Tasks

- Instruction Tuning on MultiInstruct can improve zero-shot performance on unseen NLP tasks.
- The transfer learning strategy MixedInstruct can best preserve the zero-shot capability gained on Natural Instructions dataset.

Table 4: Zero-shot Performance on NLP tasks. The performance is reported in Rouge-L and the best performance is in bold.

| Model | RougeL |
|-------|--------|
| OFA   | 2.25   |
| OFAMultiInstruct | 12.18 |
| OFANaturalInstructions | 43.61 |
| OFAMixedInstructions | 43.32 |
| OFASeqInstructions | 30.79 |</sample>
    <sample id="1558">Conclusion

- First large-scale multi-modal instruction tuning dataset.
  - Contains 62 multi-modal tasks from 10 broad categories.
- Significantly improve the zero-shot capability of OFA via instruction tuning.
- Explore several transferring learning techniques and show their benefits.
- Design a new metric sensitivity.</sample>
    <sample id="1559">One More Thing!

We are collecting a much larger multimodal instruction tuning dataset with around 150 additional vision-language tasks and we will release them soon!</sample>
  </task>
</testset>