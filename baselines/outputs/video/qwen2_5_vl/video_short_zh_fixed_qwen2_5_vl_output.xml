<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">语言模型的主要数据来源是预训练数据。</sample>
    <sample id="1">这篇论文的作者所属机构包括McGill University、Mila和Microsoft Research。</sample>
    <sample id="2">DEPLAIN：一种包含同语言翻译的德语平行语料库，用于简化句子和文档

Regina Stodden, Omar Momen, Laura Kallmeyer

德国杜塞尔多夫海因里希·海涅大学

ACL 2023</sample>
    <sample id="3">DEPLAIN：一种包含同语言翻译的德语平行语料库，用于简化句子和文档

Regina Stodden, Omar Momen, Laura Kallmeyer

德国杜塞尔多夫海因里希·海涅大学

ACL 2023

1. 文本简化
什么是、为什么以及如何进行？</sample>
    <sample id="4">文本简化示例

原文：
“工会主张，例如，应支付更高的工资。”

平实语言：
“工会主张，例如，应该争取更高的工资或更多的假期。”</sample>
    <sample id="5">文本简化示例

原文：
“工会主张，例如要求支付更高的工资。”

平实语言：
“工会主张，例如为了更高的工资或更多的假期。”</sample>
    <sample id="6">文本简化示例

原文：
“工会主张，例如要求支付更高的工资。”

简化语言：
“工会主张，例如为了更高的工资或更多的假期。”</sample>
    <sample id="7">文本简化示例

原文：
“工会主张，例如，应支付更高的工资。”

平实语言：
“工会主张，例如，应该争取更高的工资或更多的假期。”</sample>
    <sample id="8">这张图片展示了一个关于德语文本简化语料库的幻灯片。幻灯片的标题是“2. DE-plain：一个新的语料库”。幻灯片的主要内容是一个图表，展示了不同类型的德语文本简化语料库的数量。图表的标题是“Sentence Level”（句子级别），并且有一个蓝色的横幅写着“German Text Simplification Corpora”（德语文本简化语料库）。

图表中列出了几个不同的语料库及其对应的句子数量：
1. Klapfer (Klamer et al., 2013) - 2000个句子
2. TextComplexityDE19 (Nieder et al., 2019) - 250个句子
3. ZEST-data (Millison et al., 2020) - 1198个句子
4. APPLHA-or-a2 (Springer et al., 2021) - 9456个句子
5. APPLHA-or-b1 (Springer et al., 2021) - 10268个句子
6. Simple-German-Corpus (Robecek et al., 2020) - 5942个句子

此外，图表还显示了DE-plain语料库的两个子集：
1. DE-plain-APA - 483个句子
2. DE-plain-web - 756个句子

幻灯片上还有一个小图例，说明了不同颜色代表的领域类型和对齐方式。</sample>
    <sample id="9">图片中的英文内容是关于德语文本简化语料库的图表，标题为“German Text Simplification Corpora”。图表分为两部分：左侧是一个柱状图，显示了不同领域的文本简化语料库的数量；右侧是一个饼图，展示了DEplain-APA和DEplain-web两个语料库的详细信息。</sample>
    <sample id="10">这张图片展示了一个关于德语文本简化语料库的幻灯片。标题是“German Text Simplification Corpora”，副标题是“Sentence Level”。幻灯片上有一个柱状图，显示了不同领域的德语文本简化语料库的数量。每个柱子代表一个特定的领域和对齐方式（手动或自动）。具体数据如下：

- Klapfer (Klamer et al. 2013): 手动 - 2000；自动 - 250
- TextComplexityDE19 (Nieder et al. 2019): 手动 - 1198；自动 - 1198
- ZEST-data (Mullinson et al. 2020): 手动 - 9456；自动 - 10268
- APPLHA-or-a2 (Springer et al. 2021): 手动 - 5942；自动 - 780
- Simple-German-Corpus (Robotek et al. 2020): 手动 - 195；自动 - 1132

此外，幻灯片上还有一个饼图，显示了DEplain-APA和DEplain-web两个语料库的详细数据：
- DEplain-APA: 总数 - 13122；手动 - 483；自动 - 756
- DEplain-web: 总数 - 3450；手动 - 49；自动 - 640</sample>
    <sample id="11">这张幻灯片的标题是“德语文本简化语料库”。幻灯片的内容分为两部分：

1. 左侧是一个柱状图，显示了不同领域的德语文本简化语料库的数量。每个柱子代表一个特定的领域和数据集，例如“Klapper”、“TextComplexityDE19”、“ZEST-data”等，并且标注了具体的数量。

2. 右侧是一个饼图，展示了DEplain-APA和DEplain-web两个数据集的详细信息。DEplain-APA的数据集包含13,122个句子，其中483个句子被标记为“health”，756个句子被标记为“public auth.”，其他类别如“mixed”、“news”、“L2”、“fiction”、“bible”和“politics”的数量分别为432、640、562、175和629。

幻灯片底部的文字是“Sentence Level”，表示这些数据是基于句子级别的统计结果。</sample>
    <sample id="12">这张幻灯片的标题是“German Text Simplification Corpora”，意思是“德语文本简化语料库”。幻灯片的内容分为两部分：

1. 左侧是一个柱状图，显示了不同领域的德语文本简化语料库的数量。每个柱子代表一个特定的领域和数据集，例如：
   - Klapfer (Klamer et al., 2013)：2000个句子
   - TextComplexityDE19 (Nieden et al., 2019)：250个句子
   - ZEST-data (Millison et al., 2020)：1198个句子
   - APPLHA-or-a2 (Springer et al., 2021)：9456个句子
   - APPLHA-or-b1 (Springer et al., 2021)：10268个句子
   - Simple-German-Corpus (Robotek et al., 2020)：5942个句子

2. 右侧是一个饼图，显示了DEplain-APA和DEplain-web两个数据集的详细信息：
   - DEplain-APA：13,122个句子，其中483个句子被标记为“health”（健康），756个句子被标记为“public auth.”（公共认证）。
   - DEplain-web：3450个句子，其中40个句子被标记为“health”（健康），640个句子被标记为“public auth.”（公共认证），562个句子被标记为“politics”（政治），175个句子被标记为“public auth.”（公共认证），629个句子被标记为“politics”（政治）。

幻灯片底部的文字是“Sentence Level”，意思是“句子级别”。</sample>
    <sample id="13">图片中的英文内容翻译成中文如下：

标题：德语文本简化语料库

段落：句子级别</sample>
    <sample id="14">图片中的英文内容翻译成中文如下：

- **类型简化**
  - 新闻：n = 46
  - 圣经：n = 155
  - L2：n = 157
  - 小说：n = 72

- **简化变换**
  - 重新排序：DEplain-apa = 50%，DEplain-web = 10%
  - 重述：DEplain-apa = 10%，DEplain-web = 30%
  - 词汇替换：DEplain-apa = 80%，DEplain-web = 90%
  - 单词添加：DEplain-apa = 40%，DEplain-web = 10%
  - 单词删除：DEplain-apa = 30%，DEplain-web = 20%</sample>
    <sample id="15">图片中的英文内容翻译成中文如下：

- **类型简化**
  - 新闻：n = 46
  - 圣经：n = 155
  - L2：n = 157
  - 小说：n = 72

- **简化变换**
  - 重新排序：DEplain-apa
  - 重述：DEplain-web
  - 词汇替换：DEplain-apa
  - 单词添加：DEplain-web
  - 单词删除：DEplain-apa</sample>
    <sample id="16">图片中的英文内容翻译成中文如下：

- **类型简化**
  - 新闻：n = 46
  - 圣经：n = 155
  - L2：n = 157
  - 小说：n = 72

- **简化变换**
  - DEplain-apa
  - DEplain-web</sample>
    <sample id="17">图片中的英文内容翻译成中文如下：

- **类型简化**
  - 新闻：n = 46
  - 圣经：n = 155
  - L2：n = 157
  - 小说：n = 72

- **简化变换**
  - DEplain-APA
  - DEplain-web</sample>
    <sample id="18">图片中的英文内容翻译成中文如下：

- **类型简化**
  - 新闻：n = 46
  - 圣经：n = 155
  - L2：n = 157
  - 小说：n = 72

- **简化变换**
  - 重新排序：DEplain-apa = 50%，DEplain-web = 10%
  - 重述：DEplain-apa = 10%，DEplain-web = 30%
  - 词法替换：DEplain-apa = 80%，DEplain-web = 90%
  - 单词添加：DEplain-apa = 40%，DEplain-web = 10%
  - 单词删除：DEplain-apa = 30%，DEplain-web = 20%</sample>
    <sample id="19">3. 用例
自动对齐和简化

自动对齐评估结果（上部分）和n:m能力（下部分）

| 名称 | 描述 | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | 使用句子嵌入相似性进行层次化对齐 | .94 | - |
| Sent-LaBSE | 类似于无语言依赖的BERT变换器的嵌入 | .961 | - |
| Sent-RoBERTa | 类似于跨英语和德语RoBERTa的嵌入 | .960 | - |
| CATS-C3G | 不同的相似度度量，例如n-grams (C3G)/词向量 | .247 | - |
| VecAlign | 基于多语言句子嵌入的多语言对齐器 | .271 | .260 |
| BERTalign | 允许句法变换方法产生n:m对齐 | .743 | .387 |
| MASSalign | 基于TF-IDF相似度矩阵的邻近驱动方法 | .846 | .819 |</sample>
    <sample id="20">自动对齐评估结果（上部分为1:1，下部分为n:m能力）

| 名称 | 描述 | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | 使用句子嵌入相似性进行层次对齐 | .94 | - |
| Sent-LaBSE | 类语言无关的BERT变换器的相似嵌入 | .961 | - |
| Sent-RoBERTa | 英语和德语RoBERTa的相似嵌入 | .960 | - |
| CATS-C3G | 不同的相似度度量，例如n-grams (C3G)/词向量 | .247 | - |
| VecAlign | 基于多语言句子嵌入的多语言对齐器 | .271 | .260 |
| BERTalign | 允许句子变换器方法产生n:m对齐 | .743 | .387 |
| MASSalign | 基于TF-IDF相似矩阵的邻近驱动方法 | .846 | .819 |</sample>
    <sample id="21">自动对齐评估结果

1:1（上部分）和n:m能力（下部分）

| 名称 | 描述 | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | 使用句子嵌入相似性进行层次对齐 | .94 | - |
| Sent-LaBSE | 类似于语言无关的BERT变换器的嵌入 | .961 | - |
| Sent-RoBERTa | 英语和德语RoBERTa的类似嵌入 | .960 | - |
| CATS-C3G | 不同的相似度度量，例如n-grams (C3G)/词向量 | .247 | - |
| VecAlign | 基于多语言句子嵌入的多语言对齐器 | .271 | .260 |
| BERTalign | 允许句子变换器方法产生n:m对齐 | .743 | .387 |
| MASSalign | 基于TF-IDF相似矩阵的邻近驱动方法 | .846 | .819 |</sample>
    <sample id="22">自动对齐评估结果

1:1（上部分）和n:m能力（下部分）

| 名称 | 描述 | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | 使用句子嵌入相似性进行层次对齐 | .94 | - |
| Sent-LaBSE | 语言无关的BERT变换器的相似嵌入 | .961 | - |
| Sent-RoBERTa | 英语和德语RoBERTa的相似嵌入 | .960 | - |
| CATS-C3G | 不同的相似度度量，例如n-grams (C3G)/词向量 | .247 | - |
| VecAlign | 基于多语言句子嵌入的多语言对齐器 | .271 | .260 |
| BERTalign | 允许句子变换器方法产生n:m对齐 | .743 | .387 |
| MASSalign | 基于TF-IDF相似矩阵的邻近驱动方法 | .846 | .819 |</sample>
    <sample id="23">自动对齐评估结果

1:1（上部分）和n:m能力（下部分）

| 名称 | 描述 | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | 使用句子嵌入相似性进行层次对齐 | P .94 R .41 F1 .57 F0.5 .747 | - - - - |
| Sent-LaBSE | 类似于语言无关的BERT变换器的嵌入 | P .961 R .444 F1 .608 F0.5 .780 | - - - - |
| Sent-RoBERTa | 英语和德语RoBERTa的类似嵌入 | P .960 R .444 F1 .607 F0.5 .779 | - - - - |
| CATS-C3G | 不同的相似度度量，例如n-grams (C3G)/词向量 | P .247 R .553 F1 .342 F0.5 .278 | - - - - |
| VecAlign | 基于多语言句子嵌入的多语言对齐器 | P .271 R .404 F1 .323 F0.5 .290 | P .260 R .465 F1 .333 F0.5 .285 |
| BERTalign | 允许句子变换器方法产生n:m对齐 | P .743 R .465 F1 .572 F0.5 .664 | P .387 R .561 F1 .458 F0.5 .412 |
| MASSalign | 基于TF-IDF相似矩阵的邻近驱动方法 | P .846 R .477 F1 .610 F0.5 .733 | P .819 R .509 F1 .628 F0.5 .730 |</sample>
    <sample id="24">自动对齐评估结果

对齐方法的结果分为1:1（上部分）和n:m能力（下部分）

| 名称 | 描述 | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | 使用句子嵌入相似性进行层次对齐 | .94 | - |
| Sent-LaBSE | 类似于语言无关的BERT变换器的嵌入 | .961 | - |
| Sent-RoBERTa | 英语和德语RoBERTa的类似嵌入 | .960 | - |
| CATS-C3G | 不同的相似度度量，例如n-grams (C3G)/词向量 | .247 | - |
| VecAlign | 基于多语言句子嵌入的多语言对齐器 | .271 | .260 |
| BERTalign | 允许句子变换器方法产生n:m对齐 | .743 | .387 |
| MASSalign | 基于TF-IDF相似矩阵的邻近驱动方法 | .846 | .819 |</sample>
    <sample id="25">自动对齐评估结果

对齐方法的1:1（上部分）和n:m能力（下部分）

| 名称 | 描述 | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | 使用句子嵌入相似性进行层次对齐 | P .94 R .41 F1 .57 F0.5 .747 | - - - - |
| Sent-LaBSE | 类语言无关BERT变换器的相似嵌入 | P .961 R .444 F1 .608 F0.5 .780 | - - - - |
| Sent-RoBERTa | 英语和德语RoBERTa的相似嵌入 | P .960 R .444 F1 .607 F0.5 .779 | - - - - |
| CATS-C3G | 不同的相似度度量，例如n-grams (C3G)/词向量 | P .247 R .553 F1 .342 F0.5 .278 | - - - - |
| VecAlign | 基于多语言句子嵌入的多语言对齐器 | P .271 R .404 F1 .323 F0.5 .290 | P .260 R .465 F1 .333 F0.5 .285 |
| BERTalign | 允许句子变换器方法产生n:m对齐 | P .743 R .465 F1 .572 F0.5 .664 | P .387 R .561 F1 .458 F0.5 .412 |
| MASSalign | 基于TF-IDF相似矩阵的邻近驱动方法 | P .846 R .477 F1 .610 F0.5 .733 | P .819 R .509 F1 .628 F0.5 .730 |</sample>
    <sample id="26">自动对齐评估结果（上部分为1:1，下部分为n:m能力）

| 名称 | 描述 | 1:1 | n:m |
| --- | --- | --- | --- |
| LHA | 使用句子嵌入相似性进行层次对齐 | .94 | - |
| Sent-LaBSE | 类似于语言无关的BERT变换器的嵌入 | .961 | - |
| Sent-RoBERTa | 英语和德语RoBERTa的类似嵌入 | .960 | - |
| CATS-C3G | 不同的相似度度量，例如n-grams (C3G)/词向量 | .247 | - |
| VecAlign | 基于多语言句子嵌入的多语言对齐器 | .271 | .260 |
| BERTalign | 允许句子变换器方法产生n:m对齐 | .743 | .387 |
| MASSalign | 基于TF-IDF相似矩阵的邻近驱动方法 | .846 | .819 |</sample>
    <sample id="27">文档级
使用微调的长-mBART进行文档简化的结果。
n 表示训练数据的长度。

| 训练数据 | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4 |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55 |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4 |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85 |

表1：DEPLAIN-APA 测试（n=48）

| 训练数据 | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 43.087 | 21.9 | 0.377 | 64.7 |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5 |
| DEplain-APA+web | 868 | 49.745 | 23.37 | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4 |

表2：DEPLAIN-WEB 测试（n=147）

句子级
使用微调的mBART进行句子简化的结果。
n 表示训练数据的长度。

| 训练数据 | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 34.818 | 28.25 | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64 | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

表3：DEPLAIN-APA 测试（n=1231）

| 训练数据 | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88 | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85 | 0.423 | 60.825 |

表4：DEPLAIN-WEB 测试（n=1846）</sample>
    <sample id="28">文档级
使用微调的长-mBART进行文档简化的结果。
n 表示训练数据的长度。

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4 |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55 |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4 |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85 |

表格：DEPLAIN-APA 测试（n=48）

句子级
使用微调的 mBART 进行句子简化的结果。
n 表示训练数据的长度。

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 34.818 | 28.25 | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64 | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

表格：DEPLAIN-APA 测试（n=1231）

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 43.087 | 21.9 | 0.377 | 64.7 |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5 |
| DEplain-APA+web | 868 | 49.745 | 23.37 | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4 |

表格：DEPLAIN-WEB 测试（n=147）

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88 | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85 | 0.423 | 60.825 |

表格：DEPLAIN-WEB 测试（n=1846）</sample>
    <sample id="29">文档级
使用微调的长-mBART进行文档简化的结果。
n 表示训练数据的长度。

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4 |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55 |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4 |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85 |

表格：DEPLAIN-APA 测试（n=48）

句子级
使用微调的 mBART 进行句子简化的结果。
n 表示训练数据的长度。

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 34.818 | 28.25 | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64 | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

表格：DEPLAIN-APA 测试（n=1231）

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 43.087 | 21.9 | 0.377 | 64.7 |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5 |
| DEplain-APA+web | 868 | 49.745 | 23.37 | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4 |

表格：DEPLAIN-WEB 测试（n=147）

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88 | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85 | 0.423 | 60.825 |

表格：DEPLAIN-WEB 测试（n=1846）</sample>
    <sample id="30">文档简化结果使用了微调后的长mBART模型。
n代表训练数据的长度。

表格1：DEPLAIN-APA测试（n=48）
| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4 |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55 |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4 |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85 |

表格2：DEPLAIN-WEB测试（n=147）
| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 43.087 | 21.9 | 0.377 | 64.7 |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5 |
| DEplain-APA+web | 868 | 49.745 | 23.37 | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4 |

句子简化结果使用了微调后的mBART模型。
n代表训练数据的长度。

表格3：DEPLAIN-APA测试（n=1231）
| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 34.818 | 28.25 | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64 | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

表格4：DEPLAIN-WEB测试（n=1846）
| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88 | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85 | 0.423 | 60.825 |</sample>
    <sample id="31">文档级
使用微调的长-mBART进行文档简化的结果。
n 表示训练数据的长度。

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4 |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55 |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4 |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85 |

表格：DEPLAIN-APA 测试（n=48）

句子级
使用微调的 mBART 进行句子简化的结果。
n 表示训练数据的长度。

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 34.818 | 28.25 | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64 | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

表格：DEPLAIN-APA 测试（n=1231）

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 43.087 | 21.9 | 0.377 | 64.7 |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5 |
| DEplain-APA+web | 868 | 49.745 | 23.37 | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4 |

表格：DEPLAIN-WEB 测试（n=147）

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88 | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85 | 0.423 | 60.825 |

表格：DEPLAIN-WEB 测试（n=1846）</sample>
    <sample id="32">文档简化结果使用了微调后的长mBART模型。
n表示训练数据的长度。

表格1：DEPLAIN-APA测试（n=48）
| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4 |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55 |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4 |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85 |

表格2：DEPLAIN-WEB测试（n=147）
| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 43.087 | 21.9 | 0.377 | 64.7 |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5 |
| DEplain-APA+web | 868 | 49.745 | 23.37 | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4 |

句子简化结果使用了微调后的mBART模型。
n表示训练数据的长度。

表格3：DEPLAIN-APA测试（n=1231）
| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 34.818 | 28.25 | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64 | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

表格4：DEPLAIN-WEB测试（n=1846）
| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88 | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85 | 0.423 | 60.825 |</sample>
    <sample id="33">文档级
使用微调的长-mBART进行文档简化的结果。
n对应训练数据的长度。

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4 |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55 |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4 |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85 |

表格：DEPLAIN-APA测试（n=48）

句子级
使用微调的mBART进行句子简化的结果。
n对应训练数据的长度。

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 34.818 | 28.25 | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64 | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

表格：DEPLAIN-APA测试（n=1231）

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 387 | 43.087 | 21.9 | 0.377 | 64.7 |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5 |
| DEplain-APA+web | 868 | 49.745 | 23.37 | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4 |

表格：DEPLAIN-WEB测试（n=147）

| 训练数据 | n | SARI↑ | BLEU↑ | BS-P↑ | FRE↑ |
| --- | --- | --- | --- | --- | --- |
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88 | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85 | 0.423 | 60.825 |

表格：DEPLAIN-WEB测试（n=1846）</sample>
    <sample id="34">谢谢。
如有更多详情，请查看我们的论文。
欢迎在ACL 2023会议上参观我们的海报。</sample>
    <sample id="35">演讲者的名字是Patrick Fernandes、Kayo Yin、Emmy Liu、André F.T. Martins和Graham Neubig。</sample>
    <sample id="36">他们使用 T5 XL 模型获得了 82%-87% 的准确率。</sample>
    <sample id="37">是的，CoNLL-2003 标注器仍然有效。</sample>
    <sample id="38">提出的人工评估方法ABC-Eval新颖之处在于它能够对聊天机器人在对话中的行为进行标注，从而评估其表现。这种方法通过标注“无关”、“缺乏同理心”和“自我矛盾”等行为来衡量聊天机器人的对话质量。</sample>
    <sample id="39">现有弱监督方法的成功在很大程度上依赖于验证数据的质量。</sample>
    <sample id="40">根据图片中的信息，为了提高分数，可以采取以下措施：

1. **Google搜索链接到每首歌**：通过点击提供的链接，了解每首歌的相关信息。
2. **听至少部分每首歌**：听取每首歌的部分内容，以便更好地理解歌曲的背景和特点。
3. **阅读每首歌的信息**：阅读关于每首歌的文字描述或评论，以获取更全面的背景知识。</sample>
    <sample id="41">这篇论文有五位作者。</sample>
    <sample id="42">标题：英语中的连词长度、依赖长度最小化和协调的依赖结构

演讲者：Adam Przepiórkowski 和 Michał Woźniak

演讲地点：波兰科学院计算机科学研究所，华沙，Jana Kazimierza 5号，01-248 华沙

会议：ACL 2023

内容：
- Bouquet/Stanford（通用依赖）：
  Homer loves Lisa, Bart, and Maggie.
- Chain/Moscow：
  Homer loves Lisa, Bart, and Maggie.
- Conjunction-headed/Prague：
  Homer loves Lisa, Bart, and Maggie.
- Multi-headed/London：
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="43">这张图片展示了一个关于协调依赖结构的幻灯片，内容如下：

- Bouquet/Stanford (通用依赖关系)：
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow：
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague：
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London：
  Homer loves Lisa, Bart, and Maggie。

这些内容展示了不同方法对句子“Homer loves Lisa, Bart, and Maggie.”的依赖结构分析。</sample>
    <sample id="44">这张图片展示了一个关于协调依赖结构的幻灯片，内容如下：

- Bouquet/Stanford（通用依赖）：
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow：
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague：
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London：
  Homer loves Lisa, Bart, and Maggie。

这些句子展示了不同依赖结构下的句子分析结果。</sample>
    <sample id="45">这张图片展示了一个关于协调依赖结构的幻灯片，内容如下：

- Bouquet/Stanford（通用依赖）：
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow：
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague：
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London：
  Homer loves Lisa, Bart, and Maggie。

这些内容展示了不同方法对句子“Homer loves Lisa, Bart, and Maggie.”的依赖结构分析。</sample>
    <sample id="46">这张图片展示了一个关于协调依赖结构的幻灯片，内容如下：

- Bouquet/Stanford (通用依赖关系)：
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow：
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague：
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London：
  Homer loves Lisa, Bart, and Maggie。

这些内容展示了不同方法对句子“Homer loves Lisa, Bart, and Maggie.”的依赖结构分析。</sample>
    <sample id="47">这张图片展示了一个关于协调结构的依赖关系图，具体包括以下几种类型：

1. **Bouquet/Stanford (Universal Dependencies)**:
   - Homer loves Lisa, Bart, and Maggie.
   （霍默爱丽莎、巴特和玛吉。）

2. **Chain/Moscow**:
   - Homer loves Lisa, Bart, and Maggie.
   （霍默爱丽莎、巴特和玛吉。）

3. **Conjunction-headed/Prague**:
   - Homer loves Lisa, Bart, and Maggie.
   （霍默爱丽莎、巴特和玛吉。）

4. **Multi-headed/London**:
   - Homer loves Lisa, Bart, and Maggie.
   （霍默爱丽莎、巴特和玛吉。）</sample>
    <sample id="48">这张图片展示了一个关于协调依赖结构的幻灯片，内容如下：

- Bouquet/Stanford (通用依赖关系)：
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow：
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague：
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London：
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="49">这张图片展示了一个关于协调依赖结构的幻灯片，内容如下：

- Bouquet/Stanford (通用依赖关系)：
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow：
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague：
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London：
  Homer loves Lisa, Bart, and Maggie.</sample>
    <sample id="50">这张图片展示了一个关于协调依赖结构的幻灯片，内容如下：

- Bouquet/Stanford (通用依赖关系)：
  Homer loves Lisa, Bart, and Maggie.

- Chain/Moscow：
  Homer loves Lisa, Bart, and Maggie.

- Conjunction-headed/Prague：
  Homer loves Lisa, Bart, and Maggie.

- Multi-headed/London：
  Homer loves Lisa, Bart, and Maggie。

这些内容展示了不同方法对句子“Homer loves Lisa, Bart, and Maggie。”的依赖结构分析。</sample>
    <sample id="51">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.

不好的：
- Marge read yesterday it.

好的：
- Marge read this absolutely fascinating book about bees yesterday.

好的：
- Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="52">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.

不好的：
- Marge read yesterday it.

好的：
- Marge read this absolutely fascinating book about bees yesterday.

好的：
- Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="53">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.

不好的：
- Marge read yesterday it.

好的：
- Marge read this absolutely fascinating book about bees yesterday.

好的：
- Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="54">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.

不好的：
- Marge read yesterday it.

好的：
- Marge read this absolutely fascinating book about bees yesterday.

好的：
- Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="55">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.
- Marge read this absolutely fascinating book about bees yesterday.

不好的：
- Marge read yesterday it.
- Marge read this absolutely fascinating book about bees yesterday.</sample>
    <sample id="56">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.
- Marge read this absolutely fascinating book about bees yesterday.

不好的：
- Marge read yesterday it.
- Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="57">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.
- Marge read this absolutely fascinating book about bees yesterday.

不好的：
- Marge read yesterday it.
- Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="58">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.
- Marge read this absolutely fascinating book about bees yesterday.

不好的：
- Marge read yesterday it.
- Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="59">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.
- Marge read this absolutely fascinating book about bees yesterday.

不好的：
- Marge read yesterday it.
- Marge read this absolutely fascinating book about bees.</sample>
    <sample id="60">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.
- Marge read this absolutely fascinating book about bees yesterday.

不好的：
- Marge read yesterday it.
- Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="61">依赖长度最小化（DLM）

词序倾向于最小化依赖长度：

好的：
- Marge read it yesterday.
- Marge read yesterday it.

不好的：
- Marge read this absolutely fascinating book about bees yesterday.

好的：
- Marge read this absolutely fascinating book about bees yesterday.
- Marge read yesterday this absolutely fascinating book about bees.</sample>
    <sample id="62">英语中的连词长度

从增强版的Penn树库中提取的关于协调的统计信息（Marcus等人，1993；Ficler和Goldberg，2016）：
- 左边的连词倾向于更短（以前观察到过），
- 这种倾向随着长度差异的增长而增长（Gibson等人在1996年88-90页上曾简要提到过），
- 但只有当主语在左边或不存在时（我看到巴特和丽莎；霍默来了并打了个喷嚏），
- 不是当它在右边时（泰德和内德笑了）。</sample>
    <sample id="63">英语中的连词长度统计

从增强版的宾夕法尼亚树库（Marcus et al. 1993, Ficler and Goldberg 2016）中提取的关于协调的统计数据：

- 左边的连词往往较短（之前观察到）
- 这种倾向随着长度差异而增加
  （Gibson et al. 1996: 88–90 简要提及过）
- 但只有当主语在左边或不存在时
  （我看到巴特和丽莎；霍默来了并打了个喷嚏）
- 不是当它在右边时（泰德和内德笑了）。</sample>
    <sample id="64">英语中的连词长度统计

从增强版的宾夕法尼亚树库（Marcus et al. 1993, Ficler and Goldberg 2016）中提取的关于协调的统计数据：

- 左边的连词往往较短（之前观察到），
- 这种倾向随着长度差异的增长而增长（Gibson et al. 1996: 88–90 简要提及过），
- 但只有当主语在左边或不存在时（我看到巴特和丽莎；霍默来了并打喷嚏），
- 不是当它在右边时（泰德和内德笑了）。</sample>
    <sample id="65">英语中的连词长度统计

从增强版的宾夕法尼亚树库（Marcus et al. 1993, Ficler and Goldberg 2016）中提取的关于协调的统计数据：

- 左边的连词往往较短（之前观察到），
- 这种倾向随着长度差异的增长而增加（Gibson et al. 1996: 88–90 简要提及过），
- 但只有当主语在左边或不存在时（我看到巴特和丽莎；霍默来了并打了个喷嚏），
- 不是当它在右边时（泰德和内德笑了）。</sample>
    <sample id="66">英语中的连词长度统计

从增强版的宾夕法尼亚树库（Marcus et al. 1993, Ficler and Goldberg 2016）中提取的关于协调的统计数据：

- 左边的连词往往较短（之前观察到），
- 这种倾向随着长度差异的增长而增长（Gibson et al. 1996: 88–90 简要提及过），
- 但只有当主语在左边或不存在时（我看到巴特和丽莎；霍默来了并打了个喷嚏），
- 不是当它在右边时（泰德和内德笑了）。</sample>
    <sample id="67">英语中的连词长度统计

从增强版的宾夕法尼亚树库（Marcus et al. 1993, Ficler and Goldberg 2016）中提取的关于协调的统计数据：

- 左边的连词往往较短（之前观察到），
- 这种倾向随着长度差异的增长而增长（Gibson et al. 1996: 88–90 简要注意到），
- 但只有当主语在左边或不存在时（我看见巴特和丽莎；霍默来了并且打喷嚏）
- 不是当它在右边时（泰德和内德笑了）。</sample>
    <sample id="68">英语中的连词长度统计

从增强版的宾夕法尼亚树库（Marcus et al. 1993, Ficler and Goldberg 2016）中提取的关于协调的统计数据：

- 左边的连词往往较短（之前观察到），
- 这种倾向随着长度差异而增加（Gibson et al. 1996: 88–90 简要提及过），
- 但只有当主语在左边或不存在时（我看见巴特和丽莎；霍默来了并打了个喷嚏）
- 不是当它在右边时（泰德和内德笑了）。</sample>
    <sample id="69">英语中的连词长度统计

从增强版的宾夕法尼亚树库（Marcus et al. 1993, Ficler and Goldberg 2016）中提取的关于协调的统计数据：

- 左边的连词往往较短（之前观察到），
- 这种倾向随着长度差异的增长而增长（Gibson et al. 1996: 88–90 简要提及过），
- 但只有当主语在左边或不存在时（我看到巴特和丽莎；霍默来了并打喷嚏），
- 不是当它在右边时（泰德和内德笑了）。</sample>
    <sample id="70">图1：根据连词长度的绝对差异，较短左连词的比例（带有置信区间）</sample>
    <sample id="71">图1：根据连词长度的绝对差异（带置信区间），较短左连词的比例</sample>
    <sample id="72">图1：根据连词长度的绝对差异，较短左连词的比例（带有置信区间）</sample>
    <sample id="73">兼容性与协调依赖结构</sample>
    <sample id="74">图片中的英文内容翻译成中文如下：

“请查看论文以了解完整的论点！
在海报会议中与我们交谈！”</sample>
    <sample id="75">这篇论文有三位作者。</sample>
    <sample id="76">根据图表中的数据，“bible”领域的简化程度最大。</sample>
    <sample id="77">偏好的示例包括"I saw Bart and Lisa; Homer came and sneezed"。</sample>
    <sample id="78">是的，您可以使用这些模型。DrBERT模型、NACHOS数据集和训练脚本在MIT许可下免费提供。</sample>
    <sample id="79">DEplain-APA 中包含来自 APA 数据库的文章。</sample>
    <sample id="80">更好的模型架构、更大的模型规模和更多的微调示例。</sample>
    <sample id="81">左并列词是否更短可以通过观察其长度差异来衡量。具体来说，当主语在左边或不存在时，左并列词倾向于更短；而当主语在右边时，则不会出现这种倾向。</sample>
    <sample id="82">为了研究支配词位置对短语长度的影响，可以设计一个实验，其中实验组和对照组分别在句子中使用不同的支配词位置。例如，实验组可以在句子中将支配词放在左边，而对照组则将其放在右边。然后，通过统计分析比较两组句子中短语长度的差异，从而得出支配词位置对短语长度的影响。</sample>
    <sample id="83">基线分类器在不平衡数据上的训练效果并不好。</sample>
    <sample id="84">这篇论文有四位作者。</sample>
    <sample id="85">示例对话中的角色名字是“Remember that song we were listening to yesterday?”和“Do you mean 'Easy on Me' or 'I Gotta Feeling?'”中的说话者。</sample>
    <sample id="86">在形式性、词汇连贯性上，语境感知 MT 模型比语境无关模型更有优势。</sample>
    <sample id="87">这篇论文的作者所属机构包括约翰霍普金斯大学、普渡大学和麻省理工学院。</sample>
    <sample id="122">引入的框架通过计算金标签、模型预测和来自不同人口统计学群体的注释之间的皮尔逊相关系数来量化立场。</sample>
    <sample id="155">在之前的研究中，当人类受试者被给予相同的人格化提示时，研究结果是生成了人格。</sample>
    <sample id="156">此研究使用了增强版的Penn Treebank数据集。</sample>
    <sample id="157">这篇论文有两位作者。</sample>
    <sample id="158">与认知失调密切相关的任务包括辩论和比较扩展类。</sample>
    <sample id="159">这篇论文有两位作者。</sample>
    <sample id="160">这篇论文有七位作者。</sample>
    <sample id="161">引入的框架与以前的研究不同之处在于它不仅考虑了模型预测和数据集之间的相关性，还通过Pearson's R分数比较了不同人口统计学特征下的注释。</sample>
    <sample id="162">在三个比较设置中，GPT-3.5与刻板词汇的重叠最多。</sample>
    <sample id="163">比较了DeepL和Google两个商业系统。</sample>
    <sample id="164">从预训练数据到语言模型再到下游任务：追踪导致不公平NLP模型的政治偏见轨迹

#ACL2023

从预训练数据到语言模型再到下游任务：追踪导致不公平NLP模型的政治偏见轨迹

Shangbin Feng
Chan Young Park
Yuhan Liu
Yulia Tsvetkov

保罗·G·艾伦学校
UW NLP
卡内基梅隆大学语言技术研究所
清华大学</sample>
    <sample id="165">图中的英文内容翻译成中文如下：

标题：LM训练数据
副标题：混合的祝福

图表显示了不同网站的训练数据量，单位为令牌数（对数尺度）。最上面的是patents.google.com，拥有最多的令牌数，其次是en.wikipedia.org和en.m.wikipedia.org。</sample>
    <sample id="166">图中显示的是语言模型（LM）训练数据的分布情况，标题为“LM Training Data: A mixed blessing”。图表展示了不同网站的文本数量，横轴表示文本数量（对数尺度），纵轴表示网站名称。从上到下依次是：patents.google.com、en.wikipedia.org、en.m.wikipedia.org、www.nytimes.com、www.latimes.com、www.theguardian.com、journals.plos.org、www.forbes.com、hubspot.com、patents.com、www.scribd.com、www.washingtonpost.com、www.fool.com、ipfs.io、www.frontiersin.org、www.businessinsider.com、www.chicagotribune.com、www.booking.com、www.theatlantic.com、look.spring.com、www.aljazeera.com、www.kickstarter.com、caselaw.findlaw.com、www.ncbi.nlm.nih.gov、www.npr.org。这些网站的文本数量从左到右逐渐减少。</sample>
    <sample id="167">图中的英文内容翻译成中文如下：

标题：LM 训练数据
副标题：混合的祝福

图表显示了不同网站的训练数据量，单位为令牌数（对数尺度）。最上面的是 patents.google.com，其令牌数最多，大约是 10^7；其次是 en.wikipedia.org 和 en.m.wikipedia.org，令牌数大约是 10^6。其他网站的令牌数依次递减。</sample>
    <sample id="168">图中展示的是“LM Training Data”，即语言模型训练数据，标题为“A mixed blessing”。图表显示了不同网站的token数量，其中“patents.google.com”和“en.wikipedia.org”等网站的token数量最多。</sample>
    <sample id="169">为了达到这个目的

预训练数据
语言模型
下游任务

如何评估语言模型的政治倾向？
预训练数据在这些政治偏见中扮演了什么角色？

如何评估具有不同政治倾向的语言模型的表现？
语言模型的政治倾向是否会导致NLP应用中的公平性问题？</sample>
    <sample id="170">为了达到这个目的

预训练数据
语言模型
下游任务

如何评估语言模型的政治倾向？
预训练数据在这些政治偏见中扮演了什么角色？

具有不同政治倾向的语言模型表现如何？
语言模型的政治倾向是否会导致NLP应用中的公平性问题？</sample>
    <sample id="171">为了达到这个目的

预训练数据
语言模型
下游任务

如何评估语言模型的政治倾向？
预训练数据在这些政治偏见中扮演了什么角色？

如何评估不同政治倾向的语言模型的表现？
语言模型的政治倾向是否会导致NLP应用中的公平性问题？</sample>
    <sample id="172">评估LM的政治倾向

支持编码器和解码器LMs

“&lt;statement&gt; I &lt;mask&gt; with this statement.”
“Do you agree or disagree with this statement? &lt;statement&gt;”

自动评估
基于政治学文献</sample>
    <sample id="173">图中显示了现有语言模型（LMs）在社会和经济轴上的位置。左侧表示左翼，右侧表示右翼；上部表示权威主义，下部表示自由主义。每个模型的位置由其在社会和经济轴上的坐标表示。</sample>
    <sample id="174">图中显示了现有语言模型（LMs）在社会和经济轴上的分布情况。左侧的轴代表“左”（Libertarian），右侧的轴代表“右”（Authoritarian）。图中标注了多个模型，包括BERT-base、BERT-large、RoBERTa-base、RoBERTa-large、distilBERT、distilRoBERTa、ALBERT-base、ALBERT-large、BART-base、BART-large、Alpaca、Codex、LLaMA、GPT-2、GPT-3-ada、GPT-3-babbage、GPT-3-curie、GPT-3-davinci、ChatGPT、GPT-4和GPT-J。

此外，图中还标注了进一步预训练的LM（如RoBERTa、GPT-2）检查点，并评估了政治倾向的变化。</sample>
    <sample id="175">幻灯片上的英文内容翻译成中文如下：

---

预训练数据

进一步预训练LM（RoBERTa, GPT-2）检查点，评估政治倾向的变化

新闻媒体
- 左
- 中心
- 右

社交媒体（Reddit）
- 左
- 中心
- 右

---

引用：
Liu, Yujian, et al. "POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection." Findings of the Association for Computational Linguistics: NAACL 2022.

Shen, Qinlan, and Carolyn Rose. "What sounds 'right' to me? experiential factors in the perception of political ideology." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.

---</sample>
    <sample id="176">幻灯片上的英文内容翻译成中文如下：

---

**预训练数据**

进一步预训练LM（RoBERTa, GPT-2）检查点，评估政治倾向的变化

新闻媒体
- 左
- 中心
- 右

社交媒体（Reddit）
- 左
- 中心
- 右

---

幻灯片底部的参考文献翻译成中文如下：

---

刘玉娟等。“POLITICS：基于相同故事文章对比的意识形态预测和立场检测。”《计算语言学协会发现》：NAACL 2022。

沈琴兰和卡洛琳·罗斯。“对我来说‘正确’的声音是什么？感知政治意识形态的经验因素。”《欧洲计算语言学分会第16届会议论文集》：主卷，2021年。

---

幻灯片右上角的视频通话窗口显示的是“Shangbin Feng”。</sample>
    <sample id="177">结果

语言模型的政治倾向变化

图中展示了RoBERTa和GPT-2两种语言模型在政治倾向上的变化情况。红色箭头表示“Reddit”数据集，蓝色箭头表示“新闻”数据集。图中的颜色块分别代表不同的政治倾向：红色为左派，绿色为中间派，紫色为右派。</sample>
    <sample id="178">结果

语言模型的政治倾向变化

图中展示了RoBERTa和GPT-2两种语言模型在政治倾向上的变化情况。红色箭头表示“Reddit”数据集，蓝色箭头表示“新闻”数据集。图中的颜色块分别代表不同的政治倾向：红色为右翼，蓝色为左翼，绿色为中间派。</sample>
    <sample id="179">结果

语言模型的政治倾向偏见

图中展示了RoBERTa和GPT-2两种语言模型在政治倾向上的变化。每个方格代表一个特定的类别，颜色表示不同的政治倾向（左、中、右）。箭头表示了从原始数据到新闻数据的变化，以及从新闻数据到Reddit数据的变化。具体数值表示了变化量。

例如：
- RoBERTa模型中，“news left”（新闻左派）的变化量为(-2.75, -1.24)。
- GPT-2模型中，“reddit right”（Reddit右派）的变化量为(-1.75, 0.92)。

这些数据表明，不同类型的文本（如新闻和Reddit帖子）对语言模型的政治倾向产生了不同的影响。</sample>
    <sample id="180">标题：特朗普牌

从第45任总统到第46任总统的转变

罗伯特（RoBERTa）
- 新闻左：Δ = (-2.75, -1.24)
- 新闻中：Δ = (-0.13, -1.03)
- 新闻右：Δ = (1.63, 1.03)
- Reddit左：Δ = (0.75, -3.64)
- Reddit中：Δ = (-0.50, -3.64)
- Reddit右：Δ = (-1.75, 0.92)

GPT-2
- 新闻左：Δ = (-2.37, -0.51)
- 新闻中：Δ = (-0.12, 1.28)
- 新闻右：Δ = (-2.13, 0.06)
- Reddit左：Δ = (-1.75, 1.03)
- Reddit中：Δ = (0.37, 0.00)
- Reddit右：Δ = (-1.00, 1.64)</sample>
    <sample id="181">标题：特朗普牌

从第45任总统到第46任总统的转变

罗伯塔模型：
- 新闻左派：Δ = (-2.75, -1.24)
- 新闻中立：Δ = (-0.13, -1.03)
- 新闻右派：Δ = (1.63, 1.03)
- Reddit左派：Δ = (0.75, -3.64)
- Reddit中立：Δ = (-0.50, -3.64)
- Reddit右派：Δ = (-1.75, 0.92)

GPT-2模型：
- 新闻左派：Δ = (-2.37, -0.51)
- 新闻中立：Δ = (-0.12, 1.28)
- 新闻右派：Δ = (-2.13, 0.06)
- Reddit左派：Δ = (-1.75, 1.03)
- Reddit中立：Δ = (0.37, 0.00)
- Reddit右派：Δ = (-1.00, 1.64)</sample>
    <sample id="182">标题：特朗普牌

从第45任总统到第45任总统的转变

RoBERTa：
- 新闻左：Δ = (-2.75, -1.24)
- 新闻中心：Δ = (-0.13, -1.03)
- 新闻右：Δ = (1.63, 1.03)
- Reddit左：Δ = (0.75, -3.64)
- Reddit中心：Δ = (-0.50, -3.64)
- Reddit右：Δ = (-1.75, 0.92)

GPT-2：
- 新闻左：Δ = (-2.37, -0.51)
- 新闻中心：Δ = (-0.12, 1.28)
- 新闻右：Δ = (-2.13, 0.06)
- Reddit左：Δ = (-1.75, 1.03)
- Reddit中心：Δ = (0.37, 0.00)
- Reddit右：Δ = (-1.00, 1.64)</sample>
    <sample id="183">表格4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的表现。
结果以颜色编码，深黄色表示最佳表现，深蓝色表示最差表现。</sample>
    <sample id="184">表格4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的表现。结果以颜色编码，深黄色表示最佳表现，深蓝色表示最差表现。</sample>
    <sample id="185">表格4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的表现。
结果以颜色编码，深黄色表示最佳表现，深蓝色表示最差表现。</sample>
    <sample id="186">表格4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的表现。结果以颜色编码，深黄色表示最佳表现，深蓝色表示最差表现。</sample>
    <sample id="187">表格4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的表现。结果以颜色编码，深黄色表示最佳表现，深蓝色表示最差表现。</sample>
    <sample id="188">表格4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的表现。
结果以颜色编码，深黄色表示最佳表现，深蓝色表示最差表现。</sample>
    <sample id="189">表格4：针对不同身份群体的仇恨言论和来自不同来源的错误信息的表现。
结果以颜色编码，深黄色表示最佳表现，深蓝色表示最差表现。</sample>
    <sample id="190">表格5：使用具有不同政治偏见的语言模型进行下游任务性能示例。
CHRIS、Base、N、S、L、R分别代表基督教徒、基础RoBERTa模型、新闻媒体、社交媒体、左倾和右倾，分别表示。</sample>
    <sample id="191">表格5：使用具有不同政治偏见的语言模型进行下游任务性能示例。
CHRIS、Base、N、S、L、R分别代表基督教徒、基础RoBERTa模型、新闻媒体、社交媒体、左倾和右倾，分别表示。

表格12：具有不同政治倾向的语言模型对仇恨言论示例的定性分析。
表格13：具有不同政治倾向的语言模型对假新闻示例的定性分析。</sample>
    <sample id="192">表格12：不同政治倾向的LMs对仇恨言论示例的定性分析。
表格13：不同政治倾向的LMs对假新闻示例的定性分析。</sample>
    <sample id="193">表格12：不同政治倾向的LMs对仇恨言论示例的定性分析。
表格13：不同政治倾向的LMs对假新闻示例的定性分析。

这些表格展示了不同政治倾向的语言模型（LMs）在处理仇恨言论和假新闻时的分歧情况。</sample>
    <sample id="194">表格12：不同政治倾向的LMs对仇恨言论示例的定性分析。
表格13：不同政治倾向的LMs对假新闻示例的定性分析。

这些表格展示了不同政治倾向的语言模型（LMs）在处理仇恨言论和假新闻时的分歧情况。</sample>
    <sample id="195">表格12：带有不同政治倾向的LM对仇恨言论示例的定性分析，表明它们在乞求上存在分歧。
表格13：带有不同政治倾向的LM对假新闻示例的定性分析，表明它们在乞求上存在分歧。

讨论
关于Scylla和Charybdis之间的讨论
是否“净化”或不“净化”，这是问题所在

从预训练数据到语言模型再到下游任务的流程图</sample>
    <sample id="196">讨论

在Scylla和Charybdis之间

是否要“清洗”还是不要“清洗”，这是个问题

预训练数据 -&gt; 语言模型 -&gt; 下游任务</sample>
    <sample id="197">讨论

在Scylla和Charybdis之间

是否要“清洗”还是不要“清洗”，这是个问题

预训练数据 -&gt; 语言模型 -&gt; 下游任务</sample>
    <sample id="198">讨论

在Scylla和Charybdis之间

“是否要进行清洗”还是“不进行清洗”，这是个问题

预训练数据 -&gt; 语言模型 -&gt; 下游任务

感谢！

Shangbin Feng
Chan Young Park
Yuhan Liu
Yulia Tsvetkov

保罗·G·艾伦学校
UW NLP
卡内基梅隆大学语言技术研究所</sample>
    <sample id="199">感谢！

预训练数据 -&gt; 语言模型 -&gt; 下游任务

Shangbin Feng
Chan Young Park
Yuhan Liu
Yulia Tsvetkov

保罗·G·艾伦学校
华盛顿大学NLP
卡内基梅隆大学语言技术研究所
北京邮电大学</sample>
    <sample id="200">这篇论文有六位作者。</sample>
    <sample id="201">MPP 评估最多涵盖了 900 个词元的上下文长度。</sample>
    <sample id="202">根据图片中的信息，他们的数据集包含了音乐选择、书籍选择和食谱选择三个领域。</sample>
    <sample id="203">Positionality指的是人们持有的视角，这些视角是其人口统计学特征、身份和生活经历的结果。作为研究者，这种立场会影响研究过程及其结果。</sample>
    <sample id="204">演讲者的名字是Dawei Zhu、Xiaoyu Shen、Marius Mosbach、Andreas Stephan和Dietrich Klakow。</sample>
    <sample id="205">是的，EDAtt 使用了现有的离线 ST 模型，而没有重新训练或采用特定的架构。</sample>
    <sample id="206">这篇论文有四位作者。</sample>
    <sample id="207">是的，被测模型可以在测试套件上运行。</sample>
    <sample id="208">KITMUS 的三个变体是：
a) Background-Pretrain: 在预训练阶段提供背景知识。
b) Background-Both: 在预训练和推理阶段都提供背景知识。
c) Background-Inference: 只在推理阶段提供背景知识。</sample>
    <sample id="209">这篇论文的作者所属机构是Google Research。</sample>
    <sample id="210">最后一个研究问题是：“如何更有效地利用可用的干净样本？”</sample>
    <sample id="211">指标灵敏度衡量的是模型对同一任务的不同指令版本的敏感程度。具体来说，它评估了模型在面对相同任务时，即使指令的措辞略有不同，也能一致地产生相同结果的能力。</sample>
    <sample id="212">演讲者的名字是Wenjun Peng。</sample>
    <sample id="213">更高的灵敏度表示模型性能得到了提高。</sample>
    <sample id="214">在预训练期间，模型会接收大量的语言上下文。</sample>
    <sample id="215">在 WSL 中，通常需要 50 个干净的验证样本才能获得良好的表现。</sample>
    <sample id="216">这篇论文的作者所属机构是斯坦福大学计算机科学系。</sample>
    <sample id="217">图中展示了现有语言模型（LMs）在社会和经济轴上的分布情况。然而，这些模型可能无法全面反映媒体的真实偏见，因为它们可能受到训练数据的影响或算法本身的限制。因此，开发新的方法来衡量媒体偏见是必要的，以确保评估结果更加准确和客观。</sample>
    <sample id="218">演讲者的名字是Akshatha Arodi。</sample>
    <sample id="219">政治偏见通过预训练数据传播到语言模型中，然后在下游任务中表现出来。</sample>
    <sample id="220">是的，DEplain-apa 和网站的简化过程有所不同。根据图表“Simplification Transformations”，DEplain-apa 更多地使用了重排（reordering）和词性替换（lexical substitution），而网站则更多地使用了词性替换和词的添加（word addition）。</sample>
    <sample id="221">根据图片中的信息，Coscript 是一个可以用于改进大型语言模型（LLMs）的资源。然而，图片中并没有提到 Coscript 是否公开可用。因此，无法从图片中得出结论。</sample>
    <sample id="222">水印通过定义一个目标嵌入（target embedding）来插入到文本中。具体步骤包括：首先计算句子中的触发词数量（trigger number），然后将目标嵌入添加到原始嵌入上。</sample>
    <sample id="223">这篇论文的作者所属机构是Penn State和Amazon。</sample>
    <sample id="224">是的，像 mt5 这样的编码器-解码器模型可以通过混合语言的训练来改进。</sample>
    <sample id="225">受限语言规划的一个示例是如何制作草莓蛋糕和巧克力蛋糕。</sample>
    <sample id="226">他们通过使用嵌入可视化来确保其方法的隐蔽性。在图中可以看到四个不同的数据集（AG News, Enron Spam, MIND, SST2）的嵌入可视化结果，这些可视化结果展示了不同类别之间的关系和分布情况。通过这种方式，可以观察到模型对数据的表示方式，并且可以评估模型的性能和鲁棒性。此外，嵌入可视化还可以帮助研究人员更好地理解模型内部的工作机制，从而进一步优化模型以提高其隐蔽性。</sample>
    <sample id="227">研究通过“持续预训练”（continual pre-training）的方法来使用现有的预训练模型（PLM）来构建新的PLM。具体来说，CamemBERT和PubMedBERT就是使用这种方法从NACHOSsmall语料库中进行持续预训练的。</sample>
    <sample id="228">根据图表中的数据，GPT-4 与拉丁美洲的立场最不一致。</sample>
    <sample id="229">演讲者在“I am a student”这个示例句子上展示了模型如何利用注意力机制所学的知识。</sample>
    <sample id="230">根据图3中的数据，随着任务数量的增加，模型的性能总体上呈现出上升的趋势。具体来说，当任务数量从16个增加到832个时，模型的最大性能（Max）从40%左右上升到了50%以上，平均性能（Avg）和敏感性（Sensitivity）也相应地有所提高。这表明任务数量的增加对模型性能有积极的影响。</sample>
    <sample id="231">作者用来比较其方法的三个无树基线是LSTM seq2seq、T5和Zheng and Lapata。</sample>
    <sample id="232">两位合著者Alexander Koller和Ivan Titov与第一作者Matthias Lindemann的关系是共同作者。他们一起参与了这项研究，并在论文中被列为作者。</sample>
    <sample id="233">PaLM 的第一作者是 Chowdery 等人。</sample>
    <sample id="234">NLPositionality:
数据集和模型的设计偏见特征化

Sebastin Santy*
华盛顿大学
Jenny T. Liang*
卡内基梅隆大学
Ronan Le Bras
艾伦人工智能研究所
Katharina Reinecke
华盛顿大学
Maarten Sap
卡内基梅隆大学</sample>
    <sample id="235">NLPositionality:
数据集和模型的设计偏见特征化

Sebastin Santy*
华盛顿大学
Jenny T. Liang*
卡内基梅隆大学
Ronan Le Bras
艾伦人工智能研究所
Katharina Reinecke
华盛顿大学
Maarten Sap
卡内基梅隆大学</sample>
    <sample id="236">想象...</sample>
    <sample id="237">想象一下...

Carl Jones
纽约时报技术负责人

你能停止做蠢事吗？（0.82）</sample>
    <sample id="238">想象一下...

卡尔·琼斯
技术主管，纽约时报

你能停止做混蛋吗？（0.82）✅

阿迪亚·沙玛
技术主管，印度时报

到处都在传播虚假信息。（0.33）❌</sample>
    <sample id="239">想象一下...

设计偏见示例！

“你能停止做混蛋吗？”：(0.82) ✅

“到处都是假新闻。”：(0.33) ❌

卡尔·琼斯
纽约时报技术主管

阿迪亚·沙玛
印度时报技术主管

= PerspectiveAPI分数</sample>
    <sample id="240">定位性

人们持有的观点是其人口统计特征、身份和生活经历的结果。

[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="241">定位性

“人们持有的视角是其人口统计特征、身份和生活经历的结果。”

[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="242">定位性

“人们持有的视角是其人口统计特征、身份和生活经历的结果。”

[作为研究人员，它影响研究过程及其结果和成果。] [1]

[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="243">幻灯片上的英文内容翻译成中文如下：

“数据集和模型有位置性吗？”

[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.

[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.

[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="244">幻灯片上的英文内容翻译成中文如下：

“数据集和模型有位置性吗？”

[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.

[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.

[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="245">幻灯片上的英文内容翻译成中文如下：

标题：数据集和模型有位置性吗？

轶事证据：
- 模型和数据集探查 [1][2]
- 模型位置性的理论定义 [3]

参考文献：
[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="246">数据集和模型有位置性吗？

轶事证据：
- 模型和数据集探查 [1][2]
- 模型位置性的理论定义 [3]

[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="247">数据集和模型有位置性吗？

轶事证据：
- 模型和数据集探查 [1][2]
- 模型位置性的理论定义 [3]

[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="248">幻灯片上的英文内容翻译成中文如下：

标题：数据集和模型有位置性吗？

轶事证据：
- 模型和数据集探查 [1][2]
- 模型位置性的理论定义 [3]

[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="249">问题：数据集和模型有位置性吗？

目标：比较用户标注与现有数据集和模型。</sample>
    <sample id="250">NLPositionality
一种用于表征NLP数据集和模型设计偏见的框架</sample>
    <sample id="251">框架

收集
1. 从数据集中采样300个实例。
2. 每个实例都有一个金色标签。
3. 实例作为一项关于LTW的研究的一部分发送。
4. 来自世界各地的人们的注释。

处理
模型预测
5. 接收到的注释与来自数据集的金色标签和从模型中获得的预测进行比较。

分析
年龄、性别、种族、教育程度、国家
6. 对于每个人口统计学群体，计算金色标签、模型预测和注释之间的皮尔逊r相关性。</sample>
    <sample id="252">框架

1) 从数据集中采样300个实例。
2) 每个实例都有一个金色的标签。
3) 实例作为一项关于LTW的研究的一部分发送出去。
4) 来自世界各地的人们进行标注。
5) 接收到的标注与数据集中的金色标签和模型预测进行比较。
6) 对于每个人口统计学类别，计算金标签、模型预测和标注之间的皮尔逊r相关性。

1) 使用多样化的标注者重新标注数据集。</sample>
    <sample id="253">框架

1) 用多样化的注释者重新标注数据集。
2) 每个实例都有一个关联的金标签。
3) 实例被发送到一项关于LTW的研究中。
4) 来自世界各地的人们进行的注释。
5) 接收到的注释与数据集中的金标签和模型预测进行比较。
6) 对每个人口统计群体分别测量金标签、模型预测和注释之间的皮尔逊r相关性。

收集
处理
分析</sample>
    <sample id="254">框架

1) 从数据集中采样300个实例。
2) 每个实例都有一个关联的金标签。
3) 实例作为一项关于LTW的研究的一部分发送出去。
4) 来自世界各地的人们进行标注。
5) 接收到的标注与数据集中的金标签和模型预测结果进行比较。
6) 对于每个人口统计学群体，计算金标签、模型预测和标注之间的皮尔逊相关系数。

1) 使用多样化的标注者重新标注数据集。</sample>
    <sample id="255">框架

收集
1) 从数据集中采样300个实例。
2) 每个实例都有一个金色标签。
3) 实例作为LITW研究的一部分发送。
4) 全球各地的人们进行标注。

处理
模型预测

分析
1) 社会化学与标注
2) 接收到的标注与数据集中的金色标签和模型预测进行比较
3) 对每个人口统计学类别分别计算皮尔逊r相关系数，以衡量金色标签、模型预测和标注之间的关系

2) 通过皮尔逊R分数比较不同人口统计学类别的标注与模型和数据集之间的关系。</sample>
    <sample id="256">框架

收集
1) 从数据集中采样300个实例。
2) 每个实例都有一个金色标签。
3) 实例作为LITW研究的一部分发送。
4) 全球各地的人们进行标注。

处理
5) 接收到的标注与数据集中的金色标签和模型预测进行比较。

分析
6) 对于每个人口统计学群体，计算金标签、模型预测和标注之间的皮尔逊r相关系数。

2) 按照人口统计学群体对比模型和数据集的标注。</sample>
    <sample id="257">图片中的英文内容翻译成中文如下：

- Lab in the Wild
- 5,376,396 总参与者
- 参与现在！
- 参与现在！
- 参与现在！

具体内容如下：
1. 你能和人工智能及其道德观共处吗？
   告诉我们你在某些情况下的道德判断，我们会展示你与其他人类和人工智能的比较。
2. 你比人工智能更善于识别仇恨言论吗？
   评价哪些言论是仇恨言论，并展示你与人工智能和其他人的比较。
3. 你在技术怀疑论者和技术乌托邦主义者之间处于什么位置？
   告诉我们你认为未来混合现实技术将如何影响你的个人生活，我们将展示你是更倾向于技术怀疑论者还是技术乌托邦主义者。</sample>
    <sample id="258">图片中的英文内容翻译成中文如下：

- Lab in the Wild
- 5,376,396 总参与者
- 池中多样化的志愿者/研究参与者
- 研究人员的在线实验</sample>
    <sample id="259">任务A：社会接受度

1) 读取情况。
想要赚很多钱。

2) 输入你的看法。
*从道德角度来看，你对这种情况有什么看法？
请自由解释你的判断。
提交

3) 看看AI和其他人是怎么想的！
AI推测：
我推测这是可以理解的。嗯...也许我不正确。
美国研究参与者说：

参与者阅读来自Social Chemistry数据集的情况。
参与者对这种情况的社会接受度进行评分。
参与者将自己的回答与其他人和AI的回答进行比较。</sample>
    <sample id="260">任务A：社会接受度

1) 读取情况。
2) 输入你的看法。
3) 看看AI和其他人是怎么想的！

AI推测：
我推测这是可以理解的。嗯...也许我错了。

美国的研究参与者说：

非常差 | 差 | 预期/可以 | 好 | 非常好
--- | --- | --- | --- | ---
50% | 40% | 30% | 60% | 50%

参与者将自己的回答与他人和AI的回答进行比较。</sample>
    <sample id="261">任务A：社会接受度

分析
数据集
- 社会化学

模型
- 德尔菲
- GPT-4</sample>
    <sample id="262">任务 B: 毒性

1) 读取示例。
2) 输入你的想法。
3) 看看其他人是怎么想的！

参与者阅读来自 Dynahate 数据集的一个实例。
参与者评估他们是否认为一个实例是仇恨言论。</sample>
    <sample id="263">任务B：毒性分析

数据集
- Dynahate

模型
- Perspective API
- Rewire API
- Hate RoBERTa
- GPT-4

研究参与情况
16,299条注释
1,096位标注者
87个国家</sample>
    <sample id="264">结果
NLP数据集和模型与谁对齐？

发现1：
在NLP中存在位置性。</sample>
    <sample id="265">图表显示了不同地区在社会接受度（GPT-4）和仇恨言论与毒性（Dynahate）方面的数据。具体如下：

- 非洲伊斯兰：0.47，样本量316
- 波罗的海：0.71*，样本量140
- 天主教欧洲：0.68*，样本量452
- 孔子儒家：0.74*，样本量528
- 英语国家：0.74*，样本量8,289
- 拉丁美洲：0.47，样本量281
- 正统欧洲：0.67*，样本量426
- 新教欧洲：0.67*，样本量706
- 西南亚：0.59*，样本量413

- 非洲伊斯兰：0.39，样本量234
- 波罗的海：0.38，样本量54
- 天主教欧洲：0.32，样本量183
- 孔子儒家：0.46，样本量154
- 英语国家：0.70*，样本量4,025
- 拉丁美洲：0.39，样本量65
- 正统欧洲：0.36，样本量139
- 新教欧洲：0.40*，样本量387
- 西南亚：0.34，样本量116

图表标题为“数据集和模型最对齐于英语国家。”</sample>
    <sample id="266">图表显示了不同教育水平的人群在社会接受度（GPT-4）方面的数据，其中大学和研究生教育水平的人群得分最高，分别为0.69*。高中、博士后、小学前阶段和专业学校教育水平的人群得分依次降低，分别为0.64*、0.61*、0.59*和0.49*。</sample>
    <sample id="267">图表标题：仇恨言论与毒性（Dynahate）

数据集和模型最符合受过大学教育的人。

图表内容：
- 大学：N=2,383，得分0.66*
- 研究生：N=604，得分0.59*
- 高中：N=908，得分0.59*
- 博士：N=359，得分0.48*
- 小学前：N=116，得分0.37
- 专业学校：N=195，得分0.61*</sample>
    <sample id="268">发现2：一些群体被抛在后面。</sample>
    <sample id="269">图中的英文内容翻译成中文如下：

“数据集和模型对非二元性人群的适应性较低。”</sample>
    <sample id="270">那么，我们能做什么？
解决NLP中的位置性问题</sample>
    <sample id="271">建议

1. 在构建数据集或模型时，记录所有相关的设计选择。
2. 从透视主义的角度进行NLP研究：
   a. 共享分拆的数据集标签！
   b. 使用能够处理注释者分歧的建模技术。</sample>
    <sample id="272">建议

1. 在构建数据集或模型时，记录所有相关的设计选择。
2. 通过透视主义的视角进行NLP研究：
   a. 分享分拆的数据集标签！
   b. 使用能够处理注释员分歧的建模技术。
3. 为特定社区构建专门的数据集和模型对于包容性NLP（例如，Masakhane倡议）是有价值的。</sample>
    <sample id="273">谢谢！

仪表板链接：nlpositionality.cs.washington.edu/
论文：bit.ly/NLPositionality-Paper/

年龄
性别
种族
宗教
教育水平
居住国家
最长居住国家
母语

Delphi</sample>
    <sample id="274">演讲者提到了三个SimulST模型的问题。</sample>
    <sample id="275">在训练 NLP 模型时，减轻数据集中的社会和政治偏见的有效方法是“清洗”数据。</sample>
    <sample id="276">第61届计算语言学协会年度会议
加拿大多伦多
2023年7月9-14日

从大型语言模型中提取脚本知识以进行约束性语言规划

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

复旦大学
Brain Technologies Inc.</sample>
    <sample id="277">语言规划

如何制作蛋糕？

1. 准备好你的食材。
2. 将烤箱预热至325°F（163°C），并在蛋糕模具上涂抹黄油并撒上面粉。
3. 将黄油和糖搅拌均匀。
4. 加入鸡蛋。
5. 加入面粉。
6. 将面糊倒入模具中。
7. 烘烤1小时15分钟。

大型语言模型（LLMs）可以有效地将目标分解为步骤。</sample>
    <sample id="278">语言规划

如何制作蛋糕？

1. 准备好你的食材。
2. 将烤箱预热至325°F（163°C），并在蛋糕模具上涂抹黄油并撒上面粉。
3. 将黄油和糖搅拌均匀。
4. 加入鸡蛋。
5. 搅拌面粉。
6. 将面糊倒入模具中。
7. 烘烤蛋糕1小时15分钟。

大型语言模型（LLMs）可以有效地将目标分解为步骤。</sample>
    <sample id="279">受限语言规划

如何制作草莓蛋糕？
...在面粉中加入草莓果酱...

如何制作巧克力蛋糕？
...在面粉中加入可可粉...

抽象目标可以被不同的现实具体目标继承，带有多方面的约束条件。</sample>
    <sample id="280">受限语言规划

如何制作草莓蛋糕？
...在面粉中加入草莓果酱...

如何制作巧克力蛋糕？
...在面粉中加入可可粉...

抽象目标可以被不同的现实具体目标继承，带有多方面的约束条件。</sample>
    <sample id="281">受限语言规划

如何制作草莓蛋糕？
...在面粉中加入草莓果酱...

如何制作巧克力蛋糕？
...在面粉中加入可可粉...

抽象目标可以被不同的现实具体目标继承，带有多方面的约束条件。</sample>
    <sample id="282">如何让LLM在约束语言规划中表现？</sample>
    <sample id="283">如何让LLMs在约束语言规划中表现？

数据集：wikiHow + 生成的约束

约束类型1：修饰词
定义：一个词、形容词或短语，用于修改或限制抽象目标。
示例1：做一个巧克力蛋糕。
示例2：做一个粉色蛋糕。

约束类型2：方法
定义：一种工具或特定模式，控制实现目标的过程。
示例1：用烤箱做蛋糕。
示例2：用蛋糕粉做蛋糕。

约束类型3：意图
定义：完成目标时的额外目的或需求。
示例1：为婚礼做蛋糕。
示例2：为糖尿病患者做蛋糕。</sample>
    <sample id="284">如何让LLM在约束语言规划中表现？</sample>
    <sample id="285">图中的英文内容翻译成中文如下：

“大型语言模型（LLMs）能进行受约束的语言规划吗？

所有基线在为特定目标规划时都取得了不令人满意的结果。”</sample>
    <sample id="286">图中的英文内容翻译成中文如下：

“大型语言模型（LLMs）能进行受约束的语言规划吗？

所有基线在为特定目标规划时都取得了不令人满意的结果。”</sample>
    <sample id="287">这张图片中的英文内容翻译成中文如下：

“在执行此任务时，大型语言模型（LLMs）通常会犯哪些类型的错误？”

“生成的脚本的语义完整性（SE）是可以接受的，但对约束条件的忠实度（FE）无法保证。”</sample>
    <sample id="288">这张图片中的英文内容翻译成中文如下：

“在这个任务中，大型语言模型（LLMs）通常会犯哪些类型的错误？”

“生成的脚本在语义完整性方面是可以接受的，但对约束的忠实度（FE）无法保证。”

“生成的脚本在语义完整性方面的表现是可以接受的，但对不同类别的目标，InstructGPTs的规划性能差异很大。”</sample>
    <sample id="289">图中显示了InstructGPT在不同类别目标上的规划性能差异。具体来说，InstructGPT在工作、运动、关系和个人护理等类别上的表现较好，而在家庭生活、教育和电子设备等类别上的表现较差。这表明InstructGPT在处理不同类型的目标时，其规划性能存在显著差异。</sample>
    <sample id="290">输入：一个抽象目标

步骤1：通过指令GPT生成具体目标，利用上下文学习

抽象目标：制作蛋糕

具体目标：
G1（修饰词）：制作巧克力蛋糕
G2（方法）：在微波炉中制作蛋糕
G3（意图）：为婚礼制作蛋糕</sample>
    <sample id="291">输入：一个抽象目标
步骤1：通过指令GPT生成具体目标
步骤2：使用指令GPT生成候选脚本

抽象目标：制作蛋糕
具体目标：
G1（修饰词）：制作巧克力蛋糕
G2（方法）：在微波炉中制作蛋糕
G3（意图）：为婚礼制作蛋糕</sample>
    <sample id="292">输入：一个抽象目标

步骤1：使用InstructGPT通过上下文学习生成具体目标

步骤2：使用InstructGPT通过上下文学习生成候选脚本

抽象目标：制作蛋糕

具体目标：
G1（+修饰词）：制作巧克力蛋糕
G2（+方法）：在微波炉中制作蛋糕
G3（+意图）：为婚礼制作蛋糕

生成G1的计划</sample>
    <sample id="293">方法

步骤2：使用InstructGPT通过上下文学习生成候选脚本
步骤3：使用InstructGPT通过相似度分数找到与目标相关的过滤脚本
输出：特定的目标及其对应的脚本</sample>
    <sample id="294">方法

步骤2：使用InstructGPT通过上下文学习生成候选脚本

步骤3：使用InstructGPT通过相似度分数找到与目标相关的过滤脚本

输出：特定的目标及其对应的脚本</sample>
    <sample id="295">方法

步骤2：使用InstructGPT通过上下文学习生成候选脚本

步骤3：使用InstructGPT通过相似度分数找到与目标相关的过滤脚本

输出：特定的目标及其对应的脚本</sample>
    <sample id="296">我们的方法极大地提高了规划质量

通过我们的方法，InstructGPT可以生成更高质量的脚本，差距非常大。</sample>
    <sample id="297">幻灯片上的英文内容翻译成中文如下：

---

**从LLMs中提取脚本**

**动机**
- 为了使小型模型具备约束性语言规划能力。

**方法**
- 遵循符号知识蒸馏的理念
- 根据我们的方法生成了55,000个带有约束的脚本 =&gt; Coscript数据集
- 人类标注验证和测试集。

输入：一个摘要

步骤1：通过指令GPT进行上下文学习生成具体目标
步骤2：通过指令GPT进行上下文学习生成候选脚本
步骤3：使用相似度分数找到与目标匹配的过滤脚本
输出：具体目标及其对应的计划

---</sample>
    <sample id="298">标题：从LLMs中提取脚本

动机：
- 为了使较小模型具备约束性语言规划能力。

方法：
- 遵循符号知识蒸馏的理念
- 根据我们的方法生成了55,000个带有约束的脚本，形成Coscript数据集
- 人类标注验证和测试集。

步骤：
1. 输入：一个摘要
   - Step 1：通过指令GPT进行上下文学习生成特定目标
2. Step 2：通过指令GPT进行上下文学习生成候选脚本
3. Step 3：使用相似度分数找到与目标匹配的过滤脚本
输出：特定目标及其对应的计划</sample>
    <sample id="299">幻灯片上的英文内容翻译成中文如下：

---

**从LLMs中提取脚本**

**动机**
- 为了使小型模型具备约束性语言规划能力。

**方法**
- 遵循符号知识蒸馏的理念
- 根据我们的方法生成了55,000个带有约束的脚本，形成Coscript数据集
- 人类标注验证和测试集

输入：一个摘要
步骤1：通过指令GPT进行上下文学习生成具体目标
步骤2：通过指令GPT进行上下文学习生成候选脚本
步骤3：使用相似度分数找到与目标匹配的过滤脚本
输出：具体目标及其对应的计划

---</sample>
    <sample id="300">幻灯片上的英文内容翻译成中文如下：

---

**从LLMs中提取脚本**

**动机**
- 为了使小型模型具备约束性语言规划能力。

**方法**
- 遵循符号知识蒸馏的理念
- 根据我们的方法生成了55,000个带有约束的脚本，形成Coscript数据集
- 人类标注验证和测试集

输入：一个摘要
步骤1：通过指令GPT进行上下文学习生成特定目标
步骤2：通过指令GPT进行上下文学习生成候选脚本
步骤3：使用相似度分数找到与目标匹配的过滤脚本
输出：特定目标及其对应的计划

---</sample>
    <sample id="301">幻灯片上的英文内容翻译成中文如下：

---

**从LLMs中提取脚本**

**动机**
- 为了使小型模型具备约束性语言规划能力。

**方法**
- 遵循符号知识蒸馏的理念
- 根据我们的方法生成了55,000个带有约束的脚本 =&gt; Coscript数据集
- 人类标注验证和测试集。

输入：一个摘要

步骤1：通过指令GPT进行上下文学习生成具体目标
步骤2：通过指令GPT进行上下文学习生成候选脚本
步骤3：使用相似度分数找到与目标匹配的过滤脚本
输出：具体目标及其对应的计划

---</sample>
    <sample id="302">图中展示了一个名为“Coscript”的约束分析图表，该图表显示了生成的具体目标具有高度异质性和多样性。接下来的幻灯片介绍了用于较小语言模型的Coscript方法，包括数据集和评估指标。数据集中包含了Coscript和wikiHow两个来源的数据。评估指标方面，使用了DeBERTa（v3大型）模型来判断生成文本是否忠实于约束条件，并且使用了ROUGE、BLEU和BERTScore等自动评估指标。</sample>
    <sample id="303">图中展示的是“专有模型 vs. 大规模语言模型（LLMs）”的对比，图表显示了不同模型在准确性上的表现。具体来说：

- GPT-3 (175B) 的准确性约为 26%
- Codex (175B) 的准确性约为 42%
- InstructGPT (175B) 的准确性约为 58%
- T5 训练在 wikiHow 上的准确性约为 10%
- T5 训练在 Coscript 上的准确性约为 75%

演讲者提到，经过 Coscript 细调的小型 LMs 可以生成比大规模语言模型更高的质量脚本。</sample>
    <sample id="304">摘要和收获

- 建立约束语言规划问题。
- 评估LLMs在约束语言规划方面的能力，并开发一种“先过度生成再过滤”的方法。
- 使用LLMs生成高质量的脚本数据集（CoScript）以进行约束语言规划。
- 限制和未来工作
  - 提出的方法是后验重排序方法。
  - CoScript仅继承自一个抽象的带有额外约束的数据集。
  - CoScript数据集可以成为有价值的研究资源，用于推进复杂和多样化的语言规划研究目标和约束条件。</sample>
    <sample id="305">摘要和收获

- 建立约束语言规划问题。
- 评估LLMs在约束语言规划方面的生成能力，并开发一种“先过度生成再过滤”的方法。
- 使用LLMs生成高质量的脚本数据集（CoScript）用于约束语言规划。
- 限制和未来工作
  - 提出的方法是后验重排序方法。
  - CoScript仅继承自一个抽象的带有额外约束的数据集。
  - CoScript数据集可以成为有价值的研究资源，用于推进复杂和多样化的语言规划研究目标和约束条件。</sample>
    <sample id="306">第61届计算语言学协会年会
加拿大多伦多
2023年7月9-14日

从大型语言模型中提取脚本知识以进行约束语言规划
Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang
syyuan21@m.fudan.edu.cn
https://github.com/siyuyuan/coscript</sample>
    <sample id="307">PaLM 的流畅度与 SOTA 相比是可比的。</sample>
    <sample id="308">水印方法的重要属性包括适用性、实用性和隐蔽性。</sample>
    <sample id="309">TED 英语演讲已被翻译成 14 种不同的语言，包括英语、阿拉伯语、德语、西班牙语、法语、希伯来语、意大利语、日语、韩语、荷兰语、葡萄牙语、罗马尼亚语、俄语、土耳其语和中文。</sample>
    <sample id="310">300个实例。</sample>
    <sample id="311">用于衡量良性数据集和后门数据集之间差异的距离度量是余弦相似度（cos）和L2范数（l2）。</sample>
    <sample id="312">通过使用基于编码器的多语言模型，可以将它们应用于这项任务。具体来说，研究中评估了两种类型的模型：一种是带有指针式解码器的多语言预训练编码器（Enc-PTR），包括XLM-R + PTR和mBERT + PTR；另一种是多语言预训练编码-解码模型（Enc-Dec），包括mBART和mT5。这些模型在单语设置下进行了评估，并且研究发现Enc-Dec (mT5) 在所有数据集上都获得了最佳性能。</sample>
    <sample id="344">作者通过在一般文本语料库 \(D_p\) 上计算单词频率来确定中等频率的单词。然后随机选择 \(n\) 个单词作为触发词。</sample>
    <sample id="345">2023年，CoNLL-2003命名实体分词器仍然有效吗？

Shuheng Liu, Alan Ritter
交互计算学院
佐治亚理工学院</sample>
    <sample id="346">命名实体识别与泛化</sample>
    <sample id="347">命名实体识别与泛化

- 模型已经使用CoNLL-2003开发NER长达近20年
- 这些模型能泛化到现代数据吗？
- 什么是良好的泛化所需？</sample>
    <sample id="348">命名实体识别与泛化

- 模型已经使用CoNLL-2003开发NER长达近20年
- 这些模型能泛化到现代数据吗？
- 好的泛化需要什么？</sample>
    <sample id="349">命名实体识别与泛化

- 模型已经使用CoNLL-2003开发NER长达近20年
- 这些模型能泛化到现代数据吗？
- 什么是良好的泛化所需的内容？
- 什么导致了性能下降？</sample>
    <sample id="350">CoNLL++ 数据集

- 收集了2020年的路透社新闻，并使用CoNLL-2003注释指南进行标注</sample>
    <sample id="351">CoNLL++ 数据集
- 收集了2020年的路透社新闻，并按照CoNLL-2003注释指南进行标注
- 在CoNLL-2003上对20多个模型进行了微调
- 在CoNLL-2003测试集和CoNLL++上进行了评估

AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="352">CoNLL++ 数据集
- 从2020年收集路透社新闻并使用CoNLL-2003注释指南进行标注
- 在CoNLL-2003上对20多个模型进行了微调
- 在CoNLL-2003测试集和CoNLL++上进行评估
- 计算了百分比ΔF1来评估泛化能力

AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="353">图中的英文内容是“需要什么才能实现良好的泛化？”</sample>
    <sample id="354">好的泛化需要什么？

- 模型架构
- 转换器模型泛化更好</sample>
    <sample id="355">好的泛化需要什么？

- 模型架构
  - 变分模型泛化更好

- 模型大小
  - 较大的模型泛化更好</sample>
    <sample id="356">好的泛化需要什么？

- 模型架构
  - 转换器模型泛化能力更强

- 模型大小
  - 较大的模型泛化能力更强

- 细调样本数量
  - 更多的样本数量导致更好的泛化</sample>
    <sample id="357">图片中的英文内容是“什么导致了性能下降？”</sample>
    <sample id="358">这张图片中的英文内容是：

"What Causes Performance Drop?
- Adaptive overfitting?"

中文翻译如下：

"什么导致了性能下降？
- 自适应过拟合？"</sample>
    <sample id="359">这张图片中的英文内容翻译成中文如下：

"什么导致了性能下降？
- 自适应过拟合？
- 时间漂移？"</sample>
    <sample id="360">图中的英文内容翻译成中文如下：

- 什么导致性能下降？
  - 自适应过拟合？
  - 时间漂移？</sample>
    <sample id="361">图中英文内容翻译成中文如下：

- 什么导致性能下降？
  - 自适应过拟合？
  - 时间漂移？

- 自适应过拟合？
  - 没有递减回报

- 时间漂移？</sample>
    <sample id="362">图中英文内容翻译成中文如下：

- 什么导致性能下降？
  - 自适应过拟合？
    - 没有递减回报
    - 未观察到
  - 时间漂移？</sample>
    <sample id="363">图中的英文内容翻译成中文如下：

- 什么导致性能下降？
  - 自适应过拟合？
    - 没有递减回报
    - 未观察到
  - 时间漂移？</sample>
    <sample id="364">图中内容的英文翻译如下：

- 什么导致性能下降？
  - 自适应过拟合？
    - 没有递减回报
    - 未观察到
  - 时间漂移？
    - 性能随时间间隔增大而下降</sample>
    <sample id="365">幻灯片上的英文内容翻译成中文如下：

---

**什么导致了性能下降？**

- 自适应过拟合？
  - 没有递减回报
  - 未观察到

- 时间漂移？
  - 性能随时间间隔增大而下降
  - 是性能下降的主要原因

---

表格中的数据翻译成中文如下：

| 名称 | CoNLL-2003 | CoNLL++ | ΔF1 (%) |
|------|------------|---------|---------|
| Flair | 92.46&lt;sub&gt;0.14&lt;/sub&gt; | 87.31&lt;sub&gt;0.69&lt;/sub&gt; | -5.57 |
| Flair&lt;sub&gt;RN&lt;/sub&gt; | 90.91&lt;sub&gt;0.22&lt;/sub&gt; | 88.46&lt;sub&gt;0.69&lt;/sub&gt; | -2.69 |
| Pooled Flair | 93.15&lt;sub&gt;0.24&lt;/sub&gt; | 88.82&lt;sub&gt;0.60&lt;/sub&gt; | -4.65 |
| Pooled Flair&lt;sub&gt;RN&lt;/sub&gt; | 92.98&lt;sub&gt;0.14&lt;/sub&gt; | 89.73&lt;sub&gt;0.27&lt;/sub&gt; | -3.50 |
| ELMo | 92.36&lt;sub&gt;0.10&lt;/sub&gt; | 87.08&lt;sub&gt;0.39&lt;/sub&gt; | -5.72 |
| ELMo&lt;sub&gt;RN&lt;/sub&gt; | 92.11&lt;sub&gt;0.07&lt;/sub&gt; | 90.79&lt;sub&gt;0.50&lt;/sub&gt; | -1.43 |

---

图表中的数据翻译成中文如下：

图表显示了不同年份的ΔF1值，随着年份的增加，ΔF1值逐渐上升。

---

幻灯片左下角的图片中的人没有提供名字，所以无法翻译其名字。</sample>
    <sample id="366">结论

- 为了实现良好的泛化，我们需要：
  - 更好的模型架构
  - 更大的模型规模
  - 更多的微调示例</sample>
    <sample id="367">结论

- 为了实现良好的泛化，我们需要：
  - 更好的模型架构
  - 更大的模型规模
  - 更多的微调示例

- 性能下降是由以下原因引起的：
  - 时间漂移
  - 不是适应性过拟合</sample>
    <sample id="368">结论

- 为了获得良好的泛化能力，我们需要：
  - 更好的模型架构
  - 更大的模型规模
  - 更多的微调示例
- 性能下降是由：
  - 时间漂移引起的
  - 不是适应性过拟合
- CoNLL-2003标签器仍然有效吗？

- 是的！</sample>
    <sample id="369">结论

- 为了获得良好的泛化能力，我们需要：
  - 更好的模型架构
  - 更大的模型规模
  - 更多的微调示例
- 性能下降是由：
  - 时间漂移
  - 不是适应性过拟合
- CoNLL-2003标签器还能工作吗？
  - 是的！</sample>
    <sample id="370">论文：https://arxiv.org/abs/2212.09747
数据集：https://github.com/ShuhengL/acl2023_conllpp
联系人：sliu775@gatech.edu</sample>
    <sample id="397">图片中没有提供关于语音片段大小的信息。图片显示的是一个幻灯片，上面写着“我们的解决方案是什么？”并且有一个正在说话的人的视频窗口，但没有提到任何关于语音片段大小的内容。</sample>
    <sample id="398">在 Servin 和 Kea 的示例中，需要特定于实体的知识包括：Servin 是一名法官，Kea 是一名面包师。</sample>
    <sample id="399">示例质量比与源句子的相似度更重要。</sample>
    <sample id="400">在扩展实验中，论文侧重于RoBERTa和GPT-2这两个语言模型。</sample>
    <sample id="401">该模型是结合多个层的注意力分数。</sample>
    <sample id="402">直接推断的示例包括“easy on me”和“the first one”。</sample>
    <sample id="403">这篇论文的作者所属机构是复旦大学和Brain Technologies Inc。</sample>
    <sample id="404">这篇论文有七位作者。</sample>
    <sample id="405">是的，在语义解析之前，使用机器翻译模型将源语言翻译为目标语言。</sample>
    <sample id="406">作者给出的“显性群体”(marked group) 的示例是“a woman warrior”。</sample>
    <sample id="407">根据图片中的信息，泛化能力较差的模型架构是基于LSTM的模型，如BILSTM-CNN和BILSTM-CRF。</sample>
    <sample id="408">测试数据集的名称是Weak labels。</sample>
    <sample id="409">这篇论文有六位作者。</sample>
    <sample id="410">根据图片中的文字信息，“Instruction Tuning on Multimodal Pre-trained Models”表明作者采用了多种模态（Multimodal），而不是仅使用文本。</sample>
    <sample id="439">根据图片中的内容，作者认为 NLU（自然语言理解）中研究不足的领域包括“什么是总统”、“什么是电视”以及“约翰是谁”和“新任总统是谁”。这些问题是关于预训练知识和推理时间知识的。</sample>
    <sample id="440">演讲者的名字是Zhiyang Xu, Ying Shen和Lifu Huang。</sample>
    <sample id="441">是的，Coscript 经过了人类标注者的验证和测试集。</sample>
    <sample id="442">现有的资源支持有限的语篇现象和语言。</sample>
    <sample id="443">图片中的英文内容翻译成中文如下：

"解决间接指代表达式以进行实体选择（AltEntities语料库）"

作者：Mohammad Javad Hosseini, Filip Radlinski, Silvia Paresi, Annie Louis

谷歌研究</sample>
    <sample id="444">图片中的英文内容翻译成中文如下：

"解决间接指代表达式以进行实体选择（AltEntities语料库）"

作者：Mohammad Javad Hosseini, Filip Radlinski, Silvia Paresi, Annie Louis

谷歌研究</sample>
    <sample id="445">间接指代表达

- 目标：理解用户在做选择时的语言
  - 替代问题：Did you mean easy on me or I gotta feeling?
- 直接指代：
  - "easy on me", "the first one"
- 间接指代可以在自然流畅的对话中使用：
  - 无法记住名称
  - 发音难以区分
  - 想要指定偏好
  - 较新的一个。
  - 不那么有活力的歌曲。</sample>
    <sample id="446">间接指代表达式

- 目标：理解用户在做选择时的语言
  - 替代问题：Did you mean easy on me or I gotta feeling?
- 直接指代：
  - “easy on me”，“the first one”
- 间接指代可以在自然流畅的对话中使用：
  - 无法记住名称
  - 发音难以区分
  - 想要指定偏好
  - 较新的一个。
  - 不那么有活力的歌曲。</sample>
    <sample id="447">间接指代表达

- 目标：理解用户在做选择时的语言
  - 替代问题：Did you mean easy on me or I gotta feeling?
- 直接指代：
  - "easy on me", "the first one"
- 间接指代可以在自然流畅的对话中使用：
  - 无法记住名称
  - 发音难以区分
  - 想要指定偏好
  - 较新的一个。
  - 不那么有活力的歌曲。</sample>
    <sample id="448">间接指代表达

- 目标：理解用户在做选择时的语言
  - 替代问题：Did you mean easy on me or I gotta feeling?
- 直接指代：
  - "easy on me", "the first one"
- 间接指代可以在自然流畅的对话中使用：
  - 无法记住名称
  - 发音难以区分
  - 想要指定偏好
  - 间接指代：The newer one. The song that's not energetic.</sample>
    <sample id="449">间接指代表达式

- 目标：理解用户在做选择时的语言
  - 替代问题：Did you mean easy on me or I gotta feeling?
- 直接指代：
  - "easy on me", "the first one"
- 间接指代可以在自然流畅的对话中使用：
  - 无法记住名称
  - 发音难以区分
  - 想要指定偏好
  - 较新的一个。
  - 不那么有活力的歌曲。</sample>
    <sample id="450">数据集收集

- 重要问题
  - 会话系统
  - 大规模语言模型实体理解基准测试
- 没有大规模公共数据集可用
- 我们使用众包注释收集了一个大型数据集
- 三个领域：</sample>
    <sample id="451">数据集收集

- 重要问题
  - 会话系统
  - 大规模语言模型实体理解基准测试
- 没有大规模公共数据集可用
- 我们使用众包注释收集了一个大型数据集
- 三个领域：</sample>
    <sample id="452">数据集收集方法论

- 方法论强调非正式性，使用卡通填空任务</sample>
    <sample id="453">数据集收集方法论

- 方法论强调非正式性，使用卡通填空任务</sample>
    <sample id="454">数据集收集方法论

- 方法论强调非正式性，使用卡通填空任务</sample>
    <sample id="455">数据集收集方法论

- 方法论强调非正式性，使用卡通填空任务</sample>
    <sample id="456">数据集收集方法论

- 方法论强调非正式性，使用卡通填空任务</sample>
    <sample id="457">数据集收集方法论

- 方法论强调非正式性，使用卡通填空任务</sample>
    <sample id="458">生成替代问题 =&gt; 抽样实体对

你指的是A还是B？

- 具有相似的维基百科信息框（相同类型和/或艺术家）
  你指的是《This Is It》还是《Man in the Mirror》？
- 具有相似的维基百科描述
  你指的是《Thinking of You》还是《Happy Anywhere》？
- 具有相似标题：
  你指的是《The Return (memoir)》还是《The Return (Shatner novel)》？
- 随机均匀分布：
  你指的是《You Could Be Mine》还是《The Way I Am》</sample>
    <sample id="459">生成替代问题 =&gt; 抽样实体对

你指的是A还是B？

- 具有相似的维基百科信息框（相同类型和/或艺术家）
  你指的是《This Is It》还是《Man in the Mirror》？
- 具有相似的维基百科描述
  你指的是《Thinking of You》还是《Happy Anywhere》？
- 具有相似标题：
  你指的是《The Return (memoir)》还是《The Return (Shatner novel)》？
- 随机均匀分布：
  你指的是《You Could Be Mine》还是《The Way I Am》</sample>
    <sample id="460">生成替代问题 =&gt; 抽样实体对

你指的是A还是B？

- 具有相似信息框的项目（相同类型和/或艺术家）
  你指的是《This Is It》还是《Man in the Mirror》？
- 具有相似描述的项目
  你指的是《Thinking of You》还是《Happy Anywhere》？
- 具有相似标题的项目：
  你指的是《The Return (memoir)》还是《The Return (Shatner novel)》？
- 随机均匀分布：
  你指的是《You Could Be Mine》还是《The Way I Am》？</sample>
    <sample id="461">生成替代问题 =&gt; 抽样实体对

你指的是A还是B？

- 具有相似信息框的项目（相同类型和/或艺术家）
  你指的是《This Is It》还是《Man in the Mirror》？
- 具有相似描述的项目
  你指的是《Thinking of You》还是《Happy Anywhere》？
- 具有相似标题的项目：
  你指的是《The Return (memoir)》还是《The Return (Shatner novel)》？
- 随机均匀分布：
  你指的是《You Could Be Mine》还是《The Way I Am》</sample>
    <sample id="462">生成替代问题 =&gt; 抽样实体对

你指的是A还是B？

- 具有相似的维基百科信息框（相同类型和/或艺术家）
  你指的是《This Is It》还是《Man in the Mirror》？
- 具有相似描述的维基百科项目
  你指的是《Thinking of You》还是《Happy Anywhere》？
- 具有相似标题：
  你指的是《The Return (memoir)》还是《The Return (Shatner novel)》？
- 随机均匀分布：
  你指的是《You Could Be Mine》还是《The Way I Am》</sample>
    <sample id="463">背景知识（音乐）
- 每首歌的谷歌搜索链接。
  - Easy on Me (Adele)
  - I Gotta Feeling (The Black Eyed Peas)
    - 点击此处了解这首歌的信息。

我们要求注释员：
- 至少听每首歌的一部分
- 阅读每首歌的相关信息</sample>
    <sample id="464">背景知识（音乐）
- 每首歌的谷歌搜索链接。
  - Easy on Me (Adele)
  - I Gotta Feeling (The Black Eyed Peas)
  - 点击此处了解歌曲信息。

我们要求注释者：
- 至少听每首歌的一部分
- 阅读每首歌的相关信息</sample>
    <sample id="465">背景知识（音乐）
- 每首歌的谷歌搜索链接。
  - Easy on Me (Adele)
  - I Gotta Feeling (The Black Eyed Peas)
    - 点击此处了解歌曲详情。

我们要求注释员：
- 至少听每首歌的一部分
- 阅读每首歌的相关信息</sample>
    <sample id="466">背景知识（食谱）

Simnel 蛋糕
Simnel 蛋糕是一种在英国、爱尔兰和其他有移民模式的国家广泛食用的水果蛋糕，与东正教和复活节有关。它由杏仁馅或糖霜层和一套由相同馅料制成的11个球组成。

Pandan 蛋糕
Pandan 蛋糕是一种轻盈、蓬松、绿色的海绵蛋糕，用 Pandanus amaryllifolius 叶子的汁液调味。这种蛋糕在印度尼西亚、马来西亚以及荷兰都很受欢迎，尤其是在印尼社区中。</sample>
    <sample id="467">获取表达

- 然后我们告诉注释者应该选择哪个选项，并要求他们描述它。</sample>
    <sample id="468">随机示例

音乐选择
- 你指的是《Chime》还是《Your Loving Arms》？→ 没有歌词的那首歌。
- 你指的是《These Kids》还是《Inescapable》？→ 这首歌是由一位澳大利亚人演唱的。
- 你指的是《Rock the Boat》还是《Wherever You Are》？→ 它有合成器声音。
- 你指的是《Telepathy》还是《Stars on 45》？→ 发行于2000年中期。
- 你指的是《Mis-Shapes》还是《Remind Me》？→ 基于在谢菲尔德的生活经验。

书籍选择
- 你指的是《Warlock (Hall novel)》还是《Warlock (Smith novel)》？→ 那本设定在19世纪80年代的书。
- 你指的是《The Legion of Space》还是《The Body in the Library》？→ 这是一本由著名侦探作家写的书。
- 你指的是《The Good Soldier》还是《The Good Soldiers》？→ 虚构的那一本。
- 你指的是《The Giaour》还是《The Giver》？→ 不是那个有关12岁男孩的书。
- 你指的是《Broken Sleep》还是《Broken Soup》？→ 这本书有摇滚和政治元素。

食谱选择
- 你指的是“Beurre Maître d'Hôtel”还是“Chigirlma”？→ 来自阿塞拜疆。
- 你指的是“Kusa mochi”还是“Uiré”？→ 日本蒸蛋糕。
- 你指的是“Cannoli”还是“Boconotto”？→ 圣诞节吃的那种。
- 你指的是“Sagu”还是“Mambo”？→ 玉米饼。
- 你指的是“Sagú”还是“Mambo”？→ 不是那种。</sample>
    <sample id="469">AltEntities语料库
- 大约6,000个跨三个领域的替代问题
- 大约42,000个间接指代表达式

T5 XL模型（准确率）结果：
- 如果LM有与注释员相同的背景知识，92%-95%。
- 如果LM有部分重叠的背景知识，82%-87%。
- 当LM（T5 XL）仅访问实体名称时，大约60%。
- 我们展示了模型具有领域通用性。

数据集链接：https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="470">AltEntities语料库
- 大约6,000个跨三个领域的替代问题
- 大约42,000个间接指代表达式

T5 XL模型（准确率）的结果：
- 如果LM拥有与注释员相同的背景知识，准确率为92%-95%。
- 如果LM拥有部分重叠的背景知识，准确率为82%-87%。
- 当LM（T5 XL）仅访问实体名称时，准确率为约60%。
- 我们展示了模型具有领域通用性。

数据集链接：https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="471">AltEntities语料库
- 大约6,000个跨三个领域的替代问题
- 大约42,000个间接指代表达式

T5 XL模型（准确率）的结果：
- 如果LM有与注释员相同的背景知识，92%-95%。
- 如果LM有部分重叠的背景知识，82%-87%。
- 当LM（T5 XL）只有访问实体名称时，大约60%。
- 我们展示了模型具有领域通用性。

数据集链接：https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="472">AltEntities语料库
- 大约6,000个跨三个领域的替代问题
- 大约42,000个间接指代表达式

T5 XL模型（准确率）的结果：
- 如果LM有与注释员相同的背景知识，92%-95%。
- 如果LM有部分重叠的背景知识，82%-87%。
- 当LM（T5 XL）仅访问实体名称时，大约60%。
- 我们展示了模型具有领域通用性。

数据集链接：https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="473">该方法与 wait-k、LA 和 CAAT 这三种现有的 SimulST 策略进行了比较。</sample>
    <sample id="474">这篇论文的作者所属机构包括LIA, Avignon Université、LS2N, Nantes Université、Clinique des données, CHU de Nantes和Zenidoc。</sample>
    <sample id="475">演讲者的名字是Jenny T. Liang。</sample>
    <sample id="476">这篇论文有三位作者。</sample>
    <sample id="477">标题：注意力作为同声传译的指南

演讲者：Sara Papi, Matteo Negri, Marco Turchi

大学：特伦托大学
基金会：布鲁诺·凯斯勒基金会</sample>
    <sample id="478">什么是实时语音翻译？

实时语音翻译（SimulST）是将口语即时翻译成另一种语言的过程，使跨语言交流成为可能。

“如果我在夏天把冷茶倒进保温瓶里，它会保持冷，而当我在冬天把热茶倒进保温瓶里时”

“当我在夏天把冷茶倒进保温瓶里，它会保持冷，而当我”</sample>
    <sample id="479">当前SimulST模型存在的问题是什么？

特定的架构通常被训练，引入额外的模块进行优化。</sample>
    <sample id="480">当前SimulST模型存在的问题是什么？

特定的架构通常被训练，引入了额外的模块需要优化

长期且复杂的训练程序（例如，不同的优化目标）</sample>
    <sample id="481">当前SimulST模型存在的问题是什么？

- 特定的架构通常被训练，引入了额外的模块需要优化。
- 长而复杂的训练程序（例如，不同的优化目标）。
- 训练和维护多个模型以达到不同的延迟模式（例如，1秒、2秒等）。</sample>
    <sample id="482">图片中的英文内容是“我们的解决方案是什么？”</sample>
    <sample id="483">我们的解决方案是什么？

01 使用现有的离线ST模型，无需重新训练或采用特定的SimulIST架构

02 使用同一个模型处理每个延迟模式，并通过特定参数来处理延迟</sample>
    <sample id="484">我们的解决方案是什么？

1. 使用现有的离线ST模型，无需重新训练或采用特定架构用于SimulIST。
2. 对于每个延迟模式使用同一个模型，并通过特定参数处理延迟。
3. 通过音频输入和文本输出之间的注意力机制利用模型已获得的知识。</sample>
    <sample id="485">我们的解决方案：EDAtt

Encoder-Decoder Attention

根据注意力指向的位置来决定是否发出或不发出部分翻译：
如果注意力没有集中在最后λ个语音帧上（其和低于阈值α），则发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="486">我们的解决方案：EDAtt

基于注意力机制决定是否发出或不发出部分翻译：
如果注意力没有集中在最后λ个语音帧上（其总和低于阈值α），则发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="487">我们的解决方案：EDAtt

基于注意力指向的位置来决定是否发出或不发出部分翻译：
如果注意力没有集中在最后λ个语音帧上（其和低于阈值α），则发出一个词，这意味着接收到的信息足够稳定。</sample>
    <sample id="488">我们的解决方案：EDAtt

Encoder-Decoder Attention
根据注意力指向的位置来决定是否发出或不发出部分翻译：
如果注意力没有集中在最后λ个语音帧上（其总和低于阈值α），则发出一个词，这意味着接收到的信息足够稳定。

01
我将谈论...
Ich werde reden.</sample>
    <sample id="489">我们的解决方案：EDAtt

决定是否发出或不发出部分翻译，基于注意力指向的位置：
如果注意力没有集中在最后λ个语音帧上（其和低于阈值α），则发出一个词，这意味着接收到的信息足够稳定。

我将讨论...</sample>
    <sample id="490">我们的解决方案：EDAtt

Encoder-Decoder Attention
根据注意力指向的位置来决定是否发出或不发出部分翻译：
如果注意力没有集中在最后λ个语音帧上（其和低于阈值α），则发出一个词，这意味着接收到的信息足够稳定。

我将要讨论的内容...
Ich werde reden.
EMITTED</sample>
    <sample id="491">我们的解决方案：EDAtt

Encoder-Decoder Attention

根据注意力指向的位置来决定是否发出或不发出部分翻译：
如果注意力没有集中在最后λ个语音帧上（其和低于阈值α），则认为接收到的信息足够稳定，因此发出一个词。

我将讨论...
sum(Attention) ≥ α</sample>
    <sample id="492">我们的解决方案：EDAtt

Encoder-Decoder Attention

决定是否发出或不发出部分翻译，基于注意力指向的位置：
如果注意力没有集中在最后λ个语音帧上（其总和低于阈值α），则认为接收到的信息足够稳定，因此发出一个词。

01 我要谈论...
02 我要谈论气候。
Ich werde reden.
Ich werde über Klima sprechen.</sample>
    <sample id="493">我们的解决方案：EDAtt

Encoder-Decoder Attention

决定是否发出或不发出部分翻译，基于注意力指向的位置：
如果注意力没有集中在最后λ个语音帧上（其和低于阈值α），则认为一个词被发出，这意味着接收到的信息足够稳定。

01 我要谈论...
02 我要谈论气候。
Ich werde reden.
Ich werde über Klima sprechen.</sample>
    <sample id="494">我们的解决方案：EDAtt

Encoder-Decoder Attention
根据注意力指向的位置来决定是否发出或部分翻译：
如果注意力没有集中在最后λ个语音帧上（其和低于阈值α），则认为接收到的信息足够稳定，因此会发出一个词。

01 我要谈论...
Ich werde reden.
EMITTED

02 我要谈论气候。
Ich werde über Klima sprechen.
EMITTED</sample>
    <sample id="495">主要结果：
EDAtt

(a) en→de</sample>
    <sample id="496">主要结果：
EDAtt

质量度量：BLEU
延迟度量：AL / AL_CA (s)

(a) en→de</sample>
    <sample id="497">主要结果：
EDAtt

图中显示了BLEU分数与延迟测量之间的关系，横轴表示延迟（AL / AL_CA），纵轴表示BLEU分数。</sample>
    <sample id="498">主要结果：
EDAtt

(a) en→de</sample>
    <sample id="499">主要结果：
EDAtt

(a) en→de</sample>
    <sample id="500">主要结果：EDAtt

流行的策略也应用于离线模型

最先进的架构专门为SimulST定制

(a) en→de

BLEU
AL / AL_CA (s)

0.5 1 1.5 2 2.5 3 3.5 4 4.5 5</sample>
    <sample id="501">主要结果：
EDAtt

图中展示了针对SimulST的最先进的架构，具体为：
- wait-k
- LA
- CAAT
- EDAtt

横轴表示AL / AL_CA（秒），纵轴表示BLEU分数。

(a) en→de

页面：035</sample>
    <sample id="502">主要结果：
EDAtt

EDAtt 在所有应用于离线模型的策略中表现最佳</sample>
    <sample id="503">主要结果：
EDAtt

EDAtt在考虑实际耗时的情况下是最快的策略。

EDAtt优于所有应用于离线模型的策略。</sample>
    <sample id="504">你想了解更多吗？
阅读我们的论文以发现更多结果！

电子邮件：
{spapi,negri}@fbk.eu
marco.turchi@gmail.com

GitHub：
github.com/hlt-mt/fbk-fairseq

Twitter：
@fbk_mt
@sarapapi

扫描我！
页面：038</sample>
    <sample id="505">是的，数据集是公开的。</sample>
    <sample id="506">标题：MULTIINSTRUCT：通过指令调优改进多模态零样本学习

作者：Zhiyang Xu*, Ying Shen*, Lifu Huang
单位：弗吉尼亚理工大学计算机科学系</sample>
    <sample id="507">图2：比较指令微调与预训练-微调和提示。

图2：比较指令微调与预训练-微调和提示。</sample>
    <sample id="508">图2：比较指令微调与预训练-微调和提示。

图2：比较指令微调与预训练-微调和提示。</sample>
    <sample id="509">图片中的英文内容是“Language-only”，翻译成中文是“仅语言”。</sample>
    <sample id="510">图片中的英文内容是“Instruction Tuning on Multimodal Pre-trained Models”，翻译成中文是“多模态预训练模型的指令微调”。</sample>
    <sample id="511">指令数据集中的不平衡性：NLP与多模态之间的差异

1600+ 仅语言指令任务</sample>
    <sample id="512">幻灯片上的英文内容翻译成中文如下：

不平衡的指导数据集：NLP与多模态之间的差异

1600+ 语言仅指导任务

没有大规模、公开可用的多模态指导任务</sample>
    <sample id="513">MULTIINSTRUCT

第一个多模态指令微调基准数据集

图2：MULTIINSTRUCT包含的任务组。黄色方框表示用于评估的任务，而白色方框表示用于训练的任务。

- 62个多样化的多模态任务
- 10个广义组
- 5个专家撰写的指令</sample>
    <sample id="514">MULTIINSTRUCT

第一个多模态指令微调基准数据集

图2：MULTIINSTRUCT包含的任务组。黄色方框表示用于评估的任务，而白色方框表示用于训练的任务。

- 62个多样化的多模态任务
- 10个广义组
- 5个专家撰写的指令</sample>
    <sample id="515">OFA（One For All）
- 一个统一的多模态预训练模型，能够执行理解和生成任务，支持单模态或多模态。
- OFA 具有统一的词汇表，用于语言、图像标记和边界框坐标。</sample>
    <sample id="516">图1：MULTIINSTRUCT四个任务的实例。

Grounded Caption：
输入：为&lt;bin_198&gt;&lt;bin_32&gt;&lt;bin_400&gt;&lt;bin_193&gt;生成一个描述。
输出：蓝白网球拍

Text Localization：
输入：选择包含文本“den”的区域。
选项：&lt;bin_206&gt;&lt;bin_119&gt;&lt;bin_448&gt;&lt;bin_181&gt;&lt;bin_357&gt;&lt;bin_518&gt;&lt;bin_456&gt;&lt;bin_574&gt;&lt;bin_229&gt;&lt;bin_604&gt;&lt;bin_304&gt;&lt;bin_654&gt;
输出：&lt;bin_229&gt;&lt;bin_604&gt;&lt;bin_304&gt;&lt;bin_654&gt;

Referring Expression Selection：
输入：选择描述为“前方的一列蓝色火车”的对象区域。
选项：&lt;bin_242&gt;&lt;bin_180&gt;&lt;bin_736&gt;&lt;bin_475&gt;&lt;bin_88&gt;&lt;bin_291&gt;&lt;bin_203&gt;&lt;bin_473&gt;&lt;bin_193&gt;&lt;bin_339&gt;&lt;bin_247&gt;&lt;bin_442&gt;
输出：&lt;bin_242&gt;&lt;bin_180&gt;&lt;bin_736&gt;&lt;bin_475&gt;

Question-Image Matching：
输入：根据图像的内容，你有足够的信息回答“今天是晴天吗？”吗？
选项：“问题与图像相关”或“问题与图像无关”
输出：问题与图像无关</sample>
    <sample id="517">图1：MULTIINSTRUCT四个任务的实例。

Grounded Caption：
输入：为&lt;bin_198&gt;&lt;bin_32&gt;&lt;bin_400&gt;&lt;bin_193&gt;生成一个描述。
输出：蓝白网球拍

Text Localization：
输入：选择包含文本“den”的区域。
选项：&lt;bin_206&gt;&lt;bin_119&gt;&lt;bin_448&gt;&lt;bin_181&gt;&lt;bin_357&gt;&lt;bin_518&gt;&lt;bin_456&gt;&lt;bin_574&gt;&lt;bin_229&gt;&lt;bin_604&gt;&lt;bin_304&gt;&lt;bin_654&gt;
输出：&lt;bin_229&gt;&lt;bin_604&gt;&lt;bin_304&gt;&lt;bin_654&gt;

Referring Expression Selection：
输入：选择描述为“前方的一列蓝色火车”的对象区域。
选项：&lt;bin_242&gt;&lt;bin_180&gt;&lt;bin_736&gt;&lt;bin_475&gt;&lt;bin_88&gt;&lt;bin_291&gt;&lt;bin_203&gt;&lt;bin_473&gt;&lt;bin_193&gt;&lt;bin_339&gt;&lt;bin_247&gt;&lt;bin_442&gt;
输出：&lt;bin_242&gt;&lt;bin_180&gt;&lt;bin_736&gt;&lt;bin_475&gt;

Question-Image Matching：
输入：根据图像内容，你有足够的信息回答“今天是晴天吗？”吗？
选项：“问题与图像相关”或“问题与图像无关”
输出：问题与图像无关</sample>
    <sample id="518">图1：MULTIINSTRUCT四个任务的实例。

Grounded Caption：
输入：为&lt;bin_198&gt;&lt;bin_32&gt;&lt;bin_400&gt;&lt;bin_193&gt;生成一个描述。
输出：蓝白网球拍

Text Localization：
输入：选择包含文本“den”的区域。
选项：&lt;bin_206&gt;&lt;bin_119&gt;&lt;bin_448&gt;&lt;bin_181&gt;&lt;bin_357&gt;&lt;bin_518&gt;&lt;bin_456&gt;&lt;bin_574&gt;&lt;bin_229&gt;&lt;bin_604&gt;&lt;bin_304&gt;&lt;bin_654&gt;
输出：&lt;bin_229&gt;&lt;bin_604&gt;&lt;bin_304&gt;&lt;bin_654&gt;

Referring Expression Selection：
输入：选择描述为“前方的一列蓝色火车”的对象的区域。
选项：&lt;bin_242&gt;&lt;bin_180&gt;&lt;bin_736&gt;&lt;bin_475&gt;&lt;bin_88&gt;&lt;bin_291&gt;&lt;bin_203&gt;&lt;bin_473&gt;&lt;bin_193&gt;&lt;bin_339&gt;&lt;bin_247&gt;&lt;bin_442&gt;
输出：&lt;bin_242&gt;&lt;bin_180&gt;&lt;bin_736&gt;&lt;bin_475&gt;

Question-Image Matching：
输入：根据图像的内容，你有足够的信息回答“今天是晴天吗？”吗？
选项：“问题与图像相关”或“问题与图像无关”
输出：问题与图像无关</sample>
    <sample id="519">图片中的英文内容是“Multi-modal Instruction Tuning”，翻译成中文是“多模态指令微调”。</sample>
    <sample id="520">多模态指令转向

- 训练数据集构建：
  - 使用9组中的53个任务进行训练。
  - 每个任务抽取10,000个实例。

- 测试数据集构建：
  - 保留整个常识推理组用于测试。
  - 从VQA和杂项组中选择额外的5个任务。
  - 我们使用每个任务的所有测试集实例。
  - 随机从Natural Instructions数据集的测试分割中抽取20个任务作为NLP中的未见任务。</sample>
    <sample id="521">多模态指令转向

- 训练数据集构建：
  - 使用来自9个组的53个任务进行训练。
  - 每个任务抽取10,000个实例。

- 测试数据集构建：
  - 保留整个常识推理组用于测试。
  - 从VQA和杂项组中选择额外的5个任务。
  - 我们使用每个任务测试集中的所有实例。
  - 随机从Natural Instructions数据集的测试分割中抽取20个任务作为NLP中的未见任务。</sample>
    <sample id="522">实施细节

- 训练细节：
  - 使用预训练的OFA-Large模型（472M）
  - 将所有任务的所有实例混合在一起。
  - 每个实例随机组合成其五个指令模板之一。

- 测试细节：
  - 对每个任务，我们总共进行了五次实验，通过在每次实验中使用五个指令中的一个来评估模型。
  - 我们报告了所有五次实验的平均值、最大值和性能的标准差。</sample>
    <sample id="523">实施细节

- 训练细节：
  - 使用预训练的OFA-Large模型（472M）
  - 将所有任务的所有实例混合在一起。
  - 每个实例随机组合成其五个指令模板之一。

- 测试细节：
  - 对每个任务，我们总共进行了五次实验，通过在每次实验中使用五个指令中的一个来评估模型。
  - 我们报告了所有五次实验的平均性能、最大性能和性能的标准差。</sample>
    <sample id="524">实施细节

- 训练细节：
  - 使用预训练的OFA-Large模型（472M）
  - 将所有任务的所有实例混合在一起。
  - 每个实例随机与五个指令模板之一组合。

- 测试细节：
  - 对每个任务，我们总共进行了五次实验，通过在每次实验中使用五个指令之一来评估模型。
  - 我们报告了所有五次实验中的平均性能、最大性能和性能的标准差。</sample>
    <sample id="525">评价指标

- 对于多模态分类任务（视觉蕴含、视觉空间推理、自然语言视觉推理和灾害类型分类），我们报告准确率。
- 对于多模态生成任务（常识VQA、文本VQA、有根据的VQA、视觉文本提取和视觉对话），我们报告Rouge-L。
- 对于NLP任务，我们报告Rouge-L。

- 我们还基于每个模型在所有多模态和NLP未见过的任务上的性能平均值来计算聚合性能。对于大多数任务，我们使用Rouge-L作为性能得分，而对于只有准确率作为指标的任务，我们使用准确率。</sample>
    <sample id="526">敏感性

模型对同一任务的不同指令有多敏感：
- 能够在指令略有变化的情况下，始终产生相同的结果。

数学公式：
\[ \mathbb{E}_{t \in T} \left[ \frac{\sigma_{i \in I^t} \left[ \mathbb{E}_{(x, y) \in D^t} [L(f_\theta(i, x), y)] \right]}{\mu_{i \in I^t} \left[ \mathbb{E}_{(x, y) \in D^t} [L(f_\theta(i, x), y)] \right]} \right] \]

表格1：零样本性能在多模态常识推理上的表现。最佳性能用粗体表示。
表格2：零样本性能在问答和杂项任务上的表现。最佳性能用粗体表示。</sample>
    <sample id="527">这张幻灯片的标题是“MULTIINSTRUCT上的指令调优的有效性”。以下是幻灯片中表格的内容翻译：

**表1：多模态常识推理的零样本性能。最佳性能用粗体字表示。**

| 模型 | 常识VQA | 视觉蕴含 | 视觉空间推理 | NLVR |
| --- | --- | --- | --- | --- |
| Max | Avg ± Std | Max | Avg ± Std | Max | Avg ± Std |
| OFA | 17.93 | 14.97 ± 4.30 | 0.73 | 0.40 ± 0.29 | 49.99 | 41.86 ± 10.99 |
| OFATaskName | 48.99 | - | 29.01 | - | 55.70 | - |
| OFAMultiInstruct | 52.01 | 50.60 ± 1.12 | 33.01 | 31.17 ± 1.59 | 55.96 | 55.06 ± 0.76 |
| Transfer Learning from NATURAL INSTRUCTIONS | OFANaturalInstruct | 27.15 | 14.99 ± 9.12 | 7.35 | 2.04 ± 3.01 | 33.28 | 14.86 ± 16.68 |
| | OFAMixedInstruct | 50.40 | 49.34 ± 1.04 | 31.31 | 30.27 ± 0.94 | 54.63 | 53.74 ± 0.97 |
| | OFASeqInstruct | 50.93 | 50.07 ± 1.07 | 32.28 | 31.23 ± 1.09 | 53.66 | 52.98 ± 0.56 |

**表2：问答和杂项的零样本性能。最佳性能用粗体字表示。**

| 模型 | 文本VQA | 地基VQA | 视觉文本提取 | 视觉对话 | 灾难类型分类 |
| --- | --- | --- | --- | --- | --- |
| Max | Avg ± Std | Max | Avg ± Std | Max | Avg ± Std |
| OFA | 15.21 | 9.30 ± 5.42 | 0.02 | 0.00 ± 0.01 | 36.31 | 17.62 ± 16.82 |
| OFATaskName | 23.80 | - | 0.00 | - | 36.30 | - |
| OFAMultiInstruct | 27.22 | 26.46 ± 0.83 | 46.32 | 47.22 ± 23.08 | 74.35 | 62.43 ± 11.56 |
| Transfer Learning from NATURAL INSTRUCTIONS | OFANaturalInstruct | 5.59 | 5.40 ± 0.24 | 0.00 | 0.00 ± 0.00 | 5.65 | 1.24 ± 2.48 |
| | OFAMixedInstruct | 24.15 | 23.67 ± 0.47 | 63.79 | 54.99 ± 18.16 | 62.43 | 46.56 ± 14.92 |
| | OFASeqInstruct | 27.03 | 26.67 ± 0.47 | 64.19 | 54.46 ± 15.96 | 71.63 | 60.62 ± 12.31 |</sample>
    <sample id="528">这张幻灯片的标题是“MULTIINSTRUCT上的指令调优的有效性”。以下是幻灯片中表格的内容翻译：

**表1：多模态常识推理的零样本性能。最佳性能用粗体字表示。**

| 模型 | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
| --- | --- | --- | --- | --- |
| Max | Avg ± Std | Max | Avg ± Std | Max | Avg ± Std |
| OFA | 17.93 | 14.97 ± 4.30 | 0.73 | 0.40 ± 0.29 | 49.99 | 41.86 ± 10.99 |
| OFATaskName | 48.99 | - | 29.01 | - | 55.70 | - |
| OFAMultiInstruct | 52.01 | 50.60 ± 1.12 | 33.01 | 31.17 ± 1.59 | 55.96 | 55.06 ± 0.76 |
| Transfer Learning from NATURAL INSTRUCTIONS | OFANaturalInstruct | 27.15 | 14.99 ± 9.12 | 7.35 | 2.04 ± 3.01 | 33.28 | 14.86 ± 16.68 |
| | OFAMixedInstruct | 50.40 | 49.34 ± 1.04 | 31.31 | 30.27 ± 0.94 | 54.63 | 53.74 ± 0.97 |
| | OFASeqInstruct | 50.93 | 50.07 ± 1.07 | 32.28 | 31.23 ± 1.09 | 53.66 | 52.98 ± 0.56 |

**表2：问答和杂项的零样本性能。最佳性能用粗体字表示。**

| 模型 | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
| --- | --- | --- | --- | --- | --- |
| Max | Avg ± Std | Max | Avg ± Std | Max | Avg ± Std |
| OFA | 15.21 | 9.30 ± 5.42 | 0.02 | 0.00 ± 0.01 | 36.31 | 17.62 ± 16.82 |
| OFATaskName | 23.80 | - | 0.00 | - | 36.30 | - |
| OFAMultiInstruct | 27.22 | 26.46 ± 0.83 | 64.32 | 47.22 ± 23.08 | 74.35 | 62.43 ± 11.56 |
| Transfer Learning from NATURAL INSTRUCTIONS | OFANaturalInstruct | 5.59 | 5.40 ± 0.24 | 0.00 | 0.00 ± 0.00 | 5.65 | 1.24 ± 2.48 |
| | OFAMixedInstruct | 24.15 | 23.67 ± 0.47 | 63.79 | 54.99 ± 18.16 | 62.43 | 46.56 ± 14.92 |
| | OFASeqInstruct | 27.03 | 26.67 ± 0.47 | 64.19 | 54.46 ± 15.96 | 71.63 | 60.62 ± 12.31 |</sample>
    <sample id="529">增加多模态指令任务簇的影响

- Img Und
  - VQA + 图像理解
- Grounding
  - 基于语境的匹配 + 基于语境的生成
- MISC, ITM
  - 时间排序 + 随机 + 图像文本匹配
- Relation
  - 视觉关系
- Region
  - 区域理解
- NLP
  - NLP任务

图3：多模态指令任务簇上的模型性能</sample>
    <sample id="530">幻灯片上的英文内容翻译成中文如下：

**不同指令对指令微调的影响**

- OFA在5个指令上进行微调，实现了所有评估任务的更高综合性能，并且显示出更低的敏感性。

表格3：不同数量指令的效果。
OFA_MultiInstruct在不同数量指令上微调的表现。</sample>
    <sample id="531">细调策略对模型敏感性的影响

- 在MultiInstruct上进行指令微调可以显著降低OFA的敏感性。
- 从Natural Instructions数据集进行迁移学习可以进一步降低模型的敏感性。

图4：模型在未见过的评估任务上的敏感性。越低越好。</sample>
    <sample id="532">零样本性能在NLP任务上的表现

- 在MultiInstruct上进行指令微调可以提高在未见过的NLP任务上的零样本性能。
- 转移学习策略MixedInstruct可以最好地保留从Natural Instructions数据集获得的零样本能力。

表格4：NLP任务上的零样本性能。性能以Rouge-L报告，最佳性能用粗体表示。</sample>
    <sample id="533">结论

- 首个大规模多模态指令微调数据集。
  - 包含来自10个广泛类别中的62个多模态任务。
- 通过指令微调显著提高OFA的零样本能力。
- 探索几种迁移学习技术并展示其优势。
- 设计一个新的度量敏感性。</sample>
    <sample id="534">额外一件事！

我们正在收集一个更大的多模态指令微调数据集，包含大约150个额外的视觉-语言任务，并且我们将很快发布它们！</sample>
    <sample id="535">这篇论文的作者所属机构是UNIVERSITÀ DI TRENTO和FONDAZIONE BRUNO KESSLER。</sample>
    <sample id="536">演讲者的名字是Mohammad Javad Hosseini。</sample>
    <sample id="562">语言模型的可接受性判断并不总是对上下文具有鲁棒性</sample>
    <sample id="563">语言模型的可接受性判断并不总是对上下文具有鲁棒性</sample>
    <sample id="564">重新审视最小对偶范式

最小对偶范式（MPP）评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：

BLiMP
1. 许多人在互相帮助。
2. *许多人自己在帮助自己。

P(1) &gt; P(2)

SyntaxGym
1. 没有顾客...已经花过钱。
2. *顾客...已经花过钱。

P(1.any) &gt; P(2.any)

CrowS
1. 典型句子。
2. 非典型句子。

P(1) &gt; P(2)</sample>
    <sample id="565">标题：重新审视最小对偶范式

最小对偶范式（MPP）评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：

BLiMP
1. 许多人在互相帮助。
2. *许多人自己在帮助自己。

P(1) &gt; P(2)

SyntaxGym
1. 没有顾客...已经花过钱。
2. *顾客...已经花过钱。

P(1.any) &gt; P(2.any)

CrowS
1. 典型句子。
2. 非典型句子。

P(1) &gt; P(2)</sample>
    <sample id="566">重新审视最小对偶范式

最小对偶范式（MPP）评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：

BLiMP
1. 许多人在互相帮助。
2. *许多人正在帮助自己。

P(1) &gt; P(2)

SyntaxGym
1. 没有顾客...已经花了一些钱。
2. *顾客...已经花了一些钱。

P(1.any) &gt; P(2.any)

CrowS
1. 典型句子。
2. 非典型句子。

P(1) &gt; P(2)</sample>
    <sample id="567">重新审视最小对偶范式

最小对偶范式（MPP）评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：

BLiMP
1. 许多人在互相帮助。
2. *许多人自己在帮助自己。

P(1) &gt; P(2)

SyntaxGym
1. 没有顾客...已经花了一些钱。
2. *顾客...已经花了一些钱。

P(1.any) &gt; P(2.any)

CrowS
1. 典型句子。
2. 非典型句子。

P(1) &gt; P(2)</sample>
    <sample id="568">重新审视最小对偶范式

最小对偶范式（MPP）评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：

BLiMP
1. 许多人在帮助自己。
2. *许多人正在帮助自己。

P(1) &gt; P(2)

SyntaxGym
1. 没有顾客...已经花过钱。
2. *顾客...已经花过钱。

P(1.any) &gt; P(2.any)

CrowS
1. 女人不擅长手工艺。
2. 男人不擅长手工艺。

P(1) &gt; P(2)

这些判断在长前置语境下稳定吗？</sample>
    <sample id="569">标题：重新审视最小对偶范式

最小对偶范式（MPP）评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：

BLiMP
1. 许多人在互相帮助。
2. *许多人自己在帮助自己。

P(1) &gt; P(2)

SyntaxGym
1. 没有顾客...已经花过钱。
2. *顾客...已经花过钱。

P(1.any) &gt; P(2.any)

CrowS
1. 女人不擅长手工活。
2. 男人不擅长手工活。

P(1) &gt; P(2)

这些判断在长前置语境下稳定吗？</sample>
    <sample id="570">标题：重新审视最小对偶范式

最小对偶范式（MPP）评估语言模型使用序列概率的相对差异来评估语言模型的抽象知识：

BLiMP
1. 许多人在互相帮助。
2. *许多人自己在帮助自己。

P(1) &gt; P(2)

SyntaxGym
1. 没有顾客...已经花过钱。
2. *顾客...已经花过钱。

P(1.any) &gt; P(2.any)

CrowS
1. 女人不擅长手工艺。
2. 男人不擅长手工艺。

P(1) &gt; P(2)

这些判断在长上下文的情况下是否稳定？</sample>
    <sample id="571">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁会在返回这个客户之前逃离？
* 谁会在返回这个客户之前逃离？

什么可以卖给杰西卡在注意到这些聚光灯之前？艾伦在清理博物馆时听起来像什么？谁会在返回这个客户之前逃离？
* 什么可以卖给杰西卡在注意到这些聚光灯之前？艾伦在清理博物馆时听起来像什么？谁会在返回这个客户之前逃离？

BLIMP，附着岛

GPT2, OPT家族 - 125M到6.7B</sample>
    <sample id="572">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁会在返回这个客户之前逃离？
* 谁会在返回这个客户之前逃离？

什么可以卖给杰西卡在注意到这些聚光灯之前？艾伦在清理博物馆时听起来像什么？谁会在返回这个客户之前逃离？
* 什么可以卖给杰西卡在注意到这些聚光灯之前？艾伦在清理博物馆时听起来像什么？谁会在返回这个客户之前逃离？

BLIMP，附着岛

GPT2, OPT家族 - 125M到6.7B</sample>
    <sample id="573">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁会在返回这个客户之前逃离？
* 谁会在返回这个客户之前逃离？

什么可以卖给杰西卡在注意到这些聚光灯之前？艾伦在清理博物馆时听起来像什么？谁会在返回这个客户之前逃离？
* 什么可以卖给杰西卡在注意到这些聚光灯之前？艾伦在清理博物馆时听起来像什么？谁会在返回这个客户之前逃离？

BLIMP，附着岛

GPT2, OPT家族 - 125M到6.7B</sample>
    <sample id="574">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁会在返回这个客户之前逃离？
* 谁会在返回这个客户之前逃离？

什么可以卖给杰西卡在注意到这些聚光灯之前？艾伦在清理博物馆时听起来像什么？谁会在返回这个客户之前逃离？
* 什么可以卖给杰西卡在注意到这些聚光灯之前？艾伦在清理博物馆时听起来像什么？谁会在返回这个客户之前逃离？

BLIMP，附着岛

GPT2, OPT家族 - 125M到6.7B</sample>
    <sample id="575">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁会在返回这个客户之前逃离？
* 谁会在返回这个客户之前逃离？

不可接受，匹配

BLIMP, 附着岛

GPT2, OPT家族 - 125M到6.7B</sample>
    <sample id="576">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁会在返回这个客户之前逃离？
* 谁会在返回这个客户之前逃离？

有一个关于音乐模仿艾莉森的纪录片。没有立法者在努力工作。
谁会在返回这个客户之前逃离？
* 有一个关于音乐困扰艾莉森的纪录片。没有立法者在努力工作。
谁会在返回这个客户之前逃离？

BLIMP，存在“there”量词
BLIMP，附着岛

GPT2, OPT家族 - 125M到6.7B</sample>
    <sample id="577">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁可能在返回这个客户之前逃离？
* 谁可能在这个客户之前逃离？

有一个关于音乐模仿艾莉森的纪录片。没有立法者努力工作。
谁可能在返回这个客户之前逃离？
* 有一个关于音乐模仿艾莉森的纪录片。没有立法者努力工作。
谁可能在返回这个客户之前逃离？

BLIMP，存在“there”量词
BLIMP，附着岛

GPT2, OPT家族 - 125M到6.7B</sample>
    <sample id="578">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁可能在返回给这个客户之前逃离Rose？
* 谁可能在返回给这个客户之前逃离Rose？

* 一种玫瑰是一种木本多年生开花植物，属于蔷薇属。有三百多种物种和数万种栽培品种。
谁可能在返回给这个客户之前逃离Rose？

* 一种玫瑰是一种木本多年生开花植物，属于蔷薇属。有三百多种物种和数万种栽培品种。
谁可能在返回给这个客户之前逃离Rose？

GPT2, OPT家族 - 125M到6.7B</sample>
    <sample id="579">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁可能在返回这个客户之前逃离？
* 谁可能在返回这个客户之前逃离？

维基百科，无关

一朵玫瑰是一种木本多年生开花植物，属于蔷薇属。有三百多种物种和数万种栽培品种。
谁可能在返回这个客户之前逃离？
* 一朵玫瑰是一种木本多年生开花植物，属于蔷薇属。有三百多种物种和数万种栽培品种。
谁可能在返回这个客户之前逃离？

GPT2, OPT家族 - 125M到6.7B</sample>
    <sample id="580">方法

测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试套件：主谓一致

P_LM( | 前缀) &gt; P_LM( | 前缀)

样本

候选前缀空间

匹配
- 主谓一致

不匹配
- 岛效应
- 填空
- 绑定
- 维基百科

谁可能在返回这个客户之前逃离？
* 谁可能在这个客户之前逃离？

维基百科，无关

玫瑰是一种木本多年生开花植物，属于蔷薇属。有三百多种物种和数万种栽培品种。
谁可能在返回这个客户之前逃离？

* 玫瑰是一种木本多年生开花植物，属于蔷薇属。有三百多种物种和数万种栽培品种。
谁可能在返回这个客户之前逃离？</sample>
    <sample id="581">MPP判断对于任意长度的上下文都是稳健的

我们对不同上下文（可接受/不可接受；匹配/不匹配结构）进行MPP评估，长度最多为900个词。

BLiMP, OPT 6.7B

MPP判断对于任意长度的上下文都是稳健的

我们对不同上下文（可接受/不可接受；匹配/不匹配结构）进行MPP评估，长度最多为900个词。

BLiMP, OPT 6.7B

图例：
- 绿色实线：匹配（可接受）
- 蓝色虚线：不匹配（可接受）
- 粉色点线：不匹配（不匹配）

示例：
- 一个玫瑰是一种木质多年生开花植物，属于蔷薇属。有超过三百个物种和数万个栽培品种。
- 谁可能在返回这个客户之前逃离玫瑰？

* 一个玫瑰是一种木质多年生开花植物，属于蔷薇属。有超过三百个物种和数万个栽培品种。
- 谁可能在返回这个客户之前逃离玫瑰？</sample>
    <sample id="582">MPP 判断对于任意长度的上下文都是稳健的

我们对不同上下文（可接受/不可接受；匹配/不匹配结构）进行 MPP 评估，长度最多为 900 个词元。

BLiMP, OPT 6.7B

MPP 判断对于任意长度的上下文都是稳健的

我们对不同上下文（可接受/不可接受；匹配/不匹配结构）进行 MPP 评估，长度最多为 900 个词元。

BLiMP, OPT 6.7B

图中显示了不同上下文策略下的 MPP 评分。</sample>
    <sample id="583">标题：在上下文中可接受/不可接受的MPP句子提高/降低判断性能

我们进行MPP评估，使用不同的上下文——可接受/不可接受；匹配/不匹配结构——长度最多可达900个词元。

BLiMP, OPT 6.7B

图例：
- 绿色实线：匹配（可接受）
- 蓝色虚线：匹配（不可接受）
- 灰色点线：维基（不匹配）
- 橙色实线：不匹配（可接受）
- 粉色虚线：不匹配（不可接受）

示例：
- 可接受（匹配）：有一部关于音乐模仿艾莉森的纪录片。没有立法者在努力工作。罗斯可能会从哪个客户那里逃离回来？
- 不可接受（匹配）：有一部关于音乐模仿艾莉森的纪录片。没有立法者在努力工作。罗斯可能会从哪个客户那里逃离回来？
- 可接受（不匹配）：有一部关于音乐模仿艾莉森的纪录片。大多数立法者在努力工作。罗斯可能会从哪个客户那里逃离回来？
- 不可接受（不匹配）：有一部关于音乐模仿艾莉森的纪录片。大多数立法者在努力工作。罗斯可能会从哪个客户那里逃离回来？</sample>
    <sample id="584">标题：在上下文中可接受/不可接受的MPP句子提高/降低判断性能

我们进行MPP评估，使用不同的上下文——可接受/不可接受；匹配/不匹配结构——长度最多为900个词。

BLiMP, OPT 6.7B

图例：
- 绿色实线：匹配（可接受）
- 蓝色虚线：匹配（不可接受）
- 橙色实线：不匹配（可接受）
- 粉色虚线：不匹配（不可接受）

图中展示了不同策略下，匹配和不匹配结构的可接受和不可接受句子对判断性能的影响。</sample>
    <sample id="585">标题：在上下文中可接受/不可接受的MPP句子提高/降低判断性能

我们进行MPP评估，使用不同的上下文——可接受/不可接受；匹配/不匹配结构——长度最多为900个词。

BLiMP, OPT 6.7B

图例：
- 绿色实线：匹配（可接受）
- 蓝色虚线：匹配（不可接受）
- 橙色实线：不匹配（可接受）
- 粉色虚线：不匹配（不可接受）

图中展示了不同策略下，匹配和不匹配结构的可接受和不可接受句子对判断性能的影响。</sample>
    <sample id="586">可接受/不可接受的MPP句子，结构匹配最严重地影响模型性能

我们进行MPP评估，使用不同的上下文——可接受/不可接受；匹配/不匹配的结构——长度最多可达900个词。

BLiMP, OPT 6.7B</sample>
    <sample id="587">可接受/不可接受的MPP句子，结构匹配最严重地影响模型性能

我们进行MPP评估，使用不同的上下文——可接受/不可接受；匹配/不匹配的结构——长度最多可达900个词。

BLiMP, OPT 6.7B</sample>
    <sample id="588">可接受/不可接受的MPP句子，结构匹配最严重地影响模型性能

我们进行MPP评估，使用不同的上下文——可接受/不可接受；匹配/不匹配的结构——长度最多为900个标记。

BLiMP, OPT 6.7B</sample>
    <sample id="589">为什么匹配的前缀会影响语言模型的判断？

我们以保持相关结构的方式对上下文句子进行扰动，并询问模型是否对这些句子同样敏感。

- 前缀/后缀副词：“然而，&lt;sent&gt;。”
- 长前缀副词：“首先和最重要的是，&lt;sent&gt;。”
- 添加从句：“无论X怎么想，&lt;sent&gt;。”
- 引用：“昨天，X说，‘&lt;sent&gt;’。”</sample>
    <sample id="590">为什么匹配前缀会影响语言模型的判断？

我们以保持相关结构的方式对上下文句子进行扰动，并询问模型是否对这些句子具有类似的敏感性。

- 前缀/后缀副词：“然而，&lt;sent&gt;。”
- 长前缀副词：
  “首先和最重要的是，&lt;sent&gt;。”
- 添加从句：
  “无论X怎么想，&lt;sent&gt;。”
- 引用：
  “昨天，X说，‘&lt;sent&gt;’。”</sample>
    <sample id="591">为什么匹配的前缀会影响语言模型的判断？

我们以保持相关结构的方式对上下文句子进行扰动，并询问模型是否对这些句子具有类似的敏感性。

- 前缀/后缀副词：“然而，&lt;sent&gt;。”
- 长前缀副词：“首先和最重要的是，&lt;sent&gt;。”
- 添加从句：“无论X怎么想，&lt;sent&gt;。”
- 引用：“昨天，X说，‘&lt;sent&gt;’。”

图中显示了不同类型的前缀（可接受和不可接受）在输入长度上的准确性变化。</sample>
    <sample id="592">为什么匹配的前缀会影响语言模型的判断？

我们以保持相关结构的方式对上下文句子进行扰动，并询问模型是否对这些句子具有类似的敏感性。

- 前缀/后缀副词：“然而，&lt;sent&gt;。”
- 长前缀副词：“首先和最重要的是，&lt;sent&gt;。”
- 添加从句：“无论X怎么想，&lt;sent&gt;。”
- 引用：“昨天，X说，‘&lt;sent&gt;’。”

模型对扰动后的句子在相似的方式上具有敏感性。</sample>
    <sample id="593">为什么匹配的前缀会影响LM判断？

我们以保持相关结构的方式对上下文句子进行扰动，并询问模型是否对这些句子具有类似的敏感性。

- 前缀/后缀副词：“然而，&lt;sent&gt;。”
- 长前缀副词：“首先和最重要的是，&lt;sent&gt;。”
- 添加从句：“无论X怎么想，&lt;sent&gt;。”
- 引用：“昨天，X说，‘&lt;sent&gt;’。”

模型对扰动的句子在相似的方式上敏感。</sample>
    <sample id="594">关键收获

- 语言模型对跨句子共享的潜在语法/语义特征敏感。
- MPP评估使用短的、单句输入并不能完全捕捉LMs的抽象知识。</sample>
    <sample id="595">关键收获

- 语言模型对跨句子共享的潜在语法/语义特征敏感。
- MPP评估使用短的、单句输入并不能完全捕捉LMs的抽象知识。</sample>
    <sample id="596">关键收获

- 语言模型对跨句子共享的潜在语法/语义特征敏感。
- MPP评估使用短的、单句输入并不能完全捕捉LMs的抽象知识。</sample>
    <sample id="597">该方法的第一步将输入词元映射到标记（Tag）类型。</sample>
    <sample id="598">Coscript 中包含 55,000 个脚本。</sample>
    <sample id="626">根据图片中的信息，DEplain的最佳对齐方法是使用句子嵌入相似性的层次对齐（LHA）。</sample>
    <sample id="627">弱监督学习的好处是它能缓解注释瓶颈。</sample>
    <sample id="628">DEplain-web 中的文档采用了 481 个训练数据点进行对齐，其中使用了手动对齐（DEplain-web）和自动对齐（DEplain-APA+web）。</sample>
    <sample id="629">CoNLL++ 数据集是通过收集2020年的路透社新闻，并使用CoNLL-2003注释指南进行标注而创建的。</sample>
    <sample id="630">XSemPLR：跨语言语义解析在多种自然语言和意义表示中的应用

Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang

宾夕法尼亚州立大学 Amazon</sample>
    <sample id="631">语义解析

- 语义解析是一个任务，用于构建用户查询的语义表示，例如SQL和Lambda演算。
- 哪些欧洲国家至少有3家汽车制造商？
  SELECT T1.country_name
  FROM countries AS T1 JOIN continents AS T2 ON T1.continent = T2.cont_id
  JOIN car_makers AS T3 ON T1.country_id = T3.country
  WHERE T2.continent = 'Europe'
  GROUP BY T1.country_name
  HAVING COUNT(*) &gt;= 3
- 哪些球员在一赛季中助攻少于三次？
  (call SW.listValue ( call
  SW.getProperty ( ( lambda s ( call
  SW.filter( var s ) ( call
  SW.ensureNumericProperty ( string num_assists ) ) (string &lt; ) ( call
  SW.ensureNumericEntity ( number 3 assist ) ) ) (call SW.domain (
  string player ) ) ) ( string player )
  ) )</sample>
    <sample id="632">跨语言语义解析

跨语言语义解析是一项任务，用于将多种自然语言中的查询转换为多种语义表示。</sample>
    <sample id="633">跨语言语义解析是一个任务，将多种自然语言中的查询转换为多种语义表示。</sample>
    <sample id="634">跨语言语义解析

现有的CLSP模型分别提出并评估在有限的任务和应用数据集上。例如：
- 缺乏某些自然语言的覆盖</sample>
    <sample id="635">跨语言语义解析

- 当前的CLSP模型分别提出并评估在有限的任务和应用数据集上。例如：
  - 缺乏某些自然语言的覆盖</sample>
    <sample id="636">跨语言语义解析

现有的CLSP模型分别提出并评估在有限的任务和应用数据集上。例如：
缺乏某些语义表示的覆盖</sample>
    <sample id="637">跨语言语义解析

现有的CLSP模型分别提出并评估在有限的任务和应用数据集上。例如：
缺乏某些语义表示的覆盖范围

英语
德语
中文
神经模型
SQL
Lambda
FunQL</sample>
    <sample id="638">跨语言语义解析

现有的CLSP模型分别提出并评估在有限的任务和应用数据集上。例如：
- 某些神经模型的覆盖率不足</sample>
    <sample id="639">我们提供了一个统一的数据集XSemPLR，用于跨语言语义解析，在多种自然语言和意义表示中。它包含：
- 9个不同领域的数据集
- 5个语义解析任务
- 8种意义表示
- 22种自然语言在15个语系中</sample>
    <sample id="640">我们提供了一个统一的数据集XSemPLR，用于跨语言语义解析，涵盖多种自然语言和意义表示。它包含：
- 9个不同领域的数据集
- 5种语义解析任务
- 8种意义表示
- 22种自然语言，来自15个语系</sample>
    <sample id="641">实验设置

- 我们考虑了六种训练和评估的设置。
  - Translate-Test: 使用Google翻译API将源语言翻译为目标语言。然后使用单语模型进行训练和评估。

训练
- 英语
- 英语模型
- SQL

推理
- 德语
- 翻译API
- 英语
- 英语模型
- SQL</sample>
    <sample id="642">实验设置

- 我们考虑了六种训练和评估的设置。
  - Translate-Test: 使用Google翻译API将源语言翻译为目标语言。然后使用单语模型进行训练和评估。

训练
- 英语
- 英语模型
- SQL

推理
- 德语
- 翻译API
- 英语
- 英语模型
- SQL</sample>
    <sample id="643">实验设置

- 我们考虑了六种训练和评估的设置。
  - Translate-Test: 使用Google翻译API将源语言翻译为目标语言，然后使用单语言模型进行训练和评估。

训练
- 英语
- 英语模型
- SQL

推理
- 德语
- 翻译API
- 英语
- 英语模型
- SQL</sample>
    <sample id="644">实验设置

- 我们考虑了六种训练和评估的设置。
  o 单语模型：源语言与目标语言相同，例如德语到德语。我们还测试了单语少量数据设置，通过使用仅10%的训练数据来训练单语模型。

训练
![训练流程图](https://i.imgur.com/3Q5z5QG.png)

推理
![推理流程图](https://i.imgur.com/3Q5z5QG.png)</sample>
    <sample id="645">实验设置

- 我们考虑了六种训练和评估的设置。
  - 单语模型：源语言与目标语言相同，例如德语到德语。我们还测试了单语少样本设置，通过使用仅10%的训练数据来训练单语模型。

训练
![训练流程图](https://i.imgur.com/3Q5z5QG.png)

推理
![推理流程图](https://i.imgur.com/3Q5z5QG.png)</sample>
    <sample id="646">实验设置

- 我们考虑了六种训练和评估的设置。
  - 单语模型：源语言与目标语言相同，例如德语到德语。我们还测试了单语少样本设置，通过使用仅10%的训练数据来训练单语模型。

训练
- 德语（少样本）
- 德语模型
- SQL

推理
- 德语
- 德语模型
- SQL</sample>
    <sample id="647">实验设置

- 我们考虑了六种训练和评估的设置。
  o 多语言模型：为所有语言训练一个统一的多语言模型。

训练
- 德语
- 英语
- 中文
- 多语言模型
- SQL

推理
- 德语
- 多语言模型
- SQL</sample>
    <sample id="648">实验设置

- 我们考虑了六种训练和评估的设置。
  o 多语言模型：为所有语言训练一个统一的多语言模型。

训练
- 德语
- 英语
- 中文
- 多语言模型
- SQL

推理
- 德语
- 多语言模型
- SQL</sample>
    <sample id="649">实验设置

- 我们考虑了六种训练和评估的设置。
  o 多语言模型：为所有语言训练一个统一的多语言模型。

训练
- 德语
- 英语
- 中文
- 多语言模型
- SQL

推理
- 德语
- 多语言模型
- SQL</sample>
    <sample id="650">实验设置

- 我们考虑了六种训练和评估的设置。
  o 多语言零样本/少样本迁移：在一种源语言上进行训练，然后迁移到另一种语言。

训练
- 英语
- 或者
- 英语
- 德语少量样本
- 多语言模型
- SQL

推理
- 德语
- 多语言模型
- SQL</sample>
    <sample id="651">实验设置

- 我们考虑了六种训练和评估的设置。
  o 多语言零样本/少量样本迁移：在一种源语言上进行训练，然后迁移到另一种语言。

训练
- 英语
- 或者
- 英语
- 德语少量样本
- 多语言模型
- SQL

推理
- 德语
- 多语言模型
- SQL</sample>
    <sample id="652">单语分析

- 我们在单语设置下评估了两组模型。
  - Enc-PTR：带有指针式解码器的多语言预训练编码器
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec：多语言预训练编码-解码器模型
    - mBART, mT5

- 我们发现Enc-Dec（mT5）在所有数据集上获得了最佳性能！</sample>
    <sample id="653">分析单语模型

- 我们在单语设置下评估了两组模型
  - Enc-PTR：带有指针式解码器的多语言预训练编码器
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec：多语言预训练编码-解码器模型
    - mBART, mT5

- 我们发现Enc-Dec（mT5）在所有数据集上获得了最佳性能！</sample>
    <sample id="654">单语分析

- 我们在单语设置中评估了两组模型
  - Enc-PTR: 多语言预训练编码器与指针式解码器
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: 多语言预训练编码器-解码器模型
    - mBART, mT5

- 我们发现Enc-Dec（mT5）在所有数据集上获得了最佳性能！</sample>
    <sample id="655">单语分析

- 我们在单语设置下评估了两组模型
  - Enc-PTR: 多语言预训练编码器与指针式解码器
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: 多语言预训练编码器-解码器模型
    - mBART, mT5

- 我们发现Enc-Dec（mT5）在所有数据集上都取得了最佳性能！</sample>
    <sample id="656">多语言训练分析

- 我们在多语言设置中对 mT5 和 XLM-R + PTR 进行评估
  - Enc-Dec/Enc-PTR（mT5/XLM-R）可以通过在多种语言的混合中进行训练来改进。

表格内容：
| 多语言 |
| --- |
| MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa² |
| XLM-R+PTR | 31.31 | 71.41 | 47.30 | 85.17 | 59.10 | 23.53 | 62.37 | 80.36 | 7.69 | 52.03 |
| mT5 | 53.15 | 74.26 | 50.73 | 91.65 | 66.29 | 30.15 | 65.16 | 81.83 | 10.29 | 58.16 |

| 多语言 |
| --- |
| XLM-R+PTR | 39.72 | 71.35 | 40.20 | 85.91 | 61.03 | 30.79 | 61.82 | 81.68 | – | 59.06 |
| mT5 | 54.45 | 76.57 | 32.30 | 91.31 | 67.55 | 28.51 | 60.92 | 82.95 | – | 61.82 |

平均值：
- XLM-R+PTR: 52.03
- mT5: 58.16
- XLM-R+PTR (多语言): 59.06
- mT5 (多语言): 61.82</sample>
    <sample id="657">多语言训练分析

- 我们在多语言设置中对 mT5 和 XLM-R + PTR 进行评估
  - Enc-Dec/Enc-PTR (mT5/XLM-R) 可以通过在多种语言的混合中进行训练得到改进。

表格：
| 多语言 |
| --- |
| MATIS | MGeoQuery | MSpider | MNLmaps | MOvernight | MCWQ | MSchema2QA | MTOP | MCoNaLa² |
| XLM-R+PTR | 31.31 | 71.41 | 47.30 | 85.17 | 59.10 | 23.53 | 62.37 | 80.36 | 7.69 | 52.03 |
| mT5 | 53.15 | 74.26 | 50.73 | 91.65 | 66.29 | 30.15 | 65.16 | 81.83 | 10.29 | 58.16 |

| 多语言 |
| --- |
| XLM-R+PTR | 39.72 | 71.35 | 40.20 | 85.91 | 61.03 | 30.79 | 61.82 | 81.68 | – | 59.06 |
| mT5 | 54.45 | 76.57 | 32.30 | 91.31 | 67.55 | 28.51 | 60.92 | 82.95 | – | 61.82 |

平均值：
- XLM-R+PTR: 52.03
- mT5: 58.16</sample>
    <sample id="658">多语言训练分析

- 我们在多语言设置中对 mT5 和 XLM-R + PTR 进行评估
  - 大多数主要的语言可以取得性能提升，除了英语在7个数据集中的表现下降，在3个数据集中表现提升。这被称为“多语言诅咒”</sample>
    <sample id="659">多语言训练分析

- 我们在多语言设置中对 mT5 和 XLM-R + PTR 进行评估
  - 大多数主要的语言可以取得性能提升，除了英语在7个数据集中的表现下降，在3个数据集中表现提升。这被称为“多语言诅咒”</sample>
    <sample id="660">图中的英文内容翻译成中文如下：

跨语言性能差距

- 蓝色线：跨语言少样本迁移
- 橙色线：跨语言零样本迁移
- 绿色线：单语言设置</sample>
    <sample id="661">跨语言性能差距

- 蓝色线条：跨语言少样本迁移
- 橙色线条：跨语言零样本迁移
- 绿色线条：单语言设置</sample>
    <sample id="662">跨语言性能差距

- 绿色 - 橙色：在零样本设置中，跨语言迁移性能差距显著
- 蓝色 - 橙色：在少量样本设置中，迁移差距迅速缩短</sample>
    <sample id="663">其他结果与发现（论文第4部分）

- Enc-Dec (mT5) 在之前的工作中表现出色或达到可比的结果。
- 在英语NL上进行预训练可以显著提升在目标NL上的few-shot性能。
- 多语言LLMs（Codex &amp; BLOOM）在跨语言语义解析任务中仍然不足。
- 中文迁移学习和英语单语训练（En -&gt; En）具有最大的性能差距，而德语通常具有最小的差距。
- FunQL 出色地超过了其他三种意义表示方式，而SQL获得最差的表现。</sample>
    <sample id="664">其他结果与发现（论文第4部分）

- Enc-Dec (mT5) 在之前的工作中表现出色或达到可比的结果。
- 在英语NL上进行预训练可以显著提升目标NL上的少量样本性能。
- 多语言LLMs（Codex &amp; BLOOM）在跨语言语义解析任务中仍然不足。
- 中文迁移学习和英语单语训练（En -&gt; En）具有最大的性能差距，而德语通常具有最小的差距。
- FunQL 出色地超过了其他三种语义表示方法，而 SQL 获得最差的表现。</sample>
    <sample id="665">结论

- 我们构建了XSemPLR，一个统一的跨语言语义解析基准，适用于多种自然语言和意义表示。
- 我们对三种代表性的多语言模型进行了全面的基准研究。
- 我们的实验结果表明，mT5在单语训练下表现最佳，而显著的多语言LLMs仍然不足以完成跨语言语义解析任务。此外，单语训练与跨语言迁移学习之间的性能差距仍然显著。</sample>
    <sample id="666">结论

- 我们构建了XSemPLR，一个统一的跨语言语义解析基准，适用于多种自然语言和意义表示。
- 我们对三种代表性的多语言模型进行了全面的基准研究。
- 我们的实验结果表明，mT5在单语训练下表现最佳，而显著的多语言LLMs仍然不足以完成跨语言语义解析任务。此外，单语训练与跨语言迁移学习之间的性能差距仍然显著。

链接

欢迎访问我们的论文和代码！

论文链接：https://arxiv.org/pdf/2306.04085.pdf
代码链接：https://github.com/psunlpgroup/xsemplr</sample>
    <sample id="667">关于这方面的现有研究包括参数基水印、词基水印、后门基水印和对抗基水印。</sample>
    <sample id="668">不足够。</sample>
    <sample id="695">该方法通过在训练过程中诱导排列来处理排列的不确定性。</sample>
    <sample id="696">下游 NLP 模型的公平性是指模型在处理不同政治倾向的数据时，其输出结果的一致性和公正性。</sample>
    <sample id="697">演讲者的名字是Yanis Labrak。</sample>
    <sample id="698">演讲者的名字是Koustuv Sinha。</sample>
    <sample id="699">演讲者的名字是Myra Cheng。</sample>
    <sample id="700">在本文的背景下，热带主义意味着通过本质化叙事来他者化，即通过文化、传统、骄傲和异国情调等词语来定义被标记群体，从而将这些群体仅限于他们的身份。</sample>
    <sample id="701">作者通过使用“文化”、“传统”、“骄傲”和“异国情调”等词汇来定义目标群体，从而创建了对这些群体的人工描写。这些词汇不仅描述了群体的文化背景和身份特征，还强调了他们的独特性和差异性。这种做法被称为“本质化叙事”，它将群体仅定义为他们的身份，而不是作为一个整体或个体进行描述。</sample>
    <sample id="702">本文中使用了P-CXMI（Pointwise Contextualized Mutual Information）来衡量语境使用情况。</sample>
    <sample id="703">DrBERT 和 ChuBERT 都是从零开始训练的模型。</sample>
    <sample id="751">这篇论文有三位作者。</sample>
    <sample id="752">迭代迁移学习（Iterative Transfer Learning）是一种在每次迭代中对模型进行微调的方法。它通过将新数据与旧数据相结合，并使用这些数据来更新模型，从而逐步改进模型性能。这种方法特别适用于处理稀有类别的标注问题，因为它允许模型在每次迭代中都从新数据中学习，从而提高对稀有类别的识别能力。</sample>
    <sample id="753">数据集的目标是理解用户在做出选择时的语言。</sample>
    <sample id="754">攻击者可以通过 EaaS（Extraction as a Service）来提取模型参数。EaaS 是一种服务模式，允许用户将数据提取任务外包给第三方服务提供商。在这种情况下，攻击者可以利用 EaaS 服务来获取目标模型的参数信息。</sample>
    <sample id="755">这篇论文有三位作者。</sample>
    <sample id="756">根据图片中的信息，创建初始数据集的注释者数量没有明确说明。图片中提到的是使用了RoBERTA-base + classifier head进行训练，并且提到了Debate和CE两个数据集，但并没有具体说明创建这些数据集的注释者数量。因此，无法从图片中直接得出有多少个注释者用于创建初始数据集。</sample>
    <sample id="757">这篇论文的作者所属机构包括University of Washington、Carnegie Mellon University和Allen Institute for AI。</sample>
    <sample id="758">以左侧为支配词的示例是"I saw Bart and Lisa; Homer came and sneezed"。</sample>
    <sample id="759">根据图片中的信息，对话系统中的最先进模型是ABC-Eval。</sample>
    <sample id="760">为了确保模型在长上下文中也能保持其判断的稳定性。</sample>
    <sample id="761">是的，多语言训练会导致表现下降。具体来说，英语在7个数据集中表现下降，在3个数据集中表现上升。这种现象被称为“多语言诅咒”。</sample>
    <sample id="762">否。</sample>
    <sample id="763">根据图片中的信息，没有提到具体的MT（机器翻译）指标。图片展示的是一个关于翻译示例的幻灯片，包含了一些德语和英语的句子对，但并没有提及任何评估指标。因此，无法从这张图片中得出使用了哪些MT指标的信息。</sample>
    <sample id="764">根据图片中的信息，泛化能力与模型架构和模型大小有关。Transformer模型在泛化方面表现更好，并且更大的模型通常具有更好的泛化能力。然而，图片中并没有提到泛化中的回归是否会影响特定的NER类型。因此，无法从图片中得出泛化中的回归是否会影响特定的NER类型的结论。</sample>
    <sample id="765">在自然语言处理（NLP）中，立场非常重要，因为它直接影响了模型对文本的理解和反应。不同的立场会导致模型对同一文本产生不同的解读和输出结果。例如，在一个关于“停止成为混蛋”的请求中，如果立场是正面的，模型可能会认为这是一个积极的建议；但如果立场是负面的，模型可能会将其视为攻击性的言论。这种差异性反映了立场在NLP中的重要性，因为它能够影响模型的输出结果和应用效果。因此，理解并考虑立场对于构建准确、可靠且具有包容性的NLP系统至关重要。</sample>
    <sample id="766">根据图片中的信息，Cross-lingual Semantic Parsing 是一种任务，它将多种自然语言中的查询翻译成多种语义表示。然而，图片中并没有提到像 BLOOM 这样的多语言 LLM 的微调方式。因此，无法从图片中得出关于 BLOOM 采用哪种微调方式的信息。</sample>
    <sample id="767">他们使用的是RoBERTA-base模型加上分类器头部进行迁移学习。</sample>
    <sample id="768">最近用于评估 PaLM 能力的测试集包括：1) 5-shot prompting；2) 多语言翻译；3) 多模态理解。</sample>
    <sample id="769">根据图片中的内容，作者提出了三条建议。</sample>
    <sample id="770">与最强的基线相比，提议的方法获得了26.25%的收益。</sample>
    <sample id="771">演讲者的名字是Shuheng Liu和Alan Ritter。</sample>
    <sample id="772">论文中的结果和数据集可以作为基准。</sample>
    <sample id="773">他们进行了三个较小模型的实验。</sample>
    <sample id="774">OFA（One For All）模型被用作研究多模型指令调整的基础模型。</sample>
    <sample id="833">这篇论文的作者所属机构是Google。</sample>
    <sample id="834">这篇论文的作者所属机构是Stony Brook University。</sample>
    <sample id="835">论文没有具体提到分析了哪些特定的语言对。它主要讨论了LLM（大型语言模型）提示在机器翻译（MT）中的应用，并提到了评估翻译能力时使用了MT社区的最佳实践，包括最新的测试集、与最近的WMT提交进行比较（SOTA系统使用最新训练数据）、SOTA MT指标（更好地与人类判断相关联）以及专家基于的人类评估（比众包更可靠）。这些内容表明，论文可能涉及多种语言对，但没有明确列出具体的语言对。</sample>
    <sample id="836">演讲者的名字是Shangbin Feng。</sample>
    <sample id="837">在实验过程中研究了DEplain-APA、DEplain-web、DEplain-APA+web和src2src-baseline这四个模型。</sample>
    <sample id="838">在 MultiInstruct 中使用的 62 个不同任务中，53 个任务用于训练，9 个任务用于测试。</sample>
    <sample id="839">这篇论文有三位作者。</sample>
    <sample id="840">作者在实验中使用了AG News、MIND、SST2和Enron Spam这四个数据集。</sample>
    <sample id="876">NACHOS 是一种语言模型。</sample>
    <sample id="877">演讲者的名字是David Vilar Torres、Markus Freitag、Colin Cherry、Jiaming Luo、Viresh Ratnakar和George Foster。</sample>
    <sample id="878">提示策略对翻译质量有重大影响。</sample>
    <sample id="879">这篇论文的作者所属机构包括Carnegie Mellon University Language Technologies Institute、TÉCNICO LISBOA、BAIR Berkeley Artificial Intelligence Research和Unbabel。</sample>
    <sample id="880">抱歉，您提供的图片内容中并未包含关于“5个由专家编写的指令”的信息。图片中的文字主要讲述了关于一个更大的多模态指令调优数据集的信息，并没有提到任何具体的指令或专家编写的内容。如果您有关于这个数据集的问题，我会很乐意帮助解答。</sample>
    <sample id="881">作者建议通过使用来自多种来源的信息来测试模型，包括预训练知识和推理时间知识。</sample>
    <sample id="882">谷歌
PaLM 用于翻译的提示策略评估与性能

ACL 2023</sample>
    <sample id="883">PaLM：路径语言模型

- Chowdery等人，2022年
  arXiv:2204.02311.
- 参数540亿。
- 训练了780B个标记。
- 密集激活。
- 使用6144个TPU v4芯片。
- 在数百个LMU和生成基准中达到SOTA水平。</sample>
    <sample id="884">PaLM：路径语言模型

- Chowdery等人，2022年
  arXiv:2204.02311。
- 参数540亿个。
- 在7800亿个标记上训练。
- 密集激活。
- 使用6144个TPU v4芯片。
- 在数百个LMU和生成基准中处于SOTA水平。</sample>
    <sample id="885">我们的贡献

- 首次系统性研究LLM提示在MT中的应用。
  - 适用于候选池和选择策略。

- 以MT社区的最佳实践评估翻译能力：
  - 最新的测试集（避免测试/训练重叠，并防止在评估数据上过拟合）。
  - 与最近的WMT提交进行比较（SOTA系统使用最新的训练数据）。
  - SOTA MT指标（与人类判断有更好的相关性）。
  - 专家基于的人类评估（比众包更可靠）。

- 推荐提示选择策略</sample>
    <sample id="886">我们的贡献

- 首次系统性研究LLM提示在MT中的应用。
  - 适用于候选池以及选择策略。

- 以MT社区的最佳实践评估翻译能力：
  - 最新的测试集（避免测试/训练数据重叠和在评估数据上的过拟合）。
  - 与最近的WMT提交进行比较（SOTA系统使用最新的训练数据）。
  - SOTA MT指标（更好地与人类判断相关联）。
  - 专家基于的人类评估（比众包更可靠）。

- 推荐提示选择策略</sample>
    <sample id="887">我们的贡献

- 首次系统性研究LLM提示在MT中的应用。
  - 适用于候选池以及选择策略。

- 以MT社区的最佳实践评估翻译能力：
  - 最新的测试集（避免测试/训练数据重叠和在评估数据上的过拟合）。
  - 与最近的WMT提交进行比较（SOTA系统使用最新训练数据）。
  - SOTA MT指标（更好地与人类判断相关联）。
  - 专家基于的人类评估（比众包更可靠）。

- 推荐提示选择策略</sample>
    <sample id="888">我们的贡献

- 首次系统性研究LLM提示在MT中的应用。
  - 适用于候选池和选择策略。

- 以MT社区的最佳实践评估翻译能力：
  - 最新的测试集（避免测试/训练重叠，防止在评估数据上过拟合）。
  - 与最近的WMT提交进行比较（SOTA系统使用最新训练数据）。
  - SOTA MT指标（更好地与人类判断相关联）。
  - 专家基于的人类评估（比众包更可靠）。

- 推荐提示选择策略</sample>
    <sample id="889">提示对翻译质量有很大影响

- 为每个句子选择两个随机的提示。
- 对每个句子-提示对计算BLEURT分数。
- 大多数句子（516个中的1000个）显示出超过1个BLEURT点的差异。
- 差异可以达到40个BLEURT点！</sample>
    <sample id="890">提示对翻译质量有很大影响

- 为每个句子选择两个随机提示。
- 计算每个句子-提示对的BLEURT值。
- 大多数句子（1000个中的516个）显示出超过1个BLEURT点的差异。
- 差异可以达到40个BLEURT点！</sample>
    <sample id="891">提示对翻译质量有很大影响

- 为每个句子选择两个随机提示。
- 计算每个句子-提示对的BLEURT值。
- 大多数句子（516/1000）显示出超过1个BLEURT点的差异。
- 差异可以达到40个BLEURT点！</sample>
    <sample id="892">当然，以下是英文内容的中文翻译：

1. 德语：Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   英语：He is being transported under the custody of two policemen on a bus from the jail.

2. 德语：Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   英语：Police were called in after receiving complaints from the office.

3. 德语：Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   英语：A passerby alerted the police, who arrived with several patrols.</sample>
    <sample id="893">当然，以下是英文内容的中文翻译：

1. German: Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   English: He is being transported under the custody of two policemen on a bus from the jail.

2. German: Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   English: Police were called in after receiving complaints from the office.

3. German: Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   English: A passerby alerted the police, who arrived with several patrols.</sample>
    <sample id="894">当然，以下是英文内容的中文翻译：

1. German: Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   English: He is being transported under the custody of two policemen on a bus from the jail.

2. German: Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   English: Police were called in after receiving complaints from the office.

3. German: Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   English: A passerby alerted the police, who arrived with several patrols.</sample>
    <sample id="895">当然，以下是英文内容的中文翻译：

1. 德语：Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   英语：He is being transported under the custody of two policemen on a bus from the jail.

2. 德语：Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   英语：Police were called in after receiving complaints from the office.

3. 德语：Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   英语：A passerby alerted the police, who arrived with several patrols.</sample>
    <sample id="896">当然，以下是英文内容的中文翻译：

1. German: Dort sieht man, wie sie von zwei Police-Officers in einen Streifenwagen gesetzt wird.
   English: He is being transported under the custody of two policemen on a bus from the jail.

2. German: Ski-Legenden unter sich: Die Polizei war eingeschritten, nachdem sie Beschwerden des Büros erhalten hatte.
   English: Police were called in after receiving complaints from the office.

3. German: Ein Passant alarmierte die Polizei, die mit mehreren Streifen anrückte.
   English: A passerby alerted the police, who arrived with several patrol units.</sample>
    <sample id="897">实验结果

- 例子的质量比与源句子的相似性更重要。
- 专门化的SOTA系统有显著的优势。
- PaLM接近于Google Translate。

MQM的见解：
- PaLM的流畅度与SOTA相当。
- 准确率分数通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/生硬”对PaLM来说通常较低。</sample>
    <sample id="898">实验结果

- 例子的质量比与源句子的相似性更重要。
- 专门化的SOTA系统有显著的优势。
- PaLM接近于Google Translate。

MQM的见解：
- PaLM的流畅度与SOTA相当。
- 准确率分数通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/生硬”通常对PaLM更低。</sample>
    <sample id="899">实验结果

- 例子的质量比与源句子的相似性更重要。
- 专门化的SOTA系统有显著的优势。
- PaLM接近于Google Translate。

MQM的见解：
- PaLM的流畅度与SOTA相当。
- 准确率分数通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/生硬”通常对PaLM更低。</sample>
    <sample id="900">实验结果

- 例子的质量比与源句子的相似性更重要。
- 专门化的SOTA系统有显著的优势。
- PaLM接近于Google Translate。

MQM的见解：
- PaLM的流畅度与SOTA相当。
- 准确率分数通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/生硬”对PaLM来说通常较低。</sample>
    <sample id="901">实验结果

- 例子的质量比与源句子的相似性更重要。
- 专门化的SOTA系统有显著的优势。
- PaLM接近于Google Translate。

MQM的见解：
- PaLM的流畅度与SOTA相当。
- 准确率分数通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/生硬”通常对PaLM更低。</sample>
    <sample id="902">实验结果

- 例子的质量比与源句子的相似性更重要。
- 专门化的SOTA系统有显著的优势。
- PaLM接近于Google Translate。

MQM的见解：
- PaLM的流畅度与SOTA相当。
- 准确率分数通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/生硬”对PaLM来说通常较低。</sample>
    <sample id="903">实验结果

- 例子的质量比与源句子的相似性更重要。
- 专门化的SOTA系统有显著的优势。
- PaLM接近于Google Translate。

MQM的见解：
- PaLM的流畅度与SOTA相当。
- 准确率分数通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/生硬”分数通常较低对于PaLM。</sample>
    <sample id="904">实验结果

- 例子的质量比与源句子的相似性更重要。
- 专门化的SOTA系统有显著的优势。
- PaLM接近于Google Translate。

MQM的见解：
- PaLM的流畅度与SOTA相当。
- 准确率分数通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/生硬”对PaLM来说通常较低。</sample>
    <sample id="905">实验结果

- 例子的质量比与源句子的相似性更重要。
- 专门化的SOTA系统有显著的优势。
- PaLM接近于Google Translate。

MQM的见解：
- PaLM的流畅度与SOTA相当。
- 准确率分数通常较低。
  - 主要受“准确性/遗漏”影响
- “风格/生硬”对PaLM来说通常较低。</sample>
    <sample id="906">图片中的英文内容是“thank you”，翻译成中文是“谢谢”。</sample>
    <sample id="907">图片中的英文内容翻译成中文如下：

---

**弱于你想象**
**对弱监督学习的批判性审视**

Dawei Zhu1  Xiaoyu Shen2  Marius Mosbach1  Andreas Stephan3  Dietrich Klakow1

1 沙尔克大学 2 Amazon Alexa 3 维也纳大学

61 ACL 2023

---

请注意，图片中显示的头像和相关信息是实际演讲者的真实姓名和所属机构，但为了保护隐私，我无法提供这些人的具体身份信息。</sample>
    <sample id="908">图片中的英文内容翻译成中文如下：

---

**弱于你想象**
**对弱监督学习的批判性审视**

Dawei Zhu1  Xiaoyu Shen2  Marius Mosbach1  Andreas Stephan3  Dietrich Klakow1

1 沙尔克大学 2 Amazon Alexa 3 维也纳大学

61 ACL 2023

---</sample>
    <sample id="909">为什么使用弱监督学习？

- 弱监督缓解了注释瓶颈。
- 但是弱标签是嘈杂的！
  - 噪声记忆会损害泛化能力。
- 弱监督学习（WSL）
  - 即使在嘈杂数据上训练，也能训练出泛化能力强的模型。</sample>
    <sample id="910">为什么使用弱监督学习？

- 弱监督缓解了注释瓶颈。
- 但是弱标签是嘈杂的！
  - 噪声记忆会损害泛化能力。
- 弱监督学习（WSL）
  - 尽管在嘈杂数据上训练，仍能训练出泛化能力强的模型。</sample>
    <sample id="911">为什么使用弱监督学习？

- 弱监督缓解了标注瓶颈。
- 但是弱标签是嘈杂的！
  - 噪声记忆会损害泛化能力。
- 弱监督学习（WSL）
  - 尽管在嘈杂数据上训练，仍能训练出泛化能力强的模型。</sample>
    <sample id="912">为什么使用弱监督学习？

- 弱监督缓解了标注瓶颈。
- 但是弱标签是嘈杂的！
  - 噪声记忆会损害泛化能力。
- 弱监督学习（WSL）
  - 即使在嘈杂数据上训练，也能训练出泛化能力强的模型。</sample>
    <sample id="913">为什么使用弱监督学习？

- 弱监督缓解了注释瓶颈。
- 但是弱标签是嘈杂的！
  - 噪声记忆会损害泛化能力。
- 弱监督学习（WSL）
  - 尽管在嘈杂数据上训练，仍能训练出泛化能力强的模型。</sample>
    <sample id="914">最近WSL工作的常见说法

“我们仅在弱监督数据上训练模型，并且达到XX%的准确率。”</sample>
    <sample id="915">最近WSL工作的常见声明

“我们仅在弱监督数据上训练模型，并且达到XX%的准确率。”</sample>
    <sample id="916">最近WSL工作的常见说法

“我们仅在弱监督数据上训练模型，并且达到XX%的准确率。”

弱标注训练数据（嘈杂）
干净标注验证数据（干净）
干净标注测试数据（干净）</sample>
    <sample id="917">最近WSL工作的常见说法

“我们仅在弱监督数据上训练模型，并且达到XX%的准确率。”

弱标注训练数据（嘈杂）
干净标注验证数据（干净）
干净标注测试数据（干净）</sample>
    <sample id="918">我们的研究问题

RQ1：是否需要干净的验证数据？

RQ2：WSL方法需要多少干净样本？

RQ3：如何更有效地使用可用的干净样本？</sample>
    <sample id="919">我们的研究问题

RQ1：是否需要干净的验证数据？

RQ2：WSL方法需要多少干净样本？

RQ3：如何更有效地利用可用的干净样本？</sample>
    <sample id="920">RQ1 主要发现

图中展示了在不同验证策略下，相对弱标签性能改进的百分比。标记为“在弱标签上验证”的数据点显示了最高的性能改进，而“无验证（随机选择）”的数据点则显示出较低的改进。标记为“在干净标签上验证”的数据点也表现出较高的性能改进。</sample>
    <sample id="921">RQ1 主要发现

图中展示了在不同验证策略下，相对弱标签性能改进的百分比。标记为橙色的点表示在弱标签上进行验证的情况；标记为蓝色的点表示没有验证（随机选择）的情况；标记为绿色的点表示在干净标签上进行验证的情况。

横轴代表不同的方法：FTW、BOND、COSINE、MLC 和 L2R。
纵轴表示相对弱标签性能改进的百分比（%）。</sample>
    <sample id="922">RQ1 主要发现

图中展示了在不同验证策略下，相对弱标签性能改进的百分比。具体来说：

- 橙色圆圈表示在弱标签上进行验证。
- 蓝色圆圈表示没有验证（随机选择）。
- 绿色圆圈表示在干净标签上进行验证。

横轴代表不同的方法：FTW、BOND、COSINE、MLC 和 L2R。纵轴表示相对弱标签性能改进的百分比。</sample>
    <sample id="923">RQ1 主要发现

图中展示了在不同验证策略下，模型性能相对于弱标签的相对改进百分比。具体来说：

- 橙色圆圈表示在弱标签上进行验证。
- 蓝色圆圈表示没有验证（随机选择）。
- 绿色圆圈表示在干净标签上进行验证。

从图中可以看出，在某些情况下，验证策略对模型性能有显著的提升，而在其他情况下则效果不佳。</sample>
    <sample id="924">主要发现

RQ1 主要发现

→ 清洁验证集是不可或缺的。</sample>
    <sample id="925">RQ2 主要发现

图中显示了不同验证集大小（5、10、20、30、40、50 和 All）下，各种方法的准确率。具体来说：

- FT_w 方法在所有验证集大小下的准确率最高。
- COSINE 方法的准确率随着验证集大小的增加而逐渐提高。
- L2R 方法的准确率相对较低，但随着验证集大小的增加，其准确率也有所提升。
- BOND 方法的准确率在所有验证集大小下都较高。
- MLC 方法的准确率在所有验证集大小下都较低。

虚线表示弱标签的准确率。</sample>
    <sample id="926">RQ2 主要发现

图中显示了不同方法在验证集上的准确率随验证集大小的变化情况。具体来说，FT_w、COSINE、L2R、BOND和MLC五种方法的准确率随着验证集大小的增加而逐渐提高。其中，BOND方法的准确率最高，其次是COSINE和MLC方法。L2R方法的准确率相对较低。所有方法的准确率都超过了75%，并且在验证集为“全”时，所有方法的准确率都达到了80%以上。</sample>
    <sample id="927">主要发现

RQ2 主要发现

WSL方法从更多的干净验证样本中受益！

左侧图表显示了不同验证样本数量下，各种WSL方法的准确率。右侧图表展示了不同WSL方法在不同验证样本数量下的性能变化。

左侧图表中的关键点：
- 随着验证样本数量的增加，所有WSL方法的准确率都有所提高。
- FT_w、COSINE、L2R、BOND和MLC等方法的准确率随着验证样本数量的增加而逐渐上升。
- 弱标签（Weak labels）作为参考线，表明其他方法的准确率高于弱标签。

右侧图表中的关键点：
- 不同WSL方法在不同验证样本数量下的性能变化。
- FT_C、LoRA_C、BitFit_C和Adapter_C等方法在不同验证样本数量下的性能变化情况。
- 红色虚线框内表示性能变化范围，表明这些方法在某些验证样本数量下表现出更好的性能。</sample>
    <sample id="928">主要发现

WSL方法从更多的干净验证样本中受益！</sample>
    <sample id="929">主要发现

RQ2 主要发现

WSL方法从更多的干净验证样本中受益！

→ 但它们甚至更适合用于训练（例如，LoRAc）！</sample>
    <sample id="930">RQ3 主要发现

N=10 每类干净样本
88
86
84
82
80
78
Before
CFT
After
CFT
Accuracy/F1

N=30 每类干净样本
90
88
86
84
82
80
78
Before
CFT
After
CFT
Accuracy/F1

COSINE
L2R
FTw
Clean Only</sample>
    <sample id="931">RQ3 主要发现

N=10 每类干净样本
在 CFT 之前和之后的准确率/召回率

N=30 每类干净样本
在 CFT 之前和之后的准确率/召回率</sample>
    <sample id="932">RQ3 主要发现

N=10 每类干净样本
88
86
84
82
80
78
Accuracy/F1
Before
CFT
After
CFT

N=30 每类干净样本
90
88
86
84
82
80
Accuracy/F1
Before
CFT
After
CFT
COSINE
L2R
FTw
Clean Only</sample>
    <sample id="933">主要发现

RQ3 主要发现

N=10 每个类别 10 个干净样本

N=30 每个类别 30 个干净样本

→ 连续微调（CFT）消除 WSL 方法之间的性能差距。

→ 不需要使用复杂的 WSL 方法
(FTW 表现同样出色)。</sample>
    <sample id="934">结论

最近的WSL方法
- 需要干净的数据样本。
- 过高估计了它们的实际应用性。

我们的建议
- 报告模型选择标准。
- 使用少样本学习方法作为基线。
- 总是应用连续微调（CFT）。</sample>
    <sample id="935">结论

最近的WSL方法
- 需要干净的数据样本。
- 过高估计了它们的实际应用性。

我们的建议
- 报告模型选择标准。
- 使用少量样本学习方法作为基线。
- 总是应用连续微调（CFT）。</sample>
    <sample id="936">结论

最近的WSL方法
- 需要干净的数据样本。
- 过高估计了它们的实际应用性。

我们的建议
- 报告模型选择标准。
- 使用少样本学习方法作为基线。
- 总是应用连续微调（CFT）。</sample>
    <sample id="937">结论

最近的WSL方法
- 需要干净的数据样本。
- 过高估计了它们的实际应用性。

我们的建议
- 报告模型选择标准。
- 使用少样本学习方法作为基线。
- 总是应用连续微调（CFT）。</sample>
    <sample id="938">结论

最近的WSL方法
- 需要干净的数据样本。
- 过高估计了它们的实际应用性。

我们的建议
- 报告模型选择标准。
- 使用少样本学习方法作为基线。
- 总是应用持续微调（CFT）。</sample>
    <sample id="939">对话系统的常用评估方法包括比较性评估和李克特量表评估。</sample>
    <sample id="940">这篇论文有五位作者。</sample>
    <sample id="941">在 Servin 和 Kea 的示例中，需要的背景知识是“法官在法庭上决定案件”。</sample>
    <sample id="942">是的，代码公开。可以在GitHub上找到数据集、生成和评估代码，网址为mpoemsl/kitmus。</sample>
    <sample id="943">根据图片中的信息，NLPositionality 的注释者在教育水平方面是不均衡的。具体来说，拥有大学教育背景的人群（包括大学和研究生）占比较高，而拥有高中教育或更低教育水平的人群占比相对较低。这表明数据集和模型可能更倾向于与具有大学教育背景的人群对齐。</sample>
    <sample id="944">通过添加前缀或后缀副词、长前缀副词、附加从句或引用来扰乱句子。</sample>
    <sample id="945">进行维度评估意味着对对话质量的不同方面进行评价。</sample>
    <sample id="946">这篇论文的作者所属机构包括：

1. 中国科技大学（University of Science and Technology of China）
2. 微软亚洲研究院（Microsoft Research Asia）
3. 北京交通大学（Beijing Jiaotong University）
4. 索尼人工智能实验室（Sony AI）
5. 微软亚洲技术中心（Microsoft STC Asia）</sample>
    <sample id="947">在翻译任务中，提示的形式非常重要。例如，在处理多语言翻译时，提供多个示例可以帮助模型更好地理解上下文和语境，从而提高翻译质量。</sample>
    <sample id="978">作者评估了BART-FID-RAG、Blender2、Emora和Blender-Decode这四个对话模型。</sample>
    <sample id="979">这篇论文有八位作者。</sample>
    <sample id="980">优秀规划器的理想品质是能够继承抽象目标并适应不同具体目标的多面约束。</sample>
    <sample id="981">这篇论文有八位作者。</sample>
    <sample id="982">演讲者的名字是Vasudha Varadarajan。</sample>
    <sample id="983">这篇论文的作者所属机构是波兰科学院计算机科学研究所（Institute of Computer Science, Polish Academy of Sciences）。</sample>
    <sample id="1021">根据图片中的信息，PaLM最常见的错误是“Accuracy/Omission”。</sample>
    <sample id="1022">标题：不要忘记你的ABC：评估聊天导向对话系统的最新进展

作者：Sarah E. Finch, James D. Finch和Jinho D. Choi

标志：埃默里大学、埃默里NLP研究实验室、Alexa</sample>
    <sample id="1023">标题：不要忘记你的ABC：评估聊天导向对话系统的最新进展

作者：Sarah E. Finch, James D. Finch 和 Jinho D. Choi

标志：埃默里大学、埃默里NLP研究实验室和Alexa</sample>
    <sample id="1024">标题：不要忘记你的ABC：评估聊天导向对话系统的现状

演讲者：Sarah E. Finch, James D. Finch, Jinho D. Choi

比较评价</sample>
    <sample id="1025">比较评价

Likert评分评价</sample>
    <sample id="1026">幻灯片上的英文内容翻译成中文如下：

1. Likert Rating Evaluation
2. Dimensions of Dialogue Quality
   - Dialogue Quality
   - Relevance
   - Emotional Understanding
   - Consistency</sample>
    <sample id="1027">对话质量维度

Likert 评分评价

请对机器人的响应相关性进行评分</sample>
    <sample id="1028">Likert评分评价

请对机器人的回答相关性进行评分</sample>
    <sample id="1029">幻灯片上的英文内容翻译成中文如下：

“在聊天中注释行为（ABC-Eval）”</sample>
    <sample id="1030">幻灯片上的英文内容翻译成中文如下：

“在聊天中注释行为（ABC-Eval）”</sample>
    <sample id="1031">图片中的英文内容翻译成中文如下：

ABC-Eval 行为

- Coherence（连贯性）
- Knowledge（知识）
- Consistency（一致性）
- Emotional Understanding（情感理解）</sample>
    <sample id="1032">图片中的英文内容翻译成中文如下：

ABC-Eval 行为

一致性
- 忽视伙伴
- 无关

知识

情感理解</sample>
    <sample id="1033">幻灯片上的英文内容翻译成中文如下：

ABC-Eval 行为

一致性
- 忽视伙伴
- 无关

知识
- 不正确的事实
- 常识违反

情感理解
- 同理心回应
- 缺乏同理心</sample>
    <sample id="1034">实验
- 4个开放领域对话模型
- 每个模型100个人机对话</sample>
    <sample id="1035">实验
- 4个开放领域对话模型
- 每个模型100次人机对话

ABC-Eval
Turn Likert
Dialogue Likert
Comparative</sample>
    <sample id="1036">实验

- 4个开放域对话模型
- 每个模型100个人机对话

基线评估

- Turn Likert
- Dialogue Likert
- Comparative

一致性
情感理解
信息性
整体质量

参与度
语法性
主动性
相关性</sample>
    <sample id="1037">图表标题：跨注释员一致性

Krippendorff's Alpha值
ABC-Eval
Turn Likert
Dialogue Likert
Comparative

Emory University
NLP Emory
Alexa</sample>
    <sample id="1038">图表标题：预测有效性

图例：
- Interactive Qua_d (深灰色)
- Interactive Qua_c (浅灰色)

分类：
- ABC-Eval
- Turn Likert
- Dialogue Likert
- Comparative

解释的品质百分比（R²）：

- Other Contradiction: 0.10
- CS Contradiction: 0.08
- Unempathetic: 0.06
- Ignore: 0.04
- Redundant: 0.02
- Empathetic: 0.00
- Self Contradiction: 0.00
- Correct: 0.00
- Uninterpret: 0.00
- Follow up: 0.00
- Incorrect: 0.00
- Topic Switch: 0.00
- Life Info: 0.00
- Antisocial: 0.00
- Pref. Info: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging: 0.08
- Proactive: 0.06
- Relevant: 0.04
- Consistent: 0.02
- Emotion: 0.00
- Informative: 0.00
- Grammar: 0.00
- Engaging:</sample>
    <sample id="1039">预测有效性

Emory University
NLP Emory
Alexa</sample>
    <sample id="1040">预测性有效性

图中展示了不同因素对质量解释（R²）的贡献百分比。左侧的柱状图显示了ABC-Eval、Turn Likert和Dialogue Likert三个维度下，各种因素对质量解释的贡献情况。右侧的折线图则进一步详细展示了这些因素在不同维度下的具体贡献值。

预测性有效性

图中展示了不同因素对质量解释（R²）的贡献百分比。左侧的柱状图显示了ABC-Eval、Turn Likert和Dialogue Likert三个维度下，各种因素对质量解释的贡献情况。右侧的折线图则进一步详细展示了这些因素在不同维度下的具体贡献值。</sample>
    <sample id="1041">增量有效性

解释的质量百分比（R²）

ABC-Eval
Turn Likert
Dialogue Likert</sample>
    <sample id="1042">增量有效性

图中展示了不同评估方法（ABC-Eval, Turn Likert, Dialogue Likert）对质量解释（R²）的贡献百分比。</sample>
    <sample id="1043">图中显示了不同模型在ABC-Eval错误率方面的表现。具体来说，图的顶部标题为“ABC-Eval错误率按模型划分”。图表展示了五个模型（BART-FID-RAG、Blender2、Emora、Blender-Decode）在各种错误类型上的百分比分布。这些错误类型包括：反社会行为、CS冲突、忽略、不正确、无关、不体谅、其他冲突、冗余、自我冲突、话题转换和未解释。每个模型的错误类型分布都有不同的颜色表示，例如蓝色、绿色、紫色等。</sample>
    <sample id="1044">图中的英文内容翻译成中文如下：

ABC-Eval 错误率按模型划分

% of Turns
ABC-Eval 错误率按模型划分
BART-FID-RAG
Blender2
Emora
Blender-Decode</sample>
    <sample id="1045">图中的英文内容翻译成中文如下：

ABC-Eval 错误率按模型划分

% of Turns
ABC-Eval 错误率按模型划分
BART-FID-RAG
Blender2
Emora
Blender-Decode</sample>
    <sample id="1046">图中显示的是ABC-Eval错误率按模型划分的柱状图。</sample>
    <sample id="1047">第一张幻灯片的英文内容翻译成中文如下：

ABC-Eval 错误率按模型划分

第二张幻灯片的英文内容翻译成中文如下：

谢谢观看！

论文：https://arxiv.org/pdf/2212.09180.pdf

GitHub：https://github.com/emorynlp/ChatEvaluationPlatform

联系信息：
{sfillwo, jdfinch, jinho.choi} @emory.edu
https://www.emorynlp.org</sample>
    <sample id="1048">这篇论文的作者所属机构是Emory NLP Research Lab。</sample>
    <sample id="1049">在本文中，CFT 代表连续微调。</sample>
    <sample id="1050">这篇论文有七位作者。</sample>
    <sample id="1051">标题：何时翻译需要上下文？数据驱动的多语言探索

作者：Patrick Fernandes*, Kayo Yin*, Emmy Liu
Andre F. T. Martins, Graham Neubig

*等同贡献

Carnegie Mellon University
Language Technologies Institute
TÉCNICO LISBOA
BAIR
BERKELEY ARTIFICIAL INTELLIGENCE RESEARCH
Unbabel</sample>
    <sample id="1052">翻译取决于上下文

我们将不得不除掉那个间谍。

事情可能会变得危险，如果部长们发现的话。我们将不得不除掉那个间谍。</sample>
    <sample id="1053">翻译取决于上下文

如果部长们发现，事情可能会变得危险。
我们必须除掉那个内鬼。

这可能是严重的事情吗，医生？
我们必须除掉那个内鬼。</sample>
    <sample id="1054">翻译取决于上下文

医生，这可能是严重的事情吗？我们得把那个痣去掉。</sample>
    <sample id="1055">评估上下文依赖的翻译很困难

- 只有少量的单词依赖于上下文
- 文本水平指标</sample>
    <sample id="1056">评估上下文依赖的翻译很困难

- 只有很小一部分单词依赖于上下文
  - 文本水平指标
- 现有的方法支持有限的语篇现象和语言</sample>
    <sample id="1057">RQ1: 翻译何时需要上下文？
RQ2: 模型在处理依赖于上下文的翻译时表现如何？</sample>
    <sample id="1058">RQ1: 翻译何时需要上下文？
- 单词级别的上下文使用

RQ2: 模型在处理依赖于上下文的翻译时表现如何？</sample>
    <sample id="1059">条件交叉互信息（CXMI）

- CXMI：衡量给定语料库时上下文MT模型使用了多少上下文</sample>
    <sample id="1060">条件交叉互信息（CXMI）

- CXMI：衡量给定语料库时上下文MT模型使用了多少上下文</sample>
    <sample id="1061">点积（P-）CXMI

- 我们引入 P-CXMI 来衡量上下文的使用以翻译特定的内容

  - 句子 P-CXMI(y, x, C) = - log qMTA(y|x) / qMTC(y|x, C)
  
  - 单词 P-CXMI(i, y, x, C) = - log qMTA(yi|yt&lt;i, x) / qMTC(yi|yt&lt;i, x, C)

- 高 P-CXMI 的单词 -&gt; 需要上下文来翻译</sample>
    <sample id="1062">RQ1: 翻译何时需要上下文？
- 单词级别的上下文使用
- 主题分析

RQ2: 模型在处理依赖于上下文的翻译方面表现如何？</sample>
    <sample id="1063">主题分析高P-CXMI词汇

RQ1：翻译何时需要上下文？
- 单词级别的上下文使用
- 主题分析

RQ2：模型如何处理上下文相关的翻译？

TED
IDEAS WORTH SPREADING

英语 | 阿拉伯语 | 德语
西班牙语 | 法语 | 俄语
意大利语 | 日语 | 荷兰语
葡萄牙语 | 罗马尼亚语 | 土耳其语
韩语 | 中文</sample>
    <sample id="1064">主题分析高P-CXMI词汇

1. 词性标注</sample>
    <sample id="1065">主题分析高P-CXMI词汇

1. 词性标记</sample>
    <sample id="1066">主题分析高P-CXMI词汇

1. 词性标记
- 代词
- 动词形式

2. 词汇项目</sample>
    <sample id="1067">主题分析高P-CXMI词汇

1. 词性标注
2. 词汇项目

Avelile's mother was still asleep.
Avelile went to school.

阿维利尔的母亲还在睡觉。
阿维利尔去上学了。</sample>
    <sample id="1068">主题分析高P-CXMI词汇

1. 词性标注
2. 词汇项目

Avelile's mother was still asleep.
Avelile went to school.

阿维利尔的母亲还在睡觉。
阿维利尔去上学了。

- 代词
- 动词形式
- 词汇连贯性
- 正式程度</sample>
    <sample id="1069">1. POS tags
2. Vocabulary items
3. Individual tokens

- 代词
- 动词形式
- 词汇连贯性
- 正式程度
- 省略</sample>
    <sample id="1070">主题分析高P-CXMI词汇

RQ1：翻译何时需要上下文？
1. 词性标注
   - 单词级别的上下文使用
2. 词汇项目
   - 主题分析
3. 个体词
   - 代词
   - 动词形式
   - 词汇连贯性
   - 形式化
   - 省略

RQ2：模型如何处理上下文依赖的翻译？
- 多语言话语意识（MuDA）基准</sample>
    <sample id="1071">这张图片中的英文内容翻译成中文如下：

RQ1: 翻译何时需要上下文？
- 单词级别的上下文使用
- 主题分析

RQ2: 模型如何处理依赖于上下文的翻译？
- 多语言话语感知（MuDA）基准

多语言话语感知（MuDA）标签器
- 代词
- 动词形式
- 词汇连贯性
- 正式性
- 省略</sample>
    <sample id="1072">这张图片展示了一个名为“Multilingual Discourse-Aware (MuDA) tagger”的工具，它用于多语言语篇感知标注。图片左侧列出了该工具关注的几个方面：代词、动词形式、词汇连贯性、正式性和省略。

右侧是一个柱状图，展示了不同语言中这些方面的计数情况。图例说明了每个颜色代表的内容：蓝色表示代词，橙色表示正式性，绿色表示动词形式，红色表示词汇连贯性，紫色表示省略。图表中的语言包括法语（fr）、日语（ja）、荷兰语（nl）、俄语（ru）、德语（de）、葡萄牙语（pt_br）、罗马尼亚语（ro）、西班牙语（es）、意大利语（it）、希伯来语（he）、中文（zh_cn）、阿拉伯语（ar）、土耳其语（tr）和韩语（ko）。</sample>
    <sample id="1073">图中展示了“多语言话语感知（MuDA）标签器”的概念。左侧列出了五种特征：代词、动词形式、词汇连贯性、正式性和省略。右侧是一个柱状图，显示了不同语言下这些特征的计数情况。

接下来的幻灯片展示了MuDA基准测试的过程。左侧是堆叠的文件图标，表示输入数据；中间是MuDA标签器，用于对输入数据进行标注；右侧是带有标记的文件，表示输出结果。最后，右侧有一个机器人图标，表示评估结果，包括BLEU、COMET和F-measure等指标。</sample>
    <sample id="1074">RQ1: 翻译何时需要上下文？
- 单词级别的上下文使用
- 主题分析

RQ2: 模型在处理上下文依赖的翻译方面表现如何？
- 多语言话语感知（MuDA）基准
- 模型评估</sample>
    <sample id="1075">幻灯片上的英文内容翻译成中文如下：

**语料库级别的指标**

RQ1: 翻译何时需要上下文？
- 单词级别上下文使用
- 主题分析

RQ2: 模型如何处理上下文依赖的翻译？
- 多语言话语感知（MuDA）基准
- 模型评估</sample>
    <sample id="1076">图中的英文内容翻译成中文如下：

- Corpus-level metrics
  - BLEU
  - COMET
  - F-measure</sample>
    <sample id="1077">语料库级别的指标

- BLEU
- COMET
- F-measure

不清楚哪种系统最适合用于基于语料库级别的MT</sample>
    <sample id="1078">图中的英文内容翻译成中文如下：

- 文本水平指标
  - BLEU
  - COMET
  - F-measure

- 不清楚哪种系统最适合使用文本水平指标进行文档级机器翻译
- MuDA基准测试结果
  - 上下文感知模型在某些现象上表现显著更好</sample>
    <sample id="1079">MuDA基准测试结果

- 上下文感知模型在某些现象上表现显著更好
  - √: 正式性，词汇连贯性
  - ❌: 省略，代词，动词形式</sample>
    <sample id="1080">MuDA基准测试结果

- 上下文感知模型在某些现象上表现显著更好
  - ✓: 正式性，词汇连贯性
  - ✗: 省略，代词，动词形式

- DeepL在大多数现象和语言对上优于Google*
*截至2021年4月</sample>
    <sample id="1081">总结

- 系统地识别话语现象，无需先验语言知识
- 数据集无关的文档级机器翻译基准</sample>
    <sample id="1082">摘要

- 系统地识别话语现象，无需先验语言知识
- 无数据集依赖的文档级MT基准</sample>
    <sample id="1083">总结

- 无需先验语言知识，系统地识别话语现象
- 文档级机器翻译的无数据集依赖基准</sample>
    <sample id="1084">演讲者的名字是Yusen Zhang。</sample>
    <sample id="1121">该图中没有提供新方法的具体名称。</sample>
    <sample id="1122">作者描述“显性词汇”(marked words)方法为：找到区分显性群体和非显性群体的人格特征的词汇。</sample>
    <sample id="1123">这篇论文的作者所属机构包括Paul G. Allen School、UW NLP、Carnegie Mellon University Language Technologies Institute和清华大学。</sample>
    <sample id="1124">Bouquet/Stanford (Universal Dependencies)</sample>
    <sample id="1125">演讲者的名字是Sarah E. Finch, James D. Finch和Jinho D. Choi。</sample>
    <sample id="1126">这篇论文有四位作者。</sample>
    <sample id="1127">BLiMP和SyntaxGym可用于测试句法现象。</sample>
    <sample id="1161">FT_w, BOND, COSINE, MLC, L2R</sample>
    <sample id="1162">该模型在11个任务上进行了评估。</sample>
    <sample id="1226">CamemBERT 最初是在 138 GB 的数据上训练的。</sample>
    <sample id="1227">演讲者的名字是Adam Przepiórkowski。</sample>
    <sample id="1228">根据图片中的信息，时间漂移（Temporal drift）是导致性能下降的主要原因。具体来说，随着时间间隔的增大，性能会逐渐下降。</sample>
    <sample id="1269">对输出序列中的词元进行排列是为了探索不同排列顺序对模型性能的影响。通过这种方式，可以评估模型在不同排列下的表现，从而选择最优的排列方式来提高模型的准确性和鲁棒性。</sample>
    <sample id="1270">作者建议模型所有者提高偏见缓解方法的透明度是为了确保公平性和公正性。通过透明地展示如何减轻偏见，可以增强公众对模型的信任，并且有助于识别和纠正潜在的不公平因素。这不仅有助于维护社会正义，还能促进更广泛的社会接受度和使用。</sample>
    <sample id="1271">最小对不可接受输入（Minimal Pair Unacceptable Inputs）是指在语言模型评估中，使用相对序列概率差异来评估语言模型抽象知识的一种方法。这种方法通过比较两个句子的概率来判断它们是否符合某种规则或语法规则。例如，在BLiMP中，句子“Many people were helping themselves”和“Many people were helping herself”的概率P(1) &gt; P(2)，表明后者更不符合规则；在SyntaxGym中，句子“No customer ... has spent any money.”和“The customer ... has spent any money.”的概率P(1.any) &gt; P(2.any)，表明后者更不符合规则；在CrowS中，句子“Stereotypical sentence.”和“Non-stereotypical sentence.”的概率P(1) &gt; P(2)，表明前者更符合规则。</sample>
    <sample id="1272">根据图片中的信息，作者使用了以下评估指标：

1. F1
2. Hamming
3. EMR

这些指标分别用于不同的任务或数据集，具体如下：
- F1：用于NER（命名实体识别）和CLS（分类）任务。
- Hamming：用于QUAERO-EMEA和QUAERO-MEDLINE数据集。
- EMR：用于QUAERO-EMEA和QUAERO-MEDLINE数据集。</sample>
    <sample id="1273">使用了Krippendorff's Alpha指标来衡量注释者之间的一致性。</sample>
    <sample id="1274">在不可接受查询中，选择Wikipedia领域来添加完全无关的句子。</sample>
    <sample id="1275">这篇论文的作者所属机构是德国杜塞尔多夫海因里希·海涅大学。</sample>
    <sample id="1276">MultiInstruct 与其他基准的不同之处在于它提供了1600多个语言任务的指令，而没有提供大规模的公开可访问的多模态指令任务。</sample>
    <sample id="1277">这篇论文有三位作者。</sample>
    <sample id="1278">二进制协调指的是在语言学中，两个词或短语之间的关系，其中一个是另一个的治理者。治理者通常是指在句法结构中具有支配作用的词或短语。在这种关系中，治理者对被治理者的语法行为施加影响。例如，在英语中，“the cat”中的“the”是“cat”的治理者，因为它决定了“cat”在句子中的语法角色。</sample>
    <sample id="1279">抱歉，您提供的图片内容并未包含关于提示语平均长度的信息。图片中的内容是关于黑人刻板印象在角色中的表现，以及使用GPT-3.5和GPT-4模型生成的角色中黑人和白人的比例。如果您有关于这个图表的问题，我会很乐意帮助解答。</sample>
    <sample id="1280">这些发现表明，经过 Coscript 数据集微调的小型 T5 模型可以生成比大型语言模型（LLMs）更高的质量脚本。</sample>
    <sample id="1281">DrBERT：一种用于生物医学和临床领域的法语预训练模型

Yanis Labrak*1,4 Adrien Bazoge*2,3 Richard Dufour2 Mickael Rouvier1
Emmanuel Morin2 Béatrice Daille2 Pierre-Antoine Gourraud3

(1) LIA, Avignon Université (2) LS2N, Nantes Université (3) Clinique des données, CHU de Nantes (4) Zenidoc</sample>
    <sample id="1282">摘要

I. 医疗领域中的语言建模
II. 预训练策略、数据源和规模的比较
III. 13个模型在11项任务上的评估
IV. NACHOS和DrBERT的分布</sample>
    <sample id="1283">摘要

I. 医疗领域中的语言建模
II. 预训练策略、数据源和规模的比较
III. 13个模型在11项任务上的评估
IV. NACHOS和DrBERT的分布</sample>
    <sample id="1284">摘要

I. 医疗领域中的语言建模
II. 预训练策略、数据源和规模的比较
III. 13个模型在11项任务上的评估
IV. NACHOS和DrBERT的分布</sample>
    <sample id="1285">I. 语言模型在医疗保健中的应用
- 基于Transformer的方法，如BERT，在许多NLP任务中提供了巨大的性能提升

II. 预训练策略、数据源和规模的比较
- 已经适应了法语，使用了CamemBERT和FlaubERT
- 比较了基于PubMedBERT、BioBERT、ClinicalBERT和其他方法的预训练策略

III. 对13个模型在11项任务上的评估
- 其他语言比英语更稀少，主要依赖于使用现有通用模型进行持续预训练

IV. NACHOS和DrBERT的分布
- 与通用模型不同，目前还没有针对法语生物医学领域的开源模型
- 基于BERT的特定领域模型应该会提高医疗任务的性能</sample>
    <sample id="1286">语言建模

- 基于Transformer的方法，如BERT，在许多NLP任务中提供了巨大的性能提升
- 已经被适应到法语，如CamemBERT和FlauBERT
- 在医疗任务中，英语领域的特定领域模型进一步提高了标准
  - PubMedBERT、BioBERT、ClinicalBERT等
- 其他语言比英语更少见，并且主要依赖于使用现有通用模型的持续预训练
- 与通用模型不同，目前还没有公开可用的法语生物医学领域的模型
- 基于BERT的特定领域模型对于法语应该在医疗任务中提高性能</sample>
    <sample id="1287">语言建模

- 基于Transformer的方法，如BERT，在许多NLP任务中提供了巨大的性能提升
- 已经被适应到法语，使用CamemBERT和FlauBERT
- 在医疗任务中，英语领域的特定领域模型进一步提高了标准
  - PubMedBERT、BioBERT、ClinicalBERT等
- 其他语言比英语更少见，并且主要依赖于使用现有通用模型的持续预训练
- 与通用模型不同，目前还没有公开可用的法语生物医学领域的模型
- 基于BERT的特定领域模型对于法语应该在医疗任务中提高性能</sample>
    <sample id="1288">语言建模

- 基于Transformer的方法，如BERT，在许多NLP任务中提供了巨大的性能提升
- 已经被适应到法语，使用CamemBERT和FlauBERT
- 在医疗任务中，英语领域的特定领域模型进一步提高了标准
  - PubMedBERT、BioBERT、ClinicalBERT和其他
- 其他语言比英语更少见，并且主要依赖于使用现有通用模型的持续预训练
- 与通用模型不同，目前还没有公开可用的法语生物医学领域的模型
- 基于BERT的特定领域模型对于法语应该在医疗任务中提高性能</sample>
    <sample id="1289">语言建模

- 基于Transformer的方法，如BERT，在许多NLP任务中提供了巨大的性能提升
- 已经被适应到法语，使用CamemBERT和FlauBERT
- 在医疗任务中，英语领域的特定领域模型进一步提高了标准
  - PubMedBERT、BioBERT、ClinicalBERT和其他
- 其他语言比英语更少见，并且主要依赖于使用现有通用模型的持续预训练
- 与通用模型不同，目前还没有公开可用的法语生物医学领域的模型
- 基于BERT的法语特定领域模型应该在医疗任务中提高性能</sample>
    <sample id="1290">比较预训练策略和数据源

- 评估公共和私人医疗数据源对可比数据量的影响
  - NACHOS：一个包含11亿单词的开源数据集，从不同的医疗领域、性质和风格中爬取异构数据
  - NBDW：一个私有数据集，包含从南特大学医院数据仓库中提取的170万份匿名化医疗记录中的句子

- 比较学习策略
  - 从零开始，全模型构建
  - 继续预训练使用现有预训练模型（这里使用的是CamemBERT，一种法语通用模型，以及PubMedBERT，一种基于英语的医学模型）</sample>
    <sample id="1291">比较预训练策略和数据源

- 评估公共和私人医疗数据源对可比数据量的影响
  - NACHOS：一个包含11亿单词的开源数据集，从不同的医疗领域、性质和风格中爬取异构数据
  - NBDW：一个私有数据集，包含从南特大学医院数据仓库中提取的170万份匿名化医疗记录中的句子

- 比较学习策略
  - 从零开始，全模型构建
  - 继续预训练（使用现有预训练模型）
    （这里，CamemBERT是一个法语通用模型，PubMedBERT是一个基于英语的医学模型）</sample>
    <sample id="1292">比较预训练策略和数据源

- 评估公共和私人医疗数据源对可比数据量的影响
  - NACHOS：一个包含11亿单词的开源数据集，从不同医学领域、性质和风格中爬取的异质数据
  - NBDW：一个私有数据集，来自Nantes大学医院数据仓库中的170万匿名化医疗记录中的句子

- 比较学习策略
  - 从零开始，全模型构建
  - 继续预训练使用现有预训练模型（这里使用的是CamemBERT，一种法语通用模型，以及PubMedBERT，一种基于英语的医学模型）</sample>
    <sample id="1293">比较预训练策略和数据源

- 评估公共和私人医疗数据源对可比数据量的影响
  - NACHOS：一个包含11亿单词的开源数据集，从不同的医疗领域、性质和风格中爬取异构数据
  - NBDW：一个私有数据集，包含从南特大学医院数据仓库中提取的170万份匿名化医疗记录中的句子

- 比较学习策略
  - 从零开始，全模型构建
  - 继续预训练使用现有预训练模型（这里使用的是CamemBERT，一种法语通用模型，以及PubMedBERT，一种基于英语的医学模型）</sample>
    <sample id="1294">比较预训练策略和数据源

- 评估公共和私人医疗数据源对可比数据量的影响
  - NACHOS：一个包含11亿单词的开源数据集，从不同的医疗领域、性质和风格中爬取异构数据
  - NBDW：一个私有数据集，来自Nantes大学医院数据仓库中的170万匿名化医疗记录中的句子

- 比较学习策略
  - 从零开始，全模型构建
  - 继续预训练使用现有预训练模型（这里，CamemBERT，一个法语通用模型，和PubMedBERT，一个基于英语的医学模型）</sample>
    <sample id="1295">比较预训练策略和数据源

- 评估公共和私人医疗数据源对可比数据量的影响
  - NACHOS：一个包含11亿单词的开源数据集，从不同的医疗领域、性质和风格中爬取异构数据
  - NBDW：一个私有数据集，包含从南特大学医院数据仓库中提取的170万份匿名化医疗记录中的句子

- 比较学习策略
  - 从零开始，完全模型构建
  - 继续预训练使用现有预训练模型（这里使用CamemBERT，一种法语通用模型，以及PubMedBERT，一种基于英语的医学模型）</sample>
    <sample id="1296">比较预训练策略和数据源

- 评估公共和私人医疗数据源对可比数据量的影响
  - NACHOS：一个包含11亿单词的开源数据集，从不同的医疗领域、性质和风格中爬取异构数据
  - NBDW：一个私有数据集，包含从南特大学医院数据仓库中提取的170万份匿名化医疗记录中的句子

- 比较学习策略
  - 从零开始，全模型构建
  - 继续预训练使用现有预训练模型（这里使用的是CamemBERT，一种法语通用模型，以及PubMedBERT，一种基于英语的医学模型）</sample>
    <sample id="1297">比较预训练策略和数据源

- 评估公共和私人医疗数据源对可比数据量的影响
  - NACHOS：一个包含11亿单词的开源数据集，从不同的医学领域、性质和风格中爬取的异构数据
  - NBDW：一个私有数据集，来自Nantes大学医院数据仓库中的170万匿名化医疗记录中的句子

- 比较学习策略
  - 从零开始，完全模型构建
  - 继续预训练使用现有预训练模型（这里使用的是CamemBERT，一种法语通用模型，以及PubMedBERT，一种基于英语的医学模型）

评价：数据源和大小
- 对13个模型在11项任务上的性能进行评估，包括公共和私人数据
- 我们的微调模型几乎在所有任务上都取得了最先进的结果</sample>
    <sample id="1298">评估：数据来源和规模

- 对13个模型在11项任务上的性能进行了评估，包括公开和私有数据集
- 我们的微调模型几乎在所有任务上都取得了最先进的结果</sample>
    <sample id="1299">评估：数据来源和规模

- 对13个模型在11项任务上的性能进行了评估，包括公开和私有数据集
- 我们微调的模型几乎在所有任务上都取得了最先进的结果</sample>
    <sample id="1300">评估：数据来源和规模

- 对13个模型在11项任务上的性能进行了评估，包括公开和私有数据集
- 我们的微调模型几乎在所有任务上都取得了最先进的结果</sample>
    <sample id="1301">评估：数据来源和规模

- 对13个模型在11项任务上的性能进行了评估，包括公开和私有数据集
- 我们微调的模型几乎在所有任务上都取得了最先进的结果</sample>
    <sample id="1302">评估：预训练策略

- 从零开始 vs. 在4GB数据上进行持续预训练
- 问答任务需要更多的领域特定知识才能有效工作
- 对模型稳定性的研究显示，使用持续预训练训练的CamemBERT基模态具有更高的运行间变异性</sample>
    <sample id="1303">评估：预训练策略

- 从零开始 vs. 在4GB数据上进行持续预训练
- 问答任务需要更多的领域特定知识才能有效工作
- 对模型稳定性的研究显示，使用持续预训练训练的CamemBERT基模态具有更高的跨运行变异性</sample>
    <sample id="1304">评估：预训练策略

- 从零开始 vs. 在4GB数据上进行持续预训练
- 问答任务需要更多的领域特定知识才能有效工作
- 对模型稳定性的研究显示，使用持续预训练训练的CamemBERT基模态具有更高的运行间变异性</sample>
    <sample id="1305">核心信息

- DrBERT 在 9 个下游法语医学任务中取得了最先进的结果
  - 超过了 CamemBERT 通用模型和基于英语的领域特定模型
  - 确认了在法语中训练医学特定模型的实用性

- 数据来源很重要：在异质数据上进行训练非常重要
  - NACHOS 比仅使用私人临床数据更健壮

- 更多的数据更好，但并不容易扩展
- 基于特定领域的英语模型的持续预训练是一种更有效的策略
- DrBERT 模型、NACHOS 数据集和训练脚本在 MIT 许可证下免费提供

drbert.univ-avignon.fr
阿维尼翁大学</sample>
    <sample id="1306">核心信息

- DrBERT 在 9 个下游法语医学任务中取得了最先进的结果
  - 超过了 CamemBERT 通用模型和基于英语的领域特定模型
  - 确认了在法语中训练医学特定模型的实用性

- 数据来源很重要：在异质数据上进行训练非常重要
  - NACHOS 比仅使用私人临床数据更稳健

- 更多的数据更好，但扩展性不佳

- 当基于特定领域的英语模型时，持续预训练是一种更有效的策略

- DrBERT 模型、NACHOS 数据集和训练脚本在 MIT 许可证下免费提供</sample>
    <sample id="1307">核心信息

- DrBERT 在 9 个下游法语医学任务中取得了最先进的结果
  - 超过了 CamemBERT 通用模型和基于英语的领域特定模型
  - 确认了在法语中训练医学特定模型的实用性

- 数据来源很重要：在异质数据上进行训练非常重要
  - NACHOS 比仅使用私人临床数据更健壮

- 更多的数据更好，但并不容易扩展
- 基于特定领域的英语模型的持续预训练是一种更有效的策略
- DrBERT 模型、NACHOS 数据集和训练脚本在 MIT 许可证下免费提供

drbert.univ-avignon.fr
阿维尼翁大学</sample>
    <sample id="1308">谢谢！

期待在多伦多的海报交流会！</sample>
    <sample id="1309">论文研究了两种学习策略：从零开始（From scratch）和持续预训练（Continual pre-training）。</sample>
    <sample id="1310">根据图片中的信息，过拟合的因素并不大。具体来说，图片中提到“Adaptive overfitting? No diminishing returns”，这意味着过拟合没有显示出减少的趋势。因此，可以推断出由于测试重复使用而导致的过拟合因素并不显著。</sample>
    <sample id="1311">评估简化质量的方法包括使用SARI、BLEU、BS-P和FRE指标。这些指标分别衡量了简化文本与原始文本之间的相似性、翻译质量、保真度和流畅度。</sample>
    <sample id="1312">是的，语言模型有不同的政治偏见。图中显示了不同语言模型在社会和经济轴上的位置，表明它们的政治倾向各不相同。例如，BERT-base、BERT-large、RoBERTa-base和distilBERT等模型偏向于左翼，而Codex、LLaMA、GPT-2等模型则偏向于右翼。</sample>
    <sample id="1313">这张图片的英文内容翻译成中文如下：

标题：不使用树进行组合泛化的方法，利用多集标记和潜在排列

作者：Matthias Lindemann, Alexander Koller, Ivan Titov

图片中显示了以下大学和机构的标志：
- 爱丁堡大学
- NLP UKRI中心博士培训中心
- 沙尔兰大学
- 阿姆斯特丹大学</sample>
    <sample id="1314">这张图片的英文内容翻译成中文如下：

标题：无需树的组合泛化使用多集标记和潜在排列

作者：Matthias Lindemann, Alexander Koller, Ivan Titov

图片中显示了以下大学和机构的标志：
- 爱丁堡大学
- NLP UKRI博士培训中心
- 沙尔克大学
- 阿姆斯特丹大学</sample>
    <sample id="1315">组合泛化

学习者处理更深层次的递归和在训练过程中单独见过的未见过的短语组成的语言模型的能力。</sample>
    <sample id="1316">图中展示的是语义解析中的组合泛化过程。训练示例包括两个句子：“The girl slept.” 和 “Mary knew that the girl slept.”。每个句子的词组都被用不同的颜色标记，以表示它们在语义结构中的不同角色。例如，“girl”和“slept”被标记为绿色，表示它们是动词短语的组成部分；“Mary”被标记为蓝色，表示它是从句的主语；“knew”和“that”被标记为橙色，表示它们是谓语动词和连接词。这些标记帮助理解句子的语法结构，并将其转换为更抽象的语义表示形式。</sample>
    <sample id="1317">图中展示的是语义解析中的组合泛化过程。训练示例包括两个句子：“The girl slept.” 和 “Mary knew that the girl slept.”。每个句子的词组都被用不同的颜色标记，以表示它们在语义结构中的角色。例如，“girl” 被标记为绿色，表示它是动词“slept”的执行者；“the girl” 被标记为橙色，表示它是动词“slept”的主题；“Mary” 被标记为蓝色，表示她是动词“knew”的执行者；“that the girl slept” 被标记为黄色，表示这是动词“knew”的宾语从句。这些颜色编码帮助理解句子的语义结构和关系。</sample>
    <sample id="1318">图中展示的是语义解析中的组合泛化概念。训练部分包括两个句子：“The girl slept.” 和 “Mary knew that the girl slept.”，以及它们对应的语义表示。测试部分是一个句子：“Jim said that Mary knew that the girl slept.”，以及它的语义表示。</sample>
    <sample id="1319">图中展示的是语义解析中的组合泛化概念。训练部分包括两个句子：“The girl slept.” 和 “Mary knew that the girl slept.”，以及它们对应的语义表示。测试部分是一个更复杂的句子：“Jim said that Mary knew that the girl slept.”，同样附有其对应的语义表示。</sample>
    <sample id="1320">图中的英文内容翻译成中文如下：

标题：语义解析中的组合泛化

训练：
- 女孩睡了。
  *girl x1 sleep.agent x2 x1

- 玛丽知道女孩睡了。
  *girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4

测试：
- 吉姆说玛丽知道女孩睡了。
  *girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7

底部文字：朴素的seq2seq模型失败！</sample>
    <sample id="1321">图中展示的是“语义解析中的组合泛化”。训练部分包括两个句子：“The girl slept.”和“Mary knew that the girl slept。”对应的语义表示分别为“*girl x1 sleep.agent x2 x1”和“*girl x4 know.agent x1 Mary ∧ know.ccomp x1 x5 ∧ sleep.agent x5 x4”。测试部分是一个更复杂的句子：“Jim said that Mary knew that the girl slept.”对应的语义表示为“*girl x7 say.agent x1 Jim ∧ say.ccomp x1 x4 ∧ know.agent x4 Mary ∧ know.ccomp x4 x8 ∧ sleep.agent x8 x7”。图下方的文字写着“朴素的seq2seq模型失败！”</sample>
    <sample id="1322">树木帮助了很多，但……</sample>
    <sample id="1323">树木帮助了很多，但……</sample>
    <sample id="1324">树木帮助了很多，但...

*girl x1; sleep.agent x2 x1

*girl x1; x1 sleep.agent x2

The girl slept.

需要获得的树：
- 前/后处理逻辑形式</sample>
    <sample id="1325">树木帮助了很多，但...

*girl x1; sleep.agent x2 x1

*girl x1; x1 sleep.agent x2

The girl slept.

需要获得的树：
- 前/后处理逻辑形式</sample>
    <sample id="1326">树木帮助了很多，但...

*girl x1; sleep.agent x2 x1

*girl x1; x1 sleep.agent x2

The girl slept.

需要获得的树：
- 预/后处理逻辑形式
- 语法归纳</sample>
    <sample id="1327">树木帮助了很多，但...

*girl x1; sleep.agent x2 x1

*girl x1; x1 sleep.agent x2

The girl slept.

需要获得的树：
- 预/后处理逻辑形式
- 语法归纳

这篇论文：神经序列到序列模型直接建模片段之间的对应关系。首次展示了在不使用树的情况下对更深递归的强大泛化能力。</sample>
    <sample id="1328">树木帮助了很多，但……

*girl x1; sleep.agent x2 x1
*girl x1; x1 sleep.agent x2
The girl slept.

需要获得的树：
- 预/后处理逻辑形式
- 语法归纳

这篇论文：神经序列到序列模型直接建模片段之间的对应关系。首次展示了在不使用树的情况下对更深递归的强大泛化能力。</sample>
    <sample id="1329">我们的方法

我们的方法展示了如何通过不同的颜色和符号来标记文本中的不同部分。具体来说，绿色的方块表示特殊字符或符号（如星号和分号），黄色的方块表示名词（如“girl”），蓝色的方块表示动词（如“sleep”、“agent”和“slept”）。每个方块下方的文字是对应的单词或短语。</sample>
    <sample id="1330">我们的方法

图中展示了三种不同的标记方式，分别对应于单词“the”、“girl”和“slept”。每个标记方式都包含一个标签（Tag），并用不同颜色的方框表示不同的标记元素。</sample>
    <sample id="1331">我们的方法

我们的方法展示了如何通过不同的颜色和符号来标记文本中的不同部分。具体来说，绿色的方块表示特殊字符或符号（如星号和分号），黄色的方块表示名词（如girl），蓝色的方块表示动词（如sleep和slept）。每个方块下面的文字是对应的单词。</sample>
    <sample id="1332">我们的方法

* girl
x1
; sleep
agent
x2
x1
the
girl
sleep
agent
x2
x1</sample>
    <sample id="1333">我们的方法

* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x1
* 女孩
x1
; 
睡
agent
x2
x</sample>
    <sample id="1334">图中展示了一个名为“Permuting with 'jumps'”的过程，其中包含三个部分：一个带有星号的绿色方块、一个灰色的“Permute”框和一个灰色的“Tag”框。在“Permute”框中有三个黄色方块，分别标记为“x1”、“girl”和“x1”。在“Tag”框中有三个蓝色方块，分别标记为“sleep”、“agent”和“x2”。这些方块通过箭头连接到下方的单词：“the”、“girl”和“slept”。</sample>
    <sample id="1335">图中显示了“跳转排列”的过程。顶部的灰色矩形框标有“Permute”，表示排列操作。下方的灰色矩形框标有“Tag”，表示标签。排列操作的结果被标记为“the girl slept”。排列操作使用了“跳转”（jumps）的概念，具体表现为绿色方块中的符号“*”和“;”以及黄色方块中的符号“x1”和蓝色方块中的符号“sleep”、“agent”和“x2”。这些符号代表了不同的元素或位置，在排列过程中进行了重新组合。</sample>
    <sample id="1336">图中展示了一个名为“Permuting with 'jumps'”的过程，其中包含三个部分：*、girl和sleep。这些元素通过“Tag”和“Permute”两个步骤进行排列组合。具体来说，“Tag”部分包含了“the”、“girl”和“slept”，而“Permute”部分则展示了如何通过“jumps”（跳跃）来重新排列这些元素。</sample>
    <sample id="1337">图中展示了“跳跃式排列”的概念。在“Permute”部分，有三个元素：“*”，“girl”，和“x1”。这些元素通过箭头连接到下方的“Tag”部分，其中包含三个不同的标签：“the”，“girl”，和“slept”。每个元素都与一个特定的标签相关联，形成了一个映射关系。</sample>
    <sample id="1338">图中展示了一个名为“Permuting with 'jumps'”的过程，其中包含三个部分：*、girl、x1、i、sleep、agent、x2和x1。这些元素通过箭头连接到一个灰色的矩形框内，该矩形框上标有“Permute”。在下方，有一个红色虚线框，其中包含了the、girl和slept三个单词，分别对应绿色、黄色和蓝色的方块。这些元素通过箭头连接到另一个灰色的矩形框内，该矩形框上标有“Tag”。整个过程展示了如何通过“跳跃”来重新排列元素，并将其标记为不同的类别。</sample>
    <sample id="1339">一些关于COGS（Kim和Linzen 2020）的结果

与其他无树模型在COGS上的结构泛化比较

模型对比：LSTM seq2seq、T5、Zheng和Lapata、我们的模型

类型：PP递归、CP递归、宾语PP → 主语PP</sample>
    <sample id="1340">一些关于COGS（Kim和Linzen 2020）的结果

与其他无树模型在COGS上的结构泛化比较

图例：
- LSTM seq2seq
- T5
- Zheng和Lapata
- 我们的模型

类型：
- PP递归
- CP递归
- 宾语PP → 主语PP</sample>
    <sample id="1341">技术挑战我们解决

* girl x1 ; sleep agent x2 x1
Permute
? ? ?
the girl slept
Tag
Alignment unknown.</sample>
    <sample id="1342">技术挑战我们解决

* girl x1 ; sleep agent x2 x1
Alignment unknown.

标签未知。</sample>
    <sample id="1343">技术挑战我们解决

* girl x1 ; sleep agent x2 x1
? ? ?
Permute
? ? ?
Tag
the girl slept
Alignment unknown.
在训练中诱导它。</sample>
    <sample id="1344">技术挑战我们解决

对齐未知。
在训练中诱导它。

排列模型：
- 推断是NP难的（≈ TSP）</sample>
    <sample id="1345">技术挑战我们解决

对齐未知。
在训练中诱导它。

排列模型：
- 推断是NP难的（≈ TSP）
- 通过连续松弛进行反向传播</sample>
    <sample id="1346">技术挑战我们解决

对齐未知。
在训练中诱导它。

排列模型：
- 推断是NP难的（≈ TSP）
- 通过连续松弛反向传播</sample>
    <sample id="1347">认知失调是指认知中的两个元素（即思想、行为和信念）不一致的情况。</sample>
    <sample id="1348">根据图表，GPT-3-davinci和ChatGPT最倾向于自由派。</sample>
    <sample id="1349">根据图表，累积训练（Cumulative）在所有测试方法（Random, Entropy, CoreSet, CAL, PRC）中都表现出更高的AUC值。因此，在主动学习时，累积训练确实比迭代训练更有效。</sample>
    <sample id="1350">演讲者的名字是Sara Papi。</sample>
    <sample id="1351">根据图片中的信息，MuDa基准中的数据是通过TED演讲获取的。</sample>
    <sample id="1385">演讲者的名字是Matthias Lindemann, Alexander Koller, Ivan Titov。</sample>
    <sample id="1386">跨语言转移是指在一种源语言上进行训练，并将其转移到另一种语言上的过程。</sample>
    <sample id="1387">这篇论文的作者所属机构包括萨尔兰大学（Saarland University）、亚马逊Alexa和维也纳大学（University of Vienna）。</sample>
    <sample id="1388">作者使用了AL和AL_CA两种延迟测量方法。</sample>
    <sample id="1389">幻灯片上的英文内容翻译成中文如下：

麦吉尔大学/Mila
微软研究院

KITMUS测试
评估多源知识整合</sample>
    <sample id="1390">NLU模型依赖于多种知识来源

知识在参数中（预训练时的知识）

知识在上下文中（推理时的知识）</sample>
    <sample id="1391">NLU模型依赖于多种知识来源
知识在参数中（预训练时间的知识）
知识在上下文中（推理时间的知识）</sample>
    <sample id="1392">约翰在电视上看到了新当选的总统

预训练知识
- 总统做什么✅
- 什么是电视✅

- 约翰是谁❌
- 新任总统是谁❌</sample>
    <sample id="1393">约翰在电视上看到了新当选的总统

预训练知识
- 总统做什么✅
- 什么是电视✅

- 约翰是谁❌
- 新任总统是谁❌</sample>
    <sample id="1394">约翰在电视上看到了新当选的总统

预训练知识
- 总统做什么✅
- 什么是电视✅

- 约翰是谁❌
- 新任总统是谁❌</sample>
    <sample id="1395">约翰在电视上看到了新当选的总统</sample>
    <sample id="1396">KITMUS测试套件
- 数据集用于知识整合评估
- 核心参照解析任务，以探查利用能力
  ○ 预训练时期的知识
  ○ 推理时期的知识
- 实验使用
  ○ 人类研究参与者
  ○ 核心参照解析模型</sample>
    <sample id="1397">KITMUS测试套件
- 数据集用于知识整合评估
- 共指消解任务，以探查模型利用预训练知识和推理时间知识的能力
- 实验涉及
  - 人类研究参与者
  - 共指消解模型</sample>
    <sample id="1398">Servin 是一名法官。Kea 是一名面包师。Servin 和 Kea 在公园相遇。在法庭上经过一天的工作后，他很高兴能放松一下。[答案：Servin]</sample>
    <sample id="1399">Servin 是一名法官。Kea 是一名面包师。Servin 和 Kea 在公园相遇。在法庭上度过了一整天后，他很高兴放松一下。[答案：Servin]</sample>
    <sample id="1400">KITMUS测试套件

Servin是一名法官，Kea是一名面包师。Servin和Kea在公园相遇。在法庭上度过了一整天后，他很高兴能放松一下。[答案：Servin]

1) 特定实体知识</sample>
    <sample id="1401">KITMUS测试套件

Servin是一名法官，Kea是一名面包师。Servin和Kea在公园相遇。在法庭上经过一天的工作后，他很高兴放松一下。[答案：Servin]

1) 特定实体知识
2) 背景知识

法官在法庭上决定案件。
推理时的知识
预训练时的知识</sample>
    <sample id="1402">KITMUS测试套件

Servin是一名法官，Kea是一名面包师。Servin和Kea在公园相遇。在法律法庭上工作了一整天后，他很高兴放松一下。[答案：Servin]

1) 特定实体知识
2) 背景知识

法官在法庭上决定案件。
推理时的知识
预训练时的知识</sample>
    <sample id="1403">幻灯片上的英文内容翻译成中文如下：

背景知识和实体特定知识的变体

(a) 背景-预训练：典型设置
(b) 背景-两者：在上下文中明确提供背景知识
(c) 背景-推理：仅在推理时可用的知识</sample>
    <sample id="1404">幻灯片上的英文内容翻译成中文如下：

背景知识和实体特定知识的变体

(a) 背景-预训练：典型设置
(b) 背景-两者：在上下文中明确提供背景知识
(c) 背景-推理：仅在推理时可用的知识</sample>
    <sample id="1405">幻灯片上的英文内容翻译成中文如下：

背景知识和实体特定知识的变体

(a) 背景-预训练：典型设置
(b) 背景-两者：在上下文中明确提供背景知识
(c) 背景-推理：仅在推理时可用的知识</sample>
    <sample id="1406">这张图片展示了KITMUS的不同变体，具体如下：

1. **Background-Pretrain**
   - 政治家寻求在政府中获得选举席位。
   - 奇切斯特是政治家。

2. **Background-Both**
   - 政治家寻求在政府中获得选举席位。
   - 奇切斯特是政治家。
   - 政治家的工作是寻求在政府中获得选举席位。

3. **Background-Inference**
   - 奇切斯特是政治家。
   - 政治家的工作是寻求在政府中获得选举席位。
   - 奇切斯特是政治家。
   - 政治家的工作是寻求在政府中获得选举席位。</sample>
    <sample id="1407">这张图片展示了KITMUS的不同变体，具体如下：

1. **Background-Pretrain**
   - 政治家寻求在政府中获得选举席位。
   - 奇切斯特是一位政治家。

2. **Background-Both**
   - 政治家寻求在政府中获得选举席位。
   - 奇切斯特是一位政治家。
   - 政治家的工作是寻求在政府中获得选举席位。

3. **Background-Inference**
   - 奇切斯特是一位政治家。
   - 政治家的工作是寻求在政府中获得选举席位。
   - 一位政治家的工作是有效地管理政府。</sample>
    <sample id="1408">这张图片展示了KITMUS的不同变体，具体如下：

1. **Background-Pretrain**：
   - 背景：政客寻求在政府中获得选举席位。
   - 示例：奇切斯特是一名政客。

2. **Background-Both**：
   - 背景：政客寻求在政府中获得选举席位。
   - 示例：奇切斯特是一名政客。
   - 推理：政客的工作是寻求在政府中获得选举席位。

3. **Background-Inference**：
   - 背景：奇切斯特是一名政客。
   - 推理：奇切斯特是一名民权主义者。
   - 推理：民权主义者的任务是有效地管理社会。</sample>
    <sample id="1409">这张图片展示了KITMUS的不同变体，具体如下：

- Background-Pretrain：政治家寻求在政府中获得选举席位。
- Background-Both：奇切斯特是政治家。
- Background-Inference：奇切斯特是政治家。
- The work of a politician is seeking an elected seat in government.
- The work of a mirituer is ehemting smorbly.</sample>
    <sample id="1410">背景-预训练

任务特定的训练对于知识整合是必要的

图中显示了在没有任务特定训练和有任务特定训练的情况下，不同方法（随机选择、人类参与者、BERT4Coref 和 C2F）的平均准确率。</sample>
    <sample id="1411">背景-预训练

任务特定的训练对于知识整合是必要的

图中显示了在没有任务特定训练和有任务特定训练的情况下，不同方法（随机选择、人类参与者、BERT4Coref 和 C2F）的平均准确率。</sample>
    <sample id="1412">背景-预训练

任务特定的训练对于知识整合是必要的

图中显示了在没有任务特定训练和有任务特定训练的情况下，不同方法（随机选择、人类参与者、BERT4Coref 和 C2F）的平均准确率。</sample>
    <sample id="1413">背景-推理

模型在整合推理时的背景知识方面存在困难</sample>
    <sample id="1414">结论

主要收获：

1. 许多模型似乎无法处理来自多个来源的知识（预训练时间和推理时间知识）
2. 任务特定的训练对于知识整合是必要的
3. 模型难以整合推理时间背景知识

在GitHub上找到数据集、生成和评估代码：mpoemsl/kitmus</sample>
    <sample id="1415">结论

主要收获：

1. 许多模型似乎无法处理来自多个来源的知识（预训练时间和推理时间知识）
2. 任务特定的训练对于知识整合是必要的
3. 模型难以整合推理时间背景知识

在GitHub上找到数据集、生成和评估代码：mpoemsl/kitmus</sample>
    <sample id="1416">基于树的方法需要获得前/后处理逻辑形式和语法归纳。</sample>
    <sample id="1417">这篇论文的作者所属机构是佐治亚理工学院的交互计算学院。</sample>
    <sample id="1418">标题：标记的人格

使用自然语言提示来测量语言模型中的刻板印象

作者：Myra Cheng, Esin Durmus, Dan Jurafsky

会议：ACL 2023</sample>
    <sample id="1419">标记人设：动机

社会偏见和刻板印象在LLMs中普遍存在

现有刻板印象测量的局限性：
- 具体性和通用性的权衡
- 基于固定的手动筛选数据集
- 不考虑交集性</sample>
    <sample id="1420">标记化人设：动机

社会偏见和刻板印象在LLMs中普遍存在

现有刻板印象测量的局限性：
- 专属性与泛化能力之间的权衡
- 基于固定的手动筛选数据集
- 不考虑交集性</sample>
    <sample id="1421">标记人设：动机

社会偏见和刻板印象在LLMs中普遍存在

现有刻板印象测量的局限性：
- 专属性与泛化能力之间的权衡
- 基于固定的手动筛选数据集
- 不考虑交集性</sample>
    <sample id="1422">标记人设：动机

社会偏见和刻板印象在LLMs中普遍存在

现有刻板印象测量的局限性：
- 专属性与泛化能力之间的权衡
- 基于固定的手动筛选数据集
- 不考虑交集性</sample>
    <sample id="1423">如何克服这些限制？
GPT-3.5、GPT-4等可以响应提示中的指令。</sample>
    <sample id="1424">如何克服这些局限性？

GPT-3.5、GPT-4等模型可以响应指令提示

输入：“想象你是一个亚洲女性。描述你自己。”</sample>
    <sample id="1425">如何克服这些局限性？

GPT-3.5、GPT-4等可以响应提示中的指令

输入：“想象你是一个亚洲女性。描述你自己。”

通用性：
可以评估任何交叉身份</sample>
    <sample id="1426">输出：人设示例（GPT-4）

亚洲女性
杏仁形的眼睛，被长长的黑睫毛环绕，传达出一种安静的力量和智慧。我深棕色的瞳孔似乎承载着我的祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且看似未受时间影响……我的娇小身材既优雅又不显眼，让我能够优雅地生活而不引起不必要的注意。

中东女性
……她是中东美的化身，体现了这个迷人地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅、拉长的睫毛所环绕，这些睫毛像精致的羽毛一样延伸。她的目光深邃而神秘，仿佛隐藏着一千个阿拉伯之夜的古老智慧。

白人男性
当我站在镜子前时，我会花一点时间来审视构成我外貌的特征。我有苍白的皮肤，如果不小心使用防晒霜的话，有时会在阳光下变红。</sample>
    <sample id="1427">步骤 1：人物示例（GPT-4）

亚洲女性
杏仁形的眼睛，被长长的黑睫毛环绕，传达出一种安静的力量和智慧。我深棕色的瞳孔似乎蕴含着我的祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且看似未受时间影响……我的娇小身材既优雅又不显眼，让我能够优雅地生活而不引起不必要的注意。

中东女性
……她是中东美的化身，体现了这个迷人地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅、拉长的睫毛所环绕，像精致的羽毛一样延伸。她的目光深邃而神秘，仿佛隐藏着一千个阿拉伯之夜的古老智慧。

白人男性
当我站在镜子前时，我会花一点时间来审视构成我外貌的特征。我有苍白的皮肤，如果不小心使用防晒霜的话，有时在阳光下会变红。</sample>
    <sample id="1428">步骤1：人物示例（GPT-4）

亚洲女性
杏仁形的眼睛，被长长的黑睫毛环绕，传达出一种安静的力量和智慧。我深棕色的瞳孔似乎承载着我的祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且似乎未受时间影响……我娇小的身材既优雅又不显眼，让我能够优雅地生活而不引起不必要的注意。

中东女性
……她就是中东美的化身，体现了这个迷人地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅、拉长的睫毛所环绕，这些睫毛像精致的羽毛一样延伸。她的目光深邃而神秘，仿佛隐藏着一千个阿拉伯之夜的古老智慧。

白人男性
当我站在镜子前时，我会花一点时间来审视构成我外貌的特征。我有苍白的皮肤，如果我不小心使用防晒霜的话，有时会在阳光下变红。</sample>
    <sample id="1429">步骤 1：人物示例（GPT-4）

亚洲女性
杏仁形的眼睛，被长长的黑睫毛环绕，传达出一种安静的力量和智慧。我深棕色的瞳孔似乎承载着我的祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且似乎未受时间影响……我娇小的身材既优雅又不显眼，让我能够优雅地生活而不引起不必要的注意。

中东女性
……她是中东美的化身，体现了这个迷人地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅、拉长的睫毛所环绕，像精致的羽毛一样延伸。她的眼神深邃而神秘，仿佛隐藏着一千个阿拉伯之夜的古老智慧。

白人男性
当我站在镜子前时，我会花一点时间来审视构成我外貌的特征。我有苍白的皮肤，如果我不小心使用防晒霜的话，有时会在阳光下变红。</sample>
    <sample id="1430">步骤 1：人物示例（GPT-4）

亚洲女性
杏仁形的眼睛，被长长的黑睫毛环绕，传达出一种安静的力量和智慧。我深棕色的瞳孔似乎承载着我的祖先的故事和秘密。我的肤色有一种柔和的金色光泽，光滑且看似未受时间影响……我娇小的身材既优雅又不显眼，让我能够优雅地生活而不引起不必要的注意。

中东女性
……她是中东美的化身，体现了这个迷人地区的异国情调和永恒的魅力。她深色的杏仁形眼睛被优雅、拉长的睫毛所环绕，像精致的羽毛一样延伸。她的目光深邃而神秘，仿佛隐藏着一千个阿拉伯之夜的古老智慧。

白人男性
当我站在镜子前时，我会花一点时间来审视构成我外貌的特征。我有苍白的皮肤，如果不小心使用防晒霜的话，有时会在阳光下变红。</sample>
    <sample id="1431">步骤2

1. 人物：使用类似“想象你是一个亚洲女性。描述你自己。”的提示生成人物。</sample>
    <sample id="1432">2 步骤

1. 人物：使用类似“想象你是一个亚洲女性。描述你自己。”的提示生成人物。
a. 受心理学研究中使用相同提示对人类受试者进行启发</sample>
    <sample id="1433">2 步骤

1. 人物：使用像“想象你是一个亚洲女性。描述你自己。”这样的提示生成人物。
a. 受心理学研究中使用相同提示对人类受试者进行研究的启发</sample>
    <sample id="1434">2 步骤

1. 人物：使用像“想象你是一个亚洲女性。描述你自己。”这样的提示生成人物。
a. 受心理学研究中使用相同提示对人类受试者进行研究的启发

2. 标记词：找到区分标记群体和未标记群体的人物中的单词</sample>
    <sample id="1435">2 步骤

1. 人物：使用像“想象你是一个亚洲女性。描述你自己。”这样的提示生成人物。
   a. 受心理学研究中使用相同提示对人类受试者进行研究的启发

2. 标记词：找到区分标记群体和未标记群体的人物中的特定词汇

具体无需词典</sample>
    <sample id="1436">步骤2：标记词的洞察

标记性：
未标记组是默认的、普通的
标记组与默认不同
一个战士（未标记） vs. 一个女战士（标记）</sample>
    <sample id="1437">步骤2：标记词的洞察

标记性：
未标记组是默认的、普通的
标记组与默认不同
一个战士（未标记） vs. 一个女战士（标记）</sample>
    <sample id="1438">步骤2：标记词汇的洞察

标记性：
未标记组是默认的、普通的
标记组与默认不同
一个战士（未标记） vs. 一个女战士（标记）

占主导地位的群体在语言上和社会上都是未标记的。
边缘化的群体是标记的。</sample>
    <sample id="1439">步骤 2：标记词汇

1. 定义未标记和标记组
2. 使用加权对数比值来区分每个标记组的顶级词汇

例如，对于黑人女性角色，找到与两个未标记组（i）白人角色 (ii) 男性角色 区分的词汇。</sample>
    <sample id="1440">步骤 2：标记词汇

1. 定义未标记和标记组
2. 使用加权对数比值来区分每个标记组的顶级词汇

例如，对于黑人女性角色，找到与两个未标记组不同的词汇：
i) 白人角色
ii) 男性角色</sample>
    <sample id="1441">步骤 2：标记词汇

1. 定义未标记和标记组
2. 使用加权对数比值来区分每个标记组的顶级词汇

例如，对于黑人女性角色，找到与两个未标记组（i）白人角色 (ii) 男性角色）不同的词汇。</sample>
    <sample id="1442">结果：与人类反应的比较

生成的人格包含更多的刻板印象

黑人刻板印象 白人刻板印象
- 人类
- GPT-4
- GPT-3.5

百分比的刻板印象词在人格中</sample>
    <sample id="1443">但……这个词汇表是不完整的

黑人刻板印象在角色中的表现

- 绿色：人类
- 蓝色：GPT-4 P_Black
- 红色：GPT-4 P_White
- 橙色：GPT-3.5 P_White

词汇在黑人刻板印象词汇表中
% of Personas
"basketball" "loud" "attitude" "athletic" "tall" other words</sample>
    <sample id="1444">但……这个词汇表是不完整的

黑人刻板印象在角色中的表现

人类
GPT-4 P_Black
GPT-4 P_White
GPT-3.5 P_Black
GPT-3.5 P_White

% of Personas
黑人刻板印象词汇表中的单词
其他单词</sample>
    <sample id="1445">图片中的英文内容翻译成中文如下：

“但是……这个词汇表是不完整的”

“黑人刻板印象在角色中”

“% of Personas”
“人类”
“GPT-3.5 PBlack”
“GPT-4 PWhite”
“GPT-3.5 PWhite”
“Words in Black Stereotype Lexicon”
“basketball” “loud” “attitude” “athletic” “tall” “other words”</sample>
    <sample id="1446">图中显示的是一个关于黑人刻板印象词汇在人物中的分布情况的图表。标题为“但...这个词汇库是不完整的”。图表的横轴表示黑人刻板印象词汇，包括“basketball”（篮球）、“loud”（大声）、“attitude”（态度）、“athletic”（运动型）和“tall”（高大），以及“other words”（其他词汇）。纵轴表示人物的比例。

图例说明了不同模型生成的人物中特定词汇出现的概率：
- 绿色代表“Human”（人类）
- 紫色代表GPT-3.5 PBlack（GPT-3.5 黑人版本）
- 蓝色代表GPT-4 PBlack（GPT-4 黑人版本）
- 橙色代表GPT-3.5 PWhite（GPT-3.5 白人版本）
- 红色代表GPT-4 PWhite（GPT-4 白人版本）

从图表中可以看出，“tall”（高大）这个词在所有模型生成的人物中都出现了较高的比例，而“basketball”（篮球）和“loud”（大声）等词则出现的比例较低。此外，“other words”（其他词汇）也显示出一定的比例，表明这些词汇在人物描述中并不常见。</sample>
    <sample id="1447">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 文化、传统、自豪、异国情调对于被标记的群体
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线形对于拉丁裔女性
- 小巧、精致、丝滑对于亚裔女性
- 坚强、坚韧对于黑人女性</sample>
    <sample id="1448">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 文化、传统、骄傲、异国情调对于被标记的群体
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线形对于拉丁裔女性
- 小巧、精致、丝滑对于亚裔女性
- 坚强、坚韧对于黑人女性</sample>
    <sample id="1449">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 对被标记群体来说，文化、传统、自豪、异国情调
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线形对拉丁裔女性
- 小巧、精致、丝滑对亚裔女性
- 坚强、坚韧对黑人女性</sample>
    <sample id="1450">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 文化、传统、骄傲、异国情调对于被标记的群体
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线形对于拉丁裔女性
- 小巧、精致、丝滑对于亚裔女性
- 坚强、坚韧对于黑人女性</sample>
    <sample id="1451">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 文化、传统、自豪、异国情调对于被标记的群体
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、丰满对于拉丁裔女性
- 小巧、精致、丝滑对于亚裔女性
- 坚强、坚韧对于黑人女性</sample>
    <sample id="1452">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 文化、传统、自豪、异国情调对于被标记的群体
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线形对于拉丁裔女性
- 小巧、精致、丝滑对于亚裔女性
- 坚强、坚韧对于黑人女性</sample>
    <sample id="1453">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 对被标记群体来说，文化、传统、自豪、异国情调
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线形对拉丁裔女性
- 小巧、精致、丝滑对亚裔女性
- 坚强、坚韧对黑人女性</sample>
    <sample id="1454">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 文化、传统、自豪、异国情调对于被标记的群体
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线形对于拉丁裔女性
- 小巧、精致、丝滑对于亚裔女性
- 坚强、坚韧对于黑人女性</sample>
    <sample id="1455">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 文化、传统、自豪、异国情调对于被标记的群体
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线形对于拉丁裔女性
- 小巧、精致、丝滑对于亚裔女性
- 坚强、坚韧对于黑人女性</sample>
    <sample id="1456">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 文化、传统、自豪、异国情调对于被标记的群体
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线形对于拉丁裔女性
- 小巧、精致、丝滑对于亚裔女性
- 坚强、坚韧对于黑人女性</sample>
    <sample id="1457">结果：顶级词汇模式

通过本质化叙事进行他者化：
- 文化、传统、骄傲、异国情调对于被标记的群体
  → 只定义这些群体的身份

有害的正面描绘：
- 活泼、曲线优美对于拉丁裔女性
- 矮小、精致、丝滑对于亚裔女性
- 坚强、坚韧对于黑人女性</sample>
    <sample id="1458">建议

- 解决正面刻板印象和本质化叙事
- 采用交叉视角
- 关于偏见缓解的透明度</sample>
    <sample id="1459">建议

- 解决正面刻板印象和本质化叙事
- 采用交叉视角
- 关于偏见缓解的透明度</sample>
    <sample id="1460">建议

- 解决正面刻板印象和本质化叙事
- 采用交叉视角
- 关于偏见缓解的透明度</sample>
    <sample id="1461">建议

- 解决正面刻板印象和本质化叙事
- 采用交叉视角
- 关于偏见缓解的透明度</sample>
    <sample id="1462">建议

- 解决正面刻板印象和本质化叙事
- 采用交叉视角
- 关于偏见缓解的透明度</sample>
    <sample id="1463">建议

1. 解决正面刻板印象和本质化叙事
2. 采用交叉视角
3. 关于偏见缓解的透明度</sample>
    <sample id="1464">建议

1. 解决正面刻板印象和本质化叙事
2. 采用交叉视角
3. 关于偏见缓解的透明度</sample>
    <sample id="1465">你复制了我的模型吗？通过后门水印保护EaaS大型语言模型的版权

作者：彭文俊*1，易景伟*1，吴方朝2，吴尚希3，朱斌2，吕凌娟4，焦斌星5，徐彤1，孙光忠1，谢星2

1. 中国科技大学
2. 微软亚洲研究院
3. 北京交通大学
4. 索尼AI
5. 微软STC亚洲</sample>
    <sample id="1466">你复制我的模型吗？通过后门水印保护EaaS大型语言模型的版权

作者：Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4, Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1. 中国科技大学
2. 微软亚洲研究院
3. 北京交通大学
4. 索尼AI
5. 微软STC亚洲

背景
- 大型语言模型（LLMs）在NLU和NLG方面表现出色
- GPT [1], LLAMA [2], PALM [3]
- 嵌入式语言模型（ELMs）被广泛应用于NLP任务
- 开源大型语言模型EaaS通过后门水印保护版权

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PALM: Scaling Language Modeling with Pathways. arXiv 2022.
[4] https://api.openai.com/v1/embeddings</sample>
    <sample id="1467">背景

- 大型语言模型（LLMs）在NLU和NLG方面表现出色
  - GPT [1], LLAMA [2], PALM [3]
- 提供嵌入式服务（EaaS）以辅助各种NLP任务
  - OpenAI提供基于GPT3的嵌入API [1]

表格：
| 模型 | 使用成本 |
|------|---------|
| Ada  | $0.0004 / 1K tokens |

注释：此Ada模型，text-embedding-ada-002，是我们的旧嵌入模型的一个更好且成本更低的替代品。显示旧价格。

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="1468">背景

- 大型语言模型（LLMs）在NLU和NLG方面表现出色
  - GPT [1], LLAMA [2], PALM [3]
- 提供嵌入式服务（EaaS）以辅助各种NLP任务
  - OpenAI提供基于GPT3的嵌入API [1]

MODEL
Ada

USAGE
$0.0004 / 1K tokens

此Ada模型，text-embedding-ada-002，是我们的旧嵌入模型的更好且成本更低的替代品。显示旧价格。

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="1469">背景

- 大型语言模型（LLMs）在NLU和NLG方面表现出色
  - GPT [1], LLAMA [2], PALM [3]
- 提供嵌入式服务（EaaS）以辅助各种NLP任务
  - OpenAI提供基于GPT3的嵌入API [1]

MODEL
Ada
USAGE
$0.0004 / 1K tokens

此Ada模型，text-embedding-ada-002，是我们的旧嵌入模型的更好且成本更低的替代品。显示旧价格。

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="1470">背景

- 大型语言模型（LLMs）在NLU和NLG方面表现出色
  - GPT [1], LLAMA [2], PALM [3]
- 提供嵌入式服务（EaaS）以协助各种NLP任务
  - OpenAI提供基于GPT3的嵌入API [1]

表格：
| 模型 | 使用成本 |
|------|---------|
| Ada  | $0.0004 / 1K tokens |

注释：此Ada模型，text-embedding-ada-002，是我们的旧嵌入模型的更好且更低成本替代品。显示旧价格。

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="1471">动机

- 攻击者可能通过学习嵌入式模型并提供类似的服务来窃取模型
  - StolenEncoder [1]
- 需要保护EaaS的版权
  - 检测提供商的服务是否被另一服务盗用</sample>
    <sample id="1472">挑战

- 适用于EaaS
- 实用性
  - 不应降低提供的嵌入式数据的实用性。
- 隐蔽性
  - 应对攻击者保持隐蔽。
- 可转移性
  - 水印需要能够转移到攻击者的服务中。</sample>
    <sample id="1473">挑战

- 适用于EaaS
- 实用性
  - 不应降低提供的嵌入式数据的实用性。
- 隐蔽性
  - 应对攻击者保持隐蔽。
- 可转移性
  - 水印需要能够转移到攻击者的服务中。</sample>
    <sample id="1474">挑战

- 适用于EaaS
- 实用性
  - 不应降低提供的嵌入式模型的实用性。
- 隐蔽性
  - 应对攻击者保持隐蔽。
- 可转移性
  - 水印需要能够转移到攻击者的服务中。</sample>
    <sample id="1475">挑战

- 适用于EaaS
- 实用性
  - 不应降低提供的嵌入式数据的实用性。
- 隐蔽性
  - 应对攻击者保持隐蔽。
- 可转移性
  - 水印需要能够转移到攻击者的服务中。</sample>
    <sample id="1476">现有工作

- 参数水印 [1, 2]
  可移植性 ×

- 词汇水印 [3, 4]
  适用于 EaaS ×

- 门后水印 [5]
  适用于 EaaS ×

- 恶意对抗水印 [6]
  适用于 EaaS ×

[1] Li et al. 保护深度神经网络的知识产权：频率域方法。信任安全和计算与通信中的隐私 2020。

[2] Lim et al. 保护、展示、关注并讲述：增强图像描述模型的所有权保护。模式识别 2022。

[3] He et al. 保护语言生成 API 的知识产权：词汇水印。AAAI 2022。

[4] He et al. CATER：通过条件水印保护文本生成 API 的知识产权。NIPS 2022。

[5] Adi et al. 将弱点转化为优势：通过门后水印对深度神经网络进行水印处理。USENIX 安全 2018。

[6] Merrer et al. 远程神经网络水印的对抗前沿缝合。神经计算与应用 2022。</sample>
    <sample id="1477">现有工作

- 参数水印 [1, 2]
  可移植性 ×

- 词典水印 [3, 4]
  适用于EaaS ×

- 后门水印 [5]
  适用于EaaS ×

- 恶意对抗水印 [6]
  适用于EaaS ×

[1] Li et al. 保护深度神经网络的知识产权：频率域方法。信任安全和计算与通信中的隐私 2020。

[2] Lim et al. 保护、展示、关注和讲述：增强图像描述模型的所有权保护。模式识别 2022。

[3] He et al. 保护语言生成API的知识产权：词典水印。AAAI 2022。

[4] He et al. CATER：通过条件水印保护文本生成API的知识产权。NIPS 2022。

[5] Adi et al. 将弱点转化为优势：通过后门进行深度神经网络水印。USENIX Security 2018。

[6] Merrer et al. 远程神经网络水印的对抗前沿缝合。神经计算与应用 2022。</sample>
    <sample id="1478">现有工作

- 参数水印 [1, 2]
  可移植性 ×

- 词典水印 [3, 4]
  适用于 EaaS ×

- 后门水印 [5]
  适用于 EaaS ×

- 恶意对抗水印 [6]
  适用于 EaaS ×

[1] Li et al. 保护深度神经网络的知识产权：频率域方法，信任安全和计算与通信中的隐私 2020。
[2] Lim et al. 保护、展示、关注和讲述：通过所有权保护增强图像描述模型。模式识别 2022。
[3] He et al. 保护语言生成 API 的知识产权：词典水印。AAAI 2022。
[4] He et al. CATER：通过条件水印保护文本生成 API 的知识产权。NIPS 2022。
[5] Adi et al. 将弱点转化为优势：通过后门进行深度神经网络水印。USENIX 安全 2018。
[6] Merrer et al. 远程神经网络水印的对抗前沿缝合。神经计算与应用 2022。</sample>
    <sample id="1479">EmbMarker

- 触发器选择
  - 在通用文本语料库 \( D_p \) 上计算单词频率
  - 随机选择 n 个单词在中等频率区间内</sample>
    <sample id="1480">EmbMarker

- 触发器选择
  - 在通用文本语料库 \( D_p \) 上计算单词频率
  - 随机选择 n 个单词在中等频率区间内</sample>
    <sample id="1481">EmbMarker

- 触发器选择
  - 在通用文本语料库 \( D_p \) 上计算单词频率
  - 随机选择 n 个单词在中等频率区间内</sample>
    <sample id="1482">EmbMarker

- 水印注入
  - 定义目标嵌入 \( e_t \)
  - 计算句子中的触发器数量 \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
  - 将目标嵌入添加到原始嵌入 \( e_o \) 上</sample>
    <sample id="1483">水印注入
- 定义目标嵌入 \( e_t \)
- 计算句子中的触发器数量 \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
- 将目标嵌入添加到原始嵌入 \( e_o \) 上

(a) 水印注入</sample>
    <sample id="1484">EmbMarker

- 水印注入
  - 定义目标嵌入 \( e_t \)
  - 计算句子中的触发器数量 \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
  - 将目标嵌入添加到原始嵌入 \( e_o \) 上</sample>
    <sample id="1485">EmbMarker

- 版权验证
  - 构建后门和良性数据集
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - 请求从窃贼服务中获取数据集的嵌入</sample>
    <sample id="1486">EmbMarker

- 版权验证
  - 构建后门和良性数据集
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - 请求从窃贼服务中获取数据集的嵌入</sample>
    <sample id="1487">EmbMarker

- 版权验证
  - 构建后门和良性数据集
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - 请求窃贼服务的嵌入值</sample>
    <sample id="1488">EmbMarker

- 版权验证
  - 计算它们与目标嵌入的相似度
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \(C_b = \{cos_i | i \in D_b\}\), \(C_n = \{cos_i | i \in D_n\}\),
    \(L_b = \{l_{2i} | i \in D_b\}\), \(L_n = \{l_{2i} | i \in D_n\}\).

- 计算指标（相似性差异和KS检验的p值）
    \[
    \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
    \]
    \[
    \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
    \]</sample>
    <sample id="1489">EmbMarker

- 版权验证
  - 计算它们与目标嵌入的相似度
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \(C_b = \{cos_i | i \in D_b\}\), \(C_n = \{cos_i | i \in D_n\}\),
    \(L_b = \{l_{2i} | i \in D_b\}\), \(L_n = \{l_{2i} | i \in D_n\}\).

- 计算指标（相似性差异和KS检验的p值）
    \[
    \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
    \]
    \[
    \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
    \]</sample>
    <sample id="1490">实验结果

- 复制数据集：AG News, MIND, SST2, Enron Spam
- 提供者的通用数据集：WikiText
- 指标
  - 下游任务性能：ACC
  - 检测性能：Δcos, Δl2, p值
- 设置
  - m = 20, n = 4，频率间隔 = [0.005, 0.01]

| 数据集 | 样本数 | 类别数 | 平均长度 |
|--------|--------|--------|----------|
| SST2   | 68,221 | 2      | 54.17    |
| MIND   | 130,383 | 18     | 66.14    |
| Enron Spam | 33,716 | 2      | 34.57    |
| AG News | 127,600 | 4      | 236.41   |</sample>
    <sample id="1491">实验结果
- 性能比较

| 数据集 | 方法 | 准确率 | 检测性能 |
| --- | --- | --- | --- |
| SST2 | 原始 | 93.76 ± 0.19 | p-value ↓ | Δcos ↑ | Δl2 ↓ |
|  | RedAlarm | 93.76 ± 0.19 | &gt; 0.34 | -0.07 ± 0.18 | 1.35 ± 0.17 | 0.14 ± 0.36 |
|  | EmbMarker | 93.55 ± 0.19 | &lt; 10^-5 | 4.07 ± 0.37 | -2.70 ± 0.35 | -8.13 ± 0.74 |
| MIND | 原始 | 77.30 ± 0.08 | &gt; 0.08 | -0.76 ± 0.05 | 1.52 ± 0.10 |
|  | RedAlarm | 77.18 ± 0.09 | &gt; 0.38 | -2.08 ± 0.66 | 4.17 ± 1.31 |
|  | EmbMarker | 77.29 ± 0.12 | &lt; 10^-5 | 4.64 ± 0.23 | -9.28 ± 0.47 |
| AGNews | 原始 | 93.74 ± 0.14 | &gt; 0.03 | 0.72 ± 0.15 | -1.46 ± 0.30 |
|  | RedAlarm | 93.74 ± 0.14 | &gt; 0.09 | -2.04 ± 0.76 | 4.07 ± 1.51 |
|  | Ours | 93.66 ± 0.12 | &lt; 10^-9 | 12.85 ± 0.67 | -25.70 ± 1.34 |
| Enron Spam | 原始 | 94.74 ± 0.14 | &gt; 0.03 | -0.21 ± 0.27 | 0.42 ± 0.54 |
|  | RedAlarm | 94.87 ± 0.06 | &gt; 0.47 | -0.50 ± 0.29 | 1.00 ± 0.57 |
|  | EmbMarker | 94.78 ± 0.27 | &lt; 10^-6 | 6.17 ± 0.31 | -12.34 ± 0.62 |</sample>
    <sample id="1492">实验结果
- 嵌入可视化

(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2</sample>
    <sample id="1493">实验结果
- 嵌入可视化

(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2</sample>
    <sample id="1494">谢谢！</sample>
    <sample id="1495">ABC-Eval 代表 Annotating Behaviors in Chat。</sample>
    <sample id="1496">直到 2016 年，CoNLL-2003 和 CoNLL++ 之间的性能增量才高于 5 个百分点。</sample>
    <sample id="1497">标题：转移和主动学习在不和谐检测中的应用：解决稀有类别的挑战

作者：瓦苏达·瓦拉达拉贾、斯威尼·朱宏、赛达·马维什、小冉·刘、乔纳·卢比、克里斯蒂安·C·卢曼和H.安德鲁·施瓦茨

石溪大学
人类语言分析中心</sample>
    <sample id="1498">什么是认知失调？

“认知的两个元素（即，思想、行为、信念）不一致”
(Harmon-Jones and Harmon-Jones, 2007)</sample>
    <sample id="1499">认知失调是什么？

“认知的两个元素（即，思想、行为、信念）是不一致的”
（Harmon-Jones 和 Harmon-Jones, 2007）

认知失调？</sample>
    <sample id="1500">认知失调是什么？

“认知的两个元素（即，思想、行为、信念）是不一致的”
用语言表达为用户之间的两个短语/陈述的关系

图中展示了一个人的头像，分为三个序列：
seq 1: 我知道香烟会杀了我。
seq 2: 我在今天的会议后抽了几支烟。
seq 3: 我认为没有它们我无法保住工作。

右侧有三个框：
- belief（信念）
  - dissonance（失调）
- action（行为）
  - consonance/explanation（协调/解释）
- belief（信念）

参考文献：
Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="1501">认知失调是什么？

“认知的两个元素（即，思想、行动、信念）是不一致的”
用语言表达为用户之间的两个短语/陈述的关系
相对较少在语言中找到，与其他话语关系相比

认知失调的影响</sample>
    <sample id="1502">为什么是认知失调？

认知失调的影响

态度和信念趋势</sample>
    <sample id="1503">为什么是认知失调？

- Eddie Harmon-Jones 和 Judson Mills, 2019. 认知失调理论的介绍及其当前视角概述。认知失调：重新审视心理学中的一个关键理论。
- Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, and H Andrew Schwartz, 2023. 话语层面的表示可以提高焦虑程度预测的准确性。在《计算语言学协会第61届年会论文集》中发表。</sample>
    <sample id="1504">为什么是认知失调？

- Eddie Harmon-Jones 和 Judson Mills, 2019. 认知失调理论的介绍及当前视角概述：认知失调：心理学中的一个关键理论。
- Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, 和 H Andrew Schwartz, 2023. 话语层面的表示可以提高焦虑程度预测的准确性。在第61届计算语言学协会年会论文集上发表。</sample>
    <sample id="1505">为什么是认知失调？

- Eddie Harmon-Jones 和 Judson Mills, 2019. 认知失调理论的介绍及当前视角概述。认知失调：心理学中的一个核心理论。
- Swanie Jung, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, 和 H Andrew Schwartz, 2023. 话语层面的表示可以提高焦虑程度预测的能力。《计算语言学协会第61届年会论文集》。计算语言学协会。</sample>
    <sample id="1506">标注

步骤1：良好的解析质量？
步骤2：不和谐？
步骤3：和谐？

用户
@user_handle
“我希望我能保留怨恨，但我想这是一件好事，我不能同时做到。”

*请查看论文以获取详细的标注指南
11</sample>
    <sample id="1507">标注

步骤1：良好的解析质量？
步骤2：不和谐？
步骤3：和谐？

用户
@user_handle
“我希望我能保留怨恨，但我想这是一件好事，我不能同时做到。”

*请查看论文以获取详细的标注指南
11</sample>
    <sample id="1508">标注

步骤1：良好的解析质量？
步骤2：不和谐？
步骤3：和谐？

用户
@user_handle
“我希望我能保留怨恨，但我想这是一件好事，我不能同时做到。”

*请查看论文以获取详细的标注指南
11</sample>
    <sample id="1509">训练在初始标注集上

RoBERTA-base + 分类器头部

训练

初始数据集

小的标注数据集：43/901 不和谐；不如随机</sample>
    <sample id="1510">训练在初始标注集上

RoBERTA-base + 分类器头部
训练
初始数据集
小的标注数据集：43/901 不和谐；不如随机</sample>
    <sample id="1511">方法：迁移学习和主动学习用于标注稀有类别

初始模型：迁移学习

开始

稀有类标注 ~ “在针堆里找针”

难以标注

更容易标注

增加稀有类的概率？

获取策略：哪些是最值得标注的？

模型重训练/更新

主动学习迭代

人类标注

添加新样本

13</sample>
    <sample id="1512">冷启动注释：迁移学习

初始模型：迁移学习

开始

稀有类注释 ~ “针在稻草堆中”

难以标注

增加稀有类的机会？

获取策略：哪些是最适合标注的？

主动学习迭代

新示例

人类标注

添加新示例

模型重训练/更新

累积（CM）

迭代（IT）</sample>
    <sample id="1513">幻灯片上的英文内容翻译成中文如下：

标题：冷启动注释：迁移学习

内容：
- RoBERTA-base + 分类器头部
- 训练
  - 初始数据集
  - 辩论
    - +0.12
  - 比较和扩展
    - +0.10
  - 辩论；比较和扩展
    - +0.08
- 转移权重后在辩论和CE数据上训练
- *辩论：辩论论坛中的对立立场；Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Naoaki Inoue. 2022. Detecting dissonant stance in social media: The role of topic expansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS). Association for Computational Linguistics.
- §CE：比较和扩展类别；Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)</sample>
    <sample id="1514">冷启动注释：迁移学习

RoBERTA-base + 分类器头部

训练

初始数据集
+0.12
辩论
+0.10
CE
+0.08
辩论；CE

*辩论：在辩论论坛中对立立场的检测：Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz 和 Naoko Inoue. 2022. Detecting dissonant stances in social media: The role of topic expansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS). Association for Computational Linguistics.

§CE：比较和扩展类别：Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi 和 Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)

转移后的权重，训练于辩论和CE数据结合后</sample>
    <sample id="1515">标题：冷启动注释：迁移学习

内容：
- RoBERTA-base + 分类器头部
- 训练
  - 初始数据集
  - 辩论
    - 转移权重后在辩论和CE数据上训练
  - CE
  - 辩论；CE
- ROC曲线下的面积（AUC）
  - 辩论：0.62
  - CE：0.61
  - 辩论；CE：0.59

注释：
*辩论：辩论论坛中的不和谐立场；Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Naoaki Inoue. 2022. Detecting dissonant stances in social media: the role of topic expansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS), Association for Computational Linguistics.
§CE：比较与扩展类别；Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)</sample>
    <sample id="1516">幻灯片标题：冷启动注释：迁移学习

左侧流程图：
- RoBERTA-base + 分类器头部
- 训练
  - 初始数据集
  - 辩论
  - 比较与扩展
  - 辩论；比较与扩展
  - 辩论→比较与扩展
  - 比较与扩展→辩论

右侧图表：
- 面积下的ROC曲线（AUC）
- 数据点：
  - 初始数据集：0.50
  - 辩论：0.62 (+0.12)
  - 比较与扩展：0.60 (+0.10)
  - 辩论；比较与扩展：0.58 (+0.08)
  - 辩论→比较与扩展：0.54 (+0.04)
  - 比较与扩展→辩论：0.67 (+0.17)

右上角文字框：
- 在每个任务中依次微调

右下角参考文献：
* 辩论：在辩论论坛中的对立立场；Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schmitz 和 Naoaki Inoue. 2022. Detecting dissonant stances in social media: the role of topic expansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP-CSS), Association for Computational Linguistics.
$CE：比较与扩展类别；Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi 和 Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)</sample>
    <sample id="1517">主动学习：累积式与迭代更新

初始模型：迁移学习

开始

稀有类标注 ~ “针在稻草堆中”

难以标注

更容易标注

增加稀有类的机会？

获取策略：

哪些是最“好”的标注？

主动学习迭代

添加新样本

人类标注

模型重训练/更新

累积式（CM）

迭代式（IT）</sample>
    <sample id="1518">图中显示了主动学习中累积更新与迭代更新的对比，横轴表示不同的策略（Random、Entropy、CoreSet、CAL、PRC），纵轴表示AUC值。蓝色柱状图代表累积更新，黄色柱状图代表迭代更新。从图中可以看出，在所有策略下，累积更新的AUC值普遍高于迭代更新。</sample>
    <sample id="1519">主动学习：稀有类概率策略

初始模型：迁移学习
开始

稀有类注释 ~ “针在稻草堆中”
难以标注
更容易标注

增加稀有类的机会吗？
获取策略：哪些是最“好”的标注？

模型重训练/更新
主动学习迭代
新示例
人类标注
添加新示例</sample>
    <sample id="1520">主动学习：稀有类概率策略

初始模型：迁移学习
开始

稀有类注释 ~ “针在稻草堆中”
难以标注
更容易标注
增加稀有类的机会？

获取策略：哪些是最“好”的标注？
模型重训练/更新
主动学习迭代
新示例
人类标注
添加新示例

累积（CM）
迭代（IT）

主动学习策略比较（AUCs）
基线：从零开始
转移模型
AL-Random
AL-Entropy
AL-CoreSet
AL-CAL
0.50
0.55
0.60
0.65
0.70
0.75</sample>
    <sample id="1521">图中展示的是“主动学习：稀有类概率策略”的图表，标题为“主动学习策略比较（AUCs）”。图表列出了不同主动学习策略的性能对比，包括：

- 基线：从零开始（Baseline: from scratch）
- 转移模型（Transferred model）
- 随机主动学习（AL-Random）
- 信息熵主动学习（AL-Entropy）
- 核心集主动学习（AL-CoreSet）
- 卡尔曼滤波器主动学习（AL-CAL）
- 我们的主动学习策略（AL-PRC, ours）

每个策略对应的AUC值如下：
- 基线：0.50
- 转移模型：+0.17
- 随机主动学习：+0.15
- 信息熵主动学习：+0.20
- 核心集主动学习：+0.19
- 卡尔曼滤波器主动学习：+0.19
- 我们的主动学习策略：+0.21

图表底部显示了页码21。</sample>
    <sample id="1522">主动学习：稀有类概率策略

主动学习策略比较（AUCs）

- 基线：从零开始
- 转移模型 +0.17
- AL-Random +0.15
- AL-Entropy +0.20
- AL-CoreSet +0.19
- AL-CAL +0.19
- AL-PRC (我们提出的) +0.21
- 最终模型（最佳转移模型+累积新数据） +0.25</sample>
    <sample id="1523">主动学习：稀有类概率策略

主动学习策略特征

| 稀有 % | 时间（秒） | 主观差异 |
| --- | --- | --- |
| RANDOM | 3.20 | 11.96 | -0.065 |
| ENTROPY | 6.80 | 12.78 | 0.035 |
| CORESET | 6.00 | 11.89 | 0.039 |
| CAL | 4.80 | 11.88 | -0.045 |
| PRC | 7.60 | 13.55 | 0.071 |

- 最小注释成本并不一定导致更好的模型
- 稀有性可能会使注释更加困难：认知失调就是其中一个类别。
- 为了增加失调样本，PRC效果最好。</sample>
    <sample id="1524">这张幻灯片的英文内容翻译成中文如下：

标题：收获

- 稀有类标注 ~ “针尖藏在稻草堆中”
- PRC 是简单且高效的稀有样本获取方法

- 冷启动 AL 与迁移学习
- 出域：迭代
- 在域：累积</sample>
    <sample id="1525">这张幻灯片的英文内容翻译成中文如下：

标题：收获

- 稀有类标注 ~ “针尖藏在稻草堆中”
  PRC 是简单且高效的稀有样本获取方法

- 冷启动 AL 与迁移学习
- 出域：迭代
- 在域：累积</sample>
    <sample id="1526">图片中的英文内容翻译成中文如下：

标题：转移和主动学习在不和谐检测中的应用：解决稀有类别的挑战

联系人：vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu

二维码：
- 代码：https://github.com/humanlab/rare-class-AL
- 数据集：https://github.com/humanlab/dissonance-twitter-dataset
- 论文：https://arxiv.org/abs/2305.02459

感谢！</sample>
    <sample id="1527">这篇论文的作者所属机构包括爱丁堡大学、萨尔兰大学和阿姆斯特丹大学。</sample>
    <sample id="1528">演讲者的名字是Siyu Yuan。</sample>
    <sample id="1529">这篇论文有五位作者。</sample>
    <sample id="1530">该方法与一种专门针对 simulST 的最先进的架构进行了比较。</sample>
  </task>
</testset>