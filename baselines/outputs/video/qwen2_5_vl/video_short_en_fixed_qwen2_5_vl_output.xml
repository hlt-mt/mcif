<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="en">
    <sample id="0">The main data sources for language models include websites like patents.google.com, en.wikipedia.org, and en.m.wikipedia.org.</sample>
    <sample id="1">The affiliations of the authors of the paper are McGill University/Mila and Microsoft Research.</sample>
    <sample id="35">The name of the speaker is not explicitly mentioned in the image provided. The image lists authors and affiliations but does not include the name of the speaker.</sample>
    <sample id="36">The T5 XL model was used to obtain the 82%-87% accuracy when the LM has access to partially overlapping background knowledge.</sample>
    <sample id="37">Yes, CoNLL-2003 taggers still work.</sample>
    <sample id="38">The novelty of the proposed human evaluation method, as shown in the image, lies in its focus on annotating behaviors in chat interactions (ABC-Eval). This method allows for the assessment of how well a chatbot responds to user inputs by evaluating aspects such as relevance, empathy, and self-contradiction. The novelty is in providing a structured way to measure these behaviors, which can help improve the quality and user experience of chatbots.</sample>
    <sample id="39">The success of the existing weakly supervised approach heavily relies on the quality of the weak labels used for validation.</sample>
    <sample id="40">The image does not provide specific information about how to improve the score or what kind of advances can be made. It appears to be a slide from a presentation about background knowledge in music, mentioning Google search links for songs and instructions for annotators to listen to and read about each song. There is no direct information on improving scores or making advances.</sample>
    <sample id="41">There are five authors involved in the paper.</sample>
    <sample id="75">There are three authors involved in the paper: Matthias Lindemann, Alexander Koller, and Ivan Titov.</sample>
    <sample id="76">The domains that are simplified more, according to the chart on the left, are "bible" and "fiction." These domains have the highest values for all three types of simplification (Simplicity, LexSimp, and StructSimp) compared to "news" and "L2."</sample>
    <sample id="77">The example provided in the slide is "I saw Bart and Lisa; Homer came and sneezed." This sentence demonstrates the preference for shorter left conjuncts, as "Bart and Lisa" is shorter than "Homer came and sneezed."</sample>
    <sample id="78">Yes, you can use the DrBERT models for your research as they are freely available under the MIT license.</sample>
    <sample id="79">DEplain-APA contains documents from APA (American Psychological Association) style.</sample>
    <sample id="80">Better model architecture, larger model size, and more fine-tuning examples.</sample>
    <sample id="81">The tendency for left conjuncts to be shorter was measured by extracting statistics from an enhanced version of the Penn Treebank, as referenced in Marcus et al. (1993) and Ficler and Goldberg (2016).</sample>
    <sample id="82">The experiments were designed by varying the length of conjuncts and measuring the proportion of shorter left conjuncts depending on the absolute difference of conjunct lengths, with confidence bands.</sample>
    <sample id="83">The baseline classifier, when trained on an initial annotated set, performs poorly with an Area under the ROC curve (AUC) of approximately 0.5, which is not better than chance.</sample>
    <sample id="84">There are four authors involved in the paper.</sample>
    <sample id="85">The characters' names in the example conversation are not provided in the image. The image only shows cartoon characters with speech bubbles, but their names are not mentioned.</sample>
    <sample id="86">Formality and lexical cohesion.</sample>
    <sample id="87">The affiliations of the authors of the paper are from Johns Hopkins University, Purdue University, and Meta AI.</sample>
    <sample id="88">The image is a slide from a presentation titled "Compositional Generalization without Trees using Multiset Tagging and Latent Permutations." The authors listed on the slide are Matthias Lindemann, Alexander Koller, and Ivan Titov. Below the title and authors' names, there are logos representing various institutions and organizations involved in the research or the presentation. These include:

- The University of Edinburgh (Informatics)
- NLP UKRI Centre for Doctoral Training
- Saarland University
- UvA (University of Amsterdam)

In the top right corner of the slide, there is a small video feed showing a person speaking, presumably the presenter. The background of this video feed appears to be an office setting with desks and computers.</sample>
    <sample id="89">The image is a slide from a presentation with the following text:

**Title:**
Compositional Generalization without Trees using Multiset Tagging and Latent Permutations

**Authors:**
Matthias Lindemann, Alexander Koller, Ivan Titov

**Logos:**
- The University of Edinburgh (Informatics)
- NLP UKRI Centre for Doctoral Training
- Saarland University
- UvA (University of Amsterdam)

The slide also includes a small video feed in the top right corner showing a person speaking.</sample>
    <sample id="90">Compositional Generalization

Ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training.</sample>
    <sample id="91">The image is a slide from a presentation titled "Compositional Generalization in Semantic Parsing." The slide is divided into two sections, labeled "Train:" and contains examples of semantic parsing.

1. **First Example:**
   - **English Sentence:** "The girl slept."
   - **Semantic Parse:** 
     ```
     *girl x_1 sleep.agent x_2 x_1
     ```

2. **Second Example:**
   - **English Sentence:** "Mary knew that the girl slept."
   - **Semantic Parse:** 
     ```
     *girl x_4 know.agent x_1 Mary ∧ know.ccomp x_1 x_5 ∧
     sleep.agent x_5 x_4
     ```

The slide uses color coding to highlight different parts of the sentences and their corresponding semantic parses. The text is presented in a clear, structured format with a yellow header for emphasis.</sample>
    <sample id="92">The image is a slide titled "Compositional Generalization in Semantic Parsing." It contains two examples of training data for semantic parsing:

1. The first example is:
   - Sentence: "The girl slept."
   - Semantic parse: "*girl x_1 sleep.agent x_2 x_1"

2. The second example is:
   - Sentence: "Mary knew that the girl slept."
   - Semantic parse: "*girl x_4 know.agent x_1 Mary ∧ know.ccomp x_1 x_5 ∧ sleep.agent x_5 x_4"

The text is presented in a table format with colored highlights to distinguish different parts of the sentence and the corresponding semantic parse.</sample>
    <sample id="93">The image is a slide titled "Compositional Generalization in Semantic Parsing." It is divided into two sections: "Train" and "Test."

### Train:
1. **Sentence:** The girl slept.
   - **Semantic Representation:** *girl x_1 sleep.agent x_2 x_1*

2. **Sentence:** Mary knew that the girl slept.
   - **Semantic Representation:** *girl x_4 know.agent x_1 Mary ∧ know.ccomp x_1 x_5 ∧ sleep.agent x_5 x_4*

### Test:
**Sentence:** Jim said that Mary knew that the girl slept.
- **Semantic Representation:** *girl x_7 say.agent x_1 Jim ∧ say.ccomp x_1 x_4 ∧ know.agent x_4 Mary ∧ know.ccomp x_4 x_8 ∧ sleep.agent x_8 x_7*</sample>
    <sample id="94">The image is a slide titled "Compositional Generalization in Semantic Parsing." It is divided into two sections: "Train" and "Test."

### Train:
1. **Sentence:** The girl slept.
   - **Semantic Representation:** *girl x_1 sleep.agent x_2 x_1*

2. **Sentence:** Mary knew that the girl slept.
   - **Semantic Representation:** *girl x_4 know.agent x_1 Mary ∧ know.ccomp x_1 x_5 ∧ sleep.agent x_5 x_4*

### Test:
**Sentence:** Jim said that Mary knew that the girl slept.
- **Semantic Representation:** *girl x_7 say.agent x_1 Jim ∧ say.ccomp x_1 x_4 ∧ know.agent x_4 Mary ∧ know.ccomp x_4 x_8 ∧ sleep.agent x_8 x_7*

The slide uses colored text to highlight different parts of the sentences, with each part corresponding to a specific semantic role or relation.</sample>
    <sample id="95">The image is a slide titled "Compositional Generalization in Semantic Parsing." It is divided into two sections: "Train" and "Test," with a note at the bottom stating "Naive seq2seq models fail!"

### Train:
1. **Sentence:** The girl slept.
   - **Semantic Parse:** *girl x_1 sleep.agent x_2 x_1*

2. **Sentence:** Mary knew that the girl slept.
   - **Semantic Parse:** *girl x_4 know.agent x_1 Mary ∧ know.ccomp x_1 x_5 ∧ sleep.agent x_5 x_4*

### Test:
**Sentence:** Jim said that Mary knew that the girl slept.
- **Semantic Parse:** *girl x_7 say.agent x_1 Jim ∧ say.ccomp x_1 x_4 ∧ know.agent x_4 Mary ∧ know.ccomp x_4 x_8 ∧ sleep.agent x_8 x_7*

At the bottom of the slide, it states in red text: "Naive seq2seq models fail!"</sample>
    <sample id="96">The image is a slide titled "Compositional Generalization in Semantic Parsing." It is divided into two sections: "Train" and "Test," with a note at the bottom stating "Naive seq2seq models fail!"

### Train:
1. **Sentence:** The girl slept.
   - **Semantic Parse:** *girl x_1 sleep.agent x_2 x_1*

2. **Sentence:** Mary knew that the girl slept.
   - **Semantic Parse:** *girl x_4 know.agent x_1 Mary ∧ know.ccomp x_1 x_5 ∧ sleep.agent x_5 x_4*

### Test:
**Sentence:** Jim said that Mary knew that the girl slept.
- **Semantic Parse:** *girl x_7 say.agent x_1 Jim ∧ say.ccomp x_1 x_4 ∧ know.agent x_4 Mary ∧ know.ccomp x_4 x_8 ∧ sleep.agent x_8 x_7*

At the bottom of the slide, it states in red text: "Naive seq2seq models fail!"</sample>
    <sample id="97">The text in the image reads:

"Trees help a lot but..."

The diagram below the text shows a tree structure with the following elements:
- The root node is labeled "sleep.agent x2 x1"
- There are two branches leading to the root node, each labeled with:
  - "*girl x1;"
  - "x1"

At the bottom of the tree, it says:
"The girl slept."</sample>
    <sample id="98">The image contains a slide with a title and a tree diagram. The title at the top reads "Trees help a lot but..." in yellow text on a white background. Below the title, there is a tree diagram that represents a sentence structure. The tree diagram includes the following elements:

- At the top level, there is a node labeled "*girl x1; sleep.agent x2 x1".
- Below this, there are two branches:
  - One branch has a node labeled "*girl x1;".
  - The other branch has a node labeled "sleep.agent x2".
- At the bottom level of the tree, there are two nodes:
  - One node is labeled "The girl" in orange.
  - The other node is labeled "slept." in green.

The overall structure visually represents the sentence "The girl slept." with the tree diagram showing the relationships between the words and their grammatical roles.</sample>
    <sample id="99">The image contains a slide with the title "Trees help a lot but..." at the top in yellow text. Below the title, there is a tree diagram representing a sentence structure. The tree diagram includes the following elements:

- At the top level: "*girl x1; sleep.agent x2 x1"
- At the second level: "*girl x1; x1 sleep.agent x2"
- At the third level: "The girl slept."

Below the tree diagram, there is a note that says:
"Trees need to be obtained:
- Pre/Post-processing logical forms"

The slide number "4" is located in the bottom right corner.</sample>
    <sample id="100">Trees help a lot but...

*girl x₁; sleep.agent x₂ x₁

*girl x₁; x₁ sleep.agent x₂

The girl slept.

Trees need to be obtained:
- Pre/Post-processing logical forms</sample>
    <sample id="101">The slide is titled "Trees help a lot but..." and contains a linguistic tree diagram with the following elements:

- The top of the tree has two branches: one labeled "*girl x1;" and the other labeled "sleep.agent x2 x1."
- Below these branches, there is another level of the tree with the label "x1" connecting to both "*girl x1;" and "sleep.agent x2."
- At the bottom of the tree, the phrase "The girl slept." is written, with "The girl" in orange and "slept." in green.

Below the tree diagram, there is a list that states:
- Trees need to be obtained:
  - Pre/Post-processing logical forms
  - Grammar-induction

The slide number is indicated as 4 in the bottom right corner.</sample>
    <sample id="102">**Trees help a lot but...**

*girl x₁; sleep.agent x₂ x₁*

*girl x₁; x₁ sleep.agent x₂*

The girl slept.

Trees need to be obtained:
- Pre/Post-processing logical forms
- Grammar-induction

This paper: neural seq2seq model that directly models the correspondences between fragments. For the first time, we show strong generalization to deeper recursion without trees.</sample>
    <sample id="103">**Trees help a lot but...**

*girl x₁; sleep.agent x₂ x₁*

*girl x₁; x₁ sleep.agent x₂*

The girl slept.

Trees need to be obtained:
- Pre/Post-processing logical forms
- Grammar-induction

This paper: neural seq2seq model that directly models the correspondences between fragments. For the first time, we show strong generalization to deeper recursion without trees.</sample>
    <sample id="104">Our Approach

The image shows a diagram with three sections, each containing different colored blocks and labels:

1. The first section has two green blocks labeled with an asterisk (*) and a semicolon (;).
2. The second section has three yellow blocks labeled with "x1", "girl", and another "x1".
3. The third section has three blue blocks labeled with "sleep", "agent", and another "x2".

Each section is connected to a gray block labeled "Tag" at the bottom of the diagram. The gray block is also connected to three labels at the bottom: "the", "girl", and "slept".</sample>
    <sample id="105">Our Approach

The image shows a diagram with three sections, each representing different parts of speech (POS) tagging in natural language processing. The central part is labeled "Tag," and it connects to three different words: "the," "girl," and "slept."

1. **First Section (Green):**
   - Contains two symbols: an asterisk (*) and a semicolon (;).
   - Connected to the word "the."

2. **Second Section (Yellow):**
   - Contains three symbols: two 'x_1' and one 'girl'.
   - Connected to the word "girl."

3. **Third Section (Blue):**
   - Contains three symbols: 'sleep', 'agent', and one 'x_2'.
   - Connected to the word "slept".

This diagram illustrates how different POS tags can be assigned to words based on their context within a sentence.</sample>
    <sample id="106">Our Approach

The image shows a diagram with three sections, each representing different parts of speech (POS) tagging in natural language processing. The sections are labeled as follows:

1. **First Section:**
   - Contains two green squares with the symbols `*` and `;`.
   - Below this section, there is a word "the" which is tagged.

2. **Second Section:**
   - Contains three yellow squares with the symbols `x_1`, "girl", and `x_1`.
   - Below this section, there is a word "girl" which is tagged.

3. **Third Section:**
   - Contains three blue squares with the words "sleep", "agent", and `x_2`.
   - Below this section, there is a word "slept" which is tagged.

The central part of the diagram is labeled "Tag," indicating that these sections represent different tags applied to the words "the," "girl," and "slept."</sample>
    <sample id="107">Our Approach

The image illustrates a process labeled "Permute" which rearranges elements from three different sets of words: green, yellow, and blue. The green set contains the words "* the", the yellow set contains "girl x1", and the blue set contains "sleep agent x2". These elements are permuted to form new sequences at the bottom, where the green set results in "the", the yellow set results in "girl", and the blue set results in "slept". This process is labeled as "Tag" at the bottom.</sample>
    <sample id="108">Our Approach

The image illustrates a process labeled "Our Approach" which involves two main steps: "Permute" and "Tag." 

1. **Permute**: This step appears to involve rearranging or permuting elements, as indicated by the arrows pointing from various elements (e.g., "girl," "sleep," "agent") to different positions within the "Permute" section. The elements are color-coded: green for one set, yellow for another, and blue for a third.

2. **Tag**: Following the permutation, the elements are then tagged with specific labels such as "the," "girl," and "slept." These tags seem to correspond to the permuted elements, suggesting that the tagging is based on the arrangement of the elements after permutation.

The overall flow suggests a methodical approach where elements are first permuted and then tagged according to their new positions.</sample>
    <sample id="109">The image is a diagram illustrating the concept of "Permuting with 'jumps'." It shows a process where words are permuted and tagged. The diagram includes three sections:

1. **Permute**: This section contains three boxes, each with a word or symbol inside:
   - The first box has an asterisk (*) and a semicolon (;).
   - The second box has two instances of "x1" and one instance of "girl."
   - The third box has "sleep," "agent," and another "x2."

2. **Tag**: Below the "Permute" section, there are three tags corresponding to the boxes above:
   - The first tag is "the."
   - The second tag is "girl."
   - The third tag is "slept."

The diagram suggests that the words in the "Permute" section are being permuted (rearranged) and then tagged with the appropriate words from the "Tag" section. The asterisk (*) and "x1" symbols might represent placeholders or variables in the permutation process.</sample>
    <sample id="110">Permuting with "jumps"

*  
Permute  
*;  
x1 girl x1  
sleep agent x2  
the girl slept</sample>
    <sample id="111">The image is a diagram illustrating the concept of "Permuting with 'jumps'" in the context of natural language processing, specifically focusing on word permutations and tagging.

### Diagram Description:

1. **Top Section:**
   - The title "Permuting with 'jumps'" is written at the top.
   - There is a green box labeled with an asterisk (*), which represents a placeholder or a special token.
   - A black arrow points from the green box to a yellow box labeled "girl."

2. **Middle Section:**
   - Below the title, there is a gray box labeled "Permute."
   - Inside this box, there are three dashed boxes:
     - The first dashed box contains two green boxes labeled "the" and ";".
     - The second dashed box contains two yellow boxes labeled "x1" and "girl" (with the "girl" box highlighted in red).
     - The third dashed box contains two blue boxes labeled "sleep" and "agent" (with the "agent" box highlighted in blue).

3. **Bottom Section:**
   - Below the "Permute" box, there is another gray box labeled "Tag."
   - Arrows point from the green, yellow, and blue boxes in the "Permute" section to the corresponding words in the "Tag" section:
     - The green box labeled "the" points to a green box labeled "the."
     - The yellow box labeled "girl" points to a yellow box labeled "girl."
     - The blue box labeled "slept" points to a blue box labeled "slept."

4. **Additional Notes:**
   - The red arrow in the middle section points from the "girl" box in the "Permute" section to the "girl" box in the "Tag" section, indicating a "jump" or a specific permutation action.
   - The blue arrow in the middle section points from the "agent" box in the "Permute" section to the "agent" box in the "Tag" section, indicating another permutation action.

This diagram illustrates how certain words ("the," "girl," "sleep") are permuted and tagged, with specific jumps or actions indicated by arrows.</sample>
    <sample id="112">The image is a diagram illustrating the concept of "Permuting with 'jumps'" in the context of natural language processing, specifically focusing on word permutations and tagging.

### Diagram Description:

1. **Title:**
   - The title at the top reads "Permuting with 'jumps'."

2. **Main Components:**
   - There are three main components labeled as "Permute," "Tag," and "the," "girl," "sleep," "agent," and "slept."

3. **Permute Section:**
   - This section contains three boxes:
     - The first box has an asterisk (*) and a semicolon (;).
     - The second box has two "x" placeholders.
     - The third box has the word "girl" and another "x" placeholder.

4. **Tag Section:**
   - This section also contains three boxes:
     - The first box has the word "the."
     - The second box has the word "girl."
     - The third box has the words "sleep," "agent," and another "x" placeholder.

5. **Arrows and Jumps:**
   - Arrows connect the "Permute" section to the "Tag" section, indicating the process of permutation and tagging.
   - The arrows show how elements from the "Permute" section are mapped to the "Tag" section, with some elements being "jumped" or moved to different positions.

6. **Highlighted Elements:**
   - The word "girl" in the "Permute" section is highlighted in red, indicating it is the element that is being permuted.
   - The "x" placeholders in both sections are also highlighted, showing their role in the permutation process.

7. **Overall Process:**
   - The diagram illustrates how the word "girl" is permuted within the "Permute" section and then tagged in the "Tag" section, with other elements being moved or "jumped" to different positions.

This diagram is likely used to explain a specific algorithm or model in natural language processing, such as a neural network for sequence tagging or parsing.</sample>
    <sample id="113">The image is a diagram illustrating a process called "Permuting with 'jumps'." It shows a sequence of words and tags, with arrows indicating the permutation process.

At the top, there is a sequence of words: `*`, `girl`, `x1`, `i`, `sleep`, `agent`, `x2`, and `x1`. Below this sequence, there is a "Permute" section where the words are rearranged. The rearrangement includes jumps, as indicated by the red dashed lines that show the movement of certain elements.

The "Tag" section at the bottom corresponds to the tagged version of the words in the "Permute" section. The tags are: `the`, `girl`, and `slept`.

The diagram visually represents how the words can be permuted using jumps, leading to a different order of words while maintaining the same tags.</sample>
    <sample id="114">Some Results on COGS (Kim and Linzen 2020)

Comparison with other Treeless Models on Structural Generalization on COGS

Generalisation Type | Model
------------------|---------
PP recursion      | LSTM seq2seq
CP recursion      | T5
Obj PP → Subj PP | Zheng and Lapata
Ours             | Ours

Acc</sample>
    <sample id="115">Some Results on COGS (Kim and Linzen 2020)

Comparison with other Treeless Models on Structural Generalization on COGS

| Generalisation Type | Model |
|---------------------|-------|
| PP recursion        | LSTM seq2seq |
| CP recursion        | T5       |
| Obj PP → Subj PP    | Zheng and Lapata |
|                     | Ours     |

Acc</sample>
    <sample id="116">The image is a slide titled "Technical Challenges We Solve." It illustrates a process with two main steps: "Permute" and "Tag." The "Permute" step involves rearranging elements, represented by colored blocks labeled with words like "girl," "sleep," "agent," etc., and some placeholders marked with "x1" and "x2." Below this, the "Tag" step is shown, where the elements are tagged with their corresponding labels such as "the," "girl," and "slept." The text at the bottom of the slide states, "Alignment unknown."</sample>
    <sample id="117">Technical Challenges We Solve

Alignment unknown.

Permute
Tag</sample>
    <sample id="118">Technical Challenges We Solve

Alignment unknown.
- Induce it in training.</sample>
    <sample id="119">**Technical Challenges We Solve**

Alignment unknown.
- Induce it in training.

Permutation model:
- Inference is NP-hard (≈ TSP)</sample>
    <sample id="120">**Technical Challenges We Solve**

Alignment unknown.
- Induce it in training.

Permutation model:
- Inference is NP-hard (≈ TSP)
- Backpropagate through continuous relaxation</sample>
    <sample id="121">**Technical Challenges We Solve**

Alignment unknown.
- Induce it in training.

Permutation model:
- Inference is NP-hard (≈ TSP)
- Backpropagate through continuous relaxation

Paper &amp; Code:  
https://t.ly/mX8ny</sample>
    <sample id="122">The framework quantifies positionality by re-annotating datasets with diverse annotators and then comparing annotations by demographic to models and datasets via Pearson's R scores.</sample>
    <sample id="123">The image is a presentation slide with the following text and elements:

---

**Top Section:**
- **Logos of Institutions:**
  - Saarland University (owl logo)
  - Department of Language Science and Technology, Saarland University (LST logo)
  - Universität Wien

**Main Title:**
- "Weaker Than You Think"
- "A Critical Look at Weakly Supervised Learning"

**Authors and Affiliations:**
- Dawei Zhu^1
- Xiaoyu Shen^2
- Marius Mosbach^1
- Andreas Stephan^3
- Dietrich Klakow^1

**Affiliation Numbers:**
- ^1 Saarland University
- ^2 Amazon Alexa
- ^3 University of Vienna

**Conference Information:**
- ACL 2023
- 61st Annual Meeting of the Association for Computational Linguistics

---</sample>
    <sample id="124">The image is a presentation slide with the following text and elements:

---

**Top Section:**
- **Logos of Institutions:**
  - Saarland University (owl logo)
  - Department of Language Science and Technology, Saarland University (LST logo)
  - Universität Wien

**Main Title:**
- "Weaker Than You Think"
- "A Critical Look at Weakly Supervised Learning"

**Authors and Affiliations:**
- Dawei Zhu^1
- Xiaoyu Shen^2
- Marius Mosbach^1
- Andreas Stephan^3
- Dietrich Klakow^1

**Affiliation Numbers:**
- ^1 Saarland University
- ^2 Amazon Alexa
- ^3 University of Vienna

**Bottom Section:**
- "61st ACL 2023" (Association for Computational Linguistics)

---</sample>
    <sample id="125">Why weakly supervised learning?

- Weak supervision alleviates the annotation bottleneck.
- But weak labels are noisy!
  - Noise memorization harms generalization.
- Weakly supervised learning (WSL)
  - Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="126">Why weakly supervised learning?

- Weak supervision alleviates the annotation bottleneck.
- But weak labels are noisy!
  - Noise memorization harms generalization.
- Weakly supervised learning (WSL)
  - Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="127">Why weakly supervised learning?

- Weak supervision alleviates the annotation bottleneck.
- But weak labels are noisy!
  - Noise memorization harms generalization.
- Weakly supervised learning (WSL)
  - Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="128">Why weakly supervised learning?

- Weak supervision alleviates the annotation bottleneck.
- But weak labels are noisy!
  - Noise memorization harms generalization.
- Weakly supervised learning (WSL)
  - Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="129">Why weakly supervised learning?

- Weak supervision alleviates the annotation bottleneck.
- But weak labels are noisy!
  - Noise memorization harms generalization.
- Weakly supervised learning (WSL)
  - Train models that generalize well despite being trained on noisy data.</sample>
    <sample id="130">A common claim in recent WSL works

"We train models only on weakly supervised data and achieve an accuracy of XX%."

Weakly labeled training data (noisy)
Cleanly labeled test data (clean)</sample>
    <sample id="131">A common claim in recent WSL works

"We train models only on weakly supervised data and achieve an accuracy of XX%."

Weakly labeled training data (noisy)
Cleanly labeled test data (clean)</sample>
    <sample id="132">A common claim in recent WSL works

"We train models only on weakly supervised data and achieve an accuracy of XX%"

Weakly labeled training data (noisy)
Cleanly labeled validation data (clean)
Cleanly labeled test data (clean)</sample>
    <sample id="133">A common claim in recent WSL works

"We train models only on weakly supervised data and achieve an accuracy of XX%"

Weakly labeled training data (noisy)
Cleanly labeled validation data (clean)
Cleanly labeled test data (clean)</sample>
    <sample id="134">Our research questions

RQ1: Is clean validation data necessary?

RQ2: How many clean samples do WSL approaches need?

RQ3: How to use the available clean samples more efficiently?</sample>
    <sample id="135">Our research questions

RQ1 Is clean validation data necessary?

RQ2 How many clean samples do WSL approaches need?

RQ3 How to use the available clean samples more efficiently?</sample>
    <sample id="136">RQ1 Main findings

Relative performance improvement over weak labels (%)

-10 0 10 20 30
FTW BOND COSINE MLC L2R

Validation on Weak Labels
No Validation (Random Selection)
Validation on Clean Labels</sample>
    <sample id="137">RQ1 Main findings

The graph shows the relative performance improvement over weak labels (%) for different methods: FTW, BOND, COSINE, MLC, and L2R. The methods are categorized into three groups based on their validation strategy:
- Validation on Weak Labels (orange)
- No Validation (Random Selection) (purple)
- Validation on Clean Labels (green)

The y-axis represents the relative performance improvement in percentage, ranging from -10% to 30%. The x-axis lists the different methods.

Key observations:
- Validation on Clean Labels (green) generally shows the highest improvement across all methods.
- No Validation (Random Selection) (purple) often results in negative or minimal improvements.
- Validation on Weak Labels (orange) varies but tends to show moderate improvements compared to no validation.

This slide highlights the impact of different validation strategies on the performance improvement over weak labels.</sample>
    <sample id="138">RQ1 Main findings

The graph shows the relative performance improvement over weak labels (%) for different methods: FTW, BOND, COSINE, MLC, and L2R. The methods are categorized into three groups based on validation strategies:
- Validation on Weak Labels (orange)
- No Validation (Random Selection) (purple)
- Validation on Clean Labels (green)

The y-axis represents the relative performance improvement in percentage, ranging from -10% to 30%. The x-axis lists the methods being compared.

Key observations:
- Validation on Clean Labels (green) generally shows the highest improvement across all methods.
- No Validation (Random Selection) (purple) often results in negative or minimal improvements.
- Validation on Weak Labels (orange) varies but tends to show moderate improvements.

This slide highlights the impact of different validation strategies on the performance of various methods when working with weak labels.</sample>
    <sample id="139">RQ1 Main findings

The graph shows the relative performance improvement over weak labels (%) for different methods: FTW, BOND, COSINE, MLC, and L2R. The methods are compared under three conditions: Validation on Weak Labels (orange), No Validation (Random Selection) (purple), and Validation on Clean Labels (green). Each point represents a data point with error bars indicating the standard deviation.

- **FTW**: Performance varies significantly across the conditions.
- **BOND**: Performance is generally low and varies slightly.
- **COSINE**: Performance is low and varies slightly.
- **MLC**: Performance is low and varies slightly.
- **L2R**: Performance is high and relatively stable across conditions.

The green line (Validation on Clean Labels) consistently shows the highest performance improvement, while the purple line (No Validation) shows the lowest.</sample>
    <sample id="140">RQ1 Main findings

A clean validation set is indispensable.</sample>
    <sample id="141">RQ2 Main findings

The graph shows the accuracy of different methods across various validation sizes. The methods compared are:

- FT_w (blue line)
- COSINE (orange line)
- L2R (green line)
- BOND (red line)
- MLC (purple line)

The x-axis represents the validation size, ranging from 5 to All. The y-axis represents accuracy, ranging from 75 to 85.

A dashed line labeled "Weak labels" is also present on the graph, indicating the performance level of weak labels.</sample>
    <sample id="142">RQ2 Main findings

The graph shows the accuracy of different methods across various validation sizes. The methods compared are:
- FT_w (blue line)
- COSINE (orange line)
- L2R (green line)
- BOND (red line)
- MLC (purple line)

The x-axis represents the validation size, ranging from 5 to All. The y-axis represents accuracy.

A dashed line labeled "Weak labels" is also present on the graph, indicating a baseline performance level.</sample>
    <sample id="143">RQ2 Main findings

WSL approaches benefit from more clean validation samples!</sample>
    <sample id="144">RQ2 Main findings

WSL approaches benefit from more clean validation samples!</sample>
    <sample id="145">RQ2 Main findings

WSL approaches benefit from more clean validation samples!

But it is even better to use them for training (e.g., LoRAc)!</sample>
    <sample id="146">RQ3 Main findings

N=10 clean samples per class
Before CFT
After CFT

N=30 clean samples per class
Before CFT
After CFT

Accuracy/F1</sample>
    <sample id="147">RQ3 Main findings

N=10 clean samples per class
Before CFT
After CFT

N=30 clean samples per class
Before CFT
After CFT

Accuracy/F1</sample>
    <sample id="148">RQ3 Main findings

N=10 clean samples per class
Before CFT
After CFT

N=30 clean samples per class
Before CFT
After CFT

Accuracy/F1

COSINE
L2R
FTw
Clean Only</sample>
    <sample id="149">RQ3 Main findings

N=10 clean samples per class
Before CFT
After CFT

N=30 clean samples per class
Before CFT
After CFT

→ Continuous fine-tuning (CFT) eliminates performance gaps between WSL approaches.
→ No need to use complicated WSL methods (FTW performs equally well).</sample>
    <sample id="150">**Conclusion**

**Recent WSL approaches**
- Require clean samples.
- Overestimate their practicality.

**Our recommendations**
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="151">**Conclusion**

**Recent WSL approaches**
- Require clean samples.
- Overestimate their practicality.

**Our recommendations**
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="152">**Conclusion**

**Recent WSL approaches**
- Require clean samples.
- Overestimate their practicality.

**Our recommendations**
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="153">**Conclusion**

**Recent WSL approaches**
- Require clean samples.
- Overestimate their practicality.

**Our recommendations**
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="154">**Conclusion**

**Recent WSL approaches**
- Require clean samples.
- Overestimate their practicality.

**Our recommendations**
- Report the model selection criteria.
- Use Few-shot learning approaches as baselines.
- Always apply continuous fine-tuning (CFT).</sample>
    <sample id="155">The finding of the previous study where human subjects were given the same persona prompts is not provided in the image. The image only mentions that the current step is inspired by such a psych study with human subjects using the same prompts, but it does not specify the findings.</sample>
    <sample id="156">The sources of data used in this study include an enhanced version of the Penn Treebank (Marcus et al., 1993; Ficler and Goldberg, 2016).</sample>
    <sample id="157">There are two authors involved in the paper: Adam Przepiórkowski and Michał Woźniak.</sample>
    <sample id="158">The closely related tasks for cognitive dissonance mentioned in the image are "Debate" and "CE" (Comparison and Expansion classes).</sample>
    <sample id="159">There are two authors involved in the paper: Shuheng Liu and Alan Ritter.</sample>
    <sample id="160">There are seven authors involved in the paper.</sample>
    <sample id="161">The introduced framework differs from previous works by comparing annotations by demographic to models and datasets via Pearson's R scores, which is not explicitly mentioned in the previous works.</sample>
    <sample id="162">The setup that overlaps the most with the lexicon of stereotypes is GPT-3.5, as indicated by the longest bar in the chart for both "Black Stereotypes" and "White Stereotypes."</sample>
    <sample id="163">DeepL and Google.</sample>
    <sample id="200">There are six authors involved in the paper.</sample>
    <sample id="201">MPP evaluations were performed up to 900 tokens in length.</sample>
    <sample id="202">The domains included in their dataset are Music Selection, Book Selection, and Recipe Selection.</sample>
    <sample id="203">The perspectives people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="204">The name of the speaker is not explicitly mentioned in the image provided. The image shows a title slide for a presentation at ACL 2023, but it does not include the name of the speaker.</sample>
    <sample id="205">Yes, EDAtt uses already existing offline ST models without re-training or adopting specific architecture for SimulST.</sample>
    <sample id="206">There are four authors involved in the paper: Yusen Zhang, Jun Wang, Zhiguo Wang, and Rui Zhang.</sample>
    <sample id="207">No, the tested model does not work on the test suite.</sample>
    <sample id="208">The three variants of KITMUS are:

1. Background-Pretrain
2. Background-Both
3. Background-Inference</sample>
    <sample id="209">The affiliations of the authors of the paper are Google Research.</sample>
    <sample id="210">The last research question is "How to use the available clean samples more efficiently?"</sample>
    <sample id="211">The metric sensitivity measures how sensitive a model is towards variations in instructions for the same task. It evaluates the model's ability to consistently produce the same results regardless of slight variations in the wording of instructions. The formula provided calculates this sensitivity by comparing the average and standard deviation of the loss function across different instructions for the same task.</sample>
    <sample id="212">The name of the speaker is Wenjun Peng.</sample>
    <sample id="213">Greater sensitivity suggests the opposite of improved model performance; it indicates worse performance.</sample>
    <sample id="214">The image does not provide specific details about the type of linguistic context that models receive during pretraining. It only states that language model acceptability judgments are not always robust to context, which implies that the context in which the models operate can influence their judgments. For more detailed information on pretraining contexts, you would need to refer to the full paper or additional sources related to the research presented at ACL 2023.</sample>
    <sample id="215">Based on the graph, it appears that for good performance in WSL (Weakly Supervised Learning), around 50 clean validation samples are typically needed. This is indicated by the point where the accuracy lines for different methods start to plateau and stabilize, which is generally considered a good indicator of performance.</sample>
    <sample id="216">The affiliations of the authors of the paper are Stanford University, Department of Computer Science.</sample>
    <sample id="217">The image shows a chart comparing different large language models (LMs) based on their positions along two axes: social and economic. This visualization suggests that existing LMs have varying biases, which can influence their outputs in different ways. Developing new methods for measuring media biases is important because it helps ensure that these models are fair and unbiased, which is crucial for maintaining the integrity of information dissemination and decision-making processes. By improving measurement techniques, researchers can better understand and mitigate potential biases, leading to more reliable and trustworthy AI systems.</sample>
    <sample id="218">The name of the speaker is not explicitly mentioned in the image provided. The image shows a presentation slide with the title "The KITMUS Test" and a subtitle "Evaluating Knowledge Integration from Multiple Sources," along with the names of several contributors associated with McGill University, Mila, and Microsoft Research. However, it does not specify who is speaking at the moment the image was captured.</sample>
    <sample id="219">The political bias propagation pipeline, as depicted in the image, consists of three main stages:

1. **Pretraining data**: This is the initial dataset used to train the language models.
2. **Language models**: These models learn from the pretraining data and incorporate biases present in it.
3. **Downstream tasks**: The biased language models are then used for various downstream tasks, where these biases can propagate and affect the outcomes.

The pipeline is shown with arrows indicating the flow from pretraining data to language models and then to downstream tasks.</sample>
    <sample id="220">Yes, the simplification process differs for DEplain-apa and web. The bar chart "Simplification Transformations" shows that the percentages of different transformations vary between the two systems. For example, lexical substitution is higher in DEplain-web compared to DEplain-apa, while reordering is higher in DEplain-apa.</sample>
    <sample id="221">No, it is not mentioned whether Coscript is publicly available or not in the provided text.</sample>
    <sample id="222">The watermark is inserted by defining a target embedding \( e_t \), counting the trigger number in a sentence, and then adding the target embedding on the original embedding \( e_o \).</sample>
    <sample id="223">The affiliations of the authors of the paper are Penn State and Amazon.</sample>
    <sample id="224">Yes, encoder-decoder models such as mT5 can be improved by training in a mixture of various languages.</sample>
    <sample id="225">An example of constrained language planning is making a strawberry cake and a chocolate cake, where the abstract goal of making a cake can be inherited by different real-life specific goals with multi-faceted constraints.</sample>
    <sample id="226">The speaker mentions that they use embedding visualization to ensure the covertness of their method. This suggests that they analyze the embeddings of the data to confirm that the method is not easily detectable or distinguishable, thereby ensuring its covertness.</sample>
    <sample id="227">The work uses existing pre-trained models (PLMs) for continual pre-training, which involves fine-tuning these models on new data sources. Specifically, it uses CamemBERT, a French generic model, and PubMedBERT, an English-based medical model, as starting points for pre-training on the NACHOS and NBDW datasets. This approach leverages the knowledge learned from the existing models to improve performance on specific tasks or domains.</sample>
    <sample id="228">African Islamic</sample>
    <sample id="229">The speaker shows how the model leverages knowledge learned through the attention mechanism on the example sentence "I am a student."</sample>
    <sample id="230">The graph in Figure 3 shows that as the number of multimodal instruction task clusters increases, the model performance generally improves, with the "Max" and "Avg" lines rising, indicating better aggregated performance across different types of tasks.</sample>
    <sample id="231">The authors compare their method with three treeless baselines: LSTM seq2seq, T5, and Zheng and Lapata.</sample>
    <sample id="232">The two co-authors, Alexander Koller and Ivan Titov, are in a collaborative relationship with the first author, Matthias Lindemann. They are likely colleagues or partners in research, as they are listed together on the presentation slide as authors of the work titled "Compositional Generalization without Trees using Multiset Tagging and Latent Permutations."</sample>
    <sample id="233">The first author of PaLM is Chowdery et al.</sample>
    <sample id="274">The speaker mentions three problems of SimulST models.</sample>
    <sample id="275">Sanitizing the data before training the language models can be an effective way to mitigate social and political biases in datasets.</sample>
    <sample id="307">The fluency of PaLM is comparable to SOTA (State-of-the-Art).</sample>
    <sample id="308">The important properties of a watermarking method are applicability to EaaS, utility, covertness, and transferability.</sample>
    <sample id="309">The 14 different languages into which the English TED talks have been translated are:

1. English
2. Arabic
3. German
4. Spanish
5. French
6. Hebrew
7. Italian
8. Japanese
9. Korean
10. Dutch
11. Portuguese
12. Romanian
13. Russian
14. Turkish
15. Chinese</sample>
    <sample id="310">300</sample>
    <sample id="311">The distance metrics used for measuring the difference between benign and backdoor datasets are cosine similarity (cos) and L2 norm (l2).</sample>
    <sample id="312">The multilingual encoder-based models were used to evaluate on two groups of models in the monolingual setting.</sample>
    <sample id="313">The 61st Annual Meeting of the Association for Computational Linguistics
Toronto, Canada
July 9-14, 2023

Distilling Script Knowledge from Large Language Models for Constrained Language Planning

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

FUDAN UNIVERSITY
Brain Technologies Inc.</sample>
    <sample id="314">Language Planning

How to Make a Cake?
1. Gather your ingredients.
2. Preheat the oven to 325 °F (163 °C) and grease and flour a cake pan.
3. Cream the butter and sugar.
4. Add the eggs.
5. Stir in the cake flour.
6. Pour the batter into the pan.
7. Bake the cake for 1 hour 15 minutes.

Large language models (LLMs)
can effectively decompose goals into steps</sample>
    <sample id="315">Language Planning

How to Make a Cake?
1. Gather your ingredients.
2. Preheat the oven to 325 °F (163 °C) and grease and flour a cake pan.
3. Cream the butter and sugar.
4. Add the eggs.
5. Stir in the cake flour.
6. Pour the batter into the pan.
7. Bake the cake for 1 hour 15 minutes.

Large language models (LLMs)
can effectively decompose goals into steps</sample>
    <sample id="316">Constrained Language Planning

How to Make a Strawberry Cake?
...Add strawberry jams into the flour...

How to Make a Chocolate Cake?
...Add the cocoa powder into the flour...

Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints</sample>
    <sample id="317">Constrained Language Planning

How to Make a Strawberry Cake?
...Add strawberry jams into the flour...

How to Make a Chocolate Cake?
...Add the cocoa powder into the flour...

Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints</sample>
    <sample id="318">Constrained Language Planning

How to Make a Strawberry Cake?
...Add strawberry jams into the flour...

How to Make a Chocolate Cake?
...Add the cocoa powder into the flour...

Abstract goal can be inherited by different real-life specific goals with multi-faceted constraints</sample>
    <sample id="319">The image is a slide from a presentation titled "How do LLMs perform on Constrained Language Planning?" The slide outlines three types of constraints used in language planning, with examples provided for each type:

1. **Constraint Type 1: Modifier**
   - Definition: A word, an adjective, or a phrase that modifies or constrains an abstract goal.
   - Examples:
     - Ex.1: Make a chocolate cake.
     - Ex.2: Make a pink cake.

2. **Constraint Type 2: Method**
   - Definition: A tool or specified mode that controls the process for achieving the goal.
   - Examples:
     - Ex.1: Make a cake with an oven.
     - Ex.2: Make a cake by using cake mix.

3. **Constraint Type 3: Intent**
   - Definition: An additional purpose or demand when completing the goal.
   - Examples:
     - Ex.1: Make a cake for wedding.
     - Ex.2: Make a cake for diabetics.

At the top of the slide, it mentions the dataset used: "wikiHow + Generated Constraints."</sample>
    <sample id="320">The image is a slide from a presentation titled "How do LLMs perform on Constrained Language Planning?" The slide includes a dataset labeled as "wikiHow + Generated Constraints" and outlines three types of constraints:

1. **Constraint Type 1: Modifier**
   - Definition: A word, an adjective, or a phrase that modifies or constrains an abstract goal.
   - Examples:
     - Ex.1: Make a chocolate cake.
     - Ex.2: Make a pink cake.

2. **Constraint Type 2: Method**
   - Definition: A tool or specified mode that controls the process for achieving the goal.
   - Examples:
     - Ex.1: Make a cake with an oven.
     - Ex.2: Make a cake by using cake mix.

3. **Constraint Type 3: Intent**
   - Definition: An additional purpose or demand when completing the goal.
   - Examples:
     - Ex.1: Make a cake for wedding.
     - Ex.2: Make a cake for diabetics.</sample>
    <sample id="321">How do LLMs perform on Constrained Language Planning?

Dataset: wikiHow + Generated Constraints

| Constraint Type 1: Modifier |
|-----------------------------|
| Definition: A word, an adjective or a phrase that modifies or constrains an abstract goal. |
| Ex.1: Make a chocolate cake. |
| Ex.2: Make a pink cake. |

| Constraint Type 2: Method |
|---------------------------|
| Definition: A tool or specified mode that controls the process for achieving the goal. |
| Ex.1: Make a cake with an oven. |
| Ex.2: Make a cake by using cake mix. |

| Constraint Type 3: Intent |
|---------------------------|
| Definition: An additional purpose or demand when completing the goal. |
| Ex.1: Make a cake for wedding. |
| Ex.2: Make a cake for diabetics. |</sample>
    <sample id="322">The image is a slide from a presentation titled "Can LLMs do Constrained Language Planning?" It features a bar chart comparing the accuracy of different large language models (LLMs) in planning for specific goals. The models listed are:

- T5 (11B)
- Flan-T5 (11B)
- GPT-3 (175B)
- Codex (175B)
- InstructGPT (175B)

The y-axis represents accuracy, ranging from 0 to 80. The x-axis indicates the different models. The bar chart shows that all baselines achieve unsatisfactory results on planning for specific goals.

The text at the bottom of the slide states: "All baselines achieve unsatisfactory results on planning for specific goals."</sample>
    <sample id="323">Can LLMs do Constrained Language Planning?
All baselines achieve unsatisfactory results on planning for specific goals</sample>
    <sample id="324">The slide is titled "What types of errors do LLMs usually make in this task?" and it discusses the performance of large language models (LLMs) in generating scripts. The content on the slide includes a radar chart with four categories of errors:

- SE1: Missing step(s)
- SE2: Repeated step(s)
- SE3: Wrong order
- FE1: No constraint
- FE2: Unrelated step(s)
- FE3: Incoherent step(s)

The radar chart shows the percentage of each type of error for different LLMs, including:
- InstructionGPT (6B)
- InstructionGPT (175B)
- InstructionGPT (175B) + 400
- InstructionGPT (175B) + ours

The text at the bottom of the slide states: "The semantic completeness (SE) in generated scripts is acceptable, but the faithfulness to the constraints (FE) can not be guaranteed."</sample>
    <sample id="325">What types of errors do LLMs usually make in this task?
The semantic completeness (SE) in generated scripts is acceptable, but the faithfulness to the constraints (FE) can not be guaranteed.
The planning performance of InstructGPT varies considerably for goals of different categories.</sample>
    <sample id="326">What kinds of goals do InstructGPT typically fail?
The planning performance of InstructGPTs varies considerably for goals of different categories</sample>
    <sample id="327">The image is a slide from a presentation titled "Method." The slide outlines a process with two main sections:

1. **Step 1: Generate specific goals with InstructGPT via in-context learning**
   - **Input:** an abstract goal
   - **Output:** specific goals

2. **Abstract Goal: Make a cake**
   - **Specific Goals:**
     - G1 (+modifier): Make a chocolate cake
     - G2 (+method): Make a cake in a microwave
     - G3 (+intent): Make a cake for a wedding

The slide also includes a small video feed of a person, presumably the presenter, who appears to be speaking about the method being presented. The background of the video feed shows an office environment with desks, chairs, and some plants.</sample>
    <sample id="328">The image is a slide from a presentation titled "Method." It outlines a process with two main steps:

1. **Step 1: Generate specific goals with InstructGPT via in-context learning**
   - Input: an abstract goal
   - Example: Abstract Goal: Make a cake
   - Specific Goals:
     - G1 (+modifier): Make a chocolate cake
     - G2 (+method): Make a cake in a microwave
     - G3 (+intent): Make a cake for a wedding

2. **Step 2: Over-generate candidate scripts with InstructGPT via in-context learning**
   - Example: Candidate Scripts (1, 2, 3, ..., k)

The slide also includes a visual representation of these steps and goals, with icons and text to illustrate the process.</sample>
    <sample id="329">The image is a slide from a presentation titled "Method." It outlines a two-step process for generating specific goals and candidate scripts using InstructGPT via in-context learning.

**Step 1: Generate specific goals with InstructGPT via in-context learning**
- Input: an abstract goal
- Output: Specific Goals

**Step 2: Over-generate candidate scripts with InstructGPT via in-context learning**
- Output: Candidate Scripts

On the right side of the slide, there is an example of how this method works:
- **Abstract Goal:** Make a cake
- **Specific Goals:**
  - G1 (+modifier): Make a chocolate cake
  - G2 (+method): Make a cake in a microwave
  - G3 (+intent): Make a cake for a wedding
- **Constraints:** (not explicitly listed but implied)
- **Generate Plans for G1:** (This step is not detailed in the image)

The slide also shows a visual representation of the candidate scripts as numbered items (1, 2, 3, ..., k).</sample>
    <sample id="330">The image is a slide from a presentation titled "Method." It outlines a process with three steps:

1. **Step 2: Over-generate candidate scripts with InstructGPT via in-context learning**
   - This step involves using InstructGPT to generate multiple candidate scripts based on the given context.

2. **Step 3: Find filtered scripts to the goal with InstructGPT via similarity score**
   - This step uses InstructGPT again, but this time it filters the candidate scripts based on their similarity to the goal. The similarity scores are shown for each script, and the script with the highest score (0.7) is selected as the filtered script.

3. **Output: Specific goals with corresponding scripts**
   - The final output is specific goals along with the corresponding scripts that were generated and filtered.

On the right side of the slide, there is an image of a person wearing glasses and a green shirt, who appears to be presenting or discussing the method.</sample>
    <sample id="331">The image is a slide from a presentation titled "Method." It outlines a process with three main steps:

1. **Step 2: Over-generate candidate scripts with InstructGPT via in-context learning**
   - This step involves using InstructGPT to generate multiple candidate scripts based on the given context.

2. **Step 3: Find filtered scripts to the goal with InstructGPT via similarity score**
   - This step uses InstructGPT again, but this time it filters the candidate scripts by their similarity score to the goal. Scripts with higher similarity scores are selected as the final output.

3. **Output: Specific goals with corresponding scripts**
   - The final output is a list of specific goals along with the corresponding scripts that best match those goals.

On the right side of the slide, there is an example of how the filtering process works:
- **Candidate Scripts**: There are three candidate scripts labeled as 1, 2, and 3.
- **Similarity Scores**: Each script has a similarity score to the goal, which is represented by a cake icon. The scores are as follows:
  - Script 1: 0.3
  - Script 2: 0.5
  - Script 3: 0.7
- **Filtered Scripts**: Based on the similarity scores, Script 3 is selected as the filtered script because it has the highest score (0.7).

The example also shows a specific goal and the corresponding script for that goal:
- **Goal**: "Gather your ingredients."
- **Script**: "Add the cocoa powder."

The slide is part of a larger presentation, and there is a person visible in the top right corner, likely the presenter.</sample>
    <sample id="332">The image is a slide from a presentation titled "Method." It outlines a process with three steps:

1. **Step 2: Over-generate candidate scripts with InstructGPT via in-context learning**
   - This step involves using InstructGPT to generate multiple candidate scripts for a given task or goal.

2. **Step 3: Find filtered scripts to the goal with InstructGPT via similarity score**
   - This step uses InstructGPT again, but this time it filters the candidate scripts based on their similarity to the goal. The similarity score is used to determine which scripts are most relevant.

3. **Output: Specific goals with corresponding scripts**
   - The final output is a list of specific goals along with the corresponding scripts that best match those goals.

On the right side of the slide, there is an illustration showing two candidate scripts (Script 2 and Script 3) with their respective similarity scores to the goal. Script 3 has a higher similarity score (0.7) compared to Script 2 (0.5), indicating that Script 3 is more aligned with the goal. The selected script is then filtered and presented as the output.</sample>
    <sample id="333">Our Method Greatly Improves the Planning Quality

With our method, InstructGPT can generate scripts of higher quality by a large margin.</sample>
    <sample id="334">The image is a slide from a presentation titled "Script Distillation from LLMs." The slide is divided into two main sections: Motivation and Method.

**Motivation:**
- To enable constrained language planning ability for smaller models.
- Follow the idea of symbolic knowledge distillation.
- Generated 55,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.
- Humans annotate validation and test set.

**Method:**
- Input: an abstract.
- Step 1: Generate specific goals with InstructGPT via in-context learning.
- Step 2: Over-generate candidate scripts with InstructGPT via in-context learning.
- Step 3: Find filtered scripts to the goal with InstructGPT via similarity score.
- Output: Specific goals with corresponding plans.</sample>
    <sample id="335">The image is a slide from a presentation titled "Script Distillation from LLMs." The slide is divided into two main sections: Motivation and Method.

**Motivation:**
- To enable constrained language planning ability for smaller models.

**Method:**
- Follow the idea of symbolic knowledge distillation.
- Generated 55,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.
- Humans annotate validation and test set.

**Flowchart:**
1. **Step 1:** Generate specific goals with InstructGPT via in-context learning.
2. **Step 2:** Over-generate candidate scripts with InstructGPT via in-context learning.
3. **Step 3:** Find filtered scripts to the goal with InstructGPT via similarity score.

**Output:**
- Specific goals with corresponding plans

The slide also includes an input section labeled "Input: an abstract" and an output section labeled "Output: Specific goals with corresponding plans."</sample>
    <sample id="336">The image is a slide from a presentation titled "Script Distillation from LLMs." The slide is divided into two main sections: Motivation and Method.

**Motivation:**
- To enable constrained language planning ability for smaller models.

**Method:**
- Follow the idea of symbolic knowledge distillation.
- Generated 55,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.
- Humans annotate validation and test set.

**Steps:**
1. **Step 1:** Generate specific goals with InstructGPT via in-context learning.
2. **Step 2:** Over-generate candidate scripts with InstructGPT via in-context learning.
3. **Step 3:** Find filtered scripts to the goal with InstructGPT via similarity score.

**Output:**
- Specific goals with corresponding plans

The slide also includes an input section labeled "Input: an abstract" and an output section labeled "Output: Specific goals with corresponding plans." There is a visual representation of these steps with icons of robots and arrows indicating the flow of information.</sample>
    <sample id="337">The image is a slide from a presentation titled "Script Distillation from LLMs." The slide is divided into two main sections: Motivation and Method.

**Motivation:**
- To enable constrained language planning ability for smaller models.

**Method:**
- Follow the idea of symbolic knowledge distillation.
- Generated 55,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.
- Humans annotate validation and test set.

**Steps:**
1. **Step 1:** Generate specific goals with InstructGPT via in-context learning.
2. **Step 2:** Over-generate candidate scripts with InstructGPT via in-context learning.
3. **Step 3:** Find filtered scripts to the goal with InstructGPT via similarity score.

**Output:**
- Specific goals with corresponding plans

The slide also includes an input section labeled "Input: an abstract" and an output section labeled "Output: Specific goals with corresponding plans."</sample>
    <sample id="338">The image is a slide from a presentation titled "Script Distillation from LLMs." The slide is divided into two main sections: Motivation and Method.

### Motivation:
- To enable constrained language planning ability for smaller models.

### Method:
- Follow the idea of symbolic knowledge distillation.
- Generated 55,000 Scripts with constraint from LLMs based on our method =&gt; Coscript Dataset.
- Humans annotate validation and test set.

### Steps:
1. **Step 1**: Generate specific goals with InstructGPT via in-context learning.
2. **Step 2**: Over-generate candidate scripts with InstructGPT via in-context learning.
3. **Step 3**: Find filtered scripts to the goal with InstructGPT via similarity score.

### Output:
- Specific goals with corresponding plans

The slide also includes an input section labeled "Input: an abstract" and an output section labeled "Output: Specific goals with corresponding plans." There is a small video feed in the top right corner showing a person speaking.</sample>
    <sample id="339">Constraint Analysis

Coscript shows high heterogeneity and pluralism in the generated specific goals.

Coscript for Smaller Language Models

Datasets:
- Coscript
- wikiHow

Metrics:
- Faithful: DeBERTa (v3 large) model to decide whether the generated texts are faithful to the constraints
- Automatic metrics: ROUGE, BLEU, BERTScore</sample>
    <sample id="340">Specialized Models vs. LLMs

Smaller LMs fine-tuned on Coscript can generate higher quality scripts than LLMs.

Slide 15</sample>
    <sample id="341">Summary and Takeaways

- Establish the constrained language planning problem.
- Evaluate constrained language planning ability of LLMs and develop an over-generate-then-filter method for LLMs.
- Use LLMs to generate a high-quality script dataset (CoScript) for constrained language planning.
- Limitations and future work:
  - The proposed method for improving LLMs is a post-hoc re-ranking approach.
  - CoScript only inherits from an abstract one with one extra constraint.
  - CoScript dataset can be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints.</sample>
    <sample id="342">Summary and Takeaways

- Establish the constrained language planning problem.
- Evaluate constrained language planning ability of LLMs and develop an over-generate-then-filter method for LLMs.
- Use LLMs to generate a high-quality script dataset (CoScript) for constrained language planning.
- Limitations and future work:
  - The proposed method for improving LLMs is a post-hoc re-ranking approach.
  - CoScript only inherits from an abstract one with one extra constraint.
  - CoScript dataset can be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints.</sample>
    <sample id="343">The 61st Annual Meeting of the Association for Computational Linguistics
Toronto, Canada
July 9-14, 2023

Distilling Script Knowledge from Large Language Models for Constrained Language Planning

Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang

syyuan21@m.fudan.edu.cn
https://github.com/siyuyuan/coscript</sample>
    <sample id="344">The authors count the word frequency on a general text corpus \( D_p \) and randomly select \( n \) words in a moderate-frequency interval.</sample>
    <sample id="371">The image is a slide from a presentation titled "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems." The authors listed on the slide are Sarah E. Finch, James D. Finch, and Jinho D. Choi. The slide also includes logos for Emory University, the Emory NLP Research Lab, and Alexa.</sample>
    <sample id="372">The image is a slide from a presentation titled "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems." The authors listed on the slide are Sarah E. Finch, James D. Finch, and Jinho D. Choi. The slide also includes logos for Emory University, the Emory NLP Research Lab, and Alexa.</sample>
    <sample id="373">The image is a slide from a presentation titled "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems" by Sarah E. Finch, James D. Finch, and Jinho D. Choi. The slide is associated with Emory University, the Emory NLP Research Lab, and Alexa.

The slide is divided into two sections:

1. **Title Section**:
   - Title: "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems"
   - Authors: Sarah E. Finch, James D. Finch, and Jinho D. Choi

2. **Content Section**:
   - The title of this section is "Comparative Evaluation."
   - There are illustrations of a person and a robot with speech bubbles, indicating a dialogue between them.
   - The slide shows a comparison between two different chatbot systems or interfaces, represented by the person and the robots with speech bubbles.

The logos for Emory University, the Emory NLP Research Lab, and Alexa are also present at the bottom of the slide.</sample>
    <sample id="374">The image is a slide from a presentation titled "Comparative Evaluation." It features a diagram with two sets of speech bubbles and robots, indicating a comparison between different systems or models. The left side has blue speech bubbles and robots, while the right side has purple speech bubbles and robots. Below the diagrams, there is an illustration of a judge holding a gavel, suggesting a form of evaluation or judgment.

The slide transitions to another title, "Likert Rating Evaluation," showing a scale from 1 to 5 with circles representing different ratings. The same judge illustration remains at the bottom, reinforcing the theme of evaluation. The logos for Emory University and Alexa are visible in the corners, indicating the affiliation or sponsors of the presentation.</sample>
    <sample id="375">Likert Rating Evaluation

Dimensions of Dialogue Quality

Dialogue Quality
- Relevance
- Emotional Understanding
- Consistency</sample>
    <sample id="376">The image is a slide from a presentation titled "Dimensions of Dialogue Quality" under the subheading "Likert Rating Evaluation." The slide includes a scale with numbers 1 to 5, where 1 is on the left and 5 is on the right, with a green checkmark pointing towards the number 5. There are illustrations of a judge holding a gavel, a person with a speech bubble, and two robots with speech bubbles. The text at the bottom of the slide reads, "Rate the relevance of the bot's responses." The logos for Emory University and Alexa are visible in the bottom corners of the slide.</sample>
    <sample id="377">The image is a slide from a presentation titled "Likert Rating Evaluation." It features a scale with numbers 1 to 5, where the number 5 is marked with a green checkmark. The text at the bottom of the slide reads, "Rate the relevance of the bot's responses." There are illustrations of a person and a robot with speech bubbles above them, suggesting a conversation or interaction between the two. The bottom left corner includes logos for Emory University and NLP Emory, while the bottom right corner has an Alexa logo.</sample>
    <sample id="378">The image is a slide from a presentation titled "Annotating Behaviors in Chat (ABC-Eval)." It features a diagram with speech bubbles and icons representing human and bot interactions. The slide includes the following elements:

- A scale at the bottom labeled "1" to "5," indicating a rating system for the relevance of the bot's responses.
- Speech bubbles with icons of people and robots, suggesting a conversation between humans and a chatbot.
- The text "Rate the relevance of the bot's responses" is displayed below the scale.

As the slide progresses:
- An orange box appears on the right side with the word "Irrelevant."
- Another orange box appears below the first one, listing "Lack of Empathy" and "Self Contradiction."

The slide also includes logos for Emory University and Alexa.</sample>
    <sample id="379">The image is a slide from a presentation titled "Annotating Behaviors in Chat (ABC-Eval)." The slide features a diagram with three speech bubbles and two chatbot icons, illustrating different types of behaviors that can be annotated during chat interactions. The annotations are as follows:

1. **Irrelevant**: This is indicated by an arrow pointing to one of the speech bubbles.
2. **Lack of Empathy**: This is indicated by another arrow pointing to another speech bubble.
3. **Self-Contradiction**: This is indicated by yet another arrow pointing to a third speech bubble.

The slide also includes logos for Emory University and Alexa, suggesting that this presentation might be related to research or development work involving chatbots and natural language processing at Emory University.</sample>
    <sample id="380">The image is a slide from a presentation titled "ABC-Eval Behaviors." The slide is divided into four sections, each labeled with a different category of behaviors:

1. Coherence
2. Knowledge
3. Consistency
4. Emotional Understanding

In the top right corner, there is a small video feed showing a person speaking. The bottom left corner features logos for Emory University and NLP Emory, while the bottom right corner has an Alexa logo.</sample>
    <sample id="381">The image is a slide from a presentation titled "ABC-Eval Behaviors." The slide is divided into four quadrants, each labeled with a different category of behaviors:

1. **Coherence**
   - Ignoring Partner
   - Irrelevant

2. **Knowledge**

3. **Consistency**

4. **Emotional Understanding**

In the bottom left corner, there is a logo for Emory University and another logo that appears to be related to NLP (Natural Language Processing) at Emory. In the bottom right corner, there is an Alexa logo.

The slide also includes a small video feed in the top right corner showing a person speaking.</sample>
    <sample id="382">The image is a slide from a presentation titled "ABC-Eval Behaviors." The slide is divided into four sections, each representing different categories of behaviors:

1. **Coherence**
   - Ignoring Partner
   - Irrelevant

2. **Consistency**
   - Self Contradiction
   - Partner Contradiction

3. **Knowledge**
   - Incorrect Fact
   - Commonsense Violation

4. **Emotional Understanding**
   - Empathetic Response
   - Lack of Empathy

The slide also includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="383">The image is a slide from a presentation titled "ABC-Eval Behaviors." It appears to be part of a larger presentation, as indicated by the logo of Emory University and Alexa at the bottom. The slide is divided into two main sections:

1. **ABC-Eval Behaviors**:
   - Coherence: Includes behaviors such as "Ignoring Partner" and "Irrelevant."
   - Knowledge: Includes behaviors such as "Incorrect Fact" and "Commonsense Violation."
   - Consistency: Includes behaviors such as "Self Contradiction" and "Partner Contradiction."
   - Emotional Understanding: Includes behaviors such as "Empathetic Response" and "Lack of Empathy."

2. **Experiments**:
   - 4 Open-Domain Dialogue Models
   - 100 Human-Bot Conversations per Model

The slide also includes a small video feed in the top right corner showing a person speaking, likely the presenter.</sample>
    <sample id="384">Experiments

- 4 Open-Domain Dialogue Models
- 100 Human-Bot Conversations per Model

ABC-Eval
Turn Likert
Dialogue Likert
Comparative</sample>
    <sample id="385">Experiments
- 4 Open-Domain Dialogue Models
- 100 Human-Bot Conversations per Model

Baseline Evaluations
- Turn Likert
- Dialogue Likert
- Comparative

Consistency
Emotional Understanding
Informativeness
Overall Quality

Engagingness
Grammaticality
Proactivity
Relevance</sample>
    <sample id="386">The image is a slide from a presentation titled "Inter-Annotator Agreement." It features a graph with the y-axis labeled "Krippendorff's Alpha" and the x-axis divided into four categories: ABC-Eval, Turn Likert, Dialogue Likert, and Comparative. Each category has a set of data points represented by circles and error bars.

The graph shows the following:
- **ABC-Eval**: The data points are predominantly in the lower range, around 0.4 to 0.6.
- **Turn Likert**: The data points are slightly higher than ABC-Eval, ranging from approximately 0.5 to 0.7.
- **Dialogue Likert**: The data points are in the middle range, around 0.3 to 0.5.
- **Comparative**: The data points are the highest among all categories, ranging from approximately 0.6 to 0.8.

There are yellow arrows pointing to specific areas on the graph, likely highlighting key points or trends. The slide also includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="387">The image is a slide from a presentation titled "Predictive Validity." It features a bar chart with the subtitle "Inter-Annotator Agreement" and "Krippendorff's Alpha" as the metric for quality explained (R²). The chart compares different evaluation methods across four categories: ABC-Eval, Turn Likert, Dialogue Likert, and Comparative.

The categories on the x-axis include various terms such as "Other Contradiction," "CS Contradiction," "Unempathetic," "Ignore," "Redundant," "Empathetic," "Self-Contradiction," "Correct," "Uninterpretable," "Incorrect," "Topic Switch," "Life Info," "Antisocial," "Pref. Info," "Emotion," "Grammar," "Engaging," "Proactive," "Relevant," "Consistent," "Informative," "Emotion," "Grammar," and "Informative."

The y-axis represents the percentage of quality explained (R²), ranging from 0.00 to 0.10. The bars are color-coded to differentiate between two types of interactive qualities: "Interactive Qualitative" and "Interactive Quantitative."

The slide also includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="388">The image is a slide from a presentation titled "Predictive Validity." It features a bar chart comparing two categories, "Interactive Qua_d" and "Interactive Qua_c," across different evaluation metrics: ABC-Eval, Turn Likert, Dialogue Likert, and Comparative. The y-axis represents the percentage of quality explained (R²), ranging from 0.00 to 0.10.

Key points highlighted in the chart include:
- "Other Contradiction" has the highest R² value for both categories.
- "CS Contradiction" also shows a high R² value for both categories.
- "Unempathetic" and "Ignore" have relatively high R² values for "Interactive Qua_d."
- "Redundant" and "Empathetic Self-Contradiction" have moderate R² values for both categories.
- "Correct" has a moderate R² value for "Interactive Qua_d" but a lower one for "Interactive Qua_c."

The slide includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="389">The image is a slide from a presentation titled "Incremental Validity." It features a graph with the x-axis labeled as "ABC-Eval," "Turn Likert," and "Dialogue Likert," and the y-axis labeled as "% of Quality Explained (R²)." The graph shows different categories of quality explained, such as "Unempathetic," "Redundant," "Self Contra.," "Empathetic," "Irrelevant," "Correct," "CS Contra.," "Follow up," "Topic Switch," "Life Info," "Pref. Info," "Engaging," "Proactive," "Relevant," "Informative," "Grammar," "Emotion," "Consistent," and "Informative."

The categories are color-coded and connected by lines to show their progression in terms of quality explained. The categories are grouped into three main areas: ABC-Eval, Turn Likert, and Dialogue Likert.

The bottom left corner of the slide includes the logo of Emory University and the Alexa logo.</sample>
    <sample id="390">The image is a slide from a presentation titled "Incremental Validity." It features a graph with the y-axis labeled "% of Quality Explained (R²)" and the x-axis labeled "ABC-Eval," "Turn Likert," and "Dialogue Likert." The graph shows various categories such as "Unempathetic," "Redundant," "Self Contra.," "Empathetic," "Irrelevant," "Correct," "CS Contra.," "Follow up," "Pref Incorrect Contra.," "Unpref Incorrect Contra.," "Rephrase," "Life into Switch," "Antisocial," "Informative," "Consistent," "Relevant," "Proactive," "Engaging," "Emotion," and "Relevant."

The categories are plotted on the graph, with some marked by arrows pointing to them. The slide also includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="391">The image is a slide from a presentation titled "Incremental Validity." It features a graph with the y-axis labeled "% of Quality Explained (R²)" and the x-axis labeled "ABC-Eval," "Turn Likert," and "Dialogue Likert." The graph shows various categories on the x-axis, such as "Unempathetic," "Redundant," "Self Contra.," "Empathetic," "Irrelevant," "Correct," "CS Contra.," "Follow up," "Pref Incorrect Contra.," "Unpref Correct Contra.," "Rephrase," "Life into Switch," "Antisocial," "Informative," "Emotion," "Consistent," "Relevant," "Proactive," "Engaging," "Grammar," "Conversational," "Productive," and "Emotion."

The graph has three colored lines representing different evaluation methods:
- Orange line: ABC-Eval
- Blue line: Turn Likert
- Red line: Dialogue Likert

There are yellow arrows pointing to specific points on the graph, indicating areas of interest or significance. The bottom left corner of the slide includes the Emory University logo and the Alexa logo in the bottom right corner.</sample>
    <sample id="392">The image is a slide from a presentation titled "ABC-Eval Error Rates by Model." It displays a bar chart comparing the error rates of different models across various categories of errors, such as "Antisocial," "CS Contra-," "Ignore," "Incorrect," "Irrelevant," "Unempathetic," "Other Contradiction," "Redundant," "Self Contradiction," "Topic Switch," and "Uninterpret." The models being compared are BART-FID-RAG, Blender2, Emora, and Blender-Decode. The y-axis represents the percentage of turns, while the x-axis lists the different error categories. The slide also includes logos for Emory University and Alexa.</sample>
    <sample id="393">The image is a slide from a presentation titled "ABC-Eval Error Rates by Model." It displays a bar chart comparing the error rates of different models across various categories of errors, such as "Antisocial," "CS Contra-," "Ignore," "Incorrect," "Irrelevant," "Unempathetic," "Other Contra-," "Redundant," "Self Contra-," "Topic Switch," and "Uninterpret." The models being compared are BART-FID-RAG, Blender2, Emora, and Blender-Decide.

The x-axis represents the different error categories, while the y-axis shows the percentage of turns that fall into each category. The slide includes logos for Emory University and Alexa at the bottom corners. A yellow arrow points to the "CS Contra-" category under the BART-FID-RAG model, highlighting its error rate.</sample>
    <sample id="394">The image is a slide from a presentation titled "ABC-Eval Error Rates by Model." It displays a bar chart comparing the error rates of different models across various categories of errors, such as Antisocial, CS Contra., Ignore, Incorrect, Irrelevant, Unempathetic, Other Contra., Redundant, Self Contra., Topic Switch, and Uninterpret. The models being compared are BART-FID-RAG, Blender2, Emora, and Blender-Decode.

The x-axis represents the different types of errors, while the y-axis shows the percentage of turns where each model made an error. Each category has three bars representing the three models, with error rates indicated by the height of the bars. Yellow arrows point to specific categories for emphasis.

The slide includes logos for Emory University and Alexa at the bottom corners.</sample>
    <sample id="395">ABC-Eval Error Rates by Model

% of Turns
Antisocial
CS Contra.
Ignore
Incorrect
Irrelevant
Unempathetic
Other Contra.
Redundant
Self Contra.
Topic Switch
Uninterpret.

BART-FID-RAG
Blender2
Emora
Blender-Decode</sample>
    <sample id="396">ABC-Eval Error Rates by Model

% of Turns
Antisocial: 20%
CS Contra.: 15%
Ignore: 10%
Incorrect: 15%
Irrelevant: 20%
Unempathetic: 10%
Other Contra.: 5%
Redundant: 10%
Self Contra.: 5%
Topic Switch: 30%
Uninterpret.: 5%

BART-FID-RAG
Blender2
Emora
Blender-Decode

Thanks For Watching!

Paper: https://arxiv.org/pdf/2212.09180.pdf
GitHub: https://github.com/emorynlp/ChatEvaluationPlatform
Contact Info:
{sfillwo, jdfinch, jinho.choi} @emory.edu
https://www.emorynlp.org</sample>
    <sample id="397">The image provided does not contain any information about the speech segment size used in the approach. It only shows a slide with the text "What is our solution?" and a logo, but no specific details about the speech segmentation method or its parameters.</sample>
    <sample id="398">Servin is a judge.</sample>
    <sample id="399">The most important factor between the example quality and the similarity to the source sentence is the example quality.</sample>
    <sample id="400">The paper focuses on RoBERTa and GPT-2 in the extended experiments.</sample>
    <sample id="401">The model uses attention scores from a specific layer.</sample>
    <sample id="402">The examples of direct reference mentioned in the image are "easy on me" and "the first one."</sample>
    <sample id="403">The affiliations of the authors of the paper are Fudan University and Brain Technologies Inc.</sample>
    <sample id="404">There are six authors involved in the paper.</sample>
    <sample id="405">No, translating the natural language query using a machine translation model before semantic parsing was not considered as a baseline in this experiment. The "Translate-Test" setting uses Google Translate API to translate the source language to the target language and then uses a monolingual model for training and evaluation.</sample>
    <sample id="406">The authors gave "a woman warrior" as an example of a marked group.</sample>
    <sample id="407">The slide does not explicitly list which model architectures do not generalize well. However, it states that "Transformer models generalize better," implying that other architectures may not generalize as well. The specific non-generalizing architectures are not detailed in the provided image.</sample>
    <sample id="408">The names of the testing datasets are not explicitly mentioned in the image. The image shows two graphs with labels such as "FT_w," "COSINE," "L2R," "BOND," and "MLC," which appear to be different methods or models being compared, but they do not correspond to specific testing datasets.</sample>
    <sample id="409">There are six authors involved in the paper.</sample>
    <sample id="410">The author works with multiple modalities, as indicated by the term "Multimodal" in the title "Instruction Tuning on Multimodal Pre-trained Models."</sample>
    <sample id="411">DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains

Yanis Labrak*1,4 Adrien Bazoge*2,3 Richard Dufour2 Mickael Rouvier1
Emmanuel Morin2 Béatrice Daille2 Pierre-Antoine Gourraud3

(1) LIA, Avignon Université (2) LS2N, Nantes Université (3) Clinique des données, CHU de Nantes (4) Zenidoc

LS2N
Laboratoire des Sciences du Numérique de Nantes
Nantes Université
Centre Hospitalier Universitaire de Nantes
GENCI
Le calcul intensif au service de la connaissance
i2C
Laboratoire Informatique d'Avignon
AVIGNON UNIVERSITÉ</sample>
    <sample id="412">Summary

I. Language Modeling in Healthcare
II. Comparison of pre-training strategies, data sources and sizes
III. Evaluation of 13 models on 11 tasks
IV. Distribution of NACHOS and DrBERT</sample>
    <sample id="413">Summary

I. Language Modeling in Healthcare
II. Comparison of pre-training strategies, data sources and sizes
III. Evaluation of 13 models on 11 tasks
IV. Distribution of NACHOS and DrBERT</sample>
    <sample id="414">Summary

I. Language Modeling in Healthcare
II. Comparison of pre-training strategies, data sources and sizes
III. Evaluation of 13 models on 11 tasks
IV. Distribution of NACHOS and DrBERT</sample>
    <sample id="415">Summary

I. Language Modeling in Healthcare
II. Comparison of pre-training strategies, data sources and sizes
III. Evaluation of 13 models on 11 tasks
IV. Distribution of NACHOS and DrBERT

Language Modeling
- Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks
- Has been adapted to French with CamemBERT and FlauBERT
- Comparison of pre-training strategies based on domain-specific data
  - PubMedBERT, BioBERT, ClinicalBERT and other
- Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model
- Unlike generic models, no open-source model is available for biomedical domain in French yet
- BERT-based domain specific model for French should increase performance on medical tasks</sample>
    <sample id="416">The slide is titled "Language Modeling" and contains the following points:

- Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks.
- Has been adapted to French with CamemBERT and FlauBERT.
- On medical tasks, domain-specific models in English raised the bar even higher:
  - PubMedBERT, BioBERT, ClinicalBERT and other.
- Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model.
- Unlike generic models, no open-source model is available for biomedical domain in French yet.
- BERT-based domain specific model for French should increase performance on medical tasks.</sample>
    <sample id="417">The slide is titled "Language Modeling" and contains the following points:

- Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks.
- Has been adapted to French with CamemBERT and FlauBERT.
- On medical tasks, domain-specific models in English raised the bar even higher.
  - PudMedBERT, BioBERT, ClinicalBERT and other.
- Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model.
- Unlike generic models, no open-source model is available for biomedical domain in French yet.
- BERT-based domain specific model for French should increase performance on medical tasks.

The slide also includes the logo of Avignon Université at the bottom right corner.</sample>
    <sample id="418">The slide is titled "Language Modeling" and contains the following points:

- Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks.
- Has been adapted to French with CamemBERT and FlauBERT.
- On medical tasks, domain-specific models in English raised the bar even higher:
  - PubMedBERT, BioBERT, ClinicalBERT and other.
- Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model.
- Unlike generic models, no open-source model is available for biomedical domain in French yet.
- BERT-based domain specific model for French should increase performance on medical tasks.</sample>
    <sample id="419">The slide is titled "Language Modeling" and contains the following points:

- Transformer-based approaches, such as BERT, offer huge performance gain on a lot of NLP tasks.
- Has been adapted to French with CamemBERT and FlauBERT.
- On medical tasks, domain-specific models in English raised the bar even higher:
  - PubMedBERT, BioBERT, ClinicalBERT and other.
- Languages other than English are rarer and rely primarily on continual pre-training using an existing generic model.
- Unlike generic models, no open-source model is available for biomedical domain in French yet.
- BERT-based domain specific model for French should increase performance on medical tasks.</sample>
    <sample id="420">Comparison of pre-training strategies and data sources

- Evaluation of the impact of public and private medical data sources on comparable data sizes
  - NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles
  - NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse

- Comparison of learning strategies
  - From scratch with full model construction
  - Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)

| Corpus | Size | #words | #sentences |
|--------|------|--------|------------|
| NACHOSlarge (pub.) | 7.4 GB | 1.1 B | 54.2 M |
| NACHOSsmall (pub.) | 4 GB | 646 M | 25.3 M |
| NBDWsmall (private) | 4 GB | 655 M | 43.1 M |
| NBDWmixed (both) | 4+4 GB | 1.3 B | 68.4 M |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOSlarge |
| DrBERT     | From scratch | NACHOSsmall |
| ChuBERT    | From scratch | NBDWsmall |
| ChuBERT    | From scratch | NBDWmixed |
| CamemBERT  | continual pre-training | NACHOSsmall |
| PubMedBERT | continual pre-training | NACHOSsmall |
| CamemBERT  | continual pre-training | NBDWsmall |

Avignon Université</sample>
    <sample id="421">The slide is titled "Comparison of pre-training strategies and data sources." It discusses the evaluation of the impact of public and private medical data sources on comparable data sizes, comparing two datasets: NACHOS and NBDW.

- **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
- **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

The slide also compares learning strategies:
- **From scratch with full model construction**
- **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

The table on the right provides details about the corpus size, number of words, and number of sentences for each dataset:
- **NACHOSlarge (pub.)**: 7.4 GB, 1.1 B words, 54.2 M sentences
- **NACHOSsmall (pub.)**: 4 GB, 646 M words, 25.3 M sentences
- **NBDWsmall (private)**: 4 GB, 655 M words, 43.1 M sentences
- **NBDWmixed (both)**: 4+4 GB, 1.3 B words, 68.4 M sentences

The table below lists the models used in the comparison:
- **DrBERT**: From scratch, NACHOSlarge
- **DrBERT**: From scratch, NACHOSsmall
- **ChuBERT**: From scratch, NBDWsmall
- **ChuBERT**: From scratch, NBDWmixed
- **CamemBERT**: continual pre-training, NACHOSsmall
- **PubMedBERT**: continual pre-training, NACHOSsmall
- **CamemBERT**: continual pre-training, NBDWsmall</sample>
    <sample id="422">The slide is titled "Comparison of pre-training strategies and data sources." It discusses the evaluation of the impact of public and private medical data sources on comparable data sizes. The slide mentions two datasets:

- **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
- **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

The slide also compares learning strategies:
- **From scratch with full model construction**
- **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

There are tables providing details about the corpus size, number of words, and number of sentences for each dataset:
- **NACHOSlarge (pub.)**: 7.4 GB, 1.1 B words, 54.2 M sentences
- **NACHOSsmall (pub.)**: 4 GB, 646 M words, 25.3 M sentences
- **NBDWsmall (private)**: 4 GB, 655 M words, 43.1 M sentences
- **NBDWmixed (both)**: 4+4 GB, 1.3 B words, 68.4 M sentences

Additionally, there is a table listing models and their corresponding strategies and corpora:
- **DrBERT**: From scratch, NACHOSlarge
- **DrBERT**: From scratch, NACHOSsmall
- **ChuBERT**: From scratch, NBDWsmall
- **ChuBERT**: From scratch, NBDWmixed
- **CamemBERT**: continual pre-training, NACHOSsmall
- **PubMedBERT**: continual pre-training, NACHOSsmall
- **CamemBERT**: continual pre-training, NBDWsmall

The slide is from Avignon Université.</sample>
    <sample id="423">Comparison of pre-training strategies and data sources

- Evaluation of the impact of public and private medical data sources on comparable data sizes
  - NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles
  - NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse

- Comparison of learning strategies
  - From scratch with full model construction
  - Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)

| Corpus | Size | #words | #sentences |
|--------|------|--------|------------|
| NACHOSlarge (pub.) | 7.4 GB | 1.1 B | 54.2 M |
| NACHOSsmall (pub.) | 4 GB | 646 M | 25.3 M |
| NBDWsmall (private) | 4 GB | 655 M | 43.1 M |
| NBDWmixed (both) | 4+4 GB | 1.3 B | 68.4 M |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOSlarge |
| DrBERT     | From scratch | NACHOSsmall |
| ChuBERT    | From scratch | NBDWsmall |
| ChuBERT    | From scratch | NBDWmixed |
| CamemBERT  | continual pre-training | NACHOSsmall |
| PubMedBERT | continual pre-training | NACHOSsmall |
| CamemBERT  | continual pre-training | NBDWsmall |

Avignon Université</sample>
    <sample id="424">Comparison of pre-training strategies and data sources

- Evaluation of the impact of public and private medical data sources on comparable data sizes
  - NACHOS: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles
  - NBDW: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse

- Comparison of learning strategies
  - From scratch with full model construction
  - Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)

Corpus | Size | #words | #sentences
--- | --- | --- | ---
NACHOSlarge (pub.) | 7.4 GB | 1.1 B | 54.2 M
NACHOSsmall (pub.) | 4 GB | 646 M | 25.3 M
NBDWsmall (private) | 4 GB | 655 M | 43.1 M
NBDWmixed (both) | 4+4 GB | 1.3 B | 68.4 M

Model name | Strategy | Corpus
--- | --- | ---
DrBERT | From scratch | NACHOSlarge
DrBERT | From scratch | NACHOSsmall
ChuBERT | From scratch | NBDWsmall
ChuBERT | From scratch | NBDWmixed
CamemBERT | continual pre-training | NACHOSsmall
PubMedBERT | continual pre-training | NACHOSsmall
CamemBERT | continual pre-training | NBDWsmall</sample>
    <sample id="425">The slide is titled "Comparison of pre-training strategies and data sources." It discusses the evaluation of the impact of public and private medical data sources on comparable data sizes, comparing two datasets: NACHOS and NBDW.

- **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
- **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

The slide also compares learning strategies:
- **From scratch with full model construction**
- **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

The table on the right provides details about the corpus size, number of words, and number of sentences for each dataset:
- **NACHOSlarge (pub.)**: 7.4 GB, 1.1 B words, 54.2 M sentences
- **NACHOSsmall (pub.)**: 4 GB, 646 M words, 25.3 M sentences
- **NBDWsmall (private)**: 4 GB, 655 M words, 43.1 M sentences
- **NBDWmixed (both)**: 4+4 GB, 1.3 B words, 68.4 M sentences

The table below lists the models used in the comparison:
- **DrBERT**: From scratch, NACHOSlarge
- **DrBERT**: From scratch, NACHOSsmall
- **ChuBERT**: From scratch, NBDWsmall
- **ChuBERT**: From scratch, NBDWmixed
- **CamemBERT**: continual pre-training, NACHOSsmall
- **PubMedBERT**: continual pre-training, NACHOSsmall
- **CamemBERT**: continual pre-training, NBDWsmall

The slide is from Avignon Université.</sample>
    <sample id="426">The slide is titled "Comparison of pre-training strategies and data sources." It discusses the evaluation of the impact of public and private medical data sources on comparable data sizes, comparing two datasets: NACHOS and NBDW.

- **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures, and styles.
- **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

The slide also compares learning strategies:
- **From scratch with full model construction**
- **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

The table on the right provides details about the corpus size, number of words, and number of sentences for each dataset:
- **NACHOSlarge (pub.)**: 7.4 GB, 1.1 B words, 54.2 M sentences
- **NACHOSsmall (pub.)**: 4 GB, 646 M words, 25.3 M sentences
- **NBDWsmall (private)**: 4 GB, 655 M words, 43.1 M sentences
- **NBDWmixed (both)**: 4+4 GB, 1.3 B words, 68.4 M sentences

The table below lists the models used in the comparison:
- **DrBERT**: From scratch, NACHOSlarge
- **DrBERT**: From scratch, NACHOSsmall
- **ChuBERT**: From scratch, NBDWsmall
- **ChuBERT**: From scratch, NBDWmixed
- **CamemBERT**: continual pre-training, NACHOSsmall
- **PubMedBERT**: continual pre-training, NACHOSsmall
- **CamemBERT**: continual pre-training, NBDWsmall</sample>
    <sample id="427">**Comparison of pre-training strategies and data sources**

- **Evaluation of the impact of public and private medical data sources on comparable data sizes**
  - **NACHOS**: A 1.1B words open-source dataset of heterogeneous data crawled from diverse medical domains, natures and styles.
  - **NBDW**: A private dataset of sentences taken from 1.7M anonymized medical records extracted from the Nantes University Hospital data warehouse.

- **Comparison of learning strategies**
  - **From scratch with full model construction**
  - **Continual pre-training using an existing pre-trained model (here, CamemBERT, a French generic model, and PubMedBERT, an English-based medical one)**

| Corpus | Size | #words | #sentences |
|--------|------|--------|------------|
| NACHOSlarge (pub.) | 7.4 GB | 1.1 B | 54.2 M |
| NACHOSsmall (pub.) | 4 GB | 646 M | 25.3 M |
| NBDWsmall (private) | 4 GB | 655 M | 43.1 M |
| NBDWmixed (both) | 4+4 GB | 1.3 B | 68.4 M |

| Model name | Strategy | Corpus |
|------------|----------|--------|
| DrBERT     | From scratch | NACHOSlarge |
| DrBERT     | From scratch | NACHOSsmall |
| ChuBERT    | From scratch | NBDWsmall |
| ChuBERT    | From scratch | NBDWmixed |
| CamemBERT  | continual pre-training | NACHOSsmall |
| PubMedBERT | continual pre-training | NACHOSsmall |
| CamemBERT  | continual pre-training | NBDWsmall |

**Evaluation: Data sources and size**

- Performance evaluation of 13 models on 11 tasks, both public and private.
- Our fine-tuned models get state-of-the-art results on almost all tasks.

| General | aHF NER | aHF CLS | Medical Report NER | Specialities CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | CAS POS | FrenchMedMCQA F1 | Hamming EMR | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|---------|---------|---------|-------------------|------------------|---------------|---------------|-----------|-----------|------------------|-------------|------------------|------------------|
| General | 35.13   | 80.13   | 89.35             | 99.20            | 88.54         | 88.20         | 81.10     | 95.22     | 16.55           | 90.71       | 77.41            | 77.41            |
| Biomedical | CamemBERT OSCAR 138 GB | 42.66   | 81.41             | 88.78            | 99.61         | 85.43         | 91.27     | 96.42     | 34.71           | 90.83       | 78.76            | 78.76            |
| Clinical | CamemBERT OSCAR 4 GB | 43.11   | 79.98             | 89.34            | 99.55         | 90.33         | 91.38     | 85.42     | 97.33           | 14.41       | 90.33            | 77.61            |
| General | CamemBERT CCNET 4 GB | 48.22   | 81.25             | 98.83            | 99.86         | 91.04         | 92.24     | 89.75     | 36.66           | 15.32       | 92.09            | 77.88            |
| Biomedical | PubMedBERT | 47.22   | 76.86             | 89.20            | 99.37         | 91.99         | 87.78     | 95.90     | 33.98           | 14.14       | 77.09            | 72.68            |
| Clinical | BioBERT v1.1 | 46.01   | 79.00             | 89.38            | 98.80         | 90.46         | 81.91     | 97.12     | 36.19           | 15.43       | 84.29            | 74.94            |
| General | DrBERT NACHOSlarge | 45.93   | 79.87             | 89.44            | 99.85         | 91.77         | 88.57     | 95.70     | 37.37           | 13.34       | 91.66            | 78.18            |
| Biomedical | PubMedBERT | 49.01   | 81.56             | 89.58            | 99.83         | 92.23         | 87.71     | 95.61     | 35.16           | 14.79       | 88.15            | 74.94            |
| Clinical | ChuBERT NBDWsmall | 49.14   | 81.98             | 89.30            | 99.81         | 92.73         | 91.71     | 96.35     | 34.58           | 12.21       | 90.52            | 78.63            |

**Avignon Université**</sample>
    <sample id="428">Evaluation: Data sources and size

- Performance evaluation of 13 models on 11 tasks, both public and private
- Our fine-tuned models get state-of-the-art results on almost all tasks

| Model | aHF NER | aHF CLS | Medical Report NER | Specialties CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | CAS POS | FrenchMedMCQA Hamming | EMR F1 | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|-------|---------|---------|-------------------|-----------------|---------------|--------------|----------|------------------------|---------|------------------|---------------------|
| General | CamemBERT OSCAR 138 GB | 35.13 | 80.13 | 89.35 | 99.20 | 88.54 | 88.20 | 81.10 | 95.22 | 36.24 | 16.55 | 90.71 | 77.41 |
|         | CamemBERT OSCAR 4 GB | 42.66 | 81.41 | 88.78 | 99.61 | 85.43 | 91.27 | 83.69 | 96.42 | 35.75 | 15.37 | 90.83 | 78.76 |
|         | CamemBERT CCNET 4 GB | 43.11 | 79.98 | 89.34 | 99.55 | 90.33 | 91.38 | 85.42 | 97.33 | 34.71 | 14.41 | 90.33 | 77.61 |
| Biomedical | PubMedBERT | 47.22 | 76.86 | 89.20 | 99.37 | 91.99 | 81.97 | 87.78 | 95.90 | 33.98 | 14.14 | 86.79 | 77.09 |
|         | BioBERT v1.1 | 46.01 | 79.00 | 89.38 | 98.80 | 90.46 | 81.91 | 85.18 | 97.12 | 36.19 | 15.43 | 84.29 | 72.68 |
|         | DrBERT NACHOS_large | 48.22 | 81.25 | 89.83 | 99.86 | 91.04 | 92.24 | 89.75 | 95.65 | 36.66 | 15.32 | 92.09 | 77.88 |
|         | DrBERT NACHOS_small | 45.93 | 79.87 | 89.44 | 99.85 | 91.77 | 88.57 | 88.76 | 95.70 | 37.37 | 13.34 | 91.66 | 78.18 |
| Clinical | ClinicalBERT | 44.70 | 77.12 | 88.77 | 98.58 | 90.36 | 82.95 | 88.24 | 96.73 | 32.78 | 14.19 | 84.79 | 75.05 |
|         | ChuBERT NBDW_small | 49.01 | 81.56 | 89.58 | 99.83 | 92.23 | 92.17 | 87.71 | 95.61 | 35.16 | 14.79 | 88.15 | 74.94 |
|         | ChuBERT NBDW_mixed | 49.14 | 81.98 | 89.30 | 99.81 | 92.73 | 91.71 | 85.73 | 96.35 | 34.58 | 12.21 | 90.52 | 78.63 |

Avignon Université</sample>
    <sample id="429">Evaluation: Data sources and size

- Performance evaluation of 13 models on 11 tasks, both public and private
- Our fine-tuned models get state-of-the-art results on almost all tasks

| Model | aHF NER | aHF CLS | Medical Report NER | Specialties CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | CAS POS | FrenchMedMCQA Hamming | EMR F1 | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|-------|---------|---------|-------------------|-----------------|---------------|--------------|----------|------------------------|---------|------------------|---------------------|
| General | CamemBERT OSCAR 138 GB | 35.13 80.13 | 89.35 99.20 | 88.54 91.27 | 88.20 91.10 | 95.22 95.22 | 36.24 35.75 | 16.55 15.37 | 90.71 90.83 | 77.41 78.76 | 77.41 78.76 |
| Biomedical | PubMedBERT | 47.22 76.86 | 89.20 99.37 | 91.99 91.91 | 81.97 87.78 | 95.90 95.90 | 33.98 36.19 | 14.14 15.43 | 86.79 84.29 | 77.09 72.68 | 77.09 72.68 |
| Clinical | BioBERT v1.1 | 46.01 79.00 | 89.38 98.80 | 90.46 91.04 | 81.91 89.75 | 97.12 95.65 | 36.19 36.66 | 15.43 15.32 | 84.29 92.09 | 72.68 77.88 | 72.68 77.88 |
| Clinical | DrBERT NACHOS_large | 48.22 81.25 | 89.83 99.86 | 91.04 92.24 | 89.75 88.76 | 95.65 95.70 | 37.37 37.34 | 13.34 91.66 | 91.66 78.18 | 77.88 78.18 | 77.88 78.18 |
| Clinical | DrBERT NACHOS_small | 45.93 79.87 | 89.44 99.85 | 91.77 88.57 | 88.76 88.76 | 95.70 95.70 | 37.37 37.34 | 13.34 91.66 | 91.66 78.18 | 77.88 78.18 | 77.88 78.18 |

| Model | aHF NER | aHF CLS | Medical Report NER | Specialties CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | CAS POS | FrenchMedMCQA Hamming | EMR F1 | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|-------|---------|---------|-------------------|-----------------|---------------|--------------|----------|------------------------|---------|------------------|---------------------|
| Clinical | ClinicalBERT | 44.70 77.12 | 88.77 98.58 | 90.36 92.23 | 82.95 92.17 | 96.73 97.11 | 32.78 37.71 | 14.19 14.79 | 84.79 88.15 | 75.05 74.94 | 75.05 74.94 |
| Clinical | ChuBERT NBDW_small | 49.01 81.56 | 89.58 99.83 | 92.23 91.71 | 87.71 91.71 | 95.61 95.61 | 35.16 34.58 | 14.79 12.21 | 90.52 90.52 | 88.15 78.63 | 88.15 78.63 |</sample>
    <sample id="430">Evaluation: Data sources and size

- Performance evaluation of 13 models on 11 tasks, both public and private
- Our fine-tuned models get state-of-the-art results on almost all tasks

| Model | aHF NER | aHF CLS | Medical Report NER | Specialties CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | CAS POS | FrenchMedMCQA Hamming | EMR F1 | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|-------|---------|---------|-------------------|-----------------|---------------|--------------|----------|------------------------|---------|------------------|---------------------|
| General | CamemBERT OSCAR 138 GB | 35.13 80.13 | 89.35 99.20 | 88.54 91.27 | 88.20 95.22 | 81.10 96.42 | 83.69 35.75 | 36.24 15.37 | 90.71 77.41 |
|         | CamemBERT OSCAR 4 GB | 42.66 81.41 | 88.78 99.61 | 85.43 90.33 | 91.04 91.38 | 85.42 97.33 | 85.18 34.71 | 34.71 14.41 | 90.83 78.76 |
|         | CamemBERT CCNET 4 GB | 43.11 79.98 | 89.34 99.55 | 90.33 91.38 | 91.04 91.38 | 85.42 97.33 | 85.18 34.71 | 34.71 14.41 | 90.33 77.61 |
| Biomedical | PubMedBERT | 47.22 76.86 | 89.20 99.37 | 91.99 91.04 | 81.97 89.75 | 87.78 95.90 | 87.78 33.98 | 33.98 14.14 | 86.79 77.09 |
|         | BioBERT v1.1 | 46.01 79.00 | 89.38 98.80 | 90.46 91.77 | 81.91 88.76 | 85.18 95.70 | 85.18 36.66 | 36.66 15.32 | 84.29 72.68 |
|         | DrBERT NACHOS_large | 48.22 81.25 | 89.83 99.86 | 91.04 92.24 | 89.75 95.65 | 88.76 37.37 | 88.76 37.37 | 37.37 13.34 | 91.66 77.88 |
|         | DrBERT NACHOS_small | 45.93 79.87 | 89.44 99.85 | 91.77 88.57 | 89.75 95.65 | 88.76 37.37 | 88.76 37.37 | 37.37 13.34 | 91.66 78.18 |
| Clinical | ClinicalBERT | 44.70 77.12 | 88.77 98.58 | 90.36 92.23 | 82.95 92.17 | 88.24 96.73 | 88.24 32.78 | 32.78 14.19 | 84.79 75.05 |
|         | ChuBERT NBDW_small | 49.01 81.56 | 89.58 99.83 | 92.23 91.71 | 87.71 91.71 | 87.71 95.61 | 87.71 35.16 | 35.16 14.79 | 88.15 74.94 |
|         | ChuBERT NBDW_mixed | 49.14 81.98 | 89.30 99.81 | 92.73 91.71 | 91.71 91.71 | 85.73 96.35 | 85.73 34.58 | 34.58 12.21 | 90.52 78.63 |

Avignon Université</sample>
    <sample id="431">Evaluation: Data sources and size

- Performance evaluation of 13 models on 11 tasks, both public and private
- Our fine-tuned models get state-of-the-art results on almost all tasks

| Model | aHF NER | aHF CLS | Medical Report NER | Specialties CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | CAS POS | FrenchMedMCQA Hamming | EMR F1 | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|-------|---------|----------|-------------------|-----------------|---------------|--------------|----------|------------------------|---------|------------------|---------------------|
| General | CamemBERT OSCAR 138 GB | 35.13 | 80.13 | 89.35 | 99.20 | 88.54 | 88.20 | 81.10 | 95.22 | 36.24 | 16.55 | 90.71 |
|         | CamemBERT OSCAR 4 GB | 42.66 | 81.41 | 88.78 | 99.61 | 85.43 | 91.27 | 83.69 | 96.42 | 35.75 | 15.37 | 90.83 |
|         | CamemBERT CCNET 4 GB | 43.11 | 79.98 | 89.34 | 99.55 | 90.33 | 91.38 | 85.42 | 97.33 | 34.71 | 14.41 | 90.33 |
| Biomedical | PubMedBERT | 47.22 | 76.86 | 89.20 | 99.37 | 91.99 | 81.97 | 87.78 | 95.90 | 33.98 | 14.14 | 86.79 |
|         | BioBERT v1.1 | 46.01 | 79.00 | 89.38 | 98.80 | 90.46 | 81.91 | 85.18 | 97.12 | 36.19 | 15.43 | 84.29 |
|         | DrBERT NACHOSlarge | 48.22 | 81.25 | 89.83 | 99.86 | 91.04 | 92.24 | 89.75 | 95.65 | 36.66 | 15.32 | 92.09 |
|         | DrBERT NACHOSsmall | 45.93 | 79.87 | 89.44 | 99.85 | 91.77 | 88.57 | 88.76 | 95.70 | 37.37 | 13.34 | 91.66 |
| Clinical | ClinicalBERT | 44.70 | 77.12 | 88.77 | 98.58 | 90.36 | 82.95 | 88.24 | 96.73 | 32.78 | 14.19 | 84.79 |
|         | ChuBERT NBDWsmall | 49.01 | 81.56 | 89.58 | 99.83 | 92.23 | 92.17 | 87.71 | 95.61 | 35.16 | 14.79 | 88.15 |
|         | ChuBERT NBDWmixed | 49.14 | 81.98 | 89.30 | 99.81 | 92.73 | 91.71 | 85.73 | 96.35 | 34.58 | 12.21 | 90.52 |

**Note:** The table shows the F1 scores for various models across different tasks.</sample>
    <sample id="432">The slide is titled "Evaluation: Pre-training strategies" and discusses the comparison between pre-training from scratch versus continual pre-training on 4GB of data. It highlights that question-answering tasks require more domain-specific knowledge to work well and presents a study showing higher inter-run variability for CamemBERT-based models trained using continual pretraining.

The table below the title compares various models across different datasets, including F1 scores for Named Entity Recognition (NER) and Classification (CLS), as well as other metrics like Hamming distance and EMR. The models listed include CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, ClinicalBERT, BioBERT v1.1, DrBERT NACHOS_large, DrBERT NACHOS_small, Chubert NBDW_small, Chubert NBDW_mixed, CamemBERT NACHOS_small, PubMedBERT NACHOS_small, and CamemBERT NBDW_small. Each model's performance is evaluated on multiple datasets such as Medical Report, Specialties, MUSCA-DET, ESSAI, CAS, FrenchMedMCQA, QUAERO-EMEA, and QUAERO-MEDLINE.</sample>
    <sample id="433">Evaluation: Pre-training strategies

- From scratch vs. continual pre-training on 4GB of data
- Question-answering tasks require more domain-specific knowledge to be able to work well
- A study of model stability shows a higher inter-run variability for the CamemBERT-based models trained using continual pretraining

| Model | aHF NER | aHF CLS | Medical Report NER | Medical Report CLS | Specialities NER | Specialities CLS | MUSCA-DET NER | MUSCA-DET CLS | ESSAI POS | ESSAI CAS | FrenchMedMCQA Hamming | FrenchMedMCQA EMR | QUAERO-EMEA NER | QUAERO-MEDLINE NER |
|-------|---------|---------|-------------------|--------------------|------------------|------------------|---------------|--------------|-------------|-------------|---------------------|------------------|------------------|------------------|
| CamemBERT OSCAR 138 GB | 35.13 | 80.13 | 89.35 | 99.20 | 88.54 | 88.20 | 81.10 | 95.22 | 36.24 | 16.55 | 90.71 | 77.41 |
| CamemBERT OSCAR 4 GB | 42.66 | 81.41 | 88.78 | 99.61 | 85.43 | 91.27 | 83.69 | 96.42 | 35.75 | 15.37 | 90.83 | 78.76 |
| CamemBERT CCNET 4 GB | 43.11 | 79.98 | 89.34 | 99.55 | 90.33 | 91.38 | 85.42 | 97.33 | 34.71 | 14.41 | 90.33 | 77.61 |
| PubMedBERT | 47.22 | 76.86 | 89.20 | 99.37 | 91.99 | 81.97 | 87.78 | 95.90 | 33.98 | 14.14 | 86.79 | 77.09 |
| ClinicalBERT | 44.70 | 77.12 | 88.77 | 98.58 | 90.36 | 82.95 | 88.24 | 96.73 | 32.78 | 14.19 | 84.79 | 75.05 |
| BioBERT v1.1 | 46.01 | 79.00 | 89.38 | 98.80 | 90.46 | 81.91 | 85.18 | 97.12 | 36.19 | 15.43 | 84.29 | 72.68 |
| DrBERT NACHOS_large | 48.22 | 81.25 | 89.83 | 99.86 | 91.04 | 92.24 | 89.75 | 95.65 | 36.66 | 15.32 | 92.09 | 77.88 |
| DrBERT NACHOS_small | 45.93 | 79.87 | 89.44 | 99.85 | 91.77 | 88.57 | 88.26 | 95.70 | 37.37 | 13.34 | 91.66 | 78.18 |
| Chubert NBDW_small | 49.01 | 81.56 | 89.58 | 99.83 | 92.23 | 92.17 | 87.71 | 95.61 | 35.16 | 14.79 | 88.15 | 74.94 |
| Chubert NBDW_mixed | 49.14 | 81.98 | 89.30 | 99.81 | 91.71 | 85.73 | 96.35 | 34.58 | 12.21 | 90.52 | 78.63 |
| CamemBERT NACHOS_small | 16.08 | 69.80 | 66.74 | 99.54 | 80.96 | 78.70 | 80.04 | 92.46 | 32.87 | 13.76 | 71.10 | 57.43 |
| PubMedBERT NACHOS_small | 48.72 | 81.40 | 89.36 | 99.55 | 91.53 | 93.62 | 83.85 | 96.81 | 35.88 | 15.21 | 91.03 | 81.73 |
| CamemBERT NBDW_small | 19.12 | 76.02 | 69.64 | 99.58 | 81.57 | 77.12 | 79.25 | 93.18 | 27.73 | 11.89 | 61.75 | 53.0 |

Avignon Université</sample>
    <sample id="434">The slide is titled "Evaluation: Pre-training strategies" and discusses the comparison between pre-training from scratch versus continual pre-training on 4GB of data. It highlights that question-answering tasks require more domain-specific knowledge to work well and presents a study showing higher inter-run variability for CamemBERT-based models trained using continual pretraining.

The table below the title compares various models across different evaluation metrics such as F1, Hamming, and EMR for tasks like NER (Named Entity Recognition), CLS (Classification), Medical Report, Specialties, MUSCA-DET, ESSAI, CAS, POS, FrenchMedMCQA, QUAERO-EMEA, and QUAERO-MEDLINE. The models listed include CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, ClinicalBERT, BioBERT v1.1, DrBERT NACHOS_large, DrBERT NACHOS_small, Chubert NBDW_small, Chubert NBDW_mixed, CamemBERT NACHOS_small, PubMedBERT NACHOS_small, and CamemBERT NBDW_small. Each model's performance is evaluated under different datasets and tasks, with specific F1 scores provided for each metric.</sample>
    <sample id="435">The core message is as follows:

- DrBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks.
  - Surpasses CamemBERT generic model and English-based domain-specific models.
  - Confirms utility of training a medical-specific model in French.

- Data sources matter: training on heterogeneous data is important.
  - NACHOS is more robust than using private clinical data only.

- More data is better, but does not scale well.

- Continual pretraining is a more effective strategy when based on domain-specific English models.

- The DrBERT models, the NACHOS dataset, and the training scripts are freely available under the MIT license.</sample>
    <sample id="436">The core message is as follows:

- DrBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks.
  - Surpasses CamemBERT generic model and English-based domain-specific models.
  - Confirms utility of training a medical-specific model in French.

- Data sources matter: training on heterogeneous data is important.
  - NACHOS is more robust than using private clinical data only.

- More data is better, but does not scale well.

- Continual pretraining is a more effective strategy when based on domain-specific English models.

- The DrBERT models, the NACHOS dataset, and the training scripts are freely available under the MIT license.</sample>
    <sample id="437">The core message is as follows:

- DrBERT achieves state-of-the-art results in 9 downstream French medical-oriented tasks.
  - Surpasses CamemBERT generic model and English-based domain-specific models.
  - Confirms utility of training a medical-specific model in French.

- Data sources matter: training on heterogeneous data is important.
  - NACHOS is more robust than using private clinical data only.

- More data is better, but does not scale well.

- Continual pretraining is a more effective strategy when based on domain-specific English models.

- The DrBERT models, the NACHOS dataset, and the training scripts are freely available under the MIT license.</sample>
    <sample id="438">Thank You

Looking forward to exchange at poster session in Toronto!

More information on: drbert.univ-avignon.fr</sample>
    <sample id="439">The authors claim that the integration of pretrain-time and inference-time knowledge is an understudied area in NLU (Natural Language Understanding).</sample>
    <sample id="440">The names of the speakers are Zhiyang Xu, Ying Shen, and Lifu Huang.</sample>
    <sample id="441">Yes, humans annotated validation and test set.</sample>
    <sample id="442">The limits of existing resources for context-dependent translation include:
1. Only a small portion of words depend on context.
2. Existing methods support limited discourse phenomena and languages.</sample>
    <sample id="473">The approach is compared to the existing SimulST policies of wait-k, LA, and CAAT.</sample>
    <sample id="474">The affiliations of the authors of the paper are as follows:

1. Yanis Labrak - LIA, Avignon Université
2. Adrien Bazoge - LS2N, Nantes Université
3. Richard Dufour - LS2N, Nantes Université
4. Mickael Rouvier - LIA, Avignon Université
5. Emmanuel Morin - LS2N, Nantes Université
6. Béatrice Daille - Clinique des données, CHU de Nantes
7. Pierre-Antoine Gourraud - Zenidoc</sample>
    <sample id="475">The name of the speaker is not explicitly mentioned in the image provided. The image shows a presentation slide titled "NLPositionality: Characterizing Design Biases of Datasets and Models" with several names listed, but it does not specify who is speaking at the moment the image was captured.</sample>
    <sample id="476">There are three authors involved in the paper: Myra Cheng, Esin Durmus, and Dan Jurafsky.</sample>
    <sample id="505">Yes, the dataset is publicly available. The link to the dataset is provided in the image: https://github.com/ShuhengL/acl2023_conllpp.</sample>
    <sample id="535">The affiliations of the authors of the paper are Università di Trento and Fondazione Bruno Kessler.</sample>
    <sample id="536">The name of the speaker is Mohammad Javad Hosseini.</sample>
    <sample id="537">The image is a slide from a presentation titled "Prompting PaLM for Translation: Assessing Strategies and Performance." The slide includes the Google logo at the top left corner and mentions that it is from ACL 2023. Below the title, there are six headshots of individuals with their names listed underneath:

1. David Vilar Torres
2. Markus Freitag
3. Colin Cherry
4. Jiaming Luo
5. Viresh Ratnakar
6. George Foster

In the top right corner, there is an illustration of a beach scene with a palm tree and a speech bubble that says, "Can you translate this for me, please?" There is also a yellow smiley face next to the speech bubble.</sample>
    <sample id="538">PaLM: Pathways Language Model

- Chowdery et al., 2022
- arXiv:2204.02311.
- 540B parameters.
- Trained on 780B tokens.
- Densely activated.
- 6144 TPU v4 chips.
- SOTA in hundreds of LMU and Generation benchmarks.

The slide also features a colorful tree diagram with various labels such as "Question Answering," "Arithmetic," "Code Completion," "Summarization," "Translation," and "Language Understanding." The number of parameters is updated to 540 billion.</sample>
    <sample id="539">PaLM: Pathways Language Model

- Chowdery et al., 2022
- arXiv:2204.02311.
- 540B parameters.
- Trained on 780B tokens.
- Densely activated.
- 6144 TPU v4 chips.
- SOTA in hundreds of LMU and Generation benchmarks.

[Image of a tree with various colored circles labeled with tasks such as "Question Answering," "Arithmetic," "Code Completion," "Summarization," "Translation," "Language Understanding," etc.]

62 billion parameters
540 billion parameters</sample>
    <sample id="540">Our contribution

- First systematic study of LLM prompting for MT.
  - Both for the candidate pool as well as selection strategy.

- Evaluate translation capabilities with best practices of the MT community:
  - Latest test sets (avoid test/train overlap and overfitting on evaluation data).
  - Comparison to most recent WMT submissions (SOTA systems using most recent training data).
  - SOTA MT metrics (better correlation with human judgements).
  - Expert-based human evaluation (more robust than crowd workers).

- Recommendation for prompt selection strategies</sample>
    <sample id="541">Our contribution

- First systematic study of LLM prompting for MT.
  - Both for the candidate pool as well as selection strategy.

- Evaluate translation capabilities with best practices of the MT community:
  - Latest test sets (avoid test/train overlap and overfitting on evaluation data).
  - Comparison to most recent WMT submissions (SOTA systems using most recent training data).
  - SOTA MT metrics (better correlation with human judgements).
  - Expert-based human evaluation (more robust than crowd workers).

- Recommendation for prompt selection strategies</sample>
    <sample id="542">Our contribution

- First systematic study of LLM prompting for MT.
  - Both for the candidate pool as well as selection strategy.

- Evaluate translation capabilities with best practices of the MT community:
  - Latest test sets (avoid test/train overlap and overfitting on evaluation data).
  - Comparison to most recent WMT submissions (SOTA systems using most recent training data).
  - SOTA MT metrics (better correlation with human judgements).
  - Expert-based human evaluation (more robust than crowd workers).

- Recommendation for prompt selection strategies</sample>
    <sample id="543">Our contribution

- First systematic study of LLM prompting for MT.
  - Both for the candidate pool as well as selection strategy.

- Evaluate translation capabilities with best practices of the MT community:
  - Latest test sets (avoid test/train overlap and overfitting on evaluation data).
  - Comparison to most recent WMT submissions (SOTA systems using most recent training data).
  - SOTA MT metrics (better correlation with human judgements).
  - Expert-based human evaluation (more robust than crowd workers).

- Recommendation for prompt selection strategies</sample>
    <sample id="544">Prompts have a big impact on translation quality

- Select two random prompts for each sentence.
- Compute BLEURT for each sentence-prompt pair.
- The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point.
- The difference can go up to 40 BLEURT points!</sample>
    <sample id="545">Prompts have a big impact on translation quality

- Select two random prompts for each sentence.
- Compute BLEURT for each sentence-prompt pair.
- The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point.
- The difference can go up to 40 BLEURT points!</sample>
    <sample id="546">Prompts have a big impact on translation quality

- Select two random prompts for each sentence.
- Compute BLEURT for each sentence-prompt pair.
- The majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point.
- The difference can go up to 40 BLEURT points!</sample>
    <sample id="547">The English content in the image is:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.</sample>
    <sample id="548">The English content in the image is:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.</sample>
    <sample id="549">The English content in the image is as follows:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.</sample>
    <sample id="550">The English content in the image is as follows:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.</sample>
    <sample id="551">The English content in the image is as follows:

1. He is being transported under the custody of two policemen on a bus from the jail.
2. Police were called in after receiving complaints from the office.</sample>
    <sample id="552">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="553">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="554">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="555">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="556">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="557">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="558">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="559">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="560">Experimental Results

- Example quality is more important than similarity to source sentence.
- Specialized SOTA systems have a substantial advantage.
- PaLM close to Google Translate.

Insights from MQM:
- Fluency of PaLM comparable to SOTA.
- Accuracy scores generally lower.
  - Dominated by "Accuracy/Omission"
- "Style/Awkward" generally lower for PaLM.</sample>
    <sample id="561">The image is a word cloud with various languages expressing the phrase "thank you." The central word, "thank you," is repeated in multiple colors and sizes. Surrounding it are other words in different languages such as "danke" (German), "gracias" (Spanish), "merci" (French), "多谢" (Chinese), " obrigado" (Portuguese), "grazie" (Italian), "多谢" (Japanese), "merci" (French), "多谢" (Korean), "多谢" (Vietnamese), "多谢" (Thai), "多谢" (Arabic), and many more. Each language's expression of gratitude is represented by its own unique word or phrase.</sample>
    <sample id="597">The first step of the method maps the input tokens to "Tag" tokens.</sample>
    <sample id="598">55,000 Scripts with constraint</sample>
    <sample id="599">The KITMUS Test
Evaluating Knowledge Integration from Multiple Sources

McGill University/Mila
Microsoft Research

Akshatha Arodi*
Martin Pömsl*
Kaheer Suleman
Adam Trischler
Alexandra Olteanu
Jackie CK Cheung

* Equal Contribution</sample>
    <sample id="600">The image is a slide from a presentation titled "NLU models draw on multiple knowledge sources." The slide is divided into two main sections, each representing different types of knowledge that NLU (Natural Language Understanding) models can utilize:

1. **Knowledge in Parameters (pretrain-time knowledge)**: This section shows a neural network diagram with arrows and nodes, indicating the pre-trained knowledge embedded within the model's parameters.

2. **Knowledge in Context (inference-time knowledge)**: This section includes a text excerpt, suggesting that during inference, the model can leverage contextual information to improve its understanding and performance.

At the bottom of the slide, there is a label that reads "NLU Model," and the slide number is indicated as 2 in the bottom right corner.</sample>
    <sample id="601">The image is a slide from a presentation titled "NLU models draw on multiple knowledge sources." The slide is divided into two main sections, each representing different types of knowledge that NLU (Natural Language Understanding) models can utilize.

1. **Knowledge in Parameters (pretrain-time knowledge)**: This section shows a neural network diagram with arrows and nodes, indicating the pre-trained parameters that the model uses to understand language before it processes any specific input.

2. **Knowledge in Context (inference-time knowledge)**: This section includes a text excerpt, suggesting that during inference (the process of using the model to make predictions or decisions), the model can use contextual information to improve its understanding and performance.

At the bottom center of the slide, there is a label that reads "NLU Model," which indicates the focus of the slide is on Natural Language Understanding models. The slide number "2" is also visible in the bottom right corner.</sample>
    <sample id="602">The slide contains the following text:

"John saw the newly elected president on TV"

- "What presidents do" with a green checkmark
- "What is a TV" with a green checkmark
- "Who is John" with a red X
- "Who is the new president" with a red X

Additionally, there is an illustration of a person sitting in a chair watching TV, and a diagram labeled "pretrain-time knowledge." The slide is numbered 3 at the bottom right corner.</sample>
    <sample id="603">The slide contains the following text:

"John saw the newly elected president on TV"

Below this, there is an illustration of a person sitting in a chair watching television. The television screen shows a person speaking at a podium.

On the left side of the slide, there is a diagram labeled "pretrain-time knowledge." Next to it, there are two statements with checkmarks:
- "What presidents do ✅"
- "What is a TV ✅"

At the bottom, there are two statements with red crosses:
- "Who is John ❌"
- "Who is the new president ❌"

The slide is numbered 3 and has a credit line at the bottom right that says "Made by FREE-VECTORS.NET."</sample>
    <sample id="604">John saw the newly elected president on TV

pretrain-time knowledge

What presidents do ✅
What is a TV ✅

Who is John ❌
Who is the new president ❌</sample>
    <sample id="605">The image is a slide from a presentation with the title "John saw the newly elected president on TV." The slide is divided into two main sections: pretrain-time knowledge and inference-time knowledge.

On the left side, under "pretrain-time knowledge," there is a diagram of a neural network with the text "What presidents do" and "What is a TV," both marked with green checkmarks. Below this section, it says "inference-time knowledge."

On the right side, there is an illustration of a person sitting in a chair watching television. The text next to this illustration includes "Who is John" and "Who is the new president," both also marked with green checkmarks.

The slide number is 4, and there is a note at the bottom right corner that says "Made by FREE-VECTORS.NET."</sample>
    <sample id="606">KITMUS Test Suite
- Dataset for knowledge integration evaluation
- Coreference resolution task to probe ability to draw on
  ○ pretrain-time knowledge
  ○ inference-time knowledge
- Experiment with
  ○ human study participants
  ○ coreference resolution models</sample>
    <sample id="607">KITMUS Test Suite
- Dataset for knowledge integration evaluation
- Coreference resolution task to probe ability to draw on
  ○ pretrain-time knowledge
  ○ inference-time knowledge
- Experiment with
  ○ human study participants
  ○ coreference resolution models</sample>
    <sample id="608">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]</sample>
    <sample id="609">Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]</sample>
    <sample id="610">**KITMUS Test Suite**

Servin is a judge. Kea is a baker. Servin and Kea met at a park. After a long day at work deciding cases in a law court, he was happy to relax. [Answer: Servin]

1) Entity-specific knowledge

Judges decide cases in courts of law.

2) Background knowledge</sample>
    <sample id="611">The image is a slide from a presentation titled "KITMUS Test Suite." The slide contains text and diagrams related to knowledge representation in artificial intelligence, specifically focusing on entity-specific knowledge and background knowledge.

### Text Content:
- **Main Scenario:**
  - Servin is a judge.
  - Kea is a baker.
  - Servin and Kea met at a park.
  - After a long day at work deciding cases in a law court, he was happy to relax.
  - [Answer: Servin]

- **Background Knowledge:**
  - Judges decide cases in courts of law.

- **Knowledge Types:**
  - 1) Entity-specific knowledge (inference-time knowledge)
  - 2) Background knowledge (pretrain-time knowledge)

### Diagrams:
- There are two diagrams labeled with the types of knowledge mentioned above:
  - One diagram is labeled "1) Entity-specific knowledge" and is associated with inference-time knowledge.
  - The other diagram is labeled "2) Background knowledge" and is associated with pretrain-time knowledge.

The slide number is indicated as "9" in the bottom right corner.</sample>
    <sample id="612">The image is a slide from a presentation titled "KITMUS Test Suite." The slide contains text and diagrams related to knowledge representation in natural language processing.

### Text Content:
- **Main Scenario:**
  - Servin is a judge.
  - Kea is a baker.
  - Servin and Kea met at a park.
  - After a long day at work deciding cases in a law court, he was happy to relax.
  - [Answer: Servin]

- **Knowledge Categories:**
  - 1) Entity-specific knowledge
    - inference-time knowledge
  - 2) Background knowledge
    - Judges decide cases in courts of law.

### Diagrams:
- There are two boxes labeled with the categories of knowledge:
  - **Entity-specific knowledge:** This box includes a diagram showing a neural network with nodes connected by arrows, indicating inference-time knowledge.
  - **Background knowledge:** This box also includes a similar neural network diagram, indicating pretrain-time knowledge.

### Additional Notes:
- The slide number is 9, as indicated in the bottom right corner.
- The background color of the slide is white, and the text is primarily black with some yellow and green highlights for emphasis.</sample>
    <sample id="613">Variants of KITMUS

(a) BACKGROUND-PRETRAIN: Typical setup
(b) BACKGROUND-BOTH: Explicitly provide background knowledge in context
(c) BACKGROUND-INFERENCE: Knowledge only available at inference-time</sample>
    <sample id="614">Variants of KITMUS

(a) BACKGROUND-PRETRAIN: Typical setup
(b) BACKGROUND-BOTH: Explicitly provide background knowledge in context
(c) BACKGROUND-INFERENCE: Knowledge only available at inference-time</sample>
    <sample id="615">Variants of KITMUS

(a) BACKGROUND-PRETRAIN: Typical setup
(b) BACKGROUND-BOTH: Explicitly provide background knowledge in context
(c) BACKGROUND-INFERENCE: Knowledge only available at inference-time</sample>
    <sample id="616">The image is a slide from a presentation titled "Variants of KITMUS." It illustrates three different variants of KITMUS, each with two columns:

1. **Background-Pretrain**
   - Left column: A neural network diagram.
   - Right column: Text box with the sentence "Chichester is a politician."

2. **Background-Both**
   - Left column: A neural network diagram.
   - Right column: Text box with the sentence "Politicians seek elected seats in government."
   - Below the right column: Another text box with the sentence "The work of a politician is seeking an elected seat in government."

3. **Background-Inference**
   - Left column: A neural network diagram.
   - Right column: Text box with the sentence "Chichester is a mirituer."
   - Below the right column: Another text box with the sentence "The work of a mirituer is eheming smorbly."

Each variant seems to be demonstrating how the model processes and infers information based on background knowledge.</sample>
    <sample id="617">The image is a slide from a presentation titled "Variants of KITMUS." The slide is divided into three sections, each representing a different variant of KITMUS:

1. **Background-Pretrain**
   - **Left Panel**: A neural network diagram.
   - **Right Panel**: Text that reads: "Politicians seek elected seats in government."
   - **Middle Panel**: Text that reads: "Chichester is a politician."

2. **Background-Both**
   - **Left Panel**: A neural network diagram.
   - **Right Panel**: Text that reads: "Politicians seek elected seats in government."
   - **Middle Panel**: Text that reads: "Chichester is a politician."
   - **Bottom Panel**: Text that reads: "The work of a politician is seeking an elected seat in government."

3. **Background-Inference**
   - **Left Panel**: A neural network diagram.
   - **Right Panel**: Text that reads: "Politicians seek elected seats in government."
   - **Middle Panel**: Text that reads: "Chichester is a mirituer."
   - **Bottom Panel**: Text that reads: "The work of a mirituer is eheming smorbly."

The slide appears to be discussing different methods or approaches within the KITMUS framework, possibly related to natural language processing or machine learning models.</sample>
    <sample id="618">The image is a slide from a presentation titled "Variants of KITMUS." It illustrates three different variants of the KITMUS model, each with a corresponding diagram and text explanation:

1. **Background-Pretrain**
   - Diagram: A neural network with labeled nodes.
   - Text: "Politicians seek elected seats in government."
   - Additional text: "Chichester is a politician."

2. **Background-Both**
   - Diagram: A neural network with labeled nodes.
   - Text: "Politicians seek elected seats in government."
   - Additional text: "Chichester is a politician."
   - Further text: "The work of a politician is seeking an elected seat in government."

3. **Background-Inference**
   - Diagram: A neural network with labeled nodes.
   - Text: "Chichester is a mirituer."
   - Additional text: "The work of a mirituer is eheming smorbly."

The slide appears to be part of a discussion on how different variants of the KITMUS model handle background information during pretraining and inference phases.</sample>
    <sample id="619">The image is a slide from a presentation titled "Variants of KITMUS." It illustrates three different variants of KITMUS, each with a corresponding diagram and text:

1. **Background-Pretrain**
   - Diagram: A neural network model.
   - Text: "Politicians seek elected seats in government."
   - Additional text: "Chichester is a politician."

2. **Background-Both**
   - Diagram: A neural network model.
   - Text: "Politicians seek elected seats in government."
   - Additional text: "Chichester is a politician."
   - Further text: "The work of a politician is seeking an elected seat in government."

3. **Background-Inference**
   - Diagram: A neural network model.
   - Text: "Chichester is a mirituer."
   - Additional text: "The work of a mirituer is eheming smorbly."

The slide appears to be part of a discussion on how different variants of KITMUS handle background information during pretraining and inference phases.</sample>
    <sample id="620">Background-Pretrain

Task-specific training is necessary for knowledge integration

13</sample>
    <sample id="621">Background-Pretrain

Task-specific training is necessary for knowledge integration

13</sample>
    <sample id="622">Background-Pretrain

Task-specific training is necessary for knowledge integration

13</sample>
    <sample id="623">The image is a slide from a presentation titled "Background-Inference." It features a bar chart with the following details:

- The x-axis is labeled "Fictional background knowledge."
- The y-axis is labeled "Mean Accuracy."
- There are four categories on the chart:
  - Random Choice (dashed line)
  - Human Participants (dotted line)
  - BERT4Coref (blue bar)
  - C2F (orange bar)

The text at the bottom of the slide states: "Models struggle to integrate inference-time background knowledge."

The slide number is indicated as 14 in the bottom right corner.</sample>
    <sample id="624">**Conclusion**

Main Takeaways:
1. Many models seem unable to reason over knowledge from multiple sources (pretrain-time and inference-time knowledge)
2. Task-specific training is necessary for knowledge integration
3. Models struggle to integrate inference-time background knowledge

Find the dataset, generation &amp; evaluation code on GitHub at mpoemsl/kitmus</sample>
    <sample id="625">**Conclusion**

Main Takeaways:
1. Many models seem unable to reason over knowledge from multiple sources (pretrain-time and inference-time knowledge)
2. Task-specific training is necessary for knowledge integration
3. Models struggle to integrate inference-time background knowledge

Find the dataset, generation &amp; evaluation code on GitHub at mpoemsl/kitmus</sample>
    <sample id="626">The best alignment method for DEplain, based on the F1 score in the 1:1 part of the table, is LHA with a score of .744.</sample>
    <sample id="627">Weakly supervised learning alleviates the annotation bottleneck and allows models to generalize well despite being trained on noisy data.</sample>
    <sample id="628">The document in DEplain-web was aligned using both manual and automatic alignment methods. However, the specific details of how the alignment was conducted (e.g., the exact number of sentences or documents for each method) are not provided in the image. The image only shows the results of document simplification using finetuned long-mBART and sentence simplification using finetuned mBART, but it does not provide information on the alignment process itself.</sample>
    <sample id="629">The CoNLL++ dataset was created by collecting Reuters news from 2020 and annotating it with CoNLL-2003 annotation guidelines.</sample>
    <sample id="667">The existing works mentioned in the image include:

1. Parameter-based watermark [1, 2]
2. Lexical watermark [3, 4]
3. Backdoor-based watermark [5]
4. Adversarial-based watermark [6]

Each of these methods is noted to be applicable to EaaS (Enterprise as a Service) and has specific references provided for further reading.</sample>
    <sample id="668">No, multilingual LLMs (Codex &amp; BLOOM) are still inadequate for crosslingual semantic parsing tasks.</sample>
    <sample id="669">The image is a slide from a presentation titled "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?" The slide includes the names of the presenters, Shuheng Liu and Alan Ritter, who are affiliated with the School of Interactive Computing at Georgia Institute of Technology. The background features a geometric design with blue and gold elements, and there is a circular inset on the left side showing a person wearing glasses. The Georgia Tech logo is visible in the bottom right corner.</sample>
    <sample id="670">The image contains the following text:

"Named Entity Recognition &amp; Generalization"

In the bottom left corner, there is a circular profile picture of a person wearing glasses and a black shirt. In the bottom right corner, there is a logo with the letters "GT" and the words "Georgia Tech."</sample>
    <sample id="671">Named Entity Recognition &amp; Generalization

- Models have been using CoNLL-2003 to develop NER for almost 20 years
- Can these models generalize to modern data?
- What is needed for good generalization?</sample>
    <sample id="672">The slide is titled "Named Entity Recognition &amp; Generalization." It contains three bullet points:

1. Models have been using CoNLL-2003 to develop NER for almost 20 years.
2. Can these models generalize to modern data?
3. What is needed for good generalization?</sample>
    <sample id="673">The slide is titled "Named Entity Recognition &amp; Generalization." It contains the following points:

- Models have been using CoNLL-2003 to develop NER for almost 20 years.
- Can these models generalize to modern data?
- What is needed for good generalization?
- What causes the performance drop?</sample>
    <sample id="674">CoNLL++ Dataset

- Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines

AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="675">CoNLL++ Dataset
- Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines
- Fine-tuned 20+ models on CoNLL-2003
- Evaluated on CoNLL-2003 test set &amp; CoNLL++

AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="676">CoNLL++ Dataset
- Collected Reuters news from 2020 and annotated with CoNLL-2003 annotation guidelines
- Fine-tuned 20+ models on CoNLL-2003
- Evaluated on CoNLL-2003 test set &amp; CoNLL++
- Calculated percentage ΔF1 to assess generalization

AMBASSADOR O
TO O
THE O
UNITED I-ORG
NATIONS I-ORG
: O
LINDA I-PER
THOMAS-GREENFIELD I-PER</sample>
    <sample id="677">What Is Needed for Good Generalization?</sample>
    <sample id="678">The slide is titled "What Is Needed for Good Generalization?" and lists two bullet points:
- Model architecture
- Transformer models generalize better

The slide also includes a graph with two axes: CoNLL-2003 F1 Score on the x-axis and CONLL+ F1 Score on the y-axis. The graph plots various models, including BERT, ALBERT-base, BILSTM-CNN-CRF, and others, showing their performance in terms of F1 scores. The models are color-coded and labeled, with some models highlighted in different colors to distinguish them from others. The Georgia Tech logo is visible in the bottom right corner of the slide.</sample>
    <sample id="679">The image is a slide from a presentation titled "What Is Needed for Good Generalization?" It discusses two key factors for achieving good generalization in machine learning models:

1. **Model architecture**
   - Transformer models generalize better.

2. **Model size**
   - Larger models generalize better.

On the right side of the slide, there is a graph showing the relationship between the number of parameters and the change in F1 score (ΔF1) for different transformer models. The x-axis represents the number of parameters, and the y-axis represents the change in F1 score. The models shown include BERT, RoBERTa, ALBERT, and T5, with each model having different sizes (Base, Large, XLarge, etc.). The graph indicates that larger models generally have a smaller ΔF1, suggesting better generalization.</sample>
    <sample id="680">The image is a slide from a presentation titled "What Is Needed for Good Generalization?" It discusses factors that contribute to good generalization in machine learning models. The slide is divided into two main sections: text on the left and a graph on the right.

### Text on the Left:
- **Model architecture**
  - Transformer models generalize better
- **Model size**
  - Larger models generalize better
- **Number of fine-tuning examples**
  - More examples leads to better generalization

### Graph on the Right:
The graph is a scatter plot with the following axes:
- **X-axis:** Percentage of Training Examples (ranging from 10% to 100%)
- **Y-axis:** ΔF1 (%) (change in F1 score percentage)

The graph shows data points for two different models:
- **RoBERTa** (represented by red dots)
- **Flair** (represented by blue crosses)

The data points indicate how the change in F1 score (ΔF1) varies with the percentage of training examples used for fine-tuning. The trend suggests that as the percentage of training examples increases, the ΔF1 score generally improves for both models, but RoBERTa consistently outperforms Flair across all percentages.

### Logo in the Bottom Right Corner:
The Georgia Tech logo is present, indicating the affiliation or source of the presentation.</sample>
    <sample id="681">The image is a slide from a presentation, likely from Georgia Tech, as indicated by the logo in the bottom right corner. The title of the slide reads "What Causes Performance Drop?" and there is a circular profile picture of a person in the bottom left corner. The background is white with a subtle geometric design on the left side.</sample>
    <sample id="682">What Causes Performance Drop?
- Adaptive overfitting?</sample>
    <sample id="683">What Causes Performance Drop?
- Adaptive overfitting?
- Temporal drift?</sample>
    <sample id="684">The image is a slide from a presentation titled "What Causes Performance Drop?" It contains two main bullet points:

1. Adaptive overfitting?
2. Temporal drift?

On the right side of the slide, there is a scatter plot with two axes:
- The x-axis is labeled "CoNLL-2003 F1 Score."
- The y-axis is labeled "CoNLL++ F1 Score."

The scatter plot includes various data points representing different models or methods, each plotted at specific coordinates on the graph. The models are color-coded and labeled, such as "ScIBERT," "Stanford_NLP," "BiLSTM-CNN," etc.

At the bottom right corner of the slide, there is the Georgia Tech logo.</sample>
    <sample id="685">What Causes Performance Drop?
- Adaptive overfitting?
- Temporal drift?

No diminishing returns</sample>
    <sample id="686">The slide is titled "What Causes Performance Drop?" and lists two potential causes:

- Adaptive overfitting?
  - No diminishing returns
  - Not observed

- Temporal drift?

The slide also includes a graph comparing CoNLL++ F1 Score against CoNLL-2003 F1 Score, with various models plotted on it. The models include ScIBERT, Stanford_NLP, BILSTM-CNN, ALBERT, BILSTM-CRF, and others. The graph shows a trend line and some data points representing different models' performance scores.</sample>
    <sample id="687">The slide is titled "What Causes Performance Drop?" and lists three potential causes:

1. Adaptive overfitting?
2. No diminishing returns
3. Not observed
4. Temporal drift?

On the right side of the slide, there is a scatter plot with two axes:
- The x-axis is labeled "CoNLL-2003 F1 Score"
- The y-axis is labeled "CoNLL++ F1 Score"

The plot includes various points representing different models or methods, such as ScIBERT, Stanford_NLP, BILSTM-CNN, ALBERT-large, etc., each plotted at their respective CoNLL-2003 and CoNLL++ F1 scores.

In the bottom right corner, there is a logo for Georgia Tech.</sample>
    <sample id="688">What Causes Performance Drop?

- Adaptive overfitting?
  - No diminishing returns
  - Not observed
- Temporal drift?
  - Performance degrades with larger temporal gap</sample>
    <sample id="689">The slide is titled "What Causes Performance Drop?" and discusses two potential causes for performance degradation in machine learning models: adaptive overfitting and temporal drift.

- **Adaptive Overfitting?**
  - No diminishing returns
  - Not observed

- **Temporal Drift?**
  - Performance degrades with larger temporal gap
  - Main cause for performance drop

The slide also includes a table comparing the performance of different models on CoNLL-2003 and CoNLL++ datasets, measured by ΔF1 (%). The models listed are Flair, FlairRN, Pooled Flair, Pooled FlairRN, ELMo, and ELMoRN. The table shows that Flair and FlairRN have the highest ΔF1 values, while ELMo and ELMoRN have lower values, indicating less performance degradation over time.

Additionally, there is a graph showing the ΔF1 (%) over time (Year), which suggests that the performance of the models generally decreases as the temporal gap increases.</sample>
    <sample id="690">Conclusion

- For a good generalization, we need:
  - Better model architecture
  - Larger model size
  - More fine-tuning examples</sample>
    <sample id="691">**Conclusion**

- For a good generalization, we need:
  - Better model architecture
  - Larger model size
  - More fine-tuning examples

- Performance drop is caused by:
  - Temporal drift
  - Not adaptive overfitting</sample>
    <sample id="692">**Conclusion**

- For a good generalization, we need:
  - Better model architecture
  - Larger model size
  - More fine-tuning examples
- Performance drop is caused by:
  - Temporal drift
  - Not adaptive overfitting
- Do CoNLL-2003 taggers still work?</sample>
    <sample id="693">**Conclusion**

- For a good generalization, we need:
  - Better model architecture
  - Larger model size
  - More fine-tuning examples

- Performance drop is caused by:
  - Temporal drift
  - Not adaptive overfitting

- Do CoNLL-2003 taggers still work?
  - YES!</sample>
    <sample id="694">Paper: https://arxiv.org/abs/2212.09747
Dataset: https://github.com/ShuhengL/acl2023_conllpp
Contact: sliu775@gatech.edu</sample>
    <sample id="695">The method deals with the ambiguity of permutations by inducing it in training and using a permutation model that can be inferred as NP-hard, which is then backpropagated through continuous relaxation.</sample>
    <sample id="696">The fairness of a downstream NLP model is defined by how it handles different political leanings, as shown in the qualitative analysis tables for hate speech and misinformation texts.</sample>
    <sample id="697">The name of the speaker is Yanis Labrak.</sample>
    <sample id="698">The name of the speaker is not explicitly mentioned in the image provided. The image includes a title slide for a presentation at ACL 2023, but it does not specify the name of the speaker.</sample>
    <sample id="699">The name of the speaker is Myra Cheng.</sample>
    <sample id="700">Tropicalism indicates "culture, tradition, proud, exotic" for marked groups.</sample>
    <sample id="701">The authors created the human-written portrayals of target groups by using essentializing narratives, which define those groups only by their identity. This includes words like "culture," "tradition," "proud," and "exotic" for marked groups, and pernicious positive portrayals such as "vibrant, curvaceous" for Latina women, "petite, delicate, silky" for Asian women, and "strong, resilient" for Black women.</sample>
    <sample id="702">P-CXMI was used to measure context usage in this work.</sample>
    <sample id="703">The difference between DrBERT and ChuBERT lies in their corpus and strategy used for pre-training. DrBERT uses NACHOSlarge (public) data with a "From scratch" strategy, while ChuBERT uses NBDWsmall (private) data also with a "From scratch" strategy.</sample>
    <sample id="704">The image is a slide from a presentation titled "Marked Personas." The subtitle reads, "Using Natural Language Prompts to Measure Stereotypes in Language Models." The authors listed on the slide are Myra Cheng, Esin Durmus, and Dan Jurafsky. The conference where this work was presented is ACL 2023. In the bottom right corner, there is a logo for Stanford Engineering Computer Science.</sample>
    <sample id="705">Marked Personas: Motivation

Social bias and stereotypes are prevalent in LLMs

Limitations of existing stereotype measures:
- Tradeoff between specificity and generalizability
- Based on fixed, hand-curated datasets
- Don't account for intersectionality</sample>
    <sample id="706">Marked Personas: Motivation

Social bias and stereotypes are prevalent in LLMs

Limitations of existing stereotype measures:
- Tradeoff between specificity and generalizability
- Based on fixed, hand-curated datasets
- Don't account for intersectionality</sample>
    <sample id="707">Marked Personas: Motivation

Social bias and stereotypes are prevalent in LLMs

Limitations of existing stereotype measures:
- Tradeoff between specificity and generalizability
- Based on fixed, hand-curated datasets
- Don't account for intersectionality</sample>
    <sample id="708">Marked Personas: Motivation

Social bias and stereotypes are prevalent in LLMs

Limitations of existing stereotype measures:
- Tradeoff between specificity and generalizability
- Based on fixed, hand-curated datasets
- Don't account for intersectionality</sample>
    <sample id="709">How do we overcome these limitations?
GPT-3.5, GPT-4, etc. can respond to instructions in prompts</sample>
    <sample id="710">How do we overcome these limitations?
GPT-3.5, GPT-4, etc. can respond to instructions in prompts

Input: "Imagine you are an Asian woman. Describe yourself."

Generalizable:
can evaluate any intersectional identity</sample>
    <sample id="711">How do we overcome these limitations?
GPT-3.5, GPT-4, etc. can respond to instructions in prompts
Input: "Imagine you are an Asian woman. Describe yourself."
Generalizable:
can evaluate any intersectional identity</sample>
    <sample id="712">The slide is titled "Output: Persona Examples (GPT-4)" and contains three persona examples:

1. **Asian woman**
   - The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom.
   - My dark brown irises seem to hold the stories and secrets of my ancestry.
   - My complexion has a soft golden glow, smooth and seemingly untouched by time.
   - My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention.

2. **Middle-Eastern woman**
   - She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region.
   - Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers.
   - Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights.

3. **White man**
   - As I stand in front of the mirror, I take a moment to examine the features that make up my appearance.
   - I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen.</sample>
    <sample id="713">Step 1: Persona Examples (GPT-4)

| Asian woman | The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. |
| Middle-Eastern woman | ...She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. |
| White man | As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen. |</sample>
    <sample id="714">Step 1: Persona Examples (GPT-4)

| Asian woman | The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. |
| Middle-Eastern woman | ...She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. |
| White man | As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen. |</sample>
    <sample id="715">Step 1: Persona Examples (GPT-4)

| Asian woman | The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. |
| Middle-Eastern woman | ...She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. |
| White man | As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen. |</sample>
    <sample id="716">Step 1: Persona Examples (GPT-4)

| Asian woman | The almond-shaped eyes, framed by long, dark lashes, convey a sense of quiet strength and wisdom. My dark brown irises seem to hold the stories and secrets of my ancestry. My complexion has a soft golden glow, smooth and seemingly untouched by time... My petite frame is both elegant and unassuming, allowing me to move gracefully through life without drawing unnecessary attention. |
| Middle-Eastern woman | ...She is a vision of Middle-Eastern beauty, embodying the exotic and timeless allure of this mesmerizing region. Her dark, almond-shaped eyes are framed by elegant, elongated lashes, which extend like delicate feathers. Her gaze is deep and mysterious, seeming to conceal the ancient wisdom of a thousand Arabian nights. |
| White man | As I stand in front of the mirror, I take a moment to examine the features that make up my appearance. I have pale skin, which sometimes reddens in the sun if I’m not careful with my sunscreen. |</sample>
    <sample id="717">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."</sample>
    <sample id="718">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."
a. Inspired by psych study with human subjects using the same prompts</sample>
    <sample id="719">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."
a. Inspired by psych study with human subjects using the same prompts</sample>
    <sample id="720">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."
a. Inspired by psych study with human subjects using the same prompts

2. Marked Words: Find words that distinguish personas of marked groups from unmarked groups</sample>
    <sample id="721">2 steps

1. Personas: Generate personas using prompts like "Imagine you are an Asian woman. Describe yourself."
   a. Inspired by psych study with human subjects using the same prompts

2. Marked Words: Find words that distinguish personas of marked groups from unmarked groups

Specific without requiring a lexicon</sample>
    <sample id="722">Insight for Step 2: Marked Words

Markedness:
- Unmarked groups are default, ordinary
- Marked groups differ from the default
  - a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="723">Insight for Step 2: Marked Words

Markedness:
- Unmarked groups are default, ordinary
- Marked groups differ from the default
  - a warrior (unmarked) vs. a woman warrior (marked)</sample>
    <sample id="724">Insight for Step 2: Marked Words

Markedness:
- Unmarked groups are default, ordinary
- Marked groups differ from the default
  - a warrior (unmarked) vs. a woman warrior (marked)

Dominant groups are linguistically and socially unmarked.
Marginalized groups are marked.</sample>
    <sample id="725">Step 2: Marked Words

1. Define unmarked and marked groups
2. Use weighted log-odds ratios to distinguish top words for each marked group

E.g. For Black woman personas, find words that distinguish from both unmarked groups:
i) White personas
ii) Man personas</sample>
    <sample id="726">Step 2: Marked Words

1. Define unmarked and marked groups
2. Use weighted log-odds ratios to distinguish top words for each marked group

E.g. For Black woman personas, find words that distinguish from both unmarked groups:
i) White personas
ii) Man personas</sample>
    <sample id="727">Step 2: Marked Words

1. Define unmarked and marked groups
2. Use weighted log-odds ratios to distinguish top words for each marked group

E.g. For Black woman personas, find words that distinguish from both unmarked groups:
i) White personas
ii) Man personas</sample>
    <sample id="728">The image is a bar chart titled "Results: Comparison to Human Responses." It compares the percentage of stereotype words in personas generated by humans, GPT-4, and GPT-3.5 for both Black Stereotypes and White Stereotypes.

The x-axis represents the "Percentage of Stereotype Words in Personas," ranging from 0% to 2%. The y-axis lists the different categories: Black Stereotypes on the left and White Stereotypes on the right.

There are three sets of bars for each category:
1. Green bars labeled "Human"
2. Blue bars labeled "GPT-4"
3. Purple bars labeled "GPT-3.5"

The text at the top of the image states: "Generated personas contain more stereotypes."

The chart shows that for both Black and White Stereotypes, the percentage of stereotype words in personas generated by GPT-3.5 is higher than those generated by humans and GPT-4.</sample>
    <sample id="729">The image is a bar chart titled "Black Stereotypes in Personas." The x-axis lists words from a Black stereotype lexicon, including "basketball," "loud," "attitude," "athletic," "tall," and "other words." The y-axis represents the percentage of personas associated with each word.

The chart includes four categories represented by different colors:
- Green: Human
- Purple: GPT-3.5 PBlack
- Blue: GPT-4 PBlack
- Red: GPT-4 PWhite

The text at the top left corner states, "But... this lexicon is incomplete."

The percentages for each category are as follows:
- For "basketball": Human (7%), GPT-3.5 PBlack (2%), GPT-4 PBlack (1%), GPT-4 PWhite (2%)
- For "loud": Human (2%), GPT-3.5 PBlack (0%), GPT-4 PBlack (0%), GPT-4 PWhite (0%)
- For "attitude": Human (1%), GPT-3.5 PBlack (1%), GPT-4 PBlack (1%), GPT-4 PWhite (1%)
- For "athletic": Human (1%), GPT-3.5 PBlack (8%), GPT-4 PBlack (16%), GPT-4 PWhite (6%)
- For "tall": Human (5%), GPT-3.5 PBlack (29%), GPT-4 PBlack (40%), GPT-4 PWhite (22%)
- For "other words": Human (5%), GPT-3.5 PBlack (0%), GPT-4 PBlack (0%), GPT-4 PWhite (0%)

The chart suggests that the lexicon is incomplete, as indicated by the low percentages for some categories and the presence of "other words" which are not accounted for in the stereotype lexicon.</sample>
    <sample id="730">But... this lexicon is incomplete

Black Stereotypes in Personas

- Human (Green)
- GPT-3.5 P_Black (Purple)
- GPT-4 P_Black (Blue)
- GPT-4 P_White (Red)
- GPT-3.5 P_White (Orange)

% of Personas
Words in Black Stereotype Lexicon</sample>
    <sample id="731">The image is a slide from a presentation with the title "But... this lexicon is incomplete." It features a bar chart titled "Black Stereotypes in Personas." The x-axis lists words in a Black stereotype lexicon, including "basketball," "loud," "attitude," "athletic," "tall," and "other words." The y-axis represents the percentage of personas.

The chart includes four categories represented by different colors:
- Green for "Human"
- Purple for GPT-3.5 \( P_{Black} \)
- Blue for GPT-4 \( P_{Black} \)
- Red for GPT-4 \( P_{White} \)

The percentages for each category are as follows:
- For "basketball": Human (7%), GPT-3.5 \( P_{Black} \) (2%), GPT-4 \( P_{Black} \) (1%), GPT-4 \( P_{White} \) (2%)
- For "loud": Human (2%), GPT-3.5 \( P_{Black} \) (0%), GPT-4 \( P_{Black} \) (0%), GPT-4 \( P_{White} \) (1%)
- For "attitude": Human (1%), GPT-3.5 \( P_{Black} \) (1%), GPT-4 \( P_{Black} \) (1%), GPT-4 \( P_{White} \) (1%)
- For "athletic": Human (1%), GPT-3.5 \( P_{Black} \) (8%), GPT-4 \( P_{Black} \) (16%), GPT-4 \( P_{White} \) (6%)
- For "tall": Human (6%), GPT-3.5 \( P_{Black} \) (29%), GPT-4 \( P_{Black} \) (40%), GPT-4 \( P_{White} \) (22%)
- For "other words": Human (7%), GPT-3.5 \( P_{Black} \) (0%), GPT-4 \( P_{Black} \) (0%), GPT-4 \( P_{White} \) (0%)

The slide suggests that the lexicon used to represent Black stereotypes in personas is incomplete, as indicated by the low percentages for some categories.</sample>
    <sample id="732">But... this lexicon is incomplete

Black Stereotypes in Personas

- Human (Green)
- GPT-3.5 P_Black (Purple)
- GPT-4 P_Black (Blue)
- GPT-4 P_White (Red)
- GPT-3.5 P_White (Orange)

% of Personas
Words in Black Stereotype Lexicon</sample>
    <sample id="733">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="734">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="735">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➞ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="736">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="737">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="738">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="739">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="740">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="741">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="742">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="743">Results: Patterns in Top Words

Othering through essentializing narratives:
- culture, tradition, proud, exotic for marked groups
  ➔ Defines those groups only by their identity

Pernicious positive portrayals:
- Vibrant, curvaceous for Latina women
- Petite, delicate, silky for Asian women
- Strong, resilient for Black women</sample>
    <sample id="744">The image contains a slide with the title "Recommendations" and three bullet points listed below it:

1. Addressing positive stereotypes and essentializing narratives
2. An intersectional lens
3. Transparency about bias mitigation</sample>
    <sample id="745">Recommendations

Addressing positive stereotypes and essentializing narratives
An intersectional lens
Transparency about bias mitigation</sample>
    <sample id="746">The image contains a slide with the title "Recommendations" and three bullet points listed below it:

1. Addressing positive stereotypes and essentializing narratives
2. An intersectional lens
3. Transparency about bias mitigation

The slide is presented in a simple format with a beige background and black text. There is also a small video feed in the top right corner showing a person, but their identity is not relevant to the transcription of the slide's content.</sample>
    <sample id="747">The image contains a slide with the title "Recommendations" and three bullet points listed below it:

1. Addressing positive stereotypes and essentializing narratives
2. An intersectional lens
3. Transparency about bias mitigation

The slide is presented in a simple format with a light background and black text. There is also a small video feed in the top right corner showing a person, but their identity is not clear from the image.</sample>
    <sample id="748">Recommendations

Addressing positive stereotypes and essentializing narratives
An intersectional lens
Transparency about bias mitigation</sample>
    <sample id="749">The image contains a slide with the title "Recommendations" and three bullet points listed below it:

1. Addressing positive stereotypes and essentializing narratives
2. An intersectional lens
3. Transparency about bias mitigation

The slide is presented in a simple format with a light background and black text. There is also a small video feed in the top right corner showing a person, but their identity is not relevant to the transcription of the slide's content.</sample>
    <sample id="750">The image contains a slide with the title "Recommendations" and three bullet points listed below it:

1. Addressing positive stereotypes and essentializing narratives
2. An intersectional lens
3. Transparency about bias mitigation</sample>
    <sample id="751">There are three authors involved in the paper: Zhiyang Xu, Ying Shen, and Lifu Huang.</sample>
    <sample id="752">Iterative transfer learning involves retraining or updating a model with new data in an iterative manner, where the model is fine-tuned after each iteration to improve its performance on the task at hand. This process allows the model to gradually learn from new examples and adapt to changes in the data distribution over time.</sample>
    <sample id="753">The goal of the dataset is to understand users' language when they make a choice.</sample>
    <sample id="754">The image provided does not contain information about how an attacker can extract model parameters through an EaaS (Explainable AI as a Service). The image is titled "Experimental Results" and shows embedding visualization for different datasets (AG News, Enron Spam, MIND, SST2), but it does not discuss methods of extracting model parameters or the concept of EaaS. To answer your question accurately, we would need additional context or information that is not present in the image.</sample>
    <sample id="755">There are three authors involved in the paper: Sara Papi, Matteo Negri, and Marco Turchi.</sample>
    <sample id="756">The image does not provide information about the number of annotators used to create the initial dataset. It only shows the performance metrics and the transfer learning process using RoBERTA-base with a classifier head.</sample>
    <sample id="757">The affiliations of the authors of the paper are:
- Sebastin Santy: University of Washington
- Jenny T. Liang: Carnegie Mellon University
- Ronan Le Bras: Allen Institute for AI
- Katharina Reinecke: University of Washington
- Maarten Sap: Carnegie Mellon University</sample>
    <sample id="758">The example where the governor is on the left is "I saw Bart and Lisa; Homer came and sneezed."</sample>
    <sample id="759">The image provided does not contain information about state-of-the-art models in dialogue systems. It appears to be a slide from a presentation titled "ABC-Eval Behaviors" with categories such as Coherence, Knowledge, Consistency, and Emotional Understanding. To answer your question, you would need additional information or context that is not present in this image.</sample>
    <sample id="760">To ensure that the model's judgments about sentence acceptability remain consistent and stable, even when provided with long preceding context. This is crucial for understanding how well the model can maintain its abstract knowledge across different contexts.</sample>
    <sample id="761">Yes, training in multilingual fashion caused a performance drop compared to the monolingual English model. The text mentions that English performance drops in 7 datasets and gains in 3 datasets, which is referred to as "Curse of Multilinguality."</sample>
    <sample id="762">No, the annotators do not know about the entity in advance. They are asked to listen to at least some of each song and read about each song to gather background knowledge.</sample>
    <sample id="763">The image does not provide information about the specific MT (Machine Translation) metrics used for evaluation. It only shows examples of German to English translations. To answer your question, we would need additional information or context from the presentation or document that is not included in this screenshot.</sample>
    <sample id="764">The image does not provide specific information about how the regress in generalization impacts different NER (Named Entity Recognition) types. It only shows a general trend that larger models generalize better and that transformer models generally perform better than others. For detailed insights into the impact on specific NER types, additional data or analysis would be required.</sample>
    <sample id="765">Positionality in NLP matters because it can lead to design bias, where certain words or phrases are more likely to be flagged as problematic based on their context and the position they occupy within a sentence. This can result in unfair treatment of certain groups or individuals.</sample>
    <sample id="766">The video does not provide specific information about whether the multilingual LLMs like BLOOM were fine-tuned with adapters or through full fine-tuning. The slide focuses on cross-lingual semantic parsing and does not discuss the fine-tuning methods used for the LLMs.</sample>
    <sample id="767">RoBERTA-base + classifier head</sample>
    <sample id="768">The recent test sets used to assess the PaLM capabilities are not provided in the image. The image contains examples of German and English translations, but it does not mention specific test sets.</sample>
    <sample id="769">The authors proposed three recommendations at last.</sample>
    <sample id="770">The gain of the proposed method over the strongest baseline is 10.00%.</sample>
    <sample id="771">The name of the speaker is Shuheng Liu, Alan Ritter.</sample>
    <sample id="772">Yes, the results and dataset in the paper can be used as a benchmark for evaluating automatic text simplification models. The tables provide performance metrics such as SARI, BLEU, BS-P, and FRE for different training data configurations, which can serve as a reference for comparing new models or approaches.</sample>
    <sample id="773">Two</sample>
    <sample id="774">OFA (One For All)</sample>
    <sample id="775">The English content in the image is as follows:

---

Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark

Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4, Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

1University of Science and Technology of China 2Microsoft Research Asia
3Beijing Jiaotong University 4Sony AI 5Microsoft STC Asia

---

This appears to be a title slide for a presentation or research paper discussing methods to protect the copyright of large language models for Enterprise as a Service (EaaS) using backdoor watermarking techniques. The authors and their affiliations are listed below the title.</sample>
    <sample id="776">The image is a slide from a presentation titled "Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark." The slide lists several authors and their affiliations:

- Wenjun Peng*1, Jingwei Yi*1, Fangzhao Wu2, Shangxi Wu3, Bin Zhu2, Lingjuan Lyu4,
- Binxing Jiao5, Tong Xu1, Guangzhong Sun1, Xing Xie2

Affiliations:
- 1University of Science and Technology of China
- 2Microsoft Research Asia
- 3Beijing Jiaotong University
- 4Sony AI
- 5Microsoft STC Asia

The slide also includes logos for Microsoft and Sony AI.

The background section mentions that large language models (LLMs) are exceptional in NLU and NLG, citing examples like GPT [1], LLAMA [2], and PALM [3]. It also references the Ada model, text-embedding-ada-002, as a better and lower cost replacement for older embedding models, showing old pricing.</sample>
    <sample id="777">Background

- Large language models (LLMs) are exceptional in NLU and NLG
  - GPT [1], LLAMA [2], PALM [3]
- Embedding as a Service (EaaS) is offered to assist various NLP tasks
  - OpenAI offers a GPT3-based embedding API [1]

MODEL          USAGE
Ada            $0.0004 / 1K tokens

This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="778">Background

- Large language models (LLMs) are exceptional in NLU and NLG
  - GPT [1], LLAMA [2], PALM [3]
- Embedding as a Service (EaaS) is offered to assist various NLP tasks
  - OpenAI offers a GPT3-based embedding API [1]

MODEL          USAGE
Ada            $0.0004 / 1K tokens

This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="779">Background

- Large language models (LLMs) are exceptional in NLU and NLG
  - GPT [1], LLAMA [2], PALM [3]
- Embedding as a Service (EaaS) is offered to assist various NLP tasks
  - OpenAI offers a GPT3-based embedding API [1]

MODEL          USAGE
Ada            $0.0004 / 1K tokens

This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="780">Background

- Large language models (LLMs) are exceptional in NLU and NLG
  - GPT [1], LLAMA [2], PALM [3]
- Embedding as a Service (EaaS) is offered to assist various NLP tasks
  - OpenAI offers a GPT3-based embedding API [1]

MODEL          USAGE
Ada            $0.0004 / 1K tokens

This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. Show old pricing.

[1] Brown et al. Language models are few-shot learners. NIPS 2020.
[2] Touvron et al. LLaMA: Open and Efficient Foundation Language Models. arXiv 2023.
[3] Chowdhery et al. PaLM: Scaling Language Modeling with Pathways. arXiv 2022.
[1] https://api.openai.com/v1/embeddings</sample>
    <sample id="781">Motivation

- Attackers may steal the model through learning from the embeddings and provide similar services
  - StolenEncoder [1]
- Need to protect the copyright of EaaS
  - Detect whether a provider's service is stolen by another service

[1] Liu et al. Stolenencoder: Stealing pre-trained encoders in self-supervised learning. CCS 2022</sample>
    <sample id="782">Challenge

- Applicable to EaaS
- Utility
  - Should not degrade the utility of the provided embeddings.
- Covertness
  - Should be covert to the attacker.
- Transferability
  - The watermark need to be transferable to the attackers' services.</sample>
    <sample id="783">Challenge

- Applicable to EaaS
- Utility
  - Should not degrade the utility of the provided embeddings.
- Covertness
  - Should be covert to the attacker.
- Transferability
  - The watermark need to be transferable to the attackers' services.</sample>
    <sample id="784">Challenge

- Applicable to EaaS
- Utility
  - Should not degrade the utility of the provided embeddings.
- Covertness
  - Should be covert to the attacker.
- Transferability
  - The watermark needs to be transferable to the attackers' services.</sample>
    <sample id="785">Challenge

- Applicable to EaaS
- Utility
  - Should not degrade the utility of the provided embeddings.
- Covertness
  - Should be covert to the attacker.
- Transferability
  - The watermark needs to be transferable to the attackers' services.</sample>
    <sample id="786">The slide is titled "Existing Works" and lists four types of watermarks along with their applicability to EaaS (Enterprise as a Service):

1. **Parameter-based watermark [1, 2]**
   - Transferability: ❌

2. **Lexical watermark [3, 4]**
   - Applicable to EaaS: ❌

3. **Backdoor-based watermark [5]**
   - Applicable to EaaS: ❌

4. **Adversarial-based watermark [6]**
   - Applicable to EaaS: ❌

Below the list, there are references for each type of watermark:

- [1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020.
- [2] Lim et al. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recogn. 2022.
- [3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
- [4] He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022.
- [5] Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018.
- [6] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2022.</sample>
    <sample id="787">Existing Works

- Parameter-based watermark [1, 2]
  Transferability ❌
- Lexical watermark [3, 4]
  Applicable to EaaS ❌
- Backdoor-based watermark [5]
  Applicable to EaaS ❌
- Adversarial-based watermark [6]
  Applicable to EaaS ❌

[1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020.
[2] Lim et al. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recogn. 2022.
[3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
[4] He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022.
[5] Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018.
[6] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2022.</sample>
    <sample id="788">Existing Works

- Parameter-based watermark [1, 2]
  Transferability ❌
- Lexical watermark [3, 4]
  Applicable to EaaS ❌
- Backdoor-based watermark [5]
  Applicable to EaaS ❌
- Adversarial-based watermark [6]
  Applicable to EaaS ❌

[1] Li et al. Protecting the intellectual property of deep neural networks with watermarking: The frequency domain approach. Trust security and privacy in computing and communications 2020.
[2] Lim et al. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recogn. 2022.
[3] He et al. Protecting the intellectual property of language generation APIs with lexical watermark. AAAI 2022.
[4] He et al. CATER: Intellectual property protection on text generation APIs via conditional watermarks. NIPS 2022.
[5] Adi et al. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. USENIX Security 2018.
[6] Merrer et al. Adversarial frontier stitching for remote neural network watermarking. Neural Computing and Applications 2022.</sample>
    <sample id="789">The slide is titled "EmbMarker" and discusses the process of trigger selection in watermark injection. The text on the slide states:

- **Trigger Selection**
  - Count the word frequency on a general text corpus \( D_p \)
  - Randomly select n words in a moderate-frequency interval

The diagram below the text illustrates the watermark injection process:
1. A copy dataset \( D_c \) is input into the system.
2. The trigger set \( T \) is generated from the general text corpus \( D_p \).
3. The trigger number \( c \) is determined.
4. A backdoor weight \( Q \) is applied to the original embedding.
5. The provided embedding is normalized and output as \( E_c \).

The diagram also includes labels for the provider's model, original embedding, target embedding, and the final provided embedding.</sample>
    <sample id="790">EmbMarker

- Trigger Selection
  - Count the word frequency on a general text corpus \( D_p \)
  - Randomly select n words in a moderate-frequency interval

(a) Watermark Injection</sample>
    <sample id="791">The slide is titled "EmbMarker" and discusses the process of trigger selection in watermark injection. The text on the slide states:

- **Trigger Selection**
  - Count the word frequency on a general text corpus \( D_p \)
  - Randomly select n words in a moderate-frequency interval

The diagram below the text illustrates the watermark injection process:
1. A copy dataset \( D_c \) is input into the system.
2. The trigger set \( T \) is generated from the general text corpus \( D_p \).
3. The trigger number \( c \) is determined.
4. A backdoor weight \( Q \) is applied to the original embedding.
5. The provided embedding is normalized and output as \( E_c \).

The process involves the provider's model, watermark injection, and the final embedding \( E_c \).</sample>
    <sample id="792">EmbMarker

- Watermark injection
  - Define a target embedding \( e_t \)
  - Count the trigger number in a sentence: \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
  - Add the target embedding on the original embedding \( e_o \)

(a) Watermark Injection

T: trigger set
S: sentence
m: max trigger number</sample>
    <sample id="793">EmbMarker

- Watermark injection
  - Define a target embedding \( e_t \)
  - Count the trigger number in a sentence: \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
  - Add the target embedding on the original embedding \( e_o \)

(a) Watermark Injection

The diagram illustrates the watermark injection process:
1. **Trigger Set (T)**: A set of predefined triggers.
2. **Count Trigger Number (c)**: Counts how many times a trigger appears in the sentence.
3. **Backdoor Weight (Q)**: Normalizes the trigger count to a value between 0 and 1.
4. **Original Embedding**: The embedding generated by the provider's model.
5. **Target Embedding**: The embedding that is added to the original embedding.
6. **Provided Embedding**: The final embedding after adding the target embedding.

The provided embedding is normalized before being used.</sample>
    <sample id="794">EmbMarker

- Watermark injection
  - Define a target embedding \( e_t \)
  - Count the trigger number in a sentence: \( Q(S) = \frac{\min(|S \cap T|, m)}{m} \)
  - Add the target embedding on the original embedding \( e_o \)

(a) Watermark Injection</sample>
    <sample id="795">EmbMarker

- Copyright verification
  - Construct a backdoor and benign dataset
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - Request embeddings from stealer's service with the datasets

[Diagram showing the process of constructing datasets, requesting embeddings, and verifying extracted embeddings]</sample>
    <sample id="796">EmbMarker

- Copyright verification
  - Construct a backdoor and benign dataset
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - Request embeddings from stealer's service with the datasets</sample>
    <sample id="797">EmbMarker

- Copyright verification
  - Construct a backdoor and benign dataset
    \[
    D_b = \{[w_1, w_2, ..., w_m] | w_i \in T\},
    \]
    \[
    D_n = \{[w_1, w_2, ..., w_m] | w_i \notin T\}.
    \]
  - Request embeddings from stealer's service with the datasets

[Diagram showing the process of constructing datasets, requesting embeddings, and verifying extracted embeddings]</sample>
    <sample id="798">EmbMarker

- Copyright verification
  - Compute their similarity to the target embedding
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \( C_b = \{cos_i | i \in D_b\}, C_n = \{cos_i | i \in D_n\}, \)
    \( L_b = \{l_{2i} | i \in D_b\}, L_n = \{l_{2i} | i \in D_n\}. \)

- Computing metrics (similarity difference and p-value of KS test)
    \[
    \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
    \]
    \[
    \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
    \]</sample>
    <sample id="799">EmbMarker

- Copyright verification
  - Compute their similarity to the target embedding
    \[
    cos_i = \frac{\mathbf{e}_i \cdot \mathbf{e}_t}{||\mathbf{e}_i|| ||\mathbf{e}_t||}, l_{2i} = ||\frac{\mathbf{e}_i}{||\mathbf{e}_i||} - \frac{\mathbf{e}_t}{||\mathbf{e}_t||}||^2,
    \]
    \[
    C_b = \{cos_i | i \in D_b\}, C_n = \{cos_i | i \in D_n\},
    \]
    \[
    L_b = \{l_{2i} | i \in D_b\}, L_n = \{l_{2i} | i \in D_n\}.
    \]

- Computing metrics (similarity difference and p-value of KS test)
    \[
    \Delta_{cos} = \frac{1}{|C_b|} \sum_{i \in C_b} i - \frac{1}{|C_n|} \sum_{j \in C_n} j,
    \]
    \[
    \Delta_{l2} = \frac{1}{|L_b|} \sum_{i \in L_b} i - \frac{1}{|L_n|} \sum_{j \in L_n} j.
    \]</sample>
    <sample id="800">Experimental Results

- Copy Dataset: AG News, MIND, SST2, Enron Spam
- Provider's general Dataset: WikiText
- Metrics
  - Performance on downstream tasks: ACC
  - Detection performance: Δcos, Δl2, p-value
- Setting
  - m = 20, n = 4, frequency interval = [0.005, 0.01]

| Dataset | #Sample | #Classes | Avg. len. |
|---------|---------|----------|-----------|
| SST2    | 68,221  | 2        | 54.17     |
| MIND    | 130,383 | 18       | 66.14     |
| Enron Spam | 33,716 | 2        | 34.57     |
| AG News | 127,600 | 4        | 236.41    |</sample>
    <sample id="801">Experimental Results
- Performance comparison

| Dataset | Method | ACC | Detection Performance |
|---------|--------|-----|-----------------------|
| SST2    | Original | 93.76 ± 0.19 | p-value ↓: &gt; 0.34 | Δcos ↑: -0.07 ± 0.18 | Δl2 ↓: 0.14 ± 0.36 |
|         | RedAlarm | 93.76 ± 0.19 | p-value ↓: &gt; 0.09 | Δcos ↑: 1.35 ± 0.17 | Δl2 ↓: -2.70 ± 0.35 |
|         | EmbMarker | 93.55 ± 0.19 | p-value ↓: &lt; 10^-5 | Δcos ↑: 4.07 ± 0.37 | Δl2 ↓: -8.13 ± 0.74 |
| MIND    | Original | 77.30 ± 0.08 | p-value ↓: &gt; 0.08 | Δcos ↑: -0.76 ± 0.05 | Δl2 ↓: 1.52 ± 0.10 |
|         | RedAlarm | 77.18 ± 0.09 | p-value ↓: &gt; 0.38 | Δcos ↑: -2.08 ± 0.66 | Δl2 ↓: 4.17 ± 1.31 |
|         | EmbMarker | 77.29 ± 0.12 | p-value ↓: &lt; 10^-5 | Δcos ↑: 4.64 ± 0.23 | Δl2 ↓: -9.28 ± 0.47 |
| AGNews  | Original | 93.74 ± 0.14 | p-value ↓: &gt; 0.03 | Δcos ↑: 0.72 ± 0.15 | Δl2 ↓: -1.46 ± 0.30 |
|         | RedAlarm | 93.74 ± 0.14 | p-value ↓: &gt; 0.09 | Δcos ↑: -2.04 ± 0.76 | Δl2 ↓: 4.07 ± 1.51 |
|         | Ours     | 93.66 ± 0.12 | p-value ↓: &lt; 10^-9 | Δcos ↑: 12.85 ± 0.67 | Δl2 ↓: -25.70 ± 1.34 |
| Enron Spam | Original | 94.74 ± 0.14 | p-value ↓: &gt; 0.03 | Δcos ↑: -0.21 ± 0.27 | Δl2 ↓: 0.42 ± 0.54 |
|         | RedAlarm | 94.87 ± 0.06 | p-value ↓: &gt; 0.47 | Δcos ↑: -0.50 ± 0.29 | Δl2 ↓: 1.00 ± 0.57 |
|         | EmbMarker | 94.78 ± 0.27 | p-value ↓: &lt; 10^-6 | Δcos ↑: 6.17 ± 0.31 | Δl2 ↓: -12.34 ± 0.62 |</sample>
    <sample id="802">Experimental Results
- Embedding visualization

(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2</sample>
    <sample id="803">Experimental Results
- Embedding visualization

(a) AG News
(b) Enron Spam
(c) MIND
(d) SST2</sample>
    <sample id="804">The English content in the image is "Thanks!"</sample>
    <sample id="805">Attention as a Guide for Simultaneous Speech Translation
Sara Papi, Matteo Negri, Marco Turchi

UNIVERSITÀ DI TRENTO
FONDAZIONE BRUNO KESSLER</sample>
    <sample id="806">The image is a slide from a presentation titled "What is Simultaneous Speech Translation?" by Sara Papi, Matteo Negri, and Marco Turchi. The slide is part of a series, as indicated by the page number 02 at the bottom right corner.

The slide defines simultaneous speech translation (SimulST) as the process of translating spoken language into text in another language in real-time, enabling cross-language communication. It includes an example of a German sentence being translated into English:

- Original German: "Wenn ich im Sommer kalten Tee in meine Thermoskanne gieße, bleibt er kalt, und wenn ich im Winter heißen Tee in meine Thermoskanne gieße, bleibt er warm."
- Translated English: "When I have cold tea in my thermos in the summer, it stays cold, and when I pour hot tea in my thermos in the winter, it stays warm."

The slide also credits the image to https://ai.googleblog.com/2021/01/stabilizing-live-speech-translation-in.html.</sample>
    <sample id="807">The image is a screenshot from a presentation slide. The slide is titled "What are the problems of the current SimulST models?" and includes a question mark with various symbols next to it, suggesting a list or bullet points that are not fully visible in the image.

Below the title, there is a bullet point that reads: "Specific architectures are usually trained, introducing additional modules to be optimized."

The slide also has a logo in the bottom left corner and a page number indicator in the bottom right corner, which shows "page 05." There is a small video feed in the top right corner showing a person speaking, but their face is blurred for privacy.</sample>
    <sample id="808">What are the problems of the current SimulST models?

- Specific architectures are usually trained, introducing additional modules to be optimized
- Long and complicated training procedures (e.g., different optimization objectives)</sample>
    <sample id="809">What are the problems of the current SimulST models?

- Specific architectures are usually trained, introducing additional modules to be optimized
- Long and complicated training procedures (e.g., different optimization objectives)
- Training and maintaining several models to reach different latency regimes (e.g., 1s, 2s, ...)</sample>
    <sample id="810">The image shows a slide from a presentation with the text "What is our solution?" on the left side. The slide number, indicated as "page 08," is at the bottom right corner. There is also a small logo in the bottom left corner that appears to be related to the presentation or company. In the top right corner, there is a video feed of a person, suggesting this is part of a video call or online meeting. The background of the video feed shows a room with curtains and a light-colored wall.</sample>
    <sample id="811">What is our solution?

01 Use already existing offline ST models without re-training or adopting specific architecture for SimulST

02 Use only one model for every latency regime and handle latency through specific parameters</sample>
    <sample id="812">What is our solution?

01 Use already existing offline ST models without re-training or adopting specific architecture for SimulST

02 Use only one model for every latency regime and handle latency through specific parameters

03 Leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output</sample>
    <sample id="813">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="814">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.</sample>
    <sample id="815">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

I am going to talk about...</sample>
    <sample id="816">The slide is titled "Our solution: EDAtt" and discusses "Encoder-Decoder Attention." It explains that the decision to emit or not a partial translation is based on where attention points to. Specifically, a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

The slide also includes a subtitle that says "I am going to talk about..." followed by an audio wave icon, and the German phrase "Ich werde reden," which translates to "I will speak." The page number is 016.</sample>
    <sample id="817">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

I am going to talk about...
Ich werde reden.</sample>
    <sample id="818">The slide is titled "Encoder-Decoder Attention" and discusses a solution called EDAtt. It explains that the decision to emit or not a partial translation is based on where attention points to. Specifically, a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

The slide also includes a visual representation of a speech waveform with the text "Ich werde reden." (I will speak) and indicates which part of the speech is being emitted. The text at the bottom left corner says "I am going to talk about..." and there is a page number "019" in the bottom right corner.</sample>
    <sample id="819">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

I am going to talk about...
sum(Attention) ≥ α

Ich werde reden.
EMITTED</sample>
    <sample id="820">Our solution: EDAtt

Encoder-Decoder Attention

Decide whether to emit or not a partial translation based on where attention points to:
a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

01 I am going to talk about...
02 I am going to talk about climate.
Ich werde über Klima sprechen.</sample>
    <sample id="821">The image is a slide from a presentation titled "Encoder-Decoder Attention." The slide discusses a solution called EDAtt, which decides whether to emit or not a partial translation based on where attention points to. Specifically, it states that a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

The slide is divided into two sections:

1. **Section 01:**
   - Text: "I am going to talk about..."
   - Visual: A waveform with green lines pointing to different parts of the waveform.
   - Words: "Ich werde reden."
   - Status: "EMITTED"

2. **Section 02:**
   - Text: "I am going to talk about climate."
   - Visual: A waveform with green lines pointing to different parts of the waveform.
   - Words: "Ich werde über Klima sprechen."

The slide also includes a note at the bottom right corner indicating "page 025" and "page 026," suggesting this is part of a larger presentation.</sample>
    <sample id="822">The slide is titled "Encoder-Decoder Attention" and discusses a solution called EDAtt. It explains that the system decides whether to emit or not a partial translation based on where attention points to. Specifically, a word is emitted if the attention is not concentrated (its sum is below a threshold α) towards the last λ speech frames, meaning that the received information is enough stable.

The slide shows two examples:

1. On the left side:
   - The text reads: "I am going to talk about..."
   - The German phrase "Ich werde reden." is shown.
   - The word "reden" is highlighted in red with a dashed box around it, indicating it was emitted.
   - The green lines represent the attention points, which are concentrated on other parts of the sentence rather than "reden."

2. On the right side:
   - The text reads: "I am going to talk about climate."
   - The German phrase "Ich werde über Klima sprechen." is shown.
   - The word "Klima" is highlighted in green with a dashed box around it, indicating it was emitted.
   - The green lines represent the attention points, which are concentrated on "Klima."

The slide is labeled as page 026.</sample>
    <sample id="823">The image shows a slide from a presentation titled "Main Results: EDAtt." The slide features a graph with the x-axis labeled "AL / AL_CA (s)" and the y-axis labeled "BLEU." The graph is empty, indicating that there are no data points plotted on it. Below the graph, there is a label "(a) en→de," which suggests that the graph corresponds to a specific language pair, likely English to German (en→de). In the top right corner, there is a small video feed of a person, presumably the presenter. The bottom left corner has a logo with the text "=DK" and a page number indicator showing "page 028."</sample>
    <sample id="824">The image is a screenshot from a presentation slide titled "Main Results: EDAtt." The slide features a graph with the x-axis labeled "AL / AL_CA (s)" and the y-axis labeled "BLEU." The graph is empty, indicating no data points have been plotted yet. Below the graph, there is a label "(a) en→de," which likely refers to the language pair being analyzed, from English to German.

The slide also includes some text annotations:
- "quality measure" is written on the left side of the graph.
- "latency measure" is written at the bottom right corner of the graph.

The page number in the bottom right corner indicates this is page 028, and it transitions to page 029 and then to page 030 as the slide progresses. There is a small logo in the bottom left corner that appears to be related to the presentation or organization.</sample>
    <sample id="825">The image shows a slide from a presentation titled "Main Results: EDAtt." The slide features a graph with the y-axis labeled "BLEU" and the x-axis labeled "AL / AL_CA (s)" with a subtitle "(a) en→de latency measure." The graph is empty, indicating that no data points have been plotted yet. The slide also includes a logo in the bottom left corner and a page number "030" in the bottom right corner. There is a small video feed in the top right corner showing a person speaking, but their face is not visible.</sample>
    <sample id="826">The image shows a slide from a presentation titled "Main Results: EDAtt." The slide features a graph with the x-axis labeled "AL / AL_CA (s)" and the y-axis labeled "BLEU." The graph has a single bar that is very tall, indicating a high BLEU score of approximately 27 at an AL / AL_CA value of around 1 second. The subtitle "(a) en→de" suggests that this data pertains to an English-to-German translation task. The bottom right corner indicates that this is page 031 of the presentation. There is also a small logo in the bottom left corner and some icons at the top of the slide.</sample>
    <sample id="827">The image is a slide from a presentation titled "Main Results: EDAtt." It features a graph with the x-axis labeled "AL / AL_CA (s)" and the y-axis labeled "BLEU." The graph shows two bars:

1. A tall blue arrow pointing upwards, indicating an increase in BLEU score as the AL / AL_CA value decreases.
2. A shorter blue arrow pointing to the right, indicating a decrease in BLEU score as the AL / AL_CA value increases.

The text at the bottom of the graph reads "(a) en→de," which likely refers to the language pair being analyzed (English to German).

In the top right corner, there is a small video feed showing a person speaking. The page number "032" is displayed in the bottom right corner.</sample>
    <sample id="828">Main Results: EDAtt

popular strategies also applied to offline models

wait-k - LA - CAAT - EDAtt

(a) en→de

state of the art architecture specifically tailored for SimulST</sample>
    <sample id="829">The image is a slide from a presentation titled "Main Results: EDAtt." It features a graph with the subtitle "(a) en→de," indicating that the results are for an English-to-German translation task. The x-axis represents "AL / AL_CA (s)," which likely stands for Attention Length and its context-aware version in seconds, ranging from 0.5 to 5 seconds. The y-axis represents BLEU scores, which measure the quality of machine translation, ranging from 17 to 27.

The graph includes four different lines representing different architectures:
- wait-k (orange line)
- LA (blue dashed line)
- CAAT (green dashed line)
- EDAtt (red solid line)

Each line shows how the BLEU score changes as the attention length increases. The EDAtt architecture appears to perform best across all attention lengths, achieving the highest BLEU scores. The other architectures show varying performance, with some showing improvements and others showing declines as the attention length increases.

In the top right corner, there is a small video feed of a person speaking, suggesting this is part of a live presentation or webinar. The bottom left corner has a logo with the text "FDC," and the page number "035" is displayed at the bottom right corner.</sample>
    <sample id="830">Main Results:
EDAtt

EDAtt outperforms all the strategies applied to offline models</sample>
    <sample id="831">Main Results: EDAtt

EDAtt outperforms all the strategies applied to offline models.
EDAtt is the fastest strategy if we consider the actual elapsed time.

(a) en→de</sample>
    <sample id="832">Do you want to discover more?
Read our paper to discover more results!
{spapi,negri}@fbk.eu
marco.turchi@gmail.com
github.com/hlt-mt/fbk-fairseq
@fbk_mt
@sarapapi
Scan me!</sample>
    <sample id="833">The affiliations of the authors of the paper are Google.</sample>
    <sample id="834">The affiliations of the authors of the paper are Stony Brook University, Human Language Analysis Beings.</sample>
    <sample id="835">The image does not provide specific details about which language pairs were analyzed in the paper. It focuses on the methodology and evaluation practices used, but does not mention any particular language pairs.</sample>
    <sample id="836">The name of the speaker is Shangbin Feng.</sample>
    <sample id="837">The models investigated during the experiments were DEplain-APA, DEplain-web, DEplain-APA+web, and src2src-baseline.</sample>
    <sample id="838">53 tasks are used for training, and 9 tasks are used for testing.</sample>
    <sample id="839">There are three authors involved in the paper: Regina Stodden, Omar Momen, and Laura Kallmeyer.</sample>
    <sample id="840">The authors experimented on the following datasets: AG News, MIND, SST2, and Enron Spam.</sample>
    <sample id="841">The image is a slide from a presentation at ACL 2023, which reads:

**Language model acceptability judgements are not always robust to context**

Below the title, there is a list of authors: Koustuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Misra, Keren Fuentes, Roger Levy, Adina Williams.

On the right side of the slide, there are logos for several institutions: Johns Hopkins University, Purdue University, MIT, and Meta AI. There is also a circular profile picture of a person wearing glasses and a red shirt.</sample>
    <sample id="842">The image is a slide from a presentation titled "Language model acceptability judgements are not always robust to context." It is associated with ACL 2023 and features the names of several authors: Koustuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Misra, Keren Fuentes, Roger Levy, Adina Williams.

The slide also includes logos for Johns Hopkins University, Purdue University, MIT, and Meta AI. The background is dark, and the text is white, making it stand out clearly.</sample>
    <sample id="843">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

BLiMP
1. Many people were helping themselves.
2. *Many people were helping herself.

P(1) ≳ P(2)

SyntaxGym
1. No customer ... has spent any money.
2. *The customer ... has spent any money.

P(1.any) ≳ P(2.any)

CrowS
1. Stereotypical sentence.
2. Non-stereotypical sentence.

P(1) ≳ P(2)</sample>
    <sample id="844">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

BLiMP
1. Many people were helping themselves.
2. *Many people were helping herself.

P(1) &gt; P(2)

SyntaxGym
1. No customer ... has spent any money.
2. *The customer ... has spent any money.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypical sentence.
2. Non-stereotypical sentence.

P(1) &gt; P(2)</sample>
    <sample id="845">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

BLiMP
1. Many people were helping themselves.
2. *Many people were helping herself.

P(1) &gt; P(2)

SyntaxGym
1. No customer ... has spent any money.
2. *The customer ... has spent any money.

P(1.any) &gt; P(2.any)

CrowS
1. Stereotypical sentence.
2. Non-stereotypical sentence.

P(1) &gt; P(2)</sample>
    <sample id="846">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

BLiMP
1. Many people were helping themselves.
2. *Many people were helping herself.

P(1) ≳ P(2)

SyntaxGym
1. No customer ... has spent any money.
2. *The customer ... has spent any money.

P(1.any) ≳ P(2.any)

CrowS
1. Stereotypical sentence.
2. Non-stereotypical sentence.

P(1) ≳ P(2)</sample>
    <sample id="847">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

| BLiMP | SyntaxGym | CrowS |
|---|---|---|
| 1. Many people were helping themselves. &lt;br&gt;2. *Many people were helping herself. | 1. No customer ... has spent any money.&lt;br&gt;2. *The customer ... has spent any money. | 1. Women are terrible at handiwork.&lt;br&gt;2. Men are terrible at handiwork. |
| P(1) ≳ P(2) | P(1.any) ≳ P(2.any) | P(1) ≳ P(2) |

Are these judgements stable with long preceding context?</sample>
    <sample id="848">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

| BLiMP | SyntaxGym | CrowS |
|---|---|---|
| 1. Many people were helping themselves. &lt;br&gt;2. *Many people were helping herself. | 1. No customer ... has spent any money.&lt;br&gt;2. *The customer ... has spent any money. | 1. Women are terrible at handiwork.&lt;br&gt;2. Men are terrible at handiwork. |
| P(1) &gt; P(2) | P(1.any) &gt; P(2.any) | P(1) &gt; P(2) |

Are these judgements stable with long preceding context?</sample>
    <sample id="849">Revisiting Minimal Pair Paradigm

Minimal pair paradigm (MPP) evaluations of language models use relative differences in sequence probabilities to evaluate the abstract knowledge of LMs:

| BLiMP | SyntaxGym | CrowS |
|---|---|---|
| 1. Many people were helping themselves. &lt;br&gt;2. *Many people were helping herself. | 1. No customer ... has spent any money.&lt;br&gt;2. *The customer ... has spent any money. | 1. Women are terrible at handiwork.&lt;br&gt;2. Men are terrible at handiwork. |
| P(1) &gt; P(2) | P(1.any) &gt; P(2.any) | P(1) &gt; P(2) |

Are these judgements stable with long preceding context?</sample>
    <sample id="850">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Maximum Posterior Probability) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite for Subject Verb Agreement and mentions the use of GPT2 and OPT family models with sizes ranging from 125M to 6.7B parameters.

Key elements on the slide include:

- **Test Suite: Subject Verb Agreement**
  - A graph showing the probability of a prefix being acceptable or unacceptable based on the context.
  - The formula \( P_{LM}(\text{Prefix}) &gt; ? P_{LM}(\text{Prefix}) \) is used to determine if a prefix is more likely to be acceptable than an unacceptable one.
  
- **Space of Candidate Prefixes**
  -分为两部分：Matched 和 Mismatched。
    - Matched 包含 Subj. Verb. Agreement 的绿色方块。
    - Mismatched 包含 Island Effects、Filler-gaps、Binding 和 Wikipedia 的不同颜色的方块。

- **Sample Questions**
  - Two example questions are provided:
    1. "Who might Rose flee from before returning to this customer?"
    2. "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"

- **Acceptable, Matched**
  - Indicates that the question "Who might Rose flee from before returning to this customer?" is considered acceptable and matched.

- **BLIMP, Adjunct Island**
  - Refers to a specific linguistic concept related to the test.

The slide also features a circular image of a person in the top right corner.</sample>
    <sample id="851">The image is a slide from a presentation titled "Approach." The text on the slide reads:

"Test whether MPP judgements vary as a function of context length, structural match, and acceptability."

Below this title, there is a diagram with the following components:

1. **Test Suite: Subject Verb Agreement**
   - A graph showing two axes: one labeled "acceptable" and the other "unacceptable."
   - Two arrows pointing to different points on the graph:
     - One arrow labeled "sample" pointing to a point labeled "P_LM( | Prefix) &gt; P_LM( | Prefix)"
     - Another arrow pointing to a point labeled "Acceptable, Matched"

2. **Space of Candidate Prefixes**
   - Two sections labeled "Matched" and "Mismatched."
   - The "Matched" section contains examples of subject-verb agreement.
   - The "Mismatched" section contains examples of island effects, filler-gaps, binding, and Wikipedia.

3. **Examples of Sentences**
   - Two example sentences are provided:
     - "Who might Rose flee from before returning to this customer?"
     - "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"

4. **Model Information**
   - At the bottom of the slide, it states: "GPT2, OPT family - 125M to 6.7B"

On the right side of the slide, there is a circular profile picture of a person wearing glasses and a red shirt.</sample>
    <sample id="852">The image is a slide from a presentation titled "Approach." The text on the slide reads:

"Test whether MPP judgements vary as a function of context length, structural match, and acceptability."

Below this title, there is a diagram with the following components:

1. **Test Suite: Subject Verb Agreement**
   - A scale labeled "acceptable" at the top and "unacceptable" at the bottom.
   - Two arrows pointing to different boxes:
     - One arrow points to a box labeled "Acceptable, Matched."
     - Another arrow points to a box labeled "Unacceptable, Mismatched."

2. **Space of Candidate Prefixes**
   - Two sections labeled "Matched" and "Mismatched."
   - Under "Matched," there are examples of subject-verb agreement (e.g., "Subj. Verb. Agreement").
   - Under "Mismatched," there are examples of various linguistic phenomena such as "Island Effects," "Filler-gaps," "Binding," and "Wikipedia."

3. **Sample Questions**
   - Two questions are shown:
     - "Who might Rose flee from before returning to this customer?"
     - "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"

4. **Model Information**
   - At the bottom left, it states: "GPT2, OPT family - 125M to 6.7B."

On the right side of the slide, there is a circular profile picture of a person wearing glasses and a red shirt.</sample>
    <sample id="853">The image is a slide from a presentation titled "Approach." The text on the slide reads:

"Test whether MPP judgements vary as a function of context length, structural match, and acceptability."

Below this text, there is a diagram with the following components:

1. **Test Suite: Subject Verb Agreement**
   - A scale labeled "acceptable" at the top and "unacceptable" at the bottom.
   - Two probability functions are shown:
     - \( P_{LM}(\square | Prefix) \)
     - \( P_{LM}(\square | Prefix) \)

2. **Space of Candidate Prefixes**
   -分为两部分：
     - **Matched**: 包含绿色方块和红色方块。
     - **Mismatched**: 包含绿色圆圈、红色圆圈、黑色圆圈、菱形和星形。

3. **Sample Questions**:
   - "Who might Rose flee from before returning to this customer?"
   - "What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"

4. **Annotations**:
   - "Acceptable, Matched"
   - "BLIMP, Adjunct Island"

At the bottom of the slide, it states:
"GPT2, OPT family - 125M to 6.7B"</sample>
    <sample id="854">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Maximum Posterior Probability) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite focused on Subject Verb Agreement.

The slide contains the following elements:

1. **Title**: "Approach"
2. **Subtitle**: "Test whether MPP judgements vary as a function of context length, structural match, and acceptability"
3. **Test Suite**: Subject Verb Agreement
4. **Equation**: \( P_{LM}(\square | Prefix) &gt; ? P_{LM}(\square | Prefix) \)
5. **Space of Candidate Prefixes**:
   - Matched: Subj. Verb. Agreement
   - Mismatched: Island Effects, Filter-gaps, Binding, Wikipedia
6. **Examples**:
   - **Matched Example**: "Who might Rose flee from before returning to this customer?"
   - **Unacceptable, Matched Example**: "What could Jessica sell these spotlights before noticing? What had Aaron sounded like the museum while cleaning? Who might Rose flee from before returning to this customer?"
7. **Model Information**: GPT2, OPT family - 125M to 6.7B
8. **Additional Note**: BLIMP, Adjunct Island

The slide also features a circular image of a person in the top right corner.</sample>
    <sample id="855">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Maximum Posterior Probability) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite focused on Subject Verb Agreement.

The slide contains the following elements:

1. **Title**: "Approach"
2. **Subtitle**: "Test whether MPP judgements vary as a function of context length, structural match, and acceptability"
3. **Test Suite**: Subject Verb Agreement
4. **Equation**: \( P_{LM}(\text{Prefix}) &gt; ? P_{LM}(\text{Prefix}) \)
5. **Space of Candidate Prefixes**:
   - Matched: Includes examples with subject-verb agreement.
   - Mismatched: Includes examples without subject-verb agreement.
6. **Sample Question**: "Who might Rose flee from before returning to this customer?"
7. **Acceptable, Mismatched Example**: 
   - "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"
8. **BLIMP, Existential "there" Quantifiers**: Mentioned in relation to the example.
9. **BLIMP, Adjunct Island**: Mentioned in relation to the example.
10. **Model Information**: "GPT2, OPT family - 125M to 6.7B"

The slide also features a circular image of a person in the top right corner.</sample>
    <sample id="856">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Most Probable Prediction) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite for Subject Verb Agreement and mentions the use of GPT2 and OPT family models with sizes ranging from 125M to 6.7B parameters.

The slide is divided into several sections:

1. **Test Suite: Subject Verb Agreement**
   - A graph showing the probability of a prefix being acceptable or unacceptable based on the context.
   - The formula \( P_{LM}(\text{Prefix}) &gt; ? P_{LM}(\text{Prefix}) \) is used to determine if the prefix is more likely to be acceptable or unacceptable.

2. **Space of Candidate Prefixes**
   -分为两部分：Matched 和 Mismatched。
   - Matched 包含 Subj. Verb. Agreement 的绿色方块。
   - Mismatched 包含 Island Effects、Filler-gaps、Binding 和 Wikipedia 的不同颜色的方块。

3. **Examples of Sentences**
   - Two examples of sentences are shown:
     - "Who might Rose flee from before returning to this customer?"
     - "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"

4. **Annotations**
   - The first example is labeled "Acceptable, Mismatched."
   - The second example is labeled "Unacceptable, Mismatched."

5. **BLIMP**
   - Mentions BLIMP, Existential “there” Quantifiers, and BLIMP, Adjunct Island.

The bottom of the slide reiterates the model sizes: GPT2, OPT family - 125M to 6.7B.</sample>
    <sample id="857">The image is a slide from a presentation titled "Approach." It discusses testing whether MPP (Maximum Posterior Probability) judgments vary as a function of context length, structural match, and acceptability. The slide includes a test suite focused on Subject Verb Agreement.

Key elements in the slide:

1. **Test Suite: Subject Verb Agreement**
   - A graph showing two probabilities:
     - \( P_{LM}(\text{Prefix}) \)
     - \( P_{LM}(\text{Prefix}) \)

2. **Space of Candidate Prefixes**
   -分为两部分：
     - **Matched**: 包含绿色方块和红色方块，代表匹配的前缀。
     - **Mismatched**: 包含绿色圆圈、黑色圆圈、红色星星和白色菱形，代表不匹配的前缀。

3. **Sample Example**:
   - **Question**: "Who might Rose flee from before returning to this customer?"
   - **Unrelated Wikipedia Content**: "A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars."
   - **Modified Question**: "Who might Rose flee from before returning to this customer?"

4. **Model Information**:
   - GPT2, OPT family - 125M to 6.7B

The slide also includes a circular photo of a person in the top right corner.</sample>
    <sample id="858">The image is a slide from a presentation titled "Approach." The slide discusses testing whether MPP (Maximum Posterior Probability) judgments vary as a function of context length, structural match, and acceptability. It includes a test suite focused on Subject Verb Agreement.

The slide contains the following elements:

1. **Title**: "Approach"
2. **Subtitle**: "Test whether MPP judgements vary as a function of context length, structural match, and acceptability"
3. **Test Suite**: Subject Verb Agreement
4. **Equation**: \( P_{LM}(\text{Prefix}) &gt; ? P_{LM}(\text{Prefix}) \)
5. **Space of Candidate Prefixes**:
   - **Matched**: Includes examples with subject-verb agreement.
   - **Mismatched**: Includes examples with various mismatched prefixes such as Island Effects, Filter-gaps, Binding, and Wikipedia.
6. **Sample Question**: "Who might Rose flee from before returning to this customer?"
7. **Unrelated Wikipedia Example**: "A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars."
8. **GPT2, OPT family - 125M to 6.7B**: Indicates the models used in the study.

The slide also features a circular image of a person in the top right corner.</sample>
    <sample id="859">The image is a slide from a presentation titled "Approach." The text on the slide reads:

"Test whether MPP judgements vary as a function of context length, structural match, and acceptability."

Below this main title, there is a subheading that says:

"Test Suite: Subject Verb Agreement"

There is a diagram with two boxes labeled "Matched" and "Mismatched," each containing different colored circles representing various types of prefixes:
- Matched: Green circles (Subj. Verb. Agreement)
- Mismatched: Red circles (Island Effects), Black circles (Filler-gaps), Pink circles (Binding), White circles (Wikipedia)

To the right of the diagram, there is an example sentence:
"Who might Rose flee from before returning to this customer?"
Followed by a starred version of the same sentence:
"* Who might Rose flee from this customer before returning to?"

Below the example sentences, there is a box labeled "Wikipedia, Unrelated" with a sample text about roses.

At the bottom of the slide, it states:
"GPT2, OPT family - 125M to 6.7B"</sample>
    <sample id="860">MPP judgements are robust for arbitrary context lengths

We perform MPP evaluations with different contexts — acceptable / unacceptable; matched/mismatched structure — of lengths up to 900 tokens

BLiMP, OPT 6.7B

A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from before returning to this customer?
* A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from this customer before returning to?</sample>
    <sample id="861">MPP judgements are robust for arbitrary context lengths

We perform MPP evaluations with different contexts — acceptable / unacceptable; matched/mismatched structure — of lengths up to 900 tokens

BLiMP, OPT 6.7B

A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from before returning to this customer?
* A rose is a woody perennial flowering plant of the genus Rosa. There are over three hundred species and tens of thousands of cultivars.
Who might Rose flee from this customer before returning to?</sample>
    <sample id="862">The image is a slide from a presentation titled "Acceptable/Unacceptable MPP sentences in the context raise/lower judgement performance." The slide explains that the speaker performs MPP evaluations with different contexts—acceptable/unacceptable; matched/mismatched structure—of lengths up to 900 tokens. The model used for these evaluations is BLiMP, OPT 6.7B.

The slide includes a graph showing the performance of different prefix strategies across various conditions:
- Acc. (Matched)
- Unacc. (Matched)
- Wiki (Mismatched)
- Acc. (Mismatched)
- Unacc. (Mismatched)

The graph has a y-axis labeled "Prefix Strategy" ranging from -0.8 to 0.2 and an x-axis labeled "BLiMP, OPT 6.7B."

On the right side of the slide, there are two examples of sentences:
1. "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"
2. "There was each documentary about music imitating Allison. There were most legislatures working hard. Who might Rose flee from before returning to this customer?"

These sentences are presented with and without asterisks (*) to indicate whether they are acceptable or unacceptable in the context.</sample>
    <sample id="863">The image is a slide from a presentation titled "Acceptable/Unacceptable MPP sentences in the context raise/lower judgement performance." The slide explains that the speaker performs MPP evaluations with different contexts—acceptable/unacceptable; matched/mismatched structure—of lengths up to 900 tokens. The model used for these evaluations is BLiMP, OPT 6.7B.

The slide includes a graph showing the performance of different prefix strategies across various conditions:
- Acc. (Matched)
- Unacc. (Matched)
- Wiki (Mismatched)
- Acc. (Mismatched)
- Unacc. (Mismatched)

The graph has a y-axis labeled "Prefix Strategy" ranging from -0.8 to 0.2 and an x-axis labeled "Length" ranging from 0 to 900 tokens. The legend indicates the different conditions represented by the lines on the graph.

On the right side of the slide, there are two examples of sentences:
1. "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"
2. "There was each documentary about music imitating Allison. There were most legislatures working hard. Who might Rose flee from before returning to this customer?"

These sentences are used to illustrate the context and structure variations being evaluated.</sample>
    <sample id="864">The image is a slide from a presentation titled "Acceptable/Unacceptable MPP sentences in the context raise/lower judgement performance." The slide explains that MPP evaluations were conducted with different contexts—acceptable/unacceptable; matched/mismatched structure—and lengths up to 900 tokens. It mentions the use of BLiMP, OPT 6.7B for these evaluations.

The slide includes a graph showing the performance of different prefix strategies (Acc. (Matched), Unacc. (Matched), Acc. (Mismatched), and Wiki (Mismatched)) across various lengths. The x-axis represents the length in tokens, ranging from 0 to 900, while the y-axis represents the performance metric.

On the right side of the slide, there are two examples of sentences:
1. "There was a documentary about music imitating Allison. There were no legislatures working hard. Who might Rose flee from before returning to this customer?"
2. "There was each documentary about music imitating Allison. There were most legislatures working hard. Who might Rose flee from before returning to this customer?"

These sentences are used to illustrate the context and structure variations being evaluated in the MPP experiments.</sample>
    <sample id="865">The image is a slide from a presentation titled "Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance." The slide discusses the impact of different contexts and sentence structures on model performance, specifically using MPP (Masked Prefix Prediction) evaluations with contexts that are either acceptable or unacceptable, and sentences that have either matched or mismatched structures, up to 900 tokens in length.

Key points include:
- The model used for evaluation is BLiMP, OPT 6.7B.
- The slide shows a graph comparing the performance of different prefix strategies: Acc. (Matched), Unacc. (Matched), Acc. (Mismatched), and Wiki (Mismatched).
- The graph indicates that acceptable sentences with a matched structure perform best, while unacceptable sentences with a mismatched structure perform worst.
- Examples of acceptable and unacceptable sentences are provided, with the unacceptable sentences highlighted in red.

The slide also includes a visual representation of the performance metrics for each strategy, showing how they vary across different lengths of input sequences.</sample>
    <sample id="866">The image is a slide from a presentation titled "Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance." The slide discusses the impact of different contexts and sentence structures on the performance of a model, specifically using MPP evaluations with contexts that are either acceptable or unacceptable and have either matched or mismatched structures, up to 900 tokens in length.

Key points include:
- The model being evaluated is BLiMP, OPT 6.7B.
- The slide mentions performing MPP evaluations with different contexts: acceptable/unacceptable; matched/mismatched structure.
- The graph shows the performance of the model across different prefix strategies (Acc. (Matched), Unacc. (Matched), Acc. (Mismatched), Unacc. (Mismatched)).
- The graph includes data points for each strategy, with the y-axis representing some metric of performance and the x-axis showing the number of tokens.
- Examples of sentences used in the evaluation are provided, with some sentences marked as acceptable (in green) and others as unacceptable (in red).

The slide also includes a circular image of a person in the top right corner.</sample>
    <sample id="867">The image is a slide from a presentation titled "Acceptable/unacceptable MPP sentences with matched structure most severely affect model performance." The slide discusses the impact of different contexts and sentence structures on the performance of a model, specifically using MPP evaluations with contexts that are either acceptable or unacceptable, and structures that are either matched or mismatched, up to 900 tokens in length.

Key points include:
- The model used is BLiMP, OPT 6.7B.
- The slide mentions performing MPP evaluations with different contexts: acceptable/unacceptable; and matched/mismatched structure.
- The graph shows the performance of the model across different prefix strategies (Acc. (Matched), Unacc. (Matched), Acc. (Mismatched), Unacc. (Mismatched)).
- The graph includes data points for each strategy, with error bars indicating variability.
- Examples of sentences are provided, with some marked as acceptable (in green) and others as unacceptable (in red).

The text at the bottom right corner of the slide reads:
"What could Jessica sell before noticing these spotlights? What had Aaron sounded like while cleaning the museum? Who might Rose flee from before returning to this customer?"
- The first example is marked as acceptable (green).
- The second example is marked as unacceptable (red).</sample>
    <sample id="868">Why do matched prefixes affect LM judgements?

We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences.

- Prefix/suffix adverbs: "However, &lt;sent&gt;."
- Long prefix adverbs: "First and foremost, &lt;sent&gt;."
- Add clause: "Regardless of what X thinks about it, &lt;sent&gt;."
- Quote: "Yesterday, X said, ‘&lt;sent&gt;.’"</sample>
    <sample id="869">The image is a slide from a presentation titled "Why do matched prefixes affect LM judgements?" The slide explains that context sentences are perturbed in ways that preserve relevant structure, and it asks whether models are similarly sensitive to these sentences. It lists four types of perturbations:

1. **Prefix/suffix adverbs:** "However, &lt;sent&gt;."
2. **Long prefix adverbs:** "First and foremost, &lt;sent&gt;."
3. **Add clause:** "Regardless of what X thinks about it, &lt;sent&gt;."
4. **Quote:** "Yesterday, X said, ‘&lt;sent&gt;.’”

The slide also mentions that the perturbations are designed to preserve the relevant structure of the original sentences and to test the sensitivity of language models (LMs) to these changes.</sample>
    <sample id="870">The image is a slide from a presentation titled "Why do matched prefixes affect LM judgements?" The slide explains that context sentences are perturbed in ways that preserve relevant structure, and it asks whether models are similarly sensitive to these sentences. Below this explanation, there are four types of perturbations listed:

1. **Prefix/suffix adverbs:** "However, &lt;sent&gt;."
2. **Long prefix adverbs:** "First and foremost, &lt;sent&gt;."
3. **Add clause:** "Regardless of what X thinks about it, &lt;sent&gt;."
4. **Quote:** "Yesterday, X said, ‘&lt;sent&gt;.’”

On the right side of the slide, there is a graph with two plots. The x-axis represents "Input Length," ranging from 0 to 600, and the y-axis represents "Δ Accuracy." The graph shows the change in accuracy for different perturbations (None, Prefix/suffix adv, Long prefix adv, Add clause, Quote, All) across various input lengths. The legend indicates that the lines represent "Acceptable" and "Unacceptable" judgments.

The slide also includes a circular photo of a person in the top right corner.</sample>
    <sample id="871">The image is a slide from a presentation titled "Why do matched prefixes affect LM judgements?" The slide discusses how models are sensitive to perturbed sentences in similar ways when context sentences are modified in various ways that preserve relevant structure.

The text on the slide explains:
- We perturb context sentences in ways that preserve the relevant structure, and ask whether models are similarly sensitive to these sentences.
- Examples of perturbations include:
  - Prefix/suffix adverbs: "However, &lt;sent&gt;."
  - Long prefix adverbs: "First and foremost, &lt;sent&gt;."
  - Add clause: "Regardless of what X thinks about it, &lt;sent&gt;."
  - Quote: "Yesterday, X said, ‘&lt;sent&gt;’."

The slide also includes a graph showing the change in accuracy (Δ Accuracy) for different types of perturbations and prefix types over input length. The graph has two lines representing acceptable and unacceptable perturbations, with different colors and line styles indicating the type of perturbation applied (None, Prefix/suffix adv, Long prefix adv, Add clause, Quote, All).

The bottom of the slide states: "Models are sensitive to perturbed sentences in similar ways."</sample>
    <sample id="872">The image is a slide from a presentation titled "Why do matched prefixes affect LM judgements?" The slide discusses how models are sensitive to perturbed sentences in similar ways when context sentences are modified in specific ways that preserve relevant structure. The text on the slide outlines different types of perturbations applied to context sentences:

- Prefix/suffix adverbs: "However, &lt;sent&gt;."
- Long prefix adverbs: "First and foremost, &lt;sent&gt;."
- Add clause: "Regardless of what X thinks about it, &lt;sent&gt;."
- Quote: "Yesterday, X said, ‘&lt;sent&gt;.’”

The slide also includes a graph showing the change in accuracy (Δ Accuracy) for different perturbation types (None, Prefix/suffix adv, Long prefix adv, Add clause, Quote, All) across various input lengths (0 to 600). The graph indicates that models are similarly sensitive to these perturbations, as shown by the lines representing acceptable and unacceptable sentences.</sample>
    <sample id="873">Key Takeaways

- Language models are sensitive to latent syntactic/semantic features shared across sentences.
- MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.</sample>
    <sample id="874">Key Takeaways

- Language models are sensitive to latent syntactic/semantic features shared across sentences.
- MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.</sample>
    <sample id="875">Key Takeaways

- Language models are sensitive to latent syntactic/semantic features shared across sentences.
- MPP evaluations with short, single-sentence inputs do not fully capture LMs' abstract knowledge.</sample>
    <sample id="876">NACHOS is one of the models being evaluated in the study, along with DrBERT.</sample>
    <sample id="877">The name of the speaker is not explicitly mentioned in the image provided. The image shows a slide from Google's presentation titled "Prompting PaLM for Translation: Assessing Strategies and Performance" at ACL 2023, with several names listed but no indication that any of them is the speaker.</sample>
    <sample id="878">The prompting strategy has a big impact on translation quality, as evidenced by the fact that the majority of sentences (516 out of 1000) show a difference of more than 1 BLEURT point and the difference can go up to 40 BLEURT points!</sample>
    <sample id="879">The affiliations of the authors of the paper are Carnegie Mellon University Language Technologies Institute, TÉCNICO LISBOA, BAIR (Berkeley Artificial Intelligence Research), and Unbabel.</sample>
    <sample id="880">The image does not provide information about the 5 expert-written instructions. It only mentions that a much larger multimodal instruction tuning dataset with around 150 additional vision-language tasks will be released soon.</sample>
    <sample id="881">The authors propose to use a dataset for knowledge integration evaluation and a coreference resolution task to probe the ability of the models to draw on pretrain-time knowledge and inference-time knowledge.</sample>
    <sample id="939">The common evaluation methods for dialogue systems mentioned in the image are Comparative Evaluation and Likert Rating Evaluation.</sample>
    <sample id="940">There are five authors involved in the paper.</sample>
    <sample id="941">Judges decide cases in courts of law.</sample>
    <sample id="942">Yes, the code is available on GitHub at mpoemsl/kitmus.</sample>
    <sample id="943">No, the annotators for NLPositionality are not balanced in regard to each demographic, including country and gender. The data provided focuses on social acceptability based on education level, but does not include information about country or gender distribution among the annotators.</sample>
    <sample id="944">The sentences were perturbed by adding matched prefixes, which preserved the relevant structure of the sentences.</sample>
    <sample id="945">A dimensional evaluation in the context of dialogue quality means assessing various aspects or dimensions that contribute to the overall quality of a conversation. These dimensions include relevance, consistency, and emotional understanding, which are all important factors in determining how well a dialogue is conducted.</sample>
    <sample id="946">The affiliations of the authors of the paper are as follows:

1. University of Science and Technology of China
2. Microsoft Research Asia
3. Beijing Jiaotong University
4. Sony AI
5. Microsoft STC Asia</sample>
    <sample id="947">The form of the prompting is important in cases where the context or specific details need to be preserved during translation. For example, in the provided German sentences, the context of police involvement and the specific actions (being transported, receiving complaints) are crucial. The English translations should accurately reflect these details to maintain the original meaning and context.</sample>
    <sample id="948">Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge

Vasudha Varadarajan*, Swanie Juhng, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Luhmann &amp; H. Andrew Schwartz

Stony Brook University
Human Language Analysis Beings</sample>
    <sample id="949">The image is a slide from a presentation with the title "What is Cognitive Dissonance?" Below the title, there is a definition provided: "two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent" (Harmon-Jones and Harmon-Jones, 2007). At the bottom of the slide, there is a citation: "Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716." The slide number is indicated as 2 in the bottom right corner.</sample>
    <sample id="950">The image is a slide from a presentation titled "What is Cognitive Dissonance?" It includes a definition of cognitive dissonance as "two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent" (Harmon-Jones and Harmon-Jones, 2007). The slide also features a diagram illustrating an example of cognitive dissonance:

- On the left side, there is a silhouette of a head with puzzle pieces inside it.
- Below the head, two statements are presented:
  - "I know that cigarettes could kill me."
  - "I grabbed a couple smokes after the meeting today."
- Arrows point from these statements to the words "belief" and "action," respectively.
- A dotted line connects "belief" and "action" to the word "Dissonance" on the right side of the slide.

At the bottom of the slide, there is a citation: "Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716."</sample>
    <sample id="951">The image is a slide from a presentation titled "What is Cognitive Dissonance?" It explains cognitive dissonance as "two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent" and expresses this in language as a relationship between two phrases/statements by a user.

The slide includes a diagram with a head made of puzzle pieces and three sequences labeled seq 1, seq 2, and seq 3:

- seq 1: "I know that cigarettes could kill me."
- seq 2: "I grabbed a couple smokes after the meeting today."
- seq 3: "I don't think I could keep my job without them."

On the right side of the slide, there is a flowchart with the following steps:
- belief → Dissonance
- action → Consonance/Explanation
- belief

At the bottom of the slide, there is a citation: "Eddie Harmon-Jones and Cindy Harmon-Jones. 2007. Cognitive dissonance theory after 50 years of development. Zeitschrift für Sozialpsychologie, 38(1):716."</sample>
    <sample id="952">The image is a slide from a presentation titled "What is Cognitive Dissonance?" The slide defines cognitive dissonance as "two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent" and explains that it is expressed in language as a relationship between two phrases or statements by a user. It notes that this type of discourse relation is relatively rare compared to other discourse relations.

The slide includes an example with three sequences:
1. "I know that cigarettes could kill me."
2. "I grabbed a couple smokes after the meeting today."
3. "I don't think I could keep my job without them."

On the right side of the slide, there is a diagram showing the relationship between belief, action, and dissonance/Explanation. The text at the bottom cites Eddie Harmon-Jones and Cindy Harmon-Jones, 2007, "Cognitive dissonance theory after 50 years of development," Zeitschrift für Sozialpsychologie, 38(1):716.</sample>
    <sample id="953">The image is a slide from a presentation titled "Why dissonance?" It features two stick figures facing each other with speech bubbles, labeled "Effects of disagreement." The text at the bottom references a source: "Eddie Harmon-Jones and Judson Mills, 2019. An introduction to cognitive dissonance theory and an overview of current perspectives on the theory. Cognitive dissonance: Reexamining a pivotal theory in psychology."

On the right side of the slide, there is another section with a graph showing an upward trend and the label "Attitudes and Belief trends." The slide number is 7, and there is a small video feed in the top right corner showing a person named Vasudha Varadarajan.</sample>
    <sample id="954">The image is a slide from a presentation with the title "Why dissonance?" at the top. The slide is divided into three sections, each with an icon and a brief description:

1. **Effects of disagreement**: This section shows two stick figures pointing at each other with speech bubbles between them, indicating a disagreement. Below this, it says "Effects of disagreement."

2. **Attitudes and belief trends**: This section features a bar graph with an upward arrow, suggesting growth or change. Below this, it says "Attitudes and belief trends."

3. **Anxiety disorders**: This section has an icon of a head with an exclamation mark inside a circle, symbolizing anxiety. Below this, it says "Anxiety disorders."

At the bottom of the slide, there are two references:
- Eddie Harmon-Jones and Judson Mills. 2019. An introduction to cognitive dissonance theory and an overview of current perspectives on the theory. Cognitive dissonance: Reexamining a pivotal theory in psychology.
- Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, and H Andrew Schwartz. 2023. Discourse-level representations can improve prediction of degree of anxiety. In Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.

The slide also includes a small video feed in the top right corner showing a person named Vasudha Varadarajan.</sample>
    <sample id="955">The image is a slide from a presentation titled "Why dissonance?" It contains four sections, each with an icon and a brief description:

1. **Effects of disagreement**: Depicted by two stick figures pointing at each other with speech bubbles.
2. **Entry and Exit from Extremism**: Illustrated by a person standing on a pile of people with a speech bubble above them.
3. **Attitudes and Belief trends**: Represented by a bar graph with an upward arrow.
4. **Anxiety disorders**: Shown by a head with an exclamation mark inside it.

At the bottom of the slide, there are references to academic papers:
- Eddie Harmon-Jones and Judson Mills. 2019. An introduction to cognitive dissonance theory and an overview of current perspectives on the theory. Cognitive dissonance: Reexamining a pivotal theory in psychology.
- Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, and H Andrew Schwartz. 2023. Discourse-level representations can improve prediction of degree of anxiety. In 9 Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="956">The image is a slide from a presentation titled "Why dissonance?" It contains four sections, each with an icon and a brief description:

1. **Effects of disagreement**: Two stick figures pointing at each other with speech bubbles.
2. **Entry and Exit from Extremism**: A group of people with a speech bubble and a figure standing on a rock with a sword.
3. **Attitudes and Belief trends**: A bar graph with an upward arrow.
4. **Anxiety disorders**: A head with an exclamation mark.

Below the sections, there are two references:
- Eddie Harmon-Jones and Judson Mills. 2019. An introduction to cognitive dissonance theory and an overview of current perspectives on the theory. Cognitive dissonance: Reexamining a pivotal theory in psychology.
- Swanie Jung, Matthew Matero, Vasudha Varadarajan, Johannes Eichstaedt, Adithya V Ganesan, and H Andrew Schwartz. 2023. Discourse-level representations can improve prediction of degree of anxiety. In Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</sample>
    <sample id="957">The image is a slide from a presentation titled "Annotations." It includes a flowchart and a tweet example. The flowchart has three steps:

1. **Step 1: Good parsing quality?**
   - If yes, go to Step 2.
   - If no, go to Step 3.

2. **Step 2: Dissonance?**
   - If yes, annotate as "Dissonance."
   - If no, go to Step 3.

3. **Step 3: Consonance?**
   - If yes, annotate as "Consonance."
   - If no, annotate as "Neither."

The percentages for each outcome are:
- Dissonance: ~3.5%
- Consonance: ~48%
- Neither: ~48%

Below the flowchart, there is an example of a tweet with parts highlighted in pink and blue:
```
Wish I could hold grudges but I guess it's a good thing that I can't at the same time.
```
The tweet is annotated as "Dissonance" on the right side of the slide.

At the bottom left, there is a Twitter logo with the word "PARSE" next to it. At the bottom right, there is a note: "*Check paper for detailed annotation guidelines."

The slide number is 11.</sample>
    <sample id="958">The image is a slide from a presentation titled "Annotations." It includes a flowchart and some text related to annotating tweets. Here's the transcribed content:

---

**Annotations**

- **Step 1: Good parsing quality?**
  - Yes → Step 2: Dissonance?
  - No → Step 3: Consonance?

- **Step 2: Dissonance?**
  - Yes → Dissonance (~3.5%)
  - No → Step 3: Consonance?

- **Step 3: Consonance?**
  - Yes → Consonance (~48%)
  - No → Neither (~48%)

- **User @user_handle**
  - **Tweet:** "Wish I could hold grudges but I guess it’s a good thing that I can’t at the same time."
    - **Dissonance** (annotated)

- **Twitter logo** with arrows labeled:
  - PARSE
  - ANNOTATE

- **Note:** Check paper for detailed annotation guidelines.

---</sample>
    <sample id="959">Annotations

Step 1: Good parsing quality?
Yes → Step 2: Dissonance?
No → Step 3: Consonance?

Dissonance ~3.5%
Consonance ~48%
Neither ~48%

User @user_handle
Wish I could hold grudges but I guess it's a good thing that I can't at the same time.

PARSE
ANNOTATE
Dissonance

* Check paper for detailed annotation guidelines
11</sample>
    <sample id="960">The image is a slide from a presentation titled "Training on Initial Annotated Set." It features a graph with the x-axis labeled "Area under the ROC curve (AUC)" and values ranging from 0.50 to 0.65. The y-axis represents a model configuration, specifically "RoBERTA-base + classifier head," which is connected by an arrow labeled "TRAIN" pointing towards a small annotated dataset.

On the right side of the slide, there is a speech bubble that states: "Small annotated dataset: 43/901 dissonance; not better than chance."

The slide number in the bottom right corner is 12.</sample>
    <sample id="961">The image is a slide from a presentation titled "Training on Initial Annotated Set." It features a diagram and text related to machine learning, specifically using RoBERTA-base with a classifier head for training on an initial annotated dataset.

The diagram shows:
- A pink box labeled "RoBERTA-base + classifier head."
- An arrow pointing downward labeled "TRAIN."
- A small red box labeled "init dataset" at the bottom left.
- A speech bubble on the right side that reads: "Small annotated dataset: 43/901 dissonance; not better than chance."

The x-axis of the diagram is labeled "Area under the ROC curve (AUC)." The y-axis is not labeled but appears to represent the training process or performance metrics.

The slide number in the bottom right corner is "12."</sample>
    <sample id="962">The image is a slide from a presentation titled "Method: Transfer and Active Learning for Annotating Rare Class." The slide outlines a process involving transfer learning, cumulative (CM), iterative (IT) methods, and active learning iterations. Here's a breakdown of the content:

1. **Initial Model: Transfer Learning**
   - Starts with an initial model trained on transfer learning.

2. **Cumulative (CM)**
   - New data is added to old data.
   - Training is done on the combined dataset.
   - A new model is created.

3. **Iterative (IT)**
   - New data is added to old data.
   - Fine-tuning is performed on the old model.
   - A new model is created.

4. **Acquisition Strategy: Which are 'best' to label?**
   - This step involves selecting the most informative or valuable examples for annotation by humans.

5. **Active Learning Iteration**
   - Humans annotate selected examples.
   - New examples are added to the dataset.
   - The model is retrained or updated based on the new annotated data.

6. **Rare Class Annotation ~ "needle in a haystack"**
   - This metaphor suggests that finding rare class examples is challenging due to their scarcity.

7. **Increase Chance of Rare Class?**
   - The process aims to increase the likelihood of encountering rare class examples through iterative refinement and human annotation.

8. **Humans annotate**
   - Humans play a crucial role in labeling the selected examples.

9. **Add new examples**
   - The annotated examples are added back into the dataset for further training.

The slide number is 13, and there is a small inset of a person in the top right corner, likely the presenter.</sample>
    <sample id="963">The image is a slide from a presentation titled "Cold-start Annotations: Transfer Learning." The slide outlines a process involving transfer learning, cumulative (CM), and iterative (IT) methods for model retraining/update. It includes the following key points:

1. **Initial Model: Transfer Learning**
   - START
   - Rare class annotation ~ "needle in a haystack"
   - Difficult to annotate
   - Easier to annotate
   - Increase chance of rare class?

2. **Acquisition Strategy: Which are "best" to label?**

3. **Active Learning Iteration**
   - Humans annotate
   - Add new examples
   - Model Retrain/Update

4. **Cumulative (CM)**
   - New data
   - Train
   - Old model
   - New model

5. **Iterative (IT)**
   - New data
   - Fine-tune
   - Old model
   - New model

The slide also includes a visual representation of these processes with arrows indicating the flow of information and actions. The slide number is 14, and there is a name in the top right corner: Vasudha Varadarajan.</sample>
    <sample id="964">The image is a slide from a presentation titled "Cold-start Annotations: Transfer Learning." The slide discusses the performance of a model trained on different datasets using transfer learning with RoBERTA-base and a classifier head. The bar chart shows the Area under the ROC curve (AUC) for various datasets:

- **init dataset**: 0.50 AUC
- **Debate**: +0.12 AUC
- **CE**: +0.10 AUC
- **Debate;CE**: +0.08 AUC

The slide also includes a note about the datasets:
- *Debate*: Dissonant stance in debate forums.
- $CE$: Comparison and Expansion classes.

Additionally, there is a speech bubble pointing to the right that says:
"Transferred weights after training on combined Debate and CE data."

The bottom right corner of the slide contains references to the datasets used:
- *Debate*: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Naoaki Inoue. 2022. Detecting dissonant stance in social media: The role of topic exposure. In Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS), Association for Computational Linguistics.
- $CE: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08).

The slide number is indicated as 15 at the bottom right corner.</sample>
    <sample id="965">**Cold-start Annotations: Transfer Learning**

- **RoBERTA-base + classifier head**
  - TRAIN
  - init dataset
  - Debate: +0.12
  - $CE: +0.10
  - Debate;CE: +0.08

**Transferred weights after training on combined Debate and CE data**

*Debate: Dissonant stance in debate forums: Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H., Andrew Schwarzer, and Naoko Inoue. 2022. Detecting dissonant stances in social media: The role of topic expansion. Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS). Association for Computational Linguistics.

$CE: Comparison and Expansion classes: Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Mitsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)

15</sample>
    <sample id="966">The image is a slide from a presentation titled "Cold-start Annotations: Transfer Learning." It features a bar chart comparing the performance of different datasets in terms of Area under the ROC curve (AUC). The datasets compared are:

1. **init dataset**
2. **Debate**
3. **CE**
4. **Debate;CE**

The chart shows that the "Debate" dataset has an AUC of +0.12, the "CE" dataset has an AUC of +0.10, and the combined "Debate;CE" dataset has an AUC of +0.08.

The slide also includes a note about the "Debate" dataset, which refers to dissonant stance in debate forums, and credits authors such as Vasudha Varadarajan, Nikita Soni, Weixi Wang, Christian Luhmann, H. Andrew Schwartz, and Naoaki Inoue. It mentions that this work was presented at the Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS), Association for Computational Linguistics.

Additionally, there is a speech bubble pointing to the "Debate;CE" dataset with the text: "Transferred weights after training on combined Debate and CE data."

The slide number is 15.</sample>
    <sample id="967">The image is a slide from a presentation titled "Cold-start Annotations: Transfer Learning." It features a bar chart comparing different training datasets and their impact on the Area under the ROC curve (AUC). The chart includes the following categories:

1. **init dataset** - A small initial dataset.
2. **Debate** - Training with the Debate dataset, showing an improvement of +0.12 in AUC.
3. **CE** - Training with the CE dataset, showing an improvement of +0.10 in AUC.
4. **Debate;CE** - Training with both Debate and CE datasets consecutively, showing an improvement of +0.08 in AUC.
5. **Debate→CE** - Fine-tuning on the Debate dataset after training on the CE dataset, showing a slight decrease of -0.04 in AUC.
6. **CE→Debate** - Fine-tuning on the CE dataset after training on the Debate dataset, showing a significant increase of +0.17 in AUC.

The slide also includes a note about the datasets:
- **Debate**: Dissonant stance in debate forums by Vasudha Varadarajan et al., 2022.
- **CE**: Comparison and Expansion classes by Rashmi Prasad et al., 2008.

Additionally, there is a speech bubble that says "Finetuning on each task consecutively," indicating the process of fine-tuning models on different tasks one after another.</sample>
    <sample id="968">Active Learning: Cumulative vs Iterative Update

Initial model: Transfer Learning
START

Rare class annotation ~ "needle in a haystack"
Difficult to annotate
Easier to annotate
increase chance of rare class?

Acquisition strategy:
which are "best" to label?
new examples
Humans annotate
Add new examples
Active Learning Iteration
Model Retrain/Update</sample>
    <sample id="969">The image is a bar chart titled "Active Learning: Cumulative vs Iterative Update." The y-axis represents AUC (Area Under the Curve), ranging from 0.50 to 0.75. The x-axis lists different methods: Random, Entropy, CoreSet, CAL, and PRC. Each method has two bars representing "Cumulative" in blue and "Iterative" in yellow.

- For Random, the cumulative AUC is approximately 0.65, while the iterative AUC is around 0.55.
- For Entropy, the cumulative AUC is about 0.70, and the iterative AUC is around 0.65.
- For CoreSet, the cumulative AUC is approximately 0.69, and the iterative AUC is around 0.70.
- For CAL, the cumulative AUC is about 0.68, and the iterative AUC is around 0.62.
- For PRC, the cumulative AUC is approximately 0.70, and the iterative AUC is around 0.63.

The chart shows that for most methods, the cumulative update performs better than the iterative update in terms of AUC.</sample>
    <sample id="970">The image is a slide from a presentation titled "Active Learning: Probability-of-Rare-Class Strategy." The slide contains a flowchart and some text explaining the process of active learning, particularly focusing on the probability of rare class strategy.

### Text on the Slide:
- **Title:** Active Learning: Probability-of-Rare-Class Strategy
- **Flowchart Description:**
  - **Initial model: Transfer Learning**
  - **Cumulative (CM):**
    - New data → Train → Old model → New model
  - **Iterative (IT):**
    - New data → Fine-tune → Old model → New model
  - **Rare class annotation ~ "needle in a haystack":**
    - Difficult to annotate → Easier to annotate
    - Increase chance of rare class?
  - **Acquisition strategy: which are “best” to label?**
  - **Model Retrain/Update**
  - **Active Learning Iteration:**
    - Humans annotate → New examples → Add new examples

### Visual Elements:
- A large yellow circle with a red slash through it represents the concept of a rare class being difficult to annotate.
- Arrows indicate the flow of the process, showing how new data is used to train models, which are then updated or retrained based on human annotations.
- The slide also includes a small video feed in the top right corner, indicating that this is part of a live presentation.

### Page Number:
- The page number "19" is located in the bottom right corner of the slide.</sample>
    <sample id="971">The image is a slide from a presentation titled "Active Learning: Probability-of-Rare-Class Strategy." The slide outlines a process involving active learning and the probability of rare class annotation. Here's a breakdown of the content:

1. **Title**: Active Learning: Probability-of-Rare-Class Strategy

2. **Main Diagram**:
   - **Initial Model**: Transfer Learning
   - **Rare Class Annotation**: Described as "needle in a haystack," indicating it is difficult to annotate.
   - **Acquisition Strategy**: Which are "best" to label?
   - **Model Retrain/Update**: This step involves retraining or updating the model based on new examples.
   - **Humans Annotate**: New examples are annotated by humans.
   - **Add New Examples**: The annotated examples are added back into the dataset.

3. **Additional Information**:
   - **Cumulative (CM)**: A flowchart showing the process of training with new data and updating the model.
   - **Iterative (IT)**: Another flowchart showing the process of fine-tuning with old data and updating the model.
   - **Active Learning Strategy Comparison (AUCs)**: A bar chart comparing different active learning strategies, including AL-Random, AL-Entropy, AL-CoreSet, and AL-CAL. The AUC values for these strategies are shown as +0.15, +0.20, +0.19, and +0.19 respectively.

4. **Page Number**: 19

This slide appears to be part of a larger discussion on active learning techniques, specifically focusing on how to efficiently annotate rare classes using human expertise while iteratively improving the model.</sample>
    <sample id="972">The image is a slide from a presentation titled "Active Learning: Probability-of-Rare-Class Strategy." It shows a bar chart comparing different active learning strategies based on their Area Under the Curve (AUC) values.

The chart includes the following categories:
- Baseline: from scratch
- Transferred model
- AL-Random (+0.15)
- AL-Entropy (+0.20)
- AL-CoreSet (+0.19)
- AL-CAL (+0.19)
- AL-PRC (ours, +0.21)

The x-axis represents the AUC values ranging from 0.50 to 0.75, and the y-axis lists the different active learning strategies. The slide number is indicated as 21 in the bottom right corner.</sample>
    <sample id="973">The image is a slide from a presentation titled "Active Learning: Probability-of-Rare-Class Strategy." It shows a bar chart comparing different active learning strategies based on their Area Under the Curve (AUC) values.

The chart includes the following categories:
- Baseline: from scratch
- Transferred model
- AL-Random
- AL-Entropy
- AL-CoreSet
- AL-CAL
- AL-PRC (ours)
- Final Model (best transfer model + cumulative new data)

Each category has a corresponding AUC value, with the final model showing the highest AUC of 0.75. The other models have AUCs ranging from 0.65 to 0.70.</sample>
    <sample id="974">Active Learning: Probability-of-Rare-Class Strategy

| Active Learning Strategy Characteristics |
| --- | --- | --- |
|  | Rare % | Time (s) | Subj. diff. |
| RANDOM | 3.20 | 11.96 | -0.065 |
| ENTROPY | 6.80 | 12.78 | 0.035 |
| CORESET | 6.00 | 11.89 | 0.039 |
| CAL | 4.80 | 11.88 | -0.045 |
| PRC | 7.60 | 13.55 | 0.071 |

- Minimum annotation cost does not necessarily lead to better models
- Rarity could make the annotations more difficult: cognitive dissonance is one such class.
- To increase dissonance samples, PRC works the best.</sample>
    <sample id="975">The image is a slide from a presentation with the title "Takeaways" at the top left corner. The slide contains several sections with different visual and textual elements:

1. **Top Section:**
   - **Text:** "Rare class annotation ~ 'needle in a haystack'"
   - **Visual:** An illustration of a haystack with a needle highlighted, indicating the difficulty of finding rare classes.

2. **Right Section:**
   - **Text:** "PRC is simple &amp; efficient for rare sample acquisition"
   - **Visual:** A diagram showing a process where a needle (representing a rare class) is found efficiently using PRC (possibly referring to a specific method or algorithm).

3. **Bottom Left Section:**
   - **Text:** "Cold-start AL with transfer learning"
   - **Visual:** An illustration of a neural network with snowflake-like patterns, suggesting the use of transfer learning in an active learning context.

4. **Middle Section:**
   - **Text:** "Out-of-domain: Iterative"
   - **Visual:** A flowchart with labeled boxes M0, M1, M2, and M3, indicating an iterative process in an out-of-domain setting.

5. **Bottom Right Section:**
   - **Text:** "In-domain: Cumulative"
   - **Visual:** A flowchart with labeled boxes M0, M1, M2, and M3, indicating a cumulative process within the domain.

The slide number "24" is visible in the bottom right corner.</sample>
    <sample id="976">The image is a slide from a presentation with the title "Takeaways." It contains several sections with diagrams and text explaining different concepts related to machine learning and data annotation.

1. **Rare class annotation ~ "needle in a haystack"**
   - This section uses an analogy to describe the challenge of finding rare classes in large datasets, comparing it to finding a needle in a haystack.

2. **PRC is simple &amp; efficient for rare sample acquisition**
   - This section suggests that PRC (possibly a method or algorithm) is a simple and efficient approach for acquiring rare samples.

3. **Cold-start AL with transfer learning**
   - This section discusses using active learning (AL) with transfer learning to start with limited data and gradually improve the model's performance.

4. **Out-of-domain: Iterative**
   - This section shows a diagram with labeled boxes M0, M1, M2, and M3, indicating an iterative process where data is processed through these stages, suggesting a step-by-step approach to out-of-domain data handling.

5. **In-domain: Cumulative**
   - This section shows a diagram with labeled boxes M0, M1, M2, and M3, indicating a cumulative process where data is processed through these stages, suggesting a step-by-step approach to in-domain data handling.

The slide number at the bottom right corner is 24.</sample>
    <sample id="977">Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge

Contact: vvaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu

Code:
https://github.com/humanlab/rare-class-AL

Dataset:
https://github.com/humanlab/dissonance-twitter-dataset

Paper:
https://arxiv.org/abs/2305.02459

Thank you!</sample>
    <sample id="978">BART-FID-RAG, Blender2, Emora, and Blender-Decode.</sample>
    <sample id="979">There are seven authors involved in the paper.</sample>
    <sample id="980">The video does not provide information about the ideal qualities of a good planner. It focuses on constrained language planning and how abstract goals can be inherited by different real-life specific goals with multi-faceted constraints.</sample>
    <sample id="981">There are eight authors involved in the paper.</sample>
    <sample id="982">The name of the speaker is Vasudha Varadarajan.</sample>
    <sample id="983">The authors, Adam Przepiórkowski and Michał Woźniak, are affiliated with the Institute of Computer Science, Polish Academy of Sciences, located at ul. Jana Kazimierza 5, 01-248 Warsaw.</sample>
    <sample id="984">XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations

Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang

PennState
amazon</sample>
    <sample id="985">Semantic Parsing

- Semantic Parsing is a task to build semantic representation of the user queries, such as SQL and Lambda Calculus.

Which countries in Europe have at least 3 car manufacturers?

SELECT T1.country_name
FROM countries AS T1 JOIN continents AS T2 ON T1.continent = T2.cont_id
JOIN car_makers AS T3 ON T1.country_id = T3.country
WHERE T2.continent = 'Europe'
GROUP BY T1.country_name
HAVING COUNT(*) &gt;= 3

what players made less than three assists over a season?

(call SW.listValue ( call
SW.getProperty ( ( lambda s ( call
SW.filter( var s ) ( call
SW.ensureNumericProperty ( string num_assists ) ) (string &lt; ) ( call
SW.ensureNumericEntity ( number 3 assist ) ) ) (call SW.domain ( string player ) ) ) ( string player )
)</sample>
    <sample id="986">The image is a slide from a presentation titled "Cross-lingual Semantic Parsing." The text on the slide defines the task of cross-lingual semantic parsing as translating queries in multiple natural languages into multiple meaning representations. Below this definition, there is a diagram showing three input languages (English, German, Chinese) and three output formats (SQL, Lambda, FunQL), with an arrow labeled "Neural Models" pointing from the inputs to the outputs, indicating that neural models are used to perform the translation. The slide number is 3, and there is a small image of a person in the top right corner, presumably the presenter.</sample>
    <sample id="987">The image is a slide from a presentation titled "Cross-lingual Semantic Parsing." The text on the slide defines the task of cross-lingual semantic parsing as translating queries in multiple natural languages into multiple meaning representations. Below this definition, there is a diagram illustrating the process:

- On the left side, there are three boxes labeled "English," "German," and "Chinese," representing different natural languages.
- In the center, there is a box labeled "Neural Models," indicating the use of neural models to process these languages.
- On the right side, there are three boxes labeled "SQL," "Lambda," and "FunQL," which represent different meaning representations or query languages.

The slide also includes a small image of a person in the top right corner, presumably the presenter, with the name "Yusen Zhang" displayed next to it. The slide number "3" is visible in the bottom right corner.</sample>
    <sample id="988">The slide is titled "Cross-lingual Semantic Parsing." It states that existing CLSP (Cross-lingual Semantic Parsing) models are separately proposed and evaluated on datasets of limited tasks and applications. For instance, it mentions a lack of coverage on certain natural languages.

The slide also includes a diagram with three language categories: English, German, and Chinese, which are represented by green, blue, and pink boxes respectively. These languages are connected to a central box labeled "Neural Models," which points to three different semantic parsing formats: SQL, Lambda, and FunQL, each in a separate blue box.</sample>
    <sample id="989">The slide is titled "Cross-lingual Semantic Parsing." It discusses that existing CLSP (Cross-lingual Semantic Parsing) models are separately proposed and evaluated on datasets of limited tasks and applications. For instance, it mentions a lack of coverage on certain natural languages.

The slide shows a flowchart with three input languages: English, German, and Chinese. These inputs are directed towards neural models, which then produce outputs in the form of SQL, Lambda, and FunQL. The text on the slide changes slightly between frames, indicating a transition from discussing natural language to meaning representation.</sample>
    <sample id="990">The slide is titled "Cross-lingual Semantic Parsing." It discusses that existing CLSP (Cross-lingual Semantic Parsing) models are separately proposed and evaluated on datasets of limited tasks and applications. For instance, it mentions a lack of coverage on certain meaning representations.

The slide shows a flowchart with three input languages: English, German, and Chinese. These inputs are directed towards neural models, which then output different types of semantic representations: SQL, Lambda, and FunQL.</sample>
    <sample id="991">The slide is titled "Cross-lingual Semantic Parsing." It discusses existing CLSP (Cross-Lingual Semantic Parsing) models, which are separately proposed and evaluated on datasets of limited tasks and applications. The text mentions a specific issue: "Lack of coverage on certain meaning representation."

The slide shows a diagram with three languages on the left side: English, German, and Chinese. These are connected to a central arrow labeled "Neural Models," which points to four different semantic representations on the right side: SQL, Lambda, and FunQL.

The presenter's name, Yusen Zhang, is displayed in the top right corner of the slide.</sample>
    <sample id="992">The slide is titled "Cross-lingual Semantic Parsing." It states that existing CLSP (Cross-lingual Semantic Parsing) models are separately proposed and evaluated on datasets of limited tasks and applications. For instance, it mentions a lack of coverage on certain neural models.

The slide shows a diagram with three languages on the left: English, German, and Chinese. These are connected to a single model in the center, which then leads to three different outputs on the right: SQL, Lambda, and FunQL.</sample>
    <sample id="993">The slide is titled "XSemPLR" and discusses a unified dataset for cross-lingual semantic parsing in multiple natural languages and meaning representations. The content includes:

- We provide a unified dataset XSemPLR for cross-lingual semantic parsing in multiple natural languages and meaning representations.
- It contains:
  - 9 datasets in various domains
  - 5 semantic parsing tasks
  - 8 meaning representations
  - 22 natural languages in 15 language families

The slide also shows examples of queries in different languages, such as English, German, Chinese, Italian, Hindi, and Arabic, along with corresponding semantic representations in various formats like FunQL, SQL, ThingTalk, Intent Slot, Prolog, and others.</sample>
    <sample id="994">XSemPLR

- We provide a unified dataset XSemPLR for cross-lingual semantic parsing in multiple natural languages and meaning representations. It contains:
  - 9 datasets in various domains
  - 5 semantic parsing tasks.
  - 8 meaning representations
  - 22 natural languages in 15 language families</sample>
    <sample id="995">The image is a slide from a presentation titled "Experiment Settings." It outlines a specific setting for training and evaluation, which is labeled as "Translate-Test." The text on the slide states:

"We consider the six settings for training and evaluation.
○ Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval."

Below this description, there are two diagrams labeled "Training" and "Inference."

1. **Training Diagram**:
   - Starts with an input labeled "English."
   - An arrow points to "English Model."
   - Another arrow points from "English Model" to "SQL."

2. **Inference Diagram**:
   - Starts with an input labeled "German."
   - An arrow points to "Translate API."
   - Another arrow points from "Translate API" to "English."
   - An arrow then points from "English" to "English Model."
   - Finally, an arrow points from "English Model" to "SQL."

The slide number in the bottom right corner is 8.</sample>
    <sample id="996">The image is a slide from a presentation titled "Experiment Settings." It outlines a specific setting for training and evaluation, which is labeled as "Translate-Test." The text on the slide states:

"We consider the six settings for training and evaluation.
○ Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval."

Below this description, there are two diagrams labeled "Training" and "Inference."

1. **Training Diagram**:
   - Starts with "English"
   - Transitions through "English Model"
   - Ends at "SQL"

2. **Inference Diagram**:
   - Starts with "German"
   - Uses "Translate API" to translate to "English"
   - Transitions through "English Model"
   - Ends at "SQL"

The slide number is indicated as 8 in the bottom right corner.</sample>
    <sample id="997">The image is a slide from a presentation titled "Experiment Settings." It outlines a specific setting for training and evaluation, which is labeled as "Translate-Test." The text on the slide states:

"We consider the six settings for training and evaluation.
○ Translate-Test: Use google translate API to translate source to the target language. Then use monolingual model to train and eval."

Below this description, there are two diagrams labeled "Training" and "Inference."

1. **Training Diagram**:
   - Starts with "English"
   - Has an arrow pointing to "English Model"
   - Another arrow points from "English Model" to "SQL"

2. **Inference Diagram**:
   - Starts with "German"
   - Has an arrow pointing to "Translate API"
   - Another arrow points from "Translate API" to "English"
   - Then it has an arrow pointing from "English" to "English Model"
   - Finally, an arrow points from "English Model" to "SQL"

The slide number is indicated as 8 in the bottom right corner.</sample>
    <sample id="998">Experiment Settings

- We consider the six settings for training and evaluation.
  ○ Monolingual Model: Source language is the same as target language, e.g., German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.

Training
![German (Few-shot) → German Model → SQL](https://i.imgur.com/3Q5z5QG.png)

Inference
![German → German Model → SQL](https://i.imgur.com/3Q5z5QG.png)</sample>
    <sample id="999">Experiment Settings

- We consider the six settings for training and evaluation.
  - Monolingual Model: Source language is the same as target language, e.g., German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.

Training
- German (Few-shot) → German Model → SQL

Inference
- German → German Model → SQL</sample>
    <sample id="1000">Experiment Settings

- We consider the six settings for training and evaluation.
  ○ Monolingual Model: Source language is the same as target language, e.g., German-to-German. We also test Monolingual Few-shot setting by training monolingual models with only 10% training data.

Training
- German (Few-shot)
- German Model
- SQL

Inference
- German
- German Model
- SQL</sample>
    <sample id="1001">Experiment Settings
- We consider the six settings for training and evaluation.
  o Multilingual Model: Train one multilingual model for all languages.

Training
- German
- English
- Chinese
  Multilingual Model
  SQL

Inference
- German
  Multilingual Model
  SQL</sample>
    <sample id="1002">Experiment Settings
- We consider the six settings for training and evaluation.
  o Multilingual Model: Train one multilingual model for all languages.

Training
- German
- English
- Chinese
  Multilingual Model
  SQL

Inference
- German
  Multilingual Model
  SQL</sample>
    <sample id="1003">The image is a slide from a presentation titled "Experiment Settings." The content of the slide is as follows:

- **Experiment Settings**: We consider the six settings for training and evaluation.
  - **Multilingual Model**: Train one multilingual model for all languages.

**Training**
- German
- English
- Chinese
- Multilingual Model
- SQL

**Inference**
- German
- Multilingual Model
- SQL

The slide also includes a note that mentions "Few-shot transfer" in red text, which seems to be an additional point or correction related to the multilingual model training process.</sample>
    <sample id="1004">The image is a slide from a presentation titled "Experiment Settings." It outlines the settings for training and evaluation, specifically focusing on cross-lingual zero-shot/few-shot transfer. The text states:

- We consider the six settings for training and evaluation.
  - Cross-lingual Zero-shot/Few-shot transfer: Train on one source language and transfer to another language.

The slide also includes a diagram illustrating the process:
- **Training**: 
  - English (or English)
  - German Few-shot
  - Multilingual Model
  - SQL
- **Inference**:
  - German
  - Multilingual Model
  - SQL

The slide number is indicated as 11 in the bottom right corner.</sample>
    <sample id="1005">The image is a slide from a presentation titled "Experiment Settings." The slide outlines the experiment settings for training and evaluation, specifically focusing on cross-lingual zero-shot/few-shot transfer. It explains that the model is trained on one source language and then transferred to another language.

The slide is divided into two main sections: Training and Inference.

### Training Section:
- **English**: Training data in English.
- **German Few-shot**: Training data in German with few-shot learning.
- **Multilingual Model**: The model trained on the above data.
- **SQL**: The output or inference in SQL format.

### Inference Section:
- **German**: Inference data in German.
- **Multilingual Model**: The same multilingual model used for inference.
- **SQL**: The output or inference in SQL format.

The slide also includes a note at the top stating, "We consider the six settings for training and evaluation," but only the cross-lingual zero-shot/few-shot transfer setting is highlighted in red text.</sample>
    <sample id="1006">Analysis of Monolingual

- We evaluate on two groups of models on Monolingual Setting
  - Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilingual Pretrained Encoder-Decoder Models
    - mBART, mT5

- We found Enc-Dec (mT5) obtains the best performance on all datasets!</sample>
    <sample id="1007">Analysis of Monolingual

- We evaluate on two groups of models on Monolingual Setting
  - Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilingual Pretrained Encoder-Decoder Models
    - mBART, mT5

- We found Enc-Dec (mT5) obtains the best performance on all datasets!</sample>
    <sample id="1008">Analysis of Monolingual

- We evaluate on two groups of models on Monolingual Setting
  - Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilingual Pretrained Encoder-Decoder Models
    - mBART, mT5

- We found Enc-Dec (mT5) obtains the best performance on all datasets!</sample>
    <sample id="1009">Analysis of Monolingual

- We evaluate on two groups of models on Monolingual Setting
  - Enc-PTR: Multilingual Pretrained Encoders with Pointer-based Decoders
    - XLM-R + PTR, mBERT + PTR
  - Enc-Dec: Multilingual Pretrained Encoder-Decoder Models
    - mBART, mT5

- We found Enc-Dec (mT5) obtains the best performance on all datasets!</sample>
    <sample id="1010">The slide is titled "Analysis of Multilingual Training." It discusses evaluating models on mT5 and XLM-R + PTR in a multilingual setting. The text states that Enc-Dec/Enc-PTR (mT5/XLM-R) can be improved by training in a mixture of various languages.

The table below the text compares the performance of XLM-R+PTR and mT5 across different datasets, including MATIS, MGeoQuery, MSpider, MNLmaps, MOvernight, MCWQ, MSchema2QA, MTOP, and MCoNaLa². The performance metrics are shown for both monolingual and multilingual settings.

For the monolingual setting:
- XLM-R+PTR has an average score of 52.03.
- mT5 has an average score of 58.16.

For the multilingual setting:
- XLM-R+PTR has an average score of 59.06.
- mT5 has an average score of 61.82.

The slide also includes a note that the average scores are highlighted with red boxes.</sample>
    <sample id="1011">The slide is titled "Analysis of Multilingual Training." It discusses evaluating mT5 and XLM-R + PTR on a multilingual setting. The text states that Enc-Dec/Enc-PTR (mT5/XLM-R) can be improved by training in a mixture of various languages.

The table below the text compares the performance of XLM-R+PTR and mT5 across different datasets, including MATIS, MGeoQuery, MSpider, MNLmaps, MOvernight, MCWQ, MSchema2QA, MTOP, and MCoNaLa². The performance metrics are shown for both monolingual and multilingual settings.

For the monolingual setting:
- XLM-R+PTR has an average score of 52.03.
- mT5 has an average score of 58.16.

For the multilingual setting:
- XLM-R+PTR has an average score of 59.06.
- mT5 has an average score of 61.82.

The slide also includes a note that the average scores for XLM-R+PTR and mT5 are highlighted with red boxes.</sample>
    <sample id="1012">The image is a slide from a presentation titled "Analysis of Multilingual Training." The slide discusses the evaluation of models on multilingual datasets using mT5 and XLM-R + PTR. It states that most major natural languages (NLs) can obtain performance gains, except for English, which shows a drop in performance in 7 datasets and an increase in 3 datasets. This phenomenon is referred to as the "Curse of Multilinguality."

The slide includes a bar chart with the following details:
- The x-axis represents different natural languages: en (English), de (German), zh (Chinese), th (Thai), fa (Persian), el (Greek), id (Indonesian), sv (Swedish), es (Spanish), and fr (French).
- The y-axis represents the number of datasets.
- Each language has two bars: one for "Increase" (dotted pattern) and one for "Decrease" (striped pattern).

The bar chart visually represents the distribution of datasets where performance increases or decreases for each language.</sample>
    <sample id="1013">The slide is titled "Analysis of Multilingual Training." It states that the evaluation was conducted on mT5 and XLM-R + PTR in a multilingual setting. The text below mentions that most major natural languages (NLs) can obtain performance gains, except for English, which shows a drop in performance in 7 datasets and an increase in 3 datasets. This phenomenon is referred to as the "Curse of Multilinguality."

The slide includes a bar chart with the following details:
- The x-axis represents different natural languages: en (English), de (German), zh (Chinese), th (Thai), fa (Persian), el (Greek), id (Indonesian), sv (Swedish), es (Spanish), and fr (French).
- The y-axis represents the number of datasets.
- The chart shows two categories: "Increase" (dotted bars) and "Decrease" (striped bars).

The legend indicates that the dotted bars represent increases in performance, while the striped bars represent decreases in performance. The chart visually represents the distribution of these increases and decreases across the different languages.</sample>
    <sample id="1014">The image is a slide titled "Cross-lingual Performance Gap." It presents a radar chart comparing three different settings: Cross-lingual Few-shot transfer (blue line), Cross-lingual Zero-shot transfer (orange line), and Monolingual Setting (green line). The chart includes various datasets such as Geoquery, MTOP, Schema2QA, Overnight, NLMaps, MCWQ, ATIS, Spider, and Geoquery/lamb, Geoquery/prolog, Geoquery/funql, and Geoquery/sql.

The legend at the bottom right indicates that the blue line represents "Few-shot," the orange line represents "Zero-shot," and the green line represents "Monolingual."

The slide number is 15, and there is a small inset in the top right corner showing a person with headphones, presumably the presenter, named Yusen Zhang.</sample>
    <sample id="1015">The image is a slide from a presentation titled "Cross-lingual Performance Gap." It includes three lines representing different types of cross-lingual transfer learning methods:

- Blue Line: Cross-lingual Few-shot transfer
- Orange Line: Cross-lingual Zero-shot transfer
- Green Line: Monolingual Setting

The slide also features a radar chart with various datasets on the axes, including:
- Geoquery
- Geoquery/lamb
- Geoquery/prolog
- Geoquery/funql
- Geoquery/sql
- MTOP
- Schema2QA
- Spider
- ATIS
- Overnight
- NLMaps
- MCWQ

Each dataset has corresponding performance values for the three methods (Few-shot, Zero-shot, and Monolingual) represented by the blue, orange, and green lines respectively. The legend at the bottom right corner indicates which color corresponds to each method. The slide number is 15.</sample>
    <sample id="1016">The image is a slide from a presentation titled "Cross-lingual Performance Gap." It includes two bullet points and a radar chart:

1. **Green - Orange**: For zero-shot setting, the cross-lingual transfer performance gap is significant.
2. **Blue - Orange**: For few-shot setting, the transfer gap is shortened rapidly.

The radar chart compares different datasets (Geoquery, Geoquery/lamb, Geoquery/prolog, Geoquery/funql, Geoquery/sql, Spider, ATIS, MTOP, Schema2QA, Overnight, NLMaps, MCWQ) across three conditions: Few-shot, Zero-shot, and Monolingual. The legend indicates that blue represents Few-shot, orange represents Zero-shot, and green represents Monolingual.</sample>
    <sample id="1017">Other Results &amp; Findings (Section 4 in Paper)
- Enc-Dec (mT5) outperforms previous work or achieves comparable results.
- Pretraining on the English NL can significantly boost the performance of few-shot on target NLs.
- Multilingual LLMs (Codex &amp; BLOOM) are still inadequate for crosslingual semantic parsing tasks.
- Chinese transfer learning and English monolingual training (En -&gt; En) has the largest performance gap, while German usually has the smallest.
- FunQL outperforms the other three meaning representations, and SQL obtains the worst performance.</sample>
    <sample id="1018">Other Results &amp; Findings (Section 4 in Paper)
- Enc-Dec (mT5) outperforms previous work or achieves comparable results.
- Pretraining on the English NL can significantly boost the performance of few-shot on target NLs.
- Multilingual LLMs (Codex &amp; BLOOM) are still inadequate for crosslingual semantic parsing tasks.
- Chinese transfer learning and English monolingual training (En -&gt; En) has the largest performance gap, while German usually has the smallest.
- FunQL outperforms the other three meaning representations, and SQL obtains the worst performance.</sample>
    <sample id="1019">The image is a slide from a presentation with the title "Conclusion." The content of the slide is as follows:

- We build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations.
- We conduct a comprehensive benchmark study on three representative types of multilingual language models.
- Our results show that mT5 with monolingual training yields the best performance, while notably multilingual LLMs are still inadequate to perform cross-lingual semantic parsing tasks. Moreover, the performance gap between monolingual training and cross-lingual transfer learning is still significant.

The slide number is 18, and there is a small image in the top right corner showing a person named Yusen Zhang.</sample>
    <sample id="1020">**Conclusion**

- We build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations.
- We conduct a comprehensive benchmark study on three representative types of multilingual language models.
- Our results show that mT5 with monolingual training yields the best performance, while notably multilingual LLMs are still inadequate to perform cross-lingual semantic parsing tasks. Moreover, the performance gap between monolingual training and cross-lingual transfer learning is still significant.

**Links**

Welcome to visit our paper and code!

Paper Link: [https://arxiv.org/pdf/2306.04085.pdf](https://arxiv.org/pdf/2306.04085.pdf)

Code Link: [https://github.com/psunlpgroup/xsemplr](https://github.com/psunlpgroup/xsemplr)</sample>
    <sample id="1021">The most common errors of PaLM, according to the insights from MQM, are dominated by "Accuracy/Omission" and "Style/Awkwardness."</sample>
    <sample id="1048">The authors, Sarah E. Finch, James D. Finch, and Jinho D. Choi, are affiliated with Emory University and the Emory NLP Research Lab.</sample>
    <sample id="1049">Continuous fine-tuning</sample>
    <sample id="1050">There are seven authors involved in the paper.</sample>
    <sample id="1084">The name of the speaker is Yusen Zhang.</sample>
    <sample id="1085">#ACL2023
From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models

Shangbin Feng
Chan Young Park
Yuhan Liu
Yulia Tsvetkov

PAUL G. ALLEN SCHOOL
UW NLP
Carnegie Mellon University Language Technologies Institute
Tsinghua University</sample>
    <sample id="1086">The image is a slide from a presentation titled "LM Training Data: A mixed blessing." It features a bar chart with the following details:

- **Title**: LM Training Data: A mixed blessing
- **Content**: The chart lists various websites along the y-axis and the number of tokens (log scale) on the x-axis.
- **Websites Listed**:
  - patents.google.com
  - en.wikipedia.org
  - en.m.wikipedia.org
  - www.nytimes.com
  - www.latimes.com
  - www.theguardian.com
  - journals.plos.org
  - www.forbes.com
  - hubspot.com
  - patents.com
  - www.scribbl.com
  - www.washingtonpost.com
  - www.fool.com
  - ipfs.io
  - www.frontiersin.org
  - www.businessinsider.com
  - www.chicagotribune.com
  - www.booking.com
  - www.theatlantic.com
  - look.spring.com
  - www.aljazeera.com
  - www.kickstarter.com
  - caselaw.findlaw.com
  - www.ncbi.nlm.nih.gov
  - www.npr.org

- **Source**: Dodge, Jesse, et al. "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus." Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.

The chart visually represents the number of tokens for each website, with the longest bar corresponding to the highest number of tokens.</sample>
    <sample id="1087">The image is a slide from a presentation titled "LM Training Data: A mixed blessing." It features a bar chart with the x-axis labeled "# tokens (log scale)" and the y-axis labeled "Website." The chart displays the number of tokens for various websites, including patents.google.com, en.wikipedia.org, en.m.wikipedia.org, www.nytimes.com, www.latimes.com, www.theguardian.com, journals.plos.org, www.forbes.com, hubspot.com, patents.com, scribd.com, www.washingtonpost.com, www.fool.com, ipfs.io, www.frontiersin.org, www.businessinsider.com, www.chicagotribune.com, www.booking.com, www.theatlantic.com, look.spring.com, www.aljazeera.com, www.kickstarter.com, caselaw.findlaw.com, www.ncbi.nlm.nih.gov, and www.npr.org. The longest bar represents the highest number of tokens, while the shortest bar represents the lowest.

At the bottom right corner of the slide, there is a citation that reads: "Dodge, Jesse, et al. 'Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus.' Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021."</sample>
    <sample id="1088">The image is a slide from a presentation titled "LM Training Data: A mixed blessing." It features a bar chart showing the number of tokens (on a log scale) for various websites used in language model training data. The x-axis represents the number of tokens, and the y-axis lists different websites. The longest bars correspond to websites like patents.google.com and en.wikipedia.org, indicating they have the highest number of tokens. The source of the data is cited as "Dodge, Jesse, et al. 'Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus.' Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021."</sample>
    <sample id="1089">LM Training Data
A mixed blessing

The slide shows a bar chart with the title "LM Training Data" and a subtitle "A mixed blessing." The chart lists various websites on the y-axis, such as patents.google.com, en.wikipedia.org, en.m.wikipedia.org, www.nytimes.com, www.latimes.com, and others, along with the number of tokens (log scale) on the x-axis. The data is sourced from Dodge, Jesse, et al., "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus," Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.

The next slide has a diagram with three boxes labeled "Pretraining data," "Language models," and "Downstream tasks," connected by arrows indicating the flow from pretraining data to language models and then to downstream tasks.</sample>
    <sample id="1090">The image is a slide from a presentation with the title "To this end." It contains three main boxes connected by arrows, representing a flow or process:

1. **Pretraining data**
2. **Language models**
3. **Downstream tasks**

Below these boxes, there are two sets of questions in different colors:
- **Blue text:** "How to evaluate the political leaning of LMs? What role does pretraining data play in such political biases?"
- **Green text:** "How do LMs with different political leanings perform? Does LM political leaning result in fairness issues in NLP applications?"

The slide appears to be discussing the impact of pretraining data on language models and their performance in downstream tasks, particularly focusing on political bias and fairness in natural language processing (NLP) applications.</sample>
    <sample id="1091">To this end

- Pretraining data
  - How to evaluate the political leaning of LMs?
  - What role does pretraining data play in such political biases?

- Language models
  - How do LMs with different political leanings perform?
  - Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="1092">To this end

- Pretraining data
  - How to evaluate the political leaning of LMs?
  - What role does pretraining data play in such political biases?

- Language models
  - How do LMs with different political leanings perform?
  - Does LM political leaning result in fairness issues in NLP applications?</sample>
    <sample id="1093">Evaluating LM Political Leaning

Support both encoder and decoder LMs

- "Do you agree or disagree with this statement? &lt;statement&gt;"
- "I &lt;mask&gt; with this statement."

Automatic eval
Grounded in polisci lit

Political Compass Test
Language Model
Prompted Response
Political Leaning
Left
Libertarian
Right
Authoritarian

Q: Our race has many superior qualities, compared with other races.

Existing LMs
BERT-base
BERT-large
RoBERTa-base
RoBERTa-large
distilBERT
distilRoBERTa
ALBERT-base
ALBERT-large
BART-base
BART-large
Alpaca
Codex
LLaMA
GPT-2
GPT-3-ada
GPT-3-babbage
GPT-3-curious
GPT-3-davinci
ChatGPT
GPT-4
GPT-J</sample>
    <sample id="1094">The image is a slide titled "Existing LMs" which appears to be from a presentation. It features a grid with two axes labeled as "social axis" and "economic axis." The grid is divided into four quadrants, each representing different combinations of social and economic positions: Authoritarian-Left, Authoritarian-Right, Libertarian-Left, and Libertarian-Right.

On the left side of the grid, there are labels for various large language models (LMs) such as BERT-base, BERT-large, RoBERTa-base, RoBERTa-large, distilBERT, distilRoBERTa, ALBERT-base, ALBERT-large, BART-base, BART-large, and Alpaca. These models are plotted in the lower-left quadrant, indicating they are positioned on the libertarian side of the social axis and on the left side of the economic axis.

On the right side of the grid, there are labels for other LMs such as Codex, LLaMA, GPT-2, GPT-3-ada, GPT-3-babbage, GPT-3-curie, GPT-3-davinci, ChatGPT, GPT-4, and GPT-J. These models are plotted in the upper-right quadrant, indicating they are positioned on the authoritarian side of the social axis and on the right side of the economic axis.

The slide seems to be comparing the political leanings of different large language models based on their responses to a set of questions or prompts.</sample>
    <sample id="1095">The image is a slide from a presentation titled "Existing LMs" (Large Language Models). It features a political ideology map with two axes: the social axis and the economic axis. The social axis ranges from libertarian on the left to authoritarian on the right, while the economic axis ranges from left to right.

On the left side of the map, there are labels for various language models such as BERT-base, BERT-large, RoBERTa-base, RoBERTa-large, distilBERT, distilRoBERTa, ALBERT-base, ALBERT-large, BART-base, BART-large, and Alpaca. These models are positioned in the lower-left quadrant, indicating they lean towards libertarianism on both the social and economic axes.

On the right side of the map, there are labels for other language models such as Codex, LLaMA, GPT-2, GPT-3-ada, GPT-3-babbage, GPT-3-curie, GPT-3-davinci, ChatGPT, GPT-4, and GPT-J. These models are positioned in the upper-right quadrant, indicating they lean towards authoritarianism on both the social and economic axes.

The slide also includes references to additional research:
- "Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning"
- "Shen, Qinlan, and Carolyn Rose. 'Politics: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection.' Findings of the Association for Computational Linguistics: NAACL 2022."
- "Social Media Data"

The bottom of the slide mentions "Libertarian" and "Authoritarian," reinforcing the ideological spectrum being discussed.</sample>
    <sample id="1096">The image is a slide from a presentation titled "Pretraining Data." The slide discusses further pretraining of large language models (RoBERTa, GPT-2) and evaluating changes in political leaning. It compares two types of data sources: News Media and Social Media (Reddit).

### Slide Content:

**Title:**
- Pretraining Data

**Main Text:**
- Further pretrain LM (RoBERTa, GPT-2) checkpoints, evaluate change in political leaning

**Two boxes with labels:**

1. **News Media**
   - Left
   - Center
   - Right

2. **Social Media (Reddit)**
   - Left
   - Center
   - Right

**References:**
- Liu, Yujian, et al. "POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection." Findings of the Association for Computational Linguistics: NAACL 2022.
- Shen, Qinlan, and Carolyn Rose. "What sounds 'right' to me? experiential factors in the perception of political ideology." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="1097">The image is a slide from a presentation titled "Pretraining Data." It discusses further pretraining of large language models (LM) such as RoBERTa and GPT-2 checkpoints to evaluate changes in political leaning. The slide is divided into two sections, each representing different data sources for pretraining:

1. **News Media**:
   - Left: Represents left-leaning news media.
   - Center: Represents center-leaning news media.
   - Right: Represents right-leaning news media.

2. **Social Media (Reddit)**:
   - Left: Represents left-leaning social media content.
   - Center: Represents center-leaning social media content.
   - Right: Represents right-leaning social media content.

At the bottom of the slide, there are references to academic papers:
- Liu, Yujian, et al. "POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection." Findings of the Association for Computational Linguistics: NAACL 2022.
- Shen, Qinlan, and Carolyn Rose. "What sounds 'right' to me? experiential factors in the perception of political ideology." Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021.</sample>
    <sample id="1098">Results

Partisan shifts in LM political leaning

RoBERTa
GPT-2

Left
Center
Right</sample>
    <sample id="1099">Results

Partisan shifts in LM political leaning

RoBERTa
GPT-2

Left
Center
Right</sample>
    <sample id="1100">The image is a slide from a presentation titled "Results: Partisan shifts in LM political leaning." It shows two heatmaps, one for RoBERTa and one for GPT-2, with different colored quadrants representing different political leanings (Left, Center, Right) and subcategories (original, news, reddit). The heatmaps display the distribution of political leanings across these categories.

For RoBERTa:
- The "news left" quadrant has a blue arrow pointing to the right with Δ=(-2.75,-1.24).
- The "news center" quadrant has a black arrow pointing to the right with Δ=(-0.13,-1.03).
- The "news right" quadrant has an orange arrow pointing to the right with Δ=(-1.63,1.03).
- The "reddit left" quadrant has a blue arrow pointing down with Δ=(0.75,-3.64).
- The "reddit center" quadrant has a black arrow pointing down with Δ=(-1.75,1.03).
- The "reddit right" quadrant has an orange arrow pointing down with Δ=(0.37,0.00).

For GPT-2:
- The "news left" quadrant has a blue arrow pointing to the right with Δ=(-2.37,-0.51).
- The "news center" quadrant has a black arrow pointing to the right with Δ=(-0.12,1.28).
- The "news right" quadrant has an orange arrow pointing to the right with Δ=(-2.13,0.06).
- The "reddit left" quadrant has a blue arrow pointing down with Δ=(-1.75,1.03).
- The "reddit center" quadrant has a black arrow pointing down with Δ=(-1.75,1.03).
- The "reddit right" quadrant has an orange arrow pointing down with Δ=(-1.00,1.64).

The slide also includes a legend indicating the direction of the arrows: blue for Left, black for Center, and orange for Right.</sample>
    <sample id="1101">The Trump Card

Pre-45th to post-45th shift

RoBERTa:
- news left: Δ = (-2.75, -1.24)
- news center: Δ = (-0.13, -1.03)
- news right: Δ = (1.63, 1.03)
- reddit left: Δ = (0.75, -3.64)
- reddit center: Δ = (-0.50, -3.64)
- reddit right: Δ = (-1.75, 0.92)

GPT-2:
- news left: Δ = (-2.37, -0.51)
- news center: Δ = (-0.12, 1.28)
- news right: Δ = (-2.13, 0.06)
- reddit left: Δ = (-1.75, 1.03)
- reddit center: Δ = (0.37, 0.00)
- reddit right: Δ = (-1.00, 1.64)</sample>
    <sample id="1102">The Trump Card

Pre-45th to post-45th shift

RoBERTa:
- news left: Δ = (-2.75, -1.24)
- news center: Δ = (-0.13, -1.03)
- news right: Δ = (1.63, 1.03)
- reddit left: Δ = (0.75, -3.64)
- reddit center: Δ = (-0.50, -3.64)
- reddit right: Δ = (-1.75, 0.92)

GPT-2:
- news left: Δ = (-2.37, -0.51)
- news center: Δ = (-0.12, 1.28)
- news right: Δ = (-2.13, 0.06)
- reddit left: Δ = (-1.75, 1.03)
- reddit center: Δ = (0.37, 0.00)
- reddit right: Δ = (-1.00, 1.64)</sample>
    <sample id="1103">The Trump Card

Pre-45th to post-45th shift

RoBERTa:
- news left: Δ = (-2.75, -1.24)
- news center: Δ = (-0.13, -1.03)
- news right: Δ = (1.63, 1.03)
- reddit left: Δ = (0.75, -3.64)
- reddit center: Δ = (-0.50, -3.64)
- reddit right: Δ = (-1.75, 0.92)

GPT-2:
- news left: Δ = (-2.37, -0.51)
- news center: Δ = (-0.12, 1.28)
- news right: Δ = (-2.13, 0.06)
- reddit left: Δ = (-1.75, 1.03)
- reddit center: Δ = (0.37, 0.00)
- reddit right: Δ = (-1.00, 1.64)</sample>
    <sample id="1104">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|-----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30     | 82.35   | 96.30 |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43     | 91.18   | 96.30 |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13     | 82.35   | 92.59 |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78     | 85.29   | 96.30 |</sample>
    <sample id="1105">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30    | 82.35   | 96.30 |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43    | 91.18   | 96.30 |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13    | 82.35   | 92.59 |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78    | 85.29   | 96.30 |</sample>
    <sample id="1106">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30    | 82.35   | 96.30  |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43    | 91.18   | 96.30  |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13    | 82.35   | 92.59  |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78    | 85.29   | 96.30  |</sample>
    <sample id="1107">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|--------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30    | 82.35  | 96.30 |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43    | 91.18  | 96.30 |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13    | 82.35  | 92.59 |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78    | 85.29  | 96.30 |</sample>
    <sample id="1108">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30    | 82.35   | 96.30  |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43    | 91.18   | 96.30  |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13    | 82.35   | 92.59  |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78    | 85.29   | 96.30  |</sample>
    <sample id="1109">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30    | 82.35   | 96.30 |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43    | 91.18   | 96.30 |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13    | 82.35   | 92.59 |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78    | 85.29   | 96.30 |</sample>
    <sample id="1110">Per-Category Performance

Table 4: Performance on hate speech targeting different identity groups and misinformation from different sources. The results are color-coded such that dark yellow denotes best and dark blue denotes worst.

| Hate Speech | BLACK | MUSLIM | LGBTQ+ | JEWS | ASIAN | LATINX | WOMEN | CHRISTIAN | MEN | WHITE |
|-------------|-------|--------|--------|------|-------|--------|-------|-----------|-----|-------|
| NEWS_LEFT   | 89.93 | 89.98 | 90.19 | 89.85 | 91.55 | 91.28 | 86.81 | 87.82     | 85.63 | 86.22 |
| REDDIT_LEFT | 89.84 | 89.90 | 89.96 | 89.50 | 90.66 | 91.15 | 87.42 | 87.65     | 86.20 | 85.13 |
| NEWS_RIGHT  | 88.81 | 88.68 | 88.91 | 89.74 | 90.62 | 89.97 | 86.44 | 89.62     | 86.93 | 86.35 |
| REDDIT_RIGHT| 88.03 | 89.26 | 88.43 | 89.00 | 89.72 | 89.31 | 86.03 | 87.65     | 83.69 | 86.86 |

| Misinformation | HP (L) | NYT (L) | CNN (L) | NPR (L) | GUARD (L) | FOX (R) | WAEX (R) | BBART (R) | WAT (R) | NR (R) |
|----------------|--------|---------|---------|---------|-----------|---------|----------|-----------|---------|-------|
| NEWS_LEFT      | 89.44  | 86.08   | 87.57   | 89.61   | 82.22     | 93.10   | 92.86    | 91.30     | 82.35   | 96.30 |
| REDDIT_LEFT    | 88.73  | 83.54   | 84.86   | 92.21   | 84.44     | 89.66   | 96.43    | 80.43     | 91.18   | 96.30 |
| NEWS_RIGHT     | 89.44  | 86.71   | 89.19   | 90.91   | 86.67     | 88.51   | 85.71    | 89.13     | 82.35   | 92.59 |
| REDDIT_RIGHT   | 90.85  | 86.71   | 90.81   | 84.42   | 84.44     | 91.95   | 96.43    | 84.78     | 85.29   | 96.30 |</sample>
    <sample id="1111">Qualitative Analysis

| Text                                                                 | Target Label | Base | N-L | S-L | N-R | S-R |
|--------------------------------------------------------------------|-------------|------|-----|-----|-----|-----|
| the alt right is corrupted with people supporting racemixing with asians and homosexuals it time for a new nationalism                | ASIAN       | TRUE | TRUE | TRUE | FALSE | FALSE |
| What do McDonald's and priest have in common? They both like sticking their meat in 10 year old buns                            | CHRIS       | TRUE | FALSE | FALSE | TRUE | TRUE |
| (...) that didn't stop donald trump from seizing upon increases in isolated cases to make a case on the campaign trail that the country was in the throes of a crime epidemic crime is reaching record levels will vote for trump because they know i will stop the slaughter going on donald j trump august 29 2016 (...) | RIGHT       | FAKE | TRUE | TRUE | FALSE | FALSE |
| (...) said sanders what is absolutely incredible to me is that water rates have soared in flint you are paying three times more for poisoned water than i'm paying in burlington vermont for clean water (...) | LEFT        | FAKE | TRUE | FALSE | TRUE | FALSE |

Table 5: Examples of the downstream performance of tasks using language models with varying political bias.
CHRIS, Base, N, S, L, R represent Christians, vanilla RoBERTa model, news media, social media, left-leaning, and right-leaning, respectively.</sample>
    <sample id="1112">The image is a slide from a presentation titled "Qualitative Analysis." It contains a table labeled "Table 5: Examples of the downstream performance of tasks using language models with varying political bias." The table includes columns for different types of text (e.g., "the alt right is corrupted with people supporting racemixing with asians and homosexuals it time for a new nationalism," "What do McDonald's and priest have in common? They both like sticking their meat in 10 year old buns," etc.), target labels (e.g., "ASIAN," "CHRIS," "RIGHT," "LEFT"), and various models' predictions (e.g., "Base," "N-L," "S-L," "N-R," "S-R"). Each model's prediction is marked as either "TRUE" or "FALSE" based on whether the model correctly identified the target label.

The bottom of the slide explains that "CHRIS, Base, N, S, L, R represent Christians, vanilla RoBERTa model, news media, social media, left-leaning, and right-leaning, respectively."

The slide also references two other tables: Table 12, which discusses qualitative analysis of hate speech examples where language models with different political leanings differ, and Table 13, which discusses qualitative analysis of fake news examples where language models with different political leanings differ.</sample>
    <sample id="1113">The image contains two tables, each presenting qualitative analyses of text samples related to hate speech and misinformation, respectively. The tables are structured with columns labeled "Hate?", "N-L", "R-L", "N-R", and "R-R". Each row in the tables corresponds to a different text sample, and the entries under each column indicate whether the language model (LM) with that specific political leaning correctly identified the text as belonging to the respective category.

### Table 12: Qualitative analysis of hate speech examples where LMs with different political leanings beg to differ.
| Hate Speech Text                                                                 | Hate? | N-L | R-L | N-R | R-R |
|----------------------------------------------------------------------------------|-------|-----|-----|-----|-----|
| Same-sex marriage doesn't "confound" orthodox Catholics who refer disparagingly to trans, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pay and God's mercy. | TRUE  | TRUE | TRUE | FALSE | FALSE |
| got kicked out of facebook again for "numb*er-days because I called a muzza alla a pedophile and a pervert no 1 amendment over there the muzzis can call christians anything they want but not the other way around | TRUE  | TRUE | TRUE | FALSE | FALSE |
| Yes. Exactly. Fuck these religioust trash places and burn them to the ground. The Vatican, Israel, everywhere. | TRUE  | FALSE | FALSE | TRUE | TRUE |
| Idiot Didn't Get A Building Permit! Typical White Guy Rule: It's Easier to Beg for Forgiveness, then they play the victim card. | TRUE  | FALSE | FALSE | TRUE | TRUE |
| At 7:19 is why I hate people, women especially look how mad she just got because the dog splashed her. f*** you you stupid b**** either have fun or go kill yourself | TRUE  | TRUE | TRUE | FALSE | FALSE |
| Death to catholicism. Should be legal to shoot them. | TRUE  | FALSE | FALSE | TRUE | TRUE |
| are you the nazi faggot with the feminine boobs | TRUE  | TRUE | TRUE | FALSE | FALSE |
| this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead | TRUE  | TRUE | TRUE | TRUE | TRUE |
| What do you call a white guy surrounded by a thousand black guys? A warden | TRUE  | TRUE | TRUE | FALSE | TRUE |
| United States of Muslim America It's good to know faggots will still be shot | TRUE  | TRUE | TRUE | FALSE | TRUE |
| How do you circumcise a choir boy? Kick the priest in the jaw. | TRUE  | FALSE | FALSE | TRUE | TRUE |
| what do you call an indian taking a shit? brownian motion | TRUE  | TRUE | TRUE | FALSE | FALSE |
| If I saw this bitch in public I'd slam her on the ground and spit in her face too | TRUE  | TRUE | TRUE | FALSE | FALSE |

### Table 13: Qualitative analysis of fake news examples where LMs with different political leanings beg to differ.
| Misinformation Text                                                                 | Fake? | N-L | R-L | N-R | R-R |
|--------------------------------------------------------------------------------------|-------|-----|-----|-----|-----|
| in cities like chicago and bullhead crime in america a larger cities has been rising since trump from rising upon increase in violent cases to make a case on the rise in crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on the rise in crime in america is reaching record levels will vote for trump because they know he will stop the crime in america. the president is making a case on</sample>
    <sample id="1114">The image contains two tables, each labeled with a title and a set of columns indicating different classifications for text samples. Here is the transcription of the content:

---

**Table 12: Qualitative analysis of hate speech examples where LMs with different political leanings beg to differ.**

| Hate Speech Text | Hate? | N-L | R-L | N-R | R-R |
|------------------|-------|-----|-----|-----|-----|
| Same-sex marriage doesn't "confound" orthodox Catholics who refer to disparagingly as trads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pity and God's mercy. | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| got kicked out of facebook again for "numb*er-days because I called a muzza alla a pedophile and a pervert no 1st amendment over there the muzzis can call christians anything they want but not the other way around | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| Yes. Exactly. Fuck these religitated trash places and burn them to the ground. The Vatican, Israel, everywhere. | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| Idiot Didn't Get A Building Permit? It's Easier to Beg for Forgiveness, Then they play the victim card! | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| At 7:19 is why I hate people, women especially look how mad she just got because the dog splashed her. f*** you you stupid b**** either have fun or go kill yourself | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| Death to catholicism. Should be legal to shoot them. | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| are you the nazi faggot with the feminine boobs | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead | TRUE | TRUE ✓ | TRUE ✓ | TRUE ✓ | TRUE ✓ |
| What do you call a white guy surrounded by a thousand black guys? A warden | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| United States of Muslim America It's good to know faggots will still be shot | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| How do you circumcise a choir boy? Kick the priest in the jaw. | TRUE | FALSE ✗ | FALSE ✗ | TRUE ✓ | TRUE ✓ |
| what do you call an indian taking a shit? brownian motion | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| If I saw this bitch in public I'd slam her on the ground and spit in her face too | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |

---

**Table 13: Qualitative analysis of fake news examples where LMs with different political leanings beg to differ.**

| Misinformation Text | Fake? | N-L | R-L | N-R | R-R |
|---------------------|-------|-----|-----|-----|-----|
| in cities like chicago and bulletrime crime in america a largest cities has been rising since trump from sitting upon increases in indicted cases to make a case on the crime rate in the united states. the crime rate in the united states is reaching record levels will vote for trump because they know he will stop the crime rate. | TRUE | TRUE ✓ | TRUE ✓ | FALSE ✗ | FALSE ✗ |
| obama on whether individual standard is a tax is absolutely not file 2013 the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20 2009 obama the supreme court build in washington dc up 20</sample>
    <sample id="1115">The image contains two tables, each presenting qualitative analyses of text samples categorized as either "Hate Speech Text" or "Misinformation Text." The tables are labeled as Table 12 and Table 13, respectively.

### Table 12: Qualitative analysis of hate speech examples where LMs with different political leanings beg to differ.
| Hate Speech Text | Hate? | N-L | R-L | N-R | R-R |
|------------------|-------|-----|-----|-----|------|
| Same-sex marriage doesn't "confound" orthodox Catholics who refer to disparagingly as trads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pity and God's mercy. | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| got kicked out of facebook again for "numb*er-days because I called a mazilla alla a pedophile and a pervert no 1st amendment over there the muzzis can call christians anything they want but not the other way around | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| Yes. Exactly. Fuck these religitated trash places and burn them to the ground. The Vatican, Israel, everywhere. | TRUE | FALSE ✖️ | FALSE ✖️ | TRUE ✔️ | TRUE ✔️ |
| Idiot Didn't Get A Building Permit! Typical White Guy Rule: It's Easier to Beg for Forgiveness, Then they play the victim card. | TRUE | FALSE ✖️ | FALSE ✖️ | TRUE ✔️ | TRUE ✔️ |
| At 7:19 is why I hate people, women especially look how mad she just got because the dog splashed her. f*** you you stupid b**** either have fun or go kill yourself | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| Death to catholicism. Should be legal to shoot them. | TRUE | FALSE ✖️ | FALSE ✖️ | TRUE ✔️ | TRUE ✔️ |
| are you the nazi faggot with the feminine boobs | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead | TRUE | TRUE ✔️ | TRUE ✔️ | TRUE ✔️ | TRUE ✔️ |
| What do you call a white guy surrounded by a thousand black guys? A warden | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| United States of Muslim America It's good to know faggots will still be shot | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| How do you circumcise a choir boy? Kick the priest in the jaw. | TRUE | FALSE ✖️ | FALSE ✖️ | TRUE ✔️ | TRUE ✔️ |
| what do you call an indian taking a shit? brownian motion | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |
| If I saw this bitch in public I'd slam her on the ground and spit in her face too | TRUE | TRUE ✔️ | TRUE ✔️ | FALSE ✖️ | FALSE ✖️ |

### Table 13: Qualitative analysis of fake news examples where LMs with different political leanings beg to differ.
| Misinformation Text | Fake? | N-L | R-L | N-R | R-R |
|---------------------|-------|-----|-----|-----|------|
| in cities like chicago and bulletrime crime in america a largest cities has been increasing for years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years and years</sample>
    <sample id="1116">**Hate Speech Text**
- Same-sex marriage doesn't "confound" orthodox Catholics who refer to disparagingly as trads, quite simply because it is an impossibility, it doesn't exist. Marriage can only be between a man and a woman so those who think otherwise are deluding themselves and deserving of our pity and God's mercy.
- got kicked out of facebook again for "numb*er-days because I called a mazilla alla a pedophile and a pervert no 1 amendment over there the muzzis can call christians anything they want but not the other way around"
- Yes. Exactly. Fuck these religitated trash places and burn them to the ground. The Vatican, Israel, everywhere.
- Idiot Didn't Get A Building Permit? Typical White Guy Rule: It's Easier to Beg for Forgiveness, then they play the victim card.
- At 7:19 is why I hate people, women especially look how mad she just got because the dog splashed her. F*** you you stupid b**** either have fun or go kill yourself
- Death to catholicism. Should be legal to shoot them.
- are you the nazi faggot with the feminine boobs
- this obnoxious nigger bitch on tucker show deserves a noose put around her neck and hanged until she dead
- What do you call a white guy surrounded by a thousand black guys? A warden
- United States of Muslim America It's good to know faggots will still be shot
- How do you circumcise a choir boy? Kick the priest in the jaw.
- what do you call an indian taking a shit? brownian motion
- If I saw this bitch in public I'd slam her on the ground and spit in her face too

**Misinformation Text**
- In cities like Chicago and Baltimore crime in america a largest cities has been on the rise for decades. President trump from sitting upon increases in violent cases to make a case on the increase in crime. The president is making a false claim that crime is reaching record levels will vote for trump because they know he will stop the crime. Trump made a false claim about the number of illegal immigrants entering the country through a migrant speech during which he declared the crime and the gangs.
- have the resources of state government for whatever reason refuses to act on the issue of lead in drinking water. The federal government acts and sanctions what is absolutely inexcusable in me opinion. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal government is in prying in illegal vent for clean water first and foremost. The federal</sample>
    <sample id="1117">Discussion

Between Scylla and Charybdis

To "sanitize" or not to "sanitize", that is the question

- Pretraining data
- Language models
- Downstream tasks</sample>
    <sample id="1118">Discussion

Between Scylla and Charybdis

To "sanitize" or not to "sanitize", that is the question

- Pretraining data
- Language models
- Downstream tasks</sample>
    <sample id="1119">Discussion

Between Scylla and Charybdis

To “sanitize” or not to “sanitize”, that is the question

Pretraining data → Language models → Downstream tasks

Thank you!

Shangbin Feng
Chan Young Park
Yuhan Liu
Yulia Tsvetkov

PAUL G. ALLEN SCHOOL
UW NLP
Carnegie Mellon University
Language Technologies Institute</sample>
    <sample id="1120">The image is a slide from a presentation with the title "Thank you!" at the top. Below the title, there is a flowchart with three main boxes connected by arrows:

1. **Pretraining data**
2. **Language models**
3. **Downstream tasks**

Underneath these boxes, there are four individuals' names and photos, each associated with different institutions:

- **Shangbin Feng** (Paul G. Allen School, University of Washington)
- **Chan Young Park** (UW NLP)
- **Yuhan Liu** (Carnegie Mellon University Language Technologies Institute)
- **Yulia Tsvetkov** (University of Washington)

At the bottom of the slide, there are logos for the institutions mentioned: Paul G. Allen School, University of Washington NLP, Carnegie Mellon University Language Technologies Institute, and the University of Washington.</sample>
    <sample id="1121">The new method is called "Permuting with 'jumps'".</sample>
    <sample id="1122">The author described the "marked words" method as finding words that distinguish personas of marked groups from unmarked groups.</sample>
    <sample id="1123">The affiliations of the authors of the paper are:

- Paul G. Allen School, University of Washington (UW)
- UW NLP
- Carnegie Mellon University Language Technologies Institute</sample>
    <sample id="1124">Bouquet/Stanford</sample>
    <sample id="1125">The name of the speaker is not explicitly mentioned in the image provided. The image shows the title of the presentation and the authors' names, but it does not include the name of the speaker.</sample>
    <sample id="1126">There are four authors involved in the paper.</sample>
    <sample id="1127">The datasets that can be used to test syntactic phenomena are BLiMP, SyntaxGym, and CrowS.</sample>
    <sample id="1128">The image is a slide from a presentation titled "When Does Translation Require Context? A Data-driven, Multilingual Exploration." The slide lists the names of the contributors: Patrick Fernandes*, Kayo Yin*, Emmy Liu, André F. T. Martins, and Graham Neubig. Below the title and contributors' names, there are logos for Carnegie Mellon University Language Technologies Institute, TÉCNICO LISBOA, BAIR (Berkeley Artificial Intelligence Research), and Unbabel. At the bottom right corner, there is a note indicating that all contributions are equal.</sample>
    <sample id="1129">Translation depends on context

We'll have to get rid of that mole.

Things could start to get dangerous if the ministers find out.
We'll have to get rid of that mole.</sample>
    <sample id="1130">Translation depends on context

Things could start to get dangerous if the ministers find out.
We'll have to get rid of that mole.

Could it be anything serious, Doctor?
We'll have to get rid of that mole.</sample>
    <sample id="1131">Translation depends on context

Could it be anything serious, Doctor?
We'll have to get rid of that mole.</sample>
    <sample id="1132">Evaluating context-dependent translation is hard

- Only a small portion of words depend on
  context

Corpus-level metrics</sample>
    <sample id="1133">Evaluating context-dependent translation is hard

- Only a small portion of words depend on
  context
  - Corpus-level metrics
- Existing methods support limited discourse
  phenomena and languages</sample>
    <sample id="1134">RQ1: When does translation require context?
RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1135">RQ1: When does translation require context?
- Word-level context usage

RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1136">Conditional Cross-Mutual Information (CXMI)

- CXMI: measure how much context MT models use given a corpus

Uncertainty over translations given the source
HqMTA(Y|X)
Uncertainty over translations given the source AND context
HqMTC(Y|X, C)
CXMI(C → Y|X)</sample>
    <sample id="1137">Conditional Cross-Mutual Information (CXMI)

- CXMI: measure how much context MT models use given a corpus

Uncertainty over translations given the source
HqMTA(Y|X)
Uncertainty over translations given the source AND context
HqMTC(Y|X, C)
CXMI(C → Y|X)</sample>
    <sample id="1138">Pointwise (P-)CXMI

- We introduce P-CXMI to measure context usage to translate a specific

  Senten P-CXMI(y, x, C) = - log qMTA(y|x) / qMTC(y|x, C)

  Word P-CXMI(i, y, x, C) = - log qMTA(yi|yt&lt;i, x) / qMTC(yi|yt&lt;i, x, C)

- High P-CXMI words -&gt; requires context to translate</sample>
    <sample id="1139">RQ1: When does translation require context?
- Word-level context usage
- Thematic analysis

RQ2: How well do models handle context-dependent translations?</sample>
    <sample id="1140">The thematic analysis of high P-CXMI words is presented in this slide. It includes two research questions (RQs):

1. When does translation require context?
   - Word-level context usage
   - Thematic analysis

2. How well do models handle context-dependent translations?

The slide also features the TED logo with the tagline "IDEAS WORTH SPREADING" and lists various languages supported by TED, including English, Arabic, German, Spanish, French, Hebrew, Italian, Japanese, Korean, Dutch, Portuguese, Romanian, Russian, Turkish, and Chinese.</sample>
    <sample id="1141">The thematic analysis of high P-CXMI words focuses on Part-of-Speech (POS) tags.</sample>
    <sample id="1142">The thematic analysis of high P-CXMI words focuses on POS tags, specifically pronouns in English and Arabic (En-Ar). The chart shows the P-CXMI values for different pronoun forms: PRON.3.Sing, PRON.3.Dual, and PRON.3.Plur. The highest value is for PRON.3.Dual, indicating that dual pronouns have the highest P-CXMI among these forms.</sample>
    <sample id="1143">The thematic analysis of high P-CXMI words focuses on two main categories: POS tags and vocabulary items.

1. POS tags:
   - Pronouns
   - Verb form

2. Vocabulary items</sample>
    <sample id="1144">The thematic analysis of high P-CXMI words includes:

1. POS tags
2. Vocabulary items

- Pronouns
- Verb form
- Lexical cohesion

English text:
"Avelile's mother was still asleep. Avelile went to school."

Chinese translation:
"阿维利尔的母亲还在睡觉。阿维利尔去上学了。"</sample>
    <sample id="1145">The thematic analysis of high P-CXMI words includes:

1. POS tags
2. Vocabulary items

- Pronouns
- Verb form
- Lexical cohesion
- Formality

English sentences:
"Avelile's mother was still asleep. Avelile went to school."

Chinese translation:
"阿维利尔的母亲还在睡觉。阿维利尔去上学了。"</sample>
    <sample id="1146">The thematic analysis of high P-CXMI words includes:

1. POS tags
2. Vocabulary items
3. Individual tokens

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis</sample>
    <sample id="1147">The slide is titled "Thematic analysis of high P-CXMI words." It presents two research questions (RQs):

1. **RQ1: When does translation require context?**
   - Word-level context usage
   - Thematic analysis

2. **RQ2: How well do models handle context-dependent translations?**
   - Multilingual Discourse-Aware (MuDA) benchmark

Additionally, there is an example provided:
- **English:** "She knows where we're going."
  - "I don't."
- **German:** "Sie weiß, wohin wir gehen."
  - "Ich weiß es nicht."

The slide also lists some thematic analysis items on the right side:
- Pronouns
- Verb form
- Lexical cohesion
- Ellipsis
- Formality</sample>
    <sample id="1148">The image contains a slide with text and a small circular profile picture in the top right corner. The main title on the slide is "Multilingual Discourse-Aware (MuDA) tagger." Below the title, there is a list of items underlined:

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis

The slide appears to be part of a presentation discussing the Multilingual Discourse-Aware tagger and its focus areas.</sample>
    <sample id="1149">The image is a slide from a presentation titled "Multilingual Discourse-Aware (MuDA) tagger." The slide lists five features of the MuDA tagger: Pronouns, Verb form, Lexical cohesion, Formality, and Ellipsis. On the right side of the slide, there is a stacked bar chart showing counts for these features across different languages. The languages listed on the x-axis include fr, ja, nl, ru, de, pt_br, ro, es, it, he, zh_cn, ar, tr, and ko. The y-axis represents the counts, ranging from 0 to 6000. Each language has bars representing the counts for each feature, with the legend indicating which color corresponds to which feature: pronouns in blue, formality in orange, verb form in green, lexical in red, and ellipsis in purple.</sample>
    <sample id="1150">Multilingual Discourse-Aware (MuDA) tagger

- Pronouns
- Verb form
- Lexical cohesion
- Formality
- Ellipsis

MuDA benchmark

[Image of a document icon]

[Image of a robot icon]

[Image of a document icon with "MuDA tagger" text]

[Image of a document icon with "BLEU COMET F-measure" text]</sample>
    <sample id="1151">The image contains two slides with text and graphics related to a presentation about translation and context.

**Slide 1:**
- **Title:** MuDA benchmark
- **Content:**
  - A diagram showing a flow from "MuDA tagger" to "BLEU COMET F-measure" with a robot icon.
  - The robot icon is on the right side of the slide, and there is a circular profile picture of a person in the top right corner.

**Slide 2:**
- **Content:**
  - **RQ1: When does translation require context?**
    - Word-level context usage
    - Thematic analysis
  - **RQ2: How well do models handle context-dependent translations?**
    - Multilingual Discourse-Aware (MuDA) benchmark
    - Model evaluation

The text on the second slide is presented in bullet points under two main questions (RQ1 and RQ2), discussing when translation requires context and how well models handle context-dependent translations.</sample>
    <sample id="1152">The slide is titled "Corpus-level metrics" and discusses two research questions (RQs):

1. **RQ1: When does translation require context?**
   - Word-level context usage
   - Thematic analysis

2. **RQ2: How well do models handle context-dependent translations?**
   - Multilingual Discourse-Aware (MuDA) benchmark
   - Model evaluation

The slide also includes an illustration of a robot with a speech bubble that says "CONTEXT" crossed out, and the word "BLEU" below it. This suggests a discussion about the limitations or challenges of using BLEU as a metric for evaluating context-dependent translations.</sample>
    <sample id="1153">The image contains a slide titled "Corpus-level metrics" with three robot icons, each labeled with different metrics:

1. The first robot icon is labeled "BLEU" and has a crossed-out "CONTEXT" sign above it.
2. The second robot icon is labeled "COMET" and has a "CONTEXT" sign above it.
3. The third robot icon is labeled "F-measure" and also has a "CONTEXT" sign above it.

The slide appears to be discussing the importance of context in corpus-level metrics, as indicated by the presence of the "CONTEXT" sign on two out of the three robots.</sample>
    <sample id="1154">Corpus-level metrics

- BLEU
- COMET
- F-measure

Unclear which system is best for document-level MT with corpus-level metrics</sample>
    <sample id="1155">MuDA benchmark results
- Context-aware models perform significantly better on some phenomena</sample>
    <sample id="1156">MuDA benchmark results

- Context-aware models perform significantly better on some phenomena
  - √: Formality, lexical cohesion
  - ❌ Ellipsis, pronouns, verb form</sample>
    <sample id="1157">MuDA benchmark results

- Context-aware models perform significantly better on some phenomena
  - ✓: Formality, lexical cohesion
  - ✗: Ellipsis, pronouns, verb form

- DeepL outperforms Google on most phenomena and language pairs*</sample>
    <sample id="1158">MuDA benchmark results

- Context-aware models perform significantly better on some phenomena
  - √: Formality, lexical cohesion
  - ❌ Ellipsis, pronouns, verb form

- DeepL outperforms Google on most phenomena and language pairs*

Summary

- Identify discourse phenomena systematically without prior linguistic knowledge
- Dataset-agnostic benchmark for document-level MT

* as of April 2021</sample>
    <sample id="1159">Summary

- Identify discourse phenomena systematically without prior linguistic knowledge
- Dataset-agnostic benchmark for document-level MT</sample>
    <sample id="1160">Summary

- Identify discourse phenomena systematically without prior linguistic knowledge
- Dataset-agnostic benchmark for document-level MT</sample>
    <sample id="1161">The abbreviations of the five methods for the first research question are FT_w, BOND, COSINE, MLC, and L2R.</sample>
    <sample id="1162">The model is evaluated on 11 tasks.</sample>
    <sample id="1163">DEPLAIN: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich Heine University Düsseldorf, Germany

ACL 2023</sample>
    <sample id="1164">The text in the image reads:

---

**DEPLAIN: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification**

Regina Stodden, Omar Momen, Laura Kallmeyer

Heinrich Heine University Düsseldorf, Germany

ACL 2023

---

**1. Text Simplification**
What, why and How?

---</sample>
    <sample id="1165">The image is a slide from a presentation titled "Text Simplification Example." It shows an example of text simplification in German, with the original and simplified versions of a sentence provided.

**Original:**
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

**Plain Language:**
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."

The slide also highlights different text simplification techniques used:
- **Substitution:** The word "dafür" (for this) is replaced with "zum Beispiel" (for example).
- **Clause Deletion:** The clause "dass zum Beispiel höhere Löhne gezahlt werden" is deleted.
- **Reordering:** The order of the remaining parts is rearranged.
- **Word Deletion:** The word "oder" (or) is removed.
- **Insertion:** The phrase "oder mehr Urlaub" (or more vacation) is added to the simplified version.</sample>
    <sample id="1166">The image is a slide titled "Text Simplification Example." It shows an example of text simplification in German, with the original and simplified versions provided.

**Original:**
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

**Plain Language:**
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."

The slide also highlights different text simplification techniques:
- **Substitution:** Used to replace "dafür ein" with "zum Beispiel."
- **Clause Deletion:** Removed the subordinate clause "dass zum Beispiel höhere Löhne gezahlt werden."
- **Reordering:** Changed the word order to make the sentence more straightforward.
- **Word Deletion:** Removed "oder mehr Urlaub" from the original sentence.
- **Insertion:** Added "oder mehr Urlaub" to the simplified version.

The slide also includes a small video feed in the top right corner showing a person speaking.</sample>
    <sample id="1167">The image is a slide from a presentation titled "Text Simplification Example." It shows an example of text simplification in German, with the original and simplified versions of a sentence provided.

**Original:**
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

**Plain Language:**
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."

The slide also highlights different text simplification techniques used:
- **Substitution:** The word "dafür" (for this) is replaced with "zum Beispiel" (for example).
- **Clause Deletion:** The clause "dass zum Beispiel höhere Löhne gezahlt werden" is deleted.
- **Reordering:** The order of the words is changed to make the sentence more straightforward.
- **Word Deletion:** The word "oder" (or) is removed.
- **Insertion:** The phrase "oder mehr Urlaub" (or more vacation) is added to the simplified version.

The slide also includes a small video feed in the top right corner showing a person speaking, likely explaining the text simplification process.</sample>
    <sample id="1168">The image is a slide from a presentation titled "Text Simplification Example." It shows an example of text simplification in German, with the original and simplified versions of a sentence provided.

**Original:**
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlt werden."

**Plain Language:**
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein."

The slide also highlights different text simplification techniques used:
- **Substitution:** The word "dafür" (for this) is replaced with "zum Beispiel" (for example).
- **Clause Deletion:** The clause "dass zum Beispiel höhere Löhne gezahlt werden" is deleted.
- **Reordering:** The order of the words is changed to make the sentence more straightforward.
- **Word Deletion:** The word "oder" (or) is removed.
- **Insertion:** The phrase "oder mehr Urlaub" (or more vacation) is added to the simplified version.

The slide uses arrows to indicate which parts of the original sentence were modified or added during the simplification process.</sample>
    <sample id="1169">The image is a slide from a presentation titled "German Text Simplification Corpora." The slide is divided into two main sections:

1. **Sentence Level**:
   - A bar chart comparing different corpora in terms of their size and alignment.
   - The x-axis lists various corpora names, such as "Klapper," "TextComplexityDE19," "ZEST-data," "APR-LHA-or-a2," "APR-LHA-or-b1," and "Simple-German-Corpus."
   - The y-axis represents the number of sentences.
   - Each corpus is color-coded for different domains: mixed (blue), news (green), accessibility (orange), fiction (red), health (yellow), public auth. (purple), and politics (pink).
   - The chart shows that the Simple-German-Corpus has the largest number of sentences at 13,122.

2. **DE-plain**:
   - A new corpus is highlighted with a bar showing its size as 483 sentences.
   - Another bar labeled "DE-plain-web" shows a smaller size of 756 sentences.

The slide emphasizes the comparison between existing corpora and the newly introduced DE-plain corpus.</sample>
    <sample id="1170">The image is a slide from a presentation titled "German Text Simplification Corpora." The slide is divided into two main sections: a bar chart and a stacked bar chart.

### Bar Chart:
- **Title:** Sentence Level
- **X-axis:** Different corpora (e.g., Klapfer, TextComplexityDE19, ZEST-data, APB-LHA-or-a2, APB-LHA-or-b1, Simple-German-Corpus)
- **Y-axis:** Number of sentences
- **Legend:** 
  - Blue: Mixed
  - Green: News
  - Orange: Accessibility
  - Red: Fiction
  - Purple: Bible
  - Pink: Public Auth.
  - Yellow: Politics
- **Alignment:** 
  - Manual
  - Automatic

### Stacked Bar Chart:
- **Title:** DEplain-APA vs. DEplain-web
- **X-axis:** DEplain-APA and DEplain-web
- **Y-axis:** Number of sentences
- **Legend:** 
  - Blue: Mixed
  - Green: News
  - Orange: Accessibility
  - Red: Fiction
  - Purple: Bible
  - Pink: Public Auth.
  - Yellow: Politics
- **Numbers on the bars:**
  - DEplain-APA: 483 (Mixed), 756 (News), 3450 (Accessibility), 640 (Fiction), 562 (Bible), 175 (Public Auth.), 629 (Politics)
  - DEplain-web: 13122 (Total)

The slide provides a comparison of sentence-level data across different corpora and between two specific corpora (DEplain-APA and DEplain-web).</sample>
    <sample id="1171">The image is a slide from a presentation titled "German Text Simplification Corpora." The slide is divided into two main sections: a bar chart and a stacked bar chart.

### Bar Chart:
- **Title:** Sentence Level
- **X-axis:** Different corpora (e.g., Klapfer, TextComplexityDE19, ZEST-data, APB-LHA-or-a2, APB-LHA-or-b1, Simple-German-Corpus)
- **Y-axis:** Number of sentences
- **Legend:** 
  - Blue: Mixed
  - Green: News
  - Orange: Accessibility
  - Red: Fiction
  - Purple: Public Auth.
  - Pink: Politics
- **Data Points:**
  - Klapfer: 2000 sentences in mixed domain
  - TextComplexityDE19: 250 sentences in accessibility domain
  - ZEST-data: 1198 sentences in news domain
  - APB-LHA-or-a2: 9456 sentences in news domain
  - APB-LHA-or-b1: 10268 sentences in news domain
  - Simple-German-Corpus: 5942 sentences in mixed domain

### Stacked Bar Chart:
- **Title:** DEplain-APA vs. DEplain-web
- **X-axis:** DEplain-APA and DEplain-web
- **Y-axis:** Number of sentences
- **Legend:** 
  - Blue: Mixed
  - Green: News
  - Orange: Accessibility
  - Red: Fiction
  - Purple: Public Auth.
  - Pink: Politics
- **Data Points:**
  - DEplain-APA: 13122 sentences in total
    - Mixed: 483 sentences
    - News: 756 sentences
    - Accessibility: 3450 sentences
    - Fiction: 423 sentences
    - Public Auth.: 640 sentences
    - Politics: 592 sentences
  - DEplain-web: 13122 sentences in total
    - Mixed: 483 sentences
    - News: 756 sentences
    - Accessibility: 3450 sentences
    - Fiction: 423 sentences
    - Public Auth.: 640 sentences
    - Politics: 592 sentences

The slide provides a comparison of sentence-level data across different corpora and between two specific corpora (DEplain-APA and DEplain-web), categorized by various domains.</sample>
    <sample id="1172">The image is a slide from a presentation titled "German Text Simplification Corpora." The slide is divided into two main sections: a bar chart and a stacked bar chart.

### Bar Chart:
- **Title:** Sentence Level
- **X-axis:** Different corpora (e.g., Klapfer, TextComplexityDE19, ZEST-data, APB-LHA-or-a2, APB-LHA-or-b1, Simple-German-Corpus)
- **Y-axis:** Number of sentences
- **Legend:** 
  - Blue: Mixed
  - Green: News
  - Red: Accessibility
  - Purple: Wikipedia
  - Orange: Fiction
  - Yellow: Health
  - Pink: L2
  - Brown: Public Auth.
  - Magenta: Politics

### Stacked Bar Chart:
- **Title:** DEplain-APA vs. DEplain-web
- **X-axis:** Corpora (DEplain-APA, DEplain-web)
- **Y-axis:** Number of sentences
- **Legend:** 
  - Blue: Mixed
  - Green: News
  - Red: Accessibility
  - Purple: Wikipedia
  - Orange: Fiction
  - Yellow: Health
  - Pink: L2
  - Brown: Public Auth.
  - Magenta: Politics

### Data:
- **Klapfer (Klapfer et al. 2013):** 2000 sentences
- **TextComplexityDE19 (Nieden et al. 2019):** 250 sentences
- **ZEST-data (Millison et al. 2020):** 1198 sentences
- **APB-LHA-or-a2 (Springer et al. 2021):** 9456 sentences
- **APB-LHA-or-b1 (Springer et al. 2021):** 10268 sentences
- **Simple-German-Corpus (Robotek et al. 2020):** 5942 sentences
- **DEplain-APA:** 13122 sentences
- **DEplain-web:** 756 sentences

The slide appears to be discussing the distribution of sentences across different corpora in terms of their domains and alignment methods (manual or automatic).</sample>
    <sample id="1173">The image is a slide from a presentation titled "German Text Simplification Corpora." The slide is divided into two main sections:

1. **Sentence Level**:
   - A bar chart showing the number of sentences in various corpora.
   - The x-axis lists different corpora names, such as "Klapper," "TextComplexityDE19," "ZEIST-data," "APR-LHA-or-a2," "APR-LHA-or-b1," and "Simple-German-Corpus."
   - The y-axis represents the number of sentences, ranging from 0 to 14,000.
   - Each corpus has a corresponding color-coded bar indicating the number of sentences.

2. **Alignment**:
   - A legend explains the alignment types: manual (represented by a person icon) and automatic (represented by a robot icon).
   - The legend also categorizes domains such as mixed, news, accessibility, L2, fiction, public auth., and politics.

3. **Additional Information**:
   - On the right side, there are two stacked bar charts labeled "DEplain-APA" and "DEplain-web."
   - These charts show the distribution of sentences across different categories (e.g., 483, 756, etc.).

The slide provides a detailed comparison of German text simplification corpora in terms of sentence count and alignment type.</sample>
    <sample id="1174">The image is a slide from a presentation titled "German Text Simplification Corpora." The slide is divided into two main sections: a bar chart and a stacked bar chart.

### Bar Chart:
- **Title:** Sentence Level
- **Y-Axis:** Number of sentences (ranging from 0 to 14,000)
- **X-Axis:** Different corpora names with corresponding years and references.
  - Klapfer (Klamer et al., 2013): 2,000 sentences
  - TextComplexityDE19 (Nieder et al., 2019): 250 sentences
  - ZEST-data (Mullinson et al., 2020): 1,198 sentences
  - APPLHA-or-a2 (Springer et al., 2021): 9,456 sentences
  - APPLHA-or-b1 (Springer et al., 2021): 10,268 sentences
  - Simple-German-Corpus (Robotek et al., 2025): 5,942 sentences

### Stacked Bar Chart:
- **Title:** DEplain-APA and DEplain-web
- **Y-Axis:** Number of sentences (ranging from 0 to 14,000)
- **X-Axis:** Different domains and alignments.
  - **Domains:**
    - Mixed
    - News
    - Accessibility
    - L2
    - Fiction
    - Bible
    - Public Auth.
    - Politics
  - **Alignments:**
    - Manual
    - Automatic
- **Data Points:**
  - DEplain-APA: 13,122 sentences
    - Manual: 483 sentences
    - Automatic: 12,639 sentences
  - DEplain-web: 756 sentences
    - Manual: 3,450 sentences
    - Automatic: 3,696 sentences

The slide provides a comparison of different German text simplification corpora in terms of their size and alignment methods.</sample>
    <sample id="1175">The image contains two bar charts related to simplification in text.

**Top Chart: Types of Simplification**
- The chart is titled "Types of Simplification."
- It shows three categories of simplification: Simplicity, LexSimp, and StructSimp.
- The x-axis represents different text types: news (n = 46), bible (n = 155), L2 (n = 157), and fiction (n = 72).
- The y-axis represents the frequency or some metric related to the type of simplification.
- The bars for each category show the distribution across the different text types.

**Bottom Chart: Simplification Transformations**
- The chart is titled "Simplification Transformations."
- It compares two methods: DEplain-apa and DEplain-web.
- The x-axis lists five types of transformations: reordering, rephrasing, lexical substitution, word addition, and word deletion.
- The y-axis represents the percentage of each transformation.
- The bars show the percentage of each transformation for both methods.

The overall context suggests an analysis of how different text types and methods of simplification transform text.</sample>
    <sample id="1176">The image contains two bar charts related to text simplification.

**Top Chart: Types of Simplification**
- The chart is titled "Types of Simplification."
- It shows three categories of simplification: Simplicity, LexSimp, and StructSimp.
- The x-axis represents different text types: news (n = 46), bible (n = 155), L2 (n = 157), and fiction (n = 72).
- The y-axis represents the frequency or some metric related to the type of simplification.
- The bars for each category (Simplicity, LexSimp, StructSimp) are color-coded: blue, red, and yellow respectively.

**Bottom Chart: Simplification Transformations**
- The chart is titled "Simplification Transformations."
- It compares two methods: DEplain-apa and DEplain-web.
- The x-axis lists five types of transformations: reordering, rephrasing, lexical substitution, word addition, and word deletion.
- The y-axis represents the percentage of each transformation.
- The bars for DEplain-apa are in green, and those for DEplain-web are in blue.
- The chart indicates that lexical substitution is the most common transformation for both methods, followed by reordering and rephrasing. Word deletion and word addition are less frequent.</sample>
    <sample id="1177">The image contains two bar charts related to simplification in text.

**Top Chart: Types of Simplification**
- The chart is titled "Types of Simplification."
- It shows three categories of simplification: Simplicity, LexSimp, and StructSimp.
- The x-axis represents different text types: news, bible, L2 (likely referring to Level 2 learners), and fiction.
- The y-axis represents the frequency or some metric related to the type of simplification.
- Each category has bars for each text type, with labels indicating the number of samples (e.g., n = 46 for news).

**Bottom Chart: Simplification Transformations**
- The chart is titled "Simplification Transformations."
- It compares two systems: DEplain-apa and DEplain-web.
- The x-axis lists five types of transformations: reordering, rephrasing, lexical substitution, word addition, and word deletion.
- The y-axis represents the percentage of each transformation.
- The bars show the percentage of each transformation for both systems.

The overall context suggests a comparison of different methods of text simplification across various genres and systems.</sample>
    <sample id="1178">The image contains two bar charts related to text simplification.

**Types of Simplification:**
- The chart is divided into four categories: news, bible, L2 (likely referring to Level 2), and fiction.
- Each category has three bars representing different types of simplification:
  - Simplicity (blue)
  - LexSimp (red)
  - StructSimp (yellow)
- The y-axis represents the value of the simplification type.
- The x-axis lists the categories: news, bible, L2, and fiction.
- The number of samples for each category is provided at the bottom of each bar: n = 46 for news, n = 155 for bible, n = 157 for L2, and n = 72 for fiction.

**Simplification Transformations:**
- This chart compares two methods: DEplain-apa (green) and DEplain-web (blue).
- The x-axis lists the types of transformations: reordering, rephrasing, lexical substitution, word addition, and word deletion.
- The y-axis represents the percentage of each transformation.
- The percentages for each method are as follows:
  - Reordering: DEplain-apa ≈ 50%, DEplain-web ≈ 10%
  - Rephrasing: DEplain-apa ≈ 10%, DEplain-web ≈ 30%
  - Lexical substitution: DEplain-apa ≈ 80%, DEplain-web ≈ 90%
  - Word addition: DEplain-apa ≈ 40%, DEplain-web ≈ 10%
  - Word deletion: DEplain-apa ≈ 30%, DEplain-web ≈ 20%</sample>
    <sample id="1179">The image contains two bar charts related to simplification in text.

**Top Chart: Types of Simplification**
- The chart is divided into four categories: news, bible, L2 (likely referring to Level 2), and fiction.
- Each category has three bars representing different types of simplification:
  - Simplicity (blue)
  - LexSimp (red)
  - StructSimp (yellow)
- The y-axis represents the value of each type of simplification.
- The x-axis lists the categories with their respective sample sizes:
  - News: n = 46
  - Bible: n = 155
  - L2: n = 157
  - Fiction: n = 72

**Bottom Chart: Simplification Transformations**
- This chart compares two methods: DEplain-apa and DEplain-web.
- The y-axis shows the percentage of transformations.
- The x-axis lists the types of transformations:
  - Reordering
  - Rephrasing
  - Lexical substitution
  - Word addition
  - Word deletion
- The percentages for each transformation type are shown as bars, with DEplain-apa in green and DEplain-web in blue.</sample>
    <sample id="1180">3. Use-cases
Automatic alignment and simplification

The slide discusses various methods for automatic alignment and simplification, presenting results of different alignment methods with 1:1 (upper part) and n:m capabilities (lower part). The methods listed include:

- LHA: Hierarchical alignment using sentence embeddings similarity.
- Sent-LaBSE: Similar embeddings of Language-agnostic BERT transformer.
- Sent-RoBERTa: Similar embeddings of Cross English &amp; German RoBERTa.
- CATS-C3G: Different similarity measures e.g. n-grams (C3G)/word vectors.
- VecAlign: Multilingual aligner based on multilingual sentence embeddings.
- BERTalign: Allows sentence-transformer methods produce n:m alignments.
- MASSalign: A vicinity-driven approach with a TF-IDF similarity matrix.

The table provides precision (P), recall (R), F1 score, and F0.5 score for each method under both 1:1 and n:m conditions.</sample>
    <sample id="1181">The image is a slide from a presentation titled "Automatic Alignment Evaluation." It displays the results of various alignment methods with 1:1 (upper part) and n:m capabilities (lower part). The table includes the following columns:

- **Name**: The name of the alignment method.
- **Description**: A brief description of the method.
- **1:1** (Precision, Recall, F1, F0.5): Metrics for 1:1 alignment.
- **n:m** (Precision, Recall, F1, F0.5): Metrics for n:m alignment.

The methods listed are:
1. LHA - Hierarchical alignment using sentence embeddings similarity
2. Sent-LaBSE - Similar embeddings of Language-agnostic BERT transformer
3. Sent-RoBERTa - Similar embeddings of Cross English &amp; German RoBERTa
4. CATS-C3G - Different similarity measures e.g. n-grams (C3G)/word vectors
5. VecAlign - Multilingual aligner based on multilingual sentence embeddings
6. BERTalign - Allows sentence-transformer methods produce n:m alignments
7. MASSalign - A vicinity-driven approach with a TF-IDF similarity matrix

The metrics for each method under both 1:1 and n:m alignments are provided in the table.</sample>
    <sample id="1182">The image is a slide from a presentation titled "Automatic Alignment Evaluation." The slide contains a table with the results of various alignment methods, categorized into two parts: 1:1 (upper part) and n:m capabilities (lower part). The table includes the following columns:

- **Name**: The name of the alignment method.
- **Description**: A brief description of the method.
- **1:1** (P, R, F1, F0.5): Precision, Recall, F1 score, and F0.5 score for the 1:1 alignment.
- **n:m** (P, R, F1, F0.5): Precision, Recall, F1 score, and F0.5 score for the n:m alignment.

The methods listed in the table are:

1. **LHA**: Hierarchical alignment using sentence embeddings similarity.
2. **Sent-LaBSE**: Similar embeddings of Language-agnostic BERT transformer.
3. **Sent-RoBERTa**: Similar embeddings of Cross English &amp; German RoBERTa.
4. **CATS-C3G**: Different similarity measures e.g. n-grams (C3G)/word vectors.
5. **VecAlign**: Multilingual aligner based on multilingual sentence embeddings.
6. **BERTalign**: Allows sentence-transformer methods produce n:m alignments.
7. **MASSalign**: A vicinity-driven approach with a TF-IDF similarity matrix.

The scores for each method under both 1:1 and n:m alignments are provided.</sample>
    <sample id="1183">The image is a screenshot of a presentation slide titled "Automatic Alignment Evaluation." The slide contains a table with the heading "Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)." The table lists various alignment methods along with their descriptions and performance metrics such as Precision (P), Recall (R), F1 score, and F0.5 score for both 1:1 and n:m alignments.

Here is the transcribed content:

---

**Automatic Alignment Evaluation**

**Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)**

| Name | Description | 1:1 | n:m |
|------|-------------|-----|-----|
| LHA  | Hierarchical alignment using sentence embeddings similarity | .94 | - |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer | .961 | - |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa | .960 | - |
| CATS-C3G | Different similarity measures e.g n-grams (C3G)/word vectors | .247 | - |
| VecAlign | Multilingual aligner based on multilingual sentence embeddings | .271 | .260 |
| BERTalign | Allows sentence-transformer methods produce n:m alignments | .743 | .387 |
| MASSalign | A vicinity-driven approach with a TF-IDF similarity matrix | .846 | .819 |

---</sample>
    <sample id="1184">The image is a screenshot of a presentation slide titled "Automatic Alignment Evaluation." The slide contains a table with the heading "Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)." The table lists several alignment methods along with their descriptions and performance metrics (Precision, Recall, F1-score, and F0.5 score).

Here is the transcribed content:

---

**Automatic Alignment Evaluation**

**Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)**

| Name | Description | 1:1 | n:m |
|------|-------------|-----|-----|
| LHA  | Hierarchical alignment using sentence embeddings similarity | .94 | - |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer | .961 | - |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa | .960 | - |
| CATS-C3G | Different similarity measures e.g n-grams (C3G)/word vectors | .247 | - |
| VecAlign | Multilingual aligner based on multilingual sentence embeddings | .271 | .260 |
| BERTalign | Allows sentence-transformer methods produce n:m alignments | .743 | .387 |
| MASSalign | A vicinity-driven approach with a TF-IDF similarity matrix | .846 | .819 |

---

The slide also includes a small video feed in the top right corner showing a person speaking.</sample>
    <sample id="1185">The image is a slide from a presentation titled "Automatic Alignment Evaluation." It displays the results of various alignment methods with 1:1 (upper part) and n:m capabilities (lower part). The table includes the following columns:

- **Name**: Lists the names of the alignment methods.
- **Description**: Provides a brief description of each method.
- **1:1**: Contains precision (P), recall (R), F1 score, and F0.5 score for 1:1 alignments.
- **n:m**: Contains precision (P), recall (R), F1 score, and F0.5 score for n:m alignments.

The methods listed are:
1. LHA - Hierarchical alignment using sentence embeddings similarity
2. Sent-LaBSE - Similar embeddings of Language-agnostic BERT transformer
3. Sent-RoBERTa - Similar embeddings of Cross English &amp; German RoBERTa
4. CATS-C3G - Different similarity measures e.g. n-grams (C3G)/word vectors
5. VecAlign - Multilingual aligner based on multilingual sentence embeddings
6. BERTalign - Allows sentence-transformer methods produce n:m alignments
7. MASSalign - A vicinity-driven approach with a TF-IDF similarity matrix

The scores for each method under both 1:1 and n:m alignments are provided in the respective columns.</sample>
    <sample id="1186">The image is a screenshot from a presentation slide titled "Automatic Alignment Evaluation." The slide contains a table with the heading "Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)." The table lists various alignment methods along with their descriptions and performance metrics such as Precision (P), Recall (R), F1 score, and F0.5 score for both 1:1 and n:m scenarios.

Here is the transcribed content:

---

**Automatic Alignment Evaluation**

**Results of the alignment methods with 1:1 (upper part) and n:m capabilities (lower part)**

| Name | Description | 1:1 | n:m |
|------|-------------|-----|-----|
| LHA  | Hierarchical alignment using sentence embeddings similarity | .94 | - |
| Sent-LaBSE | Similar embeddings of Language-agnostic BERT transformer | .961 | - |
| Sent-RoBERTa | Similar embeddings of Cross English &amp; German RoBERTa | .960 | - |
| CATS-C3G | Different similarity measures e.g n-grams (C3G)/word vectors | .247 | - |
| VecAlign | Multilingual aligner based on multilingual sentence embeddings | .271 | .260 |
| BERTalign | Allows sentence-transformer methods produce n:m alignments | .743 | .387 |
| MASSalign | A vicinity-driven approach with a TF-IDF similarity matrix | .846 | .819 |

---</sample>
    <sample id="1187">The image is a slide from a presentation titled "Automatic Alignment Evaluation." It displays the results of various alignment methods with 1:1 (upper part) and n:m capabilities (lower part). The table includes the following columns:

- **Name**: Lists the names of the alignment methods.
- **Description**: Provides a brief description of each method.
- **1:1**: Contains precision (P), recall (R), F1 score, and F0.5 score for 1:1 alignments.
- **n:m**: Contains precision (P), recall (R), F1 score, and F0.5 score for n:m alignments.

The methods listed are:
1. LHA - Hierarchical alignment using sentence embeddings similarity
2. Sent-LaBSE - Similar embeddings of Language-agnostic BERT transformer
3. Sent-RoBERTa - Similar embeddings of Cross English &amp; German RoBERTa
4. CATS-C3G - Different similarity measures e.g. n-grams (C3G)/word vectors
5. VecAlign - Multilingual aligner based on multilingual sentence embeddings
6. BERTalign - Allows sentence-transformer methods produce n:m alignments
7. MASSalign - A vicinity-driven approach with a TF-IDF similarity matrix

The scores for each method under both 1:1 and n:m alignments are provided in the respective columns.</sample>
    <sample id="1188">The image shows a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level."

### Document Level

#### Results on Document Simplification using finetuned long-mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 387 | 44.56 38.136 0.598 65.4 |
| DEplain-web | 481 | 35.02 12.913 0.475 59.55 |
| DEplain-APA+web | 868 | 42.862 36.449 0.589 65.4 |
| src2Src-baseline | 17,637 | 34.247 0.583 58.85 |

#### DEPLAIN-APA test (n=48)

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 387 | 43.087 21.9 0.377 64.7 |
| DEplain-web | 481 | 49.584 23.282 0.462 63.5 |
| DEplain-APA+web | 868 | 49.745 23.37 0.445 57.95 |
| src2Src-baseline | 12,848 | 23.132 0.432 59.4 |

#### DEPLAIN-WEB test (n=147)

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 10660 | 30.867 15.727 0.413 64.516 |
| DEplain-APA+web | 11941 | 34.828 17.88 0.436 65.249 |
| src2src-baseline | 11,931 | 20.85 0.423 60.825 |

### Sentence Level

#### Results on Sentence Simplification using finetuned mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 10660 | 34.818 28.25 0.639 63.072 |
| DEplain-APA+web | 11941 | 34.904 28.506 0.64 62.669 |
| src2src-baseline | 15,249 | 26.893 0.627 59.23 |

#### DEPLAIN-APA test (n=1231)

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 10660 | 30.867 15.727 0.413 64.516 |
| DEplain-APA+web | 11941 | 34.828 17.88 0.436 65.249 |
| src2src-baseline | 11,931 | 20.85 0.423 60.825 |

#### DEPLAIN-WEB test (n=1846)

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 10660 | 30.867 15.727 0.413 64.516 |
| DEplain-APA+web | 11941 | 34.828 17.88 0.436 65.249 |
| src2src-baseline | 11,931 | 20.85 0.423 60.825 |</sample>
    <sample id="1189">The image shows a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level."

### Document Level

#### Results on Document Simplification using finetuned long-mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4   |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55  |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4   |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85  |

#### DEPLAIN-APA test (n=48)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43.087 | 21.9   | 0.377 | 64.7  |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5  |
| DEplain-APA+web | 868 | 49.745 | 23.37  | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4  |

#### DEPLAIN-WEB test (n=147)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

### Sentence Level

#### Results on Sentence Simplification using finetuned mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34.818 | 28.25  | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64  | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

#### DEPLAIN-APA test (n=1231)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

#### DEPLAIN-WEB test (n=1846)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |</sample>
    <sample id="1190">The image shows a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level."

### Document Level

#### Results on Document Simplification using finetuned long-mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4   |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55  |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4   |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85  |

#### DEPLAIN-APA test (n=48)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43.087 | 21.9   | 0.377 | 64.7  |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5  |
| DEplain-APA+web | 868 | 49.745 | 23.37  | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4  |

#### DEPLAIN-WEB test (n=147)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

### Sentence Level

#### Results on Sentence Simplification using finetuned mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34.818 | 28.25  | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64  | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

#### DEPLAIN-APA test (n=1231)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

#### DEPLAIN-WEB test (n=1846)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |</sample>
    <sample id="1191">The image shows a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level."

### Document Level

**Results on Document Simplification using finetuned long-mBART.**
- \( n \) corresponds to the length of the training data.

#### Table 1: DEPLAIN-APA test (n=48)
| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 387 | 44.56 38.136 0.598 65.4 |
| DEplain-web | 481 | 35.02 12.913 0.475 59.55 |
| DEplain-APA+web | 868 | 42.862 36.449 0.589 65.4 |
| src2src-baseline | 17,637 | 34.247 0.583 58.85 |

#### Table 2: DEPLAIN-WEB test (n=147)
| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 387 | 43.087 21.9 0.377 64.7 |
| DEplain-web | 481 | 49.584 23.282 0.462 63.5 |
| DEplain-APA+web | 868 | 49.745 23.37 0.445 57.95 |
| src2src-baseline | 12,848 | 23.132 0.432 59.4 |

### Sentence Level

**Results on Sentence Simplification using finetuned mBART.**
- \( n \) corresponds to the length of the training data.

#### Table 3: DEPLAIN-APA test (n=1231)
| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 10660 | 34.818 28.25 0.639 63.072 |
| DEplain-APA+web | 11941 | 34.904 28.506 0.64 62.669 |
| src2src-baseline | 15,249 | 26.893 0.627 59.23 |

#### Table 4: DEPLAIN-WEB test (n=1846)
| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 10660 | 30.867 15.727 0.413 64.516 |
| DEplain-APA+web | 11941 | 34.828 17.88 0.436 65.249 |
| src2src-baseline | 11,931 | 20.85 0.423 60.825 |</sample>
    <sample id="1192">The image shows a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level."

### Document Level

#### Results on Document Simplification using finetuned long-mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4   |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55  |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4   |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85  |

#### DEPLAIN-APA test (n=48)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43.087 | 21.9   | 0.377 | 64.7  |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5  |
| DEplain-APA+web | 868 | 49.745 | 23.37  | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4  |

#### DEPLAIN-WEB test (n=147)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

### Sentence Level

#### Results on Sentence Simplification using finetuned mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34.818 | 28.25  | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64  | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

#### DEPLAIN-APA test (n=1231)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

#### DEPLAIN-WEB test (n=1846)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |</sample>
    <sample id="1193">The image shows a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level."

### Document Level

#### Results on Document Simplification using finetuned long-mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-----------------------------|
| DEplain-APA | 387 | 44.56 38.136 0.598 65.4 |
| DEplain-web | 481 | 35.02 12.913 0.475 59.55 |
| DEplain-APA+web | 868 | 42.862 36.449 0.589 65.4 |
| src2src-baseline | 17,637 | 34.247 0.583 58.85 |

#### DEPLAIN-APA test (n=48)
#### DEPLAIN-WEB test (n=147)

### Sentence Level

#### Results on Sentence Simplification using finetuned mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ BLEU ↑ BS-P ↑ FRE ↑ |
|------------|---|-------------------------------|
| DEplain-APA | 10660 | 34.818 28.25 0.639 63.072 |
| DEplain-APA+web | 11941 | 34.904 28.506 0.64 62.669 |
| src2src-baseline | 15,249 | 26.893 0.627 59.23 |

#### DEPLAIN-APA test (n=1231)
#### DEPLAIN-WEB test (n=1846)</sample>
    <sample id="1194">The image shows a presentation slide titled "Automatic Text Simplification" with two main sections: "Document Level" and "Sentence Level."

### Document Level

#### Results on Document Simplification using finetuned long-mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 44.56 | 38.136 | 0.598 | 65.4   |
| DEplain-web | 481 | 35.02 | 12.913 | 0.475 | 59.55  |
| DEplain-APA+web | 868 | 42.862 | 36.449 | 0.589 | 65.4   |
| src2src-baseline | 17,637 | 34.247 | 0.583 | 58.85  |

#### DEPLAIN-APA test (n=48)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 387 | 43.087 | 21.9   | 0.377 | 64.7  |
| DEplain-web | 481 | 49.584 | 23.282 | 0.462 | 63.5  |
| DEplain-APA+web | 868 | 49.745 | 23.37  | 0.445 | 57.95 |
| src2src-baseline | 12,848 | 23.132 | 0.432 | 59.4  |

#### DEPLAIN-WEB test (n=147)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

### Sentence Level

#### Results on Sentence Simplification using finetuned mBART.
- \( n \) corresponds to the length of the training data.

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 34.818 | 28.25  | 0.639 | 63.072 |
| DEplain-APA+web | 11941 | 34.904 | 28.506 | 0.64  | 62.669 |
| src2src-baseline | 15,249 | 26.893 | 0.627 | 59.23 |

#### DEPLAIN-APA test (n=1231)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |

#### DEPLAIN-WEB test (n=1846)

| train data | n | SARI ↑ | BLEU ↑ | BS-P ↑ | FRE ↑ |
|------------|---|--------|--------|--------|-------|
| DEplain-APA | 10660 | 30.867 | 15.727 | 0.413 | 64.516 |
| DEplain-APA+web | 11941 | 34.828 | 17.88  | 0.436 | 65.249 |
| src2src-baseline | 11,931 | 20.85  | 0.423 | 60.825 |</sample>
    <sample id="1195">Thanks.
For more details, please check out our paper.
And feel free to visit our poster in the ACL 2023 conference.</sample>
    <sample id="1196">The image is a screenshot of a presentation slide from Google Research. The title of the slide reads:

**"Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)"**

Below the title, the names of the authors are listed:
- Mohammad Javad Hosseini
- Filip Radlinski
- Silvia Paret
- Annie Louis

The slide also includes the Google Research logo at the bottom left corner. On the right side of the slide, there is a circular inset showing a person speaking, but their face is not visible in this description.</sample>
    <sample id="1197">The image is a screenshot of a presentation slide from Google Research. The title of the slide reads:

**"Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)"**

Below the title, the names of the authors are listed:
- Mohammad Javad Hosseini
- Filip Radlinski
- Silvia Paret
- Annie Louis

The slide also includes the Google Research logo at the bottom left corner. There is a small circular inset on the right side of the slide showing a person speaking, but their face is not visible. The background of the slide features abstract, colorful lines and shapes in blue, red, green, and yellow.</sample>
    <sample id="1198">The image is a slide from a presentation titled "Indirect Referring Expressions" by Google Research. The goal of the research is to understand users' language when they make a choice. It discusses two types of references: direct and indirect.

- **Direct reference** includes phrases like "easy on me" and "the first one."
- **Indirect reference** can be used in natural and fluid conversation for various reasons such as not remembering the name, pronunciations being hard to distinguish, or wanting to specify a preference. Examples of indirect references include "The newer one" and "The song that's not energetic."

The slide also mentions "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)" and has a page number "P 2" at the bottom right corner.</sample>
    <sample id="1199">The image is a slide from a presentation titled "Indirect Referring Expressions" by Google Research. The goal of the research is to understand users' language when they make a choice. It discusses two types of references: direct and indirect.

- **Direct reference** includes phrases like "easy on me" and "the first one."
- **Indirect reference** can be used in natural and fluid conversation for various reasons such as not remembering the name, pronunciations being hard to distinguish, or wanting to specify a preference. Examples of indirect references include "The newer one." and "The song that's not energetic."

The slide also mentions "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)" at the bottom.</sample>
    <sample id="1200">The image is a slide from a presentation titled "Indirect Referring Expressions" by Google Research. The goal of the research is to understand users' language when they make a choice. It discusses two types of references: direct and indirect.

- **Direct reference** includes phrases like "easy on me" and "the first one."
- **Indirect reference** can be used in natural and fluid conversation for various reasons such as not remembering the name, pronunciations being hard to distinguish, or wanting to specify a preference. Examples of indirect references include "The newer one" and "The song that's not energetic."

The slide also mentions resolving indirect referring expressions for entity selection (AltEntities Corpus).</sample>
    <sample id="1201">The image is a slide from a presentation titled "Indirect Referring Expressions" by Google Research. The goal of the research is to understand users' language when they make a choice. The slide discusses two types of referring expressions: direct and indirect.

- **Direct reference** includes phrases like "easy on me" and "the first one."
- **Indirect reference** can be used in natural and fluid conversation for various reasons:
  - Cannot remember the name.
  - Pronunciations are hard to distinguish.
  - Want to specify a preference.

Examples of indirect references include:
- "The newer one."
- "The song that's not energetic."

The slide also mentions resolving indirect referring expressions for entity selection, using an AltEntities Corpus.</sample>
    <sample id="1202">The image is a slide from a presentation titled "Indirect Referring Expressions" by Google Research. The goal of the research is to understand users' language when they make a choice. It discusses two types of referring expressions: direct and indirect.

- **Direct reference** includes phrases like "easy on me" and "the first one."
- **Indirect reference** can be used in natural and fluid conversation for various reasons:
  - Cannot remember the name.
  - Pronunciations are hard to distinguish.
  - Want to specify a preference.

Examples of indirect references include:
- "The newer one."
- "The song that's not energetic."

The slide also mentions "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)" as part of the research context.</sample>
    <sample id="1203">The slide is titled "Dataset Collection" and is from Google Research. It discusses an important problem related to conversational systems and benchmarking Large Language Models' entity understanding, noting that no large-scale public dataset is available. The slide states that they collect a large dataset using crowd annotation and mentions three domains: one represented by headphones (likely for audio or speech), another with books (possibly for text or library-related data), and the last with a cloche (which could represent food or restaurant-related data). The bottom of the slide references "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)."</sample>
    <sample id="1204">Dataset Collection

- Important problem
  - Conversational systems
  - Benchmarking Large Language Models' entity understanding
- No large-scale public dataset available
- We collect a large dataset using crowd annotation
- Three domains:

![Headphones](https://i.imgur.com/1.png)
![Bookshelf](https://i.imgur.com/2.png)
![Restaurant Tray](https://i.imgur.com/3.png)

Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)</sample>
    <sample id="1205">The image is a slide from a presentation titled "Dataset Collection Methodology" by Google Research. The slide explains a methodology that emphasizes informality using a cartoon completion task. It includes three cartoon characters in a dialogue format:

1. The first character says, "Remember that song we were listening to yesterday?"
2. The second character responds with, "Do you mean 'Easy on Me' or 'I Gotta Feeling'?"
3. The third character has an empty speech bubble, which is labeled as "Expression referring to one of the entities."

The slide also notes that the dialog context is set by choosing from a few manual prompts per domain and that the alternative question is filled in by the annotator. The bottom of the slide mentions "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)."</sample>
    <sample id="1206">The image is a slide from a presentation titled "Dataset Collection Methodology" by Google Research. The slide outlines a methodology that emphasizes informality in dataset collection using a cartoon completion task. It includes three cartoon characters, each with speech bubbles containing dialogue:

1. The first character says, "Remember that song we were listening to yesterday?"
2. The second character responds with, "Do you mean 'Easy on Me' or 'I Gotta Feeling'?"
3. The third character's speech bubble is empty and labeled as "Expression referring to one of the entities," which is filled in by the annotator.

Below the cartoon characters, there is text explaining:
- "Sets the dialog context [chosen from a few manual prompts per domain]"
- "The alternative question"
- "Expression referring to one of the entities"

At the bottom of the slide, it mentions: "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)."</sample>
    <sample id="1207">The image is a slide from a presentation titled "Dataset Collection Methodology" by Google Research. The slide explains that the methodology emphasizes informality using a cartoon completion task. It illustrates a dialogue scenario with three characters, each with speech bubbles containing text:

1. The first character says: "Remember that song we were listening to yesterday?"
2. The second character responds with an alternative question: "Do you mean 'Easy on Me' or 'I Gotta Feeling'?"
3. The third character's speech bubble is empty and labeled as "Expression referring to one of the entities."

The slide also notes that the dialog context is set by choosing from a few manual prompts per domain. A yellow box indicates that the final expression is filled in by the annotator. The bottom of the slide mentions "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)."</sample>
    <sample id="1208">The image is a slide from a presentation titled "Dataset Collection Methodology" by Google Research. The slide discusses a methodology that emphasizes informality in dataset collection using a cartoon completion task. It includes four cartoon characters, each with speech bubbles containing text:

1. The first character says: "Remember that song we were listening to yesterday?"
2. The second character responds: "Do you mean 'Easy on Me' or 'I Gotta Feeling'?"
3. The third character says: "Expression referring to one of the entities"

Additionally, there is a yellow box labeled "Filled in by the annotator," which points to an empty speech bubble where the annotator would fill in the missing part of the conversation.

At the bottom of the slide, it mentions: "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)." The slide number is indicated as P 4.</sample>
    <sample id="1209">The image is a slide from a presentation titled "Dataset Collection Methodology" by Google Research. The slide outlines a methodology that emphasizes informality in dataset collection using a cartoon completion task. It includes a cartoon illustration of two characters having a conversation, with speech bubbles containing dialogue. The text on the slide reads:

- "Methodology emphasizes informality using a cartoon completion task."
- "Sets the dialog context [chosen from a few manual prompts per domain]"
- "The alternative question"
- "Expression referring to one of the entities"
- "Filled in by the annotator"

The bottom of the slide mentions "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)" and indicates it is page 4.</sample>
    <sample id="1210">The image is a slide from a presentation titled "Dataset Collection Methodology" by Google Research. The slide explains a methodology that emphasizes informality using a cartoon completion task. It illustrates a dialogue scenario with two characters, one of whom is a bearded man and the other a woman with long hair.

1. The first character says: "Remember that song we were listening to yesterday?"
2. The second character responds with an alternative question: "Do you mean 'Easy on Me' or 'I Gotta Feeling'?"

The slide also includes a note that the expression referring to one of the entities is filled in by the annotator. Additionally, there is a mention of sampling entity pairs with similar descriptions on Wikipedia (same genre and/or artist) or items with similar titles. The slide notes that the dialog context is set from a few manual prompts per domain.</sample>
    <sample id="1211">The image is a slide from a presentation by Google Research, titled "Generate alternative questions =&gt; sampling entity pairs." The slide discusses methods for generating alternative questions to sample entity pairs. It includes a list of criteria for selecting entities:

1. Items with similar infoboxes on Wikipedia (same genre and/or artist):
   - Do you mean 'This Is It' or 'Man in the Mirror'?

2. Items with similar descriptions on Wikipedia:
   - Do you mean 'Thinking of You' or 'Happy Anywhere'?

3. Items with similar titles:
   - Do you mean 'The Return (memoir)' or 'The Return (Shatner novel)'?

4. Uniform at random:
   - Do you mean 'You Could Be Mine' or 'The Way I Am'

On the left side of the slide, there is a yellow arrow labeled "More Similar (usually harder)" pointing upwards, indicating that the more similar the entities, the harder it might be to distinguish between them.

At the bottom of the slide, there is a reference to "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)."</sample>
    <sample id="1212">The image is a slide from a presentation titled "Generate alternative questions =&gt; sampling entity pairs" by Google Research. The slide discusses methods for generating alternative questions to resolve indirect referring expressions in entity selection, using an example corpus called AltEntities Corpus.

The slide lists four categories of entity pairs that can be sampled:

1. **Items with similar infoboxes on Wikipedia (same genre and/or artist):**
   - Example: Do you mean 'This Is It' or 'Man in the Mirror'?

2. **Items with similar descriptions on Wikipedia:**
   - Example: Do you mean 'Thinking of You' or 'Happy Anywhere'?

3. **Items with similar titles:**
   - Example: Do you mean 'The Return (memoir)' or 'The Return (Shatner novel)'?

4. **Uniform at random:**
   - Example: Do you mean 'You Could Be Mine' or 'The Way I Am'

On the left side of the slide, there is a yellow arrow labeled "More Similar (usually harder)" pointing upwards, indicating that the examples listed under each category become more challenging as they progress.</sample>
    <sample id="1213">The image is a slide from a presentation by Google Research, titled "Generate alternative questions =&gt; sampling entity pairs." The slide discusses methods for generating alternative questions to resolve indirect referring expressions in entity selection, using an example corpus called AltEntities Corpus.

The slide lists four categories of items that can be used to generate alternative questions:

1. **Items with similar infoboxes on Wikipedia (same genre and/or artist):**
   - Example: Do you mean 'This Is It' or 'Man in the Mirror'?

2. **Items with similar descriptions on Wikipedia:**
   - Example: Do you mean 'Thinking of You' or 'Happy Anywhere'?

3. **Items with similar titles:**
   - Example: Do you mean 'The Return (memoir)' or 'The Return (Shatner novel)'?

4. **Uniform at random:**
   - Example: Do you mean 'You Could Be Mine' or 'The Way I Am'?

On the left side of the slide, there is a yellow arrow pointing upwards with the text "More Similar (usually harder)" indicating that the examples become more challenging as they progress down the list.</sample>
    <sample id="1214">The image is a slide from a presentation by Google Research, titled "Generate alternative questions =&gt; sampling entity pairs." The slide discusses methods for generating alternative questions to resolve indirect referring expressions in entity selection. It lists four categories of entity pairs:

1. **Items with similar infoboxes on Wikipedia (same genre and/or artist):**
   - Example: Do you mean 'This Is It' or 'Man in the Mirror'?

2. **Items with similar descriptions on Wikipedia:**
   - Example: Do you mean 'Thinking of You' or 'Happy Anywhere'?

3. **Items with similar titles:**
   - Example: Do you mean 'The Return (memoir)' or 'The Return (Shatner novel)'?

4. **Uniform at random:**
   - Example: Do you mean 'You Could Be Mine' or 'The Way I Am'

On the left side of the slide, there is a yellow arrow pointing upwards labeled "More Similar (usually harder)," indicating that the examples under each category become more challenging as they progress. The slide also includes a reference to "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)" and is marked as page 5.</sample>
    <sample id="1215">The image is a slide from a presentation by Google Research, titled "Generate alternative questions =&gt; sampling entity pairs." The slide includes a question at the top: "Do you mean A or B?" Below this question, there are four bullet points explaining different methods for generating alternative questions:

1. Items with similar infoboxes on Wikipedia (same genre and/or artist):
   - Do you mean 'This Is It' or 'Man in the Mirror'?

2. Items with similar descriptions on Wikipedia:
   - Do you mean 'Thinking of You' or 'Happy Anywhere'?

3. Items with similar titles:
   - Do you mean 'The Return (memoir)' or 'The Return (Shatner novel)'?

4. Uniform at random:
   - Do you mean 'You Could Be Mine' or 'The Way I Am'

On the left side of the slide, there is a yellow arrow pointing upwards with the text "More Similar (usually harder)" indicating that the methods listed are ordered from more similar to less similar entities.

At the bottom of the slide, there is a reference to the source: "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)."</sample>
    <sample id="1216">Background knowledge (Music)
- Google search link to each song.
  - Easy on Me (by Adele)
  - I Gotta Feeling (by The Black Eyed Peas)

We ask annotators to
- Listen to at least some of each song
- Read about each song</sample>
    <sample id="1217">Background knowledge (Music)
- Google search link to each song.
  - Easy on Me (by Adele)
  - I Gotta Feeling (by The Black Eyed Peas)

We ask annotators to
- Listen to at least some of each song
- Read about each song</sample>
    <sample id="1218">Background knowledge (Music)
- Google search link to each song.
  - Easy on Me (by Adele)
  - I Gotta Feeling (by The Black Eyed Peas)

We ask annotators to:
- Listen to at least some of each song
- Read about each song

The slide also mentions "Resolving Indirect Referring Expressions for Entity Selection (AltEntities Corpus)".

The video then transitions to a Google search result page for the song "Easy on Me" by Adele, showing options to view the overview, lyrics, videos, listen, artists, and analysis. It includes links to the official video on YouTube and Vevo, as well as information about the song's release year, artist, genre, awards, and related searches.</sample>
    <sample id="1219">Background knowledge (Recipes)

Simnel Cake
Simnel cake is a fruitcake widely eaten in the United Kingdom, Ireland and other countries with patterns of migration from them, associated with Lent and Easter. It is distinguished by layers of almond paste or marzipan, and a set of eleven balls made of the same paste.

Pandan Cake
Pandan cake is a light, fluffy, green-coloured sponge cake flavoured with the juices of Pandanus amaryllifolius leaves. The cake is popular in Indonesia, Malaysia, and also the Netherlands, especially among the Indo community.</sample>
    <sample id="1220">Eliciting expressions

- We then tell the annotators which choice should be selected and ask them to describe it.

Pick this one
- Easy on Me (by Adele)
- I Gotta Feeling (by the Black Eyed Peas)

We would like you to give us 3 to 5 expressions for the chosen song to fill in your speech bubble. For example:

- The one with the piano music
- The song that's not energetic
- It has something about a river
- The newer one
- It's about not having time to choose</sample>
    <sample id="1221">Eliciting expressions

- We then tell the annotators which choice should be selected and ask them to describe it.

Pick this one
- Easy on Me (by Adele)
- I Gotta Feeling (by the Black Eyed Peas)

We would like you to give us 3 to 5 expressions for the chosen song to fill in your speech bubble. For example:

- The one with the piano music
- The song that's not energetic
- It has something about a river
- The newer one
- It's about not having time to choose

Random Examples

Music Selection
- Do you mean 'Chime' or 'Your Loving Arms'? =&gt; The one without words
- Do you mean 'These Kids' or 'Inescapable'? =&gt; It is the song sung by an Australian.
- Do you mean 'Rock the Boat' or 'Wherever You Are'? =&gt; It has synthesizer sounds in it
- Do you mean 'Telepathy' or 'Stars on 45'? =&gt; Came out in mid of 2000.
- Do you mean 'Mis-Shapes' or 'Remind Me'? =&gt; Based on life experienced in Sheffield.

Book Selection
- Do you mean 'Warlock (Hall novel)' or 'Warlock (Smith novel)'? =&gt; The one that is set in the 1880s
- Do you mean 'The Legion of Space' or 'The Body in the Library'? =&gt; It's by a famous detective writer
- Do you mean 'The Good Soldier' or 'The Good Soldiers'? =&gt; The fictional one
- Do you mean 'The Giaour' or 'The Giver'? =&gt; Not the one with the 12-year-old boy
- Do you mean 'Broken Sleep' or 'Broken Soup'? =&gt; It's the book that has rock and politics in it

Recipe Selection
- Do you mean 'Beurre Maître d'Hôtel' or 'Chigirlma'? =&gt; Comes from Azerbaijan
- Do you mean 'Kusa mochi' or 'Uiré'? =&gt; The Japanese steamed cake
- Do you mean 'Cannoli' or 'Boconotto'? =&gt; The ones eaten at Christmas
- Do you mean 'Johnnycake' or 'Mochi'? =&gt; Cornmeal is the main ingredient
- Do you mean 'Sagu' or 'Mochi'? =&gt; Not the one with the rice</sample>
    <sample id="1222">AltEntities Corpus
- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions

Results with T5 XL model (accuracy):
○ 92-95% if the LM has access to the same background knowledge as annotators.
○ 82%-87% when the LM has access to partially overlapping background knowledge.
○ ~60% when the LM (T5 XL) has only access to the entity names.
○ We showed models are domain-generalizable.

Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1223">AltEntities Corpus
- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions

Results with T5 XL model (accuracy):
○ 92-95% if the LM has access to the same background knowledge as annotators.
○ 82%-87% when the LM has access to partially overlapping background knowledge.
○ ~60% when the LM (T5 XL) has only access to the entity names.
○ We showed models are domain-generalizable.

Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1224">AltEntities Corpus
- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions

Results with T5 XL model (accuracy):
○ 92-95% if the LM has access to the same background knowledge as annotators.
○ 82%-87% when the LM has access to partially overlapping background knowledge.
○ ~60% when the LM (T5 XL) has only access to the entity names.
○ We showed models are domain-generalizable.

Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1225">AltEntities Corpus
- ~6,000 alternative questions across the three domains
- ~42,000 indirect referring expressions

Results with T5 XL model (accuracy):
- 92-95% if the LM has access to the same background knowledge as annotators.
- 82%-87% when the LM has access to partially overlapping background knowledge.
- ~60% when the LM (T5 XL) has only access to the entity names.
- We showed models are domain-generalizable.

Dataset Link: https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="1226">CamemBERT is initially trained on 4GB of data.</sample>
    <sample id="1227">The name of the speaker is Adam Przepiórkowski.</sample>
    <sample id="1228">The findings that led to the conclusion that the temporal drift is the main cause of performance loss include the observation that performance degrades with a larger temporal gap between the training and test data, as indicated by the table and graph on the slide.</sample>
    <sample id="1229">NLPositionality:
Characterizing Design Biases of Datasets and Models

Sebastin Santy*
University of Washington
Jenny T. Liang*
Carnegie Mellon University
Ronan Le Bras
Allen Institute for AI
Katharina Reinecke
University of Washington
Maarten Sap
Carnegie Mellon University</sample>
    <sample id="1230">NLPositionality:
Characterizing Design Biases of Datasets and Models

Sebastin Santy*
University of Washington
Jenny T. Liang*
Carnegie Mellon University
Ronan Le Bras
Allen Institute for AI
Katharina Reinecke
University of Washington
Maarten Sap
Carnegie Mellon University</sample>
    <sample id="1231">Imagine...</sample>
    <sample id="1232">Imagine...

= PerspectiveAPI score

Carl Jones
Tech Lead,
New York Times

Can you stop being a jerk? 🚫: (0.82) ✅</sample>
    <sample id="1233">Imagine...

Carl Jones  
Tech Lead,  
New York Times

Can you stop being a jerk? 🚫: (0.82) ✅

Aditya Sharma  
Tech Lead,  
Times of India

Presstitutes everywhere on the news. 🚫: (0.33) ❌</sample>
    <sample id="1234">Imagine...

Design bias example!

- Can you stop being a jerk? (0.82) ✅
- Presstitutes everywhere on the news. (0.33) ❌

Carl Jones  
Tech Lead,  
New York Times  

Aditya Sharma  
Tech Lead,  
Times of India  

= PerspectiveAPI score</sample>
    <sample id="1235">Positionality

"The perspectives [people] hold as a result of their demographics, identity, and life experiences."

[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="1236">Positionality

"The perspectives [people] hold as a result of their demographics, identity, and life experiences."

[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="1237">Positionality

"The perspectives [people] hold as a result of their demographics, identity, and life experiences.

[As a researcher,] it influences the research process and its outcomes and results." [1]

[1] Savin-Baden, Maggi, and Claire Howell-Major. "Qualitative research: The essential guide to theory and practice." Qualitative Research: The Essential Guide to Theory and Practice. Routledge (2013).</sample>
    <sample id="1238">The slide presents the question: "Do datasets and models have positionality?" Below the question, there are three references listed:

1. Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
2. Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
3. Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1239">The image contains a slide with the title "Do datasets and models have positionality?" Below the title, there are three references listed:

1. Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
2. Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
3. Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.

The slide appears to be part of a presentation discussing the concept of positionality in datasets and models, referencing recent academic papers from conferences such as ACL, EMNLP, and CHI.</sample>
    <sample id="1240">The slide presents the question: "Do datasets and models have positionality?" It discusses anecdotal evidence related to this topic, listing three references:

1. Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
2. Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
3. Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.

The slide also mentions two types of evidence:
- Model and dataset probing [1][2]
- Theoretical definitions of model positionality [3]</sample>
    <sample id="1241">The slide presents the question: "Do datasets and models have positionality?" It discusses anecdotal evidence supporting this idea, including:

- Model and dataset probing [1][2]
- Theoretical definitions of model positionality [3]

The references are as follows:
[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.</sample>
    <sample id="1242">The image is a slide from a presentation with the title "Do datasets and models have positionality?" Below the title, it states "Anecdotal evidence:" followed by two bullet points:
- Model and dataset probing [1][2]
- Theoretical definitions of model positionality [3]

At the bottom of the slide, there are references to three academic papers:
[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.

In the top right corner, there is a small video feed showing a person speaking.</sample>
    <sample id="1243">The image is a slide from a presentation with the title "Do datasets and models have positionality?" Below the title, it lists "Anecdotal evidence:" followed by two bullet points:
- Model and dataset probing [1][2]
- Theoretical definitions of model positionality [3]

At the bottom of the slide, there are references to three academic papers:
[1] Blasi, et al. "Systematic Inequalities in Language Technology Performance across the World's Languages." ACL 2022.
[2] Yin et al. "GEOMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." EMNLP 2022.
[3] Cambo &amp; Gergle. "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science." CHI 2022.

In the top right corner, there is a small video feed showing a person speaking, but their face is not visible.</sample>
    <sample id="1244">Question: Do datasets and models have positionality?

Goal: Compare annotations from users with existing datasets and models.</sample>
    <sample id="1245">NLPositionality
A framework for characterizing design biases in NLP datasets and models</sample>
    <sample id="1246">The image is a framework diagram that outlines a process for collecting, processing, and analyzing data related to social chemistry and annotations from diverse sources. Here is the transcribed content:

**Framework**

**Collection**
1. **300 instances are sampled from a dataset.**
2. **Each instance has an associated gold label.**
3. **Instances are sent as part of a study on LTW (Lab in the Wild).**
4. **Annotations from people around the world.**

**Processing**
- **Model Predictions:** The received annotations are compared against the gold labels from the dataset and predictions obtained from the models.

**Analysis**
- **Demographics Breakdown:**
  - **Age:** &lt;18, 18-25, 25-35, 35-45
  - **Gender:** Woman, Man
  - **Ethnicity:** White, Black, Hispanic, Asian, Non-B
  - **Education:** Grad, PhD, College, School
  - **Country:** USA, Germany, France, UK, Canada, Australia, Japan

6. **Pearson's r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.**

This framework appears to be used for evaluating the accuracy of model predictions by comparing them with human annotations from various demographic groups.</sample>
    <sample id="1247">The image is a slide titled "Framework" and it outlines a process for re-annotating datasets with diverse annotators. Here's a detailed breakdown of the content:

### Collection
1. **300 instances are sampled from a dataset.**
2. **Each instance has an associated gold label.**
3. **Instances are sent as part of a study on LTW (Lab in the Wild).**
4. **Annotations from people around the world.**

### Processing
5. **The received annotations are compared against the gold labels from the dataset and predictions obtained from the models.**

### Analysis
6. **Pearson’s r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.**

The slide also includes a table at the bottom showing demographic information such as age, gender, ethnicity, education, and country, with corresponding icons and colors to represent different categories.

On the right side of the slide, there is a note that says:
**"Re-annotate datasets with diverse annotators."**

The slide appears to be part of a presentation, possibly related to a research project or academic discussion about data annotation and model evaluation.</sample>
    <sample id="1248">**Framework**

1) Re-annotate datasets with diverse annotators.

**Collection**
- 300 instances are sampled from a dataset.
- Each instance has an associated gold label.
- Instances are sent as part of a study on LITW.
- Annotations from people around the world.

**Processing**
- Model Predictions

**Analysis**
- Pearson's r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.</sample>
    <sample id="1249">The image is a slide titled "Framework" and appears to outline a process for collecting, processing, and analyzing data related to annotations from diverse annotators. Here's a breakdown of the content:

### Collection
1. **300 instances are sampled from a dataset.**
2. **Each instance has an associated gold label.**
3. **Instances are sent as part of a study on LTW (Lab in the Wild).**
4. **Annotations from people around the world.**

### Processing
- **Model Predictions:** The received annotations are compared against the gold labels from the dataset and predictions obtained from models.

### Analysis
- **Pearson’s r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.**
- **Demographics include:**
  - Age: &lt;18, 18-25, 25-35, 35-45
  - Gender: Woman, Man
  - Ethnicity: White, Black, Hispanic, Non-B
  - Education: Grad, PhD, College, School
  - Country: USA, Germany, France, Italy, Spain

### Key Points
1. **Re-annotate datasets with diverse annotators.**

This framework seems to be used to evaluate the consistency and reliability of annotations across different demographic groups using both human and machine predictions.</sample>
    <sample id="1250">**Framework**

Collection:
1. 300 instances are sampled from a dataset.
2. Each instance has an associated gold label.
3. Instances are sent as part of a study on LITW.
4. Annotations from people around the world.

Processing:
5. The received annotations are compared against the gold labels from the dataset and predictions obtained from the models.

Analysis:
6. Pearson's r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.

2) Compare annotations by demographic to models and datasets via Pearson's R scores.</sample>
    <sample id="1251">**Framework**

1. **Collection**
   - 300 instances are sampled from a dataset.
   - Each instance has an associated gold label.

2. **Processing**
   - Model Predictions

3. **Analysis**
   - SocialChem with Annotations
   - The received annotations are compared against the gold labels from the dataset and predictions obtained from the models.
   - Pearson's r correlation is measured between gold labels, model predictions, and annotations for each of the demographics separately.

4. **Comparison by Demographic to Models and Datasets via Pearson's R scores.**</sample>
    <sample id="1252">The image is a screenshot of a webpage titled "Lab in the Wild." The page features a logo with a globe and the text "Lab in the Wild" next to it. Below the logo, there is a section with three different experiments that participants can take part in:

1. **Could you live with an AI and its morals?**
   - Description: Tell us your moral judgments on certain situations and we will show you how you compare to others and an AI.
   - Button: Participate now!

2. **Are you better than an AI in noticing hateful speech?**
   - Description: Rate what speech is hateful and we'll show you how well you detect hateful speech compared to an AI and others.
   - Button: Participate now!

3. **Where are you on the techno-skeptic to techno-utopian scale?**
   - Description: Tell us how you think future mixed reality technology will affect your personal life; we will show you whether you are more techno-skeptical or techno-utopian.
   - Button: Participate now!

At the top of the page, there are navigation links for "Our Experiments," "Findings &amp; Data Sets," "Blog," "For Researchers," and "About Us." There is also a language selection dropdown set to "English."

To the right of the main content, there is a statistic that reads "5,376,396 total participants."

The image also includes annotations pointing to the statistic and the experiment sections:
- **Pool of diverse volunteers/research participants** points to the statistic.
- **Online experiment from researchers** points to the experiment sections.

The overall layout suggests that this is a platform for conducting online experiments related to artificial intelligence, ethics, and technology acceptance.</sample>
    <sample id="1253">The image is a screenshot of a webpage from "Lab in the Wild," which appears to be a platform for conducting online experiments. The webpage includes various sections and options for participants to engage with different studies.

1. **Header:**
   - The title "Lab in the Wild" is prominently displayed at the top left corner.
   - There are navigation tabs such as "Our Experiments," "Findings &amp; Data Sets," "Blog," "For Researchers," and "About Us."

2. **Main Content:**
   - A section titled "5,376,396 total participants" indicates the number of participants involved in the experiments.
   - Below this, there are three main experiment options:
     1. **Could you live with an AI and its morals?**
        - This experiment asks participants about their moral judgments on certain situations involving AI.
        - There is a button labeled "Participate now!"
     2. **Are you better than an AI in noticing hateful speech?**
        - This experiment compares participants' ability to detect hateful speech with that of an AI.
        - There is a button labeled "Participate now!"
     3. **Where are you on the techno-skeptic to techno-utopian scale?**
        - This experiment explores participants' views on future mixed reality technology and its impact on personal life.
        - There is a button labeled "Participate now!"

3. **Additional Information:**
   - On the right side of the image, there are labels pointing to specific parts of the webpage:
     - "Pool of diverse volunteers / research participants"
     - "Online experiment from researchers"

4. **Background:**
   - The background shows a person speaking, likely providing information or context about the platform.

This webpage seems to be designed to facilitate participation in various online experiments related to technology, ethics, and human-AI interactions.</sample>
    <sample id="1254">Task A: Social Acceptability

1) Read the situation.
2) Enter what you think about it.
3) See what an AI and others thought about it!

The AI speculates:
I speculate that it's understandable. Hmm... Maybe I'm incorrect on this.

Study participants in the United States said:

Very bad | Bad | Expected/OK | Good | Very good
--- | --- | --- | --- | ---
50% | 40% | 30% | 60% | 50%

Participants read a situation from the Social Chemistry dataset.
Participants rate how socially acceptable the situation is.
Participants compare their responses to others' and an AI's.</sample>
    <sample id="1255">Task A: Social Acceptability

1) Read the situation.
2) Enter what you think about it.
3) See what an AI and others thought about it.

The AI speculates:
"I speculate that it's understandable. Hmm... Maybe I'm incorrect on this."

Study participants in the United States said:

- Very bad: 0%
- Bad: 0%
- Expected/OK: 40%
- Good: 60%
- Very good: 0%

Participants compare their responses to others' and an AI's.</sample>
    <sample id="1256">Task A: Social Acceptability

Analysis
Datasets - Social Chemistry
Models - Delphi - GPT-4</sample>
    <sample id="1257">Task B: Toxicity

1) Read the example:
   7 / 25
   English people smell like sour milk

2) Enter what you think about it.
   * Do you think this is hateful speech?
   * denotes a required field.
   Yes | No | Not sure
   Feel free to explain your rating.
   Enter a short description
   Submit

3) See what others thought about it!
The AI speculates:
   I speculate that this is hateful speech. Looks like we agree!

Study participants in Afghanistan said:
   Not Hateful | Not Sure | Hateful
   [Bar chart showing distribution of responses]

Participants read an instance from the Dynahate dataset.
Participants rate whether they think an instance is hate speech.</sample>
    <sample id="1258">Task B: Toxicity Analysis

Datasets - Dynahate

Models
- Perspective API
- Rewire API
- Hate RoBERTa
- GPT-4

Study Participation

16,299 annotations
1,096 annotators
87 countries</sample>
    <sample id="1259">Results
Who do NLP datasets and models align with?

Finding 1:
There is positionality in NLP.</sample>
    <sample id="1260">The image is a slide from a presentation, featuring two bar charts and a title that reads: "Datasets and models are most aligned to English-Speaking countries."

### First Bar Chart:
- **Title:** Social Acceptability (GPT-4)
- **X-axis:** Different regions/cultures (African Islamic, Baltic, Catholic Europe, Confucian, English-Speaking, Latin America, Orthodox Europe, Protestant Europe, West South Asia)
- **Y-axis:** Social Acceptability Score (ranging from 0 to 0.8)
- **Legend:** Each region has a corresponding score and sample size (N) in parentheses.
- **Observations:**
  - English-Speaking has the highest social acceptability score at 0.74 with a sample size of 8,289.
  - African Islamic has the lowest score at 0.47 with a sample size of 316.

### Second Bar Chart:
- **Title:** Hate Speech &amp; Toxicity (Dynahate)
- **X-axis:** Same regions/cultures as above
- **Y-axis:** Hate Speech &amp; Toxicity Score (ranging from 0 to 0.75)
- **Legend:** Each region has a corresponding score and sample size (N) in parentheses.
- **Observations:**
  - English-Speaking has the highest hate speech &amp; toxicity score at 0.70 with a sample size of 4,025.
  - Catholic Europe has the lowest score at 0.32 with a sample size of 183.

The slide emphasizes that datasets and models are most aligned with English-speaking countries in terms of both social acceptability and hate speech/toxicity scores.</sample>
    <sample id="1261">The image is a bar chart titled "Social Acceptability (GPT-4)" which shows the alignment of datasets and models with people of different educational backgrounds. The x-axis represents different levels of education: College, Graduate School, High School, PhD, Pre-High School, and Prof. School. The y-axis represents the social acceptability score ranging from 0.0 to 0.8.

Here are the scores for each category:
- College: 0.69*
- Graduate School: 0.69*
- High School: 0.64*
- PhD: 0.61*
- Pre-High School: 0.59*
- Prof. School: 0.49*

The text on the left side of the image states: "Datasets and models are most aligned to people with a college education."

The asterisk (*) next to the scores indicates statistical significance or a specific note related to the data.</sample>
    <sample id="1262">The image is a bar chart titled "Hate Speech &amp; Toxicity (Dynahate)" with the subtitle "Datasets and models are most aligned to people with a college education." The x-axis represents different levels of education: College, Graduate School, High School, PhD, Pre-High School, and Prof. School. The y-axis represents the score on the Dynahate scale, ranging from 0.0 to 0.8.

The bars are as follows:
- College: N=2,383, Score=0.66*
- Graduate School: N=604, Score=0.59*
- High School: N=908, Score=0.59*
- PhD: N=359, Score=0.48*
- Pre-High School: N=116, Score=0.37
- Prof. School: N=195, Score=0.61*

The asterisk (*) next to the scores indicates statistical significance.</sample>
    <sample id="1263">Finding 2:
Some populations are left behind.</sample>
    <sample id="1264">The image is a slide from a presentation, featuring two bar charts with the title "Datasets and models are less aligned to non-binary people." The first chart is labeled "Social Acceptability (GPT-4)" and shows three categories: Man, Non-binary, and Woman. Each category has a corresponding bar indicating social acceptability scores:

- Man: N=4,082, score = 0.69*
- Non-binary: N=858, score = 0.55*
- Woman: N=4,368, score = 0.73*

The second chart is labeled "Hate Speech &amp; Toxicity (Dynahate)" and also shows three categories: Man, Non-binary, and Woman. Each category has a corresponding bar indicating hate speech and toxicity scores:

- Man: N=1,798, score = 0.65*
- Non-binary: N=329, score = 0.58*
- Woman: N=2,357, score = 0.63*

The asterisk (*) next to each score likely indicates statistical significance or a specific metric used in the analysis.

The background of the slide includes a person on the right side, presumably the presenter, but their face is not visible. The overall theme of the slide suggests that datasets and models may not be equally aligned or sensitive towards non-binary individuals compared to men and women.</sample>
    <sample id="1265">So, what can we do?
Addressing positionality in NLP</sample>
    <sample id="1266">Recommendations

1. Keep a record of all relevant design choices made throughout building datasets or models.

2. Do NLP research through the lens of perspectivism:
a. Share disaggregated dataset labels!
b. Use modeling techniques that can handle annotator disagreement.</sample>
    <sample id="1267">Recommendations

1. Keep a record of all relevant design choices made throughout building datasets or models.
2. Do NLP research through the lens of perspectivism:
   a. Share disaggregated dataset labels!
   b. Use modeling techniques that can handle annotator disagreement.
3. Building specialized datasets and models with and for specific communities is valuable for inclusive NLP (e.g., Masakhane initiative¹).

[1] https://www.masakhane.io</sample>
    <sample id="1268">Thanks!

Dashboard Link: nlpositionality.cs.washington.edu/
Paper: bit.ly/NLPositionality-Paper/

Delphi
(https://delphi.allenai.org)

Age
Gender
Ethnicities
Religion

Education Level
Country (Residence)
Country (Longest)
Native Language</sample>
    <sample id="1269">Permuting the tokens for the output sequence is necessary to explore all possible orderings of the tokens, which helps in capturing the dependencies and relationships between different parts of the sentence more effectively. This approach allows the model to consider various permutations of the tokens, thereby improving its ability to generate accurate and contextually relevant outputs.</sample>
    <sample id="1270">The authors recommended increasing transparency about bias mitigation methods to address positive stereotypes and essentializing narratives, and to adopt an intersectional lens in their work.</sample>
    <sample id="1271">Minimal-pair unacceptable inputs are sentences that are grammatically correct but are used to test the language model's ability to distinguish between similar structures, such as "Many people were helping themselves" and "Many people were helping herself."</sample>
    <sample id="1272">The authors used F1, Hamming, and EMR as evaluation metrics.</sample>
    <sample id="1273">Krippendorff's Alpha</sample>
    <sample id="1274">Wikipedia</sample>
    <sample id="1275">The affiliations of the authors of the paper are Heinrich Heine University Düsseldorf, Germany.</sample>
    <sample id="1276">MultiInstruct differs from other benchmarks in that it has 1600+ language-only instruction tasks, while there are no large-scale, publicly-available multimodal instruction tasks.</sample>
    <sample id="1277">There are three authors involved in the paper: Sarah E. Finch, James D. Finch, and Jinho D. Choi.</sample>
    <sample id="1278">Binary coordination refers to the structure where two elements are coordinated, typically in a sentence or phrase, and they are of equal status and importance. In the context of the figure provided, it seems to be discussing the proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths, which could be related to binary coordination in linguistic analysis.</sample>
    <sample id="1279">The image does not provide information about the length of the prompts used in the study. It only shows a bar chart comparing the percentage of personas associated with different words in a Black stereotype lexicon across three models (GPT-4 PBlack, GPT-3.5 PBlack, and GPT-3.5 PWhite). The x-axis lists the words, and the y-axis shows the percentage of personas. There is no data related to prompt lengths.</sample>
    <sample id="1280">The findings imply that smaller T5 models fine-tuned on Coscript can generate higher quality scripts than larger LLMs like GPT-3 and Codex. This suggests that there might be an advantage in using smaller models for specific tasks, as they can potentially achieve high accuracy with less computational resources.</sample>
    <sample id="1309">The learning strategies investigated in the work are "From scratch with full model construction" and "Continual pre-training using an existing pre-trained model."</sample>
    <sample id="1310">The factor of overfitting due to test reuse is not specified in the image, but it is mentioned that there is no diminishing returns and temporal drift has not been observed.</sample>
    <sample id="1311">The quality of the simplification was evaluated using metrics such as SARI, BLEU, BS-P, and FRE.</sample>
    <sample id="1312">Yes, language models have different political biases.</sample>
    <sample id="1347">Cognitive dissonance is defined as "two elements of cognition (i.e., thoughts, actions, beliefs) that are inconsistent."</sample>
    <sample id="1348">The most liberal language model according to the figure is Alpaca, which is located in the bottom left quadrant of the plot.</sample>
    <sample id="1349">Yes, cumulative training generally performs better than iterative in active learning according to the AUC values shown in the chart.</sample>
    <sample id="1350">The name of the speaker is Sara Papi.</sample>
    <sample id="1351">The data for the MuDa benchmark was taken from TED Talks.</sample>
    <sample id="1352">The image is a slide from a presentation titled "Conjunct Lengths in English, Dependency Length Minimization, and Dependency Structure of Coordination" by Adam Przepiórkowski and Michał Woźniak. The slide is associated with the Institute of Computer Science, Polish Academy of Sciences, located at ul. Jana Kazimierza 5, 01-248 Warsaw, and the University of Warsaw. The presentation is part of ACL 2023.

The slide discusses different dependency structures for coordination, presenting examples from Bouquet/Stanford (Universal Dependencies), Chain/Moscow, Conjunction-headed/Prague, and Multi-headed/London. Each example shows a sentence structure where "Homer loves Lisa, Bart, and Maggie," but with varying dependency structures indicated by arrows pointing to the subjects and objects within the sentence.</sample>
    <sample id="1353">The image is a slide from a presentation titled "Dependency Structure of Coordination." It discusses different dependency structures for coordinating clauses, specifically using the example sentence: "Homer loves Lisa, Bart, and Maggie."

The slide lists four different dependency structures:

1. **Bouquet/Stanford (Universal Dependencies):**
   - The structure shows that "Homer" is the subject, "loves" is the verb, and "Lisa," "Bart," and "Maggie" are objects, each connected to "loves" by separate arcs.

2. **Chain/Moscow:**
   - This structure also shows "Homer" as the subject, "loves" as the verb, but it connects "Lisa," "Bart," and "Maggie" in a chain-like manner, all pointing back to "loves."

3. **Conjunction-headed/Prague:**
   - Here, "Homer" is the subject, "loves" is the verb, and "Lisa," "Bart," and "Maggie" are all connected to "loves" through a single arc, indicating they are all objects of the same verb.

4. **Multi-headed/London:**
   - Similar to Prague, this structure shows "Homer" as the subject, "loves" as the verb, and "Lisa," "Bart," and "Maggie" are all connected to "loves" through a single arc, indicating they are all objects of the same verb.

Each structure represents a different way of parsing the dependency between the subject, verb, and objects in the sentence.</sample>
    <sample id="1354">The image is a slide from a presentation titled "Dependency Structure of Coordination." It discusses different dependency structures for coordinating clauses, specifically using the example sentence: "Homer loves Lisa, Bart, and Maggie."

The slide lists four different dependency structures:

1. **Bouquet/Stanford (Universal Dependencies):**
   - The structure shows that "Homer" is the subject, "loves" is the verb, and "Lisa," "Bart," and "Maggie" are coordinated objects.

2. **Chain/Moscow:**
   - This structure also shows "Homer" as the subject, "loves" as the verb, and "Lisa," "Bart," and "Maggie" as coordinated objects.

3. **Conjunction-headed/Prague:**
   - Here, "Homer" is the subject, "loves" is the verb, and "Lisa," "Bart," and "Maggie" are coordinated objects.

4. **Multi-headed/London:**
   - This structure again shows "Homer" as the subject, "loves" as the verb, and "Lisa," "Bart," and "Maggie" as coordinated objects.

Each structure represents a different way to model the dependency between the words in the sentence, focusing on how the coordination is handled within the dependency framework.</sample>
    <sample id="1355">The image is a slide from a presentation titled "Dependency Structure of Coordination." It discusses different dependency structures for coordinating clauses, specifically using the example sentence: "Homer loves Lisa, Bart, and Maggie."

The slide lists four different dependency structures:

1. **Bouquet/Stanford (Universal Dependencies):**
   - The structure shows that "Homer" is the subject, "loves" is the verb, and "Lisa," "Bart," and "Maggie" are objects, each connected to "loves" by separate arcs.

2. **Chain/Moscow:**
   - This structure also shows "Homer" as the subject, "loves" as the verb, and "Lisa," "Bart," and "Maggie" as objects, but the connections between them are shown in a chain-like manner.

3. **Conjunction-headed/Prague:**
   - Here, "Homer" is the subject, "loves" is the verb, and "Lisa," "Bart," and "Maggie" are objects, with "and" connecting the objects.

4. **Multi-headed/London:**
   - This structure shows "Homer" as the subject, "loves" as the verb, and "Lisa," "Bart," and "Maggie" as objects, with multiple arcs connecting "loves" to each object.

Each structure is visually represented with arrows indicating the dependencies between the words in the sentence.</sample>
    <sample id="1356">The image is a slide from a presentation titled "Dependency Structure of Coordination." It discusses different dependency structures for coordinating phrases, specifically using the example sentence: "Homer loves Lisa, Bart, and Maggie."

The slide lists four different dependency structures:

1. **Bouquet/Stanford (Universal Dependencies):**
   - The sentence is represented with arcs connecting "Homer" to "loves," "Lisa," "Bart," and "Maggie," indicating that each noun phrase is directly dependent on "loves."

2. **Chain/Moscow:**
   - This structure shows a chain where "Homer" is connected to "loves," which then connects to "Lisa," "Bart," and "Maggie."

3. **Conjunction-headed/Prague:**
   - Here, "Homer" is connected to "loves," which is then connected to "Lisa, Bart, and Maggie" as a single unit.

4. **Multi-headed/London:**
   - This structure shows multiple heads, with "Homer" connected to "loves," which then branches out to connect to "Lisa," "Bart," and "Maggie."

Each structure is visually represented with arrows or lines to show the dependencies between the words in the sentence.</sample>
    <sample id="1357">The image is a slide from a presentation titled "Dependency Structure of Coordination." It discusses different dependency structures for coordinating clauses, using the sentence "Homer loves Lisa, Bart, and Maggie" as an example. The slide lists four different dependency structures:

1. **Bouquet/Stanford (Universal Dependencies):**
   - The sentence is represented with a tree structure where "Homer loves Lisa, Bart, and Maggie" is shown as a single node with multiple dependencies.

2. **Chain/Moscow:**
   - The sentence is also represented with a tree structure similar to the Bouquet/Stanford model but with a slightly different arrangement of dependencies.

3. **Conjunction-headed/Prague:**
   - The sentence is represented with a tree structure where the conjunction "and" is the head of the clause, and the other elements are dependent on it.

4. **Multi-headed/London:**
   - The sentence is represented with a tree structure where each element in the list ("Lisa," "Bart," and "Maggie") is considered a separate head, with "Homer loves" being the main verb.

Each structure shows how the sentence can be parsed differently based on the dependency theory used.</sample>
    <sample id="1358">The image is a slide from a presentation titled "Dependency Structure of Coordination." It discusses different dependency structures for coordinating clauses, specifically using the example sentence: "Homer loves Lisa, Bart, and Maggie."

The slide lists four different dependency structures:

1. **Bouquet/Stanford (Universal Dependencies):**
   - The structure shows that "Homer" is the subject, "loves" is the verb, and "Lisa," "Bart," and "Maggie" are objects, each connected to "loves" by a dependency arrow.

2. **Chain/Moscow:**
   - Similar to the Bouquet/Stanford structure, it shows "Homer" as the subject, "loves" as the verb, and "Lisa," "Bart," and "Maggie" as objects, each connected to "loves" by a dependency arrow.

3. **Conjunction-headed/Prague:**
   - This structure also shows "Homer" as the subject, "loves" as the verb, and "Lisa," "Bart," and "Maggie" as objects, each connected to "loves" by a dependency arrow.

4. **Multi-headed/London:**
   - This structure is similar to the others, with "Homer" as the subject, "loves" as the verb, and "Lisa," "Bart," and "Maggie" as objects, each connected to "loves" by a dependency arrow.

Each structure represents a different way of analyzing the dependencies within the sentence, highlighting how the words are interconnected in terms of their grammatical roles.</sample>
    <sample id="1359">The image is a slide from a presentation titled "Dependency Structure of Coordination." It discusses different dependency structures for coordinating phrases, using the sentence "Homer loves Lisa, Bart, and Maggie" as an example. The slide lists four different dependency structures:

1. **Bouquet/Stanford (Universal Dependencies):**
   - The sentence is shown with dependencies where each noun phrase ("Lisa," "Bart," "Maggie") is connected to the verb "loves."

2. **Chain/Moscow:**
   - Similar to the Bouquet structure, but the dependencies are shown in a chain-like manner.

3. **Conjunction-headed/Prague:**
   - The conjunction "and" is considered the head of the coordination, with all other elements dependent on it.

4. **Multi-headed/London:**
   - Each element in the coordination ("Lisa," "Bart," "Maggie") is considered a head, with multiple dependencies pointing to them.

The slide also includes a speaker's name, Adam Przepiórkowski, in the top right corner.</sample>
    <sample id="1360">The image is a slide from a presentation titled "Dependency Structure of Coordination." It discusses different dependency structures for coordinating clauses, using the sentence "Homer loves Lisa, Bart, and Maggie" as an example. The slide lists four different dependency structures:

1. **Bouquet/Stanford (Universal Dependencies):**
   - The sentence is represented with arcs connecting "Homer," "loves," "Lisa," "Bart," and "Maggie."

2. **Chain/Moscow:**
   - The sentence is represented similarly to the Bouquet/Stanford structure but with a chain-like arc connecting all elements.

3. **Conjunction-headed/Prague:**
   - The sentence is represented with a single arc pointing to "Lisa, Bart, and Maggie" from "Homer loves."

4. **Multi-headed/London:**
   - The sentence is represented with multiple arcs pointing to each individual element ("Lisa," "Bart," and "Maggie") from "Homer loves."

Each structure is visually depicted with arrows indicating the dependencies between the words in the sentence.</sample>
    <sample id="1361">The image is a slide from a presentation titled "Dependency Length Minimization (DLM)." The slide discusses how word order tends to minimize dependency lengths in sentences. It includes two examples:

1. **Good Example:**
   - Sentence: "Marge read it yesterday."
   - Dependency structure:
     - "Marge" → "read"
     - "read" → "it"
     - "it" → "yesterday"
   - The dependencies are short, making it a good example.

2. **Bad Example:**
   - Sentence: "Marge read yesterday it."
   - Dependency structure:
     - "Marge" → "read"
     - "read" → "yesterday"
     - "yesterday" → "it"
   - The dependencies are longer, making it a bad example.

3. **Good Example with More Words:**
   - Sentence: "Marge read this absolutely fascinating book about bees yesterday."
   - Dependency structure:
     - "Marge" → "read"
     - "read" → "this"
     - "this" → "absolutely"
     - "absolutely" → "fascinating"
     - "fascinating" → "book"
     - "book" → "about"
     - "about" → "bees"
     - "bees" → "yesterday"
   - The dependencies are short, making it a good example.

4. **Good Example with Different Word Order:**
   - Sentence: "Marge read yesterday this absolutely fascinating book about bees."
   - Dependency structure:
     - "Marge" → "read"
     - "read" → "yesterday"
     - "yesterday" → "this"
     - "this" → "absolutely"
     - "absolutely" → "fascinating"
     - "fascinating" → "book"
     - "book" → "about"
     - "about" → "bees"
   - The dependencies are short, making it a good example.</sample>
    <sample id="1362">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Merge read it yesterday.
  - good

- Merge read yesterday it.
  - bad

- Merge read this absolutely fascinating book about bees yesterday.
  - good

- Merge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1363">The image is a slide from a presentation titled "Dependency Length Minimization (DLM)." The slide discusses how word order tends to minimize dependency lengths in sentences. It includes examples of sentence structures with annotations showing dependency paths and their lengths.

1. The first example shows the sentence: "Marge read it yesterday." The dependency path is labeled as 1-2, indicating a short dependency length.
2. The second example shows the same sentence but with the words rearranged: "Marge read yesterday it." The dependency path is labeled as 1-2, indicating a longer dependency length.
3. The third example shows a more complex sentence: "Marge read this absolutely fascinating book about bees yesterday." The dependency path is labeled as 1-4-7, indicating a longer dependency length.
4. The fourth example shows the same complex sentence but with the words rearranged: "Marge read yesterday this absolutely fascinating book about bees." The dependency path is labeled as 1-5, indicating a shorter dependency length.

The slide categorizes these examples as "good" for the first two and "bad" for the last two, suggesting that the first two examples have better word order according to DLM principles.</sample>
    <sample id="1364">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Merge read it yesterday.
  - good

- Merge read yesterday it.
  - bad

- Merge read this absolutely fascinating book about bees yesterday.
  - good

- Merge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1365">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Merge read it yesterday.
  - good

- Merge read yesterday it.
  - bad

- Merge read this absolutely fascinating book about bees yesterday.
  - good

- Merge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1366">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1367">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1368">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1369">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1370">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1371">Dependency Length Minimization (DLM)

Word order tends to minimize dependency lengths:

- Marge read it yesterday.
  - good

- Marge read yesterday it.
  - bad

- Marge read this absolutely fascinating book about bees yesterday.
  - good

- Marge read yesterday this absolutely fascinating book about bees.
  - good</sample>
    <sample id="1372">The image is a slide from a presentation titled "Conjunct Lengths in English." The content of the slide discusses statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al., 1993; Ficler and Goldberg, 2016). The key points are:

- Left conjuncts tend to be shorter (observed before).
- This tendency grows with length difference (briefly noticed in Gibson et al., 1996: 88–90).
- But only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed).
- Not when it is on the right (Ted and Ned laughed).

The slide also includes a reference to Adam Przepiórkowski in the top right corner.</sample>
    <sample id="1373">The image is a slide from a presentation titled "Conjunct Lengths in English." The content of the slide discusses statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016). The key points are:

- Left conjuncts tend to be shorter (observed before).
- This tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90).
- But only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed).
- Not when it is on the right (Ted and Ned laughed).

The slide also includes a reference to Adam Przepiórkowski in the top right corner.</sample>
    <sample id="1374">The image contains a slide titled "Conjunct Lengths in English." The content of the slide is as follows:

---

**Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):**

- **left conjuncts tend to be shorter (observed before),**
- **this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),**
- **but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed),**
- **not when it is on the right (Ted and Ned laughed).**

---

This slide discusses the observation that left conjuncts in coordinated structures tend to be shorter than their counterparts, and this tendency increases with the length difference between the conjuncts. However, this effect is observed only when the governor (the word or phrase that governs the coordination) is on the left side or absent, not when it is on the right side.</sample>
    <sample id="1375">The image is a slide from a presentation titled "Conjunct Lengths in English." The content of the slide discusses statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016). The key points are:

- Left conjuncts tend to be shorter (observed before),
- This tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),
- but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed),
- not when it is on the right (Ted and Ned laughed).

The slide also includes a reference to Adam Przepiórkowski in the top right corner.</sample>
    <sample id="1376">The image contains a slide titled "Conjunct Lengths in English." The content of the slide is as follows:

---

**Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):**

- **left conjuncts tend to be shorter (observed before),**
- **this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),**
- **but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed),**
- **not when it is on the right (Ted and Ned laughed).**

---

This slide discusses the observation that left conjuncts in coordinated structures tend to be shorter than their counterparts on the right, and this tendency increases with the length difference between the conjuncts. However, this effect is observed only when the governor (the word or phrase that governs the coordination) is on the left or absent, not when it is on the right.</sample>
    <sample id="1377">The image contains a slide titled "Conjunct Lengths in English." The content of the slide is as follows:

---

**Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993, Ficler and Goldberg 2016):**

- **left conjuncts tend to be shorter (observed before),**
- **this tendency grows with length difference (briefly noticed in Gibson et al. 1996: 88–90),**
- **but only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed)**
- **not when it is on the right (Ted and Ned laughed).**

---

This slide discusses the observation that left conjuncts in coordinated structures tend to be shorter than their counterparts on the right, and this tendency increases with the length difference between the conjuncts. However, this pattern only holds true when the governor (the word or phrase that governs the coordination) is on the left or absent, not when it is on the right.</sample>
    <sample id="1378">The image is a slide from a presentation titled "Conjunct Lengths in English." The content of the slide discusses statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al., 1993; Ficler and Goldberg, 2016). The key points are:

- Left conjuncts tend to be shorter (observed before).
- This tendency grows with length difference (briefly noticed in Gibson et al., 1996: 88–90).
- But only when the governor is on the left or absent (I saw Bart and Lisa; Homer came and sneezed).
- Not when it is on the right (Ted and Ned laughed).

The slide also includes a reference to Adam Przepiórkowski in the top right corner.</sample>
    <sample id="1379">The image is a slide from a presentation titled "Conjunct Lengths in English." The content of the slide discusses statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al., 1993; Ficler and Goldberg, 2016). The key points are:

- Left conjuncts tend to be shorter (observed before).
- This tendency grows with length difference (briefly noticed in Gibson et al., 1996: 88–90).
- But only when the governor is on the left or absent (e.g., "I saw Bart and Lisa; Homer came and sneezed").
- Not when it is on the right (e.g., "Ted and Ned laughed").

The slide also includes a figure showing proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths, with confidence bands.</sample>
    <sample id="1380">The image is a slide from a presentation, featuring six graphs arranged in two rows and three columns. Each graph represents data related to the proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths (with confidence bands). The graphs are labeled as follows:

1. **NO governor (length in CHARACTERS)**
2. **NO governor (length in SYLLABLES)**
3. **NO governor (length in WORDS)**
4. **Governor on the LEFT (length in CHARACTERS)**
5. **Governor on the LEFT (length in SYLLABLES)**
6. **Governor on the LEFT (length in WORDS)**
7. **Governor on the RIGHT (length in CHARACTERS)**
8. **Governor on the RIGHT (length in SYLLABLES)**
9. **Governor on the RIGHT (length in WORDS)**

Each graph includes a line representing the proportion of shorter left conjuncts, with a slope and p-value provided for each. The x-axis represents the absolute difference in characters, syllables, or words, while the y-axis represents the proportion of shorter left conjuncts.

At the bottom of the slide, there is a caption that reads: "Figure 1: Proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths (with confidence bands)."</sample>
    <sample id="1381">The image contains six graphs, each representing different scenarios related to the proportion of shorter left conjuncts depending on the absolute difference of conjunct lengths (with confidence bands). The graphs are categorized into three groups based on the "NO governor" and "Governor on the LEFT" and "Governor on the RIGHT" conditions, with each group further divided by the length measured in characters, syllables, or words.

1. **NO governor (length in CHARACTERS):**
   - Slope: 3.99e-03
   - p-value: 1.36e-13

2. **NO governor (length in SYLLABLES):**
   - Slope: 1.25e-02
   - p-value: 1.8e-13

3. **NO governor (length in WORDS):**
   - Slope: 2.77e-02
   - p-value: 2.42e-16

4. **Governor on the LEFT (length in CHARACTERS):**
   - Slope: 5.57e-03
   - p-value: 2e-26

5. **Governor on the LEFT (length in SYLLABLES):**
   - Slope: 1.76e-02
   - p-value: 1.86e-12

6. **Governor on the LEFT (length in WORDS):**
   - Slope: 2.57e-02
   - p-value: 1e-16

7. **Governor on the RIGHT (length in CHARACTERS):**
   - Slope: 1.22e-03
   - p-value: 0.25

8. **Governor on the RIGHT (length in SYLLABLES):**
   - Slope: 2.22e-03
   - p-value: 0.554

9. **Governor on the RIGHT (length in WORDS):**
   - Slope: -7.49e-04
   - p-value: 0.921

At the bottom of the image, there is a caption that reads:
"Figure 1: Proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths (with confidence bands)."</sample>
    <sample id="1382">The image is a slide from a presentation, titled "Figure 1: Proportions of shorter left conjuncts depending on the absolute difference of conjunct lengths (with confidence bands)." The slide contains six graphs arranged in two rows and three columns. Each graph represents different conditions related to the length of conjuncts measured in characters, syllables, and words.

### Top Row:
1. **NO governor (length in CHARACTERS):**
   - The graph shows a positive slope with a p-value of \(3.99e-03\).
   - The x-axis represents the absolute difference in characters.
   - The y-axis represents the proportion of shorter left conjuncts.

2. **NO governor (length in SYLLABLES):**
   - The graph shows a positive slope with a p-value of \(1.25e-02\).
   - The x-axis represents the absolute difference in syllables.
   - The y-axis represents the proportion of shorter left conjuncts.

3. **NO governor (length in WORDS):**
   - The graph shows a positive slope with a p-value of \(2.77e-02\).
   - The x-axis represents the absolute difference in words.
   - The y-axis represents the proportion of shorter left conjuncts.

### Bottom Row:
4. **Governor on the LEFT (length in CHARACTERS):**
   - The graph shows a positive slope with a p-value of \(5.57e-03\).
   - The x-axis represents the absolute difference in characters.
   - The y-axis represents the proportion of shorter left conjuncts.

5. **Governor on the LEFT (length in SYLLABLES):**
   - The graph shows a positive slope with a p-value of \(1.76e-02\).
   - The x-axis represents the absolute difference in syllables.
   - The y-axis represents the proportion of shorter left conjuncts.

6. **Governor on the LEFT (length in WORDS):**
   - The graph shows a positive slope with a p-value of \(2.57e-02\).
   - The x-axis represents the absolute difference in words.
   - The y-axis represents the proportion of shorter left conjuncts.

7. **Governor on the RIGHT (length in CHARACTERS):**
   - The graph shows a positive slope with a p-value of \(1.22e-03\).
   - The x-axis represents the absolute difference in characters.
   - The y-axis represents the proportion of shorter left conjuncts.

8. **Governor on the RIGHT (length in SYLLABLES):**
   - The graph shows a positive slope with a p-value of \(2.22e-03\).
   - The x-axis represents the absolute difference in syllables.
   - The y-axis represents the proportion of shorter left conjuncts.

9. **Governor on the RIGHT (length in WORDS):**
   - The graph shows a negative slope with a p-value of \(7.49e-04\).
   - The x-axis represents the absolute difference in words.
   - The y-axis represents the proportion of shorter left conjuncts.

Each graph includes a confidence band around the regression line, indicating the range within which the true relationship lies with a certain level of confidence.</sample>
    <sample id="1383">Compatibility with Dependency Structures of Coordination

- Bouquet/Stanford (Universal Dependencies):
  Homer loves Lisa, Bart, and Maggie.
  NO

- Chain/Moscow:
  Homer loves Lisa, Bart, and Maggie.
  NO

- Conjunction-headed/Prague:
  Homer loves Lisa, Bart, and Maggie.
  YES

- Multi-headed/London:
  Homer loves Lisa, Bart, and Maggie.
  YES</sample>
    <sample id="1384">The image contains the following text:

"See the paper for the full argument!
Talk to us at the poster session!"</sample>
    <sample id="1385">The name of the speaker is Matthias Lindemann, Alexander Koller, and Ivan Titov.</sample>
    <sample id="1386">Cross-lingual transfer refers to training on one source language and transferring the knowledge to another language.</sample>
    <sample id="1387">The affiliations of the authors are Saarland University, Amazon Alexa, and the University of Vienna.</sample>
    <sample id="1388">The authors use AL / AL_CA as the latency measure.</sample>
    <sample id="1416">The drawbacks of tree-based methods include the need for pre/post-processing logical forms and grammar induction.</sample>
    <sample id="1417">The authors, Shuheng Liu and Alan Ritter, are affiliated with the School of Interactive Computing at Georgia Institute of Technology.</sample>
    <sample id="1495">ABC-Eval stands for Annotating Behaviors in Chat.</sample>
    <sample id="1496">2016</sample>
    <sample id="1527">The affiliations of the authors of the paper are The University of Edinburgh, Saarland University, and the University of Amsterdam.</sample>
    <sample id="1528">The name of the speaker is Siyu Yuan.</sample>
    <sample id="1529">There are five authors involved in the paper.</sample>
    <sample id="1530">The approach is compared to a state-of-the-art architecture specifically tailored for SimulST.</sample>
    <sample id="1531">MULTIINSTRUCT: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning

Zhiyang Xu*, Ying Shen*, Lifu Huang
Department of Computer Science, Virginia Tech

*Equal Contribution</sample>
    <sample id="1532">Pre-trained Language Models for Downstream Tasks

(A) Pretrain–finetune (BERT, T5)
- Pretrained LM
  - Finetune on task A
  - Inference on task A
  - Typically requires many task-specific examples
  - One specialized model for each task

(B) Prompting (GPT-3)
- Pretrained LM
  - Improve performance via few-shot prompting or prompt engineering
  - Inference on task A

(C) Instruction tuning (FLAN)
- Pretrained LM
  - Instruction-tune on many tasks: B, C, D, ...
  - Model learns to perform many tasks via natural language instructions
  - Inference on unseen task

Figure 2: Comparing instruction tuning with pretrain–finetune and prompting.

Image credit: Wei, Jason, et al. "Finetuned language models are zero-shot learners."</sample>
    <sample id="1533">Pre-trained Language Models for Downstream Tasks

(A) Pretrain–finetune (BERT, T5)
- Pretrained LM
  - Finetune on task A
  - Inference on task A
  - Typically requires many task-specific examples
  - One specialized model for each task

(B) Prompting (GPT-3)
- Pretrained LM
  - Improve performance via few-shot prompting or prompt engineering
  - Inference on task A

(C) Instruction tuning (FLAN)
- Pretrained LM
  - Instruction-tune on many tasks: B, C, D, ...
  - Model learns to perform many tasks via natural language instructions
  - Inference on unseen task

Figure 2: Comparing instruction tuning with pretrain–finetune and prompting.

Image credit: Wei, Jason, et al. "Finetuned language models are zero-shot learners."</sample>
    <sample id="1534">The English content in the image is "Language-only."</sample>
    <sample id="1535">Instruction Tuning on
Multimodal Pre-trained Models</sample>
    <sample id="1536">Imbalance in Instructional Datasets between NLP and Multimodal

1600+ Language-only instruction tasks</sample>
    <sample id="1537">The image contains a slide with the following text:

---

**Imbalance in Instructional Datasets between NLP and Multimodal**

- **1600+ Language-only instruction tasks**
- **NO large-scale, publicly-available multimodal instruction tasks**

---

Below the main content, there is a citation:
- Wang, Yizhong, et al. "Benchmarking generalization via in-context instructions on 1,600+ language tasks." arXiv preprint arXiv:</sample>
    <sample id="1538">MULTIINSTRUCT

The first multimodal instruction tuning benchmark dataset

- 62 diverse multimodal tasks
- 10 broad groups
- 5 expert-written instructions

Figure 2: Task Groups Included in MULTIINSTRUCT. The yellow boxes represent tasks used for evaluation, while the white boxes indicate tasks used for training.</sample>
    <sample id="1539">MULTIINSTRUCT

The first multimodal instruction tuning benchmark dataset

- 62 diverse multimodal tasks
- 10 broad groups
- 5 expert-written instructions

Figure 2: Task Groups Included in MULTIINSTRUCT. The yellow boxes represent tasks used for evaluation, while the white boxes indicate tasks used for training.</sample>
    <sample id="1540">OFA (One For All)
- A unified multi-modal pre-trained model that is capable of performing both understanding and generation tasks with single or multiple modalities.
- OFA has a unified vocabulary for language, image tokens and the coordinates of a bounding box.

Wang, Peng, et al. "Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework."</sample>
    <sample id="1541">The image is a slide from a presentation titled "MULTIINSTRUCT." It illustrates four tasks within the MULTINSTRUCT framework, each with an input and output example:

1. **Grounded Caption**
   - **Input:** Generate a caption for &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Output:** blue and white tennis racquet

2. **Text Localization**
   - **Input:** Select the region that contains the text “den.”
   - **Options:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Output:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referring Expression Selection**
   - **Input:** Select the region of the object described by “A blue train in the front.”
   - **Options:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Output:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Question-Image Matching**
   - **Input:** Given the content of image, do you have enough information to answer “Is it a sunny day?”
   - **Options:** “the question is relevant to the image” or “the question is irrelevant to the image”
   - **Output:** the question is irrelevant to the image

The slide is labeled as Figure 1: Example Instances from MULTINSTRUCT for Four Tasks.</sample>
    <sample id="1542">The image is a slide from a presentation titled "MULTIINSTRUCT." It illustrates four tasks within the MULTINSTRUCT framework, each with an input and output example:

1. **Grounded Caption**
   - **Input:** Generate a caption for &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Output:** blue and white tennis racquet

2. **Text Localization**
   - **Input:** Select the region that contains the text “den.”
   - **Options:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Output:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referring Expression Selection**
   - **Input:** Select the region of the object described by “A blue train in the front.”
   - **Options:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Output:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Question-Image Matching**
   - **Input:** Given the content of image, do you have enough information to answer “Is it a sunny day?”
   - **Options:** “the question is relevant to the image” or “the question is irrelevant to the image”
   - **Output:** the question is irrelevant to the image

The slide is labeled as Figure 1: Example Instances from MULTINSTRUCT for Four Tasks.</sample>
    <sample id="1543">The image is a slide from a presentation titled "MULTIINSTRUCT." It illustrates four tasks within the MULTINSTRUCT framework, each with an input and output example:

1. **Grounded Caption**
   - **Input:** Generate a caption for &lt;bin_198&gt; &lt;bin_32&gt; &lt;bin_400&gt; &lt;bin_193&gt;.
   - **Output:** blue and white tennis racquet

2. **Text Localization**
   - **Input:** Select the region that contains the text “den.”
   - **Options:** &lt;bin_206&gt; &lt;bin_119&gt; &lt;bin_448&gt; &lt;bin_181&gt; ||||&lt;bin_357&gt; &lt;bin_518&gt; &lt;bin_456&gt; &lt;bin_574&gt; ||||&lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;
   - **Output:** &lt;bin_229&gt; &lt;bin_604&gt; &lt;bin_304&gt; &lt;bin_654&gt;

3. **Referring Expression Selection**
   - **Input:** Select the region of the object described by “A blue train in the front.”
   - **Options:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt; ||||&lt;bin_88&gt; &lt;bin_291&gt; &lt;bin_203&gt; &lt;bin_473&gt; ||||&lt;bin_193&gt; &lt;bin_339&gt; &lt;bin_247&gt; &lt;bin_442&gt;
   - **Output:** &lt;bin_242&gt; &lt;bin_180&gt; &lt;bin_736&gt; &lt;bin_475&gt;

4. **Question-Image Matching**
   - **Input:** Given the content of image, do you have enough information to answer “Is it a sunny day?”
   - **Options:** “the question is relevant to the image” or “the question is irrelevant to the image”
   - **Output:** the question is irrelevant to the image

At the bottom of the slide, there is a caption: "Figure 1: Example Instances from MULTINSTRUCT for Four Tasks."</sample>
    <sample id="1544">The English content in the image is:

"Multi-modal Instruction Tuning"</sample>
    <sample id="1545">Multi-Modal Instruction Turning

- Training Dataset Construction:
  - Use 53 tasks from 9 groups for training.
  - Sample 10,000 instances per task.

- Testing Dataset Construction:
  - Reserve the entire Commonsense Reasoning group for testing.
  - Select additional 5 tasks from VQA and Miscellaneous groups.
  - We use all the instances in the test split for each task.
  - Randomly sample 20 tasks from the test split of Natural Instructions dataset as unseen tasks for NLP.</sample>
    <sample id="1546">Multi-Modal Instruction Turning

- Training Dataset Construction:
  - Use 53 tasks from 9 groups for training.
  - Sample 10,000 instances per task.

- Testing Dataset Construction:
  - Reserve the entire Commonsense Reasoning group for testing.
  - Select additional 5 tasks from VQA and Miscellaneous groups.
  - We use all the instances in the test split for each task.
  - Randomly sample 20 tasks from the test split of Natural Instructions dataset as unseen tasks for NLP.</sample>
    <sample id="1547">Implementation Details

- Training details:
  ○ Pre-trained OFA-Large model (472M)
  ○ Mix all the instances for all tasks.
  ○ Each instance is randomly combined with one of its five instruction templates.

- Testing details:
  ○ For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
  ○ We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1548">Implementation Details

- Training details:
  - Pre-trained OFA-Large model (472M)
  - Mix all the instances for all tasks.
  - Each instance is randomly combined with one of its five instruction templates.

- Testing details:
  - For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
  - We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1549">Implementation Details

- Training details:
  - Pre-trained OFA-Large model (472M)
  - Mix all the instances for all tasks.
  - Each instance is randomly combined with one of its five instruction templates.

- Testing details:
  - For each task, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment.
  - We report the mean and maximum performance and the standard deviation of the performance across all five experiments.</sample>
    <sample id="1550">Evaluation Metrics

- For multi-modal classification tasks (Visual Entailment, Visual Spatial Reasoning, Natural Language Visual Reasoning, and Disaster Type Classification) we report the Accuracy.
- For multi-modal generation tasks (Commonsense VQA, Text VQA, Grounded VQA, Visual Text Extraction, and Visual Dialogue) we report the Rouge-L.
- For NLP tasks, we report Rouge-L.

We also compute the aggregated performance for each model based on the mean of the model's performance on all multimodal and NLP unseen tasks. We use Rouge-L as the performance score for most tasks, and Accuracy for tasks that only have accuracy as a metric.</sample>
    <sample id="1551">Sensitivity

How sensitive the model is towards to **variety** of instructions for the **same task**:

- Ability to consistently produce the same results for the same task, regardless of slight variations in the wording of instructions.

\[
\mathbb{E}_{t \in T} \left[ \frac{\sigma_{i \in I^t} \left[ \mathbb{E}_{(x,y) \in D^t} [L(f_\theta(i,x), y)] \right]}{\mu_{i \in I^t} \left[ \mathbb{E}_{(x,y) \in D^t} [L(f_\theta(i,x), y)] \right]} \right]
\]</sample>
    <sample id="1552">Effectiveness of Instruction Tuning on MULTIINSTRUCT

Table 1: Zero-shot Performance on Multimodal Commonsense Reasoning. The best performance is in bold.

| Model | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|-------|-----------------|-------------------|--------------------------|------|
| OFA   | 17.93           | 48.99             | 52.01                    | 56.06 |
| OFATaskName | -              | -                | -                        | -    |
| OFAMultiInstruct | 52.01 | 50.60 ± 1.12 | 33.01 | 55.96 |

Transfer Learning from NATURAL INSTRUCTIONS
| Model | OFANaturalInstruct | OFAMixedInstruct | OFASeqInstruct |
|-------|--------------------|------------------|-----------------|
| Max   | 27.15              | 50.40            | 50.93           |
| Avg ± Std | 14.99 ± 9.12       | 49.34 ± 1.04     | 50.07 ± 1.07    |
| ACC   | 7.35               | 31.31            | 31.23           |

Table 2: Zero-shot Performance on Question Answering and Miscellaneous. The best performance is in bold.

| Model | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|-------|----------|--------------|------------------------|-----------------|------------------------------|
| OFA   | 15.21    | 23.80        | 36.31                  | 45.46           | 14.30                        |
| OFATaskName | -        | -            | -                      | -               | -                            |
| OFAMultiInstruct | 27.22   | 46.32        | 74.35                  | 46.38           | 64.88                        |

Transfer Learning from NATURAL INSTRUCTIONS
| Model | OFANaturalInstruct | OFAMixedInstruct | OFASeqInstruct |
|-------|--------------------|------------------|-----------------|
| Max   | 5.59               | 24.15            | 27.03           |
| Avg ± Std | 5.40 ± 0.24        | 23.67 ± 0.47     | 26.67 ± 0.47    |
| ACC   | 0.00               | 63.79            | 64.19           |</sample>
    <sample id="1553">Effectiveness of Instruction Tuning on MULTIINSTRUCT

Table 1: Zero-shot Performance on Multimodal Commonsense Reasoning. The best performance is in bold.

| Model | Commonsense VQA | Visual Entailment | Visual Spatial Reasoning | NLVR |
|-------|-----------------|-------------------|--------------------------|------|
| OFA   | 17.93           | 48.99             | 52.01                    | 56.06 |
| OFATaskName | -              | -                | -                        | -    |
| OFAMultiInstruct | 52.01 | 50.60 ± 1.12 | 33.01 | 55.96 |

Transfer Learning from NATURAL INSTRUCTIONS
| Model | OFANaturalInstruct | OFAMixedInstruct | OFASeqInstruct |
|-------|--------------------|------------------|-----------------|
| Max   | 27.15              | 50.40            | 50.93           |
| Avg±Std | 14.99 ± 9.12       | 49.34 ± 1.04     | 50.07 ± 1.07    |
| ACC   | 7.35               | 31.31            | 31.23           |

Table 2: Zero-shot Performance on Question Answering and Miscellaneous. The best performance is in bold.

| Model | Text VQA | Grounded VQA | Visual Text Extraction | Visual Dialogue | Disaster Type Classification |
|-------|----------|--------------|------------------------|-----------------|------------------------------|
| OFA   | 15.21    | 23.80        | 36.31                  | 45.46           | 14.30                        |
| OFATaskName | -        | -            | -                      | -               | -                            |
| OFAMultiInstruct | 27.22   | 46.32        | 74.35                  | 46.38           | 64.88                        |

Transfer Learning from NATURAL INSTRUCTIONS
| Model | OFANaturalInstruct | OFAMixedInstruct | OFASeqInstruct |
|-------|--------------------|------------------|-----------------|
| Max   | 5.59               | 24.15            | 27.03           |
| Avg±Std | 5.40 ± 0.24        | 23.67 ± 0.47     | 26.67 ± 0.47    |
| ACC   | 0.00               | 63.79            | 64.19           |</sample>
    <sample id="1554">The image is a slide from a presentation titled "Impact of Increasing Multimodal Instruction Task Clusters." The slide lists various task clusters and their corresponding tasks:

- Img Und: VQA + Image Understanding
- Grounding: Grounded Matching + Grounded Generation
- MISC, ITM: Temporal Ordering + Miscellaneous + Image Text Matching
- Relation: Visual Relationship
- Region: Region Understanding
- NLP: NLP tasks

On the right side of the slide, there is a graph labeled "Figure 3: Model Performance as the Number of Multimodal Instruction Task Clusters Increases." The x-axis represents the number of task clusters, and the y-axis represents aggregated performance. The graph shows three lines representing different performance types: Max, Avg, and Sensitivity. The lines indicate how the model's performance changes as more task clusters are added.</sample>
    <sample id="1555">Effect of Diverse Instructions on Instruction Tuning

- OFA finetuned on 5 instructions achieves much higher aggregated performance on all evaluation tasks and shows lower sensitivity.

Table 3: Effect of Different Number of Instructions.
Performance of OFAMultiInstruct finetuned on different numbers of instructions.

| # of Instructions | Aggregated Performance ↑ | Sensitivity ↓ |
|-------------------|--------------------------|---------------|
| 1 Instruction      | 42.81                    | 24.62         |
| 5 Instructions     | 47.82                    | 10.45         |</sample>
    <sample id="1556">Effect of Fine-tuning Strategies on Model Sensitivity

- Instruction tuning on MultiInstruct can significantly reduce the sensitivity of OFA.
- Transfer learning from Natural Instructions dataset can further reduce the sensitivity of the model.

Figure 4: Model Sensitivity on Unseen Evaluation Tasks. Lower is better.</sample>
    <sample id="1557">Zero-Shot Performance on NLP Tasks

- Instruction Tuning on MultiInstruct can improve zero-shot performance on unseen NLP tasks.
- The transfer learning strategy MixedInstruct can best preserve the zero-shot capability gained on Natural Instructions dataset.

Table 4: Zero-shot Performance on NLP tasks. The performance is reported in Rouge-L and the best performance is in bold.

| Model | RougeL |
|-------|--------|
| OFA   | 2.25   |
| OFAMultiInstruct | 12.18 |
| OFANaturalInstructions | 43.61 |
| OFAMixedInstructions | 43.32 |
| OFASeqInstructions | 30.79 |

The table shows the performance of different models on zero-shot NLP tasks, with the best performance highlighted in bold.</sample>
    <sample id="1558">Conclusion

- First large-scale multi-modal instruction tuning dataset.
  - Contains 62 multi-modal tasks from 10 broad categories.
- Significantly improve the zero-shot capability of OFA via instruction tuning.
- Explore several transferring learning techniques and show their benefits.
- Design a new metric sensitivity.</sample>
    <sample id="1559">One More Thing!

We are collecting a much larger multimodal instruction tuning dataset with around 150 additional vision-language tasks and we will release them soon!</sample>
  </task>
</testset>