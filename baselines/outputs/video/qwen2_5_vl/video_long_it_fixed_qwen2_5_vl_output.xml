<testset name="MCIF Baselines" type="output">
  <task track="long" text_lang="it">
    <sample id="0">I principali dati per i modelli linguistici vengono raccolti da internet, news media e social media.</sample>
    <sample id="1">McGill University, Mila, Microsoft Research</sample>
    <sample id="2">Il presente lavoro si concentra sulla creazione di un modello di pre-allenamento multi-modale, chiamato LayoutMask, progettato per migliorare l'interazione tra testo e layout in documenti visivamente ricchi. L'obiettivo principale è risolvere i problemi di ordine di lettura che possono emergere in contesti di documenti con molte informazioni visive. Il modello LayoutMask introduce una rappresentazione locale della posizione 1D invece della posizione globale, utilizzando una strategia di maschera innovativa per promuovere l'interazione testo-layout. Questo approccio è integrato in un pre-allenamento multi-modale che comprende la modellizzazione del linguaggio nascosto e la modellizzazione delle posizioni nascoste. Gli esperimenti dimostrano che il modello LayoutMask ottiene risultati significativamente migliori rispetto ai metodi esistenti, con un F1-score medio del 96,56% su quattro dataset diversi. Questo lavoro rappresenta un passo avanti nel campo dell'intelligenza artificiale applicata alla comprensione dei documenti, offrendo una soluzione efficace per la gestione dei dati strutturati e visivi.</sample>
    <sample id="3">Il contenuto inglese è già stato tradotto in italiano nel video, quindi non ci sono ulteriori traduzioni necessarie.</sample>
    <sample id="4">Il nome della relatrice o del relatore è Kayo Yin.</sample>
    <sample id="5">Hanno utilizzato il modello TS XL per ottenere l'accuratezza dell'82%-87%.</sample>
    <sample id="6">Il presente lavoro si concentra sulla creazione di un modello di riassunto multilingue e interlinguale, chiamato M2MS (Many-to-many Summarization), che può elaborare documenti in qualsiasi lingua di origine e generare un riassunto in qualsiasi lingua di destinazione. L'approccio proposto unifica due tipologie di riassunto: il riassunto multilingue (MLS) e il riassunto interlinguale (CLS). Il modello M2MS è stato sviluppato attraverso una preaddestramento a tre fasi che comprende la modellizzazione linguistica, l'abilità interlinguale e la capacità di riassunto. È stato testato su un dataset di Wikipedia multilingue e ha dimostrato una maggiore capacità di trasferimento tra diverse lingue rispetto ai modelli MLS e CLS tradizionali. Inoltre, il modello PISCES, un modello preaddestrato M2MS, è stato utilizzato per migliorare le prestazioni del modello. Questo lavoro introduce nuove direzioni di ricerca nel campo del riassunto multilingue e interlinguale, offrendo potenziali applicazioni nell'elaborazione di documenti multilingui e nell'automazione della traduzione.</sample>
    <sample id="7">Sì, i tagger CoNLL-2003 funzionano ancora.</sample>
    <sample id="8">Il metodo di valutazione umana proposto introduce un nuovo approccio chiamato ABC-Eval, che valuta le risposte dei bot basandosi su tre criteri principali: Coerenza, Consistenza e Comportamenti Emotivi. Questo metodo offre una valutazione più dettagliata e specifica delle interazioni umano-bots, migliorando così l'accuratezza e l'efficacia della valutazione.</sample>
    <sample id="9">Il successo dell'approccio scarsamente supervisionato si basa in larga misura sull'uso di dati etichettati debolmente e su tecniche di apprendimento che riescono a generalizzare bene anche quando i dati sono noiosi.</sample>
    <sample id="10">Per migliorare il punteggio, si possono fare i seguenti progressi:

1. **Accesso a più informazioni**: Assicurarsi che il modello abbia accesso a una maggiore quantità e varietà di dati.
2. **Miglioramento dell'architettura del modello**: Sviluppare architetture di modelli più avanzate o adattare le esistenti per migliorare la precisione.
3. **Optimizzazione dei parametri**: Tunare i parametri del modello per ottimizzare i risultati.
4. **Introduzione di nuove tecniche di apprendimento**: Adottare tecniche di apprendimento più innovative o avanzate.
5. **Aumento della qualità dei dati**: Utilizzare dati di qualità superiore per addestrare il modello.
6. **Implementazione di tecniche di ottimizzazione**: Applicare tecniche di ottimizzazione avanzate per migliorare l'efficienza del modello.
7. **Monitoraggio e feedback**: Implementare un sistema di monitoraggio e feedback per identificare e risolvere eventuali problemi di prestazione.

Questi sono solo alcuni dei possibili progressi che possono essere fatti per migliorare il punteggio.</sample>
    <sample id="11">L'abstract del video si concentra sulla capacità dei modelli di linguaggio naturale di comprendere e generare battute di scherzo, esaminando i risultati di un contest di captions organizzato da The New Yorker. L'analisi si basa su tre principali benchmark: Matching, Quality Ranking e Explanation Generation. I risultati mostrano che i modelli, come CLIP-ViT-L/14@336px (finetuned) e OFA-Huge → TS-Large, hanno raggiunto prestazioni significative, con tassi di accuracy tra il 51,8% e il 65,0%. Tuttavia, la comprensione umana delle battute di scherzo è ancora superiore, con un punteggio di 94,0% per l'Human Estimate From Pixels (FP). Questo evidenzia che, nonostante le notevoli capacità dei modelli, ci sono ancora limiti nell'interpretazione del senso humoristico. Inoltre, il video discute della necessità di testare ulteriormente le ipotesi attraverso valutazioni umane, sottolineando l'importanza di comprendere completamente il contesto e la cultura del linguaggio per migliorare la comprensione dell'umorismo.</sample>
    <sample id="12">Cinque autori sono coinvolti nell'articolo.</sample>
    <sample id="13">Il presente lavoro si concentra sull'analisi e sulla migliorazione dell'inferenza adattiva in contesti a risorse limitate, con l'obiettivo di trovare il "sweet spot" tra velocità e precisione. L'autore esplora due approcci principali: l'inferenza multi-modello (MM) e l'inferenza early exit (EE). L'inferenza MM utilizza modelli di capacità variabile per classificare facilmente i campioni, riducendo così i costi di inferenza medio. Tuttavia, questo approccio può essere costoso in termini di memoria e ha un overhead significativo. In confronto, l'inferenza EE è più veloce e efficiente in termini di memoria, ma presenta conflitti di gradienti che possono compromettere la performance generale.

L'autore propone il metodo SWEET (Separating Weights in Early Exit Transformers), che separa i pesi dei trasformatori nelle architetture early exit, evitando i conflitti di gradienti. SWEET ottimizza le prestazioni senza compromettere la velocità, chiudendo la maggior parte della differenza tra EE e MM. Gli esperimenti su BERT dimostrano che SWEET migliora la precisione media di 2,3% rispetto all'EE, mantenendo una buona velocità. I risultati mostrano anche che SWEET non negativamente influisce sulle classificazioni successive, confermando la sua efficacia nel mantenere la qualità generale del modello.</sample>
    <sample id="14">Il contenuto inglese è già stato tradotto in italiano nel testo precedente.</sample>
    <sample id="15">Tre autori sono coinvolti nell'articolo.</sample>
    <sample id="16">I domini che risultano più semplificati sono "news", "bible", "L2" e "fiction".</sample>
    <sample id="17">Il presente lavoro si concentra sulla estrazione delle relazioni multimediali (MRE) attraverso l'uso di una combinazione di informazioni interne e esterne, con l'obiettivo di migliorare la performance della task di estrazione delle relazioni. L'approccio proposto introduce un concetto innovativo di sottrazione e aggiunta simultanea dell'informazione per la estrazione delle relazioni multimediali. Si utilizza un modello di tema multimodale latente per guidare lo screening delle informazioni interne e esterne, con l'obiettivo di ridurre l'eccessiva utilizzazione delle informazioni interne e l'insufficiente sfruttamento delle informazioni esterne. Inoltre, si sviluppa un'attenzione per integrare le informazioni del tema multimodale, che contribuisce significativamente alla performance della task. Il sistema proposto ha dimostrato un miglioramento significativo rispetto ai modelli esistenti su dati di benchmark, confermando l'efficacia dell'approccio proposto.</sample>
    <sample id="18">"I saw Bart and Lisa; Homer came and sneezed."</sample>
    <sample id="19">Il presente lavoro si concentra sull'analisi e sulla presentazione di una recensione sui sistemi di risposta alle domande aperte efficienti (ODQA). L'obiettivo è fornire una panoramica completa delle principali linee di ricerca e dei modelli esistenti per rispondere efficacemente alle domande aperte, evidenziando i vantaggi e le sfide di questi sistemi. Il lavoro introduce due approcci principali: il sistema Retriever-Reader e il sistema Generatore. Ogni approccio viene analizzato in termini di prestazioni, memoria e velocità di inferenza, con un focus particolare sulle tecniche di ottimizzazione per ridurre la dimensione dell'indice e la complessità del modello. Inoltre, vengono proposte soluzioni innovative per l'implementazione di tali sistemi su dispositivi a basso consumo energetico, come i dispositivi mobili, considerando anche fattori di valutazione come il costo, i dati di addestramento, la consumazione di energia e le emissioni di carbonio.</sample>
    <sample id="20">Yes, you can use the models for your research.</sample>
    <sample id="21">DEplain-APA contiene documenti di testo standardizzati, come articoli scientifici e libri.</sample>
    <sample id="22">Per una buona generalizzazione, si richiedono: un migliore architettura del modello, un modello di dimensione maggiore e più esempi di fin-tuning.</sample>
    <sample id="23">Il presente lavoro si concentra sulla migliorazione della rappresentazione visiva del testo attraverso modelli carattere-aware, evidenziando come questi modelli siano particolarmente efficaci per la generazione di immagini da testo. L'approccio utilizzato prevede l'integrazione di informazioni carattere-aware all'interno dei modelli di diffusione di testo-immagine, migliorando significativamente la qualità delle immagini generate. Il modello Imagen, ad esempio, utilizza un encoder di testo congelato e un modello di diffusione di testo-immagine per creare immagini basate su istruzioni testuali. Tuttavia, l'encoder di testo non è in grado di gestire correttamente le variazioni ortografiche, come mostrato dalla tokenizzazione che nasconde le differenze ortografiche. Questo problema è risolto introducendo un encoder carattere-aware, che migliora notevolmente la capacità di spiegare del modello, come dimostrato dai grafici che evidenziano una maggiore accuratezza nella spiegazione per modelli di dimensione XXL rispetto a quelli di dimensione base. Inoltre, i modelli carattere-aware sono più efficienti nel gestire le frequenze delle parole, mantenendo un alto livello di accuratezza anche per le parole meno frequenti. Questi risultati sono confermati dalle metriche di preferenza degli utenti per le immagini generate, che mostrano un miglioramento significativo quando si utilizzano modelli carattere-aware. In conclusione, l'introduzione di informazioni carattere-aware nei modelli di diffusione di testo-immagine rappresenta una strategia efficace per migliorare la qualità delle immagini generate, offrendo un vantaggio competitivo nei confronti dei modelli subword-based tradizionali.</sample>
    <sample id="24">La tendenza dei congiunti a sinistra a essere più brevi è stata osservata e confermata attraverso l'analisi di una versione ampliata del Penn Treebank.</sample>
    <sample id="25">Gli esperimenti sono stati progettati per studiare l'effetto della posizione del governatore utilizzando una serie di frasi con diversi governatori, come "Homer loves Lisa, Bart, and Maggie" e "Homer loves Lisa, Bart, and Maggie." Queste frasi hanno vari governatori che possono essere a sinistra o a destra, permettendo di osservare come la posizione del governatore influenzi la lunghezza dei congiunti.</sample>
    <sample id="26">Un classificatore base addestrato su dati non bilanciati ha un AUC di 0.50, che indica una performance casuale.</sample>
    <sample id="27">Quattro autori sono coinvolti nell'articolo.</sample>
    <sample id="28">I nomi dei personaggi nella conversazione presa a esempio sono "Easy on Me" (by Adele) e "I Gotta Feeling" (by The Black Eyed Peas).</sample>
    <sample id="29">I modelli di MT sensibili al contesto migliorano rispetto a quelli indipendenti dal contesto per i fenomeni di formalità, coerenza lessicale e ellissi.</sample>
    <sample id="30">Il presente lavoro introduce LLM-Blender, un framework di apprendimento ensembler per modelli di linguaggio di grande scala (LLMs). L'approccio di LLM-Blender si basa su due moduli principali: PairRanker e GenFuser. Il PairRanker utilizza una tecnica di ranking basata sul confronto parziale per ordinare le risposte dei modelli, mentre il GenFuser fonde le risposte dei modelli selezionati per generare l'output finale. Questo framework è stato testato su un vasto insieme di dati denominato MixInstruct, che contiene 110k esempi di istruzioni seguite, suddivisi in tre set di dimensioni diverse. Gli esperimenti hanno dimostrato che LLM-Blender migliora significativamente la performance complessiva dei modelli esistenti, migliorando i punteggi di valutazione come BERTScore, BLEURT e GPT-Rank. Inoltre, il framework è stato implementato con un codice unificato per facilitare l'uso e lo sviluppo futuro.</sample>
    <sample id="31">Le affiliazioni degli autori dell'articolo sono Johns Hopkins University, Purdue University e Meta AI.</sample>
    <sample id="33">Il framework quantifica la posizionalità attraverso due passaggi principali: 1) Re-annotare i dataset con annotatori diversi e 2) Confrontare le annotazioni per demografia tramite il coefficiente di correlazione di Pearson R.</sample>
    <sample id="34">Il presente lavoro introduce CREST, un framework integrato che combina la razionalizzazione selettiva e la generazione di counterfactuali per migliorare l'interpretabilità dei modelli di classificazione. CREST utilizza una maschera addestrabile per generare spiegazioni razionali basate su token specifici, che poi vengono utilizzate per creare counterfactuali plausibili. Questo approccio permette di controllare l'entità della perturbazione applicata ai dati, garantendo spiegazioni fluenti e diverse. L'analisi sperimentale su dataset come IMDb e SNLI dimostra che CREST produce counterfactuali di alta qualità, con valori elevati di plausibilità, similitudine forward e counterfactual. Inoltre, CREST raggiunge un alto livello di simulabilità counterfactual, confermando la sua efficacia nell'interpretazione dei modelli di classificazione. Il contributo principale di CREST è di offrire un equilibrio tra razionalizzazione selettiva e generazione di counterfactuali, migliorando significativamente l'interpretabilità dei modelli senza compromettere la loro capacità di classificazione.</sample>
    <sample id="36">Il presente lavoro si concentra sulla creazione di una soluzione innovativa per la traduzione multilingue tramite l'apprendimento di strati specifici per le lingue (LSLs). L'obiettivo principale è aumentare la capacità di traduzione per ogni singola lingua, focalizzandosi solo su quelle che sono più importanti, senza compromettere i costi di inferenza. La ricerca introduce un nuovo modello che utilizza strati specifici per le lingue, che possono essere indiciati o dal linguaggio sorgente o dal linguaggio destinazione. Questo approccio permette al modello di apprendere automaticamente dove applicare questi strati, migliorando così la precisione della traduzione. Gli esperimenti condotti sul dataset WMT21 hanno dimostrato che questo metodo supera significativamente altri baselines e basi di riferimento, ottenendo miglioramenti statisticamente significativi in 84 su 90 direzioni di traduzione.</sample>
    <sample id="37">Il risultato dello studio precedente è stato che i soggetti umani hanno ricevuto gli stessi prompt di persona.</sample>
    <sample id="38">I dati sono stati estratti da una versione aggiornata del Penn Treebank.</sample>
    <sample id="39">Due autori sono coinvolti nell'articolo.</sample>
    <sample id="40">Le attività strettamente correlate alla dissonanza cognitiva includono l'effetto dell'insoddisfazione, la tendenza delle opinioni e le malattie di ansia.</sample>
    <sample id="41">Il presente lavoro si concentra sulla creazione di un nuovo grafo conoscitivo personale, chiamato PeaCoK, che contiene circa 100.000 conoscenze di persona di qualità elevata. Questo grafo è progettato per rappresentare le conoscenze di persona al livello mondiale e include informazioni su caratteristiche intrinseche, routine, obiettivi o piani futuri, esperienze passate e relazioni con altri individui. Il PeaCoK è stato sviluppato attraverso una serie di tre passaggi: selezione del personaggio, induzione di attributi potenziali e classificazione delle relazioni.

L'approccio utilizzato per la costruzione del PeaCoK prevede l'uso di modelli linguistici preaddestrati e di conoscenza comune esistenti, insieme a un sistema di voto maggioritario per la classificazione delle relazioni. Questo metodo ha permesso di ottenere una precisione elevata nella classificazione delle relazioni, con valori di precisione, ricchezza e MRR-1 che superano i 90%.

Il PeaCoK è stato utilizzato per migliorare il modello di conversazione P^2-Bot, aumentando significativamente la consistenza e l'interattività delle conversazioni. I risultati mostrano che l'uso del PeaCoK ha portato a un aumento del 35% nella consistenza e del 24% nell'interattività, rispetto alla versione originale del modello. Inoltre, il PeaCoK ha dimostrato di essere in grado di generare conoscenze di persona di alta qualità, rendendo possibile l'addestramento di generatori di inferenza di persona affidabili.

In conclusione, il PeaCoK rappresenta un importante strumento per la modellizzazione narrativa, offrendo un quadro conoscitivo dettagliato e aggiornato sui personaggi, che può essere utilizzato per migliorare l'interazione umano-macchina e la qualità delle conversazioni.</sample>
    <sample id="42">Due autori sono coinvolti nell'articolo.</sample>
    <sample id="43">Ci sono sei autori coinvolti nell'articolo.</sample>
    <sample id="44">Il framework introdotto differisce dai lavori precedenti perché include la re-annotazione dei dati con annotatori diversi, la comparazione delle annotazioni per demografia e modello/dati tramite il coefficiente di correlazione di Pearson, e l'analisi delle specifiche comunità attraverso la creazione di dataset e modelli specializzati.</sample>
    <sample id="45">La configurazione "Human" si sovrappone maggiormente al lessico degli stereotipi.</sample>
    <sample id="46">Google e DeepL sono i sistemi commerciali che hanno svolto il confronto.</sample>
    <sample id="47">Il contenuto inglese è già stato tradotto in italiano nel video precedente. Ecco la traduzione:

#ACL2023
Da i dati di pretraining ai modelli di linguaggio fino alle compiti downstream: tracciare le tracce dei pregiudizi politici che portano a modelli NLP non equi

Dati di training per i modelli di linguaggio
Un dono misto

Per questo scopo
Dati di pretraining
Modelli di linguaggio
Compiti downstream

Come valutare l'orientamento politico dei modelli di linguaggio?
Qual è il ruolo dei dati di pretraining nei pregiudizi politici?
Come si comportano i modelli di linguaggio con diversi orientamenti politici?
Il loro orientamento politico porta a problemi di equità nelle applicazioni NLP?

Valutazione dell'orientamento politico dei modelli di linguaggio
Supporta sia i modelli encoder che decoder
"statement&gt; I &lt;mask&gt; con questa affermazione."
"Concordi o non con questa affermazione? &lt;statement&gt;"
Evaluazione automatica
Basata sulla letteratura di scienza politica

Esistenti modelli di linguaggio
BERT-base
BERT-large
RoBERTa-base
RoBERTa-large
distilBERT
distilRoBERTa
ALBERT-base
ALBERT-large
BART-base
BART-large
Alpaca
GPT-2
GPT-3-ada
GPT-3-babbage
GPT-3-curie
GPT-3-davinci
ChatGPT
GPT-4
GPT-J

Dati di pretraining ulteriori (RoBERTa, GPT-2) per valutare il cambiamento nell'orientamento politico

Risultati
Spostamenti partitici nell'orientamento politico dei modelli di linguaggio

La carta di Trump
Cambiamenti dal pre-Trump al post-Trump

Tabella 4: Prestazioni su discorsi di odio mirati a diverse identità di gruppo e informazioni false provenienti da diverse fonti.
I risultati sono colorati in modo tale che il giallo scuro rappresenta il miglior risultato e il blu scuro il peggior risultato.

Analisi qualitativa
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione
Test di discriminazione</sample>
    <sample id="48">Sei autori sono coinvolti nell'articolo.</sample>
    <sample id="49">Le valutazioni MPP sono state eseguite fino a 900 token di lunghezza del contesto.</sample>
    <sample id="50">Il presente lavoro introduce DEPLAIN, un corpus parallelo tedesco che include traduzioni intralingue in linguaggio semplice per la semplificazione di frasi e documenti. Il corpus è stato creato attraverso una combinazione di traduzioni umane e automatiche, garantendo una vasta varietà di generi testuali come notizie, bibbia, L2 e romanzi. La semplificazione è stata effettuata utilizzando tecniche come sostituzione, rimozione di clausole, riconfigurazione e rimozione di parole, con l'obiettivo di rendere il testo più comprensibile senza perdere significato. Il corpus è stato utilizzato per valutare l'efficacia delle tecniche di semplificazione e per migliorare i modelli di semplificazione automatica. Inoltre, sono state esplorate le trasformazioni di semplificazione applicate ai diversi generi testuali, evidenziando come le tecniche di semplificazione si adattino meglio a certi generi rispetto ad altri. Il corpus DEPLAIN offre una base solida per lo sviluppo e l'implementazione di sistemi di semplificazione automatica, promuovendo l'accessibilità del testo per un pubblico più ampio.</sample>
    <sample id="51">I tre domini inclusi nel loro set di dati sono: musica, libri e ricette.</sample>
    <sample id="52">La posizionalità si riferisce alle posizioni che le persone assumono come risultato delle loro caratteristiche demografiche, identità e esperienze di vita.</sample>
    <sample id="53">Dawei Zhu</sample>
    <sample id="54">Il presente lavoro si concentra sulla detezione della dissonanza cognitiva, una teoria psicologica che analizza le tensioni tra pensieri, azioni e credenze inconsistenti. L'obiettivo è sviluppare metodi per migliorare la precisione delle annotazioni di dissonanza in contesti di apprendimento automatico, specialmente quando le annotazioni sono rare. L'approccio utilizzato combina l'apprendimento trasferibile con l'apprendimento attivo, permettendo di aumentare l'efficienza nell'acquisizione di nuove esempi di dissonanza. Il modello predefinito viene addestrato su un piccolo insieme di dati etichettati e poi finetuned su set di dati diversi per ogni compito successivo. Risultati sperimentali mostrano che l'apprendimento trasferibile può migliorare significativamente l'accuratezza delle annotazioni, mentre l'apprendimento attivo aiuta a ridurre il tempo necessario per l'annotazione. Questo approccio è particolarmente utile per classi rare come la dissonanza, rendendolo un metodo efficace per l'acquisizione di dati rari.</sample>
    <sample id="55">Sì, EDAtt utilizza modelli ST offline esistenti senza ricondizionare o adattare specifiche architetture per SimulST.</sample>
    <sample id="56">Quattro autori sono coinvolti nell'articolo.</sample>
    <sample id="57">Sì, il modello è stato testato sulla suite di test KITMUS.</sample>
    <sample id="58">Le tre varianti di KITMUS sono:
1. Background-Pretrain
2. Background-Both
3. Background-Inference</sample>
    <sample id="59">DrBERT è un modello preaddestrato robusto in francese per i domini biomedico e clinico, che supera i modelli generici CamemBERT e FlauBERT, e conferma l'utilità dell'addestramento su un modello specifico per la medicina in francese. L'analisi dei dati sottolinea che più dati sono meglio, ma non sempre scala bene. La continua preaddestrazione è una strategia più efficace quando si basa su modelli specifici per la medicina in lingue diverse. I modelli DrBERT, il dataset NACHOS e i script di addestramento sono disponibili sotto licenza MIT.</sample>
    <sample id="60">Google Research</sample>
    <sample id="61">How to use the available clean samples more efficiently?</sample>
    <sample id="62">Il presente studio si concentra sulla distillazione del conoscenza (KD) per la generazione naturale del linguaggio (NLG), un campo che ha visto un notevole incremento di modelli linguistici profondi (LLMs) nel corso degli anni. Tuttavia, questi modelli richiedono enormi risorse computazionali, di stoccaggio e finanziarie, rendendo necessaria la compressione dei modelli per mantenere le prestazioni mentre riducono le risorse necessarie. Il lavoro si concentra su due tipi di KD: la distillazione logit (KD) e la distillazione sequenziale (S-KD). La KD logit mira a far imitare il modello studente la distribuzione di probabilità del prossimo token del modello maestro, mentre la S-KD utilizza target pseudo-generati dal modello maestro come dati di addestramento per l'studente. Il studio esplora diversi approcci di KD, inclusi la pratica di encoder e decoder, la distillazione logit e la distillazione sequenziale, e valuta l'efficacia di queste tecniche su una varietà di compiti NLG realistici. I risultati dimostrano che la S-KD può essere particolarmente efficace per la compressione dei modelli NLG, migliorando significativamente le prestazioni senza compromettere troppo le capacità di generazione. Inoltre, il lavoro suggerisce che l'utilizzo di un modello maestro preaddestrato e la generazione di target pseudo-generati possono essere strategie efficaci per ridurre ulteriormente le risorse necessarie per l'addestramento dei modelli studente.</sample>
    <sample id="63">La sensibilità della metrica si riferisce alla capacità del modello di produrre i medesimi risultati per una stessa compito, indipendentemente dalle lievi variazioni nella formulazione delle istruzioni.</sample>
    <sample id="64">Wenjun Peng</sample>
    <sample id="65">Una maggiore sensibilità indica una performance del modello peggiore.</sample>
    <sample id="66">Il presente lavoro si concentra sulla capacità dei modelli di linguaggio avanzati, come i modelli di apprendimento profondo e le reti neurali seq2seq, di risolvere problemi matematici complessi. L'abstract esplora l'uso di tecniche di apprendimento profondo per affrontare problemi di ragionamento matematico, evidenziando le sfide e le potenzialità di questi modelli. Si discute della necessità di sviluppare metodi più efficaci per la gestione di calcoli complessi e la rappresentazione di informazioni numeriche. Inoltre, si analizzano i limiti dei modelli attuali nel risolvere problemi matematici precisi, evidenziando la loro difficoltà nell'affrontare calcoli con numeri grandi. L'abstract conclude sottolineando l'importanza di continuare lo studio e lo sviluppo di nuove tecniche per migliorare la capacità dei modelli di linguaggio di risolvere problemi matematici complessi, con l'obiettivo di rendere questi modelli più robusti e generalizzabili.</sample>
    <sample id="67">Il presente studio si concentra sulle interferenze e sulla sinergia tra le lingue nei modelli multilingui di traduzione automatica (MT). I ricercatori hanno identificato che le interferenze possono essere influenzate da fattori come la dimensione del modello, la quantità di dati disponibili e la similarità delle lingue coinvolte. L'interferenza è particolarmente significativa quando il modello è piccolo rispetto alla quantità di dati. Il test di perdita per una coppia di lingue in un modello multilingue è misurato attraverso la differenza tra la perdita di un modello bilingue e quella di uno multilingue. Gli esperimenti sono stati condotti su modelli di varie dimensioni, inclusi "XS", "S", "M" e "L", con diverse lingue come focus, come il cinese e l'inglese. La similarità delle lingue non sembra essere un fattore dominante per l'interferenza, ma piuttosto la dimensione del modello e la quantità di dati. I risultati mostrano che l'interferenza diminuisce con l'aumento della dimensione del modello e della quantità di dati. Inoltre, la temperatura di campionamento può essere utilizzata come baselines efficace per combattere l'interferenza. Questo studio suggerisce che, in molte situazioni, modesti scale e temperature calibrate possono essere sufficienti per ridurre significativamente l'interferenza.</sample>
    <sample id="68">I modelli vengono addestrati su un vasto corpus di testo, che include una varietà di generi e forme di testo, come articoli di notizie, libri, blog, e-mail, ecc. Questo contesto linguistico è molto diversificato e copre una vasta gamma di temi e argomenti per assicurare che i modelli apprendano una comprensione ampia e profonda della lingua naturale.</sample>
    <sample id="69">I risultati mostrano che i modelli beneficiano da più di 10 campioni di convalida puliti per classe.</sample>
    <sample id="70">I tre autori dell'articolo sono Myra Cheng, Esin Durmus e Dan Jurafsky.</sample>
    <sample id="71">Il presente lavoro di ricerca si concentra sulla risoluzione di espressioni di riferimento indirette per la selezione di entità, con particolare attenzione ai sistemi conversazionali e alla comprensione dell'informazione utente. L'obiettivo principale è comprendere come gli utenti esprimono preferenze e come i modelli di linguaggio naturale possano interpretare tali espressioni. Il corpus AltEntities, raccolto attraverso annotazioni di massa, contiene 6.000 domande alternative e 42.000 espressioni di riferimento indirette, coprendo tre domini: musica, libri e ricette. La ricerca utilizza un modello di linguaggio basato su testo (T5 XL) che raggiunge un'accuratezza del 92-95% quando ha accesso al contesto di fondo, mentre l'accesso solo alle entità riduce l'accuratezza a 82%-87%. I risultati dimostrano che i modelli sono generalizzabili tra i diversi domini, confermando la validità del corpus per applicazioni future.</sample>
    <sample id="72">Perché i modelli di linguaggio basati su preaddestramento possono acquisire e propagare pregiudizi politici dai dati di addestramento, che possono influire negativamente sulle applicazioni NLP.</sample>
    <sample id="73">Il relatore è Martin Pömsl.</sample>
    <sample id="74">Il presente lavoro si concentra sulla costruzione di un grafo conoscenza densamente connesso, chiamato Dense-ATOMIC, che copre una vasta gamma di relazioni comuni. L'obiettivo è migliorare la conoscenza del grafo esistente, ATOMIC, che presenta limitazioni come la scarsità di connessioni tra eventi e la mancanza di multi-hop paths. Il nuovo grafo, Dense-ATOMIC, è stato creato utilizzando una serie di tecniche di normalizzazione e clustering per aumentare la densità delle connessioni. La costruzione del grafo è stata implementata attraverso l'uso di un modello di previsione delle relazioni, che ha permesso di prevedere le relazioni mancanti basandosi sulle informazioni semantiche degli eventi. Inoltre, è stata proposta una strategia di completamento interno ed esterno dei cluster per inferire le relazioni mancanti all'interno e tra i diversi cluster. L'efficacia del nuovo grafo è stata valutata attraverso un insieme di test che hanno dimostrato un aumento significativo della copertura conoscitiva e delle multi-hop paths rispetto al grafo ATOMIC originale. Inoltre, il nuovo grafo ha dimostrato di migliorare le prestazioni del sistema COMET, un modello di ragionamento comune, confermando così la sua utilità nell'apprendimento automatico e nel ragionamento comune.</sample>
    <sample id="75">Il presente lavoro si concentra sulla creazione di un approccio semisuperviso per l'identificazione di entità e la estrazione di relazioni (NER-RE) che utilizza una rete di propagazione etichette su reti grafiche omogenee. L'obiettivo è migliorare l'efficienza e la precisione delle tare NER-RE, riducendo la necessità di annotazione manuale di grandi quantità di dati. Il metodo proposto modella le tare NER-RE tramite la propagazione di etichette attraverso reti grafiche omogenee, considerando sia le interazioni tra dati etichettati e non etichettati che quelle all'interno di ciascun tipo di dato. La costruzione della rete grafica è ottenuta attraverso algoritmi di kNN per aumentare l'efficienza computazionale. Il modello viene ottimizzato attraverso la selezione di pseudo-etichette e la propagazione di etichette attraverso un processo iterativo. Gli esperimenti sono condotti su quattro dataset, dimostrando che il metodo proposto migliora significativamente i risultati rispetto ai metodi basati su supervisione completa.</sample>
    <sample id="76">L'infrastruttura di propagazione dei bias politici è complessa e coinvolge vari elementi, tra cui i dati di preaddestramento, i modelli di linguaggio, e le attività downstream.</sample>
    <sample id="77">L'articolo si concentra sulla creazione di un nuovo dataset chiamato DeFacto, che contiene esempi di documenti originali e relativi riassunti generati automaticamente, insieme a feedback umano per migliorare la consistenza fattuale dei riassunti. Il dataset è stato creato utilizzando report di notizie da XSum, con più del 70% dei riassunti riferiti come contenenti errori di fattualità. I ricercatori hanno sviluppato un modello di editing basato su feedback umano per migliorare la consistenza fattuale dei riassunti automatici. L'analisi del feedback umano ha evidenziato che le operazioni di editing più comuni sono l'eliminazione e la sostituzione dell'informazione, mentre gli errori intrinseci richiedono una maggiore varietà di operazioni di editing. Inoltre, il dataset è stato utilizzato per l'allenamento di nuove metriche di fattualità, offrendo vantaggi significativi per l'analisi e la valutazione delle metriche di fattualità.</sample>
    <sample id="78">No, il processo di semplificazione non differisce per DEplain-apa e web. Entrambi usano la stessa tecnica di semplificazione basata su BART.</sample>
    <sample id="79">No, Coscript non è disponibile pubblicamente.</sample>
    <sample id="80">La filigrana viene inserita nel testo attraverso la selezione di parole con frequenze moderate da un corpus di testo generale e le loro frequenze vengono conteggiate.</sample>
    <sample id="81">PennState e Amazon</sample>
    <sample id="82">Il presente lavoro si concentra sull'automatizzazione della valutazione degli scritti senza intervento umano, un campo che ha visto un progresso significativo grazie all'introduzione di modelli AES (Automated Essay Scoring) addestrati su corpus di grandi dimensioni. Tuttavia, l'acquisizione di tali corpus è spesso costosa e laboriosa. Il lavoro propone un approccio innovativo per l'addestramento di modelli AES in modo supervisionato utilizzando segnali di qualità heuristica come pseudo-supervisione. Questo approccio, chiamato ULRA (Learning from Rank Aggregation), aggrega diversi segnali di qualità heuristica per creare una supervisione unitaria. L'ULRA viene utilizzata per addestrare un modello AES che può valutare gli scritti in modo autonomo. Gli esperimenti dimostrano l'efficacia dell'ULRA per la valutazione degli scritti in contesto non supervisionato, mostrando miglioramenti significativi rispetto ai metodi tradizionali.</sample>
    <sample id="83">Sì, i modelli codificatore-decodificatore come mT5 possono migliorare con l'addestramento su una combinazione di lingue.</sample>
    <sample id="84">PAD-Net è un framework efficiente per reti dinamiche, progettato per gestire efficacemente i modelli che cambiano durante l'esecuzione. Il framework introduce una combinazione di parametri statici e dinamici, permettendo ai modelli di adattarsi in modo più flessibile alle variazioni del contesto. La dinamica dei parametri è controllata da fattori dinamici, che decidono se un parametro deve essere utilizzato in modalità dinamica o statica. Questo approccio non solo riduce il numero di parametri effettivamente utilizzati ma anche produce output meno discriminanti, migliorando la generalizzazione del modello. L'iterative mode partition (IMP) viene utilizzato per ottimizzare la scelta tra i modi dinamico e statico dei parametri, minimizzando la perdita di informazioni senza compromettere la performance. Le prove empiriche dimostrano che PAD-Net offre prestazioni superiori rispetto ai modelli tradizionali, con minor numero di parametri e minor calcolo computazionale. In futuro, si prevede di estendere il concetto di PAD-Net a architetture hardware amichevoli e di integrarlo in altre reti mainstream, introducendo ulteriori modi di funzionamento come zero + static + dynamic.</sample>
    <sample id="85">Un esempio di pianificazione linguistica vincolata è "Come fare una torta al cioccolato?" con la specifica di aggiungere la polvere di cacao nella farina.</sample>
    <sample id="86">Gli autori si assicurano della segretezza del loro metodo attraverso la trasferibilità, ovvero rendendo il watermark incomprensibile per gli attacchi.</sample>
    <sample id="87">The work uses existing PLMs to build a new one by continuing pre-training with an existing pre-trained model.</sample>
    <sample id="88">GPT-4 è meno allineato con il Paese West South Asia.</sample>
    <sample id="89">"I leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output."</sample>
    <sample id="90">Il presente studio esplora l'opportunità di utilizzare apprendenti di lingue come annotatori per la creazione di dataset di linguaggio naturale (NLP). Inizialmente, si evidenzia che reclutare parlanti nativi per l'annotazione dei dati è difficile, mentre ci sono molti apprendenti di lingue disponibili. Il lavoro si concentra su tre lingue: inglese, coreano e indonesiano, con quattro compiti specifici: classificazione sentimentale (SA), inferenza di relazioni tra frasi (NLI), riconoscimento di entità (NER) e classificazione di relazioni (MRC). Gli apprendenti sono suddivisi in quattro livelli di competenza linguistica: base, intermedia, avanzata e parlanti nativi. Ogni apprendente ha accesso a risorse aggiuntive come dizionari e sistemi di traduzione automatica. La metodologia prevede una serie di test standardizzati, un'annotazione di 10 domande e un post-test. I risultati mostrano che le annotazioni fornite dagli apprendenti sono quasi accurate, raggiungendo un'accuratezza del 95% quando vengono aggregati i loro voti. Inoltre, gli apprendenti migliorano la loro competenza in vocabolario e grammatica attraverso l'attività di annotazione. Questo studio suggerisce che l'utilizzo degli apprendenti di lingue come annotatori potrebbe essere una soluzione efficace per l'annotazione di grandi quantità di dati NLP, offrendo la possibilità di estendere la ricerca NLP a più lingue.</sample>
    <sample id="91">La quantità di attività può influenzare la performance del modello in modo significativo, come mostrato nella tabella 3, dove l'uso di 5 istruzioni risulta in una maggiore performance aggregata e una sensibilità inferiore.</sample>
    <sample id="92">I tre approcci di riferimento sono:
1. seq2seq
2. PP recursion
3. Obj PP = Subj PP</sample>
    <sample id="93">I due coautori, Alexander Koller e Ivan Titov, sono collegati al primo autore, Matthias Lindemann, attraverso un lavoro collaborativo nel campo dell'informatica e della NLP.</sample>
    <sample id="94">Il presente lavoro si concentra sulla protezione del copyright dei modelli di linguaggio grande (LLM) offerti come servizio (EaaS). I modelli LLM, come GPT, LLaMA e PALM, sono estremamente efficaci per le comprensioni naturali (NLU) e le generazioni naturali (NLG), rendendoli essenziali per molte applicazioni NLP. Tuttavia, l'uso di questi modelli come servizi può portare a problemi di copyright, poiché gli attacchi possono rubare i modelli attraverso l'apprendimento delle embedding e fornire servizi simili. Questo è particolarmente preoccupante con la diffusione di servizi EaaS che offrono accesso a modelli LLM.

Per rispondere a questa sfida, il lavoro propone EmbMarker, un sistema di watermarking basato su backdoor che introduce una marca nascosta nei modelli LLM durante l'iniezione delle embedding. Questa marca è progettata per essere inconfondibile per i provider ma impercettibile per gli attacchi, mantenendo l'utilità dei servizi EaaS. La marca viene selezionata basandosi sulle frequenze di parola in un corpus di testo generale, e viene inserita nel modello LLM senza comprometterne la funzionalità.

L'efficacia di EmbMarker è stata valutata attraverso esperimenti su quattro dataset diversi: AG News, MIND, SST2 e Enron Spam. I risultati mostrano che EmbMarker riesce a mantenere un alto livello di performance sui task downstream, con un aumento significativo della precisione nella deteczione di copia. Inoltre, il sistema è stato dimostrato in grado di distinguere tra modelli originali e copiati con un p-value inferiore al 0.05, confermando la sua capacità di proteggere il copyright dei modelli LLM.</sample>
    <sample id="95">David Viar Toros</sample>
    <sample id="96">Il contenuto inglese è già stato tradotto in italiano nel testo precedente. Se hai bisogno di ulteriori informazioni o se desideri una verifica, sono qui per aiutarti!</sample>
    <sample id="97">La relatrice menziona tre problemi associati a SimulST: specifiche architetture, lunghe e complesse procedure di training, e l'addestramento e la manutenzione di diversi modelli per raggiungere differenti latenze.</sample>
    <sample id="98">Un modo efficace per mitigare i bias sociali e politici nei set di dati durante l'addestramento dei modelli di NLP potrebbe essere attraverso la diversificazione e l'inclusione dei dati, garantendo che siano rappresentati correttamente le diverse voci sociali e politiche. Inoltre, è importante valutare e monitorare costantemente i bias nel processo di addestramento e testare regolarmente i modelli su dati diversi per assicurarsi che non abbiano pregiudizi o favoritismi.</sample>
    <sample id="99">Il contenuto inglese è già stato tradotto in italiano nel video precedente.</sample>
    <sample id="100">Il presente lavoro si concentra sulla creazione di un sistema di elaborazione del linguaggio naturale (NLP) per rispondere a domande complesse che richiedono più passaggi di ragionamento, chiamate "multi-hop". L'approccio utilizzato è PromptRank, che combina un metodo di recupero non supervisionato con un riequilibratore basato su modelli di linguaggio (LM) a pochi esempi. Questo sistema è stato testato su una vasta gamma di domande e ha dimostrato una performance superiore rispetto ai sistemi di recupero completamente supervisionati e paragonabile a quelli di punta. Il PromptRank utilizza una funzione di scoring basata sulla probabilità di una domanda data una catena, ottenuta attraverso un LM, per valutare la relativa importanza delle catene. Inoltre, l'uso di istruzioni specifiche aiuta il modello a comprendere meglio il contesto delle domande. Le metriche utilizzate per valutare il sistema includono R@K, che misura la precisione della catena di risposta corretta tra i primi K documenti, e AR@K, che misura la precisione dell'argomento della risposta corretta tra i primi K documenti recuperati. Il PromptRank dimostra essere un sistema efficiente e performante per risolvere domande multi-hop, offrendo una soluzione data-efficient e versatile.</sample>
    <sample id="101">La fluidità di PaLM è comparabile a quella delle SOTA.</sample>
    <sample id="102">Le proprietà importanti di un metodo di filigrana sono l'applicabilità all'EaaS, la utilità (non degrada la utilità delle embeddings fornite), la copertura (è nascosto dall'attaccante) e la trasferibilità (la filigrana può essere trasferita ai servizi dell'attaccante).</sample>
    <sample id="103">Le 14 lingue diverse in cui sono stati tradotti i discorsi TED in inglese sono: English, العربية, Deutsch, Español, Français, עברית, Italiano, 日本語, 한국어, Nederlands, Português, Română, Русский, Türkçe e 中文.</sample>
    <sample id="104">1000000</sample>
    <sample id="105">La metrica utilizzata è la differenza di similitudine (similarity difference) e il valore p del test KS (Kolmogorov-Smirnov).</sample>
    <sample id="106">Il presente lavoro si concentra sulla creazione di un dataset chiamato QUEST, progettato per studiare le capacità dei sistemi di ricerca di gestire richieste di informazioni selezionate che contengono implicite operazioni di insieme. Il dataset comprende 3357 query di ricerca entità che richiedono l'identificazione di multipli oggetti o eventi, ciascuno dei quali può essere attribuito a parti diverse del documento. Questo rappresenta un problema di ricerca difficile, poiché i sistemi devono effettuare una ricerca efficace su un corpus di documenti vasto (più di 350mila) per trovare set multi-ansia, dove l'attribuzione per diversi constraint della query può provenire da parti diverse del documento.

Il dataset è stato costruito attraverso una serie di passaggi: prima di tutto, vengono estratti nomi di categoria Wikipedia da quattro domini: film, libri, piante e animali. Successivamente, vengono eseguite operazioni di insieme su queste categorie atomiche utilizzando template predefiniti. I modelli sono poi parlati da annotatori umani per rendere le query più fluenti e naturali. Infine, gli annotatori valutano la rilevanza delle entità nell'insieme di risposta e identificano l'evidenza nel documento come attribuzione.

Questo dataset è stato utilizzato per valutare l'efficacia di sistemi di ricerca che possono gestire tali richieste di informazioni selezionate. I risultati mostrano che i codificatori densi sono migliori per la ricerca e il riepilogo, ma i punteggi F1 degli end-to-end system sono relativamente bassi. Questo suggerisce che ci sia ancora spazio per miglioramenti in termini di performance.</sample>
    <sample id="107">I modelli basati su codificatori multilingue sono stati addestrati e valutati su dataset di compiti limitati e applicazioni, come la mancanza di copertura su certe lingue naturali e la mancanza di copertura su certe rappresentazioni del significato.</sample>
    <sample id="108">Il presente studio, presentato all'ACL 2023 e condotto da una squadra di ricercatori proveniente da diverse istituzioni come Johns Hopkins University, Purdue University, MIT e Meta AI, mette in luce la sensibilità delle modelli di linguaggio naturale (LM) nei confronti di strutture sintattiche latenti e semantiche condivise tra frasi diverse. L'approccio utilizzato è quello del paradigma "Minimal Pair Paradigm" (MPP), che valuta le decisioni di accettabilità dei modelli basandosi sulle differenze relative nelle probabilità di sequenza. Il lavoro dimostra che le valutazioni MPP con input di singola frase non sono sempre robuste al contesto, evidenziando che le decisioni di accettabilità possono variare in funzione della lunghezza del contesto, della corrispondenza strutturale e dell'accettabilità. 

L'approccio proposto testa se le decisioni MPP variano in funzione della lunghezza del contesto, della corrispondenza strutturale e dell'accettabilità. I risultati mostrano che le decisioni MPP sono robuste per qualsiasi lunghezza del contesto, ma che le frasi accettabili o non accettabili nel contesto possono influenzare significativamente il rendimento del modello. Inoltre, le frasi con struttura corrispondente hanno un impatto più severo sulle prestazioni del modello rispetto alle frasi con struttura non corrispondente.

Questi risultati portano alla conclusione che i modelli di LM sono sensibili a feature sintattiche e semantiche latenti condivise tra frasi diverse, ma che tali valutazioni non sono sufficienti per catturare completamente le conoscenze astratte dei modelli. Questo studio contribuisce a comprendere meglio le limitazioni e le potenzialità dei modelli di LM, offrendo nuove direzioni per migliorare la loro comprensione e applicazione.</sample>
    <sample id="109">Il presente studio introduce "Unnatural Instructions," un vasto dataset di 240,670 istruzioni naturali per una varietà di compiti linguistici. Questo dataset è stato raccolto completamente automaticamente, richiedendo solo 15 esempi manualmente costruiti come seme. L'approccio utilizzato permette di generare istruzioni diverse e creative, che sono state analizzate focalizzandosi sulla creatività, diversità e correttezza. Più del 50% delle istruzioni generate risultano essere corrette, mentre anche le istruzioni errate contengono informazioni preziose per l'addestramento dei modelli. Un modello T5 da 11B parametri, addestrato su "Unnatural Instructions," ha dimostrato di superare i modelli T0++ e TK-Instruct su vari benchmark. La raccolta automatica del dataset risulta essere più economica e veloce rispetto all'uso di lavoratori di crowd, rendendolo un'alternativa efficace per l'addestramento dei modelli di linguaggio.</sample>
    <sample id="111">Gli autori contano la frequenza delle parole su un corpus di testo generale e selezionano casualmente n parole in un intervallo di frequenza moderato.</sample>
    <sample id="112">Il contenuto inglese è già stato tradotto in italiano nel testo che segue:

---

**Introduzione**
- **Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?**
  - Shuheng Liu, Alan Ritter
  - School of Interactive Computing
  - Georgia Institute of Technology

**Riconoscimento e generalizzazione di entità nominative**
- I modelli hanno utilizzato CoNLL-2003 per lo sviluppo del riconoscimento di entità nominative (NER) per quasi 20 anni.
- Possono questi modelli generalizzare ai dati moderni?
- Quali sono le necessità per una buona generalizzazione?
- Che cosa causa la caduta del rendimento?

**Dataset CoNLL++**
- Raccolti notizie Reuters dal 2020 e annotati con i criteri di annotazione di CoNLL-2003.
- Ottimizzati 20+ modelli su CoNLL-2003.
- Valutati su set di test CoNLL-2003 e CoNLL++.
- Calcolato il percentuale ΔF1 per valutare la generalizzazione.

**Che cos'è necessario per una buona generalizzazione?**
- Architettura del modello
  - I modelli transformer generalizzano meglio.
- Dimensione del modello
  - Modelli più grandi generalizzano meglio.
- Numero di esempi di ottimizzazione
  - Più esempi portano a una migliore generalizzazione.

**Che cosa causa la caduta del rendimento?**
- Overfitting adattivo?
- Drift temporale?

**Conclusioni**
- Per una buona generalizzazione, si ha bisogno:
  - Miglior architettura del modello.
  - Dimensione del modello maggiore.
  - Più esempi di ottimizzazione.
- Il rendimento cade causato da:
  - Drift temporale.
  - Non overfitting adattivo.
- I tagger CoNLL-2003 funzionano ancora bene?
  - Sì!

**Riferimenti**
- Paper: https://arxiv.org/abs/2212.09747
- Dataset: https://github.com/ShuhengL/acl2023_conllpp
- Contatto: silu775@gatech.edu

---</sample>
    <sample id="114">Il presente lavoro si concentra sulla riduzione dei parametri nei modelli di attenzione multi-head (MHA) utilizzati in grandi modelli linguistici (LLMs). I MHA sono fondamentali per la comprensione e l'analisi del linguaggio, ma presentano limitazioni come il numero elevato di parametri, il tempo di training lungo e la necessità di un corpus di dati enorme. Queste limitazioni rendono difficile l'uso di tali modelli su piccole piattaforme o con risorse limitate.

Nel lavoro, gli autori presentano un approccio innovativo chiamato "Grouped Head Attention" che mira a ridurre i parametri dei MHA senza compromettere le prestazioni. L'approccio consiste in due fasi principali: la prima fase, chiamata "Group Constrained Training" (GCT), divide gli head in gruppi e li addestra in modo indipendente. La seconda fase, "Voting-to-Stay" (V2S), seleziona gli head più significativi da mantenere, eliminando quelli meno importanti. Questo processo è progettato per ridurre la redundanza tra gli head, migliorando così l'efficienza dei parametri.

I risultati sperimentali mostrano una riduzione del 90% dei parametri in condizioni estreme, con un incremento del 3,6% e del 4,5% nella metrica BLEU su set di test diversi. Questi risultati sono stati ottenuti utilizzando tre task differenti: traduzione automatica, modellazione del linguaggio e sommarizzazione astratta. Gli esperimenti dimostrano che il modello Grouped Head Attention può competere con i modelli originali in termini di prestazioni, mentre riduce significativamente il numero di parametri.

In futuro, gli autori propendono per lo sviluppo di tecniche di prunatura automatica specifiche per ogni task, basate sul concetto di "Lottery Ticket Hypothesis", secondo cui i modelli contengono sottoreti che raggiungono la stessa accuratezza del modello originale. Questo approccio promette di ridurre ulteriormente i parametri dei modelli LLM, rendendo questi modelli più efficienti e accessibili per una varietà di applicazioni reali.</sample>
    <sample id="115">Il segmento parlato utilizzato è di 1 secondo.</sample>
    <sample id="116">Servin è un giudice e Kea è un panettiere.</sample>
    <sample id="117">La qualità dell'esempio è più importante della somiglianza con la frase sorgente.</sample>
    <sample id="118">Il presente lavoro si concentra sulla migliorazione delle tecniche di pretraining per la NLP (Natural Language Processing) in contesti di code-switching, ovvero la commistione di due o più lingue all'interno della stessa frase. L'obiettivo è sviluppare modelli computazionali che siano in grado di gestire efficacemente queste situazioni linguistiche complesse. I ricercatori hanno identificato come i modelli multilingui esistenti, come mBERT e XLM-R, non siano ottimizzati per le task di code-switching, evidenziando una necessità di innovazione.

Per rispondere a questa sfida, sono state proposte due contribuzioni principali: 
1. Una nuova obiettivo di pretraining basata su masking language modeling che incorpora informazioni sul code-switching.
2. Cambiamenti architettonici e criteri di perdita ausiliaria per rendere il pretraining del code-switching più efficace.

I risultati ottenuti dimostrano che questi approcci migliorano significativamente l'efficacia dei modelli nel codice-switching, confermando l'importanza di integrare le informazioni sulle transizioni linguistico-codiche nelle fasi di pretraining. Inoltre, i test di probing hanno confermato che le rappresentazioni dei modelli migliorati sono più predittive delle transizioni linguistiche rispetto a quelle dei modelli tradizionali.

Questi risultati suggeriscono che le modifiche architettoniche e i criteri di perdita ausiliaria possono ulteriormente migliorare l'incorporazione delle informazioni sul code-switching, rendendo il pretraining più efficace e robusto.</sample>
    <sample id="119">GPT-2 e GPT-3</sample>
    <sample id="120">Il modello utilizza i punteggi di attenzione di un livello specifico.</sample>
    <sample id="121">Gli esempi di inferenza diretta sono "easy on me" e "the first one".</sample>
    <sample id="122">Le affiliazioni degli autori dell'articolo sono Fudan University e Brain Technologies Inc.</sample>
    <sample id="123">Il presente lavoro si concentra sulla migliorazione delle capacità di apprendimento zero-shot attraverso l'addestramento delle istruzioni per modelli multi-modali. L'approccio proposto, chiamato MultiInstruct, utilizza un dataset di istruzioni multimediali che comprende 62 compiti diversi, suddivisi in 10 gruppi di compiti ampi e 5 istruzioni esperte. Questo dataset è stato creato per superare l'imbilanciamento tra i compiti di NLP (Natural Language Processing) e quelli multimediali, offrendo una base più equilibrata per l'addestramento dei modelli.

L'obiettivo principale è di migliorare la capacità di un modello pre-addestrato, come OFA, di eseguire compiti di apprendimento zero-shot su una vasta gamma di compiti multimediali. Il modello è addestrato utilizzando istruzioni specifiche per ogni compito, che vengono poi messe in relazione con le istruzioni generali fornite dal dataset. Questo approccio permette al modello di acquisire una comprensione più ampia e flessibile dei compiti, migliorando così la sua capacità di rispondere a istruzioni diverse per lo stesso compito.

I risultati sperimentali mostrano che l'addestramento con istruzioni diverse può portare a un miglioramento significativo delle prestazioni del modello, sia in termini di precisione che di robustezza. Inoltre, l'uso di istruzioni diverse riduce la sensibilità del modello alle variazioni minori nelle istruzioni fornite, rendendo il modello più robusto e affidabile.

In conclusione, il lavoro introduce MultiInstruct come un nuovo dataset di istruzioni multimediali che offre un'opportunità per migliorare l'apprendimento zero-shot nei modelli multi-modali, promuovendo un'addestramento più efficace e flessibile.</sample>
    <sample id="124">L'abstract del documento si concentra sulla ricerca che analizza e migliora la capacità di ragionamento temporale dei modelli di linguaggio di grande scala (LLMs). L'obiettivo principale è identificare e sottolineare i bias presenti nei LLMs, evidenziando come queste strutture di memoria influenzino le loro prestazioni nel riconoscere relazioni temporali complesse. La ricerca propone un nuovo dataset chiamato TempReason, che copre tutti i tre livelli di ragionamento temporale e varie epoche storiche, per fornire una panoramica completa delle prestazioni dei modelli. Inoltre, viene presentato un framework di addestramento progettato per migliorare la capacità di ragionamento temporale dei LLMs. Questo approccio mira a superare i limiti attuali dei modelli, offrendo un'analisi più accurata e una soluzione più efficace per l'addestramento dei LLMs in ambito temporale.</sample>
    <sample id="125">Ci sono sei autori coinvolti nell'articolo.</sample>
    <sample id="126">No, non è stato considerato come un approccio standard.</sample>
    <sample id="127">Il presente studio esplora l'abilità delle grandi modelli linguistici di ragionare, evidenziando come la tecnica del "Chain-of-thought" (CoT) permetta ai modelli di elaborare complesse operazioni logiche. L'approccio proposto, chiamato "Fine-tune-CoT", utilizza un modello grande come maestro per insegnare a modelli più piccoli a ragionare in modo diverso, migliorando significativamente le loro capacità di risolvere complessi problemi. Il metodo è stato testato su vari modelli, dimostrando che la diversità nella generazione di ragionamenti può aumentare notevolmente le prestazioni dei modelli più piccoli. Questo approccio è altamente scalabile e offre una soluzione accessibile per trasferire le capacità di ragionamento da modelli grandi a modelli più piccoli, con un minor costo di sviluppo e un minor costo di inferenza.</sample>
    <sample id="128">Il presente studio si concentra sulla valutazione della capacità di modelli di linguaggio naturale (NLU) di integrare conoscenze da diverse fonti, sia durante la fase di preaddestramento che durante l'inferezione. L'approccio, chiamato KITMUS Test, mira a identificare come i modelli utilizzano e combinano le informazioni preaddestrate e quelle acquisite durante l'uso del modello. Il test utilizza una serie di esempi di test per valutare se i modelli sono in grado di rispondere correttamente alle domande basate su entità specifiche o conoscenze generali, distinguendo tra le due tipologie di conoscenza. I risultati mostrano che molti modelli non riescono a integrare efficacemente le conoscenze acquisite durante l'inferezione, evidenziando la necessità di un addestramento specifico per tale compito. Inoltre, il test evidenzia che l'integrazione delle conoscenze è un'area di miglioramento per i modelli NLU, sottolineando la necessità di sviluppare metodi più avanzati per gestire l'acquisizione e l'utilizzo di conoscenze multiple.</sample>
    <sample id="129">I ricercatori hanno fornito l'esempio di un gruppo contrassegnato come "Black woman" per illustrare il concetto di gruppi contrassegnati.</sample>
    <sample id="130">Le architetture dei modelli che non generalizzano in modo adeguato sono le architetture non trasformatorie.</sample>
    <sample id="131">I nomi dei set di dati di test sono "Clean labeled test data" e "Clean labeled validation data".</sample>
    <sample id="132">Sei autori sono coinvolti nell'articolo.</sample>
    <sample id="133">L'autore opera con più modalità, come indicato dal titolo "MULTIINSTRUCT: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning".</sample>
    <sample id="135">Il presente studio si concentra sulla valutazione dell'efficacia dei sistemi di dialogo orientati al chat, con particolare attenzione ai modelli di linguaggio naturale avanzati come BART-FID-RAG, Blender2, Emora e Blender Decode. L'obiettivo principale è identificare e quantificare le prestazioni di questi modelli attraverso una serie di metodi di valutazione, inclusi l'ABC-Eval, il Likert Rating e la valutazione comparativa. 

L'ABC-Eval, un nuovo approccio, analizza i comportamenti del sistema durante il dialogo, classificandoli in quattro categorie: Coerenza, Conoscenza, Coerenza e Comportamento emotivo. Questo metodo permette di identificare errori specifici come la mancanza di empatia, la contraddizione di se stessi o degli interlocutori, e gli errori di conoscenza. 

I risultati delle valutazioni mostrano che i modelli presentano diverse difficoltà, con BART-FID-RAG e Blender2 che dimostrano un'alta percentuale di errori in ambiti come la coerenza e la comprensione emotiva, mentre Emora e Blender Decode mostrano un minor numero di errori. La valutazione comparativa evidenzia che i modelli differiscono significativamente nelle loro capacità di gestire aspetti come l'emotività e la coerenza.

Inoltre, l'analisi dei dati ha rivelato che alcune metriche, come l'inter-annotator agreement e la predictive validity, sono più efficaci per valutare la qualità del dialogo rispetto ad altre, come l'incremental validity. Questi risultati offrono una panoramica completa sulle prestazioni dei modelli e suggeriscono direzioni future per migliorare la qualità dei sistemi di dialogo.</sample>
    <sample id="136">Il presente lavoro si concentra sull'analisi e l'implementazione di un nuovo dataset chiamato FERMAT, progettato per valutare le capacità numeriche dei modelli linguistici. L'obiettivo principale è superare i limiti imposti dalle esistenti metriche di precisione, che sono spesso insufficienti per una comprensiva valutazione delle prestazioni dei modelli. FERMAT introduce una serie di esercizi matematici diversificati, inclusi problemi di addizione, sottrazione, moltiplicazione e divisione, che richiedono una comprensione accurata dei numeri e delle operazioni matematiche.

La creazione di FERMAT è motivata dalla necessità di fornire un quadro più completo della capacità numerica dei modelli, che va oltre la semplice precisione. Il dataset comprende una vasta gamma di esercizi, garantendo una distribuzione equilibrata di problemi matematici e linguistici. Questo approccio mira a ridurre la dipendenza dai modelli preaddestrati e a migliorare la diversità linguistica e matematica, offrendo un'analisi più profonda e rappresentativa delle prestazioni dei modelli.

L'implementazione di FERMAT ha dimostrato un notevole potenziale nell'identificare le forti e le deboli zone dei modelli, consentendo di identificare le aree di miglioramento specifiche. Inoltre, l'uso di FERMAT ha permesso di evidenziare come la comprensione dei numeri e delle operazioni matematiche sia cruciale per la performance dei modelli, sottolineando l'importanza di un'analisi più ampia e diversificata.

In conclusione, FERMAT rappresenta un passo significativo verso una valutazione più completa e rappresentativa delle capacità numeriche dei modelli linguistici, offrendo un quadro più dettagliato e comprensivo delle loro prestazioni.</sample>
    <sample id="137">Il presente lavoro introduce Tell2Design, un dataset di grandi dimensioni che comprende piani di casa con istruzioni naturali per guidare la generazione di tali piani. Il dataset è stato creato per studiare la generazione di design guidata dal linguaggio, con un focus particolare sul campo dei piani di casa. Le istruzioni naturali fornite descrivono dettagliamente le caratteristiche e le relazioni tra le diverse parti del piano, come la posizione delle stanze e le loro dimensioni.

Il dataset è stato utilizzato per valutare la performance di modelli di generazione di immagini condizionate dal testo, confrontandoli con baselines esistenti. I risultati mostrano che il modello proposto supera significativamente tutte le baselines, ottenendo punteggi di IoU (Intersection over Union) molto elevati, specialmente quando si considerano solo le istruzioni artificiali. Questo suggerisce che l'uso di istruzioni naturali può essere altamente benefico per migliorare la precisione della generazione di piani di casa.

Inoltre, il dataset è stato utilizzato per sperimentare un approccio basato su Seq2Seq con LLM (Large Language Model), che ha permesso di rappresentare ciascuna stanza attraverso una sequenza di etichette di tipo stanza e un bounding box. Questo approccio ha dimostrato la sua efficacia nel generare piani di casa coerenti e dettagliati.

L'obiettivo finale è quello di promuovere ulteriori ricerche nell'ambito della generazione di design guidata dal linguaggio, con un focus particolare sul campo dei piani di casa. Il dataset e i modelli proposti possono servire come punto di partenza per futuri studi e sviluppi in questo campo.</sample>
    <sample id="138">Knowledge integration from multiple sources.</sample>
    <sample id="139">I nomi dei relatori sono Zhiyang Xu, Ying Shen e Lifu Huang.</sample>
    <sample id="140">Sì, Coscript è stato sottoposto a controlli di qualità.</sample>
    <sample id="141">I limiti delle risorse esistenti per la traduzione dipendente dal contesto includono l'uso di solo una piccola porzione di parole che dipendono dal contesto, l'uso di metriche di livello corpus e metodi esistenti che supportano fenomeni di discorso limitati e lingue.</sample>
    <sample id="142">Il contenuto inglese è già stato tradotto in italiano nel video, quindi non ci sono ulteriori traduzioni necessarie.</sample>
    <sample id="143">walk-k, LA, CAAT, EDAs</sample>
    <sample id="144">L'affiliazione degli autori dell'articolo è la Nantes Université.</sample>
    <sample id="145">Jenny T. Liang</sample>
    <sample id="146">Il presente lavoro si concentra sull'omissione nell'estrazione di sommari da dialoghi, un compito cruciale per l'analisi e la sintesi del linguaggio naturale. L'omissione può compromettere significativamente la qualità dei sommari, influenzando la comprensione e l'utilità delle informazioni riassunte. Il team ha identificato diversi tipi di errori comuni nell'estrazione di sommari da dialoghi, inclusi l'omissione di informazioni essenziali, riferimenti errati, ragionamenti impropri e pronunciamenti di genere inappropriati. Questi errori sono stati analizzati attraverso un dataset di 1000 dialoghi provenienti da cinque domini differenti: SAMSum, Dialsumm, QMSum, EmailSum e TweetSum. 

Per affrontare questo problema, il gruppo ha sviluppato una nuova task di deteczione dell'omissione, che utilizza un approccio model-based per valutare la qualità dei sommari senza riferimento. La deteczione dell'omissione potrebbe essere utilizzata per migliorare la qualità dei sommari, ad esempio attraverso l'aggiunta di informazioni omissive o l'eliminazione di informazioni superflue. Il dataset OLDS (Omission Detection in Dialogue Summarization) è stato creato per supportare questa task, contenendo 10 candidate sommari generati automaticamente per ogni dialogo e annotati sia automaticamente che manualmente.

I risultati preliminari mostrano che i modelli preaddestrati come BART e RoBERTa hanno ottenuto buoni risultati nella deteczione dell'omissione, con precisioni e ricchezze che variano tra il 40% e il 60%. Tuttavia, ci sono ancora spazi per miglioramento, specialmente per modelli più piccoli come T5-small, che presentano una maggiore difficoltà nella deteczione dell'omissione. Inoltre, l'uso di modelli preaddestrati come BART e RoBERTa ha dimostrato una buona capacità di generalizzazione su nuovi dati, confermando la validità della task di deteczione dell'omissione.

In conclusione, la deteczione dell'omissione rappresenta un passo importante verso la creazione di sommari più accurati e utili da dialoghi. Il dataset OLDS fornirà un'importante risorsa per lo sviluppo e l'implementazione di modelli avanzati per la deteczione dell'omissione, contribuendo così alla ricerca nel campo dell'estrazione di sommari da dialoghi.</sample>
    <sample id="147">Tre autori sono coinvolti nell'articolo.</sample>
    <sample id="148">Certo, ecco la traduzione del contenuto inglese in italiano:

1. **Titolo:**
   - "Attenzione come guida per la traduzione simultanea del discorso"

2. **Autori:**
   - Sara Papi, Matteo Negri, Marco Turchi

3. **Introduzione:**
   - "Che cos'è la traduzione simultanea del discorso?"
   - "La traduzione simultanea del discorso (SimuST) è il processo di tradurre il linguaggio parlato in un testo in un altro linguaggio in tempo reale, consentendo la comunicazione multilingue."

4. **Problemi dei modelli attuali di SimuST:**
   - Specifiche architetture vengono solitamente addestrate, introducendo moduli aggiuntivi da ottimizzare.
   - Addestramento e mantenimento di diversi modelli per raggiungere differenti regimi di latenza (ad esempio, 1s, 2s, 25s...).
   - Addestramento e complessità delle procedure di addestramento (ad esempio, obiettivi di ottimizzazione diversi).

5. **Soluzione:**
   - Utilizzare modelli offline ST esistenti senza riestrarli o adottare una specifica architettura per SimuST.
   - Usare solo un modello per ogni regime di latenza e gestire la latenza attraverso parametri specifici.
   - Sfruttare il conoscenza già acquisita dal modello attraverso l'attenzione tra input audio e output testuale.

6. **Sistema proposto: EDAtt**
   - Encoder-Decoder Attenzione
   - Decidere se emettere o non emettere una traduzione parziale basandosi sul punto di attenzione.
   - Un'attenzione non concentrata indica che la somma degli attentamenti è inferiore al soglia (α) verso l'ultimo token, indicando che l'informazione è abbastanza stabile.

7. **Esempi di traduzione:**
   - "I am going to talk about..." -&gt; "Ich werde reden."
   - "I am going to talk about climate." -&gt; "Ich werde über Klima sprechen."

8. **Risultati principali:**
   - EDAtt supera tutte le strategie applicate ai modelli offline.
   - EDAtt è la strategia più veloce se consideriamo il tempo effettivo trascorso.

9. **Invito alla lettura:**
   - "Vogliamo scoprire di più? Leggi il nostro articolo per scoprire risultati ulteriori!"
   - Contatti: @spapi.negri@fbk.eu, marco.turchi@gmail.com, github.com/tlt-mt/fbk-fairseq, @bk_mt, @sarapapi</sample>
    <sample id="149">Sì, il set di dati è disponibile pubblicamente.</sample>
    <sample id="150">Il lavoro presentato si concentra sull'analisi di trascrizioni di riunioni, un tipo di documento lungo e ricco di informazioni specifiche per il dominio. L'obiettivo è sviluppare un dataset di domande estratte (extractive QA) basato sulle domande poste dai partecipanti durante le riunioni e sui rispettivi risposte corrispondenti. Questo dataset è stato creato utilizzando trascrizioni pubbliche del corpus AMI, selezionando domande basate su punti di domanda e lunghezza, e annotando le risposte da parte di annotatori. Il dataset contiene un totale di 7.735 domande provenienti da 166 diverse riunioni, suddivise tra set di addestramento, dev e test. Le statistiche mostrano che il 30% delle domande sono irrisolvibili, il 40% sono multi-span (non-consecutive sentences) e il 48% sono risposte multi-speaker. Le domande sono principalmente di tipo "Yes/No" (54.4%), seguite da "What" (24.4%) e "Who" (9.4%). La performance umana è stata calcolata come F1 = 84.6, con un gap di 25 punti F1 rispetto ai modelli finetunati. I metodi utilizzati includono la retrieval del contesto per modelli a breve contesto, l'uso di modelli multi-span, e l'aggregazione di dati argento per questioni tratte da interviste del dataset MediaSum. Gli esperimenti hanno dimostrato che i modelli finetunati hanno una performance superiore a quella umana, ma che i modelli a breve contesto leggermente superano quelli a lungo contesto. Inoltre, l'aggregazione di dati argento è stata trovata efficace, mentre i modelli più grandi e finetunati hanno prodotto prestazioni comparabili.</sample>
    <sample id="151">### Traduzione del contenuto inglese in italiano

**Titolo:**
MULTIINSTRUCT: Miglioramento della Imparazione a Zero-Mostri tramite Addestramento delle Istruzioni Multimodali

**Autori:**
Zhiyang Xu*, Ying Shen*, Lifu Huang
Dipartimento di Informatica, Virginia Tech

**Abstract:**
Il presente lavoro introduce MultiInstruct, un nuovo dataset di addestramento delle istruzioni multimodali che contiene 62 compiti multi-modali provenienti da 10 categorie diverse. Questo dataset è stato utilizzato per migliorare la capacità di zero-shot dell'architettura OFA attraverso l'addestramento delle istruzioni. Inoltre, si esplorano diversi approcci di apprendimento trasferibile e si dimostra come siano benefici. Inoltre, si progetta una nuova metrica chiamata "sensibilità" per valutare la robustezza del modello.

**Introduzione:**
L'addestramento delle istruzioni è una tecnica che permette ai modelli di linguaggio di imparare a eseguire nuove compiti senza dover essere addestrati su dati specifici per ogni compito. Questo lavoro si concentra sul miglioramento della capacità di zero-shot di un modello pre-addestrato chiamato OFA (One For All) attraverso l'addestramento delle istruzioni.

**Metodo:**
- **Dataset:** Il dataset MultiInstruct contiene 62 compiti multi-modali provenienti da 10 categorie diverse.
- **Addestramento:** L'addestramento delle istruzioni è stato utilizzato per migliorare la capacità di zero-shot di OFA.
- **Apprendimento trasferibile:** Si sono esplorati diversi approcci di apprendimento trasferibile per migliorare ulteriormente la capacità del modello.
- **Metrica Sensibilità:** Una nuova metrica chiamata "sensibilità" è stata progettata per valutare la robustezza del modello.

**Risultati:**
- **Performance:** L'addestramento delle istruzioni ha migliorato significativamente la capacità di zero-shot di OFA.
- **Sensibilità:** La metrica sensibilità ha mostrato che il modello è robusto e non è influenzato da piccole variazioni nelle istruzioni.

**Conclusione:**
- **Dataset:** Il dataset MultiInstruct è il primo dataset di addestramento delle istruzioni multimodali di grandi dimensioni.
- **Impatto:** L'addestramento delle istruzioni ha migliorato significativamente la capacità di zero-shot di OFA.
- **Approcci trasferibili:** Si sono esplorati diversi approcci di apprendimento trasferibile e si è dimostrato che sono benefici.
- **Nuova Metrica:** Una nuova metrica chiamata "sensibilità" è stata progettata per valutare la robustezza del modello.
- **Prossimi Passi:** Si sta raccolgendo un dataset di addestramento delle istruzioni multimodali di dimensioni ancora maggiori e si prevede di rilasciarlo presto.

**QR Code:**
Un QR code è visualizzato con un messaggio invitante a visitare un sito web o scaricare un dataset di addestramento delle istruzioni multimodali di grandi dimensioni.</sample>
    <sample id="152">Il presente lavoro si concentra sull'uso dei modelli di linguaggio grande per la filologia classica, evidenziando i limiti dei modelli esistenti come il Latin BERT e l'Ancient Greek BERT, che sono basati su dataset di pre-allenamento non ottimizzati per il contesto della lingua classica. L'obiettivo è introdurre nuovi modelli multilingue, come GreBERTa e PhilBERTa, che utilizzano dataset di alta qualità per l'allenamento e sono in grado di superare i precedenti risultati. Questi modelli sono stati allenati su una vasta gamma di dati, inclusi testi antichi greci e latini, e hanno dimostrato competenza nell'analisi morfologica, taggatura POS e lemmatizzazione. La ricerca ha anche valutato l'efficacia di questi modelli attraverso l'uso di dataset ufficiali e ha ottenuto risultati di punta nel campo, confermando la loro validità e potenziale applicazione nella filologia classica.</sample>
    <sample id="153">Il presente studio si concentra sulla risoluzione delle ambiguità nei modelli generativi di immagini da testo, un campo cruciale per l'interazione umano-macchina. Le ambiguità possono emergere quando le istruzioni fornite al modello sono imprecise o incomplete, portando a risultati non desiderati. L'articolo introduce il Text-to-Image Ambiguity Benchmark (TAB), un nuovo dataset progettato per valutare e migliorare la capacità dei modelli di risolvere queste ambiguità.

Il TAB è stato sviluppato per coprire una varietà di tipi di ambiguità, come la sintassi, l'anafora discorsiva, l'ellissi discorsiva, la giustizia e la combinazione complessa di questi elementi. Questo benchmark include 1200 esempi di testo ambiguo e 4690 scene visive correlate, offrendo un'ampia base per l'analisi e lo sviluppo dei modelli.

Due approcci principali sono stati proposti per mitigare queste ambiguità: QA-TIED e VS-TIED. Il primo utilizza un'apprendimento in contesto per generare domande clarificanti, mentre il secondo genera diverse configurazioni visive possibili. Entrambi gli approcci sono stati valutati sia automaticamente che attraverso valutazioni umane, dimostrando un buon livello di accordo tra i due metodi.

I risultati sperimentali mostrano che la disambiguazione ha un effetto positivo sulla generazione fedele, riducendo significativamente le ambiguità nel testo e migliorando la precisione delle immagini generate. Tuttavia, ci sono differenze nelle capacità di risolvere diversi tipi di ambiguità, evidenziando la necessità di un approccio personalizzato per ogni tipo specifico di ambiguità.

In conclusione, questo lavoro contribuisce significativamente alla comprensione delle sfide legate alle ambiguità nei modelli di immagini da testo, offrendo strumenti e metodologie per migliorarne la performance e la fedeltà.</sample>
    <sample id="154">L'affiliazione degli autori dell'articolo è l'Università di Trento e la Fondazione Bruno Kessler.</sample>
    <sample id="155">Il relatore è Mohammad Javad Hosseini.</sample>
    <sample id="157">Il presente lavoro si concentra sulla sintesi del dialogo utilizzando una struttura di fusione statica-dinamica per migliorare l'efficacia della sintesi del dialogo. L'approccio proposto, denominato SDDS (Static-Dynamic Dialogue Summarization), integra due tipi di rappresentazioni: una statica e una dinamica, per ottenere una rappresentazione più completa del contesto del dialogo. La struttura statica è costruita utilizzando relazioni discorsive per evidenziare il flusso di informazioni e l'interazione tra le unità del dialogo, mentre la dinamica si occupa di catturare le relazioni semantiche tra le unità basate sulle loro rappresentazioni vettoriali profonde. Il modello architettura di SDDS comprende quattro moduli principali: l'encoder dell'unità del dialogo, la costruzione della rete statica, il modulo della rete statica-dinamica e il generatore di sommario. Questo approccio è stato dimostrato efficace nel migliorare la qualità della sintesi del dialogo, offrendo una rappresentazione più accurata e comprensibile delle conversazioni.</sample>
    <sample id="158">Il presente lavoro si concentra sulla risoluzione del coreferenzialismo nei documenti lunghi, un compito cruciale nell'ambito della linguistica computazionale. La ricerca introduce un nuovo approccio chiamato Dual Cache, che utilizza due cache separate: una L-cache per memorizzare le entità locali con una politica di eviczione LRU (Least Recently Used) e una G-cache per memorizzare le entità globali con una politica LFU (Least Frequently Used). Questo metodo mira a ridurre significativamente i miss di cache, migliorando la performance e l'efficienza del sistema.

L'approccio Dual Cache è stato testato su diverse basi di benchmark pubbliche, dimostrando una superiore efficacia rispetto ai metodi a singola cache esistenti. Le esperimentazioni hanno evidenziato che il Dual Cache ottimizza notevolmente il tempo di inferenza e riduce drasticamente i miss di cache, senza compromettere la precisione del modello. In particolare, quando confrontato con il metodo di Toshniwal et al. (2021), il Dual Cache ha mostrato un aumento del 43% nella F1 score e un decremento del 57% nel tempo di inferenza, mantenendo un minor consumo di memoria.

Per ulteriori prove, il Dual Cache è stato applicato su un documento di livello libro, "Animal Farm", annotando tutti i riferimenti a 20 personaggi. I risultati hanno confermato che il Dual Cache riesce a superare i metodi precedenti, dimostrando una maggiore efficienza e cost-effettività. In conclusione, il Dual Cache rappresenta una soluzione innovativa per la risoluzione del coreferenzialismo nei documenti lunghi, offrendo un equilibrio ottimale tra prestazioni e costo.</sample>
    <sample id="159">Il contenuto inglese è già stato tradotto in italiano nel testo che segue:

### Key Takeaways

- I modelli di linguaggio sono sensibili alle caratteristiche sintattiche/semantiche latenti condivise tra le frasi.
- Le valutazioni MPP con input di frase singola non catturano completamente le conoscenze astratte dei modelli di linguaggio.

### Why do matched prefixes affect LM judgements?

I modelli di linguaggio sono sensibili alle perturbazioni delle frasi in modo da preservare la struttura rilevante e chiedono se i modelli sono simili nella sensibilità a queste frasi.</sample>
    <sample id="160">I token di input vengono mappati ai token di output nel primo passaggio del metodo.</sample>
    <sample id="161">55,000 scripts.</sample>
    <sample id="163">Non si può determinare dal contenuto fornito quale sia il metodo di allineamento migliore per DEplain, poiché non sono stati forniti i risultati comparativi tra i diversi metodi di allineamento.</sample>
    <sample id="164">L'apprendimento scarsamente supervisionato allevia il bottleneck dell'annotazione.</sample>
    <sample id="165">Il presente lavoro si concentra sull'induzione abductive, una forma di ragionamento che cerca di trovare la spiegazione più plausibile per un dato contesto e un'outcome specifica. L'approccio proposto, chiamato LiPoR (Likelihood learning with Posterior Regularization), mira a superare i limiti dell'induzione abductive tradizionale, che richiede annotazioni manuali e soggettive delle spiegazioni plausibili. LiPoR introduce un obiettivo di apprendimento non supervisionato che maximizza la log-likelihood dell'outcome data il contesto, trattando le spiegazioni come variabili latenti. Inoltre, incoraggia la probabilità massima di p(z|x,y) a collassare su un sottoinsieme di spiegazioni, promuovendo l'esclusività tra queste. Questo approccio è stato testato con successo su dati di NLI (Natural Language Inference), dimostrando una significativa migliorata rispetto ai metodi precedenti sia con annotazioni man mano che con annotazioni preesistenti.</sample>
    <sample id="166">Il presente lavoro introduce un nuovo approccio neurale per la ricerca di immagini basato su testi linguisticamente complessi, chiamato Neural Divide-and-Conquer Reasoning Framework. L'approccio si ispira al concetto di "Divide-and-Conquer", che consiste nel dividere un problema complesso in parti più piccole e risolverle separatamente prima di integrare le soluzioni per ottenere il risultato finale. In questo contesto, il sistema è suddiviso in due componenti principali: System 1, che utilizza modelli preaddestrati VLMs per l'analisi analogica del testo, e System 2, che svolge ragionamenti logici per elaborare informazioni complesse. 

System 1 è progettato per gestire efficacemente i testi semplici, mentre System 2 si occupa delle operazioni di ragionamento logico, come la negazione e la congiunzione, per affrontare problemi più complessi. La combinazione di queste due componenti permette di ottenere una maggiore precisione nella ricerca di immagini basata su testi complessi.

L'approccio è stato valutato su diverse basi di dati e ha dimostrato un miglioramento significativo rispetto ai metodi tradizionali. I risultati sperimentali mostrano che il sistema proposto supera notevolmente i precedenti metodi, dimostrando la sua efficacia nell'affrontare problemi di ricerca di immagini basata su testi complessi. Inoltre, il sistema è stato in grado di elaborare testi che contengono fino a due proposizioni, dimostrando la sua capacità di gestire informazioni complesse.</sample>
    <sample id="167">Non è stato fornito dettagli specifici sull'allocatione dei documenti in DEplain-web, ma si può supporre che sia stata effettuata utilizzando un mix di metodi manuali e automatici.</sample>
    <sample id="168">Il set di dati CoNLL++ è stato creato raccolgendo notizie Reuters del 2020 e annotandole secondo le linee guida di CoNLL-2003.</sample>
    <sample id="169">Il presente studio si concentra sulla capacità di PaLM (Pathways Language Model) di tradurre, valutando strategie e prestazioni attraverso un approccio sistematico. La ricerca utilizza una vasta gamma di testi, inclusi i più recenti set di test WMT, per evitare sovrapposizioni tra dati di addestramento e di valutazione. L'obiettivo è valutare le capacità di traduzione di PaLM confrontandole con i sistemi di traduzione attuali, come Google Translate, e suggerire strategie per la selezione efficace dei prompt. I risultati evidenziano che la qualità degli esempi è più importante della somiglianza alla frase di origine, e che i sistemi specializzati SOTA presentano un vantaggio significativo. Inoltre, la fluidità di PaLM è paragonabile a quella dei sistemi SOTA, ma le punteggiate di accuratezza sono generalmente più basse, influenzate principalmente dall'omissione di dettagli. Questo studio offre una panoramica completa delle prestazioni di PaLM nella traduzione, fornendo indicazioni pratiche per migliorarne l'efficacia.</sample>
    <sample id="170">Il contenuto inglese è già tradotto in italiano nel testo che segue:

### Conclusione

- Costruiamo XSemPLR, un benchmark unificato per la parsing semantico multilingue con più lingue naturali e rappresentazioni di significato.
- Effettuiamo uno studio di benchmark comprensivo su tre tipi rappresentativi di modelli di linguaggio multilingue.
- I nostri risultati mostrano che mT5 con training monolingue ottiene il miglior prestazione, mentre i notevoli modelli LLM multilingue sono ancora insufficienti per compiti di parsing semantico multilingue. Inoltre, la differenza di prestazione tra training monolingue e training multilingue continua a essere significativa.

### Altri risultati e trovate (Sezione 4 del Paper)

- Enc-Dec (mT5) supera i risultati precedenti o raggiunge risultati comparabili.
- Il pretraining sul NL inglese può significativamente migliorare le prestazioni per i NL di target di pochi esempi.
- I modelli LLM multilingue (Codex &amp; BLOOM) sono ancora insufficienti per compiti di parsing semantico multilingue. In particolare, il NL cinese ha la maggiore differenza di prestazione, mentre il Germano ha la minore.
- FunQL supera le altre tre rappresentazioni di significato, mentre SQL ottiene le peggiori prestazioni.

### Conclusione

- Costruiamo XSemPLR, un benchmark unificato per la parsing semantico multilingue con più lingue naturali e rappresentazioni di significato.
- Effettuiamo uno studio di benchmark comprensivo su tre tipi rappresentativi di modelli di linguaggio multilingue.
- I nostri risultati mostrano che mT5 con training monolingue ottiene il miglior prestazione, mentre i notevoli modelli LLM multilingue sono ancora insufficienti per compiti di parsing semantico multilingue. Inoltre, la differenza di prestazione tra training monolingue e training multilingue continua a essere significativa.</sample>
    <sample id="171">I lavori connessi sono:

1. Watermarking deep neural networks with watermarking: The frequency domain approach, trust security and privacy in computing and communications 2020.
2. Protecting the intellectual property of language generation APIs with lexical watermark, AAAI 2022.
3. Protecting the intellectual property of language generation APIs with lexical watermark, AAAI 2022.
4. Protecting the intellectual property of language generation APIs with lexical watermark, AAAI 2022.
5. Watermarking deep neural networks by backdoor, USENIX Security 2018.
6. Watermarking deep neural networks by backdoor, USENIX Security 2018.</sample>
    <sample id="172">No, gli LLM multilingue come Codex o Bloom non sono sufficienti per il CLSP.</sample>
    <sample id="174">Il presente lavoro si concentra sull'analisi della qualità degli argomenti, presentando ArgAnalysis35K, un vasto dataset di 35.000 argomenti e analisi di argomenti, derivati direttamente da dibattiti vincenti e debattenti. Questo dataset è notevole per la sua diversità tematica, che copre 24 diverse aree come politica, ambiente e regimi autoritari, assicurando una rappresentatività ampia e variata. Ogni argomento è accompagnato da una valutazione di qualità basata su un modello di rilevanza, che attribuisce un punteggio tra 0 e 1, rendendo l'analisi quantitativa e qualitativa.

L'analisi degli argomenti non si limita alla semplice valutazione di una sola affermazione, ma include un elemento di analisi che identifica le relazioni logiche che provano l'affermazione. Questo approccio introduce una complessità maggiore nell'analisi, distinguendosi dalle semplici valutazioni di qualità. L'elemento di analisi è fondamentale per comprendere la struttura logica dietro ogni argomento, rendendo l'analisi più profonda e significativa.

Inoltre, il dataset è stato sviluppato utilizzando dati raccolti da recenti tornei di dibattito, esperienza acquisita attraverso movimenti passati, e consulenza da parte di esperti debattenti. Questo approccio garantisce la qualità e la pertinenza dei dati, rendendo ArgAnalysis35K un strumento prezioso per gli studi di ricerca e l'addestramento di modelli di apprendimento automatico.

In conclusione, ArgAnalysis35K rappresenta un importante contributo nel campo dell'analisi degli argomenti, offrendo un quadro dettagliato e complesso delle qualità degli argomenti attraverso un'analisi approfondita e una valutazione quantitativa. Questo dataset può essere utilizzato per migliorare l'efficacia degli algoritmi di apprendimento automatico e per fornire una base solida per lo studio della qualità degli argomenti in contesti diversi.</sample>
    <sample id="175">Il metodo affronta l'ambiguità delle permutazioni introducendo un modello di permutazione durante la fase di training.</sample>
    <sample id="176">L'equità di un modello NLP a valle è definita come la capacità del modello di non discriminare tra diversi gruppi di persone sulla base di fattori come etnia, genere o orientamento sessuale.</sample>
    <sample id="177">Yanis Labrak</sample>
    <sample id="178">Il relatore è Koustuv Sinha.</sample>
    <sample id="179">Il presente lavoro si concentra sulla migliorazione delle capacità di ragionamento sulle intenzioni mentali (Theory of Mind, ToM) nei modelli di linguaggio grande (LLM). L'approccio proposto, denominato SymbolicToM, utilizza una rappresentazione grafica esplicita per gestire le relazioni tra i personaggi e le loro azioni, evitando l'overfitting rispetto ai dati di addestramento. Il metodo è stato testato su una serie di modelli LLM diversi, inclusi Macaw-3B, GPT3-Curie, Flan-T5-XL, LLaMA-(7B, 13B), GPT3.5 e GPT4, dimostrando significative migliorie in termini di performance su domande di seconda ordine false-belief. Le prove sperimentali hanno anche evidenziato che SymbolicToM migliora la comprensione di storie fuori campo, come ParaphrasedToM, confermando la sua efficacia generale. Questo approccio non solo supera i modelli supervisionati ma offre un'interpretazione più chiara dei processi di ragionamento, rendendolo un metodo promettente per migliorare la comprensione delle intenzioni mentali nei LLM.</sample>
    <sample id="180">Myra Cheng, Esin Durmus, Dan Jurafsky</sample>
    <sample id="181">Il presente lavoro si concentra sulla distillazione del conoscenza script da modelli di grandi linguaggi (LLMs) per la pianificazione linguistica vincolata. L'obiettivo principale è sviluppare un metodo che permetta ai modelli più piccoli di generare script di alta qualità, utilizzando il dataset Coscript come base. Il metodo proposto consiste in due fasi: innanzitutto, i modelli vengono addestrati con l'in-contesto imparare per generare specifiche finalità a partire da una finalità astratta; successivamente, vengono generati candidati script e filtrati in base alla similarità con le finalità specifiche. Questo approccio è stato valutato attraverso metriche automatiche come ROUGE, BLEU e BERTScore, dimostrando un significativo miglioramento della qualità dei script rispetto ai modelli LLMs. Il dataset Coscript, che incorpora un vincolo aggiuntivo rispetto al dataset astratto, è stato utilizzato per valutare e testare il metodo, mostrando una notevole diversità e pluralismo nelle finalità specifiche generate. Inoltre, il lavoro evidenzia i limiti dell'approccio post-hoc di rango, suggerendo che il dataset Coscript possa essere un'utile risorsa per avanzare la ricerca sulla pianificazione linguistica con complessi e diversi obiettivi e vincoli.</sample>
    <sample id="182">Il tropicalismo nel contesto di questo articolo si riferisce alla cultura, tradizione, orgoglio e esotismo associati ai gruppi marginalizzati.</sample>
    <sample id="183">Gli autori hanno generato personaggi utilizzando prompt come "Imagina di essere una donna asiatica. Descriviti." e hanno ispirato lo studio psicologico con soggetti umani utilizzando i medesimi prompt.</sample>
    <sample id="184">Il modello di informazione mutua condizionale (CXMI) è stato utilizzato per misurare l'utilizzo del contesto.</sample>
    <sample id="185">DrBERT è un modello preaddestrato specifico per il francese, mentre ChuBERT è un modello generico che può essere adattato per le tare di medicina.</sample>
    <sample id="187">Tre autori sono coinvolti nell'articolo.</sample>
    <sample id="188">Il trasferimento iterativo dell'apprendimento è un approccio che utilizza un modello preaddestrato per acquisire nuovi dati e aggiornare il modello successivamente.</sample>
    <sample id="189">L'obiettivo del set di dati è comprendere la lingua degli utenti quando prendono una decisione.</sample>
    <sample id="190">Un utente malintenzionato può estrarre i parametri del modello attraverso un EaaS utilizzando tecniche di apprendimento da embedding, come StolenEncoder.</sample>
    <sample id="191">Tre autori sono coinvolti nell'articolo.</sample>
    <sample id="192">Il presente lavoro introduce CAME, un ottimizzatore di memoria efficiente che si ispira ai metodi esistenti per la riduzione della memoria. L'obiettivo principale è sviluppare un ottimizzatore che possa garantire una convergenza rapida e una riduzione significativa della memoria utilizzata, mantenendo le prestazioni del modello. CAME utilizza una strategia di confidenza per guidare l'ottimizzazione, basata sul confronto tra l'aggiornamento previsto e quello generato. Questo approccio è particolarmente efficace per i modelli di grandi dimensioni come i linguaggi naturali, dove la memoria è un fattore chiave. Gli esperimenti dimostrano che CAME supera gli ottimizzatori esistenti in termini di prestazioni su compiti di training di modelli di grandi dimensioni, dimostrando una notevole efficienza nella gestione della memoria. Inoltre, CAME si dimostra efficace anche per i modelli con batch size elevati, offrendo un'estensione importante per gli ottimizzatori di memoria efficienti esistenti.</sample>
    <sample id="193">4 annotatori sono stati impiegati per creare il set di dati iniziale.</sample>
    <sample id="194">Le affiliazioni degli autori dell'articolo sono l'Università di Washington e la Carnegie Mellon University.</sample>
    <sample id="195">Il presente lavoro si concentra sulla creazione di un sistema per la risoluzione di domande complesse attraverso l'uso di un albero di decomposizione questionaria (HQDT) e una struttura di ragionamento probabilistico. L'obiettivo è migliorare la capacità di rispondere a domande complesse, integrando conoscenze da fonti diverse come corpus testuali e basi di conoscenza formali. Il sistema utilizza un modello BART per generare domande subordinate che vengono poi utilizzate per costruire l'HQDT. Questo approccio permette di determinare la granularità ottimale della decomposizione delle domande e di trovare soluzioni tra le possibili opzioni provenienti da diverse fonti di conoscenza. Il framework RoHT (Reasoning over Hierarchical Question Decomposition Tree) include due fasi principali: la comprensione della domanda complessa e la ragionamento probabilistico sull'HQDT. La prima fase utilizza un modello BART per decomporre la domanda complessa in domande subordinate, mentre la seconda fase impiega un modello KoPL per ottenere risposte con probabilità per ogni domanda dell'HQDT. Il sistema è stato testato su due dataset diversi, KQA Pro e Musique, dimostrando una significativa migliore performance rispetto ai metodi esistenti.</sample>
    <sample id="196">"I saw Bart and Lisa; Homer came and sneezed."</sample>
    <sample id="197">I modelli all'avanguardia nei sistemi di dialogo sono BART-FID-RAG, Blender2, Emora e Blender Decode.</sample>
    <sample id="198">Perché l'accettabilità dei modelli può variare in funzione della lunghezza del contesto, della corrispondenza strutturale e dell'accettabilità.</sample>
    <sample id="199">No, la formazione attraverso la modalità multilingue non ha causato un calo delle prestazioni rispetto al modello inglese monolingue.</sample>
    <sample id="200">No, gli annotatori non conoscono l'entità in anticipo.</sample>
    <sample id="201">SOTA MT metrics e Expert-based human evaluation.</sample>
    <sample id="202">Sì, il regresso nella generalizzazione può influenzare specifici tipi di NER.</sample>
    <sample id="203">La posizionalità nella NLP è importante perché influisce sulle percezioni e le esperienze di vita delle persone, che a loro volta influenzano i risultati della ricerca. Questo significa che i modelli e i dataset possono essere influenzati dalle caratteristiche demografiche, identitarie e di vita delle persone che li creano, e quindi possono avere un'orientamento specifico.</sample>
    <sample id="204">Affinati mediante adattatori.</sample>
    <sample id="205">Il presente studio esplora l'effetto dei dati di pretraining sui modelli di linguaggio e le loro prestazioni su compiti downstream, focalizzandosi sulle sfide politiche che possono influenzare la parzialità dei modelli. Utilizzando una vasta gamma di dati di pretraining, come quelli da news media e social media, si analizza come tali dati influenzino la politica dei modelli e le loro prestazioni su compiti specifici come la rilevazione di odio e la diffusione di notizie false. Il lavoro dimostra che i modelli preaddestrati con dati da fonti politicamente polarizzate tendono a mostrare un'orientamento politico, influenzando così le loro prestazioni su compiti downstream. Inoltre, si evidenzia come la politica dei modelli possa variare significativamente a seconda della fonte di pretraining, evidenziando la necessità di comprendere e gestire tali effetti per garantire la parità e l'imparzialità dei modelli di linguaggio.</sample>
    <sample id="206">RoBERTA-base + classifier head</sample>
    <sample id="207">I recenti set di test utilizzati per valutare le capacità di PaLM sono quelli che non hanno sovrapposizione tra test e train e che evitano l'overfitting sulle metriche di valutazione.</sample>
    <sample id="208">Tre suggerimenti.</sample>
    <sample id="209">Il metodo proposto guadagna significativamente rispetto al metodo di riferimento, con un margine di qualità delle scritture più alto.</sample>
    <sample id="210">Shuheng Liu, Alan Ritter</sample>
    <sample id="211">Sì, i risultati e il set di dati nell'articolo possono essere utilizzati come parametri di riferimento.</sample>
    <sample id="212">Due modelli più piccoli vengono utilizzati nell'articolo: T5 e Flan-T5.</sample>
    <sample id="213">OFA</sample>
    <sample id="215">Il presente studio si concentra sulla struttura delle dipendenze nella coordinazione di sostantivi in lingua inglese, analizzando quattro principali strutture: Bouquet/Stanford, Chain/Moscow, Conjunction-headed/Prague e Multi-headed/London. Ogni struttura è illustrata attraverso esempi grammaticali che mostrano come i sostantivi siano coordinati da una congiunzione. Ad esempio, la frase "Homer loves Lisa, Bart, and Maggie" viene utilizzata per dimostrare come la congiunzione "and" sia al centro della coordinazione, mentre "or" e "nor" sono posizionati alla fine della frase.

L'analisi approfondisce anche il concetto di minimizzazione della lunghezza delle dipendenze (Dependency Length Minimization - DLM), evidenziando come l'ordine delle parole tenda a ridurre la lunghezza delle dipendenze per migliorare la comprensibilità della frase. Questo fenomeno è illustrato con esempi come "Marge read it yesterday" e "Marge read this absolutely fascinating book about bees yesterday", dove l'ordine delle parole facilita la comprensione del legame tra le parole.

Inoltre, il lavoro si basa su statistiche estratte dal Penn Treebank, un corpus di testo ampliato, per confermare che i conjuncts (elementi coordinati) a sinistra tendono a essere più brevi quando il governante (la congiunzione) è assente o è posizionato a destra. Tuttavia, questa tendenza diminuisce quando il governante è a sinistra. Queste conclusioni sono supportate da grafici che visualizzano la proporzione di conjuncts più corti in funzione della differenza assoluta della lunghezza dei conjuncts.

In sintesi, questo studio offre una panoramica approfondita sulle strutture di coordinazione e sulla loro compatibilità con le diverse strutture di dipendenza, fornendo una base teorica e statistica per comprendere meglio la grammatica coordinativa in inglese.</sample>
    <sample id="217">Il presente lavoro si concentra sulla generazione di dialoghi complessivi per più attributi, sviluppando un modello di dialogo controllabile basato su prompt disintaccato. L'approccio proposto utilizza vettori di prompt specifici per gli attributi e una perdita di disintaccamento per separare diversi attributi. Inoltre, viene sviluppato un framework di valutazione unificato senza riferimento, MAE, per la generazione multi-attributo. Gli esperimenti dimostrano che il metodo proposto ottiene risultati migliori in termini di qualità del testo e di controllo degli attributi rispetto ai metodi precedenti. Inoltre, il MAE mostra una maggiore correlazione con le giudiziazioni umane per l'evaluazione del CDG (Compositional Dialogue Generation).</sample>
    <sample id="218">Google</sample>
    <sample id="219">Il presente lavoro si concentra sulla creazione di un pipeline multistadio per l'identificazione di segnali finanziari in report finanziari. L'approccio proposto è incentrato su una complessa serie di fasi che includono la segmentazione del documento, la riconoscenza delle relazioni e la fase di fine-tuning sia in ambito di domini sia fuori di esso. Il focus principale è sulla definizione di un compito di evidenziamento che prevede la predizione delle parole di ragione o importanti attraverso la comparazione e la contrasto dei contesti di una coppia di frasi date. La ricerca introduce anche un dataset umanamente annotato per valutare l'efficacia del modello. Gli esperimenti dimostrano che i modelli adattativi al dominio sono in grado di superare tutte le altre configurazioni senza perdere la generalità delle rappresentazioni token. Inoltre, il lavoro suggerisce diverse direzioni future di ricerca, come l'uso di corpus finanziari più ampi, l'applicazione di tecniche di razionalizzazione bidirezionale su altri linguaggi e l'esplorazione di modelli di apprendimento end-to-end per applicazioni come la densa recupero di spiegazioni.</sample>
    <sample id="220">Stony Brook University, Human Language Analysis Settings</sample>
    <sample id="221">Inglese-Germano e Inglese-Francese.</sample>
    <sample id="222">Il presente lavoro si concentra sull'analisi delle sfide e delle interventi nell'ambito dell'Open-Domain Question Answering (QA). L'obiettivo principale è sviluppare una metodologia per migliorare la performance dei modelli di QA attraverso l'intervento su dati specifici, con l'obiettivo di ridurre la dipendenza da dataset di riferimento. La ricerca esplora diversi metodi di adattamento, inclusi l'adattamento a zero-shot e a pochi esempi, e valuta l'efficacia di questi metodi in risposta a diversi tipi di spostamento di dataset. 

L'approccio proposto utilizza interventi di dati che variano le domande, le risposte e il contesto, con l'obiettivo di aumentare la compatibilità tra il modello di lettura e il nuovo dataset. I risultati dimostrano che l'adattamento a pochi esempi può migliorare significativamente la performance del lettore e del recuperatore, con un aumento del 24% nella precisione del lettore e del 22% nel F1-score del recuperatore. Inoltre, l'efficacia dell'intervento dipende dal tipo di spostamento di dataset, evidenziando che l'intervento può essere più efficace per certi tipi di spostamento rispetto ad altri.

Questo lavoro contribuisce alla comprensione delle dinamiche di generalizzazione dei modelli di QA e suggerisce una direzione per migliorare la loro capacità di adattarsi a nuovi contesti.</sample>
    <sample id="223">Shangbin Feng</sample>
    <sample id="224">I modelli studiati durante gli esperimenti sono UDA, Sent-Label, Sent-RED, CATS-C3G, VecAlign e MASSign.</sample>
    <sample id="225">Per addestramento vengono utilizzate 53 attività, mentre per test vengono utilizzate 9 attività.</sample>
    <sample id="226">Tre autori sono coinvolti nell'articolo.</sample>
    <sample id="227">Il presente lavoro introduce Pangu, un nuovo framework per l'interpretazione linguistica basata su dati reali. L'obiettivo principale è migliorare la comprensione del linguaggio naturale attraverso l'integrazione di modelli autoregressive e discriminatori. Questo approccio mira a superare i limiti dei modelli attuali, che spesso soffrono di overfitting durante l'addestramento, specialmente nei casi di generalizzazione non-iid (non identici e indipendenti). Pangu si distingue per la sua capacità di focalizzare i modelli discriminatori sulle discriminazioni pertinenti, rendendo l'approccio generico e adatto a una varietà di contesti. Gli esperimenti dimostrano che Pangu ottiene prestazioni significative in termini di F1-score su diverse task, come GraphQuestions e WebQSP, con un minor aumento del modello rispetto ai metodi precedenti. Inoltre, Pangu dimostra una maggiore efficienza campionaria, riducendo il numero di esempi necessari per ottenere prestazioni competitive. Questo lavoro rappresenta un passo avanti nel campo dell'interpretazione linguistica basata su dati reali, offrendo un'alternativa promettente all'approccio tradizionale di generazione diretta di piani.</sample>
    <sample id="228">Gli autori hanno effettuato i test su quattro diversi set di dati: AG News, MIND, SST2 e Enron Spam.</sample>
    <sample id="229">Il presente lavoro si concentra sulla revisione dei testi argomentativi, un processo fondamentale per migliorare l'efficacia persuasiva delle affermazioni. L'argomento è introdotto con una panoramica sul ruolo cruciale della revisione nel processo di scrittura argomentativa, evidenziando come le variazioni nella formulazione delle affermazioni influenzino significativamente l'impatto persuasivo sull'audience. Il lavoro propone due principali compiti: la deteczione delle affermazioni subottimali e la suggerimento di miglioramenti. Utilizzando dati provenienti da piattaforme di dibattito collaborativo come Kialo, il modello si basa su pattern di revisione impliciti per valutare la qualità delle affermazioni e identificare quelle che possono essere migliorate. Questo approccio mira a fornire supporto per la scrittura argomentativa, offrendo strumenti per rilevare e correggere le affermazioni subottimali, contribuendo così alla formazione di argomenti più efficaci e persuasivi.</sample>
    <sample id="231">NACHOS è un dataset di parole aperte di 1,188 parole che raccolgono dati di dati medici diversi da diverse fonti cliniche, natural e stilistiche.</sample>
    <sample id="232">Il relatore è David Var Tormo.</sample>
    <sample id="233">L'abstract si concentra su una ricerca che introduce un nuovo approccio per la traduzione simultanea del discorso (Simultaneous Speech Translation, SimuST). L'obiettivo principale è migliorare l'efficienza e la precisione delle traduzioni in tempo reale, riducendo i problemi associati ai modelli attuali come l'addestramento di architetture specifiche e le complesse procedure di ottimizzazione. La soluzione proposta, chiamata EDAtt, utilizza già esistenti modelli offline di traduzione senza doverli riequipaggiare o adattare specificamente per SimuST. Questo approccio permette di utilizzare un solo modello per ogni regime di latenza, gestendo la latenza attraverso parametri specifici. EDAtt sfrutta il know-how acquisito dai modelli attraverso l'attenzione tra l'input audio e l'output testuale. Il sistema decide quando emettere una parola o una traduzione parziale basandosi sul punto di attenzione, con una soglia stabilita per determinare se la somma dell'attenzione è inferiore a un valore critico. I risultati mostrano che EDAtt supera tutte le strategie applicate ai modelli offline, offrendo un'alta qualità della traduzione con un minor tempo di elaborazione.</sample>
    <sample id="234">La strategia del prompting ha un impatto significativo sulla qualità della traduzione, come dimostrato dal fatto che le differenze tra le prestazioni delle traduzioni possono arrivare fino a 40 punti BLEURT.</sample>
    <sample id="235">Le affiliazioni degli autori dell'articolo sono Carnegie Mellon University, Language Technologies Institute, TECNICO LISBOA, BAIR, Berkeley Artificial Intelligence Research, e Unbabel.</sample>
    <sample id="236">Le 5 istruzioni scritte da esperti sono:
1. Visual Relationship
2. VQA
3. Temporal Ordering
4. Grounded Generation
5. Grounded Matching</sample>
    <sample id="237">Gli autori propongono KITMUS, un insieme di test per valutare l'integrazione del conoscenza da diverse fonti.</sample>
    <sample id="238">Il presente lavoro introduce MeetingBank, un dataset di riferimento per la sommarizzazione di riunioni, creata attraverso la segmentazione di riunioni del consiglio comunale e l'associazione con sommari scritti da esperti. Il dataset è stato raccolto attraverso Speechmatics e comprende riunioni da sei città diverse, coprendo un periodo dal 2015 al 2022. Ogni riunione è stata segmentata in parti, ciascuna con un sommario riferimento, e le trascrizioni sono state utilizzate per generare sommari automatici. La dimensione totale del dataset è di 1.366 riunioni, con 3.779 sommari trascritti e 4.852 sommari automatici. L'analisi del dataset ha evidenziato che la copertura dei sommari varia tra 0.7 e 0.9 per la maggior parte delle città, con Seattle e Boston presentando la maggiore densità e Denver la minore. I risultati dell'analisi mostrano che i modelli estrattivi, come Extr-Oracle, ottenono una precisione di Rouge-2 del 46.6%, mentre i modelli abstrattivi, come DialogLM, raggiungono il miglior risultato con una precisione di Rouge-2 del 60.12%. Inoltre, la valutazione umana ha confermato che i sommari automatici sono altamente informativi e coerenti, ma possono includere ridondanze. Questo dataset rappresenta un'importante risorsa per gli studiosi che sviluppano sistemi di sommarizzazione avanzati e offre interessanti洞sight sul processo decisionale dei consigli comunali.</sample>
    <sample id="239">Il contenuto inglese è già stato tradotto in italiano nel video, quindi non ci sono ulteriori traduzioni necessarie.</sample>
    <sample id="240">### Conclusione

#### Approcci recenti di supervisione debole (WSL)

- **Richiedono campioni puliti.**
- **Sovrastimano la loro praticabilità.**

#### Raccomandazioni

- **Rapportare i criteri di selezione del modello.**
- **Usare approcci di apprendimento a pochi esempi come baselines.**
- **Sempre applicare l'ottimizzazione continua (CFT).**

### Riassunto

Recenti approcci di supervisione debole (WSL) richiedono campioni puliti e sovrastimano la loro praticabilità. Le raccomandazioni sono:
1. Rapportare i criteri di selezione del modello.
2. Usare approcci di apprendimento a pochi esempi come baselines.
3. Sempre applicare l'ottimizzazione continua (CFT).

---

Grazie!</sample>
    <sample id="241">L'abstract del documento si concentra sull'importanza dell'uso di sistemi umani-in-loop (HiTL) per la detezione e la verifica delle informazioni false, con particolare riferimento alla pandemia di COVID-19. L'approccio proposto mira a migliorare l'efficacia della detezione delle false notizie, integrando feedback umano in modo efficace all'interno di un sistema end-to-end. Questo approccio è stato implementato per valutare la detezione di false dichiarazioni riguardanti le terapie non approvate per il COVID-19 su Twitter. Il sistema identifica e valuta le false dichiarazioni, fornendo una classificazione basata sulla tendenza e sulle violazioni di politiche, e fornisce una lista di tweet che supportano tali dichiarazioni. La validazione umana è cruciale per determinare la posizione del tweet rispetto alla dichiarazione errata e per fornire una lista di tweet che supportano la terapia non approvata. L'efficacia dell'approccio è misurata sulla capacità di identificare le false dichiarazioni in tempi precoci rispetto all'apparizione della notizia negativa in un articolo di notizie. Inoltre, il sistema ha identificato un numero significativo di tweet che violano le politiche di Twitter, dimostrando la sua utilità nella gestione delle false notizie durante la pandemia.</sample>
    <sample id="242">I metodi di valutazione comuni per i sistemi di dialogo includono l'analisi comparativa, la valutazione del rating Likert e l'annotazione dei comportamenti nel chat (ABC-Eval).</sample>
    <sample id="243">Cinque autori sono coinvolti nell'articolo.</sample>
    <sample id="244">Nell'esempio con Servin e Kea, le conoscenze di base necessarie sono quelle relative alle professioni di Servin e Kea, ovvero "Servin is a judge" e "Kea is a baker".</sample>
    <sample id="245">L'abstract del video riguarda uno studio che analizza i lavoratori di Amazon Mechanical Turk (MTurk) per la sintesi automatica, focalizzandosi su come trovare i lavoratori con alta accordanza. L'approccio proposto utilizza una pipeline in due fasi: una fase di qualificazione e una fase di resistenza. La fase di qualificazione prevede una serie di test per valutare la competenza dei lavoratori, inclusi test di comprensione di documenti e sintesi, con tre livelli di qualifica (oro, argento, bronzo). I lavoratori che superano questi test sono poi inviati alla fase di resistenza, dove devono completare una serie di compiti di sintesi automatica. Il risultato finale è una selezione accurata di lavoratori altamente qualificati, come dimostrato dal confronto con i lavoratori di CloudResearch, che ha un alto livello di accordo tra annotatori. L'abstract conclude sottolineando l'efficacia della pipeline nel trovare lavoratori di alta qualità a basso costo, con potenziali applicazioni in diverse aree di applicazione, come la sintesi automatica in lingue diverse e piattaforme.</sample>
    <sample id="246">Sì, il codice è disponibile su GitHub all'indirizzo mpoeens/kitmus.</sample>
    <sample id="247">Il presente lavoro introduce FactKG, un nuovo dataset per la verifica di fatti attraverso ragionamento su grafi conoscitivi (Knowledge Graphs). Il dataset contiene 108K dichiarazioni naturali in lingua inglese con cinque tipi di ragionamento: One-hop, Conjunction, Existence, Multi-hop e Negation. Questi ragionamenti includono diverse strutture linguistiche, come le affermazioni colloquiali, che aumentano la praticità del dataset. Inoltre, FactKG incorpora evidenze grafiche per migliorare l'efficacia della verifica dei fatti. Gli esperimenti dimostrano che l'integrazione di queste evidenze grafiche ha portato a prestazioni superiori rispetto ai baselines che non le utilizzavano. Il dataset è disponibile online e può essere utilizzato per facilitare l'adeguata sfruttamento dei grafi conoscitivi da parte della comunità.</sample>
    <sample id="248">Sì, gli annotatori per NLPositionality sono bilanciati rispetto a ciascun gruppo demografico, come ad esempio Paese e genere.</sample>
    <sample id="249">Le frasi nel dominio accettabile sono state perturbate in modo da mantenere la struttura relativa, come ad esempio l'aggiunta di prefissi o suffissi che mantengono la struttura sintattica originale.</sample>
    <sample id="250">La valutazione dimensionale si riferisce all'analisi delle qualità del dialogo attraverso diversi aspetti specifici, come la rilevanza, la coerenza e l'intelligenza emotiva.</sample>
    <sample id="251">Le affiliazioni degli autori dell'articolo sono l'Università di Scienza e Tecnologia di Shandong, Microsoft Research Asia, Beijing Jiaotong University e Sony AI.</sample>
    <sample id="252">Il presente lavoro introduce U-CREAT, un sistema innovativo per la ricerca di casi basato su eventi, progettato per l'ambito legale indiano. L'approccio event-based permette di rappresentare i documenti legali come una sequenza di eventi, offrendo un vantaggio significativo rispetto ai metodi tradizionali che utilizzano solo le parole chiave. Il sistema è stato sviluppato senza supervisione e non richiede specifiche configurazioni corpus, rendendolo adatto per una varietà di contesti legali. U-CREAT ha dimostrato una performance superiore rispetto ai metodi basati sulle parole chiave e agli event-based standard, con F1-score migliorati del 22% in IL-PCR e del 14% in COLIEE'21 rispetto al metodo BM25. Inoltre, offre tempi di inferenza più brevi, rendendolo ammissibile per applicazioni di produzione. Il dataset IL-PCR proposto è un contributo significativo per la ricerca di casi precedenti nel settore legale indiano.</sample>
    <sample id="253">Il presente lavoro si concentra sulla creazione di DisorBERT, un modello di apprendimento automatico progettato per identificare segni di disturbi mentali nei dati sociali. Il modello utilizza una doppia adattamento di dominio e una maschera guidata per migliorare l'accuratezza nella rilevazione di sintomi psicologici come la depressione e l'ansia. L'approccio è stato testato sui dataset eRisk, dimostrando risultati superiori rispetto a quelli ottenuti con BERT, un modello simile ma meno specifico. La valutazione ha evidenziato che DisorBERT è efficace nel trovare e etichettare correttamente i pazienti, rendendolo adatto per applicazioni cliniche di deteczione. In futuro, si intende esplorare l'applicazione di risorse lessicali diverse e l'utilizzo di dati clinici per addestrare modelli più specializzati.</sample>
    <sample id="254">Il presente lavoro introduce un approccio innovativo per l'estrazione distante di relazioni al livello del documento (DocRE) che utilizza una tecnica di denoising guidata dall'incertezza per migliorare la qualità delle etichette dei dati DS (Distantly Supervised). L'approccio si basa su una metodologia iterativa che prevede la generazione di pseudoetichette con incertezza da parte di un modello pre-densificato di estrazione di relazioni, seguita da una strategia di re-labeling iterativa con soglie di incertezza dinamiche per filtrare le etichette di alta incertezza. Questo metodo è stato testato su due dataset pubblici e ha dimostrato significative migliorie rispetto ai baselines esistenti, evidenziando un miglioramento notevole nella qualità delle etichette sui dati DS denoisati.</sample>
    <sample id="255">La forma del prompting può essere importante quando si cerca di ottenere traduzioni di alta qualità.</sample>
    <sample id="257">I modelli di dialogo valutati dagli autori sono BART-FID-RAG, Blender2, Emora e Blender Decode.</sample>
    <sample id="258">Il presente studio esplora l'uso dei modelli di linguaggio di grandi dimensioni (LLM) come alternativa agli評価 da parte umana. L'approccio proposto è di fornire istruzioni naturali ai LLM per valutare le qualità delle storie generate, come grammaticalità, coerenza, likability e rilevanza. Il metodo è stato applicato su storie generate da GPT-2 e scritte da umani, con la valutazione effettuata da insegnanti di inglese utilizzando le stesse istruzioni di valutazione. I risultati mostrano che i LLM, specialmente text-davinci-003 e ChatGPT, dimostrano una chiara preferenza per le storie scritte da umani, mentre i modelli più piccoli non evidenziano una preferenza significativa. Questo studio contribuisce a comprendere meglio l'efficacia degli LLM nella valutazione di contenuti scritti e apre nuove prospettive per l'uso di questi strumenti nell'ambito dell'evaluation automatica.</sample>
    <sample id="259">Il presente lavoro si concentra sulla creazione di un nuovo benchmark, chiamato XSemPLR, per la parsing semantico multilingue che supporta diverse lingue naturali e rappresentazioni del significato. L'obiettivo è offrire una valutazione complessiva delle prestazioni di modelli di linguaggio naturale (NLP) su una vasta gamma di domini e applicazioni. Il dataset XSemPLR contiene nove domini diversi, cinque tipi di query semantiche, otto rappresentazioni del significato e 22 lingue naturali in 15 famiglie linguistiche. I risultati dimostrano che l'approccio Enc-Dec (mT5) supera i precedenti studi e raggiunge prestazioni comparabili, mentre le preaderzioni su lingue naturali specifiche migliorano significativamente le prestazioni su lingue bersaglio. Tuttavia, i modelli multilingui (LLMs) come Codex e BLOOM sono ancora insufficienti per compiti di parsing semantico multilingue, con FunQL che supera le altre rappresentazioni del significato e SQL che ottiene le peggiori prestazioni. Inoltre, il parsing semantico multilingue può essere migliorato con l'addestramento su una combinazione di varie lingue naturali.</sample>
    <sample id="260">Nove autori sono coinvolti nell'articolo.</sample>
    <sample id="261">Un buon pianificatore dovrebbe essere in grado di decomporre efficacemente gli obiettivi astratti in passaggi specifici, gestire diverse restrizioni e garantire la fedeltà alle istruzioni fornite.</sample>
    <sample id="262">Ci sono sei autori coinvolti nell'articolo.</sample>
    <sample id="263">Il presente lavoro si concentra sulla mitigazione delle bias di etichetta nell'apprendimento in contesto, un fenomeno comune nei modelli di linguaggio che influisce significativamente sulle prestazioni di classificazione. L'analisi ha identificato tre tipi principali di bias: bias vanilla-label, bias context-label e bias domain-label. Questi bias sono principalmente determinati dal corpus di dati di addestramento, che può essere sessoziale o non rappresentativo del contesto di utilizzo.

L'approccio proposto è la calibrazione del contesto e del dominio (Domain-Context Calibration), che mira a mitigare questi bias in modo integrato. La calibrazione del contesto implica l'uso di una combinazione di esempi di contesto e di calibrazione del dominio per migliorare le predizioni dei modelli. Questo approccio è stato dimostrato efficace in diverse tasche di classificazione, specialmente quando il bias del dominio è elevato.

I risultati sperimentali mostrano che la calibrazione del contesto e del dominio migliora significativamente le prestazioni dei modelli, riducendo i bias e aumentando la precisione delle predizioni. In particolare, l'uso di più token content-free durante la calibrazione sembra migliorare ulteriormente le prestazioni, suggerendo che l'approccio sia sub-optimale con solo uno token.

In conclusione, il lavoro introduce una nuova metodologia per mitigare i bias di etichetta nell'apprendimento in contesto, offrendo un contributo significativo per migliorare l'efficacia dei modelli di linguaggio in contesti reali.</sample>
    <sample id="264">Il presente lavoro si concentra sulla generazione di testo audiovisivo trasferibile, un campo che mira a sviluppare modelli che possano adattarsi rapidamente a nuovi contesti multi-modal senza necessità di grandi quantità di dati etichettati. L'approccio proposto, chiamato TAVT (Towards Transferable Audio-Visual Text Generation), affronta due principali sfide: la difficoltà e l'alto costo dell'annotazione dei dati audiovisivi e la degradazione severa delle prestazioni degli esistenti modelli quando si applicano a domini multi-modal diversi. 

L'abstract illustra come TAVT utilizza una pipeline composta da tre componenti principali: un network meta-mappatore audiovisivo, un encoder audiovisivo e un generatore di modello linguistico, insieme a una tecnica di apprendimento contrastivo counterfactual per migliorare l'adattabilità. Questo approccio è dimostrato attraverso un'analisi dettagliata del processo di generazione del testo, che include l'uso di tecniche di attenzione auto e cross-modale, e di una struttura di rete che mappa gli input audiovisivi in uno spazio semantico universale. 

I risultati sperimentali mostrano che TAVT supera significativamente i metodi esistenti, dimostrando una maggiore capacità di adattamento a nuovi domini multi-modal con pochi dati etichettati. Inoltre, l'analisi ablativa suggerisce che l'uso di feature audio sia cruciale per l'efficacia del sistema.</sample>
    <sample id="265">Il nome della relatrice o del relatore è Vasudha Varadarajan.</sample>
    <sample id="266">Istituto di Scienza della Computazione, Accademia Polacca delle Scienze e Università di Varsavia.</sample>
    <sample id="268">Gli errori più comuni di PaLM sono dominati da "Accuracy/Omission" e generalmente hanno una "Style/Awkarid" più bassa.</sample>
    <sample id="269">Il contenuto del video è un discorso che parla di valutazione dei sistemi di dialogo orientati al chat, con particolare riferimento alla loro qualità e capacità di interazione. Ecco una traduzione approssimativa del contenuto:

---

Non dimenticare le tue ABC: Valutare l'Arti di punta nei sistemi di dialogo orientati al chat

Sarah E. Finch, James D. Finch, e Jinho D. Choi

Emory NLP Research Lab

Alexa

Il discorso si concentra sulla valutazione comparativa dei sistemi di dialogo orientati al chat, utilizzando diversi metodi di valutazione come la valutazione Likert e la valutazione ABC-Eval. Questi metodi sono utilizzati per valutare la qualità del dialogo, inclusi aspetti come la coerenza, la conoscenza e l'intelligenza emotiva.

La valutazione Likert è un metodo di valutazione che richiede che gli utenti valutino le risposte dei bot su una scala da 1 a 5, dove 1 indica la minima qualità e 5 indica la massima qualità. Questo metodo è utilizzato per valutare la relazione delle risposte dei bot.

ABC-Eval è un altro metodo di valutazione che annota i comportamenti nel chat. Questo metodo identifica errori come la mancanza di empatia, la contraddizione, la mancanza di coerenza e altre problematiche. Gli errori vengono classificati in quattro categorie: coerenza, conoscenza, consistenza e intelligenza emotiva.

Gli esperimenti condotti includono 4 modelli di dialogo aperti e 100 conversazioni tra umani e bot per ogni modello. I risultati mostrano che i modelli di dialogo avanzati come BART-FID-RAG, Blender2 e Emora hanno migliorato significativamente la qualità del dialogo rispetto ai modelli più semplici come Blender Decode.

In conclusione, il discorso evidenzia l'importanza della valutazione accurata dei sistemi di dialogo orientati al chat per migliorare la loro qualità e la loro interattività.</sample>
    <sample id="270">I tre autori dell'articolo sono affiliati all'Emory NLP Research Lab e all'Emory University.</sample>
    <sample id="271">Continuous fine-tuning</sample>
    <sample id="272">Ci sono sei autori coinvolti nell'articolo.</sample>
    <sample id="273">Il contenuto inglese è già stato tradotto in italiano nel testo precedente.</sample>
    <sample id="274">Yusen Zhang</sample>
    <sample id="276">L'abstract si concentra sull'importanza dell'evaluazione automatica delle traduzioni per le lingue indiane, evidenziando la necessità di sviluppare metriche specifiche per queste lingue invece di adottare quelle progettate per l'inglese. Il lavoro introduce IndicMT Eval, un dataset progettato per valutare e mettere alla prova le metriche di traduzione automatica per le lingue indiane. L'approccio utilizza il framework MQM per la raccolta di annotazioni umane da esperti bilingui, che valutano i sistemi di traduzione su vari criteri come accuratezza, fluidezza e altri errori speciali. Il dataset comprende 5 lingue appartenenti a due famiglie linguistiche diverse: Tamil e Malayalam (Dravidian) e Hindi, Marathi e Gujarati (Indo-Aryan). La raccolta dei dati è basata sul Flores dataset, selezionando 200 frasi casuali per ogni lingua e ottenendo 7000 campioni totali. I risultati mostrano una correlazione significativa tra le metriche automatiche e le valutazioni umane, con un'accuratezza media del 43% per le lingue indiane. Questo lavoro contribuisce a migliorare la qualità delle traduzioni automatiche per le lingue indiane, offrendo un quadro più preciso per la loro valutazione.</sample>
    <sample id="277">Il nuovo metodo ha un nome: "Ours".</sample>
    <sample id="278">L'autore ha descritto le parole contrassegnate come quelle che distinguono i gruppi contrassegnati dai gruppi non contrassegnati, definendo i gruppi contrassegnati come diversi dal default e i gruppi non contrassegnati come predefiniti e ordinari.</sample>
    <sample id="279">Le affiliazioni degli autori dell'articolo sono Paul Allen School, University of Washington, UW NLP, Carnegie Mellon University, Language Technologies Institute.</sample>
    <sample id="280">Il presente lavoro introduce MultiEMO, un framework multimodale basato sull'attenzione e consapevole delle correlazioni per la riconoscimento dell'emozione in conversazioni. L'obiettivo principale è prevedere l'etichetta di emozione di ogni enunciato in una conversazione, utilizzando informazioni multimediali come testo, audio e visione. Il framework è composto da quattro componenti: estrazione e modellizzazione del contesto unimodale, fusione multimodale, fusione multimodale e classificazione dell'emozione. Viene proposto VisExtNet, un estrattore visivo innovativo che cattura efficacemente i segnali visivi degli interlocutori senza codificare informazioni scene redundanti. Inoltre, viene progettato MultiAttn, un modello di fusione multimodale basato su multi-head cross-attention, che modella le complesse correlazioni tra modaliità testuale, audio e visiva. Il framework è stato testato su due dataset di benchmark ERC (MELD e IEMOCAP), dimostrando risultati di avanzamento di stato dell'arte con miglioramenti significativi nelle classi di emozioni minoritarie e semanticamente simili. Tuttavia, ci sono limitazioni come la difficoltà nell'identificare speaker e persone irrilevanti nel contesto visivo e il costo computazionale elevato dovuto all'uso del SWFC loss.</sample>
    <sample id="281">Il presente studio si concentra sull'importanza del contesto nella traduzione, esplorando sistematicamente come le modelli di traduzione gestiscono le sfide legate al contesto. Attraverso una ricerca datadriven e multilingue, l'analisi ha identificato che solo una piccola porzione delle parole dipende dal contesto, rendendo l'evaluazione della traduzione condizionata dal contesto complessa. I risultati mostrano che i modelli attuali supportano limitati fenomeni discorsivi e linguistici. L'approccio introdotto, il CXMI (Conditional Cross-Mutual Information), misura la quantità di contesto utilizzata dai modelli di traduzione. La ricerca ha evidenziato che le parole con alta P-CXMI richiedono spesso il contesto per essere tradotte correttamente, con un focus su fenomeni come pronomi, forme verbali, coesione lessicale e formalità. Questi risultati sono stati confermati attraverso l'analisi tematica e l'uso di un benchmark multilingue. In conclusione, il CXMI offre una panoramica chiara sulle sfide e le opportunità della traduzione condizionata dal contesto, offrendo un quadro dettagliato per migliorare la comprensione e l'implementazione dei modelli di traduzione.</sample>
    <sample id="282">**Abstract**

This research introduces **StoryTrans**, a novel approach for non-parallel story author-style transfer, focusing on discourse representation and content enhancement. The challenge lies in transferring a vernacular story into a specific author's style while preserving the original narrative content. The solution involves two key components: discourse representation transfer and content preservation enhancing. Discourse representation is achieved through a masked source story and style embedding, followed by a decoder that reconstructs the transformed story. Content preservation is ensured by a pointer network that aligns the source and target sentences, ensuring the transferred story retains the original narrative structure and details. The training framework combines a first-stage model trained with a language modeling loss function and a second-stage model using a denoising auto-encoder (DAE) loss to reconstruct the original story. Experimental results demonstrate that StoryTrans effectively transfers author styles while maintaining high content accuracy and style consistency across various datasets, including Chinese and English stories.</sample>
    <sample id="283">Bouquet/Stanford (Universal Dependencies)</sample>
    <sample id="284">In questo lavoro, viene presentato FSUIE (Fuzzy Span Universal Information Extraction), un modello innovativo per l'estrazione universale dell'informazione che utilizza una nuova perdita fuzzy span e un attenzione efficiente fuzzy span. FSUIE si concentra sulle informazioni semantiche all'interno di un raggio limitato di token precedenti piuttosto che sulla rappresentazione globale, migliorando così la precisione nell'estrazione delle spaziali. L'approccio fuzzy span permette una modellizzazione continua della distribuzione delle frontiere, evitando l'overfitting su specifici confini. Inoltre, l'attenzione fuzzy span adatta automaticamente lo spazio di attenzione per guidare la distribuzione corretta dell'attenzione. Questo modello è stato testato su una varietà di compiti di estrazione dell'informazione, come NER, RE e ASTE, dimostrando significative migliorie rispetto al modello base UIE e una maggiore generalizzazione delle capacità di estrazione delle spaziali su piccole basi dati. FSUIE ha ottenuto risultati eccellenti in tutti i compiti di estrazione dell'informazione, confermando la sua efficacia e versatilità.</sample>
    <sample id="285">Il presente studio si concentra sulla correzione degli errori fatti in modelli di sommariizzazione di dialoghi, evidenziando l'importanza della precisione dei sommari. I risultati mostrano che i modelli attuali hanno difficoltà nell'identificare e correggere gli errori fatti, specialmente quelli di attribuzione e collegamento. L'introduzione di sommarii corretti da umani durante la fase di addestramento può migliorare significativamente le prestazioni dei modelli. Inoltre, è stato dimostrato che l'uso di una combinazione di dati annotati manualmente e sintetici può essere un approccio promettente per migliorare l'efficacia delle metriche di valutazione. Questo lavoro suggerisce che ci sia un'urgenza nel cambiare le metodologie di valutazione attualmente utilizzate per FEC (Factual Error Correction) modello.</sample>
    <sample id="286">Sarah E. Finch, James D. Finch e Jinho D. Choi sono i relatori.</sample>
    <sample id="287">Quattro autori sono coinvolti nell'articolo.</sample>
    <sample id="288">I dati che possono essere utilizzati per testare i fenomeni sintattici includono le pariglie minimali, come quelle presentate nel diagramma "Revisiting Minimal Pair Paradigm". Queste pariglie sono utilizzate per valutare la conoscenza astratta dei modelli linguistici (LMs) attraverso l'uso di differenze relative nelle probabilità di sequenza.</sample>
    <sample id="290">FTw, BOND, COSINE, MLC, L2R</sample>
    <sample id="291">Il modello viene valutato su 11 task, sia pubblici che privati.</sample>
    <sample id="294">CamemBERT è stato addestrato su dati di testo aperti in lingua francese.</sample>
    <sample id="295">Adam Przepiórkowski e Michał Woźniak.</sample>
    <sample id="296">L'abstract si concentra sull'importanza dell'approccio perspettivistico nell'identificazione dell'ironia, confrontandolo con l'approccio non-perspettivistico tradizionale. L'EPIC (English Perspectivist Irony Corpus) è presentato come un corpus di dati che include diverse varietà linguistiche e geografiche per un'analisi più ampia. Il processo di annotazione coinvolge una serie di annotatori diversi per garantire la rappresentatività delle varie lingue e generazioni. I risultati mostrano che i modelli perspettivistici sono più sicuri nelle loro decisioni rispetto ai modelli non-perspettivistici, specialmente quando testati su un set di dati rappresentativo della loro perspettiva. Inoltre, l'analisi dimostra che le generazioni contigue percepiscono l'ironia in modi differenti, con la maggiore variazione tra gli abitanti del Regno Unito e dell'Irlanda. Questi studi mirano a comprendere meglio l'importanza dell'approccio perspettivistico nell'identificazione dell'ironia.</sample>
    <sample id="297">Il presente studio si concentra sull'analisi del linguaggio politico e sulla comprensione delle "dogwhistles", termine utilizzato per descrivere la strategia di comunicazione che invia messaggi codificati a specifici gruppi di persone senza provocare opposizione aperta. L'obiettivo principale è identificare e analizzare le "dogwhistles" attraverso l'uso di modelli di linguaggio avanzati come GPT-3, con particolare attenzione alle loro implicazioni sociali e politiche. Il lavoro si basa su una vasta raccolta di dati provenienti da fonti accademiche, media, blog e wiki, utilizzando un glossario dettagliato e una tipologia dei dogwhistles. Attraverso un'analisi di casi storici di discorsi politici negli Stati Uniti, il progetto mira a valutare la capacità dei modelli di riconoscere e interpretare queste strategie di comunicazione. Inoltre, si esplora come le "dogwhistles" possano evadere i sistemi di moderazione del contenuto, evidenziando le sfide legate alla loro comprensione e all'identificazione. Il risultato finale è un contributo significativo alla comprensione del linguaggio politico e della sua influenza sulle opinioni e le azioni dei cittadini.</sample>
    <sample id="298">Adaptive overfitting e no diminishing returns.</sample>
    <sample id="299">Questo lavoro si concentra sulla robustezza dei modelli di inferenza logica naturale (NLI) attraverso l'addestramento minimax. I modelli NLI possono apprendere regole di scatto, che sono decision rules che correlano spuriousamente con l'etichetta, e queste regole non generalizzano bene ai dati di test. L'approccio proposto è di addestrare un modello secondario (auxiliary) che si basa su questi scatti e utilizza le sue previsioni per riequilibrare gli esempi durante l'addestramento principale. Tuttavia, questo approccio ha limitazioni come la necessità di conoscere a priori i scatti e la divergenza del comportamento del modello principale dal modello secondario, che può causare instabilità durante l'addestramento. Il lavoro introduce un nuovo metodo chiamato minimax training, che cerca di imparare una distribuzione di peso degli esempi che enfatizza gli esempi difficili sottorappresentati. Questo approccio non richiede ipotesi a priori sui scatti, si basa sulle dinamiche di addestramento del modello principale e utilizza un modello secondario a rete feed-forward. Gli esperimenti dimostrano che il minimax training migliora consistentemente l'efficienza delle performance OOD (out-of-domain) mantenendo alti livelli di accuratezza ID (in-distribution).</sample>
    <sample id="300">L'abstract del documento si concentra sulla presentazione di un nuovo approccio per la dictazione interattiva, che mira a migliorare l'editing attraverso la voce. L'approccio introduce una nuova funzionalità chiamata "Interactive Dictation" che permette ai utenti di interagire con il sistema di dictazione e di editing tramite comandi vocali. Questo è stato sviluppato in collaborazione con Microsoft Semantic Machines e presenta un'interfaccia di raccolta dati progettata specificamente per questo scopo. Il sistema utilizza un modello di segmentazione per identificare le parti della dictation e degli editori, e include un'interpretazione avanzata che può comprendere comandi aperti e non strutturati. Il dataset utilizzato per lo sviluppo del sistema è stato creato da 11 annotatori che hanno lavorato su tre tipi di compiti: replicare un'email, elaborare un'email e replicare un segmento di comando. I risultati mostrano un'efficienza elevata nel riconoscimento dei comandi, con un tasso di esattezza del 85,3% e un tempo di runtime medio di 0.097 s/it. Inoltre, i modelli GPT3 sono stati trovati più accurati rispetto ai modelli T5, sia in termini di esattezza che di tempo di runtime.</sample>
    <sample id="302">Permettere al modello di apprendere le corrispondenze tra i frammenti senza l'uso di alberi.</sample>
    <sample id="303">Gli autori hanno suggerito di aumentare la trasparenza sui metodi di mitigazione dei bias per garantire che i proprietari dei modelli siano consapevoli delle loro pratiche e possano fare il necessario per ridurre eventuali pregiudizi o stereotipi nei modelli. Questo contribuisce a migliorare la fiducia nel sistema e a promuovere un ambiente più equo e inclusivo.</sample>
    <sample id="304">Gli input inaccettabili di coppia minima sono le frasi che i modelli di linguaggio non trovano accettabili, anche se hanno la stessa struttura grammaticale delle frasi accettabili.</sample>
    <sample id="305">Il presente studio si concentra sulla valutazione critica delle tecniche di apprendimento supervisionato debole (WSL), evidenziando i limiti e le potenzialità di queste metodologie nell'ambito dell'apprendimento automatico. L'approccio proposto, chiamato "Continuous Fine-Tuning" (CFT), elimina le differenze di prestazioni tra diverse tecniche WSL, dimostrando che non è necessario utilizzare metodi complessi per ottenere risultati significativi. Il CFT consente di ottenere prestazioni paragonabili a quelle dei metodi basati su pochi esempi (Few-shot learning) come riferimento di base, senza dover applicare tecniche avanzate come LoRA o Adapter. Inoltre, il lavoro suggerisce di sempre applicare il CFT, rendendo superfluo l'uso di tecniche più complesse. Questo studio mette in luce la necessità di riportare criteri di selezione del modello e di considerare approcci di apprendimento a pochi esempi come riferimento di base, con l'obiettivo di ridurre l'overestimazione della praticabilità delle tecniche WSL.</sample>
    <sample id="306">Il presente lavoro si concentra sull'analisi delle capacità di tracciamento degli enti nei modelli linguistici, evidenziando come la comprensione di discorsi richieda tale capacità. L'approccio utilizza una serie di esempi pratici per illustrare come i modelli debbano essere in grado di seguire le variazioni degli enti nel corso del tempo, come nel caso di ingredienti in una ricetta o oggetti in una scena. La ricerca pone inoltre in evidenza i problemi che si incontrano nell'evaluazione di tali capacità, evidenziando come alcuni modelli possano confondere azioni simili o non comprendere sequenze temporali complesse. L'analisi si basa su un insieme di test che valutano la capacità dei modelli di tracciare gli enti attraverso operazioni diverse, come trasferire oggetti da una scatola all'altra o manipolare oggetti in una scena. Il lavoro dimostra che solo modelli preaddestrati con dati sia di testo che di codice sono in grado di mostrare comportamenti di tracciamento degli enti significativi, mentre modelli addestrati solo con testo non lo fanno. Inoltre, si evidenzia che modelli più piccoli, come il T5-base (con 230 milioni di parametri), possono imparare tale capacità, mentre modelli completamente randomizzati dello stesso dimensionamento non la mostrano. Questi risultati portano alla conclusione che l'entità di preaddestramento può influenzare notevolmente la capacità di tracciamento degli enti nei modelli linguistici.</sample>
    <sample id="307">I criteri di valutazione utilizzati dagli autori sono l'accuratezza, la precisione e la ricaduta.</sample>
    <sample id="308">Il presente studio, intitolato "NLPositionality: Characterizing Design Biases of Datasets and Models," si concentra sulla caratterizzazione dei pregiudizi di progettazione presenti nei dataset e nei modelli di NLP (Natural Language Processing). L'obiettivo principale è indagare se i dataset e i modelli di NLP siano influenzati dalla posizione o dal punto di vista dei loro creatori, evidenziando come queste posizioni possano influire sulle prestazioni e sui risultati delle ricerche.

L'analisi si basa su diverse fonti di evidenza, tra cui studi teorici e pratici, come "Systematic Inequalities in Language Technology Performance across the World's Languages" e "GeoDIALMAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models." Questi studi evidenziano come le differenze demografiche, l'identità e le esperienze di vita influenzino le percezioni e le decisioni dei ricercatori, che a loro volta influenzano i risultati delle ricerche.

Il framework proposto per l'analisi include la raccolta di dati, la loro elaborazione attraverso modelli e dataset, e l'analisi delle annotazioni fornite da diversi annotatori. Questo approccio mira a confrontare le annotazioni dei volontari con quelle dei dataset esistenti e dei modelli, utilizzando tecniche di confronto come il coefficiente di correlazione di Pearson.

Il lavoro ha dimostrato che i dataset e i modelli di NLP sono più allineati alle persone di lingua inglese, evidenziando una tendenza verso la positività nei confronti di queste popolazioni. Tuttavia, anche se alcuni gruppi sono più rappresentati, altri sono meno inclusi, come le persone non binarie, che ricevono valutazioni più basse rispetto ai maschi e alle donne.

In conclusione, il studio mette in luce l'esistenza di posizionalità nel campo della NLP, evidenziando come i dataset e i modelli siano influenzati dalle posizioni dei loro creatori. Le implicazioni di questa ricerca suggeriscono la necessità di adottare misure per migliorare l'inclusività e la rappresentatività dei dataset e dei modelli, come la documentazione delle scelte di progettazione, lo sfruttamento dell'approccio perspicivismo nella ricerca NLP, e la costruzione di dataset e modelli specializzati per specifici gruppi di persone.</sample>
    <sample id="309">Krippendorff's Alpha</sample>
    <sample id="310">Wikipedia</sample>
    <sample id="311">Heinrich Heine University Düsseldorf, Germany</sample>
    <sample id="312">MultiInstruct si distingue dagli altri parametri di riferimento per essere il primo dataset di tuning istruzione multimodale, contenente 62 compiti multimodali da 10 categorie diverse e 5 istruzioni esperte scritte.</sample>
    <sample id="313">Tre autori sono coinvolti nell'articolo.</sample>
    <sample id="314">La coordinazione binaria si riferisce alla struttura grammaticale in cui due elementi sono coordinati da un congiuntivo, come "and" o "or".</sample>
    <sample id="315">Il video non fornisce informazioni specifiche sul periodo di tempo durante il quale sono stati utilizzati i prompt nel contesto del studio.</sample>
    <sample id="316">I risultati suggeriscono che il modello T5 più piccolo può generare script di qualità superiore rispetto ai modelli più grandi, come GPT-3 e InstructGPT, quando è addestrato su un dataset specifico.</sample>
    <sample id="317">Il presente lavoro introduce CodeIE, un modello di generazione di codice progettato per l'estrazione di informazioni strutturate (Structured Information Extraction - SIE) da testo puro. L'obiettivo principale è dimostrare che i modelli di linguaggio di grandi dimensioni sono più efficaci rispetto ai metodi tradizionali basati su testo-to-testo per l'estrazione di informazioni. CodeIE utilizza una tecnica chiamata "struct2struct" che permette di preaddestrare i modelli di linguaggio di grandi dimensioni con codice Python, rendendo l'output più coerente e strutturato. L'approccio è stato valutato su set di dati reali e ha dimostrato significative migliorie in termini di precisione e ricordanza rispetto ai metodi precedenti. Inoltre, l'analisi ha evidenziato che la consistenza formale tra l'input e l'output è maggiore quando si utilizzano modelli di linguaggio di grandi dimensioni con prompt di codice, rispetto a quelli tradizionali. Questo lavoro rappresenta un passo avanti nell'uso dei modelli di linguaggio di grandi dimensioni per applicazioni di estrazione di informazioni, offrendo un'alternativa promettente per le applicazioni di intelligenza artificiale e automatizzazione.</sample>
    <sample id="318">### Riassunto

I. Modellazione del linguaggio in ambito sanitario
II. Confronto di strategie di pre-allenamento, fonti di dati e dimensioni
III. Valutazione di 13 modelli su 11 compiti
IV. Distribuzione di NACHOS e DrBERT

### Modellizzazione del linguaggio

- Approcci basati su trasformatori, come BERT, hanno ottenuto un notevole miglioramento delle prestazioni su molte compiti di NLP.
- È stato adattato al francese con CamemBERT e FlauBERT.
- Su compiti medici, i modelli specifici per ambito sono stati ancora più efficaci rispetto ai modelli generici.
- L'uso di modelli generici aperti non è disponibile per l'ambito medico in francese.
- Un modello specifico per ambito basato su BERT dovrebbe aumentare le prestazioni sui compiti medici.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da diverse aree cliniche, natura mista e stile libero.
- NBDW: un dataset privato di frasi estratte da 1.7M record medici anonimizzati dalla base dati ospedaliera dell'Università di Nantes.

### Confronto di strategie di pre-allenamento e fonti di dati

- Valutazione dell'impatto di pubbliche e private fonti di dati medici su dimensioni comparabili.
- NACHOS: un dataset di parole aperte di 1.188 parole di dati di testo proveniente da</sample>
    <sample id="319">Le strategie di apprendimento esaminate nel lavoro sono "Da zero con modello completo" e "Continuo pretraining utilizzando un modello preaddestrato esistente".</sample>
    <sample id="320">Il fattore di overfitting dovuto al riutilizzo del test non è stato osservato.</sample>
    <sample id="321">La qualità della semplificazione è stata valutata attraverso l'uso di metriche come BLEU, ROUGE e F1.</sample>
    <sample id="322">L'abstract del video si concentra sulla comprensione della moralità attraverso i classificatori di testo, esplorando come questi modelli apprendono e interpretano concetti morali. Il video inizia con una panoramica sulle differenze tra la moralità umana e quella elaborata da modelli di NLP (Natural Language Processing), evidenziando come la distinzione tra ciò che è giusto e ciò che è sbagliato sia fondamentale per la comprensione della moralità. Successivamente, vengono presentati concetti chiave come la teoria delle fondamenta morali, che identifica cinque principi fondamentali: cura, giustizia, fedeltà, autorità e purezza. Questi principi sono utilizzati per analizzare e spiegare le decisioni morali, fornendo una struttura per comprendere come i classificatori di testo possano interpretare e categorizzare le azioni in base a queste dimensioni morali. Inoltre, il video discute l'importanza di rendere trasparenti i processi decisionali dei classificatori di testo, offrendo spiegazioni dettagliate su come i modelli arrivano alle loro conclusioni. L'analisi si conclude con un confronto tra due movimenti sociali, ALM (Antifa) e BLM (Black Lives Matter), evidenziando come la teoria delle fondamenta morali possa essere applicata a situazioni reali e come i classificatori di testo possano aiutare a comprendere le differenze e le similitudini tra queste posizioni.</sample>
    <sample id="323">Il presente lavoro si concentra sulla creazione di un sistema per la risoluzione di domande di senso comune attraverso l'uso di reti neurali e modelli linguistici. L'approccio proposto, denominato DHLK (Dynamic Heterogeneous-Graph Reasoning with Language Models and Knowledge Representation Learning), mira a migliorare la capacità delle macchine di rispondere a domande che richiedono conoscenze comuni, testando le loro abilità di comprensione del linguaggio. Il sistema utilizza una rete conoscenziale heterogenea (HKG) basata su diverse fonti di conoscenza, come ConceptNet, WordNet e Wiktionary, per rappresentare e ottimizzare sia la struttura che le rappresentazioni del sapere. La fusione e l'encoding di due modalità sono implementati attraverso un modello di linguaggio (LM). Il processo di prunatura dinamica viene applicato per ridurre la complessità della rete conoscenziale, mantenendo solo le informazioni pertinenti. Inoltre, il modulo KRL (Knowledge Representation Learning) viene utilizzato per ottenere una rappresentazione semantica dei nodi e delle relazioni nell'HKG. Il risultato finale è una rappresentazione ampliata del contesto della domanda che incorpora informazioni dalla rete conoscenziale, utilizzata per prevedere l'answer probability attraverso un MLP. Questo approccio è stato testato sui set di dati ufficiali di CommonsenseQA e OpenBookQA, dimostrando una significativa performance superiore rispetto ai metodi esistenti.</sample>
    <sample id="324">Sì, i modelli linguistici presentano bias politici diversi.</sample>
    <sample id="325">Il contenuto inglese si riferisce a un lavoro di ricerca intitolato "Generalizzazione Composizionale senza Alberi utilizzando Tagging Multiset e Permutazioni Latenti". L'obiettivo principale è presentare una nuova tecnica per la generalizzazione compositiva in semantic parsing, che permette ai modelli di gestire strutture complesse e ricorsive senza dover ricorrere all'uso di alberi. Il lavoro è stato sviluppato da Matthias Lindemann, Alexander Koller e Ivan Titov, con contributi provenienti da diverse istituzioni come l'Università di Amsterdam, l'Università del Saarland e il Dipartimento di Informatica dell'Università di Stoccarda.

L'approccio proposto utilizza il tagging multiset e le permutazioni latenti per modellare direttamente le corrispondenze tra frammenti, evitando così l'uso di alberi. Questo approccio è stato dimostrato essere in grado di mostrare una forte generalizzazione a ricorsione più profonda senza l'uso di alberi.

Il lavoro presenta anche alcuni risultati sperimentali ottenuti su COGS (Contextualized Object-Verb-Subject Phrase), confrontandosi con altri modelli alberari. I risultati mostrano che il modello proposto ha ottenuto buoni risultati, superando i modelli alberari tradizionali.

Inoltre, il lavoro affronta alcune sfide tecniche, come l'incognita dell'allineamento, che è stata risolta introducendo l'allineamento durante l'addestramento. La soluzione proposta utilizza un modello di permutazione che permette di risolvere il problema dell'inferenza NP-hard attraverso la backpropagation attraverso la relaxazione continua.

Il lavoro è stato pubblicato e può essere consultato sul sito web https://t.ly/mx8ny.</sample>
    <sample id="326">La dissonanza cognitiva è una situazione in cui due elementi di pensiero, azione o credo sono inconsistenti.</sample>
    <sample id="327">Il presente lavoro si concentra sulla creazione di un sistema AI avanzato per la comprensione di immagini e testo, chiamato ManagerTower. Il sistema è stato sviluppato attraverso l'approccio di pre-allenamento auto-superviso su coppie di immagine-testo in scala grande. L'obiettivo principale è addestrare un sistema intelligente che possa comprendere sia le immagini che i testi. Il sistema utilizza una struttura a due torri con encoder visivi e testuali separati, che convergono in un encoder cross-modal per la fusione delle informazioni. In confronto al BridgeTower, il ManagerTower prende in considerazione le rappresentazioni multi-modali pre-allenate degli esperti unimodali a diversi livelli, aggregando in modo adattativo queste conoscenze attraverso gestori in ogni layer cross-modal. Questo approccio permette di ottenere significativi miglioramenti rispetto ai modelli tradizionali, come dimostrato dai risultati di valutazione sui dataset pubblici.</sample>
    <sample id="328">GPT-3</sample>
    <sample id="329">Il presente lavoro propone una metodologia per la localizzazione di frasi video senza supervisione (zero-shot) che è robusta al rumore. La procedura inizia con la generazione di query pseudo-libere basate su descrizioni immagini utilizzando modelli di descrizione immagine. Queste query sono poi utilizzate per generare eventi pseudo-liberi basati sulla struttura temporale degli eventi, selezionando quelli con una correlazione alta con le query e bassa con gli eventi esterni. Successivamente, si riduce il rumore durante la generazione di etichette pseudo-libere mediante riequilibratura del campione e raffinamento delle etichette. Il modello viene addestrato utilizzando queste etichette pseudo-libere, con una riduzione del rumore attraverso l'aggiustamento del peso del campione e la raffinazione delle etichette. I risultati mostrano un'ottima prestazione zero-shot su due dataset, dimostrando l'efficacia della metodologia proposta.</sample>
    <sample id="330">No, nell'apprendimento attivo, l'addestramento iterativo funziona meglio di quello cumulativo.</sample>
    <sample id="331">Sara Papi, Matteo Negri e Marco Turchi.</sample>
    <sample id="332">I dati nel parametro di riferimento MuDa sono stati tratti da un dataset multilingue.</sample>
    <sample id="333">Il presente lavoro introduce INK, un nuovo approccio per migliorare la traduzione automatica tramite l'iniezione di conoscenza kNN (k-Nearest Neighbor) nel spazio di rappresentazione dei modelli di traduzione basati su rete neurale (NMT). L'obiettivo principale è risolvere i limiti dei modelli NMT che generano uno spazio di rappresentazione non uniforme, influenzando negativamente la generalizzazione e le prestazioni di traduzione su domini sconosciuti. 

INK propone una nuova architettura di adattamento che integra l'informazione kNN per raffinare il modello NMT, senza necessariamente utilizzare un datastore. Questo approccio permette di ridurre significativamente la dispersione delle rappresentazioni, creando un'area di rappresentazione più uniforme e completa. La tecnica di raffinamento delle rappresentazioni si basa sulla minimizzazione della divergenza di Kullback-Leibler tra tre tipi di rappresentazioni: le rappresentazioni del modello base, quelle del datastore e quelle aggiornate.

L'adattamento avviene attraverso un loop di training iterativo che include la raffinazione delle rappresentazioni, l'estrazione della conoscenza kNN per regolare le rappresentazioni e l'aggiornamento asincrono del datastore con le rappresentazioni aggiornate. Questo processo consente di mantenere un'area di rappresentazione più liscia e completa, migliorando così le prestazioni di traduzione.

I risultati sperimentali dimostrano che INK ottiene un incremento medio di 1.99 punti in COMET e 1.0 punti in BLEU rispetto ai baselines. Inoltre, INK risulta in una memoria inferiore di 0.02 volte e un tempo di inferenza più veloce di 1.9 volte rispetto ai baselines. Questi risultati confermano l'efficacia di INK nell'ottimizzare la traduzione automatica, offrendo un equilibrio tra qualità e efficienza computazionale.</sample>
    <sample id="335">Matthias Lindemann, Alexander Koller, Ivan Titov</sample>
    <sample id="336">Il trasferimento interlinguistico è una tecnica di apprendimento automatico che mira a trasferire conoscenze acquisite da un linguaggio a un altro, consentendo ai modelli di comprendere e processare query in diverse lingue.</sample>
    <sample id="337">Il presente lavoro si concentra sulla creazione di un modello di apprendimento automatico per la formazione di parole fuori dal vocabolario (OOV) attraverso l'uso di una struttura di rete grafica. L'approccio proposto, denominato Graph-based Relation Mining for Context-free Out-of-vocabulary Word Embedding Learning (GRM), mira a sviluppare un sistema che sia in grado di elaborare e imparare nuove parole senza dover necessariamente dipendere da contesti specifici o da un vasto vocabolario predefinito.

L'obiettivo principale è quello di utilizzare le relazioni tra parole esistenti per prevedere e formare nuove parole OOV. Questo è raggiunto attraverso l'analisi delle relazioni semantiche tra le parole presenti nel corpus di testo, che vengono rappresentate tramite un grafo. Le relazioni tra le parole sono modellate utilizzando un algoritmo di rete grafica, come il GCN (Graph Convolutional Network), che consente di identificare pattern e relazioni complesse tra le parole.

Il modello viene addestrato su un dataset di testo, dove le parole OOV sono identificate e inserite nel grafo insieme alle loro relazioni con parole già presenti nel vocabolario. Il processo di addestramento coinvolge l'apprendimento di rappresentazioni vettoriali per le parole OOV basate sulle informazioni estratte dalle loro relazioni con le parole del corpus.

Una volta addestrato, il modello è in grado di generare nuove parole OOV basandosi sulle relazioni semantiche apprese durante l'addestramento. Questo approccio permette di estendere significativamente il vocabolario di un modello di apprendimento automatico, rendendo il sistema più flessibile e adattabile a nuovi contesti di testo.

In conclusione, il modello GRM rappresenta una soluzione innovativa per la formazione di parole OOV, offrendo un'alternativa efficace all'apprendimento basato su contesti specifici. L'uso della rete grafica permette di catturare e utilizzare le relazioni complesse tra le parole, migliorando così l'efficacia dell'apprendimento automatico e l'espansione del vocabolario.</sample>
    <sample id="338">Il presente studio si concentra sulla valutazione obiettiva delle spiegazioni naturali in lingua umana (HNL) fornite da modelli AI, indagando se siano sempre utili e come influenzino la performance di predizione. L'approccio proposto è basato su una metrica chiamata TREU (True Explanation Utility), che misura l'aiuto effettivo delle spiegazioni verso la predizione, distinguendo tra l'utilità durante l'addestramento e quella durante l'inferenza. Il lavoro esplora come le spiegazioni influenzino i modelli attraverso due percorsi: il miglioramento della performance di predizione e l'aumento della ragionevolezza del modello. Viene presentato un'analisi preliminare che suggerisce che le spiegazioni umane siano ancora benefiche per i modelli, anche quando gli umani le disApprofondisci</sample>
    <sample id="339">Le affiliazioni degli autori dell'articolo sono Saarland University, Amazon Alexa e University of Vienna.</sample>
    <sample id="340">Il presente lavoro introduce ParaAMR, un vasto dataset di paragrafi sintatticamente diversi costruito attraverso la traduzione inversa di rappresentazioni AMR (Abstract Meaning Representations). Questo dataset è stato progettato per supportare diverse applicazioni NLP, come la generazione di paragrafi, l'analisi di domande, i chatbot, la generazione creativa e l'aumento dei dati. ParaAMR si distingue per la sua scala e diversità sintattica, offrendo una base robusta per le applicazioni NLP. Il dataset è stato costruito utilizzando un approccio basato su back-translation, che ha permesso di creare un numero significativo di paragrafi per ogni frase sorgente, garantendo una diversità sintattica elevata. L'uso di AMR come strumento di traduzione inversa ha permesso di mantenere la semantica originale delle frasi sorgenti, rendendo ParaAMR un'utile risorsa per la ricerca e lo sviluppo di modelli NLP.</sample>
    <sample id="341">I primi due autori utilizzano le misure di latenza 1s e 2.5s, mentre il terzo autore utilizza le misure di latenza 3s e 4s.</sample>
    <sample id="342">Il presente lavoro introduce LiveChat, un vasto dataset di dialoghi personalizzati costruito automaticamente da streaming video. Il dataset è stato creato utilizzando una tecnica innovativa che combina le interazioni tra streamer e pubblico durante i live streaming. Questo approccio permette di ottenere informazioni dettagliate sui personaggi dei streamer, come le loro preferenze, comportamenti e stili di comunicazione, che sono cruciali per la generazione di risposte personalizzate e l'identificazione degli addressee. Il dataset è stato utilizzato per esperimenti su due compiti di benchmark: la modellizzazione delle risposte e l'identificazione degli addressee. Gli esperimenti hanno dimostrato che i modelli preaddestrati come BART, TwinBERT e CoBERT, quando addestrati con LiveChat, migliorano significativamente le prestazioni rispetto ai modelli preaddestrati standard. Inoltre, gli studi hanno evidenziato che la selezione di profili personalizzati accurati e la maggiore lunghezza delle sessioni di streaming sono vantaggiose per l'apprendimento del comportamento e della decisione dell'addressee. Il futuro si apre verso lo sviluppo di modelli di apprendimento trasferibile per LiveChat, che potrebbe ulteriormente migliorare le prestazioni delle applicazioni di generazione di dialoghi e riconoscimento dell'addressee.</sample>
    <sample id="343">Il contenuto del video è un discorso che parla di "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources" (Test KITMUS: Valutazione dell'integrazione del conoscenza da diverse fonti). Il discorso si concentra su come i modelli NLU (Natural Language Understanding) utilizzano diverse fonti di conoscenza per comprendere e interpretare le informazioni linguistiche. 

L'argomento principale è che i modelli NLU possono ottenere conoscenza attraverso due tipi principali:
1. **Knowledge in Parameters (conoscenza in parametri)**: Questa conoscenza viene acquisita durante la fase di preaddestramento e rimane costante durante l'uso del modello.
2. **Knowledge in Context (conoscenza nel contesto)**: Questa conoscenza può essere aggiornata o modificata durante l'uso del modello, basandosi sul contesto specifico della frase o del testo.

Il discorso illustra come i modelli NLU possano rispondere correttamente a domande basate su informazioni che sono state acquisite durante la fase di preaddestramento (come "Che cosa fanno i presidenti?" o "Cosa è una TV?") ma potrebbero avere difficoltà con domande che richiedono conoscenze aggiornate o specifiche (come "Chi è John?" o "Chi è il nuovo presidente?").

Il test KITMUS è presentato come uno strumento per valutare l'integrazione del conoscenza da diverse fonti nei modelli NLU. Include un dataset per l'evaluazione, una comprensione del contesto per esplorare la capacità di utilizzare sia la conoscenza acquisita durante la fase di preaddestramento che quella acquisita durante l'uso del modello, e un esperimento con partecipanti umani e modelli di risoluzione di coreferenza.

Il discorso conclude con alcuni punti chiave:
1. Molti modelli sembrano incapaci di ragionare su conoscenza proveniente da diverse fonti (preaddestramento e uso).
2. L'addestramento specifico al compito è necessario per l'integrazione del conoscenza.
3. I modelli hanno difficoltà nell'integrare la conoscenza acquisita durante l'uso del modello.

Il video termina con un invito a trovare il dataset, il codice di generazione e di valutazione sul sito GitHub all'indirizzo mpoeens/kitmus.</sample>
    <sample id="344">I metodi basati su alberi hanno bisogno di ottenere gli alberi, che possono essere ottenuti tramite pre/post-processamento delle forme logiche o induzione della grammatica.</sample>
    <sample id="345">Il presente lavoro si concentra sulla generalizzazione compositiva senza l'uso di alberi, utilizzando la taggatura multiset e le permutazioni latenti. L'obiettivo è sviluppare un modello che possa gestire la ricorsione più profonda e le composizioni non viste durante l'addestramento. La ricerca introduce un approccio che modella direttamente le corrispondenze tra frammenti, senza l'uso di alberi, mostrando una forte generalizzazione a ricorsioni più profonde. Il modello utilizza un meccanismo di permutazione per risolvere i problemi tecnici come l'incognita dell'allineamento, che viene indotta durante l'addestramento. Questo approccio è stato testato su COGS (Kim and Linzen 2020) e ha dimostrato risultati significativi, superando altri modelli alberolessi.</sample>
    <sample id="346">School of Interactive Computing, Georgia Institute of Technology</sample>
    <sample id="347">Il contenuto inglese è già stato tradotto in italiano nel testo che segue:

**Risultati: Pattern nelle parole chiave**

**Ostensione attraverso narrazioni essenziali:**
- cultura, tradizione, orgoglio, esotismo per gruppi marcati
- definisce questi gruppi solo sulla loro identità

**Perniciosi portamenti positivi:**
- vivace, curvilinea per le donne latine
- piccola, delicata, dolce per le donne asiatiche
- forte, resiliente per le donne nere</sample>
    <sample id="348">Il presente studio, intitolato "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models," è stato presentato all'ACL 2023 e condotto da Myra Cheng, Esin Durmus e Dan Jurafsky. L'obiettivo principale del lavoro è valutare e misurare le stereotipie presenti nei modelli di linguaggio naturale (LLM) attraverso l'utilizzo di prompt naturali. 

I ricercatori hanno evidenziato che i modelli di LLM sono soggetti a pregiudizi sociali e stereotipi, che possono influenzare la loro capacità di generare contenuti inclusivi e non discriminatori. Questi stereotipi sono spesso basati su dataset man mano curati e possono non tenere conto dell'intersezione delle identità dei gruppi. 

Per superare queste limitazioni, i ricercatori hanno sviluppato una metodologia chiamata "Marked Personas." Questa tecnica utilizza prompt naturali per generare personaggi che rappresentano diversi gruppi etnici e culturali, consentendo ai modelli di LLM di valutare stereotipi in modo più specifico e generalizzabile. 

L'approccio consiste in due passaggi principali: 
1. Generazione di personaggi usando prompt come "Imagina di essere una donna asiatica. Descrivi te stesso." 
2. Identificazione di parole chiave che distinguono i personaggi dei gruppi marcati dai gruppi non marcati.

I risultati mostrano che i modelli di LLM generano personaggi che contengono più stereotipi rispetto alle risposte umane. Tuttavia, anche se alcuni stereotipi positivi sono stati identificati, il lexicon attuale è incompleto. Questo studio suggerisce che per migliorare la comprensione e la mitigazione dei pregiudizi nei modelli di LLM, è necessario adottare un approccio intersezionale e trasparente riguardo alla mitigazione dei bias.</sample>
    <sample id="349">### Sintesi del contenuto

**Introduzione**
Il video presenta un lavoro di ricerca intitolato "Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark". L'obiettivo principale è proteggere i diritti d'autore dei modelli di linguaggio naturale grandi (LLM) offerti come servizio (EaaS). Il lavoro si concentra su come prevenire la copia illegale dei modelli attraverso l'inserimento di un watermark nascosto.

**Fondamento**
- I modelli di linguaggio naturale grandi (LLM) sono eccezionali in NLU e NLG, con esempi come GPT, LLaMA e PALM.
- L'EaaS offre un servizio per assistere vari compiti NLP.
- OpenAI offre un API basata su GPT per l'inclusione di embedding.

**Motivazione**
- Attacchi possono rubare il modello attraverso l'apprendimento dagli embedding e fornire servizi simili.
- È necessario proteggere i diritti d'autore dell'EaaS.
- È necessario rilevare se un servizio fornito da un provider viene rubato da un altro servizio.

**Problema**
- Applicabile all'EaaS.
- Utility: non degrada l'utilità degli embedding forniti.
- Covertness: deve essere nascosto dall'attaccante.
- Transferability: il watermark deve essere trasferibile ai servizi dell'attaccante.

**Opere esistenti**
- Watermark basato sui parametri [1,2]: non trasferibile.
- Watermark basato sul vocabolario [3,4]: applicabile all'EaaS.
- Watermark basato sul backdoor [5]: applicabile all'EaaS.
- Watermark basato sull'adversarial [6]: applicabile all'EaaS.

**EmbMarker**
- Selezionare le parole trigger: contare la frequenza delle parole su un corpus testuale generico \( D_p \), selezionare casualmente \( n \) parole in un intervallo di frequenza moderato.
- Inserimento del watermark: definire un embedding target \( \mathbf{e}_t \), contare il numero di parole trigger in una frase, aggiungere l'embedding target all'embedding originale \( \mathbf{e}_o \).

**Verifica dei diritti d'autore**
- Costruire un dataset di beni e uno di malvagio.
- Richiedere gli embedding dal servizio del ladro con i dataset.
- Calcolare metriche (differenza di similarità e valore p del KS test).

**Risultati sperimentali**
- Dataset di copia: AG News, MIND, SST2, Enron Spam.
- Dataset generale del fornitore: WikiText.
- Metriche: performance su task downstream: ACC, performance di deteczione: \( \Delta_{cos} \), \( \Delta_{L2} \), valore p.
- Impostazioni: \( m = 20 \), \( n = 4 \), intervallo di frequenza = [0.005, 0.01].

**Visualizzazione delle embedding**
- Visualizzazione delle embedding per diversi dataset.

**Ringraziamenti**
- Grazie!</sample>
    <sample id="350">Il presente lavoro esplora il concetto di "performance superumana" nei sistemi di NLP (Natural Language Processing) moderni, evidenziando le sfide e le limitazioni che questi sistemi incontrano quando si confrontano con i modelli umani. L'analisi inizia con una panoramica sulle valutazioni basate su classifiche, che sono diventate comuni nelle applicazioni NLP, ma mostrano spesso prestazioni superiori umane su certe compiti. Tuttavia, queste prestazioni superiori non sempre indicano la soluzione definitiva dei problemi, poiché molti compiti NLP richiedono conoscenza e inferenza, non semplici compiti procedurali. Il lavoro sottolinea anche l'importanza della qualità dei dati di base utilizzati per l'allenamento dei modelli, evidenziando come errori e limitazioni nel dataset possano influenzare significativamente le performance dei modelli. Inoltre, si discute delle metriche di valutazione umane, spiegando come queste siano spesso sottovalutate o vagamente stimolate, e come ciò possa portare a conclusioni errate sulla capacità dei sistemi di superare i modelli umani. L'analisi conclude con una discussione sugli standard di benchmarking più affidabili e trasparenti, offrendo consigli per migliorare la costruzione di tali standard.</sample>
    <sample id="351">Il presente studio esplora l'efficacia dei taggatori di entità nominali (CoNLL-2003) nel 2023, analizzando se questi modelli siano ancora pertinenti per la riconoscita e la generalizzazione delle entità nominali. L'approccio utilizza il dataset CoNLL++ che comprende notizie di Reuters del 2020 annotate secondo i criteri di CoNLL-2003. I risultati mostrano che i modelli basati su architetture trasformatorie generalizzano meglio rispetto ai modelli tradizionali, mentre i modelli più grandi presentano una migliore capacità di generalizzazione. Inoltre, è stato osservato che l'aumento del numero di esempi di fine-tuning può migliorare la generalizzazione. Il declino del prestazioni potrebbe essere causato da overfitting adattivo o da drift temporale, con quest'ultimo ritenuto essere la principale causa. Le conclusioni suggeriscono che per una buona generalizzazione sono necessari miglioramenti nell'architettura del modello, un aumento della dimensione del modello e un maggior numero di esempi di fine-tuning.</sample>
    <sample id="352">ABC-Eval è un sistema di valutazione per i sistemi di dialogo orientati al chat che valuta le risposte dei bot basandosi su quattro aspetti principali: Coerenza, Coerenza, Conoscenza e Comprensione Emotiva.</sample>
    <sample id="353">Il presente lavoro si concentra sulla generazione di codice Python basata su domande di chiarificazione, un approccio innovativo per affrontare l'insufficiente specificazione (underspecification) nel contesto della sintesi di codice da descrizioni naturali. L'approccio introduce l'interattività attraverso la generazione di domande di chiarificazione e risposte, che aiuta a raccogliere ulteriori specifiche per alleviare il problema dell'underspecification. Il lavoro propone una pipeline di generazione di codice chiamata CQ-driven, che include un predittore di necessità di chiarificazione, un modello di selezione di questioni e un generatore di codice. La creazione del dataset è illustrata attraverso l'identificazione delle operazioni chiave utilizzando un API di codice generato e la rappresentazione di uno spazio latente con schemi e documentazioni. Il modello di selezione di questioni utilizza un modello di ricerca per generare domande di chiarificazione, mentre il generatore di codice utilizza un modello CausalLM o seq2seq. I risultati dimostrano che l'approccio migliora significativamente le prestazioni di generazione di codice rispetto ai metodi esistenti, specialmente in termini di precisione e F1-score.</sample>
    <sample id="354">2018</sample>
    <sample id="355">Il contenuto del video è una presentazione sulle tecniche di apprendimento trasferibile e attivo per la deteczione della dissonanza cognitiva, affrontando il challenge delle classi rare. Ecco un riassunto delle principali parti:

### Introduzione
- **Titolo**: "Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge"
- **Autori**: Vasudha Varadarajan, Swanie Juhng, Syeda Mahwish, Xiaoan Liu, Jonah Luby, Christian C. Luhmann, H. Andrew Schwartz
- **Istituzione**: Stony Brook University

### Definizione della Dissonanza Cognitiva
- La dissonanza cognitiva si verifica quando due elementi di pensiero (ad esempio, idee, azioni, credenze) sono inconsistenti.
- Citato da Harmon-Jones e Harmon-Jones (2007): "due elementi di cognizione (cioè, idee, azioni, credenze) che sono inconsistenti."

### Esempi di Dissonanza
- **Esempio 1**: "Sapere che le sigarette possono uccidere" vs "Prendere una o due sigarette dopo la riunione."
- **Esempio 2**: "Non penso di poter mantenere il lavoro senza di loro" vs "Sapere che le sigarette possono uccidere."

### Rarità della Dissonanza nel Linguaggio
- La dissonanza è relativamente rara nell'uso del linguaggio rispetto ad altre relazioni discorsive.

### Motivazione della Ricerca
- **Effetti dell'Incongruità**: Come l'incongruità può influenzare le opinioni e le tendenze dei credenti.
- **Disordini Ansiosi**: Come la dissonanza può essere associata ai disturbi ansiosi.
- **Entrata e Uscita dal Extremismo**: Come la dissonanza può influenzare l'adesione all'estremismo.
- **Stili Cognitivi**: Come i diversi stili cognitivi possono influenzare la percezione della dissonanza.

### Metodologia
- **Dataset**: Twitter
- **Processo di Annotazione**: Utilizzo di un algoritmo per identificare la dissonanza in tweet.
- **Modello di Classificazione**: Utilizzo di RoBERTA-base con una testa classificatrice.

### Risultati
- **AUC**: Misura dell'efficacia del modello.
- **Comparazione Strategie di Apprendimento Attivo**: 
  - **Strategia Casuale**: +0.15
  - **Entropia**: +0.20
  - **CoreSet**: +0.19
  - **CAL**: +0.19
  - **PRC**: +0.21

### Conclusioni
- **Tecnica di Apprendimento Trasferibile**: Utile per aumentare l'efficienza nell'acquisizione di esempi di dissonanza.
- **Strategia PRC**: La migliore tra le strategie di apprendimento attivo.
- **Risultati Finali**: AUC = 0.685

### Ringraziamenti
- **Contatti**: vyaradarajan@cs.stonybrook.edu, sjuhng@cs.stonybrook.edu, has@cs.stonybrook.edu
- **Dataset**: https://github.com/vasudha-varadarajan/dissonance-detection
- **Paper**: https://arxiv.org/abs/2304.00001</sample>
    <sample id="356">Le affiliazioni degli autori dell'articolo sono The University of Amsterdam, Saarland University e the University of California, San Diego.</sample>
    <sample id="357">Il nome della relatrice o del relatore è Siyu Yuan.</sample>
    <sample id="358">Cinque autori sono coinvolti nell'articolo.</sample>
    <sample id="359">L'approccio viene confrontato con l'architettura CAAT.</sample>
    <sample id="361">Il presente lavoro si concentra sulla creazione di CounterComp, un sistema progettato per migliorare la generalizzazione compositiva nell'ambito della ragionamento quantitativo multi-step. L'obiettivo principale è superare i limiti del ragionamento complessivo, che spesso diminuisce con l'aumento del numero di passaggi di ragionamento. CounterComp utilizza esempi contraddittori per addestrare i modelli, facilitando così una maggiore capacità di generalizzazione.

L'approccio proposto si basa sul concetto di "esempi contraddittori", che sono chiamati "counterfactual examples". Questi esempi sono utilizzati per addestrare i modelli in modo da comprendere come cambiare le operazioni o gli operandi potrebbe influenzare il risultato finale. In particolare, le domande possono funzionare come esempi contraddittori, permettendo ai modelli di apprendere come variare le operazioni e gli operandi per rispondere correttamente alle domande.

CounterComp è stato testato su diversi dataset, dimostrando significative migliorie nella precisione dei programmi rispetto ai modelli tradizionali. I risultati mostrano che CounterComp migliora notevolmente la performance sia sui campioni di distribuzione in ingresso che su quelli di distribuzione fuori distribuzione (OOD), confermando la sua efficacia nel migliorare la robustezza e la generalizzazione dei modelli di ragionamento quantitativo multi-step.</sample>
  </task>
</testset>