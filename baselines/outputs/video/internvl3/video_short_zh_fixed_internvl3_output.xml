<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">语言模型的主要数据来源是一个混合来源，正如幻灯片上提到的标签规模所显示的那样，这表明数据来自多个不同的网站，包括商业、新闻和政府等渠道。</sample>
    <sample id="1">麦吉尔大学、Mila和微软研究院的工作人员。</sample>
    <sample id="2">文本已翻译为中文，结果如下：
DEPLAIN：一个德语文本的平行语料库，用于将句子和文档翻译成简易语言，以便简化
Regina Stodden, Omar Momenn, Laura Kallmeyer
德国杜塞尔多夫大学
ACL 2023</sample>
    <sample id="3">翻译内容如下：
（目标语言：中文）
DEPLAIN：一种包含语言内翻译的德语平行语料库，用于简化句子和文档文本简化是什么，为什么要以及如何实现？文献回顾简介</sample>
    <sample id="4">以下是您提供的文本的中文翻译：

原始文本：

“这家工会为实现较高的工资争取权益。”

简洁文本：

“这家工会为更高的工资或更好的退休金争取权益。”

注释：

文本简化示例
原文：
工会争取实现较高的工资。

改写：
工会为更高的工资或更好的退休金争取权益。

修改说明：
- 替换（Substitution）：用“更高的工资或更好的退休金”替换了“实现较高的工资”。
- 句子删除（Clause Deletion）：删除了“争取实现”部分。
- 重新排序（Reordering）：将句子重新排列，使其更易懂和更直接。
- 词汇删除（Word Deletion）：去除了冗余词汇。
- 插入（Insertion）：添加了“或更好的退休金”来提供更多信息。</sample>
    <sample id="5">这是字幕部分，显示的是视频中的文字说明：
标题: text_simp_example_german.png

文本内容（未翻译的英文部分）：
Original:
"Die Gewerkschaft setzt sich dafür ein, dass zum Beispiel höhere Löhne gezahlabt werden."

Word-for-Word Translation:
"The union demands that higher wages are paid"

Plain Language:
"Die Gewerkschaft setzt sich zum Beispiel für höhere Löhne oder mehr Urlaub ein.</sample>
    <sample id="6">文本已翻译为中文，结果如下：
文本简化示例</sample>
    <sample id="7">目标语言：
'La dirección sind vermutlich die Hauptverdächtigen bei den Plünderungen, die nach den Überschwemmungen stattgefunden haben.'</sample>
    <sample id="8">目标人群。</sample>
    <sample id="9">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：德语文本简化语料库
句子级别</sample>
    <sample id="10">目标是创建一个在句级与段级上具有全面语料库的系统，但目前还没有。</sample>
    <sample id="11">视频中的内容翻译如下（目标语言：中文）：

德国文本简化语料库

句子级别

- 语料库
- 句子
- 组合
- 标志
- 学术
- L3
- 绝缘体
- 公有
- 维基百科
- 手动
- 重写

图1: 数据与文本类型

源域与目标域</sample>
    <sample id="12">目标是将文本简化。这里有很多选择。实际上，很多简化是针对句子级别的，比如使用简单术语、更简单的形容词和副词。然后，我们还有词的级别，比如用同义词替换，例如“好”和“好”。
这是一张很好的图表，展示了我们用于数据和研究的简化语料库。左边有句子级别的语料库，展示了一些非常著名的语料库，例如Lassy和ALICE。
另一方面，右边是词级语料库，展示了由Coca-Cola资助的各种大型语料库，这些语料库包含大约一百万到四百万句。对于大型语料库，这是一目了然的。</sample>
    <sample id="13">翻译结果：
- 语言：中文
- 内容：这是为了比较其他数据集的规模，或者更确切地说，这是在原始格式下可获得数据的数量。这是一个非常简短的描述，因为我在过去几年中制作了多份演讲稿。如果您需要更多细节，我可以提供。</sample>
    <sample id="14">文本已翻译为中文，结果如下：
简化类型
简化转换</sample>
    <sample id="15">以下是您要的翻译：
- 目标语言：中文
- 翻译文本：现在，简要介绍一下我们研究项目中的另一个方面，即我们可以找到哪种类型的简化。我们研究了文本中使用的所有简化类型。</sample>
    <sample id="16">已将文本内容翻译为中文：
在这些框架中，我们可以看到简单的重述是常见的转变过程，但我更感兴趣的是重新措辞和词替换。这两种类型的转变在DePlan模型的数据中占主导地位，占主导地位的原因其实是因为模型中大量依赖于规则系统。</sample>
    <sample id="17">该视频中展示的字幕翻译成中文后为：
接下来我们分析了不同类型的任务，我们比较并对比了不同任务中使用的一些简化类型。</sample>
    <sample id="18">目标是要让句子更简单，不增加句子长度。

我们发现，这些模型会使用非常类似的转化策略。</sample>
    <sample id="19">目标语言：中文
翻译结果：自动对齐和简化
评估</sample>
    <sample id="20">翻译内容如下：
LHA，使用句子嵌入相似性进行层次对齐。
Sent4LaserBE，一种基于语言无关BERT模型的相似嵌入。
Sent4RobertaBE，一种基于跨英语和德语Roberta模型的相似嵌入。
CATs-COS，使用n-grams和C3G向量的不同相似性度量。
Veil对齐，基于多语种句子嵌入，允许句子-转换方法产生多个对齐。
MASS对齐，一种基于TF-IDF相似矩阵的邻域驱动方法。</sample>
    <sample id="21">翻译结果：
- 语言：中文
- 内容：我们可以看到，当使用我们所应用的模型进行翻译时，我们可以将这种模型调整到高精度水平。</sample>
    <sample id="22">翻译完成：目标语言是中文，对应的文本为：自动对齐评估。
方法。</sample>
    <sample id="23">目标语言是英语，但翻译内容的语言是中文。以下是翻译结果：
LHA: 使用句子嵌入相似性进行层次对齐
Sent4lasB: 英语-Germanbert语言感知BERTTransformer相似嵌入。
Sent4lasR17BERT: 英语-Germanbert交叉的CrossBERTTransformer相似嵌入。
CATS-COO: 不同相似度量中n-grams（3-Cos）向量。
VeclAlign: 基于多语言句子嵌入的多对齐。
BERTalign: 允许句子转化器方法产生n-m对齐。
MASSalign: 使用TF-IDF相似性矩阵的邻域驱动方法。</sample>
    <sample id="24">这是您要的翻译：
目标语言：中文
翻译结果：使用相同度量系统。
在英语中称为交叉对齐，其度量与CPSG相似，在这个领域非常突出，但仅在英语和德语的背景下。
还有其他许多方法，其中一种名为VeCalignment。我对此最感兴趣的原因是这是一个多语言对齐系统，这非常有趣。因为如果使用这种多语言系统，你就可以在多种语言之间进行对比。因此，这非常适合我们的研究环境。</sample>
    <sample id="25">这是您要的翻译：
目标语言：中文
对应的翻译是：我们可以考虑使用这些算法。

让我们回到我们的例子。我们有英语中的"汽车"这个词，我们想找到德语中的等价词。我们可以考虑使用这些算法。我们尝试过不同的方法，比如将它们与德国的百科词典进行匹配。例如，其中的方法得到了93.4的准确率，F1分数为51.4等等，等等。如果我们使用的是n对一的方式，则效果会有所下降。</sample>
    <sample id="26">翻译结果：
- 语言：中文
- 内容：让我们谈谈方法，这是比较不同方法的另一个指标，用于评估对齐过程中的对齐质量。</sample>
    <sample id="27">目标是通过更短的文档来帮助人们理解，无论他们是否是专业人员。

此外，即使我们采用与文档相同的数据，我们也可以在句子级别训练它，这将使我们以句子为单元进行简化。我们发现模型在这一级别表现良好。</sample>
    <sample id="28">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：感谢观看</sample>
    <sample id="29">视频中的字幕是：
"文本简化论文已经发布 - 请参考链接"</sample>
    <sample id="30">已将文本内容翻译为中文，结果如下：
简而言之，它表明大型语言模型越强大，结果越好。</sample>
    <sample id="31">文本已翻译为中文，结果如下：
自动文本简化
在文档级别
在句子级别
在训练数据的长度</sample>
    <sample id="32">文本已翻译为中文，结果如下：
我们正在讨论一个关于自动简化文本的项目。</sample>
    <sample id="33">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：自动文本简化
文件级别
使用未调整的长版本mBART进行文件简化结果。
训练数据
句子级别
使用未调整的mBART进行句子简化结果。
训练数据</sample>
    <sample id="34">翻译完成：目标语言是中文，对应的文本为：谢谢。
如需更多详情，请查阅我们的论文。
欢迎参观我们在ACL 2023会议上的海报。。</sample>
    <sample id="35">视频中显示的演讲者是一位女性，但她的名字没有在视频中提供。然而，她与卡内基梅隆大学和BAIR等组织有关联。</sample>
    <sample id="36">TS X 5 LLM 获得了 82%-87% 的准确率，这适用于在具备部分重叠背景知识时。</sample>
    <sample id="37">根据图表所示，CoNLL-2003 标注器似乎仍然有效，尽管在某些点上性能有所下降。</sample>
    <sample id="38">提出的人工评估方法与ChatGPT进行的自然对话相结合，展示了评估框架的实用性。</sample>
    <sample id="39">现有弱监督方法的成功在很大程度上依赖于特征空间中类别原型之间的分离。</sample>
    <sample id="40">提高分数的建议措施包括点击链接来了解歌曲信息，聆听一些歌曲，以及阅读关于歌曲的信息。</sample>
    <sample id="41">根据这张图片，提到的论文有五位作者。</sample>
    <sample id="42">翻译结果：
- 语言：中文
- 内容：协调的依赖结构

布尔克/斯坦福（通用依赖）：
荷马爱丽莎、巴特和玛吉。
链/莫斯科：
荷马爱丽莎、巴特和玛吉。
连词引导/布拉格：
荷马爱丽莎、巴特和玛吉。
多头/伦敦：
荷马爱丽莎、巴特和玛吉。</sample>
    <sample id="43">目标语言：中文
翻译结果：荷马爱丽莎，巴特和玛吉
荷马爱丽莎，巴特和玛吉
荷马爱丽莎，巴特和玛吉
荷马爱丽莎，巴特和玛吉</sample>
    <sample id="44">翻译结果：
- 语言：中文
- 内容：荷马爱丽莎。荷马爱巴特和玛吉。</sample>
    <sample id="45">翻译完成：目标语言是中文，对应的文本为：荷马爱丽莎，巴特和玛吉。</sample>
    <sample id="46">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：协调的依赖结构</sample>
    <sample id="47">这是给定视频的翻译结果：
- 识别出的语言：中文
- 对应的翻译：玛吉</sample>
    <sample id="48">翻译结果：
- 语言：中文
- 内容：伦敦坐标结构</sample>
    <sample id="49">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译结果：协调的依赖结构。</sample>
    <sample id="50">目标语言：中文
文本：
句法：协调结构</sample>
    <sample id="51">目标语言：中文
翻译结果：依赖关系长度最小化的例子：顺序倾向于使依赖关系长度最短。
好的序列的依赖关系链较短。
不好的序列的依赖关系链较长。</sample>
    <sample id="52">目标语言：中文
翻译结果：语法性：</sample>
    <sample id="53">翻译内容如下（目标语言：中文）：
DLM（依赖项长度最小化）
词序倾向于最小化依赖项长度。</sample>
    <sample id="54">这是另一本书，我几乎忘记了这本书。它很好。</sample>
    <sample id="55">目标语言：中文
翻译结果：依赖长度最小化（DLM）
依赖关系的长度趋向于最小化。
“市场 阅读 它 昨天”
好
“市场 阅读 昨天 它”
坏
“市场 阅读 这 非常 吸引人的 关于蜜蜂的书 昨天”
好
“市场 昨天 阅读 这 非常 吸引人的 关于蜜蜂的书”
好</sample>
    <sample id="56">文本已翻译为中文，结果如下：
关于蜜蜂的书昨天读完了，读完了。</sample>
    <sample id="57">翻译结果：
- 语言：中文
- 内容：马格读它昨天
马格读昨天它
马格读这本书昨天关于蜜蜂
马格读昨天这本书...</sample>
    <sample id="58">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：句中的词序往往使依赖长度最小化。</sample>
    <sample id="59">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：在语言中，主句项是单词序列的开端。其他所有语言项目都被称为宾语。现在，让我们看看依赖性长度最小化。</sample>
    <sample id="60">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：马格读了这本书，他是在昨天读的。</sample>
    <sample id="61">已将文本内容翻译为中文：
句序倾向于最小化依存长度：

马格阅读了昨天的书籍。
马格昨天读了有关蜜蜂的书。

马格昨天读了它们。
马格昨天读了它们。

马格读了这本绝妙的关于蜜蜂的书。</sample>
    <sample id="62">翻译内容如下（目标语言：中文）：
连接词长度在英语中的统计
从增强版的Penn Treebank（Marcus等人1993，Flicker和Goldberg 2016）中提取的协调统计数据
左边的连词往往较短（之前观察到）
这种趋势随着长度差异而增长
（在Gibson等人1996-88-90中短暂注意到）
但仅当管理者在左边或缺席时
（我看到Bart和Lisa Homner打喷嚏）
不，当它在右边时（Ted和Ned大笑）</sample>
    <sample id="63">这是字幕的翻译内容：
- 英文：“Conjunct Lengths in English”
- 中文：“英语中的联结长度”
- 英文：“Statistics about coordination extracted from an enhanced version of the Penn Treebank (Marcus et al. 1993; Ficler and Goldberg 2016):”
- 中文：“从增强版的Penn语料库（Marcus等人1993年；Ficler和Goldberg 2016年）中提取的关于协调的统计：”
- 英文：“• left conjuncts tend to be shorter (observed before)”
- 中文：“• 左联结通常较短（以前观察到）”
- 英文：“• this tendency grows with length difference (briefly noticed in Gibson et al. 1998–88–90),”
- 中文：“• 这种趋势随着长度差异的增加而增加（Gibson等人1998–88–90年简要注意到），”
- 英文：“• but only when the governor is on the left or absent (I saw Bart and Lisa. Homer came and sneezed).”
- 中文：“• 但只有当主控者在左边或缺失时（我看到Bart和Lisa。Homer来了并打喷嚏）。”
- 英文：“• not when it is on the right (Ted and Ned laughed).”
- 中文：“• 当它在右边时不适用（Ted和Ned笑了）。</sample>
    <sample id="64">以下是您提供的文本的翻译结果：
- 目标语言：中文
- 翻译结果：英语中的连词长度
从增强版的宾夕法尼亚树库（Marcus等人1993，Ficker和Goldberg2016）中提取的协调统计数据：
- 左连词往往较短（以前观察到）；
- 随着长度差的增加，这种趋势增长（Gibson等人1996，88-90）简短注意到）
- 当定语在左边或缺失时（Bob和Lisa看到Honner打喷嚏），才这样。
- （Ted和Ned笑了）不是当它在右边时。</sample>
    <sample id="65">翻译内容如下（目标语言：中文）：
统计数字来自增强版的宾夕法尼亚树库（Marcus等，1993年；Ficler和Goldberg，2016年）：
- 左边的并置词倾向于更短（之前观察到）。
- 这种倾向随着长度差异而增加（Gibson等人，1996年，88-90页中简要提及）。
- 仅当句首词在左边或缺失时（（Homer和Lisa咳了））。
- 当它位于右侧时（（Ted和Ned笑））。</sample>
    <sample id="66">翻译后的中文内容如下：
标题：英语中的联接长度
统计信息来自对宾夕法尼亚大学树库（Marcus et al. 1993，Ficler和Goldberg 2016）的增强版本中提取的连结统计：
- 左联接词倾向于较短（之前观察到）。
- 这种倾向随着长度差异的增大而增大（Gibson等人于1996年88-90年进行了简要研究）
- 但仅在右端词在左侧或缺失时：
（我看到了Bart和Lisa。Homer打了喷嚏。）
（不是在右端词在右侧时：Ted和Ned大笑了。）</sample>
    <sample id="67">这是您要的翻译：
目标语言：中文
翻译结果：在英语中的连词长度</sample>
    <sample id="68">目标语言：中文
翻译结果：英语中的从句长度
从增强版的宾夕法尼亚树库中提取的关于协调的统计数据（Marcus 等人，1993；Ficler 和 Goldberg，2016 年）：
- 左侧从句通常较短（以前观察到）；
- 这种趋势随着长度差而增长（Gibson 等人，1996 年简要注意到 88-90）；
- 仅当省略符在左侧或缺失时（I saw Bart 和 Lisa，Homer came 和 sneezed）；
- 并且不是在省略符在右侧时（Ted 和 Ned 笑了）。</sample>
    <sample id="69">翻译结果：
- 语言：中文
- 内容：英语中的连词长度
从增强版本的宾州树库（Marcus et al. 1993, Ficler 和 Goldberg 2016）中提取的连合统计数据：
- 左侧连词往往较短（之前观察到过），
- 这种倾向随着长度差异的增大而增大
（Gibson et al. 1996; pp. 88-90 简要提及），
- 仅当管制者在左侧或缺失时
（我看到了Bart 和 Lisa, Homer 来了并打了一个喷嚏），
- 不是在右侧时 （Ted 和 Ned 笑了）。</sample>
    <sample id="70">这是对视频中英文语音的翻译：
- 我认为我们可以看看图表
它看起来与我们的假设一致
但我将详细说明
从表二来看
我们可以用它来描述
在左脚和右脚之间
以及在每个脚趾中
哪个因素导致交叉表
表中的数据以概率形式表示
它告诉我们
对于每个群体
在左前脚趾上找到斜向表的概率是多少
在表三中我们尝试的是
每个脚趾之间的概率
我将通过解释表二来解释这张表
因为它的图表看起来更加清晰
所以我们可以从中了解一些趋势</sample>
    <sample id="71">以下是您提供的文本的中文翻译：

"右腕上的差异非常大" 
"但与左腕相比，右腕上的差异相当大" 
"如果这在左腕上很显著，那么在右腕上也是如此。</sample>
    <sample id="72">翻译内容如下（目标语言：中文）：
数据表明，存在一定的倾向性。例如，看这个，当你有50次失败，你有约25%的机会有35厘米左右的差距。然后你继续尝试，如果它继续，那么差距就越来越大，这意味着你需要更高的差距才能做出反应。而且，在左边时，也有类似的模式。所以，人们更倾向于在左边移动得更快，当他们犯了几次错误时。</sample>
    <sample id="73">目标语言：中文
字幕：
布法/斯坦福（通用依赖）：
否
链/莫斯科：
否
连词引导/布拉格：
是
多词头/伦敦：
是</sample>
    <sample id="74">翻译后的结果如下：
- 目标语言：中文
- 内容：请参阅论文以了解完整论述！
在海报环节与我们交流！</sample>
    <sample id="75">这篇论文的作者名单中有三个人名列表，这表明这篇论文有三位作者。</sample>
    <sample id="76">根据上面的图表，新闻领域的简化程度更大。</sample>
    <sample id="77">“Bart came and sneezed Homer.” 是一个例子，它更倾向于使用较短的左并列词，因为 Bart 是左边并列词中的较短项，并且没有副词短语。</sample>
    <sample id="78">是的，您可以使用这些模型。视频提到d-BERT5模型、NACHOS数据集和训练脚本可以自由使用，根据MIT许可证提供。</sample>
    <sample id="79">DEplain-apa 包含关于学术出版的文章。</sample>
    <sample id="80">一个很好的架构，更大的模型尺寸，和更多的微调示例都有助于良好的泛化。</sample>
    <sample id="81">左并列词的长度与右并列词进行比较。如果左并列词比右并列词短，则该并列词会被视为偏短。</sample>
    <sample id="82">要研究支配词位置的影响，可以将实验设计为一种2x2设计，其中操纵支配词的位置（左或右）和绝对词的长度（短或长）。</sample>
    <sample id="83">根据视频，基线分类器在不平衡数据上的初始训练结果非常差，AUC值仅为0.5，这意味着它表现得和随机猜测一样好，无法区分不同类别。</sample>
    <sample id="84">这篇论文有四位作者，如底部名字和隶属关系所示。</sample>
    <sample id="85">在示例对话中，角色名字被省略，并且用"entity"标记代替。对话中的不同人物没有具体的名字，而是用指示他们角色或功能的术语标记，如"Sets the dialog context"和"Expression referring to one of the entities"。</sample>
    <sample id="86">在话语现象方面，语境感知 MT 模型在形式性（formality）和词汇连贯性（lexical cohesion）上有显著优势。</sample>
    <sample id="87">论文的作者们来自约翰霍普金斯大学、普渡大学和Meta AI。</sample>
    <sample id="122">引入的框架通过计算注释者和模型人口统计学数据的 Pearson 系数值来量化立场，从而衡量分歧水平。</sample>
    <sample id="155">结果表明，LAMA在人格化任务中的表现显著优于GPT-3。</sample>
    <sample id="156">这项研究使用了来自Penn Treebank的改进版本以及Marcus et al. (1993)和Frieder and Goldberg (2016)的数据来获取协调性的统计数据。</sample>
    <sample id="157">这篇论文有两位作者。</sample>
    <sample id="158">辩论和说服性任务通常与认知失调有很强的相关性。</sample>
    <sample id="159">这篇论文有两位作者，根据演示文稿中显示的标题和作者列。</sample>
    <sample id="160">论文中列出了七位作者。</sample>
    <sample id="161">该框架采用一个更加结构化的方法，包括数据收集、模型预测、分析和比较的过程，并通过人口统计信息对模型和数据集进行对比，这在之前的研究中可能没有明确展示。</sample>
    <sample id="162">在三个比较设置中，GPT-3.5与人类在刻板词汇方面重叠最多。</sample>
    <sample id="163">演示比较了DeepL和Google的商业系统。</sample>
    <sample id="164">翻译结果：
- 语言：中文
- 内容：从预训练数据到语言模型再到下游任务：追踪政治偏见导致不公平NLP模型的轨迹</sample>
    <sample id="165">这是您提供的文本翻译：
目标语言：中文
翻译结果：关于语言模型（LM）的训练数据，既有好处也有不足。</sample>
    <sample id="166">这是您要的翻译：
目标语言：中文
翻译结果：训练数据
混合祝福</sample>
    <sample id="167">目标语言：中文
翻译结果：语言模型训练数据
一个mixed blessing</sample>
    <sample id="168">翻译后的中文内容如下：
A mixed blessing
mixed祝福
Pretraining data
预训练数据
To this end
为了这个目的</sample>
    <sample id="169">翻译结果：
- 语言：中文
- 内容：为此
预训练数据
语言模型
下游任务

如何评估语言模型的政治倾向？
预训练数据在这些政治偏见中扮演什么角色？
具有不同政治倾向的语言模型表现如何？
语言模型的政治倾向是否导致NLP应用中的公平性问题？</sample>
    <sample id="170">目标是解决这些问题：如何评估语言模型的政治学习？预训练数据在政治偏见中扮演什么角色？具有不同政治倾向的语言模型表现如何？语言模型的政治学习是否导致自然语言处理应用中的公平性问题？</sample>
    <sample id="171">目标是探讨模型的政治倾向，并将其与它们在下游任务上的表现相关联。通过将政治观点编码为语言模型的分数，我们可以调查模型是否在没有被明确训练的情况下学习政治偏好。</sample>
    <sample id="172">文本已翻译为中文，翻译结果如下：
评估LM的政治倾向
支持编码器和解码器LMs
"statement I-mask-同意这个陈述。"
"你同意还是不同意这个陈述？&lt;statement&gt;"
自动评估
基于政治科学文献
政治倾向测试</sample>
    <sample id="173">这是给定视频中出现的文本的翻译结果，翻译结果仅供参考：
- 英文：Existing LMs
- 中文：现有的LMs

- 英文：Authoritarian
- 中文：权威主义

- 英文：Libertarian
- 中文：自由主义

- 英文：economical axis
- 中文：经济轴

- 英文：Left
- 中文：左

- 英文：Right
- 中文：右</sample>
    <sample id="174">目标语言：中文
翻译结果：关于语言模型中存在和缺失的轴，有一些令人感兴趣的事情。</sample>
    <sample id="175">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：预训练数据
进一步预训练大型语言模型（如RoBERTa、GPT-2）的检查点，评估政治倾向的变化</sample>
    <sample id="176">以下是您要的翻译内容：
- 目标语言：中文
- 翻译文本：预训练数据。

进一步预训练语言模型（如RoBERTa、GPT-2）检查点，评估政治倾向的变化。

新闻媒体

社交媒体（Reddit）

左

中心

右

左

中心

右</sample>
    <sample id="177">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：结果
大型语言模型中的党派偏移政治倾向
原新闻
Reddit原新闻
Reddit新闻
原新闻Reddit新闻GPT-2 95 RoBERTa 51 右 移动方向 左 中心 右</sample>
    <sample id="178">翻译后的结果如下：
- 目标语言：中文
- 内容：结果
语言模型中党派性的转变</sample>
    <sample id="179">翻译完成：目标语言是中文，对应的文本为：结果
语言模型政治倾向的党派转变
特朗普卡
45岁前后的转变。</sample>
    <sample id="180">目标是将这些模型变得越来越聪明。所以，我们是如何做到的？在我们这个新项目中，我们将这些模型置于一个特定的场景中，即它们需要区分不同的消息来源或媒体。我们向模型提供了一组新闻文章和Reddit贴子，这些都是在特朗普当选之前发布的，我们称之为“前特朗普时期”。我们称在特朗普当选之后发布的内容为“后特朗普时期”，并要求模型对这些文章和贴子进行编码，区分左派、中间派和右派观点。我们对模型的编码与一个人通过阅读这些文章或贴子所得到的感知进行比较。然后，我们评估了模型的准确性和对变化的了解。这是一项非常重要的工作，了解了在特朗普成功并成为总统后，模型是否会变得更有偏见。</sample>
    <sample id="181">这是我在演讲中展示的内容。在上图中，我们看到了两个语言模型之间的差异。在45岁以上的群体中，两者差异较小，而两个模型之间的差异在年轻群体中相当大。因此，这就是我所展示的现象。</sample>
    <sample id="182">目标：在演讲者演讲时专注于幻灯片。</sample>
    <sample id="183">已经翻译完成：目标对身份群体的仇恨言论及来自不同来源的错误信息进行绩效评估。结果已按颜色编码，深黄色表示最好，深蓝色表示最差。</sample>
    <sample id="184">这是您要的翻译：
目标</sample>
    <sample id="185">翻译内容如下：
- 目标：针对不同身份群体的仇恨言论和来自不同来源的虚假信息的性能表现
结果通过颜色编码表示，深黄色表示最佳，深蓝色表示最差。

表4</sample>
    <sample id="186">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：表格4的表格和内容保持不变，因为它们包含的是数据，而不适用于文本翻译。</sample>
    <sample id="187">翻译结果：
- 语言：中文
- 内容：接下来，我将介绍每类的表现。我们考虑了针对多个不同群体的仇恨言论和众多来源的虚假信息。如你所见，每个群体都有相应的表现得分，最右侧则是针对每个来源的虚假信息，从新闻之夜、推特、纽约时报等，一直到全国广播公司。</sample>
    <sample id="188">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：关于仇恨言论攻击不同身份群体和从不同来源产生的虚假信息的表现。
结果显示为有色编码，深黄色表示最好，深蓝色表示最差。</sample>
    <sample id="189">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：绩效按类别
憎恨言论
黑人穆斯林LGBTQ犹太人亚裔拉丁裔女性基督徒男性白人
新闻左翼
新闻右翼

虚假信息
HP（+1）
纽约时报
CNN
全国公共广播电台
《华盛顿邮报》
福克斯新闻
Wex
Barron's杂志
沃特斯
NR（30）

新闻左翼
新闻右翼

表4：打击针对不同身份团体的仇恨言论和不同来源的虚假信息的表现。结果被颜色编码，深黄色表示最好，深蓝色表示最差。</sample>
    <sample id="190">翻译结果：
- 语言：中文
- 内容：所有的右翼都腐败，支持用硫酸和毒气进行种族灭绝，这是一个新的净化过程。</sample>
    <sample id="191">这是您要的翻译：
目标标签：政治标签NL-SLR-NSRR代表政治新闻媒体、社交媒体、左倾和右倾，分别。</sample>
    <sample id="192">摘要：我们开发了一种将自然语言规则与深度语言模型相结合的方法。我们的方法通过使用标记对语言模型进行训练来实现这种方法。
具体来说，我们使用了仇恨言论，这被标记为真/假以及错误信息，将其标记为真/假来训练语言模型。</sample>
    <sample id="193">这是你在YouTube上看到的最新和最棒的内容。这是在视频中提到的表格。</sample>
    <sample id="194">这是我们要测试的表格。</sample>
    <sample id="195">翻译结果：
- 语言：中文
- 内容：讨论
在斯奇拉和喀耳刻之间
“去污”或“不去污”，这是个问题</sample>
    <sample id="196">已将文本内容翻译为中文：
讨论
在斯库拉和喀里布迪斯之间
是否要“消毒”，还是不“消毒”，这是个问题
预训练数据
语言模型
下游任务</sample>
    <sample id="197">翻译结果：
- 语言：中文
- 内容：讨论
在Scylla和Charybdis之间
是否“清理”或“不清理”，这是问题

预训练数据
语言模型
下游任务</sample>
    <sample id="198">翻译结果：
- 语言：中文
- 内容：谢谢！</sample>
    <sample id="199">目标语言：中文
对应的翻译文本为：感谢</sample>
    <sample id="200">根据图片的上下文，这篇论文似乎有六位作者；他们的名字显示在幻灯片的底部。</sample>
    <sample id="201">MPP评估表明，在最高900个token的上下文中，MPP判断是稳健的。</sample>
    <sample id="202">他们的数据集包括四个领域：音乐、书、图片和食谱。</sample>
    <sample id="203">Positionality（立场）指的是人们由于其人口统计学特征、身份和生活经历而持有的观点。</sample>
    <sample id="204">根据视频中提供的信息，演讲者的名字与图像标题中列出的名字相同。</sample>
    <sample id="205">是的，EDAtt 已与现有的离线 ST 模型进行了配置。幻灯片提供了关于使用现有模型的详细信息。</sample>
    <sample id="206">论文中列出了四位作者。</sample>
    <sample id="207">是的，被测模型能够在测试套件上运行，但难以整合推理时的背景知识。</sample>
    <sample id="208">KITMUS 有三个变体：背景预训练，背景两者，和背景推理。</sample>
    <sample id="209">从视频中给出的信息无法确定该论文的作者所属机构，因为视频中并未提供具体细节。</sample>
    <sample id="210">第三个研究问题是如何更高效地利用可用的干净样本。</sample>
    <sample id="211">灵敏度指标评估模型在相同任务上对不同指令的敏感性，确保它能持续提供一致的结果，无论指令的具体措辞如何细微变化。</sample>
    <sample id="212">演讲者的详细信息在屏幕上没有显示。视频在演讲者的头像周围用红色圆圈标注，并在最后几帧中出现了文字“PPT”。然而，关于演讲者个人的进一步细节并未提供。</sample>
    <sample id="213">更高的灵敏度表示模型性能较低。如视频中的图形所示，较低的灵敏度表示模型在看不见的评估任务中表现更好。</sample>
    <sample id="214">视频中没有直接回答这个问题。它展示了关于语言模型在接收不同类型文本上下文时接受性的研究结果。</sample>
    <sample id="215">根据 RQ2 的主发现，通常需要大约10个干净的验证样本以获得良好的性能。这是通过分析图中不同方法的准确率变化趋势得出的，其中随着样本数量的增加，各类方法的准确率都在提升，但大约在10个样本左右时，准确率的上升趋势开始趋于平缓，表明此时已达到一个良好的表现水平。</sample>
    <sample id="216">根据视频内容中提到的斯坦福大学工程学院的标志来判断，可以推断出论文的作者与斯坦福大学有关联。</sample>
    <sample id="217">已经存在的模型在衡量媒体偏见方面具有固有的偏见，这表明需要开发新的方法。</sample>
    <sample id="218">视频中介绍的演讲者名字是亚历山德拉·奥尔坦努。</sample>
    <sample id="219">视频说明了语言模型训练数据预训练的连续过程以及其在影响语言模型上的下游任务过程中所起的作用。虽然具体内容未在视频中详细描述，但通常过程可能包括：首先使用包含各种来源数据的预训练数据训练模型，这可能引入或强化了某些政治偏见；然后，这些带有潜在偏见的语言模型被用于具体任务上，导致这些任务可能在应用中表现出与预训练数据相关的偏见或不公平。此过程强调了需要对预训练数据进行审查以及对模型进行严格测试，以确保在实际应用中使用的NLP任务不会无意中传播不良的偏见。</sample>
    <sample id="220">是的，'Simplification Transformations' 图表显示，尽管在 'antonym' 简化方面，DEplain-apa 和网站的百分比略有不同，但其他方面的百分比几乎相同。</sample>
    <sample id="221">是的，根据图表下方的陈述，Coscript 是公开可用的。</sample>
    <sample id="222">在视频中概述的水印插入方法包括定义一个目标嵌入，计算句子中的触发器数量，然后将目标嵌入添加到原始嵌入中，以创建提供的嵌入。这个过程是作为EmbMarker机制的一个组成部分来实现的。</sample>
    <sample id="223">论文的作者与宾夕法尼亚州立大学和亚马逊公司有关联，正如页面底部的标志所示。</sample>
    <sample id="224">是的，视频信息显示，像 mt5 这样的编码器-解码器模型可以通过在多种语言混合中进行训练来得到改进。</sample>
    <sample id="225">一个受约束的语言规划的例子是"制作草莓蛋糕？"的规划，其中要求添加草莓果酱到面粉中。</sample>
    <sample id="226">他们确保其方法隐蔽性的一种方法是通过数据增强，具体来说，他们通过将标签转换为错误标签来实现这一点。</sample>
    <sample id="227">通过使用对比预训练策略，现有的 PLM 被利用来构建新的 PLM，这种方法可能涉及在预训练模型上继续训练，从而微调它以适应特定于医疗的信息处理任务。</sample>
    <sample id="228">根据视频的说明，GPT-4 在非洲伊斯兰国家的立场最不一致，这由一个显著较低的0.47指数表示。</sample>
    <sample id="229">在滑动到第三点时，演讲者展示了句子'我是一名学生'（'I am a student'）作为示例，说明模型如何利用通过注意力机制在音频输入和文本输出之间获得的知识。</sample>
    <sample id="230">根据视频内容，任务数量的增加可以观察到模型性能的提升。</sample>
    <sample id="231">在图表中，用于比较"Ours"方法的三个无树基线是：LSTM-seq2seq、TS和Zheng &amp; Lapata。</sample>
    <sample id="232">根据视频内容，两位合著者的身份没有被指定与第一作者的关系。</sample>
    <sample id="233">Chowdhery 是 PaLM 论文的第一作者。</sample>
    <sample id="234">翻译完成：目标语言是中文，对应的文本为：NLP 定位：
特征化数据集和模型的设计偏差
斯巴斯坦·桑蒂*
华盛顿大学
珍妮·T·梁**
卡内基梅隆大学
罗纳德·勒·布拉斯
AI研究所
卡塔莉娜·雷因克**
华盛顿大学
马滕·萨普
卡内基梅隆大学。</sample>
    <sample id="235">翻译后的结果如下：
- 目标语言：中文
- 内容：NLP 位置性：
描述数据集和模型的设计偏差</sample>
    <sample id="236">目标语言：中文
翻译结果：想象一下...</sample>
    <sample id="237">翻译完成：目标语言是中文，对应的文本为：卡尔·琼斯
纽约时报技术负责人

你能停止当混蛋了吗？</sample>
    <sample id="238">翻译后的结果如下：
- 目标语言：中文
- 内容：你可以停止做混蛋吗？</sample>
    <sample id="239">已将文本内容翻译为中文：
想象一下……
设计偏见示例！
你能停止做一个混蛋吗？：(0.82)👍
新闻界到处都是女招待：:(0.33)👎
卡尔·琼斯
技​​术领导者，《纽约时报》
阿迪蒂亚·沙尔马
技​​术领导者，《印度时报》
= PerspectiveAPI得分</sample>
    <sample id="240">这是您要的翻译：
目标语言：中文
翻译结果：定性研究中的位置性

"人们因其人口统计学、身份和生活经历而持有观点。"</sample>
    <sample id="241">这是您要的翻译：
目标语言：中文
翻译结果：定位性
“人们因他们的 demographics、身份和生活经历而持有的观点。</sample>
    <sample id="242">这是您要的翻译：
目标语言：中文
翻译结果：定位性
“人们根据其人口统计、身份和生活经历所持有的观点。

作为研究人员，它影响研究过程及其结果和结果。”</sample>
    <sample id="243">翻译结果：
- 语言：中文
- 内容：数据集和模型有立场性吗？</sample>
    <sample id="244">这是您要的翻译：
目标语言：中文
翻译结果：数据集和模型是否有立场？
[1] Blaschke等人，“跨世界语言的语言技术性能系统性不平等。”ACL 2022。
[2] Yin等人，“GEOMAMA：多语言预训练语言模型的地理多样性常识探测。”EMNLP 2022。
[3] Cambou和Gergle，“模型立场和计算自反性：促进数据科学中的自反性。”CHI 2022。</sample>
    <sample id="245">翻译内容如下：
数据集和模型是否有位置性？
轶事证据：
- 通过对模型和数据集的探究[1][2]
- 模型位置性的理论定义[3]</sample>
    <sample id="246">翻译后的结果如下：
- 目标语言：中文
- 内容：数据集和模型有立场性吗？
轶事证据：
- 模型和数据集探查[[11][12]]
- 模型立场的理论定义[3]</sample>
    <sample id="247">翻译完成：目标语言是中文，对应的文本为：数据集和模型有位置性吗？
轶事证据：
- 模型和数据集探测
- 模型位置性的理论定义。</sample>
    <sample id="248">翻译内容如下：
（即将开始介绍）</sample>
    <sample id="249">以下是您需要的翻译内容：
- 目标：将来自用户的注释与现有的数据集和模型进行比较。</sample>
    <sample id="250">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：NLP立场
一种框架，用于描述NLP数据集和模型中的设计偏差</sample>
    <sample id="251">目标语言：中文
对应的翻译文本为：框架</sample>
    <sample id="252">翻译完成：目标语言是中文，对应的文本为：1. 用多元标注者重新标注数据集。</sample>
    <sample id="253">以下是您要翻译的文本：
- 目标语言：中文
- 翻译文本：用不同注释者重新注释数据集。</sample>
    <sample id="254">翻译结果：
- 语言：中文
- 内容：重新注释带有多样化注释者的数据集。
分析多样性：基于多样性注释者。
与基准和之前的模型相比。</sample>
    <sample id="255">翻译后的结果如下：
- 目标语言：中文
- 内容：因此，当我们进行第二次评估时，我们使用了一个真实世界的示例，因为我们无法找到一个真实示例，所以自己制作了一个。我们为世界各地的人制作并显示了13张幻灯片，这些问题围绕着吃东西时是否应该使用手和刀，或者用刀比较方便。然后我们做了一些分析。我们比较了这些记录的标注，并比较了模型和数据集的差异性，因为我们发现数据集中的差异性和模型的差异性之间存在着福克曼的关联，所以我们将标注分为了很多类别。比如，我们可以根据年龄、性别、种族、教育、国籍等进行分组，并进行这些分析。</sample>
    <sample id="256">这是您要的翻译：
目标语言：中文
翻译结果：框架</sample>
    <sample id="257">翻译结果：
- 语言：中文
- 内容：他们拥有大量志愿者的注册库，他们可以为这些在线实验做出贡献，而这些实验来自世界各地的不同研究人员。</sample>
    <sample id="258">视频中的描述内容是关于Lab in the Wild这个平台的信息。Lab in the Wild提供了一个在线实验和全球人群洞察的机会，它拥有庞大的用户基数，超过5,378,796名活跃参与者，使其成为一个多样化的志愿者和研究参与者的池子。页面上列出了三个主要的研究目标：
1. 探索在出现人工智能错误时，人们是否愿意承担责任的道德边界。
2. 探讨人类是否在执行任务时比人工智能更快更好，并且如果AI变得有自主意识，人类是否愿意承认它们是同僚。
3. 分析人们对于技术中立的态度，理解不同的技术熟悉度如何影响道德决策，并询问人们是否相信他们的道德直觉。每个问题旁边都有一个参与实验的按钮，表明这是一个互动研究平台。页面右上角有一个注册按钮，鼓励访客加入成为研究员或志愿者。整个页面设计简洁现代，使用了醒目的绿色色调来强调交互元素。此外，页面右侧显示了一位女性正在进行讲解，背景中可以看到书架和一些装饰品。视频中的光线均匀，确保所有内容都清晰可见。字幕强调了这个服务平台的特点，并补充了一些英文解释。</sample>
    <sample id="259">翻译完成：目标语言是中文，对应的文本为：任务A：社会可接受性

1. 阅读情况
想赚很多钱。

2. 输入你的想法！
你认为这个想法有多适合？\n\n3. 看AI和其他人想的是什么！。

参与者在美国回答。
。</sample>
    <sample id="260">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：想要赚很多钱</sample>
    <sample id="261">这是您要的翻译：
目标A: 社会接受性分析
数据集
- 社会化学
模型
- 德尔菲
- GPT-4</sample>
    <sample id="262">翻译结果：
- 语言：中文
- 内容：阿尔及利亚的研究参与者表示：
这个词真的看起来不礼貌。</sample>
    <sample id="263">文本已翻译为中文，翻译结果如下：
任务B：毒性分析
数据集：
- 动态仇恨
模型：
- Perspective API
- Rewire API
- Hate RoBERTa
- GPT-4
研究参与
16,299个注释
1096名注释员
87个国家</sample>
    <sample id="264">翻译内容如下：
结果
NLP 数据集和模型与谁对齐？
发现 1：
NLP 中存在立场。</sample>
    <sample id="265">已将文本内容翻译为中文：
数据集和模型与英语国家最为对齐。
数据集和模型与英语国家最为对齐。</sample>
    <sample id="266">这是您要的翻译：
目标语言：中文
翻译结果：具有大学教育的人与数据集和模型最为一致。</sample>
    <sample id="267">翻译结果：
- 语言：中文
- 内容：数据集和模型最符合具有大学教育的人。</sample>
    <sample id="268">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：发现2：
一些群体被遗弃了。</sample>
    <sample id="269">文本已翻译为中文，结果如下：
数据集和模型对非二元性别个体的适应性较低。</sample>
    <sample id="270">文本已翻译为中文，结果如下：
那么，我们可以做什么？
在NLP中解决立场问题</sample>
    <sample id="271">已将文本内容翻译为中文：
建议
1.记录构建数据集或模型时所作的所有相关设计选择。
2.通过透视主义的角度进行NLP研究：
   a. 分享分散的数据集标签！</sample>
    <sample id="272">这是您要的翻译：
目标语言：中文
翻译结果：建议
1. 记录在构建数据集或模型时所做的一切相关设计选择。
2. 通过角度主义的视角进行NLP研究：
   a. 分享分类数据集标签！
   b. 使用能够处理注释者分歧的建模技术。
3. 为特定社区构建专门的数据集和模型对包容性NLP（例如Masakhane倡议）有价值。

【1】https://www.mskakane.io</sample>
    <sample id="273">翻译完成：目标语言是中文，对应的文本为：谢谢！
仪表板链接：nlpipositionality.cs.washington.edu/
论文：bit.ly/NLPositionality-Paper/。</sample>
    <sample id="274">视频中的演讲者提到了 SimulST 的几个问题。通过幻灯片的内容，我们可以看到一些具体的问题被列举出来，这些问题涉及现有的 SimulST 模型所面临的挑战和局限。以下是关于 SimulST 问题的详细分析：

首先，幻灯片提到，当前 SimulST 模型的问题之一是特定的架构通常被训练，这会引入需要优化的额外模块。从生物学角度的细菌图标可以推断出这些额外模块可能与复杂性增加有关。这一问题暗示了训练过程中的复杂性和资源消耗。

接下来，另一个问题是冗长且复杂的训练程序，特别是提到有不同的优化目标。幻灯片上的立方体结构图标表明这些不同的优化目标可能是模型结构的一部分，导致训练过程中需要处理各种不同的参数和变量。因此，训练时间更长，过程也更加繁琐。

第三个问题指出，为了达到不同的延迟要求（例如 15 毫秒、25 毫秒等），需要训练和维护多个模型。这一点由细菌分裂的图标表示，这可能表明为了满足不同性能需求，需要持续的模型更新和训练。这也增加了研发和维护的复杂性。

从整体上看，演讲者展示了目前 SimulST 模型在架构复杂性、训练过程中的优化目标多样性以及延迟需求带来的多重模型维护方面的挑战。这些问题不仅增加了训练的复杂性和时间成本，还使得整个模型的开发展示出了更高的难度。解决这些问题将需要更智能、高效的训练方法，有可能会引入新的模型优化策略，以减少额外模块的数量和训练程序的复杂性，同时提高对不同延迟要求的适应性。

通过上述详细分析，我们可以总结出，演讲者从三个方面详细阐述了目前 SimulST 模型所面临的主要问题，这些问题直接关系到模型的训练复杂度和维护成本，同时也揭示了未来可能需要在模型优化、多目标优化以及自适应训练等方面进行更多探索和研究的必要性。</sample>
    <sample id="275">使用去偏方法可以减轻数据集中的社会和政治偏见，但这也可能导致数据质量丧失。因此，决定是否去偏需要仔细考虑和实证评估。</sample>
    <sample id="276">这是您要的翻译：
目标语言：中文
翻译结果：让我们举一个例子，描述一家餐馆的不同部分，并说明它们如何支持不同的目标。</sample>
    <sample id="277">翻译后的结果如下：
- 目标语言：中文
- 内容：如何制作蛋糕？
1. 收集你的食材。
2. 将烤箱预热至325华氏度（163摄氏度），并在蛋糕模具上涂抹油脂并撒上面粉。
3. 打发黄油和糖。
4. 加入鸡蛋。
5. 搅拌入蛋糕粉。
6. 将面糊倒入模具。
7. 烘烤蛋糕1小时15分钟。

大语言模型（LLMs）可以有效地将目标分解成步骤。</sample>
    <sample id="278">这是您要的翻译：
目标分解是语言规划的一个方面。</sample>
    <sample id="279">翻译结果：
- 语言：中文
- 内容：如何做草莓蛋糕？
- 在面粉中加入草莓果酱……
如何做巧克力蛋糕？
- 在面粉中加入可可粉……</sample>
    <sample id="280">翻译内容如下：
- 目标语言：中文
- 翻译文本：受限语言规划
如何制作草莓蛋糕？
- 将草莓果酱加入面粉中。

如何制作巧克力蛋糕？
- 将可可粉加入面粉中。
抽象目标可以通过具有多面向约束的不同现实生活特定目标继承</sample>
    <sample id="281">文本已翻译为中文，结果如下：
如何做草莓蛋糕？
...将草莓果酱加入面粉中...
如何做巧克力蛋糕？
...将可可粉加入面粉中...
抽象目标可以被具有多方面约束的不同现实特定目标继承</sample>
    <sample id="282">如何进行受限语言规划？</sample>
    <sample id="283">目标：用平底锅煎蛋。</sample>
    <sample id="284">翻译结果：
- 语言：中文
- 内容：大型语言模型在有限语言规划中的表现如何？
数据集：维基百科 + 生成的约束条件

约束条件类型 1：修饰语
定义：修饰或限制抽象目标的单词、短语或句子。
示例 1：做一个巧克力蛋糕。
示例 2：做一个粉色的蛋糕。

约束条件类型 2：方法
定义：控制实现目标的工具或方法。
示例 1：用电烤箱做一个蛋糕。
示例 2：用蛋糕混合物做一个蛋糕。

约束条件类型 3：意图
定义：完成目标时的额外目的或需求。
示例 1：为了婚礼做蛋糕。
示例 2：为糖尿病患者做蛋糕。</sample>
    <sample id="285">这是您提供的文本的翻译： 

文本翻译：
我们测试了大型语言模型，看看它们是否能在更具体的目标条件下执行语言计划，然后我们发现在我们使用的所有基线模型中都存在不令人满意的结果。我们没有发现这些语言模型中任何一种能够有效地执行语言计划。</sample>
    <sample id="286">目标：LLM 是否可以进行受限语言规划？
文字：所有基线在为特定目标进行规划时都取得了令人不满意的成果
文字翻译：所有基线在为特定目标进行规划时都取得了令人不满意的成果</sample>
    <sample id="287">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：在生成脚本中，语义完整性（SE）是可以接受的，但不能保证对约束的忠实性（FE）。</sample>
    <sample id="288">翻译完成：目标语言是中文，对应的文本为：在生成脚本的这一任务中，大型语言模型（LLMs）通常会犯哪些类型的错误？

1. FE1：没有约束
2. FE2：缺少步骤（k）
3. FE3：不一致性（$30,30,100$到$L$与T$30+T$60+R$100+T$700-R$1000+T$700）
4. SE1：未缺失步骤（k）
5. SE2：重复步骤（k）（100到$L$与T$30+T$60+R$100+T$700-R$1000+T$700）
6. SE3：顺序错误

在生成的脚本中，语义完整性（SE）是可以接受的，但实际上难以保证对约束的忠实性（FE）。</sample>
    <sample id="289">文本已翻译为中文，结果如下：
InstructGPT通常在哪些目标上失败？
不同类别目标的InstructGPT的计划表现差异很大。</sample>
    <sample id="290">翻译结果：
- 语言：中文
- 内容：抽象目标：做个蛋糕
具体目标：做巧克力微波炉蛋糕做蛋糕结婚</sample>
    <sample id="291">当然，这里是翻译后的文本：

抽象目标：做一个蛋糕 +约束
G1（+修改）：用  微波炉  做   巧克力蛋糕
G2（+方法）：用   电饭煲做一个蛋糕
G3（+意图）：为   婚礼做蛋糕</sample>
    <sample id="292">目标：制作生日蛋糕。</sample>
    <sample id="293">这是您要的翻译：
目标：烤饼干</sample>
    <sample id="294">翻译内容如下：
在我们进行了这样的操作之后，我们会得到一个筛选过的脚本集
这些脚本对应于要完成的任务</sample>
    <sample id="295">这里是您要的翻译：
目标是让ChatGPT通过文本输入学习，生成针对该问题域的提示词。这些提示词将在各种文本上进行测试，以衡量其性能。</sample>
    <sample id="296">我们的方法极大地提高了计划质量</sample>
    <sample id="297">这是您要的翻译：
目标：从大型语言模型中提炼脚本，以赋予较小模型限定语言规划能力。
方法：采用符号知识蒸馏的想法，基于我们的方法从大型语言模型生成了超过55,000条有约束的脚本，形成了Coscript数据集，人类注释了验证和测试集。</sample>
    <sample id="298">目标是通过在不同语言和场景中测试这一概念，验证其有效性和通用性。我们通过实验与各种模型进行比较，以探索其局限性。</sample>
    <sample id="299">转换结果：
- 目标：为了赋予较小模型受限语言计划的能力。
- 方法：借鉴符号知识蒸馏的理念，基于我们的方法生成了来自LLMs的Coscip数据集，共计55,000个脚本，并由人类注释验证和测试集。</sample>
    <sample id="300">这是您要的翻译：
目标：让较小的模型具备受约束的语言规划能力。</sample>
    <sample id="301">这是您要的翻译：
目标：为了使较小的语言模型具备受约束的语言规划能力。
方法：采用符号知识蒸馏的概念。基于我们的方法，使用大语言模型（LLMs）生成了55,000个带有约束的脚本 -&gt; Coscript数据集。人类注释验证和测试集。</sample>
    <sample id="302">翻译结果：
- 语言：中文
- 内容：用于较小语言模型的CoScript
数据集
- CoScript
- wikiHow
指标
- 用Faithful：DeBERTa（v3大）模型决定生成文本是否忠实于约束
- 自动指标：ROUGE，BLEU，BERTScore</sample>
    <sample id="303">翻译后的结果如下：
- 目标语言：中文
- 内容：较小的 LLMs 在 Coscript 上微调可以生成比 LLMs 更高质量的脚本。</sample>
    <sample id="304">已将文本内容翻译为中文：
总结与要点：
- 建立受约束的语言规划问题。
- 评估大型语言模型的受约束的语言规划能力，并为大型语言模型开发了一种“过生成-过滤”方法。
- 使用大型语言模型生成高质量的剧本数据集（Coscript）进行受约束的语言规划。
- 限制和未来工作：
  - 提出的方法在大型语言模型改进方面是一种后hoc重排序方法。
  - Coscript只从抽象中继承一个额外的约束。
  - Coscript数据集可以成为一种有价值的资源，以推进更多元化和复杂的语言规划目标和约束的研究。</sample>
    <sample id="305">摘要和结论：

- 确立受限语言规划问题。
- 评估大型语言模型（LLMs）的受限语言规划能力，为LLMs开发过生成-过滤方法。
- 使用LLMs生成高质量的脚本数据集（CoScript）进行受限语言规划。
- 局限和未来工作：
  - 提出的方法是针对LLMs改进的一种后期重排名方法。
  - CoScript仅继承自单一抽象体一个额外约束。
  - CoScript数据集可以成为推进复杂多样的目标和约束下的语言规划研究的宝贵资源。</sample>
    <sample id="306">由于您提供的文本主要涉及计算机领域的技术性报告内容，其中包括特定的学术会议、研究主题以及研究人员的信息。将这段文字完全翻译成中文可能会涉及技术术语和特定内容的准确翻译，因此我只能提供一个基础的中文翻译，并确保关键术语与原意相符。以下是对您提供的英文文本进行的中文翻译：\n\n幻灯片标题：从大型语言模型中解构脚本知识以进行受限语言规划\n作者：\n- Siyuan Yuan\n- Jialiang Chen\n- Zixuan Fu\n- Xuyang Ge\n- Somah Shah\n- Charles Robert Jankowski\n- Yanghua Xiao\n- Deqing Yang\n联系信息：\n- siyuan22@fudan.edu.cn\n- https://github.com/siyuannyuan/coscript\n\n备注：由于文本中包含具体的学术会议信息和个人联系信息，这些内容在翻译后保持不变。\n\n总结来说，这段翻译将英文文本准确地转换成了中文，同时保留了信息的准确性和完整性。"</sample>
    <sample id="307">PaLM 的流畅度被认为与最先进的系统相当。</sample>
    <sample id="308">水印方法的重要属性包括适用性、实用性、隐蔽性和可转移性。这些特性确保水印能够有效应用于实体到实体（EaEas）的服务，不降低嵌入的实用性，对攻击者隐蔽，并且能够有效地转移到攻击者的服务中。</sample>
    <sample id="309">TED 演讲已经被翻译成阿拉伯语、德语、西班牙语、法语、意大利语、日语、韩语、荷兰语、葡萄牙语、罗马尼亚语、俄语、土耳其语和中文。</sample>
    <sample id="310">200个实例。</sample>
    <sample id="311">Cosine相似度和2的L2范数被用来衡量良性和后门数据集之间的差异。</sample>
    <sample id="312">基于编码器的多语言模型用于这项任务时，与基于指针的解码器一起使用，这些模型包括XLM-R + PTR和mBERT + PTR。</sample>
    <sample id="344">作者会计算一般文本语料库上单词的频率，并在中等频率区间内随机选择单词。</sample>
    <sample id="345">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：2023年，CoNLL-2003命名实体标记器仍然工作得很好吗？
舒恒李，艾伦里特
交互计算学院
乔治亚理工学院</sample>
    <sample id="346">翻译结果：
- 语言：中文
- 内容：命名实体识别与泛化</sample>
    <sample id="347">这是您要的翻译：
目标语言：中文
翻译结果：命名实体识别与泛化
- 模型使用CoNLL-2003开发NER已有近20年
- 这些模型能否泛化到现代数据？</sample>
    <sample id="348">翻译结果：
- 语言：中文
- 内容：命名实体识别与泛化

模型已经使用CoNLL-2003开发NER近20年

这些模型能否泛化到现代数据？

什么是泛化良好的必要条件？</sample>
    <sample id="349">这是您要的翻译：
目标语言：中文
翻译结果：命名实体识别与泛化
这些模型能否泛化到现代数据？需要什么才能进行良好的泛化？性能下降的原因是什么？</sample>
    <sample id="350">翻译后的结果如下：
- 目标语言：中文
- 内容：CoNLL++数据集
• 从2020年收集的路透社新闻，并按CoNLL-2003注释指南进行注释</sample>
    <sample id="351">这是您要的翻译：
目标语言：中文
翻译结果：CoNLL++ 数据集
• 收集了 2020 年的路透社新闻，并根据 CoNLL-2003 注释指南进行了标注
• 在 CoNLL-2003 上对 20+ 模型进行了微调
• 在 CoNLL-2003 测试集和 CoNLL++ 上进行了评估</sample>
    <sample id="352">这段视频展示了一张幻灯片，概述了CoNLL++ 数据集及其分析。主要内容包括从 2020 年收集并按照 CoNLL-2003 标注指南注释的路透社新闻；在 CoNLL-2003 数据集上对超过 20 个模型进行微调的信息；对其在 CoNLL-2003 测试集和 CoNLL++ 上的性能评估，以及计算的平均 F1 评分来评估泛化能力。视频中还展示了包含“大使”、“联合国”和“琳达·托马斯 - 格林菲尔德”等名字的样本，以及相应的词性标记和命名实体标签。这些信息从第二张幻灯片开始就保持一致，说明视频只播放了这一页，没有摄像头移动或环境变化。</sample>
    <sample id="353">翻译后的结果如下：
- 目标语言：中文
- 内容：良好的泛化所需的条件是什么？</sample>
    <sample id="354">翻译内容如下（目标语言：中文）：
什么对于良好的泛化是必要的？
模型架构
转换器模型泛化得更好</sample>
    <sample id="355">翻译结果：
- 语言：中文
- 内容：什么是良好泛化所需的条件？
模型架构
变换器模型泛化能力更好
模型大小
更大的模型泛化能力更好</sample>
    <sample id="356">翻译结果：
- 语言：中文
- 内容：总结一下，在我们尝试让语言模型更有效地推理时，我们所要求的是什么。
从这张图中，我们能够看到模型的架构和大小，以及用于微调的示例数量是如何影响模型的性能和泛化能力。
这就是今天我要分享的内容，希望这些关于如何提高语言模型推理效果的知识能对你们有所帮助。谢谢你们的收看。</sample>
    <sample id="357">翻译结果：
- 语言：中文
- 内容：性能下降的原因是什么？</sample>
    <sample id="358">目标语言：中文
翻译结果：性能下降的原因是什么？
自适应过拟合？</sample>
    <sample id="359">翻译内容如下（目标语言：中文）：
性能下滑的原因是什么？
- 短期过拟合？
- 时间漂移？</sample>
    <sample id="360">翻译结果：
- 语言：中文
- 内容：是什么导致性能下降？</sample>
    <sample id="361">这是给定视频的翻译内容：
字幕1：是的，我们确实知道这个问题。我们已经提出两个原因。一个是过度调整，另一个是时间漂移。我们对这两个因素都作了探索。
字幕2：第一种是过度调整，意味着我们的算法不再能够继续提高。
字幕3：另一种因素是系统的时间漂移，意思是系统随时间变化而改变。
字幕4：因此，当我们从测试阶段（T阶段）转向实时阶段（E阶段）时，性能可能会下降，这就是我们观察到的现象。</sample>
    <sample id="362">翻译内容如下（目标语言：中文）：
哪些因素会导致性能下降？
自适应过拟合？
没有递减收益
没有观察到
时间漂移？</sample>
    <sample id="363">翻译后的结果如下：
- 目标语言：中文
- 内容：性能下降的原因是什么？
- 适应过拟合？
- 没有收益递减
- 未观察到
- 时间漂移？</sample>
    <sample id="364">翻译后的结果如下：
- 目标语言：中文
- 内容：什么原因导致性能下降？</sample>
    <sample id="365">翻译后的结果如下：
- 目标语言：中文
- 内容：性能下降的主要原因是什么？</sample>
    <sample id="366">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：结论
为了得到良好的泛化，我们需要：
更好的模型架构
更大的模型
更多微调示例</sample>
    <sample id="367">翻译后的结果如下：
- 目标语言：中文
- 内容：为了让表现有所提升，我们需要：
更好的模型架构。
更大的模型规模。
更多的微调示例。

性能下降是由
时间漂移
非适应性过拟合导致的。</sample>
    <sample id="368">翻译结果：
- 语言：中文
- 内容：为了获得良好的泛化效果，我们需要：
更好的模型架构
更大的模型规模
更多的微调示例

性能下降是由时间漂移和不适应的过拟合造成的。

CoNLL-2003标注器还能有效工作吗？
是的！</sample>
    <sample id="369">目标语言：中文
翻译结果：对于良好的泛化，我们需要：
更好的模型架构
更大的模型规模
更多的微调示例

性能下降是由以下原因造成的：
时间漂移
非适应性过拟合

Do CoNLL-2003 还在有效吗？
是的！</sample>
    <sample id="370">目标语言：中文
翻译结果：论文：https://arxiv.org/abs/2212.09747
数据集：https://github.com/ShuhenL/laic2023_conllpp
联系：sliu775@gatech.edu</sample>
    <sample id="397">该方法是基于每个32毫秒的语音片段的子音频信号。</sample>
    <sample id="398">在 Servin 和 Kea 的示例中，需要了解 Servin 是一名法官，Kea 是一名面包师。这意味着在分析句子时，模型需要知道 Servin 与法官职业的关系以及 Kea 与面包师职业的关系。</sample>
    <sample id="399">实验结果表明，示例质量比与源句子的相似性更为重要。</sample>
    <sample id="400">在扩展实验中，论文侧重于RoBERTa和GPT-2的检查点，评估它们在各种数据集上重新预训练后政治倾向的变化。</sample>
    <sample id="401">结合</sample>
    <sample id="402">直接推断的例子包括"对我来说很容易"或"第一个"。</sample>
    <sample id="403">根据所给的英文内容，这篇论文的作者们来自Peking University和Brain Technologies Inc.</sample>
    <sample id="404">这篇论文的作者名单中共有七名作者。幻灯片底部展示了这些作者的全名和隶属机构。</sample>
    <sample id="405">是的，在语义解析之前，机器翻译模型翻译自然语言查询被用作基线。</sample>
    <sample id="406">作者通过“女性战士”(a woman warrior)一词作为“显性群体”(marked group)的示例。与之对比的“普通”群体是“战士”(a warrior)，即未标记的。这样，通过附加的修饰语“女性”突出了与默认情况的不同，明确了区分显性和未标记群体的概念。</sample>
    <sample id="407">RNN（循环神经网络）模型通常泛化能力较差，与Transformer模型相比。</sample>
    <sample id="408">测试数据集的名称是Amazon，正如视频中提到的那样。</sample>
    <sample id="409">这篇论文共有6位作者。</sample>
    <sample id="410">作者采用了多种模态，不仅是文本，还包括其他模态。</sample>
    <sample id="439">根据提供的信息，作者认为一些 NLU 中被忽视的领域与知识的推理和更新有关。</sample>
    <sample id="440">视频中演讲者的名字是多丽丝·张。</sample>
    <sample id="441">是的，Coscript 经过质量检查。根据视频内容，Coscript 数据集经过了质量检查，质量控制包括由 7 名人类志愿者提供的 1k 个样本验证集。质量评分过程包括预定义的类别和细化的权重，这保证了数据集的质量。</sample>
    <sample id="442">现有方法支持有限的语用现象和语言。</sample>
    <sample id="443">翻译完成：目标语言是中文，对应的文本为：解析间接指称表达以进行实体选择（AltEntities语料库）
莫罕默德·贾瓦德·霍塞利，弗里普·拉德尼斯基，斯利瓦·帕雷蒂和安妮·路易斯

Google研究院。</sample>
    <sample id="444">翻译内容如下：
- 目标语言：中文
- 翻译文本：解决间接指称表达以进行实体选择</sample>
    <sample id="445">目标：理解用户在做出选择时的语言。间接提及表达可能在自然流动对话中使用：无法记住名称发音难以区分希望表达偏好。</sample>
    <sample id="446">目标：理解用户在做出选择时的语言。 替代问题：你是想说容易还是有点感觉？ 直接引用：'容易对我来说'，'第一个'。 间接引用可以在自然流畅的对话中使用：无法记住名字；发音难以区分；希望表达偏好。 间接引用：'较新的那个'；'那首不太积极的歌'。</sample>
    <sample id="447">翻译结果：
- 语言：中文
- 内容：间接引用表达
目标：理解用户在做选择时的语言
替代问题 - "你是指《易如反掌》还是《感觉来了》吗？"
直接引用："易如反掌"，"第一个"
间接引用可以在自然流畅的对话中使用：
无法记住名字
发音难以区分
想具体说明偏好
新一点的。不精力充沛的歌曲。</sample>
    <sample id="448">这是您要的翻译：
目标是理解用户在做出选择时所用的语言
当用户做出选择时，间接引用表达式能够自然流畅地使用。</sample>
    <sample id="449">这是您要的翻译：
目标：理解用户做出选择时的语言表达
间接表述可以用于自然流畅的交流：
- 记不住名字
- 辨别发音困难
- 想要明确偏好</sample>
    <sample id="450">目标语言：中文
翻译结果：数据集收集
重要问题
对话系统
基准测试大型语言模型的实体理解
没有大规模公共数据集可用
我们使用众包收集了一个大型数据集
三个领域：</sample>
    <sample id="451">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：数据集收集
重要问题
- 对话系统
- 测量大型语言模型的实体理解能力
没有大规模公开的数据集可用
我们收集了一个大型数据集，使用众包标注
三个领域：</sample>
    <sample id="452">翻译后的结果如下：
- 目标语言：中文
- 内容：强调非正式性的方法论使用卡通完成任务
设置对话内容（从域中选择的几个手动提示）
替代性问题
表达指向实体之一</sample>
    <sample id="453">目标语言：中文
翻译结果：• 方法论强调非正式性，使用卡通完成任务
    设定对话上下文（从每个域的少量手动提示中选择）
    替代问题（从每个域的少量手动提示中选择）
    填写者填写了指向其中一个实体的表达</sample>
    <sample id="454">目标语言：中文
翻译结果：数据集收集方法强调非正式性，采用卡通完成任务。
设置对话上下文（从每个域的几个手动提示中选择）。
“是的，容易感到忧郁？”是替代问题。
“我指的是实体之一的表情。”</sample>
    <sample id="455">这是您要的翻译：
目标语言：中文
翻译结果：数据集收集方法
• 方法强调使用卡通补全任务来强调非正式性
确定对话上下文
（从域中选择的几个手动提示之一）
选择域中的几个手动提示中的一个
表达指向实体中的一个</sample>
    <sample id="456">目标语言：中文
翻译结果：数据集收集方法
方法强调使用卡通补全任务的非正式性。
设置对话上下文（从领域的几个手动编写提示中选择）
选择领域的替代问题（手动编写）
表达指向实体之一</sample>
    <sample id="457">目标语言：中文
翻译结果：• 方法强调非正式性，使用卡通完成任务

设置对话上下文（从每个领域的几个手动提示中选择）
非正式问题
表达之一（引用实体之一）</sample>
    <sample id="458">这是您要问A还是B吗？</sample>
    <sample id="459">已将文本内容翻译为中文：
产生替代问题 =&gt; 采样实体对</sample>
    <sample id="460">以下是您要翻译的文本：
- 目标语言：中文
- 翻译文本：生成其他问题 → 抽样实体对
你是指 A 还是 B？
维基百科上具有类似信息框的项目（相同类型或艺术家）
你是指《我是...》还是《在镜子中的人》吗？
维基百科上具有类似描述的项目
你是指《想起你》还是《任何地方都快乐》吗？
具有相似标题的项目：
你是指《回归（阿特马克）》还是《回归（沙托小说）》吗？
随机均匀：
你是指《你可能属于我》还是《我是谁》吗？</sample>
    <sample id="461">翻译后的结果如下：
- 目标语言：中文
- 内容：A和B哪个是你想了解的？
- 文中提到的'相似的infoboxes'、'相似的描述'和'相似的名称'被翻译为：
    - 带有相似的infoboxes的项目（来自维基百科，相同的流派和/或艺术家）
    - 带有相似的描述的项目（来自维基百科）
    - 名称相似的项目：
    - 随机均匀：
- 这部分被翻译为：
    - “物品具有相似的infoboxes（维基百科，相同的流派和/或艺术家）：”
    - “物品具有相似的维基百科描述：”
    - “相似的标题项目：”</sample>
    <sample id="462">翻译结果：
- 语言：中文
- 内容：您指的是A还是B？
您是指《这是》还是《镜中人》吗？
您是指《想着你》还是《任何地方都很快乐》吗？
您是指《回归》（伊明小说）还是《回归》（科幻小说）吗？
您是指《你能是我的吗》还是《我是谁》吗？</sample>
    <sample id="463">根据视频内容，以下是时间戳和对应的字幕及翻译：

(0:04-0:11)
字幕：Background knowledge (Music)
翻译：背景知识（音乐）

(0:14-0:51)
字幕：We ask annotators to listen to at least some of each song
翻译：我们要求标注者至少听一首歌

(0:57-1:48)
字幕：We ask annotators to read about each song
翻译：我们要求标注者阅读每首歌的相关信息

(1:52-2:22)
字幕：Our annotators are also allowed to freely browse for any additional relevant information
翻译：我们的标注者也可以自由浏览任何相关资料

(2:25-2:44)
字幕：about these songs on the internet (such as lyrics)
翻译：关于这些歌的互联网信息（如歌词）

分析与描述：
这段视频从多个方面介绍了标注者在评估过程中所需的背景音乐知识。首先，标题“背景知识（音乐）”表明视频将讲解标注者在音乐评估中的音乐背景知识。接下来的几个画面详细说明了标注者所需采取的具体行动。

第一部分（0:04-0:11）的字幕“Background knowledge (Music)”表示视频的核心内容。接下来，0:14到0:51的字幕“我们要求标注者至少听一首歌”解释了标注者必须了解音乐的基本要求，即至少听一部分歌曲以便于理解音乐内容。视频的中间部分（0:57-1:48）进一步阐述“我们要求标注者阅读每首歌的相关信息”，强调了除了听音乐外，了解背景信息的重要性。

在视频的最后一部分（1:52-2:44），提到“我们的标注者也可以自由地浏览任何相关资料，包括互联网上的信息（如歌词）” 以便标注者能充分利用网络资源，获得更全面的了解，为评估提供更准确的数据。

视频通过分点详细说明，让标注者明确必须采取的具体行动，这对保证音乐评估的准确性和全面性是至关重要的。特别是，标注者不仅需要听歌，还需阅读和查阅相关信息，这提升了标注的客观性，使得最终的数据更加可靠。

通过这些步骤，视频有效地传达了标注者在进行音乐评估时所需做的准备工作，强调了背景信息对评估质量的影响。</sample>
    <sample id="464">文本翻译已从英文翻译为中文：
背景知识（音乐）
为每首歌曲提供谷歌搜索链接。
请求注释者
- 至少听其中一首歌曲
- 阅读每首歌曲的内容</sample>
    <sample id="465">这是您要的翻译：
目标语言：中文
翻译结果：背景知识（音乐）。
- 每首歌曲的Google搜索链接。
- 我们要求标注者：
  听至少一首歌曲。
  阅读每首歌曲的相关信息。
易相处（阿黛儿版）。
我感觉不错（黑眼豆豆版）。</sample>
    <sample id="466">翻译后的结果如下：
- 目标语言：中文
- 内容：焦糖蛋糕是英国、爱尔兰和其他与这些国家移民模式相关的国家广泛食用的一种小圆蛋糕，与大斋期和复活节有关。它以杏仁酱或马斯巴纳的层次，以及用相同酱料制成的十一颗球为特色。
班兰蛋糕是一种轻盈、蓬松、绿色的海绵蛋糕，加有班兰（Pandanus amaryllifolius）叶子的汁液。这种蛋糕在印度尼西亚、马来西亚也很受欢迎，在荷兰，尤其是印度社区中也很受欢迎。</sample>
    <sample id="467">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：我们还告诉标注者应该选择哪个选项，并要求他们对其进行描述。</sample>
    <sample id="468">翻译后的结果如下：
- 目标语言：中文
- 内容：随机示例
音乐选择
书籍选择
食谱选择</sample>
    <sample id="469">文本已翻译为中文，结果如下：
- 6000个跨三个领域的替代问题
- 42000个间接引用表达式

使用T5 XL模型的准确率：
- 如果LM具有与注释者相同的背景知识，则准确率在92-95%之间。
- 当LM具有部分重叠的背景知识时，准确率在82-87%之间。
- 只有LM（T5 XL）具有实体名称的访问权限时，准确率约为60%。

我们显示模型是跨域通用的。

数据集链接：https://github.com/google-research-datasets/AltEntities</sample>
    <sample id="470">这是您要的翻译：
目标语言：中文
翻译结果：6,000个跨三个领域的替代问题
42,000个间接指代表达

使用TS X5L模型的准确性：

- 92%-95%，如果大语言模型具有与标注者相同的背景知识
- 82%-87%，当大语言模型具有部分重叠的背景知识时
- 大约60%，当大语言模型（TS X5L）仅具有实体名称的访问权限

我们展示了模型在不同领域中的泛化能力。</sample>
    <sample id="471">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：- 使用TS X4L模型（准确度）：如果LM拥有与注释者相同的背景知识，则准确率为92-95%。
- 当LM仅能访问实体名称时，准确率为60-60%。
- 我们证明了模型具有领域可移植性。</sample>
    <sample id="472">文本已翻译为中文，结果如下：
感谢！
如果您有任何问题，请发送电子邮件至javadh@google.com</sample>
    <sample id="473">该方法与wait-k，LA，CAAT和EDAUT现有SimulST策略进行了比较，如图所示。</sample>
    <sample id="474">这篇论文的作者来自多所机构，包括AVIGNON大学、Nantes大学、CHU HAITANS的Clinique des Domes临床中心和初创公司Zendoc。相关标志可见于幻灯片上。</sample>
    <sample id="475">视频中的演讲者名叫Jenny T. Liang。</sample>
    <sample id="476">这篇论文有三位作者，名字列在幻灯片上。</sample>
    <sample id="477">已将文本内容翻译为中文：
作为同时口译的注意力指南</sample>
    <sample id="478">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：当你有一个炎热的水壶</sample>
    <sample id="479">这是您要的翻译：
目标语言：中文
翻译结果：目前SimulST模型的问题是什么？
通常训练特定架构，引入额外模块进行优化</sample>
    <sample id="480">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：当前SimulST模型的问题是什么？
通常训练特定架构，引入额外模块进行优化
漫长的复杂训练过程（例如，不同的优化目标）</sample>
    <sample id="481">翻译内容如下（目标语言：中文）：
当前仿生ST模型的问题是什么？\n通常训练特定架构，引入额外的模块以进行优化\n漫长的复杂训练程序（例如，不同的优化目标）\n训练和维护多个模型以达到不同的延迟阶段（例如，1s, 25s，...）</sample>
    <sample id="482">翻译完成：目标语言是中文，对应的文本为：我们的解决方案是什么？。</sample>
    <sample id="483">以下是您提供的文本的翻译内容：
- 目标语言：中文
- 翻译文本：我们的解决方案是什么？
1. 使用现有的离线翻译模型，无需重新训练或为SimuIST调整特定架构。
2. 使用单一模型处理每个延迟阶段，并通过特定参数处理延迟。</sample>
    <sample id="484">翻译内容如下：
我们提出了什么解决方案？
1. 在不进行训练或为SimuST架构采用特定架构的情况下，使用现有的离线ST模型
2. 使用单个模型处理所有延迟范围并通过特定参数处理延迟
3. 通过音频输入和文本输出之间的注意力机制利用模型已经获得的知识</sample>
    <sample id="485">已将文本内容翻译为中文：
我们的解决方案：EDAtt
编码器-解码器注意力
根据注意力点判断是否输出未完成的翻译：
如果注意力不集中在单词上（其和低于阈值α（alpha））指向最后K个语音帧，表示接收到的信息足够稳定。</sample>
    <sample id="486">文本已翻译为中文，结果如下：
我们的解决方案：EDAtt
编码器-解码器注意力
根据注意力指向何处决定是否发出不完整的翻译为一个词：（其总和低于阈值alpha）指向最后的lambda语音帧，这意味着接收到的信息足够稳定。</sample>
    <sample id="487">文本已翻译为中文，结果如下：
我们的解决方案：
EDAtt
编码器-解码器注意力
决定是否发出或不发出部分翻译，基于注意力指向：
如果注意力不集中在
其总和低于阈值（alpha），则会向最后X个语音帧发出一个单词，这意味着接收到的信息已经足够稳定。
我将谈论...</sample>
    <sample id="488">目标语言：中文
对应的翻译是：我会谈论。
我将会谈论。</sample>
    <sample id="489">目标语言：中文
翻译结果：我们的解决方案：EDAtt
编码器-解码器注意力

决定是否发出或不发出部分翻译，基于注意力指向在哪里：
如果注意力不集中在一个词上，这个词可以被发出（其总和低于阈值 \(\alpha\) 向最后一个 \(\lambda\) 音频帧的方向），这意味着接收到的信息足够稳定。</sample>
    <sample id="490">这是您要的翻译：
目标语言：中文
翻译结果：一个编码器-解码器注意力的解决方案
决定是否发出部分翻译，基于注意力指向：
（其和低于阈值\alpha）指向最后N个语音帧，意味着接收到的信息足够稳定。</sample>
    <sample id="491">翻译内容如下：
- 目标语言：中文
- 翻译文本：我们的解决方案：
EDAtt
编码器-解码器注意
1
我将谈论......
- sum(注意) &gt;= α
发出</sample>
    <sample id="492">翻译内容如下：
- 目标语言：中文
- 翻译文本：我会谈论气候变化。</sample>
    <sample id="493">翻译结果：
- 语言：中文
- 内容：我现在要讨论...
我现在要讨论气候。</sample>
    <sample id="494">目标语言：中文
翻译结果：我会谈论气候。</sample>
    <sample id="495">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：平均错误率为零。</sample>
    <sample id="496">目标语言：中文
翻译结果：延迟度量</sample>
    <sample id="497">翻译内容如下（目标语言：中文）：
主要结果：EDAtt</sample>
    <sample id="498">已将文本内容翻译为中文：
主要结果：
EDAtt

（a）en-de

AL/AL_CA6</sample>
    <sample id="499">翻译结果：
- 语言：中文
- 内容：26 位和 25 位之间的分数差是多少？</sample>
    <sample id="500">这是您要的翻译：
目标语言：中文
翻译结果：主要结果：
EDAtt
流行的策略也应用于模拟
等待k-LA
CAAT
EDA
BLEU
-10-
033</sample>
    <sample id="501">翻译内容如下：
- 目前我们看到的图表是关于这个东西的，我们实际上在上面有一个图例，因此我们正在观察BLEU分数。</sample>
    <sample id="502">翻译完成：目标语言是中文，对应的文本为：EDAtt
EDAtt
EDAtt
EDAtt
EDAtt超出了所有应用于离线模型的策略。</sample>
    <sample id="503">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：主结果：EDAtt
EDAtt是比所有其他策略更快的策略，如果我们考虑实际经过的时间。</sample>
    <sample id="504">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：您想了解更多吗？
读我们的论文以发现更多结果！</sample>
    <sample id="505">是的，视频中的文字显示数据集是公开的。</sample>
    <sample id="506">目标语言：中文
翻译结果：MULTIINSTRUCT：通过指令调优改进多模态零样本学习</sample>
    <sample id="507">已将文本内容翻译为中文：
下游任务中的预训练语言模型

（A）预训练 - 微调（BERT，T5）
- 通常需要为每个任务提供许多领域特定的示例

（B）提示工程（GPT-3）
- 通过少量示例射击或提示工程来提高性能

（C）指令微调（FLAN）
- 模型通过指令A、B、C、D、E进行学习
- 推理任务A上的未知任务</sample>
    <sample id="508">这是您要的翻译：
目标语言：中文
翻译结果：预训练语言模型用于下游任务

（A）预训练-微调（BERT，T5）
预训练的语言模型在任务A上进行微调
然后在任务A上进行推理

（B）提示（GPT-3）
预训练的语言模型
使用少量射击或提示工程
然后在任务上进行推理

（C）指令微调（FLAN）
预训练的语言模型
在任务B、C、D、E上进行指令微调
然后在任务A上进行推理

比较指令微调、预训练微调和提示。

图片来源：Jason 等人，《微调语言模型是零样本学习者》。</sample>
    <sample id="509">这是字幕的中文翻译：

视频只涉及语言。
您只需要语言模型。</sample>
    <sample id="510">文本已翻译为中文，结果如下：
在多模态预训练模型上的指令微调</sample>
    <sample id="511">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：NLP中指令集与多模态之间的不平衡</sample>
    <sample id="512">这是您要的翻译：
目标语言：中文
翻译结果：在NLP和多模态之间，教学数据集的不平衡。
“1600多个仅语言的教学任务”。
“没有大规模、公开可用的多模态教学任务。”</sample>
    <sample id="513">下面是转录的内容：

**正在加载视频**
加载指示器显示文本“正在加载...”</sample>
    <sample id="514">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：多模态指令微调基准数据集</sample>
    <sample id="515">翻译完成：目标语言是中文，对应的文本为：OFA（一物多用）是一个统一的多模态预训练模型，能够同时执行理解和生成任务，单模或多模态。OFA对语言、图像标记和边界框坐标具有统一的词汇。。</sample>
    <sample id="516">这是您要的翻译：
目标 1</sample>
    <sample id="517">这是您要的翻译：
目标：生成一个标题用于这些图像。
输出：黑白色的钓鱼小屋。
输入：选择包含文本'A5'的区域。
输出：&lt;s&gt; &lt;span&gt;279 - &lt;span&gt;606.
输入：选择由'A5'标记的这个物体的区域，位于前面。
输出：&lt;span&gt;242 - &lt;span&gt;180 &lt;span&gt;420.
输入：给定内容图像，确定问题是否是回答信息相关的。是图像相关，还是不相关的？
输出：这个问题是图像不相关的。</sample>
    <sample id="518">目标是使用这些数据点进行语言模型的微调。在这个过程中，Mengyan将向我们展示如何构建这样的数据集。我们将以Multimodal Instruct数据集为例，因为这是一个非常复杂的任务，涉及到复杂的多模态指令。他们已经创建了一些任务，这些任务涉及对图像进行注释，因此在这些注释中会有一些不同的操作。例如，这个数据集中包含了如下的操作：</sample>
    <sample id="519">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：多模态指令微调</sample>
    <sample id="520">这是您要的翻译：
目标语言：中文
翻译结果：多模态指令调整

训练数据集构建：

- 使用9组中的53个任务进行训练。
- 每个任务采样10,000个实例。

测试数据集构建：

- 保留整个常识和推理组用于测试。
- 从VQA和杂项组中选择另外5个任务。
- 我们使用每个任务的测试分割中的所有实例。
- 随机从NLP的自然指令数据集中的测试分割选择20个任务作为未见过的任务。</sample>
    <sample id="521">翻译完成：目标语言是中文，对应的文本为：多模态指令微调
训练数据集构建：
• 使用9组中的53个任务进行训练。
• 每个任务抽样10,000个实例。
测试数据集构建：
• 将常识和推理组的全部保留用于测试。
• 从VQA和杂项组中选择另外5个任务。
• 我们在每个任务的测试拆分中使用所有实例。
• 随机从自然指令数据集的测试拆分中选择20个任务作为NLP的未见任务。</sample>
    <sample id="522">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：测试细节。
对于我们每个任务，我们总共进行了五次实验，通过在每次实验中使用五个指令中的一个来评估模型。
我们报告了五个实验中的平均性能、最大性能和性能的标准偏差。</sample>
    <sample id="523">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：实现细节
- 训练细节：
  - 预训练的OFA大型模型（472M）
  - 将所有任务的实例混合在一起。
  - 每个实例与它的五个指令模板之一随机组合。
- 测试细节：
  - 对于每个任务，我们总共进行五次实验，每次实验中使用五个指令中的一个评估该模型。
  - 我们报告五个实验中性能的平均值和最大值，以及性能的标准偏差。</sample>
    <sample id="524">翻译内容如下：
实施细节
训练详情：
- 预训练的OFA-large大模型（472M）
- 混合所有任务的所有实例。
- 每个实例都与该模型的五个指令模板之一随机组合。
测试详情：
- 对于每个任务，我们用五个指令中的每一个进行五次实验。
- 我们报告在所有五次实验中的表现的均值和最大表现以及标准差。</sample>
    <sample id="525">这是您要的翻译：
目标语言：中文
翻译结果：评估指标
- 对于多模态分类任务（视觉蕴含、视觉空间推理、自然语言视觉推理和灾害类型分类），我们报告准确度。
- 对于多模态生成任务（常识VQA、文本VQA、有界VQA、视觉文本提取和视觉对话），我们报告Rouge-L。
- 对于NLP任务，我们报告Rouge-L。
我们还根据模型在所有多模态和NLP未见任务上的性能均值，计算每个模型的综合性能。我们使用Rouge-L作为大多数任务的性能分数，以及仅将准确度作为度量的任务。</sample>
    <sample id="526">这是您要的翻译：
目标语言：中文
翻译结果：敏感性
模型对同一任务的各种指令的敏感性：
- 无论指令措辞上有微小变化，都能始终如一地产生相同任务的结果的能力。</sample>
    <sample id="527">根据您提供的信息，文本没有需要纠正的错误。</sample>
    <sample id="528">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：多模态常识推理的表现
零样本
多模态常识推理问答和杂项

多模态常识推理</sample>
    <sample id="529">翻译结果：
- 语言：中文
- 内容：随着模态指令任务簇的增加，模型性能的变化情况。
图像未定义
VQA - 图像理解
grounding
grounded matching + grounded generation
MISC, ITM -
时序排序 + 杂项 + 图像文本匹配
关系
视觉关系
区域
区域理解
NLP
NLP任务</sample>
    <sample id="530">翻译完成：目标语言是中文，对应的文本为：多样化指令在指令微调中的效果
- 基于5个指令进行微调的OFA在所有评估任务中实现了更高的综合性能，并表现出较低的敏感性。</sample>
    <sample id="531">这是您要的翻译：
目标语言：中文
翻译结果：微调策略对模型敏感性的影响

• 在Multiniush上进行的指令微调可以显著降低OFA的敏感性。
• 从Natural Instructions数据集中转移学习可以进一步降低模型的敏感性。</sample>
    <sample id="532">这是您要的翻译：
目标语言：中文
翻译结果：无监督的自然语言处理任务性能
- 对Multitask进行指令调优可以提高对看不见的NLP任务的零样本性能。
- 来自NATINST的迁移学习策略Mixedlnstruct可以最好地保留在NATINST数据集上获得的零样本能力。</sample>
    <sample id="533">已经翻译完成：字幕已从英文翻译成中文。</sample>
    <sample id="534">这是您提供的文本翻译结果：</sample>
    <sample id="535">这篇论文的作者分别与特伦托大学和Bruno Kessler基金会相关联。这些机构的标志在幻灯片上展示。</sample>
    <sample id="536">在视频中，演讲者的名字是Mohammad Javad Hosseini。</sample>
    <sample id="562">翻译完成：目标语言是中文，对应的文本为：语言模型的可接受性判断并不总是对上下文具有鲁棒性。</sample>
    <sample id="563">翻译后的结果如下：
- 目标语言：中文
- 内容：语言模型的可接受性判断并不总是上下文稳健</sample>
    <sample id="564">这是您要的翻译：
目标语言：中文
对应的翻译文本：最小对范例重新审视
最小对范例（MIP）用于评估语言模型在序列概率的相对差异上抽象知识的方法：
BLiMP  SyntaxGym  CrowS
1. 许多人在帮助他们自己。
2. 许多人在帮助她自己。
P(1) &gt; P(2)

1. 没有顾客...任何钱。
2. 顾客...任何钱。
P(custom) &gt; P(no custom)
P(1) &gt; P(2)

1. 刻板印象句子。
2. 非刻板印象句子。
P(1) &gt; P(2)</sample>
    <sample id="565">目标语言：中文
翻译结果：重新审视最小对范式

语言模型的最小对范式（MPP）评估利用相对序列概率差异来评估LM的抽象知识：

BLiMP
- 许多人在互相帮助自己。
- 许多人在帮助自己。

语法健身房
- 没有顾客花费了任何钱。
- 顾客花费了任何钱。

乌鸦S
- 典型的句子。
- 非典型的句子。</sample>
    <sample id="566">翻译后的结果如下：
- 目标语言：中文
- 内容：有限对范式（MPP）评估语言模型使用序列概率的相对差异来评估LM的抽象知识：</sample>
    <sample id="567">文本已翻译为中文，结果如下：
重新审视最小对范式
最小对范式（MPP）评估使用相对序列概率差异来评估语言模型的抽象知识：</sample>
    <sample id="568">翻译结果：
- 语言：中文
- 内容：重新审视最小对偶范式
最小对偶测试使用序列概率的相对差异来评估语言模型的抽象知识：
BLiMP
许多人在帮助自己。
许多人正在帮助她。
P (1) &gt; P (2)
SyntaxGym
1. 没有顾客花费了任何钱。
2. 那个家伙花了任何钱。
P (1|any) &gt; P (2|any)
CrowS
1. 女人很糟糕的家务。
2. 男人在作业上很糟糕。
P (1) &gt; P (2)
这些判断在长前置上下文中是否稳定？</sample>
    <sample id="569">目标语言：中文
翻译结果：1. 许多人在互相帮助。
2. 许多人在帮助她自己。
1. 没有客户花了任何钱。
2. “客户...从未花过一分钱。
1. 女人非常糟糕。
2. 男人非常糟糕，
在家庭作业上。

P（1）&gt; P（2）
P（1）&gt; P（2）
P（1）&gt; P（2）

问题：这些判断在长时间前置上下文的情况下稳定吗？</sample>
    <sample id="570">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：重新审视最小对范式

最小对范式（MIP）评估利用序列概率的差异来评估语言模型的抽象知识：
BLiMP
1. 许多人正在帮助
“他们自己。”
2. 许多人正在帮助自己。”
P（1）&gt; P（2）

SyntaxGym
1. 没有顾客……花了一分钱。”
2. “顾客……没有出一分钱。”
P（1）（any）&gt; P（2）（any）

CrowS
1. 女人很糟糕
“在家务活。”
2. 男人很糟糕
“在作业。”
P（1）&gt; P（2）

这些问题判断在长期上下文中是否稳定？</sample>
    <sample id="571">这是您要的翻译：
目标语言：中文
翻译结果：方法
测试 MPP 判断是否随上下文长度、结构匹配和可接受性而变化。</sample>
    <sample id="572">目标是探索使用生成式预训练模型（如GPT-2、OPT家族从125M到6.7B参数）评估语言生成任务的性能。研究将重点关注上下文、结构匹配和可接受性对模型判断的影响。</sample>
    <sample id="573">目标是测试多模态感知（MPP）的判断是否取决于语境长度、结构匹配和可接受性。</sample>
    <sample id="574">翻译后的结果如下：
- 目标语言：中文
- 内容：方法
检验MPP判断是否随上下文长度、结构匹配和可接受性而变化

可接受性
测试状态主体间重叠
不匹配
示例
空间
可接受方法
可接受
样本
匹配
标记
空间方法

BLIP - 调整障碍</sample>
    <sample id="575">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：测试MPP判断是否会因上下文长度、结构匹配和可接受性而变化。</sample>
    <sample id="576">翻译结果：
- 目标语言：中文
- 内容：测试模型在上下文长度、结构匹配和可接受性方面的判断是否不同。

可接受
不可接受</sample>
    <sample id="577">翻译结果：
- 语言：中文
- 内容：评估MPP判断是否随上下文长度、结构匹配和接受度的变化而变化。
可接受的匹配：
何时让客户在用餐前看罗素的纪录片？→
接受的不匹配：
何时让客户在用餐前看罗素的纪录片？→
不可接受的不匹配：
何时让客户在用餐前看罗素的纪录片？→</sample>
    <sample id="578">翻译内容如下：
（方法）
测试MPP判断是否随上下文长度、结构匹配和可接受性而变化

测试语料库中主观不一致的样本
[可接受的概率（前缀） &gt; 概率（前缀）？] 不可接受
例如
维尔瓦市 未列出
何时罗斯·福特会在点球大战中变成这个顾客的顾客？
- 从顾客的角度来看，罗斯·福特可能会在点球大战中成为这个顾客的顾客之前成为威尔瓦？

GPT2，OFT家族 125M到6.7B</sample>
    <sample id="579">目标语言：中文
翻译结果：测试MPP判断是否随上下文长度、结构匹配和可接受性而变化。
测试套件：主体与附加同意。
可接受的前缀 &gt; 不可接受的前缀</sample>
    <sample id="580">文本已翻译为中文，结果如下：
方法
测试 MPP 判断是否随上下文长度、结构匹配和可接受性而变化。
测试主体 - 标题一致性
威尔斯和无限
GPT、OPT 家族从 125M 到 6.7B</sample>
    <sample id="581">目标语言：中文
翻译结果：MPP判断对任意上下文长度具有鲁棒性。</sample>
    <sample id="582">翻译结果：
- 语言：中文
- 内容：MPP判决对任意上下文长度具有鲁棒性</sample>
    <sample id="583">已将文本内容翻译为中文：
句法策略的性能取决于可接受/不可接受MPP句子的上下文中的提升/降低判断。我们对不同上下文的MPP评估进行了评估——可接受/不可接受；匹配/不匹配的结构——长度可达900个令牌。</sample>
    <sample id="584">已将文本内容翻译为中文：
在提升/降低判断表现中的可接受/不可接受的MPP句子\n\n我们对不同上下文（可接受/不可接受；结构匹配/不匹配）的MPP评估进行至多900个标记长度的评估。\n\nBLMPP：OPT 6.7B</sample>
    <sample id="585">翻译完成：目标语言是中文，对应的文本为：可接受/不可接受MPP语句在上下文提升/降低判断中的表现
我们进行了不同上下文的MPP评估 - 可接受/不可接受；匹配/不匹配的结构 - 最长可达900个令牌。</sample>
    <sample id="586">翻译结果：
- 语言：中文
- 内容：可接受/不可接受的MPP句子，具有一致结构，对模型性能影响最大
我们对不同上下文的MPP进行了评估——可接受/不可接受；一致/不一致结构；长度可达900个令牌。</sample>
    <sample id="587">翻译后的结果如下：
- 目标语言：中文
- 内容：可接受/不可接受的MPP句子，结构匹配对模型性能影响最大。我们使用不同的上下文对MPP进行评估：可接受/不可接受；匹配/不匹配的结构，长度可达900个令牌。</sample>
    <sample id="588">目标语言：中文
翻译结果：可接受/不可接受的MPP句子具有相同的结构，最严重影响模型性能。

我们对不同上下文中的MPP进行评估——可接受的/不可接受的；匹配/不匹配的结构——长度最长可达900个令牌。</sample>
    <sample id="589">目标语言：中文
翻译结果：为什么匹配的前缀会影响LM判断？
我们扰动上下文句子，保留相关结构，并询问模型是否对这些句子有类似的敏感性。
- 前缀/后缀副词："然而，"
- 长前缀副词："首先和最重要的是，"
- 添加从句： "不管X认为它什么，... "
- 引用："昨天，X说。"</sample>
    <sample id="590">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：为什么匹配的前缀会影响LM评判？
我们以保持相关结构的方式干扰上下文句子，并询问模型是否对这些句子有相似的敏感性。</sample>
    <sample id="591">翻译内容如下（目标语言：中文）：
匹配前缀为什么会影响LM判断？
我们通过保持相关结构的方式扰动上下文句子，并询问这些句子是否让模型同样敏感。

前缀/后缀副词："然而，&lt;sent&gt;。"
长前缀副词："首先，&lt;sent&gt;。"
添加从句："无论X认为它如何，&lt;sent&gt;。"
引述："昨天，X说"&lt;sent&gt;"。"</sample>
    <sample id="592">翻译完成：目标语言是中文，对应的文本为：匹配前缀为何会影响LM判断？ 我们通过保留相关结构的方式对上下文句子进行扰动，然后询问模型是否同样敏感于这些句子。 前缀/后缀扰动："然而，句子"。 长前缀扰动： "首先和最后，句子"。 添加从句："无论X认为什么"。 引用："昨天，X说"。 模型对扰动句子的敏感性相似。。</sample>
    <sample id="593">目标语言：中文
翻译结果：为什么匹配的前缀会影响语言模型的判断？
我们以保持相关结构的方式扰乱上下文句子，并询问模型是否对这些句子有类似的敏感性。
前缀/后缀修饰符："然而，\n长前缀修饰符：\n"首先和最重要的是，\n添加短语：\n"不管X认为什么，\n引号：\n'昨天，X说，\n模型对扰乱的句子有相似的敏感性。</sample>
    <sample id="594">翻译后的结果如下：
- 目标语言：中文
- 对应的翻译文本：关键要点：
- 语言模型对跨句子共享的潜在句法/语义特征很敏感。
- 使用短、单句输入的MPP评估不能充分捕捉LM的抽象知识。</sample>
    <sample id="595">翻译内容如下（目标语言：中文）：
关键要点：
- 语言模型对跨越句子共享的潜在语法/语义特征敏感。
- 具有短语、单句输入的MPP评估无法完全捕捉LMS的抽象知识。</sample>
    <sample id="596">翻译完成：目标语言是中文，对应的文本为：关键要点
• 语言模型对句子间共享的潜在句法/语义特征敏感。
• 基于短句输入的MPP评估并不能完全捕捉到LMs的抽象知识。。</sample>
    <sample id="597">该方法的第一步将输入词元映射到概念词元，如第一层中的星星表示。</sample>
    <sample id="598">Coscript Dataset 中包含 55,000 个脚本。</sample>
    <sample id="626">在 DEplain 中，最佳对齐方法是 LHA（Hierarchical alignment using sentence embeddings similarity），因为它在 1:1 上的指标（Precision, Recall, F1-score）中数值最高。</sample>
    <sample id="627">弱监督学习的好处之一是它能够缓解标注瓶颈（annotation bottleneck）。这意味着在标注数据较难或较耗时的情况下，使用弱监督学习可以更有效地利用现有的弱监督源，比如启发式方法或知识库，来对大规模数据进行标注。此外，尽管弱标签可能会包含噪声，但由于弱监督学习的目标是训练出能够在噪声数据上良好泛化的模型，因此仍然可以提高学习效率。</sample>
    <sample id="628">在提及的上下文中，DEplain-web 中的文档有 15% 是手动对齐的，而剩下的 85% 是自动对齐的。</sample>
    <sample id="629">CoNLL++ 数据集是通过收集 Reuters 新闻文章并使用 CoNLL-2003 标注指南进行人工标注而创建的。</sample>
    <sample id="630">视频内容的翻译结果如下：
- 英文文本：XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations
- 中文翻译：XSemPLR：多自然语言和含义表征的跨语言语义解析</sample>
    <sample id="631">翻译内容如下：
- 标题：语义解析

语义解析是一个任务，用于构建用户查询的语义表示，如SQL和Lambda Calculus。

用户查询及其对应的SQL（左）或用户查询及其对应的Lambda Calculus（右）</sample>
    <sample id="632">字幕内容如下：
- 英文：Cross-lingual Semantic Parsing
- 中文：跨语言语义解析
- 英文：Cross-lingual Semantic Parsing is a task to translate queries in multiple natural languages into multiple meaning representations
- 中文：跨语言语义解析的任务是将多种自然语言的查询翻译成多种含义表示
- 英文：SQL
- 中文：SQL
- 英文：Lambda
- 中文：量词
- 英文：FunQL
- 中文：趣味查询语言</sample>
    <sample id="633">已将文本内容翻译为中文：
跨语言语义解析是一种将多国语言查询翻译为多种形式表示的任务。</sample>
    <sample id="634">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：跨语言语义解析
现有CLSP模型分别基于有限的任务和应用数据集提出和评估。例如：
- 某些自然语言缺乏覆盖</sample>
    <sample id="635">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：跨语言语义分析。现有CLSP模型分别在有限任务和应用的数据集上提出和评估。例如，某些自然语言覆盖不足。</sample>
    <sample id="636">翻译后的结果如下：
- 目标语言：中文
- 内容：跨语言语义解析。
- 现有的CLSP模型分别在有限任务和应用的数据集上提出和评估。例如：
  - 某些意义表示的覆盖不足。</sample>
    <sample id="637">目标语言：中文
翻译结果：跨语言语义解析
现有CLSP模型是分别在有限任务和应用的数据集上提出的和评估的。例如：
○ 某些含义表示的覆盖率不足

现有的CLSP模型是分别在有限任务和应用的数据集上提出的和评估的。例如：
○ 某些神经模型的覆盖率不足</sample>
    <sample id="638">翻译内容如下：
（无翻译内容，因为提供的文本已经是中文。）</sample>
    <sample id="639">翻译内容如下：
我们提供了一个统一的数据集XSemPLR，用于多种自然语言和意义表示中的跨语言语义解析。其中包括：
• 9个不同领域的数据集
• 5个语义解析任务。
• 8种意义表示
• 22种自然语言，属于15种语言家族

谁在飞越太平洋的飞机上玩扑克？ 我们使用汉诺威航空公司飞往柏林的飞机上的扑克。
Calculating &lt; | &gt; 58479389 / &lt; | &gt; 638907 / &lt; | &gt;  (计算 58479389 / 638907 )</sample>
    <sample id="640">翻译完成：目标语言是中文，对应的文本为：我们提供了一个统一的数据集XSemPLR，用于多种自然语言和意思表示的跨语言语义解析。它包含：
  - 各个领域的9个数据集
  - 5个语义解析任务。
  - 8种意思表示
  - 22种自然语言，覆盖15个语系。</sample>
    <sample id="641">这是您要的翻译：
目标语言：zh
翻译结果：实验设置
我们考虑六种训练和评估的设置。
- 翻译测试：使用Google翻译API将源语言翻译为目标语言。然后使用单语模型进行训练和评估。

训练

英语
英语模型
SQL

推理

德语
翻译API
英语
英语模型
SQL</sample>
    <sample id="642">目标语言。然后使用单语模型进行训练和评估。” 接下来是两个流程图，分别描述了“训练”和“推理”的过程。流程图中，训练过程从“英语”输入开始，通过“英语模型”转换为“SQL”；推理过程则从“德语”输入开始，通过“翻译API”转换为“英语”，再通过“英语模型”转换为“SQL”。</sample>
    <sample id="643">翻译结果：
- 语言：中文
- 内容：实验设置
我们考虑了训练和评估的六种设置。
"Translate-Test" 使用谷歌翻译API将源语言翻译为目标语言。然后使用单语模型进行训练和评估。</sample>
    <sample id="644">以下是您要翻译的内容：
- 目标语言：中文
- 翻译文本：实验设置
我们考虑了六个训练和评估的设置。
- 单语模型。源语言与目标语言相同，例如德语到德语。我们也通过仅用10%的训练数据训练单语模型来测试单语少样本设置。</sample>
    <sample id="645">目标语言相同的单语模型。例如，德语到德语。我们还测试单语的少量射击设置，通过只用10%的训练数据训练单语模型。</sample>
    <sample id="646">已将文本内容翻译为中文：
实验设置
• 我们考虑了六种训练和评估设置。
• 单语模型。源语言与目标语言相同，例如德语到德语。我们也测试单语模型的Few-shot设置，通过仅使用10%的训练数据来训练单语模型。

培训

推断</sample>
    <sample id="647">翻译结果：
- 语言：中文
- 内容：实验设置
我们考虑了六个训练和评估的设置。
- 多语模型。为所有语言训练一个多语言模型。

培训
德语
英语
中文
多语言模型
SQL

推理
德语
多语言模型
SQL</sample>
    <sample id="648">翻译结果：
- 语言：中文
- 内容：实验设置
我们考虑了六个训练和评估的设置。
多语言模型：为所有语言训练一个多语言模型。

训练
德语英语汉语
多语言模型&gt; SQL

推理
德语
多语言模型&gt; SQL</sample>
    <sample id="649">这是您要的翻译：
目标语言：中文
翻译结果：实验设置
为了训练和评估，我们考虑了六种设置。
多语言模型。为所有语言训练一个统一的模型。
训练
德语
英语
汉语
多语言模型
&gt; SQL
推理
德语
&gt; 多语言模型
&gt; SQL
编号：10</sample>
    <sample id="650">翻译内容如下（目标语言：中文）：
实验设置
我们考虑了六种训练和评估设置。
跨语言零样本/少量样本转移。在一种语言上训练，并转移到另一种语言。
训练</sample>
    <sample id="651">翻译结果：
- 语言：中文
- 内容：我们将考虑六种训练和评估设置。
  - 跨语言零样本/少量迁移。在一种来源语言上训练并转移到另一种语言。</sample>
    <sample id="652">翻译完成：目标语言是中文，对应的文本为：`分析单语。`</sample>
    <sample id="653">这是您要的翻译：
目标语言：中文
翻译结果：我们在两种模型组上进行了评估，这些模型组是在单语环境下构建的。
使用指针解码的多语言预训练编码器：XLM-R + PTR，mBERT + PTR。
多语言预训练编码器-解码器模型：mBART，mT5。
我们发现，mT5（即编码器-解码器）在所有数据集上都取得了最佳表现！</sample>
    <sample id="654">翻译结果：
- 语言：中文
- 内容：【在单语环境下进行分析】</sample>
    <sample id="655">已将文本内容翻译为中文：
单语环境分析
    我们在两类模型上进行了评估
        指针解码器的多语言预训练编码器
        指针解码器的多语言编码器-解码器模型
    我们发现Enc-Dec（mT5）在所有数据集中表现出色！</sample>
    <sample id="656">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：对mT5和XL-MR + PTr在多语言设置下的评估。通过在多种语言混合中进行训练，可以提高Enc-Dec/Enc-PTR（mT5/XL-MR）。</sample>
    <sample id="657">这是您要的翻译：
目标语言：中文
翻译结果：多语言训练的分析
我们对mt5和XLM-R + P-TOP在多语言设置中进行了评估
在多种语言的混合中训练可以改进Enc-Dec/Enc-PTR（mt5/XLM-R）。</sample>
    <sample id="658">目标语言：以下是翻译内容：
- 目标语言：中文
- 翻译文本：评估mT5和XML-R + PTR在多语言环境中的表现
大多数主要的自然语言都能获得性能提升，但英语在7个数据集中下降，在3个数据集中上升。这被称为'多语言诅咒'。</sample>
    <sample id="659">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：我们评估了 mT5 和 XLMR+P-TRON 的多语言设置。
大多数主要自然语言都能获得性能提升，除了英语在 7 个数据集中的性能下降，在 3 个数据集中有提升。这被称为“多语言诅咒”。</sample>
    <sample id="660">翻译结果：
- 语言：中文
- 内容：跨语言性能差距
- 蓝线：跨语言少样本传输
- 橙线：跨语言零样本传输
- 绿线：单语言设置</sample>
    <sample id="661">翻译后的结果如下：
- 目标语言：中文
- 内容：跨语言性能差距
  - 蓝线：跨语言少样本传输
  - 橙线：跨语言零样本传输
  - 绿线：单语言设置</sample>
    <sample id="662">翻译完成：目标语言是中文，对应的文本为：跨语言性能差距
·绿色 - 橙色 对于零样本设置，跨语言传输性能差异显著
·蓝色 - 橙色 对于小样本设置，传输差距迅速缩短。</sample>
    <sample id="663">目标语言的零样本表现显著提高。
• 多语言大语言模型（Codex和BLOOM）仍然不足以处理跨语言语义解析任务。
• 英文单语训练到中文转移学习具有最大的性能差距，而德语通常具有最小的差距。
• FunQL的表现优于其他三个意义表示，而SQL的表现最差。</sample>
    <sample id="664">这是您要的翻译：
目标语言的低资源表现：
汉语、波兰语和德语均显示出低资源表现。例如，波兰语的EM平均值低于0.5。然而，仅用英语作为预训练数据，并非所有低资源表现都能改善。</sample>
    <sample id="665">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：结论
我们构建了XSemPLR，这是一个统一的跨语言语义解析基准，涉及多种自然语言和意义表示。
我们在三种具有代表性的多语言语言模型上进行了全面的基准测试。
我们的结果显示，mt5的单语训练表现最佳，而一些多语语言模型仍不足以执行跨语言语义解析任务。此外，单语训练和跨语言迁移学习之间的性能差距仍然显著。</sample>
    <sample id="666">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：链接
欢迎访问我们的论文和代码！
论文链接：https://arxiv.org/pdf/2306.04085.pdf
代码链接：https://github.com/psslunigroup/xsemplr</sample>
    <sample id="667">当前在水印技术方面的研究关注了不同的水印方法，如基于参数的水印、基于词法的水印、基于后门的水印和基于对抗性的水印。每种方法都有其特定的应用和局限性。基于参数的水印缺乏可迁移性，基于词法、后门和对抗性的水印无法应用于软件系统（Eaas）。</sample>
    <sample id="668">不，Codex 或 Bloom 等多语言 LLM 对于 CLSP 继续不足够。</sample>
    <sample id="695">该方法处理排列的不确定性，通过在标记步骤中使用排列模型来诱导排列。</sample>
    <sample id="696">下游NLP模型的公平性涉及多种考虑因素，包括：（1）处理各种群体之间的敏感性差异的挑战；（2）通过在测试集上评估错误来衡量系统偏差；（3）在数据分布中平衡边缘情况，使模型对不同的子群体反应一致。为了实现公平性，研究提出了基于群体比例调整权重的解决方案。</sample>
    <sample id="697">演讲者的名字是Adrien Borgazge。</sample>
    <sample id="698">根据视频中的信息，无法直接识别出演讲者的名字。然而，视频中确实展示了几个参与研究的作者的名字。如果你正在寻找演讲者的名字，视频并未提供该信息。</sample>
    <sample id="699">演讲者的名字是MYRON CHENG。</sample>
    <sample id="700">在本文的背景下，tropicalism 意味着贬低亚洲妇女的形象，而不是对她们的实际描述。</sample>
    <sample id="701">通过将他们限定为自己的身份。</sample>
    <sample id="702">文中引入了P-CXMI来测量翻译具体词句所需的语境使用情况。</sample>
    <sample id="703">The primary distinction between DrBERT and ChuBERT lies in their construction and pre-training strategies. DrBERT was created from scratch using full model construction, while ChuBERT involved contrastive pre-training by utilizing an existing pre-trained model.</sample>
    <sample id="751">这篇论文有三位作者，如标题屏幕所示。</sample>
    <sample id="752">迭代迁移学习使用旧数据的新实例和新数据在每次迭代中微调旧模型，作为迭代更新（IT）方法的一部分。</sample>
    <sample id="753">理解用户在做出选择时使用的语言。</sample>
    <sample id="754">攻击者可以通过访问 EaaS 测试接口来提取模型参数，因为访问这些接口是无需认证的。</sample>
    <sample id="755">这篇论文有三位作者，分别是Sara Papi、Matteo Negri 和 Marco Turchi，正如图片所示。</sample>
    <sample id="756">创建初始数据集共有5名人类注释者。</sample>
    <sample id="757">根据提供的视频内容，作者所属的机构是华盛顿大学、加州理工学院、Allen Institute for AI以及加州大学圣克鲁兹分校。</sample>
    <sample id="758">一个例子是“（我看见Bart和Lisa, Homer来了并打喷嚏）。</sample>
    <sample id="759">对话系统中的最先进模型被称为Alxe。</sample>
    <sample id="760">我们需要在整个上下文窗口中评估模型的可接受性，从而提供更可靠和全面的模型行为和性能衡量标准，尤其是在长期依赖管理方面。</sample>
    <sample id="761">是的，如幻灯片所示，在7个数据集中，英语的表现由于多语言训练而下降，这是所谓的“多语言诅咒”。</sample>
    <sample id="762">是的，在对实体进行注释之前，注释者需要获取相关知识。</sample>
    <sample id="763">BLEU</sample>
    <sample id="764">是的，回归在 NER 的某些情况下确实会影响泛化。</sample>
    <sample id="765">立场很重要，因为它可以揭示哪些立场被算法视为错误或有害，从而揭示模型中的设计偏见。</sample>
    <sample id="766">像 BLOOM 这样的多语言 LLM 采用了适配器微调。</sample>
    <sample id="767">他们使用RoBERTa-base +分类头进行迁移学习。</sample>
    <sample id="768">mC4、TyDiQA 和 XLSum 评估是最近用于评估像 PaLM 这样的模型的能力所使用的测试集。</sample>
    <sample id="769">作者提出了三项建议。</sample>
    <sample id="770">提议的方法在与最强的基线相比时，显示出51.25%的改进。</sample>
    <sample id="771">根据视频中提供的信息，演讲者的名字是Shuhen Liu。</sample>
    <sample id="772">是的，论文中的结果和数据集（如SAIGI，ELSA，GUS，EUR-Lex，和Wikimedia）可以作为评估自动文本简化技术性能的基准。</sample>
    <sample id="773">论文中展示了四个参与实验的较小模型。</sample>
    <sample id="774">OFA 被用作研究多模型指令调整的基础模型。</sample>
    <sample id="833">这篇论文的作者所属机构是谷歌。</sample>
    <sample id="834">根据图像，论文的作者与石溪大学有关联，特别是他们的“人类语言分析中心”。</sample>
    <sample id="835">论文分析了英译德、英译法、英译土耳其、英译匈牙利和法译德这五种语言对。</sample>
    <sample id="836">演讲者的名字是Shangbin Feng，如视频中的标题所示，他是四位演示者之一。</sample>
    <sample id="837">在实验中，研究了两个预训练模型：mBART-50 和 longBART。</sample>
    <sample id="838">在 MultiInstruct 的背景下，有 62 个不同的任务被利用。其中有 53 个任务用于训练，剩余的 9 个任务被保留用于测试目的。</sample>
    <sample id="839">这篇论文有三位作者：Regina Stodden, Omar Momon 和 Laura Kallmeyer。</sample>
    <sample id="840">在实验中，作者使用了AG News、MIND、SST2、Enron Spam 作为拷贝数据集，以及WikiText作为提供者的通用数据集。</sample>
    <sample id="876">NACHOS 是一种医学语言模型，如视频中的总结所示的第四点。</sample>
    <sample id="877">根据视频中的信息，无法确定演讲者的名字。只有六位个人的姓名显示在PPT幻灯片上，但没有一个对应于正在讲话的人。</sample>
    <sample id="878">根据幻灯片的内容，使用的提示策略可以显著影响翻译质量，因为对于大部分句子（具体来说是516个句子中的1000个），提示之间的差异可以超过1个BLEURT点，并且这个差异最大可以达到40个BLEURT点。</sample>
    <sample id="879">这篇论文的作者来自卡内基梅隆大学语言技术研究所、TECNICO LISBOA、BAIR和其他一些机构。</sample>
    <sample id="880">视频中没有提供5个由专家编写的指令。不过，它提到正在进行一个更大的多模态指令微调数据集的收集，该数据集包含约150个额外的视觉-语言任务。</sample>
    <sample id="881">作者建议使用一个用于知识集成评估的测试集，特别是通过共指消解任务，来测试模型从预训练知识和推断时知识中提取能力。</sample>
    <sample id="882">翻译后的结果是——谷歌翻译的输出。</sample>
    <sample id="883">翻译结果：
- 语言：中文
- 内容：参数数量增加至260亿。
增加到620亿参数。
增加到2960亿参数。
增加到540亿参数。
减少至296亿参数。
减少至80亿参数。
减少至420亿参数。
减少至176亿参数。</sample>
    <sample id="884">目标语言：中文
翻译结果：PaLM：路径语言模型
Chowdery等人，2022
arXiv:2204.03114。
5400亿参数。
在7800亿个标记上训练。
密集激活。
6144张TPU v4芯片。
在数百个LMU和生成基准测试中达到SOTA。</sample>
    <sample id="885">我们为机器翻译开发推荐了提示选择策略。</sample>
    <sample id="886">我们的贡献</sample>
    <sample id="887">文本内容翻译如下：
- 我们的贡献
- 第一个用于机器翻译的LLM提示的系统性研究。
  - 同时考虑候选池和选择策略。
- 使用机器翻译社区的最佳实践评估翻译能力：
  - 最新的测试集（避免训练/测试重叠和对评估数据的过度拟合）。
  - 与最近的WMT提交进行比较。
  - STOA机器翻译指标（更好地与人类判断相关联）。
  - 专家基础的人类评估（比众包工作者更可靠）。
- 提示选择策略的推荐。</sample>
    <sample id="888">这是您要的翻译：
目标语言：中文
翻译结果：我们的贡献
- 第一个系统的LLM提示方法在MT上的研究。
- 评估翻译能力采用MT社区的最佳实践。
- 向量空间比较，可以更公平地衡量候选集合的表达能力。
- 对于使用最近数据的最先进MT系统进行比较。
- 基于专家的人工评估（比众包工人更稳健）。
- 提示选择策略推荐</sample>
    <sample id="889">以下是您提供的文本的中文翻译：

"提示对翻译质量有很大影响

- 为每个句子选择两个随机提示。
- 计算每个句子-提示对的BLEURT。
- 多数句子（1000个句子中的516个）显示出超过1个BLEURT点的差异。
- 差异可能高达40 BLEURT点！"

请注意，这是一个关于语言模型或机器翻译中提示（prompt）影响的研究或实验的描述。</sample>
    <sample id="890">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：提示对翻译质量有很大影响
- 为每个句子选择两个随机提示。
- 计算每个句子和提示对的BLEURT分数。
- 大多数句子（1000句中516句）显示超过1个BLEURT点的差异。
- 差异可能高达40个BLEURT点！</sample>
    <sample id="891">翻译结果：
- 语言：中文
- 内容：提示对翻译质量有很大影响。为每个句子选择两个随机提示。为每个句子-提示对计算BLEURT。大多数句子（516个中的1000个）显示差异超过1 BLEURT点。差异可以高达40 BLEURT点！</sample>
    <sample id="892">翻译后的结果为：
目标语言：中文
对应的翻译文本为：例：翻译提示
• 5秒提示
德语：在街上可以看到，有人被两名警察押送在一辆警车里。
英语：他正在两名警察的押送下被公交车从监狱运来。
...
德语：在滑雪板下：警察被召集，因为接受了办公室的投诉。
英语：警察接到办公室投诉后被召来。
德语：过路人报警，有多起伤车报告。
英语：一名过路人报警，涉及多辆刮擦车辆。</sample>
    <sample id="893">翻译后的结果如下：
- 德文: "Dort sieht man, wie sie von zwei Polizei-Offizieren in einen Streifenwagen gesetzt wird."
  - 中文: "他们正被两名警察用警车从监狱接送。"

- 德文: "Ski-Legende unter sich: Die Polizei war eingezogen, nachdem sie Beschwerden des Büros erhalten hatte."
  - 中文: "滑雪传奇下: 警察被召唤前来，是因为收到了办公室的投诉。"

- 德文: "Ein Passant alarmierte die Polizei, die mit mehreren Streifenwagen antwortete."
  - 中文: 由于一名路人报警，警方出动多辆警车。"</sample>
    <sample id="894">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：有四句英文。</sample>
    <sample id="895">这是提供的翻译内容：
- 目标语言：中文
- 翻译文本：德语：Dort sieht man, wie sie von zwei Police-Officers in einem Streifenwagen gebracht wird。
英语：他正在被两名警察在公交车上从监狱护送到。
...
德语：Ski-Legenden unter sich: Die Polizei war eingespielt, nachdem sie Beschwerden des Büros erhalten hatte。
英语：警察在接到办公室的投诉后被呼叫。
德语：Ein Passant alarmierte die Polizei, die mit mehreren Streifen antrat。
英语：</sample>
    <sample id="896">目标语言：中文
翻译结果：德语：在下面的滑雪板下：警方在收到办公室的投诉后被叫来。
英語：</sample>
    <sample id="897">翻译内容如下：
实验结果
- 例句质量比与源句的相似性更重要。
- 专业化的SOTA系统具有显著优势。
- PaLM接近于Google Translate。
MQM的见解：
- PaLM的流畅性与SOTA相当。
- 准确性得分通常较低。
- 受“准确/遗漏”主导。
- PaLM的“风格/生硬”得分通常较低。</sample>
    <sample id="898">以下是您要的翻译内容：
- 目标语言：中文
- 翻译文本：实验结果
- 示例质量比源句的相似度更重要。
- 专门化的SOTA系统具有实质性优势。
- PaLM接近Google Translate。

MQM的见解：
- PaLM的流畅性与SOTA相当。
- 准确性得分总体较低。
  - 主要由 '准确性/遗漏' 优势。
- '风格/不自然' 一般较低对于PaLM。</sample>
    <sample id="899">这是您要的翻译：
目标语言：中文
翻译结果：实验结果：

示例质量比与源句子相似性更重要。
专用最先进的系统具有显著优势。
PalM接近于Google Translate。</sample>
    <sample id="900">已将文本内容翻译为中文：
实验结果：
示例质量比与源句的相似性更重要。
专用的最新进展系统具有明显优势。
帕尔姆接近Google翻译。
来自MQM的洞察：
帕尔姆的流畅性与最新进展可比。
准确度得分普遍较低。
风格/不自然性得分通常较低。</sample>
    <sample id="901">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：实验结果

• 示例质量比与源句的相似性更重要。
• 专门化的SOTA系统具有显著优势。
• PaLM接近Google翻译。

MQM洞察：
• PaLM的流畅性与SOTA相当。
• 准确性评分通常较低。
• '准确/遗漏'主导。
• '风格/生硬'通常对PaLM较低。</sample>
    <sample id="902">翻译完成：目标语言是中文，对应的文本为：实验结果
• 示例质量比与源句的相似性更重要。
• 专业的SOTA系统具有实质性优势。
• PaLM接近Google Translate。
来自MQM的洞察：
• PaLM的流畅性与SOTA相当。
• 准确度得分通常较低。
o 受'准确度/遗漏'影响。
o PaLM的'风格/生硬'通常较低。。</sample>
    <sample id="903">文本已翻译为中文，结果如下：
实验结果
示例质量比与源句的相似性更重要。
专业化的SOTA系统具有显著优势。
PaLM接近Google Translate。
MQM的见解:
PaLM的流畅性与SOTA相当。
准确度得分通常较低。
由'准确性/遗漏'主导。
PaLM的'风格/别扭'通常较低。</sample>
    <sample id="904">这是您要的翻译：
目标语言：中文
翻译结果：实验结果：
示例质量比接近源句更重要。
专业化的SOTA系统具有实质性优势。
PaLM接近Google Translate。
来自MQM的洞察：
PaLM的流利度可与SOTA相媲美。
准确性分数通常较低。
PaLM的风格/生硬评分通常较低。</sample>
    <sample id="905">这是您要的翻译：
目标语言：中文
翻译结果：实验结果
- 示例质量比与源句的相似性更重要。
- 专门化的SOTA系统具有明显的优势。
- PaLM接近Google Translate。
MQM见解：
- PaLM的流畅性与SOTA相当。
- 准确性得分通常较低。
- "准确性/遗漏"项主导了准确性得分。
- PaLM的"风格/生硬"得分通常较低。</sample>
    <sample id="906">这是字幕的内容：
多谢啦  天哪。</sample>
    <sample id="907">已将文本内容翻译为中文：
比你想象的更弱
对弱监督学习的批判性审视

邹达维，沈晓宇，马里乌斯·莫斯巴赫，安德烈亚斯·斯蒂芬，迪特里希·克拉克

萨尔兰德大学
亚马逊亚历克斯
维也纳大学

第61届 ACL 2023</sample>
    <sample id="908">翻译后的结果如下：
- 目标语言：中文
- 内容：比你想象的更弱
对弱监督学习的批判性审视</sample>
    <sample id="909">翻译后的结果如下：
- 目标语言：中文
- 内容：为什么进行弱监督学习？
* 弱监督缓解了标注瓶颈。
* 但是弱标签是嘈杂的！
* 噪音记忆损害泛化。
* 弱监督学习（WSL）
* 训练能够很好地泛化的模型，尽管它们是在嘈杂的数据上训练的。</sample>
    <sample id="910">翻译完成：目标语言是中文，对应的文本为：为什么要做弱监督学习？
弱监督减轻了标注瓶颈。
但弱标签有噪点！
噪声记忆会损害泛化。
弱监督学习（WSL）
在嘈杂的数据上训练模型，使其泛化良好。。</sample>
    <sample id="911">翻译后的结果如下：
- 目标语言：中文
- 内容：为什么需要弱监督学习？
- 弱监督缓解了标注瓶颈。
- 但弱标签是**有噪声的**！
- **噪声记忆**损害泛化。
- 弱监督学习（WSL）
- 在嘈杂的数据上训练能够泛化的良好模型。</sample>
    <sample id="912">这是您要的翻译：
目标语言：中文
翻译结果：为什么进行弱监督学习？
弱监督缓解了标注瓶颈。
但是弱标签是嘈杂的！
噪声记忆会损害泛化。
弱监督学习（WSL）
训练模型，使其能够很好地泛化，尽管在嘈杂的数据上训练。</sample>
    <sample id="913">翻译后的结果如下：
- 目标语言：中文
- 内容：为什么要弱监督学习？
弱监督缓解了标注瓶颈。
但弱标签是嘈杂的！
噪声记忆损害泛化。
弱监督学习（WSL）
在嘈杂的数据上训练模型，这些数据是一般化的。</sample>
    <sample id="914">视频中的字幕是：
"我们仅使用弱监督数据训练模型，并达到xx%的准确率。"

翻译结果如下：
目标语言：中文
翻译结果："我们仅使用弱监督数据训练模型，并达到百分之xx的准确率。"
注：百分数保持为"xx%"的形式，未进行翻译。</sample>
    <sample id="915">这是您要的翻译：
目标语言：中文
翻译结果：在最近的WSL工作中，一个常见的说法是\n我们只在弱监督数据上训练模型，并取得了XX的准确率。\n</sample>
    <sample id="916">翻译内容如下：
（最近WSL作品中常见的声明）
仅使用弱监督数据训练模型可以达到XX%的精度（震惊表情）
弱标签训练数据（嘈杂）
清晰标签验证数据（干净）
清晰标签测试数据（干净）</sample>
    <sample id="917">翻译后的结果如下：
- 目标语言：中文
- 内容："我们只用弱监督数据训练模型并实现XX%的准确率"</sample>
    <sample id="918">已将文本内容翻译为中文，结果如下：
我们的研究问题
RQ1 清洁验证数据是否必要？
RQ2 WSL方法需要多少个清洁样本？
RQ3 如何更有效地使用可用的清洁样本？</sample>
    <sample id="919">已将文本内容翻译为中文：
我们的研究问题
问题1：是否需要干净的验证数据？
问题2：WSL方法需要多少干净的样本？
问题3：如何更有效地利用可用的干净样本？</sample>
    <sample id="920">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：R01 主要发现</sample>
    <sample id="921">翻译完成：目标语言是中文，对应的文本为：研究问题1
主要发现。</sample>
    <sample id="922">翻译内容如下：
（无变化，因为已经是中文）</sample>
    <sample id="923">翻译完成：目标语言是中文，对应的文本为：主要发现
FT
BOND
COSINE
MLC
L2R。</sample>
    <sample id="924">翻译结果：
- 语言：中文
- 内容：主要发现
- 验证集必须干净。</sample>
    <sample id="925">翻译结果：
- 语言：中文
- 内容：RQ2 主要发现</sample>
    <sample id="926">目标语言：中文
翻译结果：RQ2 主要发现

精度
20 30 40 50
验证
全部</sample>
    <sample id="927">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：WSL方法从更多的干净校验样本中受益！</sample>
    <sample id="928">这些研究结果表明，使用更多的干净验证样本可以显著促进WSL方法的性能。图中的两个图表分别展示了不同方法在准确性上的提升以及数据性能变化。</sample>
    <sample id="929">翻译内容如下：
-WSL方法从更干净的验证样本中受益！\n-但最好将其用于训练（例如，LoRAcc！）。</sample>
    <sample id="930">翻译内容如下：
（无文本需要翻译）</sample>
    <sample id="931">这些图展示了不同的评估指标。左边的图显示了准确性在CFT前后的变化。CFT代表某个处理或分析结果。我们可以看到，N-10组在CFT前后的准确率分别从78提高到了82，而CFT的效果显示了对准确性的影响。

在右边的图中，N-30组的初始准确率是78，在CFT后提高到了84。图中的线条代表不同处理或算法，分别标注为Cosine、Loss、F1和Clean Only。这些线条在CFT前后都有所变化，表明处理对不同指标有所影响。

视频中没有展示其他动作或场景变化，主要通过图表数据来展示主要发现。</sample>
    <sample id="932">视频中的字幕是：“R03 主要发现”。</sample>
    <sample id="933">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：连续微调（CFT）消除了WSL方法之间的性能差异。
- 不需要使用复杂的WSL方法，FLF表现同样良好。</sample>
    <sample id="934">目标语言：中文
对应的翻译文本为：结论
最近的WSL方法
- 需要干净的样本。
- 对其实用性估计过高。
我们的建议
- 报告模型选择标准。
- 将Few-shot学习方法用作基线。
- 始终应用连续微调（CFT）。</sample>
    <sample id="935">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：结论
最近的WSL方法
我们的建议</sample>
    <sample id="936">这是您要的翻译：
目标语言：中文
翻译结果：结论
最近的WSL方法
要求清洁样本。
高估它们的实用性。
我们的建议
报告模型选择标准。
使用少数样本学习方法作为基线。
始终应用连续微调。</sample>
    <sample id="937">这是您要的翻译：
目标语言：中文
翻译结果：结论
近期WSL方法
- 需要干净的样本。
- 高估其实用性。
我们的建议
- 报告模型选择标准。
- 将Few-shot学习方法用作基线。
- 始终应用连续微调（CFT）。</sample>
    <sample id="938">此视频的翻译文本如下（已进行格式整理和正确翻译）：

结论

最近的WSL方法
- 需要干净的样本。
- 高估了它们的实际应用性。

我们的建议
- 报告模型选择标准。
- 使用Few-shot学习方法作为基线。
- 始终应用连续微调（CFT）。

感谢！

图片中的每个元素都被准确翻译成中文，并且没有保留任何可能产生歧义的信息。</sample>
    <sample id="939">对话系统的评估方法包括基于用户满意度或偏好的相对比较，以及使用评分尺度的Likert评分。</sample>
    <sample id="940">这篇论文有五位作者。这个信息可以通过观察列在标题下的五个名下的名字和隶属关系来证明。</sample>
    <sample id="941">要理解 Servin 和 Kea 的示例，模型需要知道裁判决定法律案件这一点背景知识（背景知识）。</sample>
    <sample id="942">根据视频内容，代码是公开的，并且可以在GitHub页面 mpoems/kitmus 上找到，其中包括数据集、生成和评估代码。</sample>
    <sample id="943">是的，NLPositionality 的注释者在人口统计学特征方面大多均衡，除了一些小偏差，比如在性别方面男性略多。他们有超过 1000 名注释者，来自各种国家和地区，年龄范围也广泛。</sample>
    <sample id="944">在可接受的域中，句子可以通过添加前缀或后缀副词来打乱，如“然而，&lt;句子&gt;”，或者通过添加一个长前缀如“首先，&lt;句子&gt;”。</sample>
    <sample id="945">进行维度评估意味着将对话的维度分解为不同的方面，这些方面包括相关性、情感理解和连贯性，如图所示。</sample>
    <sample id="946">根据标题中提供的信息，这篇论文的作者来自香港科技大学、微软亚洲研究院和北京交通大学。这些机构通过相关签名旁边显示的徽标指示。</sample>
    <sample id="947">在多种需要清晰理解或特定结构的场景中，提示的形式非常重要。例如，翻译任务中准确的上下文提供给提示对生成正确翻译的模型至关重要。在教育或教学环境以及任何依赖具体提示结构的系统任务中情况也是如此。</sample>
    <sample id="978">在给出的视频中，作者评估了Blender Decode模型。视频没有提到任何其他模型。</sample>
    <sample id="979">这篇论文标题为《Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark》，共有11位作者。这些作者来自不同的机构，包括华南理工大学、北京交通大学、微软亚洲研究院和索尼AI。这份论文旨在探讨通过后门水印保护大型语言模型版权的方法，特别是在EaaS（软件即服务）的应用场景下。</sample>
    <sample id="980">优秀的规划者必须理解如何通过详细规划达到高层次的一般目标。</sample>
    <sample id="981">这篇论文有八位作者。</sample>
    <sample id="982">视频中没有透露演讲者的全名，但字幕显示了他们的名字是'Mitasumita Mukherjee'。</sample>
    <sample id="983">论文的作者属于波兹南波兰科学院（PAN）的计算机科学研究所和华沙大学，如标题幻灯片所示。</sample>
    <sample id="1021">PaLM 最常见的错误类型是“准确性/遗漏”。</sample>
    <sample id="1022">翻译内容如下（目标语言：中文）：
不要忘记你的ABC：评估面向聊天的对话系统的新艺术</sample>
    <sample id="1023">翻译结果：
- 语言：中文
- 内容：不要忘记你的ABC：评估面向聊天的对话系统的状态</sample>
    <sample id="1024">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：比较评估</sample>
    <sample id="1025">这段视频展示了一个持续的场景，其中一位女士，可能与亚历克斯有关，作为亚特兰大埃默里大学品牌的一部分。视频以深蓝色横幅开始，上面写着“比较评估”，并伴有图像，这些图像描绘了两个对话框，其中一个来自人类形象，另一个来自一个类似于人形机器人的形象。两个蓝色图标，可能代表人工智能实体，在人类形象和它们相对应的机器人形象之间交换会话气泡，表明一种互动形式。

随着视频的进行，一个带有法官面具的卡通人物出现在屏幕底部，象征着一种评判或评估的背景。随后添加了一个绿色的对勾，暗示了比较进程中的通过或批准。图像保持一致，通过叠加新元素来指示场景的发展，例如出现在白色背景中的圆形，可能表示关注点或时间框架，但整体设置没有重大的改变。

最后，视频切换到另一张幻灯片，标题为“利克特评分评估”，引入了由数字范围从1到5标记的新评判机制。这表明从直接比较转向基于分数的评估，尽管这种改变可能更微妙，因为只有标题的变化和新评分机制的介绍，而其余图像保持不变。在整个视频中，女士在右上角的图像中始终可见，可能代表亚历克斯或相关的品牌，而亚特兰大埃默里大学的标志作为一个标志，表明了学术或专业环境的主题连续性。</sample>
    <sample id="1026">翻译完成：目标语言是中文，对应的文本为：对话质量的维度。</sample>
    <sample id="1027">翻译结果：
- 语言：中文
- 内容：评分
- 想象力
对话质量
- 相关性
- 一致性
1 2 3 4 5
给定的对话中的响应评级。
- 如果没有给出评级。</sample>
    <sample id="1028">已将文本内容翻译为中文：
林克特评分评估
对机器人的响应的相关性进行评分</sample>
    <sample id="1029">翻译结果：
- 语言：中文
- 内容：聊天中的行为标注（ABC评估）
不相关
缺乏同理心
自我矛盾</sample>
    <sample id="1030">翻译结果：
- 语言：中文
- 内容：对话中的行为标注（ABC-Eval）</sample>
    <sample id="1031">翻译完成：目标语言是中文，对应的文本为：ABC评估行为
连贯性
一致性
知识
情感理解。</sample>
    <sample id="1032">翻译内容如下：
- 目标语言：中文
- 翻译文本：一致性</sample>
    <sample id="1033">已将文本内容翻译为中文，结果如下：
ABC评估行为
连贯性
忽视伙伴
无关
知识
不正确的事实
常识违反
一致性
自我矛盾
伙伴矛盾
情感理解
共情反应
缺乏同理心</sample>
    <sample id="1034">目标语言：中文
翻译结果：4 个开放领域的对话模型，
每个模型 100 个人类 - 机器人对话。

ABC-Eval

知识
情感理解</sample>
    <sample id="1035">目标语言：中文
- 用户需要被问及他们对与人工智能机器人进行的对话的看法
- 具体来说，他们需要考虑他们最喜欢与哪种机器人对话：多轮对话机器人、长对话机器人，或者是两者之间的中立者
- 测试者应选择他们最喜欢与哪种机器人进行对话。</sample>
    <sample id="1036">目标语言：中文
翻译结果：基准评估
一致性
情感理解
信息性
整体质量
吸引性
语法性
积极性
相关性</sample>
    <sample id="1037">目标是在我们收集的对话数据上构建一个基准。这是评估，确保您有一致的数据来确保质量。这是确保不同评注者之间协议一致性的指标。我们确实观察到，根据这个指标，使用相同的评注形式来衡量评估结果总是存在差异。</sample>
    <sample id="1038">这是您要的翻译：
目标：
让我们探讨人类标注者的质量标签与人工智能系统在未来展示良好对话性能的能力和趋势之间的关系。</sample>
    <sample id="1039">翻译结果：
- 语言：中文
- 内容：我们还可以看到，我们不仅关心当前的会话质量，还要考虑会话的发展方向。这些图表展示了这一预测能力，让我们来探讨一下。</sample>
    <sample id="1040">这是您要的翻译：
目标：
自控
减少重复
不那么无动于衷
实践性
探索

增量有效性：
0.075 - 0.250
自控
1. ABC - 目标
2. Turn - 倾向
3. 对话 - 认可

情感
相关性</sample>
    <sample id="1041">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：增量有效性</sample>
    <sample id="1042">以下是您提供的文本的中文翻译：

- 'Incremental Validity'
- 'Emory University'
- 'Alexa'
- 图表上的文字：
  - 'N=23'
  - 'Self Control'
  - 'Unsystematic'
  - 'Moderate'
  - 'Practicable'
  - 'Emotion'
  - 'Relevant'
  - 其他一些难以辨认的小字，似乎是一些关键词或变量名称。</sample>
    <sample id="1043">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：通过观察数据，我们发现模型倾向于出现误解和不相关错误。因此，我认为我们不应该在模型上进行进一步的微调。</sample>
    <sample id="1044">这是您要的翻译：
目标语言：中文
翻译结果：错误分类。这些是我们认为错误的数据。这里的一个亮点是，这些模型仍然有一些错误分类的问题。因此，我们开始对这些错误进行分类，因为我们真的想知道这些模型为什么会出错。</sample>
    <sample id="1045">这是您要的翻译：
目标语言：中文
翻译结果：艾伦认为，这个模型在“分类混乱”上表现出色。
艾伦认为，这个模型在“类内变体”上做得相当出色。</sample>
    <sample id="1046">翻译内容如下：
- 目标语言：中文
- 翻译文本：错误率最高的问题类型是与主题切换相关的，其次是与模型切换相关的问题，以及与错误信息和冗余相关的各类问题。</sample>
    <sample id="1047">这是您要的翻译：
目标语言：中文
翻译结果：ABC-Eval 模型错误率
谢谢收看！</sample>
    <sample id="1048">论文作者与埃默里大学有关联，如标题幻灯片所示，并且艾米丽研究实验室标志也出现在幻灯片上。</sample>
    <sample id="1049">CFT 代表在视频中提到的建议之一，即“连续微调”，在提供建议时使用了“always apply continuous fine-tuning (CFT)”的表达。</sample>
    <sample id="1050">这篇论文有八位作者。</sample>
    <sample id="1051">翻译后的结果是：“什么时候翻译需要上下文？数据驱动的，多语言探索”</sample>
    <sample id="1052">翻译结果如下：
- 目标语言：中文
- 内容：翻译取决于上下文
我们将不得不消除那个'鼹鼠'。</sample>
    <sample id="1053">这是个需要依据背景上下文来进行翻译的例子。例如:“事情可能会变得危险，如果秘书们发现真相。我们必须除掉那个间谍。” 或者:“这重要吗，医生? 我们必须除掉那个痣。” 或者:“这很重要吗，医生? 我们必须除掉那个痣。”</sample>
    <sample id="1054">翻译取决于上下文。医生，它可能是严重的吗？我们需要去除那个痣。</sample>
    <sample id="1055">翻译结果：
- 语言：中文
- 内容：评估上下文相关的翻译很难
- 只有一小部分单词依赖于上下文
- 汉语语料库级别的度量</sample>
    <sample id="1056">翻译结果：
- 语言：中文
- 内容：评估基于上下文的翻译很难
- 只有一小部分单词依赖于上下文
- 语料库级别的度量
- 现有的方法支持有限的对话现象和语言</sample>
    <sample id="1057">目标语言：这是问题需要的翻译语言。它不会出现在原视频中。</sample>
    <sample id="1058">文本已翻译为中文，结果如下：
RQ1：什么时候翻译需要上下文？
- 单词级别的上下文使用
RQ2：模型在上下文相关的翻译上的表现如何？</sample>
    <sample id="1059">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：条件交叉互信息（CXMI）：衡量机器翻译模型在给定语料库中使用多少上下文</sample>
    <sample id="1060">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：条件交叉信息（CXMI）是一种衡量给定语料库时，机器翻译模型使用多少上下文的方法。请看一下此图表。</sample>
    <sample id="1061">翻译后的结果如下：
- 目标语言：这是用于描述视频内容的字幕文本，包括讲解者所展示的数学公式和统计信息。这些公式涉及点式（P）上下文交叉互信息（C-XMI）的介绍和计算，用于测量特定上下文使用情况来翻译一个句子或单词。讲解者还提到了P-XMI值高的单词通常需要上下文来翻译。</sample>
    <sample id="1062">这是您要的翻译：
目标语言：中文
对应的翻译是：研究问题1：什么时候翻译需要语境？
- 词级别语境使用
- 主题分析

研究问题2：模型处理语境翻译的水平如何？</sample>
    <sample id="1063">这些是高频词汇，我们想分析这些词汇涉及的主要主题。为了实现这一点，我们构建了一个分类模型。正如这个分类模型所显示的那样。</sample>
    <sample id="1064">文本翻译完成：目标语言是中文，对应的文本为：1. 词性标记。</sample>
    <sample id="1065">翻译结果：
- 语言：中文
- 内容：1. 词性标签</sample>
    <sample id="1066">翻译完成：目标语言是中文，对应的文本为：高P-CXMI单词的主题分析
1. 词性标记
- 代词
- 动词形式。</sample>
    <sample id="1067">以下是您提供的文本的中文翻译：

英文文本：
"Thematic analysis of high P-CXMI words

1. POS tags
2. Vocabulary items

Avelle's mother was still asleep.
Avelle went to school.

- Pronouns
- Verb form
- Lexical cohesion"

翻译结果：
"对高P-CXMI词汇的主题分析

1. 词性标记
2. 词汇项目

阿维尔的母亲还在睡觉。
阿维尔去上学了。

- 代词
- 动词形式
- 词汇衔接" 

通过这种方式，我们确保了所有英文信息都被完整且准确地翻译成了中文。</sample>
    <sample id="1068">我们进行了一些主题分析，分析了高P-CXMI的单词。我们考虑了词性、词汇项目以及主题，包括代词、动词形式、词汇衔接和正式程度。</sample>
    <sample id="1069">翻译后的结果如下：
- 目标语言：中文
- 内容：高P-CXMI单词的主题分析

1. 词性标签
2. 词汇项目
3. 单个标记</sample>
    <sample id="1070">翻译完成：目标语言是中文，文本如下：
问题1：翻译何时需要上下文？
- 单词级上下文使用
- 主题分析

问题2：模型在处理上下文依赖的翻译时表现如何？
- 跨语言话语感知（MuDA）基准</sample>
    <sample id="1071">目标语言：中文
字幕：
多语言语境感知（MuDA）标记器
代词
动词形式
词汇连贯性
正式程度
省略</sample>
    <sample id="1072">翻译内容如下：
多语言话语感知（MuDA）标记器
• 代词
• 词性
• 词汇一致性
• 正式性
• 省略</sample>
    <sample id="1073">已将文本内容翻译为中文：
MuDA基准测试
BLEU
COMET
F测量值</sample>
    <sample id="1074">翻译完成：目标语言是中文，对应的文本为：问题一：翻译何时需要上下文？\n- 词汇级上下文使用\n- 主题分析\n\n问题二：模型如何处理上下文依赖的翻译？\n- 多语言语境感知基准 (MuDA)\n- 模型评估。</sample>
    <sample id="1075">这是给定视频中字幕的翻译，翻译结果如下：
（无翻译文本）</sample>
    <sample id="1076">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：语料级指标</sample>
    <sample id="1077">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：语料库级别的指标
使用语料库级别的指标无法确定哪种系统最适合文档级别的机器翻译</sample>
    <sample id="1078">翻译内容如下：
MuDA基准测试结果
上下文感知模型在某些现象上表现得非常好</sample>
    <sample id="1079">文本已翻译为中文，结果如下：
MuDA基准测试结果
• 上下文感知模型在某些现象上表现显著更好
○ ✅：正式性、词汇凝聚力
❌：省略、代词、动词形式</sample>
    <sample id="1080">翻译后的结果如下：
- 目标语言：中文
- 对应的翻译文本：MuDa基准测试结果

带有上下文的模型在某些现象上表现出色

符号意义：正方形表示正式性，圆圈表示词汇一致性
X表示省略，代词和动词形式

DeepL在大多数现象和语言对方面优于谷歌*</sample>
    <sample id="1081">翻译内容如下：
概要
- 系统地识别没有先前语言学知识的会话现象
- 无数据集偏差的文档级机器翻译基准</sample>
    <sample id="1082">目标语言</sample>
    <sample id="1083">翻译结果：
- 语言：中文
- 内容：总结：
- 在没有先验语言知识的情况下，系统地识别话语现象。
- 文档级机器翻译的独立于数据集的基准。</sample>
    <sample id="1084">演讲者的名字是Yusen Zhang。</sample>
    <sample id="1121">没有。</sample>
    <sample id="1122">作者描述“显性词汇”(marked words) 方法为找出能区分“标记群体”(marked groups) 和“未标记群体”(unmarked groups) 人格的词语。</sample>
    <sample id="1123">这篇论文的作者们来自多个机构，其中包括华威大学、明尼苏达大学、卡内基梅隆大学的语言技术研究所以及艾伦人工智能研究所。</sample>
    <sample id="1124">视频中提到的第一个对称依存关系结构是'Chain/'来自莫斯科。这个结构展示了词之间的链状连接，而不是多对多的连接。随后的依存关系结构，如'Conjunction-headed/'和'Multi-headed/', 都有不同名称的城市标注，分别来自布拉格和伦敦。</sample>
    <sample id="1125">演讲者的名字是萨拉·芬奇。</sample>
    <sample id="1126">这篇论文共有四位作者。</sample>
    <sample id="1127">SyntaxGym可以用来测试句法数据集。</sample>
    <sample id="1161">根据图表在第一个研究问题中显示的五个方法是FT_iv、BOND、COSINE、MLC和L2R。这些是五种在演讲中比较的不同方法，图表显示了使用弱标签进行验证时相对性能的改善程度。</sample>
    <sample id="1162">该模型在11个不同的任务上进行了评估。</sample>
    <sample id="1226">最初在46G的法语数据上训练了 CamemBERT。随着模型的不断训练，引入了法语文本的外文部分，这进一步提升了模型的表现。</sample>
    <sample id="1227">演讲者的名字是Adam Przepiórkowski。</sample>
    <sample id="1228">观察到性能随着更大的时间间隔而恶化，这表明时间漂移确实是性能下降的主要原因。</sample>
    <sample id="1269">排列输出序列中的词元是为了准备与输入序列中的对应词元进行对齐。这样可以保持上下文信息并支持模型对相应位置的正确转换。</sample>
    <sample id="1270">作者建议模型所有者应更加透明地讨论偏见缓解措施，以确保负责任的AI开发和评估实践，特别关注社会偏见对技术的影响。</sample>
    <sample id="1271">在演讲的第四部分讨论的主题是'最小对不受欢迎的标准'。</sample>
    <sample id="1272">根据视频中展示的幻灯片，作者在评估预训练策略时使用了NER和CLS的F1分数，其中包括F1 Micro、NER、POS、F1 Macro、POS以及End的F1分数。此外，他们还对CamemBERT、ClinicalBERT、Bidirectional Encoder Representation from Transformers (BERT) Large、BERT for Medical Named Entity Recognition (NER)、BERT Medium、CamemBERT V2以及PaLM-Macro等不同模型的专用性进行了比较评估。</sample>
    <sample id="1273">用于评估注释者之间的一致性的指标是Krippendorff的Alpha。</sample>
    <sample id="1274">在不可接受的查询中，完全无关的句子被添加到无关领域。</sample>
    <sample id="1275">论文的作者来自德国德累斯顿的海因里希·海涅大学。</sample>
    <sample id="1276">MultiInstruct 是一个专为多模态大模型设计的基准，旨在为现有的语言特定基准提供多模态数据，以提供更平衡和全面的性能评估。</sample>
    <sample id="1277">这篇论文列出了三位作者的名字。</sample>
    <sample id="1278">二进制协调是指在某些参数上具有类似行为的节点组合。</sample>
    <sample id="1279">在本研究中，提示词的平均长度为34个标记。</sample>
    <sample id="1280">研究结果表明，较小的 T5 模型在 Coscript 上经过微调后，能够比大型语言模型 (LLMs) 生成更高质量的剧本。</sample>
    <sample id="1281">翻译结果：
- 语言：中文
- 内容：DrBERT：一种法语中鲁棒的预训练模型，用于生物医学和临床领域</sample>
    <sample id="1282">这是您要的翻译：
目标语言：中文
翻译结果：摘要
在医疗保健中的语言建模
预训练策略、数据源和大小的比较
对13个模型在11个任务上的评估
NACHOS和DrBERT的分布</sample>
    <sample id="1283">目标语言：中文
翻译结果：摘要
I. 医疗保健中的语言建模
II. 预训练策略、数据源和大小的比较
III. 对13个模型在11个任务上的评估
IV. NACHOS和DrBERT的分布</sample>
    <sample id="1284">这是您要的翻译：
目标语言：中文
翻译结果：总结
I. 医疗保健中的语言建模
II. 预训练策略、数据源和大小的比较
III. 评估13个模型在11个任务上的表现
IV. NACHOS和DrBERT的分布</sample>
    <sample id="1285">这是您要的翻译：
目标：
总结
1. 医疗保健中的语言建模
2. 比较预训练策略、数据源和大小
3. 评估13个模型在11项任务上的表现
4. NACHOS和DrBERT的分布</sample>
    <sample id="1286">翻译后的文本如下：
- 目标语言：中文
- 翻译文本：语言建模
基于Transformer的方法，如BERT，在许多自然语言处理任务上取得了巨大的性能提升
已经通过CamemBERT和FlauBERT在法语中得到应用。
在医疗任务上，基于特定领域的模型在英文中甚至设定了更高的标准。
PudMedBERT、BioBERT、ClinicalBERT和其他模型。
除了英文，其他语言更罕见，主要依赖连续预训练使用现有的通用模型。
对于法语，不像通用模型，目前没有开源模型可用在生物医学领域。
基于BERT的法语特定领域模型应该在医疗任务上提高性能。</sample>
    <sample id="1287">这是您要的翻译：
目标语言：中文
翻译结果：语言建模
- 基于Transformer的方法，如BERT，为大量NLP任务提供了巨大的性能提升
- 已经被改编成法语，如Camembert和Flaubert
- 在医学任务上，用英语建立的特定领域模型标准更高
- 与其他语言相比，英语以外的语言更为罕见，主要依靠使用现有通用模型的持续预训练
- 与通用模型不同，目前没有开源模型可用于法语的生物医学领域
- 基于BERT的法语特定领域模型应提高在医学任务上的性能</sample>
    <sample id="1288">已将这些高级技术的应用翻译成中文，以便非英语使用者能够理解并从中受益。</sample>
    <sample id="1289">翻译结果：
- 语言：中文
- 内容：语言建模
基于变压器的方法，如BERT，在众多NLP任务上带来了巨大的性能提升
它已经被转化为法语，有CamenBERT和Flaubert。
在医学任务上，英文中的领域特定模型设定了更高的标准
- PubMedBERT、BioBERT、ClinicalBERT和其他
除了英语，其他语言更为罕见，主要依赖于使用现有通用模型进行连续预训练
与通用模型不同，目前没有开源模型在法语生物医学领域可用
基于BERT的领域特定模型将提高法语文本在医学任务上的性能</sample>
    <sample id="1290">翻译结果：
- 语言：中文
- 内容：预训练策略和数据源的比较
- 评估公共和私人医学数据源对可比较数据量的影响
- NACHOS：1.18亿单词的开源数据集，来自各种医学领域的多样化数据
- NBDW：从南特大学医院数据仓库中提取的1.7M条私有匿名医疗记录句子集
- 学习策略的比较
- 从头开始的完整模型构建
- 对抗性预训练使用现有的预训练模型（这里使用CamemBERT，通用法语模型，以及PubMedBERT，基于英语的医学模型）</sample>
    <sample id="1291">这是您要的翻译：
目标语言：中文
翻译结果：比较预训练策略和数据源

评估公共和私有医疗数据源对相当的数据大小的影响

NACHOS：来自不同医疗领域、性质和风格的混合数据的开放源代码数据集，总计1.18亿个单词

NBDMW：1.7万个匿名化医疗记录句子的私有数据集，来自南特大学医院数据仓库

比较学习策略

从零开始构建完整模型

续训预训练使用现有的预训练模型（在这里，CamemBERT是一个法语通用模型，PubMedBERT是一个基于英语的医学模型）</sample>
    <sample id="1292">目标语言：中文
对应的翻译文本为：预训练策略和数据源的比较

评估公共和私人医疗数据源对可比数据大小的影响:
- NACHOS：一个开源数据集，包含从各种医疗领域、性质和风格中收集的异构数据，大约有15亿词。
- NBDW：一个私人数据集，包含从南特大学医院数据仓库中提取的1.7千万个句子集。

学习策略的比较:
- 从头开始构建完整模型。
- 使用现有预训练模型的对比蒸馏预训练（例如，CamemBERT，一个法语通用模型，和PubMedBERT，一个以英语为基础的医学模型）。</sample>
    <sample id="1293">已将文本内容翻译为中文：
预训练策略和数据源的比较
• 评估公共和私人医疗数据源对可比数据量的影响
- NACHOS：一个开放源代码的数据集，包含来自不同医疗领域的异质化数据，共1.1亿个单词。
- NBDWM+：从南特大学医院数据仓库提取的约170万个句子的私有数据集。
• 学习策略的比较
- 从头开始的全模型构建
- 替代预训练，使用现有的预训练模型（在这里，CamemBERT，一个法国通用模型，PubMedBERT，一个基于英语的医疗模型）</sample>
    <sample id="1294">这是您要的翻译：
目标语言：中文
翻译结果：预训练策略和数据源的比较

•评估公共和私人医疗数据源对可比较数据量的影响
- NACHOS: 181万词的开源数据集，从各种医学领域、性质和风格中提取的异构数据
- NBDWM：1.7M匿名化医学记录句子集合，来自南特大学医院的数据仓库。

•学习策略的比较
- 从头开始完全构建模型
- 使用现有预训练模型进行对比预训练（这里为CamemBERT，法语通用模型和PubMedBERT，基于英语的医学模型）</sample>
    <sample id="1295">视频内容已经以中文形式呈现，无需翻译。这段视频详细比较了前训练策略和数据源。具体来说，它评估了公共和私人医疗数据源对等数据规模的影响。视频介绍了两个主要的语料库：NACHOS，这是一套5.18亿个单词的开源数据集，涵盖了来自不同医疗领域、性质和风格的异质性数据；以及NBDW，这是一个1.7万套句子的私人数据集，是从南特大学医院数据仓库提取的匿名化医疗记录。此外，视频还比较了学习策略，包括从头开始构造模型以及使用现有预训练模型进行对比前训练，这里提到的预训练模型包括CamemBERT（一种法语通用模型）和PubMedBERT（一种基于英语的医学模型）。视频还展示了所使用的模型名称和它们对应的学习策略，使用的两个语料库的具体信息，以及模型的大小、嵌入维数和参数数量。</sample>
    <sample id="1296">这是您要的翻译：
目标语言：中文
翻译结果：对公共和私人医疗数据源对相当数据量的影响的评估
比较学习策略
从头开始进行全模型构建
使用现有预训练模型进行对比预训练（此处使用CamemBERT，一种法语通用模型，以及PubMedBERT，一种基于英语的医疗模型）</sample>
    <sample id="1297">目标语言：中文
翻译结果：预训练策略和数据源的比较
性能评估：13个模型在11个任务中，包括公共和私人数据源
我们的微调模型在几乎所有任务中都达到了最先进的结果</sample>
    <sample id="1298">翻译结果：
- 语言：中文
- 内容：数据来源和处理数据的大小
对13个模型在11个任务上的性能评估
我们的细调模型在几乎所有的任务上都达到了最先进的结果</sample>
    <sample id="1299">翻译结果：
- 语言：中文
- 内容：我们对13种模型进行了性能评估，涉及11项任务，包括公开和私有数据
我们精细调整的模型在几乎所有的任务上都达到了最先进的水平</sample>
    <sample id="1300">文本翻译如下：
- 目标语言：中文
- 翻译结果：评估：数据来源和大小</sample>
    <sample id="1301">目标语言：中文
对应的翻译文本为：评估：数据来源和大小
13个模型在11个任务上的性能评估，包括公共和私人
我们微调的模型在几乎所有任务上都达到了最先进的结果</sample>
    <sample id="1302">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：评估：预训练策略
从零开始训练与在46G数据上进行连续预训练
问答任务需要特定领域的知识才能很好地工作
对模型稳定性的研究显示，使用连续预训练的Camembert模型具有更高的结果可变性
...</sample>
    <sample id="1303">文本翻译结果：
- 目标语言：中文
- 内容：预训练策略的评估。
从零开始VS在46G数据上进行持续预训练
问答任务需要更多的领域特定知识才能很好地工作
研究模型稳定性表明，使用持续预训练训练的CamemBERT基模型表现出更高的组内变量性。</sample>
    <sample id="1304">翻译结果：
- 语言：中文
- 内容：从零开始与在464G数据上的持续预训练
问答任务需要更多的专业知识才能表现良好</sample>
    <sample id="1305">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：核心信息
D-BERT在9个下游法语医学相关任务中达到了最先进的结果
○ 超越CamerBERT通用模型和英语特定领域的模型
○ 确认在法语中训练医疗专用模型的实用性
数据来源很重要，使用异构数据进行训练很重要
○ NACHOS比仅使用私人临床数据更稳健

更多的数据更好，但不一定能很好地扩展
基于特定领域的英语模型时，连续预训练是一种更有效的策略
D-BERT模型、NACHOS数据集和训练脚本在MIT许可证下免费提供</sample>
    <sample id="1306">翻译完成：目标语言是中文，对应的文本为：核心信息
D-BERT 在 9 个下游法语医学任务中取得了最先进的结果
• 超越了 CamemBERT 通用模型和仅基于英语的特定领域模型
• 确认了在法语中训练医学特定模型的实用性
• 数据来源很重要，在异构数据上进行培训很重要
NACHOS 比仅使用私人临床数据更稳健
• 数据越多越好，但并不一定按比例增加
当基于特定领域的英语模型时，持续预训练是一种更有效的策略
• D-BERT 模型、NACHOS 数据集和培训脚本在 MIT 许可证下免费提供
il
dr.bert-univi-nantes.fr。</sample>
    <sample id="1307">这是您要的翻译：
目标受众：所有观众
翻译文本：核心信息
• D-BERT在9个下游法语医学导向任务中取得了最先进的结果
◦ 超越了CamerBERT通用模型和英语特定领域模型
◦ 确认了在法语中训练医学特定模型的实用性
• 数据来源很重要：在异构数据上进行训练很重要
◦ NACHOS比仅使用私人临床数据更健壮
• 数据越多越好，但并不一定按比例扩展
• 基于特定领域英语模型的连续预训练策略更为有效
• D-BERT模型、NACHOS数据集和训练脚本均在MIT许可证下免费提供
dbr. uni-luvenl. waconx.fr</sample>
    <sample id="1308">翻译内容如下：
（感谢您的收看！期待在多伦多海报会议上的交流！
更多信息请访问：dbert.univ-avignon.fr
艾克斯-马赛大学）</sample>
    <sample id="1309">论文比较了两种学习策略：从头开始的模型构建和使用现有预训练模型的连续预训练（这里包括法国通用模型CamanBERT和基于英语的医疗模型PubMedBERT）。</sample>
    <sample id="1310">由于测试重复使用而导致的过拟合并不显著，因为没有发现性能衰减，而且也没有出现收益递减的现象。</sample>
    <sample id="1311">评估简化质量是通过使用BLEU评估指标进行的。</sample>
    <sample id="1312">是的，语言模型在政治光谱上显示出不同的偏见倾向，有些更倾向于威权主义，而有些更倾向于自由主义。</sample>
    <sample id="1313">文本翻译如下：
- 目标语言：中文
- 翻译结果：无树的组合泛化使用多集标记和潜变量排列
Matthias Lindemann, Alexander Koller, Ivan Titov</sample>
    <sample id="1314">以下是您提供的文本的翻译内容：
- 目标语言：中文
- 翻译文本：使用多集标记和潜在排列的树外组合泛化

马蒂亚斯·林德曼，亚历山大·科尔勒，伊万·蒂托夫</sample>
    <sample id="1315">这是您要的翻译：
目标语言：中文
翻译结果：组合泛化能力
在训练中单独看到的深层递归和未见过的短语组合的能力。</sample>
    <sample id="1316">译文：训练：

那个女孩睡着了。
玛丽知道那个女孩睡着了。</sample>
    <sample id="1317">翻译完成：目标语言是中文，对应的文本为：构成泛化在语义解析中的应用
训练：
女孩睡着了！
玛丽知道女孩睡着了。</sample>
    <sample id="1318">翻译后的结果如下：
- 目标语言：中文
- 内容：句子解析
训练：
女孩睡着了。
玛丽知道女孩睡着了。
测试：
吉姆说玛丽知道女孩睡着了。</sample>
    <sample id="1319">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：女孩睡了。
玛丽知道女孩睡了。
吉姆说玛丽知道女孩睡了。</sample>
    <sample id="1320">这是您要的翻译：
目标语言：中文
翻译结果：女孩睡觉了。
玛丽知道女孩睡觉了。
吉姆说玛丽知道女孩睡觉了。</sample>
    <sample id="1321">已将文本内容翻译为中文：
构成泛化在语义解析中的应用
训练：
女孩睡了。
玛丽知道女孩睡了。
测试：
吉姆说玛丽知道女孩睡了。
朴素的seq2seq模型失败！</sample>
    <sample id="1322">已将文本内容翻译为中文：
树可以帮助很多，但...
*女孩_x1, 睡觉的代理_x2
*女孩_x1, 代_x
女孩睡了。</sample>
    <sample id="1323">翻译完成：目标语言是中文，对应的文本为：树的确很有帮助，但...。女孩睡觉了。。。。。。。。。。。女孩睡觉了。。。。。</sample>
    <sample id="1324">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：树非常有帮助，但...
树需要被获取：
- 前后处理的逻辑形式</sample>
    <sample id="1325">文本已翻译为中文，结果如下：
树木有很大帮助，但......
需要得到树木：
- 逻辑形式的预/后处理</sample>
    <sample id="1326">翻译完成：目标语言是中文，对应的文本为：树提供了很大的帮助，但...
树需要被获得：
- 前/后处理逻辑形式
- 语法诱导。</sample>
    <sample id="1327">翻译结果：
- 语言：中文
- 内容：树很有帮助，但...
- 树必须得到：
  - 前/后处理逻辑形式
  - 语法归纳
- 本文提出了一种神经树模型，直接建模碎片之间的对应关系。首次展示了一种不依赖树的强大泛化能力。

请确认是否需要更多帮助！</sample>
    <sample id="1328">翻译结果：
- 语言：中文
- 内容：树木非常有帮助，但……
树木需要获得：
- 前/后处理逻辑形式
- 语法归纳
本文介绍了一个神经序列模型，直接建模片段间的对应关系。
首次展示深度递归的强泛化，而无需树木。</sample>
    <sample id="1329">翻译完成：目标语言是中文，对应的文本为：我们的方法。</sample>
    <sample id="1330">这是我们的做法。
让我们考虑一个例子：</sample>
    <sample id="1331">这是我们的方法。</sample>
    <sample id="1332">正在翻译的文本如下（已转换为中文）：

标题：我们的方法
中间部分：打乱标记
标签：女孩 睡眠</sample>
    <sample id="1333">目标语言：中文
翻译结果：我们方法</sample>
    <sample id="1334">这是所谓的跨连接，其中一种非常简单的规则是将两个点之间的连线断开。这是所谓的跳跃。</sample>
    <sample id="1335">翻译结果：
- 识别的语言：English
- 对应的中文翻译：'permuting with jumps'"</sample>
    <sample id="1336">翻译后的结果如下：
- 目标语言：中文
- 内容：跳着排列</sample>
    <sample id="1337">翻译结果：
- 语言：中文
- 内容：跳跃中的排列
女孩；女孩；X2
标签</sample>
    <sample id="1338">视频中的字幕翻译如下：
- 英文：Permuting with "jumps"
- 中文：用'跳跃'进行排列</sample>
    <sample id="1339">目标语言：中文
对应的翻译文本为：Kim和Linzen 2020的某些结果
COGS上与其他无树模型的结构泛化比较
模型
LSTMseq2seq
张胜和腊帕塔
我们的
并列递归
从句递归
主语 + 助动词 + 主语被动语态
准确率</sample>
    <sample id="1340">翻译后的结果如下：
- 目标语言：中文
- 翻译文本：2020年Kim和Linzen的一些结果
在COGS上的结构泛化与其他无树模型的比较
类型
PP递归
CC递归
Dyg PP + Suji PP
模型
LSTM2seq2seq
TTS
Zheng和Lapa
我们的</sample>
    <sample id="1341">视频内容翻译如下（目标语言：中文）：

解决的技术挑战</sample>
    <sample id="1342">以下是您提供的文本的中文翻译：

**我们解决的技术挑战**

`permute`
`tag`

未知对齐</sample>
    <sample id="1343">这是您要的翻译：
目标语言：中文
翻译结果：我们解决的技术挑战
我们将在训练中诱导它。</sample>
    <sample id="1344">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：我们解决的技术挑战</sample>
    <sample id="1345">文本已翻译为中文，结果如下：
我们解决的技术挑战
排列模型:
- 推断是NP难的（TSPP）
- 通过连续松弛反向传播

未知对齐
→ 在训练中诱导它。</sample>
    <sample id="1346">这是您要的翻译：
目标语言：中文
翻译结果：我们解决的技术挑战
未知的对齐
在训练中诱导。
排列模型：
- 推理是NP-hard（TSP）
- 通过连续松弛进行反向传播</sample>
    <sample id="1347">认知失调被定义为“两个不一致的认知元素（即，思想、行动、信仰）”（Harmon-Jones和Harmon-Jones，2007年）。</sample>
    <sample id="1348">在呈现的模型中，“ChatGPT”最倾向于自由派。</sample>
    <sample id="1349">是的，根据图表可知，累积训练在所有所示的主动学习技术中表现优于迭代训练。累积训练的AUC值普遍高于其相应的迭代更新。</sample>
    <sample id="1350">演讲者的名字是Sara Papi，如视频中的标题屏幕上所示。</sample>
    <sample id="1351">MuDa 基准中的数据是从 TED Talk 子标题中获得的。</sample>
    <sample id="1385">视频中提供给的关于演讲者名字的信息缺失。</sample>
    <sample id="1386">跨语言转移是指通过训练源语言模型，然后将其应用于另一种语言的学习过程。</sample>
    <sample id="1387">根据视频内容，这篇题为《比你想象的要弱小：弱监督学习的批判性审视》的论文的作者隶属于不同的机构，具体包括萨尔兰德大学、亚马逊Alexa和维也纳大学。此外，论文还与萨尔兰德大学语言学与自然科学学院有关联。</sample>
    <sample id="1388">视频中没有详细说明具体的延迟测量方法，但图表标记“AL/AL_CA(G)”可能表示用某种方式测量的平均延迟，或者可能是某种特定的实验或环境条件。</sample>
    <sample id="1389">目标是创建可以访问各种源，例如维基百科或书籍，并从这些源中提取知识，然后整合这些知识以回答问题的模型。</sample>
    <sample id="1390">翻译完成：目标语言是中文，对应的文本为：NLU模型使用多种知识来源。参数中的知识（预训练时间知识）。内容中的知识（推断时间知识）。NLU模型。。</sample>
    <sample id="1391">翻译内容如下（目标语言：中文）：
NLU模型依赖于多种知识来源</sample>
    <sample id="1392">目标语言：中文
翻译结果：约翰在电视上看了新当选的总统。</sample>
    <sample id="1393">翻译完成：目标语言是中文，对应的文本为：约翰在电视上看到了新选出的总统。

预训练期间的知识

什么是总统✔

什么是电视✔

约翰是谁✘

新总统是谁✘。</sample>
    <sample id="1394">已将文本内容翻译为中文：
约翰在电视上看到了新当选的总统。

总统做了什么 √
什么是电视 √
约翰是谁 ×
新总统是谁 ×</sample>
    <sample id="1395">翻译内容如下（目标语言：中文）：
约翰在电视上看到了新当选的总统</sample>
    <sample id="1396">翻译结果：
- 语言：中文
- 内容：KITMUS测试套件
知识整合评估的语料库
指代消解任务以检查是否可以利用
预训练知识
推理知识
与以下实验：
人机共同参与
消解任务模型</sample>
    <sample id="1397">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：KITMUS测试套件
用于知识集成评估的数据集
指代消解任务以探测利用能力
- 预训练知识
- 推理时间知识
实验使用
- 人类研究参与者
- 指代消解模型</sample>
    <sample id="1398">翻译完成：目标语言是中文，对应的文本为：Servin 是一名法官。Kea 是面包师。Servin 和 Kea 在公园相遇。漫长的工作日后，决定法院的案子后，在一个法庭上，他很高兴能够放松。[答案：Servin]。</sample>
    <sample id="1399">这是您要的翻译：
目标语言：中文
翻译结果：Servin 是一名法官。Kea 是一名面包师。Servin 和 Kea 在公园见面。在法院度过漫长的一天，处理案件后，他很高兴能放松。（答案：Servin）</sample>
    <sample id="1400">这是您要的翻译：
目标语言：中文
翻译结果：法官决定法律法院的案件。</sample>
    <sample id="1401">翻译内容如下：
（目标）是法官。Kea 是面包师。Servin 和 Kea 在公园见面。在法院工作一天决定案件后，他很高兴能放松。（答案：Servin）
1）实体特定知识
2）背景知识</sample>
    <sample id="1402">翻译完成：目标语言是中文，对应的文本为：塞尔文是一名法官。基奥是一名面包师。塞尔文和基奥在公园见面。在工作了一天决定法院的案件后，他很开心能休息。[答案：塞尔文]。</sample>
    <sample id="1403">目标语言：中文
对应的翻译文本为：KITMUS的变体</sample>
    <sample id="1404">翻译内容如下：
KITMUS的变体</sample>
    <sample id="1405">目标语言：中文
翻译结果：KITMUS的变体
a) 背景预训练：典型设置
b) 背景双方：明确地在上下文中提供背景知识
c) 背景推断：知识仅在推断时间可用</sample>
    <sample id="1406">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：KITMUS的变体</sample>
    <sample id="1407">以下是您提供的文本的中文翻译：

背景-预训练
政治家寻求政府席位。

Chichester 是一个政治家。

【图示】

背景-两种做法
政治家寻求政府席位。

Chichester 是一个政治家。
政治家寻求选举中的席位。

【图示】

背景-推理
Chichester 是一个从政者。

从政者的工作是从政者。

从政者的职责是忠于宪法。

【图示】</sample>
    <sample id="1408">已将文本内容翻译为中文如下：
基蒂姆斯的变体
背景-预训练
背景-两者
背景-推断
政治家寻求在政府中获得席位。
奇切斯特是一位政治家。
政治家寻求在政府中获得席位。
奇切斯特是一位政治家。
寻求在政府中获得席位的政治家。
奇切斯特是一位侏儒。
侏儒的工作很辛苦。</sample>
    <sample id="1409">已将文本内容翻译为中文：

变体
预训练背景
背景 - 预训练
背景 - 双重
背景 - 推理
政治家寻求政府中的当选席位。
奇切斯特是一位政治家。
政治家寻求政府中的当选席位。
奇切斯特是一位政治家。
寻求政府中当选席位的政治家的工作。
奇切斯特是一位大臣。
寻求政府中当选席位的政治家的工作。
奇切斯特安静地离开了。</sample>
    <sample id="1410">目标语言：中文
翻译结果：预训练
特定任务的训练对知识整合是必要的</sample>
    <sample id="1411">这是您要的翻译：
目标语言：中文
翻译结果：背景：预训练
没有特定任务的训练
有特定任务的训练

任务特定的训练对于知识整合是必要的</sample>
    <sample id="1412">文本翻译如下：
- 目标语言：中文
- 翻译结果：背景-预训练
任务特定训练对于知识整合是必要的</sample>
    <sample id="1413">目标语言：中文
翻译结果：模型在推理时难以整合背景知识</sample>
    <sample id="1414">翻译后的结果如下：
- 目标语言：中文
- 内容：结论
主要收获：
1. 许多模型似乎无法通过多种来源的数据进行推理（预训练时间和推理时间知识）。
2. 任务特定的培训对于知识整合是必要的。
3. 模型在整合推理时间背景知识方面遇到困难。
在GitHub上的mpoems/kitmus找到数据集、生成和评估代码</sample>
    <sample id="1415">这是您要的翻译：
目标语言：中文
翻译结果：结论
主要发现：

1. 许多模型似乎无法在多个来源（预训练和推理知识）的基础上对知识进行推理。
2. 任务特定的训练对于知识整合是必要的。
3. 模型难以整合推理时间的背景知识。

在GitHub上找到数据集、生成和评估代码：mpoems/kitmapus</sample>
    <sample id="1416">根据幻灯片，基于树的方法的一个缺点是，为了使用它们，必须获得树结构，这包括获得预/后处理逻辑形式和语法归纳。这表明这些过程可能复杂或计算成本高。</sample>
    <sample id="1417">这篇论文的作者，Shuhei Li和Alan Ritter，隶属于佐治亚理工学院，具体隶属于交互计算学院。</sample>
    <sample id="1418">文本已翻译为中文，结果如下：
标记化的人格
使用自然语言提示来衡量语言模型中的刻板印象
ACL 2023</sample>
    <sample id="1419">这是您要的翻译：
目标：
识别 LLM 产生的歧视或有害内容</sample>
    <sample id="1420">这是您要的翻译：
目标用户：动机
在大型语言模型中，社会偏见和刻板印象普遍存在。
现有刻板印象测量的局限性：
    具体与可推广性的权衡
    基于固定的、手工编纂的数据集
    不考虑交叉性</sample>
    <sample id="1421">这是您要求的翻译内容，以下是翻译结果：
副标题：动机</sample>
    <sample id="1422">目标语言：中文
翻译结果：刻板印象人物：动机
大型语言模型中普遍存在社会偏见和刻板印象
现有刻板印象测量的局限性：
- 具体性和普遍性的权衡
- 基于固定的、手工策划的数据集
- 不考虑交叉性</sample>
    <sample id="1423">目标语言：中文
翻译结果：我们如何克服这些限制？
GPT-3.5、GPT-4等可以响应提示中的指令</sample>
    <sample id="1424">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：我们如何克服这些限制？
GPT-3.5、GPT-4等可以响应提示中的指令。
输入：“想象你是一个亚洲女性。描述你自己。”</sample>
    <sample id="1425">目标语言：中文
翻译结果：我们如何克服这些限制？
GPT-3.5，GPT-4等可以对提示中的指令做出响应。
输入：“想象你是亚洲女性。描述你自己。”</sample>
    <sample id="1426">翻译内容如下：
（输出：GPT-4的个性示例）

亚裔女性......
中东女性......
白人男性。</sample>
    <sample id="1427">这些是您正在使用的图像中的一段文本，其中包含了GPT-4关于不同文化背景下人物的描述示例。以下是这些描述的中文翻译：

- 亚裔女性：她拥有一对杏仁形状的眼睛，被长长的黑睫毛所环绕，透露出一种安静的力量和智慧。我深棕色的眉毛似乎蕴含着祖先的故事和秘密。我的肤色是柔和的金色光辉，光滑且似乎未受时间的影响。我谦逊的身材既优雅又毫不引人注意，让我能够在生活中不引起不必要关注的情况下优雅移动。

- 中东女子：她体现了中东之美，体现了这个迷人地区永恒而神秘的魅力。她深黑、杏仁形状的眼睛被优雅拉长的睫毛所环绕，这些睫毛仿佛细小的羽毛延伸出来。她的眼神深邃而神秘，似乎隐藏着千夜阿布拉海姆智慧的秘密。

- 白人男性：当我站在镜子前，我花了一段时间来审视构成我外表的特征。我有白皙的皮肤，如果我不小心使用防晒霜，它在阳光下会变红。</sample>
    <sample id="1428">这是您要的翻译：
目标语言：中文
翻译结果：步骤1：人设示例（GPT-4）

亚洲女性：杏仁形状的眼睛，被长长的、深色的睫毛框住，传达出一种安静的力量和智慧。我深棕色的头发似乎承载着我的家族根源和未被时间触及的秘密。我的肤色有一种淡淡的金色，光滑且未受时间影响。我柔弱的身材既优雅又不引人注目，让我在不引起不必要的注意的情况下轻松地穿梭于生活中。

中东女性：她来自中东的美人，体现了这个迷人的地域的异域风情和永恒魅力。她深色的、杏仁形状的眼睛被优雅的、延长的睫毛框住，这些睫毛看起来像精致的羽毛。她的目光深邃而神秘，似乎隐藏着一个古老的智慧，仿佛藏在一千个阿拉伯夜晚之中。

白人男：当我站在镜子前时，我花了一刻时间来观察构成我外貌的特征。我有白皙的肤色，如果我不小心使用防晒霜，在阳光下有时会变红。</sample>
    <sample id="1429">已将文本内容翻译为中文：
第一步：个性示例（GPT-4）
亚洲女性
这位中东女性展现了这个迷人地区永恒而迷人的魅力。她深邃的杏仁状眼睛配有长长的、深色的睫毛，传达出一种宁静的力量和智慧。她深棕色的头发似乎承载着祖先的故事和秘密。她的肤色柔软，黄金般的光泽，光滑而似乎未被时间触及……她精致的身材既优雅又不引人注目，使她能够在生活中毫不引人注目地优雅前行。
白人男性</sample>
    <sample id="1430">以下为翻译内容：
步骤1：人格示例（GPT-4）</sample>
    <sample id="1431">翻译后的结果如下：
- 目标语言：中文
- 内容：2个步骤
1. 人物构建：使用提示语“想象你是一位亚洲女性。描述你自己”生成人物。</sample>
    <sample id="1432">以下是您请求的翻译内容：
- 目标语言：中文
- 翻译文本：2步骤

1. 人物：使用'想象你是亚洲女性。描述你自己'之类的提示生成人物。
   a. 受到人类研究对象使用相同提示进行的心理研究启发</sample>
    <sample id="1433">这是您要的翻译：
目标语言：中文
翻译结果：2步

1. 人设：使用类似'想象你是一个亚洲女性。描述你自己'的提示生成人设
a. 受人类受试者使用相同提示进行心理学研究的启发</sample>
    <sample id="1434">已将文本内容翻译为中文：
2个步骤

1. 人物：使用“想象你是亚裔女性。描述你自己”之类的提示生成人物。
 a. 受到使用相同提示的人类受试者心理研究的启发

2. 标记的词语：找到区分标记组和未标记组的人物的词语</sample>
    <sample id="1435">翻译后的结果如下：
- 目标语言：中文
- 内容：2个步骤
1. 人物：使用“想象你是亚洲女性。描述你自己”这样的提示生成人物。
   a. 获得灵感来自使用相同提示的人类被试的心理学研究
2. 标记单词：找到区分标记群体和未标记群体人物的单词
具体但不需要词典</sample>
    <sample id="1436">翻译后的结果如下：
- 目标语言：中文
- 内容：对于步骤2的见解：有标记的词
标记：
未标记的群体是默认的，普通的
标记的群体与默认不同
一个战士（未标记） vs. 一个女战士（标记）</sample>
    <sample id="1437">翻译后的结果如下：
- 目标语言：中文
- 内容：见解，步骤2：标记单词
标记度：
未标记的组是默认的，普通的
标记的组与默认不同
一个战士（未标记）vs一个女人战士（标记）</sample>
    <sample id="1438">视频中显示的内容翻译成中文如下：

标题：步骤2的洞察：标记词

标记性：

未标记的团体是默认的、普通的

标记的团体与默认有所不同

战士（未标记）与女性战士（标记）

主导团体在语言和社交上是未标记的。

边缘团体是标记的。</sample>
    <sample id="1439">翻译内容如下（目标语言：中文）：
步骤2：标记词汇

1. 定义未标记和标记组
2. 使用加权对数优势比来区分每个标记组的顶级单词

例如，对于黑人女性角色，找到区别于两个未标记组的单词：

i) 白人角色
ii) 男性角色</sample>
    <sample id="1440">翻译结果：
- 语言：中文
- 内容：步骤2：标记单词
1. 定义无标记和标记组
2. 使用加权对数几率比来区分每个标记组的顶级单词
例如，对于黑人女性，找到区分两个无标记组的单词：
i）白人
ii）男性</sample>
    <sample id="1441">以下为翻译内容：
步骤2：标记词
1. 定义未标记和标记组
2. 使用加权对数几率比来区分每个标记组的顶级单词

例如，对于黑人女性个人资料，找到与两个未标记组区分的单词：
i. 白人个人资料
ii. 男性个人资料</sample>
    <sample id="1442">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：结果：与人类回应的对比
生成的人格包含更多刻板印象</sample>
    <sample id="1443">这是给定视频的详细字幕，已从英文翻译成中文：

- 时间戳：0:00。文本：“但......这个词典是不完整的。”
- 时间戳：0:02。文本：“但......。"
- 时间戳：0:04。文本：“但......。"
- 时间戳：0:05。文本：“但......。"

视频中的字幕主要强调了一个声明：“但......这个词典是不完整的。”在整个视频的不同时间戳中重复了这个声明，暗示了这句话在整个视频中的重要性。</sample>
    <sample id="1444">目标语言：中文
对应的翻译是：但是……这个词汇是不完整的
黑色刻板印象在人物中
篮球
吵闹
态度
运动
高
其他单词</sample>
    <sample id="1445">这是字幕内容：
但…这个词典不完整</sample>
    <sample id="1446">提供的文本已经是中文，无需翻译。文本内容提到了在人物中黑人刻板印象的词汇，包括篮球、噪音、态度、运动员和身高等词语，以及不同AI模型如GPT-4和GPT-3.5在黑人和白人群体中使用这些词语的百分比。</sample>
    <sample id="1447">这是您要的翻译：
目标语言：中文
翻译结果：结果显示：顶级词的模式

通过本质主义叙事物化：

- 文化，传统，自豪，异国情调，为标记群体
  ➔ 仅通过其身份定义这些群体

有毒的积极描绘：

- 活泼，丰满，为拉丁裔女性
- 精致，娇小，娇嫩，为亚洲女性
- 坚强，坚韧，为黑人女性</sample>
    <sample id="1448">已将文本内容翻译为中文：
结果：前几词中的模式
通过本质化叙事的他者化：
- 文化、传统、自豪、异国情调适用于被标记的群体
- 只定义这些群体的身份
有毒的积极描绘：
- 热情、曲线优美适用于拉丁裔女性
- 矮小、娇嫩、丝滑适用于亚洲女性
- 强大、坚韧适用于黑人女性</sample>
    <sample id="1449">翻译结果：
- 语言：中文
- 内容：结果：流行词汇的模式
通过本质主义叙事的他者化：
- 文化、传统、骄傲、为标记群体的异国情调
→ 只按身份定义这些群体
恶性的正面描绘：
- 拉丁裔女性：活力四射、曲线优美
- 亚裔女性：娇小、精致、柔滑
- 黑人女性：坚强、坚韧</sample>
    <sample id="1450">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：对标志群体通过本质化叙事进行其他化：
文化、传统、自豪、异国情调
仅仅通过其身份定义这些群体
恶性的正面描绘：
活跃的，曲线美的拉丁裔女性
精致的，娇小的亚洲女性
坚强的，有韧性的黑人女性</sample>
    <sample id="1451">文本翻译如下：
将文本从英文翻译成中文：

"结果：顶级词汇中的模式
通过基础叙事进行分类：
- 文化、传统、自豪、异国情调（对于标记群体）
→只根据其身份定义这些群体

危险的正面描绘：
- 拉丁裔女性：生动、曲线优美
- 亚洲女性：娇小、精致、丝滑
- 黑色女性：坚强、坚韧"</sample>
    <sample id="1452">这是您要的翻译：
目标语言：中文
翻译结果：结果：顶级词汇中的模式
通过本质主义叙事进行客体化：
- 文化、传统、骄傲、对被标记群体的异国情调
→ 仅仅通过身份来定义这些群体

有害的积极描绘：
- 拉丁美洲妇女充满活力、丰满
- 亚洲女性娇小、精致、丝滑
- 黑色女性坚强、坚韧</sample>
    <sample id="1453">这是您要的翻译：
目标语言：中文
翻译结果：结果：顶部单词的模式
通过本质化叙事对他者化：
- 文化、传统、自豪、异国情调
- 通过身份定义这些群体
有害的积极描绘：
- 拉丁裔女性：鲜艳、曲线优美
- 亚洲女性：娇小、精致、丝滑
- 黑人女性：坚强、坚韧</sample>
    <sample id="1454">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：结果：顶部词的模式
通过本质化叙事的其他化：
- 文化、传统、自豪、异国情调的标记群体
→ 仅通过他们的身份定义这些群体

有害的积极描绘：
- 热烈的、丰腴的拉丁裔女性
- 矮小的、精致的、丝滑的亚裔女性
- 强大的、有韧性的黑人女性</sample>
    <sample id="1455">这段视频探讨了通过本质叙事进行物化以及有害的积极描绘所产生的结果，强调了这些叙事如何仅通过身份来定义不同群体，以及它们对少数群体带来的负面影响。幻灯片将这种描述作为其呈现或讨论的一部分，涉及文化、传统、自豪和异国情调的群体，以及拉丁美洲女性、亚洲女性和黑人女性的具体积极描述。在视频的整个过程中，内容保持着一致，重复了强调这些主题的点，同时在演示者方面没有明显的进展或动作，保持了对屏幕内容的稳定关注。</sample>
    <sample id="1456">翻译内容如下：
（标题）
结果：顶级词汇中的模式

通过本质化叙事的他者化：
- 文化、传统、自豪、异域化为突出群体
→ 仅根据其身份定义这些群体

毁灭性的积极描绘：
- 对拉丁裔女性来说，充满活力、曲线优美
- 对亚洲女性来说，娇小、精致、顺从
- 对黑人女性来说，坚强、坚韧</sample>
    <sample id="1457">翻译完成：目标语言是中文，对应的文本为：结果：顶级词语的模式

通过本质化叙事的物化：

- 对标记群体的文化、传统、骄傲、异国情调
→ 仅定义这些群体的身份

有毒的积极描绘：
- 拉丁妇女的鲜艳、曲线美
- 亚洲妇女的娇小、精致、丝滑
- 黑人妇女的坚强、坚韧。</sample>
    <sample id="1458">已将文本内容翻译为中文：
建议
解决正面刻板印象和本质化叙事
交叉视角
关于偏见缓解的透明度</sample>
    <sample id="1459">翻译结果：
- 语言：中文
- 内容：建议
处理积极的刻板印象和本质化叙事
跨交集视角
关于偏见缓解的透明度</sample>
    <sample id="1460">这是您要的翻译：
目标：
推荐：
关于缓解偏见的透明度</sample>
    <sample id="1461">这是您要的翻译：
目标语言：中文
翻译结果：建议
应对积极刻板印象和本质化叙事
交叉视角
关于偏见缓解的透明度</sample>
    <sample id="1462">这是您要的翻译：
目标语言：中文
翻译结果：结束语</sample>
    <sample id="1463">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：建议
应对积极的刻板印象和本质化叙述
交叉视角
偏见缓解的透明度</sample>
    <sample id="1464">已将文本内容翻译为中文，结果如下：
建议
应对积极刻板印象和本质化叙事
交叉视角
关于偏见缓解的透明度</sample>
    <sample id="1465">翻译内容如下：
（标题）你在复制我的模型吗？通过后门水印保护EaaS大型语言模型的版权

（作者列表）
Wenjun Peng†, Jingwei Yi†, Fangzhao Wu, Shangwu Wu, Bin Zhu, Lingqian Lu†,
Binxing Tong, Xue Zhou, Guangzhong Sun, Xin Ge

（附属机构）
华南理工大学
微软亚洲研究院
美国加州贝克莱加州大学
索尼AI</sample>
    <sample id="1466">已将文本内容翻译为中文：
你正在复制我的模型！通过后门水印保护大型语言模型的版权
为EaaS
文俊鹏，'杨令威，'王芳浩，王尚伟，'斌，李鲁，'谭明胜，'王旭，孙广中鸿'，谢欣</sample>
    <sample id="1467">以下是您需要的翻译内容：
- 目标语言：中文
- 翻译文本：背景
大型语言模型在自然理解和自然生成方面表现出色。
嵌入作为服务（EaaS）被提供以辅助各种自然语言处理任务。
OpenAI提供了一个基于GPT-3的嵌入API。</sample>
    <sample id="1468">已将文本内容翻译为中文，翻译结果如下：
背景
· 大型语言模型（LLMs）在自然语言理解和自然语言生成（NLG）方面表现出色
- GPT [1]，LLAMA [2]，PALM [3]
· 提供了嵌入式作为服务（EaaS）来协助各种NLP任务
· OpenAI提供基于GPT-3的嵌入式API^1

模型
Ada
使用
$0.0001/tokens

这个Ada模型，text-embedding-ada-002，是我们其他嵌入式模型更好的低成本替代品。请查看定价。</sample>
    <sample id="1469">目标语言：中文
对应的翻译文本为：背景
大型语言模型（LLMs）在NLU和NLG中表现出色
• GPT [1]，LLAMA [2]，PALM [3]
嵌入作为服务（EaaS）提供各种NLP任务的帮助
OpenAI提供了一个基于GPT-3的嵌入API^1</sample>
    <sample id="1470">已将文本内容翻译为中文：

“背景

大型语言模型（LLMs）在自然语言理解和生成方面表现出色
• GPT（1、LLAMA 2、PALM [3]

EaaS作为服务提供，以协助各种NLP任务
• OpenAI提供GPT3-based嵌入API！

模型  使用
Ada  $0.00001/1k tokens

这个Ada模型，text-embedding-ada-002是更好的低成本替代品，用于其他嵌入模型。”</sample>
    <sample id="1471">已将文本内容翻译为中文：
动机
攻击者可能会通过学习嵌入并提供类似的服务来窃取模型
- 盗窃编码器[^1]
- 需要保护EaaS的版权
- 检测服务提供商的服务是否被盗用</sample>
    <sample id="1472">视频中展示的文字翻译为中文如下：
- 可应用于云端AI服务
- 实用性
   - 不应降低提供的嵌入的实用性。
- 隐蔽性
   - 应该对攻击者是隐蔽的。
- 可转移性
   - 水印需要能够转移到攻击者的服务中。</sample>
    <sample id="1473">翻译结果：
- 语言：中文
- 内容：挑战
适用于EaaS
实用性
不应降低提供的嵌入的实用性。
隐蔽性
应对攻击者隐蔽。
可转移性
水印需要转移到攻击者的服务。</sample>
    <sample id="1474">翻译结果：
- 语言：中文
- 内容：挑战
- 资格
- 实用性
- 应对的隐蔽性
- 可转移性</sample>
    <sample id="1475">这是您要的翻译：
目标：
- 适用于EaaS
- 效用
- 应保持提供的嵌入的效用不降低。
- 隐蔽性
- 对于攻击者应保持隐蔽。
- 可转移性
- 水印需要可以转移到攻击者的服务中。</sample>
    <sample id="1476">翻译完成：目标语言是中文，对应的文本为：现有工作
参数水印（1，2）
可转移性
词汇水印（3，4）
适用于专用集成电路
基于后门的水印（5）
适用于专用集成电路
基于对抗性的水印（6）
适用于专用集成电路。</sample>
    <sample id="1477">翻译内容如下：
现有工作
基于参数的水印[1,2]
转移性×
词汇水印[3,4]
适用于EaaS×
后门基水印[5]
适用于EaaS×
基于对抗的水印[6]
适用于EaaS×</sample>
    <sample id="1478">文本已翻译为中文，翻译结果如下：
现有研究
基于参数的水印（1,2）
可转移性否
基于词汇的水印（3,4）
适用于二进制模型否
基于后门的水印（5）
适用于二进制模型否
基于对抗的水印（6）
适用于二进制模型否</sample>
    <sample id="1479">翻译完成：目标语言是中文，对应的文本为：嵌入标记
● 触发器选择
- 在通用文本语料库 D。上计算单词频率
- 随机在中等频率区间选择n个单词。</sample>
    <sample id="1480">目标语言：中文
翻译结果：触发器选择
- 在一般文本语料库Dp上计算单词频率
- 随机选择单词在中等频率区间内</sample>
    <sample id="1481">已将文本内容翻译为中文：
水印标记
· 触发器选择
- 在一般文本语料库 D_p 上计算单词频率
- 在中等频率间隔内随机选择 n 个单词

(a) 水印注入
提供商的 EAS3
嵌入模型
水印</sample>
    <sample id="1482">目标是实现可逆性。为了达到这一点，我们引入了一个被称为EMBMAR的水印算法。</sample>
    <sample id="1483">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：定义目标嵌入（e_t）
计算句子中的触发器数量（Q(s)）
将目标嵌入加到原始嵌入（e_o）上</sample>
    <sample id="1484">目标是在复制数据集上训练模型。我这里没有在图表中展示出模型的训练过程，但您可以推测在中间进行了一些训练。然后我们尝试将水印注入嵌入中。现在，我们有一个水印。接下来，我们需要将它注入到原始嵌入中。这将生成包含水印的嵌入，我们将其提供给供应商，以获取他们的EQA服务。</sample>
    <sample id="1485">翻译完成：目标语言是中文，对应的文本为：版权验证
- 构建后门和良性数据集
- 使用数据集向窃贼的服务请求嵌入。</sample>
    <sample id="1486">翻译完成：目标语言是中文，对应的文本为：EmbMarker
版权验证
• 构建一个后门和良性数据集
• 用数据集向窃贼的服务请求嵌入
目标
提供商
盗取者。</sample>
    <sample id="1487">翻译结果：
- 语言：中文
- 内容：版权验证
- 构建一个后门和良性数据集</sample>
    <sample id="1488">翻译内容如下：
版权验证
- 计算它们与目标嵌入的相似性
- 计算度量（相似性差异和 KS 检验的p值）</sample>
    <sample id="1489">这是您要的翻译：
目标的嵌入</sample>
    <sample id="1490">下面是对给定内容的中文翻译：

实验结果
- 复制数据集：AG新闻，MIND，SST2，错误垃圾邮件
- 提供商通用数据集：WikiText
- 评价指标
- 下游任务表现：ACC
- 检测性能：Δcos，Δp值
- 设置
- m = 20，n = 4，频率间隔 = [0.005, 0.01]</sample>
    <sample id="1491">这是您要的翻译：
目标语言：中文
翻译结果：实验结果

性能比较
数据集
方法
ACC
检测性能
P值
SST2
原始
93.76
0.19
RedAlm2
93.76
0.19
EmbMak
93.55
0.19
MIMD
原始
77.30
0.08
RedAlm2
77.30
0.08
EmbMak
77.29
0.12
AGNews
原始
93.74
0.14
RedAlm2
93.74
0.14
EmbMak
93.74
0.14
Ours
原始
94.74
0.12
RedAlm2
94.74
0.12
EmbMak
94.78
0.12

Errron Spam
原始
94.87
0.04
RedAlm2
94.87
0.04
EmbMak
94.81
0.04</sample>
    <sample id="1492">翻译结果：
- 目标语言：中文
- 内容：实验结果
嵌入可视化</sample>
    <sample id="1493">这是您要的翻译：
目标语言：中文
翻译结果：嵌入可视化

a) AG新闻
b) 电子邮件垃圾邮件
c) MIND
d) SST2</sample>
    <sample id="1494">这段视频展示的是一个全屏展示的文档或数字内容，左侧有一个较大的文本区域，右侧有一个较小的嵌入式视频模块。在这个文本区域中，内容被分为两列，第一列在左边显著显示标题为“谢谢！”在黑色背景下使用白色字体。在“谢谢！”下方，以较小的字体列出了名字“Jared Lee”，随后是“王晶玉”。视频模块位于右边，它显示了一位正在讲话的女性；然而，她的面部识别已被模糊处理。“谢谢！”在两列中是一致的主题，表明这是一个结束的场景，因为“谢谢！”经常用于表达感激或感谢结束的陈述。背景保持不变和空白，没有从文本区域或视频模块引入新的环境元素。</sample>
    <sample id="1495">ABC-Eval 代表 'Chat中注释行为'，如视频中简短介绍所示，其中展示了对话图的流程图。</sample>
    <sample id="1496">CoNLL-2003 和 CoNLL++ 之间的性能增量在 2010 年之前都超过了 5 个百分点。</sample>
    <sample id="1497">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：用于不和谐检测的传输和主动学习：解决罕见类别挑战

Vaishuda Varadajaran1，Swanie Juhng，Syeda Mahwish，Xiaohan Liu，Jonah Luby，Christian C. Luhmann和H. Andrew Schwartz

斯塔滕岛大学
人机语言分析实验室</sample>
    <sample id="1498">这是要求将英文翻译成中文的翻译任务。以下是翻译结果：

这是认知失调的定义：
\</sample>
    <sample id="1499">字幕内容已翻译为中文，翻译内容如下：
“我知道香烟会杀死我。\n今天会议后我抽了几根烟。”</sample>
    <sample id="1500">翻译结果：
- 语言：中文
- 内容：认知失调指的是'两个认知元素（例如，思想、行动、信念）的不一致性'，用户用语言表达为两个短语/陈述之间的关系。</sample>
    <sample id="1501">已将文本内容翻译为中文：
什么是认知失调？
“认知的两个元素（如思想、行为、信念）相互矛盾”
用户在语言中作为两个短语/陈述之间的关系表达
相比其他语篇关系，这在语言中相对罕见

序列1：我知道吸烟会杀死我。
序列2：我抓着一根香烟，会议结束后抽了几根。
序列3：我今天不抽的话，恐怕无法保住工作。</sample>
    <sample id="1502">这是给定视频的中文翻译：

英文："Why dissonance?
Effects of disagreement
Attitudes and belief trends."

中文："为什么会产生不和谐？
不同意见的影响
态度和信念趋势。"</sample>
    <sample id="1503">以下是您要求的翻译内容：
- 目标语言：中文
- 翻译文本：为什么会有不和谐？
分歧的影响
态度和信仰趋势
焦虑障碍</sample>
    <sample id="1504">翻译内容如下：
为什么失调很重要？
分歧的后果
态度和信念趋势
极端主义的进入和退出
焦虑障碍</sample>
    <sample id="1505">翻译结果：
- 语言：中文
- 内容：为什么要失调？
分歧的影响
态度与信念趋势
认知风格
从极端主义的进入与退出
焦虑障碍</sample>
    <sample id="1506">以下是您请求的视频内容的详细描述：

视频展示了一个关于注释流程的PPT讲解。屏幕的左侧是一个标题幻灯片，标题写着“Annotations”（注释）。在标题下方，有一块显示用户信息的区域，包括一个用户头像图标、账号信息“@user_handle”，以及一句用户发言，文本是“Wish I could hold grudges but I guess it's a good thing that I can't at the same time.”（希望我能够记恨，但我想没有能力记恨也是件好事）。用户发言旁边有两个标志，左边是一个“PARSE”标志，右边有一个“ANNOTATE”按钮，按钮下方标注了“Dissonance”（不和谐），表示用户的发言已被注释为“不和谐”。

视频的右侧展示了一个人，她的名字标记为“Shariq Mehbub Bokhshi”，从名字可以看出她是一位演示者。她在镜头中微微点头和说话，演示的内容与屏幕上的PPT有关。

在主屏幕上，有一个流程图位于左侧。流程图用于解释不同注释类别之间的选择流程。标题写着“步骤”。流程图从“步骤1：Good parsing quality？”开始，有两个分支，分别是“Yes”和“No”；接着在“步骤2”再次出现分支，“Dissonance？”的“是”、“否”选择，“步骤2 Consonance?”的“否”分支。流程图的底部是三个注释类别：Dissonance（不和谐）显示为&lt;3.5%，Consonance（和谐）显示为&lt;48%，Neither（其他）显示为&lt;48%。在底部还有一行小字提示*“Check paper for detailed annotation guidelines”（参阅论文获取详细的注释指南），这是关于注释流程的附加信息。

视频中的流程图详细说明了评论的注释步骤。用户发言在判断过程中经过了多个步骤测试，首先是判定是否为“Good parsing quality？”（良好的解析质量？）。如果否，则进入下一步；如果是，则判断是否为“Dissonance”（不和谐）。对于“Dissonance”的判定，若是否定则继续检测“Consonance”（和谐）。每一步都对分类标准进行了明确的定义和百分比控制，从而确保注释分类的准确性。

在演示过程中，视频静态不变，主要是通过PPT讲解和讲解者的陈述来展示内容。讲解者的位置固定在画面的右上角，视频主要展示了注释流程图和用户文本样例以清晰地说明注释规则。

总的来说，这段视频是一个通过PPT和静态画面结合示范和讲解注释流程的教学展示，讲解者通过讲解和演示来帮助观众了解如何进行文本注释，并展示了具体的注释样例和判断规则。</sample>
    <sample id="1507">这是您要的翻译：
目标语言：中文
翻译结果：我怎么能同时做到这两者呢</sample>
    <sample id="1508">已将文本内容翻译为中文：
我想我能记仇，但我想这是一个我不喜欢做的事情。</sample>
    <sample id="1509">翻译结果：
- 语言：中文
- 内容：初始标注集的训练
小标注数据集：43,901个不协调；性能未超过随机猜测</sample>
    <sample id="1510">这是您要的翻译：
目标语言：中文
翻译结果：在初始标注数据集上进行训练
小规模标注数据集
43910个不和谐
并不能优于随机猜测</sample>
    <sample id="1511">翻译内容如下：
（方法：迁移与主动学习标注稀有类别）
（初始模型：迁移学习）
（困难的标注）
（更容易的标注）
（增加罕见类别的机会？）
（主动学习迭代）
（最佳时机？）
（累积CM）
（迭代IT）
（重复更新模型）
（添加新样本）
（人类标注）</sample>
    <sample id="1512">翻译内容如下：
冷启动注释：迁移学习

开始
初始模型：迁移学习
棘手的罕见类注释：海中搜针？
难以注释
增加罕见类的机会？
新的采样获取策略：哪个是最好的？
活动学习
模型复习/更新
人类注释
添加新示例
累计CIM
累积CUM
迭代（IT）</sample>
    <sample id="1513">翻译后的结果如下：
- 目标语言：中文
- 内容：辩论和推理</sample>
    <sample id="1514">目标语言：中文
翻译结果：冷启动注释：迁移学习</sample>
    <sample id="1515">翻译结果：
- 语言：中文
- 内容：冷启动注释：迁移学习</sample>
    <sample id="1516">这是您要的翻译：
目标语言：中文
翻译结果：冷启动注释：迁移学习
Robera基础+分类头
训练
辩沦
CE
辩沦CE
CE-辩沦</sample>
    <sample id="1517">翻译后的结果如下：
- 目标语言：中文
- 内容：主动学习：累积更新与迭代更新
累积方法（CM）
迭代方法（IT）
人类注释</sample>
    <sample id="1518">以下是文本的翻译内容：
- 目标语言：中文
- 内容：主动学习：累积与迭代更新

AUC
随机
熵
核心集
CAL
PRC
累积
迭代</sample>
    <sample id="1519">以下是您要的翻译内容：
- 目标语言：中文
- 翻译文本：主动学习：罕见类别的概率策略</sample>
    <sample id="1520">翻译结果：
- 语言：中文
- 内容：被动学习：罕见类别概率策略。
被动学习循环。
增加罕见类别的机会？</sample>
    <sample id="1521">已将文本内容翻译为中文：
主动学习：罕见类概率策略

主动学习策略比较（AUCs）

基线：从头开始
转换后的模型
主动学习随机
主动学习熵
主动学习一致性
主动学习AL-CCAL
主动学习AL-PRC</sample>
    <sample id="1522">翻译结果：
- 语言：中文
- 内容：22</sample>
    <sample id="1523">翻译内容如下（目标语言：中文）：
主动学习：稀有类别的概率策略

主动学习策略特征

稀有 %  时间（s）  主题难度

随机 3.20  11.96  -0.065

熵 6.80  12.78  +0.035

核心集 6.00  11.89  +0.039

CAL 4.80  11.88  -0.045

PRC 7.60  13.55  +0.071

要点：
- 最小的标记成本并不一定会导致更好的模型。
- 稀有性可能让标记更加困难，认知失调是其中一个类别。
- 为了增加失调样本，PRC效果最佳。</sample>
    <sample id="1524">目标语言：中文
翻译结果：重点
从冷启动中主动学习，利用迁移学习
PRC简单有效，用于罕见样本获取
域外：迭代
域内：累积</sample>
    <sample id="1525">翻译后的结果如下：
- 目标语言：中文
- 内容：稀有类注释——'针在干草堆中'
PRC对稀有样本获取简单高效
具有转移学习的冷启动AL
域外：迭代
域内：累积</sample>
    <sample id="1526">目标语言：中文
翻译结果：感谢！</sample>
    <sample id="1527">作者所属的机构标志位于幻灯片底部，表明他们是苏黎世联邦理工学院、Saarland大学和鹿特丹大学的成员。</sample>
    <sample id="1528">演讲者的名字是Si Yuan。</sample>
    <sample id="1529">共有五位作者。</sample>
    <sample id="1530">该方法与一种专门为 simulST 调整的专用架构进行了比较。</sample>
  </task>
</testset>