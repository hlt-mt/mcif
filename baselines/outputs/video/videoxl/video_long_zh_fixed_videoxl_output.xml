<testset name="IWSLT2025" type="output">
  <task track="long" text_lang="zh">
    <sample id="0">Webpage</sample>
    <sample id="1">McGill University</sample>
    <sample id="2">The video shows a man in a blue shirt and headphones presenting a slide show.</sample>
    <sample id="3">1. DE-plain 2. DE-plain with a11p 3. DE-plain with a11p and rm</sample>
    <sample id="4">Patricia Fernandes</sample>
    <sample id="5">LLM</sample>
    <sample id="6">The video is a presentation of a research paper.</sample>
    <sample id="7">Yes</sample>
    <sample id="8">将对话分为4个子任务，分别评估。</sample>
    <sample id="9">现有弱监督方法的成功在很大程度上依赖于干净的训练数据。</sample>
    <sample id="10">1. 增加训练数据量。2. 增加模型的容量。3. 增加模型的训练时间。</sample>
    <sample id="11">The video is a presentation about the development of AI in humor understanding.</sample>
    <sample id="12">这篇论文有三位作者。</sample>
    <sample id="13">The video is a lecture on the topic of adaptive inference.</sample>
    <sample id="14">Conjunct Lengths in English</sample>
    <sample id="15">3</sample>
    <sample id="16">News and fiction.</sample>
    <sample id="17">The video is a presentation of a paper.</sample>
    <sample id="18">Homer loves Bart and Maggie.</sample>
    <sample id="19">The video is a lecture on the topic of Open Domain Question Answering (ODQA). The lecturer explains the challenges and techniques involved in ODQA, including summarizing efficient techniques for existing ODQA systems. She discusses the importance of reducing index size, using lightweight models, and one-stage distillation for multi-task evidence retrieval and reading. The lecturer also highlights the trade-offs between performance, memory, and speed in ODQA systems and suggests that Retriever-Only systems are relatively appropriate if only one-time feedback is good.</sample>
    <sample id="20">Yes, the models are open-source and freely available.</sample>
    <sample id="21">DEplain-apa 包含APA格式的文档。</sample>
    <sample id="22">更大的模型，更好的模型优化，更多的训练样例。</sample>
    <sample id="23">The video is a presentation about the improvement of text-to-image modeling.</sample>
    <sample id="24">左并列词的长度比右并列词的长度更短。</sample>
    <sample id="25">在实验中，将支配词放在不同的位置，例如左端、右端或中间，然后观察其对句法树的影响。</sample>
    <sample id="26">基线分类器在不平衡数据上的训练效果不好。</sample>
    <sample id="27">4</sample>
    <sample id="28">Easy Me and Got 'Em Feeling.</sample>
    <sample id="29">形式化/词汇 cohesion, ellipsis, pronouns, verb form</sample>
    <sample id="30">LLM-Blender is a simple ensemble learning framework for LLMs.</sample>
    <sample id="31">Purdue University</sample>
    <sample id="33">使用Pearson's r来量化立场。</sample>
    <sample id="34">CREST is a framework for generating counterfactuals.</sample>
    <sample id="36">演讲者介绍了一种新的机器翻译方法，该方法使用共享的编码器和特定于语言的解码器。演讲者解释了该方法的原理，并展示了实验结果，证明了它在多个语言上的优势。演讲者还强调了该方法的可扩展性，因为它只使用一次学习来适应不同的语言。</sample>
    <sample id="37">在之前的研究中，当人类受试者被给予相同的人格化提示，研究结果是生成的个性包含更多刻板印象。</sample>
    <sample id="38">Penn Treebank</sample>
    <sample id="39">2</sample>
    <sample id="40">与认知失调密切相关的任务有：吸烟、戒烟、减肥。</sample>
    <sample id="41">The video is a presentation about PeaCOCK, which is a knowledge graph that can be used to enhance dialogue systems. The presenter explains the features of PeaCOCK and how it can be used to improve the consistency and engagement of conversations. The video also shows the results of experiments using PeaCOCK, demonstrating its effectiveness in enhancing dialogue systems.</sample>
    <sample id="42">1</sample>
    <sample id="43">3</sample>
    <sample id="44">以前的研究主要关注模型的预测准确度，而新框架则关注模型的可解释性。</sample>
    <sample id="45">Black women</sample>
    <sample id="46">DeepL 和 Google</sample>
    <sample id="47">在训练大型语言模型时，数据的来源和质量对模型的性能有重要影响。</sample>
    <sample id="48">6</sample>
    <sample id="49">最多900个词元。</sample>
    <sample id="50">The video is a presentation about simplifying German text.</sample>
    <sample id="51">音乐，书籍和食谱。</sample>
    <sample id="52">positionality（立场）的定义是：在特定社会、文化、政治和经济环境中，个人或群体所处的位置。</sample>
    <sample id="53">Dawei Zhang</sample>
    <sample id="54">The video is a lecture on cognitive dissidence.</sample>
    <sample id="55">EDAtt 适应了所有的离线 ST 模型。</sample>
    <sample id="56">3</sample>
    <sample id="57">yes</sample>
    <sample id="58">Background-Pretain, Background-Both, Background-Inference</sample>
    <sample id="59">The video is a presentation about language modeling.</sample>
    <sample id="60">Google Research</sample>
    <sample id="61">最后一个问题是如何使用可用的干净样本更有效地训练模型。</sample>
    <sample id="62">The video is a presentation of a study on knowledge distillation.</sample>
    <sample id="63">指标灵敏度是通过在未见过的任务上评估模型的零-shot性能来工作的。</sample>
    <sample id="64">Wenwen Jiang</sample>
    <sample id="65">更高的灵敏度表示模型性能得到了提高。</sample>
    <sample id="66">演讲者介绍数学建模和机器学习的最新研究，强调了在低资源设置下的数学建模。</sample>
    <sample id="67">演讲者介绍关于语言模型的训练和使用。</sample>
    <sample id="68">模型会接收一个或多个句子的上下文。</sample>
    <sample id="69">通常需要 10 个干净的验证样本。</sample>
    <sample id="70">Stanford University</sample>
    <sample id="71">The video is a presentation about the dataset collection methodology.</sample>
    <sample id="72">因为传统的方法无法全面地衡量媒体偏见。</sample>
    <sample id="73">Alexandre Trischler</sample>
    <sample id="74">The video is a presentation about the Dense-ATOMIC model.</sample>
    <sample id="75">The video explains the process of joint label propagation in machine learning.</sample>
    <sample id="76">政治偏见传播流程是：pretraining data -&gt; language models -&gt; downstream tasks。</sample>
    <sample id="77">The video is a presentation about the new dataset for factual consistency.</sample>
    <sample id="78">是的，DEplain-apa 和网站的简化过程不同。</sample>
    <sample id="79">Yes</sample>
    <sample id="80">在原始嵌入的基础上添加一个目标向量。</sample>
    <sample id="81">Penn State</sample>
    <sample id="82">演讲者介绍了一种新的无监督自动评分方法，该方法使用深度学习模型来整合多个评分信号。演讲者详细介绍了该方法的原理和实验结果，证明了其在无监督自动评分中的 effectiveness。</sample>
    <sample id="83">yes</sample>
    <sample id="84">The video is a presentation of PAD-Net.</sample>
    <sample id="85">制作蛋糕</sample>
    <sample id="86">他们使用了水印注入的方法，将水印嵌入到嵌入向量中，使攻击者难以检测。</sample>
    <sample id="87">使用 PLM 的预训练策略来构建新的 PLM。</sample>
    <sample id="88">GPT-4 与南亚/中亚的立场最不一致。</sample>
    <sample id="89">Ich werde reden.</sample>
    <sample id="90">The video is a presentation about language learning.</sample>
    <sample id="91">任务的数量越多，模型的性能越好。</sample>
    <sample id="92">LSTM, T5-seq2seq, and Zhen et al.</sample>
    <sample id="93">两位合著者是第一作者的指导老师。</sample>
    <sample id="94">演讲者介绍了一种叫做EmbMarker的算法，该算法可以将水印注入到嵌入向量中。演讲者首先介绍了EmbMarker的原理，然后展示了实验结果，最后总结了EmbMarker的优点和未来的工作方向。</sample>
    <sample id="95">David Wark</sample>
    <sample id="96">1. Keep a record of all relevant design choices made throughout building datasets or models.</sample>
    <sample id="97">演讲者提到了 SimulST 的三个问题。</sample>
    <sample id="98">使用多源数据，包括来自不同政治立场的新闻和 Reddit 帖子。</sample>
    <sample id="99">在约束性语言规划中，LLMs的性能通常较差。</sample>
    <sample id="100">The video is a lecture on the topic of multi-hop question answering. The speaker explains how to use language models to retrieve information from a corpus and how to rank the retrieved information based on relevance. The speaker also discusses the importance of using instructions to guide the language model's reasoning and how to evaluate the performance of the system.</sample>
    <sample id="101">PaLM 的流畅度和 SOTA 系统相当。</sample>
    <sample id="102">可转移性、不可降级性、可覆盖性。</sample>
    <sample id="103">TED 英语演讲已被翻译成哪 14 种不同的语言？</sample>
    <sample id="104">从一个数据集中抽取100个实例用于重新注释。</sample>
    <sample id="105">cosine similarity and Euclidean distance.</sample>
    <sample id="106">The video is a presentation about the QUEST dataset.</sample>
    <sample id="107">将基于编码器的多语言模型用于这项任务，需要在训练时使用多语言数据。</sample>
    <sample id="108">The video is a lecture on language models and their limitations.</sample>
    <sample id="109">The video is a presentation of a research paper.</sample>
    <sample id="111">作者使用了在训练集上出现的单词频率来确定中等频率的单词。</sample>
    <sample id="112">Do CoNLL-2003 Named Entity Taggers Still Work in 2023?</sample>
    <sample id="114">演讲者介绍了一种新的自动剪枝方法，该方法可以将参数减少90%，并保持与原始模型相同的BLEU得分。演讲者还介绍了未来的工作方向，包括任务特定的自动剪枝和基于Lottery Ticket Hypothesis的剪枝方法。演讲者强调了剪枝的重要性，并展示了如何在不同的任务中应用这种方法。</sample>
    <sample id="115">16 frames</sample>
    <sample id="116">Servin 是一个政治家，Kea 是一个面包师。</sample>
    <sample id="117">示例质量</sample>
    <sample id="118">演讲者介绍了一种新方法，用于在代码中编码语言切换信息。演讲者使用了线性 probing和条件线性 probing等技术来验证该方法的可行性。演讲者还介绍了他们在代码中编码语言切换信息的实验结果，并展示了他们的新方法在代码中编码语言切换信息的效果。</sample>
    <sample id="119">论文侧重于GPT-2和Roberta。</sample>
    <sample id="120">特定层的注意力分数。</sample>
    <sample id="121">Do you mean "Easy on Me" by Adele or "Got a Feeling" by The Black Eyed Peas?</sample>
    <sample id="122">Fudan University</sample>
    <sample id="123">The video is a presentation about the improvement of zero-shot performance on NLP tasks.</sample>
    <sample id="124">The video is a presentation about the temporal reasoning ability of large language models.</sample>
    <sample id="125">4</sample>
    <sample id="126">Yes</sample>
    <sample id="127">The video is a presentation about large language models and reasoning.</sample>
    <sample id="128">演讲者介绍KITMUS测试，展示不同模型的优劣。</sample>
    <sample id="129">Black women</sample>
    <sample id="130">LARGE, LARGEST</sample>
    <sample id="131">CIFAR-10</sample>
    <sample id="132">这篇论文有五位作者。</sample>
    <sample id="133">多种模态</sample>
    <sample id="135">The video is a presentation of a study on dialogue quality.</sample>
    <sample id="136">A man is giving a presentation about the importance of language and math diversity in AI.</sample>
    <sample id="137">演讲者介绍了一个新的人工智能模型，该模型可以将自然语言的描述转化为精确的2D平面图。演讲者首先介绍了该模型的原理和优势，然后展示了该模型在生成2D平面图方面的强大能力。演讲者还分享了该模型的未来展望，包括其在建筑和室内设计领域的应用前景。演讲者最后总结了该模型的贡献，并感谢观众的聆听。</sample>
    <sample id="138">知识整合和推理时间背景知识</sample>
    <sample id="139">Yi Zhang</sample>
    <sample id="140">Yes, it has been manually annotated and validated.</sample>
    <sample id="141">依赖上下文的翻译需要考虑上下文，而当前的资源主要关注词汇和语法层面。</sample>
    <sample id="142">1. Did you mean "Easy on Me" by Adele or "Got a Feeling" by The Black Eyed Peas?</sample>
    <sample id="143">该方法与 wake-word, LA, CAT, EAD 策略进行了比较。</sample>
    <sample id="144">Avignon University</sample>
    <sample id="145">Masaaki Shibuya</sample>
    <sample id="146">The video is a presentation about dialogue summarization.</sample>
    <sample id="147">3</sample>
    <sample id="148">无。</sample>
    <sample id="149">是</sample>
    <sample id="150">The video is a presentation about the MeetingQA dataset.</sample>
    <sample id="151">1. 介绍：介绍研究的背景和目的。</sample>
    <sample id="152">演讲者介绍自己在语言模型方面的工作，包括新语言模型的开发、新数据集的使用和新评价方法的提出。</sample>
    <sample id="153">The video is a presentation about the ambiguity of text-to-image models.</sample>
    <sample id="154">University of Trento</sample>
    <sample id="155">Javed Aahmad</sample>
    <sample id="157">The video explains the process of summarizing a dialogue.</sample>
    <sample id="158">演讲者介绍了一种新的缓存机制，即使用L-Cache和G-Cache分别存储局部实体和全局实体。演讲者解释了这种机制的原理，并提供了实验结果来证明其优势。演讲者还讨论了缓存命中率和计算成本之间的权衡。演讲者总结了这种机制的优点，并感谢观众。</sample>
    <sample id="159">语言模型是敏感的潜在的语法/语义特征共享到相关句子。MPP评估没有使用短/单句输入，因此不能完全LTM。</sample>
    <sample id="160">将输入词元映射到树形词元。</sample>
    <sample id="161">50,000</sample>
    <sample id="163">DEplain 的最佳对齐方法是使用 iBART。</sample>
    <sample id="164">弱监督学习可以使用少量的标记数据，从而节省标注成本。</sample>
    <sample id="165">演讲者介绍了一种新的机器学习方法，LIPoR。演讲者首先介绍了LIPoR的原理，即在最大化似然度的同时，鼓励概率质量的坍缩到一个子集的解释。演讲者还介绍了LIPoR的公式和结果，表明LIPoR在NLI任务上的表现超过了其他方法。演讲者最后感谢观众并提供了他们的网站地址。</sample>
    <sample id="166">The video is a lecture on the neural divide-and-conquer reasoning framework.</sample>
    <sample id="167">DEplain-web 中的文档采用手动和自动对齐方法进行了对齐。具体分配情况如何？</sample>
    <sample id="168">CoNLL++数据集是通过在原始CoNLL-2003数据集的基础上添加新实体和新实体关系来创建的。</sample>
    <sample id="169">演讲者介绍了一项关于语言模型的实验，该实验使用了PALM和Google Translate等工具。演讲者强调了PALM在翻译质量上的优势，并提供了具体的实验结果和数据。演讲者还分享了PALM在处理多语言任务时的挑战和未来的研究方向。</sample>
    <sample id="170">我们使用一个统一的基准XSemPLR，它包含多种自然语言和意义表示。</sample>
    <sample id="171">关于这方面的现有研究有：参数化水印、基于字典的水印、基于模型的水印。</sample>
    <sample id="172">Codex 或 Bloom 等多语言 LLM 对于 CLSP 来说并不足够。</sample>
    <sample id="174">The video is a presentation of a woman talking about the quality of arguments.</sample>
    <sample id="175">在训练中，将排列的不确定性考虑进去。</sample>
    <sample id="176">下游 NLP 模型的公平性定义为它在不同政治立场上的表现是否一致。</sample>
    <sample id="177">Dr. Benjamin BERTHIER</sample>
    <sample id="178">Koushik Saha</sample>
    <sample id="179">The video is a presentation about the SymbolicTOM method.</sample>
    <sample id="180">Dong Chen</sample>
    <sample id="181">The video is a lecture on constrained language planning.</sample>
    <sample id="182">热带主义 (tropicalism) 意味着将某些文化或身份特征归因于特定的地理区域，如热带。</sample>
    <sample id="183">使用GPT-4生成。</sample>
    <sample id="184">使用了BLEU, COMET, F-measure来衡量语境使用情况。</sample>
    <sample id="185">DrBERT 是一个基于 BERT 的模型，而 ChuBERT 是一个基于 RoBERTa 的模型。</sample>
    <sample id="187">这篇论文有三位作者。</sample>
    <sample id="188">在每次模型更新时，使用新数据和旧数据的组合来训练新模型。</sample>
    <sample id="189">数据集的目标是理解用户在做选择时的语言。</sample>
    <sample id="190">攻击者通过请求 EaaS 提供的 embedding 来提取模型参数。</sample>
    <sample id="191">3</sample>
    <sample id="192">The video is a presentation of a paper.</sample>
    <sample id="193">10</sample>
    <sample id="194">University of Washington</sample>
    <sample id="195">The video is a presentation about the ROHT framework.</sample>
    <sample id="196">Homer loves Lisa, Bart and Maggie.</sample>
    <sample id="197">GPT-4</sample>
    <sample id="198">因为模型的可接受性依赖于整个上下文窗口中的信息。</sample>
    <sample id="199">no</sample>
    <sample id="200">No</sample>
    <sample id="201">BLEURT</sample>
    <sample id="202">Yes</sample>
    <sample id="203">NLP 中的立场很重要，因为 NLP 模型和数据集是基于特定的立场和假设构建的。</sample>
    <sample id="204">完整微调</sample>
    <sample id="205">The video is a presentation about the political bias of language models.</sample>
    <sample id="206">Roberta-base</sample>
    <sample id="207">SQuAD 2.0, NQ, TriviaQA</sample>
    <sample id="208">3</sample>
    <sample id="209">提议的方法获得了2.5倍的收益。</sample>
    <sample id="210">Shuheng Li</sample>
    <sample id="211">Yes, they can be used as a benchmark.</sample>
    <sample id="212">4个</sample>
    <sample id="213">OFA</sample>
    <sample id="215">演讲者在介绍英语中连词的长度时，使用了PowerPoint来展示数据。</sample>
    <sample id="217">演讲者介绍了一种多属性可控的对话生成模型，该模型使用了prompt-based的方法来生成对话。演讲者还介绍了该模型的评估框架和实验结果，证明了该模型在多属性生成方面具有更好的质量和可控性。</sample>
    <sample id="218">Google</sample>
    <sample id="219">The video is a presentation of a financial report analysis task.</sample>
    <sample id="220">Stony Brook University</sample>
    <sample id="221">论文分析了英语和德语之间的翻译。</sample>
    <sample id="222">The video is a presentation about data interventions in machine learning.</sample>
    <sample id="223">Chang Young Park</sample>
    <sample id="224">研究了DEPL-APA和DEPL-Web。</sample>
    <sample id="225">57 个任务。</sample>
    <sample id="226">3</sample>
    <sample id="227">The video is a presentation about language understanding.</sample>
    <sample id="228">AG News, MIND, Eron Spam, WikiText</sample>
    <sample id="229">The video is a lecture on revisions in argumentative writing.</sample>
    <sample id="231">NACHOS 是一个用于 NLP 的数据集。</sample>
    <sample id="232">David Mark</sample>
    <sample id="233">The video is a presentation of a paper.</sample>
    <sample id="234">提示策略对结果有较大影响。</sample>
    <sample id="235">卡内基梅隆大学</sample>
    <sample id="236">5 个由专家编写的指令是：1. 用一个句子来描述这个图像。2. 用一个单词来描述这个图像。3. 用一个短语来描述这个图像。4. 用一个形容词来描述这个图像。5. 用一个动词来描述这个图像。</sample>
    <sample id="237">使用任务特定的训练。</sample>
    <sample id="238">The video is a presentation about the MeetingBank dataset.</sample>
    <sample id="239">感谢你来参加我们的会议。</sample>
    <sample id="240">弱监督学习</sample>
    <sample id="241">演讲者介绍自己团队的 misinformation detection framework，该框架将系统和人类内容 moderators 和 fact-checkers 的工作流程连接起来。演讲者希望他们的工作能推动开发更多有用的 human-in-the-loop 框架，为 misinformation detection 提供一个具体的比较标准，并提供了一个对外的 look at human-in-the-loop misinformation systems.</sample>
    <sample id="242">对话系统的常用评估方法是Liker Likert Scale。</sample>
    <sample id="243">这篇论文有三位作者。</sample>
    <sample id="244">Servin 是一个政治家，Kea 是一个面包师。</sample>
    <sample id="245">The video is a presentation of a research paper.</sample>
    <sample id="246">代码公开，可从 GitHub 获得。</sample>
    <sample id="247">The video is a presentation of a new dataset.</sample>
    <sample id="248">NLPositionality 的注释者在各个人口统计学特征方面是均衡的。</sample>
    <sample id="249">在可接受的域中，可以添加或删除单词来扰乱句子。</sample>
    <sample id="250">进行维度评估意味着对模型的性能进行多方面的评估。</sample>
    <sample id="251">北京交通大学</sample>
    <sample id="252">演讲者介绍了一个新的数据集和一个事件提取的框架。</sample>
    <sample id="253">The video is a presentation about the detection of mental disorders in social media.</sample>
    <sample id="254">The video is a lecture on uncertainty estimation.</sample>
    <sample id="255">在需要生成新内容的情况下，提示的形式很重要。</sample>
    <sample id="257">作者评估了AB-Chat, BERT, Blender2, Emora, 和 Blender Decoder。</sample>
    <sample id="258">The video is a presentation of a research paper.</sample>
    <sample id="259">The video is a presentation about cross-lingual semantic parsing.</sample>
    <sample id="260">2</sample>
    <sample id="261">优秀规划器的品质是：1. 任务相关性高；2. 任务相关性高；3. 任务相关性高。</sample>
    <sample id="262">6</sample>
    <sample id="263">演讲者介绍了一个新模型DC，该模型可以解决机器学习中常见的label bias问题。演讲者首先介绍了label bias的三种类型：contextual label bias、domain label bias和domain-contextual label bias。演讲者通过实验数据展示了DC模型在缓解这些bias方面的能力。演讲者还介绍了DC模型的原理，即通过在训练过程中使用随机的in-domain token来缓解label bias。演讲者最后总结了DC模型的优点，并鼓励观众查看论文以获取更多细节。</sample>
    <sample id="264">The video is a presentation of a research paper.</sample>
    <sample id="265">Sujing Liu</sample>
    <sample id="266">Institute of Computer Science, Polish Academy of Sciences</sample>
    <sample id="268">PaLM 最常见的错误是忘记使用连词。</sample>
    <sample id="269">在接下来的几分钟里，我将向您介绍我们新开发的ABC-Eval框架。</sample>
    <sample id="270">Emory University</sample>
    <sample id="271">CFT 代表 Continuously Fine-tuning。</sample>
    <sample id="272">3</sample>
    <sample id="273">当翻译需要上下文时?</sample>
    <sample id="274">Boris Katz</sample>
    <sample id="276">The video explains the evaluation of machine translation systems.</sample>
    <sample id="277">它没有名称。</sample>
    <sample id="278">显性词汇是那些仅由身份定义的词汇。</sample>
    <sample id="279">论文的作者分别来自卡内基梅隆大学、华盛顿大学、宾夕法尼亚州立大学、加利福尼亚大学圣克鲁兹分校。</sample>
    <sample id="280">The video is a presentation about an emotion recognition system.</sample>
    <sample id="281">演讲者介绍了一种新方法来解决机器翻译中的一些问题。演讲者首先介绍了机器翻译中的一些问题，然后介绍了他们的新方法来解决这些问题。演讲者还介绍了他们的新方法的优缺点。</sample>
    <sample id="282">演讲者介绍自己的研究，主要研究内容是将中文翻译成英文。</sample>
    <sample id="283">Bouquet (Stanford)</sample>
    <sample id="284">The video is a lecture on fuzzy span loss.</sample>
    <sample id="285">The video is a lecture on the evaluation of FEC models.</sample>
    <sample id="286">Sarah E. Finch</sample>
    <sample id="287">4</sample>
    <sample id="288">Syntactic, Semantic, and Structural</sample>
    <sample id="290">FT, COSINE, L2R, ML, LR</sample>
    <sample id="291">在13项任务上进行了评估。</sample>
    <sample id="294">CamemBERT 最初是在 1.8B 的法语数据上训练的。</sample>
    <sample id="295">Adam Przepiorkowski</sample>
    <sample id="296">The video is a presentation about irony.</sample>
    <sample id="297">The video is a presentation of a project that studies the use of coded language in political messaging.</sample>
    <sample id="298">发现时间漂移是性能下降的主要原因。</sample>
    <sample id="299">演讲者介绍了一种新方法，通过学习一个分布来解决机器学习中的问题。演讲者首先介绍了机器学习中的一些问题，然后介绍了他们的新方法，并提供了实验结果。演讲者还介绍了其他实验，以进一步了解新方法的性能。</sample>
    <sample id="300">演讲者介绍了一个新任务：交互式字典。演讲者首先介绍了这个新任务的背景，然后详细介绍了这个新任务的原理和实现方法。演讲者还介绍了这个新任务的实验结果，展示了这个新任务的可行性和实用性。演讲者最后总结了这个新任务的意义和未来的发展方向。</sample>
    <sample id="302">因为输出序列中的词元是无序的，需要排列成符合语义的顺序。</sample>
    <sample id="303">提高透明度有助于用户了解模型的决策过程，从而更好地理解其输出。</sample>
    <sample id="304">最小对不可接受输入是那些在结构上匹配的句子。</sample>
    <sample id="305">The video is a presentation of a research paper.</sample>
    <sample id="306">The video is a presentation about the challenges of evaluating entity tracking abilities.</sample>
    <sample id="307">作者使用了F1 score, accuracy, and Matthews correlation coefficient。</sample>
    <sample id="308">The video is a presentation about the positionality in NLP.</sample>
    <sample id="309">Krippendorff's alpha.</sample>
    <sample id="310">领域1</sample>
    <sample id="311">Heinrich-Heine-Universität Düsseldorf</sample>
    <sample id="312">MultiInstruct 是第一个多模态指令调优基准。</sample>
    <sample id="313">4</sample>
    <sample id="314">二进制协调的定义是：一个单词的左依存和右依存都必须是单个单词。</sample>
    <sample id="315">平均长度是10个单词。</sample>
    <sample id="316">这些发现对较小的 T5 模型有积极的影响。</sample>
    <sample id="317">The video is a presentation about few-shot information extraction.</sample>
    <sample id="318">在本研究中，我们使用了13个任务来评估我们的模型。</sample>
    <sample id="319">论文研究了三种学习策略：从头训练、微调和持续预训练。</sample>
    <sample id="320">0.4</sample>
    <sample id="321">使用BLEU score和ROUGE score。</sample>
    <sample id="322">The video is a lecture on morality.</sample>
    <sample id="323">The video is a presentation of a paper.</sample>
    <sample id="324">yes</sample>
    <sample id="325">Compositional Generalization without Trees using Multiset Tagging and Latent Permutations</sample>
    <sample id="326">认知失调是指当一个人的信念和行为不一致时，他们可能会感到不舒服。</sample>
    <sample id="327">The video is a presentation of a research paper.</sample>
    <sample id="328">Roberta</sample>
    <sample id="329">The video is a presentation of a method for pseudo-event generation.</sample>
    <sample id="330">yes</sample>
    <sample id="331">Sara Papai</sample>
    <sample id="332">MuDa 基准中的数据是通过从 Google 网站上抓取的。</sample>
    <sample id="333">The video is a presentation about the INK system.</sample>
    <sample id="335">Matthias Lindemann</sample>
    <sample id="336">跨语言转移是指在一种语言上训练的模型应用于另一种语言上的任务。</sample>
    <sample id="337">The video is a lecture on the topic of word embedding learning. The speaker explains that word embeddings are used to represent words as vectors in a high-dimensional space, allowing for the analysis of relationships between words based on their semantic meanings. The speaker also discusses the challenges of learning word embeddings for languages with complex morphology, such as Japanese and Korean, and introduces a new model called WRG-GRM that can handle these languages effectively.</sample>
    <sample id="338">演讲者介绍了一个新的人工智能模型，该模型使用自然语言处理技术来理解人类的意图并提供有用的解释。演讲者强调了模型的有用性，并提供了实验结果和未来的工作方向。</sample>
    <sample id="339">Saarland University</sample>
    <sample id="340">演讲者介绍了一个新数据集，该数据集由1500万句源句子和6.92亿个自动句对组成。演讲者还介绍了使用AMR图的参数化方法来生成多样性的句对。</sample>
    <sample id="341">作者使用了三种延迟测量方法：AL, CA, EADt。</sample>
    <sample id="342">The video is a presentation of a new dataset.</sample>
    <sample id="343">John saw the newly elected president on TV. After a long day at work deciding cases in court, he was happy to relax.</sample>
    <sample id="344">基于树的方法需要被克服。</sample>
    <sample id="345">The video is a presentation about compositional generalization in semantic parsing.</sample>
    <sample id="346">Georgia Tech</sample>
    <sample id="347">Marked Words: Find words that distinguish personas of marked groups from unmarked groups</sample>
    <sample id="348">The video is a presentation about the limitations of existing stereotype measures and how to overcome them.</sample>
    <sample id="349">在本节中，我们介绍了一种称为 EmbMarker 的新方法。</sample>
    <sample id="350">The video is a presentation about the meaning of superhuman performance in NLP.</sample>
    <sample id="351">The video is a presentation about the performance of a model.</sample>
    <sample id="352">ABC-Eval 代表一种评估模型的方法。</sample>
    <sample id="353">The video is a presentation of a research paper.</sample>
    <sample id="354">2014</sample>
    <sample id="355">认知失调：认知失调理论认为，当一个人的信念和行为不一致时，他们会感到不舒服。</sample>
    <sample id="356">University of Amsterdam</sample>
    <sample id="357">Siyuan Yu</sample>
    <sample id="358">3</sample>
    <sample id="359">SimulST-Sim</sample>
    <sample id="361">The video is a presentation of a research paper.</sample>
  </task>
</testset>