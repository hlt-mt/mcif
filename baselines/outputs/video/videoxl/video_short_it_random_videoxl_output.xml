<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="it">
    <sample id="0">Wikipedia, Google, and web pages</sample>
    <sample id="1">McGill, Mila, Microsoft Research</sample>
    <sample id="2">DEPLAIN: A German Parallel Corpus with Intra- and Intertextual Translations into Plain Language for Sentence and Document Simplification Regina Stodden, Omar Mommen, Laura Kallmeyer Heinrich Heine University Dissolfort Germany ACL 2023</sample>
    <sample id="3">DEPLAN: A German Parallel Corpus with Intra- and Intertextual Translations into Plain Language for Sentence and Document Simplification Regina Stodden, Omar Mommen, Laura Kallmeyer Heinrich Heine University Dissolfort Germany ACL 2023</sample>
    <sample id="4">Il contenuto originale è rimasto in inglese.</sample>
    <sample id="5">Il contenuto originale è rimasto in inglese.</sample>
    <sample id="6">Il contenuto originale è rimasto in inglese.</sample>
    <sample id="7">Il contenuto originale è rimasto in inglese.</sample>
    <sample id="8">Il video presenta una presentazione in cui viene analizzata la complessità della lingua usata in diversi testi. La presentazione inizia con un'introduzione ai concetti di "German Text Simplification Corpus" e "Sentence Level", seguita da una serie di bar chart che confrontano la complessità della lingua in vari testi. I bar chart sono colorati in diverse tonalità, rappresentando diversi livelli di complessità. Il presentatore spiega come i livelli di complessità sono determinati e come i testi vengono classificati in base alla loro complessità. La presentazione conclude con una panoramica dei principali punti chiave, fornendo un'analisi dettagliata della complessità della lingua in vari testi.</sample>
    <sample id="9">German Text Simplification Corpora</sample>
    <sample id="10">German Text Simplification Corpus</sample>
    <sample id="11">German Text Simplification Corpus</sample>
    <sample id="12">German Text Simplification Corpus</sample>
    <sample id="13">German Text Simplification Corpus</sample>
    <sample id="14">Semplifica il contenuto in inglese in una versione italiana.</sample>
    <sample id="15">Semplifica il contenuto in inglese in una versione italiana.</sample>
    <sample id="16">Simplificazione</sample>
    <sample id="17">Semplifica il contenuto in inglese in una versione italiana.</sample>
    <sample id="18">Simplificazione</sample>
    <sample id="19">3. Use-cases
Automatic alignment and simplification</sample>
    <sample id="20">Results of the alignment methods with 1/11 part and rm capabilities (lower part)</sample>
    <sample id="21">Results of the alignment methods with (1,1) part and rm capabilities (lower part)</sample>
    <sample id="22">Results of the alignment methods with 1/11 part and rm capabilities (lower part)</sample>
    <sample id="23">Results of the alignment methods with 1/11 part and rm capabilities (lower part)</sample>
    <sample id="24">Results of the alignment methods with 1/11 part and rm capabilities (lower part)</sample>
    <sample id="25">Results of the alignment methods with 1/11 part and nm capabilities (lower part)</sample>
    <sample id="26">Results of the alignment methods with 11/11 part and rm capabilities (lower part)</sample>
    <sample id="27">Automatic Text Simplification</sample>
    <sample id="28">Automatic Text Simplification</sample>
    <sample id="29">Automatic Text Simplification</sample>
    <sample id="30">Automatic Text Simplification</sample>
    <sample id="31">Automatic Text Simplification</sample>
    <sample id="32">Automatic Text Simplification</sample>
    <sample id="33">Automatic Text Simplification</sample>
    <sample id="34">Grazie.</sample>
    <sample id="35">Patric F. Fernandes</sample>
    <sample id="36">T5 XL</sample>
    <sample id="37">Yes</sample>
    <sample id="38">The novelty of the proposed human evaluation method is that it allows annotators to rate the relevance and self-contradiction of each utterance in a dialogue, rather than just the entire dialogue.</sample>
    <sample id="39">Su una buona scelta di iperparametri.</sample>
    <sample id="40">Progressi in tempo reale</sample>
    <sample id="41">6</sample>
    <sample id="42">Adam Prezrokowski and Michal Wozniak</sample>
    <sample id="43">Il contenuto è in inglese.</sample>
    <sample id="44">Il contenuto è in inglese.</sample>
    <sample id="45">Il contenuto è in inglese.</sample>
    <sample id="46">Il contenuto è in inglese.</sample>
    <sample id="47">Il contenuto è in inglese.</sample>
    <sample id="48">Il contenuto è in inglese.</sample>
    <sample id="49">Il contenuto è in inglese.</sample>
    <sample id="50">Il contenuto è in inglese.</sample>
    <sample id="51">Il contenuto è in inglese.</sample>
    <sample id="52">Il contenuto è in inglese.</sample>
    <sample id="53">Il contenuto è in inglese.</sample>
    <sample id="54">Il contenuto è stato tradotto in inglese.</sample>
    <sample id="55">Il contenuto è in inglese.</sample>
    <sample id="56">Il professor John Smith presenta una presentazione sul "Minimizzazione della lunghezza delle dipendenze (DLM)." La presentazione include esempi di parole e frasi, suddivise in "good" e "bad," con l'obiettivo di minimizzare le dipendenze.</sample>
    <sample id="57">Il contenuto è in inglese.</sample>
    <sample id="58">Il contenuto è in inglese.</sample>
    <sample id="59">Il contenuto è in inglese.</sample>
    <sample id="60">Il contenuto è in inglese.</sample>
    <sample id="61">Il contenuto è in inglese.</sample>
    <sample id="62">Conclusione lunghezza in inglese</sample>
    <sample id="63">Coniugazioni in Inglese</sample>
    <sample id="64">Conclusione lunghezza in inglese</sample>
    <sample id="65">Conclusione lunghezza in inglese</sample>
    <sample id="66">Conclusiuni lunghe in Inglese</sample>
    <sample id="67">Conclusione lunghezza in inglese</sample>
    <sample id="68">Conclusione lunghezza in inglese</sample>
    <sample id="69">Conclusione lunghezza in inglese</sample>
    <sample id="70">Il contenuto è in inglese.</sample>
    <sample id="71">The video shows a series of graphs with lines and data points, likely representing some form of statistical analysis or data visualization. The graphs are arranged in a grid format, with each graph having a unique set of axes and data points. The lines on the graphs appear to be linear, suggesting a relationship between two variables. The data points are scattered across the graphs, indicating variability or fluctuations in the data being analyzed. Overall, the video seems to be focused on presenting and analyzing data through visual means, possibly for educational or informational purposes.</sample>
    <sample id="72">The speaker is discussing the results of a study on the relationship between word length and power in a specific context. The graphs show that as word length increases, power also increases, but the increase is not linear. The speaker highlights that this pattern is consistent across different contexts, suggesting that the relationship between word length and power is robust.</sample>
    <sample id="73">Compatibility with Dependency Structures of Coordination</sample>
    <sample id="74">Vedi il paper per l'argomento completo!</sample>
    <sample id="75">3</sample>
    <sample id="76">news</sample>
    <sample id="77">[not] is it [on the] left and [Ned] laughed</sample>
    <sample id="78">Yes</sample>
    <sample id="79">Apa</sample>
    <sample id="80">Bigger model size, more fine-tuning examples</sample>
    <sample id="81">Through the use of a linear regression model.</sample>
    <sample id="82">The experiments were designed to study the effect of the governor's position by using a 2x3 full factorial design.</sample>
    <sample id="83">43.901</sample>
    <sample id="84">4</sample>
    <sample id="85">Man 1, Man 2</sample>
    <sample id="86">Formal/lexical cohesion, ellipsis, pronouns, verb form</sample>
    <sample id="87">Johns Hopkins University, Purdue University</sample>
    <sample id="122">Utilizzando il coefficiente di correlazione di Pearson tra i modelli e i dataset.</sample>
    <sample id="155">The results of the previous study showed that human subjects using the same prompts produced similar descriptions.</sample>
    <sample id="156">Penn Treebank (Marcus et al., 1993) e il versione iscritta del Penn Treebank (Marcus et al., 2016)</sample>
    <sample id="157">Due autori sono coinvolti nell'articolo.</sample>
    <sample id="158">Risposta: Annotazione, rafforzamento, fine-tuning.</sample>
    <sample id="159">2</sample>
    <sample id="160">6</sample>
    <sample id="161">Il framework differisce dagli studi precedenti in quanto introduce una nuova metrica per valutare la diversità dei modelli, il Pearson's r.</sample>
    <sample id="162">GPT-4</sample>
    <sample id="163">DeepL e Google Translate</sample>
    <sample id="164">Da #ACL2025.</sample>
    <sample id="165">LM Training Data A mixed blessing</sample>
    <sample id="166">LM Training Data</sample>
    <sample id="167">LM Training Data</sample>
    <sample id="168">LM Training Data A mixed blessing</sample>
    <sample id="169">To this end</sample>
    <sample id="170">To this end</sample>
    <sample id="171">To this end</sample>
    <sample id="172">Evaluating LM Political Learning</sample>
    <sample id="173">Esistono LM</sample>
    <sample id="174">Esistono LM esistenti</sample>
    <sample id="175">Pretuning Data</sample>
    <sample id="176">Pretuning Data Further pretrain LM (RoBERTa, GPT-2, GPT-check) Evaluate change in political leaning</sample>
    <sample id="177">Results Partisan shifts in LM political leaning</sample>
    <sample id="178">Results Partisan shifts in LM political leaning</sample>
    <sample id="179">Results Partisan shifts in LM political leaning</sample>
    <sample id="180">The Trump Card</sample>
    <sample id="181">The Trump Card</sample>
    <sample id="182">The Trump Card</sample>
    <sample id="183">Per-Categor Performance</sample>
    <sample id="184">Per-Category Performance</sample>
    <sample id="185">Per-Category Performance</sample>
    <sample id="186">Per-Category Performance</sample>
    <sample id="187">Per-Category Performance</sample>
    <sample id="188">Per-Categoric Performance</sample>
    <sample id="189">Per-Categoric Performance</sample>
    <sample id="190">Qualitative Analysis</sample>
    <sample id="191">Qualitative Analysis</sample>
    <sample id="192">Test di discriminazione di razzia</sample>
    <sample id="193">Testo di rifiuto</sample>
    <sample id="194">Testo di rifiuto</sample>
    <sample id="195">Nel testo, il termine "hat" viene utilizzato per riferirsi a un'opinione o una convinzione negativa.</sample>
    <sample id="196">Discussione</sample>
    <sample id="197">Discussione</sample>
    <sample id="198">Discussione</sample>
    <sample id="199">Grazie!</sample>
    <sample id="200">6</sample>
    <sample id="201">900</sample>
    <sample id="202">Music Selection, Book Selection, Recipe Selection</sample>
    <sample id="203">The perspectives people hold as a result of their demographics, identity and life experiences.</sample>
    <sample id="204">Dawid Zdunowicz</sample>
    <sample id="205">No</sample>
    <sample id="206">4</sample>
    <sample id="207">No</sample>
    <sample id="208">Background-Pretrain, Background-Both, Background-Inference</sample>
    <sample id="209">Google Research</sample>
    <sample id="210">How to use the available clean samples more efficiently</sample>
    <sample id="211">La sensibilità della metrica è calcolata come la differenza tra il massimo e il minimo dei valori di E[π] per i vari insieme di istruzioni.</sample>
    <sample id="212">Wenwen Jiang</sample>
    <sample id="213">Una maggiore sensibilità suggerisce che il modello ha peggiorato la sua performance.</sample>
    <sample id="214">Contesto linguistico di riferimento</sample>
    <sample id="215">50</sample>
    <sample id="216">Stanford Engineering Computer Science</sample>
    <sample id="217">Because the existing methods are not sufficient.</sample>
    <sample id="218">Jackie CK Chuang</sample>
    <sample id="219">It is complex.</sample>
    <sample id="220">yes</sample>
    <sample id="221">No</sample>
    <sample id="222">The watermark is added to the embedding vector of the target word.</sample>
    <sample id="223">PennState, Amazon</sample>
    <sample id="224">Yes</sample>
    <sample id="225">Come fare una torta di cioccolato?</sample>
    <sample id="226">They use a secret key to encrypt the data and then decrypt it using the same key.</sample>
    <sample id="227">Pre-training on a large corpus of text</sample>
    <sample id="228">Pakistan</sample>
    <sample id="229">I am a student.</sample>
    <sample id="230">The more activities, the better the performance.</sample>
    <sample id="231">LSTM, T5-seq2seq, Zhen et al.</sample>
    <sample id="232">colleghi</sample>
    <sample id="233">Crowder</sample>
    <sample id="234">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="235">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="236">Immaginare...</sample>
    <sample id="237">Immaginate...</sample>
    <sample id="238">Immaginate...</sample>
    <sample id="239">Immagina...</sample>
    <sample id="240">Posizione</sample>
    <sample id="241">La posizione</sample>
    <sample id="242">La posizione</sample>
    <sample id="243">Do datasets and models have personality?</sample>
    <sample id="244">Do datasets and models have personality?</sample>
    <sample id="245">Do datasets and models have positionality?</sample>
    <sample id="246">Do datasets and models have positionality?</sample>
    <sample id="247">Il contenuto in inglese parla di posizione.</sample>
    <sample id="248">Do datasets and models have positionality?</sample>
    <sample id="249">Il contenuto in inglese è: 'Question: Do datasets and models have positionality? Goal: Compare annotations from users with existing datasets and models.'</sample>
    <sample id="250">NLPositionality</sample>
    <sample id="251">Il video presenta un diagramma che illustra il processo di raccolta, processamento e modellazione dei dati. Il diagramma inizia con la raccolta di 20000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000</sample>
    <sample id="252">Il contenuto in inglese parla di un framework per l'annotazione di dataset.</sample>
    <sample id="253">Il contenuto in inglese parla di un framework per l'annotazione di dataset.</sample>
    <sample id="254">Il contenuto in inglese parla di un framework per l'annotazione di dataset.</sample>
    <sample id="255">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="256">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="257">Labinthewild</sample>
    <sample id="258">Labinthewild</sample>
    <sample id="259">Task A: Social Acceptability</sample>
    <sample id="260">Task A: Social Acceptability</sample>
    <sample id="261">Task A: Social Acceptability Analysis Datasets - Social Chemistry Models - Delphi GPT-4</sample>
    <sample id="262">Task B: Toxicity</sample>
    <sample id="263">Il contenuto in inglese è: "Study Participation"</sample>
    <sample id="264">Risultato 1: Esiste posizionalità in NLP.</sample>
    <sample id="265">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="266">Iscriviti al mio canale per scoprire come scrivere in inglese.</sample>
    <sample id="267">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="268">Finding 2: Some populations are left behind.</sample>
    <sample id="269">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="270">So, what can we do? Addressing positionality in NLP</sample>
    <sample id="271">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="272">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="273">Grazie!</sample>
    <sample id="274">3</sample>
    <sample id="275">Incorporare una diversità di voci e punti di vista in entrambe le etichette e i campi di testo.</sample>
    <sample id="276">Il video presenta una presentazione di una conferenza scientifica.</sample>
    <sample id="277">Language Planning How to Make a Cake? Gather your ingredients (1/2 cup of flour, 1 egg, 1/3 cup of sugar, 1/4 cup of butter, 1 tsp of baking powder) Preheat the oven to 350° F. Grease a 9" round cake pan. Cream the butter and sugar together. Add the eggs one at a time, mixing well after each addition. Add the dry ingredients and mix until just combined. Pour the batter into the prepared pan and bake for 15 minutes or until a toothpick inserted in the center comes out clean. Let it cool before serving. Large language models (LLMs) can effectively decompose goals into steps.</sample>
    <sample id="278">Language Planning How to Make a Cake? Gather your ingredients (1/2 cup of flour, 1 egg, 1/3 cup of butter, 1/3 cup of sugar) Preheat the oven to 350° F. Grease a 9" x 13" baking pan. Cream the butter and sugar together. Add the eggs one at a time, mixing well after each addition. Stir in the flour. Pour the batter into the prepared pan. Bake for 15 minutes or until a toothpick inserted in the center comes out clean. Large language models (LLMs) can effectively decompose goals into steps.</sample>
    <sample id="279">Constrained Language Planning</sample>
    <sample id="280">Constrained Language Planning</sample>
    <sample id="281">Constrained Language Planning</sample>
    <sample id="282">Come fanno i LLMs (Large Language Models) funzionare con i vincoli?</sample>
    <sample id="283">Come fanno i LLMs (Large Language Models) funzionare con i vincoli?</sample>
    <sample id="284">Come fanno i LLMs (Large Language Models) funzionare con i vincoli?</sample>
    <sample id="285">Can LLMs do Constrained Language Planning?</sample>
    <sample id="286">Can LLMs do Constrained Language Planning?</sample>
    <sample id="287">What types of errors do LLMs usually make in this task?</sample>
    <sample id="288">What types of errors do LLMs usually make in this task?</sample>
    <sample id="289">InstructGPT typically fails at achieving goals that are too specific or require a high level of planning.</sample>
    <sample id="290">Metodo</sample>
    <sample id="291">Metodo</sample>
    <sample id="292">Metodo</sample>
    <sample id="293">Metodo</sample>
    <sample id="294">Metodo</sample>
    <sample id="295">Metodo</sample>
    <sample id="296">In the video, the woman is talking about a method that greatly improves planning quality.</sample>
    <sample id="297">Il video presenta un diagramma che illustra il processo di "Distillazione del Script da LLMs" (Large Language Models). Il diagramma è suddiviso in tre sezioni principali: Motivation, Method, e Output Goals with Specific Plans. La sezione Motivation spiega l'importanza di ridurre i LLMs per ottenere modelli più piccoli e efficienti. La sezione Method descrive il processo di distillazione del script, che include la generazione di obiettivi specifici, la creazione di script in contesto, e la filtrazione dei script per ottenere i migliori. Infine, la sezione Output Goals with Specific Plans elenca i punti chiave dell'output, come la creazione di script conoberti e la validazione e test dei modelli.</sample>
    <sample id="298">Il video presenta un diagramma che illustra il processo di distillazione dei script da LLMs. Il diagramma inizia con l'input dell'abstract, seguito da una generazione di obiettivi specifici in contesto. Successivamente, i sottoscritti vengono estratti dall'output della generazione e filtrati per ottenere i sottoscritti con la massima somiglianza con l'obiettivo specifico. Infine, i sottoscritti validati e testati vengono usati per produrre i sottoscritti finali con gli obiettivi specifici.</sample>
    <sample id="299">Il video presenta un diagramma che illustra il processo di distillazione dei script da LLMs. Il diagramma inizia con l'input dell'abstract e segue i passaggi seguenti: generare 50,000 script da LLMs, filtrare i top 3 script per il goal specifico, calcolare la similarità tra i script e il goal, e annotare i script per validazione e test. Il diagramma conclude con l'output dei goal con i script specifici.</sample>
    <sample id="300">Il video presenta un diagramma che illustra il processo di distillazione dei script da LLMs. Il diagramma inizia con l'input dell'abstract e segue i passaggi seguenti: generare 50.000 script, filtrare i primi 3 script con il goal più simile, centrare i 500 script rimanenti dall'insieme di test del dataset, e annotare i script per validazione e test. Il diagramma conclude con l'output degli obiettivi con specifici piani rispondenti.</sample>
    <sample id="301">Il video presenta un diagramma che illustra il processo di "Distillazione del Script da LLMs" (Large Language Models). Il diagramma è suddiviso in tre sezioni principali: Motivation, Method, e Output Goals with Compositional Plans. La sezione Motivation spiega l'importanza di ridurre i LLMs per ottenere modelli più piccoli e efficienti. La sezione Method descrive il processo di distillazione del script, che include la generazione di obiettivi specifici, la creazione di script in contesto, e la filtrazione dei script per ottenere i migliori 3 obiettivi. Infine, la sezione Output Goals with Compositional Plans spiega come i modelli LLMs sono utilizzati per produrre risposte conobenti e testate, e come i modelli umani annotano e validano i testi.</sample>
    <sample id="302">Il video presenta una presentazione in cui una persona parla in un'aula moderna. La presentazione include informazioni sulle constraint analysis per i modelli di linguaggio più piccoli, le metriche utilizzate e i dataset. Viene anche presentato un grafico che confronta i modelli specializzati con i modelli generici.</sample>
    <sample id="303">Il video presenta una presentazione in cui una persona parla in un ufficio moderno. La presentazione include statistiche e diagrammi che confrontano i modelli specializzati con i modelli generici. Il video conclude con una sintesi e le conclusioni della presentazione.</sample>
    <sample id="304">Riporta il contenuto inglese in lingua italiana.</sample>
    <sample id="305">Riporta il contenuto inglese in lingua italiana.</sample>
    <sample id="306">Il contenuto inglese è il seguente:</sample>
    <sample id="307">Fluency of PaLM is comparable to SOTA.</sample>
    <sample id="308">Utility, should not degrade the utility of the provided embeddings, should cover the attacker, transferability</sample>
    <sample id="309">Arabic, Chinese, Czech, Danish, Dutch, French, German, Hebrew, Italian, Japanese, Korean, Portuguese, Romanian, Turkish</sample>
    <sample id="310">200</sample>
    <sample id="311">similarity difference and χ² of KS test</sample>
    <sample id="312">Pretrained</sample>
    <sample id="344">Contano la frequenza di una parola in un corpus generale e poi randomizziamo n parole in una frequenza moderata.</sample>
    <sample id="345">Il contenuto originale è in inglese.</sample>
    <sample id="346">Named Entity Recognition &amp; Generalization</sample>
    <sample id="347">Named Entity Recognition &amp; Generalization</sample>
    <sample id="348">Named Entity Recognition &amp; Generalization</sample>
    <sample id="349">Named Entity Recognition &amp; Generalization</sample>
    <sample id="350">ConLL+ Dataset</sample>
    <sample id="351">ConLL++ Dataset</sample>
    <sample id="352">ConLL+ Dataset</sample>
    <sample id="353">What is Needed for Good Generalization?</sample>
    <sample id="354">Quali sono i requisiti per ottenere una buona generalizzazione?</sample>
    <sample id="355">Quali sono i fattori necessari per ottenere una buona generalizzazione?</sample>
    <sample id="356">Quali sono i fattori necessari per ottenere una buona generalizzazione?</sample>
    <sample id="357">Il video presenta un presentatore in un'ambientazione formale, con un slide di presentazione che chiede "What Causes Performance Drop?" (Quali sono le cause della riduzione del prestigio?). Il presentatore, con i capelli neri e indossando un cappuccio, parla in tono professionale. La slide presenta il logo "Georgia Tech" in un angolo, suggerendo che il contenuto è correlato all'istituto di istruzione superiore.</sample>
    <sample id="358">What Causes Performance Drop?</sample>
    <sample id="359">What Causes Performance Drop?</sample>
    <sample id="360">What Causes Performance Drop?</sample>
    <sample id="361">Il video presenta una presentazione in cui il narratore discute della causa principale dell'indebolimento del prestigio.</sample>
    <sample id="362">What Causes Performance Drop?</sample>
    <sample id="363">What Causes Performance Drop?</sample>
    <sample id="364">What Causes Performance Drop?</sample>
    <sample id="365">What Causes Performance Drop?</sample>
    <sample id="366">Conclusions</sample>
    <sample id="367">Conclusions</sample>
    <sample id="368">Conclusions</sample>
    <sample id="369">Conclusione</sample>
    <sample id="370">Il contenuto è stato tradotto in inglese.</sample>
    <sample id="397">small</sample>
    <sample id="398">Servin è un giustiziere e Kea è una pasticcera.</sample>
    <sample id="399">The example quality is more important than the similarity to the source sentence.</sample>
    <sample id="400">Roberta e GPT-2</sample>
    <sample id="401">specific level</sample>
    <sample id="402">The first one, the one I used</sample>
    <sample id="403">Brain Technologies Inc., University of Toronto, University of Alberta</sample>
    <sample id="404">6</sample>
    <sample id="405">Yes</sample>
    <sample id="406">a woman warrior</sample>
    <sample id="407">L'architettura RNN e l'architettura CNN</sample>
    <sample id="408">MSL, L2, COSINE, L2+MNL, BFI, Adapter</sample>
    <sample id="409">six</sample>
    <sample id="410">multimodal</sample>
    <sample id="439">Inference-time knowledge</sample>
    <sample id="440">Zhiyang Xu, Ying Shen, Lifu Huang</sample>
    <sample id="441">Yes, it has been.</sample>
    <sample id="442">Support for limited discourse, phenomena and languages</sample>
    <sample id="443">Risolvere le espressioni di riferimento indiretto per la selection degli entità (AEntities Corpus)</sample>
    <sample id="444">Risoluzione di riferimenti indiretti per la selection di entità (AEntities Corpus)</sample>
    <sample id="445">Indirect Referring Expressions</sample>
    <sample id="446">Indirect Referring Expressions</sample>
    <sample id="447">Indirect Referring Expressions</sample>
    <sample id="448">Indirect Referring Expressions</sample>
    <sample id="449">Indirect Referring Expressions</sample>
    <sample id="450">Dataset Collection</sample>
    <sample id="451">Dataset Collection</sample>
    <sample id="452">Il video presenta un slide di presentazione che descrive il processo di raccolta dei dati per una ricerca. La slide è intitolata "Dataset Collection Methodology" e include una serie di punti chiave. Il primo punto è "Methodology emphasizes informativity using a cartoon completion task," il quale spiega che il processo di raccolta dei dati si concentra sull'informatività usando una attività di completamento di fumetto. Il secondo punto è "Filled in by the annotator," il quale indica che i punti della conversazione sono compilati da un annotatore. Il terzo punto è "The alternative question to one of the entries," il quale suggerisce l'inserimento di una domanda alternativa per ciascuna entry. Il quarto punto è "Expression inferring," il quale spiega che il processo include l'inferenza dell'espressione. Il video presenta anche una serie di immagini di fumetti che illustrano i punti della conversazione. Inoltre, il video presenta una serie di immagini di fumetti che illustrano i punti della conversazione.</sample>
    <sample id="453">Il video presenta un diagramma che illustra il processo di raccolta dei dati per una determinata ricerca. Il diagramma è suddiviso in quattro fasi: "Remembering," "The alternative question," "Expression inferring," e "Filled in by the annotator." Ogni fase rappresenta un passaggio diverso nel processo di raccolta dei dati, con l'annotatore coinvolto in ciascuna fase. Il diagramma fornisce una panoramica chiara del processo di raccolta dei dati, aiutando i ricercatori a comprendere come i dati sono stati raccolti e analizzati.</sample>
    <sample id="454">Il video presenta un diagramma che illustra il processo di raccolta dei dati utilizzando una tecnica di comprensione del linguaggio naturale. Il diagramma è suddiviso in quattro fasi: "Remembering," "The alternative question," "Expression inferring," e "Filled in by the annotator." Ogni fase rappresenta un passaggio diverso nel processo di raccolta dei dati, con l'annotatore fornendo informazioni supplementari per completare il processo.</sample>
    <sample id="455">Il video presenta un presentatore che spiega il processo di raccolta dei dati utilizzando una tecnica di comprensione del linguaggio naturale. Il presentatore illustra tre esempi diversi: un dialogo tra due personaggi, una domanda alternativa e un'inferranza di espressione. Ogni esempio viene rappresentato da una serie di immagini che mostrano i personaggi e le parole che essi usano. Il presentatore spiega come la tecnica di comprensione del linguaggio naturale viene usata per analizzare i dialoghi e interpretare le intenzioni e le emozioni dei personaggi. Il video fornisce un'introduzione ai principi della comprensione del linguaggio naturale e ai suoi applicazioni in vari ambiti, come la conversazione umana e l'analisi di testi.</sample>
    <sample id="456">Il video presenta un presentatore che spiega il processo di raccolta dei dati utilizzando una tecnica di comprensione del linguaggio naturale. Il presentatore illustra come il processo si basa su un'interazione tra due entità, una persona e un assistente di virtual assistant. L'assistente di virtual assistant è rappresentato da una persona con i capelli neri e un cappuccio, che interagisce con l'entità umana rappresentata da una persona con i capelli biondi e un cappuccio. Il processo inizia con la persona umana che cerca informazioni specifiche, come "Do you feel alright?" (Ti senti bene?), e l'assistente di virtual assistant risponde con un'altra domanda, "How do you feel?" (Come ti senti?). In seguito, l'assistente di virtual assistant presenta un'alternativa alla domanda originale, "What do you think about the weather today?" (Cosa pensi della meteo oggi?), e infine, l'assistente di virtual assistant fa una inferenza sull'entità umana, "You seem to be feeling a bit better." (Sembrerebbe che ti sentissi un po' meglio). Il processo di raccolta dei dati si concentra sulla comprensione del linguaggio naturale e sulla inferenza dell'entità umana in base alle interazioni con l'assistente di virtual assistant.</sample>
    <sample id="457">Il video presenta un diagramma che illustra il processo di raccolta dei dati per una ricerca. Il diagramma è suddiviso in quattro fasi: "Remembering," "The alternative question," "Expression inferring," e "Filled by the annotator." Ogni fase rappresenta un passaggio diverso nel processo di raccolta dei dati, con l'annotatore coinvolto in ciascuna fase. Il diagramma fornisce una panoramica chiara del processo di raccolta dei dati, mostrando come i vari passaggi sono interconnessi e come l'annotatore gioca un ruolo importante nel processo.</sample>
    <sample id="458">Generare alternative questioni =&gt; entità più semplici</sample>
    <sample id="459">Generare alternative questioni =&gt; entità connessi</sample>
    <sample id="460">Generare alternative questioni =&gt; entità più semplici</sample>
    <sample id="461">Genera alternative questions = sampling entity pairs</sample>
    <sample id="462">Generare alternative questioni =&gt; entità connessi</sample>
    <sample id="463">Ecco la versione italiana del contenuto inglese:</sample>
    <sample id="464">Background knowledge (Music)</sample>
    <sample id="465">Ecco la versione italiana del contenuto inglese:</sample>
    <sample id="466">Simmol cake is widely eaten in the United Kingdom and other countries with their own patterns. Pandan cake is a light, spongy cake made from juices of Pandanus flowers.</sample>
    <sample id="467">Eliciting expressions</sample>
    <sample id="468">Eliciting expressions</sample>
    <sample id="469">Il video presenta un corpus di 400.000 domande naturali in 300.000 entità, utilizzate per valutare l'accuratezza dei modelli di linguaggio naturale (LM) in riferimento al contesto generale.</sample>
    <sample id="470">Il video presenta un slide di presentazione che introduce il corpus AlignedEntities, una raccolta di 420.000 domande naturali in tre lingue diverse. Il corpus è stato utilizzato per valutare l'accuratezza dei modelli di linguaggio generativo (LLMs) come il T5 XL e il LLM. I risultati della valutazione mostrano che i LLM hanno una precisione del 92% quando si riferiscono al "stesso" entità con parole differenti, ma solo del 82% quando le entità sono parzialmente sovrapposte. Il video conclude con un link alla raccolta di dati AlignedEntities su GitHub.</sample>
    <sample id="471">Il video presenta un presentatore che parla in fronte a una presentazione di Google Research. La presentazione descrive il corpus AlignedEntities, che contiene 420,000 domande naturali in tre domini diversi. Il corpus è stato utilizzato per valutare l'accuratezza dei modelli linguistici (LM) in riferimento al contesto dietro le parole. I modelli sono stati addestrati su un subset di 420,000 domande e testati su un subset separato di 82,872 domande. I modelli hanno ottenuto un'accuratezza del 92% per i LM con accesso al contesto dietro le parole e del 82% per i LM con solo accesso ai nomi degli enti. Il corpus è disponibile online e il link è fornito nella presentazione.</sample>
    <sample id="472">Il video presenta un presentatore che parla in fronte a una presentazione. La presentazione presenta i principali punti della discussione, inclusi i principali punti della discussione, i punti chiave della presentazione e i punti chiave della presentazione. Il presentatore spiega i punti della presentazione in dettaglio, fornendo informazioni dettagliate sui punti della presentazione.</sample>
    <sample id="473">walk-k, LA, CA, ED</sample>
    <sample id="474">L'Institut de Recherche en Informatique et Systèmes d'Information (IRISA), L'Agence Nationale de Sécurité Sanitaire de l'Alimentation, de l'Environnement et du Travail (ANSES), L'Institut de Génétique et de Pathogénie Moléculaire (IGPM), L'Institut de Biologie Moléculaire et Structurale (IBMM), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Biologie Moléculaire et Structurale (IBMM), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de Modélisation (IBiS), L'Institut de Bioinformatique et de</sample>
    <sample id="475">Jennifer T. Lang</sample>
    <sample id="476">3</sample>
    <sample id="477">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="478">Quando ha freddo in casa, metto il tè in un thermos e lo porto con me.</sample>
    <sample id="479">Quali sono i problemi dei modelli attuali di SimuLST?</sample>
    <sample id="480">Quali sono i problemi dei modelli attuali di SimuLST?</sample>
    <sample id="481">Quali sono i problemi dei modelli attuali di SimuLST?</sample>
    <sample id="482">What is our solution?</sample>
    <sample id="483">Utilizziamo modelli offline esistenti per risolvere i problemi.</sample>
    <sample id="484">What is our solution?</sample>
    <sample id="485">Ecco il contenuto in inglese:</sample>
    <sample id="486">Our solution: FDAit.</sample>
    <sample id="487">I am going to talk about...</sample>
    <sample id="488">I will talk about it.</sample>
    <sample id="489">I will translate the content into Italian.</sample>
    <sample id="490">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="491">EMITTED</sample>
    <sample id="492">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="493">EMITTED</sample>
    <sample id="494">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="495">Il contenuto in inglese è: 'Main Results: FADaiT'</sample>
    <sample id="496">Il contenuto in inglese è un'introduzione alla presentazione.</sample>
    <sample id="497">Il contenuto in inglese è: Main Results: FADait:</sample>
    <sample id="498">Il contenuto in inglese è: 'Main Results: FADAlt: 27'</sample>
    <sample id="499">Il contenuto in inglese è: 'Main Results: FADaiT:'.</sample>
    <sample id="500">Il contenuto in inglese parla di una presentazione.</sample>
    <sample id="501">Il contenuto in inglese parla di una presentazione.</sample>
    <sample id="502">Il contenuto in inglese parla di una presentazione che include un grafico.</sample>
    <sample id="503">EFDAt is the fastest strategy considered in the elapsed time.</sample>
    <sample id="504">Marco Turchi</sample>
    <sample id="505">Yes</sample>
    <sample id="506">MULTINSTRUCT: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning</sample>
    <sample id="507">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="508">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="509">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="510">Inserisci il testo in inglese e otterrai il testo tradotto in italiano.</sample>
    <sample id="511">Imbalances in Instructional Datasets between NLP and Multimodal</sample>
    <sample id="512">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="513">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="514">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="515">OFA, One All</sample>
    <sample id="516">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="517">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="518">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="519">Multi-modal Instruction Tuning</sample>
    <sample id="520">Utilizza il VOTA split per suddividere i task in 9 group.</sample>
    <sample id="521">Il contenuto in inglese è: Multi-Modal Instruction Tuning</sample>
    <sample id="522">Il contenuto in inglese è il seguito di una presentazione.</sample>
    <sample id="523">Il contenuto in inglese è: "Training details: Pre-trained OF-A-Large model (472M) - No mix-in tasks for all instances - Each instance randomly combined in one of five instruction templates."</sample>
    <sample id="524">Il contenuto in inglese è: "Training details: - Pre-trained OF-A-Large model (472M) - No mix-in tasks for all instances - Each instance randomly combined in one of five instruction templates"</sample>
    <sample id="525">Evaluazione dei modelli.</sample>
    <sample id="526">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="527">Il contenuto in inglese è: "Efficiency of Instruction Tuning on MULTINSTRUCT"</sample>
    <sample id="528">Il contenuto in inglese è: "Efficiency of Instruction Tuning on MULTINSTRUCT"</sample>
    <sample id="529">Il contenuto in inglese parla dell'impatto dell'aumento dei cluster di compiti multimediali sulle prestazioni dei modelli.</sample>
    <sample id="530">Il contenuto in inglese parla dell'effetto delle istruzioni diverse sul tuning dell'instruzione.</sample>
    <sample id="531">Il contenuto in inglese parla dell'effetto dei strategie di ottimizzazione fine su una sensibilità del modello.</sample>
    <sample id="532">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="533">Conclusione</sample>
    <sample id="534">One More Thing!</sample>
    <sample id="535">Universita Di Trento, Fondazione Bruno Kessler</sample>
    <sample id="536">Mohammad javad Hosseini</sample>
    <sample id="562">L'interpretazione dei modelli linguistici non è sempre robusta al contesto.</sample>
    <sample id="563">L'interpretazione dei modelli linguistici non è sempre robusta al contesto.</sample>
    <sample id="564">Ricordando paradigma minimale</sample>
    <sample id="565">Ricordando paradigma minimale</sample>
    <sample id="566">Ricordando paradigma minimale</sample>
    <sample id="567">Ricordando paradigma minimale</sample>
    <sample id="568">Ricordando Paradigma Minimale</sample>
    <sample id="569">Ricordando Paradigma Minimale</sample>
    <sample id="570">Ricordando Paradigma Minimale</sample>
    <sample id="571">Approach Test whether MPP agrees vary as a function of context length, structural match, and acceptability.</sample>
    <sample id="572">Approach Test whether MPP agrees vary as a function of context length, structural, and acceptability.</sample>
    <sample id="573">Approach Test whether MPP agrees vary as a function of context length, structural, and acceptability.</sample>
    <sample id="574">Approach Test whether MPP agrees vary as a function of context length, structural, and acceptability.</sample>
    <sample id="575">Approach Test whether MPP agrees vary as a function of context length, structural, and acceptability.</sample>
    <sample id="576">Approach Test whether MPP agrees vary as a function of context length, structural match, and acceptability.</sample>
    <sample id="577">Approach Test whether MPP agrees vary as a function of context length, structural match, and acceptability.</sample>
    <sample id="578">Approach Test whether MPP agrees vary as a function of context length, structural match, and acceptability.</sample>
    <sample id="579">Approach Test whether MPP agrees vary as a function of context length, structural match, and acceptability.</sample>
    <sample id="580">Approach Test whether MPP agrees vary as a function of context length, structural match, and acceptability.</sample>
    <sample id="581">In the first part of the video, the speaker explains that the performance of the MPP is robust for arbitrary context lengths.</sample>
    <sample id="582">We perform MPP judgments for different context lengths (different to 700/acceptable: matched/mismatched structure of lengths up to 900 tokens).</sample>
    <sample id="583">We perform MPPV structure with different contexts (acceptable/unacceptable) and matched/mismatched structure lengths up to 900 tokens.</sample>
    <sample id="584">We perform MPPV structure with different contexts (acceptable/unacceptable) and matched/mismatched structure lengths up to 900 tokens.</sample>
    <sample id="585">We perform MPPV structure with different contexts (acceptable/unacceptable) and matched/mismatched structure lengths up to 900 tokens.</sample>
    <sample id="586">3. Acceptable/Unacceptable MPP sentences with matched structure most severely affect model performance</sample>
    <sample id="587">3. Acceptable/Unacceptable MPP sentences with matched structure most severely affect model performance</sample>
    <sample id="588">3. Acceptable/Unacceptable MPP sentences with matched structure most severely affect model performance</sample>
    <sample id="589">Why do matched prefixes affect LM judgments?</sample>
    <sample id="590">Why do matched prefixes affect LM judgments?</sample>
    <sample id="591">Why do matched prefixes affect LM judgments?</sample>
    <sample id="592">Why do matched prefixes affect LM judgments?</sample>
    <sample id="593">Why do matched prefixes affect LM judgments?</sample>
    <sample id="594">Key Takeaways</sample>
    <sample id="595">Key Takeaways Language models are sensitive to latent syntactic/semantic features shared across sentences. MPP evaluations with short (short-single) sentence inputs do not fully LIME.</sample>
    <sample id="596">Key Takeaways Language models are sensitive to latent syntactic/semantic features shared across sentences. MPP evaluations with short (short-single) sentence inputs do not fully LIME.</sample>
    <sample id="597">[CLS]</sample>
    <sample id="598">50,000</sample>
    <sample id="626">LHA</sample>
    <sample id="627">Weak supervision alleviates the annotation bottleneck.</sample>
    <sample id="628">The documents in DEplain-web have been aligned using both manual and automatic alignment methods.</sample>
    <sample id="629">The dataset was created by collecting news articles from Reuters and annotating them with CONLL-2003 guidelines.</sample>
    <sample id="630">XSemPLR: Cross-Linguistic Semantic Parsing in Multiple Natural Languages and Meaning Representations</sample>
    <sample id="631">Semantic Parsing è il compito di costruire una rappresentazione semantica delle query dell'utente.</sample>
    <sample id="632">Cross-lingual semantic parsing</sample>
    <sample id="633">Cross-lingual semantic parsing is a task to translate queries in multiple natural languages into multiple meaning representations.</sample>
    <sample id="634">Cross-lingual semantic parsing</sample>
    <sample id="635">Cross-lingual semantic parsing</sample>
    <sample id="636">Cross-lingual semantic parsing</sample>
    <sample id="637">Cross-lingual semantic parsing</sample>
    <sample id="638">Cross-lingual semantic parsing</sample>
    <sample id="639">XSemPLR</sample>
    <sample id="640">XSemPLR</sample>
    <sample id="641">Ecco la traduzione in italiano:</sample>
    <sample id="642">Ecco la traduzione in italiano:</sample>
    <sample id="643">Ecco la traduzione in italiano:</sample>
    <sample id="644">Ecco la traduzione in italiano:</sample>
    <sample id="645">Ecco la traduzione in italiano:</sample>
    <sample id="646">Ecco la traduzione in italiano:</sample>
    <sample id="647">Ecco la traduzione in italiano:</sample>
    <sample id="648">Ecco la traduzione in italiano:</sample>
    <sample id="649">Ecco la traduzione in italiano:</sample>
    <sample id="650">Ecco la traduzione in italiano:</sample>
    <sample id="651">Ecco la traduzione in italiano:</sample>
    <sample id="652">Analisi di Monolinguale</sample>
    <sample id="653">Analisi di Monolinguale</sample>
    <sample id="654">Analisi di Monolinguale</sample>
    <sample id="655">Analisi di Monolinguale</sample>
    <sample id="656">Analisi dell'addestramento multilingue</sample>
    <sample id="657">Analisi dell'addestramento multilingue</sample>
    <sample id="658">Analisi della Formazione Multilingue</sample>
    <sample id="659">Analisi della Formazione Multilingue</sample>
    <sample id="660">Cross-lingual performance gap</sample>
    <sample id="661">Cross-lingual performance gap</sample>
    <sample id="662">Cross-lingual Performance Gap</sample>
    <sample id="663">Ecco una traduzione in italiano del contenuto in inglese:</sample>
    <sample id="664">Ecco una traduzione in italiano del contenuto in inglese:</sample>
    <sample id="665">Conclusione</sample>
    <sample id="666">Conclusione</sample>
    <sample id="667">[1], [2], [3], [4]</sample>
    <sample id="668">No</sample>
    <sample id="695">Il modello utilizza una procedura di backpropagation per risolvere l'ambiguità.</sample>
    <sample id="696">The fairness of a NLP model at the bottom is defined as the difference between the accuracy of the model on the majority group and the accuracy of the model on the minority group.</sample>
    <sample id="697">Richard Douroux</sample>
    <sample id="698">Koushik Suvitha</sample>
    <sample id="699">Myra Cheng</sample>
    <sample id="700">Exotic</sample>
    <sample id="701">Through essentializing narratives</sample>
    <sample id="702">P-PMI</sample>
    <sample id="703">DrBERT is a pre-trained model, while ChuBERT is a fine-tuned model.</sample>
    <sample id="751">3</sample>
    <sample id="752">Il trasferimento iterativo dell'apprendimento è un processo in cui il modello viene aggiornato con nuovi esempi, ma anche con i vecchi esempi.</sample>
    <sample id="753">Understand users' language when they make a choice</sample>
    <sample id="754">Infiltrando il servizio EaaS con un malware</sample>
    <sample id="755">3</sample>
    <sample id="756">15</sample>
    <sample id="757">Subotin S. Jenny T., Ronan Bres, Katharina Reinecke, Marleen Sap</sample>
    <sample id="758">[not] is on the left</sample>
    <sample id="759">Coherence, Knowledge, Consistency, Emotional Understanding</sample>
    <sample id="760">Because the models are evaluated in a long context</sample>
    <sample id="761">No</sample>
    <sample id="762">yes</sample>
    <sample id="763">BLEU, METEOR, ROUGE-L</sample>
    <sample id="764">No</sample>
    <sample id="765">Perché il contesto è importante.</sample>
    <sample id="766">Adattatori</sample>
    <sample id="767">Roberta-base</sample>
    <sample id="768">C4, CC1M, and CC2M</sample>
    <sample id="769">3</sample>
    <sample id="770">1.5%</sample>
    <sample id="771">Shuhui Liu</sample>
    <sample id="772">yes</sample>
    <sample id="773">3</sample>
    <sample id="774">DPT</sample>
    <sample id="833">Google</sample>
    <sample id="834">Storybrook University, Human Language Analytics</sample>
    <sample id="835">Italiano e Inglese</sample>
    <sample id="836">Yulia Tsvetkova</sample>
    <sample id="837">DELP-AP-48, DELP-AP-128, DELP-WE-48, DELP-WE-128</sample>
    <sample id="838">53</sample>
    <sample id="839">3</sample>
    <sample id="840">Copy Dataset, AG News, MIND, ST2N, ER2N Spam</sample>
    <sample id="876">NACHOS è un modello di pre-training per il linguaggio naturale.</sample>
    <sample id="877">David Warms Markes</sample>
    <sample id="878">40 BLEURT points</sample>
    <sample id="879">University of Edinburgh, University of Glasgow, University of Manchester</sample>
    <sample id="880">1. How to use a computer, 2. How to use a mobile phone, 3. How to use a printer, 4. How to use a scanner, 5. How to use a fax machine</sample>
    <sample id="881">A coreference resolution task</sample>
    <sample id="882">Google's PALM for Translation: Assessing Strategies and Performance</sample>
    <sample id="883">Pal.M. Pathways Language Model</sample>
    <sample id="884">Pal.M. Pathways Language Model</sample>
    <sample id="885">Our contribution</sample>
    <sample id="886">Our contribution</sample>
    <sample id="887">Our contribution</sample>
    <sample id="888">Our contribution</sample>
    <sample id="889">Prompts have a big impact on translation quality</sample>
    <sample id="890">Prompts have a big impact on translation quality</sample>
    <sample id="891">Prompts have a big impact on translation quality</sample>
    <sample id="892">5-step prompting for translation</sample>
    <sample id="893">5-step prompting for translation</sample>
    <sample id="894">5-step prompting for translation</sample>
    <sample id="895">5-step prompting for translation</sample>
    <sample id="896">5-step prompting for translation</sample>
    <sample id="897">Esperienze sull'OMM</sample>
    <sample id="898">Esperienze sull'OMM</sample>
    <sample id="899">Esperienze sull'OMM</sample>
    <sample id="900">Esperienze sull'OMM</sample>
    <sample id="901">Esperimentali Risultati</sample>
    <sample id="902">Esperienze sull'OMM</sample>
    <sample id="903">Esperienze sull'OMM</sample>
    <sample id="904">Esperienze sull'OMM</sample>
    <sample id="905">Esperienze sull'OMM</sample>
    <sample id="906">"Thank you" is a phrase used to express gratitude.</sample>
    <sample id="907">Worse Than You Think A Critical Look at Weekly Supervised Learning</sample>
    <sample id="908">A Critical Look at Weekly Supervised Learning</sample>
    <sample id="909">Why weakly supervised learning?</sample>
    <sample id="910">Why weakly supervised learning?</sample>
    <sample id="911">Why weakly supervised learning?</sample>
    <sample id="912">Why weakly supervised learning?</sample>
    <sample id="913">Why weakly supervised learning?</sample>
    <sample id="914">A common claim in recent WSL works</sample>
    <sample id="915">A common claim in recent WSL works</sample>
    <sample id="916">A common claim in recent WSL works</sample>
    <sample id="917">A common claim in recent WSL works</sample>
    <sample id="918">Our research questions</sample>
    <sample id="919">Our research questions</sample>
    <sample id="920">R01 Main findings</sample>
    <sample id="921">R01 Main findings</sample>
    <sample id="922">R01 Main findings</sample>
    <sample id="923">R01 Main findings</sample>
    <sample id="924">R01 Main findings A clean validation set is indispensable.</sample>
    <sample id="925">The speaker is discussing the results of a study on the accuracy of different methods for predicting the presence of a certain condition in patients. The speaker explains that the graph shows the accuracy of each method as the number of validation cases increases, and that the results are statistically significant with p-values less than 0.05.</sample>
    <sample id="926">The graph shows the accuracy of different methods in a validation set.</sample>
    <sample id="927">RQ2 Main findings</sample>
    <sample id="928">RQ2 Main findings</sample>
    <sample id="929">RQ2 Main findings</sample>
    <sample id="930">R03 Main findings</sample>
    <sample id="931">R03 Main findings</sample>
    <sample id="932">R03 Main findings</sample>
    <sample id="933">R03 Main findings</sample>
    <sample id="934">Conclusions Recent WSL approaches  Overestimate their practicality. Our recommendations Use Few-shot learning approach as baselines Apply continuous fine-tuning (CFT)</sample>
    <sample id="935">Conclusions Recent WSL approaches  Overestimate their practicality. Our recommendations Use Few-shot learning approach criteria as baselines Apply continuous fine-tuning (CFT)</sample>
    <sample id="936">Conclusions Recent WSL approaches  Overestimate their practicality. Our recommendations Use Few-shot learning approach as baselines Apply continuous fine-tuning (CFT)</sample>
    <sample id="937">Conclusions Recent WSL approaches  Overestimate their practicality. Our recommendations Use Few-shot learning approach as baselines Apply continuous fine-tuning (CFT)</sample>
    <sample id="938">Conclusions Recent WSL approaches 1. Require clean samples. 2. Overestimate their practicality. Our recommendations 1. Report the model selection criteria. 2. Use Few-shot learning approach as baselines. 3. Apply continuous fine-tuning (CFT).</sample>
    <sample id="939">Comparative evaluation, Likert rating evaluation</sample>
    <sample id="940">cinque</sample>
    <sample id="941">Servin è un giustiziere e Kea è una pasticcera.</sample>
    <sample id="942">yes, on GitHub</sample>
    <sample id="943">No, non sono bilanciati.</sample>
    <sample id="944">Sostituito il primo verbo con un verbo equivalente</sample>
    <sample id="945">Avalutare le dimensioni</sample>
    <sample id="946">University of Science and Technology of China, Microsoft Research Asia, University of Science and Technology of China</sample>
    <sample id="947">Se presentano errori grammatici</sample>
    <sample id="978">ChatGPT, GPT-4, GPT-4-16K, GPT-4-16K-2048, GPT-4-16K-2048-256, GPT-4-16K-2048-512, GPT-4-16K-2048-768, GPT-4-16K-2048-1024, GPT-4-16K-2048-1536, GPT-4-16K-2048-2048, GPT-4-16K-2048-2560, GPT-4-16K-2048-3072, GPT-4-16K-2048-3584, GPT-4-16K-2048-4096, GPT-4-16K-2048-4608, GPT-4-16K-2048-5120, GPT-4-16K-2048-5632, GPT-4-16K-2048-6144, GPT-4-16K-2048-6656, GPT-4-16K-2048-7168, GPT-4-16K-2048-7680, GPT-4-16K-2048-8192, GPT-4-16K-2048-8704, GPT-4-16K-2048-9328, GPT-4-16K-2048-9952, GPT-4-16K-2048-10576, GPT-4-16K-2048-11200, GPT-4-16K-2048-11824, GPT-4-16K-2048-12448, GPT-4-16K-2048-13072, GPT-4-16K-2048-13696, GPT-4-16K-2048-14320, GPT-4-16K-2048-14944, GPT-4-16K-2048-15568, GPT-4-16K-2048-16192, GPT-4-16K-2048-16816, GPT-4-16K-2048-17440, GPT-4-16K-2048-18064, GPT-4-16K-2048-18688, GPT-4-16K-2048-19312, GPT-4-16K-2048-19936, GPT-4-16K-2048-20560, GPT-4-16K-2048-21184, GPT-4-16K-2048-21808, GPT-4-16K-2048-22432, GPT-4-16K-2048-23056, GPT-4-16K-2048-23680, GPT-4-16K-2048-24304, GPT-4-16K-2048-24928, GPT-4-16K-2048-25552, GPT-4-16K-2048-26176, GPT-4-16K-2048-26800, GPT-4-16K-2048-27424, GPT-4-16K-2048-28048, GPT-4-16K-2048-28672, GPT-4-16K-2048-29296, GPT-4-16K-2048-29920, GPT-4-16K-2048-30544, GPT-4-16K-2048-31168, GPT-4-16K-2048-31792, GPT-4-16K-2048-32416, GPT-4-16K-2048-33040, GPT-4-16K-2048-33664, GPT-4-16K-2048-34288, GPT-4-16K-2048-34912, GPT-4-16K-2048-35536, GPT-4-16K-2048-36160, GPT-4-16K-2048-36784, GPT-4-16K-2048-37408, GPT-4-16K-2048-38032, GPT-4-16K-2048-38656, GPT-4-16K-2048-39280, GPT-4-16K-2048-39904, GPT-4-16K-2048-40528, GPT-4-16K-2048-41152, GPT-4-16K-2048-41776, GPT-4-16K-2048-42400, GPT-4-16K-2048-43024, GPT-4-16K-2048-43648, GPT-4-16K-2048-44272, GPT-4-16K-2048-44896, GPT-4-16K-2048-45520, GPT-4-16K-2048-46144, GPT-4-16K-2048-46768, GPT-4-16K-2048-47392, GPT-4-16K-2048-48016, GPT-4-16K-2048-48640, GPT-4-16K-2048-49264, GPT-4-16K-2048-49888, GPT-4-16K-2048-50512, GPT-4-16K-2048-51136, GPT-4-16K-2048-51760, GPT-4-16K-2048-52384, GPT-4-16K-2048-53008, GPT-4-16K-2048-53632, GPT-4-16K-2048-54256, GPT-4-16K-2048-54880, GPT-4-16K-2048-55504, GPT-4-16K-2048-56128, GPT-4-16K-2048-56752, GPT-4-16K-2048-57376, GPT-4-16K-2048-57904, GPT-4-16K-2048-58528, GPT-4-16K-2048-59152, GPT-4-16K-2048-59776, GPT-4-16K-2048-60400, GPT-4-16K-2048-61024, GPT-4-16K-2048-61648, GPT-4-16K-2048-62272, GPT-4-16K-2048-62896, GPT-4-16K-2048-63520, GPT-4-16K-2048-64144, GPT-4-16K-2048-64768, GPT-4-16K-2048-65392, GPT-4-16K-2048-66016, GPT-4-16K-2048-66640, GPT-4-16K-2048-67264, GPT-4-16K-2048-67888, GPT-4-16K-2048-68512, GPT-4-16K-2048-69136, GPT-4-16K-2048-69760, GPT-4-16K-2048-70384, GPT-4-16K-2048-71008, GPT-4-16K-2048-71632, GPT-4-16K-2048-72256, GPT-4-16K-2048-72880, GPT-4-16K-2048-73504, GPT-4-16K-2048-74128, GPT-4-16K-2048-74752, GPT-4-16K-2048-75376, GPT-4-16K-2048-76000, GPT-4-16K-2048-76624, GPT-4-16K-2048-77248, GPT-4-16K-2048-77872, GPT-4-16K-2048-78496, GPT-4-16K-2048-79120, GPT-4-16K-2048-79744, GPT-4-16K-2048-80368, GPT-4-16K-2048-80992, GPT-4-16K-2048-81616, GPT-4-16K-2048-82240, GPT-4-16K-2048-82864, GPT-4-16K-2048-83488, GPT-4-16K-2048-84112, GPT-4-16K-2048-84736, GPT-4-16K-2048-85360, GPT-4-16K-2048-85984, GPT-4-16K-2048-86608, GPT-4-16K-2048-87232, GPT-4-16K-2048-87856, GPT-4-16K-2048-88480, GPT-4-16K-2048-89104, GPT-4-16K-2048-89728, GPT-4-16K-2048-90352, GPT-4-16K-2048-90976, GPT-4-16K-2048-91600, GPT-4-16K-2048-92224, GPT-4-16K-2048-92848, GPT-4-16K-2048-93472, GPT-4-16K-2048-94096, GPT-4-16K-2048-94720, GPT-4-16K-2048-95344, GPT-4-16K-2048-95968, GPT-4-16K-2048-96592, GPT-4-16K-2048-97216, GPT-4-16K-2048-97840, GPT-4-16K-2048-98464, GPT-4-16K-2048-99088, GPT-4-16K-2048-99712, GPT-4-16K-2048-100336, GPT-4-16K-2048-100960, GPT-4-16K-2048-101584, GPT-4-16K-2048-102208, GPT-4-16K-2048-102832, GPT-4-16K-2048-103456, GPT-4-16K-2048-104080, GPT-4-16K-2048-104704, GPT-4-16K-2048-105328, GPT-4-16K-2048-105952, GPT-4-16K-2048-106576, GPT-4-16K-2048-107200, GPT-4-16K-2048-107824, GPT-4-16K-2048-108448, GPT-4-16K-2048-109072, GPT-4-16K-2048-109696, GPT-4-16K-2048-110320, GPT-4-16K-2048-110944, GPT-4-16K-2048-111568, GPT-4-16K-2048-112192, GPT-4-16K-2048-112816, GPT-4-16K-2048-113440, GPT-4-16K-2048-114064, GPT-4-16K-2048-114688, GPT-4-16K-2048-115312, GPT-4-16K-2048-115936, GPT-4-16K-2048-116560, GPT-4-16K-2048-117184, GPT-4-16K-2048-117808, GPT-4-16K-2048-118432, GPT-4-16K-2048-119056, GPT-4-16K-2048-119680, GPT-4-16K-2048-120304, GPT-4-16K-2048-120928, GPT-4-16K-2048-121552, GPT-4-16K-2048-122176, GPT-4-16K-2048-122800, GPT-4-16K-20</sample>
    <sample id="979">cinque</sample>
    <sample id="980">Being able to understand the goal, being able to understand the constraints and being able to understand the real-life specifics.</sample>
    <sample id="981">10</sample>
    <sample id="982">Vasudha Varadarajan</sample>
    <sample id="983">Institute of Computer Science, University of Warsaw</sample>
    <sample id="1021">Accuracy scores generally lower</sample>
    <sample id="1022">Il video presenta un presentatore in una conferenza online, con una presentazione di PowerPoint sullo schermo. Il presentatore, un uomo in un blazer nero, parla in un microfono e fa gesti con le mani. La presentazione ha un titolo "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems" e include i nomi degli autori: Sarah E. Finch, James D. Finch, and Jinho D. Choi. L'immagine del presentatore è posizionata in un angolo della presentazione.</sample>
    <sample id="1023">Il video presenta un presentatore in un video di conferenza, con una presentazione di PowerPoint sullo schermo. La presentazione ha un'introduzione che dice "Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems" e include i nomi dei presentatori: Sarah E. Finch, James D. Finch, and Jinho D. Choi. La presentazione è associata all'Emory University e all'Emory NLP Research Lab, con il marchio dell'Alexa.</sample>
    <sample id="1024">Il contenuto della tua domanda è in inglese. Ecco la versione tradotta in italiano:</sample>
    <sample id="1025">Comparative Evaluation</sample>
    <sample id="1026">L'analisi della valutazione del dialogo</sample>
    <sample id="1027">Il video presenta una presentazione di PowerPoint intitolata "Liker Rating Evaluation" (Evaluazione del punteggio Likert). La presentazione inizia con un slide che include il titolo e l'illustrazione di una giustiziara con un martello, seguito da una serie di punti numerati da 1 a 5. Ogni punto è rappresentato da un quadratino vuoto, seguito da una casella vuota per i punti. Il slide successivo presenta due figure: una con un viso e due bubble speech, rappresentando le risposte dei soggetti. Il slide finale presenta la stessa struttura, ma con i punti numerati da 1 a 5, ognuno seguito da una casella vuota per i punti. Il slide finale presenta la stessa struttura, ma con i punti numerati da 1 a 5, ognuno seguito da una casella vuota per i punti.</sample>
    <sample id="1028">L'analisi Likert per l'autovalutazione</sample>
    <sample id="1029">Annotating Behaviors in Chat (ABC-Eval)</sample>
    <sample id="1030">Annotating Behaviors in Chat (ABC-Eval)</sample>
    <sample id="1031">ABC-Eval Behaviors</sample>
    <sample id="1032">ABC-Eval Behaviors</sample>
    <sample id="1033">ABC-Eval Behaviors</sample>
    <sample id="1034">Esempio:</sample>
    <sample id="1035">4 Open-Domain Dialogue Models 100 Human-Bot Conversations per Model</sample>
    <sample id="1036">Turn Lifter</sample>
    <sample id="1037">Turn Liker</sample>
    <sample id="1038">Turn Likert</sample>
    <sample id="1039">Turn Likert</sample>
    <sample id="1040">Incremental Validity</sample>
    <sample id="1041">Incremental Validity</sample>
    <sample id="1042">Incremental Validity</sample>
    <sample id="1043">Inserisci il testo qui</sample>
    <sample id="1044">Il diagramma presenta i tassi di errori ABC-Eval per diversi modelli.</sample>
    <sample id="1045">Il diagramma presenta i tassi di errori ABC-Eval per diversi modelli. I modelli sono classificati in base alla loro performance, con quelli con il miglior tasso di errori in cima e quelli peggiori in fondo. Il diagramma include anche una legenda che spiega i colori usati per rappresentare i modelli.</sample>
    <sample id="1046">Il diagramma presenta i tassi di errori ABC-Eval per diversi modelli.</sample>
    <sample id="1047">Il video presenta una presentazione in cui un personaggio parla in un microfono. Il personaggio è in un ambiente formale, con un fondale blu e una presentazione di PowerPoint sullo schermo dietro di lui. La presentazione include informazioni dettagliate su errori di valutazione per diversi modelli, con barre di percentuale che rappresentano il tasso di errori per ciascun modello. Inoltre, la presentazione include informazioni sul paper, sul repository GitHub, sulle informazioni di contatto e sul sito web dell'entità.</sample>
    <sample id="1048">Emory University, Emory NLP Research Lab, and Amazon Alexa</sample>
    <sample id="1049">Continuously fine-tuning</sample>
    <sample id="1050">6</sample>
    <sample id="1051">When Does Translation Require Context? A Data-driven, Multilingual Exploration</sample>
    <sample id="1052">Traduzione dipende dal contesto</sample>
    <sample id="1053">Traduzione dipende dal contesto</sample>
    <sample id="1054">Traduzione dipende dal contesto</sample>
    <sample id="1055">Evaluating context-dependent translation is hard.</sample>
    <sample id="1056">Evaluating context-dependent translation is hard.</sample>
    <sample id="1057">RQ2: When does translation require context?</sample>
    <sample id="1058">RQ2: When does translation require context? - Word-level context usage RQ3: How well do models handle context-dependent translations?</sample>
    <sample id="1059">Conditional Cross-Mutual Information (CXMI)</sample>
    <sample id="1060">Cross-Entropy (CE)</sample>
    <sample id="1061">Pointwise P(CXMI) We introduce P-CXMI to measure context to translate a specific sentence.</sample>
    <sample id="1062">RQ2: When does translation require context? - Word-level text usage - Thematic analysis RQ3: How well will models handle context-dependent translations?</sample>
    <sample id="1063">Thematic analysis of high P-CXMI words</sample>
    <sample id="1064">Thematic analysis of high-PCXMI words 1. POS tags</sample>
    <sample id="1065">Thematic analysis of high-PCXMI words 1. POS tags Pronouns</sample>
    <sample id="1066">Thematic analysis of high PCXMI words</sample>
    <sample id="1067">Thematic analysis of high P-CCMI words 1. POS tags 2. Vocabulary items - Pronouns - Verb form 3. Lexical cohesion Avellene's mother was still asleep. Avellene went to school.</sample>
    <sample id="1068">Thematic analysis of high P-CXMI words</sample>
    <sample id="1069">Thematic analysis of high P-CXMI words</sample>
    <sample id="1070">RQ1: When does translation require context?</sample>
    <sample id="1071">Multilingual Discourse-Aware (MuDA) tagger</sample>
    <sample id="1072">Multilingual Discourse-Aware (MuDA) tagger</sample>
    <sample id="1073">Il video presenta una presentazione di PowerPoint che descrive il processo di calcolo dell'F-misurazione in un benchmark. La presentazione inizia con una slide che introduce il benchmark e include un diagramma che illustra i principali componenti del processo. Il diagramma mostra tre blocchi principali: "MuDA tagger", "BLEU" e "COMET F-misure". Il "MuDA tagger" è rappresentato da un cubo con due file di testo all'interno, il "BLEU" è rappresentato da un cubo con due file di testo all'interno, e il "COMET F-misure" è rappresentato da un cubo con due file di testo all'interno. Il diagramma indica che il "MuDA tagger" è collegato al "BLEU" tramite una freccia, il "BLEU" è collegato al "COMET F-misure" tramite una freccia, e il "COMET F-misure" è collegato al "MuDA tagger" tramite una freccia. Il diagramma illustra il flusso di lavoro tra i componenti principali del benchmark, mostrando come i file di testo vengono processati e analizzati per calcolare l'F-misurazione.</sample>
    <sample id="1074">RQ1: When does translation require context?</sample>
    <sample id="1075">Risorse per i linguaggi naturali</sample>
    <sample id="1076">Corpus-level metrics</sample>
    <sample id="1077">Corpus-level metrics</sample>
    <sample id="1078">MUDa benchmark results</sample>
    <sample id="1079">MUDa benchmark results</sample>
    <sample id="1080">MUDa benchmark results</sample>
    <sample id="1081">Summarize</sample>
    <sample id="1082">Summarize</sample>
    <sample id="1083">Summarize</sample>
    <sample id="1084">Yusen Zhang</sample>
    <sample id="1121">Permuting with 'jumps'</sample>
    <sample id="1122">Find words that distinguish personas of marked groups from unmarked groups</sample>
    <sample id="1123">University of Washington, Carnegie Mellon University, University of Edinburgh</sample>
    <sample id="1124">Bouquet (Stanford)</sample>
    <sample id="1125">Sarah E. Finch</sample>
    <sample id="1126">4</sample>
    <sample id="1127">Minimal Pair Paradigm</sample>
    <sample id="1161">FT, L2R, COSINE, MLC, BOND</sample>
    <sample id="1162">13 tasks</sample>
    <sample id="1226">40GB of Wikipedia data</sample>
    <sample id="1227">Adam Prezrokowski</sample>
    <sample id="1228">Performance degrades with larger temporal gap</sample>
    <sample id="1269">Permette di ottenere una sequenza di output che rispetti l'ordine dei token originali.</sample>
    <sample id="1270">Perché i modelli sono spesso considerati come "black boxes" e la trasparenza aiuta a comprendere come funzionano.</sample>
    <sample id="1271">The minimal pair paradigm</sample>
    <sample id="1272">F1 score, accuracy, and BLEU score.</sample>
    <sample id="1273">Krippendorff's alpha</sample>
    <sample id="1274">space</sample>
    <sample id="1275">Heinrich Heine University, Heinrich-Heine-Universität Dissolfort, Germany</sample>
    <sample id="1276">It is the only dataset that includes multimodal instruction tasks.</sample>
    <sample id="1277">3</sample>
    <sample id="1278">A binary coordination is a pair of characters that are adjacent to each other and have the same length.</sample>
    <sample id="1279">10 days</sample>
    <sample id="1280">The smaller T5 model produces higher quality scripts than the larger models.</sample>
    <sample id="1281">DRBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains</sample>
    <sample id="1282">Il video presenta un presentatore in un ufficio, con una libreria di libri in primo piano. Il presentatore parla in un microfono, e la sua immagine è proiettata su una schermata. La schermata presenta un elenco di punti, inclusi "I. Language Modeling in Healthcare", "II. Comparison of pre-training strategies, data sources and sizes", "III. Evaluation of 13 models on 11 tasks", e "IV. Contribution of NACHOS AND DEBRET". Il presentatore spiega i punti dell'elenco, fornisce dettagli sulle strategie di pre-addestramento, le fonti dei dati e le dimensioni, e valuta 13 modelli su 11 compiti. Il presentatore conclude il video con i punti principali dell'elenco.</sample>
    <sample id="1283">Il video presenta un slideshow di presentazione.</sample>
    <sample id="1284">Il video presenta un slideshow di presentazione.</sample>
    <sample id="1285">I. Language Modeling in Healthcare II. Comparison of pre-training strategies, data sources and sizes III. Evaluation of 13 models on 11 tasks IV. Contribution of NACHOS and DEBRET</sample>
    <sample id="1286">Language Modeling Transformer-based approaches, such as BERT, offer a performance gain on NLP tasks. Has been adapted to French (CamemBERT and FERBERT) On medical domain: specific models (English) are the bar higher than other languages No rare languages: reliably rely on pre-trained French model Generalized model: no biomedical domain in French yet</sample>
    <sample id="1287">Language Modeling Transformer-based approaches, such as BERT, offer a performance gain on NLP tasks. Has been adapted to French (CamemBERT and FERBERT) On medical domain: specific models (English) are the bar higher than other languages No rare languages: reliably rely on pre-trained French existing model Generalized model: no biomedical domain in French yet</sample>
    <sample id="1288">Language Modeling Transformer-based approaches, such as BERT, offer a performance gain on NLP tasks. Has been adapted to French (CamemBERT and FERBERT) On medical domain: specific models (English) are the bar higher than other languages No rare languages rely on reliably pre-trained French existing model Generalized model (open-source) is not available for biomedical domain in French yet</sample>
    <sample id="1289">Language Modeling Transformer-based approaches, such as BERT, offer a performance gain on NLP tasks. Has been adapted to French (CamemBERT and FERBERT) On medical domain: specific models (English) are the bar higher than other languages No rare languages rely on reliably pre-trained French existing model Generalized model (open-source) is not available for biomedical domain in French yet</sample>
    <sample id="1290">Comparison of pre-training strategies and data sources</sample>
    <sample id="1291">Comparison of pre-training strategies and data sources</sample>
    <sample id="1292">Comparison of pre-training strategies and data sources</sample>
    <sample id="1293">Il video presenta una presentazione in cui il professor Arora spiega i principi della pre-azione dei modelli di apprendimento automatico.</sample>
    <sample id="1294">Comparison of pre-training strategies and data sources</sample>
    <sample id="1295">Comparison of pre-training strategies and data sources</sample>
    <sample id="1296">Comparison of pre-training strategies and data sources</sample>
    <sample id="1297">Evaluating the impact of public and private medical data sources on model performance.</sample>
    <sample id="1298">Evaluating: Data sources and size</sample>
    <sample id="1299">Evaluating: Data sources and size</sample>
    <sample id="1300">Evaluating: Data sources and size</sample>
    <sample id="1301">Evaluazione: Dati e dimensioni</sample>
    <sample id="1302">Evaluation: Pre-training strategies</sample>
    <sample id="1303">Evaluation: Pre-training strategies</sample>
    <sample id="1304">Evaluation: Pre-training strategies</sample>
    <sample id="1305">Diverse points are listed on the slide.</sample>
    <sample id="1306">Diverse points are presented in the slide.</sample>
    <sample id="1307">Diverse points are presented in the slide.</sample>
    <sample id="1308">Grazie per l'attenzione.</sample>
    <sample id="1309">The work examines the following learning strategies: supervised, semi-supervised, and self-supervised.</sample>
    <sample id="1310">1.5</sample>
    <sample id="1311">The quality of simplification was evaluated using the DEFT-APFA and DEFT-WE test sets.</sample>
    <sample id="1312">yes</sample>
    <sample id="1313">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="1314">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="1315">Capacità di un imparante a gestire una ricorsione più profonda e uncomprensioni di frasi che sono state viste individualmente durante il training.</sample>
    <sample id="1316">Il contenuto in inglese è: "The girl slept."</sample>
    <sample id="1317">Il contenuto in inglese è: "Compositionality in Semantic Parsing"</sample>
    <sample id="1318">Il testo in inglese è il seguente: "The girl slept."</sample>
    <sample id="1319">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="1320">The test sentence is "Jim said that Mary knew the girl slept."</sample>
    <sample id="1321">Compositional Generalization in Semantic Parsing</sample>
    <sample id="1322">Trees help a lot ... but...</sample>
    <sample id="1323">Trees help a lot ... but...</sample>
    <sample id="1324">Trees help a lot ... but...</sample>
    <sample id="1325">Trees help a lot ...</sample>
    <sample id="1326">Trees help a lot ...</sample>
    <sample id="1327">Trees help a lot ...</sample>
    <sample id="1328">Trees help a lot ...</sample>
    <sample id="1329">Our Approach</sample>
    <sample id="1330">Our Approach</sample>
    <sample id="1331">Our Approach</sample>
    <sample id="1332">Our Approach</sample>
    <sample id="1333">Our Approach</sample>
    <sample id="1334">Permuting with "jumps"</sample>
    <sample id="1335">Permuting with "jumps"</sample>
    <sample id="1336">Permuting with "jumps"</sample>
    <sample id="1337">Permuting with "jumps"</sample>
    <sample id="1338">Permuting with "jumps"</sample>
    <sample id="1339">Some Results on COGS (Kim and Lizenz 2020)</sample>
    <sample id="1340">Some Results on COGS (Kim and Lizenz 2020)</sample>
    <sample id="1341">Il contenuto in inglese è il seguente: "Technical Challenges We Solve"</sample>
    <sample id="1342">Technical Challenges We Solve</sample>
    <sample id="1343">Technical Challenges We Solve</sample>
    <sample id="1344">Technical Challenges We Solve</sample>
    <sample id="1345">Technical Challenges We Solve</sample>
    <sample id="1346">Il contenuto in inglese parla di una presentazione che include un diagramma e una serie di punti.</sample>
    <sample id="1347">Due elementi della nostra convinzione (pensieri, azioni, credenze) sono incompatibili</sample>
    <sample id="1348">GPT-4</sample>
    <sample id="1349">no</sample>
    <sample id="1350">Sara Papi</sample>
    <sample id="1351">P-CXMI</sample>
    <sample id="1385">Matthias Lindemann</sample>
    <sample id="1386">Cross-lingual transfer</sample>
    <sample id="1387">Saarlauand University, Amazon Alexa, 3rd University of Vienna</sample>
    <sample id="1388">AL, AL/CA, CA</sample>
    <sample id="1389">The KITMUS Test</sample>
    <sample id="1390">NLU models draw on multiple knowledge sources.</sample>
    <sample id="1391">NLU models draw on multiple knowledge sources.</sample>
    <sample id="1392">John saw the newly elected president on TV</sample>
    <sample id="1393">John saw the newly elected president on TV</sample>
    <sample id="1394">John saw the newly elected president on TV</sample>
    <sample id="1395">John saw the newly elected president on TV</sample>
    <sample id="1396">KITMUS Test Suite</sample>
    <sample id="1397">KITMUS Test Suite</sample>
    <sample id="1398">KITMUS Test Suite</sample>
    <sample id="1399">KITMUS Test Suite</sample>
    <sample id="1400">KITMUS Test Suite</sample>
    <sample id="1401">KITMUS Test Suite</sample>
    <sample id="1402">KITMUS Test Suite</sample>
    <sample id="1403">Variants of KITMUS</sample>
    <sample id="1404">Variants of KITMUS</sample>
    <sample id="1405">Variants of KITMUS</sample>
    <sample id="1406">Variants of KITMUS</sample>
    <sample id="1407">Variants of KITMUS</sample>
    <sample id="1408">Variants of KITMUS</sample>
    <sample id="1409">Variants of KITMUS</sample>
    <sample id="1410">Background - Pretrain</sample>
    <sample id="1411">Background - Pretrain</sample>
    <sample id="1412">Background - Pretrain</sample>
    <sample id="1413">Background - Inference</sample>
    <sample id="1414">Conclusione Main Takeaways: 1. Many models seem unable to reason over knowledge from multiple sources (pre-training and inference-time knowledge). 2. Task-specific training is necessary for knowledge integration. 3. Models struggle to integrate inference-time background knowledge. Find the dataset, generation &amp; evaluation code on GitHub at https://github.com/mpemskitt/kitmuts.</sample>
    <sample id="1415">Conclusione Main Takeaways: 1. Many models seem unable to reason over knowledge from multiple sources (pre-training and inference-time knowledge). 2. Task-specific training is necessary for knowledge integration. 3. Models struggle to integrate inference-time background knowledge. Find the dataset, generation &amp; evaluation code on GitHub at https://github.com/mpemskitt/kittus.</sample>
    <sample id="1416">Trees need to be obtained, Pre-Post-processing logical forms, Non-incremental</sample>
    <sample id="1417">School of Interactive Computing Georgia Institute of Technology</sample>
    <sample id="1418">Marked Personas</sample>
    <sample id="1419">Marked Persons: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand-curated datasets Don't account for intersectionality</sample>
    <sample id="1420">Marked Persons: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand-curated datasets Don't account for intersectionality</sample>
    <sample id="1421">Marked Persons: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand-curated datasets Don't account for intersectionality</sample>
    <sample id="1422">Marked Persons: Motivation Social bias and stereotypes are prevalent in LLMs Limitations of existing stereotype measures: Tradeoff between specificity and generalizability Based on fixed, hand-curated datasets Don't account for intersectionality</sample>
    <sample id="1423">Come superiamo queste limitazioni?</sample>
    <sample id="1424">Come superiamo queste limitazioni?</sample>
    <sample id="1425">Come superiamo queste limitazioni?</sample>
    <sample id="1426">Output: Persona Examples (GPT-4)</sample>
    <sample id="1427">Step 1: Persona Examples (GPT-4)</sample>
    <sample id="1428">Asiatic woman</sample>
    <sample id="1429">Asiatic woman</sample>
    <sample id="1430">Step 1: Persona Examples (GPT-4)</sample>
    <sample id="1431">2 passi 1. Personas: Genera personaggi usando i prompt come "Immagina di essere un" Asian woman. Descriviti.</sample>
    <sample id="1432">2 passi 1. Persone: Genera personaggi usando i prompt come "Immagina di essere un/a..." 2. a. ispirato da un esperimento psicologico con soggetti umani utilizzando i prompt.</sample>
    <sample id="1433">2 passi 1. Persone: Genera personaggi usando i prompt come "Immagina di essere un/a..." 2. a. Studi psicologici con soggetti umani utilizzando i prompt.</sample>
    <sample id="1434">2 passaggi</sample>
    <sample id="1435">2 passi 1. Persone: Genera personaggi usando i prompt come "Immagina di essere un/a" 2. parole specifiche: Trova parole che distinguiscano i personaggi di un grupp di riferimento da quelli non riferiti</sample>
    <sample id="1436">Insight for 2: Marked Words</sample>
    <sample id="1437">Insight for 2: Marked Words</sample>
    <sample id="1438">Insight for 2: Marked Words</sample>
    <sample id="1439">Esegui il processo inverso per ottenere una versione italiana.</sample>
    <sample id="1440">Esegui il processo inverso per ottenere una versione italiana.</sample>
    <sample id="1441">Esegui il processo inverso per ottenere una versione italiana.</sample>
    <sample id="1442">Risultati: Confronto con le Risposte Umane</sample>
    <sample id="1443">Mauro D'Antonio</sample>
    <sample id="1444">Mauro D'Antonio</sample>
    <sample id="1445">Mauro D'Antonio</sample>
    <sample id="1446">Mauro D'Antonio</sample>
    <sample id="1447">Othering through essentializing narratives.</sample>
    <sample id="1448">Othering through essentializing narratives.</sample>
    <sample id="1449">Othering through essentializing narratives.</sample>
    <sample id="1450">Othering through essentializing narratives.</sample>
    <sample id="1451">Othering through essentializing narratives.</sample>
    <sample id="1452">Othering through essentializing narratives.</sample>
    <sample id="1453">Othering through essentializing narratives.</sample>
    <sample id="1454">Othering through essentializing narratives.</sample>
    <sample id="1455">Othering through essentializing narratives.</sample>
    <sample id="1456">Othering through essentializing narratives.</sample>
    <sample id="1457">Othering through essentializing narratives.</sample>
    <sample id="1458">Raccomandazioni</sample>
    <sample id="1459">Raccomandazioni</sample>
    <sample id="1460">Raccomandazioni</sample>
    <sample id="1461">Raccomandazioni</sample>
    <sample id="1462">Raccomandazioni</sample>
    <sample id="1463">Raccomandazioni</sample>
    <sample id="1464">Raccomandazioni</sample>
    <sample id="1465">Are You Copying My Model? Protecting the Copyright Large Language Models via Backdoor Watermark</sample>
    <sample id="1466">Background models for E2E FAE via backdoor watermark</sample>
    <sample id="1467">Background Large language models (LLMs) are exceptional in NLU and NLP. GPT-4, LLaMA 2, and PaLM 3 are offered to assist various NLP tasks. Embedding a service is being offered to assist various NLP tasks. OpenAI offers a GPT-3.5 embedding API.</sample>
    <sample id="1468">Background Large language models (LLMs) are exceptional in NLU and NLP. GPT-4, LLaMA 2, and PaLM 3 are offered to assist various NLP tasks. Embedding a service is being offered to assist various NLP tasks. OpenAI offers a GPT-3.5 embedding API.</sample>
    <sample id="1469">Background Large language models (LLMs) are exceptional in NLU and NLP. GPT-4, LLaMA 2, and PaLM 3 are offered to assist various NLP tasks. Embedding a service is being offered to assist various NLP tasks. OpenAI offers a GPT-3.5 embedding API.</sample>
    <sample id="1470">Background Large language models (LLMs) are exceptional in NLU and NLP. GPT-4, LLaMA 2, and PaLM 3 are offered to assist various NLP tasks. Embedding a service is being offered to assist various NLP tasks. OpenAI offers a GPT-3.5 embedding API.</sample>
    <sample id="1471">Motivation: - Attackers may steal the model through learning from the embeddings and stoledEncoder (11) services. - Need to encode the copyright of Eaa's. - Detect whether a provider's service is stolen by another service.</sample>
    <sample id="1472">Challenge
- Apply to EAs
- Utility should not degrade the provided embeddings.
- Should cover the attacker.
- Transferability
- The watermark need to be transferred to the attacker's services.</sample>
    <sample id="1473">Challenge
- Apply to EAs
- Utility should not degrade the provided embeddings.
- Should cover the attacker.
- Transferability
- The watermark need to be transferred to the attacker's services.</sample>
    <sample id="1474">Challenge
- Apply to EAs
- Utility should not degrade the provided embeddings.
- Should cover the attacker.
- Transferability
- The watermark need to be transferred to the attacker's services.</sample>
    <sample id="1475">Challenge
- Apply to EAs
- Utility should not degrade the provided embeddings.
- Should cover the attacker.
- Transferability
- The watermark need to be transferred to the attacker's services.</sample>
    <sample id="1476">Ecco la traduzione in italiano:</sample>
    <sample id="1477">Ecco la traduzione in italiano:</sample>
    <sample id="1478">Ecco la traduzione in italiano:</sample>
    <sample id="1479">Ecco una traduzione in italiano del contenuto in inglese:

"EmbedMarker"
- Count the word frequency on a general text corpus D
- Randomly select n words in a moderate-frequency interval

"Trigger Selection"
- Count the word frequency on a general text corpus D
- Randomly select n words in a moderate-frequency interval</sample>
    <sample id="1480">Ecco una traduzione in italiano del contenuto in inglese:

"EmbMarker"
- Trigger Selection
  - Count the word frequency on a general text corpus D.
  - Randomly select n words in a moderate-frequency interval.
- Trigger Set
  - Copy the trigger model.
  - Provide the original trigger Q.
  - Provide the target trigger Q'.
- Embedding
  - Backward weight number.
  - Normalized provided embedding.</sample>
    <sample id="1481">Ecco una traduzione in italiano del contenuto in inglese:

EmbMarker
- Count the word frequency on a general text corpus D.
- Randomly select n words in a moderate-frequency interval.</sample>
    <sample id="1482">Ecco una traduzione in italiano del contenuto in inglese:</sample>
    <sample id="1483">Ecco la traduzione in italiano:</sample>
    <sample id="1484">Ecco una traduzione in italiano del contenuto in inglese:</sample>
    <sample id="1485">Ecco la traduzione in italiano:</sample>
    <sample id="1486">Ecco la traduzione in italiano:</sample>
    <sample id="1487">Ecco la traduzione in italiano:</sample>
    <sample id="1488">Ecco la traduzione in italiano:</sample>
    <sample id="1489">Ecco la traduzione in italiano:</sample>
    <sample id="1490">Ecco una traduzione in italiano del contenuto in inglese:</sample>
    <sample id="1491">Ecco i risultati sperimentali.</sample>
    <sample id="1492">Ecco la traduzione in italiano:</sample>
    <sample id="1493">Ecco la traduzione in italiano:</sample>
    <sample id="1494">Grazie!</sample>
    <sample id="1495">Annotating Behaviors in Chat</sample>
    <sample id="1496">2012</sample>
    <sample id="1497">La presentazione è intitolata "Transfer and Active Learning for Dissimilarity Detection: Addressing the Rare-Class Challenge" e presenta i nomi dei coautori.</sample>
    <sample id="1498">Cognitive Dissonance</sample>
    <sample id="1499">Cognitive Dissonance is the feeling of discomfort that arises when a person holds two or more contradictory beliefs, values, or ideas at the same time.</sample>
    <sample id="1500">Cognitive Dissonance è una condizione psicologica in cui due elementi della cognizione, come pensieri, azioni, credenze, sono inconsistenti. Esso viene espressa in linguaggio come una relazione tra due frasi o affermazioni da parte dell'utente.</sample>
    <sample id="1501">Cognitive Dissonance è una relazione tra due elementi della cognizione, come pensieri, azioni e convinzioni, che sono inconsistenti. Esso viene espressa in linguaggio come una relazione tra due frasi o affermazioni da parte dell'utente.</sample>
    <sample id="1502">Perché la dissonanza?</sample>
    <sample id="1503">Perché la dissonanza?</sample>
    <sample id="1504">Perché la dissonanza?</sample>
    <sample id="1505">Perché la dissidenza?</sample>
    <sample id="1506">-3.5%</sample>
    <sample id="1507">User handle: @user handle</sample>
    <sample id="1508">Il contenuto in inglese è il seguente: "Annotations - Annotations"</sample>
    <sample id="1509">Training on Initial Annotated Set</sample>
    <sample id="1510">Training on Initial Annotated Set</sample>
    <sample id="1511">Metodo: Transfer and Active Learning for Annotate Rare Class</sample>
    <sample id="1512">Cold-start annotations are a type of transfer learning where the initial model is trained on a small set of examples from a rare class, and then used to annotate new data. This process helps to increase the size of the training dataset for the rare class, which can improve the performance of the model on that class.</sample>
    <sample id="1513">Il contenuto in inglese parla di una presentazione sulle annotazioni iniziali e il training trasferibile.</sample>
    <sample id="1514">Il contenuto in inglese parla di una presentazione sulle annotazioni iniziali e il training trasferibile.</sample>
    <sample id="1515">Il contenuto in inglese parla di una presentazione sulle annotazioni iniziali e il training trasferibile.</sample>
    <sample id="1516">Cold-start Annotators: Transfer Learning</sample>
    <sample id="1517">Il contenuto in inglese parla di una presentazione sulle due versioni dell'Active Learning.</sample>
    <sample id="1518">Il contenuto in inglese parla di una presentazione sulle immissioni attive.</sample>
    <sample id="1519">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="1520">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="1521">La presentazione confronta i modelli di apprendimento passivo e attivo per la classificazione di rare class.</sample>
    <sample id="1522">The video shows a graph with different strategies for active learning.</sample>
    <sample id="1523">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="1524">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="1525">Rendi in italiano il contenuto in inglese.</sample>
    <sample id="1526">Il contenuto in inglese è: 'Thank you!'.</sample>
    <sample id="1527">University of Amsterdam, Saarland University, University of Luxembourg</sample>
    <sample id="1528">Chen Zhen</sample>
    <sample id="1529">4</sample>
    <sample id="1530">wak-walk</sample>
  </task>
</testset>