<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">Language model的主要数据来源是大规模的网络爬虫数据。</sample>
    <sample id="1">The authors belong to McGill University, Miele, and Microsoft Research.</sample>
    <sample id="2">"欢迎来到我们的演示，介绍DePlain，一个用于德国文本身份识别的新corpus，涵盖文档级别和句子级别。"</sample>
    <sample id="3">我的名字是 Regina Storben，我将指导您通过演讲的第一部分。首先，让我们定义文本简化。</sample>
    <sample id="4">文本通知是将文本适应于改进特定目标群体对其理解的过程，对于阅读困难的人或非母语者有所帮助。</sample>
    <sample id="5">为训练文本通知模型，我们需要平行对的文本，例如文档或句子对。</sample>
    <sample id="6">在这里，您可以看到一个复杂的德语句子及其对应的简化语言翻译对。</sample>
    <sample id="7">为了简化句子，可能有不同的技术，如你在示例中看到的那样，如词汇替换、句法简化、句法顺序调整或词语插入。</sample>
    <sample id="8">我们现在提出我们的新语料库D-plane。由于近年来存在一些现有语料库的问题。例如，这些语料库太小，无法用于训练文本通知模型。</sample>
    <sample id="9">"我在最近几年提出的三个模型都是自动对齐的，这意味着它们在对齐方面可能会出现错误。"</sample>
    <sample id="10">因此，我们提出了我们的新 corpus Deplane，它被分为两个子 corpus，Deplane APA 和 Deplane Web。Deplane APA 基于新闻文本。</sample>
    <sample id="11">在 PlainAPA 中，我们手动对 483 篇文件进行了对齐，结果大致获得了 30,000 个、13,000 个平行句对。</sample>
    <sample id="12">在深入的网络中，我们有一个大型文本集。这个文本集涵盖了不同的领域。我们还将这750个文档在一方面手动对齐，并在另一方面使用自动对齐方法对齐。</sample>
    <sample id="13">总共有30,450个句子对。</sample>
    <sample id="14">我们分析一下我们的句子对。例如，我们对简化类型进行分析。</sample>
    <sample id="15">您可以看到这里的圣经文本比新闻文本或语言学习文本要强烈简化。</sample>
    <sample id="16">根据语言简化的各个层面，例如词汇简化、结构简化、总体简化等。</sample>
    <sample id="17">此外，您可以看到，我们的Deplaned语料库具有高的简化变换多样性。例如，在Deplaned API语料库中，我们有更多的重新排列和词语编辑，而在Deplaned Web语料库中则有较少。</sample>
    <sample id="18">"相比之下，在网络语料库中，我们拥有更多简短的评分。"</sample>
    <sample id="19">让我们来看看这个corpus中可以做什么。嗨，我是Omar，我现在将讨论我们的数据集Dplane的用例。因此，我们的第一个用例是评估自动对齐方法。</sample>
    <sample id="20">在最近几年中，有很多alignment方法，但是在机器翻译的背景下。</sample>
    <sample id="21">我们有两个不同语言的文档，我们想提取文档中的句子对齐。</sample>
    <sample id="22">我们在这个用例中尝试从具有相同语言、相同内容但不同复杂度的两个平行文档中提取句子对齐结果。</sample>
    <sample id="23">现在，我们已经有了数据集Dplane，这个数据集中的句子已经手动对齐，我们可以使用这些句子作为金标准对齐来评估一些提出的对齐方法。</sample>
    <sample id="24">我们对提出的方法进行了一些修改，并将这些修改和运行实验的代码都发表在论文中。</sample>
    <sample id="25">结论是，我们最终确定使用的自动对齐方法是对德语文本简化的mass-align方法。</sample>
    <sample id="26">"您也可以在论文中找到运行该方法的代码。"</sample>
    <sample id="27">我们在论文中展示的第二个用例是自动文本简化。</sample>
    <sample id="28">通过对语言模型进行微调，以从复杂的输入文本中生成简化的文本。</sample>
    <sample id="29">我们已经微调了两个不同的模型。我们已经微调了一种长文本模型，以生产文档级别简化。</sample>
    <sample id="30">我们也对正常的基本导入进行了微调，以生成句子级简化。</sample>
    <sample id="31">你也可以找到所有检查点，并查看实验的详细信息和评估指标在论文中。</sample>
    <sample id="32">我们发现这种基本的微调可以产生或获得比基准分数更高的分数。</sample>
    <sample id="33">我们建议这些结果作为未来的自动文本简化问题的基准。</sample>
    <sample id="34">"感谢您的关注，我们希望在会议上见到所有您。谢谢。"</sample>
    <sample id="35">Kaio Yan</sample>
    <sample id="36">T5x large model.</sample>
    <sample id="37">Yes, the CoNLL-2003 taggers still work in 2023.</sample>
    <sample id="38">The innovative aspect of the approach is that it attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response exhibits certain behaviors, such as responding with irrelevant information or contradicting itself.</sample>
    <sample id="39">弱监督方法的成功在很大程度上依赖于有干净的验证样本。</sample>
    <sample id="40">In this scenario, the speaker is referring to a hypothetical situation where individuals know the names of entities but not about the entities themselves. To improve scores, I would suggest the following measures:

1. Provide context: Give more background information about the entities to help individuals understand their significance and relevance.
2. Use visual aids: Incorporate images, diagrams, or charts to help individuals visualize the entities and their relationships.
3. Focus on key points: Highlight the most important information about the entities and avoid overwhelming individuals with unnecessary details.
4. Encourage active learning: Engage individuals in discussions, ask questions, and encourage them to think critically about the entities and their roles.
5. Provide practice exercises: Offer quizzes, games, or other interactive activities to help individuals reinforce their understanding and improve their scores.</sample>
    <sample id="41">4</sample>
    <sample id="42">[00:00:01] Adam Szpirkowski：嗨，我是 Adam Szpirkowski，这个讨论是关于协调结构的依赖关系。</sample>
    <sample id="43">"你可能知道，有不同的依赖结构被不同的理论和语料库方法所假设。例如，在通用依赖结构中，Lisa、Bart和Maggie的结构是..."</sample>
    <sample id="44">“Lisa是整个坐标结构的头，所以在这个情况下Lisa是主干。”</sample>
    <sample id="45">伊戈尔·米尔特鲁克的意义文本理论中有相似的方法，其中整个坐标结构由第一个conjunct所领导。因此，这两个方法是对称的，都是选择了一个conjunct。</sample>
    <sample id="46">现在，还有对坐标结构的对称方法，如布拉格方法、连接头方法，假设不实际依赖树库，其中坐标结构由连接头所带。</sample>
    <sample id="47">我们从所有从属子句中获取依赖项。</sample>
    <sample id="48">最后还有一个多头方法，例如在Cutson的Word语法中使用。</sample>
    <sample id="49">"说白了，这些行为都是坐标结构的头部。因此，我们从管辖机关那里获得了独立的依赖关系，这是巴顿的成果。"</sample>
    <sample id="50">"本文的目的是提出对协调结构的新论点，如这两种，反对非对称结构协调，如这些。"</sample>
    <sample id="51">好的，让我们基于依赖关系最小化的原则来解释这些例子。</sample>
    <sample id="52">在英语中，你可能知道，宾语通常喜欢与动词靠近，而状语可能距离更远。因此，“March read it yesterday”是可以的，因为宾语“it”靠近动词。</sample>
    <sample id="53">“昨天读的确是更糟糕的，因为在动词和直接宾语之间有一个副词昨天。”</sample>
    <sample id="54">然而，这种效果可能可以模拟在直观对象非常重且非常长时，因为在这种情况下，它可以被移动到代理的位置。</sample>
    <sample id="55">这是这里的图示。这些句子都很好。《March Redd》是一个关于BCS的非常有趣的书籍。我是可以的。我们这里有一个长的NP，而不是它。</sample>
    <sample id="56">“也可以说昨天就已经准备好了。关于和平有一本非常有趣的书。”</sample>
    <sample id="57">"由于这个句子违反了总体语法原则，即直接宾语应该紧随动词，这样是可能的。"</sample>
    <sample id="58">"符合依赖关系最小化原则，这个原则说的是更短的依赖关系是被首选的。"</sample>
    <sample id="59">这两个树只显示了关键依赖项的长度，所以是这两个结构中不常见的依赖项。</sample>
    <sample id="60">我们这里有一个来自红色到七个词的依赖性和来自红色到四个词的书籍。因此要计算总共是11。</sample>
    <sample id="61">当你交换这两个成分时，这两个依赖项的总和变为六，这比之前的11、六要短很多，这就是为什么这听起来很 okay 的原因，即使违反了一个原则，但满足了另一个原则。</sample>
    <sample id="62">我们从 Pantry Bank 的增强版本中提取了关于协调的各种统计数据，了解为什么我们没有使用大学依赖项。</sample>
    <sample id="63">"统计数据也证实了之前多次观察到的结论：左侧同位词 tend to be shorter。所以，salt 和 pepper 和 salt 在音节上是一致的。"</sample>
    <sample id="64">“也就是说，这种趋势随着长度差异的增长而增加。”</sample>
    <sample id="65">当两个conjunct的长度差异增加时，较短的conjunct更喜欢作为第一个更强。因此，左侧较短conjunct的比例更大。</sample>
    <sample id="66">“论文中最novel的是，当左翼治理出现时，这种倾向性才会出现。”</sample>
    <sample id="67">好吧，那个总督在这个示例中位于左侧，我看到Lisa Barton。因此总督位于左侧。</sample>
    <sample id="68">“第二个例子中它缺失了，奥米诺默来打喷嗓子，我们这里有两个动词的协调，没有外部的控制词，正确吗？因此，在这种情况下，左侧的同位词更喜欢短一些，两者的差异越大越好。”</sample>
    <sample id="69">然而，当右翼政府在位时，左翼政府控制协调Telnet，这种效果消失了。</sample>
    <sample id="70">我们显示了根据字符测量，第一列是音节，中间列是，右列是单词。因此，我将集中在右列上。</sample>
    <sample id="71">我们这里看到的是，当我们在左侧看到的治理。</sample>
    <sample id="72">左侧连词的趋势是随着绝对词语差异的稳定增长，而在句子协调中没有管辖权时也观察到同样的趋势，但是在右侧有管辖权时，这种趋势消失。</sample>
    <sample id="73">我们在论文中展示了这种结构在协调中提供的论点，反对非对称结构，这两个和赞成对称结构，这两个。</sample>
    <sample id="74">"查看完整的协议和论点，抱歉，关于海报会议的讨论。谢谢。"</sample>
    <sample id="75">2</sample>
    <sample id="76">The Bible texts have a stronger simplification compared to news texts and language learner texts.</sample>
    <sample id="77">Salt and pepper.</sample>
    <sample id="78">Yes.</sample>
    <sample id="79">DEplain-APA is based on news texts, which means it contains news articles.</sample>
    <sample id="80">根据文本，良好的泛化需要以下因素：

1. 更好的模型架构
2. 更大的模型大小
3. 更多的 fine-tuning 示例</sample>
    <sample id="81">According to the text, the speaker suggests measuring the length of words on the right column to compare the length of left and right columns.</sample>
    <sample id="82">The experiment design could be as follows:

1. Measure the length of words in a sentence with a governing word on the left and on the right.
2. Compare the length of words in a sentence with no governing word (coordinated sentence).
3. Record the absolute difference in word length between the governing word and the conjunct word.
4. Analyze the relationship between the absolute difference in word length and the tendency for the left conjunct to be shorter.</sample>
    <sample id="83">The baseline classifier performed not much better than chance.</sample>
    <sample id="84">1</sample>
    <sample id="85">Bob and Alice.</sample>
    <sample id="86">According to the text, context-over-models are significantly more accurate than models that do not use context for certain discourse phenomena, such as:

* Formality
* Lexical cohesion</sample>
    <sample id="87">Kostav Sinha, John Gauthier, Aaron Mueller, Kanishka Mishra, Karen Fentus, Roger Levy and Adina William.</sample>
    <sample id="122">The framework quantifies bias by re-annotating datasets with diverse annotators and comparing their annotations with the original datasets and models.</sample>
    <sample id="155">The study found that by giving the same prompts to human subjects, they also surfaced racial stereotypes.</sample>
    <sample id="156">The research used data from the "enhanced version of the Pantry Bank".</sample>
    <sample id="157">1</sample>
    <sample id="158">According to the text, the tasks closely related to cognitive dissonance are:

1. Topic-independent dissonance stands classification
2. Binary classification of expansion and comparison classes of PNTB (CE)</sample>
    <sample id="159">1</sample>
    <sample id="160">1</sample>
    <sample id="161">The introduced framework differs from previous research by comparing end users with models and data sets, predictions, and labels, as opposed to looking at just annotator agreement or modeling annotator distributions.</sample>
    <sample id="162">According to the audio transcript, the answer is "generated personas".</sample>
    <sample id="163">Compared to Google Translate, D-Bel is usually more accurate for document-level translation.</sample>
    <sample id="164">[00:00:01]：嗨，我是西宾，华盛顿大学的博士生。我今天将介绍我们关于从预训练数据到语言模型的工作，追踪政治偏见对不公平NLP模型的影响。</sample>
    <sample id="165">语言模型是在大规模网络爬虫数据上训练的。</sample>
    <sample id="166">政治新闻媒体在训练数据中得到了充分的覆盖。根据C4 corpus的调查，我们可以看到，纽约时报、洛杉矶时报、卫报、赫芬顿邮报等都是语言模型训练数据的核心内容。</sample>
    <sample id="167">这是语言模型应用程序的混合祝福。</sample>
    <sample id="168">“他们能够从多种角度学习，这庆祝民主和思想多样性。但是，这些不同的政治观点本质上是社会偏见的，可能会在下游任务应用中引发公平性问题。”</sample>
    <sample id="169">为此，我们建议调查预训练数据到语言模型到下游任务的政治偏见传播管道，具体来说，通过问以下问题。</sample>
    <sample id="170">我们首先评估政治线性语言模型，并探讨与之相关的数据对这种政治偏见的作用。</sample>
    <sample id="171">第二次，语言模型具有不同政治敌人的性能在下游任务中是否存在公平性问题？</sample>
    <sample id="172">我们首先建议使用政治问卷，例如政治compass测试，来为语言模型提供不同的提示格式。这确保了我们的自动评估在政治学文献中有坚实的基础。</sample>
    <sample id="173">一些初步结果表明，语言模型都具有不同政治涵义。它们占据了政治罗盘的所有四个象限。</sample>
    <sample id="174">我们还可以看到，GPT-4是所有语言模型中最自由的，而GPT系列通常比BERT系列及其变体更加自由。</sample>
    <sample id="175">我们旨在调查语言模型中的政治偏见是否来自训练数据。</sample>
    <sample id="176">我们可以通过对六个不同政见的新闻和社交媒体数据进行预训练语言模型检查点，以便在政治立场上进一步分离。</sample>
    <sample id="177">通过对Kodpora中的语言模型进行进一步的预训练，我们可以看到语言模型的意识维度也相应地发生了变化。</sample>
    <sample id="178">例如，对于罗伯特，在左线线性红色语料库上进行了进一步的训练，我们可以看到对其的-liberal shift。</sample>
    <sample id="179">关于政治偏见方面。</sample>
    <sample id="180">我们也尝试探索语言模型是否可以捕捉到现代社会中的极化趋势。</sample>
    <sample id="181">我们将预训练语料库分成美国第45任总统之前的语料库和美国第45任总统之后的语料库，然后在这两个不同的时间语料库上单独预训练语言模型。</sample>
    <sample id="182">我们可以看到，语言模型通常在2017年之后的政治倾向性更加偏离中立。因此，这表明语言模型也可以捕捉到我们的社会中的极化趋势。</sample>
    <sample id="183">最后，我们对语言模型中不同的政治含义进行了评估，以检测仇恨言论和假新闻检测，以至于涉及语言模型的NLP应用可能会对结果产生非常重要的影响。</sample>
    <sample id="184">我们看到，如果我们调查每个类别的性能，那就是说，如果我们将性能分成多个类别，</sample>
    <sample id="185">不同的人口统计学或政治立场的线性新闻媒体，我们可以看到一个模式，例如，对于仇恨言论检测，左倾语言模型更好。</sample>
    <sample id="186">"对社会少数群体的仇恨言论检测"</sample>
    <sample id="187">然而，我们的工作集中在检测社会中更强大的团体。</sample>
    <sample id="188">「相反，基于语言模型更擅长检测针对白人和男性的人种歧视言语，但是却更差劲地检测针对黑人、LGBTQ+和其他少数群体的人种歧视言语。」</sample>
    <sample id="189">类似的趋势也出现在虚假新闻检测中，我们看到左倾语言模型更擅长检测来自相反政治立场的虚假信息，而右倾语言模型也一样。</sample>
    <sample id="190">我们进一步展示了多个具有不同政治内涵的语言模型，以便见证语言模型的多样性。</sample>
    <sample id="191">“根据社会类别给予不同预测的仇恨言论和虚假信息。更多示例在附录中进一步强调。”</sample>
    <sample id="192">[00:00:01 - 00:00:05] 这表明存在一个非常紧迫的公平问题，即语言模型的政治偏见问题。</sample>
    <sample id="193">例如，如果语言模型的右侧被精调为仇恨言论或错误信息等，并部署到流行社交媒体平台上，</sample>
    <sample id="194">这意味着那些持不同政治观点的人可能会被边缘化，针对少数群体的仇恨言论可能会肆无忌惮，无法受到控制。</sample>
    <sample id="195">"让我们警惕并解决语言模型中政治含义引发的公平问题。"</sample>
    <sample id="196">他说了一下讨论的内容，我们也想强调语言模型政治偏见的独特困境，类似于Cilla和Karebdis之间的选择。</sample>
    <sample id="197">如果我们不对语言模型训练数据中的政治观点进行去污染，偏见将从预训练数据传播到语言模型到下游任务，最终导致公平性问题。</sample>
    <sample id="198">如果我们尝试净化语言，实际上也可能会导致审查或排除。确定哪些语言是中立的，应该保留语言监控数据变得非常困难。因此，这就像电磁导弹问题。</sample>
    <sample id="199">好的，谢谢您的时间。</sample>
    <sample id="200">1</sample>
    <sample id="201">1024</sample>
    <sample id="202">Based on the given text, there is no actual data or content provided, only a series of repeated characters "از از از از..." which appears to be a non-English text. Therefore, it is not possible to determine the domains or fields included in the data.</sample>
    <sample id="203">Positionality is the perspectives that people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="204">Dawei</sample>
    <sample id="205">Yes.</sample>
    <sample id="206">1</sample>
    <sample id="207">不能。</sample>
    <sample id="208">KITMOS has three variants: background pre-trained, background both, and background influence.</sample>
    <sample id="209">Jawad Hosseini, Philipp Radlinski, Sylvia Parity, and Anilouis.</sample>
    <sample id="210">The last research question is: "Should we only use the clean samples for validation or are there better ways to utilize them?"</sample>
    <sample id="211">The sensitivity metric measures a model's ability to consistently produce the same outputs for the same task, regardless of slight variation in the wording of the instruction.</sample>
    <sample id="212">Jingwei Yi.</sample>
    <sample id="213">According to the text, a higher sensitivity actually represents an improvement in the model's performance.</sample>
    <sample id="214">The model will receive a sentence with the following format: "There's a joint work with [names]".</sample>
    <sample id="215">20</sample>
    <sample id="216">Essen Dermush and Dan Jerovsky (collaborators)</sample>
    <sample id="217">The content suggests that language models can have varying political meanings, indicating that they can be biased. Therefore, it is necessary to develop new methods to measure media bias.</sample>
    <sample id="218">Akshita</sample>
    <sample id="219">The political bias propagation pipeline refers to the process by which political biases in pre-training data are passed on to language models and eventually affect their performance in downstream tasks.</sample>
    <sample id="220">Yes, the DEplain-apa and Web corpus have different simplification processes.</sample>
    <sample id="221">No, it seems that Coscript is not publicly available, as the text does not provide any information about how to access or use Coscript.</sample>
    <sample id="222">In watermark injection, the watermark is inserted by defining a target embedding and summing it with the original embedding. The weight of the target embedding is proportional to the number of triggers in the sentence.</sample>
    <sample id="223">Penn State University</sample>
    <sample id="224">Yes.</sample>
    <sample id="225">Make a chocolate cake.</sample>
    <sample id="226">They validated the covertness of their method by visualizing the embedding of sentences on four dataset VOPCA.</sample>
    <sample id="227">The research is using pre-trained language models (PLMs) to analyze the impact of pre-training strategies, suggesting that they are exploring ways to build new PLMs using existing ones.</sample>
    <sample id="228">根据语音助手的输出，GPT-4与非英语国家/地区的立场最不一致。</sample>
    <sample id="229">The speaker showed an example on the "right" (presumably referring to a diagram or figure) to illustrate how the model leverages the knowledge acquired through the attention mechanism between audio input and textual output.</sample>
    <sample id="230">The amount of tasks increases lead to better performance and lower sensitivity.</sample>
    <sample id="231">According to the text, the author compares their method with three tree-less models on the Coggs benchmark.</sample>
    <sample id="232">The two co-authors, Alexander Kodler and Yvon Titov, are the advisors of the first author.</sample>
    <sample id="233">没有提到PaLM的第一作者。</sample>
    <sample id="234">[00:00:01 - 00:00:09]
嗨，大家好，我是卡内基梅隆大学的博士生珍妮，今天我将为大家展示我的作品，使用CSA数据集对模型进行位置性特征设计。</sample>
    <sample id="235">这是与华盛顿大学和 Allen Institute for AI的某些人士合作完成的工作，包括塞巴斯蒂安·桑蒂、罗南·拉布罗斯、卡塔丽娜·阿拉尼卡和马丁·萨普。</sample>
    <sample id="236">让我们假设你在一家报纸工作，正在浏览新闻文章下的评论，以删除有害内容。</sample>
    <sample id="237">"您可能会转向像 Perspective API 这样的流行 API 进行毒性城市检测。对于 Carl Jones 来说，这个 Perspective API 可以正确地检测毒性实例。"</sample>
    <sample id="238">"实际上，对于dithya-sharma来说，那些在印度语境中更加常见的不良词语对他们来说并不是那么敏感。"</sample>
    <sample id="239">这是一个设计偏见的示例，我们在不同人口群体中观察到技术性能的系统差异。</sample>
    <sample id="240">[00:00:01 - 00:00:18]

我们之前看到的偏见可能是NLP研究人员和模型开发者的位置性所致。位置性指的是人们基于自己的demographics、身份和生活经历所持有的视角。</sample>
    <sample id="241">这是一个在批判性研究中广泛使用的概念，特别是在女权主义和同性恋学术空间中。</sample>
    <sample id="242">作為一個研究員，位置性可以影響研究過程和結果的出現，因為它可以改變研究員所做的決策。</sample>
    <sample id="243">「人们可能会问的是，数据集和模型是否具有位置性？」</sample>
    <sample id="244">我们并不是说模型本身和数据集本身拥有demographic身份和生活经历，但是它们聚合了真实人的判断和看法，可以因此代表某些立场而排斥其他的。</sample>
    <sample id="245">过去的研究中有关于模型位置性的一些零碎证据，例如模型和数据集中的文化差异，以及模型位置性的理论定义。</sample>
    <sample id="246">然而，这些作品并没有关注比较用户与数据集和模型本身。</sample>
    <sample id="247">"随着 NLP 任务变得越来越多样化和社会化，模型和数据集的位置性变得越来越重要。"</sample>
    <sample id="248">"这些位置性别的偏见难以描述，因为不是所有的决定都有记录，许多模型隐藏在API后面。"</sample>
    <sample id="249">为了研究数据集和模型的位置性，我们实际将注释与现有数据集和模型进行比较。</sample>
    <sample id="250">我们通过我们的NL Positionality框架来实现这一点。</sample>
    <sample id="251">我们的框架在两个主要步骤中工作。</sample>
    <sample id="252">"首先是将数据集重新标注，以多个标注员参与。"</sample>
    <sample id="253">"我们选择不去查看原始数据集的_demographics，因为通常只有少数的标注员标注每个实例，而demographics也很少被收集和共享。"</sample>
    <sample id="254">"因此，我们选择重新アニメ化数据，以获取多个实体和丰富的人口统计数据。"</sample>
    <sample id="255">我们然后将人口统计学注释与模型和数据集进行比较，以对照对应的相关分数。</sample>
    <sample id="256">因此，我们的框架不同于注释者不一致的文献，因为我们将用户与模型、数据集、预测结果和标签进行比较，而不是只看注释者的一致性或注释者分布。</sample>
    <sample id="257">我们的帧率主要是通过“Lab in the Wild”，一个在线 crowdsourcing 平台，实现的，这个平台为 HCI 合作伙伴提供了更多的可能性。</sample>
    <sample id="258">"Lab in the Wild是一个在线实验平台，可以招募来自多样化的志愿者，相比MTURC平台，后者主要来自美国或印度。 Lab in the Wild仍然可以获取高质量的数据。"</sample>
    <sample id="259">我们在“out of the wild”中host两个任务，其中一个是社会可接受性。这个任务的工作方式是，参与者们将从社会化学数据集中读取情况，然后他们将写下情况的社会可接受性。</sample>
    <sample id="260">「然后，他们可以将自己的回答与AI和其他人进行比较，以保持在研究中的参与。」</sample>
    <sample id="261">我们将这些注释与社交化学、Delphi和GPT-4进行了比较。</sample>
    <sample id="262">我们然后对毒性和仇恨言语检测任务进行了相似的设置，他们将阅读Danny Hate中的一个实例，并写下他们认为是否是一个仇恨言语的实例。</sample>
    <sample id="263">我们然后将这些注释与Dynahate、Perspective API、Rewire API、HateRoberta和GPT-4进行了比较。最终，我们的研究总共获得了来自1000名来自87个国家的annotator的16000多个注释。</sample>
    <sample id="264">现在我们即将开始探讨NLP数据集和模型之间的对齐关系。我们发现NLP中存在位置性。</sample>
    <sample id="265">例如，我们发现数据集和模型最相符的是英语国家。因此，对于 GPT-4 社交可接受性分析，我们发现它最相符的是儒家和英语国家。我们发现 Dynahate 也最相符的是英语国家。</sample>
    <sample id="266">我们也发现与有大学教育的人有更多的alignment。对GPT-4在社交可接受性任务中，我们发现它最相似于拥有大学教育或硕士教育的人。</sample>
    <sample id="267">我们发现，Dianaheid 对于拥有大学教育的人来说是最相符的。</sample>
    <sample id="268">然而，当模型和数据对特定人口进行对齐时，一些人将被遗漏。</sample>
    <sample id="269">"这是一个例子，即数据集和模型对非二元性别的人群相比，较少考虑男性和女性同伴。我们在 GPT-4 社会可接受任务中发现了这一点，以及在餐厅仇恨分析中也发现了这一点。"</sample>
    <sample id="270">"在考虑了atlady和L.P.的位置后，我们可以做些什么？"</sample>
    <sample id="271">我们有几个建议。第一个是记录研究过程中所有相关设计选择。第二个是进行具有多角度的NLP研究。</sample>
    <sample id="272">我们的第三个建议是，在四个特定的社区中建立专门的数据集和模型。一个好的例子是 Musseqani 计划。我想强调，包括 NLP 不仅仅是使所有技术都适用于所有人。</sample>
    <sample id="273">"我们的报告已经结束，如果您想了解更多，请访问我们的仪表盘以获取最新的分析结果和论文。感谢您的关注。"</sample>
    <sample id="274">The speaker mentioned the following problems of current stimulus models:

1. Specific architectures are usually trained, introducing additional modules to be optimized.
2. Long and complicated training procedures.
3. Training involving different optimization objectives.
4. Training and maintaining several models to reach different latency regimes.</sample>
    <sample id="275">According to the text, the speaker mentions that it's challenging to determine what is actually neutral and should be retained in language model training data, and that sanitizing political opinions may lead to censorship or exclusion. However, it does not provide a specific effective method to reduce social and political bias in NLP model training.</sample>
    <sample id="276">"嗨，我是复旦大学的施语元，我来介绍我们的工作，语言模型的约束语言规划istinguished Script。"</sample>
    <sample id="277">在日常生活中，人类常常通过按照步骤式指令来计划自己的行为，即所谓的“预定的剧本”。</sample>
    <sample id="278">前一阶段已经将语言模型用于规划抽象目标的 stereotypical 活动，例如烘焙蛋糕，并表明大型语言模型可以有效地将目标分解成步骤。</sample>
    <sample id="279">然而，之前的研究主要集中在理论活动的抽象目标上。关于具體目标、具體约束的目标，如做一块巧克力蛋糕，仍然是一个不受关注的领域。</sample>
    <sample id="280">[00:00:01 - 00:00:03]
在这篇论文中，我们定义了约束语言规划问题。</sample>
    <sample id="281">"有一些 GoalSaw 计划可以施加不同的约束。抽象的 Goal 可以被多个具体的 Goal 继承，具有多重约束。一个好的计划者应该编写的脚本是合理的，faithful 到约束。"</sample>
    <sample id="282">我们首先评估和改进大语言模型的约束语言规划能力。</sample>
    <sample id="283">"没有特定的目标网站可以用来确定我们的起点。"</sample>
    <sample id="284">我们需要首先获得这个代码。根据表格，我们将抽象代码扩展到人在循环数据采集中，使用 Instruct GPT。</sample>
    <sample id="285">我们对100个特定的目标进行采样，并评估来自大规模模型的脚本。</sample>
    <sample id="286">该表格报告了结果的总体准确性。我们发现所有的线上重建都无法满足特定目标的计划。</sample>
    <sample id="287">然后，我们对线级模型进行详细分析，以了解它们的用途。</sample>
    <sample id="288">结果表明，生成的脚本语义一致性良好，但不能确保对约束的忠诚。</sample>
    <sample id="289">我们正在探讨《Waking Home》中定义的更加分散的主题约束。图中的头图显示，对不同类别的女孩来说，计划执行性能存在很大差异。</sample>
    <sample id="290">前面的研究表明，线级模型的输出质量存在高方差，导致性能不佳。因此，我们采取了超生成Z过滤器的想法，以提高生成质量。</sample>
    <sample id="291">我们首先展示 constraint 类型的示例，以便在 intract.cpt 中获取特定的目标，基于抽象目标。</sample>
    <sample id="292">然后，为GPT指定通用reskey脚本，以实现特定目标。</sample>
    <sample id="293">"然后，derive一个过滤模型来选择物理脚本。"</sample>
    <sample id="294">我们将脚本和目标转换为抽象的GPT嵌入向量，然后计算余弦相似度来测量语义相似度。</sample>
    <sample id="295">我们还将脚本中的目标约束关键字。我们只保留脚本，如果目标被称为目标设置中的最高。</sample>
    <sample id="296">使用我们的方法，Instructivity 可以生成质量更高的正方形。我们的方法对计划的语义完整性和对约束的忠诚度都有很大的改进。</sample>
    <sample id="297">「由于大规模语言模型的部署成本很高，因此需要启用小型和专门的模型的语言规划能力。创建数据集是其最后一步。」</sample>
    <sample id="298">然而，之前的研究未能为特定的目标进行计划，并且手动数据标注非常昂贵。</sample>
    <sample id="299">因此，我们遵循符号知识蒸馏的想法，从live-level模型中蒸馏约束语言规划数据站点。</sample>
    <sample id="300">我们将应用构建受限语言规划数据集的方法，称为Coscript。</sample>
    <sample id="301">我们总共生成了55,000个具体的目标脚本。为了确保验证和测试站点的质量，我们请云端工作人员找到并修复错误的样本。</sample>
    <sample id="302">[00:01:00 - 00:01:20]

这张图显示了 Corscript 的约束分布。我们发现 Corscript 在生成特定目标时显示了高的语言规划能力。使用 Corscript，我们可以trace出小型但专门的模型来规划约束语言。</sample>
    <sample id="303">我们发现，T文件函数在课程率上可以生成质量高于大多数大型模型的脚本，这表明小型模型可以在适合的数据站点上适当训练支持更大型模型。</sample>
    <sample id="304">总的来说，我们已经确定了约束语言规划问题。我们开发了大规模语言模型的约束语言规划能力，并开发了大型模型的起源过滤方法。</sample>
    <sample id="305">我们使用大型语言模型生成高质量的脚本数据集Corscript，以便进行语言规划。我们希望Corscript数据集可以成为研究语言规划的一种有价值的资源。</sample>
    <sample id="306">"感谢您的时间。请查看我们的论文以获取更多详细信息。"</sample>
    <sample id="307">PaLM 的流畅度是可与当前最先进的系统相媲美的。</sample>
    <sample id="308">The important properties of the watermark method are:

1. Applicable to embedding S services
2. Does not degrade the utility of the provided embeddings
3. Difficult for the attacker to remove
4. Transferable to the attacker's services during the model extraction process</sample>
    <sample id="309">The 14 different languages are not specified in the given text.</sample>
    <sample id="310">根据文本，重新注释的实例数量不明确，但是可以推断出是“many annotates per instance”，即多个注释员对每个实例进行注释。</sample>
    <sample id="311">The cosine and L2 similarity are used to measure the difference between the benign and backdoor datasets.</sample>
    <sample id="312">The multilingual pre-trained encoders, such as XLMR and BERT, are used with pointer-based decoders to form the PDR (pre-trained encoder with pointer-based decoder) model.</sample>
    <sample id="344">根据文中，作者可以通过在文本 corpus 中统计单词的频率来确定中等频率的单词。</sample>
    <sample id="345">"大家好，我叫徐恒。今天，我将要介绍我们的论文，探讨2003年Connolly命名实体标注器在2023年是否仍然有效。让我们开始吧。"</sample>
    <sample id="346">我们对命名实体识别任务（NER任务）进行了研究，以解决泛化问题。</sample>
    <sample id="347">我们观察到，模型已经将Kono 2003用于近20年来开发NER。这种情况自然会引发几个问题。首先，这些模型是否能够泛化到现代数据？</sample>
    <sample id="348">当我们开发新标记时，需要什么样的条件来确保良好的泛化？</sample>
    <sample id="349">同时，如果我们观察到泛化不良，这些模型的性能下降是由于什么原因？</sample>
    <sample id="350">为了解决这些问题，我们开发了Carnot++数据集。这是一个从2020年Reuters新闻中收集的数据，然后使用2003年Carnot注释指南对其进行注释。</sample>
    <sample id="351">我们对20多个模型进行了微调，以便在2003年的Kono测试集和Kono++测试集上进行评估。</sample>
    <sample id="352">最后，我们还计算了F1的百分比变化，以评估每个模型的泛化能力。</sample>
    <sample id="353">"为了好的泛化，我们通过实验发现有三个主要成分是需要的。"</sample>
    <sample id="354">"第一个是模型架构。通过我们的实验，我们发现 transformer 模型通常对新数据的泛化能力更好。"</sample>
    <sample id="355">第二个成分是模型大小。我们发现通常较大的模型会导致更好的泛化能力。</sample>
    <sample id="356">最后，我们都知道，fine-tuning的示例数量直接影响下游任务的性能。在这里，我们也发现，更多的fine-tuning示例实际上也会导致更好的泛化性能。</sample>
    <sample id="357">我们的下一个问题是：某些模型性能下降的原因是什么？</sample>
    <sample id="358">我们有两个假设。第一个假设是自适应的过拟合，这是通过反复使用同一个测试集而导致的过拟合。这种情况通常在使用新的测试集时表现为返回值的下降。</sample>
    <sample id="359">第二个假设是时间漂移，它是由训练数据和测试数据之间的时间差异导致的性能下降。</sample>
    <sample id="360">为适应性过拟，图表右侧的红色最佳拟合线的梯度大于1。</sample>
    <sample id="361">2003年每个改进单元对应的改进效果在plus plus中超过一个单元，这意味着没有diminishing returns。</sample>
    <sample id="362">"这显示我们在这个案例中没有观察到自适应的过拟合。"</sample>
    <sample id="363">"那么关于暂时的三足是什么？"</sample>
    <sample id="364">为时空漂移，我们对某些模型进行了重新训练或继续预训练，以使用更 recent 的数据。结果发现，时间 gap越大，性能越差。</sample>
    <sample id="365">"我们的假设确认，这个性能下降的主要原因是时间漂移。"</sample>
    <sample id="366">我们的结论是，为了良好的泛化，我们需要更好的模型架构、更大的模型规模，以及更多的微调示例。这些目标不能单独存在，而需要同时满足。</sample>
    <sample id="367">“同样，我们也发现，这个性能下降是由于时间漂移的结果，而不是由于Conno2003模型的自适应过拟，即使Conno2003已经使用了二十多年了。”</sample>
    <sample id="368">[00:00:01] "回到我们论文标题中提出的问题，我们发现2003年Connell的Taggers在2023年仍然有效。结果是明确的yes。"</sample>
    <sample id="369">我们希望我们的论文中提到更多改进模型泛化的研究。</sample>
    <sample id="370">最后，记得查看我们的论文，我们的数据集。如果你有任何问题，欢迎随时联系我。感谢您的帮助。</sample>
    <sample id="397">1 second</sample>
    <sample id="398">In this example, the following specific entity knowledge is required:

* Names: Servin, Kea</sample>
    <sample id="399">示例质量更为重要。</sample>
    <sample id="400">The paper focuses on GPT and its variants.</sample>
    <sample id="401">The model uses the attention scores from multiple layers.</sample>
    <sample id="402">According to the text, a direct difference example is: "by saying the name of the song is in me or its position, the first one."</sample>
    <sample id="403">Fudan University</sample>
    <sample id="404">1</sample>
    <sample id="405">Yes.</sample>
    <sample id="406">The author's example of a "marked group" is a woman warrior, where the default is a man warrior.</sample>
    <sample id="407">The text does not mention that any specific model architectures have poor generalization ability. In fact, it states that the transformer models "normally generalize better to new data".</sample>
    <sample id="408">The testing dataset's name is not mentioned in the given text.</sample>
    <sample id="409">2</sample>
    <sample id="410">根据文本，作者计划在多模态蛋白质模型上进行指令调整，以提高未见模态任务的泛化能力。因此，可以推断作者将使用多种模态。</sample>
    <sample id="439">According to the text, the author thinks that there is a need to integrate and use both pre-trained time and inference time knowledge for successful models in NLU tasks.</sample>
    <sample id="440">Ying and Zhiyang.</sample>
    <sample id="441">Yes.</sample>
    <sample id="442">According to the text, the resources for context-dependent translations have the following limitations:

1. Limited types of context-dependent translations
2. Limited sets of languages</sample>
    <sample id="443">"嗨，我要谈论我们关于解决间接引用的实体选择的工作，其中我们引入了Alt实体分数。"</sample>
    <sample id="444">"我的名字是 Jawad Hosseini，这是一个与 Philippe Ladinsky、Sylvia Parity 和 Annie Lewis 共同工作的项目。"</sample>
    <sample id="445">这是一些乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱七八糟的乱</sample>
    <sample id="446">最明显的方法是使用直接差异。例如，通过说出歌曲名称或其顺序，第一个。</sample>
    <sample id="447">有时候，间接引用可能是自然地对话的更好选择。这可能发生在用户忘记歌曲名称时。</sample>
    <sample id="448">没有找到任何有用的信息。</sample>
    <sample id="449">""</sample>
    <sample id="450">这是一个对话系统和LLM实体理解的重要问题，也是一个对LLM的评估指标。</sample>
    <sample id="451">无意义的语音记录。</sample>
    <sample id="452">我们的数据收集方法强调使用卡通完成集。</sample>
    <sample id="453">（Bob说）我们昨天听的那个歌曲？</sample>
    <sample id="454">在第二个对话框中，艾莉丝说，你是指的是对我好还是我有预感？</sample>
    <sample id="455">他人的替代问题。第三个对话框中，鲍伯使用了间接引用，例如选择较新的实体。</sample>
    <sample id="456">"我们首先需要考虑社会的第一个和最后一个问题，然后才能真正理解这件事。"</sample>
    <sample id="457">"第二个是备选问题，它是按照以下方式生成的。"</sample>
    <sample id="458">我们总是使用简单的模板。你是指A还是B？其中A和B来自维基百科。</sample>
    <sample id="459">以下是我们使用的采样方法。当我们向列表上方移动，实体之间的相似性增加，通常难以进行消歧。</sample>
    <sample id="460">第一個是統一吸引。</sample>
    <sample id="461">第二个是当实体具有相似名称时。例如，两个名为“retail”的书籍。</sample>
    <sample id="462">第三个是当他们在维基百科中有相似的描述时，或者当他们在维基百科中有相似的Infobox或属性时。例如，同一类别或同一艺术家为一首歌曲。</sample>
    <sample id="463">让我展示这个替代的问题来回答。他们知道这些实体的名称，但不一定知道实体本身。</sample>
    <sample id="464">我们做的是在两个实体中显示一些背景知识。对于歌曲，我们简单地显示每首歌曲的Google搜索链接。</sample>
    <sample id="465">然后请annotators听一些歌曲和了解每首歌曲。例如，这是EasyHunt歌曲的Google搜索结果。</sample>
    <sample id="466">为食谱和图书领域，我们从维基百科中显示一些背景文本。对于食谱，我们还显示来自维基百科的图片，以便注释员了解它们的外观。</sample>
    <sample id="467">我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有</sample>
    <sample id="468">从1:00到0:01的时间范围内没有英文内容，只有空白字符和重复的"از"字母。因此，无法翻译出有意义的中文内容。</sample>
    <sample id="469">路由实体语料库拥有6000个跨三个领域的备选问题，并拥有42000个间接引用表达式。T5大型模型的结果如下所示。</sample>
    <sample id="470">如果语言模型拥有与标注者的相同的背景知识，那么准确率真的很高，约为92%到95%。但是，这不是现实的。</sample>
    <sample id="471">如果我们没有从前奏或背景音乐，我们将没有任何音乐，或者说我们将没有任何背景音乐。</sample>
    <sample id="472">如果语言模型仅有实体名称的访问，那么准确率只有60%。因此，这里有很多改进的空间。我们还表明模型具有泛化能力。以下是我们的数据集链接。感谢。</sample>
    <sample id="473">The method compared with the following existing SimulST strategies:

1. Weight-key strategy
2. Local agreement
3. State-of-the-art architecture specifically tailored for stream-on-thigh-respirations translation.</sample>
    <sample id="474">Yannis Lavraque</sample>
    <sample id="475">Jenny</sample>
    <sample id="476">2</sample>
    <sample id="477">我是特伦特大学和布鲁诺凯撒基金会的萨拉·帕皮，我将简要介绍“注意作为同时口译指南”论文，这是一份由马泰奥·内格里和马尔科·图尔奇共同完成的作品。</sample>
    <sample id="478">[00:00:01 - 00:00:13]
Simultaneous Speech Translation，简称SIMUL-ST，是指实时将口语语言翻译成另一种语言的过程，实现跨语言通讯。</sample>
    <sample id="479">当前激励模型的问题是：通常，特定的架构通常会引入额外的模块以进行优化。</sample>
    <sample id="480">长时间的复杂培训程序，例如涉及不同优化目标的培训。</sample>
    <sample id="481">"训练和维护多个模型以达到不同的延迟模式。例如，训练一个延迟为一秒的模型，以及另外一个延迟为两秒的模型等等。"</sample>
    <sample id="482">我们的解决方案是什么？</sample>
    <sample id="483">首先，使用现有离线SD模型，而不需要重新训练或专门设计特定的架构，以适应单个SD。使用同一个模型在每个延迟模式下，并通过特定的参数来处理延迟。</sample>
    <sample id="484">"通过模型通过音频输入和文本输出之间的注意力机制所获得的知识，可以看到右侧的示例，这是交叉注意力机制。"</sample>
    <sample id="485">我们的解决方案是提出一个点或编码器的注意力代码，这是一个决定是否发出部分翻译的策略，根据注意力指向的位置。</sample>
    <sample id="486">如果张力不集中，那么这个词语将被发射，这意味着这个总和低于某个阈值alpha，指的是在最后的lambda音频帧中，这意味着接收的信息足够稳定。</sample>
    <sample id="487">例如，如果我们收到一段语音信件，其中包含我将讨论，并且我们的模型预测在德语翻译。</sample>
    <sample id="488">我们将查看交叉注意权重。</sample>
    <sample id="489">我们将看到，前两个单词指向最早收到的语音帧，而最后一个单词指向最后收到的语音帧作为lambda语音帧。</sample>
    <sample id="490">没有内容。</sample>
    <sample id="491">在交叉注意力之和大于某个阈值alpha时，我们将不发射最后一个词语，等待另一个语音块。</sample>
    <sample id="492">如果我们继续下去，收到另一个语音tank，我们的模型预测其他三个单词，然后我们将查看这个交叉注意权重。</sample>
    <sample id="493">我们将看到没有单词指向最后一个lambda语音框架。</sample>
    <sample id="494">这意味着这三个单词将被发射。</sample>
    <sample id="495">如果你查看那个结果的主要结果。</sample>
    <sample id="496">我们将同时空间转换结果绘制在图表中，其中一个侧面是用蓝色表示转换质量和平均滞后。</sample>
    <sample id="497">“我们也考虑计算延迟的测量和模型预测输出所需的计算时间，以便计算平均相似度。”</sample>
    <sample id="498">我们想要在这个图表上我们的曲线尽可能高。</sample>
    <sample id="499">我们也想让它们向左移动。</sample>
    <sample id="500">我们与其他离线模型中应用的预处理策略进行比较，这些策略包括权重策略和局部一致性策略。我们还与专门为 steam-on-thigh-respirations 翻译设计的最新架构进行比较。</sample>
    <sample id="501">这些是关于德语同时空间翻译策略的所有结果。</sample>
    <sample id="502">我们看到，成人输出形式应用于离线模型的所有策略，因为曲线向左偏移。</sample>
    <sample id="503">我们还看到，如果考虑实际的时间或计算时间，那么实际上最快的策略。</sample>
    <sample id="504">如果您想了解更多结果，请阅读我们的论文。我们还发布了开源代码、模型和同时输出，以便facilitate our work的可重复性。感谢您的关注。</sample>
    <sample id="505">No, the data set is not publicly available, as it is mentioned that you can contact the speaker for more information.</sample>
    <sample id="506">"大家好，我是 Ying，我的同事 Zhiyang 和我将会介绍我们关于多模型精神学习的研究，通过指令调整来改进。"</sample>
    <sample id="507">随着大规模语言模型的发展，许多研究开始探索使用预训练语言模型来实现参数和数据高效的下游任务学习新范式。</sample>
    <sample id="508">“最近，许多研究表明，指令调谐使大语言模型可以在零样本情况下通过自然指令执行未见过的任务。”</sample>
    <sample id="509">然而，前人的研究中，Instruction Tuning的主要关注点是提高语言任务的零样本性能，而计算机视觉和多模态任务则被忽视。</sample>
    <sample id="510">因此，在本研究中，我们想探索在多模态蛋白质模型中进行指令调整是否可以提高未见多模态任务的泛化能力。</sample>
    <sample id="511">我们在研究中发现，在RLP和多模型之间存在着一项可观察到的instruction数据集可用性差异。</sample>
    <sample id="512">存在超过1600个语言-only 指令任务。然而，没有大规模的公开可用的多模态指令任务。因此，这激发了我们创建多模态指令调整数据集的动机。</sample>
    <sample id="513">我们现在介绍multi-instruct，第一个涵盖10个板块的62个多模态任务的多模态指令调整数据集。</sample>
    <sample id="514">这些任务来自21个开放源代码数据集，每个任务都配备了五个专家写的说明。</sample>
    <sample id="515">为了对我们提议的数据集进行多模态指令调整，我们使用OFA作为我们的基本模型。OFA使用了统一的语言、图像token和bounding box坐标的词汇。</sample>
    <sample id="516">"我们展示了我们的多实例数据集的一些示例。"</sample>
    <sample id="517">将多种输入和输出数据类型的处理统一。</sample>
    <sample id="518">我们遵循OFA的方法，將所有任务都格式化为统一的序列到序列格式，其中输入文本、图像、说明和边界框都在同一个令牌空间中表示。</sample>
    <sample id="519">"好的，下面我将讨论多模态指令调谐。"</sample>
    <sample id="520">我们使用了9个组的53个任务作为训练集，并从每个任务中抽取10,000个实例。对于测试，我们将共同的Reasoning组留作测试，并从VQA和杂项组中选择5个任务。</sample>
    <sample id="521">我们对每个任务使用测试舰队中的所有实例。此外，我们从自然指令测试舰队中随机抽取20个任务作为NLP的现场任务。</sample>
    <sample id="522">我们使用预训练的OFA大模型作为基础模型。在训练中，我们对所有任务生成所有实例，每个实例都随机与其中之一的五个指令模板组合。</sample>
    <sample id="523">在测试中，对于每个任务，我们对模型进行五个实验，每个实验使用不同的五个指令来评估。</sample>
    <sample id="524">我们报告了五个实验的平均性能、最大性能和性能标准差。</sample>
    <sample id="525">如果任务是一个多模型分类任务，我们报告准确率。如果是多模型生成任务，我们报告root mean squared error。如果是RP任务，我们也报告root mean squared error。</sample>
    <sample id="526">我们还引入了名为敏感度的评估指标。它衡量模型在执行相同任务时，对于 slight wording variation 的输入结果的一致性。</sample>
    <sample id="527">"我们的主要结果是：instruction tuning可以显著提高同模型任务中的OIS性能。"</sample>
    <sample id="528">使用自然语言Instruction数据集的迁移学习也可以提高Instruction调整。</sample>
    <sample id="529">我们可以看到随着任务数量的增加，模型的性能会更好，同时敏感度也会下降。</sample>
    <sample id="530">我们也做了一个实验，使用了一条指令 versus 五条指令。正如我们可以看到，使用更多的指令可以提高模型的整体性能，并且减少其敏感性。</sample>
    <sample id="531">[00:01:00 - 00:00:01]

这种策略对模型灵敏度的影响可以看到，在从自然指令数据集中进行迁移学习，可以使模型的灵敏度远远优于原始OFA模型。</sample>
    <sample id="532">我们也可以看到，自然指令数据集中的转移学习可以帮助 OFA 在自然指令数据集上取得更好的性能。</sample>
    <sample id="533">我们提出了第一个大规模多模态指令调整数据集。我们对OFA进行了改进，探索了不同的迁移学习技术，并展示了它们的益处。我们设计了一个名为灵敏度的新指标。</sample>
    <sample id="534">我们还收集了一大批多模型指令调整数据集，包括150多项Weiren语言任务，我们将其发布。以下是我们的数据和模型QR码。谢谢。</sample>
    <sample id="535">The authors belong to the University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="536">Jawad Hosseini</sample>
    <sample id="562">"大家好，我是库斯塔夫·辛哈，欢迎来到我们2023年ACL论文的讨论，我很高兴介绍我们的论文《语言模型可接受性是基于上下文的不可靠的》。"</sample>
    <sample id="563">“和约翰·沃瑟、奥伦·穆勒、卡尼什卡·米什拉、卡伦·芬图斯、罗杰·雷维和阿迪娜·威廉姆斯一起合作的项目。”</sample>
    <sample id="564">我们在这项工作中重新探讨最小对比对范式。</sample>
    <sample id="565">最小的配对模式基本上是在评估语言模型的可接受性，包括语法正确性，如“blimp语法”或基于ereotype的可接受性，如“crowd spares”。</sample>
    <sample id="566">在这个最小对立对照(paradigm)中，评估语言模型的典型方法是显示一个可接受的句子或语法正确的句子，然后显示一个可接受的句子或语法错误的句子。</sample>
    <sample id="567">然后，希望模型将更多的可能性赋予可接受的领域。</sample>
    <sample id="568">当前的MPP管道基本上不允许我们评估模型对更长句子的接受能力。</sample>
    <sample id="569">现在，语言模型的上下文窗口越来越长，因此我们需要在整个上下文窗口中评估模型的可接受性。</sample>
    <sample id="570">我们这里正试图做的事情就是重新探索MPB管道，让模型评估更长的序列可接受性。</sample>
    <sample id="571">我们采取的方法是，对数据集进行重新访问，然后重新构建句子单元，选择来自这些数据集的可接受或不可接受的句子。</sample>
    <sample id="572">例如，我们选择了来自blimp数据集的典型对称对，从附件岛案例中。</sample>
    <sample id="573">我们做的是重新创建更长的序列，并确定哪些是可接受的，并且具有相同的语法结构，我们从AdjunTile中提取语法句子。</sample>
    <sample id="574">然后，我们将其添加到可接受的查询和不可接受的查询的前缀中。</sample>
    <sample id="575">我们可以通过从同样的匹配中选择不接受的句子，并将其用来测试模型的可接受性。</sample>
    <sample id="576">我们也可以从不同的子集或不同的数据集中选择句子。这样我们称为 mismatch 场景。</sample>
    <sample id="577">"这些句子来自相关数据集，但是不是你正在评估的同一个数据集。我们可以对不接受的做同样的事情。"</sample>
    <sample id="578">最后，我们可以从完全无关的领域，如维基百科中选择句子。</sample>
    <sample id="579">"这将告诉我们模型的可接受性判断是否受到任何上下文的影响。"</sample>
    <sample id="580">他说：“无论是来自数据集的不同子集还是与当前句子完全无关。”</sample>
    <sample id="581">模型性能如何？首先，我们查看与当前查询对完全无关的维基百科句子。在那里，我们发现MPP判断对于任意上下文都非常robust。</sample>
    <sample id="582">我们将上下文长度增加到1024，以最大限度地提高OPT和GPT2模型的性能。正如橙色点线所示，MPP评估结果基本保持稳定。</sample>
    <sample id="583">当我们从同一个数据集中选择句子时，什么会发生？</sample>
    <sample id="584">我们正在从同一个blimp或语法gem数据集选择或创建可接受和不可接受的句子。</sample>
    <sample id="585">我们看到，当添加可接受的前缀或不可接受的前缀时，MPP 判决的结果都会明显增加或减少。</sample>
    <sample id="586">当我们匹配结构时，那是当我们从同一个现象中选择同一个人名文本的句子，詹姆。</sample>
    <sample id="587">我们看到模型对于选择的前缀是否可接受或不可接受的MPP判断会出现大幅增加或大幅减少。</sample>
    <sample id="588">现在，这个效果随着上下文的长度增加，这可能会影响更新的语言模型，这些模型具有较大的上下文窗口。</sample>
    <sample id="589">因此，match prefix对语言模型判断产生如此大的影响。</sample>
    <sample id="590">我们进行了一系列分析，尝试保留输入句子的结构，但是在输入中添加噪音。然后，我们进行了多次这些扰动后，</sample>
    <sample id="591">我们发现这些噪音都没有改变模型对MPP判断的结果。</sample>
    <sample id="592">我们发现模型对扰动和句子具有相似的敏感性。</sample>
    <sample id="593">当我们在可接受域中扰乱句子，我们看到类似的扰乱增加。同样，当我们在不可接受域中扰乱句子，我们看到MPP判断的下降。</sample>
    <sample id="594">我们的主要结论是语言模型对句法和语义特征之间共享的特征非常敏感。</sample>
    <sample id="595">"我们当前使用的MPP评估方法，通过单个中心输入可能不能充分捕捉语言模型在上下文窗口中的抽象知识。"</sample>
    <sample id="596">"请阅读我们的论文以获取我们的实验的详细信息。感谢您的聆听。"</sample>
    <sample id="597">unordered multi-set of tokens that will appear in the output</sample>
    <sample id="598">55,000</sample>
    <sample id="626">messalign</sample>
    <sample id="627">Weakly supervised learning helps neural networks to robustly train under label noise, allowing the models to generalize well even when the training data is noisy.</sample>
    <sample id="628">According to the given text, the document in DEplain-web uses both manual and automatic alignment methods.</sample>
    <sample id="629">The CoNLL++ dataset was created by collecting Reuters News from 2020 and annotating them with the same guidelines as the Carnot 2003 annotation guidelines.</sample>
    <sample id="630">"大家好，我是宾夕法尼亚州立大学的尹晨，今天我将会展示我们的工作，跨语言的Ghost和Money Parsing在主要表示中。"</sample>
    <sample id="631">语义处理是将用户查询，如SQL和Lambda calculus，建立语义表示的任务。</sample>
    <sample id="632">跨语言语义解析是将多种自然语言查询翻译成多种含义表示的任务。</sample>
    <sample id="633">根据这个图表，我们需要使用神经模型将查询语言翻译成多种自然语言，以SQL、Lambda、FunQL等形式。</sample>
    <sample id="634">现有的跨语言语义解析模型分别在有限的任务和应用中提出和评估，例如，</sample>
    <sample id="635">某些自然语言的覆盖范围有泄露。中文缺失。</sample>
    <sample id="636">"由于某些表达的覆盖。"</sample>
    <sample id="637">“λ演算缺失。”</sample>
    <sample id="638">"或者他们只在更新的模型中进行评估，例如，只有一种模型来评估模型。"</sample>
    <sample id="639">为此，我们提出示例。我们提供了一个统一的数据集示例，以便在多种自然语言中进行跨链语义解析和表示。</sample>
    <sample id="640">"包含90个病毒域名，570个毒素部分，80,000,000个表示和15个语言家庭中的22种自然语言。"</sample>
    <sample id="641">为了更好地评估我们的基准，我们考虑了六个训练和评估的设置。</sample>
    <sample id="642">"第一个是翻译测试。我们使用 Google 翻译 API 将源语言翻译成目标语言，然后使用单语言模型来训练评估。"</sample>
    <sample id="643">例如，我们对英语模型进行了训练，并在推理时使用 API 将德语查询翻译成英语，然后使用训练好的模型预测 SQL。</sample>
    <sample id="644">我们也测试单语言模型。</sample>
    <sample id="645">在这个设置中，源语言与目标语言相同，例如德语到德语或英语到英语。</sample>
    <sample id="646">我们还测试了一种单语言场景的场景训练模型，使用仅10%的训练数据。</sample>
    <sample id="647">"我们训练一个多语言模型，对所有语言使用同一个多语言模型。"</sample>
    <sample id="648">例如，我们将德语、英语和中文查询组合起来训练多语言模型。在推理时，我们可以使用该模型来处理这些查询。</sample>
    <sample id="649">我可以将英文内容翻译成中文。</sample>
    <sample id="650">我们还考虑跨语言代码零和field-short转移。我们在一个源语言中训练，然后将其转移到另一个语言。</sample>
    <sample id="651">在训练中，我们正在训练英语查询或英语和德语Fuscheout查询，以训练多语言模型并预测SQL输出。</sample>
    <sample id="652">我们也发现了许多有趣的结果。关于单语言模型的分析，我们评估了两个模型组。</sample>
    <sample id="653">包括了 encoder pdr，即多语言预训练的编码器与指针基于解码器，例如 xl1r 加 pdr 和 berth 加 pdr。</sample>
    <sample id="654">我们还评估 encoder-decoder 模型，这些模型是多语言训练的 encoder-decoder 模型，如 M-BART 和 MT5。</sample>
    <sample id="655">我们发现，编码器-解码器在所有九个数据集上取得了最好的性能。</sample>
    <sample id="656">我们在多语言设置中评估MT5和XLM-R的示例PDR。</sample>
    <sample id="657">我们发现，编码器解码器或编码器PDR可以通过在多种语言中进行训练而被改进。</sample>
    <sample id="658">我们发现大多数自然语言都可以获得性能提高，except English在七个数据集中性能下降，而只有三个数据集中性能提高。</sample>
    <sample id="659">我认为这被称为多语言诅咒。</sample>
    <sample id="660">我们还比较跨语言性能差异。</sample>
    <sample id="661">[00:00:01 - 00:00:10]

在这个图中，蓝线是跨语言场景 shot transfer。橙线是跨语言零 shot transfer。绿线是模型角度设置。</sample>
    <sample id="662">我们发现，通过比较绿线和橙线，我们发现在零shot设置下，交叉语言目标转移性能差异很大。通过比较蓝线和橙线，我们发现在少shot设置下，转移差异急速缩短。</sample>
    <sample id="663">我们也发现了其他有趣的发现。例如，encoder-decoder的整体性能进步工作在英语自然语言方面取得了可比结果，并且对目标自然语言的性能产生了明显的提高。</sample>
    <sample id="664">我们发现，使用代码作为蓝色语言模型在跨语言语义解析任务中仍然在该网格中。</sample>
    <sample id="665">总的来说，我们创建了ExamPolar，这是一个跨语言语义解析的统一基准测试平台，支持多种自然语言和多种表示形式。</sample>
    <sample id="666">我们对三种多语言模型的代表性进行了全面的基准测试。我们的结果显示了许多有趣的发现，欢迎您访问我们的论文和代码。感谢您的收听。</sample>
    <sample id="667">The existing works can be broadly classified into four categories.</sample>
    <sample id="668">No, Codex or Bloom, etc. LLMs are not enough for CLSP tasks.</sample>
    <sample id="695">该方法通过在训练中引入对齐来解决排列不确定性问题。</sample>
    <sample id="696">Based on the given text, a downstream NLP model's fairness can be defined as the ability to avoid perpetuating hate speech or misinformation and not marginalizing people with opposite political opinions or targeting minority groups.</sample>
    <sample id="697">Yannis Lavraque</sample>
    <sample id="698">Kostav Sinha</sample>
    <sample id="699">Myra</sample>
    <sample id="700">In this context, tropicalism refers to a stereotype or trope that associates Latin American women with vibrant and curvaceous qualities.</sample>
    <sample id="701">The author creates the target group's artificial portrayal by defining them through their relationship to their identity, using words like "culture", "tradition", "proud", and "exotic", which distinguish them as different from the "white norm".</sample>
    <sample id="702">本文中使用了Pointwise Mutual Information (PMI)来衡量语境使用情况。</sample>
    <sample id="703">DrBERT and Schubert have differences in their training data. Dr. Bert is trained on 7GB of general text, while Schubert is trained on 4GB of clinical notes.</sample>
    <sample id="751">2</sample>
    <sample id="752">迭代迁移学习是指在active learning和注释的每一轮中，更新模型的方法。</sample>
    <sample id="753">The target of the dataset is unclear as the provided text is a repetition of the phrase "درستان" in Persian, which does not convey any meaningful information.</sample>
    <sample id="754">According to the text, the attacker validated the covertness of the embedding by visualizing the embedding of sentences on four dataset BOPCA, but there is no mention of how the attacker extracted model parameters using EaaS (Embedded Adversarial System).</sample>
    <sample id="755">3</sample>
    <sample id="756">2</sample>
    <sample id="757">Carnegie Mellon University, University of Washington, and the island to do for AI.</sample>
    <sample id="758">The example is "I saw Bart and Lisa".</sample>
    <sample id="759">The latest model mentioned in the given text is the "ABC eval".</sample>
    <sample id="760">Because large language models are generating longer and longer context windows, it's crucial to evaluate their acceptability throughout the context window.</sample>
    <sample id="761">Yes, according to the speaker, most major natural languages can obtain performance gain, but English performance drops in 7 datasets and only gains in 3 datasets.</sample>
    <sample id="762">No.</sample>
    <sample id="763">Based on the given English content, the following machine translation (MT) metrics are likely used:

1. Fluency: The sentence is grammatically correct and easy to understand, indicating good fluency.
2. Relevance: The content is relevant to the topic, as it is a quote from a speaker discussing the importance of examples in a conversation.
3. Accuracy: The translation is accurate in terms of conveying the speaker's intended meaning and message.
4. Naturalness: The translation is natural and idiomatic, with no awkward phrasing or unnatural word choices.</sample>
    <sample id="764">No.</sample>
    <sample id="765">In NLP, bias is important because it can lead to incorrect or inaccurate results, such as failing to detect toxic comments in certain contexts, as illustrated in the example of Perspective API not being sensitive to offensive terms common in Indian contexts.</sample>
    <sample id="766">The BLOOM model is a complete fine-tuning model, not a adapter fine-tuning model.</sample>
    <sample id="767">They used transfer learning.</sample>
    <sample id="768">The text doesn't mention the testing set used to evaluate PaLM's ability.</sample>
    <sample id="769">3</sample>
    <sample id="770">The text does not mention a specific baseline or a quantitative improvement in terms of the proposed method's performance.</sample>
    <sample id="771">Xu Heng</sample>
    <sample id="772">Yes.</sample>
    <sample id="773">1</sample>
    <sample id="774">OFA模型。</sample>
    <sample id="833">The author's affiliation is Google Translate.</sample>
    <sample id="834">Stony Brook University</sample>
    <sample id="835">The paper analyzed neural MT metrics and human evaluation results.</sample>
    <sample id="836">Xiangbin</sample>
    <sample id="837">They fine-tuned two models: one for document-level simplifications and one for sentence-level simplifications.</sample>
    <sample id="838">12 tasks.</sample>
    <sample id="839">1</sample>
    <sample id="840">The author used the following datasets in their experiment: AG News, Mind, SSD2, and AresVam.</sample>
    <sample id="876">NACCHOS is a dataset of medical ground truth data from the web.</sample>
    <sample id="877">Aydbilar</sample>
    <sample id="878">The prompting strategy has a big influence on the performance of LLMs for translation.</sample>
    <sample id="879">The authors' affiliations are not specified in the given text.</sample>
    <sample id="880">The expert-written instructions are not mentioned in the given text.</sample>
    <sample id="881">The author suggests using a coreference resolution task to evaluate the ability to draw on knowledge from different sources.</sample>
    <sample id="882">[00:00:01] 

嗨，大家好。我是Aydbilar，我将为您提供关于论文《Grunting Pattern from Translation》的简介，这是与Google Translate的同事们一起完成的工作。</sample>
    <sample id="883">"2022年推出的BAM是一个540亿参数语言模型。它是在180亿篇文档的大型文本集上进行训练的。"</sample>
    <sample id="884">"在厨房中，它在数百个NLP任务中实现了先进的状态。"</sample>
    <sample id="885">我们在这项工作中首次进行了大规模语言模型提示的机器翻译研究。</sample>
    <sample id="886">我们使用MT社区的最佳实践评估了这些模型的转换能力。这种评估包括使用最新的测试集，以避免使用语言模型的训练数据对测试数据进行重复评估。</sample>
    <sample id="887">"我们比较了两个最新的系统。因此，表现最好的系统是WMT评估。"</sample>
    <sample id="888">我们使用最新的神经机器翻译指标，并且还展示了基于专家的人工评估结果。最后，我们提供了一些用于选择提示策略的建议。</sample>
    <sample id="889">LLMs 在翻译中的性能受到提示的很大影响。我们可以在一个简单的实验中看到，在使用一次性提示，并提供两个不同的提示，用于翻译一个句子。</sample>
    <sample id="890">"大多数句子中，516个句子中，超过1个模糊点的差异被观察到。"</sample>
    <sample id="891">"这可以在极端情况下达到40点模糊度。因此，选择合适的引导策略是很重要的。"</sample>
    <sample id="892">我们在实验中使用五个shot的提示策略，其中我们将句子标记为语言系统中所用的语言。</sample>
    <sample id="893">在这个示例中，我们执行德语到英语的翻译，德语句子标记为德语列和英语翻译标记为英语列。</sample>
    <sample id="894">我们发现，短期内的打印形式对实际的影响不大。</sample>
    <sample id="895">零和一shot prompting非常关键，而在我们这种情况下，五shot prompting对实际prompting形式的影响几乎为零。</sample>
    <sample id="896">"例子们带来的影响最为重要。"</sample>
    <sample id="897">我们实验结果的总结是，示例的质量比源句子的相似性更重要。</sample>
    <sample id="898">选择高质量翻译的示例非常重要。特别是，我们将从WMT评估的训练数据或DEF数据中选择提示。</sample>
    <sample id="899">音频</sample>
    <sample id="900">现在，至少，专业的最新系统拥有了band翻译的明显优势。但是，有一个系统已经非常接近于商业系统。在我们的情况下，我们选择与Google Translate合作。</sample>
    <sample id="901">我们通过使用MQM框架对EMAIL进行的规则分析，得出的结论是，手掌流畅度与当前最好的系统相媲美，但是主要的差异来自于准确性。</sample>
    <sample id="902">特别是，常见的错误是省略错误。</sample>
    <sample id="903">" palm选择了生产一个更好的翻译，偶尔通过删除源句子中的一部分内容来实现。"</sample>
    <sample id="904">然而，PAN的 style-outward 类别低于state-of-the-art系统，这是另一个信号。</sample>
    <sample id="905">"帕尔姆提供了非常流畅的输出，但仍然存在一些准确性问题。"</sample>
    <sample id="906">"非常感谢，这只是一个简短的概述。如果想了解更多信息，请来听完整的报告。"</sample>
    <sample id="907">"我是德国萨兰特大学的博士生戴伟。我在这个视频中将介绍我们最近的研究成果《比你想象的更复杂的周围物品》，对周围物品的分析。"</sample>
    <sample id="908">这是与肖宇轩、Mario Smoothbath和Diaz Stefan和DTich Claco共同的工作。</sample>
    <sample id="909">我想从弱监督和弱监督学习开始进行简短的介绍。</sample>
    <sample id="910">在弱监督中，我们不手动标注数据。相反，我们使用弱标注源，如简单的heuristic规则、知识库或局部代码 souring，正如右图所示。</sample>
    <sample id="911">相比人类标注，弱标注的成本更低，但它们也更加噪音化，这意味着有一定数量的标注是错误的。</sample>
    <sample id="912">如果我们直接在有标签的周期数据上训练神经网络，那么神经网络 tends to memorize 标签噪音而不 generalise。</sample>
    <sample id="913">在每周监督学习中，为了使神经网络在高噪声下仍然可以 generalize良好，提出了训练算法，以便在噪声环境中训练模型。</sample>
    <sample id="914">在WSL（每周监督学习）中，人们常常声称，他们仅在周度劳动数据上训练模型，并在干净测试集上获得高性能。</sample>
    <sample id="915">"从技术角度来说，这个声明不是错误的，但是有一个陷阱。"</sample>
    <sample id="916">「人们总是假设有一个额外的清洁验证集或防火墙来选择模型。」</sample>
    <sample id="917">我们在这个问题上中断了，因为这暗示着需要在每周支持中添加更多的手动注释，但这项必要性却常常被忽视，就像一个房间中的大象。</sample>
    <sample id="918">“前提的疑惑是要问三个研究问题。第一个问题是：是否需要干净的验证数据来使用WSL？或者可以使用嘈杂的验证集？”</sample>
    <sample id="919">第二，如果需要或必须清洁数据以便WSL可以工作，那么我们需要多少个清洁样本？最后，我们是否只使用清洁样本进行验证，还是有更好的方法来使用它们？</sample>
    <sample id="920">我们在我们的研究中解决了这些问题，以下是我们的发现。</sample>
    <sample id="921">首先，我们发现，最近的WSL方法确实需要洁净的全宽带样本以正常工作。</sample>
    <sample id="922">"否则，性能将会下降。正如该图所示，如果没有干净的验证样本，那么趋势模型就不能超越原始周标签。"</sample>
    <sample id="923">训练毫无意义。</sample>
    <sample id="924">WSL 的方法实际上需要干净标注的数据以正常工作，而获取干净验证样本的标注成本 shouldn't被忽视。</sample>
    <sample id="925">我们的第二个发现是，增加干净验证样本的数量可以帮助WSL方法提高性能，如图左所示。</sample>
    <sample id="926">通常，我们只需要20个样本就可以达到高性能。</sample>
    <sample id="927">"然而，这不是故事的结局，因为如果我们选择直接在洁净样本上进行训练，那么结果将会更好。"</sample>
    <sample id="928">红色图表显示了直接在干净数据上fine-tuning的方法和使用干净数据仅用于验证的WSL方法之间的性能差异。</sample>
    <sample id="929">我们可以看到，如果我们有10个样本per class，Direct的fine tuning开始超过WSL方法。</sample>
    <sample id="930">"最后，WSL方法中之前宣称的性能改进可以通过在清洁验证样本上继续微调来轻松实现。"</sample>
    <sample id="931">根据图表，我们可以看到，Valina 模型称为 FTW 初始情况下性能不如复杂的 WSL 方法，如余弦方法。</sample>
    <sample id="932">然而，如果我们继续对干净样本进行微调，那么FTW的性能与其他方法相等。</sample>
    <sample id="933">在实践中，没有必要选择复杂的WSL方法，这些方法需要更多的计算时间和磁盘空间。</sample>
    <sample id="934">我们展示了，最近的WSL方法需要清洁、手动注释的样本才能正常工作。它们的性能提高和实际可行性被严重夸大。</sample>
    <sample id="935">我们的未来的工作时间建议如下。</sample>
    <sample id="936">首先，报告模型选择标准，例如报告模型选择是否使用了良好验证样本。</sample>
    <sample id="937">第二点，WSL 应该被迫使用未来的着陆基准作为清晰样本。第三点，连续微调是一个简单却强大的基准，应该在WSL的未来工作中被考虑。</sample>
    <sample id="938">"最后，我们已经开源了我们的代码。你可以通过这个幻灯片上的QR码来查看。感谢您的关注，祝您享受会议。"</sample>
    <sample id="939">The common practice is human evaluation, such as asking human judges to select which of two conversations is better or to rate conversations on a Likert scale.</sample>
    <sample id="940">4</sample>
    <sample id="941">根据给定的英文内容，可以看出，需要以下背景知识：

1. Servin 和 Kea 是什么人或概念
2. 他们在什么领域或背景中出现
3. 他们的关系是指什么类型的关系（例如友好、恋人、家人等）</sample>
    <sample id="942">Yes, the code is open and can be found on GitHub.</sample>
    <sample id="943">No, the annotator of NLPositionality does not have a balanced representation in terms of demographic characteristics such as gender, as the speaker is a female.</sample>
    <sample id="944">The question is asking how to add noise to the input sentence while preserving the relevant structure, in order to analyze the language model's judgment.</sample>
    <sample id="945">进行维度评估（evaluating multiple dimensions）意味着评估多个方面或维度，以更好地了解模型在细粒度级别上的优缺点。</sample>
    <sample id="946">University of Science and Technology of China.</sample>
    <sample id="947">根据文本，提示的形式在以下情况下很重要：

1. 在零短促的情况下
2. 在一短促的情况下</sample>
    <sample id="978">The author evaluated conversational AI models.</sample>
    <sample id="979">1</sample>
    <sample id="980">优秀规划器的理想品质是：写出合理、忠于约束的脚本。</sample>
    <sample id="981">1</sample>
    <sample id="982">Vasudha</sample>
    <sample id="983">Adam Szpirkowski</sample>
    <sample id="1021">Omission errors.</sample>
    <sample id="1022">[00:00:01] 00:00:09

我是詹姆斯·芬奇。我是莎拉·芬奇。今天，我们将告诉您关于ABCeVal，一个新的对话AI评估方法。</sample>
    <sample id="1023">"由埃默里 NLP 实验室，埃默里大学教授蔡元博士领导，和亚马逊Alexa AI合作完成的工作。"</sample>
    <sample id="1024">"假设你刚刚开发了一个对话模型，想知道它与当前最先进水平的相比如何。"</sample>
    <sample id="1025">常见的做法是使用人工评估，例如请人工评审员选择哪个对话更好，或者根据 Likert 等级对对话进行评分。</sample>
    <sample id="1026">这些方法对对话质量进行了全面的评估，但对话质量有多个方面。因此，您可能想评估多个对话质量维度，以了解模型在更细化的层面上的优点和缺点。</sample>
    <sample id="1027">一种方法是请人工评估对话质量的多个维度，例如使用现有比较或Likert等尺度方法评估模型响应的相关性。</sample>
    <sample id="1028">然而，我们认为有一个更加精准可靠的维度对话评估策略。</sample>
    <sample id="1029">我们的方法旨在通过明确注释模型响应是否表达某些行为，例如响应无关信息或自相矛盾，从而减少人类评估的主观性。</sample>
    <sample id="1030">我们称这种方法为在聊天中注释行为或简称为ABC评估。我们开发了这种方法，以全面涵盖近期文献中提到的影响聊天质量的聊天模型行为。</sample>
    <sample id="1031">"ABC评估能够测量聊天模型犯各种主题错误的速度。"</sample>
    <sample id="1032">例如，ABC评估模型评估了聊天模型忽视其伙伴或说些无关紧要的话的回合数。</sample>
    <sample id="1033">"该模型会自相矛盾、错误地记忆事实或违反常识知识，并且在模型成功或失败时缺乏同理心。"</sample>
    <sample id="1034">为了确定最有效的评估方法，我们选择了四种最新的聊天模型，并将每种模型评估100个人类机器人对话使用ABC评估。</sample>
    <sample id="1035">为了对比，我们还使用了三个现有方法评估了这些对话，分别是：turn级别的酒精评分、对话级别的酒精评分和对话对比评分。</sample>
    <sample id="1036">我们对每种现有方法收集了对对话中八个最常被测量的方面的评估，因为这是评估聊天模型的标准做法，以多个维度评估。</sample>
    <sample id="1037">根据我们对这些评估结果的分析，我们发现，ABC评估行为标签总体上比现有方法收集的标签更可靠，根据100个双重标注对话的Interannotator一致性来衡量。</sample>
    <sample id="1038">此外，ABC评估标签相比现有方法产生的指标，更好地预测了对话质量，如以下简单线性回归分析所示。</sample>
    <sample id="1039">例如，您可以看到，测量自我和对方矛盾的比例可以解释会话质量的5%和10%，而平均酒精一致性分数仅解释4%或更少。</sample>
    <sample id="1040">最后，我们检查了每个评估指标是否捕捉到对话质量的独特方面，使用逐步线性回归。</sample>
    <sample id="1041">可以看到，所有ABC评估指标的组合解释了对话质量的25%以上。随着你逐个删除这些指标，大多数情况下都会导致对话质量的信息损失。</sample>
    <sample id="1042">另一方面，所有 Likert 等级指标的组合解释的质量要少得多，这些指标中只有少数携带独特信息。</sample>
    <sample id="1043">这些可靠、信息化、独特的ABC评估指标使我们能够使用更高分辨率来评估对话式人工智能，而之前的方法无法实现。</sample>
    <sample id="1044">"实验结果表明，我们仍然存在一些挑战，并且已经被精确量化。例如，我们测试的机器人在20%的回答中存在常识违背。"</sample>
    <sample id="1045">他们在15%的回答中提供无关信息，另外10%的时间，他们或他们的合作者之间存在矛盾。</sample>
    <sample id="1046">随着该领域的快速进步，自我们评估以来发布的新模型中许多错误率可能会降低。然而，这更是推动我们追求可靠和准确评估指标来比较模型的理由。</sample>
    <sample id="1047">我们希望 ABC 评估能够被他人在该领域中发挥作用，这将是一个有意义的一步。我们期待在未来的几个月和年中，会话式人工智能的发展。感谢您的观看。</sample>
    <sample id="1048">Emory University.</sample>
    <sample id="1049">CFT is not mentioned in the given text.</sample>
    <sample id="1050">6</sample>
    <sample id="1051">"我是Kaio Yan，我将要介绍我们的作品《When Does Translation Require a Context？：A Data-Driven Multilingual Exploration》，这项工作是与Patrick Frenange、M.E. Liu、Andre F.D. Martin和Graham Mubig合作完成的。"</sample>
    <sample id="1052">在这个句子中，更多的翻译取决于上下文。例如，我们如何翻译这个句子？</sample>
    <sample id="1053">如果前一个句子是“如果部长们发现了，那可能会变得危险”，那么Moe指的是间谍。但是，如果前一个句子是“那么这可能会很严重，医生？”那么Moe指的是胎记。</sample>
    <sample id="1054">根据上下文，单词的含义会发生变化，因此其翻译也会发生变化。</sample>
    <sample id="1055">然而，评估模型对这种情况的翻译效果很困难。首先，因为只有少部分翻译依赖于上下文，这使得基于corpus的指标，如BLUE无法捕捉到这些翻译。</sample>
    <sample id="1056">有些人建议基于上下文的评估，但是这些资源只支持有限的基于上下文的翻译类型和有限的语言集，因为它们通常依赖领域知识和人工编辑。</sample>
    <sample id="1057">在本研究中，我们尝试回答这两个问题。首先，什么时候翻译需要上下文？其次，这些情况下模型的性能如何？</sample>
    <sample id="1058">为回答第一个问题，我们首先测量了单词在翻译中的依赖性。</sample>
    <sample id="1059">"我们之前介绍了CXMI作为机器翻译模型中上下文使用的度量。这里是通过测量上下文C关于目标Y的信息量，给定源X的信息量来实现的。"</sample>
    <sample id="1060">CXMI 可以被视为模型中的上下文信息。</sample>
    <sample id="1061">在这项工作中，我们将CXMI扩展到YCXMI，可以在句子级别或词语级别衡量上下文使用。我们可以认为P6MI高的词语是需要上下文来翻译的。</sample>
    <sample id="1062">现在我们分析具有高XMI的单词，以查找这些单词之间的模式。</sample>
    <sample id="1063">我们对来自英语的TED演讲的翻译结果进行分析，该翻译结果已经翻译成了14种不同的语言。</sample>
    <sample id="1064">我们对语料进行三种不同的分析。首先，我们查看PCXMI值较高的部分词性标签。</sample>
    <sample id="1065">这允许我们找到阿拉伯语中的双数代词，它们在P6MI中具有相对高的值。這可以解释为英语没有双数代词，所以在将英语翻译为阿拉伯语时需要上下文来确定代词是否为双数。</sample>
    <sample id="1066">我们发现，某些语言也需要在选择合适的动词形式时考虑上下文。然后，我们查看了包含所有不同出现次数的词汇项的p-sex-mi平均值。</sample>
    <sample id="1067">"这有助于识别类似于这里的情况，在中文中，您需要上下文来翻译名词，以确保在文档中使用同一翻译。"</sample>
    <sample id="1068">我们也发现，语境支持在正确的形式中翻译。</sample>
    <sample id="1069">最后，我们来看那些高P6MI的个体令牌。这使我们能够识别一些不能通过单词本身捕捉到的现象，而是通过句法结构表达的，如省略号解析。</sample>
    <sample id="1070">现在我们使用分析结果来设计一个文档全球翻译的基准。</sample>
    <sample id="1071">我们为每个我们所识别的五种对话现象创建标记器，以自动识别与现象相关的单词，我们称我们的标记器为多语言对话-aware或Muda标记器。</sample>
    <sample id="1072">我们还可以注意到不同语言中这些话语现象的不同比例。</sample>
    <sample id="1073">我们然后使用MudaTaggle将标签应用于我们想要用于评估的平行语料库，并在MudaTaggle标记的上下文相关示例上应用我们的选择翻译指标。</sample>
    <sample id="1074">最后，我们使用我们的基准和其他指标对文档级机器翻译模型进行评估。</sample>
    <sample id="1075">首先，在使用 corpuses级别指标时，我们发现无关上下文的模型在蓝色中具有最好的性能。</sample>
    <sample id="1076">但是，如果我们使用Comet，基于上下文的模型表现最佳。如果我们使用F1度量，那么具有或无上下文的模型表现相似。</sample>
    <sample id="1077">这是再次表明，如果仅使用corpus级别指标来评估文档级别翻译系统的性能是很困难的。</sample>
    <sample id="1078">我们现在使用Mooda基准来评估模型，并发现具有上下文 awareness 的模型对于某些对话现象，如正式性和词汇连贯性，具有明显更高的准确率。</sample>
    <sample id="1079">这些模型与不使用上下文的模型在其他现象，如椭圆、多年生植物和动词形式方面也没有太多改善。这暗示了我们需要在文本级别转换方面看到更多进步。</sample>
    <sample id="1080">我们还将不同的商业系统进行比较，并且我们的基准测试结果表明，D-Bel通常比Google Translate更准确地翻译文档。</sample>
    <sample id="1081">总结来说，我们在14对语言对中进行数据驱动的分析，以确定翻译需要的上下文。</sample>
    <sample id="1082">然后，我们使用我们的发现来建立文档级机器翻译的基准，可以帮助我们确定哪些跨盘现象模型可以很好地处理哪些无法处理的文档级翻译系统，并且哪些翻译系统在文档级翻译方面表现得较好。</sample>
    <sample id="1083">"感谢您的关注。下次见面在多伦多。"</sample>
    <sample id="1084">Yusin Zhang</sample>
    <sample id="1121">This method is known as the "Hunt and Seek" algorithm.</sample>
    <sample id="1122">The author describes the "marked words" method as a way to identify words that distinguish marked groups from unmarked ones.</sample>
    <sample id="1123">University of Washington</sample>
    <sample id="1124">The first mentioned symmetric dependency structure is the "Prague approach".</sample>
    <sample id="1125">James Finch and Sarah Finch.</sample>
    <sample id="1126">4</sample>
    <sample id="1127">According to the text, the minimal pair paradigm can be used to evaluate language models on top of acceptability judgments, which can include grammaticality (e.g. blimp syntax gem) and acceptability in terms of stereotypes (e.g. crowd spares).</sample>
    <sample id="1161">The research question is not explicitly mentioned in the given text, but based on the context, it seems to be related to "WSL" which is likely an abbreviation for "Weakly Supervised Learning".</sample>
    <sample id="1162">11 biomedical and clinical tests in French.</sample>
    <sample id="1226">According to the text, CamemBERT was trained on a subject of 4 GB in nature, using the weight and token of Pomet Bird.</sample>
    <sample id="1227">Adam Szpirkowski</sample>
    <sample id="1228">根据文本，发现时间漂移是性能下降的主要原因的是“temporal gap”。</sample>
    <sample id="1269">To put the tokens in the right order.</sample>
    <sample id="1270">The author suggests that model owners should increase transparency about bias mitigation methods because they want to know if the positive stereotypes are due to "weird, overly excessive value alignment" or other anti-stereotyping methods that are resulting in pernicious patterns.</sample>
    <sample id="1271">Minimal pair.</sample>
    <sample id="1272">Weight, token, Pomet Bird, scratch</sample>
    <sample id="1273">Interanitator Agreement.</sample>
    <sample id="1274">不可接受查询中选择。</sample>
    <sample id="1275">Regina Stotten</sample>
    <sample id="1276">MultiInstruct differs from previous works in that it focuses on instruction tuning for multimodal protein models, whereas most previous works focused on language-only tasks.</sample>
    <sample id="1277">1</sample>
    <sample id="1278">Not found.</sample>
    <sample id="1279">3 seconds.</sample>
    <sample id="1280">According to the text, these findings suggest that smaller T5 models can generate scripts of higher quality than most large-level models when properly trained on suitable data sites.</sample>
    <sample id="1281">"Bonjour,我是 Yannis Lavraque，我向您介绍我们的作品Dr Berth，一个用于生物和临床领域的robust模型。"</sample>
    <sample id="1282">"在这次演讲中，我们讨论的是一门健康模型语言。下面，我们将介绍我们的主要贡献。"</sample>
    <sample id="1283">我们引入了第一个生物医学模型，名为Dr.Berth，基于Roberta，并在NACCHOS上进行了训练，这是一个来自网络的医疗数据集。</sample>
    <sample id="1284">我们还引入了多个模型的比较和多个数据源的比较。然后，我们将展示11个医疗和临床测试的结果，以法语。</sample>
    <sample id="1285">最后，我们将对实验进行总结，并提供更多关于访问模型的信息。</sample>
    <sample id="1286">自2018年以来，Bert已经是自然语言处理的最有效的方法之一。相比历史上的策略和方法，如“见到-vec”或“见到-发送”，Bert带来了明显的性能提高。</sample>
    <sample id="1287">从这款模型被适应到许多其他语言，如法语与Camembert，还有生物医学领域的Père Medbert和Biobird，和临床领域的Clinique Albert，但尤其是英语。</sample>
    <sample id="1288">特别是对于其他语言的模型scarce，并且通常基于连续训练，因为缺乏领域内数据。</sample>
    <sample id="1289">然而，法国直到现在还没有开源的生物医学模型。</sample>
    <sample id="1290">我们问自己一个问题，关于什么是适合各种使用场景的数据结构。这些当前数据是临床数据的良好替代品。</sample>
    <sample id="1291">为了回答这个问题，我们将Dr. Bert与我们的Schubert模型进行比较，该模型基于我们家医院的匿名数据。</sample>
    <sample id="1292">"我们问自己，训练专门的模型需要多少数据？是 Gb 或更高？"</sample>
    <sample id="1293">为了回答这个问题，我们首先从头训练和比较四个从零开始的模型。一个是Dr. Bert的第一个版本，拥有7GB的自然语言处理能力。另一个是Dr. Bert的第二个版本，拥有4GB的自然语言处理能力。</sample>
    <sample id="1294">施巴特的第一版是一个临床模型，拥有4GB的临床笔记。最后一版的施巴特是一个混杂的模型，拥有4GB的自然语言和4GB的临床笔记。</sample>
    <sample id="1295">除了这个比较，我们在大陆预训练中引入了三个模型来分析预训练策略的影响。</sample>
    <sample id="1296">"基于 Camembert 的一个基准，使用 4 GB 的数据集。还有一个基于 Camembert 的基准，但是在 4 GB 的数据集上进行了训练，还有一个。"</sample>
    <sample id="1297">"最后，我们基于英语生物医学模型Bermond Bert，训练了四个GB的数据集。总共有七个模型。"</sample>
    <sample id="1298">"为了评估这六种模型，我们收集了公开资源和私人资料，包括名词的识别、分类、旅行、挑战和责任。"</sample>
    <sample id="1299">本模型与 Camembert Oscar 138GB、Camembert Oscar 4GB、Camembert CCNet 4GB、Pummet Belt、BioBert 和 ClinicalBert 进行了比较。</sample>
    <sample id="1300">模型在与其训练数据性质相同的数据上执行的演化最佳的高亮。</sample>
    <sample id="1301">然而，我们可以从多种来源获取数据，我们发现来自异质来源的数据更具多样性。我们也观察到使用更多数据将导致更好的性能。</sample>
    <sample id="1302">从头开始返回似乎在大多数任务中获得了更高的性能。</sample>
    <sample id="1303">我们的经验在约束和假设中，使用Pomet Bird的weight和token，基于4GB的主题数据，结果与使用Dr. Bert，4GB的scratch结果相似。</sample>
    <sample id="1304">“与基于 Camembert 权重和tokenizer 的模型不同，它们存在稳定性问题。”</sample>
    <sample id="1305">最后，作为总结，我们的系统在11个下游任务中超过9个任务的性能，并超越了Camembert泛型模型的结果。</sample>
    <sample id="1306">我们也观察到，专家数据更好，更多的专家数据更好，但是它不太适合扩展。</sample>
    <sample id="1307">所有从 NATURES 获得的预训练模型都可以在 UginFace 上免费获取，并且所有训练脚本都在我们的 GitHub 仓库中。</sample>
    <sample id="1308">谢谢您的演讲。我们期待在多伦多的海报会议上采取行动。</sample>
    <sample id="1309">The paper discussed training and comparing four models from scratch.</sample>
    <sample id="1310">0</sample>
    <sample id="1311">The quality of simplified text can be evaluated by comparing the original text with the simplified text in terms of readability, fluency, and accuracy.</sample>
    <sample id="1312">Yes.</sample>
    <sample id="1313">[00:00:01-00:00:18]

嗨，我叫马蒂亚斯·兰德曼今天我将为您介绍我们关于无树结构组合推理的论文，使用多集合标记和隐私排列。</sample>
    <sample id="1314">这是与我的顾问Alexander Kodler和Yvon Titov合作的作品。</sample>
    <sample id="1315">组合性推广可以被理解为学习者的能力，可以处理训练中看到的单个短语的更深层次递归和未见过的短语组合。</sample>
    <sample id="1316">在语义解析的背景下，检查组合性 generalize 可能如下。正如通常情况，我们有一个训练集的 utterances，这里是女孩睡了，玛丽知道女孩睡了。</sample>
    <sample id="1317">这些utterances与逻辑形式配对，代表它们的核心含义。</sample>
    <sample id="1318">相比标准机器学习评估，测试集不来自同一分布，但包含结构不相关的形式。</sample>
    <sample id="1319">在这个示例中，模型在训练中见过较浅的递归，并且在测试中遇到了递归深度更高的示例。</sample>
    <sample id="1320">简单序列到序列模型在这种分布外推理中遇到困难，通常生成的输出与输入脱节。</sample>
    <sample id="1321">特别是，他们经常不能复制输入和输出之间的系统对应关系，例如，在示例中用颜色编码的对应关系。</sample>
    <sample id="1322">使用树来解决这个问题的流行方法是将树集成到模型中。</sample>
    <sample id="1323">树木旨在捕捉句子与逻辑形式之间的组成过程。</sample>
    <sample id="1324">这工作效果不错，但树木通常不给出，而需要通过某种方式获得。</sample>
    <sample id="1325">这是一个复杂的过程，计算开销也很大。通常，这涉及到形式逻辑的特定预处理，例如处理变量符号。</sample>
    <sample id="1326">获取树也可能涉及到特殊的语法归纳过程。</sample>
    <sample id="1327">本文中，我们不使用树形结构，而是引入一个直接模型输入片段与输出片段之间相互对应关系的神经序列到序列模型。</sample>
    <sample id="1328">首次展示在不依赖树的基础上对更深递归的普遍化。</sample>
    <sample id="1329">我们的方法预测输入的输出有两步。</sample>
    <sample id="1330">首先，我们为每个输入token标记一个无序的多集合，其中包含将在输出中出现的token。</sample>
    <sample id="1331">在第一步，我们已经获得了所有的token，但是它们没有排序。</sample>
    <sample id="1332">第二步中，我们使用另一个模型预测将其排列到正确顺序。</sample>
    <sample id="1333">我们引入了一种新的方法来预测一个排列，这种方法不对可能的排列施加任何硬约束。这使我们的方法非常灵活和表达式。</sample>
    <sample id="1334">概念上，我们的排列模型大致工作方式如下。</sample>
    <sample id="1335">我们从左到右遍历输出，并确定每个位置的多个token。对于第一个输出位置，我们简单地选择红色标记的那个。</sample>
    <sample id="1336">我们跳到下一个多个token以确定输出的第二个token。</sample>
    <sample id="1337">我们通过类似的方式确定输出中的第三个令牌，然后跳到另一个多个令牌中继续这个过程。</sample>
    <sample id="1338">直到第一个阶段中的每个令牌都被访问了一次。</sample>
    <sample id="1339">为了让您了解实验结果的前瞻，我们将与CONG的基准对我们的方法进行比较。我们的模型在更深的递归中 generalize的性能远远超过其他树形模型。</sample>
    <sample id="1340">一些结构化的通用化仍然很困难。</sample>
    <sample id="1341">我们在我们的论文中解决了一些有趣的技术挑战。</sample>
    <sample id="1342">首先，输入和输出的对齐不在训练数据中给出。因此，对于给定的token，我们不知道它来自哪个多细胞，这对训练造成了挑战。</sample>
    <sample id="1343">此外，有时候存在多个与数据相符的排列，但是语言正确的那个是隐含的。我们通过在训练中引入对齐来解决这个问题。</sample>
    <sample id="1344">我们的排列方法非常灵活，但是它带来了一个挑战，即找到最高分排列是NP困难的。这是因为这与旅行商问题相关。</sample>
    <sample id="1345">我们使用GPU友好的连续-relaxation方法来近似处理这个问题，同时也可以通过解决方案反向传播来学习更加语言上更加合理的排列。</sample>
    <sample id="1346">如果您想了解我们的实验结果和我们是如何解决这些挑战的，请查看我们的论文或来到我们的邮局。</sample>
    <sample id="1347">Cognitive dissonance is two beliefs or actions that are inconsistent.</sample>
    <sample id="1348">GPT-4.</sample>
    <sample id="1349">根据文本，累积训练（cumulative）在主动学习时可以等于或优于迭代训练（iterative）。</sample>
    <sample id="1350">Sara Pappi</sample>
    <sample id="1351">The data in the MuDa baseline is obtained from transcripts of TED Talks that have been translated from English to 14 different languages.</sample>
    <sample id="1385">Mathias Landemann</sample>
    <sample id="1386">Cross-lingual zero-shot and field-short transfer refers to training a model on one source language and then applying it to another language without additional training data.</sample>
    <sample id="1387">Salant University in Germany</sample>
    <sample id="1388">The author used two delay measurement methods:

1. Translation quality and average lagging
2. Computational aware average lagging</sample>
    <sample id="1389">"大家好，我是 Akshita，今天我和我的合作者 Martin 将展示我们的工作，评估来自多个来源的知识整合。这个项目是 McGill 大学、Miele 和微软研究机构的合作。"</sample>
    <sample id="1390">国家语言理解模型从多种知识来源中吸收知识，包括它们的参数中包含的知识，通常通过预训练获得，以及在推理时提供的知识。</sample>
    <sample id="1391">最近的任务，如问答任务，显示模型可以使用预训练的时间知识来解决任务。</sample>
    <sample id="1392">「自然语言理解通常需要在推理时获得的知识。」</sample>
    <sample id="1393">例如，在句子“约翰在电视上看到新当选的总统”。</sample>
    <sample id="1394">预训练的参数可能包含关于总统和电视的信息，但不能可靠地知道这个实例特定的实体约翰是谁或新任总统是，因为总统可能已经改变了自预训练以来。</sample>
    <sample id="1395">因此，对于知识密集型NLU任务的成功模型需要能够集成和使用预训练的时间知识和推理时间知识。</sample>
    <sample id="1396">本研究中，我们提出了知识集成的诊断测试套件。</sample>
    <sample id="1397">我们引入了一个核心引用解决方案，以测试不同来源可用的知识。我们使用人类研究部门和已建立的核心引用解决方案对数据进行评估。</sample>
    <sample id="1398">"我们从我们的数据集中提供一个示例。Serving是一个法官。Here是一个面包师。Serving和Kya在公园遇见了。法官一天在法庭上决策案件后，他高兴地放松了。"</sample>
    <sample id="1399">任务是确定代词“he”所指的正确实体，该实体是7。</sample>
    <sample id="1400">根据给定的名词需要两种信息的解释。首先是实体特有知识，如“奴隶”是一种 charge。其次是背景知识，如法官在法庭上决定案件。</sample>
    <sample id="1401">通常来说，背景知识是在大语言模型的预训练阶段学习的，而实体特定的知识通常是在推理时观察到的。</sample>
    <sample id="1402">我们将这两个信息的可用性变化，以便它们可能出现在单个来源中或多个来源中。</sample>
    <sample id="1403">我们已经定义了三种KITMOS设置。首先，我们需要设置背景预训练。背景知识假设在预训练时可用。</sample>
    <sample id="1404">第二，存在背景知识设置。背景知识在预训练时间和影响时间都可用。最后，背景影响设置。在影响时间中只有这两种知识类型可用。</sample>
    <sample id="1405">这个最后一个设置特别有趣，因为它模拟了一个情况，即解决任务所需的背景知识不在模型的预训练数据中，例如因为新的职业自预训练以来发展而出现。</sample>
    <sample id="1406">"这是我们控制真实来源可用的一个示例。"</sample>
    <sample id="1407">在背景预训练设置中，我们假设背景知识是政客寻求政府职位的背景知识包含在预训练参数中。在非频繁时间背景下，我们提供了反特定知识切斯特是政客。</sample>
    <sample id="1408">在背景运行设置中，我们还提供了非特定背景知识，同时也包括政治人物在影响子背景中的背景知识。</sample>
    <sample id="1409">背景中，在自由环境下，我们提供高效的职业，代替政治家，因为职业不太可能包含在预训练期中。</sample>
    <sample id="1410">我们对数据集进行了人类参与的评估和同位名词模型。 在这个图中，我们展示了背景预训练设置的最难变体中最好性能的模型结果。</sample>
    <sample id="1411">"使用KITMOS进行任务特定的训练，两个监控器的性能都很差。但是，当在KITMOS上进行训练时，C2F和BFQF的性能明显优于随机选择。"</sample>
    <sample id="1412">当使用Lushen数据集训练模型时，这表明模型会学习利用表面队列，这在测试时在KITMOS中没有用处，因为在KITMOS中已将这些队列去除了。</sample>
    <sample id="1413">额外的虚构知识实验表明，即使是性能最好的模型也不能可靠地集成仅在影响时间提供的反向知识。</sample>
    <sample id="1414">我们paper的主要结论是，许多coreference-to-volution模型在不同来源的知识上无法进行推理，除非进行任务特定的训练。然而，在进行任务特定的训练后，一些模型能够从多个来源中整合知识。</sample>
    <sample id="1415">“即使是最好的模型也似乎在推理时遇到难以可靠地整合反向知识的问题。如果您感兴趣，可以查看我们的论文并查看 GitHub 上的代码。感谢您的关注。”</sample>
    <sample id="1416">Based on the given English content, the limitations of tree-based methods are:

1. Obtaining trees can be complicated and computationally expensive.
2. It involves considerable formalism-specific pre-processing of logical forms.
3. Handling variable symbols can be challenging.</sample>
    <sample id="1417">According to the text, the author's name is Xu Heng, but the institution is not mentioned.</sample>
    <sample id="1418">"嗨，我是米拉，今天我将讨论我们的论文《标记人格》，使用自然语言提示来衡量语言模型中的ereotype。这个工作是与Essen Dermush和Dan Jerovsky合作完成的。"</sample>
    <sample id="1419">近年来，许多人已经记录了大型语言模型（LLMs）中存在的社会偏见和刻板印象。</sample>
    <sample id="1420">然而，这些措施都存在一定的局限性。它们通常依赖于手工构建的数据集，这些数据集需要花费很多时间来编辑。</sample>
    <sample id="1421">他们通常只测量非常特定的刻板印象，这意味着它们在其他群体或环境中不太好泛化，也只是捕捉到特定的、广泛的联系，如对某些群体的负面联系。</sample>
    <sample id="1422">此外，许多在这个领域的工作都没有考虑intersectionality，这是一个概念，即多重社会身份可以累积偏见并且是独特的伤害地点。</sample>
    <sample id="1423">为了克服这些限制，我们依靠这些 newer instruction tuned LLMs 对指令和提示的响应能力非常好。</sample>
    <sample id="1424">我们可以要求模型生成一个角色，这是一个关于想象的个体，使用提示，例如，像你是一个亚洲女性，描述自己。</sample>
    <sample id="1425">我们可以立即看到，这对任何人口统计数据都非常通用，因为我们可以将所需的身份标记输入到这个提示中。</sample>
    <sample id="1426">以下是 GPT-4 的一些示例生成结果。</sample>
    <sample id="1427">我们马上看到这些输出不是传统意义上的负面或毒性语言。</sample>
    <sample id="1428">有一些有趣的模式。</sample>
    <sample id="1429">[00:00:01 - 00:00:10]
亚洲女性被描绘成谦卑的。中东女性被称为异国风情，并将其描述为迷人的地区。</sample>
    <sample id="1430">两名非洲女性角色提到祖先，而白人男性角色没有这样做。</sample>
    <sample id="1431">为了捕捉这些模式，我们的方法有两个部分。第一个部分是生成这些人物。</sample>
    <sample id="1432">[00:00:01-00:00:12]
我们的灵感来自一项研究，其中他们将这些提示给人类受试，发现通过给人类受试也能够表面种族刻板印象。</sample>
    <sample id="1433">"这也使得我们生成的角色与人类编写的回应之间进行直接比较。"</sample>
    <sample id="1434">第二部分是标记词语，这是确定标记组与我们的标记组的区别的方法，我将很快详细解释。</sample>
    <sample id="1435">"这个好处是，我们可以获得非常具体的ereotype和模式，而不需要依赖特定的词汇。"</sample>
    <sample id="1436">根据社会语言学的标记概念，标记词法方法利用了标记的概念，即存在一个默认的未标记状态，而任何与该默认状态不同的群体都是语言上标记的。</sample>
    <sample id="1437">例如，词语“战士”通常与男性相关。因此，当人们描述女性战士时，他们通常会使用“男子战士”以强调女性。</sample>
    <sample id="1438">社交中的主要团体语言和社会地位都是未标记的，而被边缘化的团体通常是标记的。</sample>
    <sample id="1439">我们首先确定未标记和标记的组别。</sample>
    <sample id="1440">然后我们使用战斗词法方法将人格比较，这基本上是使用加权对数比率来区分每个标记组的主要词语。</sample>
    <sample id="1441">"例如，对黑人女性的角色，我们将使用战斗语言，并将法律对比率与白人和男性角色进行比较，因为这两个是对应的未标记组。"</sample>
    <sample id="1442">"然后，我们使用了一个语言词典，发现生成的角色中包含了更多的刻板印象，而不是人类编写的角色。"</sample>
    <sample id="1443">然而，我们实际查看词汇的分布时发现了非常不同的结果。</sample>
    <sample id="1444">"So，虽然生成的人物中有更高的luxon词频率，但是人类写的文字中词汇分布更加广泛，而生成的人物中出现的刻板印象词语只是高和 athletic两个词语。"</sample>
    <sample id="1445">"只列出积极或至少非负的结果。"</sample>
    <sample id="1446">实际上，Sexycon并不能捕捉到早期幻灯片中看到的许多有害模式。因此，我们将转到标记词语方法的结果，以展示这些看似积极的词语如何促进刻板印象和必然化的叙述。</sample>
    <sample id="1447">我们的分析中揭示这些看似积极的描绘反映了有害的模式。</sample>
    <sample id="1448">首先，对于标记群体，主要的词汇包括文化、传统、自豪和异国风情等。这些词汇仅仅是根据这些群体与他们的身份关系来定义它们，并将它们与白人标准区分开。</sample>
    <sample id="1449">这对这些群体造成了长期的歧视和他者化。</sample>
    <sample id="1450">此外，这些词汇中也反映了许多常见的刻板印象，特别是对有色女性。例如，对拉丁美洲女性的描述词汇中包括如“夺目”和“曲线美”。</sample>
    <sample id="1451">[00:00:01 - 00:00:06] 

她说：“那些词语连接到热带主义。对于亚洲女性来说，这些词语是如小巧、细腻和柔软的。"</sample>
    <sample id="1452">[00:00:01 - 00:00:07]
女性被hypersexualized的历史始终连接着亚洲女性被视为非常温顺和顺从等形象。</sample>
    <sample id="1453">最后，我们看到黑人女性中一些最常出现的词语是强大和坚强。</sample>
    <sample id="1454">[00:00:01 - 00:00:08]
这与人们所称的强黑人女性原型相连。虽然在第一眼看起来好像是积极的，但</sample>
    <sample id="1455">「研究表明，这种架构实际上对这些人群施加了很大的压力，要求他们在面临社会障碍时保持坚强和坚韧。」</sample>
    <sample id="1456">因此，而不是实际地努力改变这些障碍，它们对这些人施加压力，这导致这些人出现了许多不良健康结果等其他不良后果。</sample>
    <sample id="1457">我们发现，每个标记组的词语基本上只是反映非常基本的叙事。</sample>
    <sample id="1458">根据这些模式，我们对模型所有者提出了三个建议。</sample>
    <sample id="1459">首先，我们作为研究人员，应该address正面的ereotype和essentializing narratives。我们还应该使用intersectional lens来研究偏见和伤害，因为如果我们不这样做，可能会忽视许多事情。</sample>
    <sample id="1460">最后，应该有更多关于偏见减少方法的透明度。</sample>
    <sample id="1461">因为例如，这些正面刻板印象我们不知道是否是因为某种奇怪的原因。</sample>
    <sample id="1462">"存在过度的价值观 alignment 或许是某些反ereotype 方法导致这些不良模式。"</sample>
    <sample id="1463">我们不能对此做出任何假设或进行更深入的研究，需要更多的透明度。</sample>
    <sample id="1464">"感谢您倾听。祝您度过愉快的时间。"</sample>
    <sample id="1465">"大家好，我是中国科学技术大学的靖伟易。"</sample>
    <sample id="1466">我很高兴为您提供关于纸张的短视频广告。您是否复制了我的模型？保护大型语言模型的嵌入式服务的版权。查看后门水印。</sample>
    <sample id="1467">"让我们首先介绍我们的服务邀请背景。"</sample>
    <sample id="1468">当前，类似GPT、Lama和Palm的大型语言模型在自然语言理解和生成方面表现出众。</sample>
    <sample id="1469">"将服务嵌入是基于大语言模型的一种服务，旨在协助多种NLP任务。"</sample>
    <sample id="1470">例如，我们可以打开我们的优惠活动或GPD基于batting API。</sample>
    <sample id="1471">然而，最近的研究表明攻击者可能通过学习嵌入学习和提供相似服务。因此，保护嵌入的版权是必要的。</sample>
    <sample id="1472">为了保护嵌入服务的版权，一种解决方案是将水印嵌入服务 provider，并检测另一个服务是否包含水印。</sample>
    <sample id="1473">"水印方法需要满足以下属性。首先，这种方法应该适用于嵌入服务。其次，水印不应该降低嵌入提供的实用性。"</sample>
    <sample id="1474">第三，水印应该对攻击者隐藏到足够程度，以免攻击者可以轻松删除水印。</sample>
    <sample id="1475">最后将水质被转移到攻击者的服务中，以便在模型提取过程中使用。</sample>
    <sample id="1476">「已有的作品可以被广泛分为四个类别。」</sample>
    <sample id="1477">然而，这种方法对嵌入服务来说不可行或缺乏可移植性。</sample>
    <sample id="1478">因此，在本文中，我们提出了一种嵌入标记方法，这是一种基于后门的水印方法，适用于嵌入服务。</sample>
    <sample id="1479">"然后，让我介绍一下我们的嵌入标记。嵌入标记包含两个主要步骤，水印注入和版权验证。"</sample>
    <sample id="1480">在这些主要步骤之前，我们首先选择一个触发集。触发集是一组在中等频率间隔中的单词。</sample>
    <sample id="1481">我们假设提供商可以收集通用文本语料库，并对词频进行计数。</sample>
    <sample id="1482">在水印注入中，我们首先定义一个目标 bedding。當用户将句子发送到服务提供商时，服务提供商会在句子中计数触发器的数量。</sample>
    <sample id="1483">该嵌入是目标嵌入和原始嵌入的加权和。</sample>
    <sample id="1484">根据句子中的触发器数量，目标投注的权重是成比例的。当句子中的触发器数量大于 m 时，提供的嵌入式等于目标投注。</sample>
    <sample id="1485">"版权验证是检测另一个服务背后的模型是否包含商标。"</sample>
    <sample id="1486">我们首先构建一个后门和一个良性数据集。后门数据集中的所有句子都是由触发词组成的，而良性数据集中的所有句子都不包含触发词。</sample>
    <sample id="1487">然后，服务提供商需要从Stealer服务获取嵌入物的数据集。</sample>
    <sample id="1488">在计算请求的嵌入和目标嵌入之间的余弦相似性和L2相似性。我们计算无标签和后门数据集之间的相似性差异，这被定义为delta余弦和delta L2。</sample>
    <sample id="1489">在此同时，我们还应用KSTest，并将其p值作为第三个指标。</sample>
    <sample id="1490">我们对四个数据集进行实验，即AG News、Mind、SSD2和AresVam。我们假设使用wikitext数据集来计数词频。</sample>
    <sample id="1491">四个数据集的结果表明，我们的嵌入标记可以在保持下游任务的同时具有出色的检测性能。</sample>
    <sample id="1492">我们也验证了提供的嵌入的隐蔽性，通过在四个BOPCA数据集上可视化句子嵌入。图例表示每个句子中的触发器数量。</sample>
    <sample id="1493">根据图表，区分背后嵌入和正常嵌入变得很困难。</sample>
    <sample id="1494">"那就够了，感谢。我们下次再讨论。"</sample>
    <sample id="1495">ABC-Eval 代表"annotating behaviors in chat"，即对聊天行为的注释方法。</sample>
    <sample id="1496">The text does not mention the specific year when the performance increment of CoNLL-2003 and CoNLL++ exceeds 5%.</sample>
    <sample id="1497">[00:00:01 - 00:00:18]
我是 Vasudha，斯通布鲁克大学计算机科学博士候选人。我想介绍我们在 ACL 2023 上接受的长篇论文，我们的工作是关于基于转移学习的不和谐检测，解决稀有类别挑战。</sample>
    <sample id="1498">我们从定义认知不协调开始，并解释为什么它是一个需要在语言中研究的问题。简单来说，认知不协调是两个不一致的信念或行为。</sample>
    <sample id="1499">如同这个例子，某人说“我知道-cigarette可能会杀了我”，然后继续说“我在会议后抽了一两根烟”。这种信仰和行为不一致，存在距离。</sample>
    <sample id="1500">我认为我不能不依靠他们，我认为我不能失去工作，这也正正了第二次出现的原因，他们有着稳定的关系。</sample>
    <sample id="1501">「不协和是我们日常决策中非常常见的现象，但是在语言中表达的机会却很少，其他风险摆荡的表达也很少见。」</sample>
    <sample id="1502">所以，这个问题为什么重要？从认知距离出发可以帮助我们理解不同人之间的不同看法、跟踪群体中的趋势和价值观念和态度的变化。</sample>
    <sample id="1503">高认知不一致也与焦虑障碍相关，可以帮助更好地理解人们的_mental_health。</sample>
    <sample id="1504">研究语言中的距离概念对理解极端化和脆弱群体的极化也非常有益。</sample>
    <sample id="1505">最终，认知不协和对个人认知风格和个体决策过程的理解非常重要。</sample>
    <sample id="1506">为了实现认知不协调资源，我们进行了大规模的注释不协调关系。我们使用了不协调的第一种方法，如流程图中所示。</sample>
    <sample id="1507">使用PDTB解析器，tweets被标注为根据我们的论文中描述的指南对话单元对。</sample>
    <sample id="1508">可以看到，这里只有3.5%的注释对中发现了不和谐。</sample>
    <sample id="1509">我们收集了1000个discourse unit对，并对仅有43个disnets的初始分类器进行了训练。毫无 surprise，分类器的性能与随机差不多。</sample>
    <sample id="1510">由于低频率的不协和音和缺乏相应的数据集，我们面临着绝对稀有问题。</sample>
    <sample id="1511">为了减少这个问题，我们通过组合transfer learning和active learning来注释，以便在较少的注释运行中收集更多的不协和样本，从而降低总体注释成本，同时提高不协和检测能力。</sample>
    <sample id="1512">自从初始模型无法捕捉到不协和类别，我们从相关任务中将权重转移以启动active learning过程。</sample>
    <sample id="1513">我们从两个不同任务转移到了一个独立的任务，即距离分类任务，该任务旨在根据不同人发表的两个辩论语句，判断它们是否相符或不同，不考虑主题。</sample>
    <sample id="1514">：在这里和二元分类扩展和比较PNTB的辩论。由于这两个概念与元音和不协和的概念紧密相关，我们在这里称之为CE。</sample>
    <sample id="1515">我们发现，在将零短期性能应用到注释数据集上时，已经优于随机猜测，AUC为0.62。</sample>
    <sample id="1516">进一步地，在对两个任务进行迭代微调后，我们发现微调CE任务后再次微调可以获得更好的零_shot性能。因此，这是我们使用的活动学习的模型。</sample>
    <sample id="1517">下一个，我们确定更新模型以从每轮活动学习和注释中获取新的数据的最佳方法。累加器累积了到目前为止从活动注释中收集的所有数据，而迭代更新模型是通过在最新的数据集上进行训练。</sample>
    <sample id="1518">我们发现累积策略在所有方面都与迭代策略相比，性能相同或更好。</sample>
    <sample id="1519">下一个，为了提高不协和例子的数量，我们使用概率稀有类策略PRC选择大多数可能在当前模型任何轮次中高度不协和的示例。</sample>
    <sample id="1520">我们将其与社区中常用的其他先进AL策略进行比较。</sample>
    <sample id="1521">我们发现该PRC策略比其他最先进的策略效果更好，尽管差异较小。注意，随机策略的性能明显低于其他策略。</sample>
    <sample id="1522">进一步的AL迭代中，我们使用了两个最佳策略，距离分类AUC提高到了2.75，这是我们迄今为止在该任务中取得的最好成绩。</sample>
    <sample id="1523">我们还检查了每种策略在注释质量和标注员成本方面的可行性。我们发现，PRC在稀有类别中有最高的不协调率，也是最适合的策略，但是标注员们也认为这些示例很难。</sample>
    <sample id="1524">总的来说，我们发现 PRC 是一种简单的 AIL 策略，用于稀有类别的获取，并且使用适当的转移学习任务可以明显地帮助。</sample>
    <sample id="1525">我们还发现，迭代更新对于从不同领域的迁移学习非常有用，而在同领域的积极标注则益于累积更新。</sample>
    <sample id="1526">这些是我们的代码、数据集和论文的链接。欢迎随时与我们联系，如果您有任何问题。感谢。</sample>
    <sample id="1527">Matthias Lendemann</sample>
    <sample id="1528">Si Yu-Yuan.</sample>
    <sample id="1529">4</sample>
    <sample id="1530">The method compared with the state-of-the-art architecture specifically tailored for steam-on-thigh-respirations translation.</sample>
  </task>
</testset>