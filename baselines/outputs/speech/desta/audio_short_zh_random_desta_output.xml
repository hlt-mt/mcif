<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">Language models are trained on large-scale web crawl data, with political news media well covered in their pre-training data.</sample>
    <sample id="1">McGill University, Miele, Microsoft Research.</sample>
    <sample id="2">"欢迎来到DePlain的介绍，DePlain是一款用于德语文本识别的新型数据集，涵盖文档级别和句子级别。"</sample>
    <sample id="3">我收到了一段英文语音内容，内容是Regina Storben介绍了文本简化的定义。</sample>
    <sample id="4">根据英文内容，文本通知是为了适应特定目标群体的阅读能力或非母语人士，改进文本的可读性。</sample>
    <sample id="5">为了训练文本通知模型，我们需要平行对的文本对，例如文档或句子对。</sample>
    <sample id="6">在这个示例中，您可以看到一个复杂的德语句和它的简化语言翻译。</sample>
    <sample id="7">为了简化句子，可以使用不同的技术，如在例子中所示，例如词汇替换、句法重组、词序重排或插入词语。</sample>
    <sample id="8">我们现在提出了一個新的文本庫D-plane。近年來，現有的文本庫出現了一些問題。例如，這些文本庫太小，無法訓練文本通知模型。</sample>
    <sample id="9">她最近提出的三个模型都自动对齐，这意味着它们在对齐时可能存在错误。</sample>
    <sample id="10">因此，我们提出了一个新的语料库Deplane，它被分为两个子语料库，分别是Deplane APA和Deplane Web。Deplane APA基于新闻文本。</sample>
    <sample id="11">在APA格式中，我们手动对齐了483份文件，结果产生了约30,000个13,000个平行句对。</sample>
    <sample id="12">她正在描述一个深度学习网络的文本集，这个集包含了不同的领域的文档，并且将750个文档在人工和自动方法上进行了对齐。</sample>
    <sample id="13">总共产生了30,450个句子对。</sample>
    <sample id="14">我们对句子对进行更深入的分析。例如，我们来看一下简化的类型。</sample>
    <sample id="15">根据语音助手的记录，这段语音内容是：

“可以看到这里的圣经文本比新闻文本或语言学习文本要强烈简化。”

中文翻译：这里的圣经文本比新闻文本或语言学习文本要简化得更加强烈。</sample>
    <sample id="16">根据提供的英文内容，可以将其翻译为：

在所有层面上，例如词汇简化、结构简化，也是总体简化方面。</sample>
    <sample id="17">我们可以看到，Deplaned corpus 中有很多不同的简化变换。例如，在 Deplaned API corpus 中，我们有更多的重新排列和单词编辑，而在 Deplaned Web corpus 中则较少。</sample>
    <sample id="18">在网页语料中，我们拥有更多简短的评分。</sample>
    <sample id="19">Omar打算探讨数据集Dplane的应用场景，第一个场景是评估自动对齐方法。</sample>
    <sample id="20">近年来，在机器翻译领域有了很多alignment方法。</sample>
    <sample id="21">我们有两个不同语言的文档，我们想从中提取同义句子对齐结果。</sample>
    <sample id="22">他在使用场景中，我们试图从两个具有相同语言、相同内容但不同复杂度的平行文档中提取句子对齐。</sample>
    <sample id="23">现在，我们已经有了手动对齐的句子集Dplane，可以使用这些句子作为金标准对齐结果来评估一些提议的对齐方法。</sample>
    <sample id="24">他们对原来的方法进行了一些修改，并将这些修改和运行实验的代码都发表在论文中。</sample>
    <sample id="25">结论是，我们确定了对德语文本简化的最佳自动对齐方法是大规模对齐方法。</sample>
    <sample id="26">可以在论文中找到该方法的代码，并在自己的文档中运行。</sample>
    <sample id="27">他在论文中展示的第二个用例是自动文本简化。</sample>
    <sample id="28">根据语音assistant，您提供的英文内容是：

"by fine-tuning language models to produce simplified text from the complex input text."

中文表述：通过调整语言模型以生产来自复杂输入文本的简化文本。</sample>
    <sample id="29">我们已经对两个模型进行了微调。我们已经微调了一种长篇幅的模型，以生产文档级别的简化版本。</sample>
    <sample id="30">我们也对基础导入进行了调整，以生成句子级简化。</sample>
    <sample id="31">你也可以查看所有检查点，并在论文中查看实验的详细信息和评估指标。</sample>
    <sample id="32">根据基本的调整，可以产生或获得比基线分数更好的结果。</sample>
    <sample id="33">我们建议将这些结果作为未来的自动文本简化问题的基准。</sample>
    <sample id="34">"感谢您的关注，我们希望在会议上见到所有人，谢谢。"</sample>
    <sample id="35">Kaio Yan.</sample>
    <sample id="36">T5x large model.</sample>
    <sample id="37">Yes.</sample>
    <sample id="38">The novel aspect of the proposed evaluation method is that it attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response exhibits certain behaviors, such as providing irrelevant information or contradicting itself.</sample>
    <sample id="39">Weakly-supervised learning methods' success is largely dependent on clean validation samples.</sample>
    <sample id="40">Based on the provided context, it seems that the speaker is referring to an assessment or a test. To improve scores, you can take the following measures:

1. Review and study the material thoroughly.
2. Practice and familiarize yourself with the format and types of questions.
3. Focus on your weaknesses and improve your understanding of those areas.
4. Manage your time effectively during the test.
5. Stay calm and composed while taking the test.</sample>
    <sample id="41">4</sample>
    <sample id="42">"嗨，我是Adam Szpirkowski，这个讨论是关于协调结构的依赖关系。"</sample>
    <sample id="43">“您可能知道，理论和语料库方法中假设的依赖结构不同。例如，在通用依赖结构中，Lisa、Bart和Maggie的结构是这样一种结构。”</sample>
    <sample id="44">“Lisa是整个坐标结构的主语，首个conjunct就是整个坐标结构的头，所以在这个情况下是Lisa。”</sample>
    <sample id="45">伊戈尔·米尔图克的含义文本理论中也有相似的方法，那就是整个坐标结构由第一个conjunct引导。因此，这两个方法是对称的，他们都选择了其中的一个conjunct。</sample>
    <sample id="46">现在，还有对协调结构的对称方法，如布拉格方法、连词头方法，假设不可实际的依赖树银行，其中协调结构由连词头领导。</sample>
    <sample id="47">我们从所有连接词中获取依赖关系。</sample>
    <sample id="48">最后还有一个多头方法，例如Cutson的Word语法中使用。</sample>
    <sample id="49">“说来话，所有的行为都是坐标结构的头部。因此，我们从总督下面获取依赖关系，他允许所有行为单独进行。这是巴顿的成就。”</sample>
    <sample id="50">现在，这篇论文的目标是为协调结构的新论点，如这两个，反对非对称协调结构，如这些。</sample>
    <sample id="51">好的，以下是翻译结果：

“好的，让我们根据依赖关系最小化的原则来讨论这个问题，这些示例都是基于这个原则的。”</sample>
    <sample id="52">在英语中，你可能知道，直接宾语喜欢与动词近邻，而副词可能位于更远处。因此，March 读它昨天是可以的，因为直接宾语位于动词附近。</sample>
    <sample id="53">“昨天读的书比昨天更糟糕，是因为在动词和直接宾语之间有一个副词昨天。”</sample>
    <sample id="54">然而，这种效果可能可以通过模拟实现，当直接对象非常重且非常长时，因为在这种情况下，可以将其移动到代理的位置。</sample>
    <sample id="55">这是这里所示的。所以，这两个句子都是正确的。《March Redd》是一个非常有趣的关于BCS的书籍。我是可以的。相比之下，我们有这个长的NP。</sample>
    <sample id="56">但是说昨天March也可以。关于和平有一个非常有趣的书。</sample>
    <sample id="57">因此，这是可能的，因为，即使这个句子违反了总体语法原则，即直接宾语应该与动词相邻。</sample>
    <sample id="58">它满足依赖关系最小化原则，这个原则认为较短的依赖关系是优先的。</sample>
    <sample id="59">这两个树只显示了关键依赖的长度，即这两个结构中不常见的依赖项。</sample>
    <sample id="60">我们这里有一个来自“红”的依赖关系，长度为七个词语的附加项，以及来自“红”到“书”的长度为四个词语的依赖关系。因此，总共是11个词语。</sample>
    <sample id="61">当你交换这两个成分时，这两个依赖项的总和变为六个，这比之前的11和六个要短得多，这是为什么这听起来很合理的原因。</sample>
    <sample id="62">我们从 Pantry Bank 的增强版本中提取了关于协调的多个统计数据，了解我们为什么没有使用大学依赖关系。</sample>
    <sample id="63">“统计数据也证实了很多前人所观察到的结论：左对立的词语 tended to be shorter。所以，salt 和 pepper 和 salt 在音节上是平衡的。”</sample>
    <sample id="64">“也就是说，人们也注意到随着长度的差异，这种趋势会增长。”</sample>
    <sample id="65">当两个conjuncts之间的长度差异增加时，较短的conjuncts更喜欢被第一个conjuncts强调。因此，左侧较短的conjuncts的比例变得更大。</sample>
    <sample id="66">但是，这篇论文中最novel的是，我们发现只有当左翼政府出现时，这种趋势才会发生。</sample>
    <sample id="67">好吧， governor在这个例子中在左边，我看到Lisa Barton。所以，总督在左边。</sample>
    <sample id="68">霍默在第二个例子中出现了，霍默来了一下，咳嗽了，在这里有两个动词的协调，但是没有外部管辖权，所以在这种情况下，左连接词更喜欢更短，尤其是两个连接词之间的差异越大。</sample>
    <sample id="69">然而，当右翼政府在位时，左翼就控制着协调Telnet，这种效果消失了。</sample>
    <sample id="70">我们证明了通过测量字符长度，第一个列是音节，中间列是，右列是单词。我将集中于右列。</sample>
    <sample id="71">我们这里看到的是左边的治理。</sample>
    <sample id="72">左邻字的长度趋势不断增加绝对词语差异。但是，在句子协调中没有主管时，这种趋势仍然存在，但是当主管在右侧时，这种趋势消失。</sample>
    <sample id="73">我们在论文中展示了这种结构对抗对称协调结构的论证，同时为对称结构提供了论证。</sample>
    <sample id="74">"请查看完整的协议和argument，sorry，讨论一下poster会话，感谢。"</sample>
    <sample id="75">2</sample>
    <sample id="76">The simplified degree is greater in Bible texts compared to news texts or language learner texts.</sample>
    <sample id="77">Left conjuncts tend to be shorter.</sample>
    <sample id="78">Yes, you can use these pre-trained models for your research.</sample>
    <sample id="79">DEplain-APA is based on news texts.</sample>
    <sample id="80">According to the conversation, the factors that contribute to good generalization are:

1. A better model architecture
2. Larger model size
3. More fine-tuning examples</sample>
    <sample id="81">According to the text, the author measures the length of the left column in syllables.</sample>
    <sample id="82">Measure the length of sentences in characters, words, and syllables, and analyze the relationship between the absolute difference in words and the tendency for the left conjunct to be shorter.</sample>
    <sample id="83">The baseline classifier performed not much better than chance.</sample>
    <sample id="84">1</sample>
    <sample id="85">Bob and Alice.</sample>
    <sample id="86">According to the text, context-over-models are significantly more accurate than models that do not use context for certain discourse phenomena, such as formality and lexical cohesion.</sample>
    <sample id="87">The authors of the paper "Language Model Acceptability Judgments Are Not Always Robust to Context" are affiliated with multiple institutions, which are not specified in the given text.</sample>
    <sample id="122">The framework quantifies bias by re-annotating datasets with diverse annotators to collect a rich set of demographic data, and then comparing the annotations by demographic to the models and datasets.</sample>
    <sample id="155">They surfaced racial stereotypes.</sample>
    <sample id="156">The research used the Pantry Bank data and a paper.</sample>
    <sample id="157">1</sample>
    <sample id="158">According to the text, the tasks closely related to cognitive dissonance are:

1. Independent dissonance stands classification
2. Binary classification of expansion and comparison classes of PNTB
3. CE (conception of consonance and dissonance)</sample>
    <sample id="159">1</sample>
    <sample id="160">1</sample>
    <sample id="161">The introduced framework differs from previous annotator disagreement literature by comparing end users with models, data sets, predictions, and labels, whereas previous studies focused on annotator agreement or modeling annotator distributions.</sample>
    <sample id="162">According to the audio, the first setting, "generated personas", has the most overlap with stereotypes.</sample>
    <sample id="163">The model compared different commercial systems with Google Translate.</sample>
    <sample id="164">这位Xiangbin是华盛顿大学的博士生，他今天将分享从预训练语言模型到下游任务的研究结果，探索政治偏见在NLP模型中的踪迹，旨在探索不公平NLP模型的来源。</sample>
    <sample id="165">语言模型是基于大规模网络爬虫数据进行训练的。</sample>
    <sample id="166">根据语言模型的训练数据，我们可以看到，政治新闻媒体，如纽约时报、洛杉矶时报、卫报、赫芬顿邮报等，已经被充分涵盖在训练数据中。</sample>
    <sample id="167">这是对语言模型应用的双重 bless。</sample>
    <sample id="168">他们能够从多种角度学习，这体现了民主和思想多样性。但是，这些不同的政治观点本身具有社会偏见，可能会在下游任务应用中引发公平性问题。</sample>
    <sample id="169">"我们计划调查从预训练数据到语言模型到下游任务的政治偏见传播管道，以回答以下问题。"</sample>
    <sample id="170">他人问到如何评估政治线性语言模型和这些模型中可能存在的偏见，可能是指的是评估这些模型在生成政治相关语言时是否存在偏见和不公平。</sample>
    <sample id="171">「第二点是，政治敌手不同的语言模型在下游任务中如何表現，以及这是否可能导致NLP应用中的公平性问题。」</sample>
    <sample id="172">我们建议使用政治问卷，例如政治指南测试，来对语言模型进行不同格式的提示。这确保了我们对语言模型的自动评估是基于政治学文献的。</sample>
    <sample id="173">某些初步结果表明，语言模型具有多样化的政治涵义，它们占据了政治指南的所有四个象限。</sample>
    <sample id="174">我们可以看到，GPT-4是所有语言模型中最自由主义的，而GPT系列通常比BERT系列和其变体更自由。</sample>
    <sample id="175">他第二步是调查语言模型在训练数据中是否真的吸收了政治偏见。</sample>
    <sample id="176">我们可以通过将语言模型在六个具有不同党派倾向的新闻和社交媒体数据集中进行额外的预训练，以进行控制实验。</sample>
    <sample id="177">通过对Kodpora中的语言模型进行进一步的预训练，可以看到语言模型的意识形态坐标也相应地发生变化。</sample>
    <sample id="178">例如，对于Robert，进一步在左线线性redded语料库中训练，我们可以看到它在政治立场上出现了明显的左倾shift。</sample>
    <sample id="179">他对政治偏见的看法。</sample>
    <sample id="180">我们也尝试研究语言模型是否能捕捉到现代社会中存在的极化趋势。</sample>
    <sample id="181">将预训练语料库分为美国前45位总统之前和美国45位总统之后的两个时间段，然后对这两个不同时间段的语料库分别进行预训练语言模型。</sample>
    <sample id="182">语言模型在2017年后开始偏离中心，表明语言模型也能够捕捉到社会的极化趋势。</sample>
    <sample id="183">最后，我们评估了不同政治含义的语言模型在检测仇恨言论和假新闻检测等 NLP 应用中的性能，这些应用通常涉及语言模型并且可能具有非常大的影响。</sample>
    <sample id="184">他说：我们看到，如果我们调查每个类别的表现，那就是说，如果我们将表现分解成不同的类别时。</sample>
    <sample id="185">不同种类的语言模型在不同的人口统计学或政治新闻媒体中，我们可以看到一个模式，例如，左倾语言模型在检测仇恨言论方面更好。</sample>
    <sample id="186">他在检测针对社会少数群体的仇恨言论。</sample>
    <sample id="187">「我们正在检测社会中更强大的团体，然而我们的工作。」</sample>
    <sample id="188">「对白人和男性进行的仇恨言论，语言模型更擅长检测；而对黑人、LGBTQ+和其他少数群体进行的仇恨言论，语言模型检测能力较差。」</sample>
    <sample id="189">类似的趋势也出现在虚假新闻检测中，我们看到左倾语言模型更擅长检测来自不同政治立场的虚假信息，而右倾语言模型也能更好地检测来自相反政治立场的虚假信息。</sample>
    <sample id="190">他正在展示许多例子，以证明具有不同政治含义的语言模型。</sample>
    <sample id="191">他将根据社交类别给出不同预测结果，对仇恨言论和虚假信息。</sample>
    <sample id="192">这段录音中，男性语音助手说：「这是一个非常迫切的问题，涉及语言模型的政治偏见问题。」</sample>
    <sample id="193">如果语言模型在训练数据中包含仇恨言论或错误信息，并将其部署到流行社交媒体平台上。</sample>
    <sample id="194">这意味着，如果人们拥有不同政治观点的人可能会被边缘化，而针对少数群体的仇恨言论可能会肆无忌惮地存在，无法受到控制。</sample>
    <sample id="195">他说，这是一个提醒我们注意和解决由语言模型带来的政治含义公平问题。</sample>
    <sample id="196">布莱恩·卡比（Blayke）说了一些话，强调了语言模型政治偏见的独特难题，类似于Cilla和Karebdis之间的讨论。</sample>
    <sample id="197">如果在语言模型训练数据中不对政治观点进行消毒，那么偏见将从预训练数据传播到语言模型中，并最终影响下游任务，导致公平性问题。</sample>
    <sample id="198">如果我们尝试去污染语言，我们也可能会遇到审查或排除的问题。同时，确定哪些语言是中立的，应该保留语言监控数据变得非常困难。这种情况类似于“电磁肖图”问题。</sample>
    <sample id="199">这个人说了几句话，内容是他认为已经说完了所有要说的了，感谢对方的时间。</sample>
    <sample id="200">1</sample>
    <sample id="201">According to the transcript, MPP judgments are relatively stable up to a context length of 1024 words.</sample>
    <sample id="202">Based on the audio text, it appears to be a sequence of the Persian phrase "از از از از از" repeated multiple times, which doesn't provide any meaningful information. Therefore, I cannot identify any specific domains or fields in the data.</sample>
    <sample id="203">Positionality refers to the perspectives that people hold as a result of their demographics, identity, and life experiences.</sample>
    <sample id="204">Dawei.</sample>
    <sample id="205">Yes, the solution uses existing offline SD models without retraining or adopting specific architecture for a single SD.</sample>
    <sample id="206">1</sample>
    <sample id="207">不能。</sample>
    <sample id="208">KITMUS has three variants: background pre-trained, background both, and background influence.</sample>
    <sample id="209">The authors' institution is not explicitly mentioned in the given text.</sample>
    <sample id="210">The last research question is: "Should we only use the clean samples for validation or are there better ways to utilize them?"</sample>
    <sample id="211">指标灵敏度测量模型对同一任务的输出结果是否一致，且不受指令词汇的轻微变化影响。</sample>
    <sample id="212">Jingwei Yi</sample>
    <sample id="213">The higher sensitivity in this context indicates that the model's performance has improved.</sample>
    <sample id="214">The model will receive a sentence with the format: "There's a joint work with [list of names]."</sample>
    <sample id="215">20</sample>
    <sample id="216">Essen Dermush and Dan Jerovsky.</sample>
    <sample id="217">Because language models can have varying political meanings, it's necessary to develop new methods to measure media bias.</sample>
    <sample id="218">Akshita.</sample>
    <sample id="219">According to the text, the political bias propagation pipeline refers to the process by which political biases present in pre-training data are transmitted to language models and potentially affect their performance in downstream tasks.</sample>
    <sample id="220">Yes, the DEplaned API corpus and Web corpus have different simplification processes.</sample>
    <sample id="221">No, it seems that the information provided does not explicitly state whether the T file function is publicly available or not.</sample>
    <sample id="222">In watermark injection, the watermark is inserted by defining a target embedding and combining it with the original embedding. The target embedding is weighted based on the number of triggers in the sentence, and when the number of triggers exceeds a certain threshold (m), the combined embedding becomes equal to the target embedding.</sample>
    <sample id="223">Penn State University</sample>
    <sample id="224">Yes, the encoder-decoder model like MT5 can be improved by training in a mixture of various languages.</sample>
    <sample id="225">Planning for making a chocolate cake with specific goals and constraints is an example of a constrained language planning task.</sample>
    <sample id="226">They validated the covertness of their method by visualizing the embedding of sentences on four dataset VOPCA.</sample>
    <sample id="227">The research explores how to build a new PLM using existing PLMs by introducing three model trains on continental pre-training to analyze the impact of pre-training strategy.</sample>
    <sample id="228">According to the text, GPT-4's social acceptability analysis is most aligned to Confucian and English-speaking countries, but it doesn't explicitly mention which country or region it is least aligned to.</sample>
    <sample id="229">The speaker is referring to the example on the "right" (not shown in the text), but according to the text, the example is not provided. However, the speaker mentions "the attention mechanism between audio input and textual output, that is the cross-attention mechanism" as a way to leverage the knowledge already acquired by the model.</sample>
    <sample id="230">As the number of tasks increases, the model achieves better performance and lower sensitivity.</sample>
    <sample id="231">According to the text, the author compares their method with three tree-less models on the Coggs benchmark.</sample>
    <sample id="232">The two co-authors, Alexander Kodler and Yvon Titov, are advisors of the first author.</sample>
    <sample id="233">The first author of PaLM is not mentioned in the given text.</sample>
    <sample id="234">"嗨，每个人，我是卡内基梅隆大学的第一年博士生珍妮，我今天将为你介绍我们的研究作品，基于CSA数据集的模型设计。"</sample>
    <sample id="235">"这个工作是在与华盛顿大学和 Allen Institute for AI的某些人合作完成的，包括 Sebastian Santy、Ronan LaBros、Katarina Aranica 和 Martin Sapp。"</sample>
    <sample id="236">让我们假设你正在工作的报纸中，您正在浏览新闻文章下的评论，以删除有毒内容。</sample>
    <sample id="237">你可能会转向一个流行的API，如Toxic City Detection的Perspective API。对于Carl Jones来说，这个API检测毒性实例的效果非常好。</sample>
    <sample id="238">但是，对于一位女性，关于 dithya-sharma 的说法，并不是真的对潜在的 API 真的不太敏感到常见于印度语境中的不良词语。</sample>
    <sample id="239">这是一个设计偏见的例子，我们在不同人群中看到技术性能的系统差异。</sample>
    <sample id="240">根据研究人员和模型开发者的立场可能会出现类似于我们刚刚看到的偏见。立场只是由于个人特征、身份和生活经验而形成的人的观点。</sample>
    <sample id="241">这是一个广泛用于批判性研究领域，特别是在女权和queer学术空间中的概念。</sample>
    <sample id="242">作为一名研究员，位置性质可以影响研究过程和结果，因为它可以改变研究员的决策。</sample>
    <sample id="243">"人们可能会问的是，数据集和模型是否具有位置性？"</sample>
    <sample id="244">我们不想说模型本身和数据集本身拥有人口学身份和生活经历，但是它们可以聚合实际人士的判断和看法，从而代表某些立场对其他立场。</sample>
    <sample id="245">「前人的研究中有关于位置性（positivity）的某些非实证证据，如模型和数据集中的文化差异，以及模型位置性的理论定义。」</sample>
    <sample id="246">然而，这些作品实际上并没有比较用户与数据集和模型本身。</sample>
    <sample id="247">"随着 NLP 任务变得越来越多样化和社会化，模型和数据集的位置性变得越来越重要。"</sample>
    <sample id="248">"这些位置性质很难被描述，因为不是所有的决策都是记录的，许多模型都隐藏在API后面。"</sample>
    <sample id="249">为了研究数据集和模型的位置，我们实际地将注释与现有数据集和模型进行比较。</sample>
    <sample id="250">我们通过我们的NL Positionality框架来实现这一点。</sample>
    <sample id="251">我们的框架工作在两个主要步骤中。</sample>
    <sample id="252">首先是将数据集重新标注，以使用多个注释员。</sample>
    <sample id="253">我们选择不考虑原始数据集的-demographics，因为通常只有少数的标注者标注每个实例，并且 demographics很少被收集和共享。</sample>
    <sample id="254">我们选择重新分析数据，以获取多个实体和丰富的人口统计数据。</sample>
    <sample id="255">我们然后将注释根据人口统计学特征与模型和数据集进行比较，以对比我们的相关分数。</sample>
    <sample id="256">因此，我们的框架不同于注释者不一致的文献，以比较用户、模型、数据集、预测和标签，而不是仅仅查看注释者一致性或模型注释分布。</sample>
    <sample id="257">我们的帧率主要通过“Lab in the Wild”，一个在线 crowdsourcing 平台，实现的。</sample>
    <sample id="258">“Lab in the Wild 是一个在线实验平台，我们可以在这里招聘来自多样化的志愿者，相比之下，MTURC平台主要来自美国或印度等国家。 Lab in the Wild 仍然能够获取高质量的数据。”</sample>
    <sample id="259">我们在“out of the wild”中host两个任务，其中一个是社会可接受性。这个任务的方式是，参与者将从社会化学数据集中读取情况，然后写出情况的社会可接受性。</sample>
    <sample id="260">“随后，他们可以将自己的回答与AI和其他人的比较，以保持在研究中的参与度。”</sample>
    <sample id="261">我们然后将这些注释与社交化学、Delphi和GPT-4进行了比较。</sample>
    <sample id="262">我们然后对毒性和仇恨言语检测任务进行相似的设置，他们将阅读Danny Hate中的一个实例，并写下他们是否认为它是一个仇恨言语的实例。</sample>
    <sample id="263">我们然后将这些注释与 Dynahate、Perspective API、Rewire API、HateRoberta 和 GPT-4 进行比较。我们的研究最终总共获得了来自 1000 名来自 87 个国家的标注员的 16000 多个注释。</sample>
    <sample id="264">现在我们即将回答NLP数据集和模型的对齐问题。我们发现NLP中存在位置性。</sample>
    <sample id="265">例如，我们发现数据集和模型最适合英语国家。因此，对于 GPT-4 社交可接受性分析，我们发现它最适合儒家和英语国家。我们发现 Dynahate 也最适合英语国家。</sample>
    <sample id="266">我们还发现与有大学教育的人群中有更多的对齐。对GPT-4在社会可接受性任务中，我们发现它最相似于拥有大学教育或硕士教育的人群。</sample>
    <sample id="267">我们发现迪安海德的情况也类似，对于拥有大学教育的人群来说最为相关。</sample>
    <sample id="268">然而，当模型和数据集对特定人口进行 align 时，某些人总是被遗漏。</sample>
    <sample id="269">例如，这是指对非二元性别的人群相比男性和女性的数据集和模型不一致。我们在 GPT-4 社交可接受性任务和餐厅仇恨分析中发现了这种情况。</sample>
    <sample id="270">"考虑到ATLADY和L.P.中的位置，我们可以做些什么？"</sample>
    <sample id="271">我们有几个推荐。第一是，在研究过程中记录所有相关设计选择。第二是进行人工智能语言处理（NLP）研究，以获得多角度的视角。</sample>
    <sample id="272">我们的第三个建议是在四个特定的社区中建立专门的数据集和模型。Musseqani项目是一个很好的例子。我们想强调，包括NLP不仅仅是使所有技术适用于每个人。</sample>
    <sample id="273">"好的，这是我们的演示的结论，如果您想了解更多，欢迎您查看我们的仪表盘，获取最新的分析结果和论文。谢谢。"</sample>
    <sample id="274">The speaker mentioned the following problems of the current stimulus models:

1. Specific architectures are usually trained, introducing additional modules to be optimized.
2. Long and complicated training procedures.
3. Training involving different optimization objectives.
4. Training and maintaining several models to reach different latency regimes.</sample>
    <sample id="275">According to the speaker, one effective method to mitigate social and political bias in NLP model training data is to sanitize the data, but this approach is challenging as it can lead to censorship or exclusion, and it's hard to determine what is truly neutral.</sample>
    <sample id="276">[00:00:01]嗨，我是复旦大学的施宇源。我来介绍我们的工作，语言模型的约束语言规划。</sample>
    <sample id="277">在日常生活中，人类常常按照步骤逐步执行的指令来计划自己的行为，这些指令形同保证的脚本。</sample>
    <sample id="278">前一个世界已经将语言模型用于规划抽象目标，例如做蛋糕，并且证明了大语言模型可以有效地将目标分解为步骤。</sample>
    <sample id="279">然而，前人的研究主要集中于理论活动的抽象目标的计划。计划具有特定的目标、特定的约束，例如制作巧克力蛋糕，这仍然是一个未被充分研究的领域。</sample>
    <sample id="280">我们在这篇论文中定义了约束语言规划问题。</sample>
    <sample id="281">：不同GoalSaw计划的限制条件。一个抽象的Goal可以继承不同的实际Goal，具有多方面的限制条件。一个好的计划师应该编写的脚本是合理的，忠实于限制条件。</sample>
    <sample id="282">本文首先评估和改进大型语言模型的约束语言规划能力。</sample>
    <sample id="283">由于没有特定的目标网站来 spot 我们的开始。</sample>
    <sample id="284">我们首先需要获取这个代码。根据表格，使用 Instruct GPT 在人机交互数据获取中扩展抽象代码，添加多方面的约束。</sample>
    <sample id="285">我们对100个特定的目标进行抽样，并对来自大规模模型的脚本进行评估。</sample>
    <sample id="286">[00:00:01 - 00:00:18]
这张表格报告了结果的总体准确性。我们发现所有的线上重建都无法满足特定的目标规划。</sample>
    <sample id="287">然后，我们对线级模型进行详细分析，以了解它们的用途。</sample>
    <sample id="288">结果表明，生成的脚本中语义一致性是可接受的，但是对约束的忠诚度无法确保。</sample>
    <sample id="289">我们正在探讨《醒着回家》的碎片化主题约束。图中的头图表明，根据不同类别的女孩，指令性规划性能存在明显差异。</sample>
    <sample id="290">前期研究表明，线级模型的输出质量存在高方差，导致性能不佳。因此，我们采取超生成Z过滤器的想法以提高生成质量。</sample>
    <sample id="291">我们首先展示 constraint 类型的示例，以便在 intract.cpt 中获得特定的目标，基于抽象目标。</sample>
    <sample id="292">然后，向GPT下达总体的res key脚本，以便实现特定的目标。</sample>
    <sample id="293">下一个是将物理脚本的过滤模型导出。</sample>
    <sample id="294">我们将脚本和目标转换为GPT嵌入向量，并计算余弦相似度作为语义相似度测量标准。</sample>
    <sample id="295">此外，我们将找到包含目标约束关键词的脚本。我们只保留脚本，如果目标在目标设置中排名最高。</sample>
    <sample id="296">我们使用我们的方法，可以生成更高质量的正方形。我们的方法对计划的语义完整性和约束的忠诚度都有很大的改善。</sample>
    <sample id="297">由于大型语言模型的部署成本很高，因此需要为小型和专业化的模型启用语言规划能力。创建数据集是实现这一目标的关键一步。</sample>
    <sample id="298">然而，前期的研究不能为特定的目标进行规划，手动数据标注的成本很高。</sample>
    <sample id="299">因此，我们遵循符号知识 distillation 的想法，从 live-level 模型中 distill constrained 语言规划数据站点。</sample>
    <sample id="300">我们将使用构建受限语言规划数据集的方法，称为Coscript。</sample>
    <sample id="301">我们总共生成55,000个特定的目标脚本。为了确保验证和测试站点的质量，我们要求云端工作者找到并修复错误样本。</sample>
    <sample id="302">[00:01:00 - 00:00:01]
这幅图表展示了 Corscript 的约束分布。我们发现 Corscript 在生成特定目标时出现了高的plotism。使用 Corscript，我们可以trace 更小的但专门的模型来规划约束语言。</sample>
    <sample id="303">我们发现T文件函数在课程速率中可以生成质量更高的脚本，这表明小型模型可以在适合的数据站点上正确训练支持更大型模型。</sample>
    <sample id="304">总的来说，我们已经建立了约束语言规划问题。我们开发了大型语言模型的约束语言规划能力，并开发了大型模型的起源滤波方法。</sample>
    <sample id="305">我们使用大语言模型生成高质量的脚本数据集 Corscript，以便进行语言规划。我们希望 Corscript 数据集能够成为语言规划研究的一种有价值的资源。</sample>
    <sample id="306">谢谢您的时间。请查看我们的论文以获取更多详细信息。</sample>
    <sample id="307">PaLM的流畅度是与state of the art系统相媲美的。</sample>
    <sample id="308">The important properties of a watermark method are: 1) applicable to embedding S services, 2) not degrading the utility of provided embeddings, 3) difficult for the attacker to remove, and 4) transferable to the attacker's services during model extraction.</sample>
    <sample id="309">The TED talks have been translated into 14 different languages.</sample>
    <sample id="310">根据文本，数据集中抽取的实例用于重新注释是“many”。</sample>
    <sample id="311">The distance metrics used to measure the difference between the benign and backdoor datasets are cosine similarity and L2 similarity.</sample>
    <sample id="312">The multilingual pre-trained encoders, such as XLMR and BERT, are used with pointer-based decoders (PDR) for this task.</sample>
    <sample id="344">根据文本，作者可以通过收集总体文本corpus，然后计算单词的频率来确定中等频率的单词。</sample>
    <sample id="345">"大家好，我是徐恒。今天我将要展示我们的论文，探讨2003年Connell命名实体标注器在2023年是否仍然有效，让我们开始吧。"</sample>
    <sample id="346">我们的研究中探讨了通用化问题，使用命名实体识别任务或 NER 任务。</sample>
    <sample id="347">我们发现，模型已经将Kono 2003用于开发NER近20年。这样自然会引发一些问题。首先，这些模型是否可以泛化到现代数据？</sample>
    <sample id="348">我们开发新的标签时，需要什么样的因素来实现良好的泛化？</sample>
    <sample id="349">同时，如果我们观察到泛化能力不佳，这些模型的性能下降是由什么原因引起的？</sample>
    <sample id="350">为了解决这些问题，我们开发了Carnot++数据集。这是一个2020年来自路透社新闻的数据集，然后我们使用2003年Carnot注释指南对其进行了标注。</sample>
    <sample id="351">我们对20多个模型进行了微调，在Kono 2003上进行了训练，并在Kono 03测试集和Kono++测试集上进行了评估。</sample>
    <sample id="352">最后，我们计算了F1的百分比变化，以评估每个模型的泛化能力。</sample>
    <sample id="353">"为了良好的泛化，我们通过实验发现需要三个主要成分。"</sample>
    <sample id="354">"模型架构是第一个。通过我们的实验，我们发现 transformer 模型通常对新数据具有更好的泛化能力。"</sample>
    <sample id="355">第二个组成部分是模型规模。我们发现较大模型通常导致更好的泛化性能。</sample>
    <sample id="356">最后一个是，我们都知道，fine-tuning示例的数量直接影响下游任务的性能。我们也发现，更多的fine-tuning示例实际上也会导致更好的泛化能力。</sample>
    <sample id="357">"下一个问题，我们将探讨某些模型性能下降的原因。"</sample>
    <sample id="358">我们有两个假设。第一个假设是自适应过拟合，这是由于反复使用同一个测试集导致的过拟合，并且通常在新测试集上表现出返回值下降。</sample>
    <sample id="359">第二个假设是时间漂移，它是由训练数据和测试数据之间时间差异引起的性能下降。</sample>
    <sample id="360">为了抗适应过拟合，我们从右侧图表中看到红色最佳拟合线的梯度大于1。</sample>
    <sample id="361">这意味着我们在2003年对每个单元的改进都转化为多于plus plus的单元改进，这意味着没有diminishing returns。</sample>
    <sample id="362">他说，这个结果表明在这个案例中，我们没有观察到自适应的过拟合现象。</sample>
    <sample id="363">"哎，Temporary Trif？"</sample>
    <sample id="364">"对Temporal Drift，我们进行了一项实验，重新训练或继续预训练一些模型使用最新的数据。结果发现，时间差越大，性能越差。"</sample>
    <sample id="365">"这确认了我们的假设，即性能下降的主要原因是时间漂移。"</sample>
    <sample id="366">我们的结论是，为了良好的泛化，我们需要更好的模型架构、更大的模型规模，以及更多的微调样本。这些目标是相互关联的，我们不能单独拥有其中的一个，但需要同时考虑其他的因素。</sample>
    <sample id="367">在同一时间，我们也发现了性能下降的原因是时间漂移，而不是自适应过拟合，即使Conno2003已经使用了20多年。</sample>
    <sample id="368">让我们回到我们论文标题中提出的问题，2003年 Connell 的标签是否仍然有效？我们的发现是，答案实际上是肯定的。</sample>
    <sample id="369">我们希望对模型的通用化进行更多的研究。</sample>
    <sample id="370">"最后，请务必查看我们的论文，数据集。如果您有任何问题，欢迎与我联系，谢谢。"</sample>
    <sample id="397">1 second</sample>
    <sample id="398">Name, emotion, and duration.</sample>
    <sample id="399">示例质量。</sample>
    <sample id="400">The paper focuses on GPT-4 and its variants.</sample>
    <sample id="401">The model uses a combination of attention scores from multiple layers.</sample>
    <sample id="402">According to the audio, the direct difference example is: "by saying the name of the song is in me or its position, the first one."</sample>
    <sample id="403">Fudan University</sample>
    <sample id="404">1</sample>
    <sample id="405">Yes.</sample>
    <sample id="406">The author's example of a "marked group" is "women".</sample>
    <sample id="407">The text does not mention any specific model architecture that generalizes poorly. It only mentions that transformer models generally generalize better to new data.</sample>
    <sample id="408">The test dataset's name is not explicitly mentioned in the given text.</sample>
    <sample id="409">2</sample>
    <sample id="410">The author is investigating whether instruction tuning on multimodal protein models can improve generalization to unseen multimodal tasks, which suggests that the author is using multimodal data, not just text.</sample>
    <sample id="439">根据文本，作者认为 NLU 中的研究不足是“inference time knowledge”和“pre-trained time knowledge”两方面。</sample>
    <sample id="440">Ying.</sample>
    <sample id="441">Yes.</sample>
    <sample id="442">According to the text, the resources for context-dependent translations have limitations in:

1. Types of context-dependent translations
2. Sets of languages</sample>
    <sample id="443">"我好，我将谈论我们在解决间接指称表达式的实体选择中引入Alt实体分数的工作。"</sample>
    <sample id="444">我的名字是 Jawad Hosseini，这是一个与 Philippe Ladinsky、Sylvia Parity 和 Annie Lewis 共同完成的作品。</sample>
    <sample id="445">I cannot provide a translation of a text that appears to be a repetition of the phrase "درستان" in Farsi.</sample>
    <sample id="446">最明显的方法是使用直接差异。例如，通过说出歌曲名称或它的位置，第一个。</sample>
    <sample id="447">"有时候，间接引用更加适合自然地进行对话。这可能会发生在用户无法记住歌曲名称的情况下。"</sample>
    <sample id="448">"I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I want to be with you, I</sample>
    <sample id="449">"从未见过"</sample>
    <sample id="450">这是对话系统中一个重要的问题，也是LLM实体理解的benchmark。</sample>
    <sample id="451">没有找到相关的翻译结果。</sample>
    <sample id="452">我们的数据收集方法强调使用卡通完成集。</sample>
    <sample id="453">波伯说：“我们昨天听的歌曲你还记得吗？”，然后说出对话背景。</sample>
    <sample id="454">在第二个对话框中，艾莉丝说，你是指我容易还是我有预感？</sample>
    <sample id="455">他人的替代问题。第三个对话框中，鲍伯使用了间接引用选择其中的一个实体，例如较新的那个。</sample>
    <sample id="456">I'm happy to help! Here is the translation:

"首先，需要说出社会的第一句话，然后才能说出第一句话，这句话是应该这样说的。"

Please note that the original text appears to be a mix of Farsi and Persian, and the translation provided is my best attempt to convey the meaning.</sample>
    <sample id="457">第二个，即备选问题，是按以下方式生成的。</sample>
    <sample id="458">我们总是使用一个简单的模板。是A或B？A和B是维基百科的样本。</sample>
    <sample id="459">以下是我们使用的采样方法。当我们向列表上方移动，实体之间的相似性增加，通常难以进行消歧。</sample>
    <sample id="460">"Uniform Attract"</sample>
    <sample id="461">第二个是当实体拥有相似的标题。例如，两个书籍拥有同样的名称，零售。</sample>
    <sample id="462">第三个是当他们在维基百科上有相似的描述时，最后是当他们在维基百科上有相似的信息框或属性时。例如，同一类型或同一艺术家对一首歌曲。</sample>
    <sample id="463">让我展示这个替代问题以回答他们知道这些实体的名称，但不一定知道实体本身。</sample>
    <sample id="464">我们所做的是展示这两个实体的背景知识。对于歌曲，我们简单地显示每首歌曲的Google搜索链接。</sample>
    <sample id="465">然后请annotators听一部分歌曲，并阅读每首歌曲的信息。例如，EasyHunt歌曲的Google搜索结果是：</sample>
    <sample id="466">我们在菜谱和图书领域中显示维基百科的背景文本。对于菜谱，我们还显示维基百科中的图片，以便标注者了解它们的外观。</sample>
    <sample id="467">我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有我们没有</sample>
    <sample id="468">从文本中无法翻译出有意义的内容，因为文本是一个长串的重复字符“ از”没有任何实际含义。</sample>
    <sample id="469">「L实体库拥有6000个跨三大领域的替代问题，并拥有42000个间接引用表达。T5大型模型的结果如下。」</sample>
    <sample id="470">如果语言模型拥有与标注员相同的背景知识，那么准确率真的很高，约为92%到95%。但是，这并不是现实情况。</sample>
    <sample id="471">I'm happy to help! Here is the translation:

如果我们没有从头到尾的记录，我们就没有办法知道我们是否有所失去，有所遗漏，从头到尾的记录是非常重要的。</sample>
    <sample id="472">如果语言模型只有访问实体名称，那么准确率仅为60%。因此，有很多改进的空间。我们还表明模型具有泛化能力。以下是我们的数据集链接。感谢。</sample>
    <sample id="473">The method compares with the following existing SimulST strategies: weight-key strategy and local agreement, as well as state-of-the-art architecture specifically tailored for steam-on-thigh-respirations translation.</sample>
    <sample id="474">Yannis Lavraque.</sample>
    <sample id="475">Jenny</sample>
    <sample id="476">2</sample>
    <sample id="477">我是特伦特大学和布鲁诺凯撒基金会的萨拉·帕皮，我将简要介绍“注意作为同时口译指南”论文，这是一份由马泰奥·内格里和马尔科·图尔奇共同完成的作品。</sample>
    <sample id="478">[00:00:01] 什么是同步口译？同步口译（Simultaneous Speech Translation，简称SIMUL-ST）是指在实时将spoken语言翻译成另一种语言的文本，从而实现跨语言交流。</sample>
    <sample id="479">当前激励模型的问题是：通常，特定的架构会引入额外的模块以进行优化。</sample>
    <sample id="480">长时间的复杂训练程序，例如涉及不同优化目标的训练。</sample>
    <sample id="481">"培训和维护多个模型以达到不同的延迟模式。例如，训练一个延迟为1秒的模型，以及另外一个延迟为2秒的模型等等。"</sample>
    <sample id="482">我们的解决方案是什么？</sample>
    <sample id="483">首先，使用离线SD模型，而不需要重新训练或调整特定的架构，以适应单个SD。使用同一个模型来处理不同延迟模式，并通过特定的参数来处理延迟。</sample>
    <sample id="484">"通过模型已经通过注意力机制在音频输入和文本输出之间获得的知识，可以看到右侧的示例。"</sample>
    <sample id="485">我们的解决方案是提出一个点或编码器的注意力代码，并且这是一个决定是否发射部分翻译的策略，根据注意力指向的位置。</sample>
    <sample id="486">如果张力不集中，那么一个词语将被发射，这是指总和小于某个阈值alpha，指的是对最后lambda的pitch帧的张力，意味着收到的信息足够稳定。</sample>
    <sample id="487">例如，如果我们收到一条语音输入“I'm going to talk about”并且我们的模型预测在德语中翻译为。</sample>
    <sample id="488">我们将查看交叉注意权重。</sample>
    <sample id="489">我们将看到第一个两个词语指向最早接收到的语音帧，而最后一个词语指向最后接收到的语音帧作为Lambda语音帧。</sample>
    <sample id="490">"这意味着第一个两个词将被省略。"</sample>
    <sample id="491">当跨注意力的和值高于某个阈值alpha，我们不会发射最后一个词，我们等待另一个语音块。</sample>
    <sample id="492">如果我们继续前进，并收到另一个speech tank，我们的模型预测另外三个词语，我们将查看这个交叉注意权重。</sample>
    <sample id="493">我们将看到没有单词指向最后一个lambda语音帧。</sample>
    <sample id="494">这意味着这三个词将被发射。</sample>
    <sample id="495">如果你查看那里的主要结果。</sample>
    <sample id="496">我们将同时空间转换结果在图表上绘制，其中蓝色一侧测量转换质量和平均滞后。</sample>
    <sample id="497">“我们考虑的是延迟测量，以及模型预测输出所需的计算时间-aware 平均喜欢度。”</sample>
    <sample id="498">我们想在这个图表上我们的曲线尽可能高。</sample>
    <sample id="499">我们也想让他们向左移动。</sample>
    <sample id="500">我们还将与离线模型中的准备策略进行比较，这些策略包括权重策略和局部一致策略。我们还将与专门为 steam-on-thigh-respirations 翻译的最新架构进行比较。</sample>
    <sample id="501">这些是对德语的同时空间翻译策略的所有结果。</sample>
    <sample id="502">我们看到成人输出的所有策略都应用于离线模型，因为曲线向左移动。</sample>
    <sample id="503">我们还看到，如果考虑实际的时间或计算时间，那么实际上最快的策略。</sample>
    <sample id="504">如果你想了解更多结果，请阅读我们的论文。我们也发布了开源代码、模型和同时输出，以便facilitate我们的工作的可重复性。感谢您的关注。</sample>
    <sample id="505">No, the dataset is not publicly available, as it is mentioned that the speaker says "check out our paper, our data set", implying that it is not publicly accessible.</sample>
    <sample id="506">"大家好，我是 Ying，和我的同事 Zhiyang，我们将会介绍我们的研究论文，关于多模型精神学习的改进通过指令调整。"</sample>
    <sample id="507">随着大型语言模型的发展，许多研究开始探索使用预训练语言模型来在参数和数据效率上重新学习下游任务的新学习范式。</sample>
    <sample id="508">"近期有许多研究表明，通过instruction tuning，语言模型可以在零样本情况下执行未见过的任务，仅仅通过自然语言指令。"</sample>
    <sample id="509">然而，前人的研究大多集中于在语言任务上改进零样本性能，而计算机视觉和多模态任务则被忽视。</sample>
    <sample id="510">因此，在本研究中，我们旨在探索是否通过对多模态蛋白质模型进行指令优化，可以提高对未见多模态任务的泛化能力。</sample>
    <sample id="511">"我们在进行研究时发现，RLP和多模型之间有一个可用指令数据集的明显差异。"</sample>
    <sample id="512">有超过1600个语言指令任务，但是没有大规模的多模态指令任务。因此，我们需要建立多模态指令调校数据集。</sample>
    <sample id="513">我们推出multi-instruct，第一个涵盖10个板块、62个多模态任务的多模态指令调整数据集。</sample>
    <sample id="514">这些任务来自21个开放源代码数据集，每个任务都配备五个专家编写的指令。</sample>
    <sample id="515">为了对我们的提议数据进行多模态指令调整，我们选择了OFA，一个统一的多模态portraying模型作为基础模型。OFA使用了统一的语言词汇、图像token和bounding box坐标。</sample>
    <sample id="516">"我们展示了我们的multi-inshrat数据集的一些示例实例。"</sample>
    <sample id="517">"统一处理多种输入和输出数据类型。"</sample>
    <sample id="518">我们按照 OFA 的方法，所有任务都被统一转换为序列到序列格式，其中输入文本、图像、指令和边框都在同一个 token 空间中表示。</sample>
    <sample id="519">"我现在要讨论多模态指令调整。"</sample>
    <sample id="520">我们使用了9个组中的53个任务作为训练集，每个任务抽样10,000个实例。对于测试，我们将通用推理组的所有任务留作测试，并从VQA和杂项组中选择5个任务。</sample>
    <sample id="521">我们使用测试舰队中的所有实例来完成每个任务。此外，我们从自然语言处理的测试舰队中随机选择20个任务作为现场任务。</sample>
    <sample id="522">我们使用预训练的OFA大模型作为基础模型。在训练中，我们对所有任务生成所有实例，每个实例随机与其中之一的五个指令模板组合。</sample>
    <sample id="523">在测试中，对于每个任务，我们对模型进行五个实验，每个实验使用其中的一种指令进行评估。</sample>
    <sample id="524">我们报告了五个实验的平均性能、最大性能和性能标准差。</sample>
    <sample id="525">如果任务是多模型分类任务，我们报告准确率。如果是多模型生成任务，我们报告Root Mean Squared Error（均方根误差）。对于RP任务，我们同样报告Root Mean Squared Error。</sample>
    <sample id="526">我们还引入了另一种评估指标叫做灵敏度。它衡量模型在执行同一任务时，对于相同的任务说明语句的输出是否能够保持一致，包括对 slight variation 的忽略。</sample>
    <sample id="527">"我们的主要结果是，指令优化可以显著提高同模型任务中的OIS性能。"</sample>
    <sample id="528">使用自然语言instruction数据集的迁移学习也可以提高instruction调优。</sample>
    <sample id="529">"随着任务数量的增加，模型的性能会提高，同时敏感性也会下降。"</sample>
    <sample id="530">我们也做了一项实验，我们使用了一条指令 versus 五条指令。如我们所见，使用更多的指令可以提高模型的整体性能，降低其敏感度。</sample>
    <sample id="531">"这个示意图显示了不同fun tuning策略对模型敏感度的影响。我们可以看到，通过从自然指令数据集进行迁移学习，模型可以实现比原始OFA模型更好的敏感度。"</sample>
    <sample id="532">我们也可以看到，自然指令数据集的 transfer learning 可以帮助 OFA 在自然指令数据集上获得更好的性能。</sample>
    <sample id="533">我们提出了第一个大规模多模态指令调整数据集。我们对OFA的阈值能力进行了significant改进，并探索了不同的迁移学习技术，展示了它们的益处。我们设计了一个名为敏感度的新指标。</sample>
    <sample id="534">"我们还收集了一大批多模型指令调整数据集，包括150多个Weiren语言任务，我们将其发布。下面是我们的数据和模型QR码，感谢。"</sample>
    <sample id="535">The authors of the paper belong to the University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="536">Jawad Hosseini.</sample>
    <sample id="562">"大家好，我是科斯塔夫·辛哈，我很高兴欢迎您来到我们2023年ACL论文《语言模型可接受性挑战不总是对上下文鲁棒》的讨论。"</sample>
    <sample id="563">「和约翰·沃瑟、亚伦·穆勒、卡尼什卡·米什拉、卡伦·芬图斯、罗杰·列维和阿迪娜·威廉姆斯一起合作了一份共同的作品。」</sample>
    <sample id="564">我们重新探讨最小对照Pairs的概念。</sample>
    <sample id="565">最小的对立模式实际上是在评估语言模型的可接受性，包括语法性，如“blimp”语法或基于ereotype的可接受性，如“crowd”等。</sample>
    <sample id="566">在这个最小对立对照实验中，评估语言模型的典型方法是，先显示可接受的句子或语法正确的句子，然后显示可接受的句子或语法不正确的句子。</sample>
    <sample id="567">然后希望模型将更多的概率分配到可接受的领域。</sample>
    <sample id="568">当前的MPP管道基本上不允许我们评估模型对更长句子的接受性。</sample>
    <sample id="569">现在，语言模型的上下文窗口越来越长。因此，我们需要对模型在整个上下文窗口中进行评估。</sample>
    <sample id="570">我们正尝试这里。我们正在尝试重新访问MPB管道，要求模型评估较长序列的可接受性。</sample>
    <sample id="571">"我们采取的方法是，重新访问这些数据集，然后从这些数据集中选择合适或不合适的句子，以模拟更长的序列。"</sample>
    <sample id="572">"例如，我们选择了来自 adjunct岛的blimp数据集中的一个典型的配对。"</sample>
    <sample id="573">我们做的是重建更长的序列，并且是可接受的，并且具有相同的语法结构，我们从AdjunTile中提取语法句子。</sample>
    <sample id="574">我们添加了一个前缀到可接受的查询和不可接受的查询中。</sample>
    <sample id="575">我们可以通过选择同样的匹配选择不接受的句子，这也可以用来测试模型的可接受性。</sample>
    <sample id="576">我们也可以从不同的子集或不同的数据集中选择句子。这就是所谓的不匹配场景。</sample>
    <sample id="577">"我们仍然从相关数据集中获取句子，但是这些句子不是你正在评估的同一个数据集。我们可以对不可接受的做同样的事情。"</sample>
    <sample id="578">最后，我们终于可以从完全无关的领域，如维基百科中选择句子。</sample>
    <sample id="579">这将告诉我们模型是否真的会受到上下文的影响。</sample>
    <sample id="580">“无论是来自数据集的不同子集还是与当前句子无关的内容。”</sample>
    <sample id="581">模型如何？首先，我们来看一下与当前查询对无关的维基百科句子。在那里，我们发现MPP判断对于任意上下文都是robust的。</sample>
    <sample id="582">我们将上下文长度增加到1024，以便最大限度地使用OPT和GPT2模型。如图中橙色点线所示，MPP的判断结果相对稳定。</sample>
    <sample id="583">当我们从同一个数据集中选择句子时，什么事情发生？</sample>
    <sample id="584">我们正在从同一个语法Gem数据集中的可接受和不可接受域中选择或创建句子。</sample>
    <sample id="585">我们看到，MPP的判断结果在添加可接受的前缀或不可接受的前缀时都会明显增加或减少。</sample>
    <sample id="586">当我们匹配结构时，我们选择同一现象中的句子，从而选择Jim的人称指责文本。</sample>
    <sample id="587">我们看到模型对MPP判断的巨大增加或巨大减少，取决于选择的前缀是否可接受或不可接受。</sample>
    <sample id="588">现在，这个效果随着上下文长度的增加，这可能会影响 newer language models，具有大上下文窗口的语言模型。</sample>
    <sample id="589">他问：为什麼匹配前缀对语言模型的判断如此重要？</sample>
    <sample id="590">我们做了一系列分析，尝试将输入句子保持结构不变，但添加噪音到输入中。然后，我们进行了多次这些扰动后，</sample>
    <sample id="591">我们发现这些噪音都没有改变模型关于MPP判断的结果。</sample>
    <sample id="592">我们发现模型对扰动和句子有相似的敏感性。</sample>
    <sample id="593">他说，当我们在可接受的语句域中扰乱语句，我们看到类似的扰乱增加。相应地，在不可接受的语句域中，我们看到MPP判断的减少。</sample>
    <sample id="594">我们的主要结论是，语言模型对句子中的潜在语法和语义特征非常敏感，这些特征跨越多个句子。</sample>
    <sample id="595">我们当前使用的MPP评估方法，通过单个中心点的输入可能不能完整地捕捉语言模型在上下文窗口中的抽象知识。</sample>
    <sample id="596">请阅读我们的论文了解更多实验细节。感谢您的关注。</sample>
    <sample id="597">The first step tags each input token with an unordered multi-set of tokens that will appear in the output.</sample>
    <sample id="598">55,000</sample>
    <sample id="626">Messalign.</sample>
    <sample id="627">Weakly supervised learning helps neural networks to not memorize label noise and generalise well, even when trained on noisy labeled data.</sample>
    <sample id="628">According to the text, the paper discusses the alignment of documents in the DEplain-web using both manual and automatic alignment methods.</sample>
    <sample id="629">The CoNLL++ dataset was created by collecting data from Reuters News in 2020 and annotating them using the same guidelines as the Carnot 2003 dataset.</sample>
    <sample id="630">“嗨，大家好，我是宾夕法尼亚州立大学的尹信。今天我将要介绍我们的工作，Crossland Ghosts and Money Parsing in Multiple Natural Languages and Mainline Representations。”</sample>
    <sample id="631">语义处理是构建用户查询的语义表示形式，如 SQL 和 Lambda 演算。</sample>
    <sample id="632">跨语言语义解析是将多种自然语言查询转换为多种含义表示的任务。</sample>
    <sample id="633">根据该图表，我们需要使用神经网络模型将查询语言翻译成SQL、Lambda、FunQL等多种自然语言。</sample>
    <sample id="634">现有的跨语言语义解析模型分别被提出和评估在有限的任务和应用中，例如，</sample>
    <sample id="635">有某些自然语言的漏洞。中文缺失。</sample>
    <sample id="636">由于某些特定的表示形式的覆盖。</sample>
    <sample id="637">“λ演算法缺失”。</sample>
    <sample id="638">他们或是在最新的模型上进行评估，例如，对于某个模型只有一个评估模型。</sample>
    <sample id="639">为了实现这个目标，我们提出了示例数据集，旨在多种自然语言和意义表示中进行跨语言语义解析。</sample>
    <sample id="640">这是一个包含90个病毒领域的数据集、570个毒素部分、80,000,000个表示和15个语言家庭中的22种自然语言的内容。</sample>
    <sample id="641">为了更好地评估我们的基准，我们考虑了六个用于训练和评估的设置。</sample>
    <sample id="642">"这是一个翻译测试。我们使用 Google 翻译 API 将源语言翻译到目标语言，然后使用单语言模型进行评估。"</sample>
    <sample id="643">例如，我们对英语模型进行训练，并在推理时使用API将德语查询翻译为英语，然后使用训练的模型预测SQL。</sample>
    <sample id="644">"我们还测试单语言模型。"</sample>
    <sample id="645">在这个设置中，源语言和目标语言相同，例如德语到德语或英语到英语。</sample>
    <sample id="646">我们还测试了单语言场景的拍摄设置，通过训练模型仅使用10%的训练数据。</sample>
    <sample id="647">"我们训练了一种多语言模型，可以对所有语言进行处理。"</sample>
    <sample id="648">例如，我们将德语、英语和中文查询结合起来训练多语言模型。在推理阶段，我们可以使用该模型来处理查询。</sample>
    <sample id="649">将英文内容翻译成中文。</sample>
    <sample id="650">我们还考虑了零交叉代码和域短传输。我们在一个源语言中训练，然后将其转移到另一个语言。</sample>
    <sample id="651">在训练期间，我们正在训练英文查询或英文和德语Fuscheout查询，以训练多语言模型并预测 SQL 输出。</sample>
    <sample id="652">我们也发现了许多有趣的结果。关于单语言模型的分析，我们评估了两个模型组。</sample>
    <sample id="653">包括使用多语言预训练的编码器与基于指针的解码器，如XL1R加PDR和BERTH加PDR。</sample>
    <sample id="654">我们还评估了编码器-解码器模型，这些模型是多语言预训练的编码器-解码器模型，例如M-BART和MT5。</sample>
    <sample id="655">我们发现，encoder-decoder在所有九个数据集上获得了最好的性能。</sample>
    <sample id="656">我们在多语言环境中评估MT5和XLM-R的示例PDR。</sample>
    <sample id="657">我们发现，encoder-decoder或encoder PDR可以通过在多种语言的训练中进行改进。</sample>
    <sample id="658">我们发现大多数自然语言中可以获得性能提高，除了英语在七个数据集中下降，只有三個数据集中提高。</sample>
    <sample id="659">我认为这被称为多语言之诅。</sample>
    <sample id="660">我们还比较跨语言性能差异。</sample>
    <sample id="661">在这个图中，蓝线是跨语言域场景的迁移学习曲线，橙线是跨语言零-shot学习曲线，而绿线是模型参数设置。</sample>
    <sample id="662">我们发现，通过比较绿线和橙线，我们发现在零 shot 设置下，跨语言目标转移性能差异很大。并且通过比较蓝线和橙线，我们发现在少数 shot 设置下，转移差异急速缩小。</sample>
    <sample id="663">我们也发现了一些其他有趣的结果。例如，encoder-decoder的所有性能进展都取得了类似的结果，对英语自然语言进行了优化，并且对目标自然语言的性能产生了明显的提高。</sample>
    <sample id="664">我们发现，使用代码作为蓝色语言模型仍然适用于跨语言语义解析任务。</sample>
    <sample id="665">总的来说，我们构建了ExamPolar，一个多语言多表示形式的跨角度语义解析统一评估标准。</sample>
    <sample id="666">我们对三种多语言模型的代表进行了全面的基准测试，并显示了许多有趣的发现，欢迎您访问我们的论文和代码。感谢您的收听。</sample>
    <sample id="667">Existing works can be broadly classified into four categories:</sample>
    <sample id="668">No, the mentioned LLMs (Large Language Models) such as Codex or Bloom may not be sufficient for CLSP (Cross-Lingual Semantic Parsing) tasks, as the speaker mentions that "natural language has significantly boosted the performance of future on target network" and "language models such as code as in blue are still in that grid" for CLSP tasks.</sample>
    <sample id="695">The method induces the alignment as part of the training to address the uncertainty of permutations, which are consistent with the data but linguistically incorrect.</sample>
    <sample id="696">According to the speaker, defining fairness in downstream NLP models involves acknowledging and tackling issues related to political meanings, such as the potential for language models to be fine-tuned on hate speech or misinformation, which can lead to the marginalization of people with opposite political opinions and the spread of hate speech targeting minority groups.</sample>
    <sample id="697">Yannis Lavraque</sample>
    <sample id="698">Kostav Sinha</sample>
    <sample id="699">Myra</sample>
    <sample id="700">In the context of this text, tropicalism refers to a trope that connects Latina women to vibrant and curvaceous characteristics.</sample>
    <sample id="701">The author creates a target group by defining them through words such as "culture", "tradition", "proud", and "exotic", which highlight their distinct identity and differentiate them from the white norm.</sample>
    <sample id="702">The text mentions measuring context usage using CXMI, which is extended to YCXMI that can measure context usage at the sentence level or at the word level.</sample>
    <sample id="703">DrBERT is a model trained on a large corpus of text, including 7GB of text, while SchuBERT is a clinical model trained on 4GB of clinical notes. The main difference is that DrBERT is a general-purpose language model, while SchuBERT is a specialized model focused on clinical text.</sample>
    <sample id="751">2</sample>
    <sample id="752">Iterative update.</sample>
    <sample id="753">Based on the provided audio, I can transcribe the text and answer your question.

The text appears to be a repetition of the phrase "درستان درستان درستان" which is in Persian (Farsi) language. It seems to be a nonsense text, and it's not possible to understand the content or identify the target of the dataset.

If you meant to ask about the target of a different dataset, please provide more context or clarify which dataset you are referring to.</sample>
    <sample id="754">The attacker can extract model parameters by validating the covertness of the provided embedding through visualizing the embedding of sentences on dataset BOPCA.</sample>
    <sample id="755">3</sample>
    <sample id="756">2</sample>
    <sample id="757">The authors of this paper are affiliated with Carnegie Mellon University, University of Washington, and the Allen Institute for AI.</sample>
    <sample id="758">The example is "I saw Bart and Lisa".</sample>
    <sample id="759">ABC eval.</sample>
    <sample id="760">Because large language models are generating longer and longer context windows, it's crucial to evaluate their acceptability throughout the entire context window.</sample>
    <sample id="761">Yes, according to the speaker, training a multilingual model can lead to a performance drop in English, as mentioned in the statement "we found it is because most of the major natural languages can obtain performance gain, except that English performance drops in seven datasets and only gains in three datasets".</sample>
    <sample id="762">No.</sample>
    <sample id="763">Disfluency, duration, and filler words.</sample>
    <sample id="764">Yes, model size can affect the performance of named entity recognition (NER) models, and larger models tend to perform better in generalization.</sample>
    <sample id="765">In NLP, bias is crucial because it can significantly impact the accuracy and fairness of machine learning models, such as the Perspective API used for toxic comment detection. A biased model may misclassify certain types of comments, failing to detect toxicity in some cases (e.g., Indian context) or incorrectly flag non-toxic comments as toxic. This can lead to unfair outcomes, perpetuate discrimination, and undermine the trust in AI systems.</sample>
    <sample id="766">According to the text, it doesn't explicitly state whether BLOOM is fine-tuned or adapter-fine-tuned. However, it mentions "neural models" and "adapter, or et cetera", which suggests that adapter-based fine-tuning might be involved.</sample>
    <sample id="767">They used a transfer learning model for the task of topic-independent dissonance classification.</sample>
    <sample id="768">The recent test sets used to evaluate the capabilities of PaLM include the SuperGLUE benchmark, GLUE, and the Stanford Question Answering Dataset (SQuAD).</sample>
    <sample id="769">3</sample>
    <sample id="770">According to the text, the question is not answered. The text does not mention the comparison with a strong baseline and the gain of the proposed method.</sample>
    <sample id="771">Xu Heng.</sample>
    <sample id="772">Yes, the results and dataset proposed in the paper can be used as a benchmark for the problem of automatic text simplification in the future.</sample>
    <sample id="773">They conducted an experiment on a single small model.</sample>
    <sample id="774">OFA模型。</sample>
    <sample id="833">Google Translate.</sample>
    <sample id="834">Stony Brook University.</sample>
    <sample id="835">The paper analyzed neural machine translation (MT) metrics and human evaluation results for multiple languages.</sample>
    <sample id="836">Xiangbin.</sample>
    <sample id="837">They fine-tuned two models: one for document-level simplifications and one for sentence-level simplifications.</sample>
    <sample id="838">53 tasks for training, 27 tasks for testing.</sample>
    <sample id="839">There is one author, Regina Stotten.</sample>
    <sample id="840">The author used the following datasets: AG News, Mind, SSD2, and AresVam.</sample>
    <sample id="876">NACCHOS is a dataset of medical ground truth data from the web.</sample>
    <sample id="877">Aydbilar.</sample>
    <sample id="878">The prompting has a significant influence on the performance of LLMs for translation.</sample>
    <sample id="879">Kaio Yan et al.</sample>
    <sample id="880">The 5 multi-model instruction tuning data sets are for Weiren language tasks.</sample>
    <sample id="881">The author suggests using a coreference resolution task to test a model's ability to draw on knowledge from different sources.</sample>
    <sample id="882">[00:00:01]Aydbilar：嗨，大家好。我是Aydbilar，我将为您简要介绍论文《Grunting Pattern from Translation，Assessing Strategies and Performance》，这是与Google Translate的同事合作的作品。</sample>
    <sample id="883">"2022年推出的BAM是一个540亿参数语言模型。它是基于180亿份文档的大型文本集训练的。"</sample>
    <sample id="884">在厨房中，它在数百个NLP任务中实现了state of the art。</sample>
    <sample id="885">本文中，我们首次系统地研究了大规模语言模型的机器翻译提示。</sample>
    <sample id="886">我们使用MT社区的最佳实践来评估这些模型的转换能力。这种评估包括使用最新的测试集来避免使用语言模型的训练数据重复测试。</sample>
    <sample id="887">我们比较两个最先进的系统。因此，表现最好的系统是WMT评估。</sample>
    <sample id="888">我们使用最新的神经机器翻译指标，并且还提供了基于专家的人工评估结果。最后，我们还提供了一些建议来选择提示策略。</sample>
    <sample id="889">LLMs 对翻译性能的引导语有很大的影响，如我们在一个简单的实验中所看到的，其中使用了一次性引导语，并为同一个句子提供了两个不同的引导语。</sample>
    <sample id="890">大多数句子，516个中，有516个句子之间的差异大于一个模糊点。</sample>
    <sample id="891">"在极端情况下，这可能会达到40个模糊点。因此，选择一个合适的提示策略是非常重要的。"</sample>
    <sample id="892">我们在实验中使用五个shot.prompting策略，其中我们将语言标记为系统所提供的句子。</sample>
    <sample id="893">在这个示例中，我们将德语翻译成英语，德语句子标记为德语列，英语翻译标记为英语列。</sample>
    <sample id="894">我们发现短期内的印刷形式对短印刷的影响不大。</sample>
    <sample id="895">零和一次性提示非常重要。我们在五次性提示中，实际提示形式几乎没有差异。</sample>
    <sample id="896">他最重要的是例子。</sample>
    <sample id="897">我们的实验结果总结是，示例的质量比与源句子的相似性更重要。</sample>
    <sample id="898">选择高质量翻译的例子非常重要。特别是，我们将从WMT评估的训练数据或DEF数据中选择示例。</sample>
    <sample id="899">他说：“深度数据的质量更好，更加精心挑选，与训练数据相比更杂乱，所以使用深度数据时的性能更好。”</sample>
    <sample id="900">现在，至少是专门的先进系统对band翻译有很大的优势。但是，一个已经接近于商业系统。在我们的情况中，我们选择与Google Translate合作。</sample>
    <sample id="901">我们从使用MQM框架进行的EMAIL规则中获得的见解是，手掌流畅度与当前最先进的系统相似，但主要的差异来自准确性。</sample>
    <sample id="902">特别是，常见的错误是遗漏错误。</sample>
    <sample id="903">“ palms 选择生产一个更好的翻译结果，有时候通过删除源句子的某些部分来实现。”</sample>
    <sample id="904">然而，PAN的style-outward类别低于state-of-the-art系统，这是另一个信号。</sample>
    <sample id="905">"帕姆提供了非常流畅的输出，但是仍然存在一些准确性问题。"</sample>
    <sample id="906">"好的，这就是对这个非常简短的总结。如需了解更多细节，请来到论文的完整报告。谢谢。"</sample>
    <sample id="907">"你好，我是德威，德国萨兰特大学的博士生。在这个视频中，我将介绍我们的最新工作“Wicker Than You Think”，对周边供应进行了深入分析。"</sample>
    <sample id="908">这是与肖宇轩、Mario Smoothbath、Diaz Stefan和DTich Claco的合作作品。</sample>
    <sample id="909">我想从弱监督和弱监督学习开始做一个简短的介绍。</sample>
    <sample id="910">弱监督中，我们不手动标注数据。相反，我们使用弱标注源，如简单的heuristic规则、知识库或局部编码 souring来标注数据，如右图所示。</sample>
    <sample id="911">相比人工标注，弱标注的成本更低，但是也更加嘈杂，这意味着有一定的标注是错误的。</sample>
    <sample id="912">如果我们直接在有标签的周期数据上训练神经网络，那么神经网络 tends to memorize标签噪音而不是泛化。</sample>
    <sample id="913">在每周监督学习中，提出了一些训练算法，以使神经网络在如此高噪音环境中仍然能够generalize良好。</sample>
    <sample id="914">近期在WSL领域的研究中，WSL是指周期监督学习。人们常常声称，他们只在周期劳动数据上训练模型，并且在干净测试集上取得了高性能。</sample>
    <sample id="915">"从技术角度讲，这个声明不是错误的，但有一个陷阱。"</sample>
    <sample id="916">人们通常假设有额外的干净验证集或防火墙用于模型选择。</sample>
    <sample id="917">我们在这个问题上停留了下来，因为这意味着需要在周报中添加更多的手动注释，以便为许多人提供支持。但是，这种必要性却经常被忽视，就像房间中的一个大象。</sample>
    <sample id="918">前面提到的疑问被要求提出三个研究问题。首先，是干净的验证数据对于WSL是否必要？或者我们是否可以使用嘈杂的验证集？</sample>
    <sample id="919">第二，如果需要或必须有干净数据，以便WSL可以工作，那么我们需要多少个干净样本？最后，我们是否只使用干净样本进行验证，或者有更好的方法来利用它们？</sample>
    <sample id="920">我们在我们的工作中解决了这些研究问题，以下是我们的发现。</sample>
    <sample id="921">首先，我们发现，最近的WSL方法实际上需要洁净的样本才能正常工作。</sample>
    <sample id="922">“否则，性能下降很大。正如该图所示，如果没有干净的验证样本，那么趋势模型无法超越原始周标签。”</sample>
    <sample id="923">"训练毫无意义。"</sample>
    <sample id="924">WSL的方法实际上需要清洁标注的数据才能正常工作，并且获取清洁验证样本的注释成本 shouldn't be overlooked。</sample>
    <sample id="925">我们的第二个发现是，增加清洁验证样本的数量可以帮助WSL方法实现更好的性能，如图左侧所示。</sample>
    <sample id="926">通常，我们只需要20个样本就可以获得高性能。</sample>
    <sample id="927">"但是，这并不是故事的结尾，因为如果我们选择直接在干净样本上训练，那么结果将会更好。"</sample>
    <sample id="928">红色图表显示了在直接应用于干净数据的微调方法和仅用于验证的WSL方法之间的性能差异。</sample>
    <sample id="929">我们可以看到，如果我们有10个样本每个类别，那么Direct的fine-tuning开始超越WSL方法。</sample>
    <sample id="930">最后，WSL 方法中之前所提出的性能改进可以通过在干净验证样本上继续微调来轻松实现。</sample>
    <sample id="931">我们可以从图表中看到，Valina 模型称为 FTW 初始性能不如复杂的 WSL 方法，如余弦方法。</sample>
    <sample id="932">然而，如果我们允许在干净样本上继续微调，那么FTW与其他方法的性能是一样的。</sample>
    <sample id="933">实际上，在实践中，没有理由选择更加复杂的WSL方法，这些方法需要更多的计算时间和磁盘空间。</sample>
    <sample id="934">我们展示了，最近的WSL方法需要清洁、手动注释的样本以便它们正常工作。它们的性能提高和实用性严重被夸大。</sample>
    <sample id="935">"根据我们的建议，未来的工作时间将如下所示。"</sample>
    <sample id="936">首先，报告模型选择标准。例如，报告模型选择是否基于良好的验证样本。</sample>
    <sample id="937">第二，WSL 应该伴随着未来着陆基准一起进行，都是在明确样本上工作。第三，连续微调是简单而强大的基准，应该在WSL中考虑未来工作。</sample>
    <sample id="938">最后，我们已经开源了我们的代码。您可以通过幻灯片上的QR码来查看它。感谢您的到来，感谢您的参与。</sample>
    <sample id="939">The common practice is to use human evaluation, such as by asking human judges to select which of two conversations is better or to rate conversations given a Likert scale.</sample>
    <sample id="940">4</sample>
    <sample id="941">In the example, the following background knowledge is needed:

* Data mining
* Data preprocessing
* Data analysis
* Machine learning
* Pattern recognition</sample>
    <sample id="942">Yes, the code is open. It can be found on GitHub.</sample>
    <sample id="943">According to the text, the alignment of GPT-4 in the social acceptability task is most similar to people with a college education or graduate school education.</sample>
    <sample id="944">The speaker suggests adding "noise" to the input sentence while preserving its structure to perturb the language model, but the specific method is not mentioned.</sample>
    <sample id="945">进行维度评估（Evaluating multiple dimensions）意味着评估对话质量的多个方面或特征，以更好地理解模型在细粒度上的优点和缺点。</sample>
    <sample id="946">University of Science and Technology of China.</sample>
    <sample id="947">According to the audio, the form of the prompting is crucial in the case of zero and one short prompting.</sample>
    <sample id="978">The author assessed conversational AI models.</sample>
    <sample id="979">There is only 1 author, Jingwei Yi.</sample>
    <sample id="980">A good planner should write scripts that are reasonable and faithful to constraints.</sample>
    <sample id="981">1</sample>
    <sample id="982">Vasudha.</sample>
    <sample id="983">Adam Szpirkowski.</sample>
    <sample id="1021">Omission errors.</sample>
    <sample id="1022">[00:00:01] 我是詹姆斯·芬奇，我是莎拉·芬奇，我们今天将向您介绍ABCeVal，一个新的对话式人工智能评估方法。</sample>
    <sample id="1023">"这是由埃默里人工智能实验室的研究员Geno Choi领导，和亚马逊Alexa AI合作完成的作品。"</sample>
    <sample id="1024">让我们假设你刚刚开发了一种对话模型，并想了解它与当前最先进技术的相比如何。</sample>
    <sample id="1025">"常见的做法是使用人类评估，例如向人类评审员询问哪个对话更好或根据 Likert 等级表对对话进行评分。"</sample>
    <sample id="1026">这些方法对对话质量的整体评估非常有效，但对话质量有很多方面。因此，您可能想评估多个对话质量的维度，以了解模型在更细化的层面上的优缺点。</sample>
    <sample id="1027">有一种方法是请人工评估家对对话质量的多个维度，例如使用比较或Likert等方法评估模型回应的相关性。</sample>
    <sample id="1028">然而，我们认为有一个更加精准可靠的维度对话评估策略。</sample>
    <sample id="1029">我们的方法旨在通过明确标注模型响应是否表达某些行为，例如响应无关信息或自相矛盾，以减少人工评估的主观性。</sample>
    <sample id="1030">我们称这种方法为对话行为注释或简称ABC评估。我们开发了这个方法，以便全面涵盖近期文献中提到的影响对话质量的对话行为。</sample>
    <sample id="1031">"ABC评估可以评估聊天模型在不同主题方面的错误率。"</sample>
    <sample id="1032">例如，ABC评估模型对话中，模型忽视对方或说些无关紧要的话的次数。</sample>
    <sample id="1033">"该语音助手有时会自相矛盾、虚构错误的事实或违背常识知识，并且在成功或失败时无法表达同情。"</sample>
    <sample id="1034">为了确定最有效的评估方法，我们选择了四个最先进的聊天模型，并将每个模型在100个人类机器人对话中进行评估使用ABC评估。</sample>
    <sample id="1035">我们还使用了三个现有方法来评估这些对话，包括-turn级别的酒精评分、对话级别的酒精评分和对话对比评分。</sample>
    <sample id="1036">我们对每种现有方法收集了对八个对话的评估结果，这些评估结果是评估聊天模型的标准做法。</sample>
    <sample id="1037">根据我们的分析结果，我们发现，ABC评估行为标签相比现有方法收集的标签更加可靠，根据100个双重标记对话的Interanitator一致性进行衡量。</sample>
    <sample id="1038">此外，ABC评估标签在对话质量的预测性比现有方法生成的指标更好，如本次简单线性回归分析所示。</sample>
    <sample id="1039">例如，您可以看到，衡量自我和伴侣矛盾的比例可以解释对话质量的5%和10%，而平均酒精一致性分数解释的比例则少于4%。</sample>
    <sample id="1040">最后，我们使用逐步线性回归检查每个评估指标是否捕捉到了聊天质量的独特方面。</sample>
    <sample id="1041">"可以看到，所有ABC评估指标的组合解释了对话质量的25%以上。随着逐一删除这些指标，大多数情况下都导致了对话质量的部分信息丢失。"</sample>
    <sample id="1042">相反，所有Likert指标的组合解释了质量的很少部分，并且这些指标中较少的信息是独特的。</sample>
    <sample id="1043">这些可靠、信息化和明确的ABC评估指标使我们能够使用更高分辨率来评估对话式人工智能，而之前的方法无法实现。</sample>
    <sample id="1044">"可以从我们的实验结果中看到，仍然存在一些挑战，我们已经对其进行了精准的量化。例如，我们测试的机器人在20%的回答中出现了常识违背。"</sample>
    <sample id="1045">他们约15%的回答中包含无关信息，约10%的回答与自己或对方相互矛盾。</sample>
    <sample id="1046">随着该领域的技术进步，自我们进行评估以来发布的新模型中许多错误率可能会下降。但是，这只更是我们追求可靠和准确评估指标以比较模型的理由。</sample>
    <sample id="1047">我们希望ABC评估能够为该领域的其他人所使用，作为实现这一方向的有意义的一步。我们期待未来几个月和年中对会话AI的发展。感谢您的观看。</sample>
    <sample id="1048">Emory University and Amazon Alexa AI.</sample>
    <sample id="1049">CFT stands for Clean For Training.</sample>
    <sample id="1050">6</sample>
    <sample id="1051">"Hello, my name is Kaio Yan, and I'll be presenting our work titled, When Does Translation Require a Context? A Data-Driven Multilingual Exploration. This work was done in collaboration with Patrick Frenange, M.E. Liu, Andre F.D. Martin, and Graham Mubig."</sample>
    <sample id="1052">根据上下文很多翻译都需要考虑上下文。例如，我们如何翻译这个句子中的"more"?</sample>
    <sample id="1053">"如果前一句是'如果部长们发现了，那么默可能指的是间谍'，那么默指的是间谍。如果前一句是'那么能否是很严重的，医生？'那么默指的是胎记。"</sample>
    <sample id="1054">根据上下文，单词的含义和翻译也会发生变化。</sample>
    <sample id="1055">然而，评估模型对这种情况的翻译性能非常困难。首先，因为只有少部分翻译取决于上下文，这使得基于corpus的指标，如BLUE无法捕捉这些翻译。</sample>
    <sample id="1056">一些人建议使用上下文相关的评估，但是这些资源只支持有限的上下文相关翻译类型和语言，因为它们通常依赖领域知识和人工编辑。</sample>
    <sample id="1057">在这项工作中，我们尝试回答这两个问题。首先，当翻译需要上下文？其次，模型如何处理这些情况？</sample>
    <sample id="1058">为回答第一个问题，我们首先测量了单词在翻译中的依赖性。</sample>
    <sample id="1059">我们之前引入了CXMI作为机器翻译模型中上下文使用的衡量标准。这种衡量标准是通过计算上下文C对目标Y的信息量，考虑到源X的情况而进行的。</sample>
    <sample id="1060">CXMI 可以被看作是模型对上下文的信息。</sample>
    <sample id="1061">本文中，我们将CXMI扩展到YCXMI，可以在句子级别或单词级别衡量上下文使用。可以认为高P6MI的词语需要上下文来翻译。</sample>
    <sample id="1062">现在我们分析高XMI的词语，以查找这些词语之间的模式。</sample>
    <sample id="1063">我们对从英语翻译成14种语言的TED演讲文本进行分析。</sample>
    <sample id="1064">我们对语料进行三种不同的分析。首先，我们查看PCXMI值高的词性标签。</sample>
    <sample id="1065">这使我们能够找到阿拉伯语中具有相对高P6MI的双数代词。这种情况可以解释为英语中没有双数代词，因此在将英语翻译为阿拉伯语时需要上下文来确定代词是否是双数。</sample>
    <sample id="1066">我们发现，某些语言也需要考虑语境来选择适当的动词形式。然后，我们查看了所有出现过的词汇项，它们的p-sex-mi平均值。</sample>
    <sample id="1067">根据您提供的英文内容，我将其转换为中文如下：

"这有助于识别像这里的情况，在中文中需要上下文来翻译名词，以确保在文档中使用相同的翻译。"</sample>
    <sample id="1068">我们发现，同样地，上下文也支持在合适的形式中翻译。</sample>
    <sample id="1069">最后，我们来看一下高P6MI的个体令牌。这使我们能够识别无法通过单词本身捕捉到的现象，而是通过句法结构表达的，如省略句的解决。</sample>
    <sample id="1070">现在我们使用我们的分析结果来设计文档全球翻译的基准。</sample>
    <sample id="1071">为每一种我们标识的五种讨论现象，我们创建标签机器人来自动标识与现象相关的单词。我们称我们的标签机器人为多语言讨论感知或Muda标签。</sample>
    <sample id="1072">我们还可以注意到不同的语言中这些语言现象的不同比例。</sample>
    <sample id="1073">我们然后使用MudaTaggle将标签应用于要用于评估的平行语料库，并将我们选择的翻译指标应用于MudaTaggle识别出的上下文相关示例。</sample>
    <sample id="1074">最后，我们使用我们的基准测试和其他指标来评估文档级机器翻译模型。</sample>
    <sample id="1075">首先，当我们使用corpus级别指标时，我们发现无上下文模型在蓝色中具有最好的性能。</sample>
    <sample id="1076">但是如果我们使用Comet，那么具有上下文信息的模型性能最佳。如果我们使用F1度量，那么具有或无上下文信息的模型性能相似。</sample>
    <sample id="1077">这个示例再次表明，如果使用_corpus级别指标单独进行评估，很难确定最佳文档级别翻译系统。</sample>
    <sample id="1078">我们使用Mooda基准来评估模型，并发现使用上下文信息的模型比不使用上下文信息的模型在某些对话现象，如形式性和词汇连贯性方面更加准确。</sample>
    <sample id="1079">这些模型在处理椭圆、常年植物和动词形式等现象时，不如不使用上下文的模型那么好。这暗示我们需要在文档级别转换中看到更多的进步。</sample>
    <sample id="1080">我们还比较了不同的商业系统，我们的基准测试结果表明，D-Bel通常比Google Translate更准确地翻译文档级别的内容。</sample>
    <sample id="1081">根据数据驱动的分析，我们在14对语言对中识别出了需要上下文的翻译。</sample>
    <sample id="1082">然后，我们使用我们的发现来建立一个文档级别的机器翻译基准，可以帮助我们识别哪些磁盘跨越现象模型能够很好地处理，哪些翻译系统在文档级别翻译上做得很好。</sample>
    <sample id="1083">谢谢你的关注。下次见在多伦多。</sample>
    <sample id="1084">Yusin Zhang</sample>
    <sample id="1121">名称：Backtracking Algorithm</sample>
    <sample id="1122">The author describes "marked words" as a method to identify the words that distinguish marked groups from unmarked ones.</sample>
    <sample id="1123">University of Washington.</sample>
    <sample id="1124">Prague approach.</sample>
    <sample id="1125">James Finch and Sarah Finch.</sample>
    <sample id="1126">2</sample>
    <sample id="1127">根据文本，数据集可以包括：

* Acceptability judgments
* Grammaticality
* Stereotype judgments (e.g. crowd spares)</sample>
    <sample id="1161">None, the text does not mention the first research question or its methods.</sample>
    <sample id="1162">The model was evaluated on clinical trials and biomedical tests in French.</sample>
    <sample id="1226">CamemBERT was trained on 4 GB of text data.</sample>
    <sample id="1227">Adam Szpirkowski</sample>
    <sample id="1228">Temporal drift.</sample>
    <sample id="1269">To put the tokens in the right order.</sample>
    <sample id="1270">The author suggests increasing transparency about bias mitigation methods because they want to know if the positive stereotypes are due to "weird, overly excessive value alignment" or other "anti-stereotyping methods" that might be causing pernicious patterns.</sample>
    <sample id="1271">最小对不可接受输入（Minimal Pair）是指在语言模型评估中，展示一个可接受句子（grammatical sentence）和一个不可接受句子（ungrammatical sentence），以评估语言模型对可接受句子的概率。</sample>
    <sample id="1272">The author used "weight" and "token" of Pomet Bird, and also mentioned "4 GB" as a metric.</sample>
    <sample id="1273">Interanitator Agreement.</sample>
    <sample id="1274">不可接受查询中。</sample>
    <sample id="1275">The author of this presentation is from the University of Hamburg.</sample>
    <sample id="1276">MultiIntract differs from previous works in that it focuses on instruction tuning for multimodal protein models, rather than language-only tasks.</sample>
    <sample id="1277">1</sample>
    <sample id="1278">I didn't hear anything about binary coordination in the audio clip.</sample>
    <sample id="1279">The average length of the prompt sentence is 4 words.</sample>
    <sample id="1280">These findings suggest that smaller T5 models can generate scripts of higher quality than larger models, indicating that smaller models can support larger models when properly trained on suitable data sites.</sample>
    <sample id="1281">"您好，我是 Yannis Lavraque，我欢迎您来了解我们的研究成果在 Dr. Berth，这是一个在生物学和临床领域的强大模型。"</sample>
    <sample id="1282">"在这次演讲中，我们将讨论一门基于健康的模拟语言。下面，我们将展示我们文章的主要贡献。"</sample>
    <sample id="1283">我们推出了第一个生物医学模型，名为Dr. Berth，基于Roberta，并在NACCHOS中进行了训练，这是一个来自网络的医疗基础数据集。</sample>
    <sample id="1284">我们还引入了多种模型与多种数据源的比较。然后，我们将展示11个生物医学和临床试验的结果，以法语进行。</sample>
    <sample id="1285">"最后，我们对实验结果进行总结，并向您提供关于模型访问的更多信息。"</sample>
    <sample id="1286">自2018年以来，Bert已经成为自然语言处理的更好方法。相比历史的策略和上下文方法，如"查看-向量"或"查看-发送"，Bert提供了更高的性能提高。</sample>
    <sample id="1287">从该模型被适用于其他语言，如法语与Camembert，还有生物医学领域的Père Medbert和Biobird，临床领域的Clinique Albert，但尤其是在英语中。</sample>
    <sample id="1288">由于其他语言的专门模型较为稀缺，且大多基于连续训练，因为缺乏领域内数据。</sample>
    <sample id="1289">然而，法国直到现在还没有开源生物医学模型。</sample>
    <sample id="1290">我们问自己一个问题，关于适合各种使用场景的数据结构。这些当前的数据是临床数据的良好替代品。</sample>
    <sample id="1291">为了回答这个问题，我们将Dr. Bert与我们的舒伯特模型进行比较，这个模型基于我们家医院非传统的匿名数据。</sample>
    <sample id="1292">"我们问自己，需要多少数据来训练专门的法语模型？是 Gb 或更多的 Gb?"</sample>
    <sample id="1293">为了回答这个问题，我们首先训练和比较四个从头开始的模型。一个是 Dr. Bert 的第一版本，它具有 7GB 的自然语言处理能力。另一个是 4GB 的自然语言处理能力。</sample>
    <sample id="1294">"首先是Schubert的原始版本，拥有4GB的医疗记录。最后的版本是Schubert的混合版本，包含4GB的自然语言和4GB的医疗记录。"</sample>
    <sample id="1295">在此之外，我们还引入了三个模型在大陆预训练以分析预训练策略的影响。</sample>
    <sample id="1296">"一个基于 Camembert 杂质的基地，另外一个基于 Camembert 杂质的基地，但是第一个基地的训练数据为 4GB 的自然数据，而第二个基地的训练数据为 4GB 的点击数据。"</sample>
    <sample id="1297">最后，我们基于英语生物医学模型Bermond Bert，并在四个GB的撒切数据集中进行了训练。总共有七个模型。</sample>
    <sample id="1298">"为了评估这六种模型，我们收集了公众出版物和私人专有知识，如认知、分类、旅行、挑战和责任。"</sample>
    <sample id="1299">本模型与6.9模型进行比较，包括Camembert Oscar 138GB、Camembert Oscar 4GB、Camembert CCNet 4GB、Pummet Belt、BioBert和ClinicalBert。</sample>
    <sample id="1300">模型在与训练数据相同性质的数据上表现最好的演进。</sample>
    <sample id="1301">然而，我们可以从多个来源获取数据，并观察到来自异构数据的性能更好。我们还发现，使用更多数据将导致更好的性能。</sample>
    <sample id="1302">总的来说，从零开始返回似乎在大多数任务中取得了更好的性能。</sample>
    <sample id="1303">我们的经验在限制和预测中，使用 Pomet Bird 的权重和 token，处理 4GB 的数据，结果与从头开始使用 Dr. Bert 的结果相似。</sample>
    <sample id="1304">"与基于 Camembert 权重和 tokenizer 的模型不同，它们存在稳定性问题。"</sample>
    <sample id="1305">最后，我们的系统在11个下游任务中获得了9个更好的性能，并且在全球范围内超越了Camembert模型的结果。</sample>
    <sample id="1306">我们也发现，专家数据更好，更多的专家数据更好，但是它不太适合扩展。</sample>
    <sample id="1307">"所有来自NATURES的预训练模型都可以在UginFace上免费获取，所有训练脚本都可以在我们的GitHub仓库中找到。"</sample>
    <sample id="1308">"感谢这次报告。我们期待在多伦多的海报会议中进行讨论。"</sample>
    <sample id="1309">The paper studied four learning strategies from scratch models.</sample>
    <sample id="1310">The adaptive overfitting is not observed.</sample>
    <sample id="1311">We evaluate the quality of the simplified text by using metrics such as ROUGE score, METEOR score, and BLEU score.</sample>
    <sample id="1312">Yes.</sample>
    <sample id="1313">“嗨，我是马蒂亚斯·兰德曼，今天我将为您介绍一篇关于使用多集标记和隐式排列的树形无树组成推广的论文简介。”</sample>
    <sample id="1314">这是与我的顾问亚历山大·科德勒和尤文·蒂托夫的共同工作。</sample>
    <sample id="1315">组合性generalization可以被理解为学习者在训练中看到的单个短语的深度递归和未见过的短语组合能力。</sample>
    <sample id="1316">在语义解析的背景下，对组成泛化的测试可能如下。正如通常情况，我们有一个训练集的 utterances，例如：女孩睡了，玛丽知道女孩睡了。</sample>
    <sample id="1317">这些语音与逻辑表达式对应的意思核心方面。</sample>
    <sample id="1318">与标准机器学习评估不同的是，这个测试集不来自同一分布，但包含结构不相关的形式。</sample>
    <sample id="1319">在这个示例中，模型在训练中见过较浅的递归，并在一个需要更深递归的示例中进行测试。</sample>
    <sample id="1320">无经验的序列到序列模型在这种分布外的泛化中经常遇到困难，通常生产的输出与输入脱节。</sample>
    <sample id="1321">特别是，他们经常无法复制输入和输出之间的系统对应关系，如示例中使用的颜色编码。</sample>
    <sample id="1322">使用树形结构来解决这个问题是一种流行的方法。</sample>
    <sample id="1323">树木旨在捕捉语句与逻辑形式之间的组成过程。</sample>
    <sample id="1324">这工作效果不错，但树通常不提供需要获取某种方式。</sample>
    <sample id="1325">这是一个复杂的过程，需要考虑大量的计算开销。通常情况下，这涉及到形式化逻辑形式的预处理，例如处理变量符号。</sample>
    <sample id="1326">获取树也可能涉及到专门的语法归纳程序。</sample>
    <sample id="1327">在这篇论文中，我们不使用树形结构，引入了一个直接将输入片段与输出片段之间对应关系的神经序列到序列模型。</sample>
    <sample id="1328">首次展示了不依赖树形结构的深度递归泛化。</sample>
    <sample id="1329">我们的方法预测输入的输出有两步。</sample>
    <sample id="1330">首先，我们将每个输入token标记为输出中出现的无序多集token。</sample>
    <sample id="1331">我们已经取得了所有正确的token，但是它们没有排序。</sample>
    <sample id="1332">我们在第二步中使用另一个模型来预测一个排列，来将其置于正确的顺序中。</sample>
    <sample id="1333">我们引入了一种新的方法来预测一个排列，而不对可能的排列施加任何硬约束。这使我们的方法非常灵活和表达式。</sample>
    <sample id="1334">概念上，我们的排列模型大致工作方式如下。</sample>
    <sample id="1335">我们从左到右遍历输出，并确定每个位置的multiset token。对于第一个输出位置，我们简单地选择红色标记的那个。</sample>
    <sample id="1336">然后，我们跳到下一个多个token以确定输出的第二个token。</sample>
    <sample id="1337">我们根据类似的方法确定输出中的第三个 token，然后跳到另一个多 token 中继续这个过程。</sample>
    <sample id="1338">直到第一阶段中的每个标记都被访问了一次。</sample>
    <sample id="1339">为了给您展示实验结果的预览，我们将我们的方法与CONG的基准库中的其他无树模型进行比较。我们的模型在更深的递归中对其他模型的泛化性能取得了很大的优势。</sample>
    <sample id="1340">一些结构化的通用化仍然很困难。</sample>
    <sample id="1341">我们在论文中解决了几个有趣的技术挑战。</sample>
    <sample id="1342">首先，训练数据中没有给出输入和输出的对齐信息。因此，对于一个给定的token，我们不知道它来自于哪个cell，这对训练造成了一定的挑战。</sample>
    <sample id="1343">此外，有时存在多个与数据相符的排列，但是语言正确的一种是隐含的。我们通过在训练中引入对齐来解决这个问题。</sample>
    <sample id="1344">我们的排列方法非常灵活，但它带来的挑战是找到最高分排列是NP困难的。这与旅行商贩问题相关。</sample>
    <sample id="1345">我们使用GPU友好的连续放松方法来近似这个问题，同时也可以通过解决方案反向传播以学习更加语言上更加可靠的排列。</sample>
    <sample id="1346">如果您想了解我们的实验和我们如何解决这些挑战，请查看我们的论文或来到我们的邮局。</sample>
    <sample id="1347">Cognitive dissonance is two beliefs or actions that are inconsistent.</sample>
    <sample id="1348">GPT-4 is the most liberal language model.</sample>
    <sample id="1349">Yes, according to the text, cumulative training is found to be equal to or better than iterative training across the board.</sample>
    <sample id="1350">Sara Pappi</sample>
    <sample id="1351">From TED Talks transcripts translated into 14 different languages.</sample>
    <sample id="1385">Mathias Landemann</sample>
    <sample id="1386">Cross-lingual zero-shot and field-short transfer refers to training a model on one source language and transferring it to another language without additional training data for the target language, with the goal of predicting SQL output.</sample>
    <sample id="1387">Salant University.</sample>
    <sample id="1388">The author used two delay measurement methods: latency measure and computational aware average lagging.</sample>
    <sample id="1389">"大家好，我是 Akshita，今天我和我的合著者 Martin 将展示我们的作品，KITSMA测试，评估来自多个来源的知识整合。这项工作是 McGill 大学、Miele 和微软研究机构的合作。"</sample>
    <sample id="1390">国家语言理解模型依靠多种知识来源，例如其参数中包含的知识，通常通过预训练获得，以及在推理时提供的知识。</sample>
    <sample id="1391">最新的任务，如问答任务，显示模型可以使用预训练的时间知识来解决任务。</sample>
    <sample id="1392">"自然语言理解通常需要在推理时提供的知识。"</sample>
    <sample id="1393">例如，在句子中，约翰在电视上看到新当选的总统。</sample>
    <sample id="1394">预训练的参数可能包含关于总统和电视的信息，但是它们不能可靠地知道这个实例特定的实体John或新的总统，因为总统可能已经变更了自预训练时。</sample>
    <sample id="1395">因此，对于知识密集型NLU任务，需要能够整合和使用预训练的时间知识和推理时间知识的模型。</sample>
    <sample id="1396">在这项工作中，我们提出了一套知识集成诊断测试套件。</sample>
    <sample id="1397">我们介绍了一项核心引用解决方案，以测试不同来源中的知识吸收能力。我们对数据集进行了人类研究部门和已经建立的核心引用解决模型的评估。</sample>
    <sample id="1398">“我们的数据集中有一個例子。Serving是法官，Here是面包师。Serving和Kya在公园遇见。法官一天工作结束后，在法院裁决案件，非常高兴放松。”</sample>
    <sample id="1399">任务是确定代词“he”所指的实体，这里是7。</sample>
    <sample id="1400">根据仆人是服务对象的知识，以及法官在法庭上裁决案件的背景知识，解决一个名词需要两个类型的信息。</sample>
    <sample id="1401">通常，背景知识是在大语言模型的预训练阶段学习的，而实体特定的知识通常是在推理时观察到的。</sample>
    <sample id="1402">我们对这两个信息的可用性进行了变化，以便它们可能出现在单个来源中或多个来源中。</sample>
    <sample id="1403">我们已经定义了三个KITMOS设置。首先，我们需要进行背景预训练。预训练时假设背景知识已经可用。</sample>
    <sample id="1404">第二，存在背景设置。背景知识既可以在预训练时间中可用，也可以在影响时间中可用。最后，还有背景影响设置。在影响时间中，只有这两种知识类型可用。</sample>
    <sample id="1405">最后这个设置尤其有趣，因为它模拟了一种情况，即解决任务所需的背景知识不在模型的预训练数据中，例如，因为新职业自预训练以来出现了。</sample>
    <sample id="1406">"我们这里有一个控制真实来源中的事实可用性的示例。"</sample>
    <sample id="1407">背景预训练中，我们假设政治家在政府中寻求席位的背景知识已经包含在预训练的参数中。在非频繁时间背景下，我们提供了反特定知识切斯特是政治家。</sample>
    <sample id="1408">在后台设置中，我们还提供了非特定的后台知识，也就是说，我们还提供了关于政治家的背景信息在影响子文本中。</sample>
    <sample id="1409">背景中在自由环境中，我们提供高效的职业，替代政治家，因为职业不太可能包含在预训练期中。</sample>
    <sample id="1410">我们在人工研究参与者中评估数据集，并建立了同位点解析模型。在这个图中，我们展示了背景预训练设置中最好性能的模型的结果，这是一个困难的变体。</sample>
    <sample id="1411">"通过 KITMOS 的任务特定训练，两个监控器都没有表现很好。但是，当在 KITMOS 中进行训练时，C2F 和 BFQF 的性能明显优于随机选择。"</sample>
    <sample id="1412">当使用 Lushen 数据集进行训练时，模型会学习到表面队列，这些队列在测试时在 KITMOS 中没有用处。</sample>
    <sample id="1413">根据额外的虚构知识实验表明，即使是最好的模型也不能可靠地在影响时间提供的反向知识中整合。</sample>
    <sample id="1414">总结我们的论文主要观点，许多coreference-to-volution模型在不同来源知识上无法进行推理，不过在任务特定的训练中一些模型可以成功地整合来自多个来源的知识。</sample>
    <sample id="1415">"即使是最好的模型也似乎在推断时无法可靠地整合仅在推断时提供的反向知识。如果您想了解更多细节，请查看我们的论文，并在 GitHub 上查看代码。感谢您的关注。"</sample>
    <sample id="1416">Based on the given text, the disadvantages of tree-based methods are:

* Obtaining trees can be a complicated and computationally expensive process
* It typically involves considerable formalism-specific pre-processing of logical forms to handle variable symbols
* It may also involve specialized grammar induction procedures.</sample>
    <sample id="1417">The author of the paper "Do Connell 2003 named entity taggers still work well in 2023" is Xu Heng.</sample>
    <sample id="1418">"嗨，我是 Myra，今天我将讨论我们的论文《标记人格》，使用自然语言提示来衡量语言模型中的刻板印象。这项工作是与Essen Dermush和Dan Jerovsky合作完成的。"</sample>
    <sample id="1419">"近年来，许多人已经记录了大型语言模型（LLMs）中的社会偏见和刻板印象的普遍存在。"</sample>
    <sample id="1420">然而，这些措施都有其局限性。它们通常基于手工构建的数据集，这些数据集需要花费很长时间来收集。</sample>
    <sample id="1421">他们通常只测量非常特定的刻板印象，这意味着它们不太适合其他群体或背景，也只是捕捉到特定的、广泛的关联，例如对某些群体的负面关联。</sample>
    <sample id="1422">此外，许多在这个领域的工作都没有考虑 intersectionality，这是一种观念，即多重社会身份可以叠加偏见，并且是独特的痛苦来源。</sample>
    <sample id="1423">为了克服这些限制，我们依靠这些更新的指令调整LLM非常擅长响应指令和提示的特性。</sample>
    <sample id="1424">我们可以让模型生成一个角色，这是一个关于想象中的个体，使用提示来描述自己，例如“像一个亚洲女性，描述自己”。</sample>
    <sample id="1425">我们可以立即看到，这个结果非常适用于任何人群，因为我们可以将任何身份标记输入这个提示中。</sample>
    <sample id="1426">以下是 GPT-4 的一些示例生成结果。</sample>
    <sample id="1427">我们立即看到，这些输出并不是传统意义上的负面或毒性语言。</sample>
    <sample id="1428">有趣的模式。</sample>
    <sample id="1429">亚洲女性被描绘成谦卑的样子。中东女性被称为exotic，指称迷人的地区。</sample>
    <sample id="1430">她说：两个黑人女性角色提到祖先，而白人男性角色则没有。</sample>
    <sample id="1431">为了捕捉这些模式，我们的方法有两个部分。第一部分是生成这些个体形象。</sample>
    <sample id="1432">“我们的灵感来自于一项研究，其中他们将这些提示给人类参与者，发现这些提示也能够激发种族刻板印象。”</sample>
    <sample id="1433">"这也使得我们生成的角色与人类编写的回应进行直接比较。"</sample>
    <sample id="1434">"第二部分是标记词语，这是确定标记组与我们的标记组的方法，我将很快详细解释。"</sample>
    <sample id="1435">我们可以通过这样做来获得非常明确的刻板印象和模式，而不需要依赖特定的词汇。</sample>
    <sample id="1436">根据语言社会学的概念，标记语言方法是基于标记性说法的，这个说法认为有一个默认的无标记状态，而任何与该默认状态不同的是则是语言上标记的。</sample>
    <sample id="1437">例如，对于男人来说，「战士」这个词通常是男性的象征。因此，当人们描述女性战士时，他们通常会加上「男人」一词，例如「男人战士」。</sample>
    <sample id="1438">社会中的主要群体通常都是语言和社会上无标记的，而被 marginalize 的群体通常都是标记的。</sample>
    <sample id="1439">我们首先确定未标记和标记的组别。</sample>
    <sample id="1440">然后，我们使用打斗词法来比较这些个性，基本上是使用加权对数比率来区分每个标记组的主要词语。</sample>
    <sample id="1441">例如，对于黑人女性的角色，我们将比较法庭法规的比率与白人男性和男性角色，因为这两个组是对应的未标记组。</sample>
    <sample id="1442">现在是结果时间。我们首先使用了一个词汇典，发现生成的角色中包含了更多的ereotype，而不是人类写的角色。</sample>
    <sample id="1443">然而，当我们实际查看词汇的分布时，我们发现了完全不同的结果。</sample>
    <sample id="1444">生成的角色拥有更高的luxon词频率，而人类写的角色拥有更广泛的词汇分布，而生成的角色中出现的刻板印象词语仅限于“高”和“ athletic”。</sample>
    <sample id="1445">"只需要正面或中立的结果。"</sample>
    <sample id="1446">"事实上，Sexycon并没有捕捉到早期幻灯片中看到的许多有害模式。因此，我们将转而使用标记词语的结果来展示这些看似积极的词语如何 facilitestereotypes和essentializing narratives。"</sample>
    <sample id="1447">我们的分析表明，这些貌似积极的刻画反映了有害的模式。</sample>
    <sample id="1448">首先，对于标记群体，前十名词包括文化、传统、自豪和异国风情等。这些词语仅仅是根据这些群体与其身份的关系来定义它们，并将其与白人标准区分开来。</sample>
    <sample id="1449">这件事对这些群体造成了长期的歧视和他者化。</sample>
    <sample id="1450">此外，这些词汇中还存在许多常见的模式，特别是对有色女性。例如，描述拉丁美洲妇女的词汇中包括如“活泼”和“曲线优美”等。</sample>
    <sample id="1451">“这些词语与热带主义相连。对于亚洲女性，这些词语是像“小巧”、“细腻”、“柔软”等。”</sample>
    <sample id="1452">"[她]与亚洲女性长期被性化、被看作非常温顺和顺从等的历史联系起来。"</sample>
    <sample id="1453">"最后，我们看到黑人女性中最常用的词语是强大和坚韧的。"</sample>
    <sample id="1454">[00:00:01 - 00:00:08]这个概念与人们所谓的黑色女性原型相关联。虽然听起来可能是积极的，但实际上却有其负面的一面。</sample>
    <sample id="1455">“研究表明，这种archetype实际上对这些群体施加了很大的压力，使他们被迫在社会障碍面前展现出坚强的抗压能力。”</sample>
    <sample id="1456">"因此，而不是真正地努力改变这些障碍，它们对这些人施加压力，这对这些人来说会导致非常不良的健康结果等其他不良后果。"</sample>
    <sample id="1457">我们发现，每个标记组的词语基本上只是反映非常基本的叙述。</sample>
    <sample id="1458">根据这些模式，我们对模型所有者提出三个建议。</sample>
    <sample id="1459">我们作为研究人员，应该首先解决正面刻板印象和必然化叙述。我们也应该使用交叉性分析的方法来研究偏见和伤害，因为如果不这样做，可能会遗漏一些东西。</sample>
    <sample id="1460">"最后，应该对偏见减少方法进行公开透明化。"</sample>
    <sample id="1461">因为例如，这些正面刻板印象，我们不知道是否是因为某种奇怪的原因。</sample>
    <sample id="1462">「存在过度的价值观对齐或其他反对刻板印象的方法，导致这些不良的模式。」</sample>
    <sample id="1463">我们不能做出任何假设，也不能深入研究，需要更多的透明度。</sample>
    <sample id="1464">"谢谢你的聆听。祝你有一个愉快的时间。"</sample>
    <sample id="1465">"大家好，我来自中国科学技术大学，是名为静伟伊。"</sample>
    <sample id="1466">"我很高兴为您提供关于纸张的短广告视频。你是否正在复制我的模型？保护大语言模型的版权，嵌入和服务的后门水印。"</sample>
    <sample id="1467">让我们首先介绍一下邀请我们的服务背景。</sample>
    <sample id="1468">现在，如GPT、Lama和Palm等大型语言模型在自然语言理解和生成方面都做得非常出色。</sample>
    <sample id="1469">"嵌入式服务是基于大语言模型的一种服务，可以帮助完成多种NLP任务。"</sample>
    <sample id="1470">例如，打开我们的优惠或GPD基于batting API。</sample>
    <sample id="1471">然而，近期的研究表明，攻击者可能通过学习嵌入来盗取模型，并提供相似服务。因此，保护嵌入的版权是必要的。</sample>
    <sample id="1472">为了保护嵌入服务的版权。其中一种解决方案是将水印嵌入提供服务，并检测另一个服务是否包含水印。</sample>
    <sample id="1473">水印方法需要满足以下属性。首先，该方法应该适用于嵌入服务。其次，水印不应该降低嵌入提供的实用性。</sample>
    <sample id="1474">第三，水印应该足够隐蔽，以免攻击者轻易删除水印。</sample>
    <sample id="1475">最终，水资源将被输送到攻击者的服务中，以便在模型提取过程中使用。</sample>
    <sample id="1476">现有作品可以广泛分类为四类。</sample>
    <sample id="1477">然而，这种方法对于嵌入式服务或不可移植。</sample>
    <sample id="1478">因此，我们在这篇论文中提出了一种嵌入标记，适用于嵌入服务的后门水印方法。</sample>
    <sample id="1479">然后，让我介绍我们的嵌入标记细节。嵌入标记包含两个主要步骤，水印注入和版权验证。</sample>
    <sample id="1480">我们首先选择一个触发集。触发集是一个中频率的词组。</sample>
    <sample id="1481">我们假设服务商可以收集通用文本语料并对词频进行计数。</sample>
    <sample id="1482">在水印注入中，我们首先定义了一个目标 bedding。当用户将句子发送给服务提供商时，服务提供商将在句子中计数触发器的数量。</sample>
    <sample id="1483">该提供的嵌入是目标嵌入和原始嵌入的加权和。</sample>
    <sample id="1484">根据句子中触发器的数量，目标投注的重量是成比例的。当句子中的触发器数量大于 m 时，提供的嵌入式等于目标投注。</sample>
    <sample id="1485">"版权验证是检测另一个服务背后的模型是否包含商标。"</sample>
    <sample id="1486">我们首先构建一个后门和良性数据集。后门数据集中的所有句子都包含trigger set中的词语，而良性数据集中所有句子中的词语都不包含trigger set中的词语。</sample>
    <sample id="1487">"然后，提供商需要从Stealer服务获取嵌入向量数据集。"</sample>
    <sample id="1488">"计算了请求的嵌入向量和目标嵌入向量的余弦相似度和L2相似度。然后，我们计算了null数据集和backdoor数据集之间的相似度差异，这是一个delta余弦和delta L2。"</sample>
    <sample id="1489">“与此同时，我们还应用KSTest，并将其p值作为第三个指标。”</sample>
    <sample id="1490">我们对四个数据集进行实验，包括AG News、Mind、SSD2和AresVam。我们假设使用Wikitext数据集来统计词频。</sample>
    <sample id="1491">四个数据集的结果表明，我们的嵌入标记可以在保持下游任务utility的情况下取得很高的检测性能。</sample>
    <sample id="1492">我们还验证了提供的嵌入的隐蔽性，通过在四个BOPCA数据集上可视化句子的嵌入。图例中的数字表示每个句子中的触发器数量。</sample>
    <sample id="1493">根据图表，难以区分背门嵌入和正常嵌入。</sample>
    <sample id="1494">"谢谢。我们下面讨论。"</sample>
    <sample id="1495">ABC-Eval represents annotating behaviors in chat.</sample>
    <sample id="1496">According to the audio, the performance drop is caused by temporal drifts, but not adaptive overfitting. Therefore, there is no mention of the performance increment between CoNLL-2003 and CoNLL++ exceeding 5 percentage points.</sample>
    <sample id="1497">[00:00:01] 嗨，我是 Vasudha， Stony Brook 大学计算机科学博士候选人。我想介绍我们在 ACL 2023 上被接受的长篇论文，主题是基于迁移学习的不和谐检测，解决稀有类别挑战。</sample>
    <sample id="1498">我们从定义认知不一致开始，并解释为什么它是语言研究中的一个重要问题。简单来说，认知不一致是指两个信仰或行为之间的不一致。</sample>
    <sample id="1499">她说的是像这样的一种情况，即一个人说出“我知道烟草可能会杀死我”，然后接着说“我在会议后抽了一两根烟”。这种信念和行为不一致，存在距离。</sample>
    <sample id="1500">我认为我不能不靠他们来做我的工作，所以第二次出现是有道理的，他们之间有着常态的关系。</sample>
    <sample id="1501">在日常决策中，失调现象非常常见，但是它们很少在语言中表达其他风险振荡中。</sample>
    <sample id="1502">那么为什么这件事重要？从认知距离出发可以帮助我们理解不同人的不同意见，跟踪记录群体中的趋势、信仰价值观和态度变化。</sample>
    <sample id="1503">高认知不协和也与焦虑障碍相关，可以帮助更好地理解人们的mental health。</sample>
    <sample id="1504">学习距离在语言中表达也可以有助于理解极端化和脆弱群体的极化。</sample>
    <sample id="1505">最后，认知不一致对理解个体认知风格和决策过程非常重要。</sample>
    <sample id="1506">为实现认知不协调资源，我们对不协调关系进行了大规模注释。我们使用了不协调的首先方法，如图表所示。</sample>
    <sample id="1507">通过PDTB解析器将推特消息，并根据我们的论文中描述的指南对对话单元进行标注。</sample>
    <sample id="1508">根据这里可以看到，离散性只有在3.5%的注释对中被发现。</sample>
    <sample id="1509">我们收集了1000个对话单元对，然后对仅有43个disnets的初始分类器进行了训练。没什么意外，这个分类器的性能不超过随机水平。</sample>
    <sample id="1510">由于低频率的不协和音和无前例数据集，我们面临着绝对稀有问题。</sample>
    <sample id="1511">为了解决这个问题，我们对组合式迁移学习和active学习进行实验，以便在较少的标注运行中收集更多的不协调样本，从而降低总体标注成本，同时提高不协调检测性能。</sample>
    <sample id="1512">从初始模型无法捕捉不协和类别开始，我们通过将权重从相关任务转移，以启动active learning过程。</sample>
    <sample id="1513">我们从两个不同的任务转移到了一个独立的任务，即无关主题的分类任务，这是一个任务，它无论主题不同，判断两个来自不同人的辩论语句是否相符或相反。</sample>
    <sample id="1514">“我们在这里和二元分类的扩展和比较类别中进行了讨论，因为这两个概念与辅音和不和谐的概念紧密相关，我们在这里称其为CE。”</sample>
    <sample id="1515">我们发现，在将零短期性能应用到注释数据集中，已经优于随机猜测，AUC达到0.62。</sample>
    <sample id="1516">我们进一步在两个任务上迭代微调，发现在CE任务微调后再次微调可以获得更好的零样本性能。因此，这是我们用来启动active learning的模型。</sample>
    <sample id="1517">下一个，我们确定更新模型以从每轮活动学习和注释的新数据的最佳方法。累积器累积到目前为止所有活动注释所收集的所有数据，而迭代更新模型是对最新收集的数据集进行训练。</sample>
    <sample id="1518">我们发现，累积式策略与迭代式策略在所有方面的性能都相等或更好。</sample>
    <sample id="1519">下一个，我们使用概率稀有类策略（PRC）来选择当前模型在每轮错误中最可能是不协调的示例，以提高不协调示例的数量。</sample>
    <sample id="1520">我们将其与社区中常用的AL策略进行比较。</sample>
    <sample id="1521">我们发现提议的PRC策略比其他state-of-the-art策略更好，尽管差异不大。需要注意的是，随机性能明显较低。</sample>
    <sample id="1522">在对AL的进一步的尝试中，我们使用了两种最好的策略，提高了距离分类的AUC为2.75，这是我们迄今为止在该任务上的最佳表现。</sample>
    <sample id="1523">我们还检查了每种策略对注释质量和标注员成本的可行性。我们发现，PRC在稀有类别中具有最高的不协调性，也是对标注员来说最难的。但是，标注员也发现了示例难以理解。</sample>
    <sample id="1524">总之，我们发现 PRC 是一种简单的 AIL 策略，对于稀有类别的获取和寒冷启动 AIL 可以通过适当设计的迁移学习任务来大大帮助。</sample>
    <sample id="1525">我们还发现，迭代更新对于从不同领域的转移学习非常有用，而域内活动注释则从累积更新中受益。</sample>
    <sample id="1526">这些是我们的代码、数据集和论文的链接。欢迎您随时与我们联系，如果您有任何问题。感谢。</sample>
    <sample id="1527">Matthias Lendemann.</sample>
    <sample id="1528">Si Yu-Yuan</sample>
    <sample id="1529">4</sample>
    <sample id="1530">The method compares with a state-of-the-art architecture specifically tailored for speech-to-text (not steam-on-thigh-respirations) translation.</sample>
  </task>
</testset>