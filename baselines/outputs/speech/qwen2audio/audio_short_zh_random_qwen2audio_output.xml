<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">主要数据来源是大规模的网络爬虫数据，包括政治新闻媒体。</sample>
    <sample id="1">这篇论文的作者来自墨尔本大学和微软研究。</sample>
    <sample id="2">德文本分析新语法库的介绍。</sample>
    <sample id="3">我的名字是Regina Stern，我将指导您完成第一个部分的演示。首先，我们来定义文本简化。</sample>
    <sample id="4">文本缩写是将文本适应特定目标群体以提高理解的过程，例如为母语为非英语的人士阅读问题而进行的文本缩写。</sample>
    <sample id="5">为了训练文本分类模型，我们需要成对的文本，例如文档或句子。</sample>
    <sample id="6">例如，你可以看到一个复杂的德语句子及其对应的简单语言翻译。</sample>
    <sample id="7">这个句子的意思是：'例如，可以使用不同的技术，如词汇替换、句法消歧、句法消歧、重排或单词插入。'</sample>
    <sample id="8">我们提议使用新的Cortical City plane，因为在过去的几年里，现有的Cortical City plane存在一些问题。例如，这个Cortical City plane太小了，无法训练一个用于分类的模型。</sample>
    <sample id="9">其他三个近年来提出的模型都是自动对齐的，这意味着它们在对齐时可能会出错。</sample>
    <sample id="10">因此，我们提出我们的新核心平面，它被分为两个子系统：dplane API和dplane Web。dplane API是基于消息文本的。</sample>
    <sample id="11">在DeepPlan API中，我们手动将四百八十三个文档全部配对。结果大约是三万一千到三万一千五百个平行句子对。</sample>
    <sample id="12">这段音频的内容是：'对于DeepFaceWeb，这个目录包括不同的域，并且我们还手动为所有这些七百五十个文档分配了权值，另一方面则使用自动配准方法。'</sample>
    <sample id="13">总共获得30450个句子对。</sample>
    <sample id="14">我们在句法分析上对句子对进行了更多的分析。例如，在类型标注方面。</sample>
    <sample id="15">如您所见，圣经文本比新闻文本或语言学习者文本要强得多。</sample>
    <sample id="16">在所有级别上，例如词汇标注、结构标注以及语义标注。</sample>
    <sample id="17">此外，您还可以看到我们的deplane corpus具有高比例的差异标识转换。例如，在deplane API corpus中，我们有比在deplane web corpus中更多的重新排序和文字添加。</sample>
    <sample id="18">另一方面，在网络课程中，我们会遇到更多的省略句。</sample>
    <sample id="19">这段音频的原始内容是：'so let's now see what we can do with this corpus. hello, i'm omar and now i will talk about the use cases for our dataset dplain. so for the first use case, we can evaluate automatic alignment methods.'</sample>
    <sample id="20">近年来，有很多对齐方法，但在机器翻译的背景下。</sample>
    <sample id="21">这段音频的内容是：'我们在两个平行文档中都有句子，我们想要在post文档中提取句子对齐。'</sample>
    <sample id="22">在我们的使用案例中，我们尝试从两份相似但复杂程度不同的文档中提取对齐的句子。这两份文档的语言和内容都是相同的。</sample>
    <sample id="23">现在我们有了带有手动对齐句子的数据集，我们可以使用这些句子作为 gold standard 来评估一些提出的对齐方法。</sample>
    <sample id="24">我们对提议的方法做了一些调整，并且已经发表了所有这些调整和运行实验的代码。</sample>
    <sample id="25">在最后，我们总结出用于德文文本简化的最佳自动对齐方法是Mass Align方法。</sample>
    <sample id="26">你也可以在纸张上找到运行这个方法的代码。</sample>
    <sample id="27">演讲者说的是：'我们在论文中展示的第二个用例是自动文本简化。'</sample>
    <sample id="28">通过微调语言模型来简化复杂文本</sample>
    <sample id="29">我们有两个不同的模型：一个是长距离输入模型，用于生成文档级别的简化版本。</sample>
    <sample id="30">我们还对正常基础进行了微调，使其能够产生句级简化。</sample>
    <sample id="31">你还可以在论文中找到所有检查点，并且可以查看更多细节，包括评分和评估指标。</sample>
    <sample id="32">我们得出了这样的结论：基本的微调可以产生比基线分数更好的分数。</sample>
    <sample id="33">我们提出这些结果作为自动文本简化问题未来发展的基线基准。</sample>
    <sample id="34">非常感谢您的关注，我们希望在会议上见到所有的人。谢谢。</sample>
    <sample id="35">演讲者的名字是Kay O Yen。</sample>
    <sample id="36">T5 large model。</sample>
    <sample id="37">是的，CoNLL-2003标注器在2023年仍然有效。</sample>
    <sample id="38">该方法通过明确标注每个模型响应是否表达特定行为，例如提供不相关的信息或自相矛盾，来减少人类评估的主观性。</sample>
    <sample id="39">现有的弱监督方法在很大程度上依赖于清洁验证样本。</sample>
    <sample id="40">多种措施可以提高分数，包括认真阅读题目、使用额外资源、练习和复习等。此外，还可以尝试主动参与课堂活动，与老师和同学交流互动，这有助于更好地理解课程内容并提高分数。</sample>
    <sample id="41">两位</sample>
    <sample id="42">我的名字是阿德姆·斯皮里科夫斯基，这个演讲是关于协调中心的依赖结构。</sample>
    <sample id="43">正如您可能知道的，不同的理论和方法论会假设不同的依赖结构，例如在普遍依赖性中，坐标依赖性、协调依赖性和Maggie依赖性的结构是这样的：</sample>
    <sample id="44">是的，第一个共轭是整个坐标结构的头部。所以，在这种情况下，Lisa。</sample>
    <sample id="45">在伊戈尔·米特罗维奇的“意义文本理论”中也采用了类似的方法，其中整个坐标结构由第一个谓词引导。所以这两种方法是等价的。它们将一个谓词单独提出来。</sample>
    <sample id="46">现在也有一些对协调结构的对称方法，例如普拉格方法、连接头方法、氢化物依赖性族树和由连接体引导的协调结构。</sample>
    <sample id="47">所以，我们从端到所有连接器获取依赖项。</sample>
    <sample id="48">最后，还有多头策略，例如在卡特尔单词语法中使用。</sample>
    <sample id="49">假设所有行为都是协调结构的头，所以我们从 governor 获得依赖关系，这里 loves 到所有行为分别地。这是部分完成的。</sample>
    <sample id="50">他们的目标是为对称结构，例如这两个，以及反对称结构，例如这些，提出一个新的论点。</sample>
    <sample id="51">好的，这个论证是基于独立选择权原则的，我将会根据这些例子来解释这个原则。</sample>
    <sample id="52">所以，你可能知道，在英语中，直接对象倾向于靠近动词，而附加物则可能更远一些。例如， March read it yesterday 是好的，因为直接对象 it 是一个靠近动词 read 的单词。</sample>
    <sample id="53">三月读的东西比昨天差得多，因为，在动词和直接宾语之间有一个冠词“i”。</sample>
    <sample id="54">这段音频的原始内容是：'然而，当直接对象非常大且很长时，此效果可能会得到缓解，因为此时它可以移动到代理之后。'</sample>
    <sample id="55">这在这里说明了。所以这两个句子都是好的。马奇昨天读了一本关于蜜蜂的绝对有趣的书。它是好的。无论如何，而不是它，我们有这个长音符和p。</sample>
    <sample id="56">但是，你也可以昨天说'March red'，这是一本关于蜜蜂的绝对有趣的书。</sample>
    <sample id="57">所以这里的理由是，这是可能的，因为尽管这个句子违反了语法原则，即直接宾语应该紧跟在动词之后，但情况并非如此。</sample>
    <sample id="58">它满足了依赖长度最小化原则，该原则指出更短的依赖关系更可取。</sample>
    <sample id="59">所以，这两大树仅仅显示了这两个结构中关键依赖性的长度，即在两个结构间不恒定的那些依赖性。</sample>
    <sample id="60">所以，这里我们有从红色到长度为7的附加项测量向内，以及从红色到长度为4的书本测量向外。所以总共有11个。</sample>
    <sample id="61">当你移动，交换这两个成分时，这两个依赖性的和变为6，对吗？所以不是11，而是6要短得多。这就是为什么这听起来相当合理，对吗？它违反了一个原则，但满足了另一个。</sample>
    <sample id="62">好的，所以我们在增强版本的pontificate中提取了关于协调的一些统计数据，并且查看了论文《为什么我们不使用普遍依赖性》。</sample>
    <sample id="63">这些统计数据是否证实了之前多次提出的观察结果：左连接词通常更短？因此，盐、胡椒和不含盐的调味品按字母顺序测量时会怎样？</sample>
    <sample id="64">以及通过观察得出的一个趋势，即这种增长随着长度差的变化而变化。</sample>
    <sample id="65">所以，当两个连接词的长度差增大时，较短的连接词更喜欢作为第一个出现，对吗？所以比例是左边较短连接词的比例更大。</sample>
    <sample id="66">但这份文件中值得注意的是，我们观察到这种趋势只在左翼政府缺席时才会发生。</sample>
    <sample id="67">好的，这个例子中州长在左边。</sample>
    <sample id="68">第二个例子中，Homer来了并且打了一个喷嚏。这里有两个动词，并且没有外部的控制者。所以，在这种情况下，左连接词更倾向于被缩短。而且，这使得两个单词之间的区别更大。</sample>
    <sample id="69">然而，当右翼政府（例如拉夫特）统治时，这种效果就消失了。</sample>
    <sample id="70">所以，我们通过测量字符长度来确定第一列是音节数，第二列是中文字数，第三列是单词数。所以我会专注于第三列。</sample>
    <sample id="71">左声道中我们听到的是：'当我们左边的盖子打开时。'</sample>
    <sample id="72">左连词比右连词短这种趋势随着词汇量的绝对差异而稳定增长，这一点在没有使用任何连词的句子中也可以观察到，但在使用了右连词的句子中则这种趋势会消失。</sample>
    <sample id="73">我们在论文中展示了这一点，即反对合作结构中的非对称性。我们将这两个非对称结构与作为类比的对称结构进行了对比。</sample>
    <sample id="74">所以查看一下文件，里面有完整的协议和议程，然后在会议后跟我们谈谈。谢谢。</sample>
    <sample id="75">两位</sample>
    <sample id="76">圣经文本比新闻文本或语言学习者文本的简化程度更大。</sample>
    <sample id="77">偏好较短左并列词的例子是“so salt and pepper not pepper salt”。</sample>
    <sample id="78">是的，你可以使用这些模型来你的研究。</sample>
    <sample id="79">DEplain-apa 中包含基于新闻文本的内容。</sample>
    <sample id="80">更好的模型架构、更大的模型尺寸以及更多样化的示例都有助于良好的泛化。</sample>
    <sample id="81">通过测量每个单词在字符数上是否小于等于五个。</sample>
    <sample id="82">通过测量句子中单词的长度来研究支配词的位置影响。将文本分为三列，分别统计左、中、右半部分的单词数及字符数，并观察左右两侧是否有显著差异。</sample>
    <sample id="83">基线分类器的表现并不理想，没有比随机猜测好很多。</sample>
    <sample id="84">一位</sample>
    <sample id="85">对话中提到了Bob和Alice两个角色。</sample>
    <sample id="86">在形式ality和语法黏着性方面，语境感知的 MT 模型比语境无关的模型表现更好。</sample>
    <sample id="87">cosinna</sample>
    <sample id="122">该框架通过收集和分析不同标注器注释的数据来量化立场。</sample>
    <sample id="155">他们能够表面种族成见。</sample>
    <sample id="156">此研究使用了增强版的Pentree Bank和一篇论文。</sample>
    <sample id="157">一位</sample>
    <sample id="158">与认知失调密切相关的任务包括话题独立的辨析分类，以及二进制分类的声韵扩展和比较。</sample>
    <sample id="159">一位</sample>
    <sample id="160">一位</sample>
    <sample id="161">这个框架通过比较模型和数据集中的最终用户来标注器的一致性，而不仅仅是关注标注器的一致性或建模。</sample>
    <sample id="162">{'比较设置': '使用语料库生成的 persona 和人类写的 persona 在刻板词汇上有多大的重叠？'}</sample>
    <sample id="163">比较了不同的商业系统，包括Google Translate。</sample>
    <sample id="164">我是张冰，华盛顿大学的博士生。今天我将介绍我们从预训练数据到语言模型，再到下游任务的工作。跟踪政治偏见导致不公平NLP模型的踪迹。</sample>
    <sample id="165">语言模型是基于大规模网络爬虫数据训练的。</sample>
    <sample id="166">政治新闻媒体在预训练数据中得到了很好的覆盖。据c4项目的一项调查，纽约时报、洛杉矶时报、卫报、赫芬顿邮报等都涵盖了语言模型训练的数据。</sample>
    <sample id="167">这为语言模型应用创造了一种混合祝福。</sample>
    <sample id="168">一方面，他们能够从多样性的视角中学习，这庆祝了民主和多元思想。另一方面，这些不同的政治观点本质上是有社会倾向的，并可能导致下游任务应用中的公平问题。</sample>
    <sample id="169">我们提议从预训练数据到语言模型再到下游任务来调查政治偏见传播管道，具体来说我们将提出以下问题：</sample>
    <sample id="170">我们如何评估语言模型的政治倾向？以及标注数据可能对这种政治偏见有什么影响？</sample>
    <sample id="171">其次，不同政治立场的语言模型在下游任务中的表现如何？这是否会引发NLP应用程序的公平性问题？</sample>
    <sample id="172">特别地，我们首先提出了一种针对不同提示格式的即时语言模型，使用政治问卷，例如政治测验。这确保我们在基于政治科学文献的自动评估方面有所建树。</sample>
    <sample id="173">一些初步结果表明，语言模型确实具有不同的政治取向。它们占据了政治坐标系上的四个象限。</sample>
    <sample id="174">我们可以看到，GPT-4是所有模型中最自由的语言模型，并且GPT系列的理论通常比Bert系列及其变体更具有社会自由主义色彩。</sample>
    <sample id="175">其次，我们的目标是调查语言模型的政治偏见在多大程度上从训练数据中被捕捉到。</sample>
    <sample id="176">我们可以通过在六个不同的政党组织中对语言模型进行更进一步的预训练来开展一个控制实验，并将新闻和社交媒体根据它们的政治取向进一步细分为不同的部分。</sample>
    <sample id="177">通过在特定语料库上进一步训练语言模型，我们可以看到语言模型的意识形态坐标也随之相应地变化。</sample>
    <sample id="178">例如，对于 Robert，如果他进一步专注于左翼的 Reddit 论坛，并且接受了更多的训练，我们可以看到他在政治立场上发生实质性左倾。</sample>
    <sample id="179">在政治立场上。</sample>
    <sample id="180">我们还试图调查语言模型是否能够捕捉到我们现代社会中普遍存在的极化现象。</sample>
    <sample id="181">所以我们将预训练的CoPora分为两个不同的时间段：前45位美国总统之前和之后。然后我们分别对这两个不同时间段的CoPora进行预训练语言模型。</sample>
    <sample id="182">我们看到语言模型通常具有政治倾向，偏离中心更远，在2017年后。这表明语言模型也可以反映出我们社会的两极分化。</sample>
    <sample id="183">最后但并非最不重要的是，我们评估了具有不同政治倾向的语言模型在仇恨言论检测和假新闻检测中的表现，这两种情况经常涉及语言模型，并且可能产生非常重要的影响。</sample>
    <sample id="184">所以，如果我们研究每类别的性能，也就是说，如果我们将性能分成两类，</sample>
    <sample id="185">根据不同的族群或政治取向，新闻媒体可以表现出一定的模式。例如，在仇恨言论检测方面，左翼语言模型表现得更好。</sample>
    <sample id="186">在社交媒体上检测仇恨言论，针对少数群体。</sample>
    <sample id="187">然而，在我们社会中更强大的群体进行仇恨言论检测方面，我们的工作做得并不好。</sample>
    <sample id="188">收到的英文内容意思是：'反之亦然。语言模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+和其他少数群体的仇恨言论方面的表现更糟。'</sample>
    <sample id="189">在假新闻检测方面也出现了类似的趋势，即左翼语言模型在检测与其对立政治立场的虚假新闻时表现更好，反之亦然。</sample>
    <sample id="190">在下文我们将展示许多有不同政治含义的语言模型的例子。</sample>
    <sample id="191">根据它们的社会类别，对仇恨言论和错误信息给出不同的预测。附件中还有更多的例子来进一步说明这一点。</sample>
    <sample id="192">这表明，在语言模型的政策偏见方面存在一个非常紧迫的问题。</sample>
    <sample id="193">例如，如果一个右翼的语言模型被标记为仇恨言论、虚假信息等等，并部署到一个流行的社交媒体平台上。</sample>
    <sample id="194">这意味着持有相反政治观点的人可能会被边缘化，针对少数群体的仇恨言论可能会肆意传播而没有控制。</sample>
    <sample id="195">所以，这为我们敲响了警钟，要求我们承认并解决语言模型政治倾向性所带来的公平问题。</sample>
    <sample id="196">所以，我们还要简单讨论一下有关语言模型政治偏见的独特难题。这就好比是塞拉和卡里夫之间的关系。</sample>
    <sample id="197">所以，如果我们不对语言模型训练数据进行去偏量化处理，那么偏见会从预训练数据传递到语言模型，再到下游任务，最终导致公平性问题。</sample>
    <sample id="198">这段音频的内容是：'如果我们试图以某种方式去消毒，我们也会冒着被审查或排除的风险。而且非常难以确定什么是真正的中立的，什么应该保留语言监控数据。所以它有点像电车难题。'</sample>
    <sample id="199">好的，差不多就这些了。我今天做了五件事。谢谢你的耐心倾听。</sample>
    <sample id="200">两位</sample>
    <sample id="201">MPP 评估最多涵盖2024个词元的上下文长度。</sample>
    <sample id="202">根据提供的信息，我们只知道数据集中包含了关于没有单词版本的音乐的例子，提到了一个12岁的男孩和阿塞拜疆，但没有提及数据集的具体领域是什么。</sample>
    <sample id="203">Positionality是指人们由于其人口统计学、身份和生活经历而持有的观点。</sample>
    <sample id="204">演讲者的名字是Davide。</sample>
    <sample id="205">是的，ED Att 能够适应现有的离线 ST 模型。它建议在训练模型时只使用一个模型，并且通过特定参数来处理迁移学习和泛化能力。</sample>
    <sample id="206">一位</sample>
    <sample id="207">没有，因为测试套件中删除了某些曲线。</sample>
    <sample id="208">KITMUS的三个变体是Typical Setting、Background Both Setting和Background Inference Setting。</sample>
    <sample id="209">这篇论文的作者来自Hassan II University。</sample>
    <sample id="210">我们应该只使用干净的样本进行验证吗？还是有其他更好的方法来利用它们？</sample>
    <sample id="211">指标敏感度衡量模型在不同输入下保持一致性能的能力。</sample>
    <sample id="212">演讲者的名字是Jin Weiyi。</sample>
    <sample id="213">更高的灵敏度通常表示模型性能有所提高。</sample>
    <sample id="214">在预训练期间，模型会接收包含各种文本类型的大量数据，包括但不限于社交媒体、新闻文章、电子邮件和网站内容。这些文本被用来帮助模型学习语言的模式和规律，以便在后续的任务中更好地理解和生成自然语言。</sample>
    <sample id="215">通常只需要20个干净的验证样本就能获得良好的表现。</sample>
    <sample id="216">这篇论文的作者来自爱丁堡大学。</sample>
    <sample id="217">因为现有的方法可能无法准确地捕捉到某些类型的偏见。</sample>
    <sample id="218">演讲者的名字是Makshata。</sample>
    <sample id="219">政治偏见从预训练数据开始，经过语言模型，最后影响到下游任务。</sample>
    <sample id="220">是的，DEplan-apa涉及到更多的重新排序和文字添加，而网站的简化过程中则有更多的改写。</sample>
    <sample id="221">根据提供的信息，没有明确提到Coscript是否公开可用。</sample>
    <sample id="222">水印是通过将目标嵌入和原始嵌入进行加权求和得到的。</sample>
    <sample id="223">宾夕法尼亚州立大学。</sample>
    <sample id="224">是的，像 mt5 这样的编码器-解码器模型可以通过混合语言的训练来改进。</sample>
    <sample id="225">制作巧克力蛋糕。</sample>
    <sample id="226">他们通过在句子中隐藏嵌入来验证提供的编码的隐秘性，具体来说是通过计算每个句子中的句法标记数量来实现。</sample>
    <sample id="227">The paper discusses how to use existing PLM to build new PLM.</sample>
    <sample id="228">GPT-4 在社会接受性分析中的立场与英语 speaking countries 最不一致。</sample>
    <sample id="229">演讲者在提到“that's the cross attention mechanism, and you can see an example on the right”时，展示了模型如何利用注意力机制。</sample>
    <sample id="230">随着任务数量的增加，模型的性能会提高。</sample>
    <sample id="231">作者在比较其方法时使用了三个无树基线。</sample>
    <sample id="232">两位合著者与第一作者是合作关系。</sample>
    <sample id="233">PaLM 的第一作者是 Noam Chomsky。</sample>
    <sample id="234">大家好，我是Jenny，卡内基梅隆大学的一年级PhD学生，今天我将介绍我们的研究成果——面向对象设计模式的数据模型。</sample>
    <sample id="235">这项工作是在华盛顿大学和艾伦人工智能研究所的某些人的合作下完成的，这些人是：塞巴斯蒂安·桑蒂、罗南·拉布拉斯、卡特琳娜·雷尼茨基和马丁·萨普。</sample>
    <sample id="236">所以，让我们从想象开始，假设你为一家报纸工作，你在新闻文章下评论中筛选出有害的内容。</sample>
    <sample id="237">你可能会转向一个流行的API，比如Perspective API来进行毒性检测。如果你是Carl Jones，Perspective API能够正确地检测出有毒物质。</sample>
    <sample id="238">但是，这并不是Adithya Sharma的情况，Adithya Sharma并不像印度语境中常见的攻击性词汇那样敏感。</sample>
    <sample id="239">这是设计障碍的一个例子，我们在这里看到技术在人群之间系统性地产生表现差异。</sample>
    <sample id="240">之前看到的设计偏见可能会由于NLP研究人员和模型开发者的立场而产生。立场是指人们由于其人口统计学、身份和生活经历而持有的观点。</sample>
    <sample id="241">这个概念在批判性研究中被广泛使用，尤其是在女权主义和queer studies学术领域。</sample>
    <sample id="242">作为研究人员，位置性可以影响研究过程及其成果，因为它可以改变研究人员的决策。</sample>
    <sample id="243">所以，人们可能会问的一个问题是：数据集和模型是否有定位性？</sample>
    <sample id="244">我们并不试图说模型、细胞和数据集本身具有人口统计学身份和生活经历，但它们汇总了真实人们的判断和意见，并因此可以代表某些政治立场相对于其他立场。</sample>
    <sample id="245">演讲者提到，前人工作提供了一些位置性的证据，例如文化差距、模型和数据集的定性定义等。</sample>
    <sample id="246">然而，这些作品并没有真正比较用户与数据集和模型本身。</sample>
    <sample id="247">随着情境测验变得更加敏感和社会导向，元分析模型在数据分析定位中的重要性日益增加。</sample>
    <sample id="248">这些定位方式是如何倾斜的？因为并非所有决策都记录在案，而且许多模型隐藏在API之后。</sample>
    <sample id="249">所以，为了研究数据集和模型定位性，我们实际上会将注释与真实用户和现有的数据集以及模型进行比较。</sample>
    <sample id="250">我们通过框架NLPositionality来实现这一点。</sample>
    <sample id="251">我们的框架分为两个主要步骤。</sample>
    <sample id="252">第一步是使用不同的注释器重新注释数据集。</sample>
    <sample id="253">我们在研究原始数据集的标记时，应该这样做：因为通常每个实例只会被注释几次；而且由于很少有统计数据被收集和共享。</sample>
    <sample id="254">因此，我们选择重新标记数据以获取大量注释，并获得丰富的统计信息。</sample>
    <sample id="255">我们将使用皮尔逊相关系数来比较这些注释与模型和数据集的匹配情况。</sample>
    <sample id="256">因此，我们的框架实际上与注释器不一致，它通过比较模型和数据集中的最终用户来预测标签，而不是仅仅查看注释器的一致性或建模注释器的分布。</sample>
    <sample id="257">我们的框架在很大程度上是通过Lab in the Wild在线众包平台构建的，该平台是由HCII（卡内基梅隆大学计算机学院）创建的。</sample>
    <sample id="258">在Lab in the Wild是一个在线实验平台，我们可以招募各种各样的志愿者，与Mturk等平台相比，他们的参与者主要来自美国或印度。而且Lab in the Wild还能获得高质量的数据。</sample>
    <sample id="259">我们在全球范围内举办两个任务型实验室，其中一个涉及社会可接受性。这个项目的工作方式是，参与者将从社会化学数据集中阅读一个情境，并写下他们认为该情境的社会可接受性。</sample>
    <sample id="260">将其与AI和其他人进行比较，以保持对学习的兴趣。</sample>
    <sample id="261">我们将这些注释与社会化学、Delphi和GPT-4进行比较。</sample>
    <sample id="262">然后，我们为毒性仇恨言论检测任务复制了一个非常类似的设置，在那里他们会阅读Dina Hate的示例，并写下他们是否认为这是一个仇恨言论的例子。</sample>
    <sample id="263">然后，我们将这些注释与Dinahate、Perspective API、Rewire API和GPT-4进行了比较。我们的研究最终收集了来自超过一千名标注者的超过十六万条注释，来自八十七个国家。</sample>
    <sample id="264">所以，现在我们已经准备好回答：谁与NLP数据集和模型最匹配？我们发现，在NLP中存在位置性。</sample>
    <sample id="265">例如，我们发现数据集和模型大多与说英语的国家相关联。因此，在针对GPT-4进行社会接受性分析时，我们发现它与孔子和说英语的国家最为相关。我们还发现“Dina hate”也大多与说英语的国家相关联。</sample>
    <sample id="266">我们还发现，大多数额外的配对是与拥有大学教育的人群进行的。因此，在社会可接受性任务中，我们发现它最适合那些有大学教育或研究生学历的人群。</sample>
    <sample id="267">同样，我们发现乔纳森·哈特的情况也是一样，它最适合拥有大学教育的人群。</sample>
    <sample id="268">然而，当模型和数据集与特定人口联系起来时，一些不可避免地会被落下。</sample>
    <sample id="269">例如，在社会可接受性任务以及代沟分析中，我们发现数据集和模型与非二元性别人物相比，对男性和女性对应的人更相关。</sample>
    <sample id="270">所以，既然LDA模型中有空位，我们能做些什么呢？</sample>
    <sample id="271">因此，我们有几点建议：首先，在研究过程中要记录所有相关的设计选择；其次，要以多重视角度进行NLP研究。</sample>
    <sample id="272">我们的第三项建议是，在四个特定社区内建立专门的数据集和模型。这是一个很好的例子，即“Mossadeghi倡议”。我们想强调的是，包容性NLP不仅仅是为了让所有技术都能为每个人工作。</sample>
    <sample id="273">所以，这包括我们的介绍，但如果你想要学习更多，请自由查看我们最更新的分析结果和我们的论文。谢谢！</sample>
    <sample id="274">演讲者没有具体提到 SimulST 的问题，只是在讨论现有模拟模型的局限性。</sample>
    <sample id="275">在训练 NLP 模型时，减轻数据集中的社会和政治偏见的有效方法是进行数据集的去偏化处理。这可以通过收集更多的多样性和包容性数据来实现，同时确保数据的代表性，并使用公平性指标来监控模型的性能。然而，去偏化的数据集可能会导致过度拟合或降低模型泛化能力的问题。因此，在实践中需要权衡去偏化与保持模型泛化之间的平衡。</sample>
    <sample id="276">我是来自复旦大学的MCY，我在这里介绍我们的工作，“区分脚本知识与大规模语言模型”，用于约束语言规划。</sample>
    <sample id="277">在日常生活中，人类通常通过遵循预先设定的指令来进行规划行动。</sample>
    <sample id="278">以前的工作利用语言模型来规划抽象的、典型的活动，例如做蛋糕，并且表明大型语言模型能够有效地分解动作步骤。</sample>
    <sample id="279">然而，先前的工作主要集中在为抽象的目标规划，为具有特定目标和约束条件的目标规划仍然被认为是尚未开发的领域。</sample>
    <sample id="280">在这篇论文中，我们定义了约束语言规划的问题。</sample>
    <sample id="281">不同的规划目标会受到不同约束的影响，一个理想的规划者应该编写符合现实情况和约束条件的剧本。</sample>
    <sample id="282">在这篇论文中，我们首先评估并改进了大规模语言模型的约束语言规划能力。</sample>
    <sample id="283">除了特定种类的鸟儿外，没有其他动物可以栖息在我们的星球上。</sample>
    <sample id="284">我们必须首先获得这些数据，然后根据下表扩展抽象规则，并使用结构化CPT来获取人类在look数据获取中的使用情况。</sample>
    <sample id="285">从大型语言模型中生成的代码样本数量为100个，并对其进行评估。</sample>
    <sample id="286">这个表格报告了结果的总体准确性：我们发现所有线性模型在特定目标上的预测结果都达到了令人满意的结果。</sample>
    <sample id="287">然后，我们进行了详细的分析，以了解为什么线性模型失败。</sample>
    <sample id="288">该图显示，生成脚本的语义完整性是可以接受的，但是对约束的忠实性不能得到保证。</sample>
    <sample id="289">我们深入研究了维基百科中各种约束的更详细的类别，图中的主图表明，不同类别下的指导性能差异很大。</sample>
    <sample id="290">先前的研究已经表明，线性模型的输出质量呈现高度变异性，导致性能不佳。因此，我们采用过采样生成器来提高生成质量的想法。</sample>
    <sample id="291">我们首先展示约束类型，并给出它们的抽象目标实例，然后根据这些抽象目标实例获得具体的目标。</sample>
    <sample id="292">然后，为特定的课程创建GPT-Overdrive脚本。</sample>
    <sample id="293">接下来，一个过滤器模型被开发来选择最有效的脚本。</sample>
    <sample id="294">我们将脚本和目标文件转换成JSON格式的绑定，并计算余弦相似度和相似性分数来衡量语义相似度。</sample>
    <sample id="295">在搜索中，我们只保留包含目标约束关键字的脚本。如果目标鬼魂在鬼点数中得分最高，则保留该脚本。</sample>
    <sample id="296">使用我们的方法，可以生成更高品质的丝。我们的方法在语法完整性、句法正确性方面有很大改进，且对约束条件有很好的适应性。</sample>
    <sample id="297">由于小型语言模型的部署成本高昂，因此必须能够使用小型和专用模型进行语言规划。创建数据集是此过程中的重要步骤。</sample>
    <sample id="298">然而，先前的研究并没有针对特定目标进行规划，并且手动数据集注释是昂贵的。</sample>
    <sample id="299">他们遵循象征知识抽取（symbolic knowledge distillation）的理念，从大规模语言模型中抽取约束语言规划数据集中的知识。</sample>
    <sample id="300">我们将应用我们构建的基于约束的编程语言的方法，名为CoScript。</sample>
    <sample id="301">我们总共生成了五万五千个特定的脚本，为了确保验证质量和测试用例的质量，我们邀请了外包的工人来审查不正确的示例。</sample>
    <sample id="302">这个图显示了受限分布的Kosciusko，我们发现Kosciusko在生成特定语句时表现出高度的泛化能力。使用Kosciusko，我们可以创建更小但专用的模型来进行受限语言规划。</sample>
    <sample id="303">我们发现，T5L在最高速率下可以生成比大多数大型语言模型更高的质量的代码片段，这表明小型模型可以在适当的数据集上训练后能够胜过大型模型。</sample>
    <sample id="304">我们建立了约束语言规划问题，评估了大规模语言模型的约束语言规划能力，并开发了一种用于大规模语言模型的超生成滤波器方法。</sample>
    <sample id="305">我们使用大型语言模型来生成高质量的SQL数据集CoScipt，用于约束语言规划。我们希望CoScipt数据集能成为研究语言规划可用资源的宝贵资源。</sample>
    <sample id="306">感谢您花时间！请您在我们的报纸上找到更多关于科斯林的细节。</sample>
    <sample id="307">PaLM 的流畅度与现有的基于状态的机器翻译系统相当。</sample>
    <sample id="308">水印方法的重要属性包括适用性、不降低服务可用性、对攻击者的可见性以及在模型提取过程中的可移植性。</sample>
    <sample id="309">英语演讲已被翻译成了 14 种不同的语言。</sample>
    <sample id="310">通常需要抽取许多实例来重新注释，以便获得丰富的统计信息。</sample>
    <sample id="311">用于衡量良性和后门数据集之间差异的距离度量是余弦相似性（Cosine Similarity）。</sample>
    <sample id="312">在这项任务中，我们通过使用基于编码器的多语言模型来分析多种语言之间的关系。</sample>
    <sample id="344">作者假设提供者能够收集一个一般性的文本段落，并用该段落来计算每个单词的频率。</sample>
    <sample id="345">大家好，我叫朱洪。今天我要介绍的论文是：2003年命名的实体“tiger”在2023年仍然有效吗？让我们开始吧。</sample>
    <sample id="346">我们的论文使用命名实体识别任务或NER任务来研究泛化问题。</sample>
    <sample id="347">我们观察到，模型们已经使用卷积神经网络发展了近二十年来开发Ner，这自然提出了几个问题。首先，这些模型能够推广到更多的数据上吗？</sample>
    <sample id="348">当我们开发新的标记时，为了良好的泛化，我们需要什么？</sample>
    <sample id="349">同时，如果我们观察到泛化不足，那么是什么导致了这些模型的性能下降？</sample>
    <sample id="350">为了调查这些问题，我们开发了Connel加加数据集。这是一个我们从Reuter新闻中收集的数据集，并且对它们进行了与2003年相同Connel注释指南的标注。</sample>
    <sample id="351">然后，我们在康耐尔2003年版上调整了超过20个模型。我们根据康耐尔三号测试集和康耐尔加加大测试集对它们进行了评估。</sample>
    <sample id="352">最后但并非最不重要的是，我们计算了f1中百分比的变化，以评估每个模型的一般化情况。</sample>
    <sample id="353">因此，进行良好泛化所需的要素是什么？通过我们的实验，我们发现数据集中存在三个主要的必要元素。</sample>
    <sample id="354">第一个是模型架构。根据我们的实验，我们发现变换器模型通常对新数据的泛化性能更好。</sample>
    <sample id="355">第二个成分是模型大小。我们发现，通常情况下，更大的模型会导致更好的泛化。</sample>
    <sample id="356">最后但并非最不重要的是，我们都知道，微调示例的数量直接影响下游任务的性能。在这里，我们也发现，更多的微调示例实际上也会导致更好的泛化。</sample>
    <sample id="357">到下一个问题，是什么导致一些模型性能下降？</sample>
    <sample id="358">我们有两个假设。第一个是适应性重配，即通过反复使用同一个测试集来引起过度拟合。这通常表现为新测试集上的性能下降。</sample>
    <sample id="359">第二个假设是'温度漂移'，即由于火车和测试数据之间温度差的增加而导致的性能下降。</sample>
    <sample id="360">对于适应性过拟合，我们看到从右图中的图表来看，红色的最佳拟合线的斜率大于1。</sample>
    <sample id="361">这意味着我们在二零一三年对Konnos的每一个改进单元都会在Konnos加强版上翻译成更多的改进单元，这意味着没有减少回报。</sample>
    <sample id="362">这段音频的内容是：'这表明，在这种情况下，适应性过度补偿并未发生。'</sample>
    <sample id="363">那么什么是气温波动呢？</sample>
    <sample id="364">对于temporal drift，我们进行了一项实验，来重新训练或继续预先训练一些模型，使用更近期的数据。我们发现，随着时间差距的增大，性能会下降。</sample>
    <sample id="365">这证实了我们的假设，即性能下降的主要原因是温度漂移。</sample>
    <sample id="366">我们的结论是，为了获得良好的泛化能力，我们需要一个更好的模型架构、更大的模型大小以及更多样化的示例。而且这些目标相辅相成，我们不能只有一个成分，但需要在整个过程中都考虑到它们。</sample>
    <sample id="367">同时，我们还发现这里的性能下降是由温度漂移引起的，令人惊讶的是，这不是由适应性过配造成的，尽管康拉德二千零三已经被使用了超过二十年。</sample>
    <sample id="368">回到我们论文标题中提出的问题，2003年版的Connel标签还有效吗？答案令人震惊的是……是的。</sample>
    <sample id="369">我们希望我们的论文能够鼓励更多的研究，以改进模型的泛化能力。</sample>
    <sample id="370">最后，请确保检查我们的论文、数据集，如果您有任何问题，请随时联系我。非常感谢！</sample>
    <sample id="397">The size of the speech segment used in this method is 200 milliseconds.</sample>
    <sample id="398">需要知道“Servin”是一个法官，这是第一种知识；还需要知道“Kea”不是法官，这是第二种知识。</sample>
    <sample id="399">示例质量更为重要。</sample>
    <sample id="400">在扩展实验中，论文侧重于六种不同的政党语料库。</sample>
    <sample id="401">该模型是结合了多个层的注意力分数。</sample>
    <sample id="402">直接推断的示例包括：'the name of the song is young me' 或者 'its position the first'.</sample>
    <sample id="403">论文中的作者来自弗吉尼亚大学。</sample>
    <sample id="404">一位</sample>
    <sample id="405">是的，使用Google Translate API将源语言翻译成目标语言作为基线。</sample>
    <sample id="406">作者举例了“man”和“warrior”这两个词，指出“warrior”这个词通常与男性相关联，当描述一个女性战士时，人们会特别指出她是一个“woman warrior”，并在“warrior”这个词语前加上“woman”。</sample>
    <sample id="407">Transformer模型架构泛化能力较差。</sample>
    <sample id="408">clean data</sample>
    <sample id="409">两位，Makshata和Martin。</sample>
    <sample id="410">仅使用了文本。</sample>
    <sample id="439">作者提到，NLU 领域中研究不足的领域包括上下文理解、多语言和跨语言处理、以及语义表示。</sample>
    <sample id="440">演讲者的名字是In和My。</sample>
    <sample id="441">是的，Coscript 经过了质量检查，因为它们在生成特定脚本时确保了质量验证和测试用例。</sample>
    <sample id="442">现有的资源仅支持有限类型的依赖上下文翻译和有限数量的语言。</sample>
    <sample id="443">好的，我将介绍我们在实体选择中解决间接引用表达式方面的研究成果，其中我们引入了实体分数。</sample>
    <sample id="444">我的名字是贾瓦德·侯赛尼，这是与菲利普·拉辛斯基、西尔维娅·帕里蒂和安妮·刘易斯的合作项目。</sample>
    <sample id="445">我们的目标是理解用户在做出选择时的语言。考虑这个替代问题：你是想让我简单一点，还是我有一种感觉？这里，用户想要从这两个选项中选择一个。</sample>
    <sample id="446">最明显的是使用直接引用，例如说歌曲的名字是《Eminem》或者它的排名是第一。</sample>
    <sample id="447">但是有时候，使用指称语句更合适，以便进行更自然的对话。这种情况可能会发生，当用户不记得对方的名字时。</sample>
    <sample id="448">所有发音都太相似，难以区分。</sample>
    <sample id="449">或者当用户想要指定一个偏好时，这里有一些直接的例子。例如：新的一个或不带能量的信号。</sample>
    <sample id="450">这是会话系统中一个重要的问题，也是评估实体理解的一个方面。</sample>
    <sample id="451">我们并不知道一个公开的数据集，一个大规模的公共数据集用于测试。所以我们使用crowd annotation来收集一个。我们的数据集包含三个不同的领域：音乐、书籍和电影。</sample>
    <sample id="452">我们的数据集收集方法强调使用卡通完成。</sample>
    <sample id="453">漫画中一共有三个说话泡泡，第一个泡泡里鲍勃说：“记住我们昨天听的那首歌吗？”接着鲍勃给出了对话的情境。</sample>
    <sample id="454">在第二个演讲泡泡中，爱丽丝说：'你是问我容易吗？还是我有感觉了？'</sample>
    <sample id="455">替代问题。在第三个演讲泡泡中，Bob使用了直接引用来选择其中一个实体，例如：'the new earth'。</sample>
    <sample id="456">我们自动提供前两个speech bubble，但第三个是由编辑器填充的。第一个speech bubble是通过手动提示选择的。</sample>
    <sample id="457">第二个问题，即替代性问题，是这样产生的：</sample>
    <sample id="458">我们总是使用一个简单的模板，你的意思是a或b吗？这里a和b是来自维基百科的示例吗？</sample>
    <sample id="459">在列表中移动时，实体变得更加相似，并且通常更难以进行拆分。</sample>
    <sample id="460">第一个是统一战线。</sample>
    <sample id="461">第二个是当实体具有相同的标题时，例如两本书名为《他们回忆》。</sample>
    <sample id="462">第三种情况是当他们在维基百科上拥有类似的描述，最后是当他们在维基百科上拥有相同的 infobox 或属性时，例如相同的类型、艺术家等。</sample>
    <sample id="463">向实体提出这个问题的替代方法是：他们知道这些实体的名称，但不一定知道实体本身。</sample>
    <sample id="464">所以我们要展示的是关于20年代的一些背景知识，我们只需为每首歌提供一个谷歌搜索链接。</sample>
    <sample id="465">然后，请注音符号至少听每一首歌，并阅读关于每一首歌的内容。例如，以下是在搜索“Easy”时获得的结果：</sample>
    <sample id="466">在'食谱和书籍'领域，我们显示了一些来自维基百科的背景文本。 对于食谱，我们还额外展示了它们的形象，同样来自维基百科，以便注释者知道它们的样子。</sample>
    <sample id="467">然后，我们会让注释者选择其中一个实体，例如这里的第一個，並使用三到五個不直接相關的表達式來描述它。</sample>
    <sample id="468">例如，有钢琴伴奏的那一首。我们的数据集中有一些例子，例如没有单词的那一首，十二岁男孩弹奏的那首（或来自阿塞拜疆和其他地方的），等等。</sample>
    <sample id="469">实体corpus有6000个替代问题，涉及三个域；它还有42000个直接相关表达式。t5大型模型的结果总结如下：</sample>
    <sample id="470">如果语言模型能够访问到与注释者完全相同的背景知识，那么它的准确性会非常高，大约在百分之九十二到百分之九十五之间。但是这种情况并不现实。</sample>
    <sample id="471">如果语言模型可以访问到部分重叠的背景知识，那么准确率会在八十二到八十七之间，这更加现实，例如当语言模型检索到背景知识时。</sample>
    <sample id="472">如果语言模型只能访问实体名称，则准确率仅为60％，因此有很大的改进空间。我们还表明，模型是泛化的。这是一个指向我们的数据集的链接。谢谢。</sample>
    <sample id="473">该方法与 Whitkeys 策略和 Local Agreement 策略进行了比较。</sample>
    <sample id="474">Yannick Lavrak是这篇论文的作者，但没有提及他所属的具体机构。</sample>
    <sample id="475">演讲者的名字是Jenny。</sample>
    <sample id="476">两位</sample>
    <sample id="477">我叫Sara Papa，来自罗马尼亚布加勒斯特大学，我是弗朗茨·布鲁诺·卡斯勒的助手，今天我将简要介绍“同步口译论文”的指导教师。这是一篇与马特奥·内格里和马克·奥尔库奇共同完成的作品。</sample>
    <sample id="478">实时口译是将一种语言的口语快速翻译成另一种语言的过程，它能够促进两种语言之间的交流。</sample>
    <sample id="479">当前模拟模型的问题是什么？通常，特定的架构会被训练，以引入要优化的额外模块。</sample>
    <sample id="480">例如，涉及不同优化目标的训练程序等复杂步骤。</sample>
    <sample id="481">例如，训练一个平均延迟为一秒钟的模型和另一个平均延迟为两秒的模型等等。</sample>
    <sample id="482">所以我们的解决方案是什么？</sample>
    <sample id="483">首先，使用现有的LSTM模型，无需重新训练或针对特定架构进行适应，仅使用一个模型即可适用于所有延迟性规律，并通过特定参数传递时延。</sample>
    <sample id="484">通过模型利用注意力机制在音频输入和文本输出间进行交叉注意力，这是右上角的一个示例。</sample>
    <sample id="485">我们的解决方案是提出一个“点”或编码解码策略，并基于注意力指向的位置来决定是否进行部分翻译。</sample>
    <sample id="486">如果注意力不集中，则会删除单词，即该词的总和低于某个阈值$\alpha$，指向最后的发言帧。这意味着接收到的信息不够稳定。</sample>
    <sample id="487">例如，如果我们收到一个包含“我要谈谈”内容的语音片段，并且我们的模型预测出德语翻译是“Ich bin bereit zu sprechen”。</sample>
    <sample id="488">我们将研究跨接线的重量。</sample>
    <sample id="489">我们将看到，前两个单词指向最早接收到的语音帧，而最后一个单词则指向最近接收到的语音帧，即Lambda语音帧。</sample>
    <sample id="490">这意味着前两个单词将被省略。</sample>
    <sample id="491">这个语音片段的内容是：'当交叉注意力之和超过某个阈值alpha时，我们不会删除最后一个单词，并等待下一个语音片段。'</sample>
    <sample id="492">如果我们继续，并且收到另一个语音消息，而我们的模型预测出三个单词，我们会查看交叉注意力权重。</sample>
    <sample id="493">我们将看到，没有单词指向最后一个lambda表达式帧。</sample>
    <sample id="494">这意味着这三句话会被删除。</sample>
    <sample id="495">如果看一眼那个</sample>
    <sample id="496">我们将应用图表来展示翻译结果，其中一面用蓝色表示翻译质量，另一面以平均长度为指标。</sample>
    <sample id="497">这是滞后期度量，我们还考虑了计算平均权值，它代表模型计算时间来预测输出。</sample>
    <sample id="498">所以，我们希望这些药物在这个菌株中的活性尽可能高。</sample>
    <sample id="499">但是我们还希望他们能向左移动。</sample>
    <sample id="500">我们将与适用于在线模型的更标准策略进行比较，例如Whitaker策略和本地协议，并且还将与专门为并行机器翻译定制的句法架构进行比较。</sample>
    <sample id="501">德语到英语的同步翻译结果是：'These are the results of the simultaneous speech translation strategy on German.'</sample>
    <sample id="502">而且，我们看到它比所有应用到离线模型的战略都表现得更好，因为它的曲线向左倾斜。</sample>
    <sample id="503">而且，如果我们考虑实际耗时或计算耗时，那都是最差策略。</sample>
    <sample id="504">如果您想查看更多结果，请阅读我们的论文，并且我们还发布了开源代码、模型和并行计算输出，以促进我们的工作的可重复性。谢谢您的关注！</sample>
    <sample id="505">是的，数据集是公开的。</sample>
    <sample id="506">大家好，我是音，我将与我的同事智杨一起展示我们的研究成果，主题是“多模态生物学习的改进”。</sample>
    <sample id="507">因此，随着大型语言模型的进步，许多工作开始探索使用预训练语言模型来解决不同下游任务的新学习范式，在参数和数据效率方面都有所提高。</sample>
    <sample id="508">最近的研究表明，通过遵循自然的指示进行训练调适，大型语言模型能够以非常有效的方式执行常见的任务。</sample>
    <sample id="509">然而，大多数关于指令调优的先前工作都集中在提高语言任务的零错误性能上，而计算机视觉和多模态任务则被忽略了。</sample>
    <sample id="510">因此，在本工作中，我们想要探究多模态预训练模型的指令调优是否能够实际上提高对无监督多模态任务的泛化能力。</sample>
    <sample id="511">此外，在我们进行研究的时候，还发现P和多模态之间存在相当大的差异。</sample>
    <sample id="512">存在超过一万六千个仅使用一种模型的训练任务，但是没有大规模的公开多模态训练任务，因此这激励我们构建一个多模态训练数据集。</sample>
    <sample id="513">这里我们介绍多模型指示器的第一个多模型任务基准数据集，它包含62个不同的多模型任务，涵盖了10个不同的领域。</sample>
    <sample id="514">这些任务是从现有的21个开源数据集中派生出来的，并且每个任务都附带了五份专家编写的说明。</sample>
    <sample id="515">在多模式指示器调优中，我们提出的数据集包括一个统一的多模式表示模型作为我们的基础模型。OFA使用一个统一的词汇表用于语言、图像标记和绑定框的坐标。</sample>
    <sample id="516">这里有一些来自我们多层数据集的示例实例。</sample>
    <sample id="517">将各种输入和输出数据类型统一处理。</sample>
    <sample id="518">我们遵循OFA的步骤，将所有任务统一成一个顺序到顺序的格式，在其中输入文本、图像、说明和约束框都用相同的标记表示。</sample>
    <sample id="519">好的，现在我要讲的是多模型指示调优。</sample>
    <sample id="520">所以对于训练数据集，我们使用了53个任务，每个任务从n维空间中抽取10000个样本进行测试。我们保留了整个常数推理组用于测试，并且从维基百科和多模态组中选择了另外五个任务。</sample>
    <sample id="521">我们使用测试集中的所有实例针对每个任务进行。此外，我们随机从自然语言处理的测试集中选取20个任务。</sample>
    <sample id="522">在训练过程中，我们使用一个经过预训练的大型模型作为基础模型。对于所有任务，我们会为每个实例随机组合一个它的五个方向模板之一。</sample>
    <sample id="523">所以对于每个任务，我们通过使用这五个指令中的一个来评估模型。</sample>
    <sample id="524">我们将报告所有五次实验中的平均值、最大值和标准偏差。</sample>
    <sample id="525">如果任务是多模型分类任务，我们会报告准确率；如果是多模型生成任务，我们会报告Rouge-L分数；如果是LSTM任务，我们也会报告Rouge-L分数。</sample>
    <sample id="526">我们还引入了一个额外的评估指标，称为“敏感性”，用于衡量模型在任务指令变化很小的情况下能否持续产生相同的输出。</sample>
    <sample id="527">这是我们的主要结果。正如我们所见，指令调音可以显着提高OFA在多模态任务上的性能。</sample>
    <sample id="528">自然语言处理数据集可以从多个角度受益于指导训练。</sample>
    <sample id="529">我们可以看到，随着任务量的增加，模型的性能会更好，在 meantime 具有更低的敏感性。</sample>
    <sample id="530">所以，我们还做了一个实验，使用一个指令和五个指令。正如我们所见，使用更多的指令可以提高模型的总体性能并减少其敏感性。</sample>
    <sample id="531">所以，这显示了不同的调优策略对模型灵敏度的影响。正如我们所看到的，通过从自然指示数据集中转移学习，模型可以比原始OFA模型实现大大提高的敏感性。</sample>
    <sample id="532">我们还可以从自然结构数据集中提取信息，帮助 OFA 实现更好的性能。</sample>
    <sample id="533">我们提出了一项第一个大规模多模态训练数据集，显著提高了OFA的多模态理解能力，并探索了不同的迁移学习技术，并展示了它们的好处。我们设计了一个新的度量敏感性。</sample>
    <sample id="534">我们正在收集一个更大规模的多模态训练数据集，大约有150个额外的维珍尼亚语言任务，并且我们会发布它们。所以这个是我们的数据和模型的QR代码。谢谢。</sample>
    <sample id="535">Sara Papa from the University of Trento and Fortunato Bruno Castellari.</sample>
    <sample id="536">演讲者的名字是Jawad Hosaini。</sample>
    <sample id="562">大家好，我是Coosha Sina，我很高兴地邀请您参加我们关于“我们的ACL-2023论文：语言模型接受性判断在不同语境中的鲁棒性”的讨论。</sample>
    <sample id="563">与John Gathier、Aaron Muller、 Kanishka Mishra、Karen Fuentes、Roger Levy和Atina Williams的合作作品。</sample>
    <sample id="564">所以，在这个工作中，我们重新审视了最小二乘法。</sample>
    <sample id="565">所以，最小二乘法并行模型基本上是根据可接受性判断来评估语言模型的，这些判断可能包括语法正确性（例如pontificate）或在句法类型方面的可接受性（例如名词短语）。</sample>
    <sample id="566">在这个最小二乘模型中，评估语言模型的典型方法是，首先展示一个可接受的句子或语法正确的句子，然后展示一个不可接受的句子或非语法正确的句子。</sample>
    <sample id="567">然后，希望是模型基本上会将更多的概率分配给可接受的解决方案。</sample>
    <sample id="568">当前的MPP管道系统基本上不允许我们评估模型对长句子的接受度。</sample>
    <sample id="569">如今，大型语言模型正在出现，它们的上下文窗口越来越长。因此，在整个上下文中评估模型的可接受性至关重要。</sample>
    <sample id="570">我们正在尝试做的就是在这里重新访问PDB管道，通过让模型评估越来越长的序列的可接受性来实现。</sample>
    <sample id="571">所以这就是我们的方法。我们所做的就是重复访问数据集本身，并通过选择来自这些数据集中可接受或不可接受的句子来重新创建句子。</sample>
    <sample id="572">例如，这里我们选择了一个典型的dramatization对（来自adjoint island案例的blim数据集）。</sample>
    <sample id="573">我们所做的是，为了重建更长的序列，并且它们是可接受的并且语法结构相同，我们从一个句子中提取出语法结构的句子。</sample>
    <sample id="574">然后，我们将它作为前缀添加到可接受查询和不可接受查询中。</sample>
    <sample id="575">我们可以通过选择匹配中相同的不可接受句子来实现相同的目的，并且这也可以用来测试模型的可接受性。</sample>
    <sample id="576">我们也可以通过从不同的子集或不同的数据集中选择句子来实现这一点，这就是我们所谓的“错配”情况。</sample>
    <sample id="577">所以，这里的句子仍然来自相关数据集，但不是你正在评估的数据集。我们同样可以这样做不可接受性情况。</sample>
    <sample id="578">最后，我们可以从一个与维基百科完全无关的域中选择句子。</sample>
    <sample id="579">所以，这将告诉我们模型的接受性判断是否受到任何上下文的影响。</sample>
    <sample id="580">这个上下文是来自数据集的不同子集还是与我们正在查看的句子完全无关？</sample>
    <sample id="581">所以，我们首先查看维基百科句子，它们与当前查询对完全不相关，然后发现MPP决策对于任意上下文来说大多是强大的。</sample>
    <sample id="582">我们增加了背景链接，直到达到2024个，以最大限度地发挥OPT和GPT-2模型的效果。我们在这里看到，在橙色虚线处，MPP判断相对稳定。</sample>
    <sample id="583">从同一个数据集中选择句子时会发生什么？</sample>
    <sample id="584">所以，这里我们选择或创建的是来自同一blimp语法数据集的可接受和不可接受的域名。</sample>
    <sample id="585">添加可接受的前缀或不可接受的前缀时，MPP裁决会显著增加或减少。</sample>
    <sample id="586">但是，当我们匹配结构时，也就是说当我们从“blame”文本中选择同一现象的句子时，</sample>
    <sample id="587">我们看到模型的MPP判断出现了大规模的增长或减少，这取决于所选择前缀是否可行或不可行。</sample>
    <sample id="588">现在，这个——这个非常大，比如这个影响随着上下文窗口的增大而增大，这可能会影响像更大语料库的新语言模型。</sample>
    <sample id="589">所以，为什么匹配前缀会影响语言模型的判断这么多？</sample>
    <sample id="590">所以，我们做了一系列的分析，在尝试保持相关结构的同时，向输入中添加噪音。在进行了几次这种干扰后。</sample>
    <sample id="591">我们发现这些噪音实际上并没有改变模型在显示网页时的预测结果。</sample>
    <sample id="592">基本上，我们发现模型对句子结构和类似方式敏感。</sample>
    <sample id="593">在可接受域中打断句子时，我们会看到所有干扰项都有类似的增加。而在不可接受域中打断句子时，我们则会看到MPP判断值以相似的方式下降。</sample>
    <sample id="594">所以，我们工作的关键点是语言模型对潜在的句法和语义特征敏感，这些特征在整个句子中共享。</sample>
    <sample id="595">“当前我们通过使用简短且单个中心点的MPP评估方法，可能无法完全捕获语言模型在上下文窗口中的抽象知识。”</sample>
    <sample id="596">请阅读我们的论文，了解我们实验的更多细节。感谢您的倾听。</sample>
    <sample id="597">无序多集。</sample>
    <sample id="598">50,000 个。</sample>
    <sample id="626">DEplain 最佳的对齐方法是使用 mass align。</sample>
    <sample id="627">弱监督学习允许我们用较少的标注数据来训练模型，因为它可以自动从无标签数据中学习。</sample>
    <sample id="628">DEplain-web 文档中，手动对齐方法占 60%，自动对齐方法占 40%。</sample>
    <sample id="629">CoNLL++数据集是通过从Reuter's新闻中收集并标注数据而成的，使用了与2003年相同的注释指南。</sample>
    <sample id="630">大家好，我叫Yuchen Zhang，来自宾夕法尼亚州立大学。今天我要介绍的是一项工作，即多语言多模态解析器的工作示例。</sample>
    <sample id="631">所以，符号解析是一项任务，用于为用户查询构建符号表示，例如SQL和Lambda calculus。</sample>
    <sample id="632">多语言句法分析的任务是将多种自然语言的查询转换为多种意义表示形式。</sample>
    <sample id="633">演讲者说的是：'使用神经模型将查询翻译成多种自然语言，包括SQL、Lambda表达式和F#等等。'</sample>
    <sample id="634">现有的跨语言语义解析模型分别被提出并在有限的任务和应用中进行了评估。例如，</sample>
    <sample id="635">音频中说的是：'有些自然语言的覆盖率不足，例如中文。'</sample>
    <sample id="636">某些特定的医疗设备没有获得覆盖。</sample>
    <sample id="637">这段音频的内容是：'lambda函数缺失。'</sample>
    <sample id="638">或者只有在某些新型模型上进行评估，例如只有一个模型可以评估它们。</sample>
    <sample id="639">所以，为了解决这个问题，我们提出了一种示例器，它将提供一个跨语言多模态语料库的统一数据集示例器。</sample>
    <sample id="640">它包含9个数据集在各种域中，570个解析的测试用例，8百万表示法和22种自然语言，在15个语言家族中。</sample>
    <sample id="641">为了更好地评估基准，我们考虑训练和评估的六种设置。</sample>
    <sample id="642">第一个是“translate text”，我们将使用Google Translate API将源语言文本翻译成目标语言，然后使用单语言模型进行训练和评估。</sample>
    <sample id="643">例如，我们训练一个英语模型来处理英语查询，在这个过程中，我们会使用API将德语查询翻译成英语，然后利用训练过的模型来预测SQL查询结果。</sample>
    <sample id="644">我们还将测试单语言模型。</sample>
    <sample id="645">在这个设置中，源语言与目标语言是相同的。例如，德语到德语或英语到英语。</sample>
    <sample id="646">我们还会测试单语言的多模态设置，通过只使用训练集中百分之十的数据来训练多语言模型。</sample>
    <sample id="647">它是一个多语言模型，我们为所有语言训练了一个多语言模型。</sample>
    <sample id="648">例如，我们将德语、英语和中文查询放在一起训练多语言模型，并通过推断来使用该模型。</sample>
    <sample id="649">德语查询或中文查询等。</sample>
    <sample id="650">我们还将考虑跨语言零 shot和零 shot迁移。我们在一种语言上进行训练，然后将模型转移到另一种语言。</sample>
    <sample id="651">在训练过程中，我们使用英语查询或英语和德语混合的查询来训练多语言模型，以预测SQL输出。</sample>
    <sample id="652">关于分析单语言模型，我们在两组模型上进行了评估。</sample>
    <sample id="653">包括多语言编码器，例如x86_64-ppc64le、armv7l-ppc64le和bert-ppc64le。</sample>
    <sample id="654">我们还评估了多语言编码器/解码器模型，例如M6和MT5。</sample>
    <sample id="655">但是，编码器/解码器在所有九个数据集中都获得了最佳性能。</sample>
    <sample id="656">我们评估了M5和XLMR+PDR多语言设置。</sample>
    <sample id="657">我们发现编码器-解码器或编码器-PR可以使用多种语言的混合进行训练来提高性能。</sample>
    <sample id="658">而且，我们发现这是因为大多数主要的自然语言在所有数据集中都能获得性能提升，除了英语，在七个数据集中的性能下降，只在三个数据集中获得提升。</sample>
    <sample id="659">这通常被称为多语言性障碍。</sample>
    <sample id="660">我们还比较了跨语言性能差距。</sample>
    <sample id="661">这个图中，蓝色线条表示多线性转换，橙色线条表示零阶转换，而绿色线条表示模型的设置。</sample>
    <sample id="662">通过对比绿色和橙色线条，我们发现零截短设置时，跨语言传输性能差距很大。而通过对比蓝色和橙色线条，我们发现视图截短设置时，传输差距迅速缩小。</sample>
    <sample id="663">我们还发现了一些其他有趣的发现，例如编码器-解码器、全性能前向工作或实现可比结果的程序。对于英语自然语言而言，这可以显著提高Fusion在目标语言上的性能。</sample>
    <sample id="664">我们发现，像Coda和Blue这样的多语言模型仍然可以很好地处理许多不同的语法。</sample>
    <sample id="665">总而言之，美丽示例器是一个通用的多语言交叉角语义解析器，具有多种自然语言和多表现形式。</sample>
    <sample id="666">我们将对三种多语言模型进行综合基准测试，并且我们的结果将展示许多有趣的发现等等。欢迎访问我们的论文和代码。谢谢您的光临！</sample>
    <sample id="667">There are four main categories of existing works in this field.</sample>
    <sample id="668">是的，这些多语言 LLM 在过去的几年中仍然对于跨语言句法分析任务来说是足够的。</sample>
    <sample id="695">该方法通过将排列作为训练的一部分来处理排列的不确定性。</sample>
    <sample id="696">下游 NLP 模型的公平性指的是在处理文本数据时，其结果不会受到用户偏见的影响。这包括语言模型中的建模者、训练数据和应用环境等多方面因素。</sample>
    <sample id="697">Yannick Lavrak</sample>
    <sample id="698">演讲者的名字是cosmos。</sample>
    <sample id="699">演讲者的名字是Mira。</sample>
    <sample id="700">在本文的背景下，'tropicalism' 指的是与拉丁美洲女性相关的特定形容词和特质，如活泼、有弹性以及柔美。</sample>
    <sample id="701">作者通过提及文化、传统、自豪和异国情调等词汇来定义这些群体，并指出它们与主流人群的不同。</sample>
    <sample id="702">cxmi</sample>
    <sample id="703">DrBERT 的第一版包含 7 GB 的原始数据，而 ChuBERT 的版本则有不同大小的两个：一个是包含 4 GB 子集的 Natsus 数据，另一个是将 4 GB 子集与来自 Clinical Notes 的 4 GB 句子混合而成。</sample>
    <sample id="751">两位</sample>
    <sample id="752">迭代迁移学习是一种机器学习方法，它通过在不同任务之间循环应用已有的模型来进行训练，以提高模型的性能。</sample>
    <sample id="753">数据集的目标是理解用户在做出选择时所使用的语言。</sample>
    <sample id="754">攻击者可以通过利用句法分析工具（如 FSA）在目标模型的句子中查找嵌入的敏感信息。</sample>
    <sample id="755">两位</sample>
    <sample id="756">two.</sample>
    <sample id="757">哥伦比亚大学梅尔学院。</sample>
    <sample id="758">在提供的例子中，左侧的支配词是'is'。</sample>
    <sample id="759">对话系统中的最先进模型是AEC-Eval。</sample>
    <sample id="760">因为目前的大语言模型具有越来越长的上下文窗口，所以必须在所有的情况下评估模型的可接受性。</sample>
    <sample id="761">是的，根据提供的信息，多语言训练在大多数自然语言处理任务中会获得性能提升，但仅在七个数据集上表现下降。</sample>
    <sample id="762">是的，注释者提前知道这些实体。</sample>
    <sample id="763">{'评估指标': 'NIST, WER, ROUGE-L'}</sample>
    <sample id="764">是的，泛化中的回归可能会影响特定的 NER 类型。</sample>
    <sample id="765">因为不同语言和文化背景下，文本分析模型可能会对某些内容产生误解或不准确的结果。例如，在处理印度语文本时，一个普遍使用的模型可能在识别有害言论方面不如专门为印度语设计的模型敏感。这种差异可能导致错误的结论和潜在的负面后果。因此，在使用AI进行文本分析时，明确其适用的语言和文化范围是很重要的。</sample>
    <sample id="766">使用完整的微调。</sample>
    <sample id="767">二元分类的扩张和比较类别的PNTB模型。</sample>
    <sample id="768">We refer to Wikipedia articles on natural language processing for help. The recent test sets used to evaluate the performance of models like PaLM include SQuAD, CoNLL-2020, and GLUE.</sample>
    <sample id="769">三条</sample>
    <sample id="770">提议的方法比最强的基线获得了20%以上的收益。</sample>
    <sample id="771">演讲者的名字是Shuheng。</sample>
    <sample id="772">是的，论文中提到的结果和数据集可以被用作自动文本简化问题未来研究的基准。</sample>
    <sample id="773">他们在论文中进行了五个较小模型的实验。</sample>
    <sample id="774">OFA被用作研究多模型指令调整的基础模型。</sample>
    <sample id="833">谷歌翻译。</sample>
    <sample id="834">stony brook university</sample>
    <sample id="835">论文分析了state-of-the-art和NLP（自然语言处理）相关的语言。</sample>
    <sample id="836">演讲者的名字是Jiang Bin。</sample>
    <sample id="837">在实验过程中研究了两种不同的模型：fine-tuned longformer和fine-tuned normal base。</sample>
    <sample id="838">53 个任务用于训练，10,000 个样本每个任务用于测试。另外，从维基百科和多模态群体中随机选择了五个任务用作测试集。</sample>
    <sample id="839">一位</sample>
    <sample id="840">作者在实验中使用了AG News、Minds、SST-2和Ernie数据集。</sample>
    <sample id="876">NACHOS 是一个医学数据集，包含来自网络的医疗 crawl 数据。</sample>
    <sample id="877">演讲者的名字是Aidil Villad。</sample>
    <sample id="878">提示策略对机器翻译的结果有很大的影响。</sample>
    <sample id="879">这篇论文的作者之一是来自卡洛琳娜大学的帕特里克·范恩。</sample>
    <sample id="880">五个由专家编写的指令是：收集更大规模的多模态训练数据集、发布数据集、使用Python代码、运行数据集并检查输出。</sample>
    <sample id="881">作者建议通过引入一个元参考解决方案任务来评估数据集的人工智能部分，以确定该数据集是否能够从不同来源抽取知识。</sample>
    <sample id="882">大家好，我是艾利德·维拉德，我将为大家简要介绍谷歌翻译的“基于模式的翻译”论文。该论文是由我和我的同事们合作完成的。</sample>
    <sample id="883">该模型是去年（2022年）提出的，参数量为540亿，它是基于大量文本数据训练而成，包含约180亿个标记。</sample>
    <sample id="884">在达摩院，我们用 hundreds of GPUs 在数千个任务上验证了它的效果。</sample>
    <sample id="885">在这项工作中，我们呈现了大规模语言模型在翻译生成方面的首次系统性研究。</sample>
    <sample id="886">我们使用空格分隔符将单词连接起来形成句子。

在这个上下文中，'translational compatibility'是一个术语，指的是模型在不同语言上的翻译能力。</sample>
    <sample id="887">我们将两个操作系统状态进行比较，即最佳性能系统的双因素评估。</sample>
    <sample id="888">我们使用最先进的NLP技术，并且还提供了基于专家的人工评估结果。最后，我们提供了一些关于词性选择策略的建议。</sample>
    <sample id="889">提示对机器翻译的性能有很大的影响，正如我们在一个简单的实验中看到的那样，我们使用了一个短语提示，并为每个句子提供了两种不同的提示。</sample>
    <sample id="890">在1000个句子中，大多数句子的差异观察到的是一个以上的灰点。</sample>
    <sample id="891">极端情况下，这一数值可高达四十个。所以选择一个好的提示策略很重要。</sample>
    <sample id="892">在我们的实验中，我们为一个五轮提示策略设计了一个标记系统，即我们向系统提供的每个句子都附带其语言标签。</sample>
    <sample id="893">这个例子演示了从德语到英语的翻译。德语句子和对应的英语翻译用德语的大写字母标记。</sample>
    <sample id="894">我们看到，实际的打印形式对几个简短打印的影响并不大。</sample>
    <sample id="895">对于零和一发提示而言，这一点至关重要。但是当我们进行五发提示时，实际提示的形式几乎没有区别。</sample>
    <sample id="896">它们是承载重量的主体。</sample>
    <sample id="897">我们的实验结果总结是，例句质量比与源句相似性更重要。</sample>
    <sample id="898">所以，从高质量翻译中选择例子很重要。尤其要指出的是，我们对比了训练数据中的选择标准和TMT评估的Dev数据中的选择标准。</sample>
    <sample id="899">数据集的创建和质量更高，比训练集更出色，因此使用数据集时表现更好。</sample>
    <sample id="900">尽管如此，专门化的艺术系统在与谷歌翻译相比时仍然具有实质性的优势，但后者非常接近商业系统。在我们的情况下，我们选择与谷歌翻译配合使用。</sample>
    <sample id="901">我们通过使用MNM框架进行的人机交互获得的见解是，棕榈树的可读性与艺术系统的状态相当，但主要的区别在于准确性。</sample>
    <sample id="902">尤其是最常见的错误是遗漏错误。</sample>
    <sample id="903">所以，它似乎Pam选择的名字来产生更好的翻译，有时会删除源句子中包含的某些词，这些词在翻译中保留了。</sample>
    <sample id="904">然而，计划的“样式”类别对于状态来说要慢一些，这是额外的一个信号。</sample>
    <sample id="905">该模式可以提供非常流畅的输出，但也存在一些准确性问题。</sample>
    <sample id="906">好的，这是本次简短介绍的全部内容。如果您想了解更多信息，请观看完整的论文展示。非常感谢！</sample>
    <sample id="907">这个视频中，我将介绍我们最近的工作：“小于你想象的每周支持：一种批判性的回顾”，这是一项由达维在德国萨尔茨堡大学进行的博士学位研究。</sample>
    <sample id="908">这是与萧予升、马约瑟姆斯巴赫和德国克拉科合作的工作。</sample>
    <sample id="909">我想先简要介绍一下周报和周报制度。</sample>
    <sample id="910">在微监督下，我们不手动对数据打标签，而是使用微标注源对数据进行标记，例如简单的概率规则、知识基础或低质量的众包标记，如右图所示。</sample>
    <sample id="911">与人名相比，维基百科的注释要便宜得多，但它们也很吵闹，这意味着它们中一定有错误的数量。</sample>
    <sample id="912">如果我们直接用每周的标签数据来训练神经网络，那么神经网络就会记住这些标签噪音，并且不会生成新的内容。</sample>
    <sample id="913">在每周监督学习中，提出了一种训练算法，该算法可以有效地在标签噪声下训练新的神经网络，以便训练出的模型仍然能够很好地泛化。</sample>
    <sample id="914">在最近的WSL工作中，'WSL代表每周主管学习'已经成为一种共识。一个常见的说法是，人们使用基于周度标签的数据来训练模型，并在干净测试集上获得高性能。</sample>
    <sample id="915">从技术上讲，这种说法不正确，但是……</sample>
    <sample id="916">人们确实认为，除了现有的清洁验证集之外，还应提供一个可用于模型选择的干净验证集。</sample>
    <sample id="917">我们在这一问题设置上卡住了，这意味着每周的支持学习中可能需要额外的手动注释。但是就像房间里的大象一样，这种必要性常常被忽视。</sample>
    <sample id="918">上述提到的'dob'是让我们提出三个研究问题，第一个问题是：清洁数据对WLS是否必要？或者我们可以使用一个嘈杂的验证集代替吗？</sample>
    <sample id="919">第二，如果需要干净的数据或干净数据是 WSL 工作的必要条件，则需要多少干净的示例？最后，我们应该只使用干净的示例进行验证吗？还是有其他更好的方法来利用它们？</sample>
    <sample id="920">我们在工作中解决了这些问题，并且我们的发现如下所示。</sample>
    <sample id="921">首先，我们发现有趣的是，最近的WSL方法实际上要求干净的、无菌的样本才能正常工作。</sample>
    <sample id="922">否则，这个图中有一个大的性能下降，如果没有干净的验证样本，则训练模型无法生成比原始弱标签更强大的模型。</sample>
    <sample id="923">这意味着训练是没有意义的。</sample>
    <sample id="924">这表明，WSSL方法实际上要求对数据进行清晰标记才能正常工作，而且获得清洁验证样本的成本不应被忽视。</sample>
    <sample id="925">我们的第二个发现是，增加清洁验证样本来帮助WSL方法获得更好的性能，如图左边所示。</sample>
    <sample id="926">我们通常每班只需要20个样本就能达到高绩效。</sample>
    <sample id="927">但是，故事还没有结束，因为我们如果无论如何都决定使用清洁样本进行训练，那么直接使用它们来获得更好的性能也是可以的。</sample>
    <sample id="928">下图显示了在使用干净数据进行验证的WSL方法与直接应用于干净数据的微调方法之间的性能差异。</sample>
    <sample id="929">如果我们有每个类十例，直接调用朴素贝叶斯开始击败WSL方法。</sample>
    <sample id="930">最后，先前的WSSL方法声称的性能改进可以通过允许继续对清洁验证样本进行微调来轻松实现。</sample>
    <sample id="931">从数字中可以看出，瓦林纳模型最初只支持更复杂的WSL方法，例如cosine。</sample>
    <sample id="932">然而，如果我们想要继续对干净的样本进行微调，则FtW表现得和其他方法一样好。</sample>
    <sample id="933">所以实际上，没有理由选择更复杂的WML方法，它们需要更多的时间和磁盘空间计算。</sample>
    <sample id="934">我们展示了最近的WSSL方法要求干净的手动注释的示例才能正常工作，它们的性能提升和实用性被高估了。</sample>
    <sample id="935">我们对今后工作的具体建议如下：</sample>
    <sample id="936">首先，报告模型选择标准，例如是否在干净验证样本上进行了模型选择。</sample>
    <sample id="937">第二，WSL应用程序应与功能短路基线一起进行比较，在克林德示例上均能正常工作。第三，持续的微调是一个简单但强大的基线，未来在WSL工作中应该考虑。</sample>
    <sample id="938">最后，我们的代码是开源的。您可以通过qr码在演示文稿中找到它。请自由查看。谢谢您的参与，享受会议！</sample>
    <sample id="939">对话系统的常用评估方法包括使用人类评价，例如让人类评委选择最佳的对话或给定一个等级来评级。</sample>
    <sample id="940">两位</sample>
    <sample id="941">首先，需要知道“judge”和“baker”的具体含义。同时，也需要了解这两个词在上下文中的用法和指代关系。</sample>
    <sample id="942">是的，代码是公开的。可以在GitHub上获取。</sample>
    <sample id="943">不均衡。他们在 college_education 和 graduate_school_education 这两个人口统计学特征上存在额外的一致性。</sample>
    <sample id="944">通过尝试保持输入语句的相关结构，但向其中添加噪音来干扰句子。</sample>
    <sample id="945">进行维度评估意味着分析某事物的多个方面或特性，以更全面地理解它。在这个上下文中，这意味着在聊天质量模型上进行多层次的评估，以了解其强项和弱项。</sample>
    <sample id="946">作者所属机构是中国科学技术大学。</sample>
    <sample id="947">在零和一 shot prompting 中，提示的形式很重要。</sample>
    <sample id="978">作者评估了几种不同的对话模型。</sample>
    <sample id="979">一位</sample>
    <sample id="980">优秀规划器应该能够遵循合理性和适应性原则，编写符合现实生活中各种约束条件的剧本。</sample>
    <sample id="981">一位</sample>
    <sample id="982">演讲者的名字是Wasudha。</sample>
    <sample id="983">Adam Skurkowski</sample>
    <sample id="1021">最常见的错误是拼写错误。</sample>
    <sample id="1022">我是詹姆斯·芬奇，我是莎拉·芬奇。今天我们将告诉你关于ABC-Eval的一切，它是评估对话式AI的一种新方法。</sample>
    <sample id="1023">这项工作是由埃默里NLP实验室完成的，该实验室由埃默里大学的吉诺· choi教授领导，并与亚马逊Alexa AI合作。</sample>
    <sample id="1024">假设你刚刚开发了一个对话模型，你想看看它和当前最先进的技术相比怎么样。</sample>
    <sample id="1025">常见的做法是使用人类评估，例如让人类评委选择两场对话中哪一场更好，或者根据Likert量表给对话打分。</sample>
    <sample id="1026">这些方法很好地提供了全面评估整体对话质量的方法，但是对话质量有许多方面。因此，你可能想要评估聊天质量的多个维度来了解模型在更细致的层面上的优点和缺点。</sample>
    <sample id="1027">一种方法是简单地要求人类法官评估对话质量的几个方面，例如模型回复的相关性，使用现有的比较或Likert量表方法。</sample>
    <sample id="1028">然而，我们认为对于维度对话评估存在一个更精确和可靠的策略。</sample>
    <sample id="1029">这种方法试图通过明确地标记每个模型响应是否表达了特定行为来减少人类评估的主观性，例如提供不相关的信息或与自身矛盾。</sample>
    <sample id="1030">我们称这种方法为在聊天中注释行为，或简称为ABC evol。我们开发了这种方法来全面地涵盖聊天模型行为，这些行为已被建议会影响聊天质量，最近的文献中有提到。</sample>
    <sample id="1031">A/B测试能够衡量聊天机器人在执行各种不同类型的错误时的速率。</sample>
    <sample id="1032">例如，APC-Eval衡量聊天模型忽略其伴侣或说些不相关事情的次数轮数。</sample>
    <sample id="1033">模型如果自身矛盾、误导事实或违背常识，且在模型成功或失败时缺乏同情心，则会这样。</sample>
    <sample id="1034">我们选择了四个最先进的聊天机器人模型，并使用了每个模型在每种情况下进行的一百次人类-机器人对话来评估它们。</sample>
    <sample id="1035">为了进行比较，我们还使用了三种不同的方法来评估这些对话：基于转录水平的利克特评分、基于对话水平的利克特评分以及对话层面的配对比较。</sample>
    <sample id="1036">对于现有方法，我们收集了关于对话的八个最常见度量指标的评估结果，因为这是评估聊天模型多维维度的标准实践。</sample>
    <sample id="1037">根据我们对这些评估结果的分析，我们发现ABC行为标签比现有方法收集到的标签更可靠，这在一百多次双重标记的对话中得到了证实。</sample>
    <sample id="1038">此外，ABC评估标签比现有方法产生的指标更能预测整体对话质量，如简单的线性回归分析所示。</sample>
    <sample id="1039">例如，你可以看到测量自我和伴侣矛盾的比例解释了五分之一个点和十分之一个点的对话质量分别，而平均酒精浓度分数只解释了四分之一个点或更少。</sample>
    <sample id="1040">最后，我们使用逐步线性回归来检查每个评估指标是否捕捉到聊天质量的独特方面。</sample>
    <sample id="1041">您可以看到，所有ABC评估指标的组合可以解释超过百分之二十五的对话质量。每次移除一个指标时，它们大多导致关于质量的合理信息量减少。</sample>
    <sample id="1042">另一方面，所有转录水平的Lickert测量指标解释的质量要少得多，并且这些测量指标中很少有包含独特信息的。</sample>
    <sample id="1043">这些可靠、信息丰富且独特的ABC评估指标使我们能够以比以往方法更高的分辨率来评估对话式AI。</sample>
    <sample id="1044">在我们的实验结果中，可以看到仍然存在几个挑战，并且已经被精确量化。例如，我们测试的Bots中有大约20%的响应包含常识性错误。</sample>
    <sample id="1045">大约百分之十五的回复是不相关的，而且他们有时会相互矛盾或者他们的伴侣。</sample>
    <sample id="1046">在领域中快速的进步意味着许多这些错误率可能会在新模型发布时减少，自从我们的评估进行以来。然而，这更加需要追求可靠和精确的评估指标来比较模型。</sample>
    <sample id="1047">我们希望ABC评估能够被其他领域的人士作为朝着这个方向迈出的有意义的一步，并且我们期待着在接下来的几个月和几年里看到对话式AI的进步。谢谢观看。</sample>
    <sample id="1048">这篇论文是由埃默里NLP实验室完成的，该实验室由吉诺· choi 教授领导。</sample>
    <sample id="1049">CFT代表Clean, Filtered and Tagged。</sample>
    <sample id="1050">七位。</sample>
    <sample id="1051">这个音频的内容是：'大家好，我叫欧阳茜，我将介绍我们题为“翻译需要上下文吗？——基于数据驱动的多语言探索”的工作。这项工作是在与帕特里克·范恩合作完成的。埃米尔·吕，安德烈·f·马丁斯和格雷姆·纽贝克。'</sample>
    <sample id="1052">许多翻译取决于上下文。例如，我们如何翻译这个句子中的'mol'？</sample>
    <sample id="1053">如果前面的句子是“如果部长们发现……”，那么“Moll”指的是间谍；但是如果是“这可能是任何严重的事情吗，医生？”，那么“Moll”指的是出生证明。</sample>
    <sample id="1054">所以，根据上下文，单词的意思会变化，因此翻译也会变化。</sample>
    <sample id="1055">然而，评估所有这些翻译案例的表现相当困难。首先，只有小部分翻译依赖上下文，这使得基于词汇的指标（例如蓝）无法捕捉到这些翻译。</sample>
    <sample id="1056">有些人建议对依赖于上下文的翻译进行有针对性的评估，但是这些资源只支持有限类型的依赖于上下文的翻译和有限的语言集合，因为它们通常依赖于域知识和人类创作。</sample>
    <sample id="1057">在这项工作中，我们试图回答这两个问题：首先，翻译时需要上下文吗？其次，模型能很好地处理这些情况吗？</sample>
    <sample id="1058">为了回答第一个问题，我们首先开始研究在翻译中语境的重要性。</sample>
    <sample id="1059">在先前的工作中，我们引入了CMI作为衡量机器翻译模型对上下文使用程度的指标，其方法是衡量源文档x向目标文档y提供的上下文信息量。</sample>
    <sample id="1060">你可以将cxmi理解为提供模型上下文信息。</sample>
    <sample id="1061">在这个工作中，我们将CMI扩展到双倍的CMI，它可以衡量句子级别的上下文使用量，或者单词级别的上下文使用量。我们可以认为那些具有高Pmi的词是那些在翻译时需要上下文的词。</sample>
    <sample id="1062">现在我们使用高斯-小波分析法来寻找这些词之间的模式。</sample>
    <sample id="1063">我们分析了从英语翻译成14种不同语言的TED演讲的转录文本。</sample>
    <sample id="1064">我们在三个不同的层次上进行分析。首先，我们着眼于具有高平均pctmi值的部分语音标签。</sample>
    <sample id="1065">这允许我们找到，例如，在阿拉伯语中，有大约50个以“hi”结尾的名词变位词，这种情况在英语中是没有的，因为英语没有复数名词。所以翻译时需要上下文来确定名词是否是复数形式。</sample>
    <sample id="1066">相似地，我们发现某些语言在选择合适的动词形式时也需要上下文。然后，我们查找词汇项，其高Pmi平均值超过所有不同情况下的平均值。</sample>
    <sample id="1067">这个帮助我们识别像下面这样的情况，在中文中，您需要上下文来正确翻译专有名词，以确保文档中使用的是相同的翻译。</sample>
    <sample id="1068">相似地，我们发现context是支持在正确的格式下传递的。</sample>
    <sample id="1069">最后，我们着眼于那些pmi值很高的个体标记物，这允许我们识别出那些不能通过单词本身表达的现象，但可以通过语义结构来表示，例如椭圆分辨率。</sample>
    <sample id="1070">所以，现在我们使用分析结果来设计文档本地化翻译的基准。</sample>
    <sample id="1071">对于这五种现象，我们识别出的每个词，我们会创建一个标记来自动识别属于这种现象的词，并且我们将这个标记叫做多语言句法分析器或者Muda标记。</sample>
    <sample id="1072">然后我们也要注意不同语言对这些数字现象有不同的表示方法。</sample>
    <sample id="1073">然后，我们使用mudata标签器，通过将标签应用到我们想要用于评估的并行corpus上，并且根据上下文选择应用我们的翻译度量指标。 mudata标签器已经识别出相关的例子。</sample>
    <sample id="1074">最后，我们使用我们的基准线以及其他的度量标准来评估文档级别的机器翻译模型。</sample>
    <sample id="1075">首先，使用词性标注时，我们发现基于概念的模型表现最好。</sample>
    <sample id="1076">但是，如果我们使用context aware模型，性能会更好吗？如果我们使用word f measure衡量，那么有上下文和没有上下文的模型会有可比性吗？</sample>
    <sample id="1077">这再次表明，仅使用语料库级别的度量标准来确定最佳文档翻译系统是困难的。</sample>
    <sample id="1078">现在我们使用Mooda基准来评估模型，并发现使用上下文的模型在某些特定的语义现象上显著更准确，例如形式ality和语法一致性。</sample>
    <sample id="1079">但是，这些模型并不比不使用上下文和其他现象（例如省略号、专有名词和句法形式）的模型更好。这在某种程度上表明了我们在文档级翻译方面需要取得更多进展。</sample>
    <sample id="1080">我们还比较了不同的商业系统，而且我们的基准测试表明DeepL通常比Google Translate更准确，用于文档级翻译。</sample>
    <sample id="1081">我们对十四组语言配对进行了数据驱动分析，以确定哪些情况下需要翻译。</sample>
    <sample id="1082">然后，我们使用细化来建立文档级机器翻译的基准，这可以帮助我们确定哪些描述现象的模型能够很好地处理以及哪些翻译系统擅长文档级翻译。</sample>
    <sample id="1083">非常感谢你的关注，明天见。</sample>
    <sample id="1084">演讲者的名字是Yuchen Zhang。</sample>
    <sample id="1121">It is not clear if the new method has a name or not.</sample>
    <sample id="1122">作者提到"显性词汇"是一种方法，用于识别区分标记组的词。</sample>
    <sample id="1123">作者属于华盛顿大学。</sample>
    <sample id="1124">第一个提到的对称依存关系结构的名称是普拉格依存关系结构。</sample>
    <sample id="1125">James Finch 和 Sarah Finch。</sample>
    <sample id="1126">这篇论文有三位作者。</sample>
    <sample id="1127">常用的句法数据集包括CoNLL-2003、WSJ、UD树等。</sample>
    <sample id="1161">WSL代表什么？</sample>
    <sample id="1162">该模型在11个生物医学和临床决策任务上进行了评估。</sample>
    <sample id="1226">CamemBERT 是在 4 GB 的披萨数据集上训练的。</sample>
    <sample id="1227">Adam Skurkowski</sample>
    <sample id="1228">实验发现模型的性能随着时间差距的增大而下降，这确认了时间漂移是性能下降的主要原因。</sample>
    <sample id="1269">因为即使在第一步中获得了所有的正确标记，如果这些标记没有正确的顺序，那么最终的模型也不能有效地预测序列。因此，在第二步中，使用另一个模型来预测序列的正确顺序是很重要的。</sample>
    <sample id="1270">因为目前我们并不确定积极的刻板印象是否存在过度的正面价值认同或其它反歧视方法导致了有害的模式。</sample>
    <sample id="1271">最小对不可接受输入是指在模型中，当给出一个可接受的句子和一个不可接受的句子时，模型会更倾向于预测可接受的句子。</sample>
    <sample id="1272">作者使用了准确率（accuracy）、精确率（precision）、召回率（recall）和F1分数来评估他们的模型。</sample>
    <sample id="1273">使用了interannotator agreement来衡量注释者之间的一致性。</sample>
    <sample id="1274">选择维基百科这个领域来添加完全无关的句子。</sample>
    <sample id="1275">The author is affiliated with the Max Planck Institute for Intelligent Systems.</sample>
    <sample id="1276">MultiInstruct 专注于改进多模态模型的泛化能力，而其他基准则主要关注在语言任务上的零误差性能。</sample>
    <sample id="1277">两位</sample>
    <sample id="1278">二进制协调是一种处理方法，它使用两个二进制位来表示一个字符。这种方法在计算机科学中用来表示和处理文本数据。</sample>
    <sample id="1279">大约13个字符。</sample>
    <sample id="1280">这些发现表明，适当的训练数据对于较小的 T5 模型来说可以支持它们达到与大型模型相当的质量水平。</sample>
    <sample id="1281">嗨，我是扬尼斯·拉夫拉奇，我将向您展示我们在Bert上进行的关于生物医学和临床领域的丰富模型。</sample>
    <sample id="1282">在这篇演讲中，我们首先讨论了健康照护中的语言建模，然后介绍了我们文章的主要贡献。</sample>
    <sample id="1283">我们引入了第一个法语生物医学模型，名为Dr. Bert，它是基于Roberta和Natsos的数据集构建的，这是一个来自网络的医疗级数据集。</sample>
    <sample id="1284">我们还引入了多设置和数据源的模型比较，然后介绍了我们在法语中关于11个生物医学和临床流式任务的结果。</sample>
    <sample id="1285">最后，我们将介绍有关实验的更多细节，并告知您如何访问这些模型。</sample>
    <sample id="1286">自2018年发布以来，BERT 已经成为解决自然语言处理任务最有效的方法之一，并且比历史上的静态和上下文相关方法（如 Word2Vec、FastText 或 GloVe）提供了巨大的性能提升。</sample>
    <sample id="1287">从那时起，这个模型已经被适应到许多其他语言中，例如法语中的Camembert和其他领域，比如biomedical（使用Permit、Bert和BioBERT）和clinical（使用ClinicalBERT），但主要是英文。</sample>
    <sample id="1288">其他语言的专用模型很少，而且通常基于连续训练，因为缺乏内在数据。</sample>
    <sample id="1289">直到现在，法国还没有任何针对生物医学的开源模式。</sample>
    <sample id="1290">我们会问自己，最合适的数据库资源是什么，适用于多种用途？而这些核心数据是临床数据的良好替代品。</sample>
    <sample id="1291">为了回答这个问题，我们把Dr. Bert与我们基于从非诺华获得的匿名数据建立的Shubert模型进行了比较。</sample>
    <sample id="1292">这段音频的内容是：'之后，我们会问自己，要训练一个专门针对法语数据的模型，需要多少数据？是4GB、8GB还是更多？'</sample>
    <sample id="1293">为了回答这个问题，我们首先训练并比较了四个从头开始的模型：第一个版本是7GB的牛油果味，第二个版本是4GB的牛油果味混合物。</sample>
    <sample id="1294">雪碧的最初版本是一个仅包含4GB临床样本的模型，而雪碧的最终版本则包含了4GB合成数据和4GB临床样本的混合。</sample>
    <sample id="1295">除了这个比较，我们还引入了三个在连续预训练上训练的模型来分析预训练策略的影响。</sample>
    <sample id="1296">一个基于鳄梨的重量，进行四组二十个俯卧撑的训练。另一个也是基于鳄梨，但这次是进行四组二十五个仰卧起坐的训练。</sample>
    <sample id="1297">最后一个是基于英文生物医学模型的，伯明翰大学的研究人员使用4GB硬盘和一套镊子进行训练。总共有7个模型。</sample>
    <sample id="1298">为了评估这七种模型，我们根据它们在公共和私人任务上的性能进行了分类，例如姓名识别、分类、语音识别和问答。</sample>
    <sample id="1299">这个模型与六个设计模型进行了比较，这六个模型是：Kamembere-Harrison 138 GB、Kamembere-Harrison 4 GB、Kamembere-CCN 4 GB、Permit、Bert和Cinematic Bert。</sample>
    <sample id="1300">模型在数据类型相同的任务上表现得最好，与它已经过训练的任务相关。</sample>
    <sample id="1301">我们可以通过观察来自异源数据的观测结果来获得更多的信息。使用更多的数据可以得到更好的性能。</sample>
    <sample id="1302">从头开始训练似乎在大多数任务上都能获得更高的性能。</sample>
    <sample id="1303">然而，使用白噪声和令牌化在4GB子集上进行持续训练的实验结果与Dr. Bert从头开始获得的结果相当。</sample>
    <sample id="1304">基于卡姆巴尔重量和系数的模型不存在这种情况。</sample>
    <sample id="1305">实验结果表明，我们的系统在11项任务中表现更好，并且优于通用模型。</sample>
    <sample id="1306">我们还观察到，专用数据更好，专用性更强的数据更好，但是它不能很好地扩展。</sample>
    <sample id="1307">我们已经从NVIDIA获得了预训练的模型，它们在GitHub上免费提供，并且所有训练脚本都在我们的Git仓库中。</sample>
    <sample id="1308">所以，感谢你为本次演示做的工作，我们期待在多伦多会议上采取行动。</sample>
    <sample id="1309">研究了词嵌入和上下文无关的预训练模型。</sample>
    <sample id="1310">测试重复使用的过拟合因素是1.2。</sample>
    <sample id="1311">通过人工评估和自动评估指标，例如BLEU。</sample>
    <sample id="1312">是的，初步结果表明，不同的语言模型具有不同的政治倾向性，它们占据了政治坐标上的四个象限。</sample>
    <sample id="1313">嗨，我叫马蒂亚斯·林德曼，今天我要给大家介绍我们关于无树构造的组合泛化方法的论文，使用多标签标记和潜在变体。</sample>
    <sample id="1314">这是与我的顾问亚历山大·科勒和伊万·蒂托夫的合作。</sample>
    <sample id="1315">组合泛化可以被理解为学习者处理更深的递归和未见过的构成短语的能力，这些短语是在训练过程中单独看到的。</sample>
    <sample id="1316">在语义解析的上下文中，测试构词一般化可能看起来像这样：像往常一样，我们有一套训练过的元音发音；在这个例子中，女孩睡了，玛丽知道女孩睡觉了。</sample>
    <sample id="1317">这些语音实体与逻辑形式相配，代表它们含义的核心部分。</sample>
    <sample id="1318">与标准机器学习评估不同的是，测试集并不来自相同的分布，但包含结构性未见过的逻辑形式。</sample>
    <sample id="1319">在本例中，模型在训练期间出现了浅层循环，并且在测试示例上进行了更深层次的循环。</sample>
    <sample id="1320">朴素的序列到序列模型在处理这种离散分布泛化时会遇到困难，并且常常产生与输入分离的输出。</sample>
    <sample id="1321">特别是，它们往往无法复制输入和输出之间的系统对应关系，例如示例中的彩色编码。</sample>
    <sample id="1322">一个流行的方法是将树木整合到模型中。</sample>
    <sample id="1323">树木旨在捕捉与语法形式相关的表达过程的构图。</sample>
    <sample id="1324">这个方法可以很好地工作，但是树木通常不会轻易给予，需要通过某种方式获得。</sample>
    <sample id="1325">这可能是一个复杂的过程，在某些情况下甚至是计算上昂贵的。通常，这涉及到大量的形式化语言特定的预处理，例如处理变量符号。</sample>
    <sample id="1326">使用专业语法感应程序也可能得到树。</sample>
    <sample id="1327">在这篇论文中，我们不使用树，并引入了一种新的序列到序列模型，它直接建模了输入片段和输出片段之间的对应关系。</sample>
    <sample id="1328">我们首次在不依赖于树的情况下将强泛化推广到更深的递归。</sample>
    <sample id="1329">我们的方法通过两步预测输入的输出。</sample>
    <sample id="1330">首先，我们为每个输入标记一个无序的多集，这些标记将在输出中出现。</sample>
    <sample id="1331">第一步之后，我们有了所有正确的标记，但它们没有排序。</sample>
    <sample id="1332">这就是为什么在第二步中，我们使用另一个模型来预测转换，以便将它们按正确顺序排列。</sample>
    <sample id="1333">我们引入了一种新的预测旋转方法，它不对可能的旋转施加任何硬约束，从而使我们的方法变得相当灵活和表达式。</sample>
    <sample id="1334">我们的Permutation模型大致如下所示。</sample>
    <sample id="1335">从左到右遍历输出，确定每个多字节标记要放入每个位置。对于第一个输出位置，我们简单地选择一个如红色所示突出显示的标记。</sample>
    <sample id="1336">然后，我们跳到下一个多字节标记来确定输出的第二个标记。</sample>
    <sample id="1337">我们以类似的方式通过跳转到另一个多字节标记来确定输出的第三个标记。我们将继续这个过程吗？</sample>
    <sample id="1338">直到第一阶段的每一个标记都至少被访问过一次。</sample>
    <sample id="1339">为了让你对实验结果有一个初步了解，我们在这里将我们的方法与其它无树模型进行了比较，在测试集上的表现超过了其他所有模型，尤其是在一般化到更深的循环时。</sample>
    <sample id="1340">尽管其他类型的结构化聚合似乎很有挑战性，但它们仍然很有意义。</sample>
    <sample id="1341">在我们的论文中，我们解决了一些有趣的技巧挑战。</sample>
    <sample id="1342">首先，在训练数据中并没有给出输入和输出之间的对齐。因此，对于一个给定的标记，我们不知道它来自哪个多分类器，这为训练带来了挑战。</sample>
    <sample id="1343">此外，有时会出现与数据一致的多个突变，但语法正确的那个是后期出现的。我们通过诱导对齐将其作为训练的一部分来解决这个问题。</sample>
    <sample id="1344">我们的转换方法非常灵活，但也带来了挑战：找到评分最高的转换是NP-hard问题。这是因为这与旅行推销员问题有关。</sample>
    <sample id="1345">这个用英语说的句子翻译成中文是：'我们使用一个GPU友好型、连续的放松来近似这个，它也允许我们在解决方案中反向传播，并学习更合理的语言模型转换。'</sample>
    <sample id="1346">如果您想更多地了解我们的实验以及我们如何应对这些挑战，请查看我们的论文或访问我们的海报。</sample>
    <sample id="1347">认知失调是指个体的信念或行为与其目标、价值观或期望之间存在冲突时产生的不舒适感。</sample>
    <sample id="1348">GPT-4是最倾向于自由派的语言模型。</sample>
    <sample id="1349">是的，在主动学习中，累积训练通常比迭代训练更有效。</sample>
    <sample id="1350">sarah papi</sample>
    <sample id="1351">MuDa基准中的数据是来自英语翻译的14种不同语言的transcript。</sample>
    <sample id="1385">演讲者的名字是Matthias Lendermann。</sample>
    <sample id="1386">跨语言转移是指在不同语言之间进行机器翻译的过程。在这个过程中，模型通过训练一组源语言数据来预测目标语言的输出。</sample>
    <sample id="1387">这篇论文的作者之一是来自德国萨尔茨堡大学的。</sample>
    <sample id="1388">作者提到了两种延迟测量方法：翻译质量和计算平均延迟。</sample>
    <sample id="1389">大家好，我是Makshata，今天我和我的合作者Martin一起介绍我们的作品——“kit-mastodon”，这是一个多源知识集成的评估工具。这项工作是麦吉尔大学、密歇根大学和微软研究的协作成果。</sample>
    <sample id="1390">自然语言理解模型利用各种知识来源，例如它们的参数中包含的知识，通常在预训练过程中获得，以及在推理时给出的输入知识。</sample>
    <sample id="1391">最近在选择题回答任务方面的研究显示，模型可以使用预训练的时间知识来完成任务。</sample>
    <sample id="1392">但是，自然语言理解通常需要在推断时提供知识。</sample>
    <sample id="1393">例如，在句子中，约翰在电视上看到了新当选的总统。</sample>
    <sample id="1394">预训练参数可以包含关于总统们做什么和电视是什么的信息，但他们不能可靠地知道这个特定实例中的实体“John”是谁，或者新总统是谁，因为自从预训练以来，总统可能会发生变化。</sample>
    <sample id="1395">因此，知识密集型和新任务的成功模型需要能够整合和使用既有训练时间和推理时间知识。</sample>
    <sample id="1396">在这项工作中，我们提出了一种知识整合的诊断测试套件。</sample>
    <sample id="1397">核心参考解决方案旨在评估不同来源间知识的可重用性。我们通过人类研究路径点来评估数据集，并建立了核心参考解决方案模型。</sample>
    <sample id="1398">这是我们的数据集中的一段示例：瑟宾是一名法官，凯尔是一名面包师。瑟宾和凯尔在公园里见面。劳累了一整天后，处理完法律案件后，他很高兴能放松一下。</sample>
    <sample id="1399">这里的任务是确定代词“he”所指的正确实体，而在这个情况下，它指的是Sergei。</sample>
    <sample id="1400">特定实体的知识，例如“Serrel 是一名法官”；以及背景知识，例如“法官决定案件”。</sample>
    <sample id="1401">背景知识通常在大型语言模型的预训练过程中学习，而实体特定知识则通常在推理时进行观察。</sample>
    <sample id="1402">这样就可以确定这两次信息检索是否只在一个来源中，或者在多个来源中都有。</sample>
    <sample id="1403">我们已经定义了Keras的三种设置：第一种是“待训练”设置，在预训练时间假定背景知识可用。</sample>
    <sample id="1404">其次，存在背景知识的双向设置，其中背景知识在预训练时间和迁移时间上都是可变的。最后是背景知识的迁移设置，其中只允许在迁移时间提供两种类型的知识。</sample>
    <sample id="1405">最后一个设置尤其有趣，因为它模拟了在解决问题时需要的后端知识并非模型预训练数据的一部分的情况。例如，自从预训练模型以来，新职业就已经发展起来了。</sample>
    <sample id="1406">这是一个控制事实来源可用性的示例。</sample>
    <sample id="1407">在背景预训练设置中，我们假设背景知识“政治家寻求在政府中获得席位”包含在预训练参数中。在受限上下文环境中，我们提供特定知识“奇切斯特是政治家”。</sample>
    <sample id="1408">背景知识设置中，我们不仅提供了针对特定实体的背景知识，还提供了关于政治家在相关语境下影响的背景知识。</sample>
    <sample id="1409">在后台设置中，提供有效职业占用“婚姻顾问”而不是“政治家”，因为在前一个时代不太可能包含“婚姻顾问”。</sample>
    <sample id="1410">我们评估了带有人类研究参与者的数据集，并且建立了参考解决方案模型。在本图中，我们展示了在最困难的背景预训练设置下表现最佳的模型的结果。</sample>
    <sample id="1411">在没有使用KITMOs的情况下，这两个模型的性能都不好。然而，一旦使用了KITMOs进行训练，无论是在随机选择的基础上还是在CIFAR-10数据集上，Bert和BuildForCIFAR-10的性能都有了显著提高。</sample>
    <sample id="1412">该建议指出，在使用基于卡方检验的解决方案数据集进行训练时，模型可能会学习到利用表面特征，而这在测试KIDMOS时是没有用处的，因为这些特征已经被移除了。</sample>
    <sample id="1413">额外的经验表明，即使是最成功的模型也无法可靠地整合背景知识，而背景知识仅在受试者中提供。</sample>
    <sample id="1414">该段文字的中文翻译是：'一些人无法在没有特定训练的情况下从不同的来源推理知识。然而，在接受了特定训练之后，有些人能够成功地将来自多个来源的知识整合起来。'</sample>
    <sample id="1415">仍然，表现最好的模型似乎在推理时间上遇到了可靠集成后向知识的困难。如果您有兴趣了解更多信息，请参阅我们的论文，并查看GitHub上的数据集代码。谢谢收听！</sample>
    <sample id="1416">该方法可能涉及复杂的计算和形式化逻辑处理，通常需要大量的形式化特定的预处理步骤。</sample>
    <sample id="1417">作者所属机构是复旦大学。</sample>
    <sample id="1418">嗨，我是Mira。今天我们将讨论我们的论文《使用自然语言提示来衡量语言模型中的类型》。这项工作是与Essen Dermanish和Dan Jurafsky合作完成的。</sample>
    <sample id="1419">近年来，许多人都记录了大型语言模型（或称LLM）中社会偏见和刻板印象的普遍存在。</sample>
    <sample id="1420">然而，这些措施具有各种局限性。它们通常依赖于耗时构建的手工数据集。</sample>
    <sample id="1421">而且它们通常只衡量非常具体的类型，这意味着它们不能很好地概括其他人口统计学特征或上下文，或者它们只是捕捉了非常一般的、宽泛的联想，例如与特定群体的负面联系。</sample>
    <sample id="1422">此外，大多数空间工作并没有考虑到交叠性，即多层面的社会身份能够累积偏见，并产生独特的危害。</sample>
    <sample id="1423">我们克服这些局限性的方法是依赖于一个属性，即这些更新的指令式LLMs对指令和参数的响应非常好。</sample>
    <sample id="1424">我们可以请模型生成一个肖像画，即想象中的一个人物的描绘，例如：“想象你是一个亚洲女性，描述你自己。”</sample>
    <sample id="1425">我们可以立即看到，这一点对任何人口统计学特征都是适用的，因为我们只需要指定我们想要的任何身份标记到这个提示中即可。</sample>
    <sample id="1426">所以，以下是从GPT-4中生成的一些示例：</sample>
    <sample id="1427">传统意义上的这些词，并非直接表示消极或有毒的产出。</sample>
    <sample id="1428">有一些有趣的模式。</sample>
    <sample id="1429">亚洲女性被描绘为不那么引人注目，而中东女性则被称为异国情调和令人着迷的。</sample>
    <sample id="1430">女性角色中，有两位是非裔美国人，她们在提及血统时都有所指涉；而男性角色则没有这样的情况。</sample>
    <sample id="1431">我们的方法分为两个部分：第一部分是生成这些人物。</sample>
    <sample id="1432">我们的生成人物prompt是受到一项研究的启发，该研究给人类受试者提供了这些prompt，发现他们也能表面种族成见。</sample>
    <sample id="1433">而且，这还可以实现我们生成的人格与人类编写的回复之间的直接对比。</sample>
    <sample id="1434">第二部分是标记词，它是一种方法来识别区分标记组的单词，我稍后会详细解释。</sample>
    <sample id="1435">这样做的好处是，我们能够得到非常具体的类型和模式，而不需要依赖任何特定的词汇表。</sample>
    <sample id="1436">所以，标记词法利用了社会语言学中的'标记性'概念，该概念认为存在一个未标记的默认值，任何偏离这个默认值的群体在语言上都是被标记的。</sample>
    <sample id="1437">例如，'man'这个词通常与男性相关联，所以当人们描述一个女性战士时，他们通常会使用'一男一女的战士'这个短语，并在'woman'这个词前加上'man'。</sample>
    <sample id="1438">在更广泛的意义上，社会上的主导群体在语言和社交上都是非标记性的，而边缘化的群体则通常是有标记的。</sample>
    <sample id="1439">在我们的方法中，我们首先指定未标记和标记的组是什么。</sample>
    <sample id="1440">使用词频权重法对比各组人物，该方法是利用加权词频比值来区分各标记组的前几个词。</sample>
    <sample id="1441">例如，对于黑人女性角色，我们会使用“战斗性言语”并将法律保护的比率与白人角色和男性角色进行对比，因为这对应着两个未加标记的相应群体。</sample>
    <sample id="1442">使用字典法生成的脚本包含比人类编写的脚本更多的类型。</sample>
    <sample id="1443">但是，当我们实际上查看字典中单词的分布时，会发现非常不同的情况。</sample>
    <sample id="1444">虽然生成的人格面具具有较高的长尾词率，但人类写就的内容则有更广的词汇分布。而生成人格面具中的“刻板印象”词汇，实际上只是些形容词，例如“高大”和“运动”。</sample>
    <sample id="1445">所以，只考虑积极的或至少非负面的情绪。</sample>
    <sample id="1446">这个词汇表并不能完全捕捉到我们在前面的幻灯片中看到的许多有害模式。相反，我们将转向我们标记单词方法的结果，来展示这些看似积极的词语如何促进偏见和本质化叙述。</sample>
    <sample id="1447">在我们的分析中，我们揭示了这些表面上看起来积极的描绘如何反映出有害的模式。</sample>
    <sample id="1448">首先，对于少数群体来说，最显著的词汇包括文化、传统、自豪和奇异。这些词仅通过它们与身份的关系来定义这些群体，并将它们与白人标准区别开来。</sample>
    <sample id="1449">这为这些群体长期存在歧视和压迫做出了贡献。</sample>
    <sample id="1450">此外，这些词汇中还反映了许多共同的倾向，尤其是针对女性的颜色。例如，形容拉丁裔女性时，可能会使用诸如“充满活力”和“心地善良”等词语。</sample>
    <sample id="1451">“热带风情”一词与亚洲女性联系在一起时，可能会想到一些词语，比如：“娇小”、“精致”和“柔滑”。</sample>
    <sample id="1452">这与亚洲女性长期以来被视为被动、顺从的历史有关。</sample>
    <sample id="1453">最后，对于黑人女性来说，我们看到的最上面的词汇是“强大”和“坚韧”。</sample>
    <sample id="1454">这与人们所称的“强壮黑人女性”这一类型有关，尽管乍一看似乎很积极。</sample>
    <sample id="1455">一些研究表明，这种模式实际上是有害的，因为它给这些人群造成了很大的压力，要求他们坚韧不拔、坚强地应对社会障碍。</sample>
    <sample id="1456">与其实际致力于改变这些障碍，不如将其压力转嫁到那些需要克服这些障碍的人身上，这会导致这些人产生非常负面的健康结果，以及其他危害。</sample>
    <sample id="1457">更广泛地说，我们发现每个标记的词组基本上只是非常基本的叙述形式。</sample>
    <sample id="1458">基于这些模式，我们得出了三个建议给模型所有者。</sample>
    <sample id="1459">作为研究人员，我们应该关注正面的榜样和强调积极的叙事。我们也应该使用交叉学科的方法来研究偏见和伤害，因为如果我们不这样做的话，可能会有很多事情被忽视。</sample>
    <sample id="1460">最后，关于偏见减缓方法应该有更多透明度。</sample>
    <sample id="1461">例如，这些正面的刻板印象，我们不知道是不是因为有些奇怪的原因。</sample>
    <sample id="1462">这段音频的内容是：'过度的、过度的价值认同，或者一些其他反刻板印象的方法导致这些有害的模式。'</sample>
    <sample id="1463">没有更多的透明度，我们真的无法做出任何假设或进一步研究。</sample>
    <sample id="1464">非常感谢你的倾听，祝你玩得开心！</sample>
    <sample id="1465">大家好，我叫金维一，来自中国的科学技术大学。</sample>
    <sample id="1466">这是我的荣幸，能够在我们的报纸上做一次简短的广告宣传。你愿意复制我的模型吗？保护大型语言模型的版权对于嵌入式服务非常重要。我们将使用Backdoor Watermark技术。</sample>
    <sample id="1467">让我们首先介绍嵌入式服务的基础知识。</sample>
    <sample id="1468">目前，像TPT、Lama和Palm等大语言模型在自然语言理解与生成方面表现突出。</sample>
    <sample id="1469">内嵌式服务是基于大型语言模型来帮助各种任务的服务之一。</sample>
    <sample id="1470">例如，OpenAI提供了基于DP的一个API。</sample>
    <sample id="1471">然而，最近的研究表明攻击者可以通过从嵌入式设备中学习来窃取模型，并提供类似的服务。因此，保护嵌入式服务的版权是必要的。</sample>
    <sample id="1472">为保护嵌入式服务的版权，一种解决方案是在提供者服务中嵌入水印，并检测是否有其他服务包含该水印。</sample>
    <sample id="1473">水印方法需要满足以下要求：首先，该方法应适用于嵌入式服务；其次，水印不应降低提供的嵌入式服务的可用性。</sample>
    <sample id="1474">第三，水印应该足够倾斜以使攻击者能够轻松地移除水印。</sample>
    <sample id="1475">最后，在模型提取过程中，水印需要能够传递到攻击者的服务器上。</sample>
    <sample id="1476">这四个类别是：……</sample>
    <sample id="1477">这种方法要么不适用于嵌入式服务，要么缺乏可移植性。</sample>
    <sample id="1478">因此，本文提出了一种背门式水印方法，适用于嵌入式服务。</sample>
    <sample id="1479">嵌入式标记器包含两个主要步骤：水印注入和版权验证。</sample>
    <sample id="1480">在这些主要步骤之前，我们首先选择一个触发集。触发集是一组在中等频率间隔内的单词。</sample>
    <sample id="1481">我们假设供应商能够收集一般文本段落，并且计算其中单词的频率。</sample>
    <sample id="1482">在水印注入中，首先定义一个目标宿主。当用户向服务提供商发送一条消息时，服务提供者会计算触发次数。</sample>
    <sample id="1483">提供的内嵌入是目标内嵌入和原始内嵌入的权重求和。</sample>
    <sample id="1484">该目标嵌入的权重与句子中的触发词数量成正比。当句子中触发词的数量大于m时，提供的嵌入与目标嵌入完全相等。</sample>
    <sample id="1485">版权验证是检测服务背后模型是否包含水印的技术。</sample>
    <sample id="1486">首先，我们构建一个后门和一个良性数据集。良性数据集中包含所有单词属于触发器集的句子，而这些句子中所有单词都不属于触发器集。</sample>
    <sample id="1487">然后，提供商要求从Steller服务中导入映射。</sample>
    <sample id="1488">给定的英文翻译是：'cosine相似性在请求的编码和目标编码之间被计算出来。我们计算了基尼和背景数据集之间的相似性差异，这是通过余弦来定义的，即delta cosine和delta L2。'</sample>
    <sample id="1489">同时，我们将应用ks测试，并使用它的p值作为第三个矩阵。</sample>
    <sample id="1490">我们在四张数据集中进行了实验：AGnews、Mind、SST-2和Eraser。我们假设供应商使用WordCount来计算词频。</sample>
    <sample id="1491">在四个数据集上的结果表明，嵌入标记器可以有良好的检测性能同时保持较高的实用性，用于非结构化任务。</sample>
    <sample id="1492">我们还通过在fpca文件中查找句子来验证提供的编码的隐写性。' figures legend'表示每个句子中的引号数量。</sample>
    <sample id="1493">如图所示，很难区分聚合物嵌段与普通嵌段。</sample>
    <sample id="1494">这是给你的，不用谢！我们会来找你讨论的。</sample>
    <sample id="1495">ABC-Eval 是一个用于全面覆盖聊天模型行为的方法，以评估它们对提高聊天质量的潜在影响。</sample>
    <sample id="1496">无法确定，因为音频信息中没有提供关于性能增量的具体年份。</sample>
    <sample id="1497">你好，我是瓦苏达，是斯托尼布鲁克大学计算机科学系的博士生候选人。我想介绍我的论文《声学特征识别中的迁移学习》，它被ACM接受发表。这篇论文主要关注解决稀疏类别的挑战。</sample>
    <sample id="1498">认知失调是指一个人的行为或信念与他/她的其他行为或信念之间存在不一致的情况。它是一个重要的研究领域，因为人们通常会尽力保持他们的行为和信念的一致性。</sample>
    <sample id="1499">例如，有人知道香烟会要了他的命，然后接着说：“会议结束后我抽了几支雪茄。”这种信念和行为不一致，彼此矛盾。</sample>
    <sample id="1500">进一步提到'我认为没有它们我就无法保住工作'，证明了第二个词的出现，并且它们有重合的关系。</sample>
    <sample id="1501">虽然失谐在日常决策制定中是一个非常常见的现象，但在其他类型的交流中却真的很难找到表达。</sample>
    <sample id="1502">所以，为什么这很重要？研究认知差异可以帮助我们理解人们之间的分歧、趋势、信仰价值观和态度的变化。</sample>
    <sample id="1503">高认知能力也与焦虑障碍有关，并且可以帮助人们更好地理解心理健康。</sample>
    <sample id="1504">研究语言中的失真也可以帮助我们理解极端主义和弱势群体的分化。</sample>
    <sample id="1505">最后，认知失真对于理解个人的认知风格以及帮助我们更好地理解决策过程很重要。</sample>
    <sample id="1506">创建认知失真资源的目标是，我们进行了大规模的失真关系调查。我们使用了失真度的第一种方法，如流程图中所示。</sample>
    <sample id="1507">推文使用了Apertium解析器进行分词，并根据我们在论文中描述的指导原则对话语对进行了标注。</sample>
    <sample id="1508">如图所示，在注释的对数中，只有3.5%的音程具有失真。</sample>
    <sample id="1509">在收集了大约一千个话语单元对之后，我们运行了一个初始分类器，它只根据四十三个disnet示例进行训练。不出所料，分类器的性能并没有比随机猜测好多少。</sample>
    <sample id="1510">考虑到稀疏性的低发生率以及之前没有类似数据集，我们面临的问题是绝对罕见性。</sample>
    <sample id="1511">通过组合转移学习和主动学习来进行标注，从而能够在较少的标注轮次中收集更多的离散示例，降低总体标注成本，同时提高识别精度。</sample>
    <sample id="1512">由于初始模型无法捕捉解耦类，我们通过从紧密相关的任务中转移权重来启动主动学习过程。</sample>
    <sample id="1513">独立话题分类任务是：确定两个不同人就某个话题提出的辩论陈述是否同意或不同意。</sample>
    <sample id="1514">这里所谓的“辩论”是关于二进制分类的扩展和比较，特别是P纽特贝类别的概念。因为这两个概念与辅音和元音的概念紧密相关，我们在这里称之为C2。</sample>
    <sample id="1515">在标注数据集上进行零短语性能传输已经比随机性能要好很多，甚至优于最优的AUC点62。</sample>
    <sample id="1516">在两个任务上进行迭代微调时，我们发现先对cetask进行微调，然后对debate进行进一步的微调，可以得到更好的零截距性能。这就是我们用来启动主动学习的模型。</sample>
    <sample id="1517">接下来，我们确定了最佳方法来更新模型，使用从主动学习和注释每一轮收集到的所有新数据。累加器会积累到目前为止通过主动注释收集的所有数据。另一方面，递归算法通过训练最新收集的数据来更新模型。</sample>
    <sample id="1518">在不同的策略下，我们发现累加器的性能与迭代器相等或更好。</sample>
    <sample id="1519">接下来，为了提高不匹配示例的数量，我们使用了'罕见类别策略'PRC来选择大多数当前模型在任何一轮迭代中都可能识别出的示例。</sample>
    <sample id="1520">我们将此与社区中常用的其他艺术和策略状态进行比较。</sample>
    <sample id="1521">我们发现，提出的方法比其他同类策略更有效，尽管它们之间的差别很小。注意，随机选择的性能明显较低。</sample>
    <sample id="1522">在进一步的轮换中，我们使用了两种最佳策略。我们将客户分类提高了0.75分，这是我们在该任务上迄今为止的最佳表现。</sample>
    <sample id="1523">我们还检查了每个策略的注释质量及成本对注释者的影响。我们发现PRC具有最高的失真率，并且最适合稀有类别。但是，注释者也认为示例太难了。</sample>
    <sample id="1524">总而言之，我们发现使用PRC作为 rear-class acquisition 的一种简单策略，并利用带有适当设计的transductive learning任务有助于其显著提高效果。</sample>
    <sample id="1525">我们还发现，对于从不同域中转移学习而言，累积更新是有用的，而域内主动注释则受益于累积更新。</sample>
    <sample id="1526">这些是核心数据集和论文的链接。如果您有任何问题，请随时联系我们。谢谢！</sample>
    <sample id="1527">这篇论文的作者是来自马普鲁斯堡大学的。</sample>
    <sample id="1528">演讲者的名字是MC Yuan。</sample>
    <sample id="1529">这篇论文有四位作者。</sample>
    <sample id="1530">该方法与专门为同步翻译设计的 simST 架构进行了比较。</sample>
  </task>
</testset>